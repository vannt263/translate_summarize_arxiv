{"cells":[{"cell_type":"markdown","metadata":{},"source":["## C1: TextRank"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"puwMbLlcJiE4","outputId":"1f6de98f-5734-4ba5-946b-54ee261bca7c","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package stopwords to\n","[nltk_data]     C:\\Users\\duyen\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]}],"source":["import numpy as np\n","import networkx as nx\n","from sklearn.metrics.pairwise import cosine_similarity\n","import nltk\n","from nltk.corpus import stopwords\n","\n","# Download stopwords if not already present\n","nltk.download('stopwords')\n","stop_words = stopwords.words('english')\n"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"1RpuIZfTkw0F","trusted":false},"outputs":[],"source":["word_embeddings = {}\n","f = open('glove.6B.100d.txt', encoding='utf-8')\n","for line in f:\n","    values = line.split()\n","    word = values[0]\n","    coefs = np.asarray(values[1:], dtype='float32')\n","    word_embeddings[word] = coefs\n","f.close()"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"mZ548b_gnqWy","outputId":"89b3f0e7-22f0-434c-c7f8-ebc22b9243a9","trusted":false},"outputs":[],"source":["def remove_stopwords(sen):\n","    sen_clean = \" \".join([i for i in sen if i not in stop_words])\n","    return sen_clean"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"FhJhkIfInull","trusted":false},"outputs":[],"source":["def generate_text_rank_summary(text, per):\n","\n","    sentences = [sentence.strip() for sentence in text.split('.') if sentence.strip()]\n","    clean_sentences = [remove_stopwords(r.split()) for r in sentences]\n","\n","    sentence_vectors = []\n","    for i in clean_sentences:\n","        if len(i) != 0:\n","            v = sum([word_embeddings.get(w, np.zeros((100,))) for w in i.split()]) / (len(i.split()) + 0.001)\n","        else:\n","            v = np.zeros((100,))\n","        sentence_vectors.append(v)\n","    sim_mat = np.zeros([len(sentences), len(sentences)])\n","\n","    for i in range(len(sentences)):\n","        for j in range(len(sentences)):\n","            if i != j:\n","                sim_mat[i][j] = cosine_similarity(sentence_vectors[i].reshape(1, 100),\n","                                                  sentence_vectors[j].reshape(1, 100))[0, 0]\n","\n","    nx_graph = nx.from_numpy_array(sim_mat)\n","    scores = nx.pagerank(nx_graph)\n","    num_sentences = int(len(sentences) * per)\n","    ranked_sentences = sorted(((scores[i], s) for i, s in enumerate(sentences)), reverse=True)[:num_sentences]\n","    summary = '.\\n'.join([sent for score, sent in ranked_sentences])\n","\n","    return summary\n"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["summary :\n","On the other hand, news articles can vary significantly from source to source.\n","Thus, we will build a tool that can easily be adapted to any number of sources\n"]}],"source":["text = \"\"\"\n","The quality, type, and density of information conveyed via text varies from source to source. \n","Textbooks tend to be low in density but high in quality, while academic articles are high in both quality and density. \n","On the other hand, news articles can vary significantly from source to source. \n","Regardless of where the text comes from the goal here is to minimize the time you spend reading. \n","Thus, we will build a tool that can easily be adapted to any number of sources.\n","\"\"\"\n","\n","summary = generate_text_rank_summary(text,0.4)\n","summary_sentences = summary.split('. ')\n","formatted_summary = '.\\n'.join(summary_sentences)\n","print(\"summary :\")\n","print(formatted_summary)"]},{"cell_type":"markdown","metadata":{},"source":["---"]},{"cell_type":"markdown","metadata":{},"source":["## C2: Tính độ quan trọng dựa vào tần suất từ"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["import spacy\n","from spacy.lang.en.stop_words import STOP_WORDS\n","from string import punctuation\n","from heapq import nlargest"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["def summarize(text, per):\n","    nlp = spacy.load('en_core_web_sm')\n","    doc= nlp(text)\n","    # tạo từ điển để lưu lại tần số các từ\n","    word_frequencies={}\n","    for word in doc:\n","        if word.text.lower() not in list(STOP_WORDS):\n","            if word.text.lower() not in punctuation:\n","                if word.text not in word_frequencies.keys():\n","                    word_frequencies[word.text] = 1\n","                else:\n","                    word_frequencies[word.text] += 1\n","    #chuẩn hóa từ bằng cách chia tần suất max\n","    max_frequency=max(word_frequencies.values())\n","    for word in word_frequencies.keys():\n","        word_frequencies[word]=word_frequencies[word]/max_frequency\n","    sentence_tokens= [sent for sent in doc.sents]\n","    # tính điểm = tổng tần suất từ trong câu\n","    sentence_scores = {}\n","    for sent in sentence_tokens:\n","        for word in sent:\n","            if word.text.lower() in word_frequencies.keys():\n","                if sent not in sentence_scores.keys():                            \n","                    sentence_scores[sent]=word_frequencies[word.text.lower()]\n","                else:\n","                    sentence_scores[sent]+=word_frequencies[word.text.lower()]\n","    # xác định số câu và in ra các câu có số điểm từ cao nhất\n","    select_length=int(len(sentence_tokens)*per)\n","    summary=nlargest(select_length, sentence_scores,key=sentence_scores.get)\n","    final_summary=[word.text for word in summary]\n","    summary=''.join(final_summary)\n","    return summary"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["summary :\n","Russian forces are hiving off parts of the eastern city of Avdiivka, yet another town Moscow seems content to throw thousands of lives at despite its minimal importance.\n","Along the Zaporizhzhia frontline, where the counteroffensive was focused but ultimately slow and unrewarding, Russian units have come back with renewed vigor and the defense is costly for Ukraine.\n","\n"]}],"source":["text = '''\n","Yet in truth, the most useful headline for Kyiv should be how unutterably bleak the frontlines are for them now. \n","In nearly every direction, the news is grim. Russian forces are hiving off parts of the eastern city of Avdiivka, yet another town Moscow seems content to throw thousands of lives at despite its minimal importance.\n","Along the Zaporizhzhia frontline, where the counteroffensive was focused but ultimately slow and unrewarding, Russian units have come back with renewed vigor and the defense is costly for Ukraine.\n","Ukraine has made a plucky (or foolhardy) dash across the Dnipro River, with some small progress into Russian lines.\n","The casualties have been immense, their supply lines are problematic, and their prospects dim.'''\n","\n","summary = summarize(text, 0.4)\n","\n","summary_sentences = summary.split('. ')\n","formatted_summary = '.\\n'.join(summary_sentences)\n","print(\"summary :\")\n","print(formatted_summary)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":4}
