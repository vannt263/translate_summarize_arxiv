{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import thư viện"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "# Tải mô hình ngôn ngữ tiếng Anh từ spaCy\n",
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyvi import ViTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from datasets import Dataset, DatasetDict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoTokenizer, TFAutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, AdamWeightDecay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Đọc file dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "translate_folder = \"../data_translate/\"\n",
    "files = os.listdir(translate_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = []\n",
    "for file in files:\n",
    "    with open(f\"{translate_folder}{file}\", \"r\", encoding=\"utf-8\") as f:\n",
    "        data_list.append(json.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r'(?<!\\d)[^\\w\\s%](?!\\d)'\n",
    "def preprocessing(sentence, lang):\n",
    "    sentence = sentence.lower().strip()\n",
    "    if lang == \"eng\":\n",
    "        doc = nlp(sentence)\n",
    "        text = \" \".join([token.lemma_ for token in doc])\n",
    "        text = re.sub(fr'(?<!\\d)[^a-zA-Z0-9\\s]|[^a-zA-Z0-9\\s%](?!\\d)|{pattern}', '', text)\n",
    "        text = re.sub(r'\\s+', ' ', text)\n",
    "        return text\n",
    "    elif lang == \"vi\":\n",
    "        text = re.sub(r'[^\\w\\s]', '', sentence)\n",
    "        text = re.sub(r'\\s+', ' ', text)\n",
    "        text = ViTokenizer.tokenize(text)\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "      <th>highlights</th>\n",
       "      <th>vi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>For years they have been a source of joy for y...</td>\n",
       "      <td>More youngsters end up in hospital after tramp...</td>\n",
       "      <td>Nhiều thanh niên phải nhập viện sau khi nhiếp ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Once again: a hidden camera has caught New Yor...</td>\n",
       "      <td>Woman walks around New York in yoga pants with...</td>\n",
       "      <td>Người phụ nữ đi dạo quanh New York trong chiếc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought it would be a good chance for Roy Ho...</td>\n",
       "      <td>James Milner did not move the ball quickly eno...</td>\n",
       "      <td>James Milner di chuyển bóng không đủ nhanh tro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3D reconstructions of Richard III's spine show...</td>\n",
       "      <td>Shakespeare described Richard III as a 'poison...</td>\n",
       "      <td>Shakespeare mô tả Richard III là 'con lưng gù ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This is the moment a brave buffalo charged thr...</td>\n",
       "      <td>The buffalo and its young became separated fro...</td>\n",
       "      <td>Con trâu và đàn con bị ba sư tử đói ở Tanzania...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1017</th>\n",
       "      <td>A new Red Bull advert which makes light of the...</td>\n",
       "      <td>Advert shows Titanic captain dismissing crate ...</td>\n",
       "      <td>Quảng cáo cho thấy thuyền trưởng Titanic đang ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1018</th>\n",
       "      <td>By . Laura Silver for MailOnline . Everyone lo...</td>\n",
       "      <td>Two-year-old Miles is intent on getting forty ...</td>\n",
       "      <td>Cậu bé Miles hai tuổi đang có ý định nhận được...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1019</th>\n",
       "      <td>By . Associated Press Reporter and Daily Mail ...</td>\n",
       "      <td>Tampa socialite who tipped off FBI about Petra...</td>\n",
       "      <td>Trang xã hội Tampa, người đã tiết lộ cho FBI v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1020</th>\n",
       "      <td>Devastated British tycoon Alan Bond yesterday ...</td>\n",
       "      <td>Diana Bliss, 57, had stood by husband's side a...</td>\n",
       "      <td>Diana Bliss, 57 tuổi, đã sát cánh bên chồng sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1021</th>\n",
       "      <td>(CNN) -- It came closer ... closer ... and the...</td>\n",
       "      <td>An asteroid flies by Earth in the closest reco...</td>\n",
       "      <td>Một tiểu hành tinh bay ngang qua Trái đất theo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1022 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                article  \\\n",
       "0     For years they have been a source of joy for y...   \n",
       "1     Once again: a hidden camera has caught New Yor...   \n",
       "2     I thought it would be a good chance for Roy Ho...   \n",
       "3     3D reconstructions of Richard III's spine show...   \n",
       "4     This is the moment a brave buffalo charged thr...   \n",
       "...                                                 ...   \n",
       "1017  A new Red Bull advert which makes light of the...   \n",
       "1018  By . Laura Silver for MailOnline . Everyone lo...   \n",
       "1019  By . Associated Press Reporter and Daily Mail ...   \n",
       "1020  Devastated British tycoon Alan Bond yesterday ...   \n",
       "1021  (CNN) -- It came closer ... closer ... and the...   \n",
       "\n",
       "                                             highlights  \\\n",
       "0     More youngsters end up in hospital after tramp...   \n",
       "1     Woman walks around New York in yoga pants with...   \n",
       "2     James Milner did not move the ball quickly eno...   \n",
       "3     Shakespeare described Richard III as a 'poison...   \n",
       "4     The buffalo and its young became separated fro...   \n",
       "...                                                 ...   \n",
       "1017  Advert shows Titanic captain dismissing crate ...   \n",
       "1018  Two-year-old Miles is intent on getting forty ...   \n",
       "1019  Tampa socialite who tipped off FBI about Petra...   \n",
       "1020  Diana Bliss, 57, had stood by husband's side a...   \n",
       "1021  An asteroid flies by Earth in the closest reco...   \n",
       "\n",
       "                                                     vi  \n",
       "0     Nhiều thanh niên phải nhập viện sau khi nhiếp ...  \n",
       "1     Người phụ nữ đi dạo quanh New York trong chiếc...  \n",
       "2     James Milner di chuyển bóng không đủ nhanh tro...  \n",
       "3     Shakespeare mô tả Richard III là 'con lưng gù ...  \n",
       "4     Con trâu và đàn con bị ba sư tử đói ở Tanzania...  \n",
       "...                                                 ...  \n",
       "1017  Quảng cáo cho thấy thuyền trưởng Titanic đang ...  \n",
       "1018  Cậu bé Miles hai tuổi đang có ý định nhận được...  \n",
       "1019  Trang xã hội Tampa, người đã tiết lộ cho FBI v...  \n",
       "1020  Diana Bliss, 57 tuổi, đã sát cánh bên chồng sa...  \n",
       "1021  Một tiểu hành tinh bay ngang qua Trái đất theo...  \n",
       "\n",
       "[1022 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data_list, index=range(len(data_list)))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"highlights\"] = df['highlights'].apply(preprocessing, lang='eng')\n",
    "df['vi'] = df['vi'].apply(preprocessing, lang='vi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "      <th>highlights</th>\n",
       "      <th>vi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>For years they have been a source of joy for y...</td>\n",
       "      <td>more youngster end up in hospital after trampo...</td>\n",
       "      <td>nhiều thanh_niên phải nhập_viện sau khi nhiếp_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Once again: a hidden camera has caught New Yor...</td>\n",
       "      <td>woman walk around new york in yoga pant with c...</td>\n",
       "      <td>người phụ_nữ đi dạo quanh new york trong chiếc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought it would be a good chance for Roy Ho...</td>\n",
       "      <td>james milner do not move the ball quickly enou...</td>\n",
       "      <td>james milner di_chuyển bóng không đủ nhanh tro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3D reconstructions of Richard III's spine show...</td>\n",
       "      <td>shakespeare describe richard iii as a poisonou...</td>\n",
       "      <td>shakespeare mô_tả richard iii là con lưng gù đ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This is the moment a brave buffalo charged thr...</td>\n",
       "      <td>the buffalo and its young become separate from...</td>\n",
       "      <td>con trâu và đàn con bị ba sư_tử đói ở tanzania...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1017</th>\n",
       "      <td>A new Red Bull advert which makes light of the...</td>\n",
       "      <td>advert show titanic captain dismiss crate of r...</td>\n",
       "      <td>quảng_cáo cho thấy thuyền_trưởng titanic đang ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1018</th>\n",
       "      <td>By . Laura Silver for MailOnline . Everyone lo...</td>\n",
       "      <td>two year old mile be intent on get forty wink ...</td>\n",
       "      <td>cậu bé miles hai tuổi đang có ý_định nhận được...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1019</th>\n",
       "      <td>By . Associated Press Reporter and Daily Mail ...</td>\n",
       "      <td>tampa socialite who tip off fbi about petraeus...</td>\n",
       "      <td>trang xã_hội tampa người đã tiết_lộ cho fbi về...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1020</th>\n",
       "      <td>Devastated British tycoon Alan Bond yesterday ...</td>\n",
       "      <td>diana bliss 57 have stand by husband s side af...</td>\n",
       "      <td>diana bliss 57 tuổi đã sát_cánh bên chồng sau ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1021</th>\n",
       "      <td>(CNN) -- It came closer ... closer ... and the...</td>\n",
       "      <td>an asteroid fly by earth in the close record a...</td>\n",
       "      <td>một tiểu hành_tinh bay ngang qua trái_đất theo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1022 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                article  \\\n",
       "0     For years they have been a source of joy for y...   \n",
       "1     Once again: a hidden camera has caught New Yor...   \n",
       "2     I thought it would be a good chance for Roy Ho...   \n",
       "3     3D reconstructions of Richard III's spine show...   \n",
       "4     This is the moment a brave buffalo charged thr...   \n",
       "...                                                 ...   \n",
       "1017  A new Red Bull advert which makes light of the...   \n",
       "1018  By . Laura Silver for MailOnline . Everyone lo...   \n",
       "1019  By . Associated Press Reporter and Daily Mail ...   \n",
       "1020  Devastated British tycoon Alan Bond yesterday ...   \n",
       "1021  (CNN) -- It came closer ... closer ... and the...   \n",
       "\n",
       "                                             highlights  \\\n",
       "0     more youngster end up in hospital after trampo...   \n",
       "1     woman walk around new york in yoga pant with c...   \n",
       "2     james milner do not move the ball quickly enou...   \n",
       "3     shakespeare describe richard iii as a poisonou...   \n",
       "4     the buffalo and its young become separate from...   \n",
       "...                                                 ...   \n",
       "1017  advert show titanic captain dismiss crate of r...   \n",
       "1018  two year old mile be intent on get forty wink ...   \n",
       "1019  tampa socialite who tip off fbi about petraeus...   \n",
       "1020  diana bliss 57 have stand by husband s side af...   \n",
       "1021  an asteroid fly by earth in the close record a...   \n",
       "\n",
       "                                                     vi  \n",
       "0     nhiều thanh_niên phải nhập_viện sau khi nhiếp_...  \n",
       "1     người phụ_nữ đi dạo quanh new york trong chiếc...  \n",
       "2     james milner di_chuyển bóng không đủ nhanh tro...  \n",
       "3     shakespeare mô_tả richard iii là con lưng gù đ...  \n",
       "4     con trâu và đàn con bị ba sư_tử đói ở tanzania...  \n",
       "...                                                 ...  \n",
       "1017  quảng_cáo cho thấy thuyền_trưởng titanic đang ...  \n",
       "1018  cậu bé miles hai tuổi đang có ý_định nhận được...  \n",
       "1019  trang xã_hội tampa người đã tiết_lộ cho fbi về...  \n",
       "1020  diana bliss 57 tuổi đã sát_cánh bên chồng sau ...  \n",
       "1021  một tiểu hành_tinh bay ngang qua trái_đất theo...  \n",
       "\n",
       "[1022 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Khảo sát độ dài của chuỗi đầu vào và đầu ra\n",
    "highlights_word_count = []\n",
    "vi_word_count = []\n",
    "\n",
    "for i in df['highlights']:\n",
    "      highlights_word_count.append(len(i.split()))\n",
    "\n",
    "for i in df['vi']:\n",
    "      vi_word_count.append(len(i.split()))\n",
    "\n",
    "length_df = pd.DataFrame({'Tóm tắt': highlights_word_count, 'Dịch':vi_word_count})\n",
    "length_df.hist(bins = 50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "validation_df, test_df = train_test_split(test_df, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset.from_dict({\n",
    "    \"inputs\": train_df[\"highlights\"].values.tolist(),\n",
    "    \"targets\": train_df[\"vi\"].values.tolist()\n",
    "})\n",
    "\n",
    "test_dataset = Dataset.from_dict({\n",
    "    \"inputs\": test_df[\"highlights\"].values.tolist(),\n",
    "    \"targets\": test_df[\"vi\"].values.tolist()\n",
    "})\n",
    "\n",
    "validation_dataset = Dataset.from_dict({\n",
    "    \"inputs\": validation_df[\"highlights\"].values.tolist(),\n",
    "    \"targets\": validation_df[\"vi\"].values.tolist()\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tạo DatasetDict\n",
    "dataset = DatasetDict({\n",
    "    \"train\": train_dataset,\n",
    "    \"val\": validation_dataset,\n",
    "    \"test\": test_dataset\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['inputs', 'targets'],\n",
       "        num_rows: 817\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['inputs', 'targets'],\n",
       "        num_rows: 102\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['inputs', 'targets'],\n",
       "        num_rows: 103\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model VietAI/envit5-translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vannt\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\initializers\\initializers.py:120: UserWarning: The initializer RandomNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initializer instance more than once.\n",
      "  warnings.warn(\n",
      "All model checkpoint layers were used when initializing TFT5ForConditionalGeneration.\n",
      "\n",
      "All the layers of TFT5ForConditionalGeneration were initialized from the model checkpoint at VietAI/envit5-translation.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"VietAI/envit5-translation\")\n",
    "model = TFAutoModelForSeq2SeqLM.from_pretrained(\"VietAI/envit5-translation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_input_length = 128\n",
    "max_target_length = 128\n",
    "                         \n",
    "def preprocess_function(examples):\n",
    "    model_inputs = tokenizer( examples['inputs'],\n",
    "                                max_length=max_input_length,\n",
    "                                truncation=True\n",
    "                            )\n",
    "\n",
    "    labels = tokenizer( text_target=examples[\"targets\"],\n",
    "                        max_length=max_target_length,\n",
    "                        truncation=True\n",
    "                    )\n",
    "    \n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c58dae0e3394421a939a3daa93926532",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/817 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cbbe9e122224c7d815b7e5040ab164a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/102 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62165e74bd014ff48c1853a2b6eafafb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/103 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer_data = dataset.map(preprocess_function, batched = True, remove_columns = ['inputs', 'targets'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 817\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 102\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 103\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model, return_tensors=\"tf\", pad_to_multiple_of=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "learning_rate = 2e-5\n",
    "weight_decay = 0.01\n",
    "num_train_epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    }
   ],
   "source": [
    "train_dataset = model.prepare_tf_dataset(\n",
    "    tokenizer_data[\"train\"],\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    collate_fn=data_collator,\n",
    ")\n",
    "\n",
    "val_dataset = model.prepare_tf_dataset(\n",
    "    tokenizer_data[\"val\"],\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    collate_fn=data_collator,\n",
    ")\n",
    "\n",
    "test_dataset = model.prepare_tf_dataset(\n",
    "    tokenizer_data[\"test\"],\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    collate_fn=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamWeightDecay(learning_rate=learning_rate, weight_decay_rate=weight_decay)\n",
    "model.compile(optimizer=optimizer)\n",
    "check_point = keras.callbacks.ModelCheckpoint(\n",
    "    filepath='./model_translate.h5',\n",
    "    monitor='loss_accuracy',\n",
    "    mode='min',\n",
    "    save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "25/25 [==============================] - ETA: 0s - loss: 3.1128  WARNING:tensorflow:Can save best model only with loss_accuracy available, skipping.\n",
      "25/25 [==============================] - 4247s 169s/step - loss: 3.1128 - val_loss: 2.0784\n",
      "Epoch 2/2\n",
      "25/25 [==============================] - ETA: 0s - loss: 2.1920  WARNING:tensorflow:Can save best model only with loss_accuracy available, skipping.\n",
      "25/25 [==============================] - 4152s 166s/step - loss: 2.1920 - val_loss: 1.7874\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x158ee575490>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_dataset, validation_data=val_dataset, epochs=2, callbacks=[check_point])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"tf_model/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Đánh giá model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sacrebleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['inputs', 'targets'],\n",
       "    num_rows: 103\n",
       "})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vannt\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\initializers\\initializers.py:120: UserWarning: The initializer RandomNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initializer instance more than once.\n",
      "  warnings.warn(\n",
      "All model checkpoint layers were used when initializing TFT5ForConditionalGeneration.\n",
      "\n",
      "All the layers of TFT5ForConditionalGeneration were initialized from the model checkpoint at VietAI/envit5-translation.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n",
      "All model checkpoint layers were used when initializing TFT5ForConditionalGeneration.\n",
      "\n",
      "All the layers of TFT5ForConditionalGeneration were initialized from the model checkpoint at ../model/tf_model/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"VietAI/envit5-translation\")\n",
    "model_pretrained = TFAutoModelForSeq2SeqLM.from_pretrained(\"VietAI/envit5-translation\")\n",
    "model_finetuning = TFAutoModelForSeq2SeqLM.from_pretrained(\"../model/tf_model/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_translation(model, input_text):\n",
    "    input_ids = tokenizer.encode(input_text, return_tensors=\"tf\")\n",
    "    outputs = model.generate(input_ids)\n",
    "    translated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return translated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score for Example 1: 5.251325596616349\n",
      "BLEU Score for Example 2: 0.06585560504961668\n",
      "BLEU Score for Example 3: 0.008962626621970787\n",
      "BLEU Score for Example 4: 0.23102943014927285\n",
      "BLEU Score for Example 5: 0.3663878271670461\n",
      "BLEU Score for Example 6: 2.3125177829660863\n",
      "BLEU Score for Example 7: 0.21867683349848419\n",
      "BLEU Score for Example 8: 0.5468482660226331\n",
      "BLEU Score for Example 9: 5.7206899887723175\n",
      "BLEU Score for Example 10: 1.1526963230184712\n",
      "BLEU Score for Example 11: 9.529367054520856\n",
      "BLEU Score for Example 12: 0.8764402403197127\n",
      "BLEU Score for Example 13: 5.3235010579974364\n",
      "BLEU Score for Example 14: 1.2818142001556916\n",
      "BLEU Score for Example 15: 0.6852971698484914\n",
      "BLEU Score for Example 16: 0.41853566905512946\n",
      "BLEU Score for Example 17: 0.1904476572881443\n",
      "BLEU Score for Example 18: 3.450055974355716\n",
      "BLEU Score for Example 19: 0.10817062280543367\n",
      "BLEU Score for Example 20: 0.0802692481879688\n",
      "BLEU Score for Example 21: 0.10394226594851783\n",
      "BLEU Score for Example 22: 0.38298080133318796\n",
      "BLEU Score for Example 23: 0.49625138676265435\n",
      "BLEU Score for Example 24: 0.5841792956789502\n",
      "BLEU Score for Example 25: 0.4052735899348558\n",
      "BLEU Score for Example 26: 0.9179213863997923\n",
      "BLEU Score for Example 27: 0.3432773374787358\n",
      "BLEU Score for Example 28: 8.115299234305544\n",
      "BLEU Score for Example 29: 7.021865332621252\n",
      "BLEU Score for Example 30: 2.1362960366390475\n",
      "BLEU Score for Example 31: 4.399528812808727\n",
      "BLEU Score for Example 32: 0.1703664409277382\n",
      "BLEU Score for Example 33: 0.060295842537981176\n",
      "BLEU Score for Example 34: 0.39540483111255514\n",
      "BLEU Score for Example 35: 5.703169067239735\n",
      "BLEU Score for Example 36: 7.131759202115914e-05\n",
      "BLEU Score for Example 37: 0.10843109519496928\n",
      "BLEU Score for Example 38: 0.3156816682401387\n",
      "BLEU Score for Example 39: 0.9983839336341742\n",
      "BLEU Score for Example 40: 4.26269678994185\n",
      "BLEU Score for Example 41: 7.347053125977879\n",
      "BLEU Score for Example 42: 0.5447346781918202\n",
      "BLEU Score for Example 43: 0.6161214073959218\n",
      "BLEU Score for Example 44: 0.8492741486742231\n",
      "BLEU Score for Example 45: 0.0003764127919507928\n",
      "BLEU Score for Example 46: 0.012660929430964704\n",
      "BLEU Score for Example 47: 0.05771682212143855\n",
      "BLEU Score for Example 48: 0.024903023369760014\n",
      "BLEU Score for Example 49: 0.1732461473134624\n",
      "BLEU Score for Example 50: 0.020330844800365816\n",
      "BLEU Score for Example 51: 1.894223652696387\n",
      "BLEU Score for Example 52: 3.022970815924934\n",
      "BLEU Score for Example 53: 3.7125783346654475\n",
      "BLEU Score for Example 54: 0.017815590955230762\n",
      "BLEU Score for Example 55: 0.17151139752585343\n",
      "BLEU Score for Example 56: 0.03620169362404773\n",
      "BLEU Score for Example 57: 2.1850949139340705\n",
      "BLEU Score for Example 58: 0.006723559412131435\n",
      "BLEU Score for Example 59: 1.9809096577173335\n",
      "BLEU Score for Example 60: 2.4341406987444985\n",
      "BLEU Score for Example 61: 4.176680257872766\n",
      "BLEU Score for Example 62: 3.698319037936861\n",
      "BLEU Score for Example 63: 0.0024700527736561547\n",
      "BLEU Score for Example 64: 0.00044569564967775806\n",
      "BLEU Score for Example 65: 1.8997105419617817\n",
      "BLEU Score for Example 66: 0.7083866699618928\n",
      "BLEU Score for Example 67: 0.1427504878416732\n",
      "BLEU Score for Example 68: 0.02383831813950244\n",
      "BLEU Score for Example 69: 0.34897640738877417\n",
      "BLEU Score for Example 70: 1.322027551274782\n",
      "BLEU Score for Example 71: 0.002820071155320238\n",
      "BLEU Score for Example 72: 0.5074383296949898\n",
      "BLEU Score for Example 73: 0.44173298864193017\n",
      "BLEU Score for Example 74: 3.9601167245884428\n",
      "BLEU Score for Example 75: 0.1782018973317403\n",
      "BLEU Score for Example 76: 0.13615200646875425\n",
      "BLEU Score for Example 77: 0.6841794021452646\n",
      "BLEU Score for Example 78: 0.8812123483331512\n",
      "BLEU Score for Example 79: 0.35866616520048317\n",
      "BLEU Score for Example 80: 2.0328166947258985\n",
      "BLEU Score for Example 81: 2.1511580272094597\n",
      "BLEU Score for Example 82: 0.07932302330132616\n",
      "BLEU Score for Example 83: 1.266927337605428\n",
      "BLEU Score for Example 84: 0.11876287950440811\n",
      "BLEU Score for Example 85: 0.013753669348288595\n",
      "BLEU Score for Example 86: 0.003952380420214137\n",
      "BLEU Score for Example 87: 0.6047946302806415\n",
      "BLEU Score for Example 88: 0.4128641466216793\n",
      "BLEU Score for Example 89: 0.00012033467944164169\n",
      "BLEU Score for Example 90: 0.055102287964144354\n",
      "BLEU Score for Example 91: 0.7097016208108075\n",
      "BLEU Score for Example 92: 0.7298094053998894\n",
      "BLEU Score for Example 93: 0.16256413501749073\n",
      "BLEU Score for Example 94: 0.05799691632417534\n",
      "BLEU Score for Example 95: 2.261039281374007\n",
      "BLEU Score for Example 96: 0.47964660007841675\n",
      "BLEU Score for Example 97: 0.12852206528571894\n",
      "BLEU Score for Example 98: 0.3552390032316065\n",
      "BLEU Score for Example 99: 0.10423056145398196\n",
      "BLEU Score for Example 100: 5.95407249181201\n",
      "BLEU Score for Example 101: 0.20386226020627207\n",
      "BLEU Score for Example 102: 0.06166345901897651\n",
      "BLEU Score for Example 103: 0.40071499174911307\n"
     ]
    }
   ],
   "source": [
    "# Tạo danh sách đầu ra dự đoán của mô hình\n",
    "predictions = [generate_translation(model_pretrained, input_text) for input_text in test_dataset[\"inputs\"]]\n",
    "\n",
    "# Chuyển đổi references và predictions thành định dạng phù hợp với sacrebleu\n",
    "references = [[target] for target in test_dataset[\"targets\"]]  # Mỗi reference là một list của các từ\n",
    "predictions = [target for target in predictions]  # Mỗi prediction là một chuỗi\n",
    "\n",
    "# Tính và lưu BLEU score cho từng cặp câu\n",
    "bleu_model_pretrained = []\n",
    "for i in range(len(predictions)):\n",
    "    reference = references[i]\n",
    "    prediction = predictions[i]\n",
    "\n",
    "    # Tính BLEU score cho cặp câu hiện tại\n",
    "    bleu = sacrebleu.corpus_bleu([prediction], [reference])\n",
    "\n",
    "    # Lưu BLEU score vào danh sách\n",
    "    bleu_model_pretrained.append(bleu.score)\n",
    "\n",
    "    # In kết quả\n",
    "    print(f\"BLEU Score for Example {i + 1}: {bleu.score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vannt\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\tf_utils.py:838: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length.  recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score for Example 1: 5.391483981339191\n",
      "BLEU Score for Example 2: 0.06509414060547228\n",
      "BLEU Score for Example 3: 0.011878845454047202\n",
      "BLEU Score for Example 4: 0.2408823468191835\n",
      "BLEU Score for Example 5: 0.2825778303179715\n",
      "BLEU Score for Example 6: 2.3125177829660863\n",
      "BLEU Score for Example 7: 0.3677691307758176\n",
      "BLEU Score for Example 8: 1.0548704522420085\n",
      "BLEU Score for Example 9: 10.670721614580264\n",
      "BLEU Score for Example 10: 1.757168251209286\n",
      "BLEU Score for Example 11: 1.401483084566282\n",
      "BLEU Score for Example 12: 0.9245083171968447\n",
      "BLEU Score for Example 13: 4.531449772693371\n",
      "BLEU Score for Example 14: 2.6861731923207386\n",
      "BLEU Score for Example 15: 0.5578167280558859\n",
      "BLEU Score for Example 16: 0.41853566905512946\n",
      "BLEU Score for Example 17: 0.6756385622080393\n",
      "BLEU Score for Example 18: 4.380961919583343\n",
      "BLEU Score for Example 19: 0.10503189462498921\n",
      "BLEU Score for Example 20: 0.08401261576611424\n",
      "BLEU Score for Example 21: 0.07820923618967607\n",
      "BLEU Score for Example 22: 0.6679679452596851\n",
      "BLEU Score for Example 23: 1.3619140791216213\n",
      "BLEU Score for Example 24: 0.4341905011199743\n",
      "BLEU Score for Example 25: 0.06904117200440096\n",
      "BLEU Score for Example 26: 1.1987946932613671\n",
      "BLEU Score for Example 27: 1.1538217962448911\n",
      "BLEU Score for Example 28: 12.246038092509215\n",
      "BLEU Score for Example 29: 7.163792908651503\n",
      "BLEU Score for Example 30: 8.033761483133002\n",
      "BLEU Score for Example 31: 5.5484616420071395\n",
      "BLEU Score for Example 32: 0.14888921812653363\n",
      "BLEU Score for Example 33: 0.07170424495125094\n",
      "BLEU Score for Example 34: 0.3828757746289184\n",
      "BLEU Score for Example 35: 10.102594011225909\n",
      "BLEU Score for Example 36: 1.7217642166140824e-05\n",
      "BLEU Score for Example 37: 0.22930384824509753\n",
      "BLEU Score for Example 38: 0.8872489833629267\n",
      "BLEU Score for Example 39: 1.3726126264098228\n",
      "BLEU Score for Example 40: 6.109144384953947\n",
      "BLEU Score for Example 41: 11.498759556447217\n",
      "BLEU Score for Example 42: 1.2056960387773212\n",
      "BLEU Score for Example 43: 0.8860244438620478\n",
      "BLEU Score for Example 44: 0.7152097120453887\n",
      "BLEU Score for Example 45: 0.0013039321605552532\n",
      "BLEU Score for Example 46: 0.04011259327769745\n",
      "BLEU Score for Example 47: 0.05341063820851356\n",
      "BLEU Score for Example 48: 0.12858242062251357\n",
      "BLEU Score for Example 49: 0.1732461473134624\n",
      "BLEU Score for Example 50: 0.047581238128061656\n",
      "BLEU Score for Example 51: 0.8505186600341572\n",
      "BLEU Score for Example 52: 4.327542280599831\n",
      "BLEU Score for Example 53: 3.982231906397001\n",
      "BLEU Score for Example 54: 0.14781344652245193\n",
      "BLEU Score for Example 55: 1.4121564355680485\n",
      "BLEU Score for Example 56: 0.01303540190457637\n",
      "BLEU Score for Example 57: 0.3762914619963778\n",
      "BLEU Score for Example 58: 0.0065788821473504455\n",
      "BLEU Score for Example 59: 3.197350805297598\n",
      "BLEU Score for Example 60: 1.0581717669949993\n",
      "BLEU Score for Example 61: 6.619729201572463\n",
      "BLEU Score for Example 62: 3.698319037936861\n",
      "BLEU Score for Example 63: 0.009081584149944984\n",
      "BLEU Score for Example 64: 0.00044569564967775806\n",
      "BLEU Score for Example 65: 0.38383946044314105\n",
      "BLEU Score for Example 66: 1.511574422831339\n",
      "BLEU Score for Example 67: 0.24954098573420272\n",
      "BLEU Score for Example 68: 0.010040466129973401\n",
      "BLEU Score for Example 69: 0.7655741049298552\n",
      "BLEU Score for Example 70: 3.9190253473331578\n",
      "BLEU Score for Example 71: 0.0024515424239432344\n",
      "BLEU Score for Example 72: 0.5862279826945211\n",
      "BLEU Score for Example 73: 0.4219046992274298\n",
      "BLEU Score for Example 74: 5.494906577718355\n",
      "BLEU Score for Example 75: 0.19149040066659395\n",
      "BLEU Score for Example 76: 0.1453817472257235\n",
      "BLEU Score for Example 77: 2.131896691298076\n",
      "BLEU Score for Example 78: 0.3245127830492114\n",
      "BLEU Score for Example 79: 0.35866616520048317\n",
      "BLEU Score for Example 80: 3.335227703596312\n",
      "BLEU Score for Example 81: 1.2790862157263532\n",
      "BLEU Score for Example 82: 0.14050715585044565\n",
      "BLEU Score for Example 83: 0.25011071427889925\n",
      "BLEU Score for Example 84: 0.11831464620349884\n",
      "BLEU Score for Example 85: 0.03693341067939789\n",
      "BLEU Score for Example 86: 0.007222176395169851\n",
      "BLEU Score for Example 87: 1.3098259695013386\n",
      "BLEU Score for Example 88: 0.16154182738567674\n",
      "BLEU Score for Example 89: 0.00013242612187376634\n",
      "BLEU Score for Example 90: 0.13457508093636394\n",
      "BLEU Score for Example 91: 1.171731537773934\n",
      "BLEU Score for Example 92: 2.008988588738781\n",
      "BLEU Score for Example 93: 0.2578412097098247\n",
      "BLEU Score for Example 94: 0.10650268259466544\n",
      "BLEU Score for Example 95: 1.1823979151677084\n",
      "BLEU Score for Example 96: 0.6268203245349923\n",
      "BLEU Score for Example 97: 0.1977082092949219\n",
      "BLEU Score for Example 98: 0.3782742336979444\n",
      "BLEU Score for Example 99: 0.11337755472351325\n",
      "BLEU Score for Example 100: 1.9400463867879605\n",
      "BLEU Score for Example 101: 1.1147194998351468\n",
      "BLEU Score for Example 102: 0.039497247335075654\n",
      "BLEU Score for Example 103: 0.2738673313509986\n"
     ]
    }
   ],
   "source": [
    "# Tạo danh sách đầu ra dự đoán của mô hình\n",
    "predictions = [generate_translation(model_finetuning, input_text) for input_text in test_dataset[\"inputs\"]]\n",
    "\n",
    "# Chuyển đổi references và predictions thành định dạng phù hợp với sacrebleu\n",
    "references = [[target] for target in test_dataset[\"targets\"]]  # Mỗi reference là một list của các từ\n",
    "predictions = [target for target in predictions]  # Mỗi prediction là một chuỗi\n",
    "\n",
    "# Tính và lưu BLEU score cho từng cặp câu\n",
    "bleu_model_finetuning = []\n",
    "for i in range(len(predictions)):\n",
    "    reference = references[i]\n",
    "    prediction = predictions[i]\n",
    "\n",
    "    # Tính BLEU score cho cặp câu hiện tại\n",
    "    bleu = sacrebleu.corpus_bleu([prediction], [reference])\n",
    "\n",
    "    # Lưu BLEU score vào danh sách\n",
    "    bleu_model_finetuning.append(bleu.score)\n",
    "\n",
    "    # In kết quả\n",
    "    print(f\"BLEU Score for Example {i + 1}: {bleu.score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Số lượng giá trị âm: 32\n",
      "Số lượng giá trị dương: 65\n"
     ]
    }
   ],
   "source": [
    "# Chuyển đổi danh sách thành mảng NumPy để thực hiện các phép toán\n",
    "bleu_model_finetuning = np.array(bleu_model_finetuning)\n",
    "bleu_model_pretrained = np.array(bleu_model_pretrained)\n",
    "\n",
    "# Tính giá trị trừ\n",
    "difference = bleu_model_finetuning - bleu_model_pretrained\n",
    "\n",
    "# Đếm số lượng giá trị âm và dương\n",
    "negative_values = np.sum(difference < 0)\n",
    "positive_values = np.sum(difference > 0)\n",
    "\n",
    "print(\"Số lượng giá trị âm:\", negative_values)\n",
    "print(\"Số lượng giá trị dương:\", positive_values)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
