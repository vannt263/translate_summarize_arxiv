{
  "article_text": [
    "as more and more machine learning algorithms automate data - driven processes in education , recruitment , banking , and judiciary systems , one thing has become evident  algorithms can have biases @xcite .",
    "given that these algorithms have far - reaching social and economic consequences , it is important to ensure that they comply with non - discrimination and fairness policies based on race , gender , and other sensitive attributes . towards this",
    ", there is an ongoing effort to understand and incorporate fairness in machine learning algorithms ( e.g. , see @xcite ) .",
    "we study the problem of subsampling a large data set  a basic task in machine learning .",
    "subsamples are used both as an end - goal in data summarization ( where fairness could either be a legal , political or moral requirement ) and to train algorithms ( where biases in the samples are often a source of bias in the resulting model ) . a crucial requirement for either task",
    "is that the sample be _ diverse _ in the feature space ; this is important both to provide a comprehensive viewpoint if the sample is the end - goal , and to make algorithms trained on such samples robust . ensuring diversity in samples is well - studied ; there are several notions of diversity and approaches for attaining it ( see , e.g. , @xcite ) . however , diversity may not guarantee fairness on sensitive attributes and may propagate biases , leading to broken models and algorithmic prejudice @xcite .",
    "mathematically , fairness can be viewed as a measure of diversity in the combinatorial space of sensitive attributes , as opposed to the geometric space of features .",
    "this brings us to the central question of this work : _ how do we select samples from a large dataset that are both diverse in features and fair to sensitive attributes ?",
    "_ simple examples ( such as those in figure [ fig : example ] ) show that , in certain settings , diversity does not necessarily imply fairness and vice - versa ; however , both seem simultaneously achievable . while both geometric and combinatorial diversities have been studied in independent works ( e.g. , @xcite and @xcite ) , to the best of our knowledge , this is the first systematic study that addresses both _",
    "simultaneously_.    [ [ diversity - combinatorial - and - geometric . ] ] diversity : combinatorial and geometric .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    formally , we study the following problem : given a large dataset @xmath0 of @xmath1 items , output a geometrically and combinatorially _ diverse _ @xmath2 of size @xmath3 . to make this well - defined",
    ", we need to specify two things : 1 ) how the data is given and 2 ) measures of diversity .",
    "there are two extremes     1",
    ".   * combinatorial diversity . *",
    "each data point @xmath4 has an attribute from a small set @xmath5 , which leads to a combinatorial measure of diversity @xmath6 : the diversity of a set @xmath2 is the shannon entropy of the distribution @xmath7 , where @xmath8 is the set of elements in @xmath2 with attribute value @xmath9 .",
    "intuitively , the larger the entropy , the more diverse is @xmath2 with respect to the given attributes .",
    "* geometric diversity .",
    "* each data point @xmath4 has a high - dimensional feature vector @xmath10 , which motivates a geometric measure of diversity @xmath11 : the diversity of a set @xmath2 is the ( squared ) volume of the @xmath3-dimensional parallelepiped formed by the vectors @xmath12 .",
    "intuitively , the larger this volume , the more diverse is @xmath2 in the feature space .",
    "the combinatorial notion works with much less information , and is known as the _ diversity index _ @xcite in social and biological sciences .",
    "it is more suited to quantify fairness in sensitive or human - interpretable attributes that take a small set of discrete values .",
    "the geometric notion gives rise to a probability distribution known as _",
    "determinantal point process _",
    "( or @xmath3-dpp ) , and such measures have been used to quantify feature diversity in a variety of machine learning applications for images @xcite , videos @xcite , documents @xcite , recommendation systems @xcite , and sensor placement @xcite . besides quantification of diversity in feature - rich datasets , an important reason for the deployment of @xmath3-dpps is the recent efficient algorithms to sample from these distributions @xcite .",
    "[ [ our - contribution . ] ] our contribution .",
    "+ + + + + + + + + + + + + + + + +    we present an algorithmic framework that allows a user to integrate both notions of diversity , and experimentally demonstrate a marked improvement in fairness without compromising geometric diversity by much  resulting in the best of both the worlds .",
    "conceptually , we propose a novel generalization of @xmath3-dpps which we call _ @xmath13-dpp_. given the feature vectors and the partition of the dataset @xmath14 based on the @xmath15 different values of a sensitive attribute , @xmath13-dpp samples a @xmath3-sized subset @xmath2 with probability proportional to the squared volume of the parallelepiped formed by the feature vectors in @xmath2 ( as is done in @xmath3-dpps ) but _ only _ over sets @xmath2 that satisfy @xmath16 , for given @xmath17s for all @xmath18 .",
    "algorithmically , a polynomial time algorithm for sampling @xmath3-dpps generalizes , albeit non - trivially , to @xmath13-dpps with a constant number of disjoint partitions ( i.e. , @xmath19 , making our approach feasible @xcite .",
    "we experimentally compare the performance of sampling with @xmath13-dpps against three natural baselines for an image summarization task .",
    "we consider an image dataset that consists of male and female scientists and artists .",
    "we observe that @xmath13-dpp outperforms or matches other approaches with respect to both @xmath20 and @xmath21 in three different scenarios : 1 ) when we can ensure perfect fairness , see section [ sec : exp1 ] and figure [ fig : exp1 ] , 2 ) when some sensitive attributes remain hidden , see section [ sec : exp2 ] and figure [ fig : exp2 ] , and 3 ) when the underlying dataset is biased , see section [ sec : exp3 ] and figure [ fig : exp3 ] .",
    "these experiments give strong evidence that sampling with @xmath13-dpps is a successful approach for data summarization .",
    "subsampling is also an important subroutine in various machine learning tasks ( see , e.g. , @xcite ) , and it remains an important avenue for future work to study if @xmath13-dpps can also help mitigate algorithmic bias in such settings .",
    "here we give the formal definitions and theoretical constructs used in this paper .",
    "an attribute that takes one of @xmath15 different values gives a natural partition of the underlying data into @xmath15 parts .",
    "the fairness of a dataset ( or its subset ) with respect to such an attribute can then be quantified by the fairness or diversity index .    *",
    "( fairness or diversity index ) * [ def : fairness ] given a set @xmath0 of @xmath1 items and its partition @xmath22 into @xmath15 parts , the diversity index of any subset @xmath23 is defined as the shannon entropy @xmath24 where @xmath25 .    for feature - rich data , where a kernel defines the dot product of feature vectors , ( sub)determinants",
    "extend this notion to define diversity over subsets .    *",
    "( geometric diversity ) * [ def : diversity ] given a dataset @xmath0 and a positive semidefinite kernel matrix @xmath26 , the geometric diversity of a subset @xmath23 is defined as @xmath27 , which is the determinant of the principal submatrix @xmath28 given by the row and column indices in @xmath2 .",
    "geometric diversity defines a distribution on subsets known as a ( discrete ) determinantal point process .    *",
    "( dpps and @xmath3-dpps ) * [ def : kdpp ] given a dataset @xmath0 and a positive semidefinite kernel matrix @xmath26 , the dpp is a distribution over subsets @xmath23 such that the probability @xmath29 .",
    "the induced probability distribution over @xmath3-sized subsets is called @xmath3-dpp .",
    "now we define @xmath13-dpp ; our generalization of @xmath3-dpp to subsets that have the same relative partition as @xmath0 .    *",
    "( @xmath13-dpp ) * [ def : pdpp ] given a dataset @xmath0 , a positive semidefinite kernel matrix @xmath26 , a partition @xmath30 into @xmath15 parts , and numbers @xmath31 , @xmath13-dpp defines a distribution over @xmath3-sized subsets @xmath23 such that @xmath29 if @xmath32 and @xmath33 , otherwise .",
    "lastly , we introduce a natural baseline which we also compare against in our experiments .    * ( @xmath17-dpp ) * [ def : kidpp ] given a dataset @xmath0 , a positive semidefinite kernel matrix @xmath26 , a partition @xmath30 into @xmath15 parts , and numbers @xmath31 , @xmath17-dpp defines a distribution over @xmath34-sized subsets @xmath23 that is a product distribution : for each @xmath35 we obtain a sample @xmath36 of size @xmath17 independently with probability proportional to @xmath37 , and combine these samples to output @xmath38 .",
    "we emphasize that the difference between a @xmath17-dpp and a @xmath13-dpp with the same parameters @xmath39 is that the samples @xmath40 from each part in @xmath13-dpp are not _ independent _ as in @xmath17-dpp . indeed , this is what makes them more powerful .",
    "polynomial time sampling from @xmath3-dpps uses a linear algebraic fact that the partition function as well as the marginals of @xmath3-dpp can be computed using the characteristic polynomial of the underlying kernel matrix .",
    "a multivariate generalization of this can incorporate partition constraints ( and beyond ) to sample from @xmath13-dpps in time @xmath41 , which is polynomial for @xmath42 @xcite .",
    "we ran our experiments on a collection of images curated using google image search as follows : four search terms were used : ( a ) `` scientist male '' , ( b ) `` scientist female '' , ( c ) `` painter male '' , and ( d ) `` painter female '' .",
    "the search was restricted to medium sized jpeg files that passed the strictest level of safe search filtering .",
    "the top 200 distinct images from each were collected to create the following three datasets :      hence , each dataset has inherent labels ( a)-(d ) over which we can measure the combinatorial diversity of a sample . in order to measure geometric diversity , following @xcite , each image was processed with the ` vlfeat ` toolbox to obtain sets of 128-dimensional sift descriptors @xcite .",
    "the descriptors are combined , subsampled to a set of 36,000 and then clustered using @xmath3-means into 256 clusters .",
    "the feature vector for an image is the normalized histogram of the nearest clusters to the descriptors in the image .",
    "finally , the kernel value @xmath43 for any pair of images @xmath44 and @xmath45 is obtained by taking the dot - product of the sift features of @xmath44 and @xmath45 .      in each experiment",
    ", we compare four different probability distributions from which to select @xmath3 samples from a dataset : 1 ) our proposed @xmath13-dpp ( see def  [ def : pdpp ] ) , 2 ) the classic @xmath3-dpp ( see def  [ def : kdpp ] ) , 3 ) @xmath17-dpp ( see def  [ def : kidpp ] ) , and 4 ) unif , which takes a uniformly random subset of size @xmath3 .    in order to sample from @xmath3-dpp , @xmath17-dpp and @xmath13-dpp , instead of using the polynomial time algorithms of @xcite , we appeal to a markov chain monte carlo ( mcmc ) heuristic inspired by @xcite as the latter seems faster in practice .",
    "the markov chain is defined over the space of subsets of cardinality @xmath3 .",
    "the algorithm first chooses a `` warm start state '' @xmath2 obtained by greedily maximizing the determinant while satisfying the partition constraints .",
    "then , in each iteration , elements @xmath46 and @xmath47 are chosen uniformly at random . the chain moves to state @xmath48 with probability @xmath49 , if it satisfies the constraints .",
    "otherwise , it stays in state @xmath2 .",
    "this is repeated for a suitable number of iterations to guarantee that samples drawn from this chain are `` close '' to that of the desired distribution . in each experiment ,",
    "given a sample @xmath50 selected by algorithm @xmath51 , we report the combinatorial diversity using the fairness index @xmath52 ( see def  [ def : fairness ] ) and the geometric diversity @xmath53 ( see def  [ def : diversity ] ) .",
    "we first consider the performance as we vary the sample size @xmath3 from 20 to 100 on the scientist dataset ( see figure  [ fig : exp1 ] ) ; recall that the dataset has two parts , male and female , and that the dataset is unbiased .",
    "we place fairness constraints so that @xmath13-dpp and @xmath17-dpp select exactly 50% of their samples from the male and female parts .",
    "hence , we have set up the experiment to guarantee optimal @xmath20 for @xmath13-dpp and @xmath17-dpp , and measure the resulting degradation in @xmath21 .",
    "both @xmath13-dpp and @xmath17-dpp attain the optimal @xmath20 of @xmath54 .",
    "as expected , this is significantly higher than unif and @xmath3-dpp ( paired one - sided t - tests , @xmath55 ) . in fact , even unif has significantly higher fairness than @xmath3-dpp ( paired one - sided t - test , @xmath55 ) . with respect to @xmath21 ,",
    "the performance of @xmath3-dpp and @xmath13-dpp is comparable , with neither significantly outperforming the other .",
    "this is notable as @xmath13-dpp has constraints that @xmath3-dpp need not abide by ; hence , a priori , @xmath3-dpp could be significantly better .",
    "moreover , both @xmath3-dpp and @xmath13-dpp have significantly higher @xmath21 than unif and @xmath17-dpp ( paired one - sided t - tests , @xmath55 ) .",
    "outperforming unif is expected as random selection makes no effort to increase @xmath21 , however the outperformance of @xmath17-dpp is notable for two reasons : 1 ) @xmath17-dpp is the only other algorithm that matched the fairness index of @xmath13-dpp , and 2 ) @xmath17-dpp is also explicitly attempting to improve @xmath21 .",
    "however , while @xmath17-dpp improves @xmath21 _ within _ a part of the dataset , it does not diversify _ across _ parts ; @xmath13-dpp avoids exactly this pitfall .",
    "this experiment demonstrates that @xmath13-dpp can match or outperform the other approaches with respect to both fairness and diversity .",
    "this conclusion is not unique to this dataset  we also conducted the same experiment on the artist dataset , and the results are very similar with the same significance findings holding ; we omit the full details due to length constraints . exploring",
    "whether such results are consistent on other types of datasets would be a clear direction for future work .",
    "we then consider the performance of the algorithms as we vary the sample size @xmath3 from 10 to 50 on the scientist+artist dataset , but consider the case where there is a hidden underlying partition ( see figure  [ fig : exp2 ] ) . here",
    ", we place fairness constraints so that @xmath13-dpp and @xmath17-dpp select exactly @xmath56 of their samples from the male ( a and c ) images and female ( b and d ) images , but _ do not _ enforce constraints across scientist ( a and b ) images and artist ( c and d ) images , allowing for disproportionality across this dimension .",
    "however , we measure the fairness with respect to all four parts .      with respect to the @xmath20 , @xmath13-dpp and @xmath17-dpp",
    "no longer attain the optimal fairness of 4 .",
    "however , @xmath13-dpp significantly outperforms @xmath3-dpp , unif _ and _ @xmath17-dpp ( paired one - sided t - tests , @xmath55 ) , with @xmath17-dpp being the worst performer despite the partial constraints . with respect to @xmath21 , as in experiment 1",
    ", the performance of @xmath3-dpp and @xmath13-dpp is comparable , and both have significantly higher @xmath21 than unif ( paired one - sided t - tests , @xmath55 ) . for this experiment",
    ", @xmath13-dpp is also comparable to @xmath17-dpp , with a mean determinant that is higher , but not significantly so ; this is largely due to the fact that for this experiment @xmath3 is smaller while the dataset size is larger , and hence the drop - off in performance of @xmath17-dpp is not as evident as it was in experiment 1 .",
    "hence , this experiment demonstrates that @xmath13-dpp can match or outperform the other approaches with respect to both fairness and diversity , even when some of the underlying attributes are unknown .",
    "this is an important consideration as we should not inadvertently boost one kind of fairness at the expense of another .",
    "lastly , we consider the situation where the underlying dataset is biased ( see figure  [ fig : exp3 ] ) .",
    "we include all female ( b and d ) images , but only include a subsample of male images ( a and c ) in the dataset in order to create biased datasets that have between @xmath57 to @xmath56 male images .",
    "the subsampled images are selected uniformly at random from all male scientists and artists for each repetition in the experiment .",
    "we place fairness constraints so that @xmath13-dpp and @xmath17-dpp select exactly @xmath56 of their samples from the male ( a and c ) images and female ( b and d ) images , _ regardless of the bias in the underlying dataset_. as in experiment 2 , we _ do not _ enforce constraints across scientist ( a and b ) images and artist ( c and d ) images , but measure @xmath20 with respect to all four attributes .      with respect to @xmath20 ,",
    "@xmath13-dpp significantly outperforms @xmath3-dpp , unif and @xmath17-dpp ( paired one - sided t - tests , @xmath55 ) . here",
    ", we see that the bias in the underlying dataset can dramatically affect the fairness of unif and @xmath3-dpp as neither approach is designed to correct for such biases .",
    "however , @xmath13-dpp and @xmath17-dpp are able to remain relatively stable throughout . with respect to @xmath21",
    ", @xmath13-dpp has significantly higher @xmath21 than unif and @xmath17-dpp ( paired one - sided t - tests , @xmath55 ) .",
    "however , now @xmath3-dpp significantly outperforms @xmath13-dpp ( paired one - sided t - test , @xmath55 ) .",
    "this is due to the fact that when the dataset is highly biased , the available selection of images in the smaller partition is limited , and hence it is more difficult for @xmath13-dpp to diversify across the feature space .",
    "indeed , we expect this gap to close as the size ( but not proportion ) of the smaller part increases .      in this experiment",
    "we observe that , when the underlying data is highly biased , there is now a tradeoff between @xmath20 ( for which @xmath13-dpp performs best ) and @xmath21 ( for which @xmath3-dpp performs best ) . despite these differences",
    ", we note that the gap in @xmath13-dpp s geometric diversity gradually decreases , while @xmath3-dpps fairness index drops rapidly as the bias increases , leading us to conclude that @xmath13-dpps remain the best of both worlds , allowing for fairness _ and _ diversity ."
  ],
  "abstract_text": [
    "<S> due to the recent cases of _ algorithmic bias _ in data - driven decision - making , machine learning methods are being put under the microscope in order to understand the root cause of these biases and how to correct them . here </S>",
    "<S> , we consider a basic algorithmic task that is central in machine learning : subsampling from a large data set . </S>",
    "<S> subsamples are used both as an end - goal in data summarization ( where fairness could either be a legal , political or moral requirement ) and to train algorithms ( where biases in the samples are often a source of bias in the resulting model ) . </S>",
    "<S> consequently , there is a growing effort to modify either the subsampling methods or the algorithms themselves in order to ensure fairness . </S>",
    "<S> however , in doing so , a question that seems to be overlooked is whether it is possible to produce fair subsamples that are also adequately representative of the feature space of the data set  an important and classic requirement in machine learning . </S>",
    "<S> can diversity and fairness be simultaneously ensured ? </S>",
    "<S> we start by noting that , in some applications , guaranteeing one does not necessarily guarantee the other , and a new approach is required . </S>",
    "<S> subsequently , we present an algorithmic framework which allows us to produce both fair and diverse samples . </S>",
    "<S> our experimental results on an image summarization task show marked improvements in fairness without compromising feature diversity by much , giving us the best of both the worlds . </S>"
  ]
}