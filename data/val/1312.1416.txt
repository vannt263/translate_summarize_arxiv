{
  "article_text": [
    "data acquisition ( daq ) electronics in nuclear and particle physics have been shifting from analog to digital methods for many years . as part of this process , flash adc ( fadc ) chips and field programmable gate array ( fpga )",
    "modules are having ever increasing use .",
    "although these chips and modules provide a much greater range of data processing options along with the flexibility of firmware programming , considerably more data bits often must be passed through the electronics hardware , processed in computers , and stored for the long term .",
    "data analysis methods must also be able to handle the increased size and complexity of the raw data .",
    "in some situations , only a small fraction of the total data flow may contain meaningful information relevant to the physics being pursued .",
    "a common situation is that in which the signal from a detector component or a preamplifier is digitized in a fadc .",
    "the signal contains information about the energy deposited or collected as well as the time .",
    "it may have a shape that depends on the particle , or it may represent overlapping pulses . although the desired information ( e.g. , energy ) may need only a fraction of the data bits of the digitized pulse , sophisticated processing is often not possible on the fast time scale of the signals .",
    "so the digitized pulses are passed on and possibly stored for later analysis .",
    "an additional problem with such signals is that of distinguishing a real signal from a noise excursion , perhaps one that is many standard deviations from the average .",
    "precision experiments that push to the limits of sensitivity might falsely record such excursions while , due to noise fluctuations , miss good signals .",
    "to address such issues , we have been developing methods based on correlation coefficient ( cc ) algorithms .",
    "such cc methods can be used to pick out signals from a stream of input data , to scan through atomic or nuclear spectra to identify peaks , to obtain initial estimates of the yield and location of a peak for use in a detailed fitting program , for pedestal evaluations in the presence of noise @xcite , among other things .",
    "although the context for our work is the koto experiment at j - parc @xcite , benefits can also extend to many other experiments .",
    "our initial and primary interest in developing cc methods was for use in offline data analysis .",
    "we explore here the ability of cc algorithms to identify fadc signals and to distinguish them from noise .",
    "very good estimates of the energy and time of fadc signals can be obtained quickly and easily for use in event reconstruction .",
    "consideration is also given to ways in which the methods might be extended to online applications where only a small fraction of the data contains meaningful information , and/or the event rate through a daq system or the storage of data are limited .",
    "consider a set of data \\{@xmath0 } and a reference peak \\{@xmath1 } , each with @xmath2 points .",
    "a simple correlation function is that of the cosine similarity function @xcite @xmath3 where each sum is over @xmath2 points .",
    "this normalized , @xmath2-dimensional scalar product expresses how well two vectors are ` aligned ' in the space .",
    "more generally , the correlation coefficient @xmath4 is defined as @xcite @xmath5 \\ ,",
    "\\left [ n\\sum x_i^2 - ( \\sum x_i)^2 \\right ] \\right\\}^{1/2 } } \\:.\\ ] ] each sum is again over @xmath2 values .",
    "the value @xmath6 is actually more meaningful in that it expresses the fraction of the variance in the data \\{@xmath0 } which is accounted for by the hypothesis of the reference peak \\{@xmath1}. for example , if @xmath7 , about half of the variance in the data would need to be ascribed by something other than the reference peak .",
    "a reference peak can be shifted through a data spectrum to identify candidate peaks for which @xmath4 at some location exceeds a selection criterion .",
    "the sums @xmath8 , @xmath9 , and @xmath10 are all known and fixed .",
    "the sums involving @xmath0 alone can be adjusted at each step by dropping off the contributions from the first ( oldest ) data location and adding the contributions of the new location . however",
    ", the correlation sum @xmath11 must be recomputed at each step .",
    "to provide a context for the discussion , we consider the koto experiment which seeks to obtain the first observation of the @xmath12  decay and a measurement of the cp - violating parameter in the standard model ( sm ) .",
    "a full description of the koto daq system , along with an overview of the experiment , is provided in ref .",
    "only some items relevant to the discussions in this paper are noted here .",
    "the heart of the detector system is a roughly circular array of 2716 small and large csi crystals , approximately 90 cm in radius , for detecting photons .",
    "the array has a hole of 20 cm by 20 cm , partly filled with some veto detectors , for the beams to pass through . in front of and surrounding the csi array are numerous detectors to veto events with charged particles and/or photons that miss the array",
    ".    signals from each csi crystal are sent to custom - made fadc modules , each with 16 inputs @xcite .",
    "the signals are passed through a low - pass filter that is designed to convert the pulse into a quasi - gaussian shape about 45 ns full width at half maximum , and with a long and relatively flat tail .",
    "this shape is digitized by a 14-bit , 125-mhz chip into 64 time samples ( initially 48 samples ) .",
    "the top of the peak in each channel is adjusted to be near the middle of the time samples , leaving room for samples at each end to estimate pedestals .",
    "an example of a fadc signal is shown in fig .",
    "[ fig : data_peak ] .",
    "the signals in each module are placed in a 4-@xmath13s pipeline , sufficient to retain all data . upon receipt of a suitable trigger pulse",
    ", the fadcs then transmit the pipelined data for all time samples of the event to level 2 ( l2 ) modules .",
    "the l2 modules prepare the data for routing through 1-gb ethernet links to a computer array for event building , followed by ethernet transfer from j - parc to the nearby kek laboratory for long - term storage .",
    "the daq hardware is fully synchronized to an 8-ns clock .",
    "for each event , the goal of data analysis is to identify the ` hit ' crystals , their energy deposits , and their times so that clusters corresponding to the incident photons can be constructed .",
    "kinematic analyses are then applied to reconstruct the @xmath14 decay modes and their properties .",
    "it is assumed for the discussion here that suitable methods are applied to determine pedestals .",
    "our analyses typically involve an algorithm the utilizes the averages of the first 8 and the last 8 time samples , with checks on possible accidental peaks in those regions @xcite .",
    "the discussion is also focused on the csi crystals as they determine the kinematics of an event .      for this work , a model reference peak \\{@xmath1 }",
    "was constructed by averaging the shapes obtained from a large number of peaks in the data of an early koto test run . a representation of the shape is shown in fig .",
    "[ fig : data_peak ] .",
    "this parent reference peak consists of 44 samples of real ( floating point ) numbers with a maximum value of 1.0 . because the raw data are in the form of 14-bit integers , the analysis is made much faster by coding eq .",
    "( 2 ) with integer arithmetic and bit shifts . an auxiliary reference peak of 21 integers is thus used in the data analysis routines .",
    "the data for this peak includes all values of the parent reference peak down to the 2 - 3% level , where the tail becomes flat .",
    "the peak is then scaled from the parent reference peak so that the sum of the 21 values is @xmath15 .",
    "( see sec .  5 .",
    ")    to find hits , a pedestal - subtracted time spectrum is prepared for each crystal ( extended with samples of zero at each end to accommodate the samples before the maximum of the reference peak ) .",
    "the reference peak is then scanned through a time spectrum , a correlation coefficient is calculated at each step , and values that exceed the user s criterion are placed in a table along with a label of the time sample .",
    "in addition , the cc routine automatically calculates the area @xmath16 of the signal peak and the weighted time sum @xmath17 , and includes them in the candidate table .",
    "the user s code selects the highest cc value from the table , if any , to record a hit , along with the area and mean time @xmath18 .",
    "the area is converted to a value for the peak maximum by a fixed constant .",
    "the energy is obtained from this peak maximum by applying experimental calibration constants .",
    "it is to be noted that the information returned to the user is obtained directly from the data and is not the result of a fitting procedure .",
    "the cc value is simply a measure of the quality of the correlation with respect to a reference shape .",
    "statistical precision is improved by using a sum over the peak distribution rather than a single sample at the maximum .",
    "our standard analysis code contains some other useful features .",
    "for example , a time spectrum can be scanned prior to the cc analysis to see if it satisfies a tight criterion for having no energy , at which point it is removed from further processing . a simple method is to find the maximum and minimum values of all time samples and test if their difference is less than a specified value ( _ e.g. _ , 4 - 6 @xmath19 ) @xcite .",
    "also , because the peaks of all the csi signals are located near a fixed time sample by design , it is not necessary to scan over the full time distribution but only over a region around the nominal time sample .",
    "this option can eliminate crystals that have only out - of - time accidentals .",
    "two cc criterion levels are available for test and development purposes : one in the cc routine to fill its table of hit information for the user , and a second , higher one for final user selection .",
    "finally , an energy cut can be applied , commonly near the noise floor .",
    "real data are often not the best source for testing a correlation coefficient method .",
    "the energies and times have uncertainties from calibration methods , pedestal values that must be determined empirically , non - linearities , noise from known and unknown sources , and many other issues . in short , the true values are unknown and the purpose of the data analysis codes is to estimate the best values .",
    "the best tests are against monte carlo ( mc ) simulations , even with their own uncertainties .",
    "extensive mc studies were made to test the ability of the cc method to properly detect photon events in the csi array , and especially to explore its sensitivity to small signals down to the noise region . in these studies ,",
    "pseudo - fadc data were generated and then processed through the offline analysis code in the same way as real data .    in generating the pseudo - fadc data ,",
    "a pedestal level was generated randomly for each crystal .",
    "the values could be selected for the analysis , or an algorithm could be used to extract a pedestal from the first 8 and/or the last 8 time samples of a time spectrum . in the case of the algorithm ,",
    "the root - mean - square ( rms ) deviations of pedestals from their averages were about 0.7 adc counts .",
    "the pedestal fluctuations depend on noise in the system . from the data sheet for the fadc used in the experiment as well as tests with the fadc boards @xcite",
    ", a standard deviation of about @xmath20 counts was chosen .",
    "combined with a model energy conversion scale factor of 9 counts / mev , the noise floor is near 0.6 mev ( 2 - 3 @xmath21 ) .",
    "hence , the mc simulations of energy deposits in the crystals were converted to adc counts , digitized with respect to the parent reference peak , and added with gaussian distributed noise fluctuations at each time sample to the pedestal value of a crystal .",
    "the signal data were also given random time fluctuations within one time sample .",
    "apart from the effects of noise fluctuations , the conversion scale factor cancels in round - trip mc simulations .",
    "single photons for ten energies between 1 and 1000 mev were directed to the csi crystals .",
    "except for the lowest energies , the photon energy is deposited over several individual crystals .",
    "the individual deposits and the summed total energy were recorded by the mc code .",
    "the analysis code with a cc value @xmath7 was used to select hits .",
    "a window of about @xmath22 time samples about the expected location was used , and there was no energy cut .",
    "the results from the analysis were compared against the original mc energy and time values , crystal by crystal for each event , to find matched , missed , and false hits .",
    "full details are given in a separate tech note @xcite , with key features summarized here .",
    "even though the csi crystals have a radiation length of 27@xmath23 , there is some inefficiency in collecting all of the energy of an electromagnetic shower .",
    "separate mc studies have shown that @xmath24 and @xmath25 from the showers ( as well as neutrons from photonuclear processes ) can be emitted and carry energy back upstream .",
    "in addition to the intrinsic loss of energy through physical processes , analysis codes may not be able to identify all of the deposited energy of a photon due to ambiguities arising from photo - statistics , noise , and/or limitations of the detection algorithm . at some point , no method that reports energy deposits below the noise floor can be considered to be reliable .    with no energy cut on any crystal ,",
    "the csi array collected an average of 98.0% to 99.4% of the incident mc photon energy , increasing slowly over the 11000 mev range .",
    "for the same range , the analysis code collected an average of 70.2% to 98.6% of the photon energy over the csi array .",
    "note that the 30% discrepancy between the mc and analyzed hits for 1-mev photons is only 0.3 mev ; the discrepancy is 0.8% ( 8 mev ) for 1000-mev photons . if crystals with energy deposits less than 1.0 mev are excluded from the sums , both the mc and analysis codes collect nearly equal average fractions of the photon energies .",
    "the losses range from about 22.5% or @xmath260.7 mev for 3-mev photons to 2% or 20 mev for 1000-mev photons .",
    "hence , with such a cut , it would be feasible on average to correct the energy of a photon cluster obtained from data by using an energy - dependent factor determined from mc simulations .    on average",
    ", the cc method provides very good agreement with the energies and times of the hits .",
    "summing over the energy differences , positive and negative , between the individual mc deposits and the analyzed hit deposits , the net difference was about 0.01 mev for every photon energy .",
    "the rms spreads of the differences were about 0.13 mev .",
    "similarly , the summed time differences were about 0.04 time samples with an rms spread typically between 0.60 - 0.70 of the 8-ns time step .",
    "all of these quantities were obtained with the use of known pedestals .",
    "if a pedestal algorithm is used , the summed energy differences were about 0.07 mev with a rms spread of 0.23 mev , while the summed time differences and rms spreads were unaffected .",
    "the cc method is not intended to provide high precision for these quantities .",
    "yet it provides excellent estimates for the quantities as starting points if needed for detailed fitting routines .      in the previous section , events were considered",
    " matched \" if they had the same crystal i d , although the energies were generally close as well .",
    "but the energy regions for the missing and false hits also need to be examined .    the fraction , in percent , vs.  low - energy deposits within a cluster of matched , missed , and false hits between mc and analyzed pseudo - data distributions are shown in fig .",
    "[ fig : hit_distrib ] for four of the pure photon energies .",
    "the percent distributions are similar in each case , with the lines for the matched and missed hits crossing at 50% near 0.6 mev ( in our model ) .",
    "this value can be interpreted as having an equal probability for either choice : below this value , noise prevails ; above this value , there is an improving likelihood of having a real hit .",
    "the missing mc hits are nearly all gone by 1 mev , with a few reaching perhaps 1.5 mev .",
    "hence , one may define the hard noise region @xmath27 mev , and a gray region 0.6 mev @xmath28 mev .",
    "these values agree well with separate studies of the noise regions based on pseudo - fadc events with zero energy .",
    "the energy distributions here are based on assumptions in the monte carlo simulations of the overall energy calibration of fadc counts per mev .",
    "they may be different for koto or any other experiment .",
    "in addition , photo - statistics can affect the behavior at these low energies , and are not included in the model .",
    "such fluctuations would increase the energy values for the hard and gray regions .",
    "all of our mc calculations showed that very few csi crystals have energy deposits in an event . out of 2716 crystals , a 1-mev photon deposits energy on average in 1.4 crystals , while a 1000-mev photon would have hits in 48 crystals .",
    "even complicated multi - photon decays had deposits only up to 200 hits per event , with average values of about 100 - 150 hits per event . hence , 95% or more of the event data",
    "have no direct physics content .",
    "if crystals with real energy deposits can be cleanly distinguished from those with only noise , substantial enhancements in daq event rates , along with savings in analysis time and data storage , can be implemented .",
    "large compression factors of 20 , 30 , or more might be possible .",
    "to accomplish such a task , the correlation coefficient would need to be recomputed every time sample ( 8 ns for koto ) on data in a fadc pipeline .",
    "although challenging , a rearrangement of eq .",
    "( 2 ) along with the use of integer arithmetic and bit shifts has provided a solution that can be encoded in the fadc firmware .",
    "it is not necessary to know the actual cc value @xmath4 to make a decision about whether to retain some data or not , but only that it exceeds a preset value . in that case",
    ", it will be convenient to square eq .",
    "( 2 ) and rearrange it in a slightly different form . to ensure a positive correlation ,",
    "require that the numerator of eq .",
    "( 2 ) before squaring be greater than zero .",
    "then , defining @xmath29 , @xmath30 ^ 2 = \\left\\ { \\rho^2 \\left [ \\frac{1}{n}\\sum x_i^2 -   \\frac{1}{n^2}(\\sum x_i)^2 \\right ] \\right\\ }   \\left [ n\\sum y_i^2 - ( \\sum y_i)^2 \\right ] \\:.\\ ] ] as mentioned in sec .",
    "4.1 , @xmath8 in our model is normalized to 512 ( @xmath31 ) , so @xmath32 .",
    "this scaling is needed to obtain sufficient accuracy with integer arithmetic for small signals .",
    "the factor in curly braces can be precomputed once .",
    "the selection criterion is met if the left - hand side is greater than the right - hand side .",
    "it is not necessary to complete the calculations over the full dynamic range of the signals because those that exceed some level will certainly be passed .",
    "if the test fails , a compression bit for the corresponding adc input to the module can be set , and referenced by subsequent data stages to recognize missing data .",
    "the monte carlo studies have shown that a value of @xmath7 is generally successful .",
    "it has the ability to reach well into the noise region without picking up an excessive number of false hits .",
    "a more conservative value of 0.6 may be better for fadcs , to preserve marginal cases for further analysis . for the mc data , the extra hits with @xmath33",
    "all had energies below 1 mev .",
    "values below 0.6 tended to be excessively sensitive to noise .",
    "as with the offline case , a time window can be used for the cc scans to suppress accidentals .    because the correlation coefficient function is complex and can take up considerable space in a fpga , replacing it with the similarity function eq .",
    "( 1 ) may be satisfactory .",
    "in offline comparisons , very little difference has been found between the results of the two functions .",
    "many experiments need to be sensitive to signals that border on or are embedded in the noise region .",
    "a common approach is to test for an excursion that is a few noise standard deviations above the pedestal level to define a signal .",
    "this method , however , can be compromised by additional random fluctuations in the data , such as accidentals , or the pedestal level .",
    "also , excursions a few time samples from the correct time can occur .    if the signals have an approximately fixed shape apart from magnitude ( or can be transformed to such a shape ) , a correlation comparison against a reference peak is a far better way to identify a real signal . to dig a signal pattern out of noise fluctuations with some level of confidence ,",
    "there is little choice but to use such comparisons . at the lower values of @xmath4 ,",
    "the cc method is effectively a ` bump ' detector for low signals .",
    "detailed studies with simulated data have established that the correlation - coefficient ( or similarity ) method is very successful in identifying energy deposits ( hits ) in detector elements well into the noise region .",
    "it provides great benefits especially for offline analysis .",
    "it easily provides very good estimates of the signal energy and time that are needed for subsequent detailed fitting , and optionally for reducing the amount of stored data .    for online use in fadc modules ,",
    "the application of the method should be sufficiently conservative to preserve possible hits of small signals for later analysis , but also to provide a high level of data compression . as with other possible methods of working in the noise region ,",
    "there is some risk of losing a real signal .",
    "the use of the method must be carefully tailored to the design requirements of the experiment , especially the balance between the required signal range , photo - statistics , and other sources of noise .",
    "we thank our colleagues on the koto experiment for many thoughtful questions and comments during the development .",
    "this work was supported in part by the doe award de - sc0002644 through a subcontract from the university of michigan and doe award de - sc0006497 to arizona state university .",
    "9 e. frle@xmath34 , d. po@xmath35anni@xmath36 , and s. ritt , nucl .",
    "instrum .",
    "phys .  res .",
    "a * 463 * , 341 ( 2001 ) ."
  ],
  "abstract_text": [
    "<S> the large growth of flash adc techniques for processing signals , especially in applications of streaming data , raises issues such as data flow through an acquisition system , long - term storage , and greater complexity in data analysis . in addition , experiments that push the limits of sensitivity need to distinguish legitimate signals from noise . </S>",
    "<S> the use of correlation coefficients is examined to address these issues . </S>",
    "<S> they are found to be quite successful well into the noise region . </S>",
    "<S> the methods can also be extended to field programmable gate array modules for compressing the data flow and greatly enhancing the event rate capabilities .    </S>",
    "<S> flash adc , daq , koto , correlation coefficient </S>"
  ]
}