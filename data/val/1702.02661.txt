{
  "article_text": [
    "ranking from pairwise comparisons or _ preferences _ is an ubiquitous problem in machine learning , statistics and theoretical computer science . in the",
    "so - called _ non - active _ setting , one is given comparison results of @xmath0 pairs pre - selected from among all pairs of @xmath1 items where each pair is compared at least @xmath2 times . particularly , the learner does not get to choose which pairs are to be compared .",
    "the goal is then to estimate a suitable ordering of the items , using the observed comparison results , that conforms to the true ordering , assuming one exists , up to the desired error @xmath3 in a suitably defined error measure .    in practical ranking applications",
    ", we often have side information associated with the items that need to be ranked ",
    "such a scenario is referred to as the _ inductive _ setting .",
    "an advantage in this inductive learning setting is that , in addition to ranking a given set of items , one is also able to rank new unseen items that may introduced after parameter learning .",
    "motivated by these factors , we wish to leverage the available side information to compute an ordering more efficiently than existing techniques .",
    "this is relevant in many practical applications ; for instance , in addition to using a minimal amount of customer preference data , ( a ) using food characteristics like nutrition , preparation method , etc could help in finding the top - rated dishes of a restaurant , ( b ) using car features like engine type , body type , etc could help elicit useful trends for automotive industry .",
    "[ [ our - contributions ] ] our contributions : + + + + + + + + + + + + + + + + + + +    to the best of our knowledge , our work is the first to derive a provable and efficient method for ranking in the non - active inductive setting . our novelty and technical contributions can be summarized along the following axes :    1 .",
    "_ model : _ we generalize existing models so that we can incorporate ( a ) features , and ( b ) feature correlations associated with the items to be ranked . we show that our model subsumes many existing and popular ranking models .",
    "_ algorithm : _ our algorithm uses two key subroutines namely , ( a ) noisy inductive matrix completion , and ( b ) approximate pairwise ranking algorithm  @xcite .",
    "guarantee : _ we derive the guarantee that our algorithm obtains , with high probability , an @xmath3-accurate recovery using @xmath4 independent pairwise comparisons chosen uniformly at random .",
    "experiments : _ we substantiate our theoretical results by demonstrating sample complexity gains on both synthetic and real - world experiments .",
    "we would like to emphasize upfront that it is the sole focus of this paper to study the practically motivated regime of @xmath5 in detail .",
    "furthermore , we note that our sample complexity results do not violate the standard @xmath6 lower bounds for comparison - based sorting algorithms since we develop an algorithm that effectively ranks in the _ feature space _ rather than the _ item space_.      we now give a brief overview of relevant work in ranking models followed by a brief background regarding tools from inductive matrix completion theory which will be crucial in proving our sample complexity bounds .",
    "[ [ ranking - models ] ] ranking models : + + + + + + + + + + + + + + + +    in the simplest terms , the ranking problem involves estimating the _ best _ ordering items according to some observed preferences .",
    "a early thread of ranking literature has its beginnings in economics involving choice models  @xcite ; other related works in social choice theory include @xcite and @xcite . a certain deterministic version of the ranking problem is also studied as the _ sorting _ problem which is central in theoretical computer science .    1",
    ".   _ random utility ( ru ) models : _ starting with the seminal work of @xcite , the bradley - terry - luce ( btl ) model has become a landmark model for ranking . in the vanilla version of this model ,",
    "the probability that item @xmath7 beats item @xmath8 is given by @xmath9 where @xmath10 is the parameter vector to be estimated from data ; the @xmath11 entry in @xmath12 denotes the _ score _ associated with item @xmath7 .",
    "thurstone  @xcite model is also a well - known statistical model ; here , @xmath13 where @xmath14 is the standard normal cumulative distribution function ( cdf ) and @xmath15 is the score vector .",
    "these classic models fall under the so - called _ random utility _",
    "( ru ) models  @xcite .",
    "_ item feature ( if ) models : _ extending the btl model , statistical models that utilize side information are presented in @xcite .",
    "recently , @xcite presented the blade - chest ranking model which studied the stochastic intransitive setting .",
    "their algorithm involves regularized maximum likelihood estimation for which tight sample complexity properties are not known . despite the above works , to the best of our knowledge , there are no known models utilizing feature information while have provable sample - efficient algorithms for estimation and ranking .",
    "low rank ( lr ) models : _ recently , @xcite  unifying classic models such as btl and thurstone models  defined a generic class of preference matrices which have low rank under transformations involving suitable _ link functions_. upon such a transformation ,",
    "connections of the ranking problem to matrix completion theory become clear .",
    "subsequently , they use well - known matrix completion results to derive sample complexity guarantees for ranking .",
    "however , their model does not utilize side information that may be available .",
    "this list is by no means exhaustive ; while there exist several other ranking methods ( eg , ranking - svm@xcite ) , there are no known sample complexity guarantees associated with these .",
    "[ [ inductive - matrix - completion ] ] inductive matrix completion : + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    the matrix completion task  @xcite is to fill - in the missing entries of a partially observed matrix , which is possible efficiently under a low - rank assumption on the underlying matrix .",
    "oftentimes , side information may be available which further makes this task potentially easier .",
    "this is the _ inductive matrix completion _",
    "( imc ) problem which is formally defined as the optimization problem , @xmath16 where @xmath17 and @xmath18 are known feature matrices , @xmath19 is a rank-@xmath20 unknown latent parameter matrix , @xmath21 \\times [ n]$ ] is the support set corresponding to the ( uniformly sampled ) observed entries and @xmath22 is any loss function , the squared loss being the most commonly chosen one . once",
    "the estimate @xmath23 is obtained using the training set indexed by @xmath24 , predictions may then be performed as @xmath25 for any @xmath26 .",
    "the known solution techniques with recovery guarantees are :    1 .",
    "_ non - convex algorithm ( via alternating minimization ) : _ this approach entails parameterizing @xmath27 and performing alternating projected least squares updates on @xmath28 and @xmath29 .",
    "the tightest known guarantee for this approach involves a sample complexity of @xmath30 and a convergence rate of @xmath31  @xcite .",
    "2 .   _ convex relaxation ( via trace - norm formulation ) : _ this approach entails relaxing the rank constraints to a nuclear norm penalty .",
    "existence of a unique optimum can be shown with high probability @xcite and is characterized a sample complexity of @xmath32 . despite the non - smoothness , a sub - gradient descent algorithm provably converges with a rate of @xmath33  @xcite .",
    "noisy features are handled in @xcite .",
    "_ general notation : _ unless stated otherwise , we use lower - case letters for scalars , upper - case letters for universal constants , lower - case bold - face letters for vectors and upper - case bold - face letters for matrices ; specifically , @xmath34 denotes a preference matrix . for any matrix @xmath35 ,",
    "let @xmath36 , @xmath37 where @xmath38 are the singular values of @xmath39 and @xmath40 .",
    "@xmath41 denotes the identity matrix whose dimensions would be implied from the context ; similarly , depending on the context , @xmath42 denotes a vector or matrix of zeros of the appropriate dimension .",
    "next , let @xmath43 and @xmath44 .",
    "let @xmath24 be the support set of the observed entries of a matrix and let @xmath45 .",
    "define projection of a matrix on the support set @xmath46 as : @xmath47 if @xmath48 and @xmath49 if @xmath50 .",
    "+ _ items and features : _ let @xmath1 be the number of items to be ranked .",
    "let @xmath51 denote the symmetric group on @xmath1 items .",
    "let each item have a @xmath52-dimensional feature vector associated with it , ie , @xmath53 $ ] ; concatenating these , we obtain the feature matrix @xmath54 \\in { \\mathbb{r}}^{d \\times n}$ ] .",
    "+ _ link functions : _ any @xmath55 \\rightarrow { \\mathbb{r}}$ ] which is a strictly increasing bijective function is a valid link function . for example , @xmath56 could be the logit function , which is the inverse of the sigmoid function , defined as , @xmath57 for @xmath58 $ ] ; another example is the probit function defined as @xmath59 where @xmath14 is the standard normal cdf .",
    "when we apply the link function to a matrix , we mean that the transformation applied entry - wise .",
    "+ _ preference matrices : _ let @xmath60^{n \\times",
    "n } | p_{ij}+p_{ji } = 1 \\}$ ] denote the set of all pairwise preference matrices over @xmath1 items .",
    "let the set of stochastic - transitive matrices be @xmath61 and the set of stochastic - intransitive matrices be @xmath62 .",
    "let @xmath63 be the set of preference matrices associated with unary random utility models ( which are described in the next section ) .",
    "let @xmath64 for some @xmath65 .",
    "let @xmath66 .",
    "define the set of preference matrices having rank-@xmath20 under the link function @xmath56 as @xmath67 .",
    "next , define the set of preference matrices having rank-@xmath20 under the link function @xmath56 with the associated feature matrix @xmath68 as @xmath69 where @xmath70 is an unknown rank-@xmath20 latent matrix ( which is a function of the parameters of the ranking model ) and @xmath71 \\in { \\mathbb{r}}^{d \\times n}$ ] is the known feature matrix whose @xmath11 column is the feature vector corresponding to the @xmath11 item .",
    "let @xmath72 be the inverse condition number of the feature matrix @xmath73 .",
    "let @xmath74 iff @xmath75 . denoting the indicator function by @xmath76",
    ", we define the distance between a permutation @xmath77 and a preference matrix @xmath78 as : @xmath79 note that the above distance measure essentially counts the fraction of pairs on which @xmath80 and @xmath34 disagree , and can be thought of as a normalized @xmath81 loss function",
    ".      _ random utility _ ( ru ) models , arising in discrete choice theory , dating back to @xcite , characterize the probability of an item @xmath7 beating item @xmath8 , @xmath82 , using a prior on the ( latent ) score associated with those items , @xmath83 and @xmath84 .",
    "the most popular pairwise ranking models including btl and thurstone models fit in this framework .",
    "in particular , it is well - known that if @xmath85 , we obtain the btl model ; for completeness , we justify it below : @xmath86 where @xmath87 follows from the fact that the difference of two independent standard gumbel distributed random variables follows the standard logistic distribution .",
    "similarly , if @xmath88 , we obtain the thurstone model .",
    "the underlying commonality in these models is the simple observation that the prior distribution is on the scores , which are unary terms .",
    "notably , the recent result by @xcite shows that under the inverse transformation of the cdf of the difference of the latent score variables , the preference probability matrix is low - rank for btl and thurstone models .",
    "further , they extended this result to a broader class of _ low - rank _ models in which the preference matrices are low - rank when the link function is set to be this inverse cdf .",
    "one angle of motivation for this paper stems from the intuitive thought that the scores associated with an item @xmath7 in ru models can be generalized to functions involving , not just unary terms but also , pairwise terms , ie , the score of _ item @xmath7 with respect to item @xmath8 _ is given by an energy function @xmath89 that has a bilinear form .",
    "from this point onwards , for simplicity , we detail the generalization of the ru models encompassing the btl model , ie , we posit that @xmath89 has a standard gumbel distribution and consequently , we choose the link function @xmath56 to be the logit function .",
    "it is noteworthy that our results will hold under any link function for the corresponding prior .",
    "we now propose the enery - based generative model , which we call _ feature low rank _",
    "( flr ) model , defined via the preference matrix specified as follows : @xmath90 here , we define the energy function associated with the pair of items @xmath91 to be of the form @xmath92 where @xmath65 and @xmath93 are the unknown latent parameters ( vector and matrix parameters repectively ) to be estimated , and @xmath94 and @xmath95 are the known feature vectors associated with items @xmath7 and @xmath8 respectively .",
    "it is clear from equation   that a key advantage of the proposed model is the additional ability to incorporate side information in the form of feature vectors and feature correlations in a latent space described by @xmath96 . in matrix notation , @xmath97 where @xmath98 is column vector in @xmath99 , @xmath100 is the all - ones column vector , @xmath101 is the full svd of @xmath102 ( such that @xmath103 are orthonormal matrices with @xmath104 as the @xmath105 diagonal matrix of singular values padded with zeros ) and @xmath106 ( such that @xmath107 and @xmath108 if @xmath109 ) .",
    "it is now clear that the sufficient condition for @xmath110 is that @xmath111 .",
    "now , we describe the generality of the flr model in equation   by showing that it subsumes many existing models and has much more expressiveness .",
    "[ prop : lr ] the lr model is a special case of the flr model , ie , @xmath112 .",
    "[ cor : lr ] let @xmath113 and @xmath56 be the logit link function . from proposition  [ prop : lr ] , it is easy to see the following special cases from equation  .    1",
    ".   let @xmath114 .",
    "if @xmath115 , then @xmath116 . if @xmath117 , then @xmath118",
    "2 .   if @xmath96 is symmetric , then @xmath119 and hence @xmath116 .",
    "3 .   let @xmath120 be a diagonal @xmath121 matrix ; let @xmath122 be orthonormal matrices . if @xmath123 where @xmath39 is a symmetric matrix , then @xmath124 .",
    "[ prop : unary_ru ] the unary ru models are special cases of the flr model , ie , @xmath125 .",
    "cccccc * model * & @xmath102 & @xmath126 & @xmath96 & _ pairs _ & _ per _ + btl & @xmath113 & @xmath127 & @xmath128 & @xmath6 & @xmath129 + item - feature & @xmath130 & @xmath65 & @xmath128 & many & many + chest - blade & @xmath113 & @xmath127 & rank@xmath131 & many & many + low - rank & @xmath113 & @xmath127 & @xmath132 & @xmath133 & @xmath134 + * this work * & @xmath130 & @xmath65 & @xmath93 & @xmath135 & @xmath136 +    the btl and thurstone models are obtained as special cases of the flr model under the logit and the probit transormations of @xmath34 respectively .",
    "this follows from proposition  [ prop : lr ] ( or corollary  [ cor : lr]-part ( 1 ) ) above together with propositions 6 and 7 of @xcite .",
    "[ prop : if ] regression - based models with item - specific features in @xcite are special cases of the flr model , ie , @xmath137 .",
    ". then we recover the blade - chest model  @xcite as a special case of the flr model by setting @xmath138 and @xmath139 .",
    "next , when @xmath140 , it is clear from theorem 1 of @xcite that such preference matrices degenerate into matrices in @xmath141 where @xmath56 is the logit function .",
    "moreover , it is easy to see that the flr model admits both stochastic - transitive and stochastic - intransitive preference matrices .    due to space constraints , proofs of propositions [ prop : lr ] , [ prop : unary_ru ] and [",
    "prop : if ] are given in the appendix . to summarize ,",
    "we have shown how to instantiate several previously proposed ranking models as special cases of our flr model in table  [ tab : summary ] .",
    "once we have the generative ranking model as developed in the previous section , the objective in our learning problem is then to find the permutation of @xmath1 items that minimizes the number of violations with respect to the true underlying preference matrix @xmath34 , ie , to find the best ranking @xmath142 in the sense that , @xmath143 the input is the pairwise comparison dataset @xmath144 which consists of comparison results of pairs @xmath91 from a survey involving @xmath2 users where each user with index @xmath145 assigns @xmath146 if he prefers @xmath7 to @xmath8 and @xmath147 if he prefers @xmath8 to @xmath7 .",
    "note that it is not necessary that all pairs of items be compared ; our algorithm is able to handle noisy and incomplete data .",
    "since the true preference matrix @xmath34 is unknown , our algorithm instead proceeds by using the empirical preference matrix @xmath148 computed from the available @xmath149 ; it is to be noted , even then , our analysis guarantees that @xmath150 is good as opposed to just @xmath151 .",
    "additionally , in our inductive setting , the feature information is encoded by @xmath152 for every item @xmath7 and concatenated to form the feature matrix @xmath130 .",
    "we present our main algorithm for inductive ranking in algorithm  [ alg : ipr ] .",
    "the input data consist of the set of pairwise comparison results @xmath153 , @xmath21 \\times [ n]$ ] , @xmath154 $ ] , @xmath155 and the feature matrix @xmath130 .",
    "the algorithm assumes the link function and the rank as input parameters .",
    "the subroutines used are :    1 .",
    "_ noisy matrix completion with features ( subroutine  [ alg : imc ] ) : _ note that to solve our ranking problem and derive the associated recovery guarantee , it suffices , as we have done , to use the specified trace - norm program as a black - box method ; hence , we assume that we have access to an oracle that gives us the solution to the convex program .",
    "the details of how the solution to this program may be found numerically is beyond the scope of this work  for further details regarding some possible sub - gradient algorithms , we refer the reader to @xcite and @xcite .",
    "@xmath156-approximate pairwise ranking procedure ( subroutine  [ alg : pr ] ) : _ let @xmath157 be the output of any pairwise ranking ( pr ) procedure with respect to an underlying preference matrix @xmath34 .",
    "for a constant @xmath158 , @xmath142 is said to be @xmath156-approximate if @xmath159 .",
    "any constant factor approximate ranking procedure maybe used .",
    "specifically , we use the copeland procedure  @xcite as a black - box method which has a @xmath160-approximation guarantee  @xcite .",
    "this method involves simply sorting the items according to a score which is computed for every item @xmath7 as @xmath161 .",
    "in this section , we state and prove our main result .",
    "[ thm : main ] let @xmath162 be the true underlying preference matrix according to which the pairwise comparison dataset @xmath153 is generated .",
    "let @xmath56 be @xmath163-lipschitz in @xmath164 $ ] .",
    "let @xmath24 be the set of pairs of items compared such that the number of pairs compared is @xmath165 where @xmath24 is chosen uniformly at random from among all possible subsets of item pairs of size @xmath0 .",
    "let each pair in @xmath24 be compared independently @xmath166 times where @xmath167 .",
    "then , with probability atleast @xmath168 , for any @xmath169 , algorithm  [ alg : ipr ] returns an estimated permutation @xmath142 such that @xmath170 .    the key take - away message in theorem  [ thm : main ] is the reduction in sample complexity possible due to efficient utilization of features and feature correlations , associated with the items to be ranked , by algorithm  [ alg : ipr ] .",
    "for instance , when @xmath171 , which is often the case in practice , we reduce the required total number of comparisons to be made to @xmath172 . thus , we achieve a very significant gain since the total number of comparisons is poly - logarithmic as opposed to quadratic in the number of items .",
    "this is especially crucial in large - scale machine learning applications .",
    "another point to be noted from theorem  [ thm : main ] is that , under the uniform sampling assumption , when features associated with items are known , it is more important that we compare sufficient ( precisely , @xmath173 ) number of different pairs rather than high number of comparisons per pair .",
    "furthermore , he total number of comparisons needed in theorem  [ thm : main ] is given by the product @xmath174 which is @xmath4 .",
    "we now present the proof of theorem  [ thm : main ] .",
    "we shall prove the theorem under the bernoulli sampling model ( where each entry of an @xmath175 matrix is observed independently with probability @xmath176 ) rather than the uniform sampling model ( wherein @xmath24 is chosen uniformly at random from among all possible subsets of item pairs of size @xmath0 ) ; the equivalence between the two is well - known ( see , for instance , section 7.1 of @xcite ) .",
    "@xmath177 for @xmath21 \\times [ n]$ ] , feature matrix @xmath102 .",
    "completed matrix @xmath178 .",
    "solve the convex program : @xmath179 @xmath180 .",
    "preference matrix @xmath181 .",
    "ranking @xmath142 .",
    "threshold : @xmath182 .",
    "compute row - sum of @xmath183 : @xmath184 .",
    "@xmath185 .",
    "set of comparison results @xmath153 , feature matrix @xmath102 , link function @xmath56 , target rank @xmath20 .",
    "ranking of @xmath1 items , @xmath186 .",
    "construct the partially observed empirical preference matrix using @xmath187 as : @xmath188 compute svd of @xmath189 and set @xmath190 . use a noisy inductive matrix completion subroutine : @xmath191 .",
    "take the inverse transform of the truncated @xmath20-svd of the completed matrix estimate : @xmath192 . using a pairwise ranking subroutine : @xmath193 . @xmath142 .",
    "let @xmath194 be the empirical probability estimate of @xmath82 .",
    "note that we compute @xmath195 for @xmath48 from the given pairwise comparison dataset , @xmath153 . from equation  ,",
    "@xmath196 where @xmath197 .",
    "since we use the empirical estimate for @xmath82 , we have noise due to sampling error only over @xmath24 , ie , @xmath198 where @xmath199 now , we solve the trace - norm regularized convex program corresponding to the noisy inductive matrix completion problem : @xmath200 and let @xmath201 be the link - transformed completed ( estimate ) matrix where @xmath202 be the estimated noise matrix .",
    "this is equivalent to solving the problem : @xmath203 we set @xmath204 and @xmath205 which may be upper bounded , by lemma 3 of @xcite as @xmath206 for a constant @xmath207 .",
    "we now recall theorem 1 from @xcite .",
    "let @xmath208 and @xmath209 be well - conditioned , specifically , @xmath210 for constant @xmath211 .",
    "the expected squared loss under bernoulli sampling is bounded as , with probability at least @xmath212 : @xmath213 where @xmath214 and @xmath211 are constants . by triangle inequality , @xmath215 using @xmath204 in equation  , with probability at least @xmath212 , @xmath216 let @xmath217 where @xmath218 . substituting the bounds for the @xmath219 terms from lemma  [ lem : sampling_noise ] and using the union bound , with probability at least @xmath220 , @xmath221 now , setting @xmath222 and @xmath223 , we obtain , with probability @xmath168 , @xmath224 .",
    "then , arguments similar to the proof of theorem 13 of @xcite yield our result .",
    "[ lem : sampling_noise ] under the conditions of theorem  [ thm : main ] , let @xmath0 item pairs be compared such that the number of comparisons per item pair is @xmath217 . then , with probability atleast @xmath225 , @xmath226 .",
    "due to space limitations , the proof of lemma  [ lem : sampling_noise ] is given in the appendix .",
    "in this section , we conduct a systematic empirical investigation of the performance of our ranking method and justify our theoretical claim in the previous section . the goal of this study is two - fold : ( a ) to verify the correctness of our algorithm , and ( b ) to show that by using features and feature correlations , our ipr algorithm has a better sample complexity thereby improving upon the lrpr algorithm that does not take into account the available side information .      for a given set of @xmath227 items , we consider three main problem parameters : ( 1 ) @xmath0  the number of item pairs compared ( figure  [ fig : vary_m ] ) , ( 2 ) @xmath2  the number of comparisons per pair ( figure  [ fig : vary_k ] ) , ( 3 ) @xmath52  the dimensionality of features ( figure  [ fig : vary_d ] ) .",
    "we study the performance of both ipr and lrpr algorithms by varying each of the problem parameters while fixing the others .",
    "we note that by making use of side information , ipr outperforms lrpr in all the cases as shown in the sample complexity plots .",
    "all the accuracy results presented are obtained by averaging over five runs .",
    "[ [ data - generation ] ] data generation : + + + + + + + + + + + + + + + + +    we consider three representative preference matrices derived from equation  : ( a ) _ model-1 _ : we set @xmath228 , ( b ) _",
    ": we construct a general @xmath229 ; here , we generate @xmath230 , and ( c ) _ model-3 _ : we construct a low - rank @xmath96 , ie , @xmath231 ; here we generate @xmath230 and then truncating @xmath96 by setting all but its top two singular values to zero . in all the three models ,",
    "we generate @xmath232 .",
    "the features are generate as @xmath233 ; to ensure that the features are well - conditioned , we perform the full svd of feature matrix @xmath102 and set all its singular values to 1 .    [ [ parameter - settings ] ] parameter settings : + + + + + + + + + + + + + + + + + + + +    for ipr , we choose @xmath234 and @xmath235 .",
    "note that lrpr allows for the rank of the problem to be automatically determined . in the same spirit , though step-5 of algorithm  [ alg : ipr ] requires the knowledge of the true rank , we choose _ not _ to perform this truncation step thereby including the error induced by the smaller singular values resulting from noise due to sampling in our distance estimate  even then , ipr outperforms lrpr .",
    "we apply our method on two popular preference learning datasets .",
    "we briefly describe the data and the results ( figure  [ fig : vary_real ] ) we obtain below :    1 .   _",
    "sushi : _ this data  @xcite is from a survey of @xmath236 customers .",
    "each customer orders @xmath237 sushi dishes according to their preferences .",
    "the goal , then , is to estimate a global ranking of these sushi dishes using these observations from customers .",
    "each sushi has six features such as price , taste and so on .",
    "we construct the complete preference matrix @xmath238^{10 \\times 10}$ ] using the preferences of all the customers and consider this to be ground truth preference matrix . an interesting observation was that , over five runs of the algorithms , ipr gets two out of the top four sushi dishes right most of the times namely , ` amaebi ' and ` ikura ' ; on the other hand , lrpr does not succeed in recovering these always .",
    "car : _ the task in this dataset  @xcite is find an order of preference among ten cars .",
    "this data was collected by surveying @xmath239 customers regarding there preferences among pairs of cars drawn from the set of ten cars .",
    "each car has four features including engine , transmission and so on .",
    "we construct the ground truth preference matrix @xmath238^{10 \\times 10}$ ] by aggregating the pairwise preferences of all the customers .",
    "an interesting trend we found was that customers generally preferred sedans over suvs and non - hybrid vehicles over hybrid vehicles .",
    "in this paper , we have proposed and characterized the flr model together with the guaranteed ipr algorithm that utilizes available side information of the items to be ranked to provably reduce the sample complexity for ranking from @xmath240 to possibly as low as @xmath241 .",
    "a future research direction is to see if mixture models for ranking such as the recently proposed topic modeling approach  @xcite could fit into our framework while admitting sample - efficient estimation algorithms .",
    "abbasnejad , e. ; sanner , s. ; bonilla , e.  v. ; poupart , p. ; et  al .",
    ". learning community - based preferences via dirichlet process mixtures of gaussian processes . in _",
    "ijcai_.    bradley , r.  a. , and terry , m.  e. 1952 .",
    "rank analysis of incomplete block designs : i. the method of paired comparisons .",
    "39(3/4):324345 .",
    "cands , e.  j. , and recht , b. 2009 .",
    "exact matrix completion via convex optimization .",
    "9(6):717772 .",
    "cands , e.  j. ; li , x. ; ma , y. ; and wright , j. 2011 .",
    "robust principal component analysis ?",
    "58(3):11 .",
    "caragiannis , i. ; procaccia , a.  d. ; and shah , n. 2013 .",
    "when do noisy votes reveal the truth ? in _ proceedings of the fourteenth acm conference on electronic commerce _ , 143160 .",
    "cattelan , m. 2012 .",
    "models for paired comparison data : a review with emphasis on dependent data",
    ". 412433 .",
    "chen , s. , and joachims , t. 2016 .",
    "modeling intransitivity in matchup and comparison data . in _ proceedings of the ninth acm international conference on web search and data mining _ , 227236 .",
    "chiang , k .- y . ; hsieh , c .- j . ; and dhillon , i.  s. 2015 .",
    "matrix completion with noisy side information . in _ advances in neural information processing systems _ , 34473455 .",
    "copeland , a.  h. 1951 . a reasonable social welfare function . in _",
    "mimeographed notes from a seminar on applications of mathematics to the social sciences , university of michigan_.    coppersmith , d. ; fleischer , l. ; and rudra , a. 2006 .",
    "ordering by weighted number of wins gives a good ranking for weighted tournaments . in _ proceedings of the seventeenth annual acm - siam symposium on discrete algorithm _",
    ", 776782 .",
    "society for industrial and applied mathematics .    ding , w. ; ishwar , p. ; and saligrama , v. 2015 .",
    "a topic modeling approach to ranking . in _",
    "aistats_.    jain , p. , and dhillon , i.  s. 2013 .",
    "provable inductive matrix completion . .",
    "ji , s. , and ye , j. 2009 .",
    "an accelerated gradient method for trace norm minimization . in _ proceedings of the 26th annual international conference on machine learning _ , 457464 .",
    "joachims , t. 2002 . optimizing search engines using clickthrough data . in _ proceedings of the eighth acm sigkdd international conference on knowledge discovery and data mining _ , 133142 .",
    "kamishima , t. , and akaho , s. 2009 .",
    "efficient clustering for orders . in _ mining complex data_. springer .",
    "261279 .",
    "lu , t. , and boutilier , c. 2011 . learning mallows models with pairwise preferences . in _ proceedings of the 28th international conference on machine learning ( icml-11 )",
    "_ , 145152 .",
    "luce , r.  d. 1959 . .",
    "john wiley and sons .",
    "marschak , j. , et  al . 1959 .",
    "binary choice constraints on random utility indicators . technical report ,",
    "cowles foundation for research in economics , yale university .",
    "rajkumar , a. , and agarwal , s. 2016 .",
    "when can we rank well from comparisons of @xmath242 non - actively chosen pairs ? in _",
    "29th annual conference on learning theory _",
    ", 13761401 .",
    "thurstone , l.  l. 1927 . a law of comparative judgment .",
    "34(4):273 .",
    "xu , m. ; jin , r. ; and zhou , z .- h . 2013 .",
    "speedup matrix completion with side information : application to multi - label learning . in _ advances in neural information processing systems _ , 23012309 .",
    "we prove this by showing that every @xmath243 is in @xmath244 but not the other way around . by the definition of a preference matrix corresponding to the lr model , if @xmath243 , then @xmath245 .",
    "similarly , for the flr model , if @xmath246 , then @xmath196 and @xmath245 ; in other words , @xmath111 . now setting @xmath247 , we have @xmath248 . on the other hand ,",
    "if @xmath249 , we have @xmath250 .",
    "let @xmath126 be the unary score vector in ru models .",
    "the result then follows by setting the energy function of item @xmath7 with respect to item @xmath8 in the flr model to be the unary score corresponding to item @xmath7 in the ru model , ie , by simply setting @xmath113 and @xmath128 which leads to @xmath251 .",
    "this is immediate by setting @xmath128 . for concreteness , we choose @xmath56 to be the logit link function . setting @xmath128 in equation 1",
    ", we obtain @xmath252 observe that @xmath253 . writing this in matrix notation , @xmath254 .",
    "note that @xmath255 is a rank-@xmath256 skew - symmetric matrix .",
    "let @xmath257 .",
    "now , note that @xmath70 is also a rank-@xmath256 skew - symmetric matrix .",
    "thus , @xmath258 since @xmath259 .",
    "in addition , note that the flr model accounts for feature correlations when @xmath260 .",
    "for any support @xmath24 , define the following event : @xmath261 by hoeffding s bound , @xmath262 whenever @xmath263 .",
    "let @xmath163 be the lipschitz constant of @xmath56 and set @xmath217 .",
    "using the inequality that @xmath264 , we have @xmath265"
  ],
  "abstract_text": [
    "<S> we study the problem of ranking a set of items from non - actively chosen pairwise preferences where each item has feature information with it . we propose and characterize a very broad class of preference matrices giving rise to the _ feature low rank _ ( flr ) model , which subsumes several models ranging from the classic bradley  terry  </S>",
    "<S> luce ( btl )  @xcite and thurstone  @xcite models to the recently proposed blade - chest  @xcite and generic low - rank preference  @xcite models . </S>",
    "<S> we use the technique of matrix completion in the presence of side information to develop the inductive pairwise ranking ( ipr ) algorithm that provably learns a good ranking under the flr model , in a sample - efficient manner . in practice , through systematic synthetic simulations , we confirm our theoretical findings regarding improvements in the sample complexity due to the use of feature information . moreover , on popular real - world preference learning datasets , with as less as 10% sampling of the pairwise comparisons , our method recovers a good ranking . </S>"
  ]
}