{
  "article_text": [
    "in astronomy today , the standard technique for acquiring deep astronomical images is through a series of short , often dithered , exposures .",
    "applying this procedure enables the removal of cosmic rays , the filtering of bad pixels , and the masking of device defects .",
    "it also increases the dynamic range of the resulting image ( as bright sources in single , long exposures saturate ) and provides better control of the underlying point spread function ( psf ) as long as the psf is fully sampled .    to achieve the depth of a long exposure from a series of exposures",
    "requires that we combine the individual images , accounting for the variation in seeing , sky transparency , and background variability .",
    "this process is typically referred to as `` image coaddition '' and is at the heart of many image processing systems .",
    "the criteria that we optimize in the image coaddition depends on the science in question at hand .",
    "for example , in faint galaxy surveys ( e.g.  the hubble ultra deep field , @xcite ) photometric accuracy might be paramount , but for weak lensing surveys ( e.g. the canada france hawaii telescope legacy survey , @xcite ) , the preservation of the underlying image resolution may be the primary concern . given these differing objectives two open questions remain ; how do we optimize the coaddition of astronomical images and is there is an optimal criterion that is relevant to all scientific goals ?    with a new generation of deep imaging surveys coming on - line throughout this decade , including the panoramic survey telescope & rapid response system ( pan - starrs ) , the dark energy survey ( des ) , and the large synoptic sky survey ( lsst ) , each producing petabytes of data , image coaddition can not just be assed by the statistical analysis ; it is also a question of the computational efficiency of the different approaches . in this paper , we compare several different approaches for image coaddition , taking into account their statistical properties and their computational cost .",
    "we consider in detail the fourier - domain methods proposed in @xcite along with several straightforward methods , such as running means or medians .",
    "we compare these methods using two performance criteria : flux conservation ( i.e. , pixelwise photometric accuracy ) and image resolution ( using a metric we call image quality ) . using these comparisons we can make statements about whether the additional complexity outweighs the extra costs they incur .",
    "our goal is to provide a framework for assessing the magnitude of the practical advantages more complex methods might provide .    in section 2",
    ", we set up the statistical model underlying our analysis and outline the properties of the various techniques . in section 3 ,",
    "we describe the simulations and define the performance criteria , and , in section 4 , we present the results of our simulations .",
    "consider a single image of a particular patch of sky .",
    "the object of interest is the true scene , which we represent as a function @xmath0 that takes a two - dimensional argument corresponding to position in the image and returns an intensity . for ground - based viewing ,",
    "however , we observe only a blurred , discretized , and noisy version of @xmath0 .",
    "we represent the blurring ( caused by atmospheric seeing and instrument artifacts ) by an operator @xmath1 . in this case , @xmath1 is associated with a psf @xmath2 such that the action of @xmath1 on @xmath0 is to integrate @xmath0 against @xmath2 .    now , suppose instead of getting one image we get a stack of @xmath3 images , all of the same patch of sky with science @xmath0 .",
    "we assume for this discussion that the images have been registered . then , due to atmospheric conditions changing over time , for each image @xmath4",
    "there is a possibly different operator @xmath5 with associated psf @xmath6 .",
    "then , if we define a regular grid of pixel centers @xmath7 , the observation on the @xmath8 image at the @xmath9 pixel is ) for points in the sky / image .",
    "note that integrals over such two dimensional arguments are actually double integrals .",
    "] @xmath10 where the @xmath11 s are noise random variables with suitable distributions .",
    "note that equation ( [ eq : fredholm ] ) also defines the operator @xmath5 as integrating @xmath0 against the psf @xmath6 .",
    "the statistical problem is to estimate @xmath0 given observation of @xmath12 .",
    "what makes the problem challenging is that the operators @xmath5 are _ ill conditioned _ , meaning that large changes in @xmath0 can make relatively small changes in @xmath13 , making recovery of @xmath0 from @xmath13 unstable .",
    "this is so because blurring dampens high frequency structure , so the singular values of this integral operator decay quickly to zero .",
    "thus , even small levels of noise can critically obscure structure in @xmath0 .    to see this in a simple example ,",
    "assume that the psf does not vary in shape across the image , which makes @xmath14 a convolution kernel .",
    "it follows that by using the fourier transform @xmath15 , we can recover @xmath0 exactly in the absence of noise by @xmath16 because @xmath17 .",
    "while the inverse exists in the absence of noise , the decay of @xmath18 at high frequencies can produce catastrophically high variances in the presence of noise , which produces nontrivial and random contribution at high frequencies ( so the numerator is non - zero but the denominator goes to zero ) .",
    "figure [ fig : fourierinvoperator ] demonstrates this effect in a 1-dimensional analog of the problem , comparing noise free reconstruction via equation ( [ eq : fourierinvoperator ] ) with reconstruction under noise with a 10e9:1 signal - to - noise ratio ( snr ) .",
    "the estimate in the latter case is wholly untenable .",
    "+      we assume that each observation is drawn from a distribution with mean @xmath19 because the observation process in the telescope involves counting photons , the distribution of @xmath13 is well modeled by a poisson distribution @xcite .",
    "thus , we assume that the @xmath13 s are independent poisson@xmath20 random variables .",
    "if the mean counts @xmath21 are large enough , the gaussian approximation to the poisson distribution is accurate , and we can model the @xmath13 s as independent normal@xmath22 random variables .    the statistical problem is to form an estimator @xmath23 of @xmath0 given observations @xmath13 . in the present context , @xmath23 is the template or coadd we are attempting to create . for each @xmath23",
    "we need ways to measure its misfit relative to the true scene @xmath0 . in this paper",
    "we consider two .",
    "the first criteria corresponds to flux conservation , which we measure through mean integrated squared error ( mise ) , and the second criteria we refer to as image quality .",
    "we give a brief description of these here .",
    "see section [ sec : methods ] for a more thorough discussion .",
    "flux conservation gives an indication about how well a method maintains the spatial location of a given amount flux .",
    "mean integrated squared error ( mise ) , which corresponds to the expected value of the integrated squared difference between any recovered image and the true image @xmath0 is the measure of flux conservation we use . specifically , suppose we form a template @xmath24 .",
    "then @xmath25 see @xcite for a thorough overview of mise .    while mise measures the degree to which @xmath23 maintains flux in the correct location , it does nt distinguish between different scatterings of the remaining misspecified flux .",
    "we define a second comparison , which we call image quality , that is designed to measure how spread out the source is , as this is nt captured by mise . for image quality",
    ", we do a very rough psf estimation on a source in the coadded image @xmath23 .",
    "the relative size of these psfs give us an indication about how spread out an object gets by the coaddition .",
    "[ fig : misesharpnesscomparison ] for an example of proceedures with combinations of good and bad mise and image quality .",
    "+    one significant complication in practice is that the psfs are unknown and must be estimated as part of the procedure . while it is ideal to simultaneously estimate the psf and @xmath0 , it is common , and typically effective , to first estimate the psf and then use the estimate as a known psf in the coaddition procedure . because our focus is on the relative performance of techniques for estimating @xmath0 , we will follow standard practices and assume that the psfs are known .",
    "this produces a comparison of the techniques at their best but does not account for how well the procedures tolerate mis - estimation of the kernels .",
    "note that the straightforward comparison methods do not require psf estimates .",
    "so , any method that does require knowledge of the psf would need to be substantially better , given it has access to much more information .",
    "in this section , we describe a variety of methods that have been applied to the coaddition problem , with particular focus on the fourier domain approach we are analyzing .",
    "note that we restrict our attention to non - iterative methods .",
    "_ lucky imaging_. in lucky imaging , a large number of images are observed and only the best, according to some criterion such as seeing , are retained .",
    "@xcite and @xcite describe such implementations in detail .",
    "an advantage of this approach is that the reconstruction of the true scene is based entirely on high quality data .",
    "a disadvantage is that the method requires storing many images to determine which are best .",
    "moreover , the images that are discarded can contain useful information about the scene that is , in effect , wasted .",
    "_ pixelwise statistics_. if a stack of images is aligned , the values at a particular pixel in each image represent a random sample from a common distribution .",
    "the aligned pixel stacks can thus be used to estimate the parameters of these distributions and in turn the true scene .",
    "basic choices would be a mean , median , or perhaps a trimmed mean to account for heavy - tailed noise , but more sophisticated estimators tailored to particular distributional assumptions can be constructed .",
    "the advantages of these approaches are computational and conceptual simplicity .",
    "moreover , the mean can be computed sequentially with a fixed amount of storage , although this is not true of the median or trimmed mean , for which the entire image stack needs to be maintained .",
    "a big disadvantage is that pixelwise methods tend to create rough , discontinuous images as no information sharing is permitted between pixels .",
    "_ fourier deconvolution_. in spatially constant seeing case is that equation ( [ eq : fredholm ] ) has a convolutional structure @xmath26 .",
    "the advantage of fourier based methods is that the operator @xmath5 decomposes nicely in the fourier domain .",
    "an inherent disadvantage to the fourier approach is that great care must be used to avoid outcomes such as fig .",
    "[ fig : fourierinvoperator ] .",
    "the approach outlined in @xcite is to fourier transform each image and estimate the @xmath27 fourier coefficient of @xmath0 by a weighted average of the @xmath27 fourier coefficient of each image .",
    "the weighting is accomplished so that the images with better seeing are weighted more heavily in the average .",
    "this method has some associated optimality properties .",
    "however , in practice , these properties turn out to not be useful .",
    "see below for a more thorough description .",
    "note that , as presented , this method makes three nontrivial assumptions .",
    "first , it assumes that each @xmath28 , that is , spatially constant seeing . as we describe in section",
    "[ sec : results ] , while this assumption could have significant consequences when seeing varies spatially , in practice , it does not appear to cause much problem .",
    "the second assumption is that the @xmath21 s are large enough that the gaussian approximation to the poisson is accurate across the image .",
    "the third assumption is that the variance of the gaussian is a _ known _",
    "value @xmath29 that depends only on the image @xmath4 .",
    "these last two assumptions make the analysis easier , and while they are often reasonable , they need not hold in practice .",
    "to define the fourier deconvolution estimator , first expand @xmath0 into the fourier basis , which we write as @xmath30 , @xmath31 in general , we use the notation @xmath32 for the fourier transform of the function @xmath33 .    using the above assumptions , and the resulting form of the @xmath21 s",
    ", @xcite proposes two estimators of @xmath34 .",
    "see table 1 for these estimators and some of their cumulants .",
    "the first estimator in the table , @xmath35 , has the smallest variance of all unbiased estimators of @xmath34 . also , the resulting estimator of @xmath0 , defined to be @xmath36 is the best linear unbiased estimator of @xmath0 .    .",
    "@xmath37 , which is the result of a variance stabilizing transformation .",
    "[ cols=\"<,^,<,<,^ , < \" , ]     however , as alluded to previously , these optimality properties are not useful . to see this ,",
    "observe that the variance of @xmath23 is the sum of the variances of @xmath38 .",
    "also , since the @xmath39 are smoothing operators , @xmath40 is small for large @xmath41 .",
    "in fact , the worse the seeing , the smaller @xmath40 becomes and can be smaller than machine error in many cases .",
    "hence , as @xmath42 $ ] depends on the reciprocal of @xmath43 , the variance of @xmath23 can be arbitrarily large .",
    "note that we have seen a case of this already in figure [ fig : fourierinvoperator ] where this large variance property causes unusable results .",
    "generally speaking , demanding unbiased estimators is less effective than choosing an estimator with some bias but smaller variance . in this case",
    ", the distinction is crucial because the unbiased estimator is unusable .",
    "for the interested reader , chapter 7 of @xcite provides a good introduction to this surprisingly broad and deep issue .",
    "see figure [ fig : fourierestimatoroptimal ] for an example of equation ( [ eq : unbiasedestimator ] ) in a simple simulated situation . the ability of @xmath24 to reconstruct even a simple @xmath0 decays rapidly as the full width at half maximum , or fwhm , of the psf increases .",
    "in particular , even the small amount of seeing ( fwhm of 1.1 pixels ) in the right most column makes the estimator unusable .",
    "@xmath44{./kaiseropt_conv_low.eps } &        \\includegraphics[width=2.0in]{./kaiseropt_conv_med.eps } &        \\includegraphics[width=2.0in]{./kaiseropt_conv_high.eps } \\\\        \\includegraphics[width=2.0in]{./kaiseropt_low.eps } &        \\includegraphics[width=2.0in]{./kaiseropt_med.eps } &        \\includegraphics[width=2.0in]{./kaiseropt_high.eps } \\\\",
    "\\end{array}$ ]    @xcite provides a correction that prevents the variance from exploding for large @xmath41 by multiplying @xmath45 by a term that is proportional to the reciprocal of its standard deviation .",
    "see the second row of table 1 .",
    "this multiplication biases the estimator but bounds the variance .",
    "we define @xmath46 and we spend the balance of the paper investigating its properties .",
    "we refer to @xmath47 as the fourier deconvolution ( fd ) method . as an aside ,",
    "since the correction corresponds to multiplication in fourier space , we see that the bias of @xmath47 is given by @xmath48 , where the fourier transform of @xmath49 is defined in the caption of table 1 and @xmath50 is the convolution of @xmath51 and @xmath52 .",
    "the computational complexity of the fd method is dominated by the need to fourier transform the data and kernel .",
    "if we suppose the images are @xmath53 by @xmath54 and @xmath55 , then we can perform a fourier transform in @xmath56 flops via the fast fourier transform .",
    "this is the dominating computation in the fd method .",
    "however , it also has several order @xmath57 computations .",
    "the mean method requires @xmath58 flops and the median method requires @xmath59 comparisons to update for each new image .    the fd method must maintain two @xmath59 pixel images and the mean method requires one @xmath59 pixel image , each of which get updated after each new image and kernel is recorded .",
    "the median method requires the entire stack must be maintained at all times , though not necessary in ram .",
    "hence , after @xmath3 images have been observed , all @xmath3 images must be kept for possible updating of the median .",
    "for our evaluation metrics , we need to know the true sky before any distortions . hence , we simulate an idealized view of the sky ( above the atmosphere ) using a catalog of point and extend sources .",
    "extended sources are represented by sersic profiles and the density of point and extended sources is designed to match observations to a depth of r@xmath6028 .",
    "figure [ fig : simulation ] shows a representation of one such image . from these true scenes , we apply a blurring operator @xmath1 and noise with variance @xmath61 to represent the effect of the atmosphere , telescope , and instrument .    under the assumptions of the fd method , we assume the psfs are convolutional ( by that we mean spatially constant seeing ) , but this leaves open the specific functional form for the kernel @xmath2 .",
    "we choose to set @xmath2 to be the two dimensional gaussian probability density function .",
    "our results are , however , robust against more complicated parametrization of @xmath2 ( e.g. , a mixture of gaussians ) .        for evaluating the effectiveness of the fd method , we compare it to the pixel - wise mean and pixel - wise median .",
    "our goal is to assess the value added by the fd method and evaluate whether the improved performance overcomes the added cost and complexity of the method .",
    "the mean and median procedures are intended as extreme comparisons rather than serious proposals and we are nt endorsing their use in this paper .",
    "however , if the value added of more sophisticated methods relative to even these simplistic methods is not great , then it suggests that simple methods may suffice in practice .",
    "note that the computational complexity of the methods is not a purely academic concern .",
    "in large imaging surveys such as the lsst , a near constant data stream requires efficient , near real - time processing , and the cost of generating template images is an important factor .    for this comparison",
    ", we use the two general criteria introduced in section [ sec : model ] corresponding to mise and image quality . in principle",
    ", at least two different errors can be made when comparing an estimated template @xmath23 to the true scene @xmath0 .",
    "these errors can most easily be thought of in the context of a point source such as a star .",
    "our estimated image can remove some of the flux from the point source and/or it can smooth the image ( degrading the photometric accuracy and the resolution of the resulting template ) .",
    "figure [ fig : misesharpnesscomparison ] shows examples of a pixelated point source that has been reconstructed by four made - up methods .    in the mise comparison",
    "we compute the expected value of the integrated squared difference between the true image and our estimate , assuming zero background . under the non - gaussian distributions , a larger variance results in more total flux in the image .",
    "this , in turn , results in a large mise . to compensate for this increase , and to make all the cases more directly comparable , we rescale the mise by the total signal of each image to compensate for this additional flux .    for the evaluation of image quality",
    "we fit a two dimensional , spherical gaussian density to a source using least squares .",
    "the covariance matrix of this fitted gaussian is then used as a metric for the width of the point source .",
    "in this section , we present the results of our simulations .",
    "the section is divided into two parts , corresponding to the two evaluation criteria outlined above .",
    "when looking at equation ( [ eq : fredholm ] ) we see two major influences on the quality of the observation .",
    "one is the type and severity of the seeing , determined by the psf @xmath2 .",
    "the other is the distribution of the noise @xmath62 . in this section ,",
    "we look at several different scenarios for comparing the mean or median to the fd method by changing these two factors .",
    "overall , we wish to understand the impact of seeing and noise on the performance of the methods . to do this ,",
    "we simulate a stack of images with each image having a fwhm drawn from a distribution with mean , @xmath63 .",
    "we do this procedure for @xmath63 ranging from 2 pixels to 7 pixels ( 0.4  to 1.4  ) .",
    "this interval is chosen so that it contains the expected seeing width for the lsst .",
    "this procedure creates a sequence of stacks of images .",
    "we apply this increasing fwhm to six different noise parameterizations . for both high variance ( 5:1 snr ) and low variance ( 20:1 snr )",
    "we have the noise term be distributed gaussian , heavy - tailed shot , and inhomogeneous poisson noise . in all six combinations",
    ", a lower mise indicates that the method conserved the flux better , on average",
    ". see figure [ fig : results ] for the results .    in all cases , the mean severity of seeing , @xmath63 , does not impact the ranking of the methods . in the gaussian case ,",
    "the methods are ranked , from best to worst , as fd , mean , and then median . in both the low and high noise cases ,",
    "absolute difference between the mean and the median is constant for all levels of @xmath63 due to the well - known efficiency gains of the mean over the median in the gaussian case .",
    "however , in the high noise case , the difference in mise between the fd and mean methods increases 11% as @xmath63 ranges from 2 to 7 pixels .",
    "as the fd method uses the additional information of a known seeing kernel , this non - constant difference is expected .    in the inhomogeneous poisson or heavy - tailed",
    "shot noise cases , the median outperforms both other methods .",
    "this owes to the particular and well known feature of the median to be more robust against heavier - tailed distributions . in the shot - noise case",
    ", the median ignores the random noise spikes with overwhelming probability and we get a noise free version of the true scene @xmath0 with the median amount of seeing . the very small advantage of the fd over the mean method owes to the fd s slightly narrower impulse response function , which we discuss in section [ sec : imagequality ] and figure [ fig : expectedirf ] . in the inhomogeneous poisson noise case ,",
    "the observed image is created by simulating independently from a poisson@xmath64 from equation ( [ eq : theta ] ) .",
    "this creates a very noisy image , especially near sources , and hence the median s ability to ignore large , transient spikes results in the large mise advantage .    under all three noise distributions",
    ", the fd method displays a small but increasing benefit in flux conservation over the mean as @xmath63 goes from 2 to 7 .",
    "it should be kept in mind that the fd method uses the known kernel assumption .",
    "hence , as the seeing becomes more severe this informational advantage should become more pronounced . in reality , the kernel would need to be estimated and this advantage would most likely decay .     +   +   +      to do this comparison we use an image where the function @xmath0 is a @xmath65-function ( i.e. a point source ) .",
    "we use the expected distribution of seeing at the lsst stack to draw 10 independent and identically distributed gaussian psfs and apply them to the point source .",
    "this mimics the forward process of an image getting blurred by the atmosphere and corresponds to operating on @xmath0 with @xmath5 for @xmath66 . for this stack of images",
    "we apply the three methods described earlier , fd , mean , and median , to derive a template image .",
    "we then fit a spherical gaussian kernel to the template via least squares and use the diagonal element of the covariance matrix as a measure of the width of the method s psf .",
    "we make 1000 draws from the seeing distribution and compute this statistic for each method and each draw .",
    "the results are summarized in figure [ fig : sharpnessboxplot ] with boxplots of the fwhm of the fitted gaussian kernel .",
    "boxplots are a graphical tool for quickly conveying the distribution of observed data and are composed of a ` box ' and ` whiskers . '",
    "the ` box ' is the main rectangle , which has horizontal lines , increasing with fwhm , at the 25th , 50th , and 75th percentiles of the data .",
    "the ` whiskers ' correspond to the dotted vertical lines with horizontal lines at the end and the plus signs .",
    "these horizontal lines are at the 1st and 99th percentile .",
    "the pluses are at extreme data points .",
    "the boxplots are very similar and show little difference in the fwhm of the fitted kernels .",
    "the fd method has longer ` whiskers ' than the other methods , indicating a wider range of fitted fwhm that can be expected .",
    "it also has a very slightly lower ` box ' than the other two methods , indicating that the majority of draws result in a slightly better fitted fwhm .",
    "for instance , the 50th percentile of the fd method s fitted fwhm is 1.2% lower then the mean method s fitted fwhm .",
    "interestingly , one of the draws resulted in six very good seeing images and four poor images .",
    "this resulted in the median method having the smallest fitted fwhm recorded for any method on any draw .",
    "this is part of a more general property of the median to behave non - continuously with the composition of the stack .",
    "for instance , if there were instead 4 very good seeing images and 6 poor seeing images , the result would be a large fitted fwhm .",
    "+      the mean and fd methods are very similar in that they are both based around summing the images and hence are both linear filters on the observed images .",
    "let s denote the estimated coadds of the two methods as @xmath67 and @xmath68 , respectively .",
    "we can understand the filtering that we are applying to the true image @xmath0 by considering @xmath69 $ ] and @xmath70 $ ] .",
    "note that these are @xmath71 = \\left ( \\frac{1}{l } \\sum_{i=1}^l k_i\\right)g = \\int k_{mean}(x - y ) g(y ) dy \\qquad \\textrm{and } \\qquad \\mathbb{e}[\\hat{g } _ { * } ] = \\int k^{*}(x - y)g(y)dy \\label{eq : maybe}\\ ] ] where the fourier transform of the function @xmath72 is defined in the caption under table 1 .    by examining the impulse response functions ( irfs ) of these filters we can find the average width of the psfs that will result from these methods .",
    "note that in this case this corresponds to the bias of each method .",
    "see figure [ fig : expectedirf ] for a one dimensional representation of the irfs of the expected filters .",
    "the mean irf and the fourier deconvolution irf are virtually identical and would create no visible difference in the image quality .     has more mass at lag = 0 , bear in mind that it uses a weighting scheme that depends on knowledge of both the true psfs and true variances .",
    "taking this into consideration , the difference is slight.,title=\"fig:\",width=384 ] +",
    "a variety of template generation / image coaddition techniques have been applied in current imaging surveys , including the cfhtls ( @xcite ; mean technique ) , panstarrs ( @xcite , mean technique ) , mopex for sirtf images ( @xcite , mean and median technique ) , and the virmos survey ( @xcite , median technique ) . in this paper , we address the broad question of whether sophisticated methods of template generation and image coaddition are worth the added cost and complexity , in the context of modern image surveys with large and nearly constant data streams . to this end , we compare fourier domain reconstruction techniques which have a variety of nice theoretical properties to straightforward pixelwise statistics .",
    "we consider two cost metrics to evaluate the image reconstructions ; image quality by way of the resulting gaussian fwhm of an image and the conservation of flux , measured by mise .    under the assumptions that motivate the fd method , namely gaussian noise and spatially constant seeing",
    ", the fd and mean methods both have lower mise than the median .",
    "however , in the heavy - tailed shot and inhomogeneous poisson noise cases , the median outperforms the fd method .    in situations when there is a small amount of seeing in an image stack , corresponding to @xmath73 pixels , we see the mean and fd methods have nearly the same mise properties ( less than 0.7% difference across all considered noise distributions ) .",
    "however , as the severity of the seeing increases , the disparity between the methods increases as well . as the fd method incorporates knowledge of the seeing kernel , this property is to be expected",
    "however , the mise for the high noise gaussian , shot , and inhomogeneous poisson cases are only 5.4% , 1.2% , and 0.13% lower , respectively , at the most severe levels of seeing .",
    "these benefits are rather small , particularly in the more realistic heavy - tailed and poisson noise cases .",
    "this is especially so considering the extra computational complexities involved in the fd method over the mean and median methods .    for comparing image quality of the templates",
    ", we find that the resolution of the resulting images is very similar as the 50th percentile of the fitted fwhm of the fd method is less than 2% smaller than the 50th percentile of the fitted fwhm of the mean method .",
    "we find that the value added by the fd method over the mean or median procedures does not overcome its added cost and complexity .",
    "this leads us to the conclusion that there is room for improvement over all three methods .",
    "we are currently exploring various possible improvements and theoretical justifications for some of the approaches outlined in this paper .",
    "beckwith , steven et al .",
    ", 2006 , , 132 , 5 , pg .",
    "1729 fried , d.l .",
    ", 1978 , j. optical soc .",
    "amer , 86 , pgs .",
    "1651 - 1657 gwyn , s. d. j. , 2008 , , feb .",
    ", 120 , pgs .",
    "212 - 223 hu , yuchng et al . , 2007 , physics letters a , 367 , pgs .",
    "173 - 176 kaiser , nick , 2004 , private communication mokovoz , d. et al .",
    ", 2005 , astronomical data analysis software and systems xiv , 347 , dec , pg",
    ". 81 parker , laura et al .",
    ", 2007 , , 669 , 1 , pg .",
    "21 price , p.a and pan - starrs team , bulletin of the american astronomical society , 38 , may , pg .",
    "183 radovich m. et al . , 2004 , ,",
    "apr . , 417 , pgs . 51 - 60 scully , marlan et al . , 1969 ,",
    "physics review .",
    "179 , pgs .",
    "368 - 374 silverman , brian , 1985 , chapman & hall / crc , monographs on statistics and applied probability , vol 26 tubbs , r.n . , 2003 , phd thesis , cambridge univ wasserman , larry , 2006 , chapter 7 , springer science"
  ],
  "abstract_text": [
    "<S> large , multi - frequency imaging surveys , such as the large synaptic survey telescope ( lsst ) , need to do near - real time analysis of very large datasets . </S>",
    "<S> this raises a host of statistical and computational problems where standard methods do not work . in this paper </S>",
    "<S> , we study a proposed method for combining stacks of images into a single summary image , sometimes referred to as a template . </S>",
    "<S> this task is commonly referred to as image coaddition . in part , we focus on a method proposed in @xcite , which outlines a procedure for combining stacks of images in an online fashion in the fourier domain . </S>",
    "<S> we evaluate this method by comparing it to two straightforward methods through the use of various criteria and simulations . </S>",
    "<S> note that the goal is not to propose these comparison methods for use in their own right , but to ensure that additional complexity also provides substantially improved performance . </S>"
  ]
}