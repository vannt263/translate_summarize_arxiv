{
  "article_text": [
    "the idea of using cluster surveys as probes of dark energy has generated considerable interest of late @xcite . as the largest virialized objects in the universe , it is thought that clusters may be less affected by unknown or poorly understood astrophysical mechanisms and it is hoped that it will be reasonably straightforward to compare observed catalogs with theoretical estimates .",
    "while many recent works have investigated the power of upcoming surveys and the challenges due to poorly understood selection effects , there has been relatively less attention in the literature to methods of analysis .",
    "it has been generally assumed that the problem can be separated into analyzing the differential number counts as a function of redshift and investigating the correlations ( either angular or three - dimensional ) in the cluster catalog .",
    "studies of galaxy surveys have traditionally used either the power spectrum or @xmath2 point correlation functions to construct likelihood estimates , and most studies of the galaxy cluster abundance have assumed poisson statistics .",
    "however , it has been recently emphasized that poisson statistics for galaxy cluster surveys may not be a particularly good assumption @xcite .",
    "the importance of sample variance considerations is two - fold .",
    "it broadens the probability distribution of the counts in cells , weakening constraints on the true number density , and the amount of this broadening is in principle directly calculable from theory , adding new information which in principle can be used to tighten constraints . as will be shown below",
    ", the effect of sample variance on cluster counts is not negligible and treating the counts as a poisson process is incorrect .    in this work",
    ", we will go back to the work of @xcite in galaxy clustering and update it to the context of galaxy cluster studies .",
    "in particular , we will derive the correct likelihood function to use for binned estimates of the cluster number counts and we write down an explicit expression for the likelihood of observing a particular galaxy cluster catalog as a function of theoretical models for the correlation structure of the density field .",
    "we will present some very preliminary tests using the catalogs from the hubble volume simulation , demonstrating the regimes where these methods are robust and where more work clearly needs to be done .",
    "we adopt the formalism of dodelson , hui , & jaffe ( 1997 ; hereafter dhj97 ) , which in turn closely follows the development of white ( 1979 ; hereafter w79 ) .",
    "all that follows below is clearly outlined in w79 and the interested reader is referred to that paper for a full exposition .",
    "the fundamental assumption is that the probability of observing an object at a particular location ( in the absence of any other knowledge ) is simply proportional to the number density of objects : @xmath3 where @xmath2 is the number density , @xmath4 is the survey weight at that point ( the probability of detecting an object if it was at that point ) , and @xmath5 is an infinitesimal volume around the position @xmath6 .    by similar reasoning , the probability of observing two objects at two points in space @xmath6 and @xmath7 can be expressed as @xmath8 dv_1   dv_2 \\end{aligned}\\ ] ] where @xmath9 is the two - point correlation function , indicating the excess probability ( over random ) of detecting two objects at the given positions .",
    "this reasoning can be extended to three objects : @xmath10 dv_1   dv_2 dv_3 \\nonumber\\end{aligned}\\ ] ] with @xmath11 the three - point correlation function , and the sum refers to summing over all unique @xmath12 .",
    "obviously this can continue to even longer lists of objects .",
    "a given catalog will contain @xmath13 objects , and the probability of detecting those @xmath13 objects at those positions can be constructed from the hierarchy of correlation functions , but a very useful component of the catalog is that _ there are no objects detected at other points . _",
    "a quantity of interest is therefore the probability of detecting @xmath13 objects at observed @xmath14 and no other objects at the other positions .",
    "a recipe for incorporating this extra information was described in w79 . instead of using the functions @xmath15 that were used above",
    ", one can simply replace each occurrence of @xmath15 with @xmath16 , where this latter quantity is simply @xmath17    it is nice to have an exact likelihood formulation for a given catalog , but a hierarchy of infinite sums can be a bit unwieldy .",
    "dhj97 noted that for galaxy surveys there can easily be collections on the order of @xmath18 terms , even in the limit of gaussianity and weak correlations .",
    "it will be shown below that galaxy cluster surveys the number of terms is quite manageable , at least in the limit of the cluster distribution being gaussian and for a reasonably sparse survey .",
    "cluster surveys can effectively be considered as perturbatively different from a poisson distribution , allowing the probability distributions to be calculated quite efficiently .    in the gaussian limit ,",
    "it is useful to consider a few @xmath16 : @xmath19 where @xmath20 is the survey volume and the @xmath21 have all been set to unity for simplicity .",
    "note that this is not a requirement and is a straightforward way to include survey non - uniformity .",
    "this allows an expression to be written down for observing a collection of points as a function of a theory which predicts the number density and two - point correlation function .",
    "to first order in the two - point function ( dhj97 ) , @xmath22 \\nonumber\\end{aligned}\\ ] ]    in the limit of sample variance being negligible ( i.e. , in the limit where @xmath16 approaches @xmath15 ) , this approaches the likelihood one would expect for the number counts ( the first term and the first term in brackets approaches the poisson expression ) combined independently with the correlation function .",
    "the second term in brackets closely resembles the likelihood one would obtain for the correlation function assuming that the probability of observing a pair at a given pair of locations is a poisson process with mean given by @xmath23 . when sample variance is not negligible",
    ", however , the probability will not be cleanly separable .",
    "furthermore , the same formalism was used by w79 to write down a compact expression for the counts - in - cells probability : @xmath24 = { ( -nv)^n \\over n ! } { d^n \\over dn^n } exp[w_0(v ) ] \\label{eqn : p_phi}\\end{aligned}\\ ] ] where @xmath25 indicates observing @xmath13 objects ( and only @xmath13 ) in a volume @xmath20 .    again , assuming weak correlations and working in the gaussian limit , the counts in cells probability can be derived .",
    "some details are derived in the appendix , but the result is straightforward .",
    "the probability of observing @xmath13 objects in a volume @xmath20 ( to first order in the clustering ) is @xmath26 = { x^n e^{-x } \\over n!}\\bigl[1- n^2 v^2 { \\bar{w } \\over 2}\\bigl (   { n - n^2 \\over x^2 } + 2{n \\over x } -1 \\bigr)\\bigr ] \\label{eqn : countsprob}\\ ] ] where @xmath13 is again the observed number , @xmath27 , and @xmath28 is the mean correlation function over the survey geometry . in calculations in this paper",
    "we use the second order expression to generate the figures , but a careful analysis of terms indicates that if the second order term is important then there is a good chance that all higher order terms must be included .    where might this expression be expected to break down ?",
    "in w79 it is clear that @xmath29 starts to become a challenging series when @xmath30 becomes of order 0.1 or higher .",
    "we should therefore expect that this likelihood calculation will be most effective in that case and that it is suspect outside that regime .",
    "the breakdown appears to arise because the assumption of gaussianity must always break down : the density field can not be negative . with sparse sampling",
    "the probability of encountering a negative density is negligible and the assumption of gaussianity is sufficient .",
    "however , at higher number densities the intrinsic non - gaussianity becomes important .",
    "notice that this approach is straightforward to extend to objects that are tagged with an observable such as flux or richness .",
    "going back to eqn [ eqn : catprob ] , it should be sufficient to replace the initial number density with a sum over the individual number densities in each observable bin ( e.g. , theoretical number density as a function of optical richness or sz flux ) , and then keep in mind that each @xmath16 will depend on the mass of the object or pairs of object under consideration .",
    "the efficacy of this technique is currently a topic of investigation .",
    "we use the cluster catalogs derived from the hubble volume simulations @xcite to test the range of validity of the likelihood expression derived for the counts in cells .",
    "a straightforward test is to use the @xmath1 cluster catalogs , where evolution effects can be neglected .",
    "we further specialize to the @xmath31 simulation , where the transfer function is easy to reproduce .",
    "the simulation parameters are @xmath32 and @xmath33 and a box size of @xmath34 .",
    "the volume is divided into subregions of cubic geometry and the above expressions are tested for a variety of cell sizes and mass thresholds . the number of clusters within each cell is then used to construct the probability distribution of the counts in cells .",
    "mass thresholds were used to construct counts in cells for all objects above a threshold mass , with the mass defined as the number of particles ( each of mass @xmath35 ) found by the friends of friends algorithm with a linking parameter of 0.2 .",
    "the mean correlation function of the matter distribution was derived as @xmath36 where @xmath37 is the window function for the cells ( not related to the @xmath16 above ! ) . for cubic cells ,",
    "the window function is simply a product of @xmath38 functions .",
    "the mean correlation function of the galaxy clusters needs to be corrected for the bias function .",
    "this is non - trivial ; several fitting functions exist in the literature but typical errors appear to be on the order of 10% when applied in a regime where they have not been calibrated @xcite .",
    "we use the bias relation of @xcite with the mean bias for the cluster sample above a mass threshold derived using a mass function weighted bias factor .",
    "the mass function of @xcite was used , which has been calibrated using the simulation used here . in principle , given a mass correlation function one can estimate the bias as a function of an observable cluster property and use this to estimate the cluster mass as a function of cluster properties . however , current uncertainty in the theoretical understanding of bias as a function of mass in arbitrary cosmologies complicates any such undertaking .",
    "an example is shown in figure 1 . taking a relatively high threshold of @xmath39 and a cell size of 154 @xmath40mpc ,",
    "the counts in cells distribution can be synthesized .",
    "we average over ten random cell offsets to smooth the observed distribution and compare it to the exact calculation of eqn [ eqn : countsprob ] . in the limit of massive ( and therefore rare and sparse ) clusters the likelihood for the counts in cells is quite accurate .",
    "the assumption of a gaussian random field will break down when @xmath41 is of order @xmath42 ( w79 ) . to investigate the nature of the breakdown , we show in figure 2 the first breakdown for cells of size 100 mpc and 133 mpc . at higher masses ( i.e. , lower number densities )",
    "the theoretical result matches the simulations quite well .",
    "it is clear that there is noticeable deviation starting around @xmath43 .",
    "the mass thresholds were selected to straddle the transition . at yet lower masses , the theoretical result breaks down fairly comprehensively , developing bimodality .",
    "this is an indication that the theory is simply not well defined in this regime .",
    "it is impossible to set up a distribution of positive mass concentrations with vanishing correlation functions above the two - point function .",
    "as the mass threshold is lowered , clusters become more numerous . as the cell size decreases , the mean number per cell will decrease but the mean correlation function over the cell volume will increase . for reasonable power spectra it turns out that the number per cell is slightly more important in this case for the purposes of calculating @xmath41 , making it slightly advantageous to move to smaller cell sizes .    to investigate the regime where this likelihood approach can be trusted , a grid of masses and cell sizes was investigated .",
    "the quantity @xmath41 was calculated and the lines in figure 3 indicate the locus of pairs of @xmath44 and cell size that lead to @xmath45 . for a @xmath46 model with @xmath47",
    "the likelihood approximation breaks down below @xmath48 , with the @xmath31 breaking down around the same mass .",
    "however , this is a very steep function of the amplitude of the power spectrum .",
    "for example , using @xmath49 drops the threshold of applicability to below @xmath50 .",
    "this is particularly relevant because this corresponds to the amplitude of fluctuations at @xmath51 if @xmath47 .",
    "any survey for galaxy clusters at @xmath52 and targeting masses above a few @xmath53 is squarely is the regime where this likelihood calculation can be used .",
    "the preliminary ( and very highly idealized ) tests outlined above demonstrate that many cluster surveys can be considered to be in the regime where catalog likelihood methods will be readily applicable .",
    "tests on counts in cells at @xmath1 indicate that the non - gaussianity of the cluster distribution becomes important around masses of several times @xmath54 .",
    "applications of the cluster catalog likelihood ( eqn [ eqn : catprob ] ) will likely have similar problems at lower masses and may also have difficulties at small separations .",
    "this is a topic of ongoing investigation .",
    "the tests performed in this work used a @xmath1 simulation snapshot , rather than a lightcone selected volume .",
    "this was done to cleanly separate the possible complications and there is no conceptual problem with generalizing this to include redshift evolution .",
    "in fact , to generalize this one simply goes back to eqn [ eqn : countsprob ] and allows @xmath55 to be functions of @xmath56 and cosmological parameters , including the evolution of the relevant window functions .",
    "non - cubic cell volumes that are functions of cosmological parameters and redshift will certainly complicate the analysis , but all the results presented here should be directly applicable .",
    "there are several directions for more work in this area .",
    "tests on existing cluster catalogs will yield insight into exactly how hard it is to implement these ideas in practice .",
    "one of the lessons learned is that this method works best on sparse catalogs ( i.e. , massive clusters ) , so in existing data it would be most easily tested on the most massive x - ray cluster surveys .",
    "it is unfortunate that the method appears to break down in a regime where there are high quality local cluster surveys .    on the theoretical side ,",
    "an obvious next step is to apply these methods using clusters that have been additionally tagged with an observable such as x - ray or sz flux or optical richness . within this formalism",
    "such a modification is entirely straightforward , as all that is required are number densities and correlation strengths .",
    "incorporating scatter in something like a mass - observable relation would be in principle straightforward , as would allowing for non - trivial ( non power - law ) evolution in such relations .",
    "however , uncertainty in the bias relations as a function of cosmology and mass must be improved to realize the full potential of these methods .",
    "given that the breakdown in this formalism appears to coincide with the onset of non - linearity , it may be possible to extend these results to lower masses with some modelling of the effects of weak non - linearity .",
    "the excellent match between theory and simulations at higher masses demonstrates that non - linearity and non - gaussianity are not important in the high - mass regime .",
    "in this paper we outlined a likelihood approach to galaxy cluster surveys that is uniquely applicable to the case of massive galaxy clusters .",
    "essentially , for small enough sample and/or weak enough clustering strengths one can treat cluster catalogs as being expected to be drawn from a distribution that can be thought of as a poisson distribution with some perturbations . by virtue of being only perturbatively different from a poisson process , cluster catalogs lend themselves well to efficient likelihood estimation techniques that naturally include both shot noise and sample variance .",
    "this does not require an arbitrary conceptual breaking of the problem into `` counts '' and `` clustering '' but instead simply addresses the question of how likely it is to obtain a set of points given an assumed underlying correlation structure .    for galaxies ,",
    "the number of terms involved in the estimate is prohibitive , and it is also important to understand the higher order correlations .",
    "that does not appear to be the case for massive galaxy clusters .",
    "the gaussian weak correlation limit does a very good job of matching the counts in cells distribution for massive clusters in the hubble volume simulation . as the mass threshold is lower , and the number density therefore increases ,",
    "some disagreement arises , likely due to the number density becoming high enough that the distribution becomes sensitive to non - gaussianity .",
    "it should be emphasized that it is clearly not an advantage to have fewer clusters .",
    "one could always thin the number density of a sample until the catalog is in a regime where a catalog likelihood can be calculated .",
    "this would obviously be throwing away a huge amount of information and it seems unlikely that the gain in simplicity would be worth the loss of information .",
    "these techniques are straightforward to generalize to explicitly include inhomogeneous survey selection and differential number densities and clustering strengths as a function of galaxy cluster properties .    with galaxy cluster surveys now being used for cosmological parameter estimation",
    ", it is essential to include the effects of sample variance to obtain accurate parameter estimates , so obtaining accurate probability distributions for counts in cells should be a high priority .",
    "the techniques here are a step in that direction , showing that such accurate distributions are easily calculated for massive galaxy clusters .    as this article neared completion , an article appeared by hu & cohn discussing very similar ideas from a slightly different perspective .",
    "the results here largely agree with theirs in the aspects where they overlap .",
    "the calculation of the likelihood for counts in cells can be derived from equation [ eqn : p_phi ] with straightforward algebra and accounting in the limit of weak clustering .",
    "some of the details are spelled out below .",
    "define @xmath57 and using @xmath58 , the first step is to expand the exponential term as a taylor series . for convenience , define @xmath59 and the counts in cells probability distribution can be written      expanding the part inside the sum with the binomial expansion gives @xmath26 =   { ( -x)^n \\over n ! } { d^n \\over dx^n}\\left (   \\sum_{i=0}^{\\infty }   \\sum_{k=0}^{i }   { 1 \\over k ! ( i - k ) ! } ( -x)^{i+k } \\alpha ^k \\right)\\ ] ]    the effect of the derivatives is that all terms in the sums with @xmath60 are set to zero and all other terms are multiplied by @xmath61 : @xmath26 =   { ( -x)^n \\over n ! } \\left ( \\sum_{i=0}^{\\infty } \\sum_{k = max(0,n - i)}^{i }   ( -1)^n { ( i+k ) ! \\over k ! ( i - k ) ! ( i+k - n ) ! } \\alpha ^k ( -x)^{i+k - n }   \\right)\\ ] ]    up to this point , the only assumption implicit in this analysis is that the correlation functions beyond the two - point function are negligible . to see the structure in the probability distribution",
    ", we now assume that @xmath62 is small and investigate the relevant terms in the above equation . in particular , for small @xmath62 the only important terms will be terms with small @xmath63",
    ". this immediately identifies the important terms as being the ones with @xmath64 close to @xmath13 .",
    "to first order in @xmath62 , one can move to one lower value of @xmath64 : @xmath67 and to second order in @xmath62 we can continue down : @xmath68 with subsequent orders obtained similarly .",
    "these sums are straightforward to implement using software such as maple but can become tedious . in all that was implemented in this work the series",
    "was truncated at second order .",
    "the sums have an interesting property that each term seems to be of order @xmath69 , since @xmath13 is of the same order as @xmath70 . at each level",
    "the terms are actually of lower order in @xmath70 due to cancellations in the sums .",
    "for example , for @xmath71 the expression in brackets in equation [ eqn : secondorder ] reduces to @xmath72 , making this term roughly @xmath73 .",
    "nonetheless , it is clear that simply having small @xmath62 is not sufficient .",
    "for this formalism to be useful it is required that @xmath74 be small , at least , and it is preferable that @xmath75 be small to be sure that all higher order terms are negligible .",
    "it is apparent from the expression for @xmath29 that bad things are happening as @xmath74 is becoming large , since it is becoming dubious that the void probability function is bounded to be less than one ( i.e. , @xmath29 must be negative ) .",
    "this is likely a breakdown of the physical picture of poisson sampling of a gaussian random field , rather than a breakdown of any approximations .",
    "it is impossible to poisson sample with a negative mean , which a gaussian random field allows .",
    "the requirement that the density is non - negative necessitates some amount of non - gaussianity . with enough samples ,",
    "this non - gaussianity must manifest itself in the observed distribution ."
  ],
  "abstract_text": [
    "<S> galaxy cluster surveys offer great promise for measuring cosmological parameters , but survey analysis methods have not been widely studied . using methods developed decades ago for galaxy clustering studies </S>",
    "<S> , it is shown that nearly exact likelihood functions can be written down for galaxy cluster surveys . </S>",
    "<S> the sparse sampling of the density field by galaxy clusters allows simplifications that are not possible for galaxy surveys . </S>",
    "<S> an application to counts in cells is explicitly tested using cluster catalogs from numerical simulations and it is found that the calculated probability distributions are very accurate at masses above several times @xmath0 at @xmath1 and lower masses at higher redshift . </S>"
  ]
}