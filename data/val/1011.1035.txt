{
  "article_text": [
    "pose estimation is a fundamental component of many computer vision applications , ranging from robotic vision to intelligent image analysis . in general ,",
    "pose estimation refers to the process of obtaining the location and orientation of an object .",
    "however , the accuracy and nature of the pose estimate required varies from application to application .",
    "certain applications require the estimation of the full 3d pose of an object , while other applications require only a subset of the pose parameters .",
    "the 2d-3d registration problem in particular is concerned with estimating the pose parameters that describe a 3d object model within a given 2d scene .",
    "an image / photograph of a known object can be analysed in greater detail if a 3d model of the object can be registered over it , to be used as a ground truth . as an example , consider the case of automatically analysing a damaged car using a photograph .",
    "the focus of this work is to develop a method to estimate the pose of a known 3d object model in a given 2d image , with an emphasis on estimating the pose of cars .",
    "we have the following objectives in mind .",
    "* use only a single , static image limited to a single view * work with any unknown camera ( without prior camera calibration ) * avoid user interaction * avoid prior training / learning * work under varying and unknown lighting conditions * estimate the full 3d pose of the object ( not a partial pose as in an overhead view of traffic or machine parts along a conveyor belt )    a 3d pose estimation method with these properties would also be useful in remote sensing , automated scene recognition and computer graphics , as it allows for additional information to be extracted without the need for human involvement .",
    "many methods , including point correspondence based methods , implicit shape model based methods and image gradient based methods , have been developed to solve the pose estimation problem .",
    "however , the methods identified in the literature do not satisfy the objectives mentioned above , hence the necessity of our novel method .",
    "a more detailed review of existing pose estimation methods ranging over the past 30 years is presented in section  [ secrelatedwork ] .",
    "this paper presents a method which registers a known 3d model onto a given 2d photo containing the modelled object while satisfying the objectives outlined above .",
    "it does this by measuring the closeness of the projected 3d model to the 2d photo on a pixel ( rather than feature ) basis .",
    "background and unknown lighting conditions of the photo are major complications , which prevent using a naive image difference like the absolute or square loss as a measure of fit .    a major contribution of this paper is the novel `` distance '' measure in section  [ secmatching3dto2d ] that does neither depend on the lighting of the real scene in the photo nor on choosing an appropriate lighting in the rendering of the 3d model , hence does not require knowledge of the lighting .",
    "technically , we derive in section  [ seclossfunction ] a loss function for vector - valued pixel attributes ( of different modality ) that is invariant under linear transformations of the attributes .    to analyse the nature of the developed loss function , we have applied it to a series of test cases of varying complexity , as detailed in section [ seclosslandscape ] .",
    "these test cases indicate that for our target application the loss function is well behaved and can be optimised using a standard optimisation method to find an accurate pose match .",
    "as presented in section [ secoptim ] , we achieve good pose recovery results in both artificial and real world test cases using this optimisation scheme . in these optimisation tests , negative influence of the background is attenuated by clipping the photo to the projection of the 3d model when calculating the loss .",
    "technical aspects of the optimisation and loss calculation methods are discussed in section [ sectech ] .",
    "model based object recognition has received considerable attention in computer vision circles .",
    "a survey by chin and dyer @xcite shows that model based object recognition algorithms generally fall into 3 categories , based on the type of object representation used - namely 2d representations , 2.5d representations or 3d representations .",
    "representations store the information of a particular 2d view of an object ( a characteristic view ) as a model and use this information to identify the object from a 2d image .",
    "global feature methods have been used by gleason and algin @xcite to identify objects like spanners and nuts on a conveyor belt .",
    "such methods use features such as the area , perimeter , number of holes visible and other global features to model the object . structural features like boundary segments have been used by perkins @xcite to detect machine parts using 2d models .",
    "a relational graph method has been used by yachida and tsuji @xcite to match objects to a 2d model using graph matching techniques .",
    "these 2d representation - based algorithms require prior training of the system using a ` show by example ' method .",
    "approaches are also viewer centred , where the object is known to occur in a particular view .",
    "they differ from the 2d approach as the model stores additional information such as intrinsic image parameters and surface - orientation maps .",
    "the work done by poje and delp @xcite explain the use of intrinsic scene parameters in the form of range ( depth ) maps and needle ( local surface orientation ) maps .",
    "shape from shading @xcite and photometric stereo @xcite are some other examples of the use of the 2.5d approach used for the recognition of industrial parts .",
    "a range of techniques for such 2d/2.5d representations are described by forsythe and ponce @xcite , by posing the object recognition problem as a correspondence problem .",
    "these methods obtain a hypothesis based on the correspondences of a few matching points in the image and the model .",
    "the hypothesis is validated against the remaining known points .",
    "approaches are utilised in situations where the object of interest can appear in a scene from multiple viewing angles .",
    "common 3d representation approaches can be either an ` exact representation ' or a ` multi - view feature representation ' .",
    "the latter method uses a composite model consisting of 2d/2.5d models for a limited set of views .",
    "multi - view feature representation is used along with the concept of generalised cylinders by brooks and binford @xcite to detect different types of industrial motors in the so called acronym system .",
    "the models used in the exact representation method , on the contrary , contain an exact representation of the complete 3d object .",
    "hence a 2d projection of the object can be created for any desired view .",
    "unfortunately , this method is often considered too costly in terms of processing time .",
    "the 2d and 2.5d representations are insufficient for general purpose applications .",
    "for example , a vehicle may be photographed from an arbitrary view in order to indicate the damaged parts .",
    "similarly , the 3d multi - view feature representation is also not suitable , as we are not able to limit the pose of the vehicle to a small finite set of views .",
    "therefore , pose identification has to be done using an exact 3d model .",
    "little work has been done to date on identifying the pose of an exact 3d model from a single 2d image .",
    "huttenlocher and ullman @xcite use a 3d model that contains the locations of edges .",
    "the edges / contours identified in the 2d image are matched against the edges in the 3d model to calculate the pose of the object .",
    "the method has been implemented for simple 3d objects . however",
    ", this method will not work well on objects with rounded surfaces without clearly identifiable edges .",
    "recent work by arie - nachimson and ronen basri @xcite makes use of ` implicit shape models ' to recognise 3d objects from 2d images .",
    "the model consists of a set of learned features , their 3d locations and the views in which they are visible .",
    "the learning process is further refined using factorisation methods .",
    "the pose estimation consists of evaluating the transformations of the features that give the best match .",
    "a typical model requires around 65 images to be trained .",
    "there are many different types of cars in use and new car models are manufactured quite frequently . therefore , any methodology that requires training car models would be laborious and time consuming .",
    "hence , a system that does not require such training is preferred for the problem at hand .",
    "gray scale image gradients have been used to estimate the 3d pose in traffic video footage from a stationary camera by kollnig and nagel @xcite .",
    "the method compares image gradients instead of simple edge segments , for better performance .",
    "image gradients from projected polyhedral models are compared against image gradients in video images .",
    "the pose is formulated using 3 degrees of freedom ; 2 for position and 1 for angular orientation .",
    "tan and baker @xcite use image gradients and a hough transform based algorithm for estimating vehicle pose in traffic scenes , once more describing the pose via 3 degrees of freedom . pose estimation using 3 degrees of freedom is adequate for traffic image sequences , where the camera position remains fixed with respect to the ground plane .",
    "this approach does not provide a full pose estimate required for a general purpose application .",
    "work done by @xcite and later by @xcite attempt to simultaneously solve the pose and point correspondence problems .",
    "the success of these methods are affected by the quality of the features extracted from the object , which is non - trivial with objects like cars .",
    "our method on the contrary , does not depend on feature extraction .",
    "can be used to represent a distance between two data sets , and hence give a measure of their similarity .",
    "therefore , distance metrics can be used to measure similarity between different 2d images , as well as 2d images and projections of a 3d model . a basic distance",
    "metric would be the _ euclidian distance _ or the 2-norm @xmath0 .",
    "however , this has the disadvantage of being dependant on the scale of measurement .",
    "the _ mahalanobis distance _ on the other hand , is a scale - invariant distance measure .",
    "it is defined as ||x - y||_c^-1 for random vectors @xmath1 and @xmath2 with a covariance matrix of @xmath3 .",
    "the mahalanobis distance will reduce to the euclidean distance when the covariance matrix is the identity matrix ( @xmath4 ) .",
    "the mahalanobis distance is used by xing et al .",
    "@xcite for clustering .",
    "it is also used by deriche and faugeras @xcite to match line segments in a sequence of time varying images .",
    "we describe our approach of matching 3d models to 2d photos in this section using a novel illumination - invariant loss function .",
    "a detailed derivation of the loss is provided in section  [ seclossfunction ] .",
    "assume we want to match a 3d model ( @xmath5 ) to a 2d photo ( @xmath6 ) or vice versa .",
    "more precisely , we have a 3d model ( e.g.  as a triangulated textured surface ) and we want to find a projection @xmath7 for which the rendered 2d image @xmath8 has the same perspective as the 2d photo @xmath6 .",
    "as long as we do not know the lighting conditions of @xmath6 , we can not expect @xmath6 to be close to @xmath8 , even for the correct @xmath7 .",
    "indeed , if the light in @xmath6 came from the right , but the light shines on @xmath5 from the left , @xmath8 may be close to the negative of @xmath6 .",
    "formally , let @xmath9 be the set of @xmath10 ( integer ) pixel coordinates , and @xmath11 be a pixel coordinate .",
    "alternatively a smaller region of interest may be used for @xmath12 instead of @xmath13 as explained in section  [ clipbg ] .",
    "let @xmath14 be a photo with @xmath15 real pixel attributes , and @xmath16 a projection of a 3d object to a 2d image with @xmath17 real pixel attributes .",
    "the attributes may be colours , local texture features , surface normals , or else . in the following",
    "we consider the case of grey - level photos ( @xmath18 ) , and for reasons that will become clear , use surface normals and brightness @xmath19 of the ( projected ) 3d model .",
    "a simple lambertian reflection model is not realistic enough to result in a zero loss on real photos , even at the correct pose .",
    "nevertheless ( we believe and experimentally confirm that ) it results in a minimum at the correct pose , which is sufficient for matching purposes .",
    "we use phong shading without specular reflection for this purpose @xcite .",
    "let @xmath20 be the global ambient / diffuse light intensities of the 3d scene , and @xmath21 be the ( global ) unit vector in the direction of the light source ( or their weighted sum in case of multiple sources ) . for reasons to become clear later",
    ", we introduce an extra illumination offset @xmath22 ( which is 0 in the phong model ) . for each surface point @xmath23 , let @xmath24 be the ambient / diffuse reflection constants ( intrinsic surface brightness ) and @xmath25 be the unit ( interpolated ) surface `` normal '' vector",
    ". then the apparent intensity @xmath26 of the corresponding point @xmath23 in the projection @xmath27 is @xcite i(p ) = k_a(p ) i_a + k_d(p)(^v(p))i_d + i_0 am_(p ) + b the last expression is the same as the first , just written in a more covariant form : @xmath28 are the known surface ( dependent ) parameters , and @xmath29 are the four ( unknown ) global illumination constants , and @xmath30 .",
    "since @xmath31 is linear in @xmath32 and @xmath33 , any rendering is a simple global linear function of @xmath27 .",
    "this model remains exact even for multiple light sources and can easily be generalised to color models and color photos .",
    "we measure the closeness of the projected 3d model @xmath34 to the 2d photo @xmath6 by some distance @xmath35 , e.g.  square or absolute or mahalanobis .",
    "we do not want to assume any extra knowledge like the lighting conditions @xmath32 under which the photo has been taken , which rules out a direct use of @xmath36 .",
    "ideally we want a `` distance '' between @xmath6 and @xmath5 that is independent of @xmath32 and is zero if and only if there exists a lighting condition @xmath32 such that @xmath6 and @xmath37 coincide .",
    "indeed , this is possible , if ( rather than defining @xmath8 as some @xmath32-dependent rendered projection of @xmath5 ) we use @xmath32-independent brightness and normals @xmath34 as pixel features as defined above , and define a linearly invariant distance as follows : let |f : = _ pp f(p ) |m_:=_pp m_(p)^4 be the average attribute values of photo and projection , and c_f m _ : = 1|p|_pp(f(p)-|f)(m_(p)-|m_)^^14 be the cross - covariance matrix between @xmath6 and @xmath34 and similarly @xmath38 and the covariance matrices @xmath39 and @xmath40 . with this notation",
    "we can define the following distance or loss function between @xmath6 and @xmath34 : [ deflil ] ( ) : = \\{n , m } - obviously this expression is independent of @xmath32 . in the next section",
    "we show that it is invariant under regular linear transformation of the pixel / attribute values of @xmath6 and @xmath8 and zero if and only if there is a perfect linear transformation of the pixel values from @xmath8 to @xmath6 .",
    "this makes it unnecessary to know the exact surface reflection constants of the object ( @xmath24 )",
    ". we will actually derive ( ) = d_(f , am_+b ) this implies that @xmath41 is zero if and only if there is a lighting @xmath32 under which @xmath6 and @xmath34 coincide , which we desired .",
    "a detailed derivation of the loss function is given in this section .",
    "although together with section [ secmatching3dto2d ] , this is a main novel contribution of this paper , it may be skipped over by the more application - oriented reader without affecting the continuity of the rest of the paper .",
    "using the notation of the previous section , we measure the similarity of photo @xmath14 and projected 3d model @xmath16 ( returning to general @xmath42 ) by some loss : [ defloss ] ( ) : = d(f , m _ ) : = 1|p| d(f(p),m_(p ) ) where @xmath43 is a distance measure between corresponding pixels of the two images to be determined below .",
    "a very simple , but as discussed in section [ secrelatedwork ] for our purpose unsuitable , choice in case of @xmath44 would be the square loss @xmath45 .",
    "it is convenient to introduce the following probability notation : let @xmath46 be uniformly distributed in @xmath12 , i.e.  @xmath47=|p|^{-1}$ ] .",
    "define the vector random variables @xmath48 and @xmath49 .",
    "the expectation of a function of @xmath50 and @xmath51 then is : = 1|p|_pg(x(),y ( ) ) with this notation , can be written as ( ) = d(x , y ) =    let us now assume that there is some ( noisy ) relation @xmath52 between ( the pixels of ) @xmath6 and @xmath8 , i.e.  between @xmath50 and @xmath51 : y = f(x)+,= if @xmath52 is known and @xmath53 is gaussian , then d_f(x , y)=is an appropriate distance measure for many purposes . in case @xmath6 and @xmath8",
    "are from the same source ( same pixel attributes , lighting conditions , etc ) then @xmath54identity is appropriate and we get the standard square loss . in many practical applications ,",
    "@xmath52 is not the identity and furthermore unknown ( e.g.  mapping gray models to real color photos of unknown lighting condition ) .",
    "let us assume @xmath52 belongs to some set of functions @xmath55 .",
    "@xmath55 could be the set of all functions or just contain the identity or anything in between these two extremes .",
    "then the `` true / best '' @xmath52 may be estimated by minimising @xmath56 and substituting into @xmath56 : f_best=_ff d_f(x , y ) , d(x , y):= _",
    "ffd_f(x , y ) given @xmath55 , @xmath36 can in principle be computed and measures the similarity between @xmath50 and @xmath51 for unknown @xmath52 .",
    "furthermore , @xmath36 is invariant under any transformation @xmath57 for which @xmath58 .    in the following",
    "we will consider the set of linear relations _ lin : = \\{f : f(x)=ax+b ,",
    "a^mn , b^m } for instance , a linear model is appropriate for mapping color to gray images ( same lighting ) , or positives to negatives . for linear @xmath52 ,",
    "@xmath36 becomes d(x , y ) = _ a^mn_b^m good news is that this distance is invariant under all regular linear reparametrisations of @xmath50 , i.e.  @xmath59 for all @xmath60 and all non - singular @xmath32 .",
    "unfortunately , @xmath36 is not symmetric in @xmath50 and @xmath51 and in particular not invariant under linear transformations in @xmath51 .",
    "assume the components @xmath61 are of very different nature ( @xmath62=color , @xmath63=angle , @xmath64=texture ) , then the 2-norm @xmath65 compares apples with pears and makes no sense .",
    "a standard solution is to normalise by variance , i.e.use @xmath66 , where @xmath67-\\e[y_i]^2 $ ] , but this norm is ( only ) invariant under component scaling .",
    "to get invariance under general linear transformations , we have to `` divide '' by the covariance matrix c_yy : = , |y:=the mahalanobis norm ( cf .",
    "section [ secrelatedwork ] ) ||y||_c_yy^-1 ^ 2 : = y^c_yy^-1 y is invariant under linear _ homogenous _ transformations , as can be seen from    we have used @xmath68 .",
    "the following distance is hence invariant under _ any _ non - singular linear transformation of @xmath50 and any non - singular ( incl .",
    "non - homogenous ) linear transformation of @xmath51 : [ defdinv ] d(x , y ) : = _ a^mn_b^m    since the norm@xmath69 is quadratic in @xmath32 and @xmath60 , the minimisation can be performed explicitly , yielding [ abmin ] b = b_min:=|y - a_min|x a = a_min:=c_yxc_xx^-1 , c_xy : = ( x , y ) = ,    @xmath70 .",
    "inserting back into and rearranging terms gives d(x , y ) = = m - .",
    "this explicit expression shows that @xmath36 is also nearly symmetric in @xmath50 and @xmath51 .",
    "the trace is symmetric but @xmath17 is not . for comparisons ,",
    "e.g.  for minimising @xmath36 w.r.t.@xmath7 , the constant @xmath17 does not matter . since the trace can assume all and only values in the interval @xmath71 $ ]",
    ", it is natural to symmetrize @xmath36 by \\{d(x , y),d(y , x ) } = \\{n , m } - returning to original notation , this expression coincides with the loss .",
    "it is hard to visualize this loss , even for @xmath18 and @xmath72 , but the special case @xmath73 is instructive , for which the expression reduces to d(x , y)=1-^2(x , y ) , ( x , y ) = ( x , y)_x_y is the correlation between @xmath50 and @xmath51 . the larger the ( positive or _ negative _ ) correlation , the more similar the images and the smaller the loss .",
    "for instance , a photo has maximal correlation with its negative .",
    "in this section , we explore the nature of the loss function derived in section  [ seclossfunction ] for real and artificial photographs , together with a pose representation specific to vehicles .",
    "it is important to select a pose representation that suitably describes the 3d model that is being matched .",
    "careful selection of pose parameters can enhance the ability of the optimisation to find the best match , and can allow object detection or coarse alignment methods , such as that presented in @xcite to specify a starting pose for the optimisation .",
    "we use the following pose representation for 3d car models , temporarily neglecting the effects of perspective projection : [ eqn : posex ] : = ( _ x , _ y , _ x , _ y , _ x , _ y ) @xmath74 is the visible rear wheel center of the car in the 2d projection .",
    "@xmath75 is the vector between corresponding rear and front wheel centres of the car in the 2d projection .",
    "@xmath76 is a unit vector in the direction of the rear wheel axle of the 3d car model .",
    "therefore , @xmath77 and need not be explicitly included in the pose representation @xmath78 .",
    "this representation is illustrated in figure  [ fig : poserepresentationx ] .",
    "to understand the behaviour of the loss function , we have generated loss landscapes for artificial images of 3d models . to produce these landscapes ,",
    "an artificial photograph was generated by projecting the 3d model at a known pose @xmath79 with phong shading .",
    "we then vary the pose parameters , two at a time about @xmath79 and find the value of the loss function between this altered projection and the `` photograph '' taken at @xmath79 .",
    "these loss values are recorded , allowing us to visualise the behaviour of the loss function by observing surface and contour plots of these values .",
    "the unaltered pose values should project an image identical to the input photograph , giving a loss of zero according to the loss function derived in section  [ seclossfunction ] , with a higher loss exhibited at other poses .",
    "the variation of the loss with respect to a pair of pose parameters is shown in figure [ fig : f1surf ] .",
    "it can be seen from these loss landscapes that the loss has a clear minimum at the initial pose @xmath79 .",
    "the loss values increase as these pose parameters deviate away from @xmath79 , up to @xmath80 . from this data , we are able to see that the minimum corresponding to @xmath79 can be considered a global minimum for all practical purposes .",
    "the shape of the surface plots was similar for all other parameter pairs , indicating that the full 6d landscape of the loss function should similarly have a global minimum at the initial pose , allowing us to find this point using standard optimisation techniques , as demonstrated in section  [ secoptim ] .",
    "the landscape of the loss function was analysed for real photographs by varying the pose parameters of the model about a pose obtained by manually matching the 3d car model to a real photograph .",
    "the variation was plotted by taking a pair of pose parameters at a time over the entire set of pose parameters . a loss landscape obtained by varying @xmath81 and @xmath82 for a real photograph",
    "is shown in figure [ fig : losslandscaperealphoto ] .",
    "the variation of the loss function for other pose parameter pairs were found to be similar .",
    "although a global minimum exists at the best pose of the real photograph , the nature of the loss function surface makes it more difficult to optimise when compared to artificial photos ( figure [ fig : f1surf ] ) .",
    "in particular , one can observe local minima in the periphery of the landscape , and the full 6d landscape is considerably more complex .",
    "as explained in section  [ seclossfunction ] , the correct pose parameters @xmath83 will give the lowest loss value .",
    "the loss function landscape , as discussed in section  [ seclosslandscape ] , shows that @xmath83 corresponds to the global minimum of the loss function .",
    "therefore , an optimisation was performed on the loss function to obtain @xmath83 based on the pose representation @xmath78 ( equation [ eqn : posex ] ) . the optimisation strategy and its reliability in different scenarios",
    "is discussed in this section .    to immunise the optimisation from pixel quantisation artefacts and noise in the images , direct search methods that do not calculate the derivative of the loss function were considered .",
    "the optimisation was performed using the well known",
    "_ downhill simplex method ( ds ) _",
    "@xcite , owing to its efficiency and robustness .",
    "when optimising an @xmath15-dimensional function with the ds method , a so called _ simplex _ consisting of @xmath84 points is used to traverse the @xmath15-dimensional search space and find the optimum .",
    "the reliability of the optimisation is adversely affected by the existence of local minima .",
    "fortunately , the _ downhill simplex _ method has a useful property . in most cases ,",
    "if the simplex is reinitialised at the pose parameters of the local minimum and the optimisation is performed again , the solution converges to the global minimum .",
    "proper parameterisation is important for the optimiser to give good results .",
    "we have used a normalised pose parameterisation as follows .",
    "normalisation gives each pose parameter a comparable range during optimisation .",
    "the normalised pose @xmath85 was obtained by normalising @xmath86 and @xmath87 w.r.t .",
    "the dimensions of the photograph .",
    "_ n = ( , , , , _ x , _ y ) @xmath88 are the width and height of the photograph ( 2d image ) .",
    "@xmath89 is a unit vector and does not require normalisation .    the downhill simplex method , like all optimisation techniques , requires a reasonable starting position .",
    "there are many methods for selecting a starting point , from repeated random initialisation to structured partitioning of the optimisation volume .",
    "a disadvantage of these methods is that they require a number of optimisation runs to locate the optimal point , which can take significant time .",
    "depending on the application , it may be possible to develop a coarse location method which provides an estimate of the optimal pose .    the wheel match method described by hutter and brewer",
    "@xcite is one such method , providing an initial match for a vehicle pose if the vehicle s wheels are visible .",
    "estimations using this method generally locate the wheel centres with a high degree of accuracy , but perform less effectively when determining the axle direction .",
    "this indicates that it may be possible to perform staged optimisation , attempting to fix some parameters before others . in general , parameter estimation",
    "using this method is within 5 - 15% of the true value .",
    "this initial pose selection is sufficient for our purposes .",
    "tests were carried out to asses the reliability of the pose estimate .",
    "we first generated synthetic `` photographs '' by rendering a 2d projection of a 3d car model at a known pose @xmath90 .",
    "the optimisation was performed from initial poses @xmath91 that had a known deviation from @xmath90 .",
    "test poses were selected at 1% , 2% , 4% , 8% and 16% deviation from the known initial parameters so as to investigate a large hyper - volume in 6d space .",
    "the parameter values for 50 such random starting poses , 10 for each range , are shown in figure  [ fig : startingposedeviations50 ] .",
    "the reliability for each percentage range was defined as the proportion of correct matches in that deviation range .",
    "exact pose recovery for synthetic images and better than careful manual tuning for real photos were regarded as _",
    "correct_. with this definition , a reliability of 1 indicates that all test cases in the range converged .",
    "a reliability of 0 indicates that none of the test cases in the range converged .    to ensure that the selected optimisation method is appropriate",
    ", we first investigate a simple case in which an artificial image with known parameters is constructed and used to validate the optimisation method .",
    "the reliability of the optimisation ( with simplex re - initialisations ) was found to be 100% ( figure [ fig : combinedresultsgraph ] ) for initial poses with up to a 16% deviation from the matching pose .",
    "next we rendered artificial car models on a real background photo , and performed the same reliability tests .",
    "allowing simplex re - initialisations preserved a 100% convergence up to the 8% deviation range ( figure [ fig : combinedresultsgraph ] ) , although the simplex did not converge for certain starting poses at a 16% deviation .",
    "this shows that the effects of a real background can deteriorate the reliability of the pose estimate for higher deviations . in order to address this issue ,",
    "a further refinement of the algorithm was made by clipping the background in the photograph when calculating the loss .",
    "[ clipbg ] the methodology used to lower the effects of the image background is as follows : pixels in the projected image that do not correspond to points of the 3d model were treated as background .",
    "these pixels do not have surface normal components as they do not belong to the 3d model .",
    "therefore , they can easily be filtered out by identifying pixels in the projected image that have null values for all three components @xmath92 of the surface normal .",
    "only the remaining pixels @xmath93 were considered for the loss calculation ( figure [ fig : combinedresultsgraph ] ) .",
    "the reliability of the pose estimates on a real car photo are shown in figure [ fig : combinedresultsgraph ] .",
    "correct pose estimates with a high reliability were obtained for starting poses up to an 8% deviation .    the distance from the camera to the projection plane in the opengl perspective projection model was used as a seventh parameter when optimising using perspective projection .",
    "the extra pose parameter makes the optimisation harder at higher deviations as seen in the reliability graph in figure [ fig : combinedresultsgraph ] .",
    "the reliability of the pose estimate may be further improved by using more sophisticated optimisation methods .",
    "an example of a correctly estimated pose for a starting pose within a 16% deviation from the manually matched pose is shown in figures [ fig : realphotoinitialpose ] and [ fig : realphotoestimatedpose ] .",
    "given that we lack an absolute ground truth estimate , pose estimates were labelled as correct or incorrect based on their visual similarity to the input image .    .",
    "results for an artificial photograph ( a projection of the 3d model ) , an artificial photograph with a real background superimposed and a real photograph are included . ]",
    "in this section we describe some of the technical aspects of the proposed work .",
    "the initial code was implemented in matlab @xcite , however , components were gradually ported to c in order to improve performance .    in order to calculate the loss values described in section  [ seclossfunction ] , it was required to render the surface normals and brightness of a 3d model at a given pose .",
    "initially , the rendering was done using _ model3d _",
    "@xcite , a bsd licensed matlab @xcite class .",
    "as this rendering was not fast enough for our application , a separate module was written in c to render the model off - screen using opengl @xcite pbuffer extension and glx .",
    "this c module was used with the matlab code using the _ mex _ gateway .",
    "initially , only the rendering was done in c. the rendered 2d intensity and surface normal matrices were returned back to matlab using the mex gateway .",
    "this seemed to exhaust memory during the reliability tests described in section  [ secoptim ] .",
    "therefore , the rendering and the loss calculation were also implemented in c , with only the loss value returned to matlab for use in optimisation .",
    ".rendering and loss calculation times .",
    "[ cols=\"<,^ , > \" , ]     this second approach improved performance in terms of speed and memory usage .",
    "a summary of the time taken to render the image and to calculate the loss using these approaches are presented in table [ tblrenderlosscalctime ] .",
    "triangulated 3d car models of significant complexity and detail in the autodesk 3ds file format were used for the work in this paper .",
    "these models were purchased from online 3d model vendors and had in the order of 30,000 nodes and in the order of 50,000 triangles .    a typical downhill simplex minimisation required in the order of 100200 loss function evaluations .",
    "using the c based loss calculation and opengl rendering , pose estimation in artificial images took around 1 minute for models with more than 30,000 nodes .",
    "recent work done in @xcite on pose estimation using point correspondences , takes more than 3 minutes ( 200 seconds ) for an artificial image of a model with only 80 points .",
    "hence , despite being a pixel based method , the performance of our approach is very encouraging .",
    "the opengl context needs to be initialised each time the loss is calculated , when the c module ( mex ) to calculate the loss is invoked from matlab . a further speed - up",
    "could be obtained by implementing the entire code ( rendering and optimisation ) in c , whereby the time spent on initialising the opengl context could be saved , as this needs to be done only once .",
    "it was also noted that although hardware accelerated opengl performs fast rendering , reading the rendered pixels back to main memory causes a performance bottleneck .",
    "the loss calculation may also be done in the graphics hardware itself , using glsl or gpu computing , in order to avoid this bottleneck .",
    "a method to register a known 3d model on a given 2d image is presented in this paper .",
    "the correlation between attributes in the 2d image and projected 3d model are analysed in order to arrive at a correct pose estimate .",
    "the method differs from existing 2d-3d registration methods found in the literature .",
    "the proposed method requires only a single view of the object . it does not require a motion sequence and works on a static image from a given view",
    "also , the method does not require the camera parameters to be known a priori .",
    "explicit point correspondences or matched features ( which are hard to obtain when comparing 3d models and image modalities ) need not be known beforehand .",
    "the method can recover the full 3d pose of an object .",
    "it does not require prior training or learning .",
    "as the method can handle 3d models of high complexity and detail , it could be used for applications that require detailed analysis of 2d images .",
    "it is particularly useful in situations where a known 3d model is used as a ground truth for analysing a 2d photograph .",
    "the method has been currently tested on real and artificial photographs of cars with promising results .",
    "a planned application of the method is to analyse images of damaged cars .",
    "a known 3d model of the damaged car will be registered on the image to be analysed , using the proposed registration method .",
    "this will be used as a ground truth .",
    "the method could be extended further to simultaneously identify the type of the car while estimating its pose , by optimising the loss function for a number of 3d models and selecting the model with the lowest loss value .",
    "more sophisticated optimisation methods may be used to improve results further .",
    "we conclude from our results that the linearly invariant loss function derived in section  [ seclossfunction ] can be used to estimate the pose of cars from real photographs .",
    "we also demonstrate that the _ downhill simplex _ method can be effectively used to optimise the loss function in order to obtain the correct pose .",
    "allowing simplex re - initialisations makes the method more robust against local minima .",
    "the possibility of needing such re - initialisations can be significantly reduced by clipping the background of the image when calculating the loss . despite being a direct pixel",
    "based method ( as opposed to a feature / point based method ) , the performance of our method is very encouraging in comparison with other recent approaches , as discussed in section  [ sectech ] .",
    "g.  j. gleason and g.  j. agin . a modular system for sensor - controlled manipulation and inspection . in",
    "_ proceedings of the 9th international symposium on industrial robots _ , pages 5770 , washington , dc , usa , march 1979 .",
    "society of manufacturing engineers ."
  ],
  "abstract_text": [
    "<S> the problem of identifying the 3d pose of a known object from a given 2d image has important applications in computer vision ranging from robotic vision to image analysis . </S>",
    "<S> our proposed method of registering a 3d model of a known object on a given 2d photo of the object has numerous advantages over existing methods : it does neither require prior training nor learning , nor knowledge of the camera parameters , nor explicit point correspondences or matching features between image and model . </S>",
    "<S> unlike techniques that estimate a partial 3d pose ( as in an overhead view of traffic or machine parts on a conveyor belt ) , our method estimates the complete 3d pose of the object , and works on a single static image from a given view , and under varying and unknown lighting conditions . for this purpose </S>",
    "<S> we derive a novel illumination - invariant distance measure between 2d photo and projected 3d model , which is then minimised to find the best pose parameters . </S>",
    "<S> results for vehicle pose detection are presented .    </S>",
    "<S> illumination - invariant loss ; 2d-3d pose estimation ; pixel - based ; featureless ; optimisation . </S>"
  ]
}