{
  "article_text": [
    "today , the internet connects millions of users , networks , and network collections worldwide , where the internet s security and stability are quite important to the global economy and well - being of the human race .",
    "however , challenged by various forms of cyber - attacks , ensuring the security of the internet and combatting the various attacks requires proper reconnaissance that prelude countermeasure actions .",
    "the information security and threat landscape has grown significantly , making it difficult for a single defender to defend against all of these attacks alone . as such information sharing for threat intelligence ,",
    "a paradigm in which threat indicators are shared in a community of trust to facilitate defenses , has been on the rise  @xcite .    in threat intelligence sharing ,",
    "participants exchange patterns of threats with each others , in a form of threat indicators or signals .",
    "participants are defined over a community of trust , and collaborate towards a common goal or mission ; to understand and respond to emerging threats  @xcite . for such intelligence sharing to happen ,",
    "standards for representation , exchange , and consumption of indicators are proposed in the literature  @xcite .",
    "communities of trust are established , and systems and initiatives for sharing are built . for such initiatives to work ,",
    "participants need to contribute information in those systems to be consumed by other community members .",
    "however , sharing threat - related information have posed various risks to organization , which pertain to security , privacy , and competitiveness . given the coinciding benefits and risks of threat information sharing ,",
    "some community members have adopted an elusive behavior of `` free - riding ''  @xcite so that they can achieve utility of the sharing paradigms without contributing much to the community .",
    "so far , understanding the effectiveness of sharing has been viewed from the point of view of whether participants contribute or not using volume - based notions of contributions .",
    "thus , a community member who does not contribute a volume of data ( indicators ) is a free - riding community member  @xcite .",
    "the state - of - the art on the problem did not include other metrics beyond simple measures of volume - based contribution , particularly metrics that capture and assess the quality of indicators ( qoi ) as a mean of understanding contribution in the information sharing paradigms .",
    "we believe that the nature of the information sharing as a concept and its application to threat intelligence both make quality a very relevant notion , and call for further investigation into the notion s definition and quantification in various settings .",
    "a well - defined measure of qoicould provide a better way of capturing contribution in general , and distinguishing community members who contribute useful data .",
    "furthermore , threat intelligence systems present distinct challenges and opportunities to counter the problem of free - riding and other abusive behaviors once quality is defined . on the one hand",
    ", these systems generally lack the enforcement of a central authority , and therefore entities in these systems share information at their own will in a ( somewhat ) peer - to - peer fashion . as a result , it is necessary to envision a set of notions and mechanisms that characterize contribution in general , and are capable of capturing free - riding , while being implemented in a distributed manner and used by each community member .",
    "an ideal measure of qoishould be robust to distinguish between the various members based on their contribution , rather than a predefined notion of trust . with the possible speciality of community members , and the varying usefulness of indicators shared based on the context in which they are used , a major challenge is to assign context - dependent quality markers for indicators .      to the best of our knowledge",
    ", the problem of free - riding in information sharing for threat intelligence , while sparsely mentioned in other work  @xcite , is not treated properly in the literature .",
    "thus , this work is the first of its type to be dedicated to the problem by identifying qoias a new metric of contribution to capture free - riding in information sharing for threat intelligence .    given the aforementioned challenges , one simple measure of contribution in information sharing systems weigh the volume of indicators contributed by various community members .",
    "however , for many reasons , such measure is insufficient , as described earlier .",
    "therefore , it is important to understand the quality of shared information as a form of participation . without a high quality of shared information , we can not achieve actionable intelligence that is effective in combating cyber threats .",
    "unfortunately , this issue is not well understood in the literature , and requires further exploration by identifying the meaning of quality , and basic methods and tools for assessing them are lacking .      in  @xcite ,",
    "et al._explored the potential correlation between qoiand privacy . however , privacy is not the only factor that affects qoi .",
    "one feature of quality is the _ correctness _ of an indicator ; a meaningful annotation and label of the indicator that is true and accurate .",
    "a second possible feature of quality is the _ relevance _ of the indicator to the community members ; because of the targeted nature of modern cyberthreats , information that is shared has to be contextual to the domain .",
    "a third plausible feature of quality of an indicator is its _ utility _ ; informally , some indicators are more indicative than others about cyber - attacks , and therefore it is critical that participants in the threat intelligence community share information that capture prominent features of cyber - threats . finally , the _ uniqueness _ of an indicator is another assessor of quality , which is defined as a measure of ( dis)similarity with previously seen indicators .",
    "this property ensures that participants deliver indicators that are not duplicates or redundant , and provide additional threat information to other community members .",
    "besides these features , indicators are often time - sensitive , making temporal features very important when evaluating qoi . a timely indicator such as a source of an attack",
    "could be used to defend against an emerging attack , unlike a stale indicator that could be ( potentially ) used for postmortem analysis . as mentioned above",
    ", there is also potential correlation between qoiand privacy .",
    "privacy can affect qoi(although perhaps negatively when privacy of indicator is ensured ) .",
    "we elaborate on this quality metric in this work , and show its quantification through data - driven analysis .",
    "while each of the aforementioned measures can be used as a separate feature of quality , we envision that a single indicator could have multiple of those features . as such",
    ", we also assess qoiwith respect to these metrics in the form of a weighted ( continuous ) score .",
    "our method for evaluating qoiis based on exploiting a fine - grained historical records as benchmark for assessing the contributions of community members .",
    "we illustrate the concept through a concrete evaluation of a real dataset from various security vendors of antivirus scans and their results of labeling malware samples as seen in the virustotal service ( https://virustotal.com/ ) .",
    "the main contributions of this paper are multifold .",
    "first , we identify the need for qoito capture contributions by community members in information sharing paradigm .",
    "qoicaptures a wide spectrum of behaviors , from altruistic behavior , where a community member contributes a lot of ( high quality ) indicators to free - riding , where a community member contributes less , or contribute a lot of low quality indicators .",
    "second , we develop and formulate various metrics that are robust to capture the notion of quality .",
    "third , we experimentally demonstrate those measures and metrics , and show their robustness , and how they differ in identifying contributor s behavior ( particularly free - riding ) from the simple volume - based measure of contribution .",
    "the organization of this paper is as follows . in section  [ sec :",
    "overview ] , we provide an overview on cyber - threat intelligence and the risks of information sharing . in section  [ sec : methodology ] , we provide an overview of our quality of indicator(qoi ) assessment methodology . in section  [ sec : qoi ] , we describe the processes involved in our qoi - based assessment . in section  [ sec : results ] , we present the results of our benchmark experiment , afterwards we discuss related work in section  [ sec : related ] and finally we conclude in section  [ sec : conclusion ] .",
    "we first provide an overview of cyber - threat intelligence systems , then introduce to unique problem with information sharing in these systems which demand quality measures .",
    "the internet today connects hundreds of millions of users worldwide , and is operated by service providers who connect businesses , education institutes , and government agencies , collectively forming a global village . in the recent years , the internet has been challenged by various forms of cyber attacks , ranging from endpoint malware attacks  @xcite to massive network disruptions and instabilities  @xcite .    at the endpoint side , malware is capable of penetrating a perimeter s security in many enterprise systems , exfiltrating sensitive data from such systems , and causing great damage to both private and public sector networks  @xcite . at the larger scale , multiple endpoint infections by malware",
    "are more powerful , and pose a greater risk , seen often in systemized large - scale botnets  @xcite .",
    "botnets , defined as collections of networks of infected hosts are the basic fabric for the operation of many cybercriminal activities .",
    "botnets rely on principled designs , where bots ( infected hosts in a botnet ) execute commands on behalf of their herder ( botmaster ) , utilizing command and control ( c&c ) infrastructure  @xcite .",
    "botnets today are used for a variety of cybercriminal activities , including spam , massive denial - of - service ( ddos ) attacks , and data exfiltration , among many others .",
    "botnets represent a major component of the cybercrime ecosystem , with the rise of botnet - as - a - service . today",
    ", hackers utilize network reconnaissance to probe targets for vulnerabilities and craft custom payloads to gain control over their infrastructure by spreading malware in propagation efforts .",
    "defending against the threat vectors of malware and botnets is a challenging task , which resulted in a rich body of literature .",
    "the literature on defending against malware and botnets looks into identifying `` signals '' , `` indicators '' , or simply `` features '' that could be useful in identifying endpoint systems , malware , and botnets . for malware , for example , such features could include static strings in that piece of malware , dynamic artifacts that the malware generates when executed in the wild , or external context information associated with the binary binary of the malware ( such as the author s information , operating system , etc . ) . for botnets , the c&c infrastructure may include domain names and internet protocol ( ip ) addresses , and knowing such information can be very helpful in identifying a botnet .",
    "for example , botnets tend to use domain generation algorithms ( dgas )  @xcite , which result in random domain strings with high entropy , and being able to identify those domain names is key to detection of botnets .",
    "furthermore , being able to distinguish between various dgas is key to attribution of threat to a certain botnet family .",
    "an effective cyber defense would rely on a good visibility into many of those features .",
    "combatting cyber threats and attacks requires intelligence gathering that prelude countermeasure actions , as seen in the above examples . to this end",
    ", cyberthreat intelligence has become a growing concept . today , organizations in the public and private sector , government and industry , have established tools seeking first - hand knowledge about new cyber - attacks and malware threats .",
    "this includes the ability to recognize and act upon indicators of attack and compromise scenarios , essentially putting the pieces together for analysis about attack methods and processes using static and dynamic analysis and profiling techniques , open source , social media , and dark web intelligence .",
    "the need for information sharing for threat intelligence is necessitated by both economical and technical realities .",
    "being able to identify all the types of indicators and features useful for characterizing , identifying , and defending against all types of threats , while desirable , is infeasible from both technical and economical standpoints . with new technologies such as cloud , mobile computing , social networks , and the internet of things ( iots ) , and the the persistence of adversaries through cybercrime and advanced persistent threats ( apts )",
    "have also brought several challenges .",
    "therefore , it is reasonable to say that no single player in this ecosystem is capable of addressing all security issues alone .",
    "for this reason , sharing information of threat intelligence among vendors and government entities has emerged as a plausible technique for efficiently and effectively defending against new and emerging threats . with threat intelligence sharing ,",
    "operational experience is communicated to other parties in an ecosystem to enable them to effectively defend against current attacks , and to improve their defense posture by preventing such attacks from happening utilizing such actionable intelligence .    to enable information sharing , organizations need to agree on standardizing threat information .",
    "this requires defining the content fields , encoding , and exchange format of the information relevant to a particular threat or incident , along with a pre - defined protocol to communicate the criticality of such information .",
    "various standards for information sharing have been proposed  @xcite to automate and structure the exchange of threat information with a community of trust .",
    "today , standards are used in the exchange of indicators of software , hardware , and network artifacts , and are intended for operationalizing those indicators in many applications , including security operations related to malware characterization , vulnerability analysis , remediation , platform hardening , and incident - response  @xcite .",
    "while threat information sharing brings many benefits to the sharing community members , it may incur security risks about participants , their operational contexts , and security posture .",
    "not only that , the same information , once exposed to an adversary , may be used to test their applicability on other target systems , who may lag behind in security updates or miss out on patching vulnerabilities . therefore , the adversary will be able to utilize such information for attacking other unpatched systems .",
    "the risk of sharing may go beyond fingerprinting systems to leaking personal identifiable information about individuals .",
    "various types of sharing standards are proven to leak personal identifiable information ( pii ) that may contain names , email addresses , and other types of sensitive data  @xcite .",
    "for example , privacy violations in sharing standards may occur in the form of a document which contains contact information for the constituent responsible for an incident report .",
    "this type of information may become personally identifiable in the case when the contact information of a particular individual are used .",
    "participants in a threat intelligence sharing community may interact with one another with various degrees of collaboration and competition , which may affect the way they share  @xcite .",
    "because of that , many companies and organizations today are reluctant in sharing firsthand intelligence , and mostly gather and ingest information from neighboring sources that are less significant .      given the triad of security , privacy , and risks associated with threat intelligence sharing , some members might be joining communities of sharing for the purpose of benefiting from the platform without offering valuable information themselves , hence , the term , `` free - riding '' is coined to refer to the behavior of such users who act to maximize their own utility at the expense of the welfare of the community .",
    "this problem is not new , and is manifested in other distributed settings , most notably peer - to - peer ( p2p ) systems . in p2p systems , cooperation is required for the operation the system .",
    "however , cooperation may incur significant communication and computational overhead , thus users may refuse to contribute their fair share of resources . at the same time they may utilize the system by consuming the resources of other peers .",
    "researchers demonstrated the impact of free - riders in p2p systems , such as bittorent  @xcite , and observed a significant increase in download times for high contributing nodes in the presence of few low contributing ones .",
    "so far , and to the best of our knowledge , understanding the effectiveness of sharing has been viewed from the point of view of whether participants contribute or not ( thus the literal meaning of free - riding ) .",
    "this form of contribution is perceived as a volume - based contribution , since the level of contribution by any participant is evaluated directly by the amount of information communicated to the community regardless of its nature , whether it is used by community members or not .",
    "given the large amount of unprocessed threat - related events , which are generated by automation tools , such as security information and event management ( siem ) technologies , and the fact that in many sharing systems today , the contribution level amounts to the volume of data , actors may find it more convenient to submit raw , unprocessed , or unused events as indicators of threat to avoid the investment on resources for cleaning , contextualizing , operationalizing , and filtering such information .",
    "for this reason , it is important to consider the quality of shared information as the basis for evaluating the level of participation , because a simple and coarse measure of participation is insufficient . in order to overcome these obstacles , in this paper",
    "we propose qoi as a quantifiable and measurable metrics and provide a methods for quality assessment .",
    "assessing qoiis a nontrivial task . however , as other quality notions ( e.g. , quality of services , quality of experience , etc . ) , qoirequires defining metrics , methodology for assessing such metrics , and methods for validation of the proposed metrics based on sound assumptions , to find out what capabilities they provide , including addressing free - riding .",
    "our approach in developing qoimetrics is intuitive , and uses several sounds assumptions driven from the context in which indicators are used . in particular , qoimetrics include correctness of an indicator with respect to a label feature , the relevance of the indicator to a consuming community member , the utility of the indicator , and its uniqueness .",
    "more ( informal ) details are provided in section  [ sec : qoimetrics ] .",
    "our approach for assessment of qoiuses a reference `` golden '' dataset as ground truth .",
    "based on whether the indicator provided by a community member is in the reference dataset or not , the assessor proceeds by either matching the metric attribute of the indicator to that of the golden dataset . if the indicator is not in the golden set , and assuming that the golden dataset has `` similar indicators '' , a machine learning algorithm is used for predicting the attribute of the qoimetric , and compare it to the one provided by community member . for an arbitrary number of indicators provided by the community member , a score",
    "is then established for that community member based on the normalized weighted sum of qoivalues across all indicators .    in this section ,",
    "we describe the quality metrics and the details of our methodology including a system architecture for assessment , processes followed and the data - flow .      in the following , we identified four metrics to be used for assessment of quality : correctness , relevance , utility , and uniqueness , as described below .      for a given reference dataset , the correctness metric of qoicaptures whether attributes of an indicator ( e.g. , label used for attribution , severity score used for risk assessment , etc . ) are consistent with the assessor s reference . for that , and using the labeling of a malware sample as an example of an attribute for an indicator , we compute the correctness score as the fraction of samples that match the anticipated labels . specifically , this is computed as the aggregate binary score of the correct samples normalized by the size of the sample set of indicators .",
    "informally , the relevance metric of a qoimeasures the extent to which an indicator submitted by a community member to the community is contextual and of interest to the rest of the community . as such , in defining and assessing the relevance of an indicator , we use a reference weight assignment to the class labels giving higher weight to labels of greater interest to a particularly community member ( assessor ) and lower weights to less desirable labels .",
    "the relevance score is then computed as the average weighted sum for all sample indicators in the set .",
    "the utility is similar to the relevance of an indicator , although at a finer - granularity than an indicator . as such",
    ", we view the utility of an indicator as the average weighted sum of all of its feature components .",
    "this is , we assign a different weight to each feature of the indicator to leverage features that are a better candidate input to prediction of threats . while the weighting of the features of an indicator could be realized using one of many ways , we suggest the information gain as a measure of weighting features .",
    "for example , using a similar notion , the weights of the feature components can be computed using various statistical models for sensitivity analysis , including the principal component analysis ( pca ) technique  @xcite ) .",
    "the uniqueness of an indicator is a measure of the ( dis)similarity of the indicator in comparison with other submitted indicators by contributors in the community .",
    "a vector distance ( e.g. , using the mahalanobis distance  @xcite , which captures the difference between a point @xmath0 and a distribution of points @xmath1 with a mean @xmath2 ) is computed to determine the degree of uniqueness .",
    "we also define a threshold on the minimum distance between the feature vector of an indicator to other indicators , and use that threshold to tell whether an indicator is unique or not .",
    "having elaborated on the informal definition of qoimetrics , we now move to discuss the qoisystem architecture , first as a strawman highlighting the main concept of assessing qoi , and then as a fully functioning system that addresses various issues in the strawman design .    our system for assessing qoioperates for a set of distributed nodes in a community of trust .",
    "those nodes are are logically connected with each other in a p2p fashion , as shown in figure  [ fig : arch ] . as such , each of these nodes would participate in the sharing and consumption of threat indicators provided by other peers , which is achieved within a community of trust that is separated from other communities in the sharing ecosystem . before nodes can accept and operationalize ( process ) these threat indicators , they need to evaluate their quality by asking a special node , an assessor , which has sufficient information to perform such function , for a rating ( scoring ) of the indicator . in response , the assessor assigns a quality score for the indicator based on a ground - truth available to the assessor , and using a reference dataset the assessor has access to .        in this architecture",
    ", we assume that the messages sent between the peers in the system are authentic and tamper - evident , using existing threat exchange protocols that provide end - to - end security guarantees .",
    "one issue that the above architecture may suffer from is the amount of trust each community member has to put in the assessor , and the validity of his scoring of indicators .",
    "we address this issue by assuming that the architecture can support more than one assessor node , and these nodes may coordinate among each each other .",
    "we leave exploring the spectrum of the number of assessors and the rationale for various numbers as a feature work .",
    "however , as a feature , a consumer of a score by the assessors ( where the assessors number is greater than 2 ) could perform a majority voting to improve the robustness of the scoring to address intentional bias ( dishonesty of assessors , if any ) , and unintentional bias ( due to issues with the underlying ground truth dataset ) . on the other hand , any and every node in the system could act as an assessor , if the golden reference dataset is available to them .    while the latter assumption of the availability of the data to each node in the system is very implausible",
    ", a milder assumption for the operation of the strawman design above is the coverage of data : the system assumes the reference dataset has sufficient information about every possible indicators presented by the various community members .",
    "however , based on a prior work assessing coverage of indicators  @xcite , no single community member ( antivirus scanner ) in the case of malware detection and labeling has a 100% coverage or accuracy .",
    "based on the same study , and for a malware family such as zeus  @xcite , it takes 6 and 18 community members to provide close to perfect coverage of detection and correctness of labeling , respectively .",
    "such numbers are close to 10% and 30% , respectively , of the entire set of community members with antivirus scans in the virustotal dataset .",
    "this in particular calls for a more `` intelligent '' process for the assessment of qoi , using not only explicitly provided labels , but also using learned labels from features of indicators utilizing advanced machine learning techniques .      at a high - level , our ideal system for assessment has the following specific procedures for system setup :    1 .   _ defining quality metrics and scoring procedures .",
    "_ quality metrics are used as a measurement criteria to ensure that community members who participate in information sharing provide threat indicators that are valuable to other members , while scoring procedures are methods that specify how these metrics are used to generate a quality score . 2 .   _ defining annotations for threat and quality labeling .",
    "_ annotations can either be labels that indicate the type of threat or they can be labels for identifying the quality ( severity , timeliness , etc . ) level or quality type of an indicator . utilizing these annotations ,",
    "a weight value is assigned to each quality label , and a scoring method is utilized to convert the quality labels to a numeric aggregate score for the indicator .",
    "3 .   _ building the reference dataset . _",
    "the reference dataset will be used to evaluate qoifor a sample of indicators submitted by a sample provider . to build the initial reference dataset , data that is collected through security operations ( e.g. , monitoring , profiling , analyses , etc . )",
    "is vetted for their validity and applicability to the domain , perhaps using often expensive by necessary manual vetting  @xcite .",
    "4 .   _ defining extrapolation procedures and training the classifier . _",
    "extrapolation procedures enable a quality assessor to predict the label of an indicator using its feature set and classifier model .",
    "the classifier is trained using a supervised learning process extracted from the reference dataset .",
    "this reference dataset is collected for the purpose of initializing the system .",
    "after the initial setup of the system , the sample indicator is assessed for its quality and a quality score is computed .",
    "the following describes the steps of the assessment .",
    "1 ) obtain a set of sample indicators where each sample is composed of a tuple ( label , vector ) that consists of a label and a vector of features .",
    "2 ) for each sample , extract the feature vector and feed the data as test input to the trained classifier which predicts its label .",
    "3 ) compare between the predicted label and the label provided by the sample .",
    "indicate whether the two labels match , and record the comparison result as a quality annotation .",
    "4 ) compute the confidence level and include other quality annotations for the indicator using the labeling rubric .",
    "5 ) use scoring procedures and quality labels to compute a quality score for the indicator .",
    "the illustration for the complete process and dataflow of the qoiassessment method embraced in our design is depicted in figure  [ fig : method ] .",
    "as can be seen in the figure , the setup of the system is achieved through the use of a supervised learning process over the reference dataset , rather than the direct matching of explicit labels of indicators in the dataset .        in this assessment system , we assume a reference labeled ( training ) dataset that contains a comprehensive library of artifacts , such as malware samples , incident reports , and logs , and that has been collected through typical operational intelligence gathering procedures .",
    "ways for obtaining such labels falls out of the scope of this work , and industry s best practices , as described in  @xcite could be used . upon ingesting those artifacts in our system ,",
    "they are converted into a set of training samples with their corresponding features .",
    "each sample is a pair that consists of a feature vector as an input object for the machine learning algorithm and the corresponding threat label as the desired output value for the object class . to reach such end goal of predicting a label correctly ,",
    "the build of our trained model encompass multiple components , namely a feature selection procedure , a machine learning algorithm selection procedure ( e.g. , svm , logistic regression , random forest , etc . ) and the corresponding parameters ( e.g. , procedure for regularization and linearization in case of svm and lr , respectively ) , and cross validation procedures ( e.g. , fold size , validation strategy , etc . ) .    upon building the machine learning model , establishing a confidence in its performance through typical evaluation metrics ( e.g. , low false positive and false negative , and high true positive and true negative ) , we then use the built model as a predictor for previously unseen threat indicators . in such operational setting , given a sample indicator provided by a community member , and before ingesting it the community member would pass it to the assessor for further evaluation and scoring .",
    "the assessor then extracts a feature set corresponding to the indicator using a standard form , and converts it into a feature vector .",
    "the assessor then uses the previously built model as a predictor , and assigns a label ( e.g. , using a multiclass svm , the assessor can indicate the label closest in the training set to that of the newly observed indicator ) .",
    "the assessor then decides the quality of the indicator by taking both the predicted and the self - provided label by the community member into account .",
    "the quality scoring engine then uses the individual scores of the various indicators provided by each community member to assess their actual contribution , and detect free - riders .",
    "we note that the `` intelligent '' system above addresses various issues in the strawman system .",
    "first , rather than requiring the actual indicators to be present in the ground - truth dataset , this technique requires only the availability of a sufficient number of indicators of the same label .",
    "second , with such flexibility in defining the ground - truth through a learning and model - building process , the number of community members that can act as assessors greatly increase .",
    "finally , the even when the labels of indicators are not provided by the community member , e.g. , artifacts provided to the community are not operationalized , this technique makes use of those indicators through other measures of qoi , such as relevance , or utility , or uniqueness , which do not require a label to be provided by the contributing community member .",
    "as discussed in section [ sec : procedure ] , the qoiassessment process is composed of a series of steps in order to initialize and operate our system for both assessment of individual indicators and scoring of community members as a whole . specifically , these steps begin with collecting the reference dataset and building the prediction model , then extrapolating , benchmarking , and computing a quality score for a given indicator . in the following ,",
    "we outline in more details each of those processes and procedures .      after identifying metrics for defining quality , as exemplified in section  [ sec : qoimetrics ] , we demonstrated the use of qoifor the assessment of the contribution level of participants . as mentioned before , our methods for computing the qoiinvolve multiple processes . in order to initialize the system the reference dataset",
    "is used to build prediction model through supervised techniques of machine learning .",
    "specifically , this involves submission of sample artifacts from multiple sources , and the premise is to utilize the notion of quality as opposed to a simple view of contribution based on the volume of data ( i.e. the number of samples ) . in order to evaluate the qoiprovided by community members",
    ", a reference dataset is used as a resource of ground truth .",
    "while proposing methods for obtaining ground truth falls out of the scope of this work , we only use an example in this work to bootstrap the evaluation .",
    "in particular , in this work we demonstrate evaluating the quality of malware labels by av vendor using virustotal as a reference dataset with samples that are manually vetted by one community member  @xcite ( in such setting virustotal could be loosely defined as the community of trust ) . in short , virustotal is a multi - engine av scanner that accepts submissions by users and scans the samples with those engines .",
    "the results from virustotal provide many useful artifacts and annotations , including the labeling of a sample by the various engines of av scanners , as well as other behavioral and static features of malware samples .",
    "though there might be some inconsistencies in the final labeling between the results of virustotal and across vendors , the premise is that the tool can be trusted for samples that have been submitted multiple times over sufficient periods of time , particularly since av vendors update their results with virustotal whenever acquiring a new signature for a previously unknown sample .",
    "features provided in the ground truth are particularly useful in a learning a model for their label prediction . to identify the family to which a malware sample belongs , security vendors ( av scanners , community members ) usually gather various characteristics and features of the sample using static analysis , dynamic analysis , and memory forensics . for static analysis , artifacts like file name , size , hashes , magic literals , compression artifacts , date , source , author , file type and portal executable ( pe ) header ,",
    "sections , imports , import hash , among others , are used . for dynamic analysis , file system , user memory , registry , and network artifacts and features",
    "are collected . for memory forensics ,",
    "memory byte patterns are captured to create a signature .",
    "after building the prediction function by training classifier with the reference dataset , the next step is to assess qoithrough extrapolation from the prediction function results .",
    "the remaining question becomes how the reference set are used to assess and extrapolate the values and quality of indicators . in order to answer this question , we elaborate on a particular machine learning techniques , the semi - supervised learning and its application to the problem at hand .    model .",
    "while our system described in the previous section uses multiple off - the - shelf algorithms , we highlight the operation of qoiusing a classifier model based on the nearest centroid classifier ( ncc ) , specifically we adopt a variant called the linear discriminant analysis  @xcite to map threat indicators to their respective labels . in this model ,",
    "each label is characterized by its vector of average feature values ( i.e. class centroid ) .",
    "a new sample indicator is evaluated by computing the scaled distance between the features of the sample and each class centroid , and then the sample is assigned to the class to which it is nearest .    to build the classifier",
    ", we obtain @xmath3 samples for training from the reference dataset .",
    "this dataset is built such that there are @xmath4 training samples per class , with @xmath5 features per sample .",
    "for each training sample @xmath6 , we observe a label @xmath7 and a sample vector @xmath8 .",
    "for simplicity we refer to the classes labels by their indices @xmath9 .",
    "note that each @xmath8 is a vector of length @xmath10 .",
    "we assume that samples labeled by @xmath11 are distributed as @xmath12 , the multivariate normal distribution with mean vector @xmath13 and standard deviation matrix @xmath14 .",
    "we denote by @xmath15 , the corresponding probability density function .",
    "finally , let @xmath16 be the prior probability that an unknown sample comes from class labeled by @xmath11 .",
    "bayes theorem states that the probability that an observed sample @xmath17 comes from class @xmath11 is proportional to the product of the class density and prior probability : @xmath18 where @xmath19 is the posterior probability that sample @xmath17 comes from class @xmath11 .",
    "the classifier assigns the sample to the class with the largest posterior probability to minimize the misclassification error .",
    "this can be written as a rule : @xmath20 therefore , a sample is assigned to the nearest class and the distance is computed using the lda metric : @xmath21 , where @xmath22 is the square of the mahalanobis distance between @xmath17 and @xmath23",
    ".    rate .",
    "a misclassfication occurs when an indicator is assigned to an incorrect label .",
    "the probability of making a classification error @xmath24 is : @xmath25.\\ ] ] the misclassification rate using the lda rule can be derived from ( [ eq:2 ] ) . in particular , we can calculate the misclassification rate of the nearest - centroid using : @xmath26 \\times \\pi_{j},\\ ] ] where @xmath27 is the cumulative distribution function ( cdf ) of the standard normal distribution .",
    "note that this assumes that the sample data are normally distributed as stated by the model .",
    "the equation above can be interpreted as a measure of the collective distance between all of the class centroids taking into account class prior probabilities . in general , the misclassification rate is small when the centroids are far apart and increases otherwise .",
    "we used the ncc to predict labels for observed indicators and compared the results with the sample labels .",
    "this enables us to compute a score on the correctness and quality of the feature set for the indicators . in the following",
    "we formalize the steps to compute a score for the samples based on the quality metrics described earlier .",
    "denote by @xmath28 the number of users in the system .",
    "each user @xmath29 provides a set of samples @xmath30 @xmath31 with feature vector @xmath32 and sample label @xmath33 for @xmath34 and @xmath35 .",
    "as described earlier , the reference dataset is used as the benchmark for determining the correct label for an arbitrary sample .",
    "each sample consists of a feature vector and an associated label . in procedure  [ alg : correct ] we outline the algorithm used for computing the correctness as a qoimetric .",
    "obtain reference dataset @xmath36 @xmath37 where @xmath38 for @xmath39 .",
    "evaluate @xmath40 by applying the ncc method as follows :    1 .",
    "_ training _ : compute reference indicators @xmath41 for class labels in @xmath42 , as per - class centroids @xmath43 , where @xmath44 is a subset of @xmath45 belonging to the class label @xmath7 .",
    "prediction _ : for every sample @xmath32 , apply the classifier function to compute the label , @xmath46    for every sample , compute the sample score @xmath47 as : @xmath48    compute the correctness score ( c ) of @xmath40 by taking the average sum : @xmath49    as shown above , we first build a classifier by utilizing the reference dataset @xmath45 as the training set and forming a prediction on the label of @xmath0 to obtain @xmath50 .",
    "then , the assigned label of @xmath0 is compared against the predicted label @xmath50 and a positive score is given if labels match .",
    "the correctness is computed as the average sum of scores for all samples in @xmath40 .",
    "the steps for computing the relevance variable of a set of indicators are shown in scoring procedure  [ alg : relevance ] .",
    "as can be seen , the weight values @xmath51 are arbitrarily chosen , and a mapping function @xmath52 is defined to assign weights labels such that higher weight values are assigned to labels of greater interest to the community members .",
    "define weight values : @xmath53 define a weight function @xmath54 to assign elements in the label set @xmath38 as @xmath55 compute the relevance of @xmath40 as average weighted sum : @xmath56    for each sample @xmath17 , the corresponding label is evaluated using the mapping function @xmath52 to obtain the weight value as the sample score .",
    "the relevance score of @xmath40 , denoted by @xmath57 , is calculated as the average weight sum of the scores .",
    "next , we provide the sequence of steps required for calculating the utility variable of a set of indicators , in procedure  [ alg : utility ] .",
    "in this procedure we note that the utility of an indicator is determined by the sum of the utility weights of the samples .",
    "the weights @xmath58 and weight function @xmath59 are defined by the application .",
    "define utility types @xmath60 define weight values @xmath58 , where each weight value corresponds to a utility type . define a weight function @xmath59 s.t .",
    "@xmath7 maps to a utility weight , i.e. @xmath61 where @xmath62 .",
    "compute a weight of @xmath63 , using @xmath64 compute the utility score of @xmath40 as the average sum of the sample weights : @xmath65 where @xmath66 is the corresponding label type of sample @xmath67      another metric of qoiis their uniqueness , where highly unique indicators are considered more valuable than common indicators . in procedure  [ alg : uniqueness ]",
    "we outline the steps used for calculating the uniqueness of a set of indicators .",
    "consider the set @xmath68 which is initially empty , i.e. @xmath69 build the set @xmath68 by considering unique samples from the sets @xmath70  add @xmath71 to @xmath68 . compute the uniqueness score for @xmath40 as follows @xmath72 compute the uniqueness score ( n ) of @xmath40 by accumulating the scores of the elements : @xmath73    in this procedure , we assume that samples can be uniquely identified ( e.g. using hashes ) . in set notation",
    ", we can say that an element @xmath67 is unique if it is not an element of other sample sets , i.e. @xmath74 .      qoiis a comprehensive measure of the various notions of quality defined earlier .",
    "in particular , qoifor @xmath40 is the average weighted sum of the four components : correctness ( c ) , relevance ( r ) , utility ( u ) and uniqueness ( n ) , as shown in procedure  [ alg : qoi ] .",
    "the weights assigned for individual metrics are application- and community member - specific .",
    "define normalized weights for the components : @xmath75 , and @xmath76 .",
    "calculate the quality of indicator ( qoi ) as the weighted sum of the components : @xmath77",
    "in this section , we evaluate the scoring method for contribution based on quality of indicators , and highlight how it addresses the free - riding problem in information sharing in a unique way .",
    "we start by analyzing the dataset that we obtained from av vendors about their sample labeling , then we utilize this dataset and apply qoi - based and volume - based scoring methods to compare between the vendors .",
    "to highlight qoias a new notion of evaluating contribution in information sharing for threat intelligence , we compare the difference between quality - based and volume - based scoring methods for the contribution of av vendors . to this end , our dataset enumerates av vendors who submitted their artifacts of malware samples , including labels , to virustotal during the period of our data collection from mid 2011 to mid 2013  @xcite .",
    "a key goal of the evaluation is to demonstrate the deficiency in the use of volume - based scores , since one vendor can achieve a high rating by submitting a large number of artifacts about malware samples of low quality . as discussed previously",
    ", this could happen because of several reasons : the submitted artifacts about some malware sample are incorrect , the sample family is uninteresting , or that the kind of information submitted about the samples are not helpful in identifying or detecting them .",
    "table  [ tab : malfam ] depicts the malware families used in this study , their sample size , and the corresponding brief description of each family type .",
    "all scans are carried out on those malware samples around may 2013 timeframe .",
    "the dataset provides a diverse representation of families , which nicely facilitate our study .",
    "as can be seen , avzhan and darkness are the most popular ddos malware being submitted . on the other hand , shadyrat is the most popular targeted malware with the largest sample size in its category ( represents about 43% of the targeted samples and 24% of the total samples ) , while zeus has the largest sample size for trojan malware , roughly about 77% of the trojan samples and 16% of the total samples .",
    "furthermore , we observe that more than half of the samples are ddos ( 54% ) , 21% are trojans , and 25% are targeted malware.this breakdown provides an insight about the threat landscape and the frequency in which these types of malware appear in the wild .",
    "oftentimes av vendors harvest malware samples by utilizing deployment of internet sensors for packet capturing , or using isolated environments such as honeypots and virtualization tools for behavioral analysis .",
    "the increased number of samples for ddos is justified by the need for vast deployment for scaling up the number of infected hosts to launching attacks . on the other hand , targeted malware are less common in the wild because they are deployed in limited number of hosts , and are typically designed with covertness in mind . in the rest of this analysis ,",
    "the identity of the vendors is anonymized .",
    ".malware families used in the study .",
    "ddos stands for distributed denial of service .",
    "also , ddoser is known as blackenergy while darkness is known as optima .",
    "dataset and description are from @xcite .",
    "[ cols=\"<,<,<\",options=\"header \" , ]      in this section , we introduce the results and finding by performing an evaluation of the various qoimetrics over our evaluation dataset ( we evaluate all but uniqueness , since it is trivial to assess ) .",
    "first , we note that while there are more samples gathered for ddos - type malware in comparison with others , the threat - intelligence community often gives more weight to identify malware or incidents that are less observable , which present a level of sophistication .",
    "thus , for our evaluation , we consider trojan and targeted malware more relevant than ddos , from the point of view of community members consuming the shared information .    .",
    "figure  [ fig : relevance ] presents the normalized scores for the relevance of indicators for each vendor . in assessing relevance , we give more weight to targeted malware and trojans over ddos samples of each vendor ( community member ) .",
    "specifically , the weights are @xmath78 , @xmath79 , and @xmath80 m and `` 0 '' otherwise .",
    "as shown , in the relevance - based assessment a higher score is given to vendors who contribute more targeted and trojan samples , and vendors who only contribute ddos samples are greatly de - emphasized .",
    "we observe two distinct behaviors .",
    "first certain contributors who have high volume - based score tend to have a very low ( close to `` 0 '' ) score when using the qoimetric of relevance for their evaluation .",
    "in particular , with the two relevant and one less relevant family types of interest identified , such community members tend have more unidentified ( irrelevant ; i.e. , individual score of `` 0 '' ) malware samples and families ( e.g. , vendor 7 , vendor 21 , vendor 59 , etc . ) . on the other hand , certain contributors ( although smaller in numbers ) , and despite having a small volume - based contribution , tend to have higher relevance score , thanks to having the very relevant family identified in their shared indicator labels ( e.g. , vendor 10 , vendor 16 , vendor 27 , etc . ) .    .",
    "an assessment of the correctness of the av indicators is depicted in figure  [ fig : correct ] . as can be seen , vendor 4 , vendor 27 , and vendor 30 , outperformed other vendors in this metric with a score in the 80s up to top 90s percentile range , highlighting a quality of the labels provided by those vendors corresponding to the actually learned labels of the samples provided by them . on the other hand , the majority of the rest of vendors tend to have a gap in the score between the volume - based and the correctness - based contribution measures , where the correctness - based measure is significantly lower .",
    "there are various reasons for why some vendors tend to score low for correctness despite their large ( volume - based ) contribution .",
    "this could be caused by them labeling samples under unknown names , mislabeling to other family types due to similarities between families , or assigning generic labels like `` trojan '' , `` virus '' , `` unclassified '' among other misleading labels .",
    "examining the correctness of av indicators also leads to a more subtle discussion about their utility .",
    "looking closer into the label generated by some vendors , we find out that some labels are too generic in the sense that they only describe the behavior rather than name of a known malware family type , e.g. , trojan.win32.servstart vs. avzhan .    . to evaluate the utility of av indicators , we give weights for three classes of malware labels : complete labels ( @xmath81 ) are based on industrially popular name , generic labels ( @xmath82 ) are based on placeholders commonly used for labeling the family such as `` generic '' , `` worm '' , `` trojan '' , `` start '' and `` run '' , and incomplete labels , ( @xmath83 ) , including `` suspicious '' , `` malware '' , and `` unclassified '' , which do not hold any meaning of a class",
    "similar to the strategy with relevance , we assign weights of @xmath84 , @xmath85 , and @xmath86 .",
    "we plot the results of evaluating the utility of indicators in figure  [ fig : utility ] .",
    "we notice that vendors such as vendor 51 , vendor 53 , and vendor 59 are rated as high utility indicator providers that surpass their volume - based scores .",
    "nevertheless , these vendors high utility indicator is offset in figure  [ fig : metrics ] that includes two more metrics : correctness and relevance .",
    "these additional metrics show that these vendors achieve insignificant correctness and relevance .",
    "figure  [ fig : metrics ] captures the importance of displaying the three scores in a single plot to allow direct comparison of the various quality - based metrics .",
    "we notice that there is a clear correlation between the correctness and relevance scores .",
    "this is because we only compute relevance scores for correctly submitted samples , where incorrect labels are zeroed in the relevance score .",
    "as described earlier , we aggregate a single qoiscore for each vendor based on the weighted sum of the various qoimetrics . in figure",
    "[ fig : qoi ] , we present a comparative bar - plot between qoi - based and volume - based scoring for assessment of contribution by the av vendors . as can be seen , many vendors , such as vendor 14 , vendor 57 , and vendor 58 which received high qoiscores are rated with lower scores in their volume - based rating . in particular",
    ", they received from 15 - 75 percent lower rating in their volume - based scores . on the other hand ,",
    "vendors like vendor 11 and vendor 18 , and vendor 20 , which tended to provide a very high volume - based indicators , have very small ( close to zero ) qoiscore , highlighting their potential as free - riding candidates .",
    "the free - riding problem in threat intelligence sharing is not addressed before , nor measures of quality broadly defined , or closely identified for assessing contribution by community members . however , the problem of free - riding in general is not new and has been a topic of discussion in the peer - to - peer ( p2p ) systems community .",
    "going early back in the literature , adar and huberman  @xcite were first to spot the problem in p2p systems as they noticed the existence of a large fraction of users who do not share useful content in the file sharing network gnutella .",
    "a few years later , feldman et al .",
    "@xcite characterized the problem of free - riding in peer - to - peer systems and proposed potential directions for research . in response ,",
    "a stream of papers were published on the topic , most notably , the work of locher et al .",
    "@xcite , who developed a free - riding client as a proof - of - concept and demonstrated how entire files can be downloaded in the bittorrent network without providing any content to the peers . while locher et al . have concentrated on analyzing the feasibility of free - riding attacks , other papers  @xcite are more focused on analyzing their root - cause and impact on the overall system utility .    in light of operationalizing the functions of threat intelligence ,",
    "various information sharing standards were proposed including those developed by ietf ( https://www.ietf.org/ ) , mitre ( https://www.mitre.org/ ) , and nist ( https://www.nist.gov/ ) .",
    "industry leaders have picked up on these standards and developed application program interfaces ( apis ) to facilitate delivery and retrieval of raw , processed , and structure and intelligence data , such as threatexchange  @xcite by facebook and intelgraph by verisign .",
    "however , sharing standards have shown to exhibit privacy violations including leaking pii fields , as demonstrated by  @xcite , potentially encouraging the act of free - riding .",
    "of relevance to the notion of quality of indicators in threat intelligent systems is malware attribution .",
    "malware attribution have been widely employed in the literature for training algorithms and techniques of malware classification and labeling  @xcite , and understanding the utility of attributes as detector patterns of malware samples has been an important subject matter .",
    "bailey et al .",
    "@xcite were one of the early folks to characterize malware in terms of system state changes ( e.g. registry changes , files created ) and investigated the problem of behavior - based clustering as a method for classifying and analyzing internet malware .",
    "more focused on the labeling problem , canto et al .",
    "@xcite analyzed the quality of labeling of malware samples for a couple of vendors and pointed out their labeling inconsistencies .",
    "in the same vein , perdisci  @xcite analyzed the shortcomings of malware labeling of various av vendors by constructing a graph from the labels and measuring the distance between them .",
    "on the other hand , mohaisen and alrawi  @xcite quantified the inconsistencies in labeling against a reference dataset collected from thousands of samples of various types which were manually vetted by analysts . in their study , the authors evaluated the detection rate , correctness , and consistency of labeling of av scanners .",
    "in this paper , we have the first look at the notion of the quality of indicators ( qoi ) for understanding the contribution of community members in information sharing paradigms . unlike other peer - to - peer systems in which the volume of contribution ( bandwidth , size of files , etc . )",
    "is a good indicator of contribution , we argue that the special nature of security applications calls for more elaborate notion of contribution . as such , we define multiple metrics for assessing contribution , including correctness , utility , and relevance of indicators .",
    "as compared to volume - based measures for contribution , and thus free - riding , our metrics are more robust , contextual , and reasonably quantify the actual contribution of individuals . by verifying our metrics on a real - world data of antivirus scans we unveil that contribution measured by volume is not always consistent with those quality measures , and that qoias notion is capable of capturing forms of contribution beyond free - riding .",
    "d.  k. tosh , s.  sengupta , c.  a. kamhoua , k.  a. kwiat , and a.  p. martin , `` an evolutionary game - theoretic framework for cyber - threat information sharing , '' in _ 2015 ieee international conference on communications , icc 2015 , london , united kingdom , june 8 - 12 , 2015 _ , pp .  73417346 , 2015 .",
    "h.  tanaka , k.  matsuura , and o.  sudoh , `` vulnerability and information security investment : an empirical analysis of e - local government in japan , '' _ journal of accounting and public policy _ , vol .",
    "24 , no .  1 ,",
    "pp .  3759 , 2005 .",
    "d.  k. tosh , s.  sengupta , s.  mukhopadhyay , c.  a. kamhoua , and k.  a. kwiat , `` game theoretic modeling to enforce security information sharing among firms , '' in _",
    "ieee 2nd international conference on cyber security and cloud computing , cscloud 2015 , new york , ny , usa , november 3 - 5 , 2015 _ , pp .  712 , 2015 .",
    "s.  yadav , a.  k.  k. reddy , a.  reddy , and s.  ranjan , `` detecting algorithmically generated malicious domain names , '' in _ proceedings of the 10th acm sigcomm conference on internet measurement _ , pp .",
    "4861 , acm , 2010 .",
    "m.  friedewald , e.  vildjiounaite , y.  punie , and d.  wright , `` privacy , identity and security in ambient intelligence : a scenario analysis , '' _ telematics and informatics _ , vol .",
    "24 , no .  1 ,",
    "pp .  1529 , 2007 .",
    "a.  mohaisen and o.  alrawi , _ detection of intrusions and malware , and vulnerability assessment : 11th international conference , dimva 2014 , egham , uk , july 10 - 11 , 2014 .",
    "proceedings _ , ch .",
    "av - meter : an evaluation of antivirus scans and labels , pp .",
    "cham : springer international publishing , 2014 .",
    "m.  feldman , c.  papadimitriou , j.  chuang , and i.  stoica , `` free - riding and whitewashing in peer - to - peer systems , '' in _ proceedings of the acm sigcomm workshop on practice and theory of incentives in networked systems _ , pp .  228236 , acm , 2004 .",
    "c.  rossow , c.  j. dietrich , c.  grier , c.  kreibich , v.  paxson , n.  pohlmann , h.  bos , and m.  van  steen , `` prudent practices for designing malware experiments : status quo and outlook , '' in _ 2012 ieee symposium on security and privacy _ , pp .  6579 , ieee , 2012 .",
    "m.  bailey , j.  oberheide , j.  andersen , z.  m. mao , f.  jahanian , and j.  nazario , `` automated classification and analysis of internet malware , '' in _ international workshop on recent advances in intrusion detection _ , pp .  178197 , springer , 2007 .",
    "j.  canto , m.  dacier , e.  kirda , and c.  leita , `` large scale malware collection : lessons learned , '' in _ ieee srds workshop on sharing field data and experiment measurements on resilience of distributed computing systems _ , citeseer , 2008 ."
  ],
  "abstract_text": [
    "<S> threat intelligence sharing has become a growing concept , whereby entities can exchange patterns of threats with each other , in the form of indicators , to a community of trust for threat analysis and incident response . </S>",
    "<S> however , sharing threat - related information have posed various risks to an organization that pertains to its security , privacy , and competitiveness . </S>",
    "<S> given the coinciding benefits and risks of threat information sharing , some entities have adopted an elusive behavior of `` free - riding '' so that they can acquire the benefits of sharing without contributing much to the community . </S>",
    "<S> so far , understanding the effectiveness of sharing has been viewed from the perspective of the amount of information exchanged as opposed to its quality . in this paper , we introduce the notion of quality of indicators ( qoi ) for the assessment of the level of contribution by participants in information sharing for threat intelligence . </S>",
    "<S> we exemplify this notion through various metrics , including correctness , relevance , utility , and uniqueness of indicators . in order to realize the notion of qoi </S>",
    "<S> , we conducted an empirical study and taken a benchmark approach to define quality metrics , then we obtained a reference dataset and utilized tools from the machine learning literature for quality assessment . </S>",
    "<S> we compared these results against a model that only considers the volume of information as a metric for contribution , and unveiled various interesting observations , including the ability to spot low quality contributions that are synonym to free riding in threat information sharing . </S>"
  ]
}