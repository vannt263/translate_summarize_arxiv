{
  "article_text": [
    "current and future time domain optical surveys , such as the sdss stripe 82 supernova survey @xcite , palomar transient factory ( ptf , * ? ? ?",
    "* ) , the catalina real - time transient survey ( crts , * ? ? ?",
    "* ) , pan - starrs @xcite , and the large synoptic survey telescope ( lsst , * ? ? ?",
    "* ) , are providing and will provide an unprecedented flood of variability data .",
    "such data sets will number in the millions to hundreds of billions of photometric data points , providing systematic multi - wavelength variability studies for thousands to eventually billions of objects .",
    "for example , lsst will have @xmath0 trillion total measurements on @xmath1 billion objects .",
    "for many classes of astronomical sources these will be the first systematic multi - passband variability studies including large numbers of objects with well - sampled multiwavelength light curves .",
    "moreover , these rich data sets will also enable the inclusion of multi - passband variability information for distinguishing different classes of objects .",
    "data sets generated by these surveys will present many exciting opportunities , providing astrophysical insight for known classes of objects , as well as the discovery of unknown variability classes , new subclasses of known variable classes , and anomalous outliers .",
    "the central data analysis problem for extracting science from these time - domain data sets is how to quantitatively characterize the variability . for periodic signals characterizing the variability",
    "is relatively straightforward , with the period being the obvious and most important feature to use . for transient phenomenon , such as supernovae or black hole tidal disruptions ,",
    "the light curve is often characterized by fitting a parameterized deterministic model to the data , either statistical ( e.g. , splines ) or astrophysical . for quasi - periodic and stochastic light curves",
    "the variability is often characterized through the power spectral density ( psd ) .",
    "the psd is the variability amplitude per frequency , so it describes the variability power contained within a frequency interval .",
    "a similar measure that is sometimes used is the structure function , which describes the variability amplitude as a function of time scale .",
    "the variability of quasi - periodic and stochastic light curves may then be characterized by summarizing the power spectrum through a parametric form , with power - laws and sums of lorentzian functions being common choices for agn and x - ray binaries , respectively .",
    "irregular sampling or sequences of regular sampling separated by gaps are often the source of the most problematic aspects of measuring variability features from a lightcurve .",
    "unfortunately , all ground - based astronomical data and many space - based data are subject to sampling which is not strictly uniform . for periodic signals , methods have been developed to estimate periods from irregularly sampled light curves , and assess their statistical significance ( e.g. , * ? ? ?",
    "* ; * ? ? ?",
    "* ; * ? ? ?",
    "* ) ; significance tests have also been developed for periodic signals against red noise for regularly sampled light curves @xcite . for deterministic models , fitting the light curve",
    "is a traditional regression problem so the sampling pattern does not bias the results .    deriving the psd features and their uncertainties from an irregularly sampled light curve is considerably more challenging for stochastic light curves .",
    "for a regularly sampled light curve the traditional way of estimating the psd is through the discrete fourier transform of the light curve , the modulus - squared of which is called the periodogram .",
    "the periodogram suffers from biases due to the fact that it is calculated from a time series that is a sample from a continuous - time stochastic process . as a result",
    ", the sampling pattern of the light curve distorts the periodogram relative to the true psd that generated the light curve ( e.g. , * ? ? ?",
    "* ; * ? ? ?",
    "these issues similarly cause the empirical structure function to be a distorted estimate of the true structure function @xcite .",
    "this is a concern because if one does not correct for this distortion , differences in variability properties caused by vagaries of the sampling pattern could mistakenly be interpreted to have an astrophysical origin .",
    "moreover , this distortion is also a problem for classification algorithms that utilize variability information , as objects may spuriously be interpreted to belong to different variability classes simply because they have different sampling patterns .",
    "clearly this issue must be dealt with in order to take advantage of the state of the art time domain data sets .",
    "there are two primary approaches used in astronomical studies to account for irregular sampling in stochastic light curves .",
    "the first approach is to use monte carlo simulations to forward model the periodogram as a function of a model power spectrum @xcite .",
    "the approach proceeds by first simulating a large number of light curves from an assumed power spectrum , sampling them with the same pattern as the measured light curve , computing the periodogram for each down sampled simulated light curve , and averaging the simulated periodograms to create a ` model ' periodogram .",
    "the best - fit power spectrum is found by minimizing the @xmath2 between the model periodogram and the measured periodogram .",
    "moreover , confidence intervals may be estimated from the monte carlo samples .",
    "this approach is extremely flexible , but can be computationally expensive .",
    "this is especially true if there are intervals of fine sampling separated by intervals of sparse sampling , as this requires either generating a very dense light curve at the finest sampling rate , or splitting the light curve into segments and computing their periodograms separately .",
    "unfortunately , because of the computational cost , it is difficult to see how this approach can be applied to massive time domain data sets .",
    "moreover , fitting complex multi - component for even a single data set can become computationally expensive in the monte carlo forward fitting approach .",
    "the second approach to accounting for irregular sampling in stochastic light curves is to fit the light curve in the time domain .",
    "this is almost always done by assuming the light curve is a realization of a gaussian process ( e.g. , * ? ? ?",
    "* ; * ? ? ?",
    "* ; * ? ? ?",
    "* ; * ? ? ?",
    "* ; * ? ? ?",
    "* ; * ? ? ?",
    "* ; * ? ? ?",
    "* ) . in this case",
    ", the likelihood function is a multivariate normal distribution with unknown mean and covariance matrix .",
    "the covariance matrix is parameterized by the autocovariance function , which forms a fourier transform pair with the power spectrum . in this time - domain approach ,",
    "the autocovariance function is fit through maximum - likelihood or bayesian approaches , and the power spectrum is calculated from the inferred autocovariance function .",
    "the irregular sampling and measurement errors are automatically accounted for by the likelihood function .",
    "this approach is statistically powerful because of its reliance on the likelihood function , but in general is also computationally expensive . in order to calculate the multivariate gaussian likelihood function",
    "it is necessary to invert the @xmath3 covariance matrix of the light curve , where @xmath4 is the number of data points in the light curve .",
    "in general matrix inversion scales as @xmath5 , which can be prohibitive for large samples of light curves that are sampled with even moderate density .",
    "there are special classes of gaussian processes for which the computational complexity only scales linearly with the length of the light curve . for linear processes which have a ` state - space '",
    "representation ( discussed further in   [ s - statespace ] , see also * ? ? ?",
    "* ) the likelihood function can be computed using a computationally efficient ( scaling as @xmath6 ) algorithm known as the kalman filter .",
    "gaussian processes with an exponential autocorrelation fall into this class of stochastic models that have fast algorithms for computing their likelihood function @xcite .",
    "this particular process is known as both a first order continuous - time autoregressive process ( car(1 ) ) or an ornstein - uhlenbeck process , and was introduced by @xcite as a model for quasar optical light curves .",
    "subsequent work has confirmed that it provides a good description of quasar optical light curves on time scales of days to years at the level of data quality of the ogle and stripe 82 surveys @xcite .",
    "however , recent studies have found evidence for deviations from the car(1 ) model for optical light curves of agn @xcite . in addition , successful agn selection techniques have been developed based on the car(1 ) parameters @xcite .    despite its recent success ,",
    "the car(1 ) model is very simple , as it assumes a psd that is a lorentzian centered at zero .",
    "thus , there are only two free parameters in the car(1 ) model : the bend frequency of the psd ( i.e. , the width of the lorentzian ) and the normalization .",
    "this makes the model inflexible , limiting its broader use .",
    "in this paper we overcome the inflexiblity of the car(1 ) model and present the general class of continuous time autoregressive moving average ( carma ) models .",
    "carma models are generated by adding higher order derivatives to the stochastic differential equation that defines the car(1 ) processes .",
    "the special case of a car(@xmath7 ) process is discussed by @xcite , who applied it to the light curves for two variable stars .",
    "the psd of a carma process is a sum of lorentzian functions , with the free parameters being the centroid , widths , and normalizations of the lorentzian functions .",
    "this provides a significant amount of flexibility in modeling the psd , making carma modeling applicable to many classes of astronomical variables .",
    "moreover , carma models have a state space representation , enabling the use of the kalman filter for calculating their likelihood function . because of this , the computational complexity of calculating the likelihood function for carma models still scales linearly with the number of data points in the light curve , making them scalable to massive time domain data sets .",
    "the format of this paper is as follows . in   [ s - carma_def ]",
    "we begin by defining the carma process via a stochastic differential equation , present the psd of a carma process , and present the autocovariance function of a carma process .",
    "then , in   [ s - statespace ] we express the carma process using a continuous - time state space representation and use this representation to derive the solution to the stochastic differential equation defining the process .",
    "this solution forms the basis for the statistical properties of a carma process sampled at a set of observational times , which are necessary for fitting the carma process parameters to a measured time series . in   [ s - inference ] we present the likelihood function for a sampled carma process , and in   [ s - likelihood ] present an efficient algorithm for computing the likelihood function based on the kalman filter . in order to derive the kalman filter for a carma process",
    "it is necessary to obtain a discrete - time state space representation of the sampled process , and we begin ",
    "[ s - likelihood ] by using the results of   [ s - statespace ] to present this discrete time representation .",
    "we extend these results in ",
    "[ s - interpolation ] and derive an algorithm for efficiently performing interpolation and extrapolation from a measured time series assuming a carma model . in ",
    "[ s - bayes ] we describe bayesian inference for the carma model , including our adopted prior distribution , in ",
    "[ s - assess_fit ] we describe how to assess the quality of fit based on the carma model , in   [ s - order ] we discuss how to choose the order of the carma model , and in ",
    "[ s - computation ] we discuss computational aspects related to fitting the carma model to a measured time series . in ",
    "[ s - simulations ] we illustrate statistical inference under a carma model on two simulated lightcurves , and in   [ s - applications ] we apply the carma model to astronomical lightcurves from an x - ray binary , agn , and periodic variable stars . in   [ s - discussion ]",
    "we discuss our results , and provide directions for future development .",
    "in this section we introduce the important mathematical properties of the carma(p , q ) process , including its definition , psd , autocovariance function , and solution .",
    "further details may be found in , e.g. , @xcite , @xcite , @xcite , @xcite , and @xcite .",
    "a zero - mean carma(p , q ) process @xmath8 is defined to be the solution to the stochastic differential equation @xmath9 here , @xmath10 is a continuous time white noise process with zero mean and variance @xmath11 .",
    "in addition , we define @xmath12 and @xmath13 = 1 .",
    "the parameters @xmath14 are the autoregressive coefficients , and the parameters @xmath15 are the moving average coefficients . for the process to be stationary ,",
    "it is necessary that @xmath16 and that the roots @xmath17 of the autoregressive polynomial @xmath18 have negative real parts .",
    "in addition , the process has ` minimum phase ' when the roots of the moving average polynomial have non - positive real parts .",
    "if the carma process is minimum phase , this basically means that we can uniquely determine the values of the input white noise process from the output carma process .    a stationary carma(p , q ) process has the psd @xmath19 and autocovariance function at lag @xmath20 @xmath21 \\left[\\sum_{l=0}^q \\beta_l ( -r_k)^l \\right ] \\exp(r_k \\tau ) }          { -2 \\operatorname{re}(r_k ) \\prod_{l=1 , l \\neq k}^p ( r_l - r_k)(r^*_l + r_k ) } .      \\label{eq - carma_autocovar}\\ ] ] here , @xmath22 denotes the real part and @xmath23 is the complex conjugate of @xmath24 . in this work we only deal with the case when the roots are unique , as this",
    "is required in order to use the kalman filter to efficiently calculate the likelihood ( see   [ s - likelihood ] ) .    most previous work on using continuous - time autoregressive processes for characterizing astronomical time series",
    "has focused on the case when @xmath25 and @xmath26 , i.e. , a car(1 ) model .",
    "the car(1 ) model is also called an ornstein - uhlenbeck process , and has often been referred to as a ` damped random walk ' in the astronomical literature . using the notation above , the psd and autocovariance for the more familiar case of @xmath27 are , respectively , @xmath28 and @xmath29 as can be seen , the psd for the car(1 ) process is a lorentzian function centered at zero with a break frequency at @xmath30 , while the autocorrelations decay exponentially with an @xmath31-folding time scale @xmath32",
    ".    inspection of the autocovariance function and psd of a carma(p , q ) process provides some guidance on how to interpret the carma(p , q ) parameters . for",
    "the carma(p , q ) process the autocorrelation function is a weighted sum of exponential functions , with the arguments of these exponential functions being the roots of the polynomial given by equation ( [ eq - characteristic ] ) and the weights being a function of the moving average coefficients .",
    "these roots may be complex - valued , although if @xmath7 is odd there is always at least one real root . as a result ,",
    "the autocorrelation function for the carma(p , q ) process is a sum of exponentially damped sinusoidal functions ( corresponding to the complex roots ) and exponential decays ( corresponding to the real roots ) .",
    "the @xmath31-folding time scale of the decaying autocorrelations for each exponential function is @xmath33 , while the frequencies of the oscillations in the autocorrelations are @xmath34 .",
    "because the psd and the autocovariance function are a fourier transform pair , we can also connect the roots of @xmath35 to the psd . because the fourier transform of an exponentially damped sinusoidal function is a lorentzian function , the psd of a carma(p , q ) process can be expressed as a weighted sum of lorentzian functions .",
    "the widths of the lorentzian functions are proportional to @xmath36 while the centroids of the lorentzian functions are given by @xmath37 . as with the autocovariance function , the moving average coefficients @xmath15 help control the weights in the sum . incidentally ,",
    "a sum of lorentzian functions is a common model used to characterize the x - ray psds of x - ray binaries ( e.g. , * ? ? ?",
    "* ; * ? ? ?",
    "the solution to equation ( [ eq - carma ] ) may be obtained by introducing a state space representation of a carma(p , q ) process ( e.g. , * ? ? ?",
    "in addition , as discussed in section [ s - likelihood ] , representing a carma(p , q ) process in a state space representation enables efficient calculation of the likelihood function for a measured time series .",
    "a state space representation models a stochastic process as arising from an observation equation and a state equation .",
    "the observation equation relates the observed time series to an unknown latent state variable , and the state equation describes the evolution of the state variable .",
    "note that the state variable will in general not be scalar - valued . for the carma(p , q ) model ,",
    "the @xmath7-element state vector @xmath38 is a vector containing the value of a latent process @xmath39 and its derivatives as a function of time @xmath40 : @xmath41 the state space representation of a carma(p , q ) process @xmath8 is @xmath42 where @xmath43 is a wiener process , @xmath44 is a white noise process with mean zero and unit variance , @xmath45 $ ] is a @xmath7-element row vector , @xmath46 for @xmath47 , @xmath48^t$ ] is a @xmath7-element column vector , and @xmath49 is a @xmath50 matrix with elements @xmath51    the solution to equation ( [ eq - state_equation ] ) with random initial condition @xmath52 is ( e.g. , * ? ? ?",
    "* ) @xmath53 the first term on the right hand side represents the deterministic contribution to the evolution of the state vector , given the initial condition , while the second term on the right hand side is a random variable representing the stochastic contribution to this evolution . note that because @xmath54 has an expectation value of zero , the stochastic integral in equation ( [ eq - carma_solution ] ) also has an expectation value given by the zero vector",
    "the process given by the solution to equation ( [ eq - carma_solution ] ) is stationary if and only if @xmath55 has an expectation value given by the zero vector and @xmath50 covariance matrix with elements @xcite @xmath56 in this case , the stationary mean of @xmath38 is also the zero vector and the stationary covariance is also given by equation ( [ eq - state_covar ] ) . because @xmath38 is stationary , the carma process defined by equation ( [ eq - obs_equation ] ) is also stationary with mean zero and variance @xmath57 ; note that this is the same as that given by equation ( [ eq - carma_autocovar ] ) using a time lag of @xmath58 .",
    "if the white noise term in equation ( [ eq - carma ] ) is gaussian , the resulting carma(p , q ) process is also gaussian . in this case , the likelihood function for a carma(p , q ) model may be derived for a measured time series @xmath59^t$ ] sampled at times @xmath60 as @xmath61 where @xmath62 is the mean of the time series , @xmath63 , @xmath64 is the kronecker delta function , @xmath65 is the variance in the measurement error for @xmath66 , and @xmath67 is the autocovariance function of a carma(p , q ) process , given by equation ( [ eq - carma_autocovar ] ) .",
    "note that here and throughout this work we assume that the measurement errors on the time series are uncorrelated .",
    "maximum - likelihood estimates of the parameters @xmath68 and @xmath69 may be obtained by maximizing equation ( [ eq - likhood_slow ] ) , and bayesian inference may be performed by combining equation ( [ eq - likhood_covar ] ) with a suitably chosen prior .    calculating equation ( [ eq - likhood_slow ] )",
    "directly requires inverting the @xmath3 covariance matrix @xmath70 , the computational complexity of which scales as @xmath5 .",
    "this may represent a considerable bottleneck for large time series , especially when performing statistical inference for a large sample of objects .",
    "fortunately , the state space representation of a carma(p , q ) process enables application of the kalman filter , which speeds up calculation of the likelihood function to @xmath6 operations .      for state space models of gaussian processes , such as that described by equations ( [ eq - obs_equation])([eq - state_equation ] ) , the kalman filter algorithm may be used to sequentially and efficiently calculate the mean and covariance of the next state and observation of a sampled process given the previous values and the model parameters ( e.g. , * ? ? ?",
    "because a normal distribution is completely characterized by its mean and covariance , this is all that we need to calculate the likelihood function for a measured time series .",
    "we factor the likelihood as @xmath71 for a gaussian carma(p , q ) model each of the terms on the right hand side of equation ( [ eq - factored_likhood ] ) are normal distributions : @xmath72 here we have used the notation @xmath73 $ ] .",
    "the kalman filter is used to calculate the means and variances for each of these normal distributions , efficiently calculating the likelihood in @xmath6 operations .",
    "because astronomical time series are measured with error , we introduce a measurement error term to the observation equation of the state space representation , modifying equation ( [ eq - obs_equation ] ) to become @xmath74 the measurement error for @xmath66 , @xmath75 , is assumed to be normally distributed with mean zero and variance @xmath76",
    ". equations ( [ eq - obs_equation2 ] ) and ( [ eq - state_equation ] ) are a state space representation for a time series measured with error assuming a carma(p , q ) model .    in order to use the kalman filter for a sampled continuous time process",
    ", it is necessary to convert the continuous time state space representation to that of a discrete time process evaluated at the sampled time values .",
    "this requires integrating the state equation ( eq.[[eq - state_equation ] ] ) over the time intervals between subsequent observations .",
    "the discrete state space representation of a carma process sampled at times @xmath77 is derived using equation ( [ eq - carma_solution ] ) ( e.g. , * ? ? ?",
    "* ) to be @xmath78 where @xmath79 denotes the normally distributed measurement error at @xmath80 with mean zero and variance @xmath81 and @xmath82 is a random vector drawn from a multivariate normal distribution with mean given by the zero vector and covariance matrix ( e.g. , * ? ? ?",
    "* ) @xmath83 equations ( [ eq - discrete_obs_equation])([eq - discrete_error_covar ] ) provide everything we need to compute the kalman filter and the likelihood function for a carma model .",
    "calculation of the matrix exponentials needed in equations ( [ eq - discrete_state_equation ] ) and ( [ eq - discrete_error_covar ] ) is computationally expensive .",
    "however , for diagonal matrices the matrix exponential is trivial to calculate . in order to improve the efficiency of the kalman filter we use the diagonal form",
    "@xmath84 @xcite , where the columns of @xmath85 contain the right eigenvectors of @xmath49 and @xmath86 is a diagonal matrix : @xmath87 recall that @xmath88 are the roots of the autoregressive polynomial .",
    "we then transform equations ( [ eq - discrete_obs_equation ] ) and ( [ eq - discrete_state_equation ] ) to be in terms of the rotated state vectors @xmath89 : @xmath90 here @xmath91 is a diagonal matrix with diagonal elements @xmath92 , and @xmath93 . the stochastic term in the rotated state space formulation , @xmath94 , is a complex valued normally distributed random variable with mean given by the zero vector and hermitian covariance matrix .",
    "the elements of the covariance matrix of @xmath94 are not actually needed for the kalman filter ( e.g. , * ? ? ?",
    "* ) in our implementation , but they are given in @xcite .",
    "we note that the variables in the rotated state space notation are complex - valued , although they are all real - valued in the original representation .",
    "@xcite derived the kalman filter for a car(p ) model under the rotated state representation , and @xcite extended these results to a carma(p , q ) model . in   [ s - kfilter ] of the appendix we provide the kalman filter algorithm for a carma(@xmath95 ) model , and refer the reader to @xcite and @xcite for further details . after running the kalman filter",
    ", we will have the values of @xmath96 and @xmath97 needed for computing the likelihood function via equation ( [ eq - likhood ] ) .      in certain applications",
    "one may need to simulate an interpolated or extrapolated time series conditional on a measured time series .",
    "example of this include reverberation mapping of agn @xcite or studies of the time delay between images of gravitationally lensed quasars ( e.g. , * ? ? ? * ; * ? ? ? * ; * ? ? ? * ) .",
    "in addition , forecasting may also be useful for generating alerts .",
    "the probability distribution of a gaussian carma process at time @xmath98 given the measured time series is a normal distribution , and one can use the usual gaussian process machinery to calculate the conditional mean and variance of future data . however , as with the likelihood calculation this is expensive , also requiring an expensive matrix inversion .",
    "instead , for a carma process we can use the kalman filter to efficiently calculate the mean and variance of this normal distribution , and in this section we derive these quantities .",
    "denote the value of a carma process at time @xmath98 as @xmath99 , and define @xmath100 , i.e. , @xmath101 .",
    "assuming a gaussian carma process , we can write the probability distribution of @xmath99 given a carma model and a measured time series @xmath102 as @xmath103 as before , @xmath104 . the values of @xmath105 and @xmath106 can be obtained by running the kalman filter on the time series generated by inserting @xmath98 into the set of observation times @xmath80 .",
    "the sets of coefficients @xmath107 and @xmath108 can be obtained recursively through an algorithm similar to the kalman filter , which we describe in ",
    "[ s - coefs ] of the appendix .",
    "from equation ( [ eq - linear_filter ] ) we can derive the mean and variance of @xmath99 as @xmath109 \\label{eq - predicted_cmean } \\\\",
    "var(y_0|{\\bf y},\\theta ) & = \\left [ \\frac{1}{var(y_0|{\\bf y}_{<j(t_0)},\\theta ) } \\right .",
    "\\nonumber \\\\      & \\left .",
    "+ \\sum_{i = j(t_0)}^n \\frac{\\tilde{d}^2_i}{var(y_i|y_0,{\\bf y}_{<i } , \\theta ) } \\right]^{-1 } \\label{eq - predicted_cvar}.\\end{aligned}\\ ] ] equations ( [ eq - predicted_cmean ] ) and ( [ eq - predicted_cvar ] ) provide the interpolated or extrapolated value and its uncertainty , assuming the carma model .",
    "note that for forecasting and backcasting , the first and second terms appearing in the right hand sides of equations ( [ eq - predicted_cmean ] ) and ( [ eq - predicted_cvar ] ) are ignored , respectively .",
    "an interpolated or extrapolated time series may be simulated sequentially at time values @xmath110 by first using equations ( [ eq - predicted_cmean ] ) and ( [ eq - predicted_cvar ] ) to generate a value of @xmath111 from a normal distribution , inserting this value of @xmath111 into the measured time series array , and repeating for the remaining @xmath112 .      in this work",
    "we focus on bayesian inference of the carma process model .",
    "this is primarily because in bayesian inference one derives the probability distribution of the carma process given the measured time series ( i.e. , the ` posterior ' distribution ) , providing a rigorous assessment of the uncertainties in the carma model , and consequently in the inferred power spectrum .",
    "the likelihood function of a carma model can exhibit multiple maxima for @xmath113 ( e.g. * ? ? ?",
    "* ) , and therefore traditional techniques based on the fisher information matrix and the asymptotic normality of the maximum likelihood estimate do not apply in general for carma models .",
    "bayesian inference is based on the posterior distribution , which is related to the likelihood function by the equation @xmath114 here , @xmath115 is the prior distribution on the model parameters . because we have already derived the likelihood function , the only additional thing we need to do to perform bayesian inference is to specify the prior distribution . in our model",
    "we assume a uniform prior on the standard deviation of the lightcurve subject to @xmath116^{1/2 } < r_0 $ ] for some input value of @xmath117 and a uniform prior on @xmath62 . in this work we set @xmath117 to be ten times the standard deviation of the measured time series .",
    "following @xcite , we use the following parameterization for @xmath118 : @xmath119 the roots of the autoregressive polynomial will have negative real parts ( and thus produce a stationary carma process ) if and only if @xmath120 are positive . in order to enforce this",
    ", we sample the values of @xmath121 in our mcmc sampler , and place a uniform prior on their values . using",
    "the parameterization of equation ( [ eq - alpha_parameterization ] ) also has the computational convenience that the roots may be analytically computed from the quadratic and linear terms .",
    "in addition , we use a similar parameterization and prior for the moving average coefficients , @xmath69 .",
    "this parameterization of the moving average coefficients enforces the system to be minimum phase by keeping the roots of the moving average polynomial positive .",
    "because the likelihood function is invariant to permutations of the indices of @xmath122 , we place the following ordering constraint on the indices in order to make the model identifiable : @xmath123 the constraints are only with respect to the pairs @xmath124 for @xmath125 odd because the roots come in complex conjugate pairs .",
    "finally , we also constrain the lorentzian centroid values to be less than the inverse of the minimum time between measurements , and the lorentzian widths to be between the minimum and maximum frequencies probed by the light curve time sampling .    in practice",
    ", we include an additional scaling parameter on the measurement errors , @xmath126 , such that the true measurement error variances are assumed to be @xmath127 .",
    "because the derived psd depends on the amplitude of the measurement errors , especially at the high - frequency end , we include this additional parameter to incorporate uncertainty on the quoted measurement error variances @xmath65 .",
    "our prior on the parameter scaling parameter @xmath126 is a scaled inverse @xmath2 distribution with 50 degrees of freedom and scale parameter of unity .",
    "in addition , we bound the value to be @xmath128 .",
    "this prior reflects an assumption that the relative amplitude of the measurement errors are correct , but that the overall normalization of the measurement error standard deviations @xmath129 has an uncertainty of @xmath130 .",
    "this is application dependent , and researchers analyzing time series for which they have greater confidence in the quoted measurement error amplitudes may wish to use a much larger value than 50 degrees of freedom , or narrower bounds on @xmath126 .",
    "the quality of the fit , and the appropriateness of the gaussian carma model , can be assessed by noting that the standardized residuals , @xmath131 , from the kalman filter should have the form of gaussian white noise .",
    "the standardized residuals are calculated as @xmath132^{1/2 } } ,      \\label{eq - standard_resids}\\ ] ] where @xmath133 is a point estimate of @xmath134 . when inspecting the residuals we have found that it is best to use for @xmath133 the value of @xmath134 obtained from maximizing the posterior or likelihood .",
    "as discussed in   [ s - computation ] , the posterior for the carma model parameters can be multi - modal , especially for high values of @xmath7 or @xmath135 , and the carma process implied by the posterior median or mean may not be representative if these quantities fall between the modes .",
    "if the gaussian carma model is correct , then the residuals should have a normal distribution with mean zero and standard deviation of unity .",
    "deviations from the expected normal distribution can be used to assess the assumption of a gaussian process .",
    "similarly , the sequence @xmath136 should form a gaussian white noise sequence , the accuracy of which can be assessed through the autocorrelation function of the standardized residuals . under the null hypothesis that the sequence @xmath137 are a white noise sequence ,",
    "their sample autocorrelations are approximately independently and normally distributed with mean zero and variance @xmath138 .",
    "if a large number of the sample autocorrelations are outside of the , say , @xmath139 interval then there is residual correlation structure in the time series that the carma models is not picking up . finally , the sequence of squared residuals @xmath140 should also form a white noise sequence under the assumption of a gaussian carma model . therefore , deviations of the sample autocorrelations of the sequence @xmath140 from a zero mean normal distribution with variance @xmath141 signal non - linear behavior , as they indicate that the variance in the time series is changing with time . note that in both these cases it is the acf of the sequence of residuals that is calculated , and not the time series of residuals . in other words , we calculate the acf of the residuals treating their time values as being on a regular grid : @xmath142 .",
    "there are multiple approaches to choosing the order of the carma model .",
    "first , it is often the case that traditional methods based on statistical hypothesis testing are not optimal for flexible models such as the carma model .",
    "for one , carma models are not nested because a car(@xmath143 ) model can not be obtained by setting @xmath144 in a car(@xmath7 ) model to some finite value .",
    "therefore , the usual asymptotic assumptions underlying the likelihood ratio test do not apply .",
    "an exception is the transformed car model presented by @xcite , which does provide a sequence of nested models .",
    "second , choosing the order of the carma model is more of a model _ selection _ issue , and should not be framed within the context of ruling out a null hypothesis . for many applications the carma parameters will not have any specific physical meaning , so there will not be any physically meaningful null hypothesis . instead",
    ", in time series analysis it is common to choose the order of the model to be that which best predicts additional data ( i.e. , minimizes the test error ) , or otherwise is ` close ' to the process that generated the data . because we are interested in using the carma model to adequately and flexibly constrain the psd and correlation structure in the time series , as well as to provide automatic variability features that may be used , e.g. , for classification , our approach is to choose the @xmath7 and @xmath135",
    "that minimize an estimate of how close the carma(@xmath95 ) model is to the data generating process .",
    "information criteria are a common mechanism for ranking a set of models .",
    "such criteria are often used as approximations to the prediction error of future data , and are usually inexpensive to calculate . in time",
    "series analysis it is common to use the akaike information criterion ( aic , * ? ? ?",
    "* ) , which is based on the maximum - likelihood estimate of @xmath134 .",
    "the aic provides an estimate of the relative information lost in using a model to represent the underlying process that generated the data , as measured through the kullback - leibler divergence .",
    "the aic in its original form is strictly only valid asymptotically , but @xcite provide a correction to aic for finite sample sizes ( denoted as aicc ) .",
    "an alternative bayesian criteria is the deviance information criterion ( dic , * ? ? ?",
    "* ) , which may be calculated from the samples returned by a mcmc sampler .",
    "cross - validation is another approach for choosing @xmath7 and @xmath135 , as it provides an estimate of the test error .",
    "cross - validation works by dividing the light curve into @xmath145 contiguous subsamples , fitting the model to the data after removing one of the subsamples , evaluating the model performance on the withheld subsample , and repeating the for the remaining @xmath146 subsamples .",
    "the errors on the withheld subsamples are averaged , and @xmath147 can be chosen to minimize this error .    because it is more expensive to run independent mcmc samplers than to obtain a maximum - likelihood estimate for each set of candidate @xmath147 values , we use the aicc instead of dic to choose the order of the carma model .",
    "similarly , because it is expensive to perform a fit to each of the @xmath145 subsamples generated by cross - validation we use aicc in this work . the aic is defined as @xmath148 where @xmath125 is the number of parameters in the carma(@xmath95 ) model , and @xmath149 is the maximum - likelihood estimate of the carma process parameters , @xmath134 .",
    "the best model is the one that minimizes the aic .",
    "the aic penalizes against overfitting through the @xmath150 term : once the improvement to the log - likelihood function that results from using a more complex model does not increase faster than the number of parameters , the aic will begin to worsen .",
    "the aicc is @xmath151 where @xmath4 is the number of data points in the lightcurve .",
    "the aicc places a stronger penalty for model complexity due to the finite sample correction .",
    "finally , we note that in certain cases it is scientifically meaningful to assess the significance of a specific feature in the psd .",
    "for example , carma models selected based on aicc to have @xmath113 may show evidence for quasi - periodic oscillation ( qpo ) features in the psd . these features in , for example",
    ", light curves from black hole systems are thought to be driven by astrophysical phenomenon in accretion flows ( e.g. , * ? ? ?",
    "* ) , and therefore in this case there is a scientifically meaningful null hypothesis . for such situations one needs to assess the statistical significance of these features , even if their existence provides a better aicc .",
    "this can be done by inspecting the posterior distribution of the feature of interest for the chosen model ( e.g. , the one with the minimum aicc ) . to use the qpo example ,",
    "the coherence of a qpo is often quantified via a ` quality factor ' , which is the ratio of peak frequency of the qpo to its width .",
    "the ` statistical significance ' , or , more importantly , the scientific significance of a possible qpo feature could be assessed by inspecting the posterior distribution of the qpo quality factor .",
    "if most of the posterior probability is at high quality factors , then one may be confident in the existence of this qpo ( assuming the carma model has been shown to be accurate , see ",
    "[ s - assess_fit ] ) .",
    "otherwise , if most of the probability in the quality factor is at low values , then this ` qpo ' feature may not be scientifically meaningful even if its inclusion still provides a more accurate model .      the computational complexity of evaluating the likelihood function using the kalman filter scales as @xmath6 for a time series with @xmath4 data points .",
    "unfortunately , because the kalman filter is a serial calculation it can not be parallelized .",
    "for our mcmc sampler we use the robust adaptive metropolis algorithm of @xcite with a student s @xmath40-distribution with eight degrees of freedom as the proposal distribution .",
    "the algorithm of @xcite improves upon the standard metropolis algorithm by adaptively tuning the covariance matrix of the proposals to achieve a desired acceptance rate ; in this work we use an acceptance fraction of 25% .",
    "we only adapt the proposals during the burn - in phase .    for @xmath113",
    "the likelihood function often contains multiple modes , especially for higher orders of @xmath7 and @xmath135 .",
    "this presents a difficulty for many optimizers and mcmc samplers .",
    "when computing the maximum - likelihood estimates we run a local optimization algorithm using 100 random starting values of @xmath134 , and choose the best @xmath149 among the outputs .",
    "while there is no guarantee that this approach will find the global optimum , we have found it to be sufficient for the purposes of choosing the values of @xmath7 and @xmath135 via the aicc .",
    "further improvement may be obtained through the use of , for example , genetic algorithms .    in order to effectively sample the posterior for @xmath113",
    ", we also employ parallel tempering in our mcmc sampler ( e.g. , * ? ? ?",
    "* ) . in our parallel temperating implementation @xmath145 parallel chains",
    "are run using their own robust adaptive metropolis algorithm , where the @xmath152 chain samples from the distribution @xmath153 , and the sequence @xmath154 forms what is known as a ` temperature ladder ' ; note that @xmath155 .",
    "denote the value of the carma model parameters for the @xmath152 chain as @xmath156 .",
    "after each chain updates their parameters via the @xcite metropolis step , we then propose to swap values the values of @xmath156 and @xmath157 for @xmath158 .",
    "the purpose of the temperature ladder is to flatten the posterior distribution for larger values of @xmath159 , enabling the chains to move between modes in the ` hot ' chains .",
    "the swapping step then allows the coolest chain , which is the one we actually care about , to jump between modes when the hotter chains find these modes .",
    "we use a temperature ladder that forms a regular grid in @xmath160 , with @xmath161 .",
    "in general we have found that values of @xmath162 are sufficient .",
    "although we do not do so in our code , the parallel tempering algorithm is parallelizable .",
    "further details on parallel tempering , and mcmc methods in general can be found in @xcite .",
    "we have developed software to run our mcmc algorithm on a time series , assuming the carma model .",
    "the software is written in a combination of c++ and python , with the c++ code forming a python extension .",
    "the mcmc sampler is written in c++ for speed , but may be called from within python , enabling one to analyze the results within python .",
    "the python component of our software also contains a routine for computing the maximum - likelihood estimate of @xmath134 ( although the likelihood calculations are done in c++ ) , choosing the order of the carma model via aicc , and routines for analyzing the mcmc output .",
    "our software is available at https://github.com/bckelly80/carma_pack .",
    "in order to illustrate the use of carma models for analysis of astronomical time series , we generated a mock light curve from a carma(5,3 ) process under both regular and irregular sampling , and a non - stationary irregularly sampled light curve that switches from one carma(5,3 ) process to another .",
    "for the first light curve we simulated a carma(5,3 ) process sampled on a regular grid @xmath163 days .",
    "the carma(5,3 ) parameters were chosen to ensure that the mock light curve was dominated by broad - band noise , as with , for example agn .",
    "the psd for this light curve is flat on time scales @xmath164 days , falls off as @xmath165 for frequencies corresponding to time scales @xmath166 days , and steepens to @xmath167 for frequencies corresponding to time scales @xmath168 days .",
    "in addition , there is a weak qpo centered at a frequency of @xmath169 .",
    "the measurement noise level for this source was chosen to be just below the magnitude of the qpo , in order to test if we can recover an oscillatory feature at the limit of the measurement noise .",
    "the mock light curve is shown in figure [ f - mock1_lcurve ] , and the psd for this light curve is shown in figure [ f - mock1_psd ] .",
    "note that the measurement error in this case is only @xmath170 of the standard deviation in the light curve .",
    "in addition , because the light curve is regularly sampled we also show its periodogram in figure [ f - mock1_psd ] .",
    "the qpo feature appears but is not obvious above the measurement noise component of the periodogram , although one may suspect its existence through visual inspection .    ]    .",
    "the true psd is given by the solid black line , the periodogram by the orange circles , the psd from the maximum - likelihood estimate assuming a carma(5,1 ) model ( chosen to minimize aicc ) by the blue dashed line , and the blue region contains @xmath171 of the probability on the psd assuming a carma(5,1 ) model .",
    "there is a weak oscillatory feature centered at a frequency of @xmath172 which is at the measurement noise level .",
    "this feature is not obvious above the measurement error component for the periodogram , but the carma model is able to recover it , along with the rest of the psd .",
    "we note that the tight errors on the psd below the measurement noise level are due to extrapolation assuming the parametric form of carma(5,1 ) model , and using a higher order model would enable more flexibility , and consequently broader errors below the measurement noise level .",
    "[ f - mock1_psd ] ]    we searched for models of the form carma(@xmath95 ) for @xmath173 . for each value of @xmath147",
    "we computed a maximum - likelihood estimate , which we then used to compute the aicc .",
    "the values of aicc as a function of @xmath7 and @xmath135 are shown in figure [ f - mock1_aicc ] .",
    "the aicc drops off rapidly down to @xmath174 , after which it levels off .",
    "the minimum aicc is obtained for @xmath175 and @xmath176 , although models with @xmath177 provide comparable quality . as discussed in ",
    "[ s - order ] , the fact that the aicc chose a model with @xmath178 even though the true model is @xmath179 implies that the difference in log - likelihood between the two models was not sufficiently large to warrant the inclusion of the additional parameters required under the carma(5,3 ) model .",
    "however , because the aicc depends on the data , it can change for different realizations from the same stochastic process .",
    "because of this , different simulations of the carma(5,3 ) light curve may result in different values of @xmath95 for which the aicc is minimized .",
    "using the values of @xmath180 , we ran our mcmc sampler using 10 parallel chains for @xmath181 iterations , discarding the first @xmath182 as burn - in .",
    "the residuals calculated using the best - fit carma(5,1 ) model were consistent with a unit variance gaussian white noise sequence , suggesting that the carma(5,1 ) model provides an adequate fit .    in figure [ f - mock1_psd ]",
    "we show the maximum - likelihood estimate of the model psd and the region containing @xmath171 of the probability on the psd .",
    "the chosen carma(5,1 ) model recovers the psd , including the qpo feature , the centroid of which corresponds to an estimated time scale of @xmath183 days .",
    "note that the tight constraints on the psd below the noise level are caused by extrapolation of the carma(5,1 ) model form , and are not reflective of the actual uncertainty on the psd in this regime when one does not know the order of the carma process . because the psd is largely unconstrained below the measurement noise level",
    ", the uncertainties would be larger in this regime if we had used a larger value of @xmath7 .     for carma(@xmath95 ) models of order @xmath184 .",
    "the minimum aicc is achieved for the values @xmath185 although there is little change in the aicc for models of order @xmath177 .",
    "[ f - mock1_aicc ] ]      for our second simulated light curve , we used a carma(5,3 ) process but with different parameters , as well as a sampling pattern and measurement errors that are more realistic of an actual optical light curve .",
    "we simulated three observing seasons of 90 epochs separated by 180 days with time spacing drawn from a uniform probability distribution over 1 to 3 days .",
    "the measurement error standard deviations were set to @xmath186 of the standard deviation in the light curve . in this case",
    "we used a psd that has a strong oscillator mode centered at a frequency of @xmath187 ; this type of psd is more representative of certain types of variable stars . as with the first simulated light curve , there is a weak oscillatory feature at @xmath172 , but in this case the feature falls primarily below the measurement noise level .",
    "the simulated light curve is shown in figure [ f - mock2_lcurve ] , and its psd is shown in figure [ f - mock2_psd ] .",
    "note that because this light curve is irregularly sampled , we do not compute a periodogram due to distortions caused by the sampling pattern .",
    "error bands of the interpolated and extrapolated light curve , given the measured light curve .",
    "[ f - mock2_lcurve ] ]    , with symbols the same as for figure [ f - mock1_psd ] .",
    "the constraints on the psd are given by a @xmath180 model .",
    "a @xmath180 model was found to have the minimum aicc and is sufficient to capture the variability characteristics above the measurement noise .",
    "[ f - mock2_psd ] ]    we ran our mcmc sampler on the second light curve using the same configuration as for the first .",
    "the aicc values are shown in figure [ f - mock2_aicc ] . in this case , the @xmath180 model was chosen as having the best aicc .",
    "the @xmath171 probability bounds on the psd based on the carma(5,1 ) model are also shown in figure [ f - mock2_psd ] .",
    "the carma(5,1 ) model is able to recover the psd above the measurement noise level .",
    "the high - frequency oscillatory feature may be encompassed in the probability contours derived from a higher order carma process , however a ` detection ' of this feature would not be possible . in an actual analysis",
    "one would in general not have knowledge of the psd below the measurement noise level , so we consider it best practice to use the simplest model that adequately describes the variability features above the measurement noise level .     for carma(@xmath95 ) models of order @xmath184 .",
    "the minimum aicc is achieved for a value of @xmath180 , although the aicc curve is fairly flat for @xmath188 .",
    "[ f - mock2_aicc ] ]    finally , as an illustration for applications where one may desire interpolated or forecasted values of a lightcurve , in figure [ f - mock2_lcurve ] we also show the interpolated and forecasted values of the simulated lightcurve , along with their @xmath189 uncertainties , based on the best - fit carma(5,1 ) model .",
    "these quantities provide a means of simulating realizations of the light curve at these time points , conditional on the measurement light curve , as described in ",
    "[ s - interpolation ] .      in order to illustrate what a carma model fit would look like for a non - stationary process",
    ", we simulated a light curve that switches from one carma process to another .",
    "in reality the behavior of a carma model fit to a non - stationary process will depend on the nature of the non - stationarity , and this simple illustration is meant to provide some qualitative insight into how non - stationarity affects the inferred psd .",
    "moreover , we also note that non - stationarity could be modeled by allowing the carma process parameters to change with time .",
    "we constructed a non - stationary light curve by generating two separate light curves with the same sampling scheme as for the stationary irregularly sampled light curve above .",
    "for the first process we used the carma parameters from ",
    "[ s - stationary_irregular ] , while for the second we used the parameters from   [ s - stationary_regular ] .",
    "in addition , the variance of the latter carma process was set to be twice that of the former .",
    "we constructed a non - stationary light curve by setting the first half to the former process , and the second half to the latter process .",
    "the light curve is shown in figure [ f - nonstationary ] .    .",
    "b ) standardized residuals ( data points ) and their distribution ( blue histogram ) , compared with the expected standard normal distribution ( orange line ) .",
    "there is no evidence for a deviation from a gaussian carma process for this light curve .",
    "c ) and d ) autocorrelation functions of the standardized residuals ( bottom left ) and their square ( bottom right ) , compared with the 95% confidence region assuming a white noise process ( shaded region ) .",
    "there is no evidence that the residuals deviate from a white noise sequence , suggesting that the carma model has adequately captured the correlation structure in the light curve .",
    "[ f - nonstationary ] ]    minimizing the aicc chose a carma(5,2 ) model .",
    "the fit quality is shown in figure [ f - nonstationary ] and the psd is shown in figure [ f - nonstationary_psd ] .",
    "based on distribution and acf of the residuals there is no statistically significant evidence for a deviation from a single carma process for this light curve , suggesting that non - stationarity may be difficult to detected using these diagnostics , at least at this data quality .",
    "the inferred psd is a blend of the two separate carma processes , picking up the dominant sources of variability . in particular",
    ", the psd picks up the strong qpo present in the first half of the lightcurve , and large amount of broad - band variability power at the longest time scales present in the second half of the light curve .",
    "this is , in a sense , because these features have the strongest ` signal - to - noise ' ratio , as their variability amplitude and frequency distribution is most distinguished from the measurement noise and is constrained by the frequency range probed by the sampling pattern . from this",
    "we infer that the inferred psd for a non - stationary light curve will be a weighted average of a time - varying psd over the observing period of a light curve , where the weights are strongest for psds and frequencies that have the highest signal - to - noise .    .",
    "the blue region contains @xmath171 of the posterior probability , the solid line shows the psd for the first half of the light curve , and the dashed line shows the psd for the second half of the light curve . the constraints on the psd are given for a @xmath190 model .",
    "the inferred psd assuming the stationary carma model is a blend of the two true psds , picking up both the strong qpo present in the first half of the light curve and the strong low - frequency broad - band noise in the second half of the light curve .",
    "[ f - nonstationary_psd ] ]",
    "in this section we illustrate the application of carma models to a variety of astronomical variables , including an x - ray lightcurve of x - ray binaries , optical light curves of agn , optical lightcurves of two variable stars .      .",
    "the constraints on the psd are given by a @xmath191 model .",
    "the periodogram corresponds to the full light curve segment with @xmath192 data points , while the carma constraints are obtained after randomly downsampling the light curve to 4000 data points .",
    "in addition , the length of the line marking the approximate measurement error noise level in the down sampled light curve also marks the frequency range probed by the down sampled light curve , with the upper limit corresponding to the average value of the nyquist frequency , @xmath193 .",
    "we note that the measurement noise level of the down - sampled light curve is higher relative to the full light curve by the ratio of nyquist frequencies , since the integrated power in the measurement noise is preserved .",
    "the carma model recovers the dominant qpo , but does not find evidence for the higher frequency weaker qpo .",
    "it likely misses the higher frequency qpo because it lies at the upper limit of the frequency range probed by the down sampled light curve .",
    "[ f - xte_psd ] ]    we first apply our carma modeling to a rossi x - ray timing explorer ( _ rxte _ ) light curve of the x - ray binary xte 1550 - 664 ; the obsid of this light curve is 30191 - 01 - 16 .",
    "the data reduction for this light curve is described in @xcite .",
    "this light curve was chosen because it is densely and regularly sampled every @xmath194 seconds , and because it has a complex and well - measured psd with multiple qpos .",
    "we analyze a @xmath195 sec segment of this light curve from @xmath196 sec to @xmath197 sec .",
    "the full light curve has @xmath192 data points , and its periodogram is shown in figure [ f - xte_psd ] .",
    "the psd is flat on time scale longer than @xmath198 sec , and shows a strong qpo at @xmath199 hz ; there is a second weaker qpo at @xmath200 hz .",
    "the flattening in the psd at the highest frequencies is caused by the measurement noise .    before applying our carma modeling",
    "we randomly downsampled the light curve to 4000 data points .",
    "this therefore provides an interesting test of the carma modeling to recover the psd from an irregularly - sampled light curve from an astronomical source for which the psd is effectively known .",
    "the mean time spacing of the down - sampled light curve is @xmath201 sec , and the measurement noise contributes @xmath202 to the observed root - mean - square of the natural logarithm of the flux values ( i.e. , the ratio of measurement noise standard deviation to the observed rms of the natural logarithm of the measured flux values is @xmath203 ) . because the x - ray binary light curves have a log - normal distribution @xcite , and because flux must be non - negative , we applied our carma modeling to the logarithms of the flux values .",
    "the carma model that minimized the aicc had @xmath204 .",
    "the existence of two qpos in addition to a broad - band noise component in the periodogram of the full light curve implies at least @xmath205 , because the number of qpo features that can be modeled for a carma process of order @xmath7 is @xmath206 , where @xmath207 is the floor function , and because a broad - band noise component ( i.e. , a zero - centered lorentzian function in the psd ) always occurs for odd values of @xmath7 .",
    "this therefore suggests that the aicc value does not find sufficient improvement to justify the inclusion of the weaker qpo feature .",
    "in order to assess the statistical significance of the feature we ran our mcmc sampler using values of @xmath191 .",
    "the psd from the carma(5,4 ) model is also shown in figure [ f - xte_psd ] .",
    "the dominant qpo is clearly recovered , with an estimated centroid of @xmath208 hz and quality factor of @xmath209 ; the qpo quality factor is the ratio of the lorentzian centroid frequency to its fwhm .",
    "however , the weaker qpo is missed suggesting that there is not evidence for it in the down - sampled light curve .",
    "this is likely due to the fact that its centroid is close to the average nyquist frequency of the down sampled light curve , and thus falls at the edge of the frequency range probed .",
    "in addition , there is no evidence in the down sampled light curve for significant additional variability power on time scales longer than the qpo , much less evidence that it flattens to white noise .",
    "we assess the quality of the carma(5,4 ) model fit by inspection of the histogram of standardized residuals , and of the autocorrelation functions of the standardized residuals and their squares , all of which are plotted in figure [ f - xte_fit_quality ] .",
    "there is no evidence for a significant departure from the assumption of a gaussian process , and the residuals are consistent with white noise , implying that the gaussian carma(5,4 ) model adequately describes the fluctuations in this light curve .",
    "we applied our carma modeling to optical light curves of two agn .",
    "the first light curve is from the _ kepler _ observatory , and the second is from the sdss stripe 82 data set .      ]",
    "the first optical light curve is from the _ kepler _ observatory for the local agn zw 229 - 15 ( @xmath210 ) in quarter q9 .",
    "the kepler light curves are the highest quality light curves for any agn , with this one being almost regularly sampled every 30 minutes for approximately 3 months providing a total of 4375 data points .",
    "this therefore makes it a good test case for our carma modeling approach .",
    "in addition the amplitude of the measurement errors is only @xmath211 of the observed standard deviation in the light curve .",
    "this light curve was analyzed by @xcite who concluded that the psd can be characterized as a power - law @xmath212 .",
    "the light curve is shown in figure [ f - kepler_lcurve ] , and the periodogram is shown in figure [ f - kepler_psd ] . when computing the periodogram we also employed the ` end - matching ' technique used by @xcite .",
    "also shown in figure [ f - kepler_psd ] is a psd of the form @xmath212 , as estimated by @xcite .    .",
    "the constraints on the psd are given by a @xmath213 model .",
    "the dark orange line shows a power - law psd of the form @xmath214 , where @xcite find a best - fit of @xmath215 .",
    "the carma model psd tracks the periodogram well , confirming that on time scales @xmath216 days the psd for this source is steeper than expected from a car(1 ) model .",
    "the carma model also shows some evidence for the psd flattening to @xmath165 on time scales @xmath217 days .",
    "[ f - kepler_psd ] ]    the aicc values were minimized for @xmath218 .",
    "the standardized residuals using the best - fit model did not show any evidence for deviations from a gaussian white noise process , implying that the carma(6,4 ) model is sufficient .",
    "the maximum - likelihood estimate and region containing @xmath171 of the posterior probability are both shown in figure [ f - kepler_psd ] .",
    "the psd from the carma(6,4 ) model is very similar to the periodogram above the measurement noise level , and can be well - approximated as a power - law with the slope @xmath219 on time scales shorter than @xmath198 month , consistent with the analysis of @xcite .",
    "however , there is some evidence that the psd flattens to @xmath165 on time scales @xmath217 days .",
    "if real and common among agn , this may explain why a car(1 ) model has been successful in modeling optical agn variability on these longer time scales .",
    "-band light curve for a quasar from the sdss stripe 82 survey , as well as the interpolated values based on the best - fitting carma(4,1 ) process .",
    "symbols are as in figure [ f - mock2_lcurve ] .",
    "b ) standardized residuals ( data points ) and their distribution ( blue histogram ) , compared with the expected standard normal distribution ( orange line ) .",
    "there is no evidence for a deviation from a gaussian carma process for this light curve .",
    "c ) and d ) autocorrelation functions of the standardized residuals ( bottom left ) and their square ( bottom right ) , compared with the 95% confidence region assuming a white noise process ( shaded region ) .",
    "there is no evidence that the residuals deviate from a white noise sequence , suggesting that the carma model has adequately captured the correlation structure in the light curve .",
    "[ f - s82qso_lcurve ] ]    an r - band agn light curve from stripe 82 is taken from the catalogue of @xcite and is for the quasar with ra and dec ( j2000 ) 10:02:34.6 , -00:59:19.5 , and a redshift of @xmath220 .",
    "this light curve has a time baseline of a little less than 10 years , but suffers from considerable irregular sampling .",
    "the stripe 82 light curve has 68 data points and the average amplitude of the measurement errors is @xmath221 of the observed standard deviation in the light curve . the light curve is shown in figure [ f - s82qso_lcurve ] .    .",
    "the constraints on the psd are given by a @xmath222 model .",
    "there is considerable uncertainty in the estimated psd , and the psd is consistent with a power law of the form @xmath223@xmath224 .",
    "in addition , there is some marginal evidence that the psd flattens toward lower frequencies .",
    "note that the high - frequency spike in the maximum - likelihood estimate is unlikely to be real , as it falls well below the measurement noise level .",
    "[ f - s82qso_psd ] ]    the aicc values for this light curve were minimized at @xmath225 . in figure [ f - s82qso_lcurve ]",
    "we compare the measured light curve with an interpolation based on the best - fit carma(4,1 ) model .",
    "also shown in figure [ f - s82qso_lcurve ] are the standardized residuals and autocorrelation functions of the residuals and their square .",
    "there is no evidence for significant deviations from the assumption of a gaussian process , and the residuals are consistent with white noise implying that a carma(4,1 ) process adequately describes the fluctuations of this light curve .",
    "the maximum - likelihood estimate of the psd is shown in figure [ f - s82qso_psd ] , along with the region containing 95% of the posterior probability .",
    "the psd shows some evidence for steepening toward higher frequencies , although the uncertainties are large and a single power - law of the form @xmath226@xmath224 is also consistent with the estimated psd .      as an illustration we also applied our carma modeling to the optical variations of two variable stars",
    "the first is a long - period variable star , and the second is an rr - lyrae star .",
    "both show regular variations , with the rr - lyrae stars variations being more regular and deterministic .",
    "they contrast with the x - ray binary and agn light curves in that their emission does not come from an accretion disk , but instead is driven by pulsations within the stellar atmosphere .",
    "-band light curve for a long - period variable star on the red giant branch , from the ogle - iii survey .",
    "also shown is the interpolated light curve and its uncertainty assuming a carma(6,0 ) model ; the symbols are the same as in figure [ f - mock2_lcurve ] . ]",
    "the first variable star light curve we applied our carma modeling to is the @xmath227-band light curve of a long - period variable on the red giant branch from the ogle - iii variable star catalogue @xcite .",
    "the light curve is shown in figure [ f - lpv_lcurve ] .",
    "the ra and dec of this source are 04:27:55.78 , -70:24:59.4 .",
    "the light curve for this source has 437 data points , spans @xmath228 years , and has a median time sampling of 3 days .",
    "this is a relatively low @xmath229 light curve relative to the intrinsic source variability , as the measurement errors make up @xmath230 of the observed standard deviation in the light curve .",
    "part of our motivation for choosing this light curve as an example is because long - period variable stars are the main contaminant in samples of agn selected using the car(1 ) parameters @xcite , and hopefully the two sources become distinguishable using higher order carma models .    .",
    "the power spectrum is flat on the longest time scales , implying uncorrelated variations on time scales @xmath231 days . on shorter time",
    "scales the psd flatten to @xmath232 .",
    "in addition , there are two pulsation modes with quasi - periods corresponding to @xmath233 ( labeled `` b '' ) and @xmath234 days ( labeled `` a '' ) , respectively . however , the lower - frequency qpo feature is only has a posterior probability of @xmath235 .",
    "[ f - lpv_psd ] ]    the aicc for this light curve was minimized at @xmath236 .",
    "there was no significant evidence for deviations from the carma(6,0 ) model for this light curve , as the residuals were consistent with gaussian white noise . in figure [ f - lpv_lcurve ]",
    "we also show the light curve interpolated from the best - fit carma(6,0 ) .",
    "the estimated psd is shown in figure [ f - lpv_psd ] .",
    "the psd on the longest time scales is flat , implying uncorrelated variability , and steepens to @xmath232 at a characteristic frequency @xmath237 .",
    "we estimate @xmath238 days with a @xmath171 credibility interval of @xmath239 days .",
    "the higher - frequency pulsation mode , labeled `` b '' , corresponds to a quasi - periodic oscillation with a time - scale of 15.9 days ( 95% credibility interval of @xmath240 days ) .",
    "the existence of qpo `` b '' is highly significant , as it is present in all of the mcmc samples .",
    "qpo b has a posterior median quality factor of @xmath241 with a 95% credibility interval of @xmath242 .",
    "the lower - frequency pulsation mode , labeled as `` a '' , was not present in @xmath243 of the mcmc samples suggesting that it has a posterior probability of only @xmath244 and is therefore not statistically signifiant .",
    "the quasi - period found from the carma model for qpo b is shorter than the period of 22.46 days quoted in the ogle - iii catalogue @xcite , although the a pulsation mode , if real , has a period of @xmath234 days .",
    "-band light curve for an rr - lyrae star from the sdss stripe 82 survey , as well as the interpolated values based on the best - fitting carma(7,0 ) process .",
    "symbols are as in figure [ f - mock2_lcurve ] .",
    "b ) standardized residuals ( data points ) and their distribution ( blue histogram ) , compared with the expected standard normal distribution ( orange line ) .",
    "the distribution of the residuals is considerably narrower than the standard normal , suggesting that the assumption of a gaussian process is not appropriate for this lightcurve .",
    "c ) and d ) autocorrelation functions of the standardized residuals ( bottom left ) and their square ( bottom right ) , compared with the 95% confidence region assuming a white noise process ( shaded region ) .",
    "there is no evidence that the residuals deviate from a white noise sequence , suggesting that the carma model has captured the correlation structure in the light curve .",
    "[ f - rrly_lcurve ] ]    we also applied our carma modeling to the @xmath245-band light curve of an rr - lyrae from the stripe 82 catalogue of @xcite .",
    "the ra and dec ( j2000 ) of this source are 06:41:29.48 , -00:00:01.68 .",
    "there are 128 epochs in this light curve over @xmath246 years with a median time spacing of 2 days .",
    "the measurement errors are @xmath247 of the observed standard deviation in the light curve .",
    "rr - lyrae sources show regular non - sinusoidal periodic fluctuations , and thus a stochastic process such as the carma model may not provide the best representation of their light curves .",
    "we include this application as an example of how the carma modeling performs for a periodic source . the light curve for this source is shown in figure [ f - rrly_lcurve ] .",
    "a carma(7,0 ) model was found to minimize the aicc .",
    "the interpolated light curve based on the best - fit carma model is also shown in figure [ f - rrly_lcurve ] , as well as the standardized residuals and their autocorrelation functions .",
    "the autocorrelation functions do not show any significant deviations from white noise , suggesting that the carma(7,0 ) model has captured the correlation structure in the light curve within the limits of the data quality .",
    "however , the histogram of the residuals is more narrow than a normal distribution , suggesting deviations from the assumption of a gaussian stochastic process .",
    "this is not surprising , as rr - lyrae exhibit regular periodic variations and thus a carma model is unlikely to be the best choice .",
    "we note that the consistency of the residuals with a white noise sequence implies that it is not necessary for the residuals to be normally distributed in order for the carma model to capture much of the correlation structure in a light curve .",
    "in addition , the significant deviation in the residuals from a normal distribution may provide a way of using the carma process parameters to discriminate between periodic and aperiodic variables in time - domain surveys .",
    "-band light curve of an rr - lyrae star from the sdss stripe 82 , assuming a carma(7,0 ) model ; symbols are the same as in figure [ f - mock2_lcurve ] .",
    "the power spectrum is flat on the longest time scales , implying uncorrelated variations on time scales @xmath217 days .",
    "the three pulsation modes are labeled `` a '' , `` b '' , and `` c '' , and are in increasing order in terms of their centroid frequency .",
    "there are two statistically - significant pulsation modes in the psd , with the mode a being a little broader and corresponding to a period of @xmath248 days .",
    "while it appears that there are two significant higher - frequency pulsation modes ( b and c ) , only one of the two is present at any time in the mcmc samples .",
    "the high - frequency pulsation occurs at either a period of @xmath249 days ( mode b ) or @xmath250 days ( mode c ) , with the shorter period being @xmath251 times more likely .",
    "[ f - rrly_psd ] ]    the inferred psd for this light curve is shown in figure [ f - rrly_psd ] .",
    "the psd is dominated by two narrow pulsation modes ( labeled as `` b '' and `` c '' ) , plus a broader mode at lower frequency ( labeled as `` a '' ) , and is flat on time scales @xmath217 days . modes b and c are mutually exclusive , in the sense that if mode b is present in an mcmc sample , mode c is not .",
    "we used a clustering algorithm on the psd lorentzian centers and widths in order to identify which mcmc samples correspond to each pulsation mode , as the labeling used by the mcmc sampler for each lorentzian does not uniquely map to a quasi - periodic feature in the psd .",
    "mode c corresponds to a period of 0.56 days and is observed in @xmath252 of the mcmc samples .",
    "this mode corresponds very closely to the catalogue period of 0.564 @xcite , found using the super smoother algorithm @xcite .",
    "mode b corresponds to a period of 1.30 days and is present in @xmath253 of the mcmc samples . because the existence of the two modes is mutually exclusive",
    ", the fact that one of the two is present is statistically significant at @xmath254 probability , with mode c being the more likely of the two .",
    "mode a is also statistically significant , being present in @xmath255 of the mcmc samples , and corresponds to a period of 2.49 days with a @xmath171 credibility interval of @xmath256 .",
    "we note that getting our algorithm to converge was particularly problematic for this light curve , as we would often get quantitatively different results for different runs of the algorithm . moreover , the maximum - likelihood estimate is not contained within the @xmath171 probability bounds found from the mcmc sampler .",
    "this is likely because the mcmc sampler has found a better solution due to the fact that it runs for many more iterations , while the optimizer used to compute the maximum - likelihood estimate only found suboptimal modes .",
    "these facts , in addition with the fact that the light curve is inconsistent with a gaussian process , imply that the likelihood function is noisy and has many modes .",
    "this implies that optimizers and mcmc samplers that are robust against multi - modality and complicated likelihood spaces may be necessary in order to get reliable results from carma modeling of light curves that exhibit regularly periodic and non - sinusoidal variations .",
    "in this work we have introduced continuous - time autoregressive moving average processes as flexible models for stochastic and quasi - periodic light curves .",
    "these models account for irregular sampling and measurement errors , making them applicable to a wide variety of light curves .",
    "moreover , they are flexible , as their psd can be described as a sum of lorentzian functions .",
    "the primary purposes of this modeling approach are 1 ) to provide a flexible way to estimate power spectra for astronomical light curves , and 2 ) to provide variability features for light curves that may be used in variability selection techniques and potentially in the identification of new classes of variables .",
    "because one can compute the likelihood function for a light curve under a carma model they have the advantage that they are statistically efficient and rigorous , as all of the information in the light curve is used to estimate the variability parameters and inference is based on the well - developed statistical theory of maximum - likelihood or bayesian inference .",
    "moreover , calculation of the likelihood function is computationally efficient , scaling linearly with the number of data points in a light curve .",
    "this last point makes their application to massive time domain data sets particularly attractive .",
    "previous work has also expanded upon the car(1 ) model to introduce additional flexibility .",
    "@xcite developed a mixture of car(1 ) processes as a model for x - ray variability of agn . in this model ,",
    "the light curve is expressed as a weighted sum of independent car(1 ) processes with different characteristics time scales that are constrained to lie on a regular logarithmic grid .",
    "the free parameters for this model are the maximum and minimum characteristic time scales of the grid , the mean and variance of the lightcurve , and the weights .",
    "comparison with equation ( [ eq - carma_autocovar ] that the mixture of @xmath7 car(1 ) processes model of @xcite is a special case of a carma(p , q ) process where the roots of equation ( [ eq - characteristic ] ) are constrained to be real .",
    "@xcite also showed that a mixture of car(1 ) processes can closely approximate a broken - power law model for the psd . in this case , the maximum and minimum characteristic time scales correspond to the low and high frequency breaks , respectively , and the the sequence of weights can be calculated as a function of the slope of the power - law between the low and high frequency breaks , so long as the slope of the psd is constrained to the range @xmath257 $ ] .",
    "these constraints reduce the number of free parameters to five for this model , which can be a computational advantage .",
    "in addition , @xcite also showed that the solution to the stochastic linear diffusion equation is a mixture of car(1 ) processes , providing a physical interpretation of the variability model .",
    "@xcite investigated extensions to the gaussian car(1 ) process as a model for quasar variability .",
    "the processes investigated by @xcite included models with more flexible psds , such as a car(2 ) process and a carma(1,1 ) process .",
    "the former process provides the ability to capture quasi - periodic variations , while the latter process introduces additional smoothing of the stochastic driving noise .",
    "both processes are special cases of the general class of carma processes we discuss here ; however , we note that the carma(1,1 ) model is not stationary .",
    "@xcite also investigated car(1 ) models after relaxing the assumptions of a linear gaussian process .",
    "in particular , they also investigated non - gaussian car(1 ) models and non - linear processes where the light curve variance also stochastically varies in time .",
    "these models , while not as flexible in modeling the psd as a carma process , provide valuable alternatives to linear gaussian models and may provide a better description of the variability of some light curves . however , in the case of quasar light curves from stripe 82 @xcite concluded that the linear gaussian car(1 ) process provided the best model for most of the quasars , based on a bayesian model comparison",
    ".    while carma models are , in theory , computationally efficient , the likelihood space can be complex and exhibit multiple modes which can be problematic for numerical optimizers and samplers .",
    "this is especially true for higher order models , and seems to affect higher order @xmath135 models more strongly than higher order @xmath7 models .",
    "the likelihood space may also be very complex for light curves that have regular nearly deterministic variations , such as rr - lyrae stars .",
    "we consider the difficulty in optimizing or sampling from a multimodal complex posterior to be the primary short - coming of these models at this time , and dampens their computational efficiency .",
    "thus , researchers who utilize them must be careful to check that the primary posterior mode has been found , and that the dominant posterior modes have been sampled from .",
    "we deal with this in our mcmc sampler using a parallel tempering algorithm , which we have used with success .",
    "however , even this can fail to adequately sample the posterior if an insufficient number of chains are run , or if the algorithm is not run for a sufficiently long period of time .",
    "moreover , our maximum - likelihood estimation is rather simple , as we simply use 100 random starts and optimize by finding a local mode using a greedy gradient - based algorithm .",
    "future work should focus on improving the effectiveness and efficiency of the maximum - likelihood estimate and mcmc algorithm .    in order to illustrate the applicability of carma models for a variety of astronomical sources , as well as to provide a guide for interpreting their results , we applied these models to light curves for an x - ray binary , two agn , a long - period variable star , and a rr - lyrae star .",
    "in general we found that the carma models provide a good description of these light curves , suggesting that they can be applied to a broad range of astronomical sources that exhibit stochastic or quasi - periodic variations .",
    "the only exception was the rr - lyrae star light curve .",
    "this is to be expected , as rr - lyrae light curves exhibit regular non - sinusoidal variations and thus are unlikely to have a strong stochastic component .",
    "however , in spite of this the carma models still identified the period quoted by the catalogue that this light curve was taken from in @xmath252 of the mcmc samples .",
    "moreover , the deviation in the residuals from a normal distribution for the rr - lyrae star implies that the distribution of the residuals from a carma fit may provide an effective means of discriminating between different types of variables , even for those for which a carma model is not optimal .",
    "these results suggests that there may be value in using variability features derived from carma parameters even for non - stochastic light curves .",
    "further improvements to the carma modeling approach can be obtained by including a deterministic component , such as a periodic function , for modeling periodic light curves , such as those from rr - lyrae . in this case",
    "the residuals from fitting a deterministic function are modeled as following a carma process .",
    "in fact , this is the motivation behind the periodic autoregressive moving average models ( parma , e.g. , * ? ? ?",
    "* ) , which allow for periodic variations in the mean and autocovariance function of a time series .",
    "in addition , it is possible to define multivariate carma models through a vector- and matrix - valued extension to equation ( [ eq - carma ] ) ( e.g. , * ? ? ? * ; * ? ? ? * ) .",
    "multivariate carma models hold considerable potential for characterizing the full multi - passband variability information obtained by time - domain surveys , and will be the subject of future work .    in summary , carma models provide an important addition to the astronomer s statistical toolbox in the era of massive time - domain surveys , and have the potential to play an important role in the analysis of variability as a probe of astrophysics , as well as in the use of variability as a means of identifying classes of astronomical sources .",
    "we would like to thank tommaso treu for helpful discussions and comments on our manuscript , lucy heil for graciously provided the light curve for xte 1550 - 564 and helpful comments on our manuscript , simon vaughan for helpful comments on our manuscript , and an anonymous referee for helping improve our discussion of carma models .",
    "bk acknowledges support from the southern california center for galaxy evolution , a multi - campus research program funded by the university of california office of research .",
    "acknowledges funding from nasa origins grant nnx09ab32 g .",
    "was partially supported by the eu fp7 grant no .",
    "312789 , and by the polish ncn grant no .",
    "2011/03/b / st9/03459 .",
    "this paper includes data collected by the kepler mission .",
    "funding for the kepler mission is provided by the nasa science mission directorate .",
    "funding for the sdss and sdss - ii has been provided by the alfred p. sloan foundation , the participating institutions , the national science foundation , the u.s .",
    "department of energy , the national aeronautics and space administration , the japanese monbukagakusho , the max planck society , and the higher education funding council for england .",
    "the sdss web site is http://www.sdss.org/.    the sdss is managed by the astrophysical research consortium for the participating institutions .",
    "the participating institutions are the american museum of natural history , astrophysical institute potsdam , university of basel , university of cambridge , case western reserve university , university of chicago , drexel university , fermilab , the institute for advanced study , the japan participation group , johns hopkins university , the joint institute for nuclear astrophysics , the kavli institute for particle astrophysics and cosmology , the korean scientist group , the chinese academy of sciences ( lamost ) , los alamos national laboratory , the max - planck - institute for astronomy ( mpia ) , the max - planck - institute for astrophysics ( mpa ) , new mexico state university , ohio state university , university of pittsburgh , university of portsmouth , princeton university , the united states naval observatory , and the university of washington .",
    "our software made use of the armadillo c++ linear algebra library @xcite .",
    "natexlab#1#1    , h. 1973 , in proceedings of the second international symposium on information theory , ed . b.  petrov & f.  csaki ( budapest : akademiai kiado ) , 267281    anderson , p.  l. , meerschaert , m.  m. , & zhang , k. 2013 , journal of time series analysis , 34 , 187    , r. , kim , d .- w .",
    ", & bailer - jones , c.  a.  l. 2013 , , 554 , a137    belcher , j. , hampton , j.  s. , & wilson , g.  t. 1994 , journal of the royal statistical society .",
    "series b ( methodological ) , 56 , pp .",
    "141    , t.  m. 2010 , in lecture notes in physics , berlin springer verlag , vol .",
    "794 , lecture notes in physics , berlin springer verlag , ed .",
    "t.  belloni , 53    , b.  j. , treu , t. , pancoast , a. , et  al .",
    "2011 , , 733 , l33    , p. , & davis , r. 2002 , introduction to time series and forecasting , 2nd edn .",
    "( new york , ny : springer us )    broersen , p. m.  t. , & bos , r. 2006 , instrumentation and measurement , ieee transactions on , 55 , 1124    , n.  r. , & bloom , j.  s. 2011 , , 141 , 93    , y. , gibson , r.  r. , becker , a.  c. , et  al .",
    "2013 , arxiv e - prints , arxiv:1312.4957    , c. , gierliski , m. , & kubota , a. 2007 , , 15 , 1    , c. , madejski , g.  m. , mushotzky , r.  f. , et  al .",
    "1992 , , 400 , 138    , a.  j. , djorgovski , s.  g. , mahabal , a. , et  al .",
    "2009 , , 696 , 870    , d. , mchardy , i.  m. , & papadakis , i.  e. 2013 , , 433 , 907    , d. , mchardy , i.  m. , & uttley , p. 2010",
    ", , 404 , 931    , j.  a. , bassett , b. , becker , a. , et  al .",
    "2008 , , 135 , 338    gardiner , c.  w. 2004 , handbook of stochastic methods for physics , chemistry and the natural sciences , 3rd edn . , springer series in synergetics ( berlin : springer - verlag ) , xviii+415    , m.  j. , djorgovski , s.  g. , drake , a.  j. , et  al .",
    "2014 , arxiv e - prints , arxiv:1401.1785    , l.  m. , vaughan , s. , & uttley , p. 2011",
    ", , 411 , l66    , j.  h. , & baliunas , s.  l. 1986 , , 302 , 757    , k. , welsh , w.  f. , & peterson , b.  m. 1991 , , 367 , l5    , c.  m. , & tsai , c .-",
    "1989 , biometrika , 76 , 297    , z. , tyson , j.  a. , acosta , e. , et  al . 2008 , arxiv e - prints , arxiv:0805.2366    , r.  h. 1981 , in applied time series analysis iii , ed .",
    "d.  findley ( new york , ny : academic press )    jones , r.  h. , & ackerson , l.  m. 1990 , biometrika , 77 , pp .",
    "721    , n. , aussel , h. , burke , b.  e. , et  al .",
    "2002 , in society of photo - optical instrumentation engineers ( spie ) conference series , vol . 4836 , survey and other telescope technologies and discoveries , ed . j.  a. tyson & s.  wolff , 154164    , b.  c. , bechtold , j. , & siemiginowska , a. 2009 , , 698 , 895    , b.  c. , sobolewska , m. , & siemiginowska , a. 2011 , , 730 , 52    , b.  c. , treu , t. , malkan , m. , pancoast , a. , & woo , j .- h .",
    "2013 , , 779 , 187    , c.  s. 2004 , , 605 , 58    , c. 2005 , , 361 , 887    , s. , kochanek , c.  s. , udalski , a. , et  al .",
    "2010 , , 708 , 927    , n.  m. , kulkarni , s.  r. , dekany , r.  g. , et  al .",
    "2009 , , 121 , 1395    , j. 2004 , monte carlo strategies in scientific computing ( new york , ny : springer )    , c.  l. , ivezi ,  . ,",
    "kochanek , c.  s. , et  al .",
    "2010 , , 721 , 1014    , c.  l. , brooks , k. , ivezi ,  .",
    ", et  al . 2011 , , 728 , 26    , c.  l. , ivezi ,  . , sesar , b. , et  al .",
    "2012 , , 753 , 106    marquardt , t. , & stelzer , r. 2007 , stochastic processes and their applications , 117 , 96    , l. , turner , t.  j. , reeves , j.  n. , et  al .",
    "2010 , , 403 , 196    , c.  w. , hainline , l.  j. , chen , b. , et  al .",
    "2012 , , 756 , 52    , r.  f. , edelson , r. , baumgartner , w. , & gandhi , p. 2011",
    ", , 743 , l12    , m.  a. 2000 , , 318 , 361    , a. , brewer , b.  j. , & treu , t. 2011 , , 730 , 139    , a. , brewer , b.  j. , treu , t. , et  al .",
    "2012 , , 754 , 49    , w.  h. , rybicki , g.  b. , & hewitt , j.  n. 1992 , , 385 , 404    , j.  d. 1994 , phd thesis , university of california , berkeley .",
    "roux , a. 2002 , phd thesis , university of pretoria    , j.  j. , anderson , s.  f. , macleod , c.  l. , et  al .",
    "2012 , , 760 , 51    , g.  b. , & press , w.  h. 1992 , , 398 , 169    . 1995 , physical review letters , 74 , 1060    sanderson , c. 2010 , technical report , nicta , 2    , j.  d. 1982 , , 263 , 835    schlemm , e. , & stelzer , r. 2012 , bernoulli , 18 , 46    , b. , ivezi ,  . , grammer , s.  h. , et  al . 2010 , , 708 , 717    , i. , udalski , a. , szymaski , m.  k. , et  al . 2011 , acta astronomica , 61 , 217    spiegelhalter , d.  j. , best , n.  g. , carlin , b.  p. , & van der  linde , a. 2002 , journal of the royal statistical society : series b ( statistical methodology ) , 64 , 583    , p. , mchardy , i.  m. , & papadakis , i.  e. 2002 , , 332 , 231    , p. , mchardy , i.  m. , & vaughan , s. 2005 , , 359 , 345    , s. 2010 , , 402 , 307    , s. , edelson , r. , warwick , r.  s. , & uttley , p. 2003",
    ", , 345 , 1271    vihola , m. 2012 , statistics and computing , 22 , 997    , r. , cristiani , s. , lessi , o. , & provenzale , a. 1992 , , 391 , 518    wang , z. 2013 , journal of statistical software , 53 , 1    , y. , kochanek , c.  s. , kozowski , s. , & udalski , a. 2013 , , 765 , 106    , y. , kochanek , c.  s. , & peterson , b.  m. 2011 , , 735 , 80",
    "using the rotated state space representation , the kalman filter computes the mean and variance of the measured time series at time @xmath80 conditional on the measurements at times @xmath258 via the following algorithm @xcite :    1 .",
    "center the time series . for",
    "each @xmath227 compute @xmath104 .",
    "because the kalman filter assumes a zero - mean time series , we will work with the centered values instead of @xmath66 .",
    "2 .   denote the covariance matrix of the predicted rotated state as @xmath259 .",
    "initialize the rotated state vector @xmath260 and its covariance @xmath259 at time @xmath261 to its stationary mean and covariance , @xmath262 and @xmath263 respectively : @xmath264 defining @xmath265 , the stationary covariance matrix for @xmath266 has elements @xcite @xmath267 3 .",
    "calculate the mean and variance of the first measurement in the time series using the stationary values for a carma process : @xmath268 where @xmath269 is given by equation ( [ eq - carma_autocovar ] ) .",
    "4 .   initialize the kalman gain : @xmath270 here @xmath271 denotes the hermitian transpose of @xmath272 .",
    "update the estimate of the rotated state vector : @xmath273 6 .   update the covariance matrix of the rotated state vector : @xmath274    after the initializing the kalman filter as above , repeat the following steps for @xmath275 :    1 .",
    "predict the rotated state vector at the next observation time given the time series at the earlier observation times : @xmath276 2 .",
    "calculate the covariance matrix of the predicted rotated state vector at time @xmath80 : @xmath277 3 .",
    "calculate the mean and variance of the centered time series at time @xmath80 conditional on the earlier values : @xmath278 here we have used the notation @xmath279 $ ] .",
    "4 .   update the kalman gain : @xmath280 5 .   update the estimated rotated state vector : @xmath281 6 .   finally , update the covariance matrix of the estimated rotated state vector : @xmath282    the values of @xmath283 and @xmath284 computed using the above algorithm",
    "can then be used to efficiently calculate the likelihood function given by equation ( [ eq - likhood ] ) , noting that @xmath285 .",
    "the coefficients @xmath107 and @xmath108 needed to compute the expected value of @xmath66 as a function of @xmath99 for @xmath286 can be computed recursively using the following algorithm :    1 .",
    "first , run the kalman filter up to index @xmath287 . if @xmath288 then skip this step .",
    "2 .   compute @xmath289 and @xmath290 using equations ( [ eq - state_transition])([eq - ycvar ] ) .",
    "if @xmath291 , then nothing further needs to be calculated . otherwise , use these values to compute @xmath292 , and @xmath293 .",
    "3 .   initialize the rotated state vector coefficients @xmath294 and @xmath295 as @xmath296 \\\\      { \\bf d}_{j(t_0 ) } & = \\lambda_0 { \\bf k}_0,\\end{aligned}\\ ] ] where @xmath297 is a diagonal matrix with @xmath298 . if @xmath288 then @xmath299 and the initial values are @xmath300 4 .",
    "initialize the coefficients @xmath301 and @xmath302 as @xmath303 note that if @xmath288 then @xmath304 and @xmath305 .      1 .",
    "update the linear coefficients for the rotated state vector @xmath307 \\\\      { \\bf d}_{i } & = \\lambda_i [ { \\bf d}_{i-1 } - \\tilde{d}_{i-1 } { \\bf k}_i ] .\\end{aligned}\\ ] ] 2 .",
    "update the linear coefficients : @xmath308    because the kalman gains , @xmath309 , only depend on the observation times , and not on the measured time series , they are computed by performing the kalman filter using the observation times @xmath310 ."
  ],
  "abstract_text": [
    "<S> we present the use of continuous - time autoregressive moving average ( carma ) models as a method for estimating the variability features of a light curve , and in particular its power spectral density ( psd ) . </S>",
    "<S> carma models fully account for irregular sampling and measurement errors , making them valuable for quantifying variability , forecasting and interpolating light curves , and for variability - based classification . </S>",
    "<S> we show that the psd of a carma model can be expressed as a sum of lorentzian functions , which makes them extremely flexible and able to model a broad range of psds . </S>",
    "<S> we present the likelihood function for light curves sampled from carma processes , placing them on a statistically rigorous foundation , and we present a bayesian method to infer the probability distribution of the psd given the measured lightcurve . because calculation of the likelihood function scales linearly with the number of data points , carma modeling scales to current and future massive time - domain data sets . </S>",
    "<S> we conclude by applying our carma modeling approach to light curves for an x - ray binary , two agn , a long - period variable star , and an rr - lyrae star , in order to illustrate their use , applicability , and interpretation . </S>"
  ]
}