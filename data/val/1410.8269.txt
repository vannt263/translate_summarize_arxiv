{
  "article_text": [
    "the linear mixed models with both random and fixed effects have been extensively and actively studied in recent years from both theoretical and applied aspects in the literature . as specific normal linear mixed models ,",
    "the fay - herriot model ( fay and herriot , 1979 ) and the nested error regression models ( battese , harter and fuller , 1988 ) have been used in small - area estimation since direct estimates like sample means for small areas have unacceptable estimation errors because of small sample sizes in small areas .",
    "the model - based shrinkage methods such as the empirical best linear unbiased predictor ( eblup ) are very useful for providing reliable estimates for small - areas with higher precisions by borrowing data in the surrounding areas .",
    "recently , several approaches for small area estimation are proposed and investigated in terms of both parametric and nonparametric aspects .",
    "for example , see hall and maiti ( 2006a , b ) , chambers ( 2014 ) , chaudhuri and ghosh ( 2011 ) , jiang and nguyen ( 2012 ) and opsomer ( 2008 ) . also see ghosh and rao ( 1994 ) , rao ( 2003 ) , datta and ghosh ( 2012 ) and pfeffermann ( 2013 ) for a good survey on this topic .    in the most of literatures related to the fay - herriot model or the nested error regression model , it is assumed that the data has real values .",
    "however , we are often faced with the data with positive values like the price data and fitting such data to the normal distributions in nested error regression model may be inappropriate in the case that distribution of data is skewed .",
    "moreover , if we analyze bounded data like ratio data as real - valued data , we may cause the problem that prediction intervals of model - based predictors may be out from the range of the bounded data .",
    "thus , this paper is focused on developing a methodology for analyzing positive or bounded data by incorporating a parametric transformation into the conventional nested error regression model .",
    "a standard approach to analyzing positive data is to apply the log - transformation to the data , which was investigated in slud and maiti ( 2006 ) in the nested error regression model .",
    "however , such a specific transformation is not always appropriate , and we want to adjust the transformation flexibly to fit the transformed data to a normal linear mixed regression",
    ". a conventional method in this direction is the box - cox transformation suggested by box and cox ( 1964 ) , described by @xmath0 however , it is known that the maximum likelihood estimator of the transformation parameter @xmath1 in the box - cox transformation is not consistent , so that the resulting eblup is not consistent to the best linear unbiased predictor ( blup ) .",
    "thus , the inconsistency in the estimation of @xmath1 is a crucial problem in the context of small area prediction . as an alternative transformation ,",
    "in this paper , we use the dual power transformation ( dpt ) ( yang , 2006 ) which will be described in section [ tnerm ] .",
    "this is a transformation from positive numbers to real numbers , and it can be expected that the maximum likelihood estimator of @xmath1 is consistent . for analyzing bounded data , we propose the dual power logistic transformation ( dplt ) which transforms the bounded data to real - valued data .",
    "this transformation will be also described in section [ tnerm ] .    utilizing these transformations , in this paper , we suggest the parametrically transformed nested error regression model ( tnerm ) defined as @xmath2 where",
    "@xmath3 s and @xmath4 s are mutually independently normally distributed and @xmath5 is a fixed effect . here , @xmath6 is a general transformation function which is characterized with the transformation parameter @xmath1 .",
    "the examples of @xmath7 treated in this paper are dpt and dolt .",
    "the transformation parameter @xmath1 can be used for adjustment , and the proposed model enables us to flexibly analyze the small - area positive or bounded data . the detailed model description is given in section [ tnerm ] .    in the conventional nested error regression",
    ", we predict the quantity @xmath8 , where @xmath9 by the empirical best linear unbiased predictor @xmath10 .",
    "sugasawa and kubokawa ( 2014 ) proposed the parametrically transformed fay - herriot model and the gave second - order unbiased estimators of mse of @xmath10 .",
    "however , in the transformed model , the quantity of interest is the inversely transformed function @xmath11 rather than @xmath12 .",
    "thus , in this paper , we consider to predict @xmath11 and propose the transformed empirical best linear unbiased estimator ( teblup ) , namely @xmath13 . since this predictor is expected to give reliable predicted values for small - areas with higher precisions , it is important to assess uncertainty of teblup . in the context of small area estimation , we have two approaches to measuring the uncertainty : one is to provide an estimate of the mean squared error ( mse ) of the prediction ( see datta and lahiri , 2000 , datta , 2005 and hall and maiti , 2006a , b ) , and the other is the prediction ( confidence ) intervals ( see basu , , 2003 , chatterjee , 2008 , datta , 2002 , diao , 2014 and yoshimori and lahiri , 2014 ) .    the goal of this paper is to construct prediction intervals of @xmath11 based on @xmath13 .",
    "since it is harder to derive an analytical prediction interval with suitable accuracy based on the taylor series expansion , we here provide a prediction interval with second - order accuracy based on the parametric bootstrap along the line given in chatterjee , lahiri and li ( 2008 ) .",
    "we also provide a conditional prediction interval given data in the area of interest , motivated from the results of booth and hobert ( 1998 ) who discussed a conditional mse and its estimation in generalized linear mixed models .",
    "the paper is organized as follows : in section [ tnerm ] , we suggest the parametric transformed nested error regression model with dpt or dplt",
    ". some consistent estimators of parameters in tnerm are also given .",
    "in section [ prediction ] , we introduce the transformed empirical best linear unbiased predictor and construct unconditional and conditional prediction intervals with second order accuracy based on the parametric bootstrap method . in section [ num ] , we conduct simulation studies . in section [ emp ] , we apply the proposed model to two data set , the survey data in japan and crop areas data given in battese ( 1988 ) .",
    "the concluding remarks are given in section [ remark ] .",
    "all the technical proofs are given in the appendix .",
    "consider the two - stage cluster sampling , namely , @xmath14 clusters are randomly selected , and data are randomly selected from each selected cluster . for @xmath15 , a random sample taken from the @xmath16-th cluster with size @xmath17",
    "is denoted by @xmath18 .",
    "the most useful model for analyzing such data is the nested error regression model ( nerm ) described by @xmath19 where @xmath3 s and @xmath4 s are mutually independently distributed as @xmath20 and @xmath21 . here",
    ", a vector @xmath22 denotes the transpose of @xmath23 , @xmath24 denotes a normal distribution with mean @xmath25 and variance @xmath26 , @xmath27 is a @xmath28-dimensional known covariate associated with @xmath29 , @xmath30 is a @xmath28-dimensional unknown vector of regression coefficients , and @xmath31 and @xmath32 are unknown components of variance , called ` between and ` within components , respectively .",
    "the model ( [ nerm ] ) is a linear mixed model which incorporates both fixed and random effects , and it has been used for analyzing unit level data in the framework of small - area estimation . when @xmath29 s are real - valued data , the model ( [ nerm ] ) is reasonable .",
    "however , it is not necessarily appropriate when values of @xmath29 s are limited to spaces of positive or bounded numbers",
    ". then , we need to consider a transformation of @xmath29 to fit into nerm . in this paper , we consider two types of transformations for the data limited to @xmath33 or @xmath34 , where @xmath35 and @xmath36 for the real space @xmath37 . for @xmath33 , namely positive data , we use the dual power transformation ( dpt ) suggested by yang ( 2006 ) , described as @xmath38 for @xmath39 .",
    "it is noted that for @xmath40 , the inverse transformation is expressed as @xmath41 for @xmath42 , and @xmath43 for @xmath44 . when data are restricted on the space @xmath45 for @xmath46",
    ", dpt can be extended to @xmath47 for analyzing data on the space . for @xmath34 , we newly suggest the dual power logistic transformation ( dplt ) given by @xmath48 for @xmath49 . using the expression of the inverse transformation of dpt ,",
    "one gets the inverse transformation of dplt , given by @xmath50 for @xmath42 , and @xmath51 for @xmath44 .",
    "when data are restricted on the interval @xmath52 for fixed values @xmath53 and @xmath54 , @xmath55 , dplt can be extended to @xmath56 , since @xmath57 lies in @xmath58 .",
    "thus , we can analyze data on @xmath52 using @xmath56 .",
    "let @xmath7 be @xmath59 or @xmath60 for given @xmath1 .",
    "the transformation parameter @xmath1 is adjusted so that transformed data @xmath61 s can fit into nerm .",
    "thus , we can suggest the parametrically transformed nested error regression model ( tnerm ) @xmath62 it may be convenient to write the model ( [ model ] ) in matricial forms .",
    "let @xmath63 , @xmath64 , @xmath65 and @xmath66 . also , define @xmath67 by @xmath68 then , the model ( [ model ] ) is expressed as @xmath69 and @xmath67 has an @xmath17-variate normal distribution @xmath70 where @xmath71 for @xmath72 , the @xmath73 identity matrix @xmath74 and @xmath75 .",
    "it is noted that the covariance of @xmath76 has the intra - class correlation structure , namely @xmath77 are not mutually independent when @xmath78 .",
    "let @xmath79 .",
    "all the data @xmath80 s are described as the @xmath81-dimensional vector @xmath82 .",
    "then the joint density function @xmath83 is expressed as @xmath84 where @xmath85 is the jacobian of the transformation for @xmath86 .",
    "this expression will be used for estimating the unknown parameters @xmath30 , @xmath31 , @xmath32 and @xmath1 .",
    "we here provide consistent estimators of the unknown parameters @xmath30 , @xmath31 , @xmath32 and @xmath1 . to this end , we begin by estimating @xmath30 , @xmath31 and @xmath32 in the case of known @xmath1 . in this case , the conventional estimators given in the literature for nerm ( [ nerm ] ) can be inherited to the transformed model .    concerning estimation of @xmath30 , the maximum likelihood ( ml ) or generalized least square ( gls ) estimator of @xmath30 for known @xmath87 and @xmath1 is @xmath88 where @xmath72",
    ", @xmath89 is the mean of covariates @xmath27 s for the @xmath16-th area , and @xmath90 is the mean of the transformed observations . since @xmath91 , it is clear that @xmath92 is consistent and @xmath93 under the following assumption :    [ barx ] the following are assumed for @xmath94 and @xmath17 :    * @xmath95 converges to a positive definite matrix as @xmath96 .",
    "* there exist integers @xmath97 and @xmath98 which are positive and independent of @xmath14 such that @xmath99 for @xmath100 .    since @xmath31 and @xmath32 are unknown , we estimate them and substitute their estimators into @xmath92 . in nerm ( [ nerm ] ) with known @xmath1 , for estimation of @xmath31 and @xmath32 , the prasad - rao estimator , the maximum likelihood ( ml ) and the restricted maximum likelihood ( reml )",
    "estimators have been used in the literature , and it would be plausible that those estimators can be used still in tnerm ( [ model ] ) by replacing @xmath1 with an estimator .",
    "we here clarify conditions that estimators of @xmath31 and @xmath32 should satisfy in order to derive prediction intervals given in this paper . for notational convenience , @xmath101 means that every component in @xmath101 is of order @xmath102 , and the notation @xmath103 is defined similarly .",
    "[ var ]    let @xmath104 be an estimator of @xmath105 in the case of known @xmath1",
    ". then it is assumed that the estimator @xmath106 satisfies the following :    * @xmath107 .",
    "* @xmath108=\\o_p(m^{-1})$ ] .",
    "* @xmath109 .",
    "* @xmath110 \\bigr ) \\big|\\y_i = \\o_p(m^{-1/2})$ ] .",
    "condition ( a.3 ) implies that the estimators @xmath111 and @xmath112 are consistent .",
    "conditions ( a.4 ) and ( a.8 ) will be used for investigating asymptotic properties of @xmath113 .    substituting @xmath114 into @xmath92 ,",
    "one gets the estimator @xmath115 defined by @xmath116 it is noted from ( a.8 ) that @xmath117 .",
    "some asymptotic properties on @xmath115 are given in the following lemma which will be proved in the appendix .",
    "lemma [ hbeta ] will be used in theorem [ thm.boot ] for showing the second - order accuracy of the parametric bootstrap procedure .",
    "[ hbeta ] under assumptions [ barx ] and [ var ] , it holds that @xmath118 , @xmath119=\\o_p(m^{-1})$ ] and @xmath120 \\bigr ) \\big|\\y_i=\\o_p(m^{-1/2}).\\ ] ]    we here provide some conventional estimators of @xmath31 and @xmath32 and show whether those estimators satisfy assumption [ var ] .",
    "* [ 1 ]  prasad - rao type estimator .",
    "*  let @xmath121 and @xmath122 for @xmath123 . defined @xmath124 by @xmath125 then define @xmath126 and @xmath127 by @xmath128 and @xmath129 .",
    "prasad and rao ( 1990 ) suggested unbiased estimators of @xmath31 and @xmath32 given by @xmath130 where @xmath131 and @xmath132 .",
    "the prasad ",
    "rao estimator of @xmath133 is denoted by @xmath134 .",
    "it is noted that @xmath135 , @xmath136 and @xmath137 under assumption [ barx ] .    *",
    "[ 2 ]  ml estimator . *  the maximum likelihood ( ml ) estimator @xmath138 of @xmath139",
    "are given as the solutions of the equations @xmath140 where @xmath141    * [ 3 ]  reml estimator .",
    "*  the restricted maximum likelihood ( reml ) estimator @xmath142 of @xmath133 is given as the solutions of the equations @xmath143,\\\\ 0&=l_2(\\sig)+\\tr[(\\x'\\bsi^{-1}\\x)^{-1}\\x'\\bsi^{-1}\\z\\bsi^{-1}\\x ] , \\end{split}\\ ] ] where @xmath144 , the covariance matrix of @xmath124 .",
    "the following lemma guarantees that the above three estimators satisfy assumption [ var ] , where the proof will be given in the appendix .    [ ass ] under assumption [ barx ] , the above three estimators @xmath145 , @xmath146 and @xmath147 satisfy assumption [ var ] .",
    "it may be guessed from lemma [ ass ] that assumption [ var ] is not so restrictive , because it is satisfied by the three typical estimators .",
    "finally , we provide an estimator of the transformation parameter @xmath1 based on the estimators @xmath115 , @xmath111 and @xmath112 . using the likelihood ( [ dens ] )",
    ", we suggest the estimator as a solution of the equation @xmath148 where @xmath149 for @xmath150 note that @xmath151 and @xmath152    [ est.la ] under assumptions [ barx ] and [ var ] , the equation @xmath153 includes a solution which is consistent to @xmath1 .",
    "this solution is denoted by @xmath154",
    ". then , @xmath155 and @xmath156 .",
    "it is easy to see that @xmath157 from lemma [ est.la ] since @xmath158 $ ] .",
    "based on the results given in the above lemmas , we can get the following asymptotic properties of estimators for the unknown parameters in tnerm ( [ model ] ) . the proof is given in the appendix .",
    "[ paraest ] let @xmath159 and @xmath160 . under assumptions [ barx ] and [ var ] , we have @xmath161 and @xmath162 for @xmath100 .    the latter property that @xmath162 is technical but crucial for the proof of theorem [ thm.boot ] in section 3 , which gives validity of the bootstrap method for constructing prediction intervals of teblup",
    "we now provide the transformed empirical best linear unbiased predictor ( teblup ) for small area estimation and construct the prediction intervals based on teblup as a measure of uncertainty of the predictor . since teblup includes the estimators of the parameters @xmath30 , @xmath31 , @xmath32 and @xmath1 , it is difficult to construct an exact prediction interval .",
    "thus , in this section , we try to construct a prediction interval with the second - order accuracy . to this end",
    ", the asymptotic results given in the lemmas in the previous section are heavily used .",
    "we here consider the problem of predicting the quantity @xmath163 when @xmath164 is known , it is well known that the conditional distribution of @xmath12 given @xmath80 is @xmath165 , where @xmath166 = \\barx_i'\\bbe+\\frac{n_i\\rho}{1+n_i\\rho}(z_i(\\la)-\\barx_i'\\bbe),\\ ] ] and @xmath167 the estimator @xmath168 is the bayes estimator of @xmath12 in the bayesian context . substituting the gls @xmath92 given in ( [ beta ] ) into ( [ mut ] )",
    "yields the predictor @xmath169 it is known that this estimator is the best linear unbiased predictor ( blup ) of @xmath12 . for @xmath31 , @xmath32 and @xmath1",
    ", we substitute the estimators given in section [ tnerm ] into the blup , and the resulting predictor is given by @xmath170 where , for simplicity , we use the notations @xmath171 , @xmath172 , @xmath173 and @xmath174 as abbreviation of @xmath175 , @xmath176 , @xmath177 @xmath178 without any confusion .",
    "the predictor ( [ eblup ] ) is called the empirical best linear unbiased predictor ( eblup ) . in the bayesian context",
    ", it corresponds to the empirical bayes estimator of @xmath12 .",
    "since our interest is in the prediction of @xmath179 , we need to make the inverse transformation of @xmath180 .",
    "it should be remarked that the inverse transformation depends on the unknown transformation parameter @xmath1 .",
    "hence , the transformed predictor of @xmath179 is given by @xmath181 which is called the transformed empirical best linear unbiased predictor ( teblup ) .",
    "for measuring uncertainty of teblup , we propose prediction intervals of @xmath179 with a second - order accuracy for @xmath182 .",
    "the basic idea of constructing prediction intervals are based on chatterjee , @xmath183 ( 2008 ) , who proposed the parametric bootstrap method for constructing a second - order accurate unconditional confidence interval in normal linear mixed models .",
    "recall that conditionally @xmath184 , where @xmath185 and @xmath186 are given in ( [ mut ] ) and ( [ sigt ] ) , respectively .",
    "the conditional distribution given @xmath80 implies that @xmath187 is a standard normal pivot since @xmath188 .",
    "let @xmath189 . for",
    "@xmath180 given in ( [ eblup ] ) , we want to obtain a distribution of @xmath190 this distribution is denoted by @xmath191 . if there were constants @xmath192 and @xmath193 such that @xmath194=1-\\al$ ]",
    ", one would get a @xmath195 prediction interval @xmath196.\\ ] ] however , @xmath197 is directly affected by the randomness of @xmath154 , and the distribution @xmath191 of ( [ ed ] ) depends on unknown parameters .",
    "thus , @xmath192 and @xmath193 are not free from unknown parameters .",
    "a feasible approach is an asymptotic approximation of @xmath191 .",
    "since the estimator @xmath198 is consistent from lemma [ paraest ] , it can be seen that @xmath191 converges to the standard normal distribution as @xmath14 tends to infinity . by approximating @xmath192 and @xmath193 with quantiles of the standard normal distribution",
    ", we can construct a prediction interval of @xmath179 .",
    "however , the accuracy of this prediction interval can be confirmed that order @xmath199 , so that such an approximation does not guarantee enough accuracy .    to obtain a prediction interval with accuracy up to @xmath200",
    ", we consider to estimate the distribution @xmath191 based on the parametric bootstrap method .",
    "let @xmath201 s be a bootstrap sample which is generated as @xmath202 where @xmath203 s and @xmath204 s are mutually independently distributed as @xmath205 and @xmath206 .",
    "the estimator @xmath207 is calculated from @xmath208 s with the same methods as used to obtain @xmath198 .",
    "let @xmath209 and @xmath210 for @xmath211 and @xmath212 . for @xmath213",
    ", consider the distribution of @xmath214 which is denoted by @xmath215 . as shown in theorem [ thm.boot ] given below , the distribution @xmath191 in ( [ ed ] ) can be approximated by the bootstrap distribution @xmath216 with accuracy of order @xmath217 . using this approximation , we then proceed to obtain a prediction interval .",
    "[ thm.boot ] under assumptions [ barx ] and [ var ] , we have @xmath218    the proof of theorem [ thm.boot ] is given in the appendix .",
    "a direct application of theorem [ thm.boot ] is the following result on highly accurate prediction intervals .",
    "[ cor.boot ] for any @xmath219 , let @xmath220 and @xmath221 be appropriate quantiles based on the bootstrap sample such that @xmath222 where @xmath223 is the distribution function of @xmath224 .",
    "then , one gets the prediction interval of @xmath179 given by @xmath225.\\ ] ] under assumptions [ barx ] and [ var ] , it holds that @xmath226    corollary [ cor.boot ] gives us a highly accurate prediction interval of @xmath179 based on teblup .",
    "the prediction interval @xmath227 implies that one can figure out precision of teblup with the length of the interval @xmath227 .",
    "it is also noted that the coverage accuracy of the prediction interval given in corollary [ cor.boot ] can be further improved up to @xmath228 with one round of calibration .",
    "we next construct a conditional prediction interval given data in the area of interest . when data @xmath80 are observed from the @xmath16-th area , booth and hobert ( 1998 ) , datta , kubokawa , molina and rao ( 2011 ) , sugasawa and kubokawa ( 2014 ) and torabi and rao ( 2013 ) treated the conditional mse of the eblup @xmath180 given @xmath80 , namely , @xmath229 $ ] .",
    "this conditional mse measures how much the eblup has an estimation error given the data @xmath80 , and this conditional approach may be appealing because it conditions on the data in the area of interest . in this subsection",
    ", we construct a conditional prediction interval @xmath230 given @xmath80 such that @xmath231 to this end , we need to approximate the conditional distribution of @xmath232 given @xmath80 .",
    "denote this conditional distribution by @xmath233 .",
    "the difference between the unconditional and conditional prediction intervals is that the unconditional distribution of @xmath234 is considered in ( [ ed ] ) , while the conditional distribution of @xmath234 given @xmath80 is treated .",
    "it is noted that there is a correlation between @xmath12 and @xmath80 in ( [ cp ] ) , namely , the conditional distribution of @xmath12 given @xmath80 is @xmath235 for @xmath185 and @xmath236 given in ( [ mut ] ) and ( [ sigt ] ) .",
    "since it is difficult to derive an exact conditional distribution of @xmath234 given @xmath80 , we suggest to approximate it via the parametric bootstrap method . a bootstrap sample is generated as @xmath237 where @xmath238 s and @xmath239 s are mutually independently distributed as @xmath240 and @xmath241 .",
    "let @xmath242 for @xmath243 .",
    "noting that @xmath80 is fixed , we can construct the estimator @xmath244 from @xmath245 with the same technique as used to obtain @xmath198 .",
    "let @xmath246 and @xmath247 for @xmath248 and @xmath249 .",
    "let @xmath250 be a random variable having @xmath251 for @xmath252 .",
    "then , for fixed @xmath80 , we consider the distribution of @xmath253 which is denoted by @xmath254 .",
    "similarly to the unconditional case , we can obtain a conditional prediction interval via the parametric bootstrap approximation .",
    "[ thm.boot.cond ] under assumptions [ barx ] and [ var ] , we have @xmath255    the proof of theorem [ thm.boot.cond ] is given in the appendix . from theorem [ thm.boot.cond ]",
    ", we obtain a conditional prediction interval with second - order accuracy .",
    "[ cor.boot.cond ] for any @xmath219 , let @xmath256 and @xmath257 be appropriate quantiles based on the bootstrap sample such that @xmath258 where @xmath259 is the distribution function of @xmath260 .",
    "then , one gets the prediction interval of @xmath179 given by @xmath261.\\ ] ] under assumptions [ barx ] and [ var ] , it holds that @xmath262",
    "in this section , we investigate performances of the procedures suggested in the previous sections by monte carlo simulation .",
    "we investigate disadvantages when we use a misspecified transformation under dpt or dplt .",
    "+ * [ tnerm with dpt ] *   since the purpose of small area estimation is to predict the mean of each small area as accurately as possible , we begin by comparing the prediction error among tnerm with dpt , the log - transformed nerm and the non - transformed nerm .",
    "we generate observations from the model @xmath263 for @xmath264 and @xmath265 , where @xmath3 and @xmath4 are generated from @xmath266 with @xmath267 and @xmath268 with @xmath269 , respectively , @xmath270 are generated from @xmath268 , which are fixed through simulation runs , and @xmath271 .",
    "we consider the 6 patterns of @xmath1 .",
    "we note that the log - transformation is a misspecified transformation when @xmath272 , and the identity transformation is always misspecified regardless of @xmath1 .",
    "the true values we want to predict is @xmath273 let @xmath274 be the teblup defined in ( [ teblup ] ) and let @xmath275 and @xmath276 be predictors based on the log - transformed nerm and the non - transformed nerm , respectively",
    ". then we can define the prediction mean squared error ( pmse ) as @xmath277 , \\ \\ \\ \\ k=1,2,3\\ ] ] which can be estimated based on @xmath278 simulation runs . to see the differences among pmse@xmath279 , we calculate the improvement ratio of pmse ( irp ) defined as @xmath280",
    "the simulation results are given in table 1 .",
    "it is observed that pmse in log - nerm gets worse than that in tnerm when @xmath1 is away from @xmath281 . when @xmath282 , the log - transformation is the true transformation , so that it is natural that pmse in tnerm is slightly larger than that in log - nerm since there is an estimation error of @xmath1 in tnerm . in the conventional non - transformed nerm ,",
    "the prediction errors are always bad compared to the other two models , but gets better as @xmath1 gets larger .",
    "this is because the dpt is similar to the identity transformation when @xmath1 is close to @xmath283 .",
    "we next investigated the percentage of zero estimates of @xmath31 , variance of random effects .",
    "zero estimates of @xmath31 means that the resulting eblup estimator of a small area mean is over - shrunk to the regression estimator .",
    "such a situation is not preferable in practice and recently li and lahiri ( 2010 ) and yoshimori and lahiri ( 2014 ) discussed this problem .",
    "based on the same simulation runs , we calculate the percentage of zero estimates of @xmath31 .",
    "we report the simulation result in table 1 .",
    "the percentage in log - nerm is slightly larger compared to tnerm , and the percentage in conventional nerm are always large but gets smaller as @xmath1 goes to @xmath283 , which seems to be the same reason in the prediction error .",
    ".the percentage ratio of prediction errors in tnerm with dpt compared to log - transformed nerm and nerm , and the percentage of zero estimates of @xmath31 for three models . [",
    "cols=\"^,^,^,^,^,^,^,^,^,^,^,^,^ \" , ]",
    "in this paper , we have suggested the parametric transformed nested error regression model ( tnerm ) as a new unit - level model for analysis of positive or bounded small area data .",
    "we have provided the procedures for estimating unknown parameters including the transformation parameter as well as regression coefficients and the variance components .",
    "as parametric transformations , we consider the dual power transformation for positive data and the dual power logistic transformation , which we newly proposed in this paper , for bounded data .",
    "the transformed eblup ( teblup ) has been made based on the consistent estimators , and unconditional and conditional prediction intervals with second - order accuracy have been constructed based on the parametric bootstrap method . through the simulation , it is confirmed that prediction accuracy can be bad and the percentage of zero estimation of @xmath284 tends to be large under misspecified transformation , which motivated us to take the transformation parameter into account of model formulation .",
    "the finite sample performances of proposed prediction intervals have been confirmed by simulation as well and the coverage probability of the suggested prediction intervals is close to the nominal level @xmath285 . for real data applications , we applied tnerm to survey ( positive ) data in japan and famous crop areas ( bounded ) data treated in battese , @xmath183 ( 1988 ) .",
    "the crucial properties of dpt and dplt for giving validity of proposed methodology in this paper are summarized in the appendix and we can use another parametric transformation as alternative to dpt or dplt whenever it holds the properties .",
    "our proposed methodology based on the parametric transformation is regarded as a new framework to cope with small - area data , and we hope further development will be studied from theoretical and practical aspects in statistical inferences .          for notational convenience ,",
    "let @xmath286 for @xmath287 be the partial derivative of @xmath288 , i.e. @xmath289 . for example , @xmath290 , @xmath291 and others .",
    "moreover @xmath292 or @xmath293 for @xmath294 means that @xmath295 or @xmath296 respectively .    in their proofs",
    ", the following fact will be heavily used : assume that for @xmath15 , a function @xmath297 is independent of @xmath298 for @xmath299 , and that @xmath300 and @xmath301=o(1)$ ] .",
    "then , it follows from the law of large numbers ( lln ) that @xmath302 moreover , if @xmath303=o(1)$ ] , then from the central limit theorem ( clt ) , one gets @xmath304",
    "\\bigr ) \\big|\\y_i = o_p(1 ) , \\ \\ \\ i=1,\\ldots , m,\\ ] ] where @xmath305 denotes a random variable given @xmath80 . in the proofs , for notational simplicity , we treat the case of @xmath306 without loss of generality .          *  @xmath288 is a monotone increasing function of @xmath307 ( @xmath308 ) and its range is @xmath309 , where @xmath310 is the domain of transformation , namely @xmath311 for dpt and @xmath312 for dplt .",
    "*  @xmath288 and @xmath313 are three times continuously differentiable , where @xmath314 is the inverse function of @xmath288 defined by @xmath315 . *  the moments of the following exist for each fixed @xmath316 : + ( 1 ) @xmath317 and @xmath318 , + ( 2 ) @xmath319 , @xmath320 and @xmath321 , + ( 3 ) @xmath313 , @xmath322 , @xmath323 , @xmath324 , @xmath325 and @xmath326 , + where their expectations are taken with respect to @xmath288 which is normally distributed .",
    "property ( p.1 ) means that the transformation is a one - to - one and onto function from @xmath310 to @xmath37 .",
    "clearly , ( p.1 ) is not satisfied by the box - cox transformation ( box and cox , 1964 ) , but by the logarithmic transformation .",
    "properties ( p.2 ) and ( p.3 ) will be used for establishing consistency of estimators including transformation parameter @xmath1 and for constructing prediction intervals .",
    "especially , ( p.2 ) and ( p.3 ) ( 1 ) guarantees that the random variable @xmath327 given in ( [ eq.la ] ) converges in probability , and ( p.3)(2 ) guarantees that @xmath328 converges in probability .",
    "recall that @xmath329 .",
    "it is noted that @xmath330 here @xmath331 is expressed as @xmath332 where @xmath333 .",
    "note that @xmath334 since @xmath335 from ( [ clt ] ) and assumption [ barx ] .",
    "thus , @xmath336 .",
    "also , @xmath337 can be expanded as @xmath338 which implies that @xmath339 and @xmath340=o_p(m^{-1})$ ] from assumptions ( a.3 ) and ( a.4 ) . combining these observations and applying ( [ clt ] ) to the first term in the r.h.s . of ( [ a1.1 ] ) , one gets @xmath341 under assumptions [ barx ] and [ var ] .    to show @xmath342=\\o_p(m^{-1/2})$ ] , from ( [ a1.1 ] ) , it is sufficient to show that @xmath343=o_p(m^{-1})$ ] . note that @xmath344 is rewritten as @xmath345 noting that @xmath346 are independent of @xmath347 , @xmath348 , @xmath349 and @xmath350 under assumption [ barx ] , one gets @xmath351\\\\ & = \\bigl(\\sum_{i=1}^m\\frac{n_i\\barx_i\\barx_i'}{1+n_i\\rho}+\\sum _ { i=1}^m\\sum_{j=1}^{n_i}\\x_{ij}\\x_{ij}'\\bigr)^{-1}\\left(\\frac{n_m\\barx_i\\big(z_m(\\la)-\\barx_m'\\bbe\\big)}{1+n_m\\rho}+\\sum_{j=1}^{n_i}\\x_{mj}(h(y_{mj},\\la)-\\x_{mj}'\\bbe)\\right)\\\\ & = \\o_p(m^{-1}).\\end{aligned}\\ ] ] to show the third part , by straightforward calculation , one gets @xmath352 where @xmath353 , @xmath354 since @xmath355 , we have @xmath356 . also note that that @xmath357 from assumption ( a.8 ) .",
    "then , we have @xmath358&=\\bigl(\\sum_{i=1}^m\\frac{n_i\\barx_i\\barx_i'}{1+n_i\\rho}+\\sum _ { i=1}^m\\sum_{j=1}^{n_i}\\x_{ij}\\x_{ij}'\\bigr)^{-1}\\bigl(\\sum_{i=1}^{m-1}\\frac{n_i\\barx_ie[z_i(\\la)]}{1+n_i\\rho}+\\sum _ { i=1}^{m-1}\\sum_{j=1}^{n_i}\\x_{ij}e[h_{\\la}(y_{ij},\\la)]\\bigr)\\\\ & + \\bigl(\\sum_{i=1}^m\\frac{n_i\\barx_i\\barx_i'}{1+n_i\\rho}+\\sum _ { i=1}^m\\sum_{j=1}^{n_i}\\x_{ij}\\x_{ij}'\\bigr)^{-1}\\left(\\frac{n_m\\barx_mz_m(\\la)}{1+n_m\\rho}+\\sum_{j=1}^{n_m}\\x_{mj}h_{\\la}(y_{mj},\\la)\\right)+\\o_p(m^{-1/2}).\\end{aligned}\\ ] ] hence , one gets @xmath359\\bigr ) \\bigr|\\y_m\\\\ & = \\bigl(\\frac1m\\sum_{i=1}^m\\frac{n_i\\barx_i\\barx_i'}{1+n_i\\rho}+\\frac1m\\sum _ { i=1}^m\\sum_{j=1}^{n_i}\\x_{ij}\\x_{ij}'\\bigr)^{-1}\\frac{\\sqrt{m-1}}{\\sqrt{m}}\\frac1{\\sqrt{m-1}}\\\\ & \\ \\ \\ \\times\\left(\\sum_{i=1}^{m-1}\\frac{n_i\\barx_i}{1+n_i\\rho}\\bigl\\{z_i(\\la)-e[z_i(\\la)]\\bigr\\}+\\sum_{i=1}^{m-1}\\sum_{j=1}^{n_i}\\x_{ij}\\bigl\\{h_{\\la}(y_{ij},\\la)-e[h_{\\la}(y_{ij},\\la)]\\bigr\\}\\right)+\\o_p(1),\\end{aligned}\\ ] ] which is of order @xmath360 , since it follows from clt and assumption [ barx ] , @xmath361\\bigr\\}=\\o_p(1).\\ ] ] and @xmath362\\bigr\\}=\\o_p(1)\\ ] ] therefore , lemma 1 is proved .",
    "we can easily verify that assumptions ( a.3 ) and ( a.4 ) are satisfied for the three estimators of @xmath133 based on their stochastic expansions given in prasad and rao ( 1990 ) , datta and lahiri ( 2000 ) and das , jiang and rao ( 2004 ) .",
    "thus , we shall check assumptions ( a.8 ) and ( a.6 ) for @xmath306 .    *",
    "[ 1 ]   pr estimator . *",
    "recall that @xmath145 is given in ( [ pr ] ) .",
    "for @xmath126 , @xmath363 where @xmath364 .",
    "then from ( [ lln ] ) and ( [ clt ] ) , it follows that @xmath365=o_p(1 ) \\ \\ { \\rm and}\\ \\ \\frac1m\\bigl ( \\pdl s_1(\\la)-\\frac1me\\bigl[\\pdl s_i(\\la)\\bigr|\\y_m\\bigr]\\bigr)\\bigr|\\y_m = o_p(m^{-1/2}).\\ ] ] for @xmath127 , we can show similar properties since @xmath366 thus , assumptions ( a.8 ) and ( a.6 ) are satisfied .    * [ 2 ]  ml . *   the ml estimator @xmath146 is given in ( [ ml ] ) . from the implicit function theorem ,",
    "@xmath367 where @xmath368 by straightforward calculation , it is shown that @xmath369 where @xmath370 which is of order @xmath360 under assumption 1 and 2 .",
    "then from the above expression , it easily follows that @xmath371 since @xmath372 , are mutually independent random vectors @xmath373={\\bf 0}$ ] , it is seen that @xmath374 from ( [ clt ] ) .",
    "thus , @xmath375 , namely , @xmath376 also , we obtain @xmath377 which implies that @xmath378 since @xmath379 and it depends only on @xmath80 of @xmath83 , from ( [ lln ] ) and ( [ clt ] ) , one gets @xmath380\\big)\\bigr|\\y_m = o_p(m^{-1/2}).\\ ] ]    we next evaluate @xmath381 .",
    "we here give a proof for @xmath382 , and we omit proofs for the other elements since they can be similarly proved . by a straightforward calculation , @xmath383 where @xmath384 which is @xmath385 since @xmath386 as in the proof of lemma [ hbeta ] .",
    "then , @xmath387 so that , we have @xmath388 since @xmath389=\\sige+n_i\\sigv$ ] .",
    "this demonstrates that the leading term is of order @xmath390 .",
    "since the other elements of @xmath381 can be evaluated similarly , we have @xmath391 where @xmath392 is a non - stochastic matrix with bounded entries , i.e. @xmath393.therefore , one gets @xmath394 which shows that the ml estimator satisfies assumption ( a.8 ) .",
    "moreover , @xmath395\\bigr)\\big|\\y_m\\\\ & = \\c(\\btheta)^{-1}m^{-1/2}\\bigl(\\j(\\la)-e\\bigl[\\j(\\la)\\bigr|\\y_m\\bigr]\\bigr)|\\y_m+\\o_p(1),\\end{aligned}\\ ] ] which is of order @xmath360 .",
    "thus , ( a.6 ) is satisfied .",
    "* [ 3 ]  reml *   recall that reml is given in ( [ rml ] ) . from the implicit function theorem , @xmath396 where @xmath397 is defined in ( [ j ] ) and @xmath398 for @xmath399 $ ] and @xmath400 $ ] .",
    "then , the result follows if @xmath401 and @xmath402 , which can be seen from assumptions [ barx ] and ( a.3 ) .",
    "we begin by demonstrating the consistency of @xmath154 . according",
    "the cramer method explained in jiang ( 2010 ) , we show that the equation @xmath403 includes a solution which converges to @xmath1 in probability .",
    "let @xmath404 for scalar @xmath405 .",
    "then , it can be seen that @xmath406 converges to @xmath407 in probability , where @xmath408.\\ ] ] when @xmath409 , it is noted that @xmath410 , since @xmath411=0 $ ] . since @xmath407 is continuous , without loss of generality",
    ", we have @xmath412 and @xmath413 for some positive @xmath414",
    ". then , @xmath415 and @xmath416 converge to @xmath412 and @xmath413 , respectively , in probability .",
    "this implies that both probabilities @xmath417 and @xmath418 converge to one as @xmath96 .",
    "in fact , for instance , the former result follows from the fact that @xmath419 as @xmath96 since @xmath420 .",
    "thus , for any @xmath421 , there exists an @xmath422 such that for any @xmath423 , @xmath424 and @xmath425 .",
    "note that the intersection of the events @xmath426 and @xmath427 implies that @xmath154 is included in the interval @xmath428 , namely , @xmath429 .",
    "hence , @xmath430 which means that @xmath154 is consistent .",
    "we next show that @xmath431 in the case of @xmath306 . to this end , we expand the equation ( [ eq.la ] ) around @xmath1 to get @xmath432 where @xmath433 is an intermediate value between @xmath1 and @xmath154 . for the numerator in ( [ consist ] ) , from lemma [ hbeta ] and assumption [ var ] , it is seen that @xmath434 where @xmath435 for @xmath436 and the density function @xmath437 of @xmath80 .",
    "since @xmath438 are mutually independently distributed with @xmath439=0 $ ] , from ( [ clt ] ) , it is seen that @xmath440 for the denominator in ( [ consist ] ) , it follows from the consistency of @xmath154 that @xmath441 by straightforward calculation , it can be seen from lemma 1 and assumption [ var ] that @xmath442 we shall evaluate the terms @xmath443 under assumption 1 .",
    "it is easy to see that @xmath444 and @xmath445 by ( [ lln ] ) . similarly under assumptions 1 and [ var ]",
    ", we have @xmath446 by ( [ lln ] ) . to evaluate @xmath447 ,",
    "the expression is rewritten as @xmath448 where @xmath449 from lemma 1 .",
    "then from ( [ lln ] ) , @xmath450 . for @xmath451 , it is observed that the each element of @xmath452 is of order @xmath453 , since @xmath454 under assumption [ var ] .",
    "furthermore , the expression of @xmath451 reduces to @xmath455 $ ] , where @xmath456 from ( [ lln ] ) and assumption 1 , we have @xmath457 so that @xmath458 .",
    "since @xmath459 is an @xmath73 matrix , it follows that @xmath460 .",
    "these observations show that the denominator in ( [ consist ] ) is of order @xmath453 .",
    "hence , one gets @xmath461 , namely , @xmath431 .",
    "finally , we show that @xmath462=o_p(m^{-1})$ ] . evaluating the term in ( [ consist ] )",
    "more precisely based on the fact that @xmath431 , we can approximate @xmath463 stochastically as @xmath464 let @xmath465 $ ] , which is of order @xmath466 . from lemma [ hbeta ] and assumption [ var ]",
    ", it easily follows that @xmath467 then , one gets @xmath468 , so that @xmath469=-{m}^{-1}e[f(\\hbbe(\\la),\\hsigv(\\la),\\hsige(\\la),\\la)]+o(m^{-1}).\\ ] ] note that @xmath470 is evaluated as @xmath471 from assumption ( a.4 ) , it is easy to see that @xmath472=o_p(m^{-1})$ ] and @xmath473=\\o_p(m^{-1})$ ] , which conclude that @xmath474=o_p(m^{-1})$ ] . therefore , the proof is complete .    from lemma 3 , we need to establish the results for @xmath175 and @xmath113 .",
    "let @xmath306 . from lemmas [ hbeta ] and [ est.la ] , we have @xmath475\\bigr)(\\hla-\\la)\\big|\\y_m\\\\ & \\ \\ \\ \\ + e\\bigl[\\frac{\\pd}{\\pd\\la}\\hbbe(\\la)\\big|\\y_m\\bigr](\\hla-\\la)\\big|\\y_m+\\o_p(m^{-1})\\\\ & = e\\bigl[\\frac{\\pd}{\\pd\\la}\\hbbe(\\la)\\big|\\y_m\\bigr](\\hla-\\la)\\big|\\y_m+\\o_p(m^{-1}),\\end{aligned}\\ ] ] since @xmath476=\\o_p(1)$ ] .",
    "then , one gets @xmath477 and @xmath478 = \\o_p(m^{-1})$ ] from lemmas 1 and 3 .",
    "similarly , the results for @xmath113 follow from lemma [ est.la ] and assumption [ var ] , since @xmath479(\\hla-\\la)\\big|\\y_m+\\o_p(m^{-1}),\\end{aligned}\\ ] ] where @xmath480=\\o_p(1)$ ] . therefore , the proof is complete .",
    "it is first noted that in the proof , the capital @xmath481 , with or without suffix , means a generic constant .",
    "if @xmath482 is expanded as @xmath483 where @xmath484 is a smooth function with @xmath390 , then the corresponding expansion holds for @xmath485 , namely , @xmath486 thus , one gets @xmath487 which establishes the result given in theorem [ thm.boot ] .",
    "hence , we shall show the expansion ( [ a5.1 ] ) through the following steps .",
    "since the inequality @xmath488 for any @xmath489 is equivalently rewritten as @xmath490 , we have @xmath491\\\\ & = e\\bigl(p\\bigl[\\si_i^{-1}(\\xi_i-\\xih_i(\\bth))\\leq \\si_i^{-1}\\bigl\\{h(h^{-1}(\\xih_i^{eb}+q\\sih_i,\\hla),\\la)-\\xih_i(\\bth)\\bigr\\}\\bigr]\\bigr| \\y\\bigr)\\\\ & = e\\bigl [ \\phi(q+r(q,\\y))\\bigr],\\end{aligned}\\ ] ] where @xmath492 is a cumulative distribution function of the standard normal distribution and @xmath493 for the standard normal density function @xmath494 , the first and second derivatives are written as @xmath495 for @xmath496 .",
    "the taylor expansion is applied to get @xmath497-\\frac12q\\phi(q)e[r^2(q,\\y)]\\\\ & + \\frac12e\\bigl[\\int_q^{q+r(q,\\y)}\\bigl ( q+r(q,\\y)-x \\bigr)^2(x^2 - 1)\\phi(x)dx\\bigr ] \\\\ & = \\phi(q)+\\phi(q)t_1(q)-\\frac12q\\phi(q)t_2(q)+t_3(q),\\end{aligned}\\ ] ] where @xmath498 $ ] , @xmath499 $ ] and @xmath500 $ ] for @xmath501 .",
    "note that @xmath502 and @xmath503 for @xmath504 .",
    "then , @xmath505 \\leq e\\bigl[r^2 \\int_q^{q+r}2\\phi(\\sqrt{3})dx\\bigl ] \\leq c_1e\\bigl[|r|^3\\bigr],\\end{aligned}\\ ] ] which implies that @xmath506).\\ ] ]     we shall show that @xmath507 based on an expansion of @xmath508 .",
    "it follows from this property that @xmath509 and @xmath510 .",
    "let @xmath511 .",
    "then , @xmath512 where @xmath513 .",
    "since @xmath514 for @xmath515 , we have @xmath516 it is here noted that @xmath517 , which will be shown in ( step 3 ) below .",
    "then it follows from assumption [ trans ] that @xmath518 , @xmath519 and @xmath520 are @xmath453 .",
    "thus , @xmath521 for @xmath522 .",
    "since @xmath523 , it can be observed that @xmath524 , which results in @xmath525 also , the expectation of @xmath526 is evaluated as @xmath527 = \\si_i^{-1}e\\bigl [ g(\\y_i,\\bth ) e(q|\\y_i)\\bigr]+o(m^{-1 } ) .",
    "\\label{r}\\ ] ]      to get the expansion ( [ a5.1 ] ) , it is sufficient to show that @xmath517 and @xmath528=o_p(m^{-1})$ ] from ( [ r ] ) . to this end , decompose @xmath529 as @xmath530 , where @xmath531 from ( [ q1 ] ) , @xmath532 is expanded as @xmath533 where @xmath534 and @xmath535 .",
    "it is here noted that @xmath536=o_p(m^{-1 } ) , \\label{a5.5}\\ ] ] which will be shown in ( step 4 ) below .",
    "then , it follows that the last two terms of the expansion of @xmath532 are @xmath537 given @xmath80 , and @xmath538 by the similar argument .",
    "thus , @xmath539=h_x^{-1}(\\xih_i(\\bth)+q\\si_i,\\la)e(u|\\y_i)+o_p(m^{-1 } ) = o_p(m^{-1}).\\ ] ] also , @xmath540 is expanded as @xmath541 where @xmath433 is intermediate value between @xmath1 and @xmath154 . it can be observed that @xmath542 , @xmath543 under assumption [ trans ] and @xmath155 from lemma 4 .",
    "thus , @xmath544 and @xmath545&=e\\bigl [ h^{-1}_{\\la}(\\xih_i^{eb}+q\\sih_i,\\la)(\\hla-\\la ) \\bigr|\\y_i\\bigr]+o_p(m^{-1})\\\\ & = e\\bigl[\\bigl\\{h^{-1}_{\\la}(\\xih_i^{eb}+q\\sih_i,\\la)-h^{-1}_{\\la}(\\xih_i(\\bth)+q\\si_i,\\la)\\bigr\\}(\\hla-\\la)\\bigr|\\y_i\\bigr]\\\\ & \\ \\ \\ \\ + h^{-1}_{\\la}(\\xih_i(\\bth)+q\\si_i,\\la)e(\\hla-\\la|\\y_i)+o_p(m^{-1})\\\\ & = o_p(m^{-1}),\\end{aligned}\\ ] ] since @xmath546 given @xmath80 is @xmath547 , which can be verified by @xmath548 and lemma [ paraest ] .",
    "it remains to show that @xmath549 and @xmath550 , for which it is sufficient to show that both @xmath551 and @xmath552 are @xmath547 and the conditional expectation given @xmath80 is @xmath537 .",
    "recall that @xmath534 .",
    "first , @xmath553 is rewritten as @xmath554 note that given @xmath80 , @xmath555 and @xmath556 further , from lemma [ paraest ] and a similar expansion as in ( [ hr ] ) , it follows that @xmath557 and @xmath558 .",
    "hence , one gest @xmath559 and @xmath560\\\\ & = e\\bigl[\\frac{\\rho n_i}{1+\\rho n_i}z_{i,\\la}(\\la)(\\hla-\\la)+\\frac{n_i}{(1+\\rho n_i)^2}(\\hr-\\rho)(z_i(\\la)-\\barx_i'\\bbe)\\bigr| \\y_i\\bigr]+o_p(m^{-1})\\\\ & = \\frac{\\rho n_i}{1+\\rho n_i}z_{i,\\la}(\\la)e[\\hla-\\la|\\y_i]+\\frac{n_i}{(1+\\rho n_i)^2}(z_i(\\la)-\\barx_i'\\bbe)e[\\hr-\\rho| \\y_i]+o_p(m^{-1}),\\end{aligned}\\ ] ] which is of order @xmath537 from lemma [ paraest ] .",
    "a similar evaluation for @xmath561 shows that given @xmath562 , @xmath563 then , from lemma [ paraest ] , it follows that @xmath564 and @xmath565=o_p(m^{-1})$ ] , which completes the proof .    as in the proof of theorem [ thm.boot ]",
    ", we obtain an asymptotic expansion of @xmath566 in the same settings of the proof of theorem [ thm.boot ] . then for any @xmath489",
    ", we have @xmath567.\\ ] ] since @xmath568=o_p(m^{-1})$ ] , we have an asymptotic expansion of @xmath566 as @xmath569 for an @xmath390 smooth quantity @xmath570 , which leads to the result by lemma 4 .",
    "chatterjee , s. , lahiri , p. and li , h. ( 2008 ) .",
    "parametric bootstrap approximation to the distribution of eblup and related predictions intervals in linear mixed models .",
    "_ , * 36 * , 1221 - 1245 .",
    "datta , g. s. , ghosh , m. , smith , d. d. and lahiri , p. ( 2002 ) . on an asymptotic theory of conditional and unconditional coverage probabilities of empirical bayes confidence intervals .",
    "_ , * 29 * , 139 - 152 .",
    "diao , l. , smith , d. d. , datta , g. s. , maiti , t. and opsomer , j. d. ( 2014 ) .",
    "accurate confidence interval estimation of small area parameters under the fay  herriot model . _",
    "_ , * 41 * , 497 - 515 ."
  ],
  "abstract_text": [
    "<S> for analyzing positive or bounded data , this paper suggests parametrically transformed nested error regression models ( tnerm ) , which transform the data flexibly to follow the normal linear mixed regression . as useful transformations , we consider the dual power transformation for positive data and the dual power logistic transformation newly proposed for bounded data . </S>",
    "<S> we provide a procedure for estimating consistently the parameters of the proposed model and a predictor based on the consistent estimators . </S>",
    "<S> then , in order to calibrate uncertainty of the transformed empirical best linear unbiased predictor , we derive both unconditional and conditional prediction intervals with second - order accuracy based on the parametric bootstrap method . </S>",
    "<S> the proposed methods are investigated through simulation and empirical studies .    </S>",
    "<S> dual power transformation , linear mixed model , nested error regression model , parametric bootstrap , prediction intervals , small area estimation . </S>"
  ]
}