{
  "article_text": [
    "many complex systems exhibit some degree of organization at different physical scales .",
    "often , the organization is hierarchical .",
    "there exist examples of this fact in variegated fields , like biological , social and technological systems . among the former , and starting from complex molecules ( such as lipids , proteins , rna or dna ) while increasing the scale of observation , new levels of organization",
    "are found : organelles , cells , tissues , organs , anatomical systems , organisms , populations and ecosystems . in the social context ,",
    "human societies organize from the level of individuals , groups , cities , up to the global scale of countries or continents .",
    "finally , among technological systems , computer networks are also arranged at different scales from the local network level up to the domain level routing systems that constitute the backbone of internet .",
    "hierarchical organizations seem ubiquitous in complex systems and , despite the early interest of the scientific community about the subject  @xcite , it is far from being fully understood .",
    "the description of hierarchical organization of complex systems remains , to a great extent , at the semantic level .",
    "this is mainly because the following difficulties : the existence of several relevant physical scales , the existence of a variety of organizing principles , the large number of components , and the lack of a generally enough and well defined formal theory for the identification of hierarchies .",
    "the study of complex networks  @xcite plays a central role in the characterization of the organization of complex systems .",
    "in essence , networks are used to represent the structure of the interactions between the components of the system under consideration .",
    "therefore , it is reasonable to assume that some complex networks have hierarchically organized topologies , reflecting the underlying hierarchical organization of the associated complex systems . a natural way of thinking about hierarchical network topologies is that of hierarchical community structures ; i.e.  communities within communities of nodes  @xcite . typically , the identification of the communities of a network is computationally intensive and a statistically difficult problem  @xcite .",
    "although a large number of community detection methods have been developed already  @xcite  including methods for the identification of hierarchical community structures   @xcite  not all methods provide comparable results .",
    "this is true , specially for hierarchical community structures .",
    "therefore , similarity measures for the comparison of hierarchical community structures are of crucial importance .",
    "the aim of this paper is to introduce an information - theoretic tool which can be used to compare hierarchies , or trees , which might be composed of network communities .",
    "we further show that this tool can be employed to trace the evolution of hierarchies when temporal networks are analyzed .    a standard way to quantify the similarity of two community structures is to compute the mutual information between the associated node partitions  @xcite . extending the idea , the present paper introduces a _ hierarchical mutual information _ , generalizing the traditional mutual information to work with hierarchical partitions . in principle",
    ", there might be different ways in which the mutual information can be generalized into a hierarchical mutual information . in this work , hierarchies are considered to be of divisive nature ; i.e.  the whole is divided into parts , each of which is sub - divided into sub - parts , an so on , following a top - down approach . as a consequence , in this",
    "context hierarchies are represented by trees with branches of varying length .",
    "other possible generalization approaches might exist .",
    "for example , generalizations that consider agglomerative hierarchies ",
    "i.e. bottom up approaches  or overlapping communities",
    ". alternatively , related methods exists for the comparison of phylogenetic trees  @xcite .",
    "recently , a method to compare hierarchies was introduced ; the method follows a combinatorial approach  @xcite .",
    "however , to the best of our knowledge , no previous method based on information - theoretic measures , exists for the comparison of hierarchies .",
    "these alternative methods , and the previously mentioned generalization approaches , are not discussed further in this paper , but can be considered in future works .",
    "the outline of the paper is the following . in section",
    "[ sec : theo ] , the hierarchical mutual information is motivated and introduced . in section  [ sec : resu ] , this measure is tested on different synthetic setups .",
    "more specifically , in sub - section  [ sec : resu : arthier ] , the behavior of the hierarchical mutual information is tested in artificial hierarchies ; while in sub - section  [ sec : resu : artnets ] , the hierarchical mutual information is used to analyze the hierarchical community structure of artificial networks , or network models .",
    "a similar procedure is performed on empirical networks in section  [ sec : resu : empnets ] , including the case of a temporal one .",
    "finally , the discussion and conclusions are summarized in section  [ sec : conclu ] .",
    "a hierarchical partition is a generalization of the traditional concept of partition . here",
    ", each element of the partition can be recursively partitioned into others , yielding a hierarchy .",
    "the formal definition is as follows .",
    "consider a set of elements , or universe , denoted by @xmath0 .",
    "an element in @xmath0 is denoted by @xmath1 .",
    "the set @xmath0 splits into a hierarchy of sub - sets , denoted by @xmath2 .",
    "the number of elements in the sub - set @xmath2 is written as @xmath3 . the _ hierarchical partition _ , or simply hierarchy ,",
    "is represented by a tree denoted by @xmath4 .",
    "the root @xmath5 is the `` oldest ancestor '' of the various vertices , or descendants in the tree @xmath4 . as a sub - set",
    ", the root contains the whole set of elements , i.e. @xmath6 . for any sub - set @xmath7 , @xmath8 denotes the set of direct descendants of @xmath2 .",
    "a sub - set @xmath2 is at the @xmath9-th level ( or depth ) of the hierarchy if @xmath9 is the topological distance from @xmath2 to @xmath10 .",
    "when there is no confusion , we simplify the notation to @xmath11 , i.e. by omitting the reference to @xmath4 .",
    "consider a network of nodes @xmath1 and links ( weighted or not ) @xmath12 . here , the terms _ elements _ and _ nodes _ are used interchangeably ; both , referring to the entities denoted by @xmath1 .",
    "traditionally , the community structure of a network is represented by a node partition . in many cases ,",
    "these communities present a hierarchical organization .",
    "in particular , if the hierarchy is constituted by sub - communities within communities , then the structure can be mapped to a hierarchical partition @xmath4 .",
    "depending on the context , @xmath4 is referred to as a tree , as a hierarchical community structure , or simply as a hierarchy ; i.e.  the terms are used interchangeably .",
    "each sub - set @xmath13 corresponds to one and only one sub - community of the network hierarchical community structure ( see fig .",
    "[ fig:1]a ) .",
    "the root @xmath10 represents the set of all nodes in the network .",
    "the children @xmath14 correspond to a partition of the sub - community @xmath2 into sub - communities @xmath15 .",
    "the leaves of @xmath4 are the smallest sub - communities of the network .",
    "finally , each sub - community @xmath13 has an associated sub - network with links @xmath16 , between the pair of nodes @xmath17 .      in this section , the definition of the _",
    "hierarchical mutual information _ is motivated .",
    "only shannon - based information measures are used throughout the rest of the paper  @xcite .",
    "consider how the uncertainty about the identification of a specific node @xmath1 is reduced when going down a tree @xmath4 . as the root @xmath5 represents the set of all nodes , to look for a specific node @xmath1 requires checking @xmath18 binary choices .",
    "in other words , the uncertainty is reduced by @xmath19 nats when a node @xmath1 is unequivocally identified  ( a nats is a unit of information equals to @xmath20 bits ) , and there is no uncertainty left . sometimes the information pointing towards a specific node is not precise , and the uncertainty reduction is not complete .",
    "for example , if node @xmath1 is specified to be in the sub - community @xmath2 , the uncertainty reduction is @xmath21 nats , and @xmath22 nats of uncertainty still remains .",
    "traversing a hierarchy along descendants is similar to a sequential reduction of uncertainty .",
    "more specifically , it is possible to write @xmath23 where @xmath24 is the deepest level at which node @xmath1 can be found . each term @xmath25 can be considered ed a conditional uncertainty reduction .",
    "specifically , how much the uncertainty is reduced when new information is gained ( that @xmath26 ) , given that some other information was already available ( that @xmath27 ) .",
    "it is possible to average over nodes @xmath1 using an appropriate weighted version of the expression in eq .",
    "( [ eq:1 ] ) .",
    "more specifically , the average uncertainty reduction along the tree @xmath4 is defined as @xmath28 where , for simplicity , we wrote the equation for the particular case in which all branches of the tree @xmath4 have the same length , i.e. @xmath29 for all @xmath30 .",
    "the general case is introduced later in sub - section  [ ss : theo : hmi : def ] . in eq .",
    "[ eq:2 ] , every reduction step is weighted by the fraction of nodes that are found by following the corresponding branch of the tree @xmath4 . using similar ideas ,",
    "the hierarchical mutual information is defined in the next section .      in community detection problems",
    ", it is customary to quantify the similarity between two inferred community structures using the mutual information between the corresponding node partitions  @xcite . here , the goal is to introduce the hierarchical mutual information to quantify the similarity between two hierarchical partitions , or trees , associated to corresponding hierarchical community structures .",
    "consider two trees @xmath4 and @xmath31 and two sub - communities @xmath13 and @xmath32 , both at the same topological distance , or level @xmath9 , from the roots of their corresponding trees .",
    "it is not necessary for the trees @xmath4 and @xmath33 , nor the sub - communities @xmath2 and @xmath34 to contain the same elements .",
    "let @xmath35 represent the sub - tree of root @xmath2 obtained from @xmath4 .",
    "the analogous holds for @xmath36 . the hierarchical mutual information between the sub - trees @xmath35 and @xmath36 is denoted by @xmath37 . by definition",
    ", it is assumed that @xmath38 if either @xmath2 or @xmath34 is a leaf of the corresponding tree .",
    "otherwise , @xmath37 is recursively defined by the formula @xmath39 in eq .",
    "[ eq:3 ] , the first term of the r.h.s .",
    "is called the _ one step mutual information _ , and is defined as @xmath40 where @xmath41 represents the shannon entropy .",
    "these terms are computed as @xmath42 and @xmath43 in all cases , the convention @xmath44 is adopted . finally , the hierarchical mutual information of two full trees @xmath4 and @xmath31 is denoted and defined by @xmath45 where @xmath10 and @xmath46 are the roots of @xmath4 and @xmath31 , respectively .",
    "each term involved in @xmath47 is non - negative , and thus , the hierarchical mutual information is a non - negative quantity . also , @xmath48 , i.e.  it is a symmetric function of its arguments .",
    "when the trees @xmath4 and @xmath31 are just stars , i.e.  a root plus one generation of descendants , it is possible to think of them as standard partitions . in this case , the hierarchical mutual information reduces to the standard mutual information .",
    "note , the hierarchical mutual information is not a measure of the similarity between the corresponding final partitions of the nodes at the leaves of the trees ( except when both trees are stars ) .",
    "rather , it is a summation of weighted local one - step contributions , measuring how similar the partitions are at each corresponding point in both trees .",
    "for example , if two nodes @xmath1 and @xmath49 are separated at level @xmath9 in tree @xmath4 and at level @xmath50 in tree @xmath31 then , the separation of @xmath1 and @xmath49 contributes with zero to the value of the hierarchical mutual information .    for practical purposes ,",
    "a _ normalized _ hierarchical mutual information is defined as @xmath51 we would like to notice the reader that there exists more than one way to normalize the mutual information . here , we work with one that takes inspiration from the cauchy - schwarz inequality but , future experiments may prove other normalization methods to be more convenient depending on the particular context in which the hierarchical mutual information is used .",
    "the value of @xmath52 lays in the interval @xmath53 $ ] and attains the maximum 1 if and only if @xmath54 , as indicated by the results of extensive numerical exploration reported in the following sections .",
    "however , formal proofs of the previous statements , and the following ones , are still missing . more specifically , it remains to be proved that : _",
    "@xmath55 for all @xmath4 and @xmath31 and , _ ii ) _ the equality holds if and only if @xmath54 .",
    "these statements imply the previous ones , and constitute desirable properties for a well defined measure of mutual information to have .",
    "to help better understand the hierarchical mutual information , a simple example is worked out explicitly .",
    "consider the set of nodes @xmath56 , and the two hierarchical partitions @xmath57 and @xmath58 ( see figs .  [ fig:1]b  and  [ fig:1]c ) . here , @xmath59 . also , @xmath60 and @xmath61 .",
    "in the tree @xmath4 , there is an intermediate sub - community @xmath62 which is not on the other tree @xmath31 . as a consequence , the one - step mutual information at level @xmath63 is @xmath64 ( see eq .",
    "[ eq:4 ] ) .",
    "all other terms corresponding to levels @xmath65 contribute with zero because they involve leaves .",
    "this is because the tree @xmath31 is just a star which has only one level .",
    "adding all together , @xmath66 . on the other hand , the _ self - hierarchical mutual informations _",
    "are @xmath67 and @xmath68 .",
    "therefore , the normalized hierarchical mutual information yields @xmath69 ; a value smaller than one . in other words ,",
    "these trees share only a fraction of the information they contain .",
    "this holds in spite that the partitions at the bottom are the same for both trees .    to facilitate future research , collaboration and scientific reproducibility",
    ", we provide python  @xcite code implementing the hierarchical partition data - structure and the hierarchical mutual information function , as an open - source package  @xcite .",
    "the example of figs .",
    "[ fig:1]b  and  [ fig:1]c is provided in the python package",
    ".     corresponds to a hierarchical partition , or tree @xmath4 .",
    "the root @xmath70 contains all the nodes of the network @xmath12 , and @xmath2 represents a sub - community level @xmath63 . in b ) and c ) , two simple hierarchical partitions , or trees , of the same set of nodes , @xmath71 , are presented . on the tree @xmath4 ,",
    "the node @xmath72 is separated from the other nodes @xmath73 at the level @xmath74 , while on the tree @xmath31 the separation occurs at level @xmath63 .",
    "this difference implies a normalized hierarchical mutual information smaller than one , even if the partition at the bottom of both trees is the same .",
    ", title=\"fig : \" ] ( -215,79)a ) +    corresponds to a hierarchical partition , or tree @xmath4 .",
    "the root @xmath70 contains all the nodes of the network @xmath12 , and @xmath2 represents a sub - community level @xmath63 . in b ) and c ) , two simple hierarchical partitions , or trees , of the same set of nodes , @xmath71 , are presented . on the tree @xmath4 , the node @xmath72 is separated from the other nodes @xmath73 at the level @xmath74 , while on the tree @xmath31 the separation occurs at level @xmath63 .",
    "this difference implies a normalized hierarchical mutual information smaller than one , even if the partition at the bottom of both trees is the same .",
    ", title=\"fig : \" ] ( -215,119)b ) ( -105,119)c )",
    "before focusing on the hierarchical community structures of networks , we analyze the behavior of the hierarchical mutual information when used to compare artificially generated hierarchical partitions .",
    "more specifically , hierarchies composed of binary trees @xmath4 containing @xmath75 elements @xmath1 , @xmath76 levels , and @xmath77 sub - communities including the root .",
    "each tree has one element @xmath1 per sub - community at the bottom level @xmath78 , two elements per sub - community at the previous level @xmath79 , and so on until it has @xmath80 elements at the root .    in the experiments ,",
    "the original trees are compared against correspondingly randomized ones .",
    "the idea is to show how the normalized hierarchical mutual information decays with respect to the level of randomization .",
    "two different randomization procedures are used .    in the first randomization procedure , pairs of elements",
    "are randomly chosen from the tree , and consecutively swapped until a fraction @xmath81 of them is affected .",
    "this is called the _",
    "basic _ randomization procedure . in fig .",
    "[ fig:2 ] , the average normalized hierarchical mutual information @xmath82 is plotted vs the fraction @xmath81 of randomized elements .",
    "the average is computed over 100 repetitions of the randomization procedure , for each value of @xmath81 and @xmath76 .",
    "notice , @xmath82 decays approximately in an exponential way with respect to @xmath81 ; further , it is almost independent of @xmath76 except for large values of @xmath81 , where finite size effects become important . in particular , when the hierarchy is fully randomized , i.e.  @xmath83 , the @xmath82 is non - zero .",
    "although _ a priori _ this may be attributed to an error , it is indeed an expected result for finite size hierarchies : random coincidences produce a non - zero amount of shared information .",
    "a similar result is known to hold for the traditional mutual information  @xcite .    in the second procedure ,",
    "the elements are also shuffled by swapping pairs chosen at random . however , a given pair is swapped only if both elements belong to the same sub - community at depth @xmath9 .",
    "in other words , the randomization procedure preserves the classification of the elements at the levels @xmath84 , while in the subsequent levels @xmath85 , the original classification is destroyed .",
    "again , the swapping procedure runs until a fraction @xmath81 of the elements is affected .",
    "this second procedure is called the _ level - preserving _ randomization procedure . in fig .",
    "[ fig:3 ] , the average normalized hierarchical mutual information @xmath86 is plotted as a function of @xmath81 for the level - preserving randomization procedure . here",
    ", experiments are repeated for different values of @xmath9 and fixed @xmath87 .",
    "averages are computed as it was done with the basic randomization procedure . in line with the previous result of fig .",
    "[ fig:2 ] , @xmath86 also decreases with @xmath81 following approximately an exponential decay .",
    "now the greater is the shuffling level @xmath9 , the slower is the decay .",
    "in particular , for @xmath88 no decay at all is observed , i.e.  @xmath89 for all @xmath81 .",
    "this is expected because trees have @xmath87 levels and only one element per sub - community at the bottom level , which do not contribute to the hierarchical mutual information .    , comparing hierarchical partitions represented by binary trees with @xmath76 levels , and corresponding randomized partitions with a fraction @xmath81 of the elements shuffled at random .",
    "the average is computed over 100 realizations of the shuffling procedure , and the different curves correspond to trees with different number of levels @xmath76 .",
    "the black dashed line corresponds to an exponential fit , @xmath90 with @xmath91 and @xmath92 , for the case @xmath93 .",
    "error bars and standard - deviation bars are not plotted for clarity . ]",
    "levels , and corresponding randomized partitions where a fraction @xmath81 of the elements are randomly shuffled .",
    "the randomization procedure preserves the element classification of levels @xmath84 , but affects the rest of the levels ( different curves with symbols ) .",
    "the dashed line is the best fit of an exponential decay @xmath94 , with @xmath95 and @xmath96 , for @xmath97 . for clarity , error bars and standard - deviation bars",
    "are not shown . ]",
    "one of the interesting applications of the normalized hierarchical mutual information is comparing the results yielded by different community detection methods . in this paper ,",
    "three community detection methods are compared : _ infomap _",
    "@xcite , which find a hierarchy of communities through the minimization of the description length of the path traversed by a random walker ; the _ hierarchical stochastic block model _ method ( hsbm )  @xcite , which fits a hierarchy of stochastic block models to the network topology ; a _ recursive louvain _ method ( rl ) , which recursively splits the network into a hierarchy of network modules using , at each step , the well - known louvain community detection algorithm  @xcite . in",
    "what follows , the relevant aspects of the different methods are considered in more detail .",
    "infomap return hierarchies that are consistent with a _ divisive _ algorithm , i.e.  the branches of the corresponding trees may have different depths . the algorithm itself uses both approaches , repeatedly .",
    "communities are split and merged until a minimum description length is attained . in the hierarchies obtained by this method ,",
    "the leaves have one and only one node . for the sake of comparison with the other methods ,",
    "these communities of size equal to one are ignored , except if same level communities of size larger than one exists .    at difference with infomap ,",
    "the hsbm merge nodes to generate super - nodes or communities , which are further merged to obtain the communities at the contiguous higher level , and so on . as a consequence ,",
    "all the branches of the returned trees have the same depth . moreover , the hsbm may return trees containing sub - communities with descendants but no further sub - divisions , i.e. , sub - communities with only one child . although the hierarchies produced by the hsbm can be compared using the hierarchical mutual information  as they are hierarchical partitions ",
    "the comparison are not fully appropriate .",
    "this is because the hierarchical mutual information is based on a divisive approach , while the hsbm is based on an agglomerative approach .",
    "the experiments involving the hsbm show how important is the difference between both kind of approaches .",
    "the recursive application of the louvain method is a mixed agglomerative - divisive algorithm .",
    "the standard louvain method is an agglomerative algorithm ; a community structure is obtained by merging modules until the _ modularity _",
    "@xcite of the partition , denoted by @xmath98 , reaches a maximum value  @xcite . on the other hand ,",
    "the recursive use of louvain presented here , is a divisive method .",
    "more specifically , given a network @xmath12 ( defining the level @xmath97 ) , a standard louvain method is applied to obtain a partition into sub - communities @xmath2 at level @xmath63 .",
    "then , louvain is applied again on each sub - community , to split each sub - network @xmath16 into sub - communities at level @xmath74 , and so on . in this way",
    ", a tree @xmath4 is generated .",
    "the division of a particular sub - community stops when the standard louvain returns a modularity @xmath99 .",
    "importantly , the louvain method is not deterministic , leading to stochastic differences from run to run .",
    "two important points have to be stressed : first , the use of louvain is circumstantial , any other modularity maximization procedure would produce similar results .",
    "second , the idea of a recursive application of a modularity based community detection algorithm is not new , and more elaborate algorithms do exist  @xcite .",
    "however , here rl is chosen for its simplicity .",
    "our main goals are : to show how the hierarchical mutual information behaves , and to illustrate how it can be used , without aiming to find the best community detection method .      in order to analyze the performance of the different community detection methods , in this section they are run on specific networks . here , two well - known benchmark network models are used to generate the networks necessary for the experiments . in principle , these network models are able to generate network samples with underlying hierarchical community structures . clearly , the specific characteristics of the generated networks depend on the parameter values chosen .",
    "the first network model is the hierarchical planted partition model ( hpm )  @xcite , a generalization of the planted partition model  @xcite where the network obtained is hierarchically arranged . in this model",
    ", @xmath80 nodes are connected according to a hierarchical structure of @xmath76 levels and a branching factor @xmath100 . for practical purposes",
    ", we chose @xmath101 nodes , @xmath102 levels and a branching factor @xmath103  ( see fig .",
    "[ fig:4 ] ) . at the root level , @xmath97",
    ", all nodes belong to the same community . at level @xmath63",
    ", there exist @xmath103 communities with @xmath104 nodes each .",
    "consecutively , at the final level @xmath74 , there are @xmath105 communities , with 32 nodes each .",
    "each node has an average of @xmath106 links to nodes exclusively within the community they belong at level @xmath9 , i.e.  @xmath107 , @xmath108 , @xmath109 to other nodes in the same communities at levels 2 , 1 , 0 , respectively .",
    "therefore , the total average degree of the nodes is @xmath110 . in principle , networks sampled from the hpm have the expected hierarchical community structure whenever @xmath111  @xcite .",
    "the second network model consists of _ sierpinski _ networks with @xmath76 levels .",
    "[ fig:1]a illustrates a sierpinski network with @xmath102 .",
    "these networks have a natural self - similar and hierarchical modular structure .",
    "a sierpinski network with a single level is just a clique with 3 nodes , i.e. a triangle .",
    "a network of this type with @xmath112 levels is obtained by by replacing each node of a sierpinski network with @xmath76 levels by a clique of size 3 .",
    "it is worth to point out that a sierpinski network with @xmath76 levels has @xmath113 nodes , @xmath114 \\sim e^l$ ] links , and its average degree @xmath115 when @xmath116 . to make the analysis more interesting",
    ", a fraction @xmath81 of the links in the sierpinski networks are randomly rewired .",
    "the rewiring procedure is well - known  @xcite .",
    "essentially , successive pairs of links , each of which is chosen at random , swap the nodes at their extremes until a fraction @xmath81 of the links is affected . in this way , there is a well - defined hierarchy of communities for @xmath117 , which is progressively blurred out as @xmath81 increases .    in the following sections ,",
    "the different community detection methods , and these two network models are combined into a set of experiments analyzed using the normalized hierarchical mutual information .     and @xmath118 .",
    "the network contains @xmath101 nodes , 4 big communities of 128 nodes each , and 16 small communities of 32 nodes .",
    "the darkest links connect pairs of nodes sharing the same small community at level @xmath74 , the links of intermediate brightness connect nodes sharing intermediate communities at level @xmath63 , but not sharing the same small communities . finally , the brightest links connect pairs of nodes at level @xmath97 , but not nodes sharing communities at levels @xmath63 and @xmath74 . ]",
    "each network model has an associated natural or _",
    "hierarchy , denoted as @xmath119 .",
    "specifically , the reference hierarchy for the sierpinski and hpm models are shown in figs .",
    "[ fig:1]a and [ fig:4 ] , respectively .",
    "the hierarchies identified by the community detection methods are not necessarily equal to the reference ones , and in some cases , they do nt even resemble it .",
    "the degree of fidelity of the community detection method measures how similar are the identified communities to the reference ones .",
    "formally , given a community detection method , a network sample @xmath12 and a reference hierarchy @xmath119 , the _ hierarchical - fidelity _  or simply , _",
    "fidelity _  of the community method is defined as the average normalized hierarchical mutual information , @xmath120 .",
    "the average is computed summing over an ensemble of hierarchies @xmath121 , obtained by repeatedly identifying the hierarchical community structure of the network @xmath12 , using the chosen community detection method . in the results shown ,",
    "the ensemble @xmath121 was composed by 100 hierarchies .",
    "furthermore , the fidelity is averaged by sampling 100 networks from each network model .",
    "the procedure is repeated for different values of the network models parameters , and using the different community detection methods .    for the case of the hpm ,",
    "two different model re - parameterizations are used . in one case the whole network structure change simultaneously , while in the other case , only one level is affected  @xcite .",
    "more specifically , in case 1 all parameters @xmath122 , and @xmath123 are linearly re - parameterized by @xmath124 $ ] , while @xmath107 is kept constant . in case 2 ,",
    "the parameters @xmath125 = 8 are kept constant , while @xmath126 changes linearly with @xmath127 . for the case of the sierpinski network model ,",
    "the parameter is the fraction of randomized links , @xmath81 , as mentioned in section [ sss : ahn ] . in",
    "what follows the results are presented and commented .",
    "first , the results of the fidelity for infomap are shown in fig .",
    "[ fig:5]a . in the hpm ,",
    "case 1 , infomap detects the reference hierarchy almost always for @xmath128 , and the fidelity is @xmath129 . on the other extreme , at @xmath130 ,",
    "infomap typically finds a one - level hierarchy composed of 4 communities with 128 nodes .",
    "the 4 communities are the right ones at the level @xmath63 , and the fidelity decays to @xmath131 .",
    "the decay in the fidelity is expected because all @xmath106 converge to the same value @xmath132 when @xmath133 , making the generated network hierarchies less defined . in case 2 , the same scenario occurs for @xmath134 , i.e. the same 4 communities are identified . on the other hand , for small @xmath127 ,",
    "the structure of the network is dominated by links at levels 0 and 2 . as a consequence , and depending on the particular network realization",
    ", infomap finds a one - level hierarchy with either 1 or @xmath135 communities , resulting in a small fidelity value . for the sierpinski networks ,",
    "the behavior can be more easily interpreted . for small @xmath81",
    ", infomap finds an approximately accurate representation of the exact hierarchy of communities .",
    "however , as @xmath81 grows , the hierarchy is quickly blurred out and the fidelity decays accordingly .",
    "the findings of the fidelity for the hsbm method are shown in fig .",
    "[ fig:5]b . for the hpm ,",
    "the fidelity is almost a constant function of @xmath127 , for both cases 1 and 2 .",
    "a closer inspection reveals that , typically , the hsbm method splits the network samples into two communities at level @xmath63 , which are then further subdivided , giving rise to a hierarchy with 3 levels .",
    "interestingly , the identified hierarchies are similar regardless of the value of @xmath108 .",
    "therefore , the resulting fidelity is relatively small because the identified hierarchies are significantly different for the reference one .",
    "in essence , the two communities identified at level @xmath63 mean a significant difference with respect to the expected value of 4 . for the case of the sierpinski model , the hsbm typically detects only one community , except for vanishing @xmath81 and @xmath136 where the network splits into two big ones . for this second model , the fidelity is also generally small .",
    "in our view , this occurs because of two characteristics of the hsbm . on the one hand",
    ", the hsbm follows a conservative approach ; no divisions are introduced until there is enough statistical evidence to justify them in terms of a hierarchy of stochastic block models . on the other hand ,",
    "the hsbm follows a bottom - up approach ",
    "the elements in @xmath0 are iteratively merged into modules , super - modules and so on , generating a tree @xmath4 with all branches of the same topological length  while the hierarchical mutual information is more appropriate to compare top - down hierarchies ( see [ sec : intro ] ) . in this sense",
    ", the comparison of the other methods with the hsbm by means of the hierarchical mutual information , highlights the crucial difference between top - down and bottom - up approaches .",
    "thirdly , the fidelity is computed for the recursive louvain method and the corresponding results are shown in fig .",
    "[ fig:5]c . for the hpm ,",
    "the fidelity is not a monotonic function of @xmath127 , instead it displays a maximum at an intermediate value of @xmath127 . in general , this method tends to find the right communities at the first level @xmath63 .",
    "however , the random fluctuations of the network samples become meaningful information for rl , and therefore it tends to split the networks into more communities than the originally found in the reference hierarchy . as a consequence , the normalized hierarchical mutual information yields values smaller than one . however , because the information shared at level @xmath63 is non - trivial and fairly accurate , the normalized hierarchical mutual information is far from being negligible . on the other hand , for the case of the sierpinski network model , rl has a poor performance .",
    "in essence , this method finds significantly more communities than expected , even at level @xmath63 , resulting in small fidelity values for all @xmath81 .          in the previous section",
    ", it was shown that each community detection method returns hierarchies different from the expected ones ; therefore , some questions arise .",
    "how mutually consistent are the returned hierarchies ?",
    "do these hierarchies represent noise , or represent a specific detected bias ?",
    "the following set of experiments addresses these questions .",
    "more specifically , the idea is to analyze how mutually similar , or consistent are the communities detected by the methods .",
    "formally , the _ hierarchical - consistency _  or just , _ consistency _  of a method is defined as the average normalized hierarchical mutual information @xmath137 , where the average is computed over an ensemble of pairs of hierarchies , @xmath138 .",
    "the hierarchies in the pairs are randomly chosen , without repetition , from the ensembles of hierarchies generated in the previous experiments about the fidelity .",
    "the procedure is repeated for each network sample in order to average the consistency .",
    "the whole procedure is repeated for the different network models and corresponding parameters .    in fig .",
    "[ fig:6]a , the consistency is analyzed when the hierarchical communities are detected by using infomap .",
    "for the hpm , case 1 ( see section [ sss : ahn ] ) , the consistency is @xmath129 for all values of @xmath127 .",
    "in other words , in this initial setting , infomap provides very consistent results always . for case 2 ,",
    "the fidelity is also close to 1 when @xmath127 is large ; however , the consistency becomes small for small @xmath127 .",
    "this is expected , as it was already mentioned infomap s detection is largely bimodal : either it finds one or @xmath135 communities depending on the network sample , and these two cases are very inconsistent with each other . for the sierpinski networks ,",
    "the consistency is large when @xmath139 and decays to a non - zero value for larger values of @xmath81 . in other words ,",
    "network randomization becomes important for large @xmath81 , but still , part of the information captured by infomap is already contained even in this case .",
    "the results of the consistency for the hsbm are shown in fig .",
    "[ fig:6]b . for the hpm ,",
    "the observed consistency is large in both cases , 1 and 2 , despite the small fidelity with respect to the natural hierarchies shown in fig .",
    "[ fig:5]b .",
    "this means that the hsbm return hierarchies similar to each other , but significantly different from the reference one . more specifically ,",
    "the returned hierarchies share similarities at level @xmath63 , but at the following levels the differences become important  except for case 1 at @xmath128 where the consistency remains @xmath129 . for the sierpinski network model ,",
    "the consistency is negligible in most of the range of @xmath81 .",
    "this is expected because a flat hierarchy conveys no information , and the hsbm typically returns trivial hierarchies for the sierpinski networks , i.e.  hierarchies with only one community , the root one . only for small values of @xmath81 , for the case @xmath136 ,",
    "the consistency is non - zero , but still with small values . here ,",
    "only two communities are identified , agreeing only over a small fraction of the nodes .    the consistency for the rl method is shown in fig .",
    "[ fig:6]c .",
    "for the hpm , the curves look similar to the ones corresponding to the fidelities in fig .",
    "[ fig:5]c .",
    "in essence , the computed hierarchies are very similar to each other , and to the reference hierarchy . for the sierpinski network model ,",
    "the consistency can be large , even if the fidelity is small .",
    "this means that the detected structure is invariably the same , although different from the reference one .",
    "it is clear that the different community detection methods return different results .",
    "however , it remains to analyze how similar are the results of one detection method with respect to one another .",
    "to address this point , the _ hierarchical - similarity _ between two community detection methods is defined as the average normalized hierarchical mutual information , @xmath140 . in shorthand ,",
    "we speak about the _ similarity _ , and he average is computed over pairs of trees , where the trees @xmath141 are computed with one of the methods , while the trees @xmath142 with the other method . both set of trees are computed from the same network sample .",
    "later , the similarity is averaged by sampling networks from the different network models .",
    "the procedure is repeated for each set of chosen values of the corresponding model parameters . in practice , the network samples and corresponding sampled trees used to compute the fidelities are the ones used to compute the similarities ( see figs .",
    "[ fig:5 ] and [ fig:6 ] ) .    combining the methods of infomap , hsbm and rl , three different comparisons are possible :",
    "infomap vs.  hsbm , infomap vs.  rl , and hsbm vs.  rl .",
    "these are presented in figs .",
    "[ fig:7]a ,  [ fig:7]b and  [ fig:7]c , respectively .",
    "the hsbm method shares a small similarity with the other two .",
    "this is expected , because the other methods lead to relatively large fidelities , while the hsbm does not .",
    "the similarity between infomap and the rl method is the largest among the three possibilities .",
    "however , the similarity can not be as large as the consistency .",
    "this is not surprising as infomap is able to return consistencies as large as 1 , while rl is not .",
    "the largest similarity value is @xmath143 , occurring at @xmath128 for the case 1 in the hpm . also , the similarity is @xmath144 at @xmath130 for both cases , 1 and 2 . for the sierpinski network ,",
    "the similarity reaches a maximum value @xmath144 for small @xmath81 , and it decays slowly up to @xmath145 for large @xmath81 .          the experiments of the previous section can be repeated using empirical networks  as opposed to network models  except for the computation of fidelity because , a priori , it is not clear which one is the concomitant reference hierarchy .",
    "notice however , this last possibility is not necessarily impossible for all empirical networks .",
    "many empirical networks have associated a hierarchical decomposition that can be used as a `` ground - truth '' about its hierarchical structure .",
    "let us remark here that by ground - truth we refer to the practical use of the term  @xcite .",
    "for example , the _ naics _",
    "@xcite codes for the case of financial networks  @xcite , and the _ harmonized system _",
    "@xcite for the case of the international trade network  @xcite . however , these studies are left open for future research and , in what follows , only consistencies and similarities are analyzed in different empirical networks .",
    "the networks in table  [ tab:1 ] ( referenced therein ) are the ones studied in the following analysis .",
    "all of these networks have convenient characteristics : they are large enough to show relatively rich hierarchical community structures ( e.g.   infomap returns up to five hierarchical levels for the case of the power - grid  @xcite ) , with diverse shape ( e.g. compare the case of the power - grid in fig .",
    "[ fig:8]a , with the case of the network - science in fig .",
    "[ fig:10]a ) , and small enough to keep the computation time bounded .",
    "originally , some of these networks had link weights , or self - loops .",
    "for the sake of simplicity , such attributes are removed from the networks . as an illustration of how different are the hierarchical community structures identified by the different community detection methods , fig .",
    "[ fig:8 ] shows the results for the power - grid network . in this figure",
    ", it is apparent that the different methods provide substantially different results .    in order to enrich the analysis ,",
    "the topology of the empirical networks is shuffled , following the same procedure applied to the sierpinski networks ( cf .",
    "section  [ sss : ahn ] ) . in this way",
    ", the obtained hierarchies are analyzed as a function of the fraction @xmath81 of randomized links .",
    "firstly , infomap is used to study the consistency of the empirical networks .",
    "the results are shown in fig .",
    "[ fig:9]a . for some networks , like the power - grid and the erds networks ,",
    "the identified hierarchies are largely affected by the randomization procedure , i.e.  the consistency quickly decays with @xmath81 .",
    "this is particularly reasonable for the power - grid network , as its hierarchy is embedded into space ; reshuffling the links attenuates the embedding , rapidly destroying its spatial nature  @xcite .",
    "there exist other networks like eva , geometry  and network - science , for which the consistencies of the identified hierarchies seem quite robust to the randomization procedure .",
    "this can be interpreted in two ways : on the one hand , this suggests that the hierarchical community structure is mainly determined by the node degrees in the networks or some other topological property that is not destroyed by the randomization procedure . on the other other hand",
    ", it may indicate that the the relatively large values of consistency are not significant from a hierarchical point of view .",
    "a closer inspection to the network - science  network reveals that the latter possibility is the cause .",
    "specifically , just a relatively small fraction of the network has a rich hierarchical structure with up to 4 levels .",
    "the rest of the network nodes are identified as communities at depth @xmath63 , which have no children sub - communities ( see fig .  [",
    "fig:10]a ) .",
    "the hierarchical part is washed out as @xmath81 grows , eventually leading to a star - like structure ( see figs .",
    "[ fig:10]b ,  [ fig:10]c  and  [ fig:10]d ) .",
    "the relatively large consistency values for large @xmath81 are the outcome of random coincidences occurring for these star - like structures .",
    "secondly , the hsbm method is used for the analysis and the results are shown in fig .",
    "[ fig:9]b .",
    "overall , a small consistency is obtained .",
    "this is because the hsbm method often finds a single community , except for the geometry network .",
    "this suggests that the hsbm finds a rich hierarchical structure for the geometry network in the form of nested block models .",
    "however , a closer inspection indicates that the hsbm identifies simply two large communities , i.e.  there is no hierarchy , similar to what is found for the network - science network for the case of infomap .",
    "this explains the slow decay of the consistency curve .",
    "thirdly , the consistency is studied using the rl method .",
    "the results are shown in fig .",
    "[ fig:9]c . in all cases",
    ", the consistency presents a smooth decay as a function of the randomization @xmath81 .",
    "this is not a surprise because rl tends to return trees with a large number of sub - communities and levels .",
    "therefore , the small changes occurring for increasing @xmath81 lead to small changes in the consistencies .    in figs .",
    "[ fig:11]a  and  [ fig:11]c , the average similarity between the hsbm method and the other two methods is shown as a function of @xmath81 . not surprisingly , the values obtained are small . however , it is interesting to note that , in certain cases , the similarity is larger than the corresponding values for the consistency .",
    "for example , cf .  the network - science network in fig .",
    "[ fig:9]b and fig .  [ fig:11]c , for small values of @xmath81 .",
    "even though at a first glance this may seem contradictory , the explanation is simple .",
    "the hsbm tends to return trivial hierarchies , yielding a value of zero for the hierarchical mutual information .",
    "then , when the consistency is computed , the number of terms contributing with zero to the average @xmath137 is proportional to @xmath146 , where @xmath147 is the probability for the hsbm to produce a non - trivial hierarchy . on the other hand ,",
    "such probability is @xmath148 for the case of the similarity because neither infomap and nor rl produce trivial hierarchies . in other words , the chances for zero terms to occur in the case of the consistency is significantly larger than for the case of the similarity .    in fig .",
    "[ fig:11]b , the similarity compares the results for infomap and rl .",
    "a sharp peak can be appreciated at @xmath149 .",
    "this is because infomap returns a sudden change over the number of identified hierarchies .",
    "namely , the hierarchies pass from having @xmath150 communities at level @xmath63 , to up to @xmath151 .",
    "this large number of communities at level @xmath63 is always present for the rl .",
    "therefore , the sharp increase occurs when the number of communities at level @xmath63 becomes large for infomap , i.e.  when it becomes similar for both methods .    .",
    "information summary about the empirical network datasets used in the calculations .",
    "@xmath80 is number of nodes and @xmath152 number of links .",
    "erds , network - science and geometry are scientific - collaboration networks .",
    "the power - grid is technological , and eva is a network of corporate inter - relationships .",
    "the networks marked with * were originally weighted . [ cols=\"^,^,^,^ \" , ]     ( -475,110 ) a ) ( -310,110 ) b ) ( -155,110 ) c )        ( -470,90 ) a ) ( -350,90 ) b ) ( -225,90 ) c ) ( -110,90 ) d )          in this section , the subject of study is slightly modified .",
    "specifically , the study of traditional complex networks is replaced by the study of correlation matrices computed from the log - returns of stock prices in the s&p500  @xcite .",
    "the data is obtained from _ yahoo ! finance _  @xcite . in general , the correlation matrices can be considered as weighted dense networks .",
    "complex networks are not necessarily static , but change in time  @xcite",
    ". the temporal aspect of a complex network could have dramatic consequences for the behavior of the associated system  @xcite .",
    "the correlation matrices of the s&p500  and the associated hierarchical community structures  can be studied in their time evolution  @xcite .",
    "therefore , we use the hierarchical mutual information to investigate the evolution of the hierarchical community structure of the financial activity in the s&p500 .",
    "the data encompasses the 390 stocks which uninterruptedly cover the 3522 working days from january @xmath153 , 1998 until december @xmath154 , 2011 , according to yahoo ! finance .",
    "each matrix entry of the correlation matrices is given by @xmath155 specifically , the r.h.s .",
    "[ eq:9 ] is the _ cross - correlation _ between the time series @xmath156 and @xmath157 , corresponding to the stocks @xmath158 and @xmath159 , respectively . in general , cross correlation matrices have off - diagonal entries in @xmath160 $ ] , while diagonal entries are equal to one . to simplify the analysis ,",
    "the correlation matrices are transformed according to the expression  @xcite , @xmath161 .",
    "the transformation returns a weighted network of non - negative entries and zero diagonals .",
    "the transformed networks are the ones used for the computation of the hierarchies . even though more sophisticated approaches exist",
    "( see for example ref .",
    "@xcite ) , for the sake on simplicity the approach taken is the one described above .    to perform a temporal analysis , different correlation matrices , or weighted networks ,",
    "are computed by processing the data over different time windows @xmath162 $ ] , where @xmath163 is the initial day of the time window , and @xmath164 the window duration , measured in days .    in the following analysis ,",
    "only the rl community detection method is used , this is because the other two methods typically return trivial communities .",
    "more specifically , the other two methods fail to find communities because the correlation networks are dense  @xcite . on the other hand",
    ", rl is more sensitive to small link - weights differences , and therefore , it is able to find communities in the dense matrices , but at risk of over - fitting ( see section  [ ss : art_fid ] ) .",
    "as it was already mentioned , more sophisticate methods can be used to mitigate these undesired tendencies  ( see section  [ sss : cdm ] ) . however",
    ", such experiments are left for future works .",
    "two sets of experiments are analyzed ; in both cases , for each computed weighted network , 50 hierarchical community structures , or trees , are computed . in the first set of experiments , we analyze how the integration time , or time windows length @xmath164 , affects the detected hierarchies . for this purpose , we compute the following average normalized hierarchical mutual information , @xmath165 we call this quantity , the _ temporal - scale hierarchical similarity _ , or simply , the _ scale - similarity_. it compares hierarchies obtained from the full - length time window , against hierarchies obtained from time windows of length @xmath164 . in all cases , the initial time is chosen to be the first day , @xmath166 . in fig .",
    "[ fig:12]a , @xmath167 is plotted as a function of @xmath164 .",
    "as it can be seen , the larger is @xmath164 , the larger is @xmath167 . in other words ,",
    "the expected behavior is observed because , the larger is @xmath164 the more similar @xmath168 and @xmath169 become in average . in particular , a _ plateau",
    "_ exists for @xmath170 .",
    "this last observation suggests that changes do not occur smoothly , but different hierarchical structural properties emerge at different time scales .    in the second set of experiments ,",
    "@xmath164 is fixed at @xmath171 days and trees are computed out of networks corresponding to different regions in the time line .",
    "more specifically , we introduce the _ temporal hierarchical auto - similarity _  or _ auto - similarity _  which is defined as @xmath172 the auto - similarity compares two set of hierarchies .",
    "the first set is computed from the data in the time window @xmath162 $ ] , and the other set from the time window defined @xmath173 days after .",
    "we analyze the auto - similarity varying @xmath173 for fixed @xmath174 , and varying @xmath163 for fixed @xmath175 . in the first case ,",
    "we study how the time separation @xmath173 affects the hierarchy , and in the second case we compare hierarchies corresponding to consecutive time windows as time evolves . in fig .",
    "[ fig:12]b , both quantities are plotted . on the one hand",
    ", the auto - similarity @xmath176 decays as the time separation @xmath173 grows ( circles ) , i.e. the hierarchy drift away from the initial structure . on the other hand",
    ", the auto - similarity fluctuates around @xmath177 ( triangles ) , indicating that the hierarchies of consecutive time windows always share a significant amount of information .",
    ", determines how the hierarchies change with the time length @xmath164 of the time window over which the data is processed . in b ) , two different comparisons are presented using the auto - similarity @xmath178 . with circles , @xmath176 determines how similar are the hierarchies at day one , with the hierarchies @xmath173 days after . with triangles",
    ", @xmath179 determines how similar are the hierarchies of consecutive time windows , separated by 100 days , as time @xmath163 evolves . in all cases ,",
    "the bars represent standard - deviations around the mean .",
    ", title=\"fig : \" ] + , determines how the hierarchies change with the time length @xmath164 of the time window over which the data is processed . in b ) , two different comparisons are presented using the auto - similarity @xmath178 . with circles , @xmath176 determines how similar are the hierarchies at day one , with the hierarchies @xmath173 days after . with triangles , @xmath179 determines how similar are the hierarchies of consecutive time windows , separated by 100 days , as time @xmath163 evolves . in all cases ,",
    "the bars represent standard - deviations around the mean .",
    ", title=\"fig : \" ]",
    "in this work , the hierarchical mutual information has been introduced , a tool that generalizes the standard mutual information for the comparison of hierarchies .",
    "more specifically , for the comparison of hierarchical partitions , which take the form of trees where parts are subsequently subdivided further into sub - parts and so on .",
    "the hierarchical mutual information can be used to compare the hierarchical community structure of complex networks , in analogous way as the standard mutual information can be used to compare standard community structures .",
    "we define here a normalized hierarchical mutual information .",
    "the traditional normalized mutual information satisfy certain properties ; it is a quantity lying in @xmath53 $ ] , and is equal to one if and only if the compared partitions are exactly equal .",
    "if the normalized hierarchical mutual information behaves correctly , it should satisfy analogous properties .",
    "the appropriate behavior of the normalized hierarchical mutual information is extensively tested in numerical experiments .",
    "the test include artificially generated hierarchical partitions , and the hierarchical community structure of artificially and empirical complex networks .",
    "in all the experiments , the normalized hierarchical mutual information is found to behave correctly .",
    "however , it should be mentioned that a formal proof of the correct behavior is not provided in the present work .",
    "the experiments also illustrate the overall behavior of the hierarchical mutual information . on the one hand , when comparing artificially generated hierarchies against correspondingly randomized ones , the normalized hierarchical mutual information was found to decrease with the level of randomization . on the other hand ,",
    "a level by level randomization analysis of the hierarchies indicated that , the larger the number of randomized levels , the faster the normalized hierarchical mutual information decays with the randomization .",
    "another interesting finding was that the normalized hierarchical mutual information never decays to zero .",
    "this effect , also present in the standard normalized mutual information , occurs because random ( hierarchical ) partitions in finite systems share information just by chance .",
    "the experiments also constitute examples of how the hierarchical mutual information can be used to analyze the hierarchical community structure of complex networks .",
    "specifically , the hierarchical community structure of artificial and empirical networks were studied . in the analysis ,",
    "different popular community detection methods were utilized , and the results compared .",
    "the results were tested on two network models and five empirical networks .",
    "it was found that the different methods can return significantly different hierarchical community structures .",
    "the normalized hierarchical mutual information correctly identifies these differences .",
    "it was also shown that the normalized hierarchical mutual information can be used to compare the detected hierarchies against the natural , reference ones in the different network models .",
    "in particular , when the parameters of the network models are appropriate , and the network models tend to generate networks with the expected hierarchical structures , the normalized mutual information between the identified hierarchies and the expected ones tends to grow .    in another set of experiments ,",
    "the normalized hierarchical mutual information was used to compare the hierarchical community structure of the different networks  the networks generated by the models , and the empirical networks  against that of correspondingly randomized networks .",
    "as expected , the normalized mutual information was found to decay with the level of randomization . in a final example",
    ", the time evolution of the hierarchical community structure of correlation matrices was analyzed .",
    "specifically , we considered correlation matrices computed from the log returns of stock prices in the s&p500 .",
    "this final example epitomizes how the hierarchical mutual information is useful to study the evolution of temporal networks . in the analysis",
    ", the normalized hierarchical mutual information showed that the hierarchical community structure of the correlations of stocks slowly changes in time , but exhibiting important changes at different times - scales .",
    "the present work opens several possibilities for future research .",
    "the mathematical framework behind the hierarchical mutual information can be used to generalize other information measures , like generalizing the variation of information  @xcite . on a different line of research",
    ", the normalized hierarchical mutual information can be used to systematically benchmark , and compare , the different community detection methods in existence .",
    "another interesting future line of research concerns the comparison of phylogenetic trees  @xcite , where the hierarchical mutual information could have useful applications .",
    "finally , the normalized hierarchical mutual information can be used to compare the identified hierarchies against corresponding _ ground - truth hierarchies _ that different data sets might have available .",
    "the above examples go without mentioning the ample possibilities of using and extending this methodology in the many fields where hierarchical communities structures are identified .",
    "j.i.p and g.c . acknowledge support from : fet ip project multiplex nr .",
    "fet project simpol nr .",
    "610704 , fet project dolfins nr .",
    "cjt acknowledges financial support from the urpp on social networks , universitt zrich , switzerland .",
    "we also acknowledge useful comments by a. clauset , m. rosvall , t. peixoto and f. queyroi .",
    "70ifxundefined [ 1 ] ifx#1 ifnum [ 1 ] # 1firstoftwo secondoftwo ifx [ 1 ] # 1firstoftwo secondoftwo `` `` # 1''''@noop [ 0]secondoftwosanitize@url [ 0 ] ",
    "+ 12$12  & 12#1212_12%12@startlink[1]@endlink[0]@bib@innerbibempty @noop * * ,   ( ) @noop * * ,   ( ) @noop _ _  ( ,  ) @noop * * ,   ( ) @noop _ _",
    "( ,  ) @noop _ _  ( ,  ) @noop * * ,   ( ) @noop * * ,   ( ) @noop * * ,   ( ) @noop * * ,   ( ) @noop * * ,   ( ) @noop * * ,   ( ) @noop * * ,   ( ) @noop * * ,   ( ) @noop * * ,   ( ) @noop * * ,   ( ) @noop * * ,   ( ) @noop * * ,   ( ) @noop * * ,   ( ) @noop * * ,   ( ) @noop * * ,   ( ) @noop * * ,   ( ) @noop * * ,   ( ) @noop * * ,   ( ) http://dx.doi.org/10.1007/s10618-013-0335-9 [ * * , ( ) ] @noop * * ,   ( ) @noop * * ,   ( ) in  @noop _ _  ( ,  )  pp .   @noop * * ,   ( ) @noop * * ,   ( ) @noop * * ,   ( ) @noop _ _  ( ,  ,  ) @noop @noop @noop * * ,   ( ) @noop * * ,   ( ) @noop * * ,   ( ) @noop * * ,   ( ) @noop * * ,   ( ) @noop * * ,   ( ) @noop @noop * * ,   ( ) @noop * * ,   ( ) @noop ( ) http://www.wcoomd.org [ ] @noop * * ,   ( ) @noop * * ,   ( ) @noop * * ,   ( ) @noop * * ,   ( ) @noop * * ,   ( ) @noop * * , ( ) @noop * * ,   ( ) @noop _ _  ( ) @noop @noop in  @noop _ _  ( ) @noop @noop * * ,   ( ) http://finance.yahoo.com [ ] @noop * * ,   ( ) @noop * * ,   ( ) @noop * * ,   ( ) @noop * * ( ) @noop ( ) @noop * * ,   ( ) @noop * * ,   ( ) @noop * * ,   ( ) @noop * * ,   ( )"
  ],
  "abstract_text": [
    "<S> the quest for a quantitative characterization of community and modular structure of complex networks produced a variety of methods and algorithms to classify different networks . </S>",
    "<S> however , it is not clear if such methods provide consistent , robust and meaningful results when considering hierarchies as a whole . </S>",
    "<S> part of the problem is the lack of a similarity measure for the comparison of hierarchical community structures . in this work </S>",
    "<S> we give a contribution by introducing the _ hierarchical mutual information _ </S>",
    "<S> , which is a generalization of the traditional mutual information , and allows to compare hierarchical partitions and hierarchical community structures . </S>",
    "<S> the _ </S>",
    "<S> normalized _ version of the hierarchical mutual information should behave analogously to the traditional normalized mutual information . here </S>",
    "<S> , the correct behavior of the hierarchical mutual information is corroborated on an extensive battery of numerical experiments . </S>",
    "<S> the experiments are performed on artificial hierarchies , and on the hierarchical community structure of artificial and empirical networks . </S>",
    "<S> furthermore , the experiments illustrate some of the practical applications of the hierarchical mutual information . </S>",
    "<S> namely , the comparison of different community detection methods , and the study of the consistency , robustness and temporal evolution of the hierarchical modular structure of networks . </S>"
  ]
}