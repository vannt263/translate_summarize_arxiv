{
  "article_text": [
    "the nature and distribution of dark matter is one of the great mysteries of modern cosmology .",
    "although most of the matter in the universe may be dark , we can only directly observe baryons . by measuring statistical properties of visible universe ( galaxies and clusters )",
    "we can not infer statistical properties of the underlying dark matter without further assumptions .",
    "typically one has to assume that light in some way traces mass , but this has often been questioned and models have been proposed where galaxy formation is a non - local ( heyl et al .",
    "1995 ) or stochastic process ( dekel & lahav 1997 ) . until recently the only two direct tracers of matter distribution on large scales with existing data were velocity flows and cosmic microwave background ( cmb ) anisotropies .",
    "the former , while promising , still suffers from a small number of galaxies with accurate distances and a number of inherent biases present in any of the analysis methods ( @xcite ) . in recent years",
    "cmb has emerged as the most promising way to measure the dark matter distribution , with the potential of measuring several cosmological parameters with a few percent accuracy over the next decade ( @xcite ) .",
    "the main advantage of cmb over other methods is that it traces the universe in linear regime , which makes the interpretation of the data relatively straightforward .",
    "another advantage is that it is relatively free of systematic effects and foreground emission seems to be subdominant over a large range of angular scales .",
    "however , cmb by itself can not determine all of the cosmological information ( @xcite ) .",
    "in particular , it does not directly probe the matter power spectrum , which although related to the cmb power spectrum , is sensitive to somewhat different physical processes and can provide valuable information by itself .",
    "for example , massive neutrinos have only a minor effect on the cmb spectrum and it will be rather difficult to distinguish between different values of neutrino mass from the cmb data alone .",
    "their effect on the matter power spectrum is significantly more important and by measuring it one could determine the value of the neutrino mass or set an upper limit .",
    "for this reason it is important to investigate other direct tracers of matter , which may allow one a more direct determination of matter power spectrum .",
    "it has long been recognized that gravitational lensing offers the possibility of tracing the dark matter distribution directly . as light propagates through the universe it is deflected by the inhomogeneities along the line of sight and",
    "this causes a distortion in the images of background galaxies .",
    "the distortions are small and for each individual galaxy one can not separate them from an intrinsic ellipticity of the galaxy . only by averaging over several galaxies and assuming that the ellipticities of galaxies are uncorrelated",
    "can one detect this so called weak lensing effect .",
    "the effect has already been detected in clusters , where the higher projected mass density and typical radial pattern simplify the detection ( see @xcite for a review ) .",
    "the challenge for the future is to detect the weak lensing away from clusters in the field , where the distortions are significantly smaller , but the rewards potentially higher ( for some preliminary results see @xcite ) .",
    "although the typical distortion in the field is smaller the survey area can be larger ( specially with the advent of composite ccd cameras ) , which allows for a possibility of a statistical detection of structures on large scales through the two - point correlations , power spectrum or correlation function . often this will be the most useful information anyways , since on large scales , where the matter distribution is likely to be described as a gaussian random field , power spectrum contains all the information needed for a statistical description of matter distribution .",
    "power spectrum is the starting point for the extraction of various cosmological parameters .",
    "cosmological model predictions for two - point statistics , both correlation functions in real space and power spectrum in fourier space , have been investigated by a number of groups .",
    "the first calculations were those by @xcite and @xcite based on the work by @xcite .",
    "recently they have been extended to a general robertson - walker universe by @xcite , kaiser ( 1997 ) , stebbins ( 1996 ) , seljak ( 1996 ) and jain & seljak ( 1997 ) .",
    "the latter have also extended the calculations to a nonlinear regime using @xcite mapping of the power spectrum .",
    "most of these works have been theoretical and have only partially addressed the issue of extraction of the signal from the data .",
    "kaiser ( 1997 ) suggests a simple power spectrum estimator and shows that it gives an unbiased estimate of a convolved power spectrum .",
    "he also gives an estimate of the errors under the assumption that the data have gaussian distribution .",
    "another way to obtain such a quantity is to transform the data to fourier space first and then form a scalar quantity , as suggested by kaiser ( 1992 , 1997 ) .",
    "this method uses all the available information , but as we will show in this paper does not optimally weight the data which leads to a loss of information .",
    "@xcite propose a new statistic called mass - aperture @xmath0 ( previously introduced by @xcite for estimating the mass of clusters ) as a tool for estimating the power spectrum and higher order statistics .",
    "the statistic radially averages the tangential component of the shear .",
    "it was originally developed for clusters where for circular symmetry the shear pattern is indeed tangential . in the field",
    "this is no longer the case and the motivation for using this statistic becomes less obvious .",
    "one reason for introducing this statistic is to obtain a localized scalar quantity from which third and higher moments can be extracted .",
    "both of these papers do not address the question of how efficiently the methods use the data and how much information is lost in the process of reducing the data to this form .",
    "we will show in this paper that there are methods which can formally be shown to be optimal for the power spectrum reconstruction .",
    "this is particularly important on large scales , where sampling variance ( finite number of modes of a given wavelength in the survey box ) is the dominant source of error on the power spectrum .",
    "another topic that was not addressed in the context of weak lensing so far is the determination of 3-d power spectrum from 2-d data sets .",
    "one method proposed by @xcite and applied to apm galaxy survey is to compute 2-d power spectrum and invert it to obtain 3-d power spectrum .",
    "the inversion procedure is nonlinear and requires an iterative scheme .",
    "the main problem with this analysis is the treatment of errors . on large scales",
    "the 2-d estimators have a large sampling variance and unless this is properly taken into account they contribute too much weight to the 3-d estimators and the inversion is unstable .",
    "we will show in this paper that there is a well defined answer how to perform this procedure that formally minimizes the error and provides a correct error estimate for the 3-d power spectrum . with weak lensing data",
    "one can extract not only the power spectrum , but also its time evolution , if one uses photometric information to assign a distance to the background galaxies and we address how to extract this information as well .",
    "power spectrum is not the only information of interest when analyzing such data sets . on somewhat smaller scales",
    "higher order moments develop , which add additional information on the statistical properties of the process and can independently constrain some of the cosmological parameters . for example , ratio of the third moment to the square of second moment ( i.e. skewness ) of convergence depends in the second order perturbation theory only on the matter density @xmath1 and the shape of the power spectrum , but not on its amplitude .",
    "this may allow one to measure directly the cosmic density @xmath1 ( bernardeau et al .",
    "1997 , @xcite ) . because the measured shear is a tensorial quantity it has a vanishing skewness and can not be used for this test . @xcite",
    "propose to use @xmath0 as a statistic on which to apply this test , but as mentioned above this statistic does not make an optimal use of the data .",
    "we will show here that one can define a scalar quantity where all the information from the data is used and provided all the statistical properties are properly included this does not lead to a loss in information .",
    "one would also like to map large scale structures such as filaments , sheets and superclusters , which are of interest by themselves , both for cosmographical purposes and for learning about the cosmological model from their properties .",
    "again the question arises what is the optimal way to do this .",
    "we will show that for large scale structure this question has a well - defined answer , which moreover has a solution closely related to the optimal power spectrum reconstruction , so that both can be extracted within the same formalism .    in this paper",
    "we develop the so - called minimum variance linear methods for projected mass reconstruction , 2-d and 3-d power spectrum estimation from the weak lensing data .",
    "we apply the methods to simulated data sets which demonstrate that the estimators are unbiased and reach the theoretical minimum variance limit .",
    "as such the estimators are superior to the estimators mentioned above and should be used at least on large scales , where the nearly gaussian distribution guarantees their optimal performance .",
    "although the methods developed here work best for reconstruction of lss , they can be applied to the cluster reconstruction as well , where they still minimize the variance in the class of linear reconstruction methods . in this case",
    "they are no longer optimal for every application and instead can be viewed only as one of many possible linear filtering methods .",
    "other linear or nonlinear methods may be better depending on the application one has in mind .",
    "let us assume the observations consist of @xmath2 galaxies at angular positions @xmath3 with measured ratios of short to long axis @xmath4 and position angle of major axis @xmath5 .",
    "we can introduce ellipticity @xmath6 from which we can form a two - component entity of observable quantities @xmath7 .",
    "we arrange all the data into a @xmath8 component vector @xmath9 . because of gravitational lensing the `` true '' surface brightness ( i.e. the surface brightness one would see in the absence of any lensing )",
    "is mapped into the observed one , @xmath10 , where @xmath11 is the angular deflection of a photon caused by intervening mass distribution .",
    "this induces ellipticity correlations between the galaxies , information on which is contained in the symmetric deformation tensor , @xmath12 here @xmath5 is the gravitational potential and @xmath13 is the radial comoving distance with @xmath14 being the horizon distance . the radial distribution of background galaxies is described with the normalized distribution @xmath15 .",
    "the comoving angular distance @xmath16 introduced above can be expressed in terms of @xmath13 as @xmath17 curvature @xmath18 can be expressed as @xmath19 , where @xmath20 is the hubble constant and @xmath21 , @xmath22 the vacuum and matter densities , respectively .",
    "deformation tensor can be decomposed into its trace component convergence @xmath23 and two traceless components of the shear @xmath24 , @xmath25 , @xmath26 and @xmath27 .",
    "the observable ellipticities are related to these via the expression @xmath28 ( @xcite ; we are assuming that there are no critical lines where @xmath29 and between which this relation changes , see section 4 ) and so only a combination of @xmath23 and @xmath30 can be determined .",
    "however , since the distortions induced by lss are small , i.e. @xmath31 , one can in the first approximation ignore @xmath32 in the above expression and then shear becomes directly expressed in terms of the observed ellipticity .",
    "nonlinear corrections are addressed in more detail in section 4 .",
    "although there are 3 components of the deformation tensor they are in fact not independent , because they can all be expressed as a derivative of a single deflection potential ( equation [ shear ] ) .",
    "the quantity that we are mostly interested in is the convergence or surface mass density @xmath23 , which is related to the projected mass distribution over the window given in equation ( [ shear ] ) .",
    "we would like to reconstruct it and compute its power spectrum from the observables @xmath33 .",
    "the relation between the shear and convergence is most easily expressed in fourier space ( throughout the paper we will assume that the scales are sufficiently small for curvature of the sky to be unimportant and so fourier analysis to be adequate ; see @xcite for a generalization of this to all - sky measurements ) , so we first decompose shear and convergence into a fourier series , @xmath34 where @xmath35 is the power per mode and the sum is taken in the limit where the spacing between the modes @xmath36 .",
    "the two shear components can be similarly expanded and the relation between them and convergence in fourier space is ( kaiser 1992 ) @xmath37 where @xmath38 is the direction angle of @xmath39 mode .",
    "the data can be modelled in the form @xmath40 where @xmath41 is the underlying field in fourier space , @xmath42 is the noise vector , @xmath43 is a @xmath44 response matrix of the form @xmath45 for the two components of @xmath33 at position @xmath46 and @xmath47 is the number of modes we use in the model . instead of working with the complex response matrix @xmath43 and the complex field @xmath48 ( which satisfies the condition @xmath49 ) we can also work with real valued response matrix by replacing @xmath50 with @xmath51 and @xmath52 and replacing the complex @xmath35 with two real components .",
    "underlying field always has an infinite number of coefficients , but for computational reasons only a finite number of these can be included .",
    "the required number depends on the size of the survey and signal to noise ratio .",
    "the spacing between the modes @xmath53 is determined by the size of the survey @xmath54 , @xmath55 , since one can not resolve the modes more finely spaced than this .",
    "one way to see this is to embed the survey area into a box of size @xmath56 and impose periodic boundary conditions on the modes to make them orthogonal .",
    "these modes are spaced by @xmath53 and form a complete and orthonormal system in the box , so that any distribution can be expanded into this series .",
    "such an expansion will impose periodic boundary conditions on the data . to avoid spurios effects from periodic boundary condition",
    "it is necessary to have the box somewhat larger than the survey and typically 20% zero padding on each side works well ( see section 4 ) .",
    "even better is to expand in a box of twice the linear size , which will completely eliminate the boundary condition problems but with an increase in the number of modes .",
    "the upper cutoff in the expansion is determined by the signal to noise ratio : because of the noise the data do not contain information about the structure on very small scales and do not need to be modelled .",
    "one can always include more modes than necessary or embed the survey into a larger box , so in this sense their actual number is not very important , except for computational reasons .",
    "in addition to the contribution from lss each measurement also has a noise contribution @xmath57 , which is a combination of intrinsic ellipticity of the galaxy ( dominant for bright and/or large sources ) and the measurement error ( significant for faint and/or small sources ) .",
    "we will assume that the noise covariance matrix is diagonal and given by @xmath58 , where @xmath59 is the transpose ( and conjugate for complex fields ) of the vector .",
    "measurement error can differ from one galaxy to another and intrinsic rms ellipticities can vary with galaxy types and/or redshift , so in principle the variances @xmath60 for different galaxies do not have to be equal and one can include this information if necessary . for a given galaxy",
    "the errors on @xmath61 , @xmath62 are assumed equal and uncorrelated .",
    "the fluctuations in the underlying field @xmath48 are parametrized with a diagonal covariance matrix @xmath63 , @xmath64 , where @xmath65 is the convergence power spectrum at @xmath66 , amplitude of @xmath39 mode .",
    "it can be expressed as an integral over the matter density power spectrum ( kaiser 1992 , @xcite ) @xmath67d\\chi , \\label{ps}\\ ] ] where @xmath68 is the density power spectrum at conformal time @xmath69 and @xmath70 the expansion factor , related to the radial distance @xmath13 via the relation @xmath71^{1/2}$ ] .",
    "we will also need the correlation matrix for the data @xmath72 .",
    "it can be computed from the power spectrum as @xmath73 where @xmath74 here @xmath5 is the direction angle of @xmath75 and @xmath76 are the bessel functions of order @xmath77 .",
    "reconstruction techniques for lss and cmb have been extensively studied ( @xcite ) .",
    "a particularly simple nonparametric technique is optimal or wiener filtering ( wf ) , which minimizes the variance in the class of linear estimators ( @xcite ) .",
    "when the data are gaussian distributed it coincides with the maximum posterior probability estimator and so is optimal in this limit . as such",
    "it should be the ideal method when applied to the lss reconstruction from weak lensing data , where the deviations from gaussianity are either small or negligible .",
    "another advantage of wf is that it provides an analytic expression for the error covariance matrix , which can quantify which structures are statistically significant .",
    "one problem of wf is that it requires as input the power spectrum of the underlying field and this is often not known in advance . in the absence of any external information it has to be obtained from the data itself .",
    "we will show that one can obtain a power spectrum estimator directly from the wf reconstruction , thus providing a self - consistent treatment of wf without the need of having two separate analysis for the two problems ( @xcite ) .",
    "this power spectrum is in fact the optimal one in the sense of being minimum variance among all the estimators . here",
    "we will review this formalism , modifying it where necessary to the case of weak lensing .",
    "let us begin with the reconstruction of surface density in fourier space @xmath48 .",
    "we can subsequently make a real space map by transformation @xmath78 , where @xmath79 , with @xmath46 the angular position where we want the value of the reconstructed field .",
    "we will require that the estimated field @xmath80 is a linear function of the data , @xmath81 , where @xmath82 is a @xmath44 matrix .",
    "then one can minimize the variance of the residual @xmath83 with respect to @xmath82 .",
    "this gives the wf estimator of the underlying field , @xmath84 the variance of residuals is given by @xmath85 for gaussian random fields wiener filtering coincides with maximum probability estimator ( @xcite ) , which maximizes the likelihood function ( or posterior probability in bayesian language ) and so it is optimal .",
    "this is because wf only uses information on the mean and variance of statistical distribution , which completely characterize gaussian random fields .",
    "since wf basically multiplies the data with signal/(signal+noise ) one can see that the modes with low signal to noise are being filtered out and replaced with zero .",
    "only the modes with significant signal to noise will be kept in the reconstruction , thus providing the most conservative estimate of the field . for gaussian random fields",
    "this is in fact the optimal reconstruction . by using only information on the mean and variance",
    "it may be less than optimal when applied to a strongly nongaussian field , although even in such situations wf still minimizes the variance as defined in equation ( [ res ] ) in the class of linear estimators . for cluster reconstruction from weak lensing there",
    "have been proposed several methods that are linear in the data ( see e.g. @xcite and references therein ) , but since wf explicitly minimizes the variance in equation ( [ res ] ) it is in this sense optimal in this class of reconstruction methods .",
    "we will discuss this in more detail in section 4 , where we show that in such applications minimizing the variance may not be the only way to define the best image reconstruction and other reconstruction methods may be better depending on the application . note that wf requires as input the knowledge of power spectrum @xmath65 to compute @xmath63 and @xmath86 . to make the method self - consistent we therefore need a power spectrum estimator as well .",
    "we turn to this next .",
    "optimal power spectrum reconstruction from a set of noisy and incomplete observations has been investigate extensively in the field of large scale structure ( lss ) and cosmic microwave background ( cmb ) anisotropies ( @xcite ) , inspired by the existing and forthcoming large data sets ( cobe , map , planck , sdss , 2df etc . ) .",
    "the amount of information loss when analyzing the data can be quantified with the use of information theory , which allows one to define the requirements for an optimal estimator ( @xcite ) .",
    "one can define the fisher information matrix as the ensemble average of the matrix of second derivatives of the ( minus ) log - likelihood function with respect to the parameters we wish to estimate .",
    "its inverse provides a minimum bound for covariance matrix of the parameters , known as the cram ' er - rao inequality ( e.g. kendall and stuart 1969 ) .",
    "power spectrum estimator that is quadratic in the data has been proposed that reaches this theoretical limit directly ( @xcite ) and it has been shown that it gives equivalent results to the maximum likelihood analysis ( @xcite ) . under the gaussian assumption for the data",
    "the method also provides the error matrix for the estimators , which includes contributions from the sampling variance , noise and aliasing .",
    "the main shortcoming of this estimator is that it is still computationally expensive for large data sets , but this can be significantly reduced by transforming the data to a signal eigenmode basis ( @xcite ) or by using various approximations .",
    "the power spectrum @xmath65 is a continuous function of @xmath66 , but we only sample it in a finite number of modes , so we can only estimate it at discrete values of @xmath66 .",
    "moreover , we can group together the estimates from modes that are nearby in @xmath66 to reduce the scatter in the estimator .",
    "the spacing in @xmath66 can be @xmath53 or larger , depending on the amount of information in the data and on the smoothness of the power spectrum .",
    "in the following we will number these with @xmath66 and denote the corresponding power per mode estimator with @xmath87 , which can be put into a vector @xmath88 .",
    "we can introduce a projection matrix @xmath89 , which consists of ones along the diagonal corresponding to the modes contributing to @xmath66-th parameter and zeros everywhere else . if we approximate the integrals in the correlation function ( equation [ corr ] ) with the sum over the discrete modes used in the expansion we can write @xmath90 where we introduced @xmath91 .    to derive the minimum variance power spectrum estimator we write the likelihood function for the data @xmath92 and following @xcite we expand it to second order in parameters @xmath93 , @xmath94 the derivatives",
    "are given by @xmath95 ensemble average of the second expression is the fisher matrix @xmath96 at the maximum likelihood value the first derivative of the likelihood function vanishes , so we use newton - raphson method to find the zero of the derivative .",
    "this leads to a quadratic estimator , which is to be solved iteratively , @xmath97.\\ ] ] once the power spectrum has been determined one can express the estimator directly in terms of wf coefficients using equation ( [ q ] ) , taking the initial estimate to be zero ( and the corresponding correlation matrix pure noise ) .",
    "this leads to the minimum variance quadratic estimator ( @xcite ) @xmath98= { 1 \\over 2}\\sum_{l'}f^{-1}_{ll ' } [ \\bi{y}^{\\dag } \\bi{\\pi}_{l ' } \\bi{y}-b_{l ' } ] \\nonumber \\\\ \\bi{y } & \\equiv & \\tilde{\\bi{s}}^{-1}\\hat{\\tilde{\\bi{\\kappa}}}= \\bi{r}^{\\dag } \\bi{c}^{-1 } \\bi{\\kappa } \\nonumber \\\\ b_l&=&tr[\\bi{c}^{-1}\\bi{q}_l\\bi{c}^{-1 } ( \\bi{n+s_b})]= tr[\\bi{c}^{-1}\\bi{r}\\bi{\\pi}_l\\bi{r}^{\\dag } \\bi{c}^{-1}\\bi{(n+s_b } ) ] \\nonumber \\\\ f_{ll'}&= & { 1 \\over 2 }   \\sum_{\\bi{l } } \\sum_{\\bi{l } ' }     ^2 . \\label{wffll}\\end{aligned}\\ ] ] we included the additional noise term @xmath99 in equation ( [ wffll ] ) , which is the correlation matrix for the modes that are not being estimated and which alias power into the modes we do estimate ( @xcite ) .",
    "the estimator above not only improves upon the naive power spectrum estimation obtained by a simple average of wiener filtered modes ( which is always biased towards low values ) , but is also the best possible estimator , since it gives equivalent results to the maximum likelihood analysis and the covariance matrix of the estimates is given by the fisher matrix , which by cram ' er - rao inequality is the best one can do . to compute the estimator one has first to multiply the data with the inverse of correlation matrix .",
    "this first step is identical to wf and is just a generalization of the inverse noise weighting of the data .",
    "if a given measurement has a large noise or is strongly correlated with other measurements then it does not add new information and should be downweighted .",
    "once this has been done subsequent operations do not require any additional weighting : to compute the power spectrum estimator one fourier transforms the data and adds the squares of all the modes contributing to the @xmath66-th parameter in the spectrum .",
    "there is no need to put additional weighting on the modes since correct weighting has already been obtained by the first operation . for the estimator to be unbiased we need to subtract the noise and aliasing bias @xmath100 and compute the window function @xmath101 .",
    "the last step is to deconvolve the estimators with @xmath102 , which may not be recommended if the matrix is nearly singular , since the inversion may not be stable .",
    "instead one can quote convolved estimators @xmath103 , where @xmath104 .",
    "the filtering function @xmath105 is a bell shaped function in @xmath106 for a given @xmath66 and its width gives the spectral resolution at that amplitude . under the gaussian approximation for the data the covariance matrix for this estimator",
    "is given by @xmath107 .",
    "note that only the first step , multiplying the data with @xmath108 differs from the uniform weighting power spectrum estimator proposed by kaiser ( 1997 ) .",
    "this suggests that one can use an approximate form for @xmath108 , which is easier to invert , and still obtain an unbiased estimator .",
    "the closer this matrix is to @xmath108 the closer will the estimate be to the minimum variance one .",
    "the most expensive operation in computing wf is inverting @xmath86 and once this inversion is obtained one can compute @xmath109 and @xmath101 by taking matrix products , so computing the power spectrum from wf estimators is not significantly more expensive than computing wf itself .",
    "this inversion is o(@xmath110 ) operations , if one uses cholesky decomposition and becomes computationally too expensive when the data set becomes too large ( @xmath111 ) .",
    "since the shear measurements are not independent ( in the sense that both components can be derived from a single scalar field ) one can reduce the size of the matrix to be inverted by first transforming the data multiplied with the inverse of the noise matrix into the fourier space , @xmath112 .",
    "the modes @xmath48 we wish to estimate are related to these through the relation @xmath113 and their covariance matrix is given by @xmath114 if we use these modes in the likelihood function ( equation [ lik ] ) and in the corresponding quadratic estimator ( equation [ wffll ] ) we reduce the matrix by a factor of two ( and the computational cost by a factor of eight ) , even if we use the same number of modes as the number of galaxies . moreover , since weak lensing measurements have a low signal to noise ratio we need to model far fewer modes than we have galaxies , both of which suggest to use the fourier space to perform the expensive matrix inversion and multiplication . to avoid having to invert both @xmath115 and @xmath116 we can use the relation @xmath117 in which case if aliasing can be ignored only the matrix @xmath118 needs to be inverted ( otherwise we still have to invert @xmath115 as well ) .",
    "using this transformation the analogous expressions to equations ( [ wffll ] ) are ( @xcite ) , @xmath119 \\nonumber \\\\",
    "f_{ll'}&=&{1 \\over 2 } tr[\\tilde{\\bi{c}}^{-1}\\tilde{\\bi{q}}_l \\tilde{\\bi{c}}^{-1}\\tilde{\\bi{q}}_{l ' } ]   \\label{signal}\\end{aligned}\\ ] ] the role of the correlation matrix @xmath86 in real space has now been replaced by @xmath118 ( or @xmath116 ) , which has dimensions @xmath120 .",
    "if @xmath47 is significantly smaller than @xmath2 then a substantial saving in computational time can be achieved by having to invert and multiply smaller matrices .",
    "for very large @xmath47 even performing these matrix manipulations becomes computationally too expensive , so it is worth exploring approximations to the above expressions , which would allow one to compute them more rapidly .",
    "if the survey is compact and the sampling relatively uniform then on small scales there will be little mixing between the modes and the geometry of the survey will not be important , so to estimate the power at a given amplitude one can approximate the spectrum around it as flat ( white noise ) .",
    "for such a power spectrum the correlation matrix @xmath86 in equation ( [ corr ] ) is diagonal , @xmath121 , where @xmath122 is the noise variance for each galaxy and @xmath123 is the theoretical variance , @xmath124 being the mean density of galaxies at location @xmath46 .",
    "this matrix can be inverted trivially in real space and @xmath125 is a simple inverse weighting of the data , where the weight consists now of both noise and signal variance .",
    "wf estimator is give by equation ( [ wf ] ) with the variance of residuals @xmath126.\\ ] ] the bias and fisher matrix are given by latexmath:[\\ ] ]    the above expressions use all the distance information in an optimal way .",
    "it is easier to compute @xmath167 first and then multiply it with @xmath168 , since this way the inversion only needs to be done once .",
    "alternatively one can divide the galaxies into a couple of bins in distance and treat all the galaxies within the bin as having the same distance probability distribution .",
    "one possibility would be to divide the galaxies in the magnitude bins and assign to each bin a probability distribution @xmath169 and corresponding @xmath170 , where index @xmath171 now counts the bins and not individual galaxies .",
    "for each bin we can compute the 2-d modes @xmath172 using equations ( [ wffll ] ) or ( [ signal ] ) .",
    "the raw 3-d power spectrum estimate is @xmath173 and similar expressions can be written for @xmath174 and @xmath175 as well .",
    "as mentioned above with distance information one may also address the question of power spectrum evolution .",
    "we can parametrize the power spectrum growth factor as @xmath176^{\\alpha}$ ] , where @xmath177 is half the distance to the sources , from where the dominant contribution to the weak lensing signal is coming ( @xcite ) .",
    "this form minimizes the degeneracy between the amplitude of the power spectrum and the growth factor .",
    "we can ask how to extract @xmath178 from the data . expanding the likelihood function around the maximum",
    "gives the estimator of equations ( [ fisher])-([wffll ] ) , replacing @xmath179 with @xmath180 , the derivative of the correlation function with respect to @xmath178 , @xmath181 , where @xmath182 is the correlation function computed by using @xmath183 $ ] instead of @xmath142 .",
    "for a narrow dynamic range in distance and scale the growth factor will be degenerate with the shape of the power spectrum , which will be reflected by the covariance terms @xmath184 and one has to invert the matrix to obtain an estimate of the error on the growth factor that does not depend on the power spectrum .",
    "in this section we apply the formalism presented in previous section to estimate the power spectrum from simulated weak lensing data . to generate a simulated section of a field",
    "we first make a random realization of the convergence @xmath48 in fourier space and compute the two shear components based on equation ( [ shearkappa ] ) .",
    "we then fourier transform the shear to real space and select a smaller area as our observed field ( we pay special attention not to select the area to be an integer fraction of the total simulated area to avoid any effects from periodic boundary conditions ) .",
    "we randomly generate the positions of galaxies with a specified surface density and randomly generate noise for each component of the shear from a gaussian distribution with a specified rms error .",
    "we add this value to the value of the shear at the galaxy position and use this map as our simulated data .",
    "we use @xmath185 and @xmath186 as our fiducial cosmological model and place all the galaxies at @xmath187 .",
    "these numbers should be typical for a several hour exposure at a 4 m class telescope with a limiting magnitude around @xmath188 .",
    "we then compute the power spectrum estimator using the expressions in previous section using the expressions in fourier space , because they require less computational time than the corresponding expressions in real space .",
    "figure [ fig4_1]a ( left ) shows the power spectrum measured on a 1 square degree field , using @xmath189 galaxies with rms ellipticity error of @xmath190 .",
    "the estimators are given as points with attached error bars computed from the fisher matrix , connected with a solid line .",
    "we compared the errors computed analytically with the errors obtained from monte carlo realizations and found excellent agreement .",
    "the errors on small scales are dominated by noise , while on large scales the dominant contribution comes from sampling ( cosmic ) variance .",
    "these errors are based on gaussian approximation , which underestimates them in the nonlinear regime . to estimate the scale where this may be important we plot on the figure both the input nonlinear power spectrum ( thick solid line ) and the linear power spectrum ( thin solid line ) .",
    "we see that on the largest scales the two agree and the sampling variance is correctly estimated , while on smaller scales the nonlinear power spectrum significantly deviates from the linear one and the sampling variance would be underestimated",
    ". however , where this becomes important noise will often be the dominant source of error .",
    "noise can be well approximated with the gaussian probability distribution because of the large number of galaxies , even if the intrinsic distribution of ellipticities is not gaussian .",
    "for the example we have chosen uniform dense sampling of galaxies prevents any significant amount of aliasing of small scale power and we find almost identical results ignoring aliasing terms in equations ( [ wffll ] ) .",
    "this is no longer the case when the sampling is sparse , as shown below .",
    "we can also test whether the signal is gravitational by rotating the galaxies by @xmath191 .",
    "the dashed curve in figure [ fig4_1 ] is the result of power spectrum estimation on the data rotated by @xmath191 . for perfect data this rotation would eliminate the gravity mode and only excite the vorticity mode ( @xcite ) .",
    "since there were no vorticity modes put in the simulation ( and indeed almost none are expected to be present in the real data ) one can hope to detect any systematic problems through this test . the dashed curve in figure [ fig4_1 ] is the result of power spectrum estimation on this rotated data .",
    "the resulting power spectrum is significantly lower than the one using original data , which confirms the usefulness of this test .",
    "note however that the power spectrum is not consistent with zero and there is an excess of power present in this mode .",
    "the reason is aliasing of power from the gravity mode to the vorticity mode .",
    "if this aliasing is not included in the analysis ( as it was not in this example ) it will artificially create power in this mode .",
    "we tried to analyze the data without putting the power into the gravity mode and found the recovered power spectrum consistent with zero .",
    "if however there is true power present in the data it will act as an additional noise for the vorticity mode and has to be taken into account .",
    "this example shows that one has to be careful to use the rotation test as a way to monitor the contamination of the data by some source that adds equal power to the two modes .",
    "one has to account for the aliasing first by computing the power spectrum of the gravity mode and use it to compute the total noise contribution in analogy with the bias term in equation ( [ wffll ] ) @xmath192 . \\label{vorb}\\ ] ] here @xmath86 is the correlation matrix ( equation [ corr ] ) and @xmath193 the response matrix for vorticity modes , which can be obtained from @xmath43 by replacing @xmath194 with @xmath195 .",
    "similarly , fisher matrix also has to be modified to account for this additional noise term .    on large scales",
    "the errors are completely dominated by sampling variance and as suggested by kaiser ( 1997 ) sparse sampling would be very useful to reduce the errors . as an example we computed the power spectrum by randomly placing 100 observations over an area of 100 square degrees ( figure [ fig4_1]b ) . in this example",
    "each observation consists of a single exposure detecting 10000 galaxies , which can be grouped together into a single measurement with rms noise @xmath196 .",
    "an example would be a number of short ( a few minute ) exposures on a @xmath197 field , with a sampling factor of 4 , or a longer exposure with more galaxies per exposure and correspondingly lower sampling rate , both of which would only require a couple of nights with the composite ccd cameras .",
    "this choice of sampling is not necessary the optimal one for measuring the power spectrum , which in detail depends on the properties of noise , signal and aliasing power ( @xcite ) .",
    "probably even sparser sampling would give an even higher reward .",
    "even so it is clear that this strategy offers a significant promise to measure the power spectrum on very large scales where the potential rewards are largest .",
    "when the data are sparsely sampled it is important to properly remove the small scale aliasing : the power spectrum estimator without the subtraction of the aliasing term would be strongly biased towards the large values and since this term is only known to the extent that it has been measured well on small scales it can easily dominate the errors attached to the estimator .",
    "similarly , the fisher matrix had to be inverted to compare the estimators to the input ( rather than convolved ) power spectrum , otherwise the estimators would have been biased ( this effect can be minimized by estimating not the power spectrum directly , but only its departure from some fiducial power spectrum , as discussed in section 2.4 ) .",
    "this is again a consequence of strong mixing between the modes in different power spectrum bins .",
    "note that for such sparse sampling @xmath191 rotation test gives a lot of power in the vorticity mode , specially on small scales .",
    "for even sparser sampling the vorticity mode easily exceeds the input power spectrum because of the small scale aliasing .",
    "this has to be taken into account for this test to be a useful diagnostic of any nongravitational contribution .",
    "one can do this by using equation ( [ vorb ] ) when estimating the noise .",
    "[ fig4_1 ]    we also tried the 3-d power spectrum estimation using the approach outlined in section 2.3 .",
    "the results for the 1 square degree filled and 100 square degree sparse survey corresponding to examples in figure [ fig4_1 ] are shown in figure [ fig4_2 ] .",
    "we show the results for the convolved power spectrum and individual estimates are strongly correlated .",
    "this , logarithmic binning and the use of logarithmic scale make the results visually more impressive than in figure [ fig4_1]b , although the information content is the same .",
    "nevertheless , the results are quite impressive and an even larger ( and sparser ) survey would give an even bigger reward of determining the turnover in the power spectrum quite precisely .",
    "we verified the analytic error estimates from the fisher matrix by comparing them to monte carlo estimates and they agree quite well . on small scales where the nonlinear effects become important the sampling error",
    "is underestimated because we used the gaussian approximation and one has to correct for that if necessary .",
    "in this section we apply the formalism developed in section 2 to reconstruct the projected dark matter distribution from weak lensing observations . we start with the reconstruction of large scale structure , where the techniques developed here work best .",
    "we then apply the same methods to the cluster reconstruction , pointing out its advantages and disadvantages and comparing them to other reconstructions . for this case",
    "we also generalize them to include nonlinear effects and discuss how to treat the redshift distribution of the sources .",
    "we will assume throughout this section that the power spectrum of the data is known in advance , using the techniques developed in section 3 .",
    "the power spectrum is only known where the signal exceeds the noise , beyond that one has to assume its form by parametrizing it with a power law .",
    "we will use in the applications the actual power spectrum obtained from the simulated data directly .",
    "this of course can not be obtained with the real data , but it turns out that in practice the reconstruction is not very sensitive to this , because the spectral index of the data power spectrum differs significantly from the noise spectral index 0 and so the only important parameter is the scale where the signal power spectrum exceeds the noise . because we are expanding the data with modes that have periodic boundary conditions in a box it is better to use a somewhat larger box than the size of the observed field and zero pad the rest . for the examples here we used 10% padding on each side and in most cases this eliminated the spurious effects associated with periodic boundary conditions .",
    "if this is not sufficient one can always increase the size of zero padded area .",
    "we begin with the reconstruction of large scale structure . for this purpose",
    "we generated a projected density map from an n - body simulation .",
    "the simulated data in figure [ fig3_4 ] were obtained by randomly placing @xmath189 galaxies on a 1 square degree field .",
    "upper left panel of figure [ fig3_4 ] shows the input data , which have a lot of small scale structure . smoothing the input data at the scale where signal power spectrum equals the noise power spectrum produces upper right panel of figure [ fig3_4 ] .",
    "wf reconstruction is given in lower left panel of figure [ fig3_4 ] .",
    "we see that wf strikes the balance between the resolution and signal to noise ratio .",
    "the reconstruction is heavily smoothed because of the low signal to noise on small scales . on the other hand ,",
    "most of the reconstructed structures are real ( compare upper right with lower left panel ) , because wf preferentially keeps the modes that are above the noise .",
    "wf is thus particularly useful for identifying the large scale structures , such as filaments or superclusters in the data .",
    "rotation of the galaxies by @xmath191 eliminates most of the signal and the reconstructed field is now significantly lower than the typical structures in the reconstruction , as given in lower right panel of figure [ fig3_4 ] .",
    "this does not however completely eliminate the signal , because as discussed in section 3 aliasing of power from the gravity mode into the vorticity mode makes the latter nonvanishing even in the limit of small noise .",
    "the effect is rather small because of the large number of background galaxies , but would be more important if sampling was sparse .",
    "[ fig3_4 ]      the methods we developed in this paper are optimal for gaussian random fields , but they can also be applied to nongaussian situations , such as cluster reconstruction from weak lensing . in this case",
    "wf by definition still minimizes the variance in the class of linear estimators as shown in section 2.1 and so remains a useful reconstruction technique . to test it",
    "we apply it to reconstruct a massive cluster obtained from an n - body simulation ( figure [ fig3_1]a ) .",
    "we have rescaled the projected mass density of the cluster in units of critical density , so that it is nearly critical .",
    "the cluster core is very concentrated and shows double nucleus structure .",
    "the comoving size of the box is 3.2@xmath198mpc and we will take the area to be 10 across with 5000 galaxies in it .",
    "in this subsection we want to compare the reconstruction properties of various filtering methods and we will ignore the nonlinear corrections . those will be addressed in the next subsection .    there exist a number of cluster reconstruction techniques in the literature .",
    "squires & kaiser ( 1996 ) present a comprehensive review of most of these and conclude that their so - called maximum probability model is the best in the sense that it has the least amount of long - wavelength noise in the noise power spectrum .",
    "this is not surprising , since their model is identical to wf ( in fourier space ) , except that they advocate the prior power spectrum to be white noise with adjustable amplitude .",
    "the latter was taken to be larger than the noise , so that it does not suppress the modes on any scale ( the only reason @xcite add the theoretical prior is to regularize the inversion of matrix @xmath118 ) .",
    "because for long wavelength modes the actual signal is typically larger than the noise ( as shown in figure [ fig3_3 ] for the cluster used here ) the results will be similar to wf and both methods will reconstruct long wavelength modes without any suppression .",
    "however , on scales where the power spectrum drops below the noise the two methods differ : white noise prior does not filter the modes and is reconstructing mainly noise , while wf suppresses the modes , returning zero in the regions of low signal to noise .",
    "this is what one expects from a minimum variance method , since zero deviates from the true field less than the random noise does when the power spectrum of the latter exceeds the former .",
    "this is shown in figure [ fig3_3 ] for the simulated cluster . for short wavelengths white noise prior",
    "is no longer optimal in the sense of minimizing the variance and so in this sense wf is a minimum variance reconstruction among linear estimators even for a cluster .",
    "but as we show next this may not be the most desirable feature in the reconstruction and other methods ( such as the one investigated by seitz and schneider 1996 ) may result in a better overall reconstruction .    because the power spectrum has less power on small scales than the white noise one expects wf to result in a smoother reconstruction than the one assuming white noise as a theoretical prior .",
    "wf reconstruction of the cluster is shown in upper right panel of figure [ fig3_1 ] and indeed is rather smooth compared to the white noise prior wf reconstruction .",
    "note that the uniform weighting with variable theoretical variance ( equation [ wf ] ) shown in the middle left panel of figure [ fig3_1 ] gives almost identical results , but is much easier to compute .",
    "wf reconstruction shows a clear signature of the cluster above the background or above the @xmath191 rotation reconstruction in the middle right panel of figure [ fig3_1 ] , which does not show any evidence of a cluster .",
    "the noise is mostly eliminated from the map and most of the large structures one sees are real .",
    "these properties make wf to be a useful method even for cluster reconstruction .",
    "however , there is a high price to pay for this . by suppressing the small scale modes and",
    "so the noise across the field wf also suppresses the central peak of the cluster .",
    "some amount of smoothing is of course inevitable if the data do not have sufficient resolution , but wf tends to heavily smooth the data by suppressing all the small scale modes , regardless of their position .",
    "the nongaussian nature of the cluster center may give sufficient signal to noise to reconstruct it , but because all of the power on small scales is concentrated in this small region it may not give statistically significant excess above the noise in the power spectrum analysis .",
    "this in fact becomes exacerbated as we increase the area of the reconstruction , because by attempting to reconstruct the whole area ( with no power on small scales over most of the region ) wf will further suppress the central part of the cluster .",
    "for some applications one may be interested more in the central part of the cluster and willing to accept higher levels of noise at the outskirts of the cluster in which case wf will not be ideal method .",
    "[ fig3_3 ]    for cluster reconstruction it is therefore worth extending the family of linear estimators to make the prior power spectrum a free parameter .",
    "one example in this class is white noise prior advocated by squires & kaiser ( 1996 ) , which can reconstruct the structure on small scales .",
    "it should be stressed that with white noise prior one still has to impose a high frequency cutoff , otherwise the noise on small scales completely dominates the reconstruction . the way squires & kaiser ( 1996 ) impose this is by restricting themselves to a small number of modes in the expansion ,",
    "although the actual number was left unspecified .",
    "this method therefore amounts to a simple low - pass filtering , where the filter is a step function , as opposed to the wf , where the filter is more gradual and depends on the actual signal to noise ratio in the power spectrum of the data . if we extend the filtering scale beyond the scale where signal and noise power spectra are equal we obtain the reconstruction shown in lower right panel of figure [ fig3_1 ] for one particular choice of cutoff in @xmath146 .",
    "most of the reconstructed structure on small scale is noise , which clearly does not minimize the variance as defined in equation ( [ res ] ) and so is not optimal in this sense . on the other hand ,",
    "the central peak of the cluster is now significantly higher and its detection is more significant than in the case of wf . in this case reconstruction with smaller filtering scale",
    "may be more acceptable , despite being significantly noisier .",
    "nonlinear methods such as maximum entropy method ( @xcite ) are likely to do even better in such applications . note that the spike at the corner of the white noise prior reconstruction is an artifact of the periodic boundary conditions and would be eliminated if one used 20% zero padding on each side of the box .",
    "this example shows that one has to be careful about the size of the zero padding area , which will be somewhat dependent on the type of the filter one is using .",
    "[ fig3_1 ]    wf reconstruction is also not unique and changes with the size of the observed area .",
    "if we reduce the size then the cluster becomes more important and the contribution from nongaussian modes to the power spectrum can dominate over the noise to smaller scales than in previous example , resulting in keeping more small scale modes in the reconstruction .",
    "an example of this is shown in figure [ fig3_2 ] , where we increased the physical size of the cluster by a factor of two , keeping the other parameters unchanged .",
    "this enhanced the signal power spectrum and added the small scale structure to the reconstruction .",
    "most of this structure outside the cluster is noise , but now this noise does not dominate the power spectrum and the minimum variance estimator is allowed to keep this structure and reconstruct the true structure in the center as well .",
    "it is clear from this discussion that wf is no longer optimal for every application and can only be treated as one example in a wider class of linear filters . for a conservative reconstruction of the whole measured area",
    "wf will in general outperform other methods .",
    "other low - pass filters may however be more appropriate for more specific applications .",
    "we may conclude that using the measured power spectrum from the data in wf is a useful starting procedure , which should be supplemented by other linear filters by varying the prior power spectrum .",
    "nonlinear methods , such as maximum entropy method , may provide an even better reconstruction of strongly nongaussian and point - like structures .",
    "[ fig3_2 ]      so far we ignored the term @xmath32 in relating observed ellipticity to underlying shear field by assuming that @xmath23 is small .",
    "when the clusters are nearly critical , such as in the core of the cluster we used above , the corrections become important and have to be included .",
    "because the final result of the reconstruction is convergence @xmath23 one can include the correction using an iterative scheme : one first reconstructs @xmath23 using equation ( [ wf ] ) ignoring the correction and in the next step one uses the value of reconstructed @xmath23 to obtain the components of the shear @xmath30 from the observables @xmath199 @xmath200 . \\label{ge}\\ ] ] these corrections tend to suppress the reconstructed convergence , because the shear is reduced for the same measured ellipticity .",
    "a similar iterative scheme has been proposed by @xcite .",
    "assuming that @xmath201 is not close to unity then the error on the shear will continue to be dominated by the error on ellipticity @xmath199 and one can repeat the analysis as before with new values of the shear .",
    "otherwise one can improve this by adding additional term to the error matrix that corresponds to the error contribution from the reconstructed convergence , which is given by ( equation [ var ] ) @xmath202 [ \\hat{\\kappa}(\\bi{\\theta})-\\kappa(\\bi{\\theta})]^{\\dag}\\rangle = \\bi{r}_{\\kappa}\\bi{d}^{-1}\\bi{r}_{\\kappa}\\ ] ] and properly add the two error contributions . if the cluster contains a critical line where @xmath203 then inside outer line ( but outside inner critical line ) one should replace @xmath199 with @xmath204 ( @xcite ) and one way to handle this case is to identify the critical lines at the previous iteration , replace @xmath199 with @xmath204 where necessary and repeat the iteration until the convergence .",
    "we implicitly assumed that the zero point of convergence is known , which is something that can not be reconstructed from the ellipticity measurements alone . when reconstructing lss this will not be a major problem , since the mean convergence fluctuates by a few percent at most ( the power from the modes larger than the size of the field is small ) .",
    "one can thus impose the mean convergence to vanish across the survey by setting the unreconstructed @xmath205 mode to zero . for cluster reconstruction",
    "it is more appropriate to set the zero point so that the convergence at the outskirts of the cluster is zero and this is somewhat more problematic when the cluster extends to the edge of the field . for the example we used in this paper",
    "this is not so much of a problem , as one can separate the cluster from the surrounding area where the mean convergence should be small .",
    "one can in fact completely avoid this problem by using a local relation between derivatives of shear and convergence ( @xcite ) , although it does not appear straight - forward to implement this in the methods developed here .",
    "in section 3 we discussed how to handle the redshift distribution of the sources for the power spectrum estimation .",
    "one approach was to divide the galaxies into bins localized in distance and perform the analysis on each of these . the same approach should also be used for lss reconstruction , because the deflections come from a broad region along the line of sight and can only be determined in a statistical sense . in the case of cluster reconstruction",
    "the situation differs from lss because the deflector is in a single lens plane and the distance to it is assumed to be known . instead of using convergence @xmath23 , which depends on the lens and source positions , it is better to model directly the surface density @xmath206 , which is a physical quantity independent of the redshift distribution .",
    "it is related to the convergence via the relation @xmath207 where @xmath208 and @xmath209 are the radial comoving distances to the source and lens , respectively . when the sources are all at the same distance one can work with @xmath23 and then obtain @xmath206 using the above relation .",
    "when the sources are not at the same distance then @xmath23 changes with @xmath208 for the same surface density @xmath206 .",
    "the observable @xmath199 can be expressed directly in terms of @xmath206 in analogy to equations ( [ e ] ) , ( [ ge ] ) as @xmath210 because the galaxy distance is not known @xmath211 is a stochastic variable and can be treated as the estimate plus additional noise term . assuming each galaxy has a known probability distribution of distances @xmath157 ( in the absence of any distance information this is just the overall galaxy distribution ) , we can define the mean critical density @xmath212 and the dispersion around it @xmath213 for each galaxy we use the mean critical density @xmath214 in equation ( [ ecrit ] ) as the estimate and the dispersion @xmath215 as an additional source of error in the observable @xmath216",
    ". this additional noise term will be negligible for clusters at low @xmath217 ( where @xmath211 is rather insensitive to the redshift distribution of sources ) .",
    "even for high @xmath217 clusters this error is typically subdominant compared to the error on the ellipticity if the convergence is small .",
    "the only case when this error becomes important is for clusters that are close to critical , where the uncertainty on @xmath211 in the term @xmath218 of equation ( [ ecrit ] ) is amplified and can dominate over the ellipticity error , in which case we can add this error to the overall error budget of that galaxy .",
    "an alternative treatment of this problem has been discussed by @xcite for the case when the overall probability distribution of galaxy redshifts is given .",
    "the nice feature of our approach is that the mean distance and its error can be attached to each galaxy individually , which can take advantage of the multicolor photometric information . by assigning to each galaxy its photometric redshift and the corresponding error estimate we can compute for each galaxy separately its critical density and the dispersion around it .",
    "another example when this is important is when the measurement errors increase for fainter and presumably more distant sources . in this case",
    "the more nearby galaxies carry more weight than expected from their number density and one can correct for this by assigning to each galaxy a mean distance according to its observed flux .",
    "in this paper we address the question of optimal power spectrum estimation and projected mass density reconstruction from weak lensing data .",
    "we show that for gaussian random processes both have a well defined answer , which are in fact related and can be obtained from the same calculation . for the power spectrum",
    "the final answer is given by the unbiased estimator and its covariance matrix ( which also acts as a window function ) .",
    "the estimator is equivalent to the maximum likelihood method , but is significantly faster to compute .",
    "the covariance matrix of estimators includes the contributions from noise , sampling variance and aliasing .",
    "it is possible to invert from the 2-d power spectrum or to compute directly from the data the 3-d power spectrum , which will also be unbiased and minimum variance . finally , if we have distance information for the galaxies based on their photometric properties we can solve for both the power spectrum and its time dependence .",
    "the method can be used in the nonlinear regime , where it remains unbiased , but one has to compute the covariance matrix of the estimators , which now depend also on the reduced four point correlator .",
    "this can be either estimated from the data themselves , obtained from n - body simulations or computed using perturbation theory or hierarchical scaling relations .",
    "it is important to realize that even though the estimators were derived from the maximum likelihood method , the final result is always a weighted quadratic average of the data , where the weighting is the inverse of covariance matrix .",
    "this is the most expensive part of the calculation and can be replaced by some simpler weighting if necessary , such as uniform or inverse noise weighting . even in this case",
    "the method will remain unbiased and will in fact remain close to optimal on small scales . similarly",
    ", if one wants to parametrize the power spectrum with some other parameters ( such as its amplitude and slope ) one can derive unbiased quadratic estimators specifically tailored for those parameters instead of going through the power spectrum .",
    "this is however not necessary , since in the process of reducing the data to the power spectrum no information has been lost if minimum variance estimator has been used .",
    "another topic of interest that we did not discuss in detail here is the question of optimal measurement of higher moments .",
    "one attempt how to measure these has been presented by schneider et al . (",
    "1997 ) using mass aperture statistic .",
    "as mentioned in the introduction this statistic uses the tangential component of the shear to obtain a quantity that is a scalar ( as opposed to shear which is a tensor ) , which is needed to define a nonvanishing third moment in real space .",
    "alternative way to obtain a scalar quantity is to reconstruct the convergence in fourier space as done in this paper . within the context of the methods presented here the general strategy for determining the higher moments",
    "is in fact similar to the one leading to the minimum variance power spectrum methods , at least in the limit where the higher moments are small .",
    "one first multiplies the measurements with the inverse of correlation matrix .",
    "this is just a consequence of inverse variance weighting : if a given measurement has a large measurement error or it is strongly correlated with neighbouring points then it has to be downweighted , because it does not add new information to the data . on small scales",
    "this weighting reduces to the simple uniform weighting as discussed in section 2 .",
    "one then projects the data to fourier space to make a scalar quantity .",
    "because we reconstruct the fourier modes first one can attempt to measure higher order moments directly in fourier space ( e.g. bispectrum for the case of three - point statistic ) and this has some nice advantages ( e.g. @xcite ) .",
    "one can for example average over all triple products @xmath219 with @xmath220 , keeping the shape of the triangle the same and then vary this as a function of scale and angle between the wavevectors . as for the case of the power spectrum one has to compute the window for this statistic to make the estimator unbiased and to place errors on the estimates .",
    "alternatively , one can transform @xmath48 back to real space by applying @xmath221 operator to obtain a real space quantity that is a scalar , which can then be used to measure its skewness as a function of smoothing radius ( filtering scale ) . because all the operations are linear on the data",
    "one can obtain the covariance matrix of the estimates and compute the window function needed to make the estimator unbiased and provide error estimate .    for projected mass density reconstruction the wf method investigated here works best on large scales , where the distribution is close to gaussian .",
    "in that case wf preferentially keeps the structure that is above the noise and filters out scales that are noise dominated . to apply wf one has to compute the power spectrum on the data first using the methods discussed above .",
    "when the structures become nonlinear wf remains a useful reconstruction technique and still minimizes the variance in the class of linear estimators , but tends to oversmooth the data in very dense regions such as clusters . in that case",
    "it should be supplemented with linear filtering with a shorter smoothing scale or with one of the nonlinear methods , depending on the particular application one has in mind .",
    "this will be particularly important if one is searching for clusters in a random survey , where their positions are not given in advance and one wants to maximize the signal to noise for detecting such structures .",
    "baugh , c. m. , & efstathiou , g. 1994 , , 267 , 323 bernardeau , f. , van waerbeke , l. , & mellier , y. 1997 , a&a , 322 , 1 blandford , r. d. , saust , a. b. , brainerd , t. g. , & villumsen , j. v. 1991 , , 251 , 600 bond , j. r. , knox , l. , & jaffe , a. h. 1997 , astro - ph/9708203 bond , j. r. , efstathiou , g. , & tegmark , m. 1997 , astro - ph/9702100 bunn , e. f. , hoffman , y. , & silk , j. 1996 , , 464 , 1 connolly , a. j. , scabai , i. , szalay , a. s. , koo , d. c. , kron , r. c. , & munn , j. a. , , 110 , 2655 dekel , a. , & lahav , o. 1997 , in preparation fort , b. , mellier , y. 1994 , a&a review , r , 239 , 292 gazta~ naga , e. , & baugh , c. m. ( 1997 ) , in press , astro - ph/9704246 g ' orski , k. m. 1994 , , 430 , l85 gunn , j. e. 1967 , , 147 , 61 jungman , g. , kamionkowski , m. , kosowsky , a. & spergel , d. n. 1996 , phys .",
    "d , 54 , 1332 hamilton , a. j. s. , kumar , p. , lu , e. , & matthews , a. 1991 , , 374 , l1 hamilton , a. j. s. 1997 , , 289 , 285 heyl , j. s. , cole , s. , frenk , c. s. , & navarro , j. f. 1995 , , 274 , 755 .",
    "jain , b. , & seljak , u. 1997 , 484 , 560 kaiser , n. 1992 , , 388 , 272 kaiser , n. 1995 , , 439 , l1 kaiser , n. 1997 , , in press , astro - ph/9610120 kaiser , n. , squires , g. , fahlman , g. & woods , d. 1994 , in : clusters of galaxies , eds .",
    "f. durret , a. mazure & tran thanh van , editiones frontieres kendall , m. g. , & stuart , a. 1969 , ` the advanced theory of statistics ' , volume ii ( griffin , london ) kochanek , c. s. 1990 , , 247 , 135 miralda - escude , j. 1991 , , 380 , 1 narayan , r. , & nityananda , r. 1986 , , 24 , 127 oh , s. p. , spergel , d. n. , & hinshaw , g. 1997 , in preparation rybicki , g. , & press , w. h. 1992 , , 398 , 169 scoccimarro , r. , colombi , s. , fry , j. n. , frieman , j. a. , hivon , e. , & melott , a. 1997 , astro - ph/9704075 schneider , p , van waerbeke , jain , b. , & kruse , g. 1997 , astro - ph/9708143 seitz , c. , & schneider , p. 1995",
    ", a&a , 297 , 287 seitz , s. , & schneider , p. 1996 , a&a , 305 , 383 seitz , c. , & schneider , p. 1996 , a&a , 318 , 687 seljak , u. 1996 , , 463 , 1 seljak , u. 1997 , submitted to apj , astro - ph/9710269 squires , g. , & kaiser , n. 1996 , , 473 , 65 strauss , m. a. , willick , j. a. 1995 , physics reports , 261 , 271 stebbins .",
    "a. 1996 , preprint astro - ph/9609149 tegmark , m. 1997 , , 55 , 5895 tegmark , m. , taylor , a. , & heavens , a. 1997 , , 480 , 22 villumsen , j. v. 1996 , , 281 , 369 zaldarriaga , m. , spergel d. & seljak , u. 1997 , , 488 , 1 zaroubi , s. , hoffman , y. , fisher , k. , b. , & lahav , o. 1995 , , 449 , 446"
  ],
  "abstract_text": [
    "<S> large - scale structure distorts the images of background galaxies , which allows one to measure directly the projected distribution of dark matter in the universe and determine its power spectrum . </S>",
    "<S> here we address the question of how to extract this information from the observations . </S>",
    "<S> we derive minimum variance estimators for projected density reconstruction and its power spectrum and apply them to simulated data sets , showing that they give a good agreement with the theoretical minimum variance expectations . </S>",
    "<S> the same estimator can also be applied to the cluster reconstruction , where it remains a useful reconstruction technique , although it is no longer optimal for every application . </S>",
    "<S> the method can be generalized to include nonlinear cluster reconstruction and photometric information on redshifts of background galaxies in the analysis . </S>",
    "<S> we also address the question of how to obtain directly the 3-d power spectrum from the weak lensing data . </S>",
    "<S> we derive a minimum variance quadratic estimator , which maximizes the likelihood function for the 3-d power spectrum and can be computed either from the measurements directly or from the 2-d power spectrum . </S>",
    "<S> the estimator correctly propagates the errors and provides a full correlation matrix of the estimates . </S>",
    "<S> it can be generalized to the case where redshift distribution depends on the galaxy photometric properties , which allows one to measure both the 3-d power spectrum and its time evolution .    </S>",
    "<S> # 1 </S>"
  ]
}