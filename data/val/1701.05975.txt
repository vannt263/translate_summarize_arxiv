{
  "article_text": [
    "recent years , the network science , a multidiscipline research area , is concentrated by researchers from different backgrounds such as computer science , biology and physics . in these studies , betweenness centrality ( bc )",
    "is always applied as a critical metric to measure nodes or edges significance  @xcite .",
    "for example , girvan and newman developed a community detection algorithm based on edge betweenness centrality  @xcite , leydesdorff applied centrality as an indicator of the interdisciplinarity of scientific journals  @xcite and motter and lai established a model of cascading failures with node load being its betweenness  @xcite .",
    "however , the extremely high time and space complexity of calculating betweenness centrality greatly limits its applying on large networks . before the landmark work of brandes  @xcite ,",
    "the algorithm for computing betweenness centrality requires @xmath4 time and @xmath5 space . while brandes reduced the complexity to @xmath6 on space and @xmath7 and @xmath8 on time for unweighted and weighted networks , respectively , where @xmath9 is the number of vertices and @xmath10 is the number of edges  @xcite .",
    "however , this improved algorithm still can not satisfy scientific computation requirements in the present information explosion era as more and more unexpected large networks emerge , such as online social networks , gene networks and collaboration networks .",
    "for example , twitter possesses hundreds of millions active users which construct a huge online social network .",
    "however , a weighted network with one million nodes may take about one year to calculate its betweenness centrality using brandes algorithm , which is an unbearable cost .",
    "because of this , there is a pressing need to develop faster bc algorithm for explorations of diverse domains .",
    "gpu general computing , which provides excellent parallelization , achieves higher performance compared to traditional cpu sequential algorithms in many issues including network science  @xcite .",
    "cuda is the most popular gpu - computing framework developed by nvidia corporation and some researchers have even parallelized brandes s algorithm by using it  @xcite .",
    "however , previous works concentrated on unweighted networks for simplification , but to our best knowledge , most realistic networks are weighted ones .",
    "the most significant difference of bc algorithm on unweighted and weighted networks is the shortest path segment . in weighted networks ,",
    "dijkstra algorithm should be used to solve the single source shortest path ( sssp ) problem rather than depth first search ( dfs ) algorithm .",
    "many efforts in previous work have been devoted to the gpu version of sssp problem using the well - known dijkstra algorithm  @xcite .",
    "although these algorithms have been presented and developed , establishing a parallel version of betweenness centrality algorithm on weighted networks is nontrivial because the original sssp algorithm have to be modified in many critical points for this task and to our best knowledge , a proper and fast solution is still missing .",
    "aiming at filling this vital gap , we propose a fast solution using cuda to calculate bc on large weighted networks based on previous gpu bc algorithms and sssp algorithms in this paper .    to make our algorithm more efficient , we make efforts to optimize it by employing several novel techniques to conquer the influence of irregular network structures .",
    "real - world networks have many characters which could deteriorate the performance of gpu parallelization algorithms .",
    "for example , the frontier set of nodes is always small compared to the total number of vertices , especially for networks with great diameters . in the meantime",
    ", the majority of nodes do not need to be inspected in each step , hence processing all vertices simultaneously in traditional algorithms is wasteful .",
    "mclaughlin and bader proposed a work - efficient strategy to overcome this problem  @xcite .",
    "another well - known issue is that the power - law degree distribution in realistic networks brings in serious load - imbalance .",
    "several methods were proposed in previous study to conquer this problem , e.g. , merrill et al . employed edge parallel strategy to avoid load - imbalance  @xcite and hong et al . dealt with this problem by using warp technique  @xcite . in this paper",
    ", we systematically investigate the advantages and drawbacks of these previous methods and implement them in our algorithm to solve the above two problems .",
    "experiments on both real - world and synthetic networks demonstrate that our algorithm outperforms the baseline gpu algorithm significantly .",
    "our main contributions are listed as follows :    * based on previous gpu parallel sssp and betweenness centrality algorithms , we propose an efficient algorithm to calculate betweenness centrality on weighted networks , which achieves 30 to 150 speedup over the best existing cpu algorithm on realistic networks .",
    "* we compare the traditional node - parallel method to the work - efficient version and the warp - centric method .",
    "experiments on realistic networks and synthetic networks demonstrate that the combination of the two strategies works better than others , which achieves 2.65 speedup over the baseline method on realistic networks .",
    "* we package our algorithm to a useful tool which can be used to calculate both node and edge betweenness centrality on weighted networks .",
    "researchers could apply this tool to conveniently calculate bc on weighted networks fast , especially on large networks .",
    "the source code is publicly available through https://dx.doi.org/10.6084/m9.figshare.4542405 .",
    "first we briefly introduce the well - know brandes s algorithm and dijkstra algorithm based on the preliminary definitions of network and betweenness centrality .",
    "a graph can be defined as @xmath11 , where @xmath12 is the set of vertices , and @xmath13 is the set of edges .",
    "an edge is a node pair @xmath14 , which means that there is a link connecting nodes @xmath15 and @xmath16 , and its weight is @xmath17 . if the edge @xmath18 exists , it can be traversed from @xmath15 to @xmath16 and from @xmath16 to @xmath15 because we only focus on undirected graphs in this paper .",
    "however , our algorithm can be expanded to directed graph version easily .",
    "a path @xmath19 is defined as a sequence of vertices connected by edges , where @xmath20 is the starting node and @xmath21 is the end node .",
    "the length of @xmath22 is the sum of the weights of the edges involved in @xmath22 .",
    "@xmath23 is the distance between @xmath20 and @xmath21 , which represents the minimum length of all paths connecting @xmath20 and @xmath21 .",
    "@xmath24 denotes the number of shortest paths from @xmath20 to @xmath21 . according to the definition",
    ", we have @xmath25 @xmath26 , @xmath27 and @xmath28 for undirected graph .",
    "@xmath29 denotes the number of shortest paths from @xmath20 to @xmath21 where @xmath16 lies on .",
    "based on these definitions , the betweenness centrality can be defined as    @xmath30    from the above definitions , the calculation of betweenness centrality can be naturally separated into the following two steps :    1 .",
    "compute @xmath23 and @xmath24 for all node pairs @xmath31 2 .",
    "sum all pair - dependencies ,    in which pair - dependency is defined as @xmath32 .",
    "the first step consumes @xmath33 and @xmath34 time for unweighted and weighted graph respectively , therefore the bottleneck of this algorithm is the second step , which requires @xmath4 time .",
    "brandse s developed a more efficient bc algorithm which requires @xmath33 time for unweighted graph , and @xmath34 time for weighted graph .",
    "the critical point is that the dependency of a node @xmath16 when the source node is @xmath20 is @xmath35 . applying this equation",
    ", we can accumulate the dependencies after computing the distance and number of shortest paths from a source vertex @xmath20 to all other vertices , rather than after computing all pair shortest paths .",
    "we can develop a parallel version based on brandes s algorithm for unweighted graph because the graph is always traversed as a tree by using dfs algorithm .",
    "given a source node @xmath20 , the root of the tree is @xmath20 and the tree produced by dfs method in the first step . in the second step , dependencies related to source node @xmath20 are calculated from the bottom to the root of the tree and the nodes at the same level are isolated and have no influence to each other . as a result , the parallel version can explore nodes at the same level simultaneously in both of the two steps , which will essentially boost the calculation .",
    "dijkstra algorithm  @xcite and floyd - warshall algorithm  @xcite are commonly employed to solve shortest path problems . while dijkstra algorithm is more adaptable to betweenness centrality problem because brandes s algorithm accumulates dependencies after computing single source shortest paths ( sssp ) , rather than finding and storing all pair shortest paths .",
    "dijkstra algorithm applies greedy strategy to solve sssp . in this algorithm ,",
    "the source node is @xmath20 and if the shortest path from @xmath20 and another node @xmath15 is achieved , @xmath15 will be settled .",
    "according to be settled or not , all nodes in graph @xmath36 could be separated into two sets , which are settled vertices @xmath37 and unsettled vertices @xmath38 .",
    "an array @xmath39 is used to store tentative distances from @xmath20 to all nodes . at first , @xmath40 and @xmath41 for all other nodes . and the source node @xmath20",
    "is settled and considered as the frontier node to be explored . in the second step , for every node @xmath42 and the adjacent frontier node @xmath43 ,",
    "if @xmath44+w(f , u)<d[u]$ ] , @xmath45 $ ] will be updated to @xmath44+w(f , u)$ ] .",
    "then the node @xmath46 that has the smallest distance value will be settled and considered as the new frontier node and then the procedure goes back to the second step .",
    "the algorithm finishes when all nodes are settled . from the above description",
    ", dijkstra algorithm has no parallel character as it picks one frontier node in each iteration . but this restriction can be loosed that several frontier vertices can be explored simultaneously which is similar to dfs parallel approach .",
    "in this section , we introduce the details of our gpu version bc algorithm on weighed graph .",
    "firstly , we apply _ compressed sparse row _ ( csr ) format , which is widely used in graph algorithms , to store the input graph  @xcite .",
    "it is space efficient that both of the vertex and edge consume one entry , and it is convenient to perform the traversal task on gpu .",
    "moreover , edges related to the same vertex store consecutively in memory which makes warp - centric technique more efficient . for storing weighted graphs , another array that stores the weights of all edges is accordingly required .",
    "we apply both coarse - grained ( that one block processes one root vertex @xmath20 ) and fine - grained parallel ( that threads within the block compute shortest paths and dependencies that related to @xmath20 ) strategies .",
    "the pseudo - code in this paper describes the parallel procedure of threads within a block .",
    "algorithm  [ alg : init ] shows the initialization of required variables . @xmath38 and @xmath47 represent unsettled set and frontier set , respectively .",
    "@xmath16 is unsettled if @xmath48=1 $ ] and is frontier node if @xmath49=1 $ ] .",
    "@xmath50 represents the tentative distance and @xmath51 $ ] is the number of shortest paths from @xmath20 to @xmath16 .",
    "@xmath52 $ ] stores the dependencies of @xmath16 .",
    "@xmath37 and @xmath53 record the levels of traversal as csr format and they are used in the dependency accumulation step .",
    "as can be seen in algorithm  [ alg : dependency ] , in the dependency accumulation part , we get nodes at the same level from @xmath37 and @xmath53 and accumulate dependencies of these nodes simultaneously .",
    "note that in algorithm  [ alg : dependency ] we only assign threads for nodes that need to be inspected rather than assign for all nodes , which enhances the efficiency by avoiding redundant threads .",
    "@xmath48 \\leftarrow 1 $ ] + @xmath49 \\leftarrow 0 $ ] + @xmath54 \\leftarrow \\infty$ ] + @xmath51 \\leftarrow 0 $ ] + @xmath52 \\leftarrow 0 $ ] + @xmath55 \\leftarrow 0 $ ] + @xmath56 \\leftarrow 0 $ ] + @xmath57 \\leftarrow 0 $ ] + @xmath58 \\leftarrow 1 $ ] + @xmath59 \\leftarrow 0 $ ] + @xmath60 \\leftarrow 1 $ ] + @xmath61 \\leftarrow s;s_{len } \\leftarrow 1 $ ] + @xmath62 \\leftarrow 0;ends[1 ] \\leftarrow 1;ends_{len } \\leftarrow 2 $ ] + @xmath63     +   +   +   +   +   +      the parallel version of dfs procedure , which is used in bc algorithm for unweighted network , could be modified naturally from its sequential version because vertices located at the same level of the dfs tree can be inspected simultaneously .",
    "while for dijkstra algorithm , picking one frontier node each time makes its parallelization a difficult task .",
    "however , this restriction can be relaxed , which means that several nodes could be settled becoming frontier set and be inspected simultaneously in the next step . in this paper",
    ", we apply the method described in  @xcite . in this method",
    ", @xmath64 is precomputed .",
    "then we define @xmath65 as    @xmath66    where @xmath67 is the tentative distance of node @xmath15 , @xmath68 is the unsettled nodes set in iteration @xmath69 .",
    "all nodes that satisfy the following condition    @xmath70    are settled and become frontier nodes . when applying dijkstra algorithm in betweenness centrality calculation , the number of shortest paths should be counted . to achieve this goal ,",
    "the above condition should be modified to @xmath71    fig .",
    "[ fig : shortest](a ) demonstrates an example , in which vertex @xmath72 is the source node . if applying eq .",
    "[ eq : condition1 ] , @xmath73 and @xmath74 will be frontier nodes after inspecting @xmath72 in the first iteration , and the number of shortest paths will be 1 for both @xmath73 and @xmath74 . then @xmath73 and @xmath74 will be inspected simultaneously in next step .",
    "if processing @xmath74 first , the number of shortest paths for @xmath75 will be set to 1 , while the the correct value of shortest paths number for @xmath75 should be 2 .",
    "this mistake comes from the overambitious condition and @xmath74 should not be settled after the first iteration .",
    "although the distance will be correct for all nodes using eq .",
    "[ eq : condition1 ] , but the number of shortest paths will be wrong .",
    "however , eq .  [ eq : condition2 ] will lead to correct shortest paths number for @xmath75 by only settling @xmath73 after first iteration",
    ". this condition could be found at line 22 in algorithm  [ alg : shortest ] .",
    "algorithm  [ alg : shortest ] depicts our parallel dijkstra algorithm in detail . the tentative distance and number of shortest paths",
    "are calculated which can be seen from line 2 to line 12 . in this part , there will be a subtle parallel problem that several nodes in the frontier set may connect to the same node , as can be seen in fig .",
    "[ fig : shortest](b ) . in this example , both @xmath73 and @xmath74 are in frontier set and connect to @xmath17 , which results in the classical race condition problem .",
    "to avoid this situation , we define a lock for each node . the first thread focus on @xmath17 will achieve the lock and other threads",
    "will not be permitted to change @xmath76 $ ] and @xmath77 $ ] .",
    "note that other threads must not wait because in cuda framework , a group of threads in a warp performs as a simd ( single instruction multiple data ) unit . after computing @xmath50 and @xmath78 for all nodes",
    ", we can achieve @xmath65 based on the above analysis , as can be seen from line 13 to line 18 . in the end ,",
    "@xmath38 , @xmath47 , @xmath37 and @xmath53 are updated for next iteration .",
    "will make the number of shortest paths of @xmath75 incorrect .",
    "( b ) an example of race condition . @xmath73 and @xmath74 are frontier nodes in one iteration , and both of which are connected with @xmath17.,scaledwidth=80.0% ]      as can be seen on line 2 in algorithm  [ alg : shortest ] , threads will be assigned to all nodes but only nodes that in the frontier set will perform the calculation job , which may be inefficient .",
    "mclaughlin et al . figured out an excellent work - efficient technique to solve this problem  @xcite .",
    "here we develop our work - efficient version by employing this technique .",
    "@xmath47 will be changed to a _",
    "queue _ that stores all frontier nodes and a variable @xmath79 is defined to recode the length of @xmath47 , as can be seen in algorithm  [ alg : we : init ] . then on line 2 in algorithm  [ alg : we : shortest ] , threads can be assigned to @xmath80 \\sim f[f_{len}-1]$ ] , which may be much smaller than the total number of nodes . at the same time , the method of updating @xmath47 should also be changed , which can be seen in algorithm  [ alg : we : shortest ] .    //",
    "initialize other variables except @xmath47 +   + //",
    "initialize other variables    @xmath81 $ ] + // inspect @xmath16 // calculate @xmath82 +   +   +   +   +   +   +      real world networks always have scale - free character , which means their degree distributions follow power law .",
    "when implementing parallel graph algorithms through node parallel strategy , this feature brings in serious load - imbalance problem .",
    "most nodes have low degrees while some nodes have extremely high degrees .",
    "threads that assigned to high degree nodes will run slowly and other threads have to wait .",
    "edge parallel strategy can solve this problem  @xcite but bring in other under - utilizations at the same time . in this paper",
    ", we apply the novel warp - centric method  @xcite , which allocates a warp to one node rather than a thread . then threads within a warp focus on part of edges",
    "connected the specific node . as a result",
    ", each thread does less job for high degree nodes and the waiting time will be sharply decreased .",
    "moreover , memory access patterns can be more coalesced than the conventional thread - level task allocation and because of this , the efficiency of memory access can be essentially improved .",
    "nevertheless , the warp - centric method also has some drawbacks .",
    "firstly , node degree may be smaller than the warp size , which is always 32 in modern gpu . to solve this problem ,",
    "virtual warps are proposed in  @xcite .",
    "secondly , the number of required threads will be raised as each node needs _",
    "warp_size _ threads rather than one thread in this situation .",
    "but the number of threads in one block is fixed , hence each thread will be assigned to more nodes iteratively , which may results in low performance .",
    "we find that work - efficient method can relieve this problem because it requires less threads compared to the conventional node - parallel method , as can be seen in fig .",
    "[ fig : warp ] . in this paper",
    ", we apply the warp - centric method for both node - parallel and work - efficient method . as a result , we get four algorithms ( see fig .  [",
    "fig : real ] ) that using different threads allocation strategies and we compare them on both real - world and synthetic networks .",
    "we collect six real - world networks from the internet , which have broad types including collaboration network , epinions trust network , email communication network , wiki vote network and two biological networks .",
    "they are publicly available in the internet and have been analyzed extensively by previous literatures  @xcite .",
    "the details of these networks are listed in table  [ tab : real ] . to further understand the effect of network structures to algorithms performance , we generate two types of networks , which are erds  rnyi ( er ) random graphs  @xcite and kronecker graphs  @xcite .",
    "the degree distribution of er random graph is poisson , indicating its nodes degrees are relatively balanced . while kronecker graph possesses scale - free and small - world characters , which make it more similar to the realistic network .",
    "the two biological networks and the cond - mat-2005 collaboration network are weighted networks and for other networks , we uniformly assign random edge weights ranging from 1 to 10 .",
    "we run the four gpu methods on geforce gtx 980 ( only entry - level for scientific computing ) using cuda 7.5 toolkit .",
    "we also develop the sequential algorithm using c++ and optimize it by applying binary heap in dijkstra algorithm due to fibonacci heap s inefficiency in practical use , making our cpu version bc algorithm performs better than most of the existing implementations .",
    "and we run the cpu version algorithm on competent intel xeon e5620 with 2.40ghz .",
    "-0.6in0 in    .*details of networks from public dataset * [ cols=\"<,<,<,<,<,<\",options=\"header \" , ]     [ tab : real ]      from fig .",
    "[ fig : real ] , we can see that all the four gpu programs achieve much better performance than the cpu version on all the six real - world networks .",
    "the algorithm that applies work - efficient coupled with warp - centric technique is the best one for achieving 30 to 150 speedup and its performance could be essentially improved on more sophisticated gpu devices .",
    "work - efficient method is more efficient than node - parallel in all networks , while warp - centric method is better on large degree networks , such as the two biological networks . for networks with low average degrees , applying warp - centric method alone",
    "is always inefficient because nodes degrees are always smaller than _ warp_size_. using smaller virtual _",
    "warp_size _ could be better on these networks and we will demonstrate this hypothesis later .",
    "however , combining warp - centric method and work - efficient method is always better than using work - efficient method alone because it needs less threads in each step , which accordingly relieves the influence of the second drawback of warp - centric method .",
    "the combination algorithm achieves 2.65 speedup over the baseline node - parallel strategy on average .",
    "to deeply mining the relationship of the network structure and the performance of the four gpu implementations , we further run them on two types of synthetic graphs , as can be seen in fig .",
    "[ fig : scale ] . from fig .",
    "[ fig : scale](a ) , ( b ) , ( c ) and ( d ) , we find that work - efficient algorithm works better than node - parallel algorithm in all networks since it always reduces the required number of threads .",
    "as can be seen in fig .",
    "[ fig : scale](a ) and ( b ) , warp - centric method works well on networks with large degrees , which is consistent with the conclusion in realistic networks .",
    "note that for kronecker graphs , warp - centric method works better than that for random graphs as kronecker graphs have serious load - imbalance problem and warp - centric technique appropriately solves it .",
    "while for er random graphs in  [ fig : scale](a ) , the advantage of warp - centric method is only the efficient memory access . for low degree graphs ,",
    "warp - centric method works even worse than node - parallel strategy because the degrees are always smaller than _ warp_size _ , as can be seen in fig .",
    "[ fig : scale](c ) and ( d ) . for random graphs ,",
    "the performance of warp - centric method is extremely poor when the average degree is smaller than 8 and fig .",
    "[ fig : scale](e ) explains the reason .",
    "the small average degree brings in large average depth , which means that the average size of the frontier sets is small . in this case , warp - centric method assigns more useless threads to nodes that do not need inspections . on the contrary ,",
    "as the degree grows , it is closer to _ warp_size _ and the depths drop down sharply , which make the warp - centric method performs much better . while low - degree kronecker graphs have power - law degree distributions and small average depths , which make warp - centric method works not as bad as on random graphs .",
    "however , the combination of the two methods always runs faster than applying work - efficient method alone because it avoids the second drawback of warp - centric method , which is discussed in the previous section . in conclusion , work - efficient method always achieves better performance while the performance of warp - centric method relies on networks structures but the joint version always achieves the best performance .",
    "to @xmath83 for er random and kronecker graphs , respectively . and",
    "the average degrees are fixed to 32 for both of the two types of networks .",
    "( c ) and ( d ) separately tune the average degrees for random and kronecker networks , in which the random networks have 20000 vertices and the kronecker networks have @xmath84 nodes .",
    "( e ) illustrates the average depths of search trees for random graphs used in ( c ) and kronecker graphs used in ( d ) .",
    "networks with larger depths have smaller average frontier sets , indicating the poor performance with parallelism.,scaledwidth=90.0% ]    from the above analysis , applying smaller _",
    "warp_size _ may accelerate the two implementations which using warp - centric method when the netowrks average degree is small . and",
    "this hypothesis can be verified in fig .",
    "[ fig : warp_adjust ] .",
    "we apply smaller _ warp_size _ on email enron network , soc_epinions1 network and other two synthetic graphs whose average degrees are both four . from fig .",
    "[ fig : warp_adjust](a ) and ( b ) , we find that implementations with smaller _ warp_size _ do perform better than both of the baseline node - parallel algorithms and the large _ warp_size _ algorithm on both of the low - degree realistic networks . and",
    "when coupled with work - efficient method , algorithms with smaller _ warp_size _ also perform better than both of the work - efficient strategy alone and the combination of work - efficient and large _",
    "warp_size_. the reason is that small _ warp_size _ reduces the required number of threads and then eliminates the waste of assigning more threads to a node than its degree .",
    "the implementations which have small _ warp_size _ and coupled with work - efficient method achieve the best performance because they avoid both drawbacks of warp - centric method but utilize the advantages of this technique .",
    "the results on low - degree kronecker graph is similar as on realistic networks since kronecker graph is similar with real - world network . for er random graphs , the algorithm with small _ warp_size _",
    "does not achieve better performance compared to node - parallel version because the large average depth , which is analyzed in previous section .",
    "however , when coupled with work - efficient method , the implementations with small _ warp_size _ perform slightly better than the work - efficient algorithm , which further proves the excellence and stability of the joint algorithm . in summary ,",
    "the joint algorithm are most efficient and insensitive to network structure . and if we choose an appropriate _ warp_size _ , its performance could be even better .",
    "nodes whose average degree is four .",
    "warp - centric method can not accelerate the speed when combining node - parallel strategy .",
    "but when combining small _ warp_size _ with work - efficient method , the performance will be slightly better than applying work - efficient method alone .",
    "( d ) is kronecker graph with @xmath85 nodes and the average degree is four , on which smaller _ warp_size _ achieves better performance.,scaledwidth=90.0% ]",
    "existing gpu version of betweenness centrality algorithms only concentrate on unweighted networks for simplification .",
    "our work that computing betweenness centrality on large weighted networks bridges this gap and achieves prominent efficiency enhancement compared to the cpu implementation .",
    "moreover , we apply two excellent techniques which are work - efficient and warp - centric methods in our algorithm .",
    "work - efficient method allocates threads more efficiently and warp - centric method solves the load imbalance problem and simultaneously optimizes the memory access .",
    "we compare these implementations with cpu algorithm and the basic gpu algorithm in realistic networks .",
    "the results show that gpu parallel algorithms perform much better than the sequential algorithm and the algorithm which integrates the two techniques is the best , achieving 30 to 150 speedup over the cpu version .",
    "results on generated random graphs and kronecher graphs further justify the outperformance of our solution .    for future work",
    ", we will consider implementing gpu algorithm to process dynamic networks . when networks changes a little ( like few new nodes come in or several links vanish ) , calculating betweenness centrality for all nodes is unnecessary because betweenness centrality of most nodes and edges will not be changed .",
    "some previous works have explored the sequential algorithm on this issue  @xcite .",
    "we plan to develop gpu version of these algorithms to achieve better performance .",
    "this work was supported by nsfc ( grant no . 71501005 ) and the fund of the state key lab of software development environment ( grant nos . sklsde-2015zx-05 and sklsde-2015zx-28 ) .",
    "r. f. also thanks the innovation foundation of buaa for phd graduates .",
    "wang y , davidson a , pan y , wu y , riffel a , owens jd .",
    "gunrock : a high - performance graph processing library on the gpu . in : proceedings of the 20th acm sigplan symposium on principles and practice of parallel programming .",
    "ppopp 2015 .",
    "new york , ny , usa : acm ; 2015 .",
    "p. 265266 .",
    "harish p , narayanan pj .",
    "accelerating large graph algorithms on the gpu using cuda . in : proceedings of the 14th international conference on high performance computing .",
    "berlin , heidelberg : springer - verlag ; 2007 .",
    "p. 197208 .",
    "cong g , bader da .",
    "an experimental study of parallel biconnected components algorithms on symmetric multiprocessors ( smps ) . in : proceedings of the 19th ieee international parallel and distributed processing symposium .",
    "ipdps 05 .",
    "washington , dc , usa : ieee computer society ; 2005 .",
    "p. 45b45b .",
    "sariyce ae , kaya k , saule e , atalyrek v .",
    "betweenness centrality on gpus and heterogeneous architectures . in : proceedings of the 6th workshop on general purpose processor using graphics processing units ; 2013 .",
    "p. 7685 .",
    "mclaughlin a , bader da . scalable and high performance betweenness centrality on the gpu . in : proceedings of the international conference for high performance computing , networking , storage and analysis ; 2014 .",
    "p. 572583 .",
    "delling d , goldberg av , nowatzyk a , werneck rf .",
    "phast : hardware - accelerated shortest path trees . in : proceedings of the 2011 ieee international parallel & distributed processing symposium .",
    "ieee computer society ; 2011 .",
    "p. 921931 .",
    "davidson a , baxter s , garland m , owens jd .",
    "work - efficient parallel gpu methods for single - source shortest paths . in : proceedings of the 2014 ieee 28th international parallel and distributed processing symposium .",
    "ieee computer society ; 2014 .",
    "p. 349359 .",
    "hong s , kim sk , oguntebi t , olukotun k. accelerating cuda graph algorithms at maximum warp . in : proceedings of the 16th acm symposium on principles and practice of parallel programming ; 2011 .",
    "p. 267276 .",
    "bell n , garland m. implementing sparse matrix - vector multiplication on throughput - oriented processors . in : proceedings of the conference on high performance computing networking , storage and analysis ; 2009 .",
    "p. 18:118:11 .",
    "crauser a , mehlhorn k , meyer u , sanders p. a parallelization of dijkstra s shortest path algorithm . in : proceedings of the 23rd international symposium on mathematical foundations of computer science ; 1998 .",
    "p. 722731 .",
    "rossi ra , ahmed nk . the network data repository with interactive graph analytics and visualization . in : proceedings of the twenty - ninth aaai conference on artificial intelligence ; 2015.available from : http://networkrepository.com ."
  ],
  "abstract_text": [
    "<S> recent decades have witnessed the tremendous development of network science , which indeed brings a new and insightful language to model real systems of different domains . </S>",
    "<S> betweenness , a widely employed centrality in network science , is a decent proxy in investigating network loads and rankings . </S>",
    "<S> however , the extremely high computational cost greatly prevents its applying on large networks . </S>",
    "<S> though several parallel algorithms have been presented to reduce its calculation cost on unweighted networks , a fast solution for weighted networks , which are in fact more ubiquitous than unweighted ones in reality , is still missing . in this study , we develop an efficient parallel gpu - based approach to boost the calculation of betweenness centrality on very large and weighted networks . </S>",
    "<S> comprehensive and systematic evaluations on both synthetic and real - world networks demonstrate that our solution can arrive the performance of 30x to 150x speedup over the cpu implementation by integrating the work - efficient and warp - centric strategies . </S>",
    "<S> our algorithm is completely open - sourced and free to the community and it is public available through https://dx.doi.org/10.6084/m9.figshare.4542405 . considering the pervasive deployment and declining price of gpu on personal computers and servers , our solution will indeed offer unprecedented opportunities for exploring the betweenness related problems in network science .     </S>",
    "<S> + rui fan@xmath0 , ke xu@xmath0 and jichang zhao@xmath1 + @xmath0state key lab of software development environment , beihang university + @xmath2school of economics and management , beihang university + @xmath3corresponding author : jichang@buaa.edu.cn </S>"
  ]
}