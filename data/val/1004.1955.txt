{
  "article_text": [
    "we consider a channel , termed an _ individual channel _ , where no specific probabilistic or mathematical relation between the input and the output is assumed .",
    "this channel is an extreme case of an unknown channel .",
    "achievable rates are characterized using only the input and output sequences , which capture the actual ( a - posteriori ) channel behavior .",
    "this point of view is similar to the approach used in universal source coding of individual sequences where the goal is to asymptotically attain for each sequence the same coding rate achieved by the best encoder from a model class , tuned to the sequence .",
    "this framework is an evolution of those considered in shayevitz and feder @xcite and eswaran et .",
    "@xcite and is presented in more detail in our papers @xcite and @xcite , together with the relevant background .",
    "we will give a brief introduction below .",
    "the setting we consider includes a single encoder receiving a message to transmit and emitting symbols @xmath0 and a decoder receiving a sequence of symbols @xmath1 and attempting to reconstruct the message . in the present paper",
    "the input and output symbols are real - valued vectors , i.e. @xmath2 and @xmath3 .",
    "the relation between @xmath4^t$ ] and @xmath5^t$ ] is unknown to the encoder and decoder .",
    "we consider two communication scenarios : with feedback ( possibly imperfect ) and without feedback .",
    "for the case in which there is no feedback the communication system transmits in a constant rate , and outage is unavoidable , i.e. one can not guarantee a small probability of error in all circumstances",
    ". in the case feedback exists , the communication rate may be dynamically adapted and outage may be prevented . in both cases",
    "we assume common randomness exists in the encoder and the decoder .",
    "the results in the current paper extend the previous results , yet only for the first case , of transmission in a constant rate .",
    "the performance is measured by a rate function @xmath6 representing an empirical measure of the achievable rate between the channel input and channel output , over @xmath7 channel uses . in examples here and in @xcite@xcite ,",
    "@xmath8 can be viewed as the mutual information achieved in a certain family of statistical models ( in the current scope , all zero mean gaussian channels ) , when the model parameters match the empirical ones . in communication without feedback",
    "we say that a given rate function @xmath9 is achievable with an input distribution @xmath10 if for large block size @xmath11 , it is possible to communicate at any rate @xmath12 and an arbitrarily small error probability is obtained whenever @xmath13 . the communication system is required to emit blocks with probability distribution @xmath10 , which is possible due to the use of randomization . by placing this additional constraint",
    "we leave aside the question of adapting the input distribution , so that the current framework attempts at achieving the empirical `` mutual information '' rather than the empirical `` capacity '' .",
    "another reason for the fixed prior is avoiding degenerate systems which may transmit only `` bad '' sequences with low ( or zero ) @xmath8 .",
    "this constraint is further discussed in @xcite , section viii.c .",
    "the main result of this paper is that for the multiple - input multiple - output ( mimo ) channel @xmath14 ( i.e. with @xmath15 transmit and @xmath16 receive antennas ) the rate function defined below is asymptotically achievable , in the fixed rate case : @xmath17 where the @xmath18 matrix @xmath19 denotes the channel input over @xmath7 symbols , and the @xmath20 matrix @xmath21 denotes the output .",
    "@xmath22 , @xmath23 and @xmath24^t [ \\mt x \\mt y]$ ] are the input , the output and the joint empirical correlation matrices , respectively .",
    "this is a generalization of the result of @xcite where the rate function @xmath25 was proved to be achievable for real valued siso channel @xmath26 ( @xmath27 denotes empirical correlation ) . as in @xcite ,",
    "the proof is geometrically intuitive .",
    "the results easily extend to the _ complex _ mimo case , and to rate function using the empirical _ covariance _",
    "( rather than the correlation ) , but we focus here on the simpler case .    the paper is organized as follows : in section [ sec : rate_function_origin ] we explain the motivation for this rate function and its relation to the probabilistic gaussian channel , in section [ sec : main_result ] we present in detail the main result , which is proven in section [ sec : proof_of_lemma ] .",
    "section [ sec : comments ] is devoted to comments and further research items .",
    "we use lowercase boldface letters to denote vectors , and uppercase boldface letters to denote matrices .",
    "we use the same notation for random variables and their sample values , and the distinction should be clear from the context .",
    "consider the channel from @xmath28 to @xmath29 which are real valued vectors .",
    "for the additive white gaussian noise ( awgn ) mimo channel @xmath30 with @xmath31 , and @xmath32 it is well known that the mutual information is @xmath33 see for example @xcite@xcite .",
    "this reflects the maximum achievable rate with the fixed covariance matrix @xmath34 , and is sometimes termed the _ open - loop mimo capacity _ , since equal power is a reasonable choice when the transmitter does not know the channel .",
    "a more general form of the mutual information is obtained by assuming @xmath35 are any jointly gaussian random vectors and writing : @xmath36\\right ) \\right|\\end{aligned}\\ ] ] therefore : @xmath37 \\right ) \\right| } \\right]\\ ] ] where the factors @xmath38 cancel out since the dimension of the covariance matrix in the denominator is the sum of the dimensions in the nominator . the expression ( [ eq : mi_mimo ] )",
    "is more general than ( [ eq : mi_mimo_awgn ] ) since it does not assume the noise is white , and is suitable for our purpose since it expresses the mutual information through properties of the input and output vectors without using an explicit channel structure . for the case of the awgn mimo channel it yields the same value as ( [ eq : mi_mimo_awgn ] ) . for the particular scalar case where @xmath39 , @xmath40 are scalars with variances @xmath41",
    ", @xmath42 and correlation factor @xmath43 , equation ( [ eq : mi_mimo ] ) evaluates to @xmath44 , as previously obtained for the siso case .",
    "the empirical rate function we defined in ( [ eq : remp_mimo ] ) is an empirical version of the mutual information expression in ( [ eq : mi_mimo ] ) , except that the covariance matrices are replaced by empirical _",
    "( rather than covariance ) matrices , i.e. we do not cancel the mean .",
    "when @xmath45 or @xmath46 ( which leads also to @xmath47 ) , the rate function will be defined by removing the columns of @xmath19 or @xmath21 ( respectively ) , which are linearly dependant on the others , until these determinants become positive .",
    "it is not important which columns are removed to break the linear dependence , due to this function s invariance to linear transformation ( property [ property2 ] below ) . for the case of @xmath48 or @xmath49",
    "we define @xmath50 .",
    "the rate function has the following properties which are expected from an empirical metric of the `` mutual information '' :    1 .",
    "[ property1 ] * non - negativity : * @xmath51 .",
    "this is evident from the fact @xmath52 is the mutual information between two gaussian vectors with the respective covariances .",
    "it will also be shown in passing as part of the derivation in section [ sec : proof_of_lemma ] .",
    "[ property2 ] * invariance under linear transformations : * any invertible linear matrix operation on the input or output ( for example , multiplying any of the input or output signals by a factor , adding signals , etc ) does not change @xmath52 , i.e. @xmath53 . + _ proof : _ suppose we multiply @xmath19 and @xmath21 by arbitrary matrices @xmath54 and @xmath55 respectively",
    ". define @xmath56 then @xmath57 . and likewise for @xmath21 . since @xmath58 = [ \\mt x , \\mt y ] \\cdot \\left [ \\begin{array}{cc } \\mt g_x & 0 \\\\ 0 & \\mt g_y \\end{array } \\right]$ ] then from the same considerations we will have @xmath59 , therefore the factors cancel out and @xmath60 3 .",
    "[ property3 ] * symmetry : * @xmath61",
    "[ theorem : continuous_nonadaptive_mimo1 ] given the channel @xmath14 , define the input over @xmath7 symbols as an @xmath18 matrix @xmath19 , and the output as an @xmath20 matrix @xmath21 .",
    "let @xmath22 , @xmath23 and @xmath24^t [ \\mt x \\mt y]$ ] be the input , the output and the joint empirical correlation matrices , respectively . define the rate function @xmath62 then for every @xmath63 , a positive definite @xmath64 matrix @xmath65 and @xmath66 there exists random encoder - decoder pair of rate @xmath12 over block size @xmath7 , such that the distribution of the input sequence is @xmath67 and for any @xmath68 the probability of error for any message given an input sequence @xmath69 and output sequence @xmath70 is not greater than @xmath71 if : @xmath72 where @xmath73 specifically , for every @xmath74 and @xmath75 there exists @xmath7 large enough so that the probability of error is not greater than @xmath71 if : @xmath76    the theorem almost directly follows from the next lemma which we will prove subsequently :    [ lemma : pairwise_mimo ] for any @xmath20 matrix @xmath21 , the probability of @xmath77 where @xmath19 is randomly drawn @xmath67 is bounded by : @xmath78 for any @xmath79 in the range @xmath80 , and where @xmath81 is defined in ( [ eq : value_of_c_l ] ) .",
    "note that the bound does not depend on @xmath65 . to prove theorem [ theorem : continuous_nonadaptive_mimo1 ] , the codebook @xmath82 is randomly generated by i.i.d .",
    "selection of each codeword from the gaussian matrix distribution @xmath83 .",
    "the common randomness is the codebook itself .",
    "the encoder sends the @xmath84-th codeword , and the decoder uses maximum empirical rate decoder i.e. chooses : @xmath85 where ties are broken arbitrarily . by using lemma [ lemma : pairwise_mimo ] and the union bound , the probability of error given @xmath86 is bounded by : @xmath87\\end{gathered}\\ ] ]    therefore if ( [ eq : cond_on_r_to_fall_below_pe ] ) is satisfied , then @xmath88 , which proves the first part of the theorem .",
    "the second part follows directly from the first part . for any @xmath75 and @xmath89",
    "there is @xmath7 large enough so that the condition @xmath68 is satisfied , and then @xmath7 could be increased till the redundancy in ( [ eq : cond_on_r_to_fall_below_pe ] ) , @xmath90 would be smaller than @xmath91 ( note that @xmath81 is decreasing in @xmath7 ) , therefore @xmath88 will be satisfied if ( [ eq : asymptotic_cond_on_r_to_fall_below_pe ] ) is satisfied .",
    "to prove lemma [ lemma : pairwise_mimo ] we use the chernoff bound : @xmath92    to prove the lemma we need to calculate @xmath93 where the expected value is taken with respect to @xmath19 .",
    "the remainder of this section is devoted to upper bounding @xmath94 .",
    "we will first assume that @xmath95 , i.e. @xmath96 , and then extend to general @xmath65 .",
    "define @xmath97 $ ] .",
    "we perform a qr decomposition of @xmath98 and @xmath99 in order to obtain more friendly expressions . as a reminder",
    ", qr decomposition of a matrix @xmath100 ( with @xmath101 and @xmath102 upper triangular ) is performed by gram - schmidt process .",
    "we start from the left column of @xmath103 and work our way to the last one . at each time",
    "we take a column of @xmath103 and split it to the part which can be represented by a linear combination of the columns to the left of it ( equivalently , to the columns of @xmath104 already generated ) , and the `` innovation '' , i.e. the part which is orthogonal to the subspace generated by the previous columns . the vector representing",
    "the innovation is normalized , and becomes the respective column of @xmath104 , and its power becomes the diagonal element in @xmath102 .",
    "the coefficients representing the part of the vector which is in the subspace of previous columns become the elements of @xmath102 above the diagonal .",
    "another important property of qr decomposition is that the determinant of @xmath105 can be written in terms of the diagonal elements in @xmath102 : @xmath106 .",
    "now define the diagonal of the upper triangular matrix in the qr decomposition of the matrices @xmath19 , @xmath21 and @xmath99 respectively to be the vectors @xmath107 , @xmath108 and @xmath109 $ ] .",
    "i.e. if @xmath110 , @xmath111 and @xmath112 then @xmath113 , @xmath114 , and @xmath109 = \\mathrm{diag } ( \\mt r_z)$ ] .",
    "the lengths of the vectors @xmath115 are @xmath116 respectively , so that they overlap with the columns of @xmath21 and @xmath19 in the matrix @xmath99 .",
    "we have : @xmath117 note that the @xmath118 factors cancel out because the matrix dimensions are @xmath15 and @xmath16 in the nominator and @xmath119 in the denominator . since the gram - schmidt process operates sequentially from the first column to the last , and the first @xmath16 columns of @xmath99 and @xmath21 are equal , we will have @xmath120 .",
    "therefore we can write : @xmath121",
    "note that @xmath122 and @xmath123 both relate to the same vector , the @xmath124-th column of @xmath19 .",
    "the ratio @xmath125 is the ratio between the innovation of the @xmath124-th column of @xmath19 with respect to the subspace spanned by previous columns of @xmath19 alone ( nominator ) or these columns together with the columns of @xmath21 ( denominator ) . obviously from this reason",
    "@xmath126 ( and therefore @xmath51 - property [ property1 ] ) .",
    "the key observation in this derivation is as follows : consider a sequential drawing of the columns of @xmath19 and calculation of the factors @xmath125 .",
    "since the @xmath124-th column of @xmath19 is chosen isotropically and independently of the previous columns , the value of previous columns does not affect the distribution of the innovations @xmath127 ( only the number of dimensions in previous columns does ) . using this observation which we will prove subsequently",
    ", we would be able to break @xmath94 represented as the expected value of a product ( [ eq : r_as_ad ] ) into a product of expected values ( equations ( [ eq : l_prod_induction])-([eq : l_as_prod_d ] ) ) , and the proof is completed by a ( tedious ) calculation of these expected values .    to show the independence of @xmath128 in previously drawn values , denote by @xmath129 a matrix including the columns @xmath130 to @xmath124 of @xmath19 , and by @xmath131 the @xmath124-th column .",
    "define a a unitary @xmath132 matrix @xmath104 whose first @xmath133 columns span the subspace spanned by the first @xmath133 columns of @xmath19 , its next @xmath16 columns extend this subspace to cover also the columns subspace of @xmath21 , and the next @xmath134 columns complete it to an orthonormal basis .",
    "this matrix does not depend on @xmath135 and specifically on the column @xmath124 .",
    "we assume that the columns of @xmath21 are linearly independent ( we will relax this assumption later ) . also , in probability one , assuming @xmath66 , the columns of @xmath136 are linearly independent of each other and of the columns of @xmath21 . to see this ,",
    "it is easy to show that the projection of each column in any direction orthogonal to the subspace already spanned by previous ones ( including @xmath21 ) , is also gaussian therefore has probability @xmath137 to be @xmath137 , as long as there exists such an orthogonal vector , i.e. the number of previously generated vectors is smaller than @xmath7 .",
    "now define @xmath138 . since @xmath139 also @xmath140 .",
    "the first @xmath133 elements of @xmath141 represent the projections of @xmath131 to the subspace spanned by previous columns of @xmath19 , and the next @xmath16 elements represent the projections to the subspace spanned by columns of @xmath21 .",
    "so @xmath142 collects the energy of all elements except the first @xmath133 , and @xmath143 collects the energy of all elements except the first @xmath144 . to see this formally , in the gram - schmidt process the coefficients of the projection of @xmath131 on the subspace spanned by @xmath136 are @xmath145 , and",
    "the projection itself is @xmath146 , therefore the innovation is @xmath147 . since @xmath148 and @xmath149 we have @xmath150   \\vr v_i \\right\\|^2 = \\left\\| \\left [ \\begin{array}{c } 0 \\\\ { \\mt q_{i}^n}^t \\vr x_i \\end{array } \\right ]   \\right\\|^2 = \\left\\|   \\vr z_{i}^n",
    "\\right\\|^2 $ ] and similarly , @xmath151 .",
    "therefore @xmath152 are independent of @xmath21 and the previous columns of @xmath19 , and can be given by norms over parts of a gaussian i.i.d .",
    "vector of length @xmath7 . defining @xmath153 where the equality is due to the independence shown above",
    ", we have for any @xmath154 : @xmath155 = \\\\= e \\left [ \\prod_{i=1}^{k-1 } \\left ( \\frac{a_i}{d_i } \\right)^{\\gamma n } \\cdot e \\left ( \\left .",
    "\\left ( \\frac{a_k}{d_k } \\right)^{\\gamma n } \\right| \\mt x_{1}^{k-1 } \\right ) \\right ] = \\\\= e \\left [ \\prod_{i=1}^{k-1 } \\left ( \\frac{a_i}{d_i } \\right)^{\\gamma n } \\cdot d_k \\right ] = e \\left ( \\prod_{i=1}^{k-1 } \\left ( \\frac{a_i}{d_i } \\right)^{\\gamma n } \\right ) \\cdot d_k\\end{gathered}\\ ] ] therefore by induction : @xmath156^{\\frac{\\gamma \\cdot n}{2 } } = e \\prod_{i=1}^{t } \\left ( \\frac{a_i}{d_i } \\right)^{\\gamma n } \\stackrel{(\\ref{eq : l_prod_induction})}{= }",
    "\\prod_{i=1}^{t } d_i\\ ] ]    now we bound @xmath157 ( using the previously defined gaussian vector @xmath141 ) : @xmath158 where in ( a ) we used independent chi - squared distributed @xmath159 , and in ( b ) we changed variables from @xmath160 to @xmath161 , with inverse transformation @xmath162 and jacobian @xmath163 .",
    "the first integral in the expression above evaluates to : @xmath164 by definition of @xmath165 .",
    "the second integral behaves like @xmath166 near @xmath167 and like @xmath168 at @xmath169",
    ". therefore it will exist ( converge ) iff the power of @xmath170 near @xmath137 is larger than @xmath171 and at @xmath172 is smaller than @xmath171 .",
    "the first condition is @xmath173 .",
    "the other condition always holds since @xmath174 . note that since the power of @xmath175 is larger by more than 1 than the power of @xmath170 it is positive ( when the first condition holds ) .",
    "therefore we can bound :    @xmath176    combining ( [ eq : d_i_derivation ] ) , ( [ eq : w_integral ] ) and ( [ eq : v_integral_bound ] ) we obtain : @xmath177    since @xmath94 results in a rate loss of @xmath178 , and @xmath179 is superexponential in @xmath7 , we would like to express more explicitly the dependence on @xmath7 . using @xmath180 with @xmath181 , @xmath182",
    "we can obtain the bound @xmath183 therefore @xmath184 and @xmath185    substituting the above into ( [ eq : chernoff_error_bound ] ) proves lemma [ lemma : pairwise_mimo ] for @xmath186 .",
    "the two assumptions on the parameters of the problem we have made in order for @xmath94 to be bounded are ( a ) @xmath187 which was needed in order that each new column of @xmath19 would not be spanned by the previous columns and the columns of @xmath21 in probability 1 , and ( b ) @xmath188 , is needed for the existence of @xmath189 .",
    "suppose now that @xmath190 .",
    "using the cholesky decomposition we can define a coloring matrix @xmath191 , @xmath192 so that @xmath193 and @xmath194 . since by property [ property2 ] the rate function is invariant to a linear transformation of @xmath19 we would have @xmath195 , therefore if lemma [ lemma : pairwise_mimo ] holds with respect to the white signal @xmath196 it also holds with respect to @xmath19 . with regard to the assumption that the columns of @xmath21 are linearly independent : if they are not , then the rate function is defined with respect to a smaller matrix @xmath197 containing only the independent columns . comparing with a full rank @xmath21 , the random variables @xmath123 increase ( i.e. @xmath198 ) due to the smaller dimension of @xmath199 , therefore @xmath200 and the lemma still holds",
    "* comparison with the siso case : * comparing lemma [ lemma : pairwise_mimo ] with lemma 4 of @xcite for the siso case @xmath201 , which is proven by a direct calculation , the bound here is slightly worse due to the limitation @xmath202 which stems from the use of the chernoff bound . * comparison with mimo capacity : * the scheme above achieves the mutual information of a gaussian mimo channel but not its capacity .",
    "achieving the capacity requires adaptation of the input distribution , which for the known awgn channel @xmath30 is performed by svd and water pouring @xcite .",
    "the strength of the scheme is in the lack of any assumptions about the probability distribution , which make it applicable for example for non gaussian noise or one that depends on the transmitted signal .    * exploiting temporal correlation : * in the current results , as in previous ones @xcite , the rate function depends on the zero order empirical probability , and lacks the ability to exploit temporal correlation .",
    "however the results can be used to exploit such correlation in the siso or mimo channel , in a crude way , by applying the scheme on blocks of @xmath203 channel uses . the rate function over blocks is always superior to the single letter case , and the penalty is an increase in the fixed redundancy .    * using empirical covariance instead of correlation : * when the matrices @xmath204 in ( [ eq : remp_mimo ] ) are replaced with the empirical correlation @xmath205 ( where @xmath206 ) , the derivation is similar , except projection on an additional dimension ( the all - ones vector ) precedes the other projections .",
    "the results are the same with a loss of one dimension : @xmath207 and @xmath208 are required , and there is a small variation in @xmath81 .    *",
    "the complex mimo channel : * the results easily extend to the _ complex_-valued mimo channel , using the same technique .",
    "the main difference is a double number of degrees of freedom in the derivation of @xmath157 , which doubles the rate compared to equation [ eq : remp_mimo ] .",
    "* adaptivity : * in @xcite@xcite we presented a communication scheme using a low rate feedback , which dynamically adapts the transmission rate and achieves the rate functions without outage .",
    "such schemes are of higher practical interest .",
    "it is possible to show that the adaptive scheme of @xcite@xcite achieves @xmath8 of ( [ eq : remp_mimo ] ) up asymptotically vanishing redundancy , and up to a set of @xmath39 sequences having vanishing probability .",
    "o. shayevitz and m. feder , `` achieving the empirical capacity using feedback : memoryless additive models'',ieee transactions on information theory , vol.55 no.3 , march 2009 , pp.1269 -1295 k. eswaran , a.d .",
    "sarwate , a. sahai , and m. gastpar , `` zero - rate feedback can achieve the empirical capacity , '' ieee transactions on information theory , vol.58 , no.1 , january 2010 y. lomnitz and m. feder , `` communication over individual channels , '' arxiv:0901.1473v1 [ cs.it ] , 11 jan 2009 , http://arxiv.org/abs/0901.1473v1 y. lomnitz and m. feder , `` feedback communication over individual channels , '' ieee international symposium on information theory ( isit ) , 2009 , pp.1506 - 1510 , june 28 2009-july 3 2009 i. telatar , `` capacity of multi - antenna gaussian channels , '' at&t technical memorandum , june 1995 a. goldsmith , s.a .",
    "jafar , n. jindal , and s. vishwanath , `` capacity limits of mimo channels , '' ieee journal on selected areas in communications , vol . 21 , no .",
    "5 , june 2003"
  ],
  "abstract_text": [
    "<S> we consider the problem of communicating over a multiple - input multiple - output ( mimo ) real valued channel for which no mathematical model is specified , and achievable rates are given as a function of the channel input and output sequences known a - posteriori . </S>",
    "<S> this paper extends previous results regarding individual channels by presenting a rate function for the mimo individual channel , and showing its achievability in a fixed transmission rate communication scenario . </S>"
  ]
}