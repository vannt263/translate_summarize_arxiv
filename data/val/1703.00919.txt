{
  "article_text": [
    "video systems have recently gained a lot of attention .",
    "many new 3d video systems have been developed . among them",
    "super multiview television and free viewpoint television can be examples of such novel 3d systems . in the free viewpoint television a user is able to freely choose a position of a virtual camera .",
    "the requested view of a scene is generated from dynamic 3d representation of the scene .",
    "the most commonly used 3d representation is a multivideo and depth ( mvd ) @xcite composed of multiple videos acquired by the set of cameras and accompanied depth maps for each of the views .",
    "based on transmitted videos and depth data any view can be easily generated by employing depth - image - base rendering ( dibr ) @xcite .",
    "recently 3d extension of such standards as avc @xcite and hevc @xcite that allows for efficient transmission of dynamic 3d scene representation in mvd format has been finalized .",
    "depth information in such systems can be acquired either directly by depth cameras @xcite , or indirectly by algorithmic depth estimation from recorded videos @xcite .",
    "commonly depth information is obtained by the conversion from disparity information @xcite .",
    "although in computer vision , disparity @xmath0 is often treated as synonymous with depth ( distance @xmath1 ) , essentially those terms are the inverse of each other .    @xmath2    disparity is a displacement vector between corresponding fragments ( pixels , blocks ) of two images of the same scene taken from different viewpoints .",
    "those two corresponding fragments represent the same fragment of an observed scene but seen from two different viewpoints .",
    "stereo correspondence search is an active research topic in computer vision , and one of the basic method of obtaining disparity information .",
    "there are many stereo disparity estimation methods known .",
    "comprehensive study of stereo disparity estimation methods can be found in @xcite , and on the middlebury webpage @xcite containing up - to - date benchmark of stereo disparity estimation methods . in the scope of development of multiview systems",
    "stereo correspondence search was extended to multiview correspondence search @xcite .    for the sake of simplicity and accuracy",
    ", many algorithms assume that images are taken by a rectified set of cameras @xcite . consecutively",
    ", corresponding fragments of a given image can be found on the same horizontal line in the remaining images .",
    "some algorithms use three views ( left , central and right ) @xcite as inputs and produce disparity map or depth map for the central view ( fig .",
    "[ fig:3viewde ] ) .",
    "often when it is not important which of left or right view is referred to , a name `` side view '' is used instead .    during disparity estimation , for a given fragment of the central view , the algorithm searches for the corresponding fragment in the side views that represent the same fragment / portion of the scene .",
    "the correspondence search is done on the basis of similarity metric which expresses how probable it is that a certain fragment of one image is the corresponding fragment of the second image .",
    "although the metric used is often called similarity , it actually expresses dissimilarity between fragments .",
    "there are many similarity metrics known from literature : sum of absolute difference ( sad ) sum of squared difference ( ssd ) , rank , census , cross correlation and other @xcite .",
    "the correspondence search is often defined as an optimization problem in which for every fragment of the central image the best ( the most similar ) fragment of the side views is selected .",
    "this optimization problem maybe expressed in terms of energy function using markov random field ( mrf ) and optimized via one of the optimization algorithms such as belief propagation @xcite , dynamic programming @xcite , or graph cut @xcite .",
    "since input videos are captured by multiple cameras with different positions , some parts of the observed scene can be occluded , and thus not visible , within some of the views .",
    "disparity estimation for those fragments of a scene is challenging and requires special care .",
    "if the the algorithm do not properly taking into account , possible occlusions within the scene , estimated disparity can be wrong .",
    "estimated disparity can indicated not truly corresponding fragments . in this paper a novel approach to occlusion handling designed to work in three - view disparity estimation algorithms is proposed .",
    "@xmath3    given three images , center @xmath4 , left @xmath5 and right @xmath6 of the same size , we search for such a displacement @xmath7 for every pixel p of center view ( at coordinates @xmath8 ) that minimize cost function expressing a similarity between pixel p ( or small fragment around the pixel p like block ) and a corespondent pixel p ( small fragment around pixel p ) displaced by @xmath7 in side views ( at positions @xmath9 in left and @xmath10 in right view ) .",
    "such displacement is then a disparity of a given pixel p of a center view .",
    "@xmath11    in disparity estimation based on / from three views ( see fig .  [",
    "fig : occ ] ) , a given point of the scene visible from center view can be visible from both of the side views ( point a ) , or only from one of the side views ( left or right , point b ) , or from neither of them ( point c ) .    if the given fragment of the scene visible from center view is not visible from one or both of the side views , we say that a given fragment of the scene is occluded in side view ( is not visible from that particular side view ) .",
    "the simplest method for detecting occluded fragments is cross - checking @xcite .",
    "cross - checking tests the consistency of estimated disparity value for pixels from center view with those estimated for pixels in left and right views .",
    "if the disparity value estimated in each view is different for a correspondent triple of pixels from center , left and right views given pixels are assumed to be occluded .",
    "next , the disparity value for occluded pixels are extrapolated from neighboring pixels that are not occluded . in order to perform cross - checking , disparity maps for all of the three views",
    "are required .",
    "estimation of three disparity maps is not always possible . even if the estimation of three disparity maps instead of one is possible it is resource and time consuming .",
    "occlusion handling is performed by adding / putting additional constraints , such as ordering constraint or uniqueness constraint to objective function of optimization procedures like graph cut ( gc ) , dynamic programming ( dp ) or belief propagation ( bp ) used to estimate the disparity map .",
    "the ordering constraint @xcite imposes the same order of corresponding pixels in all views .",
    "if a pixel a is on the left of pixel b in the center view , in the side view pixel a that is a corresponding pixel of pixel a must be as well on the left of pixel b , a corresponding pixel of pixel b. in real scenes the ordering constraint can be violated in the case of big perspective change or in case of thin objects . in such cases ordering constraint can introduce errors in estimated disparity maps .",
    "the uniqueness constraint @xcite imposes the one - to - one correspondence between pixel in center and side views .",
    "if a given pixel a of the central view is assigned to a corresponding pixel b in the side view , no other pixel of central view can be assigned to a correspondence with pixel b in side view .",
    "this way unique pixel to pixel correspondence is forced across all of the views .",
    "there are many disparity estimation algorithms known , that handle occlusion in efficient way @xcite .",
    "the main drawback of all of those algorithms are additional constraints ( terms ) imposed in optimization procedures with increased complexity and thus execution time of the disparity estimation .",
    "another approach to occlusion handling is to change cost term ( eq .  [ eqn : cost ] ) composed of similarity metric in optimization algorithms .",
    "as we search for corresponding fragment of a central view in both side views simultaneously , there are many ways of defining a @xmath12 function .    commonly @xcite it is the sum of similarity metrics between a fragment in the center view and corresponding fragments in left and right views .",
    "@xmath13    because of the occlusions tanimoto @xcite proposed to pick just the most similar fragment from either left or right view .",
    "the intuition is that the occluded fragment of the images will lead to less similar fragment , thus the minimum of similarity metrics from left and right view is used .",
    "@xmath14    in this paper we propose yet another way to define cost function which takes into account an occlusion possible within the scene .",
    "as it was said before , a given fragment of a scene visible from center view can be occluded in one or both side views ( left or / and right ) ( fig .",
    "[ fig : occ ] ) .",
    "in such a case , searching for a correspondence of a given pixel of center view in this particular side view ( left or right ) is pointless , as the given fragment of the scene is not visible from that particular side view .",
    "considering the correspondence with an occluded fragment of an image could cause errors in estimated disparity .",
    "therefore the correspondence search should be performed only in side views in which a considered fragment of a center view is not occluded .",
    "the cost function should be constructed in such a way that it considers only similarity metrics from not occluded views .",
    "if a given fragment is visible in both views , then the cost function should be an average of both similarity metrics , in order to reduce the influence of noise , which is present in all views .",
    "we propose to define the cost function in a way that it considers only similarity metrics of fragments from a not occluded view ( either left or right ) ( eq .",
    "[ eqn : novelcost ] ) where @xmath15 , @xmath16 expresses whether a given pixel of a center view is not occluded in left and right views respectively . depending on the existence of occlusion in the views , the sum @xmath17 in the denominator of eq .",
    "[ eqn : novelcost ] can be 2 if a pixel in not occluded in both views , 1 if it is occluded in one of the side views ( either left or right ) , and 0 if it is occluded in both side views .",
    "if a given pixel is occluded in both side views the equation [ eqn : novelcost ] loses its meaning , thus in such a case constant penalty value is used as a cost value .",
    "@xmath18    but why a given fragment ( object a ) of a scene is not visible in a side view ? because in a side view that fragment is occluded by some other part of the scene ( object b ) .",
    "object b blocks light rays from object a , so in side view closer object b is visible instead the farther object a.    consider the example on fig .",
    "[ fig : occ_detection ] where two points a and b are observed by two cameras ( left and center ) .",
    "point b is closer to the cameras and point a is farther .",
    "point b is visible in both views ( left and center ) at pixel position @xmath19 and @xmath20 respectively .",
    "but due to the occlusion , point a is visible only in center view at pixel position @xmath21 .",
    "if there would be no point b , point a should / would be visible in left view at pixel position @xmath22 .",
    "the disparity of point b in left view is the difference of the pixel position @xmath19 and @xmath20 and disparity of point a in left view would be ( if the point was / would be visible ) the difference of pixel position @xmath23 and @xmath21 .",
    "@xmath24    @xmath25    the distance to the camera @xmath1 is reciprocal to disparity .",
    "so a fragment of an image representing a closer object ( point b ) has bigger disparity than the fragment representing farther object ( point a ) .",
    "@xmath26    for a given pixel @xmath21 of center view at coordinates @xmath8 and considered displacement @xmath7 , corresponding pixel @xmath23 in left view should be at coordinates @xmath9 .",
    "so , if we want to check whether a fragment a of a scene is occluded in left view we have to check the disparity ( distance ) assigned to the considered corresponding pixel @xmath23 in left view .",
    "if a disparity @xmath27 assigned already to considered corresponding pixel @xmath23 is bigger than the considered displacement t then probably a pixel @xmath22 is not a fragment of the same object a but rather some other closer object b that occludes object a in the left view .",
    "based on such a consideration we can create a function assessing whether for a pixel at coordinates @xmath8 and displacement @xmath7 , corresponding pixel is / can be / will be occluded or not in left and right views .",
    "@xmath28    @xmath29    @xmath30 equal 1 means that the corresponding pixel in side view at a given displacement is probably not occluded .",
    "the proposed idea is general - it does not impose any particular source of disparity maps @xmath31 for left and @xmath32 for right view .",
    "but in general , disparity maps for left and right views are unknown before estimating the disparity for central view .",
    "commonly , disparity maps are estimated iteratively with the use of such algorithms like belief propagation or graph cut . in such algorithms , at each iteration of the estimation , algorithm maintains up - to - date / best already estimated disparity map for center view .",
    "this disparity map is further refined in the next iteration of the algorithm .    for our occlusion detection",
    "we propose to use disparity maps of side views created based on the disparity map of center view through depth - image - based rendering ( dibr ) . after each iteration of a disparity estimation algorithm , we create disparity maps of side views ( @xmath31 and @xmath32 ) from the best already estimated disparity map of a center view .",
    "this way if the estimation algorithm used assigned already some disparity @xmath33 to some pixel @xmath20 , then pixel @xmath21 can not have such a disparity that the corresponding pixel @xmath23 ( fig .",
    "[ fig : occ_detection ] ) is at the same position as corresponding pixel @xmath19 of pixel @xmath20 . in other words fragment b of a scene represented by pixel @xmath20 in center view",
    "should occlude a fragment a of a scene ( represented by pixel @xmath21 in center view ) seen from left view .",
    ".positions of views used for evaluation of quality of estimated disparity maps . [ cols=\"<,^,^,^\",options=\"header \" , ]",
    "we have presented a novel approach to occlusion handling in disparity estimation , based on a modification of similarity cost function . proposed",
    "approach has been tested in the three - view disparity estimation scenario . for occlusion detection synthesized disparity maps of left and right views have been used .",
    "for well - known multiview video test sequences , the experimental results show that the proposed approach provides virtual view quality improvement of 1.25 db of luminance psnr over the state - of - the - art technique implemented in mpeg depth estimation reference software ( ders )",
    ". moreover , direct quality evaluation of estimated disparity reveals that proposed the approach reduces a number of bad pixels by 1.26 p.p .",
    "research project was supported by national science centre , poland , according to the decision dec-2012/05/n / st7/1279 .",
    "s.  y.  kim , j.  h.  cho , and a.  oschan , _",
    "3d video generation and service based on a tof depth sensor in mpeg-4 multimedia framework _ , ieee trans . on consumer electronics , vol .",
    "1730 - 1738 , august 2010 .",
    "m.  domaski , a.  dziembowski , a.  kuehn , m.  kurc , a.  uczak , d.  mieloch , j.  siast , o.  stankiewicz and k.  wegner , _ experiments on acquisition and processing of video for free - viewpoint television _ , 3dtv conference 2014 , budapest , hungary , july 2014 .          j.  stankowski , k.  klimaszewski , o.  stankiewicz , k.  wegner , m.  domaski , _ preprocessing methods used for poznan 3d / ftv test sequences _ ,",
    "iso / iec jtc1/sc29/wg11 mpeg 2010/m17174 , doc .",
    "m17174 , kyoto , japan , january 2010 .",
    "j.  stankowski , k.  klimaszewski , book : `` image processing and communications challenges 2 '' , chapter : `` application of epipolar rectification algorithm in 3d television '' , advances in intelligent and soft computing : vol .",
    "84 , springer - verlag , berlin , 2010 , pp .",
    "345 - 352 , isbn : 978 - 3 - 642 - 16294 - 7 .",
    "g.  egnal and r.  wildes , _ detecting binocular halfocclusions : empirical comparisons of five approaches _ , ieee trans . on pattern analysis and machine intelligence , vol .",
    "24 no . 8 , pp . 1127 - 1133 , august 2002 .",
    "t.  liu , p.  zhang , and l.  luo , _ dense stereo correspondence with contrast context histogram , segmentation - based two - pass aggregation and occlusion handling _ , lecture notes in computer science , vol .",
    "449 - 461 , january 2009 .",
    "r.  ben - ari and n.  sochen , _ stereo matching with mumford - shah regularization and occlusion handling _ , ieee trans .",
    "on pattern analysis and machine intelligence , vol .",
    "2071 - 2084 , november 2010 .",
    "d.  scharstein and r.   szeliski , _ high - accuracy stereo depth maps using structured light _ , in ieee computer society conference on computer vision and",
    "pattern recognition ( cvpr 2003 ) , volume 1 , pages 195 - 202 , madison , wi , june 2003 .",
    "g.  tech , k.  wegner , y.  chen , s.  yea , _",
    "3d - hevc draft text 6 _ joint collaborative team on 3d video coding extension development of itu - t sg 16 wp 3 and iso / iec jtc 1/sc 29/wg 11 doc .",
    "jct3v - j1001 , 10th meeting : strasbourg , fr , 1824 october 2014 .",
    "annex i _ multiview and depth video coding _ of iso / iec 14496 - 10 , int .",
    "standard _ generic coding of audio - visual objects ",
    "part 10 : advanced video coding _ , 8th ed .",
    ", 2013 , also : itu - t rec .",
    "h.264 , edition 8.0 , 2013 .",
    "s. m. seitz , b. curless , j. diebel , d. scharstein , and r. szeliski , _ a comparison and evaluation of multi - view stereo reconstruction algorithms _ , in proceedings of the ieee computer society conference on computer vision and pattern recognition ( cvpr06 ) , pp .",
    "519526 , june 2006 .",
    "o.  stankiewicz , `` stereoscopic depth map estimation and coding techniques for multiview video systems '' , phd dissertation at poznan university of technology , faculty of electronics and telecommunications , 2014 ."
  ],
  "abstract_text": [
    "<S> the paper presents a novel approach to occlusion handling problem in depth estimation using three views . a solution based on modification of similarity cost function is proposed . during the depth estimation via optimization algorithms </S>",
    "<S> like graph cut similarity metric is constantly updated so that only non - occluded fragments in side views are considered . at each iteration of the algorithm non - occluded fragments </S>",
    "<S> are detected based on side view virtual depth maps synthesized from the best currently estimated depth map of the center view . </S>",
    "<S> then similarity metric is updated for correspondence search only in non - occluded regions of the side views . </S>",
    "<S> the experimental results , conducted on well - known 3d video test sequences , have proved that the depth maps estimated with the proposed approach provide about 1.25 db virtual view quality improvement in comparison to the virtual view synthesized based on depth maps generated by the state - of - the - art mpeg depth estimation reference software .    </S>",
    "<S> depth estimation , disparity estimation , occlusion handling , mvd , graph cuts , ders , free viewpoint television . </S>"
  ]
}