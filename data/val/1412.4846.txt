{
  "article_text": [
    "numerous statistic studies have been done to uncover the dynamical universal laws in complex system in physical , biological and social areas , such as the reaction dynamics within cells , financial market fluctuations , income distribution , biological species , word frequency , scientific publication , city size , etc.[1 - 19 ] .",
    "zipf s law and heaps law are two typical representatives , the coexistence of which have been observed in various systems [ 20 , 21 ] .",
    "zipf finds a certain scaling law in the rank of the word frequencies .",
    "heaps law reveals another aspect of scaling in natural language processing , according to which the vocabulary size grows in a sub - linear function with document size .",
    "it is also found that zipf s law and heaps law holds for different languages with different characterization exponents which means more complicated statistical features [ 22 - 27 ] .",
    "moreover , similar results have been recently reported for the corpus of web texts , including collaborative tagging , social annotation , internet search result and computer programs[28 - 32 ] , which indicates universality of zipf s law and heaps law beyond natural language systems .    in this paper , we focus on the word frequency in spoken language . using the speech transcriptions from the speech british national corpus on daily conversations of various subjects and ten classic books for comparison , we show ( i ) the word frequency distribution vs. ranking obeys the zipf s law and growing of distinct words obeys heaps law ; ( ii ) the coefficients of zipf s and heaps laws have significant differences between written texts and speech transcriptions ; and ( iii ) on the basis of the above study",
    ", a generalized model is proposed to simulate the growing dynamics and construction mechanism of spoken and written languages and the difference between speech and written texts .",
    "empirical observations and model simulations agree well with each other .",
    "* experiments . * two classes of data sets were analyzed in this article : ( i ) ten speech transcriptions of the speech british national corpus [ 33 ] from phonetics laboratory , and ( ii ) ten classic books written by different authors in different era .",
    "the transcriptions of daily conversation from bnc database are selected to have comparable length as the books .",
    "as shown in table 1 , the total lengths of the text are 27341 to 268843 for books , and 25281 to 124802 for speeches .",
    "there are relatively less distinct words being used in speeches , ranging from 2158 to 5815 in the selected data sets , and from 2572 to 29020 in books ( see details about data in methods ) .",
    "firstly , we analyzed the probability distribution of word frequency .",
    "we analyzed each book and speech transcription .",
    "the probability distribution of word frequency can be described as a power - law between the word frequency @xmath0 and its probability density @xmath1 ,    @xmath2    where @xmath3 is the power - law scaling exponent .",
    "1 shows the probability distribution of word frequency @xmath1 of two sets of data , the result of book is in fig .",
    "1(a ) and speech is in fig .",
    "1(b ) , which both follow power - law .",
    "the goodness of fit is 0.9952 and 0.9944 respectively , and fitting region is @xmath4 ( see details of the goodness of fit in methods ) .",
    "all the validation results are listed in table s1 .",
    "we found significant difference of scaling exponents between books and speeches ( book : @xmath5 , speech : @xmath6 , @xmath7 ) .     vs. word frequency @xmath0 in log - log scale for ( a ) books and ( b ) speech transcriptions .",
    "the fitting regions are @xmath4.,title=\"fig : \" ]   vs. word frequency @xmath0 in log - log scale for ( a ) books and ( b ) speech transcriptions .",
    "the fitting regions are @xmath4.,title=\"fig : \" ]    zipf found a power - law relation between the work frequency @xmath8 , and its corresponding rank @xmath9 , as    @xmath10    fig .",
    "2(a ) presents the plot of word frequency distribution @xmath8 for one book and one speech transcription .",
    "the word frequency distributions can be divided into two parts , in the first part , which is corresponding to the high frequency words , the relative word frequency @xmath8 of books is less than that of speech . in the second part ,",
    "which is corresponding to the low frequency words , the @xmath8 of books is larger than that of speech .",
    "the decay of the second part for speech and book both follow power - law with the goodness of fit 0.9985 and 0.9992 respectively and we found significant difference in the decay exponents @xmath11 between books and speeches ( book : @xmath12 , speech : @xmath13 , @xmath14 , see table s1 ) .     of one book and one speech transcription , with a fitting region @xmath15 .",
    "( b ) comparison of the growth of the number of distinct words @xmath16 versus the text length @xmath17 between one book and one speech transcription , fitting region @xmath18.,title=\"fig : \" ]   of one book and one speech transcription , with a fitting region @xmath15 .",
    "( b ) comparison of the growth of the number of distinct words @xmath16 versus the text length @xmath17 between one book and one speech transcription , fitting region @xmath18.,title=\"fig : \" ]    fig .",
    "2(b ) reports the growth of the number of distinct words n(t ) versus the text length t. both books and speeches follow heaps law    @xmath19    and can also be divided into two parts . in the first part ,",
    "@xmath16 of the speeches is very close to that of the books , corresponding to the linear increasing region . in the second part , the sub - linear increasing region",
    ", we can see that @xmath16 of the books is bigger than those of the speeches , which indicates that the growth speed of new words in speech is lower than in book .",
    "we calculated the slope @xmath20 of the second part of @xmath21 curve of ten books and ten speech transcriptions as a linear approximate fitting in log - log scale , and the slope values of each subject were listed in table 1 .",
    "the @xmath17-test shows there is a significant difference between the slope of books and speeches ( book : @xmath22 , speech : @xmath23 , @xmath14 ) , which both follow power - law with the goodness of fit is 0.9988 and 0.9980 respectively , and fitting region is @xmath24 .",
    ".the basic statistics of the ten speech transcriptions and the ten books .",
    "@xmath25 is the total length of the text measured in number of words , and @xmath26 is the total number of distinct words .",
    "the slope of @xmath21 of the ten speech transcriptions and the ten books ( local linear approximate fitting in log - log scale , fitting region @xmath18 ) [ cols=\"^,^,^,^,^,^,^,^ \" , ]     fig .",
    "3 are the summary of mean and standard deviation of the scaling exponents @xmath3 , @xmath11 and @xmath20 of books and speeches .        * model .",
    "* we test whether the rich - get - richer mechanism , also named preference attachment mechanism [ 34 - 37 ] works for spoken language generating process .",
    "we denote @xmath27 the average probability that a character appeared @xmath0 times will appear again ( see methods how to measure @xmath27 ) . as shown in fig .",
    "4 , @xmath27 for all the books and speeches increase proportionally with @xmath0 , indicating a rich - get - richer effect like the preferential attachment in evolving scale - free networks .     versus @xmath0 in a log - log scale for the representative ( a ) book and ( b ) speech , and the goodness of fit are 0.9477 and 0.9575 respectively.,title=\"fig : \" ]   versus @xmath0 in a log - log scale for the representative ( a ) book and ( b ) speech , and the goodness of fit are 0.9477 and 0.9575 respectively.,title=\"fig : \" ]    we propose a generalized model to further simulate and investigate the empirical observations as an extensive yule - simon model [ 38 - 43 ] .",
    "the process of language construction can be modeled as follows . at every time step",
    ", a word will be appended to the text , either by generating a new word , or selecting one from the text that already generated .",
    "we propose that the growing dynamics revealed by heaps law can be defined as the probability @xmath28 of new word generation , which can gradually change with the text length .",
    "the fomula of the probability @xmath28 can be determined according to the specific application . in this investigation of language construction , we set it as :    @xmath29    while with probability @xmath30 , one word is copied from the text that already generated , where word will be chosen is determined by rich - get - richer mechanism .",
    "let @xmath31 be the number of appearance of @xmath32th word at time step @xmath17 , then at next step @xmath33 , the @xmath32th word will be selected with the probability    @xmath34    parameter @xmath35 provides a parameter to modulate the strength of preferential attachment . in this proposed model ,",
    "the probability @xmath28 of new word generation depends on text length @xmath17 , and decreases monotonously with text increasing , inspired by the empirical observation of @xmath21 . and",
    "the word will be reused according to the rich - by - richer rules , which gives the zipf s law .",
    "5 reports the simulation results for one book and one speech transcription using proposed model .",
    "all three scaling properties can be very well captured by the model .",
    "for all the ten books and ten speech transcriptions , the parameters are as follows : @xmath36 , book : @xmath37 , speech : @xmath38 , @xmath39 ; @xmath40 , book : @xmath41 , speech : @xmath42 , @xmath14 ; @xmath35 , book : @xmath43 , speech : @xmath44 , @xmath14 ( see table s2 and fig .",
    "s1 ) .    , @xmath45 and @xmath46 ; and for speech kbg @xmath47 , @xmath48 and @xmath49.,title=\"fig : \" ] , @xmath45 and @xmath46 ; and for speech kbg @xmath47 , @xmath48 and @xmath49.,title=\"fig : \" ] , @xmath45 and @xmath46 ; and for speech kbg @xmath47 , @xmath48 and @xmath49.,title=\"fig : \" ]    , @xmath45 and @xmath46 ; and for speech kbg @xmath47 , @xmath48 and @xmath49.,title=\"fig : \" ] , @xmath45 and @xmath46 ; and for speech kbg @xmath47 , @xmath48 and @xmath49.,title=\"fig : \" ] , @xmath45 and @xmath46 ; and for speech kbg @xmath47 , @xmath48 and @xmath49.,title=\"fig : \" ]",
    "previous statistical analyses about human languages mostly concentrated on written texts where language consists of a huge number of words .",
    "in contrast , speech languages consisting of fewer words received less attention .",
    "the empirical results of the comparison between books and conversations indicate that i ) the speech transcriptions also obey zip s law and heaps law , but with different exponents compared with books .",
    "ii ) when the content length of speech grows , the emergence of new words does not increase as much as in books , the heaps law is also deviated from linear behavior .",
    "iii ) in speech , the usage of words are much more concentrated on some words , which leads to the larger probability of high frequency rank words than in books .",
    "we can further explain the possible reasons .",
    "i ) book authors could create new words according to his own written style .",
    "new words may result from new techniques , new biological species , or new names .",
    "however , generally we seldom give birth to a new word during speech .",
    "ii ) book novel needs personalized language to express the characteristics of different persons in the story .",
    "using complex grammatical long sentences to express the thoughts .",
    "changing the style of words expression with different scenarios .",
    "take hamlet as an example , claudius s speech is rich with rhetorical figures , as is hamlet s and , at times , opheliaswhile the language of horatio , the guards , and the grave diggers is simpler . while a great speech puts the occasion , the audience , and the speaker together in an unforgettable way .",
    "most estimated the number of words per minute around @xmath50 .",
    "so the speaker always choose a more simple way to use words .",
    "the currently reported regularities from the well - known zipf s and heaps laws point of view , can be reproduced by considering decrease of new words emergence with the length of generated text in a nonlinear process , which can be formulated according to the specific growing dynamics under study .",
    "in addition , the differences we observed in word frequency distribution and zipf s law between speech and books indicate different strength of preferential attachment , which is also considered in the presented model .",
    "simulation results confirm that the scaling properties of the complex dynamics of language construction and organization can be very well captured by the proposed model , and the differences between spoken language and written language can also be accounted for by different parameter settings .",
    "we further hypothesize that the proposed model of construction and organization in complex system with preferential attachment mechanism can also be applied to other complex system in physical , biological and social areas .",
    "* data description * 10 books are analyzed in this article : no.1 , alice s adventures in wonderland , written by lewis carroll ; no.2 , the adventures of tom sawyer , written by mark twain ; no.3 , a christmas carol , written by charles dickens ; no.4 , david crockett , written by john s. c. abbott ; no.5 , an enquiry concerning human understanding , written by david hume ; no.6 , hamlet , written by william shakespeare ; no.7 , the hound of the baskervilles , written by sir arthur conan doyle ; no.8 , moby - dick : or , the whale , written by herman melville ; no.9 , the origin of species by means of natural selection , written by charles darwin ; no.10 , ulysses , written by james joyce .",
    "these books cover disparate topics and types and were accomplished in far different dates .",
    "the basic statistics of these books are presented in table 1 .",
    "this corpus of all the ten chinese books consisting of about 1,002,504 total words and 100,335 distinct words .",
    "the transcriptions of the speech british national corpus from phonetics laboratory are used in this article : the british national corpus ( bnc ) is a 100 million word collection of samples of written and speech language from a wide range of sources , designed to represent a wide cross - section of british english from the later part of the 20th century , both speech and written .",
    "the speech part consists of orthographic transcriptions of unscripted informal conversations ( recorded by volunteers selected from different age , region and social classes in a demographically balanced way ) and speech language collected in different contexts , ranging from formal business or government meetings to radio shows and phone - ins .",
    "we selected 10 transcriptions of daily conversation from bnc database which have comparable length as the books .",
    "this corpus of all the ten speech text consisting of about 747,454 total words and 43,468 distinct words .",
    "* goodness of linear fit statistics in log - log scale * the original data @xmath1 , @xmath8 and @xmath16 are calculated in linear intervals , in log - log scale a lot of data cluster at large scales ( see fig .",
    "s1 for the data clustering at large scales ) .",
    "if the fitting process is performed on the original data , the data points at large scales will dominant the cost function and the measure of goodness of fit , causing bias towards large scales when fitting data in log - log scale .",
    "thus , before the fitting process , we resample the original data to be equally distributed in log scale , as    @xmath51    where @xmath52 is the number of the original data , and b can be any real number that greater than 1 .",
    "then , we fit the resampled data in a least - squares sense in log - log scale , as to minimize the following cost function    @xmath53 ^ 2 , \\label{equ : fit2}\\ ] ]    and the statistic measures of the goodness of fit in log - log scale is defined following the definition of r - square as    @xmath54 ^ 2 } { \\sum_{i=1}^{n } [ \\log(y'(i))-\\mathrm{e}(\\log(y'(i)))]^2 } , \\label{equ : fit3}\\ ] ]    where e(@xmath55 ) denotes the calculation of mean value , and n is the number of the resampled data .",
    "* preferential attachment . * for each speech or book text , we divide it into two parts : part i contains a fraction @xmath56 of words appeared and part ii contains the remain fraction @xmath57 of words . for word @xmath32 in part",
    "ii , if @xmath32 appeared @xmath0 times in part i , we add one to @xmath27 whose initial value is zero .",
    "accordingly , @xmath27 is the number of words in part ii that appeared @xmath0 times in part i. dividing @xmath27 by the number of distinct words that appeared @xmath0 times in part i. in this paper , we show the results for @xmath58 .",
    "we thank the support from the fundamental research funds for the central universities of chinananjing university scholar exchange project , natural science foundation of china ( 61271082 , 61201029 ) , priority academic program development of jiangsu higher education institutions ( papd ) , and natural science foundation of jiangsu province ( bk2011759 ) .",
    "c.h.b conceived the research .",
    "r.k.l and q.l.m analysed the data , c.h.b and q.l.m designed and simulated the model .",
    "all authors wrote and revised the manuscript .",
    "the authors declare no competing financial interests .",
    "searls , d. b. the language of genes . _",
    "nature _ * 420 * , 211217 ( 2002 ) .",
    "gao , j. , hu , j. , mao , x. & perc , m. culturomics meets random fractal theory : insights into long - range correlations of social and natural phenomena over the past two centuries .",
    "_ j. r. soc .",
    "interface _ * 9 * , 19561964 ( 2012 ) .                                \\34 .",
    "clauset , a. & moore , c. accuracy and scaling phenomena in internet mapping .",
    "lett . _ * 94 * , 018701 ( 2005 ) .",
    "35 . jeong , h. , neda , z. & barabasi , a .-",
    "measuring preferential attachment for evolving networks .",
    "_ europhys .",
    "* 61 * , 567572 ( 2003 ) ."
  ],
  "abstract_text": [
    "<S> human language , as a typical complex system , its organization and evolution is an attractive topic for both physical and cultural researchers . in this paper , we present the first exhaustive analysis of the text organization of human speech . </S>",
    "<S> two important results are that : ( i ) the construction and organization of spoken language can be characterized as zipf s law and heaps law , as observed in written texts ; ( ii ) word frequency vs. rank distribution and the growth of distinct words with the increase of text length shows significant differences between book and speech . in speech word frequency distribution are more concentrated on higher frequency words , and the emergence of new words decreases much rapidly when the content length grows . based on these observations , </S>",
    "<S> a new generalized model is proposed to explain these complex dynamical behaviors and the differences between speech and book .    </S>",
    "<S> * keywords : * speech transcription , zipf s law , heaps law , preferential attachment , complex system </S>"
  ]
}