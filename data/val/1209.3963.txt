{
  "article_text": [
    "consider multiple hypotheses to be tested by individual tests using a procedure which corrects for multiplicity , such as the @xcite procedure or the @xcite correction .",
    "the procedure of @xcite has recently received much attention , resulting in various generalizations @xcite .",
    "standard procedures require knowledge of the ideal p - values of all tests .",
    "we consider the case where p - values are not known exactly and can only be computed by simulation . for example , this occurs for bootstrap or permutation tests .",
    "we will call such tests monte carlo tests .",
    "safe implementations of individual monte carlo tests and computation of their power have been proposed @xcite .",
    "recent studies involving monte carlo tests use a variety of data sources such as data from a genome data archive @xcite , brain activity data @xcite and microarray data @xcite . as an example , we consider microarray data of gene expressions for yeast chemostat cultivations @xcite in the present article .",
    "this article introduces ` mmctest ` , an algorithm to implement the multiplicity correction for multiple monte carlo tests .",
    "the algorithm gives , with pre - specified probability , the same classification ( rejected and non - rejected hypotheses ) as the classification based on the ideal p - values .",
    "for permutation tests , the ideal p - values can in principle be obtained by running through all permutations . for bootstrap tests ,",
    "the ideal p - value is the probability that a bootstrapped test statistic is at least as extreme as the observed test statistic .    the motivation for trying to achieve the same classification as the one obtained with the ideal p - values is mainly repeatability and objectivity of the results , which @xcite called _ first law of applied statistics _ : `` two individuals using the same statistical method on the same data should arrive at the same conclusion . ''",
    "our algorithm achieves this up to a guaranteed pre - specified error probability .",
    "another reason for comparing to the ideal p - values is that all the theoretical results of the multiple testing procedure based on the ideal p - values still hold ( again up to the guaranteed error probability ) .",
    "our proposed algorithm is sequential : it starts with all hypotheses being unclassified and then takes samples and classifies hypotheses until all but a certain number of hypotheses have been classified or until a certain effort is reached .",
    "the proposed algorithm can be stopped earlier while having the same guarantee on the probability of misclassifications . when stopped before",
    "all hypotheses have been classified , the algorithm returns three sets : the rejected , the non - rejected and the not yet classified hypotheses .",
    "a literature review detailing existing approaches used to classify multiple hypotheses without knowledge of the ideal p - values is presented in section [ section_literature ] .",
    "the basic ` mmctest ` algorithm is described in section [ section_algorithm ]",
    ". moreover , section [ section_algorithm ] states conditions which bound the probability of classification errors and which guarantee the convergence of the testing result of ` mmctest ` to the classification based on the ideal p - values .",
    "the multiple testing procedure of @xcite and the @xcite correction satisfy these conditions ( appendix [ appendix_properties ] ) .    in section [ section_empirical_comparison ]",
    ", we first present an application of ` mmctest ` motivated by real biological data , given by a microarray dataset of gene expressions for yeast chemostat cultivations @xcite .",
    "afterwards , we conduct simulation studies motivated by this real data to compare the performance of a naive approach and of ` mcfdr ` to ` mmctest ` . furthermore , we investigate the dependance of ` mmctest ` on certain parameters .",
    "we conclude with a discussion in section [ section_discussion ] .",
    "all proofs can be found in the appendix .",
    "the ` mmctest ` algorithm is implemented in an r - package ( ` simctest ` , available on cran , the comprehensive r archive network ) .",
    "the supporting information includes an evaluation of a second dataset and further simulation studies with different testing thresholds .",
    "several algorithms in the literature are related to our approach in that they aim to stop drawing samples for certain hypotheses .",
    "some of them aim to give guarantees on their result , but these guarantees are usually much weaker than our guarantee .",
    "superficially , our algorithm is close to the algorithm proposed by @xcite .",
    "both algorithms maintain confidence intervals for the p - values corresponding to each hypothesis , and stop generating samples for hypotheses for which a decision can be reached . for this",
    "both algorithms rely on the monotonicity property of the @xcite procedure @xcite .    however , there are crucial differences .",
    "these mainly come from the different aim of the algorithms : @xcite aim to reduce the effort compared to the naive approach with a fixed number of samples per hypothesis .",
    "we aim to give the same classification as the classification using the ideal p - values . as a consequence",
    ", their algorithm imposes an upper bound on the number of samples generated per hypothesis , whereas our algorithm is open - ended .",
    "their algorithm does not aim to ensure repeatability , whereas we aim to do so . to be able to do this",
    "we judiciously control the joint coverage probability of the intervals .    to be specific , the main results in ( * ?",
    "* proposition 1 , theorem 1 ) are related to lemma [ lemma_monotonicity_sets ] in the present article , with the difference that @xcite compare the classification to the naive approach with a fixed number of samples , whereas we compare the classification to the one based on the ideal p - values .",
    "furthermore , the article of @xcite has no equivalence to our theorem [ theorem_convergence ] in which we prove that the classification returned by our algorithm converges to the one based on the ideal p - values .",
    "@xcite present an early stopping procedure with a bound on its computational savings . as @xcite , @xcite aim at designing a procedure which gives the same result as the naive approach with a fixed number of samples .",
    "moreover , the authors show that their procedure only controls the false discovery rate ( fdr ) @xcite up to an error term .",
    "the ad - hoc method of @xcite stops generating samples for hypotheses for which a lower confidence level exceeds a pre - specified threshold ( leading to a non - rejection ) . no early stopping for rejections is proposed .",
    "being an ad - hoc method for a specific application , no explicit theoretical results are given .",
    "the algorithm ` mcfdr ` of @xcite is a modification of the algorithm of @xcite , which , for a single hypothesis , stops drawing further samples when a fixed number of exceedances has been observed .",
    "the main idea of ` mcfdr ` is to use the criterion of @xcite to obtain quick non - rejections and to stop the entire algorithm once all remaining hypotheses are rejected based on their current estimated p - values . although ` mcfdr ` gives quick results , the algorithm does not give any guarantees on how its result relates to the result obtained with the ideal p - values .",
    "in contrast to the above approaches , the focus of our algorithm lies on the computation of the same classification as the one obtained if the ideal p - value of each test had been available .",
    "there are other related methods which are not necessarily designed to apply the @xcite procedure or the @xcite correction : the method proposed by @xcite uses ordinary permutation p - values if sufficiently many exceedances can be observed ; otherwise , the authors approximate the p - values using a fitted extreme value distribution .",
    "the aim is to efficiently compute an estimate of all p - values , without giving any theoretical guarantees .",
    "several specialized resampling - based testing procedures for various sampling methods and various statistics can be found in @xcite .",
    "all above methods do not try to take the ( unknown ) dependance between the test statistics into account .",
    "using permutation methods this can be attempted @xcite .",
    "consider testing @xmath0 null hypotheses @xmath1 having corresponding test statistics @xmath2 and observed values @xmath3 .",
    "a large value of @xmath4 shall indicate evidence against @xmath5 . moreover , let @xmath6 denote the ideal p - value corresponding to the hypothesis @xmath5 .",
    "we assume that @xmath7 are not available analytically , but have to be obtained through simulations .",
    "we assume that for every hypothesis @xmath5 , where @xmath8 , we can obtain independent samples from the test statistic @xmath9 under the null hypothesis .",
    "we will denote these by @xmath10 , and the corresponding exceedance indicators will be denoted by @xmath11 , @xmath12 , where @xmath13 is the indicator function . in the case of a permutation test ,",
    "computing @xmath10 involves generating permutations without replacement .",
    "suppose that @xmath14^m \\rightarrow \\mathcal{p}(\\ { 1,\\ldots , m \\})$ ] takes a vector of p - values and returns the set of indices of hypotheses to be rejected , where @xmath15 denotes the power set .",
    "we will call any such function a _",
    "multiple testing procedure_. ultimately , we are interested in obtaining @xmath16 , which we refer to as the ideal set of rejections .",
    "following @xcite , we call a multiple testing procedure @xmath17 _ monotonic _ if @xmath18 @xmath19 , where @xmath20^m$ ] , i.e.  if lower p - values lead to more rejections .",
    "the following generic algorithm is designed for monotonic multiple testing procedures .",
    "it iteratively controls the set of hypotheses for which further samples need to be drawn by refining confidence intervals for every @xmath6 through monte carlo sampling . at iteration @xmath21 , the confidence interval for the p - value @xmath6",
    "is denoted by @xmath22 .",
    "the upper confidence limit of a confidence interval @xmath22 is denoted by @xmath23 and the lower confidence limit is denoted by @xmath24 .",
    "the following variables and functions control the behavior of the algorithm .",
    "the variable @xmath25 controls how many additional samples are drawn in each iteration .",
    "it is increased geometrically by a constant @xmath26 in each step of the algorithm , starting at @xmath27 . in the examples of this article we use @xmath28 and @xmath29 .",
    "two vectors @xmath30 keep track of counts .",
    "the function @xmath31 computes a confidence interval for the ideal p - value of a hypothesis based on the number of exceedances @xmath32 and the number of samples @xmath33 drawn for this hypothesis .",
    "the dependance on the current value of @xmath25 is needed to be able to guarantee a joint coverage probability of all confidence intervals produced in the algorithm . for simplicity",
    ", we will assume that @xmath34 returns closed confidence intervals .",
    "in appendix [ appendix_clopper_pearson ] we give an example for such an @xmath34 which computes @xcite confidence intervals and uses a spending sequence to guarantee an overall coverage probability .",
    "the algorithm runs until at most @xmath35 hypotheses are classified or until the total number of samples drawn reaches a pre - specified limit @xmath36 .",
    "the following pseudo - code uses @xmath37 and @xmath38 , thereby computing a classification of all hypotheses .    in the remainder of this article",
    ", @xmath39 denotes the number of elements in a finite set and the length of an interval .",
    "moreover , @xmath40 denotes the euclidean norm of a vector .",
    "[ algorithm_basic ] @xmath41}$ ]    * @xmath42 , @xmath43 , @xmath44 , @xmath45 . *",
    "@xmath46 $ ] , @xmath47 @xmath48 . * while @xmath49 * * @xmath50 .",
    "* * @xmath51 . * * for all @xmath52 : * * * @xmath53 . * * * @xmath54 . * * * @xmath55 . * * for all @xmath56 : @xmath57 . * * set @xmath58 , @xmath59 . *",
    "return @xmath60 .",
    "the algorithm works as follows : the number of additional samples @xmath25 drawn in every step is increased geometrically .",
    "the total number of samples drawn up to iteration @xmath21 for a hypothesis @xmath61 is stored in @xmath62 and the total number of observed exceedances is stored in @xmath63 . for all hypotheses which are still under consideration , i.e.  those in @xmath64 , an additional batch of @xmath25 samples",
    "is drawn and new confidence intervals are computed .",
    "the confidence intervals remain unchanged for the other hypotheses .",
    "new classifications are then computed based on the updated upper and lower confidence limits .",
    "the confidence intervals @xmath22 computed in algorithm [ algorithm_basic ] are nested by construction .",
    "hypotheses using the benjamini - hochberg procedure @xmath17 : after the second iteration ( left ) , after a few additional iterations ( center ) and after the last iteration ( right ) .",
    "bold confidence intervals denote elements of @xmath65 in the upper row and elements of @xmath66 in the lower row .",
    "the lower ( upper ) confidence limits used to compute @xmath65 ( @xmath66 ) are marked with a cross . ]    [ example_visualization ] an example run of ` mmctest ` ( with @xmath67 hypotheses and @xmath37 ) is shown in figure [ figure_visualisation ] .",
    "we use the @xcite fdr controlling procedure ( see appendix [ appendix_benjamini_hochberg ] ) with threshold @xmath68 as the multiple testing function @xmath17 . the function @xmath34 given in appendix [ appendix_clopper_pearson ]",
    "is used to compute confidence intervals .",
    "columns show different iterations , the upper row shows the computation of @xmath65 , the lower row shows the computation of @xmath66 .",
    "the indices contained in @xmath65 and @xmath66 are visualized with bold confidence intervals .",
    "additionally , the lower ( upper ) confidence limits used to compute @xmath65 ( @xmath66 ) are marked with a cross .",
    "only the lower ( upper ) end of the confidence interval matters for the computation of @xmath65 ( @xmath66 ) , thus the hypotheses are ordered by their lower ( upper ) confidence limit in the upper ( lower ) row . in this example",
    "this turns out to be the same ordering .",
    "after the second iteration ( left column ) , ` mmctest ` has already classified the last hypothesis as being non - rejected as the lower confidence limit of its p - value lies above the line connecting the points @xmath69 and @xmath70 which we call the benjamini - hochberg line .",
    "all other hypotheses are still undecided and thus their confidence intervals will be refined . after a few additional iterations ( middle column )",
    ", the seven smallest values can be classified as rejected as the upper confidence limit of the seventh value is below the line .",
    "likewise , the confidence interval of the ninth value has now been shrunk to be entirely above the line which classifies this value as non - rejected .",
    "the eighth p - value is still unclassified as its confidence interval overlaps with the line .",
    "after refining the confidence interval further , the algorithm stops in the situation depicted in the right column with a complete classification ( @xmath71 ) .",
    "the monotonicity of @xmath17 implies immediately that the sequence of sets @xmath66 is increasing , that the sequence of sets @xmath65 is decreasing and , on an additional assumption , that each @xmath66 ( @xmath65 ) is a subset ( superset ) of the ideal set of rejections @xmath16 .",
    "[ lemma_monotonicity_sets ] assume that @xmath17 is monotonic .",
    "1 .   @xmath72 and @xmath73 .",
    "2 .   if @xmath74 @xmath75 , then @xmath76 @xmath77 .      in this section",
    "we show that under certain conditions the classification of ` mmctest ` is correct with high probability , meaning that all classifications are identical to the classifications based on the ideal p - values .",
    "furthermore , we show that all hypotheses will be classified .",
    "the first condition pertains to the multiple testing procedure @xmath17 . besides asking for monotonicity",
    ", it ensures that lowering the p - value of a rejected hypothesis or increasing the p - value of a non - rejected hypothesis does not change the result of @xmath17 .",
    "[ condition_invariance ]    1 .",
    "@xmath17 is monotonic .",
    "2 .   let @xmath78^m$ ] . if @xmath79 @xmath80 and @xmath81 @xmath82 , then @xmath83 .",
    "the second condition requires the function @xmath34 to produce confidence intervals whose length goes uniformly to 0 as more samples are drawn .",
    "[ condition_intervals ] @xmath84 converges uniformly to @xmath85 as @xmath86 , i.e.@xmath87 @xmath88 such that @xmath89 , @xmath90 and @xmath91 , we have @xmath92 .",
    "the main theorem guaranteeing convergence is as follows :    [ theorem_convergence ] suppose conditions [ condition_invariance ] and [ condition_intervals ] hold and suppose that there exists @xmath93 such that @xmath94^m$ ] and @xmath95 imply @xmath96",
    ". then , on the event @xmath97 , both sequences @xmath98 and @xmath99 converge to @xmath16 , i.e.  there exists @xmath100 such that @xmath101 @xmath102 .",
    "the condition on @xmath103 in theorem [ theorem_convergence ] ensures that @xmath103 has a neighborhood on which @xmath17 is constant .    the fdr controlling procedure of @xcite ( see appendix [ appendix_benjamini_hochberg ] ) and the @xcite correction ( see appendix [ appendix_bonferroni_correction ] ) both satisfy condition [ condition_invariance ] ( see corollary [ corollary_benjamini_hochberg ] and corollary [ corollary_bonferroni ] in appendix [ appendix_properties ] ) and the condition on @xmath103 in theorem [ theorem_convergence ] ( see lemma [ lemma_invariance_delta ] and lemma [ lemma_bonferroni_invariance_delta ] in appendix [ appendix_properties ] ) for almost all @xmath103 .",
    "the following third condition ensures that the confidence intervals computed by the function @xmath34 in algorithm [ algorithm_basic ] have a guaranteed joint coverage probability . the choice of @xmath34 given in appendix [ appendix_clopper_pearson ] satisfies condition [ condition_intervals ] and condition [ condition_probability ] ( see lemma [ lemma_clopper_pearson_satisfy_condition ] in appendix [ appendix_clopper_pearson ] ) .",
    "[ condition_probability ] for a given @xmath104 , the function @xmath34 computes confidence intervals @xmath22 in such a way that @xmath105 .    the main theorem and condition [ condition_probability ] together",
    "immediately give a bound on the probability of misclassifications .",
    "[ corollary_convergence ] under the conditions of theorem [ theorem_convergence ] and under condition [ condition_probability ] , @xmath106 i.e.  the probability that all classifications are correct is at least @xmath107 .",
    "the first aim of this section is to demonstrate that ` mmctest ` can be used to classify thousands of hypotheses commonly encountered in real data studies ( section [ subsection_real_application ] ) .",
    "moreover , this section shows that when matching the effort , ` mmctest ` computes classifications containing a number of unclassified hypotheses which is comparable to the number of misclassifications incurred by current approaches like the naive method or the ` mcfdr ` algorithm  even though ` mmctest ` is able to guarantee the correctness of all its classified hypotheses while for the two other methods , misclassified hypotheses typically remain unidentified in the testing result ( section [ subsection_comparison_naive ] and section [ subsection_comparison_mcfdr ] ) .",
    "an ad - hoc variant of ` mmctest ` computing a complete classification yields less misclassifications and random classifications than the other methods , demonstrating that ` mmctest ` is the superior method for practical applications .",
    "the aim of the last two sections is to empirically investigate the dependance of ` mmctest ` on certain parameters .",
    "section [ subsection_effort_dependence_number_hypotheses ] studies the dependance of the computational effort of ` mmctest ` on the number of hypotheses @xmath0 .",
    "we conclude by empirically assessing the runtime of ` mmctest ` in section [ subsection_effort_dependence_unclassified_hypotheses ] , demonstrating that whilst a complete classification can be computationally very expensive , most hypotheses can be classified with a reasonable effort .",
    "the following parameters were used throughout section [ section_empirical_comparison ] .",
    "the batch size @xmath25 in algorithm [ algorithm_basic ] is increased by @xmath28 in every iteration , starting with @xmath29 .",
    "confidence intervals are computed using the function @xmath34 with @xcite confidence intervals and parameters @xmath108 and @xmath109 ( see appendix [ appendix_clopper_pearson ] ) . the benjamini - hochberg procedure ( at threshold @xmath110 )",
    "as defined in appendix [ appendix_benjamini_hochberg ] always serves as multiple testing procedure .",
    "we use a yeast chemostat cultivation dataset of @xcite .",
    "this dataset consists of @xmath112 microarrays of yeast cultivations .",
    "the first @xmath113 microarrays correspond to yeast which was grown aerobically , the second @xmath114 microarrays correspond to yeast which was grown anaerobically .",
    "every microarray reacts to @xmath115 genes , thus giving rise to @xmath115 null hypotheses ( no effect of the gene onto the response ) .    to speed up the computation of the simulation studies in this and the following sections as well as to have an underlying `` truth '' for the @xcite dataset",
    ", we estimated each of the @xmath116 p - values once by generating @xmath117 permutations per hypothesis as outlined in the supporting information .",
    "such a number of permutations is far more than what would commonly be used in practice .",
    "we then define these approximated p - values to be the ideal p - values @xmath118 we are interested in , although they do not necessarily have to be equal to the p - values underlying each hypothesis .",
    "a plot of the ideal p - values @xmath118 is given in the supporting information .",
    "in the following sections , we draw bernoulli samples with success probabilities @xmath118 instead of generating actual permutations . the classification obtained by applying the benjamini - hochberg procedure directly to the ideal p - values @xmath118 is used to compute misclassifications .    the supporting information contains similar simulations as the ones which are about to follow for two additional testing thresholds @xmath119 ( 1% and 5% ) .",
    "the behavior of ` mmctest ` is qualitatively similar .",
    "furthermore , the supporting information contains another comparison of ` mmctest ` to the naive method and to ` mcfdr ` on a simulated dataset with a larger proportion of true null hypotheses than the one of the dataset of @xcite , broadly confirming the qualitative results of sections [ subsection_comparison_naive ] and [ subsection_comparison_mcfdr ] .        after having drawn @xmath120 samples all but @xmath121 hypotheses are classified .",
    "this corresponds to only around @xmath122 samples per hypothesis , thus making a classification with such a precision fairly easy to compute . drawing roughly the same number of samples again ( a total number of @xmath123 samples )",
    "classifies all but @xmath124 hypotheses .    `",
    "mmctest ` can be stopped whenever the user s desired number of classifications is achieved . all but @xmath125 hypotheses are classified after @xmath126 samples and all but @xmath127 hypotheses after @xmath128 samples .",
    "a classification of all but @xmath129 hypotheses is obtained after having drawn a total number of @xmath130 samples .",
    "this is , of course , extremely computationally intensive .",
    "the total number of samples drawn for a classification of all but @xmath129 hypotheses corresponds to roughly @xmath131 samples per hypothesis .",
    "a comparison to the classification result obtained by applying the @xcite procedure to the ideal p - values shows that in all the classifications previously reported , none of the decided hypotheses was wrongly classified .                  by theorem [ theorem_convergence ]",
    "we have @xmath155 , @xmath156 as @xmath157 conditional on @xmath97 . under condition",
    "[ condition_probability ] , this event occurs with probability @xmath105 , hence @xmath158 .",
    "finner , h. , gontscharuk , v. & dickhaus , t. ( 2012 ) . false discovery rate control of step - up - down tests with special emphasis on the asymptotically optimal rejection curve .",
    "j. stat . _",
    "* 39 * , 382397 .",
    "knijnenburg , t. , daran , j .-",
    ", van  den broek , m. , daran - lapujade , p. , de  winde , j. , pronk , j. , reinders , m. & wessels , l. ( 2009 ) .",
    "combinatorial effects of environmental parameters on transcriptional regulation in saccharomyces cerevisiae : a quantitative analysis of a compendium of chemostat - based transcriptome data . _",
    "bmc genomics _ * 10*.          nusinow , d. , kiezun , a. , oconnell , d. , chick , j. , yue , y. , maas , r. , gygi , s. & sunyaev , s. ( 2012 ) .",
    "network - based inference from complex proteomic mixtures using snipe .",
    "_ bioinformatics _ * 28 * , 31153122 ."
  ],
  "abstract_text": [
    "<S> consider testing multiple hypotheses using tests that can only be evaluated by simulation , such as permutation tests or bootstrap tests . </S>",
    "<S> this article introduces ` mmctest ` , a sequential algorithm which gives , with arbitrarily high probability , the same classification as a specific multiple testing procedure applied to ideal p - values . </S>",
    "<S> the method can be used with a class of multiple testing procedures which includes the benjamini & hochberg false discovery rate ( fdr ) procedure and the bonferroni correction controlling the familywise error rate . </S>",
    "<S> one of the key features of the algorithm is that it stops sampling for all the hypotheses which can already be decided as being rejected or non - rejected . ` </S>",
    "<S> mmctest ` can be interrupted at any stage and then returns three sets of hypotheses : the rejected , the non - rejected and the undecided hypotheses . a simulation study motivated by actual biological data shows that ` mmctest ` is usable in practice and that , despite the additional guarantee , it can be computationally more efficient than other methods .    _ key words : _ benjamini hochberg , bonferroni correction , bootstrap , false discovery rate , multiple comparisons , resampling , sequential algorithm </S>"
  ]
}