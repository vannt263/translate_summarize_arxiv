{
  "article_text": [
    "noisy speech received by a single microphone is a widely - explored problem .",
    "a plethora of approaches can be found in the literature  @xcite . although many current devices are equipped with multiple microphones , there are still many applications for which only a single microphone is available .",
    "one such application involves systems .",
    "it is well - known that such systems are sensitive to mismatch between the train and test environments . enhancing the noisy speech signal prior to the application of the system ,",
    "might alleviate the performance degradation caused by the environment .",
    "nonstationary noise environments are usually more challenging , since the speech enhancement algorithm should adapt to the changing statistics of the additive noise .",
    "the celebrated and  @xcite are widely - used model - based algorithms .",
    "the estimator and in particular the noise estimator are specifically tailored to nonstationary noise environments  @xcite . however , fast changes in noise statistics often yields the _ musical noise _ phenomenon .",
    "recently , techniques gained a lot of popularity due to theoretical and algorithmic progress , and the availability of more data and more processing power . unlike past learning algorithms for nn , it is now possible to infer the parameters of the with many layers , and hence the name _",
    "deep learning_. deep learning methods were mainly applied to speech recognition and lately , for speech enhancement as well . and a were used as a nonlinear filters in  @xcite and  @xcite , respectively .",
    "the networks are trained on stereo ( noisy and clean ) audio features , to infer the complex mapping from noisy to clean speech . an experimental study with this approach",
    "is shown in  @xcite .",
    "the reduces the noise level significantly , yet , the enhanced signals still suffer from noticeable _ speech distortion_.    other methods attempt to train an to find a mask , which classifies the time - frequency bins into speech / noise classes . given the binary mask , the noisy bins are decreased . in  @xcite for instance ,",
    "a is used to estimate the for speech separation from non - speech background interference .",
    "an is trained to find the input features for the .",
    "a simpler approach is to train the itself to find the .",
    "different targets for the are presented in  @xcite .",
    "the has shown advantageous in terms of intelligibility  @xcite . yet",
    ", the binary mask is known to introduce artifacts such as _ musical noises_. for intelligibility tasks , this might not be problematic , though for speech enhancement the is not sufficient . to circumvent this phenomenon , in  @xcite",
    "the is trained to find the , which is a soft mask .",
    "a comparison between the and the is presented in  @xcite . the soft mask is better than the binary mask in terms of speech quality .",
    "these approaches do not use models nor assumptions for their speech enhancement .",
    "however , they are trained with specific noise types , resulting in poor enhancement in an untrained noise environment . to cope with this problem , in  @xcite",
    "the was trained with more than 100 different types of noise .",
    "nevertheless , in real - life where the number of noise types are not limited , this approach may not be satisfactory .",
    "training - based algorithms , such as mixmax  @xcite , were also developed .",
    "these algorithms are performed in two phases , the training phase and the test phase . in the training",
    "phase the parameters of the model are found , usually with an unsupervised machine learning algorithms , such as the algorithm in  @xcite . in the test phase ,",
    "the enhancement is carried out using the learned model parameters .",
    "one weakness of the algorithm is that the speech parameters are found in an unsupervised manner that ignores the phoneme - based structure of speech .",
    "another drawback of the mixmax algorithm is that the noise parameters are estimated once at the beginning of the utterance and then are kept fixed during the entire utterance .",
    "this enhancement approach is not always sufficient for real - life noises .    in this paper , we apply a hybrid algorithm , which integrates the generative model - based approach with the discriminative tool . as in  @xcite , we use a two phase algorithm . in the training phase",
    ", the clean speech is modeled with a phoneme - based that is built using phoneme labeled database .",
    "a is then trained to classify clean time - frame features as one of the phonemes from the phoneme - based .",
    "once the training phase is over , the training does not recur .",
    "with the estimated phonemes , an is calculated in the test phase using the generative model .",
    "soft spectral subtraction is then carried out using the spp , while , simultaneously , the noise estimation is updated .",
    "the continuity of the speech is maintained using the that uses context frames in addition to the current frame .",
    "in addition , the assists the calculation of the spp .",
    "furthermore , the phoneme - based and the soft preserve the spectral structure of the speech thus alleviating the musical noise phenomenon .",
    "this approach utilizes the benefits of both the generative and the discriminative methods to alleviate the drawbacks of the mentioned above algorithms .",
    "the rest of the paper is organized as follows . in section  [ sec :",
    "model ] , a generative model is presented .",
    "section  [ sec : algorithm ] presents the proposed enhancement algorithm and describes its implementation in details .",
    "a comprehensive experimental results using speech databases in various noise types are presented in section  [ sec : results ] . in section  [ sec : analysis ] the building blocks of the algorithm are analyzed .",
    "finally , some conclusions are drawn and the paper is summarized in section  [ sec : summer ] .",
    "in this section , a generative model of the noisy speech signal is presented .",
    "we follow the model proposed by ndas et al .  @xcite that was utilized in  @xcite .",
    "the following notation is used throughout the paper .",
    "uppercase letters are used for random variables , lower case for a given value and a boldface symbols denotes vectors .",
    "let @xmath0 and @xmath1 denote the speech and noise signals , respectively .",
    "the observed noisy signal @xmath2 is given by @xmath3 applying the with frame length set to @xmath4 samples and overlap between successive frames set to @xmath5 samples to @xmath2 yields @xmath6 with @xmath7 the frame index and @xmath8 the frequency index .",
    "the frame index @xmath7 is henceforth omitted for brevity , whenever applicable .",
    "let @xmath9 denote the @xmath10 dimensional log - spectral vector , defined by @xmath11 note that the other frequency bins can be obtained by the symmetry of the .",
    "similarly , we define @xmath12 and @xmath13 to be the log - spectral vectors of the speech and noise signals , respectively .",
    "it is assumed that the noise is statistically independent of the speech signal .",
    "furthermore , it is assumed that both the speech and noise are zero - mean stochastic processes . due to these assumptions",
    "the following approximation can be justified : @xmath14 hence @xmath15    following ndas et al .",
    "@xcite , the noisy log - spectral can be further approximated : @xmath16 where the maximization is component - wise over the elements of @xmath12 and @xmath13 .",
    "this approximation was found useful for speech recognition  @xcite , speech enhancement  @xcite and speech separation tasks  @xcite . in a speech enhancement task ,",
    "only the noisy signal @xmath9 is observed , and the aim is to estimate the clean speech @xmath12 .",
    "it is well - known that a speech utterance can be described as a time - series of phonemes , i.e. speech is uttered by pronouncing a series of phonemes  @xcite . in our approach , we give this observation a probabilistic description , namely the log - spectral vector of the clean speech signal , @xmath12 , is modelled by a distribution , where each mixture component is associated with a specific phoneme .",
    "unlike  @xcite , that uses unsupervised clustering of the speech frames , we use here a supervised clustering , explicitly utilizing the labels of the phonemes of the training speech signals . based on the mog model ,",
    "the probability density function @xmath17 of the clean speech @xmath12 , can be written as @xmath18 where @xmath19 is the number of mixture components and @xmath20 let @xmath21 be the phoneme indicator associated with the @xmath12 , i.e. @xmath22 . the term @xmath23 is the gaussian of @xmath12 given that @xmath24 .",
    "the scalar @xmath25 is the probability of the @xmath26-th mixture and @xmath27 and @xmath28 are the mean and the standard deviation of the @xmath29-th entry of the @xmath26-th mixture gaussian , respectively . due to the fourier",
    "transform properties , we neglect any residual correlation between the frequency bins .",
    "since for each class @xmath24 the @xmath12 is gaussian , the frequency bins are also statistically independent .",
    "consequently , the covariance matrix of each mixture component is diagonal . to set the mog parameters we used the phoneme - labeled timit database  @xcite as described in sec .",
    "[ subsec : trainnn ] .",
    "let @xmath13 define the log - spectral vector of the noise signal , and let @xmath30 denote the of @xmath13 .",
    "as with the log - spectral vector of the speech signal , it is assumed that the components of @xmath13 are statistically independent . for simplicity ,",
    "@xmath30 is modeled as a single gaussian , with diagonal covariance i.e. , @xmath31 where @xmath32 initial estimation and adaptation the noise parameters will be explained in sec .",
    "[ subsec : noiseadapt ] .    using the maximum assumption in the log - spectral vector of the noisy speech @xmath33 ,",
    "as explained above , it can be verified  @xcite that the of @xmath9 is given by the following mixture model : @xmath34 where @xmath35 such that @xmath36 and @xmath37 are the cumulative distribution functions of the gaussian densities @xmath38 and @xmath39 , respectively .",
    "the term @xmath40 is the of @xmath9 given that @xmath24 .",
    "the generative modeling described above was nicknamed mixmax  @xcite , since it is based on the maximum assumption and on the modelling of the clean speech as a ( gaussian ) mixture and the noisy speech is modeled as the maximum of the clean speech and the noise signal .",
    "originally , the mixture components were not associated with phonemes , but rather learned in an unsupervised manner .",
    "in this section , we describe the proposed enhancement algorithm . in sec .",
    "[ subsec : mmse ] we remind the estimator based on the mixmax model  @xcite .",
    "we then propose in sec .",
    "[ subsec : soft ] a new variant of the estimator that utilizes the same model but allows for better noise reduction . in sec .",
    "[ subsec : nn ] an approach is introduced as a tool for accurate phoneme classification .",
    "issues regarding the training of the are discussed in sec .",
    "[ subsec : trainnn ] .",
    "finally , test - phase noise adaption is discussed in sec .",
    "[ subsec : noiseadapt ] .",
    "an of the clean speech @xmath41 from measurement @xmath42 is obtained by the conditional expectation @xmath43 .",
    "note , that since the of both @xmath41 and @xmath42 is non - gaussian , this estimator is not expected to be linear . utilizing the generative model described in the previous section we can obtain a closed - form solution for the mmse estimator as follows . @xmath44 the posterior probability @xmath45 can be easily obtained from   by applying the bayes rule : @xmath46 since the gaussian covariance matrices of both the speech and the noise models are diagonal , we can separately compute @xmath47 for each frequency bin . for the @xmath29-th frequency bin",
    "we obtain : @xmath48 such that @xmath49 and for the second term in  : @xmath50 the closed - form expression for the mmse estimator of the clean speech @xmath43  @xcite is obtained from  , , , .",
    "these expressions are the core of the mixmax speech enhancement algorithm proposed by burshtein and gannot  @xcite . in their approach",
    "the mog parameters of the clean speech are inferred from a database of speech utterances utilizing the in an unsupervised manner .      assuming the maximization model in   is valid , @xmath51 was obtained in  .",
    "summing over all the possible mixture components , we obtain : @xmath52 the term @xmath53 can be interpreted as the probability that given the noisy speech vector @xmath42 , the @xmath29-th frequency bin of the current log - spectral vector @xmath42 is originated from the clean speech and not from the noise .",
    "the probability @xmath53 can thus be viewed as a training - based detector , namely the probability that the designated time - frequency bin is dominated by speech .",
    "consequently , @xmath54 can be interpreted as the posterior probability that the @xmath29-th bin is dominated by noise .    using @xmath53 and  ,",
    "the @xmath29-th frequency bin of the mmse estimator @xmath43 can be recast as follows : @xmath55 hence , given the generative model , the enhancement procedure in  , substitutes the frequency bins identified as noise with the a priori value drawn from the model and using  .",
    "the structure of voiced speech consists of dominant spectral lines which recur at multiples of the fundamental frequency ( known as _ pitch _ ) .",
    "the of different speakers pronouncing the same phoneme share similar properties , but are never identical .",
    "hence , the parameters inferred from multiple speakers , is never individualized to the current speaker and therefore can not represent the specific periodicity .",
    "the phoneme - based parameters are only capable of preserving the general structure of an averaged phoneme .",
    "this phenomenon might lead to _ residual noise _ even when the algorithm identifies the noise correctly .    to circumvent this phenomenon",
    ", we propose to substitute the optimal estimator that uses the parameters with a simpler estimate based on the spectral substraction paradigm , namely : @xmath56 is substituted by : @xmath57 where @xmath58 is a noise reduction level .",
    "it is well - known that the basic spectral subtraction method is prone to _ musical noise _  @xcite@xcite . in our proposed method",
    ", the estimator also incorporates the soft mask deduced from the , thus potentially alleviating the musical noise phenomenon .    substituting @xmath59 in   we",
    "obtain the following simplified expression for the estimated clean speech : @xmath60 or , equivalently @xmath61 which can be interpreted as -driven ( soft ) spectral subtraction algorithm .",
    "the gist of our approach is the calculation of the @xmath53  .",
    "this calculation necessitates two terms , @xmath51 which is given by   and the posterior phoneme probability @xmath62 . utilizing the generative model defined in section  [ sec : model ] , @xmath63 is obtained from   by applying the bayes rule : @xmath64 this approach exhibits some major shortcomings . estimating the required noise statistics is a cumbersome task , especially in time - varying scenarios .",
    "furthermore , as the calculation in   is carried out independently for each frame , continuous and smooth speech output can not be guaranteed .    in our approach ,",
    "( unlike  @xcite ) we adopt a _ supervised _ learning approach in which each mixture component of the clean speech is associated with a specific phoneme .",
    "hence the computation of the mixture index posterior probability becomes a phoneme classification task ( based on the noisy speech ) . to implement this",
    "supervised classification task , we substitute   with an that is known to be significantly better than models for phoneme classification tasks ( see e.g.  @xcite ) . the is trained on a phoneme - labeled clean speech . for each log - spectral vector , @xmath42",
    ", we calculate the corresponding features ( and their respective delta and delta - delta features ) . to preserve the continuity of the speech signal",
    ", 9 mfcc vectors are concatenated ( the current feature vector , 4 past vectors and 4 future vectors ) to form the feature vector , denoted @xmath65 , which is a standard feature set for phoneme classification .",
    "this feature vector is used as the input to the , and the phoneme label as the corresponding target .",
    "the phoneme - classification is trained on clean signals . however , as part of the speech enhancement procedure , we apply it to noisy signals . to alleviate the mismatch problem between train and test conditions , we use a standard preprocessing stage for robust phoneme classification , namely  @xcite .",
    "the @xmath53 is calculated using  , which requires both @xmath51 and @xmath63 .",
    "while @xmath51 is calculated from the generative model using  , we propose to replace   for calculating @xmath63 by a better phoneme - classification method .",
    "it is therefore proposed , to infer the posterior phoneme probability by utilizing the _ discriminative _ , rather than resorting to the generative mog model : @xmath66 note , that the compound feature vector @xmath65 is used instead of the original log - spectrum @xmath42 .",
    "finally , the spp @xmath53 is obtained using   and  : @xmath67 the proposed calculation is based on a _ hybrid _ method , utilizing both the generative model and a discriminative approach to infer the posterior probability . for the latter we harness the known capabilities of the .",
    "we used the phoneme - labeled clean speech timit database  @xcite to train the phoneme classifier and the phoneme - based generative model .",
    "we next describe the training procedure .",
    "we used the 462 speaker from the training set of the database excluding all sa sentences , since they consist of identical sentences to all speakers in the database , and hence can bias the results .",
    "in training the phoneme - based we set the number of gaussians to @xmath68 ( see  @xcite ) , where each gaussian corresponds to one phoneme .",
    "all frames labeled by the @xmath26-th phoneme were grouped , and for each frequency bin the mean and variance were computed using   and  , respectively .",
    "first , the log - spectrum of the segments of clean speech utterances is calculated . since the database is labeled each segment",
    "is associated with a phoneme @xmath26 .",
    "we can then calculate the following first- and second - moment with phone label @xmath26 : @xmath69 where @xmath70 is @xmath29-th bin of the @xmath7-th log - spectra vector with phoneme label @xmath26 .",
    "the term , @xmath71 is the total number of vectors associated with phoneme labeled @xmath26 .",
    "the mixture coefficients @xmath25 are set to be the relative frequency of each phoneme in the training dataset : @xmath72 note that since the data is already labeled , no iterative clustering procedure , such as the algorithm , is required .    for training the as a discriminative phoneme classifier , we used the feature vectors @xmath65 powered by the delta and delta - delta coefficients . in total , @xmath73 coefficients per time frame were used .",
    "context frames ( 4 from the future and 4 from the past ) were added to the current frame as proposed in  @xcite .",
    "hence , each time frame was represented by 351 features .",
    "we used a single hidden layer comprising of 500 neurons .",
    "( although adding more hidden layers slightly improves phoneme classification rate , we did nt gain any significant improvement in the overall enhancement procedure . )",
    "the network is constructed of sigmoid units as the transfer function for the hidden layer : @xmath74 and a softmax output layer to obtain a vector @xmath19 probabilities associated with the various phonemes : @xmath75 where @xmath76 and @xmath77 are the weights matrices , of the hidden layer and the output layer , respectively .",
    "given a sequence of mfcc feature vectors @xmath78 , where @xmath79 is the total number of vectors in the training set , with the corresponding phoneme labels , @xmath80 , the is trained to maximize the log - likelihood function : @xmath81 to train the network we can start with random weights ( or use pre - training methods ( see  @xcite ) ) and then , by applying back - propagation algorithm as part of a gradient ascent procedure , the parameter sets of the network , @xmath76 and @xmath77 , are found . in our implementation",
    "we used matlab@xmath82 r2014b pattern recognition toolbox  @xcite to train the .",
    "the default training function , namely the _ scaled conjugate gradient back - propagation _",
    "@xcite was used . to avoid mismatch between train and test conditions each utterance was normalized , such that the utterance samples mean and the variance are zero and one , respectively .    to verify the accuracy of the classifier , the trained was applied to a clean test set ( 24-speaker core test set drawn from timit database ) , obtaining @xmath83 correct phoneme classification results , which is a reasonably high score .    during the test phase of the algorithm , the is applied to speech signals contaminated by additive noise",
    "we have therefore applied the procedure before the classifier to circumvent the noisy test condition  @xcite .      to estimate the noise parameters it is assumed that the first part of the utterance ( usually 0.25  sec ) the speech is inactive and it consists of noise - only segments .",
    "these first segments can therefore be used for initializing the parameters of the noise gaussian distribution as follows : @xmath84 where @xmath85 is the number of vectors constructed form the noise - only samples .",
    "the term @xmath86 denotes the @xmath29-th bin of the @xmath7-th noise vector .    in  @xcite ,",
    "the noise parameters remain fixed for the entire utterance , rendering this estimate incapable of processing non - stationary noise scenarios . to alleviate this problem",
    ", we will apply an adaptation procedure ( see  @xcite for alternative noise adaptation techniques ) . using the derived in",
    ", the following adaptation scheme for the noise model parameters can be stated : @xmath87 where @xmath88 and @xmath89 are the updated parameters and @xmath90 and @xmath91 are the parameters before adaption , and @xmath92 is a smoothing parameter .",
    "using this scheme , the noise statistics can be adapted during speech utterances , utilizing the frequency bins that are dominated by noise .",
    "this scheme is particularly useful in non - stationary noise scenarios . as a consequence ,",
    "the first few segments , assumed to be dominated by noise , are only used for initializing the noise statistics and their influence is fading out as more data is collected .    the proposed algorithm is summarized in algorithm  [ alg : nn ] .",
    "we dub the proposed algorithm to emphasize its hybrid nature , as a combination of the generative mixmax model and the phoneme - classification .    : * input * : log - spectral vectors @xmath93 , mfcc vectors @xmath94 , and their corresponding phoneme labels @xmath95 . :",
    "set the phoneme - based parameters using @xmath96 and  .",
    ": train a nn for phoneme classification using @xmath97 .",
    ": * input * : log - spectral vector of the noisy speech @xmath42 and a corresponding mfcc vector @xmath65 .",
    "* output * : estimated log - spectral vector of the clean speech @xmath98 .",
    "in this section we present a comparative experimental study .",
    "we first describe the experiment setup in sec .",
    "[ subsec : expsetup ] .",
    "objective quality measure results are then presented in sec .",
    "[ subsec : objectmeasurs ] . in sec .",
    "[ subsec : asr ] results are compared with different approaches .",
    "finally , the algorithm is tested with an untrained database in sec .",
    "[ subsec : notimit ] .      to test the proposed algorithm we have contaminated speech signal with several types of noise from noisex-92 database  @xcite , namely _ speech - like _ , _ babble _ , _ car _ , _ room _ , _ awgn _ and _",
    "factory_. the noise was added to the clean signal drawn from the test set of the timit database ( 24-speaker core test set ) , with 5 levels of at @xmath99  db , @xmath100  db , @xmath101  db , @xmath102  db and @xmath103  db in order to represent various real - life scenarios .",
    "the algorithm was tested similarly , with the untrained database @xcite .",
    "we compared the proposed algorithm to the algorithm  @xcite with noise estimator  @xcite , a state - of - the - art algorithm for single channel enhancement .",
    "the default parameters of the were set according to  @xcite .    in order to evaluate the performance of the speech enhancement algorithm ,",
    "several objective and subjective measures were used , namely the quality measure , which has a high correlation with subjective score  @xcite , and a composite measure  @xcite , weighting the , the and the  @xcite .",
    "the composite measure outputs , and results .    as an additional measure",
    "we have examined the performance improvement of an system .",
    "we used the pocketsphinx asr system  @xcite .",
    "the feature set of the system is composed of 39 mfcc features powered by delta and delta - delta features .",
    "the acoustic model consists of a hidden markov model with 5000 states .",
    "each state is represented by a with 16 mixture components .",
    "finally , the 20,000-word vocabulary language model was trained using corpus  @xcite . finally , we have carried out informal listening tests .",
    "we first evaluate the objective results of the proposed algorithm and compare it with the results obtained by the algorithm . to further examine the upper bound of the proposed method we also replaced the classifier with an ideal classifier that always provides the correct phoneme , denoted _",
    "ideal-_. the test set was the core set of the timit database .",
    "[ fig : known_phonemes ] depicts the results of all examined algorithm for the speech - like , room , factory and babble noise types as a function of the input . in fig .  [",
    "fig : covl ] we show the covl results for factory and room noises .",
    "the results behave in a similar way , with other noise types .",
    "it can be clearly deduced that the proposed algorithm outperform the algorithm in the two designated objective measures .",
    "the ideal- outperforms the , but the difference is rather marginal .",
    "still , there is a room for improvement , would a better phoneme classifier be available .    0.5     0.5      +    0.5     0.5     0.5     0.5     to gain further insight ,",
    "we have also compared the enhancement capabilities of the proposed algorithm and the state - of - the - art algorithm in the challenging factory noise environment .",
    "it is clearly depicted in fig .",
    "[ fig : factory_spectrum ] ( obtained in snr=5  db ) that the proposed is less prone to musical noise , while maintaining comparable noise level at the output",
    ".    0.5     0.5      +    0.5     0.5       speech enhancement algorithms can also serve as a preprocessing stage on front of systems . in order to test the performance of the enhancement algorithm we added four types of noise in four different levels to a database comprising five female and five male speakers ,",
    "each uttering approximately 150 english sentences .",
    "the utterances were taken from different speech databases ( samples from the were not included ) .",
    "overall , the test database consists of 1497 sentences , 24  sec long ( 28 words each ) .    as before",
    ", we have the proposed algorithm with the original mixmax and the algorithms .",
    "the results are depicted in table  [ table : asr ] .",
    "the algorithm significantly outperforms both competing algorithms for the factory and babble noise , and most the speech - like for most values ( besides 5  db ) . in the white noise case , the original mixmax exhibits slightly better performance .",
    "the superior results of the proposed algorithm can be attributed to the improved phoneme classification , which is one of the main building blocks of an system .     method \\ & 5[db ] & 10[db ] & 15[db ] & 20[db ] + noisy signal & 8.8 & 43.0 & 68.8 & 79.7 + mixmax & 18.7 & 53.7 & 72.9 & 81.0 + omlsa & 13.7 & 45.0 & 66.0 & 76.2 + nn - mm & * 28.2 * & * 60.3 * & * 76.2 * & * 81.9 * +     method \\ & 5[db ] & 10[db ] & 15[db ] & 20[db ] + noisy signal & 1.1 & 32.7 & 62.2 & 76.1 + mixmax & 9.5 & 44.4 & 68.3 & 78.7 + omlsa & 16.3 & 47.4 & 69.0 & 78.0 + nn - mm & * 19.5 * & * 52.9 * & * 71.9 * & * 80.1 * +    [ table : asr_factory ]     method \\ &",
    "5[db ] & 10[db ] & 15[db ] & 20[db ] + noisy signal & 7.9 & 44.4 & 68.4 & 77.5 + mixmax & 38.5 & 64.9 & 77.4 & 81.6 + omlsa & * 41.3 * & 65.4 & 75.8 & 81.3 + nn - mm & 40.4 & * 66.6 * & * 78.0 * & * 82.2",
    "* +    [ table : asr ]     method \\ & 5[db ] & 10[db ] & 15[db ] & 20[db ] + noisy signal & 10.4 & 31.8 & 53.6 & 68.9 + mixmax & * 28.9 * & * 51.7 * & * 67.2 * & * 77.1 * + omlsa & 25.8 & 46.1 & 65.1 & 74.5 + nn - mm & 26.1 & 45.8 & 65.5 & 75.8 +    [ table : asr_white ]      finally , we would like to demonstrate the capabilities of the proposed algorithm when applied to speech signals from other databases . in this work",
    "we have trained the phoneme - based and the using the timit database . in this section we apply the algorithm to @xmath104 clean signals drawn from the database  @xcite .",
    "the signals were contaminated by the challenging factory and babble noise with several levels .",
    "note , that the algorithm does not train with noisy signals .",
    "[ fig : no_timit ] depicts the measure of the algorithm in comparison with the algorithm .",
    "it is that the performance of proposed algorithm and its advantages are maintained even for sentences from different database than the training database . here",
    "we show the challenging factory and babble noise types .",
    "the results in other noise types have the same construction .    0.5     0.5",
    "in this section , we analyze the individual contributions of each component of the proposed algorithm to the overall performance .",
    "first , in sec .",
    "[ subsec : phonemog ] the phoneme - based is analyzed . in sec .",
    "[ subsec : spp ] example of the is presented and the phoneme classifier is compared to the generative approach in sec .",
    "[ subsec : classification ] . finally , in sec .",
    "[ subsec : noiseadaptresults ] the noise adaptation is tested in real - life scenario .",
    "[ sec : mog ] one of the major differences between the original mixmax algorithm and the proposed algorithm is the construction of the model . while the former uses unsupervised clustering procedure based on the algorithm , the latter uses supervised clustering using the labeled phonemes .",
    "consequently , the clusters in the proposed algorithm consists of different variants of the same phoneme , while the cluster obtained by the algorithm mixtures of various phonemes .",
    "we postulate that the supervised clustering is therefore advantageous over the unsupervised clustering .",
    "we will examine this claim in the current section , using clean speech signal contaminated by room noise with snr=5  db .",
    "first , define the averaged of the speech utterance as the weighted sum of the gaussian centroids , as inferred by the two clustering procedures .",
    "the weights give the respective posterior probabilities ( either   or  ) .",
    "the averaged obtained by the supervised clustering and the discriminative is given by : @xmath105 similarly , the averaged obtained by the unsupervised clustering and the generative model is given by @xmath106    in figs .",
    "[ fig : clean_room_5db ] and  [ fig : noisy_room_5db ] we show the clean and noisy , respectively . fig .",
    "[ fig : mus_em_room_5db ] and fig .",
    "[ fig : mus_nn_room_5db ] illustrates the estimated weighted gaussians @xmath107 and @xmath108 .",
    "it evident that @xmath108 is not as successful as successful as @xmath109 in estimating the clean speech .",
    "0.5     0.5     0.5     0.5     0.5     0.5     0.5     0.5       the is the probability that the time - frequency bin is dominated by speech . in this section",
    "we examine the @xmath110 developed in this work as given in algorithm  [ alg : nn ] . to further validate the advantages of the hybrid scheme we compare it with the used in the original mixmax ,",
    "namely the posterior probabilities are inferred from the generative model and the is trained in an unsupervised manner .",
    "the latter is denoted @xmath111    we continue the example in sec .  [",
    "sec : mog ] .",
    "both , @xmath111 and @xmath112 , are depicted in figs .",
    "[ fig : rho_mm_room_5db ] and  [ fig : rho_nn_room_5db ] , respectively .",
    "it can be easily observed that @xmath112 has a better resemblance to the clean speech spectrogram shown in fig .",
    "[ fig : clean_room_5db ] and suffers from less artifacts .",
    "additionally , it is smoother than the @xmath111 in both time and frequency aspects .",
    "conversely , vertical narrow spectral lines can be easily observed in @xmath111 .",
    "this spectral artifacts may be one of the causes for the differences in the enhancement capabilities of the two algorithms , as depicted in figs .",
    "[ fig : rho_mm_room_5db ] and  [ fig : rho_nn_room_5db ] .",
    "we postulate that the designated advantages of the proposed approach stem from the better classification capabilities as exhibited by the .",
    "while the original mixmax algorithm is only utilizing the current frame for inferring the posterior probabilities , the proposed algorithm takes into account the context of the phoneme by augmenting past and future frames to the current frame .",
    "this guarantees a smoother and consequently less artifacts at the output of the algorithm .    this context - aware feature vector together with",
    "the phoneme - based may also alleviate the musical noise phenomenon .",
    "this observation is also supported by the smoother spectral envelop of the centroid as can be deduced from comparing figs .",
    "[ fig : mus_em_room_5db ] and  [ fig : mus_nn_room_5db ] .",
    "we turn now to the assessment of the proposed phoneme classifier . for",
    "that we compare the classification accuracy of the with that of the generative model in   using the phoneme - labeled .",
    "[ fig : classification_results ] depicts the percentage of correct classification results obtained on the test data .",
    "two types of noise were added to the clean signals , namely factory and babble noise .",
    "the results clearly indicate that the based classifier significantly outperforms the classifier based on the generative model , and hence better suited for the task at hand .",
    "0.5     0.5     0.5     0.5      +    0.5     0.5      +    0.5     0.5       in this section we examine the noise adaptation scheme described in  .",
    "a _ city ambiance _ noise  @xcite that consists of a siren and passing cars was chosen , as it is a highly non - stationary noise source with fast changes during the speech utterance .",
    "the clean and noisy signals are depicted in figs .",
    "[ fig : clean_siren_stft ] and  [ fig : noisy_siren_stft ] .",
    "the input was set to 5  db ( resulting in input = 2.124 .    in fig .",
    "[ fig : real_mun ] the real noise is depicted and in fig .",
    "[ fig : est_mun ] its estimate using the proposed adaptation scheme and the inferred by the algorithm .",
    "it can be observed that the estimate is quite accurate even when the noise changes very fast",
    ". note that during speech dominant time - frequency bins , the noise estimate can not adapt .",
    "these adaptation capabilities are also reflected at the output of the algorithms , especially in comparison with the algorithm , as depicted in figs .",
    "[ fig : omlsa_siren ] and  [ fig : ann_mm_siren ] .",
    "we observe that the algorithm outperforms the in reducing this challenging noise .",
    "this is also indicated by the measure .",
    "while the degrade the speech quality ( pesq=1.847 ) , the proposed hybrid algorithm slightly improves it ( pesq=2.361 ) .",
    "the reader is also referred to our website where these sound clips can be found .",
    "in this paper a novel speech enhancement scheme , denoted , is presented .",
    "the proposed algorithm is based on a hybrid scheme which combines phoneme - based generative model for the clean speech signal with a discriminative , -based estimator . in the proposed algorithm",
    "we try to adopt the advantages of model - based approaches and approaches . while the former usually trade - off noise reduction abilities with residual musical noise , the latter often suffer from speech distortion artifacts .    in the proposed algorithm we take advantage of the _ discriminative _ nature of the that preserves speech smoothness by using context frames",
    ". moreover , the phoneme - based model , where each gaussian corresponds to a specific phoneme , preserves the general phoneme structure and reduces musical noise .",
    "a comprehensive set of experiments demonstrate the capabilities of the proposed algorithm in both improving scores as well as objective quality measures .",
    "the algorithm is shown to outperform state - of - the - art algorithm ( ) for both stationary and non - stationary environmental noises and a variety of levels ."
  ],
  "abstract_text": [
    "<S> in this paper we present a single - microphone speech enhancement algorithm . </S>",
    "<S> a hybrid approach is proposed merging the generative model and the discriminative . </S>",
    "<S> the proposed algorithm is executed in two phases , the training phase , which does not recur , and the test phase . </S>",
    "<S> first , the noise - free speech is modeled as a , representing the phoneme based diversity in the speech signal . </S>",
    "<S> an is then trained with phoneme labeled database for phoneme classification with as the input features . given the phoneme classification results , an is obtained using both the generative and discriminative models . </S>",
    "<S> soft spectral subtraction is then executed while simultaneously , the noise estimation is updated . </S>",
    "<S> the discriminative maintain the continuity of the speech and the generative phoneme - based preserves the speech spectral structure . </S>",
    "<S> extensive experimental study using real speech and noise signals is provided . </S>",
    "<S> we also compare the proposed algorithm with alternative speech enhancement algorithms . </S>",
    "<S> we show that we obtain a significant improvement over previous methods in terms of both speech quality measures and speech recognition results .    </S>",
    "<S> speech enhancement , mixmax model , neural - network , phoneme classification </S>"
  ]
}