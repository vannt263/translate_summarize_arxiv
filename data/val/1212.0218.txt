{
  "article_text": [
    "mass composition analysis is fundamental to understand the features observed in the cosmic ray energy spectrum and to test theoretical models concerning the origin and the nature of the primary cosmic ray radiation at the highest energies .",
    "current theories predict different spectra for each mass component so that the knowledge of the energy spectra for every mass component , or at least for groups of components , is required in order to discriminate among the proposed models .",
    "+ at low energies ( @xmath0ev ) cosmic ray composition can be measured using direct detection techniques , such as spectrometers and calorimeters .",
    "+ at higher energies , mass measurements are performed with indirect techniques , which make use of shower parameters sensitive to the primary mass .",
    "the depth at which the longitudinal development has its maximum , , and both the number of electrons @xmath1 and muons @xmath2 at ground level are most widely used .",
    "an extensive review of the adopted detection techniques and mass composition results over the entire energy spectrum range is presented in @xcite .",
    "+ two kinds of approaches are generally adopted in composition analysis .",
    "likelihood methods , for instance in @xcite or unfolding analyses , as in @xcite , aim to infer the average mass abundances or the energy spectra for different mass components on the basis of a set of parameters sensitive to the primary mass , without attempting to establish the mass of each single event .",
    "the information of the mass identity on an event - by - event basis would however be extremely useful and would lead to considerable progress .",
    "for instance when studying possible correlations of the shower arrival direction with given astrophysical objects it is desirable to select events according to their mass .",
    "some worthwhile studies concern the flux of a given primary , e.g. protons for the p - air cross section analysis or the search of gamma ray or neutrino events in the hadronic background . in all these situations pattern recognition methods , e.g. neural networks as in @xcite , linear discriminant analysis @xcite , are typically employed .",
    "+ due to the absence of features strongly correlated to the mass and the presence of stochastic shower - to - shower fluctuations , both analyses must necessarily deal with a limited number of mass groups , typically four or five in first kind of analysis and two or three in event - by - event studies .",
    "+ in this work we study the possibility to use neural networks and clustering algorithms as mass classifier tools on the basis of two parameters , the depth of shower maximum and the number of muons , measured with hybrid detectors , such as the pierre auger observatory @xcite or the telescope array @xcite .",
    "in particular we restrict the analysis to events measured with very high zenith angles ( @xmath360@xmath4 ) at energies above @xmath5 ev . for such inclined showers the electromagnetic component",
    "is strongly absorbed before reaching ground level due to the large atmospheric depth traversed and the muon component dominates the signal measured at the particle detectors . to a rough approximation",
    "only the muon reaches ground level .",
    "these events therefore represent a simple way to measure a parameter reflecting the size of the muon component in experiments not equipped with dedicated muon detectors .",
    "this is achieved , as detailed in @xcite , by fitting the measured signals ( after subtracting a small contribution due to the electromagnetic contamination ) to a reference parameterization of the muon density at ground level obtained from simulations .",
    "the depth of maximum can be determined from the longitudinal profile extracted from the light measurements made with the fluorescence telescopes ( see for instance @xcite ) . + the paper is organized as follows .",
    "section [ simulateddatasection ] describes the data set used for this study , built from conex simulations of extensive air showers , and addresses the correlation between the two parameters ( and muon size ) and the sensitivity to the primary mass . in section [ classificationmethodssection ] a brief description of the designed neural network and clustering methods",
    "is reported . in section [ resultssection ] their application to samples of simulated data and the achieved classification results are presented .",
    "our main conclusions are summarized in section [ summarysection ] .",
    "the present study is based on a sample of simulated showers generated with the conex tool @xcite using qgsjet01 @xcite as high energy hadronic interaction model .",
    "conex is an hybrid code , based on the combination of a monte carlo strategy and the analytic solution of the cascade equations , thus allowing only a one - dimensional simulation of the shower .",
    "it requires considerably shorter cpu times with respect to the ones needed by typical three - dimensional codes , such as corsika @xcite or aires @xcite .",
    "this feature makes conex particularly suitable for applications involving data observed with fluorescence detector telescopes .",
    "+ proton , nitrogen and iron primaries have been simulated according to a flat energy spectrum from @xmath5 ev to @xmath6 ev and a @xmath7 zenith angle spectrum from 60@xmath4 to 80@xmath4 .",
    "about 10@xmath8 events are available per each primary nucleus . + in order to perform a composition study , a set of parameters sensitive to the primary mass is needed . in this work we assumed the depth of shower maximum and an estimator of the total number of muons @xmath2 reaching ground level for inclined showers , denoted as @xmath9 .",
    "while is directly available in conex simulations , the latter has to be extracted from the simulated muon profile assuming a given observation depth .",
    "for our analysis we fixed such depth to 1450 m , roughly corresponding to the altitude of the pierre auger observatory .",
    "+ unfortunately conex provides the muon profile only for muons above 1 gev , therefore we need to employ full aires simulations to derive an empirical correction factor to be applied to @xmath2 . in fig . [ nmucorrectionfactorfig ]",
    "we display the ratio between the number of muons above 1 gev @xmath10 and the total number of muons @xmath2 as a function of the shower zenith angle .",
    "proton results are shown in red dots while iron in blue triangles .",
    "as one can see the effect of the muon energy cut is not particularly relevant for inclined showers .",
    "the fraction of unaccounted muons is below 10% muons when using conex .",
    "an empirical parameterization as a function of the zenith angle is derived and shown in fig .",
    "[ nmucorrectionfactorfig ] with solid colored lines . after this correction the simulated @xmath2",
    "is divided by the number of muons of the reference parameterization of the muon density at ground , obtained for this location at a conventional energy of @xmath11 ev @xcite , to obtain the relative muon size with respect to the reference energy , @xmath12 . as the number of muons in the reference parameterization depends on the zenith angle ,",
    "an estimator @xmath12 is obtained which is basically independent of the zenith angle .",
    "+ to take into account the reconstruction effects , the simulated @xmath13 and @xmath12 have been smeared with the detector resolution . in this work",
    "we assume the resolution reported by the pierre auger observatory in @xcite .",
    "typical values for @xmath14 are @xmath1527 g/@xmath16 at 10@xmath17 ev improving at @xmath1820 g/@xmath16 above 10@xmath19 ev .",
    "the detector resolution @xmath20 has been found of the order of 25% at 10@xmath21 ev improving at @xmath1512% above 10@xmath19 ev . in fig .",
    "[ xmaxn19scatterfig ] we present a scatter plot of and @xmath9 at a fixed energy of 10@xmath19 ev for the three available primaries with the upper ( lower ) panel ignoring ( accounting for ) detector resolution as modelled .",
    "it is worth investigating the correlation of the two parameters and evaluating an estimator of the mass sensitivity for both .",
    "this has been studied in detail for vertical showers in @xcite .",
    "here we report the results obtained for inclined showers .",
    "[ xmaxn19correlationfig ] we report the pearson correlation coefficient of both parameters for the three available nuclei ,    the bottom panel accounting for detector resolution .",
    "as can be seen the two parameters are almost independent for proton primaries while for heavier nuclei the correlation amounts to 0.5 for nitrogen and 0.6 for iron . in the bottom panel",
    "the effect of the detector resolution is visible and the correlation observed for nuclei is sensibly reduced .",
    "+ to estimate which of the two parameters offers the best separation between the proton and iron distribution we computed the fisher coefficient @xmath22 for @xmath23 and @xmath9 : @xmath24^{2}+[\\sigma_{j}^{p}]^{2}}\\;\\;\\;\\;\\ ; j=\\xmax , n_{19}\\ ] ] where @xmath25 and @xmath26 are the sample mean and variance of the proton / iron distributions of the parameter @xmath27 .",
    "the computed quantity provides a measure of power to separate two populations of proton and iron : large values of @xmath22 correspond to a good discrimination power . in fig .",
    "[ xmaxn19fisherfactorfig ] we report the fisher coefficient as a function of energy . as can be seen the number of muons estimator has a better discrimination power than @xmath23 .",
    "however , the reconstruction of the @xmath23 parameter , especially at low energies , is much better than that of @xmath9 .",
    "this results in the increased sensitivity of @xmath23 when applying the resolution to the data in the bottom panel . at the highest energies both parameters are almost equally powerful .",
    "two different classification methods are used in this work , one based on the neural network technique and the other on clustering algorithms . in the following sections we briefly describe the two approaches and the strategies adopted to perform the analysis .      a simple clustering algorithm , the well - known _ k - means _",
    "@xcite , is employed for the classification task .",
    "it starts assuming an initial set of @xmath28 cluster centroids , which are then iteratively moved to determine the partition of the data that minimizes a specified square error function @xmath29 .",
    "we assumed the euclidean distance as measure and the following squared error function : @xmath30 where @xmath31 is the @xmath32 data vector ( j=@xmath23,@xmath9 ) and @xmath33 are the coordinates of the @xmath28 cluster centroids .",
    "+ the data sample were first preprocessed to have zero mean and unit variance and then divided into three smaller subsets .",
    "one of these subsets is used for the cluster training phase in which the @xmath28 clusters determined are labelled on the basis of the monte carlo information of the primary mass .",
    "the validation subsets are mainly used to choose the optimal number of clusters , while the last subset if finally used to test the partition and report the performance of the method . as such algorithm",
    "is known to depend on the initial choice of the centroids , the algorithm was run over the three subsets assuming each time 100 different initial partitions and retaining the best one in terms of the total error .",
    "a number of clusters @xmath34 20 has been found to provide optimal results for our classification problem .",
    "a feed forward neural network ( nn ) is structured in parallel layers of neurons , connected to neurons in adjacent layers through weighted links .",
    "the input layer is connected to the input data vector and a predefined number of hidden layers process the signal towards the output layer which returns the final response of the network to the presented input data .",
    "each neuron @xmath35 linearly transforms the data @xmath36 from neurons in the previous layer according to the following expression : @xmath37 where @xmath38 are the weights associated to the @xmath27 link and @xmath39 is an additive bias .",
    "the neuron output is then obtained by applying a transfer function @xmath40 to the neuron input @xmath41 .",
    "+ during the training phase the network weights and biases are iteratively adjusted to minimize the following error function @xmath42 : @xmath43^{2}\\ ] ] defined as the sum of squared differences between the desired output @xmath44 and the computed network output @xmath45 . to improve the network generalization capabilities a regularization term",
    "is often added to the above error function to minimize the squared sum of the network weights : @xmath46 where @xmath47 are the number of weights of the network and @xmath48 is a parameter responsible to guarantee a compromise between the network error minimization and the generalization performances of the network .",
    "+ after testing several network architectures and choices of transfer functions , we obtained good results using a simple network design with one hidden layer ( 3 neurons ) , and an output layer with one neuron .",
    "the activation functions are hyperbolic tangent in the hidden layer and linear in the output layer .",
    "+ the network input data have been normalized to zero mean and unit variance and then divided into three subsets , train - validation - test samples .",
    "the first is used to train the network .",
    "the cross validation sample is used to stop the training at a given epoch to avoid over fitting the data sample used for learning . the last sample is finally used to test the trained network identification capabilities .",
    "+ several back propagation training algorithms have been tested ( steepest descent , conjugated gradient and quasi - newton algorithms ) .",
    "we achieved better identification performances with quasi - newton methods using the broyden - fletcher - goldfarb - shanno ( bfgs ) error minimization formula @xcite .",
    "the classification results obtained both with the clustering and the neural network methods are reported in figs .",
    "[ clusteringoutputfig ] and [ nnoutputfig ] in a sample energy range @xmath49e= [ 19 - 19.2 ] .",
    "[ clusteringoutputfig ] we report the output of the clustering procedure for the test data sample projected in the @xmath23-@xmath9 plane .",
    "proton data are shown with red dots , while iron data with blue triangles .",
    "a number of k=20 clusters , represented by the ellipses , is considered for this case .",
    "a standard representation is adopted to visualize the obtained clusters .",
    "first a principal component analysis is applied to the standardized data to project data in the bidimensional space of the two most important components .",
    "the cluster ellipse s axes are then defined by the eigenvalues of the covariance matrix of the observations belonging to that cluster . finally the axes are scaled to create a 95% confidence ellipse .",
    "the achieved classification performances in terms of efficiency and purity are larger than 80% and are reported in table [ clusteringperformancetable ] .",
    "[ nnoutputfig ] we report the distribution of the network outputs in presence of the proton ( red lines ) and iron ( blue lines ) test data .",
    "the performance in terms of classification matrix and purity relative to such case are reported in table [ nnperformancetable ] . assuming a cut in the network output equal to 0.5 , the classification efficiencies and purity are found to be around 90% .",
    ".classification matrix and purity for the clustering method for the sample test data in the energy bin @xmath50= [ 19.0,19.2 ] . [ cols=\"^,^,^,^ \" , ]      + to have the smallest contamination for a given class and match a given analysis requirement one can tighten the applied selection cuts , increasing at the same time the event rejection rate , as shown in figs .",
    "[ nnperformancevscutfig1 ] and [ nnperformancevscutfig3 ] .    in fig .",
    "[ nnperformancevscutfig1 ] we report the classification efficiency ( filled dots ) and purity ( empty dots ) as a function of the network output for proton and iron data . the best compromise between the highest efficiency and purity is found around 0.55 - 0.60 . to decrease the contamination from other species below few percent a cut of @xmath150.2 for proton and @xmath150.8 for iron",
    "must be assumed .",
    "+ similarly , for the clustering method a smaller contamination can be achieved by rejecting those clusters having a classification purity below a given requirement during the training phase .",
    "we therefore report in fig .",
    "[ nnperformancevscutfig3 ] the results as a function of the cluster purity obtained for the training data set .",
    "the steps observed in the plots are due to the fact that for a given purity threshold an entire set of events belonging to a cluster below threshold are rejected .",
    "the effect is more pronounced when a small number of clusters is assumed in the analysis .",
    "+ the presented results so far assumed that no other species other than proton and iron is present in the flux .",
    "if an intermediate component , like nitrogen , is included in the data and both classifier are trained to recognize three species , the number of classifier parameters needed to achieve optimal results must be increased .",
    "the obtained performances deteriorate significantly in a 3-component situation .",
    "+    for the extreme components the identification efficiency and purity drops to a level of 75% , while for the intermediate component it is of order 60% .",
    "it is clear that with current parameter sensitivity to the mass and reconstruction resolution it is not possible to efficiently discriminate more than two masses .",
    "we therefore quantify in figs .",
    "[ nnperformancevscutfig2 ] , [ nnperformancevscutfig4 ] the increased contamination in the proton and iron classified samples due to the presence of nitrogen . for the neural network",
    "an optimal compromise is found assuming a cut equal to 0.2 and 0.8 .",
    "the corresponding efficiency and purity are reduced at the 80% level .",
    "however one can obtain smaller contamination by further tightening the applied cuts at the cost of reducing the detection efficiency .",
    "for the clustering method the presence of an intermediate component rises the contamination in the proton and iron sample to values around 40 - 50% . to recover the contamination observed with proton and iron components only a large number of clusters must be rejected .",
    "in the present work we propose two alternative strategies to the problem of the high energy cosmic ray mass identification on a event - by - event basis . one is based on the neural network technique while the other on clustering algorithms .",
    "the performances of both classifiers have been studied with simulated showers generated with the conex tool .",
    "the mass discrimination is based on two parameters , the depth of shower maximum @xmath23 and an estimator of the muon number @xmath9 reconstructed in very inclined showers .",
    "realistic reconstruction resolutions have been assumed for both parameters .",
    "the analysis is in particular optimized for events recorded by hybrid detectors with zenith angles above 60@xmath4 .",
    "nevertheless it can be extended in a straightforward way to nearly vertical events , provided that an alternative muon number parameter estimator is introduced .",
    "+ we have found very good identification performances for both methods in the case of a 2-component flux of proton and iron nuclei .",
    "the expected misclassification are found of the order of @xmath1510 - 15% , decreasing with energy , with slightly better performances exhibited by the neural network classifier .",
    "+ a significant loss of efficiency is observed when training the classifiers to recognize a flux with an intermediate mass component added .",
    "in this situation the expected contamination affecting the proton and iron identification has been reported .",
    "no significant performance degradation has been observed with an alternative data sample generated using a different hadronic interaction model , such as epos .",
    "+ the present method , as it is , can be applied also to other typical discrimination problems in cosmic ray physics , such as hadron - gamma or hadron - neutrino event discrimination . in such cases",
    "the classification performances are expected to increase given the better separation between the two classes .",
    "other feasible applications include the selection of a given mass group from the background , as it could be done for the selection of pure samples of protons for correlation analysis with astrophysical objects or to derive estimates of the proton - air cross section .",
    "+ in this work we made use of supervised methods .",
    "an implicit assumption is made , namely that the measured data must be well described or at least bracketed by the hadronic model predictions adopted in the classifiers .",
    "surprisingly , this is the case for most of the shower observables so far measured at such extreme energies , i.e. see @xcite . furthermore , the differences among different models are going to be significantly reduced with incoming model releases accounting for recent lhc measurements , for instance see @xcite .",
    "recently a significant discrepancy between data and monte carlo simulations has been reported in the muon number estimator both for vertical @xcite and for very inclined showers @xcite .",
    "for this reason we are currently developing a semi - supervised classifier , partially using the strong constraints offered by the available models . results and performance comparison with supervised methods",
    "will be reported in a forthcoming paper .",
    "s. riggi acknowledges the astroparticle group of the universidad de santiago de compostela for support and ideas exchanging .",
    "we thank xunta de galicia ( incite09 206 336 pr ) and consellera de educacin ( grupos de referencia competitivos  consolider xunta de galicia 2006/51 ) ; ministerio de educacin , cultura y deporte , spain ( fpa 2010 - 18410 , fpa 2012 - 39489 and consolider cpan - ingenio 2010 ) and feder funds .",
    "we are greatful to cesga ( centro de supercomputacin de galicia ) for computing resources .    99 k.h .",
    "kampert , m. unger , astroparticle physics 35 ( 2012 ) , 660 .",
    "d. durso for the pierre auger collaboration , proc . of 31st international cosmic ray conference ( 2009 ) .",
    "t. antoni at al , astroparticle physycs 24 ( 2005 ) 1 ; w.d .",
    "apel et al , astroparticle physics 31 ( 2009 ) 86 .",
    "tiba , g.a.medina-tanco , s.j.sciutto , _ astro - ph0502255_. m.ambrosio et al , astroparticle physics 24 ( 2005 ) 355 .",
    "p. abreu et al , physical review d 84 ( 2011 ) 122005 .",
    "j. abraham et al , nucl .",
    "meth . a 523 ( 2004 ) 50 .",
    "t. nonaka for the telescope array collaboration , proc . of 31st international cosmic ray conference ( 2009 )",
    "; a. taketa for the telescope array collaboration , proc . of 31st international cosmic ray conference ( 2009 )",
    "; y. tameda et al , nucl .",
    "instr . meth . a 609 ( 2009 ) 227 .",
    "g. rodriguez for the pierre auger collaboration , proc . of 32nd international cosmic ray conference ( 2011 ) .",
    "m. unger , b.r .",
    "dawson , r. engel , f. schussler and r. ulrich , nucl .",
    "instr . meth . a 588 ( 2008 ) 433 .",
    "t. pierog et al , nucl .",
    "b ( proc . suppl . )",
    "151 ( 2006 ) 159 .",
    "kalmykov et al , astroparticle physics 26 ( 2007 ) 420 .",
    "kalmykov et al , nucl .",
    "52 ( 1997 ) 17 .",
    "d. heck , j. knapp , j.n .",
    "capdevielle , g. schatz , t. thouw , forschungszentrum karlsruhe report fzka 6019 ( 1998 ) .",
    "sciutto , proc . of 27th international cosmic ray conference ( 2001 ) .",
    "j. abraham et al , phys .",
    "letters 104 ( 2010 ) 091101 .",
    "p. younk and m. risse , astroparticle physics 35 ( 2012 ) 807 .",
    "hartigan , m.a .",
    "wong , journal of the royal statistical society c 28 ( 1979 ) 100 .",
    "bishop , neural networks for pattern recognition , oxford university press ( 1995 ) .",
    "h. demuth , m. beale , neural network toolbox - matlab - user s guide ( 2006 ) , version 5 .",
    "t. pierog , proc . of 23rd european cosmic ray symposium ( 2012 ) .",
    "j. allen for the pierre auger collaboration , proc . of 32nd international cosmic ray conference ( 2011 ) ."
  ],
  "abstract_text": [
    "<S> in the present work we carry out a study of the high energy cosmic rays mass identification capabilities of a hybrid detector employing both fluorescence telescopes and particle detectors at ground using simulated data . </S>",
    "<S> it involves the analysis of extensive showers with zenith angles above 60 degrees making use of the joint distribution of the depth of maximum and muon size at ground level as mass discriminating parameters . </S>",
    "<S> the correlation and sensitivity to the primary mass are investigated . </S>",
    "<S> two different techniques - clustering algorithms and neural networks - are adopted to classify the mass identity on an event - by - event basis . </S>",
    "<S> typical results for the achieved performance of identification are reported and discussed . </S>",
    "<S> the analysis can be extended in a very straightforward way to vertical showers or can be complemented with additional discriminating observables coming from different types of detectors .    </S>",
    "<S> cosmic rays , mass composition , neural networks , clustering    96.50.sb , 96.50.sd , 96.50.s- , 95.85.ry , 07.05.mh </S>"
  ]
}