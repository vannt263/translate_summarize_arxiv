{
  "article_text": [
    "when planning cbm strategies , see , e.g. , @xcite , @xcite , @xcite , the typical assumption in the literature is that the asset at hand is monitored continuously and one can intervene and repair the asset at any given moment .",
    "however , in practice , especially for highly complicated high - tech systems , such as off - shore wind turbines , baggage handling systems in airports and interventional x - ray machines , downtimes are extremely costly and scheduling maintenance tasks is challenging , see , e.g. , @xcite , @xcite . one solution suggested in the literature to overcome this problem is the planning of opportunistic maintenance .",
    "most of the works on opportunistic maintenance consider only unscheduled opportunities , rarely treating the case of scheduled opportunities , see , e.g. , @xcite and the references therein .",
    "different from existing research on opportunistic maintenance policies , we consider both scheduled and unscheduled opportunities for cbm .",
    "furthermore , we consider distinct costs for maintenance based on the type of the opportunity . for a single - component model",
    "we derive the optimal long - run average cost cbm policy and calculate the corresponding long - run average cost .",
    "thereafter , we compare it with the corresponding cost for only one type of opportunity . our work can be viewed as a variation of the work of @xcite in the direction of cbm .",
    "the paper is organised as follows .",
    "in , we present the model and describe the exact setting that motivated our work . in the subsequent two sections we prove the two main results : in , we derive the optimal policy and in , we calculate the long - run average cost . in",
    ", we numerically compare the optimal replacement policy to other policies .",
    "finally , in the last section , we present some concluding remarks and ideas on future research .",
    "we consider a single component that is monitored continuously and whose condition is fully observable .",
    "we assume that the condition of the component can only degrade over time and it can be classified as _",
    ", _ satisfactory _ and _ failed_. this type of models are known in the literature as delay time degradation models , see ( * ? ? ?",
    "* chapter  14 ) .",
    "we will refer to the state of perfect condition as state @xmath0 , the state of satisfactory condition as state @xmath1 and the failure state as state @xmath2 .",
    "furthermore , we assume that as soon as a component failure occurs , the component is instantaneously replaced by an `` as good as new '' component .",
    "so , in the mathematical formulation of the model , we may assume , due to the instantaneous replacement at failure , that the model evolves between only states @xmath1 and @xmath0 .",
    "the component spends an exponential amount of time with rate @xmath3 in state @xmath4 , @xmath5 .",
    "the above model formulation implies that initially the component starts in state @xmath0 ( perfect state ) , then after an exponential amount of time with rate @xmath6 , the component deteriorates and the condition of the component goes to state @xmath1 ( satisfactory state ) .",
    "the component spends an exponential amount of time with rate @xmath7 in state 1 , after which a failure occurs . at a failure",
    "the component is instantaneously replaced by an `` as good as new '' component and the condition is restored to @xmath0 ( perfect state ) .",
    "a schematic evolution of the condition of the component and the corresponding times of transitions are depicted in figure [ fig:1 ] .",
    "@xmath8^{\\mathrm{exp}(\\mu_2)}&1\\ar@/^.75pc/[r]^{\\mathrm{exp}(\\mu_1)}&2   \\ar@/^.75pc/[r]^{\\mathrm{exp}(\\mu_2)}&\\cdots\\ \\ \\ \\\\ } \\ ] ]    we assume that we have two types of opportunities in which we can preventively replace the component before failure : the scheduled and the unscheduled opportunities .",
    "the scheduled opportunities correspond to pre - arranged opportunities occurring according to a fixed schedule .",
    "these opportunities can be attributed to either service / maintenance agreements or to regulation imposition checks .",
    "we assume that the scheduled opportunities occur at epochs @xmath9 , with @xmath10 .",
    "this is also in accordance with what happens in practice as maintenance actions once planned are typically not rescheduled .",
    "the unscheduled opportunities correspond to random opportunities triggered by failures of other unrelated components of the same system or failures of other systems in close proximity .",
    "we assume that these unscheduled opportunities occur according to a poisson process at rate @xmath11 .    the unscheduled and scheduled opportunities , abbreviated by uso and so , respectively , serve as opportunities for the monitored component to be replaced preventively .",
    "such a preventive replacement is assumed to cost less than a corrective replacement upon failure , which costs say @xmath12 .",
    "moreover , incorporating a planning perspective , we may assume that the preventive replacement cost at a scheduled opportunity , say @xmath13 , is less than or equal to the corresponding cost at an unscheduled opportunity , say @xmath14 , that is @xmath15 .",
    "our aim is to determine a policy when to replace the component based on its condition and the opportunity type , i.e. scheduled or unscheduled .",
    "more explicitly , we will need to formally define the state space , which refers to the condition of the component , the action space and the decision epochs .",
    "the state space is governed by the process depicting the condition of the component , i.e. the markov chain evolving between the states @xmath16 .",
    "the action space consists of only two actions : replace the component by an `` as good as new '' or do nothing .",
    "lastly , the decision epochs are the epochs of the scheduled and unscheduled opportunities . in",
    ", we depict so by ( @xmath17 ) and uso by ( o ) .",
    "( -6,0 )  ( -6,2.5 ) node[right , text width=2.7cm]condition of the component ; ( -6.1 , 1.5 ) node[left]2  ( -5.9,1.5 ) ; ( -6.1 , .5 ) node[left]1  ( -5.9,.5 ) ; ( -6,0 )  ( 7.1,0 ) node[below , xshift=1ex]time ; ( -6,1.5 )  ( -2,1.5 ) ; ( -4.5,0 ) node[yshift=-.2pt]@xmath18 node[below , yshift=-1ex ] @xmath19 ; ( -3,0 ) node[yshift=-.2pt]@xmath18 node[below , yshift=-1ex ] @xmath20 ; ( -2.4,0 ) circle ( 0.1 ) ; ( -2,.5 )  ( 2.35,.5 ) ; ( -2,1.5 )  ( -2,0 ) node[below]sc ; ( -1.5,0 ) node[yshift=-.2pt]@xmath18 node[below , yshift=-1ex ] @xmath21 ; ( 0,0 ) node[yshift=-.2pt]@xmath18 node[below , yshift=-1ex ] @xmath22 ; ( .6,0 ) circle ( 0.1 ) ; ( 1.5,0 ) node[yshift=-.2pt]@xmath18 node[below , yshift=-1ex ] @xmath23 ; ( 1.8,0 ) circle ( 0.1 ) ; ( 2.35,1.5 )  ( 2.35,0 ) node[below]sc ; ( 2.35,1.5 )  ( 6.5,1.5 ) ; ( 3,0 ) node[yshift=-.2pt]@xmath18 node[below , yshift=-1ex ] @xmath24 ; ( 4.2,0 ) circle ( 0.1 ) ; ( 4.5,0 ) node[yshift=-.2pt]@xmath18 node[below , yshift=-1ex ] @xmath25 ; ( 6,0 ) node[yshift=-.2pt]@xmath18 node[below , yshift=-1ex ] @xmath26 ; ( 6.5,1.5 )  ( 6.5,0 ) node[below]sc ; ( 6.5,.5 )  ( 7,.5 ) ;    ( -6,-.5 )  ( -2,-.5 ) node [ midway , below , yshift=-12pt ] @xmath27 ; ( -2,-.5 )  ( 2.35,-.5 ) node [ midway , below , yshift=-12pt ] @xmath28 ; ( 2.35,-.5 )  ( 6.5,-.5 ) node [ midway , below , yshift=-12pt ] @xmath27 ; at ( 3.75,2.5 ) scheduled opportunities @xmath29 ; ( .7,2 ) circle ( 0.1 ) node[right , xshift=.45ex]unscheduled opportunities poisson process @xmath30 ; at ( 2.2,3 ) state changes ( sc ) ;",
    "this section is devoted to the proof of our first main result on the optimal policy on when to replace the component . to this purpose",
    ", we set up our problem as a markov decision problem ( mdp ) . due to the stochastic nature of the problem",
    ", it does not suffice to know the type of the decision epoch ( scheduled or unscheduled opportunity ) , but it is also required to keep track of the remainder time till the next scheduled opportunity .",
    "the remaining time until the next scheduled opportunity may impact our decision , i.e. the optimal policy may depend on the residual time till the next scheduled opportunity .",
    "thus , for the full description of the condition ( state ) of the component , we will use a triplet descriptor @xmath31 , [ page - ref ] where @xmath4 indicates the condition of the component . if @xmath32 , then this means that the condition of the system is about to change and",
    "there is no decision associated with this epoch , while if @xmath33 or @xmath34 , this means that this is a decision moment of the type of a scheduled or unscheduled opportunity .",
    "finally , the third element indicates the remaining time until the scheduled opportunity . note that if @xmath33 then @xmath35 . the introduction of the time in the full description of the condition of the component renders the model inhomogeneous , and for this reason we use techniques that stem from semi - markov decision problems ( smdp ) .",
    "+      in case of equal costs at scheduled and unscheduled opportunities , the long - run optimal average cost policy does not depend on time .",
    "in particular , the optimal policy for state @xmath0 is to do nothing and for state @xmath1 the optimal policy depends on the model parameters .",
    "[ thm : opt1 ] under the assumption that @xmath36 , the long - run optimal average cost policy is : for state @xmath0 to do nothing . for state @xmath1 to replace ( at both scheduled and unscheduled opportunities ) if @xmath37 , and to do nothing otherwise .    for the proof of theorems [ thm : opt1 ] and [ thm : opt2 ]",
    ", we derive the policy that minimises the long - run average cost per time unit . to this purpose ,",
    "we state the bellman optimality equations for the decision process with action space @xmath38 , see , e.g. , @xcite , @xcite .",
    "[ thm : puterman ] for a decision process with an embedded unichain , there exists a scalar @xmath39 and a value function @xmath40 satisfying the system of equations @xmath41 where @xmath42 is the expected sojourn time of the smdp in state @xmath43 with transition probabilities @xmath44 under action @xmath45 , and @xmath46 is the stationary total expected cost of the smdp in state @xmath43 between two consecutive decision epochs under action @xmath45 .",
    "the existence of such a scalar @xmath39 ensures the existence of a policy that minimises the long - run average cost .",
    "the bellman optimality equations [ bellman ] for the model at hand become : @xmath47 @xmath48 in this paragraph we explain in detail how equation is obtained .",
    "state @xmath49 , as explained before , see page , is not associated with any decision .",
    "therefore , there is no minimum operator appearing on the right hand side of the equation and the corresponding cost , @xmath50 , is equal to zero . for the other terms appearing on the right hand side of equation",
    ", it suffices to note that there are three possible evolutions in terms of the state of the system either a so or a sc or an uso , where the time till the next so is equal to @xmath51 , while the time till the sc and uso are exponentially distributed with rates @xmath7 and @xmath11 , respectively . in particular , the expected sojourn time of the smdp in state @xmath49 can be calculated as the minimum of a deterministic time @xmath51 and two exponentially distributed times , which can be easily verified to be equal to @xmath52 .",
    "the set of equations [ eq : v1sc][eq : so ] was obtained using very similar arguments .",
    "+ note that in [ eq : uso , eq : so ] , inside the minimum , the left terms correspond to the action `` replace '' , while the right terms correspond to the action `` do nothing '' .",
    "furthermore , for @xmath53 , [ eq : uso , eq : so ] yield that it is never optimal to replace . in order to decide if it is optimal or not to replace the component in state @xmath54 at scheduled and unscheduled opportunities , cf .",
    "[ eq : uso , eq : so ] , we define the following auxiliary functions , for @xmath55 @xmath56,\\ ] ] and rewrite [ eq : v2sc , eq : v1sc , eq : uso , eq : so ] , for @xmath57 , @xmath58 from this point onward in the proof , we will use that @xmath59 . at a scheduled opportunity",
    ", we can either replace a component in state @xmath1 or do nothing .",
    "we first assume that we replace the component at a scheduled opportunity , i.e. @xmath60 thus , equation [ visot ] for @xmath54 implies that @xmath61 .",
    "furthermore , for @xmath35 , equation [ eq : fis ] yields @xmath62 and @xmath63 .",
    "combining the last two results yields @xmath64 since the functions @xmath65 are continuous functions in @xmath66 $ ] and their difference at @xmath67 is greater than @xmath68 at @xmath19 , cf .",
    "equation [ asumption1 ] , there exists an @xmath69 such that @xmath70.\\end{aligned}\\ ] ] taking the derivative in [ eq : fis ] and after straightforward manipulations , using [ v2sct] together with , yields @xmath71 .",
    "\\label{eq : difeqs}\\end{aligned}\\ ] ] the solution to the above differential equation reads @xmath72 .",
    "\\label{solution : dif}\\end{aligned}\\ ] ] note that , for @xmath73 $ ] the function @xmath74 is monotone . moreover ,",
    "if @xmath75 or equivalently if @xmath74 is non - increasing , we can extend the above approach throughout the interval @xmath76 $ ] and show that the solution of the differential equation is valid in the entire interval @xmath76 $ ] , but that would contradict assumption .",
    "hence , for @xmath73 $ ] the function @xmath74 is increasing and @xmath77    [ b][c][1][90]@xmath74 [ r][r]@xmath78 [ c][c]@xmath79 [ c][c]@xmath19 [ c][c]@xmath51    .,scaledwidth=80.0% ]    since the function @xmath74 is increasing for @xmath73 $ ] , we now need to identify the @xmath80 , more concretely the point @xmath81 such that @xmath82 .",
    "if @xmath83 is strictly positive this contradicts assumption , yielding @xmath84 .",
    "all in all , if the policy at a scheduled opportunity is to replace the component in state 1 , then the optimal long - run average cost policy at an unscheduled opportunity is to replace in state @xmath1 if @xmath37 , cf . .",
    "a schematic representation of the function @xmath74 is depicted in figure [ fig:3 ] .",
    "similarly to the case that we replace the component at a scheduled opportunity , we may assume that we do not replace the component at a scheduled opportunity and prove that then , it is also optimal not to replace the component at an unscheduled opportunity if @xmath85 . at the equality @xmath86",
    ", we are cost - wise indifferent between the two actions .      in case of different preventive costs at scheduled and unscheduled opportunities ,",
    "the optimal policy , in certain cases , becomes time - dependent , i.e. there exists a threshold @xmath87 such that it is optimal to replace if the residual time until the next scheduled opportunity is greater than or equal to the threshold and do nothing otherwise .",
    "[ thm : opt2 ] under the assumption that @xmath88 , the optimal long - run average cost policy is : for state @xmath0 to do nothing . for state @xmath1 to replace at scheduled opportunities and at unscheduled opportunities occurring in @xmath89 , with @xmath90 ,",
    "if @xmath91 , and to do nothing otherwise .",
    "similarly to the proof of , we need to make certain assumptions here regarding the actions at the given opportunities .",
    "in particular , we distinguish three cases , each corresponding to a different set of actions . _ case ( i ) : _ @xmath92 ; _ case ( ii ) : _ @xmath93 ; _ case ( iii ) : _ @xmath94 .",
    "the proof of this theorem is identical in structure to the proof of theorem [ thm : opt1 ] and for this reason it is omitted .",
    "schematic representations of the function @xmath74 for cases ( i ) and ( ii ) are depicted in figures [ fig:4a ] and [ fig:4b ] , respectively .",
    "0.48 .,title=\"fig : \" ]    0.48 .,title=\"fig : \" ]",
    "in the previous section , we derived the optimal long - run average cost policy . in this section , for any given time dependent control limit policy , we calculate the long - run average cost per time unit in theorem [ them : costs ] .    [ them : costs ] consider a given policy that states that in state @xmath0 we do nothing , and in state @xmath1 we replace at scheduled opportunities and at unscheduled opportunities for which the remaining time until the next scheduled opportunity is greater than @xmath95 , and we do nothing otherwise . under this",
    "given policy , the long - run average cost is @xmath96 .",
    "\\label{eq : replacet}\\end{aligned}\\ ] ]    for the calculation of the long - run average cost , we employ techniques from renewal - reward theory . to this purpose",
    ", we consider as renewal epochs the instants of the scheduled opportunities , thus , the inter - renewal times are deterministic and equal to @xmath19 . for the determination of the average cost during a renewal cycle ,",
    "we define the following probabilities @xmath97 where @xmath57 .",
    "then , the average cost in a cycle can be obtained as @xmath98 from which , once we calculate the unknown probability @xmath99 , @xmath57 , we can immediately derive the long - run average cost by simply dividing by @xmath19 .",
    "+ the probabilities in [ eq : propbsilam ] satisfy the following system of differential equations @xmath100 solving - , knowing that @xmath101 for all @xmath51 , @xmath102 and @xmath103 , @xmath104 , i.e. they are continuous functions , we obtain @xmath105 where @xmath106      in case of only _ scheduled opportunities _ , which corresponds to the case @xmath107 or equivalently to the case @xmath108 , the long - run expected cost equals @xmath109    in case of only _ unscheduled opportunities _ , which corresponds to the case @xmath110 , the condition of the component can be fully described using a double descriptor @xmath111 which is independent of time , and thus the new model formulation falls into the framework of regular mdps . it can be easily shown that : for state @xmath0 the optimal policy is to do nothing .",
    "for state 1 the optimal policy is to replace if @xmath112 and to do nothing otherwise .",
    "furthermore , under the optimal policy the average long - run cost is equal to @xmath113    in case of only _ corrective replacements _ , the long - run average cost is equal to @xmath114",
    "as a small numerical example , we examine the effect of @xmath19 , @xmath11 and @xmath13 on the long - run average cost , while keeping all other parameters fixed .",
    "we choose @xmath115 , @xmath116 , @xmath117 and @xmath118 . in this case , the long - run average cost in case of only corrective replacements is equal to @xmath119 . in table 1 , we show the long - run average cost for various choices of @xmath11 , @xmath19 and @xmath13 for three different policies : the optimal policy ( @xmath120 ) , the policy that we replace at only the scheduled opportunities ( @xmath121 ) , and finally , the policy under which we always replace at all opportunities ( @xmath122 ) .",
    "it seems that the use of the proposed policies can considerably improve upon the long - term average cost when compared to performing only corrective replacements .",
    "in most of the numerical scenarios we performed , as long as the choice of the parameters is reasonable , we did not notice considerable differences between the three policies , viz . @xmath123 .     & & + @xmath11 & @xmath124 & @xmath122 & @xmath120 & @xmath125 & @xmath122 & @xmath120 & @xmath121 & @xmath122 + 0.1 & 2840.41 & 2885.56 & 3384.70 & 3384.86 & 3422.03 & 3802.49 & 3807.90 & 3823.32 + 0.5 & 2840.41 & 3042.07 & 3384.09 & 3384.86 & 3538.91 & 3784.63 & 3807.90 & 3867.21 + 1 & 2840.41 & 3194.24 & 3383.38 & 3384.86 & 3636.35 & 3768.42 & 3807.90 & 3899.32 + 2 & 2840.41 & 3401.88 & 3382.15 & 3384.86 & 3747.82 & 3747.68 & 3807.90 & 3932.53 +   + & & + @xmath11 & @xmath124 & @xmath122 & @xmath120 & @xmath125 & @xmath122 & @xmath120 & @xmath125 & @xmath122 + 0.1 & 3378.56 & 3403.48 & 3719.49 & 3720.28 & 3738.77 & 3979.00 & 3985.81 & 3989.58 + 0.5 & 3378.56 & 3489.66 & 3716.57 & 3720.28 & 3796.18 & 3956.81 & 3985.81 & 3998.72 + 1 & 3378.56 & 3573.11 & 3713.40 & 3720.28 & 3842.96 & 3937.06 & 3985.81 & 4003.48 + 2 & 3378.56 & 3686.18 & 3708.32 & 3720.28 & 3894.71 & 3912.27 & 3985.81 & 4006.06 +   + & & + @xmath11 & @xmath124 & @xmath122 & @xmath120 & @xmath125 & @xmath122 & @xmath120 & @xmath125 & @xmath122 + 0.1 & 3792.57 & 3797.66 & 3916.43 & 3916.70 & 3921.39 & 4052.18 & 4055.71 & 4055.51 + 0.5 & 3792.57 & 3816.41 & 3915.40 & 3916.70 & 3937.26 & 4039.84 & 4055.71 & 4053.46 + 1 & 3792.57 & 3836.68 & 3914.21 & 3916.70 & 3951.98 & 4027.59 & 4055.71 & 4049.58 + 2 & 3792.57 & 3868.78 & 3912.11 & 3916.70 & 3970.48 & 4010.20 & 4055.71 & 4041.61 +",
    "in this paper , we derived the optimal replacement policy for a 3-state component degrading over time with corrective replacements at failures and preventive replacements at both scheduled and unscheduled opportunities .",
    "we also explicitly calculated the long - run average cost for certain time - dependent policies . in future work , we want to extend our analysis to models of components with more than three states , to models with additional features such as repairs , and to models in which the condition of the component is only partially observable .",
    "the work of sz .",
    "klosi is supported by the data science flagship framework , a cooperation between the eindhoven university of technology and philips .",
    "the work of s. kapodistria is supported by an nwo gravitation project , networks , and a tki project , daisy4offshore .",
    "the authors would like to thank m. barbieri , j. korst , and v. pronk ( all philips research ) and o. j. boxma ( eindhoven university of technology ) for their time and advice in the preparation of this work ."
  ],
  "abstract_text": [
    "<S> motivated by original equipment manufacturer ( oem ) service and maintenance practices we consider a single component subject to replacements at failure instances and two types of preventive maintenance opportunities : scheduled , which occur due to periodic system reviews of the equipment , and unscheduled , which occur due to failures of other components in the system . </S>",
    "<S> modelling the state of the component appropriately and incorporating a realistic cost structure for corrective maintenance as well as condition - based maintenance ( cbm ) , we derive the optimal cbm policy . in particular , we show that the optimal long - run average cost policy for the model at hand is a control - limit policy , where the control limit depends on the time until the next scheduled opportunity . </S>",
    "<S> furthermore , we explicitly calculate the long - run average cost for any given control - limit time dependent policy and compare various policies numerically . </S>"
  ]
}