{
  "article_text": [
    "there is little doubt that modern accounting systems have benefitted , ever since the advent of commercial computing machines , from the digitization of the processing and recording of financial transactions .",
    "the automated processing of payroll information in the 1950ies was perhaps one of the earliest examples of such benefits : ibm introduced its _ 702 data processing system _ for businesses in 1953 . and the use of rfid technology or smart phones for contactless payment of small items such as coffees is a more recent example thereof .",
    "it is then striking that the mechanisms used for managing the integrity of accounts are , in essence , those developed at least a thousand years ago .",
    "what we call the modern _ double - entry bookkeeping _ was already used by florentine merchants in the 13th century , for example . without going into great detail ,",
    "the key idea is in simplified terms that each account has an associated _ dual _ account and that each credit in one account is recorded as a debit in that dual account .",
    "this allows for the formulation and verification of an important _ financial invariant _ : no matter how complex financial transactions may be , or how many transactions may occur , it must always be the case that over the totality of accounts    _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ `` assets equal liabilities plus capital . ''",
    "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _    modern realizations of this method may enrich account entries with time stamps and other contextual data so that the flow of assets can be better understood , for example to support an audit",
    ". the above invariant may be quite simple to verify , and its verification may give us reassurance that every debit has an associated credit .",
    "but it does not prevent the recording of transactions that may be unauthorized , fraudulent , or that may be incorrect due to human error .",
    "for example , transaction records within accounting books may be manipulated to commit fraud whilst these manipulations still satisfy the above invariant .",
    "one may say that processing of transactions is governed by a form of _ legal code _ that is informed by policy on fraud prevention and detection , regulation , compliance , risk , and so forth .",
    "but the enforcement of such legal code within the _ technical code _ that operationalizes modern financial processes has been difficult at best , and too costly or impossible at worst .",
    "digitized financial processes can , of course , utilize cryptographic primitives to help with narrowing this gap between legal and technical code : digital signatures can be associated to transactions ( for example  embedded within transaction objects ) , and commitment schemes can be used to realize consistent distributed storage whose consistency is resilient to adversarial manipulation ; see for example  the discussion of byzantine agreement protocols in @xcite .",
    "but the advent of de - centralized , _ eventual consistency _ storage protocols , as pioneered in the cryptocurrency bitcoin @xcite , opened up a new way of thinking about the processing of financial transactions , even of creating and managing a currency as a unit of account .",
    "there is little doubt that cryptocurrencies are one of the most important innovations @xcite , along with the invention and introduction of central banks , in financial services since the advent of the double - entry bookkeeping .    in bitcoin",
    ", transactions are grouped into blocks , and blocks are recorded and linked in a chain of blocks    the blockchain .",
    "currency units are created through the solution of a cryptographic mining puzzle , a process in which network nodes ( called miners ) compete in determining the next block to be added to the chain and where the winner will become the owner of the currency created in that new block .",
    "these solutions causally link this new block to the last one , using cryptographic hash functions , creating thus the resiliency of this chain against manipulation .",
    "these acts of creating currency are treated as ( special ) transactions and their outputs are associated with their owners in a ( pseudo)anonymous manner    using public - key cryptography .",
    "the system dynamics is adjusted so that , on average , a new block is added to the blockchain about every 10 minutes .    in bitcoin , transactions are now technical code . without going into the technical details ,",
    "a transaction can be seen as a program that has a number of inputs and a number of outputs , each representing a unit of currency associated with some owner .",
    "that program also contains a _ proof _ that the program is authorized to rewire inputs to outputs in this manner .",
    "for example , this proof may be a cryptographic demonstration that the program",
    "_ owns _ all inputs .",
    "transactions enjoy an important invariant : the sum of currency units of all transaction outputs can not be larger than the sum of currency units of all its inputs    and any positive difference becomes a credit for the miner that created the block within which the transaction is found .",
    "the bitcoin network has many nodes that contain a full copy of the blockchain .",
    "more accurately , each node contains a tree of possible chains and identifies one of those chains deterministically as the _ real _ blockchain .",
    "the propagation of possible winning blocks and consensus protocols between these nodes ensure that nodes eventually agree on which of the chains they each store is the _ real _ chain .",
    "this does have its problems .",
    "for example , miners may collude to gain more control of mining competitions and so may force all network nodes to accept an alternative blockchain as the real one    allowing them to rewrite the transaction history .",
    "another problem is that nodes need to keep a record of which outputs of transactions recorded on the _ real _ blockchain have not been spent yet in new transactions on the blockchain ; and the above consensus mechanisms for _ eventual consistency _ do nt give hard guarantees , meaning that transaction outputs may be double spent and that transactions in a blockchain may only be trusted if their block has been linked with a certain number of blocks added to the chain subsequently .",
    "the incentive mechanism of bitcoin also led to the creation of puzzle - solving pools of miners and a complex and risky dynamics between such pools , the development of hardware for solving such puzzles and other factors .",
    "understanding such dynamics in predictable ways is one research challenge for cryptocurrencies @xcite .",
    "another risk resides in the verification of transactions , done by a run - time system that executes a verification script . whilst the designer(s ) of bitcoin deliberately chose a simple scripting language that makes its execution more secure , early implementations of that system still had security vulnerabilities .",
    "there is also a tradeoff here between security and expressiveness of technical code .",
    "other cryptocurrencies seek to program more complex transactions ( so called _ smart contracts _ ) to create new financial services , for example .",
    "but these require scripting languages that are turing complete and are therefore much more at risk of security attacks    see the dao hack of ethereum and the way in which this was dealt with as a good example thereof @xcite .",
    "the risks of cryptocurrencies discussed above suggest that there is value in also exploring alternative approaches , in which technical code for transactions is more centralized , governed or controlled by parties with specific interests or duties .",
    "for example , rscoin @xcite is proposed as a cryptocurrency in which central banks control monetary supply and where a number of distributed authorities prevent double - spending attacks .",
    "this addresses or mitigates risks of de - centralized , open cryptocurrencies but does support a more conventional model of currency control .",
    "there is also the question of whether a central bank would want to risk running any such system to scale up a currency nationally , given that such technical code may be subject to security vulnerabilities in configuration , implementation or lifecycle management .",
    "but such risks may be manageable .",
    "the oldest central bank , sweden s riksbank , for example , is actively considering whether or not to introduce a national cryptocurrency _ ekrona _ within the next two years @xcite .    in this paper ,",
    "we investigate how governed , closed blockchains can be designed so that they can support the resilient , distributed , and _ trustworthy _ storage of authentication of transactions within conventional financial processes .",
    "such governed systems with restricted access give us better control on balancing the use of energy for puzzle solving with the security of the proof of work algorithm when compared with open systems that rely on proof of work , such as bitcoin .",
    "specifically , we propose that transactions ( in the sense of bitcoin ) within blocks are hashes of transactions ( within conventional financial processes ) .",
    "we then define mathematical models that describe the design space of such a blockchain in terms of the cryptographic puzzle used    in this paper proof of work , in terms of expected availability , resiliency , security , and cost , and in terms that reflect that the system is centrally governed .",
    "we stress that our approach is also consistent with transactions within blockchains that encode transaction history , which we do nt consider in the use case of this paper .",
    "we believe that our approach has potential .",
    "it may , for example , allow designers to minimize the need for consensus mechanism by guaranteeing that puzzles have a unique winner within a certain period of time with very large probability whilst still maintaining sufficient system resiliency and security ; and this could inform the design of bespoke consensus protocols .    [ [ outline - of - paper . ] ] outline of paper",
    ". + + + + + + + + + + + + + + + + +    in section  [ section : usecase ] we present our use case . our mathematical model for proof of work in our setting is subject of section  [ section : probabilisticmodel ] .",
    "the derivation of optimization problems for these mathematical models is done in section  [ section : optimization ] .",
    "an algorithm for solving such optimization problems , experimental results , and a statistical validation of our model are reported in section  [ section : experiments ] , and the paper concludes in section  [ section : conclusion ] .",
    "the use case we consider is one of a financial process that creates financial transactions .",
    "we would like to enhance the trustworthiness of this process through a blockchain that records hash - based authentications of transactions , as seen in figure  [ fig : architecture ] , where the interaction between the legacy process and the blockchain is conceptually simple    and consistent with the use of double - entry bookkeeping if desired .",
    "our assumption is that the event streams of such transactions are not linearizable and so we can not rely on techniques such as hash chains  @xcite to obtain immutability of transactions .",
    "our data model represents a transaction as a string @xmath0 that can be authenticated with a hash @xmath1 .",
    "string @xmath0 may be a serialization of a transaction object that contains relevant information such as a time stamp of the transaction , a digital signature of the core transaction data and so forth .",
    "the trustworthiness of transaction @xmath0 is represented outside of the blockchain by the triple @xmath2    where @xmath3 is either the block height ( @xmath4 ) of a block @xmath5 in the blockchain such that @xmath1 occurs in block @xmath5 or @xmath3 is null , indicating that the transaction is not yet confirmed on the blockchain .",
    "the hashes @xmath1 of transactions that still need to be confirmed are propagated on the blockchain network , where they are picked up by miners and integrated into blocks for proof of work .",
    "we assume a suitable mechanism by which nodes that manage legacy accounts learn the blockheights of their transactions that have been successfully added to the blockchain .",
    "for example , such nodes may have a full copy of the blockchain and so update @xmath3 values in its accounts if the hash of the corresponding transaction occurs in a block that was just added .",
    "a transaction is unverified if its @xmath3 value is null or if its hash does not equal the one stored externally as in  ( [ equ : triple ] ) ; it is trustworthy if @xmath6 and @xmath7 where @xmath8 is a suitable constant and @xmath9 denotes the number of blocks added to the blockchain so far .",
    "the value of @xmath10 may be a function of how fast blocks are added to the chain on average , to ensure sufficient resiliency of trustworthiness .",
    "an auditor could then inspect any transaction by examining its triple stored as in  ( [ equ : triple ] ) . if @xmath3 equals null or",
    "if @xmath11 , the transaction is considered neither valid nor trustworthy by the auditor . otherwise , we have @xmath6 and @xmath12 and the auditor uses the merkle tree hash in block @xmath3 to verify that @xmath1 is in the block of height @xmath5 . if that is the case , the auditor considers the transaction to be verified ; otherwise , the auditor considers the transaction not to be trustworthy .",
    "a system architecture that could support such a use case is shown in figure  [ fig : architecture ] .",
    "unverified transactions have their hashes propagated on the network .",
    "miners pick up those hashes and integrate them into blocks for proof of work .",
    "we abstract away how miners manage their pools of hashes and how proof of work blocks are propagated and added to the blockchain ; this gives us flexibility in the use of blockchain technology .",
    "once blocks are added to the blockchain , blockheights are propagated to the legacy account .",
    "as mentioned above , these accounts could have full copies of the blockchain and thus implement their own update mechanisms for value @xmath3 in triples stored as in  ( [ equ : triple ] ) .    ]",
    "auditors would interface with both accounts and the blockchain to verify , in a trustworthy manner , the authenticity , that is to say the _ veracity _ , of transactions .",
    "any transaction that is not verified as discussed above would be flagged up in this audit .",
    "any pre - existing audit process    which may focus on compliance , regulations and other aspects",
    "  is consistent with such _ veracity checking _ ; and the trustworthiness of the pre - existing audit process would be increased as it would refuse to certify any financial transaction histories that involved a transaction that is not authenticated on the blockchain .",
    "the approach we advocate here is pretty flexible .",
    "it seems consistent with consensus mechanisms as used in bitcoin but it may also support 2-phase commitment schemes as proposed in @xcite .",
    "our system architecture allows for full nodes to be associated with accounts , sets of accounts or corporate boundaries .",
    "our blockchain does not create any currency , and so there is no inherent incentive to mine .",
    "but there is an incentive for the owners of this blockchain to allocate mining resources in a manner that establishes trustworthiness of transactions as recorded in this blockchain .",
    "we think that the elimination of incentives and their game - theoretic implications are a benefit , as are the relatively simple ways of propagating trust through hashes of transactions .",
    "such a blockchain may also be consulted by legacy systems to inform the authorization of further financial transactions .",
    "our blockchain does not spend any funds and so has no problem of _ double spending _ , and double spending in the legacy system would be detectable with existing mechanisms such as audits .",
    "our approach does allow for _ double authentication _ though : a transaction hash may occur more than once in a blockchain , be it in the same block or in different blocks .",
    "we deem this to be unproblematic as audits would only need to establish _ some _ , sufficiently old , authentication of the transaction in the blockchain to establish its trustworthiness    noting that hash - based authentication is deterministic .",
    "let us now briefly reflect on security issues for the system shown in figure  [ fig : architecture ] .",
    "there are various actors within that system : miners , nodes that run full copies of the blockchain , nodes that propagate transaction hashes to miners , auditors ( which may be insiders or external agents with limited inside access ) , insiders such as accountants and system administrators , external forces that seek to infiltrate these corporate networks , and so forth . here",
    "are possible scenarios of interest :    * internal auditors may want to corrupt the state of the blockchain in order to cover up the traces of internal fraudulent activity * external forces may want to corrupt transaction hashes propagated in the internal network as a denial of service attack on the blockchain itself * control over a set of miners or nodes that propagate transaction hashes may be obtained so that certain transaction hashes have priority for mining * classical security attacks such as those on key management may be launched .",
    "scenario s1 may be part of an insider attack in which skilled and sufficiently authorized insiders collude to commit fraud .",
    "the blockchain can not ensure that only legitimate transactions have their hash recorded within it .",
    "but a _ security policiy _",
    "  external to the blockchain    could specify that certain transactions are always recorded in the blockchain , for example , the hashes of security log entries that may be triggered by transactions within legacy accounts .",
    "scenario s2 is typical for a denial of service attack .",
    "the service that is being denied here is the blockchain , as the mechanism that creates sufficient trustworthiness into transactions as recorded within legacy system .",
    "these threats can be mitigated against , for example , legacy systems and the entire blockchain network may be placed behind a corporate firewall .",
    "scenario s3 is concerned with the management of transaction hashes that have not yet been recorded in the blockchain .",
    "the extent to which this is a security problem beyond that of service availability will depend on the use context of the legacy accounts .",
    "for example , for the attack discussed in scenario s1 it might help internal attackers to have control over which transaction hashes would enter the blockchain first , with a preference of recording the fraudulent transaction that changed the recipient of payments of the originally recorded transaction .    in scenario s4 ,",
    "a cyber attack may get control of the part of the system that provides authenticated information about the public keys of all used miners , for example , it might be able to learn a system admin key that allows for the modification of such information to change the private / public key pairs of miners to values of machines controlled by the attacker .",
    "security would certainly be improved in these and other scenarios if all actions of financial processes that modify accounts have their hashes recorded onto the blockchain , be these financial transactions , actions that create log entries , actions that give authority to perform financial transaction , and so forth . from this perspective , our blockchain could also facilitate a _",
    "audit  ",
    "not just one concerned with compliance and regulation .",
    "our model assumes a cryptographic hash function @xmath13 where @xmath14 such that @xmath15 has _ puzzle friendliness _",
    ". the _ level of difficulty _",
    "@xmath16 is an integer satisfying @xmath17 : proof of work has to produce some @xmath18 where @xmath19 has at least @xmath16 many leftmost @xmath20 bits .",
    "we write @xmath21 for the time to compute a sole hash @xmath19 and to decide whether it has at least @xmath16 leftmost zeros .",
    "since the range of @xmath16 will be relatively small , we make @xmath22 a device - dependent constant .",
    "our probabilistic modeling will treat @xmath15 in the _ random oracle model _ ( rom ) : function @xmath15 is chosen uniformly at random from all functions of type @xmath23 ; that is to say , @xmath15 is a deterministic function such that any @xmath18 for which @xmath15 has not yet been queried will have the property that @xmath19 is governed by a truly random probability distribution over @xmath24 .",
    "we may assume that @xmath18 consists of a block header which contains some random data field    a nonce @xmath25 of bitlength @xmath26 , that this nonce is initialized , and that the nonce is then increased by @xmath27 each time the hash of @xmath18 does not obtain proof of work . in particular , this yields that @xmath28 where @xmath29 : the input to @xmath15 will be of form @xmath30 where @xmath31 and @xmath25 have @xmath32 and @xmath26 bits , respectively .",
    "our use of rom will rely on the assumption that mining , be it by a sole miner or in a mining race of more than one miner , will never revisit the same input again :    [ assumption : mininginvariant ] the mining of a block with one or more miners will use an input to @xmath15 at most once , be it within or across miners input spaces .",
    "this assumption and appeal to rom give us that hash values are always uniformly distributed in the output space during a mining race .",
    "we now develop the probability space for mining with a sole miner , and then adapt this to the setting of more than one miner .",
    "our basic probability space has @xmath31 and @xmath16 as implicit parameters , and assumes the enumeration @xmath33 of values of @xmath25 without loss of generality .",
    "the set of basic events @xmath34 of this probability space is    @xmath35    where @xmath36 denotes the event that all @xmath37 nonce values failed to obtain proof of work for @xmath31 at level of difficulty @xmath16 , and @xmath38 models the event in which the first @xmath10 such nonce values failed to obtain proof of work for @xmath31 at level @xmath16 but the @xmath39th value of @xmath25 did render such proof of work for @xmath31 .",
    "we next want to define a discrete probability distribution @xmath40 $ ] with mass @xmath27 .",
    "now , we have @xmath41 since this is the fraction between the number of possible outputs that do proof of work at level of difficulty @xmath16 and the number of all possible outputs of @xmath15 .    to define @xmath42 for the case when @xmath43 , we first need to understand the probability @xmath44 of not obtaining proof of work for the first @xmath10 values of the nonce . for each value of @xmath25 , the probability that @xmath45 does not have @xmath16 or more leading zeros is @xmath46 . by rom and assumption  [ assumption : mininginvariant ] , these probabilities are independent from each other for each of these @xmath10 different values of @xmath25 and so @xmath47 follows . similarly , the probability that the @xmath39th hash attempt proves work is independent of whether or not any of the previous @xmath10 attempts did that  ",
    "mining never tries that same nonce value again .",
    "but then @xmath48 . we thus defined @xmath49 for events @xmath50 in @xmath51 such that @xmath52 .",
    "also , the mass of all those probabilities is less than @xmath27 :    @xmath53    but this equals @xmath54 and is therefore in @xmath55 since @xmath56 .",
    "thus , we obtain a probability distribution @xmath57 by setting @xmath58    which equals @xmath59 .      consider having @xmath60 many miners that run in parallel to find proof of work , engaging thus in a _ mining race_. we assume these miners run with the same configurations and hardware . in particular , the hash function @xmath15 and",
    "the values @xmath61 , @xmath62 , @xmath16 , @xmath26 , and @xmath22 will be the same for each of these miners .",
    "as already discussed , miners do not get rewarded :    [ assumption : miners ] miners are a resource controlled by the governing organization and have identical hardware . in particular , miners are not rewarded nor have the need for incentive structures .    but miners may be corrupted and misbehave , for example  they may refuse to mine . to simplify our analysis , we assume miners begin the computation of hashes in approximate synchrony :    [ assumption : synchronous ] miners start a mining race at approximately the same time .    for many application domains ,",
    "this is a realistic assumption as communication delays to miners would have a known upper bound that our models could additionally reflect if needed .",
    "next , we want to model the _ race _ of getting a proof of work where each miner @xmath63 has some data @xmath64 . to realize assumption  [ assumption : mininginvariant ]",
    ", it suffices that each miner @xmath63 have a nonce @xmath65 in a value space of size @xmath66 such that these nonce spaces are mutually disjoint across miners . to model this mining race between @xmath67 miners , we take the product @xmath68 of @xmath67 copies @xmath69 of our event space @xmath34 for mining with a sole miner , and quotient it via an equivalence relation @xmath70 on that product @xmath68 .",
    "the @xmath67-tuple @xmath71 models failure of this mining race , it is @xmath70 equivalent only to itself .    all @xmath67-tuples @xmath72 other than tuple @xmath71 model that the mining race succeeded for at least one miner .",
    "for such an @xmath67-tuple @xmath73 , the set of natural numbers @xmath10 such that @xmath38 is a coordinate in @xmath73 is non - empty and therefore has a minimum @xmath74 . given two @xmath67-tuples @xmath72 and @xmath75 both different from @xmath71 , we can then define @xmath73 and @xmath5 as @xmath70 equivalent iff @xmath76 .",
    "so two non - failing tuples are equivalent if they determine a first ( and so final ) proof of work at the same round of the race .",
    "this defines an equivalence relation @xmath70 and adequately models a synchronized mining race between @xmath67 miners . in the setting of @xmath60 miners , the interpretation of events @xmath38 of @xmath34 in  ( [ equ : basicevents ] )",
    "is then the equivalence class of all those tuples @xmath73 for which @xmath74 is well defined and equals @xmath10 : all mining races that succeed first at round @xmath10 .",
    "the meaning of @xmath36 is still overall failure of the mining race , the equivalence class containing only tuple @xmath71 .",
    "next , we set @xmath77 as the size of the nonce space for each of the @xmath67 miners , and define accordingly the set of basic events for @xmath67 miners as    @xmath78    in  ( [ equ : es ] ) , expression @xmath38 denotes an element of the quotient @xmath79 , the equivalence class of tuple @xmath80 .",
    "also , @xmath81 restricts the set of non - failure events from @xmath34 in  ( [ equ : basicevents ] ) to those with @xmath82 .",
    "next , we define a probability distribution @xmath83 over @xmath81 , consistent with the definition of @xmath57 over @xmath34 when @xmath67 equals @xmath27 . to derive the probability @xmath84 ,",
    "recall @xmath85 as the probability that a given miner does not obtain proof of work at level @xmath16 in the first @xmath10 rounds . by assumption  [ assumption : mininginvariant ] , these miners work independently and over disjoint input spaces . by rom , the expression @xmath86^ s = ( 1 - 2^{-d})^{k\\cdot s}$ ] therefore models the probability that none of the @xmath67 miners obtains proof of work in the first @xmath10 rounds . appealing again to rom and assumption  [ assumption : mininginvariant ] , the behavior at round @xmath39 is independent of that of the first @xmath10 rounds . therefore , we need to multiply the above probability with the one for which at least one of the @xmath67 miners will obtain a proof of work in a single round .",
    "the latter probability is the complementary one of the probability that none of the @xmath67 miners will get a proof of work in a sole round , which is @xmath87 due to the rom independence .",
    "therefore , we get @xmath88\\ ] ]    this defines a probability distribution with a non - zero probability of @xmath36 .",
    "firstly , @xmath89 $ ] is in @xmath55 : that sum equals @xmath90\\cdot\\frac{1-[(1 - 2^{-d})^s]^{\\lambda+1}}{1-(1 - 2^{-d})^s } = 1-(1 - 2^{-d})^{s\\cdot(\\lambda+1)}\\ ] ]    and since @xmath91 , the real @xmath92 is in the open interval @xmath55 , and the same is true of any integral power thereof .",
    "secondly , @xmath83 becomes a probability distribution with the non - zero probability @xmath93 being @xmath94 , that is @xmath95    this failure probability basically equals that for @xmath96 , an artefact of our parameter representation : for example , if each miner has @xmath97 bits of nonce space , then our model would have @xmath98 , so failure probabilities do decrease as @xmath67 increases .",
    "we want to optimize the use of @xmath60 miners using a level of difficulty @xmath16 , and a bit size @xmath26 of the global nonce space with respect to an objective function .",
    "the latter may be a cost function , if containing cost is the paramount objective or if a first cost estimate is sought that can then be transformed into a constraint to optimize for a security objective , as seen further below .",
    "higher values of @xmath16 add more security : it takes more effort to mine a block and so more effort to manipulate the mining process and used consensus mechanism .",
    "but lower values of @xmath16 may be needed , for example , in high - frequency trading where performance can become a real issue .",
    "we want to understand such trade - offs .",
    "moreover , we want to explore how the corruption of a number of miners or inherent uncertainty in the number of deployed miners or in the level of difficulty across the lifetime of a system may influence the above tradeoffs .",
    "we will use tools from robust optimization  @xcite and functional programming to analyze such issues .",
    "the flexibility of our approach includes the choice of objective function for optimization .",
    "let us first consider an objective function @xmath99    that models cost as a function of the number of miners @xmath67 , the bit size of the nonce @xmath26    implicit in random variable @xmath100 , and the level of difficulty @xmath16 ; where we want to _ minimize _ cost .",
    "the real variable @xmath101 models the _ variable _ cost of computing _",
    "one _ hash for _ one _ miner , reflecting the device - dependent speed of hashes and the price of energy .",
    "the real variable @xmath102 models the _ fixed _ costs of _ having one miner _ ; this can be seen as modeling procurement and depreciations . variables @xmath67 , @xmath26 , and @xmath16 are integral , making this a _ mixed integer _",
    "optimization problem @xcite .",
    "the expression @xmath100 denotes the _ expected number of rounds _ needed to mine a block in a mining race that uses @xmath67 miners , level of difficulty @xmath16 , and nonce bitsize @xmath26 .",
    "the derivation of this expression below shows that it is non - linear , making this a minlp optimization problem @xcite .",
    "we chose not to include in @xmath101 a constant that reflects how many blocks may be mined within a system horizon of interest but this can easily be done within our proposed approach , for example when there is a constraint on the carbon footprint of a system during its lifetime .",
    "we may of course use other objective functions .",
    "one of these is simply the expression @xmath16 , which we would seek to _ maximize _ , the intuition being that higher values of @xmath16 give us more trust into the veracity of a mined block and the blockchains generated in the system .",
    "figure  [ fig : firstopt ] shows an example of a set of constraints and optimizations of security and cost for this .",
    "@xmath103    integer constants @xmath104 and @xmath105 provide bounds for variable @xmath67 , and similar integer bounds are used to constrain integer variables @xmath26 and @xmath16 .",
    "the constraint for @xmath106 uses it as upper bound for the probability of a mining race failing to mine a block .",
    "the next two inequalities stipulate that the expected time for mining a block is within a given time interval , specified by real constants @xmath107 and @xmath108 .",
    "the real constant @xmath109 is an upper bound for @xmath110 , the probability that more than one miner finds pow within @xmath111 seconds in the same , synchronous , mining race .",
    "the constraint for real constant @xmath112 says that the probability @xmath113 of the _ actual _ time for mining a block being above a real constant @xmath114 is bounded above by @xmath112 .",
    "this constraint is of independent interest : knowing that the expected time to mine a block is within specified bounds may not suffice in systems that need to assure that blocks are _ almost always _ ( with probability at least @xmath115 ) mined within a specified time limit . some systems may also need assurance that blocks are almost always mined in time _ exceeding _ a specified time limit @xmath116 .",
    "we write @xmath117 to denote that probability , and add a dual constraint specifying that the actual time for mining a block has a sufficiently small probability @xmath118 of being faster than some given threshold @xmath116 .",
    "we derive analytical expressions for random variables occurring in figure  [ fig : firstopt ] . beginning with @xmath100",
    ", we have @xmath119 which we know to be equal to @xmath120\\cdot ( k+1)$ ] .",
    "we may rewrite the latter expression so that summations are eliminated and reduced to exponentiations : concretely , we rewrite @xmath121 to @xmath122 summations , each one starting at a value between @xmath20 and @xmath123 , where we exploit @xmath124 .",
    "this renders @xmath125    where we use the abbreviation @xmath126    the expected time needed to get a proof of work for input @xmath31 is then given by @xmath127    we derive an analytical expression for the above probability @xmath113 next .",
    "note that @xmath128 models that the actual time taken for @xmath39 hash rounds is larger than @xmath114 .",
    "therefore , we capture @xmath113 as @xmath129 & = & { } \\nonumber\\\\ ( 1 - 2^{-d})^{s\\cdot ( \\lceil ( th / t ) -1\\rceil + 1 ) } - ( 1- 2^{-d})^{s\\cdot ( \\lambda+1 ) } & = & { } \\nonumber\\\\ y^{\\lceil ( th / t ) -1\\rceil + 1 } - y^{\\lambda+1 } & { } & \\nonumber\\end{aligned}\\ ] ]    assuming that @xmath130 , the latter therefore becoming a constraint that we need to add to our optimization problem .",
    "one may be tempted to choose the value of @xmath112 based on the markov inequality , which gives us @xmath131    but we should keep in mind that upper bound @xmath132 depends on the parameters @xmath67 , @xmath26 , and @xmath16 ; for example , the analytical expression for @xmath100 in  ( [ equ : noranalytical ] ) is dependent on @xmath123 and so dependent on @xmath26 as well . the representation in  ( [ equ : moretimes ] ) also maintains that expression @xmath133    is in @xmath134 $ ] , i.e.  a proper probability . since @xmath135 is in @xmath55 , this is already guaranteed if @xmath136 , i.e.  if @xmath137 .",
    "but we already added that constraint to our model .",
    "similarly to how we proceded for @xmath113 , we get @xmath138    which needs @xmath139 as additional constraint .    to derive an analytical expression for @xmath110 , each miner can perform @xmath140 hashes within @xmath111 seconds .",
    "let us set @xmath141 .",
    "the probability that a given miner finds pow within @xmath111 seconds is @xmath142 = 2^{-d}\\cdot [ 1 - z]\\ ] ]    therefore , the probability that no miner finds pow within @xmath111 seconds is @xmath143\\bigr ) ^s = \\bigl ( 1 -   2^{-d}\\cdot [ 1 - z]\\bigr ) ^s\\ ] ]    the probability that exactly one miner finds pow within @xmath111 seconds is @xmath144\\bigr ) ^{s-1 } \\cdot 2^{-d}\\cdot [ 1 - z]\\ ] ]    thus , the probability that more than one miner finds pow within @xmath111 seconds is @xmath145    then we can calculate @xmath110 to be equal to @xmath146)^{s-1}\\cdot \\bigl [ 1 + ( s-1)\\cdot 2^{-d}\\cdot [ 1-z]\\bigr ] \\ ] ]    figure  [ fig : firstoptexplicit ] shows the set of constraints @xmath147 from figure  [ fig : firstopt ] with analytical expressions and their additional constraints , we add constraint @xmath148 to get consistency for the analytical representation of @xmath110 .",
    "@xmath149)^{s-1}\\cdot \\bigl [ 1 + ( s-1)\\cdot 2^{-d}\\cdot [ 1-z]\\bigr ] \\nonumber \\ ] ]      our model above captures design requirements or design decisions as a set of constraints , to optimize or trade off measures of interest subject to such constraints .",
    "we can extend this model to also _ manage uncertainty _ via robust optimization  @xcite . such uncertainty",
    "may arise during the lifetime of a system through the possibility of having corrupted miners , needed flexibility in adjusting the level of difficulty , and so forth .",
    "for example , corrupted miners may refuse to mine , deny their service by returning invalid block headers , pool their mining power to get more mining influence or they may simply break down .    consider @xmath150 corrupted miners .",
    "we can model their _ pool power _ by appeal to rom and the fact that the mining race is roughly synchronized : the probability that these @xmath151 miners win @xmath152 many subsequent mining races is then seen to be @xmath153 .",
    "we can therefore bound this with a constant @xmath154 , or equivalently we can add to the set of constraints @xmath147 from figure  [ fig : firstoptexplicit ] the constraint @xmath155 .",
    "we model uncertainty in the number of miners available by an integer constant @xmath156 as follows : if @xmath67 miners are deployed , then we assume that at least @xmath157 and at most @xmath67 many miners participate reliably in the mining of legitimate blocks .",
    "therefore , @xmath156 allows us to model aspects such as denial of service attacks or a combination of such attacks with classical faults : for example , @xmath158 subsumes the scenario in which one miner fails and two miners mine invalid blocks .",
    "furthermore , an integer constant @xmath159 models the uncertainty we have in the deployed level of difficulty @xmath16 : the intuition is that our analysis should give us results that are robust in that they hedge against the fact that any of the values @xmath160 satisfying @xmath161 may be the actually running level of difficulty .",
    "this enables us to understand a design if we are unsure about which level of difficulty will be deployed or if we want some flexibility in dynamically adjusting the value of @xmath16 in the running system .",
    "the corresponding robust optimization problem for cost minimization is seen in figure  [ fig : robustcost ] .",
    "it adds to the constraints we already consider the requirements on constants @xmath151 , @xmath162 , and @xmath154 as well as the constraint @xmath155 .",
    "the robustness of analysis is achieved by a change of the objective function from @xmath163 to @xmath164    the latter computes a worst - case cost for triple @xmath165 where @xmath67 and @xmath16 may vary independently subject to the strict uncertainties @xmath156 and @xmath159 , respectively .",
    "we call a triple @xmath165 _ feasible _ if it satisfies all constraints of its optimization problem .",
    "costs such as the one in  ( [ equ : robustcost ] ) for a triple @xmath165 are only considered for optimization if all triples @xmath166 used in the robust cost computation in  ( [ equ : robustcost ] ) are feasible",
    "  realized with predicate @xmath167 : robust optimization guarantees @xcite that the feasibility of solutions is invariant under the specified uncertainty ( here @xmath156 and @xmath159 ) .",
    "we submitted simple instances of the optimization problem in figure  [ fig : robustcost ] to state of the art minlp solvers .",
    "all these solvers reported , erroneously , in their preprocessing stage that the problem is infeasible .",
    "these solvers were not designed to deal with problems that combine such small numbers and large powers , and rely on standard floating point implementations .",
    "therefore , we wrote a bespoke solver in haskell that exploits the fact that we have only few integral variables so that we can explore their combinatorial space completely to determine feasibility .",
    "[ fig : algorithm ]      we solve the robust optimization problem for the analytical expressions we derived above with the algorithm depicted in figure  [ fig : algorithm ] .",
    "this algorithm has as input the set of constraints , a parameter @xmath62 and a parameter @xmath169 .",
    "it will output at most @xmath62 robustly feasible tuples @xmath170 from a list of all robustly feasible such tuples as follows : it will identify the maximal values of @xmath16 for which such tuples are robustly feasible , and it will report exactly one such tuple for each value of @xmath16 where @xmath26 is minimal , and @xmath171 is minimal whilst also bounded above by @xmath172 where @xmath173 is the globally minimal cost .",
    "this also determines the values of @xmath67 in these tuples and so the algorithm terminates .",
    "now , having defined the required analytical expressions and the algorithm to report the best @xmath62 robustly feasible tuples in figure  [ fig : algorithm ] , we also want to validate these expressions and the algorithm experimentally .",
    "our setup for this is based on pure haskell code , as functional    and in particular  ",
    "haskell programs offer the advantages of being modular in the dimension of functionality , being strongly typed as well as supporting an easy deconstruction of data structures , particularly lists  @xcite .",
    "furthermore , the arbitrary - precision verification is handled by the external @xmath174 package , which is also written in haskell .",
    "further verification and validation of the received results is pursued by unit testing using an arbitrary precision calculator .",
    "moreover , our experiments ran on a machine with the following specifications : intel(r ) xeon(r ) cpu e5 - 4650 with 64 cores and 2.70ghz and 64 gb ram on each core .",
    "@xmath175    we instantiate the model in figure  [ fig : robustcost ] with the constants shown in table  [ table : const ] .",
    "we choose @xmath22 to be @xmath176 for a mining asic from early 2016 with an estimated cost of 2700 usd at that time , so a fixed cost of @xmath177 usd seems reasonable .",
    "let us now explain the value @xmath178 , which models the energy cost of a sole hash ( we can ignore other costs on that time scale ) .",
    "a conservative estimate for the power consumption of an asic is @xmath179 watts per gigahashes per second , i.e.  @xmath179 watts per @xmath180 .",
    "we estimate the cost of one kilowatt hour @xmath181 to be about @xmath179 cents .",
    "a @xmath181 is @xmath182 times @xmath183 and one @xmath183 is @xmath184 watts .",
    "so @xmath179 watts per @xmath180 equals @xmath185 watts , which amounts to @xmath186 .",
    "so the cost for this is @xmath187 cents per hour , i.e. @xmath188 cents per hour .",
    "but then this costs @xmath189 cents per second .",
    "the price for a sole hash is therefore @xmath190 divided by @xmath191 , which equals @xmath192 .",
    "we insist on having at least @xmath193 miners and cap this at @xmath194 miners . the _ shared _ nonce space for miners is assumed to be between @xmath195 and @xmath97 bits .",
    "the level of difficulty is constrained to be between @xmath193 and @xmath97 .",
    "we list optimal tuples that are within a factor of @xmath196 of the optimal cost .",
    "we make the value @xmath116 irrelevant by setting @xmath197 which makes the constraint for @xmath116 vacuously true .",
    "the probability for mining failure is not allowed to exceed @xmath198 .",
    "setting @xmath199 means that we do nt insist on the average mining time to be above any particular positive time .",
    "the probability that mining a block takes more than @xmath200 seconds is bounded by @xmath201 . and the probability that more than one miner finds pow within @xmath202 seconds is also bounded by @xmath201 .",
    "the algorithm reports the top @xmath203 optimal tuples    and reports fewer if there are no @xmath204 feasible tuples .",
    "the remaining constants for robustness are as given in figure  [ fig : robustcost ] .",
    "let us now specify some values of @xmath108 of interest . as reported in @xcite ,",
    "bitcoin is believed to handle up to @xmath205 transactions per second , paypal at least @xmath206 transactions per second ( which we take as an average here ) , and visa anywhere between @xmath207 and @xmath208 transactions per second on average . by _",
    "transactions per second _ we mean that blocks are mined within a period of time consistent with this .",
    "of course , this depends on how many transactions are included in a block .",
    "for sake of concreteness and illustration , we take an average number of transactions in a bitcoin block , as reported for the beginning of april 2016 , that is @xmath209 transactions .    for a bitcoin style rate , but in our _ governed _ setting , this means that a block is mined in about @xmath210 seconds . since @xmath211 is the expected ( average ) time to mine a block , we can model that we have @xmath205 transactions per second on average by setting @xmath212 to be @xmath213 .",
    "similarly , we may compute @xmath214 and @xmath215 based on respective @xmath206 and @xmath208 transactions per second : @xmath216      [ [ transactions - per - second - as - in - bitcoin - paypal - and - visa . ] ] transactions per second as in bitcoin , paypal , and visa .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    we show in table  [ table : firstresults ] the top @xmath204 optimal robustly feasible tuples for the various values of @xmath108 in  ( [ equ : taus ] ) .",
    "we see that all three transaction rates per second can be realized with @xmath217 miners and a @xmath218-bit shared nonce space in our governed setting .",
    "the achievable level of difficulty ( within the uncertainty in @xmath156 and @xmath159 ) drops from @xmath219 for the bitcoin style rate to @xmath220 for a paypal style rate , and down to @xmath221 for a visa style rate .",
    "@xmath222    let us see what changes if we keep all constants as above but now @xmath223    this models that the probability that more than two miners find pow within @xmath224 seconds , as well as the probability of mining to take more than @xmath224 seconds , are very small .",
    "we now only report the changes to the results shown in table  [ table : firstresults ] for the top rated , optimal tuple . for @xmath212 , the level of difficulty drops from @xmath219 to @xmath225 but there are still @xmath217 miners and a shared nonce space of @xmath218 bits .",
    "this tuple @xmath226 is also optimal for @xmath214 now , whereas the problem now becomes infeasible for @xmath215 .",
    "we may explore the _ feasibility boundary _ for @xmath108 given the values of all other constants as just discussed : the optimization problem is infeasible for @xmath227 but becomes feasible when @xmath108 equals @xmath228 .",
    "next , let us keep the constants as in  ( [ equ : smalldeltas ] ) but where we now change @xmath229 to @xmath230 , decreasing the probability that corrupt miners can win @xmath231 consecutive mining races .",
    "the optimal robustly feasible tuple for @xmath212 is @xmath232 where cost is again rounded up for three decimal places .",
    "this increase of @xmath154 therefore requires @xmath233 more miners , @xmath27 more bit of shared nonce space , but can still realize @xmath225 as level of difficulty .",
    "this same tuple is also optimal for @xmath214 whereas the problem remains infeasible for @xmath215 .",
    "[ [ larger - transaction - rates - per - second . ] ] larger transaction rates per second .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    in our next experiment we want to vary the average number of transactions in a block from @xmath209 to larger values .",
    "this is sensible for our use case as transactions only record a hash , which may be @xmath233 bytes each .",
    "these results are seen in table  [ table : secondresults ] for @xmath234 transactions on average in a block with the constants as in table  [ table : const ] again .",
    "let us discuss the impact of changing the average number of transactions in a block from @xmath209 to @xmath234 .",
    "this has no impact when @xmath205 transactions per second are desired , the level of difficulty increases by @xmath235 from @xmath220 to @xmath219 for @xmath206 transactions per second , and the level of difficulty increased by @xmath204 from @xmath221 to @xmath236 for @xmath208 transactions per second .",
    "this quantifies the security benefits of packing more transactions into a block for mining throughput .",
    "@xmath237    let us now see how these results change when we set @xmath112 and @xmath109 to @xmath238 as in  ( [ equ : smalldeltas ] ) .",
    "the optimal tuples still have @xmath217 miners and a shared nonce space of @xmath218 bit .",
    "but for bitcoin style rate @xmath205 as well as for paypal style rate @xmath206 , the level of difficulty drops by @xmath193 from @xmath219 to @xmath225 whereas it drops by @xmath27 from @xmath236 to @xmath225 for a visa style rate of @xmath208 .",
    "note that these are the same results as for @xmath212 and @xmath214 but for @xmath215 this problem was infeasible .",
    "if we now change @xmath154 to @xmath230 and keep the values for @xmath112 and @xmath109 as in  ( [ equ : smalldeltas ] ) , then the optimal tuples are now the same ones as for @xmath212 and @xmath214 reported above ( respectively ) .",
    "this problem was infeasible for @xmath215 but is feasible now for @xmath239 with optimal tuple @xmath232 as for the other two cases .",
    "[ [ feasibility - boundary - for - transaction - rates - per - second . ] ] feasibility boundary for transaction rates per second .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    we now repeat the last experiment by varying the average number of transaction blocks from @xmath234 to half a million , in increments of @xmath234 . for @xmath240 as average number of transactions ,",
    "we redo the three experiments ( original constants in as table  [ table : const ] , larger @xmath241 as in  ( [ equ : smalldeltas ] ) , and larger @xmath242 with @xmath241 as in  ( [ equ : smalldeltas ] ) ) and can note only one change : for @xmath243 and the constants in table  [ table : const ] the level of difficulty increases by @xmath27 from @xmath236 to @xmath220 .",
    "all other values of @xmath170 stay the same in these three experiments ; there is no change whatsoever for @xmath244 and @xmath245 when @xmath246 is between @xmath247 and @xmath248 in increments of @xmath234 .",
    "when we increase the average number of transactions in a block to @xmath249 , we similarly see only one change for @xmath250 for the experiment with the constants in table  [ table : const ] such that the level of difficulty increases now by @xmath27 from @xmath220 to @xmath251 . increasing the average number of transactions in a block to @xmath252 does not change these results , but changing this number to @xmath253 also results in only one change : for the experiment with the constants in table  [ table : const ] the level of difficulty increases now by @xmath27 from @xmath251 to @xmath219 .",
    "none of the three experiments then result in any more changes when the average number of transactions per block changes to @xmath254 , @xmath255 , @xmath256 , @xmath257 or @xmath248 .",
    "[ [ transactions - per - second - for-500000-transactions - on - average - in - blocks . ] ] transactions per second for @xmath248 transactions on average in blocks .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    now we explore how many transactions per second can be processed when we have @xmath258 where @xmath259 is the desired number of transactions processed per second .",
    "table  [ table : thirdresults ] shows the optimal robustly feasible tuple for the experiment with constants as in table  [ table : const ] as a function of @xmath260 , except that @xmath261 as in  ( [ equ : smalldeltas ] ) and @xmath262 .",
    "this shows that for this higher average number of hashes recorded in a block , the rate of such hashes processed on the blockchain per second can span @xmath193 orders of magnitude without changing the optimal tuple of @xmath195 miners , @xmath263 bits of shared nonce space , and level of difficulty @xmath225 .    @xmath264    [ [ range - of - feasible - sizes - for - nonce - space . ] ] range of feasible sizes for nonce space .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    our tools can also compute and validate whether a robustly feasible tuple @xmath170 has any other values @xmath265 for which @xmath266 is robustly feasible .",
    "for example , for all the optimal tuples @xmath170 we computed above , we conclude that we may change @xmath26 to any @xmath265 satisfying @xmath267 .",
    "we will evaluate our model by comparing its random variables , represented in analytical form , with empirical counterparts generated through experiments .",
    "we make this comparison in terms of both absolute and relative error .",
    "we ran experiments consistent with assumptions  [ assumption : mininginvariant]-[assumption : synchronous ] to generate data for testing the random variables used in our model .",
    "specifically , for a triple @xmath165 we generated @xmath247 mining races with hash function _",
    "double sha-256 _ and recorded their outcome : either a failure of all @xmath67 miners to proof work for level of difficulty @xmath16 or an integer @xmath268 saying that mining took @xmath268 many rounds for proof of work with level of difficulty @xmath16 .",
    "the triples we studied where @xmath165 in @xmath269    the data we thus generated amount to three million and two - hundred thousand mining races .",
    "suppose , for a given @xmath165 , that @xmath151 of these @xmath247 outcomes where integers @xmath268 .",
    "then the _ empirical failure probability _ for triple @xmath165 equals @xmath270 . for the evaluation of @xmath100",
    ", we compute the arithmetic average @xmath271 of all @xmath268 values for a triple @xmath165 and compare this with the exact value of @xmath100 by computing the _ absolute _ error in  ( [ equ : absnor ] ) and the _ relative _ error in  ( [ equ : relnor ] ) @xmath272    we analyze the absolute error first : for each threshold value @xmath18 from @xmath273 , let @xmath274 be the set of all outcomes @xmath268 for all triples @xmath165 whose empirical or analytical failure probability ( i.e.  @xmath93 or @xmath270 ) is strictly less than @xmath18 .",
    "then for the set @xmath275    function @xmath276 , seen in figure  [ fig : absnor ] , renders a discrete graph of the maximal absolute error from set @xmath277 ; whereas function @xmath278 , named @xmath279 in the same figure , denotes the arithmetic average of the elements in @xmath277 . for the worst - case absolute errors , we see that they remain well below @xmath280 rounds , namely at about @xmath281 rounds for failure probabilities @xmath282 . in that range of failure probabilities ,",
    "the average absolute error is about @xmath283 rounds which is a very small difference . to illustrate , for the time @xmath284 to compute a sole hash used above",
    ", this would mean that the average absolute error for failure probability @xmath282 amounts to a time difference of about @xmath285 seconds .",
    "we did the same analysis for the relative error in  ( [ equ : relnor ] ) .",
    "for example , the relative maximal error is then about @xmath286 and the arithmetic average of relative errors is about @xmath287 .     and @xmath288 where @xmath279 is arithmetic average of @xmath277 in  ( [ equ : wx ] ) [ fig : absnor ] ]    in summary",
    ", we could show that the random variable @xmath100 accounts really well for our experimental data , and does so for failure probabilities that even extend into significant ranges such as a @xmath289 failure probability .",
    "but it also highlights that modelers need to be mindful of choosing values for @xmath106 in figure  [ fig : firstopt ] that wo nt invalidate the predictive value of random variables such as @xmath100 .",
    "clearly , for values of @xmath106 considered above , for example  @xmath238 , this is a non - issue .    for the evaluation of @xmath93 ,",
    "the absolute error is @xmath290    where @xmath151 is as above the number of successful mining races of @xmath247 overall such races for triple @xmath165 that defines @xmath93 .",
    "the worst - case , maximal , value of all absolute errors in  ( [ equ : fae ] ) ranging over all @xmath291 combinations of @xmath165 is about @xmath292 .",
    "the average of the absolute errors in  ( [ equ : fae ] ) for all these @xmath291 combinations is about @xmath293 .",
    "this shows that our model of failure probabilities is very precise , both in a worst - case and in a statistical average sense when compared to our experimental data .    for the evaluation of @xmath294 ,",
    "let the experiment for triple @xmath165 have been run on a machine which takes @xmath22 time ( in seconds ) to compute a sole hash .",
    "we use @xmath295 as a rough approximation of how long it takes to mine a block .",
    "then we set @xmath296 as a reasonable test value of @xmath114 , an increase of twenty percent .",
    "let @xmath246 be the number of times that a reported outcome @xmath268 for triple @xmath165    which defines @xmath294    satisfies @xmath297 .",
    "then we want to compute @xmath294 exactly as above , and compute the absolute error @xmath298    as the difference between the formal and the empirical probability .",
    "however , we only consider data for tuples @xmath165 for which the constraint @xmath130 is met ; otherwise , our computation of @xmath294 would result in negative and therefore unsound absolute errors .",
    "this is a valid evaluation approach since triples @xmath165 that violate @xmath130 would never contribute to optimizations in our models .",
    "the worst - case , maximal , absolute error ranging over all triples @xmath165 that satisfy @xmath130 is about @xmath299 .",
    "the arithmetic average of all these absolute errors is about @xmath230    which suggests a very good fit of our model with these experimental data .    for the evaluation of @xmath300",
    ", we now set @xmath301 as a reasonable test value of @xmath116 , a _ decrease _ of twenty percent .",
    "let @xmath302 be the number of times that values @xmath268 in our data for @xmath165    defining @xmath300    satisfies @xmath303 .",
    "we compute @xmath300 as above , and report the worst - case absolute error @xmath304    over all triples @xmath165 for which the empirical or analytical failure probability is strictly less than @xmath18 .",
    "the results , depicted in figure  [ fig : th1abs ] , show that for failure probabilities below @xmath305 the _ worst - case _ absolute errors are about @xmath306 and so very small .",
    "the worst - case absolute errors for larger failure probabilities are about @xmath307 .",
    "the arithmetic average of all these absolute errors is more variable in @xmath18 : it ranges from @xmath308 for @xmath309 to @xmath310 ( which is also the maximal arithmetic average over all @xmath18 considered ) for @xmath18 equal to @xmath27 ; and these are very small values .",
    "results for the corresponding relative error are of the same quality and so omitted .    ) for all triples @xmath165 with failure probability @xmath311 . graph _",
    "average _ shows the same result for arithmetic average of these absolute errors [ fig : th1abs ] ]    these findings above are evidence of the validity of our random variables and their use in our modelling approach .",
    "but they also highlight that failure probabilities of mining larger than 30% may require caution in using our approach .",
    "we emphasize that these experiments indirectly depended on security properties of the underlying hash function .",
    "the results for the statistical evaluation of @xmath110 will be included in a future version of this paper .",
    "in this paper we considered blockchains as a well known mechanism for the creation of trustworthiness in transactions , as pioneered in the bitcoin system @xcite .",
    "we studied how blockchains , and the choice and operation of cryptographic puzzles that drive the creation of new blocks , could be controlled and owned by one or more organizations .",
    "our proposal for such governed and more central control is that puzzle solvers are mere resources procured by those who control or own the blockchain , and that the solution of puzzles does not provide any monetary or other reward . in particular",
    ", a newly solved block will not create units of some cryptocurrency and there is therefore no inherent incentive in solving puzzles .",
    "the absence of incentives thus avoids the well known problems with game - theoretic behavior , for example that seen within and across mining pools in proof of work systems such as bitcoin .",
    "furthermore , it lends itself well to the development of proprietary or private blockchains that are _ domain - specific _ and whose specific purpose may determine who can access it and in what ways .",
    "we illustrated this idea with a use case in which financial transactions recorded within conventional accounts would be recorded as hashes within a governed blockchain and where it would be impractical to use hash chains , due to non - linearizability of transaction flows .",
    "a blockchain design should of course have specifications of its desired behavior , including but not limited to the expected time for creating a new block , resiliency against corruption of some of the puzzle solvers , service level guarantees such as a negligible probability that the time needed for creating a new block exceeds a critical threshold or a negligible probability that more than one solver does solve a puzzle within a specified period of time .",
    "we developed mathematical foundations for specifying and validating a crucial part of a governed blockchain system , the solving of cryptographic puzzles    where we focussed on proof of work . in our approach ,",
    "owners of a blockchain system can specify allowed ranges for the size of the shared nonce space , the desired level of difficulty , and the number of miners used ; and they can add mathematical constraints that specify requirements on availability , security , resiliency , and cost containment .",
    "this gives rise to minlp optimization problems that we were able to express in analytical form , by appeal to the rom model of cryptographic hash functions used for cryptographic puzzles .",
    "we then wrote an algorithm that can solve such minlp problems for sizes of practical relevance .",
    "we illustrated this on some instances of that minlp problem .",
    "this demonstrated that we have the capability of computing optimal design decisions for a governed proof of work system , where resiliency is modeled through robust optimization . this _ mining calculus _ also supports change management .",
    "for example , if we wanted to increase mining capacity and/or mining resiliency , our mathematical model could be used to determine how many new miners are needed to realize this    be it for the same or better hardware specifications . for another example",
    ", our tool could be used to determine optimal numbers of used miners or parameters by reacting to new energy prices .",
    "our approach and mathematical model are consistent with the consideration of several organizations controlling and procuring heterogeneous system resources , with each such organization having its bespoke blockchain , and with the provision of puzzle solving as an outsourced service .",
    "we leave the refinement of our mathematical models to such settings as future work .",
    "it will also be of interest to develop mathematical techniques for the real - time analysis of such blockchains , for example , to assess statistically whether the observed history of cryptographic puzzle solutions is consistent with the design specifications .",
    "we hope that the work reported in this paper will provoke more thinking about the design , implementation , and validation of blockchains that are centrally    or in a federated manner    owned and controlled and that may fulfill domain - specific needs for the creation of trustworthiness .",
    "we believe that many domains have such needs that the approach advocated in this paper might well be able to meet : existing financial processes and payment workflows ( which conventional cryptocurrencies are more likely to replace than to adequately support ) , trustworthiness of information in internet of things systems ( where the difficulty of the puzzle , for example , may have to be contained ) , but also systems that have governed blockchains at the heart of their initial design ( for example , a payment system in which the temporal and causal history of payments , logs , and audits is recorded on the blockchain ) .",
    "* acknowledgements : * this work was supported by the uk engineering and physical sciences research council with a doctoral training fees award for the first author and with projects [ grant numbers ep / n020030/1 and ep / n023242/1 ] .",
    "we expressly thank ruth misener for having run some of our models on state - of - the - art global minlp solvers  ",
    "the tools antigone @xcite , baron @xcite , and scip @xcite    to conclude that these solvers judge the models to be infeasible , although they are feasible ."
  ],
  "abstract_text": [
    "<S> we propose the formal study of governed blockchains that are owned and controlled by organizations and that neither create cryptocurrencies nor provide any incentives to solvers of cryptographic puzzles . </S>",
    "<S> we view such approaches as frameworks in which system parts , such as the cryptographic puzzle , may be instantiated with different technology . </S>",
    "<S> owners of such a blockchain procure puzzle solvers as resources they control , and use a mathematical model to compute optimal parameters for the cryptographic puzzle mechanism or other parts of the blockchain . </S>",
    "<S> we illustrate this approach with a use case in which blockchains record hashes of financial process transactions to increase their trustworthiness and that of their audits . for proof of work as cryptographic puzzle </S>",
    "<S> , we develop a detailed mathematical model to derive minlp optimization problems for computing optimal proof of work configuration parameters that trade off potentially conflicting aspects such as availability , resiliency , security , and cost in this governed setting . </S>",
    "<S> we demonstrate the utility of such a _ mining calculus _ by solving some instances of this problem . </S>",
    "<S> this experimental validation is strengthened by statistical experiments that confirm the validity of random variables used in formulating our mathematical model . </S>",
    "<S> we hope that our work may facilitate the creation of _ domain - specific _ </S>",
    "<S> blockchains for a wide range of applications such as trustworthy information in internet of things systems and bespoke improvements of legacy financial services .    * optimizing governed blockchains + for financial process authentications * + </S>"
  ]
}