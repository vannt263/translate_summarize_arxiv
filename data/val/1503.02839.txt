{
  "article_text": [
    "in wireless communications due to broadcast medium , transmissions by a user cause interference to other users . this reduces the transmission rate and/or increases the transmission error of the other users .",
    "therefore each user ( transmitter ) aims to use resources like , power and spectrum efficiently to improve its performance which may conflict with the goals of the other users .",
    "thus , in this paper , we present a game theoretic approach to obtain optimal power allocations that achieve an equilibrium among the different transmitters .",
    "we consider a single wireless channel which is being shared by multiple transmitter - receiver pairs .",
    "it is modeled as an interference channel .",
    "its power allocation in non - game theoretic setup has been studied in @xcite-@xcite and via game theory in @xcite-@xcite .",
    "power allocation for parallel gaussian interference channels is studied in @xcite .",
    "convergence of iterated best response for computing nash equilibrium under some conditions on the channel gains is studied for single antenna systems in @xcite , @xcite . in @xcite ,",
    "convergence of iterative water - filling for parallel gaussian interference channels with multiple antennas is studied .",
    "different algorithms are presented in @xcite , and @xcite to compute a nash equilibrium for parallel gaussian interference channels . in @xcite",
    ", we presented an algorithm to compute a nash equilibrium for a stochastic game on gaussian interference channels under channel conditions weaker those in @xcite .    in general , in a wireless communication system",
    ", a user may not have a knowledge about the other users channel states and their power policies .",
    "in such a setup , one needs distributed algorithms which each user can use to achieve optimal policies that require less information about the other users .",
    "online learning algorithms are such a class of algorithms @xcite .",
    "some of these algorithms , for example , fictitious play @xcite , are partially distributed algorithms that require some knowledge about other users strategies to find an equilibrium of the system . on the other hand , there exist fully distributed learning algorithms @xcite which do not need any information about the other users strategies or payoffs to find an equilibrium .",
    "we describe the prior work in the literature of wireless communications that has considered learning for optimal power allocation .",
    "the problem of minimizing energy consumption in point - to - point communication with delay constraints in stochastic and unknown traffic and channel conditions is considered in @xcite .",
    "this problem is modeled as a markov decision process and solved using online reinforcement learning .    in @xcite ,",
    "orthogonal multiple access channels are considered .",
    "the problem of power allocation is modeled as a non - cooperative potential game and distributed learning algorithms are proposed .",
    "a learning algorithm for finding a nash equilibrium for a multiple - input and multiple - output multiple access channel is proposed in @xcite .",
    "the problem of minimizing the total transmit power of a parallel gaussian interference channel subject to a minimum signal to interference plus noise ratio ( sinr ) is considered in @xcite . fully distributed algorithms based on trial and error are proposed to find a nash equilibrium and a satisfaction equilibrium .",
    "learning in wireless networks is also considered in the game theoretic framework in @xcite-@xcite .",
    "we refer to @xcite for more information on game theory and learning algorithms for wireless communications .    in @xcite , a learning algorithm using regrets",
    "is proposed to find a ce in a finite game .",
    "unlike fully distributed algorithms , this no - regret algorithm requires the knowledge of actions chosen by the other users from each play of the game .",
    "the same authors presented a fully distributed learning algorithm in @xcite that leads to a ce when the players are not aware of the functional form of their utility functions .",
    "fully distributed algorithms to find a nash equilibrium are developed in @xcite-@xcite .",
    "the algorithms in @xcite , @xcite are based on trial and error . using this algorithm users approach strategies that play a pure strategy nash equilibrium for a high portion of time . for",
    "potential and dominance solvable games , reinforcement learning algorithms in @xcite , @xcite converge to a ne .",
    "we consider a power allocation game on a wireless interference channel .",
    "it is neither a potential game nor dominance solvable .",
    "even existence of a pure strategy ne is not guaranteed .",
    "therefore , we can not use the algorithms in @xcite , @xcite to obtain an equilibrium point .",
    "thus we propose a variation of the regret matching algorithm to find a ce of the proposed game on the wireless communication system without knowing the strategies chosen by other users .",
    "the algorithms proposed in this paper is fully distributed .",
    "apart from learning a non - cooperative equilibrium , learning algorithms for finding a pareto point also exist in literature ( @xcite , @xcite ) .",
    "such points can substantially outperform a ce .",
    "we make the following contributions in this paper :    * we propose a fully distributed regret matching algorithm @xcite that finds a correlated equilibrium ( ce ) of the interference channel .",
    "the usual regret matching algorithm is a partially distributed algorithm which requires knowledge of the strategies of the other users .",
    "we propose a modification of that algorithm to convert it into a fully distributed algorithm .",
    "we also compare the sum rate at the ce obtained by our algorithm with that obtained from the algorithm in @xcite and we note that our algorithm converges faster than the algorithm in @xcite .",
    "* we use a fully distributed no - regret dynamics to compute a cce of our power allocation game . in general",
    ", every ce is a cce but the converse may not be true .",
    "* we propose a fully distributed learning algorithm to find a pareto point for our game and compare its sum rates with that of a ce . *",
    "even though pareto points outperform ce , and cce , fairness among users is not guaranteed at a pareto point . using a minor variation of the proposed algorithm to compute a pareto point",
    ", we compute a nash bargaining solution which guarantees fairness among users .",
    "* later , we show that we can use the proposed algorithms to compute ce , cce , pareto point and nash bargaining solutions when each transmitter sends at multiple rates rather than at a fixed rate .",
    "this paper is organized as follows . in section [ sm ]",
    ", we describe the system model and define the problem in game theoretic framework .",
    "we propose and analyse a learning algorithm to find a ce in section [ l_ce ] .",
    "for our game , we find pareto points through a fully distributed learning algorithm in section [ pt ] .",
    "we study nash bargaining solutions for our game in section [ nb ] .",
    "we use multiplicative weight algorithm to find cce of our game in section [ cce ] . in section [ m_rates ] , we extend the algorithms to the power allocation problem where each transmitter can transmit at multiple rates . in section",
    "[ ne ] , we compare the sum of utilities of all the users at a ce and at a pareto point and also with other algorithms also for some numerical examples . section [ concl ] concludes the paper .",
    "we consider a wireless channel being shared by @xmath0 independent transmitter - receiver pairs .",
    "transmission from each transmitter causes interference at other receivers .",
    "the transmitted signal from every transmitter undergoes fading .",
    "the fading gain experienced by the intended signal at a receiver from its corresponding transmitter is called the direct link channel gain .",
    "similarly , the fading gain experienced by other unintended signals at a receiver is called the cross link channel gain .",
    "we model this scenario as a gaussian interference channel with fading , where each receiver perceives the transmitted signal with additive white gaussian noise .",
    "let @xmath1 be the direct link channel gain alphabet and @xmath2 be the cross link channel gain alphabet of user @xmath3 .",
    "let the random variable @xmath4 denote the channel gain from transmitter @xmath5 to receiver @xmath6 in time slot @xmath7 which is assumed to be a constant during the slot .",
    "observe that @xmath8 , and @xmath9 for @xmath10 .",
    "we denote a realization of @xmath4 by @xmath11 .",
    "we assume that for a fixed @xmath12 the random variables @xmath13 , are independent and identically distributed .",
    "we also assume that @xmath4 are statistically independent for any @xmath14 , and @xmath15 .",
    "we assume that transmitter @xmath6 knows @xmath16 in the begin of slot @xmath7 but not @xmath4 , @xmath17 ; in fact it does not know the distribution of @xmath4 also .",
    "we also assume that transmitter @xmath6 has finite power levels @xmath18 to transmit in a slot .",
    "this is a typical wireless scenario .",
    "for example if , a receiver is sending an ack / nack to its transmitter and it is a time duplex channel , then a transmitter can estimate its direct link channel gain but will not know the cross link channel gains ; nor will it know the transmit powers used by the other transmitters .",
    "user @xmath6 transmits @xmath19 bits in every channel use at a power level which depends on the direct link channel gain .",
    "if receiver @xmath6 successfully receives the message sent in that slot , it sends an ack ( positive acknowledgment ) , else the receiver sends back an nack ( negative acknowledgement ) at the end of the slot .",
    "we assume that ack messages are small and sent at a low rate such that these are received with negligible probability of error and its transmission overheads are ignored .",
    "this is typically assumed @xcite .",
    "for a gaussian channel , the probability of error is a function of the received sinr and the modulation and coding used . for a given coding and modulation , we can fix a minimum sinr such that the probability of error is negligible above this sinr . to be specific",
    ", we assume that if in time slot @xmath7 , user @xmath6 transmitted @xmath19 bits per channel use at a power level @xmath20 @xmath21 and @xmath22 then , transmitter @xmath6 receives an ack from its corresponding receiver if and only if @xmath23 and the transmitter receives a nack , otherwise ; where @xmath24 is a constant that depends on the modulation and coding used by the @xmath6th receiver . in the following",
    "we will take @xmath25 for all @xmath6 for convenience .",
    "we consider stationary policies , i.e. , the power used by user @xmath6 in slot @xmath7 depends only on the channel gain @xmath16 but is independent of time @xmath7 . thus , we define the feasible action space of user @xmath6 by @xmath26 where @xmath27 is the probability distribution of @xmath16 .",
    "we note that user @xmath6 has an average power constraint @xmath28 for each feasible action .",
    "as the set of power levels of each user is finite , the number of elements in @xmath29 is also finite .",
    "let the cardinality of @xmath29 be @xmath30 .",
    "we enumerate the elements of @xmath29 as @xmath31 , i.e. , when we write @xmath32 , we mean @xmath33 is a feasible power policy of user @xmath6 for @xmath34 , and @xmath35 denotes the power used when the direct link channel gain is @xmath36 under the policy @xmath33 .",
    "we denote the action space of the set of all users by @xmath37 , and an action profile of all users by @xmath38 .",
    "we denote the action space of all users other than user @xmath6 by @xmath39 and the action profile of all users other than @xmath6 by @xmath40 .",
    "let @xmath41 indicate the action of user @xmath6 at time @xmath7 .",
    "also , @xmath42 . a strategy @xmath43 of user",
    "@xmath6 is a probability distribution on @xmath29 , and a pure strategy is a degenerate probability distribution where a certain action is chosen with probability one .    in a given time slot @xmath7",
    ", each user chooses an action that maximizes its probability of successful transmission .",
    "the strategy of each user influences the probability of successful transmission of every user and hence we are interested in finding an equilibrium point . to model this as a game , we define the reward of user @xmath6 for a given action profile @xmath44 in time slot @xmath7 with direct link channel gain @xmath45 as @xmath46 this reward of user @xmath6 in a given time slot @xmath7 is random as it depends on the cross link channel gains @xmath11 and the power levels @xmath47 at which the other users transmit in that slot , which in turn depend on the direct link channel gains of those users .",
    "the average reward of user @xmath6 for the action profile @xmath44 is @xmath48 by the strong law of large numbers this limit exists @xmath49 and average reward @xmath50 can be interpreted as the probability of successful transmission . the average reward of user @xmath6 given the",
    "strategy @xmath51 is @xmath52 u_i(k^{(i)},k^{(-i)}).\\ ] ] each player aims to maximize its own average reward or probability of successful transmission and we model this scenario as a stochastic game and restrict ourselves to stationary policies .",
    "then the utility of user @xmath6 can be written as @xmath53,\\label{ex_ut}\\ ] ] where the expectation is with respect to the distribution of random variables @xmath54 for all @xmath55 .",
    "thus the stochastic game is equivalent to the one - shot game in which user @xmath6 maximizes its utility defined in ( [ ex_ut ] ) and the set of correlated equilibria ( ce ) , defined below , for both of these games is same .    given a strategic game @xmath56 , a joint probability distribution @xmath57 is said to be a * correlated equilibrium * if for all @xmath58 , @xmath59 and @xmath40 , we have @xmath60 \\leq 0.\\label{def_ce}\\ ] ]    we get a correlated @xmath61-equilibrium if the zero in the above definition is replaced by @xmath61 .    to find a ce of a one - shot game ,",
    "a regret matching algorithm is proposed in @xcite .",
    "regret for user @xmath6 is defined in terms of utility @xmath62 and it is assumed that the functional form of utility @xmath62 is known to user @xmath6 . in this paper , we assume that user @xmath6 is not aware of functional form of @xmath62 but knows @xmath63 for each @xmath7 at the end of slot @xmath7 .",
    "we define regret in terms of @xmath64 and this definition is equivalent to the definition of regret in @xcite because , @xmath65 note that as the first summation in ( [ x_bf ] ) is finite , we can exchange summation and limit to get ( [ xchange ] ) .",
    "thus , @xmath66,\\label{reg}\\ ] ] where @xmath67 is the utility of user @xmath6 , that it would have received if the action @xmath68 is replaced by @xmath69 whenever it is played .",
    "similarly , we write @xmath70 to denote the reward of user @xmath6 , by playing @xmath69 instead of @xmath68 .",
    "we use the difference @xmath71 to define regret .",
    "thus the regret - matching algorithm in @xcite can be described as follows .",
    "the regret , @xmath72 where @xmath73 @xmath74 and @xmath75 denotes the actual interference experienced by user @xmath6 at time @xmath7 and @xmath76 is the upper bound on interference for successful transmission of user @xmath6 , and it is given by @xmath77    for every pair of pure strategies @xmath78 , the regret @xmath79 of a user is a nonnegative real number that reflects the change in utility received by the user if the choice of pure strategy @xmath68 is replaced with @xmath69 at every time instance that the user chose to play @xmath68 upto time @xmath80 .",
    "user @xmath6 chooses a pure strategy according to a probability distribution in which the probability of choosing an action is proportional to its regret .",
    "thus , user @xmath6 chooses a pure strategy according to the distribution @xmath81 for a sufficiently large @xmath82 .",
    "it is shown in @xcite that following the above procedure , the empirical frequencies of actions converge to the set of correlated equilibria .    to implement this algorithm each user @xmath6 not only needs to know its own actions ( transmit powers ) but also of the other users actions and its cross link channel gains ( to compute regret ) , which it does not know .",
    "thus , in the next section we modify this algorithm to find a correlated equilibrium where each user updates its strategy based on the rewards it received and the actions it chose in the past .",
    "the learning algorithm we propose is fully distributed in the sense that every user updates its strategy based on its own actions and rewards and independently of the other users strategies and rewards .",
    "we will show that the joint empirical distribution converges to the set of correlated equilibria with probability 1 for our algorithm .    in our problem",
    "as the transmitter is not aware of the interference at the corresponding receiver , it can not find the regrets as in ( [ regret_hm ] ) .",
    "therefore , each transmitter estimates regret by estimating the instantaneous reward based on the feedback it has received . the estimated reward is a function of the strategy @xmath69 , with respect to which we want to find the regret for not using @xmath69 instead of @xmath68 .",
    "if @xmath83 is the pure strategy that is actually chosen at a time @xmath7 and @xmath84 is the direct link channel gain at that time , then the actual interference perceived by its receiver is less than the threshold @xmath76 whenever the communication is successful and it is greater than @xmath76 whenever the communication is a failure . the user @xmath6 is optimistic in estimating the rewards for using @xmath69 instead of @xmath68 . to formally define the estimated reward we use the following notation . for each @xmath32 and @xmath85",
    ", @xmath86 user @xmath6 finds the instantaneous reward @xmath87 that could have been if user @xmath6 had used action @xmath88 instead of @xmath83 at time @xmath7 , as @xmath89    for every pair of actions @xmath90 , after @xmath80 slots , the regret @xmath91 is @xmath92 where @xmath93 @xmath94 and @xmath95 , the actual reward received by the user . if @xmath96 , i.e. , @xmath33 is the action chosen by user @xmath6 at time instant @xmath80 , then an action @xmath97 in time slot @xmath98 is chosen with probability , @xmath99 it should be noted that the quantities @xmath100 are the _ estimated _ values of reward and regret .",
    "we define the empirical frequency of strategies chosen upto time @xmath80 as @xmath101 it is shown in @xcite that the empirical frequency of strategies converges to the set of the correlated @xmath61-equilibria if and only if the actual regret @xmath79 converges to zero as @xmath102 .",
    "this can be formally stated as    [ prop_ce ] let @xmath103 be a sequence of actions chosen by the users . for any @xmath104 , @xmath105 for each user @xmath6 and every @xmath106 with @xmath107 , if and only if the sequence of empirical frequencies @xmath108 converges to the set of correlated @xmath61-equilibrium almost surely .    in proposition [ est_act ]",
    ", we prove that if the estimated regret @xmath109 converges to zero then the actual regret @xmath79 also converges to zero .",
    "[ est_act ] let @xmath103 be a sequence of actions chosen by the users . for each user @xmath6 and",
    "every @xmath110 with @xmath107 , if @xmath111 then @xmath112    to prove the proposition , we consider all @xmath7 such that @xmath113 and prove that @xmath114 for any given @xmath115 @xmath107 and given channel gain @xmath84 . here",
    ", we note that , if @xmath116 then @xmath117 .",
    "therefore ( [ step1 ] ) is satisfied and hence in the following we consider only the cases where @xmath118 .",
    "we now consider two cases separately : + _ case _ @xmath119 : @xmath120 + in this case , it should be noted that @xmath121 and as @xmath122 can be either @xmath123 or @xmath119 , ( [ step1 ] ) always holds .",
    "+ _ case _ @xmath124 : @xmath125 + in this case , if @xmath126 , then by definition @xmath121 and ( [ step1 ] ) always holds .",
    "if @xmath127 , then @xmath128 and hence @xmath129 . therefore we have @xmath130 and ( [ step1 ] ) is satisfied with equality .",
    "hence , ( [ step1 ] ) always holds and we have @xmath131 .",
    "therefore , @xmath132 , and , if @xmath91 converges to zero as @xmath80 approaches infinity , then @xmath79 also converges to zero .    in @xcite , authors have extended the regret - matching algorithm of @xcite so that one can use a function of the regret in the original procedure instead of regret , where the function satisfies certain conditions .",
    "we can not use that result here , as our estimation does not satisfy the conditions on the function .",
    "but we can generalize the result in @xcite .",
    "let the actual regret be defined as in ( [ regret_hm ] ) . let the actual utility @xmath133 in ( [ inst_reg ] ) be replaced by an estimated utility @xmath134 such that @xmath135 then following the regret - matching algorithm ( [ regret_hm])-([strgy1 ] ) with the actual",
    "regret @xmath79 replaced by the estimated regret @xmath91 , the estimated regret @xmath91 converges to zero as @xmath80 approaches infinity .",
    "following the proof of the main theorem in @xcite , we can show that for each @xmath68 and @xmath69 , the estimated regret @xmath91 converges to zeros as @xmath80 approaches infinity",
    ". therefore by proposition [ est_act ] , we get the following theorem .",
    "if each user chooses strategies in each time slot according to the algorithm ( [ proc_1])-([strgy ] ) , then the empirical frequency @xmath136 converges to the set of correlated @xmath137equilibria for any @xmath138 .    in the proof of the main theorem of @xcite , history up to time @xmath80",
    "is defined as the actions chosen by all users at time instances @xmath139 . to prove that the estimated regret converges to zero following the regret - matching algorithm",
    ", we just need to redefine the history up to time @xmath80 as the actions chosen by all users along with the direct channel states at time instances @xmath139 . with this definition of history ,",
    "the entire proof of the main theorem in @xcite , carries over and we can conclude that the estimated regret converges to zero",
    ".    the performance of the system at a ce may not be very satisfactory from the overall system point of view .",
    "therefore , we also provide a distributed algorithm in the next section which achieves a pareto point . the pareto points are socially optimal",
    "in this section , we compute a coarse correlated equilibrium which is a generalization of a correlated equilibrium .",
    "we present the multiplicative weight ( mw ) algorithm @xcite,@xcite to compute a cce of our power allocation game .",
    "mw algorithm has much less computational complexity per iteration than that of the regret matching algorithm presented in section [ l_ce ] .",
    "it also does not require estimation of regret as needed in section [ l_ce ] .",
    "also , it has been observed that the price of anarchy ( poa ) of a cce is no worse than that of a ce in a large class of games @xcite .",
    "however , it is also known that for some other classes of games , e.g. , congestion games , the poa of cce / ce can be larger compared to ne .    from the definition of ce ,",
    "condition ( [ def_ce ] ) requires that every user minimizes the conditional expectation of utility where the conditioning is on @xmath140 and @xmath68 . in cce ,",
    "user @xmath6 contemplates a deviation @xmath69 knowing only the distribution @xmath140 .",
    "let @xmath141 be the cost of user @xmath6 and each user chooses its action to minimize the cost . in our power allocation problem",
    ", we can define cost as negative of the utility , i.e. , @xmath142 .",
    "we define the cce of a cost minimization game as    a distribution @xmath140 on @xmath143 is said to be a * coarse correlated equilibrium * if @xmath144 \\leq { \\mathbb{e}}_{k \\sim \\phi}\\left[{c^{(i)}}({\\hat{k}^{(i)}},k^{(-i)})\\right],\\ ] ] for each user @xmath145 , and for all actions @xmath146 .",
    "the distribution @xmath140 is called a @xmath61-coarse correlated equilibrium if @xmath144 \\leq { \\mathbb{e}}_{k \\sim \\phi}\\left[{c^{(i)}}({\\hat{k}^{(i)}},k^{(-i)})\\right ] + \\epsilon,\\ ] ] for each user @xmath145 , for every action @xmath146 .",
    "please note that whenever the cost is a random variable , we denote it by @xmath147 rather than @xmath148 . in this definition",
    ", cost is a random variable that depends on the randomly chosen actions @xmath68 .",
    "every ce is also a cce and thus the set of cce is a larger set than the set of ce .",
    "there exist no - regret learning algorithms to compute a cce but the notion of regret used to compute a cce is different from that used to compute a ce . the regret defined in section [ sm ] is known as internal regret and we use external regret to compute a cce which is defined as    the regret of user @xmath6 given the pure strategy sequence @xmath149 with respect to an action @xmath68 is @xmath150.\\label{extn_regret}\\ ] ]    an algorithm in which users update their strategies based on the received cost in such a way that the external regret converges to zero is a no - regret algorithm .",
    "we now present a no - regret algorithm known as multiplicative weight algorithm to compute a cce .    in the initial iteration @xmath151 ,",
    "each user assigns a weight @xmath152 to action @xmath153 .",
    "user @xmath6 chooses an action @xmath68 with probability @xmath154 during the iteration @xmath7 , if @xmath68 is the action chosen by user @xmath6 in iteration @xmath7 , then it receives the expected utility @xmath155 $ ] . based on the received utility , user @xmath6 updates the weight @xmath156 of action @xmath68 , as @xmath157 for the iteration @xmath158 , user @xmath6 chooses an action according to ( [ prob_update ] ) with weights @xmath159 replaced by @xmath160 and this process is repeated .",
    "we have the following convergence result .",
    "following the multiplicative weight update algorithm , there exists a positive integer @xmath80 such that the external regret of user @xmath6 defined in ( [ extn_regret ] ) is less than @xmath61 after @xmath80 iterations .",
    "let @xmath161 denote the outcome distribution at time @xmath7 and @xmath162 .",
    "then @xmath140 is a @xmath61-coarse correlated equilibrium .",
    "we use this mw algorithm to find a cce of our power allocation game . in general to use the mw algorithm user @xmath6 needs to know the expected utility . in our game user @xmath6",
    "finds it given the history of actions and rewards as @xmath163,\\\\ & = & \\frac{1}{t}\\sum_{\\tilde{t}=1}^tw^{(i)}_{\\tilde{t}}({k^{(i)}},h_{ii}(\\tilde{t}))1_{k^{(i)}_{\\tilde{t } } = { k^{(i)}}}.\\end{aligned}\\ ] ] based on @xmath164 , user @xmath6 updates its weights using the mw update and chooses action according to ( [ prob_update ] ) with @xmath165 .",
    "unlike in the algorithm of ce , we do not need to evaluate the estimated reward as the mw algorithm does not explicitly depend on the regret defined in ( [ extn_regret ] ) .",
    "but the mw algorithm guarantees that the external regret converges to zero .",
    "hence we can apply the mw algorithm to our problem to find a cce .",
    "an action profile @xmath166 is * pareto optimal * if there does not exist another action profile @xmath167 such that @xmath168 for all @xmath58 with at least one strict inequality .    in this section",
    "we present a _ distributed _ algorithm to find a pareto optimal point .",
    "the global maximum of @xmath169 is a pareto optimal solution , where @xmath170 are positive constants @xcite .",
    "we find pareto points by finding a solution of ( [ pareto ] ) .",
    "we assume that when a receiver sends an ack / nack to its transmitter , all the other transmitters can also listen to it without error .",
    "this is realistic in many wireless systems because an ack / nack message is small and is usually transmitted at low rates with very low probability of error . under this assumption , we present a learning algorithm in which users may or may not choose to experiment and update their strategies in such a way that improves @xmath171 .",
    "the algorithm is as follows :    * each user @xmath6 chooses a random action @xmath68 uniformly from @xmath172 .",
    "all the users use these randomly chosen actions for a fixed number @xmath80 of time slots .",
    "each user @xmath173 follows the procedure below sequentially : * as user @xmath6 receives the feedback of other users , it finds the weighted sum @xmath174 of the utilities @xmath175 at the end of @xmath80 slots , user @xmath6 experiment with probability @xmath176 .",
    "when user @xmath6 experiments , with probability @xmath61 , chooses an action randomly with uniform probability from @xmath29 other than @xmath68 , and with probability @xmath177 it chooses an action other than @xmath68 in the following way : * * in the action @xmath68 , a power level has been specified for each value of direct link channel gain .",
    "user @xmath6 chooses an action randomly from a subset of @xmath29 , with feasible actions having higher power level than @xmath68 for a channel state with the highest probability of occurrence .",
    "if this subset is empty , then it chooses an action with higher power level for the channel gain with second highest probability of occurrence . * * if all the direct link channel gains occur with equal probability , then user @xmath6 chooses an action randomly from a subset of @xmath172 , with feasible actions having higher power level for the maximum value of direct link channel gain .",
    "if this subset is empty , it chooses an action with higher power level for the second maximum direct link channel gain . *",
    "let this new action be @xmath88 .",
    "for the next @xmath80 time slots , user @xmath6 uses action @xmath88 , and user @xmath5 uses actions @xmath178 for @xmath179 .",
    "user @xmath6 finds the weighted sum of the utilities of all the users @xmath180 . if @xmath181 , then user @xmath6 replaces its action @xmath33 with @xmath88 , and this new weighted sum of the average rewards is taken as a benchmark .",
    "if there is no improvement in the weighted sum of the average rewards , it randomly selects another action following the procedure described above .",
    "thus each user may experiment with upto a maximum of max number of actions chosen randomly .    if @xmath182 , each user experiments with randomly chosen actions .",
    "but , for small @xmath61 , in our algorithm we are selecting an action from the action space of that user by a _ local search_.",
    "the local search often yields a better point , that improves @xmath171 , than a purely random search in the entire action space , and yields a faster rate of convergence as seen in our numerical examples .",
    "a user updates its action whenever there is an improvement in the weighted sum of average reward over the benchmark .",
    "hence , this benchmark of utility is monotonically increasing and bounded above by @xmath183 . therefore , for a sufficiently large @xmath184 , we find a pareto optimal point with a large probability . by increasing max",
    ", this probability can be made arbitrarily close to @xmath119 .",
    "our algorithm is a distributed version of a meta heuristic , _ stochastic local search _",
    "@xcite , often used for global optimization .",
    "we can also obtain a pareto point which satisfies certain minimum probability of success ( e.g. , for voice users ) by including this constraint in the set @xmath185 .",
    "pareto points , although they globally maximize @xmath171 , may be _ unfair _ to some users .",
    "changing the weights @xmath170 can alleviate some unfairness .",
    "otherwise , one can obtain pareto points which are _ nash bargaining solutions _",
    "@xcite , which can be obtained via a similar algorithm as explained in the next section .",
    "in nash bargaining , we specify a disagreement outcome that specifies utility of each user that it receives by playing the disagreement strategy whenever there is no incentive to play the bargaining outcome . thus , by choosing the disagreement outcomes appropriately , the users can ensure certain fairness .",
    "the nash bargaining solutions are pareto optimal and also satisfy certain natural axioms @xcite .",
    "it is shown in @xcite that for a two player game , there exists a unique bargaining solution ( if the feasible region is nonempty ) that satisfies the axioms stated above and it is given by the solution of the optimization problem @xmath186 for an n - user nash bargaining problem , this result can be extended and the solution of an n - user bargaining problem is the solution of the optimization problem @xmath187    a nash bargaining solution is also related to proportional fairness , another fairness concept commonly used in communication literature .",
    "a utility vector @xmath188 is said to be _ proportionally fair _ if for any other feasible vector @xmath189 , for each @xmath190 , the aggregate proportional change @xmath191 is non - positive @xcite . if the set @xmath192 is convex , then nash bargaining and proportional fairness are equivalent @xcite .",
    "proportional fairness is studied in @xcite when @xmath192 is non - convex . in our case , @xmath192 is convex and hence nash bargaining solution is also proportionally fair .",
    "a major problem in finding a solution of a bargaining problem is choosing the disagreement outcome .",
    "it is more common to consider an equilibrium point as a disagreement outcome . in our problem",
    "we can consider the utility vector at a ce as the disagreement outcome .",
    "we can also choose @xmath193 for each @xmath6 .",
    "if we choose the disagreement outcome to be a ce , each user needs to evaluate a ce first before running the algorithm to find a solution of ( [ nb_n ] ) , which requires more computations .",
    "instead , we can choose the disagreement outcome to be the zero vector or by using the following procedure :    * each user chooses an action that gives higher power level to the channel state that has higher probability of occurrence .",
    "in other words , among the set of feasible actions , choose a subset of pure strategies that gives the highest power level to the channel state with highest probability of occurrence .",
    "we shrink the subset by considering the actions that give higher power level to the second frequently occurring channel state and we repeat this process until we get a single strategy . *",
    "if all the channel states occur with equal probability , we follow the above procedure by considering the value of the channel gain instead of the probabilities of occurrence of the channel gains .    let the pure strategy chosen by user @xmath6 be @xmath68 , and assume that the users use these strategies for a fixed number @xmath194 of slots .",
    "user @xmath6 finds @xmath195 by averaging the rewards received in the @xmath194 slots , i.e. , @xmath196    for our numerical evaluations we have chosen the disagreement outcome following the procedure described above instead of choosing the zero vector . to find the bargaining solution , i.e. , to solve the optimization problem ( [ nb_n ] ) , we use the algorithm of section [ pt ] used to find a pareto optimal point but with objective @xmath171 defined as @xmath197 in section [ ne ] , we present a nash bargaining solution for the numerical examples we consider , and observe that the nash bargaining solution obtained is a pareto optimal point which provides fairness among the users .",
    "until now , we have presented learning algorithms to compute a ce , a cce , pareto points and nash bargaining solutions , when a user is transmitting at a fixed rate . in this section ,",
    "we generalize the model so that a user can transmit at multiple rates rather than at a fixed rate and show that we can still use the same algorithms to compute equilibria .",
    "let @xmath198 be the set of possible transmission rates of user @xmath6 .",
    "let @xmath199 be the set of power levels for user @xmath6 , as considered earlier .",
    "we denote the new strategy set as @xmath200 the cardinality of @xmath201 is @xmath202 times that of @xmath203 , as every action @xmath204 can be associated with each rate in @xmath205 . we enumerate the elements of @xmath201 as in section [ sm ] . here also we denote an action by @xmath206 , and @xmath207 is the rate of transmission under the action @xmath68",
    ". if @xmath208 is the direct link channel gain of user @xmath6 and the user chooses action @xmath68 , then it transmits at a rate @xmath207 with power @xmath209 .",
    "user @xmath6 receives an ack if the interference at receiver @xmath6 satisfies @xmath210 and it receives a nack otherwise .",
    "we use the same notation @xmath211 to denote the upper bound on the interference for receiving an ack .",
    "we can redefine the estimated reward and estimated regret as in ( [ est_reward ] ) and ( [ est_regret ] ) respectively , but with the threshold redefined as @xmath212    it can easily be seen even in this case that the estimated reward @xmath213 is greater than or equal to the actual reward @xmath133 .",
    "hence , we can use the regret - matching algorithm to compute ce for the game with @xmath201 as the strategy set .",
    "we can also use the respective algorithms mentioned earlier to compute pareto points , nash bargaining solution , and cce .",
    "we can ensure that these solutions satisfy certain minimum rates by limiting our overall action space to strategies that satisfy these rate constraints .",
    "in this section we consider three examples with three transmitter - receiver pairs in the communication system . in the first example , we consider a symmetric scenario where @xmath214 and @xmath215 for each user @xmath6 , and each channel state occurs with equal probability .",
    "the set of possible power levels for each player is @xmath216 .",
    "each user transmits at a rate of @xmath217 bits per channel use , and receives feedback from its receiver .",
    "each user follows the learning algorithm ( [ proc_1])-([strgy ] ) to find a ce , and finds a pareto optimal strategy as described in section [ pt ] . in finding the pareto points ,",
    "we choose @xmath218 for all @xmath6 .",
    "the sum rate at a ce and at a pareto point are compared in figure [ fig_1 ] .",
    "we also compare the sum rate at a ce obtained by using the reinforcement learning ( rl ) algorithm in @xcite .",
    "we observe that the sum rates at ce obtained via our algorithm and that obtained via the algorithm in @xcite almost coincide in this example .",
    "even though the sum rates are close for both the algorithms , we observe that our algorithm convergences faster than the rl algorithm . in the rl algorithm",
    ", it is required that each pure strategy of each user should be played for a minimum number of time slots to find the regret as defined in @xcite .",
    "thus the algorithm requires a larger number of iterations to converge to the set of correlated equilibria . in this example , at snr of 15db , our algorithm converges in about @xmath219 iterations , whereas the algorithm in @xcite converges in about @xmath220 iterations .    in finding a pareto point ,",
    "if we randomly choose a strategy @xmath221 each time , instead of local search , the algorithm runs for about @xmath222 iterations whereas our local search algorithm finds a pareto point in @xmath223 iterations .",
    "we also plot in figure [ fig_1 ] the sum rate at a stochastically stable point of the trial and error based algorithm ( te ) in @xcite .",
    "it is known from @xcite that the algorithm therein converges to an efficient ne only if the game under consideration has at least one pure strategy ne . in general",
    ", we can not guarantee existence of a pure strategy ne for our game , and hence the stochastically stable point computed by the algorithm in @xcite need not be a ne .",
    "then the algorithm produces stochastically stable points that maximize @xmath224 for all @xmath166 where @xmath225 , and @xmath226 we refer to @xcite for further details of the function @xmath227 .",
    "we also plot the sum rate at the cce and at the nash bargaining solution obtained for example 1 in figure [ fig_1 ] .",
    "we observe that the sum rate at a cce is better than that at a ce , but that the mw algorithm runs for about @xmath228 iterations which is more than the number of iterations required for computing a ce .",
    "the sum rate at the nash bargaining solution is very close to that at the pareto point , but the former provides fairness among users .",
    "we present the rates at the pareto point and at the nash bargaining solution in table [ table1 ] to illustrate the fairness provided by the nash bargaining solution for example 1 .",
    "the rates of all the three users are mentioned as a triplet @xmath229 , where @xmath19 is the rate of user @xmath6 .",
    "it can be seen for several snr values , that the nash bargaining solution provides more fairness than at the pareto point . even though example 1 is symmetric , as the algorithms",
    "are based on stochastic local search , rate allocations need not be symmetric .",
    "we note that the sum rate of all the users is higher at the pareto optimal point than at a ce .",
    "the improvement is 21.8% at the average transmit",
    "snr constraint of 10db , and 24.6% at the snr of 15db .    in the computation of ce",
    ", for each pure strategy @xmath230 , we need to estimate the regret , which requires some calculation of a threshold in advance before starting the running of the algorithm .",
    "this requires two multiplications and two additions per action for each user .",
    "but , for one iteration in the mw algorithm , each user requires one division per action and two multiplications .",
    "hence , even though the regret - matching algorithm requires computation of estimated regret , it may converge faster than the mw algorithm which does not require computation of regret .",
    "it is observed from examples that the regret - matching has relatively less running time than the mw algorithm .",
    "next we consider an asymmetric scenario , in example 2 . in this example",
    "also we consider @xmath214 and @xmath215 for each user @xmath6 .",
    "the direct link gains from @xmath231 occur with equal probability for each user @xmath6 , but the cross link gains occur with a different probability distribution for each user . for user @xmath119 ,",
    "the distribution is @xmath232 , for user 2 it is @xmath233 , and for user 3 , it is @xmath234 .",
    "users @xmath235 and @xmath236 transmit at rates @xmath237 bits per channel use respectively . the sum rate at the ce and at the pareto point obtained from our algorithm",
    "are compared in figure [ fig_2 ] .",
    "we also compare the sum rate at the ce obtained by using the rl algorithm in @xcite . in this example also , we observe that our algorithm converges faster than the rl algorithm : at snr of 15db , our algorithm converges in about @xmath228 iterations , whereas the algorithm in @xcite converges in about @xmath238 iterations .",
    "we also plot the sum rate at a stochastically stable point of the algorithm in @xcite which maximizes @xmath224 .",
    "we also plot the sum rate at a cce and at a nash bargaining solution for example 2 in figure [ fig_2 ] . in this example also , we observe an improvement in the sum rate at a cce over that at a ce , and the mw algorithm runs for about @xmath239 iterations which is more than the number of iterations required for computing a ce",
    ". the sum rate at the nash bargaining solution is very close to that at the pareto point .",
    "we observe that the sum of the rates of all the users is higher at the pareto optimal point than at a ce .",
    "we observe an improvement of 22.7% at snr 10db and an improvement of 17.5% at snr of 15db .",
    "the sum rate obtained via @xcite at its stochastically stable point is the lowest .",
    "finally , we consider multiple rates of transmission in example 3 .",
    "for example 3 , we consider the same parameters as in example 2 , but each user can send data at any rate from the set @xmath240 .",
    "we compare the sum rates at a ce , cce , pareto point , and nash bargaining solution , in figure [ fig_3 ] .",
    "we also plot the sum rates using the rl algorithm and te algorithm for this example in figure [ fig_3 ] . in this example",
    "also we observe an improvement in the sum rate at the cce over the sum rate at the ce .",
    "sum rate at the nash bargaining solution and at the pareto point almost coincide in this example also . as the cardinality of the strategy set of each user",
    "is enlarged by transmitting at multiple rates , the regret - matching algorithm runs for about @xmath241 iterations to compute a ce and the mw algorithm runs for about @xmath242 iterations to compute a cce , at snr of 15db .",
    "we have considered a communication system in which @xmath0 transmitter - receiver pairs communicate on a wireless channel .",
    "each transmitter sends data at a certain rate at a power level that is a function of the direct link channel gain and the feedback received from its receiver , to maximize the probability of successful transmission .",
    "this scenario is modeled as a stochastic game and fully distributed learning algorithms are proposed to find a correlated equilibrium ( ce ) and a pareto point .",
    "we have compared the sum of rates of all the users at the ce and the pareto point , and we observe that the pareto optimal power allocations provide higher probability of successful transmission .",
    "we have also compared our algorithms with two other recent learning algorithms in literature @xcite , @xcite .",
    "the ce obtained by our algorithm performs as well as the ce obtained via the algorithm in @xcite but our algorithm converges much faster . on the other hand the performance of our ce is better than the best point obtained by the algorithm in @xcite",
    ".    we also note in our examples that we can achieve a higher sum rate by operating at a cce than operating at a ce but at the expense of more number of iterations to compute it .",
    "but , in general , it is not guaranteed that a cce yields a better sum rate than a ce . on the other hand",
    "a nash bargaining solution may be a better operating point than an arbitrary pareto point as it provides fairness among the users .",
    "transmitting at multiple rates can significantly improve the sum rate but as the strategy set of each player is enlarged , it requires more number of iterations to converge to either a nash bargaining solution or a cce . in practice , which algorithm to use depends on the nature of the problem , i.e. , if for example , the cardinality of the overall action space is not large , then the users can find a pareto point more quickly than a ce or cce .",
    "but if the action space is large and if it requires to converge to an equilibrium quickly , one can use regret - matching to converge to a ce .",
    "9 s. deng , t. weber , and a. ahrens , `` capacity optimizing power allocation in interference channels , '' _ aeu international journal of electronics and communications _ ,",
    "vol.63 , pp .",
    "139 - 147 , feb . 2009 .",
    "daniela tuninetti , `` gaussian fading interference channels : power control , '' _ proc . of the 42nd asilomar conference on signals , systems and computers _ , monterey , ca , pp . 701 - 706 , october 2008 .",
    "k. a. chaitanya , u. mukherji , and v. sharma , `` power allocation for interference channel , '' _ proc . of national conference on communications _ , new delhi , 2013 .",
    "g. scutari , d. p. palomar , and s. barbarossa , `` optimal linear precoding strategies for wideband non - cooperative systems based on game theory - part ii : algorithms , '' _ ieee trans on signal processing _ , vol.56 , no.3 , pp .",
    "1250 - 1267 , march 2008 . k. w. shum , k .- k .",
    "leung , and c. w. sung , `` convergence of iterative waterfilling algorithm for gaussian interference channels , '' _ ieee journal on selected areas in comm . , _",
    "vol.25 , no.6 , pp .",
    "1091 - 1100 , august 2007 .",
    "g. scutari , d. p. palomar , and s. barbarossa , `` the mimo iterative waterfilling algorithm , '' _ ieee trans on signal processing _ , vol .",
    "57 , no.5 , may 2009 .",
    "g. scutari , d. p. palomar , and s. barbarossa , `` asynchronous iterative water - filling for gaussian frequency - selective interference channels '' , _ ieee trans on information theory _ , vol.54 , no.7 , july 2008 . l. rose , s. m. perlaza , and m. debbah , `` on the nash equilibria in decentralized parallel interference channels , '' _ proc .",
    "of international conference on communications _ , kyoto , 2011 .",
    "k. a. chaitanya , u. mukherji , and v. sharma , `` algorithms for stochastic games on interference channels , '' _ proc .",
    "of national conference on communications _ , mumbai , 2015 .",
    "s. lasaulce , and h. tembine , `` game theory and learning for wireless networks : fundamentals and applications , '' _ elsevier _ , 2011 .",
    "s. hart , and a. mas - colell , `` a simple adaptive procedure leading to correlated equilibrium , '' _ econometrica _ , vol .",
    "68 , no.5 , pp .",
    "1127 - 1150 , sept . 2000",
    "d. fudenberg , and d. m. kreps , `` learning mixed equilibria , '' _ games and economic behavior _ , vol .",
    "320 - 367 , 1993 .",
    "n. mastronarde , and mihaela van der schaar , `` fast reinforcement learning for energy - efficient wireless communication , '' _ ieee tran . on signal processing _ ,",
    "p. mertikopoulos , e. v. belmega , a. l. moustakas , and s. lasaulce , `` distributed learning policies for power allocation in multiple access channels , '' _ ieee journal on selected areas in communications _ , vol .",
    "96 - 106 , jan . 2012 .",
    "e. v. belgama , s. lasaulce , m. debbah , and a. hjorungnes , `` learning distributed power allocation policies in mimo channels , '' _",
    "european signal processing conference _ , aalborg , denmark , 2010 .",
    "l. rose , s. m. perlaza , m. debbah , and c. j. le martret , `` distributed power allocation with sinr constraints using trial and error learning , '' _ ieee wireless communications and networking conference _ , paris , april 2012 .",
    "e. sabir , r. el - azouzi , v. kavitha , y. hayel , and e. bouyakhf , `` stochastic learning solution for constrained nash equilibrium throughput in non saturated wireless collision channels , '' _ proc .",
    "the 3rd icst / acm international workshop on game theory in communication networks _ ,",
    "pisa , italy , oct .",
    "h. jang , s. y. yun , j. shin , and y. yi , `` distributed learning for utility maximization over csma - based wireless multihop networks , '' _ ieee international conference on computer communications _ ,",
    "toronto , canada , april - may 2014 .",
    "h. saad , a. mohamed , and t. elbatt , `` cooperative q - learning techniques for distributed online power allocation in femtocell networks , '' _ wireless communications and mobile computing _",
    ", doi : 10.1002/wcm.2470 , 2014 .",
    "s. hart , and a. mas - colell , `` a reinforcement procedure leading to correlated equilibrium , '' _ economics essays _",
    ", springer berlin heidelberg , 2001 .",
    "k. r. fall , and w. r. stevens , `` tcp / ip illustrated volume 1 , '' addison - wesley , 2012 .",
    "b. s. r. pradelski , and h. p. young , `` learning efficient nash equilibria in distributed systems , '' _ games and economic behavior _ , elsevier , 75 , pp.882 - 897 , 2012 .",
    "h. p. young ,",
    "`` learning by trial and error , '' _ games and economic behavior _ , elsevier , 65 , pp.626 - 643 , 2009 . t. borgers , and r. sarin , `` learning through reinforcement learning and replicator dynamics , '' _ journal of economic theory _",
    ", 77 , pp.1 - 14 , 1997 . w. b. arthur , `` on designing economic agents that behave like human agents , '' _ journal of evolutionary economics _ , springer - verlag , pp.1 - 22 , 1993 . m. zuluaga , a. krause , g. sergent , and m. puschel , `` active learning for multi - objective optimization , '' _ proc .",
    "30th international conference on machine learning _ ,",
    "atlanta , georgia , usa , 2013 .",
    "j. r. marden , h. p. young , and l. y. pao , `` achieving pareto optimality through distributed learning , '' _ ieee conference on decision and control _ , maui , hawaii , usa , dec .",
    "k. miettinen , `` nonlinear multiobjective optimization , '' kluwer academic publishers , 1999 .",
    "z. han , d. niyato , w. saad , t. basar , and a. hjorungnes , `` game theory in wireless and communication networks , '' _ cambridge university press _",
    "s. hart , `` adaptive heuristics , '' _ econometrica _ , vol .",
    "1401 - 1430 , september , 2005 .",
    "h. h. hoos , and t. stutzle , `` stochastic local search : foundations and applications , '' _ morgan kaufmann / elsevier _ , 2004 .",
    "n. littlestone , and m. k. warmuth , `` the weighted majority algorithm , '' _ information and computation _ , 108(2 ) , pp 212 - 261 , 1994 .",
    "s. arora , e. hazan , and s. kale , `` the multiplicative weights update method : a meta algorithm and applications , '' _ theory of computing _ , 8(1 ) , pp 121 - 164 , 2012 .",
    "n. cesa - bianchi , and g. lugosi , `` prediction , learning , and games , '' _ cambridge university press _ , 2006 .",
    "t. roughgarden , `` intrinsic robustness of the price of anarchy , '' _ acm symposium on theory of computing _ , pp.513 - 522 , 2009 . j. nash , `` the bargaining problem , '' _ econometrica _ ,",
    "18:155 - 162 , 1950 . f. kelly , a. maulloo , and d. tan , `` rate control for communication networks : shadow prices , proportional fairness and stability , '' _ journal of the operations research society _ , vol .",
    "237 - 252 , march , 1998 .",
    "h. boche , and m. schubert , `` nash bargaining and proportional fairness for wireless systems , '' _ ieee / acm transactions on networking _ , vol .",
    "5 , pp . 1453 - 1466 , october , 2009 ."
  ],
  "abstract_text": [
    "<S> we consider a wireless communication system in which @xmath0 transmitter - receiver pairs want to communicate with each other . </S>",
    "<S> each transmitter transmits data at a certain rate using a power that depends on the channel gain to its receiver . </S>",
    "<S> if a receiver can successfully receive the message , it sends an acknowledgement ( ack ) , else it sends a negative ack ( nack ) . </S>",
    "<S> each user aims to maximize its probability of successful transmission . </S>",
    "<S> we formulate this problem as a stochastic game and propose a fully distributed learning algorithm to find a correlated equilibrium ( ce ) . </S>",
    "<S> in addition , we use a no regret algorithm to find a coarse correlated equilibrium ( cce ) for our power allocation game . </S>",
    "<S> we also propose a fully distributed learning algorithm to find a pareto optimal solution . in general pareto points do not guarantee fairness among the users , therefore we also propose an algorithm to compute a nash bargaining solution which is pareto optimal and provides fairness among users . </S>",
    "<S> finally , under the same game theoretic setup , we study these equilibria and pareto points when each transmitter sends data at multiple rates rather than at a fixed rate . </S>",
    "<S> we compare the sum rate obtained at the ce , cce , nash bargaining solution and the pareto point and also via some other well known recent algorithms .    </S>",
    "<S> interference channel , stochastic game , correlated equilibrium , distributed learning , pareto point . </S>"
  ]
}