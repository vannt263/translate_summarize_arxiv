{
  "article_text": [
    "the last few years have been characterized by huge technological changes in the area of parallel and distributed computing . today , powerful machines are available at low price everywhere in the world .",
    "the main visible line of such changes is the large spreading of _ clusters _ which consist in a collection of tens or hundreds of standard almost identical processors connected together by a high speed interconnection network @xcite .",
    "the next natural step is the extension to local sets of clusters or to geographically distant grids @xcite .    in the last issue of the top500 ranking ( from november 2003 @xcite ) ,",
    "52 networks of workstations ( now ) of different kinds were listed and 123 entries are clusters sold either by ibm , hp or dell .",
    "looking at previous rankings we can see that this number ( within the top500 ) approximately doubled each year .",
    "this democratization of clusters calls for new practical administration tools . even if more and more applications are running on such systems , there is no consensus towards an universal way of managing efficiently the computing resources .",
    "current available scheduling algorithms were mainly created to provide schedules with performance guaranties for the makespan criterion ( maximum execution time of the last job ) , however most of them are pseudo - polynomial , therefore the time needed to run these algorithms on real instances and the difficulty of their implementation is a drawback for a more popular use .",
    "we present in this paper a new method for scheduling the jobs submitted to a cluster inspired by several existing theoretically well - founded algorithms .",
    "this method has been assessed on simulations and it is currently tested on actual conditions of use on a large cluster composed by 104 bi - processor machines from compaq ( this cluster ",
    "called icluster2  was ranked 151 in the top500 in june 2003 ) .    to achieve reasonable performance within reasonable time",
    ", we decided to build a fast algorithm which has the best features of existing ones .",
    "however , to speed up the algorithm a guaranteed performance ratio can not be achieved , thus we concentrate on the average ratio on a large set of generated test instances .",
    "these instances are representative of jobs submitted on the icluster @xcite .",
    "some scheduling algorithms have been developed for classical parallel and distributed systems of the last generations .",
    "clusters introduce new characteristics that are not really taken into account into existing scheduling modules , namely , unbalance between communications and computations  communications are relatively large  or on - line submissions of jobs .",
    "let us present briefly some schedulers used in actual systems : the basic idea in job schedulers @xcite is to queue jobs and to schedule them one after the other using some simple rules like fcfs ( first come first served ) with priorities .",
    "maui scheduler @xcite extends the model with additional features like fairness and backfilling .",
    "apples is an application level scheduler system for grid .",
    "it is used to schedule , for example , an application composed of a large set of independent jobs with shared data input files @xcite .",
    "it selects resources efficiently and takes into account data distribution time .",
    "it is designed for grid environment .",
    "there exist other parallel environments with a more general spectrum ( heterogeneous and versatile execution platform ) like condor @xcite or with special capabilities like processus migration , requiring system - level implementation like mosix @xcite .",
    "in these environments scheduling algorithms are online algorithms with simple rules .      as no fast and flexible scheduling systems are available today for clusters , we started two years ago to develop a new system based on a sound theoretical background and a significant practical experience of managing a big cluster ( icluster1 , a 225 pc machine arrived in 2001 in our lab ) .",
    "it is based on the model of _ parallel tasks _",
    "@xcite which are independent jobs submitted by the users .",
    "we are interested here in optimizing simultaneously two criteria , namely the minsum ( @xmath0 ) which is usually targeted by the users who all want to finish their jobs as soon as possible , and the makespan ( @xmath1 ) which is rather a system administrator objective representing the total occupation time of the platform .",
    "there exist algorithms for each criterion separately ; we propose here a bi - criteria algorithm to optimize the @xmath1 and @xmath0 criteria simultaneously .",
    "the best existing algorithm for minimizing the makespan off - line ( all jobs are available at the beginning ) has a @xmath2 guaranty @xcite .",
    "we can derive easily an on - line batch version by using the general framework of @xcite leading to an approximation ratio of @xmath3 .",
    "for the other criterion , the best result is @xmath4 for the unweighted case and @xmath5 for the weighted case @xcite . using a nice generic framework introduced by hall et al.@xcite ,",
    "a ( @xmath6;@xmath6 ) approximation can be obtained at the cost of a big complexity which impedes the use of such algorithms .",
    "the paper is organized as follows : in the next section , we will introduce the definitions and models used in all the paper .",
    "the algorithm itself is described in section [ sec : algo ] , along with the lower bound which is used in the experiments .",
    "the experimental setting and the results are discussed in section [ sec : experiences ] .",
    "finally we will conclude in section [ sec : conclu ] with a discussion on on - going works .",
    "the target execution support that we consider here is a cluster composed by a collection of a medium number of smp or simple pc machines ( typically several dozens or several hundreds of nodes ) .",
    "the nodes are fully connected and homogeneous .",
    "the submissions of jobs is done by some specific nodes by the way of several priority queues as depicted in figure [ lightgrid ] .",
    "no other submission is allowed .    informally ,",
    "a parallel task ( pt ) is a _ task _ that gathers elementary operations , typically a numerical routine or a nested loop , which contains itself enough parallelism to be executed by more than one processor .",
    "we studied scheduling of one specific kind of pt , denoted as _",
    "moldable jobs _ according to the classification of feitelson et al .",
    "the number of processors to execute a moldable job is not fixed but determined before the execution , as opposed to _ rigid jobs _ where the number of processors is fixed by the user at submission time . in any case , the number of processors does not change until the completion of the job .    for historical reasons , most of submitted jobs are rigid .",
    "however , intrinsically , most parallel applications are moldable .",
    "an application developer does not know in advance the exact number of processors which will be used at run time .",
    "moreover , this number may vary with the input problem size or number of available nodes .",
    "this is also true for many numerical parallel libraries .",
    "the main exception to this rule is when a minimum number of processors is required because of time , memory or storage constraints .",
    "the main restriction in a systematic use of the moldable character is the need for a practical and reliable way to estimate ( at least roughly ) the parallel execution time as function of the number of processors .",
    "most of the time , the user has this knowledge but does not provide it to the scheduler , as it is not taken into account by rigid jobs schedulers .",
    "this is an inertia factor against the more systematic use of such models , as the users habits have to be changed .",
    "our algorithm proposes , thanks to moldability , to efficiently decrease average response time ( at the users request ) while keeping computing overhead and idle time as low as possible ( at the system administrators request ) .",
    "the main objective function used historically is the _ makespan_.",
    "this function measures the ending time of the schedule , i.e. , the latest completion time over all the tasks .",
    "however , this criterion is valid only if we consider the tasks altogether and from the viewpoint of a single user .",
    "if the tasks have been submitted by several users , other criteria can be considered .",
    "let us present briefly the two criteria :    * minimization of the _ makespan _",
    "( @xmath7 where the completion time @xmath8 is equal to @xmath9 ) .",
    "@xmath10 represents the execution time of task @xmath11 , @xmath12 function is the starting time and @xmath13 function is the processor number ( it can be a vector in the case of specific allocations for heterogeneous processors ) . *",
    "minimization of the average completion time ( @xmath0 ) @xcite and its variant weighted completion time ( @xmath14 ) .",
    "such a weight may allow us to distinguish some tasks from each other ( priority for the smallest ones , etc . ) .    in a production cluster context ,",
    "the jobs are submitted at any time .",
    "models were the characteristics of the tasks ( duration , release date , etc ) are only known when the task is submitted are called _ on - line _ as opposed to the _ off - line _ models were all the tasks are known and available at all times .",
    "it is possible to schedule jobs on - line with a constant competitive ratio for @xmath1 .",
    "the idea is to schedule jobs by batches depending on their arrival time .",
    "an arriving job is scheduled in the next starting batch .",
    "this simple rule allows constant competitive ratio in the on - line case if a single batch may be scheduled with a constant competitive ratio @xmath15 .",
    "roughly , the last batch starts after the last task arrival date . by definition ,",
    "all the tasks scheduled in a batch are scheduled in less than @xmath16 , where @xmath17 is the optimal off - line makespan of the complete instance .",
    "the length of the previous last batch is then lower than @xmath18 .",
    "moreover , the length of the last batch , plus the starting time of the previous last batch ( at which none of the tasks of the last batch were released ) is less than @xmath15 times the length of the optimal on - line makespan .",
    "as the on - line makespan is larger than the off - line makespan , the total schedule length is less than @xmath19 times the on - line optimal makespan .",
    "this is how the off - line @xmath20 algorithm is turned into an on - line @xmath21 algorithm as we said in the introduction .",
    "studying some extreme instances and their optimal schedules for the minsum criterion , gave us an insight on the shape of the schedules we had to build .",
    "for example , if all the tasks are perfectly moldable ( when the work does not depend on the number of processors ) the optimal solution is to schedule all the tasks on all processors in order of increasing area .",
    "this example shows that the minsum criterion tends to give more importance to the smaller tasks .",
    "previous algorithms presented in the literature are also designed to take into account this global structure of scheduling the smaller tasks first .",
    "shmoys et al .",
    "@xcite used a batch scheduling with batches of increasing sizes .",
    "the batch length is doubled at each step , therefore only the smaller tasks are scheduled in the first batches .",
    "existing makespan algorithms for moldable tasks are also designed with a common structure of shelves ( were all tasks start at the same time ) which is a relaxed version of batches .",
    "see for example @xcite or @xcite for schedules with 2 shelves .",
    "our algorithm was built with this structure in mind : stacking tasks in shelves of increasing sizes with the additional possibility of shuffling these shelves if necessary .",
    "however , our main motivation was to design a fast algorithm for the management of some clusters of a big regional grid in grenoble .",
    "our algorithm does not have a known performance guaranty on the worst cases , however we tested its behavior on a set of generated instances which simulate real jobs submitted on our local clusters .",
    "the principle of the algorithm is shown in figure  [ fig : algo - principle ] .",
    "more formally , we detail below the algorithm starting with the input describing the instances :    * @xmath22 tasks available at time @xmath23 * @xmath24 the processing time of task @xmath25 on @xmath26 processors * @xmath27 is its weight * @xmath28 the number of processors    first , our algorithm calls a dual approximation makespan algorithm ( defined in @xcite ) to determine an approximation of the optimal makespan of the instance . with this value @xmath17 and the smallest possible duration of a task @xmath29 , we compute the smallest useful batch size @xmath30 ( such that at least one task can be done ) and @xmath31 the number of batches .",
    "the values @xmath32 are the length of our batches . for every @xmath11 , @xmath33 is twice the value of @xmath32 .",
    "the main loop of the algorithm corresponds to the selection of the jobs to be scheduled in the current batch .",
    "we first select the tasks which are not too long to run in the batch .",
    "if there are several tasks that can be run in less than half the batch size on one processor , we can merge some of these tasks by stacking them together . in order to have as much weight as possible ,",
    "this merge is done by decreasing weight order .",
    "the next step is to run a knapsack selection , written with integer dynamic programming .",
    "we want to maximize the sum of the weight of the selected tasks while using at most @xmath28 processors .",
    "the allocation of the task @xmath25 is @xmath34 , the smallest allocation that fits ( in length ) into the batch .",
    "values of @xmath35 are initialized to @xmath36 for @xmath37 and @xmath23 otherwise . for @xmath25",
    "going from @xmath38 to @xmath22 and for @xmath11 going from @xmath38 to @xmath28 , we compute : @xmath39 the largest @xmath40 is the maximum weight that can be done in the batch .",
    "the complexity of this knapsack is @xmath41 .",
    "the first schedule is simple : we start all the selected tasks of one batch at the same time .",
    "a straightforward improvement is to start a task at an earlier time if all the processors it uses are idle .",
    "a further improvement is to use a list algorithm with the batch ordering and a local ordering within the batches , as it allows to change the set of processors alloted to the tasks .",
    "finally , an additional optimization step is used .",
    "the batch order is shuffled several times and the best resulting compact schedule is kept .",
    "this only leads to small improvements .",
    "the overall complexity of this algorithm is @xmath42 .      in order to assess this algorithm with experiments , for each instance",
    "we need to know the value of an optimal solution .",
    "but since the problem is np - hard in the strong sense , computing an optimal solution in reasonable time is impossible .",
    "we are thus looking for good lower bounds .",
    "for @xmath1 a good lower bound may easily be obtained by dual approximation @xcite . for @xmath0 the lower bound is computed by a relaxation of a linear programming formulation of the problem .",
    "this formulation is not intended to yield a feasible schedule , but rather to express constraints that are necessarily respected by every feasible schedule .",
    "for this formulation , we divided the time horizon into several intervals @xmath43 $ ] with @xmath44 .",
    "the values of the @xmath32 and the value of @xmath45 are defined as in the previous section .",
    "once the time division is fixed , we consider the decision variables @xmath46 if and only if task @xmath25 ends within @xmath47 ( i.e. between @xmath32 and @xmath33 ) , and @xmath48 otherwise .    for each task @xmath25 and each interval @xmath11 , we can also compute the minimal area occupied by task @xmath25 if it ends before @xmath33 : @xmath49 if the set is empty , let @xmath50 .    with these values",
    ", we can give the formulation of the problem :    @xmath51    the first constraint expresses that every task should be performed at least once .",
    "the minimization criterion implies that no task will be performed more than once : if @xmath52 and @xmath53 are equal to one , we get a better , yet still feasible solution by setting one of them to zero .",
    "the second constraint is a surface argument . for each interval @xmath47",
    ", we consider the tasks that end before or in this interval ( they end in @xmath54 , for @xmath55 ) . by definition ,",
    "a task @xmath25 ending in interval @xmath56 takes up a surface at least @xmath57 .",
    "the sum of all these surfaces has to be smaller than the total surface between time @xmath23 and time @xmath33 , which is @xmath58 .",
    "this is obviously optimistic , because it does not take into account collisions between tasks : scheduling according to this formulation might require more than @xmath28 processors .",
    "both of these constraints are satisfied by every feasible schedules , so for every feasible schedule @xmath59 , there is a solution @xmath60 to this linear program .",
    "since for each job @xmath25 , @xmath61 , the objective function of @xmath60 is not larger than the minsum criterion of the schedule @xmath59",
    ". in particular , every optimal schedule yields a solution to the linear program , so the optimal value of the objective function is always smaller than the optimal value of the minsum criterion of the scheduling problem .",
    "this still holds when considering the relaxed problem , where @xmath52 is in @xmath62 $ ] .",
    "the lower bound might be weaker , but is much faster to compute .",
    "the experimental simulations presented here were performed with an ad - hoc program .",
    "each experience is obtained by 40 runs ; for each run tasks are generated in an off - line manner , then given as an input to the scheduling algorithm and to the linear solver which computes a lower bound for this instance .",
    "comparison between the two results yields a performance ratio , and the average ratio for the whole set of runs is the result of the experiments .",
    "the runs were made assuming a cluster of 200 processors , and a number of tasks varying from 25 to 400 . in order to describe a mono - processor task , only its computing time is needed .",
    "a moldable task is described by a vector of @xmath28 processing times ( one per number of processor alloted to the task ) .",
    "we used two different models to generate the tasks .",
    "the first one generates the sequential processing times of the tasks , and the second one uses a parallelism model to derive all the other values .    two different sequential workload type were used : uniform and mixed cases .",
    "for all uniform cases , sequential times were generated according to an uniform distribution , varying from @xmath38 to @xmath63 .",
    "for mixed cases , we introduce two classes : small and large tasks .",
    "the random values are taken with gaussian distributions centered respectively on 1 and 10 , with respective standard deviations of 0.5 and 5 , the ratio of small tasks being 70% .    modeling the parallelism of the jobs was done in two different ways . in the first , successive processing times were computed with the formula @xmath64 , where @xmath65 is a random variable between @xmath23 and @xmath38 .",
    "depending on the distribution of @xmath65 , tasks generated are highly parallel ( with a quasi - linear speedup ) or weakly parallel ( with a speedup close to @xmath38 ) . respectively",
    "highly and weakly parallel are generated using gaussian distribution centered on 0.9 , and 0.1 , and with a standard deviation of 0.2 .",
    "any random value smaller than @xmath23 and larger than @xmath38 are ignored and recomputed . according to the usual parallel program behavior ,",
    "this method generates monotonic tasks , which have decreasing execution times and increasing work with @xmath26 . for the mixed cases , the small tasks are weakly parallel and the large tasks are highly parallel .",
    "the second way of modeling parallelism was done according to a model from cirne and berman  @xcite , which relies on a survey about the behavior of the users in a computing center .",
    "only the @xmath66 sequential time model is used for theses tasks .    to evaluate our algorithm",
    ", we use the lower bound ( cf section [ sec : lowerbound ] ) as reference . some simple `` standard '' algorithms",
    "are used to compare the behavior and efficiency of our approach .",
    "gang : : :    each task is scheduled on all processors .",
    "the tasks are sorted using    the ratio of the weight over the execution time .",
    "this algorithm is    optimal for instances with linear speedup .",
    "sequential : : :    each tasks is scheduled on a single processor . a list algorithm is    used , scheduling large processing time first ( lptf ) .",
    "list graham : : :    all the 3 algorithms are multiprocessor list scheduling @xcite .",
    "every    tasks is alloted using the number of processor selected by @xcite .",
    "this should lead to a very good average performance ratio with respect    to the @xmath1 criterion .",
    "only the order of the list is    changing between the three algorithms :    +    * the first one keep the order of @xcite , listing first task of the    large shelf then the tasks of small shelf then the small tasks ,    * weighted largest processing time first ( lptf ) , a classical variant ,    with a very god behavior for @xmath1 criterion , but the    tasks are in fact sorted using the ratio between weighted and their    execution time .    * smallest area first ( saf )",
    ", almost the opposite of lptf , the tasks    are sorted according to their area ( number of processors    @xmath67 execution time ) .",
    "the goal is to improve the    average performance ratio for the @xmath68    criterion .    in all experiments ,",
    "task priority is a random value taken from an uniform distribution between 1 and 10 .",
    "the results of the simulation runs are given in all the following figures , plotting the minimum , maximum and average values for @xmath1 and @xmath68 .",
    "the average of the competitive ratio is computed by dividing the sum of the execution times over the sum of the lower bounds for every point @xcite .",
    "every workload type are represented separately .",
    "the same scale is represented for identical criterion between the workload type .",
    "the tasks of figure [ fig : courbe_weak ] are weakly parallel .",
    "this is the worst case for our algorithm as it spends resources to accelerate completion of small and high priority parallel tasks .",
    "these resources are thus spend without much gain .",
    "note that gang scheduling does not appear in the presented range for @xmath1 , as gang always has a very big ratio in this case .    as expected , the average performance ratio for our algorithm is worse than all other algorithms except gang . nevertheless , the performance ratio for @xmath1 is no more than @xmath69 .",
    "all other algorithms have an average performance ratio around @xmath70 .",
    "the difference is large enough to influence also the results for the minsum criterion . from this case",
    "we may deduce that for most cases , our algorithms will not be much worse than a performance ratio of @xmath69 for both criterion .",
    "figure [ fig : courbe_hight ] presents the same experiments with the highly parallel tasks . on the minsum criterion ,",
    "our algorithm is clearly the best one .",
    "gang and sequential have opposite behavior on both criteria , gang being good with a small number of tasks and sequential good for a large number of tasks only .",
    "the other algorithms are stable ( with respect to the number of tasks ) but with a larger ratio on the minsum .",
    "remark that the allotment computed for list algorithms is quite good , as @xmath1 performance ratio of these algorithms is always smaller than @xmath69 .",
    "the next experiment ( cf figure [ fig : courbe_mixed ] ) presents mixed instances with some large tasks and plenty of small tasks . in",
    "this cases our algorithm is still quite stable with a performance ratio of around @xmath69 for both criterion , however saf is better than our algorithm .",
    "the ratio of the two other list algorithms greatly increase with the number of tasks , which points out that the order of tasks is very important here .",
    "finally , the last experiment use a well known workload generator which emulates real applications  @xcite . in",
    "this more realistic setting our algorithm clearly outperforms the other ones for the minsum criterion , and is also the only one to keep a stable ratio for any number of tasks .",
    "several observations can be made from these results .",
    "first , the performance ratio for the minsum criterion is never more than @xmath71 , and is on average around @xmath69 .",
    "the performance ratio for the makespan is almost always below @xmath69 , and is @xmath72 on average .",
    "this is very good , even for each criterion separately .",
    "the second observation is that our algorithm performs better when tasks are more parallel .",
    "this can be understood if we remark that , for a weakly parallel task , there is only one or two intervals in which it can be scheduled without degrading its performance .",
    "so the scheduling algorithm is more constrained when the tasks are not parallel .",
    "the saf algorithm perform quite well on simple cases .",
    "it appears on complex cases that our approach is required to keep a good performance on the minsum criterion .",
    "thus our algorithms should be preferred in actual applications as its performance ratio for minsum is insensitive to jobs behavior and its performance ratio for the makespan is not far from alternatives .",
    "finally , figure  [ fig : time ] shows that the execution time of our scheduling algorithm is low ( less than 2 seconds for the largest instances ) , as expected .",
    "in this paper we presented a new algorithm for scheduling a set of independent jobs on a cluster .",
    "the main feature is to optimize two criteria simultaneously .",
    "the experiments show that in average the performance ratio is very good , and the algorithm is fast enough for practical use .",
    "the algorithm has been assessed by comparing the minsum performance to a new lower bound based on the relaxation of an ilp , and comparing the makespan performance to the best known approximation .",
    "actual results are not available at the moment , but we are currently implementing this algorithm on a full - scale platform ( icluster2 ) .",
    "several technical problems still have to be solved for an even more efficient practical solution , namely the reservation of nodes which reduces the size of the cluster and the mix of different types of jobs ( moldable jobs , rigid jobs , and divisible load jobs )",
    ".                    d.  g. feitelson .",
    "scheduling parallel jobs on clusters . in r.",
    "buyya , editor , _ high performance cluster computing _ ,",
    "volume 1 , architectures and systems , pages 519533 .",
    "prentice hall ptr , upper saddle river , nj , 1999 . chap .",
    "21 .",
    "r.  l. henderson .",
    "job scheduling under the portable batch system . in d.",
    "g. feitelson and l.  rudolph , editors , _ job scheduling strategies for parallel processing _ , volume 949 of _ lncs _ , pages 279294 , 1995 .",
    "d.  jackson , q.  snell , and m.  j. clement .",
    "core algorithms of the maui schedule . in d.",
    "g. feitelson and l.  rudolph , editors , _ job scheduling strategies for parallel processing _ , volume 2221 of _ lncs _ , pages 87102 , 2001 .",
    "m.  j. litzkow , m.  livny , and m.  w. mutka .",
    "condor : a hunter of idle workstations . in _",
    "8th international conference on distributed computing systems ( icdcs 88 ) _ , pages 104111 , washington , d.c .",
    ", usa , june 1988 .",
    "ieee computer society press .",
    "g.  mouni , c.  rapine , and d.  trystram .",
    "efficient approximation algorithms for scheduling malleable tasks . in _ eleventh acm symposium on parallel algorithms and architectures ( spaa99 ) _ , pages 2332 .",
    "acm , juin 1999 .",
    "e.  romagnoli , y.  denneulin , and d.  trystram . a synthetic workload generator for cluster computing . in _",
    "3rd international workshop on performance modeling , evaluation , and optimization of parallel and distributed systems ( pmeo - pds2004 ) in conjunction with ipdps04 _ , santa fe , new mexico , 2004 ."
  ],
  "abstract_text": [
    "<S> we describe in this paper a new method for building an efficient algorithm for scheduling jobs in a cluster . </S>",
    "<S> jobs are considered as parallel tasks ( pt ) which can be scheduled on any number of processors . </S>",
    "<S> the main feature is to consider two criteria that are optimized together . </S>",
    "<S> these criteria are the _ makespan _ and the weighted minimal average completion time ( _ minsum _ ) . </S>",
    "<S> they are chosen for their complementarity , to be able to represent both user - oriented objectives and system administrator objectives .    </S>",
    "<S> we propose an algorithm based on a batch policy with increasing batch sizes , with a smart selection of jobs in each batch . </S>",
    "<S> this algorithm is assessed by intensive simulation results , compared to a new lower bound ( obtained by a relaxation of ilp ) of the optimal schedules for both criteria separately . </S>",
    "<S> it is currently implemented in an actual real - size cluster platform .    </S>",
    "<S> [ sequencing and scheduling ] [ scheduling , concurrency ] </S>"
  ]
}