{
  "article_text": [
    "quantum state preparation is the first important step for any protocol that makes use of quantum resources .",
    "examples of such protocols are quantum state teleportation and quantum key distribution which require entangled quantum states . in order to verify the integrity of the true quantum state @xmath0 prepared by the source , one carries out quantum state tomography to characterize it .",
    "measurements are performed on a collection of identical copies of quantum systems ( electrons , photons , etc . )",
    "that are emitted from the source .",
    "then , the quantum state of the source is inferred from the measurement data obtained from this collection .",
    "the measurements are generically described by a set of positive operators @xmath1 that compose a _ probability operator measurement _",
    "such a procedure of state inference is known as quantum state estimation .",
    "when the measurement outcomes form an informationally complete set , they fully characterize the source and the measurement data obtained will contain maximal information about its state . to infer the unknown state from the data , one can search for a state estimator that maximizes the _ likelihood functional _ that yields the probability of obtaining a particular sequence of measurement detections given a quantum state  the maximum - likelihood ( ml ) estimator @xcite . yet , in tomography experiments performed on complex quantum systems with many degrees of freedom , it is not possible to implement such an informationally complete set of measurement outcomes .",
    "therefore , some information about the source will be missing and its quantum state can not be unambiguously determined . for instance , if a source produces a mode of light that is described by an infinite - dimensional statistical operator @xmath0 , then no matter how ingeniously a measurement scheme is designed to probe incoming photons prepared by this source , an infinite amount of information about the mode of light will always remain unknown .",
    "the ml estimator obtained from these informationally incomplete data is no longer unique and there will in general be infinitely many other ml estimators that are consistent with the data . these estimators form a convex set under the likelihood plateau .    in order to choose an estimator from the convex set for statistical prediction",
    ", we can consider the maximum - entropy principle advocated by e. t. jaynes  @xcite .",
    "in doing so , one obtains a unique estimator that maximizes both the likelihood and",
    "the von neumann entropy functional .",
    "statistically , this estimator is least - biased for the informationally incomplete data . in @xcite , we developed and applied an algorithm , based on the steepest - ascent method , to approximately look for the maximum - likelihood - maximum - entropy ( mlme ) estimator .",
    "this algorithm involves a parameter that needs to be chosen just above a minimum threshold to obtain an estimator that is as close to the actual mlme estimator as possible . in general , this threshold depends on the true state @xmath0 .",
    "therefore , one needs to run the algorithm a few times to estimate this threshold .",
    "this paper is organized as follows .",
    "after a brief review of this steepest - ascent algorithm in section  [ sec : br ] , we introduce a numerical scheme that is based on completely different principles to directly search for the mlme estimator within the convex set in section  [ sec : aasdp ] . this scheme couples two separate optimization techniques  semidefinite programming ( sdp ) and a derivative - free optimization method  to maximize the entropy over linear combinations of a maximal set of linearly independent ml estimators that spans the ml convex set .",
    "it will be shown that , owing to the mechanisms of sdp , one can make use of this scheme to infer the expectation values of a set of entanglement witnesses to verify the presence of entanglement in the unknown quantum state for composite systems .",
    "finally , in section  [ sec : emlme ] , we establish a more robust numerical scheme that systematically generates the maximal set of linearly independent ml estimators that defines the convex set without fail . instead of sdp , this scheme utilizes a nonlinear optimization routine that finds the global maximum of a highly nonlinear functional that is used to generate this maximal set .",
    "the likelihood functional @xmath2 for a set of measurement data @xmath3 collected with a pom @xmath4 is given by + @xmath5 where @xmath6 refers to the number of occurrences of the outcome @xmath7 and @xmath8 .",
    "the corresponding frequencies are given by @xmath9 .",
    "in ml state estimation , the concave log - likelihood functional @xmath2 is maximized to obtain the ml estimator @xmath10 '' is used to denote all estimators . ] for the given set of data . if the number of linearly independent outcomes is @xmath11 , with @xmath12 being the dimension of the hilbert space , the data is informationally complete and the estimator @xmath10 is unique . in the case where this number is less than @xmath11 ,",
    "the data is informationally incomplete and there exists now a continuous set of @xmath10 that yield the same maximal likelihood .",
    "this set is convex since the likelihood functional is concave in @xmath13 .    to choose the estimator @xmath14 that has the highest entropy out of this convex set",
    ", we can consider the lagrange functional + @xmath15 where @xmath16 is the lagrange multiplier corresponding to the constraint of maximal entropy @xmath17 .",
    "in doing so , we maximize the two functionals @xmath18 and @xmath19 simultaneously .",
    "we define @xmath20 to be the estimator that maximizes @xmath21 .",
    "if @xmath22 , @xmath23 and maximizing this lagrange functional is just the procedure of ml . since the data is informationally incomplete , there exists a convex plateau structure for the log - likelihood functional and maximizing @xmath21 yields a convex set of estimators . for large @xmath16 values , the term @xmath24 dominates , so that the resulting estimator @xmath25",
    "when @xmath16 takes on a very small positive value @xcite , the contribution from @xmath24 becomes relatively much smaller than that of @xmath26 , and any variation of the von neumann entropy functional is only detectable over the state space region that coincides with the likelihood plateau . in other words , maximizing @xmath27 is equivalent to maximizing the entropy over the plateau .",
    "therefore , @xmath28 .",
    "the iterative algorithm that is based on the steepest - ascent method is described in @xcite-@xcite .    in practice",
    ", there is a limit to how small @xmath16 can be .",
    "in particular , when @xmath16 is smaller than some numerical threshold @xmath29 , the gradient of @xmath24 is no longer visible . in this case",
    ", the algorithm treats @xmath30 as @xmath31 and performs ml estimation .",
    "hence , the optimal parameter @xmath16 is to be slightly above @xmath32 so that @xmath33 .",
    "this inevitably introduces a small bias to the estimator .",
    "determining the value of @xmath32 analytically is quite complicated because @xmath32 is actually a function of the true state and the pom , that is @xmath34 .",
    "since @xmath0 is unknown to us , one needs to estimate @xmath32 through repeated runs of the algorithm . in the next section",
    ", we will introduce an alternative scheme to search for the exact mlme estimator .",
    "to obtain the unique mlme estimator that has the highest entropy , a search has to be performed within the ml convex set . in this section ,",
    "we introduce a numerical procedure to estimate @xmath14 in two steps .",
    "the first step is to obtain a collection of boundary states of the convex set for the measurement data obtained . in the next step",
    ", the operator @xmath14 can be estimated using these boundary states with a standard function optimization routine .    to carry out the first step , we need to identify the boundary of the ml convex set . especially for large dimensions ,",
    "the boundary of the convex set has an extremely complicated geometry that is too difficult to be analytically determined .",
    "instead , we investigate its boundary by numerical means .",
    "we begin with the fact that the real functional @xmath35 , where the operator @xmath36 , is a linear functional of @xmath13 .",
    "therefore , if we try to maximize ( or minimize ) @xmath37 over some subspace of @xmath13 that has a well defined boundary , the maxima ( or minima ) of this linear functional are always on the boundary of this subspace",
    ". we can thus generate boundary states by maximizing or minimizing @xmath37 , for a given hermitian operator @xmath38 , over the ml convex set .",
    "this problem is equivalent to the following optimization task : +    this is a standard linear optimization problem , with linear and positivity constraints , that can be solved with the help of sdp @xcite .    at this point",
    ", we need to find out the minimum number of boundary states that is required to search for @xmath14 . to do this",
    ", we represent a generic ml estimator @xmath10 by a set of @xmath11 linearly independent hermitian operators @xmath39 are all linearly independent , the rank of the matrix @xmath40 with elements @xmath41 is @xmath42 . ]",
    "trace - orthonormal hermitian basis operators @xmath43 satisfying the condition @xmath44 . with these basis operators , we can separate @xmath45 into the part in the measurement subspace of dimension @xmath46 , and the rest of the state space that constitutes the unmeasured parameters ( the unmeasured subspace ) of dimension @xmath47 , where @xmath48 , @xmath49 and @xmath50 . the generation of the basis operators @xmath51 that span the measurement subspace can be done by the gram - schmidt orthonormalization procedure on the @xmath7s , with all conventional inner products for vectors replaced by trace inner products for operators . in other words ,",
    "the number of linearly independent pom outcomes @xmath7 is @xmath46 . to generate the rest of the basis operators that span the unmeasured subspace",
    ", we continue the gram - schmidt procedure using randomly generated positive operators instead of the @xmath7s .",
    "from , it can be deduced that the maximum dimension of the ml convex set is @xmath47 . to show this",
    ", we note that _ every _ ml estimator contains the same operator @xmath52 since the probabilities of @xmath53 are fixed and @xmath54 for all @xmath7 by definition of the trace - orthonormal basis operators .",
    "this implies that the only difference between any two ml estimators in the convex set is @xmath55 .",
    "as the operators @xmath52 and @xmath55 are linearly independent , it follows that any ml estimator can always be expressed as a linear combination of the unique @xmath52 and the @xmath47 linearly independent basis operators that define @xmath55 .",
    "this means that a set of @xmath56 linearly independent boundary states is enough to look for the mlme estimator . as the operator @xmath52",
    "is fixed by the measurement operators , the maximal number of free parameters that span the convex set is @xmath47 . in some cases , however , the dimension of the ml convex set is lower due to the positivity constraint imposed on the ml estimators . in the extreme case ,",
    "the convex set is restricted to a single point in state space . in these situations , we do not know its actual dimension and repeated generation of boundary states is necessary to estimate the maximum number of linearly independent boundary states .",
    "we remind the reader that with enough linearly independent states , the exact mlme estimator can be obtained up to numerical precision . in section  [ sec : emlme ] , a different numerical procedure will be introduced to generate the maximal set of linearly independent ml estimators that spans the ml convex set without requiring any knowledge of the convex set .    apart from serving as a routine to numerically compute the boundary states of the convex set",
    ", sdp provides an additional useful function . for composite quantum systems , if one selects the hermitian operators @xmath38 to be entanglement witnesses @xmath57",
    ", one can obtain information about the presence of entanglement in the unknown true state even with informationally incomplete data .",
    "these witnesses have the properties that @xmath58 for all separable states @xmath59 and @xmath60 for at least one entangled state @xmath61 .",
    "the sdp routine , described above , thus looks for the maximum ( or minimum ) value of @xmath62 for any chosen witness operator @xmath57 over the space of positive @xmath13s .",
    "this way , we can in fact infer a set of maximum ( or minimum ) witness expectation values over the ml convex set from this optimization procedure .",
    "the set of inferred maximum witness expectation values is particularly informative , for if the maximum value of @xmath62 for at least one of the randomly generated operators @xmath57 is negative , we can immediately conclude that the true state is entangled since this state must lie within the ml convex set that results from the incomplete data . for practical computation , we can choose the witness operators @xmath57 to be of the decomposable form @xmath63 , where @xmath64 is a positive operator with no product kets in its range and the symbol `` @xmath65 '' denotes a partial transposition with respect to the @xmath66th subsystem .",
    "for bipartite systems , these operators are optimal witnesses @xcite , that is no other witnesses can detect all entangled states that are detected by this witness , as well as other entangled states . for multipartite systems , these operators still serve as entanglement witnesses since @xmath67 , although they are no longer optimal in general . to obtain a random set of boundary states of the ml convex set",
    ", random statistical operators @xmath64 are generated using the relation + @xmath68 where @xmath69 is a random operator which , when expressed in the computational basis , has complex matrix elements that are distributed according to the standard normal distribution of zero mean and unit variance .",
    "the second step involves an optimization procedure to maximize the entropy @xmath18 using the generated set of @xmath70 linearly independent boundary states @xmath71 . for the purpose of entanglement detection ,",
    "these boundary states are obtained by maximizing the linear functionals @xmath62 of a set of witness operators @xmath57 over the ml convex set according to the recipe described above .",
    "we start by writing a generic ml estimator as a linear combination of @xmath72 inasmuch as + @xmath73 where the @xmath74s are normalized coefficients , such that @xmath75 , that are in general real such that @xmath76 .",
    "the task now is to look for the values of @xmath77 for which the function @xmath78 is maximum over all real normalized coefficients .",
    "the unconstrained optimization of this @xmath79-dimensional function with respect to @xmath74 can be performed with any efficient multi - dimensional unconstrained optimization routine that is included in the standard libraries of commercialized mathematical softwares . in matlab , for instance , the function ` fminsearch ` does the job using the nelder - mead simplex method ( nms ) .",
    "when @xmath79 is large , it is suggested in @xcite that an adaptive version of the nelder - mead simplex method ( anms ) may be more advantageous in terms of shorter computation time .",
    "we take the resulting operator @xmath80 as the sdp  mlme estimator .",
    "there is , however , a caveat to this optimization .",
    "since the positivity of @xmath81 is no longer guaranteed over the entire space of real normalized vectors , the entropy + @xmath82 expressed in terms of the eigenvalues @xmath83 of the statistical operator @xmath84 that is represented by its eigenbasis @xmath85 , can take complex values . in order to restrict the optimization to yield only positive sdp  mlme estimators",
    ", one can replace the entropy function in with the conditional function + @xmath86 which effectively restricts the original search region to the admissible state space . to check",
    "if the evaluated operator @xmath87 is positive , a highly efficient way is to determine whether or not it admits a cholesky decomposition .    for full - rank sdp  mlme estimators",
    "@xmath88 , there is a simple way to check that @xmath88 is indeed the mlme estimator .",
    "we recall that the form of the mlme estimator is given by @xmath89 where each @xmath90 is a lagrange multiplier for the constraint @xmath91 for any ml estimator @xmath10 in the convex set .",
    "if @xmath14 is full - rank , it follows from that the operator @xmath92 is a linear combination of only the pom outcomes , that is @xmath92 resides in the measurement subspace .",
    "this is equivalent to the set of conditions @xmath93 for all @xmath94s . defining the variables @xmath95",
    ", the quantity @xmath96 can be used to determine if @xmath88 is close to the actual mlme estimator up to some numerical precision .    in summary",
    ", both the mlme estimator and information about the entanglement of @xmath0 can be obtained with informationally incomplete data using the following algorithm , which we coin as sdp  mlme : +    figure [ fig : two_qubit ] summarizes the results .",
    "+   +    in figure  ( [ fig : mepart ] ) , the convergence of @xmath97 is consistent with the fact that , in principle , the maximal number of nine linearly independent boundary states is enough to express the mlme estimator .",
    "the entanglement detection ratio in figure  [ fig : ent_det_ratio ] is computed as the ratio of the number of detected pure states to the total number of generated states for every number of boundary states used .",
    "ideally , this ratio eventually goes to one if enough witness operators are generated to detect all the random pure states since there are no positive partial - transpose entangled states in this case @xcite . for benchmarking , figure  [ fig : mlme_dist ]",
    "is generated to confirm the consistency of sdp  mlme with the mlme algorithm described in section  [ sec : br ] .",
    "there exists an average bias in [ fig : mlme_dist ] that arises from a fixed @xmath98 for all the pure states .",
    "despite the usefulness of sdp in entanglement verification and boundary states generation as discussed in section [ sec : aasdp ] , the speed of the sdp routine strongly depends on the dimension of the hilbert space and the total number of linear constraints imposed by the measurement data . when the total number of pom outcomes is large , there will generally be a considerable slowdown of the sdp routine as the search accounts for a large set of linear constraints in addition to the positivity constraint .",
    "another feature of the sdp routine is that the sequence of boundary states that are generated from random hermitian operators are not guaranteed to be linearly independent of one another .",
    "this means that typically , one would need to generate a large set of ml estimators that contains the maximal number of linearly independent estimators that span the ml convex set . for convex sets of large dimensions , this approach can be time - consuming . in this section ,",
    "we propose a different search routine , in place of sdp , to directly look for linearly independent ml estimators within the ml convex set in a deterministic way . with this routine",
    ", we establish a feasible algorithm to look for the exact mlme estimator .    to begin , we recall that a given set of @xmath79 linearly independent ml estimators , as in , implies the existence of a full - rank @xmath99 positive gram matrix @xmath100 with elements given by + @xmath101 this hints a straightforward strategy to cumulatively obtain the maximal set of linearly independent ml estimators that spans the entire ml convex set : starting with a single ml estimator , the next estimator containing the same @xmath52",
    "should be chosen such that the smallest eigenvalue @xmath102 of the gram matrix @xmath100 for these two estimators is maximized , and so forth , with the maximization performed over positive estimators @xmath103 .",
    "in general , @xmath104 is a nonlinear functional of @xmath100 that has multiple local stationary points .",
    "this functional is also not differentiable and has undefined gradients at the boundary of the state space . to search for its global maximum ,",
    "an appropriate numerical method to use is a nonlinear optimization algorithm that invokes pattern searches @xcite and can cope with functionals that have ill - defined gradients .",
    "the solver for this algorithm , ` patternsearch ` , is readily available in matlab .",
    "the positivity constraint @xmath103 is incorporated into the optimization algorithm using the augmented lagrangian method with cholesky decomposition . another versatile feature of the proposed routine is that it can be set to terminate when the maximal number of linearly independent ml estimators is generated , such that the next ml estimator always yields a zero eigenvalue for @xmath100 .",
    "we can , therefore , deterministically obtain the maximal set of linearly independent ml estimators that spans the ml convex set in this manner , in contrast with the sdp routine in sdp  mlme . in this sense ,",
    "the routine is operationally robust even without any prior information about the convex set . to ensure that the search is numerically stable , it is favorable to start the pattern search algorithm from a highly - mixed ml estimator",
    "this is obtained by performing sdp as a couple of times and defining the starting estimator as an equal mixture of the resulting ml boundary estimators and the fairly mixed ml estimator obtained from the ml algorithm starting from the maximally - mixed state in computing the ml probabilities . using this maximal set ,",
    "the mlme estimator can be directly obtained by maximizing the entropy function in over all linear combinations of the linearly independent ml estimators in the set .",
    "these lead to the following pattern search mlme algorithm ( ps  mlme ) for incomplete quantum state estimation : +    the performance of ps  mlme depends not only on the dimension @xmath47 of the unmeasured subspace , but also on the complexity of the functional @xmath102 . more generally , as the dimension of the hilbert space , or that of the unmeasured subspace , increases , the number of local maxima of @xmath102 increases .",
    "this translates to a longer computation time to locate the global maximum in the search for linearly independent ml estimators .",
    "thus , for very large dimensions , ps  mlme becomes inefficient and the approximate mlme algorithm , which is based on steepest ascent @xcite , is a more practical substitute . on the other hand ,",
    "ps  mlme consistently gives more accurate mlme estimators as compared to the steepest - ascent algorithm , which yields biased results for large dimensions because of the finite @xmath16 parameter .",
    "hence , there is a tradeoff between computation time and the accuracy of the mlme estimators .",
    "figure  [ fig : cvx_sa ] compares the performances of the ps  mlme and the steepest - ascent mlme algorithms for varying hilbert space dimensions .",
    "+   +    figure  [ fig : accuracy ] shows the consistently more accurate results obtained with ps  mlme as compared to the steepest - ascent algorithm , in exchange for its longer computation time , illustrated in figure  [ fig : cputime ] , for higher dimensions .",
    "the simulations show that for the moderately large dimensions considered in figure  [ fig : cvx_sa ] , much more accurate mlme estimators can be obtained using ps  mlme with longer computation time that is of the same order as that with steepest ascent . to reduce the computation time of ps  mlme , one can consider an approximate maximization of @xmath102 as long as the resulting value is sufficiently large . throughout the simulations , the duration of searching for each optimal ml estimator",
    "is restricted to five seconds . for even larger dimensions",
    ", ps  mlme can be computationally demanding even when approximate maximization is carried out , and the steepest - ascent algorithm turns out to be a more realistic option .",
    "efforts to further improve the performance of the ps  mlme scheme are in the works .",
    "nevertheless , we hope that the current work can serve as a stepping stone that helps to spur interesting discussions and novel contributions in related fields on numerical optimization over convex sets of positive operators .",
    "we have introduced a scheme to look for the unique estimator that maximizes the likelihood and entropy for informationally incomplete measurement data .",
    "this involves two main procedures : a generation of linearly independent boundary maximum - likelihood estimators that spans the convex set with semidefinite programming , and an entropy maximization with these estimators using a standard function optimization routine .",
    "furthermore , for composite quantum systems , one can apply this scheme to infer the expectation values of a set of entanglement witnesses .",
    "this information allows us to verify the entanglement of any quantum state with informationally incomplete data .",
    "however , semidefinite programming does not offer a definite control over the generation of maximum - likelihood estimators .",
    "this motivated us to develop an alternative scheme that is more operationally robust than the former one to search for the maximum - likelihood - maximum - entropy estimator .",
    "this latter scheme makes use of the pattern search optimization algorithm that is suitable for maximizing a nonlinear function required to deterministically generate the maximal set of estimators that defines the convex set . with numerical simulations",
    ", we showed that the latter scheme gives much more reliable results than the mlme algorithm discussed in section  [ sec : br ] at the expense of slightly longer computation time when the dimension of the reconstruction hilbert space , or the unmeasured subspace , is moderately large .",
    "this work is supported by the nus graduate school for integrative sciences and engineering and the centre for quantum technologies , which is a research centre of excellence funded by ministry of education and national research foundation of singapore , as well as the technology agency of the czech republic , project no .",
    "te01020229 ( center of digital optics ) , and the czech ministry of industry and trade , project no .",
    "fr - ti1/364 .",
    "99 fisher r a 1922 _ phil .",
    "trans . r. soc",
    ". london _ * 222 * 309 helstrm c w 1976 _ quantum detection and estimation theory _",
    "( new york : academic press ) ehek j and paris m 2004 _ lecture notes in physics ",
    "quantum state estimation",
    "_ vol  649 ( berlin heidelberg : springer ) ehek j , hradil z , knill e and lvovsky a i 2007 _  a _ * 75 * 042108 jaynes e t 1957 _ _ * 106 * 620 jaynes e t 1957 _ _ * 108 * 171 teo y s , zhu h , englert b - g , ehek j and hradil z 2011 _ _ * 10 * 020404 teo y s , englert b - g , ehek j and hradil z 2011 _  a _ * 84 * 062125 teo y s , stoklasa b , englert b - g , ehek j and hradil z 2012 _  a _ * 85 * 042317 vandenberghe l and boyd s 1996 _",
    "siam  review _ * 38 * 49 zhu h , teo y s and englert b - g 2010 _  a _ * 81 * 052339 lewenstein m , kraus b , cirac j i and horodecki p 2000 _  a _ * 62 * 052310 gao f and",
    "han l 2010 _ comput .",
    "_ * 51 * 259 audet c and dennis jr j e 2003 _ siam j. opt . _ * 13 * 889"
  ],
  "abstract_text": [
    "<S> there exists , in general , a convex set of quantum state estimators that maximize the likelihood for informationally incomplete data . </S>",
    "<S> we propose an estimation scheme , catered to measurement data of this kind , to search for the exact maximum - likelihood - maximum - entropy estimator using semidefinite programming and a standard multi - dimensional function optimization routine . </S>",
    "<S> this scheme can be used to infer the expectation values of a set of entanglement witnesses that can be used to verify the entanglement of the unknown quantum state for composite systems . </S>",
    "<S> next , we establish an alternative numerical scheme that is more computationally robust for the sole purpose of maximizing the likelihood and entropy . </S>"
  ]
}