{
  "article_text": [
    "multivariate time series modeling is an important component for the quantitative assessment of relationships between variables in many applied areas .",
    "this issue is essential in financial applications , for example , enabling optimal portfolio allocation , setting trading strategies over sectors of the market , or exchanging rates @xcite .",
    "in addition , the vector autoregressive model ( var ) is widely used in many fields such as economics @xcite , geophysics @xcite , bioinformatics @xcite and neuroscience @xcite .",
    "the main reasons for the attractiveness of the var model in applied areas are its simplicity and relation with the concept of granger causality @xcite .",
    "granger causality has become a prominent concept in connectivity networks modeling , because it provides inferences about the direction of information flow between different time series .",
    "several studies in biological systems emphasize the importance of identification and description of gene regulator networks @xcite , mainly in the study of tumors or structural diseases .",
    "@xcite introduced the utilization of var - based models to study these issues by applying these models to gene expression datasets . in neuroscience , the _ functional integration _",
    "theories highlight that brain functions heavily depend on neural connectivity networks @xcite .",
    "several neuroimaging studies @xcite suggested that var models and granger causality are suitable to identify the information flow between neural structures .",
    "nevertheless , it is well known that most biological measurements are subject to error , since the precision of acquisition equipments is never absolute . actually , this limitation is present in most studies involving experimental data , such as chemistry , physics , biometrics , etc .",
    "although technically incorrect , the most common procedure is simply to ignore the measurement errors , i.e. : assume that the variables of interest are the observed variables .",
    "it is important to highlight that this assumption has serious implications .",
    "the utilization of conventional var model in this case would not identify correctly the relationships between the variables of interest ( latent variables ) .",
    "it happens because the model white noise will not be independent which leads to misestimations of the model parameters .",
    "the usual assumption is acceptable when the errors are negligible .",
    "however , it is known that due to acquisition processes limitations , the measurement errors in biology ( e.g. : gene expressions or brain signals ) are not negligible . in these cases ,",
    "the utilization of conventional var models may result in biased parameter estimation and as a consequence , unreliable granger causality detection .    in the following ,",
    "we define the usual var model ( for a more detailed description , see for instance , * ? ? ?",
    "let @xmath2 denotes a @xmath3 vector of time series variables .",
    "the usual var(r ) model has the form @xmath4 where @xmath5 is the sample size , @xmath6 for @xmath7 are @xmath8 coefficient matrices and @xmath9 is a @xmath3 unobservable zero mean white noise vector process with covariance matrix @xmath10 .",
    "for convenience , we consider that @xmath11 for all @xmath12 .",
    "we are assuming throughout this paper that model ( [ var ] ) satisfies the stability condition defined in @xcite on page 12 .",
    "therefore , under stationarity conditions , the mean and the autocovariance function are given , respectively , by @xmath13 @xmath14=\\sum_{j=1}^r \\bm{b}_j \\bm{\\gamma}(h - j ) , \\quad \\mbox{for } \\ \\   h = 1,2,3 , \\ldots\\ ] ] and @xmath15 where @xmath16 denotes the @xmath17 identity matrix and @xmath18 .",
    "model ( [ var ] ) can be written in short as @xmath19 where @xmath20 is a @xmath21 matrix and @xmath22 .    therefore , if the white noise has normal distribution , the conditional maximum likelihood ( ml ) estimators of @xmath23 , @xmath24 and @xmath25 are equal to the ordinary least squares estimators .",
    "they are given , respectively , by @xmath26 where @xmath27 , @xmath28 , @xmath29 , @xmath30 and @xmath31 .",
    "the consistence of those conditional ml estimators is assured under the stationary conditions ( see * ? ? ? * for further details ) .",
    "the consistence is shown using the fact that    @xmath32 where ",
    "@xmath33 \" denotes convergence in probability when the sample size increases , @xmath34 denotes the kronecker product , @xmath35 is a @xmath36dimensional column vector of ones , and the covariance function of @xmath37 is given by @xmath38\\\\ & = & \\left [ \\begin{array}{cccc } \\bm{\\gamma}(h )      & \\bm{\\gamma}(h+1 )    & \\ldots & \\bm{\\gamma}(h+r-1)\\\\ \\bm{\\gamma}(h-1 )    & \\bm{\\gamma}(h )      & \\ldots & \\bm{\\gamma}(h+r-2)\\\\",
    "\\vdots              & \\vdots              & \\ddots & \\vdots \\\\ \\bm{\\gamma}(h - r+1 ) & \\bm{\\gamma}(h - r+2 ) & \\ldots & \\bm{\\gamma}(h ) \\end{array}\\right].\\end{aligned}\\ ] ]    as described previously , var modeling is commonly applied for detecting granger causality relationships .",
    "the basic idea of granger causality is the evaluation of temporal information founded on the assumption that the cause always precedes its effect @xcite .",
    "let @xmath39 and @xmath40 be two time series . from the statistical perspective , @xmath39 is said to granger - cause @xmath40 if the prediction error of @xmath40 , conditioning on the past values of both series , is less than considering solely the past values of @xmath40 .",
    "in other words , the past values of @xmath39 contains relevant information to improve the predictions of @xmath40 .",
    "note that granger causality concept is not equivalent to classical aristotelian causality , since the former is based solely on prediction errors .",
    "however , due to its simplicity , it may be applied to identify possible effective causalities .",
    "one possible approach of using var models for granger causality detection is by performing statistical tests on @xmath6 s coefficients .",
    "considering @xmath40 equation , if there is at least one coefficient multiplying the past values of @xmath39 which is not equal to zero , then @xmath39 is said to granger - cause @xmath40 .",
    "thus , this procedure involves the estimation of @xmath41 , their respective covariance matrices , and the application of hypothesis testing .    in general",
    ", many physical , biological and chemical variables have the measurement process subject to random effects and it is very common analyze them by using models assuming that these measurement errors are negligible",
    ". it may bring up undesirable features as biased estimates as well as their standard errors and , as a consequence , dangerously false confidence intervals and hypotheses testing will often be obtained using such approach .",
    "thus , it is necessary to consider the measurement error on the modeling of these type of time series .    in this paper",
    ", we study a var model with main concern on including measurement errors .",
    "let @xmath42 be the true variable that is not directly observed , instead a substitute variable @xmath43 is observed which has an additive structure given by    @xmath44    where @xmath45 is the observed vector and @xmath46 is the measurement error vector with mean zero and variance - covariance matrix @xmath47 . in most cases , if the usual conditional ml estimator is adopted for the observations subject to errors , i.e. , replacing @xmath42 with @xmath43 in the equation ( [ var ] ) , the estimator of @xmath48 will be biased ( as can be seen in ( [ olsp ] ) ) .",
    "therefore , in order to overcome this limitation the measurement errors should be included in the estimation procedure . nevertheless , the model ( [ var ] ) with the equation ( [ erro ] ) is not identifiable , since the covariance matrices of @xmath9 and @xmath49 are confounded when @xmath50 .",
    "it is easy to see that in the univariate ar(1 ) , note that when @xmath51 and @xmath52 we have : @xmath53 with @xmath54 , @xmath55 and @xmath56 for all @xmath57 .",
    "it is impossible to estimate @xmath58 and @xmath59 separately by observing only @xmath60 .",
    "this problem can be avoided by using previous knowledge about the variance of @xmath49 .",
    "this paper is organized as follows .",
    "section 2 proposes consistent estimators for the var model with measurement errors and also presents the asymptotic distribution of the estimator of the elements of @xmath48 . in section 3",
    ", simulation studies are undertaken to investigate some aspects of the proposed estimators ( rejection rates for a test of hypothesis , biases and mean square errors ) also it is verified the impact by erroneously considering the usual model .",
    "we applied the models in a functional magnetic resonance imaging dataset in section 4 and we finish the paper with conclusions and remarks in section 5 .",
    "in the presence of measurement errors , the conventional ml estimation of var models produces biased estimators and they can lead to wrong statistical inference ( see * ? ? ? * in which it is found a discussion over errors - in - variables in regression models ) .",
    "there are some studies about measurement errors in times series ( e.g. , * ? ? ?",
    "* ; * ? ? ?",
    "those studies use kalman filtering methodology and an expectation and maximization algorithm that requires intensive iterative procedures . @xcite",
    "have provided a careful expose of the identifiability of some time series models with errors in variables .",
    "@xcite describes approaches based on state space modeling and kalman filtering and demonstrates the usefulness of these tools in dynamic models .",
    "@xcite show the efficiency gains adopting an errors - in - variables model , and the precision of kalman filter estimates in the face of autocorrelation .",
    "these measurement techniques have been applied to a variety of substantive problems , including dynamic representation , social problems ( such as racial inequality ) , monetary policy and public entrepreneurship ( * citar * ) .",
    "these state space models can be attractive alternatives to conventional var modeling .",
    "however , in practice , the implementation of the estimators are not described in analytical form , but by interactive algorithms or numerical optimization solutions .",
    "in addition , the derivation of estimators convergence , standard errors , consistence and asymptotic distribution may be complex in these cases . in @xcite ,",
    "the section on state space methods shows an alternative procedure for how to estimate @xmath48 , @xmath10 and @xmath47 under model ( [ var ] ) with the error equations ( [ erro ] ) , using the em algorithm . @xcite",
    "proposed another iterative procedure to estimate these parameters .",
    "nevertheless , as the main goal of this paper is to test granger causality , these approaches can not be used , since the model becomes unidentifiable under the hypothesis @xmath61 .    in this study",
    ", we provide simple and closed forms for the estimators when @xmath47 is known , which allows the direct derivation of their respective asymptotic properties .",
    "since the main concern of several practical applications is granger causality testing , this information is essential to data analysis . in this section ,",
    "the main concern is the parameter estimation and its asymptotic properties .",
    "theorem [ esthomo ] states consistent estimators for the model parameters and theorem [ asympesthomo ] establishes the asymptotic distribution for the estimator of @xmath62 given in theorem [ esthomo ] , where @xmath63 is an operator that heaps the columns of the matrix @xmath64 .",
    "the methodology presented in this section is based on correcting the asymptotic bias of conventional ml estimator caused by the measurement error effect .",
    "the outcome is a consistent estimator with good asymptotic properties such as normality .",
    "the estimators and the asymptotic covariance matrix for the proposed estimator of @xmath62 are computed easily and no iterative procedure is required .",
    "we must remark that those estimators are not the conditional ml estimators nor the ml estimators taking into account the measurement errors which are very complicated to reach by maximizing the likelihood , even under normality of the errors .",
    "[ esthomo ] if @xmath65 with @xmath66 known .",
    "then , the parameters of the model ( [ var ] ) under measurement errors as in ( [ erro ] ) have consistent estimators given by    @xmath67^{\\top}\\ ] ]    and    @xmath68 where @xmath69 , @xmath70 , @xmath71 and @xmath72 .    the proof of theorem [ esthomo ] can be found in appendix [ a ] .",
    "notice that , if @xmath73 , that is , when there is no measurement error , then the estimators of theorem [ esthomo ] become the conditional ml estimators presented in ( [ vest ] ) .",
    "also , it can be seen that the conditional ml estimator of @xmath48 from the model ( [ var ] ) , without considering the errors ( [ erro ] ) , is given by @xmath74^{\\top},\\ ] ] which is not consistent , since    @xmath75^{-1}.\\ ] ]    the main steps to demonstrate ( [ olsp ] ) is given in appendix [ a ] , in which is sufficient to compute the limit of @xmath76 and @xmath77 .",
    "the quantity @xmath76 has two sources of variations , one that refers to the unobservable variable @xmath37 and another one that refers to the measurement error . if the measurement error is huge and the sample size is not large enough , the quantity @xmath78 may not be positive definite and the estimator @xmath79 , presented in ( [ beta ] ) , will be inadmissible",
    ". if the quantity @xmath78 has at least one eigen value close to zero the estimator @xmath79 , presented in [ beta ] , will be unstable ( because the computation of a matrix inverse requires all eigen values to be different from zero ) .",
    "if the matrix @xmath47 is well specified , one way to avoid such inadmissibility and instability is increasing the sample size .    in many practical applications ,",
    "there is some interest on testing some elements of the matrix @xmath48 ( e.g. , the so called granger causality test ) .",
    "however , the exact distribution of @xmath80 is hard to compute .",
    "thus , one can use its asymptotic distribution to build confidence regions and hypothesis testing as an approximation when the sample size is finite .",
    "the theorem below gives us the asymptotic distribution of @xmath80 .",
    "[ asympesthomo ] if @xmath81 with @xmath66 known and @xmath82 for all @xmath83 , where @xmath84 is the @xmath85 element of @xmath86 .",
    "then , the asymptotic distribution of @xmath80 obtained in theorem [ esthomo ] is given by    @xmath87    where the @xmath88 matrix @xmath89 is given by    @xmath90    where    @xmath91 + \\\\ & &   - \\sum_{h=1}^{r}\\bigg\\ { ( \\bm{b}_{h } \\bm{\\sigma}_{e})\\otimes\\bm{\\gamma}_r(h ) + ( \\bm{\\sigma}_{e}\\bm{b}_{h}^{\\top})\\otimes\\bm{\\gamma}_r(-h)\\bigg\\ } + \\\\ & & +   \\sum_{h=1-r}^{r-1 } [ \\bm{b}(\\bm{j}_{-h } \\otimes \\bm{\\sigma}_e)\\bm{b}^{\\top}]\\otimes \\bm{\\gamma}_r(h).\\end{aligned}\\ ] ]    and @xmath92 , where @xmath93 is a ( @xmath94 ) matrix of zeros with one s in the @xmath95 diagonal above ( below ) the main diagonal if @xmath96 ( @xmath97 ) and @xmath98 is a ( @xmath94 ) matrix of zeros .",
    "the proof of theorem [ asympesthomo ] can be seen in appendix [ b ] . for all",
    "@xmath99 and @xmath100 we have @xmath101 , as given in @xcite . the normal distribution assumption for the measurement error",
    "is required to compute the expectation of polynomial functions ( until forth degrees ) of the elements of @xmath49 .",
    "notice that , if @xmath102 we have the @xmath103 model and the asymptotic covariance simplifies to    @xmath104 where    @xmath105.\\ ] ]    the @xmath106 element of @xmath80 , is asymptotically normally distributed with standard error given by the square root of @xmath106 diagonal element of @xmath89 .",
    "thus , we can obtain hypotheses tests on the individual coefficients , or more general form of contrasts    @xmath107 which involves coefficients across different equations of the var model .",
    "thus , granger causality testing can be carried out by adequately specifying this contrasts matrix .",
    "an illustrative example is the case of series @xmath39 and @xmath40 , in which we are interested in evaluating the granger causality from @xmath39 to @xmath40 in an @xmath99-order var model .",
    "the matrix @xmath64 has @xmath99 rows , one for each coefficient related to the past values of @xmath39 in the @xmath40 equation .",
    "considering that each column of @xmath64 refers to each var coefficient , the contrast matrix is specified by simply setting 1 to the cell at the respective column and row for the @xmath39 coefficients in @xmath40 equation .",
    "this may be tested using the wald - type statistic conveniently expressed as    @xmath108^{-1}(\\bm{c}\\mbox{vec}(\\widehat{\\bm{b}}^{\\top})-\\bm{d})\\ ] ]    under the null hypotheses , ( [ wald ] ) has a @xmath109 distribution in the limit , where @xmath110 gives the number of linear restrictions .",
    "the above study can also be developed to the intercept model estimator , it can be found by applying the delta method @xcite in the asymptotic distribution of ( @xmath111 , @xmath112 , @xmath113 ) , since @xmath114 .",
    "although , this asymptotic distribution is important to test hypotheses regarding the model intercept , it is outside the main scope of this article and does not have any impact on the granger causality , for this reason we skip it .",
    "in this section we conduct some simulation studies in order to evaluate the adequacy of the asymptotic distribution of @xmath80 for small and moderate samples sizes .",
    "computations were performed using the software r ( www.r-project.org ) . for each setup of parameters and sample sizes",
    ", we considered @xmath115 monte carlo samples generated from a var(1 ) model with measurement errors , given by    @xmath116{z_{1,t-1 } \\choose z_{2,t-1 } } + { q_{1t}\\choose q_{2t}},\\\\ { z_{1,t } \\choose z_{2,t } } & = & { z_{1,t } \\choose z_{2,t } } + { e_{1t}\\choose e_{2t}}.\\end{aligned}\\ ] ]    in all samples , we have considered the following setup of parameters : @xmath117 , @xmath118 ,    @xmath119,\\ ] ] where the vector parameters values of ( @xmath120 ) were the values of the set @xmath121 , where @xmath122 , the variance of the measurement error @xmath49 was @xmath123 , and the size samples @xmath124 .",
    "the rejection rates of the hypothesis @xmath125 ( i.e. , @xmath126 does not help to explain @xmath127 and @xmath128 does not help to explain @xmath129 ) are shown in table [ tab : n ] , in which the test sizes are the rejection rates under the null hypothesis ( that appears in bold )",
    ". the wald - type statistics ( [ wald ] ) is used at 5% nominal level . from this table",
    "we have that , the test sizes from the proposed model are closer to the nominal level ( 5% ) as compared to the usual approach for all sample sizes .",
    "furthermore , when @xmath5 increases the test sizes for the usual model also increase and , consequently , they do not converge to the adopted nominal level .",
    "this is a somewhat expected behavior because the usual approach produces biased estimates and standard errors .",
    "table [ tab : n ] depicts the power of the test in each methodology , which shows a good performance of the proposed approach .",
    "nevertheless , it is not possible to compare the power between the two methods because they have different empirical test sizes .    [ [ table [ tab : n ] ] ]    we observe that ,",
    "the results shown in table [ tab : n ] are similar for other values of the parameters @xmath130 and @xmath48 , if we maintain the same proportionality of @xmath10 and @xmath47 as defined above .",
    "but , our simulations suggest that the larger the measurement error , the larger the sample size required to have a good asymptotic approximation for the wald - type statistics ( [ wald ] ) .    we also conduct simulation studies for testing the simple hypothesis @xmath131 at 5% nominal level . in this study , we keep fixed the value of @xmath132 .",
    "others simulations were built considering others values for @xmath133 , however , the results are close to each other and , for this reason , we omit them . as can be seen , tables [ tab : n ] and [ reject ] present similar behaviors , i.e. , the proposed model has always empirical size test closer to the nominal level than the usual model .",
    "[ [ table [ reject ] ] ]    in table [ tab : n ] and [ reject ] , the usual approach seems to be most powerful than the proposed approach when @xmath134 and @xmath135 .",
    "however , as aforementioned , they can not be compared directly , just because the real nominal level used to compute that powers are not the same .",
    "thus , we used a descriptive measure in order to analyze both methodologies around the null hypothesis .",
    "let @xmath136 be the probability of the error type i using the true distribution of ( [ wald ] ) when the sample size is @xmath5 and @xmath137 is the adopting nominal level based on its asymptotic distribution .",
    "for instance , in table [ reject ] we have estimated @xmath138 for the proposed approach and @xmath139 for the usual approach .",
    "an expected behavior for good statistics is @xmath140 which means that the quantiles of the true distribution of ( [ wald ] ) will be close to the quantiles of the asymptotic distribution , @xmath109 , when the sample size is sufficiently large .",
    "thus , the relation @xmath141 tell us how far is the @xmath137-quantil of the asymptotic distribution from the true distribution of ( [ wald ] ) for each @xmath5 .",
    "therefore , we can define a sort of corrected power as    @xmath142 where @xmath143 is the power using the true probability of the error type i , namely @xmath136 .",
    "we are just penalizing the power by the distance between @xmath136 and @xmath137 .",
    "notice that , the power under the null hypothesis has to be the nominal level and for comparing powers from different statistics it must be done using the same nominal level .",
    "let @xmath144 and @xmath145 be the true probability of the error type i for two different statistics when the sample size is @xmath5 . then , under the null hypothesis , we have    @xmath146 and hence , the corrected powers @xmath147 and @xmath148 are comparable . moreover , under an alternative hypothesis and when @xmath5 increases , an expected behavior of @xmath149 is to converge to one .",
    "although , this corrected power is not a monotonic function of the sample size nor of the nominal level , we believe that it is a kind of descriptive measure to evidence how unsuitable is the usual model when compared with the proposed one outside the null hypothesis . furthermore , the proposed corrected power varies between @xmath150 and infinity .",
    "figure [ fig:1 ] shows the corrected power for both approaches , the null hypothesis was @xmath131 .",
    "the full line refers to the proposed approach and the dashed line refers to the usual one .",
    "the panels ( a.1 ) , ( b.1 ) , ( c.1 ) and ( d.1 ) refer to the corrected power when the alternative hypothesis are @xmath151 , @xmath152 , @xmath153 and @xmath154 , respectively at @xmath155 .",
    "the panels ( a.2 ) , ( b.2 ) , ( c.2 ) and ( d.2 ) refer to the corrected power when the alternative hypothesis are @xmath151 , @xmath152 , @xmath153 and @xmath154 , respectively at @xmath156 . the panels ( a.3 ) , ( b.3 ) , ( c.3 ) and ( d.3 ) refer to the corrected power when the alternative hypothesis are @xmath151 , @xmath152 , @xmath153 and @xmath154 , respectively at @xmath157 .",
    "we observe in all graphs that , the usual approach has the worst performance ( going to zero when the sample size increases ) while the proposed one have an expected behavior for a good statistic ( going to one when the sample size increases ) . in general",
    ", the corrected power under the usual methodology goes to zero because the distance between @xmath136 and @xmath137 increases much faster than the uncorrected power , @xmath158 , when @xmath5 increases .",
    "this behavior is still true for another setup of parameters .",
    "[ [ figure [ fig:1 ] ] ]    [ [ table [ vicioeqm ] ] ]    table [ vicioeqm ] shows that , for this set of parameters , the biases of the estimators of @xmath159 ( @xmath160 ) from the proposed model is smaller than the value supplied by the usual model .",
    "the larger the sample size , the smaller the bias and mse under the proposed model ( this does not happen for the usual approach ) .",
    "as previously described , the models with measurement errors have great relevance in applied sciences , since equipment imprecisions are inherent to data acquisition .",
    "actually , the usual models are commonly applied ignoring these errors .",
    "nowadays , the scientific community started to pay enough attention to the fact that these procedures may lead to spurious results . in this section",
    ", we illustrate the concepts introduced in the present study with an application embedded in neuroscience research , with the utilization of var modeling for the characterization of brain networks .",
    "the dataset explored in this application is proceeding from a functional magnetic resonance imaging ( fmri ) experiment .",
    "basically , fmri acquisition is based on monitoring the bold signal ( blood oxygenation level dependent ) at several brain regions through time .",
    "one of the main advantages of fmri over other imaging techniques is its non - invasive protocol and relative high spatial resolution .",
    "the bold signal is related to oxygen consumption and blood flow , being considered as an indirect measure of local neural activity ( @xcite ) . regarding this property ,",
    "this signal is used to quantify and locate the brain activity in humans .    in this study ,",
    "the bold signals at four brain regions from a subject in a resting state ( eyes closed ) condition were considered .",
    "the data was collected in a siemens 3tesla mr system ( tr=1800ms , ta=900ms , te=30ms ) .",
    "the selected brain regions were : left primary motor cortex ( left m1 ) , right primary motor cortex ( right m1 ) , supplementary motor area ( sma ) and right cerebellum .",
    "the anatomical location of this areas is shown in figure [ figareas ] .",
    "these areas are frequently involved in active and planned right hand fingertapping .",
    "we aim to evaluate the information flow between these areas in a resting state condition by using var models for granger causality identification .",
    "a well described limitation inherent to all fmri acquisition is the high level of scanner noise .",
    "thus , the signals observed mirror not only the physiological variations but also includes measurement errors . for this specific dataset",
    ", it was estimated that the error composed approximately @xmath161 of the observed time series standard deviation . for simplicity , each observed series were normalized to have mean zero and variance one .",
    "thus , the measurement error was considered to be serially uncorrelated , independent of the latent variables and with a standard deviation of @xmath162 .",
    "the model considered for the latent variable is given by @xmath163 where @xmath164 is the time series length , @xmath165 with @xmath166 the _ left m1 _ bold signal , @xmath167 the _ sma _ bold signal , @xmath168 the _",
    "right m1 _ bold signal and @xmath169 the _ right cerebellum _",
    "bold signal ; @xmath170 is the @xmath171 autoregressive coefficients matrix    @xmath172    and @xmath173 is an @xmath174 unobservable zero mean white noise vector .",
    "the observed variables are given by    @xmath175    where @xmath176 and @xmath177 is the measurement error vector .",
    "the time series plots corresponding to the respective observed bold signal at each brain region are represented in figure [ figsignal ] .",
    "since we are interested in identifying the links of connectivity networks using granger causality , the statistical inferences are related to the parameters @xmath159 @xmath178 .",
    "if @xmath179 , then there is a information flow from brain area @xmath180 to area @xmath181 ( @xcite ) .",
    "the coefficient estimates , standard errors and p - values ( @xmath182 vs @xmath183 ) for both usual and proposed approaches are shown in tables [ app1 ] and [ app2 ] , respectively .",
    "[ [ figure [ figareas ] ] ]    [ [ figure [ figsignal ] ] ]    [ [ figure [ fignetwork ] ] ]    [ [ figure [ figqqapp ] ] ]    [ [ table [ app1 ] ] ]    [ [ table [ app2 ] ] ]    the results described in tables [ app1 ] and [ app2 ] suggest the existence of bidirectional information flow between left m1 and cerebellum .",
    "however , the application of usual approach indicates also that left m1 sends information to sma and right m1 , and that the latter sends to sma .",
    "for both usual and proposed approaches , the diagrams of the networks at the significance level of 5@xmath184 are shown in figure [ fignetwork ] .",
    "as highlighted by the simulations results , the utilization of usual var estimation , ignoring the measurement errors , may result in wrong test nominal sizes . in this context , it is important to mention that the main differences between the usual and proposal results were on standard deviation estimates .",
    "further , the proposal estimates are almost twice the values resulting from usual approach .",
    "the theory and simulations suggest the existence of biases in the latter .",
    "consequently , the p - values from the usual method tend to be underestimated , resulting in high rejection rates .",
    "note that this connections may possibly exist , but since the nominal level of the test is `` incorrect '' , the type i error is not under control .",
    "in addition , note that some coefficients were considerably underestimated , for example @xmath185 , @xmath186 and @xmath187 . finally , the qq - plots represented in figure [ figqqapp ] suggest that the probability density of residuals @xmath188 are reasonably approximated by the normal distribution .",
    "some studies ( @xcite ) suggest the existence of functional networks between motor areas even in resting state condition .",
    "these studies are based on correlation analysis between the bold signal at different brain sites .",
    "first , it is important to note that granger causality is conceptually different from correlation , which is symmetric ( it does not provide the direction of information flow ) , evaluated in a pairwise fashion ( and not in the full multivariate sense ) and it does not take into account temporal information .",
    "in fact , correlation analysis is more closely related to instantaneous granger causality concept , which can be useful to quantify simultaneity between time series but it is unsuitable in the context of information flow detection .",
    "second , the usual correlation analysis does not consider the presence of measurement errors , which may also affect the statistical significance of results .",
    "the nature of functional networks in resting state is still unclear and is the subject of several studies ( @xcite ) .",
    "nevertheless , we have demonstrated in this study that the inclusion of measurement errors can considerably influence the final results .",
    "thus , the development of novel approaches dealing with this artifact is necessary .    in summary ,",
    "since the proposal and usual results differ , we conclude that the presence of measurement error can not be ignored .",
    "an adequate treatment for this artifact is essential for the adequate description and modeling of brain networks .",
    "it is surprising that this important limitation received proper attention only recently .",
    "we believe that a preliminary analysis of this problem points toward the demand for the development of new estimation procedures regarding scanner noise characterization , physiological noise and computational implementation .",
    "this paper has introduced a new approach to model multivariate times series when measurement errors are present .",
    "the simulation studies indicate that the proposed approach gives coherent results ( test size close to the nominal level even for small samples , power increasing with the sample size under alternative hypotheses , biases and mean square errors decreasing when the sample size increases ) under small and moderate measurement error .",
    "such features seem no to be shared by the conventional maximum likelihood estimators which presents a much poorer performance .",
    "furthermore , the proposal is easily attained and iterative procedures are not required .",
    "the theory , simulations and application showed that the presence of measurement error can not be neglected and a proper model has to be considered for the adequate description and modeling of brain networks .",
    "we expect to report generalizations of the proposed model ( for elliptical errors and heteroscedasticity situations ) , a residual study and more simulation studies for large measurement errors on incoming papers .",
    "@xmath190 we must study the limits of the quantities @xmath76 , @xmath77 , @xmath191 and @xmath192 when the sample size goes to infinity . note that @xmath193 , where @xmath194 , and under the stationary conditions of a @xmath195 model we have that      where @xmath197 , and @xmath198 means limited in probability even multiplying by @xmath199 ( it happens with the crossing product in the above expression ) .",
    "that is , @xmath200 . following the same scheme , we have that            the proof idea has three steps .",
    "the first step consists in show that @xmath206 can be written as linear combinations of a vectorial mean .",
    "the second one , we must demonstrate that this vectorial mean has an asymptotic normal distribution .",
    "the last step must conclude that @xmath206 also has an asymptotic normal distribution . in order to prove theorem [ asympesthomo ]",
    ", we need some auxiliary results , which are exposed in two propositions below .",
    "* proof : * define @xmath211 as a vector ( @xmath212 ) of coefficients associated with the @xmath213 element of the vector @xmath214 , that is @xmath215 thus , we have that @xmath216 and the estimator of theorem [ esthomo ] for it can be written as @xmath217 , where @xmath218 and @xmath219 for @xmath220 . moreover , the model ( [ varcol ] ) may be rewritten in terms of the observed variables as                      [ prop2 ] if @xmath81 with @xmath66 known and @xmath82 for all @xmath83 , where @xmath84 is the @xmath85 element of @xmath86 .",
    "the mean , @xmath231 , of proposition [ prop1 ] has an asymptotic distribution given by      @xmath233 + \\\\ & &   - \\sum_{h=1}^{r}\\bigg\\ { ( \\bm{b}_{h } \\bm{\\sigma}_{e})\\otimes\\bm{\\gamma}_r(h ) + ( \\bm{\\sigma}_{e}\\bm{b}_{h}^{\\top})\\otimes\\bm{\\gamma}_r(-h)\\bigg\\ } + \\\\ & & +   \\sum_{h=1-r}^{r-1 } [ \\bm{b}(\\bm{j}_{-h } \\otimes \\bm{\\sigma}_e)\\bm{b}^{\\top}]\\otimes \\bm{\\gamma}_r(h).\\end{aligned}\\ ] ]      * proof : * notice that the expectation of @xmath234 is equal to zero for all @xmath181 .",
    "@xcite state a central limit theorem to a univariate m - dependent sequence of random variables with mean zero .",
    "we say that a time series @xmath39 is m - dependent if the set of values @xmath235 is independent of the set of values @xmath236 ( * ? ? ?",
    "66 ) . then , assuming that @xmath237 for all @xmath238 where @xmath84 is the @xmath85 element of @xmath86 and defining @xmath239 , where @xmath240 we have that @xmath241 , @xmath242 and    @xmath243 + e[\\bm{f}_{ih } \\otimes \\bm{e^*}_{i-1}\\bm{e}_{i - h-1}^{\\bm{*}\\top } ] + \\\\ & + & e[\\bm{f}_{ih } \\otimes \\bm{e^*}_{i-1 } ( \\bm{z^*}_{i - h-1}-\\bm{\\mu^*})^{\\top } ] + e[\\bm{f}_{ih } \\otimes(\\bm{z^*}_{i-1}-\\bm{\\mu^*})\\bm{e}_{i - h-1}^{\\bm{*}\\top } ] - \\\\ & -&\\bm{\\psi}\\bm{\\psi}^{\\top}\\end{aligned}\\ ] ]      @xmath245 @xmath246 @xmath247 @xmath248\\otimes \\bm{\\gamma}_r(h ) - ( \\bm{b}_{h } \\bm{\\sigma}_{e})\\otimes\\bm{\\gamma}_r(h ) \\qquad \\mbox{for } \\quad h = 1,\\ldots , r-1,\\ ] ] @xmath248\\otimes \\bm{\\gamma}_r(h ) - ( \\bm{\\sigma}_{e}\\bm{b}_{|h|}^{\\top})\\otimes\\bm{\\gamma}_r(h ) \\qquad \\mbox{for } \\quad h = -1,\\ldots , 1-r,\\ ] ] @xmath249 \\qquad \\mbox{for } \\quad h=0,\\ ] ] where @xmath93 is a ( @xmath94 ) matrix of zeros with one s in the @xmath95 diagonal above ( below ) the main diagonal if @xmath96 ( @xmath97 ) and @xmath98 is a ( @xmath94 ) matrix of zeros .",
    "that is , @xmath250 is a strictly m - dependent sequence of random variables with mean zero ( where @xmath251 ) and , therefore , we can use the result stated in @xcite , which says that @xmath252 where      @xmath233 + \\\\ & &   - \\sum_{h=1}^{r}\\bigg\\ { ( \\bm{b}_{h } \\bm{\\sigma}_{e})\\otimes\\bm{\\gamma}_r(h ) + ( \\bm{\\sigma}_{e}\\bm{b}_{h}^{\\top})\\otimes\\bm{\\gamma}_r(-h)\\bigg\\ } + \\\\ & & +   \\sum_{h=1-r}^{r-1 } [ \\bm{b}(\\bm{j}_{-h } \\otimes \\bm{\\sigma}_e)\\bm{b}^{\\top}]\\otimes \\bm{\\gamma}_r(h).\\end{aligned}\\ ] ]              abler , b. , roebroeck , a. , goebel , r. , hose , a. , schonfeldt - lecuona , c. , hole , g. , walter , h. ( 2005 ) . investigating directed influences between activated brain areas in a motor - response task using fmri .",
    "magn reson imaging .",
    "* 24*(2):181 - 5 .",
    "aigner , dennis , c. hsiao , a. kapteyn , and t. wansbeek .",
    "latent variables in econometric time - series . in handbook of econometrics , z. griliches and m. intriligator ( eds . ) ,",
    "amsterdam : north - holland .",
    "fujita , a. , sato , j.r .",
    ", garay - malpartida , h.m . , yamaguchi , r. , miyano , s. , sogayar , m.c .",
    ", ferreira , c.e .",
    "( 2007a ) . modeling gene expression regulatory networks with the sparse vector autoregressive model .",
    "bmc syst biol . textbf30:1 - 39 .",
    "fujita , a. , sato , j.r .",
    ", garay - malpartida , h.m . ,",
    "morettin , p.a . ,",
    "sogayar , m.c .",
    ", ferreira .",
    "( 2007b ) .",
    "time - varying modeling of gene expression regulatory networks using the wavelet dynamic vector autoregressive method . bioinformatics . * 23*(13):1623 - 30 .",
    "geweke , john .",
    "`` the dynamic factor analysis of econometric time - series . '' in latent variables in socio - economic modelse , dennis j. aigner and arthur s. goldberger ( eds . ) , amsterdam : north - holland .",
    "goebel , r. , roebroeck , a. , kim , d.s . ,",
    "formisano , e. ( 2003 ) .",
    "investigating directed cortical interactions in time - resolved fmri data using vector autoregressive modeling and granger causality mapping .",
    "magn reson imaging .",
    "* 21*(10):1251 - 61 .",
    "kelly , b.c . ,",
    "bechtold , j. , trump , j.r .",
    ", vertergaard , m. , siemiginowska , a. ( 2008 ) .",
    "observational constraints on the dependence of ratio - quiet quasar x - ray emission on black hole mass and accretion rate .",
    "_ astrophysical journal supplement series_. * 176 * : 355373 .",
    "kulathinal , s.b . ,",
    "kuulasmaa , k. , gasbarra , d. ( 2002 ) .",
    "estimation of an errors - in - variables regression model when the variances of the measurement error vary between the observations .",
    "_ statistics in medicine_. * 21*:10891101 .",
    "long xy , zuo xn , kiviniemi v , yang y , zou qh , zhu cz , jiang tz , yang h , gong qy , wang l , li kc , xie s , zang yf ( 2008 ) .",
    "default mode network as revealed with multiple methods for resting - state functional mri analysis .",
    "j neurosci methods . * 171*(2):349 - 55 .",
    "maravall , a. , and aigner , d. j. ( 1977 ) .",
    "`` identification of the dynamic shock - error model : the case of dynamic regression . '' in latent variables in socio - economic models , dennis j. aigner and arthur s. goldberger ( eds . ) , amsterdam : north - holland .",
    "sato , j.r .",
    ", amaro jr , e. , takahashi , d.y . , de maria felix , m. , brammer , m.j .",
    ", morettin , p.a .",
    "a method to produce evolving functional connectivity maps during the course of an fmri experiment using wavelet - based time - varying granger causality .",
    "neuroimage , * 31*(1):187 - 96 .",
    ".rejection rates ( % ) of the hypothesis @xmath125 ( at 5% nominal level ) using the wald statistics ( [ wald ] ) for @xmath258 , @xmath259 , @xmath260 and @xmath261 .",
    "the bold numbers at the center are test sizes ( they are expected to be 5% ) and the numbers around them are empirical powers . [ cols= \" < , > , > , > , > , > , > , > , > , > , > , > \" , ]"
  ],
  "abstract_text": [
    "<S> this paper develops a method for estimating parameters of a vector autoregression ( var ) observed in white noise . </S>",
    "<S> the estimation method assumes the noise variance matrix is known and does not require any iterative process . </S>",
    "<S> this study provides consistent estimators and shows the asymptotic distribution of the parameters required for conducting tests of granger causality . </S>",
    "<S> methods in the existing statistical literature can not be used for testing granger causality , since under the null hypothesis the model becomes unidentifiable . </S>",
    "<S> measurement error effects on parameter estimates were evaluated by using computational simulations . </S>",
    "<S> the results show that the proposed approach produces empirical false positive rates close to the adopted nominal level ( even for small samples ) and has a good performance around the null hypothesis . </S>",
    "<S> the applicability and usefulness of the proposed approach are illustrated using a functional magnetic resonance imaging dataset . </S>",
    "<S> + _ _ key words : _ </S>",
    "<S> asymptotic property , errors - in - variables model , granger causality , multivariate analysis . </S>",
    "<S> _    0.3 cm    * vector autoregressive models with measurement errors + for testing ganger causality *    0.3 cm    * alexandre g. patriota@xmath0 ,  joo r. sato@xmath1  and  betsab g. blas achic@xmath0 *    0.3 cm    @xmath0departamento de estatstica , universidade de so paulo - sp - brasil    caixa postal 66281 - cep 05314 - 970 , so paulo - sp - brasil    @xmath1 institute of radiology - hospital das clnicas , so paulo - brasil    cep 05403 - 001 , so paulo - sp - brasil </S>"
  ]
}