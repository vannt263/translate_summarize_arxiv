{
  "article_text": [
    "the beowulf project began in 1994 at the nasa goddard space flight center .",
    "the history , current status and a list of about 100 clusters may be found at http://www.beowulf.org .",
    "this year at supercompting 2000 , gordon bell sponsored a prize for a computer constructed or purchased for under $ 10,000 .",
    "thus , cost - effective clustering is a timely topic .",
    "i assume you need to do a lot of computation and need to get it done inexpensively rather than in the shortest time .",
    "it helps if you can run more than one job at a time .",
    "this should be contrasted with weather prediction , where being able to run seven one - day predictions that each take seven days is not very useful . for weather",
    "we must exceed a specific minimal speed that will let us predict tomorrow s weather from current conditions .",
    "the cost model presented here is based on capital expenditure for hardware .",
    "a more sophisticated model would include maintenance , electricity , cooling , floor space , etc .",
    "these design principles are advocated :    \\1 ) know the bottlenecks and requirements of your problem . with this knowledge",
    ", you can avoid building an unbalanced system that , for instance , might put too much money into a network whose high performance is not required .",
    "2 ) design for the sweet spot .",
    "( note : the sweet spot changes with time and may depend on the problem . ) as an example , the highest density memory available at any time tends to be quite expensive .",
    "currently , it is less expensive to buy two 256 mb parts than one 512 mb part .",
    "3 ) design for total system cost effectiveness .",
    "if a 10% increase in the speed of the processor results in a 5% performance increase , since the processor is only one component , the system price increase might be less than 5% .",
    "4 ) benchmark as much as you can before deciding on a design .",
    "a cluster compute node can be very simple .",
    "six items are ( almost ) mandatory : motherboard , cpu , memory , network card , case and floppy drive .",
    "the first three items will be the most expensive if using a fastethernet network ( unless you insist on using rack mounted cases ) .",
    "otherwise , the network card will be a major expense .",
    "some motherboards come equipped with a fastethernet interface .",
    "i have also seen some systems without individual cases .",
    "a hard drive or video card may be useful .",
    "some beowulf designers discourage a hard drive on each compute node .",
    "if your application requires lots of scratch disk i / o , then you may need a disk on the node .",
    "when a node repeatedly fails to reboot , a video card can help diagnose the problem .",
    "( at iu in two years of running with 40 nodes , this has only been necessary about half a dozen times . )",
    "we have a few spare video cards to install when needed .",
    "the indiana university physics department received $ 50,000 in 1998 to build a 32-node linux cluster .",
    "the machine we built in nov .",
    "1998 is called candycane , which stands for cpus and network do your calculation and nothing else .",
    "candycane is an appropriate name because it was designed for the `` sweet spot , '' that is , components were picked to give the best price - performance ratio attainable .",
    "the cost per node was $ 693 for a pentium ii 350 , with a 4.3 gb hard drive and 64 mb of ecc ram .",
    "each node has a floppy drive and a fastethernet card .",
    "the 40-port hp procurve switch cost about $ 2,000 , so the total cost was about $ 25,000 .",
    "in november , 2000 it would have been possible to build this system for @xmath0$320 per node , or for approximately $ 12,000 .",
    "an even more attractive alternative would be a diskless athlon 600 mhz system for which the per node cost is about $ 275 .",
    "this node would have much better performance than the pii 350 ; however , the fastethernet would be a bottleneck on the milc code with kogut - susskind quarks .",
    "even so , a 32 node system with a minimum performance of 1280 and 1660 mflops , for @xmath1 and @xmath2 sites per node , respectively , could be built for under $ 10,500 .",
    "this works out to a cost / mf of between $ 6.3 and $ 8.2 .    in sec .  2",
    ", we describe the key issues for good performance .",
    "section 3 gives details of single node performance .",
    "section  4 points the reader to a web site with extensive benchmarks , gives cost estimates for several designs and compares cost - performance ratios for these clusters and a number of supercomputers . for additional information about emerging technologies for clusters",
    "see ref .  @xcite .",
    "a very simple approach to achieving good performance for domain decomposition codes like lattice qcd codes is to optimize single node performance and to try to avoid degrading performance too much when one has to communicate boundary values to neighboring nodes .",
    "the key to a cost effective design is an appropriate balance .",
    "floating point performance is more easily adjustable than network performance because processors come in many speeds , but there are only a few choices for the network .",
    "a simple performance model of the kogut - susskind conjugate gradient algorithm gives this bandwidth requirement to overlap communication and floating point operations : @xmath3 where @xmath4 is the _ achieved _ bandwidth in megabyte / s , @xmath5 is the _ achieved _ floating point speed in megaflop / s on matrix - vector multiplication and an @xmath6 portion of the grid is on each node .",
    "we assume there are neighboring nodes in each direction , _",
    "i.e. _ , 16 or more nodes",
    ". the constant factor 0.364 is specific to ks quarks .",
    "however , the @xmath7 behavior is typical of the domain decomposition approach to parallelism and comes from the surface to volume ratio .",
    "figure [ fig : performance ] shows a log - log plot of measured bandwidth on a ping - pong test for three types of hardware and the performance model for several processor speeds .",
    "the messages vary in size from 800 bytes to 30 kb for problem sizes of interest .",
    "the arrows near the bottom of the graph correspond to different l values .",
    "the fastethernet and myrinet curves come from measured performance on the roadrunner ( rr ) supercluster at the albuquerque high performance computer center .",
    "two curves are shown for myrinet . with the newer drivers",
    ", bandwidth is better and smoother .",
    "the quadrics curve comes from the teracluster at lawrence livermore national laboratory ( llnl ) .",
    "the measurement was done using the netpipe program from the ames scalable computing laboratory @xcite .",
    "the straight lines come from the performance model presented above and are plotted for matrix times vector speeds of 50 , 100 , 200 and 400 mf .",
    "we need to run at a large enough value of l so that the measured bandwidth is above the straight line ( for whatever speed our processor achieves for the corresponding value of l ) . because of cache effects",
    ", the processors will achieve higher speeds when @xmath8 is small , but that requires the highest bandwidth .",
    "thus , pushing up the communication rate for small messages is important .",
    "being able to run for a small value of @xmath8 with high efficiency allows running a fixed size problem at high total performance .",
    "we see that none of the networks achieves more than a small fraction of its peak bandwidth for the message sizes of interest . a system design based on achieving that peak bandwidth",
    "would almost certainly be communication bound , _",
    "i.e. _ , money would have been spent on floating point capacity that could not be used .",
    "there are large differences in the prices of fastethernet , myrinet and quadrics hardware .",
    "choice of network can obviously play a critical role in system performance and cost - effectiveness .",
    "the single node performance is likely to depend upon such issues as the quality of the cpu , the performance and size of cache(s ) , the bandwidth to main memory and the quality of the compiler . for message passing performance ,",
    "key issues are the latency , peak bandwidth , processor overhead and the message passing software .",
    "it is important to make the right choices when designing your system .    for the cpu",
    ", one can choose among intel celeron , pentium ii , piii , piv , itanium ; amd athlon , thunderbird , duron ; compaq alpha and other possibilities .",
    "the celeron may have limited performance because it only has a 66 mhz front side bus ( fsb ) .",
    "if access to memory is important ( as it is for this application ) the 100 or 133 mhz fsb of the pii and piii will be useful .",
    "the piv is quite new and currently expensive .",
    "itanium is soon to be available and some results are provided below . the alpha has great performance , but it is expensive .",
    "there are currently several memory types available for different processors .",
    "they include pc100 , pc133 , rambus , double data rate ( ddr ) , which is also known as pc1600 or pc 2100 .",
    "pc100 and pc133 are fairly mature at this stage , and there is little difference in price ( currently about 0.5$/mb ) .",
    "rambus was quite expensive at introduction , but has recently decreased quite a bit ( currently slightly more than 1$/mb ) .",
    "ddr is just now coming to market ( micron ) , but it does not carry too much of a premium ( currently similar to rambus ) .",
    "motherboards that use ddr memory are just coming to market .",
    "pick the right amount of memory for your problems : you never want your code to swap , but neither do you want to buy a lot of memory that you never use .",
    "choice of motherboard is crucial .",
    "it must be matched to the processor and memory .",
    "the support chip can have an important impact on performance ( as we explore below ) .",
    "the motherboard determines the number of processors per node .",
    "we discuss below whether dual processor systems are more or less cost - effective for a particular application .",
    "the motherboard will also determine whether you have a faster or wider pci bus than the initial standard 33 mhz-32bit bus .",
    "this may be important if you have a higher speed network like myrinet .",
    "the last critical choice is the network hardware and software .",
    "it properly deserves its own section , but to save space we briefly discuss it here .",
    "fastethernet is the commodity network .",
    "other choices such a myrinet , giganet , gigabit ethernet , quadrics qsnet and sci from dolphin / scali have higher performance , but are quite expensive compared to fastethernet .",
    "( including the card and switch , you can expect to spend about $ 1,500 per node , except for quadrics which is over $ 3,000 per node . ) because of the big jump in price and performance , it is necessary to make sure the system maintains balance between cpu and network . regarding software choices , under fastethernet , mvia@xcite and gamma@xcite software",
    "have reduced latency compared with standard tcp / ip .",
    "i have recently tried vmi under myrinet which is being developed at ncsa and found it to be superior to running under standard gm ( myrinet supplied ) driver .      turning next to single node performance",
    ", we note that it is easy to waste a lot of money on a poor system design . to illustrate this",
    ", we consider the various speed amd athlon processors available and their prices on two particular days .",
    "although we focus on athlon here , the same considerations apply to intel or other processors .",
    "figure [ fig : price_vs_speed ] shows that processor price is a rapidly increasing function of speed .",
    "it can also be a rapidly decreasing function of time , especially for the faster processors .",
    "dividing the price by the speed of the chip , we find that the relative expense rises rapidly for the faster chips @xcite .",
    "on april 7 , 2000 , there was an apparent sweet spot at 600 mhz .",
    "the faster chips have a higher price - performance ratio . depending upon the costs of the other components of the system",
    ", the entire system may have a higher or lower price - performance ratio .    for our qcd codes ,",
    "access to memory is quite important . in our first example",
    ", we compare a celeron chip with a 66 mhz fsb and a pentium ii chip with a 100 mhz fsb .",
    "the pentium s clock speed is only 6% faster than the celeron , but its performance is 38% faster for @xmath96 and 23% faster for @xmath108 .",
    "this is because of its larger cache and 52% faster fsb .",
    "when we overclock the celeron , it has a slower fsb but a faster cpu speed than the pii , and performance is about equal except for @xmath96 where the smaller cache probably is the source of the difference .",
    "this work was supported by the u.s .",
    "doe under grant de - fg02 - 91er 40661 .",
    "special thanks to the milc collaboration , the albuquerque high performance computer center , indiana university , llnl , national center for supercomputing applications , pittsburgh supercomputer center and san diego supercomputer center ."
  ],
  "abstract_text": [
    "<S> small beowulf clusters can effectively serve as personal or group supercomputers . </S>",
    "<S> in such an environment , a cluster can be optimally designed for a specific problem ( or a small set of codes ) . </S>",
    "<S> we discuss how theoretical analysis of the code and benchmarking on similar hardware lead to optimal systems .    </S>",
    "<S> pacs / keywords : 12.38.gc , lattice qcd , linux , beowulf clusters , supercomputing </S>"
  ]
}