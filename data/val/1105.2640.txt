{
  "article_text": [
    "reversible markov chains are central to a number of fields .",
    "they underlie problems in applied probability like card - shuffling and queueing networks @xcite and pervade computational statistics through the many variants of markov chain monte carlo ; in physics , they are natural stochastic models for time - reversible dynamics . however , the notion of reversibility in stochastic proscesses with memory is not as widely discussed , and statistical problems like testing the order of a reversible process remain a challenge .",
    "we define a conjugate prior for higher - order , reversible markov chains , which extends a prior for reversible markov chains by diaconis and rolles  @xcite .",
    "we begin by defining reversibility in a more general setting and motivating the significance of higher - order processes . in section  [ sec2 ] ,",
    "we present two graphical representations for an order-@xmath0 , reversible markov chain , which are used in section  [ sec3 ] to derive the conjugate prior via a random walk with reinforcement .",
    "we dedicate section  [ sec4 ] to variable - order markov chains , a family of models that avoids the curse of dimensionality associated with higher - order markov chains , proving essential in certain applications .",
    "finally in section  [ sec5 ] , we discuss properties of the prior pertaining to bayesian analysis . in examples ,",
    "we test the extent of memory of a lumped markov chain and discretized molecular dynamics trajectories , and compare the posterior inferences of different models .",
    "[ defreversibility ] a stochastic process @xmath1 , with distribution @xmath2 is called _ reversible _ , if for any @xmath3 , @xmath4    it is not difficult to show that reversibility implies stationarity @xcite ; if stationarity is given , the above condition need only be checked for @xmath5 .",
    "now suppose @xmath6 is an order-@xmath0 , irreducible markov chain taking values in a  finite set @xmath7 .",
    "we will also apply the term _ reversible _ to this process when the stationary chain satisfies the reversibility condition .",
    "[ reversibilitycondition ] let @xmath2 be the stationary law of the order-@xmath0 markov chain @xmath6 .",
    "if @xmath8 , then the markov chain is reversible .",
    "it is not difficult to check that the hypothesis together with stationarity imply @xmath9 for any @xmath10 . for any @xmath11 : @xmath12 where we have used the markov property , stationarity and the hypothesis .    as a first remark ,",
    "note that @xmath13 , can be represented as a first - order markov chain @xmath14 , taking values in the space of sequences @xmath15 .",
    "however , the reversibility of @xmath6 does not imply the reversibility of its first - order representation ; therefore , the analysis of higher - order reversible markov chains requires novel techniques . in the following sections , we often use the first - order representation @xmath14 , referring to it nonetheless as an order-@xmath0 markov chain and using the notion of reversibility associated with the markov chain .",
    "secondly , we recall that kolmogorov s criterion is another necessary and sufficient condition for the reversibility of a markov chain , which only depends on the conditional transition probabilities @xcite .",
    "its equivalence to definition [ defreversibility ] in the higher - order case is proven in the .",
    "kolmogorov s criterion requires that the probability of traversing any cycle in either direction is the same .",
    "accordingly , a reversible markov chain can be interpreted as a process with no net circulation in space .    .",
    "in a circuit process started at @xmath16 in @xmath17 , we transition on some circuit that contains @xmath16 with probability proportional to its weight . ]",
    "reversibility is preserved under certain transformations .",
    "for example , let @xmath13 , be a stationary , reversible markov chain and consider a finitely valued function , @xmath18 .",
    "it is easy to check that this process is stationary and reversible , even though it may not be a markov chain of any finite order .",
    "functions or projections of reversible markov chains appear under different guises in physics and other fields , and in many cases the effects of memory subside with time , motivating the use of finite order models .",
    "the problems of determining the order and estimating the parameters of markov models have been studied extensively ; here , we address these problems with the constraint of reversibility .",
    "for any sequence @xmath19 , let @xmath20 be its inverse , @xmath21 the subsequence obtained by deleting its last element and @xmath22 the one obtained by deleting its first element .",
    "we call @xmath23 with @xmath24 an _ admissible path _ if @xmath25 for all @xmath26",
    ". the concatenation of these sequences without repeated overlaps is denoted @xmath27 .    the first representation we will consider is the circuit process of macqueen @xcite .",
    "let a _ circuit _",
    "be a periodic function on @xmath7 , and consider a class of positively weighted circuits @xmath28 ( for an example , see figure  [ circuit process picture ] ) .    a _ circuit process _ of order @xmath0 is a markov chain of the same order , where the transition probability from @xmath29 to any @xmath30 with @xmath31 is given by @xmath32 where @xmath33 is the weight of circuit @xmath34 , and the function @xmath35 counts the number of times that the circuit traverses a sequence in one period . in other words , in each step we move along some circuit in @xmath28 containing the current state with probability proportional to its weight .",
    "the process only visits states that appear in the circuits , for which transition probabilities are well defined .    an irreducible order-@xmath0 markov chain with stationary law @xmath36 is parametrized by @xmath37 for all @xmath38 .",
    "one can check that in a circuit process , this  is just @xmath39 .",
    "macqueen showed that any order-@xmath0 markov chain can be represented as a circuit process on a finite set @xmath28 , which is not unique @xcite .",
    "this is true in particular when the chain is reversible .    .",
    "in a reversible random walk , the two highlighted edges have the same weight . ]",
    "we introduce a second graphical representation that is canonical , unlike the circuit process .",
    "consider a _",
    "de bruijn graph _ on the vertices @xmath15 , which has a directed edge from @xmath16 to @xmath40 if and only if @xmath31 .",
    "that is , every path on the graph is an admissible path . for an example , see figure  [ triangle ] .",
    "assign a weight @xmath41 to each edge , and let @xmath42 be the summed weights of edges departing from @xmath16 .",
    "furthermore , require that @xmath43    the _ reversible random walk of order @xmath0 _ is a random  walk on such a graph , with transition probabilities @xmath44    [ representation ] an irreducible , reversible random walk of order @xmath0 represents a reversible markov chain of the same order .",
    "every irreducible , reversible order-@xmath0 markov chain is equivalent to a unique reversible random walk of order @xmath0 .",
    "let @xmath45 be the stationary distribution of the random walk . to prove the first statement",
    ", we will first verify that @xmath46 for all @xmath29 .",
    "let @xmath47 be the transition probability from @xmath40 to @xmath16 in the random walk ,  and recall that @xmath48 iff @xmath49 , then @xmath50 then , the stationary law @xmath51 in the random walk of a path @xmath52 is just @xmath53 which implies that @xmath54 .",
    "therefore , the @xmath7-valued , order-@xmath0 markov chain represented by the random walk satisfies the reversibility condition in proposition [ reversibilitycondition ] .",
    "proving the second statement is now straightforward .",
    "let @xmath14 , be the first - order representation of an irreducible , order-@xmath0 markov chain , with transition probabilities @xmath55 . by the perron ",
    "frobenius theorem , @xmath56 has a unique stationary distribution @xmath57 .",
    "assign edge weights to the de bruijn graph on @xmath15 , setting @xmath58 .",
    "since the order-@xmath0 markov chain is reversible , it follows directly from proposition [ reversibilitycondition ] that the edge weights satisfy conditions ( [ eq1])([eq3 ] ) .",
    "an edge - reinforced random walk ( errw ) is a random walk on an finite , undirected graph , where every edge - weight is increased by 1 each time it is crossed . since diaconis and coppersmith defined this process @xcite , we have learned that it is partially exchangeable and , by de finetti s theorem for markov chains , a  mixture of markov chains @xcite .",
    "the mixing measure , which lives on the space of reversible markov chains , was more recently characterized in the literature @xcite .",
    "diaconis and rolles showed that this distribution is a conjugate prior for the reversible markov chain , much as the beta distribution , arising from a poly urn scheme , is a conjugate prior for sequences of i.i.d .",
    "binary random variables @xcite .    here",
    ", we construct a conjugate prior for higher - order reversible markov chains via a reinforced random walk in @xmath15 , making use of de finetti s theorem for markov chains .",
    "this process is markedly different from an errw in @xmath15 due to the structure of a reversible markov chain with memory , although it is designed to be partially exchangeable .",
    "let @xmath59 be any sequence on @xmath7 and @xmath40 a sequence shorter than @xmath59 .",
    "define the function @xmath60 , which counts the number of times that @xmath40 appears in @xmath59 , and @xmath61 , which counts the number of times that @xmath40 appears in @xmath59 followed by at least one state .",
    "fix @xmath62 , a stationary measure for an irreducible , reversible , order-@xmath0 markov chain . also fix @xmath63 .",
    "let @xmath64 be a palindromic sequence that starts with @xmath65 and ends with @xmath66 .",
    "choose a positive constant @xmath67 , such that for all @xmath38 , @xmath68 .",
    "now , given a sequence @xmath69 , starting with @xmath65 , and any sequence @xmath40 , define the functions @xmath70 when @xmath69 represents the path of a stochastic process in @xmath17 up to time @xmath71 ( formally , @xmath72 ) , we will use the notation @xmath73 and @xmath74 .",
    "[ reinforcement ] the _ reinforced random walk of order @xmath0 _ is a stochastic process @xmath75 , on @xmath15 with distribution @xmath76 .",
    "the initial state is @xmath65 with probability 1 . for any admissible path @xmath77 , the conditional transition probability @xmath78 whenever @xmath79 is admissible and zero otherwise .",
    "the law @xmath76 also depends on @xmath64 and @xmath67 .",
    "these parameters are constant in the following discussion , so they are omitted from the notation for conciseness . when @xmath80 , this process is equivalent to an errw . in this case , the palindrome is unnecessary because the terms involving @xmath64 in @xmath81 and @xmath82 can be modeled with a different @xmath62 . for @xmath83 ,",
    "this is not the case , and @xmath64 is essential for partial exchangeability ( see proposition [ pe ] ) .",
    "[ circuit_interpretation ] this process admits an interpretation as a reinforcement scheme of the circuit process .",
    "consider a circuit process of order @xmath0 with stationary probability @xmath84 for all @xmath38 .",
    "in addition , consider three weighted sequences : the palindrome @xmath64 , a sequence @xmath69 that represents the path of the reinforced process from the initial state @xmath65 up to the current state , and the reversed path @xmath85 .",
    "these are depicted in figure  [ reinforcement_picture ] along with their weights @xmath86 , @xmath67 and @xmath67 , respectively .",
    "as in the circuit process , we move along any circuit or sequence that contains the current state with probability proportional to its weight . the reinforcement is accomplished by elongating the paths @xmath69 and @xmath85 .",
    "[ errw_interpretation ] the process is also a reinforcement scheme of a modified reversible random walk of order @xmath0 .",
    "consider a weighted de bruijn graph , where for every admissible @xmath52 , @xmath87 .",
    "then , for every @xmath88 in the palindrome @xmath64 , subtract @xmath67 from @xmath89 .",
    "the reinforcement scheme will consist of a random walk on the resulting graph , where after every transition @xmath90 we increase both @xmath91 and @xmath92 by @xmath67 .",
    "accordingly , if @xmath93 is a  palindrome , the weight @xmath91 is increased by @xmath94 .    [ pe ]",
    "the reinforced random walk of order @xmath0 is partially  exchangeable in the sense of diaconis and freedman @xcite .",
    "we must show that the probability @xmath95 of any admissible path @xmath77 is a function of the initial state @xmath65 and the transition counts between every pair of states . for any pair @xmath52 in @xmath15 with @xmath96 ,",
    "let @xmath97 be the total number of transitions @xmath98 , and @xmath99 .",
    "we will show the stronger statement that @xmath65 and @xmath100 are sufficient statistics for the reinforced random walk .     reinforced random walk . ]",
    "let us first establish some properties that are conserved in the process .",
    "for every @xmath38 , the initial weights @xmath101 and @xmath102 are equal .",
    "this is direct from the definition in equation  ( [ w ] ) because : @xmath62 defines a reversible markov chain of order @xmath0 ; the functions @xmath103 and @xmath104 are zero for both @xmath16 and @xmath20 ; and @xmath64 is a palindrome , so if it contains @xmath16 , it also contains @xmath20 , and @xmath105 .",
    "this property is maintained after every transition @xmath106 , because the weights may both be increased by @xmath67 if @xmath107 is @xmath16 or @xmath20 , or both remain constant otherwise .    for every @xmath108 in @xmath15 , the initial weights @xmath109 .",
    "this is direct from equation  ( [ w  ] ) because : @xmath62 is reversible , both @xmath110 and @xmath111 are zero for @xmath40 and @xmath112 , and the sequence @xmath64 is a palindrome , so for every transition starting at @xmath40 there will be another starting from @xmath112 . the last fact is not necessarily true for @xmath65 , because unless @xmath65 itself is a palindrome , @xmath64 will contain a transition starting from it , but no transition starting from @xmath66 .",
    "so , in the beginning , @xmath113 .",
    "when a transition occurs from @xmath65 to @xmath114 , the weights @xmath115 and @xmath116 become equal , while @xmath117 , provided @xmath114 is not a palindrome . hence",
    ", this singularity is preserved by the last state visited by the process .",
    "the probability @xmath118 is a ratio of two products . in the numerator",
    ", we find a factor of the form @xmath119 for every admissible transition @xmath98 , while in the denominator , we find a corresponding weight @xmath120 .",
    "it is easy to check that the numerator is only a function of @xmath100 .",
    "every transition @xmath98 or @xmath99 adds a new factor of @xmath119 , which is always greater than the previous one by @xmath67 .",
    "if @xmath88 is a palindrome , then every new factor of @xmath119 is increased by @xmath94 .",
    "so , the numerator can be computed from the initial weights and @xmath100 .",
    "we have left to show that the denominator is only dependent on @xmath65 and @xmath100 .",
    "note that the transition counts from @xmath40 or @xmath112 are a function of @xmath100 and @xmath65 , because every event @xmath121 is a transition from @xmath40 , while every event @xmath122 is followed by a transition from @xmath112 , unless this is the final state , which is determined by @xmath65 .",
    "after every transition from @xmath40 or @xmath112 , we add a factor of @xmath123 or @xmath124 to the denominator . at any time @xmath125 , these weights differ by @xmath67 ( if @xmath40 is not a palindrome ) , but the factor added is always the smaller of the two . between two transitions , each of these weights is reinforced by @xmath67 , so consecutive factors differ by that amount . if @xmath40 is a palindrome , there is no distinction between @xmath126 and @xmath124 , and consecutive factors differ by  @xmath94 .",
    "[ positive - recurrence ] suppose that in the reinforced random walk , we visit @xmath40 and @xmath112 in @xmath15 infinitely often a.s .",
    ", and let @xmath127 be the @xmath71th time we visit either state .",
    "the process @xmath128 is a mixture of markov chains .",
    "furthermore , if @xmath129 is the ratio of the number of visits to @xmath112 and @xmath40 by @xmath127 , @xmath129 converges a.s . to a finite limit @xmath130 .",
    "we claim that if @xmath131 is partially exchangeable , so is @xmath128 .",
    "it is sufficient to show that the probability of a sequence @xmath132 is invariant upon block transpositions , which generate the group of permutations that preserve transition counts ( @xcite , proposition  27 ) .",
    "the probability of a path @xmath133 in @xmath128 is the sum of the probabilities of all paths @xmath134 in @xmath131 that map to it .",
    "denote this set of paths @xmath135 .",
    "after a transposition of @xmath40-blocks or @xmath112-blocks , the probability of the path in @xmath128 is equal to the sum of the probabilities of a different set of paths @xmath136 in @xmath131 .",
    "however , it is easy to see that this transpostion of @xmath40-blocks or @xmath112-blocks defines a bijection from @xmath135 to @xmath136 , and the probability of each path and its transposition is the same , because @xmath131 is partially exchangeable",
    ". therefore , @xmath128 is partially exchangeable .",
    "furthermore , we assume that @xmath40 and @xmath112 are recurrent , so by de finetti s theorem for markov chains @xmath128 is a mixture of markov chains with a unique measure @xmath137 on the space of 2 by 2 transition matrices @xcite .",
    "note that both states are recurrent with probability 1 , so the subset of transition matrices where one of the states is transient has @xmath137-measure zero .",
    "this implies that @xmath137-a.s .",
    "the transition matrix is irreducible , and since the state space is finite , both states are positive - recurrent .",
    "therefore , @xmath129 converges a.s . to a finite limit.=-1",
    "the reinforced random walk of order @xmath0 traverses  every edge @xmath138 with @xmath139 infinitely often , almost surely .",
    "[ recurrence ]    as @xmath7 is finite , we must visit at least one state in @xmath15 infinitely often , so without loss of generality , let this state be @xmath40 .",
    "let @xmath127 be the @xmath71th time we visit @xmath40 , and @xmath140 be @xmath141 .",
    "for @xmath16 with @xmath142 admissible and @xmath143 , let @xmath144 be the event that @xmath145 .",
    "also , let @xmath146 . by lvy",
    "s extension of the borel ",
    "cantelli lemma ( lemma [ levy ] ) , @xmath147 therefore , to show that the transition @xmath121 is observed infinitely often with probability 1 , it is sufficient to show that @xmath148 a.s .",
    "the conditional probability @xmath149 is just @xmath150 .",
    "let @xmath151 be the event that we observe @xmath112 fewer than @xmath152 times between @xmath153 and @xmath154 .",
    "on @xmath151 , we can lower - bound @xmath149 using the minimum possible value of @xmath155 , which is its initial value , and the maximum possible value of @xmath156 , which is @xmath157 .",
    "thus , @xmath158 now , consider the event @xmath159 .",
    "on this set , for any @xmath160 , we will be in @xmath151 for all but finitely many @xmath161 , which implies @xmath162 , by the previous inequality .",
    "but , by lemma [ positive - recurrence ] we have @xmath163 , so noting @xmath164 we conclude that @xmath165 @xmath76-a.s . , and @xmath166 happens infinitely often . since @xmath62 defines an irreducible markov chain , the proposition follows by induction .",
    "propositions [ recurrence ] and [ pe ] are sufficient to show by de finetti s theorem for markov chains @xcite that the reinforced random walk of order @xmath0 is a mixture of markov chains on @xmath15 , or @xmath167 where @xmath168 is the distribution of a markov chain started at @xmath65 and parametrized by the matrix @xmath169 , @xmath170 is the space of @xmath171 stochastic matrices and @xmath172 is a unique measure on the borel subsets of this space .",
    "let @xmath173 be the set of matrices that represent irreducible , reversible markov chains of order @xmath0 .",
    "the reinforced random walk of order @xmath0 is a mixture of reversible markov chains of the same order , or @xmath174 .",
    "this is a special case of proposition [ concentration ] .",
    "the number of parameters of a markov chain grows as @xmath175 with the order , @xmath0 , which renders higher - order models impractical in many statistical applications . in this section",
    ", we investigate a family of models with finite memory length which do not suffer from this curse of dimensionality .",
    "[ mixed - order definition ] a _ variable - order markov chain _ is a markov chain of order @xmath0 with the constraint that for every _ history _",
    "@xmath176 in the set @xmath177 , if two states @xmath178 both end in @xmath176 , the transition probabilities @xmath179 and @xmath180 are equal for every @xmath30 .",
    "in essence , this is a discrete process which upon reaching a sequence @xmath181 loses memory of what preceded it .",
    "when @xmath182 is empty , we recover a  general markov chain of order @xmath0 .",
    "variable - order markov chains have proven useful in applications where there is long memory only in certain directions .",
    "the literature on the subject can be traced to rissanen @xcite and weinberger @xcite , who developed tree - based algorithms for estimating the set of histories efficiently in the context of compression .",
    "bhlmann and wyner proved several consistency results on these algorithms @xcite , and the former later addressed the problem of model selection @xcite .",
    "for an evaluation of different algorithms in applications , see @xcite .",
    "it is worth noting that macqueen mentioned variable - order markov chains in an unpublished abstract .",
    "however , there is a marked difference between his definition and bhlmann and wyner s , which relates to the closure properties of @xmath182 .",
    "macqueen requires that if @xmath176 is in @xmath182 , then so are all the sequences that begin with  @xmath176 .",
    "intuitively , this means that the process can not recover memory once it is lost .",
    "bhlmann and wyner do not impose this constraint .",
    "however , this is guaranteed when the process is reversible .",
    "[ regaining_memory ] let @xmath13 , be an irreducible , reversible , variable - order markov chain with histories @xmath182 .",
    "if @xmath181 , then @xmath183 is also a history ; additionally , any sequence that has @xmath176 as a prefix is also in @xmath182 .",
    "let @xmath51 be the stationary law of the chain . if @xmath181 , then for any pair @xmath184 , where @xmath185 and the length of @xmath176 sum to @xmath0 , @xmath186 is independent of @xmath187 , or @xmath188 this implies @xmath189 using the fact that @xmath51 is invariant upon time reversal and rearranging factors , we obtain @xmath190 the left - hand side is equal to @xmath191 , which by the previous identity is independent of @xmath192 . as",
    "this is true for any @xmath193 , @xmath183 must be a history in @xmath182 . to prove the second part of the statement , suppose @xmath176 is a prefix of @xmath194 . since @xmath183 is in @xmath182 , and @xmath195 ends in @xmath183 , then by definition @xmath196 . using the first result ,",
    "we conclude that @xmath197 .",
    "we will define a reinforcement scheme , which like the one in the previous section is recurrent , partially exchangeable and , by de finetti s theorem , a  mixture of markov chains .",
    "but , in this case , the mixing measure is restricted to the variable - order , reversible markov chains with a fixed set of histories @xmath182 .",
    "as before , we begin with a stationary , reversible function @xmath62 , an initial state @xmath63 , and a palindromic sequence @xmath64 that starts with @xmath65",
    ". let the function @xmath198 map any sequence to its shortest ending in @xmath182 .",
    "[ mixed - order reinforcement ] the _ variable - order _ , _ reinforced random walk _ is a stochastic process @xmath199 , on @xmath15 with measure @xmath200 .",
    "the initial state is @xmath65 with probability 1 . for any admissible path @xmath77 , the conditional transition probability @xmath201 whenever @xmath79 is admissible and zero otherwise .",
    "this process is a reinforced circuit process , just like the one defined in remark [ circuit_interpretation ] , with the difference that in computing the transition probabilities , instead of taking the current state to be the sequence @xmath202 , we let it be the shortest ending of @xmath203 in @xmath182 , or @xmath204 .",
    "the variable - order , reinforced random walk is partially exchangeable in the sense of diaconis and freedman .",
    "[ mixed - pe ]    this proof is deferred to the .",
    "one can show that this process is recurrent following the same argument of proposition [ recurrence ] . in the proof of proposition  [ recurrence ] , we use a shortest history @xmath176 in place of @xmath40 , and lemma [ positive - recurrence ] still holds for @xmath176 and @xmath183 .",
    "recurrence and partial exchangeability imply @xmath205 for a unique measure @xmath206 characterized by the function @xmath62 , and the initial state , in addition to the parameters @xmath64 , @xmath67 and @xmath182 , which we keep fixed . in the",
    ", we show that @xmath207 is restricted to the reversible , variable - order markov chains with histories @xmath182 .",
    "[ concentration ] let @xmath208 be the set of transition matrices representing an irreducible , reversible , variable - order markov chain where every @xmath181 is a history . then , @xmath209 .",
    "in section  [ sec3 ] , we defined a family of measures in the space of order-@xmath0 , reversible markov chains , and in section  [ sec4 ] we extended it to variable - order , reversible markov chains . in the following , we will show that these distributions are conjugate priors for a markov chain of order  @xmath0 .",
    "we discuss properties of the prior relevant to bayesian analysis , such as a  natural sampling algorithm and closed - form expressions for some important moments .",
    "consider a variable - order , reinforced random walk @xmath210 , @xmath211 , with distribution @xmath200 and take any admissible path @xmath212 .",
    "we define @xmath213 , to be the process with law @xmath214    in words , @xmath215 is the continuation of a variable - order reinforced random walk after traversing some fixed path @xmath216 .",
    "we can rewrite the law @xmath217 which makes it evident that @xmath215 is partially exchangeable , because for a  fixed  @xmath216 , the numerator only depends on the transition counts in @xmath218 , while the denominator is constant .",
    "it is also not hard to see that the process visits every state infinitely often with probability 1 .",
    "therefore , by de finetti s theorem for markov chains , it is a mixture of markov chains with a mixing measure that will be denoted @xmath219 .",
    "suppose we model a process @xmath220 , as a reversible , variable - order markov chain with histories @xmath221 , and we assign a prior @xmath206 to the transition probabilities , @xmath169 .",
    "given an observed path , @xmath222 , the posterior probability of @xmath169 is @xmath219 . in consequence",
    ", the family of measures @xmath223 is closed under sampling .",
    "consider the event @xmath224 . by bayes rule ,",
    "the posterior probability of this event given the observation is the prior probability of @xmath225 divided by the prior probability of @xmath226 . by equation  ( [ post ] ) , this posterior is equal to @xmath227 .",
    "let @xmath228 be the posterior distribution of  @xmath169 given the observation , then for any @xmath229 and any @xmath230 , @xmath231 by de finetti s theorem for markov chains , the mixing measure @xmath232 is unique ; therefore , we must have @xmath233 .    in the next proposition ,",
    "we show that the variable - order , reinforced random walk may be used to simulate from the conjugate prior @xmath207 ( or   a similar argument , a posterior of the form @xmath232 ) .",
    "let @xmath234 be independent samples of the reinforced random walk with initial parameters @xmath62 and @xmath65 .",
    "for any sequence @xmath235 , consider the random variable @xmath236 , the weight defined in equation  ( [ w ] ) for a sample path with distribution @xmath200 , normalized by the path s length .",
    "define the empirical estimate , @xmath237 , to be the mean of this random variable evaluated at the paths @xmath238 .",
    "also , let @xmath239 be the stationary law of an order-@xmath0 markov chain with transition probabilities @xmath169 .",
    "we have seen that @xmath240 has a one - to - one correspondence with @xmath169 .    for any bounded , real - valued function @xmath241 , [ posterior_sampling ] @xmath242    the empirical estimate @xmath243 is the average of i.i.d .",
    "observations , so by the strong law of large numbers , w.p.1 , @xmath244,\\ ] ] where the right - hand side is the expectation in a reinforced random walk with parameters @xmath245 . in the proof of proposition [ concentration ] , we showed that @xmath246 converges @xmath200-a.s . taking the limit as @xmath247 , by dominated convergence , @xmath248.\\end{aligned}\\ ] ] conditional on a variable @xmath169 measurable on its tail @xmath249-field with distribution @xmath206 ,",
    "the reinforced random walk is a markov chain with law @xmath168 .",
    "we know @xmath246 converges @xmath168-a.s . to @xmath250 , so equation  ( [ simulation ] ) follows .",
    "several moments of @xmath200 have closed - form expressions .",
    "in particular , the mean likelihood @xmath168 of any path beginning in @xmath65 is just the probability of the path in the reinforced random walk by equation  ( [ mixed - order mixture ] ) . from the proof of proposition [ mixed - pe ]",
    ", one can deduce a closed - form expression for the law of the variable - order reinforced random walk as a function of the transition counts in a path ( see supplement @xcite ) . from a realization of the transition counts as a path",
    ", one can also compute the law @xmath200 by modeling a random walk with reinforcement .",
    "the expectation of cycle probabilities with a prior @xmath206 on @xmath169 may also be computed exactly .    for any cyclic path",
    "@xmath251 , not necessarily including @xmath65 , the expectation of @xmath252 with prior @xmath207 on @xmath169 has a closed - form expression , provided @xmath101 is greater than @xmath253 for all @xmath38 .",
    "find the shortest cycle @xmath254 with positive weight @xmath62 .",
    "then , for any transition matrix @xmath169 in the support of @xmath207 , we have @xmath255 taking the expectation with a measure @xmath206 on @xmath169 , we obtain @xmath256 by bayes theorem , the product of the likelihood @xmath257 and the prior @xmath258 is equal to the marginal prior probability of the path @xmath259 times the posterior of @xmath169 : @xmath260 where @xmath261 are the weights parametrizing the posterior of @xmath169 given the path @xmath262 . to solve the integral on the right - hand side ,",
    "let us rewrite it using bayes theorem and equation  ( [ mixed - order mixture ] ) , @xmath263 where @xmath264 are the weights @xmath261 reduced by the cycle @xmath265 .",
    "these weights are positive because of the assumption @xmath266 for all @xmath16 , which could certainly be relaxed in some cases . applying equations  ( [ mixed - order mixture ] ) and ( [ ratio ] ) once more",
    ", the last expression becomes @xmath267 which completes our derivation .",
    "the ability to compute these expectations exactly makes it possible to use bayes factors for model comparison @xcite .",
    "given some data @xmath268 and two probabilistic models , where each model @xmath269 has a prior measure @xmath270 and parameters @xmath271 , a bayes factor quantifies the relative odds between them .",
    "it is formally defined as , @xmath272 the ratio between the marginal probabilities of the data under each model .",
    "each marginal probability is sometimes referred to as the _ evidence _ for the corresponding model .",
    "diaconis and rolles apply bayes factors to compare a number of models on different data sets .",
    "they consider reversible markov chains , general markov chains , and i.i.d .",
    "models @xcite , assigning conjugate priors which facilitate computing the marginal probabilities in equation  ( [ bayes_factor ] ) .",
    "the conjugate priors introduced here facilitate similar comparisons , where the family of models under consideration is expanded to include reversible markov chains that differ in their length of memory .",
    "for some data @xmath268 , one can define two variable - order reversible markov models , with different histories , @xmath273 and @xmath274 . in each case",
    ", we assign a conjugate prior , @xmath275 and @xmath276 , respectively , to the transition probability matrix . to make the prior uninformative in some sense",
    "we could set @xmath62 to be uniform for all @xmath38 and let @xmath64 be the shortest palindrome starting with @xmath65 , for example .",
    "the constant @xmath67 is set to 1 .",
    "the bayes factor is then @xmath277        we have seen that the expectations on the right - hand side can be computed exactly when @xmath268 is a path starting at @xmath65 or any cyclic path . in the following example",
    ", we apply this test to finite data sets simulated from a  lumped markov chain .",
    "[ example1 ] a  random walk was simulated on the 9-state graph shown in figure  [ example ] , from which we omitted self - edges on every state , all weighted by 1 .",
    "the observation was lumped into the 3 _ macrostates _ separated by the dashed lines .",
    "this is meant to illustrate a natural experiment , where the difference between the states within each macrostate is obscured by the measurement . from the resulting sequence , we take the initial macrostate and every 7th macrostate thereafter to form a path @xmath268 of length 1000 in @xmath278 .",
    "we test 4 reversible markov models , that differ in the length of memory :    1 .   a first - order , reversible markov chain .",
    "2 .   a second - order , reversible markov chain .",
    "3 .   a variable - order model with maximum order 2 , where states 1 and 3 are histories . intuitively , only state 2 has `` memory . ''",
    "4 .   a variable - order model with maximum order 2 , where states 2 and 3 are histories .",
    "intuitively , only state 1 has `` memory . ''    for each model @xmath269 , we assign a prior @xmath279 to the transition matrix , where @xmath65 is the initial state in @xmath268 , @xmath280 for all @xmath281 and @xmath64 is the shortest palindrome starting with @xmath65 .",
    "we compared the 4 models using 50 independent realizations of the lumped markov chain and found that model 3 had the highest evidence in 72% of the cases , while model 2 was selected in all the remaining cases . in figure",
    "[ boxplot ] , we report a boxplot of the logarithm of the bayes factors comparing models 1 , 2 , and 4 against model 3 .",
    "this represents compelling evidence for model 3 .",
    "the result is not entirely surprising given that this model gives memory to state 2 , which is slowly mixing , as indicated in figure  [ example ] .",
    "the fact that the most complex model ( model  2 ) is not necessarily selected showcases the automatic penalty for model complexity in bayes factors .     and @xmath282 .",
    "the periodic map on the right shows a partition of conformational space into 5 states .",
    "the colored markers indicate the free energy of bins centered at each point , which reveals the metastable nature of this molecule s dynamics . ]",
    "we conclude this section with two applications of bayesian analysis of reversible markov chains to molecular dynamics ( md ) .",
    "an md simulation approximates the time - reversible dynamics of a molecule in solvent .",
    "the trajectories produced by a simulation are discretized in space and time .",
    "the terminally blocked alanine dipeptide , shown in figure  [ alanine ] , is a common test system for markov models of md .",
    "the conformational space of the molecule , which is represented in the figure in a two - dimensional projection , is partitioned into 5 states .",
    "the states are believed to be metastable due to the basins that characterize the free - energy function , also plotted in the figure .",
    "this metastability allows one to approximate the dynamics of the molecule , projected onto the partition , as a reversible markov chain",
    ". the approximation will be good when the discrete time interval at which a trajectory is sampled is larger than the timescale for equilibration within every state , but smaller than the timescale of transitions .",
    "few statistical validation methods are available for markov models of md .",
    "bacallado , chodera and pande used a bayesian hypothesis test to compare different partitions of conformational space @xcite . here",
    ", we apply bayes factors to test a first - order markov model on a fixed partition , by comparing it to second - order and variable - order models on the same partition .",
    "the data @xmath268 are the transition counts in a single md trajectory of 1767 steps sampled at an interval of 6 picoseconds , as recorded in table [ counts ] .",
    "the prior parameters @xmath62 and @xmath64 are the same as in the previous example .",
    "the results of the model comparison are summarized in the following table .",
    "@lcd3.0d3.0d2.0d2.0ccccd2.0d2.0cc@ & & & & & + & & & & & + @xmath283&@xmath284 & & & & & & @xmath283 & @xmath284 & & & & & + & 0 & 261 & 187 & 13 & 2 & 0 & 3 & 0 & 5 & 13 & 2 & 0 & 0 + & 1 & 188 & 144 & 13 & 11 & 0 & & 1&5 & 4 & 2 & 1 & 0 + & 2 & 12 & 4 & 9 & 15 & 0 & & 2&4 & 3 & 16 & 5 & 0 + & 3 & 5 & 1 & 0 & 1 & 0 & & 3&2 & 5 & 3 & 3 & 0 + & 4 & 1 & 0 & 0 & 0 & 0 & & 4&0 & 0 & 0 & 0 & 0 + [ 6pt ] 1 & 0 & 180 & 143 & 22 & 5 & 0 & 4 & 0 & 1 & 0 & 0 & 0 & 0 + & 1&141 & 125 & 5 & 5 & 0 & & 1&0 & 0 & 0 & 0 & 0 + & 2&4 & 3 & 10 & 4 & 0 & & 2&0 & 0 & 0 & 0 & 0 + & 3&4 & 1 & 10 & 3 & 0 & & 3&0 & 0 & 0 & 0 & 0 + & 4&0 & 0 & 0 & 0 & 0 & & 4&0 & 0 & 0 & 0 & 0 + [ 6pt ] 2 & 0 & 16 & 13 & 3 & 0 & 0 & + & 1&16 & 4 & 1 & 1 & 0 & + & 2&12 & 12 & 37 & 11 & 0 & + & 3&9 & 5 & 15 & 6 & 0 & + & 4&0 & 0 & 0 & 0 & 0 & +    [ cols=\"<,^\",options=\"header \" , ]     this represents compelling evidence for a model that gives memory to states 14 , 15 , 30 and 31 .",
    "it is interesting to contrast inferences based on this model to those based on a first - order markov model . to do this , we computed 1000 approximate posterior samples of the transition matrix in each case .",
    "this was done by simulating a reinforced random walk , which is a mixture of variable - order markov chains with the posterior distribution of @xmath169 as a mixing measure ( see proposition [ posterior_sampling ] ) .",
    "the reinforced random walk was simulated @xmath285 steps to obtain each sample .",
    ", in @xmath286 .",
    "all sample means @xmath287 and standard deviations @xmath288 are shown . ]    in figure  [ histograms_stat ] , we histogram stationary probabilities of the transition matrices sampled from the posterior .",
    "in particular , we show plots for the stationary probabilities of states 14 , 15 , 30 and 31 . in the variable - order model",
    ", we define @xmath289 .",
    "the inferences of each model in this case are very similar .",
    "the largest eigenvalues of the transition matrix are also of interest because they are related to different modes of relaxation .",
    "each eigenvalue @xmath290 is associated with a timescale @xmath291 , which is useful in exploratory analysis . here , @xmath292 is the length in time of one step of the markov chain , or 500 picoseconds . in figure",
    "[ histograms eig tim ] , we histogram posterior samples of the three largest nonunit eigenvalues and their associated timescales . in this case , the inferences of each model are quite different , with the variable - order model predicting larger eigenvalues and timescales .",
    "we define a reinforcement scheme for the higher - order , reversible markov chain that extends the errw on an undirected graph .",
    "several properties of the errw , like recurrence and partial exchangeability , were shown to generalize to this process .",
    "other properties may also generalize but were not pursued here .",
    "in particular , we can mention the uniqueness results of johnson @xcite and rolles @xcite , and the fact that mixtures of measures in @xmath293 are weak - star dense in the space of all priors @xcite .",
    "the reinforced random walk leads to a conjugate prior that facilitates estimation and hypothesis testing of reversible processes in which the effects of memory decay after some time .",
    "certain statistical problems remain a challenge , such as inferring the transition matrix with a _ fixed _ stationary distribution . in applications",
    ", it will become important to evaluate the objectivity of the prior and to determine the optimal value of its parameters in this sense .    from a practical point of view , we only discussed bayesian updating for data sets composed of a single markov chain starting with probability 1 from the initial state @xmath65 used in the prior .",
    "numerical algorithms are needed to perform inference with data sets composed of multiple chains .",
    "a starting point could be the method developed by bacallado , chodera and pande to apply the prior of diaconis and rolles to first - order , reversible markov chains @xcite .",
    "in the following , we use the notation defined in the first paragraph of section [ sec2 ] .    let @xmath13 , be an irreducible order-@xmath0 markov chain with transition probabilities @xmath294",
    ". then @xmath295 is reversible if and only if for any cyclic admissible path @xmath296 , @xmath297    the `` only if '' statement is straightforward . by the definition of the stationary distribution and reversibility @xmath298 to prove the `` if '' statement ,",
    "choose an arbitrary state @xmath16 ; then , for any @xmath40 , since the chain is irreducible , there is an admissible path @xmath299 with positive probability .",
    "define @xmath300 where @xmath301 is a positive constant .",
    "note that this expression does not depend on the sequence @xmath302 chosen .",
    "take a different sequence @xmath303 .",
    "let @xmath304 be a palindrome , then because the chain is irreducible , we can find a sequence @xmath305 with positive probability , and it is easy to see from equation  ( [ kolmogorov ] ) that the palindrome @xmath306 has positive probability .",
    "we can construct another palindrome @xmath307 in the same way . multiplying equation  ( [ stat_construction ] ) by factors of 1 , @xmath308 the first four terms equal 1 because the numerator and denominator are the probabilities of the same cycle forward and backward , which are equal by equation  ( [ kolmogorov ] ) .",
    "now , we check that @xmath309 satisfies the reversibility conditions specified in the .",
    "first , we show that @xmath310 .",
    "take a path @xmath311 with positive probability , and the previously found palindrome @xmath307 , then applying the same method , @xmath312 from this , and equation  ( [ stat_construction ] ) we deduce that for any admissible @xmath313 , @xmath314 . since the state space is finite , we can choose @xmath301 such that @xmath57 sums to 1 .",
    "we have shown that the weights @xmath315 satisfy the conditions of a reversible random walk with memory , so by proposition [ representation ] the process with transition probabilities @xmath294 represents a reversible , order-@xmath0 markov chain .",
    "proof of proposition [ mixed - pe ] the probability @xmath316 is a  product of transition probabilities , to which the @xmath71th transition contributes a  factor of @xmath317 we know that @xmath204 can not be longer than @xmath318 by proposition [ regaining_memory ] ; let @xmath319 be the set of histories of @xmath203 that are shorter than @xmath320 .",
    "if this set is nonempty , let us multiply equation  ( [ factor1 ] ) by factors of 1 , to obtain the following factor for the @xmath71th transition : @xmath321 where @xmath322 is the ending of @xmath203 that is longer than @xmath323 by 1 .",
    "the added factor equals 1 because , if @xmath324 , then @xmath320 must end on @xmath323 , which by definition is a history shorter than @xmath320 , a contradiction .",
    "consider all the possible factors in the numerator of @xmath316 .",
    "take any @xmath181 that is _ minimal _ , meaning that it does not end in another history .",
    "for any @xmath325 , we will see a factor @xmath326 after every transition through @xmath327 .",
    "the conjugate factor @xmath328 will appear every time we go through @xmath329 , because :    * if @xmath330 , it is minimal by the closure properties of @xmath182 , so @xmath328 will be the numerator of the first factor in equation  ( [ factor2 ] ) . * otherwise , the minimal history in the transition ending in @xmath329 will be longer than @xmath183 , and there will be an added factor in equation  ( [ factor2 ] ) with @xmath328 in the numerator .",
    "conversely , note that the factor @xmath328 is only added to the numerator of equation  ( [ factor2 ] ) when we go through @xmath329 for some minimal @xmath176 , because we required that @xmath331 , so @xmath181 and does not end in another history .",
    "as in the proof of proposition [ pe ] , we argue that every new factor @xmath326 or @xmath328 is increased by @xmath67 with respect to the previous one ( or by @xmath94 if @xmath327 is a palindrome ) . therefore , the numerator of @xmath316 is only a function of the transition counts and the initial state .    finally , consider all the factors in the denominator of @xmath316 .",
    "take any minimal history @xmath176 .",
    "we will see a factor @xmath332 , for every transition through @xmath176 .",
    "the conjugate factor @xmath333 will appear every time we go through @xmath183 , because :    * if @xmath183 is also minimal , then @xmath333 will be in the denominator of the first factor in equation  ( [ factor2 ] ) .",
    "* otherwise , we know that @xmath334 is not a history , so the transition ending in @xmath183 must have a history at least as long as @xmath183 , which is longer than the history @xmath335 .",
    "so , @xmath333 will appear in the denominator of a factor added in equation  ( [ factor2 ] ) .",
    "conversely , we only add factors of @xmath333 to the denominator of equation  ( [ factor2 ] ) when we go through @xmath183 for a minimal @xmath176 , because we required @xmath336 which implies @xmath176 minimal .    as before , every new factor @xmath332 or @xmath333 will be increased by @xmath67 with respect to the previous one ( or by @xmath94 if @xmath176 is a palindrome ) .",
    "therefore , the denominator is a function of the transition counts and the initial state , and the process is partially exchangeable .",
    "proof of proposition [ concentration ] let @xmath337 be the transition counts from @xmath16 to @xmath40 in the first @xmath71 steps of a stochastic process on @xmath15 . also , define @xmath338 , which counts the visits to @xmath16 .",
    "remember @xmath339 is the set of irreducible transition matrices for variable - order , reversible markov chains where all @xmath181 are histories .",
    "define the event @xmath340 , that the set @xmath341 admissible@xmath342 converges to a transition probability matrix in @xmath339 .    from the recurrence of the variable - order ,",
    "reinforced random walk and equation  ( [ mixed - order mixture ] ) , it is evident that the set of irreducible markov chains has measure 1 under @xmath206 .",
    "in this set , the variables @xmath343 converge almost surely to the transition probabilities , so for any @xmath344 irreducible , .",
    "furthermore , by lemma [ q ] , @xmath340 happens almost surely in the variable - order , reinforced random walk .",
    "putting this into equation  ( [ mixed - order mixture ] ) , we have @xmath345 which implies the proposition .",
    "[ levy ] consider a sequence of events @xmath346 , in some filtration @xmath347 .",
    "let @xmath348 be the total number of events occurring among the first @xmath71 , and let @xmath349 be the sum of the first @xmath71 conditional probabilities .",
    "then , for almost every @xmath350 :    * if @xmath351 converges as @xmath247 , then @xmath352 has a finite limit . *",
    "if @xmath351 diverges , then @xmath353",
    ".    @xmath354 .",
    "[ q ]    for any @xmath16 in @xmath355 , the variables @xmath236 and@xmath356 are functions of @xmath357 , therefore they converge almost surely , because the reinforced random walk is a mixture of irreducible markov chains for which the latter converge .",
    "the reinforcement scheme defined in definition  [ mixed - order reinforcement ] imposes some constraints on the limits of @xmath236 and @xmath356 .",
    "note that @xmath358 , @xmath359 , @xmath246 and @xmath360 never differ by more than @xmath67 ; we also know that the reinforced random walk is positive recurrent ( it is a mixture of irreducible , finitely - valued markov chains ) , so almost surely @xmath361 \\\\[-8pt ]   & = & \\lim_{n\\to\\infty } n^{-1}w'_n(u^*)>0 . \\nonumber\\end{aligned}\\ ] ] denote this limit @xmath362 .",
    "it is also easy to see that if @xmath363 , then for all @xmath364 , @xmath365    now , let @xmath127 be the @xmath71th visit to @xmath29 and let @xmath366 be the event that we make a transition to @xmath40 at @xmath127 .",
    "define @xmath367 we know @xmath368 converges a.s . to @xmath369 .",
    "therefore , @xmath370 a.s . , and by lvy s extension of the borel  cantelli lemma ( lemma [ levy ] ) , @xmath371 this means that @xmath343 converges @xmath200-a.s .",
    "to a set of transition probabilities , @xmath372 , for a variable - order markov chain with histories @xmath182 . to show that this markov chain is reversible , note that @xmath373 is the stationary distribution , because @xmath374 where we used equation  ( [ balance ] ) in the last two identities . by equation  ( [ reversibility of limit ] )",
    ", @xmath373 satisfies the conditions for reversibility .",
    "therefore , @xmath375 .",
    "the author would like to thank persi diaconis and vijay pande for valuable suggestions , and lutz maibaum for providing molecular dynamics datasets ."
  ],
  "abstract_text": [
    "<S> we define a conjugate prior for the reversible markov chain of order @xmath0 . </S>",
    "<S> the prior arises from a partially exchangeable reinforced random walk , in the same way that the beta distribution arises from the exchangeable poly urn . </S>",
    "<S> an extension to variable - order markov chains is also derived . </S>",
    "<S> we show the utility of this prior in testing the order and estimating the parameters of a reversible markov model .    .    </S>"
  ]
}