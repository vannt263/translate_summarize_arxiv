{
  "article_text": [
    "the relay channel was introduced by van der meulen in 1971 @xcite . in this setup ,",
    "a single transmitter with channel input @xmath0 communicates with a single receiver with channel output @xmath1 , where the superscript @xmath2 denotes the length of a vector .",
    "in addition , an external transceiver , called a relay , listens to the channel and is able to output signals to the channel .",
    "we denote the relay output with @xmath3 and its input with @xmath4 .",
    "this setup is depicted in figure [ fig : relay_setup ] .      in @xcite cover & el - gamal",
    "introduced two relaying strategies commonly referred to as decode - and - forward ( daf ) and estimate - and - forward ( eaf ) . in daf",
    "the relay decodes the message sent from the transmitter and then , at the next time interval , transmits a codeword based on the decoded message .",
    "the rate achievable with daf is given in ( * ? ? ? * theorem 1 ) :    [ thm : ceg_daf ] _ ( achievability of ( * ? ? ? * theorem 1 ) ) for the general relay channel any rate @xmath5 satisfying @xmath6 for some joint distribution @xmath7 , is achievable .",
    "_    we note that for daf to be effective , the rate to the relay has to be greater than the point - to - point rate i.e. @xmath8 otherwise higher rates could be obtained without using the relay at all . for relay channels where daf is not useful or not optimal ,",
    "@xcite proposed the eaf strategy . in this strategy , the relay sends an estimate of its channel input to the destination , without decoding the source message at all",
    ". the achievable rate with eaf is given in ( * ? ? ?",
    "* theorem  6 ) :    [ thm : ceg_eaf ] _ ( ( * ? ? ? * theorem 6 ) ) for the general relay channel any rate @xmath5 satisfying @xmath9 for some joint distribution @xmath10 , where @xmath11 , is achievable . _    of course , one can combine the daf and eaf schemes by performing partial decoding at the relay , thus obtaining higher rates as in ( * ? ? ?",
    "* theorem 7 ) .      in recent years",
    ", the research in relaying has mainly focused on multiple - level relaying and the mimo relay channel . in the context of multiple - level relaying based on daf ,",
    "several daf variations were considered . in",
    "@xcite cover & el - gamal s block markov encoding / succesive decoding daf method was applied to the multiple - relay case .",
    "later work @xcite , @xcite and @xcite applied the so - called regular encoding / sliding - window decoding and the regular encoding / backward decoding techniques to the multiple - relay scenario . in @xcite",
    "the daf strategy was applied to the mimo relay channel .",
    "the eaf strategy was also applied to the multiple - relay scenario .",
    "the work in @xcite , for example , considered the eaf strategy for multiple relay scenarios and the gaussian relay channel , in addition to considering the daf strategy . also @xcite considered the eaf strategy in the multiple - relay setup .",
    "another approach applied recently to the relay channel is that of iterative decoding . in @xcite",
    "the three - node network in the half - duplex regime was considered . in the relay case ,",
    "@xcite uses a feedback scheme where the receiver first uses eaf to send information to the relay and then the relay decodes and uses daf at the next time interval to help the receiver decode its message .",
    "combinations of eaf and daf were also considered in @xcite , where conferencing schemes over orthogonal relay - receiver channels were analyzed and compared . both @xcite and @xcite focus on the gaussian case .",
    "an extension of the relay scenario to a hybrid broadcast / relay system was introduced in @xcite in which the authors applied a combination of eaf and daf strategies to the independent broadcast channel with a single common message , and then extended this strategy to the multi - step conference . in @xcite",
    "we used both a single - step and a two - step conference with orthogonal conferencing channels in the discrete memoryless framework .",
    "a thorough investigation of the broadcast - relay channel was done in @xcite , where the authors applied the daf strategy to the case where only one user is helping the other user , and also presented an upper bound for this case .",
    "then , the fully cooperative scenario was analyzed .",
    "the authors applied both the daf and the eaf methods to that case .",
    "one important instance of the relay channel we consider in this work is the gaussian relay channel with coded modulation .",
    "this scenario is important in evaluating the rates achievable with practical communication systems , where components in the receive chain , such as equalization for example , require a uniformly distributed finite constellation for optimal operation . in gaussian relay channel scenarios ,",
    "most often three types for relaying techniques are encountered :    * the first technique is decode - and - forward .",
    "this technique achieves capacity for the physically degraded gaussian relay channel ( see @xcite ) , and also for more general relay channels under certain conditions ( see @xcite ) . * the second technique is estimate - and - forward , where the auxiliary variable @xmath12 is assigned a gaussian distribution .",
    "for example , in @xcite a gaussian auxiliary random variable ( rv ) is used in conjunction with time - sharing at the transmitter , and in @xcite the ergodic capacity for full duplex transmission with gaussian eaf is obtained . *",
    "the third technique is linear relaying , where the relay transmits a weighted sum of all its previously received inputs @xcite .",
    "an important subclass of this family of relaying functions is when the relay transmits a scaled version of its input .",
    "this method is called amplify - and - forward @xcite , and was later combined with daf to produce the decode - amplify - and - forward method of @xcite .",
    "several recent papers consider the gaussian relay channel with coded modulation . in @xcite",
    "the author considered variations of daf for different practical systems . in @xcite daf and",
    "amplify - and - forward were considered for coherent orthogonal bpsk signalling , and in @xcite a practical construction that implements a half - duplex eaf coding scheme was proposed .    as indicated by several authors ( see @xcite ) it is not obvious if a gaussian relay function is indeed optimal . in this paper",
    "we show that for the case of coded modulation , there are scenarios where non - gaussian assignments of the auxiliary rv result in a higher rate than the commonly applied gaussian assignment .",
    "in the following we summarize the main contributions of this work :    * we give an intuitive insight into the relay channel in terms of information flow on a graph , and show how to obtain ( * ? ? ? * theorem 6 ) from flow considerations . using flow considerations",
    "we also obtain the rate of the eaf strategy when the receiver uses joint - decoding .",
    "a similar expression can be obtained by specializing the result of @xcite to the case where the relay does not perform partial decoding .",
    "we then show that joint - decoding does not increase the maximum rate of the eaf strategy , and find the time - sharing assignment that obtains the joint - decoding rate from the general eaf expression .",
    "we also present another time - sharing assignment that always exceeds the joint - decoding rate . *",
    "we introduce an achievable rate expression for the multiple relay scenario based on eaf , that is also practically computabe . as discussed in section [ sec : relay_strategies ] , in the  noisy relay \" case eaf outperforms daf .",
    "however , for the multiple relay scenario there is no explicit , computationally practical expression based on eaf that can be compared with the daf - based result presented in @xcite , so that the best strategy can be selected . as indicated in (",
    "* remark 22 , remark 23 ) , applying general eaf to a network with an arbitrary number of relays is computationally impractical due to the large number of constraints that characterize the feasible region .",
    "therefore , it is interesting to explore a computationally simple assignment that allows to derive a result that extends to an arbitrary number of relays .",
    "we also provide an explicit numerical example to demonstrate that indeed there are cases where multi - relay eaf outperforms the multi - relay daf .",
    "* we consider the optimization of the eaf auxiliary random variable for the gaussian relay channel with an orthogonal relay .",
    "we consider the coded modulation scenario , and show that there are three regions : high snr on the source - relay link , where daf is the best strategy , low snr on the source - relay link in which the common eaf with gaussian assignment is best , and an intermediate region where eaf with hard - decision per symbol is optimal .",
    "for this intermediate snr region we consider two kinds of hard - decisions : deterministic and probabilistic , and show that each one of them can be superior , depending on the channel conditions . *",
    "lastly , we consider the cooperative broadcast scenario with a multi - step conference .",
    "we present a general rate region , extending the marton rate region of @xcite to the case where the receivers hold a @xmath13-cycle conference prior to decoding the messages .",
    "we then specialize this result to the single common message case and obtain explicit expressions ( without auxiliary rvs ) for the two - step conference .",
    "the rest of this paper is organized as follows : in section [ sec : timeshare_single ] we discuss the single relay case .",
    "we consider the eaf strategy with time - sharing ( ts ) and relate it to the eaf rate expression for joint - decoding at the destination receiver . in section [ sec : multiplerelays ] we present an achievable region for the multiple - relay channel , and in section [ sec : gauss_relay ] we examine the gaussian relay channel with coded modulation . in section [ sec : application_multi_step ] we investigate the general cooperative broadcast scenario , and obtain an explicit rate expression by applying ts - eaf to the general multi - step conference .",
    "finally , section [ sec : conclu ] presents concluding remarks .",
    "first , a word about notation : we denote discrete random variables with capital letters e.g. @xmath14 , @xmath15 , and their realizations with lower case letters @xmath16 , @xmath17 .",
    "a random variable @xmath14 takes values in a set @xmath18 .",
    "we use @xmath19 to denote the cardinality of a finite discrete set @xmath18 , and @xmath20 denotes the probability distribution function ( p.d.f . ) of @xmath14 on @xmath18 . for brevity we may omit the subscript @xmath14 when it is obvious from the context .",
    "we denote vectors with boldface letters , e.g. @xmath21 , @xmath22 ; the @xmath23th element of a vector @xmath21 is denoted by @xmath24 and we use @xmath25 where @xmath26 to denote @xmath27 .",
    "we use @xmath28 to denote the set of @xmath29-strongly typical sequences w.r.t .",
    "distribution @xmath20 on @xmath18 , as defined in ( * ? ? ?",
    "5.1 ) and @xmath30 to denote the @xmath29-weakly typical set as defined in ( * ? ? ?",
    "we also have the following definitions :    [ def : relay_channel ] the _ discrete relay channel _ is defined by two discrete input alphabets @xmath18 and @xmath31 , two discrete output alphabets @xmath32 and @xmath33 and a probability density function @xmath34 giving the probability distribution on @xmath35 for each @xmath36 .",
    "the relay channel is called _ memoryless _ if the probability of a block of @xmath2 transmissions is given by @xmath37 .    in this paper",
    "we consider only the memoryless relay channel .",
    "[ def : code ] a _ @xmath38 code _ for the relay channel consists of a source message set @xmath39 , a mapping function @xmath40 at the encoder , @xmath41 a set of @xmath2 relay functions @xmath42 where the @xmath23th relay function @xmath43 maps the first @xmath44 channel outputs at the relay into a transmitted relay symbol at time @xmath23 .",
    "lastly we have a decoder @xmath45    [ def : perr ] the _ average probability of error _ for a code of length @xmath2 for the relay channel is defined as @xmath46 where @xmath47 is selected uniformly over @xmath48 .",
    "a rate @xmath5 is called _ achievable _ if there exists a sequence of @xmath38 codes with @xmath49 as @xmath50 .",
    "consider the following assignment of the auxiliary random variable of theorem [ thm : ceg_eaf ] : @xmath51 under this assignment , the feasibility condition of becomes @xmath52 and the rate expression becomes @xmath53 clearly , maximizing the rate implies maximizing @xmath54 subject to the constraint @xmath55 $ ] .",
    "this gives the following corollary to theorem [ thm : ceg_eaf ] :    [ corr : single_relay_taf ] _ for the general relay channel any rate @xmath5 satisfying @xmath56^ * i(x;y_1|x_1,y),\\ ] ] for the joint distribution @xmath57 , with @xmath58^ * \\triangleq \\min(x,1)$ ] , is achievable .",
    "_    now , consider the following distribution chain : @xmath59 we note that this extended chain can be put into the standard form by letting @xmath60 .",
    "after compression of @xmath61 into @xmath12 , there is a second compression operation , compressing @xmath12 into @xmath62 .",
    "the output of the second compression is used to facilitate cooperation between the relay and the destination .",
    "therefore , the receiver decodes the message based on @xmath63 and @xmath22 , repeating exactly the same step as in the standard relay decoding , with @xmath64 replacing @xmath65 .",
    "then , the expressions of theorem [ thm : ceg_eaf ] become @xmath66 now , applying ts to @xmath62 with @xmath67 the expressions in and become @xmath68 combining this with the constraint @xmath69 $ ] we obtain the following corollary to theorem [ thm : ceg_eaf ] :    [ prop : taf ] _ for the general relay channel , any rate @xmath5 satisfying @xmath70^ * i(x;{\\hat{y}}_1|x_1,y),\\ ] ] for some joint distribution @xmath71 , is achievable .",
    "_    this proposition generalizes on corollary [ corr : single_relay_taf ] by performing a general wyner - ziv ( wz ) compression combined with ts ( which is a specific type of wz compression ) , intended to guarantee feasibility of the first compression step . in section [ sec : gauss_relay ]",
    "we apply a similar idea to the eaf relaying in the gaussian relay channel scenario with coded modulation .",
    "before we discuss the relationship between joint - decoding and time - sharing we present an intuitive way to view the eaf strategy .      consider the rate bound and the feasible region of theorem [ thm : ceg_eaf ] given in equations and",
    "we note that the following intuitive explanation does not constitute a proof but it does provide an insight into the relay achievability results .",
    "we emphasize that the achievable rates stated in this section can also be proved rigorously . in the following we provide an intuitive insight into these expressions in terms of a flow on a graph .",
    "in constructing the intuitive information flow representation for the relay channel , we first need to specify the underlaying assumptions and the operations performed at the source , the relay and the destination receiver :    * the source and the relay generate their codebooks independently . *",
    "the relay compresses its channel output @xmath72 into @xmath73 , which represents the information conveyed to the destination receiver to assist in decoding the source message . *",
    "based on the above two restrictions we have the following markov chain : @xmath74 .",
    "* the relay input signal @xmath75 is based only on the compressed @xmath73 . *",
    "the destination uses @xmath75 , @xmath73 and @xmath22 to decode the source message @xmath21 .",
    "we also use the following representation for transmission , reception and compression :    * we represent an information source as a source whose output flow is equal to its information rate . *",
    "we represent the compression operation as a flow sink whose flow consumption is equal to the mutual information between the original and the compressed sequences . *",
    "the destination is represented as a flow sink . * as in a standard flow on a graph , the flows are additive , following the chain rule of mutual information .",
    "now consider the following flow diagram of figure [ fig : relay_flow ] .",
    "as can be observed from the figure , the source has an output flow of @xmath76 this follows from the fact that the destination uses @xmath77 and @xmath22 to decode @xmath21 and the fact that @xmath14 and @xmath78 are independent .",
    "this total flow reaches the receiver through two branches , the direct branch ( d ) which carries a flow of @xmath79 and the relay branch ( abce ) .",
    "now , the quantities in the relay branch are calculated given @xmath78 and @xmath15 to represent only the rate increase over the direct path .",
    "the relay branch has four parts : an edge ( a ) which carries a flow of @xmath80 , a sink ( b ) with consumption @xmath81 , a relay source ( c ) with an output flow of @xmath82 and an edge ( e ) from the relay to the destination . here ,",
    "the relay transmission to the destination ( c ) is done at a fixed rate @xmath82 , independent of the type of compression @xmath83 used at the relay , since we always transmit from the relay to the destination at the maximum possible rate in order to obtain the best performance . the rate loss due to compression is represented by @xmath84 , since we consider only the excess rates over the direct one .    now , from the laws of flow addition and conservation",
    ", the overall flow from the source to the destination through the relay branch is @xmath85 . to assist the direct link ( d )",
    "we need the flow on ( abce ) to be positive . in theorem [ thm : ceg_eaf ] the scheme considers only the last two elements , @xmath86 , and verifies that",
    "their net flow is positive , namely @xmath87 this condition guarantees a net positive flow on ( abce ) since always @xmath88 .",
    "now , the flow to the destination can be obtained as the minimum @xmath89 where , the second term in the minimum is obtained from the transmitter , since trivially the information rate at the receiver can not exceed @xmath90 .",
    "we note that because @xmath91 , the minimum in is @xmath90 .",
    "therefore , the resulting achievable rate is @xmath92 which combined with gives the result of ( * ? ? ?",
    "* theorem 6 ) .",
    "however , the condition in is not tight since even when @xmath93 the flow on ( abce ) is still non - negative if the entire sum @xmath94 is non - negative , i.e. @xmath95 then , the achievable rate to the destination is bounded by @xmath96 indeed , when the flow through the relay branch ( abce ) is zero we obtain the non - cooperative rate @xmath97 .",
    "plugging the expression into yields the following achievable rate : @xmath98 combining this with , ( informally ) proves the following proposition :    [ prop : jt - rate ] _ for the general relay channel , any rate @xmath5 satisfying @xmath99 for some joint distribution @xmath71 , is achievable .",
    "_    the proof of proposition [ prop : jt - rate ] can be made formal using joint - decoding at the destination receiver , but as in the next subsection we show that this expression is a special case of ( * ? ? ?",
    "* theorem 6 ) obtained by time - sharing , we omit the details of the proof here .      in the original work of (",
    "* theorem 6 ) , the decoding procedure at the destination receiver for decoding the message @xmath100 at time @xmath23 is composed of three steps ( the notations below are identical to ( * ? ? ?",
    "* theorem 6 ) .",
    "the reader is referred to the proof of ( * ? ? ? * theorem 6 ) to recall the definitions of the sets and variables used in the following description ) :    1 .",
    "decode the relay index @xmath101 using @xmath102 , the received signal at time @xmath23 .",
    "2 .   decode the relay message @xmath103 , using @xmath101 , the received signal @xmath104 and the previously decoded @xmath105 .",
    "3 .   decode the source message @xmath100 using @xmath104 , @xmath103 and @xmath105 .",
    "evidently , when decoding the relay message @xmath103 at the second step , the receiver does not make use of the statistical dependence between @xmath106 , the relay sequence at time @xmath44 , and @xmath107 , the transmitted source codeword at time @xmath44 .",
    "the way to use this dependence is to jointly decode @xmath103 and @xmath100 after decoding @xmath101 and @xmath105 .",
    "the joint - decoding procedure then has the following steps :    1 .   from @xmath102 , the received signal at time @xmath23 , the receiver decodes @xmath101 by looking for a unique @xmath108 , the set of indices used to select @xmath75 , such that @xmath109 . as in (",
    "* theorem 6 ) , the correct @xmath101 can be decoded with an arbitrarily small probability of error by taking @xmath2 large enough as long as @xmath110 where @xmath111 .",
    "the receiver now knows the set @xmath112 into which @xmath103 ( the relay message at time @xmath44 ) belongs .",
    "additionally , from decoding at time @xmath44 the receiver knows @xmath105 , used to generate @xmath103 .",
    "the receiver generates the set @xmath113 .",
    "the receiver now looks for a unique @xmath114 such that @xmath115 for some @xmath116 .",
    "if such a unique @xmath117 exists then it is the decoded @xmath118 , otherwise the receiver declares an error .",
    "we do not give here a formal proof for the resulting rate expression , but as indicated in section [ sec : intuitive_explanation ] , the rate expression resulting from this decoding procedure is given by proposition [ prop : jt - rate ] .",
    "let us now compare the the rates obtained with joint - decoding ( proposition [ prop : jt - rate ] ) with the rates obtained with the sequential decoding of ( * ? ? ?",
    "* thoerem 6 ) : to that end we consider the joint - decoding result of proposition [ prop : jt - rate ] with the extended probability chain of : @xmath119 where @xmath62 represents the information relayed to the destination . expanding the expressions of proposition [ prop : jt - rate ] using the assignment , similarly to proposition [ prop : taf ] , we obtain the expressions : @xmath120    we can now make the following observations :    1 .   setting @xmath121",
    "we obtain proposition [ prop : jt - rate ] .",
    "additionally , if @xmath122 then both proposition [ prop : jt - rate ] and ( * ? ? ?",
    "* theorem 6 ) give identical expressions .",
    "2 .   when @xmath123 and @xmath124 then _ for the same _ mapping @xmath125 we obtain that proposition [ prop : jt - rate ] provides rate but ( * ? ? ?",
    "* theorem 6 ) does not .",
    "the rate expression under these conditions is @xmath126 3 .",
    "now , fix the probability chain @xmath127 and examine the expressions and when holds : when @xmath128 , then guarantees that condition is still satisfied . if @xmath54 is close enough to @xmath129 such that we also have @xmath130 , the rate from , i.e. , @xmath131 is now greater than . in this case",
    "can keep decreasing @xmath54 until @xmath132 at which point the rate becomes @xmath133 this rate can be obtained from ( * ? ? ?",
    "* theorem 6 ) by applying the extended probability chain of , as long as @xmath134 .",
    "we therefore conclude that all the rates that joint decoding allows can also be obtained or exceeded by the original eaf with an appropriate time sharing .",
    "note that equality in implies @xmath135 hence @xmath136 is the maximum @xmath54 that makes the mapping @xmath137",
    "feasible for ( * ? ? ?",
    "* theorem 6 ) .",
    "plugging @xmath136 into , we obtain the rate expression of proposition [ prop : taf ] .",
    "finally , consider again the region where joint decoding is useful : @xmath138 if @xmath139 , then using time - sharing on @xmath12 with @xmath140 into equations and yields : @xmath141 as long as @xmath142 , or equivalently @xmath143 plugging assignment into we obtain : @xmath144 as long as @xmath145 , which is the region where joint - decoding is supposed to be useful .",
    "hence the joint - decoding rate of proposition [ prop : jt - rate ] can be obtained by time sharing on the ( * ? ? ?",
    "* theorem 6 ) expression .",
    "therefore , joint - decoding does not improve on the rate of ( * ? ?",
    "* theorem 6 ) .",
    "in fact the rate of proposition [ prop : taf ] is always at least as large as that of proposition [ prop : jt - rate ] .",
    "when the source - relay channel is very noisy then , as discussed in the introduction , it may be better not to use the relay at all than to employ the decode - and - forward strategy .",
    "alternatively , when decode - and - forward is not useful , one could employ estimate - and - forward .",
    "one result for multiple relays based on eaf can be found in @xcite which considered the two - relay case . in (",
    "* theorem 3 ) the eaf strategy , with partial decoding was applied to the multiple - relay case , and in ( * ? ? ?",
    "* theorem 4 ) a mixed eaf and daf strategy was applied . however , as stated in ( * ? ? ?",
    "* remark 22 , remark 23 ) applying the general estimate - and - forward to a network with an arbitrary number of relays is computationally impractical due to the large number of constraints that characterize the feasible region ( for two relays we need to satisfy @xmath146 constraints ) .",
    "moreover , the rate computation is prohibitive since it would imply solving a non - convex optimization problem . in conclusion , an alternative achievable rate to that based on decode - and - forward , which can also be evaluated with a reasonable effort , has not been presented to date . in this section",
    "we derive an explicit achievable rate based on estimate - and - forward .",
    "the strategy we use is to pick the auxiliary random variable such that the feasibility constraints are satisfied .",
    "this is not a trivial choice since setting the auxiliary random variable in theorem [ thm : ceg_eaf ] to be the relay channel output ( i.e. @xmath147 ) does not remove this constraint , and we therefore need to incorporate time - sharing as discussed in the following .",
    "we extend the idea of section [ sec : ts - single - subsec ] to the relay channel with @xmath148 relays .",
    "this channel consists of a source with channel input @xmath14 , @xmath148 relays where for relay @xmath23 , @xmath149 denotes the channel input and @xmath150 denotes the channel output , and a destination with channel output @xmath15 .",
    "this channel is denoted by @xmath151 .",
    "let @xmath152 and @xmath153 .",
    "we now have the following theorem :    [ thm : achieve_n_result_2 ] _ for the general multiple - relay channel with @xmath148 relays , @xmath154 @xmath155 , any rate @xmath5 satisfying @xmath156 where @xmath157 is an @xmath148-element vector that contains @xmath158 in the locations where the @xmath148-bit binary representation of the integer @xmath159 contains @xmath158 , @xmath160 , @xmath161 is the @xmath23th bit in the @xmath148-bit binary representation of @xmath159 , @xmath162 , where @xmath163 , @xmath164 , ... , @xmath165 are the locations of the @xmath158 in @xmath157 , and @xmath166^*,\\ ] ] for the joint distribution @xmath167 is achievable . in @xmath168",
    "is the vector containing all the variables @xmath169 decoded prior to decoding @xmath149 , @xmath170 is a vector that contains all the variables @xmath171 decoded prior to decoding @xmath172 , and @xmath173 contains all the @xmath174 , such that @xmath175 , and @xmath176 is a location of @xmath177 in the @xmath178-bit binary representation of @xmath179 . @xmath178 if the number of elements in @xmath170 .",
    "note that if @xmath180 then we must have @xmath181 .",
    "_    to facilitate the understanding of the expressions in theorem [ thm : achieve_n_result_2 ] , we first look at a simplified case where the destination decodes each relay message independently of the messages of the other relays . this can be obtained from theorem [ thm : achieve_n_result_2 ] by setting @xmath182 and @xmath183 , @xmath184 .",
    "the result is summarized in the following corollary :    [ corr : achieve_n_result_1 ] _ for the general multiple - relay channel @xmath151 , any rate @xmath5 satisfying @xmath185 is achievable , where @xmath186^*,\\ ] ] for the joint distribution @xmath167 . _    in the multi - relay strategy we employ in this section each relay transmits its channel output @xmath150 with probability @xmath187 , independent of the other relays .",
    "therefore , when considering a group of @xmath148 relays , the probability that any subgroup of relays will transmit their channel outputs simultaneously is simply the product of all transmission probabilities @xmath187 at each relay in the group , multiplied by the product of erasure probabilities @xmath188 for each relay in the complement group .",
    "now , considering the rate expression of we observe that the rate is obtained by taking all possible groupings of relays . for each grouping",
    "the resulting rate is the rate obtained when using all the channel outputs of all the relays in that group to assist in decoding .",
    "this is indicated by the term @xmath189 .",
    "this rate has to be weighted by the probability of such an overlap occurring , which is given by @xmath190 .",
    "we then sum over all such groupings to obtain the achievable rate .",
    "the parameter @xmath187 for each relay , which is determined by , can be interpreted by considering the terms in the denominator and numerator : the denominator @xmath191 is the ( exponent of the ) size of uncertainty at the destination receiver about relay @xmath23 s output @xmath150 .",
    "the numerator is the ( exponent of the ) size of the information set that can be transmitted from relay @xmath23 to the destination receiver .",
    "therefore , the fraction @xmath192 can be interpreted as the maximal fraction of the uncertainty at the destination about relay @xmath23 s channel output @xmath150 , that can be compensated by the relay transmission .",
    "of course , this faction has to be upper bounded by one . in the more general setup of theorem [ thm :",
    "achieve_n_result_2 ] , the decoding of the relay information from relay @xmath23 is done by using the information from the relays which were decoded before relay @xmath23 to assist in decoding .",
    "this results in the conditioning at the numerator and the negative terms in the denominator , both contribute to increasing the value of @xmath187 .",
    "the transmitter generates its codebook independent of the relays .",
    "next , each relay generates its own codebook independent of the other relays following the construction of ( * ? ? ?",
    "* theorem 6 ) , with the mapping @xmath193 at each relay set to the time - sharing mapping of with parameter @xmath187 .",
    "the destination receiver first needs to decode all the relay codewords @xmath194 and use this information to decode the relay messages @xmath195 . to this end , the relay decides on a decoding order for the @xmath196 sequences and a decoding order for the @xmath197 sequences .",
    "these decoding orders determine the maximum value of @xmath187 that can be selected for each relay , thereby allowing us to determine the auxiliary variables mappings and obtain an explicit rate expression .",
    "finally , the receiver uses all the decoded @xmath194 and @xmath195 sequences , together with its channel input to decode the source message .",
    "we now give the details of the construction : fix the distributions @xmath198 , @xmath199 , @xmath200, ... ,@xmath201 , and @xmath202 @xmath184 .",
    "let @xmath39 be the source message set .",
    "* code construction and transmission at the transmitter are the same as in ( * ? ? ?",
    "* theorem 6 ) .",
    "* code construction at the relays is done by repeating the relay code construction of ( * ? ? ?",
    "* theorem 6 ) for each relay , where relay @xmath23 uses the distributions @xmath193 and @xmath203 .",
    "we denote the relay message , the transmitted message and the partition set at relay @xmath23 at time @xmath204 with @xmath205 , @xmath206 and @xmath207 respectively . the message set for @xmath101",
    "is denoted @xmath208 , where @xmath209 .",
    "the message set for @xmath210 is denoted @xmath211 , @xmath212 .",
    "the relay codewords at relay @xmath23 are denoted @xmath213 , and the transmitted codewords at relay @xmath23 are denoted @xmath214 , @xmath215 , @xmath216 .",
    "@xmath217    consider relay @xmath23 at time @xmath218 :    * from the relay transmission at time @xmath218 , the relay knows @xmath219 .",
    "now the relay looks for a message @xmath216 , such that @xmath220 following the argument in ( * ? ? ?",
    "* theorem 6 ) , for @xmath2 large enough there is such a message @xmath210 with a probability that is arbitrarily close to @xmath129 , as long as @xmath221 denote this message with @xmath222 . *",
    "let @xmath206 be the index of the partition of @xmath211 into which @xmath222 belongs , i.e. , @xmath223 . * at time @xmath204 relay @xmath23 transmits @xmath224 .      *",
    "consider the decoding of @xmath225 at time @xmath204 , for a fixed decoding order : let @xmath168 contain all the @xmath169 s whose @xmath226 s are decoded prior to decoding @xmath206 .",
    "therefore , decoding @xmath206 is done by looking for a unique message @xmath215 such that @xmath227 where @xmath228 , @xmath229, ... ,@xmath230 enumerate all the @xmath169 s in @xmath231 .",
    "assuming correct decoding at the previous steps , then by the point - to - point channel achievability proof we obtain that the probability of error for decoding @xmath206 can be made arbitrarily small by taking @xmath2 large enough as long as @xmath232 + let @xmath170 contain all the @xmath233 s whose @xmath234 s are decoded prior to decoding @xmath222 .",
    "note that all the @xmath235 were already decoded at the previous time interval when @xmath236 was decoded . *",
    "the destination generates the set @xmath237 where @xmath238 , @xmath239, ...",
    ",@xmath240 enumerate all the @xmath233 s in @xmath170 .",
    "the average size of @xmath241 can be bounded using the standard technique of ( * ? ? ?",
    "* equation ( 36 ) ) and the fact that when @xmath242 , then the corresponding @xmath243 is independent of all the variables in except @xmath244 .",
    "the resulting bound is @xmath245 where @xmath246 is an @xmath247 element vector that contains all the elements of @xmath248 except @xmath149 .",
    "* now , the destination looks for a unique @xmath249 .",
    "therefore , making the probability of error arbitrarily small by taking @xmath2 large enough can be done as long as @xmath250    we note that using the assignment we can write @xmath251 where @xmath252 , @xmath253 is the @xmath176-th bit of the @xmath178-bit binary representation of @xmath179 , and @xmath254 , @xmath255 are the locations of 1 in the @xmath178-bit binary representation of @xmath179 , and @xmath256 are the indices of the @xmath172 s in locations @xmath255 in @xmath170 .",
    "for example , if @xmath257 and @xmath258 then @xmath259 and @xmath260 , @xmath261 . letting @xmath262 then @xmath263 and @xmath264 , and @xmath265      applying the above scheme requires that @xmath266 satisfies and : @xmath267 which is satisfied if @xmath268 combining with the constraint @xmath269 gives the condition in .",
    "finally , the achievable rate is obtained as follows : using the decoded @xmath270 ( assuming correct decoding of all @xmath271 ) the receiver decodes the source message @xmath225 by looking for a message @xmath272 such that @xmath273 where @xmath274 .",
    "this results in an achievable rate of @xmath275 plugging in the assignments of all the @xmath172 s , we get the following explicit rate expression : @xmath276 @xmath277      to demonstrate the usefulness of the explicit eaf - based achievable rate of theorem [ thm : achieve_n_result_2 ] we compare it with the daf - based method of ( * ? ? ?",
    "* theorem 3.1 ) for the two - relay case . for this scenario",
    "there are five possible daf setups , and the maximum of the five resulting rates is taken as the daf - based rate : @xmath278 where @xmath279 is the rate obtained when only relay 1 is active , @xmath280 is the rate obtained when only relay 2 is active , @xmath281 is the rate obtained when relay 1 decodes first and relay 2 decodes second and @xmath282 is the rate obtained when this order is reversed .",
    "@xmath283 is the rate obtained when both relays form one group we do not need to explicitly include @xmath279 and @xmath280 in the maximization , but it is included here to provide a complete presentation . ] .",
    "now , as in the single - relay case , daf is limited by the worst source - relay link . therefore ,",
    "if @xmath284 where @xmath285 is the point - to - point rate , then it is better not to use ( * ? ?",
    "* theorem 3.1 ) at all , but rather set the relays to transmit the symbol pair @xmath286 such that the point - to - point rate is maximized .",
    "however , the rate obtained using corollary [ corr : achieve_n_result_1 ] for the two - relay case is given by @xmath287 where @xmath288 and @xmath289 are positive and determined according to .",
    "this expression can , in general be greater than @xmath290 even when holds , for channels where the relay to destination links are very good .",
    "hence , this explicit achievable expression provides an easy way to improve upon the daf - based achievable rates when the source - to - relay links are very noisy .    to demonstrate this , consider the channel given in table [ table : channel_for_example ] over binary rvs @xmath14 , @xmath78 , @xmath291 , @xmath15 , @xmath61 and @xmath292 .",
    "the channel    .@xmath293 for the eaf example . [ cols=\"^,^,^,^,^,^,^,^,^ \" , ]     the optimal daf distribution fixes both @xmath78 and @xmath291 to @xmath158 and sets the probability of @xmath14 to be @xmath294 , as expected for the case where the relays limit the achievable rate . for the eaf ,",
    "the useless relay @xmath295 is fixed to @xmath296 , to facilitate transmission with the useful relay @xmath129 . in accordance ,",
    "we obtain time sharing proportions of @xmath297 and @xmath298 for relay @xmath129 and relay @xmath295 respectively .",
    "we note that in this scenario , we actually have that even the single - relay ts - eaf outperforms the two - relay daf .",
    "in this section we investigate the application of estimate - and - forward with time - sharing to the gaussian relay channel . for this channel , the common practice it to use gaussian codebooks and gaussian quantization at the relay .",
    "the rate in gaussian scenarios where coded modulation is applied , is usually analyzed by applying daf at the relay . in this section",
    "we show that when considering coded modulation , one should select the relay strategy according to the channel condition : gaussian selection seems a good choice when the snr at the relay is low and daf appears to be superior when the relay enjoys high snr conditions .",
    "however , for intermediate snr there is much room for optimizing the estimation mapping at the relay .    in the following we first recall the gaussian relay channel with a gaussian codebook , and then we consider the gaussian relay channel under bpsk modulation constraint .",
    "since we focus on the mapping at the relay we consider here the gaussian relay channel with an orthogonal relay of finite capacity @xmath299 , also considered in @xcite .",
    "this scenario is depicted in figure [ fig : gauss_relay ] .",
    "= 0.6    here @xmath300 is the channel output at the relay , @xmath301 is the channel output at the receiver , which decodes the message based on @xmath302",
    ". let @xmath39 denote the source message set , and let the source have an average power constraint @xmath303 : @xmath304 the relay signal @xmath305 is transmitted to the destination through a finite - capacity noiseless link of capacity @xmath299 . for this scenario the expressions of (",
    "* theorem 6 ) specialize to    @xmath306    with the markov chain @xmath307 .",
    "we also consider in this section the daf method whose information rate is given by ( see ( * ? ? ?",
    "* theorem 1 ) ) @xmath308 and the upper bound of ( * ? ? ? * theorem 3 ) : @xmath309 we note that although these expressions were derived for the finite , discrete alphabets case , following the argument in ( * ? ? ?",
    "* remark 30 ) , they also hold for the gaussian case .",
    "when @xmath310 , i.i.d .",
    ", then the channel outputs at the relay and the receiver are jointly normal rvs : @xmath311 the compression is achieved by adding to @xmath61 a zero mean independent gaussian rv , @xmath312 : @xmath313 we refer to the assignment as gaussian - quantization estimate - and - forward ( gq - eaf ) . evaluating the expressions and with assignment results in ( see also @xcite ) :    @xmath314    the feasibility condition yields @xmath315 and because maximizing the rate requires minimizing @xmath316 , the resulting gq - eaf rate expression is @xmath317 now , when using gaussian quantization at the relay it is obvious that time sharing does not help : we need the minimum @xmath316 in order to maximize the rate .",
    "this minimum is obtained only when the entire capacity of the relay link is dedicated to the transmission of the ( minimally ) quantized @xmath61 . however , when we consider the gaussian relay channel with coded modulation , the situation is quite different , as we show in the remaining of this section .      consider the gaussian relay channel where @xmath14 is an equiprobable bpsk signal of amplitude @xmath318 : @xmath319 under these conditions , the received symbols @xmath320 are no longer jointly gaussian , but follow a gaussian - mixture distribution : @xmath321 where @xmath322 contrary to the gaussian codebook case , where it is hard to identify a mapping @xmath323 that will be superior to gaussian quantization ( if indeed such a mapping exists ) , in this case it is a natural question to compare the gaussian mapping of , which induces a gaussian - mixture distribution for @xmath12 with other possible mappings . in the case of binary inputs",
    "it is natural to consider binary mappings for @xmath12 .",
    "we can predict that such mappings will do well at high snr on the source - relay link , when the probability of error for symbol - by - symbol detection at the relay is small , with a much smaller complexity than gaussian quantization .",
    "we start by considering two types of hard - decision ( hd ) mappings :    1 .",
    "the first mapping is hd - eaf : the relay first makes a hard decision about every received @xmath61 symbol , determining whether it is positive or negative , and then randomly decides if it is going to transmit this decision or transmit an erasure symbol @xmath324 instead .",
    "the probability of transmitting an erasure , @xmath325 , is used to adjust the conference rate such that the feasibility constraint is satisfied .",
    "therefore , the conditional distribution @xmath326 is given by : + @xmath327 + this choice is motivated by the time - sharing method considered in section [ sec : timeshare_single ] : after making a hard decision on the received symbol s sign  positive or negative , the relay applies ts to that decision so that the rate required to transmit the resulting random variable is less than @xmath299 .",
    "this facilitates transmission to the destination through the conference link .",
    "since the entropy of the sign decision is @xmath129 , then when @xmath328 we can transmit the sign decisions directly without using an erasure .",
    "therefore , we expect that for values of @xmath299 in the range @xmath329 , this mapping will not exceed the rate obtained for @xmath330 .",
    "the focus is , therefore , on values of @xmath299 that are less than @xmath129 .",
    "the expressions for this assignment are given in appendix [ append : gauss - deriv - hd - eaf ] .",
    "2 .   the second method is deterministic hard - decision . in this approach",
    ", we select a threshold @xmath331 such that the range of @xmath61 is partitioned into three regions : @xmath332 .",
    "then , according to the value of each received @xmath61 symbol , the corresponding @xmath12 is deterministically determined : @xmath333 the threshold @xmath331 is selected such that the achievable rate is maximized subject to satisfying the feasibility constraint .",
    "we refer to this method as deterministic hd ( dhd ) .",
    "therefore , this is another type of ts in which the erasure probability is determined by the fraction of the time the relay input is between @xmath334 to @xmath331 .",
    "this method should be better than hd - eaf at high relay snr since for hd - eaf , erasure is selected without any regard to the quality of the decision - both good sign decisions and bad sign decisions are erased with the same probability .",
    "however in dhd , the erased area is the area where the decisions have low quality in the first place and all high quality decisions are sent .",
    "however , at low relay snr and small capacity for the relay - destination link , hd - eaf may perform better than dhd since the erased area ( i.e. the region between @xmath334 to @xmath335 ) for the dhd mapping has to be very large to allow squeezing the estimate through the relay link , while hd - eaf may require less compression of the hd output .",
    "the expressions for evaluating the rate of the dhd assignment are given in appendix [ sec : expressions_dhd ] .",
    "we now examine the performance of each technique using numerical evaluation : first , we examine the achievable rates with hd - eaf .",
    "the expressions are evaluated for @xmath336 and @xmath337 . for every pair of values @xmath338 considered ,",
    "the maximum @xmath339 was selected .",
    "figure [ fig : hard - decision - vs - g ] depicts the achievable rate vs. @xmath340 for @xmath341 , together with the upper bound and the decode - and - forward rate .",
    "as can be observed from figure [ fig : hard - decision - vs - g ] , the information rate of hd - eaf increases with @xmath299 until @xmath342 and then remains constant .",
    "it is also seen that for small values of @xmath340 , hd - eaf is better than daf .",
    "this region of @xmath340 increases with @xmath299 , and for @xmath328 the crossover value of @xmath340 is approximately @xmath343 .",
    "however , even for @xmath344 , daf is only @xmath345 better than hd - eaf .",
    "next , examine dhd : as can be seen from figure [ fig : dhd - vs - g ] , for small values of @xmath299 , daf exceeds the information rate of dhd for values of @xmath340 greater than @xmath129 , but for @xmath346 , dhd is superior to daf , and in fact daf approaches dhd from below .",
    "another phenomena obvious from the figure ( esp . for @xmath347 ) , is the existence of a threshold : for low values of @xmath299 there is some @xmath340 at which the dhd rate exhibits a jump .",
    "this can be explained by looking at figure [ fig : dhd - explanation ] , which depicts the values of @xmath348 and @xmath349 vs. the threshold @xmath331 : the bold - solid graph of @xmath349 can intersect the bold - dashed horizontal line representing @xmath299 at two values of @xmath331 .",
    "we also note that for small @xmath331 the value of @xmath348 is generally greater than for large @xmath331 .",
    "now , the jump can be explained as follows : as shown in appendix [ sec : hdh - explanation ] , for small @xmath331 and @xmath340 , @xmath349 is bounded from below .",
    "now , if this bound value is greater than @xmath299 then the intersection will occur only at a large value of @xmath331 , hence the small rate .",
    "when @xmath340 increases , the value of @xmath349 for small @xmath331 decreases accordingly , until at some @xmath340 it intersects @xmath299 for a small @xmath331 as well as for a large @xmath331 , as indicated by the arrow in the right - hand part of figure [ fig : dhd - explanation ] .",
    "this allows us to obtain the rates in the region of small @xmath331 which are in general higher than the rates for large @xmath331 and this is the source of the jump in the achievable rate .",
    "it is clearly evident from the above numerical evaluation that none of the two mappings , hd - eaf and dhd , is universally better than the other : when @xmath340 is small and @xmath299 is less than @xmath129 , then hd - eaf performs better than dhd , since the erased region is too large , and when @xmath340 increases , dhd performs better than hd - eaf since it erases only the low quality information .",
    "it is therefore natural to consider a third mapping which combines both aspects of binary mapping at the relay , namely deterministically erasing low quality information and then randomly gating the resulting discrete variable in order to allow its transmission over the conference link .",
    "this hybrid mapping is given in the following equation :    [ eqn : def_ts - dhd ] @xmath350    in this mapping , the region @xmath351 is always erased , and the complement region is erased with probability @xmath352 .",
    "of course , now both @xmath331 and @xmath353 have to be optimized .",
    "the expressions for ts - dhd can be found in appendix [ appndx : expressions_ts_dhd ] .",
    "figure [ fig : compare_hd - eaf_dhd_ts - dhd ] compares the performance of dhd , hd - eaf and ts - dhd .",
    "as can be seen , the hybrid method enjoys the benefits of both types of mappings and is the superior method .",
    "next , figure [ fig : compare - hd - eaf - gq - eaf ] compares the performance of ts - dhd , gq - eaf , and daf .",
    "as can be seen from the figure , gaussian quantization is not always the optimal choice : for @xmath354 ( the lines with diamond - shaped markers ) we have that gq - eaf is the best method for @xmath355 , for @xmath356 ts - dhd is the best method and for @xmath357 daf achieves the highest rate . for @xmath342 ( x - shaped markers ) ts - dhd is superior to both gq - eaf and daf for @xmath358 and for @xmath359 , gq - eaf is the superior method for all @xmath360 .",
    "this suggests that for the practical gaussian relay scenario , where the modulation constraint is taken into account , there is room to optimize the mapping at the relay since the choice of gaussian quantization is not always optimal .",
    "lastly , figure [ fig : daf - eaf - regions ] depicts the regions in the g - c plane in which each of the methods considered here is superior , in a similar manner to @xcite in the values of @xmath340 and @xmath299 used for evaluating the rates . in the final version we will present an evaluation over a finer grid ( such an evaluation requires several weeks to complete ) . ] .",
    "as can be observed from the figure , in the noisy region of small @xmath340 and also in the region of very large @xmath299 , gq - eaf is superior , and in the strong relay region of medium - to - high @xmath340 and medium - to - high @xmath299 , ts - dhd is the superior method .",
    "daf is superior small @xmath299 and high @xmath340 . in a sense ,",
    "the ts - dhd method is a hybrid method between the daf which makes a hard - decision on the entire block and gq - eaf which makes a soft decision every symbol , therefore it is superior in the transition region between the region where daf is distinctly better , and the region where gq - eaf is distinctly superior .      in this subsection",
    "we analyze the relaying strategies discussed in this section as the snr on the direct link @xmath362 approaches zero . because ts - dhd is a hybrid method combining both dhd and hd - eaf",
    ", we analyze the behavior of the components rather than the hybrid , to gain more insight .",
    "this analysis is particularly useful when trying to numerically evaluate the rates , since as the direct - link snr goes to zero , the computer s numerical accuracy does not allow to numerically obtain the rates using the general expressions .",
    "first we note that when the snr of the direct link @xmath362 approaches @xmath296 we have that @xmath363 as well . to see this we write @xmath364 with @xmath365 , and from @xmath366 where the approximation is in the sense that for small @xmath367 we have @xmath368 and for large @xmath367 , @xmath369 drives the entire expression to zero as @xmath369 , for @xmath361 .",
    "this approximation reflects the intuitive notion that as the variance increases to infinity , the two - component , symmetric gaussian mixture resembles more and more a zero - mean gaussian rv with the same variance .",
    "therefore , for low snr , the output is very close to a zero - mean normal rv with variance @xmath370 , and @xmath371 , we have that @xmath372 , for @xmath373 , @xmath374 and for @xmath375 , @xmath376 . ]",
    "hence @xmath377 note that the upper bound and the decode - and - forward rate in this case are both equal to @xmath378    now , let us evaluate the rate for hd - eaf as the snr goes to zero . from : @xmath379 and @xmath380 using appendix [ append : gauss - deriv ] , equations ",
    ", we have @xmath381 when @xmath361 and @xmath382 $ ] is selected such that @xmath383 . the approximation in ( a )",
    "is because for small @xmath367 , @xmath384 and @xmath385 , and for large @xmath367 , both @xmath386 and @xmath387 . hence",
    "@xmath388 dy\\\\                  & = & \\frac{1}{2\\pr(y_1>0 ) } \\left[h(n ) + \\log_2 \\left(2\\pr(y_1>0)\\right)\\right],\\end{aligned}\\ ] ] and using @xmath389 and @xmath390 , we obtain @xmath391 therefore , at low snr , @xmath15 and @xmath12 become independent .",
    "then , @xmath392 and the information rate becomes ( see appendix [ appndx : appndxhd - eaf - highsnr ] ) @xmath393 where @xmath394 is the discrete entropy for the specified discrete distribution and @xmath395 .",
    "now , consider the feasibility condition @xmath396 : @xmath397 where ( a ) follows from the independence of @xmath15 and @xmath12 at low snr , see appendix [ appndx : appndxhd - eaf - highsnr ] . therefore , for low snr , we set @xmath398 and the rate becomes @xmath399    for the gq - eaf we first approximate @xmath400 at low snr starting with : @xmath401 as @xmath402 in the region when @xmath403 is significant , for both @xmath404 or @xmath405 .",
    "we conclude that as the direct snr approaches 0 , @xmath15 and @xmath12 become independent .",
    "now , the rate is given by : @xmath406 the feasibility condition becomes : @xmath407 with @xmath408.\\ ] ]    for dhd , as @xmath361 we have @xmath409 where ( a ) follows from the independence of @xmath15 and @xmath61 as @xmath361 and the fact that @xmath12 is a deterministic function of @xmath61 , combined with the fact that given @xmath14 , @xmath61 and @xmath15 are independent .",
    "the feasibility condition becomes @xmath410 because @xmath411 is not a monotone function of @xmath331 we have to optimize over @xmath331 to find the actual rate .    as can be seen from the expression for hd - eaf , when the snr on the direct link decreases , the capacity of the conference link acts as a scaling factor on the rate of the binary channel from the source to the relay .    in figure",
    "[ fig : low - direct - snr ] we plotted the information rate for dhd , hd - eaf , gq - eaf and daf ( which coincides with the upper bound ) . comparing the three eaf strategies we note that dhd , which at intermediate snr on the source - relay channel performs well for @xmath346 , has the worst performance at low snr up to @xmath412 . at @xmath412",
    ", dhd becomes the best technique out of the three . for @xmath413 and high",
    "snr on the source - relay channel , hd - eaf outperforms both dhd and gq - eaf . for low snr on the source - relay channel",
    ", gq - eaf is again superior .",
    "we make the following observations :    * as noted at the beginning of this section , for low snr on the source - relay link , gq - eaf outperforms ts - dhd . to see why , consider the distribution of @xmath61 : @xmath414 where the approximation is obtained using the first order taylor expansion , and the fact that for large values of @xmath61 , @xmath415 dominates the expression .",
    "therefore , as @xmath416 , @xmath61 approaches a zero - mean gaussian rv : @xmath417 . as discussed in (",
    "13.1 ) , the closer the reconstruction variable is to the original variable , the better the quantization performance are expected to be .",
    "therefore it should be natural to guess that gq will perform better at low relay link snr .",
    "* at the other extreme , as @xmath418 , consider the daf strategy : as @xmath418 , have that @xmath419\\times\\\\              &   & \\qquad \\qquad \\qquad              \\log_2\\left(\\frac{1}{2}\\left[g_{y_1}(g\\sqrt{p},{\\sigma_1 ^ 2 } ) + g_{y_1}(-g\\sqrt{p},{\\sigma_1 ^ 2})\\right ]              \\right)dy_1\\\\          & \\stackrel{g \\rightarrow \\infty}{\\approx } &   1 - \\int_{y_1 = -\\infty}^{\\infty } \\frac{1}{2}g_{y_1}(g\\sqrt{p},{\\sigma_1 ^ 2 } )              \\log_2 g_{y_1}(g\\sqrt{p},{\\sigma_1 ^ 2 } ) dy_1 \\\\          &    & \\qquad \\qquad \\qquad - \\int_{y_1 = -\\infty}^{\\infty } \\frac{1}{2}g_{y_1}(-g\\sqrt{p},{\\sigma_1 ^ 2 } )              \\log_2 g_{y_1}(-g\\sqrt{p},{\\sigma_1 ^ 2 } ) dy_1\\\\          & = & 1 + h(n_1 ) ,      \\end{aligned}\\ ] ] and therefore , @xmath420 hence , @xmath421 which is the maximal rate .",
    "therefore , as @xmath418 daf provides the optimal rate .",
    "* we can expect that at intermediate snr , methods that balance between the soft - decision per symbol of gq - eaf and the hard - decision on the entire codeword of daf , will be superior to both .",
    "furthermore , we believe that as the snr decreases , increasing the cardinality of @xmath12 accordingly will improve the performance .",
    "in this section we consider the cooperative broadcast ( bc ) scenario . in this scenario ,",
    "one transmitter communicates with two receivers . in its most general form ,",
    "the transmitter sends three independent messages : a common message intended for both receivers and two private messages , one for each receiver , where all three messages are encoded into a single channel codeword @xmath0 .",
    "each receiver gets a noisy version of the codeword , @xmath3 at @xmath422 and @xmath423 at @xmath424 . after reception , the receivers exchange messages in a k - cycle conference over noiseless conference links of finite capacities @xmath425 and @xmath426 .",
    "each conference message is based on the channel output at each receiver and the conference messages previously received from the other receiver , in a similar manner to the conference defined by willems in  @xcite for the cooperative mac .",
    "after conferencing , each receiver decodes its message .",
    "this scenario is depicted in figure [ fig : three_msg_bc ] .",
    "this setup was studied in @xcite for the single common message case over the independent bc ( i.e. @xmath427 ) , and in @xcite for the general setup with a single cycle of conferencing .",
    "we use the standard definition for the discrete memoryless general broadcast channel given in @xcite .",
    "we define a cooperative coding scheme as follows :    _ a @xmath428-admissible k - cycle conference _ consists of the following elements :    1 .",
    "@xmath13 message sets from @xmath422 to @xmath424 , denoted by @xmath429 , @xmath430, ... ,@xmath431 , and @xmath13 message sets from @xmath424 to @xmath422 , denoted by @xmath432 , @xmath433, ... ,@xmath434 .",
    "message set @xmath435 consists of @xmath436 messages and message set @xmath437 consists of @xmath438 messages .",
    "@xmath13 mapping functions , one for each conference step from @xmath422 to @xmath424 : @xmath439 and @xmath13 mapping functions , one for each conference step from @xmath424 to @xmath422 : @xmath440 where @xmath441 .",
    "the conference rates satisfy : @xmath442    _ a @xmath443 code _ for the general broadcast channel with a common message and two independent private messages , consists of three sets of source messages , @xmath444 , @xmath445 and @xmath446 , a mapping function at the transmitter , @xmath447 a @xmath428-admissible @xmath13-cycle conference , and two decoders , @xmath448    the _ average probability of error _ is defined as the average probability that at least one of the receivers does not decode its message pair correctly : @xmath449 where we assume that each message is selected uniformly and independently over its respective message set .",
    "we first present the general result for the cooperative broadcast scenario with a @xmath13-cycle conference .",
    "denote with @xmath450 and @xmath451 .",
    "let @xmath279 and @xmath280 be the private rates to @xmath422 and @xmath424 respectively , and let @xmath452 denote the rate of the common information .",
    "then , the following rate triplets are achievable :    [ thm : multi - step - general - bc ] _ consider the general broadcast channel @xmath453 with cooperating receivers , having noiseless conference links of finite capacities @xmath425 and @xmath426 between them .",
    "let the receivers hold a conference that consists of @xmath13 cycles .",
    "then , any rate triplet @xmath454 satisfying _",
    "@xmath455    subject to ,    @xmath456    for some joint distribution @xmath457 is achievable .",
    "the cardinality of the @xmath204th auxiliary random variables are bounded by : @xmath458      the coding strategy is based on combining the bc code construction of @xcite , after incorporating the common message into the construction , with the @xmath13-cycle conference of @xcite .",
    "the transmitter constructs a broadcast code to split the rate between the three message sets .",
    "this is done independently of the relaying scheme .",
    "each receiver generates its conference messages according to the construction of @xcite .",
    "after @xmath13 cycles of conferencing each receiver decodes its information based on its channel output and the conference messages received from the other receiver .",
    "* fix all the distributions in . fix @xmath459 and let @xmath460 .",
    "let @xmath461 be a positive number whose value is determined in the following steps .",
    "let @xmath462 .",
    "let @xmath463\\delta}^{(n)}$ ] denote the set of all @xmath464 sequences such that @xmath465 and @xmath466 is non - empty , as defined in ( * ? ? ?",
    "* corollary 5.11 ) . from (",
    "* corollary 5.11 ) we have that @xmath467\\delta}^{(n)}|| \\ge 2^{n(h(w)-\\phi)}$ ] , where @xmath468 as @xmath469 and @xmath50 . *",
    "pick @xmath470 sequences from @xmath463\\delta}^{(n)}$ ] in a uniform and independent manner according to @xmath471\\delta}^{(n)}|| } & , { { \\bf w}}\\in s_{[w]\\delta}^{(n)}\\\\                      0    & , \\mbox{otherwise}.                  \\end{array }              \\right.\\ ] ] label these sequences with @xmath472 .",
    "* for each sequence @xmath473 , @xmath474 , consider the set @xmath475 , @xmath476 .",
    "since the sequences @xmath464 are selected such that @xmath477 is non - empty and since @xmath478 implies @xmath479 , then also @xmath475 in non - empty , and by ( * ? ? ?",
    "* theorem 5.9 ) , @xmath480 , @xmath481 as @xmath482 and @xmath50 .",
    "* for each @xmath474 pick @xmath483 sequences in a uniform and independent manner from @xmath475 according to @xmath484 label these sequences with @xmath485 , @xmath486 .",
    "similarly , pick @xmath487 sequences in a uniform and independent manner from @xmath488 according to @xmath489 label these sequences with @xmath490 , @xmath491 .",
    "@xmath492 is selected such that @xmath467\\delta}^{(n)}|| \\ge 2^{n(r(w)-{\\epsilon})}$ ] , and @xmath493 we have that @xmath494 and @xmath495 . * partition the set @xmath496 into @xmath497 subsets @xmath498 , @xmath499 , let + @xmath500 $ ] .",
    "similarly partition the set @xmath501 into @xmath502 subsets @xmath503 , @xmath504 ,",
    "let + @xmath505 $ ] . * for each triplet @xmath506 consider the set @xmath507 by ( * ? ? ?",
    "* lemma on pg .",
    "121 ) , we have that taking @xmath2 large enough we can make @xmath508 for any arbitrary @xmath459 , as long as + @xmath509 + note that the individual rate constraints are required to guarantee that the sets @xmath498 and @xmath503 are non - empty .",
    "* for each @xmath474 , we pick a unique pair of @xmath510 , @xmath511 .",
    "the transmitter generates the codeword @xmath512 according to + @xmath513 . when transmitting the triplet @xmath506 the transmitter outputs @xmath512 .",
    "* for the first conference step from @xmath422 to @xmath424 , @xmath422 generates a codebook with @xmath514 codewords indexed by @xmath515 according to the distribution @xmath516 : @xmath517 .",
    "@xmath422 uniformly and independently partitions the message set @xmath518 into @xmath519 subsets indexed by @xmath520 .",
    "denote these subsets with @xmath521 .",
    "* for the first conference step from @xmath424 to @xmath422 , @xmath424 generates a codebook with @xmath522 codewords indexed by @xmath523 for each codeword @xmath524 , @xmath525 , in an i.i.d .",
    "manner according to @xmath526 .",
    "@xmath424 uniformly and independently partitions the message set @xmath527 into @xmath528 subsets indexed by @xmath529 .",
    "denote these subsets with @xmath530 .",
    "* for the @xmath204th conference step from @xmath422 to @xmath424 , @xmath422 considers each combination of @xmath531 , @xmath532 . for each combination",
    ", @xmath422 generates a codebook with @xmath533 messages indexed by @xmath534 , according to the distribution @xmath535 .",
    "@xmath422 uniformly and independently partitions the message set @xmath536 into @xmath436 subsets indexed by @xmath537 .",
    "denote these subsets with @xmath538 . * the codebook for the @xmath204th conference step from @xmath424 to @xmath422",
    "is generated in a parallel manner for each combination of @xmath539 , @xmath532 .",
    "@xmath422 needs first to decode the message @xmath541 sent from @xmath424 at the @xmath542th cycle .",
    "to that end , @xmath422 uses @xmath543 , the index received from @xmath424 at the @xmath542th conference step . in decoding @xmath541",
    "we assume that all the previous @xmath544 were correctly decoded at @xmath422 .",
    "we denote the @xmath545 sequences corresponding to @xmath544 by + @xmath546 , and similarly define @xmath547 .",
    "* @xmath422 first generates the set @xmath548 defined by : @xmath549 * @xmath422 then looks for a unique @xmath550 such that @xmath551 .",
    "if there is none or there is more than one , an error is declared . * from an argument similar to @xcite , the probability of error can be made arbitrarily small by taking @xmath2 large enough as long as @xmath552 here , @xmath553 , since for the first conference message from @xmath422 to @xmath424 no decoding takes place .    in generating the @xmath204th conference message to @xmath424",
    ", it is assumed that all the previous @xmath218 messages from @xmath424 were decoded correctly .",
    "* @xmath422 looks for a message @xmath554 such that @xmath555 from the argument in @xcite , the probability that such a sequence exists can be made arbitrarily close to @xmath129 by taking @xmath2 large enough as long as @xmath556 * @xmath422 looks for the partition of @xmath536 into which @xmath557 belongs .",
    "denote the index of this partition with @xmath558 .",
    "* @xmath422 transmits @xmath558 to @xmath424 through the conference link .      using similar arguments to section [ sec : decencmultisteprgood ] , we obtain the following rate constraints :",
    "* decoding @xmath557 at @xmath424 can be done with an arbitrarily small probability of error by taking @xmath2 large enough as long as @xmath559 * encoding @xmath560 can be done with an arbitrarily small probability of error by taking @xmath2 large enough as long as @xmath561      first consider the bounds on @xmath562 , @xmath441 : @xmath563 this can be satisfied only if @xmath564 hence @xmath565 + 2k{\\epsilon}\\nonumber\\\\                     & = &   \\sum_{k = 1}^{k } i\\left({\\hat{y}}_1^{(k)},{\\hat{y}}_2^{(k ) } ; y_1\\big| y_2 , { \\hat{y}}_1^{(1)},{\\hat{y}}_1^{(2)}, ... ,{\\hat{y}}_1^{(k-1 ) } ,                          { \\hat{y}}_2^{(1)},{\\hat{y}}_2^{(2)}, ...",
    ",{\\hat{y}}_2^{(k-1)}\\right ) + 2k{\\epsilon}\\nonumber\\\\                     \\label{eqn : constr_c12_general_bc }                     & = &    i\\left ( { \\hat{y}}_1^{(1)},{\\hat{y}}_1^{(2)}, ...",
    ",{\\hat{y}}_1^{(k ) } ,                          { \\hat{y}}_2^{(1)},{\\hat{y}}_2^{(2)}, ... ,{\\hat{y}}_2^{(k)};y_1\\big| y_2\\right ) + 2k{\\epsilon } ,          \\end{aligned}\\ ] ] and similarly @xmath566 this provides the rate constraints on the conference auxiliary variables of and .",
    "@xmath422 uses @xmath567 and @xmath568 received from @xmath424 , to decode @xmath569 as follows :    * @xmath422 looks for a unique message @xmath474 such @xmath570 from the point - to - point channel capacity theorem ( see @xcite ) , this can be done with an arbitrarily small probability of error by taking @xmath2 large enough as long as @xmath571 denote the decoded message @xmath572 .",
    "now @xmath422 decodes @xmath573 by looking for a unique @xmath574 such that @xmath575 if a unique such @xmath204 exists , then denote the decoded index with @xmath576 .",
    "now @xmath422 looks for the partition of @xmath496 into which @xmath577 belongs and sets @xmath578 to be the index of that partition : @xmath579 .",
    "similarly to the proof in ( * ? ?",
    "* ch 14.6.2 ) , assuming successful decoding of @xmath580 , the probability of error can be made arbitrarily small by taking @xmath2 large enough as long as @xmath581 which is satisfied by construction .      repeating similar steps for decoding at @xmath424 we get that decoding @xmath580 can be done with an arbitrarily small probability of error by taking @xmath2 large enough as long as @xmath582 and assuming successful decoding of @xmath580 , decoding @xmath583 with an arbitrarily small probability of error requires that @xmath584 which again is satisfied by construction .",
    "finally , collecting , , , and give the achievable rate constraints of theorem [ thm : multi - step - general - bc ] , and and give the conference rate constraints of the theorem .      in the single common message cooperative broadcast scenario , a single transmitter sends a message to two receivers encoded in a single channel codeword @xmath0 .",
    "= 0.6    this scenario is depicted in figure [ fig : broadcast - cooperation - common ] .",
    "after conferencing , each receiver decodes the message . for this setup",
    "we have the following upper bound :    [ prop : common_upper ] _ ( ( * ? ? ?",
    "* theorem 6 ) ) _ _ consider the general broadcast channel @xmath585 with cooperating receivers having noiseless conference links of finite capacities @xmath425 and @xmath426 between them .",
    "then , for sending a common message to both receivers , any rate @xmath5 must satisfy @xmath586 _    in @xcite",
    "we also derived the following achievable rate for this scenario :    [ prop : achive_common_one_step ] _ ( ( * ? ? ? * theorem 5 ) ) _    _ assume the broadcast channel setup of proposition [ prop : common_upper ] .",
    "then , for sending a common message to both receivers , any rate @xmath5 satisfying _    @xmath587 , \\nonumber\\\\              \\label{eqn : prevresult1 }                   r_{12}(p_x(x ) ) & \\triangleq & \\min \\big ( i(x;y_1 ) + c_{21 } ,   \\max\\big\\{i(x;y_2 ) ,                          i(x;y_2 ) - h(y_1|y_2,x ) + \\min\\big(c_{12},h(y_1|y_2)\\big)\\big\\ } \\big),\\phantom{xx}\\\\               \\label{eqn : prevresult2 }                   r_{21}(p_x(x ) ) & \\triangleq & \\min \\big ( i(x;y_2 ) + c_{12 } ,                          \\max \\big\\{i(x;y_1 ) , i(x;y_1 )   - h(y_2|y_1,x ) + \\min\\big(c_{21},h(y_2|y_1)\\big)\\big\\ } \\big),\\phantom{xx }              \\end{aligned}\\ ] ]    is achievable .",
    "note that this rate expression depends only on the parameters of the problem and is , therefore , computable . in proposition [ prop : achive_common_one_step ]",
    "the achievable rate increases linearly with the cooperation capacity .",
    "the downside of this method is that it produces a rate increase over the non - cooperative rate only for conference links capacities that exceed some minimum values .",
    "specializing the three independent messages result to the single common message case we obtain the following achievable rate with a @xmath13-cycle conference for the general bc with a single common message :    [ corr : single - coomon - message - with - multi - step ] _ consider the general broadcast channel with cooperating receivers , having noiseless conference links of finite capacities @xmath425 and @xmath426 between them .",
    "let the receivers hold a conference that consists of @xmath13 cycles .",
    "then , any rate @xmath5 satisfying @xmath588 is achievable . _    here",
    "@xmath281 is defined as follows : @xmath589 } \\min \\left\\ { r_1 , r_2 \\right\\},\\ ] ] with    @xmath590    subject to    @xmath591    for the joint distribution @xmath592 the cardinality of the @xmath204th auxiliary random variables are bounded by : @xmath593 @xmath282 is defined in a parallel manner to @xmath281 , with @xmath424 performing the first conference step , and the appropriate change in the probability chain .",
    "the proof of corollary [ corr : single - coomon - message - with - multi - step ] is provided in appendix [ appndx : prof_corollary_single_common ] .",
    "we note that ( * ? ? ?",
    "* theorem 2 ) presents a similar result for this scenario , under the constraint that the memoryless broadcast channel can be decomposed as @xmath427 , and considering the sum - rate of the conference .",
    "here we show that the same achievable rate expressions hold for the general memoryless broadcast channel .",
    "a recent result appears in @xcite , where the single common message case for a gaussian bc is considered . in the multi - cycle conference considered in this section ,",
    "we let the auxiliary rvs follow a more general chain than that of @xcite  which results in a larger achievable rate .",
    "consider the case where only a single cycle of conferencing between the receivers is allowed .",
    "specializing corollary [ corr : single - coomon - message - with - multi - step ] to a single cycle case we obtain    @xmath594    and the ts - eaf assignment is @xmath595 applying the ts - eaf assignment to and we obtain @xmath596 maximizing @xmath280 requires maximizing @xmath597 $ ] . therefore setting @xmath598^*$ ] , we obtain @xmath599^ * i(x;y_1|y_2)$ ] . combining with @xmath279 we have that the rate when @xmath424 decodes first is given by @xmath600^ * i(x;y_1|y_2)\\right\\},\\ ] ] and by symmetric argument",
    "we can obtain @xmath282 .",
    "we conclude that the rate for the single - cycle conference with ts - eaf is given by @xmath601^ * i(x;y_1|y_2)\\right\\}\\\\      r_{21 } & = & \\min \\left\\{i(x;y_1 ) + \\left[\\frac{c_{21}}{h(y_2|y_1)}\\right]^ * i(x;y_2|y_1 ) , i(x;y_2 ) + c_{12}\\right\\}.\\end{aligned}\\ ] ] we note that this rate is always better than the point - to - point rate and also better than the joint - decoding rate of proposition [ prop : achive_common_one_step ] ( whenever cooperation can provide a rate increase ) .",
    "however , as in proposition [ prop : achive_common_one_step ] , at least one receiver has to satisfy the slepian - wolf condition for the full cooperation rate to be achieved .",
    "we also note that using ts - eaf with more than two steps does not improve upon this result .",
    "finally , we demonstrate the results of proposition [ prop : achive_common_one_step ] and corollary [ corr : single - coomon - message - with - multi - step ] through a symmetric bc example : consider the symmetric broadcast channel where @xmath602 and @xmath603 for any @xmath604 and @xmath605 .",
    "let @xmath606 .",
    "for this scenario we have that @xmath607 , in corollary [ corr : single - coomon - message - with - multi - step ] and also @xmath608 in proposition [ prop : achive_common_one_step ] .",
    "the resulting rate is depicted in figure [ fig : compare : ft_and_ts ] for a fixed probability @xmath198 .",
    "we can see that for this case , time - sharing exceeds joint - decoding for all values of @xmath299 .",
    "both methods meet the upper bound at @xmath609 .",
    "we note that this is a corrected version of the figure in @xcite .",
    "in this paper we considered the eaf technique using time - sharing on the auxiliary rvs . we first showed that incorporating joint - decoding at the destination into the eaf technique results in a special case of the classic eaf of ( * ? ? ? * theorem 6 ) .",
    "we then used the time - sharing assignment of the auxiliary rvs to obtain an easily computable achievable rate for the multiple - relay case , which can be compared against the daf - based results , to select the highest rate for any given scenario .",
    "next , we showed that for the gaussian relay channel with coded modulation , the gaussian auxiliary rv assignment is not always optimal , and a ts - eaf implementing a per - symbol hard decision may sometimes perform better .",
    "finally , we considered a third application of ts - eaf to the cooperative broadcast scenario with a multi - cycle conference .",
    "we first derived an achievable rate for the general channel , and then we specialized it to the single - cycle conference for which we obtained an explicit achievable rate .",
    "this rate is superior to the explicit expression that can be obtained with joint - decoding .",
    "in the final version .",
    "we evaluate @xmath348 , with @xmath326 given by and using : @xmath610    1 .",
    "evaluating @xmath411 : note that both @xmath14 and @xmath12 are discrete rvs , therefore @xmath411 can be evaluated using the discrete entropies .",
    "the conditional distribution of @xmath12 given @xmath14 is given by : @xmath611 where @xmath612 @xmath613 can be obtained from @xmath614 by switching @xmath129 and @xmath615 in .",
    "2 .   evaluating @xmath616 :",
    "write first @xmath617 and we note that @xmath618 using the chain rule we write @xmath619 @xmath620 can be obtained by combining and which results in @xmath621 and we note that @xmath622 , since erasure is equivalent to no prior information",
    ". finally we note that by definition @xmath623 where @xmath624 next , we have @xmath625 using @xmath626 we obtain @xmath627    next we need to evaluate @xmath628 :    1 .",
    "@xmath629 . here",
    "@xmath630 2 .   by the definition of conditional entropy we have @xmath631",
    "where @xmath632 , and for @xmath633 , for example , we have @xmath634 finally , we need to derive the distributions @xmath635 and @xmath636 . begin with @xmath637 and due to the symmetry , @xmath638 .",
    "we also have @xmath639      we evaluate the achievable rate using @xmath640 .",
    "the distribution of @xmath12 is given by : @xmath641 and by symmetry , @xmath642 and @xmath643 .",
    "therefore , we need the conditional distribution @xmath644 : @xmath645 this allows us to evaluate @xmath646 . for evaluating @xmath616 note that @xmath647 and we need only to evaluate @xmath648 : by definition @xmath649 and note that @xmath650 .",
    "finally , @xmath651    evaluating @xmath349 we have : @xmath652 where ( a ) is due to the deterministic mapping from @xmath61 to @xmath12 , and @xmath653 can be evaluated using .      as",
    "@xmath654 we have that @xmath655 and @xmath12 converges in distribution to a bernoulli rv with probability @xmath656 .",
    "therefore @xmath657 where @xmath658 .",
    "now , letting @xmath416 we have that @xmath659 and therefore @xmath660 we conclude that as @xmath661 , then @xmath662 and therefore the @xmath663 becomes @xmath664 using the continuity of @xmath663 we conclude that for small values of @xmath340 , as @xmath331 decreases then @xmath663 is bounded from below .",
    "this implies that for small @xmath340 and small @xmath299 the feasibility is obtained only for large @xmath331 , which in turn implies low rate .",
    "we first write @xmath666 evaluating @xmath646 requires the marginal of @xmath12 . using the mapping defined in we find the marginal distribution of @xmath12 : @xmath667 where @xmath668d y_1\\\\      \\pr(|y_1| < t ) &",
    "= & \\int_{y_1 = -t}^{t } \\frac{1}{2}\\left[g_{y_1}(\\sqrt{p},{\\sigma_1 ^ 2})+ g_{y_1}(-\\sqrt{p},{\\sigma_1 ^ 2 } ) \\right]d y_1.\\end{aligned}\\ ] ] also , due to symmetry we have that @xmath643 , and therefore we need only to find the conditional @xmath669 : @xmath670 and we note that @xmath671 .",
    "next , we need to evaluate @xmath672 .",
    "we first note that @xmath673",
    "lastly , we have @xmath674 we note that @xmath675 and that @xmath676 and @xmath677 are calculated exactly as in appendix [ sec : expressions_dhd ] for the dhd case .",
    "begin by writing @xmath678 where we used the fact that given @xmath61 , @xmath12 is independent of @xmath15 .",
    "all the terms in the above expressions have been calculated in the previous subsection , except @xmath679 : @xmath680      here the relay uses the assignment of equation : @xmath681 we first evaluate @xmath682    1 .",
    "@xmath683 2 .",
    "we also have @xmath684",
    "lastly we need to evaluate @xmath685 where @xmath686      using and we can write @xmath687 @xmath688 where in ( a ) we used the fact that @xmath12 and @xmath15 are independent as @xmath361 , and that given @xmath61 , @xmath12 is independent of @xmath15 .",
    "in the following we highlight only the modifications from the general broadcast result due to the application of daf to the last conference step from @xmath422 to @xmath424 , and the fact that we transmit a single message .",
    "the transmitter generates @xmath689 codewords @xmath21 in an i.i.d .",
    "manner according to @xmath690 , @xmath691 . for transmission of the message @xmath692 at time @xmath23 the transmitter outputs @xmath693 .",
    "the @xmath13 conference steps from @xmath422 to @xmath424 are carried out exactly as in section [ sec : decencmultisteprgood ] .",
    "the first @xmath694 steps from @xmath424 to @xmath422 are carried out as in section [ sec : decencmultisteprbad ] . the @xmath13th conference step from @xmath424 to @xmath422 , is different from that of theorem [ thm : multi - step - general - bc ] , as after the @xmath13th step from @xmath422 to @xmath424 , @xmath424 may decode the message since @xmath424 received all the @xmath13 conference messages from @xmath422 .",
    "then , @xmath424 uses decode - and - forward for its @xmath13th conference transmission to @xmath422 .",
    "therefore , @xmath424 simply partitions @xmath48 into @xmath695 subsets in a uniform and independent manner .",
    "[ [ encoding - and - decoding - at - the - kth - conference - step - from - r_x2-to - r_x1 ] ] encoding and decoding at the @xmath13th conference step from @xmath424 to @xmath422 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^    * before the @xmath13th conference step , @xmath424 decodes its message using his channel input and all the @xmath13 conference messages received from @xmath422 .",
    "this can be done with an arbitrarily small probability of error as long as is satisfied . *",
    "having decoded its message , @xmath424 uses the decode - and - forward strategy to select the @xmath13th conference message to @xmath422 .",
    "the conference capacity allocated to this step is @xmath696 . *",
    "having received the @xmath13th conference message from @xmath424 , @xmath422 can now decode its message using the information received at the first @xmath694 steps , and combining it with the information from the last step using the decode - and - forward decoding rule .",
    "this gives rise to .",
    "the bounds on @xmath562 , @xmath441 can be obtained as in section [ sec : combining_bounds_general ] : @xmath697 and similarly @xmath698 where @xmath699 is the total capacity allocated to the first @xmath694 conference steps from @xmath424 to @xmath422 .",
    "this provides the rate constraints on the conference auxiliary variables ."
  ],
  "abstract_text": [
    "<S> _ in this work we focus on the general relay channel . </S>",
    "<S> we investigate the application of estimate - and - forward ( eaf ) to different scenarios . specifically , we consider assignments of the auxiliary random variables that always satisfy the feasibility constraints . </S>",
    "<S> we first consider the multiple relay channel and obtain an achievable rate without decoding at the relays . </S>",
    "<S> we demonstrate the benefits of this result via an explicit discrete memoryless multiple relay scenario where multi - relay eaf is superior to multi - relay decode - and - forward ( daf ) . </S>",
    "<S> we then consider the gaussian relay channel with coded modulation , where we show that a three - level quantization outperforms the gaussian quantization commonly used to evaluate the achievable rates in this scenario . </S>",
    "<S> finally we consider the cooperative general broadcast scenario with a multi - step conference . </S>",
    "<S> we apply estimate - and - forward to obtain a general multi - step achievable rate region . </S>",
    "<S> we then give an explicit assignment of the auxiliary random variables , and use this result to obtain an explicit expression for the single common message broadcast scenario with a two - step conference . </S>",
    "<S> _    ( 0,0 ) ( 0,70)submitted to the ieee transactions on information theory , october 2006 . </S>"
  ]
}