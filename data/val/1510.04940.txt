{
  "article_text": [
    "the amount of wireless ip data traffic is projected to grow by well over @xmath0 times within a decade ( from under @xmath5 exabytes in 2010 to more than @xmath6 exabytes by 2020 ) @xcite . to address such wireless data traffic demand ,",
    "there has been increasing effort to define the 5 g network in recent years .",
    "it is widely recognized that the 5 g network will be required to deliver data rate about @xmath0 to @xmath1 times the current 4 g technology , utilizing radical increase in wireless bandwidths at very high frequencies , extreme network densitification , and massive number of antennas @xcite .    distributed base station architecture and cloud radio access network ( c - ran ) will continue to be an important network architecture well into the future @xcite .",
    "therefore , there is a pressing need to drastically enhance the data rate of the common public radio interface ( cpri ) ( see fig .",
    "[ fig : cpri ] ) , which is the industry standard for interface between the baseband units ( bbu ) and the remote radio units ( rru ) .    one way to address the significant increase in the cpri data rate is to deploy more links ( typically fibers ) connecting the bbus and the rrus , but such deployment would incur extraordinary high cost .",
    "an alternative method , which can be much more cost effective , is to employ data compression over cpri links .",
    "it is impossible to utilize only cpri link compression to meet the cpri link data rate requirement .",
    "nevertheless , cpri link compression can greatly reduce the required cost when employed in conjunction with new links deployment .",
    "rate reduction between the bbu and the rru can also be achieved by moving some of the functions traditionally performed at the bbu to the rru , but this requires a significant change to the existing distributed base station or c - ran architecture @xcite .",
    "this paper focuses on cpri link data compression which can be employed with minimal change to the current distributed base station or c - ran architecture .",
    "cpri link compression techniques commonly found in the literature are based on scalar quantization @xcite , often with block scaling before quantization to adjust for the dynamic range of samples to be quantized . for lte networks , time - domain lte ofdm i",
    "/ q samples are carried over cpri links .",
    "cyclic prefix removal for downlink and decimation to remove the inherent redundancy in oversampled lte signals have been proposed to achieve additional compression .",
    "@xcite proposed a non - linear scalar quantization , whereby the quantizer is trained off - line using an iterative gradient algorithm .",
    "compression gain of @xmath5 times was reported with approximately @xmath4 evm for @xmath7 mhz downlink lte data .",
    "@xcite reported a compression gain of @xmath8 times with approximately @xmath4 evm distortion using decimation , an enhanced block scaling and a uniform quantizer .",
    "lloyd - max scalar quantization with noise shaping was considered in @xcite , and distributed compression was investigated in @xcite .",
    "our approach differs from previous approaches in that we consider a vector quantization ( vq ) based compression , rather than a scalar one .",
    "we exploit the fact that due to the ifft ( fft ) operation for downlink ( uplink ) , the i / q samples of an ofdm symbol are correlated over time .",
    "scalar quantizer is not capable of exploiting such time correlations .",
    "on the other hand , vector quantization , by mapping grouped samples into codewords , can explore such correlations and achieves better compression gain @xcite .",
    "from complex i / q samples , vectors need to be formed before quantization .",
    "there are several vectorization methods depending on how i / q samples are placed within the vectors that are formed .",
    "we investigate the performance of different vectorization methods for constructing vectors from i / q samples . for vector quantization codebook training ,",
    "lloyd algorithm is introduced . to further enhance performance , we propose a modified algorithm with different initialization step , where multiple trials work in serial to generate better codebook .",
    "low - complexity vector quantization algorithms in the form of multi - stage vector quantization ( msvq ) and unequally protected multi - group quantization ( upmgq ) are also considered in the paper .",
    "analysis and simulation result show that the proposed compression scheme can achieve @xmath2 times compression for uplink and @xmath3 times compression for downlink within @xmath4 evm distortion .",
    "the rest of this paper is organized as follows .",
    "section  [ sec : algorithm ] describes the cpri compression algorithm in details , including the report on the serial initialization pattern to improve the performance of trained codebook from regular vector quantization as well as the discussion on universal compression .",
    "section  [ sec : advanced ] discusses advanced quantization methods , in order to reduce the searching and storing complexities of regular vector quantization .",
    "after that , section  [ sec : simulation ] contains all simulation results for both downlink and uplink , comparing different quantization methods mentioned in previous sections .",
    "finally , section  [ sec : conclusion ] concludes the paper .",
    "a system framework for our vector quantization based cpri compression and decompression for both downlink and uplink is illustrated in fig .",
    "[ fig : framework ] . for downlink ,",
    "the input to the cpri compression module located at the bbu site is a stream of digital i / q samples from the bbu .",
    "the cpri compression module further contains modules of _ cyclic prefix removal _ , _ decimation _ , _ block scaling _ , _ vector quantizer _ and _ entropy encoding_. at the rru site , the cpri decompression module performs the reverse operations . for uplink ,",
    "the analog - to - digital converter ( adc ) output is the input to the cpri compression module located at the rru site and the cpri decompression module at the bbu site performs the reverse operations .        within these function blocks , _ cyclic prefix removal _ , _ decimation _ , and _",
    "block scaling _ are standard signal processing @xcite .",
    "a sketch of their roles and compression gains are summarized as follows ( please refer to appendix  [ app : details ] for details of theses blocks ) :    * _ cp removal _ block , applicable for downlink only , aims to eliminate the time domain redundancy from cyclic prefix . the compression gain from this block ( i.e. , @xmath9 )",
    "can be expressed as @xmath10 where @xmath11 and @xmath12 denote ifft output symbol length and cyclic prefix length , respectively . *",
    "_ decimation _ block aims to reduce the redundancy in frequency domain because lte signal is oversampled .",
    "the compression gain from this block ( i.e. , @xmath13 ) can be expressed as @xmath14 where @xmath15 and @xmath16 denote downsampling and upsampling factors , respectively . *",
    "_ block scaling _ block aims to lower the resolution of the signal and maintain the dynamic range to be consistent with the downstream quantization codebook .",
    "there is no direct compression gain from this block .",
    "in contrast , extra signaling overhead of @xmath17 bits for every @xmath18 samples is required , where @xmath17 is the target resolution and @xmath18 is the number of samples forming a block .",
    "_ vector quantization _ and _ entropy coding _",
    "blocks are key techniques in our cpri compression algorithm . in section  [ sec : algorithm : vq ] and section  [ sec : algorithm : ec ] , we present their mechanisms and performances in detail .      as shown in fig .",
    "[ fig : quantization ] , vector quantization / dequantization is performed based on a vector quantizer codebook @xcite . the inputs",
    "to vector quantization module are the vectorized samples @xmath19 ( @xmath20 , where @xmath21 is the number of i / q samples and @xmath22 is the vector length ) , and the vector quantizer codebook which is a set of vector codewords @xmath23 ( @xmath24 , where @xmath25 is the codebook size ) .",
    "the codebook is trained off - line using training samples such that a specified distortion metric ( such as the euclidean distance ) is minimized .",
    "the vector quantizer maps a vector sample @xmath19 to one of the vector codewords which would minimize the specified distortion metric .",
    "each quantized sample vector is represented by @xmath26 bits .",
    "then , the compression gain from vector quantization is given by @xmath27 where @xmath28 is the uncompressed bitwidth of i or q component of each sample , and @xmath29 is the effective bitwidth of quantized samples .",
    "@xmath28 is typically @xmath30 , specified in @xcite .",
    "next , we discuss in detail the vectorization step and the codebook training .          before vector quantization , the vectorization of i / q samples is needed .",
    "the purpose of vectorization is to construct vectors from i / q samples that can capture correlation or dependency across i / q samples .",
    "a question of interest is : given a vector length @xmath22 , what is the best way to perform vectorization of i / q samples such that the compression gain of vector quantization can be maximized ? to this end , we consider the following three vectorization methods ( see fig .  [ fig : vectorization ] for an illustration ) :    * method 1 : consecutive i components in time are grouped as vectors .",
    "similarly , consecutive q components are grouped as vectors .",
    "* method 2 : i and q components of the same time index are grouped as vectors .",
    "* method 3 : i and q components of all samples are randomly grouped as vectors .",
    "the three vectorization methods are compared using the entropy of the distribution of the constructed vectors of chosen length in euclidean orthants as metric . since lower entropy value indicates higher correlation between the components of the constructed vectors , the vectorization method with smaller entropy implies higher quantization compression gain .",
    "[ fig : vecmethod ] shows plots of entropy versus @xmath22 for the three vectorization methods .",
    "it is evident from the plots that for lte signals , method 1 has the smallest entropy among the three methods , which shall be assumed in the rest of this paper .",
    "our vector quantizer codebook is trained using lloyd algorithm @xcite ( a special case of lbg algorithm @xcite ) .",
    "lloyd algorithm is an iterative algorithm that can be utilized to construct codebook for vector quantization .",
    "it aims to find evenly - spaced sets of points ( as codewords ) in subsets of euclidean spaces , and to partition input samples into well - shaped and uniformly sized convex cells . in general , lloyd algorithm may start by randomly picking a number of input samples as initial codewords , and it then repeatedly executes samples partitioning and codebook updating in every iteration to reduce target distortion .",
    "a commonly used distortion metric is the euclidean distance .",
    "each time , the codeword points are left in a slightly more even distribution : closely spaced points move farther apart , and widely spaced points move closer together .",
    "finally , lloyd algorithm terminates at certain local optimal , after a proper stopping criterion is satisfied .",
    "classical lloyd algorithm is known to be quite sensitive to the initial choice of codewords , especially when input sample space does not have a smooth structure @xcite@xcite .",
    "in other words , if the input samples are concentrated in a particular space , lloyd algorithm easily converges to a local optimum which can be away from the global optimum . to this end",
    ", classical lloyd algorithm performs multiple independent trials and chooses the codebook that produces the lowest distortion metric from all trials to evade the initialization problem . a process chain for classical lloyd algorithm with multiple trials",
    "is illustrated in fig .",
    "[ fig : classical_lloyd ] .        in the case of lte",
    "i / q samples , the sample values are observed to be highly concentrated in a narrow range .",
    "however , we also observe that independent trials is not effective to overcome the initialization problem described earlier , specifically we observe persistent convergence to similar local optimum despite multiple lloyd trials . to resolve this issue",
    ", we introduce a modified lloyd algorithm , whereby the output ( codebook ) from previous trial is utilized as the input ( the initial codebook ) to the next trial , after applying proper rescaling to the initial codebook magnitude .",
    "the procedure of rescaling is essential , because the output from previous trial is already a local optimum .",
    "rescaling helps to evade this local optimum and restart the search for a better codebook .",
    "the rescaling factor can be the square root of the average power of the i / q samples .",
    "the diagram illustrating the modified lloyd algorithm is given in fig .",
    "[ fig : modified_lloyd ] .",
    "the effectiveness of the modified lloyd algorithm is illustrated by comparing the codebooks trained using the classical lloyd algorithm and the modified lloyd algorithm as shown in fig .",
    "[ fig : codebook_compare_classical ] and fig .  [ fig : codebook_compare_modified ] respectively . in this simulation ,",
    "lte uplink signals with @xmath31db snr , @xmath32qam modulation , and awgn channel are considered as training sequences using vq with @xmath33 and @xmath34 .",
    "two axes of fig .",
    "[ fig : codebook_compare ] represent the two elements of the grouped vectors . each point on",
    "the plot represents a codeword and the color corresponds to frequencies ( warmer color for higher frequency ) .",
    "it is observed that the codebook from modified algorithm better reflects the distribution of training sample vectors .",
    "this is also confirmed from the evm improvement of @xmath35 from the classical algorithm to @xmath36 from the modified lloyd algorithm for this particular case ( @xmath37 improvement ) .",
    "entropy coding is a lossless data compression scheme that utilizes more bits to represent sources with lower frequency ( higher entropy ) and fewer bits to represent sources with higher frequency ( lower entropy ) .",
    "the most common entropy coding technique is huffman coding @xcite . in huffman coding , the dictionary construction procedure",
    "can be completed in linear time , and the final codeword for each symbol can be simply constructed from a splitting tree . according to shannon s lossless source coding theorem @xcite",
    ", the optimal average coded length for a source is its entropy , and huffman codes are proven to be optimal with linear time complexity for symbol - by - symbol coding @xcite .    without entropy coding",
    ", each codeword of vector quantization codebook requires exactly @xmath26 bits for representation .",
    "however , it is observed that the probability mass function ( pmf ) of codewords is not uniform ( see fig .",
    "[ fig : codebook_compare ] , where warmer color represents higher probability ) , implying potential entropy coding gain . to this end , huffman coding is applied based on the pmf of codewords . denoting the average length of huffman codes as @xmath38 , the compression gain from entropy coding can be expressed as @xmath39      in this subsection",
    ", the aforementioned blocks in system are integrated together and performance of the whole cpri compression framework is evaluated .",
    "the compression gain and the evm distortion are investigated .",
    "we summarize the main results of the proposed cpri compression algorithm in a theorem as follows .",
    "[ thm : cr ] for a given vectorization method and a given vector length , the proposed vector quantization based lossy compression algorithm for cpri link can achieve the rate distortion trade - off given by _",
    "@xmath40 _ and _ @xmath41 _ for large value of @xmath21 , where the compression gains in the denominator of are given by , , , and , respectively ; @xmath28 is the uncompressed bitwidth of i or q component of each sample ; @xmath17 and @xmath18 are parameters for block scaling ; @xmath42 is the input sequence to compression algorithm ; @xmath43 is the output from decompression algorithm ; @xmath21 is the number of input or output complex samples .    from the description of proposed algorithm , if @xmath21 complex samples are considered as input to the module , where each complex component is represented by @xmath28 bits , after compression , @xmath44 number of binary strings are transmitted on cpri link , where the average length for each string is @xmath38 . for _ block scaling _ block ,",
    "@xmath17 number of extra bits are needed for every @xmath18 complex samples .",
    "hence , the final compression gain by cpri compression can be expressed as @xmath45 which further gives the expression in . note that if any of the blocks is not enabled / present , the corresponding compression gain is set to @xmath46 ( especially , if the block scaling is not enabled , @xmath17 is set to @xmath47 ) .",
    "equation is the standard form of error vector magnitude ( evm ) , which is a measure of deviation of constellation points from their ideal locations . in this study , evm is used to quantify the distortions introduced by compression .",
    "time - domain evm calculates the distortion over the whole bandwidth .",
    "however , for lte signals , only part of the bandwidth carries useful information .",
    "this motivates the use of frequency - domain evm instead of the time - domain evm as the distortion measure , i.e. , @xmath48 where @xmath49 and @xmath50 are transformed signals by fft for input and output respectively , and @xmath51 is the collection of indices corresponding to the utilized bandwidth .      in principle ,",
    "vector quantization codebook constructed from a particular set of training samples can produce the intended performance if the real samples do not deviate significantly from the training samples in statistical sense .",
    "however , in practice , system parameters or properties , such as channel types , snrs , and modulation schemes , may not be known perfectly , or may not always match those assumed for the training samples .",
    "this motivates the need for a universal compression technique , i.e. , a robust codebook that can provide reasonable or acceptable performances in all or a large range of system parameters , although the codebook is not necessarily optimal for a specific system setting .",
    "to understand if such a universal codebook exists , we investigate the performance of codebooks produced using mismatched training samples , in order to find the sensitivity factors impacting the performance .",
    "a key step is to discover the most robust parameter contributing to the universal codebook .",
    "if this procedure is infeasible , i.e. , such a parameter does not exist , a larger training sample pool mixing with different parameters should be considered , such that the trained codebook could reflect the distributions of all parameters .",
    "for example , for uplink lte samples with @xmath2 times target compression ratio , if vector length @xmath34 with decimation value @xmath52 is performed , constructed codebook is rather insensitive to modulation methods or channel types ( see table  [ tab : level2_mismatch_modulation ] and table  [ tab : level2_mismatch_channel ] ) , but is relatively more sensitive to snrs ( see table  [ tab : level2_mismatch_snr ] ) .",
    "nevertheless , the @xmath31db codebook can be adopted as the universal codebook , since its evm performances are acceptable for all snr training samples .",
    "based on these observations , we conclude that the codebook obtained from @xmath31db snr , @xmath32qam modulation , and awgn channel can be a suitable universal codebook , which we shall assume for further performance evaluation in section  [ sec : simulation : ul ] .",
    "signal on cpri link can have a large dynamic range .",
    "for instance , for uplink cpri signals , different propagation path loss , shadowing , fading channel and mobility for different users may result in significant variance in general .",
    "_ block scaling _ , also known as automatic gain control ( agc ) , is employed to lower the resolution of signal and to maintain the dynamic range simultaneously @xcite@xcite .    in agc",
    ", a sequence of signal samples are grouped into blocks of consecutive samples , where the samples in each block are scaled by a scaling factor which can vary from block to block .",
    "more precisely , assume @xmath53 number of samples form a block , and the largest absolute value of i / q components for a particular block @xmath54 is determined by @xmath55 where @xmath56 is the output from the _ decimation _ block , and @xmath57 and @xmath58 represent the real and imaginary parts of a complex - valued sample , respectively .",
    "next , the corresponding scaling factor for block @xmath59 is determined by @xmath60 by this definition , @xmath61 is an integer that can be represented with @xmath17 bits .",
    "samples in block @xmath59 are then scaled to produce an output @xmath62 as follows .",
    "@xmath63 where @xmath29 denotes the number of bits per complex component for vector quantization .",
    "in essence , block scaling normalizes the input signals for vector quantization .",
    "there is a slight increase in signal processing latency associated with block scaling .",
    "for instance , in lte @xmath7 mhz system , by choosing @xmath64 , the latency due to block scaling is @xmath65 @xmath66s with decimation value chosen as @xmath52 .",
    "d.  samardzija , j.  pastalan , m.  macdonald , s.  walker , and r.  valenzuela , `` compressed transport of baseband signals in radio access networks , '' _ ieee transactions on wireless communications _",
    "11 , no .  9 , pp .",
    "32163225 , sep . 2012 .",
    "y.  ren , y.  wang , g.  xu , and q.  huang , `` a compression method for lte - a signals transported in radio access networks , '' in _ 2014 international conference on telecommunications ( ict 2014 ) _ , may 2014 , pp .",
    "293297 .",
    "k.  f. nieman and b.  l. evans , `` time - domain compression of complex - baseband lte signals for cloud radio access networks , '' in _ 2013 ieee global conference on signal and information processing ( globalsip 2013 ) _ , dec .",
    "2013 , pp . 11981201 .",
    "s.  h. park , o.  simeone , o.  sahin , and s.  shamai , `` robust and efficient distributed compression for cloud radio access networks , '' _ ieee transactions on vehicular technology _ , vol .",
    "62 , no .  2 ,",
    "692703 , feb .",
    "2013 .",
    "b.  h. juang and a.  gray  jr , `` multiple stage vector quantization for speech coding , '' in _ 1982 ieee international conference on acoustics , speech , and signal processing ( icassp82 ) _ , vol .  7 , may 1982 , pp . 597600 .",
    "h.  si , o.  o. koyluoglu , and s.  vishwanath , `` lossy compression of exponential and laplacian sources using expansion coding , '' in _ 2014 ieee international symposium on information theory ( isit 2014 ) _ , jun .",
    "2014 , pp . 30523056 ."
  ],
  "abstract_text": [
    "<S> the future wireless network , such as centralized radio access network ( c - ran ) , will need to deliver data rate about @xmath0 to @xmath1 times the current 4 g technology . for c - ran based network architecture </S>",
    "<S> , there is a pressing need for tremendous enhancement of the effective data rate of the common public radio interface ( cpri ) . </S>",
    "<S> compression of cpri data is one of the potential enhancements . in this paper , we introduce a vector quantization based compression algorithm for cpri links , utilizing lloyd algorithm . </S>",
    "<S> methods to vectorize the i / q samples and enhanced initialization of lloyd algorithm for codebook training are investigated for improved performance . </S>",
    "<S> multi - stage vector quantization and unequally protected multi - group quantization are considered to reduce codebook search complexity and codebook size . </S>",
    "<S> simulation results show that our solution can achieve compression of @xmath2 times for uplink and @xmath3 times for downlink , within @xmath4 error vector magnitude ( evm ) distortion . </S>",
    "<S> remarkably , vector quantization codebook proves to be quite robust against data modulation mismatch , fading , signal - to - noise ratio ( snr ) and doppler spread . </S>"
  ]
}