{
  "article_text": [
    "modelling and estimating the underlying spatial dependence structure of the observed data is a key element to spatially interpolate data and perform simulations .",
    "its description is commonly carried out using statistical tools such as the covariance or variogram calculated on the whole domain of interest .",
    "simplifying assumptions are often made on the spatial dependence structure .",
    "they include stationarity assumption where the second order association between pairs of locations is assumed to depend only on the vector between these locations .",
    "however , it has become increasingly clear that this assumption is driven more by mathematical convenience than by reality . in pratice",
    ", it often happens that the stationarity assumption may be doubtful .",
    "non - stationarity can occur due to many factors , including specific landscape and topographic features of the region of interest or other localized effects .",
    "these local influences can be observed by computing local variograms , whose characteristics may vary across the domain of observations .",
    "more practionners choose to replace this convenient assumption with more realistic assumption of non - stationarity .",
    "they subdivide the modelling area into stationary domains , thereby increasing the required professional time for modelling and potentially producing disjointed domains that are globally inconsistent .",
    "various approaches have been developped over the years to deal with non - stationarity through second order moments ( see @xcite , for a review ) .",
    "one of the most popular methods of introducing non - stationarity is the convolution approach .",
    "it consists of taking a spatial white noise , then averaging it using weights that vary spatially to thereby obtain a non - stationary random function . in this way , the resulting spatial dependence structure is non - stationary . the covariance or variogram as a whole is allowed to vary in some way between different locations .",
    "@xcite use spatially varying gaussian kernel function to induce a non - stationary covariance structure .",
    "the resulting covariance function has a closed - form , but is infinitely differentiable , which may not be desirable for modelling real phenomena .",
    "@xcite use a family of spatially varying modified bessel kernel functions to produce a non - stationary covariance function with local smoothness characteristics that are similar to the stationary matrn covariance functions class .",
    "one limitation of this approach is that the non - stationary covariance function does not have a closed - form and in general can only be evaluated by numerical integration . moreover",
    ", this approach does not take into account a spatially varying anisotropy .",
    "furthermore , explicit expressions of some non - stationary covariance functions class that include a non - stationary version of the stationary matrn covariance function have been introduced by @xcite .",
    "this was further developed by @xcite , @xcite and @xcite .",
    "however , these classes of analytical non - stationary covariance functions do not directly derived from a random function model like the convolution representation or the spectral representation . thus , this does not facilitate their understanding and interpretability .",
    "it is helpful to have a constructive approach for random functions admitting such closed - form non - stationary covariance functions .",
    "moreover , the inference of the parameters of these latter remains a critical problem .",
    "@xcite enumerate some difficulties and suggest some possible methods including the moving windows approach based on the local variogram or local likelihood .",
    "@xcite mention two typical problems arising with moving windows method .",
    "first , the range of validity of a stationary approximation can be too small to contain enough local data to estimate the spatial dependence structure reliably .",
    "second , it can produce non - smooth parameter estimates , leading to discontinuities on the kriging map which is undesirable in many cases .",
    "@xcite develop a weighted local likelihood approach for estimating parameters of the non - stationary version of the stationary matrn covariance function .",
    "this approach downweight the influence of distant observations and allows irregular sampling observations .",
    "a few drawbacks of their approach are the computational burden of inverting covariance matrices at every location for parameter estimation and the gaussian distributional assumption for analytical tractability .    in this work",
    ", we are interested primarily in the modelling of second order non - stationary random functions , using a constructive approach in the spirit of convolution model .",
    "we present a new model for second order non - stationary random functions as a convolution of an orthogonal random measure , with a spatially varying stochastic weighting function .",
    "this is an extension of the classical convolution model where a deterministic weighting function is used .",
    "by this modelling approach , the resulting class of non - stationary covariance functions is very general , flexible and allows to retrieve classes of closed - form non - stationary spatial covariance functions known from the literature , for a suitable choices of the stochastic weighting functions family .",
    "these latter classes show locally a stationary behaviour and their parameters are allowed to vary with location , yielding local variance , range , geometric anisotropy and smoothness . in this way",
    ", it naturally allows stationary local covariance parameters to be knitted together into a valid non - stationary global covariance .",
    "thus , we establish a direct link between the existing explicit classes of non - stationary covariance functions and the convolution approach .",
    "this construction bears some resemblance to the moving average model with stochastic weighting function introduced by @xcite to generate stationary covariance functions like cauchy and matrn families .",
    "secondly , we develop a procedure of estimating parameters that govern these classes of closed - form non - stationary covariance functions under a single realization and local stationarity framework , through a step by step approach .",
    "first , we compute local variograms by a non - parametric kernel estimator .",
    "then , it is used in a weighted local least squares procedure for estimating the parameters at a reduced set of representative points referred to as anchor points .",
    "finally , a kernel smoothing method is used to interpolate the parameters at any location of interest .",
    "the estimation method proposed is free distribution and no matrix inversions or determinants calculation are required .",
    "it is applied to two real datasets : soil and rainfall data .",
    "the outline of the paper is as follows : a generalized convolution model is described through its basic ingredients and main properties in section [ sec2 ] . in section [ sec3 ] ,",
    "we show how the model allows us to construct explicit classes of non - stationary covariance functions . in section [ sec4 ] ,",
    "parameter inference of these explicit classes of non - stationary covariance is detailed .",
    "we tackle the spatial predictions and conditional simulations in section [ sec5 ] . in section [ sec6 ] ,",
    "two real datasets are used to illustrate the performances of the proposed method and its potential .",
    "finally , section [ sec7 ] outlines concluding remarks .",
    "let @xmath0 be a random function defined on a fixed continuous domain of interest @xmath1 of the euclidean space @xmath2 . the random function @xmath3 is defined as follows : @xmath4 where @xmath5 is an orthogonal random measure on @xmath2 with @xmath6 ; @xmath7 is the dirac measure at @xmath8 and @xmath9 .",
    "@xmath10 is a family of independent and identically distributed random variables , and independent of @xmath5 , taking their values in the subset @xmath11 of @xmath12 according to a probability measure @xmath13 .",
    "@xmath14 is a family of square - integrable functions on @xmath2 , for all @xmath15 . for fixed @xmath16",
    ", @xmath17 is a random variable whose first two moments are assumed finite and integrable on @xmath2 .    under these assumptions ,",
    "the stochastic convolution defined in ( [ eq1 ] ) is well - defined in @xmath18 , that is @xmath19 . to fix ideas , here are two examples of orthogonal random measure which can be used to simulate the random function @xmath3 @xcite :    1 .",
    "consider a homogeneous poisson point process on @xmath2 with intensity @xmath20 .",
    "let @xmath21 the number of points that falls in a measurable set @xmath22 .",
    "the function @xmath5 defined by @xmath23 is an orthogonal random measure , where @xmath24 is the @xmath25-dimensional lebesgue measure . 2 .",
    "gaussian white noise on @xmath2 is an orthogonal random measure @xmath5 such that : @xmath26 is normally distributed with mean @xmath27 and variance @xmath28 ; when @xmath29 and @xmath30 are disjoint @xmath26 and @xmath31 are independent and @xmath32 .",
    "[ prop1 ] under the model specified in ( [ eq1 ] ) , we have the following moment properties : @xmath33    the proposition [ prop1 ] gives a very general and flexible class of non - stationary covariance functions .",
    "this latter is defined at any two locations and is valid on @xmath34 , that is to say positive definite .",
    "therefore , the random function @xmath3 is non - stationary through its second order moment .",
    "the proof of the above properties is deferred to the [ appendix - sec1 ] .",
    "note that the class of non - stationary covariance functions obtained in ( [ eq2b ] ) is a mixture of convolutions .",
    "it allows to generate different forms of regularity at the origin including low degree of regularity .",
    "indeed , the operation of randomization by the positive measure @xmath35 produces models that can be less regular than the base model induced by @xmath36 , but never more regular .",
    "consider @xmath37 a mapping from @xmath2 to @xmath38 the set of real - valued positive definite @xmath25-dimensional square matrices .",
    "let @xmath39 be a continuous isotropic stationary correlation function , positive definite on @xmath2 , for all @xmath40 .",
    "let @xmath41 and @xmath42 .",
    "consider the families of functions @xmath43 and @xmath44 for all @xmath15 such that @xmath45 and @xmath46 is the @xmath25-variate gaussian density function centered at @xmath47 , with covariance matrix @xmath48 .",
    "the following propositions and corollaries are proven in the [ appendix - sec1 ] .",
    "[ prop2 ] if @xmath49 , then the class of non - stationary covariance functions generated through is : @xmath50    proposition [ prop2 ] provides a very general class of non - stationary covariance functions similar to that proposed by @xcite . the corollaries which will follow",
    "show that appropriate choices for the function @xmath51 and the positive measure @xmath35 give explicit classes of non - stationary covariance functions known from the literature .",
    "we thus establish a direct link between these latter and the convolution model .",
    "[ cor1 ] if @xmath52 and @xmath53 , for @xmath54 a finite positive measure on @xmath55 such that + @xmath56 , then the class of non - stationary correlation functions generated through is : @xmath57    we thus find the class of closed - form non - stationary correlation functions introduced by @xcite .",
    "the intuition behind this class is that to each input location @xmath47 is assigned a local gaussian kernel matrix @xmath58 and the correlation between two targets @xmath47 and @xmath59 is calculated by averaging between the two local kernels at @xmath47 and @xmath59 . in this way",
    ", the local characteristics at both locations influence the correlation of the corresponding target values .",
    "thus , it is possible to account for non - stationarity .",
    "it is done by specifying the mapping @xmath60 which models the anisotropy of the correlation function .",
    "the resulting kernel matrix @xmath58 at each point @xmath47 is interpreted as a locally varying geometric anisotropy matrix .",
    "it controls the anisotropic behavior of the random function in a small neighborhood around @xmath47 .",
    "the positive measure @xmath54 defined in the corollary [ cor1 ] is the measure associated with the schoenberg representation of the correlation function @xmath39 which is a continuous , positive definite and radial function on @xmath2 , for all @xmath40 @xcite .",
    "an approach based on a class of non - stationary correlation models defined in does not allow the use of isotropic stationary correlation models that are not valid in all dimensions .",
    "thus , we lost the isotropic stationary correlation functions with compact support such that the spherical model ( valid in @xmath61 ) .",
    "[ ex1 ] by a specific choice of the positive measure @xmath35 in corollary [ cor1 ] , we obtain some subclasses of closed - form non - stationary correlation functions :    1 .",
    "@xmath62 ; 2 .",
    "@xmath63 ; 3 .",
    "@xmath64 , with @xmath65 the density of the gamma distribution @xmath66 , where @xmath67 is the modified bessel function of second kind with order @xmath68 @xcite ; 4 .",
    "@xmath64 , with @xmath65 the density of the inverse gamma distribution @xmath69    the example [ ex1 ] shows that a suitable choice of the positive measure @xmath35 produces non - stationary versions of some well known stationary correlation functions : gaussian , exponential , matrn and cauchy .",
    "these examples can also be deduced from the following corollaries [ cor2 ] and [ cor3 ] .",
    "[ cor2 ] if @xmath70 and @xmath71 , with @xmath65 the density of gamma distribution @xmath72 , then the class of non - stationary correlation functions generated through is : @xmath73 where @xmath74 ; @xmath75 is the modified bessel function of second kind with order @xmath76 .    from corollary [ cor2 ]",
    ", we retrieve the non - stationary version of the stationary matrn correlation function introduced by @xcite .",
    "this one allows both local geometric anisotropy and degree of differentiability to vary spatially .",
    "when the function @xmath77 is constant , we obtain the non - stationary matrn correlation function with constant regularity parameter shown in example [ ex1 ] . however , the associated function @xmath78 and positive measure @xmath35 are different .",
    "[ cor3 ] if @xmath79 et @xmath80 , with @xmath65 the density of inverse gamma distribution @xmath81 , then the class of non - stationary correlation functions generated through is : @xmath82 where @xmath83 .",
    "the corollary [ cor3 ] gives a non - stationary version of the cauchy correlation function introduced by @xcite .",
    "both the local geometric anisotropy and long - range dependence are allowed to vary spatially .",
    "for the constant long - range dependence parameter @xmath84 , we obtain the cauchy non - stationary correlation function shown in example [ ex1 ] .    from above formulas , it is straightforward to construct a closed - form non - stationary covariance function including a standard deviation function . doing so , the non - stationary covariance is defined as follows : @xmath85 where @xmath86 is a standard deviation function and @xmath87 a closed - form non - stationary correlation function .    note",
    "that , the closed - form non - stationary covariance functions defined in have the desirable property of including stationary covariance functions as a special case .",
    "in this section , we propose a procedure for estimation of spatially variable parameters that govern the classes of closed - form non - stationary second order structure model presented in section [ sec3 ] .",
    "although it could be used for all of these classes , we focus on the one defined in which is flexible enough for many applications . the proposed estimation methodology allows us to deal simultaneously with other types of non - stationarity : mean and variance .",
    "thus , we consider an extended model built from the model specified in which includes a non - stationarity both in mean and variance . the estimation procedure is based on the local stationarity assumption and is achieved using a three - step estimation scheme .",
    "first , a non - parametric kernel estimator of the local variogram is built .",
    "then , it is used in a weighted local least squares procedure to estimate parameters at a representative set of points referred to as anchor points .",
    "next , a kernel smoothing approach is used to interpolate the parameters at any location of interest .      to include a non - stationarity both in mean and variance",
    ", we consider a random function @xmath88 described as follows :    @xmath89    where @xmath90 is an unknown fixed function .",
    "@xmath91 is an unknown positive fixed function .",
    "@xmath3 is a zero - expectation , unit variance random function with correlation function defined in : @xmath92    thus , the random function @xmath3 carries the spatial dependence structure of the random function @xmath93 .",
    "the model formulation defined in leads to a first and second order moments written as follows : @xmath94    from the expressions ( [ eq10a ] ) and ( [ eq10b ] ) , we see that the non - stationarity of the random function @xmath93 is characterized by the parameters @xmath86 , @xmath60 and @xmath95 defined at any location of the domain of interest .",
    "let @xmath96 be a @xmath97 vector of observations from a unique realization of the random function @xmath93 , associated to known locations @xmath98 .",
    "the goal is to use the data @xmath99 to infer the standard deviation function @xmath86 , the correlation function determined by @xmath60 and the mean function @xmath95 .",
    "next , we use them to predict the value of the random function @xmath93 at unsampled locations . from now on , without loss of generality , we assume that @xmath100 .",
    "the estimation of the parameters @xmath86 , @xmath60 and @xmath95 relies on the quasi - stationarity or local stationarity assumption which allows certain simplifications .",
    "specifically , we work with the following definition of local stationarity introduced by @xcite .      a random function @xmath88 will be locally stationary if it has an expectation @xmath101 and covariance @xmath102 such that :    1 .",
    "@xmath101 is a very regular function varying slowly in space at the scale of the available information ; more precisely , @xmath101 can be considered as constant in a neighborhood of @xmath47 ; 2 .   there is a function of three arguments @xmath103 such that @xmath104 and such that , for a given @xmath105 , @xmath103 is a very regular and slowly varying ( in the same sense as in 1 . ) function of the two arguments @xmath47 and @xmath59 .",
    "in other words , for locations @xmath47 and @xmath59 not too far from each other , @xmath103 only depends on @xmath105 , as is if the covariance @xmath106 was stationary .",
    "the intuitive idea behind this definition is that if a random function is locally stationary , then at any location @xmath107 there exists a neighborhood @xmath108 where the random function can be approximated by a stationary random function .",
    "thus , @xmath109 ; where @xmath110 is a stationary covariance function and the limit @xmath111 represents the radius of the quasi - stationarity neighborhood @xmath108 . in this way , the parameters are assumed to be very smooth functions which vary slowly over the domain .",
    "the expectation of the random function being approximately equal to a constant inside the quasi - stationarity neighborhood , the resulting local covariance structure at any location @xmath112 is written as follows : @xmath113    in more practical terms , we can define moving neighborhoods @xmath114 within which the expectation and the covariance can be considered stationary , and where the available information is sufficient to make the inference .",
    "the quasi - stationarity assumption is a compromise between the distances of homogeneity of the studied phenomenon and the density of the available information .",
    "indeed , it is always possible to reach the stationarity by reducin the size @xmath111 of neighborhoods .",
    "but most of these neighborhoods will contain almost no data ; therefore inference of parameters will not be possible in these neighborhoods .      locally , the non - stationary spatial dependence structure defined in is thus reduced to an anisotropic stationary one .",
    "the anisotropy function @xmath115 is parameterized using the spectral decomposition . by this way",
    ", the positive definiteness is guaranteed and the locally varying geometric anisotropy can be captured . precisely , at any location @xmath107 , @xmath116 , where @xmath117 is the diagonal matrix of eigenvalues and @xmath118 is the eigenvector matrix .",
    "then , we have    @xmath119 and @xmath120    doing so , the scale parameter of the isotropic stationary correlation function @xmath121 in the expression is set to one to avoid any overparameterization .",
    "at each point , the square roots of the eigenvalues control the local ranges and the eigenvector matrix specify the local orientations .",
    "thus , the anisotropy function @xmath115 is characterized by the functions @xmath122 , @xmath123 and @xmath124 .",
    "it is convenient to estimate the second order spatial structure through the variogram . under the local stationarity framework",
    ", we define a non - parametric kernel moment estimator of the stationary local variogram at a fixed location @xmath107 and lag @xmath125 , @xmath126 as follows : @xmath127}^2}{2\\sum_{v(\\mathbf{h})}k^{\\star}_{\\epsilon}(\\mathbf{x}_0,\\mathbf{s}_i)k^{\\star}_{\\epsilon}(\\mathbf{x}_0,\\mathbf{s}_j ) } , \\",
    "\\|\\mathbf{h}\\| \\leq b,\\ ] ] where the average is taken over @xmath128 , the set of all pairs of locations separated by vector @xmath105 ; @xmath129 are standardized weights ; @xmath130 is a non - negative , symmetric kernel on @xmath34 with bandwidth parameter @xmath131 . for irregularly spaced data there ,",
    "are generally not enough observations separated by exactly @xmath105 .",
    "then , @xmath132 is usually modified to @xmath133 , where @xmath134 is a tolerance region of @xmath2 surrounding @xmath105 .",
    "this moment estimator of the local variogram at any location @xmath107 is a kernel weighted local average of squared differences of the regionalized variable .",
    "the kernel function is used to smoothly downweight the squared differences ( for each lag interval ) according to the distance of these paired values from a target location .",
    "we assign to each data pair a weight proportional to the product of the individual weights .",
    "observation pairs near to the target location @xmath112 have more influence on the local variogram estimator than those which are distant .    note that when @xmath135 and @xmath136 ; where @xmath137 is the diameter of the domain of interest @xmath1 , we obtain the classical matheron moment estimator for a global stationary structure @xcite . for @xmath138 and @xmath139 ,",
    "we get the moving window estimator @xcite .    to calculate the non - parametric kernel estimator , we opt for an isotropic stationary gaussian kernel : @xmath140 .",
    "the latter has a non - compact support and therefore considers all observations .",
    "thus , the local variogram estimator is not limited only to the local information , distant points are also considered .",
    "this avoids artifacts caused by the only use of observations close to the target location .",
    "it also reduces instability of the obtained local variogram at regions with low sampling density .",
    "furthermore , it provides a smooth parameter estimate and then is compatible with the quasi - stationarity assumption . concerning the size of the quasi - stationarity neighborhood @xmath111 , it is set with respect to the bandwidth @xmath141 .",
    "we take @xmath142 such that the standard deviation of the isotropic stationary gaussian kernel match the isotropic stationary uniform kernel ( with compact support ) .",
    "another possible choice for @xmath111 is to take a quantile of the isotropic stationary gaussian kernel ( e.g. @xmath143 ) or full width at half maximum ( @xmath144 ) .",
    "we want to estimate the vector of structural parameters @xmath145 and the mean parameter @xmath95 at any location of the domain of interest .",
    "the estimation of the parameters vector @xmath146 which characterizes the stationary local variogram @xmath147 at a fixed location @xmath112 are found via the following minimization problem : @xmath148 where @xmath149 is the product term by term ; @xmath150}^t$ ] ; @xmath151}^t$ ] ; @xmath152}^t$ ] , @xmath153}^{1/2}$ ] ; @xmath154 are given lag vectors ; @xmath155 is the vector of unknown parameters and @xmath156 is an open parameter space .    the estimation of the structural parameters @xmath157 and @xmath124 depends on the bandwidth parameter @xmath141 through the kernel function @xmath158 .",
    "the bandwidth parameter controls the range of validity of the stationary approximation and its selection is adresssed in section [ ssec3 ] .",
    "note that the estimation of the structural parameters does not require the prior estimation of the mean function @xmath95 .",
    "moreover , no model is specified for this latter .",
    "concerning the estimation of the parameter @xmath95 , the mean @xmath159 at a fixed location @xmath112 is approximatively equal to a constant inside the quasi - stationarity neighborhood @xmath114 .",
    "thus , using the estimate of the vector of structural parameters @xmath160 obtained in , @xmath159 is estimated explicitly by a local stationary kriging of the mean @xcite . specifically we have : @xmath161 where @xmath162 $ ] are the kriging weights given by : @xmath163 with @xmath164 , ( \\mathbf{s}_i , \\mathbf{s}_j ) \\in \\mathcal{v}_{\\mathbf{x}_0 } \\times \\mathcal{v}_{\\mathbf{x}_0}$ ] .      for the spatial prediction purpose , one needs to compute the parameters @xmath86 , @xmath60 and @xmath95 at prediction and observation locations . in practice",
    ", it is unnecessary to solve the minization problem at each target location .",
    "indeed , doing so is computationally intensive and redundant for close locations , since these estimates are highly correlated . to reduce the computational burden ,",
    "the proposed idea consists in obtainning the parameter estimates only at some reduced set of @xmath165 representative points referred to as anchor points defined over the domain .",
    "then , using the estimates obtained at anchor points , a kernel smoothing method is used to make available estimates at any location of interest . since the parameters @xmath166 and @xmath95 are supposed to vary slowly in space ( quasi - stationarity )",
    ", the nadaraya - watson kernel estimator seems appropriate , in addition to being relatively simple .",
    "however , other smoothers can be used as well ( local polynomials , splines ,  ) .",
    "the nadaraya - watson kernel estimator @xcite of @xmath167 at any location @xmath168 is given by : @xmath169 where @xmath170 is a kernel on @xmath2 ; @xmath171 is a smoothing parameter ; @xmath172 are the raw estimates of parameter @xmath167 at anchor points @xmath173 .",
    "we similarly define kernel smoothing estimator @xmath174 , @xmath175 and @xmath176 at any location @xmath168 . for the specific case of the orientation parameter @xmath124 , the kernel estimator at any location @xmath168",
    "is given through the minimization of the following criteria : @xmath177 where @xmath178 are the raw estimates of parameter @xmath124 at anchor points @xmath173 ; @xmath179 is the @xmath25-dimensional sphere of unit radius its centre at the origin ; @xmath180 is a distance between two orientations . for @xmath100",
    ", we can take the @xmath181 .    since",
    ", the parameters @xmath86 , @xmath60 and @xmath95 are assumed to vary slowly and regularly across the domain of interest ( local stationarity ) , we choose @xmath170 as an isotropic stationary gaussian kernel .",
    "the selection of its smoothing parameter @xmath182 is discussed in section [ ssec3 ] .      in the proposed method",
    ", a crucial point is the determination of the bandwidth parameter @xmath141 used in the computation of the local variogram non - parametric kernel estimator defined in .",
    "indeed , the size of the local stationarity neighborhood is expressed in terms of the bandwidth parameter .",
    "we are also interest in the choice of the bandwidth used to smooth the parameter estimates .",
    "concerning the bandwidth parameter @xmath141 , in some applications it may be appropriate to choose it subjectively , but in general , it is desirable to have available methods for choosing it automatically from the data . the data - driven method used to select the bandwidth @xmath141 consists of leaving out one data location and using a form of cross - validation . because the estimation of the spatial dependence structure is rarely a goal per se but an intermediate step before kriging , we want to choose the bandwidth that gives the best cross - validation mean square error ( mse ) .",
    "more explicitly , we minimize with respect to @xmath141 the leave - one - out cross - validation score @xcite : @xmath183 where @xmath184 denotes the spatial predictor computed at location @xmath185 using all observations except @xmath186 . the prediction method is described in section [ ssec4 ] .",
    "the choice of the smoothing bandwidth @xmath182 associated to the parameter @xmath86 is done using the following cross - validation criteria @xcite : @xmath187 where @xmath188 are respectively the raw and smoothed estimates of the parameter @xmath86 at anchor points @xmath189 .",
    "the cross - validation score function is minimized over a grid of smoothing bandwidths to choose the optimal value .",
    "theoretically , smoothing bandwidths associated to each local parameter can be different .",
    "our numerical examples indicate that choosing the same smoothing bandwidth for all local parameters in order to reduce the computational burden , makes little difference in terms of prediction performance .",
    "this remark was already highlighted by @xcite .",
    "the main purposes of modelling and estimating the spatial dependence structure is to spatially interpolate data and perform conditional simulations .",
    "the expected benefit using the closed - form non - stationary covariance model is to obtain spatial predictions and variance estimation errors more realistic than those based on a inadequate stationary covariance . in this section ,",
    "a description of kriging and conditional simulations based on the non - stationary model is presented .",
    "let @xmath190 the non - stationary covariance function of the random function @xmath93 and @xmath95 its mean .",
    "given the vector of observtaions @xmath191 at @xmath192 fixed locations @xmath193 , the point predictor for the unknown value of @xmath93 at unsampled location @xmath194 is given by the optimal linear predictor : @xmath195    the kriging weight vector @xmath196 $ ] and the corresponding kriging variance @xmath197 are given by : @xmath198 where @xmath199 $ ] ; @xmath200}$ ] .      despite its optimality , the estimator obtained by kriging smoothes reality .",
    "thus , the spatial texture of the reality ( captured by the covariance or variogram ) can not be reproduced from data points only . however , in some situations , it is more important to reproduce the spatial variability than obtain the best accuracy .",
    "we want to have a realization which has the same degree of variability than the actual phenomenon and coincides with observations at data points . to do this",
    ", we use conditional simulations .    here",
    "we assume that @xmath93 is a gaussian random function , with mean @xmath95 and non - stationary covariance structure @xmath106 .",
    "we want to simulate at a large number of locations a gaussian random function with same mean and covariance , and ensure that the realization honors the observed values @xmath201 .",
    "this can be accomplished from an unconditional simulation of the random function @xmath93 as follows @xcite :    1 .   realize a unconditional simulation @xmath202 of the random function @xmath93 ; 2",
    ".   carried out a simple kriging of @xmath203 from its values taken at the data points @xmath204 , using @xmath95 and @xmath106 ; 3 .",
    "add the unconditional simulation and the result of kriging .",
    "we have @xmath205 , where @xmath3 is a gaussian random function with zero expectation , unit variance and non - stationary correlation function @xmath87 .",
    "thus , to simulate the gaussian random function @xmath93 ( step 1 of the previous algorithm ) , we need to known how we can simulate @xmath3 .",
    "simulation of the gaussian random function @xmath3 can be carried out using a propagative version of the gibbs sampler proposed by @xcite .",
    "this algorithm allows to simulate a gaussian vector at a large number of locations ( comparatively to the existing classical algorithms such as cholesky method or gibbs sampler ) without relying on a markov assumption ( it does not need to have a sparse precision matrix ) .",
    "the algorithm proposed in @xcite requires neither the inversion nor the factorization of a covariance matrix .",
    "note that simulation methods such as spectral method or turning bands method are not adapted to the non - stationary case @xcite . the representation that underlies these methods relies on the stationarity assumption .",
    "formally , the algorithm proposed by @xcite is outlined below :    let @xmath206 be a standardized gaussian vector , with covariance matrix @xmath207 .",
    "the underlying idea is that instead of simulating the vector @xmath208 , we can simulate the vector @xmath209 .",
    "this latter is a gaussian vector with covariance matrix @xmath210 . noting that the inverse of @xmath210 is precisely @xmath211 , the gibbs sampler is applied to @xmath212 and @xmath208 is updated accordingly .",
    "this gives the following algorithm :    1 .",
    "set @xmath213 ; 2 .",
    "generate @xmath214 ; 3 .   generate @xmath215 and take @xmath216 for each @xmath217 ; 4 .",
    "take @xmath218 and go to 2 .",
    "thus , at each step of the algorithm , a gaussian value is assigned randomly to a pivot , and then spread to the other components .",
    "in this section , we illustrate the advantages of our proposed approach and its potential on two datasets : a soil data and a rainfall data .",
    "a comparison scheme of kriging under stationary and non - stationary models is carried out through a validation sample .",
    "next , we compare prediction and prediction standard deviation maps on a fine grid . the aim is to compare the behaviour of the models in terms of spatial interpolation and associated uncertainty .",
    "we now study a dataset coming from a soil gamma radiometric potassium concentration ( in shots per second , cps ) survey in the region of the hunter valley , nsw , australia .",
    "this data set was used by @xcite to illustrate their approach .",
    "we have a training data ( 537 observations ) which serves to calibrate the model and a validation data ( 1000 observations ) which serves only to assess the prediction performances .",
    "raw estimates of parameters @xmath95 , @xmath219 and @xmath60 at anchor points are shown respectively on figures [ fig1b ] , [ fig1c ] and [ fig1d ] .",
    "they are based on the non - stationary exponential covariance function ( example [ ex1 ] ) . concerning the estimated anisotropy function @xmath220 at anchor points ,",
    "it is represented by ellipses as shown in figure [ fig1d ] .",
    "indeed , covariance ( positive definite ) matrices have an appealing geometrical interpretation : they can be uniquely identified with an ellipsoid . based on these estimates , non - stationarity in the data",
    "is quite visible .",
    "especially , from figure [ fig1d ] where we can clearly see the spatially varying azimuth .",
    "such directional effects are also quite apparent on data ( figure [ fig1a ] ) .",
    "note that the stationary approach has not detected a global geometric anisotropy .",
    "0.35   at anchor points ; ( c ) estimated variance function @xmath221 at anchor points ; ( d ) estimated anisotropy function @xmath220 at anchor points where the ellipses were scaled to ease vizualisation .",
    "( potassium concentration data)[fig1],title=\"fig:\",scaledwidth=100.0% ]    0.35   at anchor points ; ( c ) estimated variance function @xmath221 at anchor points ; ( d ) estimated anisotropy function @xmath220 at anchor points where the ellipses were scaled to ease vizualisation .",
    "( potassium concentration data)[fig1],title=\"fig:\",scaledwidth=100.0% ]    0.35   at anchor points ; ( c ) estimated variance function @xmath221 at anchor points ; ( d ) estimated anisotropy function @xmath220 at anchor points where the ellipses were scaled to ease vizualisation .",
    "( potassium concentration data)[fig1],title=\"fig:\",scaledwidth=100.0% ]    0.35   at anchor points ; ( c ) estimated variance function @xmath221 at anchor points ; ( d ) estimated anisotropy function @xmath220 at anchor points where the ellipses were scaled to ease vizualisation .",
    "( potassium concentration data)[fig1],title=\"fig:\",scaledwidth=100.0% ]    following the hyper - parameters selection procedure presented in section [ ssec3 ] , the bandwidth associated with non - parametric gaussian kernel estimator of the local variogram is @xmath222 m. figure [ fig2 ] shows the maps of smoothed parameters over the whole domain of observations : mean , variance , anisotropy ratio and azimuth .",
    "the optimal smoothing bandwidth associated to the gaussian kernel smoothing corresponds to @xmath223 m , following the selection procedure described in section [ ssec3 ] .",
    "0.35     0.35     0.35     0.35     a visualization of the covariance at certain points for estimated stationary and non - stationary models is presented in figure [ fig3 ] .",
    "we can see how the non - stationary spatial dependence structure changes the shape from one place to another as compared to the stationary one .",
    "the stationary model is a nested isotropic model ( nugget effect , exponential and spherical ) while the non - stationary model corresponds to the non - stationary exponential covariance function ( example [ ex1 ] ) .",
    "the kriged values and the kriging standard deviations for the stationary and non - stationary models are shown in figure [ fig4 ] .",
    "the overall look of the predicted values and prediction standard deviations associated with each model differ notably . in particular",
    ", the proposed method takes into account certain local characteristics of the regionalization that the stationary approach is unable to retrieve .",
    "this example shows the ability of our non - stationary approach to manage data with locally varying anisotropy .",
    "figure [ fig5 ] shows some conditional simulations in the gaussian framework , based on the estimated non - stationary model .    to assess the predictive performances of our approach ,",
    "the regionalized variable is predicted at a hold - out sample ( 1000 points ) .",
    "table [ tab1 ] presents the summary statistics for the external validation results using the classical stationary approach and the new proposed one .",
    "some well - known discrepancy measures are used , namely the mean absolute error ( mae ) , the root mean square error ( rmse ) , the normalized mean square error ( nmse ) , the logarithmic score ( logs ) and the continued rank probability score ( crps ) . for rmse , logs and crps , the smaller the better",
    "; for mae , the nearer to zero the better ; for nmse the nearer to one the better . table [ tab1 ] shows that the proposed approach outperforms the stationary one with respect to all the measures",
    ". the cost of non - using the non - stationary approach in this case can be substantial : in average the prediction at validation locations is about 22% better for the non - stationary model than for the stationary model , in terms of rmse .",
    ".external validation on a set of 1000 locations .",
    "( potassium concentration data ) [ cols=\"<,^,^\",options=\"header \" , ]",
    "the proposed convolution approach provides in terms of modelling a new model for second order non - stationary random functions .",
    "this new model generalizes the classical convolution model and provides explicit and flexible classes of non - stationary covariance functions known from the literature .",
    "moreover , a statistical methodology for estimating these latter is developed .",
    "the estimation method offers an integrated treatment of all aspects of non - stationarity ( mean , variance , spatial continuity ) in the modelling process .",
    "the estimation procedure relies on the mild hypothesis of quasi - stationarity and does not impose any distributional assumptions except the existence of the first and second moment . furthermore , no matrix inversions or determinants are required , and hence the inference is practicable even for large datasets .",
    "the proposed method provides an exploratory analysis tool for the non - stationarity .",
    "indeed , mapping of the parameter values ( mean , variance , azimuth ) by location allows to exhibit or describe the non - stationarity .",
    "a plot of variance versus mean allows to identify the common relationships between the mean and variance which is known as proportional effect @xcite .",
    "the performance of our proposed method has been demonstrated on two real datasets : soil and rainfall data .",
    "the two applications have revealed an increased prediction accuracy when compared to the standard stationary method , and demonstrated the ability to extract the underlying non - stationarity from a single realization .",
    "a comparison of predictions and prediction standard deviations maps indicates that our non - stationary method captures some varying spatial features ( such as locally varying anisotropy ) in the data that can be not present detected with the stationary method , the resulting outcome appears much more realistic . beyond the spatial predictions ,",
    "we also show how conditional simulations can be carried out in this non - stationary framework .    in the proposed convolution method ,",
    "the estimation relies on the local variogram non - parametric kernel estimator .",
    "to better adapt to the variable sampling density in the domain of observations , it would be interesting to work with a non - parametric locally adaptive kernel estimator .",
    "the idea is to increase the bandwidth in low sample density areas and to narrow it in highly sampled areas .",
    "the local stationarity assumption is the basis of the proposed methodology , then it works well for smoothly varying non - stationarity",
    ". however it can be difficult to apply on sparse data or data that present rapid or abrupt spatial structure variations . in these cases",
    ", it may be advisable to proceed under a stationary framework",
    ". it would be interesting to extend the proposed method for inclusion of covariates .",
    "this can be achieved by setting the variance and anisotropy functions for covariates .",
    "this can be done by following the work of @xcite and @xcite . to date",
    ", the non - stationary modelling convolution approach does not provide closed - form non - stationary covariance functions with compact support , this remains an open problem .",
    "indeed , the use of such covariances considerably reduce the computational burden of kriging when dealing with large data sets .",
    "the authors would like to thank dr budiman minasny at the faculty of agriculture & environment at the university of sydney in australia , for providing the first data used in this paper .",
    "the integral @xmath228 for all @xmath15 exists and is finite , because the product of two square integrable functions is integrable .",
    "furthermore , it is easy to show that for all @xmath15 , @xmath229 is positive definite on @xmath2 . since @xmath230 , @xmath229 is integrable on @xmath11 with respect to the positive measure @xmath35 for every pair @xmath231 . then , @xmath232 is a valid covariance function on @xmath34 , according to @xcite ."
  ],
  "abstract_text": [
    "<S> standard geostatistical models assume second order stationarity of the underlying random function . in some instances , there is little reason to expect the spatial dependence structure to be stationary over the whole region of interest . in this paper </S>",
    "<S> , we introduce a new model for second order non - stationary random functions as a convolution of an orthogonal random measure with a spatially varying random weighting function . </S>",
    "<S> this new model is a generalization of the common convolution model where a non - random weighting function is used . </S>",
    "<S> the resulting class of non - stationary covariance functions is very general , flexible and allows to retrieve classes of closed - form non - stationary covariance functions known from the literature , for a suitable choices of the random weighting functions family . under the framework of a single realization and local stationarity </S>",
    "<S> , we develop parameter inference procedure of these explicit classes of non - stationary covariance functions . from a local variogram </S>",
    "<S> non - parametric kernel estimator , a weighted local least - squares approach in combination with kernel smoothing method is developed to estimate the parameters . </S>",
    "<S> performances are assessed on two real datasets : soil and rainfall data . </S>",
    "<S> it is shown in particular that the proposed approach outperforms the stationary one , according to several criteria . beyond the spatial predictions , </S>",
    "<S> we also show how conditional simulations can be carried out in this non - stationary framework .    </S>",
    "<S> non - stationarity , convolution , covariance , kernel , kriging , simulation . </S>"
  ]
}