{
  "article_text": [
    "suppose we are given a set of points @xmath2 , and some non - negative weights @xmath3 to these points .",
    "consider the problem @xmath4 where @xmath5 is the euclidean norm and @xmath6 is closed and convex .",
    "this is a convex optimization problem .",
    "the ( global ) minimizer of when @xmath7 is the entire space is called the _",
    "euclidean median _",
    "( also referred to as the geometric median ) @xcite .",
    "the euclidean median has classically been used as a robust estimator of centrality for multivariate data @xcite .",
    "this multivariate generalization of the scalar median also comes up in transport engineering , where is used to model the problem of locating a facility that minimizes the cost of transportation @xcite .",
    "more recently , it was demonstrated in @xcite that the euclidean median and its non - convex extensions can be used to perform robust patch - based regression for image denoising by generalizing the poplar non - local means algorithm @xcite .",
    "note that the minimizer of is simply the projection of the euclidean median onto @xmath7 .",
    "unfortunately , there is no simple closed - form expression for the euclidean median , even when it is unique @xcite .",
    "nevertheless , the euclidean median can be computed using numerical methods such as the iteratively reweighted least squares ( irls ) .",
    "one such iterative method is the so - called weiszfeld algorithm @xcite .",
    "this particular algorithm , however , is known to be prone to convergence problems @xcite .",
    "geometric optimization - based algorithms have also be proposed for approximating the euclidean median @xcite .",
    "more recently , motivated by the use of irls for sparse signal processing and @xmath8 minimization @xcite , an irls - based algorithm for approximating the euclidean median was proposed in @xcite .",
    "more precisely , here the authors consider a smooth convex surrogate of , namely , @xmath9 and describe an iterative method for optimizing .",
    "the convergence properties of this iterative algorithm was later studied in @xcite . in the last few years , there has been a lot of renewed interest in the use of variable splitting , the method of multipliers , and the alternating direction method of multipliers ( admm ) @xcite for various non - smooth optimization problems in signal processing @xcite .",
    "motivated by this line of work , we introduce a novel algorithm for approximating the solution of using variable splitting and the augmented lagrangian in section [ sec : admm ] .",
    "an important technical distinction of the present approach is that , instead of working with the smooth surrogate , we directly address the original non - smooth objective in .",
    "the attractive feature here is that the subproblems involved in the admm - based optimization of the augmented lagrangian can be resolved using simple closed - form projections . in section",
    "[ sec : results ] , the proposed algorithm is used for robust patch - based denoising of images following the proposal in @xcite . in particular , we incorporate the information that the pixels of the original ( clean ) patches take values in a given dynamic range ( for example , in [ 0,255 ] for grayscale images ) using an appropriately defined @xmath7 .",
    "numerical experiments show that the iterates of the proposed algorithm converge much more rapidly than the irls iterates for the denoising method in question",
    ". moreover , the reconstruction quality of the denoised image obtained after few admm iterations is often substantially better than the irls counterpart .",
    "since we will primarily work with in this paper , we will overload terminology and refer to the minimizer of as the euclidean median . the main idea behind",
    "the admm algorithm is to decompose the objective in into a sum of independent objectives , which can then be optimized separately .",
    "this is precisely achieved using variable splitting @xcite . in particular , note that we can equivalently formulate as @xmath10 where @xmath11 and @xmath12 is the indicator function of @xmath7 @xcite . in other words ,",
    "we artificially introduce one local variable for each term of the objective , and a common global variable that forces the local variables to be equal @xcite .",
    "the advantage of this decomposition will be evident shortly .",
    "note that in the process of decomposing the objective , we have introduced additional constraints . while one could potentially use any of the existing constrained optimization methods to address",
    ", we will adopt the method of augmented lagrangian which ( among other things ) is particularly tailored to the separable structure of the objective .",
    "the augmented lagrangian for can be written as @xmath13 where @xmath14 are the lagrange multipliers corresponding to the equality constraints in , and @xmath15 is a penalty parameter @xcite .",
    "we next use the machinery of generalized admm to optimize @xmath16 jointly with respect to the variables and the lagrange multipliers .",
    "the generalized admm algorithm proceeds as follows @xcite : in each iteration , we sequentially minimize @xmath17 with respect to the variables @xmath18 in a gauss - seidel fashion ( keeping the remaining variables fixed ) , and then we update the lagrange multipliers @xmath14 using a fixed dual - ascent rule . in particular , note that the minimization over @xmath19 at the @xmath20-th iteration is given by @xmath21 where @xmath22 denotes the variable @xmath23 at the end of the @xmath24-th iteration .",
    "a similar notation is used to denote the lagrange multipliers at the end of the @xmath24-th iteration .",
    "next , by combining the quadratic and linear terms and discarding terms that do not depend on @xmath23 , we can express the partial minimization over @xmath23 as @xmath25 where @xmath26 therefore , @xmath27 where @xmath28 denotes the projection of @xmath1 onto the convex set @xmath7 .",
    "note that we have used the most recent @xmath19 variables in .",
    "finally , we update the lagrange multipliers using the following standard rule : @xmath29    we loop over , and until some convergence criteria is met , or up to a fixed number of iterations . for a detailed exposition on the augmented lagrangian , the method of multipliers , and the admm , we refer the interested reader to @xcite .",
    "we now focus on the update in . by combining the linear and quadratic terms ( and discarding terms that do not depend on @xmath1 )",
    ", we can express in the following general form : @xmath30 where @xmath31 note that the objective in is closed , proper , and strongly convex , and hence @xmath32 exists and is unique .",
    "in fact , we immediately recognize @xmath32 to be the _",
    "proximal map _ of @xmath33 evaluated at @xmath34 @xcite .",
    "for any @xmath35 $ ] that is closed , proper , and convex , the proximal map @xmath36 is defined to be @xmath37    as per this definition , @xmath38 .",
    "note that involves the @xmath39 norm , which unlike the @xmath8 norm is not separable .",
    "a coordinate - wise minimization of is thus not possible ( as is the case for the @xmath8 norm leading to the well - known shrinkage function ) .",
    "however , we have the following result on proximal maps @xcite .",
    "let @xmath35 $ ] be closed , proper , and convex . then we can decompose any @xmath40 as @xmath41 where @xmath42 $ ] is the convex conjugate of @xmath33 , @xmath43    the usefulness of is that both @xmath44 and and its proximal map can be obtained in closed - form . indeed , by change - of - variables , @xmath45 now , if @xmath46 , then by cauchy - schwarz , @xmath47 .",
    "in this case , the maximum over @xmath1 is @xmath48 . on the other hand , if @xmath49 , then setting @xmath50 , we have @xmath51 which can be made arbitrarily large by letting @xmath52 .",
    "thus , @xmath53 where @xmath54 is the indicator function of the ball @xmath55 with centre @xmath48 and radius @xmath56 , @xmath57 having obtained , we have from , @xmath58 which is precisely the projection of @xmath59 onto @xmath55 .",
    "this is explicitly given by @xmath60 combining with , we have @xmath61 it is reassuring to note that @xmath62 equals @xmath63 when @xmath64 , and equals @xmath34 when @xmath65 .",
    "in the context of the admm update , note that @xmath66 the overall admm algorithm ( called ` em - admm ` ) for computing the euclidean median is summarized in algorithm [ algo ] .",
    "* initialize * : @xmath67    we next demonstrate how ` em - admm ` can be used for robust patch - based denoising of images .",
    "we also investigate its convergence behavior in relation to the irls algorithm in @xcite .",
    "in the last ten years or so , some very effective patch - based algorithms for image denoising have been proposed @xcite .",
    "one of the outstanding proposals in this area is the non - local means ( nlm ) algorithm @xcite .",
    "several improvements and adaptations of nlm have been proposed since its inception , some of which currently offer state - of - the - art denoising results @xcite .",
    "recently , it was demonstrated in @xcite that the denoising performance of nlm can be further improved by introducing the robust euclidean median into the nlm framework .",
    "we consider the denoising setup where we are given a noisy image @xmath68 ( @xmath69 is some linear ordering of the pixels in the image ) that is derived from some clean image @xmath70 via @xmath71 where @xmath72 is iid @xmath73 .",
    "the denoising problem is one of estimating the unknown @xmath74 from the noisy measurement @xmath75 .    , and for the irls , we set @xmath76 . in either case , we use the noisy patch to seed the iterations ( please see main text for further details ) . ]    for any pixel @xmath77 , let patch @xmath78 denote the restriction of @xmath75 to a square window centered at @xmath79 . letting @xmath80 be the length of this window , this associates every pixel @xmath79 with a patch - vector @xmath78 of length @xmath81 . for @xmath82 , define the weights @xmath83 , where @xmath84 is a smoothing parameter . for every @xmath77 , we consider the following optimization problem @xmath85 here @xmath86 denotes the neighborhood pixels of @xmath79 , namely , those pixels that are contained in a window of size @xmath87 centred at @xmath79 .",
    "the convex set @xmath7 is defined to be the collection of patches whose pixel intensities are in the dynamic range @xmath88 $ ] ; e.g. , @xmath89 and @xmath90 for a grayscale image .",
    "the projection onto @xmath7 can be computed coordinate - wise at negligible cost . in particular , for @xmath91 , @xmath92 = \\begin{cases } \\x[i ] & \\text{if } \\",
    "l \\leq \\x[i ]   \\leq u , \\\\",
    "l        & \\text{if } \\",
    "\\x[i ]   < l , \\text { and } \\\\ u       & \\text{if } \\",
    "\\x[i ]   > u. \\end{cases}\\ ] ]    notice that is exactly the optimization in .",
    "in other words , we denoise each patch by taking the euclidean median of its neighbouring noisy patches . the center pixel of the denoised patch is taken to be the denoised pixel .",
    "the overall denoising scheme is called the non - local euclidean medians ( in short , nlem ) @xcite .",
    "l c rrrrr    image & method & +    & ( a ) & * 34.22 & 29.78 & 25.20 & 23.37 & 22.35 + _ house _ & ( b ) & 32.66 & 29.01 & 26.68 & 24.78 & 23.46 + & ( c ) & 34.13 & * 30.77 & * 27.04 & * 24.87 & * 23.47 + * * * * *    & ( a ) & 33.24 & 29.31 & 26.17 & 24.54 & 23.64 + _ lena _ & ( b ) & 32.54 & 29.48 & 27.31 & 25.38 & 24.37 + & ( c ) & * 33.57 & * 30.38 & * 27.59 & * 25.42 & * 24.38 + * * * * *    & ( a ) & * 32.32 & 27.66 & 23.11 & 21.03 & 19.99 + _ peppers _ & ( b ) & 30.95 & 26.95 & 24.31 & 22.84 & 21.24 + & ( c ) & 32.14 & * 28.54 & * 25.06 & * 22.98 & * 21.26 + * * * * *    & ( a ) & 32.37 & 27.39 & 23.53 & 22.05 & 21.34",
    "+ _ barbara _ & ( b ) & 30.77 & 27.28 & 25.55 & 23.77 & 22.61 + & ( c ) & * 32.43 & * 28.84 & * 25.67 & * 23.77 & * 22.62 + * * * * *    [ tablepsnr ]    the denoising experiments were performed on several grayscale test images .",
    "we used the standard nlm parameters for all the experiments @xcite : @xmath93 , and @xmath94 .",
    "the proposed ` em - admm ` algorithm is used for computing the solution of . notice that the main computation here is that of determining the distances in .",
    "since we require a total of @xmath95 such distance evaluations in @xmath81 dimensions , the complexity is @xmath96 per iteration per pixel .",
    "incidentally , this is also the complexity of the irls algorithm in @xcite .",
    "for all the denoising experiments , we initialized the lagrange multipliers in ` em - admm ` to zero vectors .",
    "we considered two possible initializations for @xmath23 , namely , the noisy patch and the patch obtained using nlm .",
    "exhaustive experiments showed that the best convergence results are obtained for @xmath97 .",
    "for example , figure [ psnrevolution ] shows the evolution of the peak - signal - to - noise ratio ( psnr ) over the first ten iterations obtained using the admm algorithm . also show in this figure is the evolution of the psnr for the irls algorithm from @xcite . in either case",
    ", we used the noisy patch as the initialization .",
    "notice that the increase in psnr is much more rapid with admm compared to irls .",
    "in fact , in about @xmath98 iterations , the optimal psnr is attained with admm .",
    "notice that at @xmath99 , the psnr from irls grows much more slowly compared to admm .    .",
    "the inset shows the position of the particular pixel where the patch regression is performed .",
    "the objective functions shown in the plot correspond to and that are respectively optimized by admm and irls ( note that the objectives are very close since we use @xmath100 in ) .",
    "the noisy image patch was used to initialize both algorithms . for ` em - admm ` , the objective function converges to the optimal value ( up to to three decimal places ) in just @xmath101 iterations .",
    "the convergence is relatively slow for irls ( accuracy up to three decimals obtained after @xmath102 iterations ) . ]",
    "the above observation is also supported by the convergence result shown in figure [ comparisonobj ] for the _ house _ image .",
    "notice that admm converges in just @xmath101 iterations , while irls takes about @xmath102 iterations to attain the same accuracy ( we recall that the cost per iteration is comparable ) .",
    "in general , we observed that the within @xmath101 iterations the admm result converges to an accuracy that is sufficient for the present denoising application . at higher noise levels ( @xmath103 ) , about @xmath98 iterations are required .",
    "this applies to all the test images that we have experimented with .",
    "the denoising results for some test images obtained using nlm and nlem are provided in table [ tablepsnr ] . for nlem",
    ", we used both the admm and irls solvers . following the previous observations , we used @xmath98 iterations for both solvers . for @xmath104 , we used the noisy patch to initialize the iterations , and for @xmath105 we used the nlm patch .",
    "this initialization scheme was found to give the best psnr results . at large noise levels",
    ", there is not much difference after @xmath98 iterations .",
    "however , at low noise levels , the psnr obtained using admm is often substantially larger than that obtained using irls after @xmath98 iterations .",
    "the reason for this is that irls converges really slow in such situations .",
    "this is evident from the psnr plots in figure [ psnrevolution ] at @xmath106 .",
    "for a visual comparison , a particular denoising result for the _ barbara _ image obtained using nlm and nlem ( using the admm solver ) is shown in figure [ comparison1 ] .",
    "roughly speaking , at the cost of just four nlms , we are able to improve the psnr by more than @xmath101 db . notice that the nlem result is much more sharp compared to the nlm counterpart .",
    "we proposed a new algorithm for computing the ( constrained ) euclidean median using variable splitting and the augmented lagrangian .",
    "in particular , we demonstrated how the admm - based optimization of the augmented lagrangian can be resolved using simple closed - form projections .",
    "the proposed algorithm was used for image denoising using the non - local euclidean medians , and was generally found to exhibit faster convergence compared to the irls algorithm .",
    "one interesting direction that we did not pursue is to adapt the penalty @xmath107 at each iteration , which is known to speed up the convergence @xcite .",
    "yet another interesting direction is the use of accelerated admm @xcite to further speed up the convergence .",
    "k. n. chaudhury and a. singer , `` non - local patch regression : robust image denoising in patch space , '' _ proc .",
    "ieee international conference on acoustics , speech and signal processing _ ,",
    "pp.1345 - 1349 , 2013 .",
    "i. daubechies , r. devore , m. fornasier , and c. s. gunturk `` iteratively reweighted least squares minimization for sparse recovery , '' _ communications on pure and applied mathematics _ ,",
    "63 , pp . 1 - 38 , 2009 .",
    "j. eckstein and d. p. bertsekas , `` on the douglas - rachford splitting method and the proximal point algorithm for maximal monotone operators , '' _ mathematical programming _ ,",
    "55 , no . 1 - 3 , pp .",
    "293 - 318 , 1992 .",
    "m. v. afonso , j. m. bioucas - dias , and m. a. figueiredo , `` fast image recovery using variable splitting and constrained optimization , '' _ ieee transactions on image processing _ , vol .",
    "9 , pp . 2345 - 2356 , 2010 .",
    "m. v. afonso , j. m. bioucas - dias , and m. a. figueiredo , `` an augmented lagrangian approach to the constrained optimization formulation of imaging inverse problems , '' _ ieee transactions on image processing _ , vol .",
    "681 - 695 , 2011 .",
    "s. boyd , n. parikh , e. chu , b. peleato , and j. eckstein , `` distributed optimization and statistical learning via the alternating direction method of multipliers , '' _ foundations and trends in machine learning _ ,",
    "1 , pp . 1 - 122 , 2011 .",
    "m. aharon , m. elad , a. bruckstein , `` k - svd : an algorithm for designing overcomplete dictionaries for sparse representation , '' _ ieee transactions on image processing _ , vol",
    ". 54 , no .",
    "4311 - 4322 , 2006 ."
  ],
  "abstract_text": [
    "<S> the euclidean median ( em ) of a set of points @xmath0 in an euclidean space is the point @xmath1 minimizing the ( weighted ) sum of the euclidean distances of @xmath1 to the points in @xmath0 . while there exits no closed - form expression for the em , it can nevertheless be computed using iterative methods such as the weiszfeld algorithm . </S>",
    "<S> the em has classically been used as a robust estimator of centrality for multivariate data . </S>",
    "<S> it was recently demonstrated that the em can be used to perform robust patch - based denoising of images by generalizing the popular non - local means algorithm . in this paper </S>",
    "<S> , we propose a novel algorithm for computing the em ( and its box - constrained counterpart ) using variable splitting and the method of augmented lagrangian . </S>",
    "<S> the attractive feature of this approach is that the subproblems involved in the admm - based optimization of the augmented lagrangian can be resolved using simple closed - form projections . </S>",
    "<S> the proposed admm solver is used for robust patch - based image denoising and is shown to exhibit faster convergence compared to an existing solver .    </S>",
    "<S> image denoising , patch - based algorithm , robustness , euclidean median , variable splitting , augmented lagrangian , alternating direction method of multipliers ( admm ) , convergence . </S>"
  ]
}