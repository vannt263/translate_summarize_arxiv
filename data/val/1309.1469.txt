{
  "article_text": [
    "the next generation of large - scale radio interferometers , such as askap  @xcite , mwa  @xcite , paper  @xcite , and ska  @xcite , promise incredible scientific reward but also incredible data analysis challenges .",
    "the tremendous volume of data , high dynamic range , wide bandwidth , large amounts of radio interference , and significant foregrounds present serious instrumentation and analysis difficulties  @xcite .",
    "image deconvolution  the process of removing the effects of signal mode coupling due to the primary beam , noise mode coupling due to @xmath0 sampling , incomplete fourier mode sampling , and noise  is an important first step in scientific analysis from these instruments  @xcite .",
    "the ideal algorithm for performing image deconvolution suitable for these upcoming surveys would be : ( 1 ) robust to changes in the input signal and instrument configuration , ( 2 ) parametrized by as few tunable inputs as possible , ( 3 ) as automated as possible , ( 4 ) driven by the _ data _ rather than user - selected guesses as to the source signal , ( 5 ) as informative as possible given the difficulty of processing the data even a single time , ( 6 ) scalable to the extreme sizes of future data sets , ( 7 ) as fast as possible , and ( 8) able to easily incorporate modeling of foregrounds or other systematics .",
    "unfortunately , the most commonly used algorithm for interferometric image reconstruction , clean  @xcite , satisfies few  if any  of these criteria .",
    "originally developed to remove point source foregrounds from a smooth background source image , clean works by iteratively removing the effects of high - intensity point sources in the fourier - transformed @xmath0-plane .",
    "while the original algorithm excels in a limited number of cases , it is not appropriate for general reconstruction problems .",
    "modern implementations of clean that appear in standard radio astronomy packages ( e.g. , casa  @xcite ) incorporate several advanced features such as simultaneous deconvolution at multiple scales  @xcite and time - varying analysis  @xcite .    however , even these more advanced versions of clean require significant fine - tuning and supervision during the deconvolution process .",
    "users must select thresholds for deciding which pixels contain `` point sources '' and the amount by which to remove the point source effects in @xmath0-space .",
    "the optimal choices for these thresholds are not known in advance for a given observation .",
    "users may also select specific regions of the image to apply more or fewer cleaning iterations .",
    "clean has no final end state : users must decide when an image has been deconvolved `` enough '' without introducing unwanted artefacts .",
    "finally , clean gives no information on the uncertainties in the reconstruction .",
    "realizing the shortcomings of traditional and more sophisticated clean - based algorithms , methods based on a regularized likelihood , such as the maximum entropy method ( mem ;  @xcite ) generated significant interest .",
    "mem produces an image estimate which minimizes the difference between the estimate and the data given the level of noise and some chosen metric .",
    "while mem requires less fine - tuning and supervision than clean , the user must still choose the metric ( usually expressed as an entropy functional ) , and the optimal choice of the metric is not known in advance  @xcite .",
    "the final reconstructed image is thus only optimal in regards to that metric . similarly to clean",
    ", mem gives no uncertainty information and in general tends to underestimate the source image intensity  @xcite .    as  @xcite and  @xcite pointed out",
    ", optimal reconstruction techniques must be spatially adaptive and operate at multiple scales simultaneously .",
    "many authors have proposed relatively new alternative methods based on compressed sensing techniques @xcite , bayesian processes  @xcite , and separation of smooth and point - like components  @xcite .    in this work ,",
    "we present a general purpose , bayesian reconstruction algorithm to infer the source image from realistic interferometric radio data .",
    "bayesian analysis starts with building a generative probabilistic forward model of the data .",
    "given this model choice , the posterior probability density function ( the _ posterior distribution _ ) quantifies what is known about the source image once the data have been obtained  @xcite .",
    "the purpose of this paper is to demonstrate that a surprisingly simple choice of model for the source image , that of an _ isotropic gaussian process _ , performs very well in realistically simulated examples for a test suite of widely diverse images .",
    "the key to practical bayesian image analysis is to be able to navigate efficiently through the very high dimensional parameter space , since every pixel value is an independent parameter .",
    "for example , in this paper we will explore posterior distributions in @xmath2-dimensional parameter spaces .",
    "gibbs sampling is a powerful technique that has been used successfully for sky maps with more than @xmath3 pixels in the context of cosmic microwave background signal reconstruction and power spectrum estimation  @xcite .",
    "conceptually , gibbs sampling iterates between samples of the signal and its power spectrum in a way that respects the joint posterior distribution of signal and power spectrum given the image .",
    "this separation allows for significant speedups compared to grid based evaluations of the posterior : the algorithm scales as @xmath4 , where @xmath5 is the total number of pixels , in the ideal pregridded flat - sky limit discussed here .",
    "our assumptions for our mock observations allow us to pregrid the intensities before the iterative solution step . more general curved - sky analysis would necessarily be more expensive , either with gridding - regridding steps during the analysis in an aw - projection method or with the spherical harmonic transform operation in a full sky",
    "this is similar to the computational scalability of traditional clean .",
    "however , clean typically completes in order @xmath6 steps , whereas our method usually requires @xmath7 iterations . as we will see below",
    ", the primary computational cost in each iteration comes from solving a matrix - vector equation .",
    "fortunately , this is a common problem in computational science and there are many fast , scalable solutions available  @xcite .",
    "while the gibbs sampling framework itself is independent of prior ( see , for example ,  @xcite for an implementation based on fluxon models ) we choose an isotropic gaussian process prior .",
    "gaussian processes are surprisingly flexible in describing a variety of images  @xcite . because gibbs sampling can be understood as a non - linear generalization of the least - squares optimal signal reconstruction provided by the wiener filter ( see section  [ sec : method ] ) without requiring a choice of the signal covariance _ a priori _ ,",
    "successive samples are always constrained by the data in regions of high signal - to - noise . in regions of low signal - to - noise , the gaussian process is the least informative completion to a full probabilistic model . in this regime",
    "the method still maps out the signal likelihood taking into account all modeled signals and imperfections in the data at the two - point correlation level .",
    "in addition to the speed gains mentioned above , the method of gibbs sampling offers several advantages over traditional deconvolution techniques : ( 1 ) it explores the full posterior shape , giving _",
    "statistical information on the resulting image ; ( 2 ) it _ automatically _ takes into account signal mode coupling from the primary beam ; ( 3 ) the sampled representation produced by the method makes marginalization _ trivial _ ; ( 4 ) it provides optimal reconstruction ( i.e. , wiener filtering ) _ without _ assuming a signal covariance ; ( 5 ) since we have already specified the signal prior , the method has _ no _ tunable parameters and operates completely unsupervised ; and ( 6 ) it offers a _ sparse _ reconstruction technique with a full bayesian motivation .",
    "section  [ sec : sims ] below presents our mock observations and interferometer setup used to assess our new method .",
    "next , in section  [ sec : method ] we outline the method of gibbs sampling as applied to radio interferometers . in section  [ sec : comparison ]",
    "we compare our method to a proxy for traditional clean in terms of reconstructed image fidelity , residuals , and statistics such as rms error and residual signal - to - noise levels .",
    "finally , we conclude in section  [ sec : conclusion ] with a discussion of planned extensions and the potential role of this method in future observations .",
    "we model the visibility data @xmath8 obtained from an interferometric observation as @xmath9 where @xmath10 is a vector containing a discretization of the input sky , @xmath11 is a primary beam pattern , @xmath12 is a fourier transform operator that converts from pixel space to the @xmath0-plane , @xmath13 is an interferometer pattern in the @xmath0-plane , and @xmath14 is a gaussian realization of the noise .",
    "we discretize the signal @xmath10 , data @xmath8 , and noise @xmath14 with @xmath5 elements .",
    "we generate all input visibilities within a @xmath15  degree square patch discretized to @xmath16 pixels per side , similar to the approach of  @xcite and  @xcite .",
    "while this size of patch violates the strict flat - sky approximation , it allows us to explore the validity of our technique at higher resolutions and probe the range of scales accessible to realistic interferometers . because it is easier in interferometry to perform calculations in visibility space than in image space  @xcite",
    ", we do not establish an observation wavelength for these mock observations , since our results and conclusions are independent of wavelength .",
    "we model the primary beam pattern @xmath11 as a gaussian with peak value of unity and standard deviation @xmath17 deg . with these parameters",
    "the primary beam decreases to a value of @xmath18 halfway to the edge of the box .",
    "this allows us to include all fourier modes up to the nyquist frequency in our analysis and ensures that the periodic boundary conditions inherent in the fourier transform do not cause unwanted edge - effects .",
    "we prevent the primary beam from reaching values below @xmath19 .",
    "this value reflects a balance between faithfully representing the suppression of signals far from the point center ( so that fourier transforms have correct periodic boundaries ) and the need to preserve numerical stability in the conjugate - gradient algorithm utilized in the method below .",
    "we assemble the interferometer array in a simple way by randomly placing 12 antennas and selecting all baseline pairs within the @xmath0-plane .",
    "we then allow the assembly to rotate uniformly for 6 hours while observing the same sky patch at the north celestial pole .",
    "this choice of antenna arrangement and integration time roughly corresponds to existing instruments , such as an extended configuration of alma  @xcite or vla  @xcite , although our fiducial setup uses fewer elements to highlight the performance of our method in less - than - optimal observing regimes .",
    "the interferometer pattern is discretized to the same resolution as our input images ( @xmath20 pixels on a side ; described below ) .",
    "we construct the interferometer pattern @xmath13 by placing a value of one wherever a baseline length intersects a pixel during its rotation and zeros elsewhere .",
    "we show the resulting @xmath0-plane coverage in figure  [ fig : pattern ] .",
    "this configuration covers roughly @xmath21 of the @xmath0-plane , although the coverage varies significantly for each @xmath22-bin , where @xmath22 is the radius of a given annulus in the @xmath0-plane .",
    "some bins , especially at very low and very high @xmath22 , have zero coverage due to the lack of baselines at that distance .",
    "however , even if these bins had adequate coverage , we expect statistics here to be relatively poor due to the reduced number of modes in these regions .",
    "most bins have at least @xmath23 coverage and several bins have complete coverage .",
    "we determine the noise per pixel by summing the integration time spent in that pixel by all baselines .",
    "we do not adopt a noise model for a particular instrument ; rather , we set the noise variance to be @xmath24 where @xmath25 is the observation time in pixel @xmath26 .",
    "we then set an overall signal - to - noise ratio of @xmath27 by multiplying all noise variances by a constant value to maintain @xmath28 .",
    "this provides a scaling of the noise that would normally be caused by instrument effects such as the effective area of the apertures and the system temperature in a realistic observation .",
    "we use a gaussian realization of this noise variance to generate @xmath14 in equation ( [ eq : data ] ) .",
    "we then multiply this noise by the interferometer pattern @xmath13 to maintain consistency with the signal .",
    "figure  [ fig : noiseanddata ] shows a particular noise realization for one of our test images and the resulting data @xmath8 .",
    "radio interferometers are used to study a wide variety of interesting astrophysical and cosmological phenomena , such as supernova remnants  @xcite , molecular gas clouds  @xcite , cluster radio halos  @xcite , magnetic fields in dwarf galaxies  @xcite , the interstellar medium  @xcite , the galactic center  @xcite , and the cosmic microwave background  @xcite . to assess the ability of our method to cope with this variety of targets we select eight input images drawn from the casa  @xcite user guide , which we present in figure  [ fig : inputs ] .",
    "the test images represent a diverse variety of realistic  and a few unrealistic  imaging scenarios , such as a protoplanetary disk , a face - on spiral galaxy , a cluster , an agn jet and lobe , and the face of einstein .",
    "these images were provided in a mix of resolutions and dynamic ranges . to simplify our analysis ( but without loss of generality ) , we remapped all images to a uniform grid @xmath29 pixels on a side and renormalized all intensities to a peak of unity .",
    "some test images had artificial artefacts built - in , and the remapping procedure introduced some additional glitches in the image .",
    "we left these artefacts intact to test the ability of our isotropic gaussian process prior to recover highly anisotropic portions of the data .",
    "previous works have extensively discussed gibbs samples  ( e.g. , * ? ? ?",
    "* ; * ? ? ?",
    "* ) , so we only briefly introduce the relevant equations as applied to interferometric observations here .",
    "we begin with some initial guess of the angular power spectrum @xmath30 and progressively iterate samples from the conditional distributions @xmath31 where @xmath32 is the least squares estimate of the signal @xmath10 given the data @xmath8 ( i.e. , @xmath33 , where @xmath34 represents a full signal - to - data operator ) .",
    "the samples @xmath35 converge to samples from the joint distribution @xmath36 after a sufficient number of iterations .",
    "given an angular power spectrum sample @xmath37 , we generate a new signal sample by drawing from a multivariate gaussian with mean @xmath38 and variance @xmath39 . here",
    "@xmath40 and @xmath41 are the signal and noise covariance , respectively .",
    "we do this by solving the set of equations @xmath42 where we define the matrix operator @xmath43 as @xmath44 in the above equations @xmath45 is the primary beam transpose and @xmath46 is the inverse fourier transform .",
    "the first term in the right - hand side of the above equation provides the solution for the wiener - filtered map , while the second and third terms of eq .",
    "( [ eq : sky ] ) provide random fluctuations with the required variance .",
    "the vectors @xmath47 and @xmath48 are of length @xmath5 with elements drawn from a standard normal distribution . as an illustration ,",
    "figure  [ fig : iteration ] shows an example wiener - filtered map ( i.e. , from just solving the first term in the right - hand side ) and full signal sample @xmath49 at a single iteration for the _ einstein _ test case .",
    "we see that the fluctuation terms in equation  ( [ eq : sky ] ) fill in regions weakly constrained by the data with a guess that mimics the known portions of the signal given the level of noise .",
    "the signal covariance matrix @xmath40 is diagonal in the @xmath0-plane for isotropic signals ( which we assume as part of our gaussian process prior ) , so @xmath50 , where @xmath51 , with @xmath52 being the radial distance in the @xmath0-plane .",
    "here and throughout we assume the flat - sky approximation that makes this identity valid . by construction",
    ", gibbs sampling explores the exact posterior and therefore treats the couplings introduced by partial sky coverage optimally  @xcite .",
    "the algorithm `` knows '' about the couplings since they are contained in the data model ( eq .  [ eq : data ] ) which underlies the analysis .",
    "however , to a very good approximation",
    "the noise covariance matrix @xmath41 is diagonal , and thus we will assume this for simplicity .",
    "we assign to the matrix @xmath41 entries equal to @xmath53 , where @xmath54 is the noise variance for the @xmath26th pixel in the @xmath0-plane .",
    "the construction @xmath55 provides a pseudo - inverse of @xmath41 , so that any locations in the @xmath0-plane with no antenna coverage do not yield infinities when taking the inverse .",
    "we solve numerically the above matrix - vector equation using a preconditioned conjugate - gradient scheme  @xcite .",
    "the preconditioner approximates the diagonal components of @xmath43 and is @xmath56 where @xmath57 is the fourier transform of the primary beam pattern .",
    "we implemented the code to solve the above equations with the open - source petsc library  @xcite and the mpi - parallelized version of fftw  @xcite .",
    "given the latest signal sample , @xmath49 , we generate a new angular power spectrum sample from eq .",
    "( [ eq : iterations ] ) by computing the variance @xmath58 in annuli of constant @xmath22 on the fourier - transformed signal .",
    "we then use this variance to draw from the probability density @xmath59 , which follows an inverse gamma distribution , by creating a vector @xmath60 of length @xmath61 ( assuming a jeffreys ignorance prior ) and unit gaussian random elements . here",
    ", @xmath61 is the number of pixels in the bin @xmath22 .",
    "the next power spectrum sample is then simply @xmath62    in the above , we assume @xmath63 to be constant across the width of each annulus in the @xmath0-plane .",
    "the width of each annulus can be set as desired . for the test cases which we work with in this paper we chose the width to be @xmath64 , where @xmath65 is the longest baseline of the interferometer .",
    "this is four times the @xmath0-space resolution .",
    "this choice limits correlations between angular power spectrum bins which develop as a consequence of partial sky coverage .",
    "all @xmath22-bins have uniform width except for the first , which we restrict to cover only the central zone where we enforce @xmath66 , since our analysis can not constrain the dc mode .",
    "we wish to capture as much power spectrum information as possible , so we correspondingly widen the width of the second bin to close this gap .    to determine convergence so that our iterative samples from the conditional distributions ( eq .  [ eq : iterations ] ) are indeed samples from the joint distribution , we employ multiple chains with different random number seeds .",
    "our convergence criterion is the gelman - rubin ( g - r ) statistic , which compares the variance among chains to the variance within each chain .",
    "the g - r statistic asymptotes to unity , so convergence is said to be achieved when this statistic is below a given tolerance level for each @xmath22-bin  @xcite . for our test images we stopped iterating when the g - r statistic reached less than @xmath67 , which took from 500 to 1500 steps , depending on the image .    after convergence ,",
    "we take the mean of the signal samples as our reconstructed image and simply calculate the variance for each pixel to assess the uncertainty in the reconstruction .",
    "figure  [ fig : variance ] shows the variance for the _ einstein _ test image .",
    "we naturally see insignificant variance in the center of the primary beam where the data support is strongest , with steadily increasing variance away from the pointing center .",
    "we may use the variance to build a mask of the final reconstructed image in which we only accept pixels below a given variance threshold . while this certainly is nt necessary for the method to work , it provides an easy way to combine the posterior mean and variance information in a single plot .",
    "first , we compute the asymptotic variance @xmath68 , or the mean of the variance along the outer edge of image plane .",
    "we then reject any pixel whose variance @xmath69 is greater than @xmath70 _ and _ whose signal - to - noise ratio @xmath71 .",
    "this last criterion prevents us from masking low - intensity , but still well - constrained , pixels .",
    "the values chosen to create the mask are arbitrary , and we choose them solely on aesthetic merit .",
    "we repeat : this mask is not necessary to perform the deconvolution and produce a reconstructed signal .",
    "we only use it to neatly incorporate the measured uncertainty information in the plotted images .",
    "as we see in figure  [ fig : variance ] , the acceptance mask generally follows the primary beam pattern .",
    "the detailed shape near the mask edge is influenced by the relative signal - to - noise levels and highlights the non - obvious nature of the regions of reliable reconstruction .",
    "we also notice an asymmetry in the acceptance mask : this is in response to the asymmetric nature of the fiducial interferometer setup ( figure  [ fig : pattern ] ) and provides strong evidence that the symmetric nature of our gaussian process prior does not greatly influence our inference .",
    "we compare images recovered by gibbs sampling , as described in the previous section , to those recovered by a proxy for the point source - based clean algorithm .",
    "clean is implemented in various radio interferometric imaging packages ( such as casa ) .",
    "however , it is not straightforward to use these packages to reconstruct images from simulated visibilities already defined on gridded coordinates ; these packages are instead tailored to analyse observations made by real interferometric telescopes , with data in a specific format .",
    "consequently , we compare to reconstructions made with a proxy for the point source - based clean algorithm . while there are more sophisticated implementations of clean that would undoubtedly perform better with our test images ,",
    "this gives us a simple standard of comparison allowing us to demonstrate the viability of our method .",
    "we will include further comparisons in future work .",
    "it was shown by @xcite that @xmath72 reconstruction with the dirac basis ( i.e.  pixel basis ) results in very similar reconstruction quality to clean ( see * ? ? ?",
    "* figure  1 ) .",
    "this is to be expected since it is known already that clean is closely related to @xmath72 reconstruction with the dirac basis @xcite .",
    "we thus take a similar approach to that taken by recent studies ( mcewen & wiaux 2011 ; carrillo et al . 2012 ; wolz et al .",
    "2013 ; carrillo et al . 2013 ) and use @xmath72 reconstruction with a dirac basis as a proxy for the clean algorithm . the reconstructed image that serves as a clean proxy",
    "is therefore given by the solution of the optimisation problem : @xmath73 where @xmath74 denotes the @xmath72 norm and @xmath75 is related to a residual noise level estimator  ( see , e.g. , * ? ? ?",
    "* ; * ? ? ?",
    "we solve this problem using the sparse optimisation ( sopt ) package  @xcite using the douglas - rachford splitting algorithm @xcite .",
    "note that the sopt package is a versatile code , capable of solving much more sophisticated optimisation problems than the straight - forward @xmath72 minimisation performed here ( for examples of more extensive use see carrillo et al .",
    "2012 , 2013b ; wolz et al .",
    "2013 ) .",
    "figures  [ fig : gallery1 ] and  [ fig : gallery2 ] are galleries of the input images ( without noise ) , our posterior mean reconstruction using gibbs sampling , and a standard reconstruction using our implementation of clean .",
    "for all these images we have zoomed in to the inner 10 degrees where the primary beam selects the most prominent signal .",
    "we have applied our variance - based acceptance mask for our gibbs sampling reconstructions .",
    "we see that gibbs sampling is able to recover the complete range of source images to very high fidelity .",
    "we even faithfully recover glitches in the input image , such as the asymmetric protoplanetary disk in the _ swolf _ image and discontinuous lobe structure in the _",
    "3c288 _ image .",
    "this emphasizes the power of the wiener filter : in regions of strong data support , our samples are driven to the data regardless of choice of prior .",
    "we also recover low - intensity portions of the image both in the center of the image and towards the edge of the primary beam , such as the regions between the spiral arms in the _",
    "m51 ha _ image . however , there are other low - intensity regions , such as the lower portion of the mustache in the _ einstein _ image , where the signal is too low to distinguish it from the noise , and our mask rejects those pixels .",
    "a comparison to the clean images especially highlights the abilities of our gibbs sampling reconstruction technique . in all images ,",
    "we recover a broader range of fluxes over a wider extent than clean ( as in , for example , the _ cluster _ reconstruction ) . also , gibbs sampling is able to recover portions of the image further into the edges of the primary beam , as can be easily seen in the _ 3c288 _ and _ hco+4 - 360 _ images .",
    "finally , in images with glitches , such as _ swolf _ , clean tends to exaggerate the asymmetries .",
    "figure  [ fig : residuals ] shows the residuals ( i.e. , difference maps ) between the mean posterior signal generated by gibbs sampling and the input test image . in all cases",
    "the variance - based acceptance mask has been applied .",
    "we see that the maximum residual occurs in the center of the _ einstein _ test image , where the gibbs method slightly underestimates the source intensity .",
    "this is probably due to the method attempting to average the very high - contrast features adjacent to the center .",
    "the _ einstein _",
    "image turns out to be the most difficult : the residuals for all other images are typically an order of magnitude smaller . while the residuals are somewhat correlated with the distributions of the source image , like the _ einstein _ test image it appears that our method performs poorest in regions of high intensity contrast . however , these differences are very mild : typically on the order of 1% of the input source intensity .",
    "we may further quantify the differences between the input signals and their reconstructions with clean and our gibbs sampling method by binning the intensities , as we do in figure  [ fig : histograms ] .",
    "bounding the histograms of the posterior mean are 2@xmath69 error bars measured from the variance in the generated samples .",
    "this is another example of the kind of information unavailable in traditional reconstruction techniques . for almost all test images and intensity bins , our posterior mean",
    "reconstruction is within two standard deviations of the input signal .",
    "this is unsurprising : our bayesian method automatically discovers the local variance because that variance is directly related to the relative level of signal and noise in a given bin . in a few bins , such as the high - intensity bin of the _ einstein _ test image , our method tends to underestimate the true intensity .",
    "this is due to the high pixel - by - pixel contrast in the central image region discussed above .",
    "while the clean image intensities largely fall within the uncertainty ranges of the gibbs reconstruction , there is a systematic steepening of the distributions : clean tends to have too many low - intensity pixels and correspondingly too many high - intensity pixels .",
    "this validates the discussion above which noted that clean does not fully reproduce the observed range of input fluxes .",
    "finally , we may further simplify the comparison by reducing our measurement error to a single scalar .",
    "two error metrics are commonly used : the root - mean - square ( rms ) of the residual map , and the signal - to - noise ratio ( snr ) .",
    "this last quantity itself has several variations ; we take that of  @xcite : @xmath76 where @xmath77 is the standard deviation of image x , with @xmath10 denoting the original image and @xmath78 denoting the reconstructed image . for both measures",
    "we first apply our variance - based acceptance mask before calculating the error metrics .",
    "figure  [ fig : error ] shows the rms and snr for each of our test images for both gibbs sampling and traditional clean .",
    "as expected from our residuals , gibbs sampling performed most poorly in terms of rms with the _ einstein _ test image due to its highly complex structure . with the exception of that image and _ g41.1 - 0.3.b _ , all rms errors are below @xmath79 .",
    "the snr for all reconstructions with gibbs sampling fall between 10 and 25 . in both rms and snr measures",
    "gibbs sampling outperforms clean for all test images .",
    "the largest differences occur in images with high degrees of symmetry ( e.g. , _",
    "m51 ha _ , _ swolf _ ) since in these cases our isotropic gaussian process prior performs best in marginal signal - to - noise portions of the image .",
    "we have presented an innovative method for deconvolving radio interferometric images using the bayesian method of gibbs sampling .",
    "our method naturally offers several advantages over traditional deconvolution approaches .",
    "it fully accounts for signal and noise mode coupling and incomplete @xmath0-plane coverage in an automatic and well - motivated fashion , requires no fine - tuning or supervision as the method progresses , and provides an informative description of the uncertainty information in the signal reconstruction .",
    "we choose an isotropic gaussian process image prior , though we do nt specify the signal covariance in advance .",
    "we have tested our method with a realistic interferometric observing scenario of a wide variety of source images .",
    "these images represent typical targets , including protoplanetary disks and active galactic nuclei jet - and - lobe systems .",
    "note that our choice of prior is wrong for _ all test cases _ , but the iterative application of the wiener filter allows us to discover the source images within the noise and incomplete @xmath0-plane coverage .",
    "we find that our method is quite robust : regardless of the structure of the source image we are able to recover the intensity distribution to a very high fidelity .",
    "our method outperforms traditional point source - based clean in terms of intensity distributions , rms error , and reconstruction signal - to - noise ratio .",
    "as expected given our isotropic gaussian process prior , we perform best on images with large amount of symmetry , though the wiener filter provides a route for reliable reconstructions of asymmetric images in regions of strong data support regardless of source structure .    using our method",
    "we can also easily incorporate uncertainty information in the reconstructed image . as discussed in earlier works  @xcite , the error model generated from the isotropic gaussian process",
    "prior tends to underestimate the true errors , but this situation is far preferable to no error model at all . with our error model",
    "we can construct acceptance masks based on the local ( i.e. , pixel - by - pixel ) signal - to - variance ratios .",
    "the desired threshold can be adjusted based on the desired level of confidence in the deconvolution .",
    "since the sample variance is directly tied to the relative level of noise by way of the wiener filter , our method naturally and self - consistently determines this mask .",
    "while the test cases we have presented in this work use an interferometric setup with realistic noise levels , primary beam shape , and antenna array , they do represent a relatively simplistic observing scenario .",
    "a fully implemented method would include simultaneous solutions of multiple frequencies , mosaicked images , and wide bandwidth observations .",
    "also , we have specified an overall snr of 10 for our fiducial observations , and we must examine the performance of this method in different regimes .    additionally , future large - scale interferometers will deliver incredibly high volumes of data .",
    "image deconvolution from even a single pointing at a single frequency will tax most computing systems . to accommodate future data sets",
    "we have implemented our algorithm using the mpi - parallelized petsc  @xcite toolkit , so our approach automatically grows with the size of the data without loss of scalability .",
    "algorithmically , the most expensive portion of our approach is the solution to equation  ( [ eq : sky ] ) , which scales as @xmath80 in the ideal pregridded flat - sky approximation we have presented here .",
    "while we have not discussed foreground removal in this work , this method easily accommodates modeling in two fashions .",
    "first , partial signal or foreground information , if known in advance , can enter as an additional prior .",
    "alternatively , foreground models can be added as an additional sampling step within the algorithm  @xcite .",
    "the resulting posterior mean signal will thus _ automatically _ include marginalizations over the unconstrained parameters of the model .",
    "the same approach can be taken with the noise : if , for example , the noise spectrum is known but the absolute amplitude is not , we can sample over that amplitude .",
    "this flexibility , in addition to the other strengths discussed above , suggest that gibbs sampling is a promising response to the challenges of contemporary and future radio interferometric observations .",
    "m. sutter and b. d. wandelt acknowledge support from nsf grant ast-0908902 .",
    "b. d. wandelt also acknowledges funding from an anr chaire dexcellence , the upmc chaire internationale in theoretical cosmology , and nsf ast-0708849 .",
    "mcewen is supported in part by a newton international fellowship from the royal society and the british academy .",
    "l. zhang and p. timbie acknowledge support from nsf grant ast-0908900 .",
    "e. f. bunn acknowledges support from nsf grant ast-0908900 .",
    "g. s. tucker and a. karakci acknowledge support from nsf grant ast- 0908844 ."
  ],
  "abstract_text": [
    "<S> we present a novel , general - purpose method for deconvolving and denoising images from gridded radio interferometric visibilities using bayesian inference based on a gaussian process model . </S>",
    "<S> the method automatically takes into account incomplete coverage of the @xmath0-plane , signal mode coupling due to the primary beam , and noise mode coupling due to @xmath0 sampling . </S>",
    "<S> our method uses gibbs sampling to efficiently explore the full posterior distribution of the underlying signal image given the data . </S>",
    "<S> we use a set of widely diverse mock images with a realistic interferometer setup and level of noise to assess the method . compared to results from a proxy for point source - based clean method </S>",
    "<S> we find that in terms of rms error and signal - to - noise ratio our approach performs better than traditional deconvolution techniques , regardless of the structure of the source image in our test suite . </S>",
    "<S> our implementation scales as @xmath1 , provides full statistical and uncertainty information of the reconstructed image , requires no supervision , and provides a robust , consistent framework for incorporating noise and parameter marginalizations and foreground removal .    </S>",
    "<S> = -0.8 in    [ firstpage ]    instrumentation : interferometers , methods : data analysis , methods : statistical </S>"
  ]
}