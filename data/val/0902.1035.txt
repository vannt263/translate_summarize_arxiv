{
  "article_text": [
    "the community of program optimisation and analysis , code performance evaluation , parallelisation and optimising compilation has published since many decades hundreds of research and engineering articles in major conferences and journals .",
    "these articles study efficient algorithms , strategies and techniques to accelerate programs execution times , or optimise other performance metrics ( mips , code size , energy / power , mflops , etc . ) .",
    "the efficiency of a code optimisation technique is generally published according to two principles , non necessarily disjoint .",
    "the first principle is to provide a mathematical proof given a theoretical model that the published research result is correct or / and efficient : this is the hard part of research in computer science , since if the model is too simple , it would not represent real world , and if the model is too close to real world , mathematics become too complex to digest .",
    "a second principle is to propose and implement a code optimisation technique and to practice it on a set of chosen benchmarks in order to evaluate its efficiency .",
    "this article concerns this last point : how can we convince the community by rigorous statistics that the experimental study publishes correct and fair results ?",
    "hard natural sciences such as physics , chemistry and biology impose strict experimental methodologies and rigorous statistical measures in order to guarantee the reproducibility of the results .",
    "the reproducibility of the experimental results in our community is , namely , our dark point .",
    "given a research article , it is in practice impossible or too difficult to reproduce the published performance .",
    "if our results are not reproducible , we can not say that we are doing science !",
    "some aspects make a research article non - reproducible :    * non using precise scientific languages such as mathematics . ideally , mathematics must always be preferred to describe ideas , if possible , with an accessible difficulty . *",
    "non available software , non released software , non communicated precise data . *",
    "not providing formal algorithms or protocols make impossible to reproduce exactly the ideas . for instance",
    ", the authors in @xcite spent large efforts to re - implement some branch predictor algorithms based on the published research articles , but they fail to reproduce the initial results of the authors . simply because the initial articles describing the branch predictors are not formal , so they can be interpreted differently .",
    "* hide many experimental details . as demonstrated by @xcite ,",
    "bringing small modification on the execution environment brings contradictory experimental results .",
    "for instance , just changing the size of the linux shell variables or the order of linking an application alter the conclusions .",
    "as pointed by the authors in @xcite , a lot of published articles in major conferences hide these details , meaning that their experimental results are meaningless .",
    "* usage of deprecated machines , deprecated os , exotic environment , etc .",
    "if we take a research article published five years after the experiences for instance , there is a high chance that the workstations that served the experiences have already died or already changed their behaviour ( usury of hardware , software patches , etc . ) .    with the huge amount of published articles in the code optimisation community , with the impressive published speedups ,",
    "an external reviewer of our community has the right to ask the following naive question : _ if we combine all the published speedups ( accelerations ) on the well known public benchmarks since four decades , why do nt we observe execution times approaching to zero ? _ this question is justified , and brings a reforming malaise to us .",
    "now , we are asked to be clear about our statistics , some initiatives start to collect published performance data in order to compare them@xcite .",
    "the malaise raised by the above question is not a suspicion of a general _ cheating _ in research .",
    "we believe that our community is honest in publishing data , but the published observed speedups are sometimes _ rare _ events far from what we could observe if we redo the experiences multiple times .",
    "even if we take an ideal situation where we use exactly the original experimental machines and software , it is too difficult to reproduce exactly the same performance numbers again and again , experience after experience .",
    "usually , published speedups are computed with bias describing pretty _ rare _ events . frankly ,",
    "if a computer scientist succeeds in reproducing the performance numbers of his colleagues ( with a reasonable error ratio ) , it would be equivalent to what rigorous probabilists and statisticians call a _",
    "surprise_.      what makes a binary program execution time to vary , even if we use the same data input , the same binary , the same execution environment ?    * background tasks , concurrent jobs , os process scheduling ; * interrupts ; * input / output ; * starting loader address ; * branch predictor initial state ; * cache effects ; * non deterministic dynamic instruction scheduler ; * temperature of the room ( dynamic voltage / frequency scaling service )    one of the reasons of the non - reproducibility of the results is the variation of execution times of the same program given the same input and the same experimental environment . with the massive introduction of multicore architectures",
    ", we believe that the variations of executions times will become exacerbated because of the complex dynamic features influencing the execution : threads scheduling policy , synchronisation barriers , resource sharing between threads , hardware mechanisms for speculative execution , etc . consequently",
    ", if you execute a program ( with a fixed input and environment ) @xmath0 times , it is possible to obtain @xmath0 distinct execution times .",
    "the mistake here is to assume that these variations are minor , and are stable in general .",
    "the variation of execution times is something that we observe everyday , we can not neglect it .",
    "an usual error in the community is to replace all the @xmath0 execution times by one value , such that the minimum , the mean or the maximum .",
    "doing that would produce _ sexier _ speedups to publish , but does not reflect the reality with fair numbers .",
    "considering the minimum value of the @xmath0 observed execution times is unfair because :    * nothing guarantees that this minimum execution time is an ideal execution of the program . *",
    "nothing guarantees that this minimum execution time is a consequence of the optimisation technique under study .",
    "maybe this minimum execution time is an accident , or a consequence of dynamic voltage scaling , or anything else . *",
    "if this minimal execution time is a rare event , all your statistics describe rare speedups .",
    "so , they become non - reproducible easily",
    ".      we base our reasoning here on common well known results in statistics , especially on some results explained in the book of raj jain @xcite .",
    "we propose a first step towards a rigorous statistical methodology to evaluate program optimisation techniques .",
    "this article recalls some common mistakes in performance evaluation , explains which statistics should be used in a particular situation , and provide practical examples .",
    "furthermore , we show how to use the free software called r to compute these statistics @xcite .",
    "our article is organised to help computer scientists ( and of course phd students ) willing to make correct and rigorous statistical study of their code optimisation method .",
    "the question is how to convince real experts by statistics , provided a confidence level @xmath1 0\\% , 100\\% [ $ ] , that your code optimisation technique is really efficient in practice .",
    "section  [ sec : speedup ] explains when we can decide about a speedup of a program and how we can measure it using @xmath0 observations of execution times .",
    "having a set of @xmath2 distinct independent programs ( considered as a set of benchmarks ) , section  [ sec : overal_speedup ] explains how to compute an average speedup ( while it is a bad idea to synthesise a set of speedups in by a unique average ) .",
    "getting a speedup ( acceleration ) inside a sample of @xmath2 benchmarks does not guarantee you that you can get a speedup on another program .",
    "consequently , section  [ sec : prop_conf_interval ] shows how we can estimate the chance that the code optimisation would provide a speedup on a program non belonging to the initial sample of benchmarks used for experiences .",
    "the limitations of this article are : we do not study the variation of execution times due to changing the program input .",
    "we consider real executions , not emulation / simulation nor executions on virtual machines .",
    "we also consider a fixed ( universal ? ) experimental environment .",
    "let @xmath3 be an initial program , let @xmath4 be a transformed version after applying the code optimisation technique under study . if you execute the program @xmath3 @xmath0 times , it is possible to obtain @xmath0 distinct execution times ( especially if the program is short ) : @xmath5 .",
    "the transformed program @xmath4 can be executed @xmath6 times producing @xmath6 execution times too @xmath7 .",
    "the unit of measure here is the milisecond in general , so we can consider a timing precision in seconds with three digits after the coma . below is a list of elementary recommendations before starting statistics :    1 .",
    "@xmath3 and @xmath4 must be executed with the same data input in _",
    "similar _ experimental environment .",
    "the community of code optimisation has not decided yet on the exact semantics of _ similar _ , since many unknown / hidden factors may influence the experiences .",
    "statistically , it is not necessary that @xmath8 .",
    "however , it is _ strongly _ recommended that @xmath9 and @xmath10 .",
    "30 runs may seem quite prohibitive , but this is the practical limits of the number of observations used in statistics if you want to have a precise student test that we will explain later . if the number of observations is below 30",
    ", computing the confidence intervals of the mean time becomes more complex : we should first check the normality of the distribution ( using the normality test of shapiro - wilk for instance ) .",
    "if the normality check succeeds , then the test of student can be applied .",
    "otherwise , the confidence intervals of the mean execution times must be computed using complex bootstrap methods @xcite instead of the test of student .",
    "we highly recommend 30 runs per program to ensure the validity of the student test .",
    "if the program execution time is too large to consider 30 executions , you can do less executions but you should follow the method we just described ( either a normality check followed by a student test , or by using bootstrap methods ) .",
    "it is important that the repetitive executions of the same program should be independent .",
    "for instance , it is not fair to use a single loop around a code kernel that repeat the execution @xmath0 times .",
    "this is because repeating a program @xmath3 inside a loop makes them to execute inside the same application .",
    "consequently , the operating system does not behave as if you execute the program @xmath0 times from the shell .",
    "furthermore , the caches are warmed by the repetitive executions of the code kernels if they belong to the same application .",
    "4 .   anyway ,",
    "even if we execute a program @xmath0 times from the shell , the executions are not necessarily independent , especially if they are executed back - to - back : the seek time of the disk is altered by repetitive executions , some data are cached on the disk by applications and benefit from repetitive executions .",
    "recently , we have been told that branch predictors are also influenced by separate applications : this seems strange , but we should stay careful with hardware mechanisms . as you can see , it is not easy to guarantee @xmath0 independent executions !    we have remarked a common mistake in computing speedups in presence of program execution time variance : assuming that the variations in execution times are not really a problem , because caused by external factors , these variations may be neglected and smoothed .",
    "consequently , we may be asked to compute the speedup resulted from transforming @xmath3 into @xmath4 by using one of the following fractions : @xmath11 , @xmath12 , or @xmath13 . here",
    ", @xmath14 is the usual notation of the sample arithmetic mean : @xmath15 , @xmath16 . if one of the previous speedups is higher than 1 , than people conclude victory .",
    "the mistake here is to assume that @xmath0 observed execution times represent any future execution time of the program , even with the same data input .",
    "statistically , we are wrong if we do not consider confidence intervals . to be rigorous",
    ", we can follow the four major steps described below to assert a high confidence in the computed speedup .",
    "the whole detailed protocol is illustrated in figure  [ fig : stat_protocole ] .",
    "as said before , if the number of runs is at least 30 , you can skip this step .",
    "if the number of runs of a program is below 30 , we should check if the values @xmath17 and @xmath18 follow a normal distribution . in practice",
    ", we can use the shapiro - wilk normality test providing a confidence level .",
    "the user should fix a confidence level ( say @xmath19 ) , and the shapiro - wilk test can determine ( with @xmath20 chance of error ) that the values follow a normal distribution .",
    "a later example will show how to practice this using the r software .",
    "if the normality check fails , you can either run more executions till 30 , or use complex bootstrap method ( that we will not explain here ) .",
    "the student test allows to statistically check if all the future executions of the program @xmath4 are faster than the executions of @xmath3 with a fixed confidence level @xmath21 ( @xmath22 ) .",
    "the student test allows to say that we have @xmath23 of chance that the mean execution time of @xmath4 is faster than the mean execution time of @xmath3 by just analysing the @xmath24 observations . this test estimates the confidence interval of the difference between the mean execution times of @xmath3 and @xmath4 .",
    "if the value zero is inside the confidence interval , then the student test does not guarantee with a confidence level @xmath21 that the program @xmath4 is faster in average than the program @xmath3 .",
    "that is , if 0 belongs to confidence interval of the student test , no speedup can be concluded for the program @xmath3 .",
    "let @xmath25 $ ] be the confidence interval computed by the student test .",
    "if @xmath26 then we can say that @xmath4 would be faster in average than @xmath3 in @xmath27 of the future executions ( considering the same data input and experimental environment ) .",
    "an example is illustrated later .",
    "the speedup factor for the program @xmath4 can be defined as the fraction between the sample mean times , as follows : @xmath13 . here",
    ", @xmath14 is the usual notation of the sample arithmetic mean : @xmath15 , @xmath16 .",
    "the problem with this definition of speedup is that it is sensitive to _ outliers_. indeed , the distributions of the values of @xmath17 and @xmath18 may be biased .    for the above reasons , we prefer using the median as suggested by @xcite instead of the sample mean of the execution times .",
    "consequently , the speedup becomes    @xmath28    remember that this speedup has no sense if the student test fails to determine if 0 is outside the confidence interval . for the remaining part of the article , we note by @xmath29 and @xmath30 the observed median of the execution times of the program @xmath3 and @xmath4 resp .",
    "let @xmath3 be a initial program with its `` representative '' data input .",
    "we are willing to statistically demonstrate with a confidence level @xmath19 that an optimisation technique transforms it into @xmath4 and produces benefit in terms of execution speed . for doing this ,",
    "i should execute @xmath3 and @xmath4 at least 30 times . for the sake of the example ,",
    "i consider here only 5 executions for @xmath3 and @xmath4 .",
    "using the software r , i introduce the values of execution times ( in seconds ) of @xmath3 and @xmath4 as two vectors @xmath31 and @xmath32 resp .    ....",
    "> library(stats ) > t1<- c(2.799 , 2.046 , 1.259 , 1.877 , 2.244 ) > t2 < - c(1.046 , 0.259 , 0.877 , 1.244 , 1.799 ) ....    we must not hurry to conclude and to publish the following result : the resulted speedup for this program is equal to @xmath33 .",
    "publishing such performance gain ( acceleration of factor equal to 4.86 ) is a statistical mistake .",
    "since we have only 5 observations instead of 30 , we should check the normality of the values of @xmath31 and @xmath32 resp . using the test of shapiro - wilk .    ....",
    "shapiro.test(t1 )      shapiro - wilk normality test data :   t1   w = 0.9862 , p - value = 0.9647 ....    the test of shapiro - wilk on the data @xmath34 computes here a value @xmath35 . in order to say that the test succeeds with confidence level @xmath21 , the value @xmath36 must be greater or equal to the @xmath36 value of the shapiro - wilk table ( this table can be found on internet for instance ) .",
    "i use here a confidence level @xmath19 .",
    "the shapiro - wilk table for @xmath37 ( number of values ) and @xmath38 indicates the value of 0.986 .",
    "consequently , the normality test succeeds for @xmath34 .",
    "idem for @xmath39 .",
    "> shapiro.test(t2 )      shapiro - wilk normality test data :   t2   w = 0.9862 , p - value = 0.9647 ....    since @xmath40 , the values of @xmath32 follows a normal distribution with a confidence level of @xmath38 .",
    "it is important to notice here that if the normality test fails for a program ( @xmath31 or @xmath32 ) , we must run it at least 30 times .",
    "i can now continue with the student test to check if @xmath41 is faster than @xmath3 with a very high confidence level @xmath42 .    ....",
    "> t.test(t1,t2 , alternative=\"greater \" , conf.level=0.99 ) welch two sample t - test ... 99 percent confidence interval : -0.02574667          inf   ... ....    the obtained confidence interval for the difference between the mean execution times is @xmath43 $ ] .",
    "this interval includes 0 .",
    "consequently , we can not assert with @xmath44 confidence level that @xmath41 is faster in average than @xmath3 .",
    "i have the choice by either rejecting the obtained speedup ( too hard ) , or reduce my confidence level .",
    "i check with @xmath19 instead of @xmath45    .... > t.test(t1,t2 , alternative=\"greater \" , conf.level=0.95 ) ... 95 percent confidence interval :   0.3414632        inf   ... ....    the confidence interval is @xmath46 $ ] , it does not include 0 .",
    "consequently , we can assert with 95% confidence level that we obtained a speedup .",
    "in other words , the risk ( of error ) of not obtaining an acceleration for the future executions is equal to 5% .",
    "the obtained speedup is @xmath47 .",
    "if the confidence level used for the student test is too low , it is not impossible that we reach a situation where the student test detects a speedup while the computed speedup is @xmath48 .",
    "the following example shows that low confidence levels may bring incoherent speedup measure .",
    "let take the same previous example with @xmath31 and @xmath32 .",
    "we apply a student test with a confidence level equal to 1% to ensure that @xmath4 is slower than @xmath3 . in the previous example",
    ", we showed the contrary with a confidence level equal to 95% .    ....",
    "> t.test(t2 , t1 , alternative=\"greater \" , conf.level=0.01 ) ... 1 percent confidence interval :   0.02574667         inf   ... ....    as you can see , the test of student succeeds , so we have 1% of chance that @xmath4 is slower than @xmath3 .",
    "the computed speedup ( either by considering the sample mean of the median ) is as follows :    ....   > mean(t2)/mean(t1 ) [ 1 ] 0.5110024 > median(t2)/median(t1 ) [ 1 ] 0.5112414 ....    as you can see , the speedup here is below 1 . is this a contradiction",
    "no of course , remember that the confidence level of this speedup is only 1% .",
    "this section explained how to check with a confidence level @xmath21 that a code optimisation technique produces a faster transformed program ( for a fixed data input and experimental environment ) .",
    "we also provided a formula for quantifying the speedup .",
    "the following section explains how to compute an overall average of speedups of a set of benchmarks .",
    "when we implement a code optimisation technique , we are generally asked to test it on a set of benchmarks , not on a unique one .",
    "let @xmath2 be the number of considered benchmarks .",
    "ideally , the code optimisation technique should produce speedups on the @xmath2 programs ( at least no slowdown ) with the same confidence level @xmath21 .",
    "unfortunately , this situation is rare nowadays .",
    "usually , only a fraction of @xmath49 programs among @xmath2 would benefit from an acceleration .",
    "let @xmath50 be the obtained speedup for the program @xmath51 .",
    "while this is not correct in statistics , some reviewers ask an average speedup of all the benchmarks . in statistics , we can not provide a fair average because the programs are different , and their weights are different too .",
    "so , asking for an overall speedup for a set of benchmarks will highly bring unfair value . neither an arithmetic mean , nor a geometric or harmonic mean can be used to synthesise in a unique speedup of the whole set of benchmarks .",
    "the arithmetic mean does not distinguish between short and long programs : for instance , having a speedup of 105% on a program which lasts 3 days must not have the same impact as a speedup of 300% obtained on a program which lasts 3 seconds . in the former ,",
    "we save 5% of 3 days ( = 216 minutes ) , while in the latter we save 200% of 3 seconds ( = 2 seconds ) .",
    "if we use the arithmetic mean , we would obtain an overall speedup equal to ( 105 + 300)/2=202% , this does not reflect the reality with a fair number .",
    "the geometric mean can not be applied here because we are not faced to a succession of accelerations on the same program , but to accelerations to distinct programs .",
    "the harmonic mean in our case is not meaningful too because the quantity @xmath52 represents also a sort of speedup , so we can provide the same criticism as the arithmetic mean .    in order to compute @xmath53 an overall _ performance gain factor _",
    "( not an overall speedup ) that represents the weights of the different programs , we can use the following method .",
    "the confidence level of this performance gain factor is equal to the minimal value of confidence levels used in the student tests to validate individual speedups .",
    "first , an interesting question is to decide if we should neglect the @xmath54 programs where no speedup has been validated by the student test .",
    "that is , the performance gain factor is computed for a subset @xmath49 of programs , not on all the @xmath2 benchmarks .",
    "we believe we neglect the @xmath54 programs that fail in the student test if we study afterwards ( in the next section ) the confidence interval of the proportion @xmath55 : studying this proportion helps us to decide if the reported overall gain is meaningful . if we decide to include all the @xmath2 programs for computing the overall performance gain factor , this is also fair , but the reported gain may be negative since it includes the slowdowns .",
    "second , we associate a weight @xmath56 to each program @xmath51 . the general characteristics of a weight function is @xmath57 .",
    "if not , we should normalise the weights so that they sum to 1 .",
    "the weight of each benchmark can be chosen by the community , by the benchmark organisation , by the user , or we can simply decide to associate the same weight to all benchmarks . also , it is legitimate to choose the weight as the fraction between the observed execution time and the sum of all observed execution times : @xmath58 .",
    "here we choose to put @xmath59 , ie , the median of all the observed execution times of the program @xmath51 .",
    "someone would argue that this would give more weight on long running time programs : the answer is yes , because what we want to optimise at the end is the absolute execution time , not the relative one .",
    "third , transforming a program @xmath51 into @xmath60 allows to reduce the execution time by @xmath61 .",
    "this absolute gain should not be considered as it is , but should be multiplied by the weight of the program as follows : @xmath62 .",
    "fourth and last , the overall performance gain factor is defined as the fraction between weighted gains and the sum of weighted initial execution times : @xmath63 . by simplification ,",
    "we obtain : @xmath64 by definition , the overall gain @xmath65 , since the execution times of the optimised programs are hopefully non zero values ( @xmath66 ) .",
    "let a program p1 that initially lasts 3 seconds .",
    "assume we succeed to accelerate it with a factor of 300% with a confidence level @xmath67 .",
    "thus , its new median execution time becomes 1 second .",
    "let p2 be a program that initially lasts 1 hour and has been accelerated with a factor of 105% with a confidence level @xmath68 .",
    "thus , its new median execution time becomes 3428 seconds .",
    "the arithmetic mean of these two speedups is 202.5% , the geometric mean is 177.48% and the harmonic mean is 155.56% .",
    "none of these means is suggested for publications as explained before .",
    "the weights of the programs p1 and p2 are resp . @xmath69 and @xmath70 .",
    "the obtained weighted gain for each program is : @xmath71 and @xmath72 .",
    "the overall performance gain factor is then @xmath73 and the confidence level is equal to @xmath74 . if we consider that the weights are unit , @xmath75 , then the overall performance gain factor is then @xmath76 and the confidence level is still equal to @xmath74 . as can be remarked , there is not a direct comparison between the overall gain and the individual speedups .",
    "the following section gives a method to evaluate the quality of a code optimisation method .",
    "precisely , we want to evaluate the chance that a code optimisation technique produces a speedup on a program that does not belong to the initial set of experimented benchmarks .",
    "computing the overall performance gain for a sample of @xmath2 programs does not allow to estimate the quality nor the efficiency of the code optimisation technique .",
    "in fact , within the @xmath2 programs , only a fraction of @xmath49 benchmarks have got a speedup , and @xmath54 programs got a slowdown . if we take this sample of @xmath2 program as a basis , we can measure the chance of getting the fraction of accelerated programs as @xmath55 .",
    "the higher is this proportion , better would be the quality of the code optimisation .",
    "in fact , we want to estimate if the code optimisation technique is beneficial for a large fraction of programs .",
    "the proportion @xmath77 has been observed on a sample of @xmath2 programs .",
    "the confidence interval for this proportion ( with a confidence level @xmath21 ) is given by the equation @xmath78 , where @xmath79 .",
    "in other words , the confidence interval of the proportion is equal to @xmath80 $ ] . here",
    ", @xmath81 represents the value of the @xmath82 quartile of the unit normal form .",
    "this value is available in a known table ( table a.2 in @xcite ) .",
    "the confidence level @xmath21 is equal to the minimal value of confidence levels used in the student tests to validate individual speedups .",
    "we should notice that the previous formula of the confidence interval of the proportion @xmath83 is valid only if @xmath84 .",
    "if @xmath85 , computing the confidence interval becomes too complex according to @xcite .",
    "having @xmath86 benchmarks , we obtained a speedup on only @xmath87 cases .",
    "we want to compute the confidence interval for the proportion c=17/30=0.5666 with a confidence level @xmath88 .",
    "the quantity @xmath89 , i can then easily estimate the confidence interval of @xmath83 using the r software as follows .    ....",
    "> prop.test(17 , 30 , conf.level=0.90 ) ... 90 percent confidence interval :   0.4027157 0.7184049   ... ....    the above test allows us to say that we have 90% of chance that the proportion of accelerated programs is between @xmath90 and @xmath91 .",
    "if this interval is too wide for the purpose of the study , we can reduce the confidence level as a first straightforward solution .",
    "for instance , if i consider @xmath92 , the confidence interval of the proportion becomes @xmath93 $ ] . or , if we do not want to reduce the confidence level , we need to do more experiences on more benchmarks .",
    "the next formula gives the minimal number @xmath2 of benchmarks requested if we want to estimate the confidence interval with a precision equal to @xmath94 with a confidence level @xmath21 : @xmath95    in the previous example , we have got an initial proportion equal to @xmath96 .",
    "if i want to estimate the confidence interval with a precision equal to 5% with a confidence level of 95% , i put @xmath97 and i read in the quartiles tables @xmath98 .",
    "the minimal number of benchmarks to observe is then equal to : @xmath99 .",
    "we need to experiment 378 benchmarks in order to assert that we have 95% of chances that the proportions of accelerated programs are in the interval @xmath100 .",
    "the discussion that we can have here is on the quality or on the representativeness of the sample of @xmath2 benchmarks .",
    "this is outside the scope of the paper ! until now",
    ", we do not know what does a set of representative programs means .",
    "program performance evaluation and their optimisation techniques suffer from the disparity of the published results .",
    "it is of course very difficult to reproduce exactly the experimental environment since we do not always know all the details or factors influencing it .",
    "this article treats a part of the problem by recalling some principles in statistics allowing to consider the variance of program execution times .",
    "the variance of program execution times is not a chaotic phenomena to neglect or to smooth ; we should keep it under control and incorporate it inside the statistics we publish .",
    "this would allows us to assert with a certain confidence level that the results we publish are reproducible under similar experimental environment .    using simulators instead of real executions provide reproducible results ,",
    "since simulators are deterministic : usually , simulating a program multiple times should always produce the same performance numbers .",
    "this article assumes that the observations have been done on the physical machine not by simulation .",
    "if the physical machine does not exist , the observations based on simulation can not be studied exactly with the methods described in this article .",
    "the study should more be concentrated on the statistical quality of the simulator . as far as we know",
    ", it does not exist yet a simulator that has been rigorously validated by statistics as described in @xcite .",
    "usual error ratios reported by simulators are not sufficient alone to judge about their quality .",
    "this article does not treat performance evaluation with multiple data inputs of a program .",
    "in fact , the speedups defined in this article are computed for a unique set of data input . experimenting multiple sets of data",
    "input to measure a speedup is let for a future work .",
    "we conclude with a short discussion about the confidence level we should use in this sort of statistical study .",
    "indeed , there is not a unique answer to this crucial question . in each context of code",
    "optimisation we may be asked to be more or less confident in our statistics . in the case of hard real time applications ,",
    "the confidence level should be high enough ( more than 95% for instance ) , requiring more experiments and benchmarks . in the case of soft real time applications ( multimedia , mobile phone , gps , etc . )",
    ", the confidence level can be more than 80% . in the case of desktop applications",
    ", the confidence level should not be necessarily high . in any case",
    ", the used confidence level for statistics must be declared for publication .    9    raj jain . _",
    "the art of computer systems performance analysis : techniques for experimental design , measurement , simulation , and modelling_. john wiley and sons , inc .",
    ", new york , 1991 .",
    "pierre - andr cornillon , arnaud guyader , franois husson , nicolas jgou , julie josse , maella kloareg .",
    "ric matzner - lober , laurent rouvire .",
    "_ statistiques avec r_. presses universitaires de rennes , socit franaise de statistique , 2008 .    .",
    "r foundation for statistical computing , vienna , austria , 2008 .",
    "3 - 900051 - 07 - 0 .",
    "grigori fursin and olivier temam .",
    "_ collective optimization_. the 4th international conference on high performance and embedded architectures and compilers ( hipeac ) .",
    "a. c. davison and d. v. hinkley _ bootstrap methods and their application _ cambridge university press .",
    "1997    todd mytkowicz et amer diwan et peter f. sweeney et mathias hauswirth _ producing wrong data without doing anything obviously wrong ! _ to appear in asplos 2009 .",
    "daniel gracia prez and gilles mouchard and olivier temam .",
    "_ microlib : a case for the quantitative comparison of micro - architecture mechanisms . _",
    "micro 2004 : 43 - 54",
    "we would like to thank sebastien briais from the university of versailles saint - quentin en yvelines for his helpful remarks to improve this document ."
  ],
  "abstract_text": [
    "<S> the community of program optimisation and analysis , code performance evaluation , parallelisation and optimising compilation has published since many decades hundreds of research and engineering articles in major conferences and journals . </S>",
    "<S> these articles study efficient algorithms , strategies and techniques to accelerate programs execution times , or optimise other performance metrics ( mips , code size , energy / power , mflops , etc . ) . </S>",
    "<S> many speedups are published , but nobody is able to reproduce them exactly . </S>",
    "<S> the non - reproducibility of our research results is a dark point of the art , and we can not be qualified as _ computer scientists _ if we do not provide rigorous experimental methodology .    </S>",
    "<S> this article provides a first effort towards a correct statistical protocol for analysing and measuring speedups . </S>",
    "<S> as we will see , some common mistakes are done by the community inside published articles , explaining part of the non - reproducibility of the results . </S>",
    "<S> our current article is not sufficient by its own to deliver a complete experimental methodology , further efforts must be done by the community to decide about a common protocol for our future experiences . anyway , our community should take care about the aspect of reproducibility of the results in the future .    [ [ keywords ] ] keywords : + + + + + + + + +    program optimisation , statistical performance evaluation </S>"
  ]
}