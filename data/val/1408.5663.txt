{
  "article_text": [
    "application - level forward erasure correction ( al - fec ) codes have become a key component of many content delivery systems .",
    "they are widely used as an efficient technique to recover packet losses in internet ( usually caused by congested routers ) or wireless communications ( often caused by a short term fading problem ) .",
    "such a network can be regarded as a packet erasure channel ( or equivalently a bit erasure channel , bec ) , characterized by the property that the transmitted data packets are either received without error or erased ( lost ) .",
    "packet loss resilience may also be achieved with automatic repeat request ( arq ) techniques ( e.g. , with tcp ) , but : a round trip time ( rtt ) is needed to recover from a loss , which can be a issue for delay - sensitive applications ( e.g. , video - conferencing ) , the return channel may not exist ( e.g. , in case of a unidirectional broadcast network ) , and it does not scale well with the number of receivers in case of multicast or broadcast transmissions .",
    "al - fec codes are a key building block of content broadcast technologies such as the flute / alc  @xcite protocol stack for the reliable and scalable transmission of files to a potentially huge number of receivers , and the fecframe framework  @xcite when dealing with real - time delivery services as in streaming applications .",
    "al - fec is now deployed in all systems relying on flute / alc ( e.g. , 3gpp mbms service  @xcite or isdb - tmm  @xcite ) and sometimes at the link layer as well ( e.g. , the mpe - fec layer of dvb - h systems  @xcite ) .    in all of the previous use - cases ( real - time delivery included ) ,",
    "only block codes are considered , and the set of source packets is first grouped into blocks where al - fec encoding / decoding is performed . in the present work we introduce an alternative and practical al - fec solution that aims at encompassing both block oriented and sliding window oriented use - cases .",
    "random linear codes ( rlc ) are another class of al - fec codes .",
    "they are increasingly popular due to their simple yet powerful encoding techniques , in particular in the context of random linear network coding ( rlnc ) where encoding / decoding can be performed at the various network nodes , namely either at intermediate nodes ( e.g. , wifi access point or routers ) or end nodes  @xcite . at a source ( sender )",
    "node or intermediate node , rlc generates encoded packets ( also called encoded symbols in this paper ) just by linearly combining the available symbols using encoding vectors ( also called coefficients ) randomly selected from a given finite field ( e.g. , @xmath0 ) . in general",
    ", the set of available symbols evolves over the time , i.e. , rlc are used as convolutional codes . in  @xcite",
    ", rlc is also utilized in a convolutional manner , but end - to - end ( i.e. , there is no re - encoding within the core network ) , with feedback information from the receiver , which enables to achieve a full reliability when desired .",
    "the authors show that the recovery delay for lost packets is in that case independent of the rtt .",
    "however the main issue to be considered with rlc is the high decoding complexity , typically a gaussian elimination ( ge ) over a dense linear system .",
    "this problem becomes even more pronounced when the number of source symbols involved is large , and/or when the finite field is @xmath0 ( or higher ) so as to improve the erasure recovery capabilities  @xcite .    since we believe that rlc can play a key role in network coding systems for the erasure channel  @xcite , we have focused on the design of new improved rlc techniques .",
    "our goal is to design rlc codes that :    * can be used either as block or convolutional codes ; * can be used with encoding window sizes in 210,000s symbols range , as very large sizes are beneficial to bulk file transfers while small values are useful for real - time contents ; * have excellent erasure recovery performance , and at the same time enable fast encoding / decoding which is essential for devices with limited computational and memory capabilities ; * enable compact signaling ( e.g. , transmitting the full encoding vector does not scale ) ;    in other words , we try to bridge the gap between block and convolutional al - fec codes . with these goals in mind",
    ", we have designed the so - called structured random linear codes ( srlc ) @xcite.in the present work , as a first step to a complete evaluation , we only focus on use - cases that require only end - to - end encoding ( i.e. , there is a single end point for al - fec encoding / decoding , no matter whether this end is a `` host '' or a `` middlebox '' ) and we evaluate the srlc effectiveness in terms of erasure recovery performance only .",
    "the remainder of this paper is organized as follows : section  [ sec : related - work ] introduces related work .",
    "section  [ sec : prop - srlc ] describes the proposed structured random linear codes ( srlc ) in detail .",
    "section  [ sec : eval ] evaluates the recovery performances of srlc , and we conclude in section  [ sec : concl ] .",
    "in  @xcite batched sparse ( bats ) codes are proposed for file distribution through a communication network where intermediate nodes have coding capabilities  @xcite .",
    "these codes are designed so as to control the computational and storage requirements at the source , intermediate nodes , and destination , as well as the transmission overhead when transmitting the coding vector .",
    "this is made possible by the use of both an outer code ( sender ) , that forms `` batches '' of coded packets , using a specific distribution for defining the number of input packets considered to create each batch , and inner codes ( intermediate nodes ) that perform random linear codings of packets of a given batch .",
    "the authors show the good performance of these batch codes , when associated to `` inactivation decoding '' as in @xcite . in  @xcite , gamma codes",
    "are proposed as a family of sparse random linear network codes with outer code like bats codes .",
    "the codes also manage `` chunked '' encoded packets . the key idea is to enable the outer code to play as soon as the first chunked packets are recovered , which realizes a joint decoder scheme that coordinates a proper combination of an outer coding and a basic sparse random linear network coding .",
    "it was presented that gamma codes can achieve better reception overhead while keeping lower encoding / decoding complexity in fixed block length configuration .",
    "these works differ from ours .",
    "we designed rlc in order to be flexibly used as either block or convolutional codes , over wide ranges of block / encoding - window sizes .",
    "additionally , we do not distinguish outer / inner codes per se , but add a structure to the rlc approach in order to find an appropriate balance between computational complexity and erasure recovery performance .",
    "let us now describe the srlc codes , characterized by :    1 .   a mostly sparse binary structure , which reduces the number of symbol xor operations and improves iterative ( it)/structured gaussian elimination ( sge ) decodings  @xcite@xcite@xcite .",
    "it is a key feature to favor high speed encoding and decoding ; 2 .   a limited use of non - binary ( over @xmath0 ) coefficients in encoding vectors .",
    "it is a key feature to favor a good erasure recovery performance ; 3 .",
    "the addition of a dedicated repeat - and - accumulate structure ( as in irregular repeat - accumulate ( ira )  @xcite and ldpc - staircase codes ) .",
    "it is a second key feature to favor a good erasure recovery performance .    in the following ,",
    "we first explain the srlc approach when used in block mode , and later we extend it to the case of convolutional coding .",
    "the first idea consists in using both binary and non - binary coefficients .",
    "all the examples of this section are for the block mode case , when considering a fixed set of @xmath1 source symbols .",
    "[ fig : mix - bin - nonbin ] shows an example parity check matrix , @xmath2 , when the number of source symbols is fixed ( here @xmath3 source symbols ) and both binary and non - binary coefficients are used .",
    "the @xmath2 matrix is composed of two parts , the left side @xmath4 and the right side @xmath5 .",
    "the columns of @xmath4 correspond to the source symbols from @xmath6 to @xmath7 ( a.k.a .",
    "source packets ) , while those of @xmath5 correspond to the repair symbols to be generated ( a.k.a .",
    "repair packets ) .",
    "each row of @xmath4 represents a constraint ( or equation ) used for instance to generate the repair symbol of the same row . for example , the @xmath8 repair symbol in the first row is generated by '' coefficients are omitted . ] : @xmath9    three key parameters exist :    * @xmath1 : the source block length ( or encoding window size ) ; * @xmath10 : the density of each `` sparse binary sub - matrix '' , given as the ratio of the number of non - zero coefficients to the total number of coefficients in a sub - matrix : @xmath11 * @xmath12 : the ratio of the number of non - binary columns to @xmath1 ( i.e. , the total number of columns ) in @xmath4 : @xmath13    @xmath4 should be largely composed of sparse binary parts so that most equations are sparse with binary coefficients , because this is a key for high encoding / decoding speeds .",
    "however , a trade - off between speed and erasure recovery performance must be considered since being too sparse and binary negatively impacts the erasure recovery performance .",
    "[ fig : avg - ineff - binary - rlc ] shows the average erasure recovery performance of a fully binary rlc with various @xmath10 values as a function of @xmath1 .",
    "the performance metric is the `` average decoding inefficiency ratio '' , defined as the ratio of the average number of symbols needed for decoding to complete successfully to @xmath1 : @xmath14 where @xmath15 is called `` decoding overhead '' , and also often expressed as a percentage .",
    "the closer to @xmath16 ( achieved with ideal codes ) the ratio , the better . assuming that our target average decoding overhead is set ( arbitrarily ) to 0.1%",
    ", we can see in fig .",
    "[ fig : avg - ineff - binary - rlc ] that none of the codes achieves the goal , even with binary rlc ( where @xmath17 ) which performs the best .    on the opposite , we see in fig .  [ fig : avg - ineff - nonbin_1_40_-rlc ] that adding a few dense non - binary columns ( we used @xmath18 and the same values for @xmath10 ) , the target average decoding overhead is easily achieved with @xmath19 . and",
    "adding more non - binary columns easily enables to further improve the decoding performance with smaller @xmath1 values .",
    "we will address the question of what are the appropriate \\{@xmath12 , @xmath10 } tuples as a function of @xmath1 in section  [ subsec : add - structure ] .    in the srlc design , dense non - binary coefficients are always gathered in columns ( i.e. , assigned to certain symbols ) .",
    "the motivation is to enable the use of the high speed structured gaussian elimination optimization  @xcite . in this approach , when a stopping set is encountered during it decoding , certain well chosen symbols of the system ( i.e. , corresponding to unknown / non - recovered source symbols ) are logically removed from the linear system .",
    "this process enables it decoding to pursue .",
    "finally , decoding finishes with a classic gaussian elimination over the removed symbols , and their values are finally re - injected into equations where they were involved . because non - binary coefficients are affected to well identified source symbols , these symbols are immediately logically removed from the linear system .",
    "the linear system therefore remains a sparse binary system , not `` polluted '' by non binary coefficients , and most operations consist of fast xor operations over symbols , a key for high speed decoding .",
    "adding a structure to codes can be highly beneficial .",
    "for instance , the repeat - and - accumulate structure of ira and ldpc - staircase codes significantly improves their performance : because the number of source symbols a repair symbol actually depends on increases with its index , the erasure recovery performance is improved while keeping a sparse system .",
    "however , adding this particular structure would make signaling prohibitively complex when the codes are used in convolutional mode .        in order to solve this problem ,",
    "we propose to add a single accumulative row to create @xmath8 , defined as the `` heavy repair symbol '' , and to make all repair symbols depend upon @xmath8 .",
    "[ fig : srlc - block - example ] shows an example of the proposed srlc in block mode . in this example , @xmath20 is generated by : @xmath21    this simple structure enables a compact signaling to enable a receiver to determine the relationships between source and repair symbols .",
    "this is accomplished , in block mode , by the knowledge of the matrix generation algorithms ( specified in a non ambiguous way in the specifications ) , plus the \\{@xmath1 , @xmath12 , @xmath10 } tuple that is sent once at encoder / decoder synchronization time .",
    "because the full encoding vector is not sent along with repair packets ( it is useless if @xmath2 is known ) , the approach can scale with very large @xmath1 values .",
    "we will see in section  [ subsec : appli - convol ] how to perform signaling when srlc are used in a sliding window mode .",
    "let us now determine the most appropriate values for the \\{@xmath12 , @xmath10 } tuple for a given @xmath1 and target average performance .",
    "of course :    * @xmath12 should be as small as possible to reduce computation complexity , and * @xmath10 should be as small as possible so that it decoding performs well .    to find appropriate values , we did as described in algorithm  [ algo : find - value ] .",
    "we set the target average overhead to @xmath22 ( same value as in fig .",
    "[ fig : avg - ineff - nonbin_1_40_-rlc ] ) plus a security margin ( set to @xmath23 ) so as to accommodate some fluctuations during the optimization process . as a result",
    ", we obtain a table of \\{@xmath12 , @xmath10 } tuples , with an entry for each @xmath1 value .",
    "note that this table ( not reproduced here ) does not need to be sent to the receiver(s ) as the \\{@xmath1 , @xmath12 , @xmath10 } tuple is communicated at synchronization time to the receiver(s ) .",
    "this provides additional flexibility since the the target code performance may be changed dynamically for the following transfers , at the discretion of the sender .",
    "@xmath24 ; / * for instance * / @xmath25 ; / * for instance * / / * first of all , find @xmath12 if @xmath10 is set to @xmath23 * / @xmath26 ; @xmath27 ; @xmath28 @xmath29 ; @xmath30 ; break ;    / * then find smallest @xmath10 for the selected @xmath12 * / @xmath31 ; @xmath28 @xmath32 ; @xmath33 ; break ;    @xmath34 ;      @xmath35 ; / * reset to zero as well * / @xmath36 ; / * reset to zero * / @xmath37 ; @xmath38 ; @xmath39 ; @xmath40 @xmath41 ;    @xmath42 ; @xmath43 ; @xmath44 ; / * non - binary col . ,",
    "choose coeff randomly *",
    "/ @xmath45 ; @xmath46 ; / * binary column , choose 0 or 1 randomly * / @xmath47 ; @xmath48 ; @xmath49 ; @xmath50 ; @xmath51 ;    convolutional coding is appropriate to situations where a fully or partially reliable delivery of continuous data flows is needed , especially when these data flows feature real - time constraints , as in  @xcite .",
    "srlc can then be used as a convolutional code , in a systematic way ( i.e. , source symbols are sent on the network ) , as described in algorithm  [ algo : convol ] . the way the encoding window",
    "is managed ( i.e. , how to set the encoding window start and the number @xmath1 of source symbols in the window ) is a key aspect that depends on the protocol in use .",
    "[ fig : srlc - convol - example ] illustrates the use of srlc in the simple sliding window mode . here",
    "the encoding window has a fixed size , @xmath52 , and slides in a regular way over the source symbol flow . the target code rate ( @xmath53 is such that one repair symbol is sent after two source symbols .",
    "the only exception is at session start : the encoder waits for @xmath52 source symbols to be available , and then generates two repair symbols , including a heavy repair one , @xmath54 ( i.e. , the xor sum from @xmath6 to @xmath55 ) .",
    "then , after sending two more source symbols , @xmath56 and @xmath57 , the srlc encoder considers the union of the encoding windows since the previous repair computation ( i.e. , from @xmath58 to @xmath57 ) and generates a new repair symbol , @xmath59 .",
    "@xmath59 accumulates the current heavy repair symbol , @xmath60 ( i.e. , the xor sum from @xmath6 to @xmath57 ) to the encoding vector : @xmath61 here also , the encoding vector is set according to the \\{@xmath1 , @xmath12 , @xmath10 } tuple , using pre - calculated tables as described in section  [ subsec : add - structure ] , and a pseudo - random number generator ( prng ) that can be seeded by a specific value communicated to the receiver .",
    "note that the repair symbol identifier may be used as a seed .    from a signaling point of view",
    ", we can assume that the \\{@xmath1 , @xmath12 , @xmath10 } tuple and all the algorithms are known by both ends .",
    "in that case , it is sufficient for the sender to let the receiver know the union of the encoding windows considered ( e.g. , from @xmath58 to @xmath57 in the case of @xmath59 ) , the repair symbol identifier , along with the prng seed ( if different from the repair symbol identifier ) .",
    "this is all the srlc decoder needs to know to generate the constraint equation associated to this repair symbol , even for large encoding window sizes .    in practice ,",
    "the heavy repair symbols are transmitted periodically in order to remove the long term dependencies they create .",
    "this is useful if past source symbols remain impossible to recover by a given receiver ( who for instance joined the session late ) .",
    "in this section we evaluate the srlc erasure recovery performance both in block and convolutional modes .      all the tests are carried out with the performance evaluation tools provided by our ` openfec.org ` project  @xcite and a modified version of the ` kodo ` library  @xcite for the codec implementation .",
    "we use the pre - calculated values for \\{@xmath12 , @xmath10 } ( see algorithm  [ algo : find - value ] ) and we choose @xmath53 in all tests",
    ". however srlc is by nature rateless and the actual code rate is of little importance ( i.e. , the decoding overhead does not depend on the code rate ) . because we do not want to define any specific channel model ( e.g. , the two transition probabilities of a gilbert model ) , in all tests we assume the source and repair symbols are transmitted in a fully random order , which means that only the packet loss rate is of importance .",
    "finally we assume that gaussian elimination decoding is used for maximum performance , rather than it decoding ( we do not consider decoding speeds in this work ) .",
    "let us focus on the srlc in block mode .",
    "we measure both the average inefficiency ratio as a function of @xmath1 and the decoding failure probability as a function of the number of received symbols in addition to @xmath1 ( in both cases decoding is said to fail as soon as at least one erased source symbol can not be recovered ) .",
    "the first goal of tests is to demonstrate the efficiency of the use of a heavy repair symbol .",
    "the second goal is to assess the performance of srlc codes .",
    "however , due to the space limitations , we only show the results when @xmath1 is small , from 50 to 500 symbols .",
    "[ fig : avg - ineff - comp - heavyrepair ] compares the two options for @xmath63 or @xmath64 .",
    "we see the benefits of using the heavy repair symbol , especially when @xmath1 is small , on average .",
    "let us look at fig .",
    "[ fig : srlc - decfail ] , when @xmath65 and @xmath66 . in both cases ,",
    "the decoding failure probability curves are similar when the number of received symbols is only slightly higher than @xmath1 ( i.e. , for low overheads ) .",
    "however we clearly see a difference when the overhead is higher , meaning that there is a significant number of tests where decoding fails without any heavy repair symbol : @xmath67 extra symbols need to be received ( @xmath68% overhead ) for the decoding failure probability to go below @xmath69 . on the opposite ,",
    "the full featured srlc solution reaches a decoding failure probability lower than @xmath69 with 209 symbols only ( a @xmath70% overhead ) .",
    "[ fig : srlc - decfail]-(b ) also confirms the excellent recovery performance of srlc codes , not only on average , but also when looking precisely at the decoding failure probability .",
    "let us now consider srlc in convolutional mode .",
    "since we are focusing on real - time flows , like video / audio real - time streaming systems , a full reliability is not necessarily required ( this is different from typical use in block mode , for file transfer applications )",
    ". therefore we measure the srlc average source packet loss ratio ( once decoding is finished ) as a function of packet loss probability , and compare it with those of binary rlc ( i.e. , @xmath71 ) and of rlc over @xmath0 ( all coefficients are randomly chosen in @xmath0 ) .",
    "additionally , to make the comparison more visible , we measure the decoding failure probability of the three codes .    the performance results for the transmission of @xmath72 source symbols in total and a window of size @xmath73 symbols ,",
    "are shown in fig .",
    "[ fig : srlc - srcloss - convol ] .",
    "we see that srlc performs the best , even when compared to rlc over @xmath0 , which is exceptional .",
    "the performance results for a larger encoding window , of size @xmath74 symbols , are shown in fig .",
    "[ fig : srcloss - k100 ] .",
    "we see that all the average loss ratios improve when compared to the @xmath73 case , because a larger encoding window size offers better protection .",
    "therefore there is no significant differences among the three codes especially on average .",
    "however , when looking at the decoding failure probability in fig .",
    "[ fig : decfail - k100 ] , the srlc performance pronouncedly becomes worse than that of rlc codes over @xmath0 .",
    "one reason is that srlc uses the @xmath75 table optimized for the block mode case .",
    "a new table should be calculated for the convolutional case .",
    "this work introduces the srlc codes , an end - to - end al - fec solution that is sufficiently flexible to be applied in block mode and convolutional mode . in order to enable excellent erasure recovery performance as well as fast encoding and decoding speeds ,",
    "these codes have been designed in a manner that favors a mostly sparse and binary structure , with some well chosen non binary coefficients , plus a heavy binary row . additionally , the design is such that it facilitates an efficient signaling , the parameters exchanged to synchronize encoder and decoders being kept to a minimum .",
    "these considerations make srlc codes a very practical solution , no matter the block or encoding window size : small , medium or large .",
    "our evaluation of their erasure recovery performance confirms the benefits in future works we will analyze the encoding and decoding complexity ( similarly the associated speeds ) of srlc codes .",
    "we will also further optimize the value of the code internal parameters when used in convolutional mode , both in a fixed - size configuration and in elastic window configuration ( e.g. , as in  @xcite ) .",
    "t. paila , r. walsh , m. luby , v. roca , and r. lehtonen , `` flute - file delivery over unidirectional transport '' , ietf rmt working group , request for comments , rfc 6726 ( `` standards track / proposed standard '' ) , nov .",
    "a. yamada , h. matsuoka , t. ohya , r. kitahara , j. hagiwara , and t. morizumi , `` overview of isdb - tmm services and technologies '' , ieee international symposium on broadband multimedia systems and broadcasting ( bmsm11 ) , june 2011 .",
    "tournoux , e. lochin , j. lacan , a. bouabdallah , and v. roca , `` on the fly erasure coding for time - constrained applications '' , ieee transactions on multimedia , vol .",
    "797 - 812 , aug .",
    "s. nazir , d. vunkobratovi ' and v. stankovi , `` peformance evaluation of raptor and random linear codes for h.264/avc video transmission over dvb - h networks '' , ieee international conference on acoustics , speech and signal processing ( icassp11 ) , may 2011 .",
    "v. roca , m. cunche , c. thienot , j. detchart and j. lacan , `` rs+ldpc - staircase codes for the erasure channel : standards , usage and performance '' , ieee international conference on mobile computing , networking and communications ( wimob13 ) , nov . 2013 .",
    "v. roca , c. neumann and d. furodet , `` low density parity check ( ldpc ) staircase and triangle forward error correction ( fec ) schemes '' , ietf rmt working group , rfc 5170 ( `` standards track / proposed standard '' ) , june 2008 ."
  ],
  "abstract_text": [
    "<S> several types of al - fec ( application - level fec ) codes for the packet erasure channel exist . random linear codes ( rlc ) , where redundancy packets consist of random linear combinations of source packets over a certain finite field , are a simple yet efficient coding technique , for instance massively used for network coding applications . </S>",
    "<S> however the price to pay is a high encoding and decoding complexity , especially when working on @xmath0 , which seriously limits the number of packets in the encoding window . on the opposite , </S>",
    "<S> structured block codes have been designed for situations where the set of source packets is known in advance , for instance with file transfer applications . here </S>",
    "<S> the encoding and decoding complexity is controlled , even for huge block sizes , thanks to the sparse nature of the code and advanced decoding techniques that exploit this sparseness ( e.g. , structured gaussian elimination ) . </S>",
    "<S> but their design also prevents their use in convolutional use - cases featuring an encoding window that slides over a continuous set of incoming packets .    in this work </S>",
    "<S> we try to bridge the gap between these two code classes , bringing some structure to rlc codes in order to enlarge the use - cases where they can be efficiently used : in convolutional mode ( as any rlc code ) , but also in block mode with either tiny , medium or large block sizes . </S>",
    "<S> we also demonstrate how to design compact signaling for these codes ( for encoder / decoder synchronization ) , which is an essential practical aspect . </S>"
  ]
}