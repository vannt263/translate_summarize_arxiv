{
  "article_text": [
    "imagine writing low - level systems code in a purely functional language and then reasoning about this code equationally and productively in an interactive theorem prover .",
    "imagine doing this without the need for a trusted compiler , runtime or garbage collector and letting this code interoperate with native c parts of the system , including your own efficiently implemented and formally verified additional data types and operations .",
    "cogentachieves this goal by certified compilation from a high - level , pure , polymorphic , functional language with linear types , specifically designed for certain classes of systems code . for a given well - typed cogentprogram",
    ", the compiler will produce a high - level shallow embedding of the program s semantics in isabelle / hol  @xcite , and a theorem that connects this shallow embedding to the c code that the compiler produces :  any property proved of the shallow embedding is guaranteed to hold for the generated c.    the compilation target is c , because c is the language most existing systems code is written in , and because with the advent of tools like compcert  @xcite and gcc translation validation  @xcite , c is now a language with well understood semantics and existing formal verification infrastructure .",
    "if c is so great , why not verify c systems code directly ?",
    "after all , there is an ever growing list of successes @xcite in this space .",
    "the reason is simple : verification of manually written c programs remains expensive .",
    "just as high - level languages increase programmer productivity , they should also increase verification productivity .",
    "certifying compilation of a language with verification - friendly semantics is a key step in achieving this goal for cogent .",
    "the state of the art for certified compilation of a full featured functional language is cakeml  @xcite , which covers an entire ml dialect .",
    "cogentis targeted at a substantially different point in the design space .",
    "cakeml includes a verified runtime and garbage collector , while cogentworks hard to avoid these so it can be applicable to low - level embedded systems code .",
    "cakeml covers full turing - complete ml with complex semantics that works well for code written in theorem provers .",
    "cogentis a restricted language of total functions with intentionally simple semantics that are easy to reason about equationally .",
    "cakeml is great for application code ; cogentis great for systems code , especially layered systems code with minimal sharing such as the control code of file systems or network protocol stacks .",
    "cogentis not designed for systems code with closely - coupled , cross - cutting sharing , such as microkernels .",
    "cogent s main restrictions are the ( purposeful ) lack of recursion and iteration and its linear type system .",
    "the former ensures totality , which is important for both systems code correctness as well as for a simple shallow representation in higher - order logic .",
    "the latter is important for memory management and for making the transition from imperative c semantics to functional value semantics . even in the restricted target domains of cogent",
    ", real programs will of course contain some amount of iteration .",
    "this is where cogent s integrated foreign function interface comes in : the engineer provides her own verified data types and iterator interfaces in c and uses them seamlessly in cogent , including in formal reasoning .",
    "cogentis restricted , but it is not a toy language . we have used it to implement two efficient full - scale linux file systems  a custom flash file system and an implementation of standard linux ext2 .",
    "we plan to report on the experience with these implementations in separate work .",
    "the focus of this paper is what can be learned from cogentabout the formal verification of certifying compilation .",
    "in particular , this paper discusses in detail the following contributions :    the self - certifying cogentcompiler and language ;    the formal semantics of the cogentlanguage and the switch from imperative update semantics to functional value semantics formally justified by the linear type system ( ) ;    the top - level compiler certificate ( ) , which is a series of language - level meta proofs and per - program translation validation phases ;    the verification stages that make up the correctness theorem ( ) , including automated refinement calculi , formally verified type checking , a - normalisation , and monomorphisation ; and    the lessons learned in this project on functional language formalisation and compiler correctness proofs ( ) .",
    "our aim in this paper is to build a self - certifying compiler from cogentto efficient c code , such that a proof engineer can reason equationally about its semantics in isabelle / hol and apply the compiler theorem to derive properties about the generated c code .",
    "formally , the certificate theorem is a refinement statement between the shallow embedding and the c code .",
    "this generated c code can be compiled by compcert .",
    "it also falls into the subset of the gcc translation validation tool by @xcite , whose theorem would compose directly with our compiler certificate .",
    "shallow embeddings are nice for the human user , but they do not provide much syntactic structure for constructing the compiler theorem . therefore , the compiler also generates a deep embedding for each cogentprogram to use in the internal proof chain .",
    "there are two semantics for this deep embedding .    a formal functional _ value semantics _ where programs evaluate to values and    a formal imperative _ update semantics _ where programs manipulate references to mutable global state",
    ".        shows an overview of the program representations generated by the compiler and the break - down of the automatic refinement proof that makes up the compiler certificate .",
    "the program representations are , from the bottom of : the c code , the semantics of the c code expressed in isabelle / simpl  @xcite , the same expressed as a monadic functional program  @xcite , a monomorphic a - normal deep embedding of the cogentprogram , a polymorphic a - normal deep embedding of the same , an a - normal shallow embedding , and finally a ` neat ' shallow embedding of the cogentprogram that is syntactically close to the cogentinput of the compiler .",
    "most of the theorems assume that the cogentprogram is well - typed , which is discharged automatically in isabelle with type inference information from the compiler .",
    "the solid arrows on the right - hand side of the figure represent refinement proofs and the labels on these arrows correspond to the numbers in the following description .",
    "the only arrow that is not formally verified is the one crossing from c code into isabelle / hol at the bottom of  this is the c - to - isabelle parser  @xcite , which is a mature verification tool used in a number of large - scale verifications . as mentioned , it could additionally be checked by translation validation .",
    "we briefly describe each intermediate theorem , starting with the simpl code at the bottom of the figure . for well - typed cogentprograms ,",
    "we automatically prove :    1 .",
    "theorem : the simpl code produced by the c parser corresponds to a monadic representation of the c code .",
    "the proof is generated using an adjusted version of the autocorres tool .",
    "theorem : the monadic program terminates and is a refinement of the monomorphic cogentdeep embedding under the update semantics . 3 .",
    "theorem : if a cogentdeep embedding evaluates in the update semantics then it evaluates to the same result in the value semantics .",
    "this is a known consequence of linear type systems  @xcite , but to our knowledge it is the first mechanised proof of such a property , esp .  for a full - scale language .",
    "theorem : if a monomorphic cogentdeep embedding evaluates in the value semantics then the polymorphic deep embedding evaluates equivalently in the value semantics . 5 .",
    "theorem : if the polymorphic cogentdeep embedding evaluates in the value semantics then the cogentshallow embedding evaluates to a corresponding shallow isabelle / hol value .",
    "theorem : the a - normal shallow embedding is ( extensionally ) equal in isabelle / hol to a syntactically neater shallow embedding , which is more convenient for human reasoning .",
    "this human - friendly shallow embedding corresponds to the cogentcode before the compiler s a - normalisation phase .",
    "arrow 7 indicates verification of user - supplied abstract data types ( adts ) implemented in c and further manual high - level proofs on top of the human - friendly shallow embedding .",
    "these are enabled by the previous steps , but are not part of this paper .    in",
    "we define in more detail the relations that formally link the values ( and states , when applicable ) that these programs evaluate to .",
    "steps ( 3 ) and ( 4 ) are general properties about the language and we therefore prove them manually once and for all .",
    "steps ( 1 ) , ( 2 ) , ( 5 ) , and ( 6 ) are generated by the compiler for every program .",
    "the proof for step ( 1 ) is generated by autocorres .",
    "for steps ( 2 ) and ( 5 ) we define compositional refinement calculi that ease the automation of these proofs .",
    "step ( 6 ) , the correctness of a - normalisation , is straightforward to prove via rewriting because at this stage we can already use equational reasoning .",
    "in this section we formally define cogent , including its linear type system , its two dynamic semantics  update and value  mentioned earlier in , and the refinement theorem between them .",
    "we begin the section by walking through an example cogentprograms",
    ".      shows an excerpt of our cogentext2 implementation .",
    "the example uses not all , but many features of the language .    ....",
    "type exst type uarray a type opt a = < none ( ) | some a > type node = # { mbuf : opt buf , ptr : u32 , fr : u32 , to : u32 } type acc = ( exst , fsst , vfsinode ) type cnt = ( uarray node ,     ( u32 , node , acc , u32 , uarray node ) - > ( node , acc ) )    uarray_create : all ( a : < e ) .",
    "( exst , u32 )     - > < success ( exst , uarray a ) | err exst >    ext2_free_branch : ( u32 , node , acc , u32 )     - > ( node , acc , < expd cnt | iter ( ) > ext2_free_branch ( depth , nd,(ex , fs , inode),mdep ) =    if depth + 1 < mdep       then        uarray_create[node ] ( ex , nd.to - nd.fr ) !",
    "nd        | success ( ex , children ) = >          let nd_t { mbuf } = nd          and ( children , ( ex , inode , _ , mbuf ) ) =             uarray_map_no_break # {              arr   = children ,              f     = ext2_free_branch_entry ,              acc   = ( ex , inode , node_t.fr , mbuf ) ,              ... } !",
    "nd_t          and nd = nd_t { mbuf }          in ( nd , ( ex , fs , inode ) ,             expd ( children , ext2_free_branch_cleanup ) )        | err ex - > ( nd , ( ex , fs , inode ) , iter ( ) )      else ... ....    the first line in shows the cogentside of the foreign function interface",
    ". it declares an abstract cogentdata type  `` , implemented in c. line 2 shows a parametric abstract type , and line 9 shows a corresponding abstract function  ` ( ) ` , also implemented in c. note that this abstract function is polymorphic , with a kind constraint  @xmath0 ( see ) on type argument ` a ` .",
    "the integration of such foreign functions is seamless on the cogentside , but naturally has requirements on the corresponding c code .",
    "the c side must respect the cogenttype system , and , for example , keep all shared state internal to the abstract type to comply with linearity constraints .",
    "it must also be terminating and implement the user - supplied semantics that appear in the corresponding shallow embedding of the cogentprogram in isabelle / hol  ideally the user should provide a formal proof to discharge the corresponding assumption of the compiler certificate theorem .",
    "abstract functions can be higher - order and provide the iteration constructs that are intentionally left out from core cogent .",
    "e.g.  line 21 , ` ( ) ` implements a map iterator for arrays . in our file system applications",
    "we have found it sufficient to provide a small library of iterators for types such as arrays .",
    "we also interfaced to an existing mature red - black tree implementation .",
    "returning to the example in , lines 37 show basic type constructors and declarations of variants , records and tuples using type variables and the primitive type `` .",
    "for instance , type `` is defined as a pair of `` and a function type .",
    "types in cogentare structural  @xcite , i.e.  two types with the same structure but different names are intensionally equal .",
    "moreover , line 17 calls the abstract polymorphic function ` ( ) ` , instantiated with type argument `` .",
    "nd ` notation temporarily turns a linear object of type `` into a read - only one ( see ) .",
    "the two basic , non - linear fields ` to ` and ` fr ` in type `` can directly be accessed read - only using projection functions .",
    "line 18 and 29 are pattern matches on the result of the function invocation .",
    "line 19 shows surface syntax for cogent s linear * take * construct ( see ) , accessing and binding the ` mbuf ` field of ` nd ` to the name  ` mbuf ` ( punning as in haskell ) , as well as binding the rest of the record to the name ` nd_t ` .",
    "the linear type system tracks that the field ` mbuf ` is logically absent in ` nd_t ` .",
    "it also tracks that ` nd ` on line 19 has been used , so can not be accessed again .",
    "thus the programmer is safe to bind a new object to the same name ` nd ` ( on line 26 ) without worrying about name shadowing .",
    "line 26 shows surface syntax for @xmath1 , the dual to @xmath2 , which re - establishes the ` mbuf ` fields in the example .",
    "@xcite first noted that linear types can be used as a way to safely model mutable state and similar effects while maintaining a purely functional semantics .",
    "@xcite later proved wadler s intuition by showing that , for a linear language , imperative c code can implement a simple set - theoretic semantics .",
    "we use linear types for two reasons : to ensure safe handling of heap - allocated objects , without the need for runtime support , and to allow us to assign to cogentprograms a simple , equational , purely functional semantics implemented via mutable state and imperative effects .",
    "& t & & + & , & & + & & & t + & & & + & & & + & & = & \\ { , , } + & & & + & & : : = & + & m & & + & & & , + & & & , + & & & + & & &     +    [ cols= \" < , < \" , ]     ( @xmath3 indicates lists , i.e. zero or more )    the type structure and associated syntax of cogentis presented in .",
    "our type system is loosely based on the polymorphic @xmath4 of @xcite .",
    "we restrict this polymorphism to be rank-1 and predicative , in the style of ml , to permit easy implementation by specialisation with minimal performance penalty . to ease implementation , and to eliminate any direct dependency on a heap allocator , we require that all functions be defined on the top - level .",
    "this eliminates the need for linear function types : any top - level function can be shared freely because they can not capture _ any _ local variables , let alone linear ones .",
    "we include a set of primitive integer types ( @xmath5 , @xmath6 etc . ) .",
    "records @xmath7 comprise ( 1 )  a sequence of fields @xmath8 , where @xmath9 is the type on an inaccessible field , and ( 2 )  a mode @xmath10 ( see and for a more detailed description ) .",
    "we also have polymorphic variants @xmath11 , a generalised sum type in the style of ocaml , the mechanics of which are briefly described in .",
    "abstract types @xmath12 are also parametrised by modes .",
    "we omit product types from this presentation ; they are desugared into unboxed records .",
    "the most obvious similarity to @xmath4 is our use of _ kinds _ to determine if a type may be freely shared or discarded , as opposed to earlier linear type systems , such as that of  @xcite , where a type s linearity is encoded directly into its syntactic structure .",
    "kinds in cogentare sets of _ permissions _ , denoting whether a variable of that type may be discarded without being used ( @xmath13 ) , shared freely and used multiple times ( @xmath14 ) , or safely bound in a @xmath15 expression ( @xmath0 ) . a _ linear _ type , values of which must be used exactly once , has a kind that excludes  @xmath13 and  @xmath14 , and so forbids it being discarded or shared .",
    "we discuss @xmath15 expressions in .",
    "another similarity to @xmath4 is that we explicitly represent the context operations of weakening and contraction , normally relegated to structural rules , as explicit judgements : @xmath16 for weakening ( discarding assumptions ) and @xmath17 for contraction ( duplicating them ) .",
    "the rules for these judgements are presented in . for a typing assumption to be discarded (",
    "respectively duplicated ) , the type must have kind @xmath18 ( resp .",
    "@xmath19 ) .",
    "+   +   +   +    @xmath20 @xmath21 @xmath22    the full kinding rules for the types of cogentare given in .",
    "basic types such as @xmath23 or @xmath5 , as well as functions , are simply passed by value and do not contain any heap references , so they may be given any kind .",
    "kinding for structures and abstract functions is discussed shortly in .",
    "a type may have multiple kinds , as a nonlinear type assumption may be used linearly , never being shared and being used exactly once .",
    "therefore , a type with a permissive kind , such as @xmath24 , would be an acceptable instantiation of a type variable of kind @xmath25 , as we are free to _ waive _ permissions that are included in a kind .",
    "we can prove formally by straightforward rule induction :    if @xmath26 and @xmath27 , then @xmath28 .",
    "this result allows for a simple kind - checking algorithm , not immediately apparent from the rules .",
    "for example , the maximal kind of an unboxed structure with two fields of type @xmath29 and @xmath30 respectively can be computed by taking the intersection of the computed maximal kinds of @xmath29 and @xmath30 .",
    "this result ensures that this intersection is also a valid kind for @xmath29 and @xmath30 .",
    "recall that cogentmay be extended with _ abstract types _ , implemented in c , which we write as @xmath31 in our formalisation .",
    "we allow abstract types to take any number of _ type parameters _",
    "@xmath32 , where each specific instance corresponds to a distinct c type . for example , a @xmath33 abstract type , parameterised by its element type , would correspond to a family of c @xmath33 types , each one specialised to a particular concrete element type . because the implementations of these types are user supplied , the user is free to specialise implementations based on these type parameters , for example representing an array of boolean values as a bitstring , so long as they can show that every different operation implementation is a refinement of the same user - supplied cdsl semantics for that operation .",
    "values of abstract types may be represented by references to heap data structures .",
    "specifically , an abstract type or structure is stored on the heap when its associated _ storage mode _",
    "@xmath10 is not `` '' . for boxed records and abstract types",
    ", the storage mode distinguishes between those that are `` '' vs. `` '' .",
    "the same is true for record types , written @xmath7 , which are discussed in more detail in .    the storage mode @xmath10 affects the maximal kind that can be assigned to the type .",
    "for example , an unboxed structure with two components of type @xmath5 is freely shareable , but if the structure is instead stored on the heap , then a writable reference to that structure must be linear .",
    "thus , the type given to such references has the `` @xmath34 '' mode , whose kind is @xmath35 , thereby preventing such a reference from being assigned a nonlinear kind such as @xmath36 .      like @xcite",
    ", we allow linear values to be shared read - only in a limited scope .",
    "this is useful for practical programming in a language with linear types , as it makes our types more informative .",
    "for example , to write a function to determine the size of a ( linear ) buffer object , a naive approach would be to write a function : @xmath38 this function has a cumbersome additional return value just so that the linear argument is not discarded .",
    "further , the type above does not express the fact that the input buffer and output buffer are identical  this would need to be established by additional proof . to address this problem",
    ", we include a type operator  @xmath39 , in the style of wadler s @xmath40 operator , which changes all writable modes in a type to read - only ones .",
    "the full definition of @xmath39 is in .",
    "we can therefore write the type of our function as : @xmath41 for any valid type @xmath42 , the kind of @xmath43 will be nonlinear , which means that our @xmath44 function no longer needs to be encumbered by the extra return value .",
    "this kinding result is formally stated as :    for any type @xmath42 , if @xmath26 then @xmath45 .    to integrate this type operator with parametric polymorphism",
    ", we borrow a trick from odersky s observer types  @xcite , and tag type variables that have been made read only , using the syntax @xmath46 .",
    "whenever a variable @xmath47 is instantiated to some concrete type @xmath42 , we also replace @xmath46 with @xmath43 .",
    "the lemma above ensures that our kinding rule for such tagged variables is sound , and enables us to prove the following :    for any type @xmath42 , @xmath48 implies @xmath49 when , for each @xmath50 , @xmath51 .",
    "& o & & \\{`+ ` , ` * ` , ` / ` , ` < = ` , ` = = ` , ` || ` , ` < < ` ,",
    " } + & & & \\{123 , , ` a ` ,  }",
    "+ & e & & + & & & + & & & + & & & + & & & + & & & + & & & + & & & + & & & + & d & & + & p & & + & & & , + & & & , + & & & , , + & & & , +    @xmath52    while cogentfeatures a rich surface syntax , due to space constraints , we only document the ( full ) core language in to which the surface syntax is desugared .",
    "+   +    p0.625|p0.25    c +   +   +    &     +     +   +    shows the typing rules for cogentexpressions .",
    "many of these are standard for any linear type system .",
    "we will discuss here the rules for @xmath15 , where we have taken a slightly different approach to established literature , and the rules for the extensions we have made to the type system , such as variants and record types .",
    "on the expression level , the programmer can use @xmath15 expressions , in the style of @xcite , to temporarily convert variables of linear types to their read - only equivalents , allowing them to be freely shared . in this example",
    ", we wish to copy a buffer @xmath53 onto a buffer @xmath54 only when @xmath53 will fit inside @xmath54 .",
    "@xmath55 note that even though @xmath54 and @xmath53 are used multiple times , they are only used once in a linear context . inside",
    "the @xmath15 binding , they have been made temporarily nonlinear .",
    "our kind system ensures these read - only , shareable references inside @xmath15 bindings can not `` escape '' into the outside context .",
    "for example , the expression @xmath56 would violate the invariants of the linear type system , and ruin the purely functional abstraction that linear types allow , as both @xmath57 and @xmath58 would refer to the same object , and a destructive update to @xmath57 would change the shareable @xmath58 .",
    "we are able to use the existing kind system to handle these safety checks with the inclusion of the @xmath0 permission , for @xmath0scapable , which indicates that the type may be safely returned from within a @xmath15 .",
    "we ensure , via the typing rules of , that the left hand side of the binding ( @xmath59 in the example ) has the @xmath0 permission , which excludes temporarily nonlinear references via @xmath39 ( see ) .",
    "our solution is as powerful as odersky s , but we encode the restrictions in the kind system directly , not as side - condition constraints that recursively descend into the structure of the binding s type .",
    "a variant type @xmath60 is a generalised sum type , where each alternative is distinguished by a unique _ data constructor",
    "_  @xmath61 .",
    "the order in which the constructors appear in the type is not important .",
    "one can create a variant type with a single alternative simply by invoking a constructor , e.g. @xmath62 might be given the type @xmath63 .",
    "the original value of @xmath64 can be retrieved using the @xmath65 construct .",
    "the set of alternatives is enlarged by using @xmath66 expressions that are automatically inserted by the type - checker of the surface language , which uses subtyping to infer the type of a given variant .",
    "a similar trick is used for numeric literals and @xmath67 .    in order to pattern match on a variant ,",
    "we provide a @xmath68 construct that attempts to match against one constructor .",
    "if the constructor does not match , it is _ removed _ from the type and the reduced type is provided to the @xmath69 branch . in this way , a traditional multi - way pattern match can be desugared by nesting : @xmath70 note that because the typing rule for @xmath65 only applies when only one alternative remains , our pattern matching is necessarily total .",
    "some care is needed to reconcile record types and linear types .",
    "assume that @xmath71 is a type synonym for an ( unboxed ) record type containing an integer and two ( linear ) buffers .",
    "@xmath72 let us say we want to extract the field @xmath73 from an @xmath71 .",
    "if we extract just a single @xmath74 , we have implicitly discarded the other buffer @xmath75 .",
    "but , we ca nt return the entire @xmath71 along with the @xmath74 , as this would introduce aliasing .",
    "our solution is to return along with the @xmath74 an @xmath71 where the field @xmath73 can not be extracted again , and reflect this in the field s type , written as @xmath76 .",
    "this field extractor , whose general form is @xmath77 , operates as follows : given a record  @xmath78 , it binds the field @xmath79 of @xmath78 to the variable @xmath80 , and the new record to the variable @xmath81 in @xmath82 . unless the type of the field @xmath79 has kind @xmath19 , that field will be marked as unavailable , or _ taken _ , in the type of the new record @xmath81 .",
    "conversely , we also introduce a @xmath1 operation , which , given a record with a taken field , allows a new value to be supplied in its place . the expression @xmath83 returns the record in @xmath78 where the field @xmath79 has been replaced with the result of @xmath82 . unless the type of the field @xmath79 has kind @xmath18 , that field must already be taken , to avoid accidentally destroying our only reference to a linear resource .",
    "unboxed records can be created using a simple struct literal @xmath84 .",
    "we also allow records to be stored on the heap to minimise unnecessary copying , as unboxed records are passed by value .",
    "these boxed records are created by invoking an externally - defined c allocator function . for these allocation functions",
    ", it is often convenient to allocate a record with all fields already taken , to indicate that they are uninitialised .",
    "thus a function for allocating ` object`-like records might return values of type : @xmath85 .",
    "for any nonlinear record ( that is , ( 1 )  read - only boxed records , which can not have linear fields , as well as  ( 2 )  unboxed records without linear fields ) we also allow traditional member syntax @xmath86 for field access .",
    "the typing rules for all of these expressions are given in .",
    "as mentioned earlier , we implement parametric polymorphism by specialising code to avoid paying the performance penalties of other approaches such as boxing .",
    "this means that polymorphism in our language is restricted to predicative rank-1 quantifiers .",
    "this allows us to specify dynamic objects , such as our value typing relations ( see ) and our dynamic semantics ( see ) , in terms of simple monomorphic types , without type variables .",
    "thus , in order to evaluate a polymorphic program , each type variable must first be instantiated to a monomorphic type .",
    "we show that typing of the instantiated program follows from the typing of the polymorphic program , if the type instantiation used matches the kinds of the type variables .",
    "[ lemma : spec ] @xmath87 implies @xmath88 when , for each @xmath50 , @xmath51 .",
    "the above lemma is sufficient to show the monomorphic instantiation case , by setting @xmath89 ( the empty context ) .",
    "this lemma is a key ingredient for the refinement link between polymorphic and monomorphic deep embeddings ( see ) .      &",
    "v & & + & & & & + & & & & + & & & & + & & & & + & & & a_v & + & v & & + & a_v    @xmath90    & u & & + & & & & + & & & & + & & & & + & & & & + & & & a_u & + & & & p & + & u & & + & p & & + & a_u & & +    @xmath91    defines the big - step evaluation rules for the _ value _ semantics of cogent .",
    "the relation states that under environment @xmath92 , the expression @xmath93 evaluates to a resultant value @xmath94 .",
    "these values are documented in . in many ways ,",
    "the semantics is entirely typical of a purely functional language , albeit with some care to handle abstract function calls appropriately .",
    "this is intentional , since our goal is to automatically produce a purely functional shallow embedding from this semantics .",
    "as functions must be defined on the top level , our function values @xmath95 consist only of an unevaluated expression , which is evaluated when the function is applied .",
    "abstract function values , written @xmath96 , are instead passed more indirectly , as a pair of the function name and a list of the types used to instantiate any type variables .",
    "when an abstract function value @xmath96 is applied , the user - supplied semantics @xmath97 are invoked , which is simply a function from input value to output value .",
    "the _ update _ semantics , by contrast , is much more imperative .",
    "the semantic rules can also be found in , with associated definitions in .",
    "this semantics is also an evaluation semantics , written @xmath98 in the style of  @xcite .",
    "values in the update semantics may now be _ pointers _",
    ", written @xmath99 , to values in a mutable store or _ heap _",
    "this mutable store is modelled as a partial function from a pointer to an update semantics value .",
    "most of the rules in only differ from the value semantics in that they thread the store  @xmath100 through the evaluation of the program . however , the key differences arise in the treatment of records and of abstract types , which may now be represented as _ boxed _ structures , stored on the heap . in particular , note that the rule @xmath101 destructively updates the heap , instead of creating a new record value , and the semantics of abstract functions @xmath102 may also modify the heap .     +   +",
    "vprom +   +     +   + uprom +     +      in order to show that the update semantics is a refinement of the value semantics , we must exploit the information given to us by cogent s linear type system . a typical refinement approach to relate the two semantics would be to define a correspondence relation between update semantics states and value semantics values , and show that an update semantics evaluation implies a corresponding value semantics evaluation .",
    "however , such a statement is not true if aliasing exists , as a destructive update ( from , say , @xmath1 ) would result in multiple values being changed in the update semantics but not necessarily in the value semantics .",
    "as our type system forbids aliasing of writable references , we must include this information in our correspondence relation .",
    "written as @xmath103 $ ] , this relation states that the update semantics value @xmath104 with store @xmath100 corresponds to the value semantics value @xmath94 , which both have the type @xmath42 .",
    "the sets @xmath105 and @xmath106 contain all pointers accessible from the value @xmath104 that are read - only and writable respectively .",
    "we use this to encode the uniqueness property ensured by linear types as explicit non - aliasing constraints in the rules for the correspondence relation , which are given in .",
    "read - only pointers may alias other read - only pointers , but writable pointers do not alias any other pointer , whether read - only or writable .    because our correspondence relation includes types",
    ", it naturally implies a value typing relation for both value semantics ( written @xmath107 ) and update semantics ( written @xmath108 $ ] ) .",
    "in fact , the rules for both relations can be derived from the rules in simply by erasing either the value semantics parts ( highlighted like ) or the update semantics parts ( highlighted like ) .",
    "as we ultimately prove preservation for this correspondence relation across evaluation , this same erasure strategy can be applied to our proofs to produce a type preservation proof for either semantics .",
    "[ [ formalising - uniqueness ] ] formalising uniqueness + + + + + + + + + + + + + + + + + + + + + +    with this correspondence relation , we can prove our intuitions about linear types .",
    "for example , the following lemma , which shows that we do not discard any unique writable reference via weakening , makes use of the fact that a value is only given a discardable type when it contains no writable pointers .",
    "@xmath109 if @xmath110 and @xmath111 then there exists such that @xmath112 .",
    "we also prove a similar lemma about our context splitting judgement , which uses the fact that a value is only given a shareable type when it contains no writable pointers to conclude that the two output contexts give access to non - aliasing sets of writable pointers .",
    "@xmath109    if @xmath110 and @xmath113 then there exists and where and , such that @xmath114 and @xmath115 and .",
    "in addition , we prove our main intuition about @xmath39 , necessary for showing refinement for @xmath15 expressions .    @xmath109    if @xmath116",
    "then @xmath117    [ [ dealing - with - mutable - state ] ] dealing with mutable state + + + + + + + + + + + + + + + + + + + + + + + + + +    we define a _ framing _ relation which specifies exactly how evaluation may affect the mutable store @xmath100 . given an input set of writable pointers @xmath118 , an input store @xmath119 , an output set of pointers @xmath120 and an output store @xmath121 , the relation , written @xmath122 , ensures three properties for any pointer @xmath99 :    inertia : :    if @xmath123 , then    @xmath124 .",
    "leak freedom : :    if @xmath125 and @xmath126 , then    @xmath127 .",
    "fresh allocation : :    if @xmath128 and @xmath129 , then    @xmath130 .    framing implies that our correspondence relation , for both values and environments , is unaffected by unrelated store updates :    assume two unrelated pointer sets and that , then    * if @xmath116 then @xmath131 and . * if @xmath110 then @xmath132 and .    [ [ refinement - and - preservation ] ] refinement and preservation + + + + + + + + + + + + + + + + + + + + + + + + + + +    with the above lemmas and definitions , we are able to prove refinement between the value and the update semantics .",
    "this of course requires us to assume the same for the semantics given to abstract functions , @xmath133 and @xmath102 .",
    "let @xmath79 be an abstract function with type signature @xmath134 , and @xmath135 be an instantiation of the type variables @xmath136 such that for each @xmath50 , @xmath137 .",
    "let @xmath138 and @xmath139 be update- and value - semantics values such that @xmath140 .",
    "the user - supplied meaning of @xmath79 in each semantics gives @xmath141 and @xmath142 .",
    "then , there exists and such that @xmath143 and .",
    "we first prove that the correspondence relation is preserved when both semantics evaluate from corresponding environments . by erasing one semantics ,",
    "this becomes a type preservation theorem for the other .",
    "due to space constraints , we omit the details of the proof in this paper , but the full proof is available in our isabelle / hol formalisation .",
    "@xmath109 [ thm : preservation ] if @xmath144 and @xmath110 and @xmath145 and @xmath146 , then there exists and such that @xmath147 and .    in order to prove refinement , we must show that every evaluation on the concrete update semantics has a corresponding evaluation in the abstract value semantics . while already gets us most of the way there , we still need to prove that the value semantics can evaluate whenever the update semantics does .",
    "@xmath109    if @xmath144 and @xmath148 and @xmath98 , then there exists a @xmath94 such that @xmath149    composing this lemma and , we can now easily prove our desired refinement statement .",
    "[ thm : updvalrefinement ]    if @xmath144 and @xmath148 and @xmath98 , then there exists a value @xmath94 and pointer sets @xmath150 and @xmath151 such that @xmath149 , and @xmath152 and @xmath153",
    ".     +   +   +   +    &     +   +",
    "with the formal semantics of cogentavailable , this section describes each of the proof steps that make up the compiler certificate , depicted in in .",
    "we start by describing the top - level theorem that forms the program certificate , emitted by the compiler .",
    "recall that for a well - typed cogentprogram , the compiler produces c code , a shallow embedding in isabelle / hol , and a refinement proof between them .",
    "we say a c program correctly implements its cogentshallow embedding if the following holds :    the c program terminates with defined execution ; and    if the initial c state and cogentstore are related , and the input values of the programs are related , then their output values are related .",
    "this means , the compiler correctness theorem states that a _ value relation _ is preserved .",
    "this relation is concrete and can be inspected . in  , we introduced a value typing relation between update semantics and value semantics . at each other refinement stage in the following sections",
    ", we will introduce a further relation between values of the two respective programs . by composing these value relations ,",
    "we get the value relation @xmath154 between the result @xmath155 of the c program @xmath156 and the shallow embedding @xmath157 by going through the intermediate update semantics value @xmath104 and value semantics result @xmath94 .",
    "note that the relation in   also depends on a cogentstore @xmath100 .",
    "the c state and cogentstore are related using the _ state relation _ , defined in detail in .",
    "let @xmath158 and @xmath159 ( defined in  ) be two functions that monomorphise expressions and ( function ) values , respectively , using a rename function provided by the compiler .",
    "further , let @xmath160 be a state relation , @xmath157 a shallow embedding , @xmath93 a monomorphic deep embedding , @xmath156 a c program , @xmath100 a cogentstore and @xmath161 a c state",
    ". then we define @xmath162 as follows : + if ( @xmath163 and @xmath164 , then @xmath156 successfully terminates starting at @xmath161 ; and after executing @xmath156 , for any resulting value @xmath155 and state @xmath165 , there exist @xmath166 , @xmath104 , and @xmath94 such that : @xmath167    given a cogentfunction  @xmath79 that takes @xmath81 of type @xmath42 as input , let  @xmath156 be its generated c code , @xmath157 its shallow embedding , and @xmath93 its deep embedding .",
    "let  @xmath155 be an argument of  @xmath156 , and  @xmath104 and @xmath94 be the update and value semantics arguments , of appropriate type , for  @xmath79 . if @xmath105 is injective , then @xmath168    this top - level refinement theorem additionally assumes that abstract functions in the program adhere to their specification and that their behaviour remains the same when they are monomorphised .",
    "intuitively , this theorem states that for related input values , all programs in the refinement chain evaluate to related output values .",
    "this can of course be used to deduce that there exist intermediate programs through which the c code and its shallow embedding are directly related .",
    "the proof engineer does not need to care what those intermediate programs are .",
    "before we present each refinement step , we briefly describe the well - typing theorems that are used in these steps .",
    "the cogentcompiler proves , via an automated isabelle / hol tactic , that the monomorphic deep embedding of the input program is well - typed .",
    "specifically , the compiler defines @xmath169 in isabelle / hol and proves that each cogentfunction  @xmath170 is well - typed in accordance with its type as given by @xmath169 .",
    "polymorphic well - typing is derived generically in the monomorphisation proof in .",
    "let  @xmath79 be a ( monomorphic ) cogentfunction , where",
    ". then @xmath171 .",
    "because , as we will see in , proving refinement requires access to the typing judgements for program sub - expressions and not just for the top level , the cogentcompiler also instructs isabelle to store all of the intermediate typing judgements established during type checking .",
    "these theorems are stored in a tree structure , isomorphic to the type derivation tree for the cogentprogram .",
    "each node is a typing theorem for a sub - expression of the program .",
    "this section describes the first three transformations from in . in the first step",
    ", the c code is converted to simpl  @xcite by the c - to - isabelle parser  @xcite , used in the sel4 project  @xcite .",
    "this step is kept as simple as possible and makes no effort to abstract from the details of c.    the second step in , which is the first link in the formal refinement chain , applies a modified version of the autocorres tool to produce a _ monadic _ shallow embedding of the c code semantics , and additionally proves that the simpl c semantics is a refinement of the monadic shallow embedding .",
    "we modify autocorres to make its output more predictable by switching off its control - flow simplification and forcing it to always output the shallow embedding in the _ nondeterministic state monad _ of  @xcite . in this monad",
    ", computation is represented by functions of type @xmath172 . here",
    "@xmath173 is the global state of the c program , including global variables , while @xmath47 is the return - type of the computation .",
    "a computation takes as input the global state and returns a set , , of pairs with new state and result value .",
    "additionally the computation returns a boolean , , indicating whether it failed ( e.g. whether there was undefined behaviour ) .",
    "while autocorres was designed to facilitate manual reasoning about c code , here we use it as the foundation for automatically proving correspondence to the cogentinput program .",
    "one of the main benefits autocorres gives us is a _ typed _ memory model .",
    "specifically , the @xmath173 of the autocorres monadic representation contains a set of _ typed heaps _ , each of type  @xmath174 , one for each type  @xmath47 used on the heap in the c input program .",
    "proving that the autocorres - generated monadic embedding never fails implies that the c code is type- and memory - safe , and is free of undefined behaviour  @xcite .",
    "we prove non - failure as a side - condition of the refinement statement from the autocorres shallow embedding to the cogentmonomorphic deep embedding in its update semantics , essentially using cogent s type system to guarantee c memory safety during execution .",
    "this refinement proof is the third step in . to phrase the refinement statement we first define how deeply - embedded cogentvalues and types relate to their corresponding monadic shallowly - embedded c values .",
    "the value - mapping is captured by the _ value relation _",
    "@xmath175 , defined in isabelle / hol automatically by the cogentcompiler using ad hoc overloading .",
    "@xmath175 is defined separately for each cogentprogram because the types used in the shallow c embedding depend on those used in the c program as , e.g. , c structs are represented directly as isabelle / hol records .",
    "the type relation @xmath176 is used to determine , for a cogentvalue  @xmath94 of type @xmath42 , which typed heap in the state of the monadic shallow embedding  @xmath94 should appear in . as with @xmath175",
    "it is defined automatically for each cogentprogram .    given @xmath175 and  @xmath176 for a particular cogentprogram , the _ state relation _",
    "@xmath177 defines the correspondence between the store  @xmath100 over which the cogentupdate semantics operates , and the state  @xmath161 of the monadic shallow embedding .",
    "@xmath178 if and only if : for all pointers  @xmath99 in the domain of @xmath100 , there exists a value  @xmath94 in the appropriate heap of  @xmath161 ( as defined by @xmath176 ) at location  @xmath99 , such that @xmath179 holds .    with @xmath177 and @xmath175 , we define refinement generically between a monadic computation  @xmath156 and a cogentexpression  @xmath93 , evaluated under the update semantics .",
    "we denote the refinement predicate .",
    "because @xmath177 changes for each cogentprogram , we parameterise by an arbitrary state relation  @xmath160 .",
    "it is parameterised also by the typing context  @xmath180 and the environment  @xmath181 , as well as by the initial update semantics store  @xmath100 and monadic shallow embedding state  @xmath161 .",
    "monad - to - update correspondence @xmath182)\\longrightarrow \\\\ \\quad \\;\\ ;      ( \\mu,\\sigma ) \\in r \\longrightarrow \\\\ \\quad\\quad    \\;(\\neg\\ \\failed \\ ( p_m \\ \\sigma)\\ ; \\wedge \\\\ \\quad\\quad    \\;(\\forall v_m \\;\\sigma^\\prime . \\ ( v_m,\\sigma^\\prime ) \\in \\results\\ ( p_m\\;\\sigma ) \\longrightarrow",
    "\\\\ \\quad\\quad\\quad     ( \\exists \\mu^\\prime \\",
    "\\updsem{u}{e}{\\mu}{u}{\\mu^\\prime } \\wedge         ( \\mu^\\prime,\\sigma^\\prime ) \\in r \\wedge",
    "\\valrel\\ u\\ v_m ) ) ) \\end{array}\\ ] ]    the definition states that if the state relation  @xmath160 holds initially , then the monadic computation  @xmath156 can not fail and , moreover , for all executions of  @xmath156 there must exist a corresponding execution under the update semantics of the expression  @xmath93 such that the final states are related by  @xmath160 and @xmath175 holds between their results .",
    "autocorres proves automatically that : @xmath183 .",
    "[ [ refinement - proof ] ] refinement proof + + + + + + + + + + + + + + + +    the refinement proof is automatic in isabelle , driven by a set of syntax - directed rules , one for each cogentconstruct . the proof procedure makes use of the fact that the cogentterm is in a - normal form to reduce the number of cases that need to be considered and to simplify the higher - order unification problems that some of the proof rules pose to isabelle .",
    "this refinement theorem does not need an explicit formal assumption of well - typedness of the cogentprogram .",
    "the proof tactic will simply fail for programs that are not well - typed .",
    "depicts two rules , one for expressions  @xmath81 that are variables and the other for  @xmath184 .",
    "these correspond respectively to the two basic monadic operations  , which yields values , and @xmath185 , for sequencing computations .",
    "observe that the rule corres - let is _ compositional _ : to prove that @xmath184 corresponds to @xmath186 the rule involves proving that ( 1 )  @xmath187 corresponds to @xmath188 and ( 2 )  that  @xmath57 corresponds to  @xmath58 when each are executed over corresponding results  @xmath189 and  @xmath155 ( e.g. as yielded by @xmath187 and @xmath188 respectively ) .",
    "compositionality significantly simplifies the automation of the correspondence proof .",
    "the typing assumptions of corres - let are discharged by appealing to the type theorem tree generated by the compiler ( see ) .",
    "c corres - var +   + corres - let +    the rules for some of the other constructs , such as @xmath2 , @xmath1 , and @xmath190 , contain non - trivial assumptions about and about the types used in the program .",
    "once a program and its are fixed , a set of simpler rules is automatically generated by _",
    "specialising _ the generic rules for each of these constructs to the particular and types used in the input program .",
    "this in effect discharges the non - trivial assumptions of these rules once - and - for - all , allowing the automated proof of correspondence to proceed efficiently .",
    "conceptually , the refinement proof proceeds bottom - up , starting with the leaf functions of the program and ending with the top - level entry points ; results proved earlier are used to discharge assumptions for callees .",
    "the proof tactic thus follows the call - graph of the input program .",
    "currently , the tactic is limited to computing call graphs correctly only for programs containing up to second - order functions .",
    "we did not need higher orders in our applications yet , but the tactic can certainly be extended if needed .",
    "the resulting refinement theorem at this stage assumes that holds for all the abstract functions used in the program .",
    "let  @xmath79 be a ( monomorphic ) cogentfunction , such that @xmath191 .",
    "let  @xmath156 be its monadic shallow embedding , as derived from its generated c code .",
    "let  @xmath104 and @xmath155 be arguments of appropriate type for  @xmath79 and @xmath156 respectively . then",
    ": @xmath192      to complete this step , the compiler simply applies .",
    "[ s : mono ] having made the transition to the value semantics , the proof now establishes the correctness of the compiler s monomorphisation pass , moving upwards in from a monomorphic to a polymorphic deep embedding of the input program .    in this pass",
    ", the compiler generates an injective renaming function that , for a polymorphic function name @xmath193 and types @xmath194 , yields the specialised monomorphic function name @xmath195 , mapping names downwards , from the polymorphic to the monomorphic level .",
    "just as we assume abstract functions are correctly implemented in c , we also assume that their behaviour remains consistent under .",
    "to establish correctness of monomorphisation , we essentially have an isabelle function that repeats the monomorphisation process on behalf of the cogentcompiler , and prove that ( 1 )  the monomorphised program it produced is identical to that produced by the compiler , and ( 2 )  that the monomorphised program is a correct refinement of the polymorphic one .",
    "we define two isabelle / hol functions , both parameterised by  @xmath196 : one for monomorphising expressions , called @xmath197 , and the other for monomorphising ( function ) values , called .",
    "the functions specialise function calls and use to monomorphise all function calls in expressions and values , respectively .",
    "the functions are defined compositionally for all other cogentconstructs .",
    "step  ( 1 ) is proved by straightforward rewriting , and is automated on a per - program basis .",
    "step  ( 2 ) is embodied in the following refinement theorem , which we prove , once and for all , by rule induction over the value semantics .",
    "the specialisation lemma   of , is a key ingredient of this proof .",
    "let @xmath79 be a ( polymorphic ) cogentfunction whose definition given by @xmath169 is @xmath170 .",
    "let  @xmath94 be an appropriately - typed argument for  @xmath79 .",
    "let  @xmath196 be an injective renaming function .",
    "then : @xmath198    note that on the left - hand - side of the implication , the computation runs under the value semantics where the renaming is applied across the @xmath169 of the right - hand side .",
    "the compiler generates a well - typedness proof for the monomorphic deeply embedded program ( ) .",
    "we use the top - level theorem s injectivity assumption on to infer well - typedness of the polymorphic deeply embedded program .      in this section ,",
    "the proof makes the transition from deep to shallow embedding , where the shallow embedding is a pure function in isabelle / hol .",
    "this shallow embedding is still in a - normal form and is produced by the compiler as a separate isabelle / hol theory file .",
    "there is a second , neater shallow embedding , explained in the following section , that is closer to the cogentinput program .    for each cogenttype ,",
    "the compiler generates a corresponding isabelle / hol type definition , and for each cogentfunction , a corresponding isabelle / hol constant definition .",
    "we can drop the linear types at this stage and remain in isabelle s simple types , because we have already made use of them : we are in the value semantics .",
    "in addition to these definitions , the compiler produces a theorem that the deeply embedded polymorphic cogentterm under the value semantics correctly refines this isabelle / hol function .",
    "refinement is formally defined here by the predicate @xmath199 that defines when a shallowly embedded expression  @xmath157 is refined by a deeply embedded one  @xmath93 when evaluated under the environment  @xmath92 .",
    "@xmath200    that is , @xmath157 corresponds to @xmath93 under variable bindings @xmath92 if whenever @xmath93 evaluates to an @xmath105 under @xmath92 , then @xmath157 and @xmath94 are in the value relation @xmath201 .",
    "similarly to the proof from monadic c to update semantics , the value relation here is one polymorphic constant in isabelle / hol , defined incrementally via ad - hoc overloading .",
    "the program - specific refinement theorem produced is :    let @xmath79 be an a - normal cogentfunction such that @xmath202 , and let  @xmath157 be @xmath79 s shallow embedding .",
    "then @xmath203    note that @xmath204 ensures that @xmath205 and @xmath94 are of matching type , and that the shallow expression @xmath206 ensures in isabelle s type system that it is the appropriate one .",
    "like the c refinement proof in , this proof is automatic and driven by a set of syntax - directed rules , specialised to cogenta - normal form .",
    "depicts the final top - level shallow embedding , only mildly polished for presentation , for the cogentexample of .    ....",
    "ext2_free_branch ( cnt.mk depth nd ( acc.mk ex fs inode ) mdep ) \\<equiv > if depth + 1 < mdep then   case uarray_create ( rr.mk ex ( to\\<^sub > f nd - fr\\<^sub > f nd ) ) of    r\\<^sub>1\\<^sub>1.success ds\\<^sub>1\\<^sub>0 \\<rightarrow >      let ( ex , ds\\<^sub>1\\<^sub>2 ) = take ds\\<^sub>1\\<^sub>0 rr.p1\\<^sub > f ;          ( children , ds\\<^sub>1\\<^sub>3 ) = take ds\\<^sub>1\\<^sub>2 rr.p2\\<^sub > f ;          ( mbuf , nd_t ) = take nd mbuf\\<^sub > f ;          ( children , ds\\<^sub>1\\<^sub>6 ) = take            ( uarray_map_no_break              ( arraymapp.mk children ( fr\\<^sub > f nd_t )                ( to\\<^sub > f nd_t ) ext2_free_branch_entry                ( cnt.mk ex inode ( fr\\<^sub > f nd_t ) mbuf ) ( ) ) )            rr.p1\\<^sub > f ;    ...      ....    as shows , the isabelle definitions use the same names as the cogentinput program and they have the same structure as the input program . in this example",
    ", it remains visible that the compiler replaces tuples from the surface syntax with records in the core language , e.g.`cnt.mk ` is the isabelle record constructor for the type ` cnt ` , and instead of tuple pattern matching , the compiler generates a sequence of ` take ` expressions . in practice , these disappear by rewriting when reasoning about the function .",
    "tuple syntax could be reconstructed in an additional small proof pass if so desired .",
    "the correctness statement for this phase is simple : it is pure isabelle / hol equality between the a - normal and neat shallow embedding for each function .",
    "for instance : @xmath207 the proof is simple as well .",
    "since we can now use equational reasoning with isabelle s powerful rewriter , we just unfold both sides , apply extensionality and the proof is automatic given the right congruence rules and equality theorems for functions lower in the call graph .",
    "this proof stage was the easiest and fastest of the stages to construct ; it took about 1 person day .",
    "this is a strong indication that this representation of the program is well suited for further reasoning on top .",
    "[ [ language - restrictions - totality ] ] language restrictions : totality + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    the current version of cogentpurposefully omits primitive constructs for iteration and recursion , because we wanted to ensure that the language was total for a neat shallow embedding in hol ( which is total ) .",
    "however , since our language meta - level proofs do not require totality , we only require that _ each program _ is terminating .",
    "we are therefore contemplating to relax this restriction and allow cogentiterator constructs where termination is obvious enough for isabelle to prove automatically .",
    "[ [ formal - language - semantics ] ] formal language semantics + + + + + + + + + + + + + + + + + + + + + + + + +    the cogentsemantics in isabelle departs slightly from that presented in . in particular , we enriched the update semantics to carry enough value type information to infer their corresponding c types , and adjusted the typing rules accordingly . while not needed for any of the proofs of , this information is used in the automatic c - correspondence proof . in addition , we found ourselves repeating parts of the ( linear ) type preservation proof in rule inductions on the semantics that make use of typing assumptions .",
    "this means , while type erasure is an important property for languages to enjoy ( and _ is _ enjoyed by cogent ) , dynamic semantics with type information are helpful for mechanised reasoning . ideally , there should be an erased and a typed dynamic semantics , with type safety implying their equivalence .    [ [ optimisation ] ] optimisation + + + + + + + + + + + +    the current cogentcompiler performs little optimisation when generating c code and leaves low - level optimisation to gcc or compcert .",
    "clever optimisations in the cogent - to - c stage would complicate our current syntax - directed correspondence approach .",
    "cogent - to - cogentoptimisations , however , are different . the ease by which we prove the correctness of the a - normalisation over the shallow embedding via rewriting , suggests fruitful ground for optimisation .",
    "we leave exploring this idea for future work .    [",
    "[ effort - and - size ] ] effort and size + + + + + + + + + + + + + + +    cogenthas been under development for over 2 years and has continually evolved as we have scaled the language to ever larger applications .",
    "all up , the combined language development and certifying compiler took @xmath208 person - years .",
    "engineering the cogentcompiler , excluding @xmath209 person - monthsspent on proof automation and proof framework development , consumed @xmath210 person - months .",
    "the remaining @xmath211 person - monthswas for the design , formalisation and proof of cogentand its properties ( e.g. the theorems of ) , a small amount of which was also spent on early compiler development .",
    "the total size of the development in the isabelle theorem prover is @xmath212 lines of code ( including comments and whitespace ) , which includes the once - and - for - all language proofs plus automated proof tactics to perform the translation validation steps , given appropriate hints from the cogentcompiler .",
    "the cogentcompiler , written in haskell , is @xmath213 source lines of code ( excluding comments and whitespace ) . for 6,454lines of etx2 cogentcode",
    "we generate 76,759lines of isabelle / hol proofs and embeddings .",
    "like us , the high - assurance systems programming  @xcite project seeks to improve systems software by combining formal methods and programming language research . like",
    "cogent , hasp s systems language , habit , is a domain specific functional language .",
    "@xcite show the correctness of a garbage collector in this project ; however , to the best of our knowledge , there exist no full formal language semantics yet .",
    "ivory  @xcite is a domain specific language embedded in haskell also for implementing correct systems software .",
    "it generates well - defined , memory safe c code ; however , unlike cogentit does not _ prove _ correctness of the generated code .",
    "linear types have been used in several general purpose imperative languages to ensure memory safety without depending on a runtime , such as in vault  @xcite and @xcite .",
    "paclang @xcite is an imperative domain - specific language which uses linear types to guide optimisation of packet processing applications on network processors .",
    "similar substructural type systems , namely uniqueness types , have been integrated into functional programming languages such as clean  @xcite .",
    "however , the type system there is only used as a way to provide a purely functional abstraction over effects , and thus clean still depends on a run - time garbage collector .",
    "to the best of our knowledge , @xcite is the only work which proves the equivalence of the functional and imperative interpretation of a language with a linear type system .",
    "the proof is by pen and paper , from a first order functional language with linear types to its translation in c. cogentin comparison is higher order and its compiler produces a machine checked proof linking a purely functional shallow embedding to its c implementation .",
    "examples for verified compilers for high - level languages are cakeml  @xcite , discussed in more detail in , which compiles a full ml dialect , including verified runtime and garbage collection . in contrast , @xcite focuses on a compositional approach to compiler verification for a relatively simple functional language , pilsner , to an idealised assembly language .",
    "@xcite also generate a shallow embedding representation of a program to facilitate proofs about properties via a proof assistant , as we do .",
    "however , they do not address the verification of the code generated by the compiler .",
    "we have presented the cogentlanguage , its self - certifying compiler , their formal definitions and top - level compiler certificate theorem , and the correctness theorems for each compiler stage .",
    "the language targets systems code where data sharing is minimal or can be abstracted , performance and small memory footprint are requirements , and formal verification is the aim .",
    "cogentis a pure , total functional language to enable productive equational reasoning in an interactive theorem prover .",
    "it is higher - order and polymorphic to increase conciseness .",
    "it uses linear types to make memory management bugs compile time errors , and to enable efficient destructive in - place update .",
    "it avoids garbage collection and a trusted runtime to reduce footprint .",
    "it supports a formally modelled foreign - function interface to interoperate with c code and to implement additional data types , iterators and operations .      cogentsets a new benchmark for trustworthy systems languages , and demonstrates , through the careful application of language design with verified compilation in mind , that writing systems code that supports purely functional equational reasoning is possible"
  ],
  "abstract_text": [
    "<S> we present a self - certifying compiler for the cogentsystems language . </S>",
    "<S> cogentis a restricted , polymorphic , higher - order , and purely functional language with linear types and without the need for a trusted runtime or garbage collector . </S>",
    "<S> it compiles to efficient c code that is designed to interoperate with existing c functions . </S>",
    "<S> the language is suited for layered systems code with minimal sharing such as file systems or network protocol control code .    for a well - typed cogentprogram </S>",
    "<S> , the compiler produces c code , a high - level shallow embedding of its semantics in isabelle / hol , and a proof that the c code correctly implements this embedding . </S>",
    "<S> the aim is for proof engineers to reason about the full semantics of real - world systems code productively and equationally , while retaining the interoperability and leanness of c.    we describe the formal verification stages of the compiler , which include automated formal refinement calculi , a switch from imperative update semantics to functional value semantics formally justified by the linear type system , and a number of standard compiler phases such as type checking and monomorphisation . </S>",
    "<S> the compiler certificate is a series of language - level meta proofs and per - program translation validation phases , combined into one coherent top - level theorem in isabelle / hol .        </S>",
    "<S> [ applicative ( functional ) languages ] [ formal methods ]    verification , semantics , linear types , domain - specific languages , file systems , isabelle / hol </S>"
  ]
}