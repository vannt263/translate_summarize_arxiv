{
  "article_text": [
    "zero - shot learning ( zsl ) aims at solving the problem when the new test image categories are not seen in the training samples @xcite .",
    "different from the open set recognition and novelty detection which only distinguish abnormalities in the testing data , zsl seeks to classify the unseen testing classes @xcite .",
    "this is a practical problem setting in image classification , as there are thousands of categories of objects we intend to recognize , but only a few of them may have been appropriately annotated .",
    "consequently , it is more challenging than the conventional image classification problems .",
    "the key ideas of zsl are to choose better side information ( also known as modalities ) and to develop an effective common semantic space .",
    "the side information provides a bridge to transfer knowledge from the seen classes for which we have training data to the unseen classes for which we do not , and the common space offers a fusion feasibility for the visual features and the side information .",
    "two types of commonly used side information in zsl are attributes @xcite and word vectors @xcite , @xcite .",
    "particularly , attributes act as intermediate representations shared across multiple classes , indicating the presence or absence of several predefined properties .",
    "direct attribute prediction ( dap ) @xcite is one of the first efforts to exploit the attributes to zsl .",
    "it learns attribute - specific classifiers with the seen data and infers the unseen class with the learned estimators",
    ". however , attribute - based approaches suffer from a poor scalability as the attributes ontology for each class is generally manually defined .",
    "word - vector - based approaches @xcite avoid this limitation since word vectors are extracted from a linguistic corpus with neural language models such as golve @xcite and word2vec @xcite .",
    "therefore , word vectors have become another popular side information in zsl .",
    "for instance , socher _ et al . _",
    "@xcite construct a two layer neural network to project images into the word vector space . in @xcite ,",
    "frome _ et al .",
    "_ present a deep visual - semantic embedding model with a hinge loss function , which trains a linear mapping to link the image visual space to the word vector space .",
    "besides attributes and word vectors , some other side information , such as wordnet @xcite , visual prototypical concepts @xcite , class co - occurrence statistics @xcite , is also applied in zsl .",
    "further , since different types of side information captures different aspects of the structure of the semantic space , several studies have been made to combine them to achieve higher classification performance @xcite,@xcite,@xcite .",
    "for example , in @xcite , akata _ et al . _ first learn the joint embedding weight matrices corresponding to different types of side information , then perform a grid search over the coefficients on a validation set to get the joint compatibility model . in @xcite ,",
    "semantic projections are trained for attributes and word vectors independently , followed by a transductive multi - view semantic embedding space to alleviate the projection domain shift problem .",
    "these efforts demonstrate that different types of side information complement each other and construct a better embedding space for knowledge transfer .",
    "however , although multiple types of side information are utilized , they still exploit each type of side information in its own semantic space independently , and then just combine the predicted scores together @xcite , @xcite .",
    "this can not make full use of the complementary knowledge of different types of side information .",
    "a more efficient and robust solution is to investigate multiple types of side information in a unified space .",
    "unfortunately , to the best of our knowledge , there has been little previous work exploiting this idea . to this end , we present a novel approach called mbfa - zsl to employ multiple types of side information in a unified space , as shown in fig .",
    "[ fig1 ] .",
    "it is worth highlighting several aspects of the proposed mbfa - zsl approach .",
    "( 1 ) it develops an advanced multi - view embedding algorithm named multi - battery factor analysis ( mbfa ) , which extends tucker s inter - battery factor analysis ( ibfa ) @xcite .",
    "( 2 ) as far as we know , it represents one of the first attempts that embeds both the image visual features and multiple types of side information into one unified semantic space , which fully utilizes the interrelations among different types of information .",
    "( 3 ) the close - form solution makes it simple to implement and efficient to run on large datasets . ( 4 ) extensive experiments on popular datasets demonstrate its significant superiority over the existing state - of - the - art approaches .",
    "the reminder of this paper is structured as follows .",
    "section 2 introduces the proposed multi - battery factor analysis ( mbfa ) algorithm , and section 3 describes the proposed mbfa - zsl approach in detail .",
    "experimental results are presented in section 4 , and conclusions are drawn in the final section .",
    "multi - battery factor analysis ( mbfa ) is developed to provide a unified semantic space for both the visual features and multiple types of side information .",
    "it originates from tucker s inter - battery factor analysis ( ibfa ) @xcite , which transforms two modalities into a shared space where they are not only well explained but also as much correlated as possible with each other .",
    "thus , we first briefly introduce the ibfa algorithm , and then extend it to a multi - view version , i.e. , mbfa .    given a set of @xmath0 instances from two modalities , @xmath1\\in{\\mathbb{r}^{p_1\\times{n}}}$ ] and @xmath2\\in{\\mathbb{r}^{p_2\\times{n}}}$ ] , where @xmath3 and @xmath4 are their dimensionalities , respectively . with @xmath5 , @xmath6 centered , ibfa finds two projection matrices , @xmath7 and @xmath8 , by the following constrained maximization : @xmath9 where @xmath10 is an identity matrix .",
    "ibfa maximizes the total covariance between the two modalities , which can be seen plainly by rewriting @xmath11 as @xmath12 . with the lagrange multiplier method , ( [ eq : ibfa ] ) can be solved analytically through the eigenvalue decomposition .",
    "compared with canonical correlation analysis ( cca ) @xcite , ( [ eq : ibfa ] ) can be rewritten as : @xmath13 where @xmath14 denotes the pearson correlation , and @xmath15 is the variance",
    ". it can be seen from ( [ eq : ibfav2 ] ) that ibfa attempts to capture both the correlation and variation of @xmath5 and @xmath6 .",
    "this is different from cca that only aims at maximizing their correlation . in particular , the maximized correlation and variance in ( [ eq : ibfav2 ] ) depict the relationship between @xmath5 and @xmath6 and strengthen their own discriminant capabilities , respectively .",
    "to broaden ibfa to a multi - view scenario , we develop the mbfa algorithm on the basis of ibfa .",
    "given a set of @xmath0 instances from @xmath16 modalities , @xmath17\\in{\\mathbb{r}^{p_i\\times{n } } } , i=1,\\dots , c$ ] , where @xmath18 denotes the dimensionality , with @xmath19 centered , the objective function of mbfa is expressed as : @xmath20 similar to ibfa , mbfa tries to find a set of projection matrices that maximize the total covariance in the common space .",
    "equation ( [ eq : mbfa ] ) can be rewritten as : @xmath21 where @xmath22 and @xmath23 are as follows : @xmath24^t.\\ ] ] @xmath25 , \\mathbf{m}_{ij } = \\left\\ { \\begin{array}{ll }      0 , & i = j \\\\",
    "\\mathbf{x}_i\\mathbf{x}_j^t , & i \\neq j. \\end{array } \\right.\\ ] ] equation ( [ eq : mbfav2 ] ) can be solved via the eigenvalue decomposition ; thus each projection matrix @xmath26 can be obtained .",
    "it is obvious that ibfa can be considered as a special case of mbfa when @xmath16 is 2 .",
    "in addition , the main difference between mbfa and multi - view canonical correlation analysis ( mcca ) @xcite , @xcite is worth highlighting .",
    "both of them find a set of linear transformations to project multiple modalities into one common space .",
    "however , mcca seeks to maximize the total correlation in the common space , whereas mbfa maximizes the total covariance , which is equivalent to maximize the total correlation and variance simultaneously . to the best of our knowledge",
    ", there is no previous work using mcca on zsl . in this paper",
    ", we also implement mcca on zsl as a comparative approach ( we call this approach as mcca - zsl ) .",
    "in a zsl setting , we are given @xmath27 labeled training instances @xmath28 and @xmath29 unlabeled testing instances @xmath30 . @xmath31 and @xmath32 are the @xmath33-dimensional visual feature vectors of training and testing instances respectively . @xmath34 and @xmath35 are the seen and unseen class label vectors , and @xmath36 .",
    "we have @xmath37 different types of side information , @xmath38 and @xmath39 denote the @xmath40-th type of @xmath41-dimensional side information for training and testing datasets respectively .",
    "note that for the testing dataset , @xmath42 is missing as testing instances are unlabeled .",
    "the task of zsl is to predict the class labels @xmath35 .",
    "the proposed mbfa - zsl algorithm mainly contains the following two steps :    _ step 1 : build a mbfa space with the seen data . _",
    "the mbfa algorithm provides an unified semantic space @xmath43 for different types of side information as well as the visual features . with the seen images together with the side information , we can train the mbfa model to obtain a set of projection matrices @xmath26 @xmath44 , where @xmath16 is the sum of all the types of side information and the visual features , such that @xmath45 . for example , if we use both attributes and word vectors as the side information , then @xmath16 is 3 .    _",
    "step 2 : unseen category inference . _ with the projection matrix @xmath7 learned from the seen data , the unseen image features @xmath46 can be embedded into the common space @xmath43 by @xmath47 .",
    "typically , the unseen category of @xmath48 can be inferred by searching for the nearest output embedding vector that corresponds to one of the unseen classes , if there is only single side information available in @xmath43 .",
    "since there are multiple types of side information used in the mbfa - zsl approach , we introduce a multi - modality fusion method to predict the unseen category of the @xmath48 with : @xmath49,l=1,2,\\dots , n , \\end{aligned}\\ ] ] where @xmath50 is a weight associated with each type of side information , which can be determined by a grid search on the validation set .",
    "each type of side information that corresponds to the @xmath51-th unseen class is denoted as @xmath52 , and it can be embedded into the common space @xmath43 by @xmath53 .",
    "the similarity between two vectors can be represented as the common distance measurements , such as dot product similarity and euclidean distance . in this paper ,",
    "the cosine distance is utilized , i.e. , @xmath54    moreover , mbfa - zsl has an explicit , close - form solution , which makes it simple to implement and efficient to run on large datasets .",
    "* algorithm 1 * outlines the procedures of the proposed mbfa - zsl approach .    .",
    "construct the covariance matrix @xmath23 with the labeled visual features @xmath55 and the corresponding side information @xmath56 .",
    "solve the eigenvalue decomposition problem in ( [ eq : mbfav2 ] ) , and the eigenvectors corresponding to the largest @xmath57 eigenvalues form the projection matrices @xmath22 .",
    "learn the weight parameters of the category inference function ( [ eq : inference ] ) in the validation set .",
    "project the unseen visual feature @xmath58 and the side information of the unseen classes into the unified space with projection matrices @xmath22 .",
    "predict the labels of @xmath59 with ( [ eq : inference ] ) .",
    "we evaluate the proposed mbfa - zsl approach on three publicly popular datasets : animals with attributes ( awa ) @xcite , caltech - ucsd - birds-200 - 2011 ( cub ) @xcite , and sun attribute @xcite . specifically , awa is a collection of 30,475 images on 50 classes of animals , with 85 associated class - level attributes .",
    "we use the standard training / test ( seen / unseen ) split as that in @xcite , which chooses 40 classes for training and validation and 10 classes for testing .",
    "cub provides 200 classes of birds ( 11,788 images ) , and each class is annotated with 312 attributes . particularly , cub is a much more challenging dataset in that it is designed for fine - grained image classification and contains more classes but fewer images .",
    "similar to @xcite , we use 150 classes as training and validation set , leaving 50 disjoint classes as test set .",
    "sun attribute dataset consists of 14,340 images from 717 scene categories , and each category is annotated with a taxonomy of 102 discriminate attributes .",
    "we adopt the popular training / test ( seen / unseen ) split as that in @xcite , which selects 707 classes for training and validation , and takes the remaining 10 classes as testing set .",
    "we cross - validate the parameters @xmath50 in ( [ eq : inference ] ) .",
    "the example images in these datasets are shown in fig .",
    "[ fig2 ] .    on the awa dataset",
    ", we use the vgg ( very deep 19-layer cnn ) features provided in @xcite as visual features . on the cub and sun dataset",
    ", we use a pre - trained vgg model to extract visual features @xcite . for each image ,",
    "the 4,096 dimensional top - layer hidden unit activations ( fc7 ) of vgg are taken as visual features .",
    "we use both the word vectors ( t ) and attributes ( a ) as the side information in mbfa - zsl . specifically , we train the word2vec model @xcite on a corpus of wikipedia documents to form 1000-d word vectors for the three datasets",
    ". meanwhile , we use the attribute information provided by the datasets . the average per - class top-1 accuracy on the test sets is reported .",
    "we compare the proposed mbfa - zsl with 7 state - of - the - art approaches as well as mcca - zsl , which utilize a range of side information . among them , dap @xcite , @xcite , eszsl @xcite , and sse - relu @xcite only use attributes ; latem @xcite can make use of either word vectors or attributes ; sje @xcite , amp @xcite , tmv - hlp @xcite and mcca - zsl employ more than one type of side information .",
    "different cnn visual features are applied in these approaches , such as googlenet @xcite , overfeat @xcite , and vggnet-19 @xcite .",
    "additionally , we also implement mbfa - zsl and mcca - zsl in the situation where only attributes ( a ) or word vectors ( t ) are available .",
    "the performance of mbfa - zsl are taken via ten times of cross validation .",
    "it should be noticed that when only t or a is avaliable , the single parameter @xmath50 in ( [ eq : inference ] ) does not need to be tuned , thus there is no standard deviation for the corresponding results .",
    "furthermore , the standard deviations of some comparative results are absent as they are not avaliable in the original papers .",
    "the comparative results are summarized in table [ performance ] , from which we can observe that mbfa - zsl achieves the amazingly best performance in all cases for all the three datasets . besides , we also have the following observations :    max width=    c|c|ccccccccc & & & & + & & t & a & t+a & t & a & t+a & t & a & t+a + & sje @xcite & 51.2 & 66.7 & 73.5 * & 28.4 & 50.1 & 51.0 * & - & - & - + & latem @xcite & 61.1 & 71.9 & - & 31.8 & 45.5 & - & - & - & - + & amp @xcite & - & - & 66.0 & - & - & - & - & - & - + & tmv - hlp @xcite & - & - & 73.5 & - & - & 47.9 & - & - & - + & dap @xcite & - & 60.8 & - & - & - & - & - & 72.0 & - + & sse - relu @xcite & - & 76.3@xmath600.8 & - & - & 30.4@xmath600.2 & - & - & 82.5@xmath601.3 & - + & eszsl * * @xcite & - & 74.6@xmath603.7 & - & - & 50.8@xmath600.4 & - & - & 84.5@xmath601.4 & - + & mcca - zsl * * & 65.8@xmath601.7 & 74.9@xmath600.3 & 75.3@xmath601.8 & 32.1@xmath600.3 & 45.8@xmath600.2 & 46.4@xmath600.7 & 59.5@xmath601.7 & 82.8@xmath600.5 & 85.1@xmath601.5 + & mbfa - zsl * * & * 72.5 * & * 77.8 * & * 79.9@xmath600.7 * & * 32.4 * & * 51.7 * & * 52.2@xmath600.4 * & * 61.5 * & * 85.0 * & * 87.4@xmath600.2",
    "* +   +   +    \\(1 ) for awa dataset , the second - best approaches are mcca - zsl , sse - relu , and mcca - zsl in the cases of t , a , and t+a , respectively .",
    "mbfa - zsl outperforms them in 6.7% , 1.5% , and 4.6% , respectively . for cub dataset",
    ", mbfa - zsl outperforms the second - best approaches , mcca - zsl in 0.3% , eszsl in 0.9% , and sje in 1.2% in the three cases , respectively . for sun dataset , in the three cases , mbfa - zsl outperforms the second - best approaches , mcca - zsl in 2.0% , eszsl in 0.5% , and mcca - zsl in 2.3% , respectively .",
    "these are very promising results .",
    "\\(2 ) for mbfa - zsl , the performance on awa in t+a is better than those in t and a in 7.4% and 2.1% , respectively .",
    "on cub , the performance in t+a is better than those in t and a in 19.8% and 0.5% , respectively . on sun ,",
    "the promotions are 25.9% and 2.4% , respectively .",
    "similar observation can also be found in mcca - zsl .",
    "the excellent performance in t+a of mbfa - zsl and mcca - zsl demonstrates that it is effective to embed multiple types of side information into a unified space .",
    "it also confirms that different types of side information complement each other in transferring knowledge .",
    "\\(3 ) in the situation of `` t+a '' , it can be found that mbfa - zsl outperforms the others significantly .",
    "take the awa for example , the performance improvements of mbfa - zsl over sje , amp and tmv - hlp are 6.4% , 13.9% , and 6.4% , respectively .",
    "this demonstrates that embedding the visual features and multiple types of side information in a unified space is more promising than the conventional methods that projecting the visual features to each type of side information space independently at first , and then combining them together .",
    "\\(4 ) when only single type of side information is available , attributes often help achieve a higher accuracy than word vectors .",
    "this is due to that attributes are manually defined for a specific dataset , so they are able to describe category relationship of the dataset more effectively ; nevertheless , word vectors are extracted from the corpus in an unsupervised manner , whose capacity is constrained by the size or specific domain of the corpus , as well as the polysemy issue .",
    "\\(5 ) interestingly , the performance on cub is inferior to that on awa and sun .",
    "the reason may lie in the fine - grained characteristic of cub .",
    "both the visual appearance and the class names in it are similar to each other , which make it hard to recognize .    to clearly evaluate the performance of mbfa - zsl on each class , we present the confusion matrix of awa with t+a , as illustrated in fig . [ confusionmat ] .",
    "the diagonal elements denotes the correct prediction accuracy of each class , from which we can see that the proposed mbfa - zsl can achieve relatively high performance on every class .",
    "[ confusionmat ]      there are two types of parameters in mbfa - zsl : the weights @xmath50 in ( [ eq : inference ] ) and the dimensionality @xmath57 of the unified space that multiple modalities are projected into .",
    "the weights are decided by the cross validation .",
    "the impact of dimensionalities @xmath57 is shown in fig .",
    "[ parameter ] .",
    "the optimal dimensionalities for awa , cub , and sun are 40 , 50 , and 120 , respectively .",
    "it can be observed that a higher dimensionality has no performance improvement .      finally ,",
    "as shown in table [ speed ] , we report the running times of the training and testing stages for awa , cub , and sun , respectively .",
    "our implementation is based on an unoptimized matlab code . on our computer with i5 4590 cpu and 12 g memory , the training times for the three datasets are 18.8s , 22.2s , and 17.4s , respectively .",
    "the test times on each image for the three datasets are 0.006ms , 0.010ms , and 0.019ms , respectively .",
    "therefore , mbfa - zsl is extremely efficient .",
    "max width=    [ cols=\"^,^,^,^\",options=\"header \" , ]",
    "in this paper , we have proposed the mbfa - zsl approach to projecting both the visual features and multiple types of side information into one unified semantic space to perform zsl .",
    "it can also be applied to the situation where only a single type of side information is available .",
    "the results on the three popular datasets show its superior performance over the state - of - the - art approaches on the cases of utilizing a ( attributes ) , t ( word vectors ) , and a+t ( attributes + word vectors ) as an effective and efficient method .",
    "moreover , it has a close - form solution .",
    "+   + * acknowledgements *    this work was supported by the national basic research program of china ( 973 program ) under grant 2014cb340400 , the national natural science foundation of china under grant 61271325 , grant 61472273 , the elite scholar program of tianjin university under grant 2015xrg-0014 , and the research program of application foundation and advanced technology of tianjin under grant 15jcybjc17100 .",
    "0 m.  palatucci , d.  pomerleau , g.  e.  hinton , and t.  m.  mitchell , `` zero - shot learning with semantic output codes , '' in _ advances in neural information processing systems _",
    ", 2009 , pp .",
    "1410 - 1418",
    ". m.  a.  f.  pimentel , d.  a.  clifton , l.  clifton , and l.  tarassenko , `` a review of novelty detection , '' _ signal processing _",
    "215 - 249 , 2014 . c.  h.  lampert , h.  nickisch , and s.  harmeling , `` learning to detect unseen object classes by between - class attribute transfer , '' in _ proceedings of the ieee conference on computer vision and pattern recognition _ , 2009 , pp .",
    "951 - 958 .",
    "c.  h.  lampert , h.  nickisch , and s.  harmeling , `` attribute - based classification for zero - shot visual object categorization , '' _ ieee transactions on pattern analysis and machine intelligence _",
    "453 - 465 , 2014 .",
    "j.  deng , n.  ding , y.  jia , a.  frome , k.  murphy , s.  bengio , y.  li , h.  neven , and h.  adam , `` large - scale object classification using label relation graphs , '' in _",
    "european conference on computer vision _ , 2014 ,",
    "b.  paredes and p.  torr , `` an embarrassingly simple approach to zero - shot learning , '' in _ proceedings of the 32nd international conference on machine learning _",
    ", 2015 , pp .",
    "2152 - 2161",
    ". j.  pennington , r.  socher , and c.  d.  manning , `` glove : global vectors for word representation , '' in _ proceedings of the empirical methods in natural language processing _",
    ", 2014 , pp .",
    "1532 - 1543 .",
    "t.  mikolov , i.  sutskever , k.  chen , g.  corrado , and j.  dean , `` distributed representations of words and phrases and their compositionality , '' in _ advances in neural information processing systems _ , 2013 ,",
    "3111 - 3119 .",
    "m.  norouzi , t.  mikolov , s.  bengio , y.  singer , j.  shlens , a.  frome , g.  corrado , and j.  dean , `` zero - shot learning by convex combination of semantic embeddings , '' in _ international conference on learning representations _ , 2014 .",
    "r.  socher , m.  ganjoo , c.  manning , and a.  ng , `` zero - shot learning through cross - modal transfer , '' in _ advances in neural information processing systems _ , 2013 , pp . 935 - 943 .",
    "m.  elhoseiny , b.  saleh , and a.  elgammal .",
    "`` write a classifier : zero - shot learning using purely textual descriptions , '' in _ proceedings of the ieee international conference on computer vision _",
    ", 2013 , pp .",
    "2584 - 2591 .",
    "a.  frome , g.  corrado , j.  shlens , s.  bengio , j.  dean , m.  ranzato , and t.  mikolov , `` devise : a deep visual - semantic embedding model , '' in _ advances in neural information processing systems _ , 2013 ,",
    "2121 - 2129",
    ". z.  akata , s.  reed , d.  walter , h.  lee , and b.  schiele , `` evaluation of output embeddings for fine - grained image classification , '' in _ proceedings of the ieee conference on computer vision and pattern recognition _ , 2015 ,",
    "2927 - 2936 .",
    "s.  jetley , b.  romera - paredes , s.  jayasumana , and p.  torr , `` prototypical priors : from improving classification to zero - shot learning , '' in _ british machine vision conference _ , 2015 , pp . 1 - 12",
    ". t.  mensink , e.  gavves , and c.  snoek , `` costa : co - occurrence statistics for zero - shot classification , '' in _ proceedings of the ieee conference on computer vision and pattern recognition _ , 2014 , pp .",
    "2441 - 2448 .",
    "y.  fu , t.  m.  hospedales , t.  xiang , and s.  gong , `` transductive multi - view zero - shot learning , '' _ ieee transactions on pattern analysis and machine intelligence _ , vol .",
    "2332 - 2345 , 2015",
    ". y.  fu , t.  m.  hospedales , t.  xiang , z.  fu , and s.  gong , `` transductive multi - view embedding for zero - shot recognition and annotation , '' in _",
    "european conference on computer vision _ , 2014 ,",
    "584 - 599 .",
    "l.  r.  tucker , `` an inter - battery method of factor analysis , '' _ psychometrika _ , vol .",
    "111 - 136 , 1958 .",
    "h.  hotelling , `` relations between two sets of variates , '' _ biometrika _ , vol .",
    "321 - 377 , 1936 .",
    "y.  gong , q.  ke , m.  isard , and s.  lazebnik , `` a multi - view embedding space for modeling internet images , tags , and their semantics , '' _ international journal of computer vision _ ,",
    "210 - 233 , 2014 .",
    "j.  rupnik , and  j. shawe - taylor , `` multi - view canonical correlation analysis , '' in _ conference on data mining and data warehouses _ , 2010 , pp . 1 - 4 .",
    "c.  wah , s.  branson , p.  welinder , p.  perona , and s.  belongie , `` the caltech - ucsd birds-200 - 2011 dataset , '' _ computation & neural systems technical report _ ,",
    "cns - tr-2011 - 001 , caltech , 2011 . g.  patterson , c.  xu , h.  su , _ et al _ , `` the sun attribute database : beyond categories for deeper scene understanding , '' _ international journal of computer vision _ ,",
    "59 - 81 , 2014 .",
    "d.  jayaraman , k.  grauman , `` zero - shot recognition with unreliable attributes , '' _ advances in neural information processing systems _ , 2014 ,",
    "3464 - 3472 .",
    "[ online ] .",
    "available : http://attributes.kyb.tuebingen.mpg.de/ k.  simonyan and z.  andrew , `` very deep convolutional networks for large - scale image recognition , '' in _ international conference on learning representations _ , 2015 .",
    "z.  zhang , and v.  saligrama , `` zero - shot learning via semantic similarity embedding , '' in _ proceedings of the ieee international conference on computer vision _",
    ", 2015 , pp .",
    "4166 - 4174 .",
    "y.  xian , z.  akata , g.  sharma , _",
    "et al_. `` latent embeddings for zero - shot classification , '' in _ proceedings of the ieee conference on computer vision and pattern recognition _ , 2016 .",
    "z.  fu , t.  xiang , e.  kodirov , and s.  gong , `` zero - shot object recognition by semantic manifold distance , '' in _ proceedings of the ieee conference on computer vision and pattern recognition _ , 2015 , pp",
    ". 2635 - 2644 . c.  szegedy , w.  liu , y.  jia , p.  sermanet , s.  reed , d.  anguelov , d.  erhan , v.  vanhoucke , and a.  rabinovich , `` going deeper with convolutions , '' in _ proceedings of the ieee conference on computer vision and pattern recognition _ , 2015 , pp . 1 - 9 .",
    "p.  sermanet , d.  eigen , x.  zhang , m.  mathieu , r.  fergus , and y.  lecun , `` overfeat : integrated recognition , localization and detection using convolutional networks , '' in _ international conference on learning representations _"
  ],
  "abstract_text": [
    "<S> zero - shot learning ( zsl ) extends the conventional image classification technique to a more challenging situation where the test image categories are not seen in the training samples . </S>",
    "<S> most studies on zsl utilize side information such as attributes or word vectors to bridge the relations between the seen classes and the unseen classes . </S>",
    "<S> however , existing approaches on zsl typically exploit a shared space for each type of side information independently , which can not make full use of the complementary knowledge of different types of side information . to this end </S>",
    "<S> , this paper presents an mbfa - zsl approach to embed different types of side information as well as the visual feature into one shared space . </S>",
    "<S> specifically , we first develop an algorithm named multi - battery factor analysis ( mbfa ) to build a unified semantic space , and then employ multiple types of side information in it to achieve the zsl . </S>",
    "<S> the close - form solution makes mbfa - zsl simple to implement and efficient to run on large datasets . </S>",
    "<S> extensive experiments on the popular awa , cub , and sun datasets show its significant superiority over the state - of - the - art approaches .    </S>",
    "<S> zero - shot learning , multi - battery factor analysis , image classification , attribute , word vector . </S>"
  ]
}