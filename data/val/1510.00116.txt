{
  "article_text": [
    "in this paper , we describe an algorithm to create a wait - free stack .",
    "a concurrent data structure is said to be wait - free if each operation is guaranteed to complete within a finite number of steps . in comparison",
    ", the data structure is said to be lock - free if at any point of time , at least one operation is guaranteed to complete in a finite number of steps .",
    "lock - free programs will not have deadlocks but can have starvation , whereas wait - free programs are starvation free .",
    "wait - free stacks have not received a lot of attention in the past , and we are not aware of algorithms that are particularly tailored to creating a generalized wait - free stack .",
    "however , approaches have been proposed to create wait - free stacks with certain restrictions  @xcite ,  @xcite ,  @xcite ,  @xcite , and with universal constructions  @xcite ,  @xcite .",
    "the main reason that it has been difficult to create a wait - free stack is because there is a lot of contention at the stack top between concurrent @xmath3 and @xmath0 operations .",
    "it has thus been hitherto difficult to realize the gains of additional parallelism , and also guarantee completion in a finite amount of time .",
    "the crux of our algorithm is as follows .",
    "we implement a stack as a linked list , where the @xmath4 pointer points to the stack top .",
    "each @xmath3 operation adds an element to the linked list , and updates the @xmath4 pointer .",
    "both of these steps are done atomically , and the overall operation is linearizable ( appears to execute instantaneously ) .",
    "however , the @xmath0 operation does not update the @xmath4 pointer .",
    "this design decision has been made to enable more parallelism , and reduce the time per operation .",
    "it instead scans the list starting from the @xmath4 pointer till it reaches an unmarked node .",
    "once , it reaches an unmarked node , it marks it and returns the node as the result of the @xmath0 operation . over time , more and more nodes get marked in the stack .",
    "to garbage collect such nodes we implement a @xmath1 operation that can be invoked by both the @xmath3 and @xmath0 operations .",
    "the cleanup operation removes a sequence of @xmath2 consecutively marked nodes from the list . in our algorithm",
    ", we guarantee that at no point of time the size of the list is more than @xmath2 times the size of the stack ( number of pushes - pops ) .",
    "this property ensures that @xmath0 operations complete within a finite amount of time . here , @xmath2 is a user defined parameter and it needs to be set to an optimal value to ensure the best possible performance .",
    "the novel feature of our algorithm is the @xmath1 operation that always keeps the size of the stack within limits .",
    "it does not allow the number of marked nodes that have already been popped to indefinitely grow .",
    "the other novel feature is that concurrent @xmath0 and @xmath3 operations do not cross each others paths .",
    "moreover , all the @xmath0 operations can take place concurrently .",
    "this allows us to have a linearizable operation . in this paper , we present our basic algorithm along with proofs of important results .",
    "readers can find the rest of the pseudo code , asymptotic time complexities , and proofs in the appendices .",
    "in 1986 , treiber  @xcite proposed the first lock - free implementation of a concurrent stack .",
    "he employed a linked list based data structure , and in his implementation , both the @xmath3 and @xmath0 operations modified the @xmath4 pointer using cas instructions .",
    "subsequently , shavit et al .",
    "@xcite and hendler et al .",
    "@xcite designed a linearizable concurrent stack using the concept of software combining . here ,",
    "they group concurrent operations , and operate on the entire group .    in 2004 , hendler et al .",
    "@xcite proposed a highly scalable lock - free stack using an array of lock - free exchangers known as an elimination array .",
    "if a @xmath0 operation is paired with a @xmath3 operation , then the baseline data structure need not be accessed .",
    "this greatly enhances the amount of available parallelism , and is known to be one of the most efficient implementations of a lock - free stack .",
    "this technique can be incorporated in our design as well .",
    "subsequently , bar - nissan et al .",
    "@xcite have augmented this proposal with software combining based approaches .",
    "recently , dodds et al .",
    "@xcite proposed a fast lock - free stack , which uses a timestamp for ordering the @xmath3 and @xmath0 operations .",
    "the restricted wait - free algorithms for the stack data structure proposed so far by the researchers are summarized in table  [ tab : rel ] .        _ author _ & _ primitives _ & _ remarks _ +    & & 1 .",
    "copies every global update to the private copy of every thread .",
    "+ & & 2 . replicates the stack data structure @xmath5 times ( @xmath6 # threads ) .",
    "+    afek et al .",
    "@xcite & f&a , & 1 .",
    "requires a semi - infinite array ( impractical ) .",
    "+ 2006 ] & tas & 2 .",
    "unbounded stack size .",
    "+    hendler et al .",
    "@xcite & & 1 .",
    "dcas not supported in modern hardware + 2006 ] & & 2 .",
    "variation of an implementation of a shared counter .",
    "+    fatourou et al .",
    "@xcite & ll / sc , & 1 .",
    "copies every global update to the private copy of every thread .",
    "+ 2011 ] & f&a & 2 .",
    "relies on wait - free implementation of f&a in hardware .",
    "+ david et al .",
    "2011  @xcite & bh object & 1 .",
    "supports at the most two concurrent pop operations +   +   +    -3 mm    the @xmath7-@xmath8 stack proposed in  @xcite employs a semi - infinite array as its underlying data structure .",
    "a @xmath3 operation obtains a unique index in the array ( using getandincrement ( ) ) and writes its value to that index .",
    "a @xmath0 operation starts from the top of the stack , and traverses the stack towards the bottom .",
    "it marks and returns the first unmarked node that we find .",
    "our @xmath0 operation is inspired by this algorithm .",
    "due to its unrestricted stack size , this algorithm is not practical .",
    "david et al .",
    "@xcite proposed another class of restricted stack implementations .",
    "their implementation can support a maximum of two concurrent @xmath3 operations .",
    "kutten et al .",
    "@xcite suggest an approach where a wait - free shared counter can be adapted to create wait - free stacks .",
    "however , their algorithm requires the dcas ( double cas ) primitive , which is not supported in contemporary hardware .",
    "wait - free universal constructions are generic algorithms that can be used to create linearizable implementations of any object that has valid sequential semantics .",
    "the inherent drawback of these approaches is that they typically have high time and space overheads ( creates local copies of the entire ( or partial ) data structure ) . a recent proposal by fatourou et al .",
    "@xcite can be used to implement stacks and queues .",
    "the approach derives its performance improvement over the widely accepted universal construction of herlihy  @xcite by optimizing on the number of shared memory accesses .",
    "algorithm  [ alg : node ] shows the @xmath9 class , which represents a node in a stack .",
    "it has a @xmath10 , and pointers to the next ( @xmath11 ) and previous nodes ( @xmath12 ) respectively .",
    "note that our stack is not a doubly linked list , the next pointer @xmath11 is only used for reaching consensus on which node will be added next in the stack .    to support @xmath0 operations , every node has a @xmath13 field .",
    "the @xmath14 field contains the i d of the thread that created the request .",
    "the @xmath15 field and @xmath16 is an atomic integer and is used to clean up the stack .    *",
    "class node * + @xmath17 @xmath10 + @xmath18 @xmath11 + @xmath19 @xmath12 + @xmath20 @xmath13 + @xmath17 @xmath14 + @xmath21 @xmath15 + @xmath21 @xmath16 / * initially set to 0 * / +    in our wait - free stack , the nodes are arranged as a linked list .",
    "initially , the list contains only the @xmath22 node , which is a dummy node .",
    "as we push elements , the list starts to grow .",
    "the @xmath4 pointer points to the current stack top .",
    "the @xmath3 operation starts by choosing a phase number ( in a monotonically increasing manner ) , which is greater than the phase numbers of all the existing push operations in the system .",
    "this phase number along with a reference to the node to be pushed and a flag indicating the status of the @xmath3 operation are saved in the @xmath23 array in an atomic step .",
    "after this , the thread @xmath24 scans the @xmath23 array and finds out the thread @xmath25 , which has a @xmath3 request with the least phase number .",
    "note that , the thread @xmath25 found out by @xmath24 in the last step might be @xmath24 itself .",
    "next , @xmath24 helps @xmath25 in completing @xmath25 s operation . at this point of time",
    ", some threads other than @xmath24 might also be trying to help @xmath25 , and therefore , we must ensure that @xmath25 s operation is applied exactly once .",
    "this is ensured by mandating that for the completion of any @xmath3 request , the following steps must be performed in the exact specified order :    1 .   modify the state of the stack in such a manner that all the other @xmath3 requests in the system must come to know that a @xmath3 request @xmath26 is in progress and additionally they should be able to figure out the details required by them to help @xmath26 .",
    "2 .   update the status flag to @xmath27 in @xmath26 s entry in the @xmath23 array .",
    "3 .   update the @xmath4 pointer to point to the newly pushed node .",
    "the @xmath0 operation has been designed in such a manner that it does not update the @xmath4 pointer .",
    "this decision has the dual benefit of eliminating the contention between concurrent @xmath3 and @xmath0 operations , as well as enabling the parallel execution of multiple @xmath0 operations .",
    "the @xmath0 operation starts by scanning the linked list starting from the stack s top till it reaches an unmarked node .",
    "once , it gets an unmarked node , it marks it and returns the node as a result of the @xmath0 operation .",
    "note that there is no helping in the case of a @xmath0 operation and therefore , we do not need to worry about a @xmath0 operation being executed twice . over time , more and more nodes get marked in the stack . to garbage collect such nodes we implement a @xmath28 operation that can be invoked by both the @xmath3 and @xmath0 operations .      the first step in pushing a node is to create an instance of the @xmath29 class .",
    "it contains the reference to a node ( @xmath30 ) , a boolean variable @xmath31 that indicates the status of the request , and a phase number ( @xmath32 ) to indicate the age of the request .",
    "let us now consider the @xmath3 method ( line  [ line : push ] ) .",
    "we first get the phase number by atomically incrementing a global counter . once the @xmath29 is created and its phase is initialized , it is saved in the @xmath23 array .",
    "subsequently , we call the function @xmath33 to actually execute the @xmath3 request",
    ".    the @xmath33 function ( line  [ line : help ] ) finds the request with the least phase number that has not been pushed yet .",
    "if there is no such request , then it returns .",
    "otherwise it helps that request ( @xmath34 ) to complete by calling the @xmath35 method .",
    "after helping @xmath34 , we check if the request that was helped is the same as the request that was passed as an argument to the @xmath33 function ( @xmath36 ) in line  [ line : help ] .",
    "if they are different requests , then we call @xmath35 for the request @xmath36 in line  [ line : attachreq ] .",
    "this is a standard construction to make a lock - free method wait - free ( refer to  @xcite ) .    in the @xmath35 function , we first read the value of the @xmath4 pointer , and its @xmath37 field . if these fields have not changed between lines  [ read1 ] and  [",
    "line : notlast ] , then we try to find the status of the request in line  [ line : ifdone ] .",
    "note that we check that @xmath37 is equal to null , and @xmath13 is equal to false in the previous line ( line  [ line : nextnull ] ) .",
    "the @xmath13 field is made true after the @xmath4 pointer has been updated .",
    "hence , in line  [ line : nextnull ] , if we find it to be true then we need to abort the current iteration and read the @xmath4 pointer again .    * class pushop * + @xmath38 @xmath32 + @xmath39 @xmath31 + @xmath9 @xmath30 + @xmath40 @xmath23 + * push*(@xmath41 , @xmath10 ) [ line : push ] + @xmath32 @xmath42 @xmath43 + @xmath36 @xmath42 new @xmath29(@xmath32,@xmath44,@xmath45 @xmath9(@xmath10,@xmath41 ) ) + announce[tid ] @xmath42 @xmath36 + @xmath33(@xmath36 ) +    * help*(@xmath36 ) [ line : help ] + ( @xmath46 , @xmath34 ) @xmath42 @xmath47 \\ { ( @xmath48 , @xmath49 ) @xmath50 @xmath51 , @xmath52 $ ] , ! req.pushed } + attachnode(@xmath34 ) +    * attachnode*(@xmath36 ) +    after , we read the status of the request , and find that it has not completed , we proceed to update the @xmath37 field of the stack top in line  [ line : pushcas ] using a compare - and - set ( cas ) instruction .",
    "the aim is to change the pointer in the @xmath37 field from @xmath53 to the node the push request needs to add . if we are successful , then we need to update the @xmath4 pointer by calling the function , @xmath54 .",
    "after the @xmath4 pointer has been updated , we do not really need the @xmath37 field for subsequent @xmath3 requests .",
    "it will not be used . however",
    ", concurrent requests need to see that @xmath55 has been updated .",
    "the additional compulsion to delete the contents of the pointer in the @xmath37 field is that it is possible to have references to deleted nodes via the @xmath37 field .",
    "the garbage collector in this case will not be able to remove the deleted nodes .",
    "thus , after updating the top pointer , we set the @xmath37 field s pointer to @xmath53 , and set the @xmath13 to true .",
    "if a concurrent request reads the mark to be true , then it can be sure , that the @xmath4 pointer has been updated , and it needs to read it again .",
    "if the cas instruction fails , then it means that another concurrent request has successfully performed a cas operation .",
    "however , it might not have updated the @xmath4 pointer . it is thus necessary to call the @xmath54 function to help the request complete .    *",
    "updatetop * ( ) + @xmath56 @xmath42 @xmath57 ( ) + ( @xmath37 , @xmath13 ) @xmath42 @xmath58 ( ) +    the @xmath54 method is shown in algorithm  [ alg : updatetop ] .",
    "we read the @xmath4 pointer , and the @xmath37 pointer .",
    "if @xmath37 is non - null , then the request has not fully completed .",
    "it is necessary to help it complete . after having checked the value of the @xmath4 pointer , and the value of the @xmath37 field",
    ", we proceed to connect the newly attached node to the stack by updating its @xmath12 pointer .",
    "we set the value of its @xmath12 pointer in line  [ line : push_prev ] .",
    "every node in the stack has an index that is assigned in a monotonically increasing order .",
    "hence , in line  [ line : index ] , we set the index of @xmath37 to 1 plus the index of @xmath56 .",
    "next , we set the @xmath31 field of the @xmath36 equal to true .",
    "the point of linearizability is line  [ line : updatetop ] , where we update the @xmath4 pointer to point to @xmath37 instead of @xmath56 .",
    "this completes the @xmath3 operation .",
    "we have a cleanup mechanism that is invoked once the index of a node becomes a multiple of a constant , @xmath2 .",
    "we invoke the @xmath59 method in line  [ line : trycleanup ] .",
    "it is necessary that the @xmath60 method be called by only one thread .",
    "hence , the thread that successfully performed a cas on the top pointer calls the @xmath59 method if the index is a multiple of @xmath2 .",
    "algorithm  [ alg : pop ] shows the code for the @xmath0 method .",
    "we read the value of the @xmath4 pointer and save it in the local variable , @xmath61 .",
    "this is the only instance in this function , where we read the value of the @xmath4 pointer .",
    "then , we walk back towards the sentinel node by following the @xmath12 pointers ( lines  [ line : popwhile ]  [ line : popwhileend ] ) .",
    "we stop when we are successfully able to set the mark of a node that is unmarked .",
    "this node is logically `` popped '' at this instant of time .",
    "if we are not able to find any such node , and we reach the sentinel node , then we throw an @xmath62 .",
    "* pop * ( ) + @xmath63 @xmath42 @xmath57 ( ) + [ alg : prev_top ] @xmath64 @xmath42 @xmath63 + [ alg : while_mark ] [ line : popwhileend ]    / * try to clean up parts of the stack * / + trycleanup(curr ) [ line : popclean ]    return @xmath64    after logically marking a node as popped , it is time to physically delete it .",
    "we thus call the @xmath59 method in line  [ line : popclean ] .",
    "the @xmath0 method returns the node that it had successfully marked .",
    "the aim of the @xmath28 method is to clean a set of @xmath2 contiguous entries in the list ( indexed by the @xmath12 pointers ) .",
    "let us start by defining some terminology .",
    "let us define a range of @xmath2 contiguous entries , which has four distinguished nodes as shown in figure  [ fig : rangew ] .",
    "a range starts with a node termed the @xmath65 , whose index is a multiple of @xmath2 .",
    "let us now define @xmath66 as @xmath67 .",
    "the node at the end of a range is @xmath68 .",
    "its index is equal to @xmath69 .",
    "let us now define a node @xmath70 such that @xmath71 .",
    "note that for a given range , the @xmath65 and @xmath68 nodes are fixed , whereas the @xmath66 and @xmath70 nodes keep changing .",
    "@xmath70 is the base of another range , and its index is a multiple of @xmath2 .",
    "the @xmath3 and the @xmath0 methods call the function @xmath59",
    ". the @xmath3 method calls it when it pushes a node whose index is a multiple of @xmath2 .",
    "this is a valid @xmath70 .",
    "it walks back and increments the counter of the @xmath65 node of the previous range .",
    "we ensure that only one thread ( out of all the helpers ) does this in line  [ line : onethread ] .",
    "similarly , in the @xmath0 function , whenever we mark a node , we call the @xmath59 function .",
    "since the @xmath0 function does not have any helpers , only one thread per node calls the @xmath59 function .",
    "now , inside the @xmath59 function , we increment the counter of the @xmath65 node . once",
    ", a thread increments it to @xmath72 , it invokes the @xmath28 function .",
    "since only one thread will increment the counter to @xmath72 , only one thread will invoke the @xmath28 function for a range .",
    "entries [ fig : rangew ] ]    * trycleanup(mynode ) * + @xmath73 @xmath42 @xmath74 +    the functionality of the @xmath28 function is very similar to the @xmath3 function . here",
    ", we first create a @xmath75 that has four fields : @xmath32 ( similar to phase in @xmath29 ) , @xmath76 , @xmath77 ( whether the delete has been finished or not ) , and the value of the @xmath65 node .",
    "akin to the @xmath3 function , we add the newly created @xmath75 to a global array of @xmath75s .",
    "subsequently , we find the pending request with the minimum phase in the array @xmath78 .    note that at this stage it is possible for multiple threads to read the same value of the request with the minimum phase number .",
    "it is also possible for different sets of threads to have found different requests to have the minimum phase . for example , if a request with phase 2 ( @xmath79 ) got added to the array before the request with phase 1 ( @xmath80 ) , then a set of threads might be trying to complete @xmath79 , and another set might be trying to complete @xmath80 . to ensure that our stack remains in a consistent state ,",
    "we want that only one set goes through to the next stage .    to achieve this",
    ", we adopt a strategy similar to the one adopted in the function @xmath35 .",
    "interested readers can refer to the appendices for a detailed explanation of how this is done .",
    "beyond this point , all the threads will be working on the same @xmath75 which we term as @xmath81 .",
    "they will then move on to call the @xmath82 function that will actually finish the delete request .",
    "let us describe the @xmath82 function in algorithm  [ alg : helpfinishdelete ] .",
    "we first read the current request from the atomic variable , @xmath81 in line  [ line : currread ] .",
    "if the request is not pending , then some other helper has completed the request , and we can return from the function . however , if this is not the case , then we need to complete the delete operation .",
    "our aim now is to find the @xmath66 , @xmath68 , and @xmath70 .",
    "we search for these nodes starting from the stack top .",
    "the index of the @xmath68 is equal to the index of the node in the current request ( @xmath83 ) + @xmath84 .",
    "@xmath85 is set to this value in line  [ line : endidx ] .",
    "subsequently , in lines  [ line : right][line : sentinel ] , we start from the top of the stack , and keep traversing the @xmath12 pointers till the index of @xmath68 is equal to @xmath85 .",
    "once , the equality condition is satisfied , lines  [ line : right ] and [ line : left ] give us the pointers to the @xmath70 and @xmath68 respectively .",
    "if we are not able to find the @xmath68 , then it means that another helper has successfully deleted the nodes .",
    "we can thus return .",
    "+    * helpfinishdelete * ( ) + @xmath83 @xmath42 @xmath86 ( ) [ line : currread ] + @xmath85 @xmath42 @xmath87 [ line : endidx ] + @xmath70 @xmath42 @xmath88 / * search for the request from the @xmath4 * / + @xmath68 @xmath42 @xmath89 + [ line : sentinel ] / * find the target node * / + @xmath66 @xmath42 @xmath68 [ line : targetstart ] + [ line : targetend ] @xmath90 / * perform the cas operation and delete the nodes * / [ line : rightcas ] + @xmath91 @xmath42 * false * / * set the status of the delete request to not pending*/ [ line : setpending ] +    the next task is to find the @xmath66 .",
    "the @xmath66 is @xmath2 hops away from the @xmath68 .",
    "lines  [ line : targetstart][line : targetend ] run a loop @xmath2 times to find the target . note that we shall never have any issues with null pointers because @xmath92 is set to @xmath22 itself .",
    "once , we have found the target , we need to perform a cas operation on the @xmath12 pointer of the @xmath70 .",
    "we accomplish this in line  [ line : rightcas ] .",
    "if the @xmath12 pointer of @xmath70 is equal to @xmath68 , then we set it to @xmath66 .",
    "this operation removes @xmath2 entries ( from @xmath68 to @xmath65 ) from the list .",
    "the last step is to set the status of the @xmath77 field in the current request ( @xmath83 ) to false ( see line  [ line : setpending ] ) .",
    "the most popular correctness criteria for a concurrent shared object is _ linearizability _  @xcite .",
    "linearizability ensures that within the execution interval of every operation there is a point , called the linearization point , where the operation seems to take effect instantaneously and the effect of all the operations on the object is consistent with the object s sequential specification . by the property of compositional linearizability , if each method of an object is linearizable we can conclude that the complete object is linearizable .",
    "thus , if we identify the point of linearization for both the push and the pop method in our implementation , we can say that our implementation is linearizable and thus establish its correctness .",
    "interested readers can refer to the appendices , where we show that our implementation is legal and push and pop operations complete in a bounded number of steps .",
    "the @xmath3 and @xmath0 operations are linearizable .",
    "let us start out by defining the notion of `` pass points '' .",
    "the pass point of a @xmath3 operation is when it successfully updates the @xmath4 pointer in the function @xmath54 ( line  [ line : updatetop ] ) .",
    "the pass point of the @xmath0 operation , is when it successfully marks a node , or when it throws the _ emtpystackexception_. let us now try to prove by mathematical induction on the number of requests that it is always possible to construct a linearizable execution that is equivalent to a given execution . in a linearizable execution",
    "all the operations are arranged in a sequential order , and if request @xmath93 precedes @xmath94 in the original execution , then @xmath93 precedes @xmath94 in the linearizable execution as well .",
    "* base case : * let us consider an execution with only one pass point . since the execution is complete , we can conclude that there was only one request in the system .",
    "an equivalent linearizable execution will have a single request .",
    "the outcome of the request will be an _ emptystackexception _ if it is a @xmath0 request , otherwise it will push a node to the stack .",
    "our algorithm will do exactly the same in the @xmath0 and @xmath35 methods respectively .",
    "hence , the executions are equivalent .",
    "+ * induction hypothesis : * let us assume that all executions with @xmath95 requests are equivalent to linearizable executions .",
    "+ * inductive step : * let us now prove our hypothesis for executions with @xmath96 requests .",
    "let us arrange all the requests in an ascending order of the execution times of their pass points .",
    "let us consider the last ( @xmath97 ) request just after the pass point of the @xmath98 request .",
    "let the last request be a @xmath3 .",
    "if the @xmath98 request is also a @xmath3 , then the last request will use the @xmath4 pointer updated by the @xmath98 request .",
    "additionally , in this case the @xmath98 request will not see any changes made by the last request .",
    "it will update @xmath99 and the @xmath4 pointer , before the last request updates them . in a similar manner",
    "we can prove that no prior @xmath3 request will see the last request .",
    "let us now consider a prior @xmath0 request .",
    "a @xmath0 request scans all the nodes between the @xmath4 pointer and the sentinel .",
    "none of the pop requests will see the updated @xmath4 pointer by the last request because their pass points are before this event .",
    "thus , they have no way of knowing about the existence of the last request .",
    "since the execution of the first @xmath95 requests is linearizable , an execution with the @xmath97 push request is also linearizable because it takes effect at the end ( and will appear last in the equivalent sequential order ) .",
    "let us now consider the last request to be a @xmath0 operation .",
    "a @xmath0 operation writes to any shared location only after its pass point . before its pass point",
    ", it does not do any writes , and thus all other requests are oblivious of it .",
    "thus , we can remove the last request , and the responses of the first @xmath95 requests will remain the same .",
    "let us now consider an execution fragment consisting of the first @xmath95 requests .",
    "it is equivalent to a linearizable execution , @xmath100 .",
    "this execution is independent of the @xmath97 request .",
    "now , let us try to create a linearizable execution , @xmath101 , which has an event corresponding to the last request . since the linearizable execution is sequential ,",
    "let us represent the request and response of the last @xmath0 operation by a single event , @xmath102 .",
    "let us try to modify @xmath100 to create @xmath101 .",
    "let the sequential execution corresponding to @xmath100 be @xmath103 .",
    "now , it is possible that @xmath102 could have read the @xmath4 pointer long ago , and is somewhere in the middle of the stack . in this case",
    ", we can not assume that @xmath102 is the last request to execute in the equivalent linearizable execution .",
    "let the state of the stack before the @xmath0 reads the top pointer be @xmath104 .",
    "the state @xmath104 is independent of the @xmath0 request .",
    "also note that , all the operations that have arrived after the @xmath0 operation have read the @xmath4 pointer , and overlap with the @xmath0 operation .",
    "the basic rule of @xmath105 states that , if any operation @xmath106 precedes @xmath107 then @xmath106 should precede @xmath107 in the equivalent sequential execution also .",
    "whereas , in case the two operations overlap with each other , then their relative order is undefined and any ordering of these operations is a valid ordering  @xcite .    in this case",
    ", we have two possibilities : ( i ) @xmath102 returns the node that it had read as the top pointer as an output of its @xmath0 operation , or ( ii ) it returns some other node .    in this case",
    ", we can consider the point at which @xmath102 reads the top pointer as the point at which it is _",
    "linearized_. @xmath102 in this case reads the stack top , and pops it .    in this case , some other request , which is concurrent must have popped the node that @xmath102 read as the top pointer .",
    "let @xmath102 return node @xmath108 as its return value .",
    "this node must be between the top pointer that it had read ( node @xmath109 ) , and the beginning of the stack .",
    "moreover , while traversing the stack from @xmath109 to @xmath108 , @xmath102 must have found all the nodes in the way to be marked . at the end it must have found @xmath108 to be unmarked , or would have found @xmath108 to be the end of the stack ( returns exception ) .",
    "let us consider the journey for @xmath102 from @xmath109 to @xmath108 .",
    "let @xmath110 be the last node before @xmath108 that has been marked by a concurrent request , @xmath107 .",
    "we claim that if @xmath102 is linearized right after @xmath107 , and the rest of the sequences of events in @xmath100 remain the same , we have a linearizable execution ( @xmath101 ) .",
    "let us consider request @xmath107 and its position in the sequential execution , @xmath103 . at its point of linearization",
    ", it reads the top of the stack and returns it ( according to @xmath103 ) .",
    "this node @xmath110 is the successor of @xmath108 . at that point @xmath108",
    "becomes the top of the stack . at this position ,",
    "if we insert @xmath102 into @xmath111 , then it will read and return @xmath108 as the stack top , which is the correct value .",
    "subsequently , we can insert the remaining events in @xmath111 into the sequential execution .",
    "they will still return the same set of values because they are unaffected by @xmath102 as proved before .",
    "this proof can be trivially extended to take cleanup operations into account .",
    "every @xmath3 request is inserted at line  [ line : pushcas ] at most once .",
    "[ lemm : atmost ]    to the contrary , let us assume that the same request is inserted at least twice in line  [ line : pushcas ] .",
    "let us consider the sequence of steps that need to take place .",
    "step 0 : : :    read the value of @xmath56 and @xmath37 , and    observe that @xmath140 .",
    "step 1 : : :    we read the status as in line  [ line : ifdone ] . step 2 : : :    the cas succeeds in line  [ line : pushcas ] .",
    "step 3 : : :    some thread reads _",
    "next @xmath141 null _ in    line  [ line : nextnonnull ] ( @xmath54 function ) .",
    "step 4 : : :    the status of the node is updated to by some thread in    line  [ line : announce ] .",
    "step 5 : : :    the top pointer is changed in line  [ line : updatetop ] .    let us now explain the steps and mention why these steps need to be performed in a sequence ( not necessarily by the same thread ) . to insert any node in line  [ line : pushcas ]",
    "it is necessary to perform steps 0 , 1 and 2 because to reach line  [ line : pushcas ] , it is necessary to satisfy the condition of the _ if _ statement in line  [ line : ifdone ] . at this point , the @xmath37 pointer has been updated , and the @xmath4 pointer has not been updated . it is not possible to insert any other request till the @xmath37 pointer does not become @xmath53 .",
    "this is only possible when we update the @xmath4 pointer . to update the @xmath4 pointer some thread  either the thread that is doing the @xmath3 operation , or some other thread  needs to successfully perform the @xmath54 operation .",
    "this can only be achieved if a thread executes lines  [ line : nextnonnull ] to  [ line : updatetop ] , or in other words , performs steps 3 , 4 , and 5 . before the @xmath4 pointer is updated in line  [ line : updatetop ] , another concurrent @xmath3 request can not be successful because two @xmath3 requests can not simultaneously perform a successful cas operation in step 2 .",
    "now we have proved that if any @xmath3 operation has successfully completed step 2 ( performed the cas on the @xmath37 pointer ) , then till steps 3 , 4 , and 5 are performed no other @xmath3 request can be successful .",
    "this means that between any two successful @xmath3 operations , the status of the request needs to be changed ( step 4 ) .",
    "let us now assume that two @xmath3 requests for the same node are successful .",
    "let the request that performs step 2 first be @xmath106 , and let the other request be @xmath107 .",
    "we denote this fact as : @xmath142 .",
    "@xmath107 must read a different value of the stack top in step 0 .",
    "otherwise , it will find @xmath99 to be non - null and it will not proceed beyond step 0 .",
    "subsequently , it will try to read the status of the request in step 1 .",
    "note that this step is preceded by step 4 of @xmath106 .",
    "thus @xmath107 will read the status to , and it will not be able to proceed to step 2 .",
    "consequently , @xmath107 will not be able to do the @xmath3 operation done by @xmath106 once again .",
    "hence , the lemma stands proved .",
    "a @xmath3 request always adds an entry to the top of the stack in line  [ line : pushcas ] in a bounded number of steps .",
    "[ lemm : atleast ]    let us assume that a @xmath3 request , @xmath106 never gets fulfilled .",
    "this can happen because it either fails the @xmath143 conditions in lines  [ line : notlast ] and [ line : nextnull ] , or the cas operation in line  [ line : pushcas ] .",
    "this can only happen if some other @xmath3 request makes progress .",
    "now , let us assume that @xmath106 has the least phase number out of all the @xmath3 requests that remain unfulfilled for an unbounded amount of time .",
    "since @xmath106 has the least phase number out of all the unfulfilled requests , all other request with a lower phase number must have gotten fulfilled .",
    "this means that there is a point of time at which @xmath106 has the least phase in the @xmath23 array . at this point",
    "all the threads must be helping @xmath106 to complete its request .",
    "one of the threads needs to perform a successful cas in line  [ line : pushcas ] . either that thread or some other thread can update the @xmath4 pointer . in this manner ,",
    "request @xmath106 will get satisfied .    hence , it is not possible to have a request , @xmath106 that waits for an infinite amount of time to get fulfilled .    a @xmath3 request adds an entry only once to the stack in a bounded number of steps",
    ". futhermore , if we just consider the @xmath37 pointers , the stack is always a linked list without duplicate nodes .",
    "thus , the @xmath3 operation is lock - free .",
    "lemma  [ lemm : atmost ] and lemma  [ lemm : atleast ] prove that an entry is added only once ( in a bounded number of steps ) .",
    "secondly , we are allowed to modify the @xmath37 pointer of a node only once .",
    "it can not only point to another node .",
    "each node points to another node that is pushed to the stack after it because steps 2 - 5 are executed in sequence .",
    "thus the stack at all times has a structure similar to a linked list .",
    "the end of the linked list is the stack top .",
    "the @xmath0 method does not touch the @xmath37 pointer ; hence , this property is maintained .",
    "every @xmath0 operation pops just one element or returns an emptystackexception .",
    "[ lemm : poponce ]    we start at the stack top ( @xmath144 ) , and proceed towards the bottom of the stack . if we get any unmarked node , then we mark it . after marking a node",
    "the @xmath0 operation is over .",
    "note that there is no helping in the case of a @xmath0 operation .",
    "hence , other threads do not work on behalf of a thread . as a result",
    "only one node is marked ( or popped ) .",
    "if we are not able to mark a node then we return an emtpystackexception .",
    "the crux of our algorithm is the @xmath28 routine , which ensures that the size of the stack never grows beyond a predefined factor , @xmath2 .",
    "this feature allows for a very fast @xmath0 operation , where we need to find the first entry from the top of the stack that is not marked .",
    "this optimization also allows for an increased amount of parallelism , and also decreases write - contention on the @xmath4 pointer because it is not updated by @xmath0 operations . as a result ,",
    "the time per @xmath0 operation is very low .",
    "the @xmath3 operation is also designed to be very fast .",
    "it simply needs to update the @xmath4 pointer to point to the new data . to provide wait - free guarantees it was necessary to design a @xmath28 function that is slow",
    "fortunately , it is not invoked for an average of @xmath84 out of @xmath2 invocations of @xmath3 and @xmath0 .",
    "we can tune the frequency of the @xmath28 operation by varying the parameter , @xmath2 ( to be decided on the basis of the workload ) .",
    "10 [ 1]`#1 `    afek , y. , gafni , e. , morrison , a. : common2 extended to stacks and unbounded concurrency .",
    "distributed computing 20(4 ) , 239252 ( 2007 )    bar - nissan , g. , hendler , d. , suissa , a. : a dynamic elimination - combining stack algorithm . in : principles of distributed systems , pp .",
    "springer ( 2011 )    david , m. , brodsky , a. , fich , f. : restricted stack implementations . in : fraigniaud , p. ( ed . ) distributed computing , lecture notes in computer science , vol . 3724 , pp .",
    "springer berlin heidelberg ( 2005 )    dodds , m. , haas , a. , kirsch , c.m . : a scalable , correct time - stamped stack ( 2014 )    fatourou , p. , kallimanis , n.d . : a highly - efficient wait - free universal construction . in : spaa ( 2011 )",
    "hendler , d. , incze , i. , shavit , n. , tzafrir , m. : flat combining and the synchronization - parallelism tradeoff . in : proceedings of the 22nd acm symposium on parallelism in algorithms and architectures .",
    "acm ( 2010 )    hendler , d. , kutten , s. : constructing shared objects that are both robust and high - throughput . in : distributed computing ,",
    ". 428442 .",
    "springer ( 2006 )    hendler , d. , kutten , s. , michalak , e. : an adaptive technique for constructing robust and high - throughput shared objects - technical report ( 2010 )    hendler , d. , shavit , n. , yerushalmi , l. : a scalable lock - free stack algorithm . in : proceedings of the sixteenth annual acm symposium on parallelism in algorithms and architectures .",
    ". 206215 .",
    "spaa 04 , acm , new york , ny , usa ( 2004 )    herlihy , m. : wait - free synchronization .",
    "acm trans .",
    "13(1 ) , 124149 ( jan 1991 )    herlihy , m. , shavit , n. : the art of multiprocessor programming .",
    "elsevier ( 2012 )    herlihy , m.p . , wing , j.m .",
    ": linearizability : a correctness condition for concurrent objects .",
    "acm trans .",
    "12(3 ) , 463492 ( jul 1990 )    michael , m.m . ,",
    "scott , m.l . : nonblocking algorithms and preemption - safe locking on multiprogrammed shared memory multiprocessors .",
    "journal of parallel and distributed computing 51(1 ) , 1  26 ( 1998 )    shavit , n. , zemach , a. : combining funnels : a dynamic approach to software combining .",
    "journal of parallel and distributed computing 60(11 ) , 13551387 ( 2000 )    treiber , r.k .",
    ": systems programming : coping with parallelism . international business machines incorporated , thomas j. watson research center ( 1986 )",
    "let us now consider the asymptotic worst - case time complexity of the @xmath3 , @xmath0 and @xmath28 methods in terms of the number of concurrent threads in the system ( @xmath5 ) , the actual size of the stack(@xmath111 ) and the parameter @xmath2 .",
    "the time complexity of the @xmath28 method is the same as that of the @xmath112 function .",
    "the @xmath112 function finds the @xmath113 request with the minimum phase number , which requires @xmath114 steps . after having found the request with the minimum phase number , it calls the @xmath115 function .",
    "the @xmath115 function contains a @xmath116 loop . in the worst case",
    "this @xmath116 loop might execute @xmath5 times .",
    "now , when we look into the body of this @xmath116 loop , everything except the call to the @xmath82 function has o(1 ) time complexity .",
    "the @xmath82 function contains two loops .",
    "the first is a @xmath116 loop , which traverses the stack from the top to the point it finds the desired node . in the worst possible case",
    ", this loop might end up traversing the complete stack .",
    "we do not allow the size of the stack to increase by more than a factor of @xmath2 as compared to @xmath111 , the worst case time complexity of this loop is therefore o(@xmath117 ) .",
    "the other loop in the function is a @xmath118 loop , with time complexity o(w ) .",
    "so , the worst case time complexity of the @xmath82 function is o(@xmath117 ) and therefore , the worst case time complexity of the clean function is o(@xmath119 ) .",
    "the high time complexity of this method is an achilles heel of our algorithm ; hence , we are working on reducing its complexity as well as practical run time .",
    "however , it should be noted that this function is meant to be called infrequently ( 1 in @xmath2 times ) .      in the @xmath0 method ,",
    "everything except the @xmath116 loop and the call to the @xmath59 function take o(1 ) time .",
    "the @xmath116 loop is iterated over till the time an unmarked mode is encountered . in our algorithm , as soon as @xmath2 consecutive nodes get marked , we issue a @xmath120 request for it and at any point of time there can be at most @xmath121 @xmath28 requests in the system .",
    "thus after having traversed at most @xmath122 nodes , a @xmath0 request is assured to find an unmarked node .",
    "now , if we analyze the @xmath59 method , in the worst case scenario , the @xmath116 loop inside the function will be iterated over @xmath2 times but the @xmath28 method will only be called at most once .",
    "in fact , the @xmath28 method is called only once for a group of @xmath72 operations , and therefore , the worst case time complexity of the @xmath59 function , which is o(@xmath119 ) , will be incurred very infrequently ( 1 in @xmath2 ) .",
    "nevertheless the worst case time complexity of the @xmath0 operation is o(@xmath119 ) , and the amortized time complexity ( across @xmath2 pop operations is @xmath123 .",
    "the time complexity of the @xmath3 method is the same as that of the @xmath33 function .",
    "since the @xmath33 function is supposed to find the request with the least phase number , it takes at least o(@xmath5 ) time . after having found the request with the minimum phase number , the @xmath33 function calls the @xmath35 function .",
    "note that for any @xmath3 request , the maximum number of times the @xmath116 loop in the @xmath35 function could possibly execute is of o(@xmath5 ) .",
    "also note that everything inside the @xmath116 loop , except the call to the @xmath54 function requires only a constant amount of time for execution .",
    "if the index of the newly pushed node is not a multiple of @xmath2 , the @xmath54 s time complexity is o(1 ) , and therefore the time complexity of the @xmath3 operation is o(@xmath5 ) , but if this is not the case , the time complexity of the @xmath54 function becomes dependent on the time complexity of the @xmath59 function , which is o(@xmath119 ) in the worst case .",
    "all our methods : @xmath3 , @xmath0 and @xmath28 are bounded wait - free .",
    "a @xmath124 is a data structure that provides @xmath3 and @xmath0 operations with @xmath125((last - in - first - out ) semantics .",
    "a data structure is said to respect lifo semantics , if the last element inserted is the first to be removed .",
    "the most popular correctness criteria for a concurrent shared object is _ linearizability _  @xcite .",
    "let us define it formally .",
    "let us define two kinds of events in a method call namely _ invocations ( inv ) _ and _ responses ( resp)_. a chronological sequence of _ invocations ( inv ) _ and _ responses ( resp ) _ events in the entire execution is known as a _",
    "history_. let a matching invocation - response pair with a sequence number @xmath48 be referred to as request @xmath93 .",
    "note that in our system , every invocation has exactly one matching response . a request @xmath93 precedes request @xmath94 , if @xmath93 s response comes before @xmath94 s invocation .",
    "this is denoted by @xmath93 @xmath126 @xmath94 .",
    "a history , @xmath127 , is said to be sequential if an invocation is immediately followed by its response .",
    "a subhistory @xmath128 is the subsequence of @xmath127 containing all the events of thread @xmath129 .",
    "two histories , @xmath127 and @xmath130 , are equivalent if for every thread ,",
    "@xmath131 @xmath132 @xmath133 . a complete history - _ complete(h ) _ is a history that does not have any pending invocations .",
    "the _ sequential specification _ of an object constitutes of the set of all sequential histories that are correct .",
    "a sequential history is _ legal _ if for every object x , @xmath134 is in the sequential specification of x.    a history @xmath127 is linearizable if _",
    "complete(h ) _ is equivalent to a legal sequential history , @xmath111 .",
    "additionally , if @xmath93 @xmath126 @xmath94 in _",
    "complete(h ) _ , then @xmath93 @xmath126 @xmath94 in s also .",
    "alternatively we can say , linearizability ensures that within the execution interval of every operation there is a point , called the linearization point , where the operation seems to take effect instantaneously and the effect of all the operations on the object is consistent with the object s sequential specification .",
    "generally , there are two kinds of implementations for a concurrent object : @xmath135 and @xmath136-@xmath135 . blocking algorithm use locks .",
    "approaches that protect critical sections with locks unnecessarily limit parallelism and are known to be inefficient .    in comparison",
    "non - blocking implementations can prove to be much faster .",
    "such algorithms rely on atomic primitives such as compare - and - set(cas ) , ll / sc , and getandincrement .",
    "they do not have critical sections . in this context , lock - freedom",
    "is defined as a property that ensures that at any point of time at least one thread makes progress . or in other words , the system as a whole is always making progress .",
    "they can still have problems of starvation .",
    "wait - free algorithms provide starvation freedom in addition to being lock - free .",
    "they ensure that every process completes its operation in a finite number of steps .",
    "the wait - free algorithms have a notion of inherent _ fairness _ , where _ fairness _ measures the degree of imbalance across different threads .",
    "we quantify fairness as the ratio of the average number of operations completed by an thread divided by the number of operations completed by the fastest thread .",
    "figure  [ fig : fairness ] shows a comparison of the fairness of our wait - free stack @xmath137 with the lock - free stack @xmath138 in  @xcite and the locked stack in  @xcite @xmath139 . for the @xmath137 version , the average _ fairness _ is around 80% , whereas for @xmath138 the _ fairness _ goes as low as 50% , and for @xmath139 , it even drops to 25% .",
    "also , as shown in figure  [ fig : pdflf ] and  [ fig : pdfwf ] , in the case of @xmath137 , almost all the threads have completed more than 90% of their work , whereas for @xmath138 only 11 out of 64 threads have completed more than 90% of their work and for some threads the percentage of work done is as low as 40% only .",
    "let us consider the @xmath28 method first .",
    "it is called by the @xmath59 method in line  [ line : callclean ] .",
    "the aim of the @xmath28 method is to clean a set of @xmath2 contiguous entries in the list ( indexed by the @xmath12 pointers ) .",
    "let us start out by defining some terminology .",
    "let us define a range of @xmath2 contiguous entries , which has four distinguished nodes ( see figure  [ fig : rangewa ] ) .",
    "a range starts with a node termed the @xmath65 , whose index is a multiple of @xmath2 .",
    "let us now define @xmath66 as @xmath67 .",
    "the node at the end of a range is @xmath68 .",
    "its index is equal to @xmath69 .",
    "let us now define a node @xmath70 such that @xmath71 .",
    "note that for a given range , the @xmath65 and @xmath68 nodes are fixed , whereas the @xmath66 and @xmath70 nodes keep changing .",
    "@xmath70 is the base of another range , and its index is a multiple of @xmath2 .",
    "the @xmath3 and the @xmath0 methods call the function @xmath59",
    ". the @xmath3 method calls it when it pushes a node whose index is a multiple of @xmath2 .",
    "this is a valid @xmath70 .",
    "it walks back and increments the counter of the @xmath65 node of the previous range .",
    "we ensure that only one thread ( out of all the helpers ) does this in line  [ line : onethread ] .",
    "similarly , in the @xmath0 function , whenever we mark a node , we call the @xmath59 function .",
    "since the @xmath0 function does not have any helpers , only one thread per node calls the @xmath59 function .",
    "now , inside the @xmath59 function , we increment the counter of the @xmath65 node .",
    "once , a thread increments it to @xmath72 , it invokes the @xmath28 function .",
    "since only one thread will increment the counter to @xmath72 , only one thread will invoke the @xmath28 function for a range .",
    "* clean*(@xmath41 , @xmath30 ) + @xmath32 @xmath42 @xmath147 ( ) + @xmath36 @xmath42 @xmath45 deleterequest(@xmath32 , @xmath41 , @xmath148 , @xmath30 ) + @xmath78[@xmath41 ] @xmath42 @xmath36 [ line : alldel ] + @xmath112(@xmath36 ) + * helpdelete*(@xmath36 ) + ( @xmath46 , @xmath34 ) @xmath42 @xmath47 \\ { @xmath48 , @xmath49",
    "@xmath50 @xmath51 , @xmath49 = @xmath150 $ ] , @xmath151 = * true * } + @xmath115(@xmath34 ) +      let us now consider the @xmath28 , @xmath112 , and @xmath115 functions .",
    "their functionality at a high level is very similar to the @xmath3 and @xmath33 methods . here",
    ", we first create a @xmath75 that has four fields : @xmath32 ( similar to phase in @xmath29 ) , @xmath76 , @xmath77 ( whether the delete has been finished or not ) , and the value of the @xmath65 node .",
    "akin to the @xmath3 function , we add the newly created @xmath75 to a global array of @xmath75s in line  [ line : alldel ] .",
    "subsequently , we call the @xmath112 function .",
    "this function finds a pending request with the minimum phase in the array @xmath78 , and returns the request as @xmath34 .",
    "subsequently , we invoke @xmath115 .    note that at this stage it is possible for multiple threads to read the same value of the request with the minimum phase number .",
    "it is also possible for different sets of threads to have found different requests to have the minimum phase .",
    "for example , if a request with phase 2 ( @xmath79 ) got added to the array before the request with phase 1 ( @xmath80 ) , then a set of threads might be trying to perform @xmath115 on @xmath80 , and another set might be trying to perform @xmath115 on @xmath80 .",
    "our aim in the @xmath115 function is to ensure that only one set goes through to the next stage .",
    "it takes two arguments : @xmath49 ( request ) and @xmath32 ( phase number ) .",
    "we adopt a strategy similar to the one adopted in the function @xmath35 .",
    "we define a global atomic variable , @xmath81 .",
    "if a delete is not pending ( line  [ line : deluniquepending ] ) on @xmath81 , we read its contents , and try to perform a cas operation on it .",
    "we try to atomically replace its current contents with the argument , @xmath49 .",
    "note that at this stage , only one set of threads will be successful . beyond this point",
    ", all the threads will be working on the same deleterequest .",
    "they will then move on to call the @xmath82 function that will finish the delete request . for threads that are not successful in the cas operation , or threads that find that the current request contained in @xmath81",
    "has a delete pending will also call the @xmath82 function .",
    "this is required to ensure wait freedom .    * helpfinishdelete * ( ) + @xmath83 @xmath42 @xmath86 ( ) [ line : currreada ] + @xmath85 @xmath42 @xmath87 [ line : endidxa ] + / * search for the request from the @xmath4 * / + @xmath70 @xmath42 @xmath88 + @xmath68 @xmath42 @xmath89 + [ line : sentinela ]          lastly , let us describe the @xmath82 function in algorithm  [ alg : helpfinishdeletea ] .",
    "we first read the current request from the atomic variable , @xmath81 in line  [ line : currreada ] .",
    "if the request is not pending , then some other helper has completed the request , and we can return from the function . however , if this is not the case , then we need to complete the delete operation .",
    "our aim now is to find the @xmath66 , @xmath68 , and @xmath70 .",
    "we search for these nodes starting from the stack top .",
    "the index of the @xmath68 is equal to the index of the node in the current request ( @xmath83 ) + @xmath84 .",
    "@xmath85 is set to this value in line  [ line : endidxa ] .",
    "subsequently , in lines  [ line : righta][line : sentinela ] , we start from the top of the stack , and keep traversing the @xmath12 pointers till the index of @xmath68 is equal to @xmath85 . once , the equality condition is satisfied lines  [ line : righta ] and [ line : lefta ] give us the pointers to the @xmath70 and @xmath68 respectively .",
    "if we are not able to find the @xmath68 , then it means that another helper has successfully deleted the nodes .",
    "we can thus return .",
    "the next task is to find the @xmath66 .",
    "the @xmath66 is @xmath2 hops away from the @xmath68 .",
    "lines  [ line : targetstarta][line : targetenda ] run a loop @xmath2 times to find the target . note that we shall never have any issues with null pointers because @xmath92 is set to @xmath22 itself .",
    "once , we have found the target , we need to perform a cas operation on the @xmath12 pointer of the @xmath70 .",
    "we accomplish this in line  [ line : rightcasa ] . if the @xmath12 pointer of @xmath70 is equal to @xmath68 , then we set it to @xmath66 .",
    "this operation removes @xmath2 entries ( from @xmath68 to @xmath65 ) from the list .",
    "the last step is to set the status of the @xmath77 field in the current request ( @xmath83 ) to false ( see line  [ line : setpendinga ] ) ."
  ],
  "abstract_text": [
    "<S> in this paper , we describe a novel algorithm to create a concurrent wait - free stack . to the best of our knowledge , </S>",
    "<S> this is the first wait - free algorithm for a general purpose stack . in the past , researchers have proposed restricted wait - free implementations of stacks , lock - free implementations , and efficient universal constructions that can support wait - free stacks . </S>",
    "<S> the crux of our wait - free implementation is a fast @xmath0 operation that does not modify the stack top ; instead , it walks down the stack till it finds a node that is unmarked . </S>",
    "<S> it marks it but does not delete it . </S>",
    "<S> subsequently , it is lazily deleted by a @xmath1 operation . </S>",
    "<S> this operation keeps the size of the stack in check by not allowing the size of the stack to increase beyond a factor of @xmath2 as compared to the actual size . </S>",
    "<S> all our operations are wait - free and linearizable . </S>"
  ]
}