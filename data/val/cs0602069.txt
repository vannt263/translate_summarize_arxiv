{
  "article_text": [
    "formal concept analysis ( fca )  @xcite has found many applications since its introduction . as the size of datasets grows , such as data generated from high - throughput technologies in bioinformatics ,",
    "there is a need for efficient algorithms for constructing concept lattices .",
    "the input of fca consists of a triple @xmath0 , called _ context _ , where @xmath1 is a set of objects , @xmath2 is a set of attributes , and @xmath3 is a binary relation between @xmath1 and @xmath2 . in fca , the context is structured into a set of _ concepts_. the set of all concepts , when ordered by set - inclusion , satisfies the properties of a _",
    "complete lattice_. the lattice of all concepts is called _ concept _  @xcite or _ galois _  @xcite lattice .",
    "when the binary relation is represented as a bipartite graph , each concept corresponds to a maximal bipartite clique ( or maximal biclique ) .",
    "there is also a one - one correspondence of a closed itemset @xcite studied in data mining and a concept in fca .",
    "the one - one correspondence of all these terminologies  concepts in fca , maximal bipartite cliques in theoretical computer science ( tcs ) , and closed itemsets in data mining ( dm )  was known , e.g. @xcite .",
    "there is extensive work of the related problems in these three communities , e.g. @xcite@xcite in tcs , @xcite@xcite in fca , and @xcite@xcite in dm .",
    "in general , in tcs , the research focuses on efficiently enumerating all maximal bipartite cliques ( of a bipartite graph ) ; in fca , one is interested in the lattice structure of all concepts ; in dm , one is often interested in computing frequent closed itemsets only .",
    "[ [ time - complexity . ] ] time complexity .",
    "+ + + + + + + + + + + + + + + +    given a bipartite graph , it is not difficult to see that there can be exponentially many maximal bipartite cliques . for problems with potentially exponential ( in the size of the input ) size output , in their seminal paper  @xcite ,",
    "johnson  et  al introduced several notions of _ polynomial time _ for algorithms for these problems : _ polynomial total time _",
    ", _ incremental polynomial time _",
    ", _ polynomial delay time_. an algorithm runs in polynomial total time if the time is bounded by a polynomial in the size of the input and the size of the output .",
    "an algorithm runs in incremental polynomial time if the time required to generate a successive output is bounded by the size of input and the size of output generated thus far .",
    "an algorithm runs in polynomial delay time if the generation of each output is only polynomial in the size of input .",
    "it is not difficult to see that polynomial delay is stronger than incremental polynomial ( namely an algorithm with polynomial delay time is also running in incremental polynomial ) , which is stronger than polynomial total time .",
    "polynomial delay algorithm , we can further distinguish if the space used is polynomial or exponential in the input size .",
    "[ [ previous - work . ] ] previous work .",
    "+ + + + + + + + + + + + + +    observe that the maximal bipartite clique ( mbc ) problem is a special case of the maximal clique problem in a general graph .",
    "namely , given a bipartite graph @xmath4 , a maximal bipartite clique corresponds to a maximal clique in @xmath5 where @xmath6 .",
    "consequently , any algorithm for enumerating all maximal cliques in a general graph , e.g. , @xcite , also solves the mbc problem .",
    "in fact , the best known algorithm in enumerating all maximal bipartite cliques , which was proposed by makino and uno  @xcite that takes @xmath7 polynomial delay time where @xmath8 is the maximum degree of @xmath9 , was based on this approach .",
    "the fact that the set of maximal bipartite cliques constitutes a lattice was not observed in the paper and thus the property was not utilized for the enumeration algorithm .    in fca ,",
    "much of research has been devoted to study the properties of the lattice structure .",
    "there are several algorithms , e.g. @xcite , that construct the lattice , i.e. computing all concepts together with its lattice order .",
    "there are also some algorithms that compute only concepts , e.g. @xcite .",
    "( we remark that the idea of using a total _ lectical order _ on concepts ganter s algorithm  @xcite is also used in @xcite for enumerating maximal ( bi)cliques . )",
    "see @xcite for a comparison studies of these algorithms .",
    "the best polynomial total time algorithm was by nourine and raynaud @xcite with @xmath10 time and @xmath11 space , where @xmath12 and @xmath13 and @xmath14 denote the set of all concepts .",
    "this algorithm can be easily modified to run in @xmath15 incremental time @xcite .",
    "observe that the space of total size of all concepts is needed if one is to keep the entire structure explicitly .",
    "there were several other algorithms , e.g.@xcite , all run in @xmath16 polynomial delay .",
    "there is another algorithm  @xcite that is based on divide - and - conquer approach , but the analytical running time of the algorithm is unknown as it is difficult to analyze .",
    "there are several algorithms in data mining for computing frequent closed itemsets , such as charm(-l ) @xcite , and closet(+ )  @xcite .",
    "to our best knowledge , the algorithm with theoretical analysis running time was given in @xcite with @xmath17 incremental polynomial running time , where @xmath12 and @xmath13 .",
    "[ [ our - results . ] ] our results .",
    "+ + + + + + + + + + + +    in this paper , by making use of the lattice structure of concepts , we present a simple and fast algorithm for computing all concepts together with its lattice order .",
    "the main idea of the algorithm is that given a concept , when all of its successors are considered together ( i.e. in a batch manner ) , they can be efficiently computed .",
    "we compute concepts in the breadth first search ( bfs ) order  the ordering given by bfs traversal of the lattice .",
    "when computing the concepts in this way , not only do we compute all concepts but also we identify all successors of each concept .",
    "another idea of the algorithm is that we make use of the concepts generated to dynamically update the adjacency relations .",
    "the running time of our algorithm is @xmath18 polynomial delay for each concept @xmath19 ( see section  [ sec : background ] for related background and terminology ) , where @xmath20 is the reduced adjacency list of @xmath21 .",
    "our algorithm is faster than the best known algorithms for constructing a lattice because the algorithm is faster than a basic algorithm that runs in @xmath22 , where @xmath23 is number of attributes adjacent to the object @xmath21 , and this basic algorithm is already as fast as the current best algorithms for the problem .",
    "we also present two variants of the algorithm : one is computing all concepts only and another is constructing the frequent closed itemset lattice .",
    "both algorithms are faster than the current start - of - the - art program for these problems .",
    "[ [ outline . ] ] outline .",
    "+ + + + + + + +    the paper is organized as follows . in section",
    "[ sec : background ] , we review some background and notation on fca . in section  [ sec :",
    "basic ] , we describe some basic properties of concepts that we use in our lattice - construction algorithm . in section  [ sec :",
    "algorithms ] , we first describe the high level idea of our algorithm . then we describe how to efficiently implement the algorithm . in section  [ sec : variants ] , we describe two variants of the algorithm .",
    "one is for computing all concepts only and another is for constructing a frequent closed itemset lattice .",
    "we conclude with discussion in section  [ sec : discussion ] .",
    "in fca , a triple @xmath24 is called a _ context _ , where @xmath25 is a set of @xmath26 elements , called _ objects _ ; @xmath27 is a set of @xmath28 elements , called _ attributes _ ; and @xmath29 is a binary relation .",
    "the context is often represented by a _",
    "cross - table _ as shown in figure  [ table1 ] .",
    "a set @xmath30 is called an _",
    "object set _ , and a set @xmath31 is called an _ attribute set_. following the convention , we write an object set @xmath32 as @xmath33 , and an attribute set @xmath34 as @xmath35 .    for @xmath36 ,",
    "denote the adjacency list of @xmath37 by @xmath38 .",
    "similarly , for @xmath39 , denote the adjacency list of @xmath40 by @xmath41 .",
    "the function @xmath42 maps a set of objects to their common attributes : @xmath43 , for @xmath30 .",
    "the function @xmath44 maps a set of attributes to their common objects : @xmath45 , for @xmath31 .",
    "it is easy to check that for @xmath30 , @xmath46 , and for @xmath31 , @xmath47 .",
    "an object set @xmath30 is _ closed _ if @xmath48 .",
    "an attribute set @xmath31 is closed if @xmath49 .",
    "the composition of @xmath50 and @xmath51 induces a _ galois connection _ between @xmath52 and @xmath53 .",
    "readers are referred to @xcite for properties of the galois connection .    a pair @xmath54 , with @xmath55 and @xmath56 ,",
    "is called a _ concept _ if @xmath57 and @xmath58 .    for a concept @xmath54 , by definition ,",
    "both @xmath59 and @xmath60 are closed .",
    "the object set @xmath59 is called the _ extent _ of @xmath19 , written as @xmath61 , and the attribute set @xmath60 is called the _ intent _ of @xmath19 , and written as @xmath62 .",
    "the set of all concepts of the context @xmath0 is denoted by @xmath63 or simply @xmath14 when the context is understood .",
    "let @xmath64 and @xmath65 be two concepts in @xmath14 .",
    "observe that if @xmath66 , then @xmath67",
    ". we order the concepts in @xmath14 by the following relation @xmath68 : @xmath69 it is not difficult to see that the relation @xmath68 is a partial order on @xmath14 .",
    "in fact , @xmath70 is a complete lattice and it is known as the _ concept _ or _ galois _ lattice of the context @xmath0 . for @xmath71 with @xmath72 , if for all @xmath73 such that @xmath74 implies that @xmath75 or @xmath76 , then @xmath19 is called the _ successor_(or _ lower neighbor _ ) of @xmath77 , and @xmath77 is called the _ predecessor _ ( or _ upper neighbor _ ) of @xmath19 .",
    "the diagram representing an ordered set ( where only successors / predecessors are connected by edges ) is called a _ hasse diagram _ ( or a line diagram ) .",
    "see figure  [ table1 ] for an example of the line diagram of a galois lattice .    for a concept @xmath78 , @xmath79 and @xmath80 .",
    "thus , @xmath19 is uniquely determined by either its extent , @xmath81 , or by its intent , @xmath82 .",
    "we denote the concepts restricted to the objects @xmath1 by @xmath83 , and the attributes @xmath2 by @xmath84 for @xmath85 , the corresponding concept is @xmath86 . for @xmath87 ,",
    "the corresponding concept is @xmath88 .",
    "the order @xmath68 is completely determined by the inclusion order on @xmath52 or equivalently by the reverse inclusion order on @xmath53 .",
    "that is , @xmath89 and @xmath90 are order - isomorphic .",
    "we have the property that @xmath91 is a successor of @xmath92 in @xmath93 if and only if @xmath94 is a successor of @xmath95 in @xmath96 .",
    "since the set of all concepts is finite , the lattice order relation is completely determined by the covering ( successor / predecessor ) relation .",
    "thus , to construct the lattice , it is sufficient to compute all concepts and identify all successors of each concept .",
    "in this section , we describe some basic properties of the concepts on which our lattice construction algorithms are based .",
    "[ prop-1 ] let @xmath19 be a concept in @xmath63 .",
    "for @xmath97 , if @xmath98 is not empty , @xmath99 is closed .",
    "consequently , @xmath100 is a concept .    for @xmath97 ,",
    "suppose that @xmath98 is not empty .",
    "we will show that @xmath101 .",
    "since @xmath102 , it remains to show that @xmath103 . by definition , @xmath104 .",
    "thus , @xmath105 .",
    "consequently , @xmath106 .",
    "[ cols=\"^,^,^ \" , ]     * example . *",
    "consider the concept @xmath107 of context in figure  [ table1 ] , we have @xmath108 .",
    "for a closed attribute set @xmath109 , denote the set of remaining attributes @xmath110 by @xmath111 .",
    "consider the following equivalence relation @xmath112 on @xmath111 : @xmath113 , for @xmath114 .",
    "let @xmath115 be the equivalence classes induced by @xmath112 , i.e. @xmath116 , and @xmath117 for any @xmath118 , @xmath119 .",
    "we denote the set @xmath120 by @xmath121 .",
    "we call @xmath122 the sibling of @xmath123 for @xmath124 . for convenience",
    ", we will write @xmath125 by @xmath126 . when there is no confusion , we abuse the notation by writing @xmath127 .",
    "note that by definition , @xmath128 for some @xmath129 .",
    "we denote the pairs @xmath130 by @xmath131 .",
    "recall that @xmath89 and @xmath132 are order - isomorphic .",
    "we have the property that @xmath133 is a successor of @xmath92 in @xmath93 if and only if @xmath134 is a successor of @xmath95 in @xmath96 . for each @xmath135 , we call @xmath136 a child of @xmath95 and @xmath95 a parent of @xmath136 . by the definition of the equivalence class , for each @xmath94 that is a successor of @xmath95 , there exists a @xmath137",
    "such that @xmath138 .",
    "that is , if @xmath94 is a successor of @xmath95 , @xmath94 is a child of @xmath95 .",
    "let @xmath139 denote all the successors of @xmath95 , then we have @xmath140 . however , not every child of @xmath95 is a successor of @xmath95 . for the example in figure",
    "[ table1 ] , @xmath141 , where @xmath142 and @xmath143 are successors of @xmath144 but @xmath145 is not . @xmath146 ; while @xmath147 , @xmath148 .",
    "similarly , if @xmath149 is a predecessor of @xmath95 , then p is parent of @xmath95 but it is not necessary that every parent of @xmath95 is a predecessor of @xmath95 .    note that for @xmath150 , if @xmath151 , then by definition @xmath136 is closed .",
    "it is easy to check that the converse is also true .",
    "namely , if @xmath136 is closed , then @xmath151 . in other words",
    ", we have the following proposition .",
    "[ succ - prop ] @xmath152 is closed , @xmath153 .      by definition , an attribute set @xmath95 is closed if @xmath154 . in the following we give",
    "two characterizations for an attribute set being closed based on its relationship with its siblings .",
    "[ close - prop ] for @xmath150 , @xmath136 is not closed if and only if there exists @xmath155 , @xmath156 , such that @xmath157 .",
    "furthermore , for all @xmath155 with @xmath157 , there exists @xmath158 such that @xmath159 , @xmath160 and @xmath161 .",
    "if @xmath136 is not closed , by definition , there exists @xmath162 such that @xmath163 . as @xmath121 is a partition of @xmath111 ,",
    "there exists a @xmath164 such that @xmath165 , and thus @xmath166 .",
    "conversely , suppose there exists @xmath164 such that @xmath167",
    ". then @xmath168 . that is",
    ", @xmath169 , which implies @xmath136 is not closed .",
    "suppose that @xmath157 with @xmath164 .",
    "for @xmath170 , @xmath171 .",
    "thus , there exists @xmath158 such that @xmath159 , @xmath160 . since @xmath172 are disjoint , @xmath173 .",
    "based on the first part of this proposition ( first characterization ) , we can test if @xmath136 is closed , for @xmath150 , by using",
    "_ subset testing _ of its object set against its siblings object set .",
    "namely , @xmath136 is closed if and only @xmath174 is not a proper subset of its siblings object set . in our running example in figure  [ table1 ] , @xmath145",
    "is not closed because its object set @xmath175 is a proper subset of the object set of its sibling , @xmath176 .    in general ,",
    "subset testing operations are expensive .",
    "we , however , can make use of the second part of the proposition ( second characterization ) for testing closure using set exact matching operations instead of subset testing operations .",
    "this is because if we process the children in the decreasing order of their object - set size , we can test the closure of @xmath136 by comparing its size against the size of the attribute set ( if exists ) of @xmath174 .",
    "namely , we first search if @xmath174 exists by a set exact matching operation .",
    "if it does not , then @xmath136 is closed .",
    "otherwise , if the size of the existing attribute set of @xmath174 is greater than @xmath177 , then @xmath136 is not closed . in our running example , @xmath145 is not closed because @xmath178 has a larger attribute set @xmath179 .",
    "in this section , we first describe the algorithm in general terms , independent of the implementation details .",
    "we then show how the algorithm can be implemented efficiently .",
    "recall that constructing a concept lattice includes generating all concepts and identifying each concept s successors .",
    "our algorithm starts with the top concept @xmath180 .",
    "we process the concept by computing all its _ successors _ , and then recursively process each successor by either the depth first search ( dfs ) order  the ordering obtained by dfs traversal of the lattice  or breadth first search ( bfs ) order . according to proposition  [ succ - prop ] , successors of a concept",
    "can be computed from its children .",
    "let @xmath181 be a concept .",
    "first , we compute all the children @xmath182 .",
    "then for each @xmath150 , we check if @xmath136 is closed . if @xmath136 is closed , @xmath183 is a successor of @xmath19 .",
    "since a concept can have several predecessors , it can be generated several times .",
    "we check its existence to make sure that each concept is processed once and only once .",
    "the pseudo - code of the algorithm based on bfs is shown in algorithm  [ bfs - lattice - alg ] .",
    "compute the top concept @xmath184 ; initialize a queue @xmath185 ; compute @xmath186 ;    @xmath187 ; let @xmath188 and suppose @xmath189 ; denote the concept @xmath190 by @xmath191 ; compute @xmath192 ; enqueue @xmath191 to @xmath193 ; identify @xmath191 as a successor of @xmath19 ;      the efficiency of the algorithm depends on the efficient implementation of processing a concept that include three procedures : ( 1 ) computing @xmath194 ; ( 2)testing if an attribute set is closed ; ( 3 ) testing if a concept already exists .",
    "first , we describe how to compute @xmath131 in @xmath195 time , using a procedure , called sprout , described in the following lemma .    for @xmath196 , it takes @xmath195 to compute @xmath197 .",
    "let @xmath198 .",
    "for each @xmath199 , we associate it with a set @xmath99 ( which is initialized as an empty set ) . for each object @xmath200",
    ", we scan through each attribute @xmath37 in its neighbor list @xmath201 , append @xmath21 to the set @xmath99 .",
    "this step takes @xmath195 .",
    "next we collect all the sets @xmath202 .",
    "we use a trie to group the same object set : search @xmath99 in the trie ; if not found , insert @xmath99 into the trie with @xmath203 as its attribute set , otherwise we append @xmath37 to @xmath99 s existing attribute set .",
    "this step takes @xmath204 .",
    "thus , this procedure , called sprout@xmath92 , takes @xmath195 time to compute @xmath131 .    for @xmath150",
    ", we test if @xmath136 is closed based on the second characterization in proposition  [ close - prop ] . for this method to work",
    ", it requires processing the children @xmath131 in the decreasing order of their object - set size .",
    "suppose @xmath205 where @xmath206 before @xmath123 .",
    "if @xmath207 is closed , we also compute its children @xmath208 . now to test if @xmath126 is closed , we check if @xmath209 exists .",
    "if it does not , then @xmath126 is closed .",
    "otherwise , we compare @xmath210 against the size of the existing attribute set of @xmath209 .",
    "if @xmath210 is not smaller , then @xmath126 is closed otherwise it is not . to efficiently search @xmath209",
    ", we use a trie ( with hashing over each node ) to store the object sets of concepts generated so far and it takes linear time to search and insert ( if not exists ) an object set .",
    "that is , it will take @xmath211 time to check if @xmath126 is closed .",
    "the total time it takes to check if all children are closed is @xmath212 .",
    "recall that a concept @xmath213 is uniquely determined by its extent @xmath214 or its intent @xmath95 .",
    "therefore , we can store either the object sets or the attribute sets generated so far in a trie , and then test the existence of @xmath19 by testing the existence of @xmath214 or @xmath95 .",
    "since searching the object sets are needed in testing the closure of an attribute set as described above , the cost of testing the existence @xmath214 comes for free .",
    "note that @xmath215 .",
    "hence , the time it takes to process a concept is dominated by the procedure sprout , in @xmath216 time .",
    "if we can reduce the sizes of the adjacency lists ( @xmath217 ) , we can reduce the running time of the algorithm . note that this basic algorithm is already as fast as any existing algorithm for constructing a concept lattice ( or computing all concepts only that takes @xmath7 time where @xmath8 is the maximum size of adjacency lists ) .    in the following",
    "we describe how to dynamically update the adjacency lists that will reduce the sizes of adjacent lists , and thus improve the running time of the algorithm .",
    "consider a concept @xmath213 , the object sets of all descendants of @xmath19 are all subsets of @xmath214 . to compute the descendants of @xmath19",
    ", it suffices to consider the objects with restriction to @xmath214 . for @xmath150 , by definition , all attributes in @xmath218 have the same adjacency lists when restricting to @xmath214 .",
    "that is , for all @xmath219 , @xmath220 .",
    "in other words , for all @xmath200 , @xmath221 , for all @xmath222 , i.e. , the adjacent list of @xmath21 either contains all elements in @xmath218 or no element in @xmath218 . therefore , we can reduce the sizes of adjacent lists of objects by representing all attributes in @xmath218 by a single element .",
    "for example in figure  example2 , we can use a single element @xmath223 to represent the two attributes @xmath142 and @xmath224 , and @xmath225 to represent @xmath145 and @xmath226 . in doing so ,",
    "we reduce the size of adjacency list of @xmath227 from @xmath226 elements @xmath228 to three elements @xmath229 .",
    "we call the reduced adjacency lists the condensed adjacency lists . denoted the condensed adjacent list by @xmath230",
    ". the set of condensed adjacency lists corresponds to a reduced cross - table .",
    "for example , the reduced cross table of @xmath231 of the above example is shown in figure  [ example2 ] .",
    "c@c@c    & &     + ( a ) & ( b ) & ( c )    in order to use the condensed adjacency lists in procedure sprout , we need to process our concepts in bfs order and it requires one extra level , i.e. in a two - level manner .",
    "more specifically , for a concept @xmath213 , we first compute all its children @xmath186 .",
    "then we dynamically update the adjacency lists by representing the attributes in each child of @xmath19 with one single element .",
    "we then use these condensed adjacency lists to process each child of @xmath19 . that is , instead of using the global adjacency lists , when processing @xmath183 , we use the condensed adjacency lists of its parent .",
    "it takes @xmath232 for @xmath19 to generate its condensed adjacency lists @xmath230 ( see algorithm  [ condenseadj - procedure ] in the appendix for the pseudo - code ) .",
    "and the time for the procedure sprout is @xmath233 ( see algorithm  [ sprout - procedure ] in the appendix for the pseudo - code ) .",
    "notice that @xmath234 , the time for updating the adjacency lists is subsumed by the time required for procedure sprout .",
    "therefore , our new running time is @xmath233 for each concept @xmath92",
    ". see algorithm  [ 2-level - bfs ] for the pseudo - code and figure  [ bfstrees ] for a step - by - step illustration of the algorithm .",
    "for some applications , one is not interested in the entire concept lattice . in the following",
    ", we will describe how to modify our algorithm to solve two special cases : enumerating all concepts only and constructing a frequent closed itemset lattice .      if one is interested in computing all the concepts and not in their lattice order , as in enumerating all maximal bicliques studied in  @xcite .",
    "we can easily modify our algorithm to give an even faster algorithm for this purpose .",
    "this is because in our algorithm , each concept is generated many times , more precisely , at least number of its predecessors times .",
    "for example in figure  [ bfstrees ] , @xmath235 is generated twice , one by each of its predecessor . however , when we need all concepts only , we do not need regenerate the concepts again and again .",
    "this can be easily accomplished by considering the right siblings only in the procedure sprout , i.e. changing the line 3 to @xmath236 , while the other parts of the algorithm remain the same . depending on the lattice structure , this can significantly speed up the algorithm as the number of siblings is decreasing in a cascading fashion .",
    "a more careful analysis is needed for the running time of this algorithm .      in data mining ,",
    "one is interested in large concepts , i.e. @xmath92 where @xmath237 is larger than a threshold .",
    "although our algorithm can naturally be modified to construct such a closed itemset lattice : we stop processing a concept when the size of its object set is less than the given threshold , where objects correspond to transactions and attributes correspond to items .",
    "theoretically , when the memory requirement is not a concern , our algorithm is faster than all other existing algorithms ( including the state - of - art program charm - l ) for constructing such a frequent closed itemset lattice .",
    "however , in practice , for large data sets ( as those studied in data mining ) , the data structure  a trie on objects ( transactions )  requires huge memory and this may threaten the algorithm s practical efficiency .",
    "however , it is not difficult to modify our algorithm so that a trie on attributes ( items ) instead is used .",
    "recall that a trie on objects are required in two steps of our algorithm : testing the closure of an attribute set and testing the existence of a concept .",
    "as noted above , the existence of a concept can also be tested on its intent ( i.e. attributes ) , thus we can use a trie on attributes for testing the existence of a concept . to avoid using a trie on objects for testing the closure of an attribute set , we can use the first characterization in proposition  [ close - prop ] instead , that is , we test the closure of an attribute set by using _ subset testing _ of its object set against its siblings object set , as described in section  [ sec : basic ] .",
    "further , we can employ the practically efficient technique _",
    "diffset _ as in charm(-l ) for both our sprout procedure and subset testing operations .",
    "we are testing the performance of the diffset based implementation on the available benchmarks and the results will be reported elsewhere .",
    "our interest in fca stems from our research in microarray data analysis @xcite .",
    "we have implemented an not yet optimized version of our algorithm ( with less than 500 effective lines in c++ ) .",
    "the program is very efficient for our applications , in which our data consists of about 10000 objects and 29 attributes .",
    "it took less than 1 second for the program to produce the concept lattice ( about 530 vertices / concepts and 1500 edges ) in a pentium iv 3.0ghz computer with 2 g memory running under fedora 2 linux os .",
    "the program is available upon request at this point and will release to the public in the near future .    as fca finds more and more applications , especially in bioinformatics , efficient algorithms for constructing concept / galois lattices",
    "are much needed .",
    "our algorithm is faster than the existing algorithms for this problem , nevertheless , it seems to have much room to improve .",
    "we would like to thank reinhard laubenbacher for introducing us fca .",
    "we thank yang huang for his participation in his project .",
    "v.  choi , y.  huang , v.  lam , d.  potter , r.  laubenbacher , k.  duca . using formal concept analysis for microarray data comparison .",
    "_ dimacs workshop on clustering problems in biological networks .",
    "piscataway , new jersey , may 911 , 2006 .",
    "manuscript in preparation .",
    "t.  kashiwabara , s.  masuda , k.  nakajima , t.  fujisawa .",
    "generation of maximal independent sets of a bipartite graph and maximum cliques of a circular - arc graph .",
    ", 13 , p161174 , 1992 .",
    "johnson , m.  yannakakis , c.h .",
    "papadimitriou . on generating all maximal independent sets . , 27 , p119123 , 1988",
    "search @xmath209 in @xmath259 ; denote @xmath190 by @xmath191 ; @xmath191 is not necessary a concept .",
    "insert @xmath209 into @xmath259 , and associate it with the attribute set @xmath126 ; identify @xmath191 as the successor of @xmath19 ; @xmath267 sprout@xmath268 ; enqueue @xmath191 into @xmath193 ; identify @xmath191 as the successor of @xmath19 ;"
  ],
  "abstract_text": [
    "<S> in this paper , we present a fast algorithm for constructing a concept ( galois ) lattice of a binary relation , including computing all concepts and their lattice order . </S>",
    "<S> we also present two efficient variants of the algorithm , one for computing all concepts only , and one for constructing a frequent closed itemset lattice . </S>",
    "<S> the running time of our algorithms depends on the lattice structure and is faster than all other existing algorithms for these problems . </S>"
  ]
}