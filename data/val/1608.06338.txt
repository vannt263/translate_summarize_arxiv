{
  "article_text": [
    "gesture and human action recognition from visual information is an active research topic in computer vision and machine learning .",
    "it has many potential applications including human - computer interactions and robotics .",
    "since first work  @xcite on action recognition from depth data captured by commodity depth sensors ( e.g. , kinect ) in 2010 , many methods  @xcite for action recognition have been proposed based on specific hand - crafted feature descriptors extracted from depth or skeleton data . with the recent development of deep learning ,",
    "a few methods have also been developed based on convolutional neural networks ( convnets )  @xcite and recurrent neural networks ( rnns )  @xcite .",
    "however , most of the works on gesture / action recognition reported to date focus on the classification of individual gestures or actions by assuming that instances of individual gestures and actions have been isolated or segmented from a video or a stream of depth maps / skeletons before the classification . in the cases of continuous recognition , the input stream usually contains unknown numbers , unknown orders and unknown boundaries of gestures or actions and both segmentation and recognition have to be solved at the same time .",
    "there are three common approaches to continuous recognition .",
    "the first approach is to tackle the segmentation and classification of the gestures or actions separately and sequentially .",
    "the key advantages of this approach are that different features can be used for segmentation and classification and existing classification methods can be leveraged .",
    "the disadvantages are that both segmentation and classification could be the bottleneck of the systems and they can not be optimized together .",
    "the second approach is to apply classification to a sliding temporal window and aggregate the window based classification to achieve final segmentation and classification .",
    "one of the key challenges in this approach is the difficulty of setting the size of sliding window because durations of different gestures or actions can vary significantly .",
    "the third approach is to perform the segmentation and classification simultaneously .",
    "this paper adopts the first approach and focuses on robust classification using convnets that are insensitive to inaccurate segmentation of gestures .",
    "specifically , individual gestures are first segmented based on quantity of movement ( qom )  @xcite from a stream of depth maps . for each segmented gesture , an improved depth motion map ( idmm )",
    "is constructed from its sequence of depth maps .",
    "convnets are used to learn the dynamic features from the idmm for effective classification .",
    "[ fig : framework ] shows the framework of the proposed method .",
    "the rest of this paper is organized as follows .",
    "section ii briefly reviews the related works on video segmentation and gesture / action recognition based on depth and deep learning .",
    "details of the proposed method are presented in section iii .",
    "experimental results on the dataset provided by the challenge are reported in section iv , and section v concludes the paper .",
    "there are many methods proposed for segmenting individual gestures from a video .",
    "the popular and widely used method employs dynamic time warping  ( dtw ) to decide the delimitation frames of individual gestures  @xcite .",
    "difference images are first obtained by subtracting two consecutive grey - scale images and each difference image is partitioned into a grid of @xmath1 cells . each cell",
    "is then represented by the average value of pixels within this cell .",
    "the matrix of the cells in a difference image is flattened as a vector called motion feature and calculated for each frame in the video excluding the final frame .",
    "this results in a @xmath2 matrix of motion features for a video with @xmath3 frames .",
    "the motion feature matrix is extracted from both test video and training video which consists of multiple gestures .",
    "the two matrices are treated as two temporal sequences with each motion feature as a feature vector at an instant of time .",
    "the distance between two feature vectors is defined as the negative euclidean distance and a matrix containing dtw distances ( measuring similarity between two temporal sequences ) between the two sequences is then calculated and analysed by viterbi algorithm  @xcite to segment the gestures .",
    "another category of gesture segmentation methods from a multi - gesture video is based on appearance . upon the general assumption that the _ start _ and",
    "_ end _ frames of adjacent gestures are similar , correlation coefficients  @xcite and k - nearest neighbour algorithm with histogram of oriented gradient  ( hog )  @xcite are used to identify the _ start _ and _ end _ frames of gestures .",
    "jiang et al .",
    "@xcite proposed a method based on quantity of movement  ( qom ) by assuming the same _ start _ pose among different gestures .",
    "candidate delimitation frames are chosen based on the global qom .",
    "after a refining stage which employs a sliding window to keep the frame with minimum qom in each windowing session , the _ start _ and _ end _ frames are assumed to be the remained frames .",
    "this paper adopts the qom based method and its details will be presented in section  [ subsec : video - seg ] .      with microsoft kinect sensors",
    "researchers have developed methods for depth map - based action recognition .",
    "@xcite sampled points from a depth map to obtain a bag of 3d points to encode spatial information and employ an expandable graphical model to encode temporal information @xcite .",
    "yang et al . @xcite stacked differences between projected depth maps as a depth motion map ( dmm ) and then used hog to extract relevant features from the dmm .",
    "this method transforms the problem of action recognition from spatio - temporal space to spatial space . in @xcite ,",
    "a feature called histogram of oriented 4d normals ( hon4d ) was proposed ; surface normal is extended to 4d space and quantized by regular polychorons . following this method , yang and tian @xcite cluster hypersurface normals and form the polynormal which can be used to jointly capture the local motion and geometry information .",
    "super normal vector ( snv ) is generated by aggregating the low - level polynormals . in @xcite ,",
    "a fast binary range - sample feature was proposed based on a test statistic by carefully designing the sampling scheme to exclude most pixels that fall into the background and to incorporate spatio - temporal cues .",
    "existing deep learning approach can be generally divided into four categories based on how the video is represented and fed to a deep neural network .",
    "the first category views a video either as a set of still images  @xcite or as a short and smooth transition between similar frames  @xcite , each color channel of the images is fed to one channel of a convnet . although obviously suboptimal , considering the video as a bag of static frames performs reasonably well .",
    "the second category represents a video as a volume and extends convnets to a third , temporal dimension  @xcite replacing 2d filters with 3d equivalents .",
    "so far , this approach has produced little benefits , probably due to the lack of annotated training data .",
    "the third category treats a video as a sequence of images and feeds the sequence to an rnn  @xcite . an rnn is typically considered as memory cells , which are sensitive to both short as well as long term patterns .",
    "it parses the video frames sequentially and encodes the frame - level information in their memory .",
    "however , using rnns did not give an improvement over temporal pooling of convolutional features  @xcite or over hand - crafted features .",
    "the last category represents a video as one or multiple compact images and adopts available trained convnet architectures for fine - tuning  @xcite .",
    "this category has achieved state - of - the - art results of action recognition on many rgb and depth / skeleton datasets .",
    "the proposed gesture classification in this paper falls into the last category .",
    "the proposed method consists of two major components , as illustrated in fig .",
    "[ fig : framework ] : video segmentation and construction of improved depth motion map ( idmm ) from a sequence of depth maps as the input to convnets . given a sequence of depth maps consisting of multiple gestures , the _ start _ and _ end _ frames of each gesture are identified based on quantity of movement ( qom )  @xcite .",
    "then , one idmm is constructed by accumulating the absolute depth difference between current frame and the _ start _ frame for each gesture segment .",
    "the idmm goes through a pseudo - color coding process to become a pseudo - rgb image as an input to a convnet for classification .",
    "the main objective of pseudo - color coding is to enchance the motin pattern captured by the idmm . in the rest of this section , video segmentation , construction of idmm , pseudo - color coding of idmm , and training of the convnets",
    "are explained in detail .    [ cols=\"^,^,^,^,^,^,^,^\",options=\"header \" , ]",
    "this paper presents an effective yet simple method for continuous gesture recognition using only depth map sequences .",
    "depth sequences are first segmented so that each segmentation contains only one gesture and a convnet is used for feature extraction and classification .",
    "the proposed construction of idmm enables the use of available pre - trained models for fine - tuning without learning afresh .",
    "experimental results on chalearn lap congd dataset verified the effectiveness of the proposed method .",
    "how to exactly extract the neutral pose and fuse different modalities to improve the accuracy will be our future work .",
    "the authors would like to thank nvidia corporation for the donation of a tesla k40 gpu card used in this challenge .",
    "10 w.  li , z.  zhang , and z.  liu , `` action recognition based on a bag of 3d points , '' in _ proc .",
    "ieee computer society conference on computer vision and pattern recognition workshops ( cvprw ) _ , 2010 , pp .",
    "j.  wang , z.  liu , y.  wu , and j.  yuan , `` mining actionlet ensemble for action recognition with depth cameras , '' in _ proc .",
    "ieee conference on computer vision and pattern recognition ( cvpr ) _ , 2012 , pp .",
    "12901297 .",
    "x.  yang , c.  zhang , and y.  tian , `` recognizing actions using depth motion maps - based histograms of oriented gradients , '' in _ proc .",
    "acm international conference on multimedia ( acm mm ) _ , 2012 , pp .",
    "10571060 .",
    "o.  oreifej and z.  liu , `` hon4d : histogram of oriented 4d normals for activity recognition from depth sequences , '' in _ proc .",
    "ieee conference on computer vision and pattern recognition ( cvpr ) _ , 2013 , pp .",
    "716723 .",
    "x.  yang and y.  tian , `` super normal vector for activity recognition using depth sequences , '' in _ proc .",
    "ieee international conference on computer vision and pattern recognition ( cvpr ) _",
    ", 2014 , pp . 804811 .",
    "p.  wang , w.  li , p.  ogunbona , z.  gao , and h.  zhang , `` mining mid - level features for action recognition based on effective skeleton representation , '' in _ proc .",
    "international conference on digital image computing : techniques and applications ( dicta ) _ , 2014 , pp .",
    "18 .",
    "p.  wang , w.  li , z.  gao , c.  tang , j.  zhang , and p.  o. ogunbona , `` convnets - based action recognition from depth maps through virtual cameras and pseudocoloring , '' in _ proc .",
    "acm international conference on multimedia ( acm mm ) _ , 2015 , pp .",
    "11191122 .",
    "p.  wang , w.  li , z.  gao , j.  zhang , c.  tang , and p.  ogunbona , `` action recognition from depth maps using deep convolutional neural networks , '' _ human - machine systems , ieee transactions on _ , vol .",
    "46 , no .  4 , pp . 498509 , 2016 .",
    "p.  wang , z.  li , y.  hou , and w.  li , `` action recognition based on joint trajectory maps using convolutional neural networks , '' in _ proc .",
    "acm international conference on multimedia ( acm mm ) _",
    ", 2016 , pp . 15 .",
    "y.  hou , z.  li , p.  wang , and w.  li , `` skeleton optical spectra based action recognition using convolutional neural networks , '' in _ circuits and systems for video technology , ieee transactions on _ , 2016 , pp .",
    "y.  du , w.  wang , and l.  wang , `` hierarchical recurrent neural network for skeleton based action recognition , '' in _ proc .",
    "ieee conference on computer vision and pattern recognition ( cvpr ) _ , 2015 , pp .",
    "11101118 .      w.  zhu , c.  lan , j.  xing , w.  zeng , y.  li , l.  shen , and x.  xie , `` co - occurrence feature learning for skeleton based action recognition using regularized deep lstm networks , '' in _ the 30th aaai conference on artificial intelligence ( aaai ) _",
    ", 2016 .",
    "j.  wan , v.  athitsos , p.  jangyodsuk , h.  j. escalante , q.  ruan , and i.  guyon , `` csmmi : class - specific maximization of mutual information for action and gesture recognition , '' _ ieee transactions on image processing _ , vol .",
    "23 , no .  7 , pp .",
    "31523165 , july 2014 .",
    "d.  wu , f.  zhu , and l.  shao , `` one shot learning gesture recognition from rgbd images , '' in _ 2012 ieee computer society conference on computer vision and pattern recognition workshops _",
    ", june 2012 , pp . 712 .",
    "w.  li , z.  zhang , and z.  liu , `` expandable data - driven graphical modeling of human actions based on salient postures , '' _ circuits and systems for video technology , ieee transactions on _ , vol .",
    "18 , no .  11 ,",
    "14991510 , 2008 .",
    "j.  yue - hei  ng , m.  hausknecht , s.  vijayanarasimhan , o.  vinyals , r.  monga , and g.  toderici , `` beyond short snippets : deep networks for video classification , '' in _ proc .",
    "ieee conference on computer vision and pattern recognition ( cvpr ) _ , 2015 , pp .",
    "46944702 .",
    "s.  ji , w.  xu , m.  yang , and k.  yu , `` 3d convolutional neural networks for human action recognition , '' _ pattern analysis and machine intelligence , ieee transactions on _ , vol .",
    "35 , no .  1 ,",
    "pp . 221231 , 2013 .",
    "d.  tran , l.  bourdev , r.  fergus , l.  torresani , and m.  paluri , `` learning spatiotemporal features with 3d convolutional networks , '' in _ proc .",
    "ieee international conference on computer vision ( iccv ) _ , 2015 , pp .",
    "44894497 .",
    "j.  donahue , l.  anne  hendricks , s.  guadarrama , m.  rohrbach , s.  venugopalan , k.  saenko , and t.  darrell , `` long - term recurrent convolutional networks for visual recognition and description , '' in _ proc .",
    "ieee conference on computer vision and pattern recognition ( cvpr ) _ , 2015 , pp .",
    "26252634 .",
    "b.  r. abidi , y.  zheng , a.  v. gribok , and m.  a. abidi , `` improving weapon detection in single energy x - ray images through pseudocoloring , '' _ systems , man , and cybernetics , part c : applications and reviews , ieee transactions on _ , vol .",
    "36 , no .  6 , pp .",
    "784796 , 2006 .",
    "a.  krizhevsky , i.  sutskever , and g.  e. hinton , `` imagenet classification with deep convolutional neural networks , '' in _ proc . annual conference on neural information processing systems ( nips ) _ , 2012 , pp .",
    "11061114 .",
    "y.  jia , e.  shelhamer , j.  donahue , s.  karayev , j.  long , r.  b. girshick , s.  guadarrama , and t.  darrell , `` caffe : convolutional architecture for fast feature embedding . '' in _ proc .",
    "acm international conference on multimedia ( acm mm ) _ , 2014 , pp .",
    "675678 .",
    "h.  j. escalante , v.  ponce - lpez , j.  wan , m.  a. riegler , b.  chen , a.  claps , s.  escalera , i.  guyon , x.  bar , p.  halvorsen , h.  mller , and m.  larson , `` chalearn joint contest on multimedia challenges beyond visual analysis : an overview , '' in _ proceedings of icprw _ , 2016 .",
    "j.  wan , g.  guo , and s.  z. li , `` explore efficient local features from rgb - d data for one - shot learning gesture recognition , '' _ ieee transactions on pattern analysis and machine intelligence _",
    "38 , no .  8 , pp .",
    "16261639 , aug 2016 ."
  ],
  "abstract_text": [
    "<S> this paper addresses the problem of continuous gesture recognition from sequences of depth maps using convolutional neural networks ( convnets ) . </S>",
    "<S> the proposed method first segments individual gestures from a depth sequence based on quantity of movement ( qom ) . for each segmented gesture , </S>",
    "<S> an improved depth motion map ( idmm ) , which converts the depth sequence into one image , is constructed and fed to a convnet for recognition . </S>",
    "<S> the idmm effectively encodes both spatial and temporal information and allows the fine - tuning with existing convnet models for classification without introducing millions of parameters to learn . </S>",
    "<S> the proposed method is evaluated on the large - scale continuous gesture recognition of the chalearn looking at people ( lap ) challenge 2016 . </S>",
    "<S> it achieved the performance of 0.2655 ( mean jaccard index ) and ranked @xmath0 place in this challenge .    </S>",
    "<S> gesture recognition ; depth map sequence ; convolutional neural network , depth motion map </S>"
  ]
}