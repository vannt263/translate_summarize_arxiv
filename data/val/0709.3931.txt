{
  "article_text": [
    "predicting interactions between small molecules and proteins is a key element in the drug discovery process .",
    "in particular , several classes of proteins such as g - protein - coupled receptors ( gpcr ) , enzymes and ion channels represent a large fraction of current drug targets and important targets for new drug development  @xcite .",
    "understanding and predicting the interactions between small molecules and such proteins could therefore help in the discovery of new lead compounds .",
    "various approaches have already been developed and have proved very useful to address this _ in silico _ prediction issue  @xcite .",
    "the classical paradigm is to predict the modulators of a given target , considering each target as a different problem .",
    "usual methods are classified into _ ligand - based _ and _ structure - based _ or _ docking _ approaches .",
    "ligand - based approaches compare a candidate ligand to the known ligands of the target to make their prediction , typically using machine learning algorithms  @xcite whereas structure - based approaches use the 3d - structure of the target to determine how well each candidate binds the target  @xcite .",
    "ligand - based approaches necessitate to know enough ligands of a given target with respect to the complexity of the ligand / non - ligand separation to produce accurate predictors .",
    "if few or no ligands are known for a target , one is compelled to use docking approaches , which in turn necessitate to know the 3d structure of the target and are very time consuming . if for a given target with unavailable 3d structure no ligand is known , none of the classical approaches can apply .",
    "this is the case for many gpcr as very few structures have been crystallized so far  @xcite and many of these receptors , referred to as _",
    "gpcr , have no known ligand .    an interesting way to solve this problem is to cast it in the _ chemogenomics _ framework .",
    "chemogenomics aims at mining the _ chemical space _ , which roughly corresponds to the set of all small molecules , for interactions with the _ biological space _ ,",
    "i.e. , the set of all proteins , in particular drug targets .",
    "a salient feature of the chemogenomics approach is the realization that some classes of molecules can bind `` similar '' proteins , suggesting that the knowledge of some ligands for a target can be helpful to determine ligands for similar targets .",
    "besides , this type of method allows for a more rational approach to design drugs since controlling a whole ligand s selectivity profile is crucial to make sure that no side effect occurs and that the compound is compatible with therapeutical usage .",
    "recent reviews  @xcite list several chemogenomic approaches to predict interactions between compounds and targets  @xcite .",
    "many of these chemogenomics methods rely on some fixed choice of which targets should be used when learning a predictor for a given target , the most extreme example being the learning of a predictor for a whole family or subfamily of targets  @xcite .",
    "most of them also need some specific procedure to choose which ligands of the selected targets are used and how they are used .",
    "we propose a method that uses existing and well tested machine learning algorithms , casting the interaction prediction problem in a joint ligand - target space .",
    "this embeds the sharing level threshold problem in a simple representation choice for which we also propose a systematic approach based on combinations of features of the ligand and features of the target .",
    "for the three families of targets of interest , we show that our approach outperforms the state - of - the - art individual svm , and gives good performances even for targets with no known ligand .",
    "we formulate the typical _ in silico _ chemogenomics problem as the following learning problem : given a collection of @xmath0 target / molecule pairs @xmath1 known to interact or not , estimate a function @xmath2 that would predict whether any chemical @xmath3 binds to any target @xmath4 . in this section we propose a rigorous and general framework to solve this problems , building on recent developments of kernel methods in bio- and chemoinformatics .",
    "much effort in chemoinformatics has been devoted to the more restricted problem of mining the chemical space for interaction with a single target @xmath4 , using a training set of molecules @xmath5 known to interact or not with the target .",
    "machine learning approaches , such as artificial neural networks ( ann ) or support vector machines ( svm ) , often provide competitive models for such problems .",
    "the simplest linear models start by representing each molecule @xmath3 by a vector representation @xmath6 , before estimating a linear function @xmath7 whose sign ( positive or negative ) is used to predict whether or not the small molecule @xmath3 is a ligand of the target @xmath4 .",
    "the weight vector @xmath8 is typically estimated based on its ability to correctly predict the classes of molecules in the training set .",
    "the _ in silico _ chemogenomics problem is more general because data involving interactions with different targets are available to train a model which must be able to predict interactions between any molecule and any protein . in order to extend the previous machine learning approaches to this setting , we need to represent a _ pair _",
    "@xmath9 of target @xmath4 and chemicals @xmath3 by a vector @xmath10 , then estimate a linear function @xmath11 whose sign is used to predict whether or not @xmath3 can bind to @xmath4 . as before the vector @xmath12 can be estimated from the training set of interacting and non - interacting pairs , using any linear machine learning algorithm .",
    "to summarize , we propose to cast the _ in silico _ chemogenomics problem as a learning problem in the ligand - target space thus making it suitable to any classical linear machine learning approach as soon as a vector representation @xmath10 is chosen for protein / ligand pairs .",
    "we propose in the next sections a systematic way to design such a representation .",
    "a large literature in chemoinformatics has been devoted to the problem of representing a molecule @xmath4 by a vector @xmath13 , e.g. , using various molecular descriptors  @xcite .",
    "these descriptors encode several features related to the physico - chemical and structural properties of the molecules , and are widely used to model interactions between the small molecules and a single target using linear models described in the previous section  @xcite .",
    "similarly , much work in computational biology has been devoted to the construction of descriptors for genes and proteins , in order to represent a given protein @xmath4 by a vector @xmath14 .",
    "the descriptors typically capture properties of the sequence or structure of the protein , and can be used to infer models to predict , e.g. , the structural or functional class of a protein .    for our _ in silico",
    "_ chemogenomics problem we need to represent each pair @xmath15 of small molecule and protein by a single vector @xmath16 . in order to capture interactions between features of the molecule and of the protein that may be useful predictors for the interaction between @xmath3 and @xmath4",
    ", we propose to consider features for the pair @xmath15 obtained by multiplying a descriptor of @xmath3 with a descriptor of @xmath4 . intuitively , if for example the descriptors are binary indicators of specific structural features in each small molecule and proteins , then the product of two such features indicates that both the small molecule and the target carry specific features , which may be strongly correlated with the fact that they interact .",
    "more generally , if a molecule @xmath3 is represented by a vector of descriptors @xmath13 and a target protein by a vector of descriptors @xmath14 , this suggests to represent the pair @xmath15 by the set of all possible products of features of @xmath3 and @xmath4 , i.e. , by the tensor product : @xmath17 remember that the tensor product in is a @xmath18 vector whose @xmath19-th entry is exactly the product of the @xmath20-th entry of @xmath21 by the @xmath22-th entry of @xmath23 . this representation can be used to combine in a principled way any vector representation of small molecules with any vector representation of proteins , for the purpose of _ in silico _ chemogenomics or any other task involving pairs of molecules / protein . a potential issue with this approach , however , is that the size of the vector representation for a pair may be prohibitively large for practical computation and storage .",
    "for example , using a vector of molecular descriptors of size @xmath24 for molecules and representing a protein by the vector of counts of all @xmath25-mers of amino - acids in its sequence ( @xmath26 ) results in more than 400k dimensions for the representation of a pair . in order to circumvent this issue",
    "we now show how kernel methods such as svm can efficiently work in such large spaces .",
    "svm is an algorithm to estimate linear binary classifiers from a training set of patterns with known class  @xcite .",
    "a salient feature of svm , often referred to as the _ kernel trick _ , is its ability to process large- or even infinite - dimensional patterns as soon as the inner product between any two patterns can be efficiently computed .",
    "this property is shared by a large number of popular linear algorithms , collectively referred to as _ kernel methods _ , including for example algorithms for regression , clustering or outlier detection  @xcite .    in order to apply kernel methods such as svm for _ in silico _",
    "chemogenomics , we therefore need to show how to efficiently compute the inner product between the vector representations of two molecule / protein pairs .",
    "interestingly , a classical and easy to check property of tensor products allows to write the inner product between two tensor product vectors as a product of inner products : @xmath27 this factorization dramatically reduces the burden of working with tensor products in large dimensions .",
    "for example , in our previous example where the dimensions of the small molecule and proteins are vectors of respective dimensions @xmath24 and @xmath28 , the inner product in @xmath29 dimensions between tensor products is simply obtained from ( [ eq : inptp ] ) by computing two inner products , respectively in dimensions @xmath24 and @xmath28 , before taking their product .",
    "even more interestingly , this reasoning extends to the case where inner products between vector representations of small molecules and proteins can themselves be efficiently computed with the help of _ positive definite _",
    "kernels  @xcite , as explained in the next sections .",
    "positive definite kernels are linked to inner products by a fundamental result  @xcite : the kernel between two points is equivalent to an inner product between the points mapped to a hilbert space uniquely defined by the kernel .",
    "now by denoting @xmath30 we obtain the inner product between tensor products by : @xmath31    in summary , as soon as two kernels @xmath32 and @xmath33 corresponding to two implicit embeddings of the chemical and biological spaces in two hilbert spaces are chosen , we can solve the _ in silico _ chemogenomics problem with an svm ( or any other relevant kernel method ) using the product kernel ( [ eq : product ] ) between pairs .",
    "the particular kernels @xmath32 and @xmath33 should ideally encode properties related to the ability of similar molecules to bind similar targets or ligands respectively .",
    "we review in the next two sections possible choices for such kernels .",
    "recent years have witnessed impressive advances in the use of svm in chemoinformatics  @xcite . in particular much work",
    "has focused on the development of kernels for small molecules for the purpose of single - target virtual screening and prediction of pharmacokinetics and toxicity .",
    "for example simple inner products between vectors of classical molecular descriptors have been widely investigated , including physicochemical properties of molecules or 2d and 3d fingerprints  @xcite .",
    "other kernels have been designed directly from the comparison of 2d and 3d structures of molecules , including kernels based on the detection of common substructures in the 2d structures molecules seen as graphs  @xcite or on the encoding of various properties of the 3d structure of a molecules  @xcite .",
    "while any of these kernels could be used to model the similarities of small molecules and be plugged into ( [ eq : product ] ) , we restrict ourselves in our experiment to a particular kernel proposed by  @xcite called the _ tanimoto kernel _ , a classical choice that usually gives state - of - the - art performances in molecule classification tasks .",
    "it is defined as : @xmath34 where @xmath21 is a binary vector whose bits indicate the presence or absence of all linear path of length @xmath35 or less as subgraph of the 2d structure of @xmath3 .",
    "we chose @xmath36 in our experiment , i.e. , characterize the molecules by the occurrences of linear subgraphs of length @xmath37 or less , a value previously observed to give good results in several virtual screening task @xcite .",
    "we used the freely and publicly available _",
    "_ chemcpp _ _ software to compute this kernel in the experiments .",
    "svm and kernel methods are also widely used in bioinformatics  @xcite , and a variety of approaches have been proposed to design kernels between proteins , ranging from kernels based on the amino - acid sequence of a protein  @xcite to kernels based on the 3d structures of proteins  @xcite or the pattern of occurrences of proteins in multiple sequenced genomes  @xcite .",
    "these kernels have been used in conjunction with svm or other kernel methods for various tasks related to structural or functional classification of proteins .",
    "while any of these kernels can theoretically be used as a target kernel in , we investigate in this paper a restricted list of specific kernels described below , aimed at illustrating the flexibility of our framework and test various hypothesis .",
    "* the _ dirac _ kernel between two targets @xmath38 is : @xmath39 this basic kernel simply represents different targets as orthonormal vectors .",
    "from ( [ eq : product ] ) we see that orthogonality between two proteins @xmath4 and @xmath40 implies orthogonality between all pairs @xmath15 and @xmath41 for any two small molecules @xmath3 and @xmath42 .",
    "this means that a linear classifier for pairs @xmath15 with this kernel decomposes as a set of independent linear classifiers for interactions between molecules and each target protein , which are trained without sharing any information of known ligands between different targets . in other words , using dirac kernel for proteins amounts to performing classical learning independently for each target , which is our baseline approach .",
    "* the _ multitask _ kernel between two targets @xmath38 is defined as : @xmath43 this kernel , originally proposed in the context of multitask learning @xcite , removes the orthogonality of different proteins to allow sharing of information . as explained in @xcite , plugging @xmath44 in amounts to decomposing the linear function used to predict interactions as a sum of a linear function common to all targets and of a linear function specific to each target : @xmath45 a consequence is that only data related to the the target @xmath4 are used to estimate the specific vector @xmath8 , while all data are used to estimate the common vector @xmath46 . in our framework",
    "this classifier is therefore the combination of a target - specific part accounting for target - specific properties of the ligands and a global part accounting for general properties of the ligands across the targets .",
    "the latter term allows to share information during the learning process , while the former ensures that specificities of the ligands for each target are not lost .",
    "* while the multitask kernel provides a basic framework to share information across proteins , it does not allow to weight differently how known interactions with a protein @xmath4 should contribute to predict interactions with a target @xmath40 .",
    "empirical observations underlying chemogenomics , on the other hand , suggest that molecules binding a ligand @xmath4 are only likely to bind ligand @xmath40 similar to @xmath4 in terms of structure or evolutionary history . in terms of kernels",
    "this suggest to plug into   a kernel for proteins that quantifies this notion of similarity between proteins , which can for example be detected by comparing the sequences of proteins . in order to test this approach ,",
    "we therefore tested two commonly - used kernels between protein sequences : the mismatch kernel  @xcite , which compares proteins in terms of common short sequences of amino acids up to some mismatches , and the local alignment kernel  @xcite which measures the similarity between proteins as an alignment score between their primary sequences . in our experiments involving the mismatch kernel",
    ", we use the classical choice of @xmath47-mers with a maximum of @xmath48 mismatch , and for the datasets where some sequences were not available in the database , we added @xmath49 to the kernel ( and normalized at @xmath48 on the diagonal ) in order to keep it valid .",
    "* alternatively we propose a new kernel aimed at encoding the similarity of proteins with respect to the ligands they bind . indeed , for most major classes of drug targets such as the ones investigated in this study ( gpcr , enzymes and ion channels )",
    ", proteins have been organized into hierarchies that typically describe the precise functions of the proteins within each family .",
    "enzymes are labeled with _ enzyme commission numbers _ ( ec numbers ) defined in  @xcite , that classify the chemical reaction they catalyze , forming a @xmath50-level hierarchy encoded into 4 numbers .",
    "for example @xmath51 includes oxydoreductases , @xmath52 includes oxidoreductases that act on the aldehyde or oxo group of donors , @xmath53 is a subclass of @xmath52 with @xmath54 or @xmath55 as acceptor and @xmath56 is a subgroup of enzymes catalyzing the oxidation of formate to bicarbonate .",
    "these number define a natural and very informative hierarchy on enzymes : one can expect that enzymes that are closer in the hierarchy will tend to have more similar ligands .",
    "similarly , gpcrs are grouped into @xmath50 classes based on sequence homology and functional similarity : the _ rhodopsin _ family ( class a ) , the _ secretin _ family ( class b ) , the _ metabotropic _ family ( class c ) and a last class regrouping more diverse receptors ( class d ) .",
    "the kegg database  @xcite subdivides the large rhodopsin family in three subgroups ( amine receptors , peptide receptors and other receptors ) and adds a second level of classification based on the type of ligands or known subdivisions . for example , the rhodopsin family with amine receptors is subdivided into cholinergic receptors , adrenergic receptors , _",
    "etc_. this also defines a natural hierarchy that we could use to compare gpcrs .",
    "finally , kegg also provides a classification of ion channels .",
    "classification of ion channels is a less simple task since some of them can be classified according to different criterions like voltage dependence or ligand - gating .",
    "the classification proposed by kegg includes _ cys - loop superfamily , glutamate - gated cation channels , epithelial and related na+ channels , voltage - gated cation channels , related to voltage - gated cation channels , related to inward rectifier k+ channels , chloride channels _ and _ related to atpase - linked transporters _ and each of these classes is further subdivided according for example to the type of ligands ( _ e.g. _ , glutamate receptor ) or to the type of ion passing through the channel ( _ e.g. _ , na+ channel ) . here again , this hierarchy can be used to define a meaningful similarity in terms of interaction behavior .",
    "+ for each of the three target families , we define the hierarchy kernel between two targets of the family as the number of common ancestors in the corresponding hierarchy plus one , that is , @xmath57 where @xmath58 contains as many features as there are nodes in the hierarchy , each being set to @xmath48 if the corresponding node is part of @xmath4 s hierarchy and @xmath59 otherwise , plus one feature constantly set to one that accounts for the `` plus one '' term of the kernel .",
    "we extracted compound interaction data from the kegg brite database  @xcite concerning enzyme , gpcr and ion channel , three target classes particularly relevant for novel drug development .    for each family ,",
    "the database provides a list of known compounds for each target . depending on the target families , various categories of compounds",
    "are defined to indicate the type of interaction between each target and each compound .",
    "these are for example _ inhibitor , cofactor _ and _ effector _ for enzyme ligands , _ antagonist _ or _ ( full / partial ) agonist _ for gpcr and _ pore blocker , ( positive / negative ) allosteric modulator , agonist _ or _ antagonist _ for ion channels .",
    "the list is not exhaustive for the latter since numerous categories exist .",
    "although different types of interactions on a given target might correspond to different binding sites , it is theoretically possible for a non - linear classifier like svm with non - linear kernels to learn classes consisting of several disconnected sets .",
    "therefore , for the sake of clarity of our analysis , we do not differentiate between the categories of compounds .",
    "we eliminated all compounds for which no molecular descriptor was available ( principally peptide compounds ) , and all the targets for which no compound was known . for each target , we generated as many negative ligand - target pairs as we had known ligands forming positive pairs by combining the target with a ligand randomly chosen among the other target s ligands ( excluding those that were known to interact with the given target ) .",
    "this protocol generates false negative data since some ligands could actually interact with the target although they have not been experimentally tested , and our method could benefit from experimentally confirmed negative couples .",
    "this resulted in @xmath60 data points for enzymes ( @xmath61 known enzyme - ligand pairs and @xmath61 generated negative points ) representing interactions between @xmath62 enzymes and @xmath63 compounds , @xmath64 training data points for gpcrs representing interactions between @xmath65 receptors and @xmath66 compounds and @xmath67 ion channel data points representing interactions between @xmath68 channels and @xmath69 compounds .",
    "besides , figure  [ fig : distrib ] shows the distribution of the number of known ligands per target for each dataset and illustrates the fact that for most of them , few compounds are known .                for each target @xmath4 in each family , we carried out two experiments .",
    "first , all data points corresponding to other targets in the family were used for training only and the @xmath70 points corresponding to @xmath4 were @xmath71-folded with @xmath72 .",
    "that is , for each fold , an svm classifier was trained on all points involving other targets of the family plus a fraction of the points involving @xmath4 , then the performances of the classifier were tested on the remaining fraction of data points for @xmath4 .",
    "this protocol is intended to assess the incidence of using ligands from other targets on the accuracy of the learned classifier for a given target .",
    "second , for each target @xmath4 we learned an svm classifier using only interactions that did not involve @xmath4 and tested on the points that involved @xmath4 .",
    "this is intended to simulate the behavior of our framework when making predictions for orphan targets , _",
    "i.e. _ , for targets for which no ligand is known .",
    "for the first protocol , since learning an svm with only one training point does not really make sense and can lead to `` anti - learning '' less than @xmath73 performances , we set all results @xmath74 involving the dirac target kernel on targets with only @xmath48 known ligand to @xmath75 .",
    "this is to avoid any artefactual penalization of the dirac approach and make sure we measure the actual improvement brought by sharing information across targets .",
    "we first expose the results obtained on the three datasets for the first experiment , assessing how using training points from other targets of the family improves prediction accuracy with respect to individual ( dirac - based ) learning .",
    "table  [ tab : exp1 ] shows the mean success rate across the family targets for an svm with a product kernel using the tanimoto kernel for ligands and various kernels for proteins .    ) for ion channels with multitask , hierarchy and local alignment kernels . ]    ) for ion channels with multitask , hierarchy and local alignment kernels . ]    ) for ion channels with multitask , hierarchy and local alignment kernels . ]    for the enzymes and ion channels datasets , we observe significant improvements when the multitask kernel is used in place of the dirac kernel , on the one hand , and when the hierarchy kernel replaces the multitask kernel , on the other hand .",
    "for example , the dirac kernel only performs at an average accuracy of @xmath76 for the ion channel dataset , while the multitask kernel increases the accuracy to @xmath77 and the hierarchy kernel brings it to @xmath78 . for the enzymes , a global improvement of @xmath79",
    "is observed between the dirac and the hierarchy approaches .",
    "this clearly demonstrates the benefits of sharing information among known ligands of different targets , on the one hand , and the relevance of incorporating prior information into the kernels , on the other hand .    on the gpcr dataset",
    "though , the multitask kernel performs worse than the dirac kernel , probably because some targets in different subclasses show very different binding behavior which results in adding more noise than information when sharing naively with this kernel .",
    "however a more careful handling of the similarities between gpcrs through the hierarchy kernel again results in significant improvement over the dirac kernel ( from @xmath80 to @xmath81 ) , again demonstrating the relevance of the approach .",
    "sequence - based target kernels do not achieve the same performance as the hierarchy kernel , although they perform relatively well for the ion channel dataset . in the case of enzymes ,",
    "it can be explained by the diversity of the proteins in the family and for the gpcr , by the well known fact that the receptors do not share overall sequence homology  @xcite .",
    "figure  [ fig : kernels ] shows 3 of the tested target kernels for the ion channel dataset .",
    "the hierarchy kernel adds some structure information with respect to the multitask kernel , which explains the success rate increase .",
    "the local alignment sequence - based kernels fail to precisely re - build this structure but retains some substructures . in the cases of gpcr and enzymes , almost no structure is found by the sequence kernels , which , as alluded to above , was expectable and suggests that more subtle comparison of the sequences would be required to exploit the information they contain .",
    "figure  [ fig : ratios ] illustrates the influence of the number of training points for a target on the improvement brought by using information from similar targets . as one could expect , the improvement is very strong when few ligands are known and decreases when enough training points become available . after a certain point ( around @xmath82 training points ) , using similar targets can even deteriorates the performances .",
    "this suggests that the method could be globally improved by learning for each target independently how much information should be shared , for example through kernel learning approaches  @xcite .    *",
    "4c @xmath83 target & enzymes & gpcr & channels + dirac & @xmath84 & @xmath85 & @xmath86 + multitask & @xmath87 & @xmath88 & @xmath89 + hierarchy & @xmath90 & @xmath91 & @xmath92 + mismatch & @xmath93 & @xmath94 & @xmath95 + local alignment & @xmath96 & @xmath97 & @xmath98 +                the second experiment aims at pushing this remark to its limit by assessing how each strategy is able to predict ligands for proteins with no known ligand .",
    "table  [ tab : exp2 ] shows the results in that case .",
    "as expected , the classifiers using dirac kernels show random behavior in this case since using a dirac kernel with no data for the target amounts to learning with no training data at all .",
    "on the other hand we note that it is still possible to obtain reasonable results using adequate target kernels .",
    "in particular , the hierarchy kernel loses only @xmath99 for the ion channel dataset , @xmath100 for the gpcr dataset and @xmath101 compared to the first experiment where known ligands were used , suggesting that if a target with no known compound is placed in the hierarchy through , _",
    "e.g. _ in the case of gpcr homology detection with known members of the family using specific gpcr alignment algorithms  @xcite or fingerprint analysis  @xcite , it is possible to predict some of its ligands almost as accurately as if some of them were already available .    *",
    "4c @xmath83 target & enzymes & gpcr & channels + dirac & @xmath102 & @xmath102 & @xmath102 + multitask & @xmath103 & @xmath104 & @xmath105 + hierarchy & @xmath106 & @xmath107 & @xmath108 + mismatch & @xmath109 & @xmath110 & @xmath111 + local alignment & @xmath112 & @xmath113 & @xmath114 +",
    "we propose a general method to combine the chemical and the biological space in a principled way and predict interaction between any small molecule and any target , which makes it a vary valuable tool for drug discovery .",
    "the method allows to represent systematically a ligand - target couple , including information on the interaction between the ligand and the target .",
    "prediction is then performed by any machine learning algorithm ( an svm in our case ) in the joint space , which makes targets with few known ligands benefit from the data points of similar targets , and which allows to make predictions for targets with no known ligand .",
    "our information sharing process therefore simply relies on a description choice for the ligands , another one for the targets and on classical machine learning methods : everything is done by casting the problem in a joint space and no explicit procedure to select which part of the information is shared is needed . since it subdivides the representation problem into two subproblems , our approach makes use of previous work on kernels for molecular graphs and kernels for biological targets . for the same reason",
    ", it will automatically benefit from future improvements in both fields .",
    "this leaves plenty of room to increase the performance .",
    "results on experimental ligand datasets show that using target kernels allowing to share information across the targets considerably improve the prediction , especially in the case of targets with few known ligands .",
    "the improvement is particularly strong when the target kernel uses prior information on the structure between the targets , _",
    "e.g. _ , a hierarchy defined on a target class .",
    "although sequence kernels did not give very good results in our experiments , we believe using the target sequence information could be an interesting alternative or complement to the hierarchy kernel . further improvement could come from the use of kernel for structures in the cases where 3d structure information is available ( _ e.g. _ for the enzymes , but not for the gpcr ) .",
    "our method also shows good performances even when no ligand at all is known for a given target , which is excellent news since classical ligand based approaches fail to predict ligand for these targets in the one hand , and docking approaches are computationally expensive and not feasible when the target 3d structure is unknown which is the case of gpcr in the other hand .    in future work , it could be interesting to apply this framework to quantitative prediction of binding affinity using regression methods in the joint space .",
    "it would also be important to confirm predicted ligands experimentally or at least by docking approaches when the target 3d structure is available .",
    "we thank pierre mah for his help with chemcpp and kernels for molecules , and vronique stoven for insightful discussions on the biological aspects of the problem .",
    "attwood , t.  k. , bradley , p. , flower , d.  r. , gaulton , a. , maudling , n. , mitchell , a.  l. , moulton , g. , nordle , a. , paine , k. , taylor , p. , uddin , a. , and zygouri , c. ( 2003 ) .",
    "prints and its automatic supplement , preprints . , * 31*(1 ) , 400402 .",
    "azencott , c .- a . , ksikes , a. , swamidass , s.  j. , chen , j.  h. , ralaivola , l. , and baldi , p. ( 2007 ) .",
    "one- to four - dimensional kernels for virtual screening and the prediction of physical , chemical , and biological properties .",
    ", * 47*(3 ) , 965974 .",
    "boser , b.  e. , guyon , i.  m. , and vapnik , v.  n. ( 1992 ) . a training algorithm for optimal margin classifiers . in _ proceedings of the 5th annual acm workshop on computational learning theory _ , pages 144152 .",
    "acm press .",
    "grtner , t. , flach , p. , and wrobel , s. ( 2003 ) . on graph kernels : hardness results and efficient alternatives . in b.",
    "schlkopf and m.  warmuth , editors , _ proceedings of the sixteenth annual conference on computational learning theory and the seventh annual workshop on kernel machines _ , volume 2777 of _ lecture notes in computer science _",
    ", pages 129143 , heidelberg .",
    "horvth , t. , grtner , t. , and wrobel , s. ( 2004 ) .",
    "cyclic pattern kernels for predictive graph mining . in _ proceedings of the tenth acm sigkdd international conference on knowledge discovery and data mining _ , pages 158167 , new york ,",
    "ny , usa . acm press .",
    "ivanciuc , o. ( 2007 ) .",
    "applications of support vector machines in chemistry . in k.",
    "b. lipkowitz and t.  r. cundari , editors , _ reviews in computational chemistry _ ,",
    "volume  23 , pages 291400 , weiheim .",
    "wiley - vch .",
    "kashima , h. , tsuda , k. , and inokuchi , a. ( 2003 ) .",
    "marginalized kernels between labeled graphs . in t.",
    "faucett and n.  mishra , editors , _ proceedings of the twentieth international conference on machine learning _ , pages 321328 .",
    "aaai press .",
    "kratochwil , n.  a. , malherbe , p. , lindemann , l. , ebeling , m. , hoener , m.  c. , mhlemann , a. , porter , r. h.  p. , stahl , m. , and gerber , p.  r. ( 2005 ) .",
    "an automated system for the analysis of g protein - coupled receptor transmembrane binding pockets : alignment , receptor - based pharmacophores , and their application .",
    ", * 45*(5 ) , 13241336 .",
    "leslie , c. , eskin , e. , and noble , w. ( 2002 ) .",
    "the spectrum kernel : a string kernel for svm protein classification . in r.  b. altman , a.  k. dunker , l.  hunter , k.  lauerdale , and t.  e. klein , editors , _ proceedings of the pacific symposium on biocomputing 2002 _ , pages 564575 .",
    "world scientific .",
    "oloff , s. , zhang , s. , sukumar , n. , breneman , c. , and tropsha , a. ( 2006 ) .",
    "chemometric analysis of ligand receptor complementarity : identifying complementary ligands based on receptor information ( colibri ) .",
    ", * 46*(2 ) , 844851 .",
    "ramon , j. and grtner , t. ( 2003 ) .",
    "xpressivity versus efficiency of graph kernels . in t.",
    "washio and l.  de  raedt , editors , _ proceedings of the first international workshop on mining graphs , trees and sequences _ , pages 6574 .",
    "vert , j .-",
    ", saigo , h. , and akutsu , t. ( 2004 ) .",
    "local alignment kernels for biological sequences . in b.",
    "schlkopf , k.  tsuda , and j.  vert , editors , _ kernel methods in computational biology _ , pages 131154 . mit press .",
    "zernov , v.  v. , balakin , k.  v. , ivaschenko , a.  a. , savchuk , n.  p. , and pletnev , i.  v. ( 2003 ) .",
    "drug discovery using support vector machines .",
    "the case studies of drug - likeness , agrochemical - likeness , and enzyme inhibition predictions .",
    ", * 43*(6 ) , 204856 ."
  ],
  "abstract_text": [
    "<S> predicting interactions between small molecules and proteins is a crucial ingredient of the drug discovery process . in particular , </S>",
    "<S> accurate predictive models are increasingly used to preselect potential lead compounds from large molecule databases , or to screen for side - effects . while classical _ in silico _ approaches </S>",
    "<S> focus on predicting interactions with a given specific target , new chemogenomics approaches adopt cross - target views . building on recent developments in the use of kernel methods in bio- and chemoinformatics , we present a systematic framework to screen the chemical space of small molecules for interaction with the biological space of proteins . </S>",
    "<S> we show that this framework allows information sharing across the targets , resulting in a dramatic improvement of ligand prediction accuracy for three important classes of drug targets : enzymes , gpcr and ion channels . </S>"
  ]
}