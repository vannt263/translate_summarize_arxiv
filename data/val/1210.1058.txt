{
  "article_text": [
    "during the last decades nonlinear models have become a workhorse for data analysis in many applications . while there is now an extensive literature on data analysis for such models , research on design selection",
    "has not kept pace , even though there has seen a spike in activity in recent years . identifying optimal designs for nonlinear models",
    "is indeed much more difficult than the much better studied corresponding problem for linear models . for nonlinear models results",
    "can typically only be obtained on a case - by - case basis , meaning that each combination of model , optimality criterion and objective of the experiment requires its own proof .",
    "another challenge is that for a nonlinear model an optimal design typically depends on the unknown parameters .",
    "this leads to the concept of locally optimal designs , which are optimal for a priori chosen values of the parameters .",
    "the designs may be poor if the choice of values is far from the true values .",
    "where feasible , a multistage approach could help with this . a  small initial design is then used to obtain some information about the parameters , and this information is used at the next stage to estimate the true parameter values and to extend the initial design in a locally optimal way to a larger design .",
    "the design at this second stage could be the final design , or there could be additional stages at which more design points are selected .",
    "the solution presented in this paper is applicable for a one - shot approach for finding a locally optimal design as well as for a multistage approach .",
    "the argument that our method can immediately be applied for the multistage approach is exactly as in @xcite .    for a broader discussion on the challenges to identify optimal designs for generalized linear models ,",
    "many of which apply also for other nonlinear models , we refer the reader to @xcite .",
    "the work presented here is an extension of @xcite , @xcite and @xcite . the analytic approach in those papers unified and extended many of the results on locally optimal designs that were available through the so - called geometric approach .",
    "the extension in the current paper has major consequences for two reasons .",
    "first , it enables the application of the basic approach in the three earlier papers to many models for which it could until now not be used . as a result",
    ", this paper opens the door to finding locally optimal designs for models where no feasible approach was known so far .",
    "second , for a number of models for which answers could be obtained by earlier work , the current extension enables the identification of locally optimal designs with a smaller support .",
    "this is important because it simplifies the search for optimal designs , whether by computational or analytical methods .",
    "section  [ sec4 ] will illustrate the impact of our results .",
    "the basic approach in @xcite , @xcite and @xcite , which is also adopted here , is to identify a subclass of designs with a simple format , so that for any given design @xmath0 , there exists a  design @xmath1 in that subclass with @xmath2 under the loewner ordering .",
    "we will refer to this subclass as a complete class for this problem . here ,",
    "@xmath3 and @xmath4 are information matrices for a parameter vector @xmath5 under @xmath1 and @xmath0 , respectively .",
    "others , such as @xcite have called such a class _ essentially _ complete , which is admittedly indeed more accurate , but also more cumbersome .",
    "when searching for a locally optimal design , for the common information - based optimality criteria , including @xmath6- , @xmath7- , @xmath8- and @xmath9-criteria , one can thus restrict consideration to this complete class , both for a one - shot or multistage approach .",
    "also , as shown in @xcite , this conclusion holds for arbitrary functions of the parameters .",
    "ideally , the same complete class results would apply for all a priori values of the parameter vector  @xmath5 .",
    "however , it turns out , as we will see in section  [ sec4 ] , that there are instances where complete class results hold only for certain a priori values of @xmath5.=-1    @xcite , @xcite and @xcite identify small complete classes for certain models .",
    "they do so by showing that for any design @xmath0 that is not in their complete class , there is a design @xmath1 that is in the complete class such that all elements of @xmath3 are the same as the corresponding elements in  @xmath4 , except that _ one diagonal element _ in @xmath10 is at least as large as that in @xmath4 .",
    "this guarantees of course that @xmath11 .",
    "the contribution of this paper is that we focus on increasing a _ principal submatrix _ rather than just a single _",
    "diagonal element_. this allows us to obtain results for more models than could be addressed by @xcite , @xcite and @xcite , and also facilitates the identification of smaller complete classes for some models considered in these earlier papers .    in section  [ sec2 ]",
    "we will present the necessary background , while the main results are featured in section  [ sec3 ] .",
    "the power of the proposed extension is seen through applications in section  [ sec4 ] .",
    "we conclude with a short discussion in section  [ sec5 ] .",
    "consider a nonlinear regression model for which a response variable @xmath12 depends on a single regression variable @xmath13 .",
    "we assume that the @xmath12 s are independent and follow some exponential distribution @xmath14 with mean @xmath15 , where @xmath5 is the @xmath16 parameter vector , and the values of @xmath13 can be chosen by the experimenter .",
    "typically , approximate designs are used to study optimality in this context .",
    "an approximate design @xmath0 can be written as @xmath17 , where @xmath18 is the weight for design point @xmath19 and @xmath20 .",
    "it is often more convenient to present @xmath0 as @xmath21 , @xmath22 $ ] , with the @xmath23 s obtained from the @xmath19 s through a bijection that may depend on @xmath5 .",
    "typically , the information matrix for @xmath5 under design @xmath0 can be written as @xmath24 where @xmath25 the functions @xmath26 are allowed to depend on @xmath5 not just through @xmath27 , but in an attempt to simplify notation we write , for example , @xmath28 rather than @xmath29 . in ( [ infor2 ] ) , @xmath30 is a symmetric matrix , and @xmath31 is a @xmath32 nonsingular matrix that depends only on @xmath5 . some examples of ( [ infor1 ] ) and ( [ infor2 ] ) will be seen in section  [ sec4 ] .    for some @xmath33 , @xmath34 , we partition @xmath30 as @xmath35 here , @xmath36 is the lower @xmath37 principal submatrix of @xmath38 , that is , @xmath39    in the context of local optimality , if designs @xmath40 and @xmath41 satisfy @xmath42 , then it follows from ( [ infor1 ] ) that @xmath43 .",
    "hence , @xmath44 follows if it holds that @xmath45 this is what we explore in this paper .",
    "note that this is more general than @xcite , @xcite and @xcite , where @xmath46 .",
    "we develop a theoretical framework for general values of @xmath33 .",
    "following @xcite and @xcite , a set of @xmath47 real - valued continuous functions @xmath48 defined on an interval @xmath49 $ ] is called a chebyshev system on @xmath49 $ ] if @xmath50 is strictly positive whenever @xmath51 .    along the lines of @xcite , we select a maximal set of linearly independent nonconstant functions from the @xmath26 functions that appear in the first @xmath52 columns of the matrix @xmath38 defined in ( [ infor2 ] ) , and rename the selected functions as @xmath53 . for a given nonzero @xmath54 vector @xmath55 ,",
    "let @xmath56 where @xmath36 is as defined in ( [ infor_c22 ] ) .    for @xmath57 , @xmath58 and @xmath36",
    ", we will say that a set of @xmath59 pairs @xmath60 is dominated by a set of @xmath61 pairs @xmath62 if @xmath63 where the summations on the left - hand sides are over the @xmath59 subscripts for the pairs @xmath60 and those on the right - hand sides over the @xmath61 subscripts for the pairs @xmath64 .",
    "the following two lemmas provide the basic tools for the main results .",
    "we point out that the pairs @xmath60 in these lemmas need not form a design ; in particular , the @xmath65 s need not add to 1 .",
    "[ lemma1 ] for the functions @xmath66 defined on an interval @xmath49 $ ] , suppose that either @xmath67\\\\[-8pt ] & & \\mbox{form chebyshev systems for every nonzero vector } q\\nonumber\\end{aligned}\\ ] ] or @xmath68\\\\[-8pt ] & & \\mbox{form chebyshev systems for every nonzero vector } q.\\nonumber\\end{aligned}\\ ] ]    then the following conclusions hold :    for @xmath69 , if ( [ assumption1 ] ) holds , then for any set @xmath70 } with @xmath71 , there exists a set @xmath72 with @xmath73 , such that  @xmath74 is dominated by @xmath75 .    for @xmath69 ,",
    "if ( [ assumption2 ] ) holds , then for any set @xmath76 with @xmath77 , there exists a set @xmath78 with @xmath79 , such that @xmath74 is dominated by @xmath75 .    for @xmath80 ,",
    "if ( [ assumption1 ] ) holds , then for any set @xmath81 with @xmath82 , there exists a set @xmath83 with @xmath84 , such that @xmath74 is dominated by @xmath75 .    for @xmath80 ,",
    "if ( [ assumption2 ] ) holds , then for any set @xmath85 with @xmath86 , there exists a set @xmath87 with @xmath88 , such that @xmath74 is dominated by  @xmath75 .    since the proof is similar for all parts , we only provide a proof for part ( a ) .",
    "let @xmath74 be as in part ( a ) .",
    "first consider the special case that @xmath89 . by ( 1a ) of therorem 3.1 in @xcite",
    ", there exists a set of at most @xmath90 pairs ( @xmath91 with one of the points equal to @xmath92 so that  ( [ exist:1 ] ) and  ( [ exist:2 ] ) hold for this @xmath55",
    ". by part ( a ) of proposition  [ prop0 ] in the , the number of distinct points with @xmath93 must then be exactly @xmath90 .",
    "thus we have @xmath94 , and the @xmath23 s and @xmath95 s must alternate by part ( b ) of proposition  [ prop0 ] .",
    "the result follows now for an arbitrary nonzero @xmath55 by applying proposition  [ prop1 ] in the and using ( [ assumption1 ] ) and ( [ exist:2 ] ) .",
    "lemma  [ lemma2 ] partially extends lemma  [ lemma1 ] by observing that larger sets @xmath74 than in lemma  [ lemma1 ] are also dominated by sets @xmath75 as in that lemma .    [ lemma2 ] with the same notation and assumptions as in lemma  [ lemma1 ] , let @xmath96 , where @xmath97 for cases ( ) , ( ) , and ( ) of lemma  [ lemma1 ] , and @xmath98 for case ( ) . then the following conclusions hold :    for @xmath69 , if ( [ assumption1 ] ) holds , then @xmath74 is dominated by a set @xmath75 of size @xmath90 that includes @xmath92 as one of the points .    for @xmath69 ,",
    "if ( [ assumption2 ] ) holds , then @xmath74 is dominated by a set @xmath75 of size @xmath90 that includes @xmath6 as one of the points .    for @xmath80 ,",
    "if ( [ assumption1 ] ) holds , then @xmath74 is dominated by a set @xmath75 of size @xmath99 that includes both @xmath6 and @xmath92 as points .    for @xmath80 ,",
    "if ( [ assumption2 ] ) holds , then @xmath74 is dominated by a set @xmath75 of size @xmath90 .",
    "the results follow by application of lemma  [ lemma1 ] .",
    "for example , for case  ( a ) , if @xmath100 , the result follows directly from lemma  [ lemma1 ] . if @xmath101 , we start with the points @xmath102 in @xmath74 .",
    "using lemma  [ lemma1 ] , we obtain points @xmath103 in a set @xmath104 that dominates @xmath74 . using lemma  [ lemma1 ] again on the @xmath90 largest points other than @xmath105 in @xmath106 , we move one more point to @xmath92 , obtaining a new set with @xmath107",
    "points that dominates @xmath106 .",
    "continue until the size of the set is reduced to @xmath90 ; this is the desired set @xmath75 .",
    "the first main result is an immediate consequence of lemma  [ lemma2 ] .",
    "[ main1 ] for a regression model with a single regression variable @xmath13 , suppose that the information matrix @xmath38 can be written as in ( [ infor1 ] ) for @xmath108 $ ] .",
    "partitioning the information matrix as in ( [ infor_part ] ) , let @xmath58 be a maximum set of linearly independent nonconstant @xmath26 functions in the first @xmath52 columns of @xmath30 .",
    "define @xmath109 as in ( [ psiq ] ) .",
    "suppose that either  ( [ assumption1 ] ) or ( [ assumption2 ] ) in lemma  [ lemma1 ] holds .",
    "then the following complete class results hold :    for @xmath69 , if ( [ assumption1 ] ) holds , the designs with at most @xmath90 support points , including @xmath92 , form a complete class .",
    "for @xmath69 , if ( [ assumption2 ] ) holds , the designs with at most @xmath90 support points , including @xmath6 , form a complete class .",
    "for @xmath80 , if ( [ assumption1 ] ) holds , the designs with at most @xmath99 support points , including both @xmath6 and @xmath92 , form a complete class .",
    "for @xmath80 , if ( [ assumption2 ] ) holds , the designs with at most @xmath90 support points form a complete class .",
    "note that if ( [ exist:1 ] ) holds for @xmath110 , @xmath111 , then the same is true if we replace one or more of the @xmath112 s by @xmath113 .",
    "therefore , if ( [ assumption1 ] ) or ( [ assumption2 ] ) do not hold for the original @xmath112 s , conclusions in theorem  [ main1 ] would still be valid if  ( [ assumption1 ] ) and ( [ assumption2 ] ) hold after multiplying one or more of the @xmath112 s , @xmath114 , by @xmath115 .    while theorem  [ main1 ] is very powerful , applying it directly may not be easy .",
    "the next result , which utilizes a generalization of a tool in @xcite , will lead to a condition that is easier to verify . using the notation of theorem  [ main1 ] , define functions @xmath116 , @xmath117 as follows : @xmath118 the following lower triangular matrix contains all of these functions , and suggest an order in which to compute them : @xmath119 note that , for @xmath120 , the functions in the last row are matrix functions , which is a key difference with @xcite .",
    "the derivatives of matrices in  ( [ def : df ] ) are element - wise derivatives . for the next result",
    ", we will make the following assumptions :    all functions @xmath26 in the information matrix @xmath121 are at least @xmath122th order differentiable on @xmath123 .    for @xmath124 ,",
    "the functions @xmath125 have no roots in @xmath49 $ ] .    for ease of notation , in the remainder we will write @xmath126 instead of @xmath125 , and",
    "@xmath127 means that @xmath128 for all @xmath129 $ ] .",
    "this also applies for @xmath130 , in which case it means that the matrix @xmath131 is positive definite for all @xmath108 $ ] .",
    "[ main2 ] for a regression model with a single regression variable  @xmath13 , let @xmath132 $ ] , @xmath38 , @xmath133 and @xmath134 be as in theorem  [ main1 ] .",
    "for the functions @xmath126 in ( [ def : df ] ) , define @xmath135 , @xmath136 $ ] .",
    "suppose that either @xmath137 or @xmath138 is positive definite for all @xmath129 $ ] .",
    "then the following complete class results hold :    for @xmath69 , if @xmath139 , the designs with at most @xmath90 support points , including @xmath92 , form a complete class .",
    "for @xmath69 , if @xmath140 , the designs with at most @xmath90 support points , including @xmath6 , form a complete class .    for @xmath80 ,",
    "if @xmath139 , the designs with at most @xmath99 support points , including both @xmath6 and @xmath92 , form a complete class .    for @xmath80 ,",
    "if @xmath140 , the designs with at most @xmath90 support points form a complete class .",
    "we only present the proof for case ( a ) since the other cases are similar .",
    "for any nonzero vector @xmath55 , @xmath141 for all @xmath129 $ ] . among all @xmath126 , @xmath114 , and @xmath142 ,",
    "suppose that @xmath143 of them are negative .",
    "let @xmath144 denote the subscripts for these negative terms , and note that @xmath143 must be even .",
    "note also that the labels @xmath145 do not depend on the choice of the vector @xmath55 since @xmath146 do not depend on @xmath55 .",
    "finally , note that for any @xmath147 with @xmath148 , if we replace @xmath110 by @xmath149 , then the signs of @xmath126 and @xmath150 are switched while all others remain unchanged .",
    "we now change some of the @xmath112 s to @xmath113 .",
    "this is done for those @xmath147 that satisfy @xmath151 for some value of @xmath152 .",
    "denote the new @xmath26-functions by @xmath153 .",
    "notice that @xmath154 . from the last observation in the previous paragraph ,",
    "it is easy to check that @xmath127 , @xmath155 , for the functions @xmath126 that correspond to this new set of @xmath156-functions . by proposition  [ prop3 ] in the , @xmath157 and @xmath158 are chebyshev systems on @xmath49 $ ] , regardless of the choice for @xmath159 .",
    "the result follows now from case ( a ) of theorem  [ main1 ] and the observation immediately after theorem  [ main1 ] .    for case ( a ) in theorem  [ main2 ] ,",
    "the value of @xmath6 in the interval @xmath49 $ ] is allowed to be @xmath160 .",
    "in this situation , for any given design @xmath0 , we can choose @xmath161 , and the conclusion of the theorem holds .",
    "similarly , @xmath92 can be @xmath162 in case ( b ) , and the interval can be unbounded at either side for case ( d ) .",
    "as noted at the end of section  [ sec2 ] , the results in @xcite , @xcite , and @xcite correspond to @xmath46 .",
    "the extension in this paper allows the choice of larger values of @xmath33 where feasible .",
    "larger values of @xmath33 lead to designs with smaller support sizes .",
    "the reason for this is that the value of @xmath122 in theorems  [ main1 ] and  [ main2 ] corresponds to the number of equations in ( [ exist:1 ] ) . for a particular model ,",
    "this number is smaller for larger  @xmath33 .",
    "since the support size of the designs is roughly half the value of  @xmath122 , the support size is smaller for larger values of @xmath33 .",
    "we will provide some examples of the application of theorems  [ main1 ] and  [ main2 ] in the next section , and will offer some further thoughts on the ease of their application in section  [ sec5 ] .",
    "whether the model is for continuous or discrete data , with homogeneous or heterogeneous errors , theorems  [ main1 ] and  [ main2 ] can be applied as long as the information matrix can be written as in ( [ infor1 ] ) . as the examples in this section will show , in many cases the result of the theorem facilitates the determination of complete classes with the minimal number of support points .",
    "dette , melas and wong ( @xcite ) studied exponential regression models , which can be written as @xmath163 where the @xmath164 s are i.i.d . with mean 0 and variance @xmath165 , and",
    "@xmath166 $ ] is the value of the regression variable to be selected by the experimenter . here",
    "@xmath167 , with @xmath168 , @xmath169 , and @xmath170 . for @xmath171",
    ", they showed that there is a @xmath7-optimal design for @xmath172 based on four points , including the lower limit @xmath173 .",
    "further , for @xmath174 and @xmath175 , they showed that there is a @xmath7-optimal design for @xmath5 based on six points , again including the lower limit @xmath173 . by using theorem  [ main2 ]",
    ", we will show that similar conclusions are possible for other optimality criteria , including @xmath6- and @xmath8-optimality , and other functions of interest for many a  priori values of @xmath5 .    for @xmath171",
    ", the results in @xcite can be used to obtain a complete class of designs with at most five points .",
    "we can do better with theorem  [ main2 ] .",
    "the information matrix for @xmath176 under design @xmath177 can be written in the form of ( [ infor1 ] ) with @xmath178 and @xmath179 where @xmath180 and @xmath181 .",
    "let @xmath182 , @xmath183,@xmath184 , @xmath185 , @xmath186 , @xmath187 and @xmath188 then @xmath189 , @xmath190 , @xmath191 , @xmath192 , @xmath193 , @xmath194 and @xmath195 note that @xmath196 and @xmath197 , so that @xmath137 is positive definite if @xmath198 .",
    "this is equivalent to @xmath199 , which is satisfied when @xmath200 .",
    "thus , by ( a ) of theorem  [ main2 ] , we have the following result .    for model ( [ example1 ] ) with @xmath171 ,",
    "if @xmath201 then the designs with at most four points , including the lower limit @xmath173 , form a complete class .    for @xmath174 and @xmath202",
    ", the information matrix for @xmath203 under design @xmath177 can be written in the form of ( [ infor1 ] ) with @xmath204 and @xmath205 where @xmath180 and @xmath181 .",
    "let @xmath206 and @xmath207 , @xmath208 , and let @xmath209 then @xmath189 , @xmath210 , @xmath211 , @xmath212 , @xmath213 , and @xmath214 again , @xmath196 and @xmath197 , so that @xmath137 is positive definite if @xmath215 and its leading principal minors are positive .",
    "this is equivalent to @xmath216\\\\[-8pt ] 1295\\lambda^2 + 5180\\lambda- 4&>&0\\nonumber\\\\ \\mbox{and}\\quad 55\\lambda^2 + 330\\lambda+ 431&>&0.\\nonumber\\end{aligned}\\ ] ] simple computation shows that this holds for @xmath217 ( or , equivalently , @xmath218 ) . by theorem  [ main2 ] , we have the following result .    for model  ( [ example1 ] ) with @xmath174 and @xmath219 , if @xmath220 , then the designs with at most six points , including the lower limit @xmath173 , form a complete class .",
    "demidenko ( @xcite ) proposed a model referred to as the linexp model to describe tumor growth delay and regrowth .",
    "the natural logarithm of the tumor volume is modeled as @xmath221 with independent @xmath222 and @xmath223 $ ] as the value of the single regression variable , which in this case refers to time . here",
    "@xmath224 is the parameter vector , where @xmath225 is the baseline logarithm of the tumor volume , @xmath226 is the final growth rate and @xmath227 is the rate at which killed cells get washed out .",
    "the size of the parameter @xmath228 relative to @xmath229 determines whether regrowth is monotonic ( @xmath230 ) or not .",
    "@xcite recently studied this model and showed that a @xmath7-optimal design for @xmath5 can be based on four points , including @xmath173 and @xmath231 .",
    "we will now show that theorem  [ main2 ] extends this conclusion to other optimality criteria and functions of interest .",
    "the information matrix for @xmath5 under design @xmath232 can be written in the form of ( [ infor1 ] ) with @xmath233\\\\[-8pt ] c(\\theta , c)&= & % \\pmatrix { 1 & & & \\cr e^{c } & e^{2c } & & \\cr c & c e^{c } & c^2 & \\cr c e^{c } & c e^{2c } & c^2 e^{c } & c^2 e^{2c } } % , \\nonumber % \\end{aligned}\\ ] ] where @xmath234 . with a proper choice of @xmath26 functions",
    ", it can be shown that the result in @xcite yields a complete class of designs with at most five points , including @xmath173 and @xmath231 .",
    "we can again do better with theorem  [ main2 ] .",
    "define @xmath235 , @xmath236 , @xmath237 , @xmath238 , @xmath239 and @xmath240 this yields @xmath241 , @xmath242 , @xmath243 , @xmath244 , @xmath245 and @xmath246 clearly @xmath137 is a positive definite matrix .",
    "therefore , by part ( c ) of theorem  [ main2 ] , we reach the following conclusion .    for the linexp model ( [ linexp ] ) , the designs with at most four points , including @xmath173 and @xmath231 , form a complete class .",
    "demidenko ( @xcite ) , using a two - compartment model , developed a double - exponential regrowth model to describe the dynamics of post - irradiated tumors .",
    "the model can be written as @xmath247 + \\varepsilon_{ij } , % \\ ] ] with independent @xmath222 and @xmath248 $ ] again as the value for the variable time . here",
    "@xmath249 is the parameter vector , where @xmath225 is the logarithm of the initial tumor volume , @xmath250 is the proportional contribution of the first compartment and @xmath251 and @xmath252 are cell proliferation and death rates .    using chebyshev systems and an equivalence theorem",
    ", @xcite showed that a @xmath7-optimal design for @xmath5 can be based on four points including @xmath173 and @xmath231 .",
    "theorem  [ main1 ] allows us to extend this result to a  complete class result , thereby covering many other optimality criteria and any functions of interest .",
    "the information matrix for @xmath5 under design @xmath232 is of the form ( [ infor1 ] ) with @xmath253 and with @xmath254 a @xmath255 matrix as in ( [ infor2 ] ) , where @xmath256 , @xmath257 , @xmath258 , @xmath259 , @xmath260 , @xmath261 , @xmath262 , @xmath263 , @xmath264 and @xmath265 . here ,",
    "note that @xmath267 can be written as a linear combination of @xmath268 and @xmath269",
    ". we can apply theorem  [ main1 ] if we can show that both @xmath270 and @xmath271 , @xmath272 are chebyshev systems for any nonzero vector @xmath55 , where @xmath273 .    rather than do this directly , we first simplify the problem .",
    "we multiply each of the @xmath26 s by the positive function @xmath274 , which preserves the chebyshev system property . after further simplifications by replacing some of the resulting functions by independent linear combinations of these functions , which also preserves the chebyshev system property , we arrive at the systems @xmath275 , @xmath276 , @xmath277 , @xmath13 , @xmath278 , @xmath279 and @xmath280 , @xmath276 , @xmath277 , @xmath13 , @xmath278 , @xmath281 , @xmath282 .",
    "it suffices to show that these are chebyshev systems for any nonzero vector @xmath55 , which follows from proposition  [ prop3 ] if we show that @xmath127 , @xmath283 , for the latter system .",
    "it can be shown that @xmath284 , @xmath285 and @xmath286 , where @xmath287 .",
    "thus both systems are chebyshev systems , and by part ( c ) of theorem  [ main1 ] , we reach the following conclusion .    for the double - exponential regrowth model ( [ double ] ) , the designs with at most four points , including @xmath173 and @xmath231 , form a complete class .",
    "we have given a powerful extension of the result in @xcite that has potential for providing a small complete class of designs whenever the information matrix can be written as in ( [ infor1 ] ) .",
    "irrespective of the optimality criterion ( provided that it does not violate the loewner ordering ) and of the function of @xmath5 that is of interest , the search for an optimal design can be restricted to the small complete class . as the examples in section  [ sec4 ] show ,",
    "the results lead us to conclusions that were not possible using the results in @xcite and @xcite .    as already pointed out",
    ", direct application of theorem  [ main1 ] may not be easy .",
    "section  [ subsec3 ] shows some tricks that can be useful when using theorem  [ main1 ] .",
    "direct application of theorem  [ main2 ] is easier because the condition for the function  @xmath137 can be verified with the help of software for symbolic computations .",
    "sometimes it is more convenient to do this after multiplying each of the @xmath26 functions by the same positive function ( see section  [ subsec3 ] ) .",
    "there remain , however , some basic questions related the application of either theorem  [ main1 ] or theorem  [ main2 ] that do not have simple general answers . for example , what is a good choice for @xmath33 in forming the matrix @xmath36 in ( [ infor_c22 ] ) ? in section  [ sec4 ] , the choice @xmath288 worked well , and selecting @xmath33 approximately equal to @xmath289 may be a good general starting point .",
    "moreover , there is the question of how to order the rows and columns of the information matrix . by reordering the elements in the parameter vector @xmath5",
    ", we could wind up with different matrices @xmath36 , even after fixing @xmath33 .",
    "so what ordering is best ? in all of the examples in section  [ sec4 ] , we have used an ordering that makes `` higher - order terms '' appear in @xmath36 , and this may offer the best general strategy .",
    "there is still another issue related to ordering : in renaming the independent @xmath26-functions in the first @xmath52 columns of @xmath38 , different orders will result in different @xmath126-functions . in some cases ,",
    "but not for all , these functions will result in a function @xmath137 that satisfies the condition in theorem  [ main2 ] . in the examples ,",
    "we have tended to associate `` lower - order terms '' with the earlier @xmath26-functions , but what order is best may require some trial and error .",
    "whereas we have demonstrated that the main results of the paper are powerful , regrettably we can not offer any guarantees that they will always give results as desired , even when the information matrix can be written in the form ( [ infor1 ] ) .",
    "[ prop0 ] assume that @xmath290 is a chebyshev system defined on an interval @xmath49 $ ] .",
    "let @xmath291 , and let @xmath292 be coefficients that satisfy the following @xmath122 equations : @xmath293 then we have :      if @xmath296 and one @xmath297 is not zero , then all are nonzero ; moreover all  @xmath297 s for odd @xmath298 must then have the same sign , which is opposite to that of the @xmath297 s for even @xmath298 .    for part ( a ) ,",
    "if @xmath299 , we can expand @xmath300 to a set of @xmath122 distinct points , taking @xmath301 for the added points .",
    "thus without loss of generality , take @xmath302 .",
    "consider the matrix @xmath303 then ( [ prop0:1 ] ) can be written as @xmath304 where @xmath305 . since @xmath306 is a chebyshev system ,",
    "@xmath307 is nonsingular , so that @xmath308 .    for part ( b ) , if one @xmath297 is 0 , then it follows from part ( a ) that all @xmath297 s are  0 . therefore ,",
    "if at least one @xmath297 is nonzero , then all of them must be nonzero . with the notation from the previous paragraph",
    ", we can write ( [ prop0:1 ] ) as @xmath309 where @xmath310 .",
    "it follows that @xmath311 by the chebyshev system assumption , the denominator @xmath312 in  ( [ addthis ] ) is positive , while the numerator @xmath313 is positive for @xmath314 and negative otherwise .",
    "the result in ( b ) follows .",
    "[ prop1 ] let @xmath315 be a chebyshev system on an interval @xmath49 $ ] , and suppose that @xmath69 . consider @xmath90 pairs @xmath316 , @xmath317 , and @xmath90 pairs",
    "@xmath318 , @xmath317 , with @xmath18 , @xmath319 and @xmath320 .",
    "suppose further that the following @xmath122 equations hold : @xmath321 then , for any function @xmath322 on @xmath49 $ ] , we can conclude that @xmath323 if @xmath324 is also a chebyshev system .    with @xmath325 the @xmath122 equations in ( [ prop1:1 ] )",
    "can be written as @xmath326 where @xmath26 and @xmath327 are as defined in the proof of proposition  [ prop0 ] .",
    "further , ( [ prop1:2 ] ) is equivalent to @xmath328 using ( [ prop1:3 ] ) to solve for @xmath329 , and using that @xmath330 , we see that ( [ prop1:4 ] ) is equivalent to @xmath331 from an elementary matrix result [ see , e.g. , theorem 13.3.8 of @xcite ] , the left - hand side of ( [ prop1:5 ] ) can be written as @xmath332 where @xmath333\\\\[-8pt ] & & \\qquad= \\pmatrix { \\psi_0(c_1 ) & \\psi_0(\\tilde{c}_1 ) & \\cdots & \\psi_0(c_n ) & \\psi _ 0(\\tilde{c}_n ) \\cr \\psi_1(c_1 ) & \\psi_1(\\tilde{c}_1 ) & \\cdots & \\psi_1(c_n ) & \\psi _",
    "1(\\tilde{c}_n ) \\cr \\vdots & \\vdots & \\ddots & \\vdots & \\vdots\\cr \\psi_{k-1}(c_1 ) & \\psi_{k-1}(\\tilde{c}_1 ) & \\cdots & \\psi_{k-1}(c_n ) & \\psi_{k-1}(\\tilde{c}_n)\\cr \\psi_{k}(c_1 ) & \\psi_{k}(\\tilde{c}_1 ) & \\cdots & \\psi_{k}(c_n ) & \\psi _ { k}(\\tilde{c}_n ) } .\\nonumber\\end{aligned}\\ ] ] since both @xmath334 and @xmath335 are chebyshev systems and @xmath336 , it follows that ( [ prop1:6 ] ) is negative , which is what had to be shown .",
    "[ prop2 ] let @xmath337 be a chebyshev system on an interval @xmath49 $ ] and suppose that @xmath80 .",
    "consider @xmath90 pairs @xmath316 , @xmath317 , and @xmath99 pairs @xmath338 , @xmath339 , with @xmath18 , @xmath319 and @xmath340 .",
    "suppose further that the following @xmath122 equations hold : @xmath341 then , for any function @xmath322 on @xmath49 $ ] , we can conclude that @xmath342 if @xmath324 is also a chebyshev system .",
    "[ prop3 ] consider functions @xmath343 on an interval @xmath49 $ ] .",
    "compute the corresponding functions @xmath126 as in ( [ def : df ] ) , but with @xmath36 replaced by @xmath322 , and suppose that @xmath127 , @xmath114",
    ". then @xmath344 is a chebyshev system if @xmath345 , while @xmath346 is a chebyshev system if @xmath347 .",
    "the conclusion for the case @xmath347 follows immediately from that for @xmath345 , so that we will only focus on the latter .",
    "we need to show that @xmath348 for any given @xmath349 .",
    "consider ( [ prop3:1 ] ) as a function of  @xmath350 .",
    "the determinant is 0 if @xmath351 , so that it suffices to show that the derivative of ( [ prop3:1 ] ) with respect to @xmath350 is positive on @xmath352 , that is , @xmath353 for any @xmath354 .",
    "now consider ( [ prop3:2 ] ) as a function of @xmath355 , and use a  similar argument .",
    "it suffices to show that for @xmath356 , @xmath357 continuing like this , it suffices to show that @xmath358 for any @xmath359 . since @xmath360 for @xmath129 $ ] , ( [ prop3:3 ] )",
    "is equivalent to @xmath361 recall that the entries in the last @xmath362 rows of this matrix are by definition simply values of @xmath363 , @xmath364 .",
    "hence , applying the same arguments used for ( [ prop3:1 ] ) to ( [ prop3:4 ] ) and using that @xmath365 for @xmath136 $ ] , it is sufficient to show that @xmath366 continuing like this , the ultimate sufficient condition is that @xmath367 for @xmath136 $ ] , which is precisely our assumption .",
    "thus the conclusion follows ."
  ],
  "abstract_text": [
    "<S> we extend the approach in [ _ ann . </S>",
    "<S> statist . _ * 38 * ( 2010 ) 24992524 ] for identifying locally optimal designs for nonlinear models . </S>",
    "<S> conceptually the extension is relatively simple , but the consequences in terms of applications are profound . </S>",
    "<S> as we will demonstrate , we can obtain results for locally optimal designs under many optimality criteria and for a larger class of models than has been done hitherto . </S>",
    "<S> in many cases the results lead to optimal designs with the minimal number of support points .    .    </S>"
  ]
}