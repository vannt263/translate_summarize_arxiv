{
  "article_text": [
    "observations of the cosmic microwave background ( cmb ) have proved to be extremely valuable for testing and constraining cosmological models .",
    "the majority of models predict that the anisotropies in the cmb signal are gaussian and their statistics isotropic across the sky .",
    "the angular power spectrum @xmath0 therefore provides a natural connection between theory and observation and a variety of methods have been explored to compute the power spectrum from sets of observations .",
    "maximum - likelihood methods @xcite provide an optimal estimate of the cmb power spectrum which has made them an invaluable tool for analysing the cmb for single - dish experiments and interferometers @xcite .",
    "brute force implementations of the method can only be applied to small data sets as the required computation scales as @xmath1 , where @xmath2 is the number of pixels in a cmb map ( see @xcite for a review ) . for",
    "a number of special cases one can construct maximum - likelihood estimators that perform more favourably @xcite , although their lack of generality limits their applicability and , as their computational demands scale as @xmath3 , even they can not be applied directly the largest contemporary ( _ wmap _ ) or future ( _ planck _ ) data .",
    "alternatively one can resort to approximate pseudo-@xmath0 methods , @xcite .",
    "these scale as the map - making process and are fast even for the largest data sets .",
    "hybrid methods @xcite combine a maximum - likelihood approach on large angular scales with a fast pseudo-@xmath4 estimator on small scales .    to compare theoretically predicted power spectra and those estimated from a set of observations it is necessary to construct a likelihood function .",
    "maximum - likelihood and pseudo-@xmath0 methods can only provide approximations to this likelihood .",
    "an alternative framework has been developed @xcite where one explores the full posterior distribution of the power spectrum with monte carlo samples .",
    "this method is not only exact but scales like the pseudo-@xmath4 methods . under the assumption of position",
    "invariant , circularly symmetric beams and uncorrelated noise , one can perform the beam convolution in the spherical harmonic domain and evaluate the likelihood of the data in the map domain , and the method scales as @xmath5 .",
    "the favourable scaling has enabled the method to be applied to the _ wmap _ data @xcite .",
    "the approach relies on the availability of an efficient method for sampling from high - dimensional distributions .",
    "previous implementations use a gibbs sampler but this restricts the applicability of the method to gaussian noise and cmb .",
    "we propose the use of a hamiltonian monte carlo ( hmc ) sampler @xcite .",
    "as opposed to the majority of markov - chain monte carlo ( mcmc ) methods , hmc scales well with problem size .",
    "few requirements are made on the distribution to be sampled , thus giving us the opportunity for great flexibility .",
    "hmc has been widely applied in bayesian computation @xcite and has also been employed for cosmological parameter estimation @xcite .    in this work",
    "we begin , in section [ sec : psest ] , by outlining the procedure for estimating power spectra with sampling . in section [ sec : hmc ] we describe the hmc method and a technique for determining the convergence of samples drawn with a hmc sampler .",
    "a summary of the process of applying hmc to the power spectrum estimation problem can be found in section [ sec : hmcpsest ] and we provide a prescription for setting the many tuneable parameters of the sampler . in section [ sec : lowres ] we apply the method to low - resolution simulations and compare the hamiltonian and gibbs samplers .",
    "section [ sec : wmap ] details our application of the method to simulated _ wmap _ observations .",
    "our conclusions are presented in section [ sec : conc ] .",
    "suppose the true cmb sky , divided for convenience into pixels , is represented by the temperature vector @xmath6 .",
    "the sky is observed and the resultant data vector @xmath7 , in any domain , is the sum @xmath8 of contributions due to the underlying cmb signal @xmath9 in that domain and the corresponding noise @xmath10 .",
    "moreover the signal @xmath9 is usually linearly related to the true cmb sky @xmath6 .",
    "thus we have @xmath11 where the matrix @xmath12 represents the linear mapping from the true cmb sky to the corresponding cmb signal in whatever domain the data resides .    in the following discussion",
    ", we need not assume a particular domain for the generic data vector @xmath7 .",
    "nevertheless , it is most common for @xmath7 to represent the pixelised cmb map convolved with the instrument beam and our work , so far , has used solely this form for the data vector .    the temperature field @xmath6 is related to the spherical harmonic coefficients of the field @xmath13 by @xmath14 where @xmath15 is a single pixel in the map vector @xmath6 and the @xmath16 are the spherical harmonics .",
    "although formally one may take the upper limit of the @xmath17 summation to be infinite , it is more typical to choose a finite value for @xmath18 appropriate to the beam size .",
    "we have not considered the effect of the mono- and dipole contributions , the handling of which , within this framework , is discussed in @xcite . in this notation we may write our model for the data in the form @xmath19 where @xmath20 describes the application of the spherical harmonic transform and we represent the spherical harmonic coefficients by a real vector .    for an isotropic gaussian cmb sky the covariance matrix @xmath21 of",
    "the @xmath22 has components @xmath23 where the set of coefficients @xmath24 constitute the theoretical angular power spectrum .",
    "note that , since the sky is real , @xmath25    we aim to sample from the joint distribution of the power spectrum coefficients @xmath26 .",
    "although this is difficult to perform directly , it is possible to sample from the joint density of the power spectrum coefficients and the signal realization @xmath27 and then marginalise over @xmath13 .",
    "the joint density can be written as the product of the appropriate conditional distributions @xmath28 the choice of prior @xmath29 is an interesting topic . @xcite",
    "have some suggestions for making this choice but for the purpose of this work we set @xmath30 so that the maximum of our posterior will correspond directly to a maximum - likelihood estimate .",
    "given our choice of prior and assuming the noise is gaussian then the conditional distributions that make up ( [ eq : joint ] ) can be written in the form @xmath31,\\ ] ] where @xmath32 , and @xmath33 where @xmath21 is easily constructed using ( [ eq : pstoalms ] ) .",
    "it is convenient to rewrite this in the form @xmath34 where @xmath35 is the power spectrum of the signal realization .",
    "the selection of a domain in which to represent the data is determined by the requirement that @xmath36 has a simple form . in this work",
    "we make the assumption that in the map domain @xmath36 is well represented by a diagonal matrix . in this domain incomplete sky coverage",
    "is straightforwardly handled by setting the elements of @xmath37 that correspond to excluded pixels to zero .",
    "if the instrument beam is position invariant and circularly symmetric then we can compute the beam convolution quickly in harmonic space and the predicted noiseless data can be written in the form @xmath38 where @xmath39 represents the smoothing by the beam .",
    "the computational cost of evaluating the posterior ( and its gradients ) is now limited by the speed at which one can compute the spherical harmonic transform @xmath20 .",
    "the transforms scale as @xmath5 and can be efficiently parallelised .",
    "we draw samples from the joint space @xmath40 using a hamiltonian monte ",
    "carlo sampler described in section [ sec : hmc ] .",
    "let us suppose that we wish to draw samples from a target density @xmath41 , where @xmath42 is the @xmath43-dimensional vector of our parameters .",
    "conventional mcmc methods move through the parameter space by a random walk and therefore require a prohibitive number of samples to explore - high dimensional spaces . the hamiltonian monte carlo method",
    "@xcite draws parallels between sampling and classical dynamics . by exploiting techniques developed for describing the motion of particles in potentials it is possible to suppress random walk behaviour .",
    "introducing persistent motion of the chain through the parameter space allows hmc to maintain a reasonable efficiency even for high dimensional problems @xcite .    for each parameter ,",
    "@xmath44 we introduce a ` momentum ' @xmath45 and a ` mass ' @xmath46 ; we discuss how to set the mass in the appendix .",
    "we construct a hamiltonian formed from a potential energy term @xmath47 and a kinetic energy term such that @xmath48 where our potential is related to the target density by @xmath49 our new objective is to draw samples from a distribution that is proportional to @xmath50 .",
    "the form of the hamiltonian is such that this distribution is separable into a gaussian in @xmath51 and the target distribution , i.e. @xmath52 we can then obtain samples from @xmath41 by marginalising over @xmath51 .    to find a new sample",
    "we first draw a set of momenta from the distribution defined by our kinetic energy term , i.e. an @xmath43 dimensional uncorrelated gaussian with a variance in dimension @xmath53 of @xmath46 .",
    "we then allow our system to evolve deterministically , from our starting point @xmath54 in the phase space for some fixed time @xmath55 according to hamilton s equations ,",
    "@xmath56 at the end of this trajectory we have reached the point @xmath57 and we accept this point with probability @xmath58 where @xmath59 after a new proposed sample is generated the momentum variable is discarded and the process restarts by randomly drawing a new set of momenta as described above .",
    "this implies that if we are able to integrate hamilton s equations exactly then , as energy is conserved along such a trajectory , the probability of acceptance is unity .",
    "in fact the method is more general as , provided one uses the metropolis acceptance criterion ( [ eq : acceptance ] ) , it is permitted to follow any trajectory to generate a new candidate point .",
    "however only trajectories that approximately conserve the value of the hamiltonian ( [ eq : ham ] ) will result in high acceptance rates .",
    "for some problems it may be advantageous to generate trajectories using an approximate hamiltonian that can be computed rapidly , and bear the cost of lowering the acceptance probability .    to integrate the equations of motions",
    "it is common practice to use the leapfrog method .",
    "this method has the property of exact reversibility which is required to ensure the chain satisfies detailed balance .",
    "it is also numerically robust and allows for the simple propagation of errors .",
    "we make @xmath60 steps with a finite step size @xmath61 , such that @xmath62 , as follows , @xmath63 until @xmath64 . the interval @xmath55 must be varied , usually by drawing @xmath60 and @xmath61 randomly from uniform distributions , to avoid resonant trajectories .",
    "higher - order integration schemes are permitted , provided exact reversibility is maintained , although generally incur significant additional computational costs .      diagnosing",
    "the convergence of a chain in an mcmc process is the subject of much literature ( see @xcite for comprehensive reviews ) .",
    "@xcite provides a method that uses the gradient information , which we must possess to calculate trajectories in hmc , to compute a convergence criteria .",
    "one constructs two estimates of the variance of a chain , that depend quite differently upon the distribution of samples across the target density , although the basic method is easily generalised to ( combinations of ) higher order central moments of @xmath41 .",
    "when the two estimates agree to within a certain accuracy the chain is assumed to have converged .",
    "we compute the variance of each parameter @xmath44 independently .",
    "our first estimate of the variance of the samples is calculated by @xmath65 where @xmath66 labels a sample in a chain of @xmath67 samples and the integral extends over the entire @xmath42-space . for our second estimate",
    "we take the expression for the variance and integrate by parts @xmath68 the first term of which will vanish if the marginalized distribution @xmath69 drops off faster than @xmath70 as @xmath44 tends to @xmath71 . using ( [ eq : psi ] ) we rewrite this expression as @xmath72 we compute ( [ eq : varint2 ] ) from the samples in our chain by @xmath73 to test for convergence we compute the ratio @xmath74 of ( [ eq : var1 ] ) and ( [ eq : var2 ] ) , and we believe the chain has converged when all the @xmath74 are close to unity .    we have tested how this criterion compares to the widely used gelman - rubin statistic @xcite and have found that hanson s method tends to be , if anything , slightly pessimistic .",
    "we find that values of @xmath75 in the range @xmath76 to @xmath77 represent good convergence and values in the range @xmath78 to @xmath79 are acceptable .",
    "the gelman - rubin method requires multiple chains to be generated and compares inter - chain with intra - chain statistics , whereas hanson s test uses a single chain and compares two different intra - chain statistics .",
    "we use the hanson test as it is very easy to compute , scales well with problem size and requires that we only generate one chain . we plan to explore other intra - chain convergence diagnostics such as that proposed by @xcite .",
    "we use hmc to draw samples simultaneously from the joint density ( [ eq : joint ] ) .",
    "our potential is defined by @xmath80 such that @xmath81 and the gradient of the potential can be computed exactly by @xmath82 @xmath83    the positivity requirement on the power spectrum @xmath4 can result in a high rejection rate and we have found it advantageous to reparametrize the problem in terms of the logarithm of the @xmath4s . for this reparametrization it is easy to calculate the corresponding potential and its derivatives . to enforce a flat prior on each @xmath4",
    "we must apply an exponential prior on @xmath84 .    to generate a new sample",
    "requires us to evaluate the gradient at each point along the leapfrog trajectory and to evaluate the value of the potential once at the end of the trajectory .",
    "therefore , if we take @xmath60 leapfrog steps , we must perform @xmath85 spherical harmonic transforms , although we can reuse the gradient at the end of one trajectory for the first step of the next .",
    "we split the sampling process into a burn in phase , in which we attempt to lose any dependence on our starting point , and a sampling phase where we store the samples from the chain and we believe these samples are drawn from the target density . during burn in we are permitted to adjust the parameters of the sampler , for example to tune the acceptance rate .",
    "once burn in is complete we must fix the parameters of the sampler in order that our samples come from the desired distribution .",
    "a good starting point can significantly reduce the time required for burn in .",
    "we have explored a number of possibilities for computing a starting point for the signal @xmath13 given some initial guess for the power spectrum .",
    "one we have found particularly effective is to draw a single signal sample , as for one step of the gibbs sampler , from the conditional distribution @xmath86 .",
    "this is a computationally expensive process and is described fully in @xcite .",
    "the basic procedure involves solving the following equation for @xmath42 , the spherical harmonic coefficients of the mean field ( wiener filtered ) map , @xmath87 and a fluctuation term @xmath88 that corrects for the bias in @xmath42 @xmath89 where @xmath90 is a set of spherical harmonic coefficients and @xmath91 a map both containing gaussian white noise of zero mean and unit variance .",
    "the sum of @xmath42 and @xmath88 is our starting sample @xmath13 .",
    "we solve for @xmath92 using a conjugate gradient algorithm ( see , for example @xcite ) .",
    "a preconditioner can be used to reduce the number of iterations required for the convergence of the conjugate gradient solver , however the construction of a preconditioner is itself a complex procedure , and since we only perform this step once and the accuracy of the result is of little consequence , we have not made use of one in this work . whether or not applying the conjugate gradient algorithm without a preconditioner is feasible depends on the nature of the data set under consideration .",
    "hmc has a large number of adjustable parameters , notably the masses .",
    "the distribution for the @xmath13 parameters is gaussian and so we attempt to set the mass associated with each @xmath22 such that they are inversely proportional to the variance of that @xmath22 .",
    "we justify this choice in the appendix .",
    "the masses for the @xmath13 are estimated for a fixed power spectrum for which the variance is computed by @xmath93 where we use our initial estimate of the power spectrum as the value of @xmath4 and compute the diagonal elements of the inverse noise covariance matrix in harmonic space using monte carlo simulations .    at high @xmath17 and with good signal - to - noise",
    "the marginal distributions for each @xmath4 are close to gaussian and we can obtain masses from the standard expression for the variance ( see , for example @xcite ) @xmath94 where @xmath95 is the power spectrum of the noise in the data,@xmath96 is the beam transfer function and @xmath97 is the fraction of the sky observed . for low multipoles the distributions are significantly skewed and in low signal - to - noise the sharp cut off of the distribution at @xmath98 has a similar effect . in these cases we have found that setting the masses from the variances is insufficient",
    ". instead we tune these masses empirically .",
    "we aim to set the mass for each parameter to as small a value as possible while maintaining our target acceptance rate .",
    "we sample the @xmath4s from simple approximate likelihood function and gradually reduce the masses until the acceptance rate drops .",
    "this gives masses that are sufficient for sampling the full problem efficiently .",
    "during burn in we can further tune the masses ; the convergence criterion for each parameter providing a good indication of whether or not the mass associated with that parameter is set correctly .",
    "we must randomise the length of each trajectory and have found that drawing @xmath60 from a uniform distribution between @xmath99 and @xmath100 is appropriate .",
    "therefore we typically require the application of @xmath101 spherical harmonic transforms to generate a new proposed sample .",
    "we then tune the step size @xmath61 such that we obtain an acceptance rate between 70 and 90 per cent .",
    "a higher acceptance rate is used for hmc than other mcmc methods as the computational cost of a rejection is so high .",
    "once sampling we store each @xmath24 sample and the realization power spectrum @xmath102 of each signal sample .",
    "the @xmath102 can be used to form the blackwell - rao estimator of the posterior distribution @xcite .",
    "the posterior can be written @xmath103 which for a gaussian cmb can be written as @xmath104 where @xmath105 we can therefore compute the posterior probability of a set of @xmath24 from @xmath67 samples @xmath106 by @xmath107 it is also possible to construct the marginal distributions for any @xmath4 or subset of @xmath108 . for a single @xmath4 the marginal distribution can be approximated by @xmath109 where @xmath110 extremely large numbers of samples would be needed to make this estimator accurate at high @xmath17 .",
    "however even with a relatively small number of samples it forms a useful tool for the analysis of large angular scales .",
    "it is worth noting that the expression ( [ eq : brfromsamples ] ) , or its one - dimensional marginalized version ( [ eq : brmarginal ] ) , do not depend on the @xmath108-samples , but only on the realization power spectra @xmath111 of the @xmath13-samples .",
    "to compare the hamiltonian and gibbs samplers we applied them both to a set of low ",
    "resolution simulations .",
    "we produced a map of the cmb with a healpix @xmath112 ( @xmath113 pixels ) .",
    "our cmb simulation is a realization of a @xmath114cdm cosmology with the best fitting parameters from the 5-year _ wmap _ observations @xcite and includes multipoles up to @xmath115 .",
    "we smoothed the map with a @xmath116-degree gaussian beam and added isotropic noise with an rms amplitude of @xmath117 per pixel .",
    "we chose the noise level so that we could explore how the sampler behaved as a function of the signal - to - noise ratio .",
    "we degraded the _",
    "kp2 mask such that any ( large ) pixel in our final mask is excluded if any of the ( small ) subpixels in the original mask are excluded .",
    "this has the effect of enlarging the kp2 mask to remove around @xmath118 percent of the sky : a large contiguous area along the galactic plane and a number of small regions around the locations of bright point sources .    for each sampler",
    "we take 20000 burn in samples and then record the next 50000 samples .",
    "a large number of samples helps to estimate correlation lengths accurately ; far fewer samples are required to explore the distribution . the marginal distributions of a selection of the @xmath4 are shown in fig .",
    "[ fig : lowresmarginal ] . for most @xmath17",
    "the data is too noisy to constrain the value of the @xmath4 however we do see good agreement between the results from the gibbs and hamiltonian samplers .",
    "the hmc samples have also been used in conjunction with the blackwell - rao estimator to generate a smooth approximation to the marginal distributions .",
    "this estimator appears to agree well with the histograms across this range of @xmath17 , but more samples are likely to be needed if we were to calculate the joint distribution of the @xmath108 .        in order to characterise the performance and efficiency of the samplers we considered the correlation of the @xmath108 samples . assuming that the @xmath4s are independent we can examine the auto - correlation function , @xmath119 we show the auto - correlation function for a selection of multipoles in fig .",
    "[ fig : lowrescorcoeff ] . as the signal - to - noise ratio for a single @xmath17 , defined as the ratio of the signal and noise power spectra at that @xmath17 , decreases with increasing @xmath17",
    "the samples become more highly correlated ; it takes more steps of the samplers to generate independent samples .",
    "this feature is a well known limitation of the gibbs sampler caused by the fact that drawing the power spectrum from the conditional distribution @xmath120 is limited to the size of the cosmic variance while the joint distribution may be much wider .",
    "similar behaviour is observed with the hamiltonian sampler although the cause is now related to the difficulty in sampling the highly skewed distributions that occur when the signal - to - noise ratio is low .",
    "the correlation length for each parameter can be estimated using @xmath121 where we truncate the summation at some maximum lag @xmath122 at which the auto - correlation function becomes noisy .",
    "[ fig : lowrescorlen ] shows how the measured correlation lengths for the power spectrum parameters from the gibbs and hamiltonian samplers depend on the signal - to - noise ratio for each parameter , again estimated assuming the parameters are independent .",
    "we see that in the high signal - to - noise regime the gibbs sampler performs exceptionally well whereas the hamiltonian sampler produces samples with typical correlation lengths of around four steps .",
    "once the data becomes noise dominated the picture is less clear with the hamiltonian sampler generally performing marginally better than the gibbs sampler . as the signal - to - noise ratio drops below about 0.01",
    "both samplers perform poorly .",
    "it is worth noting that hamiltonian sampler requires around an order of magnitude fewer spherical harmonic transforms ( the computationally intensive step in the process ) per sample than a gibbs sampler that uses no preconditioner and around a factor of 3 - 4 fewer transforms than is reported for gibbs samplers with carefully tuned preconditioners @xcite .",
    "furthermore we have found that the correlation lengths of the hamiltonian sampler strongly depend on the masses one uses , offering the opportunity for significant improvements given a more sophisticated prescription for setting the masses .    ) as a function of the signal - to - noise ratio of each @xmath123 parameter .",
    "the red points show the results from the gibbs sampler the blue points those from the hamiltonian sampler .",
    ", scaledwidth=50.0% ]",
    "we produce a cmb simulation as for section [ sec : lowres ] but with @xmath124 ( @xmath125 pixels ) and including multipoles up to @xmath126 .",
    "the map was then smoothed with a @xmath127-arcmin gaussian beam , which is similar in size to the beam of the _ wmap _ _ w_-band .",
    "we then added anisotropic uncorrelated noise by making use of the published @xmath128 and noise variance for the 5-year _ wmap _ combined _ w _ band map .",
    "the map was cut with the kp2 mask which excludes @xmath129 of the sky .",
    "we included multipoles up to @xmath130 in our analysis .",
    "this gives us a total of around @xmath131 parameters in our sampling space .    to generate a good signal starting point , using a single gibbs sample , required @xmath132 iterations ( @xmath100 minutes on the hardware described below ) of the conjugate gradient to solve ( [ eq : meanfield ] ) and ( [ eq : fluctuation ] ) such that the rms residual was less than @xmath133 .    for these simulations we made a total of @xmath134 burn in samples and recorded @xmath135 samples from the post burn - in phase .",
    "it takes @xmath136 seconds to generate a single sample using two dual core intel xeon 5150 processors and the mpi parallelised healpix spherical harmonic transforms , resulting in a total processing time of around @xmath137 hours .    for comparison we applied the master method @xcite to the same data set .",
    "our peak likelihood @xmath0 sample and 68 per cent confidence intervals , binned with the _ wmap _ team s scheme , are shown alongside the results of the master method in fig .",
    "[ fig : binnedps ] . for most of the range of angular scales",
    "the two estimates and their errors agree well . on the largest angular scales the master estimate tends to underestimate the uncertainities and the symmetric errors are far from representative of the posterior .",
    "percent confidence intervals as compared to the results of an application of the master method to the same simulated _ wmap _ data .",
    "the black solid line shows the power spectrum from which the simulation was generated while the grey shows the power spectrum of the realization .",
    "the grey squares and error bars show the master results .",
    "the black circles and error bars show the peak and 68 per cent confidence intervals found from samples generated with the hmc sampler.,scaledwidth=50.0% ]    in fig . [",
    "fig : binnedr ] we show a summary of the convergence statistics , using hanson s diagnostic , see section [ sec : converge ] , demonstrating that we have fully explored the distribution across the entire range in @xmath17 . for all multipoles",
    "the @xmath75 value is within the range @xmath138 to @xmath139 .",
    "samples used to produce the power spectrum in fig .",
    "[ fig : binnedps ] .",
    "although convergence is judged from the @xmath75 for every parameter we show here only the average @xmath75 for in each bin for the @xmath0 ( blue line ) and @xmath13 ( red line ) .",
    ", scaledwidth=50.0% ]",
    "we have introduced the hmc sampler for cmb power spectrum estimation and demonstrated its performance both on low - resolution simulations and simulations of 5-year _ wmap _ data .",
    "we find that the hamiltonian sampler has similar or shorter correlation lengths when compared to the gibbs sampler except in the regions of the highest signal - to - noise .",
    "bearing in mind the reduced computational cost and greater flexibility of the hamiltonian sampler we believe it is an attractive method for performing the analysis .    for high - resolution data sets of size ( @xmath124 , @xmath140 ) we can generate a sample in @xmath141 seconds on a high - end desktop .",
    "this is a significant gain over the reported performance of gibbs samplers .",
    "hmc requires that we are able to compute the logarithm of the target density and its gradients .",
    "even if exact gradients are not available we can generate approximate trajectories and these will still result in samples drawn from the required distribution .",
    "the generality of the approach removes the requirement for strictly gaussian signal and noise and therefore promises to be an interesting method for tackling a wide range of related problems .",
    "we are currently testing the performance of the method on high - resolution _ planck _ simulations and working on extending the method to include polarization .",
    "we also intend to apply the technique to the _ wmap _ data .",
    "we thank morgan french for his contributions to the early development of our sampler .",
    "jft acknowledges a stfc ( formerly pparc ) studentship .",
    "maja is a member of the cambridge planck analysis centre , supported by stfc grant st / f005245/1 .this work was conducted in cooperation with sgi / intel utilising the altix 3700 supercomputer at damtp cambridge supported by hefce and stfc .",
    "we acknowledge the use of the legacy archive for microwave background data analysis ( lambda ) . support for lambda is provided by the nasa office of space science .",
    "some of the results in this paper have been derived using the healpix @xcite package .",
    "hamiltonian monte carlo can be extremely sensitive to the choice of masses .",
    "when sampling from an approximately isotropic distribution this does not affect the performance significantly but when the marginal distributions of different parameters show considerable variation in width the masses must be set correctly to sample efficiently .",
    "@xcite suggests that one should set the mass associated with each parameter to be approximately equal to the variance of that parameter in the target density .",
    "this is an attempt to circularise the trajectories in the @xmath142 space .",
    "we take an alternative approach , where the mass for a parameter is inversely proportional to the width of the distribution , as suggested in @xcite . in order to justify this approach we have generalised the framework in @xcite to describe the application of the leapfrog method .",
    "consider the problem of sampling from an @xmath60-dimensional gaussian distribution in @xmath42 with covariance matrix @xmath21 .",
    "our hamiltonian is quadratic in @xmath42 and @xmath51 @xmath143 where @xmath144 is a @xmath145 mass matrix , and the trajectory will be determined by hamilton s equations @xmath146 @xmath147 we integrate the equation of motion with the leapfrog method @xmath148 @xmath149 @xmath150 a single application of the leapfrog method can be written in the form @xmath151 @xmath152 where @xmath153 is the identity matrix .",
    "we can rewrite this in a matrix form @xmath154    = { \\mathbfss{t } }    \\left[\\begin{array}{c }        \\bmath{x}\\left(t \\right)\\\\        \\bmath{p}\\left(t \\right )      \\end{array }    \\right],\\ ] ] where @xmath155.\\ ] ]    if the method is to be stable under the repeated application of @xmath156 then we require its eigenvalues to have unit modulus .",
    "the eigenvalues @xmath157 are found from the characteristic equation @xmath158 = 0.\\ ] ]    to explore the space rapidly we wish to find the largest @xmath61 compatible with the condition for stability .",
    "any dependence of ( [ eq : characteristiceqn ] ) on @xmath21 implies no single value for @xmath61 will meet the requirement for every eigenvalue to have unit modulus ( unless both @xmath21 and @xmath144 are proportional to the identity matrix ) . the maximum value for @xmath61 should therefore be controlled by the width of the distribution for a small subset of parameters .    by setting @xmath159",
    "we remove the dependence of @xmath61 on the size of the distribution . in this situation",
    "the characteristic equation reduces to @xmath160^n   = 0\\ ] ] and the stability criterion is met by @xmath161 .    if the dimensionally of the problem is such that it is impractical to perform the required matrix inversion and decomposition of @xmath144 ( to compute the hamiltonian and to draw new values for the momentum variables respectively ) then simple approximations must be employed .",
    "typically one might construct a diagonal mass matrix with the mass associated with each parameter inversely proportional to the variance of that parameter ."
  ],
  "abstract_text": [
    "<S> we present a method for fast optimal estimation of the temperature angular power spectrum from observations of the cosmic microwave background . </S>",
    "<S> we employ a hamiltonian monte carlo ( hmc ) sampler to obtain samples from the posterior probability distribution of all the power spectrum coefficients given a set of observations . </S>",
    "<S> we compare the properties of the hmc and the related gibbs sampling approach on low - resolution simulations and find that the hmc method performs favourably even in the regime of relatively low signal - to - noise . </S>",
    "<S> we also demonstrate the method on high - resolution data by applying it to simulated _ wmap _ data . </S>",
    "<S> analysis of a </S>",
    "<S> _ wmap_-sized data set is possible in a around eighty hours on a high - end desktop computer . </S>",
    "<S> hmc imposes few conditions on the distribution to be sampled and provides us with an extremely flexible approach upon which to build .    </S>",
    "<S> [ firstpage ]    cosmic microwave background  </S>",
    "<S> methods : data analysis  methods : statistical </S>"
  ]
}