{
  "article_text": [
    "despite a variety of criticisms of its effectiveness @xcite , peer review is a fundamental mechanism for validating the quality of the research that is published in today s scientific literature @xcite .",
    "it is a complex , multi - phase process and there appear to be some growing concerns regarding how to improve its functioning . given the growth of scientific journals , the increasing number of submitted articles , and the limited pool of reviewers , acquiring a good and timely review is becoming progressively more challenging .",
    "reviews can take even a year , depending on the complexity of the topic , the number of reviewers involved , and the details of the editorial procedures .    in face of these problems ,",
    "many suggestions have been proposed to make the peer review and editorial process more efficient and equitable @xcite . in particular , the role of editors in the process of selecting and managing reviewers has been increasingly discussed @xcite .",
    "the main focus of these discussions are ethical issues and general , qualitative recommendations for both the editors and the reviewers @xcite . while such issues are certainly practical and significant , there is still the lack of quantitative suggestions that could point out possible measurable improvements to the peer review process .",
    "do the editors send out a sufficient number of reviewer invitations to obtain two or three timely reviews of a manuscript ?",
    "how often should they draw on expertise of the same reviewers consuming their time and energy ?",
    "how long should they wait for a review before they can repeat an invitation or assume that a response is unlikely ?",
    "what is the statistical chance that reviewers will respond ?",
    "does it depend on whether they were previously reviewers for the same journal ?",
    "although all editors try to answer these and other questions while optimizing their work on their own , they do it somewhat in the dark . without an intensive discussion that could help to answer the aforementioned questions in a more systematic way one can be sure that editorial lags will be increasing in the years to come .",
    "our paper is meant to fill this gap with the help of quantitative analysis .",
    "we examine selected aspects of peer review and suggest possible improvements . to this end , we analyse a dataset containing information about 300 papers submitted to the biochemistry and biotechnology section of the journal of the serbian chemical society ( jcsc ) . after separating the peer review process into stages that each review has to go through , we use a weighted directed graph to describe it in a probabilistic manner and test the impact of some modifications of the editorial policy on the efficiency of the whole process .",
    "the paper is organized as follows :    section 2 describes the dataset used in the paper as well as the methodology employed to analyse the data .",
    "section 3 is devoted to the data driven theoretical analysis of the review times .",
    "simulations of various editorial policy scenarios and their impact on the efficiency of the process are presented in section 4 . in section 5",
    "we provide some concluding remarks and describe open problems that may be researched within the presented methodology in the future .",
    "the sample we studied contains information about reviews of 58 manuscripts submitted to one of the editors of jcsc between november 2011 and july 2014 .",
    "each of 323 members of the sample corresponds to a single reviewer and comprises the group the reviewer belongs to , the i d of the reviewed manuscript and dates associated with phases of the review process .",
    "reviewers were divided into two groups - 65 * trusted * reviewers are known personally by the editor while 258 * other * reviewers were chosen through various different means .",
    "the review process itself is separable into distinct phases that mirror interactions between the editor , authors and reviewers .",
    "it begins when the editor , after receiving a new submission , sends out invitations to a number of reviewers ( 5 on average - 4 * other * and 1 * trusted * ) and waits for their responses . if any of the invited reviewers does not respond , then after about 7 days an inquiry is sent .",
    "if that inquiry also remains without an answer for 10 days , then the review process for that particular reviewer is considered finished with a negative outcome . after receiving the initial invitation or the inquiry , reviewers who do answer either confirm their willingness to write the review or decline . in the latter case , much like for reviewers who did not answer at all ,",
    "the review process is considered finished with a negative outcome . in the former",
    ", the editor waits for the report for 25 days before sending an inquiry .",
    "this may result in either the reviewer finishing the review and sending the report - which is the only outcome of the process that is considered positive - or a lack of answer . to sum it up",
    ", there are three possible outcomes of the review process - * report * , * no response * or * decline*.                a directed graph in which nodes correspond to phases and edges connect subsequent phases can be used as a visual representation of the review process .",
    "graphs that describe our sample can be found in figures [ fig : bdiag - all]-[fig : bdiag - trusted ] .",
    "the value expressed in percent next to each edge is the probability that a realisation of the review process will pass through the edge - that is , the number of members from our sample for which the transition between nodes connected by the edge occurred divided by the size of the sample . widths of edges were scaled proportionally to that probability .",
    "what is striking is that only 43% of all invitations actually result in a finished review ( figure [ fig : bdiag - all ] ) .",
    "most of reviewers - that is 64% - do not even respond to the initial invitation and 42% ignore the inquiry .",
    "these poor results are mostly driven by reviewers that belong to the * other * group ( figure [ fig : bdiag - other ] ) , which constitutes the majority of all reviewers .",
    "only 31% of * other * reviewers finish the review , 73% ignore the initial inquiry , 51% do not answer at all and 16% reject the invitation . on the other hand , * trusted * reviewers - who are in minority - are far more reliable .",
    "most of them , 74% , respond to the invitation and 89% finish the review .",
    "only 3% do not answer and 8% reject . as we will show in the following sections , this disparity between * trusted * and * other * reviewers may play a crucial role in the review process and is the key factor that determines its effectiveness .",
    "review time , that is the number of days between the * invitation * phase and * report * phase , is the most direct and tangible measure of the efficiency of the review process .",
    "since our sample contains information about the beginning and end of each phase , we were able to acquire distributions of review time for * trusted * and * other * reviewers , as well as partial distributions of days between all intermediate phases .",
    "these partial distributions are especially interesting , as they can serve as building blocks with which one can create a simulation of the entire review process and recreate the cumulative distribution of review time under various assumptions .",
    "the distribution of review time can be reassembled using partial distributions in the following way .",
    "to each node ( phase ) @xmath0 of the review process graph ( figures [ fig : bdiag - all]-[fig : bdiag - trusted ] ) one can assign the probability @xmath1 that a realisation of the process will pass through node @xmath0 and the probability distribution @xmath2 of days between the * invitation * phase and phase @xmath0 .",
    "similarly , each edge is characterised by the probability @xmath3 that the review process will pass from phase @xmath4 to @xmath0 and the probability distribution @xmath5 of days associated with such a transition . given all these probabilities ,",
    "@xmath2 can be calculated as follows @xmath6 where the summation is over set @xmath7 of all predecessors of node @xmath0 and symbol @xmath8 represents the discrete convolution @xmath9 weights @xmath10 are defined as @xmath11 and the probability @xmath1 can be expressed as @xmath12 equations [ equ : gj]-[equ : qj ] are recursive .",
    "the distribution @xmath2 associated with node @xmath0 depends on the corresponding distributions associated with predecessors of node @xmath0 and probabilities @xmath1 exhibit similar dependence . as such",
    ", these equations can be solved recursively if one assumes appropriate initial conditions for nodes without parents ( in our case it is @xmath13 and @xmath14 for the node that corresponds to the * invitation * phase ) and acquires probabilities @xmath15 and @xmath3 from the sample .",
    "one last fact worth noting is that the quantity @xmath16 from the numerator in equation [ equ : wij ] is actually the same as the probability in figures [ fig : bdiag - all]-[fig : bdiag - trusted ] next to each edge .                    using the aforementioned procedure we recreated the distribution of review times for both * trusted * and * other * reviewers which we then compared with the corresponding empirical distributions from the sample . according to our theoretical calculations based on equations [ equ : gj]-[equ : qj ] the average review time for * trusted * reviewers is 23 days with standard deviation of 12 days .",
    "average review time and standard deviation acquired from the sample are the same . as for * other * reviewers , the theoretical average review time is 20 days with standard deviation of 11 days and the sample , again , yields the same values . one - sample kolmogorov - smirnov test performed to compare the theoretical distribution with the sample gives p - value 0.88 for * trusted * reviewers and 0.97 for * other * reviewers .",
    "it means that the distributions of review times calculated using partial distributions are essentially the same as the ones obtained directly from data .",
    "this is an important and non - obvious observation , as the only underlying assumption behind equations [ equ : gj]-[equ : qj ] is that the review process is memoryless - that is partial distributions assigned to edges do not depend on the history of the process .",
    "results presented thus far seem to confirm this assumption and it is reinforced even further in the following section .",
    "other than the validity of theoretical distributions , there are two main conclusions that can be drawn from results presented in figures [ fig : totdist - trusted - theor]-[fig : totdist - other ] .",
    "firstly , the review time distribution is bimodal .",
    "reviewers who either confirmed or sent in their reviews after receiving the invitation are the ones who contribute to the first maximum ( and they are in the majority of those who actually completed the reports - 69% of * other * and 82% of * trusted * ) .",
    "secondly , distributions of review time are similar for * trusted * and * other * reviewers .",
    "the difference between means and standard deviations is negligible from any practical standpoint and two - sample kolmogorov - smirnov test for both empirical distributions gives p - value 0.40 .",
    "based on these fact one can make a very strong assumption that the distribution of review time is the same across the entire population of reviewers and does not depend on the type of reviewer .",
    "so far we have considered review times of a single reviewer . however , editors usually need more than one review in order to judge whether to publish an article . in the case of our data from jcsc ,",
    "the editor required two reviews per article and sent invitations to five reviewers on average - one * trusted * and four * other*. while this review strategy indeed resulted in two reviews per article on average ( 2.34 to be exact ) , 9 articles were published after receiving only one review , 24 after 2 reviews , 21 after 3 and 4 after 4 reviews .",
    "this discrepancy between the target number of reviews and the number of reviews actually received stems from the difference in the probability of finishing the report between * trusted * and * other * reviewers .",
    "we are going to call this probability the completion rate .        using partial distributions",
    "we can easily simulate the effects of any editorial strategy and find the number of reviewers needed to achieve a certain number of reviews per article .",
    "we will use the average time of receiving two reviews as a measure of effectiveness of each strategy .",
    "figure [ fig : allways - finish ] shows these average times under the assumption that a reviewer always writes the report ( the completion rate is equal 1 ) for both * trusted * and * other * reviewers as a function of the number of reviewers .",
    "the average time decreases as the number of reviewers increases and results for * trusted * and * other * reviewers are very similar .",
    "this is intuitive and consistent with our prediction made in the previous section .",
    "but with the x axis rescaled for * other * reviewers.,width=302 ]    the assumption that reviewers always write the report is not realistic .",
    "if we want to take into account the fact that the actual completion rate of the review process for a single reviewer is much smaller , especially for * other * reviewers , then some additional strategy needs to be introduced to deal with situations when two reviews are not received at all . in our simulations we decided to use a very simple solution -",
    "if two reviews are not received , then invitations are resent to the same number of reviewers .",
    "this procedure is repeated if necessary until reviewers produce two reports in total .",
    "while this is not the most effective and time - efficient strategy , it still allows us to study the consequences of the difference between the completion rates of * trusted * and * other * reviewers .",
    "figure [ fig : fraction - finish ] is analogous to figure [ fig : allways - finish ] - in that it shows the average time of receiving two reviews - but this time we used the actual completion rates taken from the sample ( 89% for * trusted * , 31% for * other * reviewers ) and employed the policy described in the previous paragraph . as can be clearly seen , the difference in completion rates between * trusted * and * other * reviewers results in a completely different dynamics .",
    "* other * reviewers are far less effective and their average times are much higher - for example , two reviews can be received from 2 * trusted * reviewers after 32 days but 2 * other * reviewers finish the reviews after 70 days .",
    "even as the number of reviewers increases , this difference remains significant .",
    "however , in the last section we have shown that distributions of review time for * trusted * and * other * reviewers are very similar which suggests that the completion rate is the leading factor during the review process . this claim is partially supported by results presented in figure [ fig : allways - finish ] .",
    "if that is indeed the case , then one * trusted * reviewer should be  worth  89%/31% * other * reviewers and conversely one * other * reviewer is  worth  31%/89% * trusted * reviewers . by ",
    "worth  we mean that proportionally substituting one type of reviewer for another should yield the same results .",
    "figure [ fig : fraction - finish - rescaled ] , where the x axis for one type of reviewers was rescaled to match their worth in the other type of reviewers , confirms this prediction . the average number of days after which 2 reviews are acquired are similar and standard deviations , while not exactly the same - which is to be expected - are comparable .    .average number of days needed to receive two reviews from a group of reviewers with a given number of * trusted * ( columns ) and * other * ( rows ) reviewers .",
    "values for groups of reviewers smaller than two were omitted .",
    "[ cols=\">,>,>,>,>,>,>,>,>,>,>\",options=\"header \" , ]     so far we have studied separately * trusted * and * other * reviewers , however the group of reviewers invited to review an article usually contains reviewers of both kinds .",
    "figure [ fig : mix ] shows the average time of acquiring two reviews when reviewer types are mixed . as one could expect , the average time decreases with the increasing total number of reviewers and * trusted * reviewers are far more effective than * other*. still , by rescaling the x axis - that is by expressing the worth of one kind of reviewer using another - we get similar results ( figure [ fig : mix - rescaled ] ) .",
    "information about average times in groups of mixed reviewers , expressed in a slightly different way in figure [ fig : mix-3d ] and summarised in table [ fig : mix - table ] can potentially be of great importance for editors and act as a guide in determining the optimal number of reviewers .",
    "for example , in order to receive two reviews after about 30 days , one needs to invite 7 * other * reviewers , 2 * trusted * or a mixed group of 4 * other * and 1 * trusted*. that last option is consistent with the choice made by the editor of jcsc who provided us with the data .",
    "it is important to note that while editors may be tempted to invite only * trusted * reviewers - which would lead to shortest review times - such a policy would not only be not realistic but also inadvisable .",
    "since the pool of potential * trusted * reviewers is limited , editors would be forced to invite the same reviewers multiple times within a short time frame .",
    "this , in turn , could discourage reviewers and make them more likely to turn down invitations .         but with rescaled x axis.,width=302 ]",
    "our results show that the distribution of review time is similar for all kinds of reviewers and it is the completion rate that is the main factor that determines the effectiveness of the review process . *",
    "trusted * reviewers , that is reviewers known personally by the editor , are far more reliable than * other * reviewers .",
    "their completion rate is very high , which means that they are much more likely to answer the invitation and finish the review . on the other hand , only a fraction of * other * reviewers answer the initial invitation and write the report .",
    "it means that * trusted * reviewers are objectively better than * other * reviewers and there is no advantage in choosing the latter over the former . in an ideal world , editors would invite only * trusted * reviewers , which , unfortunately , is not possible .    one question remains , then - who exactly is this mythical * trusted * reviewer ? what makes the difference between * trusted * and * other * reviewers ?",
    "in the case of jcsc , it was a personal relationship with the editor .",
    "one can easily imagine that this mechanism works in a very similar way in journals of comparable scope .",
    "what about bigger journals or ones in which editors do not choose reviewers themselves ? even without knowing the editor , reviewers invited by prestigious journals with high impact factor may be more inclined to write the review and thus act as * trusted*. in the end , it seems that the distinction between * trusted * and * other * reviewers is slightly artificial and was motivated mostly by the way our data is structured . instead , the completion rate is a much more intrinsic property that differentiates between reviewers .",
    "it is also important to notice that the completion rate is not a property of a reviewer , but of his relationship with other entities - be it journals , editors or even other reviewers .",
    "as such , the same reviewer can be treated as * trusted * by some journals and as * other * by others .",
    "also , since relations between people can change , the completion rate does not have to be constant and it may evolve with time .",
    "authors of manuscripts , reviewers and editors form a complex network of mutual connections , the structure of which have a direct influence on the effectiveness of the review process . however , since editors are the ones who actually manage the entire process , it would seem that their workflow is equally , if not even more important . with the right kind of workflow one",
    "can potentially overcome many shortcoming of the behaviour of both authors and reviewers .",
    "we have shown that through very naive and most certainly not optimal means - by sending invitations to a certain number of potential reviewers - it is possible to achieve almost any desirable average review time .",
    "while it is a very simple example , our results presented in this manuscript can be used as a foundation necessary to study the dynamics of the review process and determine the optimal workflow for an editor , which will be the subject of our future work .",
    "a.f . & p.f . were supported by the foundation for polish science ( grant no .",
    "pomost/2012 - 5/5 ) and by the european union within european regional development fund ( innovative economy ) .",
    "this paper is a part of scientific activities in cost action td1306 new frontiers of peer review ( peere ) .",
    "99 wager e. , jefferson t. , _ the shortcomings of peer review _ , learned publishing , * 14 * , pp.257 - 263 ( 2001 ) .",
    "cooper m.l . , _ problems , pitfalls , and promise of the peer - review process :",
    "commentary on trafimow & rice ( 2009 ) _ , perspect .",
    "sci . * 4 * , 8490 ( 2009 ) .",
    "baker d. , _ the peer review process in science education journals _",
    ", research in science education , * 32 * , 171180 ( 2002 ) .",
    "publishing research consortium , _ peer review in scholarly journals : perspective of the scholarly community  an international study _ , ( 2008 ) .",
    "bornmann l. , _ scientific peer review _ ,",
    "* 45 * , pp.199 - 245 ( 2011 ) .",
    "cawley v. , _ an analysis of the ethics of peer review and other traditional academic publishing practices _ , int .",
    ", * 1 * , 205 - 213 ( 2011 ) .",
    "resnik d.b , gutierrez - ford c. , peddada s. , _ perceptions of ethical problems with scientific journal peer review : an exploratory study _",
    "* 14 * , 305 - 310 ( 2008 ) .",
    "schwartz s.j . , zamboanga b.l .",
    ", _ the peer - review and editorial system : ways to fix something that might be broken _ ,",
    ", * 4 * , 54 - 61 ( 2009 ) .",
    "kravitz r.l . , franks p. , feldman m.d .",
    ", et al . , _ editorial peer reviewers recommendations at a general medical journal : are they reliable and do editors care ?",
    "_ , plos one , * 5 * , e10072 ( 2010 ) .",
    "newton d.p . ,",
    "_ quality and peer review of research : an adjudicating role for editors _ , account .",
    ", * 17 * , 130145 ( 2010 )",
    ". committee on publication ethics , _ cope ethical guidelines for peer reviewers _ , http://publicationethics.org/files/ethical_guidelines_for_peer_reviewers_0.pdf , ( 2013 ) .",
    "wager e. , _ ethics : what is it for ?",
    "_ , nature : web debate  peer - review , http://www.nature.com/nature/peerreview/debate/nature04990.html , ( 2006 ) ."
  ],
  "abstract_text": [
    "<S> we examine selected aspects of peer review and suggest possible improvements . to this end , we analyse a dataset containing information about 300 papers submitted to the biochemistry and biotechnology section of the journal of the serbian chemical society . after separating the peer review process into stages that each review has to go through , we use a weighted directed graph to describe it in a probabilistic manner and test the impact of some modifications of the editorial policy on the efficiency of the whole process .    _ </S>",
    "<S> keywords : _ peer review , editorial process , weighted directed graph 0.5 cm </S>"
  ]
}