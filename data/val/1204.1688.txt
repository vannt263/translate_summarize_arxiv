{
  "article_text": [
    "recent years have seen significant developments in the theory of classification , most notably binary classification , where strong theoretical results are available that quantify rates of convergence and shed light on qualitative aspects of the problem @xcite .",
    "extensions to multi - class classification have also been explored , and connections to the theory of regression are increasingly well understood , so that overall a satisfactory theory of supervised machine learning has begun to emerge @xcite .    in many real - world problems in which labels or responses are available , however , the problem is not merely to classify or predict a real - valued response , but rather to list a set of items in order .",
    "the theory of supervised learning can not be considered complete until it also provides a treatment of such _ ranking _ problems .",
    "for example , in information retrieval , the goal is to rank a set of documents in order of relevance to a user s search query ; in medicine , the object is often to rank drugs in order of probable curative outcomes for a given disease ; and in recommendation or advertising systems , the aim is to present a set of products in order of a customer s willingness to purchase or consume . in each example",
    ", the intention is to order a set of items in accordance with the preferences of an individual or population .",
    "while such problems are often converted to classification problems for simplicity ( e.g. , a document is classified as `` relevant '' or not ) , decision makers frequently require the ranks ( e.g. , a search engine must display documents in a particular order on the page ) . despite its ubiquity ,",
    "our statistical understanding of ranking falls short of our understanding of classification and regression .",
    "our aim here is to characterize the statistical behavior of computationally tractable inference procedures for ranking under natural data - generating mechanisms .",
    "we consider a general decision - theoretic formulation of the _ supervised ranking problem _ in which preference data are drawn i.i.d . from an unknown distribution , where each datum consists of a _ query _ , @xmath1 , and a _ preference judgment _",
    ", @xmath2 , over a set @xmath3 of candidate items that are available based on the query @xmath4 . the exact nature of the query and preference judgment depend on the ranking context . in the setting of information retrieval , for example",
    ", each datum corresponds to a user issuing a natural language query and expressing a preference by selecting or clicking on zero or more of the returned results .",
    "the statistical task is to discover a function that provides a query - specific ordering of items that best respects the observed preferences .",
    "this query - indexed setting is especially natural for tasks like information retrieval in which a different ranking of webpages is needed for each natural language query .",
    "following existing literature , we estimate a _ scoring function _ @xmath5 , where @xmath6 assigns a score to each of @xmath7 candidate items for the query @xmath8 , and the results are ranked according to their scores @xcite . throughout the paper ,",
    "we adopt a decision - theoretic perspective and assume that given a query - judgment pair @xmath9 , we evaluate the scoring function @xmath10 via a loss @xmath11 . the goal is to choose the @xmath10 minimizing the risk @xmath12.\\ ] ] while minimizing the risk ( [ eqnrisk ] ) directly is in general intractable , researchers in machine learning and information retrieval have developed surrogate loss functions that yield procedures for selecting @xmath10 . unfortunately , as we show , extant procedures fail to solve the ranking problem under reasonable data generating mechanisms . the goal in the remainder of the paper is to explain this failure and to propose a novel solution strategy based on preference aggregation .    let us begin to elucidate the shortcomings of current approaches to ranking .",
    "one main problem lies in their unrealistic assumptions about available data .",
    "the losses proposed and most commonly used for evaluation in the information retrieval literature @xcite have a common form , generally referred to as ( normalized ) discounted cumulative gain ( ( n)dcg ) .",
    "the ndcg family requires that the preference judgments @xmath13 associated with the datum @xmath9 be a vector @xmath14 of _ relevance scores _ for the entire set of items ; that is , @xmath15 denotes the real - valued relevance of item @xmath16 to the query @xmath4 . while having complete preference information makes it possible to design procedures that asymptotically minimize ndcg losses ( e.g. , @xcite ) , in practice such complete preferences are unrealistic : they are expensive to collect and difficult to trust . in biological applications , evaluating the effects of all drugs involved in a study  or all doses  on a single subject is infeasible . in web search ,",
    "users click on only one or two results : no feedback is available for most items .",
    "even when practical and ethical considerations do not preclude collecting complete preference information from participants in a study , a long line of psychological work highlights the inconsistency with which humans assign numerical values to multiple objects ( e.g. , @xcite ) .",
    "the inherent practical difficulties that arise in using losses based on relevance scores has led other researchers to propose loss functions that are suitable for _ partial preference data _ @xcite .",
    "such data arise naturally in a number of real - world situations ; for example , a patient s prognosis may improve or deteriorate after administration of treatment , competitions and sporting matches provide paired results , and shoppers at a store purchase one item but not others . moreover",
    ", the psychological literature shows that human beings are quite good at performing pairwise distinctions and forming relative judgments ( see , e.g. , @xcite and references therein ) .",
    "more formally , let @xmath17 denote the vector of predicted scores for each item associated with query @xmath4 .",
    "if a preference @xmath13 indicates that item @xmath18 is preferred to @xmath16 then the natural associated loss is the zero - one loss @xmath19 .",
    "minimizing such a loss is well known to be computationally intractable ; nonetheless , the classification literature @xcite has shown that it is possible to design convex fisher - consistent surrogate losses for the 01 loss in classification settings and has linked fisher consistency to consistency . by reduction to classification ,",
    "similar consistency results are possible in certain bipartite or binary ranking scenarios @xcite .",
    "one might therefore hope to make use of these surrogate losses in the ranking setting to obtain similar guarantees .",
    "unfortunately , however , this hope is not borne out ; as we illustrate in section  [ secconsistency ] , it is generally computationally intractable to minimize any fisher - consistent loss for ranking , and even in favorable low - noise cases , convex surrogates that yield fisher consistency for binary classification fail to be fisher - consistent for ranking .    we find ourselves at an impasse : existing methods based on practical data - collection strategies do not yield a satisfactory theory , and those methods that do have theoretical justification are not practical . our approach to",
    "this difficulty is to take a new approach to supervised ranking problems in which partial preference data are aggregated before being used for estimation .",
    "the point of departure for this approach is the notion of _ rank aggregation _",
    "( e.g. , @xcite ) , which has a long history in voting @xcite , social choice theory @xcite and statistics @xcite . in section  [ secaggregation",
    "] , we discuss some of the ways in which partial preference data can be aggregated , and we propose a new family of @xmath0-statistic - based loss functions that are computationally tractable . sections  [ secconsistency ] and [ secu - statistics ] present a theoretical analysis of procedures based on these loss functions , establishing their consistency .",
    "we provide a further discussion of practical rank aggregation strategies in section  [ secrank - aggregation ] and present experimental results in section  [ secexperiments ] .",
    "section  [ secconclusions ] contains our conclusions , with proofs deferred to appendices .",
    "we begin by considering several ways in which partial preference data arise in practice .",
    "we then turn to a formal treatment of our aggregation - based strategy for supervised ranking .",
    "[ itempaired - comparison ] _ paired comparison data_. data in which an individual judges one item to be preferred over another in the context of a query are common .",
    "competitions and sporting matches , where each pairwise comparison may be accompanied by a magnitude such as a difference of scores , naturally generate such data . in practice",
    ", a single individual will not provide feedback for all possible pairwise comparisons , and we do not assume transitivity among the observed preferences for an individual .",
    "thus , it is natural to model the pairwise preference judgment space @xmath20 as the set of weighted directed graphs on @xmath7 nodes .    _",
    "selection data_. a ubiquitous source of partial preference information is the selection behavior of a user presented with a small set of potentially ordered items .",
    "for example , in response to a search query , a web search engine presents an ordered list of webpages and records the url a user clicks on , and a store records inventory and tracks the items customers purchase .",
    "such selections provide partial information : that a user or customer prefers one item to others presented .",
    "_ partial orders_. an individual may also provide preference feedback in terms of a partial ordering over a set of candidates or items . in the context of elections , for example ,",
    "each preference judgment @xmath2 specifies a partial order @xmath21 over candidates such that candidate @xmath18 is preferred to candidate @xmath16 whenever @xmath22 .",
    "a  partial order need not specify a preference between every pair of items .",
    "using these examples as motivation , we wish to develop a formal treatment of ranking based on aggregation . to provide intuition for",
    "the framework presented in the remainder of this section , let us consider a simple aggregation strategy appropriate for the case of paired comparison data .",
    "let each relevance judgment @xmath2 be a weighted adjacency matrix where the @xmath23th entry expresses a preference for item @xmath18 over @xmath16 whenever this entry is nonzero . in this case ,",
    "a natural aggregation strategy is to average all observed adjacency matrices for a fixed query .",
    "specifically , for a set of adjacency matrices @xmath24 representing user preferences for a given query , we form the average @xmath25 . as @xmath26",
    ", the average adjacency matrix captures the mean population preferences , and we thereby obtain complete preference information over the @xmath7 items .",
    "this averaging of partial preferences is one example of a general class of aggregation strategies that form the basis of our theoretical framework . to formalize this notion ,",
    "we modify the loss formulation slightly and hereafter assume that the loss function @xmath27 is a mapping @xmath28 , where @xmath29 is a problem - specific _ structure space_. we further assume the existence of a series of _ structure functions _",
    ", @xmath30 , that map sets of preference judgments @xmath31 into @xmath29 .",
    "the loss @xmath27 depends on the preference feedback @xmath32 for a given query only via the structure @xmath33 . in the example of the previous paragraph",
    ", @xmath29 is the set of @xmath34 adjacency matrices , and @xmath35 .",
    "a typical loss for this setting is the pairwise loss @xcite @xmath36 where @xmath37 is a set of scores and @xmath38 is the average adjacency matrix with entries @xmath39 . in section  [ secrank - aggregation ] , we provide other examples of structure functions for different data collection mechanisms and losses . hereafter , we abbreviate @xmath40 as @xmath41 whenever the input length @xmath42 is clear from context .    to meaningfully characterize the asymptotics of inference procedures",
    ", we make a mild assumption on the limiting behavior of the structure functions .",
    "[ assumptionlimit - structures ] fix a query @xmath43 .",
    "let the sequence @xmath44 be drawn i.i.d .",
    "conditional on @xmath8 , and define the random variables @xmath45 . if @xmath46 denotes the distribution of @xmath47 , there exists a limiting law @xmath48 such that @xmath49    for example , the averaging structure function satisfies assumption  [ assumptionlimit - structures ] so long as @xmath50 < \\infty$ ] with probability 1 .",
    "aside from the requirements of assumption  [ assumptionlimit - structures ] , we allow arbitrary aggregation within the structure function .",
    "in addition , our main assumption on the loss function @xmath27 is as follows :    [ assumptionloss - continuity ] the loss function @xmath51 is bounded in @xmath52 $ ] , and , for any fixed vector @xmath53 , @xmath54 is continuous in the topology of @xmath29 .    with our assumptions on the asymptotics of the structure function @xmath55 and the loss @xmath27 in place",
    ", we now describe the risk functions that guide our design of inference procedures .",
    "we begin with the pointwise conditional risk , which maps predicted scores and a measure @xmath56 on @xmath29 to @xmath52 $ ] : @xmath57 \\qquad\\mbox{where } \\condloss(\\alpha , \\limitlaw ) \\defeq \\int l(\\alpha , \\structure ) \\,d \\limitlaw(\\structure ) .",
    "\\label{eqncondloss}\\ ] ] here , @xmath58 denotes the closure of the subset of probability measures on the set @xmath29 for which @xmath59 is defined . for any query @xmath8 and @xmath60",
    ", we have @xmath61 by the definition of convergence in distribution .",
    "this convergence motivates our decision - theoretic approach .",
    "our goal in ranking is thus to minimize the risk @xmath62 where @xmath63 denotes the probability that the query @xmath43 is issued .",
    "the risk of the scoring function @xmath10 can also be obtained in the limit as the number of preference judgments for each query goes to infinity : @xmath64 = \\lim_k \\sum_q \\queryprob_q \\condloss\\bigl(f(q ) , \\limitlaw_q^k \\bigr).\\ ] ] that the limiting expectation ( [ eqnalternate - risk ] ) is equal to the risk ( [ eqnrisk - def ] ) follows from the definition of weak convergence .",
    "we face two main difficulties in the study of the minimization of the risk ( [ eqnrisk - def ] ) .",
    "the first difficulty is that of _ fisher consistency _ mentioned previously : since @xmath27 may be nonsmooth in the function @xmath10 and is typically intractable to minimize , when will the minimization of a tractable surrogate lead to the minimization of the loss ( [ eqnrisk - def ] ) ? we provide a precise formulation of and answer to this question in section  [ secconsistency ] .",
    "in addition , we demonstrate the inconsistency of many commonly used pairwise ranking surrogates and show that aggregation leads to tractable fisher consistent inference procedures for both complete and partial data losses .",
    "the second difficulty is that of _ consistency _ : for a given fisher consistent surrogate for the risk ( [ eqnrisk - def ] ) , are there tractable statistical procedures that converge to a minimizer of the risk ?",
    "in section  [ secu - statistics ] , we develop a new family of aggregation losses based on @xmath0-statistics of increasing order , showing that uniform laws of large numbers hold for the resulting @xmath65-estimators .",
    "in this section , we formally define the fisher consistency of a surrogate loss and give general necessary and sufficient conditions for consistency to hold for losses satisfying assumption  [ assumptionloss - continuity ] . to begin , we assume that the space @xmath66 of queries is countable ( or finite ) and thus bijective with @xmath67 . recalling the definition ( [ eqnrisk - def ] ) of the risk and the pointwise conditional risk ( [ eqncondloss ] ) ,",
    "we define the bayes risk for @xmath68 as the minimal risk over all measurable functions @xmath69 : @xmath70 the second equality follows because @xmath66 is countable and the infimum is taken over all measurable functions .",
    "since it is infeasible to minimize the risk ( [ eqnrisk - def ] ) directly , we consider a bounded - below surrogate @xmath71 to minimize in place of @xmath27 .",
    "for each structure @xmath72 , we write @xmath73 , and we assume that for @xmath74 , the function @xmath75 is continuous with respect to the topology on @xmath29 .",
    "we then define the conditional @xmath71-risk as @xmath76 and the asymptotic @xmath71-risk of the function @xmath10 as @xmath77 whenever each @xmath78 exists [ otherwise @xmath79 .",
    "the optimal @xmath71-risk is defined to be @xmath80 , and throughout we make the assumption that there exist measurable @xmath10 such that @xmath81 so that @xmath82 is finite .",
    "the following is our general notion of fisher consistency .",
    "[ definitionconsistency ] the surrogate loss @xmath71 is _ fisher - consistent _ for the loss @xmath27 if for any @xmath83 and probability measures @xmath84 , the convergence @xmath85    to achieve more actionable risk bounds and to more accurately compare surrogate risks , we also draw upon a uniform statement of consistency :    [ definitionuniform - consistency ] the surrogate loss @xmath71 is _ uniformly fisher - consistent _ for the loss @xmath27 if for any @xmath86 , there exists a @xmath87 such that for any @xmath83 and probability measures @xmath88 , @xmath89    the bound ( [ eqnuniform - consistency ] ) is equivalent to the assertion that there exists a nondecreasing function @xmath90 such that @xmath91 and @xmath92 . bounds of this form have been completely characterized in the case of binary classification  @xcite , and steinwart  @xcite has given necessary and sufficient conditions for uniform fisher - consistency to hold in general risk minimization problems .",
    "we now turn to analyzing conditions under which a surrogate loss @xmath71 is fisher - consistent for ranking .",
    "the main approach in establishing conditions for the surrogate risk fisher consistency in definition  [ definitionconsistency ] is to move from global conditions for fisher consistency to local , pointwise fisher consistency .",
    "following the treatment of steinwart  @xcite , we begin by defining a function measuring the discriminating ability of the surrogate @xmath71 : @xmath93 this function is familiar from work on surrogate risk fisher consistency in classification @xcite and measures surrogate risk suboptimality as a function of risk suboptimality .",
    "a reasonable conditional @xmath71-risk will declare a set of scores @xmath74 suboptimal whenever the conditional risk @xmath94 declares them suboptimal .",
    "this corresponds to @xmath95 whenever @xmath86 , and we call any loss satisfying this condition _ pointwise consistent_.    from these definitions , we can conclude the following consistency result , which is analogous to the results of @xcite . for completeness , we provide a proof in the supplementary material @xcite .",
    "[ propositionuniform - consistency ] let @xmath96 be a bounded - below loss function such that for some @xmath10 , @xmath97 .",
    "then @xmath71 is pointwise consistent if and only if the uniform fisher - consistency definition ( [ eqnuniform - consistency ] ) holds .",
    "proposition  [ propositionuniform - consistency ] makes it clear that pointwise consistency for general measures @xmath56 on the set of structures @xmath29 is a stronger condition than that of fisher consistency in definition  [ definitionconsistency ] . in some situations , however , it is possible to connect the weaker surrogate risk fisher consistency of definition  [ definitionconsistency ] with uniform fisher consistency and pointwise consistency .",
    "ranking problems with appropriate choices of the space @xmath29 give rise to such connections . indeed , consider the following :    [ assumptionfiniteness ] the space of possible structures @xmath29 is finite , and the loss @xmath27 is discrete , meaning that it takes on only finitely many values .    binary and multiclass classification provide examples of settings in which assumption  [ assumptionfiniteness ] is appropriate , since the set of structures @xmath29 is the set of class labels , and @xmath27 is usually a version of the @xmath98@xmath99 loss .",
    "we also sometimes make a weaker version of assumption  [ assumptionfiniteness ] :    [ assumptioncompact - s ] the ( topological ) space of possible structures @xmath29 is compact , and for some @xmath100 there exists a partition @xmath101 of @xmath102 such that for any @xmath72 , @xmath103    assumption  [ assumptioncompact - s ] may be more natural in ranking settings than assumption  [ assumptionfiniteness ] .",
    "the compactness assumption holds , for example , if @xmath104 is closed and bounded , such as in our pairwise aggregation example in section  [ secaggregation ] .",
    "losses @xmath27 that depend only on the relative order of the coordinate values of @xmath74common in ranking problems  provide a collection of examples for which the partitioning condition holds .    under assumption  [ assumptionfiniteness ] or [ assumptioncompact - s ] , we can provide a definition of local consistency that is often more user - friendly than pointwise consistency ( [ eqnsuboptimality - def ] ) :    [ definitionstructure - consistent ] let @xmath71 be a bounded - below surrogate loss such that @xmath105 is continuous for all @xmath106 .",
    "the function @xmath71 is _ structure - consistent _ with respect to the loss @xmath27 if for all @xmath107 , @xmath108    definition  [ definitionstructure - consistent ] describes the set of loss functions @xmath71 satisfying the intuitively desirable property that the surrogate @xmath71 can not be minimized if the scores @xmath74 are restricted to not minimize the loss @xmath27 .",
    "as we see presently , definition  [ definitionstructure - consistent ] captures exactly what it means for a surrogate loss @xmath71 to be fisher - consistent when one of assumptions [ assumptionfiniteness ] or [ assumptioncompact - s ] holds .",
    "moreover , the set of fisher - consistent surrogates coincides with the set of uniformly fisher - consistent surrogates in this case .",
    "the following theorem formally states this result ; we give a proof in the supplementary material @xcite .",
    "[ theoremstructure - consistency ] let @xmath109 satisfy @xmath110 for some measurable @xmath10 . if assumption  [ assumptionfiniteness ] holds , then :    [ theoremstructure - consistency - a ] if @xmath71 is structure consistent ( definition  [ definitionstructure - consistent ] ) , then @xmath71 is uniformly fisher - consistent for the loss @xmath27 ( definition  [ definitionuniform - consistency ] ) .",
    "[ theoremstructure - consistency - b ] if @xmath71 is fisher - consistent for the loss @xmath27 ( definition  [ definitionconsistency ] ) , then @xmath71 is structure consistent .",
    "if the function @xmath105 is convex for @xmath106 , and for @xmath111 the conditional risk @xmath112 as @xmath113 , then assumption  [ assumptioncompact - s ] implies and .",
    "theorem  [ theoremstructure - consistency ] shows that as long as assumption  [ assumptionfiniteness ] holds , pointwise consistency , structure consistency , and both uniform and nonuniform surrogate loss consistency coincide .",
    "these four also coincide under the weaker assumption  [ assumptioncompact - s ] so long as the surrogate is @xmath98-coercive , which is not restrictive in practice . as a final note",
    ", we recall a result due to steinwart @xcite , which gives general necessary and sufficient conditions for the consistency in definition  [ definitionconsistency ] to hold , using a weaker version of the suboptimality function ( [ eqnsuboptimality - def ] ) that depends on @xmath56 : @xmath114    [ propositionall - consistency ] the suboptimality function ( [ eqnlocal - suboptimality - def ] ) satisfies @xmath115 for any @xmath86 and @xmath48 with @xmath116 and @xmath117 if and only if @xmath71 is fisher - consistent for the loss @xmath27 ( definition  [ definitionconsistency ] ) .    as a corollary of this result , any structure - consistent surrogate loss @xmath71 ( in the sense of definition  [ definitionstructure - consistent ] ) is fisher - consistent for the loss @xmath27 whenever the conditional risk @xmath118 has finite range , so that @xmath119 implies the existence of an @xmath86 such that @xmath120 .",
    "we now turn to the question of whether there exist structure - consistent ranking losses . in a preliminary version of this work @xcite , we focused on the practical setting of learning from pairwise preference data and demonstrated that many popular ranking surrogates are inconsistent for standard pairwise ranking losses .",
    "we review and generalize our main inconsistency results here , noting that while the losses considered use pairwise preferences , they perform no aggregation .",
    "their theoretically poor performance provides motivation for the aggregation strategies proposed in this work ; we explore the connections in section  [ secrank - aggregation ] ( focusing on pairwise losses in section  [ secstructured - aggregation ] ) .",
    "we provide proofs of our inconsistency results in the supplementary material @xcite . to place ourselves in the general structural setting of the paper , we consider the structure function @xmath121 which performs no aggregation for all  @xmath42 , and we let @xmath13 denote the weighted adjacency matrix of a directed acyclic graph ( dag ) @xmath122 , so that @xmath123 is the weight of the directed edge @xmath124 in the graph @xmath122 .",
    "we consider a pairwise loss that imposes a separate penalty for each misordered pair of results : @xmath125 where we distinguish the cases @xmath126 and @xmath127 to avoid doubly penalizing @xmath128 .",
    "when pairwise preference judgments are available , use of such losses is common . indeed",
    ", this loss generalizes the disagreement error described by dekel et  al .",
    "@xcite and is similar to losses used by joachims @xcite .",
    "if we define @xmath129 , then @xmath130 we assume that the number of nodes in any graph @xmath122 ( or , equivalently , the number of results returned by any query ) is bounded by a finite constant @xmath7 .",
    "hence , the conditional risk ( [ eqnedge - condloss ] ) has a finite range ; if there are a finite number of preference labels @xmath13 or the set of weights is compact , assumptions [ assumptionfiniteness ] or [ assumptioncompact - s ] are satisfied , whence theorem  [ theoremstructure - consistency ] applies .",
    "let the set @xmath131 denote the complexity class of problems solvable in polynomial time and @xmath132 denote the class of nondeterministic polynomial time problems ( see , e.g. , @xcite ) .",
    "our first inconsistency result ( see also  @xcite , lemma  7 ) is that unless @xmath133 ( a widely doubted proposition ) , any loss that is tractable to minimize can not be a fisher - consistent surrogate for the loss ( [ eqnedge - loss ] ) and its associated risk .",
    "[ propositionranking - np - hard ] finding an @xmath37 minimizing @xmath94 is @xmath132-hard .",
    "in particular , most convex functions are minimizable to an accuracy of @xmath134 in time polynomial in the dimension of the problem times a multiple of @xmath135 , known as poly - logarithmic time @xcite .",
    "since any @xmath37 minimizing @xmath136 must minimize @xmath118 for a fisher - consistent surrogate @xmath71 , and @xmath137 has a finite range ( so that optimizing @xmath138 to a fixed @xmath134 accuracy is sufficient ) , convex surrogate losses are inconsistent for the pairwise loss ( [ eqnedge - loss ] ) unless @xmath133 .",
    "we now turn to showing that , surprisingly , many common convex surrogates are inconsistent even in low - noise settings in which it is easy to find an @xmath37 minimizing @xmath118 .",
    "( weaker versions of the results in this section appeared in our preliminary paper @xcite . ) inspecting the loss definition  ( [ eqnedge - loss ] ) , a natural choice for a surrogate loss is one of the form @xcite @xmath139 where @xmath140 is a convex function , and @xmath141 is a some function of the penalties @xmath123 .",
    "this surrogate implicitly uses the structure function @xmath142 and performs no preference aggregation .",
    "the conditional surrogate risk is thus @xmath143 , where @xmath144 .",
    "surrogates of the form ( [ eqnsurr - edge - loss ] ) are convenient in margin - based binary classification , where the complete description by bartlett , jordan and mcauliffe @xcite shows @xmath145 is fisher - consistent if and only if it is differentiable at 0 with @xmath146 .",
    "we now precisely define our low - noise setting . for any measure @xmath56 on a space  @xmath20 of adjacency matrices , let the directed graph @xmath147 be the _ difference graph _ ,",
    "that is , the graph with edge weights @xmath148 on edges @xmath124 , where @xmath149 .",
    "then we say that the edge @xmath150 if @xmath151 ( see figure  [ figdag - examples ] ) . we define the following low - noise condition based on self - reinforcement of edges in the difference graph .",
    ", yielding the difference graph @xmath147 at right , assuming @xmath152 . ]",
    "[ defrev - triangle ] the measure @xmath56 on a set @xmath13 of adjacency matrices is _ low - noise _ when the corresponding difference graph @xmath147 satisfies the following reverse triangle inequality : whenever there is an edge @xmath124 and an edge @xmath153 in @xmath147 , the weight @xmath154 on the edge @xmath155 is greater than or equal to the path weight @xmath156 on the path @xmath157 .",
    "if @xmath56 satisfies definition  [ defrev - triangle ] , its difference graph @xmath147 is a dag .",
    "indeed , the definition ensures that all global preference information in @xmath147 ( the sum of weights along any path ) conforms with and reinforces local preference information ( the weight on a single edge ) .",
    "hence , we would expect any reasonable ranking method to be consistent in this setting .",
    "nevertheless , typical pairwise surrogate losses are inconsistent in this low - noise setting ( see also the weaker theorem  11 in our preliminary work @xcite ) :    [ theoreminconsistency - convex ] let @xmath71 be a loss of the form ( [ eqnsurr - edge - loss ] ) and assume @xmath158 . if @xmath145 is convex , then even in the low - noise setting of definition  [ defrev - triangle ] the loss @xmath71 is not structure - consistent .    given the difficulties we encounter using losses of the form ( [ eqnsurr - edge - loss ] ) , it is reasonable to consider a reformulation of the surrogate . a natural alternative is a margin - based loss , which encodes a desire to separate ranking scores by large margins dependent on the preferences in a graph .",
    "similar losses have been proposed , for example , by  @xcite .",
    "the next result shows that convex margin - based losses are also inconsistent , even in low - noise settings .",
    "( see also the weaker theorem  12 of our preliminary work @xcite . )",
    "[ theoreminconsistency - margin ] let @xmath159 and @xmath71 be a loss of the form @xmath160 if @xmath145 is convex , then even in the low - noise setting of definition  [ defrev - triangle ] the loss @xmath71 is not structure - consistent .",
    "although section  [ secconsistency - hard ] suggests an inherent difficulty in the development of tractable losses for ranking , tractable fisher consistency is in fact achievable if one has access to _ complete _ preference data .",
    "we review a few of the known results here , showing how they follow from the fisher consistency guarantees in section  [ secgeneral - consistency ] , and derive some new fisher consistency guarantees for the complete data setting ( we defer all proofs to the supplementary material @xcite ) .",
    "these results may appear to be of limited practical value , since complete preference judgments are typically unavailable or untrustworthy , but , as we show in sections  [ secu - statistics ] and [ secrank - aggregation ] , they can be combined with aggregation strategies to yield procedures that are both practical and come with consistency guarantees .",
    "we first define the normalized discounted cumulative gain ( ndcg ) family of complete data losses .",
    "such losses are common in applications like web search , since they penalize ranking errors at the top of a ranked list more heavily than errors farther down the list .",
    "let @xmath161 be a vector of relevance scores and @xmath74 be a vector of predicted scores .",
    "define @xmath162 to be the permutation associated with @xmath37 , so that @xmath163 is the rank of item @xmath16 in the ordering induced by @xmath37 . following ravikumar et  al .",
    "@xcite , a general class of ndcg loss functions can be defined as follows : @xmath164 where @xmath165 and @xmath166 are functions monotonically increasing in their arguments . by inspection ,",
    "@xmath167 $ ] , and we remark that the standard ndcg criterion @xcite uses @xmath168 and @xmath169 .",
    "the `` precision at @xmath42 '' loss @xcite can also be written in the form ( [ eqnndcg ] ) , where @xmath170 ( assuming that @xmath171 ) and @xmath172 for @xmath173 and @xmath174 otherwise , which measures the relevance of the top @xmath42 items given by the vector @xmath37 .",
    "this form generalizes standard forms of precision , which assume @xmath175 .    to analyze the consistency of surrogate losses for the ndcg family ( [ eqnndcg ] ) , we first compute the loss @xmath176 and then state a corollary to proposition  [ propositionall - consistency ] .",
    "observe that for any @xmath107 , @xmath177 since the function @xmath166 is increasing in its argument , minimizing @xmath118 corresponds to choosing any vector @xmath37 whose values @xmath178 obey the same order as the @xmath7 points @xmath179 . in particular , the range of @xmath94 is finite for any @xmath56 since it depends only on the permutation induced by @xmath37 , so we have corollary  [ corollaryndcg - consistency ] .",
    "[ corollaryndcg - consistency ] define the set @xmath180 a surrogate loss @xmath71 is fisher - consistent for the ndcg family ( [ eqnndcg ] ) if and only if for all @xmath181 , @xmath182    corollary  [ corollaryndcg - consistency ] recovers the main flavor of the consistency results in the papers of ravikumar et  al . @xcite and buffoni et  al . @xcite .",
    "the surrogate @xmath71 is consistent if and only if it preserves the order of the integrated terms @xmath183 : any sequence @xmath184 tending to the infimum of @xmath185 must satisfy @xmath186 for large enough @xmath187 .",
    "zhang @xcite presents several examples of such losses ; as a corollary to his theorem  5 ( also noted by @xcite ) , the loss @xmath188 is convex and structure - consistent ( in the sense of definition  [ definitionstructure - consistent ] ) whenever @xmath189 is nonincreasing , differentiable and satisfies @xmath190 .",
    "the papers @xcite contain more examples and a deeper study of ndcg losses . to extend corollary  [ corollaryndcg - consistency ] to a uniform result",
    ", we note that if @xmath191 for all @xmath16 and @xmath29 is compact , then @xmath71 is 0-coercive over the set @xmath192 , , so we may arbitrarily set a value for @xmath193 . ]",
    "whence theorem  [ theoremstructure - consistency ] implies that structure consistency coincides with uniform consistency .",
    "another family of loss functions is based on a cascade model of user behavior  @xcite .",
    "these losses model dependency among items or results by assuming that a user scans an ordered list of results from top to bottom and selects the first satisfactory result . here",
    ", satisfaction is determined independently at each position .",
    "let @xmath194 denote the index of item that @xmath74 assigns to rank @xmath18 .",
    "the form of such expected reciprocal rank ( err ) losses is @xmath195 where @xmath196 $ ] is a nondecreasing function that indicates the prior probability that a result with score @xmath197 is selected , and @xmath198 is an increasing function that more heavily weights the first items .",
    "the err family also satisfies @xmath199 $ ] , and empirically correlates well with user satisfaction in ranking tasks  @xcite .    computing the expected conditional risk @xmath200 for general @xmath107 is difficult , but",
    "we can compute it when @xmath56 is a product measure over @xmath201 .",
    "indeed , in this case , we have @xmath202 \\prod _ { j=1}^{i-1 } \\bigl(1 - \\e_\\limitlaw\\bigl[g ( \\structure_{\\pi_\\alpha^{-1}(j)})\\bigr ] \\bigr).\\end{aligned}\\ ] ] when one believes that the values @xmath203 represent the a priori relevance of the result @xmath18 , this independence assumption is not unreasonable , and indeed , in section  [ secrank - aggregation ] we provide examples in which it holds .",
    "regardless , we see that @xmath118 depends only on the permutation @xmath162 , and we can compute the minimizers of the conditional risk for the err family ( [ eqnerr ] ) using the following lemma , with proof provided in the supplementary material @xcite .",
    "[ lemmaerr - minimizers ] let @xmath204 $ ] .",
    "the permutation @xmath205 minimizing @xmath118 is in decreasing order of the @xmath206 .",
    "lemma  [ lemmaerr - minimizers ] shows that an order - preserving property is necessary and sufficient for the fisher - consistency of a surrogate @xmath71 for the err family ( [ eqnerr ] ) , as it was for the ndcg family ( [ eqnndcg ] ) . to see this",
    ", we apply a variant of corollary  [ corollaryndcg - consistency ] where @xmath207 as defined in equation ( [ eqnndcg - optimal - set ] ) is replaced with the set @xmath208 theorem  5 of @xcite implies that @xmath209 is a consistent surrogate when @xmath145 is convex , differentiable and nonincreasing with @xmath210 .",
    "theorem  [ theoremstructure - consistency ] also yields an equivalence between structure and uniform consistency under suitable conditions on @xmath29 .    before concluding this section",
    ", we make a final remark , which has bearing on the aggregation strategies we discuss in section  [ secrank - aggregation ] .",
    "we have assumed that the structure spaces @xmath29 for the ndcg ( [ eqnndcg ] ) and err ( [ eqnerr ] ) loss families consist of real - valued relevance scores .",
    "this is certainly not necessary . in some situations",
    ", it may be more beneficial to think of @xmath106 as simply an ordered list of the results or as a directed acyclic graph over @xmath211 .",
    "we can then apply a transformation @xmath212 to get relevance scores , using @xmath213 in place of @xmath55 in the losses ( [ eqnndcg ] ) and ( [ eqnerr ] ) .",
    "this has the advantage of causing @xmath29 to be finite , so theorem  [ theoremstructure - consistency ] applies , and there exists a nondecreasing function @xmath90 with @xmath214 such that for any distribution and any measurable  @xmath10 , @xmath215",
    "in section  [ secconsistency ] , we gave examples of losses based on readily available pairwise data but for which fisher - consistent tractable surrogates do not exist .",
    "the existence of fisher - consistent tractable surrogates for other forms of data , as in section  [ secachieve - consistency ] , suggests that aggregation of pairwise and partial data into more complete data structures , such as lists or scores , makes the problem easier .",
    "however , it is not obvious how to design statistical procedures based on aggregation . in this section",
    ", we formally define a class of suitable estimators that permit us to take advantage of the weak convergence of assumption  [ assumptionlimit - structures ] and show that uniform laws of large numbers hold for our surrogate losses .",
    "this means that we can indeed asymptotically minimize the risk  ( [ eqnrisk - def ] ) as desired .",
    "our aim is to develop an empirical analogue of the population surrogate risk ( [ eqnsurrogate - risk ] ) that converges uniformly to the population risk under minimal assumptions on the loss @xmath71 and structure function @xmath55 . given a dataset @xmath216 with @xmath217 , we begin by defining , for each query @xmath8 , the batch of data belonging to the query , @xmath218 , and the empirical count of the number of items in the batch , @xmath219 . as a first attempt at developing an empirical objective , we might consider an empirical surrogate risk based on complete aggregation over the batch of data belonging to each query : @xmath220 while we would expect this risk to converge uniformly when @xmath71 is a sufficiently smooth function of its structure argument , the analysis of the complete aggregation risk ( [ eqnfull - aggregation - risk ] ) requires overly detailed knowledge of the surrogate @xmath71 and the structure function @xmath55 .    to develop a more broadly applicable statistical procedure ,",
    "we instead consider an empirical surrogate based on @xmath0-statistics . by trading off the nearness of an order-@xmath42 @xmath0-statistic to an i.i.d .",
    "sample and the nearness of the limiting structure distribution @xmath48 to a structure @xmath221 aggregated over @xmath42 draws , we can obtain consistency under mild assumptions on @xmath71 and @xmath55 .",
    "more specifically , for each query  @xmath8 , we consider the surrogate loss @xmath222 when @xmath223 , we adopt the convention @xmath224 , and the above sum becomes the single term @xmath225 as in the expression ( [ eqnfull - aggregation - risk ] ) .",
    "hence , our @xmath0-statistic loss recovers the complete aggregation loss ( [ eqnfull - aggregation - risk ] ) when @xmath226 . an alternative formulation to loss ( [ eqnu - statistic - loss ] ) might consist of @xmath227 aggregation terms per query , with each query - preference pair appearing in a single term .",
    "however , the instability of such a strategy is high : a change in the ordering of the data or a substitution of queries could have a large effect on the final estimator .",
    "the @xmath0-statistic ( [ eqnu - statistic - loss ] ) grants robustness to such perturbations in the data . moreover , by choosing the right rate of increase of the aggregation order @xmath42 as a function of @xmath187 , we obtain consistent procedures for a broad class of surrogates @xmath71 and structures @xmath55 .",
    "we associate with the surrogate loss ( [ eqnu - statistic - loss ] ) a surrogate empirical risk that weights each query by its empirical probability of appearance : @xmath228 let @xmath229 denote the probability distribution of the queries given that the dataset is of size @xmath187 . then by iteration of expectation and fubini s theorem",
    ", the surrogate risk  ( [ eqnu - statistic - emprisk ] ) is an unbiased estimate of the population quantity @xmath230 \\biggr].\\ ] ]    it remains to establish a uniform law of large numbers guaranteeing the convergence of the empirical risk ( [ eqnu - statistic - emprisk ] ) to the target population risk ( [ eqnsurrogate - risk ] ) . under suitable conditions such as those of section  [ secconsistency ] , this ensures the asymptotic consistency of computationally tractable statistical procedures .",
    "hereafter , we assume that we have a nondecreasing sequence of function classes @xmath231 , where any @xmath232 is a scoring function for queries , mapping @xmath233 and giving scores to the ( at most @xmath7 ) results for each query @xmath234 . our goal is to give sufficient conditions for the convergence in probability @xmath235    while we do not provide fully general conditions under which the convergence  ( [ eqnuniform - convergence ] ) occurs , we provide representative , checkable conditions sufficient for convergence . at a high level , to establish ( [ eqnuniform - convergence ] ) , we control the uniform difference between the expectations @xmath236 and @xmath237 and bound the distance between the empirical risk @xmath238 and its expectation @xmath239 via covering number arguments .",
    "we now specify assumptions under which our results hold , deferring all proofs to the supplementary material  @xcite . without loss of generality ,",
    "we assume that @xmath63 , the true probability of seeing the query @xmath8 , is nonincreasing in the query index @xmath8 .",
    "first , we describe the tails of the query distribution :    [ assumptionpower - law ] there exist constants @xmath240 and @xmath241 such that @xmath242 for all @xmath8 .",
    "that is , @xmath243 .",
    "infinite sets of queries @xmath66 are reasonable , since search engines , for example , receive a large volume of entirely new queries each day .",
    "our arguments also apply when @xmath66 is finite , in which case we can take @xmath244 .",
    "our second main assumption concerns the behavior of the surrogate loss @xmath71 over the function class @xmath231 , which we assume is contained in a normed space with norm  @xmath245 .    [ assumptionbounded - lipschitz ]",
    "the surrogate loss function @xmath71 is bounded and lipschitz continuous over @xmath231 : for any @xmath72 , any @xmath246 , and any @xmath116 , there exist constants @xmath247 and @xmath248 such that @xmath249 and @xmath250    this assumption is satisfied whenever @xmath105 is convex and @xmath231 is compact [ and contained in the interior of the domain of @xmath105 ] @xcite .",
    "our final assumption gives control over the sizes of the function classes @xmath231 as measured by their covering numbers .",
    "( the @xmath134-covering number of @xmath252 is the smallest @xmath253 for which there are @xmath254 , @xmath255 , such that @xmath256 for any @xmath257 . )",
    "[ assumptioncovering - number ] for all @xmath86 , @xmath231 has @xmath134-covering number @xmath258 .    with these assumptions in place ,",
    "we give a few representative conditions that enable us to guarantee uniform convergence ( [ eqnuniform - convergence ] ) .",
    "roughly , these conditions control the interaction between the size of the function classes @xmath231 and the order @xmath42 of aggregation used with @xmath187 data points . to that end , we let the aggregation order @xmath259 grow with @xmath187 . in stating the conditions , we make use of the shorthand @xmath260 $ ] for @xmath261 $ ] .    [ conditionpolynomial - in - k ]",
    "there exist a @xmath262 and constant @xmath263 such that for all @xmath116 , @xmath264 , @xmath265 , and @xmath232 , @xmath266 - \\lim _ { k ' } \\e_q\\bigl[\\surrloss\\bigl(f(q ) , \\structure ( \\preflabel_1 , \\ldots , \\preflabel_{k'})\\bigr)\\bigr ] \\bigr { \\vert}\\le c \\surrbound_n k^{-\\rho}.\\ ] ] additionally , the sequences @xmath247 and @xmath259 satisfy @xmath267 .",
    "this condition is not unreasonable ; when @xmath71 and @xmath55 are suitably continuous , we expect @xmath268 .",
    "we also consider an alternative covering number condition .",
    "[ conditioncovering - expectations ] sequences @xmath269 and @xmath270 and an @xmath271-cover @xmath272 of @xmath231 can be chosen such that @xmath273\\biggr | + 2 \\lipbound_n \\varepsilon_n \\rightarrow0.\\ ] ]    condition [ conditioncovering - expectations ] is weaker than condition [ conditionpolynomial - in - k ] , since it does not require uniform convergence over @xmath116 . if the function class @xmath274 is fixed for all @xmath187 , then the weak convergence of @xmath275 as in assumption  [ assumptionlimit - structures ] guarantees condition  [ conditioncovering - expectations ] , since @xmath276 , and we may take @xmath134 arbitrarily small .",
    "we require one additional condition , which relates the growth of @xmath259 , @xmath247 , and the function classes @xmath231 more directly .",
    "[ conditionall - sequence - growths ] the sequences @xmath259 and @xmath247 satisfy @xmath277 . additionally , for any fixed @xmath278 , the sequences satisfy @xmath279^{{1}/ { 2}}= o(\\sqrt{n}).\\ ] ]    by inspection , condition [ conditionall - sequence - growths ] is satisfied for any @xmath280 if the function classes @xmath231 are fixed for all @xmath187 .",
    "similarly , if for all @xmath281 , @xmath282 , so @xmath55 depends only on its first @xmath283 arguments , condition [ conditionall - sequence - growths ] holds whenever @xmath284 .",
    "if the function classes @xmath231 consist of linear functionals represented by vectors @xmath285 in a ball of some finite radius , then @xmath286 , which means that condition  [ conditionall - sequence - growths ] roughly requires @xmath287 as @xmath288 .",
    "modulo the factor @xmath259 , this condition is familiar from its necessity in the convergence of parametric statistical problems .    the conditions in place , we come to our main result on the convergence of our @xmath0-statistic - based empirical loss minimization procedures .",
    "[ theoremconvergence ] assume condition [ conditionpolynomial - in - k ] or [ conditioncovering - expectations ] and additionally assume the growth condition [ conditionall - sequence - growths ] . under assumptions [ assumptionpower - law ] , [ assumptionbounded - lipschitz ] and [ assumptioncovering - number ] , @xmath289    we remark in passing that if condition [ conditionall - sequence - growths ] holds , with the change that the @xmath290 bound is replaced by @xmath291 for some @xmath292 , the conclusion of theorem  [ theoremconvergence ] can be strengthened to both convergence almost surely and in expectation .    by inspection , theorem  [ theoremconvergence ]",
    "provides our desired convergence guarantee ( [ eqnuniform - convergence ] ) . by combining the fisher - consistent loss families outlined in section  [ secachieve - consistency ] with the consistency guarantees provided by theorem  [ theoremconvergence ] ,",
    "it is thus possible to design statistical procedures that are both computationally tractable  minimizing only convex risks  and asymptotically consistent .",
    "in this section , we give several examples of practical strategies for aggregating disparate user preferences under our framework .",
    "motivated by the statistical advantages of complete preference data highlighted in section  [ secachieve - consistency ] , we first present strategies for constructing complete vectors of relevance scores from pairwise preference data .",
    "we then discuss a model for the selection or `` click '' data that arises in web search and information retrieval and show that maximum likelihood estimation under this model allows for consistent ranking .",
    "we conclude this section with a brief overview of structured aggregation strategies .      here",
    "we treat partial preference observations as noisy evidence of an underlying complete ranking and attempt to achieve consistency with respect to a complete preference data loss .",
    "we consider three methods that take as input pairwise preferences and output a relevance score vector @xmath293 .",
    "such procedures fit naturally into our ranking - with - aggregation framework : the results in section  [ secachieve - consistency ] and section  [ secu - statistics ] show that a fisher - consistent loss is consistent for the limiting distribution of the scores @xmath55 produced by the aggregation procedure .",
    "thus , it is the responsibility of the statistician  the designer of an aggregation procedure  to determine whether the scores accurately reflect the judgments of the population .",
    "we present our first example in some detail to show how aggregation of pairwise judgments can lead to consistency in our framework and follow with brief descriptions of alternate aggregation strategies . for an introduction to the design of aggregation strategies for pairwise data , see tsukida and gupta  @xcite as well as the book by david @xcite .",
    "_ thurstone  mosteller least squares and skew - symmetric scoring_. the first aggregation strategy constructs a relevance score vector @xmath55 in two phases .",
    "first , it aggregates a sequence of observed preference judgments @xmath294 , provided in any form , into a skew - symmetric matrix @xmath295 satisfying @xmath296 . each entry @xmath39 encodes the extent to which item @xmath18 is preferred to item @xmath16 .",
    "given such a skew - symmetric matrix , thurstone and mosteller @xcite recommend deriving a score vector @xmath55 such that @xmath297 . in practice",
    ", one may not observe preference information for every pair of results , so we define a masking matrix @xmath298 with @xmath299 , @xmath300 , and @xmath301 if and only if preference information has been observed for the pair @xmath302 . letting @xmath303",
    "denote the hadamard product , a natural objective for selecting scores ( e.g. , @xcite ) is the least squares objective @xmath304 the gradient of the objective ( [ eqnskew - symmetric - score ] ) is @xmath305 setting @xmath306 yields the solution to the minimization problem  ( [ eqnskew - symmetric - score ] ) , since @xmath307 is an unnormalized graph laplacian matrix @xcite , and therefore @xmath308 .",
    "if @xmath309 , so that all pairwise preferences are observed , then the eigenvalue decomposition of @xmath310 can be computed explicitly as @xmath311 , where @xmath312 is any orthonormal matrix whose first column is @xmath313 , and @xmath314 is a diagonal matrix with entries @xmath98 ( once ) and @xmath7 repeated @xmath315 times .",
    "thus , letting @xmath316 and @xmath317 denote solutions to the minimization problem ( [ eqnskew - symmetric - score ] ) with different skew - symmetric matrices @xmath318 and @xmath319 and noting that @xmath320 since @xmath321 , we have the lipschitz continuity of the solutions @xmath55 in @xmath318 : @xmath322 similarly , when @xmath323 is fixed , the score structure @xmath55 is likewise lipschitz in @xmath318 for any norm @xmath324 on skew - symmetric matrices .",
    "a variety of procedures are available for aggregating pairwise comparison data @xmath294 into a skew - symmetric matrix @xmath318 .",
    "one example , the bradley  terry  luce ( btl ) model @xcite , is based upon empirical log - odds ratios .",
    "specifically , assume that @xmath325 are pairwise comparisons of the form @xmath326 , meaning item @xmath16 is preferred to item @xmath327",
    ". then we can set @xmath328 where @xmath329 denotes the empirical distribution over @xmath330 and @xmath331 is a smoothing parameter .",
    "since the proposed structure @xmath55 is a continuous function of the skew - symmetric matrix @xmath318 , the limiting distribution @xmath56 is a point mass whenever @xmath318 converges almost surely , as it does in the btl model .",
    "if aggregation is carried out using only a finite number of preferences rather than letting @xmath42 approach @xmath332 with @xmath187 , then @xmath56 converges to a nondegenerate distribution .",
    "theorem  [ theoremstructure - consistency ] grants uniform consistency since the score space @xmath29 is finite .",
    "_ borda count and budgeted aggregation . _ the borda count @xcite provides a computationally efficient method for computing scores from election results . in a general election setting ,",
    "the procedure counts the number of times that a particular item was rated as the best , second best , and so on . given a skew - symmetric matrix @xmath318 representing the outcomes of elections , the borda count assigns the scores @xmath333 . as above , a skew - symmetric matrix @xmath318 can be constructed from input preferences @xmath334 , and the choice of this first - level aggregation can greatly affect the resulting rankings .",
    "ammar and shah @xcite suggest that if one has limited computational budget and only pairwise preference information then one should assign to item @xmath16 the score @xmath335 which estimates the probability of winning an election against an opponent chosen uniformly .",
    "this is equivalent to the borda count when we choose @xmath336 as the entries in the skew - symmetric aggregate @xmath318 .",
    "_ principal eigenvector method .",
    "_ saaty @xcite describes the principal eigenvector method , which begins by forming a reciprocal matrix @xmath337 , with positive entries @xmath338 , from pairwise comparison judgments .",
    "here @xmath39 encodes a multiplicative preference for item @xmath18 over item @xmath16 ; the idea is that ratios preserve preference strength @xcite . to generate @xmath318",
    ", one may use , for example , smoothed empirical ratios @xmath339 .",
    "saaty recommends finding a vector @xmath55 so that @xmath340 , suggesting using the perron vector of the matrix , that is , the first eigenvector of @xmath318 .",
    "cascade models @xcite explain the behavior of a user presented with an ordered list of items , for example from a web search . in a cascade model ,",
    "a user considers results in the presented order and selects the first to satisfy him or her .",
    "the model assumes the result @xmath341 satisfies a user with probability @xmath342 , independently of previous items in the list .",
    "it is natural to express a variety of ranking losses , including the expected reciprocal rank ( err ) family ( [ eqnerr ] ) , as expected disutility under a cascade model , but computation and optimization of these losses require knowledge of the satisfaction probabilities @xmath342 . when the satisfaction probabilities are unknown , chapelle et  al .",
    "@xcite recommend plugging in those values @xmath342 that maximize the likelihood of observed click data . here",
    "we show that risk consistency for the err family is straightforward to characterize when scores are estimated via maximum likelihood .    to this end , fix a query @xmath8 , and let each affiliated preference judgment @xmath343 consist of a triple @xmath344 , where @xmath345 is the number of results presented to the user , @xmath346 is the order of the presented results , which maps positions @xmath347 to the full result set @xmath348 , and @xmath349 is the position clicked on by the user ( @xmath350 if the user chooses nothing ) .",
    "the likelihood @xmath351 of an i.i.d .",
    "sequence @xmath352 under a cascade model @xmath353 is @xmath354 and the maximum likelihood estimator of the satisfaction probabilities has the closed form @xmath355    to incorporate this maximum likelihood aggregation procedure into our framework , we define the structure function @xmath55 to be the vector @xmath356 of maximum likelihood probabilities , and we take as our loss @xmath27 any member of the err family ( [ eqnerr ] ) .",
    "the strong law of large numbers implies the a.s .",
    "convergence of @xmath357 to a vector @xmath358^\\numresults $ ] , so that the limiting law @xmath359 .",
    "since @xmath48 is a product measure over @xmath52^\\numresults$ ] , lemma  [ lemmaerr - minimizers ] implies that any @xmath37 inducing the same ordering over results as @xmath353 minimizes the conditional err risk @xmath118 . by application of theorems [ theoremstructure - consistency ] ( or proposition  [ propositionall - consistency ] ) and [ theoremconvergence ] ,",
    "it is possible to asymptotically minimize the expected reciprocal rank by aggregation .",
    "our framework can leverage aggregation procedures ( see , e.g. , @xcite ) that map input preferences into representations of combinatorial objects . consider the setting of section  [ secconsistency - hard ] , in which each observed preference judgment @xmath13 is the weighted adjacency matrix of a directed acyclic graph , our loss of interest @xmath27 is the edgewise indicator loss ( [ eqnedge - loss ] ) , and our candidate surrogate losses have the form ( [ eqnu - statistic - loss ] ) .",
    "theorems [ theoreminconsistency - convex ] and [ theoreminconsistency - margin ] establish that risk consistency is not generally attainable when @xmath360 . in certain cases ,",
    "aggregation can recover consistency . indeed , define @xmath361 the average of the input adjacency matrices .",
    "for an i.i.d .",
    "sequence @xmath362 associated with a given query @xmath8 , we have @xmath363 by the strong law of large numbers , and hence the asymptotic surrogate risk @xmath364 recalling the conditional pairwise risk ( [ eqnedge - condloss ] ) , we can rewrite the risk as @xmath365 \\\\ & = & \\sum_q \\queryprob_q \\sum_{i > j } \\e [ \\preflabel_{ij } \\mid q = q ] \\\\ & & { } + \\sum_q \\queryprob_q \\sum_{i",
    "< j } \\e [ \\preflabel_{ij } - \\preflabel_{ji } \\mid q = q ] 1 \\bigl({f_i(q ) \\le f_j(q ) } \\bigr ) . \\ ] ]    the discussion immediately following proposition  [ propositionall - consistency ] shows that any consistent surrogate @xmath71 must be bounded away from its minimum for @xmath366 .",
    "since the limiting distribution @xmath56 is a point mass at some adjacency matrix @xmath55 for each @xmath8 , a surrogate loss @xmath71 is consistent if and only if @xmath367 in the important special case when the difference graph @xmath368 associated with @xmath369 $ ] is a dag for each query @xmath8 ( recall section  [ seclow - noise - inconsistency ] ) , structure consistency is obtained if for each @xmath370 , @xmath371 for each pair of results @xmath372 . as an example , in this setting @xmath373_+ \\phi(\\alpha_i - \\alpha_j)\\ ] ] is consistent when @xmath145 is nonincreasing , convex , and has derivative @xmath210 .",
    "the fisher - consistent loss ( [ eqnpairwise - consistent ] ) is similar to the inconsistent losses ( [ eqnsurr - edge - loss ] ) considered in section  [ secconsistency - hard ] , but the coefficients adjoining each @xmath374 summand exhibit a key difference . while the inconsistent losses employ coefficients based solely on the average @xmath375 weight @xmath376 , the consistent loss coefficients are nonlinear functions of the edge weight differences @xmath377 : they are precisely the edge weights of the difference graph @xmath368 introduced section  [ seclow - noise - inconsistency ] . since at least one of the two coefficients @xmath378_+$ ] and",
    "@xmath379_+$ ] is always zero , the loss ( [ eqnpairwise - consistent ] ) penalizes misordering either edge @xmath380 or @xmath381 .",
    "this contrasts with the inconsistent surrogates of section  [ secconsistency - hard ] , which simultaneously associate nonzero convex losses with opposing edges @xmath382 and @xmath381 .",
    "note also that our argument for the consistency of the loss ( [ eqnpairwise - consistent ] ) does not require definition  [ defrev - triangle ] s low - noise assumption : consistency holds under the weaker condition that , on average , a population s preferences are acyclic .",
    "in this section , we describe strategies for solving the convex programs that emerge from our aggregation approach to ranking and demonstrate the empirical utility of our proposed procedures .",
    "we begin with a broad description of implementation strategies and end with a presentation of specific experiments .      at first glance",
    ", the empirical risk ( [ eqnu - statistic - emprisk ] ) appears difficult to minimize , since the number of terms grows exponentially in the level of aggregation @xmath42 .",
    "fortunately , we may leverage techniques from the stochastic optimization literature @xcite to minimize the risk ( [ eqnu - statistic - emprisk ] ) in time linear in @xmath42 and independent of @xmath187 .",
    "let us consider minimizing a function of the form @xmath383 where @xmath384 is some collection of data , @xmath385 is convex in its first argument , and @xmath386 is a convex regularizing function ( possibly zero ) .",
    "duchi and singer @xcite , using ideas similar to those of nemirovski et  al .",
    "@xcite , develop a specialized stochastic gradient descent method for minimizing composite objectives of the form ( [ eqnstochastic - objective ] ) .",
    "such methods maintain a parameter @xmath387 , which is assumed to live in convex subset @xmath274 of a hilbert space with inner product @xmath388 , and iteratively update @xmath387 as follows . at iteration @xmath389 ,",
    "an index @xmath390 $ ] is chosen uniformly at random and the gradient @xmath391 is computed at @xmath387 .",
    "the parameter @xmath10 is then updated via @xmath392 where @xmath393 is an iteration - dependent stepsize and @xmath245 denotes the hilbert norm .",
    "the convergence guarantees of the update ( [ eqnfobos - update ] ) are well understood @xcite . define @xmath394 to be the average parameter after @xmath395 iterations .",
    "if the function @xmath396 is strongly convex  meaning it has at least quadratic curvature  the step - size choice @xmath397 gives @xmath398 - \\inf_{f \\in\\funclass } \\emprisk_n(f ) = \\order \\biggl ( \\frac{1}{t } \\biggr),\\ ] ] where the expectation is taken with respect to the indices @xmath399 chosen during each iteration of the algorithm . in the convex case ( without assuming any stronger properties than convexity ) , the step - size choice @xmath400 yields @xmath398 - \\inf_{f \\in\\funclass } \\emprisk_n(f ) = \\order \\biggl ( \\frac{1}{\\sqrt{t } } \\biggr).\\ ] ] these guarantees also hold with high probability @xcite .",
    "neither of the convergence rates @xmath401 or @xmath402 depends on the number of terms @xmath253 in the stochastic objective ( [ eqnstochastic - objective ] ) . as a consequence",
    ", we can apply the composite stochastic gradient method ( [ eqnfobos - update ] ) directly to the empirical risk ( [ eqnu - statistic - emprisk ] ) : we sample a query @xmath8 with probability @xmath403 , after which we uniformly sample one of the @xmath404 collections @xmath405 of @xmath42 indices associated with query @xmath8 , and we then perform the gradient update ( [ eqnfobos - update ] ) using the gradient sample @xmath406 .",
    "this stochastic gradient scheme means that we can minimize the empirical risk in a number of iterations independent of both @xmath187 and @xmath42 ; the run - time behavior of the method scales independently of @xmath187 and depends on @xmath42 only so much as computing an instantaneous gradient @xmath407 increases with @xmath42 .     and",
    "@xmath187 when applying the method ( [ eqnfobos - update ] ) .",
    "the horizontal axes are the number of stochastic gradient iterations ; the vertical axes are the estimated optimality gap for the empirical surrogate risk . left : varying amount of aggregation @xmath42 , fixed @xmath408 . right : varying total number of samples @xmath187 , fixed @xmath409 . ]    in figure  [ figtiming ] , we show empirical evidence that the stochastic method ( [ eqnfobos - update ] ) works as described . in particular , we minimize the empirical @xmath0-statistic - based risk ( [ eqnu - statistic - emprisk ] ) with the loss ( [ eqnregression - loss ] ) we employ in our experiments in the next section . in each plot in figure  [ figtiming ] , we give an estimated optimality gap , @xmath410 , as a function of @xmath389 , the number of iterations . as in the section to follow , @xmath252 consists of linear functionals parameterized by a vector @xmath411 with @xmath412 . to estimate @xmath413",
    ", we perform 100,000 updates of the procedure ( [ eqnfobos - update ] ) , then estimate @xmath414 using the output predictor @xmath415 evaluated on an additional ( independent ) 50,000 samples ( the number of terms in the true objective is too large to evaluate ) . to estimate the risk @xmath416 , we use a moving average of the previous 100 sampled losses @xmath417 for @xmath418 , which is an unbiased estimate of an upper bound on the empirical risk @xmath419 ( see , e.g. , @xcite ) .",
    "we perform the experiment 20 times and plot averages as well as 90% confidence intervals . as predicted by our theoretical results ,",
    "the number of iterations to attain a particular accuracy is essentially independent of @xmath187 and @xmath42 ; all the plots lie on one another .      to perform our experimental evaluation",
    ", we use a subset of the microsoft learning to rank web10k dataset @xcite , which consists of 10,000 web searches ( queries ) issued to the microsoft bing search engine , a set of approximately 100 potential results for each query , and a relevance score @xmath420 associated with each query / result pair .",
    "a query / result pair is represented by a @xmath412-dimensional feature vector of standard document - retrieval features .    to understand the benefits of aggregation and consistency in the presence of partial preference data , we generate pairwise data from the observed query / result pairs , so that we know the true asymptotic generating distribution .",
    "we adopt a loss @xmath27 from the ndcg - family ( [ eqnndcg ] ) and compare three surrogate losses : a fisher - consistent regression surrogate based on aggregation , an inconsistent but commonly used pairwise logistic loss @xcite , and a fisher - consistent loss that requires access to complete preference data @xcite . recalling the ndcg score ( [ eqnndcg ] ) of a prediction vector @xmath421 for scores @xmath422 ( where @xmath162 is the permutation induced by  @xmath37 )",
    ", we have the loss @xmath423 where @xmath424 is the normalizing value for the ndcg score , and @xmath425 and @xmath426 are increasing functions .",
    "given a set of queries @xmath8 and relevance scores @xmath427 , we generate @xmath187 pairwise preference observations according to a bradley  terry ",
    "luce ( btl ) model @xcite .",
    "that is , for each observation , we choose a query @xmath8 uniformly at random and then select a uniformly random pair @xmath428 of results to compare .",
    "the pair is ordered as @xmath429 ( item @xmath18 is preferred to @xmath16 ) with probability @xmath430 , and @xmath431 with probability @xmath432 , where @xmath433 for @xmath434 and @xmath435 the respective relevances of results @xmath18 and @xmath16 under query @xmath8 .",
    "we define our structure functions @xmath436 as score vectors in @xmath102 , where given a set of @xmath42 preference pairs , the score for item @xmath18 is @xmath437 the average empirical log - odds of result @xmath18 being preferred to any other result . under the btl model ( [ eqnlogistic - pairwise - sampling ] ) , as @xmath438 the structural score converges foreach @xmath439 $ ] to @xmath440 .",
    "\\label{eqnexperiment - limiting - score}\\ ] ] in our setting , we may thus evaluate the asymptotic ndcg risk of a scoring function @xmath10 by computing the asymptotic scores ( [ eqnexperiment - limiting - score ] ) .",
    "in addition , corollary  [ corollaryndcg - consistency ] shows that if all minimizers of a loss obey the ordering of the values @xmath441 then the loss is fisher - consistent . a well - known example @xcite of",
    "such a loss is the least - squares loss , where the regression labels are @xmath442 : @xmath443 we compare the least - squares aggregation loss with a pairwise logistic loss natural for the pairwise data generated according to the btl model ( [ eqnlogistic - pairwise - sampling ] ) . specifically , given a data pair with @xmath429 , the logistic surrogate loss is @xmath444 which is equivalent or similar to previous losses used for pairwise data in the ranking literature @xcite . for completeness",
    ", we also compare with a fisher - consistent surrogate that requires access to complete preference information in the form of the asymptotic structure scores ( [ eqnexperiment - limiting - score ] ) .",
    "following ravikumar et  al .",
    "@xcite , we obtain such a surrogate by granting the regression loss ( [ eqnregression - loss ] ) direct access to the asymptotic structure scores .",
    "note that such a construction would be infeasible in any true pairwise data setting .",
    "having described our sampling procedure , aggregation strategy , and loss functions , we now describe our model .",
    "we let @xmath445 denote the feature vector for the @xmath18th result from query @xmath8 , and we model the scoring function @xmath446 for a vector @xmath447 . for the regression loss ( [ eqnregression - loss ] ) , we minimize the @xmath0-statistic - based empirical risk ( [ eqnu - statistic - emprisk ] ) over a variety of orders @xmath42 , while for the pairwise logistic loss  ( [ eqnlogistic - loss ] ) , we minimize the empirical risk over all pairs sampled according to the btl model  ( [ eqnlogistic - pairwise - sampling ] ) .",
    "we regularize our estimates by adding @xmath448 to the objective minimized , and we use the specialized stochastic method ( [ eqnfobos - update ] ) to minimize the empirical risk .",
    "estimated using the logistic pairwise loss  ( [ eqnlogistic - loss ] ) and the @xmath0-statistic empirical risk with @xmath71 chosen to be regression loss ( [ eqnregression - loss ] ) . the horizontal axis of each plot is the order @xmath42 of the aggregation in the @xmath0-statistic ( [ eqnu - statistic - emprisk ] ) , the vertical axis is the ndcg risk , and each plot corresponds to a different number @xmath187 of samples . @xmath449 ; @xmath450 ; @xmath451 ; @xmath452 . ]",
    "estimated using the @xmath0-statistic empirical risk  ( [ eqnu - statistic - emprisk ] ) with @xmath71 chosen as the regression loss ( [ eqnregression - loss ] ) under various choices of the regularization parameter , @xmath453 . ]",
    "our goals in the experiments are to understand the behavior of the empirical risk minimizer as the order @xmath42 of the aggregating statistic is varied and to evaluate the extent to which aggregation improves the estimated scoring function .",
    "a secondary concern is to verify that the method is insensitive to the amount @xmath453 of regularization performed on @xmath454 .",
    "we run each experiment 50 times and report confidence intervals based on those 50 experiments .",
    "let @xmath455 denote the estimate of @xmath454 obtained from minimizing the empirical risk  ( [ eqnu - statistic - emprisk ] ) with the regression loss ( [ eqnregression - loss ] ) on @xmath187 samples with aggregation order @xmath42 , let @xmath456 denote the estimate of @xmath454 obtained from minimizing the empirical pairwise logistic loss ( [ eqnlogistic - loss ] ) , and let @xmath457 denote the estimate of @xmath454 obtained from minimizing the empirical risk with surrogate loss ( [ eqnregression - loss ] ) using the asymptotic structure scores  ( [ eqnexperiment - limiting - score ] ) directly . then",
    "each plot of figure  [ figk - orders ] displays the risk @xmath458 as a function of the aggregation order @xmath42 , using @xmath459 and @xmath460 as references .",
    "the four plots in the figure correspond to different numbers @xmath187 of data pairs .",
    "broadly , the four plots in figure  [ figk - orders ] match our theoretical results .",
    "consistently across the plots , we see that for small @xmath42 , it appears there is not sufficient aggregation in the regression - loss - based empirical risk , and for such small @xmath42 the pairwise logistic loss is better",
    ". however , as the order of aggregation @xmath42 grows , the risk performance of @xmath461 improves .",
    "in addition , with larger sample sizes @xmath187 , the difference between the risk of @xmath456 and @xmath455 becomes more pronounced .",
    "the second salient feature of the plots is a moderate flattening of the risk @xmath458 and widening of the confidence interval for large values of @xmath42 .",
    "this seems consistent with the estimation error guarantees in the theoretical results in lemmas  7 and  10 in the appendices , where the order @xmath42 being large has an evidently detrimental effect .",
    "interestingly , however , large values of @xmath42 still yield significant improvements over @xmath462 .",
    "for very large @xmath42 , the improved performance of @xmath455 over @xmath457 is a consequence of sampling artifacts and the fact that we use a finite dimensional representation .",
    "[ by using sufficiently many dimensions @xmath463 , the estimator @xmath457 attains zero risk by matching the asymptotic scores ( [ eqnexperiment - limiting - score ] ) directly . ]",
    "figure  [ figlambda - size ] displays the risk @xmath458 for @xmath464 pairs , @xmath465 , and multiple values of the regularization multiplier @xmath453 on @xmath466 .",
    "the results , which are consistent across many choices of @xmath187 , suggest that minimization of the aggregated empirical risk ( [ eqnu - statistic - emprisk ] ) is robust to the choice of regularization multiplier .",
    "in this paper , we demonstrated both the difficulty and the feasibility of designing consistent , practicable procedures for ranking . by giving necessary and sufficient conditions for the fisher consistency of ranking algorithms",
    ", we proved that many natural ranking procedures based on surrogate losses are inconsistent , even in low - noise settings . to address this inconsistency",
    "while accommodating the incomplete nature of typical ranking data , we proposed a new family of surrogate losses , based on @xmath0-statistics , that aggregate disparate partial preferences .",
    "we showed how our losses can fruitfully leverage any well behaved rank aggregation procedure and demonstrated their empirical benefits over more standard surrogates in a series of ranking experiments .",
    "our work thus takes a step toward bringing the consistency literature for ranking in line with that for classification , and we anticipate several directions of further development .",
    "first , it would be interesting to formulate low - noise conditions under which faster rates of convergence are possible for ranking risk minimization ( see , e.g. , the work of @xcite , which focuses on the minimization of a single pairwise loss ) .",
    "additionally , it may be interesting to study structure functions @xmath55 that yield nonpoint distributions @xmath56 as the number of arguments @xmath42 grows to infinity .",
    "for example , would scaling the thurstone  mosteller least - squares solutions ( [ eqnskew - symmetric - score ] ) by @xmath467to achieve asymptotic normality ",
    "induce greater robustness in the empirical minimizer of the @xmath0-statistic risk ( [ eqnu - statistic - emprisk ] ) ?",
    "finally , exploring tractable formulations of other supervised learning problems in which label data is naturally incomplete could be fruitful .",
    "we thank the anonymous reviewers and the associate editor for their helpful comments and valuable feedback ."
  ],
  "abstract_text": [
    "<S> we consider the predictive problem of supervised ranking , where the task is to rank sets of candidate items returned in response to queries . although there exist statistical procedures that come with guarantees of consistency in this setting </S>",
    "<S> , these procedures require that individuals provide a complete ranking of all items , which is rarely feasible in practice . </S>",
    "<S> instead , individuals routinely provide partial preference information , such as pairwise comparisons of items , and more practical approaches to ranking have aimed at modeling this partial preference data directly . </S>",
    "<S> as we show , however , such an approach raises serious theoretical challenges . </S>",
    "<S> indeed , we demonstrate that many commonly used surrogate losses for pairwise comparison data do not yield consistency ; surprisingly , we show inconsistency even in low - noise settings . with these negative results as motivation , we present a new approach to supervised ranking based on aggregation of partial preferences , and we develop @xmath0-statistic - based empirical risk minimization procedures . </S>",
    "<S> we present an asymptotic analysis of these new procedures , showing that they yield consistency results that parallel those available for classification . </S>",
    "<S> we complement our theoretical results with an experiment studying the new procedures in a large - scale web - ranking task .    , </S>"
  ]
}