{
  "article_text": [
    "we present a sequential monte carlo @xcite algorithm for adaptive sampling from a binary distribution .",
    "a monte carlo algorithm is said to be adaptive if it adjusts , sequentially and automatically , its sampling distribution to the problem at hand .",
    "besides sequential monte carlo , important classes of adaptive monte carlo are adaptive importance sampling ( e.g. * ? ? ?",
    "* ) and adaptive markov chain monte carlo ( e.g. * ? ? ?",
    "a central aspect of adaptive algorithms is their need for a parametric family of auxiliary distributions which should have the following three properties : ( a ) the family is sufficiently flexible to guarantee a reasonable performance in the context of the specific algorithm ; ( b ) it allows to quickly draw independent samples ; ( c ) it can , with reasonable effort , be calibrated using past simulations .    for problems in continuous sampling spaces ,",
    "the typical example is the multivariate normal distribution , which clearly fulfils ( b ) and ( c ) , and complies with ( a ) in many practical problems . in this paper",
    ", we propose an analogue for high - dimensional binary sampling spaces .",
    "our objective is to construct a parametric family for sequential monte carlo on the binary sampling space @xmath0 , where @xmath1 is too large to allow for exhaustive enumeration of the whole space @xmath2 .",
    "since there is no multivariate binary family which we can easily parametrise by its first and second order moments like the multivariate normal , the construction of suitable proposal distributions seems more difficult for the discrete adaptive sampling problem than for its continuous counterpart .",
    "the major application for our algorithm is variable selection in linear regression models . in this context",
    ", a binary vector @xmath3 encodes whether each of @xmath1 possible covariates are included in the linear regression model or not . in a bayesian framework , and for a judicious choice of prior distributions",
    ", we can explicitly calculate the posterior distribution @xmath4 up to a constant .",
    "we want to sample from this distribution in order to approximate quantities like the expected value @xmath5 , that is the marginal probability of inclusion of each variable .",
    "often , the marginal probabilities provide a richer picture of the posterior distribution than a collection of modes found using stochastic optimisation techniques .",
    "our sequential monte carlo approach to variable selection views a well studied problem from a different angle and provides new perspectives .",
    "the reason is two - fold .",
    "firstly , there is growing evidence that global methods , which track a population of particles , initially well spread over the sampling space @xmath2 , are often more robust than local methods based on markov chain monte carlo .",
    "the latter are more prone to get trapped in the neighbourhood of local modes .",
    "we largely illustrate this effect in our simulations in section [ sec : simu ] .    secondly , global methods have the property to be easily parallelisable .",
    "parallel implementations of monte carlo algorithms have gained a tremendous interest in the very recent years @xcite , due to the increasing availability of multi - core ( central or graphical ) processing units in standard computers .",
    "the paper is organised as follows .    in section [ sec",
    ": var sel ] , we recapitulate the basics of bayesian variable selection in linear regression models as the motivating application .    in section [ sec : mcmc ] , we briefly review the principal markov chain monte carlo methods which are commonly used to integrate with respect to a binary distributions .    in section [ sec :",
    "smc ] , we describe an alternative approach to the same problem using sequential monte carlo methods .",
    "the key ingredient of this algorithm is a parametric family which is flexible enough to come close to the target distribution .    in section [ sec : bv ] , we extensively discuss approaches for constructing rich parametric families on binary spaces .",
    "this is the core of our work .",
    "some of the binary models discussed are not suitable in the framework of our sequential monte carlo algorithm but mentioned for completeness of the survey .    in section [ sec : simu ] , we construct two examples of variable selection problems which yield challenging posterior distributions . we show that standard markov chain techniques fail to produce reliable estimates of the marginal probabilities while our sequential monte carlo approach successfully copes with the integration problem .",
    "[ [ notation ] ] notation + + + + + + + +    for a vector @xmath6 , we write @xmath7 for the sub - vector indexed by @xmath8 . we write @xmath9 if the indices are a complete sequence @xmath10 .",
    "we denote by @xmath11 the sub - vector @xmath12 .",
    "we write @xmath13 for @xmath14 .    for a matrix @xmath15 , we denote its components by @xmath16 , its determinant by @xmath17 .",
    "the operator @xmath18 transforms the vector @xmath19 into a diagonal matrix . for a finite set @xmath20 ,",
    "we denote by @xmath21 the number of elements in @xmath20 .",
    "the standard linear normal model postulates that the relationship between the observed explained variable @xmath22 and the observations @xmath23\\in\\r^{m , d}$ ] is @xmath24 here , @xmath25 is a vector of regression coefficients and @xmath26 the variance of @xmath27 .",
    "we denote by @xmath28 the identity matrix and assume the first column @xmath29 to be constant .",
    "the parameter @xmath30 determines which covariates are included in or dropped from the linear regression model . in total",
    ", we can construct @xmath31 different linear normal models from the data .",
    "we assign a prior distribution @xmath32 to the parameters . from the posterior distribution @xmath33",
    "we may compute the posterior probability of each model @xmath34 by integrating out the parameters @xmath35 and @xmath26 .",
    "[ [ sec : hb ] ] hierarchical bayesian model + + + + + + + + + + + + + + + + + + + + + + + + + + +    in a purely bayesian context , we obtain , up to a constant , an explicit formula for the integral in by choosing conjugate hierarchical priors , that is a normal @xmath36 and an inverse - gamma @xmath37 . for all bayesian posterior distributions in this paper ,",
    "we use the prior distributions @xmath38 where @xmath39 denote an inverse - gamma and @xmath40 a uniform law .    for our numerical examples in section [ sec : simu ] , we assume not to have any prior information about the data . we follow the recommendations of @xcite and choose the hyper - parameters @xmath41 where @xmath42 is the least square estimate of @xmath26 based on the saturated model .",
    "the rationale behind this choice is to have a flat prior on @xmath25 and provide @xmath26 with sufficient mass on the interval @xmath43 , where @xmath44 denotes the variance of @xmath27 .",
    "next , we quickly state the form of the log - posterior mass function .",
    "we write @xmath45 for @xmath46 without zero columns .",
    "let @xmath47 and @xmath48 a cholesky decomposition .",
    "we denote the least square estimate of @xmath26 based on @xmath49 and the model @xmath50 by @xmath51 we find the log - posterior probability to be @xmath52 where @xmath53 is an unknown normalization constant .    [ [ related - approaches ] ] related approaches + + + + + + + + + + + + + + + + + +    in a frequentist framework , we choose a model which minimizes some specified criterion . a popular one is schwarz s criterion ( * ? ? ?",
    "* also bayesian information criterion ) which basically is a second degree laplace approximation of : @xmath54 where @xmath55 is the maximum likelihood estimator of @xmath26 based on the model @xmath56 .",
    "note that for a large sample size @xmath57 the hierarchical bayesian approach and the bayesian information criterion coincide .",
    "[ [ alternative - approaches ] ] alternative approaches + + + + + + + + + + + + + + + + + + + + + +    the posterior of a bayesian linear regression variable selection problem has , in general , no particular structure we can exploit to speed up optimisation or integration with respect to @xmath4 . therefore , alternative approaches such as the least absolute shrinkage and selection operator @xcite have been proposed which draw from the theory of convex optimization and allow for computation of larger problems .    while a comparison between competing approaches to variable selection is beyond the scope of this paper , we remark that more sophisticated , parallelisable algorithms are essential for making bayesian modelling feasible in the context of high dimensional problems where alternative methods are often used for practical reasons only .",
    "markov chain monte carlo is a well - studied approach to approximate the expected value of a posterior @xmath4 given by a bayesian model choice problem @xcite . in this section",
    ", we rapidly review the standard methods we are going to compare our sequential monte carlo approach against .",
    "there are more advanced markov chain monte carlo algorithms that use parallel tempering ideas combined with more elaborate local moves ( see e.g. * ? ? ?",
    "* ; * ? ? ?",
    "* ) , but a thorough comparison is beyond the scope of this paper . for background on markov chain monte carlo methods ,",
    "we refer to standard literature ( see e.g. * ? ? ?",
    "the idea is to construct a transition kernel @xmath58 , typically some version of a metropolis - hastings kernel , which admits @xmath4 as unique stationary distribution .",
    "then , the distribution of the markov chain @xmath59 started at some randomly chosen point @xmath60 converges to @xmath4 .",
    "we obtain an estimate @xmath61 for the expected value via the ergodic theorems for markov chains .",
    "the first @xmath62 states are usually discarded to give the chain some time to converge towards the stationary distribution before we start to average . for the estimate to be valid , we need to ensure that the at time @xmath62 the chain is close to its stationary distribution @xmath4 , and at time @xmath63 we have sampled an ergodic trajectory such that the ergodic theorems applies .",
    "classic markov chain methods on binary spaces work locally , that is they propose moves to neighbouring models in the metropolis - hastings steps .",
    "a neighbouring model is a copy of the current model where just a few components are altered .",
    "we shall see that these kinds of transition kernels often fail to sample ergodic trajectories within a reasonable amount of time if the stationary distribution @xmath4 is very multi - modal .",
    "[ [ algorithm ] ] algorithm + + + + + + + + +    we loop over a uniformly drawn subset of components @xmath64 and propose to change the components @xmath65 . the number of components @xmath66 might be fixed or drawn from some distribution @xmath67 on the index set @xmath68 .",
    "precisely , we take a copy @xmath27 of the current state @xmath69 and replace @xmath70 by @xmath71 for all @xmath65 , where @xmath72 is a bernoulli distribution with parameter @xmath73 .",
    "we set @xmath74 with probability @xmath75 and @xmath76 otherwise .",
    "this framework , summarized in algorithm [ algo : generic mg ] , yields a markov chain with unique invariant distribution @xmath4 for any fixed @xmath77 .",
    "the interesting special cases , however , use a @xmath78 which depends on the current state of the chain",
    ".    @xmath79 @xmath80),\\ k\\sim \\mathcal{g}_{k^*}$ ] @xmath64 @xmath81 * for * @xmath65 * do * @xmath82 + * if * @xmath83 * then * @xmath84 + @xmath19    [ [ performance ] ] performance + + + + + + + + + + +    we refer to the ratio as the acceptance probability of the metropolis - hastings step . in binary spaces , however , accepting a proposal does not imply we are changing the state of the chain , since we are likely to re - propose the current state @xmath85 .",
    "we are actually interested in how fast the chain explores the state spaces , precisely its mutation probability @xmath86 .      for this section ,",
    "let @xmath87 be constant .",
    "algorithm [ algo : generic mg ] collapses to changing a single component . instead of independently drawing the index @xmath88 , we could also iterate @xmath89 through a uniformly drawn permutations @xmath90 of the index set @xmath68 .",
    "kernels of this kind are often referred to as metropolised gibbs samplers , since they proceed component - wise as does the classical gibbs sampler , but also involve a metropolishastings step . in the sequel",
    ", we discuss some special cases .",
    "[ [ classical - gibbs ] ] classical gibbs + + + + + + + + + + + + + + +    the gibbs sampler sequentially draws each component from the full marginal distribution , which corresponds to @xmath91 by construction , the acceptance probability is @xmath92 while the mutation probability is only @xmath93 , where @xmath27 is a copy of the current state @xmath69 with component @xmath89 altered .    [ [ adaptive - metropolised - gibbs ] ] adaptive metropolised gibbs + + + + + + + + + + + + + + + + + + + + + + + + + + +    an adaptive extension of the metropolised gibbs has been proposed by @xcite .",
    "the full marginal distribution @xmath94 is approximated by a linear predictor . in their notation , @xmath95 where @xmath96 is the estimated mean , @xmath97 the estimated covariance matrix and @xmath98 a design parameter which ensures that @xmath99 is a probability .",
    "analogously to our vector notation , @xmath100 denotes the matrix @xmath101 without the @xmath89th row and column .",
    "we obtain the estimates from the past trajectory of the chain @xmath102 and update them periodically .",
    "the mutation probability is of the same order as that of the gibbs kernel , but adaption largely avoids the computationally expensive evaluations of @xmath4 .",
    "the non - adaptive gibbs sampler already requires evaluation of @xmath103 just to produce the proposal @xmath27 .",
    "in contrast , the adaptive metropolised gibbs samples from a proxy and only evaluates @xmath103 if @xmath104 .",
    "[ [ modified - metropolised - gibbs ] ] modified metropolised gibbs + + + + + + + + + + + + + + + + + + + + + + + + + + +    in comparison to the classical gibbs kernel , we obtain a more efficient chain @xcite using the simple form @xmath105 since we always propose to change the current state , the acceptance and mutation probabilities are the same",
    ". they amount to @xmath106 , where @xmath27 is a copy of the current state @xmath19 with component @xmath89 altered . comparing the mutation probabilities of the two kernels , we see that the modified metropolised gibbs chain moves , on average , faster than the classical gibbs chain .",
    "the modified metropolised gibbs easily generalises to the case where @xmath66 may take values larger than one .",
    "suppose , for example , we propose to change @xmath107 components simultaneously , where @xmath108 is a truncated geometric distribution .",
    "note that we suggest , on average , to change approximately @xmath109 components .",
    "in other words , for larger values of @xmath109 , we are more likely to propose further steps in the sampling space .",
    "large step proposals improve the mixing properties of the chain and help to escape from the attraction of local modes .",
    "they are , however , less likely to be accepted than single component steps which leads to a problem - dependent trade - off . in our numerical examples , we could not observe any benefit from block updating , and we do not further consider it to keep the comparison with our sequential monte carlo method more concise .      we can construct a fast mixing markov chain based on independent proposals . let @xmath110 be some distribution with @xmath111 , that is @xmath112 for all @xmath113 .",
    "we propose a new state @xmath114 and accept it with probability @xmath115 the associated markov chain has the unique invariant measure @xmath4 .",
    "this kernel is referred to as the independent metropolis - hastings kernel , since the proposal distribution is not a function of the current state @xmath69 .",
    "the mutation rate is the acceptance rate minus @xmath116 , so the two notions practically coincide in large spaces .",
    "obviously , in order to make this approach work , we need to choose @xmath110 sufficiently close to @xmath4 , which implies high acceptance rates on average . in absence of reliable prior information , however , we are not able to produce such a distribution @xmath110 .",
    "we shall , however , use precisely this markov kernel as part of our sequential monte carlo algorithm . in this context",
    ", we can calibrate sequences @xmath117 of proposal distributions to be close to our current particle approximation .",
    "in this section , we show how to estimate the expected value with respect to a probability mass function @xmath118 defined on @xmath2 using sequential monte carlo @xcite . this general class of algorithms alternates importance sampling steps , resampling steps and markov chain transitions , to recursively approximate a sequence of distributions , using a set of weighted ` particles ' which represent the current distribution . in the following , we present a version which is tailored to work on binary spaces .    for readers not familiar with sequential monte carlo , the following algorithm described might seem rather complex at first glance .",
    "we introduce the steps separately before we look at the complete algorithm .",
    "we give comprehensive instructions which correspond exactly to our implementation in order to make our results plausible and easily reproducible for the reader .",
    "the first ingredient of sequential monte carlo is a smooth sequence of distributions @xmath119 , which ends up at the distribution of interest @xmath120 .",
    "the intermediary distributions @xmath121 are purely instrumental : the idea is to depart from a distribution @xmath122 with broad support and to progress smoothly towards the distribution of interest @xmath4 .    [",
    "[ initial - distribution ] ] initial distribution + + + + + + + + + + + + + + + + + + + +    theoretically , we can use any @xmath122 with @xmath123 that can sample from as initial distribution .",
    "numerical experiments taught us , however , that premature adjustment of @xmath122 , for example using markov chain pilot runs , leads to faster but less robust algorithms .",
    "thus , in practice , we recommend the uniform distribution for its simplicity and reliability . therefore ,",
    "in the sequel , we let @xmath124 .    [",
    "[ intermediate - distributions ] ] intermediate distributions + + + + + + + + + + + + + + + + + + + + + + + + + +    we construct a smooth sequence of distributions by judicious choice of an associated real sequence @xmath125 increasing from zero to one .",
    "the most convenient and somewhat natural strategy is the geometric bridge @xcite @xmath126 alternatively , one could use a sequences of mixtures @xmath127 or , in a bayesian context , a sequences of posterior distributions where data is added as @xmath128 increases , that is @xmath129 see @xcite . in the following ,",
    "we use the geometric bridge for its computational simplicity and present a procedure to determine a suitable sequence @xmath125 .",
    "suppose we have already produced a sample @xmath130 of size @xmath131 from @xmath132 .",
    "we can roughly approximate @xmath121 by the empirical distribution @xmath133})\\,\\delta_{\\v x_k^{[\\,t-1]}}(\\v\\gamma),\\ ] ] where the corresponding importance function @xmath134 is @xmath135    note that @xmath136 is the step length at time @xmath137 . as we choose @xmath138 larger , that is @xmath121 further from @xmath132 , the weights become more uneven and the accuracy of the importance approximation deteriorates .",
    "@xmath139 * for all * @xmath140 @xmath141 * for all * @xmath140 @xmath142    if we repeat the weighting steps until we reach @xmath120 , we obtain a classical importance sampling estimate with instrumental distribution @xmath122 .",
    "the idea of the sequential monte carlo algorithm , however , is to control the weight degeneracy such that we can intersperse resample and move steps before loosing track of our particle approximation .",
    "[ [ effective - sample - size ] ] effective sample size + + + + + + + + + + + + + + + + + + + + +    we measure the weight degeneracy through the effective sample size criterion , see @xcite .",
    "in our case , we have @xmath143.\\ ] ] the effective sample size is @xmath92 if all weights are equal and @xmath144 if all mass is concentrated in a single particle .    for a geometric bridge ,",
    "the effective sample size is merely a function of @xmath145 .",
    "we can thus control the weight degeneracy by judicious choice of the step lengths @xmath138 .",
    "we pick a step length @xmath145 such that the effective sample size @xmath146 equals a fixed value @xmath147 , see @xcite . since @xmath148 is continuous and monotonously increasing in @xmath145 ,",
    "we solve @xmath149 using bi - sectional search , see procedure [ algo : step ] .",
    "this approach is numerically more stable than a newton - raphson iteration , for the derivative @xmath150 involves fractions of sums of exponentials which are difficult to handle .",
    "let @xmath151 be the unique solution to .",
    "we can construct an associated sequence setting @xmath152 .",
    "thus , the number of steps @xmath153 depends on the complexity of the integration problem at hand and is not known in advance .    in other words , for fixed @xmath147 ,",
    "the associated sequence @xmath154 is a self - tuning parameter . in our simulations ,",
    "we always choose @xmath155 , which yields convincing results on both example problems in section [ sec : simu ] .",
    "smaller values significantly speed up the sequential monte carlo algorithm but lead to a higher variation in the results .    @xmath156",
    "* if * @xmath157 * then * @xmath158 * else * @xmath159 @xmath160      suppose we have a sample @xmath161 of size @xmath131 from @xmath132 with importance weights as defined in .",
    "we can obtain a sample @xmath162 which is approximately distributed according to @xmath121 by drawing from the empirical approximation defined in .",
    "@xmath163 * sample * @xmath164)$ ] @xmath165",
    "@xmath166 @xmath167    for the implementation of the resampling step , there exist several recipes .",
    "we could apply a multinomial resampling @xcite which is straightforward .",
    "there are , however , more efficient ways like residual @xcite , stratified @xcite and systematic resampling @xcite .",
    "we use the latest in our simulations , see procedure [ algo : resample ] .    in the resulting unweighted particle system @xmath168 of size",
    "@xmath131 , the particles with small weights have vanished while the particles with large weights have bee multiplied .",
    "there are approaches that resample a weighted particle system of size @xmath131 from an augmented system of size @xmath169 , see @xcite , but these techniques are computationally more demanding without visibly improving our numerical results .",
    "theoretically , one would expect a rao - blackwellisation effect but its analysis is beyond the scope of this paper .    in any case",
    ", if we repeat the weighting and resampling steps several times , we rapidly deplete our particle reservoir reducing the number of different particles to a very few .",
    "thus , the particle approximation will be totally inaccurate .",
    "the key to fighting the decay of our approximation is the following move step .",
    "the resampling step provides an unweighted particle system @xmath162 of @xmath121 containing multiple copies of many particles .",
    "the central idea of the sequential monte carlo algorithm is to diversify the resampled system , replacing the particles by draws from a markov kernel @xmath170 with invariant measure @xmath121 @xcite .",
    "since the particle @xmath171 is , approximately , distributed according to @xmath121 , a draw @xmath172 is again , approximately , distributed according to @xmath121 .",
    "we can repeat this procedure over and over without changing the target of the particle approximation .",
    "note that , even if the particles @xmath173 are equal after resampling , the particles @xmath174 are almost independent after sufficiently many move steps . in order to make the algorithm practical , however , we need a transition kernel which is rapidly mixing and therefore diversifies the particle system within a few steps . therefore , the locally operating markov kernels reviewed in section [ sec : mcmc ] are not suitable .",
    "in fact , our numerical experiments suggest that making a sequential monte carlo algorithm work with local kernels is practically impossible",
    ".    therefore , we use a metropolis - hastings kernel with independent proposals as described in section [ sec : ind mh ] .",
    "precisely , we construct a kernel @xmath170 employing a parametric family @xmath175 on @xmath2 which , for some @xmath176 , is sufficiently close to @xmath121 to allow for high acceptance probabilities .    for this purpose",
    ", we fit a parameter @xmath177 to the particle approximation @xmath178 of @xmath121 according to some convenient criterion .",
    "the choice of the parametric family @xmath175 is crucial to a successful implementation of the sequential monte carlo algorithm .",
    "we come back to this issue in section [ sec : bv ] .",
    "@xmath179 * sample * @xmath180 * for all * @xmath140 +   + @xmath181    [ [ particle - diversity ] ] particle diversity + + + + + + + + + + + + + + + + + +    we need to determine how often we move the particle system before we return to the weight - resample step .",
    "an easy criterion for the health of the particle approximation @xmath182 is its particle diversity @xmath183,\\ ] ] that is the proportion of distinct particles .",
    "note that the particle diversity is a quality criterion which has no simple analogue in continuous sampling spaces .    for optimal results",
    ", we recommend to keep on moving the particle system until the particle diversity can not be augmented any longer . in the first steps of the algorithm",
    ", @xmath121 is still close to the uniform distribution , and we manage to raise the particle diversity up to one . as @xmath121 is approaching a strongly multi - modal target distribution @xmath4 , however , the particle diversity reaches a steady - state we can not push it beyond .    clearly , even if we could draw a particle system independently from @xmath4 , the particle diversity would be a lot smaller than one , since we would draw the modes of @xmath4 several times .",
    "[ [ aggregated - weights ] ] aggregated weights + + + + + + + + + + + + + + + + + +    shifting weights between identical particles does not affect the nature of the approximation but it changes the effective sample size @xmath184 which seems paradoxical at first sight . for reasons of parsimoniousness , we could just keep a single representative @xmath185 for identical particles @xmath186 and aggregate the associated weights to the sum @xmath187 without changing the quality of the particle approximation .",
    "there are , however , three reasons why we refrain from doing so .",
    "firstly , it is vital not to confuse the weight disparity induced by reweighting according to the progression of @xmath121 and the weight disparity due to aggregation of the weights of multiply sampled states . from the aggregated system",
    ", we can not tell whether the effective sample size is determined by the gap between @xmath121 and @xmath188 , that is the step length @xmath145 , or by the presence of particle copies due to the mass of @xmath121 being very concentrated .",
    "therefore , it seems more difficult to control the smoothness of the sequence of distributions and find a suitable sequence @xmath125 .",
    "secondly , aggregation is an additional computational effort equivalent to keeping the particle system sorted . here",
    ", we trade in computing time for memory while the required memory is proportional to the number of particles and not critical in the context of our algorithm .",
    "thirdly , the straightforward way to implement repeated move steps is breaking up the particles into multiple copies corresponding to their weights and moving them separately .",
    "consequently , instead of permanently splitting and aggregating the weights we might just allow for multiple copies of the particles .      finally , we summarize the complete sequential monte carlo method in algorithm [ algo : smc ] .",
    "note that , in practice , the sequence @xmath189 is not indexed by @xmath137 but rather by @xmath190 , that is the counter @xmath137 is only given implicitly .",
    "* sample * @xmath191 * for all * @xmath140 .    [ cols= \"",
    "< , < , < \" , ]",
    "n.  chopin is supported by the anr grant anr-008-blan-0218 `` bigmc '' of the french ministry of research .",
    "we would like to thank pierre jacob and two anonymous referees for their valuable comments on this paper .",
    "we acknowledge the statlib data archive and the uci machine learning repository for providing the data sets used in this work ."
  ],
  "abstract_text": [
    "<S> a monte carlo algorithm is said to be adaptive if it automatically calibrates its current proposal distribution using past simulations . </S>",
    "<S> the choice of the parametric family that defines the set of proposal distributions is critical for good performance . in this paper </S>",
    "<S> , we present such a parametric family for adaptive sampling on high - dimensional binary spaces .    a practical motivation for this problem is variable selection in a linear regression context . </S>",
    "<S> we want to sample from a bayesian posterior distribution on the model space using an appropriate version of sequential monte carlo .    </S>",
    "<S> raw versions of sequential monte carlo are easily implemented using binary vectors with independent components . for high - dimensional problems , </S>",
    "<S> however , these simple proposals do not yield satisfactory results . </S>",
    "<S> the key to an efficient adaptive algorithm are binary parametric families which take correlations into account , analogously to the multivariate normal distribution on continuous spaces .    </S>",
    "<S> we provide a review of models for binary data and make one of them work in the context of sequential monte carlo sampling . </S>",
    "<S> computational studies on real life data with about a hundred covariates suggest that , on difficult instances , our sequential monte carlo approach clearly outperforms standard techniques based on markov chain exploration . </S>"
  ]
}