{
  "article_text": [
    "predicting the function of a protein is key to understanding life at a molecular level .",
    "conventionally , comparison of primary sequences of proteins has long been a widely - used method for detecting proteins that share a similar function and modeling phylogenetic trees [ 1 , 2 ]",
    ". however , sequence comparison alone is not purposive for detecting distant evolutionary connections between proteins , which may elucidate useful functional information [ 3 - 5 ] . sequence similarity , although simpler and more streamlined , is a far less accurate predictor of functional similarity than structure comparison , which is significantly more powerful for identifying cases where the evolutionary progress of the individual subject protein precludes the comparison of the protein sequences . investigating structural similarity is also functional for analyzing cases with insufficient sequence similarity [ 6 ] or identifying mutual functional protein sites and motifs [ 7 , 8 ] .",
    "-trypsin ( 1aks ) and flavodoxin ( 1akr ) . ]    -trypsin ( 1aks ) and flavodoxin ( 1akr ) . ]",
    "problems regarding similarity search also arise in many different applications in computer science , such as knowledge discovery and data mining ( kdd ) [ 9 ] , vector quantization , and pattern recognition and classification [ 10 ] .",
    "similarity search is not only fundamental to data science , but it also lies within problem domains in various other fields where data are not represented numerically , such as the statistical analysis of sets of molecular descriptors [ 11 ] , investigation of cross - generational mutative patterns [ 12 ] , and the representation of environmental sound waveform features [ 13 ] .",
    "+   + in the recent years , an explosion of newly discovered protein structures has been witnessed .",
    "consequently , the protein data bank ( pdb ) , the largest protein structure database available online , has come to surpass 110,000 structural entries , with an increase of around 7,000 in 2015 .",
    "as the amount of information in the pdb becomes overwhelmingly high , the need for methods to organize and classify structures for structure neighbor identification arises [ 14 ] .",
    "table [ scatter , x = year , y = ttl , col sep = comma , mark= ] pdb.csv ;    one method for the identification of structural neighbors is structural alignment , which attempts to discover similarity between two multiple protein structures based on their three - dimensional conformation . performing structural alignment between the subject protein and all other proteins in the protein data bank ( pdb ) via a structural alignment tool such as protein structure comparison by alignment of distance matrices ( dali ) [ 15 ] , flexible structure alignment by chaining aligned fragment pairs allowing twists ( fatcat ) [ 16 ] , or multiple alignment with translations and twists ( matt ) [ 17 ]",
    "can elucidate the discovery of the function of a protein of known structure but unknown function .",
    "+   + many methods evaluate similarity between structures of proteins via the comparison of @xmath0- or @xmath1-carbon coordinates of amino acids as a representation for the subject proteins . after the amino acids of subject proteins",
    "are paired , subject proteins are superimposed and the original similarity function is modified to obtain a final solution , often optimizing the distances between already paired amino acids while preserving the three - dimensional conformations of all subject proteins . the final solution is always quasi - optimal as the aforementioned problem has been proven , in principle , to be np - hard with no exact solution [ 18 ] .",
    "thus , it is possible to see the vast differences of heuristics and scoring criteria , as noted by mayr et al .",
    "( 2007 ) , in all protein structure alignment methods , which diversifies the so - called `` optimal '' solution for the structural alignment of a certain set of subject proteins [ 19 ] .",
    "one example of the heuristics used in alignment methods is the alternating approach to macromolecular docking : many existing methods [ 15 , 20 - 23 ] consider the subject proteins as rigid bodies , and attempt to minimize the deviation between the mapping of identified structures in all subject proteins while maximizing the number of mappings , describing the cumulative success in superimposition in terms of root mean square deviation ( rmsd ) : @xmath2 where @xmath3 is the distance between @xmath4 pairs of @xmath0- or @xmath1-carbon atoms . +   + menke et al .",
    "( 2008 ) showed that introducing flexibility to structural alignment would enable to align better with particularly marginal three - dimensional states ( the three - dimensional folding of a protein changes accordingly to the number , location , or character of ligands attached to it ) , which can not be achieved through rigid - body structural alignment . performing structural alignment while allowing a flexible - body conformational state with twists and translations",
    "also facilitates the management of pairwise distortions outside the stable backbone [ 17 ] .",
    "menke et al . ( 2008 ) also provided a pairwise structural alignment tool , namely multiple alignment with translations and twists ( matt ) , to demonstrate flexible - body structural alignment . nevertheless , flexible structural alignment is computationally more exhaustive than rigid - body structural alignment : menke et al .",
    "( 2008 ) reported that multiple alignment with translations and twists ( matt ) runs in @xmath5(@xmath6 log @xmath7 ) time [ 17 ] compared to @xmath5(@xmath6 ) during rigid - body structural alignment , reported by konagurthu et al .",
    "( 2006 ) [ 24 ] , where @xmath8 is the number of protein structures being aligned , and @xmath7 is the primary structure length of the longest protein included in the alignment [ 17 ] .",
    "it is important to note that for small values of @xmath7 , the discrepancy in running time is infinitesimal ; but the aforementioned increase in protein structures in the pdb and the discovery of proteins of unknown function demand more exhaustive alignments , which in turn makes the rigid - body approach more preferable .",
    "+   + looking at both commercialized and non - commercialized ( open - source ) pairwise and multiple structural alignment methods available , we report an arising problem in the daily use of these tools : given the need for better methods to detect structural neighbors to a newly - discovered protein , the current methods do not offer a starting point to the user in terms of proteins of similar structure .",
    "current methods take at least two protein structures as input , rendering the user optionless if the user has an unknown protein to which they would like to find structurally similar other proteins . in such a case ,",
    "an exhaustive search through the pdb is optimal , as demonstrated by holm et al .",
    "( 1993 ) [ 15 ] , and godzik et al .",
    "( 2004 ) [ 16 ] .",
    "given the high - order time complexity of structural alignment ,",
    "the running time of a full database search for a single query protein is too long to detect structurally similar proteins real - time ( an average running time of 20 minutes up to an hour for a single query [ 25 ] ) . protein structure database search methods available also assume a non - redundant library , neglecting the possibility of finding interesting structural and functional variability in newly discovered structures [ 26 ] .",
    "furthermore , these techniques can only be executed for annotated structures in the pdb , which hinders the potential use of structural alignment in determining the function of an unannotated protein that do not yet have a structural neighbor in the library .",
    "none of the pdb search methods available today do a complete and exhaustive search of the pdb , which is computationally expensive and demanding as it requires naive @xmath9 and @xmath10 comparisons ; furthermore , to our knowledge , no protein structure search and alignment tool that produces statistically significant flexible - body structural alignments using the database hits currently exists .",
    "+   + the aim of this study is establish a novel , robust , and accurate framework for protein structure database search and multiple structural alignment , through which we are able to search the entire protein data bank ( pdb ) to find structural homologs of an input protein , and conduct pairwise structural alignment with the nearest structural neighbors allowing flexibility in shape and sort the resultant structural neighbors in descending order of statistical significance .",
    "we also present a web - based database search and structural alignment tool with a dynamic user interface to actualize this approach .",
    "we build upon some techniques proposed by budowski - tal et al .",
    "( 2009 ) [ 27 ] and yu et al .",
    "( 2015 ) [ 28 ] , while genuinely optimizing both the database search and the structural alignment .",
    "+   + we approach the problem of searching the entire protein data bank in an efficient way using the `` filter and refine '' method [ 29 ] , where a computationally inexpensive search is conducted to choose a small set of potential structural neighbors , followed by a more exhaustive and demanding alignment technique . usually via the representation of structures as vectors in a @xmath8-dimensional hyperspace , techniques to search the pdb",
    "prove to be faster than raw structural alignment methods : namely , choi et al .",
    "( 2004 ) use distance matrices inside the structure as a vector representation of frequencies , and quantize similarity by computing the distance between each vector ( lff ) [ 30 ] ; rogen et al .",
    "( 2003 ) utilize and adapt knot theory in algebraic topology and homotopy theory to engineer the scaled gauss metric ( sgm ) , representing structures as a vector of 30 topological quantities [ 31 ] ; various techniques used a finite , orderly string of fragments , and consider the comparison and alignment of these vectors as a channel to detect structural similarity [ 32 - 34 ] .",
    "although these filter methods easily outperform single - channel rigid structural alignment in running time , they report accuracy benchmark classifications that easily favor using full structural alignment over filter and refine methods : lff , sgm , and pride2 by gaspari et al .",
    "( 2005 ) [ 34 ] report classification accuracies of 68.7% , 69.1% , and 48.4% respectively , benchmarked to the scop protein classification database [ 35 ] , which are easily outperformed by full ( both rigid - body and flexible ) structural alignment tools .",
    "we take a filter - and - refine method initially proposed by budowski - tal et al .",
    "( 2009 ) [ 27 ] , which represents objects as an unordered collections of local structural features , where the query is described as a vector of the occurrences of the structural motifs in the query protein backbone , as a starting point for a quick and accurate structural neighbor retrieval method .",
    "+   + our best filter method easily outperforms other filter - and - refine approaches , and , more importantly , full - body structural aligners such as dali [ 15 ] and fatcat [ 16 ] ; it can potentially be used to both efficiently , accurately , and rapidly identify good candidates of structural neighbors , and generate a set of potential structural neighbors for a protein with known structure and unknown function .",
    "we elaborate on the unordered vector space approach to protein structure similarity search proposed by budowski - tal et al .",
    "( 2009 ) , fragbag [ 27 ] , which expresses proteins as a collection of frequencies of structural features with no specific order .",
    "fragbag utilizes a non - redundant library of structural fragments and motifs within proteins in the protein data bank to collectively compute how similar two query proteins are , where the two query proteins are described as a collection of its contiguous structural fragments that overlap .",
    "the protein is then simply represented as a `` bag - of - fragments '' , which is a @xmath8-dimensional vector that holds the frequency of each contiguous overlapping structural fragment as a separate entry within the vector .",
    "( image ) at ( 0,0 ) -trypsin ( 1aks ) . after each unique contiguous backbone fragment of the query protein",
    "is identified , the occurrences @xmath11 of each segment is counted and put as entries in a @xmath8-dimensional query vector . for porcine @xmath0-trypsin ( 1aks ) , the resultant fragbag vector @xmath12 would have six non - zero dimensions : [ 3 , 1 , 3 , 6 , 11 , 1 ] .",
    "note that all 400(11 ) library fragbag vectors put in a high - dimensional vector space representative of the protein structure dataset @xmath13 are 400-dimensional ; yet , only the structures that are present in the backbone have a non - zero occurrence @xmath11.,title=\"fig:\",scaledwidth=60.0% ] ;    ( 0.87,0.7 ) ",
    "+ ( 0.1in,0.5in)node[anchor = west ] @xmath14 ; ( 0.58,0.6 )  + ( 0.8in,-0.7in)node[anchor = west ] @xmath15 ; ( 0.29,0.5 )  + ( -0.6in,-0.15in)node[anchor = east ] @xmath16 ; ( 0.40,0.1 ) ",
    "+ ( -0.6in,-0.1in)node[anchor = east ] @xmath17 ; ( 0.18,0.66 ) ",
    "+ ( -0.35in,0.55in)node[anchor = east ] @xmath18 ; ( 0.5,0.38 ) ",
    "+ ( 0.7in,-0.7in)node[anchor = north ] @xmath19 ;    ( 8,1.6 ) ( 2,0.8)@xmath20 $ ]    fragbag ultimately notes two benefits to representing a query protein in terms of its backbone segments :    * to implement a fast and efficient estimation of full database search of the protein data bank ; * for structure predictions where there is partial ( fragment - wise ) , albeit no complete structural similarity .    both of these aspects are favored in any approach to structural similarity ; yet , we provide conceptual and methodological motivation to select fragbag as a starting point over other filter - and - refine methods : namely , during the task of similarity search for structural neighbors in the high - dimensional vector space @xmath13 constructed by representative data points , as we widen our search radius , the vector space tends to not drastically increase , showing point density .",
    "this is to be elaborated later , particularly in ii.b .",
    "+   + fragbag remains to be the gold standard in filter - and - refine methods mimicking full - body structural aligners , identifying structural neighbors on a par with some state - of - the - art full - body structural aligners within the 400(11 ) non - redundant structural fragment library .",
    "budowski - tal et al .",
    "( 2009 ) reports robustly generated results from similar rankings with varying definitions of structural similarity , and report a cumulative success of identifying over 75% of true positive structural neighbors benchmarked to the scop classification database [ 27 ] in all distance metrics benchmarked , with a maximum score of 89% within the 400(11 ) non - redundant library .",
    "+      we generalize and justify a novel method that can be applied to not just similarity search within potential structural neighbors of a query protein but any kind of exhaustive search of -omics data .",
    "we approach the task of similarity search within the protein structure dataset by defining search performance in terms of the difference in novelty between new data and already existing data , _ entropy _ , hence the name `` entropy - based clustering '' .",
    "this approach enables the re - construction of the protein structure dataset , so that both the amount of time and space that the task of similarity search requires are linearly proportional to the entropy of the dataset , thus sublinearly proportional to the increase in size of the dataset itself .",
    "+   + we define two key elements of a dataset that will be vital to our approach : _ metric entropy _ and _ fractal dimension_. we provide rigorous definitions for both of the concepts in appendix a , but we are able to succinctly define metric entropy as describing the amount of dissimilarity a database appears to provide within itself , and fractal dimension as describing the relation between the number of clusters needed to cover all unique data points in a database and the respective radii of the clusters ( note that the concept of metric entropy is different from that of a distance metric , which is a measure of distance applicable to any database ) . via the analysis and generalization of these two elements of any database ,",
    "we show that if the database in question ( in our case , the protein structure database ) appears to exhibit asymptotically low metric entropy and fractal dimension , the method outperforms naive full - body structural alignments and heuristically optimized filter - and - refine methods .",
    "the main advantage of optimizing entropy - based clustering and similarity search using metric entropy and fractal dimension is that it allows for a mathematical , instead of an experimental , evaluation of the approach in terms of efficiency and accuracy .",
    "we also show that the entropy - based clustering approach results in zero loss in sensitivity .",
    "+   + the entropy - based similarity search is a quasi-@xmath8-means clustering algorithm , followed by an @xmath7-step hierarchical search that consists of four main steps .    1 .   exhaustively analyze the database entries and define a high - dimensional vector space @xmath13 , mapping each unique database entry onto unique points in this space @xmath13 .",
    "2 .   use this space @xmath13 and a quantized measure of similarity to group data points into clusters .",
    "3 .   to search for",
    "potential candidates , perform an initial search to identify the clusters that could possibly contain similar data points to the query .",
    "4 .   do a search within these clusters to find the closest data points to the query .",
    "we support this initial framework of hierarchical search by providing a conceptual supplemental rationale .",
    "we verbally approximate entropy as the vector distance between data points in this high - dimensional vector space @xmath13 ( protein structures represented as vectors ) ; hence , if @xmath13 exhibits low entropy , data points added to @xmath13 tend to not be distant from points already existing in @xmath13 .",
    "we quantize the distance between data points in @xmath13 using generic distance metrics : namely , euclidean and cosine distance : +   + for given queries @xmath21 and @xmath22 , the euclidean distance is : @xmath23 and the cosine distance is : @xmath24we experimentally evaluate both metrics in our process of creating a hierarchical clustering framework later .",
    "+   + many studies defined the protein data bank to be highly redundant [ 36 - 40 ] , but it is vital that we define what being redundant for the protein structure data set signifies .",
    "smith et al .",
    "( 2015 ) posited that many of the data points of protein structures may be exact duplicates ; that is , they may appear to have the same construction of representative vectors after the filter - and - refine method .",
    "this case can easily be solved by using a non - redundant library of proteins , as demonstrated by ye et al .",
    "( 2004 ) [ 16 ] .",
    "maybe the representative data points exist in only a minimal number of dimensions ; namely , showing low - dimensionality .",
    "if the dimension of the high - dimensional vector space is low enough , it can be divided into countable units , which would then ameliorate the running time for similarity searches .",
    "although it is important to note that for datasets where empty space fills the vector space so that data points are sparsely distributed , many empty cells will be included in the search , significantly increasing running time .",
    "furthermore , yu et al . (",
    "2015 ) noted that many biological datasets do not reside in low - dimensions ; instead , they arise from a highly chaotic high - dimensional vector space , properly characterized as a `` tree of life '' [ 28 ] . in these datasets , local low - dimensionality can be observed while the whole vector space is high - dimensional .",
    "this local low - dimensionality can be harnessed to search through specific regions of low - dimension with entropy - based similarity search .",
    ".,scaledwidth=50.0% ]    as seen in figure 2 , -omics data reside in high - dimensional vector spaces , but given a coarse scale to observe in this high - dimensional space , the density and the distribution of the representative data points are almost unidimensional . it is important to note that , based on the aforementioned succinct definition of fractal dimension , the high - dimensional vector space @xmath13 exhibits low local fractal dimension within the blue circles around the green query , and high fractal dimension within the red circles around the orange query .",
    "the blue circles around the green query point illustrate low fractal dimension : the larger - radius circle contains only linearly more points than the smaller one , rather than exponentially more .",
    "in contrast , the red circles around the orange query point illustrate higher local fractal dimension .",
    "+   + approaching this juxtaposition of different amounts of dimensionality in the same database , we may be able to exploit the local and global discrepancy : using a wide enough search radius , the entropy - based approach assumes a unidimensional space , and as the search radius is reduced , we can gradually start to consider the branches of high - dimensionality . for this high - dimensional vector space @xmath13 , we assume a coverage with spheres with radius @xmath25 , where @xmath25 is equals the low - dimensional branch width in question , and @xmath26 where @xmath27 is the metric entropy of the high - dimensional vector space @xmath13 and @xmath28 is the number of spheres needed to cover @xmath13 .",
    "+ we note that by the use of a spherical cluster , we assume that the points on this high - dimensional vector space @xmath13 are very close , thus can be encoded in terms of one another , which is in parallel with the aforementioned redundancy in the protein data bank .",
    "thus , using the triangle inequality , we are able to search all points within @xmath29 by only looking at adjacent spheres with cluster centers within @xmath30 of the query . for a wide search radius",
    ", we see that the spheres needed to cover @xmath13 extend along a minimal number of dimensions : as the radius decreases , the depth of the sphere matters .",
    "we call this property of local low - dimensionality the fractal dimension @xmath31 of the high - dimensional vector space @xmath13 at the radius scale @xmath25",
    ". local fractal dimension @xmath31 in @xmath13 is computed via the increase between radii @xmath32 and @xmath33 over the points added to @xmath34 , let us call these new points @xmath35 and previous points @xmath36 , by the increase in radii .",
    "the local fractal dimension is then simply : @xmath37 intuitively , we note that when @xmath38 , the number of points added to the sphere @xmath34 is linear to the increase in radii , thus , our approach is maximally efficient when the fractal dimension @xmath31 and metric entropy @xmath8 is minimal .",
    "( 2015 ) reports @xmath39 for average local fractal dimension of fragbag vectors [ 28 ] , thus providing a rationale to investigate our approach over the protein structure high - dimensional vector space .",
    "when we search in a wider radius around a query , the number of points added to the spherical cluster covering the points around the query within the radius grows exponentially with the fractal dimension ; implying that this growth will not hinder the efficiency provided by an entropy - based search .",
    "we provide a rigorous investigation in appendix a : theoretical foundations that given a high - dimensional vector space @xmath13 with a fractal dimension @xmath31 , an entropy @xmath8 , and an initial search radius @xmath40 , the time complexity @xmath41 of the entropy - based similarity search is @xmath42 which is asymptotically linear to @xmath8 with minimal values of output size and fractal dimension .",
    "when the problem involves comparing properties of a data point to one another , the most straightforward way to reduce computational expense is to cluster already existing data points in the database prior to the search . to reduce the running time for a query as much as possible , we used hierarchical divisive clustering as it offers a complexity reduction from @xmath9 to @xmath43log @xmath44 for query search . the goal of our approach is to balance the computational expense on both sides ; for a reduction from @xmath9 to @xmath43log @xmath44 for query search compensates for @xmath45 on our side since the user can withstand much less computational burden . +   +    0.5    table [ only marks , x = x , y = y , col sep = comma , mark= * ] co.csv ;       0.5    table [ only marks , black , x = x , y = y , col sep = comma , mark= * ] co.csv ; ( axis cs:46,33 ) circle ( 20 ) ; coordinates ( 46 , 33 ) ; coordinates    ( 46,33 ) ( 47,14 ) ( 50,50 ) ( 51,50 ) ( 53,25 ) ( 53,34 ) ( 59,29 ) ( 52,17 ) ( 27,36 ) ( 31,32 ) ( 32,43 ) ( 34,35 ) ( 38,30 ) ( 42,42 ) ( 45,19 )    ;    0.5    table [ only marks , x = x , y = y , col sep = comma , mark= * ] co.csv ; ( axis cs:46,33 ) circle ( 20 ) ; coordinates ( 46 , 33 ) ; coordinates ( 46,33 ) ( 47,14 ) ( 50,50 ) ( 51,50 ) ( 53,25 ) ( 53,34 ) ( 59,29 ) ( 52,17 ) ( 27,36 ) ( 31,32 ) ( 32,43 ) ( 34,35 ) ( 38,30 ) ( 42,42 ) ( 45,19 ) ; ( axis cs:32,56 ) circle ( 20 ) ; coordinates ( 32 , 56 ) ; coordinates ( 18,65 ) ( 22,69 ) ( 25,70 ) ( 37,71 ) ( 17,51 ) ( 16,88 ) ( 22,93 ) ( 32,56 ) ( 34,58 ) ( 34,55 ) ( 14,66 ) ( 14,69 ) ( 26,40 ) ( 17,43 ) ( 41,54 ) ( 41,62 ) ( 17,43 ) ; ( axis cs:87,20 ) circle ( 20 ) ; coordinates ( 87 , 20 ) ; coordinates ( 82,4 ) ( 85,5 ) ( 89,5 ) ( 85,11 ) ( 84,14 ) ( 88,14 ) ( 86,17 ) ( 87,20 ) ( 75,6 ) ( 75,16 ) ( 70,13 ) ( 76,23 ) ( 71,31 ) ( 70,25 ) ( 82,33 ) ( 97,33 ) ( 99,33 ) ( 100,32 ) ( 100,29 ) ( 100,19 ) ( 99,22 ) ; ( axis cs:11,80 ) circle ( 20 ) ; coordinates ( 11 , 80 ) ; coordinates ( 3,96 ) ( 6,96 ) ( 11,100 ) ( 10,89 ) ( 12,89 ) ( 16,88 ) ( 22,93 ) ( 11,80 ) ( 6,76 ) ( 11,64 ) ( 14,66 ) ( 14,69 ) ( 24,78 ) ( 27,79 ) ; ( axis cs:53,85 ) circle ( 20 ) ; coordinates ( 53 , 85 ) ; coordinates ( 51,73 ) ( 61,72 ) ( 54,81 ) ( 53,85 ) ( 57,80 ) ( 52,88 ) ( 36,94 ) ( 44,94 ) ( 41,93 ) ( 41,91 ) ( 69,96 ) ; ( axis cs:83,64 ) circle ( 20 ) ; coordinates ( 83 , 64 ) ; coordinates ( 92,82 ) ( 93,74 ) ( 97,69 ) ( 96,62 ) ( 92,60 ) ( 95,51 ) ( 83,64 ) ( 86,67 ) ( 96,49 ) ( 66,68 ) ( 70,71 ) ( 78,70 ) ( 68,54 ) ( 75,51 ) ; ( axis cs:9,31 ) circle ( 20 ) ; coordinates ( 9 , 31 ) ; coordinates ( 1,46 ) ( 4,45 ) ( 10,45 ) ( 12,42 ) ( 9,49 ) ( 9,31 ) ( 2,14 ) ( 9,39 ) ( 18,18 ) ( 21,19 ) ( 15,33 ) ( 19,26 ) ;       0.5    table [ only marks , x = x , y = y , col sep = comma , mark= * ] co.csv ; ( axis cs:46,33 ) circle ( 200 ) ; ( axis cs:53,34 ) circle ( 100 ) ; coordinates ( 46 , 33 ) ; coordinates ( 46,33 ) ( 47,14 ) ( 50,50 ) ( 51,50 ) ( 53,25 ) ( 53,34 ) ( 59,29 ) ( 52,17 ) ( 27,36 ) ( 31,32 ) ( 32,43 ) ( 34,35 ) ( 38,30 ) ( 42,42 ) ( 45,19 ) ; ( axis cs:32,56 ) circle ( 200 ) ; coordinates ( 32 , 56 ) ; coordinates ( 18,65 ) ( 22,69 ) ( 25,70 ) ( 37,71 ) ( 17,51 ) ( 16,88 ) ( 22,93 ) ( 32,56 ) ( 34,58 ) ( 34,55 ) ( 14,66 ) ( 14,69 ) ( 26,40 ) ( 17,43 ) ( 41,62 ) ( 17,43 ) ; ( axis cs:87,20 ) circle ( 200 ) ; coordinates ( 87 , 20 ) ; coordinates ( 82,4 ) ( 85,5 ) ( 89,5 ) ( 85,11 ) ( 84,14 ) ( 88,14 ) ( 86,17 ) ( 87,20 ) ( 75,6 ) ( 75,16 ) ( 70,13 ) ( 76,23 ) ( 71,31 ) ( 70,25 ) ( 82,33 ) ( 97,33 ) ( 99,33 ) ( 100,32 ) ( 100,29 ) ( 100,19 ) ( 99,22 ) ; ( axis cs:11,80 ) circle ( 20 ) ; coordinates ( 11 , 80 ) ; coordinates ( 3,96 ) ( 6,96 ) ( 11,100 ) ( 10,89 ) ( 12,89 ) ( 16,88 ) ( 22,93 ) ( 11,80 ) ( 6,76 ) ( 11,64 ) ( 14,66 ) ( 14,69 ) ( 24,78 ) ( 27,79 ) ; ( axis cs:53,85 ) circle ( 20 ) ; coordinates ( 53 , 85 ) ; coordinates ( 51,73 ) ( 61,72 ) ( 54,81 ) ( 53,85 ) ( 57,80 ) ( 52,88 ) ( 36,94 ) ( 44,94 ) ( 41,93 ) ( 41,91 ) ( 69,96 ) ; ( axis cs:83,64 ) circle ( 20 ) ; coordinates ( 83 , 64 ) ; coordinates ( 92,82 ) ( 93,74 ) ( 97,69 ) ( 96,62 ) ( 92,60 ) ( 95,51 ) ( 83,64 ) ( 86,67 ) ( 96,49 ) ( 66,68 ) ( 70,71 ) ( 78,70 ) ( 75,51 ) ; ( axis cs:9,31 ) circle ( 20 ) ; coordinates ( 9 , 31 ) ; coordinates ( 1,46 ) ( 4,45 ) ( 10,45 ) ( 12,42 ) ( 9,49 ) ( 9,31 ) ( 2,14 ) ( 9,39 ) ( 18,18 ) ( 15,33 ) ( 19,26 ) ;    we present a novel algorithm that relies on the hierarchical exhaustive logic that drives every single data point to eventually be part of a cluster .",
    "once the real - world objects ( proteins ) are expressed as vectors and are put in a high - dimensional vector space @xmath13 ( the whole protein data bank ) , an initial cluster center @xmath8 is randomly chosen in this high dimensional space @xmath13 .",
    "@xmath8 is a data point in @xmath13 itself .",
    "a user defined radius of @xmath29 defines a circular grid in which all the points are considered a part of the cluster by the user . in other words ,",
    "once @xmath8 is chosen in @xmath13 , the user decides to what extent should the data points be represented by the cluster center @xmath8 by giving @xmath29 as an input .",
    "+   + a data point @xmath46 is part of the cluster @xmath47 with the cluster center @xmath8 , where the distance value between @xmath46 and @xmath8 @xmath48 .",
    "thus , a cluster is formed based on a user - defined @xmath29 .",
    "then , the cluster is temporarily removed from @xmath13 and another randomly chosen cluster center @xmath49 is investigated for data points with distance less than @xmath29 . this is repeated until every data point @xmath46 in the high dimensional vector space @xmath13 is part of a cluster with a center @xmath8 .",
    "it is irrelevant to project the amount of initial clusters after input @xmath29 since it very much depends on the data set and the magnitude of @xmath29 and does not affect the output since the only prerequisite for the next step is to make sure every data point is part of a cluster .",
    "+   + once every data point in @xmath13 is a member of a cluster , the dummy timer @xmath50 , and the user - defined radius @xmath29 is reduced by a user - defined function @xmath51 where @xmath52 @xmath53 for both the search and the clustering .",
    "some options of @xmath29 is automatically given to the user for the query search , such as @xmath54 and @xmath55 , and users are able to define @xmath51 as long as it outputs a value where @xmath56 .",
    "within each cluster , another randomly assigned cluster center @xmath49 and the decreased radius @xmath57 is put in to find data points similar to @xmath49 and include them in the new cluster @xmath58 where now data point @xmath59 if @xmath60 .",
    "once this process is done , the dummy timer @xmath61    @xmath62 all points @xmath63 ; @xmath64 @xmath65 cluster with center @xmath8 ; @xmath66 distance between @xmath46 and @xmath8 ; _ top _ : * quit * ; _ loop _ : @xmath67 ; * goto * _ loop _ ; * close * ; @xmath68 ; * hide * @xmath69 ; * goto * _",
    "top_.    once all the clustering within all existing clusters completes , the clustering continues with radius @xmath29 getting reduced by both the user - defined function @xmath51 and the dummy timer @xmath50 . after each data point in the vector space @xmath13",
    "is a cluster within itself , the process stops .",
    "@xmath70 yields the number of levels of clustering that can depend on the data set and radius @xmath29 and also , incidentally , the level of the deepest point ( the point within the most number of clusters ) .",
    "the algorithm assumes that the system is unsupervised in the sense that it will always reach the static state where there is no clustering that needs to be done . to make the algorithm more flexible , an optional user - defined operator @xmath31 is introduced where @xmath31 denotes how deep the clustering should go .",
    "the algorithm quits when @xmath71 .",
    "+   + ultimately , the high dimensional vector space @xmath13 will include at least @xmath7 clusters for @xmath7 data points , and probably more .",
    "yet , this final specificity is redundant as the only member of the final cluster is the data point itself : when d is specified , the algorithm quits at @xmath72 to prevent redundant search of clusters @xmath73 where @xmath74 .",
    "once a query is submitted to the system , cluster centers are identified in a user - defined radius @xmath29 .",
    "cluster centers which are in this circular grid of radius @xmath29 is only searched when @xmath50 for radius @xmath57 .",
    "to obtain an optimal distance metric to be used in our entropy - based search , we investigated the increase in speed between both cosine and euclidean distance functions .",
    "the resulting values imply that the acceleration across metrics depend largely on the initial cluster radius .",
    "we produced databases for initial cluster radii of 0.1 , 0.2 , 0.3 , 0.4 , and , 0.5 and 10 , 20 , 25 , 50 , and 100 , for cosine and euclidean distance respectively , with a unit change of 0.01 ( 50 unique values of cluster radius in total ) .",
    "we ran similarity searches for 4 query proteins with varying size and number of structural neighbors : porcine @xmath0-trypsin ( 1aks ) , flavodoxin ( 1akr ) , hiv-1 reverse transcriptase ( 1fko ) , and hemoglobin - a ( 1ash ) .",
    "we used reduction functions @xmath54 and @xmath55 for @xmath51 ; yet , due to the minimal change in results , reported an average of the two functions .",
    "we ran each query protein 5 times through the entropy - based structural similarity search for each cluster radius and included the averages for each cluster radius as one data point in our investigation .",
    "+   + we also report a comparison of clustering time of both euclidean and cosine distances with aforementioned unique cluster radii .",
    "we compared the average clustering time over the whole high - dimensional vector space @xmath13 across five trials for each unique cluster radius .",
    "we used all 20 threads on an intel xeon x5690 ( 12-core ) while clustering , compared to only one during search .    .clustering time using cosine distance [ cols=\"^,^,^,^,^,^\",options=\"header \" , ]      since esperite only provides a list of potential structural neighbors , a full - body multiple structural alignment tool is needed to maximize the functionality of the web - based environment .",
    "we integrated the tool multiple alignment with translations and twists ( matt ) , engineered by menke et al .",
    "( 2008 ) [ 17 ] into the esperite kernel , where we are able to conduct full - body structural alignment after narrowing the high - dimensional protein structure vector space down to a quite precise list of potential structural neighbors .",
    "+   + yet , it is crucial to make the distinction to need full structural alignment , and offer full structural alignment to the user .",
    "hence , we conducted a correlation study between esperite and matt to decide whether or not the web - based tool need to run full structural alignment to get as accurate results as a computationally expensive structural alignment tool like matt .",
    "+   + matt uses a unit length ( block ) that is the set of @xmath0-carbon atoms in between five and nine amino acid residues in a protein . given a block @xmath75 , @xmath76 is the very first residue and @xmath77 is the very last residue across the block . for a pair of blocks @xmath78 ,",
    "@xmath79 is the minimum rmsd transformation to trigger the second structure to align its @xmath0-carbons to the first , and @xmath80 is the rmsd of the two blocks under @xmath81 .",
    "then for @xmath78 , @xmath82 since both the @xmath83value and the cosine distance is bounded by [ 0,1 ] , and cosine distance is our accuracy benchmark classifier , we used a sample size of @xmath84 hits for trials with 5 different unique proteins to measure cosine distance hits , executed matt on the hits , and averaged the values .",
    "table [ scatter , x = cos , y = matt , col sep = comma , mark=*]corr.csv ; ;",
    "we present esperite , a web server devoted to applying our entropy - based clustering and search for protein structure neighbors in a user - centered , web - based environment .",
    "esperite serves as a real - time web - based tool through which structural neighbors can be identified in a fast , efficient and computationally expensive way . using this algorithm ,",
    "the bag - of - words representations of the proteins in the protein data bank are clustered for fast and efficient structure homolog search in the database .",
    "esperite is freely available to the public and is hosted by the mit servers .",
    "the web server runs real - time commands for database search - so that the tool is available when the files hosted on the server are damaged or deleted .",
    "indeed , the files are retrieved directly from the protein data bank ( pdb ) and uploaded to the server without any prior modification . whenever the pdb file format and/or content changes in the database , the pdb file used on the web server is updated and uploaded automatically .",
    "every user starts a session with a unique session i d which would then be used to reach results without entering parameters . once the session is over ,",
    "the temporary files are deleted from the local host .",
    "all session ids are contained in a log file .",
    "esperite is up and running at http://esperite.csail.mit.edu and the source code is also available on github .",
    "a pdb file contains the atomic coordinates for either a protein or other biomacromolecule . using different methods ,",
    "structural biologists determine the location of each atom of the molecule on the plane relative to one another , annotating and finally releasing the resultant data as a pdb file to the public .",
    "the local shell command takes a pdb file as an input for the structure search .",
    "the web server also allows for identification of the input pdb file remotely from the protein data bank itself : the user is presented with the option of entering the pdb i d which is then be sent to the protein data bank to locate the actual pdb file .",
    "the pdb file is then uploaded temporarily to the local host and is deleted once the user@xmath85s session ends . once the file is uploaded to the local host , the database search shell command is run from the server .",
    "+          the web server offers options to customize the database search for structure homologs of a pdb file .",
    "these options include : the metric that will be used to express distance between two bow vectors ( cosine distance or euclidean distance ) , the initial search radius @xmath29 ( as an integer ) , the function that the initial search radius will be replaced with ( current options include @xmath54 , and @xmath55 ) , and the depth of divisive clustering @xmath31 ( @xmath31 also denotes the level of the last cluster created ) .",
    "the user is also able to enter a function of their own ( provided that it complies with the syntax and the range of the dynamic radius @xmath57 ) .",
    "the user is also free to choose the default settings already set where @xmath86 , @xmath87 , used metric is euclidean distance and @xmath31 is not specified .",
    "+      after the job is submitted , the web server will display a self - refreshing page with the task status until the job is completed .",
    "all files generated during the session are marked with a unique i d for future reference , which is reported to the user .",
    "the output window consists of a set of drop - down menus to display the pdb output file of each hit , to run matt for each hit and the input protein , and to see the pdb file in a new tab . a dynamic ajax jsmol window",
    "is also embedded to the results screen so the user can access the real - time multiple flexible alignment quickly .",
    "it has been recognized that predicting the function of a protein is key to understanding life at a molecular level .",
    "sequence comparison , which is the most frequently used method to predict the function of a protein of known sequence but unknown function , has failed to identify relationships where the subject proteins may exhibit differences in function , regardless of the significant similarity in sequence .",
    "these relationships , hence , need to be investigated through another method which would ensure prediction of a function of an unannotated protein with we introduced a novel entropy - based hierarchical framework to protein structure database clustering and search , allowing for linear - time similarity search even with an exponential increase in data .",
    "we rigorously proved that our approach scales linearly with the entropy of the database , thus sublinearly with the database itself .",
    "+   + given the drastic exponential increase in size of the protein data bank , the biggest protein structure database online , the need for methods to scale in a sublinear proportion with the increase of data arises .",
    "we present an approach through which we are able to exploit the redundancy present in the protein data bank , which has a plausible tendency to exhibit low - dimensionality on a local level .",
    "+   + the main motivation behind the applicability of our approach is the minimal metric entropy and fractal dimension the protein structure database exhibits , which is demonstrated by the scaling behavior of the cosine and euclidean distances with increasing initial cluster radius .",
    "+   + furthermore , we contribute to the arising interest and knowledge on already existing filter - and - refine protein structure alignment methodology by a number of ways :    * to our knowledge , our approach is the * fastest * filter - and - refine protein structure alignment method to date , outperforming even state - of - the - art full - body structural alignments by a large margin . * to our knowledge",
    ", it is the * most accurate * filter - and - refine method that preserves the accuracy of the state - of - the - art full - body structural alignments to date . *",
    "it is the * only * approach to date whose time and space complexity bounds can be mathematically justified without any experimental background . * it is the * only * approach to scale sublinearly with the protein structure database to date , allowing for control over the increase of the database . *",
    "it is the * only * approach that allows for the discovery and investigation of structural neighbors of a newly - discovered protein , allowing for interesting biological elucidation . *",
    "it is the * only * approach that can construct structural neighbor families and superfamilies _ ab initio _ ,",
    "i.e. , with no prior training with or starting from experimental data .",
    "* the web server esperite is the * only * protein structure alignment server who offers full flexible structural alignment using hits from a filter - and - refine method .",
    "+    when we discuss the problem of finding the structural neighbors of a protein while the amount of information that needs to be processed increases , we are inclined to stay in the concept of proteomics . yet , our approach is easily implementable to and versatile for any other `` big data '' problem our society is facing today . any -omics data that are bounded in an exponentially increasing rate can be controlled and harnessed using entropy - based hierarchical clustering .",
    "esperite is currently being thoroughly investigated by the computer science and artificial intelligence laboratory ( csail ) at the massachusetts institute of technology ( mit ) and the department of computer science at tufts university graduate school of engineering , both of which have endorsed esperite to be the protein structure discovery tool of the respective computational biology labs in order to conduct more thorough benchmark classifications and detailed engineering of the tool .",
    "corral - corral et al . (",
    "2015 ) raise an important question : given two representative data points of real - world objects , would the existence of a proximal similarity based on the dimensionality of the high - dimensional vector space in which the data points are clustered imply that the aforementioned two real - world objects are , in fact , similar ? [ 43 ]     and @xmath29 has a greater distance in between than that of @xmath88  and square class member @xmath89 .",
    "this high - dimensional vector space is already clustered , and intuitively , we note that any characteristic of the given cluster is highly effective on the proximal errors a high - dimensional vector space can yield",
    ". reprinted from [ 44 ] . ]    in order to begin to address this very frequently appearing issue in clustering and similarity search , corral - corral et al .",
    "( 2015 ) posit that the lower and upper boundaries by which the proteins with different folds are surrounded can be investigated and numerically obtained via the training from empirical data and machine learning approaches .",
    "we have established earlier that one of the biggest advantages of our entropy - based clustering and search method for protein structure comparison is that we are able to find structurally similar proteins to a protein of newly - discovered structure .",
    "esperite is able to find structural neighbors _ ab initio _ , so no empirical data on the structure of the query protein is needed .",
    "the protein data bank is filled with proteins with newly - discovered structures every day , and esperite appears to be the optimal utility to begin to identify and/or predict the function of various proteins .",
    "+   + using esperite , we identified four uncharacterized proteins whose function can potentially be elucidated by further investigation . on the protein structural neighbor pairs shown in figure 10 ,",
    "we continue our investigation at the new mexico highlands university ( nmhu ) in las vegas , nm , using nuclear magnetic resonance spectroscopy .",
    "0.40     0.40     0.40     0.40",
    "all of our software is available in github , under the gnu general public license , and our tools can be integrated into existing frameworks and the code and methodology can be incorporated into other software .",
    "+   + esperite is up and running at http://esperite.csail.mit.edu .",
    "to facilitate and streamline the analysis of time complexity , we consider the high - dimensional vector space as a set @xmath13 of the collection of @xmath7 unique points : @xmath90 the problem at hand then becomes to compute @xmath91 for a query protein @xmath89 and a given non - zero radius @xmath29 .",
    "it is important to note that a distance metric , particularly , is needed to only avoid a non - zero loss in sensitivity .",
    "+   + initially , a random cluster center @xmath8 is defined in this high - dimensional vector - space @xmath13 .",
    "the points around this cluster center @xmath8  within a user - defined radius @xmath25 are then clustered and assigned to the cluster center @xmath8 .",
    "iteratively , a set @xmath92 of @xmath8 cluster centers are defined so that there are no clusters with a cluster radius greater than a user - defined radius @xmath25 .",
    "we assign and note each cluster to its center , so the set @xmath92 is also the exhaustive set of clusters in the high - dimensional vector space @xmath13 . for a given task of similarity measurement between a query protein @xmath89 and all data points within distance @xmath31 , the approach consists of @xmath7",
    "iterative steps , combined with two real - time variables @xmath25 and @xmath29 that change values according to another user - specified parameter @xmath93 , where @xmath94 for ease of analysis , we will work on a hierarchical framework where @xmath95 , i.e. , only two layers of clustering is done in the high - dimensional vector space @xmath13 ( note that a deeper clustering will result in a depth of @xmath96 , where @xmath8 is a non - zero integer , thus scaling linearly with the running time of the search ) .",
    "the overall search is then split into 2 stages of searches , with radii of @xmath97 and @xmath29 , respectively .",
    "the similarity task of the first stage of the search , or the _ coarse search _ , is then @xmath98 , and the union of all defined clusters @xmath47 with center @xmath8 for the radius @xmath97 is then @xmath99 triangle inequality , which all distance metrics obey , implies that the second stage of the search , or the _ fine search _ , @xmath100 .",
    "intuitively , as @xmath101 , @xmath102 so the same defined clusters @xmath47 with centers @xmath8 and radius @xmath97 in the coarse search can be used in fine search with radius @xmath29 .",
    "+   + in an entropy - based construction of the dataset , the distance function used is only a metric to avoid disobeying the triangle inequality .",
    "it has been noted by yu et al .",
    "( 2015 ) that the use of many distance functions are plausible , yet decrease the amount of sensitivity the approach exhibits .",
    "more particularly , if a triplet of data points @xmath103 over all triplets @xmath104 in the high - dimensional vector space @xmath13 do not satisfy the inequality , the sensitivity is then @xmath105 [ 28 ] .",
    "as experimentally shown in the results , this loss is infinitesimal , and inclined to lose significance as @xmath106 . +   + if the fractal dimension of the high - dimensional vector space @xmath13 is low , the @xmath7-stage hierarchical clustering approach has a running time increase that is linearly proportional with the metric entropy of the database .",
    "we note that this database , along with any newly - added points to the database , can also be stored in a space complexity linearly proportional to the metric entropy of the database",
    ".      * definition 1 .",
    "* let @xmath13 be a high - dimensional vector space , @xmath107 a subset of @xmath13 , and @xmath29 a non - zero radius .",
    "the _ metric entropy _",
    "@xmath108 of the high - dimensional vector space @xmath13 is then the minimum number of points @xmath109 so that spherical clusters @xmath110 include all points in @xmath13 [ 44 ]",
    ". +   + * definition 2 . * given any high - dimensional vector space @xmath13 , the hausdorff - besicovitch dimension is @xmath111 intuitively , we note that for all cases , @xmath112 since @xmath13 is finite and countable .",
    "we then utilize a more narrow definition of fractal dimension located around a distance scale with large radii : +   + * definition 3 . * given any high - dimensional vector space @xmath13 , and a radius scale @xmath113 $ ] , the _ fractal dimension _",
    "is @xmath114 intuitively , we note that after the initial clustering with radii @xmath25 and the construction of a set @xmath92 of @xmath8 cluster centers in the high - dimensional vector space @xmath13 , @xmath115 , since the criterion that no cluster has a radius greater than @xmath25 is satisfied .",
    "thus , set of cluster centers @xmath8 is bounded by metric entropy @xmath116 of the high - dimensional vector space @xmath13 .",
    "+   + still following the specific case of @xmath7-stage hierarchical clustering approach where @xmath95 , we note that :    * for a given query @xmath89 , the coarse search will be exhaustively completed only after @xmath8 comparisons . * the fine search",
    "is bounded in the union @xmath117 in ( 5 ) , which is the union of clusters @xmath97 away from query @xmath89 .",
    "thus , the running time for the @xmath95 search overall is @xmath118 , as the sum of running times for both the coarse and the fine search .",
    "* @xmath119 by the triangle inequality ( proof is trivial ) ; thus , @xmath117 is bounded by @xmath120 . *",
    "recall definition 3 .",
    "given the non - rigorous definition of fractal dimension , we note that for a scale of radii @xmath121 $ ] , and an increase from @xmath122 to @xmath123 , any newly - discovered point will be covered by fractal dimension @xmath31 in a running time of @xmath124 .",
    "thus , the overall time complexity for @xmath95 is @xmath42 note that for asymptotically small values of fractal dimension and a linear output size , the running time converges to @xmath125 as @xmath8 is linearly scaled with entropy , thus logarithmically with the dataset ; and the output size @xmath7 is linear .",
    "two distinct methods can be used for hierarchical clustering : agglomerative , and divisive .",
    "agglomerative clustering is when each data point is initially accepted as a cluster within itself , and these clusters are merged using the similarity quantification via distance metrics .",
    "clustering continues until the high - dimensional vector space @xmath126 .",
    "+   + divisive clustering can be thought of as the inverse : the high - dimensional vector space @xmath13 is initialized as the first cluster , and closer data points in the cluster create a new sub - cluster .",
    "divisive hierarchical clustering continues until every single data point in @xmath13 is a cluster within itself .",
    "+   + because the algorithm starts with the high dimensional vector space @xmath13 being the initial cluster , and ends when all data points are clusters within themselves or user - defined @xmath31 equals timer @xmath70 , the system is based on flat divisive hierarchical clustering . although these two methods may seem like they are supposed to replicate results when timer @xmath70 is reversed , when the distance metric and the similarity criterion are introduced , using divisive hierarchical clustering is proven to be more optimal :    * assume you have a cluster center @xmath8 and a radius @xmath29 when @xmath127 and @xmath128 .",
    "every data point @xmath7 where @xmath129 where @xmath130 is included in cluster @xmath47 . * if this cluster center @xmath8 is @xmath131 further away from another cluster center @xmath132 , then when @xmath133 , @xmath47 and @xmath134 should be merged .",
    "* at this point , we want the data points which are members of @xmath134 to be less than or equal to @xmath135 .    yet",
    "when we merge the two clusters , @xmath7 is almost @xmath136 away from @xmath132 but is still a member of @xmath134 .",
    "+   + agglomerative clustering is flawed in similarity search ; it is not error - free for radius @xmath29 , thus the cluster centers are not entirely reliable as they include more distant points in each step .",
    "the advantage of starting clustering from a high - dimensional vector space @xmath13 is that since each level of clustering happens only within the clusters from the previous level , clusters that have elements that are too far from one another are not merged .",
    "it is also a more succinct implementation on top of the existing initial clustering .",
    "the author thanks dr . bonnie berger and dr .",
    "noah daniels at computer science and artificial intelligence laboratory ( csail ) at the massachusetts institute of technology ( mit ) for their mentorship and guidance , dr . semsettin turkoz , mr . and",
    "mustafa basar arioglu , and mr .",
    "kemal tunc for their sponsorship , joseph dexter and marie herring for their suggestions and support , andrew jin and daniel yang for their feedback , andrew gallant and yun william yu for fragbag implementation , and the related groups for making the following packages available : the jmol / jsmol package ( http://jmol.sourceforge.net ) , go programming language ( http://golang.org ) , and the pdb ( http://rcsb.org/pdb )",
    ".    99 a. pastore and a. m. lesk , comparison of the structures of globins and phycocyanins : evidence for evolutionary relationship , _ proteins : structure , function , and bioinformatics _ , 8:133 - 155 , 1990 . w. a. koppensteiner , p. lackner , m. wiederstein , and m. j. sippl , characterization of novel proteins based on known protein structures , _ journal of molecular biology _",
    ", 296:1139 - 1152 , 2000 .",
    "c. chothia and a. m. lesk , the relation between the divergence of sequence and structure in proteins , _ the embo journal _ , 5:823 - 826 , 1986 .",
    "r. eisner , b. poulin , d. szafron , p. lu , and r. grenier , improving protein function prediction using hierarchical structure of the gene ontology , _ proceedings of the 2005 ieee symposium on computational intelligence in bioinformatics and computational biology _",
    "n. s. boutonnet , m. j. rooman , m. e. ochagavia , j. richelle , and s. j. wodak , optimal protein structure alignments by multiple linkage clustering : application to distantly related proteins , _ protein engineering , design & selection _ , 8:647 - 662 , 1995 .",
    "c. p. ponting , issues in predicting protein function from sequence , _ briefings in bioinformatics _ , 2:19 - 29 , 2001 .",
    "a. godzik , the structural alignment between two proteins : is there a unique answer ?",
    ", _ protein science _ , 5:1325 - 1338 , 1996 .",
    "u. m. fayyad , g. piatetsky - shapiro , p. smyth , and r. uthurusamy , advances in knowledge discovery and data mining , _ aaai / mit press _ , 1996 .",
    "a. gersho and r. m. gray , vector quantization and signal compression , _ boston : kluwer academic _ , 1992 .",
    "t. kanungo , d. m. mount , n. s. netanyahu , c. piatko , r. silverman , and a. y. wu , an efficient k - means clustering algorithm : analysis and implementation , _ ieee transactions on pattern analysis and machine intelligence _",
    ", 24:7 , 2002 .",
    "a. brahme , comprehensive biomedical physics , _ newnes _ , 1:136 , 2014 . b. ekim ,",
    "a machine learning approach to cross - generational single - point mutation patterns across the e.coli genome , unpublished .",
    "m. sunouchi , y. tanaka , similarity search of freesound environmental sound based on their enhanced multiscale fractal dimension , _ proceedings of the sound and music computing conference _ , 2013 .",
    "m. j. sippl and m. wiederstein , a note on difficult structure alignment problems , _ bioinformatics _ , 24:426 - 427 , 2008 . l. holm and c. sander , protein structure comparison by alignment of distance matrices , _ journal of molecular biology _",
    ", 233:123 - 138 , 1993 . y. ye and a. godzik , fatcat : a web server for flexible structure comparison and structure similarity searching .",
    "_ nucleic acids research _ , 32:582 - 585 , 2004 . m. menke , b. berger , and l. cowen , matt : local flexibility aids protein multiple structure alignment .",
    "_ plos computational biology _ , 4:10 , 2008 .",
    "r. h. lathrop , the protein threading problem with sequence amino acid interaction preferences is np - complete , _ protein engineering , design & selection _ , 7:1059 - 1068 , ( 1994 )",
    ". g. mayr , f. s. domingues , and p. lackner , comparative analysis of protein structure alignments , _ bmc structural biology _",
    ", 7:50 , 2007 .",
    "r. mosca , b. brannetti , and t. r. schneider , alignment of protein structures in the presence of domain motions , _ bmc bioinformatics _ , 9:352 , 2008 . z. lu , z. zhao , and b. fu , efficient protein alignment algorithm for protein search , _ bmc bioinformatics _",
    ", 11:34 , 2010 . t. kato , k. tsuda , k. tomii , and k. asai , a new variational framework for rigid - body alignment , _ lecture notes in computer science _",
    ", 3138:171 - 179 , 2004 .",
    "e. roberts , j. eargle , d. wright , and z. luthey - schulten , multiseq : unifying sequence and structure data for evolutionary analysis , _ bmc bioinformatics _ , 7:382 , 2006 .",
    "a. s. konagurthu , j. c. whisstock , p. j. stuckey , and a. m. lesk , mustang : a multiple structural alignment algorithm , _ proteins : structure , function , and bioinformatics _ , 64:559 - 574 , 2006 . l. holm and j. park , dalilite workbench for protein structure comparison , _ bioinformatics _ , 16:566 - 567 , 2000 . m. kosloff and r. kolodny .",
    "sequence - similar , structure - dissimilar protein pairs in the pdb , _ proteins : structure , function , and bioinformatics _ , 71:891 - 902 , 2008 . i. budowski - tal , y. nov , and r. kolodny , fragbag , an accurate representation of protein structure , retrieves structural neighbors from the entire pdb quickly and accurately , _ proceedings of the national academy of sciences of the united states of america _ , 107:3481 - 3486 , 2009 . y. w. yu , n. m. daniels , d. c. danko , and b. berger , entropy - scaling search of massive biological data , _ cell systems _ , 1:130 - 140 , 2015 . z. aung and k. l. tan , rapid retrieval of protein structures from databases , _ drug discovery today _",
    ", 12:732 - 739 , 2007 . i. g. choi , j. kwon , and s. h. kim , local feature frequency profile : a method to measure structural similarity in proteins , _ proceedings of the national academy of sciences of the united states of america _",
    ", 11:3797 - 3802 , 2004 .",
    "p. rgen and b. fain , automatic classification of protein structure by using gauss integrals , _ proceedings of the national academy of sciences of the united states of america _ , 1:119 - 124 , 2003 . i. friedberg , t. harder , r. kolodny , e. sitbon , z. li , and a. godzik , using an alignment of fragment strings for comparing protein structures , _ bioinformatics _",
    ", 23:219 - 224 , 2007 .",
    "tung , j. w. huang , and j. m. yang , kappa - alpha plot derived structural alphabet and blosum - like substitution matrix for rapid search of protein structure database , _ genome biology _ , 8:31 , 2007 . z. gaspari , k. vlahovicek , and s. pongor , efficient recognition of folds in protein 3d structures by the improved pride algorithm , _ bioinformatics _",
    ", 21:3322 - 3323 , 2005",
    ". m. gerstein and m. levitt , comprehensive assessment of automatic structural alignment against a manual standard , the scop classification of proteins , _",
    "protein science _ , 7:445 - 456 , 1998 . f. krull , g. korff , n. elghobashi - meinhardt , and e. w. knapp , propairs : a data set for protein - protein docking , _ journal of chemical information and modeling _",
    ", 55:1495 - 507 , 2015 .",
    "k. p. smith , k. m. gifford , and j. s. waitzman , survey of phosphorylation near drug binding sites in the protein data bank ( pdb ) and their effects , _ proteins : structure , function , and bioinformatics _ , 83:25 - 36 , 2015 .",
    "e. cukuroglu , a. gursoy , r. nussinov , and o. keskin , non - redundant unique interface structures as templates for modeling protein interactions , _ plos one _ , 9:86738 , 2014 .",
    "d. mary - rajathei and s. selvaraj , analysis of sequence repeats of proteins in the pdb , _ computational biology and chemistry _ , 47:156 - 166 , 2013 . s. c. bull , m. r. muldoon , and a. j. doig , maximising the size of non - redundant protein datasets using graph theory , plos one .",
    "_ plos one _ , 8:55484 , 2013 . y. zhang and j. skolnick , tm - align : a protein structure alignment algorithm based on tm - score , _ nucleic acids research _",
    ", 33:2302 - 2309 , 2005 .",
    "c. h. tung , j. w. huang , and j. m. yang , kappa - alpha plot derived structural alphabet and blosum - like substitution matrix for fast protein structure database search , _ genome biology _ , 8:31 , 2007 .",
    "r. corral - corral , e. chavez , g. del rio , machine learnable fold space representation based on residue cluster classes . , _ computational biology and chemistry _ , 59:1 - 7 , 2015 . t. tao , product set estimates for non - commutative groups , _ combinatorica _ , 2006 ."
  ],
  "abstract_text": [
    "<S> identification and alignment of three - dimensional folding of proteins may yield useful information about relationships too remote to be detected by conventional methods , such as sequence comparison , and may potentially lead to prediction of patterns and motifs in mutual structural fragments . with the exponential increase of structural proteomics data , the methods that scale with the rate of increase of data </S>",
    "<S> lose efficiency . </S>",
    "<S> hence , new methods that reduce the computational expense of this problem should be developed . </S>",
    "<S> we present a novel framework through which we are able to find and align protein structure neighbors via hierarchical clustering and entropy - based query search , and present a web - based protein database search and alignment tool to demonstrate the applicability of our approach . </S>",
    "<S> the resulting method replicates the results of the current gold standard with a minimal loss in sensitivity in a significantly shorter amount of time , while ameliorating the existing web workspace of protein structure comparison with a customized and dynamic web - based environment . </S>",
    "<S> our tool serves as both a functional industrial means of protein structure comparison and a valid demonstration of heuristics in proteomics . </S>"
  ]
}