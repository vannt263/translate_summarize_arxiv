{
  "article_text": [
    "the standard clustering problem @xcite consists of partitioning a set of input vectors , such that the vectors in each partition ( cluster ) are close to one another according to some predefined distance function .",
    "this formulation is the objective of the popular @xmath4-means algorithm ( see , for example , @xcite ) , where @xmath4 denotes the final number of clusters and the distance function is defined by the @xmath3-norm .",
    "another similar example of this formulation is the @xmath4-median algorithm ( see , for example , @xcite ) , where the distance function is given by the @xmath1-norm .",
    "clustering a set of input vectors is a well - known np - hard problem even for @xmath5 clusters @xcite .",
    "several approximation guarantees have been shown for this formulation of the standard clustering problem ( see @xcite and references therein ) .",
    "intensive recent research has focused on the discovery of homogeneous substructures in large matrices .",
    "this is also one of the goals in the problem of _",
    "biclustering_. given a set of @xmath6 rows in @xmath7 columns from a matrix @xmath8 , a biclustering algorithm identifies subsets of rows exhibiting similar behavior across a subset of columns , or vice versa .",
    "note that the optimal solution for this problem necessarily requires to cluster the @xmath6 vectors and the @xmath7 dimensions simultaneously , thus the name biclustering .",
    "each submatrix of @xmath8 , induced by a pair of row and column clusters , is typically referred to as a _",
    "bicluster_. see figure [ fig : ex ] for a simple toy example .",
    "the main challenge of a biclustering algorithm lies in the dependency between the row and column partitions , which makes it difficult to identify the optimal biclusters .",
    "a change in a row clustering affects the cost of the induced submatrices ( biclusters ) , and as a consequence , the column clustering may also need to be changed to improve the solution .    finding an optimal solution for the biclustering problem is np - hard .",
    "this observation follows directly from the reduction of the standard clustering problem ( known to be np - hard ) to the biclustering problem by fixing the number of clusters in columns to @xmath7 . to the best of our knowledge",
    ", no algorithm exists that can efficiently approximate biclustering with a proven approximation ratio .",
    "the goal of this paper is to propose such an approximation guarantee by means of a very simple scheme .",
    "our approach will consist of relieving the requirement for simultaneous clustering of rows and columns and instead perform them independently .",
    "in other words , our final biclusters will correspond to the submatrices of @xmath8 induced by pairs of row and columns clusters , found independently with a standard clustering algorithm .",
    "we sometimes refer to this standard clustering algorithm as one - way clustering .",
    "the simplicity of the solution alleviates us from the inconvenient dependency of rows and columns .",
    "more importantly , the solution obtained with this approach , despite not being optimal , allows for the study of approximation guarantees on the obtained biclusters . here",
    "we prove that our solution achieves a worst - case approximation ratio of @xmath0 under @xmath1-norm for 01 valued matrices , and of @xmath2 under @xmath3-norm for real valued matrices .",
    "finally , note that our final solution is constructed on top of a standard clustering algorithm ( applied twice , once in row vectors and the other in column vectors ) and therefore , it is necessary to multiply our ratio with the approximation ratio achieved by the used standard clustering algorithm ( such as @xcite ) . for clarity",
    ", we will lift this restriction in the following proofs by assuming that the applied one - way clustering algorithm provides directly an optimal solution to the standard clustering problem .",
    "this basic algorithmic problem and several variations were initially presented in @xcite with the name of direct clustering .",
    "the same problem and its variations have also been referred to as two - way clustering , co - clustering or subspace clustering . in practice , finding highly homogeneous biclusters has important applications in biological data analysis ( see @xcite for review and references ) , where a bicluster may , for example , correspond to an activation pattern common to a group of genes only under specific experimental conditions .",
    "an alternative definition of the basic biclustering problem described in the introduction consists on finding the maximal bicluster in a given matrix .",
    "a well - known connection of this alternative formulation is its reduction to the problem of finding a biclique in a bipartite graph  @xcite .",
    "algorithms for detecting bicliques enumerate them in the graph by using the monotonicity property that a subset of a biclique is also a biclique  @xcite .",
    "these algorithms usually have a high order of complexity .",
    "we assume given a matrix @xmath8 of size @xmath9 , and integers @xmath10 and @xmath11 , which define the number of clusters partitioning rows and columns , respectively .",
    "the goal is to approximate the optimal biclustering of @xmath8 by means of a one - way row clustering into @xmath10 clusters and a one - way column clustering into @xmath11 clusters .    for any @xmath12",
    "we denote @xmath13 = \\{1,\\ldots , t\\}$ ] .",
    "we use @xmath14 , where @xmath15 $ ] and @xmath16 $ ] , to denote the submatrix of @xmath8 induced by the subset of rows @xmath17 and the subset of columns @xmath18 .",
    "let @xmath19 denote an induced submatrix of @xmath8 , that is @xmath20 for some @xmath15 $ ] and @xmath16 $ ] . when required by the context",
    ", we will also refer to @xmath20 as a bicluster of @xmath8 and denote the size of @xmath19 with @xmath21 , where @xmath22 and @xmath23 .",
    "we use @xmath24 and @xmath25 to denote the median and mean of all elements of @xmath19 , respectively .",
    "the scheme for approximating the optimal biclustering is defined as follows .",
    "+    p0.94 * input : * matrix @xmath8 , number of row clusters @xmath10 , number of column clusters @xmath11 +   + @xmath26 + @xmath27 +   + * output : * a set of biclusters @xmath14 , for each @xmath28 , @xmath29 +    the function @xmath30 denotes here an optimal one - way clustering algorithm that partitions the row vectors of matrix @xmath8 into @xmath10 clusters .",
    "we have used @xmath31 to denote the transpose of matrix @xmath8 .    instead of fixing a specific norm for the formulas",
    ", we use the dissimilarity measure @xmath32 to absorb the norm - dependent part . for @xmath1-norm",
    ", @xmath32 would be defined as @xmath33 , and for @xmath3-norm as @xmath34 . given @xmath19 of size @xmath35",
    ", we further use a special row norm , @xmath36,j))}$ ] , and a special column norm , @xmath37))}$ ] .",
    "we define the one - way row clustering , given by kcluster above , as a partition of rows @xmath38 $ ] into @xmath10 clusters @xmath39 such that the cost function @xmath40 is minimized .",
    "analogously , the one - way clustering of columns @xmath41 $ ] into @xmath11 clusters @xmath42 is defined such that the cost function @xmath43 is minimized .",
    "the cost of biclustering , induced by the two one - way clusterings above , is @xmath44    notice that we are assuming that the one - way clusterings above , denoted @xmath45 on rows and @xmath46 on columns , correspond to optimal one - way partitionings on rows and columns , respectively .",
    "finally , the optimal biclustering on @xmath8 is given by simultaneous row and column partitions @xmath47 and @xmath48 , that minimize the cost @xmath49",
    "given the definitions above , our main result reads as follows .",
    "there exists an approximation ratio of @xmath50 such that @xmath51 , where @xmath52 for @xmath1-norm and @xmath53 , and @xmath54 for @xmath3-norm and @xmath55 .",
    "[ thm : main ]    we use the following intermediate result to prove the theorem .",
    "there exists an approximation ratio of at most @xmath50 , that is , @xmath56 , if for any @xmath8 and for any partitionings @xmath45 and @xmath46 of @xmath8 , all biclusters @xmath57 , with @xmath58 and @xmath59 , satisfy @xmath60 [ lem : alpha ]    first we note that the cost of the optimal biclustering @xmath61 can not increase when we increase the number of row ( or column ) clusters .",
    "for example , consider the special case where @xmath62 ( or @xmath63 ) .",
    "in such case , each row ( or column ) is assigned to its own cluster and the cost of the optimal biclustering equals the cost of the optimal one - way clustering on columns @xmath64 ( or rows @xmath65 ) .",
    "hence , the optimal biclustering solution is bounded from below by @xmath66    summing both sides of equation ( [ eq : thbound ] ) , @xmath67 and using equations ( [ eq : lr ] ) , ( [ eq : lc ] ) and ( [ eq : l ] ) , gives @xmath68 , which together with equation ( [ eq : lower ] ) implies the approximation ratio of @xmath69 .",
    "theorem [ thm : main ] is proven separately in sections [ sec : l1 ] and [ sec : l2 ] using lemma [ lem : alpha ] .",
    "section [ sec : l1 ] deals with the case of having a 01 valued matrix @xmath8 and @xmath1-norm distance function , while section [ sec : l2 ] deals with real valued matrix @xmath8 and @xmath3-norm .",
    "consider a 01 valued matrix @xmath8 and @xmath1-norm . to prove theorem",
    "[ thm : main ] it suffices to show that equation ( [ eq : thbound ] ) holds for each of the biclusters @xmath57 of @xmath8 , where @xmath58 and @xmath59 .",
    "therefore , in the following we concentrate on one single bicluster @xmath70 .    without loss of generality ,",
    "we consider only the case where the bicluster @xmath19 has at least as many 0 s as 1 s . in such case",
    ", the median of @xmath19 can be safely taken to be zero and the cost @xmath71 is then fixed to the number of 1 s in the matrix . to get the worst case scenario towards the tightest upper bound on @xmath50 in equation ( [ eq : thbound ] ) , we should find first a configuration of 1 s such that , given @xmath72 , the sum @xmath73 is minimized .",
    "denote by @xmath74 and @xmath75 the sets of rows and columns in @xmath19 which have more 1 s than 0 s , respectively .",
    "denote @xmath76 , @xmath77\\setminus o_c)$ ] , @xmath78\\setminus o_r , o_c)$ ] , @xmath79\\setminus o_r,[m]\\setminus o_c)$ ] , @xmath80 and @xmath81 .",
    "note that @xmath82 , @xmath83 , @xmath18 and @xmath84 are simply blocks of bicluster @xmath19 , which we need to make explicit in our notation for the proof .    changing a 0 to 1 in @xmath82 or",
    "a 1 to 0 in @xmath84 decreases @xmath73 by two , while changing a 0 to 1 or 1 to 0 in @xmath83 or @xmath18 changes @xmath73 by at most one .",
    "it follows that _ swapping _ a 1 in @xmath83 or @xmath18 with a 0 in @xmath82 ( see figure [ fig : swaps]a ) , or swapping a 1 in @xmath84 with a 0 in @xmath82 , @xmath83 or @xmath18 ( see figure [ fig : swaps]b ) decreases @xmath73 while @xmath72 remains unchanged . in other words , in a solution that minimizes @xmath73 no such swaps can be made . in the remainder of this subsection , we assume that the bicluster @xmath19 satisfies this mentioned property .",
    "it follows that ( i ) @xmath82 , @xmath83 and @xmath18 are blocks of 1 s , ( ii ) @xmath82 is a block of 1 s and @xmath84 is a block of 0 s , or ( iii ) @xmath83 , @xmath18 and @xmath84 are blocks of 0 s .",
    "denote by @xmath85 the number of 1 s in a given block .",
    "it follows that @xmath86 , @xmath87 and @xmath88 .",
    "we denote @xmath89 , @xmath90 , @xmath91 , @xmath92 , @xmath93 and @xmath94 and rewrite equation ( [ eq : thbound ] ) as @xmath95 with constraints @xmath96 $ ] , @xmath97 $ ] @xmath98 $ ] , as well as ( i ) @xmath99 , @xmath100 , @xmath101 and @xmath102 $ ] ; ( ii ) @xmath99 , @xmath103 $ ] , @xmath104 $ ] and @xmath105 ; or ( iii ) @xmath106 $ ] and @xmath107 .",
    "the optimization problem has two solutions , ( i ) @xmath108 , @xmath99 , @xmath100 , @xmath101 and @xmath105 , and ( ii ) @xmath109 , @xmath99 and @xmath107 , both solutions yielding @xmath110 when exactly half of the entries in the bicluster @xmath19 are 1 s .",
    "this proves theorem [ thm : main ] for 01 valued matrices and @xmath1-norm .",
    "notice that the above proof relies on the fact that the input matrix @xmath8 has only two types of values .",
    "therefore , the proof does not generalize to real valued matrices .",
    "an example of a matrix with approximation ratio of 2 is given by a @xmath111 matrix @xmath112 with @xmath113 columns in the first column group , @xmath113 columns in the second column group and @xmath114 columns in the third column group , clustered to two row clusters , @xmath115 , and one column cluster , @xmath116 , at the limit of large @xmath113 .",
    "the optimal one - way clustering of rows is given by @xmath117 , @xmath118 , and the optimal biclustering of rows by @xmath119 , @xmath120 .",
    "consider now a real valued matrix @xmath8 and @xmath3-norm .",
    "we want to prove theorem [ thm : main ] for the real valued biclusters @xmath19 of @xmath8 .",
    "to find the approximation ratio , it suffices to show that equation ( [ eq : thbound ] ) holds for each bicluster @xmath121 , which are determined by @xmath57 , where @xmath58 and @xmath59 .",
    "using the definitions of @xmath122 @xmath123 and @xmath124 we can write @xmath125 , where @xmath126,j))+\\mathrm{mean}(y(i,[m]))-\\mathrm{mean}(y)$ ] . hence , equation ( [ eq : thbound ] ) is satisfied for @xmath127-norm and real valued matrices when @xmath54 .",
    "we have shown that approximating the optimal biclustering with independent row- and column - wise standard clusterings achieves a good approximation guarantee .",
    "however in practice , standard one - way clustering algorithms ( such as @xmath4-means or @xmath4-median ) are also approximate , and therefore , it is necessary to multiply our ratio with the approximation ratio achieved by the standard clustering algorithm ( such as presented in @xcite ) to obtain the true approximation ratio of our scheme .",
    "still , our contribution shows that in many practical applications of biclustering , it may be sufficient to use a more straightforward standard clustering of rows and columns instead of applying heuristic algorithms without performance guarantees .",
    "we thank nikolaj tatti for reading through the manuscript and giving useful comments ."
  ],
  "abstract_text": [
    "<S> the problem of biclustering consists of the simultaneous clustering of rows and columns of a matrix such that each of the submatrices induced by a pair of row and column clusters is as uniform as possible . in this paper </S>",
    "<S> we approximate the optimal biclustering by applying one - way clustering algorithms independently on the rows and on the columns of the input matrix . </S>",
    "<S> we show that such a solution yields a worst - case approximation ratio of @xmath0 under @xmath1-norm for 01 valued matrices , and of @xmath2 under @xmath3-norm for real valued matrices . </S>"
  ]
}