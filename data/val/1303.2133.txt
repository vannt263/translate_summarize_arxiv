{
  "article_text": [
    "the main objective of weather forecasting is to give a robust and reliable prediction of future atmospheric states on the basis of observational data , prior forecasts valid for the initial time of the forecasts and mathematical models describing the dynamical and physical behaviour of the atmosphere .",
    "these models numerically solve the set of the hydro - thermodynamic non - linear partial differential equations of the atmosphere and its coupled systems ( like surface or oceans for instance ) .",
    "the difficulty with these numerical weather prediction models is that since the atmosphere has a chaotic character the solutions strongly depend on the initial conditions and also on other uncertainties related to the numerical weather prediction process . in practice ,",
    "the results of such models are never fully accurate and forecast uncertainties should be also taken into account in the forecast preparation .",
    "a possible solution is to run the model with different initial conditions ( since the uncertainties in the initial conditions are one of the most important sources of uncertainty ) and produce an ensemble of forecasts .",
    "the forecast ensemble can estimate the probability distribution of future weather variables which allows probabilistic weather forecasting @xcite , where not only the future atmospheric states are predicted , but also the related uncertainty information ( which is indeed a valuable extension to the so called deterministic approach , where only the forecast is given without uncertainty estimation ) .",
    "the ensemble prediction method was proposed by @xcite and since its first operational implementation @xcite it has become a widely used technique all over the world and the users understand more and more its merits and economic value as well . however , although e.g. the ensemble mean on average yields better forecasts of a meteorological quantity than any of the individual ensemble members , it is often the case that the ensemble is under - dispersive and in this way , uncalibrated @xcite , so that calibration is needed to account for this deficiency .",
    "the bayesian model averaging ( bma ) method for post - processing ensembles in order to calibrate them was introduced by @xcite .",
    "the basic idea of bma is that for each member of the ensemble forecast there is a corresponding conditional probability density function ( pdf ) that can be interpreted as the conditional pdf of the future weather quantity provided the considered forecast is the best one .",
    "then the bma predictive pdf of the future weather quantity is the weighted sum of the individual pdfs corresponding to the ensemble members and the weights are based on the relative performance of the ensemble members during a given training period . in practice , the performance of the individual ensemble members should have a clear characteristic ( and not a random one ) or if it is not the case this fact should be taken into account at the calibration process ( see e.g. * ? ? ?",
    "* ) . in @xcite",
    "the bma method was successfully applied to obtain 48 hour forecasts of surface temperature and sea level pressure in the north american pacific northwest based on the 5 members of the university of washington mesoscale ensemble @xcite .",
    "these weather quantities can be modeled by normal distributions , so the predictive pdf is a gaussian mixture .",
    "later , @xcite developed a discrete - continuous bma model for precipitation forecasting , where the discrete part corresponds to the event of no precipitation , while the cubic root of the precipitation amount ( if it is positive ) is modeled by a gamma distribution . in @xcite",
    "the bma method was used for wind speed forecasting and the component pdfs follow gamma distributions . finally , using von mises distribution to model angular data",
    "@xcite introduced a bma scheme to predict surface wind direction .    in the present work",
    "the bma method is applied for calibrating ensemble temperature forecasts produced by the operational limited area model ensemble prediction system ( lameps ) of the hungarian meteorological service ( hms ) called aladin - huneps @xcite .",
    "aladin - huneps covers a large part of continental europe with a horizontal resolution of 12 km and it is obtained by dynamical downscaling ( by the aladin limited area model ) of the global arpege based pearp system of mto france @xcite .",
    "the ensemble consists of 11 members , 10 initialized from perturbed initial conditions and one control member from the unperturbed analysis .",
    "this construction implies that the ensemble contains groups of exchangeable forecasts ( the ensemble members can not be distinguished , thus it is not possible to depict a systematic behaviour of each member ) , so for post - processing one has to use the modification of bma as suggested by @xcite .",
    "we remark , that bma method has already been successfully applied for wind speed ensemble forecasts of the aladin - huneps  in @xcite it is shown that bma post - processing of these forecasts significantly improves the calibration and the accuracy of point forecasts as well .",
    "now this latter work is extended towards the calibration of the 2 m temperature ensemble forecasts .",
    "as it was mentioned in the introduction , bma post - processing of ensemble predictions was applied for temperature data produced by the operational aladin - huneps system of the hms .",
    "the data file contains 11 member ensemble ( 10 forecasts started from perturbed initial conditions and one control ) of 42 hour forecasts for 2 m temperature ( given in kelvin ) for 10 major cities in hungary ( miskolc , szombathely , gyr , budapest , debrecen , nyregyhza , nagykanizsa , pcs , kecskemt , szeged ) together with the corresponding validating observations , for the period between october 1 , 2010 and march 25 , 2011 .",
    "the forecasts are initialized at 18 utc .",
    "the data set is fairly complete , since there are only two days ( 18.10.2010 and 15.02.2011 ) when three ensemble members are missing for all sites and one day ( 20.11.2010 ) when no forecasts are available .",
    "figure [ fig : fig1 ] shows the verification rank histogram of the raw ensemble , that is the histogram of ranks of validating observations with respect to the corresponding ensemble forecasts ( see e.g. * ? ? ?",
    "* section 8.7.2 ) .",
    "it is clear that this histogram is far from the desired uniform distribution , in many cases the ensemble members either underestimate , or overestimate the validating observations ( the ensemble range contains the observed near - surface temperature values only in @xmath0 of the cases ) .",
    "hence , the ensemble is under - dispersive and in this way it is uncalibrated . in case of proper calibration",
    "the probability of a validating observation being below the ensemble range would be @xmath1 and we would have the same probability for the observation being above it . in this way the probability @xmath2 ( i.e. @xmath3 ) can be considered as the nominal value of the ensemble range .",
    "in order to calibrate the aladin - huneps ensemble forecasts for temperature the modification of bma normal model of @xcite for ensembles with exchangeable members @xcite was used .",
    "the grouping of ensemble members was similar to the case of wind speed investigated in @xcite .",
    "in the first model we have two exchangeable groups : one contains the control denoted by  @xmath4 ,  the other one the 10 ensemble members corresponding to the different perturbed initial conditions which are denoted by  @xmath5 ,  respectively .",
    "we assume that the probability density function ( pdf ) of the forecasted temperature  @xmath6  equals : @xmath7 where  @xmath8 $ ] ,  and  @xmath9  is a normal pdf with mean  @xmath10  ( linear bias correction ) and variance  @xmath11 . in this way the two groups have different mean parameters  @xmath12  and  @xmath13 ,  and a common standard deviation parameter @xmath14 .",
    "mean parameters  @xmath12  and  @xmath13  are estimated with linear regression , while the weight parameter  @xmath15 and the variance  @xmath11 ,  by maximum likelihood method , using training data consisting of ensemble members and verifying observations from the preceding  @xmath16  days ( training period ) .",
    "the maximum of the likelihood function is found with the em algorithm @xcite and due to the normality of the model both the expectation ( e ) and the maximization ( m ) step lead to closed formulae which allows fast calculations . for more details",
    "see @xcite .",
    "once the estimated parameters for a given day are available , one can use either the mean or the median of the predictive pdf as a point forecast .",
    "we also investigate special cases when in model only additive bias correction is present , that is @xmath17 ,   and when we do not use bias correction at all , i.e.  @xmath18  and @xmath17 .",
    "now , similarly to wind speed data investigated in @xcite , to obtain the ten exchangeable ensemble members only five perturbations are calculated and then they are added to ( odd numbered members ) and subtracted from ( even numbered members ) the unperturbed initial conditions @xcite .",
    "figure [ fig : fig2 ] shows the plume diagram of ensemble forecasts of 2 m temperature for debrecen initialized at 18 utc , 22.10.2010 .",
    "this diagram clearly illustrates that the behaviour of ensemble member groups  @xmath19  and  @xmath20   differ from each other ( particularly look at the 2436h and 4860h forecast ranges ) .",
    "therefore , in this way one can also consider a model with three exchangeable groups : control , odd numbered exchangeable members and even numbered exchangeable members .",
    "this idea leads to the following pdf of the forecasted wind speed  @xmath6 : @xmath21 where for weights  @xmath22 $ ]  we have @xmath23 ,  while the definition of the pdf @xmath24  and of the parameters  @xmath25  and  @xmath11   remains the same as for the model .",
    "obviously , both the weights and the parameters can be estimated in the same way as before .    to 9 truecm ( a ) ( b )    to 9 truecm ( c ) ( d )    similarly to the two - group case , we also investigate model with additive bias correction ( @xmath26 )  and without bias correction at all ( @xmath27  and  @xmath26 )",
    ". we also remark , that according to our experiments with the current data set , the use of different variance parameters for the different groups in models and does not lead to a significant improvement in the performance of the corresponding forecasts .    as an illustration we consider the data and forecasts for debrecen for two different dates 24.11.2010 and 21.12.2010 illustrating two typical situations for models and with linear bias correction .",
    "figures [ fig : fig3]a and [ fig : fig3]b show the pdfs of the two groups in model , the overall pdfs , the median forecasts , the verifying observations , the first and last deciles and the ensemble members . the same functions and quantities can be seen in figures [ fig : fig3]c and [ fig : fig3]d , where in addition to the overall pdf we have the three component pdfs and three groups of ensemble members .",
    "on 24.11.2010 the spread of the ensemble members is reasonable ( the ensemble range equals 3.3 k ) but all ensemble members underestimate the validating observation ( 279.9 k ) .",
    "obviously the same holds for the ensemble median ( 276.9 k ) , while bma median forecasts corresponding to the two- and three - group models ( 279.8 k and 280.0 k , respectively ) are quite close to the true temperature .",
    "a different situation is illustrated on figures [ fig : fig3]b and [ fig : fig3]d , where the ensemble range is only 1.4 k , but it contains the validating observation ( 274.3 k ) . the ensemble median ( 273.5 k ) slightly underestimates the true temperature , but the bma post - processing yields more accurate estimators also in this case .",
    "the median forecasts corresponding to models and are 273.8 k and 273.7 k , respectively .    in order to check the performance of probabilistic forecasts based on models and and the corresponding point forecasts , as a reference we use the ensemble mean and the ensemble median .",
    "we compare the mean absolute error ( mae ) and the root mean square error ( rmse ) of these point forecasts and also the mean continuous ranked probability score ( crps ) @xcite and the coverage and average width of @xmath28 central prediction intervals of the bma predictive probability distributions and of the raw ensemble .",
    "the coverage of this central prediction interval allows a direct comparison to the raw ensemble , where the ensemble of forecasts corresponding to a given location and time is considered as a statistical sample and the sample quantiles are calculated according to ( * ? ? ?",
    "* definition 7 ) .",
    "we remark that for mae and rmse the optimal point forecasts are the median and the mean , respectively @xcite .",
    "further , given a cumulative distribution function ( cdf )  @xmath29  and a real number  @xmath6 ,  the crps is defined as @xmath30 the mean crps of a probability forecast is the average of the crps values of the predictive cdfs and corresponding validating observations taken over all locations and time points considered .",
    "for the raw ensemble the empirical cdf of the ensemble replaces the predictive cdf .",
    "the coverage of a  @xmath31  central prediction interval is the proportion of validating observations located between the lower and upper @xmath32  quantiles of the predictive distribution . for a calibrated predictive pdf",
    "this value should be around  @xmath33 .",
    "modeling and analysis of temperature data was performed with the help of the ensemblebma package in r @xcite . as a first step the length of the appropriate training period",
    "was determined , then the performances of the bma post - processed ensemble forecasts corresponding to models and were analyzed .",
    "similarly to @xcite and @xcite to determine the length of the training period to be used we compare the mae values of bma median forecasts , the rmse values of bma mean forecasts , the crps values of bma predictive distributions and the coverages and average widths of @xmath28 bma central prediction intervals for training periods of length  @xmath34  calendar days . in order to ensure the comparability of the results we consider verification results from 02.12.2010 to 25.03.2011 ( 114 days ; being after the maximum training period length ) .",
    "consider first the two - group model . in figure",
    "[ fig : fig4 ] the crps values of bma predictive distributions , mae values of bma median forecasts and rmse values of bma mean forecasts for different bias correction methods ( black : linear ; blue : additive ; red : no bias correction ) are plotted against the length of the training period .",
    "first of all it is noticeable that the results are very consistent for each diagnostics , i.e. the curves are similar for all measures .",
    "the best verification scores are obtained without any bias correction : the crps , mae and rmse values are rather constant ( on low values ) with respect to the length of the training period , their relative standard deviations are @xmath35 , @xmath36 and @xmath37 , respectively . in case of linear bias correction",
    "the values of all diagnostics are decreasing with the increase of the length of the training period reaching their minima around the 3235 days interval ( there is an increase afterwards ) .",
    "particularly , crps , mae and rmse take their minima at day 33 , the corresponding values are @xmath38 , @xmath39 and @xmath40 , respectively . for additive bias correction",
    "the patterns of the curves are very similar to that of the linear case .",
    "the minima of crps ( @xmath41 ) and rmse ( @xmath42 ) are also reached at 33 days , while mae takes its minimum of @xmath43 at 34 days ( the value at day 33 is very near to this minimum , in fact that is the second smallest one ) .",
    "furthermore , figure [ fig : fig5 ] shows the average width and coverage of the @xmath28 central prediction interval for different bias correction methods as a function of the training period length . concerning the average width the worst results ( largest values )",
    "are obtained for model without bias correction and , similarly to the previous diagnostics , the curve is rather flat .",
    "the linear bias correction results in the narrowest prediction intervals , the average width is increasing until around 50 days , then shows a slight decreasing trend , so up to 48 days , shorter training periods yield sharper estimates .",
    "a similar behaviour can be observed in the case of additive bias correction ( the maximum is reached at around 40 days ) .",
    "as far as the coverage values are concerned , unfortunately , none of the considered models result in coverage reaching the nominal value of @xmath28 ( dashed line )",
    ". however , the case without bias correction is the best having its maximal value at day 40 with @xmath44 . until that day",
    "the coverage values are slightly increasing and then decreasing afterwards ( although the curve is rather flat again ) .",
    "the linear bias correction is starting from the lowest value and reaching its maxima in the period of 3040 days ( actually , the maximum is at day 40 , but the values at these 10 days are very similar ) .",
    "the additive bias correction starts higher and reaches its plateau at around day 30 keeping its rather constant values until the end of the examined periods .",
    "the maximum coverage values of the two bias corrected cases are slightly below @xmath45 , the additive one being better with a small margin . comparing the average width and coverage",
    "it can be noticed that they have opposite behaviour , i.e. the average width values favour shorter training periods , while the coverage figures prefer longer ones",
    ". a reasonable compromise should be found , which is at the range of 2040 days .",
    "all in all for all three versions of model a 33 days training period seems to be a reasonable choice ( particularly see conclusions based on figure [ fig : fig4 ] , which are not compromised by the other two diagnostics at figure [ fig : fig5 ] ) .",
    "the same conclusion can be drawn from figures [ fig : fig6 ] and [ fig : fig7 ] for the variants of the three - group model .",
    "the overall behaviour of the different systems for the various diagnostics is very similar to that for the two - group model .",
    "the no bias correction option provides the best results all over the time periods in 4 of the 5 diagnostics ( the exception is the average width ) .",
    "the additive bias correction slightly outperforms the linear one ( except in terms of average width ) . in terms of specific values",
    "the minima for crps , mae and rmse , respectively , are reached again at day 33 for the linear and additive bias corrections . regarding the average width",
    "the values are increasing until day 30 and then they are rather constant until day 50 and decreasing afterwards . for the coverage the period of highest values are between days 30 and 40 ( having another maximum of similar value for the additive bias correction at the end of the period ) .",
    "hence , the training period proposed for the two - group model can be kept for the three - group model as well , so we suggest the use of a training period of length 33 days for all the investigated bma models .      according to the results of the previous subsection , to test the performance of bma post - processing on the 11 member aladin - huneps ensemble we use a training period of 33 calendar days . in this way",
    "ensemble members , validating observations and bma models are available for the period 04.11.2010  25.03.2011 ( just after the 33 days training period having 141 calendar days , since on 20.11.2010 all ensemble members are missing ) .",
    "to get a first insight about the calibration of bma post - processed forecasts we consider probability integral transform ( pit ) histograms .",
    "the pit is the value of the predictive cumulative distribution evaluated at the verifying observations @xcite , which is providing a good measure about the possible improvements of the under - dispersive character of the raw ensemble .",
    "the closer the histogram is to the uniform distribution , the better the calibration is . in figure",
    "[ fig : fig8 ] the pit histograms corresponding to all three versions of two- and three - group bma models and are displayed .",
    "a comparison to the verification rank histogram of the raw ensemble ( see figure [ fig : fig1 ] ) shows that post - processing significantly improves the statistical calibration of the forecasts .",
    "however , in case of linear bias correction both pit histograms are slightly under - dispersive , while for models with additive bias correction and without bias correction one can accept uniformity .",
    "the latter statement can be also derived from table [ tab : tab1 ] where the significance levels of kolmogorov - smirnov tests for uniformity of the pit values are listed . based on these tests",
    "it can be concluded that the additive bias correction produces the best pit histograms ( the no bias correction case is just slightly worse ) .",
    ".significance levels of kolmogorov - smirnov tests for uniformity of pit values corresponding to models and . [ cols=\"<,^,^,^ \" , ]     figure [ fig : fig10 ] shows the bma weights of the control member @xmath15  in three variants of the two - group model . in case of linear bias correction we have a real mixture in @xmath46 of the forecasted days ( none of the groups has a weight which is almost 1 , e.g. above @xmath47 ) , while for additive bias correction and for model without bias correction this rate equals @xmath48 and @xmath49 , respectively .",
    "the values of  @xmath15  that are close to 1 in all three cases correspond to a time interval 18.02.2011  08.03.2011 , when the control member of the ensemble gives much better forecasts than the ten exchangeable ensemble members ( this can be clearly seen from table [ tab : tab4 ] where the mae and rmse values of the particular ensemble members are given for the above mentioned period ) .",
    "this special behaviour is therefore correctly diagnosed by the calibration with the provision of large weights for the control member .",
    "furthermore , for model with linear bias correction there is a long period between 29.12.2010 and 16.01.2011 where  @xmath50 ( which means that the control is practically not used for the calibration ) , but in the other two cases this phenomenon practically disappears .",
    "the average mae and rmse values for that period are also displayed for each ensemble member ( see table [ tab : tab5 ] ) .",
    "it can be seen that the control member is not really worse than the other ones ( it outperforms around half of the members ) , which is correctly `` recognized '' by the additive and no bias correction techniques .",
    "finally , figure [ fig : fig11 ] shows the bma weights of the control and of the odd and even ensemble members corresponding to the three variants of the three - group model . in case of linear and additive bias correction on a part of the problematic period 18.02.2011",
    " 08.03.2011 ( between 20.02.2011 and 05.03.2011 ) the weight  @xmath51  of the control is still close to @xmath52 ( greater than @xmath53 ) , while for the model without bias correction this happens only on four days . in the remaining cases ( @xmath54 , @xmath55 and @xmath56 of the days , respectively ) we have real mixtures of normal distributions ( it is particularly remarkable for the no bias correction ) . on the other hand for the period ,",
    "when the control gets zero weight in the linear bias correction it is again ( correctly ) partly disappearing in the additive and no bias correction cases .",
    "in the present study the bma ensemble post - processing method is applied to the 11 member aladin - huneps ensemble of the hms to obtain 42 hour calibrated predictions for 2 m temperature .",
    "two different bma models are investigated , one assumes two groups of exchangeable members ( control and forecasts from perturbed initial conditions ) , while the other considers three ( control and forecasts from perturbed initial conditions with positive and negative perturbations ) . in both cases",
    "three different treatments of bias are considered ( linear and additive bias correction and no bias correction at all ) and for all models a 33 days training period is suggested .",
    "the comparison of the raw ensemble and of the probabilistic forecasts shows that the mean crps values of bma post - processed forecasts are considerably lower than the mean crps of the raw ensemble , while there is no big change in the mae and rmse values of bma point forecasts ( median and mean ) compared to the mae and rmse of the ensemble median and of the ensemble mean .",
    "this latter fact might mean that although the spread of the raw ensemble was too small , the median and mean of the point forecasts were sufficiently correct not having too much space for further improvement .",
    "it is remarkable to notice that the real probabilistic forecasts as demonstrated by the probability of freezing for debrecen have been significantly improved . for models with additive bias correction and without bias correction",
    "the coverage of the @xmath28 central prediction interval is rather close to the nominal value , while their pit values fit the uniform distribution . from the six competing post - processing methods the overall performance of the three - group model without bias correction seems to be the best , while models with linear bias correction give the worst results .",
    "finally , we conclude that bma post - processing of the aladin - huneps temperature ensemble forecasts significantly improves the calibration and the probabilistic forecasts , however no significant changes are found in accuracy of point forecasts .",
    "the first two aspects encourage the operational application of the method , while the third one calls for some further investigations to see whether improvements can be made for the point forecasts as well .    *",
    "acknowledgments . *",
    "research was supported by the hungarian scientific research fund under grant no .",
    "otka nk101680 and by the tmop-4.2.2.c-11/1/konv-2012 - 0001 project .",
    "the project has been supported by the european union , co - financed by the european social fund .",
    "the authors are indebted to tilmann gneiting for his useful suggestions and remarks and to mt mile and mihly szcs from the hms for providing the data .    99 bao , l. , gneiting , t. , raftery , a. e. , grimit , e. p. and guttorp , p. ( 2010 ) bias correction and bayesian model averaging for ensemble forecasts of surface wind direction . _",
    "rev . _ * 138 * , 18111821 .",
    "descamps , l. , labadier , c. , joly , a. and nicolau , j. ( 2009 ) ensemble prediction at mto france ( poster introduction by olivier riviere ) _ 31st ewglam and 16th srnwp meetings , _",
    "28th september ",
    "1st october , 2009 .",
    "available at : http://srnwp.met.hu/annual_meetings/2009/download/sept29/morning/posterpearp.pdf    fraley , c. , raftery , a. e. , gneiting , t. and sloughter , j. m. ( 2009 ) ensemblebma : an r package for probabilistic forecasting using ensembles and bayesian model averaging .",
    "_ technical report _",
    "516r , department of statistics , university of washington .",
    "available at : www.stat.washington.edu/research/reports/2008/tr516.pdf                  hornyi , a , kertsz , s. , kullmann , l. and radnti , g. ( 2006 ) the arpege / aladin mesoscale numerical modeling system and its application at the hungarian meteorological service .",
    "_ i d ojrs _ * 110 * , 203227 ."
  ],
  "abstract_text": [
    "<S> weather forecasting is mostly based on the outputs of deterministic numerical weather forecasting models . </S>",
    "<S> multiple runs of these models with different initial conditions result in forecast ensembles which is are used for estimating the distribution of future atmospheric variables . </S>",
    "<S> however , these ensembles are usually under - dispersive and uncalibrated , so post - processing is required .    in the present work bayesian model averaging ( bma ) </S>",
    "<S> is applied for calibrating ensembles of temperature forecasts produced by the operational limited area model ensemble prediction system of the hungarian meteorological service ( hms ) .    </S>",
    "<S> we describe two possible bma models for temperature data of the hms and show that bma post - processing significantly improves calibration and probabilistic forecasts although the accuracy of point forecasts is rather unchanged .    _ </S>",
    "<S> key words : _ bayesian model averaging , continuous ranked probability score , ensemble calibration , normal distribution . </S>"
  ]
}