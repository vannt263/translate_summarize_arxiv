{
  "article_text": [
    "this paper studies the following panel data models with unobservable interactive effects : @xmath0 where @xmath1 is the dependent variable ; @xmath2 is a row vector of explanatory variables ; @xmath3 is an intercept ; the term @xmath4 is unobservable and has a factor structure , @xmath5 is an @xmath6 vector of factor loadings , @xmath7 is a vector of factors and @xmath8 is the idiosyncratic error .",
    "the interactive effects ( @xmath9 ) generalize the usual additive individual and time effects ; for example , if @xmath10 , then @xmath11 .",
    "a key feature of the model is that the regressors @xmath12 are allowed to be correlated with @xmath13 .",
    "this situation is commonly encountered in economics and other social sciences , in which some of the regressors @xmath12 are decision variables that are influenced by the unobserved individual heterogeneities .",
    "the practical relevance of the model will be further discussed below .",
    "the objective of this paper is to obtain consistent and efficient estimation of @xmath14 in the presence of correlations between the regressors and the factor loadings and factors .",
    "the usual pooled least squares estimator or even the within - group estimator is inconsistent for @xmath15 .",
    "one method to obtain a consistent estimator is to treat @xmath16 as parameters and estimate them jointly with @xmath15 .",
    "the idea is `` controlling through estimating '' ( controlling the effects by estimating them ) .",
    "this is the approach used in @xcite and @xcite . while there are some advantages , an undesirable consequence of this approach is the incidental parameters problem .",
    "there are too many parameters being estimated , and the incidental parameters bias arises ; see @xcite . in @xcite and @xcite",
    "the authors consider the generalized method of moments ( gmm ) method .",
    "the gmm method is based on a nonlinear transformation known as quasi - differencing that eliminates the factor errors .",
    "quasi - differencing increases the nonlinearity of the model especially with more than one factor .",
    "the gmm method works well with a small @xmath17 .",
    "when @xmath17 is large , the number of moment equations will be large , and the so called many - moment bias arises . in @xcite , the author considers an alternative method by augmenting the model with additional regressors @xmath18 and @xmath19 , which are the cross - sectional averages of @xmath1 and @xmath12 .",
    "these averages provide an estimate for @xmath7 .",
    "the estimator of @xcite becomes inconsistent when the factor loadings in the @xmath20 equation are correlated with those in the @xmath21 equation , as shown in @xcite .",
    "a further approach to controlling the correlation between the regressors and factor errors is to use the mundlak",
    " chamberlain projection ( @xcite and  @xcite ) .",
    "the latter method projects @xmath3 and @xmath5 onto the regressors such that @xmath22 , where @xmath23 ( @xmath24 are parameters to be estimated , and @xmath25 is the projection residual ( a similar projection is done for  @xmath3 ) .",
    "the projection residuals are uncorrelated with the regressors so that a variety of approaches can be used to estimate the model .",
    "this framework is designed for small @xmath17 and is studied by @xcite .    in this paper",
    "we consider the pseudo - gaussian maximum likelihood method under large @xmath26 and large @xmath17 .",
    "the theory does not depend on normality . in view of the importance of the mle in the statistical literature ,",
    "it is of both practical and theoretical interest to examine the mle in this context .",
    "we develop a rigorous theory for the mle .",
    "we show that there is no incidental parameters bias for @xmath15 .",
    "we allow time - invariant regressors such as education , race and gender in the model .",
    "the corresponding regression coefficients are time - dependent .",
    "similarly , we allow common regressors , which do not vary across individuals , such as prices and policy variables .",
    "the corresponding regression coefficients are individual - dependent so that individuals respond differently to policy or price changes . in our view , this is a sensible way to incorporate time - invariant and common regressors . for example , wages associated with education and with gender are more likely to change over time rather than remain constant . in our analysis , time invariant regressors are treated as the components of @xmath5 that are observable , and common regressors as the components of @xmath7 that are observable .",
    "this view fits naturally into the factor framework in which part of the factor loadings and factors are observable , and the maximum likelihood method imposes the corresponding loadings and factors at their observed values .    while the theoretical analysis of mle is demanding , the limiting distributions of the mle are simple and have intuitive interpretations .",
    "the computation is also easy and can be implemented by adapting the ecm ( expectation and constrained maximization ) of @xcite .",
    "in addition , the maximum likelihood method allows restrictions to be imposed on @xmath5 or on @xmath7 to achieve more efficient estimation .",
    "these restrictions can take the form of known values , being either zeros , or other fixed values .",
    "part of the rigorous analysis includes setting up the constrained maximization as a lagrange multiplier problem .",
    "this approach provides insight into which kinds of restrictions provide efficiency gain and which kinds do not .",
    "panel data models with interactive effects have wide applicability in economics . in macroeconomics , for example , @xmath1 can be the output growth rate for country @xmath27 in year @xmath28 ; @xmath12 represents production inputs , and @xmath7 is a vector of common shocks ( technological progress , financial crises ) ; the common shocks have heterogenous impacts across countries through the different factor loadings @xmath5 ; @xmath8 represents the country - specific unmeasured growth rates . in microeconomics , and especially in earnings studies",
    ", @xmath1 is the wage rate for individual @xmath27 for period @xmath28 ( or for cohort @xmath28 ) , @xmath12 is a vector of observable characteristics such as marital status and experience ; @xmath5 is a vector of unobservable individual traits such as ability , perseverance , motivation and dedication ; the payoff to these individual traits is not constant over time , but time varying through @xmath7 ; and @xmath8 is idiosyncratic variations in the wage rates . in finance",
    ", @xmath1 is stock @xmath27 s return in period @xmath28 , @xmath12 is a vector of observable factors , @xmath7 is a vector of unobservable common factors ( systematic risks ) and @xmath5 is the exposure to the risks ; @xmath8 is the idiosyncratic returns .",
    "factor error structures are also used as a flexible trend modeling as in @xcite .",
    "most of panel data analysis assumes cross - sectional independence ; see , for example , @xcite and @xcite .",
    "the factor structure is also capable of capturing the cross - sectional dependence arising from the common shocks @xmath7 .",
    "further motivation can be found in @xcite .    throughout the paper",
    ", the norm of a vector or matrix is that of frobenius , that is , @xmath29^{1/2}$ ] for matrix @xmath30 ; @xmath31 is a column vector consisting of the diagonal elements of @xmath30 when @xmath30 is matrix , but @xmath31 represents a diagonal matrix when @xmath30 is a vector .",
    "in addition , we use @xmath32 to denote @xmath33 for any column vector @xmath34 and @xmath35 to denote @xmath36 for any vectors @xmath37 and @xmath38 .",
    "the rest of the paper is organized as follows .",
    "section  [ sec2 ] introduces a common shock model and the maximum likelihood estimation .",
    "consistency , rate of convergence and the limiting distributions of the mle are established .",
    "section  [ sec3 ] shows that if some factors do not affect the @xmath20 equation but only the @xmath21 equation , more efficient estimation can be obtained .",
    "section  [ sec4 ] extends the analysis to time - invariant regressors and common regressors ; the corresponding coefficients are time varying and cross - section varying , respectively .",
    "computing algorithm is discussed in section  [ sec5 ] , and simulations results are reported in section  [ sec6 ] .",
    "the last section concludes .",
    "the theoretical proofs are provided in the supplementary document @xcite .",
    "in the common - shock model , we assume that both @xmath1 and @xmath12 are impacted by the common shocks @xmath7 so the model takes the form @xmath39\\\\[-8pt ] x_{itk}&=&\\mu_{ik}+\\gamma_{ik}'f_t+v_{itk}\\nonumber\\end{aligned}\\ ] ] for @xmath40 . in across - country output studies , for example , output @xmath1 and inputs @xmath12 ( labor and capital )",
    "are both affected by the common shocks .",
    "the parameter of interest is @xmath41 .",
    "we also estimate @xmath42 and @xmath43 @xmath44 . by treating the latter as parameters",
    ", we also allow arbitrary correlations between @xmath45 and @xmath46 . although we also treat @xmath7 as fixed parameters , there is no need to estimate the individual @xmath7 , but only the sample covariance of @xmath7 .",
    "this is an advantage of the maximum likelihood method , which eliminates the incidental parameters problem in the time dimension .",
    "this kind of the maximum likelihood method was used for pure factor models in @xcite and  @xcite . by symmetry",
    ", we could also estimate individuals @xmath7 , but then we only estimate the sample covariance of the factor loadings .",
    "the idea is that we do not simultaneously estimate the factor loadings and the factors @xmath7 ( which would be the case for the principal components method ) .",
    "this reduces the number of parameters considerably .",
    "if @xmath26 is much smaller than @xmath17 @xmath47 , treating factor loadings as parameters is preferable since there are fewer parameters .",
    "because of the correlation between the regressors and regression errors in the @xmath20 equation , the @xmath20 and @xmath21 equations form a simultaneous equation system ; the mle jointly estimates the parameters in both equations .",
    "the joint estimation avoids the mundlak ",
    "chamberlain projection and thus is applicable for large @xmath26 and large @xmath17 .",
    "we assume the number of factors @xmath48 is fixed and known . determining the number of factors",
    "is discussed in section  [ sec6 ] , where a modified information criterion proposed by @xcite is used .",
    "let @xmath49 , @xmath50 , @xmath51 and @xmath52 .",
    "the second equation of ( [ comshkmaineq1 ] ) can be written in matrix form as @xmath53 further let @xmath54 , @xmath55 , @xmath56 , @xmath57",
    ". then model ( [ comshkmaineq1 ] ) can be written as @xmath58z_{it}= \\mu_i+\\gamma_i'f_t+ \\varepsilon_{it}.\\ ] ] let @xmath59 denote the coefficient matrix of @xmath60 in the preceding equation .",
    "let @xmath61 , @xmath62 , @xmath63 and @xmath64 . stacking the equations over @xmath27",
    ", we have @xmath65 to analyze this model , we make the following assumptions .",
    "[ assa ] the factor process @xmath7 is a sequence of constants .",
    "let @xmath66 , where @xmath67 .",
    "we assume that @xmath68 is a strictly positive definite matrix .",
    "the nonrandomness assumption for @xmath7 is not crucial .",
    "in fact , @xmath7 can be a sequence of random variables such that @xmath69 uniformly in @xmath28 , and @xmath7 is independent of @xmath70 for all @xmath71 .",
    "the fixed @xmath7 assumption conforms with the usual fixed effects assumption in panel data literature and , in certain sense , is more general than random @xmath7 .",
    "[ assb ] the idiosyncratic errors @xmath72 are such that :    the @xmath8 is independent and identically distributed over @xmath28 and uncorrelated over @xmath27 with @xmath73 and @xmath74 for all @xmath75 and @xmath76 .",
    "let @xmath77 denote the variance of @xmath8 .",
    "@xmath78 is also independent and identically distributed over @xmath28 and uncorrelated over @xmath27 with @xmath79 and @xmath80 for all @xmath75 and @xmath76 .",
    "we use @xmath81 to denote the variance matrix of @xmath78 .",
    "@xmath8 is independent of @xmath82 for all @xmath83 .",
    "let @xmath84 denote the variance matrix @xmath85 .",
    "so we have @xmath86 , a block - diagonal matrix .",
    "let @xmath87 denote the variance of @xmath88 .",
    "due to the uncorrelatedness of @xmath85 over @xmath27 , we have @xmath89 , a block - diagonal matrix .",
    "assumption  [ assb ] is more general than the usual assumption in the factor analysis . in a traditional factor model ,",
    "the variances of the idiosyncratic error terms are assumed to be a diagonal matrix . in the present setting ,",
    "the variance of @xmath90 is a block - diagonal matrix . even without explanatory variables ,",
    "this generalization is of interest .",
    "the factor analysis literature has a long history to explore the block - diagonal idiosyncratic variance , known as multiple battery factor analysis ; see @xcite .",
    "the maximum likelihood estimation theory for high - dimensional factor models with block diagonal covariance matrix has not been previously studied . the asymptotic theory developed in this paper not only provides a way of analyzing the coefficient @xmath14 , but also a way of analyzing the factors and loadings in the multiple battery factor models .",
    "this framework is of independent interest .",
    "[ assc ] there exists a @xmath91 sufficiently large such that :    @xmath92 for all @xmath93 ;    @xmath94 for all @xmath93 , where @xmath95 and @xmath96 denote the smallest and largest eigenvalues of the matrix  @xmath97 , respectively ;    there exists an @xmath98 positive matrix @xmath99 such that @xmath100 where @xmath101 is defined earlier .    [ assd ] the variances @xmath84 for all @xmath27 and @xmath102 are estimated in a compact set , that is , all the eigenvalues of @xmath103 and @xmath104 are in an interval @xmath105 $ ] for a sufficiently large constant @xmath106 .",
    "it is a well - known result in factor analysis that the factors and loadings can only be identified up to a rotation ; see , for example , @xcite .",
    "the models considered in this paper can be viewed as extensions of the factor models . as such",
    "they inherit the same identification problem .",
    "we show that identification conditions can be imposed on the factors and loadings without loss of generality . to see this , model ( [ comshkmaineq2 ] )",
    "can be rewritten as @xmath107 \\bigl[r'm_{f f}^{-1/2}(f_t- \\bar f)\\bigr]+\\varepsilon_t,\\ ] ] where @xmath108 is an orthogonal matrix , which we choose to be the matrix consisting of the eigenvectors of @xmath109 associated with the eigenvalues arranged in descending order . treating @xmath110 as the new @xmath111 , @xmath112 as the new @xmath113 and @xmath114 as the new @xmath115",
    ", we have @xmath116 with @xmath117 and @xmath118 being a diagonal matrix .",
    "thus we impose the following restrictions for model ( [ comshkmaineq2 ] ) , which we refer to as ( _ identification _ restrictions for _ basic _ models ) .",
    "@xmath119 ;    @xmath120 , where @xmath121 is a diagonal matrix with its diagonal elements distinct and arranged in descending order ;    @xmath122 .",
    "the objective function considered in this section is @xmath123,\\ ] ] where @xmath124 and @xmath125 .",
    "the latter is the data matrix .",
    "the parameters are @xmath126 .",
    "the mle is defined as @xmath127 where the parameter space @xmath128 is defined to be a closed and bounded subset containing the true parameter @xmath129 as an interior point ; @xmath87 and @xmath102 are positive definite matrices , as in assumption  [ assd ] .",
    "the boundedness of @xmath128 implies that the elements of @xmath15 and @xmath101 are bounded .",
    "this is for theoretical purpose and is usually assumed for nonconvex optimizations , as in @xcite and @xcite . in actual computation with the em algorithm , we do not find the need to impose an upper or lower bound for the parameter values .",
    "the likelihood function involves simple functions and are continuous on @xmath128 ( in fact differentiable ) , so the mle @xmath130 exists because a continuous function achieves its extreme value on a closed and bounded subset .",
    "note that the determinant of @xmath131 is 1 , so the jacobian term does not depend on @xmath59 .",
    "if @xmath90 and @xmath7 are independent and normally distributed , the likelihood function for the observed data has the form of ( [ comshkmaineq3 ] ) . here recall that @xmath7 are fixed constants , and @xmath90 are not necessarily normal ; ( [ comshkmaineq3 ] ) is a pseudo - likelihood function .    for further analysis , we partition the matrix @xmath132 and @xmath133 as @xmath134 where for any @xmath135 , @xmath136 and @xmath137 are both @xmath138 matrices .",
    "let @xmath139 and @xmath140 denote the mle .",
    "the first order condition for @xmath15 satisfies @xmath141 \\biggr\\}\\dot x_{it}=0,\\hspace*{-35pt}\\ ] ] where @xmath142 .",
    "the first order condition for @xmath143 satisfies @xmath144 post - multiplying @xmath145 on both sides of ( [ comshkmaineq5 ] ) and then taking summation over @xmath146 , we have @xmath147 the first order condition for @xmath84 satisfies @xmath148 where @xmath149 is a @xmath138 matrix such that its upper - left @xmath150 and lower - right @xmath151 submatrices are both zero , but the remaining elements are undetermined .",
    "the undetermined elements correspond to the zero elements of @xmath84 .",
    "these first order conditions are needed for the asymptotic representation of the mle .",
    "theorem [ comshkthm2 ] states the convergence rates of the mle .",
    "the consistency is implied by the theorem .",
    "[ comshkthm2 ] let @xmath152 be the solution by maximizing ( [ comshkmaineq3 ] ) . under assumptions  [ assa][assd ] and the identification conditions , we have @xmath153    bai @xcite considers an iterated principal components estimator for model ( [ comshkmaineq1 ] ) .",
    "his derivation shows that , in the presence of heteroscedasticities over the cross section , the pc estimator for @xmath15 has a bias of order @xmath154 . as a  comparison , theorem [ comshkthm2 ] shows that the mle is robust to the heteroscedasticities over the cross section .",
    "so if @xmath26 is fixed , the estimator in @xcite is inconsistent unless there is no heteroskedasticity , but the estimator here is still .",
    "let @xmath155 denote the project matrix onto the space orthogonal to @xmath156 , that is , @xmath157 .",
    "we have    [ comshkthm3 ] under the assumptions of theorem [ comshkthm2 ] , we have @xmath158 where @xmath159 is a @xmath151 matrix whose @xmath160 element @xmath161 with @xmath162 being the @xmath160 element of matrix @xmath81 .",
    "[ rmk25 ] in appendix  a.3 of the supplement  @xcite , we show that the asymptotic expression of @xmath163 can be alternatively expressed as @xmath164 & \\cdots & \\operatorname{tr}\\bigl[\\ddot mx_1\\mathcal{m}(\\widebar{\\mathbb f } ) x_k ' \\bigr ] \\vspace*{3pt}\\cr \\vdots & \\vdots & \\vdots \\vspace*{3pt}\\cr \\operatorname{tr}\\bigl[\\ddot mx _",
    "k\\mathcal { m}(\\widebar{\\mathbb f})x_1 ' \\bigr ] & \\cdots&\\operatorname{tr}\\bigl[\\ddot mx _ k\\mathcal { m}(\\widebar{\\mathbb f } ) x _ k ' \\bigr]}^{-1 } \\nonumber\\\\[20pt]\\\\[-30pt ] & & { } \\times\\pmatrix { \\operatorname{tr}\\bigl[\\ddot mx_1\\mathcal{m}(\\widebar{\\mathbb f } ) e ' \\bigr ] \\vspace*{3pt}\\cr \\vdots \\vspace*{3pt}\\cr \\operatorname{tr}\\bigl[\\ddot mx _ k\\mathcal{m}(\\widebar{\\mathbb f } ) e'\\bigr]}\\nonumber \\\\ & & { } + o_p \\bigl(t^{-3/2}\\bigr)+o_p\\bigl(n^{-1}t^{-1/2}\\bigr)+o_p\\bigl(n^{-1/2}t^{-1}\\bigr),\\nonumber\\end{aligned}\\ ] ] where @xmath165 is @xmath166 ( the data matrix for the @xmath167th regressor , @xmath168 ) ; @xmath169 is @xmath166 ; @xmath170 with @xmath171 and @xmath172 ; @xmath173 ; @xmath174 where @xmath175 is a @xmath176 vector with all 1 s .    theorem [ comshkthm3 ] shows that the asymptotic expression of @xmath163 only involves variations in @xmath8 and @xmath78 .",
    "intuitively , this is due to the fact that the error terms of the @xmath20 equation share the same factors with the explanatory variables .",
    "the variations from the common factor part of @xmath177 ( i.e. , @xmath178 ) do not provide information for @xmath15 since this part of information is offset by the common factor part of the error terms ( i.e. , @xmath9 ) in the @xmath20 equation .",
    "[ comshkthm4 ] under the assumptions of theorem  [ comshkthm3 ] , if @xmath179 , we have @xmath180 where @xmath181 , and @xmath182 is also the limit of @xmath183 & \\cdots & \\operatorname{tr}\\bigl[\\ddot mx_1\\mathcal{m } ( \\widebar{\\mathbb f } ) x_k ' \\bigr ] \\vspace*{3pt}\\cr \\vdots & \\vdots & \\vdots \\vspace*{3pt}\\cr \\operatorname{tr}\\bigl[\\ddot mx _ k\\mathcal { m}(\\widebar{\\mathbb f})x_1 ' \\bigr ] & \\cdots&\\operatorname{tr}\\bigl[\\ddot mx _ k\\mathcal { m}(\\widebar{\\mathbb f } ) x _ k ' \\bigr]}.\\ ] ]    [ remark2 ] matrix @xmath182 can be consistently estimated by @xmath184 & \\cdots & \\operatorname{tr}\\bigl[\\widehat{\\ddot m}x_1\\mathcal{m}(\\widehat{\\widebar{\\mathbb f } } ) x_k ' \\bigr ] \\vspace*{3pt}\\cr \\vdots & \\vdots & \\vdots \\vspace*{3pt}\\cr \\operatorname{tr}\\bigl[\\widehat{\\ddot m}x_k\\mathcal{m}(\\widehat{\\widebar{\\mathbb f}})x_1 ' \\bigr ] & \\cdots & \\operatorname{tr}\\bigl[\\widehat{\\ddot m}x_k\\mathcal { m}(\\widehat{\\widebar{\\mathbb f } } ) x _ k ' \\bigr]},\\ ] ] where @xmath185 is the @xmath166 data matrix for the @xmath167th regressor , @xmath186 @xmath187 with @xmath188 and @xmath189 here @xmath190 and @xmath191 are the maximum likelihood estimators .",
    "the basic model in section  [ sec2 ] assumes that the explanatory variables @xmath12 share the same factors with @xmath1 .",
    "this section relaxes this assumption .",
    "we assume that the regressors are impacted by additional factors that do not affect the @xmath20 equation .",
    "an alternative view is that some factor loadings in the @xmath20 equation are restricted to be zero .",
    "consider the following model : @xmath192 \\\\[-8pt ] x_{itk}&=&\\mu_{ik}+\\gamma_{ik}^{g\\prime}g_t+ \\gamma_{ik}^{h\\prime } h_t+v_{itk } \\nonumber\\end{aligned}\\ ] ] for @xmath40 , where @xmath193 is an @xmath194 vector representing the shocks affecting both @xmath1 and @xmath12 , and @xmath195 is an @xmath196 vector representing the shocks affecting @xmath12 only .",
    "let @xmath197 , @xmath198 and @xmath199 , the above model can be written as @xmath200 which is the same as model ( [ comshkmaineq1 ] ) except that @xmath201 elements of @xmath5 are restricted to be zeros .",
    "for further analysis , we introduce some notation .",
    "we define @xmath202 we also define @xmath203 and @xmath204 similarly as @xmath205 , that is , @xmath206 , @xmath207 .",
    "this implies that @xmath208 .",
    "the presence of zero restrictions in ( [ zerores1 ] ) requires different identification conditions .",
    "zero loading restrictions alleviate rotational indeterminacy . instead of @xmath209 restrictions , we only need to impose @xmath210 restrictions .",
    "these restrictions are referred to as iz restrictions ( _ identification _ conditions with _ zero _ restrictions ) .",
    "they are :    @xmath119 ;    @xmath211 and @xmath212 , where @xmath213 and @xmath214 are both diagonal matrices with distinct diagonal elements in descending order ;    @xmath215 and @xmath216 .",
    "in addition , we need an additional assumption for our analysis .",
    "[ asse ] @xmath217 is of full column rank .",
    "identification conditions iz are less stringent than of the previous section .",
    "assumption  [ asse ] says that the factors @xmath193 are pervasive for the @xmath20 equation . in appendix",
    "b of the supplement  @xcite , we explain why @xmath210 restrictions are sufficient .",
    "the likelihood function is now maximized under three sets of restrictions , that is , @xmath218 , @xmath219 and @xmath220 where @xmath221 denotes the zero factor loading matrix in the @xmath20 equation . the likelihood function with the lagrange multipliers",
    "is @xmath222 \\\\ & & { } + \\operatorname{tr } \\biggl[\\upsilon_1 \\biggl(\\frac{1}{n } \\gamma^{g\\prime } \\sigma_{\\varepsilon \\varepsilon}^{-1}\\gamma^g -d_1 \\biggr ) \\biggr]+\\operatorname{tr } \\biggl[\\upsilon_2 \\biggl(\\frac { 1}{n}\\gamma^{h\\prime}\\sigma _ { \\varepsilon\\varepsilon}^{-1 } \\gamma^h - d_2 \\biggr ) \\biggr ] \\\\ & & { } + \\operatorname { tr}\\bigl [ \\upsilon_3'\\phi\\bigr],\\end{aligned}\\ ] ] where @xmath223 ; @xmath224 is @xmath225 and @xmath226 is @xmath227 , both are symmetric lagrange multipliers matrices with zero diagonal elements ; @xmath228 is a lagrange multiplier matrix of dimension @xmath229 .",
    "let @xmath230\\widehat\\sigma_{z z}^{-1}$ ] .",
    "notice @xmath231 is a symmetric matrix .",
    "the first order condition on @xmath232 gives @xmath233 post - multiplying @xmath232 yields @xmath234 since @xmath235 is a symmetric matrix , the above equation implies that @xmath236 is also symmetric .",
    "but @xmath237 is a diagonal matrix .",
    "so the @xmath135th element of @xmath238 is @xmath239 , where @xmath240 is the @xmath135th element of @xmath224 and @xmath241 is the @xmath146th diagonal element of @xmath242 .",
    "given @xmath243 is symmetric , we have @xmath244 for all @xmath245 .",
    "however , @xmath246 is also symmetric , so @xmath247 .",
    "this gives @xmath248 .",
    "since @xmath249 by iz2 , we have @xmath250 for all @xmath245 .",
    "this implies @xmath251 since the diagonal elements of @xmath224 are all zeros .",
    "let @xmath252 with @xmath253 , and @xmath254 , a block diagonal matrix of @xmath255 dimension .",
    "we partition the matrix @xmath231 and define the matrix @xmath256 as @xmath257 where @xmath258 is a @xmath138 matrix , and @xmath259 is the lower - right @xmath151 block of @xmath260 .",
    "notice @xmath261 is also a symmetric matrix .",
    "then the first order condition on @xmath262 gives @xmath263 post - multiplying @xmath264 yields @xmath265 notice @xmath266 . by the similar arguments in deriving @xmath251",
    ", we have @xmath267 .",
    "the interpretation for the zero lagrange multipliers is that these constraints do not affect the optimal value of the likelihood function nor the efficiency of @xmath268 .",
    "in contrast , we can not show @xmath228 to be zero .",
    "thus the restriction @xmath220 affects the optimal value of the likelihood function and the efficiency of @xmath269 . in section  [ sec2 ] , we did not use the lagrange multiplier approach to analyze the identification restrictions .",
    "had this been done , we would have obtained zero valued lagrange multipliers .",
    "this is another view of why these restrictions do not affect the limiting distribution of @xmath269 .",
    "but these restrictions are needed to remove the rotational indeterminacy .",
    "now the likelihood function is simplified as @xmath270+\\operatorname{tr}\\bigl [ \\upsilon_3'\\phi\\bigr].\\ ] ] the first order condition on @xmath101 is @xmath271\\widehat\\sigma_{z z}^{-1}=w',\\ ] ] where @xmath272 is a matrix having the same dimension as @xmath101 , whose element is zero if the counterpart of @xmath101 is not specified to be zero , otherwise undetermined ( containing the lagrange multipliers ) .",
    "post - multiplying @xmath273 gives @xmath274\\widehat\\sigma_{z z}^{-1}\\widehat\\gamma = w'\\widehat\\gamma.\\ ] ] by the special structure of @xmath272 and @xmath273 , it is easy to verify that @xmath275 has the form @xmath276.\\ ] ] however , the left - hand side of the preceding equation is a symmetric matrix , and so is the right - hand side .",
    "it follows that the subblock `` @xmath277 '' is zero , that is , .",
    "thus , @xmath278\\widehat\\sigma_{z z}^{-1}\\widehat\\gamma=0 $ ] .",
    "( this equation would be the first order condition for @xmath279 if it were unknown . )",
    "this equality can be simplified as @xmath280\\widehat\\sigma_{\\varepsilon\\varepsilon}^{-1}\\widehat\\gamma=0\\ ] ] because @xmath281 with @xmath282 .",
    "next , we partition the matrix @xmath283 and @xmath284 as follows : @xmath285 = { \\left}[\\matrix{\\widehat g_{11 } & \\widehat g_{12 } \\vspace*{3pt}\\cr \\widehat g_{21 } & \\widehat g_{22 } } { \\right } ] , \\qquad \\widehat h= { \\left } [ \\matrix{\\widehat h_1 \\vspace*{3pt}\\cr \\widehat h_2 } { \\right } ] = { \\left}[\\matrix { \\widehat h_{11 } & \\widehat h_{12 } \\vspace*{3pt}\\cr \\widehat h_{21 } & \\widehat h_{22 } } { \\right}],\\ ] ] where @xmath286 are @xmath225 , while @xmath287 are @xmath227",
    ".    notice @xmath288 and @xmath289 .",
    "substitute these results into ( [ extenmaineq1 ] ) , and use ( [ extenmaineq2 ] ) .",
    "the first order condition for @xmath290 can be simplified as @xmath291 where @xmath292 is the first column of the identity matrix of dimension @xmath293 .",
    "similarly , the first order condition for @xmath294 is @xmath295 where @xmath296 is a @xmath297 matrix , obtained by deleting the first column of the identity matrix of dimension @xmath293 .",
    "the first order condition for @xmath97 is @xmath298 \\\\[-8pt ] & & \\qquad { } -\\sum_{i=1}^n \\bigl(\\widehat bm_{z z}^{ji}\\widehat b{}'-\\widehat\\sigma_{z z}^{ji } \\bigr)\\widehat\\sigma_{ii}^{-1}\\widehat\\gamma_i ' \\widehat g\\widehat\\gamma_j=\\mathbb { w } , \\nonumber\\end{aligned}\\ ] ] where @xmath149 is defined following ( [ comshkmaineq7 ] ) .",
    "the first order condition for @xmath15 is @xmath299 \\biggr\\}\\dot x_{it}=0,\\hspace*{-35pt}\\ ] ] which is the same as in section  [ sec2 ] .",
    "we need an additional identity to study the properties of the mle .",
    "recall that , by the special structures of @xmath272 and @xmath273 , the three submatrices of @xmath275 can be directly derived to be zeros .",
    "the remaining submatrix is also zero , as shown earlier .",
    "however , this submatrix being zero yields the following equation ( the detailed derivation is delivered in appendix  f ) : @xmath300 these identities are used to derive the asymptotic representations .",
    "the results on consistency and the rate of convergence are similar to those in the previous section , which are presented in appendixes b.1 and b.2 . for simplicity , we only state the asymptotic representation for the mle here .    [ extenthm1 ] @xmath301under assumptions and the identification restriction iz",
    ", we have @xmath302 where @xmath303 is a @xmath151 symmetric matrix with its @xmath160 element equal to @xmath304 ; @xmath305'$ ] ; @xmath306 $ ] ; @xmath307 and @xmath308 .    proposition [ extenthm1 ] is derived under the identification conditions iz . in appendix",
    "b.3 of the supplement  @xcite , we show that for any set of factors and factor loadings @xmath309 , it can always be transformed into a new set @xmath310 , which satisfies iz , and at the same time , leaving @xmath220 intact .",
    "given the asymptotic representation in proposition [ extenthm1 ] , together with the relationship between the two sets , we have the following theorem , which does not depend on iz .    [ extenthmnew ] under assumptions [ assa][asse ]",
    ", we have @xmath311 where @xmath312 @xmath313 is a @xmath151 symmetric matrix with its @xmath160 element equal to @xmath314+\\frac{1 } n\\sum_{i=1}^n\\sigma _ { iie}^{-1}\\sigma_{iix}^{(p , q)},\\ ] ] where @xmath315 ; @xmath316 , @xmath317 .",
    "[ remark - asy - beta ] in appendix  b.3 , we show that the asymptotic expression of @xmath163 in theorem [ extenthmnew ] can be expressed alternatively as @xmath318 & \\cdots & \\operatorname{tr}\\bigl[\\ddot mx_1\\mathcal{m}(\\widebar{\\mathbb g } ) x_k ' \\bigr ] \\vspace*{3pt}\\cr \\vdots & \\vdots & \\vdots \\vspace*{3pt}\\cr \\operatorname{tr}\\bigl[\\ddot mx_k\\mathcal { m}(\\widebar{\\mathbb g})x_1 ' \\bigr ] & \\cdots&\\operatorname{tr}\\bigl[\\ddot mx_k\\mathcal{m}(\\widebar{\\mathbb g } ) x_k ' \\bigr]}^{-1 } \\\\[4pt ] & & { } \\times\\pmatrix{\\operatorname{tr}\\bigl[\\ddot mx_1\\mathcal{m}(\\widebar{\\mathbb g } ) e ' \\bigr ] \\vspace*{3pt}\\cr \\vdots \\vspace*{3pt}\\cr \\operatorname{tr}\\bigl[\\ddot mx _",
    "k\\mathcal{m}(\\widebar{\\mathbb g } ) e'\\bigr ] } \\\\ & & { } + o_p \\bigl(t^{-3/2}\\bigr)+o_p\\bigl(n^{-1}t^{-1/2 } \\bigr)+o_p\\bigl(n^{-1/2}t^{-1}\\bigr),\\end{aligned}\\ ] ] where @xmath185 and @xmath319 are defined below ( [ alternative1 ] ) and @xmath320 .",
    "notice @xmath321 is defined as @xmath322 , which is equal to @xmath323 since @xmath324 in the present context . in appendix",
    "b.3 of the supplement  @xcite , we also provide an intuitive explanation for this alternative expression .",
    "given theorem [ extenthmnew ] and remark [ remark - asy - beta ] we have the following corollary .",
    "[ extenthm2 ] under assumptions [ assa][asse ] , if @xmath179 , we have @xmath325 where @xmath326 , and @xmath327 is also the probability limit of @xmath328 & \\cdots & \\operatorname{tr}\\bigl[\\ddot mx_1\\mathcal{m}(\\widebar{\\mathbb g } ) x_k ' \\bigr ] \\vspace*{3pt}\\cr \\vdots & \\vdots & \\vdots \\vspace*{3pt}\\cr \\operatorname{tr}\\bigl[\\ddot mx _ k\\mathcal { m}(\\widebar{\\mathbb g})x_1 ' \\bigr ] & \\cdots&\\operatorname{tr}\\bigl[\\ddot mx _ k\\mathcal { m}(\\widebar{\\mathbb g } ) x_k ' \\bigr]}.\\ ] ]    [ remark1 ] compared with the model in section  [ sec2 ] , @xmath269 is more efficient under the zero loading restrictions .",
    "the reason is intuitive . in the previous model ,",
    "only variations in @xmath78 provide information for @xmath15 .",
    "but in the present case , variations in @xmath329 of @xmath12 also provide information for @xmath15 .",
    "this can also be seen by comparing the limiting variances of corollaries [ comshkthm4 ] and [ extenthm2 ] .",
    "notice the projection matrix now only involves @xmath330 instead of @xmath331 ; and @xmath330 is a submatrix of @xmath331 .",
    "in addition , the covariance matrix @xmath327 can be estimated by the same method as in estimating @xmath182 ; see remark [ remark2 ] .",
    "in this section , we extend the basic model in section  [ sec2 ] to include time - invariant regressors and common regressors .",
    "examples of time - invariant regressors include gender , race and education ; and examples for common regressors include price variables , unemployment rate , or macroeconomic policy variables .",
    "these types of regressors are important for empirical applications .",
    "we first consider the model with only time - invariant regressors , @xmath332 \\\\[-8pt ] x_{itk}&=&\\mu_{ik}+\\gamma_{ik}^{g\\prime}g_t+ \\gamma_{ik}^{h\\prime } h_t+v_{itk } \\nonumber\\end{aligned}\\ ] ] for @xmath40 , where @xmath193 is an @xmath333-dimensional vector , and @xmath195 is an dimensional vector .",
    "let @xmath199 , an @xmath48-dimensional vector .",
    "the key point of model ( [ obseffeq2 ] ) is that the @xmath334 s are known ( but not zeros ) .",
    "we treat @xmath334 as new added time - invariant regressors , whose coefficient @xmath195 is allowed to be time - varying .",
    "the parameter of interest is still @xmath15 .",
    "the inference for @xmath195 is provided in appendix  c.4 of the supplement  @xcite .",
    "the model in the previous section can be viewed as @xmath220 , where @xmath335 .",
    "however , the earlier derivation is not applicable here because now @xmath221 is a general matrix with full column rank , which provides more information ( restrictions ) on the rotation matrix .",
    "thus the number of restrictions required to eliminate rotational indeterminacy is even fewer than in section  [ sec3 ] .",
    "this point can be seen in the next subsection .",
    "we define the following notation for further analysis : @xmath336 then equation ( [ obseffeq2 ] ) has the same matrix expression as ( [ comshkmaineq2 ] ) .",
    "note that @xmath337 $ ] is the factor loading matrix for the @xmath338 vector @xmath339 .",
    "we make the following identification conditions , which we refer to as io ( _ identification _ conditions with partial _",
    "observable _ fixed effects ) , to emphasize the observed fixed effects :    we partition the matrix @xmath102 as @xmath340\\ ] ] and impose @xmath341 and @xmath342 ;    @xmath343 , where @xmath121 is a diagonal matrix with its diagonal elements distinct and arranged in descending order ;    @xmath215 and @xmath216 .    in appendix  c , we show that io is sufficient for identification .",
    "these restrictions can be imposed without loss of generality , as argued formally in appendix  c.3 .",
    "in addition , we make the following assumption .",
    "[ assf ] the loading matrix @xmath337 $ ] is of full column rank .      for clarity , in this subsection",
    ", we use @xmath344 to denote the observed value for @xmath221 . recall that",
    "@xmath345 , where @xmath101 contains the factor loading coefficients ( including @xmath221 ) ; @xmath102 contains the sub - blocks @xmath346 , @xmath347 and @xmath348 ; @xmath349 contains the heteroskedasticity coefficients .",
    "the regression coefficient @xmath15 is contained in matrix @xmath59 .",
    "the maximization of the likelihood function is now subject to four sets of restrictions , @xmath341 , @xmath350 , @xmath351 and @xmath352 .",
    "the likelihood function augmented with the lagrange multipliers is @xmath222+\\operatorname { tr } [ \\upsilon _ 1m_{gh } ] \\\\ & & { } + \\operatorname{tr } \\bigl[\\upsilon_2(m_{g g}-i_{r_1 } ) \\bigr]+\\operatorname{tr } \\biggl[\\upsilon_3 \\biggl(\\frac { 1}{n } \\gamma^{g\\prime}\\sigma_{\\varepsilon\\varepsilon}^{-1 } \\gamma^g - d \\biggr ) \\biggr]+\\operatorname{tr } \\bigl[\\upsilon_4\\bigl(\\phi-\\phi ^ * \\bigr ) \\bigr],\\end{aligned}\\ ] ] where @xmath353 and @xmath354 are all lagrange multipliers matrices ; @xmath224 is an @xmath355 matrix ; @xmath226 is an @xmath225 symmetric matrix ; @xmath356 is an @xmath225 symmetric matrix with all diagonal elements zeros ; @xmath354 is an @xmath229 matrix ; and @xmath357 . using the same arguments in deriving @xmath251 in section  [ sec3 ]",
    ", we have @xmath358",
    ". then the likelihood function is simplified as @xmath359 \\nonumber \\\\[-8pt ] \\\\[-8pt ] & & { } + \\operatorname{tr}[\\upsilon_1m_{g h } ] + \\operatorname{tr}\\bigl[\\upsilon_2(m_{g g}-i_{r_1 } ) \\bigr]+\\operatorname { tr}\\bigl[\\upsilon_4\\bigl(\\phi-\\phi^*\\bigr ) \\bigr ] .",
    "\\nonumber\\end{aligned}\\ ] ] the first order condition for @xmath101 gives @xmath360\\widehat\\sigma_{z z}^{-1}=w',\\ ] ] where @xmath272 is defined in ( [ extenmaineq1 ] ) .",
    "pre - multiplying @xmath361 and post - multiplying @xmath273 , and by the special structures of @xmath272 and @xmath273 , we have @xmath362\\widehat\\sigma_{z z}^{-1}\\widehat\\gamma \\\\ & & \\qquad = - { \\left } [ \\matrix{0_{r_1\\times r_1 } & 0_{r_1\\times r_2 } \\vspace*{3pt}\\cr \\dfrac{1 } n \\widehat m_{hh}^{-1}\\upsilon_4 ' \\widehat\\psi & \\dfrac{1 } n\\widehat m_{hh}^{-1}\\upsilon _ 4'\\phi}{\\right}].\\end{aligned}\\ ] ] but the first order condition for @xmath102 gives @xmath363\\widehat\\sigma_{z z}^{-1}\\widehat\\gamma= { \\left}[\\matrix { \\upsilon_2 & \\upsilon_1 ' \\vspace*{3pt}\\cr \\upsilon_1 & 0_{r_2\\times r_2 } } { \\right}].\\ ] ] comparing the proceeding two results and noting that the left - hand side is a symmetric matrix , we have @xmath364\\widehat\\sigma_{z z}^{-1}\\widehat\\gamma=0 $ ] . but @xmath365 can be replaced by @xmath366 ; see ( s.2 ) in the appendix .",
    "thus @xmath367\\widehat\\sigma_{\\varepsilon\\varepsilon}^{-1}\\widehat\\gamma=0.\\ ] ] the above result implies that @xmath251 , @xmath267 , @xmath368 and @xmath369 .",
    "the first order condition for @xmath84 is the same as ( [ extenmaineq5 ] ) , that is , @xmath370 \\\\[-8pt ] & & \\qquad{}-\\sum_{i=1}^n \\bigl(\\widehat bm_{z z}^{ji}\\widehat b{}'-\\widehat\\sigma_{z z}^{ji } \\bigr)\\widehat\\sigma_{ii}^{-1}\\widehat\\gamma_i ' \\widehat g\\widehat\\gamma_j=\\mathbb { w } , \\nonumber\\end{aligned}\\ ] ] where @xmath149 is defined following ( [ comshkmaineq7 ] ) .",
    "the first order condition on @xmath15 is the same as ( [ extenmainbeta ] ) , that is , @xmath371 \\biggr\\}\\dot x_{it}=0.\\hspace*{-35pt}\\ ] ]    we need an additional identify for the theoretical analysis in the appendix .",
    "the preceding analysis shows that @xmath372 and @xmath373 .",
    "they imply @xmath374 where @xmath375 .",
    "the asymptotic representation for @xmath163 is :    [ obseffthm1 ] under assumptions [ assa][assd ] and [ assf ] , and under the identification condition , we have @xmath376 where @xmath377 is a @xmath151 symmetric matrix with its @xmath160 element equal to @xmath378+\\frac{1 } n\\sum_{i=1}^n\\sigma_{iie}^{-1}\\sigma_{iix}^{(p , q)}$ ] ; @xmath379 ; @xmath380'$ ] ; @xmath381 ; and @xmath382 $ ] .",
    "proposition [ obseffthm1 ] is derived under the identification conditions io . in appendix",
    "c.3 , we show that for any set of factors and factor loadings @xmath383 , we can always transform it to another set @xmath384 which satisfies io , and at the same time , still maintains the observability of @xmath221 ( i.e. , @xmath221 is untransformed ) .",
    "this is in agreement with the lagrange multiplier analysis , in which @xmath385 ( @xmath386 , but the multiplier for @xmath351 is nonzero . using the relationship between the two sets , we can generalize proposition [ obseffthm1 ] into the following theorem , which does not depend on io .",
    "[ obseffthmnew ] under assumptions [ assa][assd ] and [ assf ] , we have @xmath387 where @xmath312 @xmath388 is a @xmath151 symmetric matrix with its @xmath160 element equal to @xmath389+\\frac{1 } n\\sum _ { i=1}^n\\sigma _ { iie}^{-1 } \\sigma_{iix}^{(p , q)}\\ ] ] and @xmath321 , @xmath390 and @xmath391 are defined in proposition [ obseffthm1 ] .",
    "[ remark3 ] in appendix  c.3 we show that the asymptotic expression of @xmath392 in theorem [ obseffthmnew ] can be expressed alternatively as @xmath318 & \\cdots & \\operatorname{tr}\\bigl[\\ddot mx_1\\mathcal{m}(\\widebar{\\mathbb g } ) x_k ' \\bigr ] \\vspace*{3pt}\\cr \\vdots & \\vdots & \\vdots \\vspace*{3pt}\\cr \\operatorname{tr}\\bigl[\\ddot mx _",
    "k\\mathcal { m}(\\widebar{\\mathbb g})x_1 ' \\bigr ] & \\cdots&\\operatorname{tr}\\bigl[\\ddot mx _ k\\mathcal { m}(\\widebar{\\mathbb g } ) x _ k ' \\bigr]}^{-1 } \\\\[4pt ] & & { } \\times\\pmatrix{\\operatorname{tr}\\bigl[\\ddot mx_1\\mathcal{m}(\\widebar{\\mathbb g } ) e ' \\bigr ] \\vspace*{3pt}\\cr \\vdots \\vspace*{3pt}\\cr \\operatorname{tr}\\bigl[\\ddot mx _",
    "k\\mathcal{m}(\\widebar{\\mathbb g } ) e'\\bigr]}+o_p \\bigl(t^{-3/2}\\bigr ) \\\\ & & { } + o_p\\bigl(n^{-1}t^{-1/2 } \\bigr)+o_p\\bigl(n^{-1/2}t^{-1}\\bigr),\\end{aligned}\\ ] ] where @xmath185 and @xmath319 are defined below ( [ alternative1 ] ) and @xmath315 .",
    "we also show in appendix  c.3 that this alternative expression has an intuitive explanation .    from theorem [ obseffthmnew ]",
    ", we obtain the following corollary .",
    "[ obseffcor ] under the conditions of theorem [ obseffthm1 ] , if @xmath179 , we have @xmath393 where @xmath394 , which has an alternative expression @xmath395 & \\cdots & \\operatorname{tr}\\bigl[\\ddot mx_1\\mathcal{m}(\\widebar{\\mathbb g } ) x_k ' \\bigr ] \\vspace*{3pt}\\cr \\vdots & \\vdots & \\vdots \\vspace*{3pt}\\cr \\operatorname{tr}\\bigl[\\ddot mx _",
    "k\\mathcal { m}(\\widebar{\\mathbb g})x_1 ' \\bigr ] & \\cdots&\\operatorname{tr}\\bigl[\\ddot mx_k\\mathcal { m}(\\widebar{\\mathbb g } ) x _ k ' \\bigr]}.\\ ] ]    compared with the model in section  [ sec2 ] , @xmath269 is more efficient with observable fixed effects ( time - invariant regressors ) . the reason is provided in remark [ remark1 ] .      in this subsection , we consider the joint presence of time - invariant regressors and common regressors .",
    "consider the following model : @xmath396 \\\\[-8pt ] x_{itk}&=&\\gamma_{ik}^{g\\prime}g_t+ \\gamma_{ik}^{h\\prime}h_t+\\gamma _ { ik}^{d\\prime}\\,d_t+v_{itk } \\nonumber\\end{aligned}\\ ] ] for @xmath40 , where @xmath193 , @xmath195 and @xmath397 are @xmath194 , @xmath196 and @xmath398 vectors , respectively .",
    "a key feature of model ( [ obseffeq7 ] ) is that @xmath397 and @xmath334 are observable for all @xmath27 and @xmath28 .",
    "we call @xmath334 the time - invariant regressors because they are invariant over time and @xmath397 the common regressors because they are the same for all the cross - sectional units . in this model ,",
    "the time - invariant regressors have time - varying coefficients , and the common regressors have heterogeneous ( individual - dependent ) coefficients . if @xmath399 , @xmath400 plays the role of @xmath3 in ( [ obseffeq2 ] ) .",
    "so the model here is more general .",
    "similar to the previous subsection , we make the following assumption :    [ assg ] the matrices @xmath401 and @xmath402 are both of full column rank , where @xmath403 and @xmath404 .",
    "let @xmath405 , @xmath406 and @xmath407 .",
    "the model can be written as @xmath58z_{it}= \\gamma_i'f_t + \\delta_i'd_t+ \\varepsilon_{it},\\ ] ] where @xmath408 are defined in section  [ sec2 ] ; let @xmath409 .",
    "then @xmath410 where the symbols @xmath411 are defiend in section  [ sec2 ] .",
    "the likelihood function can be written as @xmath412 ' \\sigma_{z z}^{-1}\\bigl[(i_n\\otimes b)z_t-\\delta d_t\\bigr].\\ ] ] take @xmath132 and @xmath15 as given .",
    "@xmath413 maximizes the above function at @xmath414 substituting @xmath415 into the above likelihood function , we obtain the concentrated likelihood function @xmath416,\\ ] ] where @xmath417 , @xmath418 and @xmath419 , a projection matrix .",
    "consider ( [ obseffeq8 ] ) , which is equivalent to @xmath420 where @xmath421 .",
    "post - multiplying @xmath422 on both sides , we have @xmath423 if we treat @xmath424 as the new observable data , @xmath425 as the new unobservable factors , the preceding equation can be viewed as a special case of ( [ obseffeq2 ] ) .",
    "invoking theorem [ obseffthmnew ] , which does not need io [ the factors @xmath425 may not satisfy io ] , we have the following theorem :    [ obseffthm3 ] under assumptions [ assa][assd ] and [ assg ] , the asymptotic representation of @xmath268 in the presence of time invariant and common regressors is @xmath426 where @xmath427^{-1 } \\bigl(g_t-\\mathbb g'\\mathbb d\\bigl(\\mathbb d'\\mathbb d\\bigr)^{-1}\\,d_t\\bigr);\\ ] ] @xmath428 is a @xmath151 symmetric matrix with its @xmath160 element equal to @xmath429+\\frac{1 } n\\sum_{i=1}^n \\sigma_{iie}^{-1}\\sigma _ { iix}^{(p , q)},\\ ] ] where @xmath430 and @xmath431 , a matrix of @xmath432 dimension ; @xmath433 ; @xmath434 .",
    "[ remark - invariant - common ] the asymptotic expression of @xmath163 can be alternatively expressed as @xmath435 & \\cdots & \\operatorname{tr}\\bigl[\\ddot mx_1\\mathcal{m}(\\mathbb b ) x_k ' \\bigr ] \\vspace*{3pt}\\cr \\vdots & \\vdots & \\vdots \\vspace*{3pt}\\cr \\operatorname{tr}\\bigl[\\ddot mx_k\\mathcal { m}(\\mathbb b)x_1 ' \\bigr ] & \\cdots & \\operatorname{tr}\\bigl[\\ddot mx_k\\mathcal{m}(\\mathbb b ) x_k ' \\bigr]}^{-1 } \\\\[4pt ] & & { } \\times\\pmatrix{\\operatorname{tr}\\bigl[\\ddot mx_1\\mathcal{m}(\\mathbb b ) e ' \\bigr ] \\vspace*{3pt}\\cr \\vdots \\vspace*{3pt}\\cr",
    "\\operatorname{tr}\\bigl[\\ddot mx_k\\mathcal{m}(\\mathbb b ) e'\\bigr ] } \\\\ & & { } + o_p \\bigl(t^{-3/2}\\bigr)+o_p\\bigl(n^{-1}t^{-1/2 } \\bigr)+o_p\\bigl(n^{-1/2}t^{-1}\\bigr).\\end{aligned}\\ ] ] if @xmath436 , the above asymptotic result reduces to the one in theorem [ obseffthmnew ] since @xmath437 .",
    "given theorem [ obseffthm3 ] and remark [ remark - invariant - common ] , we have the following corollary .    [ corsub44 ] under assumptions [ assa][assd ] and [ assg ] , if @xmath438 , then @xmath439 where @xmath440 , and @xmath441 can also be expressed as @xmath442 & \\cdots & \\operatorname{tr}\\bigl[\\ddot mx_1\\mathcal{m}(\\mathbb b ) x_k ' \\bigr ] \\vspace*{3pt}\\cr \\vdots & \\vdots & \\vdots \\vspace*{3pt}\\cr \\operatorname{tr}\\bigl[\\ddot mx_k\\mathcal { m}(\\mathbb b)x_1 ' \\bigr ] & \\cdots&\\operatorname{tr}\\bigl[\\ddot mx_k\\mathcal{m}(\\mathbb b ) x_k ' \\bigr]}.\\ ] ]",
    "to estimate the model by the maximum likelihood method , we adapt the ecm ( expectation and conditional maximization ) procedures of @xcite .",
    "more specifically , in the m - step we split the parameter @xmath443 into two blocks , @xmath444 and @xmath445 , and update @xmath446 to @xmath447 given @xmath448 and then update @xmath448 to @xmath449 given @xmath447 , where @xmath450 is the estimated value at the @xmath167th iteration . in this section , we only state the iterating formulas for basic models .",
    "the iterating formulas for the models in sections  [ sec3 ] and [ sec4 ] can be found in appendix  e of @xcite . in appendix  e",
    ", we also show that the iterated em solutions satisfy the first order conditions .",
    "so the em estimators are at least locally optimal .    in the basic model , @xmath119 .",
    "so the parameters to be estimated reduce to @xmath451 .",
    "let @xmath452 be the estimated value at the @xmath167th iteration .",
    "we update @xmath453 according to @xmath454 \\biggl[\\frac{1 } t\\sum _ { t=1}^te\\bigl(f_tf_t'|z , \\theta^{(k)}\\bigr ) \\biggr]^{-1},\\ ] ] where @xmath455 & & \\qquad = i_r-\\gamma ^{(k)\\prime } \\bigl(\\sigma_{z z}^{(k ) } \\bigr)^{-1}\\gamma^{(k)}\\label{52 } \\\\ & & \\quad\\qquad { } + \\gamma^{(k)\\prime}\\bigl(\\sigma_{z z}^{(k ) } \\bigr)^{-1}\\bigl(i_n\\otimes b^{(k ) } \\bigr)m_{z z}\\bigl(i_n\\otimes b^{(k)\\prime}\\bigr ) \\bigl ( \\sigma_{z z}^{(k)}\\bigr)^{-1}\\gamma ^{(k ) } , \\nonumber \\\\[-2pt ] \\label{53 } & & \\frac{1 } t\\sum _ { t=1}^te\\bigl(z_tf_t'|z , \\theta ^{(k)}\\bigr)=\\bigl(i_n\\otimes b^{(k ) } \\bigr)m_{z z}\\bigl(i_n\\otimes b^{(k)\\prime } \\bigr ) \\bigl ( \\sigma _ { z z}^{(k)}\\bigr)^{-1}\\gamma^{(k)}\\end{aligned}\\ ] ] with @xmath456 .",
    "we update @xmath457 and @xmath458 according to @xmath459\\label{54 } \\\\[-9pt ] & & \\hspace*{27pt } { } \\times\\bigl(i_n\\otimes b^{(k)}\\bigr)m_{z z } \\bigl(i_n\\otimes b^{(k)\\prime}\\bigr ) \\bigr\\ } , \\nonumber \\\\ \\beta^{(k+1)}&= & \\biggl(\\sum_{i=1}^n \\sum_{t=1}^t\\dot x_{it } ' \\bigl(\\sigma _ { iie}^{(k+1)}\\bigr)^{-1}\\dot x_{it } \\biggr)^{-1 } \\nonumber \\\\[-9pt]\\label{55 } \\\\[-9pt ] & & { } \\times \\biggl(\\sum_{i=1}^n\\sum _ { t=1}^t\\dot x_{it } ' \\bigl(\\sigma _ { iie}^{(k+1)}\\bigr)^{-1}\\bigl(\\dot y_{it}-\\lambda_i^{(k+1)\\prime } f_t^{(k ) } \\bigr ) \\biggr ) , \\nonumber\\end{aligned}\\ ] ] where @xmath460 is the transpose of the @xmath28th row of @xmath461 where @xmath462 with @xmath463 ; @xmath464 is the operator that sets the entries of its argument to zeros if the counterparts of @xmath465 are zeros .",
    "putting together , we obtain @xmath466 .",
    "the above iteration continues until @xmath467 is smaller than a preset error tolerance .",
    "the initial values use the iterated pc estimators of @xcite .",
    "in this section , we consider the finite sample properties of the mle .",
    "data are generated according to @xmath468 \\\\[-8pt ] x_{itk}&=&\\mu_{ik}+\\gamma_{ik}^{g\\prime}g_t+ \\gamma_{ik}^{h\\prime } h_t+\\gamma_{ik}^{d\\prime}\\,d_t+v_{itk } , \\qquad k=1,2 . \\nonumber\\end{aligned}\\ ] ] the dimensions of @xmath469 are each fixed to 1 .",
    "we set @xmath470 and @xmath471 .",
    "we consider four types of dgp ( data generating process ) , which correspond to the four models considered in the paper .",
    "@xmath472 and @xmath473 are fixed to zeros ; @xmath474 and @xmath193 are generated from @xmath475 and @xmath476 .",
    "@xmath477 and @xmath478 are fixed to zeros ; @xmath474 , @xmath479 and @xmath195 are generated from @xmath475 ; @xmath476 .",
    "@xmath400 and @xmath478 are fixed to zeros ; @xmath480 and @xmath195 are generated from @xmath475 ; @xmath476 and @xmath481",
    ". here @xmath334 is observable .",
    "@xmath482 and @xmath195 are generated from @xmath475 ; @xmath483 , @xmath484 , @xmath485 and @xmath486 . here",
    "@xmath334 and @xmath397 are observable .    using the method of writing",
    "( [ comshkmaineq2 ] ) , we can rewrite ( [ datagen ] ) as @xmath487 where @xmath488 for dgp1 ; @xmath489 for dgp2 and dgp3 ; @xmath490 for dgp4 , and @xmath491 is the corresponding loadings matrix .",
    "let @xmath492 be the @xmath27th row of @xmath491 .",
    "we generate the cross - sectional heteroscedasticity @xmath493 , an @xmath494 vector , according to @xmath495 , where @xmath25 is drawn from @xmath496 $ ] with @xmath497 .",
    "a similar way of generating heteroscedasticity is also used in @xcite and @xcite .",
    "let @xmath498 be an @xmath499 block diagonal matrix , in which @xmath500 , @xmath501 with @xmath502 being a @xmath151 standard normal random matrix for each @xmath27 .",
    "once @xmath503 is generated , the error term  @xmath90 , which is defined as @xmath504 with @xmath505 , is calculated by @xmath506 , where @xmath507 is an @xmath494 vector with all its elements being i.i.d .",
    "@xmath508 , where @xmath509 denotes the chi - squared distribution with two freedom degrees , which is normalized to mean zero and variance one .",
    "additional simulation results for normal and student-@xmath28 errors are given in appendix  d. once @xmath90 is obtained , we use @xmath510 to yield the observable data .    in the basic model ,",
    "the number of factors is determined by @xmath511 with @xmath512 where @xmath513 and @xmath514 are the respective estimators of @xmath101 and @xmath349 when the factor number is set to @xmath515 and @xmath516 . in the simulation , we set @xmath517 . for the model with zero restrictions , we consider a two - step method to determine @xmath333  and  @xmath201 .",
    "first , we use ( [ eq0 ] ) to estimate the total number @xmath518 , denoted by @xmath519 , and obtain @xmath520 by the method of the basic model under @xmath519 .",
    "then we calculate the matrix @xmath521 with @xmath522 and use the information criterion proposed by @xcite to determine the factor number in @xmath523 , which we use @xmath524 to denote . in the second step ,",
    "the upper bound of the factor number is set to @xmath519 .",
    "then @xmath525 . for models in section  [ sec4 ] , even though there are observable common regressors and time invariant regressors in the @xmath20 equation , we treat them as part of the unknown factor structure when estimating the total number of factors .",
    "once the total number of factors are obtained , the dimension of @xmath193 is obtained by subtracting the dimension of @xmath334 and that of @xmath397 because @xmath334 and @xmath397 are observable in section  [ sec4 ] .",
    "this approach works very well .",
    "other methods may also be considered .",
    "we consider an unified way to estimate the model in section  [ sec2 ] and the model in section  [ sec3 ] ( with zero restrictions ) .",
    "more specifically , for a given data set , we calculate @xmath48 and @xmath333 .",
    "if @xmath526 , we turn to the basic model ; if @xmath527 , we turn to the model with zero restrictions .    tables  [ table1][table2 ] report the simulation results based on 1000 repetitions .",
    "bias and root mean square error ( rmse ) are computed to measure the performance of the estimators .",
    "the percentage that the factor number is correctly estimated by the above procedure is given in the third column of each table . for comparison",
    ", we also report the performance of the within - group ( wg ) estimators and bai s iterated principal components estimators ( pc ) .",
    "simulations for the models in section  [ sec4 ] are provided in the supplement  @xcite .",
    "@ld3.0d3.1ccccccccd2.4ccc@ & & & & & + & & & & & + & & & & & & & & + & & & & & & & & + & & & & & & & & & & & & & & + 50&75&99.9&0.1562&0.1616&0.1550&0.1600&0.0174&0.0405&0.0171&0.0411&-0.0001&0.0020&0.0000&0.0034 + 100&75&100.0&0.1539&0.1568&0.1558&0.1587&0.0061&0.0228&0.0062&0.0224&0.0000&0.0011&0.0000&0.0010 + 150&75&100.0&0.1534&0.1556&0.1540&0.1561&0.0029&0.0168&0.0028&0.0146&0.0000&0.0007&0.0000&0.0007 + 50&125&100.0&0.1559&0.1605&0.1588&0.1636&0.0182&0.0389&0.0184&0.0409&0.0000&0.0017&0.0000&0.0016 + 100&125&100.0&0.1561&0.1586&0.1554&0.1579&0.0050&0.0167&0.0052&0.0167&0.0000&0.0009&0.0000&0.0008 + 150&125&100.0&0.1546&0.1565&0.1551&0.1570&0.0025&0.0108&0.0025&0.0106&0.0000&0.0006&0.0000&0.0005 +    @ld3.0d3.1cccccccccccc@ & & & & & + & & & & & + & & & & & & & & + & & & & & & & & + & & & & & & & & & & & & & & + 50&75&99.7&0.1098&0.1137&0.1095&0.1135&0.0097&0.0245&0.0099&0.0246&0.0000&0.0012&0.0000&0.0011 + 100&75&100.0&0.1088&0.1111&0.1092&0.1114&0.0038&0.0140&0.0038&0.0140&0.0000&0.0006&0.0000&0.0006 + 150&75&100.0&0.1086&0.1102&0.1083&0.1099&0.0011&0.0075&0.0015&0.0076&0.0000&0.0004&0.0000&0.0004 + 50&125&99.7&0.1089&0.1121&0.1097&0.1130&0.0076&0.0199&0.0077&0.0196&0.0000&0.0009&0.0000&0.0009 + 100&125&100.0&0.1088&0.1107&0.1087&0.1106&0.0029&0.0104&0.0026&0.0100&0.0000&0.0005&0.0000&0.0004 + 150&125&100.0&0.1086&0.1099&0.1076&0.1090&0.0011&0.0055&0.0010&0.0054&0.0000&0.0003&0.0000&0.0003 +    from the tables , we can see that the factor number can be correctly estimated with very high probability .",
    "it is also seen from the simulations that the wg estimators are inconsistent .",
    "the bias of the wg estimators shows no signs of decreasing as the sample size grows .",
    "the iterated pc estimators are consistent , but biased .",
    "as the sample size becomes large , the bias decreases noticeably .",
    "however , when the sample size is moderate , the bias of the iterated pc estimators is still pronounced . in comparison ,",
    "the ml estimators are consistent and unbiased .",
    "for all the sample sizes , the biases of the ml estimators are very small and negligible . in addition , the rmses of the ml estimators are always the smallest among the three estimators , illustrating the efficiency of the ml method .",
    "the same patten is observed for all of the four models considered .",
    "this paper considers estimating panel data models with interactive effects , in which explanatory variables are correlated with the unobserved effects .",
    "standard panel data methods ( such as the within - group estimator ) are not suitable for this type of models .",
    "we study the maximum likelihood method and provide a rigorous analysis for the asymptotic theory .",
    "while the analysis is difficult , the limiting distributions of the mle are simple and have intuitive interpretations .",
    "the maximum likelihood method can incorporate parameter restrictions to gain efficiency , a useful feature in view of the large number of parameters under large @xmath26 and large @xmath17 .",
    "we analyze the restrictions via the lagrange multiplier approach , which is capable of revealing what kinds of restrictions lead to efficiency gain .",
    "we allow the model to include time invariant regressors and common regressors .",
    "the coefficients of the time invariant regressors are time dependent , and the coefficients of the common regressors are cross - section dependent .",
    "this is a sensible way for modeling the effects of such variables in panel data context and fits naturally into the framework of interactive effects .",
    "the likelihood method is easy to implement and performs very well , as demonstrated by the monte carlo simulations .",
    "the authors thank two anonymous referees , an associate editor and an editor for constructive comments ."
  ],
  "abstract_text": [
    "<S> this paper considers the maximum likelihood estimation of panel data models with interactive effects . </S>",
    "<S> motivated by applications in economics and other social sciences , a notable feature of the model is that the explanatory variables are correlated with the unobserved effects . </S>",
    "<S> the usual within - group estimator is inconsistent . </S>",
    "<S> existing methods for consistent estimation are either designed for panel data with short time periods or are less efficient . </S>",
    "<S> the maximum likelihood estimator has desirable properties and is easy to implement , as illustrated by the monte carlo simulations . </S>",
    "<S> this paper develops the inferential theory for the maximum likelihood estimator , including consistency , rate of convergence and the limiting distributions . </S>",
    "<S> we further extend the model to include time - invariant regressors and common regressors ( cross - section invariant ) . </S>",
    "<S> the regression coefficients for the time - invariant regressors are time - varying , and the coefficients for the common regressors are cross - sectionally varying . </S>"
  ]
}