{
  "article_text": [
    "linear canonical correlation analysis ( lcca ) @xcite is a technique for multivariate data analysis and dimensionality reduction , which quantifies the linear associations between a pair of random vectors . in particular , lcca generates a sequence of pairwise unit variance linear combinations of the considered random vectors , such that the pearson correlation coefficient between the elements of each pair is maximal , and each pair is uncorrelated with its predecessors .",
    "the coefficients of these linear combinations , called the linear canonical directions , give insight into the underlying relationships between the random vectors .",
    "they are easily obtained by solving a simple generalized eigenvalue decomposition ( gevd ) problem , which only involves the covariance and cross - covariance matrices of the considered random vectors .",
    "lcca has been applied to blind source separation @xcite , image set matching @xcite , direction - of - arrival estimation @xcite , @xcite , data fusion and group inference in medical imaging data @xcite , localization of visual events associated with sound sources @xcite , audio - video synchronization @xcite , undersea target classification @xcite among others .",
    "the pearson correlation coefficient is only sensitive to linear associations between random variables .",
    "therefore , in cases where the considered random vectors are statistically dependent yet uncorrelated , lcca is not an informative tool .    in order to overcome the linear dependence limitation several generalizations of lcca",
    "have been proposed in the literature . in @xcite",
    "an information - theoretic approach to canonical correlation analysis , called icca , was proposed .",
    "this method generates a sequence pairwise unit variance linear combinations of the considered random vectors , such that the mutual - information ( mi ) @xcite between the elements of each pair is maximal , and each pair is uncorrelated with its predecessors . since the mi is a general measure of statistical dependence , which is sensitive to non - linear relationships , the icca @xcite is capable of capturing pairs of linear combinations exhibiting non - linear dependence .",
    "however , in contrast to lcca , the icca does not reduce to a simple gevd problem .",
    "indeed , in @xcite each pair of linear combinations must be obtained separately via an iterative newton - raphson @xcite algorithm , which may converge to undesired local maxima .",
    "moreover each step of the newton - raphson algorithm involves re - estimation of the mi in a non - parametric manner at a potentially high computational cost .",
    "another approach to non - linear generalization of lcca is kernel canonical correlation analysis ( kcca ) @xcite-@xcite .",
    "kcca applies lcca to high - dimensional non - linear transformations of the considered random vectors that map them into some reproducing kernel hilbert spaces .",
    "although the kcca approach can be successful in extracting non - linear relations @xcite , @xcite-@xcite , it suffers from the following drawbacks .",
    "first , the high - dimensional mappings may have high computational complexity .",
    "second , the method is highly prone to over - fitting errors , and requires regularization of the covariance matrices of the transformed random vectors to increase numerical stability . finally , the non - linear mappings of the random vectors may mask the dependencies between their original coordinates .    in this paper",
    "we propose a different non - linear generalization of lcca called measure transformed canonical correlation analysis ( mtcca ) .",
    "we apply a structured transform to the joint probability distribution of the considered pair of random vectors , i.e. , a transformation of the joint probability measure defined on their joint observation space .",
    "the proposed transform is structured by a pair of non - negative functions called the mt - functions .",
    "it preserves statistical independence and maps the joint probability distribution into a set of probability measures on the joint observation space . by modifying the mt - functions classes of measure transformations",
    "can be obtained that have different properties .",
    "two types of mt - functions , the exponential and the gaussian , are developed in this paper .",
    "the former has a translation invariance property while the latter has a localization property .",
    "mtcca applies lcca to the considered pair of random vectors under the proposed probability measure transform . by modifying the mt - functions the correlation coefficient under the transformed probability measure , called the mt - correlation coefficient ,",
    "is modified , resulting in a new general framework for canonical correlation analysis . in mtcca",
    ", the mt - correlation coefficients between the elements of each generated pair of linear combinations are called the mt - canonical correlation coefficients .",
    "the mt - functions are selected from exponential and gaussian families of functions parameterized by scale and location parameters . under these function classes",
    "it is shown that pairs of linear combinations with non - linear dependence can be detected by mtcca .",
    "the parameters of the mt - functions are selected via maximization of a lower bound on the largest mt - canonical correlation coefficient .",
    "we show that , for these selected parameters , the corresponding largest mt - canonical correlation coefficient constitutes a measure for statistical independence under the original probability distribution . in this case",
    "it is also shown that the considered random vectors are statistically independent under both transformed and original probability distributions if and only if they are uncorrelated under the transformed probability distribution .    in the paper an empirical implementation of mtcca",
    "is proposed that uses strongly consistent estimators of the measure transformed covariance and cross - covariance matrices of the considered random vectors .",
    "the mtcca approach has the following advantages over lcca , icca , and the kcca discussed above :    in contrast to lcca , mtcca is capable of detecting non - linear dependencies . moreover , under appropriate selection of the mt - functions , the largest mt - canonical correlation coefficient is a measure of statistical independence between the considered random vectors .    in comparison to the icca , mtcca is easier to implement from the following reasons .",
    "first , it reduces to a simple gevd problem , which only involves the measure transformed covariance and cross - covariance matrices of the considered random vectors .",
    "second , while mtcca with exponential and gaussian mt - functions involves a _",
    "maximization for choosing the mt - functions parameters , the icca involves a _ sequence _ of maximization problems , each having the same dimensionality as in mtcca .    in the paper",
    "we show that unlike the empirical icca and kcca , the computational complexity of the empirical mtcca is linear in the sample size which makes it favorable in large sample size scenarios .",
    "unlike kcca , mtcca does not expand the dimensions of the random vectors , nor does it require regularization of their measure transformed covariance matrices .    finally , unlike kcca , in mtcca",
    "the original coordinates of the observation vectors are retained after the probability measure transform .",
    "therefore , mtcca can be easily applied to variable selection @xcite by discarding a subset of the variables for which the corresponding entries of the measure transformed canonical directions are practically zero .",
    "the proposed approach is illustrated for two applications .",
    "the first is a simulation of graphical models with known dependency structure . in this simulated example",
    "we show that in similar to icca , the mtcca outperforms the lcca in selecting valid linear / non - linear graphical model topology .",
    "the second application is construction of networks that analyze long - term associations between companies traded in the nasdaq and nyse stock markets .",
    "we show that mtcca and kcca better associate companies in the same sector ( technology , pharmaceutical , financial ) than does lcca and icca . furthermore , mtcca is able to achieve this by finding strong non - linear dependencies between the daily log - returns of these companies .",
    "the paper is organized as follows . in section [ cca_review ]",
    ", lcca is reviewed . in section [ pmt_cca ] ,",
    "lcca is generalized by applying a transform to the joint probability distribution .",
    "selection of the mt - functions associated with the transform is discussed in section [ choiceofkernels ] . in section",
    "[ estimation ] , empirical implementation of mtcca is obtained . in section [ examp ] ,",
    "the proposed approach is illustrated via simulation experiment . in section [ disc ] , the main points of this contribution are summarized .",
    "the propositions and theorems stated throughout the paper are proved in the appendix .",
    "let @xmath0 and @xmath1 denote two random vectors , whose observation spaces are given by @xmath2 and @xmath3 , respectively .",
    "we define the measure space @xmath4 , where @xmath5 is a @xmath6-algebra over @xmath7 , and @xmath8 is the joint probability measure on @xmath5 .",
    "the marginal probability measures of @xmath8 on @xmath9 and @xmath10 are denoted by @xmath11 and @xmath12 , where @xmath9 and @xmath10 are the @xmath6-algebras over @xmath13 and @xmath14 , respectively .",
    "let @xmath15 denote an integrable scalar function on @xmath7 .",
    "the expectation of @xmath16 under @xmath8 is defined as @xmath17\\triangleq\\int\\limits_{\\xcalsc\\times\\ycalsc}g\\left({{\\bf{x}}},{{\\bf{y}}}\\right)d\\pxy\\left({{\\bf{x}}},{{\\bf{y}}}\\right),\\ ] ] where @xmath18 and @xmath19 .",
    "the random vectors @xmath0 and @xmath1 will be said to be statistically independent under @xmath8 if @xmath20={\\rm{e}}\\left[g_{1}\\left({{\\bf{x}}}\\right);\\px\\right ] { \\rm{e}}\\left[g_{2}\\left({{\\bf{y}}}\\right);\\py\\right]\\ ] ] for all integrable scalar functions @xmath21 , @xmath22 on @xmath13 and @xmath14 , respectively .",
    "the random vectors @xmath0 and @xmath1 will be said to be uncorrelated under @xmath8 if @xmath23={\\rm{e}}\\left[{{\\bf{x}}};\\px\\right]{\\rm{e}}\\left[{{\\bf{y}}}^{t};\\py\\right],\\ ] ] where @xmath24 denotes the transpose operator .",
    "lcca generates a sequence of pairwise unit - variance linear combinations @xmath25 , @xmath26 in the following manner .",
    "the first pair @xmath27 is determined by maximizing the pearson correlation coefficient between @xmath28 and @xmath29 over @xmath30 and @xmath31 with the constraint that both @xmath28 and @xmath29 have unit variance .",
    "similarly , the @xmath32-th pair @xmath25 @xmath33 is determined by maximizing the pearson correlation coefficient between @xmath28 and @xmath29 over @xmath30 and @xmath31 with the constraints that both @xmath28 and @xmath29 have unit variance and @xmath34 are uncorrelated with all the previously obtained pairs @xmath35 , @xmath36 .",
    "the pairs @xmath37 and @xmath25 are called the @xmath32-th order _ linear canonical directions _ and the @xmath32-th order _ linear canonical variates _ , respectively .",
    "the pearson correlation coefficient between @xmath38 and @xmath39 is called the @xmath32-th order _ linear canonical correlation coefficient_.    the pearson correlation coefficient between @xmath28 and @xmath29 under @xmath8 is given by @xmath40\\triangleq\\frac{{\\rm{cov}}\\left[{{\\bf{a}}}^{t}{{\\bf{x}}},{{\\bf{b}}}^{t}{{\\bf{y}}};{\\pxy}\\right]}{\\sqrt{{\\rm{var}}\\left[{{\\bf{a}}}^{t}{{\\bf{x}}};{\\px}\\right]}\\sqrt{{\\rm{var}}\\left[{{\\bf{b}}}^{t}{{\\bf{y}}};{\\py}\\right]}}=\\frac{{{\\bf{a}}}^{t}\\bsigma_{{{\\mbox{\\boldmath \\tiny $ { { \\bf{x}}}$}}}{{\\mbox{\\boldmath \\tiny $ { { \\bf{y}}}$}}}}{{\\bf{b}}}}{\\sqrt{{{\\bf{a}}}^{t}\\bsigma_{{{\\mbox{\\boldmath \\tiny $ { { \\bf{x}}}$}}}}{{\\bf{a}}}}\\sqrt{{{\\bf{b}}}^{t}\\bsigma_{{{\\mbox{\\boldmath \\tiny $ { { \\bf{y}}}$}}}}{{\\bf{b}}}}},\\end{aligned}\\ ] ] where @xmath41 $ ] and @xmath42 $ ] denote the variance and covariance under @xmath11 and @xmath8 , respectively . the last equality in ( [ rhodef ] ) can be easily verified using the basic definitions of variance and covariance , where @xmath43 , @xmath44 and @xmath45 denote the covariance matrix of @xmath0 under @xmath11 , the covariance matrix of @xmath1 under @xmath12 , and their cross - covariance matrix under @xmath8 , respectively , and it is assumed that @xmath46 and @xmath47 are non - singular .",
    "hence , lcca solves the following constraint maximization sequentially over @xmath48 .",
    "@xmath49 where @xmath50 denotes the @xmath32-th order linear canonical correlation coefficient .",
    "since the number of constraints in ( [ ccaoptprob ] ) increases with @xmath32 , it is implied that the linear canonical correlation coefficients satisfy the following order relation @xmath51 .",
    "it is well known that the constrained maximization problem in ( [ ccaoptprob ] ) reduces to the set of @xmath52 distinct solutions of the following generalized eigenvalue problem @xcite @xmath53\\left[\\begin{array}{c}{{{\\bf{a } } } } \\\\{{{\\bf{b}}}}\\end{array}\\right]=\\rho\\left[\\begin{array}{cc}{\\bsigma_{{{\\mbox{\\boldmath \\tiny $ { { \\bf{x}}}$ } } } } } & { { { \\bf{0 } } } } \\\\ { { { \\bf{0 } } } } & { \\bsigma_{{{\\mbox{\\boldmath \\tiny $ { { \\bf{y}}}$}}}}}\\end{array}\\right]\\left[\\begin{array}{c}{{{\\bf{a } } } } \\\\{{{\\bf{b}}}}\\end{array}\\right],\\ ] ] where @xmath54 is the @xmath32-th largest generalized eigenvalue of the pencil in ( [ gevd ] ) , and @xmath55^{t}=\\left[{{\\bf{a}}}^{t}_{k},{{\\bf{b}}}^{t}_{k}\\right]^{t}$ ] is its corresponding generalized eigenvector .",
    "in this section lcca is generalized by applying a transform to the joint probability measure @xmath8 .",
    "first , a transform which maps @xmath8 into a set of joint probability measures @xmath56 on @xmath5 is derived that have the property that they preserve statistical independence of @xmath0 and @xmath1 under @xmath8 .",
    "the mtcca method is obtained by applying lcca to @xmath0 and @xmath1 under the transformed probability measure @xmath57 .",
    "[ def1 ] given two non - negative functions @xmath58 and @xmath59 satisfying @xmath60}<\\infty,\\ ] ] a transform on the joint probability measure @xmath8 is defined via the following relation @xmath61\\left(a\\right)=\\int\\limits_{a}\\varphi_{u , v}\\left({{\\bf{x}}},{{\\bf{y}}}\\right)d\\pxy\\left({{\\bf{x}}},{{\\bf{y}}}\\right),\\ ] ] where @xmath62 , @xmath18 , @xmath19 , and @xmath63}.\\ ] ] the functions @xmath64 and @xmath65 , associated with the transform @xmath66 $ ] , are called the mt - functions .    in the following proposition ,",
    "some properties of the measure transform ( [ measuretransform ] ) are given .",
    "[ prop1 ] let @xmath57 be defined by relation ( [ measuretransform ] )",
    ". then    1 .",
    "[ p1 ] @xmath57 is a probability measure on @xmath5 .",
    "[ p2 ] @xmath57 is absolutely continuous w.r.t .",
    "@xmath8 , with radon - nikodym derivative @xcite given by @xmath67 3",
    ".   [ p3 ] if @xmath0 and @xmath1 are statistically independent under @xmath8 , then they are statistically independent under @xmath57 .",
    "[ p4 ] assume that the mt - functions @xmath64 and @xmath65 are strictly positive .",
    "if @xmath0 and @xmath1 are statistically independent under @xmath57 , then they are statistically independent under @xmath8 .",
    "[ a proof is given in appendix [ prop1proof ] ]    by modifying the mt - functions @xmath64 and @xmath65 , such that the conditions in definition [ def1 ] are satisfied , an infinite set of joint probability measures on @xmath5 can be obtained .",
    "mtcca generates a sequence of pairwise linear combinations @xmath25 , @xmath26 that have the following properties under the transformed probability measure @xmath57 : @xmath38 and @xmath68 have unit variance , the correlation coefficient between @xmath69 and @xmath68 is maximal , and @xmath25 are uncorrelated with @xmath35 for all @xmath70 . in mtcca ,",
    "the pairs @xmath37 and @xmath25 are called the @xmath32-th order _ mt - canonical directions _ and the @xmath32-th order _ mt - canonical variates _ , respectively . the correlation coefficient between @xmath69 and @xmath68 under @xmath57",
    "is called the @xmath32-th order _ mt - canonical correlation coefficient_.    the correlation coefficient between @xmath28 and @xmath29 under @xmath57 is given by @xmath71\\triangleq\\frac{{\\rm{cov}}\\left[{{\\bf{a}}}^{t}{{\\bf{x}}},{{\\bf{b}}}^{t}{{\\bf{y}}};{\\qxy}\\right]}{\\sqrt{{\\rm{var}}\\left[{{\\bf{a}}}^{t}{{\\bf{x}}};{\\qx}\\right]}\\sqrt{{\\rm{var}}\\left[{{\\bf{b}}}^{t}{{\\bf{y}}};{\\qy}\\right]}}=\\frac{{{\\bf{a}}}^{t}\\bsigma^{\\left(u , v\\right)}_{{{\\mbox{\\boldmath \\tiny $ { { \\bf{x}}}$}}}{{\\mbox{\\boldmath \\tiny $ { { \\bf{y}}}$}}}}{{\\bf{b}}}}{\\sqrt{{{\\bf{a}}}^{t } \\bsigma^{\\left(u , v\\right)}_{{{\\mbox{\\boldmath \\tiny $ { { \\bf{x}}}$}}}}{{\\bf{a}}}}\\sqrt{{{\\bf{b}}}^{t}\\bsigma^{\\left(u , v\\right)}_{{{\\mbox{\\boldmath \\tiny $ { { \\bf{y}}}$}}}}{{\\bf{b}}}}},\\ ] ] where @xmath72 $ ] is called the _ mt - correlation coefficient _ , and the measures @xmath73 and @xmath74 are the marginal probability measures of @xmath57 on @xmath9 and @xmath10 , respectively . the matrices @xmath75 , @xmath76 and @xmath77",
    "denote the covariance matrix of @xmath0 under @xmath73 , the covariance matrix of @xmath1 under @xmath74 , and their cross - covariance matrix under @xmath57 , respectively , where it is assumed that @xmath75 and @xmath76 are non - singular .    using ( [ expdef ] ) and ( [ measuretransformradnik ] )",
    "it can be shown that @xmath78={\\rm{e}}\\left[{{\\bf{g}}}\\left({{\\bf{x}}},{{\\bf{y}}}\\right)\\varphi_{u , v}\\left({{\\bf{x}}},{{\\bf{y}}}\\right);\\pxy\\right]$ ] , where @xmath79 is some arbitrary matrix function of @xmath0 and @xmath1 .",
    "therefore , one can easily verify that @xmath80-{\\rm{e}}\\left[{{\\bf{x}}}\\varphi_{u , v}\\left({{\\bf{x}}},{{\\bf{y}}}\\right);\\pxy\\right]{\\rm{e}}\\left[{{\\bf{x}}}^{t}\\varphi_{u , v}\\left({{\\bf{x}}},{{\\bf{y}}}\\right);\\pxy\\right],\\ ] ] @xmath81-{\\rm{e}}\\left[{{\\bf{y}}}\\varphi_{u , v}\\left({{\\bf{x}}},{{\\bf{y}}}\\right);\\pxy\\right]{\\rm{e}}\\left[{{\\bf{y}}}^{t}\\varphi_{u , v}\\left({{\\bf{x}}},{{\\bf{y}}}\\right);\\pxy\\right],\\ ] ] and @xmath82-{\\rm{e}}\\left[{{\\bf{x}}}\\varphi_{u , v}\\left({{\\bf{x}}},{{\\bf{y}}}\\right);\\pxy\\right]{\\rm{e}}\\left[{{\\bf{y}}}^{t}\\varphi_{u , v}\\left({{\\bf{x}}},{{\\bf{y}}}\\right);\\pxy\\right].\\ ] ] equations ( [ rxmod_pxy])-([rxymod_pxy ] ) imply that @xmath75 , @xmath76 and @xmath77 are weighted covariance and cross - covariance matrices of @xmath0 and @xmath1 under @xmath8 , with weighting function @xmath83 .",
    "mtcca solves the following constrained maximization sequentially over @xmath48 .",
    "@xmath84 where @xmath85 denotes the @xmath32-th order mt - canonical correlation coefficient .",
    "since the number of constraints in ( [ ccaoptprobmod ] ) increases with @xmath32 , the mt - canonical correlation coefficients satisfy the following order relation @xmath86    similarly to ( [ ccaoptprob ] ) the constrained maximization problem in ( [ ccaoptprobmod ] ) reduces to the following generalized eigenvalue problem @xmath87\\left[\\begin{array}{c}{{{\\bf{a } } } } \\\\{{{\\bf{b}}}}\\end{array}\\right]=\\rho\\left[\\begin{array}{cc}{\\bsigma^{\\left(u , v\\right)}_{{{\\mbox{\\boldmath \\tiny $ { { \\bf{x}}}$ } } } } } & { { { \\bf{0 } } } } \\\\ { { { \\bf{0 } } } } & { \\bsigma^{\\left(u , v\\right)}_{{{\\mbox{\\boldmath \\tiny $ { { \\bf{y}}}$}}}}}\\end{array}\\right]\\left[\\begin{array}{c}{{{\\bf{a } } } } \\\\{{{\\bf{b}}}}\\end{array}\\right],\\ ] ] where @xmath54 is the @xmath32-th largest generalized eigenvalue of the pencil in ( [ gevd_pmtcca ] ) , and @xmath55^{t}=\\left[{{\\bf{a}}}^{t}_{k},{{\\bf{b}}}^{t}_{k}\\right]^{t}$ ] is its corresponding generalized eigenvector .    by modifying the mt - functions @xmath64 and @xmath65 , such that the condition in ( [ assumption2 ] ) is satisfied , the mt - correlation coefficient under @xmath57 is modified , resulting in a family of canonical correlation analyses , generalizing lcca described in subsection [ classcca ] . in particular , by choosing @xmath88 and @xmath89 , then @xmath90 , @xmath91={{\\rm{corr}}}\\left[{{\\bf{a}}}^{t}{{\\bf{x}}},{{\\bf{b}}}^{t}{{\\bf{y}}};{\\pxy}\\right]$ ] , and the lcca is obtained .",
    "other choices of @xmath64 and @xmath65 are discussed below .",
    "in this section we parameterize the mt - functions @xmath92 and @xmath93 with parameters @xmath94 and @xmath95 under the exponential and gaussian families of functions . this will result in the corresponding cross - covariance matrix @xmath96 gaining sensitivity to non - linear relationships between the entries of @xmath0 and @xmath1 .",
    "optimal choice of the parameters @xmath97 and @xmath98 is also discussed .",
    "let @xmath99 and @xmath100 be defined as the parameterized functions @xmath101 where @xmath94 and @xmath95 . using ( [ varphidef ] ) ,",
    "( [ rxymod_pxy ] ) and ( [ expkernel ] ) one can easily verify that the cross - covariance matrix of @xmath0 and @xmath1 under @xmath102 takes the form @xmath103 where @xmath104\\ ] ] is the joint moment generating function of @xmath0 and @xmath1 , and it is assumed that @xmath105 is finite in some open region in @xmath106 containing the origin . note that the cross - covariance matrix in ( [ offhessxy ] ) involves higher - order statistics of @xmath0 and @xmath1 .",
    "additionally , observe that @xmath107 reduces to the standard cross - covariance matrix @xmath108 for @xmath109 and @xmath110 .",
    "finally , note that the quantity in ( [ offhessxy ] ) has been proposed in @xcite-@xcite for blind source separation , blind channel estimation , blind channel equalization , and auto - regression parameter estimation . to the best of our knowledge",
    "this paper is the first to propose this quantity for generalizing lcca .    in the following theorem , which follows directly from ( [ offhessxy ] ) and the properties of @xmath105 @xcite , @xcite",
    ", one sees that @xmath107 preserves statistical independence and can capture non - linear dependencies when they exist .",
    "[ offoriginindepprop ] let @xmath111 denote an arbitrary open region in @xmath106 containing the origin , and assume that @xmath105 is finite on @xmath111 .",
    "the random vectors @xmath0 and @xmath1 are statistically independent under the joint probability measure @xmath8 if and only if @xmath112 [ a proof is given in appendix [ expkerth ] ] .",
    "the `` if '' is the interesting part of the theorem since the `` only if '' part follows directly from property [ p3 ] of proposition [ prop1 ] .",
    "in particular , if @xmath0 and @xmath1 are statistically dependent under @xmath8 , then there exist @xmath30 , @xmath31 , @xmath94 and @xmath95 , such that @xmath113 .",
    "thus , ( [ mtrhodef ] ) implies that if @xmath0 and @xmath1 are statistically dependent under @xmath8 then there exist linear combinations of the form @xmath28 and @xmath29 whose mt - correlation coefficient under @xmath102 is non - zero .",
    "finally , we show that mtcca with the exponential mt - functions in ( [ expkernel ] ) is translation - invariant .",
    "let @xmath114 and @xmath115 , where @xmath116 and @xmath117 are deterministic vectors in @xmath118 and @xmath119 , respectively . according to ( [ varphidef ] ) and ( [ expkernel ] ) @xmath120",
    "therefore , by ( [ rxmod_pxy])-([rxymod_pxy ] ) : @xmath121 , @xmath122 , and @xmath123 .",
    "thus , by ( [ ccaoptprobmod ] ) , the mt - canonical correlation coefficients are invariant to translation , i.e. @xmath124 for @xmath125 .",
    "next we define the mt - functions @xmath126 and @xmath127 by @xmath128 where @xmath94 , @xmath95 , @xmath129 , @xmath130 , and @xmath131 denotes the @xmath132-norm .",
    "since @xmath133 and @xmath134 are strictly positive and bounded , one can easily verify that the condition in ( [ assumption2 ] ) is satisfied .",
    "relations ( [ varphidef ] ) and ( [ rxymod_pxy ] ) imply that the mt - functions ( [ gausskernel ] ) produce a weighted cross - covariance matrix , for which the observations are weighted in an inverse proportion to the distances @xmath135 and @xmath136 . hence , the resulting mt - correlation coefficient is a measure of local linear dependence in the vicinity of @xmath137 .",
    "we note that local linear dependence exists whenever there are global non - linear dependencies .",
    "sensitivity of @xmath138 to non - linear relationships between @xmath0 and @xmath1 is shown via the following theorem .",
    "[ gaussindepprop ] let @xmath6 , @xmath139 be fixed and positive . additionally , let @xmath111 denote an arbitrary open region in @xmath106 containing the origin .",
    "the random vectors @xmath0 and @xmath1 are statistically independent under the joint probability measure @xmath8 if and only if @xmath140 [ a proof is given in appendix [ gausskerth ] ] .",
    "hence , if @xmath0 and @xmath1 are statistically dependent under @xmath8 , then there exist @xmath30 , @xmath31 , @xmath94 and @xmath95 , such that @xmath141 .",
    "therefore , again , non - linear dependencies can be detected using mtcca .",
    "unlike mtcca with gaussian mt - fucntions ( [ gausskernel ] ) , mtcca with exponential mt - functions ( [ expkernel ] ) is translation invariant .",
    "moreover , in mtcca with gaussian mt - functions , in addition to the location parameters @xmath97 , @xmath98 , which share the same dimensionality of the scaling parameters of the exponential mt - functions , one has to set two width parameters @xmath6 and @xmath139 . on the other hand , unlike the exponential mt - functions , the gaussian mt - functions are bounded in the joint observation space @xmath7 .",
    "hence , mtcca with gaussian mt - functions is more robust to outliers .",
    "additionally , the gaussian mt - functions has the property that they localize linear dependence over the observation space .",
    "this property is illustrated in subsection [ simexamp1 ] .",
    "additional common properties of the exponential and gaussian mt - functions are given in the following remarks :    since the exponential and gaussian mt - functions are strictly positive , by property [ p4 ] of proposition [ prop1 ] we conclude that @xmath142 and @xmath143 preserve statistical dependence under @xmath8 .",
    "the exponential and gaussian mt - functions preserve gaussianity in the sense that if @xmath0 and @xmath1 are jointly gaussian under @xmath8 , then they are jointly gaussian under @xmath142 and @xmath143 .      a natural choice of the parameters @xmath97 and @xmath98 , would be those that maximize the first - order mt - canonical correlation coefficient @xmath144 in ( [ ccaoptprobmod ] ) .",
    "however , this maximization is analytically cumbersome . therefore , as an alternative , we propose maximizing a lower bound on @xmath144 . we show that the resultant first - order mt - canonical correlation coefficient will be sensitive to dependence between @xmath0 and @xmath1 .    [ lowerboundth ] define the following element - by - element average : @xmath145^{2}_{i , j } } { \\left[\\bsigma^{\\left(u , v\\right)}_{{{\\mbox{\\boldmath \\tiny $ { { \\bf{x}}}$}}}}\\left({{\\bf{s}}},\\tvec\\right)\\right]_{i , i}\\left[\\bsigma^{\\left(u , v\\right)}_{{{\\mbox{\\boldmath \\tiny $ { { \\bf{y}}}$}}}}\\left({{\\bf{s}}},\\tvec\\right)\\right]_{j , j}}\\right)^{1/2},\\ ] ] where @xmath146_{i , j}$ ] denotes the @xmath147-th entry of @xmath148 .",
    "@xmath149 [ a proof is given in appendix [ lowerboundproof ] ]    proposition [ lowerboundth ] suggests choosing the optimal mt - functions parameters by maximizing the lower bound in ( [ lowerboundeq ] ) : @xmath150 where @xmath151 a closed region in @xmath106 containing the origin . under the mt - functions pairs in ( [ expkernel ] ) and ( [ gausskernel ] )",
    "one can verify that @xmath152 is continuous in @xmath106 .",
    "therefore , by the extreme value theorem @xcite it has a maximum in @xmath151 . the maximization problem in ( [ maxprob ] )",
    "can be solved numerically , e.g. , using gradient ascent @xcite or greedy search over the region @xmath151 .",
    "the following theorem justifies the use of the first - order mt - canonical correlation coefficient as a measure of statistical independence .",
    "[ indprop ] the random vectors @xmath0 and @xmath1 are statistically independent under @xmath8 if and only if @xmath153 where @xmath154 are the mt - functions in ( [ expkernel ] ) or ( [ gausskernel ] ) , and @xmath155 are selected according to ( [ maxprob ] ) .",
    "[ a proof is given in appendix [ indpropproof ] ]    therefore , if the mt - functions and their parameters are selected as in theorem [ indprop ] , we conclude that @xmath0 and @xmath1 are statistically independent under @xmath8 if and only if they are uncorrelated under @xmath57 . hence ,",
    "since by property [ p3 ] of proposition [ prop1 ] @xmath57 preserves statistical independence under @xmath8 , we also conclude that @xmath0 and @xmath1 are statistically independent under @xmath57 if and only if they are uncorrelated under @xmath57 .",
    "given @xmath156 i.i.d .",
    "samples of @xmath157 an empirical version of mtcca ( [ ccaoptprobmod ] ) can be implemented by replacing @xmath75 , @xmath76 and @xmath77 in ( [ ccaoptprobmod ] ) , ( [ gevd_pmtcca ] ) and ( [ maxprob ] ) with their sample covariance estimates .",
    "hence , strongly consistent estimators of @xmath75 , @xmath76 and @xmath77 are constructed , based on @xmath156 i.i.d .",
    "samples of @xmath157 .",
    "[ consistentest ] let @xmath158 , @xmath159 denote a sequence of i.i.d .",
    "samples from the joint distribution @xmath8 , and define the empirical covariance estimates @xmath160 @xmath161 and @xmath162 where @xmath163 and @xmath164 assume @xmath165<\\infty,&&{\\rm{e}}\\left[v^{4}\\left({{\\bf{y}}}\\right);\\py\\right]<\\infty,\\end{aligned}\\ ] ] @xmath166<\\infty\\hspace{0.2cm}\\forall{k=1,\\ldots , p}&\\rm{and}&{\\rm{e}}\\left[y^{4}_{l};\\py\\right]<\\infty\\hspace{0.2cm}\\forall{l=1,\\ldots , q},\\end{aligned}\\ ] ] where @xmath167 and @xmath168 denote the @xmath32-th and the @xmath169-th entries of @xmath0 and @xmath1 , respectively",
    ". then @xmath170 , @xmath171 and @xmath172 almost surely as @xmath173 . [ a proof is given in appendix [ consistestproof ] ]    note that for @xmath174 and @xmath175 , the estimators @xmath176 , @xmath177 , and @xmath178 reduce to the standard unbiased estimators of the covariance and cross - covariance matrices @xmath46 , @xmath47 and @xmath108 , respectively .",
    "the empirical mtcca procedure with the exponential and gaussian mt - functions is given in appendix [ empmtcca ] .",
    "in the first stage of the procedure , the parameters of the mt - functions are selected by solving a _ single _",
    "@xmath179-dimensional maximization problem ( [ maxprob2 ] ) using gradient ascent .",
    "it can be shown that each iteration of the gradient ascent algorithm , which only involves the empirical measure transformed covariance and cross - covariance matrices , has asymptotic computational load ( acl ) of @xmath180 flops per iteration . in the second stage ,",
    "the empirical mt - canonical correlation coefficients and directions are obtained _ simultaneously _ by solving the gevd problem ( [ gevd_pmtcca_2 ] ) with acl of @xmath181 flops . unlike the empirical mtcca ,",
    "the empirical icca @xcite involves a _ sequence _ of @xmath182-dimensional numerical maximizations , one for each pair of canonical directions , using an iterative newton - raphson algorithm .",
    "it can be shown that each iteration of the newton - rafson algorithm , which involves re - estimation of the mutual - information in a non - parametric manner and inversion of a hessian matrix , has acl of @xmath183 flops , where @xmath32 denotes a canonical directions pair index . the empirical kcca procedure @xcite-@xcite , which involves computation of two @xmath184 gram matrices followed by solving a gevd problem , has acl of @xmath185 flops .",
    "hence , one sees that unlike the empirical icca and kcca , the computational complexity of the empirical mtcca is linear in @xmath156 , which makes it favorable in large samples size scenarios .",
    "in this section , we illustrate the use of empirical lcca , icca , kcca and mtcca for graphical model selection . in every example below the empirical mtcca",
    "was performed with the exponential and gaussian mt - functions via the procedure in appendix [ empmtcca ] . in icca , the empirical mutual - information , @xmath186 , between each pair of canonical variates was mapped to the interval @xmath187 $ ] via the formula @xmath188 which produce the empirical informational canonical correlation coefficients .",
    "the empirical kcca was performed using gaussian radial basis function kernels .",
    "since kcca masks the original coordinates of @xmath0 and @xmath1 , it is not illustrated for the graphical model selection tasks in simulation examples 1 and 2 , which involve variable selection . in simulation examples 1 and 2 , the canonical correlation coefficients and canonical directions were estimated using @xmath189 i.i.d .",
    "samples of @xmath0 and @xmath1 .",
    "the statistical significance of the empirical canonical correlation coefficients was tested using empirical estimates of @xmath190-values associated with rejecting the null - hypothesis of no statistical dependence between @xmath0 and @xmath1 ( see appendix [ pval ] ) .      in this example",
    ", we consider the random vectors @xmath191^{t}$ ] and @xmath192^{t}$ ] , where @xmath193 and @xmath194 , @xmath195 , @xmath196 , and @xmath197 are mutually independent standard normal random variables .",
    "for this example , the pair of linear combinations of the form @xmath34 having maximal dependency is obtained for the vector pair @xmath198^{t},{{\\bf{b}}}_{1}=\\left[1,0\\right]^{t})$ ] which are identical to the true first - order mt - canonical directions . in this example , all pairs of linear combinations of the form @xmath28 and @xmath29 have zero linear correlation even though they are not statistically independent .",
    "the dependencies between @xmath0 and @xmath1 are depicted by the bipartite graphical model in fig .",
    "[ graphmod1 ] .",
    "the averaged estimates of the mt , linear , and informational canonical correlation coefficients and their corresponding averaged @xmath190-values , based on 1000 monte - carlo simulations , are given in table [ tab1 ] .",
    "the sample means and standard deviations of the absolute dot products of @xmath199 and @xmath200 , based on @xmath201 monte - carlo simulations , are given in table [ tab2 ] .",
    "the absolute dot products should be equal to 1 when the estimated canonical directions @xmath202 , @xmath203 are equal to @xmath204^{t}$ ] , @xmath205^{t}$ ] , respectively .",
    "one can notice that in contrast to lcca , the mtcca and icca detect the true dependencies between @xmath0 and @xmath1 , depicted by the bipartite graphical model in figs .",
    "[ graphmod1 ] .",
    ".simulation example 1 : the averaged estimates of the mt , linear , and informational canonical correlation coefficients and their corresponding averaged @xmath190-values ( in parentheses ) .",
    "[ cols=\"^,^,^,^,^\",options=\"header \" , ]     [ tab4 ]      here , mtcca is applied to a real world example of capturing long - term associations between pairs of companies traded on the nasdaq and nyse stock markets .",
    "the compared companies were microsoft ( msft ) , intel ( intc ) , apple ( aapl ) , merck ( mrk ) , pfizer ( pfe ) , johnson and johnson ( jnj ) , american express ( axp ) , jp morgan ( jpm ) , and bank of america ( bac ) .",
    "for each pair of companies , we considered the random vectors @xmath206^{t}$ ] and @xmath207^{t}$ ] .",
    "the variables @xmath194 and @xmath208 are the log - ratios of two consecutive daily closing prices of a stock , called log - returns .",
    "the variables @xmath195 and @xmath196 are the log - ratios of two consecutive daily trading volumes of a stock , called log - volume ratios .",
    "consecutive daily measurements of @xmath0 and @xmath1 from january 2 , 2001 to december 31 , 2010 , comprising 2514 samples , were obtained from the wrds database @xcite .",
    "[ fig_2_a ] and [ fig_2_b ] display the matrix of empirical first - order mt - canonical correlation coefficients for the exponential and gaussian mt - functions , respectively . figs .",
    "[ fig_2_c]-[fig_2_e ] show the matrix of empirical first - order canonical correlation coefficients obtained by lcca , icca and kcca , respectively .",
    "note that mtcca and kcca better cluster companies in similar sectors : ( msft , intc , aapl ) - technology , ( mrk , pfe , jnj ) - pharmaceuticals , ( axp , jpm , bac ) - financial . in this example , the @xmath190-values associated with all empirical first - order canonical correlation coefficients were less than @xmath209 .",
    "the empirical first - order canonical correlation coefficients were used for constructing graphical models in which the nodes represent the compared companies . the criterion for connecting a pair of nodes",
    "was set to empirical first - order canonical correlation coefficient greater than a threshold @xmath210 . in figs .",
    "[ graphmodfinancial1]-[graphmodfinancial3 ] the graphical models selected by mtcca with exponential mt - functions are compared to lcca , icca and kcca , respectively .",
    "similarly , in figs . [ graphmodfinancial4]-[graphmodfinancial6 ] the graphical models selected by mtcca with gaussian mt - functions are compared to lcca , icca and kcca , respectively . in the first column of each figure",
    "we show the graphs selected by mtcca for @xmath211 . in the second column",
    "we show the corresponding graphs selected by the other compared method by scanning @xmath210 over the interval @xmath212 $ ] and finding the graph with minimum edit distance @xcite .",
    "the symmetric difference graphs are shown in the third column .",
    "the red lines in the symmetric difference graphs indicate edges found by mtcca and not by the other compared method , and vice - versa for the black lines .",
    "note that for all of the threshold parameters @xmath210 investigated , the mttca graph shows equal or larger number of dependencies than the closest lcca , icca and kcca graphs .",
    "this result suggests that mtcca has captured more dependencies than lcca , icca and kcca . while there is no ground truth validation , the fact that mtcca clusters together companies in similar sectors ( banking , pharmaceuticals , and technology ) provides anecdotal support for the power and applicability of mtcca .",
    "[ fig3 ] depicts the distribution of the empirical mt , linear , and informational first - order canonical directions .",
    "let @xmath213^{t}$ ] and @xmath214^{t}$ ] on the unit circle .",
    "observe that in mtcca ( first and second columns ) @xmath215 and @xmath216 are relatively small in comparison to @xmath217 and @xmath218 .",
    "one can conclude that , unlike lcca and icca , mtcca is zeroing in on the strong non - linear dependencies between the daily log - returns of these companies and is de - emphasizing the daily log - volume ratios .",
    "this analysis is not performed for kcca since the empirical canonical directions obtained by kcca do not correspond to the original coordinates of @xmath0 and @xmath1 .",
    "we note that in this example the difference between mtcca and icca may possibly arise from the sensitivity of fixed kernel density estimation , preformed in icca , to the heavy - tailed financial data @xcite .",
    "in this paper , lcca was generalized by applying a structured transform to the joint probability distribution of @xmath0 and @xmath1 . by modifying the functions associated with the transform , this generalization , called mtcca , preserves independence and captures non - linear dependencies .",
    "two classes of mtcca were proposed based on specification of mt - functions in the exponential and gaussian families , respectively .",
    "the proposed mtcca approach was compared to lcca , icca and kcca for graphical model selection in simulated data having non - linear dependencies , and for measuring long - term associations between pairs of companies traded on the nasdaq and nyse stock markets .",
    "it is likely that there exist other classes of mt - functions that have a similar capability to accurately detect non - linear dependencies .    in the paper",
    "we have shown that the hessian of the joint cumulant generating function ( [ offhessxy ] ) is a special case of measure transformed covariance matrix with exponential mt - functions .",
    "therefore , in similar to the generalization proposed in this paper , the techniques in @xcite-@xcite , which are based on hessians of the cumulant generating function , may also be generalized by the measure - transformation framework .",
    "this research was supported in part by aro grant w911nf-11 - 1 - 0391 .      1 .   * property [ p1 ] : * + since @xmath219 is nonnegative , then by corollary 2.3.6 in @xcite @xmath57 is a measure on @xmath5 . furthermore , @xmath220 so that @xmath57 is a probability measure on @xmath5 .",
    "* property [ p2 ] : * + follows from definitions 4.1.1 and 4.1.3 in @xcite .",
    "* property [ p3 ] * : + let @xmath73 and @xmath74 denote the marginal probability measures of @xmath57 , defined on @xmath221 and @xmath222 , respectively .",
    "additionally , let @xmath223 and @xmath224 denote arbitrary sets in the @xmath6-algebras @xmath221 and @xmath222 , respectively . using ( [ measuretransform ] ) and ( [ varphidef ] ) , the assumed statistical independence of @xmath0 and @xmath1 under @xmath8 , and tonelli s theorem @xcite : @xmath225}d\\pxy\\left({{\\bf{x}}},{{\\bf{y}}}\\right ) \\\\\\nonumber & = & \\int\\limits_{a_{x}}\\frac{u\\left({{\\bf{x}}}\\right)}{{\\rm{e}}\\left[u\\left({{\\bf{x}}}\\right);\\px\\right]}d\\px\\left({{\\bf{x}}}\\right ) \\int\\limits_{\\ycalsc}\\frac{v\\left({{\\bf{y}}}\\right)}{{\\rm{e}}\\left[v\\left({{\\bf{y}}}\\right);\\py\\right]}d\\py\\left({{\\bf{y}}}\\right ) = \\int\\limits_{a_{x}}\\frac{u\\left({{\\bf{x}}}\\right)}{{\\rm{e}}\\left[u\\left({{\\bf{x}}}\\right);\\px\\right]}d\\px\\left({{\\bf{x}}}\\right).\\end{aligned}\\ ] ] similarly , it can be shown that @xmath226}d\\py\\left({{\\bf{y}}}\\right)$ ] , and @xmath227}d\\px\\left({{\\bf{x}}}\\right ) \\int\\limits_{a_{y}}\\frac{v\\left({{\\bf{x}}}\\right)}{{\\rm{e}}\\left[v\\left({{\\bf{y}}}\\right);\\px\\right]}d\\py\\left({{\\bf{y}}}\\right ) = \\qx\\left(a_{x}\\right)\\qy\\left(a_{y}\\right).\\ ] ] therefore , since @xmath223 and @xmath224 are arbitrary , @xmath0 and @xmath1 are statistically independent under the transformed probability measure @xmath57 .",
    "* property [ p4 ] * : + according to the definition of @xmath219 in ( [ varphidef ] ) , the strict positivity of @xmath228 and @xmath229 , and property [ p2 ] , we have that @xmath57 is absolutely continuous w.r.t . @xmath8 with strictly positive radon - nikodym derivative @xmath230 . therefore ,",
    "by proposition 4.1.2 in @xcite it is implied that @xmath8 is absolutely continuous w.r.t .",
    "@xmath57 with a strictly positive radon - nikodym derivative given by @xmath231 + hence , let @xmath223 and @xmath224 denote arbitrary sets in the @xmath6-algebras @xmath221 and @xmath222 , respectively . using ( [ varphidef ] ) , ( [ radnik2 ] ) , the assumed statistical independence of @xmath0 and @xmath1 under @xmath57 , and tonelli s theorem @xcite : @xmath232\\int\\limits_{a_{x}}\\frac{1}{u\\left({{\\bf{x}}}\\right)}d\\qx\\left({{\\bf{x}}}\\right)\\int\\limits_{a_{y}}\\frac{1}{v\\left({{\\bf{y}}}\\right)}d\\qy\\left({{\\bf{y}}}\\right).\\end{aligned}\\ ] ] similarly , it can be shown that @xmath233{\\rm{e}}\\left[\\frac{1}{v\\left({{\\bf{y}}}\\right)};\\qy\\right ] \\int\\limits_{a_{x}}\\frac{1}{u\\left({{\\bf{x}}}\\right)}d\\qx\\left({{\\bf{x}}}\\right)\\end{aligned}\\ ] ] and @xmath234{\\rm{e}}\\left[\\frac{1}{u\\left({{\\bf{x}}}\\right)};\\qx\\right ] \\int\\limits_{a_{y}}\\frac{1}{v\\left({{\\bf{y}}}\\right)}d\\qy\\left({{\\bf{y}}}\\right).\\end{aligned}\\ ] ] now , using ( [ expdef ] ) , ( [ varphidef ] ) , and ( [ measuretransformradnik ] ) we have that @xmath235={\\rm{e}}\\left[\\frac{1}{u\\left({{\\bf{x}}}\\right)};\\qxy\\right ] = { \\rm{e}}\\left[\\frac{\\varphi_{u , v}\\left({{\\bf{x}}},{{\\bf{y}}}\\right)}{u\\left({{\\bf{x}}}\\right)};\\pxy\\right ] = \\frac{{\\rm{e}}\\left[{v\\left({{\\bf{y}}}\\right)};\\py\\right]}{{\\rm{e}}\\left[u\\left({{\\bf{x}}}\\right)v\\left({{\\bf{y}}}\\right);\\pxy\\right]},\\ ] ] and similarly , @xmath236 = \\frac{{\\rm{e}}\\left[{u\\left({{\\bf{x}}}\\right)};\\px\\right]}{{\\rm{e}}\\left[u\\left({{\\bf{x}}}\\right)v\\left({{\\bf{y}}}\\right);\\pxy\\right]}.\\ ] ] additionally , by setting @xmath237 and @xmath238 in ( [ prop4eq1 ] ) , followed by using ( [ expdef ] ) , ( [ prop4eq4 ] ) , and ( [ prop4eq5 ] ) it is implied that @xmath239={\\rm{e}}\\left[u\\left({{\\bf{x}}}\\right);\\px\\right]{\\rm{e}}\\left[v\\left({{\\bf{y}}}\\right);\\py\\right].\\end{aligned}\\ ] ] finally , substitution of ( [ prop4eq7 ] ) into ( [ prop4eq1 ] ) , ( [ prop4eq5 ] ) into ( [ prop4eq2 ] ) , and ( [ prop4eq4 ] ) into ( [ prop4eq3 ] ) yields @xmath240}{u\\left({{\\bf{x}}}\\right)}d\\qx\\left({{\\bf{x}}}\\right ) \\int\\limits_{a_{y}}\\frac{{\\rm{e}}\\left[v\\left({{\\bf{y}}}\\right);\\py\\right]}{v\\left({{\\bf{y}}}\\right)}d\\qy\\left({{\\bf{y}}}\\right ) = \\px\\left(a_{x}\\right)\\py\\left(a_{y}\\right),\\ ] ] and therefore , since @xmath223 and @xmath224 are arbitrary , @xmath0 and @xmath1 are statistically independent under @xmath8 .      using ( [ offhessxy ] ) and ( [ mongenfunc ] )",
    "one can verify that if the condition in ( [ indcond ] ) is satisfied , then @xmath241 where @xmath242 and @xmath243 are the marginal moment generating functions of @xmath0 and @xmath1 , respectively .",
    "the joint moment generating function reduced to any open region containing the origin , within its region of convergence , uniquely determines the joint distribution @xcite , @xcite ( this property stems from the analyticity of the joint moment generating function about the origin ) .",
    "hence , by the relation above we have that @xmath0 and @xmath1 are statistically independent .",
    "conversely , if @xmath0 and @xmath1 are statistically independent under @xmath8 , then by property [ p3 ] of proposition [ prop1 ] we have that @xmath244 for all @xmath245 .      using ( [ varphidef ] ) , ( [ rxymod_pxy ] ) , and ( [ gausskernel ] ) one can easily verify that @xmath246 } { { \\rm{e}}\\left[g\\left({{\\bf{x}}}\\right)h\\left({{\\bf{y}}}\\right)\\exp\\left(\\frac{{{\\bf{s}}}^{t}{{\\bf{x}}}}{\\sigma^{2 } } + \\frac{\\tvec^{t}{{\\bf{y}}}}{\\tau^{2}}\\right);\\pxy\\right]}- \\\\ \\frac{{\\rm{e}}\\left[{{\\bf{x}}}{g}\\left({{\\bf{x}}}\\right)h\\left({{\\bf{y}}}\\right)\\exp\\left(\\frac{{{\\bf{s}}}^{t}{{\\bf{x}}}}{\\sigma^{2 } } + \\frac{\\tvec^{t}{{\\bf{y}}}}{\\tau^{2}}\\right);\\pxy\\right]{\\rm{e}}\\left[{{\\bf{y}}}^{t}g\\left({{\\bf{x}}}\\right)h\\left({{\\bf{y}}}\\right)\\exp\\left(\\frac{{{\\bf{s}}}^{t}{{\\bf{x}}}}{\\sigma^{2 } } + \\frac{\\tvec^{t}{{\\bf{y}}}}{\\tau^{2}}\\right);\\pxy\\right ] } { { \\rm{e}}^{2}\\left[g\\left({{\\bf{x}}}\\right)h\\left({{\\bf{y}}}\\right)\\exp\\left(\\frac{{{\\bf{s}}}^{t}{{\\bf{x}}}}{\\sigma^{2 } } + \\frac{\\tvec^{t}{{\\bf{y}}}}{\\tau^{2}}\\right);\\pxy\\right ] } , \\end{gathered}\\ ] ] where @xmath247 additionally , define @xmath248\\ ] ] as the joint moment generating function of @xmath0 and @xmath1 under the transformed probability measure @xmath249 associated with the mt - functions @xmath250 and @xmath251 in ( [ ghdef ] ) . using ( [ expdef ] ) and ( [ measuretransformradnik ] ) it can be shown that @xmath252,\\ ] ] where @xmath253 is defined in ( [ varphidef ] ) . therefore , by ( [ offhessxy21 ] ) and ( [ mxy23 ] ) we have that @xmath254 hence , if the condition in ( [ indcond2 ] ) is satisfied , then by the properties of the joint moment generating function @xcite , @xcite , it is implied that @xmath0 and @xmath1 are statistically independent under @xmath249 .",
    "thus , since the mt - functions @xmath250 and @xmath251 are strictly positive , then by property [ p4 ] of proposition [ prop1 ] we conclude that @xmath0 and @xmath1 are statistically independent under @xmath8 .",
    "conversely , if @xmath0 and @xmath1 are statistically independent under @xmath8 , then by property [ p3 ] of proposition [ prop1 ] we have that @xmath255 for all @xmath245 .",
    "let @xmath256 denote a @xmath190-dimensional column vector , where @xmath257_{k}=\\delta_{i , k}$ ] , and @xmath258 denotes the kronecker delta function .",
    "it is easily verified that @xmath259 hence , by ( [ lowerboundproofeq1 ] ) @xmath260 where the last equality stems from the invariance of @xmath261 to normalization of @xmath262 and @xmath263 . therefore , according to ( [ ccaoptprobmod ] ) , ( [ psidef ] ) and ( [ lowerboundproofeq2 ] ) , the relation in ( [ lowerboundeq ] ) is verified .",
    "if @xmath264 , then by ( [ lowerboundeq ] ) and the positivity of @xmath265 @xmath266 therefore , since by ( [ maxprob ] ) @xmath155 are the maximizers of @xmath152 over @xmath151 , which is a closed region in @xmath106 containing the origin , we have that @xmath267 hence , by the definition ( [ psidef ] ) of @xmath265 , @xmath268 on the interior of @xmath151 , which is an open region in @xmath106 containing the origin . thus , since the mt - functions @xmath64 and @xmath65 are chosen according to ( [ expkernel ] ) or ( [ gausskernel ] ) , by theorems [ offoriginindepprop ] and [ gaussindepprop ] @xmath0 and @xmath1 must be statistically independent under @xmath8 .",
    "conversely , if @xmath0 and @xmath1 are statistically independent under @xmath8 , then by property [ p3 ] of proposition [ prop1 ] we have that @xmath268 for all @xmath269 , and in particular for @xmath155 . therefore , by ( [ ccaoptprobmod ] ) , @xmath264 .",
    "it suffices to show that if the conditions in ( [ cond1 ] ) and ( [ cond2 ] ) are satisfied , then @xmath172 almost surely as @xmath173 .",
    "convergence proofs for @xmath176 and @xmath177 are very similar and therefore omitted .      in the following , the limits of the series in the r.h.s . of ( [ xy_lim])-([muy_lim ] )",
    "are obtained .",
    "additionally , in remark [ remark3 ] below , we show that the assumption in ( [ nonzeroassumption ] ) is satisfied .",
    "since @xmath158 , @xmath159 is a sequence of i.i.d .",
    "samples of @xmath157 , then the random matrices @xmath275 , @xmath159 , in the r.h.s . of ( [ xy_lim ] ) , define a sequence of i.i.d .",
    "samples of @xmath276 . moreover , if @xmath277<\\infty$ ] , for any @xmath278 , @xmath279<\\infty$ ] , for any @xmath280 , @xmath281<\\infty$ ] , and @xmath282<\\infty$ ] , then @xmath283 & \\leq & \\left({\\rm{e}}\\left[\\left(x_{k}y_{l}\\right)^{2};\\pxy\\right]{\\rm{e}}\\left[\\left(u\\left({{\\bf{x}}}\\right)v\\left({{\\bf{y}}}\\right)\\right)^{2};\\pxy\\right]\\right)^{\\frac{1}{2 } } \\\\\\nonumber & \\leq & \\left({\\rm{e}}\\left[x^{4}_{k};\\px\\right]{\\rm{e}}\\left[y^{4}_{l};\\py\\right]{\\rm{e}}\\left[u^{4}\\left({{\\bf{x}}}\\right);\\px\\right]{\\rm{e}}\\left[v^{4}\\left({{\\bf{y}}}\\right);\\py\\right]\\right)^{\\frac{1}{4}}<\\infty,\\end{aligned}\\ ] ] for any @xmath278 and any @xmath280 , where the second and third semi - inequalities stem from the hlder inequality for random variables @xcite .",
    "therefore , by khinchine s strong law of large numbers ( kslln ) @xcite @xmath284\\hspace{0.2cm}{\\rm{a.s.}}\\ ] ] similarly , it can be shown that if the conditions in ( [ cond1 ] ) and ( [ cond2 ] ) are satisfied , then by the kslln @xmath285\\hspace{0.2cm}{\\rm{a.s.}},\\ ] ] @xmath286\\hspace{0.2cm}{\\rm{a.s.}},\\ ] ] and @xmath287\\hspace{0.2cm}{\\rm{a.s.}}\\ ] ]      therefore , since the sequences in the l.h.s .",
    "of ( [ xy_lim])-([muy_lim ] ) are obtained by continuous mappings of the elements of the sequences in their r.h.s .",
    ", then by ( [ nomxylim])-([denlim ] ) , and the mann - wald theorem @xcite @xmath288}{{\\rm{e}}\\left[u\\left({{\\bf{x}}}\\right)v\\left({{\\bf{y}}}\\right);\\pxy\\right ] } = { \\rm{e}}\\left[{{\\bf{x}}}{{\\bf{y}}}^{t}\\varphi_{u , v}\\left({{\\bf{x}}},{{\\bf{y}}}\\right);\\pxy\\right]\\hspace{0.2cm}{\\rm{a.s.}}\\ ] ] @xmath289}{{\\rm{e}}\\left[u\\left({{\\bf{x}}}\\right)v\\left({{\\bf{y}}}\\right);\\pxy\\right ] } = { \\rm{e}}\\left[{{\\bf{x}}}\\varphi_{u , v}\\left({{\\bf{x}}},{{\\bf{y}}}\\right);\\pxy\\right]\\hspace{0.2cm}{\\rm{a.s.}}\\ ] ] and @xmath290}{{\\rm{e}}\\left[u\\left({{\\bf{x}}}\\right)v\\left({{\\bf{y}}}\\right);\\pxy\\right ] } = { \\rm{e}}\\left[{{\\bf{y}}}\\varphi_{u , v}\\left({{\\bf{x}}},{{\\bf{y}}}\\right);\\pxy\\right]\\hspace{0.2cm}{\\rm{a.s.}},\\ ] ] where the last equalities in ( [ xy_lim_closed])-([muy_lim_closed ] ) follow from the definition of @xmath291 in ( [ varphidef ] ) .    thus , since the sequence in the l.h.s . of ( [ rxy_uv_est_lim ] ) is obtained by continuous mappings of the elements of the sequences in its r.h.s .",
    ", then by ( [ xy_lim_closed])-([muy_lim_closed ] ) , the mann - wald theorem , and ( [ rxymod_pxy ] ) it is concluded that @xmath172 a.s . as @xmath173 .        1 .   estimate the optimal mt - functions parameters in ( [ expkernel ] ) and ( [ gausskernel ] ) according to @xmath292 where @xmath265 is defined in ( [ psidef ] ) , and @xmath293 , @xmath294 , and @xmath295 are the estimates in ( [ rx_uv_est])-([rxy_uv_est ] ) of the covariance matrices @xmath296 , @xmath297 , and @xmath298 , respectively . the maximization in ( [ maxprob2 ] ) was carried out numerically using gradient ascent over the search region @xmath151 , which was selected as follows : 1 .   for the exponential mt - functions , we chose @xmath299 where @xmath300 , and @xmath301 is a quadratic empirical approximation of the joint moment generating function @xmath105 in ( [ mongenfunc ] ) .",
    "the vectors @xmath302 and @xmath303 denote the sample expectations of @xmath0 and @xmath1 , respectively .",
    "the matrices @xmath304 , @xmath305 , and @xmath306 denote sample auto - correlation matrix of @xmath0 , the sample auto - correlation matrix of @xmath1 , and their cross - correlation matrix , respectively .",
    "since @xmath300 and @xmath307 is quadratic and takes a unit value at the origin , then @xmath308 defines a closed region in @xmath106 containing the origin .",
    "2 .   for the gaussian mt - functions ,",
    "the search region was set to @xmath309 where @xmath310 and @xmath311 are the @xmath32-th and @xmath169-th entries of @xmath97 and @xmath98 , respectively , and @xmath312 is the empirical @xmath313-th percentile of the random variable @xmath314 .",
    "one can notice that @xmath315 defines a closed rectangle in @xmath106 . in the considered examples it was verified that @xmath315 contains the origin .",
    "we note that in case where @xmath315 does not contain the origin , one can always subtract the expectations of @xmath0 and @xmath1 and perform mtcca on @xmath316 $ ] and @xmath317 $ ] .",
    "2 .   obtain estimates of the mt - canonical correlation coefficients , @xmath318 and estimates of the mt - canonical directions , @xmath319 by solving the following gevd equation @xmath320\\left[\\begin{array}{c}{{{\\bf{a } } } } \\\\{{{\\bf{b}}}}\\end{array}\\right]=\\rho\\left[\\begin{array}{cc}{\\hat{\\bsigma}^{\\left(u , v\\right)}_{{{\\mbox{\\boldmath \\tiny $ { { \\bf{x}}}$}}}}\\left(\\hat{{{\\bf{s}}}}^{*},\\hat{\\tvec}^{*}\\right ) } & { { { \\bf{0 } } } } \\\\ { { { \\bf{0 } } } } & { \\hat{\\bsigma}^{\\left(u , v\\right)}_{{{\\mbox{\\boldmath \\tiny $ { { \\bf{y}}}$}}}}\\left(\\hat{{{\\bf{s}}}}^{*},\\hat{\\tvec}^{*}\\right)}\\end{array}\\right]\\left[\\begin{array}{c}{{{\\bf{a } } } } \\\\{{{\\bf{b}}}}\\end{array}\\right],\\ ] ] where @xmath321 is the @xmath32-th largest generalized eigenvalue of the pencil in ( [ gevd_pmtcca_2 ] ) , and @xmath322^{t}=\\left[\\hat{{{\\bf{a}}}}^{t}_{k},\\hat{{{\\bf{b}}}}^{t}_{k}\\right]^{t}$ ] is its corresponding generalized eigenvector .    in all considered examples the width parameters @xmath6 and @xmath139 of the gaussian mt - functions ( [ gausskernel ] )",
    "were set to @xmath323 and @xmath324 , where @xmath325 denotes the empirical standard deviation the random variable @xmath314 .",
    "let @xmath326 and @xmath327 denote sequences of @xmath156 i.i.d .",
    "samples of @xmath0 and @xmath1 , respectively . additionally , let @xmath328 denote the empirical @xmath32-th order canonical correlation coefficient based on @xmath329 and @xmath330 . a bootstrap based procedure for testing the statistical significance of the empirical @xmath32-th order canonical correlation coefficient",
    "is specified below :    1 .",
    "repeat the following procedure for @xmath331 times ( with index @xmath332 ) : 1 .",
    "generate a randomly permuted version of the sequence @xmath330 , denoted by @xmath333 .",
    "2 .   compute the statistic @xmath334 .",
    "2 .   construct an empirical cumulative distribution function from the sample statistics @xmath335 , @xmath332 , as @xmath336 where @xmath337 is an indicator random variable on its argument @xmath338 .",
    "3 .   compute the @xmath190-value @xmath339 where @xmath340 is the true detection statistic .",
    "4 .   if @xmath341 , then we have that @xmath328 is significant at level @xmath313 , leading to rejection of the null - hypothesis of no dependence between @xmath0 and @xmath1",
    ".              t.k .",
    "kim , j. klitter , and r. cipolla , `` discriminative learning and recognition of image set classes using canonical correlations , '' _ ieee trans .",
    "pattern analysis and machine intelligence , _ vol .",
    "1005 - 1018 , 2007 .",
    "x. wang , h. ge , and i. p. kirsteins , `` direction - of - arrival estimation using distributed arrays : a canonical coordinates perspective with limited array size and sample support , '' _ proc . of the icassp 2010 , _ pp .",
    "2622 - 2625 , 2010 .",
    "y. yamanishi , j. p. vert , a. nakaya , and m. kanehisa , `` extraction of correlated gene clusters from multiple genomic data by generalized kernel canonical correlation analysis , '' _ bioinformatics , _ vol .",
    "19 , pp . 323i-330i , 2003 .",
    "h. suetani , y. iba , and k. aihara , `` detecting hidden synchronization of chaotic dynamical systems : a kernel - based approach , '' _ journal of physics a : mathematical and general , _ vol .",
    "10723 - 10742 , 2006 ."
  ],
  "abstract_text": [
    "<S> in this paper linear canonical correlation analysis ( lcca ) is generalized by applying a structured transform to the joint probability distribution of the considered pair of random vectors , i.e. , a transformation of the joint probability measure defined on their joint observation space . </S>",
    "<S> this framework , called measure transformed canonical correlation analysis ( mtcca ) , applies lcca to the data after transformation of the joint probability measure . </S>",
    "<S> we show that judicious choice of the transform leads to a modified canonical correlation analysis , which , in contrast to lcca , is capable of detecting non - linear relationships between the considered pair of random vectors . unlike kernel canonical correlation analysis , where the transformation is applied to the random vectors , in mtcca </S>",
    "<S> the transformation is applied to their joint probability distribution . </S>",
    "<S> this results in performance advantages and reduced implementation complexity . </S>",
    "<S> the proposed approach is illustrated for graphical model selection in simulated data having non - linear dependencies , and for measuring long - term associations between companies traded in the nasdaq and nyse stock markets .    </S>",
    "<S> * *    * *    * *    * s *    * *    association analysis , canonical correlation analysis , graphical model selection , multivariate data analysis , probability measure transform . </S>"
  ]
}