{
  "article_text": [
    "realistic networks show heterogeneous interconnection delays . the cortex is a paradigmatic example of such networks . in the brain ,",
    "neurons form large - scale assemblies ( termed neural populations ) subject to an intense noise .",
    "they communicate through the emission of spikes ( action potentials ) that are transmitted through synapses that can be chemical or , less often , electrical .",
    "the transport of spikes through the axons takes a specific time , function of the length of the axon and of the time taken for the signal to be transmitted through synapses , and therefore are highly heterogeneous .",
    "moreover , chemical synapses modify the membrane potential of the post - synaptic neuron through a complex mechanism of release and binding of neurotransmitters .",
    "this mechanism takes a specific time , and results in random variations of the current transmitted through the different synapses and also from spike to spike .",
    "models describing the emergent behavior arising from the interaction of neurons in large - scale networks largely overlooked both phenomena of heterogeneous delays and stochastic synapses .",
    "most models have relied on continuum limits ever since the seminal work of wilson and cowan and amari @xcite .",
    "such models tend to represent the activity of the network through a macroscopic variable , the population - averaged firing rate , that is generally assumed to be deterministic .",
    "many analytical and numerical results and properties have been derived from these equations and related to cortical phenomena , for instance for the problem of spatio - temporal pattern formation in spatially extended models ( see e.g.  @xcite ) .",
    "this approach tends to implicitly make the assumption that the effect of noise and heterogeneities vanishes in large populations .",
    "a different approach has been to study regimes where the activity is uncorrelated .",
    "a number of computational studies on the integrate - and - fire neuron showed that under certain conditions neurons in large assemblies end up firing asynchronously , producing null correlations @xcite . in these regimes , the correlations in the firing activity decrease towards zero in the limit where the number of neurons tends to infinity .",
    "the emergent global activity of the population in this limit is deterministic , and evolves according to a mean - field firing rate equation .",
    "however , these states arise in sparsely connected networks which is not the case of cortical columns . in order to go beyond asynchronous states and take into account the stochastic nature of the firing and how this activity scales as the network size increases",
    ", different approaches have been developed , such as the population density method and related approaches @xcite .",
    "most of these approaches involve expansions in terms of the moments of the resulting random variable , and the moment hierarchy needs to be truncated which is a quite hard task that can raise a number of technical issues ( see e.g.@xcite ) .",
    "homogeneous spatially extended systems of neurons were recently analyzed using the theory of probability  @xcite .",
    "these were the first studies considering individual delays between neurons .",
    "in these studies , the propagation delays between neurons were considered constant , and in these cases , no specific delay - induced transition was identified .",
    "heterogeneous networks have been considerably less analyzed .",
    "one notable exception is the work of sompolinsky and collaborators  @xcite recently analyzed from a mathematical viewpoint using large deviations techniques  @xcite , where the authors considered random heterogeneous connections between neurons .",
    "the main question we shall address in this article is the effect of heterogeneous delays on the macroscopic dynamics of such neuronal areas in the presence of stochastic coupling .",
    "although it now firmly established that delays are fundamental for shaping the activity of large - scale neuronal networks  @xcite , very little is understood about the type of delays involved in such networks .",
    "the question of how these individual delays translate in macroscopic limits , and how the heterogeneity in the distribution of delays affect macroscopic behaviors , hence has deep implications , and is still largely open . at the microscopic scale",
    ", it is relatively clear that transmission delays are well approximated by constant delay depending on the distance between neurons and on the typical synaptic time scale .",
    "these constant delays hence vary depending on the pair of neurons considered and are related to the topology of the network in the physical space .    considering random heterogeneous delays between neurons , we establish the limit , as the number of neurons tend to infinity , of the network equations .",
    "we will show that the propagation of chaos property occurs in these systems , and that the asymptotic macroscopic behavior in the limit where the number of neurons tends to infinity is described by a mckean - vlasov equation with distributed delays , the delay measure being exactly the statistical distribution of individual delays .",
    "the dynamics of the obtained mckean - vlasov equations with distributed delays is very hard to analyze for general neuron models . in order to uncover the macroscopic dynamics of the neurons and their dependence on the distribution of delays , we eventually instantiate a particularly suitable model , the classical firing - rate model . in that case , that solutions are gaussian , and the mean and standard deviation satisfy a closed system of delay differential equations with distributed delays .",
    "this reduction allows using classical tools of the domain of infinite - dimensional dynamical systems to show generic qualitative transitions between different qualitative states , as a function of the delays and of the variance of the synaptic weights .",
    "in this section , we describe the mathematical formalism used throughout the manuscript .",
    "we shall analyze the dynamics of a relatively general neuron model , valid for most usual models used in computational neuroscience .",
    "the state of each neuron @xmath0 in the network is classically described by a @xmath1-dimensional variable @xmath2 , typically corresponding to the membrane potential of the neuron and possibly additional variables such as those related to ionic concentrations and gated channels ( see e.g.  @xcite ) .",
    "we consider networks composed of a finite number of populations @xmath3 .",
    "the populations differ through the intrinsic properties of each neurons and the input they receive .",
    "we assume that the number of neuron in each population @xmath4 , denoted @xmath5 increases as the network size increases , and tends to infinity in the limit considered , which we will be denoting @xmath6 .",
    "we define the population function that associates to a neuron @xmath0 the population @xmath7 it belongs to : @xmath8 .",
    "let us consider a single neuron @xmath0 belonging to population @xmath7 .",
    "the state of the neuron , @xmath9 , has an intrinsic dynamics governed by a nonlinear drift function @xmath10 ( including the intrinsic dynamics and the deterministic inputs ) and a diffusion matrix @xmath11 .",
    "each individual process @xmath12 takes values in @xmath13 , and when there is no interaction , is governed by the equation : @xmath14 where @xmath15 are independent @xmath16 brownian motions .",
    "this equation corresponds to the intrinsic dynamics of each individual diffusion , i.e. the behavior of a single neuron when disconnected of the network .",
    "when included in the network , the neurons interact with all other neurons and this interaction is modeled through a continuous function @xmath17 , multiplied by a coefficient , called the synaptic weight @xmath18 .",
    "these synaptic weights are themselves stochastic , due to the nature of the synaptic transmission .",
    "incoming interactions are known to be bounded , the total incoming connectivity from a given population ( say @xmath19 ) to a single neuron from population @xmath7 has a fixed averaged @xmath20 and standard deviation @xmath21 .",
    "we consider that the synaptic weights are stochastic , and are assumed to be equal , for a neuron @xmath0 in population @xmath7 and a neuron @xmath22 in population @xmath19 , to @xmath23 where @xmath24 are independent @xmath25-dimensional `` white noise '' processes related to the independent brownian motions @xmath26 introduced to neuron @xmath22 when the sign of @xmath18 changes .",
    "other more biologically relevant problems involve enforcing the synaptic weight not to change sign by modeling it as the solution of particular stochastic differential equation that does not change sign , such as the cox - ingersoll - ross process , and by fit our framework by formally adding the @xmath27 synaptic weights of neuron @xmath0 in the state variable @xmath9 of neuron @xmath0 . ] .",
    "the delay @xmath28 occurring in the interaction between neuron @xmath22 and @xmath0 , and related to the information transmission through the axons and the synapses , depend on the precise distance between neurons @xmath0 and @xmath22 .",
    "we assume that for any fixed neurons @xmath29 , the delays @xmath30 are pairwise independent ( and independent of the brownian motions involved in the network dynamics ) and identically distributed in each population , with a law denoted @xmath31 .",
    "this is a reasonable assumption from the modeling viewpoint . indeed ,",
    "neural populations can be considered to form certain clusters in the space in which the specific locations of neurons can be considered independent , and delays hence depend on the typical distance between the populations , their dispersion , and on the characteristic time constants of the synapse . from the referential of one given neuron @xmath0 , the resulting delays are hence independent . from the global network viewpoint , these delays are of course correlated ( distance between two points are symmetrical , topological relationship between neuronal locations induces relationship between distances , e.g. triangular inequality ) .",
    "let us denote by @xmath32 the largest possible delay in the network .",
    "all delay distributions hence charge only the interval @xmath33 $ ] .",
    "we eventually denote by @xmath34 the averaged delay between neurons of population @xmath7 and neurons of population @xmath19 , were the average is taken over all possible values of @xmath35 for @xmath0 in population @xmath7 ( for instance , averaged on all possible locations for neurons of population @xmath7 ) .",
    "the infinitesimal current the neuron @xmath0 receives from its neighbors is hence modeled as : @xmath36    for the sake of simplicity , we make an abuse of notations and replace the notation @xmath37 ( resp .",
    "@xmath38 ) by @xmath39 ( resp .",
    "@xmath40 ) .",
    "the resulting network equation reads : @xmath41 these equations are stochastic differential equations on the infinite - dimensional space of functions @xmath42,e)$ ] ( i.e. on the variable @xmath43)$ ] , see e.g.  @xcite ) of continuous functions of @xmath33 $ ] with values in @xmath13 .",
    "let us denote by @xmath44,e^p)$ ] .",
    "the initial conditions are not specified at this point .",
    "we will sometimes make the assumption that the network has chaotic initial condition , i.e. independent identically distributed initial conditions . in details , for @xmath45 a stochastic process with independent components , a chaotic initial condition on the network consists in setting the initial condition of all neurons @xmath0 of population @xmath7 to an independent copy of @xmath46 .",
    "for any @xmath47 , we make the following technical assumptions on the parameters of the model :    1 .",
    "[ assump : loclipsch ] @xmath48 and @xmath49 are uniformly locally lipschitz - continuous with respect to their second variable 2 .",
    "[ assump : loclipschb ] @xmath50 and @xmath51 are @xmath52-lipschitz - continuous , i.e. there exists a positive constant @xmath52 such that for all @xmath53 and @xmath54 in @xmath55 we have : @xmath56 for @xmath57 .",
    "[ assump : bbound ] there exists a @xmath58 such that : @xmath59 4 .",
    "[ assump : monotonegrowth ] the drift and diffusion functions satisfy the monotone growth condition : @xmath60    assumptions  [ assump : loclipsch ] and  [ assump : monotonegrowth ] are technical assumptions necessary to deal with the particular case of the fitzhugh - nagumo neuron model  @xcite .",
    "most classical neuron models are however defined through globally lipschitz - continuous vector fields .",
    "when the drift and diffusion functions are only locally lipschitz continuous , a classical localization argument allows extending the proofs done in the globally lipchitz continuous case , as done in  @xcite .",
    "this is why in the manuscript we will consider the case of globally lipschitz continuous functions @xmath48 and @xmath49 and refer the interested reader to  @xcite for extending these proofs to locally lipschitz continuous drift and diffusion functions .",
    "let us first state the following proposition ensuring well - posedness of the network system under the assumptions of the section :    [ pro : existenceuniquenessnetwork ] let @xmath61 , e^n))$ ] an initial condition of the network system",
    ". under the assumptions of the section , there exists a unique strong solution to the network equations .",
    "the proof of this proposition is a direct application of mao s result  @xcite , and essentially uses the same arguments as those of the proof theorem  [ thm : existenceuniqueness ] .",
    "the interested reader is invited to follow the steps of this demonstration to prove proposition  [ pro : existenceuniquenessnetwork ] .",
    "we address the problem of the asymptotic behavior , as the number of neurons @xmath62 goes to infinity , of these network equations , in particular the question of the propagation of chaos property in this randomly delayed , randomly interacting system .",
    "assuming translation invariance in the neural field , the delays distribution @xmath63 is only function of the neural population @xmath0 belongs to . in that case , for any realization of the synaptic delays @xmath28 , the propagation of chaos property states that , provided that the initial condition on the network is chaotic ( i.e. for all @xmath0 in population @xmath7 , the initial condition @xmath64}$ ] is an independent copy of a given process @xmath65 ) and when @xmath66 , the state of each neurons are independent for all times , and have a law given by a nonlinear mckean - vlasov equation that only depends on the neural population ( say , @xmath7 ) , which is the unique solution of the mckean - vlasov equations with distributed delays : @xmath67d\\eta_{\\alpha\\beta}(s ) \\,dt \\\\",
    "+ g_{\\alpha}(t,\\bar{x}^{\\alpha}_t)\\,dw_t^{\\alpha }      + \\sum_{\\gamma=1}^p\\int_{-\\tau}^0 { \\mathbbm{e}}_{\\bar{y}}[\\beta_{\\alpha\\beta}(\\bar{x}^{\\alpha}_t , \\bar{y}^{\\beta}_{t+s})]d\\eta_{\\alpha\\beta}(s ) \\,db^{\\alpha\\gamma}_t\\end{gathered}\\ ] ] where @xmath68 is a process independent of @xmath69 that has the same law , @xmath70 the expectation under the law of @xmath68 , @xmath71 and @xmath72 are independent adapted standard brownian motions of dimensions @xmath16 and @xmath73 respectively .",
    "in other words , the mean field equation can be written , denoting by @xmath74 the law of @xmath75 : @xmath76 where @xmath77 is the probability distribution of @xmath78 . in these equations ,",
    "@xmath79 for @xmath80 are independent standard @xmath81-dimensional brownian motions .",
    "this equation is also classically written as the mckean - vlasov fokker - planck equation on the probability density , with a slightly abuse of notations denoted @xmath82 , of the solution : @xmath83 with initial condition @xmath84}=p^{\\alpha}(t , x)$ ] where @xmath85 is the density of @xmath46 , if it exists .",
    "the same result holds when the neural field is not translation invariant ( i.e. @xmath86 varies depending on the choice of neuron @xmath0 in population @xmath7 ) , but in that case the result holds for the law of the limit distribution averaged on the law of the delays .    in that view",
    ", the equation is an implicit equation on the law of @xmath87 ( denoting when no confusion is possible the vector @xmath88 ) . in order to prove the propagation of chaos property",
    ", we will use the coupling method ( see e.g.  @xcite ) .",
    "the proof is in two steps : ( i ) we prove that the equation has a unique solution , and ( ii ) that the law of @xmath89 converges towards the law of and more precisely that for any finite set of neurons @xmath90 the law of @xmath91)$ ] converge almost surely towards a vector @xmath92)$ ] where the processes @xmath93 are independent and have the law of @xmath94 given by .",
    "in this section , we show existence and uniqueness of solutions for the delayed mckean - vlasov equation   that constitute the putative mean - field limit .",
    "let us denote by @xmath95 the set of probability distributions on @xmath96 the set continuous functions",
    "@xmath97 \\mapsto e^{p}$ ] , and @xmath98 the space of square - integrable processes .",
    "let @xmath99 ( respectively @xmath100 ) be a family of @xmath27 ( resp .",
    "@xmath101 ) independent @xmath16 ( resp .",
    "@xmath102)-dimensional standard brownian motion adapted on @xmath103 .",
    "let us also fixe @xmath104 a random variable , and @xmath105 an iid sequence with the same law as @xmath106 , that constitutes the chaotic initial condition of the network equations .",
    "we introduce the map @xmath107 map acting on stochastic processes and defined by : @xmath108 \\big)\\,d\\eta_{\\alpha\\gamma}(u ) \\,ds \\\\      & + \\int_0^t g_{\\alpha}(s , x^{\\alpha}_s)\\,dw_s^{\\alpha } + \\sum_{\\gamma=1}^p \\int_0^t \\int_{-\\tau}^0{\\mathbbm{e}}_{z}[\\beta_{\\alpha\\gamma}(x_s^{\\alpha } , z^{\\gamma}_{s+u})]\\,d\\eta_{\\alpha\\gamma}(u ) \\cdot db_s^{\\alpha\\gamma } \\;;\\ ; t>0 \\\\      & \\\\      & y_t=\\zeta_0^{\\alpha}(t ) \\qquad t\\in [ -\\tau , 0 ] \\end{cases}\\ ] ] where the process introduce a process @xmath109 has the same law as @xmath110 and to be independent of @xmath110",
    ". there is a trivial identification between the solutions of the mean - field equation and the fixed points of the map @xmath107 : any fixed point of @xmath107 provides a solution for equation and conversely any solution of equation constitute a fixed point of @xmath107 .",
    "let us start by proving that the possible solutions of the system have bounded second moment .",
    "[ lem : solul2 ] let @xmath111,e^{p})$ ] a square - integrable process . under the assumptions ( h1)-(h4 ) , there exists a constant @xmath112 depending on the parameters of the system and on the horizon @xmath113 , such that for any solution @xmath110 of the mean - field equation with initial condition @xmath114 : @xmath115}{\\mathbbm{e } } [ \\vert x_t \\vert^2]\\leq c(t).\\ ] ]    the proof is based on the application of it s formula for the squared modulus of @xmath116 , standard inequalities and gronwall s lemma .",
    "let @xmath110 be a solution of the mean - field equations , and @xmath117 the first time the process @xmath118 exceeds the quantity @xmath119 .",
    "due to the non - standard nature of the equation , let us underline the fact that it s formula is valid , i.e. that @xmath120 is a semimartingale . by definition ,",
    "it is clear that both @xmath121 and @xmath122 are @xmath123 measurable for all @xmath124 $ ] , and hence necessarily @xmath120 is a semi - martingale , i.e. the sum of a continuous adapted process of finite variation : @xmath125 \\,d\\eta_{\\alpha\\gamma}(u)\\big ) \\,ds\\ ] ] and a continuous @xmath126-local martingale , defined as the sum of different stochastic integral of a progressively measurable processes with respect to brownian motions : @xmath127\\,d\\eta_{\\alpha\\gamma}(u ) \\cdot db_s^{\\alpha\\gamma}\\ ] ] we can hence apply it formula to @xmath128 , and because of the particular form of the squared norm , we can treat each component @xmath129 separately .",
    "since all the different brownian motions involved are independent , we have for all @xmath130 : @xmath131 d\\eta_{\\alpha\\gamma}(u )      +      \\frac 1 2 \\sum_{\\gamma=1}^p   \\vert \\int_{-\\tau}^0 { \\mathbbm{e}}_{y}[\\beta_{\\alpha\\gamma}(x_s^{\\alpha},y_{s+u}^{\\gamma } ) ] d\\eta_{\\alpha\\gamma}(u ) \\vert^2 \\big\\}\\,ds \\\\      + \\int_0^{t\\wedge \\tau_n }   ( x_s^{\\alpha})^t g_{\\alpha}(s , x_s^{\\alpha } ) dw^{\\alpha}_t +   \\sum_{\\gamma=1}^p \\int_0^{t\\wedge \\tau_n } ( x_s^{\\alpha})^t\\int_{-\\tau}^0 { \\mathbbm{e}}_{y}[\\beta_{\\alpha\\gamma}(x_s^{\\alpha},y_{s+u}^{\\gamma } ) ]",
    "d\\eta_{\\alpha\\gamma}(u ) db^{\\alpha\\gamma}_s      \\end{gathered}\\ ] ]    the stochastic integral term has a null expectation , and the stieljes integration term involves the term @xmath132 , which is upperbounded because of assumption  [ assump : bbound ] by @xmath133 , and the term @xmath134 which is upperbounded , using assumption  [ assump : monotonegrowth ] , by @xmath135 . finally , assumption  [ assump : bbound ] again allows us to upperbound the term @xmath136 $ ] by @xmath137 . we hence have for all @xmath130 : @xmath138 & \\leq { \\mathbbm{e}}[\\vert \\zeta_0^{\\alpha}(0 ) \\vert^2 ] + 2\\int_0^{t\\wedge \\tau_n } \\big\\ { k(1+{\\mathbbm{e}}[\\vert x_s^{\\alpha}\\vert^2 ] )   + p \\sqrt{\\tilde{k } } ( 1+{\\mathbbm{e}}[\\vert x_s^{\\alpha}\\vert^2 ] ) \\\\      &",
    "\\qquad + \\frac { \\tilde{k } } 2   \\sum_{\\gamma=1}^p \\int_{-\\tau}^0   ( 1+{\\mathbbm{e}}[\\vert x_s^{\\alpha}\\vert^2 ] )   d\\eta_{\\alpha\\gamma}(u )   \\big\\}\\,ds \\\\       & \\leq { \\mathbbm{e}}[\\vert \\zeta_0^{\\alpha}(0 ) \\vert^2 ] + 2\\int_0^{t\\wedge \\tau_n } ( k+   \\sqrt{\\tilde{k } } p + \\frac { \\tilde{k } } 2 p ) ( 1+{\\mathbbm{e}}[\\vert x_s^{\\alpha}\\vert^2])\\,ds      \\end{aligned}\\ ] ] summing over @xmath7 and applying gronwall s lemma directly yields : @xmath139 } { \\mathbbm{e}}[\\vert x_t\\vert^2 ] \\leq { \\mathbbm{e}}[\\vert \\zeta_0(0)\\vert^2 ] + { \\mathbbm{e}}[1+\\vert \\zeta_0(0)\\vert^2 ] ( e^{k ' t}-1)\\ ] ] with @xmath140 , and hence , letting @xmath141 , we conclude that : @xmath142 } { \\mathbbm{e}}[\\vert x_t\\vert^2 ] \\leq \\max(\\sup_{[-\\tau,0 ] } { \\mathbbm{e}}[\\vert\\zeta_0(s)\\vert^2 ] \\;\\;,\\;\\ ; { \\mathbbm{e}}[\\vert \\zeta_0(0)\\vert^2 ] + { \\mathbbm{e}}[1+\\vert \\zeta_0(0)\\vert^2 ] ( e^{k ' t}-1))\\ ] ]    we now prove the existence and uniqueness theorem , using this boundedness property of the possible solutions .",
    "[ thm : existenceuniqueness ] for any @xmath111,e^{p})$ ] a square - integrable process , the mean - field equation with initial condition @xmath114 has a unique strong solution on @xmath97 $ ] for any @xmath143 .",
    "we start by showing the existence of solutions , and then prove the uniqueness property .",
    "we recall that by application of lemma  [ lem : solul2 ] , any possible solution has a bounded second moment . the proof is based on a classical contraction argument on iterates of the map @xmath107 .",
    "there are two main differences with usual proofs .",
    "first is the fact that our functions are not globally lipschitz - continuous , issue which is solved through a truncation argument and using the result of the _ a priori _ estimate of lemma  [ lem : solul2 ] , see  @xcite .",
    "second is the fact that we are considering delayed equations , which leads us to deal with uniform in @xmath97 $ ] convergence properties .",
    "the rest of the proof uses classical inequalities such as cauchy - schwarz ( cs ) , burkholder - davis - gundy ( bdg ) and hlder inequalities , all these applied on a decomposition of the term of interest into elementary terms .",
    "+ _ existence : _",
    "+ let @xmath144 such that @xmath145 } \\operatorname{\\stackrel{\\mathcal{l}}{=}}\\zeta_0 $ ] a given stochastic process .",
    "we consider that the drift and diffusion functions are @xmath146-lipschitz continuous ( up to truncation ) .",
    "we introduce the sequence of probability distributions @xmath147 on @xmath148 defined by induction as @xmath149 .",
    "we denote by @xmath150 a sequence of processes independent of the collection of processes @xmath151 and having the same law .",
    "we start by controlling one of the components of the sequence of processes @xmath152 , and for compactness of notations denote @xmath153 the component @xmath7 of @xmath154 .",
    "we decompose into six elementary terms the difference : @xmath155d\\eta_{\\alpha\\gamma}(u ) \\ , ds \\\\           &",
    "\\quad\\quad + \\int_0^t \\sum_{\\gamma=1}^p   \\int_{-\\tau}^0 { \\mathbbm{e}}_z\\big [ b_{\\alpha\\gamma}({}^{\\alpha}x^{k-1}_s , { } ^{\\gamma}z^{k}_{s+u } ) - b_{\\alpha\\gamma}({}^{\\alpha}x^{k-1}_s , { } ^{\\gamma}z^{k-1}_{s+u } ) \\big ] d\\eta_{\\alpha\\gamma}(u ) \\ , ds \\\\           &",
    "\\quad\\quad + \\int_0^t \\big ( g_{\\alpha}(s,{}^{\\alpha}x^{k}_s)-g_{\\alpha}(s,{}^{\\alpha}x^{k-1}_s ) \\big ) \\ , dw_s^{\\alpha}\\\\          & \\quad\\quad + \\sum_{\\gamma=1}^p \\int_0^t \\int_{-\\tau}^0 { \\mathbbm{e}}_z \\big [ \\beta_{\\alpha\\gamma}({}^{\\alpha}x^{k}_s ,    { } ^{\\gamma}z^{k}_{s+u } )    - \\beta_{\\alpha\\gamma}({}^{\\alpha}x^{k-1}_s , { } ^{\\gamma}z^{k}_{s+u } ) \\big]d\\eta_{\\alpha\\gamma}(u ) \\cdot db_s^{\\alpha\\gamma } \\\\           &",
    "\\quad\\quad + \\sum_{\\gamma=1}^p\\int_0^t \\int_{-\\tau}^0 { \\mathbbm{e}}_z   \\big [ \\beta_{\\alpha\\gamma}({}^{\\alpha}x^{k-1}_s , { } ^{\\gamma}z^{k}_{s+u } ) - \\beta_{\\alpha\\gamma}({}^{\\alpha}x^{k-1}_s , { } ^{\\gamma}z^{k-1}_{s+u } ) \\big]d\\eta_{\\alpha\\gamma}(u ) \\cdot db_s^{\\alpha\\gamma } \\\\          & \\stackrel{\\text{def}}{= } a_t^{\\alpha } + b_t^{\\alpha } + c_t^{\\alpha } + d_t^{\\alpha } + e_t^{\\alpha } + f_t^{\\alpha }      \\end{aligned}\\ ] ] where we simply identify each of the six terms @xmath156 , @xmath157 , @xmath158 , @xmath159 , @xmath160 and @xmath161 with the corresponding expression in the previous formulation . by a simple convexity inequality ( hlder )",
    "we have : @xmath162 and treat each term separately .",
    "the term @xmath163 is easily controlled using cauchy - schwarz inequality , fubini identity and standard inequalities and we obtain : @xmath164 } } \\vert a_s \\vert^2\\big ]                                           & \\leq k^2 \\,t \\ , \\int_0^t { \\mathbbm{e}}\\big [ \\sup_{-\\tau\\leq u\\leq s } \\vert x^{k}_u - x^{k-1}_u \\vert^2\\big ] \\ , ds      \\end{aligned}\\ ] ] similarly , the martingale term @xmath159 is bounded using the burkholder - davis - gundy theorem to the @xmath165-dimensional martingale @xmath166 and we obtain : @xmath167                          & \\leq 4 k^2 \\",
    ", \\int_0^t { \\mathbbm{e}}\\big [ \\sup_{-\\tau \\leq u\\leq s } \\vert x^{k}_u - x^{k-1}_u \\vert^2 \\big ]   \\ , ds       \\end{aligned}\\ ] ]    let us now deal with the deterministic interaction terms @xmath157 and @xmath158 .",
    "we have : @xmath168)\\,d\\eta_{\\alpha\\gamma}(u)\\,ds \\right\\vert^2\\\\          & \\leq \\sum_{\\alpha=1}^p t\\,p\\ ,   \\int_0^t \\sum_{\\gamma=1}^p \\int_{-\\tau}^0 { \\mathbbm{e}}_z\\left [ \\vert b_{\\alpha\\gamma}({}^{\\alpha}x^{k}_s,{}^{\\gamma}z^{k}_{s+u } ) - b_{\\alpha\\gamma}({}^{\\alpha}x^{k-1}_s,{}^{\\gamma}z^{k}_{s+u})\\vert^2\\right ] )          \\,d\\eta_{\\alpha\\gamma}(u)\\,ds\\\\          & \\leq t p^2   l^2 \\int_0^t \\vert x^k_s - x^{k-1}_s\\vert^2\\,ds \\leq t p^2   l^2 \\int_0^t \\sup_{-\\tau \\leq u\\leq s}\\vert x^k_u - x^{k-1}_u\\vert^2\\,ds      \\end{aligned}\\ ] ] hence easily conclude that @xmath169}\\vert b_s \\vert^2 ] \\leq t p^2   l^2 \\int_0^t { \\mathbbm{e}}[\\sup_{-\\tau \\leq u\\leq s}\\vert x^k_u - x^{k-1}_u\\vert^2]\\,ds\\ ] ]    and similarly , since @xmath170 and @xmath171 have the same law as @xmath172 and @xmath173 , @xmath169}\\vert c_s \\vert^2 ] \\leq t p^2   l^2 \\int_0^t { \\mathbbm{e}}[\\sup_{-\\tau \\leq u\\leq s}\\vert x^k_u - x^{k-1}_u\\vert^2]\\,ds\\ ] ]    eventually , the terms @xmath160 and @xmath161 use burkholder - david - gundy ( bdg ) inequality in place of cauchy - schwarz together with similar arguments as used for @xmath157 and @xmath158 . using the independence of the brownian motions @xmath174 , bdg inequality yields , for the term @xmath160 ( and similarly for the term @xmath161 ) : @xmath169}\\vert \\theta_s \\vert^2 ]",
    "\\leq 4 p^2   l^2 \\int_0^t { \\mathbbm{e}}[\\sup_{-\\tau \\leq u\\leq s}\\vert x^k_u - x^{k-1}_u\\vert^2]\\,ds\\ ] ] for @xmath175 equal to @xmath160 or @xmath161 .",
    "putting all these evaluations together , we get : @xmath176 } \\vert x^{k+1}_s - x^k_s \\vert^2 \\big ] \\leq 6(t+4)(k^2 + 2p^2\\,l^2\\ , ) \\int_0^t { \\mathbbm{e } } [ \\sup_{-\\tau \\leq u\\leq s } \\vert x^{k}_u - x^{k-1}_u \\vert^2 ] ds\\ ] ] moreover , since @xmath177 for @xmath178 $ ] by definition , we have , noting @xmath179,\\ ] ] the recursive inequality @xmath180 with @xmath181 .",
    "we thus get by an immediate recursion : @xmath182 and @xmath183 is finite because of lemma  [ lem : solul2 ] .",
    "routine methods starting from inequality   and allows proving existence and uniqueness of fixed point for @xmath107 ( see  @xcite ) .",
    "indeed , the fact that @xmath184}\\vert x^{k+1}_s - x^k_s \\vert^2   \\right]}^{1/2 } < \\infty,\\ ] ] implies the almost sure convergence of the series @xmath185}\\vert x^{k+1}_s - x^k_s \\vert$ ] and hence the a.s .",
    "uniform convergence of the partial sums : @xmath186 on @xmath97 $ ] .",
    "denote by @xmath87 the thus defined limit .",
    "it is clearly almost surely continuous and @xmath123 adapted . from lemma [ lem : solul2 ] , we know that @xmath187 . it remains to show that @xmath69 indeed satisfies the equation .",
    "this is easily done using the estimates we derived . indeed , it is easy to show at this point that @xmath188 \\leq k''\\int_0^t { \\mathbbm{e}}[\\sup_{-\\tau \\leq t\\leq t}\\vert x^n_s-\\bar{x}_s\\vert^2]\\,ds \\rightarrow 0\\ ] ] as @xmath141",
    ". hence @xmath189 is equal to the limit of the sequence @xmath190 , which is by definition , equal to @xmath191 whose limit is @xmath69 .",
    "this concludes the fact that @xmath69 is a fixed point of @xmath107 which completes the proof of the existence of solutions of the mean - field equation .",
    "_ uniqueness : _ + assume that @xmath110 and @xmath192 are two solutions of the mean - field equations . from lemma [ lem : solul2 ] , we know that both solutions are in @xmath98 . using the bound , we directly obtain the inequality : @xmath193 \\leq k '' \\int_0^{t } { \\mathbbm{e}}\\big [ \\sup_{-\\tau\\leq u\\leq s } \\vert x_u - y_u \\vert^2 \\big ]   \\ , ds\\ ] ] which by gronwall s theorem directly implies @xmath194=0 $ ] whence @xmath195 on @xmath97 $ ] a.s . follows .",
    "we now turn to the main result , namely the convergence in law of the solutions of the network equations towards the equations  .",
    "more precisely , we are interested in showing that the propagation of chaos applies in this case .",
    "the propagation of chaos property states that provided that all neurons have a chaotic initial condition ( i.e. , i.i.d . in @xmath196 ) , then in the limit where the number of neurons is infinite , all neurons behave independently and the limit process satisfies the equation given by .",
    "the proof follows standard proofs in the domain as generally done in particular by tanaka or sznitman @xcite .",
    "it is based on the very powerful coupling argument , that identifies the almost sure limit of the network solutions @xmath197 ( the exponent @xmath62 denotes the dependence of the law of neuron @xmath0 upon the network size @xmath62 ) as the number of neuron tends to infinity , a method popularized by sznitman in his extensive works ( see e.g.  @xcite ) , the ideas of which traces back to the 70 s ( for instance , dobrushin uses it in  @xcite ) .",
    "we start by considering the translation invariant case where the delay measures @xmath86 only depend on the neural population of neuron @xmath0 , prior to dealing with the non translation invariant case .",
    "we consider here @xmath198 for all @xmath0 in population @xmath7 .",
    "we intend to prove the propagation of chaos property and the convergence towards the mean field equations for almost all realization of the the delays @xmath28 under the assumption that for any fixed @xmath0 , the random variables @xmath199 are independent .",
    "this is termed the quenched propagation of chaos property . in order to demonstrate this property , we define a coupling between the solutions of the network equations   and the mean - field equations  .",
    "let @xmath200 such that @xmath8 .",
    "we define the process @xmath201 solution of the mean - field equation  , driven by the brownian motions @xmath202 and @xmath203 that govern the network process @xmath9 , and having the same initial condition as neuron @xmath0 in the network , @xmath204 . in details , @xmath205 is the unique solution of the equation , for @xmath206 : @xmath207d\\eta_{\\alpha\\gamma}(s)\\,dt \\\\              & \\quad + g_{\\alpha}(t,\\bar{x}^{i}_t)\\ , dw^i_t              + \\sum_{\\gamma=1}^p\\int_{-\\tau}^0{\\mathbbm{e}}_z[\\beta_{\\alpha\\gamma}(\\bar{x}^i_t , z_{t+s}^{\\gamma})]\\,d\\eta_{\\alpha\\gamma}(s)\\,db^{i\\gamma}_t   & t\\geq 0\\\\          \\bar{x}^i_t & = \\zeta^i_0 ( t ) & t\\in [ -\\tau , 0 ]      \\end{array }      \\right .      , \\ ] ] which constitutes a collection of independent stochastic processes @xmath208 that are identically distributed with law @xmath209 .",
    "let us denote by @xmath210 the probability distribution of @xmath211 solution of the mean - field equation .",
    "as previously , the processes @xmath212 constitute a collection of processes independent of @xmath208 and having the distribution @xmath213 .",
    "we aim at proving the almost sure convergence of a collection of processes @xmath214 for some @xmath215 and @xmath216 towards @xmath217 , implying the convergence of the law of @xmath218 towards @xmath219 as @xmath62 goes to infinity .",
    "we start by proving this result for @xmath220 which will readily imply the case @xmath221 . in what follows",
    ", we shall denote by @xmath222 the expectation over the delays @xmath28 .",
    "[ thm : propagationchaos ] under the assumptions ( h1)-(h4 ) and the chaotic initial condition assumption , the process @xmath223 , solution of the network equations  , converge almost surely towards the process @xmath224 solution of the mean - field equations  .",
    "this implies in particular convergence in law of the process @xmath223 towards @xmath225 solution of the mean - field equations  .",
    "moreover , if @xmath226 and @xmath227 are globally lipschitz - continuous , we have for any @xmath228 and any @xmath143 : @xmath229\\right\\ } < \\frac{c(t)}{\\min_{\\gamma}(n_{\\gamma})}\\ ] ] where @xmath230 is a constant only depending on the parameters of the system and the time horizon @xmath113 .    the proof differs from more classical proofs in that we consider that the network is composed of several distinct populations and includes random delays .",
    "moreover , a special care has to be taken when dealing with the delayed interactions , and the fact that our drift and diffusion coefficients are not globally lipschitz - continuous , which again is not explicitly dealt with in the present proof but can be classically obtained using a localization argument .",
    "the principle of the proof consists in thoroughly analyzing the difference between the two processes as @xmath62 tends to infinity .",
    "this difference is written as the sum of eight terms denoted @xmath231 through @xmath232 : @xmath233\\,d\\eta_{\\alpha\\gamma}(u)\\ , ds\\\\          \\nonumber & \\qquad + \\sum_{\\gamma=1}^p\\int_0^t \\frac 1 { n_{\\gamma } } \\sum_{p(j)=\\gamma } ( \\beta_{\\alpha\\gamma}(x^{i , n}_s , x^{j , n}_{s-\\tau_{ij}})-\\beta_{\\alpha\\gamma}(\\bar{x}^i_s , x^{j , n}_{s-\\tau_{ij}}))\\ , db^{i\\gamma}_s\\\\          \\nonumber & \\qquad + \\sum_{\\gamma=1}^p\\int_0^t \\frac 1 { n_{\\gamma } } \\sum_{p(j)=\\gamma } ( \\beta_{\\alpha\\gamma}(\\bar{x}^i_s , x^{j , n}_{s-\\tau_{ij}})-\\beta_{\\alpha\\gamma}(\\bar{x}^i_s,\\bar{x}^j_{s-\\tau_{ij}}))\\ , db^{i\\gamma}_s\\\\          \\nonumber & \\qquad + \\sum_{\\gamma=1}^p\\int_0^t   ( \\frac 1 { n_{\\gamma } } \\sum_{p(j)=\\gamma}\\beta_{\\alpha\\gamma}(\\bar{x}^i_s,\\bar{x}^j_{s-\\tau_{ij}})-\\int_{-\\tau}^0 { \\mathbbm{e}}_z[\\beta_{\\alpha\\gamma}(\\bar{x}^i_s , z^{\\gamma}_{s+u})])\\,d\\eta_{\\alpha\\gamma}(u)\\ , db^{i\\gamma}_s\\\\          \\label{eq : eightterms}&= a_t(n)+b_t(n)+c_t(n)+d_t(n)+e_t(n)+f_t(n)+g_t(n)+h_t(n )      \\end{aligned}\\ ] ]    let us underline the fact that the probability distribution of these terms do not depend on the specific neuron @xmath0 in population @xmath7 considered .",
    "we are interested in the limit , as @xmath62 goes to infinity , of the quantity @xmath234\\}$ ] .",
    "we decompose this expression into the sum of the eight terms involved in equation using hlder s inequality and upperbound each term separately .",
    "the terms @xmath235 and @xmath236 are treated exactly as in the proof of theorem [ thm : existenceuniqueness ] , and the control all the terms except @xmath160 and @xmath237 essentially uses on the same ingredients as in the proof of theorem  [ thm : existenceuniqueness ] .",
    "we denote @xmath146 a common lipschitz constant for @xmath226 and @xmath227 and deduce , similarly to the analysis performed in the proof of theorem  [ thm : existenceuniqueness ] , the following inequalities : @xmath238 & \\leq k^2\\ , t\\ , \\int_0^{t\\wedge \\tau_u } { \\mathbbm{e}}[\\sup_{-\\tau\\leq u\\leq s } \\vert x_u^{i , n}-\\bar{x}_u^i\\vert^2 ] \\ , du\\\\              { \\mathbbm{e}}[\\sup_{0\\leq s\\leq t\\wedge \\tau_u } \\vert b_s(n ) \\vert^2 ] & \\leq 4\\ , k^2\\ , \\int_0^{t\\wedge \\tau_u } { \\mathbbm{e}}[\\sup_{-\\tau\\leq u\\leq s } \\vert x_u^{i , n}-\\bar{x}_u^i\\vert^2 ] \\ , du\\\\              { \\mathbbm{e}}[\\sup_{0\\leq s\\leq t\\wedge \\tau_u } \\vert c_s(n ) \\vert ^2 ] & \\leq t l^2 p^2   \\int_0^{t\\wedge \\tau_u }   { \\mathbbm{e}}[\\sup_{-\\tau\\leq u\\leq s}\\vert x^{i , n}_u-\\bar{x}^i_u \\vert^2 ] \\ , ds\\\\              { \\mathbbm{e}}[\\sup_{0\\leq s\\leq t\\wedge \\tau_u } \\vert d_s(n ) \\vert ^2 ] & \\leq t\\,l^2 p^2   \\int_0^{t\\wedge \\tau_u } \\max_{j=1\\cdots n } { \\mathbbm{e}}[\\sup_{-\\tau \\leq u \\leq s}\\vert x^{j , n}_u-\\bar{x}^j_u \\vert^2 ] \\ ,",
    "ds\\\\              { \\mathbbm{e}}[\\sup_{0\\leq s\\leq t\\wedge \\tau_u}\\vert f_s(n ) \\vert ^2 ] & \\leq 4 l^2 p^2   \\int_0^t   { \\mathbbm{e}}[\\sup_{-\\tau\\leq u\\leq s}\\vert x^{i , n}_u-\\bar{x}^i_u \\vert^2 ] \\ , ds\\\\              { \\mathbbm{e}}[\\sup_{0\\leq s\\leq t\\wedge \\tau_u}\\vert g_s(n ) \\vert ^2 ] & \\leq 4 l^2 p^2   \\int_0^t \\max_{j=1\\cdots n } { \\mathbbm{e}}[\\sup_{-\\tau\\leq   u \\leq s}\\vert x^{j , n}_u-\\bar{x}^j_u \\vert^2 ] \\ , ds          \\end{cases}\\ ] ] let us for instance treat the case of @xmath239 for the sake of clarity , all other terms are treated along the same lines .",
    "we have : @xmath240 & \\leq p \\sum_{\\gamma=1}^p { \\mathbbm{e}}\\bigg[\\sup_{0 \\leq s\\leq t } \\big\\vert \\int_0^s \\frac 1 { n_{\\gamma } } \\sum_{p(j)=\\gamma } \\beta_{\\alpha\\gamma}(x^{i , n}_u , x^{j , n}_{u-\\tau_{ij}})\\\\      & \\quad -\\beta_{\\alpha\\gamma}(\\bar{x}^{i}_u , x^{j , n}_{u-\\tau_{ij } } ) db^{i\\gamma}_u\\big\\vert^2\\bigg]\\\\      \\text{(bdg)}&\\leq",
    "4p \\sum_{\\gamma=1}^p { \\mathbbm{e}}\\left[\\int_0^t \\left\\vert\\frac 1 { n_{\\gamma } } \\sum_{p(j)=\\gamma } \\beta_{\\alpha\\gamma}(x^{i , n}_s , x^{j , n}_{s-\\tau_{ij}})-\\beta_{\\alpha\\gamma}(\\bar{x}^{i}_s , x^{j , n}_{s-\\tau_{ij } } ) \\right\\vert^2d_s\\right]\\\\      \\text{(cauchy - schwartz)}&\\leq 4p \\sum_{\\gamma=1}^p \\int_0^t \\frac 1 { n_{\\gamma } }   \\sum_{p(j)=\\gamma } { \\mathbbm{e}}\\left[\\left\\vert \\beta_{\\alpha\\gamma}(x^{i , n}_s , x^{j , n}_{s-\\tau_{ij}})-\\beta_{\\alpha\\gamma}(\\bar{x}^{i}_s , x^{j , n}_{s-\\tau_{ij}})\\,\\right\\vert^2\\right]\\,ds\\\\      \\text{(assumption~\\ref{assump : loclipschb } ) } & \\leq 4p^2 l^2 \\int_0^t { \\mathbbm{e}}\\left[\\left\\vert x^{i , n}_s-\\bar{x}^i_s\\right\\vert^2\\right]\\,ds\\\\      & \\leq 4 p^2 l^2   \\int_0^t { \\mathbbm{e}}\\left[\\sup_{-\\tau \\leq u\\leq s}\\vert x^{i , n}_u-\\bar{x}^i_u \\vert^2\\right ] \\ , ds .      \\end{aligned}\\ ] ]    in the decomposition  , the two terms @xmath241 and @xmath232 are of a new form and remain to be evaluated .",
    "both term involves the difference between an empirical mean of a function of processes and an expectation term , and all have bounded second moment thanks to proposition  [ lem : solul2 ] and assumption  [ assump : bbound ] .",
    "we have : @xmath242\\ } & = { \\mathcal{e}}\\big\\{{\\mathbbm{e}}[\\sup_{0\\leq s\\leq t } \\vert \\int_0^s \\sum_{\\gamma=1}^p   \\frac 1 { n_{\\gamma } } \\sum_{p(j)=\\gamma } ( b_{\\alpha\\gamma}(\\bar{x}^i_s,\\bar{x}^j_{s-\\tau_{ij}})-\\int_{-\\tau}^0{\\mathbbm{e}}_z[b_{\\alpha\\gamma}(\\bar{x}^i_s , z_{s+u}^{\\gamma } ) ] ) \\,d\\eta_{\\alpha\\gamma}(u)\\ , ds\\vert^2]\\big\\}\\\\          \\label{eq : ethtcontrol } & \\leq t p   \\sum_{\\gamma=1}^p \\int_0^t { \\mathcal{e}}\\big\\ { { \\mathbbm{e}}[\\bigg \\vert \\frac 1 { n_{\\gamma } } \\sum_{p(j)=\\gamma } b_{\\alpha\\gamma}(\\bar{x}^i_s,\\bar{x}^j_{s-\\tau_{ij}})- \\int_{-\\tau}^0{\\mathbbm{e}}_z[b_{\\alpha\\gamma}(\\bar{x}^i_s , z_{s+u}^{\\gamma})\\ , d\\eta_{\\alpha\\gamma}(u ) ] \\bigg\\vert^2 ] \\",
    ", ds\\big\\ }      \\end{aligned}\\ ] ] and using burkholder - davis - gundy @xmath243\\big\\ } \\leq 4 p   \\sum_{\\gamma=1}^p \\int_0^t   { \\mathcal{e}}\\big\\{{\\mathbbm{e}}[\\bigg \\vert \\frac 1 { n_{\\gamma } } \\sum_{p(j)=\\gamma } \\beta_{\\alpha\\gamma}(\\bar{x}^i_s,\\bar{x}^j_{s-\\tau_{ij}})- \\int_{-\\tau}^0{\\mathbbm{e}}_z[\\beta_{\\alpha\\gamma}(\\bar{x}^i_s , z_{s+u}^{\\gamma } ) \\ ,",
    "d\\eta_{\\alpha\\gamma}(u ) ] \\bigg\\vert^2]\\big\\}\\ , ds\\ ] ] each of these expressions involve the processes @xmath244 which , under the tensor product law of the brownian motion and the delays , are independent and identically distributed population - wise .",
    "moreover , we have : @xmath245d\\eta_{\\alpha\\gamma}(u)]\\vert^2]\\big\\ } \\\\= \\frac 1 { n_{\\gamma}^2 } \\sum_{k , l = 1}^{n_{\\gamma } } { \\mathcal{e}}\\big\\{{\\mathbbm{e}}\\big[(\\theta(\\bar{x}^i_s,\\bar{x}^j_{s-\\tau_{ij}})-{\\mathbbm{e}}_{z,\\tilde{\\tau}_{\\alpha\\gamma}}[\\theta(\\bar{x}^i_s , z_{s-\\tilde{\\tau}_{\\alpha\\gamma}}^{\\gamma})])^t \\cdot ( \\theta(\\bar{x}^i_s,\\bar{x}^k_{s-\\tau_{ij}})-{\\mathbbm{e}}_{z,\\tilde{\\tau}}[\\theta(\\bar{x}^i_s , z_{s-\\tilde{\\tau}_{\\alpha\\gamma}}^{\\gamma})])\\big]\\big\\ }      \\end{gathered}\\ ] ] where @xmath246 , noting that the expectation @xmath247\\}$ ] of the composed random variable @xmath248 under the law of @xmath249 and of the delays @xmath250 is precisely equal to @xmath251d\\eta_{\\alpha\\gamma}(u)]$ ] . in the above expression",
    ", @xmath252 denotes a random variable with law @xmath34 independent of the sequence of delays and of the brownian motions .",
    "it is now easy to show that all the terms of the sum corresponding to indexes @xmath22 and @xmath253 such that the three conditions @xmath254 , @xmath255 and @xmath256 are satisfied are null .",
    "the simpler way to see this property is to write the expectations as integrals with respect to the measure @xmath77 and observe that all terms annihilate , using the mutual independence of the processes @xmath257 , of the random variables @xmath199 , and the independence between the processes and the delays .",
    "therefore , there are no more than @xmath258 non - null terms in the sum ( in the case @xmath259 there are just @xmath260 non - null terms ) , and moreover , all of these terms are uniformly bounded .",
    "the terms related to indexes @xmath261 satisfy the inequality : @xmath262\\right \\vert^2\\right]\\right\\ } & \\leq 2\\,{\\mathcal{e}}\\left\\{{\\mathbbm{e}}\\left[\\left \\vert\\theta(\\bar{x}^i_s,\\bar{x}^j_{s-\\tau_{ij}})\\right \\vert^2 + \\left \\vert{\\mathbbm{e}}_{z,\\tilde{\\tau}_{\\alpha\\gamma}}[\\theta(\\bar{x}^i_s , z_{s-\\tilde{\\tau}_{\\alpha\\gamma}}^{\\gamma})]\\right \\vert^2\\right]\\right\\}\\\\                  & \\leq 4 \\tilde{k } ( 1+c_2(s ) )      \\end{aligned}\\ ] ] where @xmath263 is the upperbound of the @xmath264 norm of @xmath265 given by lemma  [ lem : solul2 ] .",
    "the terms related to the cases @xmath266 ( or symmetrically @xmath267 ) are bounded by the same constant , since we have for all @xmath253 such that @xmath268 , by cauchy - schwartz inequality : @xmath269\\right ) ^t \\cdot \\left ( \\theta(\\bar{x}^i_s,\\bar{x}^k_{s-\\tau_{ij}})-{\\mathbbm{e}}_{z,\\tilde{\\tau}_{\\alpha\\gamma}}[\\theta(\\bar{x}^i_s , z_{s-\\tilde{\\tau}_{\\alpha\\gamma}}^{\\alpha})]\\right ) ^t \\right ] \\right\\}\\\\          & \\qquad \\leq { \\mathcal{e}}\\left\\{{\\mathbbm{e}}\\left[\\left \\vert\\theta(\\bar{x}^i_s,\\bar{x}^i_{s-\\tau_{ij}})-{\\mathbbm{e}}_{z,\\tau}[\\theta(\\bar{x}^i_s , z_{s-\\tau}^{\\alpha})]\\right \\vert^2\\right]\\right\\}^{1/2 } { \\mathcal{e}}\\left\\{{\\mathbbm{e}}\\left[\\left \\vert\\theta(\\bar{x}^i_s,\\bar{x}^k_{s-\\tau_{ij}})-{\\mathbbm{e}}_{z,\\tau}[\\theta(\\bar{x}^i_s , z_{s-\\tau}^{\\alpha})]\\right \\vert^2\\right]\\right\\}^{1/2}\\\\                  & \\qquad \\leq 4 \\tilde{k }",
    "( 1+c_2(s ) )      \\end{aligned}\\ ] ]    we note @xmath270 .",
    "we have : @xmath271\\right\\ } \\leq t^2p c \\sum_{\\gamma=1}^p\\frac{3n_{\\gamma}-2}{n_{\\gamma}^2 } \\leq 3\\,t^2\\,p^2\\ , c \\frac{1}{\\min_{\\gamma}(n_{\\gamma})}\\ ] ] and @xmath272\\right\\ } \\leq 12\\,t\\,p^2\\ , c \\frac{1}{\\min_{\\gamma}(n_{\\gamma})}\\ ] ]    assembling all the estimates , we obtain @xmath273\\ } & \\leq 8\\ , \\bigg\\{(k^2 + 2 l^2 p^2 )",
    "\\,(t+4 ) \\int_0^t\\max_{j=1\\cdots n}{\\mathbbm{e}}\\big[\\sup_{-\\tau \\leq",
    "u\\leq s}\\vert x^j_u - \\bar{x}^j_u\\vert^2\\big]\\ , du \\\\          & \\qquad + 3(t+4)t\\frac{c\\,p^2}{\\min_{\\gamma}(n_{\\gamma})}\\big\\ }                              \\end{aligned}\\ ] ] let us denote @xmath274 and @xmath275 .",
    "since @xmath89 and @xmath205 are equal on @xmath33 $ ] , this inequality implies : @xmath276 \\leq k ' \\int_0^t\\max_{j=1\\cdots",
    "n}{\\mathbbm{e}}\\big[\\sup_{-\\tau \\leq u\\leq s}\\vert x^j_u - \\bar{x}^j_u\\vert^2\\big]\\ , du + \\frac{c'}{\\min_{\\gamma}(n_{\\gamma})}\\ ] ] using gronwall s inequality , we obtain : @xmath277 \\leq \\frac{c'}{\\min_{\\gamma}(n_{\\gamma})}\\,\\int_0^t e^{k'\\,(t - s)}\\,ds \\leq \\frac{c'}{k ' \\min_{\\gamma}(n_{\\gamma } ) } e^{k ' t}\\ ] ] which tends to zeros as @xmath62 goes to infinity by assumption .",
    "this property implies the convergence in law of @xmath278 towards @xmath279 .",
    "[ cor : propachaos ] let @xmath215 and fix @xmath280 neurons @xmath281 . under the assumptions of theorem  [ thm : propagationchaos ] , the law of @xmath282 converges towards @xmath283 .",
    "we have , using the notations of the proof of theorem  [ thm : propagationchaos ] , @xmath284\\right\\ } \\\\          & \\qquad \\leq \\sum_{k=1}^l { \\mathcal{e}}\\left\\{{\\mathbbm{e}}\\left [ \\sup_{-\\tau\\leq t \\leq t\\wedge\\tau_u } \\left\\vert x^{i_k , n}_t-\\bar{x}^{i_k}_t\\right\\vert^2 \\right]\\right\\}\\\\          & \\qquad \\leq \\frac{l\\,c'}{k ' { \\min_{\\gamma}(n_{\\gamma } ) } } e^{k ' t }      \\end{aligned}\\ ] ] which tends to zero as @xmath62 goes to infinity , hence the law of @xmath282 converges towards that of @xmath285 .",
    "this property implies the convergence in law of @xmath282 towards @xmath286 whose law is equal to @xmath283 .",
    "these two results readily yields the announced results on the quenched propagation of chaos and convergence for almost all realization of the delays in the translation invariant case .",
    "let us now deal with the averaged convergence of the process in the non translation invariant case .",
    "we now consider the case of non - translation invariant neural fields . in that case , the distribution of delays depends on the properties of the particular neuron considered ( see e.g. the case of neurons in a box treated in section  [ sec : firingrate ] ) .",
    "let us consider neuron @xmath0 in population @xmath7 .",
    "the delays @xmath28 between neuron @xmath0 and neuron @xmath22 of population @xmath19 has a distribution given by @xmath35 and these different laws , averaged across all possible choices of location of neuron @xmath0 , has the law given by @xmath34 .    in the previous section",
    ", we were able to take into account possible correlations between delays : indeed , the only property used was that for any fixed neuron , the sequence of delays @xmath199 were independent , whatever possible correlations between @xmath28 and @xmath287 for @xmath255 .",
    "we make the same assumption here .",
    "we denote by @xmath288 the expectation over all possible choices of locations for neuron @xmath0 , i.e. all possible distributions @xmath35 .",
    "following the same lines as done in the quenched heterogeneity case for translation invariant systems , we show the following :    [ thm : averagedpropachaos ] under the assumptions ( h1)-(h4 ) and the chaotic initial condition assumption , the process @xmath223 , solution of the network equations   averaged across all possible values of the delays converge towards the process @xmath224 solution of the mean - field equations  .",
    "this implies in particular convergence in law of the process @xmath289 , -\\tau \\leq t\\leq t)$ ] towards @xmath225 solution of the mean - field equations  . moreover , if @xmath226 and @xmath227 are globally lipschitz - continuous , we have for any @xmath228 and any @xmath143 : @xmath290 - \\bar{x}^i_s\\vert^2 \\big]\\right\\ } < \\frac{c(t)}{\\min_{\\gamma}(n_{\\gamma})}\\ ] ] where @xmath230 is a constant only depending on the parameters of the system and the time horizon @xmath113 .",
    "the proof proceeds as the one of theorem  [ thm : propagationchaos ] by thoroughly controlling the distance between @xmath291 $ ] and @xmath205 under the norm @xmath292 $ ] .",
    "this distance is decomposed into the sum of eight terms analogous to the quenched translation invariant case , that are controlled exactly in the same manner as done in the proof of theorem  [ thm : propagationchaos ] , except two terms @xmath293 and @xmath294 analogous to @xmath241 and @xmath232 . regarding these terms , we have : @xmath295\\ } & = { \\mathcal{e}}\\big\\{{\\mathbbm{e}}[\\sup_{0\\leq s\\leq t } \\vert \\int_0^s \\sum_{\\gamma=1}^p   \\frac 1 { n_{\\gamma } } \\sum_{p(j)=\\gamma } { \\mathcal{e}}_i\\big\\{(b_{\\alpha\\gamma}(\\bar{x}^i_s,\\bar{x}^j_{s-\\tau_{ij}})\\big\\}-\\int_{-\\tau}^0{\\mathbbm{e}}_z[b_{\\alpha\\gamma}(\\bar{x}^i_s , z_{s+u}^{\\gamma } ) ] ) \\,d\\eta_{\\alpha\\gamma}(u)\\ , ds\\vert^2]\\big\\}\\\\      \\label{eq : ethtprimecontrol } & \\leq t p   \\sum_{\\gamma=1}^p \\int_0^t { \\mathcal{e}}\\big\\ { { \\mathbbm{e}}[\\bigg \\vert \\frac 1 { n_{\\gamma } } \\sum_{p(j)=\\gamma } { \\mathcal{e}}_i\\big\\{b_{\\alpha\\gamma}(\\bar{x}^i_s,\\bar{x}^j_{s-\\tau_{ij}})\\big\\}- \\int_{-\\tau}^0{\\mathbbm{e}}_z[b_{\\alpha\\gamma}(\\bar{x}^i_s , z_{s+u}^{\\gamma})\\ , d\\eta_{\\alpha\\gamma}(u ) ] \\bigg\\vert^2 ] \\ , ds\\big\\}\\end{aligned}\\ ] ] and using burkholder - davis - gundy @xmath296\\big\\ } \\leq 4 p   \\sum_{\\gamma=1}^p \\int_0^t   { \\mathcal{e}}\\big\\{{\\mathbbm{e}}[\\bigg \\vert \\frac 1 { n_{\\gamma } } \\sum_{p(j)=\\gamma } { \\mathcal{e}}_i\\big\\{\\beta_{\\alpha\\gamma}(\\bar{x}^i_s,\\bar{x}^j_{s-\\tau_{ij}})\\big\\}- \\int_{-\\tau}^0{\\mathbbm{e}}_z[\\beta_{\\alpha\\gamma}(\\bar{x}^i_s , z_{s+u}^{\\gamma } ) \\ ,",
    "d\\eta_{\\alpha\\gamma}(u ) ] \\bigg\\vert^2]\\big\\}\\ , ds.\\ ] ] in that case again , the expectation of the process @xmath297 under @xmath249 and the delays is @xmath298 $ ] , and hence developing this expression , we are left with at most @xmath299 terms that are bounded , and we can hence conclude on the convergence of the averaged law towards the mean - field equations , and obtain the announced speed of convergence .",
    "let us now go deeper into the dynamics of these limit equations .",
    "in the previous sections , we showed the convergence of network equations   towards well - posed delayed mckean - vlasov equations  .",
    "these equations form a system of implicit equations in the space of stochastic processes .",
    "understanding the qualitative dynamics of the networks in the limit @xmath6 is hence highly challenging in this general context . in order to go deeper into the analysis of the dynamics of the mean - field equations , we consider the dynamics of the classical firing - rate model .",
    "we now instantiate the dynamics of our neurons as firing - rate models . in this model",
    "the intrinsic dynamics @xmath300 is affine , the diffusion function @xmath301 is constant ( equal to @xmath302 ) and in which the interactions only depend on a nonlinear transform of the membrane potential of presynaptic neurons : @xmath303 and @xmath304 .",
    "it is obvious that the assumptions of the above sections are satisfied by the firing - rate model .",
    "therefore , when considering the delays @xmath35 only depending on @xmath305 , we have propagation of chaos and almost sure ( quenched ) convergence towards the mean - field equations : @xmath306d\\eta_{\\alpha\\gamma}(s ) \\big)\\,dt \\\\      + \\lambda_{\\alpha}\\,dw_t^{\\alpha }      + \\sum_{\\gamma=1}^p\\sigma_{\\alpha\\gamma}\\int_{-\\tau}^0 { \\mathbbm{e}}_{\\bar{x}}[s(\\bar{x}^{\\gamma}_{t+s})]d\\eta_{\\alpha\\gamma}(s ) \\,db^{\\alpha\\gamma}_t\\end{gathered}\\ ] ] and if the delay distributions @xmath35 depend on the choice of @xmath0 , the same result hold in an averaged sense .    in these cases , we can reduce the dynamics as follows :    [ thm : firingrategaussian ] in the firing - rate model , solutions of the mean - field equations   are exponentially fast attracted towards gaussian solutions . when the initial conditions are gaussian processes , the solution is gaussian , with mean @xmath307 and variance @xmath308 satisfying a well - posed system of delayed differential equations : @xmath309 where @xmath310 $ ] for @xmath311 .    by the variation of constant formula we have : @xmath312d\\eta_{\\alpha\\gamma}(u ) \\big)\\,ds \\\\",
    "+ \\int_0^t e^{-(t - s)/\\theta_{\\alpha } } \\lambda_{\\alpha}\\,dw_s^{\\alpha }          +   \\sum_{\\gamma=1}^p\\sigma_{\\alpha\\gamma}\\int_0^t e^{-(t - s)/\\theta_{\\alpha } } \\int_{-\\tau}^0 { \\mathbbm{e}}_{\\bar{x}}[s(\\bar{x}^{\\gamma}_{s+u})]d\\eta_{\\alpha\\gamma}(u ) \\,db^{\\alpha\\gamma}_s .",
    "\\end{gathered}\\ ] ] the initial condition term @xmath313 vanishes exponentially fast . the other terms include deterministic terms and stochastic integrals with respect to brownian motions of deterministic functions , hence are gaussian .",
    "all but the initial condition term are hence gaussian and the solutions are exponentially fast attracted towards gaussian solutions . taking the mean and covariance function of this process readily yields equations  .    in the firing - rate case",
    ", we hence have an important reduction of complexity .",
    "we now exploit this simpler form of the mean - field equations to analyze the dynamics of the network using the theory of delayed differential equations ( see e.g.  @xcite ) and compare it to numerical simulations .",
    "we particularly focus on the importance of the noise in the stochastic weights and on the distribution of delays .      in order to analyze the impact of the distribution of delays on the dynamics of the network , we simplify the model considering a one - population network ( @xmath314 , we hence drop the population indexes since there is no ambiguity here ) .",
    "we further assume that @xmath315 , or more precisely consider centered sigmoid functions ( @xmath316 ) and no input ( @xmath317 ) . in order to further simplify the system , we consider @xmath318 where @xmath319 . in that case , integration by parts yields : @xmath320 in that simplified case ,",
    "it is easy to see that a stationary solution is given by @xmath321 . due to the quadratic form of the variance equation , the linearized equation on",
    "the variance is trivial @xmath322 .",
    "therefore , the level of noise in the connections do not come into play in that particular case , and the stability of the fixed point only depends on the characteristic equation related to the main , which is given by the dispersion relationship : @xmath323 the solutions of this equations are the characteristic exponents of the system , and relate to the stability of the fixed point considered : if all characteristic exponents have negative real part , the equilibrium is asymptotically exponentially stable , and there exists a characteristic exponent with strictly positive real part , the equilibrium is unstable .",
    "changes in the sign of the real part of the characteristic exponent constitute bifurcations of the system .",
    "let us start by analyzing the presence of _ pitchfork _ bifurcations that correspond to real characteristic exponents crossing the imaginary axis .",
    "such bifurcations hence occur when the following relationship is satisfied : @xmath324 and hence this bifurcation occurs independently of the choice of the delay .",
    "turing - hopf bifurcations occur when the system has a pair of complex conjugate characteristic exponents with non - zero imaginary part crossing the imaginary axis .",
    "such bifurcations hence occur when there exists @xmath325 such that @xmath326 , i.e. : @xmath327 the existence of such bifurcations exist depending on the type of delay distribution .",
    "it is important to note at this point that there is no such bifurcation when delays are equal to zero .      assuming that the neuronal populations are highly concentrated so that delays can be considered constant ( i.e. @xmath328 ) .",
    "the dispersion relationship can be easily solve and one finds that hopf bifurcations exist only for @xmath329 i.e. for strong enough connectivity and small enough noise . under that assumption",
    "is then easy to show that turing - hopf bifurcations arise when the parameters satisfy the relationship , when @xmath330 : @xmath331 with @xmath332 .",
    "these result into oscillations of the solutions at a pulsation equal by @xmath333 .",
    "details of the calculations are left to the reader and follow the lines of the proof used for localized delays of the next section .",
    "note that the value of the delay corresponding to the hopf bifurcation is a function of @xmath334 .",
    "in particular , no hopf bifurcation is to be found for @xmath335 .",
    "the curve of hopf bifurcations obtained in the plane @xmath336 and simulations the moment equations are displayed in figure fig .",
    "[ fig : deltadelay ] .",
    "these simulations illustrate the fact that , depending on the noise and the delay chosen , the law of the mean - field equations has a mean that is either periodic or constant , yielding periodic or stationary laws of the mean - field equations . since all neurons have the same probability distribution , in the periodic case all neurons will oscillate in phase .",
    "these results are valid for numerical simulations of the stochastic network as displayed in figure fig .",
    "[ fig : networkdeltadelay ] .",
    "we now consider instead of dirac delta distributions of the delays that the neurons in each population have a dispersion of order @xmath25 around a typical value @xmath32 .",
    "one of the simplest distribution modeling this kind of dispersion is the uniform distribution @xmath337 } dt/\\delta$ ] .",
    "the dirac delta delay can be seen as the limit of this distribution as @xmath338 .",
    "it is easy to show that we have in that case a dispersion relationship : @xmath339 and possible hopf bifurcations occurring when there exists @xmath325 such that : @xmath340 equating the real parts and the imaginary parts on both sides yields the system : @xmath341 where we denoted @xmath342 .",
    "these equations are relatively hard to solve .",
    "but since we are interested in parameters @xmath343 corresponding to hopf bifurcations , we can consider that these equations are self - consistent equations in the plane @xmath343 parametrized by the variable @xmath333 ( or more precisely @xmath344 ) and obtain the following equations on the hopf bifurcation curves when @xmath330 : @xmath345     +   +    these curves are plotted for different choices of parameters in figure fig .",
    "[ fig : uniformdelays ] . for small absolute values of the connectivity coefficient @xmath346 ,",
    "the system presents a hopf bifurcation curve which is an increasing function of @xmath25 : the larger the dispersion , the larger the necessary delay to trigger oscillations . for instance fixing @xmath347 and @xmath348 and a fixed value of the delay @xmath349 ,",
    "we show that increasing the dispersion of the delays @xmath25 destroys the oscillatory pattern : the network shows a transition from perfectly periodic in law synchronized oscillations to stationary asynchronous behaviors . for a different set parameters , we display a relatively complex bifurcation diagram presenting several parameter regions corresponding to the first hopf bifurcation and hence to the presence of oscillations .",
    "let us now further specify the type of distribution of delays that arises in neurosciences .",
    "as stated , delays are chiefly related to the axonal propagation at finite speed and to the specific time the signal transmission takes , @xmath350 . assuming constant speed @xmath351",
    ", the delay @xmath28 between neuron @xmath0 at location @xmath352 and a neuron @xmath22 at location @xmath353 is @xmath354 .",
    "delays are hence strongly related to the distribution of neurons in the cortex . moreover , in that case , the system may not be translation invariant ( if we do not assume for instance periodicity ) as we will see below .",
    "we hence need to identify the distribution of distances between distributed points in specific topologies .",
    "such distributions are known in closed form for some simple topologies , such as the rectangle or the ball .",
    "but even in these favorable cases , the bifurcations appear harder to characterize .",
    "this is however possible rigorously in a 1-dimensional case .",
    "assuming uniform distribution of the neurons in an interval @xmath355 $ ] and that @xmath356 ( without loss of generality ) , it is easy to show that the distribution of the distance @xmath357 between neuron @xmath0 at location @xmath352 and other neurons has the density : @xmath358}+ \\mathbbm{1}_{[0,r_i]}\\right)\\frac{dr}{a}\\ ] ] and the averaged law the density : @xmath359    in the case where we consider a periodic neural area ( i.e. identifying @xmath360 and @xmath361 ) , the distribution of distances is clearly the uniform distribution on @xmath362 $ ] and the results of the previous section apply .",
    "when considering non - periodic neural areas , applying the results of the above section ensures that an averaged propagation of chaos takes place , and that the network equations converge towards the mean - field equations given by theorem  [ thm : firingrategaussian ] .",
    "a gaussian process with mean @xmath360 and covariance @xmath363 is a stationary solution , i.e. the point @xmath364 is a fixed point of the moment equations  . at this point",
    "the dispersion relationship now reads , denoting @xmath365 : @xmath366 possible hopf bifurcations occur when one can find @xmath367 such that : @xmath368 in order to solve this equation , we note @xmath369 and @xmath370 . remark that @xmath371 tends to @xmath372 when @xmath373 hence recovering the dirac delta delay case .",
    "equating modulus and argument in the hopf dispersion relationship one obtains : @xmath374 considering as above",
    "@xmath344 as a parameter , we can find the locus of the hopf bifurcations in the plane @xmath375 .",
    "we obtain a sequence of hopf bifurcations indexed by @xmath253 , and the first bifurcation is responsible for oscillations appearing in the system .",
    "interestingly , we observe that the value of @xmath350 corresponding to oscillations takes a minimal value for a certain value of @xmath361 ( see figure fig .  [",
    "fig : neuronsbox ] ) . this can be understood heuristically as follows . in the interval",
    "@xmath355 $ ] , the mean distance between neurons is equal to @xmath376 and the standard deviation to @xmath377 .",
    "increasing @xmath361 hence has the effect of linearly increasing the averaged effective delay , and quadratically the dispersion .",
    "for small values of @xmath361 , the effective delay created by the dispersion of the neuron increases faster than the dispersion , and therefore a smaller constant delay @xmath350 is necessary to trigger oscillations .",
    "as @xmath361 is further increased , the dispersion grows faster than the mean effective delay , and in that case the dispersion implies that larger delays are necessary to trigger oscillations , as seen in the uniformly distributed delays case .",
    "+    fixing all parameters and changing the size of the interval in which the neurons lie can hence induces transition from stationary to periodic and back to stationary .",
    "neurons are hence perfectly synchronized in a specific region of the neural field spatial extension , and otherwise asynchronous .",
    "in this article , we analyzed the limits and dynamics of large - scale neuronal network models in the presence of noise .",
    "we particularly focused on the presence of heterogeneous delays in the interactions between neurons , an ubiquitous phenomenon in neuronal network activity that is understood to have important effects on the brain function .",
    "we considered two different kinds of systems : ( i ) translation invariant systems where the delays have the same distributions whatever the neurons considered , and ( ii ) non translation invariant case where delays distribution depend on the particular neuron @xmath0 considered . in both cases , we derived the mean - field equations associated with such randomly delayed networks for general models , and showed that the propagation of chaos occurred , in a quenched sense for translation invariant systems ( i.e. for almost all realization of the delays ) , or after averaging across possible delay distributions in the non translation invariant case .    in both cases ,",
    "the limit equations are identical and given by a system of delayed mckean - vlasov equations with distributed delays .",
    "the equations obtained are not classical stochastic equations : they involve a term depending on the law of the solution at previous times ( due to the presence of distributed delays ) .",
    "we showed that these equations were well - posed , and admit a unique solution .",
    "nonetheless , this solution remains relatively hard to characterize at that level of generality . in order to characterize the dynamics of the network and in particular the importance of heterogeneity in the interconnection delays , we instantiated a popular model in neuroscience , the firing - rate model . in the mean - field limit ,",
    "the solutions converge towards gaussian processes , whose mean and variance satisfy a closed set of differential equations with distributed delays .",
    "this property allowed , using the theory of bifurcations of delayed differential equations ( see e.g.  @xcite ) , to analyze in detail the role of delays in the macroscopic dynamics of neuronal networks .",
    "we showed that depending on the averaged delays , the network can either present a stationary or a synchronized periodic behavior .",
    "such transitions as a function of the amplitude of delays were already observed in heuristic models including constant delays .",
    "but beyond this fact , we showed that averaged delay is not enough to predict the behavior of the system , and a knowledge of the full delay distribution is necessary .",
    "we illustrated this fact exhibiting the bifurcation diagram of the hopf bifurcations as a function of the variance of uniformly distributed delays , and probably more interestingly from the biological viewpoint the dependence of the network behavior as a function of the delays arising from the distance between the cells .",
    "we showed that the macroscopic behavior arising from such networks depend on the size of the neural area considered , that parametrizes the delay distributions in the network .",
    "this was done analytically in a simple one dimensional case , and observed that the size of the cortical column considered has non - trivial effects on the macroscopic dynamics of the neural area .",
    "this observation is very interesting from the neuroscience viewpoint .",
    "indeed , it has been observed that across different species , the cortex either organizes into columns or shows a dispersed distribution .",
    "this is for instance the case of the primary visual areas : mice and rats for instance present no specific organization of the neurons responsible for orientation selectivity ( a so called salt - and - pepper structure ) , whereas the cat and primate present structured orientation selectivity columns ( see e.g.  @xcite ) .",
    "the reason of that difference is still poorly understood , and in that article , the authors suggest that the lack of orientation maps in rodent is related to the small size of v1 in these species .",
    "they argue that making a synaptic connection is easier locally .",
    "this possibility of creating synaptic connections is not a definitive answer to that question since the authors report a few counter - examples such as the ferret or the tree shrew . including the delay distribution in this picture and how the topology and size of the cortex influence the synchronization property at the level of cortical columns could allow going deeper into the analysis of the reasons of the functional reliability of orientation selectivity across different species with sensitively different cortex size .",
    "this work brings another refinement into the theoretical implication of delays in the dynamics of the network .",
    "the equations derived here provide a model of large - scale neuronal network with heterogeneous delay , and a preliminary study of the dynamics of such networks was initiated .",
    "enriching this model by considering several populations is a straightforward extension and the present manuscript , and analyzing such models would allow going deeper into the analysis of neuronal networks and on the effect of heterogeneous delays in relationship with specific cortical functions . eventually , the cortex is far from being the only system presenting heterogeneous distributions of interconnection delays .",
    "most networks , including communication networks , internet , social networks and physical networks such as spin glass present delays in the communications , that depend on the specific distance between nodes .",
    "this study can hence be applied to these other cases , and applications of that framework to the tcp protocol is currently under investigation ."
  ],
  "abstract_text": [
    "<S> realistic networks display heterogeneous transmission delays . </S>",
    "<S> we analyze here the limits of large stochastic multi - populations networks with stochastic coupling and random interconnection delays . </S>",
    "<S> we show that depending on the nature of the delays distributions , a quenched or averaged propagation of chaos takes place in these networks , and that the network equations converge towards a delayed mckean - vlasov equation with distributed delays . </S>",
    "<S> our approach is mostly fitted to neuroscience applications . </S>",
    "<S> we instantiate in particular a classical neuronal model , the wilson and cowan system , and show that the obtained limit equations have gaussian solutions whose mean and standard deviation satisfy a closed set of coupled delay differential equations in which the distribution of delays and the noise levels appear as parameters . </S>",
    "<S> this allows to uncover precisely the effects of noise , delays and coupling on the dynamics of such heterogeneous networks , in particular their role in the emergence of synchronized oscillations . </S>",
    "<S> we show in several examples that not only the averaged delay , but also the dispersion , govern the dynamics of such networks . </S>"
  ]
}