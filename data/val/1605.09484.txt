{
  "article_text": [
    "an ageing population is a major challenge that many countries are facing today .",
    "the problem arises from the fact that fertility rates are declining while life expectancy has been increasing in the past several decades without any sign of slowing down .",
    "the adverse financial outcome of people living longer than expected , and hence the possibility of outliving their retirement savings , is known as longevity risk .",
    "this long term demographic risk has significant implications for societies and manifests as a systematic risk for pension plans and annuity providers .",
    "policymakers rely on mortality projection to determine appropriate pension benefits and to understand the costing of different economic assumptions and regulations regarding the age of retirement of a given population .",
    "for instance , in the uk and australia defined - benefit pension plans prior to 2000 s had limited exposure to effects of longevity risk since high equity returns on pension fund wealth management portfolios were masking the impact of longevity risk , however post 2000 declining equity returns coupled with record low interest rate financial environments has demonstrated the significance of decades of longevity improvements , posing a very real problem for pension schemes . furthermore , by regulation , insurers who offer retirement income products are required to hold additional reserving capital to cover longevity risk . a key input to address longevity risk is the development of advanced mortality modelling methodology , so that human longevity can be predicted with better accuracy and any uncertainties can be accounted for in mortality forecasting .    since the introduction of the lee - carter model ( @xcite )",
    ", a range of stochastic mortality models have been proposed in the literature .",
    "@xcite and @xcite introduce multiple period effects and cohort effect to capture the change of mortality with respect to year and year - of - birth , respectively , to the lee - carter model .",
    "@xcite proposed a two - factor period effect mortality model , known as the cairns - blake - dowd ( cbd ) model , for pensioner ages .",
    "a cohort extension of the cbd model was studied in @xcite .",
    "@xcite draws on the strengths of the lee - carter model and the cbd model to produce an age - period - cohort model that includes a term to capture young mortality dynamics . in these well known cases",
    "it is common practice in actuarial settings to estimate stochastic mortality models based on a singular value decomposition approach ( @xcite , @xcite ) or via a maximum likelihood based approach if a discrete poisson regression setting is considered ( @xcite , @xcite ) .",
    "a common feature of the estimation methods adopted in the frameworks mentioned above is that the dynamics of the period effect , the stochastic latent processes , are not directly incorporated into joint parameter and state estimation , and instead form a component of a second stage of estimation .",
    "typically this involves specifying a model for the period effect for forecasting purpose only after an estimation is performed .",
    "such approaches often suffer from a statistical lack of efficiency compared to methods that perform joint static model parameter estimation and latent process filtering .",
    "_ hence , the first argument we make is that recasting different classes of mortality models in a state - space formulation can better facilitate state - space based inference under either frequentist or bayesian estimation .",
    "this is especially true in the case that the inference is performed jointly on the latent process and static model parameters , rather than in a less statistically efficient two - stage procedure_.    typically the studies carried out in practice and in the literature have the feature that only mortality data from the past several decades is considered . for many countries ,",
    "age - specific death rates are evolving rather smoothly except for some potential change of trend in the last 50 years or so in some developed countries . besides arima models ,",
    "structural change model have been proposed to take into account the trend - changing behaviour of the period effect ( @xcite , @xcite ) . despite this , the implication of including earlier periods that exhibit significant volatility of mortality , which can be attributed to some life - critical events such as wars and epidemics , is still not yet being investigated . the ability to incorporate such structural information into a mortality model",
    "is greatly facilitated when recasting the model in a state - space formulation .",
    "furthermore , extensions to mortality models that can also be facilitated in a state - space formulation are increasingly able to be considered and may better explain the stochastic dynamics of such processes .",
    "these include features such as : time varying volatility ; cross - sectional volatility between different age groups ; extremal dependence features ; cohort effects ; structure breaks in regimes ; long memory or persistence in mortality features in different age - groups ; cointegration and non - stationarity features ; as well as regression based structures that decompose mortality according to categorical features such as official death causes , regional categories etc .    moreover , additional stochastic factor models such as two and three factor models can be easily considered .",
    "this can be particularly relevant when modelling features such as trends in excess mortality in particular age - groups resulting from disease epidemics ( @xcite , @xcite ) , cold and heat - waves ( @xcite , @xcite ) and other effects such as medical impairements , occupational hazards , hazardous persuites , geographical location of residence and ethnic origin , see @xcite and @xcite .",
    "_ hence , the second argument we make is that all these different model structures can readily be encoded in state - space model structures .",
    "furthermore , they can be consistently combined in joint estimation procedures in such state - space model structures in either frequentist and bayesian formualtions , whilst also admitting consistent joint forecasting models for predictive purposes_.    a variety of state - space model approaches exist in a range of different literatures , in this paper we propose to begin with the widely adopted frameworks typically introduced in state - space modelling settings in @xcite or @xcite , which we develop to address some of the aforementioned issues .",
    "in contrast to the singular value decomposition and poisson regression estimation approaches where the period effect is treated as parameter without any temporal structure in the first - stage estimation , period effect is regarded as a latent process with a markovian structure under the state - space approach . in other words ,",
    "a state - space formulation permits modelling , estimation and forecasting of mortality under a unified framework .",
    "recent progress in sampling - based techniques has allowed statistical inference to be conducted on sophisticated state - space models that can incorporate multiple latent driving factors which may exhibit non - linear and non - gaussian stochastic dynamics .",
    "we take advantage of this development and utilise realistic model to capture the long term volatility structure of mortality time series .",
    "@xcite and @xcite consider bayesian estimation of the lee - carter model in state - space form .",
    "a maximum likelihood approach is studied in @xcite . here",
    ", we extend such frameworks to show how to adopt a combination of filtering procedures with rao - blackwellization to obtain gradient based fisher score equation recursions to accurately and efficiently perform optimal filtering of the latent state process , in the sense of mean square error minimization , and recursive least squares estimation for the static model parameters jointly in a recursive manner .",
    "furthermore , we extend such state - space models to incorporate non - linear and non - gaussian features in the state - space structure that no longer admit simple kalman filter forward backward algorithm recursions , leading us to more cutting edge filtering techniques based on sequential monte carlo methods . in this regard , we estimate and examine the lee - carter model with heteroscedasticity using both gradient - based maximum likelihood and bayesian analysis .",
    "alternative models that have tried to include such features include , for example , the poisson regression in @xcite and @xcite , who aimed to replace the homogeneous additive error term in the lee - carter model by a poisson error structure . also we note a recently developed framework for modelling death counts with common latent risk factors via credit risk plus methodology with model estimation via markov chain monte carlo ( mcmc ) in @xcite .",
    "however , we argue that the state - space formulation allows heteroscedasticity to be accounted for in a more straightforward manner .    through reformulation and extensions of the lee - carter type mortality models in a state - space model structure",
    ", we investigate several key properties observed in mortality data .",
    "first , the cross sectional variance - covariance matrix between age - group structures is non - homogeneous .",
    "second , examination of mortality data over a long period indicates that volatility of the evolution of death rates is not constant , i.e. homoskedascity is present .",
    "we show that the incorporation of a second stochastic volatility latent factor will allow us to identify the periods in which mortality demonstrates heightened volatility .",
    "this will aid in interpretation and forecasting from such models .",
    "specifically , we introduce a stochastic volatility model for the period effect , aiming to capture long term mortality dynamics .",
    "the state - space framework provides a natural platform to analyse stochastic volatility models ( @xcite , @xcite ) . in this paper",
    "we develop a particle markov chain monte carlo ( pmcmc ) ( @xcite ) bayesian model formulation in order to estimate the resulting stochastic volatility model of mortality jointly with the other latent stochastic factors and the static model parameters .",
    "we introduce to mortality modelling the estimation framework based around the pmcmc algorithm which utilises sequential monte carlo ( smc ) ( @xcite , @xcite ) to obtain required quantities in metropolis - hastings algorithms that has found many applications in a variety of areas , for example finance ( @xcite ) , economics ( @xcite ) , non - life insurance ( @xcite ) , risk management ( @xcite ) and computational biology ( @xcite ) .",
    "we apply this powerful tool in mortality modelling and it allows us to develop efficient algorithms to estimate a stochastic volatility extension of the lee - carter model .",
    "the paper is organised as follows . in section 2",
    "we give an overview of the conventional mortality modelling and estimation methodology in the literature .",
    "a state - space approach for mortality modelling is formulated and discussed in section 3 .",
    "section 4 is devoted to state - space inference for stochastic mortality models in a frequentist approach .",
    "section 5 focuses on bayesian inference for dynamic mortality models in state - space framework . in section 6",
    "we analyse danish mortality data based on the enhanced models and methodologies proposed in the paper .",
    "section 7 provides concluding remarks .",
    "in this section we first briefly recall some important definitions on mortality modelling .",
    "we then review stochastic mortality models that are commonly found in the literature .",
    "standard estimation procedures under frequentist and bayesian approaches are discussed .",
    "we use the following standard definitions from actuarial literature on mortality modelling ( @xcite , @xcite ) .",
    "let @xmath0 be a random variable representing the remaining lifetime of a person aged @xmath1 .",
    "the cumulative distribution function and survival function of @xmath0 are written as @xmath2 and @xmath3 respectively . for a person aged @xmath1 , the force of mortality at age @xmath4 is defined as @xmath5 let @xmath6 be the density function of @xmath0 ,",
    "then from we have @xmath7 . the central death rate for a @xmath1-year - old , where @xmath8 , is defined as @xmath9 which is a weighted - average of the force of mortality ( here @xmath10 ) .",
    "under the so - called piecewise constant force of mortality assumption , that is @xmath11 where @xmath12 and @xmath8 , we have , from , @xmath13 .",
    "moreover , if a poisson assumption is made for the actual number of deaths , then the resulting maximum likelihood estimate of the force of mortality @xmath14 ( and hence @xmath15 ) is given by @xmath16 where @xmath17 is the number of deaths recorded at age @xmath1 last birthday and the exposure - to - risk @xmath18 is the average number of people aged @xmath1 last birthday , during the observation year .",
    "note that @xmath18 is approximated by an estimate of the population aged @xmath1 last birthday in the middle of the observation year .",
    "we refer to @xmath19 as the crude death rate .    in the above setup",
    "it is assumed that the force of mortality @xmath20 is deterministic .",
    "the stochastic case can be handled by the intensity - based framework where death time is modeled as the first jump time of a doubly stochastic process ( @xcite ) .",
    "hereafter we treat the force of mortality @xmath21 , the central death rate @xmath22 and the crude death rate @xmath23 as stochastic processes . for a detailed discussion of the background of stochastic mortality modelling in discrete - time and continuous - time ,",
    "see @xcite .",
    "one of the most widely considered examples of stochastic factor model in the context of mortality modelling is the approach first presented in @xcite who proposed a stochastic mortality model for the age - specific crude death rate @xmath23 , where @xmath24 and @xmath25 represent age ( or age - group ) and year ( time ) respectively . under the model , the dynamics of the log crude death rates , @xmath26 ,",
    "is given by .",
    "the distinction of the crude and central death rate is of particular importance when one considers a poisson regression setup of death counts ( discussed in section  [ sec : regressionbased ] ) where the dynamics of the central death rate is being modeled ( @xcite and @xcite ) . ]",
    "@xmath27 where @xmath28 denotes a gaussian distribution with zero mean and variance @xmath29 .",
    "the vector @xmath30 $ ] represents the age - profile of the log death rates and @xmath31 measures the sensitivity of of death rates for different age group to a change of the time series @xmath32 .",
    "the period effect , @xmath32 , for forecasting purpose , is assumed to satisfy the equation @xmath33 where @xmath34 and @xmath35 are independent .    under this specification , it is clear that the lee - carter model is not identifiable , since is invariant up to some linear transformations of the parameters : @xmath36 where @xmath37 , @xmath38 and @xmath39 .    to overcome this identification issue",
    "when estimating the lee - carter model , one has to impose a non - unique choice of constraints to restrict the model to an identifiable class .",
    "it is standard practice in actuarial literature to consider the following two constraints : @xmath40 as suggested in @xcite to remedy the identifiability issue .",
    "this choice of constraints is equivalent to fixing @xmath41 and @xmath42 .",
    "consequently we have @xmath43 and @xmath44 .",
    "the reason for these particular form of identification constraints relates to the fact that the constraint on the path space of the stochastic factor @xmath45 is intended to have the effect of centering the @xmath32 values over the range @xmath46 , such that the structure is designed to capture age - period effects with the @xmath47 terms incorporating the main age effects , averaged over time , and the bilinear terms @xmath48 incorporating the age specific period trends ( relative to the main age effects ) .    since the introduction of the lee - carter model it has found a widespread uptake of this class of factor model in both practice , where the lee - carter model is now used as a benchmark methodology by the us bureau of the census , and in academia where a range of stochastic mortality model extensions have been proposed in the literature , see table  [ table : modelsliterature ] .",
    "we note here that @xcite and @xcite introduces multi - period ( @xmath49 ) and cohort factor ( @xmath50 ) , respectively , to the lee - carter method .",
    "@xcite considers a simplified version of the model in @xcite .",
    "@xcite propose to model @xmath51 instead of log death rates and @xmath52 is the average age in the sample range .",
    "an addition of cohort factor is studied in @xcite .",
    "@xcite introduces a model which combines the desirable features of the previous models and include a term @xmath53 to capture better young age mortality . the specification of identification constraints for the lee - carter type models , that is for those where the log death rate is being modeled in table  [ table : modelsliterature ] ,",
    "is discussed in @xcite .",
    "several `` classical '' approaches to lee - carter model estimation have been proposed in the literature , though they typically involve a two - stage procedure looking first at the observation equation as a regression ( ignoring the latent factor structure explicitly ) and then in the second stage they fit time series models to the latent factor structures . a good overview of such methods is obtained in @xcite .",
    "this two - stage procedure is at odds with modern state - space modelling procedures which have been progressively moving towards joint parameter estimation and latent state estimation in frequentist and bayesian formulations , which will be discussed in subsequent sections .",
    "this is reflected in the first attempt to improve the calibration approaches as reflected in the comment in @xcite where they highlight that the `` .. _ key element of the proposed framework is our single - stage approach to model fitting and process parameter estimation .",
    "_ '' such sentiments , relating to consistent single stage joint estimation are also echoed in the work of @xcite .",
    "one of the most commonly adopted approaches to estimate stochastic mortality models is via singular value decomposition ( svd ) .",
    "we use the multi - period ( @xmath54-factor ) lee - carter model ( @xcite ) with identification constraints given by @xmath55 where @xmath56 , as an example to illustrate the methodology below ( @xcite ) .",
    "stage 1a - observation equation estimation stage : : :    we first notice that the constraint    @xmath57 will lead to an    estimator for the level @xmath58 given by    @xmath59 stage 1b - observation equation estimation stage : : :    the next stage is to de - trend the observations    @xmath60 by the level estimate    @xmath61 and then to perform a svd on the    resulting @xmath62 matrix of residual observations to    obtain the decomposition    @xmath63 = \\sum^h_{i=1}\\rho_i \\bm{u}_{i}\\bm{v}^\\top_{i},\\ ] ]    where @xmath64 denotes transposition and    @xmath65 , for @xmath66 , are the    descending singular values where @xmath67 is the rank of the    data matrix . here",
    "@xmath68 and    @xmath69 are the corresponding left and right singular    vectors of the singular value @xmath65 with dimension    @xmath70 and @xmath71 respectively . for a    @xmath54-rank , where @xmath72 , approximation of    the matrix , we have    @xmath73    where    @xmath74    is the @xmath54-rank residuals .",
    "we then identify    @xmath75 and    @xmath76 , for    @xmath56 .",
    "one then performs the transformation    @xmath77    to ensure the constraints @xmath78 , for    @xmath56 , are satisfied .",
    "stage 2 - latent process factor estimation stage : : :    at this stage suggested in @xcite . ] , the estimation of the    latent factors can be performed by specifying a time series model    structure such as arima model for each of the factors :    @xmath79    or alternatively one could fit the equivalent vector auto - regressive    ( var ) model structure not treating each factor as independent in the    time series specification .",
    "one would typically perform this stage of    estimation via the yule - walker equations , see for instance discussions    in @xcite . under such specifications ,",
    "one then obtain closed form    distributions and estimators for period effect latent factor forecasts    that can be substituted into the observation model for forecasts of    the mortality by age in future forecast horizons and used to construct    life tables .",
    "it is important to note that the svd approach assumes homoscedasticity in the error structure .",
    "therefore , to account for heteroscedasticity in mortality data for different ages , @xcite propose to model death counts , instead of death rates , via poisson regression where the addition error term in the lee - carter approach is replaced by poison random variation .",
    "specifically , the number of death @xmath80 is modeled as @xmath81 where @xmath82 is the death exposure , @xmath83 is a model of the central death rate and @xmath84 is the parameter vector according to the model being used , including time dynamic factors such as period and cohort effect , see for example table  [ table : modelsliterature ] .",
    "the parameter vector is then estimated by maximising the log - likelihood function , which is given by @xmath85 where @xmath86 indicates the factorial of @xmath80 .",
    "times series models are then used to model the time dynamic factors forming a second stage estimation procedure for forecasting purpose .",
    "note that the cbd type models can be estimated under this approach since we have @xmath87 ( @xcite ) .",
    "in all the discussed cases above , there is the general idea that the two - stage estimation approaches ( svd and regression ) treat the unobserved factors corresponding to for instance a period effect @xmath32 and a cohort effect @xmath50 as parameters . for forecasting purpose ,",
    "these dynamics factors are then modeled as time series , typically under the arima framework . in this paper",
    "we argue that a more consistent approach involves embedding the specification of the model formally within a state - space model structure and to perform the estimation via a joint combination of filtering and static - parameter estimation , which can be achieved either in bayesian ( posterior - based ) or frequentist ( likelihood - based ) settings .",
    "we will demonstrate both in this paper .",
    "from the bayesian modelling perspective there are few papers that study stochastic mortality models , the main papers in this area involve the works of @xcite , @xcite and @xcite . as observed in these studies ,",
    "there are many possible advantages to adopting a bayesian approach for mortality modelling , especially in the context of small populations which may also have substantial quantities of missing data .",
    "an important point to note is that all bayesian model formulations to date in the mortality modelling literature , that we are aware of , have utilised what would , in modern statistical approaches be considered rudimentary sampling based approaches to performing bayesian estimation of the lee - carter type models .",
    "the criticism here can be leveled in two ways .    1",
    ".   the first relates to the fact that in these bayesian formulations the latent dynamic process states are still treated in the mcmc sampling procedures as if they were a set of static model parameters .",
    "the issues with doing this have been mentioned in numerous places , see for example @xcite .",
    "recently new approaches to such inference in bayesian models have been developed to avoid having to make univariate conjugate gibbs or metropolis - within - gibbs steps for the latent processes .",
    "the reason for this is that it is known in general to be very inefficient in performing inference and can be prone to misleading posterior inference results due to poor mixing performance of the markov chain for a finite computational budget .",
    "detailed discussions have been provided on such problems in @xcite and subsequently in work such as @xcite and the specific case to population based state - space models in ecology in @xcite .",
    "2 .   secondly",
    ", all existing mcmc sampling - based approaches we are aware of for bayesian inference in the mortality modelling literature tends to neglect the issue of model identification in the likelihood which can cause issues in the bayesian formulation . in fact , some approaches implement identification constraint in the bayesian model and develop an mcmc sampler that tries to impose the identification constraint in such a manner that the resulting markov chain may not be consistent with preserving the correct invariant stationary distribution if one applies the constraints inappropriately .",
    "we investigate this issue in a separate paper ( @xcite ) .",
    "these two considerations need to be resolved to update the approaches to more efficient sampling approaches with enhanced specifications of the model formulation to deal with such issues directly . in particular , modern approaches to such model estimations",
    "are to treat the latent unobserved process not as static parameters but as a state - space model in which filtering based methods ( kalman filter variants , smc ) can be utilised for the latent process estimations jointly with consistent estimation of the ` static ' model parameters .",
    "we will detail such estimation procedures which are also consistent with imposing specific identification constraints of relevance to the lee - carter model formulations , that are developed to ensure the correct invariant bayesian posterior model is preserved by the markov chain sampler and filters developed .",
    "we note the fact that model parameters that are not identified in the likelihood pose no formal problem in a bayesian analysis .",
    "identification is a property of the likelihood function , whereas bayesian inference simply uses the likelihood function to map through the data from prior beliefs to posterior beliefs .",
    "however , it is often the case that working with unidentified likelihood functions is usually unsatisfactory from a practical perspective as it may lead to partial identification issues in the posterior or problematic multimodality in the posterior . in general",
    "if one utilises a proper prior distribution it may act to provide a `` near - identification '' in the sense that one considers parameter restrictions as limiting forms of prior densities , then there is at least a functional equivalence between introducing prior information about parameters , and imposing identifying restrictions .",
    "we are now in a position to present an alternative representations of stochastic mortality modelling based on state - space methodology ( @xcite , @xcite ) .",
    "a key advantage of this approach is that the two - stage estimation and forecasting procedure under the svd or poisson regression maximum likelihood approaches can be combined in a single setting .",
    "the improved statistical consistency of a single stage approach is recognised in @xcite .",
    "another key advantage comes from the recent progress in sampling - based techniques in the estimation of state - space models .",
    "the advancement allows statistical inference to be conducted on sophisticated state - space models .",
    "we take advantage of this development and utilise realistic model aiming to capture long term mortality dynamics .",
    "a general state - space model consists of a state equation @xmath88 and an observation equation @xmath89 where the states @xmath90 form a hidden / latent markov process with disturbance @xmath91 , and the observed time series data @xmath92 depends only on @xmath90 and disturbance @xmath93 . here",
    "@xmath94 and @xmath95 are possibly nonlinear functions , and the states @xmath90 and observations @xmath92 can be multi - dimensional .",
    "it is clear that the models in table  [ table : modelsliterature ] specify the observation equation of different state - space models that can be considered .",
    "for example , for the multi - period lee - carter model ( @xcite ) , the observed data is @xmath96 for different age @xmath1 and the latent states are the period effects @xmath97 .",
    "we also note that multi - population ( i.e. multi - curve ) structures can be incorporated in the following state - space models in a number of different ways and the approaches we will develop for estimation will accommodate such settings . in the following sub - sections we will discuss a few different classes of mortality models that are difficult to deal with in the approaches mentioned in section 2 , but can be handled straightforwardly in state - space framework .",
    "we present here a state - space formulation of the lee - carter model with heteroscedasticity structure . in this context",
    ", the hetroscedasticity refers to a relaxation of the constant single degree of freedom diagonal covariance assumption typically made on the observation vector for each year @xmath98 across the panel of age group stratefications @xmath99 . within this state - space model structure",
    "we propose an alternative identification constraint which is tailored for the estimation under the state - space approach .    the lee - carter model with heteroscedasticity structure",
    "can be written in state - space form by combining the processes @xmath100 and @xmath32 into one dynamical system    [ eqn : lch ] @xmath101    where @xmath102 , @xmath31 and @xmath32 is the latent state of the resulting linear gaussian state - space model . here",
    "@xmath103 is a @xmath70 by @xmath70 diagonal matrix with @xmath104 on the diagonal .",
    "we refer to this model as lc - h model , and the special case with @xmath105 , @xmath106 , as lc model .    instead of the identification constraint ,",
    "we suggest an alternative constraint which is simpler and more readily applicable to monte carlo based procedures such as mcmc and smc . our formulation of the identification constraints are given by setting @xmath107",
    "such a choice is a valid identification constraint since if one of the elements of each @xmath108 and @xmath109 are known ( here we have arbitrarily chosen @xmath110 and @xmath111 ) , then a non - trivial linear transformation in is not allowed anymore ; that is , we must have @xmath112 and @xmath113 .",
    "note that implementing the proposed constraint is straightforward in both maximum likelihood and bayesian setting compared to the constraint .",
    "a natural extension of the lc - h model is to include a second stochastic factor for the cohort effect .",
    "we denote this model by lc2-h model . the cohort effect ( @xcite )",
    "can be modeled under the state - space framework as follows @xmath114 where @xmath115 .",
    "the state equation can be expressed as @xmath116 here we assume @xmath32 is a random walk with drift process and an ar(1 ) process is assumed for the cohort effect , that is @xmath117 , where @xmath118 .",
    "note that , from , we have @xmath119 for @xmath120 , which is the defining property of the cohort effect and consequently we are only required to model the dynamics of @xmath121 .",
    "we can write the model - in the following form    [ eqn : lch ] @xmath122^\\top+ \\boldsymbol{\\varepsilon}_t , \\quad \\boldsymbol{\\varepsilon}_t \\overset{iid}{\\sim } \\text{n}(0,\\sigma ) , \\\\",
    "\\kappa_t & = \\kappa_{t-1}+\\theta+\\omega^{\\kappa}_{t } , \\quad \\omega^\\kappa_t \\overset{iid}{\\sim } \\text{n}(0,\\sigma^2_{\\omega^\\kappa}),\\\\ \\bm{\\zeta}_t & = c\\bm{\\zeta}_{t-1 } + d\\bm{\\omega}^\\zeta_t , \\quad \\omega^{\\zeta_1}_t   \\overset{iid}{\\sim } \\text{n}(0,\\sigma^2_{\\omega^\\zeta}),\\end{aligned}\\ ] ]    where @xmath123 is the @xmath70 by @xmath124 matrix in , @xmath125 is the corresponding @xmath70 by @xmath70 sub - matrix in and @xmath126 is a zero @xmath70 by @xmath70 matrix except for the @xmath127 element with value @xmath128 .",
    "we can further extend the lc2-h model by adding a third factor for the dynamic of volatility in the observation vector over time .",
    "the state - space dynamics is given by :    [ eqn : lch ] @xmath122^\\top+ \\sqrt{\\gamma^y_t}\\boldsymbol{\\varepsilon}_t , \\quad \\boldsymbol{\\varepsilon}_t \\overset{iid}{\\sim } \\text{n}(0,\\sigma ) , \\\\",
    "\\kappa_t & = \\kappa_{t-1}+\\theta+\\omega^\\kappa_{t } , \\quad \\omega^\\kappa_t \\overset{iid}{\\sim } \\text{n}(0,\\sigma^2_{\\omega^\\kappa}),\\\\ \\bm{\\zeta}_t & = c\\bm{\\zeta}_{t-1 } + d\\bm{\\omega}^\\zeta_t , \\quad \\omega^{\\zeta_1}_t   \\overset{iid}{\\sim } \\text{n}(0,\\sigma^2_{\\omega^\\zeta}),\\\\ \\gamma^y_{t } & = a(b-\\gamma^y_{t-1 } ) + \\gamma^y_{t-1 } + \\sigma \\sqrt{\\gamma^y_{t-1 } } \\epsilon^{\\gamma^y}_t , \\quad \\epsilon^{\\gamma^y}_t \\overset{iid}{\\sim } \\text{n}(0,1),\\end{aligned}\\ ] ]    where @xmath129 is a process obtained via an euler discretization of a square bessel process corresponding to the cox - ingersoll - ross process given by @xmath130 where @xmath131 to ensure @xmath129 is strictly positive .",
    "such a dynamic volatility factor can be used to explain time varying periods of heightened observation variance , which potentially occur in some populations over time .",
    "these may be attributed to disease , war , famine , environmental factors or shocks as well as changes in migration and immigration patterns that could influnce the volatility of the observed death counts in different age groups .      a common assumption in mortality modelling is that the period effect is derived from a discretization of a random walk with drift process .",
    "such a process may be sufficient for modelling simple dynamics , but can be insufficient if time varying periods of volatility are present in the time series .",
    "in fact , much of the literature focuses mainly on capturing the trend of the period effect @xmath32 for the past several decades where mortality time series for many countries are reasonably smooth .    here",
    "we extend the lee - carter framework to incorporate stochastic volatility in the latent process . as a result",
    ", the impact of epidemics , natural disasters , medical breakthrough or wars on the evolution of mortality can be taken into account .",
    "this will produce different structural effects on the calibration and importantly on the forecasting when compared to the previously developed model of lc3-h2 .",
    "we refer - as lee - carter stochastic volatility model which we denote as lcsv model :    [ eqn : lcsv ] @xmath132    the log - volatility process @xmath133 is introduced in the state equation for @xmath32 via the error term @xmath35 .",
    "the process @xmath133 is an autoregressive model of order 1 ( ar(1 ) ) with @xmath134 and the mean reverting level is given by @xmath135 .",
    "a heteroscedasticity structure can be introduced in and will be referred to as lcsv - h model .",
    "cohort effect can also be incorporated as follows :    [ eqn : fps3_sv ] @xmath136^\\top + \\boldsymbol{\\varepsilon}_t , \\quad \\boldsymbol{\\varepsilon}_t      \\overset{iid}{\\sim } \\text{n}(\\boldsymbol{0},\\sigma^2_\\varepsilon\\boldsymbol{1}_p ) ,   \\\\",
    "\\kappa_t & = \\kappa_{t-1 } + \\theta + \\omega_t , \\quad \\omega_t|\\gamma_t \\sim      \\text{n}(0,\\exp\\{\\gamma_t\\ } ) , \\\\",
    "\\gamma_t & = \\lambda_1 \\gamma_{t-1 } + \\lambda_2 + \\eta_t ,",
    "\\quad \\eta_t \\overset{iid}{\\sim }      \\text{n}(0,\\sigma^2_\\gamma ) , \\\\",
    "\\bm{\\zeta}_t & = c\\bm{\\zeta}_{t-1 } + d\\bm{\\omega}^\\zeta_t , \\quad \\omega^{\\zeta_1}_t   \\overset{iid}{\\sim } \\text{n}(0,\\sigma^2_{\\omega^\\zeta}).\\end{aligned}\\ ] ]    compared to the lc3-h2 model where stochastic volatility is included in the observation noise term , introducing stochastic volatility in the latent period process has the advantage , in terms of simplicity and ease of interpretation , that the variability of mortality data in the time dimension is captured purely by the latent process .",
    "given these different state - space model structures , the next task to consider is the inference for the joint single stage state and parameter estimation . in this section",
    "we consider full likelihood based joint inference procedures based on filtering and gradient estimation . to achieve this",
    "we must describe both filtering in linear gaussian and non - linear / non - gaussian filtering via smc method ( particle filters ) and their application to gradient based estimation in the marginal likelihood , having integrated out the latent state processes .",
    "we will do this in a general way and then present particular examples of relevance to this paper .    under the classical maximum likelihood approach ,",
    "parameters are estimated by maximizing a model s log - likelihood function . in the case of state - space models in the form of -",
    ", the likelihood is in two forms : the complete data likelihood , assuming @xmath137 fixed , is given by @xmath138 and the marginal likelihood , typically used for the static model based inference , is given by @xmath139 where @xmath140 denotes the @xmath141-dimensional parameter vector of the model .",
    "two challenges now arise .",
    "the first is that typically the integral in can not be evaluated in closed form , except for linear gaussian state - space model systems .",
    "the second issue is that the gradient equations for such a state - space model marginal likelihood , even if they can be calculated in closed form , requires a non - linear multiple equation solver . for this reason it is common to adopt a solution based on a recursive estimation using gradient and hessian information from the marginal likelihood . under the gradient - based approach",
    ", the optimal parameter vector can be found by iterations , where the @xmath142-th estimate is obtained by : @xmath143^{-1}\\nabla_{\\bm{\\psi}}\\,\\ell\\left(\\boldsymbol{\\psi}^{(m)}\\right),\\ ] ] where @xmath144 , @xmath145 and @xmath146 denote the log - likelihood function , the gradient ( or score ) vector and the hessian information matrix of the log - likelihood function respectively , defined with respect to grad and laplacian differential operators given by : @xmath147_{i } & : = { \\partial \\over \\partial \\psi_i } , \\;\\ ; \\forall i \\in \\{1,\\ldots , n\\ } \\\\",
    "\\left[\\nabla^2_{\\bm{\\psi}}\\right]_{i , j } & : = \\frac{\\partial^2}{\\partial \\psi_i \\partial \\psi_j } , \\;\\ ; \\forall i , j \\in \\left\\{1,\\ldots , n\\right\\}. \\end{split}\\ ] ] the iterating scheme will stop once certain criterion is met , for example when the magnitude of the score vector is small enough .",
    "this will be illustrated using the lc - h model as an example in section [ subsec : mle ] .",
    "the result developed are based on the marginal likelihood of the state - space model , with generic static model parameters @xmath140 for observations @xmath148 having integrated out latent states @xmath149 , denoted by @xmath150 .",
    "we are then interested in forming recursive filtering to integrate the complete data likelihood to find the marginalized likelihood and then working with recursive gradient based estimation to update static model parameters in newton - descent type algorithm , or for linear gaussian systems a recursive least squares based approach .",
    "as observed in @xcite and @xcite , it is useful to consider two classes of identities for the gradient and hessian of the marginalized likelihood , given by the fisher s identity and the louis identity , respectively according to @xmath151 where @xmath152 an important point about these recursions is that the integrals for the gradient vector and hessian matrix are expressed in terms of the path - space distribution @xmath153 . in the case of the linear gaussian dynamics this distribution",
    "can be obtained based on variations of the kalman filter recursion , however when the state - space model is non - linear or non - gaussian this distribution must be estimated via monte carlo methods .",
    "the most efficient of these methods for state - space modelling purposes is known as the class of smc methods ( particle filters ) . in this case",
    "it will be more accurate from the perspective of the variance of the estimated gradient and hessian matrices to utilise the filter distribution based estimators in a recursive fashion based on the local estimates of the distributions @xmath154 , for each @xmath155 rather than the path space estimator which is based on distribution @xmath153 at the final time @xmath71 . the result explaining the difference in estimation precision for the gradient and hessian , from the perspective of variance of the solution on the path space distribution versus filter distributions is provided in theorem 1 of @xcite .",
    "this motivates the need to work with the filter recursions .    to achieve",
    "this one can replace in the fisher and louis identities the path - space quantities @xmath156 and @xmath153 by the filter quantities given by @xmath157 and @xmath154 .",
    "after this substitution , one may utilise the following recursive formulations to evaluate the gradient and hessian , see @xcite and @xcite . in this case",
    "the fisher identity is recursively given by : @xmath158d\\bm{\\phi}_{t-1},\\\\ p_{\\bm{\\psi}}\\left(\\bm{\\phi}_t,\\bm{z}_{1:t}\\right ) & = p_{\\bm{\\psi}}\\left(\\bm{z}_{1:t-1}\\right)p_{\\bm{\\psi}}\\left(\\bm{z}_{t}|\\bm{\\phi}_t\\right)\\int p_{\\bm{\\psi}}\\left(\\bm{\\phi}_t|\\bm{\\phi}_{t-1}\\right ) p_{\\bm{\\psi}}\\left(\\bm{\\phi}_{t-1}|\\bm{z}_{1:t-1}\\right ) \\ , d\\bm{\\phi}_{t-1}. \\end{split}\\ ] ]    the recursive form of luis identity is given by : @xmath159\\right.\\\\ & \\times \\left[\\nabla_{\\bm{\\psi}}\\ln p_{\\bm{\\psi}}\\left(\\bm{z}_{t}|\\bm{\\phi}_t\\right ) + \\nabla_{\\bm{\\psi}}\\ln p_{\\bm{\\psi}}\\left(\\bm{\\phi}_t|\\bm{\\phi}_{t-1}\\right ) + \\nabla_{\\bm{\\psi}}\\ln p_{\\bm{\\psi}}\\left(\\bm{\\phi}_{t-1},\\bm{z}_{1:t-1}\\right)\\right]^\\top\\\\ & \\left .",
    "+ \\left[\\nabla^2_{\\bm{\\psi}}\\ln p_{\\bm{\\psi}}\\left(\\bm{z}_{t}|\\bm{\\phi}_t\\right ) + \\nabla^2_{\\bm{\\psi}}\\ln p_{\\bm{\\psi}}\\left(\\bm{\\phi}_t|\\bm{\\phi}_{t-1}\\right ) + \\nabla^2_{\\bm{\\psi}}\\ln p_{\\bm{\\psi}}\\left(\\bm{\\phi}_{t-1},\\bm{z}_{1:t-1}\\right)\\right ] \\right\\ } d\\bm{\\phi}_{t-1}. \\end{split}\\ ] ] in general , the solution to these recursions can be achieved via smc as detailed in @xcite and @xcite .    in the following sections we will illustrate the use of these recursive identities for the special case of the lc - h model where the state - space takes a linear gaussian form . in this case the integrals and recursive evaluation of the gradient and hessian",
    "can be written in closed form .",
    "to proceed we first introduce the optimal filter recursion , with respect to minimization of mean squared error , in the case of linear gaussian state - space models , known as the kalman filter ( @xcite and @xcite ) .",
    "the aim of filtering is to obtain the distribution of the latest state given observations . for a general state - space model , - , the filtering density @xmath160 at time @xmath98 can be calculated sequentially by first assuming the filtering density @xmath161 at time @xmath162 is known . then the one - step ahead predictive density for the state is given by @xmath163 from bayes formula and the structure of the conditional dependency of the state - space model , one can obtain the filtering density as @xmath164 for nonlinear and non - gaussian state - space models , numerical techniques such as smc methods are required to estimate the filtering density , see @xcite , @xcite and @xcite .    in the case of the lc - h model , since it is a linear and gaussian state - space model , the filtering distribution can be obtained analytically via kalman filtering . in particular we can find the conditional distributions of the key quantities in the filtering recursions are all gaussian distributions as follows :    @xmath165    where the recursive nature of these distributions arises from the recursions of the sufficient statistics :    @xmath166    that is , given the filtering distribution at @xmath162 , , the filtering distribution at @xmath98 is given by using - .",
    "for the lc - h model , the log - likelihood function @xmath167 is given by @xmath168 where @xmath169 , and @xmath170 is an @xmath171-dimensional parameter vector .",
    "the log - likelihood function can be derived directly from .",
    "it can be shown that ( @xcite ) the elements of the score vector and the information matrix are given in closed form for the lc - h model according to the expressions : @xmath172 + 2\\frac{\\partial      \\boldsymbol{v}^\\top_t}{\\partial \\psi_i}\\boldsymbol{q}^{-1}_t\\boldsymbol{v}_t\\right\\ } , \\quad i=1,\\dots , n\\ ] ] where @xmath173 $ ] denotes the trace operator and @xmath174=      \\frac{1}{2}\\sum^t_{t=1}\\left[\\text{tr}\\left(\\boldsymbol{q}^{-1}_t\\frac{\\partial      \\boldsymbol{q}_t}{\\partial \\psi_i}\\boldsymbol{q}^{-1}_t\\frac{\\partial \\boldsymbol{q}_t}{\\partial      \\psi_j}\\right)\\right ] + \\text{e}\\left[\\sum^t_{t=1}\\frac{\\partial      \\boldsymbol{v}^\\top_t}{\\partial \\psi_i}\\boldsymbol{q}^{-1}_t\\frac{\\partial \\boldsymbol{v}_t}{\\partial      \\psi_j}\\right ] , \\quad i , j=1,\\dots , n\\ ] ] and the expectation operator @xmath175 $ ] on the second term in can be dropped ( since the expressions are asymptotically equivalent ) . in order to evaluate the score vector and the information matrix ,",
    "we need @xmath176 and @xmath177 the expressions and require , for @xmath25 and @xmath178 , @xmath179 the expressions in in turn require , for @xmath180 and @xmath178 , @xmath181 and @xmath182 note that @xmath183 for @xmath178 and the required differentiation matrices @xmath184 , @xmath185 , @xmath186 , @xmath187 and @xmath188 are displayed in appendix  [ appa : matrices ] .",
    "the gradient - based estimation for the lc - h model is described in algorithm [ mlalgorithm ] .    ;",
    "specify @xmath189 and @xmath190 .",
    "count the number of iteration performed as @xmath191 ; run kalman filter using @xmath192 ; obtain and for @xmath193 ; evaluate the score vector @xmath194 using ; evaluate the information matrix @xmath195 $ ] given by ; set @xmath196\\right]^{-1}\\nabla_{\\boldsymbol{\\psi}}\\,\\ell(\\bm{\\psi}^{(m)})$ ] .",
    "in contrast to the classical maximum likelihood approach where parameters are deterministic but unknown , in a bayesian view the parameters are treated as random variables . in this way",
    "the bayesian paradigm can take parameter uncertainty into account and incorporate in a consistent manner apriori beliefs on the important model parameters , as encoded through the prior .",
    "in this section we aim to develop modern approaches to bayesian inference for state - space modelling that do not rely on potentially inefficient sampling approaches based on gibbs or metropolis - within - gibbs for the latent state process .",
    "instead we will introduce to stochastic mortality modelling state - space models of two classes of bayesian inference :    * * linear gaussian stochastic mortality models : * a rao - blackwellised gibbs sampler approach which is based on a combination of metropolis - within - gibbs and gibbs sampling steps for the static model parameters , combined with a forward - backward kalman filter recursion for the state process .",
    "we assume the proposed constraints throughout , avoiding the constraint issue when performing mcmc as discussed in section [ classicalbayes ] . * * non - linear / non - gaussian stochastic mortality models : * in the case of non - linear and or non - gaussian state - space model dynamics such as the stochastic volatility models of lc3-h2 and the lcsv models , the sampler we develop is based on novel developments of the particle metropolis hastings samplers of @xcite adapted to the stochastic mortality models .",
    "in particular we consider a combination of rao - blackwellized kalman filter and particle filter for the latent state process full posterior conditionals , combined with a combination of metropolis - within - gibbs and gibbs sampling steps for the static model parameters .    in general under all the bayesian approaches",
    "we consider , we aim to obtain the joint posterior density @xmath197 of the states @xmath198 as well as the parameters , @xmath199 , given the observations @xmath200 . we begin with the first case of the linear gaussian state - space stochastic mortality models and we use the lc - h model as an example where the parameter vector is @xmath201 as we use the constraint proposed in .",
    "we develop an efficient approach involving a combined gibbs sampling conjugate model sampler for the marginal target distributions of the static model parameters along with a forward backward kalman filter sampler for the latent process @xmath202 . a sample of the targeted density is obtained via gibbs sampling where @xmath203 is the number of mcmc iterations ( algorithm [ gibbsalgorithm ] ) .",
    "sample @xmath204 from @xmath205 via ffbs ( section [ sec : estimationfirstdensity ] ) .",
    "sample @xmath206 from @xmath207 , where @xmath208 .",
    "the general block gibbs sampling algorithm steps require to sample from the full conditional densities @xmath209 and @xmath210 , which are shown in the following .",
    "samples of the full conditional density @xmath209 can be obtained via the so - called forward - filtering - backward sampling ( ffbs ) procedure ( @xcite ) .",
    "we can write @xmath211 where the last term in the product , @xmath212 , is distributed as @xmath213 which is obtained from the last iteration of the kalman filtering procedure .    once we draw a sample @xmath214 from @xmath213",
    ", then suggests that we can draw recursively and backwardly @xmath32 from @xmath215 where @xmath216 .",
    "moreover , we have @xmath217 where    @xmath218    which can be derived based on kalman smoother ( @xcite ) .",
    "the ffbs procedure is displayed in algorithm  [ ffbsalgorithm ] .",
    "note that the prior distribution for @xmath219 can be set to be vague to run the kalman filter ; the output of the algorithm includes the posterior distribution of @xmath219 .",
    "sample @xmath32 from @xmath220 using the sample @xmath221 obtained in the previous step .",
    "the first thing to observe is that under the reparameterization of the identification constraints , the following gibbs sampling stages can be performed exactly .",
    "we assume that the prior for @xmath222 are given by    @xmath223    where @xmath224 denotes an inverse - gamma distribution with mean @xmath225 and variance @xmath226 for @xmath227 .",
    "we assume that the priors for all parameters are independent . in this case",
    "the posterior densities of parameters are of the same type as the prior densities , a so - called conjugate prior .",
    "the posterior distribution for each parameter is given by ( we write , for ease of notation , @xmath228 , @xmath229 , family @xmath230 means ",
    "parameter vector @xmath199 without the parameter @xmath231 \" ) : @xmath232      in the case of non - linear / non - gaussian state - space model dynamics such as the stochastic volatility models of lc3-h2 and the lcsv models , the sampler we develop is based on novel developments of the particle metropolis hastings samplers of @xcite adapted to the stochastic mortality models . in particular",
    "we consider a combination of rao - blackwellized kalman filter and particle filter for the latent state process full posterior conditionals , combined with a combination of metropolis - within - gibbs and gibbs sampling steps for the static model parameters , both embedded within a pmcmc framework .",
    "we will illustrate the idea of this methodology for the lcsv model where a stochastic volatility dynamics is included in the latent process for the period effect .",
    "the static parameter vector is denoted as @xmath233 .",
    "note that we treat @xmath234 as a static parameter and our task is to obtain samples from the joint posterior distribution : @xmath235 in this setting one can try a number of different approaches , the first would be to sample jointly from the full posterior distribution via pmcmc methods to be described below .",
    "a second approach would be to combine pmcmc methods within a block - gibbs based sampler such as the following sampling scheme , where we apply gibbs sampling to sample from the full conditional densities    @xmath236    note that sampling from can be achieved by the ffbs procedure described in algorithm [ ffbsalgorithm ] , as one can apply kalman filtering since @xmath237 is assumed to be given . the only difference compared to section [ sec : estimationfirstdensity ] is that the term @xmath238 is replaced by @xmath239 in kalman filtering .    in the following we provide details on how to sample from either the full posterior or from full conditionals such as the density in , via pmcmc method .",
    "sampling from the posteriors of the static parameters is detailed in section  [ sec : lcsvstaticposteriors ] .      in this section",
    "we explain the generic form of the pmcmc methodology that can be applied in a range of approaches for state - space stochastic mortality models . in general",
    "a pmcmc sampling method is a class of mcmc method where smc algorithm is used as a proposal distribution within a mcmc algorithm .",
    "though this seems trivial , it is actually based on a key observation that by using such a filter within the mcmc , the dimension of the acceptance probability in the metropolis - hastings acceptance - rejection stage is significantly reduced and can therefore facilitate much better mixing performance of the resulting markov chain , reducing variance in estimation , see discussion in detail in @xcite .    to bring out the essence of pmcmc",
    ", we first discuss a generic approach to sample from a target distribution @xmath240 where @xmath241 and @xmath199 are the latent state and static parameters of a general state - space model .",
    "note , the state processes in this context are generally non - linear and potentially non - gaussian .    from the perspective of obtaining the most efficiently mixing markov chain to sample from this posterior , the ideal proposal distribution for constructing the markov chain for @xmath242",
    "is easily seen to be given by @xmath243 where @xmath244 is a proposal for the parameters and the proposal for the latent state , @xmath245 , is from the state equation ( given @xmath246 ) .",
    "here @xmath247 is the current state at mcmc iteration @xmath248 and @xmath242 is the proposed next move at mcmc iteration @xmath249 .    in this ideal case ,",
    "the acceptance probability of this ideal proposal is given by : @xmath250 where @xmath251 .",
    "a desirable property of the ideal proposal is that the acceptance probability depends only on the marginal likelihood , together with the prior and proposal for the static parameters .",
    "this is optimal in the sense that the dimension of the numerator and denominator is reduced significantly to the static model parameter dimensions , and not including explicitly the path - space latent process dimensions , a reduction of @xmath252 dimensions for a d - dimensional state vector @xmath253 .",
    "however , clearly one can never achieve this goal as it requires perfect knowledge of @xmath245 as well as the ability to sample this distribution , both of which are unachievable except in the special case of the linear - gaussian case explained in section [ sec : estimationfirstdensity ] .    to circumvent this problem , the particle marginal metropolis - hastings sampler ( pmmh ; @xcite ) applies smc method to obtain an approximate of the state transition density ( which is also the state proposal ) @xmath254 where @xmath255 is the importance weight",
    ", @xmath256 denotes a dirac mass function centered at @xmath257 and a proposed next move of the latent state is drawn from this discrete approximate distribution .",
    "moreover , a by - product of a smc algorithm is the marginal likelihood , @xmath258 , which has the following important property :    [ lem : unbiasedmarginal ] a smc proposal admits as a by - product an unbiased estimator of the marginal likelihood @xmath259 given by @xmath260 where a smc approximation with @xmath261-particles produces , for all @xmath98 , @xmath262 which is an unbiased particle estimate of @xmath263 .",
    "this non - trivial unbiasedness was first presented in @xcite and has since been utilised to great advantage as explained in @xcite .",
    "in addition the variance of this estimator typically only grows linealy with @xmath71 .",
    "the unbiased approximate marginal likelihoods are then used in the acceptance probability : @xmath264 due to the unbiasedness of the estimated marginal likelihood , @xcite show that , even though only smc approximates are used ( with finite number of particles @xmath261 ) , the invariant distribution of pmmh is the target distribution @xmath265 .",
    "to apply pmcmc for an efficient estimation of the lcsv model , we first notice that we can obtain explicitly the posteriors of static parameters via conjugate priors . as a result",
    "we are only required to sample from the density @xmath266 , instead of the joint density @xmath267 .",
    "it turns out that there is a class of pmcmc algorithm , called particle independent metropolis - hastings sampler ( pimh ) , which provide a mechanism to sample exactly from @xmath266 .",
    "our approach to sampling from the joint posterior distribution , @xmath268 , of the lcsv model is summarised in algorithm  [ gibbsalgorithmlcsv ] .",
    "sample @xmath204 from @xmath269 via ffbs ; sample @xmath270 from @xmath271 via pimh ( section [ sec : pimh ] ) ; sample @xmath206 from @xmath272 , where @xmath273 via conjugate prior .",
    "we first note that @xmath274 given the structure of the lcsv model . using an independent proposal density , @xmath275 , in the metropolis - hastings algorithm",
    ", the acceptance probability is given by @xmath276 ideally , one may take @xmath277 . however , in most cases such an ideal choice is impossible to sample from and to evaluate .",
    "the pimh sampler proposes instead to use the smc approximation @xmath278 as the proposal density and calculate the acceptance probability as @xmath279},\\ ] ] where @xmath280 and @xmath281 $ ] are unbiased marginal likelihoods estimated by smc ( see lemma  [ lem : unbiasedmarginal ] ) in the current mcmc iteration @xmath249 and the previous iteration @xmath248 respectively .",
    "it can be shown that the invariant distribution of the pimh sampler is the target distribution @xmath282 ( @xcite ) .",
    "it remains to specify an smc approximation @xmath278 ( appendix  [ app : smc ] ) .",
    "we use the so - called bootstrap filter , that is , the proposal distribution in the smc algorithm to draw @xmath133 is given by the state equation : @xmath283 consequently , the importance weight is evaluated as @xmath284 where @xmath285 is the incremental importance weight .",
    "our approach for sampling from @xmath286 is summarised in algorithm  [ pimhalgorithm ] ( together with algorithm  [ bootstrapalgorithm ] ) .",
    "iteration @xmath287 : obtain an smc approximation @xmath288 via algorithm  [ bootstrapalgorithm ] .",
    "draw @xmath289 \\sim \\hat{\\pi}_{\\boldsymbol{\\psi}}(\\gamma_{1:t}|\\kappa_{0:t})$ ] and obtain the corresponding marginal likelihood estimate @xmath290 $ ] .",
    "obtain an smc approximation @xmath288 via algorithm  [ bootstrapalgorithm ] .",
    "draw @xmath291 and obtain the corresponding marginal likelihood estimate @xmath280 .",
    "draw @xmath292 .",
    "if @xmath293},\\ ] ] set @xmath294 = \\gamma'_{1:t}$ ] and @xmath295=\\hat{\\pi}_{\\boldsymbol{\\psi}}(\\kappa_{0:n})'$ ] ; otherwise set @xmath294 = \\gamma_{1:t}[j-1]$ ] and @xmath295=\\hat{\\pi}_{\\boldsymbol{\\psi}}(\\kappa_{0:n})[j-1]$ ] .",
    "obtain @xmath296 $ ] as a sample of @xmath286 .",
    "draw @xmath297 from @xmath298 and set @xmath299 evaluate @xmath300 normalise : @xmath301 evaluate @xmath302 obtain @xmath303 .",
    "we assume the prior for @xmath305 is given by    @xmath306}(\\tilde{\\mu}_{\\lambda_1 } , \\tilde{\\sigma}^2_{\\lambda_1}),\\ ,          \\lambda_2 \\sim          \\text{n}(\\tilde{\\mu}_{\\lambda_2 } , \\tilde{\\sigma}^2_{\\lambda_2}),\\ ,          \\gamma_0 \\sim          \\text{n}(\\tilde{\\mu}_{\\gamma_0 } , \\tilde{\\sigma}^2_{\\gamma_0 } ) ,      \\end{aligned}\\ ] ]    where @xmath307 and @xmath308}$ ] denotes a truncated gaussian with support @xmath309 $ ] .",
    "it is assumed that the priors for all parameters are independent .",
    "samples from the density @xmath304 are obtained by sampling from the following posteriors : @xmath310 } \\left(\\frac{\\sigma^2_\\gamma\\tilde{\\mu}_{\\lambda_1}+\\tilde{\\sigma}^2_{\\lambda_1}\\sum_t\\gamma_{t-1}\\gamma_t }         { \\sigma^2_\\gamma+\\tilde{\\sigma}^2_{\\lambda_1}\\sum_t\\gamma^2_{t-1 } } ,        \\frac{\\tilde{\\sigma}^2_{\\lambda_1}\\sigma^2_\\gamma}{\\sigma^2_\\gamma+\\tilde{\\sigma}^2_{\\lambda_1}\\sum_t\\gamma^2_{t-1}}\\right ) , \\\\",
    "\\lambda_2|\\boldsymbol{y}_{1:t},\\boldsymbol{\\kappa } , \\bm{\\gamma } , \\boldsymbol{\\psi}_{-\\lambda_2 } & \\sim    \\text{n } \\left(\\frac{\\sigma^2_\\gamma\\tilde{\\mu}_{\\lambda_2}+\\tilde{\\sigma}^2_{\\lambda_2}\\sum_t(\\gamma_t-\\lambda_1\\gamma_{t-1 } ) }          { \\sigma^2_\\gamma+t\\tilde{\\sigma}^2_{\\lambda_2 } } , \\frac{\\tilde{\\sigma}^2_{\\lambda_2}\\sigma^2_\\gamma}{\\sigma^2_\\gamma+t\\tilde{\\sigma}^2_{\\lambda_2}}\\right ) , \\\\",
    "\\gamma_0|\\boldsymbol{y}_{1:t},\\boldsymbol{\\kappa } , \\bm{\\gamma } , \\boldsymbol{\\psi}_{-\\gamma_0 } & \\sim \\text{n } \\left(\\frac{\\sigma^2_\\gamma\\tilde{\\mu}_{\\gamma_0}+\\tilde{\\sigma}^2_{\\gamma_0}\\lambda\\gamma_1 }          { \\sigma^2_\\gamma+\\tilde{\\sigma}^2_{\\gamma_0}\\lambda^2 } ,          \\frac{\\tilde{\\sigma}^2_{\\gamma_0}\\sigma^2_\\gamma}{\\sigma^2_\\gamma+\\tilde{\\sigma}^2_{\\gamma_0}\\lambda^2}\\right).\\end{aligned}\\ ] ] where the posterior distributions are obtained similarly as in section [ subsubsec : parapostdistlch ] .",
    "in this section a real data empirical study is conducted on danish mortality data using the models summarised in table [ table : modelsummary ] .",
    "the lc , lc - h and lcsv models are described in section [ subsec : ssm ] . while the lc - h model addresses heteroscedasticity in the observation equation , the lcsv model attempts to incorporate stochastic volatility in the state dynamics .",
    "the lcsv - h model includes both features of the lc - h model and the lcsv model , thus allowing for a full consideration of variability in long term mortality dynamics .",
    "the human mortality database provides a particularly long time series of mortality data from year 1835 to 2011 for the danish population , supplemented with a detailed document analysing the data ( @xcite ) .",
    "the provision of a long time series is important to our analysis concerning stochastic volatility . in the past several decades , mortality trend for developed countries",
    "generally exhibit a rather smooth pattern .",
    "the inclusion of periods that involve wars , epidemics or other life - critical events are crucial factors in witnessing significant volatility in mortality time series . in the following",
    "we analyse the population mortality from denmark based on the models in table  [ table : modelsummary ] and bayesian methodologies studied in this paper .",
    "we then examine the models in terms of the forecasting properties of death rates and life expectancies",
    ". we also comment on the linear trend assumption and jump - off bias in mortality forecasting .      the data set consists of danish male population death rates for 21 age groups ( 0 , 1 - 4 , 5 - 9 , @xmath311 , 95 - 99 ) from year 1835 - 2010 where we fix year 2010 as the end year .",
    "figure  [ fig : timeseriesden ] displays some of the time series of the log death rates for the danish male population .",
    "it is clear that the multi - dimensional time series exhibit different volatility for different age groups , which justify the introduction of heteroscedasticity into the observation equation as discussed in section  [ sec : lchetero ] .",
    "we also observe that , mainly before 1950 , there are periods that the volatility of death rates for some age groups are markedly different .",
    "such a change of volatility in the temporal dimension suggests that stochastic volatility may be present in the underlying time preiod effect .          in our empirical study",
    "we focus on bayesian inference and forecasting .",
    "we assume vague priors so that all inferences are mainly based on the data and the impact of the prior is not material . taking the lcsv model as an example ,",
    "we assume @xmath312 , @xmath313 , @xmath314 , @xmath315 , @xmath316 , @xmath317 , @xmath318 , @xmath319 and @xmath320 , where @xmath321 .",
    "the number of iterations of the markov chain is @xmath322 with @xmath323 burn - in .",
    "we fix @xmath324 and @xmath325 as an identification constraint .",
    "estimated values of the static parameters ( except @xmath108 and @xmath109 ) for the danish mortality data ( 1835 - 2010 ) are shown in table  [ table : denstaticpara ] .",
    "the rest of the estimated parameters and states are displayed in figure  [ fig : denlcsvh18352010 ] .",
    "here we only show the plots for the lcsv - h model since the corresponding figures obtained from the lc , lc - h and lcsv model are visually similar to the case of the lcsv - h model .",
    "it is evident from figure  [ fig : denlcsvh18352010 ] that there are periods , namely 1850 - 1870 , 1910 - 20 , 1930 - 1950 , that the time effect @xmath326 exhibits higher volatility compared with other periods .",
    "we also observe that @xmath326 accelerates markedly downward after 1990 and is relatively smooth in the recent period 1950 - 2010 .",
    "the filtering of the log - volatility process @xmath327 ( figure  [ fig : denlcsvh18352010 ] ) quantifies the volatility level ( @xmath328 ) of the time effect and gives further evidence on the stochastic volatility nature of mortality . to see more clearly the phenomenon of changing volatility",
    ", we plot the first difference @xmath329 in figure  [ fig : denlcsvh18352010 ] for the lcsv - h model , where @xmath330 denotes the posterior mean of @xmath32 , @xmath331 .",
    "it shows evidently the change of volatility level in the latent process @xmath32 .",
    "the patterns of the estimated log - volatility @xmath327 and the first difference @xmath332 clearly suggest that it is not appropriate to assume constant volatility ( @xmath238 ) for the time effect .",
    "the state - space modelling approach is able to uncover the age - specific heteroscedasticity structure hidden in the danish mortality time series .",
    "figure  [ fig : denlcsvh18352010 ] reveals that variability is particularly high for the very young and very old age group .",
    "implications of the heteroscedastic structure on forecasting will be discussed in section  [ sec : forecast ] .    to investigate the forecasting properties of the stochastic volatility model",
    ", we also estimate the models based on calibration periods 1835 - 1990 and 1950 - 1990 .",
    "figure  [ fig : denlcsvh18351990 ] and [ fig : denlcsvh19501990 ] show the estimated parameters and states for the lcsv - h model in those periods .                      to compare the fit of the models to the data , we apply deviance information criterion ( dic ) as a bayesian measures of model complexity and fit ( @xcite ) .",
    "it is common to assess and compare models with latent variables using conditional dic ( @xcite , @xcite ) .",
    "specifically , we use the so - called conditional log - likelihood which is calculated as @xmath333 note that the likelihood is conditional on parameters that include both static parameters and the latent process @xmath326 . using the conditional log - likelihood function ,",
    "the deviance is defined as @xmath334 where @xmath335 and we assume @xmath336 since in the models we consider it plays the role of a constant which is the same for competing models .",
    "the effective dimension , @xmath337 , is evaluated as @xmath338 where @xmath339 and @xmath340 denote , respectively , the mean of @xmath341 and the mean of the posterior distribution of @xmath342 .",
    "the conditional dic is then given by @xmath343 which can be evaluated straightforwardly using mcmc samples .",
    "the dic values for the models with different calibration periods are shown in table  [ table : dic ] .",
    "the inclusion of heteroscedasticity structure has markedly improved the lc and lcsv model . for long calibration period ,",
    "the lcsv model has outperformed the lc model .",
    "it indicates that the better fit of the lcsv model has more than compensated for its increased complexity . for short calibration period ( 1950 - 1990 )",
    ", the lc model performed better than the lcsv model which is expected , since over the short period the evolution of mortality rates is rather smooth and there is no clear advantage in introducing stochastic volatility to the lc model .      in this section",
    ", we investigate the forecasting properties of the mortality models summarised in table  [ table : modelsummary ] where heteroscedasticity as well as stochastic volatility structures are incorporated .",
    "our analysis is based on the forecasting distributions of ( log ) death rates and life expectancy .",
    "the bayesian state - space framework allows us to obtain the forecasting distributions using mcmc samples which is shown below .      for the lc ( lc - h ) model ,",
    "the @xmath54-step ahead forecasting distribution of @xmath344 , given @xmath200 , is given by @xmath345 where @xmath199 is the parameter vector for the lc ( lc - h ) model .",
    "suggests that we can sample recursively to obtain the forecasting distribution , for @xmath346 , as follows    [ eqn : forecastlcsample ] @xmath347    where @xmath348 and @xmath349 is the number of mcmc iterations after burn - in . here",
    "@xmath103 is a diagonal matrix with @xmath350 on the diagonal for the lc - h model and @xmath29 for the lc model .",
    "this procedure generates an estimate of the forecasting distribution .",
    "similarly , the forecasting distribution of @xmath344 , given @xmath351 , for the lcsv ( lcsv - h ) model is given by @xmath352 for @xmath346 , the forecasting distribution can be obtained by sampling recursively    [ eqn : forecastlcsvsample ] @xmath353    where @xmath348 , and @xmath103 is a diagonal matrix with @xmath350 on the diagonal for the lcsv - h model and @xmath29 for the lcsv model .",
    "figure  [ fig : forecastdeathrates18352010 ] shows the forecasted log death rates based on the lc - h , lcsv and lcsv - h model , using the lc model as a benchmark .",
    "we show age groups 5 - 9 , 35 - 39 , 65 - 69 and 95 - 99 as representatives of young , adult , old and very old age .",
    "the models are estimated using data for the period 1835 - 2010 and forecast for 30 years .",
    "the heteroscedasticity structure , from the lc - h model , gives rise to materially larger forecasting intervals for the young and very old age group , while the forecasting interval for the age group 35 - 39 is narrower than predicted by the lc model .",
    "the lcsv model , on the other hand , produces a wider forecasting interval compared to the lc model except for the very old age group .",
    "the observed wider forecasting interval is due to the fact that the volatility level is increasing in the last estimation periods and is larger than @xmath238 estimated in the lc model .",
    "moreover , as the estimated @xmath354 is close to zero at older ages ( figure  [ fig : denlcsvh18352010 ] ) , the impact of the forecasted @xmath326 on the prediction of death rates diminished significantly as older ages are considered . the lcsv - h model exhibits similar features of the lc - h and the lcsv model .",
    "it is interesting to note that the forecasted means obtained from the different models are very similar and their differences mainly lie in the forecasting interval .    to illustrate further the forecasting property of the lcsv model",
    ", we estimate the models for the period 1835 - 1990 and plot 20-year out - of - sample forecasted log death rates in figure  [ fig : forecastdeathrates18351990 ] .",
    "it turns out the forecasting intervals predicted by the lcsv model tends to be narrower than the lc model , as the estimated @xmath238 in the lc model is larger than the volatility level at the last estimation period for the lcsv model in this case .",
    "note that the forecasted distributions produced by the lc - h model are biased compared to the benchmark lc model since the fitted rates at the last estimation period , that is year 1990 , are different for the lc and lc - h model .",
    "this feature is known as jump - off error ( @xcite ) .",
    "one may remove this jump - off bias by forcing the forecasted death rates to start at the actual rates instead of the fitted rates ( @xcite and @xcite ) . in this paper",
    "we do not perform this procedure , however .",
    "figure  [ fig : forecastdeathrates19501990 ] shows the forecasting distributions of log death rates where we assume a shorter calibration period from 1950 to 1990 .",
    "for all the models , the estimated @xmath354 for all age groups , except for age groups 0 , 1 - 4 and 5 - 9 , are very close to zero .",
    "it is in fact expected since there is no clear downward trend in the observed mortality data besides the first few age groups , during the period 1950 - 1990 .",
    "therefore there is only small difference between the forecasting distributions produced by the lc model and the lcsv model , except for young age groups .",
    "note that there is a clear change of downward trend for some of the middle age groups for the danish male mortality data as shown in figure  [ fig : forecastdeathrates19501990 ] .",
    "it results in the out - of - sample data falling out of the lower bound of the @xmath355 credible intervals and its consequence for the forecasting of life expectancy will be discussed in section [ sec : lifeexp ] and generally in section [ sec : lineartrend ] .    by comparing the forecast performance using in - sample data from 1835 - 1990 and from 1950 - 1990 displayed in figure  [ fig : forecastdeathrates18351990 ] and [ fig : forecastdeathrates19501990 ] ,",
    "we expose the influence that leaving out important historical events , that may affect the mortality rates markedly in a population , can have on the ability to accurately model trend and volatility structures in population dynamics .",
    "in particular we observe that one must be cautious as forecast performance can degrade markedly when important historical events are excluded from the sample as the forecast using data from 1835 - 1990 has clearly outperformed the forecast using only shorter calibration data from 1950 - 1990 .                                  using the samples of the forecasted log death rates @xmath356 , where @xmath348 and @xmath349 is the number of mcmc samples , we can obtain the so - called period life expectancy at different ages by constructing an abridged life table , since we use age group data , as follows ( @xcite , @xcite ) .",
    "we consider age group @xmath357 \\{0 , 1 - 4 , 5 - 9 , @xmath311 , 95 - 99 } and @xmath358 is defined as the initial age of age group @xmath1 , that is @xmath359 .",
    "define @xmath360 as the length of the interval of age group @xmath1 ( corresponds to @xmath358 ) and hence we have @xmath361 .",
    "we then calculate the ( crude ) death probability that a person aged @xmath358 in year @xmath98 will die in the next @xmath360 years as @xmath362 where @xmath363 is the average fraction of the @xmath360 years lived by the people who is initially aged @xmath358 in that interval . using the assumption that deaths are distributed uniformly in the interval",
    ", we set @xmath364 for every @xmath358 . in different period .",
    "for ease of comparison we use the typical assumption that @xmath364 . for the special case when age , instead of age group is considered ( that is @xmath365 )",
    ", the one - year death probability @xmath366 in year @xmath98 is defined as the ratio of death counts and the population at the beginning of the year . assuming half of the deaths occurred during the first half of the year",
    ", then we have @xmath367 where @xmath82 is the population at the middle of the year .",
    "the @xmath360-year death probability for the general case when age group is considered can be derived similarly .",
    "] the hypothetical number of people alive at age @xmath368 , @xmath369 , is determined by @xmath370 where @xmath371 is assumed to be @xmath372 .",
    "we can then calculate the number of deaths @xmath373 and the person - years lived @xmath374 .",
    "the total future lifetime of the @xmath375 persons who attain age @xmath358 is @xmath376 , where @xmath377 . finally , a sample of the period life expectancy at age @xmath358 is obtained as @xmath378 and the distributions are obtained in different forecasting year @xmath379 where @xmath380 .",
    "period life expectancy assumes there is no trend for future death rates ( it is evaluated based on the age - specific death rates in a fixed year @xmath98 ) while cohort life expectancy assumes death rates following the lifetime of a cohort and hence it takes mortality trend into account . for example , to evaluate period life expectancy at age @xmath381 in year @xmath98 , one needs @xmath382 while for cohort life expectancy , @xmath383 are used instead .",
    "however , the cohort life expectancy for people born in recent years can not be evaluated using data alone since some of the death rates data are yet to be observed . as a result",
    "we focus on period life expectancy so that our forecasts can be compared with the observed data .",
    "figure  [ fig : forecastlifeexp18352010 ] shows 30-year forecasted ( period ) life expectancy at birth , age 65 and age 85 for all the models estimated using data from 1835 - 2010 .",
    "interestingly , the forecasted life expectancy at birth is similar for the lc and lc - h model .",
    "it reflects the fact that forecast intervals of death rates produced by the lc - h model are wider for some age groups and narrower for others , compared to the lc model .",
    "these effects tend to cancel each other out as death rates are aggregated for all age groups to form the life expectancy at birth , resulting with a comparable life expectancy at birth distributions .",
    "this explanation does not apply to life expectancy at age 65 and 85 , however , since only forecasted death rates for age groups larger than 65 and 85 are used to obtained the corresponding life expectancy distribution . as the forecast intervals of death rates generated by the lc - h model are narrower for old age groups compared with the lc model , the interval for the forecasted life expectancy at age 65 and 85 distribution produced by the lc - h model is observably narrower than the lc model .",
    "the higher variability of the forecasted death rates for the lcsv model translates to a wider forecast interval for life expectancy compared to the lc model .",
    "similarly to the case of death rates forecasting , the lcsv - h model has both the features of the lc - h and lcsv model in terms of life expectancy prediction .    as we use the fitted death rates instead of the observed death rates in the jump - off year ( that is year 2010 ) ,",
    "there is a jump - off bias in the forecasted death rates .",
    "the forecasted life expectancy at age 65 is particularly sensitive to this jump off bias .",
    "it comes from a sudden decline of death rates for age groups larger than 65 beginning in year 1990 , hence an increase of life expectancy at age 65 is observed .",
    "the jump - off bias is significantly smaller when the calibration period 1835 - 1990 is considered , see figure  [ fig : forecastlifeexp18351980 ] .",
    "as expected , the forecasted distributions of life expectancy at birth and age 65 are similar for all the models estimated using mortality data from year 1950 - 1990 ( figure  [ fig : forecastlifeexp19501980 ] ) .",
    "note that the @xmath355 credible intervals capture poorly the out - of - sample data in this case except for the life expectancy at age 85 .",
    "it is a consequence of the sudden change of significant downward trend for the death rates observed in the middle age groups of the danish mortality data starting from around 1990 , see figure [ fig : forecastdeathrates19501990 ] , as well as the jump - off bias .",
    "we discuss about the linear trend assumption and jump - off bias in the next section .",
    "in performing the forecasting of death rates and life expectancies , we use the models summarised in table [ table : modelsummary ] where the lc - h , lcsv and lcsv - h models are variants of the lee - carter model in which a linear trend of the period effect is assumed .",
    "however , for the danish male mortality data that we used , the overall trend is reasonably linear for the whole period 1835 - 2010 , but the same may not be said for the shorter period 1950 - 2010 as figure [ fig : forecastdeathrates18351990]-[fig : forecastdeathrates19501990 ] indicate .",
    "in particular , we observe in figure [ fig : forecastdeathrates19501990 ] that there is a clear change of trend for the death rates of middle age groups .",
    "such a change of trend is difficult , if not impossible , to predict in terms of timing and magnitude .",
    "we also perform the analysis on french male mortality data and found similar patterns . for forecasting purpose",
    ", one may therefore argue that expert opinion will be an important factor in predicting mortality .",
    "even though any change of mortality trend in the short run can not be predicted with reasonable accuracy using data alone , it can be _ detected _ if the instantaneous volatility of mortality is quantified .",
    "for example , using the lcsv - h model , the log - volatility @xmath384 is quantified and we observe from figure [ fig : denlcsvh18352010 ] that @xmath384 started to increase around 1990 after several decades of declining .",
    "the change of volatility level not only affect the prediction intervals as discussed in previous sections , but also indicates that the change of mortality is heightened and one should be cautious whether a change of trend is taking place .",
    "we also find that jump - off bias , discussed in section [ sec : deathrates]-[sec : lifeexp ] , is an important factor in predicting deaths rates and life expectancies .",
    "we note that it is straight forward to remove the jump - off bias by adjusting - so that the actual death rates , instead of the fitted death rates , are used in the beginning of the forecasting period .",
    "we do not provide the corresponding plots in the paper but one can envisage the results simply by shifting the forecasted distribution so that the forecasted mean is attached to the ( in - sample ) data at the end of the estimation year .",
    "removing the jump - off bias will have a significant impact on the accuracy of mortality forecasting especially when data exhibit clear trending .",
    "we developed and presented a comprehensive state - space framework for stochastic mortality modelling .",
    "the state - space approach has two key advantages .",
    "first , it puts modelling , estimation and forecasting of mortality in a unified framework in contrast to common practice in this area .",
    "second , the methodology permits realistic and sophisticated mortality models to be estimated and forecasted , which could be difficult to handled using other approaches .",
    "we show that many of the popular mortality models exist in the literature can be cast in state - space form .",
    "we then suggest several classes of mortality models that can be classified as linear gaussian state - space models and non - linear / non - gaussian state - space models .",
    "our proposals are not exhaustive but aim to illustrate the flexibility of the methodology .",
    "in particular we incorporate heteroscedasticity and stochastic volatility in mortality modelling , as an examination of mortality data suggests that volatility of death rates is not constant in the age and time dimension over a long time period .",
    "moreover , we propose an alternative identification constraint for the lee - carter type modelling , which is tailored for the state - space approach .",
    "frequestist state - space inference for stochastic mortality models is carried out and explained based on the gradient and hessian of the marginalized likelihood developed recently in statistics literature .",
    "we also utilise a modern approach to bayesian inference for state - space modelling hinged on the pmcmc framework .",
    "in particular we develop a sampler using a combination of rao - blackwellized kalman filter and particle filter for the latent state process full posterior conditionals , combined with gibbs sampling steps for the static model parameters to estimate a stochastic volatility model for mortality proposed in this paper .    using mortality data of danish male population ,",
    "we assess the extended models based on deviance conditional criterion .",
    "it is found that incorporating heteroscedasticity is a crucial improvement factor in model fitting , while model complexity is accounted for .",
    "the incorporation of stochastic volatility clearly enhances model performance for fitting of long term mortality time series .",
    "estimation results for long calibration period support the assumption of stochastic volatility .",
    "we show that forecasting can be carried out straightforwardly in state - space framework under a bayeisan setting .",
    "we examine the forecasting properties of the models using different calibration periods .",
    "the inclusion of heteroscedasticity and stochastic volatility substantially affects prediction intervals of death rate and life expectancy distributions .",
    "the linear trend assumption commonly found in mortality modelling and jump - off bias are discussed in light of the danish mortality data .",
    "state - space framework provides attractive features that are of importance to mortality modelling .",
    "the methods and results developed and shown in the paper will have significant implications for longevity risk management in actuarial applications which is a topic of future research .",
    "this research was supported by the csiro - monash superannuation research cluster , a collaboration among csiro , monash university , griffith university , the university of western australia , the university of warwick , and stakeholders of the retirement system in the interest of better outcomes for all .",
    "this research was also partially supported under the australian research council s discovery projects funding scheme ( project number : dp160103489 ) .",
    "for the lc - h model , the parameter vector is denoted by @xmath385 with dimension @xmath386 where @xmath70 is the number of age group considered . we are required to evaluate @xmath184 , @xmath185 , @xmath186 , @xmath187 and @xmath188 in the gradient - based estimation ( section [ subsec : mle ] ) .",
    "define @xmath387 then we have @xmath388 where @xmath389",
    "if @xmath390 and zero otherwise ; @xmath103 is a diagonal matrix with diagonal @xmath391 .",
    "note that @xmath392 for @xmath393 , where @xmath102 and @xmath31 .",
    "smc , also known as particle filtering , can be viewed as a generalisation of kalman filtering in state - space modelling context .",
    "the method is based on importance sampling and it has become an essential sampling - based tool in many domains ( @xcite ) . in the following we give a brief review of the method using the lcsv model , - , as an example to derive a basic particle filtering algorithm .",
    "our target density is the joint posterior distribution of the states for stochastic volatility : @xmath394 where the parameters of the model are assumed to be known and is suppressed here for ease of notation . to apply importance sampling ,",
    "we first calculate @xmath395 the importance density is assumed to satisfy @xmath396 and the importance weight is given by @xmath397 where @xmath398 is called the incremental importance weight .",
    "the normalised importance weights are then obtained as @xmath399 . to summarise ,",
    "suppose we have @xmath261 particle paths @xmath400 to approximate the density @xmath401 at time @xmath162 .",
    "then , from , the @xmath402-th particle path at time @xmath98 is given by @xmath403 where @xmath297 is sampled from @xmath404 .",
    "the target density @xmath405 is approximated by @xmath406 where the normalised weight @xmath407 is obtained from and normalisation is carried out .",
    "the problem of degeneracy , that is a majority of the particle paths may have negligible weight , can be handled by resampling .",
    "specifically , we define the so - called effective sample size @xmath408 at each time @xmath98 , if @xmath409 is smaller than some threshold ( for example @xmath410 of @xmath261 ) then we draw @xmath261 samples ( denoted by @xmath411 ) from a multinomial distribution with probability weights @xmath412 , @xmath413 , and replace the particle paths @xmath414 by @xmath415 , and set @xmath416 . the resampling step allows to keep the particle paths in proportion to their weights and tend to discard those that have negligible weights ."
  ],
  "abstract_text": [
    "<S> this paper explores and develops alternative statistical representations and estimation approaches for dynamic mortality models . </S>",
    "<S> the framework we adopt is to reinterpret popular mortality models such as the lee - carter class of models in a general state - space modelling methodology , which allows modelling , estimation and forecasting of mortality under a unified framework . </S>",
    "<S> furthermore , we propose an alternative class of model identification constraints which is more suited to statistical inference in filtering and parameter estimation settings based on maximization of the marginalized likelihood or in bayesian inference . </S>",
    "<S> we then develop a novel class of bayesian state - space models which incorporate _ apriori _ beliefs about the mortality model characteristics as well as for more flexible and appropriate assumptions relating to heteroscedasticity that present in observed mortality data . </S>",
    "<S> we show that multiple period and cohort effect can be cast under a state - space structure . to study long term mortality dynamics , we introduce stochastic volatility to the period effect . </S>",
    "<S> the estimation of the resulting stochastic volatility model of mortality is performed using a recent class of monte carlo procedure specifically designed for state and parameter estimation in bayesian state - space models , known as the class of particle markov chain monte carlo methods . </S>",
    "<S> we illustrate the framework we have developed using danish male mortality data , and show that incorporating heteroscedasticity and stochastic volatility markedly improves model fit despite an increase of model complexity . forecasting properties of the enhanced models </S>",
    "<S> are examined with long term and short term calibration periods on the reconstruction of life tables . </S>"
  ]
}