{
  "article_text": [
    "biological systems must process information about fluctuating environments , with a classical example being a cell computing an external ligand concentration by time - averaging @xcite . understanding the thermodynamics of cellular information processing",
    "is of central importance and has attracted much interest recently .",
    "particularly , the role of energy dissipation has been studied for _ _ e .",
    "coli @xcite and eukaryotic @xcite adaptation , a cell computing an external ligand concentration @xcite , biochemical sensing @xcite , and proofreading @xcite ( see also @xcite for older works ) .    in these studies ,",
    "energy dissipation is characterized by the familiar entropy production of stochastic thermodynamics @xcite .",
    "however , they do not consider an entropic rate characterizing information processing of a noisy external environment that is related to the thermodynamic entropy production through an inequality .",
    "in related work @xcite , we have shown that the rate of mutual information between an internal process , corresponding to chemical reactions inside the cell , and an external process is _ not _ bounded by the thermodynamic entropy production .    more broadly , the relation between information and thermodynamics is a very active topic , with theoretical studies focused on second law inequalities and fluctuation relations @xcite , as well as experimental works @xcite .",
    "of particular relevance to this paper , it has recently been realized that a bipartite markov process provides a simple realization of a maxwell s demon @xcite , where the entropic rate characterizing information is the entropy reduction rate of a subsystem due to its coupling to the other subsystem composing the bipartite system .",
    "this entropy rate has been studied for the first time by allahverdyan et al .",
    "@xcite for two brownian particles coupled to different heat baths , where it was interpreted as an information flow . for bipartite jump processes a closely related entropic rate , also named information flow , has been studied more recently in @xcite .",
    "moreover , in related work a relation between dissipation and information about an external signal has been obtained @xcite .    in this paper , we show that for a bipartite process , with an internal process learning about an unaffected external process , the rate at which the uncertainty about the external environment , represented by a conditional shannon entropy , decreases due to the dynamics of the internal process is bounded by the thermodynamic entropy production .",
    "we call this rate the learning rate .",
    "this concept allows for the definition of an informational efficiency for biological information processing .",
    "particularly , we consider three different models inspired by the _ _ e .",
    "coli chemotaxis signaling network @xcite , where , for simplicity , the external process is assumed to correspond to an external ligand concentration jumping between two values .",
    "we demonstrate how an informational efficiency can be defined and analyzed in a simple four - state model , for which the entropy production corresponds to atp consumption inside the cell .",
    "for this system , a comparison with the efficiency of molecular motors is possible .",
    "we then consider a system where the internal process corresponds to an equilibrium monod - wyman - changeux ( mwc ) @xcite model for a single _ _ e .",
    "coli receptor . in this case , even if there is no energy consumption inside the cell , the learning rate is bounded by the chemical work done by the external process .",
    "finally , we analyze a more complete model for _ _ e .",
    "coli receptors including adaptation @xcite .",
    "we show that the learning rate can even exceed the rate at which the cell consumes the free energy source if work done by the external process compensates for it .",
    "we also analyze a coarse - grained learning rate for the model with adaptation : comparing it with the mwc model not including adaptation , we find that the concentration range for which the learning rate is non - negligible increases with adaptation",
    ".    the paper is organized as follows . in sec .",
    "[ sec2 ] , we define the class of markov processes and observables we study in this paper . moreover ,",
    "we show that the learning rate is bounded by the thermodynamic entropy production . in sec .",
    "[ sec3 ] , the four state model is studied , while sec .",
    "[ sec4 ] contains the mwc like model . in sec .",
    "[ sec5 ] , the model with adaptation is analyzed .",
    "we conclude in sec .",
    "let us first introduce discrete bipartite markov processes @xcite , where a state @xmath0 is labeled by two variables .",
    "moreover , it is assumed that @xmath1 is an external process unaffected by the internal process @xmath2 .",
    "the transition rates , from @xmath3 to @xmath4 , are defined as @xmath5 where a transition changing both variables is not allowed .",
    "the fact that @xmath1 is an external process implies that the transition rates @xmath6 are independent of the internal variable @xmath7 . denoting the stationary probability distribution by @xmath8 , the thermodynamic entropy production is given by @xcite @xmath9 where @xmath10 .",
    "the first ( second ) term of the right hand side of ( [ thermoent ] ) , related to external ( internal ) jumps , is denoted by @xmath11 ( @xmath12 ) .      in the stationary state",
    "the conditional shannon entropy of @xmath1 given @xmath2 is @xmath13= -\\sum_{i,\\alpha } p_i^\\alpha \\ln p(\\alpha|i),\\ ] ] where @xmath14 , with @xmath15 . this shannon entropy quantifies the uncertainty about the external process given the internal variable .",
    "therefore , the stationary rate at which the internal process reduces the uncertainty of the external process due to its jumps can be written as @xmath16 in other words , @xmath17 , which we will call the learning rate , is the rate at which @xmath2 through its dynamics learns about @xmath1 .",
    "note that the @xmath2 jumps do not change the stationary shannon entropy of @xmath1 , therefore , the learning rate is also equal to the rate of change in the stationary mutual information due to the @xmath2 jumps @xcite .",
    "the full time derivative of @xmath18 $ ] in the stationary state reads @xmath19= l_y - h_x=0 , \\label{consl}\\ ] ] where @xmath20 arises from the @xmath1 jumps .",
    "hence , equation ( [ consl ] ) implies @xmath21 .",
    "the rates @xmath22 and @xmath17 have been recently considered in @xcite , where @xmath22 , for example , is interpreted as the rate of the entropy reduction of subsystem @xmath1 due to its coupling with @xmath2 .",
    "the conservation law @xmath23 simply means that the rate of entropy reduction of @xmath1 is precisely the rate with which @xmath2 learns about @xmath1 .",
    "these entropic rates have also been considered recently in @xcite , where they are referred to as information flow and obtained from the time derivative of the mutual information . moreover , to our knowledge the first reference to introduce similar entropic rates is @xcite , where two coupled langevin equations were studied and the entropic rate is introduced as a time derivative of time - delayed mutual information .",
    "the learning rate fulfills @xmath24 , which comes from the fact that the transfer entropy from @xmath2 to @xmath1 is an upper bound on @xmath25 and equal to zero if @xmath1 is an external process unaffected by @xmath2 @xcite . whereas the positivity of the above thermodynamic entropy production ( [ thermoent ] ) represents the second law for the full system , it is straightforward to show that the second law for the subsystem @xmath2 reads @xmath26 @xcite .",
    "moreover , since @xmath1 is an external process , if we integrate out the @xmath2 variable @xmath1 is still a markovian process , therefore @xmath27 , which implies @xmath28 this inequality is a main foundation of the present paper : for a bipartite system with @xmath1 being an external process , the rate at which @xmath2 learns about @xmath1 is bounded by the thermodynamic entropy production , which characterizes the dissipation necessary for a nonzero learning rate . from inequality ( [ mainine ] ) , the following informational efficiency can be defined , @xmath29 if the external process is further assumed to be in equilibrium ( @xmath30 ) , which is the case in all the examples studied in this paper , then @xmath31 and @xmath32 .    in the following we demonstrate with three examples that the framework discussed in this section allows the study of cellular information processing , with the cost and thermodynamic efficiency of learning about an external random environment being well characterized .",
    "moreover , we show that while the learning rate @xmath17 is bounded by @xmath33 , it can be larger than the energy consumed by the cell if the external process does work .      for the mwc single receptor model in sec .",
    "[ sec4 ] and the model with adaptation in sec .",
    "[ sec5 ] , we have to consider an internal process which comprises two variables @xmath34 .",
    "the internal transition rates are now written as @xmath35 . in this case , another relevant quantity is the coarse - grained learning rate @xmath36 where @xmath37 with @xmath38 .",
    "this is the rate at which @xmath39 reduces the conditional shannon entropy @xmath40= -\\sum_{i_1,\\alpha } p_{i_1}^\\alpha \\ln p(\\alpha|i_1),\\ ] ] due to its jumps .",
    "hence , it is the rate at which the coarse - grained internal process @xmath39 learns about @xmath1 .",
    "the contribution due to @xmath1 jumps to @xmath41=0 $ ] is @xmath42 and the conservation law for the coarse - grained learning rate reads @xmath43 . from the log sum inequality , we obtain @xmath44 , showing that the coarse - grained variable @xmath39 can not learn more than the full variable @xmath2 . moreover , the coarse - grained entropy production is defined as @xcite @xmath45 which provides a lower bound on @xmath12 . finally ,",
    "similar to the second law inequality for a subsystem we also have @xmath46 we point out that this coarse - grained learning rate and the above discussion about it are novel .",
    "we start with the simplest thermodynamically consistent model for which the inequality ( [ mainine ] ) can be studied @xcite , see fig .",
    "[ fig1a ] .",
    "the internal process corresponds to a protein inside the cell y , which can be activated and deactivated by phosphorylation and dephosphorylation reactions .",
    "the chemical potential difference driving the reactions is @xmath47 .",
    "these reactions are represented by @xmath48{\\kappa_+ } { \\rm y}^*+{\\rm adp } \\xrightleftharpoons[\\omega_-]{\\omega_+ } { \\rm y}+{\\rm adp}+{\\rm p}_i , \\label{eqreaction}\\ ] ] where @xmath49 is the phosphorylation rate and @xmath50 is the dephosphorylation rate , with @xmath51 and @xmath52 representing the rates of the respective reversed reactions .",
    "the reaction rates are related to the chemical potential difference through @xmath53 $ ] , where we set @xmath54 throughout the paper .",
    "+    the external process corresponds to the external ligand concentration which jumps between low and high concentration with rate @xmath55 .",
    "the internal reaction rates depend on the external concentration in the following way .",
    "it is assumed that if the concentration is high the receptors in the cell surface are occupied by a ligand and in the inactive state , whereas if the concentration is low they are unbound and in the active state .",
    "moreover , an active receptor enhances the phosphorylation rate of the internal chemical reaction .",
    "more precisely , we consider that if the concentration is high , implying inactive receptors , only dephosphorylation occurs and if the concentration is low only phosphorylation takes place .",
    "this leads to the four state model represented in fig .",
    "[ fig1a ] .",
    "note that a full model with both chemical reactions occurring for both low and high concentration would have two links , representing the different chemical reactions , for the vertical transitions in fig .",
    "[ fig1a ] @xcite .",
    "this model is a quite simplified description of the _ _ e .",
    "coli chemotaxis signaling network @xcite , with the internal protein corresponding to the chey protein , which binds to the flagellar motor in its phosphorylated form , inducing tumbling .",
    "see @xcite for a related model where the number of phosphorylated internal proteins can be large .    the stationary probability current @xmath56 , where @xmath57 and @xmath58 are the stationary probabilities of the states shown in fig .",
    "[ fig1a ] , can be easily calculated and is given by @xmath59+(\\kappa_++\\kappa_-)(\\omega_++\\omega_-)}. \\label{currsimp}\\ ] ] the thermodynamic entropy production @xmath33 equals the rate of atp consumption , i.e. , @xmath60 for a nonzero learning rate the cell must consume atp and @xmath61 where @xmath62 $ ] , is bounded by the rate of atp consumption .",
    "this model shows tight coupling since @xmath17 and @xmath33 are proportional to the same probability current @xmath63 .",
    "it allows for an analogy with molecular motors @xcite .",
    "whereas molecular motors transform chemical energy obtained from atp hydrolysis into mechanical work , in our model atp is consumed so that the internal protein can learn about the external process at rate @xmath17 .",
    "there are two special limits related to the time - scales of the external process .",
    "for @xmath64 the current ( [ currsimp ] ) goes to zero and @xmath65 , implying maximal efficiency .",
    "therefore , this limit of zero learning rate and efficiency one corresponds to an adiabatic case .",
    "second , for @xmath66 the current tends to its maximal value for fixed @xmath67 @xmath68 but @xmath69 , implying @xmath70 .",
    "this limit is very inefficient , with zero learning rate and maximal atp consumption for fixed @xmath67 .",
    "these two limits are represented in the efficiency diagram plotted in fig .",
    "[ fig1b ] . comparing again with a molecular motor",
    ", the second limit corresponds to the case where the mechanical force goes to zero , leading to a high velocity of the motor but no mechanical work extraction . the first case , @xmath64 , is related to the stall force case , where the mechanical force equals the chemical potential difference driving the motor and the velocity tends to zero with efficiency approaching one .    from these two limiting cases",
    "it is clear that , for fixed @xmath71 , there is an optimal time - scale @xmath72 for which the learning rate @xmath17 should be maximal .",
    "this can be seen in fig [ fig1c ] .",
    "the maximum learning rate @xmath73 increases with @xmath67 , while the efficiency at maximum power @xmath74 decreases with @xmath67 , where @xmath75 , as plotted in fig .",
    "[ fig1d ] .",
    "furthermore , the efficiency at maximum power is maximal near equilibrium where it tends to @xmath76 , a well known result from linear response theory for tightly coupled heat engines @xcite and molecular motors @xcite .    the entropy production corresponding to the rate of atp consumed inside the cell is specific to this model .",
    "as we show next the entropy production can also arise from work done by the external process .",
    "_ e. coli _ receptors sit at its membrane and external ligands molecules can bind to them .",
    "the kinase chea is connected to the receptor through a protein chew and its activity is influenced by the binding of external ligands . if chea is in the active form , it acts as an enzyme of the phosphorylation reaction of the protein chey @xcite .",
    "here we consider a mwc model for a single receptor accounting for the indirect regulation of the kinase activity by the binding events @xcite .",
    "even though this single receptor model contains indirect regulation , it does lack cooperativity , which is the other key concept in mwc models @xcite . to study cooperativity more binding sites",
    "are needed which corresponds to a straightforward extension of the model . as we do not investigate cooperativity effects but rather the relation between learning rates and energy consumption , it is more convenient to keep a simpler model with a reduced number of states .",
    "more precisely , the internal process @xmath77 corresponds to the following four - state model , see fig .",
    "[ fig2a ] .",
    "the receptor can be either bound @xmath78 ( occupied by an external ligand ) or unbound @xmath79 .",
    "the free energy difference between the bound and unbound states is given by @xmath80 , where @xmath81 is the dissociation constant and @xmath82 the external ligand concentration .",
    "the quantities @xmath83 and @xmath84 represent the free energies of the receptor together with the external solution : in @xmath85 the term @xmath86 is related to a change in the free energy of the receptor and @xmath87 is the chemical potential of the particle taken from the solution in a binding event @xcite",
    ". moreover , the kinase attached to the receptor can be either inactive @xmath88 or active @xmath89 .",
    "a conformational change in the receptor is assumed to be an equilibrium process with the free energy difference between active and inactive given by @xmath90 .",
    "the interaction between the receptor and the enzyme attached to it is reflected in the dissociation constant depending on @xmath91 , being @xmath92 for @xmath88 and @xmath93 for @xmath89 .",
    "it is assumed that @xmath94 , with the activity increasing the dissociation constant . combining these parameters ,",
    "the free energy of an internal state @xmath95 can be written as @xmath96 the transition rates of this four - state model @xmath97 , from state @xmath95 to state @xmath98 , have to respect the detailed balance relation @xmath99= f(a , b , c)-f(a',b',c)$ ] .",
    "the four - state model corresponding to the internal process is represented in fig .",
    "[ fig2a ] , where @xmath100 and @xmath101 set the time - scale of the conformational changes and binding events , respectively .",
    "the time - scale of the latter is assumed to be much smaller than the time - scale of the conformational changes , i.e. , @xmath102 . as this is an equilibrium model ,",
    "the cycle affinity of the four - state cycle is zero .",
    "the external process corresponds to the external ligand concentration jumping between the values @xmath103 and @xmath104 at rate @xmath55 . the resulting full eight - state model is shown in fig . [ fig2b ]",
    "denoting the stationary probability of the state @xmath105 by @xmath106 , and using schnakenberg s formula @xcite , where the terms in the entropy production are cycle affinities multiplying probability currents , it is possible to write the entropy production ( [ thermoent ] ) in the form @xmath107 this entropy production arises from cycles , as indicated in fig .",
    "[ fig2b ] , where a ligand molecule is taken from the solution at concentration @xmath104 and released in the solution at concentration @xmath103 , corresponding to a chemical potential difference @xmath108 . therefore , @xmath33 is the chemical work that is done by the external process .",
    "in contrast to the first toy model , where the cell consumes atp , the work done by the external process compensates for a nonzero learning rate @xmath109 , which follows from ( [ learnrate ] ) as @xmath110 we also consider the coarse - grained rate at which @xmath91 learns about @xmath82 , which is obtained from ( [ learnratecg ] ) as @xmath111 where @xmath112 .",
    "the rate @xmath113 characterizes how much the internal kinase chea learns about the external process .",
    "this is the central quantity assuming that other chemical reactions inside the cell that are influenced by the activity can only learn as much as @xmath113 .    numerical results for this model with the choice of transition rates shown in fig .",
    "[ fig2 ] are shown in fig .",
    "[ fig4 ] . comparing figs .",
    "[ fig4a ] and [ fig4b ] , we see that the coarse - grained learning rate @xmath113 is close to @xmath109 if @xmath55 is small . as @xmath55 increases , the difference between both quantities increases .",
    "more precisely , if the external environment is considerably faster then the internal variable @xmath91 ( @xmath114 ) , then @xmath91 can not track concentration changes ( @xmath115 )",
    ". however , the learning rate @xmath109 is still nonzero , with its main contribution coming from the variable @xmath116 .",
    "the efficiency plot in fig . [ fig4c ] demonstrates that if the external environment is very slow @xmath117 the model reaches an adiabatic limit with @xmath118 and @xmath119 . for @xmath120",
    "there is a region of lower efficiency @xmath121 and high learning rates @xmath122 . if @xmath55 is further increased beyond the values displayed in fig .",
    "[ fig4c ] , the efficiency decays , going to zero for @xmath123 . in this case , not even @xmath116 can track the fast external changes .",
    "choosing the external concentrations as @xmath124 and @xmath125 , in fig .",
    "[ fig5a ] we plot @xmath109 and @xmath33 as a function of @xmath82 for different values of the conformational free energy difference @xmath90 .",
    "besides the simple illustration that the learning rate is bounded by the chemical work , these graphs demonstrate that for every @xmath82 there is an optimal value of @xmath90 that maximizes the learning rate @xmath109 .",
    "this is also the case for the coarse - grained learning rate @xmath113 . comparing @xmath109 with @xmath113",
    ", we see that the contribution of the variable @xmath116 to @xmath109 is more substantial for very low and very high @xmath82 .",
    "however , for @xmath126 the correlation between bound ( unbound ) and inactive ( active ) is high leading to @xmath127 .",
    "since binding events are faster than the conformational changes , it is possible to integrate out the variable @xmath116 @xcite . in this case , the internal process reduces to the two - state model of fig [ fig3a ] . in the limit @xmath128 the coarse - grained transition rates become @xcite @xmath129 where @xmath130 corresponds to the stationary conditional probability @xmath131 of the full internal process .",
    "the effective free energy difference resulting from a conformational change from @xmath88 to @xmath89 then reads @xmath132 the full system , including the concentration jumps , is the four - state model shown in fig .",
    "[ fig3b ] .",
    "the entropy production for this model is the coarse - grained entropy production ( [ thermoentcg ] ) , which reads @xmath133 , \\label{coarw}\\ ] ] where @xmath134 denotes the stationary probability of the coarse - grained model .",
    "this quantity provides a lower bound on the full chemical work ( [ chemicalw ] ) , which in the limit @xmath128 becomes @xmath135 therefore , with this time - scale separation the full chemical work can be calculated with the coarse - grained model by using this formula . in fig .",
    "[ fig5b ] we compare @xmath33 for @xmath136 , @xmath137 , and @xmath138 .",
    "the important result shown in this figure is that for @xmath126 the lower bound @xmath138 is close to the full chemical work @xmath137 . in this case , @xmath139 since @xmath140 , @xmath141 , and the affinity in ( [ coarw ] ) becomes @xmath108 .    in principle",
    ", the conformational change of the receptor could also involve atp consumption , which would lead to an internal process breaking detailed balance even without the external jumps @xcite . in this case",
    ", the entropy production of the full model would involve both energy consumed inside the cell and work done by the external process .",
    "in this section , we study a more complete model also including adaptation , where the free energy difference arising from conformational changes for the activity is taken from the coarse - grained model discussed in the previous section .      for adaptation , besides the kinase activity @xmath91 , the internal process must include the methylation level @xmath142 @xcite . as in the previous model , the activity @xmath91 takes the values @xmath88 if chea is inactive and @xmath89 if it is active .",
    "the average value of @xmath91 is assumed to be around @xmath76 , independent of @xmath82 . whereas @xmath91 quickly responds to a change in @xmath82 at a time - scale @xmath143 , the methylation level @xmath144 guarantees adaption by returning the average activity to @xmath76 at a time - scale @xmath145 .",
    "more specifically , a step decrease in @xmath82 leads to a fast increase in @xmath91 .",
    "this change in @xmath91 generates a slow decrease in the methylation level @xmath142 which acts back on the activity slowly decreasing it to @xmath76 .",
    "the free energy difference for the conformational change of the activity @xmath91 is obtained from the coarse - grained mwc model expression ( [ coarsefree ] ) .",
    "explicitly , @xmath146 where the free energy dependence on the methylation level is @xmath147 this choice for the free energy difference leads to @xmath148 . for simplicity , we assume @xmath149    two different chemical reactions control the methylation level . if @xmath88 , the receptor can be methylated with the reaction @xmath150_0+{\\rm sam } \\rightleftharpoons [ m+1]_0+{\\rm sah } ,   \\label{eq : demethylation}\\ ] ] where the subscript indicate the value of @xmath91 . here",
    "sam represents a s - adenosyl methionine molecule and sah represents a s - adenosyl - l - homocysteine molecule .",
    "the free energy difference of the reaction is @xmath151 . likewise ,",
    "if @xmath89 , the receptor can be demethylated with the reaction @xmath152_1+{\\rm h_2o } \\rightleftharpoons   [ m]_1+{\\rm ch_3oh } ,   \\label{eq : methylation}\\ ] ] for which the free energy difference is @xmath153 the chemical potential difference @xmath154 then drives the internal process out of equilibrium , corresponding to the affinity of the internal cycles shown in fig .",
    "[ fig6 ] , where our choice for the transition rates for the internal process is displayed .",
    "we note that if @xmath155 the internal process is in equilibrium . for @xmath156",
    "the system dissipates but there is no adaptation : @xmath142 increases @xmath91 instead of repressing it .",
    "adaptation happens only if @xmath71 overcomes the conformational free energy difference in a internal cycle @xmath157 .",
    "the variable @xmath158 defines the internal process , the external process @xmath1 is again the fluctuating concentration of external ligand , which jumps with rate @xmath55 between @xmath103 and @xmath104 .",
    "the full model thus has @xmath159 states , as shown in fig .",
    "[ fig6b ] . in general , its transition rates are denoted by @xmath160 and the stationary probability by @xmath161 .",
    "moreover , the internal probability current is @xmath162 and the marginal probability is @xmath163      using schnakenberg s network theory @xcite , the entropy production ( [ thermoent ] ) can be conveniently written as @xmath164 where @xmath165\\vardelta\\mu \\label{sigmamu}\\ ] ] corresponds to the consumption of sam inside the cell and @xmath166 \\label{sigmac}\\ ] ] is a lower bound on the chemical work done by the external process , as explained in the previous section .",
    "the term @xmath167 is related to the internal cycles in fig .",
    "[ fig6b ] . in principle",
    ", the full chemical work can only be obtained if we consider a process with @xmath168 states , for which the variable @xmath116 is not integrated out . however ,",
    "if there is time - scale separation ( @xmath116 faster than @xmath91 ) , we can adapt equation ( [ fullw ] ) to include methylation levels . for the present model ,",
    "the full work done by the external process then reads @xmath169 where , contrary to ( [ fullw ] ) , @xmath170 is now the marginal probability ( [ marg ] ) .",
    "furthermore , the learning rate ( [ learnrate ] ) , becomes @xmath171     +    numerical results for this model are shown in fig .",
    "[ fig7 ] . from the plot of the thermodynamic entropy production and the learning rate as a function of @xmath55 in fig .",
    "[ fig7a ] , we see that if the external process is very slow the dissipation inside the cell due to sam consumption @xmath167 is much larger than the learning rate .",
    "therefore , if the bacterium swims in an environment with @xmath172 , it will dissipate much more than it learns about the environment .",
    "the sam consumption rate is nearly independent of @xmath55 , being related to probability currents in the internal cycles as expressed in eq .",
    "( [ sigmamu ] ) , while @xmath173 grows with @xmath55 .",
    "the learning rate @xmath174 reaches a maximum , similar to the behavior observed with the toy model from sec .",
    "[ sec3 ] and the mwc model from sec .",
    "[ sec4 ] .    fig .",
    "[ fig7b ] demonstrates that the learning rate @xmath174 can be larger than the rate of sam consumption @xmath167 inside the cell since the work done by the external process also contributes to the cost of the learning rate .",
    "the internal dissipation @xmath167 grows with @xmath71 , while the learning rate @xmath174 saturates for high @xmath71 .    in adaptation",
    ", the fast variable @xmath91 learns about the changes in external concentration whereas the function of the slow variable @xmath142 is to appropriately regulate the conformational free energy difference @xmath175 .",
    "with such a perspective , it is more meaningful to look at the coarse - grained learning rate @xmath113 , which from ( [ learnratecg ] ) follows as @xmath176 the relation between the learning rates and the external concentration is plotted in fig .",
    "[ fig7c ] . the external concentration",
    "are fixed to @xmath124 and @xmath125 , with @xmath82 as free parameter .",
    "the learning rates @xmath174 and @xmath113 approach zero if @xmath82 increases ( decreases ) beyond @xmath93 ( @xmath92 ) . moreover , in fig .",
    "[ fig7c ] we see that the difference between @xmath173 and @xmath177 is small in the region @xmath126 .",
    "an interesting result is obtained in fig .",
    "[ fig7d ] where we compare @xmath113 with the coarse - grained learning rate obtained for the mwc model without adaptation plotted in fig .",
    "[ fig5a ] . for fixed @xmath90 ,",
    "i.e. , without adaptation , the maximal learning rate @xmath178 achieved at any given value of @xmath82 by fine - tuning @xmath90 represents the maximum the kinase dynamics can learn about the environment for given @xmath82 .",
    "as demonstrated in fig .",
    "[ fig7d ] , the learning rate @xmath113 for the model with adaptation is below @xmath178 . the advantage of adaptation , however , is that it increases the region at which @xmath113 is non - negligible ( see comparison between the blue solid and gray dotted curves in fig .",
    "[ fig7d ] ) , which is roughly @xmath179 .",
    "similarly , it has been found that adaptation maintains high sensitivity over a wide concentration range @xcite ( see @xcite for a different perspective ) .    a closely related study of the present model for _ _ e . coli adaptation has been recently performed by sartori et al .",
    "in contrast to our model , in their work the external concentration is suddenly changed from an initial to a final value with some preassigned probability .",
    "the mutual information between the internal system @xmath180 and the final concentration , which is related to measuring the final concentration , is analogous to our learning rate @xmath174 . in @xcite",
    "this mutual information is shown to increase with time , reaching its maximal value at a time of the order of the methylation time - scale .",
    "this is in agreement with our result that the learning rate is much smaller than the internal dissipation for @xmath181 : after a time of order @xmath182 the correlation with the external concentration is saturated but the cell keeps dissipating .",
    "for markov processes that can be decomposed into an external process unaffected by an internal process , as represented by the transition rates in eq .",
    "( [ defrates2 ] ) , we have defined an entropic rate that is bounded by the thermodynamic entropy production and that characterizes how much the internal process learns about the external process .",
    "this learning rate allows for the definition of an informational efficiency that , as demonstrated with three different models related to _ _",
    "coli sensory network , can be used to study the thermodynamics of cellular information processing .",
    "we have analyzed a simple toy model of an internal protein tracking an external concentration , for which the learning rate is bounded by the rate of atp consumption inside the cell .",
    "this thermodynamically consistent model allows for a comparison with molecular motors , where the learning rate plays the role of extracted mechanical work .    for an internal process corresponding to an equilibrium mwc model for a single _ _ e .",
    "coli receptor with no internal dissipation , we have shown that a nonzero learning rate is possible if work done by the external process accounts for it . in this model ,",
    "the work comes from the chemical potential difference of binding a ligand at concentration @xmath103 and unbinding it at another concentration @xmath104 .",
    "if the external medium changes much faster than the activity , the full learning rate is nonzero because the binding and unbinding process , which is assumed to be faster than activity changes , can also learn about the external environment .",
    "however , the learning rate of the activity alone goes to zero , as the activity can not track an environment much faster than its own time - scale .",
    "our framework has also been applied to a model including adaptation .",
    "we have shown that a bacterium in an external environment that changes at a time - scale much larger than the time - scale of the activity , dissipates through sam consumption at a rate much higher than the one of learning about the external environment , corresponding to a quite inefficient situation .",
    "in general , the rate of sam consumption does not bound the learning rate , which can increase due to work done by the external process . using a coarse - grained learning rate ,",
    "we have analyzed how much the activity alone learns about the external process .",
    "we have shown that adaptation increases the concentration range for which this learning rate is non - negligible .",
    "we have assumed the external process to be an external ligand concentration jumping between two values . however , the framework from sec . [ sec2 ] is also valid for more elaborate external processes .",
    "likewise , more complete internal processes that include further elements of the _ _ e .",
    "coli sensory network could be studied in the future .",
    "we expect features like the thermodynamic entropy production having one contribution due to energy dissipation inside the cell and another one due work done by the external process , the learning rate being much smaller than the internal dissipation if changes in the external medium are slow , and the learning rate not necessarily being bounded by the dissipation inside the cell to be relevant also for more complex models",
    ". finally , it would be worthwhile to explore the relation between the learning rate studied here and quantities characterizing further aspects of a sensory system , like adaptation error and sensitivity ."
  ],
  "abstract_text": [
    "<S> we show that a rate of conditional shannon entropy reduction , characterizing the learning of an internal process about an external process , is bounded by the thermodynamic entropy production . </S>",
    "<S> this approach allows for the definition of an informational efficiency that can be used to study cellular information processing . </S>",
    "<S> we analyze three models of increasing complexity inspired by the _ _ e . </S>",
    "<S> coli sensory network , where the external process is an external ligand concentration jumping between two values . </S>",
    "<S> we start with a simple model for which atp must be consumed so that a protein inside the cell can learn about the external concentration . with a second model for a single receptor </S>",
    "<S> we show that the rate at which the receptor learns about the external environment can be nonzero even without any dissipation inside the cell since chemical work done by the external process compensates for this learning rate . </S>",
    "<S> the third model is more complete , also containing adaptation . for this model </S>",
    "<S> we show _ _ inter alia that a bacterium in an environment that changes at a very slow time - scale is quite inefficient , dissipating much more than it learns . using the concept of a coarse - grained learning rate , we show for the model with adaptation that while the activity learns about the external signal the option of changing the methylation level increases the concentration range for which the learning rate is substantial . </S>"
  ]
}