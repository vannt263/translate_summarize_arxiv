{
  "article_text": [
    "model predictive control ( mpc ) for deterministic systems has received a considerable amount of attention over the last few decades , and significant advancements have been realized in terms of theoretical analysis as well as industrial applications .",
    "the motivation for such research thrust comes primarily from tractability of calculating optimal control laws for constrained systems .",
    "in contrast , the counterpart of this development for stochastic systems is still in its infancy .",
    "the deterministic setting is dominated by worst - case analysis relying on robust control methods .",
    "the central idea is to synthesize a controller based on the bounds of the noise such that a certain target set becomes invariant with respect to the closed - loop dynamics .",
    "however , such an approach usually leads to rather conservative controllers and to large infeasibility regions , and although disturbances are not likely to be unbounded in practice , assigning an a priori bound to them seems to demand considerable insight .",
    "a stochastic model of the disturbance is a natural alternative approach to this problem : the conservatism of the worst - case analysis may be circumvented , and one need not impose any a priori bounds on the maximum magnitude of the noise . however , since in practice control inputs are almost always bounded , it is of great importance to consider hard bounds on the control inputs as essential ingredients of the controller synthesis ; probabilistic constraints on the controllers naturally raise difficult questions on what actions to take when such constraints are violated ( see however  @xcite for one possible approach to answer these questions ) .",
    "in this paper we aim to provide answers to the following questions : given a linear system that is affected by ( possibly unbounded ) stochastic noise , to be controlled by applying predictive - type _ bounded _ control inputs , ( i ) is the associated optimization problem tractable ?",
    "( ii ) under what conditions is stability ( in a suitable stochastic sense ) of the closed - loop system guaranteed ?",
    "( iii ) is stability retained both in the case of mpc implementation and the case of rolling horizon control ( rhc ) implementation ?    in the deterministic setting , there exists a plethora of literature that settles tractability and stability of model - based predictive control , see , for example , @xcite and the references therein .",
    "however , there are fewer results in the stochastic case , some of which we outline next . in  @xcite",
    ", the authors reformulate the stochastic programming problem as a deterministic one with bounded noise and solve a robust optimization problem over a finite horizon , followed by estimating the performance when the noise can take unbounded values , i.e. , when the noise is unbounded , but takes high values with low probability ( as in the gaussian case ) . in  @xcite a slightly different problem is addressed in which the noise enters in a multiplicative manner into the system , and hard constraints on the state and control input are relaxed to probabilistic ones .",
    "similar relaxations of hard constraints to soft probabilistic ones have also appeared in  @xcite for both multiplicative and additive noise inputs , as well as in  @xcite .",
    "there are also other approaches , for example those employing randomized algorithms as in  @xcite .",
    "finally , a related line of research can be found in @xcite , and a novel convex analysis dealing with chance and integrated chance constraints can be found in @xcite .    in this paper",
    "we restrict attention to linear time - invariant controlled systems with affine stochastic disturbance inputs .",
    "our approach has three main features .",
    "firstly , for the finite - horizon optimal control subproblem we adopt a feedback control strategy that is affine in certain bounded nonlinear functions of the past noise inputs . secondly , instead of following the usual trend of adding element - wise constraints to the control input in the optimization , we propose a new approach that entails saturating the utilized noise measurements first and then optimizing over the feedback gains , ensuring that the hard constraints on the input will be satisfied by construction .",
    "this novel approach does not require artificially relaxing the hard constraints on the control input to soft probabilistic ones to ensure large feasible sets , and still provides a solution to the problem for a wide class of noise input distributions .",
    "in fact , we demonstrate that our strategy ( without state constraints ) leads to global feasibility .",
    "the effect of the noise appears in the finite - horizon optimal control problem as certain covariance matrices , and these matrices may be computed off - line and stored .",
    "thirdly , the measurement saturation functions are only required to be elementwise _ bounded _ in order to ensure tractability of the optimization problem while maintaining hard constraints on the control input ; therefore , these measurement saturation functions may be picked from among the wide class of saturation functions , the standard sigmoidal functions and their piecewise affine approximations , etc .",
    "once tractability of the finite - horizon underlying optimization problem is insured , it is possible to implement the resulting optimal solution using an mpc approach or an rhc approach . in the former case  @xcite ,",
    "the optimization problem is resolved at each step and only the first control input is implemented . in the latter case",
    "@xcite , the optimization problem is resolved every @xmath0 steps ( with @xmath0 being the horizon length ) and the entire sequence of @xmath0 input vectors is implemented . both of these approaches are shown to provide stability under the assumption that the zero - input and zero - noise system is asymptotically stable , which translates into the condition that the state matrix @xmath1 is schur stable . at a first glance",
    ", this assumption might seem restrictive .",
    "however , the problem of ensuring bounded variance of linear gaussian systems with bounded control inputs is , to our knowledge , still open , and here we are considering the problem of controlling a linear system with bounded control input and possibly unbounded noise .",
    "it is known that for discrete - time systems without any noise acting on the system it is possible to achieve global stability if and only if the matrix @xmath1 is neutrally stable  @xcite .",
    "this paper unfolds as follows . in ",
    "[ s : ps ] we state the main problem to be tackled with the underlying assumptions . in  [ s : if ] , we provide a tractable approach to the finite horizon optimization problem with hard constraints on the control input , as well as some examples in  [ sec : examples ] . stability of the mpc and rhc implementations is shown in  [ sec : stability ] , and hints onto the input - to - state stable properties of this result are provided in ",
    "[ sec : iss ] . finally , we provide a numerical example in  [",
    "sec : nexample ] and conclude in  [ sec : conclusions ] .",
    "hereafter , @xmath2 is the set of natural numbers , @xmath3 , and @xmath4 is the set of nonnegative real numbers .",
    "we let @xmath5 denote the indicator function of a set @xmath1 , and @xmath6 and @xmath7 denote the @xmath8-dimensional identity and zeros matrices , respectively .",
    "also , let @xmath9 $ ] denote the expected value given @xmath10 , and @xmath11 denote the trace of a matrix .",
    "for a given symmetric @xmath8-dimensional matrix @xmath12 with real entries , let @xmath13 be the set of eigenvalues of @xmath12 , and let @xmath14 and @xmath15 .",
    "let @xmath16 denote standard @xmath17 norm .",
    "finally , the mean and covariance matrix of any vector @xmath18 are denoted by @xmath19 and @xmath20 , respectively .",
    "consider the following general affine discrete - time stochastic dynamical model : @xmath21 where @xmath22 is the state , @xmath23 is the control input , @xmath24 is a stochastic noise input vector , @xmath1 , @xmath25 and @xmath26 are known matrices , and @xmath27 is a known constant vector .",
    "we assume that the initial condition @xmath28 is given and that , at any time @xmath29 , @xmath30 is observed exactly .",
    "we shall assume further that the noise vectors @xmath31 are i.i.d . and that the control input vector is bounded at each instant of time @xmath29 , i.e. , @xmath32 where @xmath33 is some given element - wise saturation bound .",
    "note that the model with constraints can handle a wide range of convex polytopic constraints .",
    "in particular , any system @xmath34 with input constraints @xmath35 that can be transformed to the form by an affine transformation @xmath36 is amenable to our approach by setting @xmath37 and @xmath38 in .",
    "note that the set @xmath39 need not necessarily be a hypercube , or even contain the origin . note also that we can assume that @xmath31 is zero mean in without loss of generality ; given a system of the form where @xmath40 is not zero mean , we can replace it by a system in the form with zero mean in which @xmath41\\ ] ] by setting @xmath42 $ ] .    fix a horizon @xmath43 and set @xmath44 .",
    "the _ mpc _ procedure can be described as follows .",
    "* determine an admissible optimal feedback control policy , say @xmath45 , for an @xmath0-stage cost function starting from time @xmath29 , given the ( measured ) initial condition @xmath30 ; * increase @xmath29 to @xmath46 , and go back to step ( a ) .    on the other hand , the _ rhc _ procedure simply replaces ( b ) above by    * apply the entire sequence @xmath47 of control inputs , update the state @xmath48 at the @xmath49-th step , increase @xmath29 to @xmath50 and go back to step ( a ) .",
    "accordingly , the @xmath29-th step of this procedure consists of minimizing the stopped @xmath0-period cost function starting at time @xmath29 , namely , the objective is to find a feedback control policy that attains @xmath51.\\label{e : rhcf}\\end{aligned}\\ ] ] since both the system and cost are time - invariant , it is enough to consider the problem of minimizing the cost for @xmath44 , i.e. , the problem of minimizing @xmath52 over @xmath53 .",
    "+ in view of the above we consider the problem @xmath54 , \\\\ \\textrm{s.t.}\\quad&\\mathrm{dynamics}\\,(\\ref{eq",
    ": system}),\\ , \\mathrm{and\\,\\ , constraints}\\,(\\ref{eq : bddu } ) \\end{aligned}\\ ] ] where @xmath55 and @xmath56 are some given symmetric matrices of appropriate dimension .",
    "if feasible with respect to , problem generates an optimal sequence of feedback control laws @xmath57 .",
    "the evolution of the system ( [ eq : system ] ) over a single optimization horizon @xmath0 can be described in compact form as follows : @xmath58 where @xmath59 } , \\ ,",
    "\\bar{w } : = \\begin{bmatrix } w_0 \\\\ w_1 \\\\ \\vdots \\\\ w_{n-1 } \\end{bmatrix},\\ ] ] @xmath60 @xmath61}}\\ ] ] where the input @xmath62 using the compact notation above , the optimization problem   can be rewritten as follows : @xmath63 , \\\\",
    "\\textrm{s.t.}\\quad & { \\rm dynamics}\\ , ( \\ref{eq : compactdyn}),\\ , \\mathrm{and\\,\\ , constraints}\\,(\\ref{eq : bddu2 } ) , \\\\ \\end{aligned}\\ ] ] where @xmath64},\\ , \\bar r={\\left[\\begin{matrix } r_0&\\hdots & \\mathbf 0_{m\\times m } \\\\ \\vdots & \\ddots & \\vdots\\\\   \\mathbf 0_{m\\times m } & \\hdots & r_{n-1 }   \\end{matrix}\\right]}.\\ ] ]    the solution to problem is difficult to obtain in general . in order to obtain an optimal solution to problem over the class of feedback policies , we need to solve the dynamic programming equations",
    "this generally requires using some gridding technique , making the problem extremely difficult to solve computationally .",
    "another approach is to restrict attention to a specific class of state feedback policies .",
    "this will result in a suboptimal solution to our problem , but may yield a tractable optimization problem .",
    "it is the track we pursue in the next section .",
    "by the hypothesis that the state is observed without error , one may reconstruct the noise sequence from the sequence of observed states and inputs by the formula @xmath65 in the light of this , and inspired by the works  @xcite , we shall consider feedback policies of the form : @xmath66 where the feedback gains @xmath67 and the affine terms @xmath68 must be chosen based on the control objective , while observing the constraints . with this definition ,",
    "the value of @xmath69 at time @xmath29 depends on the values of @xmath70 up to time @xmath71 . using  ( [ eq : noiserec ] )",
    "we see that @xmath72 is a function of the observed states up to time @xmath29 .",
    "it was shown in  @xcite that there exists a one - to - one ( nonlinear ) mapping between control policies in the form  ( [ eq : controlpolicy ] ) and the class of affine state feedback policies .",
    "that is , provided one is interested in affine state feedback policies , parametrization  ( [ eq : noiserec ] ) constitutes no loss of generality .",
    "of course , this choice is generally suboptimal , but it will ensure the tractability of a large class of optimal control problems . in compact notation ,",
    "the control sequence up to time @xmath73 is given by @xmath74 where @xmath75}{^\\mathsf{t}}$ ] , and @xmath76    since the elements of the noise vector @xmath77 are not assumed to be bounded , there can be no guarantee that the control input will meet the constraint .",
    "this is a problem in practical applications , and has traditionally been circumvented by assuming that the noise input lies within a compact set  @xcite , and designing a worst - case controller . in this article",
    "we propose to use the controller @xmath78 instead of ( [ eq : auginput ] ) , where @xmath79},\\ ] ] @xmath80 is a shorthand for the vector @xmath81{^\\mathsf{t}}$ ] , @xmath82 is the @xmath83-th row of the matrix @xmath26 , and @xmath84 is any function with @xmath85 . in other words ,",
    "we have chosen to saturate the measurements that we obtain from the noise input vector before inserting them into our control vector . this way we do not assume that the noise distribution is defined over a compact domain , which is an advantage over other approaches @xcite . moreover ,",
    "the choice of element - wise saturation functions @xmath86 is left open . as such , we can accommodate standard saturation , piecewise linear , and sigmoidal functions , to name a few .",
    "our choice of saturating the measurement from the noise vectors renders the optimization problem tractable as opposed to just calculating the whole input vector @xmath87 and then saturating it afterwards , which tends to an intractable optimization problem .",
    "note that the choices of control inputs in and are both _",
    "non markovian _ ; however , they differ in the fact that the former depends affinely on previous noise inputs @xmath77 , whereas the latter is a nonlinear feedback due to passing noise measurements through the function @xmath88 .",
    "[ p : main ] assume that @xmath89=0 $ ] , @xmath90 .",
    "then , problem   with the input   is a convex optimization problem , with respect to the decision variables @xmath91 , which is given by @xmath92 where @xmath93 is the @xmath94-th row of @xmath95 , @xmath96,\\cdots , \\bigr .",
    "\\\\ & \\qquad \\qquad \\bigl .",
    "\\ee\\bigl[\\varphi_{n-1}(fw_{n-1})\\varphi_{n-1}(fw_{n-1}){^\\mathsf{t}}\\bigr]\\bigr\\},\\\\    \\lambda_2 & = \\mathrm{diag}\\bigl\\{\\ee\\bigl[\\varphi_0(fw_0 ) w_0{^\\mathsf{t}}\\bigr],\\cdots,\\bigr . \\\\ & \\qquad \\qquad \\bigl.\\ee\\bigl[\\varphi_{n-1}(fw_{n-1})w_{n-1}{^\\mathsf{t}}\\bigr]\\bigr\\}.\\end{aligned}\\ ] ]    let us first consider the cost function in problem [ eq : problem1 ] . after substituting the system equations , we obtain @xmath97 = \\\\ & \\ee_{\\xz}[\\left(\\bar a x_0 + \\bar b \\bar u+\\bar d\\bar f\\bar w+\\bar r\\right){^\\mathsf{t}}\\bar q\\left(\\bar a x_0 + \\bar b \\bar u+\\bar d\\bar f\\bar w+\\bar r\\right){\\nonumber}\\\\ & \\qquad + \\bar u{^\\mathsf{t}}\\bar r\\bar u ] { \\nonumber}\\\\    & = ( \\bar a x_0+\\bar r){^\\mathsf{t}}\\bar q(\\bar a x_0+\\bar r ) + 2(\\bar a x_0+\\bar r){^\\mathsf{t}}\\bar q\\bar d \\bar f\\ee_{\\xz}\\bigl[\\bar w\\bigr]{\\nonumber}\\\\ & \\quad   + 2(\\bar a x_0+\\bar r){^\\mathsf{t}}\\bar q\\bar b \\ee_{\\xz}\\bigl[\\bar u\\bigr ]    + 2\\ee_{\\xz}\\bigl [ \\bar w{^\\mathsf{t}}\\bar f{^\\mathsf{t}}\\bar d{^\\mathsf{t}}\\bar q \\bar b\\bar u\\bigr ] { \\nonumber}\\\\    & \\quad + \\ee_{\\xz}\\bigl",
    "[ \\bar w { ^\\mathsf{t}}\\bar f{^\\mathsf{t}}\\bar d{^\\mathsf{t}}\\bar q\\bar d \\bar f\\bar w\\bigr ] + \\ee_{\\xz}\\bigl [ \\bar u{^\\mathsf{t}}(\\bar r+ \\bar b{^\\mathsf{t}}\\bar q \\bar b)\\bar u\\bigr].{\\nonumber}\\end{aligned}\\ ] ] note that since @xmath89=0 $ ] , we have that @xmath98=\\bar d$ ] . accordingly , using the definitions of @xmath99 , @xmath100 , @xmath101 , and @xmath102 , @xmath103    & = b{^\\mathsf{t}}\\bar d+{\\mathbf{tr}\\!\\left(m_2\\bar g\\lambda_2\\right ) }   + c { \\nonumber}\\\\ & \\quad + \\ee_{\\xz}\\bigl [ \\bar u{^\\mathsf{t}}m_1\\bar u\\bigr],\\label{eq : arg0}\\end{aligned}\\ ] ] where @xmath104 is a constant that we omit as it does not change the optimization problem , and we have used the following intermediate step @xmath105     = \\ee_{\\xz}\\bigl [ \\bar w{^\\mathsf{t}}\\bar f{^\\mathsf{t}}\\bar d{^\\mathsf{t}}\\bar q \\bar b(\\bar g\\bar \\varphi(\\bar f\\bar w)+\\bar d)\\bigr]\\\\ & \\qquad =   { \\mathbf{tr}\\!\\left(\\bar f{^\\mathsf{t}}\\bar d{^\\mathsf{t}}\\bar q\\bar b\\bar g\\lambda_2\\right)}+\\mu_{\\bar w}{^\\mathsf{t}}\\bar f{^\\mathsf{t}}\\bar d{^\\mathsf{t}}\\bar q \\bar b\\bar d.\\end{aligned}\\ ] ] using again the assumption that @xmath89=0 $ ] , we have that @xmath106 = \\ee_{\\xz}\\bigl[(\\bar{g}\\bar\\varphi(\\bar f\\bar{w})+\\bar{d}){^\\mathsf{t}}m_1(\\bar{g}\\bar\\varphi(\\bar f\\bar w)+\\bar{d})\\bigr ] { \\nonumber}\\\\     & = \\ee_{\\xz}\\bigl[\\bar\\varphi(\\bar f\\bar{w}){^\\mathsf{t}}\\bar g{^\\mathsf{t}}m_1\\bar g\\bar\\varphi(\\bar f\\bar{w})\\bigr]+\\bar d{^\\mathsf{t}}m_1\\bar d { \\nonumber}\\\\     & = { \\mathbf{tr}\\!\\left(\\bar g{^\\mathsf{t}}m_1\\bar g \\ee_{\\xz}\\bigl[\\bar\\varphi(\\bar f\\bar{w})\\bar\\varphi(\\bar f\\bar{w}){^\\mathsf{t}}\\bigr]\\right)}+\\bar d{^\\mathsf{t}}m_1\\bar d { \\nonumber}\\\\     & = { \\mathbf{tr}\\!\\left(\\bar g{^\\mathsf{t}}m_1\\bar g\\lambda_1\\right)}+\\bar d{^\\mathsf{t}}m_1\\bar d. \\label{eq : arg2}\\end{aligned}\\ ] ] finally , combining and , we obtain the cost in problem [ eq : problem2 ] , which is convex .",
    "let us look at the constraints in problem [ eq : problem1 ] .",
    "the proposed control input satisfies the hard constraints as long as the following condition is satisfied : @xmath107 , @xmath108 such that @xmath109 .",
    "this is equivalent to the following conditions : @xmath110 , @xmath111 , @xmath108 such that @xmath109 .",
    "as these conditions should hold for any permissible value of the function @xmath112 , we can eliminate the dependence of the constraints on @xmath112 through the following optimization problems @xmath113 .",
    "it is straightforward now to show , using h \" older s inequality @xcite , that @xmath114 , and the result follows .",
    "problem   is a quadratic program in the optimization parameters @xmath115  @xcite , and can be solved efficiently by standard solvers such as ` cvx `  @xcite .",
    "an important step in the solvability of problem is being able to calculate the matrices @xmath116 and @xmath102 .",
    "in general , these matrices can be calculated off - line by numerical integration . however , in some instances these matrices can be given in terms of explicit formulas ; two of these instances are given in the following examples .",
    "recall the following standard special mathematical functions : the _ standard error function _ @xmath117 and the _ complementary error function _",
    "@xcite defined by @xmath118 for @xmath119 , the _ incomplete gamma function _",
    "@xcite defined by @xmath120 for @xmath121 , the _ confluent hypergeometric function _",
    "@xcite defined by @xmath122 for @xmath123 and @xmath124 is the standard gamma function .",
    "we collect a few facts in the following    [ p : collect ] for @xmath125 we have    1 .",
    "@xmath126 ; 2 .",
    "@xmath127 + @xmath128 ; 3 .",
    "@xmath129 + @xmath130 ; 4 .",
    "@xmath131 ; 5 .",
    "@xmath132 .",
    "[ ex : sigmoids ] let us consider   with gaussian noise and sigmoidal bounds on the control input . more precisely ,",
    "suppose that the noise process @xmath133 is an independent and identically distributed ( i.i.d ) sequence of gaussian random vectors of mean @xmath134 and covariance @xmath135 .",
    "let the components of @xmath31 be mutually independent , which implies that @xmath135 is a diagonal matrix @xmath136 .",
    "suppose further that the matrix @xmath137 and that the function @xmath138 is a standard sigmoid , i.e. , @xmath139 .",
    "then from proposition  [ p : collect ] we have for @xmath140 and @xmath141 , @xmath142              & = 2\\cdot\\frac{1}{\\sqrt{2\\pi}\\sigma_i}\\int_{0}^\\infty \\frac{t^2}{1+t^2 } { \\mathrm e^{-\\frac{t^2}{2\\sigma_i^2}}}\\\\              & = \\sqrt{2\\pi}\\sigma_i - \\pi{\\mathrm e^{-\\frac{1}{2\\sigma_i^2}}}\\operatorname{erfc}\\bigl(\\frac{1}{\\sqrt 2\\sigma_i}\\bigr ) .",
    "\\end{aligned}\\ ] ] this shows that the matrix @xmath116 in proposition  [ p : main ] is equal to @xmath143 , where @xmath144 @xmath145 similarly , since @xmath146              & =   \\frac{2}{\\sqrt{2\\pi}\\sigma_i}\\int_{-\\infty}^\\infty \\frac{t^2}{\\sqrt{1+t^2 } } { \\mathrm e^{-\\frac{t^2}{2\\sigma_i } } } { \\mathrm}dt\\\\              & = \\frac{\\sigma_i}{\\sqrt 2}u\\bigl(\\frac{1}{2 } , 0 , \\frac{1}{2\\sigma_i^2}\\bigr ) ,          \\end{aligned}\\ ] ] the matrix @xmath102 in proposition  [ p : main ] is @xmath147 , where @xmath148 therefore , given the system  , the control policy  , and the description of the noise input as above , the matrices @xmath116 and @xmath102 derived above complete the set of hypotheses of proposition  [ p : main ] .",
    "the problem   can now be solved as a quadratic program  .",
    "note that we have chosen to use the standard sigmoidal functions in example [ ex : sigmoids ] .",
    "however , the result still holds for more general sigmoidal functions of the form @xmath149 , where @xmath150 is some given magnitude and @xmath151 is some given slope .",
    "this slight change is reflected in the entries of the matrices @xmath116 and @xmath102 , i.e. , for @xmath140 and @xmath141 , @xmath142 & = m\\left(\\sqrt{2\\pi}\\sigma_i\\alpha - \\pi{\\mathrm e^{-\\frac{1}{2\\sigma_i^2\\alpha^2}}}\\operatorname{erfc}\\left(\\frac{1}{\\sqrt 2\\sigma_i\\alpha}\\right)\\right ) ,          \\end{aligned}\\ ] ] and @xmath152   = m\\frac{\\sigma_i \\alpha}{\\sqrt 2}u\\bigl(\\frac{1}{2 } , 0 , \\frac{1}{2\\sigma_i^2\\alpha^2}\\bigr)$ ] .",
    "[ ex : saturation ] consider the system   as in example  [ ex : sigmoids ] , with @xmath138 being the standard saturation function defined as @xmath153 . from proposition",
    "[ p : main ] we have for @xmath140 and @xmath141 , @xmath154 = \\frac{1}{\\sqrt{2\\pi}\\sigma_i}\\int_{-\\infty}^\\infty \\varphi(t)^2 { \\mathrm e^{-\\frac{t^2}{2\\sigma_i^2 } } } { \\mathrm}dt\\\\              & = \\frac{2}{\\sqrt{2\\pi}\\sigma_i}\\int_0 ^ 1 t^2{\\mathrm e^{-\\frac{t^2}{2\\sigma_i^2 } } } { \\mathrm}dt + \\frac{2}{\\sqrt{2\\pi}\\sigma_i}\\int_1^\\infty { \\mathrm e^{-\\frac{t^2}{2\\sigma_i^2 } } } { \\mathrm}dt\\\\              & = \\sqrt{2\\pi}\\sigma_i^3\\operatorname{erf}\\bigl(\\frac{1}{\\sqrt 2\\sigma_i}\\bigr ) - 2\\sigma_i^2{\\mathrm e^{-\\frac{1}{2\\sigma_i^2 } } } + 1 + \\operatorname{erf}\\bigl(\\frac{1}{\\sqrt 2\\sigma_i}\\bigr )                      \\end{aligned}\\ ] ] and @xmath155 = \\frac{1}{\\sqrt{2\\pi}\\sigma_i}\\int_{-\\infty}^\\infty t \\varphi(t ) { \\mathrm e^{-\\frac{t^2}{2\\sigma_i^2 } } } { \\mathrm}dt\\\\              & = \\frac{2}{\\sqrt{2\\pi}\\sigma_i}\\int_0 ^ 1 t^2{\\mathrm e^{-\\frac{t^2}{2\\sigma_i^2 } } } { \\mathrm}dt + \\frac{2}{\\sqrt{2\\pi}\\sigma_i}\\int_1^\\infty t{\\mathrm e^{-\\frac{t^2}{2\\sigma_i^2 } } } { \\mathrm}dt\\\\              & = \\sqrt{2\\pi}\\sigma_i^3\\operatorname{erf}\\bigl(\\frac{1}{\\sqrt 2\\sigma_i}\\bigr ) - 2\\sigma_i^2{\\mathrm e^{-\\frac{1}{2\\sigma_i^2 } } } + \\sqrt{\\frac{2}{\\pi}}\\sigma_i\\gamma(2\\sigma_i^2 , 1 ) .",
    "\\end{aligned}\\ ] ] therefore , in this case the matrix @xmath116 in proposition  [ p : main ] is @xmath143 with @xmath156 , and the matrix @xmath102 is @xmath147 with @xmath157 . these information complete the set of hypotheses of proposition  [ p : main ] , and the problem   can now be solved as a quadratic program  .",
    "in this section , we assume that the matrix @xmath1 is schur stable , i.e. , @xmath158 , @xmath159 . accordingly , and since the control is bounded , it is intuitively evident that the closed - loop system is stable in some sense .",
    "indeed , we shall show that the variance of the state is uniformly bounded both in the mpc and rhc cases , the only difference being a choice of implementation based on available memory .",
    "first we need the following lemma .",
    "it is a standard variant of the foster - lyapunov condition  @xcite ; we include a proof here for completeness .",
    "the hypotheses of this lemma are stronger than usual , but are sufficient for our purposes ; see e.g. ,  @xcite for more general conditions .",
    "[ l : fl ] let @xmath160 be an @xmath161-valued markov process .",
    "let @xmath162 be a continuous positive definite and radially unbounded function , integrable with respect to the probability distribution function of @xmath70 .",
    "suppose that there exists a compact set @xmath163 and a number @xmath1640 , 1[$ ] such that @xmath165 { \\leqslant}\\lambda v(x),\\qquad \\forall x\\not\\in k.\\ ] ] then @xmath166 < \\infty$ ] .    from the conditions it follows immediately that @xmath167 { \\leqslant}\\lambda v(x ) + b{\\mathbf 1_{k}}(x ) , \\qquad { \\forall\\,}x\\in \\mathbb r^n\\ ] ] where @xmath168 $ ] .",
    "we then have @xmath169 & = \\ee_x\\bigl[\\ee\\bigl[v(x_{t})\\big|x_{t-1}\\bigr]\\bigr ] \\\\ & { \\leqslant}\\ee_x\\bigl[\\ee\\bigl[\\lambda v(x_{t-1 } ) + b{\\mathbf 1_{k}}(x_{t-1})\\bigr]\\bigr]{\\nonumber}\\\\              & { \\leqslant}\\lambda^t v(x ) + \\sum_{i=0}^{t-1}\\lambda^{t-1-i } b\\;\\ee_x\\bigl[{\\mathbf 1_{k}}(x_i)\\bigr]{\\nonumber}\\\\              & { \\leqslant}\\lambda^t v(x ) + \\frac{b(1-\\lambda^{t})}{1-\\lambda } ,          \\end{aligned}\\ ] ] which shows that @xmath170 { \\leqslant}v(x ) + b/(1-\\lambda ) < \\infty$ ] as claimed .",
    "we shall utilize lemma [ l : fl ] in order to show that the implementation of either the mpc or the rhc strategy generated by the solution of problem results in a uniformly bounded state variance .",
    "the mpc implementation corresponding to our input   and optimization program   consists of the following steps : given a fixed optimization horizon @xmath0 , set the initial time @xmath171 , calculate the optimal control gains @xmath172 using the program , apply the first optimal control input @xmath173 , increase @xmath29 to @xmath46 , and iterate .",
    "of course , the optimal gain depends implicity on the current given initial state , i.e. , @xmath174 , which in turn gives rise to a stationary infinite horizon optimal policy given by @xmath175 .",
    "the closed - loop system is thus given by @xmath176    [ prop : shmain ] assume that the matrix @xmath1 is schur stable and the assumptions of proposition [ p : main ] hold .",
    "then , under the control policy @xmath177 defined above , the closed loop system   satisfies @xmath178 < \\infty$ ] .    since by assumption the matrix @xmath1 is schur stable , there exists a positive definite and symmetric matrix with real entries , say @xmath179 , such that @xmath180 .",
    "using the system , at each time instant @xmath181 we have @xmath182 = \\\\ & \\ee_{x_t}\\bigl[(ax_t + b \\bar d^*_{0|t } + fw_t+r){^\\mathsf{t}}p(ax_t + b \\bar d^*_{0|t } + fw_t+r)\\bigr]\\\\                  & = x_t{^\\mathsf{t}}a{^\\mathsf{t}}p a x_t + 2 x_t{^\\mathsf{t}}a{^\\mathsf{t}}p(b\\bar d^*_{0|t}+f\\mu_{w_t}+r ) \\\\ & \\quad + \\bar d^{*\\mathsf t}_{0|t } b{^\\mathsf{t}}pb\\bar d^*_{0|t } + r{^\\mathsf{t}}p r + 2(f\\mu_{w_t}+r){^\\mathsf{t}}pb \\bar d^*_{0|t}\\\\ & \\quad   + 2r{^\\mathsf{t}}pf\\mu_{w_t } + { \\mathbf{tr}\\!\\left(f{^\\mathsf{t}}pf\\sigma_{w_t}\\right)}.          \\end{aligned}\\ ] ] using the fact that @xmath183 ( from  ) , we obtain the following bound @xmath184 & \\leq   x_t{^\\mathsf{t}}a{^\\mathsf{t}}p a x_t + 2c_1{\\left\\lvert{x_t}\\right\\rvert}_\\infty + c_2 ,          \\end{aligned}\\ ] ] where @xmath185 and @xmath186 . since @xmath187 , we have that @xmath188 \\leq x_t{^\\mathsf{t}}px_t - { \\left\\lvert{x_t}\\right\\rvert}^2 + 2c_1{\\left\\lvert{x_t}\\right\\rvert}_\\infty + c_2 .          \\end{aligned}\\ ] ] for @xmath189\\max\\{0,1-\\lambda_{\\max}(p)\\ } , 1[$ ] we know that @xmath190 where @xmath191 . from   it now follows that @xmath192 { \\leqslant}x_t{^\\mathsf{t}}p x_t - ( 1-\\theta){\\left\\lvert{x_t}\\right\\rvert}^2 , \\forall { \\left\\lvert{x_t}\\right\\rvert}_\\infty > r ,          $ ] whence @xmath193 { \\leqslant}\\bigl(1- \\frac{1-\\theta}{{\\lambda_{\\text{max}}(p)}}\\bigr)x_t{^\\mathsf{t}}px_t,\\,\\quad\\forall{\\left\\lvert{x_t}\\right\\rvert}_\\infty > r.\\ ] ] we see that the hypotheses of lemma  [ l : fl ] are satisfied with @xmath194 , @xmath195 , and @xmath196 . since @xmath197",
    ", it follows that @xmath198 { \\leqslant}\\frac{1}{\\lambda_{\\text{min}}(p)}\\sup\\limits_{t\\in\\nz}\\ee_{\\xz}\\bigl[v(x_t)\\bigr ] < \\infty,\\ ] ] which completes the proof .      in the rhc implementation",
    "is also iterative in nature , however instead of recalculating the gains at each time instant the optimization problem is solved every @xmath199 steps , where @xmath200 .",
    "the resulting optimal control policy ( applied over a horizon @xmath0 ) is given by @xmath201 , where again the control gains depend implicitly on the initial condition @xmath202 , i.e. , @xmath203 and @xmath204 .",
    "therefore , the optimal policy is given by @xmath205 .",
    "for @xmath206 , the resulting closed - loop system over horizon @xmath0 is given by @xmath207 where @xmath200 , and @xmath208 and @xmath209 are suitably defined matrices that are extracted from @xmath210 and @xmath211 , respectively .",
    "[ prop : rhmain ] assume that the matrix @xmath1 is schur stable and the assumptions of proposition [ p : main ] hold .",
    "then , under the control policy @xmath212 defined above , the closed loop system   satisfies @xmath178 < \\infty$ ] .    using and the fact that @xmath213=0 $ ] , @xmath214 , we have that @xmath215 @xmath216   =   x_{kn}{^\\mathsf{t}}(a^\\ell){^\\mathsf{t}}p_\\ell a^\\ell x_{kn}\\\\ & \\ , + 2x_{kn}{^\\mathsf{t}}(a^\\ell){^\\mathsf{t}}p_\\ell(\\bar b_\\ell \\bar d^*_{kn}+\\bar d_\\ell\\bar f\\mu_{\\bar w } + \\bar d_\\ell \\bar r)+\\bar r{^\\mathsf{t}}\\bar d_\\ell{^\\mathsf{t}}p_\\ell \\bar d_\\ell \\bar r\\\\&\\ , + ( \\bar d^*_{kn}){^\\mathsf{t}}\\bar b_\\ell{^\\mathsf{t}}p_\\ell \\bar b_\\ell \\bar d^*_{kn } + 2(\\bar d^*_{kn}){^\\mathsf{t}}\\bar b_\\ell{^\\mathsf{t}}p_\\ell\\bar d_\\ell(\\bar f\\mu_{\\bar w}+\\bar r)\\\\&\\ , + 2\\mu_{\\bar w}{^\\mathsf{t}}\\bar f{^\\mathsf{t}}\\bar d_\\ell{^\\mathsf{t}}p_\\ell\\bar d_\\ell\\bar r   + { \\mathbf{tr}\\!\\left((\\bar g^*_{kn}){^\\mathsf{t}}\\bar b_\\ell { ^\\mathsf{t}}p_\\ell \\bar b_\\ell \\bar g_{kn}^*\\lambda_1\\right)}\\\\          & \\ , + 2{\\mathbf{tr}\\!\\left((\\bar g^*_{kn}){^\\mathsf{t}}\\bar b_\\ell{^\\mathsf{t}}p_\\ell\\bar d_\\ell\\bar f\\lambda_2\\right ) } + { \\mathbf{tr}\\!\\left(\\bar f{^\\mathsf{t}}d_\\ell{^\\mathsf{t}}p_\\ell d_\\ell \\bar f \\sigma_{\\bar w}\\right)}.{\\nonumber}\\end{aligned}\\ ] ] using the fact that @xmath217 and @xmath218 ( from  ) , we obtain the following bound @xmath219 \\\\ & \\quad \\leq   x_{kn}{^\\mathsf{t}}(a^\\ell){^\\mathsf{t}}p_\\ell a^\\ell x_{kn } + 2 c_{1\\ell } { \\left\\lvert{x_{kn}}\\right\\rvert}_\\infty + c_{2\\ell } ,      \\end{aligned}\\ ] ] where @xmath220 and @xmath221 $ ] . again , since @xmath1 is a schur stable matrix ( and hence @xmath222 ) there exists a matrix @xmath223 with real valued entries that satisfies @xmath224 , and its eigenvalues are real .",
    "then we have @xmath225 .",
    "therefore , @xmath226 & \\leq x_{kn}{^\\mathsf{t}}p_\\ell x_{kn } - { \\left\\lvert{x_{kn}}\\right\\rvert}^2{\\nonumber}\\\\ & + 2 c_{1\\ell } { \\left\\lvert{x_{kn}}\\right\\rvert}_\\infty + c_{2\\ell}.\\label{e : stab11 }      \\end{aligned}\\ ] ] for @xmath227\\max\\{0,1-\\lambda_{\\max}(p_\\ell)\\ } , 1[$ ] we know that @xmath228 where @xmath229 . from   it now follows that @xmath230 { \\leqslant}x_{kn}{^\\mathsf{t}}p_\\ell x_{kn } - ( 1-\\theta_\\ell){\\left\\lvert{x_{kn}}\\right\\rvert}^2 , \\forall { \\left\\lvert{x_{kn}}\\right\\rvert}_\\infty > r_\\ell ,      $ ] whence @xmath231 { \\leqslant}\\lambda_\\ell x_{kn}{^\\mathsf{t}}p_\\ell x_{kn},\\ , \\forall { \\left\\lvert{x_{kn}}\\right\\rvert}_\\infty > r_\\ell ,      \\end{aligned}\\ ] ] where @xmath232 .",
    "define @xmath233 , @xmath234 , @xmath235 , @xmath236 , then we can obtain using   the conservative bound @xmath237 { \\leqslant}\\lambda ' x_{kn}{^\\mathsf{t}}p_nx_{kn},\\ , \\forall { \\left\\lvert{x_{kn}}\\right\\rvert}_\\infty > r'\\ ] ] for every @xmath238 , where @xmath239 , and the @xmath0-step bound @xmath240 & { \\leqslant}\\lambda_n x_{kn}{^\\mathsf{t}}p_nx_{kn},{\\nonumber}\\\\ & \\qquad   \\forall { \\left\\lvert{x_{kn}}\\right\\rvert}_\\infty > r_n.\\label{eqn : boundl23 }      \\end{aligned}\\ ] ] let @xmath241 .",
    "now , following the same reasoning as in lemma  [ l : fl ] , we can establish the following bound ( for @xmath200 , @xmath242 ) @xmath243=\\ee_{x}\\bigl[\\ee[v_n(x_{kn+\\ell})|x_{kn}]\\bigr]{\\nonumber}\\\\          & \\qquad\\leq \\ee_{x}\\bigl[\\ee[\\lambda'v_n(x_{kn})+b'{\\mathbf 1_{k'}}(x_{kn})]\\bigr]{\\nonumber}\\\\          & \\qquad \\leq \\ee_{x}\\bigl[\\ee[\\lambda'\\ee[v_n(x_{kn})|x_{(k-1)n}]+b'{\\mathbf 1_{k'}}(x_{kn})]\\bigr]{\\nonumber}\\\\          & \\qquad \\leq \\ee_{x}\\bigl[\\ee[\\lambda'\\ee[\\lambda_n v_n(x_{(k-1)n})+b{\\mathbf 1_{k_n}}(x_{(k-1)n})]{\\nonumber}\\\\ & \\qquad   \\quad + b'{\\mathbf 1_{k'}}(x_{kn})]\\bigr]{\\nonumber}\\\\          & \\qquad \\leq \\lambda'\\lambda_n^kv_n(x)+\\sum_{i=0}^{k-1}\\lambda_n^{k-1-i}b \\ee_{x}\\bigl[{\\mathbf 1_{k_n}}(x_{in})\\bigr]{\\nonumber}\\\\ & \\qquad \\quad + b'\\ee_x\\bigl[{\\mathbf 1_{k'}}(x_{kn})\\bigr]{\\nonumber}\\\\          & \\qquad \\leq \\lambda'\\lambda_n^kv_n(x)+\\frac{b(1-\\lambda_n^k)}{1-\\lambda_n}+b ' , \\label{eqn : finalbound }      \\end{aligned}\\ ] ] where @xmath244 $ ] , @xmath245 $ ] for @xmath246 , @xmath247 , and @xmath248 .",
    "note that the conditioning in the steps of   is done every @xmath0 steps as the problem is _ not markovian _ except then .",
    "therefore , it follows from   that , @xmath249 , @xmath250 &          \\leq \\frac{1}{\\lambda_{\\min}(p_n)}\\sup\\limits_{t\\in\\nz}\\ee_{x}\\bigl[v_n(x_{kn+l})\\bigr],{\\nonumber}\\\\          & \\hspace{-2cm}\\leq \\frac{1}{\\lambda_{\\min}(p_n)}\\left(\\lambda'\\lambda_n^kv_n(x)+\\frac{b}{1-\\lambda_n}+b'\\right)<\\infty      \\end{aligned}\\ ] ] which completes the proof .",
    "input - to - state stability ( iss ) is an interesting and important qualitative property of systems , dealing with input - output behavior . in the deterministic context",
    "@xcite it generalizes the well - known bounded input bounded output ( bibo ) property of linear systems  @xcite .",
    "iss provides a description of the behavior of a system subjected to bounded inputs .",
    "here we are interested in a stochastic variant of input - to - state stability ; see e.g. ,  @xcite for other possible definitions and ideas ( primarily in continuous - time ) .    one possible way to measure",
    "the strength of stochastic inputs is in terms of their covariances ; sometimes their moment generating functions are also employed . for gaussian noise",
    "it is customary to consider a suitable norm of the covariance matrix as a measure of its strength . the deterministic version of input - to - state stability deals with @xmath251-to-@xmath251 gain from the input to the state of a system .",
    "we consider the linear system  , and establish a natural iss - type property from the control and the noise inputs to the state of the system  , under both the mpc and the rhc strategies .",
    "the system   is _ input - to - state stable in @xmath252 _ if there exist functions @xmath253 and @xmath254 such that for every initial condition @xmath255 and @xmath256 we have @xmath257 { \\leqslant}\\beta({\\left\\lvert{\\xz}\\right\\rvert } , t ) + \\gamma_1\\bigl(\\sup_{s\\in\\nz}{\\left\\lvert{u_s}\\right\\rvert}_\\infty\\bigr ) + \\gamma_2\\bigl({\\left\\lvert{\\sigma}\\right\\rvert}'\\bigr),\\ ] ] where @xmath258 is an appropriate matrix norm .",
    "one difference with the deterministic definition of iss is immediately evident , namely , the presence of the function @xmath259 inside the expectation in  .",
    "it turns out that often it is more natural to arrive at an estimate of @xmath260 $ ] for some @xmath261 than an estimate of @xmath262 $ ] .",
    "moreover , in case @xmath259 is convex , jensen s inequality  @xcite shows that such an estimate implies an estimate of @xmath262 $ ] .",
    "the following proposition can be easily established with the aid of proposition  [ prop : shmain ] and proposition  [ prop : rhmain ] .",
    "the closed - loop systems   and   are input - to - state stable in @xmath252.@xmath263    the proof is omitted for space limitations .",
    "let us consider the system with some generic matrices @xmath264}$ ] , @xmath265}$ ] , @xmath266 , and @xmath267 .",
    "we simulate the system starting from @xmath268 different initial conditions , all of which are sampled according to a uniform distribution over @xmath269 ^ 3 $ ] .",
    "the noise inputs are independent and identically sampled according to a normal distribution , @xmath270 , the noise saturation function is chosen as in example [ ex : sigmoids ] with @xmath271 , and the input saturation bound @xmath272 .",
    "the optimization gain matrices are chosen to be @xmath273 and",
    "@xmath274 , @xmath275 , and the optimization horizon @xmath276 .",
    "the optimization matrices are given by @xmath277 , and @xmath278 .",
    "we used the ` cvx ` solver  @xcite to handle the optimization problem .",
    "the results for the mpc implementation are shown in figure [ fig : mpc ] , and those for the rhc implementation are shown in figure [ fig : rh ] , for the full state evolution over a horizon of 40 time steps .",
    "finally , it is interesting to note that the mpc and rhc _ average _ performance indices over the 50 different runs are given by 3985 and 4327 , respectively .",
    "in this paper , we provided a tractable optimization program that solves the stochastic model predictive control and rolling horizon control problems , while guaranteeing the satisfaction of hard bounds on the control input .",
    "we have showed that in both cases the resulting closed - loop process has bounded variance .",
    "we demonstrated that both implementations enjoy some qualitative notion of stochastic input - to - state stability .",
    "we provided several examples in which crucial matrices in our optimization program can be calculated off - line .",
    "future direction for this research is aimed at lifting the current feedback strategy onto general vector spaces .",
    "d.  chatterjee , e.  cinquemani , g.  chaloulos , and j.  lygeros , `` stochastic optimal control up to a hitting time : optimality and rolling - horizon implementation , '' 2008 .",
    "[ online ] .",
    "available : http://arxiv.org/abs/0806.3008                    f.  oldewurtel , c.  jones , and m.  morari , `` a tractable approximation of chance constrained stochastic mpc based on affine disturbance feedback , '' in _ conference on decision and control , cdc _ , cancun , mexico , dec .",
    "[ online ] .",
    "available : http://control.ee.ethz.ch / index.cgi?page = publications;action = details;id% = 3118[http://control.ee.ethz.ch / index.cgi?page = publications;action = details;id% = 3118 ]      m.  maciejowski , a.  lecchini , and j.  lygeros , `` nmpc for complex stochastic systems using markov chain monte carlo , '' in _ international workshop on assessment and future directions of nonlinear model predictive control _ , ser .",
    "lecture notes in control and information sciences , vol .",
    "1em plus 0.5em minus 0.4emstuttgart , germany : springer , 2005 , pp .",
    "269281 .    a.  a. stoorvogel , a.  saberi , and s.  weiland , `` on external semi - global stochastic stabilization of linear systems with input saturation , '' 2006 , submitted .",
    "[ online ] .",
    "available : http://homepage.mac.com/a.a.stoorvogel/subm03.pdf    m.  agarwal , e.  cinquemani , d.  chatterjee , and j.  lygeros , `` on convexity of stochastic optimization problems with constraints , '' in _",
    "european control conference _ , 2009 , submitted .",
    "[ online ] .",
    "available : http://control.ee.ethz.ch / index.cgi?page = publications;action = details;id% = 3271[http://control.ee.ethz.ch / index.cgi?page = publications;action = details;id% = 3271 ]                  m.  abramowitz and i.  a. stegun , _ handbook of mathematical functions with formulas , graphs , and mathematical tables _ , ser",
    ". national bureau of standards applied mathematics series.1em plus 0.5em minus 0.4emfor sale by the superintendent of documents , u.s .",
    "government printing office , washington , d.c . , 1964 ,",
    "vol .  55 .",
    "v.  s. borkar , `` uniform stability of controlled markov processes , '' in _ system theory : modeling , analysis and control ( cambridge , ma , 1999 ) _ , ser .",
    "kluwer international series in engineering computer science.1em plus 0.5em minus 0.4emboston , ma : kluwer academic publishers , 2000 , vol .",
    "107120 .",
    "j.  spiliotis and j.  tsinias , `` notions of exponential robust stochastic stability , iss and their lyapunov characterization , '' _ international journal of robust and nonlinear control _ , vol .  13 , no .  2 , pp .",
    "173187 , 2003 .",
    "r.  m. dudley , _ real analysis and probability _ , ser .",
    "cambridge studies in advanced mathematics.1em plus 0.5em minus 0.4emcambridge : cambridge university press , 2002 , vol .",
    "74 , revised reprint of the 1989 original ."
  ],
  "abstract_text": [
    "<S> this paper is concerned with the problem of model predictive control and rolling horizon control of discrete - time systems subject to possibly unbounded random noise inputs , while satisfying hard bounds on the control inputs . </S>",
    "<S> we use a nonlinear feedback policy with respect to noise measurements and show that the resulting mathematical program has a tractable convex solution in both cases . </S>",
    "<S> moreover , under the assumption that the zero - input and zero - noise system is asymptotically stable , we show that the variance of the state , under the resulting model predictive control and rolling horizon control policies , is bounded . </S>",
    "<S> finally , we provide some numerical examples on how certain matrices in the underlying mathematical program can be calculated off - line . </S>"
  ]
}