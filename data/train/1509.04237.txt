{
  "article_text": [
    "this paper presents a fractional - order derivative based regularizer for variational image restoration .",
    "it may be used for other imaging models such as image registration . denote an observed image by @xmath1 , @xmath2 where @xmath3 is the bounded domain of the image with @xmath4 space dimension and has a lipschitz boundary . here",
    "we consider @xmath5 and mainly the image denoising problem with an additive noise i.e. assume @xmath6 with @xmath7 representing some unknown gaussian noise of mean zero and deviation @xmath8 , but most results are applicable to @xmath9 and other noise models .      restoring the unknown @xmath10 ( without any restrictions ) from @xmath11 is an inverse problem .",
    "according to the maximum likelihood principle @xcite , most image processing problems involve solving the least - square problem @xmath12 measuring the fidelity to @xmath11 .",
    "for example , @xmath13 for image denoising , @xmath14 takes the template image @xmath15 ( and @xmath16 for a reference image ) for image registration , and @xmath17 for image inpainting with @xmath18 the subdomain with missing data .",
    "the problem ( [ eq1.1 ] ) is in general ill - posed due to non - uniqueness , therefore how to effectively solve it becomes a fundamental task in image sciences .",
    "the most popular idea is to regularize it so that the resulting well - posed problem admits an unique solution .",
    "the classical regularization technique by tikhonov et .",
    "al @xcite is to add a smoothing regularization term into the energy functional to derive the following minimization problem @xmath19[eq1.2 ] where @xmath20 is a positive constant .",
    "this model can not preserve image edges , though it is simple to use . the total variation ( tv ) model by rudin - osher - fatemi @xcite or the rof model @xmath21[eq1.3 ]",
    "is widely used , where @xmath8 is an estimate of the error @xmath7 between the noisy image @xmath11 and the true data @xmath10 .",
    "the rof model preserves the image edges by seeking solutions of piecewise constant functions in the space of bounded variation functions ( bv ) .",
    "a variety of methods based on the tv regularization have been developed to deal with the imaging problems such as image restoration @xcite , image registration @xcite , image decomposition @xcite , image inpainting @xcite and image segmentation @xcite . restoring smooth images in some applications where edges are not the main features presents difficulties for the rof model as it can yield the so - called blocky ( staircase ) effects .",
    "another disadvantage of the model is to the loss of image contrasts @xcite .",
    "it should be remarked that the recently popular method by the iterative regularization technique @xcite can reduce the staircasing effect and improve on the image contrast to some extent ; besides it provides a fast implementation .      to remedy the",
    "above mentioned two drawbacks ( stairicasing and contrast ) , two types of alternative regularizer to the tv have been proposed in the literature .",
    "the first type introduces higher order regularization into image variational models @xcite .",
    "the mean curvature - based variation denoising model was studied in @xcite where the regularized solution @xmath10 is obtained by solving the fourth - order euler - lagrangian equation .",
    "bredies et al .",
    "@xcite proposed the total generalized variation regularizer involving a linear combination of higher - order derivatives and the tv of @xmath10 to model the image denoising while chang et al .",
    "@xcite considered a nonlinear combination of regularizer based on first and second order derivatives . for image inpainting , a high order regularization based on euler s elastica of @xmath10 is used in @xcite .",
    "similarly the euler s elastica energy @xcite and mean curvature @xcite are also proposed to transform the template image @xmath22 to map the reference image @xmath23 in image registration ; see also @xcite .",
    "the above mentioned high order regularization methods are effective but due to high nonlinearity efficient numerical solution is a major issue .",
    "the second type introduces fractional - order derivatives , which are widely studied in other research subjects beyond image processing @xcite , into regularization of images .",
    "for example , bai and feng @xcite introduced first fractional - order derivative into anisotropic diffusion equations for noise removal @xmath24 where @xmath25 denotes the divergence parameter and @xmath26 denotes the adjoint operator of @xmath27 , which may be viewed as a generalization of the perona - malik model .",
    "although the above equation can be related to the euler - lagrange equations of an energy functional with the fractional derivative of the image intensity , generalizing commonly used pde models , the energy minimization models are not studied as such . the discrete fourier transform is used to implement the numerical algorithm assuming a periodic input image at its borders @xcite .",
    "see also @xcite for more motivations and studies based on the above diffusion equation .",
    "chen et al .",
    "@xcite considered the fractional - order tv-@xmath28 image denoising model @xmath29 and numerically obtained improved denoising results over the perona - malik and rof models ; however no analysis was given .",
    "there , they converted this primal formulation into a dual problem for the new dual variable @xmath30 by @xmath31 and used a dual algorithm using the gradient descent idea similar to the chambolle method @xcite for the rof .",
    "in @xcite , the authors proposed a _",
    "discrete _ optimization framework for image denoising problem where the fractional order derivative is used to model the regularization term , @xmath32|^2,\\;1\\leq\\alpha\\leq 2,0\\leq s_j\\leq 1\\big\\},\\ ] ] which is solved by an alternating projection algorithm .",
    "see also @xcite .",
    "these works have reflected good performance of the fractional order derivative in achieving a satisfactory compromise such as no stair - casing and in preserving important fine - scale features such as edges and textures .",
    "these encouraging results motivated us to investigate this new model more closely .",
    "there have been several other works involving discrete forms of an @xmath0-order derivative proposed to tackle image registration problem @xcite and image inpainting problem @xcite .",
    "comparing with the first type of high order models @xcite , a fractional order model ( type two ) is less nonlinear and hence is more amenable to developing fast iterative solvers .",
    "clearly there is strong evidence to suggest that fractional order derivatives may be effective regularizer for imaging applications .",
    "there is an urgent need to establish a rigorous theory for the total @xmath0-order variation based variational model so that further applications to image inverse problems can be considered in a systematic way .",
    "this work is substantially different from previous studies .",
    "we mainly focus on the continuous total @xmath0 variation - based model , instead of discrete formulation , and its analysis and associated numerical algorithms .",
    "our contributions are four - fold :    * we analyze properties of the total @xmath0-order variation laying foundations for applications to image inverse problems as a regulariser ; * we give a new method for treating non - zero dirichlet boundary conditions which represents a generalization of similar results that existed only in 1d to 2d ; * we establish the convexity , the solvability and a solution theory for the total @xmath0-order variation model to make it more advantageous to work with than high order and non - convex counterparts ( such as a mean curvature based model ) which are not gradient based and do not have much known theory on their solutions ; * we propose and test four solution algorithms ( respectively split - bregman based , forward - backward algorithm , nesterov accelerated method and fast iterative shrinkage - thresholding algorithm ",
    "fista ) to solve the underlying total @xmath0-order variation model .",
    "we also compare with related models .",
    "our work is hoped to motivate further studies and facilitate future applications of @xmath0-order variation based regularizer to other imaging problems in the community .",
    "the rest of the paper is organized as follows .",
    "section 2 reviews the definitions and basic properties of the fractional order derivative .",
    "section 3 first defines the total @xmath0-order variation and the space of functions of fractional - order bounded variations . in this space",
    ", it then analyzes the the existence and the uniqueness of the solution of the total @xmath0-order variation based model for denoising . in section 4 , a boundary condition regularization method for treating nonzero dirichlet boundary conditions is proposed to effectively employ and compute the fractional order derivatives of an image .",
    "section 5 first discusses the discretization of the fractional order derivatives by a finite difference method and presents a split - bregman scheme for effective solution .",
    "section 6 takes the alternative discretise - optimize solution approach and develops three optimization - based algorithms ( forward - backward algorithm , nesterov accelerated method and fista ) to solve the image denoising model .",
    "experimental results are shown in section 7 , and the paper is concluded with a summary in section 8 .",
    "this section reviews definitions and simple properties of a fractional order derivative which has a long history and may be considered as a generalization of the integer order derivatives .",
    "three popular definitions to be reviewed are the riemann - liouville ( r - l ) , the grnwald - letnikov ( g - l ) and the caputo definitions @xcite .    in this paper , a fraction @xmath33 is assumed to lie in between two integers @xmath34 i.e. @xmath35 and a fractional @xmath0-order differentiation at point @xmath36 is denoted by the differential operator @xmath37}^\\alpha$ ] , where @xmath38 and @xmath39 are the bounds of the integral over a 1d computational domain .",
    "undoubtedly , the gamma function is very important for the study of fractional derivative , which is defined by the integral @xcite @xmath40 one of the basic properties is that @xmath41 and hence @xmath42 . before introducing formal definitions ,",
    "we review the following informative but classical example :    the abel s integral equation , with , @xmath43 has the solution given by the well - known formula @xmath44    this example helps to understand the formal definitions of fractional derivatives .",
    "in fact for @xmath45 , equation ( [ example1 - 1 ] ) taking on the form @xmath46}\\psi(x):=d^{-\\alpha}_{[0,x]}\\psi(x)=f(x)$ ] is called the fractional @xmath0-order left r - l * integral * of @xmath47 , and equation ( [ example1 - 2 ] ) taking on the form @xmath48}f(x)=\\psi(x)$ ] is defined as the fractional @xmath0-order left r - l * derivative * of @xmath49 . as operators , under suitable conditions @xcite , we have @xmath50}d^{\\alpha}_{[0,x]}=i$ ] where @xmath51 denotes the identity operator .    the first definition of a general order @xmath0 derivative is the left sided r - l derivative @xmath52}f(x)=\\frac{1}{\\gamma(n-\\alpha ) } \\left(\\frac{d}{dx}\\right)^n \\int^x_a\\frac{f(\\tau)d\\tau}{(x-\\tau)^{\\alpha - n+1}}.\\ ] ] subsequently the right - sided r - l and the riesz - r - l ( central ) fractional derivative are respectively given by @xmath53}f(x)=\\frac{(-1)^n}{\\gamma(n-\\alpha)}\\left(\\frac{d}{dx}\\right)^n \\int^b_x\\frac{f(\\tau)d\\tau}{(\\tau - x)^{\\alpha - n+1}}\\ ] ] and@xmath54}f(x)=\\frac{1}{2}\\left(d^\\alpha_{[a , x]}f(x)+(-1)^nd^\\alpha_{[x , b]}f(x)\\right).\\ ] ] the second definition is the g - l left - sided derivative denoted by @xmath55}f(x)=\\lim\\limits_{h\\rightarrow 0}\\frac{1}{h^\\alpha}\\sum_{j=0}^{[\\frac{x - a}{h}]}(-1)^j\\bigg(\\begin{array}{c}\\alpha \\\\ j \\\\ \\end{array}\\bigg ) f(x - jh),\\;\\;\\;\\bigg(\\begin{array}{c}\\alpha \\\\ j \\\\ \\end{array}\\bigg)=\\frac{\\alpha(\\alpha-1)\\dots(\\alpha - j+1)}{j!},\\ ] ] which resembles the definition for an integer order derivative , where @xmath56 $ ] is the integer such that @xmath57\\leq \\vartheta$ ] .",
    "the third definition is the caputo order @xmath0 derivative defined by @xmath58}f(x)=\\frac{1}{\\gamma(n-\\alpha ) }    \\int^x_a\\frac{f^{(n)}(\\tau)d\\tau}{(x-\\tau)^{\\alpha - n+1}}.\\ ] ] where @xmath59 denotes the @xmath60-order derivative of function @xmath49 .",
    "the right sided derivative and the riesz - caputo fractional derivative are similarly defined by @xmath61}f(x)=\\frac{(-1)^n}{\\gamma(n-\\alpha ) } \\int^b_x\\frac{f^{(n)}(\\tau)d\\tau}{(\\tau - x)^{\\alpha - n+1}},\\quad { } ^{c}d^\\alpha_{[a , b]}f(x)=\\frac{1}{2}\\left({}^{c}d^\\alpha_{[a , x]}f(x ) + ( -1)^n{}^{c}d^\\alpha_{[x , b]}f(x)\\right).\\ ] ] when @xmath62 is an integer , the above left - sided r - l definition reduces to the usual definition for a derivative .",
    "one notes that when a function is @xmath63 times continuously differentiable and its @xmath64th derivative is integrable , the fractional derivatives by the above definitions are equivalent subject to homogeneous boundary conditions @xcite .",
    "however we do not require such equivalence for our image function @xmath10 ; refer to remark [ rem2 ] later .",
    "fractional derivatives have many interesting properties  below we review a few that are useful to this work .    *",
    "linearity*. for a fractional derivative @xmath65}$ ] by any of the above three definitions , then one has @xmath52}(p\\ ; f(x)+q\\ ; g(x))=p\\ ; d^\\alpha_{[a , x]}f(x)+q\\ ; d^\\alpha_{[a , x]}g(x),\\ ] ] for any fractional differentiable functions @xmath66 and @xmath67 .",
    "this property will be shortly used to prove convexity and to derive the first order optimal conditions .",
    "* zero fractional derivatives*. an integer derivative of an image @xmath10 at pixels of flat regions may be close to zero but the left r - l derivative of a constant intensity function is not zero .",
    "one advantage of minimizing a r - l derivative instead of the total variation ( image gradients ) could be a non - constant solution",
    ". it would be interesting to know the kind of functions that have zero @xmath0-order derivatives .",
    "[ lemma_sigularity ] assume that @xmath65}$ ] is one of the above three fractional - order derivative operators .",
    "for any non - integer @xmath68 and @xmath69 , there exists a non - constant value function @xmath70 in @xmath71 $ ] such that @xmath65 } f(x)=0.$ ]    [ riemann - liouvilledefinition ] we give explicit constructions .",
    "here we only consider the r - l and caputo derivatives ; for g - l derivative , we can derive a similar conclusion through their equivalency .    1 .",
    "assume that @xmath45 , for some @xmath72 , if @xmath70 is taken as @xmath73 for any @xmath74 $ ] in abel s inverse transform ( [ example1 - 2 ] ) , then @xmath75 } f(x)=\\psi(x)=0 $ ] ; 2 .",
    "assume that @xmath76 , if @xmath70 is taken as @xmath77 for any @xmath78 $ ] in @xmath0-order r - l derivative , then @xmath65 } f(x)=0 $ ] ; 3 .",
    "assume that @xmath68 in caputo derivative definition , if @xmath70 is taken as @xmath79 for any @xmath78 $ ] in equation ( [ caputo ] ) , then @xmath80 } f(x)=0.$ ]    actually for any @xmath68 , the left r - l @xmath81}^\\alpha f(x)=0 $ ] if @xmath82 for all @xmath83 ( note @xmath84=n-1 $ ] ) ; refer to @xcite .    for our later applications ",
    "[ sec_num ] , we take @xmath85 .",
    "hence we have the left r - l @xmath81}^\\alpha f(x)=0 $ ] if @xmath86 or @xmath87 i.e. @xmath88 or @xmath89 when @xmath90 . for the caputo derivative , @xmath91}^\\alpha",
    "f(x)=0 $ ] if @xmath92 or @xmath39 .",
    "* boundary conditions*. for the left r - l derivative @xmath65}f(x)$ ] of @xmath49 , one assumes that @xmath93 or @xmath94 for the right r - l derivative ; otherwise there is a singularity at the end point .",
    "so the riesz r - l derivative would require @xmath95 .",
    "one solution for nonzero dirichlet boundary conditions for @xmath96 would be to extract off a linear approximation @xmath97 ( that coincides with @xmath96 at @xmath98 ) and to consider @xmath65}(f(x)-g(x))$ ] ; however there was no such a method for the 2d case . in jumarie",
    "s work @xcite , a simple alternative is to modify the r - l derivative to the following @xmath52}f(x)=\\frac{1}{\\gamma(n-\\alpha ) } \\left(\\frac{d}{dx}\\right)^n\\int^x_a\\frac{f(\\tau)-f(a ) } { ( x-\\tau)^{\\alpha - n+1}}d\\tau,\\ ] ] also ensuring that the new fractional derivative of a constant is equal to zero and removing the singularity at @xmath99 @xcite . in section [ sec_bndy ] ,",
    "we present one method for treating nonzero dirichlet boundary conditions in 2d .",
    "this section first studies the properties of the total @xmath0-order variation , second analyzes a total @xmath0-order variation based denoising model and finally presents a numerical algorithm . for the classical total variation based model ,",
    "its solution lies in a suitable space called the function space @xmath100 of bounded variation @xcite . from tests ,",
    "the total fractional - order variation model can preserve both edges and smoothness of an image ; we anticipate from the former that its solution should lie in a space similar to the bv space and from the latter that the smoothness is due to the non - local nature of the new regulariser .",
    "it turns out that for total @xmath0-order variation using @xmath0-order derivatives , a suitable space is the space @xmath101 of functions of @xmath0-bounded variation on @xmath3 which will be defined and studied next .",
    "the work of this section is motivated by analysis of the total variation ( tv ) @xcite and of the total generalized variation ( tgv ) @xcite",
    ".    in variational regularization methods , integration by parts involves the space of test functions in addition to the main solution space . before discussing the total @xmath0-order variation , we give the following definition :    let @xmath102 denote the space of @xmath103-order continuously differentiable functions . furthermore for any @xmath104 ,",
    "if the @xmath105 order derivative @xmath106 is integrable and @xmath107 for all @xmath108 , @xmath109 is compactly supported continuous - integrable function in @xmath3 .",
    "therefore the @xmath103-compactly supported continuous - integrable function space is denoted by @xmath110 .",
    "[ definition3.2 ] let @xmath111 denote the space of special test functions @xmath112 where @xmath113 .",
    "then the total @xmath0-order variation of @xmath10 is defined by @xmath114 where @xmath115 and @xmath116 denotes a fractional @xmath0-order derivative @xmath117}\\phi_i$ ] of @xmath118 along @xmath119 direction .",
    "we note that @xmath120 is the same for any definition of @xmath116 because @xmath121 satisfies the equivalence conditions .",
    "however for our applications in the paper , @xmath122 is generally not the same for different fractional derivatives ( not even in the distributional sense ) .",
    "based on the @xmath0-bv semi - norm , the @xmath0-bv norm is defined by @xmath123 and further the space of functions of @xmath0-bounded variation on @xmath3 can be defined by @xmath124    [ lemma3 - 2 ] let @xmath125 be a sequence from @xmath101 which converge in @xmath126 to a function @xmath127 . then @xmath128    since @xmath129 , for any @xmath130 such that @xmath131 on @xmath3 , then @xmath132 is bounded , hence @xmath133 from @xmath134 in @xmath126 .",
    "taking @xmath135 in the above inequality , we have lower semi - continuity from @xmath136 ( _ see _ @xcite for tv case ) .",
    "[ lemma3 - 3 ] the space @xmath101 is a banach space .    first we can see that @xmath101 is a normed space following immediately from the definitions of @xmath137 and total @xmath0-order variation @xmath120 , so it only remains to prove completeness .",
    "suppose @xmath138 is a cauchy sequence in @xmath101 ; then , by the definition of the norm , it must also be a cauchy sequence in @xmath126 . according to the completeness of @xmath126",
    ", there exists a function @xmath10 in @xmath126 such that @xmath139 in @xmath126 .",
    "since @xmath138 is a cauchy sequence in @xmath101 , @xmath140 is bounded .",
    "thus @xmath141 is bounded as @xmath142 , by the lower semi - continuity of @xmath120 in @xmath101 space ( _ see _ lemma [ lemma3 - 2 ] ) , one shows that @xmath143 .    we shall show that @xmath139 in @xmath101 .",
    "we know that for any @xmath144 there exists a positive integer @xmath145 such that @xmath146 for any @xmath147 , hence one has @xmath148 . since @xmath139 in @xmath126 , thus @xmath149 in @xmath126 . hence by lemma [ lemma3 - 2 ] , @xmath150 which shows that @xmath139 in @xmath101",
    ", therefore @xmath101 is a banach space .",
    "[ rem2 ] in the literature @xcite , the equivalence of different fractional derivatives requires stringent continuity conditions e.g. one has @xmath151}\\eta(x)=d^\\alpha_{[a , b]}\\eta(x)$ ] in the test space @xmath152,\\mathbb{r})$ ] .",
    "however for imaging applications ( the objective function @xmath10 ) , we do not require such equivalence .    to distinguish the two definitions",
    ", we shall continue using the superscript @xmath153 for @xmath153 derivatives based quantities such as @xmath154 and @xmath155 while no superscript means that a quantity is based on the r - l derivative .    for",
    "any positive integer @xmath156 , let @xmath157 be a function space embedding with the norm @xmath158    for any @xmath159)$ ] and @xmath160,\\mathbb{r})$ ]",
    "@xmath161}\\eta(x)dx\\\\ = & ( -1)^n\\int_a^b\\eta(x)\\cdot d^\\alpha_{[a",
    ", b]}\\xi(x)dx\\   + \\sum_{j=0}^{n-1}(-1)^jd^{\\alpha - n+j}_{[a , b]}\\xi(x)\\frac{\\partial^{n - j-1}\\eta(x)}{\\partial x^{n - j-1}}\\big|_{x = a}^{x = b}\\\\ = & ( -1)^n\\int_a^b\\eta(x)\\cdot d^\\alpha_{[a , b]}\\xi(x)dx \\end{split}\\ ] ] gives the @xmath0-order integration by parts formula ( _ see _ @xcite ) .",
    "furthermore , applying ( [ part_integral ] ) twice , we have shown the relationship @xmath162 where @xmath163 and @xmath130 ; clearly the operator @xmath164 is the adjoint of operator @xmath165 .",
    "note that , for @xmath130 , we have @xmath166 which may not be true if @xmath167 is in a different space .",
    "[ proposition_regularization_term ] assume that @xmath168 , then @xmath169 .",
    "for any @xmath68 , using the dual relationship ( [ fractional_dual ] ) , one can obtain that @xmath170 and in addition @xmath171 in @xmath111 implies that @xmath172 can maximize the functional @xmath173 . by multiplying @xmath174 by a suitable characteristic @xmath103-compactly",
    "supported continuous function @xmath175 in @xmath3 ( e.g. , @xmath176 ) and then mollifying ( _ see _ @xcite for tv and @xcite ) , the new @xmath177 with @xmath178 is arbitrarily close to @xmath179 as @xmath180 @xcite , hence one shows that @xmath169 by taking @xmath181 .",
    "[ rem1 ] since @xmath168 leads to @xmath169 , in fact , it is easy to show that the lower semi - continuity @xmath182 holds in the space @xmath183 similar to the tv case @xcite ) .",
    "the space @xmath184 is a banach space .",
    "the @xmath185 case is clear .",
    "now for @xmath186 , let @xmath187 satisfy @xmath188 . to obtain the lower semi - continuity , taking @xmath189 and @xmath190 , the following inequality @xmath191 holds ; further one has @xmath192",
    ". then we can deduce the result , following the similar lines to proving lemma [ lemma3 - 3 ] .",
    "the following embedding results hold : @xmath193    firstly , from the definitions of @xmath194 and @xmath195 , we can see that @xmath196 and @xmath197 . secondly , for any @xmath198 and @xmath199 , we have @xmath200 i.e. , @xmath201 or @xmath202",
    ". finally @xmath203 follows @xmath204 .",
    "[ lemma3.4 ] the functional @xmath120 is convex .",
    "the proof follows the linearity of fractional order derivatives , and the positively homogeneous and sub - additive properties of @xmath120 .",
    "[ section4 ] * theory for a total @xmath0-order variation model*. we are now ready to analyze model ( [ tv_alpha ] ) or the total @xmath0-order variation model in a more precise form @xmath205 to focus on the total @xmath0-order variation model in @xmath206 , we assume @xmath207 ; the following theorem establishes convexity of the minimization problem ( [ reg - problem1 ] ) .",
    "[ theorem_convexity ] the functional @xmath208 in @xmath209 is convex for @xmath210 and strictly convex if @xmath211 .",
    "since @xmath212 is a strictly convex functional , the proof follows from lemma [ lemma3.4 ] .",
    "if a banach space @xmath213 is reflexive ( separable ) , then every bounded sequence in @xmath213 ( in @xmath214 ) has a weakly ( @xmath215 ) convergent subsequence ( * ? ? ?",
    "38.2 ) . although @xmath101 is not reflexive , however , it is the dual of a separable space",
    ". therefore we can give the following definition :    [ definition3.14 ] in @xmath101 , a weak @xmath216 topology is defined as @xmath217{*}u\\;\\;\\longleftrightarrow u_j\\xlongrightarrow[l^1(\\omega)]{}u\\;\\text { and } \\ ; \\int_\\omega { \\boldsymbol{\\phi } } \\cdot \\nabla^\\alpha u_j\\;dx\\xlongrightarrow\\;\\int_\\omega { \\boldsymbol{\\phi } } \\cdot\\nabla^\\alpha u\\;dx\\ ] ] for all @xmath121 in @xmath218 .",
    "from the above definition [ definition3.14 ] , we may derive the weak compactness of @xmath101 on the @xmath215 topology .",
    "this , combined with the weak lower semi - continuity of @xmath208 and boundedness of banach space @xmath101 ( i.e , @xmath10 is bounded in banach space @xmath101 ) , yields the following result :    [ theorem_existence0 ] the functional @xmath219 has a minimum .",
    "follow the similar lines of ( * ? ? ?",
    "38.12(d ) ) ) .    [ theorem3 ]",
    "the functional @xmath208 has a unique minimizer in @xmath101 when @xmath211 .",
    "the convexity result of theorem [ theorem_convexity ] leads to uniqueness of solutions .",
    "refer to ( * ? ? ?",
    "* theorem 47c ) .",
    "we remark that similar existence and uniqueness theories of the total variation problem can be found in @xcite .",
    "the standard definitions for fractional derivatives require a function to have zero dirichlet boundary conditions due to end singularity , but for imaging applications such conditions are unrealistic and too restrictive . to obtain the system for finding the unknown intensities @xmath10 at inner nodes of a discretization grids",
    ", we have to use boundary conditions , but the difficulties caused by them in fractional derivative computations would be hard to overemphasize ; inaccurate boundary conditions can easily lead to the oscillations near boundaries , so proper treatment of the boundary conditions for problems involving fractional derivatives is crucial .    in this section , we shall reduce nonzero dirichlet boundary conditions to zero ones so that standard definitions and our introduced algorithms become applicable .",
    "the basic idea of boundary regularization is to introduce an auxiliary unknown function which satisfies the zero boundary conditions . in this way ,",
    "the non - zero boundary conditions move to the right - hand side of the equation as a new known quantity .",
    "we recall that , in the 1d case , if the boundary conditions are nonzero @xmath220 we can reduce them to zero boundary conditions by introducing an auxiliary function @xmath221 .",
    "precisely taking @xmath222 @xcite , then @xmath223 and a neumann boundary condition is imposed by artificially extending the boundary values i.e. @xmath224 on @xmath225 .    below we generalize the above 1d idea to the 2d case , assuming that the four corners of the solution are given or accurately estimated : @xmath226 with @xmath227 known , at any image point @xmath228 , a bilinear auxiliary function satisfying the above @xmath229 conditions @xmath230 can be constructed to lead to @xmath231 which takes zero values at all @xmath229 corners .",
    "if boundary conditions @xmath232 at @xmath225 are known a priori , then we can easily verify that @xmath233 define the new dirichlet conditions for @xmath234 .",
    "we can achieve zero conditions at the edges using the auxiliary function @xmath235 .",
    "it is clear to see that the new image @xmath236 satisfies @xmath237    [ remark4 ] it remains to address the question of how to obtain estimates of @xmath238 at corners and edges :    1 .",
    "the true intensities @xmath239 in four corner points are unknown a priori , to build the auxiliary function @xmath240 , the solutions approximating to them should be solved from the observed image @xmath241 by the local smoothing or other simple techniques .",
    "2 .   similarly , the true edge intensities @xmath242 , @xmath243 , @xmath244 and @xmath245 are also not given , a reconstruction step on boundary @xmath225 must be proceeded in order to capture a robust solution .",
    "to do this , we can apply a 1d model .    according to remark [ remark4 ]",
    ", we can propose a complete procedure for regularizing boundary conditions for 2d variational image inverse problems in edges and corners .    *",
    "firstly , we restore image intensities in 4 corner points from an observed image @xmath11",
    ". a natural technique would be local smoothing operator for the region of corner points , the oscillations could also be reduced by many variational methods to local regions . * secondly , in order to reconstructed 4 edges from the restored intensities @xmath246 , @xmath247 , @xmath248 and @xmath249 , the total @xmath0-order variation regularization would be used to solve four 1d inverse problems i.e. solve an equation like ( [ reg - problem1 ] ) : @xmath250    thus through @xmath251 , we see that equation ( [ boundary_regularization1 ] ) reduces to finding the new image @xmath234 with zero dirichlet conditions and hence the standard definitions of fractional derivatives for @xmath234 apply .",
    "since solution uniqueness of our variational model ( [ reg - problem1 ] ) is resolved , we now consider how to seek a numerical solution of the total @xmath0-order variation model .",
    "we first reformulate it in preparation for employment of an efficient solver and then discuss some discretization details ( by finite - differences ) before presenting our algorithm 1 .      inspired by goldstein and osher s split - bregman work @xcite",
    ", we introduce a special and new variable @xmath252 to the total @xmath0-order variation based model ( [ reg - problem1 ] ) to derive the following constrained optimization problem : @xmath253 to enforce the constraint condition , we transfer it into the bregman formulation @xmath254 the above iterative scheme can be simplified to the two - step algorithm @xcite : @xmath255 with the multiplier updated by iteration @xmath256 where @xmath257 . here",
    "the two main subproblems of ( [ sb_ud ] ) are @xmath258 further note that the subproblem @xmath259 has a closed - form solution @xcite , while the subproblem @xmath10 is determined by the associated euler - lagrange equation as shown below .",
    "[ reg - problem02 ] let @xmath127 be a minimizer of functional @xmath260 from ( [ eqn_u2 ] ) .",
    "then @xmath127 satisfies the following first order optimal condition @xmath261 with one of these sets of boundary conditions @xmath262 where @xmath263 denotes the unit outward normal and @xmath264 denotes the divergence operator based on the c derivative .",
    "refer to appendix .      before introducing the finite difference discretization of the fractional derivative ,",
    "we define a spatial partition @xmath265 ( for all @xmath266 ) of image domain @xmath3 .",
    "assume @xmath10 has a zero dirichlet boundary condition ( practically we apply the regularization method ",
    "[ sec_bndy ] first before discretization ) .",
    "here we mainly consider the discretization of the @xmath0-order fractional derivative at the inner point @xmath265 ( for all @xmath267 ) on @xmath3 along @xmath39-direction by using the approach @xmath268}^\\alpha f(x_k , y_l ) & = \\frac{\\delta_0^\\alpha f(x_k , y_l)}{h^\\alpha}+o(h)\\ = \\frac{1}{2}\\big(\\frac{\\delta_-^\\alpha f(x_k , y_l)}{h^\\alpha}+\\frac{\\delta_+^\\alpha f(x_k , y_l)}{h^\\alpha}\\big)+o(h)\\\\ & = \\frac{1}{2}\\big(h^{-\\alpha}\\sum_{j=0}^{k+1 } \\omega_j^{\\alpha}f^l_{k - j+1}+h^{-\\alpha}\\sum_{j=0}^{n - k+2 } \\omega_j^{\\alpha}f^l_{k+j-1}\\big)+o(h ) , \\end{split}\\ ] ] which is applicable to both the r - l and c derivatives @xcite , where @xmath269 , @xmath270 , @xmath271 and @xmath272 alterative discretization for fractional derivatives in the fourier space can be found in @xcite .",
    "observe from ( [ fractionaldiscretization ] ) that the first order estimate of the @xmath0-order fractional @xmath273}^\\alpha f(x_k , y_l)$ ] along @xmath39-direction at the point @xmath265 with a fixed @xmath274 is a linear combination of @xmath275 values @xmath276 .",
    "after incorporating zero boundary condition in the matrix approximation of fractional derivative , all @xmath277 equations of fractional derivatives along @xmath39 direction in ( [ fractionaldiscretization ] ) can be written simultaneously in the matrix form ( denote @xmath278 ) : @xmath279 from the definition of fractional order derivative ( [ fractionaldiscretization ] ) , for any @xmath207 , the coefficients @xmath280 has the following properties @xcite",
    ":    1 ) . : :    @xmath281,**2).**@xmath282 , 3 ) . : :    @xmath283 , * 4 ) . *",
    "@xmath284 .    hence by the gerschgorin circle theorem",
    ", one can derive that matrix @xmath285 in ( [ eq5.1 ] ) is a symmetric and negative definite toeplitz matrix ( i.e. @xmath286 is a positive definite toeplitz matrix ) .",
    "we recall that the kronecker product @xmath287 of the @xmath288 matrix @xmath289 $ ] and the @xmath290 matrix @xmath291 $ ] is the @xmath292 matrix having the block structure @xmath293 $ ] .",
    "further vector @xmath294 can be computed by matrix scheme @xmath295 ( i.e. , @xmath296_s=[bxa^t]_{j , i}$ ] with @xmath297 ) , where the @xmath298 matrix @xmath213 is the reshape of the vector @xmath39 along its column .",
    "let @xmath299 denote the solution matrix at all nodes @xmath300 , @xmath301 , corresponding to x - direction and y - direction spatial discretization nodes .",
    "denote by @xmath302 the ordered solution vector of @xmath303 .",
    "the direct and discrete analogue of differentiation of arbitrary @xmath0 order derivative is @xmath304 where @xmath305 similarly , the @xmath0-th order y - direction derivative of @xmath306 is approximated by : @xmath307      in discrete form , we are ready to state the discretized equations in structured matrix form .",
    "the discrete scheme of ( [ fractionalsbel ] ) is given by @xmath308 with discretizations @xmath309 and @xmath310 of vectors @xmath259 and @xmath311 ( @xmath312 ) .",
    "a matrix approximation equation is given as @xmath313 where @xmath314 and @xmath315 are @xmath316-size reshape matrices of vectors @xmath317 and @xmath318 for @xmath312 , @xmath319 .",
    "the following justifies the use of a conjugate gradient method for @xmath320 .",
    "[ theorem5.5 ] the weighted matrices inner product @xmath321 is positive for any matrix @xmath322 , where @xmath323 is a known positive definite operator .    for any matrix @xmath322 ,",
    "it is easy to show that @xmath324 which completes the proof .",
    "an implementation of this method may be summarized below :    [ algsb02 ]    1 .",
    "boundary regularization for an observed image @xmath11;[alg02 - 00 ] 2 .",
    "given initial matrices @xmath325 , @xmath326 and @xmath327;[alg02 - 01 ] 3 .",
    "solve subproblem @xmath328 : compute the auxiliary matrix @xmath329 from the closed form solution @xmath330[alg02 - 02 ] by solving the moreau - yosida problem with the @xmath331 regularization ; 4 .",
    "solve subproblem @xmath10 : find the solution @xmath332 of ( [ sbeq ] ) with an effective parameter @xmath20 @xmath333 by cg method;[alg02 - 03 ] 5 .",
    "update @xmath334 with @xmath335$];[alg02 - 04 ] 6 .",
    "check the stopping condition ; [ alg02 - 05 ] * if @xmath336 , + stop and return @xmath337 ; * else + @xmath338 , go back to step [ alg02 - 02];[alg02 - 06 ] * end 7 .",
    "accept the correct solution @xmath303 from boundary regularization .",
    "as many variational models are increasingly solved by the discretise - optimise approach , we now present three related algorithms for model ( [ reg - problem02 ] ) after applying a finite difference discretization . in this section",
    ", we assume that we have the zero dirichlet boundary conditions for @xmath10 mainly to simplify the notation .    as in ",
    "[ sec_dis ] , the @xmath0-th order derivative @xmath339 of @xmath306 along all @xmath39-direction nodes in @xmath3 can be given by matrix @xmath340 , and similarly @xmath341 for @xmath342-direction ( as @xmath303 is the solution matrix ) .",
    "define @xmath343 and let @xmath344 . then using the discrete setting introduced above",
    ", the discretised problem of model ( [ reg - problem1 ] ) is @xmath345 where @xmath346 and @xmath347 , due to @xmath348 .",
    "we also have the adjoint relationship @xmath349 with @xmath350 and @xmath351 . in line with the literature",
    ", this model can be denoted by the convex optimization problem in a generic notation by @xmath352 where one views @xmath353 , @xmath354 .",
    "we also need the notation @xmath355 where @xmath356 can be any other convex function and @xmath357 .    to solve ( [ min - f - g ] ) by the methods to be presented , computation of the proximal point @xmath358 is a major and nontrivial step .",
    "we consider how to compute it when @xmath359 , borrowing ideas from solving a similar problem of tv regularization . in a dual",
    "setting , chambolle @xcite firstly proposed a discrete dual method by optimizing a cost function consisting of two variants @xcite . recently , one variant of this scheme is employed in @xcite to effectively solve a fractional image model by a dual transform .",
    "the other variant is used in @xcite .    define two projections as @xmath360 noting @xmath361 and that the optimal solution is @xmath362 where @xmath363 and @xmath364 is unknown . based on methods of chambolle @xcite and beck - teboulle @xcite",
    ", we see that ( [ discrete_solution ] ) can be used to reduce the min - max problem @xmath365 to the dual problem @xmath366 and further to @xmath367 @xmath368 i.e. @xmath369 where @xmath370 .    below we consider the operator @xmath371 . since",
    "its gradient is @xmath372 , we get @xmath373 the minimization problem @xmath374 can be solved to obtain the @xmath364-update as follows    1 .",
    "@xmath375 2 .",
    "@xmath376    using the gradient projection scheme of @xmath377 @xcite . here",
    "@xmath378 is the lipschitz constant .",
    "finally the proximal point @xmath379 is given by ( [ discrete_solution ] ) once @xmath364 is obtained ; see also @xcite .",
    "various applications in sparse optimizations stimulated the search for simple and efficient first - order methods .",
    "the forward backward scheme for ( [ min - f - g ] ) is based ( as the name suggests ) on recursive application of an explicit forward step with respect to @xmath380 , i.e , @xmath381 and followed by an implicit backward step with respect to @xmath356 , i.e. , @xmath382 the scheme decouples the contributions of the functions @xmath356 and @xmath380 in a gradient descent step @xcite .",
    "the scheme is also known under the name of proximal gradient methods @xcite , since the implicit step relies on the computation of the so - called proximity operator .",
    "the forward backward algorithm is summarised as follows .",
    "[ algfb ]    * fix initial @xmath383 , set @xmath384 $ ] , @xmath385 ( a lipschitz parameter ) ; * for @xmath386 1 .",
    "@xmath387 $ ] , @xmath388 $ ] ; 2 .",
    "@xmath389 3 .",
    "@xmath390 ; 4 .",
    "@xmath391 ; 5 .",
    "stop when @xmath392 is small enough otherwise continue .      as a gradient based method , though simple , the above method can exhibit a slow speed of convergence .",
    "for this reason , nesterov @xcite proposed an improved gradient method aiming to accelerate and modify the classical forward - backward splitting algorithm , while achieving an almost optimal convergence rate . as a consequence of this breakthrough ,",
    "a few recent works have followed up the idea and improved techniques for some specific problems in signal or image processing @xcite .",
    "recently nesterov @xcite presented an accelerated multistep version , which converges as @xmath393 ( @xmath394 is the iteration number ) . for a problem of type ( [ min - f - g ] ) , this new method introduced a composite gradient mapping .",
    "we now show the algorithm as follows .",
    "[ alg_nesterov ]    * fix initial @xmath383 , @xmath395 , set @xmath396 and @xmath385 ( a lipschitz parameter ) ; * for @xmath386 1 .",
    "find @xmath397 from the quadratic equation @xmath398 ; 2 .",
    "@xmath399 ; 3 .",
    "@xmath400 ; 4 .",
    "@xmath401 ; 5 .",
    "@xmath402 ; 6 .",
    "@xmath403 ; 7 .",
    "stop when @xmath392 is small enough otherwise continue .",
    "beck and teboulle @xcite proposed a fast iterative shrinkage thresholding algorithm ( fista ) to solve the image denoising and deblurring model , the method applies the idea of nesterov to the forward - backward splitting framework , resulting in the same optimal convergence rate as nesterov s method but wider applicability .",
    "it can be applied to a variety of practical problems arising from sparse signal recovery , image processing and machine learning and hence has become a standard algorithm .",
    "applying it to ( [ min - f - g ] ) , we obtain algorithm [ algfgp ] below .",
    "[ algfgp ]    * fix initial @xmath383 , set @xmath404 and @xmath405 , @xmath385 ( a lipschitz parameter ) ; * for @xmath386 1 .",
    "@xmath406 2 .",
    "@xmath407 3 .",
    "@xmath408 4 .",
    "@xmath409 ; 5 .",
    "stop when @xmath392 is small enough otherwise continue .",
    "finally , we present some numerical results from using the four presented algorithms denoted by    pde - sb : : :    pde - based split - bregman ( algorithm [ algsb02 ] ) ; opti - fb : : :    optimization based forward - backward ( algorithm [ algfb ] ) ; opti - nesterov : : :    optimization based nesterov accelerated method ( algorithm    [ alg_nesterov ] ) ; opti - fista : : :    optimization based fista ( algorithm [ algfgp ] ) ,    and their comparisons with related methods . in all tests , an initial solution is the noisy image @xmath241 , the algorithms solving the diffusion equation or optimization problem are stopped after achieving a relative residual of @xmath410 or a relative error of @xmath411 within 1000 outer and 15 inner iterations . here",
    "we mainly compare the solution s visual quality , the _ snr _ ( the signal - to - noise ratio ) and _ psnr _ ( the peak signal - to - noise ratio ) values which are given @xmath412 where @xmath413 is an average value of the true image @xmath414 , @xmath415 and @xmath416 denote the size of the test image @xmath11 .",
    "it should be noted however that these valuations do not always correlate with human perception . in real life situations ,",
    "the two measures are also not possible because the true image is not known .    in general , an optimization problem",
    "may be solved many times to select a suitable regularization parameter @xmath20 or to optimize the solution for the underlying inverse problem ; a solution is accepted when some stopping criterion is satisfied .",
    "it remains to carry out a systematic study on our new model as in @xcite for the tv model .",
    "however we shall use the best ( numerical ) @xmath20 for all models in the following tests .    for denoising",
    ", @xmath417 is the @xmath28 measure between the solution @xmath10 and the observed image @xmath11 . to intuitively describe the denoising ability ,",
    "four sets of data will be used in this part ( _ also see _ fig.[figure - example ] ) :    p1 : : :    _ problem 1 _ - parabolic surfaces ; @xmath418 _ problem 2 _    - saddle surface ; p3 : : :    _ problem 3 _ - pepper ; @xmath419 _ problem 4 _ - penguin .",
    "[ figexample ]    though our framework is readily applicable to image deblurring and image registration , here we only present denoising results .",
    "we first test the idea from  [ sec_bndy ] .",
    "one the hand , the variational framework seeks the boundary conditions of a nonzero dirichlet or a neumann type on @xmath225 and also real images do have nonzero boundary conditions . on the other hand ,",
    "fractional order derivatives require homogeneous boundary conditions ( as used in works of many authors ) due to end singularity . in order to aid accurate computation of the discretized fractional order derivative , in our work , a boundary processing technique  [ sec_bndy ] has been proposed to transform nonzero boundary conditions of observed data @xmath11 into zero boundary conditions ; hence a consequent matrix approximation to the fractional derivative operator @xmath420}$ ] can use a zero dirichlet boundary condition .    here",
    "we test the performance and effectiveness of our boundary regularization against no regularization .",
    "the experiment is carried out on * p1 * - parabolic surfaces as shown in fig .",
    "[ figure-1 ] , i.e. , a synthetic image of size @xmath421 and range [ 0 , 1 ] , in fig .",
    "[ fig1](a ) , which is added zero mean value gaussian random noise with a mean variance @xmath422 to get the noisy image displayed in fig .",
    "[ fig1](d ) . for the boundary regularization case ,",
    "the approximation @xmath423 from the observed data @xmath424 is from applying one dimensional fractional order variation model as described in ",
    "[ sec_bndy ] .",
    "the treated case is named as ` treated ' whose results are depicted on fig . [ fig1](b ) and fig .",
    "[ fig1-e ] ) , where _ _ psnr__@xmath425 and _ _ snr=__@xmath426 .",
    "the solution obtained from assuming zero boundary conditions for @xmath10 is named as ` non - treated ' with its results depicted in fig .",
    "[ fig1](c ) and fig .",
    "[ fig1-f ] , where @xmath427 and @xmath428 .",
    "clearly our boundary regularization treatment is effective .    ) using pde - sb .",
    "the treated case has _",
    "_ psnr__=@xmath429 and _ _ snr__=@xmath426 , while the non - treated case has _ _ psnr__=@xmath430 and _ _ snr__=@xmath431 .",
    "clearly our boundary regularization ",
    "[ sec_bndy ] is effective while direct application of a fractional model leads to incorrect boundary restoration . here",
    "the error @xmath432 .",
    ", title=\"fig:\",width=537,height=297][fig1 ] +      in table [ tab0 ] , we compare the restoration quality ( via _ psnr _ and _ snr _ ) of 4 algorithms .",
    "there , all four test datasets are used . in the cases of synthetic images * p1 * and * p2 * with noise variation @xmath433 , @xmath20 is taken as @xmath434 and @xmath435 respectively and @xmath90 . in the cases of natural images * p3 * and * p4 * with noise variation @xmath436 , @xmath20 is taken as @xmath437 and @xmath438 respectively and @xmath439 .",
    "one can see that , from table [ tab0 ] , opti - nesterov and pde - sb perform similarly in terms of the best restoration quality ( via _ psnr _ and _ snr _ ) .",
    "however in efficiency ( computation times _",
    "cpu(s ) _ ) , opti - fista and pde - sb are the best while opti - nesterov takes more computational times than other three algorithms .",
    "evidently , overall , pde - sb ( algorithm 1 ) shows the most consistence in good performance in tested cases considered .",
    "cccccccccccccccc + & & & & & & & +   +   + & _ snr_&_psnr_&_cpu(s ) _ & & _",
    "snr_&_psnr_&_cpu(s ) _ & & _ snr_&_psnr_&_cpu(s)_&&_snr_&_psnr_&_cpu(s ) _ +   + * p1 * & 36.78 & 50.09&16.83&&36.91&50.22&27.23&&36.94&50.24&16.71&&36.96&50.27&14.53 +   + * p2 * & 31.04&53.08&17.28 & & 31.61&53.67&28.43 & & 31.46&53.50&18.14 & & 31.63&53.69&15.09 +   + * p3 * & 29.21&43.29&15.96 & & 29.40&43.49&16.09 & & 29.40&43.49&9.75&&29.48&43.56&8.16 +   + * p4 * & 25.19&38.01&14.68 & & 25.35&38.15&16.27 & & 25.34&38.15&8.62&&25.34&38.14&8.45 +   +      since our model ( [ reg - problem1 ] ) contains two main parameters : @xmath0 for the order of differentiation and @xmath20 as the coupling parameter for a regularized inverse problem , it is of interest to test their sensitivity on the restoration quality . here",
    "we shall test all algorithms s sensitivity using the image * p2 * - saddle surface of size @xmath421 , after adding zero mean value gaussian random noise image of range [ 0 , 1 ] and @xmath440 .",
    "varying @xmath20 in a large range from @xmath441 to @xmath442 , all four algorithms are tested on this synthetic image with the results shown in figs .",
    "[ fig - opti_meth_lambda - a ] and [ fig - opti_meth_lambda - c ] for different stopping criterions ( * gsc : * the general stopping criterions with the relative residual @xmath410 , relative error @xmath411 , inner iterations 10,*ssc : * the strong stopping criterions with the relative residual @xmath443 , relative error @xmath444 , inner iterations 25 ) .",
    "different from the tv denoising case where the regularization parameter @xmath20 is crucial for restoration quality @xcite , however , figs .",
    "[ fig - opti_meth_lambda - a ] and [ fig - opti_meth_lambda - c ] show that our total @xmath0-order variation regularization model still obtains a satisfactory solution for a large range of @xmath20 ; this is a pleasing observation .",
    "of course there exists an issue of an optimal choice .",
    "next varying @xmath445 from @xmath446 to @xmath447 , figs .",
    "[ fig - opti_meth_alpha - b ] and [ fig - opti_meth_alpha - d ] show four algorithms s restored results responding to two stopping conditions * gsc * and * ssc*. as represented , the smaller @xmath0 leads to the blocky ( staircase ) effects in @xmath10 and the larger @xmath0 will make solution @xmath10 too smooth along @xmath448- and @xmath449-directions respectively . for denoising",
    ", our test suggests that @xmath90 is suitable for smooth problems because the diffusion coefficients are almost isotropic in all regions , leading to smooth deformation fields , and @xmath439 is appropriate for nonsmooth problems because the diffusion coefficients are close to zero in regions representing large gradients of the fields , allowing discontinuities at those regions .",
    "we should emphasize that the stopping criterions have impacted on the actual numerical implementation .",
    "in other words , if we drop the limit on the maximal number of inner iterations and relative residuals ( and relative errors ) , some methods take too long but obtain the more satisfactory results .      in this test",
    ", we compare our total @xmath0-variation model(pde - sb ) with three popular methods for variational image denoising .",
    "the first compared approach is naturally the tv model proposed by rudin et al .",
    "@xcite because the total @xmath0-order variation model in this work is inspired by it .",
    "the second compared work is the mean curvature model @xcite which also addresses the problem of restoring a good result for a smooth image ; their approach is different from ours since it is focused on higher order regularization and a multigrid method .",
    "see also @xcite .",
    "the third compared approach is the tgv model @xcite involving a combination of first order and higher - order derivatives to reduce the staircasing effect of the bounded variation functional .    in table",
    "[ tab:3 ] , we first compare the restoration quality ( via _ psnr _ , _ snr _ ) and efficiency ( computation times _",
    "cpu(s ) _ ) of four approaches by testing the artificial images ( * p1 * - parabolic surface , * p2 * - saddle surface ) and the natural images ( * p3 * - pepper , * p4 * - penguin ) ; in each approach relevant parameters are shown in table [ tab:3 ] .",
    "we see that , with the emperically optimal parameters @xmath450 , the differences of four models are very small , though our new and convex model is slightly better . in other tests where such optimal parameters are not used , our new model performs more robustly and better .    in order to present more visual differences , some stronger regularization parameters ( @xmath451 ) and higher noise variations ( with the noise level @xmath452 ) are tested , the solution s visual representations restoring the natural image * p3 * - pepper in fig .",
    "[ fig4-b ] are shown in fig .",
    "[ figure-4 ] . while rof denoising leads to blocky results , the mean curvature model performs better in the smooth regions but exhibits more smooth near discontinuities , the total generalized variation model leads to further improvements over the aforementioned models .",
    "the total fractional - order variation model leads to significantly better results .",
    "the reason is that the new model tries to approximate the image based on affine functions or non - local high order smooth functions , which is clearly better in this case , in other words , our approach is more effective in eliminating the noise for smooth images and is competitive to high order methods ; in efficiency the new approach ( pde - sb ) is much faster than the tgv and the mean curvature .",
    "we also plot four error results between the restored and true images along a diagonal ( magenta ) line in fig .",
    "[ fig4-a ] for comparison in fig .",
    "[ figure-4 - 2 ] ; we see that pde - sb produces the best restored surface , which show a major advantage ( or better performance ) of using our total @xmath0-order variation model ( [ reg - problem1 ] ) when the test image is smooth , and even when the contrast between meaningful objects and the background is low .",
    "cccccccccccccc + & & & & & +   +   + & @xmath453&__&_snr_&_psnr_&__&_snr_&_psnr_&__&_snr_&_psnr_&__&_snr_&_psnr _ +   + & @xmath454 & & 33.44&46.74 & & 32.17 & 45.52 & & 36.41 & 49.72 & & 37.55&50.86 + * p1 * & @xmath455 & & 30.19&43.50 & & 29.55 & 42.83 & & 33.03 & 46.33 & & 33.52&46.83 + & & & & & & & & & + & & & & & & & & & +   + & @xmath454 & & 27.27&49.31 & & 23.09 & 45.13 & & 30.75 & 52.68 & & 32.02&54.18 + * p2*&@xmath455 & & 22.88&44.92 & & 19.45 & 41.49 & & 25.62 & 47.51 & & 26.48&48.54 + & & & & & & & & & + & & & & & & & & & +   + & @xmath454 & & 20.43&38.80 & & 20.08&38.35 & & 20.40&38.78 & & 20.48&38.86 + & @xmath456 & & 18.76&37.11 & & 18.01&36.69 & & 18.68&37.12 & & 18.84&37.20 + * p3 * & @xmath455 & & 17.48&35.82 & & 17.17&35.33 & & 17.55&35.87 & & 17.57&35.90 + & & & & & & & & & + & & & & & & & & & + & & & & & & & & & +   + & @xmath457 & & 25.16&37.95 & & 24.85&37.58 & & 25.39&38.20 & & 25.34&38.14 + & @xmath454 & & 21.72&34.60 & & 21.33 & 34.07 & & 21.82&34.71 & & 21.75&34.62 + * p4*&@xmath456 & & 19.26&32.05 & & 18.66&31.29 & & 19.44&32.21 & & 19.42&32.20 + & & & & & & & & & + & & & & & & & & & + & & & & & & & & & +    [ tab:3 ]     +     +",
    "the total @xmath0-order variation regularization with fractional order derivative is potentially useful in modeling all imaging problems . in this paper",
    "we analyzed rigorously a simple variational model using total @xmath0-order variation for image denoising .",
    "one split - bregman based algorithm and three optimization - based algorithms were developed to solve the resulting image inverse problem .",
    "instead of using the usual fixed and zero boundary conditions , we proposed a boundary regularization method to treat the fractional order derivatives .",
    "numerical results show that the pde - based split - bregman algorithm ( pde - sb ) performs similarly to ( though more stably than ) optimization - based approaches while our boundary regularization method is essential for getting good results for imaging denoising .",
    "moreover , pde - sb outperforms currently competitive variational models in terms of restoration quality .",
    "there are still outstanding issues with our proposed model and algorithms ; among others optimal selection of @xmath20 is to be addressed .",
    "future work will also consider generalization of this work to other image inverse problems .      to shorten the proof ,",
    "let @xmath458 be a function in @xmath183 to be specified shortly .",
    "for @xmath459 , we compute the first - order g - derivative ( gateaux ) of the functional @xmath260 in the direction @xmath458 by @xmath460 where @xmath461  see ( [ eqn_u2 ] ) . using the taylor series w.r.t @xmath462 yields @xmath463 with @xmath464 .",
    "recall that @xmath465}w_1\\frac{\\partial^{n - j-1}\\omega(x)}{\\partial x_1^{n - j-1}}\\big|_{x_1=0}^{x_1=1 } dx_2\\\\ - & \\sum_{j=0}^{n-1}(-1)^j \\int_0 ^ 1   d^{\\alpha - n+j}_{[c , d]}w_2\\frac{\\partial^{n - j-1}\\omega(x)}{\\partial x_2^{n - j-1}}\\big|_{x_2=0}^{x_2=1 } dx_1 . \\end{split}\\ ] ] where we note @xmath466 for @xmath467 .",
    "next consider 2 case studies .",
    "i ) . given @xmath468 , since @xmath469 and @xmath470",
    ", it suffices to take @xmath471 .",
    "such a choice ensures @xmath472 . hence equation ( [ euler - lagrange1 ] ) with ( [ euler - lagrange2 ] ) reduces to ( [ fractionalsbel ] ) .",
    "ii ) . keep @xmath473 . since @xmath474 , the boundary terms in equation ( [ euler - lagrange4 ] )",
    "can only diminish if @xmath475}w_1 \\big|_{x_1=0   \\",
    "\\mbox{or } \\ 1 }      = 0 \\ \\",
    "\\mbox{and } \\ \\",
    "d^{\\alpha - n+j}_{[c , d]}w_2 \\big|_{x_2=0   \\ \\mbox{or } \\ 1 }      = 0 \\ \\",
    "\\rightarrow \\ \\",
    "d^{\\alpha - n+j } \\boldsymbol{w}\\cdot n = 0 , j=0,1.\\ ] ] the proof is complete .    in imaging applications , the above first set i ) of boundary conditions",
    "seems not reasonable , because one hardly knows a priori what @xmath476 should be .",
    "the second set ii ) of boundary conditions appears complicated which might be simplified as follows . from (",
    "* section 2.3.6 pp.75 ) , if @xmath477 has a sufficient number of continuous derivatives , then + @xmath478}w_1 \\big|_{x_1=0   \\ \\mbox{or } \\ 1 }      = 0 $ ] for any @xmath445 is equivalent to @xmath479 , i.e. , @xmath480 indeed , if the @xmath64-th derivative of @xmath127 is integrable in @xmath481 $ ] , then @xmath482 is equivalent to @xmath483 on the other hand , @xmath484 ( for all @xmath485 ) are equivalent to @xmath486 and @xmath487 , hence one has @xmath488 .",
    "the derivations of @xmath489 are similar to those of @xmath490 .",
    "height 2pt depth -1.6pt width 23pt , _ necessary and sufficient conditions for the fractional calculus of variations with caputo derivatives _ , communications in nonlinear science and numerical simulation , 16 ( 2011 ) , pp .",
    "14901500 .                                                                                              , _ noise removal using fourth - order partial differential equation with application to medical magnetic resonance images in space and time _",
    ", ieee transactions on image processing , 12 ( 2003 ) , pp .  15791590 .                        , _",
    "fractional differential equations : an introduction to fractional derivatives , fractional differential equations , to methods of their solution and some of their applications _",
    ", mathematics in science and engineering , elsevier science , 1999 ."
  ],
  "abstract_text": [
    "<S> to overcome the weakness of a total variation based model for image restoration , various high order ( typically second order ) regularization models have been proposed and studied recently . in this paper </S>",
    "<S> we analyze and test a fractional - order derivative based total @xmath0-order variation model , which can outperform the currently popular high order regularization models . there </S>",
    "<S> exist several previous works using total @xmath0-order variations for image restoration ; however first no analysis is done yet and second all tested formulations , differing from each other , utilize the zero dirichlet boundary conditions which are not realistic ( while non - zero boundary conditions violate definitions of fractional - order derivatives ) .    </S>",
    "<S> this paper first reviews some results of fractional - order derivatives and then analyzes the theoretical properties of the proposed total @xmath0-order variational model rigourously . </S>",
    "<S> it then develops four algorithms for solving the variational problem , one based on the variational split - bregman idea and three based on direct solution of the discretise - optimization problem . </S>",
    "<S> numerical experiments show that , in terms of restoration quality and solution efficiency , the proposed model can produce highly competitive results , for smooth images , to two established high order models : the mean curvature and the total generalized variation .    </S>",
    "<S> * keywords*. fractional - order derivatives ; total @xmath0-order variation ; pde ; image denoising ; image inverse problems ; optimization methods .  </S>",
    "<S> ams . </S>",
    "<S> 62h35 , 65n22 , 65n55 , 74g65 , 74g75 </S>"
  ]
}