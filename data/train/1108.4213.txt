{
  "article_text": [
    "stochastic partial differential equations ( spdes ) frequently arise from applications in areas such as physics , engineering and finance .",
    "however , in many cases it is difficult to derive an explicit form of their solution .",
    "moreover , current numerical algorithms often show limited success for high - dimensional problems or in complex domains  even for deterministic partial differential equations .",
    "the _ kernel - based _ approximation method ( _ meshfree _ approximation method  @xcite ) is a relatively new numerical tool for the solutions of high - dimensional problems . in this paper",
    "we apply  to our knowledge for the first time  such a kernel - based collocation method to construct numerical estimators for stochastic partial differential equations .",
    "galerkin - type approximation methods based on the eigenvalues and eigenfunctions of the underlying differential operator are currently very popular for the numerical solution of spdes @xcite . with the kernel - based meshfree collocation method introduced here explicit knowledge of these eigenvalues and eigenfunctions",
    "is not required since the kernels can be directly obtained as green kernels of the differential operators @xcite .",
    "stochastic collocation methods using a polynomial basis are also frequently found in the literature @xcite .",
    "these methods usually require the collocation points to lie on a regular grid . in our method",
    "the collocation points can be placed at rather arbitrarily scattered locations .",
    "this allows for the use of either deterministic or random designs such as , e.g. , uniform or sobol points , but also for adaptively chosen locations . in this paper",
    "we do not study the design aspect of our algorithm , but reserve this important aspect for future work .",
    "another advantage of using a meshfree method is its ability  also not explicitly pursued here  to deal with problems on a complex domain @xmath0 , @xmath1 , by using appropriately placed collocation points .",
    "another advantage of this method is its high efficiency , in the sense that once certain matrices are inverted and factored we can compute , essentially for free , the value of the approximated solution at any point in the spatial domain and at any event from sample space .",
    "in particular the method is suitable for simulation of a large number of sample paths of the solution . in this article",
    "we present only a general framework for this new numerical method and prove weak convergence of the corresponding schemes .",
    "we conclude the paper with a numerical implementation of this method applied to a one - dimensional stochastic heat equation with dirichlet boundary conditions driven by an additive space - time white noise ( colored in space ) .",
    "much more details , as well as some of the aspects just mentioned , will be discussed in qi ye s ph.d .",
    "thesis  @xcite or in future publications .",
    "assume that @xmath2 is a _ regular _ open bounded domain in @xmath3 ( see appendix  [ s : diff - bound ] ) , and let @xmath4 be a separable hilbert space of functions defined on @xmath2 .",
    "also , let @xmath5 be a stochastic basis with the usual assumptions .",
    "we consider the following parabolic it equation @xmath6 where @xmath7 is a linear elliptic operator in @xmath4 , @xmath8 is a boundary operator for dirichlet or neumann boundary conditions , @xmath9 , and @xmath10 is a wiener process in @xmath4 , with mean zero and spatial covariance function @xmath11 given by @xmath12 , and @xmath13 ( see for instance  @xcite ) .",
    "we assume that equation has a unique solution @xmath14 .",
    "the proposed numerical method for solving a general spde of the form can be described as follows :    1 .",
    "discretize in time by the implicit euler scheme at equally spaced time points @xmath15 , @xmath16 where @xmath17 and @xmath18 .",
    "since it follows from and the definition of brownian motion that the noise increment @xmath19 at each time instance @xmath20 is independent from the solution @xmath21 at the previous step , we simulate the gaussian field with covariance structure @xmath22 at a finite collection of predetermined _ collocation points _ @xmath23 3 .",
    "let the differential operator @xmath24 , and the noise term @xmath25 . since @xmath26 is a gaussian field with @xmath27 and @xmath28 , equation together with the corresponding boundary condition becomes an elliptic spde of the form @xmath29 where @xmath30 is seen as an unknown part and @xmath31 and @xmath26 are viewed as given parts .",
    "we will solve for @xmath32 using a kernel - based collocation method written as @xmath33 where @xmath34 is a _ reproducing kernel _ and the integral - type kernels @xmath35 are defined in lemmas  [ l : gauss - rk ] and  [ l : p - b - cov - expan ] .",
    "the unknown random coefficients @xmath36 are obtained by solving a random system of linear equations ( with constant deterministic system matrix and different random right - hand side ) at each time step .",
    "details are provided in section [ s : col - spde ] .",
    "4 .   repeat s2 and s3 for all @xmath37 .    obviously",
    ", many other  potentially better ",
    "time stepping schemes could be applied here . however , as mentioned earlier , we focus mainly on step s3 and are for the time being content with using the implicit euler scheme .",
    "naturally , the rate of convergence of the above numerical scheme depends on the size of the time step @xmath38 , and the _",
    "fill distance _",
    "@xmath39 of the collocation points .",
    "we support this statement empirically in section  [ sec : numerical - experimants ] . we should mention that even for deterministic time - dependent pdes to find the exact rates of convergence of kernel - based methods is a delicate and nontrivial question , only recently solved in @xcite .",
    "we will address this question in the case of spdes in future works .",
    "the fundamental building block of our mesh - free method is the reproducing kernel @xmath40 and its reproducing - kernel hilbert space @xmath41 ( see appendix  [ s : rkhs ] for more details ) . by the very nature of such a kernel - based method , the approximate solution @xmath42 , must live in @xmath41 .",
    "thus , we make the following standing assumption throughout the paper :    * the solution @xmath43 of the original equation lies in a hilbert space @xmath44 which can be embedded in the reproducing kernel hilbert space @xmath41 .",
    "usually , @xmath44 is a sobolev space @xmath45 , for some positive @xmath46 . in this case",
    "it is possible to choose an appropriate kernel @xmath34 such that the above embedding assumption is satisfied . for a general discussion of existence and uniqueness of the solution of problem",
    "see , e.g. , @xcite .",
    "in this section we briefly review the standard kernel - based approximation method for high - dimensional interpolation problems . however , since we will later be interested in solving a stochastic pde , we present the following material mostly from the stochastic point of view . for further discussion of this method",
    "we refer the reader to the recent survey papers @xcite and references therein .",
    "assume that the function space @xmath41 is a reproducing - kernel hilbert space with norm @xmath47 and its reproducing kernel @xmath48 is symmetric positive definite ( see appendix  [ d : rkhs ] ) .",
    "given the data values @xmath49 at the collocation points @xmath50 of an unknown function @xmath51 , i.e. , @xmath52 the goal is to find _ an optimal estimator _ from @xmath41 that interpolates these data .",
    "[ d : gaussian ] a stochastic process @xmath53 is said to be _ gaussian _ with mean @xmath54 and covariance kernel @xmath55 on a probability space @xmath56 if , for any pairwise distinct points @xmath57 , the random vector @xmath58 is a multi - normal random variable on @xmath56 with mean @xmath59 and covariance matrix @xmath60 , i.e. , @xmath61 , where @xmath62 and @xmath63 .      in the _ deterministic formulation _ of kernel interpolation",
    "we solve an optimization problem by minimizing the reproducing - kernel norm subject to interpolation constraints , i.e. , @xmath64 in this case , the minimum norm interpolant ( also called the collocation solution ) @xmath65 is a linear combination of `` shifts '' of the reproducing kernel @xmath34 , @xmath66 where the coefficients @xmath67 are obtained by solving the following system of linear equations @xmath68 with @xmath69 and @xmath70 .    for simple kriging , i.e. , in the _ stochastic formulation _",
    ", we let @xmath71 be a gaussian process with mean @xmath72 and covariance kernel @xmath34 on some probability space @xmath56 . kriging is based on the modeling assumption that @xmath32 is a realization of the gaussian field @xmath71 .",
    "the data values @xmath73 are then realizations of the random variables @xmath74 .",
    "the optimal unbiased predictor of @xmath75 based on @xmath76 is equal to @xmath77 where the coefficients @xmath78 are given by @xmath79 with @xmath80 and the same matrix @xmath81 as above .",
    "we can also compute that @xmath82    note that , in the kriging approach we consider only the values of the stochastic process @xmath71 at the collocation points , and view the obtained vector as a random variable . however , if we view @xmath71 as a real function , then @xmath83 by ( * ? ? ?",
    "* theorem  7.3 ) . a simple example for this fact is given by the scalar brownian motion defined in the domain @xmath84 ( see , e.g. , ( * ? ? ?",
    "* example  5.1 ) ) .",
    "this means that it is difficult to apply the kriging formulation to pde problems .",
    "next we will introduce a new stochastic data fitting approach that will subsequently allow us to perform kernel - based collocation for stochastic pdes .",
    "from now on we will view the separable reproducing - kernel hilbert space @xmath41 as a sample space and its borel @xmath85-field @xmath86 as a @xmath85-algebra to set up the probability spaces so that the stochastic process @xmath87 is gaussian .",
    "we use the techniques of  @xcite to verify lemma  [ l : gauss - rk ] , which is a restatement of ( * ? ? ?",
    "* theorem  7.2 ) .",
    "this theoretical result is a generalized form of wiener measure defined on the measurable space @xmath88 , called canonical space , such that the coordinate mapping process @xmath89 is a brownian motion ( see , for instance , @xcite ,  chapter  2 ) .",
    "[ l : gauss - rk ] let the positive definite kernel @xmath48 be the reproducing kernel of the reproducing - kernel hilbert space @xmath41 .",
    "given a function @xmath90 there exists a probability measure @xmath91 defined on @xmath92 such that @xmath87 is gaussian with mean @xmath93 and covariance kernel @xmath94 on @xmath95 , where the integral - type kernel @xmath94 of @xmath34 is given by @xmath96 moreover , the process @xmath71 has the following expansion @xmath97 where @xmath98 and @xmath99 are the eigenvalues and eigenfunctions of the reproducing kernel @xmath34 , and @xmath100 are independent gaussian random variables with mean @xmath101 and variance @xmath102 , @xmath103 .    before we prove lemma  [ l : gauss - rk ] we remark that we have introduced the integral - type kernel @xmath94 for convenience only . as seen later , in order to `` match the spaces '' , any other kernel that `` dominates '' @xmath34 ( in the sense of @xcite ) could play the role of the integral - type kernel @xmath94 .",
    "we first consider the case when @xmath104 .",
    "there exist countably many independent standard normal random variables @xmath105 on a probability space @xmath106 , i.e. , @xmath107 , @xmath103 .",
    "let @xmath98 and @xmath99 be the eigenvalues and eigenfunctions of the reproducing kernel @xmath34 as in theorem  [ t : rkhs ] .",
    "we define @xmath108 @xmath109-a.s .",
    "note that @xmath71 is gaussian with mean @xmath72 and covariance kernel @xmath94 . since @xmath110 indicates that @xmath111 @xmath109-a.s .",
    ", theorem  [ t : rkhs ] shows that @xmath112 @xmath109-a.s . therefore @xmath71 is a measurable map from @xmath113 into @xmath114 by ( *",
    "* chapter 4.3.1 ) and ( * ? ? ?",
    "* lemma  2.1 ) . on the other hand",
    ", the probability measure @xmath115 ( also called the _ image measure _ of @xmath109 under @xmath71 ) is well defined on @xmath114 , i.e. , @xmath116 for each @xmath117 .",
    "hence , @xmath71 is also a gaussian process with mean @xmath72 and covariance kernel @xmath94 on @xmath118 .",
    "let @xmath119 on @xmath118 .",
    "then @xmath120 and @xmath121 with respect to @xmath122 .",
    "we define a new probability measure @xmath91 by @xmath123 for each @xmath117 .",
    "it is easy to check that @xmath124 and @xmath125 .",
    "thus @xmath71 is gaussian with mean @xmath93 and covariance kernel @xmath94 on @xmath95 .",
    "moreover , since @xmath126 , it can be expanded in the form @xmath127 , where @xmath101 , so that @xmath128 .",
    "but then @xmath129 are independent on @xmath95 .    according to ( * ? ?",
    "* theorem  4.91 ) , we can also verify that the random variable @xmath130 , is a scalar normal variable on @xmath95 , i.e. , @xmath131 where @xmath132 and @xmath133 .",
    "therefore the probability measure @xmath91 defined in lemma  [ l : gauss - rk ] is _",
    "gaussian_.    let @xmath134 be the joint probability density function of @xmath135 defined on @xmath95 .",
    "then it is a normal density function with mean @xmath62 and covariance matrix @xmath136 . in analogy to the kriging formulation we can find the optimal mean function @xmath137 fitting the data values @xmath70 , i.e. , @xmath138 where @xmath139 .",
    "we now fix any @xmath140 .",
    "straightforward calculation shows that the random variable @xmath75 , given @xmath135 , defined on @xmath95 has a conditional probability density function @xmath141 where @xmath142 , @xmath143 , and @xmath144 .",
    "then the optimal estimator that maximizes the probability @xmath145 is given by @xmath146    [ prop : main - approximation ] with the above notations , the following equality holds true @xmath147 moreover , for any @xmath148 , @xmath149 where @xmath150    identity follows by direct evaluations .",
    "consequently , taking into account that @xmath71 is gaussian , inequality follows also immediately .    instead of giving a deterministic ( or strong ) error bound for the proposed numerical scheme , we provide _ a weak type convergence _ of the approximated solution @xmath151 to the true solution @xmath32 , as stated in proposition [ prop : main - approximation ] .",
    "in fact , inequality can be seen as a confidence interval for the estimator @xmath151 with respect to the probability measure @xmath152 .    in the next section",
    "we generalize this stochastic approach to solve elliptic pdes .",
    "we begin by setting up gaussian processes via reproducing kernels with differential and boundary operators .",
    "suppose that the reproducing - kernel hilbert space @xmath41 is embedded into the sobolev space @xmath153 where @xmath154 .",
    "let @xmath155 . by the sobolev embedding theorem @xmath156 .",
    "when the differential operator @xmath157 and the boundary operator @xmath8 have the orders @xmath158 and @xmath159 , then the stochastic processes @xmath160 and @xmath161 are well - defined on @xmath95 . according to lemma  [",
    "l : p - b - expan ] , we have @xmath162 and @xmath163 . if @xmath164 , then @xmath165 and @xmath166 .",
    "lemma  [ l : p - b - cov - expan ] implies that @xmath167 and @xmath168 ( here we can use the fact that @xmath169 and @xmath170 ) . applying lemma  [ l : gauss - rk ] , we can obtain the main theorem for the construction of gaussian processes via reproducing kernels coupled with differential or boundary operators .",
    "[ t : gauss - rk - pb ] suppose that the reproducing kernel hilbert space @xmath41 is embedded into the sobolev space @xmath153 with @xmath154 .",
    "further assume that the differential operator @xmath157 and the boundary operator @xmath8 have the orders @xmath171 and @xmath172 .",
    "given a function @xmath90 there exists a probability measure @xmath91 defined on @xmath173 ( as in lemma  [ l : gauss - rk ] ) such that the stochastic processes @xmath174 , @xmath175 given by @xmath176 are jointly gaussian processes with means @xmath177 ,",
    "@xmath178 and covariance kernels @xmath179 , @xmath180 defined on @xmath95 , respectively . in particular , they can be expanded as @xmath181 where @xmath98 and @xmath99 are the eigenvalues and eigenfunctions of the reproducing kernel @xmath34 and their related fourier coefficients are the independent normal variables @xmath182 and @xmath101 , @xmath103 .",
    "[ c : cov - matrix - gauss - rk - pb ] suppose all notations and conditions are as in theorem  [ t : gauss - rk - pb ] .",
    "given collocation points @xmath50 and @xmath183 , the random vector @xmath184 defined on @xmath95 has a multi - normal distribution with mean @xmath185 and covariance matrix @xmath186 , i.e. , @xmath187 where @xmath188 and @xmath189    while the covariance matrix @xmath186 may be singular , it is always positive semi - definite and therefore always has a pseudo - inverse @xmath190 .",
    "using corollary  [ c : cov - matrix - gauss - rk - pb ] , we can compute the joint probability density function @xmath191 of @xmath192 defined on @xmath95 . in the same way",
    ", we can also get the joint density function @xmath193 of @xmath194 defined on @xmath95 . by bayes rule",
    ", we can obtain the conditional probability density function of the random variable @xmath75 given @xmath192 .",
    "[ c : cond - prob - density ] we follow the notations of corollary  [ c : cov - matrix - gauss - rk - pb ] . for any fixed @xmath140 ,",
    "the random variable @xmath75 given @xmath192 defined on @xmath95 has a conditional probability density function @xmath195 where @xmath196    in particular , given the real observation @xmath197 , @xmath75 conditioned on @xmath198 has the probability density @xmath199 .",
    "this corollary is similar to the features of gaussian conditional distributions ( see  ( * ? ? ?",
    "* theorem  9.9 ) ) .",
    "suppose that @xmath51 is the unique solution of the deterministic elliptic pde @xmath200 where @xmath201 and @xmath202 .",
    "denote by @xmath203 and @xmath204 the values of @xmath205 and @xmath206 at the collocation points @xmath207 and @xmath208 , respectively : @xmath209    from now on we assume that the covariance matrix @xmath186 defined in corollary  [ c : cov - matrix - gauss - rk - pb ] is nonsingular and we therefore can replace pseudo - inverses with inverses .",
    "let @xmath210 , and denote by @xmath211 the conditional density function defined in corollary  [ c : cond - prob - density ] .",
    "we approximate the solution @xmath32 of by the optimal estimator @xmath212 derived in the previous section , i.e. , we maximize the conditional probability given the data values @xmath213 : @xmath214 by direct evaluation as in section  [ sec : stochasticproblems ] one finds that @xmath215 where the basis functions @xmath216 are defined in corollary  [ c : cond - prob - density ] .",
    "moreover , the estimator @xmath217 fits all the data values : @xmath218 and @xmath219 .",
    "this means that we have computed a collocation solution of the pde .",
    "also note that @xmath151 can be written as a linear combination of the kernels as in , i.e. , @xmath220 where @xmath221 .",
    "finally , we can perform a weak error analysis for @xmath222 as in proposition  [ prop : main - approximation ] , and deduce that @xmath223 where @xmath224 is defined in corollary  [ c : cond - prob - density ] , and @xmath225    because the form of the expression for the variance @xmath224 is analogous to that of the _ power function _ , we can use the same techniques as in the proofs from @xcite to obtain a formula for the order of @xmath226 .",
    "[ l : powerfun - order ] when @xmath157 is the second - order elliptic differential operator and @xmath8 is the dirichlet boundary condition , then @xmath227 where @xmath228 and @xmath229 is the fill distance of @xmath207 and @xmath208 .    since there is at least one collocation point @xmath230 such that @xmath231 we can use the multivariate taylor expansion of @xmath232 to introduce the order of @xmath226 , i.e. , @xmath233 where @xmath234 for some @xmath235 and @xmath155 .",
    "the rest of the proof proceeds as in ( * ? ? ?",
    "* chapter  14.5 ) and ( * ? ? ?",
    "* chapters  11.3 , 16.3 ) .",
    "using lemma  [ l : powerfun - order ] we can deduce the following proposition .",
    "when @xmath157 is the second - order elliptic differential operator and @xmath8 is the dirichlet boundary condition , then , for any @xmath148 , @xmath236 which indicates that @xmath237    therefore we say that the estimator @xmath151 converges to the exact solution @xmath32 of the pde  ( [ e : pde - ell - no - noise ] ) in all probabilities @xmath91 when @xmath229 goes to @xmath72 .",
    "sometimes we know only that the solution @xmath238 . in this case , as long as the reproducing kernel hilbert space is dense in the sobolev space @xmath153 with respect to its sobolev norm , we can still say that @xmath151 converges to @xmath32 in probability .",
    "let @xmath239 be gaussian with mean @xmath72 and covariance kernel @xmath240 on the probability space @xmath241 .",
    "we consider an elliptic pde driven by a gaussian additive noise @xmath26 @xmath242 and suppose its solution @xmath243 .",
    "since @xmath26 is a gaussian process , on some underlying probability space @xmath241 with a known correlation structure , we can simulate the values of @xmath26 at @xmath244 .",
    "consequently , we assume that the values @xmath203 and @xmath204 defined by @xmath245 are known . in this case ,",
    "@xmath246 , where @xmath247 and @xmath248 with @xmath249 being the covariance kernel of @xmath26 .",
    "let @xmath250 and @xmath251 be the probability density function of the random vector @xmath252 .    in order to apply the general interpolation framework developed in section  [ sec : stochasticproblems ]",
    ", we consider the product space @xmath253 we assume that the random variables defined on the original probability spaces are extended to random variables on the new probability space in the natural way : if random variables @xmath254 and @xmath255 are defined on @xmath95 and @xmath241 , respectively , then @xmath256 note that in this case the random variables have the same probability distributional properties , and they are independent on @xmath257 .",
    "this implies that the stochastic processes @xmath71 , @xmath174 , @xmath175 and @xmath26 can be extended to the product space @xmath257 while preserving the original probability distributional properties .",
    "fix any @xmath140 .",
    "let @xmath258 for each @xmath259 , and @xmath260 . using the methods in section  [ s : int - pde ] and",
    "theorem  [ t : gauss - rk - pb ] , we obtain @xmath261 where @xmath211 is the conditional probability density function of the random variable @xmath75 given the random vector @xmath262 .",
    "( here @xmath252 is viewed as given values . ) according to the natural extension rule , @xmath263 is consistent with the formula in corollary  [ c : cond - prob - density ] . if @xmath186 is nonsingular , then the approximation @xmath212 is solved by the maximization problem @xmath264 where @xmath186 and @xmath216 are defined in corollary  [ c : cov - matrix - gauss - rk - pb ] and  [ c : cond - prob - density ] .",
    "this means that its random coefficients are obtained from the linear equation system @xmath265    the estimator @xmath151 also satisfies the interpolation condition , i.e. , @xmath218 and @xmath219 .",
    "it is obvious that @xmath266 for each @xmath267 .",
    "since the random part of @xmath212 is only related to @xmath252 , we can formally rewrite @xmath268 as @xmath269 and @xmath212 can be transferred to a random variable defined on the finite - dimensional probability space @xmath270 , where the probability measure @xmath271 is defined by @xmath272 .",
    "moreover , the probability distributional properties of @xmath212 do not change when @xmath273 is replaced by @xmath270 .",
    "finally , we discuss the convergence analysis of this estimator .",
    "we assume that @xmath274 belongs to @xmath41 almost surely for @xmath275 .",
    "therefore @xmath32 can be seen as a map from @xmath276 into @xmath41 .",
    "so we have @xmath277 .",
    "we fix any @xmath140 and any @xmath148 .",
    "let the subset @xmath278 because @xmath279 , @xmath280 and @xmath281 for each @xmath282 and @xmath267 ( see  theorem  [ t : gauss - rk - pb ] ) we can deduce that @xmath283 where the variance of @xmath284 is @xmath285 ( see corollary  [ c : cond - prob - density ] ) .    similar to the analysis of the error bounds from section  [ s : int - pde ] , we also deduce the following proposition ( for more details see @xcite ) .",
    "when @xmath157 is the second - order elliptic differential operator and @xmath8 is the dirichlet boundary condition , then , @xmath286",
    "we consider the following stochastic heat equation with zero boundary condition @xmath287 driven by two types of space - time white noise ( colored in space ) @xmath10 of the form @xmath288 where @xmath289 , is a sequence of independent one - dimensional brownian motions , and @xmath290 .",
    "note that choosing the larger value of @xmath291 corresponds to a noise that is smoother in space .",
    "the spatial covariance function @xmath292 , @xmath290 , takes the specific forms @xmath293 and @xmath294    the solution of spde is given by ( for more details see , for instance , @xcite ) @xmath295 where @xmath296 from this explicit solution we can get that @xmath297    we discretize the time interval @xmath298 $ ] with @xmath299 equal time steps so that @xmath300 .",
    "we also choose the reproducing kernel @xmath301 , where @xmath302 is the matrn function with degree @xmath303 and shape parameter @xmath304 ( see example  [ ex : sobolev - spline ] ) .",
    "as collocation points we select uniform grid points @xmath305 and @xmath306 .",
    "let @xmath307 and @xmath308 .",
    "using our kernel - based collocation method we can perform the following computations to numerically estimate the sample paths @xmath309 .",
    "_ algorithm to solve spde  ( [ eq : num - exa ] ) : _    1 .",
    "initialize * @xmath310 * @xmath311 * @xmath312 * @xmath313 * @xmath314 2 .",
    "repeat for @xmath315 , i.e. , for @xmath316 * simulate @xmath317 * @xmath318    note that in the very last step the matrix @xmath319 is pre - computed and can be used for all time steps , and for different sample paths ; that makes the proposed algorithm to be quite efficient .",
    "we approximate the mean and variance of @xmath320 by sample mean and sample variance from @xmath321 simulated sample paths using the above algorithm , i.e. , @xmath322    figure  [ fig : distribution ] shows that the histograms at different values of @xmath323 and @xmath324 resemble the theoretical normal distributions .",
    "we notice a small shift in the probability distribution function of the solution @xmath43 , at times closer to zero , and when the noise is equal to @xmath325 ( figure  [ fig : distribution ] , left panel ) .",
    "this shift is due to the fact that @xmath325 is rougher in space than @xmath326 .",
    "our use of an implicit time stepping scheme reduces the frequency of the white noise , i.e. , @xmath327 .",
    "consequently , figure  [ fig : mean - variance ] shows that the approximate mean is well - behaved but the approximate variance is a little smaller than the exact variance .",
    "according to figure  [ fig : time - h - order ] we find that this numerical method is convergent as both @xmath38 and @xmath229 are refined . finally , we want to mention that the distribution of collocation points , the shape parameter , and the kernel itself were chosen empirically and based on the authors experience .",
    "as mentioned before , more precise methods are currently not available .",
    "a rigorous investigation of these questions , as well as determination of precise rates of convergence is reserved for future work .",
    "this new numerical approach can also be used to approximate systems of elliptic pdes with vector gaussian noises @xmath328 and @xmath329 or nonlinear pdes with gaussian noise @xmath26 , i.e. , @xmath330 where @xmath331 is a vector differential operator and @xmath332 is a vector boundary operator , and @xmath333 and @xmath334 ( see  @xcite ) .",
    "in addition to the additive noise case discussed here , we can also use the kernel - based collocation method to approximate other well - posed stochastic parabolic equations with multiplicative noise , e.g. , @xmath335 where @xmath336 .",
    "since @xmath337 , the algorithm for spde  ( [ e : spde - par - extend ] ) is similar to before :    1 .",
    "initialize * @xmath338 * @xmath339 * @xmath340 * @xmath341 2 .",
    "repeat for @xmath342 , i.e. , for @xmath343 * @xmath344 * @xmath345 * simulate @xmath346 * @xmath347    of course , now the matrix @xmath319 needs to be updated for each time step and for each sample path so that the algorithm is much costlier .",
    "[ d : rkhs ] a hilbert space @xmath41 of functions @xmath201 is called a _ reproducing - kernel hilbert space _ with a _ reproducing kernel _ @xmath40 if @xmath348 for all @xmath349 and all @xmath350 . here",
    "@xmath351 is the inner product of @xmath41 .    according to ( * ? ? ?",
    "* theorem  10.4 ) all reproducing kernels are positive semi - definite .",
    "* theorem  10.10 ) shows that a symmetric positive semi - definite kernel @xmath34 is always a reproducing kernel of a reproducing - kernel hilbert space @xmath41 .    if @xmath2 is open and bounded ( pre - compact ) and @xmath352 is symmetric positive definite , then mercer s theorem  ( * ? ? ?",
    "* theorem  13.5 ) guarantees the existence of a countable set of positive values @xmath353 with @xmath354 and an orthonormal base @xmath99 of @xmath355 such that @xmath34 possesses the absolutely and uniformly convergent representation @xmath356 this mercer series of @xmath34 implies that @xmath357    [ d : eigval_fun ] the sequences @xmath98 and @xmath99 given above are called the _",
    "eigenvalues _ and _ eigenfunctions _ of the reproducing kernel @xmath34 .",
    "since @xmath99 is orthonormal in @xmath355 we can compute the series expansion of the integral - type kernel @xmath94 defined in lemma  [ l : gauss - rk ] , i.e. , @xmath358 it is easy to check that @xmath359 is symmetric positive definite and @xmath360 and @xmath99 are the eigenvalues and eigenfunctions of @xmath94 .",
    "[ t : rkhs ] suppose that @xmath352 is a symmetric positive definite kernel on a pre - compact @xmath0",
    ". then its reproducing - kernel hilbert space is given by @xmath361 and the inner product has the representation @xmath362 where @xmath98 and @xmath99 are the eigenvalues and eigenfunctions of @xmath34 .",
    "we can verify that @xmath363 is an orthonormal base of @xmath41 .",
    "[ ex : sobolev - spline ]    the papers  @xcite show that the _ sobolev spline _ ( matrn function ) of degree @xmath364 , @xmath365 is a full - space green function of the differential operator @xmath366 , i.e. , @xmath367 , where @xmath368 is the modified bessel function of the second kind of order @xmath369 .",
    "the kernel function @xmath370 is a positive definite kernel whose reproducing - kernel hilbert space is equivalent to the @xmath371-based sobolev space of degree @xmath46 , i.e. , @xmath372 .",
    "its inner product has the explicit form @xmath373 where @xmath374 and @xmath375 according to ( * ? ? ?",
    "* theorem  1.4.6 ) , the reproducing - kernel hilbert space @xmath376 is endowed with the reproducing - kernel norm @xmath377 moreover , if the open bounded domain @xmath0 is regular then @xmath376 is equivalent to the @xmath371-based sobolev space of degree @xmath46 , i.e. , @xmath378",
    "in this section we define differential and boundary operators on sobolev spaces @xmath45 .",
    "the differential and boundary operators in this paper are well - defined since we assume that the open and bounded domain @xmath2 is _ regular _ ,",
    "i.e. , it satisfies a strong local lipschitz condition which implies a uniform cone condition ( see  ( * ? ? ?",
    "* chapter  4.1 ) ) .",
    "this means that @xmath2 has a regular boundary @xmath379 .",
    "let the notation for typical derivatives be @xmath380 we extend these derivatives to _ weak derivatives _",
    "( see  ( * ? ? ?",
    "* chapter  1.5 ) ) using the same symbol @xmath381 . using these weak derivatives ,",
    "the _ classical @xmath371-based sobolev space _",
    "@xmath45 is given by @xmath382 equipped with the natural inner product @xmath383 the weak derivative @xmath384 is a bounded linear operator from @xmath45 into @xmath355 when @xmath385 .",
    "moreover , @xmath386 is well - posed on the boundary @xmath379 when @xmath387 and @xmath388 and we denote that @xmath389 . the book  @xcite and the paper  @xcite show that @xmath390 can be extended to a bounded linear operator from @xmath45 into @xmath391 when @xmath388 because @xmath2 has a regular boundary @xmath379 .",
    "the @xmath391-inner product is denoted by @xmath392 and @xmath393    [ d : diff - bound ] a _ differential operator _",
    "@xmath394 is well - defined by @xmath395 and its _ order _ is given by @xmath396 a _ boundary operator _",
    "@xmath397 is well - defined by @xmath398 and its _ order _ is given by @xmath399    it is obvious that the differential operator @xmath157 and the boundary operator @xmath8 are bounded ( continuous ) linear operators on @xmath45 with values in @xmath371 whenever @xmath400 and @xmath401",
    ". much more detail on differential and boundary operators can be found in  @xcite .    if @xmath41 is embedded whose reproducing - kernel hilbert space @xmath41 is continuously embedded into the sobolev space @xmath45 . ] into @xmath45 then the eigenvalues @xmath98 and eigenfunctions @xmath99 of the reproducing kernel @xmath34 satisfy @xmath402 because @xmath363 is an orthonormal base of @xmath41 .",
    "when @xmath154 then @xmath45 is embedded into @xmath403 by the sobolev embedding theorem .",
    "this implies that @xmath404 because @xmath405 for each @xmath350 and @xmath34 is symmetric .",
    "based on these properties , we can introduce the following lemma .",
    "[ l : p - b - expan ] consider a differential operator @xmath157 with order @xmath400 and a boundary operator @xmath8 with order @xmath401 , where @xmath154 . if the reproducing - kernel hilbert space @xmath41 is embedded into the sobolev space @xmath45 , then @xmath406 where @xmath407 for each @xmath103 and @xmath98 and @xmath99 are the eigenvalues and eigenfunctions of the reproducing kernel @xmath34 .",
    "according to theorem  [ t : rkhs ] each @xmath349 can be expanded as @xmath408 . since @xmath363 is an orthonormal basis we have @xmath409 .",
    "let @xmath410 for each @xmath411 .",
    "then @xmath412 the proof is completed by remembering that @xmath157 and @xmath8 are bounded linear operators on @xmath45 .    if @xmath41 is embedded into @xmath45 , then for each @xmath385 , @xmath413 and @xmath414 , we have @xmath415 which implies that @xmath416 .",
    "let @xmath155 .",
    "the sobolev embedding theorem shows that @xmath417 .",
    "then we can obtain the following lemma .",
    "[ l : p - b - cov - expan ] consider a differential operator @xmath157 with order @xmath171 and a boundary operator @xmath8 with order @xmath172 , where @xmath154 . if the reproducing - kernel hilbert space @xmath41 is embedded into the sobolev space @xmath45 , then @xmath418 where @xmath98 and @xmath99 are the eigenvalues and eigenfunctions of @xmath34 .",
    "moreover , @xmath419 , @xmath420 and @xmath421 .",
    "we would like to thank phaedon - stelios koutsourelakis for the inspiration to solve spdes with a maximum likelihood - based approach .",
    "the work of igor cialenco was partially supported by the national science foundation ( nsf ) grant dms-0908099 .",
    "gregory e. fasshauer and qi ye acknowledge support from nsf grants dms-0713848 and dms-1115392 . the authors would like to thank the anonymous referee and the editors for their helpful comments and suggestions which improved greatly the final manuscript .",
    "m. k. deb , i. m. babuka , and j. t. oden , _ solution of stochastic partial differential equations using galerkin finite element techniques_. comput .",
    "methods appl .",
    "48 , 2001 , pp .",
    "63596372 .",
    "y. c. hon and robert schaback , _ the kernel - based method of lines for the heat equation_. university of gttingen , preprint , 2010 , http://num.math.uni-goettingen.de/schaback/research/papers/mktfthe.pdf .",
    "t. mller - gronbach , k. ritter and t. wagner , _ optimal pointwise approximation of a linear stochastic heat equation with additive space - time white noise_. monte carlo and quasi - monte carlo methods 2006 , berlin , 2008 , pp .",
    "577589 .",
    "f. nobile , r. tempone and c. g. webster , _ a sparse grid stochastic collocation method for partial differential equations with random input data_. siam j. numer .",
    "46 , no . 5 , 2008 , pp .",
    "23092345 .",
    "b. l. rozovskii , _ stochastic evolution systems : linear theory and applications to nonlinear filtering_. vol .",
    "35 of mathematics and its applications ( soviet series ) , kluwer academic publishers group , dordrecht , 1990 .    m. scheuerer , r. schaback and m. schlather , _ interpolation of spatial data  a stochastic or a deterministic problem?_. data page of r. schaback s research group , 2010 , http://num.math.uni-goettingen.de/schaback/research/papers/iosd.pdf ."
  ],
  "abstract_text": [
    "<S> in this paper we present the theoretical framework needed to justify the use of a kernel - based collocation method ( meshfree approximation method ) to estimate the solution of high - dimensional stochastic partial differential equations ( spdes ) . using an implicit time stepping scheme , we transform stochastic parabolic equations into stochastic elliptic equations . </S>",
    "<S> our main attention is concentrated on the numerical solution of the elliptic equations at each time step . </S>",
    "<S> the estimator of the solution of the elliptic equations is given as a linear combination of reproducing kernels derived from the differential and boundary operators of the spde centered at collocation points to be chosen by the user . </S>",
    "<S> the random expansion coefficients are computed by solving a random system of linear equations . </S>",
    "<S> numerical experiments demonstrate the feasibility of the method .    </S>",
    "<S> * keywords : * kernel - based collocation ; numerical solutions ; stochastic partial differential equation ; reproducing kernel ; matrn function ; gaussian process .    </S>",
    "<S> * ams subject classification : * 46e22 ; 65d05 ; 60g15 ; 60h15 ; 65n35 . </S>"
  ]
}