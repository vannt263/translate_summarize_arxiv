{
  "article_text": [
    "effective field theory ( eft ) methods allow the treatment of problems in which there is a separation of scales . in these theories",
    "dynamics at the low - energy scale , @xmath6 , say , is incorporated explicitly in the theory , while the degrees of freedom that enter the problem at the high - energy scale , @xmath7 , are integrated out .",
    "( see , refs .",
    "@xcite for pedagogical introductions to eft . ) the impact of modes with @xmath8 on dynamics for @xmath9 is then accounted for via a sequence of contact operators of increasing dimension .",
    "if there is no pre - determination as to which operators appear in this sequence then the theory is free of model assumptions about the high - energy dynamics .",
    "therefore , in general , all contact operators consistent with the symmetries that are applicable at the scale @xmath9 should be included in the eft expansion .",
    "the coefficients of these admissible contact operators encode the impact of high - energy physics on low - energy observables in a systematic and model - independent way .",
    "observables corresponding to momenta @xmath10 can be computed as an expansion in powers of @xmath11 , and the resultant formulae are model - independent predictions , depending only on the existence of the scale separation and the symmetries of the low - energy theory .",
    "one popular application of eft is to low - energy qcd . in this case",
    "the scale separation is between the mass of the pion , the pseudo - goldstone boson of qcd s spontaneously - broken ( approximate ) chiral symmetry , and the masses of other hadronic degrees of freedom .",
    "the eft which incorporates chiral symmetry and encodes this scale separation is known as chiral perturbation theory ( @xmath12pt )  @xcite .",
    "the @xmath12pt expansion for a hadronic observable is then an expansion in powers of @xmath11 , with loop diagrams introducing non - analytic dependence on this expansion parameter.pt can , of course , also be used to compute the low - energy dependence of observables on @xmath13 , where @xmath14 is any kinematic parameter with dimensions of mass . ]",
    "the dynamics at scale @xmath7 impacts this expansion through certain coefficients which are not determined _ a priori_. the low - energy symmetries of qcd mandate that once determined in one process these parameters  the  low - energy constants \" ( lecs ) of @xmath12pt  will appear in other processes too , thereby giving @xmath12pt predictive power once the lecs at a given order are known .",
    "there are some instances in which an lec can be rigorously computed from the underlying theory , but lattice calculations which do this for low - energy qcd exist in only a very few cases .",
    "in this situation the only model - independent way to find the lecs is to fit them to experimental data .",
    "such parameter estimation is thus a crucial component of @xmath12pt , and indeed of all eft programs .",
    "the standard method of determining lecs from data is to perform a fit using the eft expansion of that physical quantity at a fixed order , employing techniques such as least squares or maximum likelihood .",
    "but here we face several dilemmas as regards thebest \" way to obtain the lecs , including :    1 .",
    "which data should be used to determine the lec ?",
    "more data is available as the maximum energy of the data set is increased , but the reliability of a fixed order eft calculation decreases as the energy is increased .   2 .",
    "what order of eft calculation should be used to extract the lec ?",
    "the first one at which that lec appears , or the highest one to which the expansion has been computed ?   3 .",
    "how should prior constraints on lecs ( e.g. from the requirement of  naturalness \" with respect to the scale @xmath7 , or from other processes ) be incorporated into the fit ?     in an ideal situation none of these dilemmas matter , and all fitting paths lead to the same lec ( within errors ) .",
    "but if only somewhat imprecise experimental data is available in the region of validity of the eft then the extracted lec can be significantly sensitive to the manner in which the fit is done .    in this paper",
    "we argue that bayesian methods ( see e.g.  refs .",
    "@xcite ) are ideal for parameter estimation of lecs in efts , and that they resolve all the above dilemmas . in the bayesian approach",
    "the central object is the posterior probability distribution function ( pdf ) for the lecs of interest , say @xmath15 and @xmath16 , and we want their joint , conditional distribution given a data set @xmath3 : @xmath17 .",
    "bayes theorem gives us the following relation between this and the more - usually computed @xmath18 : @xmath19 here the first factor on the right - hand side is the  likelihood \" that is minimized in a @xmath4 or least - squares approach .",
    "it is through the second factor that prior information can be incorporated in the fit .",
    "( the factor in the denominator may be determined by the requirement of a normalized pdf for @xmath17 . )",
    "the fact that efts intrinsically depend on scale separation means that in an eft fit there is information available on the size of lecs prior to the analysis of the data . in a standard , perturbative eft with one high - energy scale",
    "the lecs should be `` natural '' with respect to the scale @xmath7 , i.e. @xmath0 when measured in units of @xmath7 .",
    "consequently we begin by encoding the fact that the lecs @xmath20 should be natural through the prior @xmath21 .",
    "we choose a @xmath22-dimensional gaussian prior , of width @xmath2 , since that is the least informed prior if we know the expectation value of @xmath23  @xcite .",
    "this yields a version of the  constrained curve fitting \" method recently advocated for lattice qcd data by lepage  @xcite , morningstar  @xcite and others ( see e.g.  refs .",
    "@xcite ) .",
    "constrained curve fitting therefore amounts to the computation of a posterior pdf with a gaussian prior at fixed order @xmath1 .",
    "we can eliminate sensitivity to the precise value of @xmath2 by averaging the resulting pdf over a range of @xmath2 values , thereby incorporating in our result the inherent ambiguity in the notion of  @xmath0 \" lecs . ",
    "marginalizing \" in this way over unwanted parameters is a technique used to obtain posterior pdfs that incorporate the uncertainty that results from systematic differences in the parameters which are obtained when fits are done in different ways .",
    "therefore we also marginalize over the order @xmath1 of the eft calculation .",
    "this necessitates additional marginalization over the lecs that appear at orders @xmath24 and so amount to  nuisance parameters \" in our effort to extract @xmath15 and @xmath16 . our final formula for the posterior pdf @xmath17 , eq .",
    "( [ ex : final : pdf ] ) , therefore involves a sum over @xmath1 , as well as integrals over @xmath2 and @xmath25 .",
    "the resulting central values and uncertainties for @xmath15 and @xmath16 incorporate a rigorous accounting of the theoretical uncertainty present in a low - order eft fit .",
    "in section  [ sec : bayes ] we review bayesian methods as well as the standard maximum - likelihood technique , derive the formula for the ",
    "augmented @xmath4\"a @xmath4 which penalizes unnatural values of the fit parameters  and derive our final formula  see eq .",
    "( [ ex : final : pdf])for @xmath17 . in sec .",
    "[ sec : toy ] we apply both the augmented @xmath4 and the formula ( [ ex : final : pdf ] ) to the  toy \" problem of extracting the coefficients of a power - series approximant to the function @xmath26  from pseudo - data that is statistically distributed around the curve @xmath27 .",
    "we show that these two bayesian methods provide an extraction which does not depend on the interval over which the fit is performed .",
    "we also show how they avoid certain ambiguities that are present in @xmath4-minimization .",
    "and we find that reliable information on power - series coefficients can be gleaned from the data even in cases where standard techniques are powerless .    in sec .",
    "[ sec : nucleonmass ] we generate pseudo - data with small errors from the @xmath12pt function for the nucleon mass as a function of the pion mass .",
    "we show that methods based on eq .",
    "( [ ex : final : pdf ] ) are capable of determining the nucleon mass in the chiral limit , @xmath5 , from pseudo - data in the pion - mass range @xmath28@xmath29 mev .",
    "we follow this in sec .",
    "[ sec : model ] with a similar analysis of pseudo - data generated from an underlying function @xmath30 that deviates from the @xmath12pt form above 500 mev .",
    "bayesian extractions of @xmath5 from such pseudo - data generated in different ranges of @xmath6 yield consistent results .",
    "this conclusion holds even for fit windows that extend significantly above the pion mass where the @xmath12pt from for @xmath30 ceases to be valid .",
    "these three problems are variants of polynomial regression using bayesian methods , a problem that has received extensive treatment in the literature .",
    "a gaussian prior for the polynomial coefficients is a common choice  @xcite .",
    "however , many authors  @xcite also incorporate the ` commonly held belief that the [ coefficients ] will tend to decrease in absolute value as the order increases '  @xcite .",
    "the idea of marginalizing over the order of the polynomial fit is also not new .",
    "it is discussed extensively in studies of  bayesian model averaging \" , e.g. refs .  @xcite . in eft applications the basis for regression includes non - polynomial functions and , as will be discussed extensively in sec .",
    "[ sec : toy ] , the fit form only has a limited region of applicability .",
    "these peculiarities make the problem of parameter estimation in efts one that has  as far as we can tell  evaded treatment in the bayesian literature until now .    on the eft side bayesian methods",
    "have been applied to chiral extrapolations of quenched lattice data on the nucleon mass as a function of the pion mass in ref .",
    "@xcite . in this",
    "work a technique based on using priors obtained from a subset of the lattice data in the analysis of the full data set was employed .",
    "such iterative methods are frowned upon in the bayesian literature  @xcite .",
    "meanwhile , trottier _ et al .",
    "_ @xcite have  among other applications  employed bayesian methods to perform extrapolations of the static - quark self energy as a function of the lattice size @xmath31 .",
    "the extrapolant in this problem can be computed using lattice effective field theory and trottier et al",
    ". used  constrained curve fitting \" to stabilize the fit of certain coefficients in that eft expansion , thereby incorporating some prior information regarding the naturalness of coefficients in the eft expansion in their fit .",
    "however , hadronic observables , such as the behavior of the nucleon mass as a function of @xmath6 , were not considered .",
    "this paper seeks to develop a general strategy for parameter estimation in efts : one based only on the expectation that these parameters are  natural \" with respect to the underlying scale .",
    "we believe that such priors provide a more stable and reliable estimation of coefficients than standard fitting techniques .",
    "this conclusion seems very general , and should apply to a wide variety of eft situations .",
    "we discuss those conclusions in sec .",
    "[ sec : conclusion ] and give a sampling of possible applications .",
    "in this section we outline the way in which we will use data to estimate the parameters in an eft . after a brief review of the standard maximum - likelihood technique",
    "we describe the basics of bayesian probability theory and explain how it can be used for this problem . in particular we show how prior information on an eft s low - energy constants can be systematically included in the data analysis , and how the impact of higher - order effects on the extracted lecs can be accounted for by marginalization .    throughout this section",
    "we denote a set of data on a particular observable by @xmath32 , with @xmath33 an individual measurement at point @xmath34 and @xmath35 the corresponding uncertainty . the functional form which we want to use to describe the observable",
    "is given by @xmath36 , where @xmath36 depends on a set of eft parameters @xmath37 which we wish to determine from the data set @xmath3 .",
    "in any eft application ( and in many others too ! ) @xmath38 need not and should not be assumed to be the correct functional form for the observable for all @xmath39 .",
    "instead we only assume that there is some @xmath39 domain , @xmath40 say , where @xmath41 can be systematically improved via the addition of more terms ( and hence more parameters ) .",
    "@xmath42 would then be the breakdown scale of the eft expansion represented by @xmath41 .",
    "the maximum - likelihood method is often used to determine the unknown parameters @xmath43 . in this method one",
    "tries to find those values of the parameters that maximize the probability of generating the data set @xmath3 , assuming that @xmath36 is indeed the true theory , i.e. we seek to find @xmath44 such that @xmath45 is maximum , where @xmath46 denotes the probability of @xmath47 _ given _ @xmath48 .",
    "( here and below the notation @xmath49 is used to specify both the functional form @xmath36 as well as the particular values of @xmath43 . ) the maximum - likelihood method simplifies further if the data are independent and the noise due to measurement is gaussian . in this case",
    "the probability of finding the data given the underlying functional form @xmath36 can be written as @xmath50 where @xmath51 finding the maximum of @xmath49 is  equivalent to minimizing @xmath4 , giving justification to the widely used method of least - squares .",
    "in fact , the least - squares likelihood of eq .",
    "( [ bayes : maxlike ] ) is the least biased pdf in the case that the means @xmath33 and variances @xmath35 of the @xmath52 uncorrelated measurements are known .",
    "this statement can be proven via the `` principle of maximum entropy '' @xcite which states that the least - biased pdf is found by maximizing @xmath53\\ ] ] under the constraints of the available information , where @xmath54 is a ` measure ' for the maximum entropy calculation ( see app .",
    "[ sec : maxent ] ) .      the above approach , while standard , has three shortcomings as far as the particular application we have in mind is concerned .",
    "the first is that maximizing eq .",
    "( [ bayes : likelihood ] ) is not exactly the problem we want to solve .",
    "it assumes that the theory , in particular the values of the parameters @xmath43 , is given , while in fact the data are given and we want to infer values for @xmath43 .",
    "mathematically we are really interested in @xmath55 ( provided we assume a particular functional form @xmath41 to describe the data ) .",
    "the question of which of these two probabilities we should try to maximize is related to a long - lasting discussion about the correct interpretation of probability , and we do not wish to comment on this here ( see e.g.  @xcite ) . as we will see below , the two probabilities are related by bayes theorem .",
    "the second issue is of a more practical nature .",
    "the maximum - likelihood approach assumes no prior knowledge of the values of the parameters @xmath43 . while there are circumstances in which this is indeed appropriate , there are other cases in which information on the parameters @xmath43 is available before the data analysis .",
    "this information could come from the naturalness arguments mentioned above , from symmetry arguments , or via constraints from other experimental data .",
    "incorporating such knowledge into @xmath56 refines the eft parameter estimate obtained from the data set @xmath3 , and is very easy within the framework of bayesian statistics @xcite .",
    "finally , the entire discussion thus far assumes a particular functional form for @xmath41 .",
    "a more general approach would allow the extraction of relevant lecs from data using different eft forms , for example obtained by carrying the eft calculation to different orders in the @xmath11 expansion .",
    "such marginalization is straightforward once @xmath57 is in hand .",
    "it amounts to standard manipulations of conditional probabilities ( see e.g.  @xcite ) .",
    "bayes theorem relates the probability of a certain parameter set being correct given a set of data @xmath3 , @xmath55 , to the probability @xmath49 of obtaining the data @xmath3 given the theory @xmath36 with a specific @xmath43 , @xmath58 here , @xmath55 is referred to as the posterior pdf , while @xmath59 is called the prior pdf and incorporates information on the parameters @xmath43 that we have prior to analysis of the data .",
    "@xmath60 is the probability to find the data @xmath3 regardless of the specific values of the @xmath61 and can often be absorbed in a normalization constant , yielding @xmath62 here we will take the @xmath61 s to be dimensionless . in that case",
    "they are so - called  location \" parameters , and if there is no prior information on @xmath43 then @xmath59 should be taken to be a constant  @xcite .",
    "consequently one finds that @xmath63 which leads us back to the method of maximum likelihood described in the previous section .    however , in the case that prior information on the parameters _ is _ available a constant @xmath59 is not appropriate and one has to decide how to incorporate the available information in the prior pdf",
    "this is not always straightforward , as can be seen by the example of naturalness that is of interest to us here . in that case",
    "the information we want to encode in @xmath59 is that the parameters @xmath43 are supposed to be natural , i.e.  of order @xmath0 .",
    "however , neither of these statements gives us much guidance as to what form to choose for @xmath59 .",
    "for instance , one way to incorporate the fact that @xmath64 would be to assign a uniform prior in the region @xmath65 : @xmath66 however , this is a very strict prior outside the range @xmath67 $ ] , and while lecs with magnitude larger than @xmath68 might not be ideal for the convergence of the eft it is not clear that they should be rejected entirely .",
    "we will incorporate naturalness in a less restrictive form .",
    "we choose the function @xmath36 to contain @xmath22 parameters @xmath61 , and we assume only that @xmath41 is linear in these parameters , i.e. we write @xmath69 where the @xmath70 are basis functions , e.g.  monomials of order @xmath71 .",
    "we will refer to @xmath1 as the order of the eft calculation .",
    "so as to simplify the notation we replace e.g. @xmath57 by @xmath72 , since specifying the order @xmath1 usually defines @xmath41 in a given eft .",
    "we then interpret the naturalness assumption as a constraint on the ensemble average of the sum of squares of the coefficients  @xcite : @xmath73 where @xmath2 encodes our interpretation of what ",
    "@xmath0 \" means .",
    "we want to find the least informed pdf that incorporates the information in eq .",
    "( [ bayes : ensembleave ] ) . as discussed above this can be achieved by the application of the maximum entropy principle . using the constraint of eq .",
    "( [ bayes : ensembleave ] ) we arrive at the prior pdf ( see app .",
    "[ sec : maxent ] ) @xmath74 which is a multivariate gaussian distribution with mean @xmath75 and standard deviation @xmath2 and can thus be written as @xmath76 with @xmath77 note that since our testable information ( [ bayes : ensembleave ] ) did not include  any statement about correlations between the lecs we have obtained a @xmath78 in which the @xmath61 s are uncorrelated . if correlations between different coefficients are known to exist then they should ( and can ) be part of the testable information provided to the maximum - entropy principle .    combined with a gaussian likelihood function @xmath49",
    "the probability of finding a theory @xmath36 given the data @xmath3 again assumes a gaussian form , @xmath79 where we follow ref .",
    "@xcite and introduce an `` augmented @xmath4 '' , @xmath80 the expectation values of the parameters @xmath61 are then determined by finding the maximum of the probability @xmath81which is equivalent to a least - squares problem with @xmath4 replaced by @xmath82 .",
    "this form has the advantage that techniques developed for the standard least - squares approach can be adopted , and certain manipulations can be performed analytically , as we will now demonstrate .    the standard @xmath4 can be written in matrix form as @xmath83 where the @xmath84 matrix @xmath85 is defined as @xmath86 the @xmath87-component vector @xmath88 is given by @xmath89 and @xmath90 the augmented @xmath4 can be written in similar form by simply replacing the matrix @xmath85 by @xmath91 , @xmath92 where @xmath93 is the @xmath84 identity matrix .",
    "the minimum of @xmath82 is then simply given by @xmath94    from these formulae it is easy to see how the size of @xmath2 influences the result of the regression . as long as @xmath95 , where @xmath96 is the smallest eigenvalue of @xmath85",
    ", it will have only very little effect on the extraction of @xmath97 . in this case the constraint by the prior information is very weak .",
    "however , for the case that @xmath98 is much larger than the smaller eigenvalues of @xmath85 , i.e.  @xmath2 is small , the prior information of eq .",
    "( [ bayes : ensembleave ] ) amounts to a strong constraint on the allowed parameter values and will dominate the solution @xmath97 .",
    "the augmented @xmath4 is thus of most use when @xmath99 .",
    "the naturalness constraint can then help to refine and distinguish between what would otherwise be shallow and/or equivalent minima in the @xmath4 hypersurface .",
    "in general the theory underlying the data can depend on a large number of parameters .",
    "when we are only interested in a subset of these parameters the other ( `` nuisance '' ) parameters can be eliminated from the analysis by marginalization .",
    "suppose that the theory depends on the parameter sets @xmath47 and @xmath48 , where @xmath47 stands for the parameters of interest while @xmath48 denotes all nuisance parameters .",
    "standard probability theory tells us that the pdf @xmath100 can be obtained by summing / integrating the probability @xmath101 over all possible values of @xmath48 , @xmath102 it is interesting to note a similarity between marginalization and effective field theory . in both cases",
    "one `` integrates out '' those degrees of freedom one is not explicitly interested in ( @xmath48 and heavy degrees of freedom , respectively ) and takes their contributions into account implicitly . as we shall now see , in the case of linear dependence of @xmath41 on the parameters the similarity is particularly striking as the marginalization involves a gaussian integral over the irrelevant degrees of freedom .",
    "once the marginalized pdf is obtained , the problem of estimating the parameters @xmath47 is reduced to a lower dimensionality , thereby reducing the numerical cost . finding the marginalized pdf has its own cost ;",
    "however , for the case of a gaussian posterior the marginalization integral can be performed analytically .",
    "we will be interested in the case where @xmath47 stands for a subset of low - order parameters @xmath103 , and @xmath48 denotes higher - order parameters @xmath104 with @xmath105 .",
    "we want to obtain the marginalized pdf @xmath106 , which is given by marginalization of the posterior of eq .",
    "( [ bayes : gaussposterior ] ) over @xmath107 , @xmath108 as explained in the previous subsection we can write @xmath82 as @xmath109 performing the integration over the parameters @xmath107 one again obtains a gaussian pdf , @xmath110,\\ ] ] where @xmath111 and @xmath112 are related to @xmath91 and @xmath88 by @xmath113 where @xmath114 and @xmath115 with @xmath116 an @xmath117 , @xmath118 an @xmath119 , @xmath120 an @xmath121 , and @xmath122 an @xmath123 matrix , respectively .",
    "the estimates for the parameters @xmath124 are now given by @xmath125 a straightforward calculation ( see app .  [",
    "sec : margovera ] ) shows that these results for @xmath126 are identical to the ones obtained from the non - marginalized posterior @xmath81 .",
    "the first @xmath127 entries in the covariance matrix are also unaffected .",
    "therefore marginalization has no effect on the parameter estimates in the case that the posterior pdf is gaussian .",
    "but , for a general posterior pdf , the estimates of the parameters @xmath124 after marginalization can differ from the ones obtained from the unmarginalized pdf .",
    "the marginalized probability @xmath128 still depends on @xmath1 and @xmath2 , i.e.  the choice as to which order of the eft expansion is used to obtain the fitting function and the meaning of what is really  natural \" for the @xmath61 s . neither the exact order of the polynomial from which we estimate @xmath124 nor the exact value of @xmath2 are of specific interest to us .",
    "ultimately we are only interested in what the data can tell us about the value of @xmath124 , and the pdf of interest is really @xmath129 , i.e.  we want to eliminate @xmath1 and @xmath2 .",
    "we now show how the probability @xmath129 can be obtained from the familiar likelihood @xmath130 by marginalization and bayes theorem ( also see ref .",
    "@xcite for marginalization over @xmath2 ) .    to construct @xmath129",
    "we marginalize @xmath1 and @xmath2 over suitable domains : @xmath131 using bayes theorem we can rewrite the right - hand side as @xmath132 in an @xmath1th - order calculation with @xmath133 there are additional parameters in the eft function @xmath41 .",
    "thus , to calculate @xmath134 , we introduce them by marginalization : @xmath135 inserting eq .",
    "( [ ex : final : amarg ] ) in eq .",
    "( [ ex : final : bayes ] ) we find @xmath136 the first probability in the numerator should be independent of our choice of @xmath2 , i.e. @xmath137 , and the last two terms in the numerator of eq .",
    "( [ ex : final : combined ] ) can be rewritten as @xmath138 where in the last step we have used that @xmath1 and @xmath2 should be independent of each other .",
    "this gives as our final pdf @xmath139 eq .",
    "( [ ex : final : pdf ] ) is a key result of this paper .",
    "its derivation employs only bayes theorem and the standard rules of probability .",
    "it thus encodes , in a completely general way , an eft fitting strategy that accounts for systematic differences in fits due to results obtained with different eft orders .",
    "it can also incorporate the requirement that eft parameters be natural .",
    "furthermore , the integrals over @xmath107 that appear tend to reduce the impact on the pdf of data points where higher - order terms in the eft are large , and",
    "so eq .  ( [ ex : final : pdf ] ) includes the notion of  theoretical uncertainty \" in the fitting procedure in a well - defined way .",
    "while eq .",
    "( [ ex : final : pdf ] ) is general the manner in which the naturalness requirement is implemented is open to interpretation . for the rest of this paper we will use the maximum - entropy prior ( [ bayes : prior ] ) for our analyses .",
    "priors in @xmath1 and @xmath2 also need to be specified",
    ". we will let the sum over @xmath1 run from @xmath140 to some @xmath141 .",
    "in general one should try to ensure that the parameter estimates for @xmath124 are not sensitive to @xmath141 .",
    "( technically this is an implementation of an  improper prior \" on @xmath1 via a limiting procedure . )",
    "we do not have any information that would lead us to favor one value of @xmath1 over the other , and we therefore assign a uniform prior to @xmath1 , @xmath142    similar reasoning applies to the prior on @xmath2 .",
    "we integrate over some region @xmath143 .",
    "if the data analysis is being done in a sensible choice of units we would expect that values of @xmath2 close to 1 will be favored , but we do not wish to bias the fit unduly in this regard , and so we choose a uniform prior .",
    "however , since @xmath2 is a scale parameter the prior should be uniform in @xmath144 @xcite , not @xmath2 , and we thus obtain @xmath145    therefore while @xmath81 is gaussian , the final pdf of eq .",
    "( [ ex : final : pdf ] ) after marginalization over @xmath1 and @xmath2 is no longer of gaussian form .",
    "this means that  unlike the case defined by eqs .",
    "( [ bayes : gaussmargdef ] ) and ( [ bayes : chiaugdef])estimates for @xmath124 can not be determined from a simple matrix multiplication . instead , given the pdf @xmath129 we calculate the expectation values and variances of the parameters @xmath124 , according to : @xmath146 where we have assumed @xmath129 to be normalized .",
    "this reveals another advantage of the bayesian approach : in addition to the uncertainty in the data , the variance @xmath147 includes the uncertainties due to fitting at different @xmath1 s and choosing different @xmath2 s .",
    "these effects are included in the final pdf @xmath129 .",
    "indeed , it is useful to think of eq .",
    "( [ ex : expval ] ) as a weighted sum over the possible values of @xmath1 , where the weight is given by the probability @xmath148 ( c.f . ref .",
    "@xcite ) . if one specific value of @xmath1 is much more likely than any other , the pdf @xmath129 is dominated by this specific term in the sum and our approach will yield approximately the same answers as a fit solely at that particular order .",
    "this is in contrast to much of the eft literature where assumptions about @xmath1 are often implicitly made in parameter estimation .",
    "equation  ( [ ex : final : pdf ] ) forces and allows such assumptions to be explicitly included in the extraction of lecs from data .",
    "a similar argument holds for @xmath2 : if the pdf @xmath149 has a spike near a particular value of @xmath2 then the integral over @xmath2 will be dominated by that value , and a fit with @xmath2 fixed would be quite successful . the advantage of eq .",
    "( [ ex : final : pdf ] ) is that it makes no assumptions about whether special cases associated with such peaks in the @xmath1 and @xmath2 pdfs are realized or not .",
    "instead marginalization lets the data ( together with the minimal assumptions encoded in our priors ) determine which values of @xmath2 and @xmath1 will be important in the extraction of the @xmath61 s .",
    "in the following we consider an example that allows us to illustrate the main features and advantages of bayesian methods in fitting data in order to extract eft parameters . instead of real data from an actual experiment we choose to generate artificial data from the function @xmath150 for @xmath151 . while we are not aware of any physical quantity that is described by @xmath152 , it exhibits several features that commonly appear in the analysis of data relevant to efts .",
    "the function @xmath152 is nonanalytic for @xmath153 , but within a finite radius of convergence @xmath42 it can be approximated to arbitrary precision by a power series . with the application to efts in mind",
    "we think of @xmath42 as the `` high - energy '' scale .",
    "therefore coefficients in the expansion of @xmath27 in powers of @xmath39  will be natural when written in units of @xmath42 . because of the particular argument we have chosen for the tangent function in eq .",
    "( [ ex : func ] ) the radius of convergence of the taylor series for @xmath152 is @xmath154 , which simplifies the subsequent discussion .",
    "it has the consequence that the absolute values of the coefficients in the power series expansion of @xmath152 , @xmath155 are  natural \" for at least the first 10 terms , with an rms value of around 3 .",
    "however it is interesting to note that the coefficients do _ not _ decrease with increasing order , and so priors based on the expectation that they do  @xcite could potentially lead to misleading results .",
    "we generate `` data '' that are normally distributed about the curve @xmath152 and we assign a relative error @xmath156 at each value of @xmath39 .",
    "the data are then given by @xmath157 where the @xmath158 are random numbers that are normally distributed with mean @xmath159 and variance  @xmath160 ... for the following example we generate two data sets @xmath161 and @xmath162 , the first for @xmath163 and the second for @xmath164 , each containing 10 data points with @xmath165 .",
    "the data are shown in fig .",
    "[ ex : datamax05err5 ] and can be found in app .",
    "[ sec : data ]      our aim is to extract the coefficients of a polynomial @xmath169 of degree @xmath1 from a fit to the data , where @xmath170 as can be seen in fig .",
    "[ ex : fullvsexp ] , the power series expansion of @xmath152 up to order 3 does not reproduce the complete function for @xmath171 , while at order 7 good agreement is found up to @xmath172 .      in this section",
    "we explore three methods for extracting the coefficients @xmath15 and @xmath16 from the two different data sets shown in fig .",
    "[ ex : datamax05err5 ] .",
    "first , we review the results obtained via a standard maximum - likelihood fit at different orders .",
    "then we examine the way in which the augmented @xmath4 obtained above can be used to improve those results .",
    "finally , we show how marginalization over @xmath1 and @xmath2 retains the improvement seen due to the use of the @xmath175 , and deals with the sometimes awkward issue of which values should be chosen for those two parameters .",
    "we begin with a standard maximum - likelihood analysis of the data .",
    "since our data are normally distributed , this reduces to a @xmath4-minimization problem as explained above .",
    "the first issue is the choice of the order of the polynomial .",
    "for the first data set with @xmath176 a polynomial of low order might result in values of the coefficients close to the ones in eq .",
    "( [ ex : funcexp ] ) .",
    "but it seems clear from fig .",
    "[ ex : fullvsexp ] that for data corresponding to larger values of x a fit at low ( e.g. third ) order will not give accurate results for the true coefficients in the power series of @xmath152 .",
    "conversely too high an order leads to an over - constrained fit .",
    "if , as is often the case , the function @xmath152 is not known we will not know what order in @xmath1 is necessary in order to obtain reasonable likelihoods .",
    "so here we perform the analysis at several orders , @xmath177 .",
    "we start with the data set @xmath161 for which @xmath178 .",
    "the results for the first few coefficients at each order together with the corresponding @xmath4 per degree of freedom are given in table  [ ex : standresultd1 ] .",
    "t.  d.  cohen , j.  l.  friar , g.  a.  miller and u.  van kolck ,  phys .",
    "c * 53 * , 2661 ( 1996 ) .   v.  pascalutsa and d.  r.  phillips ,  phys .",
    "c * 67 * , 055202 ( 2003 ) .",
    "u.  van kolck ,  nucl .",
    "phys .  a * 645 * , 273 ( 1999 ) .   d.  b.  kaplan , m.  j.  savage and m.  b.  wise ,  phys .",
    "b * 424 * , 390 ( 1998 )  [ arxiv : nucl - th/9801034 ] .",
    "m.  c.  birse , j.  a.  mcgovern and k.  g.  richardson ,  phys .",
    "b * 464 * , 169 ( 1999 )  [ arxiv : hep - ph/9807302 ] .",
    "s.  f.  gull , `` bayesian inductive inference and maximum entropy '' in _ maximum entropy and bayesian methods in science and engineering _ , vol .  1 ( ed",
    ". g.  j.  erickson and c.  r.  smith ) , kluwer , dortrecht , 1988 .",
    "s.  r.  beane , m.  malheiro , j.  a.  mcgovern , d.  r.  phillips and u.  van kolck ,  phys .",
    "b * 567 * , 200 ( 2003 )  [ erratum - ibid .",
    "b * 607 * , 320 ( 2005 ) ]  [ arxiv : nucl - th/0209002 ] ;  s.  r.  beane , m.  malheiro , j.  a.  mcgovern , d.  r.  phillips and u.  van kolck ,  nucl .",
    "a * 747 * , 311 ( 2005 )  [ arxiv : nucl - th/0403088 ] .",
    "m.  c.  m.  rentmeester , r.  g.  e.  timmermans and j.  j.  de swart ,  phys .",
    "c * 67 * , 044001 ( 2003 )  [ arxiv : nucl - th/0302080 ] .",
    "j.  hoeting , d.  madigan , a.  raftery and c.  volinsky ,  statist .",
    "* 14 * , 382 - 401 ( 1999 ) ."
  ],
  "abstract_text": [
    "<S> we demonstrate and explicate bayesian methods for fitting the parameters that encode the impact of short - distance physics on observables in effective field theories ( efts ) . </S>",
    "<S> we use bayes theorem together with the principle of maximum entropy to account for the prior information that these parameters should be natural , i.e. @xmath0 in appropriate units . </S>",
    "<S> marginalization can then be employed to integrate the resulting probability density function ( pdf ) over the eft parameters that are not of specific interest in the fit . </S>",
    "<S> we also explore marginalization over the order of the eft calculation , @xmath1 , and over the variable , @xmath2 , that encodes the inherent ambiguity in the notion that these parameters are @xmath0 . </S>",
    "<S> this results in a very general formula for the pdf of the eft parameters of interest given a data set , @xmath3 . </S>",
    "<S> we use this formula and the simpler  augmented @xmath4 \" in a toy problem for which we generate pseudo - data . </S>",
    "<S> these bayesian methods , when used in combination with the  naturalness prior \" , facilitate reliable extractions of eft parameters in cases where @xmath4 methods are ambiguous at best . </S>",
    "<S> we also examine the problem of extracting the nucleon mass in the chiral limit , @xmath5 , and the nucleon sigma term , from pseudo - data on the nucleon mass as a function of the pion mass . </S>",
    "<S> we find that bayesian techniques can provide reliable information on @xmath5 , even if some of the data points used for the extraction lie outside the region of applicability of the eft . </S>"
  ]
}