{
  "article_text": [
    "let @xmath0 and @xmath1 be two natural numbers .  for an integer @xmath2 and a matrix @xmath3 ,",
    "the standard low rank approximation problem can be formulated as @xmath4 where @xmath5 denotes the rank of the matrix @xmath6 and @xmath7 denotes the frobenius norm of matrices .",
    "it is well known that the solutions to this problem can be given using the singular value decompositions  ( svds ) of @xmath8 through the hard thresholding operations on the singular values : the solutions to  ( [ pca ] ) are given by @xmath9 where @xmath10 is a svd of @xmath8 and @xmath11 is the diagonal matrix obtained from @xmath12 by thresholding :  keeping only @xmath13 largest singular values and replacing other singular values by 0 along the diagonal .",
    "this is also referred to as ektart - young - mirsky s theorem  ( @xcite ) and is closely related to the pca method in statistics  @xcite .",
    "the solutions to  ( [ pca ] ) as given in  ( [ hardthresholding ] ) suffer from the fact that none of the entries of @xmath14 is guaranteed to be preserved in @xmath15 . in many real world problems ,",
    "one has good reasons to keep certain entries of @xmath8 unchanged while looking for a low rank approximation .",
    "for example , if svd is used in quadrantally - symmetric two - dimensional  ( 2-d ) filter design , as pointed out in  ( @xcite ) , it might lead to a degraded construction in some cases as it is not able to discriminate between the important and unimportant components of @xmath14 . to address this problem , a weighted least squares matrix decomposition  ( wlr ) method",
    "was first proposed by shpak  @xcite .",
    "following his idea of assigning different weights to discriminate between important and unimportant components of the test matrix , lu , pei , and wang  ( @xcite ) designed a numerical procedure to find the best rank @xmath13 approximation of the matrix @xmath8 in the _ weighted frobenius _ norm sense : @xmath16 where @xmath17 is a weight matrix and @xmath18 denotes the hadamard product .    in 1987 ,",
    "golub , hoffman , and stewart were the first to consider the following _ constrained _ low rank approximation problem  @xcite :    given @xmath19 with @xmath20 and @xmath21 , find @xmath22 such that  ( with @xmath23 ) @xmath24 that is , golub , hoffman , and stewart required that the first few columns , @xmath25 of @xmath8 must be preserved when one looks for a low rank approximation of @xmath26 as in the standard low rank approximation , the constrained low - rank approximation problem of golub , hoffman , and stewart also has a closed form solution .",
    "@xcite [ theorem 1 ] with @xmath27 and @xmath28 , the solutions @xmath22 in  ( [ golub s problem ] ) are given by @xmath29 where @xmath30 and @xmath31 are the projection operators to the column space of @xmath32 and its orthogonal complement , respectively .",
    "[ remark1 ] according to section 3 of  ( @xcite ) , the matrix @xmath22 is unique if and only if @xmath33 is unique , which means the @xmath34th singular value of @xmath35 is strictly greater than @xmath36th singular value .",
    "when @xmath22 is not unique , the formula for @xmath22 given in theorem  [ theorem 1 ] should be understood as the membership of the set specified by the right - hand side of  ( [ ghs ] ) .",
    "we will use this convention in this paper .",
    "inspired by theorem  [ theorem 1 ] above and motivated by applications in which @xmath32 may contain noise , it makes more sense if we require @xmath37 small  ( as in the case of the total least squares ) instead of asking for @xmath38 .",
    "this leads us to consider the following problem : let @xmath39 and @xmath40 , find @xmath41 such that @xmath42 this problem can be viewed as `` approximately '' preserving ( controlled by a parameter @xmath43 ) , instead of requiring exactly matching , in the first few columns .",
    "indeed , as in a related work of background estimation , shadows and specularities removal from face images , and domain adaptation problems in computer vision and machine learning in  ( @xcite ) , a closely related weighted low - rank approximation is shown to be more effective .",
    "note that multiplying a matrix from right by @xmath44 is same as multiply @xmath43 to each element of the first @xmath45 columns of that matrix and leaving the rest of the elements unchanged .",
    "as it turns out , this formulation can be viewed as generalized total least squares problem  ( gtls )  @xcite .",
    "problem  ( [ weighted problem ] ) is a special case of weighted low - rank approximation with a rank - one weight matrix and can be solved in closed form by using a single svd of the given matrix @xmath46  @xcite .",
    "a careful reader must also note that , both problems  ( [ golub s problem ] ) and  ( [ weighted problem ] ) can be cast as special cases of structured low - rank problems with element - wise weights  @xcite . in this paper",
    ", we consider a more general point - wise multiplication with a matrix @xmath47 of non - negative terms : @xmath48 this is the weighted low rank approximation problem studied first when @xmath49 is an indicator weight for dealing with the missing data case ( @xcite ) and then for more general weight in machine learning , collaborative filtering , 2-d filter design , and computer vision  @xcite .",
    "one can consider  ( [ hadamard problem ] ) as a special case of the weighted low - rank approximation problem defined in  @xcite : @xmath50 where @xmath51 is a symmetric positive definite weight matrix .  denote @xmath52 , where @xmath53 is an operator which maps the entries of @xmath54 to @xmath55 . since @xmath56 is symmetric and positive definite , the problem  ( [ manton ] ) can be transformed into  ( [ hadamard problem ] ) through an unitary transformation .",
    "so , problem  ( [ hadamard problem ] ) and problem  ( [ manton ] ) are equivalent .",
    "unlike problem  ( [ weighted problem ] ) the weighted low rank approximation problem  ( [ hadamard problem ] ) has no closed form solution in general  @xcite .",
    "also note that the entry - wise multiplication is not associative with the regular matrix multiplication : @xmath57 and as a consequence , we lose the unitary invariance property in case of using the frobenius norm .",
    "we are interested in finding out the limit behavior of the solutions to problem  ( [ hadamard problem ] ) when @xmath58 and @xmath59 , a matrix whose entries are equal to 1 .",
    "one can expect that , with appropriate conditions , the solutions to  ( [ hadamard problem ] ) will converge and the limit is @xmath60 .",
    "we will verify this with an estimate on the rate of convergence .",
    "we will also extend the convergence result to the unconstrained version of the problem  ( [ hadamard problem ] ) and propose a numerical algorithm to solve  ( [ hadamard problem ] ) for the special case of the weight matrix @xmath58 and @xmath59 .",
    "the rest of the paper is organized as follows . in section 2 , we state our main results .",
    "their proofs are given in section 3 .",
    "in section 4 , we present the numerical solution to problem  ( [ hadamard problem ] ) for the special case of the weight and discuss the convergence of our algorithm .",
    "numerical results verifying our main results are given in section 5 .",
    "let @xmath61 be a solution to  ( [ hadamard problem ] ) .",
    "denote @xmath62 and @xmath63 also denote @xmath64 and let the ordered non - zero singular values of @xmath65 be @xmath66 let @xmath67 and @xmath68 .    [",
    "theorem 3 ] let @xmath69 . if @xmath70 then @xmath71 where @xmath72 is defined to be the unique solution to  ( [ golub s problem ] ) .    (",
    "the assertion of the uniqueness of @xmath60 is due to the assumption @xmath73 ( see the remark  [ remark1 ] ) .",
    "( ii ) . as in  ( @xcite ) , with proper condition one can find @xmath74 as @xmath58 and @xmath75 .",
    "we should mention , however , it does not give the convergence rate as proposed in theorem  [ theorem 3 ] .",
    "next , if we do not know @xmath13 but still want to reduce the rank in our approximation , consider the unconstrained version of  ( [ hadamard problem ] ) :  for  @xmath76 , @xmath77 again one can expect that the solutions to  ( [ unconstrained hadamard problem ] ) will converge to @xmath60 as @xmath58 and @xmath78 define @xmath79 , to be the set of all solutions to  ( [ golub s problem ] ) .",
    "let @xmath80 be a solution to  ( [ unconstrained hadamard problem ] ) .",
    "[ theorem 5 ] every accumulation point of @xmath80 as @xmath81 belongs to @xmath82    [ theorem 6 ] assume that @xmath83 .",
    "denote @xmath84 and @xmath85 then the accumulation point of the sequence @xmath86 as @xmath58 and @xmath87 is unique ; and this unique accumulation point is given by @xmath88 with @xmath89 satisfying @xmath90    for the case when @xmath35 has repeated singular values , we leave it to the reader to verify the following more general statement by using a similar argument : let @xmath91 be the singular values of @xmath35 with multiplicity @xmath92 respectively . note that @xmath93 let @xmath94 where @xmath95 has multiplicity @xmath96 then the accumulation points of the set @xmath97 as @xmath98 , belongs to the set @xmath99 where @xmath100",
    "to prove theorem  [ theorem 3 ] , we first establish the following lemmas .",
    "[ lemma 1 ] as @xmath58 and @xmath75 , we have the following estimates .",
    "a.   @xmath101 .",
    "b.   @xmath102 . c.   @xmath103 .    _",
    "note that , @xmath104 then @xmath105 and so @xmath106 thus @xmath107 _ ( ii ) .",
    "_ for simplicity , let us assume @xmath108 , full rank . if @xmath109 , then @xmath32 can be replaced by a matrix with @xmath110 linearly independent columns chosen from @xmath32  @xcite .",
    "we use the @xmath111 decomposition of @xmath112 let @xmath113 where @xmath114 is an orthogonal matrix with block matrices @xmath115 ,  @xmath116 , and @xmath117 of sizes @xmath118 , @xmath119 and @xmath120 , respectively , and the matrices @xmath121 and @xmath122 are both upper triangular .",
    "therefore , @xmath123 note that @xmath124 and @xmath125 by ( i ) , we see that @xmath126 for all large @xmath127 we now look at the @xmath111 decomposition of @xmath128 @xmath129 where @xmath130 is column orthogonal  ( @xmath131 ) , and @xmath132 is upper triangular .",
    "the @xmath111 decomposition can be obtained via the gram - schmidt process . if we write the matrices as collection of column vectors : @xmath133 and @xmath134 where @xmath135 then by ( i ) , @xmath136 so , as @xmath137 , @xmath138 where @xmath139 denotes the @xmath140 norm of vectors .",
    "similarly , we see that @xmath141 and @xmath142 which leads to @xmath143 continuing this process we obtain , as  @xmath144 , @xmath145 finally , we have @xmath146 as @xmath144 . + _ ( iii ) _ we know that @xmath147 using ( ii ) @xmath148 therefore , @xmath149 this completes the proof of lemma  [ lemma 1 ] .    for the case",
    "when there is an uniform weight in @xmath150 , one might refer to  @xcite for an alternative proof of lemma  [ lemma 1 ] .",
    "but the proof in  @xcite can not be applied in the more general case as in lemma  [ lemma 1 ] .",
    "[ lemma 2 ] if @xmath70 then @xmath151    _ proof .",
    "_ let the svds of @xmath152 be given by @xmath153 @xmath154 such that @xmath155 with @xmath156 and @xmath157 being diagonal matrices containing singular values of @xmath65 and @xmath158 , respectively , arranged in a non - increasing order",
    "; @xmath159 using  ( [ svda ] ) and  ( [ svda1 ] ) we have @xmath160 then by ( iii ) of lemma  [ lemma 1 ] , we know that @xmath161 we will need the following result .    [ lemma 3]@xcite let @xmath162 and @xmath163 be a non - repeating singular value of the matrix @xmath65 with @xmath164 and @xmath165 being left and right singular vectors respectively . then as @xmath166 there is a unique singular value @xmath167 of @xmath158 such that @xmath168    the lemma above will allow us to estimate @xmath169 indeed , with the non - increasing arrangement of the singular values in @xmath156 and @xmath157 , and the fact that @xmath170 as @xmath144 , lemma  [ lemma 3 ] immediately implies that @xmath171 we pause on the proof of lemma  [ lemma 2 ] further and introduce some useful tools .",
    "our goal is to compare @xmath172 and @xmath173 this leads us to consider the column spaces of @xmath172 and @xmath173 one way to measure the distance between two subspaces is to measure the angle between them  @xcite .",
    "davis and kahan measured the difference of the angles between the invariant subspaces of a hermitian matrix and its perturbed form as a function of their perturbation and the separation of their spectra .",
    "wedin proposed a more generalized form . using the generalized @xmath174 theorem of wedin  ( @xcite )",
    ", the following results can be achieved  ( see section 4.4 in  @xcite ) .",
    "[ lemma 4 ] @xcite let @xmath175 and @xmath158 be as given in  ( [ per_svd2 ] ) .",
    "assume there exists an @xmath176 and a @xmath177 such that @xmath178 then @xmath179     + _ proof of lemma  [ lemma 2 ] continued .",
    "_ note that @xmath180 and , since @xmath70 we can choose @xmath181 such that @xmath182 note that , in this way , for all large @xmath43 the assumption of lemma  [ lemma 4 ] will be satisfied . since @xmath183 and @xmath184  ( [ thresholding inequality ] ) can be written as @xmath185 since @xmath186 is fixed , @xmath187 as @xmath144 . on the other hand , by  ( [ svd bound ] ) , as @xmath144 , @xmath188 now the unitary invariance of the matrix norm implies , @xmath189 which is bounded as @xmath144 .",
    "therefore  ( [ thresholding inequality1 ] ) becomes @xmath190 for some constant @xmath191 and for all large @xmath144 .",
    "thus @xmath192 since @xmath170 as @xmath144 .",
    "this completes the proof of lemma  [ lemma 2 ] .",
    "@xmath193    _ proof of theorem  [ theorem 3 ] . _",
    "the proof is a consequence of lemmas  [ lemma 1 ] and  [ lemma 2 ] .",
    "@xmath193    _ proof of theorem  [ theorem 5 ] .",
    "_ let @xmath194 .",
    "we need to verify that @xmath195 is a bounded set and every accumulation point is a solution to  ( [ golub s problem ] ) for some @xmath13 . since @xmath80 is a solution to  ( [ unconstrained hadamard problem ] ) , we have @xmath196 for all @xmath197 by choosing @xmath198 , we can obtain a constant @xmath199 such that @xmath200 therefore , @xmath201 is bounded .",
    "let @xmath202 be an accumulation point of the sequence .",
    "we only need to show that @xmath203 as in the proof of lemma  [ lemma 1 ]  ( i ) , we can show that @xmath204 now , taking limit and setting @xmath38 in  ( [ ineq2 ] ) , we can obtain , @xmath205 for all @xmath206 if we denote @xmath207 then for @xmath208 with @xmath209  ( [ limitcase ] ) yields @xmath210",
    "so , @xmath211 is a solution to the problem of golub , hoffman , and stewart .",
    "thus , by theorem  [ theorem 1 ] , @xmath212 this , together with  ( [ 2 ] ) completes the proof .",
    "@xmath193    _ proof of theorem  [ theorem 6 ] .",
    "_ let @xmath194 solve the minimization problem  ( [ unconstrained hadamard problem ] ) .",
    "for convenience , we will drop the dependence on @xmath49 in our notations .",
    "then @xmath213 satisfies @xmath214 for all @xmath215 . by choosing @xmath216 and @xmath217 in  ( [ weighted unconstrained problem 4 ] ) we obtain @xmath218 therefore , @xmath219 next we choose @xmath220 in  ( [ weighted unconstrained problem 4 ] ) and find , for all @xmath221 , @xmath222 as in the proof of  ( ii ) of lemma  [ lemma 1 ] , assume @xmath108 and consider a @xmath111 decomposition of @xmath223 @xmath224 write @xmath225 and let @xmath226 be in compatible block partitions .",
    "since the rank of a matrix is invariant under an unitary transformation ,  ( [ weighted unconstrained problem 5 ] ) can be rewritten as @xmath227 when @xmath43 is large enough , @xmath228 is nonsingular by  ( [ r_1 ] ) and the fact that @xmath108  and we can perform the row and column operations on the second term on left hand side of  ( [ weighted unconstrained problem 6 ] ) to get : @xmath229 which is equal to @xmath230 performing the similar operations on the right hand side we obtain@xmath231 substituting these back in  ( [ weighted unconstrained problem 6 ] ) we obtain @xmath232 for all @xmath233 from theorem  [ theorem 5 ] , we know that @xmath234 has accumulation points which belong to @xmath82 we are going to show that @xmath235 indeed exists .",
    "assume @xmath236 be an accumulation point . from  ( [ r_1 ] )",
    ", using the fact that @xmath237 as @xmath98 in  ( [ weighted unconstrained problem 7 ] ) we get @xmath238 for all @xmath239 since frobenius norm is unitarily invariant , ( [ weighted unconstrained problem 8 ] ) reduces to @xmath240 for all @xmath239 substituting @xmath241 , and  @xmath242 , in  ( [ weighted unconstrained problem 9 ] ) yields @xmath243 which implies @xmath244 .",
    "next , substituting @xmath245 in  ( [ weighted unconstrained problem 9 ] ) we find @xmath246 for all @xmath247 .",
    "let @xmath248 and @xmath249 then  ( [ weighted unconstrained problem 11 ] ) implies @xmath250 for all @xmath251 with @xmath252  so @xmath253 solves a problem of classical low - rank approximation of @xmath254 .",
    "note that , @xmath255  ( see  ( [ qr - a ] ) ) and it is assumed that @xmath35 has distinct singular values . so there exists a unique @xmath253 which is given by @xmath256 as in  ( [ hardthresholding ] ) ) .",
    "therefore there is only one accumulation point of @xmath257 and so @xmath235 exists .",
    "it remains for us to identify this unique accumulation point .",
    "assume that @xmath258 is a svd of @xmath259 then , for any @xmath260  ( [ weighted unconstrained problem 11 ] ) gives @xmath261 since @xmath262 and @xmath263 , choosing @xmath264 such that @xmath265 and using  ( [ qr inequality ] ) we find @xmath266 next we choose @xmath264 such that @xmath267 and so @xmath268 .",
    "now  ( [ r22lowrank ] ) and ektart - young - mirsky s theorem then imply the equality in  ( [ qr inequality ] ) can not hold .",
    "so , @xmath269 therefore , we obtain @xmath270 it is easy to see that if ( [ sigma inequality ] ) holds then @xmath271 so , @xmath272 and in this case when  @xmath273 , we have shown that @xmath274 . thus , together with  ( [ r_1 ] ) , this implies @xmath275 which is the same as @xmath276 this completes the proof .",
    "in this section we propose a numerical algorithm to solve a special case of  ( [ hadamard problem ] ) , which , in general , does not have a closed form solution  @xcite . note  ( [ hadamard problem ] ) can be written as @xmath277 we assume that @xmath278 . it can be verified that any @xmath279 such that @xmath280 can be given in the form @xmath281 for some arbitrary matrices @xmath282 @xmath283 and @xmath284 here we will focus on a special case when @xmath75 in solving : @xmath285 this will serve two purposes for us :  one is to verify the rate given by theorem  [ theorem 3 ] numerically and to gain some insight on the sharpness of the rate  ( @xmath286 , as @xmath144 ) ; the other one is to demonstrate a numerical procedure based on alternating direction method in solving the weighted low - rank approximation problem that also allows detailed convergence analysis which is usually hard to obtain in other algorithms proposed in the literature  @xcite .    if @xmath287 then  ( [ main problem 2 ] ) is an unweighted rank @xmath13 factorization of @xmath288 and is known as alternating least squares problem  @xcite .",
    "denote @xmath289 as the objective function .",
    "the above problem can be numerically solved by using an alternating strategy  @xcite of minimizing the function with respect to each component iteratively : @xmath290 note that each of the minimizing problem for @xmath291 and @xmath292 can be solved explicitly by looking at the partial derivatives of @xmath293 . but",
    "finding an update rule for @xmath294 turns out to be more involved than the other three variables .",
    "we update @xmath294 element wise along each row . therefore we will use the notation @xmath295 to denote the @xmath296-th row of the matrix @xmath294 .",
    "we set @xmath297 and obtain @xmath298 solving the above expression for @xmath294 sequentially along each row gives @xmath299 where @xmath300 .",
    "similarly , @xmath301 satisfies @xmath302 which implies @xmath303 and consequently can be solved as long as @xmath304 is of full rank .",
    "therefore solving for @xmath301 gives @xmath305 next we find @xmath306 satisfies @xmath307 solving  ( [ b_p ] ) for @xmath306 obtains  ( assuming @xmath308 is of full rank ) @xmath309 finally , @xmath310 satisfies @xmath311 and we can write  ( assuming @xmath306 is of full rank ) @xmath312    1",
    ".   inputs : @xmath313 ( the given matrix ) ; @xmath314 ( the weight ) ; threshold @xmath315 2 .",
    "initialization : @xmath316 .",
    "3 .   while not converged do + @xmath300 + @xmath317 + @xmath318 + @xmath319 + @xmath320 + @xmath321 4 .",
    "output : @xmath322      next we will discuss the convergence of our numerical algorithm",
    ". the following equality will be very helpful .",
    "[ theorem 7 ] for a fixed @xmath323 , and @xmath324 let @xmath325 .",
    "then,@xmath326    denote @xmath327 therefore , @xmath328 note that , @xmath329 as @xmath304 satisfies  ( [ x_p ] ) .",
    "this , together with  ( [ update rule calc ] ) , will lead us to @xmath330 similarly we find @xmath331 combining them together we have the desired result .",
    "theorem  [ theorem 7 ] implies a lot of interesting convergence properties of the algorithm .",
    "for example , we have the following estimates .",
    "[ corollary 2 ] we have    a.   @xmath332 for all @xmath333 b.   @xmath334 for all @xmath335 .    _",
    "( i ) . _ from  ( [ mj equality ] ) we can write , for all @xmath335 , @xmath336 by parallelogram identity . therefore , @xmath337 this completes the proof . + _ ( ii ) .",
    "_ this follows immediately from  ( [ mj equality ] ) .",
    "we now can state some convergence results as a consequence of theorem  [ theorem 7 ] and corollary  [ corollary 2 ] .",
    "[ theorem 8 ]    a.   we have the following :  @xmath338 , and + @xmath339 .",
    "b.   if @xmath340 then @xmath341 and @xmath342 and exist . furthermore if we write @xmath343 then @xmath344 for all @xmath333    _ ( i ) . _ from corollary  [ corollary 2 ] we can write , for @xmath345 , @xmath346 recall , @xmath347 . also note that , @xmath348 is a decreasing non - negative sequence . hence the results follows . + _ ( ii ) .",
    "_ again using corollary  [ corollary 2 ] we can write , for @xmath345 , @xmath349 which implies @xmath350 is convergent if @xmath351 therefore , @xmath352 exists . similarly , we conclude @xmath342 exists . + further , @xmath353 since @xmath348 converges .",
    "therefore @xmath354 exists and is equal to @xmath355 this completes the proof .    from theorem  [ theorem 8 ] , we can only prove the convergence of the sequence @xmath356 but not of @xmath357 and @xmath358 separately .",
    "we next establish the convergence of @xmath357 and @xmath358 with stronger assumption .",
    "consider the situation when @xmath359    [ theorem 9 ] assume  ( [ mj inequality ] ) holds .",
    "a.   if @xmath360 is of full rank and @xmath361 for large @xmath335 and some @xmath362 then @xmath363 exists",
    ". b.   if @xmath308 is of full rank and @xmath364 for large @xmath335 and some @xmath177 then @xmath365 exists . c.   if @xmath366 is of full rank , then @xmath367 exists .",
    "furthermore , if we write @xmath368 for @xmath369 , then @xmath370 will be a stationary point of @xmath371 .    _",
    "_ using  ( [ mj equality ] ) we have , for @xmath345 , @xmath372 } ,              \\end{aligned}\\ ] ] where @xmath373 denotes the trace of the matrix @xmath14 .",
    "note that , @xmath374 and we obtain @xmath375 which implies @xmath376 is convergent if  ( [ mj inequality ] ) holds . therefore @xmath377 exists .",
    "similarly we can prove @xmath378 .",
    "+ _ ( iii ) .",
    "_ note that , from  ( [ mj equality ] ) we have , for @xmath345 , @xmath379}.              \\end{aligned}\\ ] ] if @xmath366 is of full rank , it follows that , for large @xmath335 , @xmath380 for some @xmath381 therefore , we have @xmath382 following the same argument as in the previous proof we can conclude @xmath383 exists if  ( [ mj inequality ] ) holds .",
    "recall from  ( [ x_p]-[d_p ] ) , we have , @xmath384 taking limit @xmath385 in above we have @xmath386 therefore @xmath370 is a stationary point of @xmath371 .",
    "this completes the proof .",
    "in this section we will demonstrate numerical results of our weighted rank constrained algorithm and show the convergence to the solution given by golub , hoffman and stewart when @xmath144 as predicted by our theorems in section 2 .",
    "all experiments were performed on a computer with 3.1 ghz intel core i7 - 4770s processor and 8 gb memory .",
    "we performed our experiments on three full rank synthetic matrices @xmath14 of size @xmath387 , @xmath388 and @xmath389 respectively .",
    "we constructed @xmath14 as low rank matrix plus gaussian noise such that @xmath390 , where @xmath391 is the low - rank matrix ,  @xmath392 is the noise matrix , and @xmath393 controls the noise level .",
    "we generate @xmath391 as a product of two independent full - rank matrices of size @xmath394 whose elements are independent and identically distributed  ( i.i.d . ) @xmath395 random variables such that @xmath396 .",
    "we generate @xmath392 as a noise matrix whose elements are i.i.d .",
    "@xmath395 random variables as well . in our experiments",
    "we choose @xmath397 .",
    "the true rank of the test matrices are 10% of their original size but after adding noise they become full rank .",
    "let @xmath398 where @xmath399 , @xmath400 be a solution to  ( [ main problem 2 ] ) .",
    "we denote @xmath401 as our approximation to @xmath402 at @xmath335th iteration .",
    "recall that @xmath403 we denote @xmath404 and use @xmath405 as a measure of the relative error . for a threshold @xmath406 the stopping criteria of our algorithm at the @xmath335th iteration is @xmath407 or @xmath408 or if it reaches the maximum iteration .",
    "the algorithm performs the best when we initialize @xmath294 and @xmath292 as random normal matrices and @xmath409 and @xmath410 as zero matrices . throughout this section we set @xmath13 as the target low rank and @xmath45 as the total number of columns we want to constrain in the observation matrix .",
    "the algorithm takes approximately @xmath411 seconds on an average to perform 2000 iterations on a @xmath412 matrix for fixed @xmath413 , and @xmath43 .",
    "we first verify our implementation of the algorithm for computing @xmath402 for fixed weights .",
    "we initialize our algorithm by random matrices . throughout this subsection",
    "we set the target low - rank @xmath13 as the true rank of the test matrix and @xmath414 . to obtain the accurate result",
    "we run every experiment 25 times with random initialization and plot the average outcome in each case . a threshold equal to @xmath415 ( `` machine @xmath416 '' )",
    "is set for the experiments in this subsection . for figure 5.1",
    ", we consider a nonuniform weight with entries in @xmath417 randomly chosen from the interval @xmath418 $ ] , where @xmath419 and @xmath420 in the first block @xmath417 and @xmath75 and plot iterations versus relative error .",
    "relative error is plotted in logarithmic scale along @xmath421-axis .",
    ".5 ;  ( b )  @xmath422.,title=\"fig : \" ]    .5 ;  ( b )  @xmath422.,title=\"fig : \" ]    .5 :  ( a )  @xmath423 ;  ( b )  @xmath424,title=\"fig : \" ]    .5 :  ( a )  @xmath423 ;  ( b )  @xmath424,title=\"fig : \" ]    next , we consider a uniform weight in the first block @xmath417 and @xmath75 .",
    "recall that ,  in this case the solution to problem  ( [ hadamard problem ] ) can be given in closed form . by solving  ( [ weighted problem ] ) .",
    "that is , when @xmath425 ,  the rank @xmath13 solutions to  ( [ hadamard problem ] ) are @xmath426 $ ] , where @xmath427 $ ] is obtained in closed form using a svd of @xmath428 $ ] . in figure 5.2 , we plot iterations versus @xmath429 in logarithmic scale . from figures 5.1 and 5.2",
    "it is clear that the algorithm in section 4.1 converges . even for the bigger size matrices",
    "the iteration count is not very high to achieve the convergence .",
    "we now demonstrate numerically the rate of convergence as stated in theorem 2.1 when the block of weights in @xmath417 goes to @xmath430 and @xmath75 .",
    "first we use an uniform weight @xmath425 and @xmath75 . the algorithm in section 4",
    "is used to compute @xmath402 and svd is used for calculating @xmath60 , the solution to  ( [ golub s problem ] ) when @xmath431 .",
    "we plot @xmath43 vs. @xmath432 where @xmath432 is plotted in logarithmic scale along @xmath421-axis .",
    "we run our algorithm 20 times with the same initialization and plot the average outcome . a threshold equal to @xmath433",
    "is set for the experiments in this subsection .",
    "for figure 5.3 we set @xmath434 $ ] .",
    ".495    vs. @xmath432 :  ( a )  @xmath435 ,  ( b )  @xmath436.,title=\"fig : \" ]    .495    vs. @xmath432 :  ( a )  @xmath435 ,  ( b )  @xmath436.,title=\"fig : \" ]    .495    vs. @xmath432 :  ( a )  @xmath435 ,  ( b )  @xmath436.,title=\"fig : \" ]    .495    vs. @xmath432 :  ( a )  @xmath435 ,  ( b )  @xmath436.,title=\"fig : \" ]    the plots indicate for an uniform @xmath43 in @xmath417 the convergence rate is at least @xmath437 next we consider a nonuniform weight in the first block @xmath417 and @xmath75 .",
    "we consider @xmath438 $ ] such that @xmath439 , [ 2050,2070]$ ] and so on . for figure 5.4 ,",
    "@xmath432 is plotted in regular scale along @xmath421-axis .",
    "the curves in figure  5.4 are not always strictly decreasing but it is encouraging to see that they stay bounded .",
    "figures  5.3  and  5.4  provide numerical evidence in supporting theorem  [ theorem 3 ] . as established in theorem  [ theorem 3 ] the above plots demonstrate the convergence rate is at least @xmath437",
    "we would like to thank the anonymous referees and the handling editor for providing many useful references , and for their valuable comments and suggestions which improved the presentation and results of this paper .",
    "we would also like to thank dr .",
    "afshin dehghan , at the center for research in computer vision , university of central florida for his invaluable comments in the numerical results section .",
    ", _ damped ewton algorithms for matrix factorization with missing data _",
    ",  in proceedings of the 2005 ieee computer society conference on computer vision and pattern recognition , 2  ( 2005 ) , pp .  316322 ,",
    "doi : 10.1109/cvpr.2005.118 .",
    ", _ weighted low - rank approximation of general complex matrices and its application in the design of 2-d digital filters _ ,",
    "ieee transactions on circuits and systems i : fundamental theory and applications , 44 - 7  ( 1997 ) ,  pp.650655 ,  doi :  10.1109/81.596949 ."
  ],
  "abstract_text": [
    "<S> we study a weighted low rank approximation that is inspired by a problem of constrained low rank approximation of matrices as initiated by the work of golub , hoffman , and stewart ( linear algebra and its applications , 88 - 89(1987 ) , 317 - 327 ) .  </S>",
    "<S> our results reduce to that of golub , hoffman , and stewart in the limiting cases .  </S>",
    "<S> we also propose an algorithm based on the alternating direction method and demonstrate convergence asserted in our theorems .    weighted low rank approximation , singular value decomposition , alternating direction method    65f30 , 65k05 , 49m15 , 49m30 </S>"
  ]
}