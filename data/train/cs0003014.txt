{
  "article_text": [
    "with the explosive growth of the internet and the world wide web ( _ web _ ) , it is becoming increasingly difficult for users to retrieve relevant information .",
    "this is the so - called problem of _ information overload _ on the internet .",
    "augmenting existing internet search tools with personalised information filtering agents is one possible method to alleviate this problem .",
    "adaptive information filtering agents are computer systems situated on the web . they _ autonomously _ filter the incoming stream of information on behalf of the users .",
    "users information needs will change over time , and information filtering agents must be able to revise their beliefs about the users information needs so that the accuracy of the filtering process can be maintained .",
    "the * agm * belief revision paradigm  @xcite provides a rich and rigorous foundation for modelling such revision processes .",
    "it enables an agent to modify its beliefs in a rational and minimal way . *",
    "maxi - adjustment *  @xcite is a specific change strategy that follows the agm s rationale of belief revision . in particular , it transmutes the underlying entrenchment ranking of beliefs in an absolute minimal way under maximal information inertia . in information retrieval models",
    "@xcite , information objects are often assumed independent unless semantic relationships among them can be derived .",
    "this intuition coincides with the underlying assumption of the maxi - adjustment strategy .",
    "the advantage of employing the maxi - adjustment strategy as the agents learning mechanism is that semantic relationships among information items can be taken into account during the agents learning and adaptation processes .",
    "less users relevance feedback  @xcite is required to train the filtering agents , and hence a higher level of _ learning autonomy _ can be achieved when compared with the other learning approaches employed in adaptive information agents  @xcite .",
    "this paper focuses on the application of the maxi - adjustment method to the development of learning mechanisms in adaptive information filtering agents .",
    "moreover , difficulties of applying such a framework to the filtering agents are discussed .",
    "figure  [ agent ] is an overview of the major functional components of an adaptive information filtering agent .",
    "the focus of this paper is on the _ learning _ component of the _ adaptive information filtering agent_. the filtering agent s memory holds the current representation of a user s information needs . in particular , the notion of belief state  @xcite is used to represent these information needs .",
    "the learning component accepts a user s relevance feedback about filtered web documents .",
    "based on the proposed induction method , these feedback is converted to the beliefs of a user s information needs .",
    "the maxi - adjustment strategy is then applied to revise the beliefs stored in the agent s memory with respect to these newly induced beliefs .",
    "as the user s information needs will change over time , such a belief revision process needs to be conducted repeatedly . technically , the learning behavior demonstrated by the agent is a kind of _ reinforcement learning _  @xcite .",
    "the matching component filters out relevant information from a stream of incoming web documents .",
    "it is underpinned by logical deduction . in other words , if the representation of a web document is logically entailed by the set of beliefs stored in the agent s memory , the web document will be considered as relevant and presented to the user .",
    "according to the user s relevance feedback , new beliefs may be added to , or existing beliefs may be contracted from the agent s memory .",
    "the adaptive information filtering agent is one of the main elements in the agent - based information filtering system ( aifs )  @xcite .",
    "the agm paradigm  @xcite provides a rigorous foundation for modelling consistent and minimal changes to an agent s beliefs . in particular , belief revision is taken as transitions among belief states  @xcite .",
    "a belief state can be represented by a belief set @xmath0 which is a theory in a propositional language @xmath1  @xcite . for the discussion in this paper , it is assumed that @xmath1 is the classical propositional language . in the agm framework",
    "@xcite , three principle types of belief state transitions are identified and modelled by corresponding belief functions : _ expansion _ ( @xmath2 ) , _ contraction _ ( @xmath3 ) , and _ revision _ ( @xmath4 ) . the process of belief revision can be derived from the process of belief contraction and vice versa through the so - called _ levi identity _",
    "i.e. @xmath5 , and the _ harper identity _",
    "i.e. @xmath6 . essentially , the agm framework proposes sets of postulates to characterise these functions such that they adhere to the rationales of _ consistent _ and _ minimal _ changes .",
    "in addition , it also describes the constructions of these functions based on various mechanisms .",
    "one of them is _ epistemic entrenchment _ ( @xmath7 )  @xcite .",
    "for instance , if @xmath8 are beliefs in a belief set @xmath0 , @xmath9 means that @xmath10 is at least as entrenched as @xmath11 .",
    "if inconsistency arises after applying changes to a belief set , beliefs with the lowest degree of epistemic entrenchment are given up . technically , epistemic entrenchment  @xcite is a total preorder of the sentences ( e.g.  @xmath12 ) in @xmath1 , and is characterised by the following postulates : * ( ee1 ) * : if @xmath9 and @xmath13 , then @xmath14 ; * ( ee2 ) * : if @xmath15 , then @xmath9 ; * ( ee3 ) * : for any @xmath11 and @xmath10 , @xmath16 ; * ( ee4 ) * : when @xmath17 , for all @xmath10 ; * ( ee5 ) * : if @xmath18 for all @xmath10 , then @xmath19 .",
    "it has been proved that an unique contraction function can be defined by the underlying epistemic entrenchment through the ( c- ) condition  @xcite : @xmath20    where @xmath21 is the strict part of epistemic entrenchment defined above . moreover , the ( c - r ) condition  @xcite also ensures that if an ordering of beliefs satisfies ( ee1)-(ee5 ) , the contraction function , uniquely determined by ( c - r ) , satisfies all but the _ recovery",
    "_ postulates for contraction .",
    "@xmath22    nevertheless , for a computer based implementation , a finite representation of epistemic entrenchment ordering and a policy of iterated belief changes are required .",
    "williams @xcite proposed the _ finite partial entrenchment ranking _ @xmath23 that ranked the sentences of a theory in @xmath1 with the minimum possible degree of entrenchment @xmath24 .",
    "moreover , _",
    "maxi - adjustment _",
    "@xcite was proposed to transmute a finite partial ranking using an absolute measure of minimal change under maximal information inertia .",
    "belief revision is not just taken as adding or deleting a sentence from a theory but the transmutation of the underlying entrenchment ranking .",
    "williams  @xcite formally defined the following definitions for a computational model of belief revision .",
    "[ rankb ] a finite partial entrenchment ranking is a function @xmath25 that maps a finite subset of sentences in @xmath1 into the interval @xmath26 $ ] such that the following conditions are satisfied for all @xmath27 :    ( per1 ) @xmath28 .",
    "( per2 ) if @xmath29 then @xmath30 .",
    "( per3 ) @xmath31 if and only if @xmath19 .",
    "the set of all partial entrenchment rankings is denoted @xmath32 .",
    "@xmath33 is referred as the _ degree of acceptance _ of @xmath11 .",
    "the explicit information content of @xmath34 is @xmath35 , and is denoted @xmath36 .",
    "similarly , the implicit information content represented by @xmath34 is @xmath37 , and is denoted @xmath38 .",
    "@xmath39 is the classical consequence operator . in order to describe the epistemic entrenchment ordering @xmath24 generated from a finite partial entrenchment ranking @xmath25 , it is necessary to rank implicit sentences .",
    "[ degree ] let @xmath11 be a non tautological sentence",
    ". let @xmath25 be a finite partial entrenchment ranking .",
    "the degree of acceptance of @xmath11 is defined as :    @xmath40    the maxi - adjustment strategy transmutes a partial entrenchment ranking @xmath25 based on the rationale of absolute minimal change under maximal information inertia .",
    "it is assumed that sentences in exp(@xmath25 ) ( e.g.  @xmath8 ) are independent unless logical dependence exists between them . in particular , @xmath11 is defined as a _ reason _ of @xmath10 if and only if @xmath41 .",
    "[ maxi ] let @xmath34 be finite .",
    "the range of @xmath25 is enumerated in ascending order as @xmath42 .",
    "let @xmath11 be a contingent sentence , @xmath43 and @xmath44 .",
    "then the @xmath45 maxi - adjustment of @xmath25 is @xmath46 defined by :    @xmath47    where for all @xmath48 , @xmath49 is defined as follows :    \\1 . for @xmath10 with @xmath50 .",
    "\\2 . for @xmath10 with @xmath51 , assuming that @xmath52 for @xmath10 is defined with @xmath53 for @xmath54 , then for @xmath10 with @xmath55 ,    @xmath56    \\3 . for @xmath10 with @xmath57 .    for all @xmath58",
    "is defined as follows :    @xmath59    it has been stated that if @xmath60 then @xmath61 is an agm revision , and @xmath62 satisfies all but the _ recovery _ postulates for agm contraction  @xcite .",
    "a web page is characterised by a set of weighted keywords based on traditional information retrieval ( _ ir _ ) techniques  @xcite . at the symbolic level , each keyword @xmath63 is mapped to the ground term of the _ positive keyword _",
    "predicate _ pkw _",
    "i.e.  @xmath64 .",
    "basically , @xmath64 is a _ proposition _ since its interpretation is either true or false .",
    "the intended interpretation of these sentences is that they are satisfied in a document @xmath65 i.e.  @xmath66 if @xmath65 is taken as a model  @xcite .",
    "for example , if d = \\ { business , commerce , trade ,  } is the document representation at the keyword level , the corresponding representation at the symbolic level will be d = \\ { @xmath67 , @xmath68 , @xmath69 ,  } .",
    "similarly , a user s information needs are also represented as a set of weighted keywords at the keyword level .",
    "however , this set of weighted keywords is derived from a set of relevant documents @xmath70 and a set of non - relevant documents @xmath71 with respect to the user s information needs  @xcite .",
    "based on the frequencies of these keywords appearing in @xmath70 and @xmath71 , it is possible to induce a preference ordering among the keywords with respect to the user s information needs .",
    "the basic idea is that a keyword appearing more frequently in @xmath70 is a more preferred keyword than another keyword that appears less frequently in @xmath70 .",
    "once this preference ordering is induced , it is taken as the epistemic entrenchment ordering of the corresponding beliefs .",
    "it is observed that the postulates of epistemic entrenchment is valid in the context of information retrieval in general  @xcite .",
    "for example , if @xmath72 is a set of information carriers  @xcite , @xmath9 and @xmath13 implies @xmath14 . in other words , if an information searcher prefers information carrier @xmath73 rather than information carrier @xmath10 , and information carrier @xmath10 rather than information carrier @xmath11 , they prefer retrieving @xmath73 rather than @xmath11 . this characteristic of information carriers matches the epistemic entrenchment postulate e.g. ( ee1 ) of beliefs .    moreover , it is necessary to classify a keyword as _ positive _ , _ neutral _ , or _ negative _",
    "intuitively , positive keywords represent the information items in which the users interested .",
    "negative keywords represent the information items that the users do not want to retrieve .",
    "neutral keywords mean that these keywords are not useful for determining the users interests .",
    "eq.([eq1 ] ) is developed based on the _ keyword classifier _",
    "@xcite . it can be used to induce the preference value @xmath74 of a keyword @xmath63 , and classify it as positive , negative , or neutral .",
    "@xmath75    where @xmath76 is used to restrict the range of @xmath74 such that @xmath77 .",
    "the examples illustrated in this paper assume that @xmath78 .",
    "@xmath79 is the sum of the number of relevant documents @xmath80 and the number of non - relevant documents @xmath81 that contains the keyword @xmath63 , and @xmath82 is the hyperbolic tangent . the rarity parameter @xmath83 is used to control rare or new keywords and is expressed as int@xmath84 , where @xmath85 is the total number of web documents judged by a user , and int is an integer function that truncates the decimal values .",
    "@xmath86 is the estimated probability that a document containing keyword @xmath63 is relevant and is expressed as the fraction @xmath87 .",
    "@xmath88 is the estimated probability that a document is relevant . in our system",
    ", it is assumed that the probability that a web document presented by the filtering agent and judged as relevant by a user is @xmath89 . a positive value of @xmath74 implies that the associated keyword is positive , whereas a negative value of @xmath74 indicates a negative keyword . if @xmath74 is below a threshold value @xmath90 , the associated keyword is considered neutral .",
    "it is assumed that @xmath91 for the examples demonstrated in this paper .",
    "basically a positive keyword @xmath63 is mapped to @xmath64 , and a negative keyword @xmath63 is mapped to @xmath92 .",
    "there is no need to create the symbolic representations for neutral keywords . for @xmath64 or",
    "@xmath92 , the entrenchment rank @xmath93 of the corresponding formula @xmath94 is defined as :    @xmath95    the following is an example of computing the entrenchment rank @xmath93 from a set of judged web documents .",
    "it is assumed that there are a set of five documents having been judged as relevant ( i.e. @xmath96 ) and another set of five documents having been judged as non - relevant by a user ( i.e. @xmath97 ) .",
    "each document is characterised by a set of keywords e.g.  @xmath98 .",
    "table  [ tab : frequency ] summarises the frequencies of these keywords appearing in both @xmath70 and @xmath71 , their preference values , and the entrenchment ranks of corresponding formulae .    .",
    "representation of users information preferences [ cols=\"^,^,^,^,^,^\",options=\"header \" , ]",
    "in our current framework , the matching function of the filtering agent is modelled as logical deduction .",
    "moreover , a web document is taken as the conjunction of a set of formulae  @xcite .",
    "the following example illustrates the agent s deduction process with reference to previous examples .",
    "the resulting belief sets @xmath99 from examples",
    "@xmath100 , @xmath101 , and @xmath102 in the previous section are used to determine the relevance of the following three web documents :    @xmath103    the filtering agent s conclusions about the relevance of the web documents are summarised as follows : + time : ( t1 ) @xmath104    time : ( t2 ) @xmath105    time : ( t3 ) @xmath106    as can be seen tentative conclusion drawn at time @xmath107 may not hold when new information e.g. @xmath108 is processed by the agent at time @xmath109 . strictly speaking ,",
    "the deduction process of the agent should be described as @xmath110 , where @xmath111 is a nonmonotonic inference relation because the inferred beliefs ( i.e. conclusions ) will not grow monotonically .",
    "it is not difficult to see that this @xmath111 should belong to the class of nonmonotonic inference called _ expectation inference _ ( @xmath112 )  @xcite .",
    "the basic idea of expectation inference is that given a sentence @xmath11 of a propositional language @xmath1 , if @xmath11 and the subset of sentences in a belief set @xmath0 that is consistent with @xmath11 ( i.e. @xmath113 ) can classically entail another sentence @xmath10 , @xmath114 can be deduced . with reference to our examples , since @xmath0 classically entails or not entails @xmath115 , @xmath116 and @xmath117 , and @xmath118 , the definition of expectation inference can trivially be applied to describe the characteristics of the inference mechanism in the filtering agent .",
    "therefore , @xmath119 , where @xmath0 is the filtering agent s belief set and @xmath115 is the logical representation of a web document , represents an inference conducted by the adaptive filtering agent .",
    "an alternative approach for developing the filtering agent s learning mechanism is to apply the ( c- ) or the ( c - r ) condition to revise the agent s beliefs .",
    "it has been stated that both the ( c- ) and the ( c - r ) conditions can be used to construct the same class of belief revision functions that satisfy the agm postulates for belief revision  @xcite .",
    "the following example illustrates how belief revision may be conducted based on the ( c - r ) condition . assuming that the filtering agent s initial belief set @xmath0 is as follows :    @xmath120    moreover ,    @xmath121    if a user perceives some web documents characterised by the keyword _ business _ as non - relevant , the revision process @xmath122 will be invoked .",
    "based on the levi identity , the sentence @xmath67 should first be contracted from the belief set @xmath0 .",
    "consequently , all the beliefs from @xmath0 will be contracted according to the ( c - r ) condition .",
    "the resulting belief set becomes @xmath123 .",
    "nevertheless , a user who does not require information objects about _ business _ may still be interested in information objects about _ art _ and _ sculpture_. therefore , applying ( c - r ) or ( c- ) to construct belief contraction or belief revision function seems producing drastic changes in the context of information retrieval and filtering .",
    "in fact , term independence is often assumed in information retrieval .",
    "this intuition is reflected in the vector space model of information retrieval  @xcite , where changing the weight of a particular keyword may not affect the others in the weight vector .",
    "therefore , the maxi - adjustment strategy produces a better approximation in terms of revising or contracting beliefs about information objects with respect to a user s information needs .    under the current framework ,",
    "domain knowledge such as semantic relationships among information objects is transferred to the filtering agent s memory through a knowledge engineering process . since",
    "not all semantic relationship is highly certain ( i.e. assigning the maximal entrenchment rank ) , by applying belief revision to the agent s memory , the corresponding beliefs may be contracted from the memory over time .",
    "therefore , domain knowledge perhaps needs to be transferred to the agent s memory periodically in accordance with the postulates of epistemic entrenchment .",
    "this can be taken as an off - line process to minimise its impact on the availability of the filtering agents .",
    "however , further investigation is required to apply such a background learning process to the filtering agents .",
    "the belief set @xmath124 is actually used by the agents to infer the relevance of web documents .",
    "on the other hand , maxi - adjustment is employed to revise the theory base @xmath36 and to maintain its consistency after applying changes .",
    "though maxi - adjustment ensures that the revised theory base is consistent , it is possible that the belief set @xmath0 becomes inconsistent ( i.e. @xmath125 ) after applying changes such as @xmath46 .",
    "the following is a classical example to explain such a problem .",
    "it is assumed that the set of explicit beliefs @xmath36 as well as their entrenchment ranking is as follows :    @xmath126,\\\\ \\qquad   \\forall x [ penguin(x ) \\rightarrow \\neg fly(x ) ] , \\\\",
    "\\qquad   \\forall x [ bird(x ) \\rightarrow fly(x ) ] \\ } \\\\ \\end{array}\\ ] ]    @xmath127 ) = 0.9,\\\\ { \\mathbf{b}}(\\forall x [ penguin(x ) \\rightarrow \\neg fly(x ) ] ) = 0.7 , \\\\ { \\mathbf{b}}(\\forall x [ bird(x ) \\rightarrow   fly(x ) ] ) = 0.4 \\\\ \\end{array}\\ ] ]    in the context of information retrieval and filtering ,",
    "@xmath128 @xmath129 @xmath130 can be interpreted as : if a user is interested in information objects about @xmath131 , it is likely that the user is also interested in information objects about @xmath132 .",
    "the other formulae in @xmath36 can be interpreted in similar way .",
    "given the fact that the user is interested in @xmath133 which is a penguin i.e.  @xmath134 and @xmath135 , by applying maxi - adjustment @xmath136 , the revised entrenchment ranking @xmath137 will be :    @xmath138 ) = 0.9 , \\\\",
    "new{\\mathbf{b}}(penguin(tweety ) ) = 0.8 , \\\\ new{\\mathbf{b}}(\\forall x [ penguin(x ) \\rightarrow \\neg fly(x ) ] ) = 0.7 , \\\\ new{\\mathbf{b}}(\\forall x [ bird(x ) \\rightarrow   fly(x ) ] ) = 0.4\\\\ \\end{array}\\ ] ]    the degree of acceptance of implicit beliefs is computed based on definition  [ degree ] :    @xmath139    as can be seen , even though @xmath140 , it is clear that @xmath141 , where @xmath142 is classical derivability relation . if the filtering agent employs the belief set @xmath143 to deduce the relevance of web documents , any documents will be considered as relevant .",
    "this problem must be addressed before the filter agents can be put to practical use .",
    "one possible solution is to make use of the degree of acceptance of beliefs to produce the largest _ cut _ of @xmath38 so that it does not entail @xmath144 . in other words ,",
    "only the set of consistent beliefs @xmath145 , where @xmath21 is the strict part of epistemic entrenchment , will be used by the filtering agent to infer the relevance of web documents .",
    "similar idea has been explored in developing the expectation inference relation  @xcite .",
    "for instance , @xmath146 iff @xmath147 is developed based on @xmath148 .",
    "so , with reference to the above example , after applying @xmath136 , the agent should only make use of the following set of beliefs for reasoning :    @xmath149,\\\\ \\qquad penguin(tweety ) , \\\\ \\qquad bird(tweety ) , \\\\",
    "\\qquad   \\forall x [ penguin(x ) \\rightarrow \\neg fly(x ) ] , \\\\ \\qquad \\neg fly(tweety ) \\ } \\\\ \\end{array}\\ ] ]    therefore , the agent can conclude that the user is interested in information objects about _ non - flying tweety_. the above reasoning process can also be explained based on _ nontrivial possibilistic deduction _ ( @xmath150 )  @xcite . in possibilistic logic ,",
    "the inconsistency degree @xmath151 of a possibilistic knowledge base @xmath152 is defined as the least certain formula involved in the strongest contradiction of @xmath152 .",
    "moreover , nontrivial possibilistic deduction is defined as : @xmath153 . if the entrenchment rank of a formula @xmath11 is taken as the certainty @xmath154 of a possibilistic formula , @xmath155 with reference to the above example . by employing possibilistic resolution ,",
    "@xmath156 and @xmath157 can be obtained , where @xmath158 is possibilistic entailment . since the certainty degree @xmath154 of @xmath159 equals @xmath160 and is greater than @xmath161 , @xmath162 .",
    "nevertheless , @xmath163 can not be deduced from @xmath0 based on ( @xmath150 ) because @xmath164 .",
    "however , further investigation is required to apply possibilistic based inference to the matching components of adaptive information filtering agents .",
    "the agm belief revision paradigm offers a powerful and rigorous foundation to model the changes of an agent s beliefs .",
    "the maxi - adjustment strategy , which follows the agm rationale of consistent and minimal belief changes , provides a robust and effective computational mechanism for the development of the filtering agents learning components . as semantic relationships among information items",
    "can be reasoned about via the maxi - adjustment method , less human intervention may be required during the agents reinforcement learning processes .",
    "this opens the door to better learning autonomy in adaptive information filtering agents .",
    "the technical feasibility of applying the maxi - adjustment method to adaptive information filtering agents has been examined . however",
    ", quantitative evaluation of the effectiveness of these agents needs to be conducted to verify the advantages of applying such a framework to construct the learning mechanisms of these agents .",
    "allan , j. 1996 .",
    "incremental relevance feedback for information filtering . in _ proceedings of the 19th annual international acm sigir conference on research and development in information retrieval _ , filtering , 270278 .",
    "balabanovic , m. 1997 . an adaptive web page recommendation service . in johnson , w.  l. , and hayes - roth , b. , eds .",
    ", _ proceedings of the first international conference on autonomous agents ( agents97 ) _ , 378385 .",
    "new york : acm press .",
    "billsus , d. , and pazzani , m. 1999 . a personal news agent that talks , learns and explains . in",
    "_ proceedings of the third international conference on autonomous agents ( agents99 ) _ , 268275 .",
    "seattle , wa : acm press .",
    "bruza , p. , and huibers , t. 1994 . .",
    "in croft , w. , and rijsbergen , c.  v. , eds . , _ proceedings of the 17th annual international acm sigir conference on research and development in information retrieval _ , 112121 .",
    "dublin , ireland : springer - verlag .",
    "buckley , c. ; salton , g. ; and allan , j. 1994 .",
    "the effect of adding relevance information in a relevance feedback environment . in _ proceedings of the seventeenth annual international acm sigir conference on research and development in information retrieval _ , routing , 292300 .",
    "dubois , d. ; lang , j. ; and parade , h. 1993 . .",
    "in gabbay , d.  m. ; hogger , c.  j. ; robinson , j.  a. ; and nute , d. , eds . , _ handbook of logic in artificial intelligence and logic programming _ , volume  3 .",
    "oxford : oxford university press .",
    "439513 .",
    "grdenfors , p. , and makinson , d. 1988 .",
    "revisions of knowledge systems using epistemic entrenchment . in vardi , m.  y. , ed . , _ proceedings of the second conference on theoretical aspects of reasoning about knowledge _ , 8395 .",
    "san francisco , ca : morgan kaufmann inc .",
    "kindo , t. ; yoshida , h. ; morimoto , t. ; and watanabe , t. 1997 .",
    "adaptive personal information filtering system that organizes personal profiles automatically . in pollack ,",
    "m.  e. , ed . ,",
    "_ proceedings of the fifteenth international joint conference on artificial intelligence _ , 716721 .",
    "san francisco , ca : morgan kaufmann publishers inc .",
    "lau , r. ; hofstede , a. h.  m. ; and bruza , p.  d. 1999 . . in _ proceedings of the fifth international computer science conference ( icsc99",
    ") _ , volume 1749 of _ lecture notes in computer science _ , 110 .",
    "berlin : springer .",
    "pazzani , m. ; muramatsu , j. ; and billsus , d. 1996 .",
    "syskill and webert : identifying interesting web sites . in _ proceedings of the thirteenth national conference on artificial intelligence and the eighth innovative applications of artificial intelligence conference _ , 5461 .",
    "menlo park : aaai press / mit press .",
    "williams , m .- a .",
    "iterated theory base change : a computational model . in mellish , c.  s. , ed . ,",
    "_ proceedings of the fourteenth international joint conference on artificial intelligence _ , 15411547 .",
    "san francisco , ca : morgan kaufmann publishers inc .",
    "williams , m .- a . 1996 . towards a practical approach to belief revision : reason - based change . in aiello ,",
    "l.  c. ; doyle , j. ; and shapiro , s. , eds . , _",
    "kr96 : principles of knowledge representation and reasoning _ , 412420 .",
    "san francisco , ca : morgan kaufmann publishers inc",
    ".    williams , m .- a .",
    "1997a . anytime belief revision . in pollack , m.  e. , ed .",
    ", _ proceedings of the fifteenth international joint conference on artificial intelligence _ , 7479 .",
    "san francisco , ca : morgan kaufmann publishers inc ."
  ],
  "abstract_text": [
    "<S> _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ learning and adaptation is a fundamental property of intelligent agents . in the context of adaptive information filtering , </S>",
    "<S> a filtering agent s beliefs about a user s information needs have to be revised regularly with reference to the user s most current information preferences . </S>",
    "<S> this learning and adaptation process is essential for maintaining the agent s filtering performance . </S>",
    "<S> the agm belief revision paradigm provides a rigorous foundation for modelling rational and minimal changes to an agent s beliefs . </S>",
    "<S> in particular , the maxi - adjustment method , which follows the agm rationale of belief change , offers a sound and robust computational mechanism to develop adaptive agents so that _ learning autonomy _ of these agents can be enhanced . </S>",
    "<S> this paper describes how the maxi - adjustment method is applied to develop the learning components of adaptive information filtering agents , and discusses possible difficulties of applying such a framework to these agents . _ </S>",
    "<S> _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ </S>"
  ]
}