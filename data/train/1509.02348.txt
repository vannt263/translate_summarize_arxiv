{
  "article_text": [
    "hybrid system identification aims at estimating a model of a system switching between different operating modes from input - output data .",
    "more precisely , most of the literature considers autoregressive with external input ( arx ) models to cast the problem as a regression one @xcite .",
    "then , two cases can be distinguished : switching regression , where the system arbitrarily switches from one mode to another , and piecewise affine ( pwa ) regression , where the switches depend on the regressors .",
    "a number of methods with satisfactory performance in practice are now available for these problems @xcite .",
    "however , compared with linear system identification , a major weakness of these methods is their lack of guarantees . for the particular case of noiseless data , the algebraic method @xcite provides a solution to switching regression with a small number of modes . however , the quality of the estimates quickly degrades with the increase of the noise level .",
    "a few sparsity - based methods @xcite also offer guarantees in the noiseless case , but these are subject to a condition on both the data and the sought solution . in the presence of noise , most methods consider the minimization of the error of the model over the data @xcite .",
    "while this does not necessarily yields the best predictive model ( due to issues like identifiability , persistence of excitation and access to a limited amount of data ) , obtaining statistical guarantees with such an approach has a long history in statistics and system identification @xcite . however , such results are not available for hybrid systems .",
    "this is probably due to the fact that minimizing the error of a hybrid model is a difficult nonconvex optimization problem involving the simultaneous classification of the data points into modes and the regression of a submodel for each mode .",
    "thus , theoretical guarantees could only be obtained under the rather strong assumption that this problem has been solved to global optimality and most of the literature @xcite focuses on this issue with heuristics of various degrees of accuracy and computational efficiency .",
    "many recent works @xcite try to avoid local minima by considering convex formulations , but these only yield optimality with respect to a relaxation of the original problem .",
    "global optimality in the presence of noise was only reached in @xcite for a particular class of continuous pwa maps known as hinging - hyperplanes by reformulating the problem as a mixed - integer program solved by branch - and - bound techniques .",
    "however , such optimization problems are np - hard @xcite and branch - and - bound algorithms have a worst - case complexity exponential in the number of integer variables , here proportional to the number of data and the number of modes .    inspired by related clustering problems , such as the minimization of the sum of squared distances between points and their group centers , we could minimize the hybrid model error by enumerating all possible classifications of the points .",
    "but the number of classifications is exponential in the number of data .",
    "conversely , the other approach enumerating a sample of values for the real variables of the problem is exponential in the dimension and can only offer an approximate solution .",
    "overall , the literature does not provide a method that can guarantee both the optimality and the computability of a global minimizer of the error , while the computational complexity of this problem remains unknown and can not be deduced from the np - hardness of classical clustering problems  @xcite ( see  @xcite for an introduction to computational complexity and its relevance to control theory ) .",
    "[ [ contribution ] ] contribution + + + + + + + + + + + +    the paper provides two results regarding the computational complexity of pwa regression , and more precisely for the problem of finding a global minimizer of the error of a pwa model , formalized in sect .",
    "[ sec : problem ] .",
    "first , we show in sect .",
    "[ sec : nphard ] that the problem is np - hard .",
    "then , we show in sect .",
    "[ sec : exact ] that , for any fixed dimension of the data , an exact solution can be computed in time polynomial in the number of data via an enumeration of all possible classifications . to obtain this result and avoid the exponential growth of the number of classifications with the number of data ,",
    "we show that , in pwa regression , the classification of the data points is highly constrained and the number of classifications to test can be limited .",
    "the price to pay for this gain is an exponential complexity with respect to the data dimension and the number of modes .",
    "future work is outlined in sect .",
    "[ sec : discuss ] .",
    "[ [ notations ] ] notations + + + + + + + + +    we use the indicator function @xmath0 of an event @xmath1 that is @xmath2 if the event occurs and @xmath3 otherwise .",
    "we define @xmath4 if @xmath5 and @xmath6 otherwise .",
    "given a set of labels @xmath7 and a set of @xmath8 points , a labeling of these points is any @xmath9 .",
    "we use @xmath10 as a shorthand for @xmath11 . given two sets , @xmath12 and @xmath13 , @xmath14 is the set of functions from @xmath12 to  @xmath13 .",
    "as in most works , we concentrate on discrete - time pwarx system identification considered as a pwa regression problem with regression vectors @xmath15^t\\in{\\mathcal{x}}$ ] built from past inputs @xmath16 and outputs @xmath17 . since we are interested in computational complexity results , we restrain the data to rational , digitally representable , values and set @xmath18 .",
    "the outputs are assumed to be generated by a pwa system @xmath19 as @xmath20 , where @xmath21 is a noise term .",
    "more precisely , pwa models can be expressed via a set of @xmath22 affine submodels and a function @xmath23 determining the active submodel : @xmath24 , where @xmath25^t$ ] .",
    "we call the function @xmath26 a classifier as it classifies the data points in the different modes .",
    "typically , pwa systems are defined with @xmath26 implementing a polyhedral partition of @xmath12 , with modes possibly spanning unions of polyhedra . however , in most of the literature on pwa system identification @xcite , @xmath26 is estimated within the family of linear classifiers @xmath27 based on a set of @xmath22 linear functions and for which a mode spanning a union of polyhedra must be modeled as several modes with similar affine submodels . for pwa maps with @xmath28 modes , @xmath26 is a binary classifier for which it is common to consider its output in @xmath29 instead of @xmath30 .",
    "such a binary classifier can be obtained by taking the sign of a real - valued function . if this function is linear ( or affine )",
    ", then we obtain a linear classifier , which is equivalent to a separating hyperplane dividing the input space @xmath12 in two half - spaces . in this case",
    ", the function class @xmath31 can be defined as @xmath32 with a single set of parameters @xmath33 corresponding to the normal to the hyperplane and the offset from the origin .",
    "an equivalence with the multi - class formulation in   is obtained by using @xmath34 and @xmath35 .    in this paper , we consider the common estimation approach of minimizing the error on @xmath8 data pairs @xmath36 , measured pointwise by a loss function @xmath37 as @xmath38 more precisely , we focus on well - posed instances of the problem where @xmath8 is significantly larger than the dimension @xmath39 and the number of modes @xmath22 is given .",
    "indeed , with free @xmath22 the problem is ill - posed as the solution is only defined up to a trade - off between the number of modes and the model accuracy . for the converse",
    "well - posed approach that minimizes @xmath22 for a given error bound , a complexity analysis can be found in  @xcite . under these assumptions ,",
    "the problem is as follows .",
    "[ pb : pwa ] given a data set @xmath40 with @xmath41 and an integer @xmath42 $ ] , find a global solution to @xmath43 where @xmath44 is the concatenation of all parameter vectors and @xmath45 is the set of @xmath22-category linear classifiers as in   or  .",
    "the following analyzes the time complexity of problem  [ pb : pwa ] under the classical model of computation known as a turing machine @xcite .",
    "the time complexity of a problem is the lowest time complexity of an algorithm solving any instance of that problem , where the time complexity of an algorithm is the maximal number of steps occuring in the computation of the corresponding turing machine program .",
    "the loss function @xmath46 is assumed to be computable in polynomial time throughout the paper .",
    "this section contains the proof of the following np - hardness result , where an np - hard problem is one that is at least as hard as any problem from the class np of nondeterministic polynomial time decision problems  @xcite ( np is the class of all decision problems for which a solution can be certified in polynomial time ) .",
    "[ thm : nphard ] with a loss function @xmath46 such that @xmath47 , problem  [ pb : pwa ] is np - hard .",
    "the proof uses a reduction from the partition problem , known to be np - complete  @xcite , i.e. , a problem that is both np - hard and in np .",
    "[ pb : partition ] given a multiset ( a set with possibly multiple instances of its elements ) of @xmath39 positive integers , @xmath48 , decide whether there is a multisubset @xmath49 such that @xmath50    more precisely , we will reduce problem  [ pb : partition ] to the decision form of problem  [ pb : pwa ] .    [",
    "pb : pwadecision ] given a data set @xmath40 , an integer @xmath42 $ ] and a threshold @xmath51 , decide whether there is a pair @xmath52 such that @xmath53 where @xmath31 is the set of linear classifiers as in   or   and the loss function @xmath46 is such that @xmath47 .",
    "problem  [ pb : pwadecision ] is np - complete .",
    "since given a candidate pair @xmath54 the condition   can be verified in polynomial time , problem  [ pb : pwadecision ] is in np .",
    "then , the proof of its np - completeness proceeds by showing that the partition problem  [ pb : partition ] has an affirmative answer if and only if problem  [ pb : pwadecision ] with @xmath55 has an affirmative answer .    given an instance of problem  [ pb : partition ] , let @xmath56 , @xmath28 , @xmath57 and build a data set with @xmath58 where @xmath59 is the @xmath60th unit vector of the canonical basis for @xmath61 and @xmath62",
    ". if problem  [ pb : partition ] has an affirmative answer , then , using the notations of  , we can set @xmath63 where @xmath64^t$ ] , @xmath65 is the set of indexes of the elements of @xmath66 in @xmath67 and @xmath68 .",
    "this gives @xmath69 and we can similarly show that @xmath70 while @xmath71 is positive if @xmath72 and negative if @xmath73 .",
    "therefore , for all points , @xmath74 , @xmath75 , and the cost function of problem  [ pb : pwa ] is zero , yielding an affirmative answer for problem  [ pb : pwadecision ] .",
    "it remains to prove that if   holds with @xmath55 , then problem  [ pb : partition ] has an affirmative answer . to see this , note that due to @xmath46",
    "being positive , a zero cost implies a zero loss for all data points .",
    "thus , by @xmath47 , if   holds with @xmath55 , @xmath76 also note that if @xmath77 for some @xmath78 , we have @xmath79 .",
    "this is only possible if @xmath80 , which is not the case ( otherwise we can simply remove @xmath81 without influencing the partition problem ) , or if @xmath82 .",
    "the latter is impossible if @xmath83 since @xmath26 is a linear classifier that must return the same category for all points on the line segment between @xmath84 and @xmath85 , which includes the origin @xmath86 and thus would imply by   that @xmath87 . as a consequence , @xmath77 can not hold , and since we can similarly show that @xmath88 can not hold , we have @xmath89 for all @xmath78 .",
    "hence ,   leads to @xmath90 let @xmath91 and @xmath92 . then , if @xmath93 , @xmath94 and for all @xmath78 , @xmath95 . therefore , for all @xmath96 , @xmath97 , while for all @xmath98 , gives @xmath99 , i.e. , @xmath100 and @xmath101 .",
    "this leads to @xmath102 thus , if @xmath103 or @xmath104 , a valid partition in the sense of problem  [ pb : partition ] is obtained with @xmath105 .",
    "in addition , if @xmath106 and @xmath107 , then by  , @xmath108 , which by construction implies that @xmath109 . in this case , we redefine @xmath110 and @xmath111 to obtain @xmath112 for all @xmath98 and @xmath113 for all @xmath96 , resulting also in a valid partition by the fact that @xmath114 .",
    "since a similar reasoning applies to the case @xmath115 by symmetry ( substituting @xmath116 for @xmath117 ) , a zero cost , i.e. , with @xmath55 , always implies an affirmative answer to problem  [ pb : partition ] .",
    "since the decision form of problem  [ pb : pwa ] with @xmath47 , i.e. , problem  [ pb : pwadecision ] , is np - complete , problem  [ pb : pwa ] with such a loss function is np - hard ( solving problem  [ pb : pwa ] also yields the answer to problem  [ pb : pwadecision ] and thus it is at least as hard as problem  [ pb : pwadecision ] ) .",
    "we now state the result regarding the polynomial complexity of problem  [ pb : pwa ] with respect to @xmath8 under the following assumptions , the first of which holds almost surely for randomly drawn data points , while the second one holds for instance for @xmath118 with a linear time complexity @xmath119 @xcite .    [",
    "ass : generalposition ] the points @xmath120 are in general position , i.e. , no hyperplane of @xmath61 contains more than @xmath39 points .",
    "[ ass : subpb ] given @xmath121 , the problem @xmath122 has a polynomial time complexity @xmath123 for any fixed integer @xmath124 .    [ thm : main ] for any fixed number of modes @xmath22 and dimension @xmath39 , under assumptions  [",
    "ass : generalposition][ass : subpb ] , the time complexity of problem  [ pb : pwa ] is no more than polynomial in the number of data @xmath8 and in the order of @xmath125 .",
    "the proof of theorem  [ thm : main ] relies on the existence of exact algorithms with complexity polynomial in @xmath8 for the binary case ( @xmath28 , proposition  [ prop : exact ] ) and the multi - class case ( @xmath126 , corollary  [ cor : multiclass ] ) .",
    "these algorithms are based on a reduction of problem  [ pb : pwa ] to a combinatorial search in two steps .",
    "the first step reduces the problem to a classification one .",
    "indeed , problem  [ pb : pwa ] can be reformulated as the search for the classifier @xmath26 , since by fixing @xmath26 , the optimal parameter vectors @xmath127 can be obtained by solving @xmath22 independent linear regression problems on the subsets of data resulting from the classification by @xmath26 , which , by assumption  [ ass : subpb ] , can be performed in the polynomial time @xmath123 .",
    "this yields the following reformulation of the problem .",
    "[ prop : pwals ] problem  [ pb : pwa ] is equivalent to @xmath128    the second step reduces the estimation of @xmath26 to a combinatorial problem solved in @xmath129 operations , as detailed in sect .",
    "[ sec : optclassif][sec : globalpwa ] for @xmath28 and in sect .",
    "[ sec : multiclass ] for @xmath126 .",
    "we reduce the complexity of searching for the classifier by considering all possible linear classifications instead of all possible linear classifiers . in other words",
    ", we project the class @xmath31 of classifiers onto the set of points @xmath130 to reduce a continuous search to a combinatorial problem .",
    "this is in line with the techniques used in statistical learning theory @xcite for the different purpose of computing error bounds for infinite function classes .",
    "thus , we introduce definitions from this field .",
    "the projection of a set of classifiers @xmath45 onto @xmath130 , denoted @xmath131 , is the set of all labelings of @xmath66 that can be produced by a classifier in @xmath31 : @xmath132    the _ growth function _",
    "@xmath133 of @xmath31 at @xmath8 is the maximal number of labelings of @xmath8 points that can be produced by classifiers from @xmath31 : @xmath134    we now focus on binary pwa maps and thus on binary classifiers with output in @xmath29 . for such classifiers , we obviously have @xmath135 for all @xmath8 . by further restricting @xmath31 to affine classifiers as in",
    ", results from statistical learning theory ( see , e.g. , @xcite ) provide the tighter bound @xmath136 , which is polynomial in @xmath8 and thus promising from the viewpoint of global optimization .",
    "however , its proof is not constructive and does not provide an explicit algorithm for enumerating all the labelings . the following theorem , though leading to a looser bound on the growth function , offers a constructive scheme to compute the projection @xmath131 , which is what we need in order to test all the labelings in @xmath131 for global optimization .",
    "[ thm : enum ] the growth function of the class of binary affine classifiers of  @xmath61 , @xmath31 in , is bounded for any @xmath137 by @xmath138 and , for any set @xmath66 of @xmath8 points in general position , an algorithm builds the projection @xmath131 in @xmath139 time .",
    "the proof of theorem  [ thm : enum ] relies on the following proposition , which is illustrated by fig .  [",
    "fig : prophyperplane ] .",
    "( plain line ) produces the same classification ( into and ) as the hyperplane @xmath140 ( dashed line ) obtained by a translation ( dotted line ) and a rotation of @xmath141 such that it passes through exactly 2 points of @xmath66 ( ) .",
    "[ fig : prophyperplane ] ]    [ prop : hyperplane ] for any binary affine classifier @xmath26 in @xmath31 and any finite set of @xmath137 points @xmath142 in general position , there is a subset of points @xmath143 of cardinality @xmath144 and a separating hyperplane of parameters @xmath145 passing through the points in @xmath146 , i.e. , @xmath147",
    "which yields the same classification of @xmath66 in the sense that @xmath148    for all classifiers @xmath26 with separating hyperplanes passing through @xmath39 points of @xmath66 , the statement is obvious . for the others passing through @xmath149 points with @xmath150",
    ", they can be transformed to pass through additional points without changing the classification of the remaining points .",
    "if @xmath151 , it suffices to translate the hyperplane to the closest point . if @xmath152 , the hyperplane can be rotated with a plane of rotation that leaves unchanged the subspace spanned by the @xmath149 points and a minimal angle yielding a rotated hyperplane passing through @xmath153 points , where @xmath154 by the general position assumption",
    "iterating this scheme until @xmath155 yields a hyperplane passing through the points in @xmath146 of parameters @xmath145 satisfying   and",
    ".    we can now prove theorem  [ thm : enum ] .",
    "for any labeling @xmath156 in @xmath131 , there is a classifier @xmath157 that produces this labeling .",
    "applying proposition  [ prop : hyperplane ] to @xmath26 , we obtain another classifier @xmath158 of parameters @xmath145 that passes through the points in @xmath146 and that agrees with @xmath26 on @xmath159 .",
    "let @xmath160 be defined by @xmath161 , @xmath162 .",
    "then , we generate @xmath163 labelings by setting its entries @xmath164 with @xmath165 to all the @xmath163 combinations of signs ( recall that @xmath166 ) . by construction , there is no labeling of @xmath66 that agrees with @xmath156 on @xmath159 other than these @xmath163 labelings .",
    "since this holds for any @xmath167 , the cardinality of @xmath131 can not be larger than @xmath163 times the number of hyperplanes passing through @xmath39 points of @xmath66 . since each subset @xmath143 of cardinality @xmath39 gives rise to two hyperplanes of opposite orientations ,",
    "the number of such hyperplanes is @xmath168 and we have @xmath169 . in addition",
    ", there is an algorithm that enumerates all the subsets @xmath146 in @xmath170 iterations and builds @xmath131 by computing a hyperplane passing through the points of a hyperplane @xmath171 passing through @xmath39 points @xmath172 in @xmath61 can be computed as a unit vector in the null space of @xmath173 @xmath174^t$ ] , while the offset is given by @xmath175 for any of the @xmath84 s . ] in @xmath146 and the corresponding @xmath176 labelings at each iteration .",
    "since these inner computations can be performed in constant time with respect to @xmath8 , the algorithm has a time complexity in the order of @xmath177 .",
    "we can use the results above to reduce the complexity of problem  [ pb : pwa ] in the binary case , considered in the following in its equivalent form from proposition  [ prop : pwals ] .",
    "first , note that the cost function in   only depends on @xmath26 , since all feasible values of @xmath178 for a given @xmath26 yield the same cost .",
    "furthermore , the cost does not depend on the exact value of @xmath26 , but only on the resulting classification , i.e. , on @xmath179 , @xmath162 .",
    "thus , given a global solution @xmath180 to , any classifier @xmath26 producing the same classification yields the same cost function value and hence is also a global solution .",
    "thus , the problem reduces to the search for the correct classification @xmath181 , whose complexity is in @xmath182 and bounded by theorem  [ thm : enum ] .",
    "in addition , for the purpose of binary pwa regression , opposite labelings @xmath156 and @xmath183 are equivalent and can be pruned from @xmath131 .",
    "this is due to the symmetry of the cost function .",
    "algorithm  [ alg : exact ] provides a solution to problem  [ pb : pwa ] for the binary case while taking this symmetry into account .    a data set @xmath184 .",
    "initialize @xmath185 and @xmath186 .",
    "compute the parameters @xmath145 of a hyperplane passing through the points in @xmath146 .",
    "classify the data points : @xmath187 , @xmath188 .",
    "set @xmath189 @xmath190 and update the best solution @xmath191^t , { \\boldsymbol{h}}^ * \\leftarrow { \\boldsymbol{h}}_{s_h } , b^ * \\leftarrow b_{s_h } ) $ ] if @xmath192 .",
    "@xmath193 .",
    "[ prop : exact ] under assumptions  [ ass : generalposition][ass : subpb ] , algorithm  [ alg : exact ] exactly solves problem  [ pb : pwa ] for @xmath28 and any fixed @xmath39 with a polynomial complexity in the order of @xmath194 .    by following a similar path as for theorem",
    "[ thm : enum ] , algorithm  [ alg : exact ] can be proved to test all linear classifications of the data points up to symmetric ones . since algorithm  [ alg : exact ]",
    "computes a solution in terms of @xmath178 that is feasible for   for each of these classifications , the value of @xmath195 coincides with the cost function of   for a particular @xmath26 . by the symmetry of this cost function with respect to @xmath26 and",
    "the fact that it only depends on @xmath26 via its values at the data points , algorithm  [ alg : exact ] computes all possible values of the cost function , including the exact global optimum of  , and returns a global minimizer .",
    "thus , by proposition  [ prop : pwals ] , it also solves problem  [ pb : pwa ] .",
    "the total number of iterations of algorithm  [ alg : exact ] is @xmath196 and , under assumption  [ ass : subpb ] , these iterations only involve operations computed in polynomial time in the order of @xmath123 , hence the overall time complexity in the order of @xmath194 .      for @xmath197 , the boundary between 2 modes @xmath198 and @xmath199 implemented by a linear classifier from @xmath31 in is a hyperplane of equation @xmath200 , i.e. , based on the difference of the two functions @xmath201 and @xmath202 .",
    "based on these hyperplanes , the classification rule can be written as@xmath203 based on these facts , we can build an algorithm to recover all possible classifications consistent with a linear classification in the sense of  .",
    "[ thm : multiclass ] for the set of multi - class linear classifiers of  @xmath61 , @xmath31 in , the growth function is bounded for any @xmath137 by @xmath204^{n(n-1)/2 } = { \\mathcal{o}}(n^{dn(n-1)/2})\\ ] ] and , for any set @xmath66 of @xmath8 points of @xmath61 in general position , an algorithm builds @xmath131 in @xmath205 time .    any classification produced by a classifier from can be computed from the signs of the @xmath206 functions @xmath207 , @xmath208 , corresponding to the pairwise separating hyperplanes . for any @xmath66 , for each of these hyperplanes , proposition  [ prop : hyperplane ] provides an equivalent binary classifier which must be one from the @xmath168 hyperplanes passing through @xmath39 points @xmath209 of @xmath66 .",
    "the number of sets of @xmath210 such hyperplanes is @xmath211 .",
    "since these classifiers can not produce all the @xmath212 classifications of the @xmath213 points in the sets @xmath209 , we must also take these into account so that the number of classifications of @xmath66 is upper bounded by @xmath214 .",
    "this upper bound holds for any @xmath66 , and thus also applies to the growth function .",
    "finally , an algorithm that makes explicit all the classifications mentioned above to build @xmath131 can be constructed in a recursive manner , with one classification per iteration and thus with a similar number of iterations , each one including computations performed in constant time .",
    "theorem  [ thm : multiclass ] implies the following for pwa regression .",
    "[ cor : multiclass ] under assumptions  [ ass : generalposition][ass : subpb ] , a global solution to problem  [ pb : pwa ] with @xmath126 can be computed with a polynomial complexity in the order of @xmath215 .",
    "the paper discussed complexity issues for pwa regression and showed that i ) the global minimization of the error is np - hard in general , and ii ) for fixed number of modes and data dimension , an exact solution can be obtained in time polynomial in the number of data .",
    "the proof of np - hardness also implies that the problem remains np - hard even when the number of modes is fixed to  @xmath216 , which indicates that the complexity is mostly due to the data dimension .",
    "an open issue concerns the conditions under which a pwa system generates trajectories satisfying the general position assumption used by the polynomial - time algorithm .",
    "future work will also focus on the extension of the results to the case of arbitrarily switched systems and heuristics inspired by the polynomial - time algorithm , whose practical application remains limited by an exponential complexity in the dimension .",
    "the author would like to thank the anonymous reviewers for their comments and suggestions .",
    "thanks are also due to yann guermeur for carefully reading this manuscript .",
    "r.  vidal , s.  soatto , y.  ma , s.  sastry , an algebraic geometric approach to the identification of a class of linear hybrid systems , in : proc . of the 42nd ieee conf . on decision and control ( cdc ) , maui ,",
    "hawa , usa , 2003 , pp . 167172 .",
    "f.  lauer , estimating the probability of success of a simple algorithm for switched linear regression , nonlinear analysis : hybrid systems 8 ( 2013 ) 3147 , supplementary material available at http://www.loria.fr/~lauer / klinreg/.            f.  lauer , v.  l. le , g.  bloch , learning smooth models of nonsmooth functions via convex optimization , in : proc . of the ieee int .",
    "workshop on machine learning for signal processing ( mlsp ) , santander , spain , 2012 ."
  ],
  "abstract_text": [
    "<S> the paper provides results regarding the computational complexity of hybrid system identification . </S>",
    "<S> more precisely , we focus on the estimation of piecewise affine ( pwa ) maps from input - output data and analyze the complexity of computing a global minimizer of the error . </S>",
    "<S> previous work showed that a global solution could be obtained for continuous pwa maps with a worst - case complexity exponential in the number of data . in this paper , we show how global optimality can be reached for a slightly more general class of possibly discontinuous pwa maps with a complexity only polynomial in the number of data , however with an exponential complexity with respect to the data dimension . </S>",
    "<S> this result is obtained via an analysis of the intrinsic classification subproblem of associating the data points to the different modes . </S>",
    "<S> in addition , we prove that the problem is np - hard , and thus that the exponential complexity in the dimension is a natural expectation for any exact algorithm . </S>"
  ]
}