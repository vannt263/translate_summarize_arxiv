{
  "article_text": [
    "from considerations of multifractals , tsallis @xcite was led to conjecture a generalization of the boltzmann - gibbs entropy given by @xmath0 , \\label{eqn : tsallis_entropy}\\ ] ] where @xmath1 is a probability distribution for a discrete random variable with values @xmath2 and @xmath3 is any real number different from one .",
    "@xmath4 is defined to be the usual boltzmann - gibbs entropy , in agreement with the limit @xmath5 .",
    "( boltzmann s constant is set to one . )",
    "non - gibbsian distributions are obtained by extremizing the tsallis entropy under special constraints , described below , while using @xmath3 as an adjustable parameter .",
    "the parameter @xmath3 typically has no direct physical interpretation , but when it is used as an adjustable parameter the resulting distributions can give surprisingly good agreement with experimental data in a wide variety of fields @xcite . in a few cases , @xmath3",
    "is uniquely determined by the constraints of the problem and may thereby bear some physical interpretation @xcite .",
    "although the tsallis entropy preserves all of the familiar thermodynamic formalism , curado @xcite has noted that this is true of a much broader class of entropies .",
    "given the myriad of possible entropy functions , one is led to ask why the tsallis entropy is special , and a natural place to look for answers is in the theory of large deviations @xcite , which gives a probabilistic justification for the maximum entropy principle in terms of a unique entropy function . in this brief report",
    "we compare the probabilities obtained by tsallis s maximum entropy principle with the asymptotic frequencies predicted by large deviation theory ( i.e. the law of large numbers ) under similar constraints .",
    "we find that the two do not in general agree .",
    "if no constraints are imposed upon @xmath6 ( other than that it be nonnegative and normalized ) , @xmath7 is readily seen to be extremized by @xmath8 .",
    "( the case @xmath9 is special , as @xmath10 is a constant function . )",
    "this conclusion , independent of @xmath3 , agrees with the usual boltzmann - gibbs result and corresponds to a microcanonical ensemble .",
    "if we view @xmath11 as a sampling distribution , then the empirical distribution of frequencies obtained from a random sample @xmath12 converges to @xmath11 almost surely as @xmath13 grows large .",
    "this well - known result , originally due to boltzmann @xcite , may be viewed as a example of the ( strong ) law of large numbers . since @xmath14 has a global extremum at @xmath11 , the distribution predicted by extremizing @xmath7 agrees with the actual asymptotic empirical distribution .    placing additional constraints when extremizing @xmath7 may result in a distribution dependent upon @xmath3 , i.e. one at variance with that predicted from the boltzmann - gibbs case @xmath15 . as a generalization of the internal energy constraint ,",
    "tsallis @xcite has suggested the following constraint be used when extremizing @xmath7 : @xmath16 where @xmath17 is a given fixed constant . for @xmath15",
    "this of course reduces to the usual expectation value constraint . by extremizing ( [ eqn : tsallis_entropy ] ) subject to ( [ eqn : q - expectation ] ) ,",
    "one obtains a solution in general different from the boltzmann distribution .",
    "this solution is given explicitly by @xmath18^{1/(1-q ) } , \\label{eqn : q - canonical}\\ ] ] where @xmath19 is chosen such that eqn .",
    "( [ eqn : q - expectation ] ) is satisfied .",
    "it has been noted that this explicit form of the distribution appears to be more numerically robust than the more common implicit form , for which @xmath20 @xcite .",
    "for @xmath15 the constraint on the expectation may be interpretation as a constraint on the sample mean , the two being equivalent for large samples .",
    "thus , if we consider random samples @xmath12 from @xmath11 which satisfy @xmath21 then the empirical distributions of such samples will approach the boltzmann distribution @xmath22 as @xmath13 grows large .",
    "the question arises whether a similar interpretation may be made of the constraint in eqn .",
    "( [ eqn : q - expectation ] ) for @xmath23 and , more importantly , whether the resulting empirical distribution converges to that given by eqn .",
    "( [ eqn : q - canonical ] ) .",
    "as our observable is discrete , let @xmath24 denote the observed frequency of @xmath25 in the sample @xmath12 .",
    "( there is no obvious interpretation for continuous values . )",
    "we may interpret eqn .",
    "( [ eqn : q - expectation ] ) to mean @xmath26 we will show that random samples drawn from @xmath11 which satisfy eqn.([eqn : empirical_constraint ] ) do not in general give rise to empirical distributions which converge to the tsallis prediction of eqn .",
    "( [ eqn : q - canonical ] ) .",
    "the general problem we are considering is the convergence in probability of the empirical frequencies @xmath27 , where @xmath28 is a random vector with domain @xmath29 taking values in the convex set @xmath30 .",
    "unconstrained , an infinite random sample @xmath31 from @xmath11 gives rise to a sequence of empirical frequencies which converge in probability to @xmath11 .",
    "theorem @xcite gives the large deviation rate function for this convergence to be just the negative of the boltzmann - gibbs entropy : @xmath32 loosely speaking , sanov s theorem states that for @xmath33 , @xmath34 \\sim \\exp[-n\\inf_{p\\in a } i_{\\mu}(p)]$ ] for large @xmath13 ( cf . the boltzmann - einstein formula @xmath35 ) . the asymptotic measure , @xmath11 , is the unique minimum of the rate function @xmath36 , which is continuous and strictly convex .    when we impose additional constraints on @xmath28 , the asymptotic value changes from @xmath11 to a new distribution which minimizes @xmath36 under the added restrictions @xcite",
    "if we condition on the sample mean for example , i.e. @xmath37 the resulting asymptotic distribution is no longer @xmath11 but the canonical distribution @xmath38 , where @xmath39 satisfies @xmath40 it is in this sense that finding the asymptotic empirical distribution under ( [ eqn : fixed_mean ] ) is equivalent to maximizing @xmath4 under ( [ eqn : fixed_expectation ] ) .    more generally , imposing condition ( [ eqn : empirical_constraint ] ) results in an asymptotic distribution which minimizes @xmath36 ( maximizes @xmath4 ) subject to ( [ eqn : q - expectation ] ) .",
    "this distribution is given implicitly by @xmath41 , \\label{eqn : asymptotic_distribution}\\ ] ] where @xmath39 is such that eqn .",
    "( [ eqn : q - expectation ] ) is satisfied with @xmath6 replaced by @xmath42 .",
    "comparison with eqn.([eqn : q - canonical ] ) shows that both @xmath6 and @xmath42 will agree when @xmath5 .",
    "for @xmath9 , eqn .",
    "( [ eqn : q - canonical ] ) gives @xmath43/m$ ] , with @xmath19 unrestricted , while eqn.([eqn : asymptotic_distribution ] ) implies @xmath44 .",
    "clearly both agree if @xmath19 is arbitrarily chosen to be zero .",
    "however , as we have noted @xmath10 is a constant function , so the entropy extremization procedure may be expected to break down in this case .",
    "taking @xmath17 to be the equilibrium value @xmath45 also results in general agreement between @xmath6 and @xmath42 for all @xmath46 .",
    "indeed , by choosing @xmath47 we see that @xmath48 is the unique solution for both eqn.([eqn : q - canonical ] ) and eqn .",
    "( [ eqn : asymptotic_distribution ] ) .",
    "this agreement simply reflects that fact that both @xmath49 and @xmath7 have the same global extremum .",
    "when @xmath50 the two constraints are sufficient to uniquely determine the distribution , and for this reason general agreement is also expected . in particular",
    "we find @xmath51 assuming @xmath52 and @xmath46 . it is readily verified that eqn .",
    "( [ eqn : q - expectation ] ) is satified . by solving for @xmath19 and @xmath39 , eqns .",
    "( [ eqn : q - canonical ] ) and ( [ eqn : asymptotic_distribution ] ) , respectively , may be satisfied as well .",
    "disagreement between @xmath6 and @xmath42 is therefore expected when @xmath53 . to show this explicitly",
    ", we may compute @xmath6 from eqn.([eqn : q - canonical ] ) for an arbitary @xmath17 and then search for a value of @xmath39 such that eqn .",
    "( [ eqn : asymptotic_distribution ] ) is satisfied when @xmath6 is substituted for @xmath42 .",
    "the claim is that a single @xmath39 can not always be found which satisfies this equation for all values of @xmath54 when @xmath53 .",
    "the case @xmath55 is particularly amenable to analytic study @xcite and appears in an early application of the tsallis entropy to turbulence in a two - dimensional electron plasma @xcite . for this case ,",
    "( [ eqn : q - canonical ] ) may be solved explicitly in terms of @xmath17 to obtain @xmath56 ^ 2.\\ ] ] using a given value of @xmath17 and the corresponding @xmath6 given above , we then consider zeros of the functions @xmath57 , where @xmath58}{\\sum_{j=1}^{m } \\exp\\left[-\\beta(\\epsilon_j - u)p_j^{-1/2}\\right ] } - p_i,\\ ] ] for @xmath59 . a plot of these functions is shown in fig.[fig : zeros ] for selected parameter values .",
    "the failure of all three graphs to have a zero at the same value of @xmath39 indicates that @xmath6 and @xmath42 are in this case distinct .    from this example one can derive a general necessary condition for agreement with @xmath42 .",
    "suppose that for given @xmath3 , @xmath60 , and @xmath17 there exists a simultaneous solution to both eqns.([eqn : q - canonical ] ) and ( [ eqn : asymptotic_distribution ] ) .",
    "( more generally , @xmath6 may be any probability distribution satisfying eqn .",
    "( [ eqn : q - expectation ] ) . )  substituting the former into the latter we find @xmath61 / z(\\beta ) , \\label{eqn : impossible}\\ ] ] where @xmath62.\\ ] ] the value of each @xmath63 is fixed in terms of the given parameters , so a single value of @xmath39 must simultaneously satisfy eqn.([eqn : impossible ] ) for @xmath59 . if any @xmath64 then eqn .  ( [ eqn : impossible ] ) can not possibly be satisfied , so suppose all @xmath63 are nonzero .",
    "for any given @xmath65 , @xmath66 / [ ( \\epsilon_j - u)p_j^{q-1}].\\ ] ] substituting this expression back into eqn .",
    "( [ eqn : impossible ] ) gives @xmath67 the rhs of eqn .",
    "( [ eqn : impossible_too ] ) is invariant under the interchange of @xmath54 and @xmath68 , so it has at most @xmath69 distinct values .",
    "the lhs , of course , is the same for all choices of @xmath54 and @xmath68 .",
    "now , the rhs will be independent of the choice of @xmath54 and @xmath68 if either ( 1 ) @xmath70 , ( 2 ) @xmath50 , or ( 3 ) @xmath71 for all @xmath54 and @xmath68 , the latter being equivalent to @xmath72 , which is equivalent to @xmath73 .",
    "assuming none of these three conditions hold , the rhs must be the same for all choices of @xmath54 and @xmath68 if indeed @xmath74 .",
    "this gives a necessary condition for agreement .",
    "we have compared the probability distribution over @xmath75 states predicted from tsallis s maximum entropy principle , which constrains the normalized @xmath3-expectation to a value @xmath17 , to the asymptotic frequencies when the empirical @xmath3-expectation is similarly constrained .",
    "the two will always agree if either ( 1 ) @xmath70 , ( 2 ) @xmath50 , or ( 3 ) @xmath72 .",
    "a specific example for which @xmath55 and @xmath76 was used to demonstrate numerically that the two distributions may be different . for the case in which none of these three conditions hold , we derived a necessary condition to be satisfied by any candidate distribution in order that it be identical to true asymptotic distribution .    from the point of view of large deviation theory",
    ", the maximum entropy principle specifies the overwhelmingly most probable distribution to be realized by a large - sample empirical distribution under given constraints .",
    "the uniqueness of the rate function in large deviation theory implies that the boltzmann - gibbs entropy plays a special role in determining this most likely distribution . for this reason",
    ", novel entropy functions such as that proposed by tsallis may give results which are at variance with actual sample frequencies except , as observed , in some special cases ."
  ],
  "abstract_text": [
    "<S> tsallis has suggested a nonextensive generalization of the boltzmann - gibbs entropy , the maximization of which gives a generalized canonical distribution under special constraints . in this brief report </S>",
    "<S> we show that the generalized canonical distribution so obtained may differ from that predicted by the law of large numbers when empirical samples are held to the same constraint . </S>",
    "<S> this conclusion is based on a result regarding the large deviation property of conditional measures and is confirmed by numerical evidence . </S>"
  ]
}