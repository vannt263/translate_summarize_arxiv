{
  "article_text": [
    "suppose we have distributed many sensors in a region , each of which detects if it rains at that point .",
    "we want to obtain a summary : in which sub - region is it raining ? just listing all the positions at which a raindrop has been detected is not a helpful answer , first because a long list of positions is not the answer a user would want on the question `` where does it rain ? , '' but also because each individual answer is subject to random errors ; the detected drop of water could have come from an air - conditioner , or from children splashing in the water , or numerous other random events , and in the same way , even if it is raining , the sensor might coincidentally not catch any drop .",
    "we expect a useful answer to the question `` where does it rain ? '' to be some region with a simple structure .",
    "the abstract model underlying this question is as follows : we have a region @xmath1 , in which there is a set @xmath5 of sensors .",
    "there is an unknown region @xmath6 in which the event happens .",
    "possible events would be rain , forest fires , or occurrences of invasive species .",
    "we want to detect the event region @xmath0 , most importantly , its boundary , where it is far from the boundary of @xmath1 and has a ` nice ' topology , not being highly irregular , random or fractal .",
    "the sensors @xmath7 are 0 - 1 sensors who decide whether @xmath8 or @xmath9 , making an error with probability @xmath3 in this measurement , called the measurement error .",
    "our aim is to reduce the error rate in detecting the boundary of @xmath0 by allowing each sensor to compare its result with those of its neighbors . to reduce the error rate by local communication",
    ", we assume that each sensor knows the values measured by all neighboring sensors within distance @xmath4 . the most straightforward method to use the neighbors sensing information is to follow the majority .",
    "this majority vote scheme is as follows : if the sensor has @xmath10 neighbors and knows its own and those @xmath10 other measurements , then in its revised decision it just follows the majority of the measurements of its @xmath10 neighbors , with itself as tie - breaking if necessary .",
    "this scheme was already proposed by chintalapudi and govindan  @xcite and further in  @xcite .",
    "it does not use the position information of the neighboring sensors .",
    "it was stated in  @xcite that this scheme gives a good correction of measurement errors for sensor error @xmath3 up to @xmath11 .",
    "however , we think this observation needs further qualification , since the situation really depends on the size of voting neighborhood and several geometric parameters of the boundary of @xmath0 .",
    "sensors are distributed uniformly in a unit square @xmath1 , and the gray - colored region is the event region @xmath0 . among @xmath12 sensors , @xmath13 sensors ( marked by black boxes in left figure ) made wrong initial measurements , but @xmath14 sensors ,",
    "@xmath15 of misclassified ones , revised correctly ( marked by gray discs in the right figure ) , and the other @xmath16 sensors ( marked by black boxes ) remained still in their wrong classification , but @xmath17 sensors ( marked by black discs ) turned from the correct classification to the wrong classification.,width=415 ]    figure  [ fig : intro ] shows a simulation on the majority vote scheme with @xmath12 sensors distributed uniformly in a unit square @xmath1 .",
    "the event region @xmath0 is a square of side length @xmath18 with rounded corners of the curvature radius @xmath19 .",
    "the measurement error probability @xmath20 and the neighborhood radius @xmath21 .",
    "the error correction rate by this scheme is about @xmath22 . from this simulation",
    ", one can observe that the total error of event detection is significantly reduced by the majority vote scheme .",
    "in fact , the error depends on several sensing parameters such as the measurement error @xmath3 and the neighborhood radius @xmath4 , and some geometric parameters of the event region @xmath0 such as the convexity , the perimeter and the boundary curvature .    in this paper",
    ", we analyze the majority scheme further , and make explicit and precise the dependency on these parameters . to analyze this , we first need an assumption on the distribution of sensors in the region of interest @xmath1 .",
    "we adapt the most important model ; the sensors are randomly distributed by a poisson process of density @xmath2 , which is independent from the measurement error @xmath3 that the sensors make . to our best knowledge",
    ", this gives the first bounds on the expected number of incorrectly classified sensors in the majority vote scheme with all these parameters , @xmath2 , @xmath3 , @xmath4 , and the shape of @xmath0 .",
    "it should be noticed that our sensors are point sensors ; there is no sensing range , but a yes / no decision about the situation at the sensor .",
    "many other papers have dealt with continuous - valued sensors , but then the dependence of a sensor s decision on the neighboring values is much less clear . also , for many practical applications a yes / no decision is ultimately the desired answer : ` does it rain ? ' , ` is there a forest fire ? ' , etc .",
    "the distance @xmath4 within which we compare the sensor values is not related to the communication distance of the network nodes ; it is a choice made depending on our a - priori knowledge on the size and shape of @xmath0 , that is , choosing the right radius @xmath4 is an important aspect .",
    "finally , our majority vote scheme does not need absolute positions of the sensors , but it is not efficient in detecting thin and long event regions ; to identify such event regions we would need sensors with known positions with the help of gps units and by more complicated decision algorithms .",
    "local event boundary detection problem has been studied in several previous papers .",
    "chintalapudi and govindan  @xcite were the first to analyze the local event boundary detection problem .",
    "they proposed three different types of algorithms ; among them a simple neighborhood counting scheme that does not use the position information of the neighboring sensors , and a scheme that finds the optimum line separating in the neighborhood the event - sensors from the no - event - sensors .",
    "they found by simulation that the separating - line scheme performs best , but provided no analysis of that scheme , and assumed for the other schemes that the event boundary is a straight line .",
    "krishnamachari and iyengar  @xcite discussed a model with a similar counting scheme , not using the neighbor s position information ; in their simulation , however , the sensors are always distributed in a square grid .",
    "wu et al .",
    "@xcite discussed continuous - valued sensors , looking for threshold events , and proposed several methods based on comparing a sensor s value with the median of a set of neighbor s values to identify faulty or boundary sensors .",
    "similar was the discussion by jin and nittel  @xcite , who used the mean instead of the median .",
    "ding and cheng  @xcite fit a mixture of multivariate gaussian distributions to the observed sensor values and decided on the base of that fitted model which sensors are boundary sensors .",
    "wang et al .",
    "@xcite considered a model that can be interpreted as only no - event sensors being available , e.g. , because the event like the fire in the forest destroyed all sensors in its region ; they reconstruct a boundary of the regione containing sensors , based on neighbor connectivity information without the neighbor positions .",
    "nowak and mitra  @xcite use a non - local communication model based on a hierarchical partitioning scheme to identify event boundaries .",
    "a different line of related works contains the fusion of different information sources for the same event ; e.g. , combining the output of multiple classifiers in a pattern - recognition problem .",
    "this has been studied in @xcite , but that problem abstracts from the geometric structure which is the core of our considerations .",
    "yet another related line of works contains the opinion formation in social networks : instead of spatially related nodes , we have persons with friends , and a person might change his opinion to conform to the majority opinion of his group .",
    "this has been studied both as social dynamics and as abstract process on graphs , see , e.g. , @xcite .",
    "majority vote among neighbors has also been studied as model for some spin systems in physics , see e.g. , @xcite .      for a set @xmath23 in the plane",
    ", we denote its area , perimeter , boundary and number of components , by @xmath24 , @xmath25 and @xmath26 , respectively .",
    "we assume that the set @xmath5 of sensors is generated by a poisson process of density @xmath2 on our region of interest @xmath1 . within @xmath1",
    ", an event happens in the region @xmath0 .",
    "each sensor @xmath7 makes a 0 - 1 event detection ( or measurement ) , whether @xmath27 or @xmath28 , which might be incorrect with probability @xmath3 .",
    "the sensor errors are independent from each other , and from the poisson process placing the sensors .",
    "each sensor knows the measurement results of all other sensors within radius @xmath4 and revises his own measurement based on that information .",
    "the comparison with neighboring sensors gives information only if the sensor has neighboring sensors .",
    "the expected number of neighbors in this model is @xmath29 and thus the probability that a sensor has no neighbors is @xmath30 , which should be much smaller than the measurement error @xmath3 .",
    "the expected number of sensors in @xmath1 is @xmath31 , so without correction by neighborhood comparison , the expected number of incorrect sensors , i.e. , misclassified sensors , is @xmath32 .",
    "theorem  [ thm : general_outz ] and theorem  [ thm : general_inz ] show that the expected number of misclassified sensors is improved significantly by the majority vote scheme .",
    "let @xmath33 be the set of points within distance @xmath4 to the boundary of @xmath0 .",
    "any sensor in this dubious region @xmath33 has potentially neighbors inside and outside @xmath0 , in other words , we possibly have both of correct 0- and 1-answers within the same neighborhood , which would lead such sensors to make the wrong decision after the majority vote .",
    "thus the analysis on the expected number of misclassified sensors in @xmath33 is a key in the majority vote scheme .    in section  [ sec :",
    "analysis ] , we analyze the majority vote scheme in a most general setting and derive the following bounds on the expected number of misclassified sensors in @xmath34 and on the expected number of misclassified sensors in @xmath33 .    [ thm : general_outz ] for @xmath35 , the expected number of sensors in @xmath36 that are misclassified by the simple majority rule in the neighborhood of radius @xmath4 is at most @xmath37 and at least @xmath38    [ thm : general_inz ] for @xmath35 , the expected number of sensors in @xmath33 that are misclassified by the simple majority rule in the neighborhood of radius @xmath4 is at most @xmath39 there exists some event region @xmath0 such that the expected number of misclassified sensors in @xmath33 is at least @xmath40 .",
    "the ratio of the upper bound to the lower bound in theorem  [ thm : general_outz ] grows linearly with the expected number of neighbors @xmath29 .",
    "however , since @xmath41 for any @xmath42 , they both decrease exponentially with the expected number of neighbors @xmath29 , so the expected number of misclassified sensors outside @xmath33 decreases exponentially with the expected number of neighbors @xmath29 .",
    "theorem  [ thm : general_inz ] tells us that the expected number of sensors in @xmath33 grows with the parameters @xmath2 and @xmath4 , and the perimeter of @xmath0 .",
    "thus a region @xmath0 with long boundary or with many components would be the worst in the majority vote scheme .",
    "moreover such worst examples exist . as a result ,",
    "theorems  [ thm : general_outz ] and  [ thm : general_inz ] illustrate the trade - off between the error outside @xmath33 , which decreases exponentially with @xmath2 and @xmath4 , and the error inside @xmath33 , which increases with @xmath2 and @xmath4 .",
    "sensors very near to the boundary of @xmath0 can be unavoidably misclassified according to theorem  [ thm : general_inz ] . if @xmath0 is thin so that @xmath43 , then there are no sensors sufficiently deep inside @xmath0 whose neighbors are mainly inside @xmath0 , so the region will not be recognized by the majority vote scheme .",
    "we thus need to make some ( seemingly strong ) assumptions on the shape of @xmath0 such that @xmath44 is guaranteed . in this paper",
    ", we consider @xmath0 as a convex event region with a bounded curvature , i.e. , with sufficiently rounded boundary .",
    "for such @xmath0 , in section  [ sec : convex ] , we prove a significantly improved upper bound on the expected number of misclassified sensors in @xmath33 , which is a main result in this paper .",
    "[ thm : convex ] let @xmath45 .",
    "if the event region @xmath0 is convex and the radius of curvature at each point on the boundary is at least @xmath4 , then the expected number of sensors in @xmath33 that are misclassified by the simple majority rule in the neighborhood of radius @xmath4 is less than @xmath46    finally , in section  [ sec : experiment ] , we perform some simulation for convex and round event regions and check the effect of the various parameters in the majority vote scheme such as @xmath3 , @xmath4 , @xmath2 , and the perimeter of @xmath0 , and present a refinement method to improve the performance particularly for the tricky cases , i.e. , for small @xmath4 and large @xmath3 .",
    "[ sec : analysis ]    in this section we analyze the simple majority rule and prove theorem  [ thm : general_outz ] and theorem  [ thm : general_inz ] . throughout the paper , we will use the following lemma .",
    "[ lem : bn ] for @xmath35 , the probability @xmath47 of at least @xmath48 successes among @xmath49 independent bernoulli trials of success probability @xmath3 is @xmath50    the upper bound can be easily derived by the chernoff inequality proven in  @xcite . for the lower bound , let @xmath51",
    ". then @xmath52 . by simple arithmetic calculation",
    ", we can show that the probability of at least @xmath51 successes among @xmath49 independent bernoulli trials of success probability @xmath3 is at least @xmath53 the last inequality is given in  @xcite . applying @xmath54 to the last term of the above inequality",
    ", we get the lower bound we wanted as follows : @xmath55      recall that @xmath33 is the set of points of @xmath1 within distance @xmath4 to @xmath56 , the boundary of @xmath0 .",
    "the expected number of the misclassified sensors in @xmath36 by the majority vote is @xmath57 times the probability of a sensor @xmath58 in @xmath34 being misclassified by the majority rule in the neighborhood of radius @xmath4 .",
    "suppose that @xmath58 has @xmath10 neighbors .",
    "since @xmath59 , the @xmath10 neighbors of @xmath58 lie all inside @xmath0 or all outside @xmath0 .",
    "the probability of @xmath59 being misclassified is the one that at least half of measurements of the neighbors should be erroneous .",
    "when @xmath10 is odd , at least @xmath60 errors among @xmath10 measurements must happen .",
    "but when @xmath10 is even , the measurement of @xmath58 can be served as a tie breaker , thus at least @xmath61 errors must happen among @xmath62 measurements including a measurement of @xmath58 .",
    "let @xmath63 be the probability that at least @xmath60 successes among @xmath10 trials with success probability @xmath45 . for odd @xmath10",
    ", it holds from binomial distribution that @xmath64 because @xmath65 for @xmath45 .",
    "the probability of @xmath59 being misclassified is simplified as follows : @xmath66    the first probability is @xmath67 by the definition of the poisson process .",
    "the second probability @xmath68 is at most @xmath69 by lemma  [ lem : bn ] .",
    "thus we get the upper bound of the probability of @xmath59 being misclassified as follows : @xmath70 multiplying this with @xmath71 gives the upper bound of the theorem .",
    "for the lower bound in theorem  [ thm : general_outz ] have a similar inequality as in the upper bound as follows : @xmath72 where @xmath73 for @xmath45 .",
    "the second probability is at least @xmath74 by lemma  [ lem : bn ] .",
    "thus we get the following lower bound of the probability of @xmath59 being misclassified , which proves the lower bound of the theorem .",
    "@xmath75      for the upper bound of the theorem , we simply assume that any sensor in @xmath33 always makes the wrong decision .",
    "the expected number of sensors in @xmath33 is @xmath76 , and we have the geometric bound @xmath77 for any general set @xmath0 .",
    "thus the expected number of misclassified sensors in @xmath33 by the majority vote rule is at most @xmath78 .",
    ".,width=302 ]    we now explain that this bound is asymptotically the best we can obtain for the expected number of misclassified sensors in @xmath33 for any @xmath0 with @xmath79 . indeed ,",
    "if @xmath0 is a thin and long rectangle of height @xmath80 and of width @xmath81 as shown in figure  [ fig : thin - lowerbound ] , then all sensors in @xmath0 will be in @xmath33 , i.e. , @xmath82 . the perimeter of @xmath0 is @xmath83 . consider any sensor @xmath58 in @xmath0 at distance at least @xmath4 from the both vertical edges of @xmath0 .",
    "let @xmath23 be a disk of radius @xmath4 around @xmath58 .",
    "since the height of @xmath0 is @xmath80 , @xmath23 consists of three parts as in figure  [ fig : thin - lowerbound ] ; two circle segments of @xmath84 and the middle part , @xmath85 , between the circle segments .",
    "the expected numbers of sensors in @xmath86 and @xmath85 whose initial measurement is `` not in x '' are @xmath87 and @xmath88 , respectively .",
    "thus @xmath58 has at least @xmath89 neighbors in @xmath23 whose initial measurement is `` not in @xmath0 '' .",
    "we can prove that this is at least half of the number of sensors in @xmath23 , i.e. , @xmath90 for any @xmath91 by simple calculation .",
    "this results in making a wrong decision of @xmath58 by the majority vote scheme .",
    "the expected number of such misclassified sensors in @xmath0 is @xmath92 , which is at least @xmath93 .",
    ", satisfying that the radius of curvature is at least @xmath4 everywhere on the boundary.,width=377 ]    we can also find such a worst example even when @xmath0 is not convex but has a round boundary satisfying some curvature constraint : the radius of curvature is at least @xmath4 everywhere on the boundary .",
    "figure  [ fig : lowerbound ] illustrates an event region @xmath0 of the curvature radius @xmath4 , but not convex .",
    "all sensors in roughly @xmath94 thin rectangular strips have a majority of neighbors outside @xmath0 , thus they will make wrong decisions .",
    "assume that @xmath95 is a multiple of @xmath81 , so @xmath96 .",
    "total area of thin strips is at least @xmath97 .",
    "the boundary of @xmath0 consists of circular arcs at its both ends and linear segments of thin strips .",
    "since the length of any circular arc is at most @xmath98 , the total length of circular arcs is at most @xmath99 .",
    "then @xmath100 since @xmath101 .",
    "thus the expected number of misclassified sensors in @xmath33 of this non - convex region @xmath0 with bounded curvature @xmath4 is at least @xmath102 .",
    "we now complete the proof of theorem  [ thm : general_inz ] .",
    "[ sec : convex ]    we now prove our main result , theorem  [ thm : convex ] that if @xmath0 is a convex region with a round boundary of the curvature radius @xmath4 , then the expected number of misclassified sensors in @xmath33 significantly decreases . as a result ,",
    "the convexity and the curvature constraint both are crucial for a better bound .",
    "let @xmath58 be a sensor in @xmath33 whose nearest point to @xmath56 is @xmath103 in distance @xmath104 for some constant @xmath105 .",
    "let @xmath23 be the disc of radius @xmath4 around @xmath58 .",
    "let @xmath106 be the fraction of @xmath23 on the same side of @xmath56 as @xmath58 , i.e. , @xmath107 if @xmath8 , @xmath108 if @xmath109 .",
    "then we can prove the following :    [ lem : good0 ] if @xmath110 and @xmath111 , then the probability of @xmath58 being misclassified is at most @xmath112    assume first that @xmath58 lies in @xmath113",
    ". then @xmath114 .",
    "the sensors are located in @xmath23 according to a poisson distribution , but if we assume there are @xmath10 sensors in @xmath23 , which happens with the probability @xmath115 , then the conditional distribution of these @xmath10 sensors over @xmath23 is uniform .",
    "so each of these @xmath10 sensors independently falls with probability @xmath106 in @xmath116 , and @xmath117 in @xmath86 , and there , with probability @xmath3 , reports incorrectly , and with probability @xmath118 , reports correctly .",
    "thus , we have @xmath10 independent bernoulli experiments , which report being in @xmath0 with probability @xmath119 and being outside @xmath0 with probability @xmath120 .",
    "since @xmath58 is in @xmath0 , the probability of an incorrect classification is the probability of a majority vote for being outside @xmath0 , that is , more than half of @xmath10 bernoulli experiments being successful with success probability @xmath120 ; if @xmath121 , by the chernoff bound ( lemma  [ lem : bn ] ) , this is at most @xmath122 for @xmath110 and @xmath111 , the necessary condition for the chernoff inequality , i.e. , @xmath123 , is satisfied , and thus the probability of @xmath58 being misclassified , without the condition on @xmath10 , is at most @xmath124 set @xmath125 for fixed @xmath126 $ ] , @xmath127 is a monotone increasing function in @xmath128 with @xmath129 and @xmath130 , and satisfies that @xmath131 .",
    "thus we get the probability of @xmath58 in @xmath113 being misclassified is at most @xmath132    for sensors",
    "@xmath58 lying in @xmath133 , letting @xmath134 , we get the same upper bound as ( [ eq : insidex ] ) for the probability of @xmath58 being misclassified by more than half of neighbours reporting being inside @xmath0 .",
    "therefore we get the upper bound of the lemma for the probability of @xmath58 being misclassified , no matter whether @xmath58 is inside or outside @xmath0 .",
    "this lemma provides us a good bound on the expected number of misclassified sensors , but only for those satisfying its necessary condition , @xmath111 . since @xmath0 is convex , all sensors in @xmath135",
    "satisfy the condition , but some sensors in @xmath136 may not satisfy the condition . indeed , for sensors @xmath137 , we can get a simple lower bound on @xmath138 as follows : the sensor @xmath58 is assumed to be on the inner parallel curve at distance @xmath104 from @xmath56 for some @xmath139 .",
    "let @xmath103 be the point on @xmath56 from @xmath58 in distance @xmath104 .",
    "consider another disk @xmath140 of radius @xmath4 with its center in @xmath0 such that it is tangent to @xmath56 at @xmath103 .",
    "since the radius of curvature is at least @xmath4 everywhere on @xmath56 , by blaschke s rolling ball theorem  @xcite , the interior of @xmath140 is completely contained in @xmath0 , thus we have @xmath141 , where @xmath142 =   \\frac{\\pi}{2 } + 2 \\left [ \\frac{\\pi}{4}-2 \\int^{\\frac{1-\\delta}{2}}_0 \\sqrt{1-x^2 } dx \\right].\\ ] ] since @xmath143 is a monotone increasing function with @xmath144 , we can conclude that for sensors in @xmath113 within distance @xmath145 to the boundary of @xmath0 , it is not necessarily true that @xmath146 , i.e. , @xmath111 .",
    "therefore it is unavoidable to split the sensors into  good \" and  bad \" groups and to analyze them in different ways .    .",
    "( a ) @xmath58 is good since @xmath147 .",
    "( b ) @xmath58 is bad since @xmath148.,width=453 ]    for easier analysis , we use the following criteria for the split . consider the disk @xmath23 of radius @xmath4 around @xmath58 and the boundary curve @xmath56 as illustrated in figure  [ fig : bad ] . by blaschke s rolling ball theorem",
    ", the curve @xmath56 enters @xmath23 once at some point @xmath3 , leaves @xmath23 once at some point @xmath149 and it never enters @xmath23 afterwards . let @xmath150 be the diametrically opposite point of @xmath3 in @xmath23 .",
    "then there are two possibilities when @xmath58 is in @xmath33 : @xmath150 lies in the same side of @xmath56 as @xmath58 , or in the opposite side of @xmath56 to @xmath58 .",
    "for the two cases when @xmath58 lies in @xmath113 , see figure  [ fig : bad ] .",
    "we call @xmath151 _ good _ if @xmath150 lies in the side of @xmath56 as @xmath58 , and otherwise _ bad_. by the convexity of @xmath0 , it is clear that all sensors in @xmath135 are good .      for good sensors in @xmath33 , we get the following bound on the probability of being misclassified .",
    "[ lem : good1 ] let @xmath58 be a good sensor in @xmath33 whose distance to the boundary of @xmath0 is @xmath104 .",
    "then the probability of @xmath58 being misclassified is at most @xmath152    as in figure  [ fig : bad](a ) , we first consider the case that @xmath153 .",
    "let @xmath23 be a disk of radius @xmath4 around @xmath58 on the inner parallel curve at distance @xmath104 from @xmath56 , and let @xmath103 be the closest point on @xmath56 from @xmath58 . using the curvature constraint and the fact that @xmath154 , the half of @xmath23 bounded by line @xmath155 is contained in @xmath0 .",
    "in addition , on the other side of @xmath155 , the triangle @xmath156 of height @xmath157 , where @xmath158 is the point on @xmath56 directly above @xmath58 , is also contained in @xmath0 .",
    "thus @xmath159 .",
    "this gives us a lower bound on @xmath160 , where the area of the portion of @xmath23 lying inside @xmath0 is expressed as @xmath161 , that is , @xmath162 .",
    "then @xmath163 similarly , for good sensors @xmath58 lying in @xmath135 , the portion of @xmath23 lying outside @xmath0 satisfies that @xmath164 . plugging the lower bound @xmath165 into @xmath106 of lemma  [ lem : good0 ] , we get the result .",
    "we integrate this probability over all inner and outer parallel curves and get an upper bound on the expected number of misclassified good sensors in @xmath33 : @xmath166 for the upper bound on the integrals , we used that @xmath167 , where @xmath168 is an error function appeared in integrating the gaussian function with @xmath169 for any @xmath170 .",
    "now we derive a bound on the expected number of misclassified bad sensors in @xmath33 .",
    "note that all bad sensors of @xmath33 appear only in @xmath136 , and see figure  [ fig : bad](b ) for illustration . for bad points(sensors ) , we do not know any upper bound but @xmath171 on the probability of being misclassified .",
    "however , we can get an upper bound on the total length of disjoint bad curve segments , which consist of bad points only , on @xmath172 , an inner parallel curve at distance @xmath104 from @xmath56 for some @xmath173 . for this we use a covering argument and the fact that the total direction change of a simple closed convex curve is @xmath174 .",
    "[ lem : length_bad ] the total length of bad curve segments on the inner parallel curve @xmath172 at distance @xmath104 to the boundary of @xmath0 is at most @xmath175    as in the proof for the good sensors , we define @xmath23 , @xmath103 , and @xmath158 for a bad sensor @xmath58 on the inner curve @xmath172 . see figure  [ fig : bad](b ) .",
    "then the disk @xmath176 around @xmath58 of radius @xmath104 touches @xmath56 at @xmath103 and is completely contained in @xmath0 .",
    "let @xmath177 be the angle by which the direction of @xmath56 changes in counterclockwise direction between entering and leaving @xmath23 . using the facts that @xmath178 , @xmath179 , and @xmath180 over @xmath181 $ ] , we have that @xmath182 since the total direction change of @xmath56 traversing a simple curve once around is at most @xmath174 , we can not have more than @xmath183 such curve segments on @xmath172 whose interiors are disjoint , each with a direction change of at least @xmath184 .",
    "we now pick bad points on @xmath172 at distance of at least @xmath4 along @xmath172 as traversing it in counterclockwise direction as follows .",
    "if the points on @xmath172 are all bad , then its length becomes the perimeter of @xmath172 , i.e. , at most @xmath185 .",
    "otherwise , there must be at least one good point on @xmath172 .",
    "we traverse @xmath172 from the good point in counterclockwise direction .",
    "we will meet the first bad point , then we pick this bad point and call it @xmath186 .",
    "we next pick the bad point @xmath187 on @xmath172 at distance of at least @xmath4 from @xmath186 along the curve . continuing this picking process",
    ", we can pick @xmath10 bad points @xmath188 where the distance from @xmath189 to @xmath186 might be less than @xmath4 . as in figure",
    "[ fig : pick](a ) , we denote by @xmath190 a right half of the disk of radius @xmath4 around each picked bad point @xmath191 with respect to the traversing direction .",
    "then it is clear that the union of such right half disks covers all the bad points on @xmath172 because any bad point @xmath58 between @xmath191 and @xmath192 . ]",
    "is contained in @xmath190 .    without loss of generality , we assume that @xmath10 is odd .",
    "let us now consider the intersections of @xmath172 with the right half disks @xmath193 around every even picked bad points @xmath194 .",
    "these intersections @xmath195 for even @xmath196 result in curve segments ( or arc intervals ) of @xmath172 whose the left endpoint is @xmath191 .",
    "we claim that these segments except from the first and last ones are disjoint ; @xmath197 can overlap with @xmath198 . as in figure",
    "[ fig : pick ] , we consider two consecutive intersections , @xmath195 and @xmath199 for even @xmath200 .",
    "it suffices to show that the right endpoint of @xmath201 lies in the left of the left endpoint of @xmath199 on the curve .",
    "the arc length between @xmath191 and @xmath202 is at least @xmath203 by picking rule , and the length of @xmath201 is at most @xmath204 by curvature constraint .",
    "thus the distance between the right endpoint of @xmath201 and the left endpoint of @xmath199 is at least @xmath205 , so the claim is proved .",
    "the number of disjoint bad curve segments on @xmath172 is already proved to be no more than @xmath183 , so the sum of their length ( excluding the length of @xmath197 ) is at most @xmath206 . for the last curve segment @xmath197 , we simply add its length @xmath207 , which gives the length of @xmath208 for @xmath209 .",
    "considering the curve segments generated by every odd picked bad points , the sum of their length is at most @xmath210 .",
    "note here that the first odd segment does not overlap with the last odd one .",
    "thus the total length of bad curve segments on @xmath172 is at most @xmath211 .",
    "furthermore , the total length should be no more than the length of @xmath172 , @xmath185 , which completes the lemma .    integrating this over all inner parallel curves",
    ", we get an upper bound on the expected number of all misclassified bad sensors in @xmath33 as follows :    @xmath212    now we put both ( [ eq : good ] ) and ( [ eq : bad ] ) together to obtain the upper bound on the expected number of misclassified points in @xmath33 , completing the proof of theorem  [ thm : convex ] : @xmath213",
    "we perform some simulations to see the performance of the majority vote scheme and the dependency of several parameters such as the error probability @xmath3 of sensors , the neighboring radius @xmath4 , and the geometric parameters of a convex event region @xmath0 .",
    "we simulate the majority vote scheme each with @xmath214 , and @xmath215 sensors distributed by poisson process in a unit square @xmath1 .",
    "we consider two event regions @xmath216 and @xmath217 as shown in figure  [ fig : experiment ] ; @xmath216 is a square of side length @xmath18 with rounded corners of the curvature radius @xmath19 , and @xmath217 is a longer and thinner rectangle of dimension @xmath218 with the same type of corners .",
    "note here that they have the same area , but @xmath217 has a longer perimeter than @xmath216 ; @xmath219 and @xmath220 .",
    "we test the majority vote scheme for @xmath16 different radii @xmath4 by incrementing @xmath221 from @xmath221 to @xmath19 and for @xmath222 different error probabilities @xmath3 by incrementing @xmath223 from @xmath223 to @xmath224 .",
    "we first check the correction rate of the major vote scheme , which is the ratio of the number of sensors revised correctly after the major vote scheme with the number of the initial errors .",
    "figure  [ fig : sim - ratio ] shows such correction rates for various values of @xmath4 , @xmath3 and @xmath2 , respectively . if @xmath4 is small or @xmath2 is small , then each sensor has too few neighbors to correct its error by the majority vote scheme , and what is worse is that the initial right decision can be changed even when the sensor is far from the boundary of @xmath0 .",
    "however , as @xmath4 grows or @xmath2 increases , much more misclassified sensors are correctly revised by neighborhood comparisons ; more than @xmath225 for @xmath226 or @xmath227 .",
    "the correction rate for @xmath3 becomes the highest around @xmath20 ; almost @xmath228 for @xmath216 and @xmath229 for @xmath217 .",
    "but , if @xmath3 is too small or too large , then the rate goes below @xmath225 , still above @xmath230 .",
    "figure  [ fig : sim - ub - final ] shows the comparison on the difference between the number of final errors in the simulation and the upper bound on the number of the final errors proved in this paper for @xmath216 and @xmath217 .",
    "the upper bound is given as the sum of two upper bounds , each in @xmath34 of theorem  [ thm : general_outz ] and in @xmath33 of theorem  [ thm : convex ] , which is at most @xmath231 the number of final errors in the simulation is clearly much less than the theoretical upper bound , which tells us the upper bound could be improved further .",
    "we next test how much the sensors in @xmath33 are likely to be misclassified out of the total final errors in @xmath1 .",
    "figure  [ fig : sim - beta ] shows that as @xmath4 grows ( or @xmath2 increases ) , the misclassified sensors occur mostly in @xmath33 since the errors in @xmath34 decreases exponentially with the expected number of neighbors @xmath232 by the bound  ( [ eq : ub ] ) , but the errors in @xmath33 increases linearly with @xmath232 .",
    "however , the high probability @xmath3 causes many initial errors everywhere in @xmath1 , which makes the voting effect less powerful for the sensors in @xmath34 , thus the ratio decreases as @xmath3 increases .",
    "we can also see the effect of the perimeter .",
    "since @xmath216 and @xmath217 have the same area , the average number of sensors falling into them is almost equal , but @xmath217 has a @xmath233 longer perimeter than @xmath216 .",
    "a longer perimeter is a bad factor to misclassify more sensors outside the event region . according to theorem  [ thm : convex ]",
    ", we can expect there would be a linear relation between the number of misclassified sensors and the perimeter of @xmath0 .",
    "we can find such relation in figure  [ fig : sim - ratio ] to figure  [ fig : sim - beta ] .",
    "we now count the misclassified sensors @xmath136 and @xmath135 separately .",
    "we expected the misclassified sensors in @xmath136 are more likely to occur than the ones in @xmath113 since the sensors in @xmath234 are all good , i.e. , @xmath235 , where @xmath23 is the disk of radius @xmath4 around a sensor in @xmath135 .",
    "we have checked such situation actually happens as in figure  [ fig : sim - gamma ] .",
    "finally , we conclude from the simulation results that the best radius @xmath4 that produces the least misclassified sensors is @xmath236 for @xmath237 , @xmath238 for @xmath239 , @xmath240 for @xmath241 , and @xmath242 for @xmath243 .",
    "a sensor with a small neighborhood radius @xmath4 , say less than @xmath244 in our simulation , has few neighbors to correct its error by the majority vote scheme , so the correction rate is not satisfactory as we already checked in figure  [ fig : sim - ratio ] . a refinement method to achieve the high correction rate for small",
    "@xmath4 is to apply the majority vote scheme more than once , i.e. , multiple vote rounds .",
    "suppose that an initial error of a sensor @xmath58 is not corrected during the first vote round .",
    "after the first vote , several erroneous neighbors of @xmath58 would be revised correctly , thus @xmath58 is more likely to correct its error at the second vote round .",
    "after @xmath245 rounds , the measurement of the sensors at distance @xmath246 from @xmath58 can affect the decision of @xmath58 .",
    "this , on the other hand , tells that more rounds are not always helpful , particularly for the sensor @xmath58 near @xmath56 in the sense that @xmath58 can receive the information from many sensors on the opposite side of @xmath58 , which can lead @xmath58 to make the wrong change .",
    "thus we need to choose @xmath158 carefully . for a fixed distance from @xmath58 ,",
    "as @xmath4 gets smaller , @xmath158 becomes larger , so @xmath158 should be set in proportional to @xmath247 . for large error probability @xmath3 , we can expect the similar effect as for small @xmath4 , but its impact seems a bit weaker than that of @xmath4 .",
    "we set @xmath248 and @xmath249 . in our simulation",
    ", @xmath158 is at most @xmath250 .    in our simulation , instead of simply repeating a majority vote scheme @xmath158 times , we take an indirect but efficient implementation as follows : with each sensor @xmath58 , we associate a real value @xmath251 .",
    "initially , @xmath252 if the initial measurement of @xmath58 is that @xmath28 and @xmath253 if @xmath254 . at each round",
    ", @xmath251 is updated to be the average value of @xmath255 for the neighbors @xmath103 of @xmath58 .",
    "after the first round , if @xmath256 , then it means @xmath58 has the majority of its neighbors inside @xmath0 , otherwise outside @xmath0 , which is the exactly same judgement as the single - round vote scheme .",
    "the score values are propagated gradually like the pattern in the well - known gau - seidel iterative method , thus after @xmath158 rounds , each sensor @xmath58 receives the score values of the sensors within distance @xmath246 from @xmath58 .",
    "each sensor @xmath58 decides its final measurement by the sign of @xmath251 , that is , decides that @xmath8 if @xmath257 and @xmath254 if @xmath258 .",
    "if @xmath259 , then it follows the measurement of @xmath58 made at the previous round .",
    "figure  [ fig : sim - s - m ] compares the correction rates for @xmath216 and @xmath217 between single - round and multiple - round vote schemes .",
    "the multiple - round scheme performs much better for large @xmath260 ; @xmath261 and @xmath262 improvements each for @xmath241 and @xmath243",
    ". if we focus only on small radius @xmath4 between @xmath263 and @xmath244 , then the correction rates are improved more as in figure  [ fig : sim - s - m ] . as a result ,",
    "the multiple - round vote scheme is a reasonable refinement to improve the correction rate for small @xmath4 and large @xmath3 .",
    "the simulation is done in the desktop computer with intel core i7 - 2600 cpu , 3.40ghz .",
    "regardless of the values of @xmath4 , @xmath3 , and @xmath2 , every major vote scheme runs in @xmath264 seconds , which is the multiple - round case with @xmath250 rounds where @xmath265 , @xmath266 , and @xmath267 , but the average execution time over all @xmath4 , @xmath3 , and @xmath2 is @xmath268 seconds .",
    "in this paper we analyzed the simple majority rule and make explicit and precise the dependency on the error probability @xmath3 of sensors , the radius @xmath4 of the voting neighborhood , and the geometric parameters of event regions .",
    "to our best knowledge , this is the first to give bounds on the expected number of incorrectly classified sensors , with all such parameters in majority vote scheme .",
    "we also provided some empirical evidence indicating the dependency on such parameters .",
    "* there is some background error , @xmath269 which happens even when there is no event at all , i.e. , @xmath270 .",
    "this error depends on the total size of the area of interest @xmath1 , but decreases exponentially fast with the expected number of neighbors of each sensor , i.e. , @xmath29 .",
    "* there is a term that depends on the perimeter of @xmath0 , which means that sensors very near to the boundary of @xmath0 can be unavoidably misclassified .",
    "in fact , @xmath271 sensors can be misclassified in a simplest thin rectangle of height @xmath80 , which gives the lower bound for the term .",
    "* there are terms that depend on the expected number of neighbors of a point , the number of components of @xmath0 , or the logarithm of the perimeter of @xmath0 specially for a convex region with bounded curvature .",
    "the assumption on the boundary curvature might look strong .",
    "we need it for two related things ; for the existence of inner parallel curves of @xmath56 at distance up to @xmath4 , and for the property that any sensor neighborhood extends across @xmath56 only on one side .",
    "the first might be a technical restriction which can somehow be circumvented , but the second is crucial for the voting algorithm : if the set @xmath0 is thin , then there are no sensor positions sufficiently deep inside @xmath0 that the majority of their neighbors will also be inside @xmath0 , so the set will not be recognized by the majority rule .    100 .",
    "the number of fixed points of the majority rule . _ discrete mathematics _ , * 70 * : 295302 , 1988 . .",
    "experimental evaluation of expert fusion strategies . _ pattern recognition letters _ , * 20 * : 13611369 , 1999 .                      .",
    "distributed bayesian algorithms for fault - tolerant event region detection in wireless sensor networks .",
    "_ ieee transactions on computers _ , * 53*(3 ) : 241250 , 2004 . . a theoretical analysis of six classifier fusion strategies . _ ieee transactions on pattern analysis and machine intelligence _ , * 24 * : 281286 , 2002 ."
  ],
  "abstract_text": [
    "<S> in this paper we study the identification of an event region @xmath0 within a larger region @xmath1 , in which the sensors are distributed by a poisson process of density @xmath2 to detect this event region , i.e. , its boundary . </S>",
    "<S> the model of sensor is a 0 - 1 sensor that decides whether it lies in @xmath0 or not , and which might be incorrect with probability @xmath3 . </S>",
    "<S> it also collects information on the 0 - 1 values of the neighbors within some distance @xmath4 and revises its decision by the majority vote of these neighbors . in the most general setting </S>",
    "<S> , we analyze this simple majority vote scheme and derive some upper and lower bounds on the expected number of misclassified sensors . </S>",
    "<S> these bounds depend on several sensing parameters of @xmath3 , @xmath4 , and some geometric parameters of the event region @xmath0 . by making some assumptions on the shape of @xmath0 , </S>",
    "<S> we prove a significantly improved upper bound on the expected number of misclassified sensors ; especially for convex regions with sufficiently round boundary , and we find that the majority vote scheme performs well in the simulation rather than its theoretical upper bound . </S>"
  ]
}