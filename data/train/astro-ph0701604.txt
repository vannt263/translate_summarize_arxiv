{
  "article_text": [
    "high - dimensional data present difficulties when analyzing and understanding their statistical properties .",
    "the efficiency of typical statistical and computational methods usually degrades very fast when the dimensionality of the problem increases , thus making the analysis of the observed data a cumbersome or , sometimes , unfeasible task .",
    "this fact is often referred to as the _ curse of dimensionality_. the advent of computers has permitted to face the analysis of increasingly complex data .",
    "these data usually exhibit an intricate behavior and , in order to understand the underlying physics that produces such effects , we have been forced to develop very complicated models .",
    "ideally , these models have to be based on physical grounds but there seems to be no way of knowing in advance how complicated this model has to be to correctly reproduce the observed behavior .    in spite of their inherent complexity ,",
    "the analysis of large datasets such as those produced by modern instrumentation , indicates that not all measured datapoints are equally relevant for the understanding of the underlying phenomena . in other words",
    ", it is clear that the reason why many simplified physical models are successful in reproducing a large amount of observations is because the data itself is not truly high - dimensional .",
    "based on this premise , efforts are being made to develop methods that are capable of reducing the dimensionality of the observed datasets while still preserving their fundamental properties .",
    "mathematically , the idea is that , while the original data may have a very large dimensionality , they are in fact confined to a small sub - region of that high - dimensional space . in this case",
    ", we can consider that the data `` lives '' in a subspace of low dimension ( the so - called intrinsic dimension ) that is embedded in the high - dimensional space .",
    "this lower dimension subspace is not usually simple to describe because it often lies in a manifold whose relation with the original high - dimensional space has to be described by a very complex non - linear ( and usually unknown ) function . in spite of the complexity ,",
    "when facing a high - dimensionality dataset , it is of great interest to reduce the dimension of the original data prior to any modeling effort . in this manner",
    "we can uncover more easily the physics underlying the observations and even detect previously unknown properties that can be of interest .    among the most popular methods for dimensionality reduction we find principal component analysis ( pca ) or karhunen - loeve expansion .",
    "due to its computational simplicity , it is one of the most widely employed methods ( e.g. , * ? ? ?",
    "* ; * ? ? ?",
    "* ; * ? ? ?",
    "* ; * ? ? ?",
    "* ; * ? ? ?",
    "pca seeks orthogonal directions in the original high - dimensional space along which the data correlation is the largest . from a computational point of view",
    ", the method finds the eigenvalues and eigenvectors of the covariance matrix obtained from a given dataset .",
    "then , the directions on the space where the correlation is large ( large eigenvalues ) may be approximately described with only one parameter ( a factor multiplying the associated eigenvector ) and have sometimes a physical meaning .",
    "an example of this can been seen in @xcite , who demonstrated how the eigenvectors associated with the largest eigenvalues of the correlation matrix obtained from spectropolarimetric observations of a sunspot are related to fundamental physical parameters .",
    "they showed that the first eigenvector is associated with the average spectrum , the second eigenvector gives information about the velocity and the third eigenvector gives information about the magnetic splitting .",
    "one of the weakest points of pca is its linear character , because it relies only in the information provided by second order statistics .",
    "therefore , it can not efficiently describe a dataset whose embedding in the original high - dimensional space is a nonlinear manifold .",
    "several methods have been developed during the last years to overcome this difficulty . among them , we can find locally linear embedding ( lle , * ? ? ?",
    "* ) , isomap @xcite and self - organizing maps ( som , * ? ? ?",
    "these methods are very promising and have been shown to outperform pca when reducing the dimension of datasets that present clear nonlinearities .",
    "recently , a promising non - linear extension of pca ( kernel pca ) has also been developed @xcite .",
    "it is based on the extension of pca to non - linear mappings by the application of mercer kernels and it effectively takes into account high - order statistics from the datasets",
    ". another nonlinear version of pca can be carried out with the aid of auto - associative neural networks ( aanns ) ( e.g. , * ? ? ? * for applications in the inversion of stokes profiles ) .",
    "all the previous methods are computationally expensive .",
    "aanns require the training of a neural network with a bottleneck hidden layer that contains @xmath1 neurons , with @xmath1 the expected intrinsic dimension of the dataset .",
    "this training requires a very complex non - linear optimization that can be carried out with standard methods , such as the backpropagation algorithm @xcite .",
    "concerning kpca , it requires the numerical diagonalization of a very large correlation matrix of size @xmath2 @xcite . for large datasets ,",
    "the diagonalization poses a heavy burden in terms of computational time and memory requirements because the correlation matrix is not sparse .",
    "the above - mentioned tools have been introduced recently and probably require further study in order to understand all their statistical and computational properties .",
    "unfortunately , they all suffer from a very important limitation : none of these methods is capable of giving a reliable estimation of the intrinsic dimension @xmath1 of the datasets .",
    "when this number is known or obtained by a different method , the previous methods are able to yield the projection of the original dataset in a nonlinear subspace of dimension @xmath1 .",
    "if @xmath1 is close to the correct intrinsic dimension of the original dataset , they usually capture the structure of the nonlinear subspace and give good results .",
    "although it seems of reduced importance , a good estimation of @xmath1 gives the key to understanding the physics underlying in the observations . in the framework of spectropolarimetry",
    ", it would be desirable to find possible direct relations between the nonlinear dimensions captured by these methods and the physical parameters employed for the forward modeling ( magnetic field strength , filling factor , macroscopic velocities , etc . ) .",
    "if @xmath1 is too small , important features of the data are projected onto the same dimension and part of the information available is lost . if , on the contrary , @xmath1 is too large , then the methods can introduce noise in the nonlinear manifold . also important",
    "is the fact that a good estimation of @xmath1 is very important to reduce the computational work and avoid a trial - and - error procedure .    except for pca and aanns ,",
    "no other dimension reduction methods have been applied to the field of spectropolarimetry .",
    "furthermore , the authors are not aware that any nonlinear dimension reduction method has been applied to spectropolarimetric data thus far . in any case",
    ", it is always advantageous to have reliable information on the intrinsic dimensionality of the observed datasets . although the spatial resolution of solar spectro - polarimetric observations has improved during the last decades , the resolution elements are typically much larger than the organization scales in the solar atmosphere .",
    "the ensuing mixture of signals inside the resolution element makes it necessary to use complicated models to explain the observed signals .",
    "however , it is fundamental to have in mind that too complicated models ( with a large amount of free parameters ) may not be constrained by the observations",
    ". this paper presents a step forward in the systematic investigation of observational datasets with the aim of extracting as much information as possible from the observations .",
    "although we focus on spectroscopic and/or spectropolarimetric datasets , the philosophy of the approach is applicable to other kinds of data as well .",
    "nowadays , solar spectroscopic and spectropolarimetric datasets are becoming very large and some effort is needed to correctly exploit all the information they carry about the physical processes taking place in the plasma .",
    "we review a powerful method presented recently to estimate the intrinsic dimension of a dataset and we apply it to different observations , analyzing in detail the consequences .",
    "an example of the datasets we are interested here is shown in fig .",
    "[ fig : spectropol_data ] .",
    "the usual intensity spectrum is shown in the upper panel for two different spectral ranges , while the wavelength variation of the circular polarization is shown in the lower panel .",
    "the intrinsic dimension of a dataset is informally defined as the number of parameters that is needed to describe it . in other words ,",
    "given a dataset consisting of @xmath3 different observations , each one made of an @xmath4-dimensional vector , we seek the dimension @xmath5 of the nonlinear manifold that captures the behavior of the @xmath3 vectors .",
    "as already stated , the dimension of this nonlinear manifold is smaller than that of the original space .",
    "this is a consequence of the large number of correlations that are present among the data .",
    "consequently , we can consider that the number of parameters @xmath5 that we need to describe our observations fulfills @xmath6 , always keeping in mind that these parameters have to be able to describe the whole nonlinear manifold .",
    "dimension estimation methods can be classified in two groups .",
    "the first group contains all the methods that rely on the diagonalization of a given correlation matrix ( either linear , such as pca , or nonlinear , such as kernel pca ) .",
    "these methods estimate the dimension by calculating the number of eigenvalues greater than a given threshold .",
    "as discussed above , these methods depend largely on the ability to capture the nonlinearity of the manifold .",
    "moreover , the estimated dimension critically depends on the threshold chosen , a quantity that is often difficult to define and has some degree of arbitrariness .",
    "however , model complexity information may be incorporated into the dimension estimate problem to generate a less arbitrary threshold @xcite .",
    "the second group contains methods based on geometry , especially important in determining the fractal dimension of dynamical systems .",
    "the analysis of dynamical systems reveals that a large fraction of them exhibit trajectories in the phase space that have not an integer dimension .",
    "after @xcite , these objects have been named _",
    "fractals_. powerful method have been developed to estimate fractal dimensions .",
    "many of them are based on the box - counting dimension ( e.g. , * ? ? ?",
    "* ; * ? ? ?",
    "this method estimates the dimension of a given dataset by calculating the minimum number of `` boxes '' of side @xmath7 that are needed to cover the space occupied by the dataset .",
    "it is expected that the number of boxes @xmath8 increases when @xmath7 decreases , so that the box - counting dimension of the dataset is given by the following scaling relation : @xmath9 where @xmath10 is a constant . from this , the dimension is obtained by taking logarithms : @xmath11 for the case of simple low dimensionality datasets , it is easy to verify that the box - counting dimension gives the correct answer .",
    "for instance , if our data are distributed on a straight line of length @xmath12 in a two - dimensional space , it is easy to demonstrate that @xmath13 , so that @xmath14 .",
    "however , this estimation based on box - counting suffers from computational problems for complex dataset and the computational work grows exponentially with the dimension of the original data . another less computationally intensive dimension estimation method ( and probably the most popular thus far )",
    "was introduced by @xcite and employs the correlation dimension .",
    "this correlation dimension is based on the observation that in a @xmath3-dimensional dataset , the number of pairs of points that are closer than a distance @xmath7 is proportional to @xmath15 , where @xmath5 is the correlation dimension .",
    "refinements to this method have been introduced recently to overcome some of its limitations @xcite .",
    "a recent approach to the estimation of dimension has been suggested by @xcite .",
    "it has been obtained by applying the principle of maximum likelihood to the nearest neighbor distances , resulting in a method for dimension estimation that ourperforms the previous ones .",
    "let @xmath16 represent one of the @xmath3 @xmath4-dimensional vectors that constitute the observed dataset .",
    "the maximum likelihood dimension estimation assumes that the data points surrounding @xmath16 can be correctly described with a uniform probability distribution function . as a consequence ,",
    "the nearest neighbor distances follow a poisson process .",
    "this also leads to an easy calculation of the statistical properties of the estimator .",
    "we assume that the observed dataset represents a nonlinear embedding of a lower dimensional space of dimension @xmath17 .",
    "@xcite demonstrated that the maximum likelihood estimator @xmath18 of the intrinsic dimension ( mleid ) can be written as : @xmath19 where @xmath20 represents the euclidean distance between point @xmath16 and its @xmath10-th nearest neighbor .",
    "note that the previous equation is only valid for @xmath21 .",
    "the outcome of the previous equation depends critically on the number of neighbors @xmath10 that are taken into account .",
    "the reason for this is that @xmath10 sets the scale at which we are analyzing the dataset , and it is possible that the data have a different dimension at different scales .",
    "for instance , this is the case for a set of points in a two - dimensional space distributed according to a gaussian density . at very small scale ( small value of @xmath10 )",
    ", we see individual points and the dimension is close to 0 . at larger scales ,",
    "the dimension reaches the value of 2 ( e.g. , * ? ? ?",
    "like other methods , the quality of the estimated dimension usually degrades when @xmath10 increases as a consequence of the finite number of observations in the dataset @xcite .",
    "the previous equation is interesting because it allows us to give local estimations of the intrinsic dimension , in cases where one expects it to change from point to point .",
    "although more work needs to be done , in principle it permits to locate points in the dataset that present anomalies with respect to the average behavior . in any case",
    ", it is important to take into account that large fluctuations can be expected in the estimation of the local dimension and the information provided by eq .",
    "( [ eq : estimation ] ) has to be analyzed with care .",
    "however , if we assume that the observed dataset belongs to the same manifold , it is more convenient to use an estimation that takes into account all the points in the dataset . @xcite",
    "propose to use the following estimation : @xmath22 which is simply an average over the complete dataset . on the contrary",
    ", it has been suggested elsewhere that , due to the mathematical structure of eq .",
    "( [ eq : estimation ] ) , it makes more sense and is more stable to carry out the average of the inverse of the estimators : @xmath23 so that the estimation of the dimension is given by @xmath24 .",
    "we have verified that both estimates give almost the same value for the dimension , although the latter has a better behavior for small values of @xmath10 .",
    "the computational cost of this method @xcite is mainly dominated by the calculation of the @xmath10 nearest neighbors for every point @xmath16 .",
    "the computational cost of evaluating eqs .",
    "( [ eq : average1 ] ) or ( [ eq : average2 ] ) turns out to be almost negligible .",
    "since we are not dealing with too large datasets , our calculations rely on the calculation of the distances among all the points , so that the computational work is essentially proportional to @xmath25 .",
    "however , alternative ways of calculating ( exact or approximate ) nearest neighbors have been developed , the majority of them being based on the construction of efficient tree - like structures that highly reduce the computational work .",
    "in order to show the reliability of the method introduced by @xcite , it is of interest to test it with datasets of known low dimensionality .",
    "although these tests present nothing new with respect to what is already known ( e.g. , * ? ? ?",
    "* and references therein ) , we consider them necessary to indicate the potential of these methods . to this aim , we selected a particular stokes  @xmath26 profile observed with the tenerife infrared polarimeter @xcite of an internetwork region of the quiet sun @xcite . with this profile",
    "we generate a dataset of 2000 elements by performing a random horizontal ( i.e. , in the wavelength direction ) shift .",
    "the values of the shift obey a gaussian distribution .",
    "the estimated dimension is shown in the left panel of fig  [ fig : known_cases ] . due to the possible variation of the dimension with the scale at which the data are analyzed , we plot the estimated dimension for each value of @xmath10 . when @xmath10 is small , we are referring to small scales while the scale increases when @xmath10 increases .",
    "because the dataset is probably not dense enough to correctly sample the whole nonlinear manifold , there may be a systematic deviation from the correct dimension for large values of @xmath10 .",
    "the solid line presents the estimation of the intrinsic dimension obtained from eq .",
    "( [ eq : average1 ] ) while the dashed line presents the estimation given by eq .",
    "( [ eq : average2 ] ) .",
    "note that they both yield similar values for the dimension , which is actually the correct one ( since we have allowed only one degree of freedom ) .",
    "the method has captured the fact that , although these profiles are discretized in @xmath27 wavelength points , only one parameter suffices to describe the entire dataset .    a further complication is introduced in the artificial dataset by carrying out an additional vertical shift to the stokes @xmath26 profile .",
    "the shift follows again a gaussian distribution that is no correlated with the horizontal shift .",
    "the estimated dimension is shown in the right panel of fig  [ fig : known_cases ] .",
    "the method correctly gives a dimension of 2 .",
    "interestingly , when the vertical and horizontal shifts are forced to be correlated ( for instance , we make them equal ) the estimated dimension is again 1 , just as one would expect .",
    "noise turns out to be a problem for estimating dimensions .",
    "if a dataset is confined inside a manifold of a high - dimensional space , the inclusion of noise tends to spread the points out of this manifold and starts to fill up a larger volume of the original high - dimensional space .",
    "consequently , we expect that the addition of noise will tend to increase the estimated dimension asymptotically approaching @xmath4 , the dimension of the original space .",
    "we have generated various sets of profiles with different sizes .",
    "each profile consists of a vector of dimension @xmath4 made of completely uncorrelated noise following a gaussian distribution .",
    "the intrinsic dimension of a dataset composed of @xmath4-dimensional elements of pure noise is equal to @xmath4 and we expect the estimators given by eqs .",
    "( [ eq : average1 ] ) and ( [ eq : average2 ] ) to converge to this value for sufficiently large values of the number of observables @xmath3 .",
    "the estimated dimensions for each value of @xmath4 are shown in fig  [ fig : noise ] for datasets of different sizes , from @xmath28 to @xmath29 . in order to minimize figure cluttering ,",
    "the curves correspond only to the estimation given by eq .",
    "( [ eq : average2 ] ) .",
    "the same overall pattern is found for eq .",
    "( [ eq : average1 ] ) , with a behavior similar to that found in fig  [ fig : known_cases ] .",
    "when @xmath4 is small ( for instance the case with @xmath30 at the top left panel ) , the estimated dimension is very good for small values of @xmath10 .",
    "it degrades as @xmath10 increases because the assumption of uniform distribution of the datapoints breaks for this 10-dimensional space with such a small number of points .",
    "consequently , the assumptions under which the formalism of @xcite has been developed are not fulfilled and it can not be applied . however , it is surprising that it is possible to have a rough estimate with a dataset of only @xmath28 elements . when the number of elements of the dataset increases , the curves asymptotically tend to @xmath4 . for increasing values of @xmath4 ,",
    "the dimension estimate is biased towards smaller values , although it is clear that it still yields a reasonable approximation to the correct value even for very small datasets .",
    "figure  [ fig : noise ] shows in detail how increasing the number of elements in the dataset leads to an improved estimation of the intrinsic dimension . in the limiting case of a space with extremely large dimension ( @xmath31 ) , the method underestimates the dimension by a factor of @xmath323 .",
    "one of the fastest techniques for stokes profiles inversion is based on a look - up algorithm with pca coefficients @xcite .",
    "once a model atmosphere ( with a given number of parameters ) is selected , a database of models and emerging profiles is generated .",
    "the database has to be able to correctly sample the space spanned by all the parameters . due to computational limitations ,",
    "the pca inversion technique has only been applied to the simple milne - eddington atmosphere thus far .",
    "the eigenvectors of the pca decomposition are then saved , along with the projection of each element of the database on these eigenvectors , and the milne - eddington parameters associated with each one . in the inversion process , an observed set of stokes profiles is projected on the eigenvectors and the corresponding projections are compared to those saved in the database . here",
    "we have used the pca database as our observed dataset .",
    "we are interested in estimating the dimension of the manifold in which these observation `` live '' . in principle , each profile contains 180 wavelength points and the phase space would have dimension 180 .",
    "however , correlations between many of these wavelength points ( for instance , all the continuum points that always present the same value ) drastically reduce the dimension of the manifold .",
    "the database that we use consists of @xmath326200 solar stokes profiles of the 6301 - 6302    region , where two lines and two telluric lines are visible .",
    "fig  [ fig : database_pca ] shows the estimated dimension for the stokes  @xmath26 ( upper panel ) and the stokes  @xmath33 profiles ( lower panel ) .",
    "the database is reconstructed from the pca eigenvectors and the projections of each element of the database on these eigenvectors . in order to see the information carried out by the eigenvectors , we show in fig  [ fig : database_pca ] the estimated dimension using an increasing number of eigenvectors @xmath34 in the reconstruction .",
    "the trend obtained is very instructive , showing that the estimated dimension increases with @xmath34 until a saturation is reached .",
    "the case @xmath35 demonstrates that the first two eigenvectors contain a large amount of information and they may be seen , as shown by @xcite , as directly associated with physical parameters .",
    "the situation remains unchanged when reconstructing with @xmath36 eigenvectors , while a saturation is reached when reconstructing with @xmath37 .",
    "this means that , although the number of milne - eddington parameters defining each element of the dataset is 9 , only 6 are actually needed to describe the entire dataset .",
    "this is an alternative way of showing the strong degeneracy present in the 6301 - 6302     lines @xcite .",
    "although pca can not capture the possible nonlinearity of the 6-dimensional manifold , it can be shown that the first 6 eigenvectors are sufficient to describe all the elements of the database with a very small error .",
    "we have shown that the method developed by @xcite correctly captures the dimension of pure noise data .",
    "it is even more important to see how the method behaves when data is corrupted with noise .",
    "it is expected that , since the noise reduces the correlation between some of the components of the @xmath4-dimensional vectors that represent the dataset , the estimated dimension will grow when the signal - to - noise ratio decreases .",
    "a fundamental problem arises because it is very difficult to recognize truly high - dimensional data from low signal - to - noise data .",
    "this test has been carried out with the dataset reconstructed using all the information available ( we used the first 10 eigenprofiles ) .",
    "we have calculated the estimated dimension for four different noise levels , given in terms of the standard deviation @xmath38 of the gaussian noise in units of the continuum intensity . since the typical stokes  @xmath33 signals are around 1 - 2 orders of magnitude smaller than stokes  @xmath26 , a noise of the same @xmath38 implies a much smaller signal - to - noise ratio for stokes  @xmath33 than for stokes  @xmath26 .",
    "consequently , we expect the dimension increase to start at smaller values of @xmath38 for stokes  @xmath33 than for stokes  @xmath26 .",
    "figure  [ fig : noise_effect ] presents the results for three different values of the noise .",
    "the value of @xmath39 is small enough so that no appreciable difference is found in either stokes  @xmath26 or  @xmath33 in the estimated dimension with respect to the case with no noise .",
    "when the noise increases to @xmath40 , the stokes  @xmath26 profiles still maintain the original dimension while the estimated dimension for the stokes  @xmath33 dataset increases rapidly .",
    "it is interesting to note that the estimated dimension increases faster for small values of @xmath10 .",
    "this is because the noise is small enough to produce perturbations ( cancellation of correlation between the @xmath4 components of each stokes profile ) at very small scales , while the large scale dimension still remains unchanged .",
    "when the noise is increased further , a drastic increase of the dimension is observed in stokes  @xmath33 and a smaller one for stokes  @xmath26 .",
    "note that for even smaller signal - to - noise ratios , the estimated dimensions for large values of @xmath10 would also increase until reaching ( in the limiting case of an infinitely large dataset ) a flat dimension estimate , constant for all scales , and equal to @xmath4 .",
    "the typical noise in spectro - polarimetric observations is usually well below 10@xmath41 , so that it is apparent from fig  [ fig : noise_effect ] that noise is not expected to change appreciably the dimensionality of noiseless data .",
    "a consequence of the previous analysis is a possible technique to recognize when data is affected in an important manner by noise .",
    "our datasets usually present a large value of @xmath4 so that , in the case of very large noise , the dimension has to grow until reaching a very large value . a clear effect of the noise , as stated in section [ sec : pure_noise ] ,",
    "is that the estimated dimension rapidly increases at small values of @xmath10 while being held constant for large values of @xmath10 .",
    "thus , if a calculation shows a estimated dimension that exhibits large values at small @xmath10 and a steep logarithmic fall for large @xmath10 , noise is likely rather important .",
    "a caveat is mandatory .",
    "this test relies on the behavior of the mleid for large values of @xmath10 . as already pointed out by @xcite and",
    "also shown here , a degradation of the dimension estimation occurs for large values of @xmath10 and the maximum likelihood estimation does not hold .",
    "for this reason , one has to be cautious with low signal - to - noise ratio observations .",
    "recently , @xcite have addressed the problem of dimension estimation of high - noise observations when using the mleid .",
    "their approach to the problem is based on a smoothing of the original dataset , so that the performance of the method is greatly enhanced .",
    "they find that the estimated dimension for high - noise spectroscopic observations of chemical mixtures turns out to be extremely large .",
    "however , when a certain amount of smoothing is introduced , the mleid turns out to be a very accurate estimation of the dimension .",
    "thanks to the low noise in our observations , our estimations of the intrinsic dimension are surely not dominated by noise and we consider that smoothing is not necessary .",
    "we have shown how the mleid developed by @xcite works for synthetic data . in this section",
    "we focus on real spectropolarimetric observations .",
    "our aim is to learn about the intrinsic information content of the data .",
    "this may help understand how much complexity can be introduced in the models used to interpret the observational data .",
    "a proposed physical model usually consists of a set of free parameters that we have to constrain with the observations .",
    "it is crucial to have as much information as possible in the observed dataset so that one can constrain the model parameters .",
    "obviously , it is undesirable to use too complex models to infer physical information from a dataset if the observables contain only a small amount of information .",
    "the parameters used in the physical models are typically non - orthogonal and they usually present degeneracies because the same observable can be obtained with different sets ( finite or infinite ) of model parameters .",
    "although it is not straightforward to estimate from the intrinsic dimension how many parameters one can introduce in the modeling , it obviously should not be much larger than the estimated intrinsic dimension .",
    "if this number is made much larger , many of these parameters may not be constrained by the observations , thus leading to unphysical results or ill - conditioned inversions .",
    "an important application of the estimated dimension tools we have presented here is to make relative comparisons of the intrinsic information present in two different observations .",
    "there is an ongoing debate about the different results obtained for unresolved magnetic fields in the quiet sun from the inversion of two pairs of lines at two different spectral regions , one at 6302    and the other one at 1.56  @xmath0 m .",
    "recently , @xcite has demonstrated that the information available in the pair of lines at 6302    is not sufficient to constrain simultaneously the intrinsic magnetic field strength and the thermodynamical properties of the plasma .",
    "they showed that it is possible to obtain exactly the same observables from completely different combinations of model parameters . here , we consider this problem by analyzing in detail the amount of information available in the two different spectral regions . to this aim , we compare the intrinsic dimension of the two pairs of lines .    the observations employed here have been explained in detail elsewhere @xcite and an example has been already shown in fig .",
    "[ fig : spectropol_data ] .",
    "they were targeted to the detailed investigation of the magnetic properties of internetwork regions in the quiet sun .",
    "these high spatial resolution observation were taken simultaneously at two different spectral windows , one in the visible around 6302    and the other one in the near - ir around 1.56  @xmath0 m .",
    "the visible observations were acquired with the polarimetric littrow spectrograph ( polis ; * ? ? ?",
    "* ) while the near - ir data were obtained with the tenerife infrared polarimeter ( tip ; * ?",
    "both instruments were mounted at the german vacuum tower telescope ( vtt ) , located at the observatorio del teide of the instituto de astrofsica de canarias .",
    "the instruments were used in a configuration such that simultaneous and co - spatial observations of the same field - of - view were possible .",
    "the noise level for both sets of data is of the order of 5@xmath4210@xmath43 in units of the continuum intensity .",
    "the stokes profiles at each spatial location were considered as vectors in a space of dimension @xmath44 . in principle , one expects that , unless noise dominates the signal , the intrinsic dimension has to be much smaller than @xmath4 .",
    "this follows from the fact that simple physical models are successful in reproducing many of the properties of the observed stokes profiles .",
    "in fact , this is the case as shown in fig  [ fig : tip_polis ] .",
    "the figure shows the estimated dimension of the observed dataset , the upper panel displaying the results for the tip observations and the lower panel presenting the polis results .",
    "the intrinsic dimension has been estimated for stokes  @xmath26 and  @xmath33 separately using a database of 5000 observed profiles .",
    "the results obtained with eq .",
    "( [ eq : average1 ] ) are in solid line and those of eq .",
    "( [ eq : average2 ] ) are in dashed line .",
    "it is clear from the figure that the intrinsic dimension of stokes  @xmath26 is always smaller than for stokes  @xmath33 , implying that the amount of information encoded in the stokes  @xmath26 profiles is smaller than that in the circular polarization profiles .",
    "the magnetic field in these observations is unresolved and the filling factor of the magnetic regions inside the resolution element is of the order of 2% .",
    "therefore , the stokes  @xmath26 profile is representative of the 98% of the resolution element that is non - magnetic and carries virtually no information about the magnetic field .",
    "one expects that it may contain information about the doppler velocity shift , temperature and density stratifications .    focusing on stokes  @xmath26",
    ", we can see that the estimated dimension is very stable with respect to the scale at which the data are observed . according to the previous discussions ,",
    "there is no indication of an artificial increase of the dimension due to noise , as expected for these low - noise observations .",
    "the presence of noise tends to raise the dimension for small values of @xmath10 , also increasing the slope of the curve for larger values of @xmath10 .",
    "it is interesting to point out that the curve obtained for the dataset in the visible spectral range appears to be more stable with @xmath10 than that for the near - ir lines .",
    "this indicates that the near - ir data present a richer structure , also yielding a structure that changes with the scale at which one analyzes it .",
    "it is not obvious to build up an intuitive idea of what this variation means .",
    "a possible interpretation might be that the set of similar stokes  @xmath26 profiles present a small variability ( dimension @xmath323 ) , thus it is possible to describe them with a very reduced set of parameters .",
    "it is plausible to consider that similar stokes  @xmath26 profiles are also observed in nearby spatial locations or locations exhibiting similar brightness ( bright granules versus dark lanes ) .",
    "this result might appear obvious because data seen at small scale typically appear similar unless strong pixel - to - pixel variations are present in the observations .",
    "when the scale is increased , the variability increases as well ( dimension @xmath326 ) , meaning that the set of parameters used for describing them would need to be augmented . in these intermediate values of @xmath10",
    ", we are focusing on the differences between stokes @xmath26 profiles coming from different regions ( granules and lanes ) .",
    "therefore , the lack of variation of the visible data has important consequences , in the sense that their stokes  @xmath26 profiles tend to be less sensitive to the physical properties of the atmosphere .",
    "when the data are observed at large scale , the behavior of both spectral domains tends to be similar .",
    "the decay for @xmath45 is likely produced by the breakage of the fundamental assumption that the points follow a uniform distribution in the neighborhood of every point .",
    "the conclusion from the results obtained for stokes  @xmath26 is that there seems to be an indication that the near - ir data are capable of detecting more variability in the observations than the visible data .",
    "turning our attention to stokes  @xmath33 , essentially the same behavior is observed with almost invariable estimated dimensions for the visible data and strong variations for the near - ir data .",
    "the estimated dimension is @xmath3210 for the visible data and only for @xmath45 we detect a drop - off . from the results shown in fig  [ fig : tip_polis ]",
    "it is clear that the near - ir data capture more physical information about the atmosphere where they are formed .",
    "this is another way of looking at the issues described by @xcite . among other problems , due to the small splitting present in the visible lines ,",
    "it is possible to mask variations in the magnetic field as variations in the thermodynamical parameters .",
    "consequently , these parameters alone are not constrained by the observations and only some ( possibly nonlinear ) combination of them can be constrained .",
    "the splitting in the near - ir lines is much larger ( the splitting is proportional to the wavelength and the effective land factor ) and these problems are less prominent . on the other hand ,",
    "the visible lines produce much stronger signals and are less sensitive to noise , especially for weak ( @xmath46500  g ) fields .",
    "we have already pointed out that the information encoded in the pair of lines at 6302    is not sufficient to constrain simultaneously the thermodynamical and magnetic properties of the plasma in small unresolved magnetic structures in the quiet sun .",
    "it has been suggested that the solution to this problem relies on the simultaneous observation of many spectral lines ( e.g. , * ? ? ?",
    "* ; * ? ? ?",
    "each line contributes by adding somewhat different ( hopefully complementary ) information and constraints , so that the thermodynamical and magnetic properties of the plasma can be inferred with more confidence .",
    "this increase in the information content must be accompanied by an increase in the intrinsic dimension of the space spanned by the observations .",
    "it is likely that a large fraction of the information carried out by all the spectral lines is common and only a small part can be better inferred from a set of lines .",
    "consequently , it is expected that the inclusion of each additional spectral line would increase slightly the information available , unless the new line turns out to be sensitive to a physical parameter to which the original set was nearly insensitive . in order to investigate this in detail ,",
    "we show in fig  [ fig : increasing ] the intrinsic dimension obtained using eq .",
    "( [ eq : average2 ] ) for three synthetic datasets .",
    "these datasets contain the pair of lines at 1.56  @xmath0 m , the pair of lines at 6302    and the line at 8740 .",
    "the full dataset has been obtained using local thermodynamical equilibrium ( lte ) synthetic profiles .",
    "the hsra model atmosphere @xcite was chosen as a reference and random values of the following nine parameters were added to it , producing 10000 different random profiles : macro- and micro - turbulent velocities , filling factor , temperature offset ( shifting the whole hsra temperature height profile ) , temperature gradient ( changing the slope of the reference temperature height profile ) , magnetic field offset , magnetic field gradient , velocity field offset and velocity gradient .",
    "a total of 9 parameters have been used to construct the database .",
    "if the lines contain reliable information about the 9 parameters , one would expect to infer an intrinsic dimension close to 9 .",
    "however , this is not the case , as can be seen in fig  [ fig : increasing ] . the maximum value of the dimension we obtain is only 6 and",
    "this is the maximum number of orthogonal parameters we can introduce in our modeling .",
    "there are two possible reasons for this .",
    "first , the parameters we have varied for generating the database might be degenerate , in the sense that ( possibly nonlinear ) combinations of two or more parameters yield the same ( or very similar ) emergent profiles .",
    "second , it is possible that some information be lost in the line formation process due to radiative transfer effects ( e.g. , line - of - sight blurring ) .",
    "both mechanisms tend to reduce the information available in the observations .",
    "a very important conclusion of this synthetic experiment is that the amount of information that we can extract from a set of observables increases with the number of spectral lines included in the set increases .",
    "this might sound obvious , but our approach of calculating the intrinsic dimensionality of the observed dataset demonstrates this point rigorously for the first time . the increase in the information content is shown in fig  [ fig : increasing ] , where we have plotted the intrinsic dimension obtained from the considered lines .",
    "we have also overplotted the result that we obtain when the intrinsic dimension is estimated considering all the lines simultaneously .",
    "fig  [ fig : increasing ] demonstrates that the available information is a monotonically increasing function of the number of lines .",
    "it is important to note , however , that the results presented in this section are not in accordance with those shown in the previous section . in",
    "the synthetic experiment carried out here , the 630  nm lines capture slightly more information than the 1.5  @xmath0 m .",
    "we assign this apparently puzzling behavior to the fact that this synthetic test is not realistic in the sense that either the variations in the physical properties that we have included are not representative of what is happening in the solar atmosphere , either that the solar case contains correlations among physical parameters absent from the database , or both .",
    "we have applied a computationally efficient method developed by @xcite for estimating the intrinsic dimension of a dataset .",
    "the method relies only on the calculation of the euclidean distances between the observables ( taken as vectors in a high - dimensional space ) .",
    "the properties of the method have been analyzed in detail with artificial datasets .",
    "we have verified that it is able to correctly estimate the intrinsic dimension in artificially generated data .",
    "if the simulated observations contain noise , the method correctly estimates an increase in the intrinsic dimension that tends towards the dimension of the high - dimensional space . in very high - dimensional spaces with a small number of observations , the assumptions under which the method relies are not fulfilled , so that the method can not be applied .",
    "the presence of noise in the observations produces an overestimation of the dimension at small values of @xmath10 and it may be used to judge whether the information has been significantly degraded by the presence of noise .",
    "since both an intrinsically high - dimensional manifold and the noise produce an increase in the estimated dimension , it turns out to be extremely difficult to discriminate between both .",
    "we have suggested a possible way of discriminating both effects by analyzing the behavior of the mleid curve for large values of @xmath10 .",
    "however , it suffers from problems because the hypotheses under which mleid is based are not correctly fulfilled for large values of @xmath10 .",
    "the application of the method to real observations in the pair of lines at 1.56 @xmath0 m and the pair at 6302    shows that the near - ir lines appear to carry more information than the visible ones .",
    "an extra numerical experiment has shown unequivocally that the amount of information that may be obtained from an observed dataset increases as the number of included lines increases .",
    "although this work has focused on spectro - polarimetric datasets , it is fundamental to point out the enormous applicability of the estimators of the intrinsic dimension like the one presented by @xcite .",
    "physics , and specially astrophysics depends on the development of models with different levels of complexity that are used to explain the observables .",
    "a posteriori , inversion techniques allow to infer the properties of the object under study by fitting the observables with the proposed model .",
    "the complexity of the model has to be constrained by the amount of information available in the observables .",
    "consequently , the estimators of the intrinsic dimensionality of the observed datasets help us accept or reject different models depending on the amount of information carried out by the observables .",
    "we thank r. casini , m. collados , e. khomenko , b. ruiz cobo and j. trujillo bueno for helpful discussions .",
    "we thank the anonymous referee for useful suggestions .",
    "this research has been funded by the spanish ministerio de educacin y ciencia through project aya2004 - 05792 ."
  ],
  "abstract_text": [
    "<S> the amount of information available in spectro - polarimetric data is estimated . to this end </S>",
    "<S> , the intrinsic dimensionality of the data is inferred with the aid of a recently derived estimator based on nearest - neighbor considerations and obtained applying the principle of maximum likelihood . we show in detail that the estimator correctly captures the intrinsic dimension of artificial datasets with known dimension . </S>",
    "<S> the effect of noise in the estimated dimension is analyzed thoroughly and we conclude that it introduces a positive bias that needs to be accounted for . </S>",
    "<S> real simultaneous spectro - polarimetric observations in the visible 630  nm and the near - infrared 1.5  @xmath0 m spectral regions are also investigated in detail , showing that the near - infrared dataset provides more information of the physical conditions in the solar atmosphere than the visible dataset . </S>",
    "<S> finally , we demonstrate that the amount of information present in an observed dataset is a monotonically increasing function of the number of available spectral lines . </S>"
  ]
}