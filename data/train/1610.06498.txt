{
  "article_text": [
    "the current massive production of data has brought up plenty of challenges to the areas of data mining , natural language processing ( nlp ) and machine learning .",
    "an example of a current challenge in information sciences is the authorship attribution task , which amounts to the ability to assign authorship to anonymous or disputed documents .",
    "this task has drawn attention from researchers mostly for its implications in real applications , such as plagiarism detection  @xcite , forensics against cyber crimes  @xcite and resolution of disputed documents  @xcite .",
    "several methods have been proposed to undertake the authorship attribution problem  @xcite .",
    "traditional techniques use text analytics and natural language processing concepts to characterize authors writing styles  @xcite . for example , in several studies , it has been shown that the raw frequency of function words or the intermittency of content words is notably useful to discriminate authors styles  @xcite . in recent years , deeper paradigms have been employed to tackle this problem .",
    "syntactical and semantical features are some examples of features not relying only on simple statistical analyses  @xcite .",
    "despite being effective in particular contexts , deeper paradigms require a more complex data handling , a painstaking effort that may not yield good results in generic scenarios . even though methods based on simple statistical analyses yield , in general , excellent results with the advantage of not requiring a large corpora for training or language - dependent resources , they are prone to manipulation via obfuscation of imitation attacks  @xcite .",
    "for this reason , more robust statistical methods have been proposed .",
    "a recent trend in authorship attribution research is using the complex network framework , due to the success of its use in related tasks , mostly in text classification tasks  @xcite . in this paradigm ,",
    "documents are modeled by means of a co - occurrence network  @xcite , and the properties of the formed networks are used as authors fingerprints in the classification process  @xcite .",
    "although such methods have proven useful for discriminating writing styles with a certain robustness provided by topological analysis , they usually provide no better results than traditional techniques based e.g. in n - grams models when used as a single source of text characterization . however , complex network topologies are less prone to manipulation , which makes these network - based methods more robust in real scenarios .",
    "note that complex network - based measurements provide a complementary view of unstructured documents , a feature that can be further explored in hybrid approaches .    in a typical networked - based authorship recognition system ,",
    "texts are modeled as a network and the structure of these networks is then used as a relevant feature to discriminate distinct authors  @xcite . while traditional network topology measurements are useful to understand the main topological properties of texts , they may provide an ambiguous characterization , mainly when subtleties in style are not mapped into equivalent informative network structures .",
    "for this reason , the creation of informative , efficient and unambiguous network measurements for specific models remains as an open problem in network science . in this context , we explore a novel network characterization based on cellular automata theory ( ca )  @xcite .    in the last decade , the fusion of networks and cellular automata , appeared into the literature  @xcite .",
    "this discrete dynamical system , called as network automata ( na ) , uses the network structure as the tessellation of the cellular automaton , whose dynamics is governed by a rule that defines the states of its nodes at each time step .",
    "nas turned out to be a powerful tool for pattern recognition purposes because it combines the advantages of the networks for modeling and analyses with the capabilities of cas to extract complex patterns  @xcite .    in this manuscript",
    ", we propose a method to characterize networks representing written texts to tackle the authorship attribution task .",
    "the proposed method is based on life - like network automata ( llna )  @xcite , which was inspired by the 2d life - like ca  @xcite , a well - known set of rules explored in diverse fields  @xcite .",
    "we depart from the well - known word - adjacency model and include a llna dynamics to characterize text networks .",
    "more specifically , our approach relies on a selection of informative llna s rules and , therefore , we expect to obtain spatio - temporal patterns possessing two important properties : ( i ) the books written by the same author displays similar patterns ; and ( ii ) books written by distinct authors display distinct spatio - temporal patterns . using a collection of texts written by 8 authors",
    ", we obtained an accuracy of 76% , which is considerably more accurate than traditional methods based solely on topological properties of networks and , therefore , demonstrating the good performance of the proposed method .",
    "in this section , we introduce an overview of the main proposal ( see figure  [ fig : procedure ] ) to understand not only the sequence of mathematical preliminaries , but also the experiments setup that are presented in section  [ sec : results ] .",
    "first , we introduce the well - known network model of text representation , the word - adjacency model .",
    "we also present optional text pre - processing strategies which may be applied to improve the characterization of texts .",
    "some network measurements used to explore the properties of networks are presented .",
    "next , we discuss the life - like network automata representation used in this article and their respective measurements .",
    "the measurements extracted from the life - like network automata dynamics are then used to characterize the style of each author .          in recent years",
    ", distinct ways to model texts as complex networks and graphs have been proposed  @xcite .",
    "particularly , in the current study , we have used the so - called word adjacency ( or co - occurrence ) model , as it has been proven useful to grasp stylistic textual patterns  @xcite . in this model ,",
    "each node represents",
    "a word and the edges are created whenever two words appear as adjacent in the raw text .",
    "mathematically , the word adjacency network is represented by an adjacency matrix @xmath0 , whose elements @xmath1 are defined as @xmath2      prior to the transformation of the text as a network , some pre - processing steps may be required . in most of the applications devoted to represent texts as networks ,",
    "the three following steps are performed .",
    "the first step is the _ tokenization _ , which is responsible to split the document into meaningful units , such as words and punctuation marks .",
    "the second step performs the removal of _ stopwords _ , which are the words conveying little semantic meaning such as articles and prepositions .",
    "the list of stopwords is shown in section s3 of the supplementary information .",
    "note that , in this phase , punctuation marks are also disregarded , as they do not contribute to the semantic meaning of text .",
    "finally , the third step , a lemmatization is applied to map the remaining words into their canonical forms . as such",
    ", verbs and nouns are mapped to their infinitive and singular forms , respectively .",
    "the lemmatization process usually requires the identification of the individual parts - of - speech to solve possible ambiguities . in this paper , we have used the average perceptron part - of - speech tagger proposed by collins  @xcite .",
    "an exemplification of the pre - processing steps of a text extracted from the book _ the valley of fear _ by doyle , is shown in section s4 of the supplementary information .",
    "although lemmatization is often used in nlp tasks , toman  @xcite argued that this pre - processing step does not affect the performance of general text classification systems . to our knowledge",
    ", there is no systematic analysis on the effect of lemmatization on network - based authorship recognition methods .",
    "for this reason , we have considered the following three variations in the application of pre - processing in raw texts : ( i ) _ none _ , no lemmatization is performed ; ( ii ) _ partial _ , only nouns are lemmatized ; and ( iii ) _ full _ , all words are lemmatized , as it is done in more traditional works .      in this section",
    ", we present a brief description of measurements used to characterize the topological properties of complex networks .",
    "these measurements are used here to study how the properties of text networks vary with distinct pre - processing steps .",
    "in addition , these measurements are also used for comparison and validation purposes .",
    "the simplest measurements are the number of nodes ( @xmath3 ) and edges ( @xmath4 ) .",
    "the density of a network is defined as @xmath5 , i.e. the fraction between the total number of edges and the maximum possible number of edges obtained in an equivalent fully connected network .",
    "the degree @xmath6 of a node @xmath7 is defined as the number of neighbors that @xmath7 and is given by @xmath8 the coefficient @xmath9 of the degree distribution @xmath10 is another widely known measurement in network science  @xcite .",
    "similar to other real - world networks , text adjacency networks display the scale - free behavior  @xcite . to estimate the coefficient @xmath9",
    ", we used the strategy defined in  @xcite .",
    "the degree is also usually measured in global terms as @xmath11 the quantity defined in equation [ avgdegree ] is the average degree , a measurement that has been applied in a myriad of network contexts  @xcite , even though many of the studied distributions makes this quantity not a representative element of the distribution , as many networks display a fat - tailed behavior  @xcite .",
    "this is the case of text networks , whose fat - tailed degree distribution stems from the zipf s law  @xcite .",
    "however , in several cases , the average degree is useful to discriminate distinct topologies  @xcite .",
    "another well known connectivity measurement is the hierarchical degree @xmath12 , which corresponds to the number of neighbors at distance @xmath13 .",
    "this is a simple extension of the concept of node degree for further hierarchies . despite its seeming simplicity ,",
    "the use of hierarchies has proven useful to improve the characterization of several real - world networks  @xcite .    while the degree is essentially a local measurement , some other indexes",
    "were specially devised to characterize the global topology of networks .",
    "this is the case of distance - based metrics .",
    "measurements based on geodesic paths include the average shortest path length ( @xmath14 ) and the diameter ( @xmath15 ) .",
    "the average shortest path length of a network is computed as @xmath16 where @xmath17 is the length of the shortest distance between nodes @xmath7 and @xmath18 .",
    "the diameter of a network @xmath15 , is the largest path length among all distances .",
    "the transitivity of the network was measured by the average clustering coefficient @xmath19 , where @xmath20 is the clustering coefficient computed for node @xmath7 and measure the probability of any two neighbors of @xmath7 being linked .",
    "mathematically , the local clustering coefficient is computed as @xmath21 where @xmath22 represents the number of edges between the neighbors of node @xmath7 . even though this measure was originally used in social sciences ,",
    "the clustering coefficient has been used to identify the specificity of words in distinct contexts .",
    "finally , we used the assortativity measure to measure if similar nodes are connected to each other . in this case",
    ", we used the concept of degree correlation , which assigns a high assortativity value for networks with edges established mostly between nodes with similar degree  @xcite .",
    "the assortativity is given by @xmath23 ^ 2}{(1/e)\\sum_{j > i } ( 1/2)(k_i^2+k_j^2)a_{ij } - [ ( 1/e)\\sum_{j > i } ( 1/2)(k_i+k_j)a_{ij}]^2}\\ , .",
    "\\label{eq : assortativity}\\ ] ] in general ,",
    "text networks are disassortative , i.e. @xmath24  @xcite .",
    "a network automata can be defined as a tuple @xmath25 .",
    "@xmath26 represents the na space , which is the topology of a network comprising @xmath3 nodes ( cells ) .",
    "@xmath27 is the set of binary states @xmath28 , where @xmath29 is the live state and @xmath30 the dead state .",
    "the cell s state can be identified by the function @xmath31 , such that @xmath32 gives the state of cell @xmath33 at time @xmath34 .",
    "finally , @xmath35 represents the initial configuration of all cells ( i.e. the configuration at @xmath36 ) and @xmath37 is a transition function , i.e. , the rule that governs the na dynamics by defining how cells states are updated over time  @xcite .",
    "hereafter , we consider that the automata dynamics is stopped when @xmath38 .    the llna was proposed as a class of binary na inspired by the rules of the life - like cellular automata ( ca )  @xcite , which uses a set of outer - totalistic rules , _",
    "i.e. , _ rules that depend on the current state of cell @xmath33 and on the states of its neighboring cells .",
    "the llna transition function @xmath37 is stated as @xmath39    where the neighborhood density @xmath40 of node @xmath7 is the proportion of alive neighbors , i.e. @xmath41 in the llna method , @xmath42 due to moore s neighborhood  @xcite . as a consequence ,",
    "there exists a total of @xmath43 possible transition rules in the life - like family of rules  @xcite . in equation [ eq : rule ] , the parameters @xmath44 and @xmath45 serve to label the rule in the form b@xmath46-s@xmath47 , where b and s stand for `` born '' and `` survive '' , respectively ; and @xmath48 and @xmath49 are the possible @xmath42 digits in the rule described by equation [ eq : rule ] . for instance , the rule b3-s23 is given by    @xmath50      the dynamic of a network automata provides a global spatio - temporal pattern of evolution .",
    "thus , each network node can be analyzed as a sequence of ones and zeros .",
    "a set of measurements , such as the shannon entropy and lempel - ziv complexity were suggested to extract quantitative properties from the generated spatio - temporal patterns  @xcite .",
    "the shannon entropy of a binary sequence is defined as @xmath51 where @xmath52 and @xmath53 are the probability of having ones and zeros in the sequence , respectively  @xcite .",
    "the shannon entropy ranges in the interval @xmath54 $ ] , where oscillating and complex spatio - temporal patterns tend to higher entropy values , while steady patterns tend to lower values .",
    "the lempel - ziv complexity @xmath55 , different from shannon entropy , is a measurement based on the number of different blocks ( @xmath56 ) that a sequence can contain  @xcite .",
    "a minimum block is defined using the first bit on the left of the sequence .",
    "then , one moves rightward , bit by bit , until an unseen subsequence appears , which is formed starting exactly after a previous block and ending at the current position .",
    "for instance , the binary sequence @xmath57 of length @xmath58 , can be divided into @xmath59 minimum blocks : @xmath60 .",
    "given the number of blocks @xmath56 , the lempel - ziv complexity is computed as @xmath61 in literature , there exist several statistical similarity measurements designed to compare two binary sequences @xmath62 and @xmath63  @xcite .",
    "most of these measurements are defined in terms of the following binary instances @xmath64=@xmath65 , @xmath66 , @xmath67 and @xmath68 . the most traditional measurements are @xmath69    in our experiments , we have compared binary sequences by considering both spatial and temporal patterns . if we consider the spatial pattern , binary sequences generated by all nodes in two distinct time steps are compared .",
    "analogously , if one considers temporal patterns , sequences generated by two nodes are compared by considering all times . in short , the spatio - temporal states of nodes can be represented in a matrix form , whose element stored in the @xmath7-th row and @xmath34-th column represents the state of node @xmath7 at time @xmath34 .",
    "thus , spatial patterns are analyzed via comparison of horizontal sequences , while temporal patterns are analyzed by comparing vertical sequences .",
    "let @xmath70 be a horizontal sequence obtained at the @xmath34-th time step and @xmath71 a vertical sequence obtained from the @xmath7-th node .",
    "horizontal sequences @xmath70 and @xmath72 are compared , with @xmath73 . in a similar fashion , vertical sequences @xmath71 and @xmath74 are also compared , with @xmath75 .",
    "the similarity obtained from spatial and temporal comparisons are represented by @xmath76 and @xmath77 , respectively .",
    "further experiments regarding the influence the parameters @xmath78 and @xmath79 are explained in section s1 of the supplementary information .",
    "we employed the llna method to extract the intrinsic patterns from textual networks , which aim to distinguish among authors written style .",
    "in the so - called training phase , these techniques first identify patterns for each author s writing style .",
    "then , the patterns identified in the previous phase are used to classify unseen instances in the classification phase . in this manuscript ,",
    "several well - known supervised classification methods were employed : bayesian networks ( bnt ) , naive bayes ( nvb ) , rbf networks ( rbf ) , multi layer perceptron ( mlp ) , support vector machines ( svm ) , k nearest neighbors ( knn ) , c4.5 ( c45 ) and random forest ( rfo )  @xcite .",
    "all classifiers were set up with their default configuration of parameters , as suggested in  @xcite .    to evaluate the performance of the classification",
    ", we used the k - fold cross - validation strategy  @xcite . to perform the evaluation , this method splits the data into two sets : the training dataset is the set of samples used for training purposes , while the test set is used for validation purposes .",
    "since these two sets are mutually exclusive and , therefore , the evaluation is performed over unknown instances , the cross - validation method is a reliable strategy . in this study , we use @xmath80 because each author was characterized by a set of 5 books ( see description of the dataset in section  [ datasets ] ) .",
    "thus , at each iteration , one book of each author is chosen to compound the test dataset , while the remaining books are selected to form the training dataset .",
    "the results were also further probed by using confusion matrices , which are structures , reporting for each possible class ( in our case , for each distinct author ) the relationship between predicted and real classes .",
    "traditionally , a confusion matrix is used to identify the following patterns of performance : @xmath81 , which is the number of instances belonging to class @xmath82 which were correctly assigned to @xmath82 ; while @xmath83 is the number of instances belonging to class @xmath82 which were incorrectly assigned to class @xmath84 .",
    "specially , the quantity @xmath83 will be useful to identify which authors can not be discriminated with the proposed technique .",
    "an english corpus of known authors ( labeled instances in the supervised training phase ) was created to evaluate the accuracy of the proposed method .",
    "the corpus comprises @xmath85 books , which were extracted from the project gutenberg repository  .",
    "the books in our dataset were written by @xmath86 distinct authors .",
    "the full list of books and the respective authors is provided in section s2 of the supplementary information .",
    "the distribution of books for authors is uniform , i.e. each author is represented by a set of 5 books . in this study",
    ", we considered the task of discriminating among 8 distinct authors .",
    "this dataset is hereafter referred to as _ validation - dataset_. note that datasets using a similar distribution of authors and genres have been considered in related works  @xcite .",
    "the remaining set of @xmath87 authors , hereafter referred to as _ rule - selection - dataset _ , was used to the particular process of selecting the best llna set of rules .",
    "note that the choice of best rules was performed in a different dataset because , if the same dataset was used for selecting rules and evaluating classifiers , the obtained results could not represent a true classifier generalization  @xcite .    in the general scenario of textual classification",
    ", the application of pre - processing steps may be useful for the task in hand .",
    "in semantical tasks , such as the word sense disambiguation , the lemmatization of words plays an important role on the performance  @xcite . in the authorship attribution task , conversely",
    ", this same lemmatization step may lead to a great loss of information , hindering the accurate identification of authors particular writing choices  @xcite .",
    "however , it has been shown that in network based techniques , the lemmatization step is important to cluster distinct writing forms into the same node . in our experiments",
    ", we also evaluated three types of lemmatization strategies to generate the textual networks , which led to the creation of three distinct variations of datasets for both _ validation - dataset _ and _ rule - selection - dataset_.    1 .   _",
    "none - dataset _",
    ": the original dataset was kept , i.e. the lemmatization step was disregarded .",
    "partial - dataset _ : the lemmatization was applied only in nouns .",
    "thus , all nouns are mapped to their singular forms .",
    "_ full - dataset _ : the lemmatization was applied to all words .",
    "therefore , verbs and nouns are mapped to their infinitive and singular forms , respectively .",
    "the main purpose of this manuscript is to characterize networks representing written texts to obtain informative features for the authorship attribution task . differently from traditional approaches , here we explored the use of llna rules to discriminate network topologies .",
    "we have used this approach because it has been shown that authors particular writing choices modify word adjacency networks in a consistent form  @xcite .",
    "as described in section  [ datasets ] , our dataset comprises @xmath85 books written by 20 distinct authors , and three distinct pre - processing strategies were probed to generate the textual networks . in section [ stevolution ] , we qualitatively discuss the patterns arising from the dynamics of the llna modelling for each book . in section [ selecrules ] , we perform the selection of the best llna rules , which are then applied in the authorship problem described in section [ classification ] . in section [ other - measures ] , we compared the proposed approach with the one based on traditional topological measurements  @xcite . finally , in section [",
    "sec : effectlemmatization ] , we explore the effects of the lemmatization process on the properties of the networks .      table  [ tab : spacetime ] shows the spatio - temporal diagram of 40 networks of the _ partial - dataset _ using rule b024678-s4 .",
    "a spatio - temporal diagram is the representation of the states along time , thus , each column represents the state of a given node and each line represents one time step . in this particular case",
    ", for each spatio - temporal diagram , the columns were ordered by the node degree .",
    "thus , the left - most columns are the nodes taking the lowest degrees @xmath88 , and , the right - most , the ones taking the largest values of @xmath88 .",
    "note that the number of nodes @xmath3 varies across networks ( also reported in figure  [ fig : avg - measures ] ) , therefore , the diagrams are formed by a different number of columns . for simplicity s sake",
    ", the diagrams were scaled to fit within the columns of the table .",
    "notice that for the particular llna rule b024678-s4 , table  [ tab : spacetime ] reveals a general pattern among all the authors .",
    "three notable regions arise : the leftmost correspond to an oscillatory pattern with a higher tendency of alive nodes , followed by a row with tendency of dead nodes ( region comprising nodes with average degree @xmath89 ) .",
    "then , another shorter oscillatory region appears , followed by a second region , which also presents a higher frequency of dead nodes ( region comprising nodes with average degree @xmath90 ) .",
    "the reader should note that rule b024678-s4 does not favor nodes with average degrees @xmath91 and @xmath92 for birth and survival conditions , which explains the distribution of these vertical patterns in the diagrams .",
    "the influence of this rule over the nodes with average degree @xmath93 is less apparent due to the lower frequency of these nodes .",
    "the rightmost nodes , which correspond to hubs in the network , also show oscillatory patterns that are directly related to the dynamics of rule b024678-s4 , which favors the birth of the nodes and penalizes their survival . therefore , there are a dependency between the rule and the network topology .    despite the above",
    "mentioned similar structures in the spatio - temporal diagram , author - dependent patterns can also be noted .",
    "for instance , the patterns obtained for darwin in all five books are strongly similar .",
    "darwin s textual networks present a bigger region corresponding to nodes with average degree @xmath94 , and a major ratio of nodes with high connectivity which are influenced by the rule .",
    "therefore , the spatio - temporal diagram lead us to deduce that the books written by the same author exhibits similar patterns , while allowing to distinguish among the other authors , and that there is a strong dependency of the llna s rule .    based on the spatio - temporal diagram displayed in table  [ tab : spacetime ] ,",
    "we applied measurements ( see section  [ method : llnameasurements ] ) that allow the characterization of the textual networks in terms of a time series containing only zeros and ones . before presenting the results of the classification based on time series analysis in section  [ classification ] ,",
    "we first address the llna rule selection in the next section .",
    "the rule selection is as important parameter to achieve higher accuracies using the llna method  @xcite .",
    "we evaluated , exhaustively , each of the @xmath95 possible life - like rules using the _ rule - selection - dataset _ comprising 12 authors .",
    "as discussed before , the reader should note that the rule selection was performed in different dataset in order to obtain llna rules that best represent a true classifier generalization  @xcite .    to characterize the dynamics of the llna",
    ", we used a feature vector storing the shannon entropy and the lempel - ziv distributions @xmath96 $ ] , during @xmath97 time steps . because the choice of the best rule encompasses the induction and evaluation of @xmath95 classifiers , we only used in this phase the knn method .",
    "we have chosen particularly this method because , in general , it generates better results while keeping an excellent processing time  @xcite . note that , the application of other methods in this phase , such as neural networks or svm , would be impractical owing to the time complexity associated to these methods  @xcite .",
    "figure  [ fig : selectionrule ] depicts the histogram distribution of the accuracies obtained for the complete rule - space of the llna .",
    "most of the rules yielded low accuracy classifiers .",
    "typically , accuracies lower than 40% have been found . in this study",
    ", we only selected the 400 rules yielding the highest accuracy rates .",
    "note that the selection of best rules is performed independently in each of three datasets : _",
    "none- _ , _ partial- _ and _ full- _ from the _ rule - selection - dataset_. moreover , as the selection rule is a preliminary phase , one should expect that among the set of best rules further improvement can be achieved by using other llna measurements  @xcite .",
    "evaluated rules of the llna in the _ rule - selection - dataset _ comprising 12 authors . from left to right , the histograms for each of the 3 datasets _ none _ , _ partial _ and _ full _ , are shown respectively .",
    "as an example , the highlighted five rules maximizes the classification of the _ rule - selection - dataset _ , when a partial lemmatization was applied . for this rule selection experiment ,",
    "both shannon entropy and lempel - ziv complexity were considered as corresponding feature vectors , and knn classifier . ]      for the authorship identification problem , we applied the best rules obtained to identify authorship in the _ validation - dataset _ comprising the 8 authors .",
    "first , we compared the three datasets , _",
    "none- _ , _ partial- _ and _ full - dataset _ by using different measurements extracted from the llna dynamics : the shannon entropy distribution @xmath98 , the lempel - ziv distribution @xmath99 , and the binary distance distribution , which can be analyzed in a twofold way : horizontally @xmath100 and vertically @xmath101 ( see section  [ method : llnameasurements ] ) .",
    "we evaluated the performance of the classification by using different llna measurements , extracted from the spatio - temporal pattern , in two ways , isolated and combined .",
    "thus , four feature vectors were used to characterize authors styles .",
    "the first feature vector @xmath98 is composed by the distribution of the shannon entropy @xmath102 , which is divided into 40 bins , therefore , @xmath98 contains 40 attributes .",
    "similarly , the second feature vector @xmath99 is composed by the lempel - ziv complexity distribution divided into 40 bins .",
    "this vector was normalized by the maximum value achieved among the group of samples .",
    "the third and fourth feature vectors are the binary distance distributions , which were explored by means of vertical @xmath103 and horizontal @xmath100 analyses , which also contains 30 attributes per measurement .",
    "finally , the combined vector @xmath104 $ ] contains 140 attributes .",
    "we tested the accuracy of the 400 selected rules ( see section  [ selecrules ] ) with different feature vectors as well as the combination of them . table  [ tab : acuracia1 ] presents the best rules obtained for the _ validation - dataset_. the columns @xmath98 , @xmath99 , @xmath100 and @xmath101 show the accuracy rates obtained for each distinct feature vector .",
    "the results when combining these distributions are shown in the last column of the same table .",
    "note that the isolated feature vector @xmath101 yielded the maximum accuracy of 76.03% ( @xmath105 12.02% ) for rule b024678-s4 when using the _ partial - dataset_.    [ cols=\"<,<,^,^,^,^,^\",options=\"header \" , ]     ) .",
    "the following distributions are shown for each author : number of nodes ( @xmath3 ) , number of edges ( @xmath4 ) , average connectivity ( @xmath106 ) , average clustering coefficient ( @xmath107 ) , average path length ( @xmath108 ) , diameter ( @xmath15 ) , density ( @xmath109 ) , power - law exponent ( @xmath110 and degree assortativity ( @xmath111 ) . ]    figure  [ fig : avg - measures ] presents a set of average topological measurements calculated for each author of the _ validation - dataset_. the standard deviation was obtained considering the five books of each author . figure  [ fig : avg - measures ] also shows the values obtained for the three variations of dataset .",
    "the main results concerning each measurement are described below :    * * total number of nodes ( @xmath3 ) and edges ( @xmath4 ) * : @xmath3 decreases with the lemmatization process , whereas @xmath4 is not influenced by this process .",
    "this effect occurs because , even when nodes are removed during the lemmatization , adjacency relationships are not affected , and , consequently , the degree of the remaining nodes tends to increase .",
    "this effect is evident in the top - right diagram displaying the average network connectivity @xmath112 . * * average clustering coefficient ( @xmath107 ) * : this measurement was influenced by both @xmath3 and @xmath88 .",
    "@xmath107 tends to increase with the lemmatization process because the network remains with almost the same number of edges , while the number of nodes decreases as a consequence of mapping distinct variations of the same concept into the same node . *",
    "* average shortest path length ( @xmath108 ) * : similarly to the number of edges , the average shortest path length is not much affected by the lemmatization process .",
    "however , note that the values of @xmath108 tend to decrease as a consequence of the decrease in the total number of nodes . *",
    "* diameter ( @xmath15 ) * : in most cases , the diameter increases by a short margin when the lemmatization process is performed",
    ". however , this pattern seems to depend from author to author .",
    "note , e.g. that the average diameter decreases when the full lemmatization is applied for books authored by doyle .",
    "conversely , the lemmatization process seems to cause an opposite effect on networks modelling books written by allan poe . *",
    "* density ( @xmath109 ) * : the density of links increases in most cases , as the lemmatization process removes nodes , and the number of edges is practically not affected .",
    "an exception occurs for darwin .",
    "remarkably , the average density of the _ none-",
    "_ and _ full- _ datasets are in a similar fashion . * * power - law exponent ( @xmath110 * : almost all the textual networks present power exponent between 2 and 3 , which is a characteristic that have been demonstrated for many real - world networks  @xcite and , particularly in text networks , is a consequence of the zipf s law . concerning the effect of the lemmatization process on this feature ,",
    "no clear pattern can be identified , as opposite effects have been found e.g. for stoker and poe .",
    "in this paper , we have addressed the authorship attribution problem , which is a task of practical relevance in many contexts of information science research .",
    "we have specifically studied the effect of the textual organization in the discriminability of documents written by distinct authors . to capture the structural properties of texts , we have used the well - known network framework , given",
    "its potential revealed in related applications . unlike the traditional approach based only on topological properties of networks ,",
    "we have proposed here a methodology to capture further information concerning authors particular styles .",
    "to do so , we have represented networks modelling texts as network automata with a dynamics based on life - like rules . upon selecting a set of discriminative rules that serve to coordinate the automata dynamics ,",
    "we have found that the variations in the binary states of nodes are more discriminative than simple traditional topological characterization .",
    "more specifically , we have obtained an improvement of almost 15% in the classification of @xmath113 distinct authors .",
    "interestingly , the best results were obtained with a partial lemmatization process , suggesting that this procedure is more adequate than just lemmatizing all words when text networks are used as the underlying model for this task .",
    "the methodology proposed here paves the way for improving the characterization of related information systems modelled in terms of networks .",
    "this is evident if we recall that network automata approaches are specially suitable to describe networks with scale - free distributions  @xcite and , as a consequence , documents following zipf s law .",
    "further works could investigate the effectiveness of our approach e.g. in the analysis of the complexity of texts or in applications related to extractive summarization .",
    "given the complementarity of the analysis provided by the network automata framework , we argue that a combination relying on traditional superficial and networked features could lead to optimized results in a variety of natural language processing applications .",
    "j.m . is grateful for the support of the coordination for the improvement of higher education personnel ( capes ) .",
    "e.a.c.j . and d.r.a .",
    "are grateful for the support from google ( google research awards in latin america grant ) .",
    "is also grateful for the financial support from so paulo research foundation ( fapesp grant # 2014/20830 - 0 ) .",
    "g.h.b.m . is grateful for the support from capes and fapesp with grant # 2015/05899 - 7 .",
    "o.m.b . gratefully acknowledges the financial support of cnpq ( national council for scientific and technological development , brazil ) ( grant # 307797/2014 - 7 and grant # 484312/2013 - 8 ) and fapesp ( grant # 11/01523 - 1 and grant # 2015/05899 - 7 ) ."
  ],
  "abstract_text": [
    "<S> the authorship attribution is a problem of considerable practical and technical interest . </S>",
    "<S> several methods have been designed to infer the authorship of disputed documents in multiple contexts . while traditional statistical methods based solely on word counts and related measurements have provided a simple , yet effective solution in particular cases ; they are prone to manipulation . </S>",
    "<S> recently , texts have been successfully modeled as networks , where words are represented by nodes linked according to textual similarity measurements . </S>",
    "<S> such models are useful to identify informative topological patterns for the authorship recognition task . however , there is no consensus on which measurements should be used . </S>",
    "<S> thus , we proposed a novel method to characterize text networks , by considering both topological and dynamical aspects of networks . </S>",
    "<S> using concepts and methods from cellular automata theory , we devised a strategy to grasp informative spatio - temporal patterns from this model . </S>",
    "<S> our experiments revealed an outperformance over traditional analysis relying only on topological measurements . </S>",
    "<S> remarkably , we have found a dependence of pre - processing steps ( such as the lemmatization ) on the obtained results , a feature that has mostly been disregarded in related works . </S>",
    "<S> the optimized results obtained here pave the way for a better characterization of textual networks . </S>"
  ]
}