{
  "article_text": [
    "this paper is about optimal sequential allocation in unknown random environments .",
    "more precisely , we consider the setting known under the conventional , if not very explicit , name of ( stochastic ) _ multi - armed bandit _ , in reference to the 19th century gambling game . in the multi - armed bandit model , the emphasis",
    "is put on focusing as quickly as possible on the best available option(s ) rather than on estimating precisely the efficiency of each option .",
    "these options are referred to as arms , and each of them is associated with a distribution ; arms are indexed by @xmath0 and associated distributions are denoted by @xmath1 .",
    "the archetypal example occurs in clinical trials where the options ( or arms ) correspond to available treatments whose efficiencies are unknown a priori , and patients arrive sequentially ; the action consists of prescribing a particular treatment to the patient , and the observation corresponds ( e.g. ) to the success or failure of the treatment .",
    "the goal is clearly here to achieve as many successes as possible .",
    "a  strategy for doing so is said to be _ anytime _ if it does not require to know in advance the number of patients that will participate to the experiment .",
    "although the term multi - armed bandit was probably coined in the late 1960s [ @xcite ] , the origin of the problem can be traced back to fundamental questions about optimal stopping policies in the context of clinical trials [ see thompson ( @xcite ) ] raised since the 1930s ; see also @xcite .    in his celebrated work ,",
    "@xcite considered the _ bayesian - optimal _ solution to the discounted infinite - horizon multi - armed bandit problem .",
    "gittins first showed that the bayesian optimal policy could be determined by dynamic programming in an extended markov decision process .",
    "the second key element is the fact that the optimal policy search can be factored into a set of simpler computations to determine _ indices _ that fully characterize each arm given the current history of the game [ @xcite ] .",
    "the optimal policy is then an _ index policy _ in the sense that at each time round , the ( or an ) arm with highest index is selected .",
    "hence , index policies only differ in the way the indices are computed .    from a practical perspective , however , the use of gittins indices is limited to specific arm distributions and is computationally challenging [ @xcite ] . in the 1980s ,",
    "pioneering works by @xcite , @xcite , burnetas and katehakis ( @xcite ) suggested that gittins indices can be approximated by quantities that can be interpreted as upper bounds of confidence intervals .",
    "@xcite formally introduced and provided an asymptotic analysis for generic classes of index policies termed ` ucb ` ( for upper confidence bounds ) . for general bounded reward distributions",
    ", @xcite provided a finite time analysis for a particular variant of ` ucb ` based on hoeffding s inequality ; see also @xcite for a recent survey of bandit models and variants .",
    "there are , however , significant differences between the algorithms and results of @xcite and @xcite . first",
    ", ` ucb ` is an anytime algorithm that does not rely on the use of a discount factor or even on the knowledge of the horizon of the problem .",
    "more significantly , the bayesian perspective is absent , and ` ucb ` is analyzed in terms of its frequentist ( distribution - dependent or distribution - free ) performance , by exhibiting _ finite - time _",
    ", nonasymptotic bounds on its expected regret .",
    "the expected regret of an algorithm  a quantity to be formally defined in section  [ secnot]corresponds to the difference , in expectation , between the rewards that would have been gained by only pulling a best arm and the rewards actually gained .    `",
    "ucb ` is a very robust algorithm that is suited to all problems with bounded stochastic rewards and has strong performance guarantees , including distribution - free ones .",
    "however , a closer examination of the arguments in the proof reveals that the form of the upper confidence bounds used in ` ucb ` is a direct consequence of the use of hoeffding s inequality and significantly differs from the approximate form of gittins indices suggested by @xcite or @xcite .",
    "furthermore , the frequentist asymptotic lower bounds for the regret obtained by these authors also suggest that the behavior of ` ucb ` can be far from optimal . indeed , under suitable conditions on the model @xmath2 ( the class of possible distributions associated with each arm ) , any policy that is `` admissible '' [ i.e. , not grossly under - performing ; see @xcite for details ] must satisfy the following asymptotic inequality on its expected regret @xmath3 $ ] at round @xmath4 : @xmath5}{\\log ( t ) } \\geq\\sum _ { a:\\mu_a<\\mu^\\star } \\frac{\\mu^\\star-\\mu_a}{{\\mathcal{k}}_{\\inf } ( \\nu _ a,\\mu^\\star)},\\ ] ] where @xmath6 denotes the expectation of the distribution @xmath1 of arm @xmath0 , while @xmath7 is the maximal expectation among all arms .",
    "the quantity @xmath8 which measures the difficulty of the problem , is the minimal kullback",
    " leibler divergence between the arm distribution @xmath9 and distributions in the model @xmath2 that have expectations larger than @xmath10 . by comparison ,",
    "the bound obtained in @xcite for ` ucb ` is of the form @xmath11 \\leq c \\biggl ( \\sum_{a:\\mu_a<\\mu^\\star } \\frac{1}{\\mu^\\star-\\mu_a } \\biggr ) \\log(t)+ o \\bigl(\\log(t ) \\bigr)\\ ] ] for some numerical constant @xmath12 , for example , @xmath13 ; we provide a refinement of the result of @xcite as corollary  [ corucb ] , below .",
    "these two results coincide as to the logarithmic rate of the expected regret , but the ( distribution - dependent ) constants differ , sometimes significantly . based on this observation ,",
    "honda and takemura ( @xcite ) proposed an algorithm , called ` dmed ` , that is not an index policy but was shown to improve over ` ucb ` in some situations .",
    "they later showed that this algorithm could also accommodate the case of semi - bounded rewards ; see @xcite .",
    "building on similar ideas , we show in this paper that for a large class of problems there does exist a generic index policy  following the insights of @xcite , @xcite and @xcite  that guarantees a bound on the expected regret of the form @xmath11 \\leq\\sum_{a:\\mu_a<\\mu^\\star } \\biggl ( \\frac{\\mu^\\star-\\mu_a}{{\\mathcal{k}}_{\\inf } ( \\nu_a,\\mu^\\star ) } \\biggr ) \\log(t)+ o \\bigl(\\log(t ) \\bigr),\\ ] ] and which is thus asymptotically optimal .. in this paper , we focus on problem - dependent optimality . ]",
    "interestingly , the index used in this algorithm can be interpreted as the upper bound of a confidence region for the expectation constructed using an empirical likelihood principle [ @xcite ] .",
    "we describe the implementation of this algorithm and analyze its performance in two practically important cases where the lower bound of ( [ eqbinfregret ] ) was shown to hold [ @xcite]namely , for one - parameter canonical exponential families of distributions ( section  [ secklucb ] ) , in which case the algorithm is referred to as ` kl - ucb ` , and for finitely supported distributions ( section  [ secklemp ] ) , where the algorithm is called empirical ` kl - ucb ` . determining the empirical ` kl - ucb `",
    "index requires solving a convex program ( maximizing a linear function on the probability simplex under kullback  leibler constraints ) for which we provide in the supplemental article [ @xcite , appendix c.1 ] a simple algorithm inspired by @xcite .",
    "the analysis presented here greatly improves over the preliminary results presented , on the one hand by @xcite , and on the other hand by @xcite ; more precisely , the improvements lie in the greater generality of the analysis and by the more precise evaluation of the remainder terms in the regret bounds .",
    "we believe that the result obtained in this paper for ` kl - ucb ` ( theorem  [ thmklucb ] ) is not improvable . for empirical ` kl - ucb ` the bounding of the remainder term could be improved upon obtaining a sharper version of the contraction lemma for @xmath14 [ lemma 6 in the supplemental article , @xcite ] .",
    "the proofs rely on results of independent statistical interest : nonasymptotic bounds on the level of sequential confidence intervals for the expectation of independent , identically distributed variables , ( 1 ) in canonical exponential families ( equation  ( [ eqinegdevindepinterest ] ) ; see also lemma 11 in the supplemental article [ @xcite ] ) and ( 2 ) using the empirical likelihood method for bounded variables ( proposition  [ propcovel ] ) .    for general",
    "bounded distributions , we further make three important observations .",
    "first , the particular instance of the ` kl - ucb ` algorithm based on the kullback  leibler divergence between normal distributions is the ` ucb ` algorithm , which allows us to provide an improved optimal finite - time analysis of its performance ( corollary  [ corucb ] ) .",
    "next , the ` kl - ucb ` algorithm , when used with the kullback ",
    "leibler divergence between bernoulli distributions , obtains a strictly better performance than ` ucb ` , for any bounded distribution ( corollary  [ thborneregretklucb ] ) . finally , although a complete analysis of the empirical ` kl - ucb ` algorithm is subject to further investigations , we show here that the empirical ` kl - ucb ` index has a guaranteed coverage probability for general bounded distributions , in the sense that , at any step , it exceeds the true expectation with large probability ( proposition [ propcovel ] ) .",
    "we provide some empirical evidence that empirical ` kl - ucb ` also performs well for general bounded distributions and illustrate the tradeoffs arising when using the two algorithms , in particular for short horizons .",
    "the paper is organized as follows .",
    "section  [ secnot ] introduces the necessary notations and defines the notion of regret .",
    "section  [ secklucb ] presents the generic form of the ` kl - ucb ` algorithm and provides the main steps for its analysis , leaving two facts to be proven under each specific instantiation of the algorithm .",
    "the ` kl - ucb ` algorithm in the case of one - dimensional exponential families is considered in section  [ secklucb ] , and the empirical ` kl - ucb ` algorithm for bounded and finitely supported distributions is presented in section  [ secklemp ] .",
    "finally , the behavior of these algorithms in the case of general bounded distributions is investigated in section  [ secgeneral ] ; and numerical experiments comparing ` kl - ucb ` and empirical ` kl - ucb ` to their competitors are reported in section  [ secexpnum ] .",
    "proofs are provided in the supplemental article [ @xcite ] .",
    "we consider a bandit problem with finitely many arms indexed by @xmath15 , with @xmath16 , each associated with an ( unknown ) probability distribution @xmath1 over @xmath17 .",
    "we assume , however , that a model @xmath2 is known : a family of probability distributions such that @xmath18 for all arms @xmath0 .",
    "the game is sequential and goes as follows : at each round @xmath19 , the player picks an arm @xmath20 ( based on the information gained in the past ) and receives a stochastic payoff @xmath21 drawn independently at random according to the distribution @xmath22 .",
    "he only gets to see the payoff @xmath21 .      for each arm @xmath23 , we denote by @xmath6 the expectation of its associated distribution  @xmath1 , and we let @xmath24 be any optimal arm , that is , @xmath25 we write @xmath7 as a short - hand notation for the largest expectation @xmath26 and denote the gap of the expected payoff @xmath6 of an arm @xmath0 to @xmath7 as @xmath27 .",
    "in addition , the number of times each arm @xmath0 is pulled between the rounds @xmath28 and @xmath4 is referred to as @xmath29 , @xmath30    the quality of a strategy will be evaluated through the standard notion of expected regret , which we define formally now . the expected regret ( or simply , regret ) at round @xmath31 is defined as @xmath32 = { \\mathbb{e}}\\biggl [ t \\mu^{\\star } - \\sum_{t=1}^t \\mu_{a_t } \\biggr ] = \\sum_{a = 1}^k \\delta_a { \\mathbb{e}}\\bigl [ n_a(t ) \\bigr],\\ ] ] where we used the tower rule for the first equality .",
    "note that the expectation is with respect to the random draws of the @xmath21 according to the @xmath22 and also to the possible auxiliary randomizations that the decision - making strategy is resorting to .",
    "the regret measures the cumulative loss resulting from pulling suboptimal arms , and thus quantifies the amount of exploration required by an algorithm in order to find a best arm , since , as ( [ eqdefregr ] ) indicates , the regret scales with the expected number of pulls of suboptimal arms .",
    "we will denote them in two related ways , depending on whether random averages indexed by the global time @xmath33 or averages of a given number @xmath34 of pulls of a given arms are considered .",
    "the first series of averages will be referred to by using a functional notation for the indexing in the global time : @xmath35 , while the second series will be indexed with the local times @xmath34 in subscripts : @xmath36 .",
    "these two related indexings , functional for global times and random averages versus subscript indexes for local times , will be consistent throughout the paper for all quantities at hand , not only empirical averages .    more formally , for all arms @xmath0 and all rounds @xmath33 such that @xmath37 , @xmath38 where @xmath39 denotes the dirac distribution on @xmath40 .    for averages based on local times",
    "we need to introduce stopping times . to that end",
    ", we consider the filtration @xmath41 , where for all @xmath42 , the @xmath43-algebra @xmath44 is generated by @xmath45 . in particular ,",
    "@xmath46 and all @xmath47 are @xmath44-measurable . for all @xmath48 ,",
    "we denote by @xmath49 the round at which @xmath0 was pulled for the @xmath34th time ; since @xmath50 we see that @xmath51 is @xmath52-measurable . that is , each random variable @xmath53 is a ( predictable ) stopping time .",
    "hence , as shown , for instance , in chow and teicher [ ( @xcite ) , section 5.3 ] , the random variables @xmath54 , where @xmath55 , are independent and identically distributed according to @xmath1 .",
    "for all arms @xmath0 , we then denote by @xmath56 the empirical distributions corresponding to local times @xmath48 .",
    "all in all , we of course have the rewriting @xmath57",
    "we fix an interval or discrete subset @xmath58 and denote by @xmath59 the set of all probability distributions over @xmath60 . for two distributions @xmath61 ,",
    "we denote by @xmath62 their kullback  leibler divergence and by @xmath63 and @xmath64 their expectations .",
    "( this expectation operator is denoted by @xmath65 while expectations with respect to underlying randomizations are referred to as  @xmath66 . )    _ parameters _ : an operator @xmath67 ; a nondecreasing function + @xmath68 + _ initialization _ : pull each arm of @xmath69 once +    the generic form of the algorithm of interest in this paper is described as algorithm  [ algklucb ] .",
    "it relies on two parameters : an operator @xmath70 ( in spirit , a projection operator ) that associates with each empirical distribution @xmath35 an element of the model  @xmath2 ; and a nondecreasing function @xmath71 , which is typically such that @xmath72 .    at each round @xmath73 , an upper confidence bound @xmath74 is associated with the expectation @xmath6 of the distribution @xmath1 of each arm ; an arm @xmath46 with highest upper confidence bound",
    "is then played .",
    "note that the algorithm does not need to know the time horizon @xmath4 in advance .",
    "furthermore , the ` ucb ` algorithm of @xcite may be recovered by replacing @xmath75 with a quantity proportional to @xmath76 ; the implications of this observation will be made more explicit in section  [ secgeneral ] .      in sections  [ secklucb ] and  [ secklemp ] , we prove nonasymptotic regret bounds for algorithm  [ algklucb ] in two different settings .",
    "these bounds match the asymptotic lower bound ( [ eqbinfregret ] ) in the sense that , according to ( [ eqdefregr ] ) , bounding the expected regret is equivalent to bounding the number of suboptimal draws .",
    "we show that , for any suboptimal arm @xmath0 , we have @xmath77 \\leq\\frac{\\log(t)}{{\\mathcal{k}}_{\\inf } ( \\nu_a,\\mu ^\\star ) } \\bigl(1+o(1 ) \\bigr),\\ ] ] where the quantity @xmath78 was defined in the .",
    "this result appears as a consequence of nonasymptotic bounds , which are derived using a common analysis framework detailed in the rest of this section .",
    "note that the term @xmath79 has an heuristic interpretation in terms of large deviations , which gives some insight on the regret analysis to be presented below .",
    "let @xmath80 be such that @xmath81 , let @xmath82 be independent variables with distribution @xmath83 and let @xmath84 .",
    "by sanov s theorem , for a small neighborhood @xmath85 of @xmath1 , the probability that @xmath86 belongs to @xmath85 is such that @xmath87 in the limit , ignoring the sub - exponential terms , this means that for @xmath88 , the probability @xmath89 is smaller than @xmath90 .",
    "hence , @xmath79 appears as the minimal number @xmath34 of draws ensuring that the probability under any distribution with expectation at least @xmath7 of the event `` the empirical distribution of @xmath34 independent draws belongs to a neighborhood of @xmath1 '' is smaller than @xmath90 .",
    "this event , of course , has an overwhelming probability under  @xmath1 .",
    "the significance of @xmath90 as a cutoff value can be understood as follows : if the suboptimal arm @xmath0 is chosen along the @xmath4 draws , then the regret is at most equal to @xmath91 ; thus , keeping the probability of this event under @xmath90 bounds the contribution of this event to the average regret by a constant . incidentally",
    ", this explains why knowing @xmath7 in advance does not significantly reduce the number of necessary suboptimal draws .",
    "the analysis that follows shows that the bandit problem , despite its sequential aspect and the absence of prior knowledge on the expectation of the arms , is indeed comparable to a sequence of tests of level @xmath92 with null hypothesis @xmath93 and alternative hypothesis @xmath94 , for which stein s lemma [ see , e.g. , @xcite , theorem 16.12 ] states that the best error exponent is @xmath95 .",
    "let us now turn to the main lines of the regret proof . by definition of the algorithm , at rounds @xmath73",
    ", one has @xmath96 only if @xmath97 .",
    "therefore , one has the decomposition @xmath98\\\\[-8pt ] & \\subseteq & \\bigl\\ { \\mu^{\\dagger}\\geq u_{a^\\star}(t ) \\bigr \\ } \\cup \\bigl\\ { \\mu^{\\dagger } < u_a(t ) \\mbox { and } a_{t+1 } = a \\bigr\\},\\nonumber\\end{aligned}\\ ] ] where @xmath99 is a parameter which is taken either equal to @xmath100 , or slightly smaller when required by technical arguments .",
    "the event @xmath101 can be rewritten as @xmath102 where for @xmath103 and @xmath104 , the set @xmath105 is defined as @xmath106 by definition of @xmath14 , @xmath107 using ( [ eqmajonta ] ) , and recalling that for rounds @xmath108 , each arm is played once , one obtains @xmath109 & \\leq&1 + \\sum_{t = k}^{t-1 } { \\mathbb{p}}\\bigl\\ { \\mu^{\\dagger}\\geq u_{a^\\star}(t ) \\bigr\\ } \\\\ & & { } + \\sum_{t = k}^{t-1 } { \\mathbb{p}}\\ { \\widehat { \\nu}_{a , n_a(t ) } \\in{\\mathcal{c}}_{\\mu^{\\dagger } , f(t)/n_a(t ) } \\mbox { and } a_{t+1 } = a \\}.\\end{aligned}\\ ] ] the two sums in this decomposition are handled separately .",
    "the first sum is negligible with respect to the second sum : case - specific arguments , given in sections  [ secklucb ] and [ secklemp ] , prove the following statement .    [ fact1 ] for proper choices of @xmath70 , @xmath71 and @xmath99 , the sum @xmath110 is negligible with respect to @xmath111 .",
    "the second sum is thus the leading term in the bound .",
    "it is first rewritten using the stopping times @xmath112 introduced in section  [ secnot ] .",
    "indeed , @xmath96 happens for @xmath73 if and only if @xmath113 for some @xmath114 ; and of course , two stopping times @xmath49 and @xmath115 can not be equal when @xmath116 . we also note that @xmath117 for @xmath118 .",
    "therefore , @xmath119 where we used , successively , the following facts : the sets @xmath120 grow with  @xmath121 ; the event @xmath122 can be written as a disjoint union of the events @xmath123 , for @xmath124 ; the events @xmath125 are disjoint as @xmath33 varies between @xmath126 and @xmath127 , with a possibly empty union ( as @xmath49 may be larger than @xmath4 ) .    by upper bounding the first @xmath128 terms of the sum in ( [ eqdecompnat ] ) by @xmath28",
    ", we obtain @xmath129 it remains to upper bound the remaining sum : this is the object of the following statement , which will also be proved using case - specific arguments .",
    "[ fact3 ] for proper choices of @xmath70 , @xmath71 and @xmath99 , the sum @xmath130 is negligible with respect to @xmath111 .    putting everything together",
    ", one obtains @xmath131 & \\leq&\\frac{f(t)}{{\\mathcal{k}}_{\\inf } ( \\nu_a,\\mu^\\star ) } \\nonumber\\\\[-8pt]\\\\[-8pt ] & & { } + \\underbrace{\\sum_{n \\geq n_0 + 1 } { \\mathbb{p}}\\ { \\widehat { \\nu}_{a , n } \\in{\\mathcal{c}}_{\\mu^{\\dagger } , f(t)/n } \\}}_{o(\\log t ) } { } + { } \\underbrace { \\sum _ { t = k}^{t-1 } { \\mathbb{p}}\\bigl\\ { \\mu^{\\dagger}\\geq u_{a^\\star}(t ) \\bigr\\}}_{o(\\log t ) } + \\ , 2 .",
    "\\nonumber\\end{aligned}\\ ] ] theorems  [ thmklucb ] and  [ thmklempucb ] are instances of this general bound providing nonasymptotic controls for @xmath132 $ ] in the two settings considered in this paper .",
    "we consider in this section the case when @xmath2 is a canonical exponential family of probability distributions @xmath133 , indexed by @xmath134 ; that is , the distributions @xmath135 are absolutely continuous with respect to a dominating measure @xmath136 on @xmath17 , with probability density @xmath137 we assume in addition that @xmath138 is twice differentiable .",
    "we also assume that @xmath139 is the natural parameter space , that is , the set @xmath140 and that the exponential family @xmath2 is regular , that is , that @xmath141 is an open interval ( an assumption that turns out to be true in all the examples listed below ) . in this",
    "setting , considered in the pioneering papers by @xcite and @xcite , the upper confidence bound defined in ( [ equcbdef ] ) takes an explicit form related to the large deviation rate function .",
    "indeed , as soon as the reward distributions satisfy chernoff - type inequalities , these can be used to construct an ucb policy , while for heavy - tailed distributions other approaches are required , as surveyed by @xcite .    for a thorough introduction to canonical exponential families , as well as proofs of the following properties ,",
    "the reader is referred to @xcite .",
    "the derivative @xmath142 of @xmath143 is an increasing continuous function such that @xmath144 for all @xmath134 ; in particular , @xmath143 is strictly convex .",
    "thus , @xmath142 is one - to - one with a continuous inverse @xmath145 and the distributions @xmath133 of @xmath2 can also be parameterized by their expectations @xmath146 . defining the open interval of all expectations , @xmath147",
    ", there exists a unique distribution of @xmath2 with expectation @xmath148 , namely , @xmath149 .",
    "the kullback ",
    "leibler divergence between two distributions @xmath150 is given by @xmath151 which , writing @xmath152 and @xmath153 , can be reformulated as @xmath154\\\\[-8pt ] & = & \\bigl ( \\dot{b}^{-1}(\\mu)- \\dot{b}^{-1 } \\bigl(\\mu ' \\bigr ) \\bigr ) \\mu- b \\bigl ( \\dot{b}^{-1}(\\mu )",
    "\\bigr ) + b \\bigl ( \\dot{b}^{-1 } \\bigl ( \\mu ' \\bigr ) \\bigr).\\nonumber\\end{aligned}\\ ] ] this defines a divergence @xmath155 that inherits from the kullback ",
    "leibler divergence the property that @xmath156 if and only if @xmath157 .",
    "in addition , @xmath158 is ( strictly ) convex and differentiable over @xmath159 .    as the examples below of specific canonical exponential families illustrate , the closed - form expression for this re - parameterized kullback ",
    "leibler divergence is usually simple .",
    "@xmath160 , @xmath161 , @xmath162 , @xmath163 , @xmath164 the case @xmath165 corresponds to bernoulli distributions .",
    "@xmath166 , @xmath161 , @xmath167 , @xmath168 , @xmath169    @xmath170 , @xmath171 , @xmath172 , @xmath173 , @xmath174 the case @xmath175 corresponds to geometric distributions .",
    "@xmath176 , @xmath161 , @xmath177 , @xmath178 , @xmath179    @xmath180 , @xmath181 , @xmath182 , @xmath173 , @xmath183 the case @xmath184 corresponds to exponential distributions .    for all @xmath185 the convex functions @xmath186 and @xmath187",
    "can be extended by continuity to @xmath188 $ ] as follows : @xmath189 with similar statements for the second function .",
    "note that these limits may equal @xmath190 ; the extended function @xmath191 $ ] is still a convex function . by convention",
    ", we also define @xmath192 .",
    "note that our exponential family models are minimal in the sense of wainwright and jordan [ ( @xcite ) , section 3.2 ] and thus that @xmath193 coincides with the interior of the set of realizable expectations for all distributions that are absolutely continuous with respect to @xmath136 ; see @xcite , theorem 3.3 and appendix  b. in particular , this implies that distributions in @xmath2 have supports in @xmath194 and that , consequently , the empirical means @xmath35 are in @xmath194 for all @xmath0 and @xmath33 .",
    "( note , however , that they may not be in @xmath193 itself : think in particular of the case of bernoulli distributions when @xmath33 is small . )      as the distributions in @xmath2 can be parameterized by their expectation , @xmath70 associates with each @xmath195 such that @xmath196 the distribution @xmath197 which has the same expectation . as shown above , for all @xmath198",
    ", it then holds that @xmath199 ; and this equality can be extended to the case where @xmath200 . in this",
    "setting , sufficient statistics for @xmath35 and @xmath36 are given by , respectively , @xmath201 where the former is defined as soon as @xmath202 .",
    "the upper - confidence bound @xmath74 may be defined in this model not only in terms of @xmath2 but also of its `` boundaries , '' namely , in terms of @xmath194 and not only @xmath193 , as @xmath203 this supremum is achieved : in the case when @xmath204 , this follows from the fact that @xmath158 is continuous on @xmath205 ; when @xmath206 , this is because @xmath207 ; in the case when @xmath208 , either @xmath209 is the only @xmath210 for which @xmath211 is finite , or @xmath212 is convex thus continuous on the open interval where it is finite .",
    "thus , in the setting of this section , algorithm  [ algklucb ] rewrites as algorithm  [ algklucb ] , which will be referred to as ` kl - ucb ` .",
    "_ parameters _ : a nondecreasing function @xmath213 + _ initialization _ : pull each arm of @xmath69 once +    in practice , the computation of @xmath74 boils down to finding the zero of an increasing and convex scalar function .",
    "this can be done either by dichotomic search or by newton iterations . in all the examples given above , well - known inequalities ( e.g. , hoeffding s inequality )",
    "may be used to obtain an initial upper bound on  @xmath74 .      in this parametric context",
    "we have @xmath214 when @xmath196 and @xmath185 . in light of the results by @xcite and @xcite ,",
    "the following theorem thus proves the asymptotic optimality of the ` kl - ucb ` algorithm .",
    "moreover , it provides an explicit , nonasymptotic bound on the regret .",
    "[ thmklucb ] assume that all arms belong to a canonical , regular , exponential family @xmath215 of probability distributions indexed by its natural parameter space @xmath216 .",
    "then , using algorithm  [ algklucb ] with the divergence @xmath158 given in ( [ eqklexpfam ] ) and with the choice @xmath217 for @xmath218 and @xmath219 , the number of draws of any suboptimal arm @xmath0 is upper bounded for any horizon @xmath220 as @xmath221 & \\leq&\\frac{\\log(t)}{d ( \\mu_a,\\mu^\\star ) } + 2\\sqrt { \\frac{2\\pi\\sigma_{a,\\star}^2 ( { d'}(\\mu_a , \\mu^\\star ) ) ^2 } { ( d(\\mu_a,\\mu^\\star ) ) ^3 } } { \\sqrt{\\log(t ) + 3\\log \\bigl(\\log ( t ) \\bigr ) } } \\\\ & & { } + \\biggl(4e + \\frac{3}{d(\\mu_a,\\mu^\\star ) } \\biggr)\\log \\bigl(\\log(t ) \\bigr ) + 8 \\sigma_{a,\\star}^2 \\biggl ( \\frac{d'(\\mu_a,\\mu^\\star)}{d(\\mu _ a,\\mu^\\star ) } \\biggr)^2 + 6,\\end{aligned}\\ ] ] where @xmath222 and where @xmath223 denotes the derivative of @xmath224 .",
    "the proof of this theorem is provided in the supplemental article [ @xcite , appendix a ] .",
    "a key argument , proved in lemma 2 ( see also lemma 11 ) , is the following deviation bound for the empirical mean with random number of summands : for all @xmath225 and all @xmath226 , @xmath227    for binary distributions , guarantees analogous to that of theorem [ thmklucb ] have been obtained recently for algorithms inspired by the bayesian paradigm , including the so - called @xcite sampling strategy , which is not an index policy in the sense of @xcite ; see @xcite and @xcite .",
    "in this section , @xmath2 is the set @xmath228 of finitely supported probability distributions over @xmath229 $ ] . in this case",
    ", the empirical measures @xmath230 belong to @xmath228 and hence the operator @xmath70 is taken to be the identity .",
    "we denote by @xmath231 the finite support of an element @xmath232 .",
    "the maximization program ( [ equcbdef ] ) defining @xmath74 admits in this case the simpler formulation @xmath233 which admits an explicit computational solution ; these two points are detailed in the supplemental article [ @xcite , appendix c.1 ] . the reasons for which the value 1 needs to be added to the support ( if it is not yet present ) will be detailed in section  [ secklucbgeneral ] .",
    "thus algorithm  [ algklucb ] takes the following simpler form , which will be referred to as the empirical ` kl - ucb ` algorithm .    like",
    "the ` dmed ` algorithm , for which asymptotic bounds are proved in honda and takemura ( @xcite ) , algorithm  [ algklucb ] relies on the empirical likelihood method [ see @xcite ] for the construction of the confidence bounds .",
    "however , ` dmed ` is not an index policy , but it maintains a list of active arms  an approach that , generally speaking , seems to be less satisfactory and slightly less efficient in practice . besides , the analyses of the two algorithms , even though they both rely on some technical properties of the function @xmath14 , differ significantly .",
    "_ parameters _ : a nondecreasing function @xmath234 + _ initialization _ : pull each arm of @xmath69 once +    [ thmklempucb ] assume that @xmath235 for all arms @xmath0 and that @xmath236",
    ". there exists a constant @xmath237 only depending on @xmath1 and @xmath7 such that , with the choice @xmath238 for @xmath239 , the expected number of times that any suboptimal arm @xmath0 is pulled by algorithm  [ algklempucb ] is smaller , for all @xmath240 , than @xmath109 & \\leq & \\frac{\\log(t)}{{\\mathcal{k}}_{\\inf } ( \\nu _ a,\\mu^\\star ) } + \\frac{36}{(\\mu^\\star)^4 } \\bigl ( \\log(t ) \\bigr)^{4/5 } \\log \\bigl(\\log(t ) \\bigr ) \\\\ & & { } + \\biggl ( \\frac{72}{(\\mu^\\star)^4 } + \\frac{2\\mu^\\star } { ( 1-\\mu^\\star ) { \\mathcal{k}}_{\\inf } ( \\nu_a,\\mu^\\star)^2 } \\biggr ) \\bigl ( \\log(t ) \\bigr)^{4/5 } \\\\ & & { } + \\frac{(1-\\mu^\\star)^2 m(\\nu_a,\\mu^\\star)}{2(\\mu^\\star)^2 } \\bigl ( \\log(t ) \\bigr)^{2/5 } \\\\ & & { } + \\frac{\\log(\\log(t ) ) } { { \\mathcal{k}}_{\\inf } ( \\nu_a,\\mu^\\star ) } + \\frac{2\\mu^\\star}{(1-\\mu^\\star ) { \\mathcal{k}}_{\\inf } ( \\nu_a,\\mu^\\star ) ^2 } + 4.\\end{aligned}\\ ] ]    theorem  [ thmklempucb ] implies a nonasymptotic bound of the form @xmath241 \\leq\\frac{\\log(t)}{{\\mathcal{k}}_{\\inf } ( \\nu _ a,\\mu^\\star ) } + o \\bigl ( \\bigl ( \\log(t ) \\bigr)^{4/5 } \\log \\bigl(\\log(t ) \\bigr ) \\bigr).\\ ] ] the exact value of the constant @xmath242 is provided in the proof of theorem  [ thmklempucb ] , which can be found in the supplemental article [ @xcite , appendix b ] ; see , in particular , section b.3 as well as the variational form of @xmath14 introduced in lemma 4 of section b.1 of the supplement .",
    "in this section , we consider the case where the arms are only known to have bounded distributions . as in section  [ secklemp ] , we assume without loss of generality that the rewards are bounded in @xmath243 $ ] .",
    "this is the setting considered by @xcite , where the ` ucb ` algorithm was described and analyzed .",
    "we first prove that ` kl - ucb ` ( algorithm  [ algklucb ] ) with kullback ",
    "leibler divergence for bernoulli distributions is always preferable to ` ucb ` , in the sense that a smaller finite - time regret bound is guaranteed . `",
    "ucb ` is indeed nothing but ` kl - ucb ` with quadratic divergence and we obtain a refined analysis of ` ucb ` as a consequence of theorem  [ thmklucb ] .",
    "we then discuss the use of the empirical ` kl - ucb ` approach , in which one directly applies algorithm  [ algklempucb ] .",
    "we provide preliminary results to support the observation that empirical ` kl - ucb ` achieves improved performance on sufficiently long horizons ( see simulation results in section  [ secexpnum ] ) , at the price , however , of a significantly higher computational complexity .",
    "a careful reading of the proof of theorem  [ thmklucb ] ( see the supplemental article [ @xcite , section  a ] ) shows that ` kl - ucb ` enjoys regret guarantees in models with arbitrary bounded distributions @xmath9 over @xmath243 $ ] as long as it is used with a divergence @xmath158 over @xmath243 ^ 2 $ ] satisfying the following double property : there exists a family of strictly convex and continuously differentiable functions @xmath244 , indexed by @xmath245 $ ] , such that first , @xmath246 is the convex conjugate of @xmath247 for all @xmath245 $ ] ; and , second , the domination condition @xmath248 for all @xmath249 and all @xmath250 ) $ ] holds , where @xmath251 denotes the moment - generating function of @xmath9 , @xmath252 } e^{\\lambda x } \\,{\\mathrm{d}}\\nu(x).\\ ] ]    the following elementary lemma dates back to @xcite ; it upper bounds the moment - generating function of any probability distribution over @xmath243 $ ] with expectation @xmath10 by the moment - generating function of the bernoulli distribution with parameter @xmath10 , which is further bounded by the moment - generating function of the normal distribution with mean @xmath10 and variance @xmath253 .",
    "all these moment - generating functions are defined on the whole real line @xmath17 . in light of the above",
    ", it thus shows that the kullback ",
    "leibler divergence @xmath254 between bernoulli distributions and the kullback  leibler divergence @xmath255 between normal distributions with variance @xmath253 are adequate candidates for use in the ` kl - ucb ` algorithm in the case of bounded distributions .",
    "[ lembounded2bernoulli ] let @xmath256 ) $ ] and let @xmath257 .",
    "then , for all @xmath249 , @xmath258 } e^{\\lambda x } \\,{\\mathrm{d}}\\nu(x ) \\leq1-\\mu+ \\mu\\exp(\\lambda ) \\leq\\exp \\bigl ( \\lambda \\mu+ 2\\lambda^2 \\bigr).\\ ] ]    the proof of this lemma is straightforward ; the first inequality is by convexity , as @xmath259 for all @xmath260 $ ] , and the second inequality follows by standard analysis .    we therefore have the following corollaries to theorem [ thmklucb ] .",
    "( they are obtained by bounding in particular the variance term @xmath261 by @xmath253 . )    [ thborneregretklucb ] consider a bandit problem with rewards bounded in @xmath243 $ ] .",
    "choosing the parameters @xmath262 for @xmath263 and @xmath219 , and @xmath264 in algorithm  [ algklucb ] , the number of draws of any suboptimal arm @xmath0 is upper bounded for any horizon @xmath240 as @xmath221 & \\leq&\\frac{\\log(t)}{d_{{\\mathrm{ber}}}(\\mu_a,\\mu ^\\star ) } \\\\ & & { } + \\frac{\\sqrt{2\\pi } \\log({\\mu^ \\star(1-\\mu_a)}/({\\mu_a(1-\\mu ^\\star ) } ) ) } { ( d_{{\\mathrm{ber}}}(\\mu_a,\\mu^\\star ) ) ^{3/2 } } { \\sqrt{\\log(t ) + 3\\log \\bigl(\\log(t ) \\bigr ) } } \\\\ & & { } + \\biggl(4e + \\frac{3}{d_{{\\mathrm{ber}}}(\\mu_a,\\mu^\\star ) } \\biggr ) \\log \\bigl(\\log(t ) \\bigr)\\\\ & & { } + \\frac{2 ( \\log({\\mu^ \\star(1-\\mu_a)}/({\\mu_a(1-\\mu^\\star ) } ) ) ) ^2 } { ( d_{{\\mathrm{ber}}}(\\mu_a,\\mu^\\star ) ) ^2 } + 6.\\end{aligned}\\ ] ]    we denote by @xmath265 the upper bound on @xmath251 exhibited in lemma [ lembounded2bernoulli ] .",
    "standard results on kullback ",
    "leibler divergences are that for all @xmath266 $ ] and all @xmath267 ) $ ] , @xmath268 see massart [ ( @xcite ) , pages 21 and 28 ] ; see also @xcite .",
    "because of lemma  [ lembounded2bernoulli ] , it thus holds that for all distributions @xmath269 ) $ ] , @xmath270 and it follows that in the model @xmath271 ) $ ] one has @xmath272 as expected , the ` kl - ucb ` algorithm may not be optimal for all sub - families of bounded distributions . yet , this algorithm has stronger guarantees than the ` ucb ` algorithm .",
    "it is readily checked that the latter exactly corresponds to the choice of @xmath273 in algorithm  [ algklucb ] together with some nondecreasing function @xmath71 .",
    "for instance , the original algorithm ` ucb1 ` of auer , cesa - bianchi and fischer [ ( @xcite ) , theorem 1 ] , relies on @xmath274 .",
    "the analysis derived in this paper gives an improved analysis of the performance of the ` ucb ` algorithm by resorting to the function @xmath71 described in the statement of theorem  [ thmklucb ] .",
    "[ corucb ] consider the _ `",
    "kl - ucb ` _ algorithm with @xmath255 and the function @xmath71 defined in theorem  [ thmklucb ] , or equivalently , the _ ` ucb ` _ algorithm tuned as follows : at step @xmath275 , an arm maximizing the upper - confidence bounds @xmath276 is chosen .",
    "then the number of draws of a suboptimal arm @xmath0 is upper bounded as @xmath221 & \\leq&\\frac{\\log(t)}{2(\\mu^\\star- \\mu _ a)^2 } + \\frac { 2 \\sqrt{\\pi } } { ( \\mu^\\star-\\mu_a ) ^2 } { \\sqrt{\\log(t ) + 3\\log \\bigl(\\log(t ) \\bigr ) } } \\\\ & & { } + \\biggl(4e + \\frac{3}{2(\\mu^\\star-\\mu_a)^2 } \\biggr)\\log \\bigl(\\log(t ) \\bigr ) + \\frac{8}{(\\mu^\\star-\\mu_a)^2 } + 6.\\end{aligned}\\ ] ]    as claimed , it can be checked that the leading term in the bound of corollary  [ thborneregretklucb ] is smaller than the one of corollary [ corucb ] by applying pinsker s inequality @xmath277 .",
    "the bound obtained in corollary  [ corucb ] above also improves on the one of auer , cesa - bianchi and fischer [ ( @xcite ) , theorem  1 ] , and it is `` optimal '' in the sense that the constant @xmath278 in the logarithmic term can not be improved . note that a constant in front on the leading term of the regret bound is proven to be arbitrarily close to ( but strictly greater than ) @xmath278 for the ` ucb2 ` algorithm of @xcite , when the parameter @xmath279 goes to @xmath280 as the horizon grows , but then other terms are unbounded . in comparison ,",
    "corollary  [ corucb ] provides a bound for ` ucb ` with a leading optimal constant @xmath278 , and all the remaining terms of the bound are finite and made explicit .",
    "note , in addition , that the choice of the parameter  @xmath279 , which drives the length of the phases during which a single arm is played , is important but difficult in practice , where ` ucb2 ` does not really prove more efficient than ` ucb ` .",
    "the justification of the use of empirical ` kl - ucb ` for general bounded distributions @xmath281)$ ] relies on the following result .",
    "the empirical - likelihood ( or el in short ) method provides a way to construct confidence bounds for the true expectation of i.i.d .",
    "observations ; for a thorough introduction to this theory , see @xcite .",
    "we only recall briefly its principle . given a sample @xmath282 of an unknown distribution @xmath283 , and denoting @xmath284 the empirical distribution of this sample , an el upper - confidence bound for the expectation @xmath285 of @xmath283 is given by @xmath286 where @xmath287 is a parameter controlling the confidence level .",
    "an apparent impediment to the application of this method in bandit problems is the impossibility of obtaining nonasymptotic guarantees for the covering probability of el upper - confidence bounds .",
    "in fact , it appears in ( [ eqsel ] ) that @xmath288 necessarily belongs to the convex envelop of the observations .",
    "if , for example , all the observations are equal to @xmath280 , then @xmath289 is also equal to @xmath280 , no matter what the value of @xmath290 is ; therefore , it is not possible to obtain upper - confidence bounds for all confidence levels .    in the case of ( upper-)bounded variables ,",
    "this problem can be circumvented by adding to the support of @xmath291 the maximal possible value . in our case , instead of considering @xmath289 , one should use @xmath292 this idea was introduced in honda and takemura ( @xcite ) , independently of the el literature .",
    "the following guarantee can be obtained ; its proof is provided in the supplemental article [ @xcite , section  c.2 ] .",
    "[ propcovel]@xmath293 let @xmath294)$ ] with @xmath295 and let @xmath282 be independent random variables with common distribution @xmath296 ) $ ] , not necessarily with finite support .",
    "then , for all @xmath297 , @xmath298 where @xmath14 is defined in terms of the model @xmath299 .    for @xmath300-valued observations",
    ", it is readily seen that @xmath301 boils down to the upper - confidence bound given by ( [ equcbexp ] ) .",
    "this example and some numerical simulations suggest that the above proposition is not ( always ) optimal : the presence of the factor @xmath34 in front of the exponential @xmath302 term is indeed questionable .",
    "the analysis of empirical ` kl - ucb ` in the case where the arms are associated with general bounded distributions is a work in progress . in view of proposition  [ propcovel ] and of the discussion above",
    ", it is only the proof of fact that needs to be extended .    as a preliminary result",
    ", we can prove an asymptotic regret bound , which is indeed optimal , but for a variant of algorithm  [ algklempucb ] ; it consists of playing in regimes @xmath303 of increasing lengths instances of the empirical ` kl - ucb ` algorithm in which the upper confidence bounds are given by @xmath304 where @xmath305 as the index of the regime @xmath303 increases .",
    "the open questions would be to get an optimal bound for algorithm [ algklempucb ] itself , preferably a nonasymptotic one like those of theorems  [ thmklucb ] and  [ thmklempucb ] .",
    "also , a computational issue arises : as the support of each empirical distribution may contain as many points as the number of times the corresponding arm was pulled , the computational complexity of the empirical ` kl - ucb ` algorithm grows , approximately linearly , with the number of rounds .",
    "hence the empirical ` kl - ucb ` algorithm as it stands is only suitable for small to medium horizons ( typically less than ten thousands rounds ) . to reduce the numerical complexity of this algorithm without renouncing to performance",
    ", a possible direction could be to cluster the rewards on adaptive grids that are to be refined over time .",
    "the results of the previous sections show that the ` kl - ucb ` and the empirical ` kl - ucb ` algorithms are efficient not only in the special frameworks for which they were developed , but also for general bounded distributions . in the rest of this section , we support this claim by numerical experiments that compare these methods with competitors such as ` ucb ` and ` ucb - tuned ` [ @xcite ] , ` moss ` [ @xcite ] , ` ucb - v ` [ @xcite ] or ` dmed ` [ honda and takemura ( @xcite ) ] . in these simulations ,",
    "similar confidence levels are chosen for all the upper confidence bounds , corresponding to @xmath306a choice which we recommend in practice . indeed , using @xmath262 or @xmath307 ( with a small @xmath297 )",
    "yields similar conclusions regarding the ranking of the performance of the algorithms , but leads to slightly higher average regrets .",
    "more precisely , the upper - confidence bounds we used were @xmath308 for ` ucb ` , @xmath309 with @xmath310 for ` ucb - v ` and , following @xcite , @xmath311 for ` ucb - tuned ` .",
    "both ` ucb - v ` and ` ucb - tuned ` are expected to improve over ` ucb ` by estimating the variance of the rewards ; but ` ucb - tuned ` was introduced as an heuristic improvement over ` ucb ` ( and does not come with a performance bound ) while ` ucb - v ` was analyzed by @xcite .",
    "different choices of the divergence function @xmath158 lead to different variants of the ` kl - ucb ` algorithm , which are sometimes compared with one another in the sequel . in order to clarify this point ,",
    "we reserve the term ` kl - ucb ` for the variant using the _ binary _ kullback  leibler divergence ( i.e. , between bernoulli distributions ) , while other choices are explicitly specified by their denomination ( e.g. , ` kl - poisson - ucb ` or ` kl - exp - ucb ` for families of poisson or exponential distributions ) . the simulations presented in this section",
    "have been performed using the ` py / mabandits ` package [ @xcite ] , which is publicly available from the ` mloss.org ` website and can be used to replicate these experiments .",
    "we first consider the case of bernoulli rewards , which has a special historical importance and which covers several important practical applications of bandit algorithms ; see @xcite and references therein . with @xmath300-valued rewards and with the binary kullback ",
    "leibler divergence as a divergence function , it is readily checked that the ` kl - ucb ` algorithm coincides exactly with empirical ` kl - ucb ` .",
    "region and the upper @xmath312 quantile . ]    in figure  [ fig10 ] we consider a difficult scenario , inspired by a situation ( frequent in applications like marketing or internet advertising ) where the mean reward of each arm is very low . in our scenario , there are ten arms : the optimal arm has expected reward @xmath313 , and the nine suboptimal arms consist of three different groups of three ( stochastically ) identical arms , each with respective expected rewards @xmath314 , @xmath315 and @xmath316",
    ". we resorted to @xmath317 simulations to obtain the regret plots of figure  [ fig10 ] .",
    "these plots show , for each algorithm , the average cumulated regret together with quantiles of the cumulated regret distribution as a function of time ( on a logarithmic scale ) .    here , there is a huge gap in performance between ` ucb ` and ` kl - ucb ` .",
    "this is explained by the fact that the variances of all reward distributions are much smaller than @xmath253 , the pessimistic upper bound used in hoeffding s inequality ( i.e. , in the design of ` ucb ` ) . the gain in performance of `",
    "ucb - tuned ` is not very significant . `",
    "kl - ucb ` and ` dmed ` reach a performance that is on par with the lower bound ( [ eqbinfregret ] ) of @xcite ( shown in strong dashed line ) ; the performance of ` kl - ucb ` is somewhat better than the one of ` dmed ` .",
    "notice that for the best methods , and in particular for ` kl - ucb ` , the mean regret is below the lower bound , even for larger horizons , which reveals and illustrates the asymptotic nature of this bound .",
    "in this second scenario , we consider @xmath318 arms with truncated poisson distributions .",
    "more precisely , each arm @xmath319 is associated with @xmath1 , a poisson distribution with expectation @xmath320 , truncated at @xmath321 .",
    "the experiment consisted of @xmath322 monte carlo replications on an horizon of @xmath323 steps . note that the truncation does not alter much the distributions here , as the probability of draws larger than @xmath321 is small for all arms .",
    "in fact , the role of this truncation is only to provide an explicit upper bound on the possible rewards , which is required for most algorithms .",
    "figure  [ figtruncpoisson ] shows that , in this case again , the ` ucb ` algorithm is significantly worse than some of its competitors .",
    "the ` ucb - v ` algorithm , which appears to have a larger regret on the first @xmath324 steps , progressively improves thanks to its use of variance estimates for the arms .",
    "but the horizon @xmath323 is ( by far ) not sufficient for ` ucb - v ` to provide an advantage over ` kl - ucb ` , which is thus seen to offer an interesting alternative even in nonbinary cases .",
    "these three methods , however , are outperformed by the ` kl - poisson - ucb ` algorithm : using the properties of the poisson distributions ( but not taking truncation into account , however ) , this algorithm achieves a regret that is about ten times smaller . in - between stands the empirical ` kl - ucb ` algorithm ; it relies on nonparametric empirical - likelihood - based upper bounds and is therefore distribution - free as explained in section  [ secklucbgeneral ] , yet , it proves remarkably efficient .      in the third and last example",
    ", there are @xmath325 arms associated with continuous distributions : the rewards are exponential variables , with respective parameters @xmath326 , @xmath253 , @xmath327 , @xmath278 and @xmath28 , truncated at @xmath328 ( i.e. , they are bounded in @xmath329 $ ] ) .",
    "figure  [ figeb5 ] shows that in this scenario , ` ucb ` and ` moss ` are clearly suboptimal .",
    "this time , the ` kl - ucb ` does not provide a significant improvement over ` ucb ` as the expectations of the arms are not particularly close to @xmath280 or to @xmath328 ; hence the confidence intervals computed by ` kl - ucb ` are close to those used by ` ucb ` .",
    ", by estimating the variances of the distributions of the rewards , which are much smaller than the variances of @xmath330-valued distributions with the same expectations , would be expected to perform significantly better . but here again , ` ucb - v ` is not competitive , at least for a horizon @xmath323 .",
    "this can be explained by the fact that the upper confidence bound of any suboptimal arm @xmath0 , as stated in  ( [ equcbv ] ) , contains a residual term @xmath331 ; this term is negligible in common applications of bernstein s inequality , but it does not vanish here because @xmath332 is precisely of order @xmath333 ; see also @xcite for further discussion of this issue .",
    "the ` kl - exp - ucb ` algorithm uses the divergence @xmath334 prescribed for genuine exponential distributions , but it ignores the fact that the rewards are truncated .",
    "however , contrary to the previous scenario , the truncation has an important effect here , as values larger than @xmath321 are relatively probable for each arm . because ` kl - exp - ucb ` is not aware of the truncation , it uses upper bounds that are slightly too large ; however , the performance is still excellent and stable , and the algorithm is particularly simple .",
    "but the best - performing algorithm in this case is the nonparametric algorithm , empirical ` kl - ucb ` .",
    "this method appears to reach here the best compromise between efficiency and versatility , at the price of a larger computational complexity .",
    "the ` kl - ucb ` algorithm is a quasi - optimal method for multi - armed bandits whenever the distributions associated with the arms are known to belong to a simple parametric family . for each one - dimensional exponential family ,",
    "a specific divergence function has to be used in order to achieve the lower bound ( [ eqbinfregret ] ) of @xcite .",
    "however , the binary kullback  leibler divergence plays a special role : it is a conservative , universal choice for bounded distributions .",
    "the resulting algorithm is versatile , fast and simple and proves to be a significant improvement , both in theory and in practice , over the widely used ` ucb ` algorithm .",
    "the more elaborate ` kl - ucb ` algorithm relies on nonparametric inference , by using the so - called empirical likelihood method .",
    "it is optimal if the distributions of the arms are only known to be bounded ( with a known upper bound ) and finitely supported . for general bounded arms ,",
    "the empirical - likelihood - based upper confidence bounds , which are the core of the algorithm , still have an adequate level , but obtaining explicit finite - time regret bounds for the algorithm itself and/or reducing its computational complexity is still the object of further investigations ; see the discussion in section  [ secklucbgeneral ] .",
    "the simulation results show that empirical ` kl - ucb ` is efficient in general cases when the distributions are far from being members of simple parametric families .    in a nutshell ,",
    "empirical ` kl - ucb ` is to be preferred when the distributions of the arms are not known to belong ( or be close ) to a simple parametric family and when the ` kl - ucb ` algorithm is know not to get satisfactory performance ",
    "that is , for instance , when the variance of a @xmath243$]-valued arm with expectation @xmath10 is much smaller than @xmath335 ."
  ],
  "abstract_text": [
    "<S> we consider optimal sequential allocation in the context of the so - called stochastic multi - armed bandit model . </S>",
    "<S> we describe a generic index policy , in the sense of gittins [ _ j . </S>",
    "<S> r. stat . </S>",
    "<S> soc . </S>",
    "<S> ser . </S>",
    "<S> b stat . </S>",
    "<S> methodol . _ </S>",
    "<S> * 41 * ( 1979 ) 148177 ] , based on upper confidence bounds of the arm payoffs computed using the kullback  </S>",
    "<S> leibler divergence . </S>",
    "<S> we consider two classes of distributions for which instances of this general idea are analyzed : the ` kl - ucb ` algorithm is designed for one - parameter exponential families and the empirical ` kl - ucb ` algorithm for bounded and finitely supported distributions . </S>",
    "<S> our main contribution is a unified finite - time analysis of the regret of these algorithms that asymptotically matches the lower bounds of lai and robbins [ _ adv . in appl . </S>",
    "<S> math . </S>",
    "<S> _ * 6 * ( 1985 ) 422 ] and burnetas and katehakis [ _ adv . in appl . </S>",
    "<S> math . </S>",
    "<S> _ * 17 * ( 1996 ) 122142 ] , respectively . </S>",
    "<S> we also investigate the behavior of these algorithms when used with general bounded rewards , showing in particular that they provide significant improvements over the state - of - the - art .    ,    ,    , </S>"
  ]
}