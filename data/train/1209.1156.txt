{
  "article_text": [
    "regression analysis is one of the most important tools used to investigate the relationship between a response @xmath3 and a predictor @xmath4 .",
    "many major studies of regression have been concerned with the estimation of the conditional mean function of @xmath3 given a predictor @xmath5 .",
    "on the other hand , the estimation of the conditional quantile function of @xmath3 given @xmath6 has gained momentum in recent years .",
    "this analysis is called quantile regression . in quantile regression ,",
    "the purpose is to estimate an unknown function @xmath7 that satisfies @xmath8 for a given @xmath1 .",
    "when @xmath9 , @xmath7 is the conditional median of @xmath3 .",
    "one established advantage of quantile regression as compared to mean regression is that the estimators are more robust against outliers in the response measurements .",
    "quantile regression models have been suggested by koenker and bassett ( 1978 ) .",
    "many authors have studied quantile regression based on the parametric method , its asymptotic theories , the computational aspects and other properties , and these developments have been summarized by koenker ( 2005 ) and hao and naiman ( 2007 ) .",
    "the nonparametric methods for quantile regression have also been studied extensively .",
    "many authors have explored the topic in relation to kernel methods , including fan et al .",
    "( 1994 ) , yu and jones ( 1998 ) , takeuchi et al .",
    "( 2006 ) , kai et al .",
    "( 2011 ) . on the other hand , hendricks and koenker ( 1992 ) and koenker et al .",
    "( 1994 ) used the low - rank regression splines method and the smoothing splines method , respectively .",
    "pratesi et al .",
    "( 2009 ) and reiss and huang ( 2012 ) utilized the penalized spline smoothing method .",
    "this paper focuses on penalized splines .",
    "compared with unpenalized splines and smoothing splines , an advantage of the penalized spline methods is follows .",
    "although the smoothing spline estimator gives the predictor with fitness and smoothness , the computational cost to construct the estimator is high . in unpenalized regression spline methods , on the other hand",
    ", it is known that the estimator tends to have a wiggle curve , but the computational cost is lower than that of smoothing spline methods .",
    "the penalized spline estimator , however , gives the curve with fitness and smoothness and its computational cost is lower than that of smoothing spline methods .",
    "thus , penalized splines can be considered an efficient technique .",
    "previous results of asymptotic studies of nonparametric quantile regressions include the following .",
    "fan et al .",
    "( 1994 ) showed the asymptotic normality of the kernel estimator .",
    "yu and jones ( 1998 ) proposed a new kernel estimator and studied its asymptotic results .",
    "he and shi ( 1994 ) showed the convergence rate of the unpenalized regression spline estimator .",
    "portnoy ( 1997 ) discussed asymptotics for smoothing spline estimators .",
    "however , the asymptotics for the penalized spline estimator of quantile regression have not yet been studied .    in this paper",
    ", we show the asymptotic distribution of the penalized spline estimator for quantile regression with a low - rank @xmath2-spline model and the difference penalty .",
    "the penalized spline estimator of @xmath7 for a given @xmath0 is defined as the minimizer of the convex loss function , which is the check function @xmath10 with an additional difference penalty . to establish the asymptotic distribution of the penalized spline estimator",
    ", we need to derive two biases ( i ) the model bias between the true function @xmath7 and the @xmath2-spline model , and ( ii ) the bias arising from using the penalty term . by showing the asymptotic form of these two biases , the resulting asymptotic bias of the penalized spline estimator can be obtained .",
    "finally , together with the asymptotic variance of the estimator , we show the asymptotic normality of the penalized spline quantile estimator .    this paper is organized as follows . in section 2 ,",
    "we define the penalized spline quantile estimator for a given @xmath0 . in terms of our estimation method , we mainly focus on the penalized iteratively reweighted least squares method .",
    "section 3 provides the asymptotic bias and variance as well as the asymptotic distribution of the penalized spline quantile estimator .",
    "furthermore , the related properties are described . in section 4 ,",
    "numerical studies are conducted .",
    "related discussion and issues for future research are provided in section 5 .",
    "finally , proofs for the theoretical results are all given in the appendix .",
    "for a given dataset @xmath11 , consider the conditional @xmath12 quantile of response @xmath13 given @xmath14 as @xmath15 where @xmath1 and @xmath16 is an unknown true conditional quantile function of @xmath13 given @xmath14 .",
    "it is easy to show that the true function satisfies @xmath17.\\end{aligned}\\ ] ] here , @xmath10 is the check function provided by koenker and bassett ( 1978 ) , given as @xmath18 where @xmath19 is the indicator function of @xmath20 .",
    "we want to estimate @xmath7 using penalized spline methods . to approximate @xmath7",
    ", we consider the @xmath2-spline model @xmath21}(x)b_k(\\tau),\\end{aligned}\\ ] ] where @xmath22}(x)(k =- p+1,\\cdots , k)$ ] are the @xmath23th degree @xmath2-spline basis functions defined recursively as @xmath24}(x)&= & \\left\\ { \\begin{array}{cc } 1 , & \\kappa_{k-1}<x\\leq \\kappa_k,\\\\ 0 , & { \\rm otherwise } , \\end{array } \\right .",
    "\\\\ b_k^{[p]}(x)&=&\\frac{x-\\kappa_{k-1}}{\\kappa_{k+p-1}-\\kappa_{k-1}}b_k^{[p-1]}(x)+\\frac{\\kappa_{k+p}-x}{\\kappa_{k+p}-\\kappa_{k}}b_{k+1}^{[p-1]}(x),\\end{aligned}\\ ] ] where @xmath25 are knots and @xmath26 are unknown parameters .",
    "we denote @xmath22}(x)$ ] as @xmath27 unless the degrees of @xmath2-splines are specified .",
    "details and many properties of the b - spline function are clarified by de boor ( 2001 ) .",
    "the estimator of @xmath28 is defined as @xmath29 where @xmath30 , @xmath31 is the smoothing parameter and @xmath32th matrix @xmath33 is the @xmath34th difference matrix , which is defined as @xmath35 , where @xmath36 for @xmath37 , and 0 for otherwise .",
    "it is well known that the difference penalty in ( [ plsc ] ) is very useful in mean regression and can be regarded as the controller of the smoothness of @xmath38 because we can interpret @xmath39 ( see , eilers and marx ( 1996 ) ) .",
    "although reiss and huang ( 2012 ) used the penalty @xmath40 , this penalty contains an integral and hence the computational difficulty for the resulting estimator grows .",
    "therefore , this paper proposes using @xmath41 as the penalty .",
    "in fact , @xmath42 is obtained via linear - programming methods , such as simplex methods or interior points methods ( see koenker and park ( 1996 ) , koenker ( 2005 ) ) . on the other hand",
    ", it is known that the iteratively reweighted least squares ( irls ) method is a useful in nonparametric quantile regression .",
    "the penalized spline estimator obtained via irls was also studied and detailed by reiss and huang ( 2012 ) .",
    "since irls is important for obtaining the estimator , we now provide the complete algorithm . for a given @xmath43 ,",
    "the @xmath44-steps iterated estimator @xmath45 is defined as follows : @xmath46 where @xmath47 , @xmath48 , @xmath49 $ ] and @xmath50 for small @xmath51 and the initial @xmath52 . as @xmath53 , it can be shown that @xmath54 is approximately equivalent to the minimizer of ( [ plsc ] ) . by using @xmath42 , the penalized spline estimator of @xmath7",
    "is defined as @xmath55}(x)\\hat{b}_k(\\tau)={b}(x)^t\\hat{\\vec{b}}(\\tau).\\end{aligned}\\ ] ]",
    "in this section , we show the asymptotic property of @xmath56 .",
    "then , we assume that the number of knots @xmath57 and smoothing parameter @xmath43 are dependent on @xmath58 , and we write @xmath59 and @xmath60 , respectively . for simplicity , we write @xmath61 . we give some assumptions regarding the asymptotics of the penalized spline quantile estimator . + * assumptions *    1 .   the explanatory @xmath4 is distributed as @xmath62 on @xmath63 $ ] .",
    "the knots for the @xmath2-spline basis are equidistantly located as @xmath64 and the number of knots satisfies @xmath65 .",
    "there exists @xmath66 such that @xmath67<\\infty$ ] .",
    "the order of the difference matrix is @xmath68 .",
    "the smoothing parameter @xmath69 is a positive sequence such that @xmath70 is larger than the maximum eigenvalue of @xmath71 .    to describe the asymptotic form of @xmath56 , we introduce the following symbols and notations .",
    "define the @xmath72th square matrix @xmath73 by @xmath74 and the @xmath72th square matrix @xmath75 as having the @xmath76-component @xmath77 where @xmath78 is the conditional density function of @xmath3 given @xmath5 .",
    "let @xmath79 be a best @xmath80 approximation to the true function @xmath81 , which satisfies @xmath82 where @xmath83 @xmath84 is the indicator function of an interval @xmath85 and @xmath86 is the @xmath23th bernoulli polynomial(see zhou et al .",
    "( 1998 ) ) .",
    "next , we use @xmath87",
    ".    the penalized spline quantile estimator can be decomposed as @xmath88 we investigate the asymptotic distribution of @xmath89 in the following proposition .",
    "[ para ] let @xmath90 .",
    "furthermore suppose @xmath91 and @xmath92 . then under the assumptions , for @xmath93 , as @xmath94 , @xmath95 where @xmath96    the following theorem , which is the main result in this paper , can be obtained straightforwardly from proposition [ para ] .",
    "[ clt ] under the same assumptions as proposition [ para ] , for @xmath93 , as @xmath94 , @xmath97 where @xmath98 and @xmath99 are those given in proposition [ para ] .",
    "* remark 1 * under the same assumption as theorem [ clt ] , the rate of convergence of the mean squared error(mse ) of @xmath56 becomes @xmath100=o(n^{-(2p+2)/(2p+3)}).\\end{aligned}\\ ] ] this rate is the same as that of the penalized spline estimator in mean regression ( see , kauermann et al .",
    "( 2009 ) ) .",
    "* remark 2 * for the unpenalized regression spline quantile estimator , its asymptotic normality is obtained through theorem [ clt ] with @xmath101 .",
    "* remark 3 * when the true quantile function has a polynomial form @xmath102 , @xmath103 is satisfied since the @xmath104th polynomial model can be expressed as the linear combination of the @xmath23th @xmath2-spline bases @xmath105}_{k}:k =- p+1,\\cdots , k_n\\}$](see de boor ( 2001 ) ) .",
    "therefore , in this case , the model bias becomes 0 , indicating that the regression spline quantile estimator is unbiased .",
    "we can definitely show that @xmath106=0 $ ] in the proof of lemma [ lyapnov ] .",
    "* remark 4 * let @xmath107 be independently and identically distributed as the density @xmath108 and assume that @xmath109 and @xmath110 are independent .",
    "consider the data @xmath11 with @xmath111 .",
    "then the conditional @xmath12 quantile of @xmath13 given @xmath14 can be written as @xmath112 , where @xmath113 is the @xmath12 quantile of @xmath110 . for any @xmath1 , @xmath114 , with which @xmath115 is unchanged by @xmath0 .",
    "next , we obtain @xmath116 since @xmath117 is equal to @xmath118 . furthermore , @xmath79 can be written as @xmath119 , where @xmath120 is the best @xmath121 approximation of @xmath122 defined in the same manner as @xmath79 and @xmath123 is a @xmath72 vector with all components equal to 1 .",
    "since all components of @xmath124 are vanishing , for @xmath1 , we have @xmath125 the asymptotic variance of @xmath56 can be written as @xmath126 where @xmath127 when the sample size is sufficiently large under the same assumptions as theorem [ clt ] and @xmath128 , the influences of @xmath0 on @xmath98 and @xmath99 appear only as @xmath129 and @xmath130 , respectively .",
    "in general , if the density of @xmath110 is symmetrical at @xmath131 , the asymptotic bias and variance of @xmath56 are small at @xmath9 .",
    "figure [ exam ] shows @xmath129 and @xmath130 with normal and cauchy distributions .",
    "we observe that @xmath98 and @xmath99 are smallest at @xmath9 . for @xmath99 near @xmath132 or @xmath133 , the effect of @xmath0 becomes small .",
    "( solid ) and @xmath130(dashed ) .",
    "the left panel shows the standard normal distribution and the right panel shows the cauchy distribution with location 0 and scale 0.01.[exam],title=\"fig:\",width=188,height=151 ] ( solid ) and @xmath130(dashed ) .",
    "the left panel shows the standard normal distribution and the right panel shows the cauchy distribution with location 0 and scale 0.01.[exam],title=\"fig:\",width=188,height=151 ]    * remark 5 * claeskens et al .",
    "( 2009 ) studied the asymptotics of penalized spline estimators in mean regression , with the estimator @xmath134 , where @xmath135 is the minimizer of @xmath136 here , @xmath137 and @xmath138 is the smoothing parameter .",
    "they developed the asymptotics for @xmath139 under two scenarios : ( a ) @xmath140 , which as given in their paper is less than 1 , or ( b ) @xmath141 .",
    "assumption 5 of this paper is equal to the condition @xmath142 .",
    "together with the approximation property that @xmath143 , the results of this paper can be regarded as the quantile regression version of theorem 2 ( a ) of claeskens et al .",
    "( 2009 ) .",
    "* remark 6 * to construct the penalized spline estimator of @xmath7 , we can also use the truncated spline @xmath144 as an approximation to @xmath7 , where @xmath145 $ ] , @xmath146 , and @xmath147 is an unknown parameter vector .",
    "pratesi et al .",
    "( 2009 ) obtained the estimator @xmath148 , where @xmath149 is the minimizer of @xmath150 where @xmath138 is the smoothing parameter and @xmath151 $ ] . by the equivalence property between the @xmath2-spline model and truncated model , there exists a @xmath72th square and nonsingular matrix @xmath152 such that @xmath153 .",
    "therefore @xmath154 can be written as @xmath155 where @xmath156 . furthermore ,",
    "the penalty term in ( [ pentr ] ) satisfies from claeskens et al .",
    "( 2009 ) @xmath157 the asymptotic distribution of @xmath148 can be obtained by showing that of @xmath158 , where @xmath159 is the minimizer of @xmath160 then , the asymptotic distribution of @xmath161 can be obtained using theorem [ clt ] under @xmath162 and @xmath163 .",
    "thus , we obtain the asymptotic distribution of the penalized truncated spline quantile estimator .",
    "* remark 7 * under some weakly condition , the local @xmath23th polynomial quantile estimator @xmath164 has an asymptotic order @xmath165=o(n^{-2(p+1)/(2p+3)})\\ ] ] ( see fan et al .",
    "( 1994 ) and ghouch and genton ( 2009 ) ) and , hence , it can be said that the rate of convergence of the @xmath23th @xmath2-spline quantile estimator and the local @xmath23th polynomial quantile estimator are the same .",
    "we note the bias of these estimators with @xmath166 . from fan et al .",
    "( 1994 ) , the asymptotic bias of the local linear quantile estimator is @xmath167 where @xmath168 is the second order kernel function and @xmath169 is the bandwidth . if @xmath170 is equal to @xmath169 , then the difference between @xmath115 and @xmath171 is only @xmath172 it is easy to show that @xmath173 for @xmath174 $ ] , while we have @xmath175 for the gaussian kernel @xmath176 and @xmath177 for the epanechnikov kernel @xmath178",
    ". therefore the bias of the regression spline estimator is smaller than that of the local linear estimator in this situation .",
    "in this section , we show numerical simulation to confirm the performance as well as the asymptotic normality of the penalized spline quantile estimator claimed in theorem [ clt ] .",
    "the explanatory @xmath179 is generated from a uniform distribution on the interval @xmath63 $ ] .",
    "the response @xmath13 is created by @xmath111 , where @xmath180 .",
    "the errors @xmath110 s are independently distributed via ( i ) a normal distribution with mean 0 and variance @xmath181 , ( ii ) an exponential distribution with mean 2 and ( iii ) a cauchy distribution with location 0 and scale 0.01 . in this simulation , to obtain the penalized spline quantile estimator , we use @xmath182 and @xmath183 is given via the generalized approximate cross - validation ( gacv ) discussed by yuan ( 2006 ) . for comparison",
    ", we construct the unpenalized regression spline quantile estimator with linear spline bases(@xmath166 ) and the local linear quantile estimator .",
    "the penalized spline estimator , regression spline estimator , and local linear estimator are denoted as p - cubic , r - linear and l - linear , respectively .",
    "the number of knots of r - linear and the bandwidth of l - linear are given by gacv .",
    "let @xmath184 where @xmath185 and @xmath186 is the estimator for the @xmath187th repetition . for @xmath188 and 0.5 , we calculate the mean integrated squared error ( mise ) .",
    "we then use sample sizes @xmath189 and 1000 and the number of repetitions @xmath190 .",
    "next , from p - cubic , we calculate @xmath191 where @xmath192 @xmath193 $ ] and @xmath194 is the conditional kernel density estimate given @xmath5",
    ". then we construct the density estimate of @xmath195 at @xmath196 and compare with the density of @xmath197 . to obtain @xmath194 and @xmath198 , the normal kernel and the bandwidth discussed by sheather and jones ( 1991 )",
    "are utilized .",
    "[ 0.9 ]    .results of mise for @xmath189 and @xmath199 .",
    "all entries for mise are @xmath200 times their actual values . [",
    "cols=\"^,^,^,^,^,^,^,^,^,^\",options=\"header \" , ]     table 1 shows the mise for @xmath201 and 0.5 . for p - cubic with normal error ,",
    "the performance of the quantile estimator is good even if @xmath202 .",
    "it is well known that the cauchy distribution is a pathological distribution . however , the mise of p - cubic with the cauchy distribution is sufficiently small , indicating that the quantile estimator is robust .",
    "for the boundary @xmath0 , on the other hand , the mise of the estimators is worse than that with interior @xmath0 . for the normal and cauchy models , the median estimator has better behavior than those with @xmath203 and 0.25 . on the other hand , for the exponential model",
    ", the median estimator has a larger mise than @xmath204 with other values of @xmath0 .",
    "the reason for this is that the density @xmath205 of exponential distribution is monotonically decreasing and its peak is at @xmath131 , which leads to many responses @xmath13 s being dropped near @xmath206 with small @xmath0 .",
    "we note the performance of the penalized spline estimator for @xmath207 .",
    "when a normal or cauchy error is used , it appears that the mise of @xmath204 and that of @xmath208 become similar since @xmath209 has a symmetrical density function at @xmath210 . for an exponential error ,",
    "the closer @xmath0 is to 0 , the smaller the mise of @xmath204 will become .",
    "overall , p - cubic has better behavior than r - linear and l - linear .",
    "however , for the exponential distribution and @xmath199 , the mise of l - linear is slightly smaller than that of p - cubic . additionally , the performance of l - linear is slightly superior to that of r - linear .",
    "this indicates that the variance of l - linear is less than that of r - linear ( see remark 7 ) .    in figure [ simu ] ,",
    "the density estimate of @xmath198 for @xmath211 and 0.5 and the density of @xmath197 for each error are illustrated . in all errors",
    ", we can see that the density estimate of @xmath212 becomes close to @xmath197 as @xmath58 increases . for a normal distribution with @xmath199 ,",
    "the density estimate @xmath213 and @xmath197 are similar . in both errors",
    ", we see that the speed of convergence of @xmath213 is faster than that of @xmath214 .",
    "* remark 8 *  we have confirmed the behavior of the penalized splines with @xmath166 ( p - linear ) and the regression splines with @xmath215 ( r - cubic ) though this is not shown in this paper for reasons of space .",
    "the mise of p - linear and r - cubic are similar to the p - cubic and r - linear , respectively .",
    "for spline smoothing , it is generally known that the pair of the ` cubic spline and the second difference penalty are particularly useful in data analysis .",
    "therefore we mainly focused on @xmath182 in this simulation .     for @xmath189(dot - dashed ) and @xmath199(dashed ) , and the density of @xmath197(solid ) .",
    "the left panels are for @xmath211 and the right panels are for @xmath9 .",
    "the upper , middle and bottom panels are for normal , exponential and cauchy errors , respectively . [ simu],title=\"fig:\",width=283,height=188 ]   for @xmath189(dot - dashed ) and @xmath199(dashed ) , and the density of @xmath197(solid ) .",
    "the left panels are for @xmath211 and the right panels are for @xmath9 .",
    "the upper , middle and bottom panels are for normal , exponential and cauchy errors , respectively . [ simu],title=\"fig:\",width=283,height=188 ] +   for @xmath189(dot - dashed ) and @xmath199(dashed ) , and the density of @xmath197(solid ) .",
    "the left panels are for @xmath211 and the right panels are for @xmath9 .",
    "the upper , middle and bottom panels are for normal , exponential and cauchy errors , respectively .",
    "[ simu],title=\"fig:\",width=283,height=188 ]   for @xmath189(dot - dashed ) and @xmath199(dashed ) , and the density of @xmath197(solid ) .",
    "the left panels are for @xmath211 and the right panels are for @xmath9 .",
    "the upper , middle and bottom panels are for normal , exponential and cauchy errors , respectively . [ simu],title=\"fig:\",width=283,height=188 ] +   for @xmath189(dot - dashed ) and @xmath199(dashed ) , and the density of @xmath197(solid ) .",
    "the left panels are for @xmath211 and the right panels are for @xmath9 .",
    "the upper , middle and bottom panels are for normal , exponential and cauchy errors , respectively . [ simu],title=\"fig:\",width=283,height=188 ]   for @xmath189(dot - dashed ) and @xmath199(dashed ) , and the density of @xmath197(solid ) .",
    "the left panels are for @xmath211 and the right panels are for @xmath9 .",
    "the upper , middle and bottom panels are for normal , exponential and cauchy errors , respectively . [ simu],title=\"fig:\",width=283,height=188 ]      in this section , we apply the penalized spline quantile estimator to real data . in all examples ,",
    "we use @xmath182 and @xmath183 is chosen via gacv .",
    "figure [ bmd ] showed the penalized spline quantile estimators ( @xmath216 ) for bone mineral density ( bmd ) data .",
    "this data was presented by hastie et al .",
    "takeuchi et al . ( 2006 ) applied the kernel estimator to the same data .",
    "compared with figure 2 ( b ) of their paper , the penalized splines have a somewhat smooth curve .    next , the confidence interval of @xmath7 is illustrated .",
    "the 100@xmath217 confidence interval of @xmath7 based on the asymptotic result of @xmath56 is obtained as @xmath218,\\label{conf}\\end{aligned}\\ ] ] where @xmath219 , @xmath220 and @xmath221 are the estimators of @xmath115 , @xmath222 and @xmath99 , while @xmath223 is a @xmath224th normal percentile . as the estimator of @xmath222 ,",
    "@xmath225 is used .",
    "we utilize @xmath221 as given in the previous section . as the pilot estimator of @xmath226 in @xmath219",
    ", we construct the @xmath227th derivative of the penalized spline quantile estimator with the @xmath228th @xmath2-spline model .",
    "thus , we obtain ( [ conf ] ) .    in figure",
    "[ motor ] , the @xmath229 approximate confidence interval of @xmath230 for motor cycle impact data is drawn .",
    "this dataset , with @xmath231 was given by h@xmath232rdle ( 1990 ) , where @xmath233 is the acceleration ( g ) and @xmath234 is the time ( ms ) . for comparison , the @xmath229 approximate confidence interval with uncorrected bias of @xmath230 defined by @xmath235\\end{aligned}\\ ] ] is shown .",
    "the penalized spline estimator of the median has a curve with fitness and smoothness . in the area near @xmath236",
    ", we see that there is a strong correction of the bias of @xmath237 .",
    "finally , we compare the median estimator and the mean estimator for boston housing data , with @xmath238 , where @xmath233 is the median value of owner - occupied homes in usd 1000s ( given by medv ) and @xmath234 is the average number of rooms per dwelling ( denoted rm ) .",
    "this dataset is available from harrison and rubinfeld ( 1979 ) .",
    "figure [ boston ] shows the penalized spline quantile estimator of @xmath230(solid ) and the penalized spline estimator @xmath239 of the conditional mean of @xmath3 : @xmath240 $ ] ( dashed ) , where @xmath138 is the smoothing parameter chosen by generalized cross - validation . at around @xmath241 and the right - hand side of @xmath242 ,",
    "the behavior of the median estimator and the mean estimator are different .",
    "we see that @xmath243 is affected by extreme points , such as @xmath244 and @xmath245 . on the other hand",
    ", it appears that the influence of extreme values is limited for the median estimator .    ) with @xmath204 .",
    "the solid lines are for @xmath1320.1 , 0.2 , 0.3 , 0.4 , 0.5 , 0.6 , 0.7 , 0.8 and 0.9 from the bottom to top .",
    "[ bmd],width=453,height=302 ]    ) with @xmath237 ( dashed ) , the @xmath229 approximate confidence intervals ( solid ) and the @xmath229 approximate confidence intervals with uncorrected bias ( dot - dashed ) .",
    "[ motor],width=453,height=302 ]    ) with the mean(dashed ) and median(solid ) estimators .",
    "[ boston],width=453,height=302 ]",
    "this paper have discussed the asymptotic theory of the penalized spline quantile estimator . we showed the asymptotic bias and variance as well as the asymptotic normality of the penalized spline quantile estimator .",
    "the results can be regarded as the quantile regression version of the theorem 2 ( a ) of claeskens et al .",
    "( 2009 ) .    as the further study",
    ", we may consider the asymptotic property of the penalized splines with multivariate covariate @xmath246 .",
    "doskum and koo ( 2000 ) have studied the unpenalized spline quantile estimator in additive models , but the asymptotic results were not discussed .",
    "the additive model has the true quantile function as @xmath247 .",
    "the aim is then to estimate @xmath248 for each @xmath249 .",
    "similar to the work of doskum and koo , we can construct the penalized spline estimator in additive models . in this field",
    ", the asymptotic results should be determined .    in relation to the serious problem of the nonparametric quantile regression ,",
    "a phenomenon called the `` quantile crossing \" occurs ( see koenker ( 2005 ) ) .",
    "he ( 1997 ) and takeuchi et al .",
    "( 2006 ) studied the original estimation methods of @xmath7 without quantile crossing .",
    "however , the asymptotics for their estimators have not yet been developed .",
    "the asymptotic study of the penalized splines without quantile crossing would be an interesting topic for further study .",
    "in addition , by using the asymptotic results of the penalized spline estimator @xmath56 , it may be possible to construct the penalized spline quantile estimator without quantile crossing although this is beyond the scope of this paper .",
    "for a random variable @xmath250 , @xmath251 $ ] and @xmath252 $ ] denote the conditional expectation and variance of @xmath250 given @xmath253 , respectively . for the matrix @xmath254 , @xmath255 . for random sequence @xmath256 and @xmath257 ,",
    "if @xmath258 , then it is written as @xmath259 .",
    "let @xmath269 we show the asymptotic distribution of @xmath270 by lyapunov s theorem .",
    "first from the fact that @xmath271 , we have @xmath272 & = & \\tau - e[i(y_i<\\vec{b}(x_i)^t\\vec{b}^*(\\tau))|\\vec{x}_n]\\\\ & = & \\tau - p(y<\\vec{b}(x_i)^t\\vec{b}^*(\\tau)|x_i = x_i)\\\\ & = & \\tau - p(y<\\eta_\\tau(x_i)+b_a(x_i,\\tau)(1+o(1))|x_i = x_i)\\\\ & = & -b_a(x_i,\\tau)f(\\eta_\\tau(x_i)|x_i)(1+o(1))\\\\ & = & o(1).\\end{aligned}\\ ] ] therefore we obtain @xmath273\\}\\right|^{2+\\gamma}\\right|\\vec{x}_n\\right]\\\\ & & = \\left(\\frac{k_n}{n}\\right)^{(2+\\gamma)/2}|\\vec{b}(x_i)^t \\vec{\\delta}|^{2+\\gamma}e[|\\psi_\\tau(u_i)|^{2+\\gamma}+o(1)|\\vec{x}_n]\\\\ & & \\leq o\\left(\\left(\\frac{k_n}{n}\\right)^{(2+\\gamma)/2}\\right).\\end{aligned}\\ ] ] the straightforward calculation yields @xmath274 & = & \\frac{k_n}{n}\\sum_{i=1}^n \\{\\vec{b}(x_i)^t \\vec{\\delta}\\}^2v[\\psi_\\tau(y_i-\\vec{b}(x_i)^t\\vec{b}^*(\\tau))|\\vec{x}_n]\\\\ & = & \\tau(1-\\tau)\\vec{\\delta}^t\\left(\\frac{k_n}{n}\\sum_{i=1}^n \\vec{b}(x_i)\\vec{b}(x_i)^t \\right)\\vec{\\delta}\\\\ & = & k_n\\tau(1-\\tau)\\vec{\\delta}^t g\\vec{\\delta}(1+o_p(1))\\\\ & = & o(k_n)\\end{aligned}\\ ] ] so it follows that @xmath275^{(2+\\gamma)/2}}\\sum_{i=1}^n e\\left[\\left.\\left|\\sqrt{\\frac{k_n}{n}}\\vec{b}(x_i)^t \\vec{\\delta}\\{\\psi_\\tau(u_i)-e[\\psi_\\tau(u_i)|\\vec{x}_n]\\}\\right|^{2+\\gamma}\\right|\\vec{x}_n\\right]\\\\ & & \\leq o(k_n^{-(2+\\gamma)/2})o\\left(n\\left(\\frac{k_n}{n}\\right)^{(2+\\gamma)/2}\\right)\\\\ & & = o(1)\\end{aligned}\\ ] ] since @xmath66 .",
    "this leads to @xmath276}{v[z_n|\\vec{x}_n]}\\stackrel{d}{\\longrightarrow } n(0,1)\\end{aligned}\\ ] ] from lyapnov s theorem .",
    "the expectation of @xmath277 can be calculated as @xmath278 & = & -\\sqrt{\\frac{k_n}{n}}\\sum_{i=1}^n \\vec{b}(x_i)^t \\vec{\\delta}e[\\psi_\\tau(u_i)|\\vec{x}_n]\\\\ & = & \\sqrt{\\frac{k_n}{n}}\\sum_{i=1}^n \\vec{b}(x_i)^t \\vec{\\delta}b_a(x_i,\\tau)f(\\eta_\\tau(x_i)|x_i)(1+o_p(1))\\\\ & = & \\sqrt{nk_n}\\int_0 ^ 1 \\vec{b}(u)^t \\vec{\\delta}b_a(u,\\tau)f(\\eta_\\tau(u)|u)du(1+o_p(1)).\\end{aligned}\\ ] ] from the proof of lemma 6.10 of argwall and studen ( 1989 ) , for @xmath279 , we have @xmath280 by which @xmath281 .",
    "consequently , we have @xmath282/v[z_n|\\vec{x}_n]=o_p(1)$ ] and lemma [ lyapnov ] holds .",
    "let @xmath286 since @xmath287\\\\ & & = \\int_0^{w_{in } } e[\\{i(u_i\\leq s)-i(u_i\\leq 0)\\}|\\vec{x}_n]ds\\\\ & & = \\int_0^{w_{in } } \\left\\{p\\left(y_i<\\vec{b}(x_i)^t\\vec{b}^*(\\tau)+s|x_i = x_i\\right)-p(y_i<\\vec{b}(x_i)^t\\vec{b}^*(\\tau)|x_i = x_i)\\right\\}ds\\\\ & & = { \\small \\sqrt{\\frac{k_n}{n}}\\int_0^{\\vec{b}(x_i)^t\\vec{\\delta } } \\left\\{p\\left(\\left.y_i<\\vec{b}(x_i)^t\\vec{b}^*(\\tau)+t\\frac{k_n}{n}\\right|x_i = x_i\\right)-p(y_i<\\vec{b}(x_i)^t\\vec{b}^*(\\tau)|x_i = x_i)\\right\\}dt } \\\\ & & = \\frac{k_n}{n}\\int_0^{\\vec{b}(x_i)^t\\vec{\\delta } } f\\left(\\vec{b}(x_i)^t\\vec{b}^*(\\tau)|x_i\\right)tdt\\\\ & & = \\frac{k_n}{2n}f\\left(\\vec{b}(x_i)^t\\vec{b}^*(\\tau)|x_i\\right)\\{\\vec{b}(x_i)^t\\vec{\\delta}\\}^2.\\end{aligned}\\ ] ] therefore we obtain @xmath288 & = & \\frac{k_n}{2n}\\sum_{i=1}^n f\\left(\\vec{b}(x_i)^t\\vec{b}^*(\\tau)|x_i\\right)\\vec{\\delta}^t\\vec{b}(x_i)\\vec{b}(x_i)^t\\vec{\\delta}\\\\ & = & \\frac{k_n}{2}\\vec{\\delta}^t \\left(\\frac{1}{n}\\sum_{i=1}^n f\\left(\\eta_\\tau(x_i)+o(1)|x_i\\right)\\vec{b}(x_i)\\vec{b}(x_i)^t\\right)\\vec{\\delta}\\\\ & = & \\frac{k_n}{2}\\vec{\\delta}^t g(\\tau)\\vec{\\delta}(1+o_p(1)).\\end{aligned}\\ ] ] finally , we show @xmath289=o_p(1)$ ] . for @xmath290 ,",
    "we have @xmath291 therefore the variance of @xmath292 can be evaluated as @xmath293 & \\leq & \\sum_{i=1}^n e\\left[\\left.\\left(\\int_0^{w_{in } } \\{i(u_i\\leq s)-i(u_i\\leq 0)\\}ds\\right)^2\\right|\\vec{x}_n\\right]\\\\ & \\leq &   \\sqrt{\\frac{k_n}{n}}\\max_{i=1,\\cdots , n}\\{\\vec{b}(x_i)^t \\vec{\\delta}\\}e[r_n|\\vec{x}_n].\\end{aligned}\\ ] ] since @xmath294=o(k_n)$ ] , we obtain @xmath295}/e[r_n|\\vec{x}_n]=o_p(1)$ ] and , hence , lemma [ var ] holds .",
    "let @xmath296\\\\ & & + \\frac{\\lambda_{n}}{2}\\left(\\vec{b}^*(\\tau)+\\sqrt{\\frac{k_n}{n}}\\vec{\\delta}\\right)^t d_m^t d_m\\left(\\vec{b}^*(\\tau)+\\sqrt{\\frac{k_n}{n}}\\vec{\\delta}\\right)-\\frac{\\lambda_{n}}{2}\\vec{b}^*(\\tau)^td_m^t d_m\\vec{b}^*(\\tau),\\end{aligned}\\ ] ] where @xmath266 .",
    "then the minimizer @xmath297 of @xmath298 can be obtained as @xmath299 first we show the convergence point @xmath300 of @xmath301 for any @xmath284 . for the following discussion",
    ", we introduce the knight s idntity(see , knight ( 1998 ) ) : @xmath302 where @xmath265 . by using ( [ knight ] ) , we can write @xmath298 as @xmath303 where @xmath304 where @xmath305 . from lemma 1",
    ", @xmath306 satisfies @xmath307 where @xmath268 .",
    "furthermore lemma 2 and @xmath308 yield @xmath309 therefore , we obtain @xmath310 because @xmath300 is convex with respect to @xmath311 and has unique minimizer , the minimizer @xmath297 of @xmath301 converge to @xmath312 .",
    "this fact is detailed in pollard(1991 ) , knight ( 1998 ) and kato ( 2009 ) .",
    "hence we have @xmath313 since @xmath314 , we obtain for @xmath93 , as @xmath94 , @xmath315 by the definition of @xmath316 .",
    "we can confirm with lemma [ g1 ] that @xmath317 .",
    "finally we show the asymptotic order of @xmath318 .",
    "let @xmath319}(x)=(b_{-p+1}^{[p]}(x)\\ \\cdots\\ b_{k_n}^{[p]}(x))^t$ ] . by the properties of the derivative of the @xmath2-spline model , we have @xmath320}(x)^t d_m\\vec{b}(\\tau)$ ] .",
    "therefore we obtain @xmath321}(x)^t \\{k_n^md_m\\vec{b}^*(\\tau)\\}=\\eta_\\tau^{(m)}(x)(1+o(1))$ ] for @xmath322 . since the asymptotic order of @xmath321}(x)^t \\{k_n^md_m\\vec{b}^*(\\tau)\\}$ ] and that of @xmath323 are the same as @xmath324 , @xmath325 is satisfied for @xmath322 .",
    "in addition , similar to the proof of theorem 1 of kauermann et al .",
    "( 2009 ) , @xmath326 is fulfilled .",
    "together with lemma [ g1 ] , we obtain @xmath327 thus proposition 2 has been proven .",
    "10 agawal , g . and studden , w.(1980 ) , `` asymptotic integrated mean square error using least squares and bias minimizing splines,''_ann",
    ". statist . _",
    "* 8*,1307 - 1325 .",
    "claeskens , g . , krivobokova , t . and",
    "opsomer , j.d.(2009 ) .",
    "asymptotic properties of penalized spline estimators .",
    "@xmath330 @xmath331 , 529 - 544 . de boor , c.(2001 ) .",
    "springer - verlag .",
    "eilers , p.h.c . and",
    "marx , b.d.(1996 ) .",
    "flexible smoothing with @xmath2-splines and penalties(with discussion ) . @xmath333 . *",
    "11 * , 89 - 121 .",
    ", hu , t.c . , and truong , y.k.(1994 ) . robust nonparametric function estimation . _ scandinavian journal of statistics_. * 21 * , 433 - 446 .",
    "hao , l . and naiman , d.q.(2007 ) .",
    "_ quantile regression_. sage publications , inc .",
    "hastie , t . ,",
    "tibshirani , r . and friedman , j.(2009 ) .",
    "_ the elements of statistical learning _ ,  springer - verlag .",
    "he , x . and shi , p.(1994 )",
    ". convergence rate of b - spline estimators of nonparametric conditional quantile functions .",
    "_ j. nonparam . statist_. * 3 * , 299 - 308 .",
    "hendricks , w . and koenker , r.(1992 ) .",
    "hierarchical spline models for conditional quantiles and the demand for electricity .",
    "_ j. amer .",
    "* 87 * , 58 - 68 .",
    ", li , r . , and zou , h.(2011 ) .",
    "new efficient estimation and variable selection methods for semiparametric varying - coefficient partially linear models",
    "_ * 39 * , 305 - 332 .",
    "kato , k.(2009 ) .",
    "asymptotics for argmin processes : convexity arguments .",
    "_ j. multi . anal_.",
    "* 100 * , 1816 - 1829 .",
    "kauermann , g . ,",
    "krivobokova , t . , and fahrmeir , l.(2009 ) .",
    "some asymptotic results on generalized penalized spline smoothing._j .",
    "r. statist .",
    "_ b * 71 * , 487 - 503 .",
    "knight.k.(1998 ) . limiting distributions for @xmath334 regression estimators under general conditions .",
    "statist . _",
    "* 26 * , 755 - 770 .",
    "koenker , r .",
    "_ quantile regression_. cambridge univ . press ,",
    "koenker , r . and bassett , g.(1978 ) .",
    "regression quantiles .",
    "_ econometrica_. * 46 * , 33 - 50 .",
    "koenker , r . , ng , p . and portnoy , s.(1994 ) .",
    "quantile smoothing splines .",
    "_ biometrika_. * 81 * , 673 - 680 .",
    "koenker , r . and park , b.j.(1996 ) . an interior point algorithm for nonlinear quantile regression .",
    "_ j. econom_. * 71 * , 265 - 283 .",
    "nychka , d . ,",
    ", haaland , p . ,",
    "martin , d . , and oconnell , m.(1995 )",
    ". a nonparametric regressio n approach to syringe grading for quality improvement .",
    "_ j. amer .",
    "assoc . _ * 90 * , 1171 - 1178 .",
    "pollard , d.(1991 ) .",
    "asymptotics for least absolute deviation regression estimators .",
    "_ econometric theory_. * 7 * , 186 - 199 .",
    "portnoy , s.(1997 ) .",
    "local asymptotics for quantile smoothing splines .",
    "_ * 25 * , 414 - 434 .",
    "pratesi , m .",
    ", ranalli.m.g . , and salvati , n.(2009 ) .",
    "nonparametric m - quantile regression using penalised splines .",
    "_ j. nonparam . statist_.",
    "* 21 * , 287 - 304 .",
    "reiss , p.t . and",
    "huang , l.(2012 ) .",
    "smoothness selection for penalized quantile regression splines .",
    "_ the international journal of biostatistics_. * 8.1*. sheather , s. j. and jones , m. c.(1991 ) . a reliable data - based bandwidth selection method for kernel density estimation .",
    "_ j. r. statist .",
    "_ 53 , 683 - 690 .",
    "and li , g.(1995 ) . global convergence rates of @xmath2-spline @xmath335-estimators in nonparametric regression . _ statistica sinica_. * 5 * , 303 - 318 .",
    "takeuchi , i .",
    ", li , q.v , sears , t.d . , and smola , a.j.(2006 ) .",
    "nonparametric quantile estimation",
    ". _ journal of machine learning research_. * 7 * , 1231 - 1264 .",
    "yu , k . and jones , m.c.(1998 ) . local linear quantile regression .",
    "_ j. amer .",
    "statist . assoc . _",
    "* 93 * , 228 - 237 .",
    "yuan , m.(2006 ) .",
    "gacv for quantile smoothing splines._computational statistics @xmath336 data analysis_. * 50 * , 813 - 829 .",
    "zhou , s . , shen , x . and",
    "wolfe , d.a.(1998 ) .",
    "local asymptotics for regression splines and confidence regions .",
    "_ * 26*(5):1760 - 1782 ."
  ],
  "abstract_text": [
    "<S> quantile regression predicts the @xmath0-quantile of the conditional distribution of a response variable given the explanatory variable for @xmath1 . </S>",
    "<S> the aim of this paper is to establish the asymptotic distribution of the quantile estimator obtained by penalized spline method . a simulation and an exploration of real data </S>",
    "<S> are performed to validate our results .    </S>",
    "<S> * keywords * asymptotic normality , @xmath2-spline , penalized spline , quantile regression . </S>"
  ]
}