{
  "article_text": [
    "extracellular recordings are an indispensable tool in neuroscience , enabling the real time monitoring of neural activity .",
    "central to these recordings is the measurement of action potentials ( aps ) or `` spikes '' , which provide an indication of neuron populations present in the region of interest .",
    "characterisation of these can further our understanding of various neural mechanisms , including responses to various stimuli .",
    "spike sorting refers to the collection of techniques suited to this purpose , encompassing the stages of ap detection , processing and classification .",
    "comprehensive reviews of each of these stages are provided by @xcite and @xcite .",
    "this paper focuses on the final step , corresponding to inference around the assignment of individual spikes to source neurons .",
    "common to approaches developed for this purpose is the grouping of aps based on templates or a reduced set of features , for example , firing statistics @xcite , wavelet transforms @xcite or principal components @xcite .",
    "mixture models are a popular tool for ap classification by virtue of their unsupervised approach to clustering , and are used to group individual aps into clusters containing spikes of similar shapes representing different sources of neurological activity .",
    "these models are underpinned by the assumption that each ap has been generated by one of a number of distinct clusters , where the composition of each cluster is _ a priori _ unknown . to date , methodologies proposed include finite mixtures of gaussian @xcite and t - distributions @xcite , mixtures of factor analysers @xcite , reversible jump markov chain monte carlo ( rjmcmc ) @xcite , and time - dependent mixtures to account for non - stationarity @xcite .",
    "non - parametric approaches to mixture estimation , based on the dirichlet process , have also been posited @xcite .",
    "whilst these models share the common goal of clustering , there exist key differences in the assumptions underpinning their development .",
    "this has the potential to impact on subsequent model - based inferences , particularly when interest lies in the determination of the optimal clustering of the observed data .",
    "the implications of applying different mixture - based methods , in the context of the featured problem , remains relatively unexplored .",
    "this paper seeks to provide insight into this issue by comparing two mixture - based approaches to spike classification , both of which are formulated within the bayesian framework .",
    "the first model considered is a finite mixture of multivariate gaussian distributions , applying methodology recently proposed by @xcite .",
    "outlined further in section [ sec : ofmodel ] , this method approaches mixture model estimation by initially overfitting the number of clusters expected to be present . specified conditions on the prior distribution for the mixture weights encourage the emptying out of excess components in the posterior distribution @xcite .",
    "the performance of this methodology is compared to a dirichlet process mixture model , a non - parametric alternative to mixture modelling .",
    "the chosen models are compared with respect to three objectives .",
    "firstly , differences in posterior inference concerning the number of occupied clusters are compared .",
    "the second objective seeks to reconcile differences in the inferred classification of the aps into clusters , based on posterior pairwise probabilities of individual aps being assigned to the same cluster .",
    "finally , the third objective is to compare the composition of the mixture components , under an inferred , optimal cluster configuration . to address these objectives ,",
    "the models are applied to spikes collected from the subthalamic nucleus during deep brain stimulation , a surgical intervention for the alleviation of symptoms in patients with advanced parkinsons disease ( pd ) .",
    "the remainder of this paper is organised as follows . in section [ sec : data ] , the data used for analysis are described .",
    "key details of the chosen mixture models are outlined in section [ sec : methods ] .",
    "the results of the aforementioned application are reported in section [ sec : results ] , and are organised in line with the stated objectives .",
    "a discussion of key results and directions for future work are summarised in section [ sec : discussion ] .",
    "the data analysed in this paper consisted of extracellular recordings of the subthalamic nucleus collected during deep brain stimulation , a treatment for advanced parkinson s disease .",
    "these data are comprised of spikes extracted from three independent recordings of deep brain stimulation , using standard techniques , and was originally analysed by @xcite ( see @xcite for further details ) .",
    "the resulting waveforms from each recording , labelled @xmath0 , @xmath1 and @xmath2 are displayed in figure [ figure_1 ] , with sample sizes @xmath3 , @xmath4 and @xmath5 , respectively .    , @xmath1,@xmath2 ) .",
    "]    dimension reduction was performed on the sampled waveforms using a robust version of principal components analysis ( pca ) @xcite , to lessen the influence of outliers on the calculation of principal components ( pcs ) .",
    "for all analyses presented in section [ sec : results ] , the first four principal components ( pcs ) were used as inputs into each model for all three datasets , in each case explaining greater than 80% of variation among waveforms ( 83% , 91% , and 85% for the first , second and third dataset respectively ) .",
    "robust scree plots were used to assist this choice , and the four pc s are illustrated in figure [ figure_2 ] .          in this section ,",
    "the key details of the two proposed mixture - based approaches are outlined .",
    "common to both approaches is the problem of inferring the partition of @xmath6 ( possibly multivariate ) observations into @xmath7 clusters , where @xmath7 is unknown . for the sample @xmath8 ,",
    "let @xmath9 consist of @xmath10 measurements associated with the @xmath11th observation .",
    "cluster membership for each @xmath12 is inferred via the discrete latent variable @xmath13 , with @xmath14 denoting the assignment of @xmath12 to cluster @xmath15 .    in light of data described in section [ sec : data ] , assume that , conditional on assignment to a cluster @xmath15 , @xmath12 follows a multivariate gaussian distribution with mean @xmath16 $ ] and variance - covariance matrix @xmath17 , @xmath18 .",
    "conditional on assignment to cluster @xmath15 , the likelihood for @xmath12 is , @xmath19 defined by the unknown parameter set @xmath20 .    in this paper",
    ", each model was estimated using markov chain monte carlo ( mcmc ) , with details provided in the relevant subsections . for each @xmath15 , a joint prior distribution of form @xmath21",
    "was adopted , with @xmath22 where @xmath23=\\frac{\\mathbf{c}_0}{\\left(c_0-r-1\\right)}$ ] .",
    "the choice of hyperparameters @xmath24 for the featured study is discussed in section [ sec : results ] .      the overfitted finite mixture model ( ofm ) approach consisted of fitting a finite mixture model where the number of components specified , say @xmath25 , is greater than the true number of clusters .",
    "using the aforementioned notation , the likelihood of @xmath26 is given by @xmath27 where @xmath28 and @xmath29 , corresponding to the _ a priori _ probability of a randomly selected observation being assigned to cluster @xmath15 .",
    "collectively , @xmath30 represent the mixture weights and are subject to the constraint @xmath31 .",
    "given the above definition of the mixture weights , the prior distribution for each @xmath13 is multinomial , @xmath32 and is updated as part of the chosen mcmc scheme .",
    "the inclusion of @xmath13 as a latent variable represents a form of data augmentation @xcite , to facilitate feasible computation of equation ( [ eq : fmmlikey ] ) .",
    "the key feature of the ofm approach lies in the choice of prior distribution for the mixture weights . in this case",
    ", the vector of weights follows a dirichlet distribution , @xmath33 characterised by the hyperparameter @xmath34 for @xmath35 .",
    "we consider here the case @xmath36 to obtain an exchangeable prior .    building on theoretical results first published by @xcite ,",
    "overfitting finite mixture models with posterior emptying has recently been rendered achievable using well - known mcmc techniques @xcite .",
    "the methodology ( called zmix ) , was applied by @xcite to the case of univariate gaussian mixture models .",
    "the ofm depends on the choice of an appropriate value of @xmath37 that results in the excess components @xmath38 being assigned negligible weight , so that in practice no observations are allocated to unnecessary groups . as a result ,",
    "the partition of @xmath26 implied by @xmath39 provides insight into the true number of mixture components .",
    "the appropriate choice of @xmath34 was considered at length in @xcite , who showed that when @xmath7 is unknown , a very small value of @xmath34 close to zero must be used , to prevent extra groups from being populated in practice .",
    "the resulting posterior parameter surface is difficult for a gibbs sampler to traverse thanks to the complex mutlimodal nature of ofms , which is exacerbated by this choice of hyperparameter .",
    "the mcmc can however be augmented with a prior parallel tempering algorithm , which enables accurate estimation of the ofm posterior with plentiful mixing by drawing on the behaviour of the ofm under small changes in the prior hyperparameters @xcite .",
    "briefly , writing @xmath40 , a ladder of @xmath41 values @xmath42 was created where @xmath43 corresponded to the smallest , chosen _ a priori _ to promote emptying behaviour based on the results of @xcite . as @xmath44 increases , the values of @xmath45 increase gradually , eventually reaching values which entirely prevent empty clusters from being estimated .    the mcmc algorithm is implemented in parallel in combination with gibbs sampling steps for the remaining model parameters .",
    "further details of the zmix algorithm can be found in @xcite .",
    "code used to implement the mcmc algorithm for the ofm model is provided in .",
    "dirichlet process mixture ( dpm ) modelling has become increasingly popular for unsupervised clustering , and is commonly viewed as a nonparameteric alternative to the finite mixture model .",
    "dpms are distinguished by their use of a dirichlet process ( dp ) as a prior over mixture model components .",
    "formally , for a given measurable space @xmath46 , the dp is a stochastic process defined as a distribution over probability measures .",
    "its use as a prior distribution leads to the following model for @xmath12 , @xmath47 where @xmath48 denotes a random probability measure .",
    "the dp in equation ( [ eq : dp1 ] ) is defined by a base distribution , @xmath49 , corresponding to the mean of the dp , and concentration parameter @xmath50 .",
    "the applicability of the dp within a mixture setting is attributed to its discreteness property , that states the existence of a non - zero probability of multiple @xmath51 s equalling the same value , in turn inducing clustering behaviour .",
    "this discrete nature of @xmath48 is made clear with the stick - breaking construction @xcite , that replaces @xmath48 with an infinite weighted sum of point masses . using this construction ,",
    "the dp is rewritten as , @xmath52 where @xmath53 and for each @xmath54 , @xmath55 denotes a dirac mass at @xmath56 weighted by @xmath57 ; @xmath58 . the term ` stick - breaking ' refers to the analogy that the weights @xmath59 represent portions of a unit - length stick , with each @xmath57 being a randomly drawn proportion of length remaining , given preceding clusters .",
    "similar to the ofm , @xmath59 represent cluster weights , albeit in this case , @xmath7 is countably infinite .",
    "for this reason , the dpm is often referred to as an infinite mixture model @xcite .",
    "compared to the ofm in section [ sec : ofmodel ] , the dpm introduces an additional parameter , @xmath60 , related to the concentration of the dp around the base distribution . in light of the stick - breaking construction in equation ( [ eq : dpstick ] ) ,",
    "@xmath60 is seen to influence the construction of the weights , @xmath61 that , in turn , directly influence each @xmath57 . in this paper , the true value of @xmath60 is assumed unknown and assigned a @xmath62 prior distribution .",
    "this choice encourages a small number of clusters a priori , and is centered around 1 , a commonly chosen value when @xmath60 is assumed to be fixed @xcite .    similar to the ofm , each @xmath12",
    "is associated with @xmath63 through the introduction of a latent variable @xmath13 , which is updated as part of the mcmc scheme . for the results presented in section [ sec : results ] , the slice sampler proposed by @xcite was implemented .",
    "this algorithm proposes an efficient way of sampling from the stick - breaking construction via the introduction of auxiliary variables .",
    "the key benefit of this approach is that it avoids the need to approximate the dp by truncating the number of components computed @xcite .",
    "rather , the resulting slice sampler allows for adaptive truncation of the stick - breaking representation in a way that enables feasible computation of @xmath39 . to improve the mixing behaviour of the sampler ,",
    "two label switching moves were also implemented @xcite .",
    "r code to implement the chosen mcmc scheme is provided in .    due to the countably infinite dimension of the dpm ,",
    "the primary focus is not on the determination of the optimal value for @xmath7 .",
    "rather , one seeks to infer similarities among elements of @xmath26 .",
    "the most common method for achieving this inference is to compute posterior pairwise probabilities of equality for all pairs of labels @xmath13 and @xmath64 , i.e. , @xmath65 @xmath66 @xmath67 .",
    "this approach is easily implemented within an mcmc framework and has the benefit of being label invariant .",
    "furthermore , in cases in which the optimal partition of @xmath12 is sought , there exist a number of methods for the determination of the maximum a posteriori ( map ) estimate of @xmath39 , based on the @xmath68 matrix of posterior pairwise probabilities @xcite . for results presented in section [ sec : results ] , the posterior expected rand ( pear ) index proposed by @xcite , which is based on the rand index @xcite ,",
    "was adopted for this purpose .",
    "the results of modelling the three multivariate datasets under both approaches ( ofm and dpm ) are explored according to the three objectives detailed in section [ sec : intro ] .",
    "for both the ofm and dpm , the results presented are based on 50,000 mcmc iterations , discarding the first 25,000 .",
    "convergence to the target distribution after burn - in was assessed via graphical examination of the mcmc samples . for the estimation of each ofm",
    ", @xmath69 components were included in the mixture model fit to each dataset .",
    "likewise , for the estimation of each dpm , the slice sampler was initialised with @xmath69 clusters .",
    "@xmath25 was chosen to be larger than the maximum expected number of components contained in each dataset . in each case , the allocation variable @xmath39 was initialised based on the results of a k - means algorithm on @xmath26 ( assuming @xmath25 clusters ) .    to specify the prior distributions defined in equation [ eq : mvnpriors ] , the following values were chosen for the hyperparameters : @xmath70 , @xmath71 , @xmath72 and @xmath73 .",
    "these values were chosen to reflect a plausible range of values for each parameter , whilst remaining relatively non - informative .",
    "similar choices for multivariate gaussian mixture models are discussed in @xcite .    as noted in section [ sec : data ] , the first four principal components computed explained a large proportion of the variation in the data and were extracted for this analysis , such that each resulting dataset has @xmath74 dimensions . throughout this section ,",
    "these datasets are referred to as @xmath0 , @xmath1 and @xmath2 , respectively .",
    "objective 1 is to compare the distribution of the number of occupied components in the results generated by the two approaches , ofm and dpm .",
    "this value is tightly distributed around 4 in the results from the ofm approach , with a probability of @xmath75 , 0.86 , and 0.67 that four groups are needed to model @xmath0 , @xmath1 , and @xmath2 respectively . for @xmath0 and @xmath1",
    "there was a probability of 0.11 and 0.10 that only 3 groups were needed .",
    "for @xmath1 a small probability of 0.04 of 5 groups was also observed . for @xmath2",
    "the ofm model resulted in four or five groups , with a probability of 0.33 for the later .",
    "the large majority of iterations corresponded to a model with four occupied components for all three datasets under the ofm model .",
    "the dpm model identified a larger number of occupied groups across all three datasets . in comparison to the same value in the ofm ,",
    "the dpm also exhibited much greater variability , resulting in a wider distribution over models with a varying number of occupied groups .",
    "for dpm however , the number of occupied groups is not expected to reflect the true value , and further investigation is required to examine the structure estimated by the two approaches .",
    "objective 2 is to explore whether the posterior membership of observations to components is similar under the ofm and dpm models .",
    "this is explored in terms of the similarity of the pairwise posterior allocations . for each dataset @xmath76 ,",
    "a @xmath68 matrix containing the proportion of mcmc iterations in which each pair of observations is allocated to the same group is computed .",
    "the estimated pairwise posterior allocation probability matrices thus created are denoted @xmath77 and @xmath78 to indicate the relevant method and dataset .",
    "the results are depicted in figure [ figure_3 ] ( a ) and ( b ) , ordered by the first dimension of each @xmath79 ; light areas of the plots correspond to large probabilities . in figure [ figure_3](c ) ,",
    "@xmath80 is included to illustrate their differences more clearly ; here large differences between the matrices correspond to dark areas .",
    "the results indicate that both approaches sample a very similar posterior space , in that the estimated relationships between observations are quite consistent between the ofm and dpm models . in the case of @xmath0 and @xmath1",
    "this was almost indistinguishable for most observations , while for @xmath2 , some structural differences exist , reflecting larger uncertainty in the clustering of these data .",
    "direct interpretation is limited as the data are multivariate and corresponds to principal components .",
    "for @xmath0 and @xmath1 , three clusters are delineated by both approaches , visible in this plot as blocks of observations with a large probability of being allocated together . in both datasets ,",
    "a large cluster near the median of the observations ( dimension 1 ) is surrounded by two smaller groups .",
    "the results of @xmath2 are less interpretable , as ordering on the first dimension does not appear to capture the structure of the clusters well for this dataset . when comparing these directly ( @xmath81 plot of fig.[figure_3](c ) , the differences between the two appears to be slightly larger than for @xmath0 and @xmath1 , but this is quite even and does not indicate any significant structural differences .    , @xmath1 , @xmath2 ) .",
    "a ) ofm , b ) dpm , c ) comparison . ]",
    "objective 3 is to compare the composition of the components if a single model representing the optimal partition of the data into clusters is chosen . for the ofm approach ,",
    "the chosen optimal model is the configuration with the most frequently reported number occupied components ( as reported in table [ table_1 ] ) , as was done by @xcite . for the dpm approach ,",
    "this is the pear estimate of the clustering , as discussed in section [ sec : npmodel ] @xcite .",
    ".posterior distribution of the number of occupied components by model and dataset , expressed as a proportion of the number of mcmc iterations . [ cols=\"^,^,^,^,^,^,^ \" , ]     the composition of each cluster , for each model , is summarised in table [ table_2 ] . for the ofm ,",
    "the majority of the observations were clustered in three large groups , and one small fourth cluster .",
    "the results of the dpm are similar for @xmath0 and @xmath1 ; the first three clusters are very close in size , the main difference being the presence of an extra group with a single observation .",
    "the structure of the inferred clusters appears to be quite different for @xmath2 under the dpm , the model is composed of one large group of 195 observations , with a long tail of seven more clusters of decreasing size .",
    "& & + * k * & * count * & * % * & * k * & * count * & * % * & * k * & * count * & * % * + 1 & 101 & 52.60 % & 1 & 122 & 57.82% & 1 & 176 & 50.57 % + 2 & 59 & 30.73 % & 2 & 44 & 20.85 % & 2 & 72 & 20.69 % + 3 & 25 & 13.02 % & 3 & 42 & 19.91% & 3 & 79 & 22.70 % + 4 & 7 & 3.65 % & 4 & 3 & 1.42% & 4 & 21 & 6.03 % +   + & & + * k * & * count * & * % * & * k * & * count * & * % * & * k * & * count * & * % * + 1 & 112 & 58.33 & 1 & 125 & 59.24&1 & 195 & 56.03 + 2 & 47 & 24.48 & 2 & 41 & 19.43&2 & 54 & 15.52 + 3 & 25 & 13.02 & 3 & 42 & 19.91&3 & 42 & 12.07 + 4 & 7 & 3.65 & 4 & 2 & 2&4 & 31 & 8.91 + 5 & 1 & 0.52 & 5 & 1 & 1 & 5&13 & 3.74 + 6 &  &  & 6 &  & &6 & 10 & 2.87 + 7 &  &  & 7 &  & &7 & 2 & 0.57 + 8 &  &  & 8 &  & &8 & 1 & 0.29 +    figures [ figure_4 ] , [ figure_5 ] and [ figure_6 ] allow for the direct comparison of the inferred clusters .",
    "the spikes are shown plotted according to the groups found by the ofm , with each spike coloured according to their optimal clustering under the dpm .",
    "the plots are ordered according to the number of observations allocated in the ofm clusters , so that group 1 is the largest ofm group and 4 the smallest , as in table [ table_2 ] .",
    "the inverse plots of the spikes sorted by the dpm clusters and coloured according to the ofm clusters can be found in the supplementary material ( see , , and ) .",
    "for all three datasets , the three largest ofm clusters correspond closely with different pdm clusters ; all spikes in clusters 1 and 3 of @xmath0 and @xmath1 ( see figures [ figure_4 ] and [ figure_5 ] ) are from a single dpm group . in a few of the large groups , a small number of spikes are allocated originating from other dpm clusters , as can be seen by the small number of red and blue lines in cluster 2 for @xmath0 ( figure [ figure_4 ] ) .",
    "the results of @xmath2 in figure [ figure_6 ] indicate larger differences between the clusterings found by ofm and dpm .",
    "the ofm cluster 1 corresponds closely to dpm cluster 1 , indicated by red curves .",
    "this is also true for third largest ofm group , which contains mostly spikes from dpm group 2 ( with a few extra observations from the red dpm group ) .",
    "ofm group 2 is made of two different dpm clusters , those indicated by the dark blue and pink lines .",
    "the composition of the smallest clusters ( ofm cluster 4 ) is different from the other three groups , and appears to contain spikes of widely varying shapes which do not fit well into the other groups . for @xmath0 ,",
    "this contains 7 observations , all from the two smallest dpm clusters . in @xmath1 ,",
    "the smallest ofm cluster contains only 3 observations , again from the two smallest dpm components . in @xmath2",
    "the fourth ofm cluster is larger and contains 21 observations , but is again made up mostly of spikes allocated to the small , variable clusters found by the dpm .     under the ofm ( one cluster per frame ) .",
    "the clusters inferred under the dpm are represented by different colours , to indicate their composition / relationship with respect to clusters inferred by the ofm . ]     under the ofm ( one cluster per frame ) .",
    "the clusters inferred under the dpm are represented by different colours , to indicate their composition / relationship with respect to clusters inferred by the ofm . ]     under the ofm ( one cluster per frame ) .",
    "the clusters inferred under the dpm are represented by different colours , to indicate their composition / relationship with respect to clusters inferred by the ofm . ]",
    "performing a comparison of the two approaches for mixtures with an unknown number of components , one parametric and one non - parametric , provides insights on the impact of the underlying assumptions involved in both methods .",
    "the two methods , ofm and dpm are used to fit similar multivariate gaussian finite mixture models .",
    "the small differences in these reveal how uncertainty is handled under the two approaches , both in the posterior distribution of occupied cluster and in the composition of the clusters identified .",
    "this understanding is crucial for the future applications of mixture models that seek to describe complex data .",
    "the choice of method will depend on the goal of the analysis .",
    "both methods are effective at identifying high probability clusters made up of spikes with similar trajectories , effectively capturing the bulk of the variability in the spike shapes .",
    "the uncertainty in the clustering in both methods is caused by the presence of a small number of spikes in each dataset which tend to not be allocated in these larger clusters . in the dpm , these are captured with a number of small clusters with small posterior weights , reflecting a range of potential models explaining the components for which few observations are present .",
    "thus the number of occupied groups in the mcmc tends to vary and be greater than may be supported by the data , even though most observations are allocated to a small number of occupied components . in this manner ,",
    "the dpm approach is able to capture fine details in structure pertaining to potentially very small clusters , and reflects their lack of strong support with greater variability in these small clusters .",
    "the ofm treats the uncertainty in the clustering differently , as the prior strongly discourages the posterior from placing mass on clusters which are not strongly supported by observations .",
    "the observations which do not fit into the high probability groups ( with large weights ) , are combined into a single group with a large covariance , capturing the outliers with the addition of a multivariate gaussian noise component .",
    "this prevents interpretation of the smallest clusters , as may be possible with the results of the dpm if the small components can be justified .",
    "well defined clusters are , on the whole , easy to identify using the methods considered and are expected to be so using any number of other approaches for unsupervised clusters .",
    "the differences in the results occurred where data was insufficient to overcome the suggestion of the priors",
    ". a clear understanding of exactly how such uncertainty is handled in both the ofm and dpm is crucial to their effective use in practice , allowing the future analyst to choose an approach suited to the situation and goal of the research problem at hand and interpret the results .",
    "when the aim is to obtain a sparse clustering strongly supported by the data , as well as to identify gaussian noise , the ofm approach is ideal and requires few inputs or decisions on the part of the analyst to obtain the result . in cases",
    "where a ` hard ' clustering is too restrictive to explain complex data however , the dpm is able to explore a finer , more intricate underlying structure , and as such can estimate a larger number of small components which are less likely , but possible given the data . in a sense ,",
    "the ofm provides information on the _ probable _ set of models which explain the data , while the dpm provides informations about all _ possible _ models , producing a richer but slightly more cumbersome result .",
    "99 bar - hillel , a. , spiro , a.  stark , e. 2006 , ` spike sorting : bayesian clustering of non - stationary data ' , _ j. neurosci .",
    "methods_157(2 ) ,  303316 .    bullen , p.  s. 1970 , ` a constructive definition of an integral ' , _ tohoku math . j. _",
    "22(4 ) ,  597603 .    calabrese , a.  paninski , l. 2011 , ` kalman filter mixture model for spike sorting of non - stationary data ' , _ j. neurosci . methods _",
    "196(1 ) ,  159169 .",
    "delescluse , m.  pouzat , c. 2006 , ` efficient spike - sorting of multi - state neurons using inter - spike intervals information ' , _ j. neurosci . methods _",
    "150(1 ) ,  1629 .",
    "fritsch , a.  ickstadt , k. 2009 , ` improved criteria for clustering based on the posterior similarity matrix ' , _ bayesian anal . _",
    "4(2 ) ,  367392 .",
    "frhwirth - schnatter , s. 2006 , _",
    "finite mixture and markov switching models _ , springer science & business media .",
    "gasthaus , j. , wood , f. , gorur , d.  teh , y.  w. 2009 , dependent dirichlet process spike sorting , _ in _ ` adv . neural inf . process . syst . ' , pp .  497504 .",
    "gorur , d. , rasmussen , c.  e. , tolias , a.  s. , sinz , f. , logothetis , n.  k. , grr , d. , rasmussen , c.  e. , tolias , a.  s. , sinz , f. logothetis , n.  k. 2004 , modelling spikes with mixtures of factor analysers , _ in _ ` pattern recognit . ' , springer , pp .",
    "391398 .",
    "hubert , m. , rousseeuw , p.",
    "j.  vanden branden , k. 2005 , ` robpca : a new approach to robust principal component analysis ' , _ technometrics _",
    "47(1 ) ,  6479 .",
    "ishwaran , h.  james , l.  f. 2001 , ` gibbs sampling methods for stick - breaking priors ' , _ j. am .",
    "stat . assoc . _ 96(453 ) ,  161173 .",
    "letelier , j.  c.  weber , p.  p. 2000 , ` spike sorting based on discrete wavelet transform coefficients ' , _ j. neurosci .",
    "methods _ 101(2 ) ,  93106 .",
    "lewicki , m.  s. 1998 , ` a review of methods for spike sorting : the detection and classification of neural action potentials . ' , _ network _",
    "9(4 ) ,  r53r78 .",
    "medvedovic , m.  sivaganesan , s. 2002 , ` bayesian infinite mixture model based clustering of gene expression profiles . ' , _ bioinformatics _ 18(9 ) ,  11941206 .",
    "mengersen , k. , robert , c.  titterington , m. 2011 , _ mixtures : estimation and applications _ , vol . 896 , wiley series in probability and statistics .",
    "nguyen , d. d.  p. , frank , l. l.  m.  brown , e. n.  e. 2003 , ` an application of reversible - jump markov chain monte carlo to spike classification of multi - unit extracellular recordings . ' , _ network _ , 14(1 ) ,  6182 .",
    "papaspiliopoulos , o.  roberts , g.  o. 2008 , ` retrospective markov chain monte carlo methods for dirichlet process hierarchical models ' , _ biometrika _ , 95(1 ) ,  169186 .",
    "pouzat , c. , delescluse , m. , viot , p.  diebolt , j. 2004 , ` improved spike - sorting by modeling firing statistics and burst - dependent spike amplitude attenuation : a markov chain monte carlo approach . ' , _ j. neurophysiol . _ * 91*(6 ) ,  29102928 .",
    "rand , william m 1971 , ` objective criteria for the evaluation of clustering methods ' , _ journal of the american statistical association _ ,",
    "taylor & francis group * 66 * ( 336 ) ,  846850    sahani , m. 1999 , ` latent variable models for neural data analysis maneesh sahani ' , _ phd thesis .",
    "california institute of technology . _ 1999 .",
    "shoham , s. , fellows , m.  r.  normann , r.  a. 2003 , ` robust , automatic spike sorting using mixtures of multivariate t - distributions ' , _ j. neurosci . methods _",
    "127(2 ) ,  111122 .",
    "taylor , p. , tanner , m.  a.  wong , w.  h. 2012 , ` augmentation the calculation of posterior distributions by data augmentation ' , _ j. am .",
    "_ 82(september 2013 ) ,  3741 .",
    "teh , y.  w. , 2010 , dirichlet processes , _ in _ ` encyclopedia of machine learning ' , springer , pp .",
    "280287 .",
    "van havre , z. , white , n. , rousseau , j.  mengersen , k. 2015 , ` overfitting bayesian mixture models with an unknown number of components ' , _ plos one _ 10(7 ) ,  e0131739 .",
    "walker , s.  g. 2007 , ` sampling the dirichlet mixture model with slices ' , _ commun .",
    "comput . _ 36(1 ) ,  4554 .",
    "white , n. 2011 , bayesian mixtures for modelling complex medical data : a case study in parkinson s disease , phd thesis , queensland university of technology .",
    "wood , f. , fellows , m. , donoghue , j.  black , m. 2004 , ` automatic spike sorting for neural decoding . ' , _ conf .",
    "_ 6 ,  40094012 .",
    "wood , f. , goldwater , s.  black , m.  j. 2006 , ` a non - parametric bayesian approach to spike sorting . ' , _ conf .",
    "_ 1 ,  11651168 .",
    "supporting information : additional information for this article is available .",
    "* inferred optimal partitions for @xmath0 under the dpm * the clusters inferred under the ofm are represented by different colours , to indicate their composition / relationship with respect to clusters inferred by the dpm .",
    "* inferred optimal partitions for @xmath1 under the dpm * the clusters inferred under the ofm are represented by different colours , to indicate their composition / relationship with respect to clusters inferred by the dpm .",
    "* inferred optimal partitions for @xmath2 under the dpm * the clusters inferred under the ofm are represented by different colours , to indicate their composition / relationship with respect to clusters inferred by the dpm ."
  ],
  "abstract_text": [
    "<S> the modelling of action potentials from extracellular recordings , or spike sorting , is a rich area of neuroscience research in which latent variable models are often used . </S>",
    "<S> two such models , overfitted finite mixture models ( ofms ) and dirichlet process mixture models ( dpms ) are considered to provide insights for unsupervised clustering of complex , multivariate medical data when the number of clusters is unknown . </S>",
    "<S> ofm and dpm are structured in a similar hierarchical fashion but they are based on different philosophies with different underlying assumptions . </S>",
    "<S> this study investigates how these differences impact on a real study of spike sorting , for the estimation of multivariate gaussian location - scale mixture models in the presence of common difficulties arising from complex medical data . </S>",
    "<S> the results provide insights allowing the future analyst to choose an approach suited to the situation and goal of the research problem at hand . </S>"
  ]
}