{
  "article_text": [
    "the classic database textbook dedicates several chapters to schema design : carefully crafting an abstract model , translating it into a relational schema , which is then normalized .",
    "while walking their students through the course , scholars emphasize again and again the importance of an anticipatory , holistic design , and the perils of making changes later on .",
    "decades of experience in writing database applications have taught us this . yet",
    "this waterfall approach no longer fits when building today s web applications .    during the last decade",
    ", we have seen radical changes in the way we build software , especially when it comes to interactive , web - based applications : release cycles have accelerated from yearly releases to weekly or even daily , new deployments of beacon applications such as youtube ( quoting marissa meyer in  @xcite ) .",
    "this goes hand in hand with developers striving to be agile . in the spirit of lean development ,",
    "design decisions are made as late as possible .",
    "this also applies to the schema .",
    "fields that _ might _ be needed in the future are not added presently , reasoning that until the next release , things might change in a way that would render the fields unnecessary after all .",
    "it is partly due to this very need for more flexibility , that schema - free nosql data stores have become so popular .",
    "typically , developers need not specify a schema up front .",
    "moreover , adding a field to a data structure can be done anytime and at ease .",
    "[ [ scope - of - this - work . ] ] scope of this work .",
    "+ + + + + + + + + + + + + + + + + + +    we study aspects of schema management for professional web applications that are backed by nosql data stores .",
    "figure  [ fig : architecture ] sketches the typical architecture .",
    "all users interact with their own instance of the application , e.g.  a servlet hosted by a platform - as - a - service , or any comparable web hosting service .",
    "it is established engineering practice that the application code uses an object mapper for the mapping of objects in the application space to the persisted entities .",
    "we further assume that the nosql data store is provided as database - as - a - service , so we have no way of configuring or extending it .",
    "our work addresses this important class of applications . of course , there are other use cases for employing nosql technology , yet they are not the focus of our work .    [",
    "[ case - study - blogging - applications . ] ] case study : blogging applications .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    we introduce a typical example of a professional web application : an online blog . in the spirit of shipping",
    "early and often , both the features of our application as well as the data will evolve .",
    "we use a nosql data store , which stores data as entities .",
    "we will establish our terminology in later chapters , and make do with a hand - wavy introduction at this point .",
    "each entity has an entity key , which is a tuple of an entity kind and an identifier .",
    "each entity further has a value , which is a list of properties :    .... ( kind , i d ) = { comma - separated list of properties } ....    let us dive right in . in our first release , users publish blogs ( with title and content ) and guests can leave comments on blogposts . for each blogpost , information about the author and the date of the post is stored . in the example",
    "below , we use a syntax inspired by json  @xcite , a lightweight data - interchange format widely used within web - based applications .    ....",
    "( blogpost , 007 ) = {   title : \" nosql data modeling techniques \" ,   content : \" nosql databases are often ... \" ,   author : \" michael \" ,   date : \" 2013 - 01 - 22 \" ,     comments : [    { comment - content : \" thanks for the great article ! \" ,     comment - date : \" 2013 - 01 - 24 \" } ,   { comment - content : \" i would like to mention ... \" ,     comment - date : \" 2013 - 01 - 26 \" } ] } ....    soon , we realize that changes are necessary : we decide to support voting , so that users may `` like '' blogposts and comments .",
    "consequently , we expand the structure of blogposts and add a `` likes '' counter . since we have observed some abuse , we no longer support anonymous comments . from now on ,",
    "users authenticate with a unique email address .",
    "users may choose a username ( ` user ` ) and link from their comments to their website ( ` url ` ) , as well as specify a list of interests .",
    "accordingly , we add new fields .",
    "we take a look at a new data store entity  ` ( blogpost , 234708 ) ` and the state of an older entity ` ( blogpost , 007 ) ` that has been added in an earlier version of the application . for the sake of brevity ,",
    "we omit the data values :    .... ( blogpost , 234708 ) = {   title , content , author , date , likes ,   comments [     { comment - content , comment - date , comment - likes ,      user , email , url , interests [ ] } ] } ....    .... ( blogpost , 007 ) = {   title , content , author , date ,    comments [     { comment - content , comment - date } ,    { comment - content , comment - date } ] } ....    next , we decide to reorganize our user management . we store user - related data in separate ` user ` entities .",
    "these entities contain the user s ` login ` , ` passwd ` , and ` picture ` .    during this reorganization",
    "we further rename ` email ` to ` login ` in ` blogpost ` entities .",
    "the ` interests ` are moved from ` blogpost ` to the ` user ` entities , and the ` url ` is removed .",
    "below , we show blogpost ` ( blogpost , 331175 ) ` of this new generation of data , along with old generation blogposts that were persisted in earlier versions of the application .",
    "the structural differences are apparent .    ....",
    "( blogpost , 331175 ) = {    title , content , author , date , likes ,    comments [    { comment - content , comment - date ,       comment - likes , user , login } ] } ( user , 42 ) = { login , passwd , interests [ ] , picture } ....    .... ( blogpost , 234708 ) = {   title , content , author , date , likes ,   comments [     { comment - content , comment - date , comment - likes ,      user , email , url , interests [ ] } ] } ....    .... ( blogpost , 007 ) = {   title , content , author , date ,    comments [     { comment - content , comment - date } ,    { comment - content , comment - date } ] } ....    after only three releases , we have accumulated considerable technical debt in our application code .",
    "it is now up to the developers to adapt their object mappers and the application logic so that all three versions of blogposts may co - exist .",
    "whenever a blogpost is read from the data store , the application logic has to account for the heterogeneity in the comments : some comments do not have any user information , while others have information about the user identified by ` email ` ( along with other data ) .",
    "a third kind of ` blogpost ` contains ` comments ` identified by the user s ` login ` .",
    "if new generation comments are added to old generation blogposts , we produce even a fourth class of blogposts .",
    "not only does this introduce additional code complexity , it also increases the testing effort . with additional case distinctions ,",
    "a good code coverage in testing becomes more difficult to obtain .    in an agile setting where software is shipped early and often",
    ", developers would rather spend their time writing new features than fighting such forms of technical debt . at the same time , the nosql data store offers little , if any , support in evolving the data along with the application .",
    "our main contribution in this paper is an approach to solving these kinds of problems .",
    "[ [ schema - evolution - in - schema - less - stores . ] ] schema evolution in schema - less stores .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    while the sweet spot of a schema - less backend is its flexibility , this freedom rapidly manifests in ever - increasing technical debt with growing data structure entropy .",
    "once the data structures have degenerated , a nosql data store provides little support for getting things straightened out .",
    "most nosql data stores do not offer a _",
    "data definition language _ for specifying a global schema ( yet some systems , such as cassandra , actually do  @xcite ) .",
    "usually , they merely provide basic read- and write operations for manipulating single entities , delegating the manipulation of sets of entities completely to the application logic .",
    "consequently , these systems offer no dedicated means for migrating legacy entities , and developers are referred to writing batch jobs for data migration tasks ( e.g.  @xcite ) . in such batch jobs , entities are fetched one - by - one from the data store into the application space , modified , and afterwards written back to the store .",
    "worse yet , since we consider interactive web applications , migrations happen while the application is in use .",
    "we refer to data migration in batches as _ eager migration _ , since entities are migrated in one go .    alas , for a popular interactive web - application , the right moment for migrating all entities may never come",
    ". moreover , a large - scale data store may contain legacy data that will never be accessed again , such as stale user accounts , blogposts that have become outdated , or offers that have expired . migrating this data",
    "may be a wasted effort , and expensive , when you are billed by your database - as - a - service provider for all data store reads and writes .    as an alternative",
    ", the developer community pursues what we call a _ lazy _ data migration strategy .",
    "entities of the old and new schema are allowed to co - exist .",
    "whenever an entity is read into the application space , it can be migrated . effectively",
    ", this will migrate only `` hot '' data that is still relevant to users .",
    "for instance , the objectify object mapper  @xcite has such support for google datastore  @xcite .",
    "however , all structure manipulations require custom code . as of today",
    ", there is no systematic way to statically analyze manipulations before executing them .",
    "moreover , from a database theory point - of - view , lazy migration is little understood ( if at all ) .",
    "this makes lazy migration a venture that , if applied incorrectly on production data , poses great risks .",
    "after all , once entities have been corrupted , there may be no way to undo the changes .",
    "[ [ desiderata . ] ] desiderata .",
    "+ + + + + + + + + + +    what is missing in today s frameworks is a means to systematically manage the schema of stored data , while at the same time maintaining the flexibility that a schema - less data store provides .",
    "what we certainly can not wish for is a rigorous corset that ultimately enforces a relational schema on nosql data stores .",
    "most systems do provide some kind of data store viewer , where single entities can be inspected , and even modified , or data can be deleted in bulk ( e.g.  @xcite ) . yet to the best of our knowledge , there is no schema management interface that would work _ across _ nosql systems from different providers , allowing application administrators to manage their data s structure systematically .",
    "this entails basic operations such as adding or deleting fields , copying or moving fields from one data structure to another . from studying the discussions in developer forums ,",
    "we have come to believe that these are urgently needed operations ( e.g.  @xcite to list just a few references ) .",
    "add , rename , and delete correspond to the capabilities of an `` alter table '' statement in relational databases .",
    "just as with relational databases , more complex data migration tasks would then have to be encoded programmatically .    yet in the majority of nosql databases , _ any _ data structure maintenance affecting more than one entity must be coded manually  @xcite .",
    "we still lack some of the basic tooling that one would expect in a nosql data store _ ecosystem _ , so that we may professionally maintain our production data in the long run .",
    "[ [ contributions . ] ] contributions .",
    "+ + + + + + + + + + + + + +    the goal of this work is to address this lack of tooling .",
    "we lay the foundation for building a generic schema evolution interface to nosql systems .",
    "such a tool is intended for developers , administrators , and software architects to declaratively manage the structure of their production data . to this end",
    ", we make the following contributions :    * we investigate the established field of schema evolution in the new context of schema - less nosql data stores . *",
    "we contribute a declarative _ nosql schema evolution",
    "language_. our language consists of a set of basic yet practical operations that address the majority of the typical cases that we see discussed in developer forums .",
    "* we introduce a generic _ nosql database programming language _ that abstracts from the apis of the most prominent nosql systems .",
    "our language clearly distinguishes the state of the persisted data from the state of the objects in the application space .",
    "this is a vital aspect , since the nosql data store offers a very restricted api , and data manipulation happens in the application code .",
    "* by implementing our schema evolution operations in our nosql database programming language , we show that they can be implemented for a large class of nosql data stores .",
    "* we investigate whether a proposed schema evolution operation is _ safe _ to execute . * apart from exploring _ eager _",
    "migration , we introduce the notion of _ lazy _ migration and point out its potential for future research in the database community .    [ [ structure . ] ] structure .",
    "+ + + + + + + + + +    in the next section , we start with an overview on the state - of - the - art in nosql data stores .",
    "section  [ sec : evolution ] introduces our declarative language for evolving the data and its structure . in section  [ sec : api ] , we define an abstract and generic nosql database programming language for accessing nosql data stores .",
    "the operations of our language are available in many popular nosql systems . with this formal basis",
    ", we can implement our schema evolution operations eagerly , see section  [ sec : encoding_evolution ] .",
    "alternatively , schema evolution can be handled lazily .",
    "we sketch the capabilities of object mappers that allow lazy migration in section  [ sec : lazy ] . in section  [ sec : related ] , we discuss related work on schema evolution in relational databases , xml applications , and nosql data stores .",
    "we then conclude with a summary and an outlook on our future work .",
    "we focus on nosql data stores hosted in a cloud environment .",
    "typically , such systems scale to large amounts of data , and are schema - less or schema - flexible .",
    "we begin with a categorization of popular systems , discussing their commonalities and differences .",
    "we then point out the nosql data stores that we consider in this paper with their core characteristics . in doing so",
    ", we generalize from proprietary details and introduce a common terminology .",
    "nosql data stores vary hugely in terms of data model , query model , scalability , architecture , and persistence design .",
    "several taxonomies for nosql data stores have been proposed .",
    "since we focus on schema evolution , a categorization of systems by data model is most natural for our purposes .",
    "we thus resort to a ( very common ) classification  @xcite into ( 1 )  key - value stores , ( 2 )  document stores , and ( 3 )  extensible record stores . often , extensible record stores are also called wide column stores or column family stores .    [",
    "[ key - value - stores . ] ] ( 1 ) key - value stores .",
    "+ + + + + + + + + + + + + + + + + + + + +    systems like redis  ( * ? ? ?",
    "* chapter  8) or riak  @xcite store data in pairs of a unique key and a value .",
    "key - value stores do not manage the structure of these values .",
    "there is no concept of schema beyond distinguishing keys and values .",
    "accordingly , the query model is very basic : only inserts , updates , and deletes by key are supported , yet no query predicates on values .",
    "since key - value stores do not manage the schema of values , schema evolution is the responsibility of the application .",
    "[ [ document - stores . ] ] ( 2 ) document stores .",
    "+ + + + + + + + + + + + + + + + + + + +    systems such as mongodb  @xcite or couchbase  @xcite also store key - value pairs .",
    "however , they store `` documents '' in the value part .",
    "the term `` document '' connotes loosely structured sets of name - value pairs , typically in json ( javascript object notation ) format or the binary representation bson , a more type - rich format of json .",
    "name - value pairs represent the properties of data objects .",
    "names are unique , and name - value pairs are sometimes even referred to as key - value pairs .",
    "the document format is hierarchical , so values may be scalar , lists , or even nested documents .",
    "documents within the same document store may differ in their structure , since there is no fixed schema .",
    "queries in document stores are more expressive than in key - value stores . apart from inserting , updating , and deleting documents based on the document key , we may query documents based on their properties .",
    "the query languages differ from system to system .",
    "some systems , such as mongodb , have an integrated query language for ad - hoc queries , whereas other systems , such as couchdb  ( * ? ? ?",
    "* chapter  6 ) and couchbase , do not .",
    "there , the user predefines views in form of mapreduce functions  @xcite .",
    "an interesting and orthogonal point is the behavior in evaluating predicate queries : when a document does not contain a property mentioned in a query predicate , then this property is not even considered in query evaluation .",
    "document stores are schema - less , so documents may effortlessly evolve in structure : properties can be added or removed from a particular document without affecting the remaining documents . typically , there is no schema definition language that would allow the application developer to manage the structure of documents globally , across all documents .",
    "[ [ extensible - record - stores . ] ] ( 3 ) extensible record stores .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + +    extensible record stores such as bigtable  @xcite or hbase  @xcite actually provide a loosely defined schema .",
    "data is stored as records .",
    "a schema defines families of properties , and new properties can be added within a property family on a per - record basis .",
    "( properties and property families are often also referred to as _ columns _ and _ column families_. ) typically , the schema can not be defined up front and extensible record stores allow the ad - hoc creation of new properties .",
    "however , properties can not be renamed or easily re - assigned from one property family to the other .",
    "so certain challenges from schema evolution in relational database systems carry over to extensible record stores .",
    "google datastore  @xcite is built on top of megastore  @xcite and bigtable , and is very flexible and comfortable to use .",
    "for instance , it very effectively implements multitenancy for all its users .",
    "the cassandra system  @xcite is an exception among extensible record stores , since it is much more restrictive regarding schema .",
    "properties are actually defined up front , even with a `` create table '' statement , and the schema is altered globally with an `` alter table '' statement .",
    "so while cassandra is an extensible record store  @xcite , it is not schema - less or schema - flexible . in this work",
    ", we will exclusively consider schema - less data stores .",
    "[ [ a - word - on - null - values . ] ] a word on null values .",
    "+ + + + + + + + + + + + + + + + + + + + + +    the handling of null values in nosql data stores deserves attention , as the treatment of unknown values is a factor in schema evolution . in relational database systems ,",
    "null values represent unknown information , and are processed with a three - valued logic in query evaluation .",
    "yet in nosql data stores , there is no common notion of nulls across systems :    * some systems follow the same semantics of null values as relational databases , e.g.  @xcite . *",
    "some systems allow for null values to be stored , but do not allow nulls in query predicates , e.g.  @xcite .",
    "* some systems do not allow null values at all , e.g.  @xcite , arguing that null values only waste storage .    while there is no common strategy on handling unknown values yet",
    ", the discussion is ongoing and lively .",
    "obviously , there is a semantic difference between a property value that is not known ( such as the first name for a particular user ) , and a property value that does not exist for a variant of an entity ( since home addresses and business addresses are structured differently ) .",
    "consequently , some nosql data stores which formerly did not support null values have introduced them in later releases  ( * ? ? ?",
    "* ; * ? ? ?",
    "* chapter  6 ) .    in section",
    "[ sec : api ] , we present a generic nosql data store programming language .",
    "as the approaches to handling null values are so manifold , we choose to disregard nulls as values and in queries , until a consensus has been established among nosql data stores .      in this paper , we investigate schema evolution for feature - rich , interactive web applications that are backed by nosql data stores .",
    "this makes document stores and schema - less extensible record stores our primary platforms of interest . since key - value stores",
    "do not know any schema apart from distinguishing keys and values , we believe they are not the technology of choice for our purposes ; after all , one can not even run the most basic predicate queries , e.g.  to find all blogs posted within the last ten hours .",
    "we assume a high - level , abstract view on document stores and extensible record stores and introduce our terminology .",
    "our terminology takes after google datastore  @xcite .",
    "we also state our assumptions on the data and query model .    [",
    "sec : terminology ]    [ [ data - model . ] ] data model .",
    "+ + + + + + + + + + +    objects stored in the nosql data store are called _ entities_. each entity belongs to a _",
    "kind _ , which is a name given to groups of semantically similar objects .",
    "queries can then be specified over all entities of the same kind .",
    "each entity has a unique _ key _ , which consists of the entity kind and an _ id_. entities have several _ properties _ ( corresponding to attributes in the relational world ) .",
    "each entity property consists of a _ name _ and a _",
    "value_. properties may be scalar , they may be multi - valued , or consist of nested entities .    [",
    "[ query - model . ] ] query model .",
    "+ + + + + + + + + + + +    entities can be inserted and deleted based on their key .",
    "we can formulate queries against all entities of a kind . at the very least ,",
    "we assume that a nosql data store supports conjunctive queries with equality comparisons .",
    "this functionality is commonly provided by document stores and extensible record stores alike .",
    "[ [ freedom - of - schema . ] ] freedom of schema .",
    "+ + + + + + + + + + + + + + + + + +    we assume that the global structure of entities can not be fixed in advance .",
    "the structure of a single entity can be changed any time , according to the developers needs .    _",
    "the blogging application example from the introduction is coherent with this terminology and these assumptions .",
    "in schema - less nosql data stores , there is no explicit , global schema . yet when we are building feature - rich , interactive web applications on top of nosql data stores",
    ", entities actually do display an implicit structure ( or schema ) ; this structure manifests in the entity kind and entity property names .",
    "this especially holds when object mappers take over the mundane task of marshalling objects from the application space into persisted entities , and back .",
    "these object mappers commonly map class names to entity kinds , and class members to entity properties .",
    "( we discuss object mappers further in the context of related work in section  [ sec : related ] . )",
    "thus , there is a large class of applications that use nosql data stores , where the data is _ somewhat _ consistently structured , but has no fixed schema in the relational sense .",
    "moreover , in an agile setting , these are applications that evolve rapidly , both in their features and their data . under these assumptions",
    ", we now define a compact set of declarative schema migration operations , that have been inspired by schema evolution in relational databases , and update operations for semi - structured data  @xcite .",
    "while we can only argue empirically , having read through discussions in various developer forums , we are confident that these operations cover a large share of the common schema migration tasks .",
    ".... evolutionop : : = add | delete | rename | move | copy ;    add : : = \" add \" property \" = \" value [ selection ] ;   delete : : = \" delete \" property [ selection ] ;   rename : : = \" rename \" property \" to \" pname [ selection ] ;   move : : = \" move \" property \" to \" kname [ complexcond ] ; copy : : = \" copy \" property \" to \" kname [ complexcond ] ;    selection : : = \" where \" conds ; complexcond : : = \" where \"   ( joincond | conds                              | ( joincond \" and \" conds ) ) ; joincond : : = property \" = \" property ; conds : : = cond { \" and \" cond } ; cond : : =   property \" = \" value ;    property : : = kname \" . \" pname ; kname : : = identifier ; pname : : = identifier ; ....    figure [ fig : ebnf ] shows the syntax of our _ nosql schema evolution language _ in extended backus - naur form ( ebnf ) .",
    "an evolution operation adds , deletes , or renames properties .",
    "properties can also be moved or copied .",
    "operations may contain conditionals , even joins .",
    "the property kinds ( derived from ` kname ` ) and the property names ( ` pname ` ) are the terminals in this grammar .",
    "we will formally specify the semantics for our operations in section  [ sec : encoding_evolution ] .",
    "for now , we discuss some examples to develop an intuition for this language .",
    "we introduce a special - purpose numeric property  `` version '' for all entities .",
    "the version is incremented each time an entity is processed by an evolution operator .",
    "this allows us to manage heterogeneous entities of the same kind .",
    "this is an established development practice in entity evolution .",
    "we begin with operations that affect all entities of one kind :    the add operation adds a property to all entities of a given kind .",
    "a default value may be specified ( see example  [ ex : add ] ) .",
    "the delete operation removes a property from all entities of a given kind ( see example  [ ex : delete ] ) .",
    "the rename operation changes the name of a property for all entities of a given kind ( see example  [ ex : rename ] ) .    _",
    "[ ex : add ] below , we show an entity from our blogpost example before and after applying operation * add blogpost.likes = 0*. this adds a likes - counter to all blogposts , initialized to zero .",
    "we chose a compact tabular representation of entities and their properties . _",
    "c c|c c    [ cols=\"<,<\",options=\"header \" , ]     section [ sec : encoding_evolution ] formalizes the semantics and investigates the effort of our migration operations . as a prerequisite , we next introduce a generic nosql database programming language .",
    "relational databases come with a query language capable of joins , as well as dedicated data definition and data manipulation language . yet in programming against nosql data stores , the application logic needs to take over some of these responsibilities .",
    "we now define the typical operations on entities in nosql data stores , building a purposeful nosql database programming language .",
    "our language is particularly modeled after the interfaces to google datastore  @xcite , and is applicable to document stores ( e.g.  @xcite ) as well as schema - less extensible record stores ( e.g.  @xcite ) .",
    "we consider system architectures such as shown in figure  [ fig : architecture ] .",
    "each user interacts with an instance of the application , e.g.  a servlet .",
    "typically , the application fetches entities from the data store into the application space , modifies them , and writes them back to the data store .",
    "we introduce a common abstraction from the current state of the data store and the objects available in the application space .",
    "we refer to this abstraction as the _ memory state_.    [ [ the - memory - state . ] ] the memory state .",
    "+ + + + + + + + + + + + + + + + +    we model a memory state as a set of mappings from entity keys to entity values .",
    "let us assume that an entity has key  @xmath1 and value  @xmath2 .",
    "then the memory contains the mapping from this key to this value : @xmath3 .",
    "keys in a mapping are unique , so a memory state does not contain any mappings @xmath4 and  @xmath5 with  @xmath6 .",
    "the entity value itself is structured as a mapping from property names to property values .",
    "a property value may be from an atomic domain  @xmath7 , either single - valued ( @xmath7 ) or multi - valued ( @xmath8 ) , or it may consist of the properties of a nested entity .    _ [ ex : single_entity ] we model a memory state with a single entity managing user data .",
    "the key is a tuple of kind _ user _ and the i d  @xmath9 .",
    "the entity value contains the user s login  `` hhiker '' and password  `` galaxy '' : @xmath10 .",
    "@xmath0 _    [ [ substitutions . ] ] substitutions .",
    "+ + + + + + + + + + + + + +    we describe manipulations of a memory state by substitutions .",
    "a substitution  @xmath11 is a mapping from a set  @xmath12 ( e.g.  the entity keys ) to a set  @xmath13 ( e.g.  the entity values ) and the special symbol  @xmath14 . to access  @xmath15 in a substitution @xmath16 ,",
    "we write  @xmath17 .",
    "if @xmath18 , then this explicitly means that this mapping is not defined .",
    "let  @xmath19 be the memory state , and let  @xmath11 be a substitution .",
    "in _ updating the memory state @xmath19 by substitution  @xmath11 _ , we follow a create - or - replace philosophy for each mapping in the substitution .",
    "we denote the updated memory by @xmath20 $ ] : @xmath21 = \\bigcup_{m \\in \\textit{ms}}(m[\\sigma]).\\ ] ] let @xmath22 , and let @xmath23 .",
    "then @xmath24 =   \\bigcup_{\\{b \\mapsto w\\ } \\in \\sigma } ( \\{a \\mapsto v\\}[\\{b \\mapsto w\\ } ] ) \\\\ & \\{a \\mapsto v\\}[\\{b \\mapsto w\\ } ] = \\left\\ {     \\begin{array}{l l }     \\{b \\mapsto w\\ } & a = b\\\\     \\{a \\mapsto v , b \\mapsto",
    "w\\ }   &   \\text{otherwise }    \\end{array } \\right.\\end{aligned}\\ ] ]    we further use the shortform @xmath25 $ ] to abbreviate the substitution with a single mapping  @xmath26 $ ] .",
    "_ we continue with example  [ ex : single_entity ] and abbreviate the key  @xmath27 by  @xmath28 . to delete the user s account",
    ", we update the memory state as @xmath29 \\\\ & =   \\{k \\mapsto \\bot\\}.\\end{aligned}\\ ] ] _    to mark the account as expired ( state `` x '' ) , we write @xmath30 ) \\ }   \\\\ & = \\ { k \\mapsto \\{\\textit{login } \\mapsto \\textit{``hhiker '' } , \\ ; \\textit{pwd } \\mapsto \\textit{``galaxy '' } , \\textit{state } \\mapsto \\textit{``x''}\\}\\}.\\end{aligned}\\ ] ] to change the user s password to `` g2 g '' , we write @xmath31 ) \\ }   \\\\ & = \\ { k \\mapsto \\{\\textit{login } \\mapsto \\textit{``hhiker '' } , \\ ; \\textit{pwd } \\mapsto \\textit{``g2g''}\\}\\}.\\end{aligned}\\ ] ] @xmath0    [ [ evaluating - operations . ] ] evaluating operations .",
    "+ + + + + + + + + + + + + + + + + + + + + +    operations may change the state of the data store and the application space .",
    "we call the former the _ data store state _ , and call the latter the _ application state_. we denote the impact of operations by rules of the form @xmath32 where @xmath33 denotes the operation to be executed on the data store state  @xmath34 and the application state  @xmath35 . by evaluating the operation , the data store state changes to @xmath36 , and the application state to @xmath37 .",
    "operations may be executed in sequence , which we define as @xmath38    let @xmath34 and @xmath35 be a data store state and an application state .",
    "let @xmath39 be entity keys .",
    "let @xmath40 be property names , and let @xmath41 be a property value .",
    "the symbol  @xmath14 denotes the undefined value .",
    "let @xmath42 be properties , i.e.  a set of mappings from property names to property values .",
    "@xmath43 is a function that extracts the entity kind from a key .",
    "@xmath44 is a conjunctive query , and @xmath45 is a string constant .",
    "@xmath46 ) \\label{sem : new}\\\\ \\llbracket \\mbox{new}(\\kappa , \\pi ) \\rrbracket(\\textit{ds } , \\textit{as } )   & =   ( \\textit{ds } , \\textit{as}[\\kappa \\mapsto \\pi ] ) \\label{sem : new_initialized}\\\\   \\llbracket \\mbox{setproperty}(\\kappa , n , v ) \\rrbracket(\\textit{ds } , \\textit{as } \\cup \\{\\kappa \\mapsto \\pi\\ } )   & = ( \\textit{ds } , \\textit{as } \\cup \\{\\kappa \\mapsto ( \\pi[n \\mapsto v])\\ } ) \\label{sem : setproperty } \\\\",
    "\\llbracket \\mbox{setproperty}(\\kappa , n",
    ", \\kappa ' ) \\rrbracket(\\textit{ds } , \\textit{as } \\cup \\{\\kappa \\mapsto \\pi\\ } \\cup \\{\\kappa ' \\mapsto \\pi'\\ } )   & = ( \\textit{ds } , \\textit{as } \\cup \\{\\kappa \\mapsto ( \\pi[n \\mapsto \\pi'])\\ } \\cup \\{\\kappa ' \\mapsto \\pi'\\ } ) \\label{sem : setproperty_nested } \\\\   \\llbracket \\mbox{removeproperty}(\\kappa ,",
    "n ) \\rrbracket(\\textit{ds } , \\textit{as } \\cup \\{\\kappa \\mapsto \\pi\\ } )   & = ( \\textit{ds } , \\textit{as } \\cup \\{\\kappa \\mapsto ( \\pi[n \\mapsto \\bot])\\ } ) \\label{sem : removeproperty } \\\\[1 mm ] \\llbracket \\mbox{put}(\\kappa ) \\rrbracket(\\textit{ds } , \\textit{as } \\cup \\{\\kappa \\mapsto \\pi\\ } )   & = ( \\textit{ds } [ \\kappa \\mapsto \\pi ] , \\textit{as } \\cup \\{\\kappa \\mapsto \\pi\\ } ) \\label{sem : put } \\\\",
    "\\llbracket \\mbox{delete}(\\kappa ) \\rrbracket(\\textit{ds } , \\textit{as } )   & = ( \\textit{ds } [ \\kappa \\mapsto \\bot ] , \\textit{as } ) \\label{sem : delete } \\\\",
    "\\llbracket \\mbox{get}(\\kappa ) \\rrbracket(\\textit{ds } \\cup \\{\\kappa \\mapsto \\pi\\ } , \\textit{as } )   & = ( \\textit{ds } \\cup \\{\\kappa \\mapsto \\pi\\ } , \\textit{as } [ \\kappa \\mapsto \\pi ] ) \\label{sem : get } \\\\[1 mm ] \\llbracket \\mbox{get}(\\textit{kind } = c ) \\rrbracket(\\textit{ds } , \\textit{as } ) &   =   ( \\textit{ds } , \\textit{as } [ \\{\\kappa \\mapsto \\pi \\mid \\kappa \\mapsto \\pi \\in \\textit{ds } \\land \\textit{kind}(\\kappa ) = c\\ } ] ) \\label{sem : query_kind}\\\\ \\llbracket \\mbox{get}(\\textit{kind } = c \\land \\theta ) \\rrbracket(\\textit{ds } , \\textit{as } )   & = ( \\textit{ds } , as [ \\ { \\kappa \\mapsto \\pi \\mid    \\kappa \\mapsto \\pi \\in \\textit{ds } \\land \\textit{kind}(\\kappa ) = c \\land \\llbracket \\theta \\rrbracket(\\kappa \\mapsto \\pi ) \\ } ] ) \\label{sem : query_theta } \\end{aligned}\\ ] ]      we next formalize operations common to most nosql data stores , namely creating and persisting entities , as well as retrieving and deleting single entities . figure  [ fig : semantics ] defines our operations .",
    "let @xmath47 be the set of entity kinds .",
    "let @xmath48 be a set denoting identifiers .",
    "the set of entity keys is defined as @xmath49 , i.e.  an entity key is a tuple of the kind and an identifier .",
    "entity properties are named .",
    "let @xmath50 be the set of property names .",
    "a property value can be either an atomic value from domain @xmath7 , multi - valued ( i.e.  from @xmath8 ) , or a nested entity .",
    "[ [ creating - entities . ] ] creating entities .",
    "+ + + + + + + + + + + + + + + + + +    we start with the rules to create entities and their properties .",
    "they affect the application state only .",
    "( for a change to have lasting effect , the entity must be persisted . )",
    "rule  [ sem : new ] creates a new entity with key  @xmath1 .",
    "initially , an entity does not have any properties . to also set initial properties , we can use rule  [ sem : new_initialized ] . rule  [ sem : setproperty ]",
    "adds a new property with name  @xmath51 and value  @xmath41 to the entity with key  @xmath1 . adding a nested entity as a property is specified in rule  [ sem : setproperty_nested ] .",
    "rule  [ sem : removeproperty ] removes the property with name  @xmath51 from the entity with key  @xmath1 : by setting the property value to  @xmath14 , the property by that name is no longer defined .",
    "[ [ persisting - entities . ] ] persisting entities .",
    "+ + + + + + + + + + + + + + + + + + + +    rule  [ sem : put ] persists the entity with key  @xmath1 , replicating this entity to the data store state .",
    "the put - operation replaces any entity by the same key , should one exist .",
    "rule  [ sem : delete ] deletes the entity with key  @xmath1 from the data store state .",
    "with rule  [ sem : get ] , we retrieve a particular entity by key from the data store state .    _ the following sequence of operations creates the entity from example  [ ex : single_entity ] and persists it in the data store . _    xxx = xxxxxx = new((``_user _ '' , @xmath9 ) ) ; + setproperty((``_user _ '' , @xmath9 ) , _ login _ , `` _ hhiker _ '' ) ; + setproperty((``_user _ '' , @xmath9 ) , _ pwd _ , `` _ galaxy _ '' ) ; + put((``_user _ '' , @xmath9 ) )    we evaluate the operations one by one on the initially empty data store and application state : @xmath52    @xmath0    [ [ accessing - entity - values . ] ] accessing entity values .",
    "+ + + + + + + + + + + + + + + + + + + + + + + +    to access a particular value of an entity , we introduce a dedicated operation .",
    "we consider all variables as in figure  [ fig : semantics ] , with  @xmath41 being a property value .",
    "if such a value exists , @xmath41 is either in @xmath8 or a set of properties ( from a nested entity ) : @xmath53 if property  @xmath51 is not defined for the entity with key  @xmath1 , calling  getproperty(@xmath1 , @xmath51 ) yields  @xmath14 .    _",
    "[ ex : update_nested_entity ] we illustrate nesting and unnesting of entities in close accordance with existing apis ( c.f .",
    "let @xmath1 be the key of an entity with a nested entity as property  @xmath51 . to add a further property  @xmath54 with value  @xmath55 to the nested entity",
    ", we unnest property  @xmath51 into a temporary entity .",
    "let @xmath56 be a new entity key .",
    "after modification and re - nesting , we can persist the changes .",
    "_    = get(@xmath1 ) ; + new(@xmath56 , getproperty(@xmath1 , @xmath51 ) ) ; _ // unnesting _",
    "+ setproperty(@xmath56 , @xmath54 , @xmath55 ) ; + setproperty(@xmath1 , @xmath51 , @xmath56 ) ; + put(@xmath1 )    @xmath0      given an entity key  @xmath1 , we define the function @xmath57 such that it returns the kind of this entity",
    ". then rule  [ sem : query_kind ] retrieves all entities from the store that are of the specified kind  @xmath45 .",
    "in addition to querying for a particular kind , we can also query with a predicate  @xmath44 , as described by rule  [ sem : query_theta ] .",
    "we consider conjunctive queries , with equality as the only comparison operator .",
    "this type of queries is typically supported by all of today s nosql data stores .",
    "various systems may even have more expressive query languages ( e.g.with additional comparison operators and support for disjunctive queries , yet typically no join ) .",
    "more precisely , @xmath44 is a conjunctive query over atoms of the form @xmath58 where @xmath51 is a property name and @xmath41 is a property value from @xmath7 .",
    "the predicate  @xmath44 is evaluated on one entity at - a - time .",
    "we evaluate an atom @xmath59 on a single entity : @xmath60 an atom involving  @xmath14 as an operand is always evaluated to false .",
    "queries over nested entities are not supported , e.g.  as in  @xcite .",
    "the evaluation of conjunctions follows naturally : @xmath61      for batch updates on entities , we define a for - loop .",
    "let  @xmath62 be a variable denoting an entity key , and let  @xmath33 denote an operation from our nosql database programming language .",
    "@xmath44 is a conjunctive query with atomic equality conditions .",
    "the operands in atoms are of the form  @xmath62 , @xmath63 , or  @xmath41 , where @xmath62 is a variable denoting a key , @xmath51 is a property name , and @xmath41 is a value from @xmath7 .",
    "we consider the execution of for - loops on a data store state  @xmath34 and an application state  @xmath35 : @xmath64 let @xmath65 be the result of evaluating query  @xmath44 , i.e.@xmath66 and let @xmath67 be the keys of all entities in the query result .",
    "we can then evaluate the for - loop as follows .    *",
    "while * ( @xmath68 * do * + = there exists some key @xmath1 in @xmath12 ; + @xmath69 ; + evaluate operation @xmath33 for the binding of  @xmath62 to key @xmath1 : + @xmath70\\ ; \\rrbracket        ( \\textit{ds } , \\textit{as})$ ] ; +    above , @xmath71 $ ] is obtained from operation  @xmath33 by first substituting each occurrence of  @xmath62 in  @xmath33 by  @xmath1 , and next replacing all operands @xmath72 in query predicates by the value of `` getproperty(@xmath73 ) '' .    _",
    "[ ex : safe_migrations ] we add a new property `` email '' to all user entities in the data store , and initialize it with the empty string  @xmath74 .",
    "_    * foreach * @xmath62 * in * get(@xmath75 ) * do * + = setproperty(@xmath76 , @xmath74 ) ; + put(@xmath62 ) +    since denormalization is vital for performance in nosql data stores , we show how to copy the property `` url '' from each user entity to all blogposts written by that user .",
    "* foreach * @xmath77 * in * get(@xmath78 ) * do * + * foreach * @xmath79 * in * get(@xmath80 ) * do * + = setproperty(@xmath79 , @xmath81 , getproperty(@xmath77 , @xmath81 ) ) ; + put(@xmath79 ) + * od + * od * *    @xmath0",
    "now that we have a generic nosql database programming language , we can implement the declarative schema evolution operations from section  [ sec : evolution ] .",
    "we believe the declarative operations cover common schema evolution tasks . for more complex migration scenarios",
    ", we can always resort to a programmatic solution .",
    "this matches the situation with relational databases , where an `` alter table '' statement covers the typical schema alterations , but where more complex transformations require an etl - process to be set up , or a custom migration script to be coded .",
    "figure  [ fig : implementing_operations_adr ] shows the implementation for the operations add , delete , and rename .",
    "a for - loop fetches all matching entities from the data store , modifies them , and updates their version property ( as introduced in section  [ sec : evolution ] ) .",
    "the updated entities are then persisted .",
    "figure  [ fig : implementing_operations_cm ] shows the implementation for copy and move .",
    "again , entities are fetched from the nosql data store one by one , updated , and then persisted .",
    "this requires joins between entities .",
    "since joins are not supported in most nosql data stores , they need to be encoded in the application logic .",
    "this batch update corresponds to the recommendation of nosql data store providers on how to handle schema evolution ( e.g.  @xcite ) .",
    "note that the create - or - replace semantics inherent in our nosql database programming language make for a _ well - defined _ behavior of operations .",
    "for instance , renaming the property `` text '' in blogposts to `` content '' ( c.f .",
    "example  [ ex : rename ] ) effectively overwrites any existing property named content .",
    "moreover , the version property added to all entities makes the migration _ robust _ in case of interruptions .",
    "nosql data stores commonly offer very limited transaction support .",
    "for instance , google datastore only allows transactions to span up to five entities in so - called _ cross - group transactions _ ( or alternatively , provides the concept of entity groups not supported in our nosql database programming language )  @xcite .",
    "so a large - scale migration can not be performed as an atomic action . by restricting migrations to all entities of a particular version ( using the where - clause ) ,",
    "we may correctly recover from interrupts , even for move and copy operations .",
    "interestingly , not all migrations that can be specified are desirable .",
    "for instance , assuming a 1:n relationship between users and the blogposts they have written , the result of the migration @xmath82 does not depend on the order in which blogpost entities are updated . however , if there is an n : m relationship between users and blogposts , e.g.  since we specify the copy operation as cross product between all users and all blogposts , @xmath83 then the execution order influences the migration result . naturally , we want to be able to know whether a migration is safe before we execute it .",
    "concretely , we say a migration is _ safe _ if it does not produce more than one entity with the same key .",
    "[ [ legend ] ] legend : + + + + + + +    let @xmath45 be a kind , let @xmath51 be a property name , and let @xmath41 be a property value from @xmath7 .",
    "@xmath44 is a conjunctive query over properties .",
    "+    * foreach * @xmath84 * in * get(@xmath85 ) * do * + = setproperty(@xmath84 , @xmath51 , @xmath41 ) ; + setproperty(@xmath84 , @xmath86 , getproperty(@xmath84 , @xmath86 ) @xmath87 ) ; + put(@xmath84 ) + * od *    * foreach * @xmath84 * in * get(@xmath85 ) * do * + = removeproperty(@xmath84 , @xmath51 ) ; + setproperty(@xmath84 , @xmath86 , getproperty(@xmath84 , @xmath86 ) @xmath87 ) ; + put(@xmath84 ) + * od *    * foreach * @xmath84 * in * get(@xmath85 ) * do * + = setproperty(@xmath84 , @xmath54 , getproperty(@xmath84 , @xmath51 ) ) ; + removeproperty(@xmath84 , @xmath51 ) ; + setproperty(@xmath84 , @xmath86 , getproperty(@xmath84 , @xmath86 ) @xmath87 ) ; + put(@xmath84 ) + * od *    [ [ legend-1 ] ] legend : + + + + + + +    let @xmath88 be kinds and let @xmath51 be a property name .",
    "conditions  @xmath89 and  @xmath90 are conjunctive queries .",
    "@xmath89 has atoms of the form @xmath91 , where @xmath54 is a property name and @xmath41 is a value from @xmath7 .",
    "@xmath90 has atoms of the form @xmath92 or @xmath93 , where @xmath94 , and @xmath54 are property names .",
    "@xmath41  is a value from @xmath7 .",
    "+    * foreach * @xmath84 * in * get(@xmath95 ) * do * + * foreach * @xmath96 * in * get(@xmath97 ) * do * + = setproperty(@xmath96 , @xmath51 , getproperty(@xmath84 , @xmath51 ) ) ; + setproperty(@xmath96 , @xmath86 , getproperty(@xmath96 , @xmath86 ) @xmath87 ) ; + put(@xmath96 ) + * od ; + setproperty(@xmath84 , @xmath86 , getproperty(@xmath84 , @xmath86 ) @xmath87 ) ; + removeproperty(@xmath84 , @xmath51 ) ; + put(@xmath84 ) + * od * *    * foreach * @xmath84 * in * get(@xmath95 ) * do * + * foreach * @xmath96 * in * get(@xmath97 ) * do * + = setproperty(@xmath96 , @xmath51 , getproperty(@xmath84 , @xmath51 ) ) ; + setproperty(@xmath96 , @xmath86 , getproperty(@xmath96 , @xmath86 ) @xmath87 ) ; + put(@xmath96 ) + * od + * od * *    the following propositions follow from the implementations of schema evolution operators in figures  [ fig : implementing_operations_adr ] and  [ fig : implementing_operations_cm ] .",
    "an add , delete , or rename operation is safe .    for a move or copy operation , and a data store state  @xmath34",
    ", the safety of executing the operation on  @xmath34 can be decided in @xmath98 .",
    "deciding whether a copy or move operation is safe can be done in a simulation run of the evolution operator .",
    "if an entity has already been updated in such a `` dry - run '' and is to be overwritten with different property values , then the migration is not safe .",
    "in relational data exchange , the existence of solutions for relational mappings under constraints is a highly related problem .",
    "there , it can be shown that while the existence of solutions is an undecidable problem per - se , for certain restrictions , the problem is ptime - decidable  ( c.f .",
    "corollary  2.15 in  @xcite ) .",
    "moreover , the vehicle for checking for solutions is the chase algorithm , which fails when equality - generating dependencies in the target schema are violated .",
    "this is essentially the same idea as our dry - run producing entities with the same key , but conflicting values .",
    "since our schema evolution operations copy and move require two nested for - loops , we can check for safety in quadratic time .",
    "( keeping track of which entities have already been updated can be done efficiently , e.g.  by maintaining a bit vector in the size of @xmath34 . )",
    "our nosql database programming language can also express operations for lazy migration . to illustrate this on an intuitive level , we encode some features of the objectify object mapper  @xcite .",
    "we will make use of some self - explanatory additional language constructs , such as if - statements and local variables .",
    "additionally , we assume an operation `` hasproperty(@xmath1 , @xmath51 ) '' that tests whether the entity with key  @xmath1 in the application state has a property by name  @xmath51 .    _",
    "the following example is adapted from the objectify documentation .",
    "it illustrates how properties are renamed when an entity is loaded from the data store and translated into a java object .",
    "_    the java class person is mapped to an entity .",
    "the annotation  ` @id ` marks the identifier for this entity , the entity kind is derived from the class name .",
    "the earlier version of this entity has a property `` name '' , which is now renamed to `` fullname '' .",
    "legacy entities do not yet have the property `` fullname '' .",
    "when they are loaded , the object mapper assigns the value of property `` name '' to the class attribute `` fullname '' .",
    "the next time that the entity is persisted , its new version will be stored .",
    "....     public class person {       @id long i d ;       @alsoload(\"name \" ) string fullname ;     } ....    in our nosql database programming language , we implement the annotation ` @alsoload ` as follows .",
    "= key @xmath99 : = @xmath100 ; + hasproperty(@xmath99 , @xmath101 ) * do *   + = setproperty(@xmath99 , @xmath102 , getproperty(@xmath99 , @xmath101 ) ) ; + removeproperty(@xmath99 , @xmath101 ) + * od *    @xmath0    _ the following example is adapted from  @xcite .",
    "the annotation ` @onload ` specifies the migration for an entity when it is loaded . if the entity has properties street and city , these properties are moved to a new entity storing the address .",
    "these properties are then discarded from the person entity when it is persisted ( specified by the annotation ` @ignoresave ` ) .",
    "saving an entity is done by calling the objectify function ` ofy().save ( ) ` . _    ....     public class person {       @id long i d ;       @ignoresave string street ;       @ignoresave string city ;          @onload void onload ( ) {         if ( this.street ! = null & & this.city ! = null ) {           entity a = new entity(\"address \" ) ;           a.setproperty(\"person \" , this.id ) ;           a.setproperty(\"street \" , this.street ) ;           a.setproperty(\"city \" , this.city ) ;           ofy().save().entity(a ) ;          }         }       } ....    we implement the method with annotation ` @onload ` as follows .",
    "= key @xmath99 : = @xmath100 ; + ( hasproperty(@xmath99 , @xmath103 ) @xmath104 hasproperty(@xmath99 , @xmath105 ) ) * do *   + = key @xmath106 = @xmath107 ; + new(@xmath106 ) ; + setproperty(@xmath106 , @xmath108 , @xmath109 ) ; + setproperty(@xmath106 , @xmath103 , getproperty(@xmath99 , @xmath103 ) ) ; + setproperty(@xmath106 , @xmath105 , getproperty(@xmath99 , @xmath105 ) ) ; + put(@xmath106 ) ; + removeproperty(@xmath99 , @xmath103 ) ; + removeproperty(@xmath99 , @xmath105 ) ; + * od *    @xmath0    it remains future work to explore lazy migrations in greater detail , and develop mechanisms to statically check them prior to execution : the perils of using such powerful features in an uncontrolled manner , on production data , are evident .",
    "lazy migration is particularly difficult to test prior to launch , since we can not foretell which entities will be touched at runtime .",
    "after all , users may return after years and re - activate their accounts , upon which the object mapper tries to evolve ancient data .",
    "it is easy to imagine scenarios where lazy migration fails , due to artifacts in the entity structure that developers are no longer aware of . in particular",
    ", we would like to be able to determine whether an annotation for lazy migration is safe . at the very least",
    ", we would like to check whether a lazy migration is _ idempotent _ , so that when transactions involving evolutions fail , there is no harm done in re - applying the migration .",
    "we define a nosql database programming language as an abstract interface for programming against nosql data stores . in recent work ,",
    "@xcite  present a calculus for nosql systems together with its formal semantics .",
    "they introduce a turing - complete language and its type system , while we present a much more restricted language with a focus on updates and schema evolution .    for relational databases ,",
    "the importance of designing database programming languages for strong programmability , concerning both performance and usability , has been emphasized in  @xcite .",
    "the language presented there can express database operators , query plans , and also capture operations in the application logic .",
    "however , the work there is targeted at query execution in relational databases , while we cover aspects of data definition and data manipulation in nosql data stores .",
    "moreover , we treat the data store itself as a black box , assuming that developers use a cloud - based database - as - a - service offering that they can not manipulate .",
    "all successful applications age with time  @xcite , and eventually require maintenance or evolution . typically , there are two alternatives to handling this problem on the level of schema : schema versioning and schema evolution .",
    "relational databases have an established language for schema evolution ( `` alter table '' ) .",
    "this schema definition language is part of the sql standard , and is implemented by all available relational databases systems .    for evolving xml - based applications ,",
    "research prototypes have been built that concentrate on the co - evolution of xml schemas and the associated xml documents  @xcite .",
    "the authors of  @xcite have developed a model driven approach for xml schema design , and support co - evolution between different abstraction levels . a dedicated language for xml evolution",
    "is introduced in  @xcite that formalizes xml schema change operations and describes the corresponding updates of associated xml documents .",
    "jsoniq is a quite new query language for json documents , the first version was published in april 2013 @xcite .",
    "future versions of jsoniq will contain an update facility and will offer operations to add , delete , insert , rename , and replace properties and values . our schema evolution language can be translated into corresponding update expressions . if jsoniq establishes itself as a standard for querying and updating nosql datastores , we can also base our schema evolution method on this language .",
    "the question whether an evolution is safe corresponds to the existence of ( universal ) solutions in data exchange .",
    "in particular , established practices from xml data exchange , using regular tree grammars to specify the source and the target schema  @xcite , are highly relevant to our work .",
    "the use of object mappers translating objects from the application space into persisted entities can be seen as a form of schema specification .",
    "this raises an interesting question : provided that all entities conform to the class hierarchy specified by an object mapper , if we evolve entities , will they still work with our object mapper ?",
    "this boils down to checking for absolute consistency in xml data exchange  @xcite , and is a current topic in database theory ( e.g.  @xcite ) .",
    "it is therefore part of our plans to see how we can leverage the latest research on xml data exchange for evolving data in schema - less data stores .",
    "there are various object - relational mapping  ( orm ) frameworks fulfilling well established standards such as the java persistence api  ( jpa ) , and supporting almost all relational database systems .",
    "some orm mappers are even supported by nosql data stores , of course not implementing all features , since joins or foreign - keys are not supported by the backend ( e.g.  see the  jpa and  jdo implementations for google datastore  @xcite ) .",
    "so far , there are only few dedicated mappers for persisting objects in nosql data stores ( sometimes called object - data - store mappers ( odm ) ) .",
    "most of today s odms are proprietary , supporting a particular nosql data store ( e.g.  morphia  @xcite for mongodb , or objectify@xcite for google datastore ) .",
    "few systems support more than one nosql data store ( e.g.  hibernate ogm  @xcite ) .    today , these objects - to - nosql mapping tools have at best rudimentary support for schema evolution .",
    "to the best of our knowledge , objectify and morphia go the furthest by allowing developers to specify lazy migration in form of object annotations .",
    "however , we could not yet find any solutions for systematically managing and expressing schema changes .",
    "at this point , the ecosystem of tools for maintaining nosql databases is still within its infancy .",
    "this work investigates the maintainability of feature - rich , interactive web applications , from the view - point of schema evolution .",
    "in particular , we target applications that are backed by schema - less _ document stores _ or _ extensible record stores_. this is an increasingly popular software stack , now that database - as - a - service offerings are readily available : the programming apis are easy to use , there is near to no setup time required , and pricing is reasonable .",
    "another sweet spot of these systems is that the data s schema does not have to be specified in advance .",
    "developers may freely adapt the data s structure as the application evolves . despite utter freedom",
    ", the data nevertheless displays an _",
    "implicit _ structure : the application class hierarchy is typically reflected in the persisted data , since object mappers perform the mundane task of marshalling data between the application and the data store .    as",
    "an application evolves , so does its schema . yet",
    "schema - free nosql data stores do not yet come with convenient schema management tools . as of today",
    ", virtually all data migration tasks require custom programming ( with the exception of very basic data inspection tools for manipulating _ single _",
    "entities ) .",
    "it is up to the developers to code the migration of their production data `` on foot '' , getting the data ready for the next software release .",
    "worse yet , with weekly releases , the schema evolves just as frequently .    in this paper , we lay the foundation for systematically managing schema evolution in this setting .",
    "we define a declarative _ nosql schema evolution language _ , to be used in a nosql data store administration console . using our evolution language , developers can specify common operations , such as adding , deleting , or renaming properties in batch .",
    "moreover , properties can be moved or copied , since data duplication and denormalization are fundamental in nosql data stores .",
    "we emphasize that we do not mean to enforce a relational schema onto nosql data stores .",
    "rather , we want to ease the pain of schema evolution for application developers .    we regard it as one of our key contributions that our operations can be implemented for a large class of nosql data stores .",
    "we show this by an implementation in a generic _ nosql database programming language_. we also discuss which operations can be applied safely , since non - deterministic migrations are unacceptable .",
    "our nosql schema evolution language specifies operations that are executed _ eagerly _ , on all qualifying entities .",
    "an alternative approach is to migrate entities _",
    "lazily _ , the next time they are fetched into the application space .",
    "some object mappers already provide such functionality .",
    "we believe that lazy evolution is still little understood , and at the same time poses great risks when applied erroneously",
    ". we will investigate how our nosql schema evolution language may be implemented both safely _ and _ lazily .",
    "ideally , a dedicated schema evolution management tool would allow developers to migrate data eagerly for leaps in schema evolution , and to patch things up lazily for minor changes ."
  ],
  "abstract_text": [
    "<S> nosql data stores are commonly schema - less , providing no means for globally defining or managing the schema . </S>",
    "<S> while this offers great flexibility in early stages of application development , developers soon can experience the heavy burden of dealing with increasingly heterogeneous data . this paper targets schema evolution for nosql data stores , the complex task of adapting and changing the implicit structure of the data stored . </S>",
    "<S> we discuss the recommendations of the developer community on handling schema changes , and introduce a simple , declarative schema evolution language . with our language , software developers and architects can systematically manage the evolution of their production data and perform typical schema maintenance tasks . </S>",
    "<S> we further provide a holistic nosql database programming language to define the semantics of our schema evolution language . </S>",
    "<S> our solution does not require any modifications to the nosql data store , treating the data store as a black box . </S>",
    "<S> thus , we want to address application developers that use nosql systems as database - as - a - service .    </S>",
    "<S> nosql data stores , schema evolution    api for data stores , schema evolution language , schema management , eager migration , lazy migration , schema versioning </S>"
  ]
}