{
  "article_text": [
    "with the development of internet , we have entered the era of big data .",
    "it is consequently a natural idea to leverage the large scale yet noisy data on the web for various vision tasks @xcite .",
    "methods of exploiting web images for automatically image dataset construction have recently become a hot topic @xcite in the field of multimedia processing .",
    "existing methods @xcite usually use an        [ fig : figure1 ]    iterative mechanism in the process of image selection , but these datasets tend to be statistically problematic because of the visual feature distribution of images selected in this way , which is known as the dataset bias problem @xcite .",
    "1 shows the  airplane \" images from four different image datasets .",
    "we observe some significant differences : pascal @xcite shows  airplanes \" from the flying viewpoint , while sun @xcite tends to show distant views at the airport ; caltech @xcite has a strong preference for side views and imagenet @xcite is rich in diversity , but mainly contains close - range views .",
    "classifiers learned from these datasets usually perform poorly in domain adaptation @xcite . to address this problem ,",
    "a large number of domain adaptation approaches that explicitly cope with the noisy labels of web images have been proposed for various vision tasks @xcite .",
    "the images are partitioned into a set of clusters ; each cluster is treated as a  bag \" and the images in each bag as  instances \" . as a result , these tasks can be formulated as a multi - instance learning ( mil ) problem , and different mil methods have been proposed in @xcite . however , the yield for all of these methods is limited by the restriction of diversity which provided by image search engine with a single query .    to obtain high accuracy and diverse candidate images , as well as to overcome the download restrictions of the image search engine , @xcite proposed the use of multiple query expansions instead of a single query to collect candidate images from the image search engine .",
    "the issue remains that these methods still use iterative mechanisms in the process of image selection , which leads to the dataset bias problem @xcite .",
    "motivated by the situation described above , we target the construction of an image dataset in a scalable way , while ensuring robustness and accuracy .",
    "the basic idea is to leverage multiple query expansions for the initial candidate image collection and to use mil methods for selecting images from different distributions . to obtain multiple query expansions ,",
    "we expand each query to a set of query expansions , which results in most of the noisy expansions being filtered out . after obtaining the raw image dataset with unfiltered query expansions ,",
    "mil methods are applied to filter individual and group noisy images . to verify the effectiveness of our proposed approach , we build an image dataset with 20 categories .",
    "we compare the image classification ability , cross - dataset generalization ability and dataset diversity of our dataset with three manually labelled image datasets , cifar-10 , stl-10 and imagenet , to demonstrate the domain robustness of our dataset .",
    "we also report the results of object detection on pascal voc 2007 , and then compare the object detection ability of our method with four baseline methods .",
    "our main contributions are summarized as follows :    [ 1 .",
    "] to the best of our knowledge , we are the first to propose the automatic construction of a domain - robust image dataset .",
    "our proposed approach , based on multiple query expansions and multi - instance learning , considers the source of candidate images and retains images from different distributions .",
    "the dataset constructed by our approach thus efficiently alleviates the dataset bias problem .",
    "[ 2 . ] to suppress the search error and unfiltered noisy query expansions induced noisy images , we formulate image selection as multi - instance learning problems and propose to solve the associated optimization problems by the cutting - plane and concave - convex procedure ( cccp ) algorithm , respectively .",
    "we have released our image dataset drid-20 on website : https://drive.google.com / drive / folders/0b7ds7afpuzt1bm pwcfrkcdzwuue?usp = sharing .",
    "we hope the diversity of drid-20 will offer unparalleled opportunities to researchers in the multi - instance learning , transfer learning , image dataset construction and other related fields .",
    "this paper is an extended version of @xcite .",
    "the extensions include : taking both bag level and instance level noisy images into account in the process of image selection instead of only instance level noisy images , we use a combination of bag level and instance level selection mechanisms and achieve better results ; comparing the image classification ability and dataset diversity of our dataset drid-20 with stl-10 , cifar-10 and imagenet ; and increasing the number of categories in the dataset from 10 to 20 , so that our dataset drid-20 covers all categories in the pascal voc 2007 dataset .",
    "the rest of the paper is organized as follows : in section 2 , a brief discussion of related works is given .",
    "the proposed algorithm including query expanding , noisy expansion filtering and noisy image filtering is described in section 3 .",
    "we evaluate the performance of the proposed algorithm against several other methods in section 4 .",
    "lastly , the conclusion and future work are offered in section 5 .",
    "given the importance of labelled image datasets in the area of high - level image understanding , many efforts have been directed toward image dataset construction . in general , these efforts can be divided into three principal categories : manual methods , semi - automatic methods and automatic methods .      in the early years , manual labelling was the most important way to construct image datasets .",
    "( e.g. , stl-10 @xcite , cifar-10 @xcite , pascal voc 2007 @xcite , imagenet @xcite and caltech-101 @xcite ) .",
    "the process of constructing these datasets mainly consists of submitting keywords to an image search engine to download candidate images , then cleaning these candidate images by manual annotation .",
    "this method has high accuracy but is labor intensive .",
    "to reduce the cost of manual labelling , a large number of works have focused on active learning ( a special case of semi - supervised method)@xcite@xcite@xcite .",
    "@xcite randomly labelled some seed images to learn visual classifiers .",
    "the learned visual classifiers were then implemented to conduct image classification on unlabelled images and find low confidence images for manual labelling . here",
    "low confidence images are those whose probability is classified into positive and negative close to 0.5 .",
    "the process is iterated until sufficient classification accuracy is achieved .",
    "@xcite presented an active learning framework to simultaneously learn contextual models for scene understanding tasks ( multi - class classification ) .",
    "@xcite presented an approach for on - line learning of object detectors , in which the system automatically refines its models by actively requesting crowd - sourced annotations on images crawled from the web .",
    "however , both manual labelling and active learning require pre - existing annotations , which often results in one of the most significant limitations to developing a large scale image dataset .",
    "automatic methods have attracted more and more attention to decrease the cost of manual annotation @xcite .",
    "@xcite adopted text information to re - rank images retrieved from a web search and used these top - ranked images to learn visual models to re - rank images once again .",
    "@xcite leveraged the first few images returned from an image search engine to train the image classifier , classifying images as positive or negative .",
    "when the image is classified as a positive sample , the classifier uses incremental learning to refine its model . with the increase in the number of positive images accepted by the classifier , the trained classifier will reach a robust level for this query .",
    "@xcite proposed the use of a clustering based method to filter `` group '' noisy images and a propagation - based method to filter individual noisy images .",
    "the advantage of these methods is that the need for manual intervention is eliminated .",
    "however , for methods @xcite , the domain adaptation ability is        limited by the restriction of the initial candidate images and the iterative mechanism in the process of image selection . to obtain high diversity candidate images , @xcite proposed the use of multiple query expansions instead of a single query in the process of collecting the initial candidate images , then using an iterative mechanism to filter noisy images .",
    "the automatic works discussed here mainly focus on accuracy and scale in the process of image dataset construction , which often results in poor performance on domain adaptation .",
    "there are many works related to the generation of query expansions and noisy image filtering , though they are not aimed at image dataset construction . since most image search engines restrict the number of images returned for each query , wordnet @xcite and conceptnet @xcite are often used to obtain synonyms to overcome the download restriction of these search engines .",
    "the advantage of wordnet and conceptnet is that synonyms are usually relevant to the given query and almost do not need to be purified .",
    "the disadvantage of wordnet and conceptnet is that both of them are usually not comprehensive enough for query expanding .",
    "worse , the images returned from an image search engine using synonyms tend to experience the homogenization problem , which results in poor performance on domain adaptation .",
    "recent works @xcite have proposed the use of google books ngram corpus ( gbnc ) @xcite to expand query to a set of query expansions .",
    "the google books ngrams corpus covers almost all related queries at the text level .",
    "it is much more general and richer than wordnet and conceptnet .",
    "the disadvantage of using gbnc for query expanding is that it may also generate noisy query expansions .",
    "recently , word embedding @xcite provides a learning - based method for computing the word - word similarity distance which can be used to filter noisy query expansions . in this paper",
    ", we use gbnc to expand the query to a set of query expansions , and then take both word - word and visual - visual similarity distance to filter noisy query expansions .    to efficiently ease the dataset bias problem , several authors have developed domain adaptation approaches for vision tasks . @xcite clustered relevant images using both textual and visual features . by treating each cluster as a  bag \" and the images in the bag as  instances \" , the authors formulated this problem as a multi - instance learning problem ( mil ) which learns a target decision function for image re - ranking . however , the yield is limited by the restriction placed on the initial candidate images obtained from the internet using a single query . in this paper",
    ", we focus on the mil method , as it retains images from different data distributions while filtering out noisy images .",
    "it can be anticipated that there will be more visual patterns ( responding to different query expansions ) in our work to represent the given query .",
    "in addition , mil methods are applied to filter group and individual noisy images to retain images from different distributions . in return , the constructed image dataset could achieve a better domain adaptation ability than traditional datasets constructed by a single query and an iterative mechanism .",
    "we seek to construct a domain robust image dataset which can be well generalized to unseen target domains . as shown in fig .",
    "2 , we propose three major steps for our web - supervised image dataset construction framework : query expanding , noisy expansion filtering and noisy image filtering . a set of semantically rich expansions are obtained by searching in the gbnc @xcite , from which the visually non - salient and less relevant expansions are filtered by exploiting both word - word and visual - visual similarity . after obtaining the candidate images by retrieving unfiltered expansions with the image search engine",
    ", we treat each unfiltered expansion as a  bag \" and the images in each bag as  instances \" .",
    "we then formulate this task as an mil problem with constrained positive bags . using this approach ,",
    "images from different data distributions will be kept while noisy images will be filtered out , and a domain robust image dataset will be constructed .",
    "image datasets constructed by existing methods tend to have high accuracy but usually have weak domain adaptation ability @xcite . to construct a domain - robust image dataset ,",
    "we expand the query ( e.g. , `` horse '' ) to a set of query expansions ( e.g. , `` jumping horse , walking horse , roaring horse '' ) and then use these different query expansions ( corresponding images ) to reflect the different  visual patterns \" of the query .",
    "we use gbnc to discover query expansions for the given query with parts - of - speech ( pos ) , specifically with noun , verb , adjective and adverb .",
    "our motivation is to identify all related query expansions .",
    "gbnc is much more general and richer than wordnet @xcite and conceptnet @xcite .",
    "using gbnc can help us to find all the expansions ever published for any possible query .      through query expanding , we obtain a comprehensive semantic description for the given query .",
    "however , query expanding not only brings all the useful query expansions , but also some noisy query expansions .",
    "these noisy query expansions can be roughly divided into two types : ( 1 ) visual non - salient ( e.g. , `` betting horse '' ) and ( 2 ) less relevant ( e.g. , `` sea horse '' ) . using these noisy query expansions to retrieve images will have a negative impact on dataset accuracy and robustness .      from the visual perspective , we want to identify visually salient query expansions and eliminate non - salient query expansions in this step .",
    "the intuition is that visually salient expansions should exhibit predictable visual patterns , hence we use an image classifier - based filtering method . for each query expansion ,",
    "we directly download the top @xmath0 images from the google image search engine as positive images ( based on the fact that the top few images returned from image search engine tend to be positive ) , then randomly split these images into a training set and validation set @xmath1 .",
    "we gather a random pool of negative images and split them into a training set and validation set @xmath2 .",
    "we train a linear support vector machine ( svm ) classifier @xmath3 with @xmath4 and @xmath5 using dense histogram of oriented gradients ( hog ) features .",
    "we then use @xmath6 as validation images to calculate the classification results .",
    "we declare a query expansion @xmath7 to be visually salient if the classification results @xmath8 give a relatively high score .      from the relevance perspective , we want to identify both semantically and visually relevant expansions for the given query .",
    "the intuition is that relevant expansions should have a relatively small semantic and visual distance , therefore we use a combined word - word and visual - visual similarity distance - based filtering method .    words and phrases acquire meaning from the way they are employed in society . for computers , the equivalent of `` society '' is `` database '' , and the equivalent of `` use '' is `` a way to search the database '' @xcite .",
    "normalized google distance ( ngd ) constructs a method to extract semantic similarity distance from the world wide web ( www ) using google page counts @xcite . for a search term @xmath9 and search term @xmath10 ,",
    "ngd is defined by : @xmath11 where @xmath12 denotes the number of pages containing @xmath9 , @xmath13 denotes the number of pages containing both @xmath9 and @xmath10 and @xmath0 is the total number of web pages searched by google .",
    "we denote the semantic distance of all query expansions by a graph @xmath14 in which each node represents a query expansion and its edge represents the @xmath15 between the two nodes .",
    "we set the target query as center ( x ) and other query expansions have a score ( @xmath16 ) which corresponds to the distance to the target query .",
    "similarly , we represent the visual distance of the query and expansions by a graph @xmath17 in which each node represents a query expansion and each edge represents the visual distance between the query and the expansions .",
    "the feature is a 1000 dimensional bag of visual words based on sift features .",
    "the edge weight @xmath18 corresponds to the euclidean distance .",
    "the semantic distance and visual distance will be used to construct a new two - dimensional feature @xmath19}$ ] .",
    "the problem is to calculate the importance weight @xmath20 and bias penalty @xmath21 in decision function @xmath22 to determine whether or not the expansion is relevant .",
    "there are many methods of obtaining these coefficients @xmath20 and @xmath21 . here",
    "we take linear svm to work around this problem .",
    "although linear svm is not the prevailing state - of - the - art method for classification , we find our method to be effective in pruning irrelevant query expansions .",
    "unfiltered expansions are then used to retrieve the top @xmath23 images from the image search engine to construct the raw image dataset .",
    "regardless of the fact that our method is unable to remove noisy expansions thoroughly in most cases , the raw image dataset constructed by our method still achieves much higher accuracy than directly using the flickr or google image data . besides",
    ", the raw image dataset constructed through unfiltered query expansions has much richer visual patterns .",
    "although the google image search engine ranks the returned images , several noisy images are still included . in addition , a few unfiltered noisy expansions will also bring noisy images to the raw image dataset .",
    "in general , these noisy images can be divided into two types : group noisy images ( caused by unfiltered noisy expansions ) and individual noisy images ( as a result of the error index of the image search engine ) . to filter these group and individual noisy images while retaining the images from different distributions , we use mil methods instead of an iterative mechanism in the process of noisy image filtering .    by treating each unfiltered expansion as a  bag \" and the images corresponding to the expansion as  instances \" , we formulate a multi - instance learning problem by selecting a subset of bags and a subset of images from each bag to construct a domain robust image dataset for the given query .",
    "since the precision of images returned from the google image search engine tends to have relatively high accuracy , we define each positive bag as at least having a portion of @xmath24 positive instances which effectively filter group noisy images caused by unfiltered noisy query expansions .",
    "we denote each instance as @xmath25 with its label @xmath26 , where i=1, ... ,n .",
    "we also denote the label of each bag @xmath27 as @xmath28 .",
    "the transpose of a vector or matrix is represented by superscript @xmath29 and the element - wise product between two matrices is represented by @xmath30 .",
    "we define the identity matrix as @xmath31 and @xmath32 , @xmath33 @xmath34 denote the column vectors of all zeros and ones , respectively .",
    "the inequality @xmath35{}'\\geq \\mathbf{0}}$ ] means that @xmath36 for i=1, ... ,n .",
    "the decision function for filtering individual noisy images is assumed in the form of @xmath37 and has to be learned from the raw image dataset .",
    "we employ the formulation of lagrangian svm , in which the square bias penalty @xmath38 and the square hinge loss for each instance are used in the objective function .",
    "the decision function can be learned by minimizing the following structural risk function : @xmath39 @xmath40 @xmath41 where @xmath42 is a mapping function that maps @xmath9 from the original space into a high dimensional space @xmath43 , @xmath44 is a regularization parameter and @xmath45 values are slack variables .",
    "the margin separation is defined as @xmath46 .",
    "@xmath47{}'}$ ] means the vector of instance labels , @xmath48 and @xmath49 satisfies constraint ( 4 ) . by introducing a dual variable @xmath50 for inequality constraint ( 3 ) and kernel trick @xmath51",
    ", we arrive at the optimization problem below : @xmath52 where @xmath53 , @xmath54 and @xmath55{}'$ ] . by defining @xmath56}$ ] as a @xmath57 kernel matrix , @xmath58 and @xmath59 as a",
    "@xmath57 transformed kernel matrix for the augmented feature mapping @xmath60{}'}$ ] of kernel @xmath61 .",
    "( 5 ) can be rewritten as follows : @xmath62 ( 6 ) is a mixed integer programming problem with respect to the instance labels @xmath63 .",
    "we take the label - generating    initialize @xmath64 for @xmath65 as @xmath66 , and set @xmath67 ; + use mkl to solve @xmath68 and @xmath69 in ( 10 ) with @xmath70 ; + select most violated @xmath71 with @xmath72 and set @xmath73 ; + repeat step 2 and step 3 until convergence .",
    "+    mmc ( lg - mmc ) algorithm proposed in @xcite to solve this mixed integer programming problem .",
    "we first consider interchanging the order of @xmath74 and @xmath75 in ( 6 ) and obtain : @xmath76    according to the minmax theorem @xcite , the optimal objective of ( 6 ) is an upper bound of ( 7 ) .",
    "we rewrite ( 7 ) as : @xmath77 @xmath71 is any feasible solution in @xmath78 . for the inner optimization sub - problem ,",
    "let @xmath79 be the dual variable for inequality constraint .",
    "its lagrangian can be obtained as : @xmath80 setting the derivative of ( 9 ) with respect to @xmath81 to zero , we have @xmath82 .",
    "@xmath83 is denoted as the domain of @xmath69 , where @xmath69 is the vector of @xmath84 .",
    "the inner optimization sub - problem is replaced by its dual and ( 8) can be rewritten as : @xmath85 or @xmath86 here , we can interchange the order of @xmath87 and @xmath88 because the objective function is concave in @xmath89 and convex in @xmath69 .",
    "additionally , ( 10 ) can be regarded as a multiple kernel learning ( mkl ) problem @xcite , and the target kernel matrix is a convex combination of base kernel matrices @xmath90 . although @xmath78 is finite and ( 10 ) is an mkl problem , we can not directly use existing mkl techniques like @xcite to solve this problem .",
    "the reason is that the exponential number of possible labellings @xmath91 and the fact that the base kernels are also exponential in size make direct mkl computations intractable .",
    "fortunately , not all the constraints in ( 8) are active at optimality , thus we can employ a cutting - plane algorithm @xcite to find a subset @xmath92 of the constraints that can well approximate the original optimization problem .",
    "the detailed solutions of the cutting - plane algorithm for ( 10 ) are described in algorithm 1 .",
    "finding the most violated constraint @xmath71 is the most challenging aspect of the cutting - plane algorithm . according to ( 5 ) ,",
    "the most violated @xmath71 is equivalent to the following optimization problem : @xmath93 we solve this integer optimization problem by enumerating all possible candidates of @xmath71 . here",
    "we only enumerate the possible labelling candidates of the instances in positive bags as all instances in the negative bags are assumed to be negative in our paper .",
    "lastly , we can derive the decision function from the raw image dataset for the given query as : @xmath94 where @xmath95 and @xmath96 .",
    "the decision function will be used to filter individual noisy images in each bag which correspond to unfiltered query expansions .",
    "to filter group noisy images ( caused by unfiltered noisy expansions ) , we represent bag @xmath27 with the compound feature @xmath97 of its first @xmath98 positive instances : @xmath99 with @xmath100 we refer to the instances in @xmath101 as the first @xmath98 instances of @xmath27 according to classifier @xmath102 ( see equation 12 ) .",
    "the closer the images in @xmath27 are to the bag centre , the higher is the probability that these images will be relevant to the bag .",
    "the assignment of relatively heavier weights to images which are a short distance from the bag centre will increase the accuracy of classifying bag @xmath27 as positive or negative , then increase the efficiency of filtering noisy group images .",
    "following @xcite , we assume @xmath103^{-1}}$ ] to be a weighting function , @xmath104 represents the euclidean distance of images @xmath25 from the bag centre , @xmath105 and @xmath106 are scaling and offset parameters which can be determined by cross - validation .",
    "the representation of ( 13 ) for bag @xmath27 can be generalized to a weighted compound feature : @xmath107 with @xmath108 where @xmath109\\in \\mathbb{r}^{d\\times i}}$ ] is a matrix whose columns are the instances of bag @xmath27 , @xmath110^{t}\\in \\mathbb{r}_{++}^{i}}$ ] are the vectors of weights , and @xmath111 is an indicator function for the first k positive instances of bag @xmath27 .",
    "then classifying rule of bag @xmath27 to be positive or negative is : @xmath112 where @xmath113 is the vector of classifying coefficients , @xmath114 is the feature vector of ( 15 ) , @xmath115 is a vector of latent variables and @xmath116 is the hypothesis space @xmath117 .",
    "the learning problem is to determine the parameter vector @xmath118 .",
    "initialize @xmath118 with svm by setting @xmath119 ; + compute a convex upper bound using the current model for the second term of ( 21 ) ; + minimize this upper bound by solving a structural svm problem via the proximal bundle method @xcite ; + repeat step 2 and step 3 until convergence .",
    "+    given a training set @xmath120 , this is a latent svm learning problem : @xmath121    before solving ( 18 ) , we first solve the classifying rule of ( 17 ) .",
    "it is necessary to solve the below following problem : @xmath122 this is an integer linear - fractional programming problem .",
    "since @xmath123 , ( 19 ) is identical to the relaxed problem : @xmath124    where @xmath125^i}$ ] is a unit box in @xmath126 .",
    "( 20 ) is a linear - fractional programming problem and can be reduced to a linear programming problem of @xmath127 variables and @xmath128 constraints @xcite .    in this work , we take the concave - convex procedure ( cccp ) @xcite to solve ( 18 ) .",
    "we rewrite the objective of ( 18 ) as two convex functions :    @xmath129-\\left [ c\\sum_{i\\in d_{p } } f_\\omega \\left ( x_{b_i } \\right ) \\right ] } \\\\ \\end{aligned}\\ ] ]    where @xmath130 and @xmath131 are positive and negative training sets respectively .",
    "the detailed solutions of the cccp algorithm for ( 21 ) are described in algorithm 2 .",
    "lastly , we obtain the bag classifying rule as ( 17 ) to filter group noisy images which correspond to unfiltered noisy query expansions .    in summary ,",
    "the existing automatic methods reduce the cost of manual annotation by leveraging the generalization ability of machine learning models . however , this generalization ability is affected by both the quality of the initial candidate images and the capability of models to retain images from different distributions .",
    "previous works largely focus on accuracy and scale , and most use an iterative mechanism for the image selection process which often results in the dataset bias problem . to the best of our knowledge , we are the first to propose the automatic construction of a domain - robust image dataset .",
    "we achieve the domain adaptation ability of our dataset by maximizing both the initial candidate images and the final selected images from different data distributions .",
    "since the datasets for existing dataset construction methods @xcite have not been released , we are unable to directly compare our dataset with their extracted datasets .",
    "we therefore systematically compare the image classification ability , cross - dataset generalization ability and dataset diversity of our dataset with three publicly available datasets stl-10 , cifar-10 and imagenet .",
    "the motivation is to verify that a domain - robust image dataset has a better image classification ability on third - party datasets , and to confirm that a domain - robust image dataset has better cross - dataset generalization ability and dataset diversity .",
    "we also report the object detection ability of our dataset and compare our method with four baseline methods @xcite .      to facilitate comparison with datasets stl-10 , cifar-10 and imagenet , we choose common categories in these datasets : airplane / aeroplane , bird , cat , dog , horse to construct our dataset .",
    "we also select 15 other categories in pascal voc 2007 to construct our dataset , since most of the existing weakly supervised and web - supervised learning methods are tested on the pascal voc 2007 dataset .",
    "overall , we use the proposed method in this paper to build our dataset , drid-20 , which consists of all 20 categories in the pascal voc 2007 dataset .    for each given query ( e.g.,horse \" ) in our experiments ,",
    "we first expand the given query to a set of query expansions with pos .",
    "to filter visual non - salient expansions , we retrieve the top @xmath132 images from the image search engine as positive images ( in spite of the fact that noisy images might be included ) . set the training set and validation set @xmath133 , @xmath134 . through experiments ,",
    "we declare a query expansion @xmath7 to be visually salient if the classification results ( @xmath135 ) return a relatively high score .",
    "we have released the query expansions for twenty categories and corresponding images ( original image url ) on website : https://drive.google.com/drive/folders/0b7ds7afpuzt1bmpwc frkcdzwuue?usp = sharing .",
    "to filter less relevant expansions , we select @xmath136 positive training samples from these expansions that have a small semantic or visual distance from these expansions .",
    "we calculate the semantic distance and visual distance between different queries ( e.g. , `` horse '' and `` cow '' ) and obtain the @xmath137 negative training samples .",
    "we do not select the @xmath137 negative training samples from expansions which have a large semantic or visual distance because these expansions have a higher probability of being positive than other different query expansions . here , we set @xmath138 and train a classifier based on linear svm to filter less relevant expansions .    the first @xmath139 ( for category `` plant '' expansions , @xmath140 ) images are retrieved from the google image search engine for each unfiltered query expansion to construct the raw image dataset .",
    "we treat unfiltered query expansions as positive bags and images in bags as instances .",
    "we define each positive bag as having at least a portion of @xmath141 positive instances .",
    "negative bags can be obtained by randomly sampling a few irrelevant images that are not associated with the given query .",
    "mil methods are applied to learn the decision function ( 12 ) , and the individual noisy images in each bag are filtered .",
    "the decision function of ( 12 ) is also used to select the most @xmath98 positive instances in each bag , representing this bag for group noisy image filtering .",
    "the value of @xmath98 for different categories may be different .",
    "in general , categories which have larger query expansions tend to select a smaller value .",
    "there are multiple methods for learning the weighting function ( e.g. , logistic regression or cross - validation ) , here we follow @xcite and use cross - validation to learn the weighting function .",
    "we label 10 datasets , each containing 100 positive bags and 100 negative bags .",
    "the positive bags and negative bags each have 50 images .",
    "labelling only needs to be carried out once to learn the weighting function and weighted bag classification rule ( 17 ) . the learned weighted bag classification rule ( 17 )",
    "will be used to filter noisy bags ( corresponding to group noisy images ) . for better comparison with other datasets",
    ", we evenly select positive images from positive bags to construct the dataset drid-20 .",
    "each category in drid-20 has 1000 images , and this dataset has been released publicly on website .",
    "p2.2cm<|p1cm<|p0.7cm<|p0.7cm<|p0.7cm<|p0.7 cm < dataset @xmath142 category & airplane & bird & cat & dog & horse + stl-10 & 1300 & 1300 & 1300 & 1300 & 1300 + cifar-10 & 6000 & 6000 & 6000 & 6000 & 6000 + pascal voc & 238 & 330 & 337 & 421 & 287 + imagenet & 1434 & 2126 & 1083 & 1603 & 1402 + drid-20 & 1000 & 1000 & 1000 & 1000 & 1000 +      for dataset image classification ability , cross - dataset generalization ability and dataset diversity comparison , we select five common categories in stl-10 , cifar-10 , pascal voc 2007 , imagenet and drid-20 . for object detection ability comparison",
    ", we use all 20 categories in the drid-20 dataset and pascal voc 2007 .",
    "stl-10 has ten categories , and each category of which contains 500 training images and 800 test images .",
    "all of the images in stl-10 are colour 96@xmath14396 pixels .",
    "we use all the training images and test images in stl-10 to represent the dataset .",
    "the cifar-10 dataset consists of 60000 32@xmath14332 colour images in 10 categories , with 6000 images per category , of which 5000 are training images and 1000 are test images .",
    "similarly , we use all 6000 images in cifar-10 to represent the dataset .",
    "imagenet is an image dataset organized according to the wordnet @xcite hierarchy .",
    "it provides on average 1000 images to illustrate each category .",
    "we use all the images in imagenet for each category to represent the imagenet dataset .",
    "pascal voc 2007 is a benchmark dataset in image classification and object detection which provides the vision and machine learning communities with a standard dataset of images and evaluation procedures .",
    "pascal voc 2007 contains 20 categories , each of which contains training / validation data and test data . for image classification ability , cross - dataset generalization ability and dataset diversity comparison",
    ", we utilize the training / validation data to represent the pascal voc 2007 dataset .",
    "our dataset drid-20 is constructed according to the categories in pascal voc 2007 and has 1000 images in each category . to evaluate the image classification ability , cross - dataset generalization ability and dataset diversity , we resize all the images in stl-10 , imagenet , pascal voc 2007 and our drid-20 to 32@xmath14332 . for all    [ t ]    [ fig : roi_seg_10000_result ]    datasets",
    ", we extract the same histogram of oriented gradient ( hog ) feature and train one - versus - all classifiers .",
    "the detailed number of images in each category for above mentioned experiments is shown in table 1 .",
    "the idea of training detection models without bounding boxes has received renewed attention due to the success of the dpm @xcite detector . to compare the object detection ability of our method with four other baseline methods @xcite , we select pascal voc 2007 as the test data , because recent state - of - the - art weakly supervised and web - supervised methods have been evaluated on this dataset .    for each query expansion , we train a separate dpm to constrain the visual variance .",
    "we resize images to a maximum of 500 pixels and ignore images with extreme aspect ratios ( aspect ratio @xmath144 2.5 or @xmath145 0.4 ) . to avoid getting stuck to the image boundary during the latent re - clustering step , we initialize our bounding box to a sub - image within the image that ignores the image boundaries .",
    "following @xcite , we also initialize components using the aspect - ratio heuristic .",
    "some of the components across different query expansion detectors ultimately learn the same visual pattern .",
    "for example , the images corresponding to the query expansion  walking horse \" are similar to the images corresponding to  standing horse \" . in order to select a representative subset of the components and merge similar components , we represent the space of all query expansions components by a graph @xmath146 , in which each node represents a component and each edge represents the visual similarity between them .",
    "the score @xmath147 for each node corresponds to the average precision .",
    "the weight on each edge @xmath148 is obtained by running the @xmath149 component detector on the @xmath150 component set .",
    "we solve for the same objective function proposed in @xcite to select the representative components @xmath151 : @xmath152 where @xmath153 is a soft coverage function that implicitly pushes for diversity : @xmath154    [ t ]    after the representative subset of components has been obtained , we augment them with method as described in @xcite and subsequently merge all the components to produce the final detector .",
    "we choose pascal voc 2007 as the third - party test data for comparing the image classification ability of our dataset drid-20 with stl-10 , cifar-10 and imagenet . for this experiment , we select five categories that are common to all these datasets : airplane / aeroplane , bird , cat , dog and horse .",
    "we randomly select training images from various datasets for our choice of positive training images .",
    "we choose the same 1000 negative training images for all datasets . for details , we sequentially select [ 200,400,600,800,1000 ] training images from cifar-10 , stl-10 , imagenet and drid-20 as the positive training images , and use 1000 fixed negative training images to learn the image classifiers .",
    "we then test the performance of these classifiers on the corresponding categories of the pascal voc 2007 dataset .",
    "we repeat the above experiment 10 times and use the average performance of image classifiers as the final performance for each dataset .",
    "the image classification ability of all datasets for each category and the entire dataset is shown in figure 3 .",
    "we make the following observations from fig . 3 :    \\(1 ) it is interesting to observe that the category ",
    "airplane \" has a relatively higher classification accuracy than the categories  bird \" ,  cat \" ,  dog \" and  horse \" with a small amount of training data [ 200,400 ] .",
    "a possible explanation is that the scenes and visual patterns of  airplane \" are relatively simpler than the categories  bird \" ,  cat \" ,  dog \" and  horse \" .",
    "even with a small amount of training data , there are still a large number of positive patterns in both auxiliary and target domains .",
    "that is to say , the samples are densely distributed in the feature space , and the distribution of the two domains overlap much more easily . on the other hand ,",
    "the positive samples from both domains for the categories  bird \" ,  cat \" ,  dog \" and  horse \" are distributed sparsely in the feature space .",
    "it is likely that there will be less overlap of the data distributions of the two domains .",
    "\\(2 ) cifar-10 exhibits much worse performance on image classification than stl-10 , imagenet and drid-20 according to the accuracy over all five common categories , which demonstrates that the svm classifier learned with training data from the auxiliary domain performs poorly on the target domain .",
    "the explanation is perhaps that the data distributions of cifar-10 are quite different from those of the pascal voc 2007 dataset .",
    "the cifar-10 dataset has a more serious dataset bias problem than stl-10 , imagenet and drid-20 .",
    "\\(3 ) we also observe that imagenet is slightly worse than drid-20 in each individual category and in the whole dataset , possibly because the distribution of samples from imagenet is relatively rich .",
    "imagenet is constructed with the goal that objects in images should have variable appearance , positions ,    [ t ]    view points , and poses , as well as background clutter and occlusions .",
    "\\(4 ) drid-20 outperforms cifar-10 , stl-10 and imagenet in terms of average accuracy in five common categories , which demonstrates the domain robustness of drid-20 .",
    "the explanation is that drid-20 constructed by multiple query expansions and mil selecting mechanisms has much more visual patterns than cifar-10 , stl-10 and imagenet when given the same number of training samples . in other words",
    ", drid-20 has much richer feature distribution and is more easily overlapped with unknown target domains .",
    "we also report the hardware configuration of our experiment .",
    "we use hp desktop pcs ( 3.2ghz cpu with 8 gbyte ram ) for the image collection .",
    "all the data processing and experiments are performed on an acer workstation ( 3.5ghz cpu , 16 gbyte ram and 4 gbyte vram ) with libsvm @xcite .",
    "cross - dataset generalization ability measures the performance of classifiers learned from one dataset and tested on other datasets .",
    "it indicates the domain robustness of dataset @xcite .",
    "here we compare the cross - dataset generalization ability of our dataset drid-20 with three publicly available dataset cifar-10 , stl-10 and imagenet .",
    "we choose the same five categories ( horse , bird , airplane , cat and dog ) included in all four datasets to verify their cross - dataset generalization ability .",
    "we randomly select 200 images per category from each dataset as the test data . for the choice of training data , we sequentially select [ 200,300,400,500,600,700,800 ] images per category from various datasets as the positive training images and use 1000 fixed negative training images to learn the image classifiers .",
    "the training images in each category are selected randomly and the training images and test images have no duplicates .",
    "the average classification accuracy for five categories ( horse , bird , airplane , cat and dog ) represents the cross - dataset generalization ability of one dataset on another dataset .",
    "when training the image classification model , we set the same options for four datasets ; we set the type of svm as c - svc , the type of kernel as a radial basis function and all other options as the default libsvm options .",
    "the cross - dataset performance of the four datasets and their average performance is shown in figure 4 .    by observing figure 4 , we draw the following conclusions :    \\(1 ) in three of four datasets , the best classification performance with the increase in the number of training images is achieved by drid-20 .",
    "when tested on stl-10 , imagenet and drid-20 , it can be seen that the generalization ability of stl-10 , imagenet and our dataset drid-20 is very close , but drid-20 performs slightly better than stl-10 and imagenet .",
    "in addition , drid-20 outperforms cifar-10 , stl-10 and imagenet in terms of average cross - dataset performance on four datasets , which demonstrates the domain robustness of drid-20 .",
    "a possible explanation is that our drid-20 dataset , being constructed by multiple query expansions , has much more visual patterns or feature distributions than stl-10 or cifar-10 , which just use only one query for candidate image collection . at the same time , mil selection mechanisms maximize the retention of useful visual patterns to represent the drid-20 dataset .",
    "\\(2 ) cifar-10 shows poor performance on cross - dataset generalization except on its own dataset .",
    "the explanation is that the data distributions of its auxiliary domain and target domain are quite strongly related , making it difficult for other datasets to exceed its performance when tested on cifar-10 .",
    "all images in cifar-10 are cut to 32@xmath14332 and objects in these images are located in the middle of the image . besides , these images contain relatively small other objects or scenes .",
    "images in stl-10 are 96@xmath14396 and are full size in imagenet and drid-20 .",
    "these images not only contain target objects , but also include a large number of other scenarios or objects .",
    "based on these conditions , although cifar-10 has a better performance on its own domain , it still has a serious dataset bias problem which coincides with its average cross - dataset generalization performance .      following @xcite , we compute the average image of each category and measure the lossless jpg file size , which reflects the amount of information in an image .",
    "the basic idea is that a diverse image dataset will result in a blurrier average image , whereas an image dataset with little diversity will result in a more structured , sharper average image .",
    "therefore , we expect the average image of a more diverse image dataset to have a smaller jpg file size .",
    "we resize all images in stl-10 , imagenet and drid-20 to 32@xmath14332 grey images , and create average images for each category from 100 randomly sampled images . fig .",
    "5 compares the image diversity of five common categories in drid-20 , imagenet , and stl-10 , and shows example images    .object detection results ( a.p . ) on pascal voc 2007 ( test ) . [ cols=\"^,^,^,^,^,^,^\",options=\"header \" , ]     and average images in these datasets . by observing fig .",
    "5(a ) , it can be seen that the average image of drid-20 is blurred and it is difficult to recognize the object , while the average image of imagenet and stl-10 is relatively more structured and sharper .",
    "drid-20 has a slightly smaller jpg file size than imagenet and stl-10 .",
    "this phenomenon is universal for all five categories .",
    "drid-20 is constructed with the goal that images in this dataset should exhibit domain robustness and be able to effectively alleviate the dataset bias problem . to achieve domain robustness , we not only consider the source of the candidate images , but also retain the images from different distributions .",
    "we can see from the above experiments that , with a certain number of samples , drid-20 has much more effective visual patterns and feature distributions than the cifar-10 , stl-10 and imagenet datasets , and thus has better domain adaptation ability .",
    "we report the performance of object detection on the pascal voc 2007 test set .",
    "table 2 shows the results of our proposed method and compares it to the state - of - the - art weakly supervised and web - supervised methods @xcite .",
    "methods @xcite and @xcite have state - of - the - art performance for weakly supervised object detection .",
    "@xcite is trained on manually selected videos without bounding boxes and shows results on 10 out of 20 categories .",
    "@xcite uses weak human supervision ( voc data with image - level labels for training ) and initialization from objectness @xcite .",
    "@xcite takes web supervision and then trains a mixture dpm detector for the object .",
    "@xcite is a fully supervised object detection method and it is a possible upper bound for weakly supervised and web - supervised approaches .",
    "compared to @xcite which uses weak supervision , and @xcite which uses full supervision , the training set of our proposed approach and @xcite do not need to be labelled manually .",
    "nonetheless , the results of our proposed approach and @xcite surpass the previous best results of weakly supervised object detection methods @xcite .",
    "a possible explanation is perhaps that both our approach and that of @xcite use multiple query expansions for candidate image collection , and the training data collected by our approach and @xcite are richer and contain more effective visual patterns . in most cases , our method surpasses the results in @xcite , which also uses web supervision and multiple query expansion for candidate image collection .",
    "the explanation for this is that we use different mechanisms for noisy images removal .",
    "compared to @xcite which takes iterative mechanisms in the process of noisy image filtering , our approach applies an mil method for removing noisy images .",
    "this maximizes the ability to retain images from different data distributions while filtering out the noisy images .    by using the same feature and training strategies",
    ", our approach achieves the best performance compared to weakly supervised and web - supervised method @xcite .",
    "the main reason for this is that our training data are generated from multiple query expansions and mil filtering mechanisms , and thus contain much richer and more accurate visual descriptions for these categories . in other words",
    ", our approach discovers many more useful linkages to visual patterns for the given category .",
    "in this paper , we presented a new framework for domain - robust image dataset construction with web images .",
    "three successive modules were employed in the framework including query expanding , noisy expansion filtering and noisy image filtering . to verify the effectiveness of our proposed method",
    ", we constructed an image dataset drid-20 .",
    "extensive experiments show that our dataset has better domain adaptation ability than the traditional manual - labelled datasets stl-10 , cifar-10 and imagenet .",
    "in addition , our data was successfully applied to help improve object detection on pascal voc 2007 , and the results demonstrated the superiority of our method to several weakly supervised and web - supervised state - of - the - art methods .",
    "we have publicly released the drid-20 dataset to facilitate the research in this field .",
    "although good results were obtained , there is still room to improve the proposed dataset construction framework .",
    "for example , we can potentially use more sophisticated approaches to purify noisy query expansions , noisy images and that will be the focus of our future work .",
    "this research was supported by the national natural science foundation of china ( no . 61473154 ) ."
  ],
  "abstract_text": [
    "<S> labelled image datasets have played a critical role in high - level image understanding ; however the process of manual labelling is both time - consuming and labor intensive . </S>",
    "<S> to reduce the cost of manual labelling , there has been increased research interest in automatically constructing image datasets by exploiting web images . </S>",
    "<S> datasets constructed by existing methods tend to have a weak domain adaptation ability , which is known as the `` dataset bias problem '' . to address this issue </S>",
    "<S> , we present a novel image dataset construction framework which can be generalized well to unseen target domains . in specific , </S>",
    "<S> the given queries are first expanded by searching in the google books ngrams corpus to obtain a richer semantic description , from which the visually non - salient and less relevant expansions are filtered out . by treating each unfiltered expansion as a `` bag '' and the retrieved images as `` instances '' , </S>",
    "<S> image selection can be formulated as a multi - instance learning problem with constrained positive bags . </S>",
    "<S> we propose to solve the employed problems by the cutting - plane and concave - convex procedure ( cccp ) algorithm . </S>",
    "<S> using this approach , images from different distributions will be retained while noisy images will be filtered out . to verify the effectiveness of our proposed approach , we build a domain - robust image dataset with 20 categories , which we refer to as drid-20 . </S>",
    "<S> we compare drid-20 with three publicly available datasets stl-10 , cifar-10 and imagenet . </S>",
    "<S> the experimental results confirm the effectiveness of our dataset in terms of image classification ability , cross - dataset generalization ability and dataset diversity . </S>",
    "<S> we further run object detection on pascal voc 2007 using our data , and the results demonstrate the superiority of our method to the weakly supervised and web - supervised state - of - the - art detection methods .    </S>",
    "<S> shell : bare demo of ieeetran.cls for ieee journals    domain robust , multiple query expansions , image dataset construction , mil </S>"
  ]
}