{
  "article_text": [
    "let @xmath4 be an @xmath0 complex matrix and let @xmath5 be the set of all @xmath0 complex matrices that have @xmath6 as a multiple eigenvalue .",
    "malyshev @xcite obtained the following singular value optimization characterization for the spectral norm distance from @xmath4 to @xmath5 : @xmath7 } \\right),\\ ] ] where @xmath8 denotes the spectral matrix norm subordinate to the euclidean vector norm , and @xmath9 is the @xmath10th singular value of the corresponding matrix ordered in a nonincreasing order .",
    "malyshev s work can be considered as a solution to wilkinson s problem , that is , the computation of the distance from a matrix @xmath11 with all its eigenvalues simple to the @xmath0 matrices that have multiple eigenvalues .",
    "this distance was introduced by wilkinson in @xcite , and some bounds for it were computed by ruhe @xcite , wilkinson @xcite and demmel @xcite . a spectral norm distance from @xmath4 to matrices that have a prescribed eigenvalue of algebraic multiplicity @xmath12 , or any prescribed algebraic multiplicity ,",
    "were obtained by ikramov and nazri @xcite and mengi @xcite , respectively . moreover",
    ", lippert @xcite and gracia @xcite studied a spectral norm distance from @xmath4 to the matrices with two prescribed eigenvalues , and obtained a nearest matrix to @xmath4 having these two eigenvalues .    in 2008 , papathanasiou and psarrakos @xcite generalized malyshev s results for the case of matrix polynomials , introducing a ( weighted ) spectral norm distance from an @xmath13 matrix polynomial @xmath1 to the matrix polynomials that have a prescribed @xmath14 as a multiple eigenvalue , and obtaining an upper and a lower bounds for this distance . lately , motivated by mengi s results in @xcite , psarrakos @xcite introduced the matrix polynomials @xmath15 =    \\left [ { \\begin{array}{*{20}{c } } { p(\\lambda ) } & 0 & \\cdots & 0\\\\    { \\gamma { p^{(1)}}(\\lambda ) } & { p(\\lambda ) } & \\cdots & 0\\\\    { \\frac{{{\\gamma ^2}}}{{2!}}{p^{(2)}}(\\lambda ) } &    { \\gamma { p^{(1)}}(\\lambda ) } & \\cdots & 0 \\\\    \\vdots & \\vdots & \\ddots   & \\vdots \\\\    { \\frac{{{\\gamma ^{k - 1}}}}{{(k - 1)!}}{p^{(k - 1)}}(\\lambda ) } &    { \\frac{{{\\gamma ^{k - 2}}}}{{(k - 2)!}}{p^{(k - 2)}}(\\lambda ) } &    \\cdots & { p(\\lambda ) } \\end{array } } \\right ] ,    \\;\\;\\ ; k=1,2,\\dots,\\ ] ] where @xmath16 denotes the @xmath10th derivative of @xmath1 with respect to @xmath17 .",
    "then , he derived lower and upper bounds for a distance from @xmath1 to the matrix polynomials with a prescribed eigenvalue of a desired algebraic multiplicity , by generalizing the methodology used in @xcite . recently , kokabifar , loghmani , nazari and karbassi @xcite extended the results of @xcite to the case of two distinct eigenvalues , by replacing the first order derivative of @xmath1 in @xmath18 $ ] by a divided difference .",
    "also , karow and mengi @xcite studied systematically an alternative distance from a given @xmath13 matrix polynomial to matrix polynomials with a specified number of eigenvalues at specified locations in the complex plane , deriving singular value optimization characterizations based on a sylvester s equation characterization .    in this paper , motivated by the above spectrum updating problems , we introduce and study a ( weighted ) spectral norm distance from an @xmath13 matrix polynomial @xmath1 to the set of all matrix polynomials with @xmath19 prescribed distinct eigenvalues .",
    "in particular , we obtain an upper and a lower bounds for this distance , and construct an optimal perturbation associated to the upper bound . replacing the derivatives of @xmath1 in",
    "@xmath20 $ ] by divided differences formulas , extending necessary definitions and lemmas of @xcite , and constructing an appropriate perturbation of @xmath1 are the main ideas used herein .",
    "( hence , this article can be considered as a generalization of the results obtained in @xcite to the case of matrix polynomials , and also as an extension of @xcite to the case of @xmath21 arbitrary distinct eigenvalues ) . in the next section , we review standard definitions on matrix polynomials , and we also introduce some definitions which are necessary for the remainder . in section",
    "[ perturbation ] , we construct an admissible perturbation of @xmath1 by extending the methods described in @xcite . in section [ bounds ] , we obtain our bounds , and in section [ example ] , we give two numerical examples to illustrate the effectiveness of the proposed technique .",
    "in the last decades , the study of matrix polynomials , especially with regard to their spectral analysis , has received much attention of several researchers and has met many applications .",
    "some basic references for the theory and applications of matrix polynomials are @xcite and references therein .    for @xmath22 @xmath23 and a complex variable @xmath17",
    ", we define the _ matrix polynomial _ @xmath24 if for a scalar @xmath25 and some nonzero vector @xmath26 , it holds that @xmath27 , then the scalar @xmath28 is called an _ eigenvalue _ of @xmath1 and the vector @xmath29 is known as a _ ( right ) eigenvector _ of @xmath1 corresponding to @xmath28 .",
    "similarly , a nonzero vector @xmath30 is known as a _ ( left ) eigenvector _ of @xmath1 corresponding to @xmath28 when @xmath31 .",
    "the _ spectrum _ of @xmath1 , denoted by @xmath32 , is the set of its eigenvalues . throughout of this paper",
    ", it is assumed that the coefficient matrix @xmath33 is _ nonsingular _ ; this implies that the spectrum of @xmath1 contains no more than @xmath34 distinct elements .",
    "the multiplicity of an eigenvalue @xmath35 as a root of the scalar polynomial @xmath36 is called the _ algebraic multiplicity _ of @xmath37 , and the dimension of the null space of the ( constant ) matrix @xmath38 is known as the _ geometric multiplicity _ of @xmath37 . the algebraic multiplicity of an eigenvalue is always greater than or equal to its geometric multiplicity .",
    "an eigenvalue is called _ semisimple _ if its algebraic and geometric multiplicities are equal ; otherwise , it is known as _",
    "defective_. the singular values of @xmath1 are the nonnegative roots of the eigenvalue functions of @xmath39 , and they are denoted by @xmath40 ( i.e. , they are considered in a nondecreasing order ) .",
    "[ dis ]    [ uv ]    [ fg ]",
    "in this section , we construct an @xmath0 matrix polynomial @xmath41 such that the given set of distinct scalars @xmath42 @xmath43 is included in the spectrum of the perturbed matrix polynomial @xmath44 . without loss of generality ,",
    "hereafter we can assume that the parameter @xmath45 is real nonnegative @xcite .",
    "moreover , for convenience , we set @xmath46 .",
    "[ uv ]    suppose now that @xmath47 and @xmath48 .",
    "define the quantities @xmath49 and the vectors @xmath50    \\;\\ ; ( p = 2 , 3 , \\dots , k ) \\ ] ] and @xmath51    \\;\\ ; ( p = 2 , 3 , \\dots , k ) .\\ ] ]    analogously to definition [ uv ] , we define the @xmath52 matrices @xmath53 \\;\\;\\ ; \\mbox{and } \\;\\;\\ ;    { \\hat v } ( \\gamma ) = \\left [ \\,{\\hat v}_1 ( \\gamma ) \\ ; { \\hat v}_1(\\gamma ) \\ ; \\cdots \\ ;    { \\hat v}_k(\\gamma ) \\",
    ", \\right ] .\\ ] ] we also consider the quantities @xmath54 where @xmath55 and , by convention , we set @xmath56 whenever @xmath57 . if @xmath58 are nonzero , then we define the @xmath13 matrix @xmath59 ) { \\hat u}(\\gamma )    \\,\\textup{diag } \\left\\ { \\frac{1}{\\beta_1 } , \\frac{1}{\\beta_2 } , \\dots , \\frac{1}{\\beta_k } \\right \\ }    { \\hat v } ( \\gamma)^\\dag   , \\ ] ] where @xmath60 denotes the _ moore - penrose pseudoinverse _ of @xmath61 , and the @xmath13 matrix polynomial @xmath62 where @xmath63    by straightforward computations , we verify that the matrix polynomial @xmath64 satisfies @xmath65\\delta _ \\gamma }      \\,=\\ , { \\beta_s}{\\delta_\\gamma } , \\;\\;\\ ; s = 1 , 2 , \\dots , k   .\\ ] ] notice that the condition @xmath66 implies @xmath67 , @xmath68 and @xmath69 , where @xmath70 denotes the @xmath71 identity matrix .",
    "moreover , since @xmath72 is a pair of left and right singular vectors of @xmath73 } \\right)$ ] , we have @xmath74 } v(\\gamma ) =   { s_\\rho } \\left({f_{\\gamma}[p,\\sigma ] } \\right ) u(\\gamma ) , \\ ] ] or equivalently , the following hold : @xmath75 } \\right ) u_1(\\gamma )    & = & p(\\mu_1 )    v_1(\\gamma )    ,   \\\\    { s_\\rho } \\left({f_{\\gamma}[p,\\sigma ] } \\right ) u_2(\\gamma )    & = & { \\gamma } p[\\mu_1,\\mu_2 ] v_1(\\gamma ) + p(\\mu_2 ) v_2(\\gamma ) , \\\\",
    "\\vdots   \\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\ ;    & & \\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\ ; \\vdots \\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\ ; \\vdots \\\\    { s_\\rho } \\left({f_{\\gamma}[p,\\sigma ] } \\right ) u_k(\\gamma )    & = &   { \\gamma^{k-1 } } p [ { \\mu_1 } , \\ldots,{\\mu_k}]}v_1(\\gamma ) +    { \\gamma^{k-2 } p[{\\mu_2 } , \\ldots,{\\mu_k } ] v_2(\\gamma ) +    \\cdots + p({\\mu_k } ) v_k(\\gamma ) .\\end{aligned}\\ ] ] substituting @xmath76 and @xmath77 into these equations yields @xmath78 } \\right){{\\hat",
    "u}_i}(\\gamma )    =   p\\left ( { { \\mu _ i } } \\right){{\\hat v}_i}(\\gamma )   ,    \\;\\;\\ ; i = 1 , 2 , \\ldots , k .\\ ] ]    therefore , for the matrix polynomial @xmath79 ( recall the coefficient perturbations @xmath80 in ( [ deltagammaj ] ) ) , and for every @xmath81 , it follows @xmath82 }   \\right){{\\hat u}_i}(\\gamma ) +   { \\beta _ i}{\\delta_\\gamma}{{\\hat v}_i}(\\gamma ) \\\\ & = &   { s_\\rho } \\left ( { { f_\\gamma } [ p,\\sigma ] }   \\right){{\\hat u}_i}(\\gamma ) + { \\beta _ i}\\left ( { - { s_\\rho }   \\left ( { { f_\\gamma } [ p,\\sigma ] } \\right )   \\frac{1}{{{\\beta _ i } } } } \\right){{\\hat u}_i}(\\gamma ) \\\\ & = & 0 .\\end{aligned}\\ ] ] as a consequence , if rank@xmath83 ( recall that all @xmath84 in ( [ betas ] ) are nonzero ) , then @xmath85 are eigenvalues of the matrix polynomial @xmath86 in ( [ q ] ) with @xmath87 as their associated eigenvectors , respectively .",
    "the next result follows immediately .",
    "consider a matrix polynomial @xmath1 as in ( [ plambda ] ) and a given set of @xmath3 distinct complex numbers @xmath88 , and suppose that the quantities @xmath58 in ( [ betas ] ) are nonzero .",
    "for every @xmath47 such that @xmath48 , the scalars @xmath85 are eigenvalues of the matrix polynomial @xmath86 in ( [ q ] ) , with corresponding eigenvectors @xmath89 , respectively .",
    "the construction of the perturbed matrix polynomial @xmath91 in ( [ q ] ) yields immediately an upper bound for the distance @xmath90 .",
    "in particular , from ( [ deltagammaj ] ) we have @xmath92 consequently , if all @xmath58 in ( [ betas ] ) are nonzero , then for any @xmath93 such that @xmath48 , it follows @xmath94    next , we compute a lower bound for @xmath90 .",
    "it is worth mentioning that for calculating this lower bound , the condition @xmath95 is not necessary .",
    "[ lem1 ] suppose that @xmath1 is a matrix polynomial as in ( [ plambda ] ) , and @xmath96 are @xmath21 distinct eigenvalues of @xmath1 .",
    "then , for every @xmath97 , it holds that @xmath98 \\right ) = 0 $ ] ( recall that @xmath99 ) .",
    "since @xmath100 are distinct eigenvalues of @xmath1 , there exist @xmath21 nonzero ( but not necessarily linearly independent ) vectors @xmath101 satisfying @xmath102 , @xmath103 .    recalling definition [ fg ] and the quantities @xmath104 @xmath105 defined by ( [ quant ] ) , the @xmath106 matrix @xmath107 $ ]",
    "can be written in the form @xmath108 = \\left [     \\begin{array}{cccccc }     p(\\mu_1 )                         & 0         & 0 & \\cdots & 0 \\\\     \\theta_{1,2}(p(\\mu_1)-p(\\mu_2 ) ) & p(\\mu_2 ) & 0 & \\cdots & 0 \\\\     \\theta_{1,3}[\\theta_{1,2 } p(\\mu_1)-(\\theta_{1,2}+\\theta_{2,3})p(\\mu_2 )     + \\theta_{2,3}p(\\mu_3 ) ] & \\theta_{2,3}(p(\\mu_2)-p(\\mu_3 ) ) & p(\\mu_3 ) & \\cdots & 0 \\\\     \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\     \\ast & \\ast & \\ast   & \\cdots & p(\\mu_k )     \\end{array }   \\right ]   . }",
    "\\ ] ] denoting the @xmath109th @xmath110 block of this matrix by @xmath111 , it follows readily that @xmath112 moreover , for all distinct @xmath10 , @xmath113 and @xmath114 in @xmath115 , it holds that @xmath116 by straightforward calculations , and using ( [ ffff ] ) and ( [ tttt ] ) , one can verify that the @xmath21 ( nonzero ) linearly independent vectors @xmath117 ,    \\left [   \\begin{array}{c }      0 \\\\      \\nu_2 \\\\",
    "\\theta_{2,3}\\nu_2   \\\\      \\vdots \\\\      \\left ( \\prod\\limits_{j=3}^{k-1 } \\theta_{2,j } \\right ) \\nu_2",
    "\\\\      \\left ( \\prod\\limits_{j=3}^{k } \\theta_{2,j } \\right ) \\nu_2 \\end{array } \\right ] ,        \\left [   \\begin{array}{c }      0 \\\\      0 \\\\      \\nu_3 \\\\      \\vdots \\\\      \\left ( \\prod\\limits_{j=4}^{k-1 } \\theta_{3,j } \\right ) \\nu_3 \\\\      \\left ( \\prod\\limits_{j=4}^{k } \\theta_{3,j } \\right ) \\nu_3 \\end{array } \\right ] ,      \\dots ,        \\left [   \\begin{array}{c }      0 \\\\      0 \\\\      \\vdots \\\\      0 \\\\      \\nu_{k-1 } \\\\      \\theta_{k-1,k } \\nu_{k-1 } \\end{array } \\right ] ,        \\left [   \\begin{array}{c }      0 \\\\      0 \\\\      \\vdots \\\\      0 \\\\      0 \\\\      \\nu_k \\end{array } \\right]\\ ] ] lie in the null space of the matrix @xmath118 $ ] .",
    "thus , the rank of @xmath107 $ ] is less than or equal to @xmath119 , and the proof is complete .",
    "the next lemma yields a lower bound of @xmath90 .",
    "we need to define the nonnegative quantities @xmath120 = w \\left ( \\left| \\mu_i \\right|     \\right ) ,   \\;\\;\\ ; i=1,2,\\dots , k,\\ ] ] @xmath121 =     \\sum \\limits_{j = 0}^m",
    "w_j   \\frac{\\left| \\mu_i^j - \\mu _ { i+1}^j     \\right| } { \\left | \\mu_i - \\mu_{i+1 }   \\right| } , \\;\\;\\ ; i=1,2,\\dots , k-1,\\ ] ] and ( recursively ) @xmath122    = \\frac { \\varpi \\left [ \\mu_i , \\ldots , \\mu_{i+t-1 } \\right ]      + \\varpi \\left [ \\mu_{i+1 } , \\ldots , \\mu_{i+t } \\right ] }      { \\left| \\mu_i - \\mu_{i+t }   \\right | } ,      \\;\\;\\ ; i = 1 , 2 , \\dots , k-2 ,   \\ ; t = 2 , 3 , \\dots , k - i , \\ ] ] and the @xmath123 matrix @xmath124 = \\left [ { \\begin{array}{*{20}c }     { \\varpi \\left [ { \\mu _ 1 } \\right ] }                     & 0                                             &   \\cdots   & 0   \\\\     \\gamma \\varpi \\left [ \\mu_1 , \\mu_2   \\right ]           & \\varpi \\left [ \\mu_2   \\right ]              &   \\cdots   & 0   \\\\     \\gamma^2 \\varpi \\left [ \\mu _ 1 , \\mu_2 , \\mu_3   \\right ] & { \\gamma \\varpi \\left [ \\mu_2 , \\mu_3 \\right ] } &   \\cdots   & 0   \\\\      \\vdots                                               &   \\vdots                                       &   \\ddots   &   \\vdots    \\\\     { \\gamma^{k-1 } \\varpi \\left [ \\mu_1 , \\mu_2 , \\ldots , \\mu_k \\right ] } & \\gamma^{k-2 } \\varpi \\left [ \\mu_2 , \\mu_3 , \\ldots , \\mu_k   \\right ] & \\cdots   & \\varpi \\left [ \\mu_k \\right ] \\end{array } } \\right ]    .\\ ] ]    [ lowerbound ] suppose that the matrix polynomial @xmath125 belongs to @xmath126 . if @xmath21 distinct scalars @xmath127 are eigenvalues of @xmath128 , then for any @xmath47 , @xmath129 \\right ) }    { \\left\\| f_{\\gamma }   \\left [ \\varpi , \\sigma \\right ] \\right\\|_2 } .\\ ] ]    it is easy to see that @xmath130 ,    \\;\\;\\ ;   i=1,2,\\dots , k,\\ ] ] @xmath131 \\right\\|_2 \\le   \\sum\\limits_{j=0}^m \\left\\| \\delta_j \\right\\|_2 \\left|   \\frac{\\mu_i^j - \\mu_{i+1}^j}{\\mu_i - \\mu_{i+1 } } \\right|    \\le   \\varepsilon \\varpi \\left [ \\mu_i , \\mu_{i+1 }   \\right ] ,   \\;\\;\\ ; i=1,2,\\dots , k-1 , \\ ] ] and @xmath132\\right\\|_2    & \\le & \\frac{1 } { \\left| \\mu_i - \\mu_{i+2 } \\right| }         \\left ( \\left\\| \\delta \\left [ \\mu_i , \\mu_{i+1 } \\right ] \\right\\|_2         + \\left\\| \\delta\\left [ \\mu_{i+1},\\mu_{i+2}\\right]\\right\\|_2 \\right ) \\\\    & \\le & \\frac{1 } { \\left| \\mu_i - \\mu_{i+2 } \\right| } \\left ( \\varepsilon         \\sum\\limits_{j=0}^m w_j \\frac { \\left| \\mu_i^j - \\mu_{i+1}^j\\right| }         { \\left| \\mu_i - \\mu_{i+1 } \\right| }   + \\varepsilon         \\sum\\limits_{j=0}^m   w_j \\frac { \\left| \\mu_{i+1}^j - \\mu_{i+2}^j   \\right| }         { \\left| \\mu_{i+1 } - \\mu _ { i+2 } \\right|   } \\right )   \\\\    & \\le & \\varepsilon \\varpi",
    "\\left [ \\mu_i , \\mu_{i+1 } , \\mu_{i+2 } \\right ] ,         \\;\\;\\;\\ ; i=1,2,\\dots , k-2 .\\end{aligned}\\ ] ] similarly , we can obtain @xmath133 } \\right\\|_2 \\le    \\varepsilon \\varpi \\left [ \\mu_i , \\ldots , \\mu_{i + t } \\right ] , \\;\\;\\ ;    i = 1 , 2 , \\dots , k-2 ,   \\ ; t = 2 , 3 ,   \\dots , k - i .\\ ] ]    as in the proof of theorem 2.4 of @xcite , we can consider a unit vector @xmath134   \\in \\mathbb{c}^{kn } \\;\\;\\ ; \\left ( { x_i } \\in \\mathbb{c}^n , \\ ;   i = 1 , 2 , \\ldots , k \\right)\\ ] ] such that @xmath135 \\right\\|_2 ^ 2    & = & \\left\\| f_{\\gamma } \\left [ \\delta , \\sigma \\right ] x \\right\\|_2 ^ 2 \\\\    & = & \\left\\| \\delta \\left ( \\mu_1 \\right ) x_1 \\right\\|_2 ^ 2      + \\left\\| \\gamma \\delta \\left [ \\mu_1 , \\mu_2 \\right ] x_1 + \\delta \\left ( \\mu_2 \\right ) x_2 \\right\\|_2 ^ 2 \\\\    & &   + \\ , \\cdots + \\left \\| \\sum\\limits_{i=1}^k \\gamma^{k - i } \\delta \\left [ \\mu_i , \\ldots , \\mu_k \\right ] x_i \\right\\|_2 ^ 2 \\\\    & \\le & \\left ( \\varepsilon \\varpi \\left [ \\mu_1 \\right ] \\right)^2 \\left \\| x_1 \\right\\|_2 ^ 2 +          \\left ( \\gamma \\varepsilon \\varpi \\left [ \\mu_1 , \\mu_2 \\right ] \\right)^2 \\left\\| x_1   \\right\\|_2 ^ 2          + \\left ( \\varepsilon \\varpi \\left [ \\mu_2 \\right ] \\right)^2 \\left\\| x_2 \\right\\|_2 ^ 2   \\\\    & & + \\,2\\gamma \\left ( \\varepsilon \\varpi \\left [ \\mu_1 , \\mu_2 \\right ] \\right )          \\left ( \\varepsilon \\varpi \\left [ \\mu_2 \\right ] \\right)\\left\\| x_1 \\right\\|_2 \\left\\| x_2 \\right\\|_2          +   \\cdots + \\left ( \\varepsilon \\varpi \\left [ \\mu_k \\right ] \\right)^2 \\left\\| x_k   \\right\\|_2 ^ 2   \\\\    & = &    \\varepsilon^2    { \\small      \\left\\| \\left [ { \\begin{array}{*{20}c }         { \\varpi \\left [ { \\mu _ 1 } \\right ] }                     & 0                                             &   \\cdots   & 0   \\\\         \\gamma \\varpi \\left [ \\mu_1 , \\mu_2   \\right ]           & \\varpi \\left [ \\mu_2   \\right ]              &   \\cdots   & 0   \\\\         \\gamma^2 \\varpi \\left [ \\mu _ 1 , \\mu_2 , \\mu_3   \\right ] & { \\gamma \\varpi \\left [ \\mu_2 , \\mu_3 \\right ] } &   \\cdots   & 0   \\\\         \\vdots                                               &   \\vdots                                       &   \\ddots   &   \\vdots    \\\\         { \\gamma^{k-1 } \\varpi \\left [ \\mu_1 , \\mu_2 , \\ldots , \\mu_k \\right ] } & \\gamma^{k-2 } \\varpi \\left [ \\mu_2 , \\mu_3 , \\ldots , \\mu_k   \\right ] & \\cdots   & \\varpi \\left [ \\mu_k \\right ]   \\\\",
    "\\end{array } } \\right ]          \\left [ \\begin{array}{c } \\left\\|{x_1}\\right\\|_2 \\\\ \\left\\|{x_2}\\right\\|_2 \\\\          \\vdots \\\\ \\left\\|{x_k}\\right\\|_2 \\end{array } \\right ] \\right\\|_2 ^ 2   }    \\\\    & \\le & \\varepsilon^2 \\left\\| f_\\gamma",
    "\\left [ \\varpi , \\sigma   \\right ] \\right\\|_2 ^ 2 .\\end{aligned}\\ ] ] moreover , since the @xmath21 distinct scalars @xmath96 are eigenvalues of @xmath136 , lemma [ lem1 ] implies that @xmath137 } \\right)=0 $ ] .",
    "applying the weyl inequalities ( e.g. , see corollary 5.1 of @xcite ) for singular values , with respect to the relation @xmath138 = f_\\gamma \\left [ p,\\sigma \\right ] + f_\\gamma \\left [ \\delta , \\sigma \\right]$ ] , yields @xmath139 \\right )   \\le \\left\\| { { f_\\gamma } \\left [ { \\delta , \\sigma } \\right ] }",
    "\\right\\|_2   \\le \\varepsilon \\left\\| f_\\gamma   \\left [ \\varpi , \\sigma   \\right ] \\right\\|_2\\ ] ] for any @xmath47 .",
    "this completes the proof .    keeping in mind definition [ dis ] , the above lemma yields a lower bound for @xmath140 , namely , @xmath141 \\right ) }    { \\left\\| f_\\gamma   \\left [ \\varpi , \\sigma \\right ] \\right\\|_2 } .\\ ] ]    it will be convenient to denote the lower bound in ( [ lbound ] ) by @xmath142 and the upper bound in ( [ ubound ] ) by @xmath143 , i.e. , @xmath144 \\right ) } { \\left\\| f_{\\gamma }   \\left [ \\varpi , \\sigma \\right ] \\right\\|_2 }   , \\ ] ] and @xmath145    our results",
    "so far are summarized in the following theorem .",
    "[ thm11 ] consider an @xmath13 matrix polynomial @xmath1 as in ( [ plambda ] ) and a given set of @xmath3 distinct complex numbers @xmath88 .",
    "( a ) : :    for any @xmath47 ,    @xmath146 .",
    "( b ) : :    if the quantities @xmath58 in    ( [ betas ] ) are nonzero , then for any @xmath47 such that    @xmath48 ,    @xmath147 and the matrix polynomial    @xmath148 in ( [ q ] ) lies on the boundary of    @xmath149 .",
    "next we consider the case @xmath150 .",
    "for @xmath103 , let @xmath151 be a pair of left and right singular vectors of @xmath152 corresponding to @xmath153 , respectively .",
    "if the vectors @xmath154 are linearly independent , then we define the constant matrix @xmath155   \\textup{diag } \\left \\ { { \\sigma _ 1 } , { \\sigma _ 2 } , \\dots , { \\sigma _ k } \\right \\ }   \\left [ \\ , { \\tilde v_1 } \\ ; { \\tilde v_2 } \\ ; \\cdots \\ ; { \\tilde v_k } \\ , \\right]^\\dag\\ ] ] and observe that @xmath156^\\dag \\left [ \\ , { \\tilde v_1 } \\ ; { \\tilde v_2 } \\ ; \\cdots \\ ; { \\tilde v_k } \\ , \\right ] = i_k$ ] .",
    "therefore , the matrix polynomial @xmath157 lies on the boundary of @xmath158 and satisfies @xmath159 hence , the scalars @xmath160 are eigenvalues of the matrix polynomial @xmath161 in ( [ q0 ] ) with corresponding eigenvectors @xmath162 , respectively .",
    "let @xmath150 , and let @xmath163 be a pair of left and right singular vectors of @xmath152 corresponding to @xmath153 , respectively , for every @xmath164 .",
    "if the vectors @xmath165 are linearly independent , then the matrix polynomial @xmath161 in ( [ q0 ] ) lies on the boundary of @xmath166 and has @xmath167 as eigenvalues .    in the next remark",
    ", we give an upper and a lower bounds for a spectral norm distance from an @xmath13 matrix @xmath4 to the set of all matrices with @xmath21 prescribed eigenvalues .",
    "this issue is explained in @xcite in detail .",
    "in this section , the validity of the method described in the previous sections is verified by two numerical examples .",
    "the lower and upper bounds for the distance @xmath140 are computed by applying the procedures described in section [ bounds ] , and by using the matlab function ` fminbnd ` which finds a minimum of a function of one variable within a fixed interval . as it was mentioned in remark [ rrank ] , the condition @xmath168 appears to be generic when @xmath47 .",
    "all computations were performed in matlab with @xmath169 significant digits ; however , for simplicity , all numerical results are shown with @xmath170 decimal places ."
  ],
  "abstract_text": [
    "<S> consider an @xmath0 matrix polynomial @xmath1 and a set @xmath2 consisting of @xmath3 distinct complex numbers . in this paper , a ( weighted ) </S>",
    "<S> spectral norm distance from @xmath1 to the matrix polynomials whose spectra include the specified set @xmath2 , is defined and studied . </S>",
    "<S> an upper and a lower bounds for this distance are obtained , and an optimal perturbation of @xmath1 associated to the upper bound is constructed . </S>",
    "<S> numerical examples are given to illustrate the efficiency of the proposed bounds .    </S>",
    "<S> matrix polynomial , eigenvalue , perturbation , singular value .    </S>",
    "<S> _ ams classification : _ </S>",
    "<S> 15a18 , 65f35 . </S>"
  ]
}