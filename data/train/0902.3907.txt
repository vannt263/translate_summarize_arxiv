{
  "article_text": [
    "the study of stellar oscillations provides a powerful probe of the physical properties of stars . in particular , knowledge of the frequencies of many eigenmodes of a star",
    "can significantly constrain its internal structure and composition ( e.g. * ? ? ?",
    "* ) . in practice",
    ", these frequencies are inferred from time series data of the star s radial velocity or intensity , which is analysed in order to determine the frequencies of the oscillation modes that contributed to the signal @xcite .",
    "the amount and quality of data has increased spectacularly over the past few years , mostly due to advances in instrumentation that were primarily intended for extrasolar planet searches @xcite . despite these advances , oscillation data on stars",
    "other than the sun is still much more sparse and noisy , for obvious reasons .",
    "most of this data is analysed with fourier power spectrum methods inherited from helioseismology . recently",
    ", there has been growing interest in examining the fundamentals of data analysis techniques , and attempts to improve on these classical techniques have yielded modest , but non - negligible improvements to our ability to make use of time series data . separately , there has been a steady growth in interest in bayesian inference @xcite as the most consistent and natural way to model uncertainties .",
    "thus , the approach described in this paper is bayesian .",
    "the idea behind bayesian methods is to describe our knowledge by a probability distribution over the space of possible solutions we are considering .",
    "this probability distribution then gets updated to take into account the information contained in the data , in this case the time series data @xmath3 . in asteroseismology ,",
    "the possible solutions we consider are all possible values for the parameters of interest : the frequencies @xmath4 of the oscillation modes , their amplitudes @xmath5 and phases @xmath6 , and the total number of modes , @xmath7 . for brevity",
    ", we drop the braces hereafter ; @xmath8 , @xmath9 and @xmath10 now stand for arrays of amplitudes , frequencies and phases respectively . any additional parameters ( mode lifetime , for example )",
    "are denoted collectively by @xmath11 . before taking into account the data",
    ", we assign a _ prior distribution _ @xmath12 .",
    "we also probabilistically model the predictions for what data @xmath13 we expect to observe as a function of the parameters : @xmath14 , called the _",
    "sampling distribution_. sometimes it is possible to marginalise out the amplitude and phase parameters , by integrating over them .",
    "this helps the computational search , because the algorithms only need to find good values for the frequencies , not the amplitudes and phases .",
    "this was done in a previous paper ( * ? ? ?",
    "* hereafter b07 ) by replacing the amplitudes and phases with sine - amplitudes and cosine - amplitudes ; however , it is not possible for the model we introduce in this paper . throughout this paper , we will be fitting both the frequencies and the amplitudes .",
    "it turns out ( section  [ simcov ] ) that we do not need phases in our model , so we will drop the phases hereafter .",
    "once the prior distribution and the sampling distribution have been specified , we have defined a joint probability distribution for the parameters and the data : @xmath15 this probability distribution describes what we know about the parameters and the data before we observe the actual data .",
    "once we learn the actual values of the data @xmath16 , we update our probability distribution by deleting all hypotheses in the @xmath17 space that are now known to be false ; i.e. we restrict our attention to the slice @xmath18 .",
    "this gives the _ posterior distribution _ for the parameters given the data , describing our knowledge after updating to include the effect of the data .",
    "this is expressed by bayes s theorem : @xmath19 the second factor in equation  [ bayes ] is the sampling distribution ( probability distribution for the data as a function of the parameters ) with the data fixed at the observed values ; thus it is a function of the parameters only .",
    "once the data have been fixed , it is commonly referred to as the _ likelihood function_.    many existing methods , including the bayesian analysis of b07 , rely on the assumption that the observed time series is composed of a sum of sinusoidal signals , plus gaussian noise - basically , this was our choice for the sampling distribution @xmath20 .",
    "interestingly , the periodogram can be proven to be a sufficient statistic from this same assumption , plus the assumption that the time series has complete phase coverage .",
    "what this means is that if we intend to infer the frequencies of the modes , no information is lost by reducing the time series to the periodogram @xcite , as long as the signal is purely sinusoidal and the time series has no significant gaps .",
    "successful methods have been developed to infer frequencies and mode lifetimes by fitting to the power spectrum .",
    "however , the presence of stochastically excited modes and gaps in the data both break the assumptions required for the periodogram to be a sufficient statistic . hence , _ ideally _ , when either of these conditions do not hold , we should work with the raw time series data .",
    "of course , it may be the case that using the power spectrum discards an insignificant amount of information , and the gain in convenience of the power spectrum far outweights such theoretical concerns .",
    "this is certainly the case with solar data , and stellar data with good coverage and a long mode lifetime",
    ". it may be more generally true ; however , this question is beyond the scope of this paper . in this paper",
    "we describe a new method to analyse time series data , taking into account the fact that the predicted signal from an oscillation mode is quasi - sinusoidal , and that the data may contain gaps , removing any concerns about information loss due to pre - processing via taking the power spectrum .",
    "this is done by making the choice for @xmath20 as realistic as possible .",
    "in the following , we will consider a single stochastically excited mode , and obtain a model for the sampling distribution @xmath20 when @xmath21 .",
    "subsequently , we will expand this to include multiple oscillation modes and observational errors , in section  [ independence ] .",
    "solar - like oscillations are oscillations in main sequence or red giant stars that are continually damped and re - excited by turbulent convection , and therefore do not produce purely sinusoidal signals . for solar - like oscillations ,",
    "the signal due to a single mode is modelled as a _ damped and stochastically excited _ oscillator with a driving force @xmath22 : @xmath23 where @xmath24 is a damping timescale ( the factor of two is introduced such that solutions to equation  [ ode ] without the driving force decay with an e - folding time of @xmath24 ) , and @xmath25 is an amplitude constant for the driving force @xmath22 .",
    "if @xmath22 is specified and the initial conditions @xmath26 and @xmath27 are known , then equation  [ ode ] has a unique solution . however , as the term _ stochastic excitation _ suggests , @xmath22 is only specified probabilistically . throughout this paper , we will assume that @xmath22 is unit variance white noise , so @xmath22 at any time @xmath28 comes from a standard gaussian distribution with mean 0 and standard deviation 1 .",
    "@xmath29 and @xmath30 are independent for all distinct times @xmath31 .",
    "the white noise probability distribution that we assigned to @xmath22 is an example of a _ gaussian process _ distribution . in general , a gaussian process is a probability distribution over a space of possible functions @xcite ; however a more general gaussian process may differ from white noise because the function value at different times may be correlated .    since equation  [ ode ] is a linear ordinary differential equation , and @xmath22",
    "is assigned a gaussian process distribution , we have implicitly also assigned a gaussian process distribution for the value of the oscillating signal @xmath32 at all times @xmath28 . whereas @xmath29 and @xmath30 are independent ( for @xmath31 ) ,",
    "the value of the oscillation signal at any two times , @xmath33 and @xmath34 , are correlated , with the _ covariance function _ defined as @xmath35 where the expectatation value ( mean ) of @xmath13 , @xmath36 , has been set to zero for all time . a typical signal obtained by solving equation  [ ode ]",
    "is shown in figure  [ sim ] .",
    "clearly , the signal value at any given time is strongly correlated with the signal value at a time one period later , and anticorrelated with the value half a period later .",
    "however , the correlation is weaker than would be the case if the signal was purely sinusoidal .",
    "the entire signal displayed in figure  [ sim ] can be regarded as a single point sampled from a gaussian process distribution with mean function zero and a particular covariance function .",
    "equation  [ ode ] is capable of producing solutions with any initial phase , which is why we do not need phases in our model .",
    "a useful property of gaussian processes is that the joint distribution for the function evaluated at a finite set of points ( i.e. the signal @xmath32 evaluated at the observation times ) is a multivariate gaussian , with covariance matrix given by the covariance function evaluated at the relevant points .",
    "hence , the joint distribution for the value of the oscillation signal at a discrete set of @xmath37 times @xmath38 is : @xmath39 where @xmath40 , the expectation values ( means ) of all of the @xmath13 s are zero , and @xmath41 is a covariance matrix that implicitly depends on @xmath8 , @xmath9 and @xmath24 .",
    "equation  [ gaussian ] is the first step in the construction of a realistic @xmath42 : it would suit perfectly if we had noise - free data containing one mode , and if we knew how @xmath41 depended on @xmath8 , @xmath9 and @xmath24 .",
    "the dependence of @xmath41 on @xmath8 , @xmath9 and @xmath24 is addressed in section  [ simcov ] , while the generalisation to noisy data with multiple modes occurs in section  [ independence ] .    throughout this paper ,",
    "no results depend on the choice of the origin for @xmath28 , only relative times matter . in this case",
    ", the covariance function is said to be _",
    "this implies that the covariance of @xmath33 and @xmath34 depends only on the difference between @xmath43 and @xmath44 , and not on their absolute values : @xmath45 where the symbol @xmath46 has been used to denote the covariance function , whether it takes one argument or two .",
    "this result is used to evaluate the elements of the covariance matrix @xmath41 .      in this section ,",
    "we aim to find exactly how the covariance function for the signal depends on @xmath8 , @xmath9 and @xmath24 , for a single mode .",
    "the dependence on @xmath8 is trivial : if @xmath32 comes from a gaussian process distribution with mean function zero and covariance function @xmath47 , then @xmath48 comes from a gaussian process distribution with mean zero and covariance function @xmath49 .",
    "note that these quasi - sinusoidal signals do not have a strict amplitude like sinusoidal signals do , the amplitude @xmath8 is really just the expected standard deviation of the oscillation signal .    to investigate how the covariance function of a stochastically excited oscillation signal depends on frequency and mode lifetime , equation  [ ode ] was solved numerically using a fourth order runge - kutta algorithm with a timestep much smaller than the natural period of the oscillations . from a very long simulation ,",
    "the covariance function for solutions of equation  [ ode ] was estimated by taking random pairs of times @xmath43 and @xmath44 , and plotting the average value of @xmath50 as a function of @xmath51 .",
    "a short section of the simulated time series is plotted in figure  [ sim ] , which clearly shows that while there is some periodic nature to the oscillations , the varying amplitude and phase changes would frustrate any simple modelling of the signal as sinusoidal waves - too many frequencies will be required in order to fit the data ( b07 ) .",
    "the estimated covariance function of the signal due to a single mode is shown in figure  [ covfn ] .",
    "it can be accurately modelled by a cosine curve multiplied by an exponential decay : @xmath52 where the decay timescale in the covariance function is empirically found to agree with @xmath24 to within 5 per cent ( figure  [ covfn ] ) , and in practice we will take it as being equal . in the absence of stochastic excitation and damping , the covariance function would be just a cosine function , with frequency equal to the oscillation frequency .",
    "hence , the effect of stochastic excitations and damping can be parameterised by the single parameter @xmath24 and its effect is to put an exponential decay factor into the covariance function for the signal . in the next subsection , this result is generalised to include multiple modes and observational errors .",
    "suppose there are two functions of time ( for instance , the signal from two modes ) , @xmath53 and @xmath32 and our knowledge of these functions is described by independent stationary gaussian processes for each : with mean zero and covariance functions @xmath54 and @xmath55 respectively . if we are interested in the sum @xmath56 then the sum is also a gaussian process with mean zero and covariance @xmath57 since @xmath58 and @xmath13 are independent , the expectations of the last two terms are zero . hence @xmath59 therefore , the covariance function for the sum of two independent gaussian processes is the sum of their individual covariance functions .",
    "this result can easily be extended to any number of gaussian processes .",
    "thus , if we are testing the hypothesis that there are many modes with various frequencies and amplitudes , and that there is also gaussian noise in the data , the relevant covariance matrix ( equations  [ cov ] and  [ gaussian ] ) is the sum of the covariance matrix for each mode ( obtained from equation  [ cosdecay ] ) and a diagonal covariance matrix for the noise , with the given measurement uncertainties used as the values for the noise standard deviation .",
    "in addition to these components , we included an `` extra noise '' signal to account for unmodelled errors , misquoted error bars , or correlated noise due to stellar effects that are not the oscillations of interest .",
    "the extra noise signal has an unknown standard deviation parameter @xmath60 and a correlation timescale @xmath61 for its exponentially decaying covariance function .",
    "thus , @xmath60 and @xmath61 are additional parameters to be estimated from the data .",
    "we measure the signal at a discrete set of times @xmath62 with additive gaussian noise of standard deviation @xmath63 , where @xmath64 are the reported error bars on the observations .",
    "the probability distribution for the total data set given all of the parameters ( number of modes , their frequencies and amplitudes , the extra noise and its timescale ) is gaussian with covariance matrix formed by the sum of the covariance functions for each component ( section  [ independence ] ) .",
    "thus , we have now constructed the sampling distribution - the probability distribution for the observed data given the parameters of interest .",
    "the sampling distribution is the same as equation  [ gaussian ] , but where the covariance matrix @xmath41 is the sum of the covariance matrices for each mode , the diagonal covariance matrix of the measurement errors , and the covariance matrix for the extra noise term .",
    "the posterior probability distribution for the parameters of interest given the data is then given by bayes s theorem ( equation  [ bayes ] ) , where @xmath65 : i.e. the mode lifetime , extra noise standard deviation , and the correlation timescale for the extra noise term .",
    "the previous sections described the sampling distribution , and thus the likelihood function , the second term in equation  [ bayes ] , in terms of gaussian processes .",
    "now we must assign prior distributions for all of the parameters , i.e. the first term in equation  [ bayes ] .",
    "for simplicity , we chose the priors for all of the parameters to be independent of each other . in principle , this could be improved ; for example , the expected amplitude of a mode is not the same at all frequencies .",
    "the prior for the number of modes , @xmath7 , was a uniform probability distribution ranging from 1 to a user - specified maximum number , which we took to be 200 .",
    "the prior for the frequencies @xmath9 was a uniform distribution between a user - specified lower and upper limit : for the data sets discussed in this paper , these limits were 0 and 200 @xmath2hz .",
    "the prior for the amplitudes @xmath8 was chosen to be an exponential distribution with unknown mean @xmath2 , which effectively becomes yet another parameter to be inferred from the data .",
    "the priors for @xmath2 , and the remaining parameters @xmath24 , @xmath60 and @xmath61 , all positive parameters , were chosen to be scale - invariant priors of the form @xmath66 between generous upper and lower limits .",
    "these priors correspond to uniform priors for the logarithm of the quantities , and is appropriate for positive parameters with unknown order of magnitude .",
    "since the specification of the priors introduced an extra parameter @xmath2 to be inferred , the additional parameter vector is now extended to include @xmath2 .",
    "thus , @xmath67 .",
    "the posterior distribution can be effectively sampled using markov chain monte carlo ( mcmc ) . in our implementation",
    ", we used the metropolis algorithm @xcite .",
    "starting from a model with a single mode of arbitrary frequency and amplitude , and typical values for the additional parameters @xmath67 , we propose to either add a mode ( with its frequency and amplitude chosen from the prior ) , remove a mode , move a mode s frequency or amplitude , or shift the value of one of the additional parameters such as mode lifetime @xmath24 .",
    "then , the proposed change is accepted with a probability that depends on the relative likelihoods and prior probabilities of the current and the proposed model .",
    "steps to models with higher posterior probability are always accepted , steps to models with a lower posterior probability are accepted with a probability given by the ratio of the posterior probability of the proposed model to the probability of the current one . if a proposed change to the model is rejected , the next model in the sequence is the same as the previous one .",
    "when this algorithm runs , the output of the code is a random sequence of models ( sets of frequencies and amplitudes ) , each possibly slightly different from the last , where the diversity amongst the models is indicative of the uncertainty of any inference . to save memory , a subset of effectively independent models from this sequence",
    "may be used for any subsequent calculations .",
    "this is called `` thinning the chain '' . for an introduction to mcmc see @xcite , for a description within a context similar to this one , see b07 .",
    "unfortunately , the presence of the matrix inverse and determinant in the likelihood function ( equation  [ gaussian ] ) limits this algorithm to time series with less than @xmath68 1500 points : even if the cholesky decomposition is used to calculate det(@xmath41 ) and @xmath69 this still involves a calculation that takes time proportional to @xmath70 , where @xmath37 is the number of points in the time series . for longer time series , other approaches",
    "are necessary ; alternatively , approximations to equation  [ gaussian ] may be possible , but are beyond the scope of this paper .",
    "additional efficiency can be obtained by using slice sampling @xcite rather than metropolis for the moving of frequencies and amplitudes .",
    "in this section , we demonstrate the use of our model on simulated data . to illustrate the method we show its output alongside output from other methods .",
    "we start with a simple case of a time series containing one mode and subsequently expand to several modes .",
    "we generated a long time series by numerically solving the ordinary differential equation  [ ode ] for a single mode of frequency 100 @xmath2hz and damping timescale ( mode lifetime ) 10@xmath71 s = 1.1574 days or 10 oscillation periods .",
    "the amplitude of the signal was scaled to a standard deviation of 2 ms@xmath72 and then evaluated at 433 points in time , simulating 8 hours of nightly observations over an observing period of a month .",
    "in fact , the time stamps were the same as those from the @xmath1 data observed by ) .",
    "thus , the simulated data has the same window function as the actual @xmath1 data .",
    "measurement error was simulated by adding noise from a gaussian distribution with a standard deviation of 2.5 m s@xmath72 .",
    "the results obtained from analysing this data are displayed in figure  [ onemode1 ] .",
    "the top panel shows the standard periodogram . in the 2nd panel ,",
    "the results from bayesian sine - wave fitting ( b07 ) are shown .",
    "the b07 method is closely related to the iterative sine - wave fitting algorithm clean , except that all frequencies are fitted simultaneously , and quantitative uncertainties are easily obtained .",
    "the mcmc approach of the b07 method actually returns a _",
    "sample _ of fitted models , not a single one , however the results can be conveniently summarised by accumulating all detected frequencies into a single container , and then plotting a histogram of the frequencies .",
    "this histogram is what appears in the 2nd panel of figure  [ onemode1 ] . in the 3rd panel ,",
    "a similar histogram is plotted of the output from running mcmc with the gaussian process likelihood introduced in this paper .",
    "finally , the `` amplitude - weighted '' lower panel is a similar histogram , however in this case , before binning , each detected frequency is given a weight proportional to its amplitude .",
    "thus , the 3rd panel indicates our confidence in the existence of a peak , while the 4th panel illustrates the estimated amplitude of each peak , and can be considered our version of an amplitude spectrum .",
    "the mcmc run with the gaussian process likelihood took about one hour to complete ( although an mcmc run never really finishes , just becomes more and more useful the longer it runs ) on a modern pc with a 2 ghz dual core processor , compared to 15 minutes for the bayesian sine - wave fitting and seconds for computing the periodogram .",
    "note that the periodogram would need further processing , such as lorentzian profile fitting @xcite , to obtain a posterior distribution for the frequency of the mode .",
    "doing this would result in a posterior similar to the 3rd panel of figure  [ onemode1 ] , but with a slightly larger uncertainty due to the fact that the periodogram is not a sufficient statistic .",
    "the approach outlined in this paper clearly identifies the presence of a mode with frequency 100.38 @xmath73 0.48 @xmath2hz .",
    "this is possible because the gaussian process model takes into account at the outset the fact that the predicted signal due to a mode is not a pure sinusoid .",
    "lacking this information , the sine - wave fitting approach is forced to introduce many peaks in order to explain the data ( figure  [ onemode1 ] ) .",
    "note that the alias peaks at 90 and 110 @xmath2hz are automatically removed by the gaussian process model .",
    "they are only partially removed by the sinewave fitting , but would have been completely removed had the signal been truly sinusoidal .    ]",
    "a further test of this method was done by testing it on simulated data containing many modes .",
    "specifically , we generated simulated data from a star with 11 modes with frequencies ranging from 50 - 150 @xmath2hz in steps of 10 @xmath2hz .",
    "the time series contained 433 data points at the @xmath1 times , as above .",
    "the results from analysing this simulated data set are shown in figure  [ multifreq_spectrum ] . while this result is less impressive than the single mode case ,",
    "the algorithm has still successfully identified most of the input frequencies .",
    "there are some anomalies , such as the merging of the peaks at 50 and 60 @xmath2hz , and the upward shift of the 80 @xmath2hz mode .",
    "note that the uncertainty about each frequency can be read off the width of the peaks in the bottom panel of figure  [ multifreq_spectrum ] . whilst our method provides cleaner results than the raw periodogram",
    ", it is clearly not perfect . when interpreting results from this method , the summary plots like those shown in figure  [ multifreq_spectrum ] may be used as a guide , but the full output of the mcmc sample should be considered when the results are critical .",
    "the mode lifetime @xmath24 can be measured using our analysis , as it is just another parameter that gets estimated by the mcmc .",
    "the posterior distribution for the mode lifetime is simply a histogram of the @xmath24 values encountered by the mcmc chain . for the multiple - mode simulated data ,",
    "this distribution is shown in figure  [ modelifetime ] .",
    "the true input value of @xmath74 is recovered , albeit with a large uncertainty , which is unsurprising given the time series is only 433 points in size .",
    "the distribution is asymmetric , largely due to our choice of a @xmath75 prior .",
    "thus , conventional error bars are inappropriate .",
    "an alternative statement of uncertainty is the symmetric 95% credible interval for the mode lifetime , which is [ 0.58 , 2.10 ] days .",
    "we now turn to the real observations of @xmath76hydrae .",
    "the first preliminary analysis of the data presented by showed strong evidence for solar - like oscillations based on the amplitude , the frequency range , and the frequency separation of the extracted modes , which all agreed with theoretical predictions .",
    "they assumed that the mode lifetime was relatively long , in accord with the theoretical calculations by @xcite ( @xmath77 days ) , and hence their analysis relied on the conventional power spectrum and iterative sine - wave fitting ( clean ) .",
    "the value they found for the dominant frequency separation was 7.1 @xmath2hz found between the strongest modes and 6.8 @xmath2hz found from an autocorrelation of the power spectrum in the region of excess power .",
    "subsequent studies of the same data including extensive simulations by @xcite indicated that the mode lifetime was significantly shorter than the theoretical value ( @xmath78 days ) .",
    "this result was further confirmed by using an independent approach which also confirmed the frequency separation found by , but they showed that the precision by which the frequency separation could be established from the data was low due to the short mode lifetime . in this section we will apply our new gaussian process method to the @xmath76hydrae observations and compare our results with those found by the previous studies .",
    "the results from running our code on the @xmath1 data are displayed in figures  [ xihya_sample ] and  [ xihya_spectrum ] .",
    "the diversity of the models in figure  [ xihya_sample ] indicates that the uncertainties are quite large , and only a few modes are securely detected ; this result agrees with the analysis of .",
    "the large uncertainty about the frequencies is confirmed by the lower panel of figure  [ xihya_spectrum ] - the area under the curve over any frequency range is proportional to the probability that a mode exists within that range , yet even the peaks in this plot are only a factor of @xmath68 2 - 3 higher than the background .",
    "there is some suggestion of a regular pattern to the peaks . to measure the large frequency separation",
    ", we took the power spectrum of the lower panel of figure  [ xihya_spectrum ] ( a full bayesian estimate of the large frequency separation , as done in b07 , is prohibitive in this case ) in order to search for periodicities .",
    "this power spectrum is displayed in figure  [ sep ] and shows at least three possible periodicities in the frequency pattern : one at 6.3 @xmath2hz , another at 9.6 @xmath2hz and a third peak at 19.2 @xmath2hz ( although this is simply a doubling of the 9.6 @xmath2hz peak ) .",
    "usually , if @xmath79 and @xmath80 modes are detected , the dominant separation of modes is half of the large frequency separation .",
    "this would imply that the large separation of @xmath1 is 12.6 , 19.2 or 38.4 @xmath2hz .",
    "however , from the classical stellar parameters ( luminosity , mass , and effective temperature ) , the estimated large separation is 7.0 @xmath2hz with about 10% uncertainty , using the solar scaling presented in .",
    "also , a stellar pulsation model that goes through the star s position in the h - r diagram gives an average large spacing of 7.2 @xmath2hz .",
    "hence , the most plausible solution consistent with stellar astrophysics is that 6.3 @xmath2hz is the large separation , not half of the large separation .",
    "thus , we conclude that radial modes contributed most of the signal , non - radial modes may be excited with amplitudes below the detection threshold .",
    "although we have not formally modelled the uncertainty in the large separation , inspection of figure  [ xihya_sample ] shows that the uncertainty must be large .",
    "this uncertainty may be reduced with further observations , or perhaps by taking theoretical models of the star into account as prior information ( b07 ) .",
    "our analysis used a uniform prior distribution for the frequencies , but if a large ensemble of plausible stellar models is produced , this would significantly reduce the range of possible frequency patterns and significantly improve the quality of the data analysis . performing such an analysis",
    "is beyond the scope of this paper .    the posterior distribution for the mode lifetime of @xmath1 is shown in figure  [ modelifetime_xihya ] .",
    "the mode lifetime is found to be very short , of order 1 day , albeit with a fairly large uncertainty .",
    "an estimate with 1-@xmath81 error bars is @xmath82 , and we find that @xmath24 lies between 0.41 and 2.65 days with 95% posterior probability .",
    "this compares well with the result of who estimated @xmath24 to be 2 days , but also with a large uncertainty .",
    "this mode lifetime remains much shorter than the theoretical predictions of 15 - 20 days @xcite .",
    "in this paper , we have described a new bayesian method for inferring the frequencies and amplitudes ( with uncertainties on everything , including the number of modes present ) of stellar oscillation modes from time series observations of the radial velocity or the intensity of the star .",
    "the method includes a gaussian process likelihood , which allows us to take into account the fact that the predicted signature of an oscillation mode is not exactly sinusoidal .",
    "exactly how non - sinusoidal the oscillation signals are , is described by the mode lifetime , which is also estimated from the data , along with a measurement of the uncertainty in this value .",
    "the method was implemented using a markov chain monte carlo algorithm and applied to two simulated data sets .",
    "as expected , the method removed the extra peaks caused by aliasing and the finite mode lifetime .",
    "we speculate that this method is , at the very least , comparable to the results obtained by fitting the power spectrum , but is more straightforward to interpret .",
    "our method also avoids any concerns about information loss due to the fact that the power spectrum is not a sufficient statistic ; whether this is of significant practical importance depends on the sampling of the time series , and the mode lifetime . for well - sampled time series and long mode lifetimes ,",
    "information loss is not an issue .",
    "unfortunately , the method presented in this paper is computationally intensive due to the presence of a matrix inverse and determinant in the likelihood function .",
    "this limits its practical use to small time series with less than about 1500 points . for time series with 1500 - 15000 points , the bayesian sine wave fitting approach ( b07 )",
    "is recommended , and for those with more than 15000 points , neither is computationally feasible ; periodogram - based analysis is clearly the best choice here .    applying the method to radial velocity data of the red giant @xmath1",
    ", we found that the mode lifetime lies between 0.41 and 2.65 days with 95% posterior probability .",
    "the large frequency separation was estimated to be either 6.3 @xmath2hz or 9.6 @xmath2hz , with the former being the most plausible given the star s position in the hertzsprung - russell diagram .",
    "c++ programs implementing the methods described in this paper ( both the gaussian process and the sinewave fitting versions ) are available upon request from b. j. brewer .",
    "bjb would like to thank david mackay for convincing me that a gaussian process approach would be feasible for this problem , and matt francis for bringing the pictionary to my graduation party .",
    "the authors would like to thank tim bedding and hans bruntt for valuable discussion .",
    "bjb and ds acknowledge funding from the australian research council .",
    "we also acknowledge the anonymous referee for their criticism , which helped us to improve the paper ."
  ],
  "abstract_text": [
    "<S> the measured properties of stellar oscillations can provide powerful constraints on the internal structure and composition of stars . to begin this process </S>",
    "<S> , oscillation frequencies must be extracted from the observational data , typically time series of the star s brightness or radial velocity . in this paper , </S>",
    "<S> a probabilistic model is introduced for inferring the frequencies and amplitudes of stellar oscillation modes from data , assuming that there is some periodic character to the oscillations , but that they may not be exactly sinusoidal . </S>",
    "<S> effectively we fit damped oscillations to the time series , and hence the mode lifetime is also recovered . </S>",
    "<S> while this approach is computationally demanding for large time series ( @xmath0 1500 points ) , it should at least allow improved analysis of observations of solar - like oscillations in subgiant and red giant stars , as well as sparse observations of semiregular stars , where the number of points in the time series is often low . </S>",
    "<S> the method is demonstrated on simulated data and then applied to radial velocity measurements of the red giant star @xmath1 , yielding a mode lifetime between 0.41 and 2.65 days with 95% posterior probability . </S>",
    "<S> the large frequency separation between modes is ambiguous , however we argue that the most plausible value is 6.3 @xmath2hz , based on the radial velocity data and the star s position in the hr diagram .    </S>",
    "<S> [ firstpage ]    stars : oscillations  methods : statistical  stars : individual : @xmath1 </S>"
  ]
}