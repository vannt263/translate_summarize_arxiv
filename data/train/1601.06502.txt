{
  "article_text": [
    "a _ multiset _ is a generalization of a set in which each element has an associated integer _ multiplicity_. given a possibly infinite set @xmath4 , a set ( resp .",
    "multiset ) homomorphic hash function on @xmath4 maps finite subsets of @xmath4 ( resp .",
    "finitely - supported multisets on @xmath4 ) to fixed - length hash values , allowing incremental updates : when new elements are added to the ( multi)set , the hash value of the modified ( multi)set can be computed in time proportional to the degree of modification .",
    "the incremental update property makes homomorphic hashing a very useful and versatile primitive .",
    "it has found applications in many areas of computer security and algorithmics , including network coding  @xcite and verifiable peer - to - peer content distribution  @xcite , secure internet routing  @xcite , byzantine fault tolerance  @xcite , _ streaming _ set and multiset equality comparison  @xcite , and various aspects of database security , such as access pattern privacy  @xcite and integrity protection  @xcite .",
    "this latter use case provides a simple example of how the primitive is used in practice : one can use homomorphic hashing to verify the integrity of a database with a transaction log , by computing a hash value for each transaction in such a way that the hash of the complete database state is equal to the ( appropriately - defined ) sum of the hashes of all transactions .",
    "another observation  @xcite is that homomorphic hashing can be used for incremental and parallel hashing of lists , arrays , strings and other similar data structures : for example , the list @xmath5 can be represented as the set @xmath6 , and it suffices to apply the homomorphic hash function to that set .",
    "a framework for constructing provably secure homomorphic hash functions ( in some suitably idealized model , such as the random oracle model ) was introduced by bellare and micciancio  @xcite , and later extended to the multiset hash setting by clarke  et al .",
    "@xcite , and revisited by cathalo  et al .",
    "@xcite .",
    "roughly speaking , the framework of bellare and micciancio can be described as follows . to construct a ( multi)set homomorphic hash function on @xmath4",
    ", one can start with a usual hash function @xmath7 from @xmath4 to some additive group @xmath8 , and extend it to finite subsets of @xmath4 ( resp .",
    "multisets on @xmath4 ) by setting @xmath9 ( resp .",
    "@xmath10 , where @xmath11 is the multiplicity of @xmath12 ) . and",
    "in fact , it is clear that all possible homomorphic hash functions arise in that way .",
    "note that as in clarke  et al .",
    "@xcite , and unlike the original framework of bellare and miciancio  @xcite , there is no block index @xmath13 included in the hash @xmath14 of each element @xmath12 , because we are hashing unordered sets / multisets , rather than ordered sequences of blocks .",
    "assume that the underlying hash function @xmath7 is ideal ( i.e. it behaves like a random oracle ) .",
    "then we can ask when the corresponding homomorphic hash function @xmath15 is secure ( collision resistant , say ) .",
    "this translates to a knapsack - like number - theoretic assumption on the group @xmath8 , which bellare and micciancio show holds , for example , when the discrete logarithm problem is hard in @xmath8 .    concretely , bellare and micciancio and the authors of subsequent works propose a number of possible instantiations for @xmath15 which essentially amount to choosing @xmath16 or @xmath17 for suitable parameters @xmath18 .",
    "these concrete instantiations yield simple implementations , but they all suffer from suboptimal output size ( they require outputs of several thousand bits to achieve collision resistance at the @xmath19 security level ) , and their efficiency is generally unsatisfactory .",
    "essentially all practical applications of homomorphic hashing in the security literature seem to focus on the case @xmath20 , called ` muhash ` .      within bellare and micciancio s framework , constructing a homomorphic hash function",
    "amounts to choosing a group @xmath8 where the appropriate number - theoretic assumption holds , together with a hash function to @xmath8 whose behavior is close enough to ideal for the security proof to go through .    in this paper , we propose a novel concrete construction of a multiset hash function by choosing @xmath8 as the group of points of a binary elliptic curves , and picking the hash function following the approach of brier  et al .",
    "@xcite ( which we improve upon slightly ) applied to the binary curve variant of shallue and van de woestijne s encoding function  @xcite .",
    "we also describe a software implementation of our proposal ( building upon the work of aranha  et al .",
    "@xcite for binary curve hashing , and using blake2  @xcite as the actual underlying hash function ) and provide extensive performance results showing that our function outperforms existing methods by a large margin on modern cpu architectures ( especially those supporting carry - less multiplication ) .",
    "furthermore , choosing an elliptic curve ( with small cofactor ) for the group of hash values solves the `` output size '' problem of homomorphic hashing outright : @xmath21 collision security is achieved with roughly @xmath22-bit long digests .",
    "yet , they do not seem to have been used in concrete implementations of homomorphic hashing so far for a more detailed discussion . ] .",
    "one can wonder why ; the most likely explanation is that usual methods for hashing to elliptic curves are far too inefficient to make curves attractive from a performance standpoint : almost all such methods require at least one full size exponentiation in the base field of the curve , which will be much more costly by itself than the single multiplication ( in a much larger field ) required by ` muhash`even on curves over fast prime fields at the 128-bit security level  @xcite , such an encoding function is over @xmath23 times slower than ` muhash ` at equivalent security on haswell , and over @xmath24 times slower than our construction .",
    "only by using binary curves and relatively sophisticated implementation techniques do we avoid that stumbling block and prove that elliptic curves can be competitive . as a result",
    ", we achieve a processing speed of over 3 million set elements per second on a intel haswell cpu at the @xmath19-bit security level .",
    "speedups are expected with the release of intel broadwell processors and its improved implementation of carry - less multiplication .",
    "recently , new developments have been announced regarding the asymptotic complexity of the discrete logarithm problem on binary elliptic curves , particularly by semaev  @xcite .",
    "these results are somewhat controversial , since they are based on heuristic assumptions that prevailing evidence suggests are unlikely to hold  @xcite , and their storage requirements appear to make them purely theoretical anyway  @xcite .    however , if semaev s claims of an @xmath25 $ ] attack turn out to be correct , the asymptotic security of binary elliptic curve - based ecmh would be reduced .",
    "concrete _ security of our construction , on the other hand , would be completely unaffected on curves of up to 300 + bits ( and in particular at the 128-bit security level on gls254 ) , since the claimed attack is worse than generic attacks on such curves . moreover , even if _ actually practical _ @xmath25 $ ] attacks were to be found , ecmh on binary curves is likely to remain attractive , since it mainly competes against ` muhash ` , which is vulnerable to an @xmath26 $ ] subexponential attack .    for all these reasons , we believe that ecmh on binary elliptic curves is a safe choice for security - minded practitioners , and that the switch from ` muhash ` to ecmh is entirely justified in view of the considerable performance gain ( which lets designers choose a higher security margin and still come out far ahead ) .",
    "formally , we define a multiset @xmath27 as a function with finite support mapping a base set @xmath4 to the integers @xmath28 . as an extension of the usual definition in which multiplicities are restricted to @xmath29 , we allow negative multiplicities as well",
    ". we will implicitly consider subsets @xmath30 to be multisets in @xmath31 .",
    "clarke  et al .",
    "@xcite introduce a definition of a multiset hash function that efficiently supports incrementally adding ( multisets of ) elements .",
    "we give a simpler ( but nearly equivalent . ] ) definition that makes the connection to homomorphic hash functions  @xcite explicit :    let @xmath4 be a set and let @xmath32 be a finite group .",
    "a function @xmath33 that maps multisets over the base set @xmath4 to a point in @xmath8 is said to be a _",
    "homomorphic multiset hash function _",
    "if @xmath15 is a group homomorphism from the pointwise - additive group of functions @xmath34 to @xmath32 ; equivalently , @xmath35 for all @xmath36 .",
    "we define @xmath37 by @xmath38 .",
    "[ def : homomorphic - multiset - hash ]    this definition minimally captures an intuitive notion of a multiset hash function that supports incrementally adding and removing ( multisets of ) elements .",
    "these incremental updates are efficient assuming that addition and negation in @xmath8 can be performed efficiently and @xmath39 can be computed efficiently ( e.g.  in time linear in the representation length of the non - zero values of @xmath40 ) .",
    "note that since pointwise addition in @xmath31 is commutative , the relevant subgroup @xmath41 is necessarily commutative , and therefore without loss of generality we can assume that @xmath8 is commutative .",
    "it may seem that it is too strong of an assumption to require a group structure on @xmath8 , or equivalently , that ( multisets of ) elements can be removed as well as added . in fact , provided that @xmath42 is lossless , in that @xmath43 implies @xmath44 , there is no loss of generality .",
    "we show in [ sec : monoid - to - group ] that we can construct a group that supports ( efficient ) incremental removals based only on ( efficient ) incremental additions .",
    "since the set of singleton subsets of @xmath4 generates the group @xmath34 , @xmath15 can conversely be uniquely defined by @xmath45 : @xmath46 indeed , this is precisely the _ randomize - then - combine paradigm _ proposed by bellare and micciancio  @xcite for incremental hashing of messages , which is readily ( in fact , more naturally than to message hashing ) applied by clarke  et al .",
    "@xcite to multiset hashing .",
    "our goal is to minimize the computational cost for computing @xmath15 and the representation size for elements of @xmath8 while achieving a given level of collision resistance .",
    "a _ collision _ for a hash function @xmath15 is a pair @xmath47 such that @xmath48 but @xmath49 . for any group - homomorphic hash function @xmath15 from a group @xmath50 to @xmath51 , a collision",
    "can equivalently be defined as a value @xmath52 . by the birthday",
    "bound that applies to any hash function , a collision can be found with at most expected @xmath53 hash computations ; we can hope to design a multiset hash function for which expected time @xmath54 is also a lower bound . and",
    "group @xmath32 from some hash function family ( distribution ) @xmath55 . ]    a _ preimage attack _ seeks to invert the hash function , namely to find a value @xmath56 such that @xmath57 , for a random element @xmath58 in the image of @xmath15 .",
    "we can hope to design a multiset hash function for which the expected time complexity of the best preimage attack is also equal to the generic upper bound @xmath59 .",
    "note that for a homomorphic hash function we do not consider preimage attacks on the identity element @xmath60 , since its preimage is fixed .",
    "a _ second preimage attack _ seeks to find a value @xmath61 such that @xmath62 , for some known value @xmath56 .",
    "since a second preimage implies a collision , the time complexity of a second preimage attack is lower bounded by the time complexity of the best collision attack , ideally @xmath54 . for a general , non - homomorphic hash function , we can hope that the best attack has expected @xmath59 time complexity . for any homomorphic hash function",
    ", however , the group structure implies that a second preimage attack is no harder than a collision attack ( with expected time complexity upper - bounded by @xmath53 ) .",
    "a random oracle @xmath37 clearly achieves the optimal preimage resistance of @xmath63 and the optimal collision resistance of @xmath64 , in the sense that at least this many oracle queries are needed to compute preimages and collisions respectively .",
    "it does not follow , however , that the associated multiset hash function @xmath65 has the same security level ; for example , if we choose @xmath66 , then @xmath67 oracle queries , instead of @xmath68 , are enough to find arbitrary preimages in polynomial time by solving a simple @xmath69 linear system over @xmath70 .",
    "however , bellare and micciancio  @xcite have shown ( in the set hash setting , but this generalizes naturally to multisets ) how to obtain a security reduction for @xmath71 based on a computational hardness assumption on the group @xmath8 . for concrete choices of @xmath8 ,",
    "that hardness assumption is related to standard number theoretic problems , such as the discrete logarithm problem or modular knapsacks .    when @xmath72 , the resulting multiset hash function @xmath71 is essentially ` mset - mu - hash `  @xcite , the multiset variant of ` muhash `  @xcite .",
    "when @xmath73 , we essentially obtain ` mset - vadd - hash `  @xcite , the multiset variant of ` lthash ` ( for @xmath74 ) or ` adhash ` ( for @xmath75 )  @xcite .",
    "these functions all have security reductions in the framework sketched above .",
    "it is relatively easy to find plausible concrete instantiations of the random oracle @xmath7 to a group like @xmath76 , but for more general groups , this is usually more complicated , and as a result it is often convenient to replace @xmath7 by a _ pseudo - random oracle _ ,",
    "i.e.  a construction that is indifferentiable from a random oracle in the sense of maurer  et al .",
    "typically , we can take @xmath7 of the form @xmath77 where @xmath78 is a random oracle to some intermediate set @xmath79 ( such as bit strings , so that we can plausibly instantiate it with standard hash function constructions like sha-2 can be readily encoded as octet strings . ] ) and @xmath80 is an _ admissible encoding function _  @xcite that has the property of mapping the uniform distribution over @xmath79 to a distribution indistinguishable from uniform over @xmath8 .",
    "` adhash ` is appealing for its simplicity , but is far from optimal in terms of hash code size . in the _",
    "set _ hashing setting ( i.e.  @xmath81 ) , the best known attack is the generalized birthday attack  @xcite ; under the assumption that this attack is optimal , the group @xmath82 corresponds to a security level of roughly @xmath83 bits . in the _ multiset _ hashing setting , `",
    "adhash ` is completely impractical due to the extremely large hash code sizes @xmath84 required to defeat lattice reduction attacks described in [ sec : adhash - attack ] .",
    "there are reductions from computing discrete logarithms in a group @xmath8 to finding collisions in the corresponding random oracle multiset hash function @xmath85  @xcite .",
    "these reductions can be used to prove a collision resistance property for the generic multiset hash family over any group in which computing discrete logarithms is hard , such as @xmath86 .",
    "however , because discrete logarithms in @xmath86 can be solved by e.g.  the number field sieve with ( heuristic ) subexponential time complexity @xmath87{64/9}\\big]$ ]  @xcite , it is usually estimated that we need to choose @xmath88 of around @xmath89 bits for @xmath19-bit security ( see for example the evaluation of the ecrypt  ii report on key sizes  @xcite ) .",
    "in contrast , in a generic group , discrete logarithms can not be computed faster than expected time @xmath64 , which is also the optimal collision resistance .",
    "for properly chosen elliptic curves over finite fields , there are no known algorithms for solving the discrete logarithm problem in the elliptic curve group faster than in a generic group , i.e.  expected time @xmath64 .",
    "therefore , there is a clear possibility for using an elliptic curve group to obtain a given level of collision resistance with a much lower group size than with ` mset - mu - hash ` .    applying the generic multiset hash construction to elliptic curve groups",
    "presents a problem , however : while it is easy to define a very efficient admissible encoding from @xmath90 to @xmath86 for sufficiently large @xmath91 , an admissible encoding to an elliptic curve group is not so easily defined . while constructions for admissible encoding functions have been demonstrated  @xcite ,",
    "their computational cost is higher than we would like .",
    "in fact , we can significantly relax the requirement on the encoding function @xmath92 and still obtain a very tight reduction , due to random self - reducibility of the discrete logarithm problem .",
    "our relaxed requirement is related to the definition of @xmath93-weak encodings by brier  et al .",
    "@xcite , and is satisfied in practice by a large class of encoding functions  @xcite .    a function @xmath94 between finite sets is said to be an @xmath95-weak encoding , for integer @xmath96 and real value @xmath97 , if it satisfies the following properties :    1 .",
    "_ samplable _ : there is an efficient randomized algorithm for computing @xmath98 and sampling uniformly from @xmath99 for any @xmath100 .",
    "@xmath101 for all @xmath100 .",
    "3 .   @xmath102 \\geq 1 / \\beta$ ] .",
    "an @xmath95-weak encoding function @xmath92 allows us to efficiently sample @xmath103 uniformly at random using @xmath104 uniform samples @xmath105 in expectation , with the property that @xmath106 for any accepted sample @xmath107 obtained from @xmath108.-weak encoding @xmath92 is an @xmath109-weak encoding .",
    "our definition allows for a tighter bound to be given in [ thm : dlpreduction ] . ]",
    "[ def : alpha - beta - weak - multiset - hash - family ] let @xmath110 be an @xmath95-weak encoding from @xmath79 to the abelian group @xmath8 .",
    "assume that @xmath8 admits as a direct factor a cyclic subgroup @xmath111 of prime order @xmath112 , and that we can efficiently sample from the complement group @xmath113 in the direct factor decomposition @xmath114 .",
    "given a random oracle @xmath78 , we denote by @xmath115 the function @xmath116 given by @xmath117 , and by @xmath118 the associated multiset hash function .",
    "the following theorem shows that finding a collision in @xmath119 with multiplicities up to @xmath120 is as hard as computing discrete logarithms to the base @xmath121 , up to a small factor that depends on @xmath104 .",
    "note that @xmath119 does not depend on the choice of subgroup @xmath111 , but the strongest security result is obtained by choosing the largest prime - order subgroup .",
    "the requirement of efficient samplability of @xmath113 is easily satisfied in practice , since efficiency concerns regarding representation size dictate that @xmath113 be as small as possible ( usually having at most @xmath122 elements , and most of the time only @xmath123 or @xmath124 ) .",
    "theoremdlpreduction [ thm : dlpreduction ] let @xmath119 be a multiset hash function as in [ def : alpha - beta - weak - multiset - hash - family ] .",
    "given an algorithm @xmath125 with access to the underlying random oracle @xmath126 that finds a non - empty multiset @xmath127 with @xmath128 , in expected time @xmath129 with probability @xmath130 using @xmath131 queries to @xmath126 , discrete logarithms to the base @xmath121 can be computed with probability @xmath132 in expected time @xmath133 , where @xmath134 is a bound on the length of the output of @xmath125 ; @xmath135 denote the time required for a constant number of group operations , and are given in the proof .",
    "see appendix  [ sec : proofthmdlpreduction ] .",
    "concretely , if @xmath136 is the group of @xmath137-rational points on a suitable elliptic curve @xmath138 chosen to avoid any discrete logarithm weaknesses , with a subgroup @xmath111 of prime order @xmath139 , and @xmath92 is an @xmath95-weak encoding function with small constant @xmath104 , then @xmath119 has collision resistance roughly @xmath140 .",
    "since an element of @xmath141 can be represented using @xmath142 bits , the collision resistance of @xmath119 is essentially optimal ( to within a few bits ) .      the shallue - van de",
    "woestijne ( sw ) algorithm for characteristic 2 fields  @xcite can be used to map any point @xmath143 to a pair @xmath144 satisfying an arbitrary elliptic curve equation @xmath145 where @xmath146 .",
    "it constructs three values of @xmath56 from @xmath147 with the property that at least one necessarily has a corresponding value @xmath58 satisfying [ eq : elliptic - curve ] .",
    "in addition to the usual arithmetic operations over @xmath148 , its definition depends on three _ linear _ maps :    1 .   the _ trace _ function @xmath149 defined by @xmath150 ;  @xcite 2 .",
    "a _ quadratic solver _",
    "function @xmath151 that satisfies @xmath152 and @xmath153 ; 3 .",
    "@xmath154 where @xmath155 is the zeroth coefficient of any ( fixed ) polynomial representation of @xmath56 .    an optimized version of the algorithm that requires only a single field inversion  @xcite is shown as [ alg : sw - encode ] .",
    "the algorithm is parameterized by a value @xmath156 satisfying @xmath157 ; for fields of degree @xmath158 , we can choose @xmath159 where @xmath160 is the indeterminate in the polynomial representation of @xmath148 .",
    "the result @xmath161 is represented in @xmath162-affine coordinates  @xcite for efficiency . satisfying [ eq : elliptic - curve ] : @xmath163 .",
    "when using @xmath162-affine coordinates , this value must be represented specially . ]",
    "the addition to @xmath162 of @xmath164 in [ alg : sw - encode : coeff - line ] is not part of the original sw algorithm ; this trivial addition serves to halve the number of collisions at essentially no extra cost .",
    "@xmath156 such that @xmath165    @xmath166 , @xmath167 for @xmath168 @xmath169 @xmath163 @xmath170 @xmath171 @xmath172 @xmath173 @xmath174 [ alg : sw - encode : coeff - line ] @xmath175    it is clear from the definition that the number of preimages of any point @xmath175 under is at most @xmath176 , since @xmath177 and @xmath147 is uniquely determined from @xmath178 , @xmath56 , and @xmath162 by @xmath179 the preimage set for any point @xmath175 can be efficiently computed by these same formulas .",
    "furthermore , aranha  et al .",
    "@xcite show that the proportion of curve points with @xmath91 preimages under @xmath180 for @xmath181 is @xmath182 , @xmath183 , @xmath184 , and @xmath185 , respectively , up to an error term of @xmath186 .",
    "it follows that @xmath187 = 1/3 \\pm o(2^{-n/2})$ ] , and therefore , swchar2 is an @xmath188-weak encoding with @xmath189 .",
    "based on this encoding function , we define the _ elliptic curve multiset hash ( ecmh ) _ : given a binary elliptic curve group @xmath190 and an intermediate hash function @xmath191 ( modeled as a random oracle ) , we define @xmath192 .",
    "commonly used elliptic curves over @xmath148 , including the nist - recommended ones , have a generator of prime order @xmath193 with an easily determined complement group of size @xmath194 .",
    "thus , the samplability requirement on @xmath113 is easily satisfied in practice .",
    "hence , by [ thm : dlpreduction ] , finding a collision in ecmh is as hard ( up to a small constant factor ) as computing discrete logarithms to the base @xmath121 , which we assume to be @xmath195 .",
    "similar suitable encoding algorithms exist for elliptic curves over fields of characteristic @xmath196  @xcite , and could also be used to define an elliptic curve multiset hash . however , the use of a characteristic 2 field eliminates the need for an expensive field exponentiation in order to solve a quadratic equation , which would otherwise dominate the computation time , and on modern cpus that support fast carry - less multiplication , fast implementations of all other required field operations are also possible for characteristic @xmath124  @xcite .",
    "the group of @xmath148-rational points on an elliptic curve @xmath197 has order @xmath198 .",
    "each point is naturally represented as a pair @xmath199 ( or @xmath200 ) , but there is a well - known method for encoding a point using just @xmath201 bits : given @xmath56 there are at most two possible values for @xmath58 ( or @xmath162 ) if @xmath202 ( or @xmath203 ) satisfy @xmath197 , and they can be recovered efficiently using a small number of field operations .",
    "thus , a point can be encoded by its @xmath56 value and a single additional bit to disambiguate the two possible points .",
    "the elliptic curve group identity element ( the point at infinity ) can be encoded specially without increasing the representation size , by using a bit sequence that would not otherwise encode a valid point .",
    "we developed an optimized implementation of elliptic curve multiset hash ( ecmh ) as an open - source c++ library  @xcite , with support for all nist - recommended binary elliptic curves  @xcite and the record - breaking gls254 curve  @xcite , as well as several other sec  2-recommended curves  @xcite . using a combination of c++ templates and code generation",
    ", we were able to write generic code to support many different configurations without sacrificing runtime performance ; only for modular reduction was a custom implementation required for each supported field .",
    "we incorporated existing fast x86/x86 - 64 polynomial multiplication , squaring , and modular reduction routines for @xmath204 , @xmath205 , @xmath206 , @xmath207 , @xmath208 , @xmath209 , @xmath210  @xcite and for @xmath211  @xcite .",
    "we implemented field inversion using a polynomial - basis itoh ",
    "tsujii inversion method making use of multi - squaring tables  @xcite .",
    "we generated field inversion routines for each field degree automatically based on an a^*^ search procedure for computing the optimal itoh ",
    "tsujii addition chain and set of multi - squaring tables , based on a machine - specific cost model estimated from field operation performance measurements  @xcite .",
    "we also developed optimized implementations of the ` mset - mu - hash ` and ` mset - add - hash ` hash functions , based on the modular arithmetic functions in the openssl library version 1.0.1i , for the purpose of comparison .",
    "ecmh requires an intermediate hash function @xmath191 . under our assumption that the base set @xmath4 is the set of octet strings , we simply require a standard cryptographic hash function ( modeled as a random oracle ) with output size @xmath212 .",
    "given the inherent property of any homomorphic hash function that a single collision leads to arbitrary second preimages , we advise using a keyed hash function when possible to minimize risk .    any standard hash function with fixed output size greater than @xmath212 bits can simply be truncated to @xmath212 bits .",
    "standard expansion techniques can be used to efficiently generate an arbitrary length @xmath212 output from a hash function with fixed output size @xmath213 .",
    "sponge constructions , such as keccak  @xcite , are particularly convenient since they support arbitrary output sizes .",
    "both ` adhash ` and ` muhash ` similarly require intermediate hash functions , but with much larger output sizes @xmath212 for equivalent security levels .",
    "we designed our implementation to support arbitrary hash functions , but for our performance evaluation , we selected blake2  @xcite because of its state - of - the - art performance . for @xmath214 , we used the blake2s variant ( 256-bit output ) , truncating the output to @xmath212 bits . for @xmath215",
    ", we used the blake2b variant ( 512-bit output ) with truncation . for @xmath216",
    ", we used blake2b repeatedly to generate sufficient output , in such a way that the underlying compression function is called a minimum number of times .      several key operations for @xmath148 , such as squaring , multi - squaring ( @xmath217 ) , square root , and half - trace , are linear in the coefficients .",
    "for multi - squaring ( useful for inversion ) and half - trace , an implementation based on a lookup table can be significantly faster than direct computation  @xcite .",
    "the coefficients are split into @xmath218 blocks of @xmath104 bits , and a separate table of @xmath219 entries is precomputed for each block position , using a total of @xmath220 bytes of memory , where @xmath221 is the word size in bits .",
    "the linear transform can then be computed from the precomputed tables with @xmath222 memory accesses and @xmath223 xor operations .",
    "the fastest implementation of ecmh is susceptible to timing and cache side - channel attacks , due to the use of lookup tables ( for inversion and qs ) , and the use of branching ( for swchar2 ) .",
    "a branch - free implementation of swchar2 adds only a few additional multiplications and squarings .",
    "lookup tables are unavoidable for good performance , but we can blind inversion at a cost of just two multiplications and generation of one random field element .",
    "we likewise can blind qs at a cost of 1 squaring , 2 additions , and generation of one random field element , as well as a few bit operations to ensure the random element is in the image of qs . in this way we can fully protect against timing and cache side - channel attacks at only a small additional cost .      for even @xmath212 ,",
    "representing @xmath148 as a quadratic extension of @xmath224 results in significantly faster field operations relative to an odd - degree field of roughly the same size : inversion in the extension field requires only one inversion in the base field ( effectively reducing the memory and computation costs by nearly a factor of 4 for a table - based multi - squaring implementation ) , and half - trace requires only 2 half - trace computations in the base field ( reducing , for a table - based implementation , the computation cost by a factor of 2 and the memory requirement by a factor of 4 )  @xcite .",
    "we use this representation to support the gls254 elliptic curve over @xmath225  @xcite .",
    "although an element in the elliptic curve group of points @xmath190 can be represented directly using the standard affine @xmath202-representation or the @xmath162-affine @xmath203 representation , and more compactly using just @xmath226 bits as described in [ sec : compressed - point - representation ] , we can more efficiently perform group operations using the @xmath162-projective representation @xmath227 corresponding to the @xmath162-affine representation @xmath228 : this representation allows point addition and point doubling to be performed without any field inversions  @xcite .",
    "a large fraction of the computational cost of our elliptic curve multiset hash construction is due to the single field inversion required by the swchar2 encoding function . using montgomery s trick ,",
    "@xmath84 independent elements can be inverted simultaneously at the cost of just 1 field inversion and @xmath229 field multiplications  @xcite .",
    "since field inversion is much more than 3 times as expensive as field multiplication , this provides significant computational savings .",
    "a key cost in a nave implementation of ` mset - mu - hash ` is the reduction modulo @xmath88 required by multiplication in @xmath86 .",
    "to avoid this cost , we can use the _ montgomery reduction _",
    "@xcite defined by @xmath230 @xmath231 if @xmath108 is chosen to be a power of @xmath124 , or a power of @xmath232 , where @xmath147 is the word size , then the computational cost of @xmath233 is significantly lower than a reduction @xmath234 .",
    "we represent an element @xmath235 as a triplet @xmath236 corresponding to @xmath237 , where @xmath108 is the montgomery reduction constant .",
    "multiplication under this representation is defined by @xmath238 @xmath239",
    "as our test platforms we used an intel westmere i7 - 970 cpu ( with l3 cache ) and an intel haswell i7 - 4790k cpu ( with l3 cache ) .",
    "both of these processors support the ` pclmulqdq ` instruction for carry - less multiplication , westmere being the first intel architecture to support it ; on the much more recent haswell architecture , where this instruction has significantly lower cost , alternative modular reduction routines based on it are used for @xmath240 , @xmath241 , and @xmath242 for a modest gain in performance  @xcite .",
    "our implementation used a word size of @xmath243 bits and a block size of @xmath244 bits for all half trace and multi - squaring tables .",
    "all code was compiled separately for each architecture using version 3.5 of the clang compiler at the highest optimization level .",
    "we measured the execution time of all operations in cpu cycles , using the combination of ` rdtsc ` , ` rdtscp ` , and ` cpuid ` instructions recommended by intel  @xcite . to improve accuracy and reduce variance",
    ", we disabled turboboost , frequency scaling , and hyperthreading , and ensured that a single non - boot cpu core was used for all benchmarks on each machine .",
    "for each operation , we estimated the benchmarking overhead and subtracted it from the measured number of cycles",
    ". additionally , we automatically determined a per - measurement repeat count for each operation that ensured the benchmarking overhead was less than 10% .",
    "the execution time was computed as the median of the cycle measurements ; the number of cycle measurements for each operation from which the median was computed was at least 1000 and chosen automatically to ensure a sufficiently small 99% confidence interval on the median estimate ( less than the larger of @xmath245 of the estimated median or @xmath246 of a cycle ) . for consistency",
    ", we ensured warm - cache conditions for all estimates by discarding the first 2000 measurements .      for operations with data - dependent memory accesses , such as table - based multi - squaring , half trace computation , and the higher - level operations based on these primitives , we measured the aggregate execution time for a set of inputs guaranteed to induce a uniform memory access pattern ( and then divided by the number of inputs ) , in order to obtain worst - case warm - cache estimates . failure to do so results in a large underestimate of execution time",
    ".    we also observed the performance characteristics of table operations to be significantly affected by the size of the virtual memory pages backing the tables ; in particular , on the x86 - 64 test machines , both the base level performance and the scaling of execution times with increasing table size were significantly better with ( huge ) pages than with pages , due to the cost of translation lookaside buffer ( tlb ) misses . the linux transparent huge page support ( introduced in linux version 2.6.38 ) results in some , but not all , memory regions being backed automatically by huge pages , depending on a number of factors including region alignment and physical memory fragmentation ; when not taken into account ,",
    "this significantly reduced the reliability of our performance measurements . for consistent performance",
    ", we therefore ensured that all lookup tables were backed by huge pages .",
    "in order to obtain performance results for a full range of security levels , we evaluated the performance of ecmh using each of the following eight elliptic curves : sect163k1  @xcite ( nist k-163  @xcite ) , sect193r1  @xcite , sect233k1  @xcite ( nist k-233  @xcite ) , sect239k1  @xcite , gls254  @xcite , sect283k1  @xcite ( nist k-283  @xcite ) , sect409k1  @xcite ( nist k-409  @xcite ) , and sect571k1  @xcite ( nist k-571  @xcite ) .",
    "{ 64/9}\\right]$ ] of the number field sieve for solving discrete logarithms in @xmath86  @xcite . for ` adhash ` , we determined a _ set _ hashing security level of @xmath83 corresponded to groups @xmath82 based on the assumption that the generalized birthday attack  @xcite is optimal . ]    based on [ thm : dlpreduction ] and the assumed hardness of the elliptic curve discrete logarithm problem , the ecmh using an elliptic curve group of order @xmath112 has collision resistance of @xmath247 , corresponding to a security level @xmath248 bits .",
    "we also evaluated ` muhash ` and ` adhash ` ( for set hashing only ) using group sizes corresponding to the same range of security levels .",
    "the correspondence between security level and hash code size under each method is shown in [ fig : hash_code_size ] .",
    "for each multiset hash @xmath15 , we measured the computational cost of incremental hash code updates corresponding to a sequence of incremental additions or removals of multiset elements , i.e.  incrementing or decrementing by 1 the multiplicity of each element in the sequence .",
    "larger changes in multiplicity can also be handled efficiently by scalar multiplication in the group , but we expect incremental additions and removals to be the most common case .",
    "we used a sequence of 1024 randomly generated 32-byte strings ; , 1024 random elements ensures high coverage of the tables and a random access pattern , in order to correctly estimate execution time , as described in [ sec : memory - dependent - measurement ] . ]",
    "longer strings would simply impose an additional cost independent of @xmath15 .",
    "the average cost per element reflects the cost of the intermediate hash function based on blake2 , the cost of encoding the expanded bit sequence as a group element , and the cost of one group operation to add the encoded element to a running total . in the case of ecmh , the encoding is swchar2 and the group operation is implemented as the mixed addition of a @xmath162-affine and a @xmath162-projective point ; batch ecmh effectively replaces 1 field inversion by 3 multiplications , as described in [ sec : batch - swchar2 ] . in the case of",
    "` adhash ` , the encoding is trivial and the group operation is simply integer addition ; batch computation would offer no advantage . for ` muhash ` , the encoding requires a comparison and at most one subtraction , and the group operation requires just a single montgomery multiplication , as described in [ sec : muhash - montgomery ] ; batch computation would offer no advantage over the montgomery representation already used .",
    "the results are shown in [ fig : multiset_hash_cycles ] and in [ tab : multiset_hash_cycles ] .",
    "only element addition performance is shown , as due to the representations used , element removal performance is nearly identical .",
    "timings for point encoding , compression , and decompression are given in [ tab : elliptic_curve_operation2_cycles ] .",
    "base field operation timings are given in [ tab : field_operation_cycles ] , and a comparison of curve operation performance under @xmath162-affine and @xmath162-projective point representations is given in [ tab : elliptic_curve_operation_cycles ] .",
    "@ @ plus 1fil minus @skip    [ cols=\"<,<,>,^,^,^,^,^,^,>,^,^,^,^,^,^ \" , ]     [ tab : elliptic_curve_operation_cycles ]",
    "elliptic curve multiset hash significantly outperforms the existing methods of ` muhash ` and ` adhash ` , particularly in the batch setting , while requiring significantly smaller hash codes at all security levels .",
    "in fact , the hash code size is essentially optimal . because the single field inversion required by the encoding function swchar2 accounts for a large fraction of the computational cost , particularly with larger field degrees , the use of montgomery s trick in the batch setting significantly reduces the computational cost .",
    "the lower computational cost at the 127-bit security level is due to the efficiency of the gls254 curve implementation ; the quadratic extension field representation of @xmath249 employed , and the close match of the degree to the word size @xmath243 , significantly reducing the cost of field operations .",
    "quadratic extension field representations for other fields , such as @xmath250 , could potentially be used to obtain similar performance improvements at other security levels .",
    "furthermore , our choice of parameters follows the trend of increasing native support to binary field arithmetic in desktop processors and will likely benefit from improvements to the carry - less multiplication instruction in the recently released broadwell processor family .",
    "our work is very related to the encrypted elliptic curve hash ( eech )  @xcite .",
    "that construction also encodes separate bit strings as points on a binary elliptic curve and then combines those points using point addition . like our approach",
    ", it relies on the property of binary elliptic curves that curve points can be decoded from a non - redundant representation without expensive field exponentiations , using instead a precomputed lookup table for half - trace , and notes that better performance may be obtained using batch inversion and hardware support for carry - less multiplication .",
    "the full eech construction is proposed as an incremental hash for bit strings ( the message is split into fixed - size blocks , and each block , concatenated with the block index , is encoded as an elliptic curve point ) .",
    "in contrast to our elliptic curve multiset hash , it is specifically designed to _ avoid _ reliance on an underlying random oracle , relying instead on redundancy / padding in the point encoding function for collision resistance .    while the _ full _ construction is not well - suited to homomorphic multiset hashing , under the eech construction at most @xmath251 bits of input data",
    "can be encoded per point to retain collision resistance of @xmath252 .",
    "optimal collision resistance of @xmath253 for the representation size requires that @xmath254 .",
    "each multiset element @xmath255 ( assumed to be a bit string ) must therefore be split into one or more blocks of @xmath251 bits , each encoded as a separate elliptic curve point . for elements longer than @xmath251 bits , this is likely to be significantly more expensive than hashing @xmath256 with a fast hash function like blake2 and then encoding the result into a single elliptic curve point .",
    "eech also offers no preimage resistance by default .",
    "there is a proposed pairing - based variant peech that relies on an elliptic curve pairing to define a homomorphic one - way function .",
    "this provides preimage resistance at the cost of significantly higher computational cost and representation size . ]",
    ", we can make the fairer comparison between our ecmh construction and a straightforward randomize - then - combine - style  @xcite construction over binary elliptic curve groups using the implementation techniques proposed for eech .",
    "such a construction was neither explicitly proposed nor implemented , and there was no prior evidence that it would be practical performance wise .",
    "our work goes significantly beyond this :    * we provide a thorough empirical analysis of performance , and demonstrate for the first time that an elliptic curve - based multiset hash actually significantly exceeds the performance of ` adhash ` and ` muhash ` . *",
    "we demonstrate that a fully blinded implementation is possible at only a minor performance penalty .",
    "we also demonstrate batch variants of both the regular and fully - blinded implementations that are significantly faster .",
    "in contrast , the try - and - increment encoding method proposed for eech has no guaranteed time bound , making it unavoidably susceptible to timing attacks , and less amenable to speedup by batch inversion . *",
    "our security proof is based on existing techniques  @xcite but the security bound we obtain is novel in several ways : * * the hash function @xmath45 into the elliptic curve group need not be indistinguishable from a random oracle , but is instead permitted to satisfy the weaker property of being an @xmath95-weak encoding , which significantly reduces the computational cost . * * the hash function @xmath45 can map to the full elliptic curve group , rather than only a cyclic subgroup , as is required by eech .",
    "this allows for a simpler implementation that does not rely on patent - encumbered techniques  @xcite for efficiently testing for subgroup membership .",
    "it was originally suggested  @xcite that while finding collisions in ` muhash ` is provably as hard as the discrete logarithm problem ( dlp ) , the converse is not necessarily true : it may be that ` muhash ` is still collision resistant even if discrete logarithms can be computed efficiently .",
    "in fact , though , by computing discrete logarithms , finding a collision in ` muhash ` can be reduced to finding a collision in ` adhash ` .",
    "it would therefore be susceptible to a generalized birthday attack  @xcite in the set hashing setting or to lattice reduction attacks in the multiset hashing setting .",
    "the same reduction applies to our elliptic curve multiset hash , and is even more effective because of the smaller group order .",
    "99    brown , d. r.  l. ( 2008 ) the encrypted elliptic curve hash . , * 2008 * , 12 .    brown , d. and yamada , a. ( 2007 ) . method and apparatus for performing validation of elliptic curve public keys .",
    "gkantsidis , c. and rodriguez , p. ( 2006 ) cooperative security for network coding file distribution . .",
    "krohn , m.  n. , freedman , m.  j. , and mazires , d. ( 2004 ) on - the - fly verification of rateless erasure codes for efficient content distribution . , pp .",
    "ieee computer society .",
    "subramanian , l. , roth , v. , stoica , i. , shenker , s. , and katz , r.  h. ( 2004 ) listen and whisper : security mechanisms for bgp . in morris , r. and savage , s. ( eds . ) , _ usenix nsdi _ , pp . 127140 .",
    "usenix .",
    "castro , m. and liskov , b. ( 1999 ) practical byzantine fault tolerance . in seltzer , m.  i. and leach , p.  j. ( eds . ) , _ usenix osdi _ , pp .",
    "usenix association .",
    "castro , m. and liskov , b. ( 2002 ) practical byzantine fault tolerance and proactive recovery .",
    ", * 20 * , 398461 .",
    "cathalo , j. , naccache , d. , and quisquater , j .- j .",
    "( 2009 ) comparing with rsa . , pp . 326335 .",
    "springer .",
    "ning , p. , syverson , p.  f. , and jha , s. ( eds . ) ( 2008 ) _ proceedings of the 2008 acm conference on computer and communications security , ccs 2008 , alexandria , virginia , usa , october 27 - 31 , 2008_. acm .",
    "clarke , d. , devadas , s. , van  dijk , m. , gassend , b. , and suh , g.  e. ( 2003 ) incremental multiset hash functions and their application to memory integrity checking . , pp .",
    "springer .",
    "bellare , m. and micciancio , d. ( 1997 ) a new paradigm for collision - free hashing : incrementality at reduced cost . , pp .",
    "springer .",
    "brier , e. , coron , j .- s . ,",
    "icart , t. , madore , d. , randriam , h. , and tibouchi , m. ( 2010 ) efficient indifferentiable hashing into ordinary elliptic curves . , pp .",
    "springer .",
    "shallue , a. and van  de woestijne , c.  e. ( 2006 ) construction of rational points on elliptic curves over finite fields . , pp .",
    "springer .",
    "aranha , d.  f. , fouque , p .- a . ,",
    "qian , c. , tibouchi , m. , and zapalowicz , j .- c .",
    "( 2014 ) binary elligator squared . , pp .",
    "springer .",
    "aumasson , j .-",
    ", neves , s. , wilcox - ohearn , z. , and winnerlein , c. ( 2013 ) blake2 : simpler , smaller , fast as md5 . ,",
    ". 119135 .",
    "springer .",
    "semaev , i. ( 2015 ) .",
    "new algorithm for the discrete logarithm problem on elliptic curves .",
    "cryptology eprint archive , report 2015/310 .",
    "kosters , m. and yeo , s.  l. ( 2015 ) .",
    "notes on summation polynomials .",
    "arxiv:1503.08001 .",
    "huang , m.  a. , kosters , m. , and yeo , s.  l. ( 2015 ) last fall degree , hfe , and weil descent attacks on ecdlp .",
    "in gennaro , r. and robshaw , m. ( eds . ) , _ advances in cryptology - crypto 2015 - 35th annual cryptology conference , santa barbara , ca , usa , august 16 - 20 , 2015 , proceedings , part i _ , lecture notes in computer science , * 9215 * , pp . 581600 .",
    "springer .",
    "galbraith , s. ( 2015 ) .",
    "elliptic curve discrete logarithm problem in characteristic two .",
    "https://ellipticnews.wordpress.com/2015/04/13/elliptic - curve - discrete - logarithm - problem - in - characteristic - two/.    krohn , m.  n. , freedman , m.  j. , and mazieres , d. ( 2004 ) on - the - fly verification of rateless erasure codes for efficient content distribution . , pp .",
    "226240 . ieee .",
    "maurer , u.  m. , renner , r. , and holenstein , c. ( 2004 ) indifferentiability , impossibility results on reductions , and applications to the random oracle methodology . in naor , m. ( ed . ) ,",
    "_ tcc _ , lecture notes in computer science , * 2951 * , pp .",
    "springer .",
    "boneh , d. and franklin , m. ( 2001 ) identity - based encryption from the weil pairing . , pp .",
    "springer .",
    "wagner , d. ( 2002 ) a generalized birthday problem . , pp .",
    "springer .",
    "impagliazzo , r. and naor , m. ( 1996 ) efficient cryptographic schemes provably as secure as subset sum . ,",
    "* 9 * , 199216 .    menezes , a.  j. , van  oorschot , p.  c. , and vanstone , s.  a. ( 2010 ) _ handbook of applied cryptography_. crc press .    smart , n.  p. et al .",
    "( 2010 ) ecrypt  ii yearly report on algorithms and key lengths . technical report .",
    "european network of excellence in cryptology ii .",
    "http://www.ecrypt.eu.org/documents/d.spa.13.pdf .",
    "hankerson , d. , vanstone , s. , and menezes , a.  j. ( 2004 ) _ guide to elliptic curve cryptography_. springer .",
    "oliveira , t. , lpez , j. , aranha , d.  f. , and rodrguez - henrquez , f. ( 2014 ) two is the fastest prime : lambda coordinates for binary elliptic curves . , * 4 * , 317 .",
    "taverne , j. , faz - hernndez , a. , aranha , d.  f. , rodrguez - henrquez , f. , hankerson , d. , and lpez , j. ( 2011 ) speeding scalar multiplication over binary elliptic curves using the new carry - less multiplication instruction . , * 1 * , 187199 .    maitin - shepard , j. library .",
    "http://jeremyms.com/ecmh .",
    "\\(2013 ) fips 186 - 4 : digital signature standard ( dss ) , federal information processing standard ( fips ) , publication 186 - 4 .",
    "technical report .",
    "department of commerce , gaithersburg , md , usa .    research , c. ( 2000 ) _ sec 2 : recommended elliptic curve domain parameters_. standards for efficient cryptography .",
    "version 1.0 .",
    "bluhm , m. and gueron , s. ( 2015 ) fast software implementation of binary elliptic curve cryptography .",
    ", * 5 * , 215226 .",
    "guajardo , j. and paar , c. ( 2002 ) itoh  tsujii inversion in standard basis and its application in cryptography and codes .",
    ", * 25 * , 207216 .    maitin - shepard , j. ( 2015 ) .",
    "optimal software - implemented itoh ",
    "tsujii inversion for @xmath257 .",
    "cryptology eprint archive , report 2015/028 .",
    "http://eprint.iacr.org/.    bertoni , g. , daemen , j. , peeters , m. , and van  assche , g. ( 2009 ) keccak sponge function family main document . , * 3*.    bos , j.  w. , kleinjung , t. , niederhagen , r. , and schwabe , p. ( 2010 ) ecc2k-130 on cell cpus . , pp .",
    "springer .",
    "shacham , h. and boneh , d. ( 2001 ) improving ssl handshake performance via batching . , pp .",
    "2843 . springer .",
    "montgomery , p.  l. ( 1985 ) modular multiplication without trial division . , * 44 * , 519521 .",
    "paoloni , g. ( 2010 ) how to benchmark code execution times on intel ia-32 and ia-64 instruction set architectures . technical report .",
    "gama , n. and nguyen , p.  q. ( 2008 ) predicting lattice reduction . in smart , n.  p. ( ed . ) , _ eurocrypt _ , lecture notes in computer science , * 4965 * , pp . 3151 .",
    "springer .",
    "chen , y. and nguyen , p.  q. ( 2011 ) bkz 2.0 : better lattice security estimates . in lee , d.  h. and wang , x. ( eds . ) , _ asiacrypt _ , lecture notes in computer science , * 7073 * , pp . 120 .",
    "springer .",
    "van  de pol , j. and smart , n.  p. ( 2013 ) estimating key sizes for high dimensional lattice - based systems . in stam , m. ( ed . ) , _ imacc _ , lecture notes in computer science , * 8308 * , pp . 290303 .",
    "springer .",
    "lindner , r. et al .",
    "lattice challenge : hall of fame .",
    "http://www.latticechallenge.org/halloffame.php , accessed 17 october 2014 .",
    "we prove [ thm : dlpreduction ] , which reduces solving discrete logarithms to finding collisions in a homomorphic multiset hash function based on an @xmath95-weak encoding .",
    "let a @xmath259 , for which we wish to find @xmath260 such that @xmath261 , be given .",
    "we simulate each successive distinct query @xmath262 to the random oracle @xmath126 for @xmath263 using the following algorithm :    1 .",
    "sample uniformly at random @xmath264 , @xmath265 , @xmath266 , @xmath267 .",
    "2 .   compute @xmath268 . note that since @xmath269 has prime order , @xmath270 is a generator of @xmath269 , and therefore @xmath271 is distributed uniformly in @xmath8 .",
    "3 .   if @xmath272 , sample @xmath273 from @xmath274 uniformly at random . otherwise ,",
    "resample @xmath275 , and @xmath276 .",
    "4 .   return @xmath273 .",
    "note that @xmath273 is uniformly distributed in @xmath79 , and the expected number of sampling attempts is @xmath277 .    under the simulated @xmath126 , @xmath125 finds a non - empty @xmath278 in expected time @xmath279 with success probability @xmath280 . consider the case that a collision is found .",
    "( otherwise , we fail to compute the discrete logarithm . ) without loss of generality , we can assume @xmath40 is non - zero only for values @xmath12 on which @xmath126 was queried .",
    "thus , we have @xmath281 ,    \\end{aligned}\\ ] ] which implies @xmath282 where @xmath283 since @xmath284 and @xmath285 , it follows that @xmath286 in [ eq : dlpreduction : eq - full - with - subs ] ; we therefore have @xmath287 .",
    "since @xmath40 is non - empty , there exists a value @xmath13 such that @xmath288 .",
    "consider that the distribution of @xmath289 conditioned on @xmath290 is still uniform in @xmath291 , and therefore @xmath292 , and hence , @xmath293 .",
    "if @xmath294 , then @xmath295 , and therefore @xmath296 .",
    "if @xmath297 , we fail to compute the discrete logarithm . otherwise , @xmath108 has an inverse @xmath298 in @xmath299 and we have @xmath300 .",
    "thus , @xmath301 is a solution to the discrete logarithm problem . since we only fail if @xmath125 fails or @xmath297 , we find a solution with probability at least @xmath302 .",
    "each query @xmath12 to the simulated random oracle requires a table lookup to check if @xmath12 has been queried previously .",
    "if it has not , we must repeatedly sample @xmath303 , @xmath289 , @xmath304 and @xmath276 and compute @xmath268 in time @xmath305 @xmath306 until @xmath307 , which requires @xmath104 attempts in expectation , since @xmath92 is an @xmath95-weak encoding . we then sample @xmath308 .",
    "thus , each of the @xmath131 queries to the random oracle require expected time @xmath309 , where @xmath310    we can compute @xmath108 and @xmath311 as a sum of @xmath312 terms in time @xmath313 , where @xmath314 finally , we can compute @xmath84 from @xmath108 and @xmath311 in time @xmath315 thus , the total expected time is @xmath133 .",
    "the best known attack on bellare and micciancio s incremental hash function ` adhash ` when it is used to hash _ sets _ is wagner s generalized birthday attack  @xcite .",
    "however , when the function is used for _ multiset _ hashing , as proposed by clarke  et al .",
    "* theorem 6 ) , its security is much weaker . indeed , finding a multiset collision on ` adhash ` with @xmath131 random oracle queries is equivalent to finding a vector @xmath317 of polynomial norm such that : @xmath318 where the @xmath319 s are the hash values returned by the oracle , and @xmath40 is the ` adhash ` modulus . in other words ,",
    "the problem is to find a short vector in the full rank lattice @xmath320 of vectors orthogonal to @xmath321 modulo @xmath40 .",
    "the volume @xmath322 $ ] of @xmath312 is clearly at most @xmath40 , since @xmath312 is the kernel of a homomorphism to @xmath323 .",
    "therefore , a lattice reduction algorithm with hermite factor constant @xmath178 ( see  @xcite ) is expected to find a vector in @xmath312 of euclidean norm at most @xmath324 . by choosing @xmath325",
    ", we obtain a multiset collision of size roughly @xmath326 bits . for @xmath91 bits of security against this multiset collision attack , it is thus necessary to choose : @xmath327 this is similar to wagner s attack in the sense that the size of @xmath40 should be at least quadratic in the security parameter , but the constant is typically much larger . over a large range of lattice dimensions ,",
    "a security level of @xmath328 bits corresponds to a hermite factor constant @xmath329  @xcite .",
    "hence , a conservative choice of @xmath40 should be at least 400,000-bit long , which is obviously impractical .",
    "even @xmath330 corresponds to @xmath331 and requires @xmath40 to be chosen larger than 100,000 bits .    at any rate ,",
    "recommended sizes for the set - hash setting are highly insecure in the multiset hash setting .",
    "consider a modulus @xmath40 of @xmath332 bits , appropriate for @xmath333-bit security in the set - hash setting .",
    "simply doing @xmath334 oracle queries and easily reducing the corresponding lattice with lll ( not even bkz ! ) , which has a hermite factor constant @xmath335 , yields a multiset collision of weight about @xmath336 ( less that @xmath337-bit long ) . similarly , given a @xmath338-bit modulus @xmath40 ( as used for @xmath19-bit security in the set - hash setting ) , doing @xmath339 queries and reduction the corresponding @xmath340-dimensional lattice with bkz-28 using bkz with block size @xmath341 and up  @xcite .",
    "] , which has a hermite factor constant @xmath342  @xcite , yields a multiset collision of weight about @xmath343 ( less than @xmath344-bit long ) .",
    "consider a more limited definition of an incremental multiset hash function , under which only incremental additions ( and non - negative multiplicities ) are supported :    let @xmath4 be a set , and let @xmath345 be a finite set with an associative operation @xmath346 .",
    "a function @xmath347 is a _ monoid - homomorphic multiset hash function _ if @xmath348 for all @xmath349 .",
    "note that @xmath350 is necessarily a commutative monoid under this definition .",
    "thus , without loss of generality , we can assume that @xmath351 is a commutative monoid .",
    "if we make the additional assumption that @xmath351 has the cancellation property , i.e.  @xmath352 implies @xmath44 for all @xmath353 , then we can construct a ( group-)homomorphic multiset hash function @xmath354 from @xmath31 into a group @xmath8 that embeds @xmath345 .",
    "furthermore , this construction has only a constant factor time and space overhead of @xmath124 .",
    "since @xmath345 is a finite , commutative monoid with the cancellation property , there must exist an inverse for every element , and therefore @xmath345 is a group .",
    "however , to ensure that the inverse can be computed efficiently , we use the grothendieck construction in which we represent the positive and negative parts by separate elements of @xmath345 .",
    "let @xmath8 be the quotient set @xmath355 , where the equivalence relation @xmath356 is given by @xmath357 if , and only if , @xmath358 , for all @xmath359 .",
    "we define the addition operation @xmath360 + _ g [ ( b_+ , b_- ) ] = [ ( a_+ + _ t b_+ , a_- + _ t b_-)]$ ] .",
    "note that @xmath42 respects @xmath356 , and the inverse is given by @xmath361 = [ ( a_- , a_+)]$ ] .",
    "we define the hash function @xmath362 by @xmath363 $ ] . since @xmath364 for all @xmath36 , we have @xmath365                  = [ ( h(\\max(m_1,0 ) ) , h(\\max(-m_1,0 ) ) ) ] + [ ( h(\\max(m_2,0 ) ) , h(\\max(-m_2,0 ) ) ) ]                 = h'(m_1 ) + h'(m_2)$ ] .",
    "finally , we can embed @xmath345 in @xmath8 using that map @xmath366 $ ] for all @xmath367 .",
    "it follows directly from the definition of @xmath356 and @xmath42 that @xmath368 is an injective homomorphism .",
    "note that the representation size for an element of @xmath8 is twice the representation size of an element of @xmath345 , and @xmath354 and @xmath42 require two invocations of @xmath15 and @xmath369 , respectively .",
    "is based on the definition of an incremental multiset hash function given by clarke  et al .",
    "@xcite , which we restate as follows :    [ def : clarke - multiset - hash ] let @xmath370 and @xmath371 be probabilistic algorithms using randomness @xmath100 , where @xmath345 is a finite set , and let @xmath372 be an equivalence relation over @xmath345 .",
    "the triple @xmath373 is a _ multiset hash function _ if it satisfies the following properties :      this differs from our definition of a monoid - homomorphic multiset hash function ( [ sec : monoid - to - group ] ) only in that it allows for randomness in the hash function and in the addition operation @xmath369 .",
    "note that this randomness is for a fixed hash function , and is independent of the randomness in choosing the hash function from a hash function family .",
    "the multiset hash function ` mset - add - hash `  @xcite relies on this randomness for security .",
    "in fact , though , the randomness is not integral to the hashing operation itself , but rather is used as a nonce in encrypting the hash code , which we view as an orthogonal operation .",
    "therefore , we dispense with this randomness in our definition .    as explained in [ sec : monoid - to - group ] , if we assume that @xmath351 has the cancellation property , i.e.  that @xmath369 does not itself introduce any additional collisions , then a simple construction produces a ( group-)homomorphic multiset hash function from any multiset hash function satisfying [ def : clarke - multiset - hash ] ."
  ],
  "abstract_text": [
    "<S> a homomorphic , or incremental , multiset hash function , associates a hash value to arbitrary collections of objects ( with possible repetitions ) in such a way that the hash of the union of two collections is easy to compute from the hashes of the two collections themselves : it is simply their sum under a suitable group operation . </S>",
    "<S> in particular , hash values of large collections can be computed incrementally and/or in parallel . </S>",
    "<S> homomorphic hashing is thus a very useful primitive with applications ranging from database integrity verification to streaming set / multiset comparison and network coding .    </S>",
    "<S> unfortunately , constructions of homomorphic hash functions in the literature are hampered by two main drawbacks : they tend to be much longer than usual hash functions at the same security level ( e.g. to achieve a collision resistance of @xmath0 , they are several thousand bits long , as opposed to @xmath1 bits for usual hash functions ) , and they are also quite slow .    in this paper , </S>",
    "<S> we introduce the elliptic curve multiset hash ( ecmh ) , which combines a usual bit string - valued hash function like blake2 with an efficient encoding into binary elliptic curves to overcome both difficulties . on the one hand , </S>",
    "<S> the size of ecmh digests is essentially optimal : @xmath2-bit hash values provide @xmath3 collision resistance . on the other hand , </S>",
    "<S> we demonstrate a highly - efficient software implementation of ecmh , which our thorough empirical evaluation shows to be capable of processing over 3 million set elements per second on a intel haswell machine at the 128-bit security level  many times faster than previous practical methods .    </S>",
    "<S> while incremental hashing based on elliptic curves has been considered previously  @xcite , the proposed method was less efficient , susceptible to timing attacks , and potentially patent - encumbered  @xcite , and no practical implementation was demonstrated .    </S>",
    "<S> * keywords : * homomorphic hashing , elliptic curves , efficient implementation , gls254 , pclmulqdq . </S>"
  ]
}