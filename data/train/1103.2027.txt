{
  "article_text": [
    "[ sec : intro ] _ counterexample - guided abstraction refinement _ ( _ cegar _ , or more briefly , _ ar _ )  @xcite , has been a very successful technique for proving safety in large programs .",
    "starting with a coarse abstraction of the program ( _ abstraction phase _ ) , the abstraction is checked for the desired property ( _ verification phase _ ) .",
    "if no error is found , then the program is safe .",
    "otherwise , an abstract counterexample is produced .",
    "the counterexample is then analyzed to test if it corresponds to a concrete counterexample in the original program . if yes , the program is reported as unsafe .",
    "otherwise , a _",
    "counterexample - driven refinement _ is performed to refine the abstract model such that the abstract counterexample is excluded ( _ refinement phase _ ) , and the process starts again .",
    "several systems have been developed during recent years following this approach  @xcite .    in a previous work",
    "@xcite we presented a _",
    "dual _ algorithm to ar , here called _ abstraction learning _ , for loop - free program fragments .",
    "essentially , our technique starts with the concrete model of the program .",
    "then , the model is checked for the desired property ( _ verification phase _ ) via _ symbolic execution_. if a counterexample is found , then it must be a real error and hence , the program is unsafe .",
    "otherwise , the program is safe . in order to make the symbolic execution process practical",
    ", the technique learns the facts that are irrelevant for keeping infeasible paths by computing",
    "_ interpolants _ ( _ learning phase _ ) , and then it eliminates those facts from the model ( _ abstraction phase _ ) .",
    "unfortunately , this work did not provide an automatic treatment of loops while it assumed user - provided loop invariants to make symbolic executions finite .    in this paper , we extend the technique proposed in  @xcite to discover loop invariants .",
    "the central idea is to progressively discover the strongest invariants through a lazy process of loop unrolling .    for a given loop , _ path - based loop invariants _",
    "are computed and used to generalize the states at the looping points ( program points where the merging of control paths construct some cyclical paths ) .",
    "our computation of invariants is _ lightweight _ as they are computed by manipulation , using the theorem prover , of explicit constraints .",
    "the algorithm attempts to minimize the loss of information by computing the _ strongest _ possible invariants . these _ speculative _ invariants may be still too coarse to ensure safety . here",
    "the algorithm computes interpolants to ensure that error locations are not reachable , resulting in _ selective _ unrolling at points where the path - based invariant can no longer be produced due to the strengthening introduced by the interpolants .",
    "similar to ar , this procedure is only guaranteed to terminate when loop iterations are bounded .",
    "a fundamental distinction with ar is that we attempt to always construct the most precise abstraction for loops by computing the strongest lightweight loop invariants .",
    "this feature is vital to detect as many infeasible paths as possible during the symbolic execution - based traversal .",
    "our thesis is that this investment often pays off , and even in examples where it does not , it is affordable .",
    "the contributions of this paper can be summarized as follows :    1 .",
    "we extend the interpolation - based symbolic execution algorithm in  @xcite to deal with unbounded loops by describing a novel lazy loop unrolling algorithm called _",
    "minimax_. 2 .",
    "we provide an analysis using several academic examples of the major differences between our proposed algorithm and mainstream techniques mainly based on abstraction refinement .",
    "finally , we implement the main ideas of this paper in a system called tracer , and we evaluate it using real programs against blast , available state - of - the - art system .    * related work . *",
    "our work is clearly related to abstraction refinement ( cegar )  @xcite .",
    "we dedicate sec .",
    "[ sec : overview ] to exemplify main differences through some academic examples and sec .",
    "[ sec : results ] to compare with blast using real programs .",
    "recent algorithms such as synergy / dash / smash  @xcite use test - generation features to enhance the process of verification .",
    "the main advantage comes from the use of lightweight symbolic execution provided by dart  @xcite to mitigate the expensive cost of the _ abstract post - image operator _ when predicate abstraction is used .",
    "an advantage of our approach is that it does not suffer from this drawback since ours is symbolic execution - based and does not use predicate abstraction .",
    "more importantly , these tools rely on cegar to build the abstract model of the program , and hence , major limitations observed in sec .  [ sec : overview ] still hold .",
    "moreover , there is no benefit of using test cases using our method unless there is a real counterexample in the program . on the contrary",
    ", we can construct reasonable scenarios where synergy and its descendants can have an exponential slowdown wrt to ours as shown in sec .",
    "[ sec : overview ] .",
    "our closest related works are in  @xcite . where interpolation was performed on a search tree of a clp goal in pursuit of a target property .",
    "( the earlier paper  @xcite focussed on a finite domain for an optimization problem . ) but these works did not consider loops .",
    "the main conceptual advance of this paper is to address loops , and in doing so , allows for the consideration of real - life programs .",
    "furthermore , this paper provides a detailed analysis of differences with the state - of - the - art cegar method , and finally , we present a comprehensive experimental evaluation with blast , the most advanced cegar implementation available to us at this time .    very recently , another interpolation - based symbolic execution method has been proposed , independent from ours , in  @xcite .",
    "this work can be considered in two parts . in the consideration of loop - free program fragments ,",
    "this work is in fact subsumed by the earlier works  @xcite . in the consideration of loops ,  @xcite presented a _",
    "strategy for handling loops based on an iterative deepening process .",
    "the central idea is to compute interpolants for a fixed depth in the hope they will converge to inductive assertions after an expensive fixpoint computation .",
    "we quote from  @xcite :  _ the question of how to obtain convergence in practice for unbounded loops needs further study _  .",
    "therefore , the description of a concrete algorithm from this idealistic one is far from being trivial .",
    "furthermore , experimental evaluation was provided only in regard to testing , and not for the case of verification .",
    "in contrast , in this paper we present a _ directed _ approach which essentially amounts to an intelligent backtracking strategy which takes into account the reason for failure at the current stage .",
    "[ sec : basic_idea ]    our basic algorithm performs _ symbolic execution _ of the programs while attempting to find an execution path that reaches the * error ( ) * function .",
    "if such path can not be found , then it concludes that the program is safe .",
    "lcc    .... 0 : x=0 ; 1 : if ( * ) 2 :   x = x+1 ; 3 : if(y>=1 ) 4 :   x = x+2 ; 5 : if(y<1 ) 6 :   x = x+4 ; 7 : if(x>5 ) 8 :   error ( ) ; 9 : ....    &        &         +     +    consider the program in fig .  [ fig : infeasible](a ) .",
    "we depict in fig  [ fig : infeasible](b ) the naive symbolic execution tree , and in fig .",
    "[ fig : infeasible](c ) a smaller tree , which still proves the absence of bugs . during the traversal of the tree ,",
    "our algorithm _ preserves the infeasibility _ of the paths using the well - known concept of _ interpolation_. let us focus on fig .",
    "[ fig : infeasible](c ) and consider , for instance , the path @xmath0 ---- which is detected as infeasible ( @xmath1 ) . applying our infeasibility preservation principle",
    ", we keep node labeled with .",
    "this produces the interpolant @xmath2 at node since this is the most general condition that preserves the infeasibility of node .",
    "note that here , @xmath2 is entailed by the original state @xmath3 of node and in turn entails @xmath4    now consider another path @xmath5 ------ and the node with the formula @xmath6 which is also infeasible .",
    "the node can be interpolated to @xmath7 . as before , this would produce the precondition @xmath8 at .",
    "the final interpolant for is the _ conjunction _ of @xmath2 ( produced from @xmath9 ) and @xmath8 ( produced from @xmath10 ) . in this way ,",
    "when is visited through the path ---- the state can not yet be subsumed since the current context @xmath11 does not entail the interpolant stored at ( @xmath12 ) .",
    "after that , the symbolic execution continues normally until the the prefix @xmath13 --- is traversed .",
    "the formula @xmath14 associated to the state at entails the interpolant at @xmath15 at and hence , our algorithm finishes proving safety without traversing the whole subtree rooted at prefix @xmath16 .",
    "* we now explain how our algorithm handles loops using a slightly modified classic example from  @xcite shown in fig .",
    "[ example : loop](a ) . essentially , it automatically infers path - based loop invariants using information learned during traversal .",
    "the constructed loop invariant for a given path inside a loop is a conjunction of constraints whose truth values remain unchanged after one or more iterations of the loop . similar to abstraction refinement , this process may require refinements in the case the abstraction is too coarse to prove the safety property .    in fig .",
    "[ example : loop](b ) assume the first path explored is ---- denoting a cyclic path from location back to . note that and correspond to the same program point .",
    "we use primed versions to distinguish multiple occurrences .",
    "our algorithm then examines the constraints at the entry of the loop ( i.e. , ` lock==0 ` , ` new==old+1`,`flag==1 ` ) to discover those whose truth values remain unchanged after the loop ( i.e. , ` lock==1 ` , ` new==old ` , ` flag==1 ` )",
    ". clearly , the constraints ` lock==0 ` and ` new==old+1 ` are no longer satisfied while ` flag==1 ` still holds .    at this point",
    ", our algorithm produces an abstraction at the location by making the truth values of ` lock==0 ` and ` new==old+1 ` unknown . in this way",
    ", the constraints at now entails the modified constraints of ( ` flag==1 ` ) , achieving parent - child subsumption .",
    "assume the next explored path is ----- ( fig .",
    "[ example : loop](b ) ) . at",
    ", the constraints already entail the generalized constraint of ( they are invariant ) , and we therefore stop the traversal .",
    "after the loop is traversed , the remaining constraint at is ` flag==1 ` and this is in fact a loop invariant discovered by the algorithm .",
    "since we have removed ` new==old+1 ` from , the exit path of the loop now becomes feasible as the condition ` new==old ` becomes satisfiable .",
    "for this reason the traversal reaches with the constraint ` flag==1 ` propagated from and ` new==old ` which is obtained by strongest postcondition propagation through the loop exit transition .    lcc",
    ".... 0:lock=0 ;    new = old+1 ;    flag=1 ; 1:while(new!=old ) { 2 : lock=1 ;     old = new ; 3 : if ( * ) 4 :   lock=0 ;      new++ ;    } 5:if(!flag ) 6 : lock=0 ; 7:if(lock==0 ) 8 : error ( ) ; 9 :    ....    &        &         +   + ( a ) & ( b ) & ( c ) +    since we keep ` flag==1 ` in the loop invariant at , the algorithm manages to reason that the path --- is infeasible ( fig .",
    "[ example : loop](b ) ) .",
    "one important point here is that the algorithm exits the loop with maximal information .",
    "this is useful to detect as many infeasible paths as possible .",
    "an ar algorithm would not detect the infeasibility and would visit * error * ( ) at .",
    "next , our algorithm visits the nodes and also in fig .",
    "[ example : loop](b ) , which is an error location .",
    "the path is spurious , and the algorithm discovers using interpolation that one of the reason for the reachability of this point is the removal of ` new==old+1 ` at . the algorithm decides to _ lock _ `",
    "new==old+1 ` at and restarts the traversal from .",
    "locking declares that the constraint can not be removed for generating loop invariant .",
    "this is our main mechanism to ensure _",
    "progress_.    the next traversal after the locking is depicted in fig .",
    "[ example : loop](c ) .",
    "similar to the first traversal , the path --- is again re - traversed . at",
    ", the constraints do not entail the constraints of anymore .",
    "due to locking of ` new==old+1 ` , we are prevented from generating a loop invariant , and hence , subsumption does not hold . as the result ,",
    "the traversal continues , and it is completed without visiting the error program point at .",
    "an essential observation is that due to its directed search for loop invariants , the algorithm does not unroll the location at ( fig .",
    "[ example : loop](c ) ) since the state is already subsumed by without the need to force any abstraction .",
    "a naive iterative deepening algorithm ( e.g. ,  @xcite ) would also unroll that path , and hence , we can construct reasonable scenarios in which this leads to an exponential explosion .",
    "[ sec : overview ] we now analyze essential differences between our approach and mainstream techniques which are mainly based on abstraction refinement ( cegar ) .    * exploration of infeasible paths . * the core idea of abstraction refinement is to use the most general abstraction first , and refine later .",
    "this causes the exploration of _ infeasible paths _ which _ stresses significantly _ well - known problems in ar .",
    "first , the more predicates are considered in the abstract model the more costly will be the verification phase .",
    "moreover , if predicate abstraction is used ( e.g. , slam and blast ) expensive abstract post - image and quantifier elimination are needed .",
    "finally , the cost of the refinement process may be also prohibitive .",
    "because of the huge impact of exploring infeasible paths significant research has been done recently .",
    "a partial solution has been the use of dart in order to provide a symbolic execution engine in synergy - like tools  @xcite .",
    "however , the construction of the abstract model is still needed and the above problems persist .",
    "furthermore , these tools may perform unnecessary refinements that may create reasonable scenarios which lead to an exponential behavior .",
    "consider the program in fig .",
    "[ fig : example](a ) .",
    "assume that a synergy - like tool produces the test case ---- , and that the abstract model , with no predicates , reaches the error through the path ------ .",
    "then , it tries now to produce new test cases by negating the first constraint which is not in the common prefix ( i.e. , ` x>0 ` ) but it is unsatisfiable since @xmath14 .",
    "therefore , it will likely add the predicate @xmath17 which is irrelevant for proving safety .",
    "our technique will traverse the path through ---- and produce the interpolant @xmath18 .",
    "the rest of paths will entail that interpolant , and hence , the behavior will be linear on the size of the program .    * discovering loop invariants .",
    "* any symbolic traversal method will have to eventually discover loop invariants that are strong enough for the proof process to conclude successfully . in the case of ar ,",
    "the abstract model is refined from spurious counterexamples by discovering which predicates can refute the error path , and in this process , they are _ hoped _ to be in fact invariant through loops .",
    "a crucial observation is that the inference of invariant predicates can speedup significantly the convergence of loops  @xcite .",
    "we therefore employ invariant discovery by searching for the _ strongest _ invariants .",
    "this principle is also in accordance with our philosophy to perform concrete symbolic execution in order to maintain exact information for loop - free fragments .",
    "[ fig : example](b ) illustrates the benefits of computing strongest loop invariants .",
    "ar will discover the predicates @xmath19 and also @xmath20 , and hence full unrolling of the loop is needed . to understand why our approach avoids the full unrolling ,",
    "the concept of inference of path - based loop invariant constraints is essential .",
    "consider the path ----- .",
    "the state at can be specified by the constraint @xmath21 on the variables @xmath22 and @xmath23 .",
    "our algorithm will attempt to infer which constraints are individually invariant in order to get parent - child subsumption ( i.e. , `` close '' the loop ) .",
    "it is straightforward to see that @xmath24 ( by slackening @xmath25 to @xmath26 ) is invariant through the loop because when is first visited , @xmath27 holds and after one iteration the constraints @xmath28 still imply @xmath29 .",
    "the second essential step is when the exit condition is taken ( i.e. , -- ) our technique will attach @xmath30 to all invariant constraints ( in this case @xmath24 ) by computing strongest postcondition .",
    "more importantly , those two constraints ( @xmath31 ) suffice to prove that the error condition @xmath32 is false .",
    "therefore , we are done with only one iteration through the loop .",
    "llll    ....   1:q=1 ;    2:if ( * )    3 :   x=0 ;     else     4 :   x=1 ;   5:if(x>0 )    6 :   y=0 ;       else     7 :   y=1 ;   8:if(q==0 )    9 :   error ( ) ; 10 : ....    &    .... 1:assume(y = = 0 ) ; 2:n = 0 ; 3:while ( n < n ) { 4 :   y++ ; 5 :   n++ ;    } 6:if ( y+n",
    "< n )    7 :   error ( ) ; ....    &    ....   1:s=0 ;   2:if ( * ) z=0 ;   3:else   z=999 ;     // 1   4:if ( * ) s++    5:else   s+=2 ;     ...     // n   6:if ( * ) s++    7:else   s+=2 ;     8:if(s+z>2*n & & z==0 )    9 :   error ( ) ; ....    &    ....   1:if ( * ) {   2 : x=0 ;    3 : y=0 ; }   4:else {    5 : x = complex_func ( ) ;    6 : y=0 ; }       7:s = x ;   8:t = y ;     /*1*/     9:if(*){s++;t++ ; }     ...   /*n*/ 10:if(*){s++;t++ ; } 11:if(t > n & & s",
    "> n ) error ( ) ;       ....     + & & &    * using newly discovered predicates in future traversal . * another fundamental question in ar : after the set of predicates required to exclude the spurious counterexample has been discovered , how should those predicates be used in other paths ?",
    "consider our next program in fig  [ fig : example](c ) .",
    "a counterexample - guided tool will discover the predicates @xmath33 .",
    "then , it will either add @xmath34 or @xmath35 .",
    "assume that it first adds the predicate @xmath34 .",
    "the key observation is that all the paths that include @xmath35 ( location ) will be traversed considering all the predicates discovered from paths that included @xmath34 ( location ) , and hence , the traversal will be exponential .",
    "our algorithm will basically perform the same amount of work for the case that @xmath36 is considered .",
    "however , it traverses the paths that include @xmath37 without consideration of the facts learnt from paths that include @xmath36 since it only keeps track of the concrete state collected so far ( i.e. , @xmath38 ) .",
    "then , after the path ---  -- is traversed we can discover in a straightforward manner that @xmath37 suffices to refute the error state and hence , the rest of the paths will be subsumed .",
    "notice that ar will also discover the predicate @xmath35 after the counterexample is found",
    ". the essential difference , for this class of programs , is that the predicates discovered previously ( @xmath39 ) are used , and hence , the traversal will be significantly affected by them .",
    "* running an abstract state hampers subsumption . *",
    "the next example illustrates another potential weakness of ar that is not present in our approach .",
    "even if locality is well exploited , the likelihood of subsuming the _ currently traversed _ state may be diminished because the state , being abstract , is too coarse .",
    "consider now the program in fig .",
    "[ fig : example](d ) .",
    "assume ` complex_func ` returns always @xmath40 .    in principle",
    ", a counterexample - guided tool will behave very similarly as in the program in fig .",
    "[ fig : example](c ) .",
    "assume that the prefix path -- is taken .",
    "it will then discover the predicates @xmath41 .",
    "again , those predicates are likely to be used during the exploration of the else - branch ( -- ) . however , an essential difference with respect to program in fig .",
    "[ fig : example](c ) is that although the discovered predicate @xmath42 is taken into consideration , the abstract state can not be covered since it is too coarse assuming it does not consider lazily the value returned by ` complex_func ` , and hence , it does not entail the predicate @xmath42 .",
    "in contrast , since our method does perform a systematic propagation of the program state the value returned by ` complex_func ` will be captured and we will be able to entail the interpolant @xmath14 .",
    "the main consequence is that the state now will be subsumed .",
    "* unnecessary detection of infeasible paths .",
    "* so far we have illustrated scenarios where our approach behaves better than ar .",
    "the advantage exploited in the preceding examples is the preservation of infeasible paths while abstracting loops using the strongest lightweight loop invariants .",
    "unfortunately , this characteristic might be an important downside if the program can be proved safe even traversing infeasible paths since all the work of generating interpolants for preserving infeasible paths would be wasteful .",
    "we claim that eager detection of infeasible paths even if they are not relevant to the safety property is not limiting in practice .",
    "the reason is that many of the infeasible paths in real programs must be considered anyway to block the error paths , and hence , counterexample - guided approaches will also consider them although lazily paying a higher price later on . the results obtained by our prototype with real programs shown in sec .",
    "[ sec : results ] support strongly our view .    to elaborate even more this point",
    "let us consider a real program ` statemate `  @xcite used commonly for testing wcet tools .",
    "the program is generated automatically and its main feature is the huge amount of infeasible paths .",
    "we try to build the worst possible scenario by instrumenting the program and adding ` x=0 ` at the first statement of the program where ` x ` is a fresh variable , and then adding the condition ` if ( x>0 ) ` * error * ( ) at the end . an ar tool should add only the predicate @xmath42 to prove that the program is bug free .",
    "however , an actual evaluation using blast shows some significant performance degradation as it may not always choose the right predicate , resulting in @xmath43 predicates discovered in 74 seconds on intel 2.33ghz 3.2 gb ( our algorithm takes 88 seconds ) .",
    "this experiment exhibits the worst possible scenario for our approach and also illustrates another potential limitation of ar .",
    "if the abstract error path has more than one infeasibility reason , then existing refinement techniques have difficulties in choosing the right refinement .",
    "synergy - like tools mitigate this problem but introduce other challenges as discussed above .",
    "[ sec : preliminaries ] here we briefly model a program as a transition system and formalize the proof process as one of producing a closed tree of the transition steps .",
    "it is convenient to use the formal framework of _ constraint logic programming _ ( _ clp _ )  @xcite , which we outline as follows .",
    "the _ universe of discourse _ is a set of terms , integers , and arrays of integers .",
    "a _ constraint _ is written using a language of functions and relations .",
    "an _ atom _ is of the form @xmath44 where @xmath45 is a user - defined predicate symbol and the @xmath46 a tuple of terms .",
    "a _ rule _ is of the form @xmath47 where the atom @xmath48 is the _ head _ of the rule , and the atom @xmath49 and the ( conjunction of ) constraint @xmath50 ( possibly relating the variables @xmath51 and @xmath52 ) constitute the _ body _ of the rule . here",
    "both @xmath53 and @xmath54 are positive numbers denoting program points or the special constant @xmath55 to denote an error location .",
    "we may omit either the atom or the constraint from the body .",
    "goal _ has exactly the same format as a body of a rule .",
    "given a goal @xmath56 : @xmath57 we denote by @xmath58 the constraint @xmath59 or @xmath60 when @xmath59 is empty .",
    "each clp rule represents a transition in the program . for example , given a program fragment with two variables ` x ` and ` y ` , the assignment ` 5 : x = y+1 6 : ` is represented as the rule @xmath61 for a conditional ` 6 : if ( x>0 ) 7 : ` , we represent the transition between @xmath62 and @xmath63 by the rule @xmath64    a _ substitution _ simultaneously replaces each variable in a term or constraint into some expression .",
    "we specify a substitution by the notation @xmath65,$ ] where @xmath51 is a sequence @xmath66 of variables and @xmath67 a list @xmath68 of expressions , such that @xmath69 is replaced by @xmath70 for all @xmath71 given a substitution @xmath72 we write as @xmath73 the application of the substitution to an expression @xmath74 a _ renaming _ is a substitution which maps variables into variables .",
    "grounding _ is a substitution which maps each variable into a value in its domain .",
    "a _ ground instance _ of a constraint , atom and rule is defined in the obvious way .    given a goal @xmath75 @xmath76\\!]$}}$ ] is the set of the groundings @xmath77 of the primary variables @xmath51 such that @xmath78 holds . a goal @xmath79 _ subsumes _ another goal @xmath80 if @xmath81 and @xmath82\\!]$}}\\supseteq { \\mbox{$[\\![$}}{\\mbox{$\\cal g$}}{\\mbox{$]\\!]$}}$ ] .",
    "equivalently , we say that @xmath83 is a _ generalization _ of @xmath84 .",
    "we write @xmath85 if @xmath86 and @xmath87 are generalizations of each other .",
    "we use the notion of _ reduction _ to represent symbolic strongest postcondition operation .",
    "let a rule @xmath88 @xmath89 belong to a clp program . given a goal @xmath90 @xmath91 with variables disjoint from @xmath92",
    "a _ reduct _ or _ derivation _ of @xmath84 using @xmath93 ( denoted @xmath94 ) is the goal @xmath95[\\tilde{x}_{i+1}/\\tilde{x}']$ ] . a derivation sequence ( path ) is a sequence of goals @xmath96 where @xmath97 is a reduct of @xmath98 .    a goal @xmath99 is called _ terminal _ if there are no applicable rules to perform reduction on it , and it is called _ looping _ if it is derived from another goal with the same @xmath53 ( called its _ looping parent _ ) through one or more reduction steps . a goal is _",
    "infeasible _ if its constraints are unsatisfiable , and a derivation sequence is so called when it ends in an infeasible goal .",
    "[ sec : algorithm ] as mentioned above , there is an obvious strategy for dealing with loops by using iterative deepening on the level of loop unrolling , and in each iteration , to generate loop invariants . in this section",
    ", we present an algorithm that performs unrolling in an _ intelligent _ manner , using information about why a particular path does not suffice . in this regard , there is similarity to cegar where , if a candidate loop invariant is found insufficient ( too weak ) , the refinement process takes into account the _ reason _ for this insufficiency in order to arrive at the next refinement .",
    "our algorithm maintains knowledge about a state ( goal ) @xmath84 @xmath100 @xmath101 by means of a vector @xmath102 where each @xmath103 is an _ annotation _ of one of the following kinds :    * a annotation , indicating that the constraint @xmath104 _ must be kept _ * a annotation , indicating that the constraint @xmath104 _ must be deleted _ , or * a _ neutral _ annotation .",
    "denote the @xmath105-th annotation in @xmath106 by @xmath107 let @xmath108 be a constraint , its annotation is denoted @xmath109 @xmath110 denotes a vector @xmath111 of the same length as @xmath112 we write @xmath113 if @xmath114 such that ( @xmath115 ) and ( @xmath116 ) .",
    "a pair @xmath117 where the state @xmath118 is called an _ annotated state_. the meaning of an annotated state @xmath119 is obtained in two ways .",
    "a interpretation @xmath120 is the state obtained by deleting all but the -annotated constraints in @xmath50 .",
    "dually , a interpretation @xmath121 is the state obtained by including all but the -annotated constraints in @xmath50 .",
    "for example , given an annotated state @xmath122 : @xmath123 @xmath124 @xmath125 @xmath126 @xmath120 and @xmath121 are , respectively the two states @xmath127 @xmath128 @xmath129 @xmath130 and @xmath131 note @xmath132 is weaker than @xmath133    the use of vectors is an efficient way for computing interpolants .",
    "@xmath134-annotated constraints of an annotated state @xmath135 must be kept to preserve some infeasible paths in the derivation tree emanating from @xmath122 .",
    "given an infeasible annotated state @xmath136 derived from @xmath122 , we minimally @xmath134-annotate the constraints in @xmath136 ( some of which are constraints of @xmath122 since they share the vector ) such that the infeasibility is maintained . in this way",
    "we immediately obtain an abstraction at @xmath122 ( that is , @xmath120 ) by the @xmath134 annotations generated at @xmath136 without performing _ weakest precondition _ propagation or some approximation of it .",
    "@xmath120 subsumes @xmath84 yet it entails the infeasibility of @xmath136 and therefore is an interpolant .",
    "the final abstraction at @xmath122 is a conjunction of the interpolants returned by the children , and this is easily obtained by the conjunction of all @xmath134-annotated constraints at @xmath122 after the subtree is traversed .",
    "l1.6 in    the algorithm operates on annotated states .",
    "its depth - first traversal is outlined in fig .",
    "[ fig : outline ] . when encountering a loop ( point @xmath137 in fig .",
    "[ fig : outline ] ) a loop invariant is produced by weakening the constraints at @xmath137 by minimally @xmath138-annotating its state .",
    "this weakening is then applied in the forward execution of the points beyond the @xmath139 this abstraction , however , is not the final abstraction that is used to subsume other states since it still can be weakened further as some constraints may not contribute to the infeasibility or subsumption of descendant states .",
    "the final abstract state ( in @xmath137 or elsewhere ) is computed by propagating @xmath134 annotations backward in post - order manner .",
    "@xmath140 annotations are produced by interpolation at points where infeasibility and subsumption are found ( lines  [ falseinterpolation ] ,  [ conflictinterpolation ] and  [ subsumptioninterpolation ] in fig .",
    "[ fig : minimax ] ) .    before detailing the algorithm of fig .",
    "[ fig : minimax ] we first explain its main components .",
    "* interpolation .",
    "* if @xmath122 is @xmath141 and @xmath142 is unsatisfiable , ( @xmath122 , @xmath143 ) returns an annotation @xmath144 which has the same length as @xmath106 ( and @xmath50 ) , satisfying the following :    1 .",
    "@xmath145 2 .",
    "@xmath146 and 3 .",
    "@xmath147    @xmath144 is computed by adding the fewest annotations to neutral annotations in @xmath106 , thus representing a computation of an _ interpolant : _",
    "@xmath148 maintains the unsatisfiability ( consequence ) of @xmath121 yet it has less constraints ( more general ) .",
    "for example , consider the annotated state @xmath149 @xmath150 @xmath124 @xmath151 @xmath125 @xmath152 with @xmath50 be @xmath153 @xmath154 @xmath155 @xmath156 and a constraint @xmath157",
    "where here , @xmath121 is unsatisfiable",
    ". then @xmath158 produces the vector @xmath159 @xmath124 @xmath151 @xmath151 @xmath160 that is , the third constraint s annotation is changed from _",
    "neutral _ to _ max _ such that @xmath161 maintains the unsatisfiability .",
    "* subsumption and loop invariants . * an essential feature of our algorithm , existing also in ar methods , is the ability of blocking the forward search traversal of an annotated state @xmath122 if there exists another state @xmath136 already processed such that the state of @xmath122 entails the state associated with @xmath136 . during the symbolic traversal",
    "there are two kinds of subsumptions .",
    "_ parent - child : _ assume that @xmath136 is a looping ancestor of @xmath122 . here",
    "@xmath136 would be of the form @xmath162 and @xmath122 of the form @xmath163 where @xmath164 with @xmath165 of the same length as @xmath166 since we would like to unroll as few times as possible , the algorithm forces ( if possible ) parent - child subsumption by computing the strongest path - based loop invariant .",
    "therefore , @xmath167 can be replaced with a vector @xmath168 of the same length where some _ neutral _ annotations ( those that are not individually invariant ) in @xmath167 are transformed to _ min _",
    "annotations in @xmath168 such that @xmath169 subsumes @xmath121 .",
    "the function @xmath170 returns the vector @xmath171 if subsumption holds . otherwise , the parent - child subsumption is not possible and the algorithm returns @xmath172 .",
    "this our mechanism to lazily unroll loops .    _",
    "sibling - sibling : _ assume now the state @xmath136 has been already processed and stored in a _ memo table _ , @xmath173 .",
    "the condition here is that the current state associated to @xmath122 entails the interpolant associate to @xmath136 .",
    "that is , @xmath148 subsumes @xmath121 .",
    "this test is done by the function @xmath174 in the algorithm .",
    "if the test holds , this function also returns a _ subsuming state _ @xmath175 .",
    "otherwise , @xmath172 .    for @xmath175",
    "we need to distinguish two subcases . if @xmath136 is out of the scope of a loop , then @xmath176 . otherwise , as in the case of parent - child subsumption , we may need to convert some _ neutral _ annotations into _ min _ annotations to communicate ancestors the conditions under the subsumption took place .",
    "in particular , those neutral annotations which if had been _ max _",
    "annotations then subsumption would not have held .",
    "* merging vectors .",
    "* we use two operations for merging both and annotations . given two vectors @xmath167 and @xmath165 :    ( @xmath177 ) : if the condition @xmath178 holds then it returns a vector @xmath106 satisfying @xmath179 @xmath180 @xmath181 otherwise , the function returns @xmath182    ( @xmath183 ) : returns always a vector @xmath106 satisfying @xmath184 @xmath185 @xmath186 @xmath187 @xmath188 @xmath189 @xmath190    [ cols= \" > , < \" , ]     in summary , tracer is competitive with blast in most of the benchmark examples , sometimes much faster .",
    "however , there are two programs where blast is faster ( ` tcas-1a ` , and ` tcas-2a ` ) .",
    "we believe the main reason is that tracer does perform some extra work due to unnecessary infeasible paths .",
    "nevertheless , the numbers show that the differences are not significant .",
    "note that programs such as ` cdaudio ` , ` floppy ` , and ` serial ` are annotated with the symbol * in the blast column which means that blast raised an exception and aborted .",
    "therefore , we were not able to verify those programs using blast .",
    "although we could not contact blast authors we are aware that ` cdaudio ` and ` floppy ` have been proved safe in  @xcite after 21m59s and 11m17s discovering 196 and 156 predicates , respectively on pentium 2.4ghz 512 mb .",
    "special mention deserves the cases where the programs were proved unsafe . in these cases ,",
    "tracer found a real counterexample much faster than blast .",
    "the reason is that tracer blocks infeasible paths and then finds very quick the real error .",
    "blast will spent some time performing refinements and traversing space which are irrelevant to the real error path .",
    "nevertheless , this is an example where we believe that synergy - like tools using test cases would perform as ours since dart could also find the real error path faster .",
    "[ sec : conclusions ] we extended abstraction learning , an interpolation - based symbolic execution method , to automatically handle unbounded loops . the algorithm is an intelligent unrolling process by classifying into and constraints .",
    "the constraints are those which must be abstracted in order to achieve subsumption and loop invariance , while the constraints are those which must not be abstracted so as to detect infeasible paths and also to preserve safety . the idea is to have as few of these two kinds of constraints as possible .",
    "we discussed the relative merits of ours and ar - based methods using academic examples .",
    "we also evaluated our prototype , tracer , against blast , the most advanced system available to us , using real programs .",
    "the results show competitive performance , with some examples showing significant improvement . in all cases ,",
    "the results show that eagerly detecting infeasible paths can be efficient ."
  ],
  "abstract_text": [
    "<S> in previous work , we presented a symbolic execution method which starts with a concrete model of the program but progressively abstracts away details only when these are known to be irrelevant using interpolation . in this paper , we extend the technique to handle unbounded loops . </S>",
    "<S> the central idea is to progressively discover the strongest invariants through a process of loop unrolling . </S>",
    "<S> the key feature of this technique , called the minimax algorithm , is _ intelligent backtracking _ which directs the search for the next invariant . </S>",
    "<S> we then present an analysis of the main differences between our symbolic execution method and mainstream techniques mainly based on abstract refinement ( cegar ) . </S>",
    "<S> finally , we evaluate our technique against available state - of - the - art systems . </S>"
  ]
}