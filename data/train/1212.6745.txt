{
  "article_text": [
    "the challenge of finding and defining 2-dimensional complexity measures has been identified as an open problem of foundational character in complexity science  @xcite . indeed ,",
    "for example , humans understand 2-dimensional patterns in a way that seems fundamentally different than 1-dimensional  @xcite .",
    "these measures are important because current 1-dimensional measures may not be suitable to 2-dimensional patterns for tasks such as quantitatively measuring the spatial structure of self - organizing systems . on the one hand ,",
    "the application of shannon s entropy and kolmogorov complexity has traditionally been designed for strings and sequences .",
    "however , @xmath0-dimensional objects may have structure only distinguishable in their natural dimension and not in lower dimensions .",
    "this is indeed a question related to the lost in dimension reductionality  @xcite",
    ". a few measures of 2-dimensional complexity have been proposed before building upon shannon s entropy and block entropy  @xcite , mutual information and minimal sufficient statistics  @xcite and in the context of anatomical brain mri analysis  @xcite . a more recent application ,",
    "also in the medical context related to a measure of consciousness , was proposed using lossless compressibility for egg brain image analysis was proposed in  @xcite .    on the other hand , for kolmogorov complexity",
    ", the common approach to evaluating the algorithmic complexity of a string has been by using lossless compression algorithms because the length of lossless compression is an upper bound of kolmogorov complexity .",
    "short strings , however , are difficult to compress in practice , and the theory does not provide a satisfactory solution to the problem of the instability of the measure for short strings .    here",
    "we use so - called _ turmites _",
    "( 2-dimensional turing machines ) to estimate the kolmogorov complexity of images , in particular space - time diagrams of cellular automata , using levin s coding theorem from algorithmic probability theory .",
    "we study the problem of the rate of convergence by comparing approximations to a universal distribution using different ( and larger ) sets of small turing machines and comparing the results to that of lossless compression algorithms carefully devising tests at the intersection of the application of compression and algorithmic probability .",
    "we found that strings which are more random according to algorithmic probability also turn out to be less compressible , while less random strings are clearly more compressible .",
    "compression algorithms have proven to be signally applicable in several domains ( see e.g. @xcite ) , yielding surprising results as a method for approximating kolmogorov complexity .",
    "hence their success is in part a matter of their usefulness .",
    "here we show that an alternative ( and complementary ) method yields compatible results with the results of lossless compression .",
    "for this we devised an artful technique by grouping strings that our method indicated had the same program - size complexity , in order to construct files of concatenated strings of the same complexity ( while avoiding repetition , which could easily be exploited by compression ) .",
    "then a lossless general compression algorithm was used to compress the files and ascertain whether the files that were more compressed were the ones created with highly complex strings according to our method .",
    "similarly , files with low kolmogorov complexity were tested to determine whether they were better compressed .",
    "this was indeed the case , and we report these results in section  [ comparison ] . in subsection  [ eca ]",
    "we also show that the coding theorem method yields a very similar classification of the space - time diagrams of elementary cellular automata , despite the disadvantage of having used a limited sample of a _",
    "universal distribution_. in all cases the statistical evidence is strong enough to suggest that the coding theorem method is sound and capable of producing satisfactory results .",
    "the coding theorem method also represents the only currently available method for dealing with very short strings and in a sense is an expensive but powerful  microscope \" for capturing the information content of very small objects .",
    "central to algorithmic information theory ( ait ) is the definition of algorithmic ( kolmogorov - chaitin or program - size ) complexity @xcite :    @xmath2    that is , the length of the shortest program @xmath3 that outputs the string @xmath4 running on a universal turing machine @xmath5 . a classic example is a string composed of an alternation of bits , such as @xmath6 , which can be described as  @xmath0 repetitions of 01 \" .",
    "this repetitive string can grow fast while its description will only grow by about @xmath7 . on the other hand , a random - looking string such as @xmath8 may not have a much shorter description than itself .",
    "a technical inconvenience of @xmath9 as a function taking @xmath4 to the length of the shortest program that produces @xmath4 is its uncomputability @xcite . in other words , there is no program which takes a string @xmath4 as input and produces the integer @xmath10 as output .",
    "this is usually considered a major problem , but one ought to expect a universal measure of complexity to have such a property .",
    "on the other hand , @xmath9 is more precisely upper semi - computable , meaning that one can find upper bounds , as we will do by applying a technique based on another semi - computable measure to be presented in the next section .",
    "the invariance theorem guarantees that complexity values will only diverge by a constant @xmath11 ( e.g. the length of a compiler , a translation program between @xmath12 and @xmath13 ) and that they will converge at the limit . +",
    "* invariance theorem * ( @xcite ) : if @xmath12 and @xmath13 are two universal turing machines and @xmath14 and @xmath15 the algorithmic complexity of @xmath4 for @xmath12 and @xmath13 , there exists a constant @xmath11 such that :    latexmath:[\\[\\label{invariance }     hence the longer the string , the less important @xmath11 is ( i.e. the choice of programming language or universal turing machine ) . however , in practice @xmath11 can be arbitrarily large because the invariance theorem tells nothing about the rate of convergence between @xmath17 and @xmath18 for a string @xmath4 of increasing length , thus having an important impact on short strings .",
    "the algorithmic probability ( also known as levin s semi - measure ) of a string @xmath4 is a measure that describes the expected probability of a random program @xmath3 running on a universal ( prefix - free . ) for details see @xcite . ] ) turing machine @xmath5 producing @xmath4 upon halting .",
    "formally @xcite ,    @xmath19    levin s semi - measure @xmath20 defines a distribution known as the universal distribution ( a beautiful introduction is given in @xcite ) .",
    "it is important to notice that the value of @xmath20 is dominated by the length of the smallest program @xmath3 ( when the denominator is larger ) .",
    "however , the length of the smallest @xmath3 that produces the string @xmath4 is @xmath10 .",
    "the semi - measure @xmath20 is therefore also uncomputable , because for every @xmath4 , @xmath20 requires the calculation of @xmath21 , involving @xmath9 , which is itself uncomputable . an alternative to the traditional use of compression algorithms",
    "is the use of the concept of algorithmic probability to calculate @xmath10 by means of the following theorem . + * coding theorem * ( levin  @xcite ) : @xmath22    this means that if a string has many descriptions it also has a short one .",
    "it beautifully connects frequency to complexity , more specifically the frequency of occurrence of a string with its algorithmic ( kolmogorov ) complexity .",
    "the coding theorem implies that @xcite one can calculate the kolmogorov complexity of a string from its frequency @xcite , simply rewriting the formula as :    @xmath23    an important property of @xmath24 as a semi - measure is that it dominates any other effective semi - measure @xmath25 , because there is a constant @xmath26 such that for all @xmath4 , @xmath27 .",
    "for this reason @xmath20 is often called a _ universal distribution _ @xcite .",
    "let @xmath28 be a function  @xcite defined as follows :    @xmath29    where @xmath30 is the turing machine with number @xmath3 ( and empty input ) that produces @xmath4 upon halting , and @xmath31 is , in this case , the cardinality of the set @xmath32 . in  @xcite we calculated the output distribution of turing machines with 2-symbols and @xmath33 states for which the busy beaver @xcite values are known , in order to determine the halting time , and in  @xcite results were improved in terms of number and turing machine size ( 5 states ) and in the way in which an alternative to the busy beaver information was proposed , hence no longer needing exact information of halting times in order to approximate an informative distribution .",
    "here we consider an experiment with 2-dimensional deterministic turing machines ( also called _ turmites _ ) in order to estimate the kolmogorov complexity of 2-dimensional objects , such as images that can represent space - time diagrams of simple systems .",
    "turmite _ is a turing machine which has an orientation and operates on a grid for  tape \" .",
    "the machine can move in 4 directions rather than in the traditional left and right movements of a traditional turing machine head .",
    "a reference to this kind of investigation and definition of 2d turing machines can be found in  @xcite , one popular and possibly one of the first examples of this variation of a turing machine is lagton s ant  @xcite also proven to be capable of turing - universal computation .    in section  [ sec : strings - lenghts-10 ] , we will use the so - called _ turmites _ to provide evidence that kolmogorov complexity evaluated through algorithmic probability is consistent with the other ( and today only ) method for approximating @xmath9 , namely lossless compression algorithms .",
    "we will do this in an artful way , given that compression algorithms are unable to compress strings that are too short , which are the strings covered by our method .",
    "this will involve concatenating strings for which our method establishes a kolmogorov complexity , which then are given to a lossless compression algorithm in order to determine whether it provides consistent estimations , that is , to determine whether strings are less compressible where our method says that they have greater kolmogorov complexity and whether strings are more compressible where our method says they have lower kolmogorov complexity .",
    "we provide evidence that this is actually the case .",
    "in section  [ eca ] we will apply the results from the coding theorem method to approximate the kolmogorov complexity of 2-dimensional evolutions of 1-dimensional , closest neighbor cellular automata as defined in @xcite , and by way of offering a contrast to the approximation provided by a general lossless compression algorithm ( deflate ) .",
    "as we will see , in all these experiments we provide evidence that the method is just as successful as compression algorithms , but unlike the latter , it can deal with short strings .",
    "turmites or 2-dimensional ( 2d ) turing machines run not on a 1-dimensional tape but in a 2-dimensional unbounded grid or array . at each step",
    "they can move in four different directions ( _ up _ , _ down _ , _ left _ , _ right _ ) or _",
    "stop_. transitions have the format @xmath34 , meaning that when the machine is in state @xmath35 and reads symbols @xmath36 , it writes @xmath37 , changes to state @xmath38 and moves to a contiguous cell following direction @xmath39 .",
    "if @xmath38 is the halting state then @xmath39 is @xmath40 .",
    "in other cases , @xmath39 can be any of the other four directions .",
    "let @xmath41 be the set of turing machines with @xmath0 states and @xmath24 symbols .",
    "these machines have @xmath42 entries in the transition table , and for each entry @xmath43 there are @xmath44 possible instructions , that is , @xmath24 different halting instructions ( writing one of the different symbols ) and @xmath45 non - halting instructions ( 4 directions , @xmath0 states and @xmath24 different symbols ) .",
    "so the number of machines in @xmath41 is @xmath46 .",
    "it is possible to enumerate all these machines in the same way as 1d turing machines ( e.g. as has been done in @xcite and @xcite ) .",
    "we can assign one number to each entry in the transition table .",
    "these numbers go from 0 to @xmath47 ( given that there are @xmath48 different instructions ) .",
    "the numbers corresponding to all entries in the transition table ( irrespective of the convention followed in sorting them ) form a number with @xmath49 digits in base @xmath48 .",
    "then , the translation of a transition table to a natural number and vice versa can be done through elementary arithmetical operations .",
    "we take as output for a 2d turing machine the minimal array that includes all cells visited by the machine .",
    "note that this probably includes cells that have not been visited , but it is the more natural way of producing output with some regular format and at the same time reducing the set of different outputs .    [ cols= \" < , < \" , ]     [ corbylength ]      a 1-dimensional ca can be represented by an array of _ cells _",
    "@xmath51 where @xmath52 ( integer set ) and each @xmath53 takes a value from a finite alphabet @xmath54 .",
    "thus , a sequence of cells \\{@xmath51 } of finite length @xmath0 describes a string or _ global configuration _ @xmath11 on @xmath54 .",
    "this way , the set of finite configurations will be expressed as @xmath55 .",
    "an evolution comprises a sequence of configurations @xmath56 produced by the mapping @xmath57 ; thus the global relation is symbolized as :    @xmath58    where @xmath59 represents time and every global state of @xmath11 is defined by a sequence of cell states . the global relation",
    "is determined over the cell states in configuration @xmath60 updated simultaneously at the next configuration @xmath61 by a local function @xmath62 as follows :    @xmath63    wolfram @xcite represents 1-dimensional cellular automata ( ca ) with two parameters @xmath64 where @xmath65 is the number of states , and @xmath66 is the neighborhood radius .",
    "hence this type of ca is defined by the parameters @xmath67 .",
    "there are @xmath55 different neighborhoods ( where @xmath68 ) and @xmath69 distinct evolution rules .",
    "the evolutions of these cellular automata usually have periodic boundary conditions .",
    "wolfram calls this type of ca elementary cellular automata ( denoted simply by eca ) and there are exactly @xmath70 rules of this type .",
    "they are considered the most simple cellular automata ( and among the simplest computing programs ) capable of great behavioral richness .",
    "1-dimensional eca can be visualized in 2-dimensional space - time diagrams where every row is an evolution in time of the eca rule . by their simplicity and",
    "because we have a good understanding about them ( e.g. at least one eca is known to be capable of turing universality @xcite ) they are excellent candidates to test our measure @xmath71 , being just as effective as other methods that approach eca using compression algorithms @xcite that have yielded the results that wolfram obtained heuristically .",
    "we have seen that our coding theorem method with associated measure @xmath50 ( or @xmath71 in this paper for 2d kolmogorov complexity ) is in agreement with bit string complexity as approached by compressibility , as we have reported in section  [ sec : strings - lenghts-10 ] .    the universal distribution from turing machines that we have calculated ( @xmath72 )",
    "will help us to classify elementary cellular automata .",
    "classification of eca by compressibility has been done before in @xcite with results that are in complete agreement with our intuition and knowledge of the complexity of certain eca rules ( and related to wolfram s classification @xcite ) . in @xcite",
    "both classifications by simplest initial condition and random initial condition were undertaken , leading to a stable compressibility classification of ecas .",
    "here we followed the same procedure for both simplest initial condition ( single black cell ) and random initial condition in order to compare the classification to the one that can be approximated by using @xmath72 , as follows .",
    "we will say that the space - time diagram ( or evolution ) of an elementary cellular automaton @xmath11 after time @xmath59 has complexity :    @xmath73    that is , the complexity of a cellular automaton @xmath11 is the sum of the complexities of the @xmath66 arrays or image patches in the partition matrix @xmath74 from breaking @xmath75 into square arrays of length @xmath39 produced by the eca after @xmath59 steps .",
    "an example of a partition matrix of an eca evolution is shown in fig .",
    "[ rule30 ] for eca rule 30 and @xmath76 where @xmath77 .",
    "notice that the boundary conditions for a partition matrix may require the addition of at most @xmath78 empty rows or @xmath78 empty columns to the boundary as shown in fig .",
    "[ rule30 ] ( or alternatively the dismissal of at most @xmath78 rows or @xmath78 columns ) if the dimensions ( height and width ) are not multiples of @xmath39 , in this case @xmath76 .",
    "decomposing ( with boundary conditions ) the evolution of rule 30 ( top ) eca after @xmath79 steps into 10 subarrays of length @xmath80 ( bottom ) in order to calculate @xmath81 to approximate its kolmogorov complexity.,width=222 ]    @xmath82     decomposing ( with boundary conditions ) the evolution of rule 30 ( top ) eca after @xmath79 steps into 10 subarrays of length @xmath80 ( bottom ) in order to calculate @xmath81 to approximate its kolmogorov complexity.,width=309 ]     all the first 128 ecas ( the other 128 are 0 - 1 reverted rules ) starting from the simplest ( black cell ) initial configuration running for @xmath83 steps , sorted from lowest to highest complexity according to @xmath81 .",
    "notice that the same procedure can be extended for its use on arbitrary images.,width=396 ]    if the classification of all rules in eca by @xmath71 yields the same classification obtained by compressibility , one would be persuaded that @xmath71 is a good alternative to compressibility as a method for approximating the kolmogorov complexity of objects , with the signal advantage that @xmath71 can be applied to very short strings and very short arrays such as images . because all possible @xmath84 arrays of size @xmath85 are present in @xmath71 we can use this arrays set to try to classify all ecas by kolmogorov complexity using the coding theorem method .",
    "fig  [ fig : arrays3x3 ] shows all relevant ( non - symmetric ) arrays .",
    "we denote by @xmath81 this subset from @xmath71 .",
    "[ scatterplots ] displays the scatterplot of compression complexity against @xmath81 calculated for every cellular automaton .",
    "it shows a positive link between the two measures .",
    "the pearson correlation amounts to @xmath86 , so the determination coefficient is @xmath87 .",
    "these values correspond to a strong correlation , although smaller than the correlation between 1- and 2-dimensional complexities calculated in section  [ sec : strings - lenghts-10 ] .",
    "concerning orders arising from these measures of complexity , they too are strongly linked , with a spearman correlation of @xmath88 . the scatterplots ( fig .",
    "[ scatterplots ] ) show a strong agreement between the coding theorem method and the traditional compression method when both are used to classify ecas by their approximation to kolmogorov complexity .",
    "scatterplots of compression complexity against @xmath81 complexity as evaluated on the 128 first eca evolutions after @xmath89 steps .",
    "the top plot also shows the distribution of points along the axes displaying some clusters .",
    "the bottom plot shows a few of the eca rules used in fig.[sample ] ( but here for a black cell initial condition).,title=\"fig:\",width=302 ] +   scatterplots of compression complexity against @xmath81 complexity as evaluated on the 128 first eca evolutions after @xmath89 steps .",
    "the top plot also shows the distribution of points along the axes displaying some clusters .",
    "the bottom plot shows a few of the eca rules used in fig.[sample ] ( but here for a black cell initial condition).,title=\"fig:\",width=302 ]    the anomalies found in the classification of elementary cellular automata ( e.g. rule 77 being placed among eca with high complexity according to @xmath81 ) is a limitation of @xmath81 itself and not of the coding theorem method which for @xmath76 is unable to  see \" beyond 3-bit squares using , which is obviously very limited . and",
    "yet the degree of agreement with compressibility is surprising ( as well as with intuition , as a glance at fig .",
    "[ allecas ] shows , and as the distribution of ecas starting from random initial conditions in fig .",
    "[ sample ] confirms ) .",
    "in fact an average eca has a complexity of about 20k bits , which is quite a large program - size when compared to what we intuitively gauge to be the complexity of each eca , which may suggest that they should have smaller programs .",
    "however , one can think of @xmath90 as attempting to reconstruct the evolution of each eca for the given number of steps with square arrays only 3 bits in size , the complexity of the three square arrays adding up to approximate @xmath71 of the eca rule .",
    "hence it is the deployment of @xmath90 that takes between 500 to 50k bits to reconstruct every eca space - time evolution depending on how random vs. how simple it is .",
    "other ways to exploit the data from @xmath91 ( e.g. non - square arrays ) can be utilized to explore better classifications .",
    "we think that constructing a universal distribution from a larger set of turing machines , e.g. @xmath92 will deliver more accurate results but here we will also introduce a tweak to the definition of the complexity of the evolution of a cellular automaton .",
    "_ block decomposition method_. all the first 128 ecas ( the other 128 are 0 - 1 reverted rules ) starting from the simplest ( black cell ) initial configuration running for @xmath83 steps , sorted from lowest to highest complexity according to @xmath93 as defined in eq .",
    "[ newecaeq].,width=411 ]    splitting eca rules in array squares of size 3 is like trying to look through little windows 9 pixels wide one at a time in order to recognize a face , or training a microscope on a planet in the sky .",
    "one can do better with the coding theorem method by going further than we have in the calculation of a 2-dimensional universal distribution ( e.g. calculating in full or a sample of @xmath92 ) , but eventually how far this process can be taken is dictated by the computational resources at hand .",
    "nevertheless , one should use a telescope where telescopes are needed and a microscope where microscopes are needed .",
    "one can think of an improvement in resolution of @xmath94 for growing space - time diagrams of cellular automaton by taking the @xmath7 of the sum of the arrays where @xmath0 is the number of repeated arrays , instead of simply adding the complexity of the image patches or arrays .",
    "that is , one penalizes repetition to improve the resolution of @xmath71 for larger images as a sort of  optical lens \" .",
    "this is possible because we know that the kolmogorov complexity of repeated objects grows by @xmath7 , just as we explained with an example in section  [ kolmo ] . adding the complexity approximation of each array in the partition matrix of a space - time diagram of an eca provides an upper bound on the eca kolmogorov complexity , as it shows that there is a program that generates the eca evolution picture with the length equal to the sum of the programs generating all the sub - arrays ( plus a small value corresponding to the code length to join the sub - arrays ) .",
    "so if a sub - array occurs @xmath0 times we do not need to consider it s complexity @xmath0 times but @xmath7 .",
    "taking into account this , eq .  [ eqeca ] can be then rewritten as :    @xmath95    where @xmath96 are the different square arrays in the partition matrix @xmath74 and @xmath97 the multiplicity of @xmath96 , that is the number of repetitions of @xmath98-length patches or square arrays found in @xmath75 . from now on we will use @xmath99 for squares of size greater than 3 and it may be denoted only by @xmath9 or bdm for _ block decomposition method_. bdm has recently been applied successfully to measure the kolmogorov complexity of complex networks  @xcite .",
    "side by side comparison of 8 evolutions of representative ecas , starting from a random initial configuration , sorted from lowest to highest bdm values ( top ) and smallest to largest compression lengths using the deflate algorithm as a method to approximate kolmogorov complexity @xcite.,width=491 ]    now complexity values of @xmath100 range between 70 to 3k bits with a mean program - size value of about 1k bits .",
    "the classification of eca , according to eq .",
    "[ newecaeq ] , is presented in fig .  [ newecaeq ] .",
    "there is an almost perfect agreement with a classification by lossless compression length ( see fig .",
    "[ allecaslog ] and [ sample ] ) which makes even one wonder whether the coding theorem method is actually providing more accurate approximations to kolmogorov complexity than lossless compressibility for this objects length .",
    "notice that the same procedure can be extended for its use on arbitrary images .",
    "we denominate this technique _",
    "block decomposition method_. we think it will prove to be useful in various areas , including machine learning as an of kolmogorov complexity ( other contributions to ml inspired in kolmogorov complexity can be found in @xcite ) .    also worth notice that the fact that eca can be successfully classified by @xmath71 with an approximation of the universal distribution calculated from turing machines ( tm ) suggests that output frequency distributions of eca and tm can not be but strongly correlated , something that we had found and reported before in @xcite and @xcite .",
    "another variation of the same @xmath71 measure is to divide the original image into all possible square arrays of a given length rather than taking a partition .",
    "this would , however , be exponentially more expensive than the partition process alone , and given the results in fig .",
    "[ allecaslog ] further variations do not seem to be needed , at least not for this case .",
    "one important question that arises when positing the soundness of the coding theorem method as an alternative to having to pick a universal turing machine to evaluate the kolmogorov complexity @xmath9 of an object , is how many arbitrary choices are made in the process of following one or another method and how important they are .",
    "one of the motivations of the coding theorem method is to deal with the constant involved in the invariance theorem ( eq .  [ invariance ] ) , which depends on the ( prefix - free ) universal turing machine chosen to measure @xmath9 and which has such an impact on real - world applications involving short strings . while the constant involved remains ,",
    "given that after application of the coding theorem ( eq .  [ coding ] ) we reintroduce the constant in the calculation of @xmath9 , a legitimate question to ask is what difference it makes to follow the coding theorem method compared to simply picking the universal turing machine .",
    "on the one hand , one has to bear in mind that no other method existed for approximating the kolmogorov complexity of short strings .",
    "on the other hand , we have tried to minimize any arbitrary choice , from the formalism of the computing model to the informed runtime , when no busy beaver values are known and therefore sampling the space using an educated runtime cut - off is called for . when no busy beaver values are known the chosen runtime is determined according to the number of machines that we are ready to miss ( e.g. less than .01% ) for our sample to be significative enough",
    "as described in section  [ sec : setting - runtime ] .",
    "we have also shown in  @xcite that approximations to the universal distribution from spaces for which busy beaver values are known are in agreement with larger spaces for which busy beaver values are not known .    among the possible arbitrary choices it is the enumeration that may perhaps be questioned , that is , calculating @xmath101 for increasing @xmath0 ( number of turing machine states ) , hence by increasing size of computer programs ( turing machines ) .",
    "on the one hand , one way to avoid having to make a decision on the machines to consider when calculating a universal distribution is to cover all of them for a given number of @xmath0 states and @xmath24 symbols , which is what we have done ( hence the enumeration in a thoroughly @xmath102 space becomes irrelevant ) . while it may be an arbitrary choice to fix @xmath0 and @xmath24 , the formalisms we have followed guarantee that @xmath0-state @xmath24-symbol turing machines are in @xmath103 with @xmath104 ( that is , the space of all @xmath105-state @xmath106-symbol turing machines ) . hence the process is incremental , taking larger spaces and constructing an average universal distribution .",
    "in fact , we have demonstrated @xcite that @xmath107 ( that is , the universal distribution produced by the turing machines with 2 symbols and 5 states ) is strongly correlated to @xmath108 and represents an improvement in accuracy of the string complexity values in @xmath108 , which in turn is in agreement with and an improvement on @xmath109 and so on . we have also estimated the constant @xmath11 involved in the invariance theorem ( eq .  [ invariance ] ) between these @xmath101 for @xmath110 , which turned out to be very small in comparison to all the other calculated universal distributions @xcite .",
    "with two different experiments we have demonstrated that our measure is compatible with compression , yielding similar results but providing an alternative method  to compression  for short strings , that is the coding theorem method . we have also shown that @xmath71 ( and @xmath50 ) are ready for applications , and that calculating universal distributions is a stable alternative to compression and a worthwhile tool for approximating the kolmogorov complexity of objects , strings and images ( arrays ) .",
    "we think this method will prove to do the same for a wide range of areas where compression is nt an option given the size of strings involved .",
    "we also introduced the _ block decomposition method_. as we have seen with anomalies in the classification such as eca rule 77 ( see fig .",
    "[ allecas ] ) , when approaching the complexity of the space - time diagrams of eca by splitting them in square arrays of size 3 , the coding theorem method does have its limitations , especially because it is computationally very expensive ( although the most expensive part needs to be done only once  that is , producing an approximation of the universal distribution )",
    ". like other high precision instruments for examining the tiniest objects in our world , measuring the smallest complexities is very expensive , just as the compression method can also be very expensive for large amounts of data .",
    "we have shown that the method is stable in the face of the changes in turing machine formalism that we have undertaken ( in this case turmites ) as compared to , for example , traditional 1-dimensional turing machines or to strict integer value program - size complexity  @xcite as a way to estimate the error of the numerical estimations of kolmogorov complexity through algorithmic probability . for the turing machine model",
    "we have now changed the number of states , the number of symbols and now even the movement of the head and its support ( grid versus tape ) .",
    "we have shown and reported here and in  @xcite that all these changes yield distributions that are strongly correlated with each other up to the point to assert that all these parameters have marginal impact in the final distributions suggesting a fast rate of convergence in values that reduce the concern of the constant involved in the invariance theorem . in  @xcite",
    "we also proposed a way to compare approximations to the universal distribution by completely different computational models ( e.g. post tag systems and cellular automata ) , showing that for the studied cases reasonable estimations with different degrees of correlations were produced .",
    "the fact that we classify elementary cellular automata ( eca ) as shown in this paper , with the output distribution of turmites with results that fully agree with lossless compressibility , can be seen as evidence of agreement in the face of a radical change of computational model that preserves the apparent order and randomness of turmites in eca and of eca in turmites , which in turn are in full agreement with 1-dimensional turing machines and with lossless compressibility .",
    "we have made available to the community  a microscope \" in the form of the online algorithmic complexity calculator ( http://www.complexitycalculator.com ) implementing @xmath50 ( in the future it will also implement @xmath71 and many other objects and a wider range of methods ) that provides objective complexity estimations for short binary strings using these methods .",
    "raw data and the computer programs to reproduce the results for this paper can also be found under the publications section of the algorithmic nature group ( http://www.algorithmicnature.org ) .      yu.a .",
    "andrienko , n.v .",
    "brilliantov and j. kurths , complexity of two - dimensional patterns , _ eur .",
    "phys . j. _",
    "b 15 , 539546 , 2000 . c.h .",
    "bennett , logical depth and physical complexity in rolf herken ( ed ) _ the universal turing machine  a half - century survey , _ oxford university press 227257 , 1988 .",
    "bennett , how to define complexity in physics and why . in _ complexity , entropy and the physics of information .",
    "_ zurek , w. h. , addison - wesley , eds .",
    "sfi studies in the sciences of complexity , p 137 - 148 , 1990 .",
    "brady , the determination of the value of rado s noncomputable function @xmath111 for four - state turing machines , _ mathematics of computation 40 _ ( 162 ) : 647665 , 1983 .",
    "calude , _ information and randomness _ , springer , 2002 . c.s . calude and m.a .",
    "stay , most programs stop quickly or never halt , _ advances in applied mathematics _",
    ", 40 , 295 - 308 , 2008 .",
    "chaitin , on the length of programs for computing finite binary sequences : statistical considerations , _ journal of the acm _ , 16(1):145159 , 1969 .",
    "_ from philosophy to program size ,",
    "estonian winter school in computer science , institute of cybernetics , tallinn , 2003 .",
    "a. g. casali , o. gosseries , m. rosanova , m. boly , s. sarasso , k. r. casali , s. casarotto , m. bruno , s. laureys , g. tononi and m. massimini , a theoretically based index of consciousness independent of sensory processing and behavior , _ sci transl med , _ vol .",
    "5:198 , p. 198ra105",
    "r. cilibrasi , p. vitanyi , clustering by compression , _ ieee transactions on information theory , _ 51 , 4 , 15231545 , 2005 .",
    "universality in elementary cellular automata .",
    "_ complex systems , _ 15 , pp .",
    "140 , 2004 .",
    "t.m . cover and j.a .",
    "thomas , _ information theory , _ j. wiley and sons , 2006 .",
    "delahaye , _ complexit alatoire et complexit organise , _ editions quae , 2009 .",
    "delahaye , h. zenil , towards a stable definition of kolmogorov - chaitin complexity , arxiv:0804.3459 , 2007 .",
    "j - p . delahaye and h. zenil , on the kolmogorov - chaitin complexity for short sequences . in c. calude ( ed . ) , _ randomness and complexity : from leibniz to chaitin _ ,",
    "world scientific , 2007 .",
    "delahaye & h. zenil , numerical evaluation of the complexity of short strings : a glance into the innermost structure of algorithmic randomness , _ applied math . and comp .",
    "r. downey & d.r .",
    "hirschfeldt , _ algorithmic randomness and complexity _ , springer , 2010 .",
    "feldman and j.p .",
    "crutchfield , _ phys .",
    "e _ 67 , 051104 , 2003 .",
    "feldman , some foundations in complex systems : entropy , information , computation , and complexity , _",
    "santa fe institute s annual complex systems summer school _ , beijing china , 2008 .",
    "m. gardner , mathematical games - the fantastic combinations of john conway s new solitaire game  life \" , pp . 120123 , _ scientific american _ 223 , 1970 . m. hutter , on the existence and convergence of computable universal priors , in : proc .",
    "14th internat . conf . on algorithmic learning theory ( alt-2003 ) , lecture notes on artificial intelligence , vol . 2842 , sapporo , springer , berlin , pp . 298312 , 2003 . j. joosten , ",
    "turing machine enumeration : nks versus lexicographical \" , _ wolfram demonstrations project _ , 2012 .",
    "w. kircher , m. li , and p. vitanyi , the miraculous universal distribution , _ the mathematical intelligencer , _ 19:4 , 715 , 1997 .",
    "kolmogorov , three approaches to the quantitative definition of information , _ problems of information and transmission _ , 1(1):17 , 1965 .",
    "c.g.langton , studying artificial life with cellular automata , _ physica d : nonlinear phenomena _ 22 ( 13 ) : 120149 , 1986 . l. levin , laws of information conservation ( non - growth ) and aspects of the foundation of probability theory .",
    ", _ problems in form . transmission _ 10 . 206210 , 1974 . m. li , p. vitnyi , _ an introduction to kolmogorov complexity and its applications , _ springer , 2008 .",
    "pegg , jr .",
    " math puzzle \" . retrieved 10 june 2013 .",
    " . rivals , m. dauchet , j .-",
    "delahaye , o. delgrange , compression and genetic sequence analysis . , _ biochimie _ , 78 , pp 315 - 322 , 1996 .",
    "t. rad , on non - computable functions , _ bell system technical journal , _ vol .",
    "3 , pp . 877884 , 1962 .",
    "shalizi , k.l .",
    "shalizi , and r. haslinger , quantifying self - organization with optimal predictors _ phys .",
    "_ , 93 , 118701 , 2004 f. soler - toscano , h. zenil , j .-",
    "delahaye and n. gauvrit , calculating kolmogorov complexity from the frequency output distributions of small turing machines , plos one ( in press ) . f. soler - toscano , h. zenil , j .-",
    "delahaye and n. gauvrit , correspondence and independence of numerical evaluations of algorithmic information measures , arxiv:1211.4891 [ cs.it ] .",
    "solomonoff , a formal theory of inductive inference : parts 1 and 2 . _ information and control _ , 7:122 and 224254 , 1964 .",
    "s. wolfram , _ a new kind of science _",
    ", wolfram media , champaign , il .",
    "usa , 2002 .",
    "patterns of structural complexity in alzheimer s disease and frontotemporal dementia k. young , a - t .",
    "du , j. kramer , h. rosen , b. miller , m. weiner , and n. schuff , _ hum brain mapp .",
    "_ , 30(5 ) : 16671677 , 2009 . k. young and n. schuff , measuring structural complexity in brain images , _ neuroimage _ , 2008 ; 39(4 ) : 17211730 .",
    "h. zenil , compression - based investigation of the dynamical properties of cellular automata and other systems , _ complex systems . _ 19(1 ) , pages 1 - 28 , 2010 .",
    "h. zenil , j .-",
    "delahaye and c. gaucherel , image information content characterization and classification by physical complexity , _ complexity _ , vol .",
    "173 , pages 2642 , 2012 . h. zenil and j - p .",
    "delahaye , on the algorithmic nature of the world , in g. dodig - crnkovic and m. burgin ( eds ) , _ information and computation _ , world scientific publishing company , 2010 .",
    "h. zenil , n. kiani , j. tegnr , information conservation in dimensionality reduction and analysis techniques , submitted .",
    "zenil , f. soler - toscano , k. dingle and a. louis , correlation of automorphism group size and topological properties with program - size complexity evaluations of graphs and complex networks , _ physica a : statistical mechanics and its applications , _ vol .",
    "341358 , 2014 . h. zenil , une approche exprimentale  la thorie algorithmique de la complexit , dissertation in fulfilment of the degree of doctor in computer science , universit de lille 1 , 2011 ."
  ],
  "abstract_text": [
    "<S> the question of natural measures of complexity for objects other than strings and sequences , in particular suited for 2-dimensional objects , is an open important problem in complexity science . </S>",
    "<S> here we provide a measure based upon the concept of algorithmic probability that elegantly connects to kolmogorov complexity that provides a natural approach to @xmath0-dimensional algorithmic complexity by using an @xmath0-dimensional deterministic turing machine , popularized under the term of _ turmites _ for @xmath1 , from which the so - called _ </S>",
    "<S> langton s ant _ is an example of a turing universal _ </S>",
    "<S> turmite_. a series of experiments to validate estimations of kolmogorov complexity based on these concepts is presented , showing that the measure is stable in the face of some changes in computational formalism and that results are in agreement with the results obtained using lossless compression algorithms when both methods overlap in their range of applicability . </S>",
    "<S> we also present a _ block decomposition method _ ( bdm ) application to classification of images and space - time evolutions of discrete systems , providing evidence of the soundness of the method as a complementary alternative to compression algorithms for the evaluation of algorithmic complexity . </S>",
    "<S> we provide exact numerical approximations of kolmogorov complexity of square image patches of size 3 and more , with the bdm allowing scalability to larger images . + </S>",
    "<S> * keywords : * dimensional complexity ; image classification ; algorithmic probability ; compressibility ; pattern detection ; cellular automata . </S>"
  ]
}