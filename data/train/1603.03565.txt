{
  "article_text": [
    "although known earlier , fraction - free methods for exact matrix computations became popular after bareiss s study of gaussian elimination @xcite .",
    "extensions to related topics , such as lu factoring , were considered in @xcite . gram  schmidt orthogonalization and qr factoring were studied by @xcite , under the more descriptive name of exact division .",
    "recent studies have looked at extending fraction - free lu factoring to non - invertible matrices  @xcite and rank profiling @xcite , and more generally to areas such as the euclidean algorithm , and the berlekamp ",
    "massey algorithm  @xcite .",
    "we consider matrices over an integral domain @xmath0 .",
    "for the purposes of giving illustrative examples and conducting computational experiments , matrices over @xmath1 and @xmath2 $ ] are used , because the metrics associated with these domains are well established and familiar to readers .",
    "we emphasize , however , that the methods here apply for all integral domains , as opposed to methods that target specific domains , such as  @xcite .",
    "the starting point for this paper is the fraction - free form for lu decomposition  @xcite : given a matrix @xmath3 over an integral domain @xmath0 , @xmath4 where @xmath5 , @xmath6 and @xmath7 are over @xmath0 .",
    "@xmath5 and @xmath7 are lower and upper triangular and their diagonals contain the pivots of the gaussian elimination ; @xmath6 is diagonal and contains products of the pivots .",
    "the permutation matrices @xmath8 and @xmath9 ensure that the decomposition is always a full - rank decomposition , even if @xmath3 is rectangular or rank deficient .",
    "in addition to the usual indeterminacy due to varying pivot choices , the columns of @xmath5 and the rows of @xmath7 can be multiplied by common factors , which then appear also in @xmath6 .",
    "we show in section [ sec : qr ] that this form can cover @xmath10 decomposition also .",
    "our first main result is for qr factoring . in this context",
    ", the orthonormal @xmath11 matrix used in floating point calculations is replaced by a @xmath12 matrix , which is left - orthogonal , i.e. @xmath13 is diagonal , but @xmath14 is not .",
    "we show that for a square matrix @xmath3 , the last column of @xmath12 , as calculated by existing algorithms , is subject to an exact division by the determinant of @xmath3 , with a significant reduction in size .",
    "this is an example of a systematic factor , being one inherent to the algorithm .",
    "systematic factors occur in several ways .",
    "the bareiss algorithm uses exact division precisely to remove systematic factors ; the gram ",
    "schmidt algorithm from @xcite is another , where exact division removes systematic factors during the reduction .",
    "in addition to these , we add a different type of systematic factor : we show a relation between gcds existing for the rows in matrices obtained from lu factoring , and entries in the smith normal form of the same initial matrix .",
    "we next consider statistical factors : ones which depend on the initial data .",
    "when @xmath15 and @xmath10 matrices are computed using current standard fraction - free algorithms , their rows and columns may contain common factors .",
    "we discuss their origins and show we can predict a significant proportion of them from simple considerations .",
    "their presence influences aspects such as uniqueness .",
    "specifically , for the basic decomposition , we show how common factors can be moved between the three matrices .",
    "we discuss when this is beneficial .",
    "we next consider the role of pivoting in gaussian reduction .",
    "_  @xcite comment  we also mention that when the entries of @xmath16 are not of uniform size , it may be worthwhile to interchange rows in order to obtain a smaller pivot at the next step \" .",
    "it is often said that whereas for _ floating - point _ gaussian elimination the largest pivot should be chosen , in the setting of the smallest pivot is best .",
    "although within the floating - point literature , pivoting has been studied over an extended period , much less attention has been paid to the question in the context of exact computation .",
    "we consider a number of strategies empirically , and show that selecting the smallest pivot , suitably defined , leads to smaller output matrices .",
    "the paper will start with a brief discussion of fraction - free methods , then present results for qr factoring , lu factoring , and finally pivoting .",
    "fraction - free methods are based on the assumption that it is more efficient to compute with the elements of the input domain of a matrix than to compute with elements from the quotient field .",
    "since the solutions usually sought require the quotient field , fraction - free methods can be regarded as delaying for as long as possible the ultimate fall from grace of the computation . here ,",
    "some measurements are reported to supply empirical evidence to support fraction - free methods .",
    "our first point of comparison is between the lu decomposition offered by maple , through ` ludecomposition(a ) ` , and our own implementation of the @xmath17 decomposition based on @xcite .",
    "the built - in maple  command returns matrices @xmath5 and @xmath7 such that all diagonal elements of @xmath5 are @xmath18 , and both @xmath5 and @xmath7 contain elements from the quotient field of @xmath0 .",
    "the procedure which we implemented has the output format described in ( * ? ? ? * theorem  2 ) .",
    "figure  [ fig : luvsgauss.size.int ] shows the ratio of average storage requirements for the decomposition of integer matrices .",
    "here , we measure the total number of digits needed to represent the final output .",
    "note that this metric does not depend on the internal implementation of the two functions , nor does it depend on the particular computer algebra system .",
    "as figure  [ fig : luvsgauss.size.int ] illustrates , fraction - free methods require roughly half the storage .",
    "table  [ tab : luvsgauss.time.int ] compares timings for random integer matrices , as functions of matrix size and initial data size .",
    "for this experiment we used our own implementation of gaussian elimination , since we do not know the details of maple s built - in procedure , which may well use compiled code . by writing our own programme",
    "we make sure that every common part , for example pivot searching , uses exactly the same code and only the reduction steps differ .",
    "as table  [ tab : luvsgauss.time.int ] reveals , the advantages of the fraction - free method are clear , while not spectacular .",
    "( 0,2.2 ) node[above ] ratio |- ( 125,0 ) node[above ] size ; in 1,2 ( 0 , )  ( -1 , ) node[left ] @xmath19 ; in 10,20, ... ,120 ( , 0 ) ",
    "( , -0.1 ) node[below ] @xmath20 ; ( 5,1.303055 ) circle ( 2pt ) ; ( 10,1.581456 ) circle ( 2pt ) ; ( 15,1.720346 ) circle ( 2pt ) ; ( 20,1.800852 ) circle ( 2pt ) ; ( 25,1.842972 ) circle ( 2pt ) ; ( 30,1.872806 ) circle ( 2pt ) ; ( 35,1.896453 ) circle ( 2pt ) ; ( 40,1.912146 ) circle ( 2pt ) ; ( 45,1.926344 ) circle ( 2pt ) ; ( 50,1.936022 ) circle ( 2pt ) ; ( 55,1.944593 ) circle ( 2pt ) ; ( 60,1.949722 ) circle ( 2pt ) ; ( 65,1.953816 ) circle ( 2pt ) ; ( 70,1.958742 ) circle ( 2pt ) ; ( 75,1.965640 ) circle ( 2pt ) ; ( 80,1.968056 ) circle ( 2pt ) ; ( 85,1.970237 ) circle ( 2pt ) ; ( 90,1.972478 ) circle ( 2pt ) ; ( 95,1.975701 ) circle ( 2pt ) ; ( 100,1.976291 ) circle ( 2pt ) ; ( 105,1.978391 ) circle ( 2pt ) ; ( 110,1.980522 ) circle ( 2pt ) ; ( 115,1.981887 ) circle ( 2pt ) ; ( 120,1.982245 ) circle ( 2pt ) ; ( 125,1.983518 ) circle ( 2pt ) ;    r|*11r & 11 & 19 & 31 & 53 & 73 & 97 & 107 + 3 & 1.00 & 0.85 & 0.91 & 0.78 & 0.72 & 0.63 & 0.62 + 7 & 0.97 & 0.88 & 0.83 & 0.71 & 0.65 & 0.59 & 0.56 + 13 & 0.94 & 0.84 & 0.82 & 0.68 & 0.61 & 0.55 & 0.52 + 23 & 0.93 & 1.33 & 0.85 & 0.66 & 0.59 & 0.51 & 0.49 + 37 & 0.89 & 0.81 & 0.77 & 0.63 & 0.56 & 0.49 & 0.47 + 53 & 0.93 & 0.80 & 0.74 & 0.62 & 0.55 & 0.47 & 0.45 + 67 & 0.90 & 1.32 & 0.73 & 0.60 & 0.54 & 0.46 & 0.44 + 89 & 0.89 & 0.53 & 0.72 & 0.61 & 0.53 & 0.45 & 0.43 + 109 & 0.87 & 0.77 & 0.73 & 0.60 & 0.52 & 0.44 & 0.42 +",
    "a fraction - free ( exact division ) algorithm for gram  schmidt orthogonalization was described by @xcite .",
    "an algorithm based on @xmath15 factoring has been described in @xcite .",
    "the two approaches yield the same results .",
    "we denote the decomposition by @xmath21 , because @xmath11 usually denotes an orthonormal matrix , and @xmath12 is not orthonormal .",
    "we give a new statement of the basic theorem .",
    "l = u^t ] given a square , full - rank matrix @xmath3 over an integral domain @xmath0 , the partitioned matrix @xmath22 has a fraction - free lu decomposition @xmath23 where @xmath24 and @xmath21 .",
    "we can apply @xmath25 factoring , to get @xmath26 where the notation @xmath27 emphasizes that the matrices refer not to a factoring of @xmath3 , but of @xmath28 . since this matrix is symmetric",
    "we obtain @xmath29 because @xmath3 has full rank , so do @xmath5 and @xmath7 and we can rewrite the equation as @xmath30 examination of the matrices on the left hand side reveals that they and therefor also their product are all upper triangular . similarly , the left hand side is a lower triangular matrix and the equality of the two implies that they must both be diagonal .",
    "cancelling @xmath6 and rearranging the equation yields @xmath31 where @xmath32 is diagonal .",
    "this shows that the rows of @xmath33 are just multiples of the rows of @xmath34 .",
    "however , we know that the diagonal entries of @xmath33 and @xmath35 are the same .",
    "thus , @xmath32 is the identity and @xmath36 .",
    "we now write @xmath37 .",
    "the proof of ( * ? ? ?",
    "* theorem  8) shows @xmath38 and @xmath39 expanding the last expression and using the definition of @xmath40 gives then @xmath41    we now give an explicit expression of the last column of @xmath12 , showing the common factor of @xmath42 .",
    "[ thm : deta ] with @xmath43 and @xmath12 as in theorem  [ thm : l = u^t ] , we have for all @xmath44 that @xmath45 where @xmath46 is the @xmath47 minor of @xmath3 .",
    "we use the notation from the proof of theorem  [ thm : l = u^t ] . from @xmath48",
    "we obtain @xmath49 thus , since @xmath3 has full rank , @xmath50 or , equivalently , @xmath51 where @xmath52 is the adjugate matrix of @xmath3 .",
    "since @xmath53 is a lower triangular matrix with @xmath54 at position @xmath55 , the claim follows .",
    "[ thm : qr.cancel ] given a square matrix @xmath3 , a reduced fraction - free @xmath10 decomposition is given by @xmath56 , where @xmath57 and @xmath58 , and @xmath59 .",
    "in addition , @xmath60 .    by theorem [ thm :",
    "deta ] , @xmath61 is an exact division .",
    "the theorem follows from @xmath62 .    as an example we consider the @xmath63-by-@xmath63 integer matrix @xmath64 computing the @xmath65 decomposition with theorem  [ thm : l = u^t ] yields @xmath66 @xmath67 + @xmath68  , + @xmath69 @xmath70 we can now check that indeed @xmath71 divides the last column of @xmath12 .",
    "cancelling @xmath42 from the last column of @xmath12 and the last entry of @xmath40 as well as reducing @xmath6 accordingly leads to the much simpler output @xmath72 @xmath67 + @xmath73 and @xmath74",
    "given a matrix @xmath3 over an integral domain @xmath0 , we consider the fraction - free decomposition @xmath75 .",
    "it is clear that if the elements in a column of @xmath5 or a row of @xmath7 possess a common gcd , then that factor can be removed , reducing the size of the matrix elements .",
    "we identify 3 sources of common gcds .",
    "the initial matrix may contain one or more rows having a common gcd , usually because of modelling choices made by the user .",
    "standard gaussian elimination will then transfer the common factor into all subsequent rows .",
    "if several rows have different gcds , then all gcds accumulate in subsequent rows .",
    "the following theorem links the smith normal form of a given matrix with factors appearing in the lu decomposition .",
    "[ thm : smith ] let @xmath76 have the smith normal form @xmath77 where @xmath78 .",
    "moreover , let @xmath79 be an @xmath80 decomposition of @xmath3 .",
    "then for @xmath81 @xmath82    the values @xmath83 are known as the _ determinantal divisors _ of @xmath3 .    according to (",
    "* ii.15 ) , the diagonal entries of the smith form are quotients of the determinantal divisors , i.e. , @xmath84 and @xmath85 for @xmath86 .",
    "moreover , @xmath87 is the greatest common divisor of all @xmath88-by-@xmath88 minors of @xmath3 for each @xmath81 .",
    "thus , we only have to prove that the entries of the @xmath88  row of @xmath7 are @xmath88-by-@xmath88 minors of @xmath3 .",
    "however , this follows from ( * ? ? ?",
    "* eqns  ( 9.8 ) , ( 9.12 ) ) , since the @xmath88  row of @xmath7 are just @xmath89    similarly , following the algorithm in @xcite , we see that the columns of @xmath5 are just made up by copying entries from the columns of @xmath7 during the reduction .",
    "more precisely , the @xmath88  column of @xmath5 will have the entries @xmath90 ( using the notation of @xcite ) .",
    "but these are again just @xmath88-by-@xmath88 minors of @xmath3 .",
    "we give an example using the domain @xmath2 $ ] .",
    "let @xmath3 be the polynomial matrix @xmath91       -3        & -2 x^3 + 10 x^2 + 5 x - 9    & 2 x^2 + 2 x & x^3 - 2 x^2          \\\\[1ex ]       \\frac12   & x^3 + \\frac32                & 0            & -\\frac12 x^3         \\\\[1ex ]       -\\frac12 & -x - \\frac32                 & 0            & \\frac12 x    \\end{pmatrix}.\\ ] ] the smith normal form @xmath92 of @xmath3 is @xmath93 and thus its determinantal divisors are @xmath94 , @xmath95 , @xmath96 and @xmath97 .",
    "computing the @xmath17 decomposition of @xmath3 yields @xmath79 where @xmath5 is @xmath98      -3 & \\frac32 x & 0 & 0 \\\\[1ex ]      \\frac12 & -x^3   - \\frac52 x^2   - \\frac32 x & \\frac12 x^3   + \\frac12 x^2   & 0 \\\\[1ex ]      -\\frac12 & -\\frac12 x^3   + \\frac52 x^2   + 3 x & -\\frac12 x^3   - \\frac12 x^2 &      -\\frac14 x^6   - \\frac14 x^5   + \\frac14 x^4   + \\frac14 x^3    \\end{pmatrix},\\ ] ] @xmath99 , @xmath7 is @xmath100      0 & \\frac32 x & 0 & 0 \\\\[1ex ]      0 & 0 & \\frac12 x^3 + \\frac12 x^2 & -\\frac12 x^4 - \\frac12 x^3 \\\\[1ex ]      0 & 0 & 0 & -\\frac14 x^6 - \\frac14 x^5 + \\frac14 x^4 + \\frac14 x^3    \\end{pmatrix}.\\ ] ] computing the column factors of @xmath5 and the row factors of @xmath7 yields @xmath18 , @xmath101 , @xmath102 and @xmath103 , i.e. , exactly the determinantal divisors . in general",
    ", there could be other factors as well .",
    "suppose that during bareiss s algorithm after @xmath104 iterations we have reached the following state @xmath105 where @xmath7 is an upper triangular matrix , @xmath106 , @xmath107 and the other overlined quantities are row vectors and the underlined quantities are column vectors .",
    "assume that @xmath108 and that we choose it as a pivot .",
    "continuing the computations we now eliminate @xmath109 ( and the entries below ) by cross - multiplication @xmath110 here , we can see that any common factor of @xmath111 and @xmath109 will be a factor of every entry in that row , i.e. , @xmath112 .",
    "however , we still have to carry out the exact division step . this leads to @xmath113 the division by @xmath114 is exact .",
    "some of the factors in @xmath114 might be factors of @xmath111 or @xmath109 while others are hidden in @xmath115 or @xmath116 .",
    "however , every common factor of @xmath111 and @xmath109 which is not also a factor of @xmath114 will still be a common factor of the resulting row .",
    "in other words , @xmath117    in fact , the factors do not need to be tracked during the @xmath80 reduction but can be computed afterwards : all the necessary entries @xmath111 , @xmath109 and @xmath114 of @xmath118 will end up as entries of @xmath5 .",
    "more precisely , we will have @xmath119 , @xmath120 and @xmath121 .    if @xmath0 are the integers , then the probability that the quotient @xmath122 , i.e. nontrivial , for random @xmath123 equals @xmath124 @xcite",
    ". thus , for integer matrices these factors occur with a high enough frequency to suggest we care about them . in our experiments we saw that independently of the size of the input matrix",
    "this method could detect about @xmath125 of all the common prime row factors occurring in @xmath7 . of sizes between @xmath126-by-@xmath126 and @xmath127-by-@xmath127 .",
    "we decomposed @xmath3 into @xmath128 and then computed the number of predicted prime factors in @xmath7 and related that to the number of actual prime factors .",
    "we did not consider the last row of @xmath7 since this contains only the determinant . ]    as an example consider the matrix @xmath129 this matrix has a @xmath80 decomposition with @xmath130 and @xmath131 the method outlined above correctly predicts the common factor @xmath132 in the second row , the factor @xmath133 in the third row and the factor @xmath132 in the fourth row .",
    "however , it does not detect the additional factor @xmath126 in the fourth row .",
    "there is another way in which common factors in integer matrices can arise : let @xmath134 be any number .",
    "then for random @xmath135 the probability that @xmath136 is @xmath137 .",
    "that means that if @xmath138 are vectors , then @xmath139 with a probability of @xmath140 .",
    "this effect is noticable in particular for small numbers like @xmath141 and in the last iterations of the @xmath80 decomposition when the number of non - zero entries in the rows has shrunk .",
    "for instance , in the second last iterations we only have three rows with at most three non - zero entries each .",
    "moreover , we know that the first non - zero entries of the rows cancel during cross - multiplication",
    ". thus , a factor of @xmath132 appears with a probability of @xmath142 in one of those rows , a factor of @xmath133 with a probability of @xmath143 . in the example above , the probability for the factor @xmath126 to appear in the fourth row was @xmath144 .    in a manner similar to theorem  [ thm : qr.cancel ]",
    ", we can cancel all factors which we find from the final output :    [ thm : lu.cancel ] given a matrix @xmath145 with rank @xmath146 and its decomposition @xmath147 , if @xmath148 is a diagonal matrix with @xmath149 , then setting @xmath150 and @xmath151 where both matrices are fraction - free we have the decomposition @xmath152 .    by ( * ? ? ? * theorem  2 ) the diagonal entries of @xmath7 are the pivots chosen during the decomposition and they also divide the diagonal entries of @xmath6 .",
    "thus , any common divisor of @xmath153 will also divide @xmath154 and therefor both @xmath33 and @xmath155 are fraction - free .",
    "we can easily check that @xmath156 .",
    "if we can find common column factors of @xmath5 we can cancel them in the same way .",
    "however , if we have already cancelled factors from @xmath7 , then there is no guarantee that @xmath157 implies @xmath158 .",
    "thus , in general we can only cancel @xmath159 from @xmath160 .",
    "our pivoting strategies are all based on full pivoting , which is already implied by the definition of the form .",
    "we define a number of pivoting strategies .",
    "largest : :    we select the largest pivot according to an appropriate metric .",
    "metrics were the absolute value for integer matrices and the degree as    well as the height for matrices univariate polynomials .",
    "smallest : :    here we select the smallest pivot according to the same metrics as    above . first",
    ": :    we select the first non - zero pivot .",
    "factors : :    with this strategy we select the pivot which has the least number of    prime factors counted with multiplicity .    of course , the `` factors '' strategy is not viable in practice since the factorisation is much too costly .",
    "however , it does provide interesting theoretical insight .",
    "in contrast to floating point calculations , accuracy of the result is not an issue , and we consider instead the size of the elements in the matrices generated , and any impact on the efficiency of the computation . by size",
    "we examine the following    digits : :    for integer matrices or matrices we count the total number of    base-@xmath161 digits needed to represent it .",
    "we also use this    measurement for matrices with rational number entries where we simply    add up the digits of the numerators and the denominators .",
    "terms : :    for univariate polynomial matrices we count the total number of    non - zero terms in the fully expanded representation of the entries .",
    "height : :    as another metric for polynomial matrices we use the maximal height of    its entries .",
    "factors : :    for both integer and polynomial matrices we measure the total number    of row factors . here , we compute the greatest common divisor of each    row and count the number of prime factors with multiplicity .",
    "the    number of factors for ech row is then added up .",
    "note that the measured quantities do solely depend on the output .",
    "in particular do they not depend on how the programme handles its memory during the computations .",
    "also note that the measurements are chosen in such a way that they are independent of the internal representation of the data .",
    "for instance , every programme has to store all the digits of the output matrices somehow .",
    "the experiments included in this paper were all carried out with maple .",
    "we use our own implementation of the @xmath80 decomposition which closely follows @xcite . for each experiment we generated random matrices",
    "@xmath3 of different sizes and then performed the decomposition @xmath147 using the strategies described above .",
    "that is , each random matrix @xmath3 was decomposed with each of the strategies .",
    "we then applied the applicable measurements . in the end",
    "we computed the mean value of all the results .",
    "more precise description of the experiments follow below .",
    "for table  [ tab : pivoting.int ] we generated three hundred integer matrices for each size .",
    "the entries where between @xmath162 and @xmath163 .",
    "also in order to be closer to real world problems , we made sure that the sizes of the entries in our matrices varied widely with less than @xmath142 of the entries reaching maximal size .",
    "table  [ tab : pivoting.int ] shows the number of digits and the number of row factors of @xmath7 where the decompositions are done using the `` smallest '' , `` largest '' and `` factors '' strategies described at the beginning of this section .",
    "r|*3r|*3r @xmath164 & & + & smallest & largest & factors & smallest & largest & factors + 5 & 78.13 & 101.74 & 85.13 & 7.58 & 8.01 & 5.74 + 10 & 503.72 & 678.40 & 569.40 & 11.65 & 12.80 & 6.44 + 15 & 1625.08 & 2130.83 & 1833.94 & 17.17 & 17.95 & 7.77 + 20 & 3832.33 & 4888.83 & 4297.05 & 21.38 & 22.88 & 7.98 + 25 & 7533.28 & 9365.39 & 8316.27 & 26.06 & 27.92 & 8.26    table  [ tab : pivoting.polynom ] shows a similar experiment for matrices of univariate polynomials .",
    "we compare the strategies of choosing the pivot with the smallest degree versus choosing the largest degree and choosing the smallest height .",
    "the matrices @xmath3 contained random polynomials with integer coefficients between @xmath165 and @xmath166 and degree at most @xmath133 . during the same experiment we also measured the number of row factors and the height of @xmath7 but",
    "we did not find a significant difference between the different strategies .",
    "r|*3r @xmath164 & smallest degree & largest degree & height + 5 & 83.07 & 106.80 & 91.91 + 10 & 532.45 & 698.15 & 609.13 + 15 & 1696.09 & 2154.53 & 1946.16 + 20 & 3932.09 & 4860.95 & 4504.71",
    "in this section we detail a method for solving linear systems in such a way that fractions are delayed until the final output .",
    "let @xmath145 and @xmath167 .",
    "we wish to solve the system @xmath168 , seeking solutions @xmath101 with entries in the field of fractions of @xmath0 .",
    "first , apply the @xmath80 decomposition as in @xcite .",
    "we obtain @xmath169 where all ( sub ) matrices have entries in @xmath0 , @xmath7 is an @xmath146-by-@xmath146 , regular and upper triangular matrix , @xmath146 is the rank of @xmath3 and where @xmath170 has dimension @xmath146 .",
    "then @xmath168 if and only if @xmath171 and @xmath172 .",
    "now , perform a second @xmath80 decomposition on @xmath7 ( pivoting is not needed as all diagonal entries of @xmath7 are non - zero ) , working from the bottom to the top , and from right to left be the matrix of the permutation which maps @xmath173 to @xmath174 and decompose @xmath175 in the normal way applying the same permutations to the result . ] .",
    "this will compute a regular @xmath176 such that @xmath177 is a diagonal matrix . then @xmath168 if and only if @xmath171 and @xmath178 .",
    "assume now that the compatibility condition @xmath171 is fulfilled . in order to compute a particular solution @xmath179 of the system @xmath168",
    ", we can simply choose @xmath180 and where @xmath181 is a diagonal matrix with entries in @xmath0 .",
    "moreover , we can compute the nullspace of @xmath3 in the following way : if @xmath182 then we can easily check that @xmath183 .",
    "since the @xmath184 columns of the matrix spanning the space are clearly linearly independent , it follows that this is already the entire nullspace of @xmath3 .",
    "thus , setting @xmath185 we see the nullspace of @xmath3 is @xmath186 , with @xmath187 as defined above .",
    "note that @xmath92 and @xmath188 are both matrices over @xmath0 .",
    "thus , the particular solution and the nullspace are both computed in a fraction - free way . moreover , neither of the matrices depends on the right hand side @xmath109 .",
    "consequently , after computing @xmath189 , @xmath92 , @xmath187 and @xmath188 , we can solve the system @xmath168 for arbitrary @xmath109 by just checking whether @xmath171 and then computing @xmath190 .",
    "we summarise the method as follows :    [ alg : solve ]    input : : :    a matrix @xmath145 .",
    "output : : :    matrices @xmath189 , @xmath92 , and @xmath188 with    entries in @xmath0 and a diagonal    matrix @xmath187 with entries in    @xmath0 such that for any    @xmath167 if the compatibility    condition @xmath171 is met , then the system    @xmath168 has the solution set    @xmath191 .",
    "steps : : :",
    "1 .   apply the @xmath80 decomposition to obtain    @xmath192 where @xmath7 is upper triangular .    2 .",
    "use a backwards @xmath80 decomposition on    @xmath7 to obtain a matrix @xmath193 such that diagonal    @xmath177 is a diagonal matrix .",
    "let @xmath194 and    @xmath181 .",
    "as an example we consider the matrix @xmath195 and examine the two systems below for solutions .",
    "@xmath196    following algorithm  [ alg : solve ] , we first compute @xmath197 where @xmath9 represents the permutation @xmath198 ; and use this to define the matrices @xmath199 , @xmath189 , @xmath7 and @xmath200 .",
    "next , we compute @xmath201 and @xmath202 .",
    "this leads to @xmath203 and @xmath204 .",
    "we can check that @xmath205 .",
    "consequently , the system @xmath206 does not have a solution . on the other hand , @xmath207 and the solution set for @xmath208 is @xmath209",
    "we have shown that fraction - free lu and qr decompositions can contain significant common factors , and we have shown how these can be beneficially removed to obtain more compact decompositions . moreover ,",
    "their removal makes the decomposition unique .",
    "we considered removing the common factors as soon as they can be detected during the computation of the decompositions .",
    "this would require either discovering the gcds by direct computation , or by predicting them by different , preferably simpler , computations .",
    "although we have displayed here mechanisms that generate common factors , and which lend themselves to predictions through relatively simple calculations , there are other mechanisms which we have not discussed .",
    "these require more extensive computations to predict , and quickly leave the realm of reasonable strategies .",
    "therefore we have concluded that it is most sensible to leave common factor identification to the final stage of decomposition .",
    "we hope that reduced decompositions can be implemented as the standard form in future computer - algebra systems .",
    "this work was supported in part by the austrian science fund ( fwf ) grant sfb50 ( f5009-n15 ) .",
    "dumas , c.  pernet , and z.  sultan . computing the rank profile matrix . in d.",
    "robertz , editor , _ proceedings of the 2015 international symposium on symbolic and algebraic computation , issac15 _ , pages 149156 .",
    "acm , acm press , 2015 .                      c.  pauderis and a.  storjohann . computing the invariant structure of integer matrices : fast algorithms into practice . in m.  kauers , editor , _ proceedings of the international symposium on symbolic and algebraic computation , issac13_. acm press , 2013 ."
  ],
  "abstract_text": [
    "<S> we consider exact matrix decomposition by gauss - bareiss reduction . we investigate two aspects of the process : common row and column factors and the influence of pivoting strategies . </S>",
    "<S> we identify two types of common factors : systematic and statistical . </S>",
    "<S> systematic factors depend on the process , while statistical factors depend on the specific data . </S>",
    "<S> we show that existing fraction - free qr ( gram  schmidt ) algorithms create a common factor in the last column of q. we relate the existence of row factors in lu decomposition to factors appearing in the smith normal form of the matrix . for statistical factors , </S>",
    "<S> we identify mechanisms and give estimates of the frequency . </S>",
    "<S> our conclusions are tested by experimental data . for pivoting strategies , we compare the sizes of output factors obtained by different strategies </S>",
    "<S> . we also comment on timing differences . </S>"
  ]
}