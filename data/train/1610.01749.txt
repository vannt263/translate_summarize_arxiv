{
  "article_text": [
    "for a general source , han @xcite has introduced a notion of `` decoding error '' for variable - length coding and analyzed the minimum average codeword length provided that the decoding error probability vanishes as the source sequence length goes to infinity .",
    "koga and yamamoto @xcite have analyzed the minimum average codeword length for variable - length @xmath0-coding for which the decoding error probability is allowed up to @xmath1 . for a stationary memoryless source satisfying a certain mild condition , kostina et al .",
    "@xcite have recently given a single - letter characterization of the optimum second - order codeword length for variable - length @xmath0-codes .",
    "the problem of minimizing the average codeword cost with a cost function , which imposes unequal costs for code symbols , has been studied .",
    "this problem , without decoding error , has been introduced by shannon @xcite .",
    "karp @xcite has studied a construction of the optimum prefix code , and krause @xcite has characterized the minimum average codeword cost for stationary memoryless sources .",
    "han and uchida @xcite have extended the formula established by @xcite to general sources .    in this paper , we introduce the notion of decoding error for variable - length coding with cost .",
    "we first derive finite length upper and lower bounds on the cost rate and establish a general formula of the minimum achievable cost rate by allowing the error probability up to @xmath0 .",
    "we also give a general formula of the second - order minimum achievable rate .",
    "based on the established second - order coding theorem and the recently obtained result by @xcite ( with the uniform cost ) , a single - letter characterization of the second - order optimum cost rate is obtained for stationary memoryless sources .",
    "let @xmath2 be a _ finite _ or _ countably infinite _ source alphabet .",
    "let @xmath3 denote a general source , where @xmath4 takes values in @xmath2 .",
    "we do not impose any assumptions on @xmath5 such as stationarity or ergodicity .",
    "let @xmath6 be a code alphabet of size @xmath7 and let @xmath8 denote the set of all finite - length sequences taken from @xmath9 .",
    "we consider a _ prefix code _",
    "@xmath10 , where @xmath11 and @xmath12 denote an encoder and a decoder , respectively .",
    "let @xmath13 denote the length of the codeword @xmath14 for @xmath15 .",
    "we now introduce the cost function @xmath16 .",
    "we assume that the cost function can be decomposed for @xmath17 as @xmath18 with @xmath19 and there exists a unique solution @xmath20 of the equation @xmath21 for all @xmath22 . from and",
    ", we can easily checked that @xmath23 , called the _ cost capacity _",
    "@xcite , is also the unique solution for the equation @xmath24 this class of cost functions , said to be _ regular _ , was first considered by han and kato @xcite . for the prefix code @xmath10 , we focus on the two performance indices ; the _ average cost rate _ @xmath25 and the _ average error probability _ @xmath26 a code of source sequence of length @xmath27 , the average codeword cost @xmath28 , and the average error probability @xmath29 is called an @xmath30 code ( or simply an @xmath31 code ) with cost @xmath32 .",
    "consider a special case where the cost function @xmath32 satisfies @xmath33 where the costs are independent of @xmath34 .",
    "then , the cost @xmath35 of the codeword @xmath14 is just the codeword length @xmath36 .",
    "the average codeword cost is then the average codeword length , which is often the subject of studies on variable - length source coding .",
    "the codeword cost , which may be asymmetric for @xmath37 , is a generalized notion of the codeword length .",
    "in this section , we establish finite length lower and upper bounds on the average codeword cost .      [ theo : converse_bound ] any @xmath30 prefix code with regular cost @xmath32 satisfies @xmath52}(x^n ) } { \\alpha_c n } + \\frac{\\varepsilon_n c_{\\min}}{n } , \\label{eq : converse_bound}\\end{aligned}\\ ] ] where @xmath53 is defined as in .",
    "( _ _ p__roof )   for an @xmath30 code @xmath10 , let @xmath54 be defined as @xmath55 then we have @xmath56 where @xmath57 denotes the complement of @xmath58 .",
    "it is easily verified that the average codeword cost rate @xmath28 is bounded as @xmath59 where @xmath60 denotes the indicator function .",
    "defining @xmath61 for all @xmath37 , we have @xmath62 since @xmath63 is one - to - one between @xmath64 and @xmath14 .",
    "then , @xmath65 } ( x^n ) } { \\pr\\{x^n \\in d_n \\ } } ,   \\label{eq : ineq2}\\end{aligned}\\ ] ] where the inequality in follows due to the log - sum inequality . plugging into yields .",
    "[ theo : achievability_bound ]  there exists an @xmath30 prefix code with regular cost @xmath32 satisfying @xmath66}(x^n)}{\\alpha_c n }   + \\frac{1}{n } \\left ( \\frac{\\log 2 + \\gamma}{\\alpha_c }   + ( 2 + \\varepsilon_n ) c_{\\max } \\right ) , \\label{eq : achievability_bound}\\end{aligned}\\ ] ] where @xmath67 is an arbitrary constant and @xmath68 is defined as in .",
    "( _ proof _ )  for any @xmath69 fix a subset @xmath70 such that @xmath71 and @xmath72 } ( x^n ) + \\gamma , \\label{eq : set_an}\\end{aligned}\\ ] ] where we define @xmath73 assume that elements of @xmath74 are ordered as @xmath75 .",
    "we use a generalized version of shannon - fano - elias coding with costs ( cf .",
    "@xcite ) for encoding of elements of @xmath74 . for every @xmath76",
    "we define @xmath77 where @xmath78 .",
    "then , there exists a prefix code @xmath79 such that @xmath80 and @xmath81 ( cf .",
    "@xcite and the proof of theorem [ theo : epsilon - achievable - relation ] in section [ sect : asymptotic_analysis ] ) .",
    "we construct a new prefix code @xmath10 from @xmath79 by setting @xmath82 and @xmath83 where @xmath84 denotes concatenation .",
    "then , it follows from that for all @xmath85 @xmath86    the decoding error probability is obviously @xmath87 .",
    "we evaluate the average cost rate as @xmath88 in view of , the first term is evaluated as @xmath89}(x^n)}{\\alpha_c n }   +   \\frac{\\log 2 + \\gamma}{\\alpha_c n } + \\frac{2 c_{\\max}}{n } , \\label{eq : ineq4}\\end{aligned}\\ ] ] where we have used for the last inequality . plugging into yields .",
    "we define the @xmath0-achievable cost rates as follows :    for @xmath90 , a cost rate @xmath91 is said to be _ type - i @xmath0-achievable with cost @xmath32 _ if there exists a sequence of @xmath31 codes satisfying @xmath92 the infimum of all type - i @xmath0-achievable cost rates with cost @xmath32 is denoted by @xmath93 .",
    "also , @xmath91 is said to be _",
    "type - i optimistically @xmath0-achievable with cost _",
    "@xmath32 if there exists a sequence of @xmath31 codes satisfying @xmath94 the infimum of all optimistically @xmath0-achievable cost rates with cost @xmath32 is denoted by @xmath95 .",
    "the following definition gives a right - continuous version of the infimum @xmath0-achievable cost rate , which is a generalized notion of _ weak achievability _ for variable - length codes ( cf .",
    "han @xcite , koga and yamamoto @xcite ) .    for @xmath1 , a cost rate @xmath91",
    "is said to be _ type - ii @xmath0-achievable with cost @xmath32 _ if there exists a sequence of @xmath31 codes satisfying and @xmath96 the infimum of all type - ii @xmath0-achievable cost rates with cost @xmath32 is denoted by @xmath97 .",
    "[ rema : type - iand - ii ] it is easily shown that we have @xmath98 we have the analogous relation for optimistically @xmath0-achievable cost rates .",
    "this means that it suffices to establish a formula for type - i @xmath0-achievable cost rates , so we shall consider only the type - i achievability .",
    "now , we establish the general formula for the type - i @xmath0-achievable cost rates .",
    "[ theo : typei - epsilon - achievable - rate ] for every @xmath90 , any general source @xmath5 satisfies @xmath99}({\\boldsymbol x})}{\\alpha_c } = \\limsup_{n \\rightarrow \\infty } \\frac { h_{[\\varepsilon ] } ( x^n)}{\\alpha_c n } , \\label{eq : typei_min_rate } \\\\ \\mathcal{r}_c^{(\\mathrm{i } ) * }   ( \\varepsilon| { \\boldsymbol x } ) & = \\frac{h_{[\\varepsilon]}^*({\\boldsymbol x})}{\\alpha_c } = \\liminf_{n \\rightarrow \\infty } \\frac{h_{[\\varepsilon ] } ( x^n)}{\\alpha_c n } .",
    "\\label{eq : typei_opt_min_rate } \\end{aligned}\\ ] ]    [ rema : previous_formulas ] formulas and are established for the first time even when @xmath100 ( i.e. , @xmath101 ) .",
    "based on remark [ rema : type - iand - ii ] , formulas and lead to the general formulas for the type - ii achievable rate cost rates , which generalize formulas for the @xmath0-achievable rate with uniform cost @xmath100 given by @xcite and @xcite and the general formula for the achievable rate with regular cost @xmath32 and @xmath102 given by @xcite .",
    "_ proof of converse part : _",
    "we shall show the formula for @xmath103 .",
    "the formula for @xmath104 can be proven in a similar way .",
    "_ proof of direct part : _",
    "we shall show the formula for @xmath103 .",
    "the formula for @xmath104 can be proven in a similar way .",
    "now , we turn to discussing a relationship between the @xmath0-achievable cost rates under two different cost functions .",
    "although the following theorem is an immediate consequence of theorem [ theo : typei - epsilon - achievable - rate ] , we describe an alternative proof which leads to an observation on the structure of optimal codes with distinct cost functions ( cf .",
    "remark [ rema : dominant_set ] ) .",
    "[ theo : epsilon - achievable - relation ] let @xmath117 be regular cost functions and let @xmath23 and @xmath118 denote the unique solution of equation for each cost function .",
    "then , for every @xmath90 we have @xmath119    it suffices to show the following claims :    * if @xmath120 is type - i ( resp .",
    "type - ii ) @xmath0-achievable with cost @xmath32 , then @xmath121 is type - i ( resp .",
    "type - ii ) @xmath0-achievable with cost @xmath122 . *",
    "if @xmath120 is type - i ( resp .",
    "type - ii ) optimistically @xmath0-achievable with cost @xmath32 , then @xmath121 is type - i ( resp .",
    "type - ii ) optimistically @xmath0-achievable with cost @xmath122 .",
    "these claims may be proven by applying ( * ? ? ?",
    "* lemma 1 ) twice . here",
    ", we give a slightly more direct proof .    for a type - i @xmath0-achievable cost rate @xmath120 with cost @xmath32 , there exists a prefix code @xmath10 satisfying and . set @xmath123 by definition",
    ", we have @xmath124 . then , similarly to the derivation of , we have @xmath125 where we define @xmath126 we use a generalized version of shannon - fano - elias coding with costs ( cf .",
    "assume that the elements of @xmath58 are indexed as @xmath127 .",
    "we define @xmath128 for all @xmath129 , where @xmath130 for the cost function @xmath122 with @xmath131 , we also define @xmath132 where @xmath133 denotes the lexicographic order on the set @xmath134 .",
    "now , to each @xmath135 we assign @xmath136 as @xmath137 where @xmath138 is the set of @xmath37 such that @xmath139 includes @xmath140 but neither @xmath141 nor @xmath142 .",
    "then , it holds that @xmath143 and intervals @xmath144 are disjoint , implying that @xmath145 forms a prefix code .",
    "we arrange a new encoder @xmath146 as @xmath147 where @xmath84 denotes concatenation .",
    "the decoder @xmath148 is such that @xmath149 for all @xmath150 .",
    "therefore , the decoding error probability does not change and the code @xmath151 satisfies .",
    "now , for each @xmath152 , where @xmath153 , set @xmath154 .",
    "then , by definition , @xmath155 and @xmath156 or @xmath157 .",
    "this means that the width @xmath158 of the interval @xmath159 is larger than @xmath160 , so that @xmath161 we obtain @xmath162 then , we obtain @xmath163 where we have used and .",
    "thus , the proof of claim ( i ) is completed . claim ( ii )",
    "can be proven similarly .",
    "[ rema : dominant_set ] in the foregoing proof , a good @xmath31 code for cost @xmath122 is obtained from a good @xmath31 code for cost @xmath32 without changing the _ dominant set _",
    "@xmath58 , which is the set of source sequences that can be decoded without error .",
    "this means that for any two regular cost functions , the dominant set for a code that attains the infimum @xmath0-achievable cost rate with a cost function is also the dominant set for a code attaining the infimum @xmath0-achievable cost rate with the other cost function .",
    "we define the second - order achievable cost rates as follows :    for @xmath90 and @xmath91 , @xmath164 is said to be second - order _ type - i @xmath165-achievable with cost @xmath32 _ if there exists a sequence of @xmath31 codes satisfying @xmath166 the infimum of all type - i @xmath167-achievable cost rates with cost @xmath32 is denoted by @xmath168 .",
    "also , @xmath164 is said to be second - order _ type - i optimistically @xmath165-achievable with cost _",
    "@xmath32 if there exists a sequence of @xmath31 codes satisfying @xmath169 the infimum of all type - i optimistically @xmath167-achievable cost rates with cost @xmath32 is denoted by @xmath170 .",
    "[ rema:2nd_type - iand - ii ] similarly to the first - order cost rates , we can also define a right - continuous version of the infimum @xmath165-achievable rate ( called type - ii @xmath165-achievable cost rate ) , denoted by @xmath171 , by replacing with @xmath172 then , for @xmath1 we have @xmath173      we establish the second - order coding theorem , which is a counterpart of theorem [ theo : typei - epsilon - achievable - rate ] of the first - order .",
    "[ theo:2nd_typei - epsilon - achievable - rate ] for every @xmath90 and @xmath91 , any general source @xmath5 satisfies @xmath174 } ( x^n)}{\\alpha_c } - n r \\right ) , \\label{eq:2nd_typei_min_rate } \\\\ \\mathcal{l}_c^{(\\mathrm{i } ) * }   ( \\varepsilon , r| { \\boldsymbol x } ) & = \\liminf_{n \\rightarrow \\infty } \\frac{1 } { \\sqrt{n } } \\left(\\frac{h_{[\\varepsilon ] } ( x^n)}{\\alpha_c } - n r \\right ) .",
    "\\label{eq:2nd_typei_opt_min_rate } \\end{aligned}\\ ] ]    ( _ proof _ )  using the relation @xmath175 } ( x^n ) = \\limsup_{n \\rightarrow \\infty } \\frac{1 } { \\sqrt{n } } g_{[\\varepsilon ] } ( x^n),\\end{aligned}\\ ] ] we can prove the theorem similarly to theorem [ theo : typei - epsilon - achievable - rate ] .",
    "for the case where @xmath100 , we have the following immediate consequence of theorem [ theo:2nd_typei - epsilon - achievable - rate ] : for every @xmath90 and @xmath91 , any general source @xmath5 satisfies @xmath176 } ( x^n ) - n r ) .",
    "\\label{eq:2nd_typei_min_rate2}\\end{aligned}\\ ] ] thus , we have @xmath177 for any regular cost function @xmath32 .    in the case where @xmath100 and the source @xmath5 is stationary and memoryless with the finite third absolute moment of @xmath178 , kostina et al .",
    "@xcite has recently given a single - letter characterization of @xmath179 with @xmath180}({\\boldsymbol x})$ ] as @xmath181 where @xmath182 denotes the variance of @xmath178 ( varentropy ) and @xmath183 is the inverse of the complementary cumulative distribution function of the standard gaussian distribution .",
    "notice that @xmath180}({\\boldsymbol x } ) = ( 1-\\varepsilon)h(x)$ ] in this case @xcite , where @xmath184 is the entropy of the source .",
    "now , let us consider the case where the cost function is _ additive _ @xcite . in view of the relation , we can also obtain a single - letter characterization @xmath185 where the first - order cost rate is @xmath186}({\\boldsymbol x})/\\alpha_c$ ] . as is observed in @xcite ,",
    "it is of interest to see that the optimum second - order @xmath165-achievable cost rate is always negative , and allowing the decoding error up to @xmath0 is beneficial for both the first- and second - order cost rates .",
    "we shall prove ( i ) @xmath187}^ * ( { \\boldsymbol x})$ ] , ( ii ) @xmath44}^ * ( { \\boldsymbol x } ) \\le ( 1-\\delta ) \\overline{h}^*({\\boldsymbol x})$ ] , and ( iii ) @xmath44 } ( { \\boldsymbol x } ) \\le ( 1-\\delta ) \\overline{h}({\\boldsymbol x})$ ] because other inequalities are trivial .",
    "fix @xmath189 and @xmath190 arbitrarily . for all @xmath191 ,",
    "we choose a subset @xmath70 such that @xmath192}(x^n ) + \\eta .",
    "\\label{eq : set : an}\\end{aligned}\\ ] ] set @xmath193 then , for sufficiently large @xmath27 we have @xmath194 where the last inequality is due to the definition of @xmath195 .",
    "we obtain @xmath196 it follows from that @xmath197}^*({\\boldsymbol x } ) & \\ge \\liminf_{n \\rightarrow \\infty }   \\frac{1}{n } \\sum_{{\\boldsymbol x } \\in a_n } \\log \\frac{1}{p_{x^n}({\\boldsymbol x } ) } - \\eta \\nonumber \\\\ & \\ge   ( 1- \\delta - 2 \\gamma)(\\underline{h}({\\boldsymbol x } ) - \\eta ) - \\eta.\\end{aligned}\\ ] ] since @xmath198 is arbitrary , we obtain the inequality @xmath199}^ * ( { \\boldsymbol x})$ ] . by taking @xmath200 ,",
    "we have proven the inequality @xmath187}^ * ( { \\boldsymbol x})$ ] .",
    ":   set @xmath201 where @xmath67 is an arbitrary constant . in view of the equation @xmath202",
    "let @xmath203 denote an increasing sequence such that @xmath204 we fix any @xmath205 . for all @xmath206 ,",
    "we choose a subset @xmath207 such that @xmath208 notice that we can always choose such @xmath207 , for example , by successively inserting @xmath209 to @xmath210 in the decreasing order of @xmath211 and stop this procedure once is satisfied . from and we have @xmath212 on the other hand , fixing an arbitrary @xmath213 with @xmath214 and setting @xmath215 , we have @xmath216 where the second inequality is due to the definition of @xmath217 and the last inequality is due to and @xmath218 for @xmath219 $ ] .",
    "it follows from that @xmath220}(x^{n_i})\\le   \\frac{1}{n_i } \\sum_{{\\boldsymbol x } \\in b_{n_i } \\cap s_{n_i } } p_{x^{n_i}}({\\boldsymbol x } ) \\log \\frac{1}{p_{x^{n_i}}({\\boldsymbol x } ) } \\nonumber \\end{aligned}\\ ] ] and thus from that @xmath221}(x^{n_i } ) \\le    ( 1- \\delta')(\\overline{h}^*({\\boldsymbol x } ) + \\gamma ) + \\frac{\\log e}{n_ie } \\nonumber \\end{aligned}\\ ] ] for all @xmath222 , which leads to @xmath223}(x^{n } ) \\nonumber \\\\ & ~~\\le \\liminf_{i \\rightarrow \\infty } \\frac{1}{n_i } h_{[\\delta'+\\gamma]}(x^{n_i } ) \\le    ( 1- \\delta')(\\overline{h}^*({\\boldsymbol x } ) + \\gamma ) .",
    "\\nonumber \\end{aligned}\\ ] ] since @xmath224 is arbitrarily fixed and @xmath44}(x^{n})$ ] is a nonincreasing function of @xmath45 , letting @xmath225 , we obtain @xmath226}(x^{n } ) \\le    ( 1- \\delta')\\overline{h}^*({\\boldsymbol x } ) .",
    "\\label{eq : ineq0e}\\end{aligned}\\ ] ] since @xmath227 is arbitrarily fixed , inequality implies @xmath44}^ * ( { \\boldsymbol x } ) \\le ( 1-\\delta ) \\overline{h}^*({\\boldsymbol x})$ ] .",
    "\\(iii ) _ proof of @xmath44 } ( { \\boldsymbol x } ) \\le ( 1-\\delta ) \\overline{h}({\\boldsymbol x})$ ] _ :",
    "this is a slightly strengthened version of the inequality given in ( * ? ? ?",
    "* theorem 3 ) , which demonstrates @xmath228 } ( { \\boldsymbol x } ) \\le ( 1-\\delta ) \\overline{h}({\\boldsymbol x})$ ] . this inequality can be proven similarly to case ( ii ) ."
  ],
  "abstract_text": [
    "<S> we derive a general formula of the minimum achievable rate for fixed - to - variable length coding with a regular cost function by allowing the error probability up to a constant @xmath0 . for a fixed - to - variable length code </S>",
    "<S> , we call the set of source sequences that can be decoded without error the dominant set of source sequences . for any two regular cost functions </S>",
    "<S> , it is revealed that the dominant set of source sequences for a code attaining the minimum achievable rate with a cost function is also the dominant set for a code attaining the minimum achievable rate with the other cost function . </S>",
    "<S> we also give a general formula of the second - order minimum achievable rate . </S>"
  ]
}