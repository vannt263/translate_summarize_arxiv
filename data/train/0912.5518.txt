{
  "article_text": [
    "consider a two - players dice game in which players accumulate points by turns with the following rules .",
    "the player who reaches a certain fixed number of points is the winner of the game . in his turn",
    "each player rolls the dice several times until deciding to stop or rolling an ace . if he decides to stop the accumulated successive scores are added to his account ; while if he rolls an ace no additional points are obtained . as a first approach to find optimal strategies for this game",
    "roters @xcite studied the optimal stopping problem corresponding to the maximisation of the expected score in one turn .",
    "the optimal solution is a good way of minimising the number of turns required to reach the objective .",
    "later , roters & haigh @xcite found the strategy that minimises the expected number of turns required to reach the target . this second strategy is better than the one obtained in @xcite but none of them take into account the consideration of the number of points of the opponent , that is clearly relevant in order to win the game .    in this paper",
    "we formulate this game in the framework of competitive markov decision processes ( also known as _ stochastic games _ ) , show that the game has a value , provide an algorithm to compute the optimal minimax strategy , and present results of this algorithm in three different variants of the game .",
    "the concept of `` stochastic games '' was introduced in 1953 by shapley in @xcite . in the recent book by filar and vrieze @xcite ,",
    "the authors provide a general and modern comprehensive approach to this theory departing from the theory of _ controlled markov processes _ ( that can be considered `` solitaire '' stochastic games ) and call the type of games we are interested in _ competitive markov decision processes _ , a denomination that we find more accurate than the more usual denomination _ stochastic game_.    during the preparation of this paper we found the related article by neller and presser @xcite where the authors , following an heuristic approach , formulate the bellman equation of the problem ( that is a consequence of our results ) , and compute the optimal strategy of a variant of this game .",
    "it must be noted that the theory of filar and vrieze @xcite , that we follow , provide the solution of the problem in the set of all possible strategies , including non - stationary and randomised strategies , i.e. the set of behaviour strategies .",
    "in section 2 we present the theory of _ competitive markov decision processes _ , specially in the _ transient _ case and we conclude the section with the formulation of the theorem we need to solve our dice game . a proof of this theorem",
    "can essentially be found in @xcite . in section 3",
    "we determine the state space of our game , the corresponding action spaces for each player , the payoff function of the game , and the markov transitions depending on each state of the process and action of the players . in section 4",
    "we present two related games : first , in order to win , the player has to reach the target exactly ( if the target is exceeded , he gives the dice to his opponent without changing his accumulated score ) ; in the second variant the players aim to maximise the difference between their scores .",
    "in section 5 we present the conclusions .",
    "a _ competitive markov decision process _ ( also known as a _ stochastic game _ ) is the mathematical model of a sequential game , in which two players take actions considering the status of a certain markov processes .",
    "both actions determine an immediate payoff for each player and the probability distribution of the following state of the game .",
    "our interest is centred in two - players , finite - state and finite - action , zero - sum games . to define them",
    "formally we need the following ingredients :    * states : a finite set @xmath0 of the possible states of the game .",
    "* actions : for each state @xmath1 we consider finite sets @xmath2 and @xmath3 whose elements are the possible actions for the players ; at each step both players take his actions simultaneously and independently . *",
    "payoffs : for each state @xmath1 a function @xmath4 determines the amount that player two has to pay to player one depending on the actions taken by both players . * transition probabilities : for each @xmath5 , @xmath6 is a distribution probability on @xmath0 , which determines the following state of game .",
    "we denote by @xmath7 the state of the game at time @xmath8 ; the initial state is fixed @xmath9 . at each step",
    "@xmath10 players choose actions @xmath11 and @xmath12 in @xmath13 @xmath14 respectively , which determine that player two has to pay to player one an amount of @xmath15 and the distribution probability of @xmath16 will be @xmath17 .",
    "the random variable @xmath18 is the total amount that player two pays to player one ( could be negative ) .",
    "note that @xmath19 depends on the way in which players take their actions .",
    "the objective of the game for player one is to maximise the expected value @xmath20 of the accumulated payoff @xmath19 , while player two has the objective of minimising it . in principle",
    "@xmath20 could be infinite .",
    "often for economic applications the accumulated payoff is @xmath21 , called `` the discounted sum '' , where @xmath22 represent the devaluation of the money .",
    "this discount factor @xmath23 ensures that @xmath19 is finite with probability one and the existence of its expected value .",
    "in the case of _ transient _ stochastic games , the situation considered in this paper , the sum defining @xmath19 is finite a.s . due to the fact that the process always reaches a final state @xmath24 in a ( not necessarily bounded ) finite number of steps . in the definition of transient stochastic game additional conditions are required , in order to @xmath20 to be finite . before the formal definition of transient stochastic games , the concept of behaviour strategy",
    "is introduced .",
    "consider the set @xmath25 defined by @xmath26 we define , for each @xmath8 , the sets @xmath27 , of admissible histories up to time @xmath10 , by    @xmath28    given a stochastic game , a _ behaviour strategy _ for player one ( two ) in the game is a function @xmath29 which associates to each history @xmath30 a distribution probability @xmath31 in @xmath2 ( respectively @xmath32 in @xmath3 ) .",
    "in the context of a stochastic game , we denote by @xmath33 ( @xmath34 ) , the set of all behaviour strategies for player one ( two ) .",
    "note that the previous definition is in agreement with the intuitive idea that a player can choose his action based on the history of the game .",
    "there are two relevant subclasses of strategies , _ pure _ and _ stationary _ , introduced below .",
    "a behaviour strategy @xmath29 is said to be _ pure _ , if for each history @xmath35 there exists an action @xmath36 such as @xmath37 .",
    "we could say that a pure strategy chooses the action to be taken in a deterministic way .",
    "a behaviour strategy @xmath29 is said to be _ stationary _ , if the probability distribution @xmath31 depends only on @xmath38 , the last state of the history . in this case",
    "we use the notation @xmath39 .",
    "we now construct the probability space in which the optimisation procedure takes place .",
    "consider the product space @xmath40 equipped with the product @xmath41-algebra @xmath42 , defined as the minimal @xmath41-algebra containing the cylinder sets of @xmath43 .",
    "given @xmath44 , a sequence of states and actions in the product space , the coordinate processes @xmath45 are defined by @xmath46    in this framework , given @xmath29 , @xmath47 behaviour strategies for players one and two and an initial state @xmath48 , it is possible to introduce a probability @xmath49 , such that , for the random vector @xmath50 and the finite sequence of states and actions @xmath51 the following assertions hold :    * the game starts in the state @xmath38 , i.e. , @xmath52 * with probability 1 , @xmath53 take their values in @xmath27 ; * the probability distribution on the actions chosen by players at time @xmath10 depends on @xmath53 , according to @xmath54 @xmath55 @xmath56 * the distribution probability of @xmath16 depends only on @xmath57 , being the transition probabilities ( tp ) of the game @xmath58    we denote by @xmath59 the expected value in the probability space @xmath60      [ deftransient ] a stochastic game is _ transient _ when there exists a final state @xmath24 such that :    1 .",
    "@xmath61 2 .",
    "@xmath62 3 .",
    "for all pair of strategies @xmath63 of player one and two respectively and for all initial state @xmath38 @xmath64    conditions ( 1 ) and ( 2 ) ensure that , once the game falls into the final state @xmath65 , it never changes the state again and the gain of both players is zero .",
    "the third condition ensures that the game finishes with probability one .",
    "given @xmath66 , strategies for players one and two in a transient stochastic game , the value of the strategies is a function @xmath67 defined by @xmath68    a behaviour strategy @xmath69 for player one in a transient stochastic game is said to be optimal if @xmath70 analogously a behaviour strategy @xmath71 for player two , is said to be optimal if @xmath72    we now formulate the result used to solve our dice game .",
    "[ thmoptimal ] given a transient stochastic game the following identity is fulfilled @xmath73 the vector defined in , denoted by @xmath74 , is called the _ value of the game_. this value is the unique joint solution of @xmath75^*_{a\\in a^s , b\\in b^s},\\ ] ] where @xmath76^*$ ] represents the value of the matrix game ( in the minimax sense ) obtained by considering rows @xmath77 and columns @xmath78 .",
    "moreover , the stationary strategies @xmath29 and @xmath47 for players one and two , such that @xmath39 and @xmath79 are the optimal strategies of the matrix game @xmath80_{a\\in a^s , b\\in b^s}\\ ] ] for all state @xmath48 , are optimal strategies in the transient stochastic game .",
    "this theorem is essentially a particular case of theorem 4.2.6 in @xcite .",
    "a detailed proof can be found at @xcite .",
    "the previous theorem ensures the existence of optimal strategies for both players .",
    "particularly they are in the subclass of stationary strategies . in the proof of this theorem",
    "a map @xmath81 such that @xmath82^*_{a\\in a^s , b\\in b^s } , \\label{eq1}\\ ] ] which is a @xmath83-step contraction , is considered .",
    "afterwards , we used the map @xmath81 to implement a numerical method to find a unique fixed point , that is the value of the game .",
    "in this section we describe the states , actions , payoffs , and transition probabilities ( defined in section 2 ) corresponding to our dice game , and present the numerical results , showing the optimal strategy for a player .",
    "this strategy , optimal in the class of behaviour strategies , ensures a player to win with probability of at least 1/2 independently of the opponent strategy .",
    "the optimal strategy is pure and stationary , and consists in a simple rule indicating whether _ to roll _ or _ to stop _ , depending on the scores of the player and its opponent .      to solve the dice game ( compute optimal strategies ) , we model it as a transient stochastic game . we have to specify the set of states , possible actions , payoffs and transition probabilities .",
    "* states : during the dice game , there are four aspect varying : the player @xmath84 who has the dice @xmath85 , the accumulated score @xmath86 of player one , the accumulated score @xmath23 of player two and the turn score @xmath87 of the player @xmath84 .",
    "so , we consider states @xmath88 .",
    "we also need to consider two special states : an initial state @xmath89 , and a final state @xmath65 .",
    "+ if the score of either of the players is greater or equal than @xmath90 the game is over , then , it is in the state @xmath65 . because of that , states @xmath88 , only make sense if @xmath91 , @xmath92 . the same happen if @xmath87 is big enough to reach @xmath90 stopping .",
    "so the finite set @xmath0 of possible states is @xmath93 where @xmath94 is the set of states of the player one : @xmath95 and @xmath96 is the set of states of the player two : @xmath97 * actions : we have to specify the set of actions per state for each player .",
    "possible actions in this game are _ to roll _ and _ to stop_. we add an extra action _ to wait _ , which represents that is not the turn of the player",
    ". there are some constraints to ensure the transient condition of the stochastic game : in the states @xmath98 does not make sense for player one to take the action _ to stop _ because there s nothing to loose .",
    "if in our model we permit taking the action _ to stop _ with 0 points in the turn @xmath99 , is easy to see that there exist a pair of strategies that make the game infinite .",
    "the same happen if the action _ to roll _ is possible when stopping is enough to win .",
    "the table [ tabla ] shows the set of possible actions per state .",
    "+ .possible actions for each player depending on the state of the game.[tabla ] [ cols=\"<,^,^\",options=\"header \" , ]    * payoffs : because we want to maximise the probability of winning , we define the payoff function in such a way that maximising the probability of winning is equivalent to maximising the expected value @xmath20 of the payoffs accumulated along the game .",
    "the model of transient stochastic game allow us to define a payoff for each pair @xmath100 but in this case is enough to define the payoff depending only on the state as follows : @xmath101 * transition probabilities : to represent graphically the transition probabilities we use the following representation for the states : @xmath102[f]{\\alpha^\\tau_\\beta } } \\qquad ( 2,\\alpha,\\beta,\\tau ) = \\xymatrix{*+[f]{\\beta^\\tau_\\alpha}}.\\ ] ] the dynamic of the game and the semantic of the states determine transition probabilities between states . in the figure [ figtrans ] ,",
    "the probability transitions from a state @xmath103 with @xmath104 , depending on the player decision are presented .",
    "+ + @xmath105[f]{\\alpha^\\tau_\\beta } \\ar[drr]^{\\frac{1}{6 } } \\ar[dl]_{\\frac{1}{6 } } \\ar[ddrr]^{\\frac{1}{6 } } \\ar[ddl]^{\\frac{1}{6 } }     \\ar[dd]^{\\frac{1}{6 } } \\ar[ddr]^{\\frac{1}{6 } } & & \\\\      * + + [ f]{\\beta^0_\\alpha } & & &   * + + [ o][f]{\\alpha^{\\tau+2}_\\beta } \\\\      * + + [ o][f]{\\alpha^{\\tau+3}_\\beta } & * + + [ o][f]{\\alpha^{\\tau+4}_\\beta } & * + + [ o][f]{\\alpha^{t+5}_\\beta } & * + + [ o][f]{\\alpha^{\\tau+6}_\\beta } } $ ] @xmath106[f]{\\alpha^\\tau_\\beta } \\ar[dd]^1\\\\      \\\\      * + [ f]{\\beta^0_{\\alpha+\\tau } } } $ ] + figure [ figtrans ] shows that , when the decision is _ to roll _ , the distribution probability on the states is associated with the results of rolling a dice ; particularly the probability of loosing the turn is 1/6 . in the winning states of player one ( i.e. @xmath103 with @xmath107 ) the transition is , with probability one , to the final state ( @xmath65 ) .",
    "transitions for player two are completely symmetric . as is showed in figure [ figtransfinal ] in the special states @xmath108 and @xmath65 transitions do not depend on the actions taken by players , indeed they do not have options .",
    "+ @xmath109[f]{s_i } \\ar[dl]^{\\frac{1}{2 } } \\ar[dr]_{\\frac{1}{2 } } & \\\\      * + [ f]{0 ^ 0_0 } & &   * + + [ o][f]{0 ^ 0_0 } } $ ] @xmath110[f]{s_f } \\ar@(d , r)_{1 } } $ ]    now we verify that the stochastic game defined above is transient .",
    "we then prove that @xmath65 satisfies conditions ( 1 ) , ( 2 ) and ( 3 ) in definition [ deftransient ] .",
    "conditions ( 1 ) and ( 2 ) are trivially fulfilled , it remains to verify that @xmath111 for all initial state @xmath38 , and every pair of strategies @xmath29 , @xmath47 . due to the fact that at the beginning of a turn the only option is _ to roll _ , and that in a state in which the accumulated score is enough to win the player has _ to stop _ , the game can not continue indefinitely .    for example , if a 6 is rolled consecutively 70 times it is impossible to avoid reaching the final state . denoting by @xmath112 the probability of rolling 70 times a 6 , i.e. @xmath113 , it is easy to see that @xmath112 is a lower bound for the probability of @xmath114 for @xmath115 . by a similar argument , it follows that , for @xmath116 @xmath117 then @xmath118 and our model is transient .      in this section",
    "the results of the theorem [ thmoptimal ] are applied to the particular case of the transient stochastic game defined above . rewriting the definition of application @xmath81 , defined in equation ,",
    "we obtain :    @xmath119    where @xmath120 note that in the equations above we have replaced the value of the matrix games in equation by a maximum , in the states in which player one has to take the decision , and by a minimum when is player two the one that has to do it . in the states in which both players have only one choice the value of the matrix game is the only entry of the matrix . since there are no states in which both players have to decide simultaneously , the stationary strategy that emerges from the theorem turns out to be pure , i.e. each player takes an action with probability 1 . to determine the complete solution is necessary to specify",
    "which action should be taken in about @xmath121 states . in figure",
    "[ optima ] the optimal strategy for player one for some states is shown .",
    "the complete solution can be found at    ` www.cmat.edu.uy/cmat/docentes/fabian/documentos/optimalstrategy.pdf ` .",
    "\\\\    \\beta=180&\\beta=185\\\\ \\includegraphics[scale=0.32]{codicia_oponente_180.png}&\\includegraphics[scale=0.32]{codicia_oponente_185.png } \\end{array } $ ]    * some observations about the solution : *    * at the beginning of the game , when both players have low scores , we see that the optimal action is _ to roll _ when @xmath123 and _ to stop _ in the other case , following the strategy found by roters @xcite maximising the expected value of a turn score .",
    "+ the heuristic interpretation of this fact is : when far away from the target it is optimal to approach it in steps as large as possible .",
    "* when the opponent score @xmath23 becomes larger the optimal strategy becomes riskier .",
    "this can be explained because there are less turns to reach the target . * for opponent scores greater or equal than 187 @xmath124 ,",
    "the graphic becomes absolutely gray .",
    "in other words , when the opponent is close to win , giving him the dice is a bad idea . * to compare the optimal strategy with the one found by haigh & roters @xcite",
    ", we simulate @xmath125 games .",
    "our simulation showed that in @xmath126 of the games , the winner was the player with the optimal strategy .",
    "it is interesting to explore how the optimal strategy changes when the game is modified . in this section",
    "we consider the same dice game , with the only difference being that the condition to win is to reach exactly 200 points . if the sum of accumulated and turn score is greater than 200 the turn finishes without capitalising any point .",
    "the formulation of the game is quite similar , the difference appears when the accumulated score plus the turn score is greater that 194 , situation in which one roll of the dice can exceed the target . as an example of the mentioned difference , in figure [ figrebote ] we show",
    "the transition probabilities when the accumulated score is 180 and the turn score is 16 ( @xmath127 ) .",
    "@xmath128[f]{180^{16}_\\beta } \\ar[ddl]_{\\frac{3}{6 } } \\ar[dd]_{\\frac{1}{6 } } \\ar[ddr]_{\\frac{1}{6 } } \\ar[ddrr]^{\\frac{1}{6 } } & & \\\\       \\\\      * + + [ f]{\\beta^0_{180 } } & * + + + [ o][f]{180^{18}_\\beta } & * + + + [ o][f]{180^{19}_\\beta }   & * + + + [ o][f]{180^{20}_\\beta } & \\\\ \\\\ } $ ]    note that the probability of losing the turn is the probability of rolling a 1,5,6 . in figure [ rebote ]",
    "part of the optimal strategy for this variant of the game is shown .",
    "the complete optimal strategy is available in ` www.cmat.edu.uy/cmat/docentes/fabian/documentos/optimalexactly.pdf ` .",
    "@xmath122{rebote_oponente_0.png}&\\includegraphics[scale=0.32]{rebote_oponente_150.png}\\\\ \\\\    \\beta=180&\\beta=198\\\\ \\includegraphics[scale=0.32]{rebote_oponente_180.png}&\\includegraphics[scale=0.32]{rebote_oponente_198.png } \\end{array } $ ]    * some remarks about the solution : *    * as in the classical game , when the target is far , the strategy is similar to `` stop if @xmath129 '' .",
    "* unlike the classical game , the optimal strategy in this case never becomes so risky .",
    "this is easy to understand because the probability of winning in any turn is less or equal than @xmath130 , even in the case of being very close to the target .",
    "* when @xmath131 there is a `` roll zone '' larger than usual , because 194 is the largest score in which there is no risk of losing in one roll but it is possible to win rolling a 6 .      in the second variant of the game ,",
    "the winner , when reaching the target , obtains from the loser the difference between the target and the loser s score .",
    "again , the model of the game is very similar to the classical model , the only difference is the payoff function : @xmath132 figure [ maxdif ] shows the optimal strategy for some opponent scores .",
    "the complete optimal strategy can be found at + ` www.cmat.edu.uy/cmat/docentes/fabian/documentos/optimalmaxdif.pdf ` .",
    "+ the main difference with the optimal strategy in the classical case , is that when one player is close to win ( taking into account his current turn score ) , he takes the risk of rolling , this feature being observed for any score of the opponent .",
    "\\\\ \\beta=170&\\beta=180\\\\ \\includegraphics[scale=0.32]{maxdif_oponente_170.png}&\\includegraphics[scale=0.32]{maxdif_oponente_180.png } \\end{array } $ ]",
    "in this paper we model a dice game in the framework of markov competitive decision processes ( also known as _ stochastic games _ ) in order to obtain optimal strategies for a player .",
    "our main results are the proof of the existence of a value and an optimal minimax strategy for the game , and the proposal of an algorithm to find this strategy .",
    "we base our results on the theory of transient stochastic games exposed by filar and vrieze in @xcite .",
    "previous mathematical treatments of this problem include the solution of the optimal stopping problem for a player that wants to maximise the expected number of points in a single turn ( see roters @xcite ) and the minimisation of the expected number of turns required to reach a target ( see haigh and roters and @xcite ) .",
    "another previous contribution was done by neller and presser @xcite , who found the optimal strategy in the set of stationary pure strategies , departing from a bellman equation .",
    "we also provide an algorithm to compute explicitly this optimal strategy ( that coincides with the optimal strategy in the larger class of behaviour strategies ) and show how this algorithm works in three different variants of the game .",
    "this work was partially supported by antel - fundaciba agreement `` anlisis de algoritmos de codificacin y cifrado ''"
  ],
  "abstract_text": [
    "<S> each of two players , by turns , rolls a dice several times accumulating the successive scores until he decides to stop , or he rolls an ace . </S>",
    "<S> when stopping , the accumulated turn score is added to the player account and the dice is given to his opponent . </S>",
    "<S> if he rolls an ace , the dice is given to the opponent without adding any point . </S>",
    "<S> in this paper we formulate this game in the framework of competitive markov decision processes ( also known as _ stochastic games _ ) , show that the game has a value , provide an algorithm to compute the optimal minimax strategy , and present results of this algorithm in three different variants of the game .    </S>",
    "<S> * keywords : * competitive markov processes , stochastic games , dice games , minimax strategy .    </S>",
    "<S> * ams msc : * 60j10 , 60g40 , 91a15 </S>"
  ]
}