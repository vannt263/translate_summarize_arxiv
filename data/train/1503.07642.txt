{
  "article_text": [
    "the most common regression models for analysing ordinal data fall under the set of cumulative link models , in which the categories of the response variable can be modelled as contiguous intervals on some continuous scale  @xcite . a general monotonic increasing link function",
    "is then used to map these intervals from the continuous scale onto the interval @xmath0 .",
    "the choice of link function will generally lead to qualitatively similar model fits , and so can be chosen on the basis of interpretability  @xcite or convenient mathematical properties ( e.g.  @xcite ) . to this end",
    "we concentrate on the logistic link , leading to comparisons of the cumulative odds .",
    "a popular implementation assumes that the relationship between the cumulative log - odds and the explanatory variables does not depend on the response category ( the _ proportional odds _ [ po ] model@xcite ) . under simple constraints ,",
    "this implementation guarantees that the model exhibits _",
    "stochastic ordering _",
    "( i.e. it ensures that for @xmath1 ordered groups , the cumulative probability of belonging to group @xmath2 is less than or equal to the cumulative probability of belonging to group @xmath3 , for @xmath4 ) . as a direct result of its simplicity and ease - of - interpretation ,",
    "the po model is commonly used in the literature .",
    "an alternative is to allow the relationship between the response and explanatory variables to vary by response category ( the _ non - proportional odds _ [ npo ] model ) .",
    "whilst more flexible than the po model , the use of npo models in the literature is limited , since the stochastic ordering conditions will only hold for a limited range of values of the explanatory variables @xcite .",
    "this means that many traditional fitting mechanisms can fail to fit  @xcite , and in the case where the po assumption fails to hold , it may be difficult to find estimates for the general npo model .",
    "a useful alternative is to fit a set of @xmath5 separate binary logistic regression models to each cumulative logit separately  @xcite , however , the parameter estimates for the regression parameters do not always correspond to those obtained from the general model  @xcite .",
    "the _ partial proportional odds _",
    "( ppo ) model  @xcite allows for a mixture of po and npo variables to be included , though the structure for each variable must be specified in advance .",
    "various approaches have been developed as a means of assessing whether the po assumption is appropriate for a set of given variables ( see e.g.  @xcite ) , but these are difficult to apply to large numbers of variables , particularly if there are interactions between some of them that may impact the relationship .",
    "another alternative approach  when the response variable is such that to belong to a particular category it is necessary to pass through all previous categories in turn  is to use continuation ratios  @xcite .",
    "good reviews of general ordinal regression frameworks can be found in  @xcite and  @xcite .",
    "the motivating example for this paper is a longitudinal , individual animal - level study of risk factors associated with body condition score in a population of dogs .",
    "these data form part of a wider study to examine the impact of immunological and demographic factors on canine rabies vaccination coverage , which covered four locations : braamfischerville and zenzele in gauteng province , south africa ; and antiga and kelusa in bali province , indonesia .",
    "full details of the wider study , and a comprehensive analysis of all the data collected from each of the sites is provided in  @xcite .    to illustrate the requirement and performance of the methodology",
    ", we focus attention on one particular data set from zenzele . full details of these data are given in section  [ sec : app ] .",
    "the response variable is body condition score ( bcs)defined on a scale from 19 where a score of 1 is highly underweight , 5 is healthy , and 9 is highly overweight . as such it seems sensible to consider using cumulative link models .",
    "there are various challenges with modelling this system , and we expand on each point in the subsequent discussion :    1 .",
    "we wish to perform variable selection , in order to assess the relative impact and importance of a series of potential risk factors on bcs .",
    "the data are longitudinal , and so it is necessary to account for clustering due to repeated measurements on individual animals .",
    "we wish to assess the weight - of - evidence for po versus npo structures for each of the variables .",
    "this information is useful in helping to build up a picture ( along with other indirect sources of evidence ",
    "see  @xcite ) of the environmental processes driving canine demography in these regions ( see section  [ sec : app ] for a more detailed discussion of this point).[item3 ] 4 .   in order to tackle point  [ item3 ] , it is necessary to overcome some of the challenges regarding the fitting of npo models when the stochastic ordering conditions may not hold .    in a classical statistical framework",
    ", model choice is usually performed using some form of model comparison criteria , such as akaike s information criterion ( aic ;  @xcite ) , or likelihood ratio testing .",
    "these procedures use information from a single point estimate of the parameters , @xmath6 , and neglect the uncertainty in @xmath7 .",
    "in addition , inference is made conditionally on the selected model , and does not incorporate uncertainty in the choice of model .",
    "this can be important in cases where explanatory variables show consistent evidence of an effect across a range of models , but is not selected in the ` final ' model ( see e.g.  @xcite ) .",
    "here we propose to use a bayesian framework , and implement model selection using posterior probabilities of association ( see e.g.  @xcite ) .",
    "this has the advantage that it allows us to assess the weight - of - evidence in favour of a given model , and also allows us to assess the evidence for a particular variable being associated with the response after averaging across all possible models .",
    "this is particularly important to this study , since we also wish to assess the conditional evidence of a po or npo structure for the relationship between an explanatory variable and the response , given that an association exists .",
    "a common method to account for clustering due to repeated measurements is to use mixed effects models ( see e.g.  @xcite ) , in which the error term is split into different components in order to model the variance - covariance structure at different hierarchies ( @xcite ) .",
    "these techniques are well characterised in the literature , though there is some debate about how to perform model selection in the presence of random effects in a classical setting ( see e.g.  @xcite ) . in the bayesian",
    "setting , all parameters are considered random variables , and it is straightforward to incorporate _ a priori _ clustering into the prior .",
    "the model choice problem then remains the same , as the parameters are simply integrated over when estimating the posterior probabilities of association .",
    "the literature surrounding the development of ordinal regression frameworks is large and varied , applied in a wide range of fields .",
    "focussing on bayesian models ; probit link functions are frequently used ( e.g.  @xcite ) and there are various recent developments in modelling the link function using mixture distributions ( e.g.  @xcite ) .",
    "different fitting mechanisms have also been developed , including markov chain monte carlo ( mcmc@xcite ) , laplace approximations ( e.g. @xcite ;  @xcite ) and expectation - propagation algorithms ( @xcite ) .",
    "@xcite develop efficient mcmc samplers for logistic multinomial regression models , and  @xcite develop a multivariate logistic regression framework that provides a marginal logistic structure for each of the outcomes .",
    "some work has also been done on model selection using probit models ( e.g.  @xcite ) , and  @xcite extend a po model to account for interobserver measurement error .",
    "this list is by no means exhaustive , but as far as we are aware no method has been developed that accounts for all four of the challenges we highlighted earlier within the same framework .",
    "this manuscript is an attempt to provide an alternative approach for fitting logistic regression models , which allows both po and npo structures to be used ( and provides a model - driven means of assessing which structure is most relevant for each variable in the presence of other variables ) , and which can be extended to deal with repeated or clustered measurements , as well as variable selection .",
    "the first challenge we address is to provide a framework in which the stochastic ordering conditions can be made to hold for any given data set .",
    "this provides a means to explore the fitting of npo models to any data set , and facilitates the development of a more general approach in which the relationship between the response and explanatory variables ( e.g. po or npo ) can be allowed to vary according to the data .",
    "the latter is our second contribution , and is useful because often we do not know which explanatory variables are best modelled using po or npo structures in advance , particularly when there are a large number of variables . to this end ,",
    "@xcite propose a method that switches between the po , ppo and npo models , fitting the model via a penalised likelihood approach .",
    "however , in this case we also would like to produce an estimate of the support under the data for these competing structures for each of the variables , which can provide some indirect evidence regarding the mechanisms at play in the underlying system . although the po model could be viewed as a special case of the npo model , the nave use of a straight npo model could result in overfitting .",
    "the challenge with comparing po and npo structures is that the dimensionality of the system is different in each case ( a single regression parameter for the po model corresponds to @xmath5 parameters for the npo model ) .",
    "to deal with this issue we use reversible - jump markov chain monte carlo ( rj - mcmc@xcite ) to fit the model , and bayesian model averaging ( bma  e.g .",
    "@xcite ) to produce posterior probabilities of association ( ppas ) for the support under the prior and the data for the choice of po or npo structure , averaged across the set of possible models .",
    "finally we extend these ideas to incorporate variable selection ( see e.g.  @xcite ) .",
    "note that an implementation of model choice based on bayes factors for ordinal regression models was developed in  @xcite , though each competing model needs to be fitted separately in order to be compared  @xcite . here",
    "we integrate across the competing models in one framework , which is likely to be much more efficient when searching across a large model space .",
    "an alternative bayesian rj - mcmc approach to model choice for ordinal probit models is developed in  @xcite .    in section  [ sec : bayes ]",
    "we discuss the bayesian paradigm and ( rj-)mcmc . in section  [ sec : cumlink ] we introduce the general cumulative link model , and more specifically the po , npo and ppo models .",
    "in section  [ sec : npo ] we discuss how the bayesian framework can be used to ensure stochastic ordering for specified variable ranges , and we justify this approach in practice in section  [ sec : criteria ] .",
    "the specific rj - mcmc sampler for this ordinal model choice problem is described in section  [ sec : rj ] .",
    "we then apply these methods to both simulated data , as well as data from a longitudinal study of individual - level risk factors affecting body condition score in a dog population in zenzele , south africa ( section  [ sec : app ] ) .",
    "we conclude with a discussion ( section  [ sec : dis ] ) .",
    "all of the models described in this paper will be formulated in a bayesian framework , and fitted using markov chain monte carlo ( mcmc ) .",
    "we assume that readers are familiar with the bayesian framework , but otherwise they are referred to various excellent texts available , such as  @xcite and  @xcite . the model fitting algorithms described in this manuscript are specifically variations of the metropolis - hastings ( m - h ) algorithm  @xcite .",
    "reversible - jump mcmc  @xcite is an extension to the classic m - h routine that allows the markov chain to jump between models with different dimensionality .",
    "again , we do not discuss the full details of rj - mcmc here , but for good introductions to the method the reader is referred to papers by  @xcite and  @xcite .",
    "assume that we have @xmath8 competing models to choose between .",
    "we can formulate the bayesian model choice problem as one of estimating the posterior probability that a model ( @xmath9 ) is true , given the choice of competing models ( @xmath10 ) .",
    "formally , this quantity is defined as @xmath11 with @xmath12 the _ prior _ probability of association for model @xmath9 , and @xmath13 the _ integrated likelihood _ ; where @xmath14 is the data , and @xmath15 is the ( multidimensional ) parameter space for the unknown parameters @xmath16 corresponding to model @xmath9 . the quantity ( [ eq : ppa ] ) is sometimes referred to as the _ posterior probability of association _ ( ppa ) .",
    "these ideas for bayesian model choice go back originally to  @xcite , and for a detailed introduction see  @xcite and  @xcite .    to implement model choice in an rj - mcmc framework , let @xmath17 be the model indicator at a given iteration ( i.e. the chain is in model @xmath18 ) , then let @xmath19 denote the probability that a jump from @xmath18 to @xmath20 is proposed .",
    "in order to jump between models of differing dimensionality , the parameters @xmath21 are mapped to a set of parameters @xmath22 via the inclusion of a set of dummy parameters , @xmath23 and @xmath24 , that are chosen to ensure that @xmath25 .",
    "once these dummy parameters are chosen , @xmath26 is mapped to @xmath27 through a deterministic bijective function @xmath28 , such that @xmath29 , and the reverse move is @xmath30 .",
    "the acceptance probability of the move is then given by : @xmath31,\\end{aligned}\\ ] ] where @xmath32 is the proposal density for the dummy parameters @xmath23 , and likewise for @xmath33 .",
    "the final quantity in ( [ eq : rjacc ] ) is the absolute value of the determinant of the jacobian matrix .",
    "one advantage of using rj methodology is that for a well - mixing model , the ppa defined in ( [ eq : ppa ] ) for a model @xmath9 can be simply estimated as the proportion of time that the chain spends in model @xmath34 . in section  [ sec : rj ]",
    "we show how this routine can be implemented for variable selection , as well as choosing between po and npo structures for individual variables . for other applications of rj - mcmc in bayesian model choice",
    "see e.g.  @xcite and  @xcite .",
    "let @xmath35 be a set of counts of individuals in @xmath36 _ ordered _ categories , which can be modelled as @xmath37 where @xmath38 is the number of individuals , and @xmath39 correspond to the probabilities of each individual being in any given category @xmath2 ( such that @xmath40 ) .",
    "if we have a set of @xmath41 explanatory variables , @xmath42 , associated with subset @xmath43 of the @xmath38 individuals ( where @xmath44 , such that @xmath45 ) , then @xmath46 where @xmath47 and @xmath48 . for a fully individual - based model then @xmath49 and @xmath50 for all @xmath43 . letting @xmath51 correspond to the category that an individual @xmath43 belongs to ( such that @xmath51 takes values @xmath52 ) , then following  @xcite , we can model the cumulative probabilities , @xmath53 through a monotonic increasing _ link _ function @xmath54 , mapping the interval @xmath55 , as @xmath56 where @xmath57 is a linear regression term , and @xmath58 is a vector of @xmath59 regression parameters . in this framework",
    "the @xmath60 parameters correspond to a set of latent continuous ` cut - points ' , such that @xmath61 .",
    "for identifiability we set @xmath62 .",
    "the probabilities of category membership are then given by @xmath63 in ( [ eq : link ] ) , the effect of the explanatory variables is independent of the grouping , and so regardless of the choice of link function the models display _ strict stochastic ordering _  @xcite .",
    "this means that subject to the constraint @xmath61 , the cumulative probabilities will be such that @xmath64 .",
    "a more general model would allow the effect of the covariates to vary between the groups , such that @xmath65 in this case the models are only stochastically ordered for certain ranges of explanatory variables ( see e.g.  @xcite ) .",
    "we discuss both forms of these models in detail for the case of the logistic - link function , but also extend the discussion to more general cases .",
    "a common form for the link function is the _",
    "logistic _ link : @xmath66 this is known as the _ proportional odds _ ( po )",
    "model  @xcite , so - called because the cumulative log - odds ratio for two sets of explanatory variables , @xmath67 and @xmath68 is given by @xmath69 hence the cumulative log - odds ratio is proportional to the distance between @xmath67 and @xmath68 ( see also  @xcite ) .    in the case of the po model ( [ eq : propodds ] ) , the @xmath7 and @xmath70 parameters are _ a priori _ independent , and so the joint prior distribution can be written as @xmath71 , where we let @xmath72 where @xmath73 is defined in @xmath74 , and @xmath75 is defined in the range @xmath76 for @xmath77 ( see also  @xcite ) .",
    "this ensures stochastic ordering for any values of @xmath70 .",
    "we let @xmath78 , @xmath79 ( for @xmath80 ) and @xmath81 where @xmath82 signifies that the distribution is truncated in the region @xmath83 ( i.e. it is a _ lower - truncated _ normal distribution ) with @xmath84 .",
    "other alternative choices for the prior distributions include doubly - truncated normals  @xcite , an ordered uniform distribution  @xcite , or a re - parameterisation which maps the constrained variables @xmath7 to a set of unconstrained variables , @xmath85 , which can be given , for example , a multivariate normal prior  @xcite .",
    "we choose normal random walk proposal distributions for each @xmath86 , such that @xmath87 where @xmath88 is the proposal variance . for the cut - point parameters , @xmath60 , we choose truncated uniform random - walk proposals , such that @xmath89\\right ) & \\mbox{if $ j=1$},\\\\[6pt ]              u\\left(\\max\\left[\\theta_j^{(i)}-\\tau_{\\theta},\\theta_{j-1}^{(i)}\\right],\\min\\left[\\theta_j^{(i)}+\\tau_{\\theta},\\theta_{j+1}^{(i)}\\right]\\right ) & \\mbox{if $ j=2,\\dots , j-2$},\\\\[6pt ]              u\\left(\\max\\left[\\theta_j^{(i)}-\\tau_{\\theta},\\theta_{j-1}^{(i)}\\right],\\theta_j^{(i)}+\\tau_{\\theta}\\right ) & \\mbox{if $ j = j-1$},\\\\              \\end{array }              \\right.\\ ] ] where @xmath90 controls the size of the maximum unconstrained move away from the current value at each iteration .",
    "the non - proportional odds ( npo ) model is specified as @xmath91 in this case the regression parameters are allowed to vary with category level , such that @xmath92 ( see e.g.  @xcite ) .",
    "the key challenge is that in order for stochastic ordering to hold , it is necessary that @xmath93 for all @xmath94 . for identifiability",
    "we set each of the intercept parameters @xmath95 .",
    "if we have @xmath41 explanatory variables , then after expanding out the regression in the stochastic ordering constraints ( [ eq : stochorder ] ) , for any @xmath96 , we have that @xmath97 which must hold for any value of @xmath98 .    in the first instance , assume that we have a lower and upper bound for the possible values of @xmath98 , such as would be the case if @xmath98 were categorical .",
    "denote the minimum and maximum values of @xmath98 as @xmath99 and @xmath100 respectively .",
    "the condition ( [ eq : nonpocond ] ) then becomes @xmath101x_k^m,\\left[\\beta_{kj } - \\beta_{k(j+1)}\\right]x_k^m \\right).\\ ] ] for brevity , let @xmath102~\\mbox{and}~c_j = \\sum_{k=1}^k c_{kj}.\\ ] ]    in a similar manner to the po model , we can therefore specify the joint prior distribution of @xmath70 and @xmath7 ; however this time we do not assume both sets of parameters are independent , hence @xmath103\\prod_{k=1}^k f\\left(\\beta_k\\right),\\end{aligned}\\ ] ] where @xmath104 ( @xmath80 ) and @xmath73 are defined as before , and + @xmath105 is the probability density function for a truncated normal distribution , @xmath106 with @xmath107 .",
    "we choose to update each @xmath108 parameter in turn , conditional on all other parameters remaining fixed .",
    "it is tricky to define a simple mechanism for truncated sampling of the regression parameters , due to the fact that the conditions ( [ eq : stochorder ] ) change according to whether we propose @xmath109 or @xmath110 .",
    "instead we opt here for a simple random - walk proposal , such that @xmath111 where @xmath112 controls the size of the maximum move away from the current value at each iteration . for the cut - point parameters , @xmath60 , we choose truncated uniform random - walk proposals , such that @xmath113\\right ) & \\mbox{if $ j=1$},\\\\[6pt ]              u\\left(\\max\\left[\\theta_j^{(i)}-\\tau_{\\theta},\\theta_{j-1}^{(i)}-c_{j-1}^{(i)}\\right],\\right.&\\\\[6pt ]              \\qquad \\left.\\min\\left[\\theta_j^{(i)}+\\tau_{\\theta},\\theta_{j+1}^{(i)}+c_j^{(i)}\\right]\\right ) & \\mbox{if $ j=2,\\dots , j-2$},\\\\[6pt ]              u\\left(\\max\\left[\\theta_j^{(i)}-\\tau_{\\theta},\\theta_{j-1}^{(i)}-c_{j-1}^{(i)}\\right],\\theta_j^{(i)}+\\tau_{\\theta}\\right ) & \\mbox{if $ j = j-1$},\\\\              \\end{array }              \\right.\\ ] ] where @xmath90 controls the size of the maximum unconstrained move .      the _ partial proportional odds _ ( ppo ) model , proposed by  @xcite , allows some variables to have a proportional odds structure and some to not .",
    "it takes the form @xmath114 where @xmath115 and @xmath4 .",
    "the regression parameters @xmath70 correspond to the set of explanatory variables , @xmath116 , that have a proportional odds structure , and the regression parameters @xmath117 correspond to the set of explanatory variables , @xmath118 , that have a non - proportional odds structure .",
    "the approaches described in sections  [ sec : po ] and  [ sec : npo ] can be combined in order to fit a ppo model , where the po and npo variables ( @xmath94 and @xmath119 ) are known in advance . in subsequent sections",
    "we formulate an approach whereby the optimal choice of po or npo structure for each explanatory variable can instead be directly estimated by the model .",
    "the approach described in the previous section assumes that each of the @xmath98 variables is bounded in some finite region , which is true for any set of categorical explanatory variables , since for a categorical variable @xmath120 with @xmath121 levels ( @xmath122 ) , it is straightforward to represent @xmath120 as a set of @xmath123 dummy variables , @xmath124 , such that @xmath125 in the case of continuous or discrete explanatory variables that are bounded in a finite range , then the approach described in section  [ sec : npo ] will also ensure stochastic ordering holds .",
    "however , if @xmath98 is defined over an infinite range , then these conditions will break for some values of @xmath98 if the @xmath108 parameters are also unbounded .    here",
    "we argue for a pragmatic solution to this problem , by considering that it is possible to define an upper and lower bound for @xmath98 based on the observed data , and then use ( [ eq : nonpocond2 ] ) to set boundary conditions for the conditional priors in ( [ eq : nonpropprior ] ) .",
    "although this does not mean that the stochastic ordering will hold for all possible theoretical values of @xmath98 , it does ensure that the stochastic ordering will hold for the range of values found in the observed data .",
    "we make two main arguments to justify this approach :    1 .",
    "although theoretically the values for @xmath98 might be infinite , for any practical applications of the model there will almost certainly be a finite range of possible values .",
    "if the observed data are a fair representation of the underlying population , then provided the model is a good fit , any population - level inference made from the model is likely to be fairly robust ( i.e. the posterior distribution is the distribution of the parameters _ given _ the observed data , so this is explicitly represented within the bayesian paradigm ) .",
    "the assumptions underlying _ any _ statistical model can only be assessed across the range of values used to fit the data , there is no guarantee that the assumptions will hold beyond this range , even if it is possible to extrapolate without breaking any conditions of the model .",
    "consider that we have @xmath41 parameters describing the explanatory variables . in the first instance",
    "assume that each parameter measures the effect of a single variable ( i.e. there are no categorical variables with @xmath126 levels , or any interaction effects ) .",
    "we will extend discussion to these more complex variables in due course .",
    "we can model the relationship between the response variable @xmath127 and each variable @xmath98 in one of three ways : either with a po structure , an npo structure or no relationship at all ; in this example giving @xmath128 possible models . here",
    "we will assume that we have no prior information to distinguish between which of these models is most likely , and so assume equal prior probabilities of association for each competing model . to model these structures we introduce an indicator variable @xmath129 , for @xmath80 , where @xmath130 to ease programming , it is helpful to treat each of these three possibilities as special cases of the npo - structure , such that",
    "if a variable has a po - structure then this is equivalent to setting @xmath131 for @xmath4 , with independent point - mass priors on @xmath132 such that @xmath133 .",
    "if a variable is excluded then this is equivalent to setting @xmath134 with a point - mass prior @xmath133 .",
    "this enables us to use the conditions in ( [ eq : stochorder ] ) to ensure general stochastic ordering .",
    "our stochastic search routine updates each variable @xmath98 in a random order , by proposing to add the variable ( if currently excluded ) or to remove the variable ( if currently included ) with a probability @xmath135 ( hence we do nothing with a probability @xmath136 ) .    to add a variable into the model",
    ", we sample whether to use a po or npo structure with probability @xmath137 and @xmath138 respectively . to add a variable to the model with a po structure , we define a bijective function @xmath139 where @xmath140 is sampled from some distribution with p.d.f .",
    "@xmath141 . to add a variable with an npo structure",
    ", we define a bijective function @xmath142 where @xmath143 are independent and identically distributed ( i.i.d . ) samples from a distribution following @xmath141 . for a 0 @xmath144 po move",
    ", the acceptance probability is @xmath145.\\ ] ] the probability of adding or dropping a variable , @xmath135 , is the same for the forwards and reverse moves , and so cancel in the acceptance ratio .",
    "the determinant of the jacobian matrix is 1 . for a 0 @xmath144 npo move ,",
    "the acceptance probability is @xmath146\\left[\\prod_{j=2}^{j-1 } f\\left(\\theta_j^{(i ) } \\mid \\theta_{j-1}^{(i)},{\\mbox{\\boldmath{$\\beta$}}}_{j}',{\\mbox{\\boldmath{$\\beta$}}}_{j-1 } ' \\right)\\right]}{\\left[\\prod_{j=2}^{j-1 } f\\left(\\theta_j^{(i ) } \\mid \\theta_{j-1}^{(i)},{\\mbox{\\boldmath{$\\beta$}}}_{j}^{(i)},{\\mbox{\\boldmath{$\\beta$}}}_{j-1}^{(i ) } \\right)\\right ] }   \\nonumber \\\\      & & \\qquad \\qquad   \\times \\frac{1}{q_u\\left(u_1,\\dots , u_{j-1}\\right ) } \\times \\frac{1}{1-p_{\\mbox{\\scriptsize po } } } \\biggr].\\end{aligned}\\ ] ] we let @xmath147 be i.i.d .",
    "random variables such that @xmath148 , where @xmath88 is the proposal variance . to remove a variable that is currently included",
    "we can simply reverse this process , amending the acceptance probabilities accordingly .",
    "the second stage of our mcmc routine involves updating the values for any parameters that are currently included in the model . in a random order ,",
    "we select each of the @xmath41 variables in turn , and with probability @xmath149 we propose new values for the associated parameter(s ) , and with probability @xmath150 we propose a shift from po @xmath144 npo ( if variable @xmath151 has a po structure ) , or npo @xmath144 po ( if variable @xmath151 has an npo structure ) .    if variable @xmath151 has a po structure , then to update the value of @xmath86 we simply propose a new value from some proposal distribution with p.d.f .",
    "the update is then a standard metropolis - hastings step . likewise for @xmath108 ( @xmath4 ) if variable @xmath151 has an npo structure .    to switch structures we require a reversible - jump step . to make an npo @xmath144 po move  i.e .",
    "map @xmath153we define a bijective function @xmath154 where @xmath155 . to make the reverse move we do not have to propose any new values , and simply use the inverse function @xmath156",
    "these choices are based around the moment matching approach of  @xcite .",
    "the acceptance probability for a po @xmath144 npo move is : @xmath157,\\end{aligned}\\ ] ] where the final term is the absolute value for the determinant of the jacobian .",
    "similarly , the acceptance probability for an npo @xmath144 po move is @xmath158.\\end{aligned}\\ ] ] we then proceed to update the cut - points , @xmath159 , in the same way as described in section  [ sec : npo ] .",
    "we note that this general rj - mcmc algorithm can be adapted in various ways simply by altering the move probabilities .",
    "for example , we can remove the variable selection steps and just allow the model to move betwen the po and npo structures for each variable by setting @xmath160 .",
    "similarly , we can also fix all parameters to have either a po or npo structure , both with or without variable selection , by adjusting @xmath135 and @xmath149 accordingly .      in some cases there",
    "may be some identifiability issues between regression parameters and their corresponding inclusion indicators when implementing variable selection routines using the framework decribed above .",
    "for example , there may be almost identical likelihoods when a parameter is removed ( set to zero ) and when a parameter is present but has a value close to zero ( e.g.  @xcite ) . if vague priors are used for the regression parameters and inclusion indicators , then these parameters may be unidentifiable . one way to control",
    "this is to use a more informative prior , such as one guided by the data or training runs of the model .",
    "however , as  @xcite note , there is a danger that these approaches will contravene the philosophical construct that the prior distribution should represent one s beliefs about the parameters _ before _ obtaining any data .    a potential way to tackle",
    "this problem in this case is to introduce a hyperprior governing the variance component of the priors for the regression parameters , @xmath70 .",
    "this could be done in various ways , but for po structures we set @xmath161 and @xmath162 is the maximum _ a priori _ range for @xmath163  @xcite , and for npo structures we set @xmath164 this adds a further complexity to the model since it introduces additional parameters to sample during the dimension - jumping steps .",
    "for example , a 0 @xmath144 po move would now consist of moving from 0 @xmath144 @xmath165 , likewise a po @xmath144 npo jump would consist of moving from @xmath166 @xmath167 and so on . to do this",
    "we update each @xmath168 parameter and its corresponding @xmath169 parameter at the same time , using independent proposal distributions .",
    "a slight complexity is that the standard deviations must be positive .",
    "hence for a 0 @xmath144 po or 0 @xmath144 npo move ( or the reverse moves ) , we use the same bijective functions as are described in section  [ sec : addrem ] , except that the dummy variables for the standard deviations are i.i.d .",
    "samples from a @xmath170 distribution .",
    "the acceptance probabilities are adjusted accordingly . for a po @xmath144 npo",
    ", we use a slightly different bijective function for proposing the standard deviations than for the regression parameters .",
    "here we propose values for @xmath171 as i.i.d .",
    "@xmath172,\\min\\left[\\sigma_k+\\tau_{\\sigma},\\xi\\right]\\right)$ ] variables , and then define @xmath173 to make the reverse move we do not have to propose any new values , and simply use the inverse function @xmath174 the acceptance probabilities are updated accordingly , but the additional proposals of the standard deviation terms do not change the jacobian terms in ( [ eq : accpotnpo ] ) or ( [ eq : accnpotpo ] ) .      when comparing nested models including interaction effects , it is usual to specify that interactions can only be included as long as the corresponding main effect terms are also included , and that higher - order interaction terms are included only if all lower - order terms are included  @xcite .",
    "these constraints can be incorporated into the routines described in section  [ sec : rj ] by altering the move probabilities .",
    "for example , consider the possible moves for a main effect variable , @xmath98 , currently included in the model ( with a po structure ) .",
    "if there were no interaction effects , then we propose to exclude the variable with probability @xmath135 .",
    "if we are modelling interaction effects , then we would instead propose to exclude the variable with probability @xmath175 , where @xmath176 likewise , to add interaction effects we need to check that all associated main effects and lower - order interaction effects are present first .",
    "this ensures that we only drop or add variables in the correct manner .",
    "explanatory variables with @xmath126 categories require more than one dummy variable to model ( see section  [ sec : criteria ] ) . in this case , when proposing to add or remove a variable of this form , we must ensure that all associated dummy variables are added or removed simultaneously .",
    "we propose to add a variable of this nature with probability @xmath135 , and then for each associated dummy variable @xmath177 , we independently propose whether these will have po or npo structures on addition , with probabilities @xmath137 or @xmath178 respectively .",
    "the acceptance probabilities are amended accordingly , with the jacobian term being just a product of the corresponding jacobian terms for each of the dummy variables .",
    "the reverse process proceeds in a similar manner .",
    "all the following routines were coded in c and r  @xcite and are in an r package called ` bayesord ` , which in turn uses the ` coda `  @xcite and ` multicore `  @xcite packages to produce output and run multiple chains in parallel .",
    "all results are reported to 2 significant figures ( s.f . ) .",
    "the development   of this package is available at https://github.com/tjmckinley/bayesord .",
    "following  @xcite , we do not thin our mcmc chains once the burn - in has been .=-1      to test the performance of our algorithms , we simulated different data sets assuming    a.   each variable has a po structure ; b.   each variable has an npo structure ; and c.   a mixture of po and npo variables are used .    for each scenario we simulated @xmath179 data sets , each containing @xmath180 samples .",
    "each sample corresponds to measurements on the response variable ( @xmath127 ) and 7 explanatory variables ( 5 binary , @xmath181 , and 2 discrete , @xmath182 and @xmath183 ) .",
    "the response is an ordinal variable with three levels .",
    "each simulation proceeds as follows :    1",
    ".   in scenario ( a ) , set each explanatory variable , @xmath98 , to have a po structure . in scenario",
    "( b ) set each structure to npo , and in scenario ( c ) sample the structure for each @xmath98 from a bernoulli distribution with probability 0.5 . 2 .   for each categorical variable @xmath184 ( @xmath185 ; @xmath186 ) , sample its value ( 0 or 1 ) from a bernoulli distribution with probability 0.5 .",
    "( ensure that there are at least 5% of samples in each group by resampling if required . )",
    "3 .   for each discrete @xmath184 ( @xmath185 ; @xmath187 ) ,",
    "sample data points as @xmath188 , where @xmath189 . here , @xmath190 and @xmath191 .",
    "4 .   sample the regression parameters @xmath192 , where @xmath193 corresponds to the length of the response . for each @xmath151 corresponding to a po structure ,",
    "set @xmath194 .",
    "sample the first threshold parameter , @xmath195 , and then simulate the second threshold parameter , @xmath196 conditional on @xmath197 , the simulated data @xmath94 and the regression parameters , ensuring that the stochastic ordering conditions ( [ eq : stochorder ] ) hold . to do this",
    "we can use ( [ eq : nonpocond2 ] ) to define a lower bound for @xmath196 , and then add some positive random noise ( we chose the absolute value from a @xmath198 distribution ) .",
    "( note that in the case of scenario ( a ) we only need to simulate such that @xmath199 , since the stochastic ordering conditions always hold . )",
    "6 .   finally , sample values of the response variable , @xmath200 , from a multinomial distribution with probability vector defined using ( [ eq",
    ": ppoeq ] ) .",
    "( ensure that there are at least 5% of the samples in each category of the response , else re - simulate . )",
    "once the data sets were simulated , we proceeded to fit po and npo models in both bayesian and maximum likelihood ( ml ) frameworks .",
    "the bayesian models were fitted using the routines developed in this manuscript and implemented in the ` bayesord ` package .",
    "the maximum likelihood po models were fitted using the ` polr ` function in the ` mass `  @xcite package in r , and the ml npo models were fitted using binary logistic regressions , as described in e.g.  @xcite .",
    "we also fitted a bayesian ppo model , using the reversible - jump routines described earlier to choose between the competing structures for each variable .",
    "for the mcmc routines , we used 200,000 updates , with the first 10,000 discarded as burn - in .    to summarise the results we examine the distributions for the squared error between the true value of the regression parameters and the ml estimate or posterior mean accordingly .",
    "table  [ tab : sims ] summarises these results .",
    "focussing first on the results from scenario ( a ) , we can see that as expected , the po models perform well , with the ml and bayesian estimates showing a similar degree - of - accuracy .",
    "the npo and ppo models also perform well , suggesting that although they are overparameterised , given enough data they can produce robust inference on the parameters .    for data sets",
    "simulated using scenario ( b ) , the po models now fit poorly , but the npo and ppo models once again perform well .",
    "similar patterns are observed for the simulations based on scenario ( c ) , and once again the bayesian npo and ppo models perform very well in comparison to the other approaches .",
    "there are occasional poor estimates of the parameters used in the simulations ( seen by the high 97.5% credible intervals in table  [ tab : sims ] ) .",
    "these could be caused either by a lack - of - fit ( most likely when these values are very high ) , or more frequently when the data are a sample from the extremes of the expected sampling distribution . in any case , the bayesian methods seem more robust to these outliers , particularly compared to the extreme ml npo mismatches .",
    "we postulate that this is likely due to the fact that the bayesian methods contain all information in the likelihood , as opposed to the ml npo method which must treat groups independently .    as a simple exploration of the utility of the bayesian ppo model for discriminating between po and npo structures ,",
    "we apply a threshold such that any variable with @xmath201 is classified as having a po structure . in this case",
    "we have @xmath202 possible predictions for each simulation scenario . in the case of scenario ( a ) ,",
    "only @xmath203 are incorrectly specified as having an npo structure .",
    "in the case of scenario ( b ) , @xmath204 are misclassified as having a po structure . for scenario ( c ) , @xmath205 are misclassified , of which @xmath206 are npo variables misclassified as po variables , and @xmath207 are po variables misclassified as npo variables .",
    "this shows a good predictive power , bearing in mind that the bayesian model choice framework intrinsically favours more parsimonious models , and as such the majority of misclassifications were npo variables being reduced to po variables , such as we might expect if the differences between the regression parameters for each level of the response are small .",
    "of course these ` misclassifications ' may be directly due to quirks in the data as a result of random sampling , and to this end table  [ tab : sims ] suggests that the bayesian npo and ppo estimates are robust compared to other methods , even accounting for any misclassification in the actual structure used for the simulations .",
    "we reiterate that these model fits were performed blind , without a prerequisite descriptive analysis that might shed some light on our _ a priori _ expectations of variable structures . in practice",
    "we would take more care with our preliminary model exploration and our model diagnostics , but with this in mind we think the methods perform well .",
    ".summaries of squared error between estimated and true values , for data sets generated using three different scenarios ( defined in the main text ) . within each panel , @xmath179",
    "simulated data sets are generated , each of size @xmath180 samples .",
    "each panel is further stratified by the type of model ( po , npo , ppo ) and the fitting mechanism ( ml or bayesian).[tab : sims ] [ cols=\"<,<,<,<,<\",options=\"header \" , ]     the effect of age is interesting ; relative to the 06 month category , dogs aged between 712 months are 1.1 times more likely to have a _ higher _ bcs ; dogs aged between 1336 months are 1.2 times more likely to have a _ lower _ bcs , and as adults ( @xmath20836 months ) they are between 14.5 times more likely to have a _ higher _ bcs , depending on the category level ( since the adult age class has very strong evidence of an npo structure ) .",
    "a likely explanation is that this pattern reflects normal morphological variation  generally , as dogs become older their activity levels will decrease , resulting in a general increase in bcs .",
    "an interesting finding in this analysis is that other than the @xmath208 36 month age category , all other variables had very strong support for a po structure ( conditional on inclusion ) .",
    "one of the key motivations for the study that generated these data was to examine the hypothesis that these canine populations are regulated by environmental resource constraints ( as they would be in wild populations ) .",
    "if this hypothesis is true , then consistent with empirical evidence in other species and ecological theory , the thin dogs should generally be the ones with highest energy requirements ( particularly lactating and growing dogs ) .",
    "the marginal distributions shown in figure  [ fig : fitted ] provide qualitative evidence against this hypothesis , since whilst on average there was a tendency for lactating dogs to be thinner than non - lactating dogs , overall the body condition distribution for lactating dogs shows that most dogs are in reasonable body condition , with fewer dogs in the extremes .",
    "crucially there are underweight lactating dogs and underweight non - lactating dogs , and there are overweight lactating dogs and overweight non - lactating dogs  consistent with variable food availability most likely from an owner , rather than from the environment ( e.g. scavenging ) . the same is true for young dogs .    a similar argument",
    "could be made by examining the evidence for po versus npo structures for these key variables ( particularly opl and age ) . under the hypothesis of environmental constraints limiting population size",
    ", then we might expect lactating and young dogs to be more likely to exhibit an npo structure , with decreasing negative log - odds ratios with increasing bcs .",
    "we do not observe this here .",
    "there is strong evidence of an npo structure for the @xmath208 36 month age class , though this is again consistent with the population being ` managed ' , rather than acting as a wild population .",
    "similar results are obtained for all four study regions . this information has important implications for designing optimal vaccination strategies against rabies in these populations . for full details of the study , and a comprehensive discussion about all the collected evidence , see  @xcite .",
    "confinement is associated with a _",
    "lower _ bcs , with confined dogs being 1.7 times more likely to have a lower bcs than unconfined dogs .",
    "although confinement , as defined in this study , was highly variable ( with regards to the length of time dogs were confined and the frequency that they were released ) , in general it was observed that dogs that were tied up were often neglected .",
    "see  @xcite for a full discussion on these issues .",
    "finally , the clinical signs variables cover a wide range of possible conditions .",
    "these were classified into ` minor ' ( considered unlikely to cause weight loss , such as localised skin lesions and lameness ) and ` major ' ( considered likely to cause weight loss , such as vomiting and lethargy ) .",
    "this variable serves as an indicator of the general health of the dog , and it can be seen that as expected , dogs that show evidence of an ongoing medical condition ( that is likely to cause weight loss ) , are more likely to have _ lower _ bcs values than their healthy counterparts : 1.2 times more likely for minor ailments and 2.7 times more likely for major ailments .",
    "we have introduced a method for fitting cumulative link ordinal regression models that does not require _ a priori _ assumptions regarding po or npo structures to model the relationship between the response and explanatory variables . for categorical explanatory variables",
    "we show how stochastic ordering can be ensured in the case of npo models , and provide a pragmatic approach to ensuring that stochastic ordering holds for continuous or discrete covariates within the range of the observed data .",
    "in addition these approaches can be extended to incorporate variable selection within a bayesian framework , allowing posterior probabilities of association to be produced for competing models .",
    "it is straightforward to include individual - level terms to account for repeated measures , and bayesian model averaging can to be used to provide weighted ppa estimates for the parameters that account for model uncertainty .",
    "we have illustrated the methods on a large - scale real - life data set .",
    "the method uses reversible - jump mcmc to jump between models of differing dimensionality .",
    "however , implementational difficulties can exist with this method , particularly when jumping between models where the dimensionality is quite different .",
    "we found that the simple proposal mechanisms used throughout the paper worked well for this application and others we have tried . nonetheless it is likely that specific situations may require more additional tuning ( as with any mcmc method ) .",
    "for example , if some of the intervals specified by the stochastic ordering conditions ( [ eq : stochorder ] ) are small , and the proposal size , @xmath209 is too large , then for npo structures this may result in a large proportion of proposed values for the @xmath108 parameters being rejected as a result of breaking the prior conditions on stochastic ordering .",
    "an alternative would be to sample from some form of truncated distribution , though due to the nature of the constraints , this is not trivial .",
    "another interesting alternative would be to use some form of _ shrinkage _ model , where the model is defined as @xmath210 where @xmath115 and @xmath4 .",
    "the conditional prior distributions for the @xmath211 parameters are centred around the corresponding @xmath86 with a small prior variance .",
    "the @xmath86 parameters can be given the same prior distribution as before .",
    "in this variation the model does not change dimensionality , and so no reversible - jump step is required .",
    "the @xmath211 parameters then correspond to the degree to which the parameter estimates deviate away from the proportional odds structure .",
    "this idea could also be expanded to incorporate variable selection in various ways ( see e.g.  @xcite ) .",
    "using single - component updates with simple random - walk proposals can also produce markov chains that are highly autocorrelated , and thus require a large number of iterations and a lot of thinning .",
    "adaptive proposal mechanisms  @xcite exist for standard ( i.e. non - transdimensional ) mcmc , that can automatically tune the proposal distributions to produce much more efficient chains in terms of both convergence and mixing .",
    "however , it is not currently understood whether these sorts of approaches hold for transdimensional routines , and this is a key area of ongoing research for those who are developing these methods  @xcite .",
    "for the kinds of examples shown in this paper the runtimes required to produce a reasonable number of pseudo - independent samples are not prohibitive , and so we do not worry about this aspect here .",
    "it is not the purpose of this paper to provide a catch - all routine that works well in every situation , but rather to provide a flexible method that can be adapted to deal with different situations as required .",
    "we occasionally noticed some identifiability issues when fitting npo models , predominantly between categorical explanatory variables with low counts in some of the groups , and the cut - off parameters .",
    "this can be tackled in two main ways : firstly , the variables can be recategorised to ensure that there is a minimum number of individuals in each group . secondly",
    ", we can start the mcmc routines using more informative initial values .",
    "appealing to the occam s razor principal , in this paper we decided to generate initial values by producing a short training run , using a po model that includes all of the explanatory variables ( but ignoring the repeated measures ) .",
    "we then ran the full model using the parameter values from the final iteration of the training run as initial values .",
    "a similar approach would be to generate maximum likelihood estimates for the simple po model and use these as initial values instead .",
    "an example of the utility of these routines is that stochastic ordering can be ensured for continuous / discrete covariates within the range of the observed data .",
    "it is theoretically possible to ensure these conditions hold for any finite range of values , if an upper or lower bound was known from sources of information other than the observed data . in any case , if it is of interest to extrapolate beyond the range of the data , then it is possible to use the posterior samples to explore the range of covariate values over which the stochastic conditions will hold  essentially building a posterior distribution for the range of valid values .",
    "this could also be used as a form of sensitivity analysis to the model assumptions based on the model fit .",
    "it is also worth noting that although we have illustrated these methods using a logistic link function , the methods are applicable to any monotonically increasing link function ( though of course the interpretation of the regression parameters will no longer be in terms of the cumulative odds ) .",
    "brooks , s.  p. , giudici , p. , and roberts , g.  o. ( 2003 ) .",
    "`` efficient construction of reversible jump markov chain monte carlo proposal distributions . ''",
    "_ journal of the royal statistical society .",
    "series b ( methodological ) _ , 65(1 ) : 355 .",
    "german , a.  j. and holden , s.  l. ( 2006 ) .",
    "`` subjective estimation of body condition can predict body fat mass as well as condition scoring with an established 9-point scale . '' in _",
    "bsava congress 2006 scientific proceedings _ , 508 .",
    "bsava publications .",
    "ishwaran , h. and gatsonis , c.  a. ( 2000 ) .",
    "`` a general class of hierarchical ordinal regression models with applications to correlated roc analysis . '' _ the canadian journal of statistics _ , 28(4 ) : 731750 .",
    "lall , r. , campbell , m.  j. , walters , s.  j. , morgan , k. , and mrc cfas co - operative ( 2002 ) .",
    "`` a review of ordinal regression models applied on health - related quality of life assessments . '' _ statistical methods in medical research _",
    ", 11 : 4967 .",
    "leon - novelo , l.  g. , zhou , x. , bekele , b.  n. , and mller , p. ( 2010 ) .",
    "`` assessing toxicities in a clinical trial : bayesian inference for ordinal data nested within categories . '' _ biometrics _ , 66 : 966974 .",
    "morters , m. , mckinley , t. , restif , o. , conlan , a. , cleaveland , s. , hampson , k. , whay , b. , damriyasa , i.  m. , and wood , j. ( 2014 ) .",
    "`` the demography of free - roaming dog populations and applications to disease and population control . '' _ to appear in journal of applied ecology_.    mwalili , s.  m. , lesaffre , e. , and declerck , d. ( 2005 ) . `` a bayesian ordinal logistic regression model to correct for interobserver measurement error in a geographical oral health study . '' _ applied statistics _ , 54 : 7793 .",
    "paquet , u. , holden , s. , and naish - guzman , a. ( 2005 ) .",
    "`` bayesian hierarchical ordinal regression . '' in duch , w. , oja , e. , and zadrozny , s. ( eds . ) , _ artificial neural networks : formal models and their applications ",
    "icann 2005 _ , 267272 .",
    "springer - verlag berlin heidelberg .",
    "richardson , s. and green , p. ( 1997 ) .",
    "`` on bayesian analysis of mixtures with an unknown number of components ( with discussion ) . ''",
    "_ journal of the royal statistical society .",
    "series b ( methodological ) _ , 59 : 731792 .",
    "tjm is supported by biotechnology and biological sciences research council grant number bb / i012192/1 .",
    "mm is supported by a grant from the international fund for animal welfare ( ifaw ) and the world society for the protection of animals ( wspa ) , with additional support from the charles slater fund and the jowett fund .",
    "jw is supported by the alborada trust and the rapidd program of the science and technology directorate , department of homeland security and the fogarty international centre .",
    "thanks to andrew conlan and richard dybowski for useful discussions , and to the anonymous referees whose comments and suggestions helped greatly improve this manuscript ."
  ],
  "abstract_text": [
    "<S> the use of the proportional odds ( po ) model for ordinal regression is ubiquitous in the literature . </S>",
    "<S> if the assumption of parallel lines does not hold for the data , then an alternative is to specify a non - proportional odds ( npo ) model , where the regression parameters are allowed to vary depending on the level of the response . </S>",
    "<S> however , it is often difficult to fit these models , and challenges regarding model choice and fitting are further compounded if there are a large number of explanatory variables . </S>",
    "<S> we make two contributions towards tackling these issues : firstly , we develop a bayesian method for fitting these models , that ensures the stochastic ordering conditions hold for an arbitrary finite range of the explanatory variables , allowing npo models to be fitted to any observed data set . secondly , we use reversible - jump markov chain monte carlo to allow the model to choose between po and npo structures for each explanatory variable , and show how variable selection can be incorporated . </S>",
    "<S> these methods can be adapted for any monotonic increasing link functions . </S>",
    "<S> we illustrate the utility of these approaches on novel data from a longitudinal study of individual - level risk factors affecting body condition score in a dog population in zenzele , south africa .    ,    , </S>"
  ]
}