{
  "article_text": [
    "the question of how to obtain an overall significance level for the results of _ independent _ runs of studies has been investigated since the 1930s  @xcite . in fact , forming a single statistical significance out of multiple independent tests has been an important subject of study in numerous area of scientific disciplines , including social psychology  @xcite , medical research  @xcite , genetics  @xcite , proteomics  @xcite , genomics  @xcite , bioinformatics  @xcite and others .",
    "frequently used methods for combining independent @xmath0-values fall into numeric and analytic categories .",
    "this classification is not totally precise since method such as fisher s started out with the necessity of inverting the @xmath1 cumulative distribution function and thus seemed like a numerical approach  @xcite .",
    "the method mentioned in  @xcite , although not in the context of combining @xmath0-values , brought out an analytical expression for combined @xmath0-value using fisher s method , thus effectively brought fisher s method into analytic category . in the context of combining @xmath0-values , by mapping to a known result by feller  @xcite",
    ",  @xcite also provided an analytic formula for fisher s combined @xmath0-value .",
    "numerical approaches typically involve inverting cumulative distribution functions .",
    "for example , stouffer s z - methods  @xcite , whether unweighted  @xcite or weighted  @xcite , require inverting the error function .",
    "lancaster s generalization  @xcite of fisher s formalism also requires inverting gamma distribution function to incorporate unequal weighting for @xmath0-values combined .    in this paper , we focus on analytic methods only .",
    "two existing analytic approaches , fisher s  @xcite and good s  @xcite , are frequently employed .",
    "fisher s method combines @xmath2 independent tail - area probabilities democratically to form a single significance assignment while good s formula weights each tail - area probability differently to form a different single significance assignment .",
    "since good s expression involves , in the denominator , pairwise differences between weights , he cautiously remarked that the expression may become ill - conditioned and thus the calculations should be done by holding more decimal places when weights of similar magnitudes exist .",
    "this statement has been paraphrased by many authors  @xcite .",
    "in addition to the cases considered by fisher and good , it is foreseeable that one may wish to categorize obtained independent @xmath0-values into different groups so that one would like to weight @xmath0-values within the same group democratically and weight different group differently . we will call this scenario the _ general case _ ( gc ) .",
    "the gc naturally occurs since one may wish to categorize data obtained from the same type of experimental instruments into the same group , and data collected from different instrument types may justify the use of different weights .",
    "when there is only one instrument type , the gc reduces to fisher s consideration .",
    "when there exist no replicates within each instrument types , the gc coincides with the consideration of good . in principle",
    ", the weighted version of the stouffer s method can also be used for this purpose .",
    "since the main scope here is to pursue analytic results , we wo nt delve into methods in numerical category .",
    "it is important , however , to point out that the mathematical problem of combining @xmath0-values is also related to other areas of research .",
    "for example , the equivalent of good s formula had already emerged in 1910 in the context of sequential radioactive decay  @xcite , while analytical expression for fisher s combined @xmath0-value emerged in 1960 as a special case of the former when all the decay constants are identical  @xcite . after good s formula  @xcite ,",
    "the same distribution function was rederived by  @xcite and later on by  @xcite . as for the gc ,",
    "fisher s method included , the mathematical equivalents appear in different areas of studies mainly under the consideration of sum of exponential / gamma variables . the distribution function of linear combination of exponential / gamma variables are useful in various fields .",
    "when limited to exponential variables , it results in the erlang distribution that is often encountered in queuing theory  @xcite .",
    "it is also connected to the renewal theory  @xcite , time series problem  @xcite , and can be applied to model reliability  @xcite .",
    "the intimate connections between these seemingly different problems are not obvious at first glance .",
    "consequently , it is not surprising that the distribution function has been rediscovered / rederived many times and that some information about it has not been widely circulated .",
    "our literature searches show that the first explicit result ( without further derivatives involved ) for the distribution function was obtained by @xcite .",
    "subsequently , motivated by different contexts ,  @xcite ,  @xcite , and  @xcite all rederived the same distribution function .",
    "employing a complex variable integral formulation , we are able to provide a different derivation of the distribution function and become the first to make connection to the gc of combining @xmath0-values . since both fisher s and good s considerations arise as special limiting cases of the gc",
    ", we also illustrate that our cumulative probability distribution for gc indeed reduces to the appropriate limiting formulas upon taking appropriate parameters . the main novelty of this paper , however , is the explicit treatment of cases where nearly degenerate weights exist .",
    "these cases are known for numerical instabilities , which motivated many authors to pursue uncontrolled approximations  @xcite .",
    "we have derived a controlled expansion , in power of differences in inverse weights , that provides both accurate statistics and stable numerics .    in the following section",
    ", we will first summarize fisher s and good s methods for combining @xmath0-values , followed by the mathematical definition of the gc . a section devoted to derivation of",
    "the probability distribution function and cumulative probability for the gc then follows .",
    "we then delve into the case of nearly degenerate weights and provides a formula with controllable accuracy for combining @xmath0-values .",
    "a few examples of using the main results are then provided .",
    "this paper concludes with future directions .",
    "a c++ program , which computes the combined @xmath0-values with equal numerical stability regardless of whether weights are ( nearly ) degenerate or not , is available upon request from the authors .",
    "imagine that one wishes to combine @xmath2 independent @xmath0-values @xmath3 , each of which is drawn from an uniform , independent distribution over @xmath4 $ ] .",
    "for later convenience , let us define & & p_1p_2 p_l , [ fisher_tau ] + & & p_1^w_1 p_2^w_2 p_l^w_l [ good_tau ] . to form a unified significance , fisher and good considered respectively the stochastic quantities @xmath5 and @xmath6 , defined by q_f & & x_1 x_2 x_l [ fisher_q ] , + q_g & & x_1^w_1 x_2^w_2 x_l^w_l [ good_q ] , where each @xmath7 represents a random variable drawn from an uniform , independent distribution over @xmath4 $ ] .",
    "the following probabilities ( q_f ) & = & _ l=0^l-1 [ ( 1/)]^l l ! [ comb.fisher ] + ( q_g ) & = & _ l=1^l _ l ^1/w_l [ comb.good ] provide the unified statistical significances , corresponding respectively to fisher s and good s considerations , from combining @xmath2 independent @xmath0-values . in eq .",
    "( [ comb.good ] ) , the prefactor @xmath8 is given by _",
    "apparently , @xmath8 is ill - defined when the weight @xmath9 coincides with or is numerically close to any other weights @xmath10 .",
    "although fisher did not derive ( [ comb.fisher ] ) , from this point on , we shall refer to ( [ comb.fisher ] ) as fisher s formula and ( [ comb.good ] ) as the good s formula .",
    "let us divide the @xmath2 @xmath0-values into @xmath11 groups with @xmath12 . within each group @xmath13 ,",
    "we weight the @xmath14 @xmath0-values within equally ; while @xmath0-values in different groups are weighted differently . therefore , when @xmath15 and @xmath16 @xmath17 , we have the good s case and when @xmath18 and @xmath19 , we reach fisher case .",
    "we will therefore define the following quantities of interest & & _",
    "k=1^m ^w_k [ unify_tau ] + q & & _",
    "k=1^m ^w_k [ unify_tau ] where each @xmath20 represents again a random variable drawn from an uniform , independent distribution over @xmath4 $ ] .",
    "the quantity of interest @xmath21 , if obtained , should cover both results of fisher s and good s as the limiting cases . in the next section",
    ", we will derive an exact expression for @xmath22 and describe how to recover the results of fisher s and good s .",
    "let @xmath23 , we then may write f ( ) = _ 0 ^ 1 _ 0 ^ 1 ( - _ k=1^m ^w_k ) _ k=1^m _ j=1^n_k dx_k;j , [ f.def ] where the heaviside step function @xmath24 takes value @xmath25 when @xmath26 and value @xmath27 when @xmath28 . upon taking a derivative with respect to @xmath29 , we obtain f ( ) = _ 0 ^ 1 _ 0 ^ 1 ( - _ k=1^m ^w_k ) _ k=1^m _ j=1^n_k dx_k;j , [ f.def ] where @xmath30 represents dirac s delta function that takes zero value everywhere except at @xmath31 and that @xmath32 , @xmath33 .    to proceed , let us make the following change of variables & = & e^-t + x_k;j & = & e^-u_k;j and remember that if @xmath34 is the only root of @xmath35 ( @xmath36 ) @xmath37 we may then rewrite ( [ f.def ] ) as f ( ) = _ 0^ _ 0^ e^t e^-_k , j u_k;j ( t - _ k=1^m w_k ) _ k=1^m _ j=1^n_k du_k;j .",
    "[ f.0 ] note that the right hand side of ( [ f.0 ] ) , except for the additional factor @xmath38 , is the probability density function of a weighted , linear sum of exponential variables .    by introducing the integral representation of the @xmath39 function @xmath40 we may re - express ( [ f.0 ] ) as f ( ) & = & _ -^ e^-it(q+i ) _",
    "k=1^m ^n_k + & = & _ -^ e^-it(q+i ) _",
    "k=1^m ^n_k + & = & _ -^ e^-it(q+i ) _ l=1^m ( ) ^n_l _",
    "k=1^m ^n_k + & = & ( i ) ^_k=1^m n_k _ -^",
    "e^-it(q+i ) _ k=1^m ^n_k [ f.1 ] + & & f ( ; n_1,n_2, ",
    ",n_m ) , [ tf.def ] where @xmath41 is introduced for the ease of analytical manipulation and @xmath42 is introduced for later convenience . since all @xmath43 , implying that all @xmath44 and thus the poles of the integrand in ( [ f.1 ] ) lie completely at the lower half of the @xmath45-plane .",
    "the integral of @xmath45 may be extended to enclose the lower half @xmath45-plane to result in f ( ) & = & e^t ( ) _ k=1^m _ q = -ir_k + & = & e^t _ k=1^m \\ { ( -i ) _ _ j=1,jk^m ( ) ^n_j+g_j } + & = & e^t _ k=1^m \\ { _ e^-r_k t _",
    "j=1,jk^m } .",
    "[ f.1.2 ] comparing eq .",
    "( [ f.1.2 ] ) with eq .",
    "( [ f.0 ] ) , we see that the right hand side of ( [ f.1.2 ] ) is composed of the product of the factor @xmath38 and the probability density function of a weighted sum of exponential variables .",
    "in fact , the explicit expression of latter , in addition to the new derivation presented here , was derived much earlier  @xcite under different context and was rediscovered / rederived multiple times  @xcite by different means .",
    "its connection to combining @xmath0-values , however , was never made explicit till now .    from ( [ f.def ] ) , we know that @xmath46 , implying that f ( ) & = & _ 0^f( ) d = _ t^f ( e^-t ) e^-t dt + & = & _ k=1^m _ ( _ j=1,jk^m ) _",
    "t^ e^-r_k t dt + & = & _ k=1^m _ ( _ j=1,jk^m ) ( _ l=0^g_k e^-r_k t ) + & = & _ k=1^m _ ( _ j=1,jk^m ) ( _ l=0^g_k e^-r_k t ) + & = & _ k=1^m _ g_k=0^n_k-1 _ ^n_k-1-g_k ( _ j=1,jk^m ) h(r_k t , g_k ) , [ f.unify.0 ] where the function @xmath47 is defined as [ h.def ] h(x , n ) e^-x _ k=0^n .",
    "( [ f.unify.0 ] ) represents the most general formula that interpolates the scenarios considered by fisher and good .",
    "let us take the limiting case from ( [ f.unify.0 ] ) . for fisher s formula , one weights",
    "every @xmath0-value equally , and thus correspond to @xmath18 and @xmath19 .",
    "the constraint in the sum of ( [ f.unify.0 ] ) forces @xmath48 .",
    "consequently , we have ( by calling @xmath49 by @xmath50 for simplicity ) ( q_f ) = h(rt , l-1 ) = e^-rt _ l=0^l-1 [ unify.fisher.0 ] notice that regardless whatever the weight @xmath51 one assigns to all the @xmath0-values , the final answer is independent of the weight .",
    "this is because @xmath52 and therefore @xmath53 .",
    "this results in [ f.unify.fisher ] ( q_f ) = _ l=0^l-1 , exactly what one anticipates from ( [ comb.fisher ] ) . to obtain the results of good",
    ", one simply makes @xmath15 and @xmath54 @xmath17 , implying all @xmath55 . in this case ,",
    "( [ f.unify.0 ] ) becomes ( with @xmath56 , @xmath57 and @xmath58 @xmath59 ) [ f.unify.good ] ( q_g ) = _ l=1^l ( _ k l ) ^1/w_l = _ l=1^l _ l ^1/w_l , reproducing exactly ( [ comb.good ] )    one may also re - express eq .",
    "( [ f.unify.0 ] ) in a slightly different form f ( ) & = & _ k=1^m _ g_k=0^n_k-1 h(r_k t , g_k ) + & & _ ^n_k-1-g_k ( _ j=1,jk^m ) + & & f (;",
    "n_1 , n_2 ,  , n_m ) .",
    "[ f.unify.1 ] note that in the expression ( [ f.unify.1 ] ) , we have isolated an overall multiplying factor and keeps explicit the @xmath60 dependence for later convenience .",
    "in our derivation of ( [ f.unify.fisher ] ) , it is explicitly shown in section  [ sec : derivation ] that the final @xmath0-value obtained is independent of the weight @xmath51 that was used to assign to all the individual @xmath0-values , @xmath61 .",
    "it is thus natural to ask , if one starts by weighting each @xmath0-value differently , upon making the weights closer to one another , will one recover fisher s formula ( [ comb.fisher ] ) from good s formula ( [ comb.good ] ) ? by continuity , the answer is expected to be affirmative . more generally , one would like to have a formal protocol to compute the combined @xmath0-value when the weights may be categorized into several subsets , within each subset the weights are almost degenerate .    in this section ,",
    "we first illustrate the transition from good s formula to fisher s formula by combining two almost degenerate @xmath0-values .",
    "we will then provide a general protocol to explicitly , when there exist nearly degenerate weights , deal with the possible numerical instability that was first cautioned by  @xcite and subsequently by many authors  @xcite .",
    "let us consider combining @xmath62 and @xmath63 with weights @xmath64 and @xmath65 using good s formula .",
    "one has [ good.2p.0 ] ( q_g ) = . without loss of generality",
    ", one assumes @xmath66 and hence writes @xmath67 with @xmath68 .",
    "we are interested in the case when the weights get close to each other , or when @xmath69 .",
    "we now rewrite eq .",
    "( [ good.2p.0 ] ) as [ good.2p.1 ] ( q_g ) = = . in the limit of small @xmath70",
    ", we may rewrite ( [ good.2p.1])as ( q_g ) & = & = + & = & + & = & p_1p_2 + & & p_1p_2 = ( q_f ) .",
    "[ good.2p.to.fisher ] note that when the small weight difference @xmath71 is near the machine precision of a digital computer , using formula ( [ comb.good ] ) directly will inevitably introduce numerical instability caused by rounding errors . to construct a general protocol to deal with nearly degenerate weights , one first observes from eqs .",
    "( [ f.1]-[f.unify.1 ] ) that it is the inverse of weights @xmath41 that permeates the derivation of the unified @xmath0-value .",
    "the closeness between weights is thus naturally defined by closeness in the inverse weights . as shown in eqs .",
    "( [ good_tau ] ) and ( [ comb.good ] ) , the combined @xmath0-value by good s formula is independent of the absolute size of the weights but only on the relative weights . making the observation that @xmath72 in eq .",
    "( [ f.unify.0 ] ) only depend on the ratios @xmath73 , one also sees explicitly that the most general combined @xmath0-values ( see ( [ f.unify.0 ] ) ) only depend on the relative weights as well .",
    "we are thus free to choose any scale we wish . for simplicity ,",
    "we normalize the inverse weight associated with each method by demanding the sum of inverse weights equal the total number of methods [ iw.norm ] _ j=1^m r_j = _ j=1^m 1 = m , where @xmath74 represents the weight associated method @xmath75 and @xmath76 represents the total number of @xmath0-values ( or methods ) to be combined . for the gc described in section  [ sec : derivation ] , @xmath77 .",
    "this normalization choice makes the average inverse weight of participating methods be @xmath25 .",
    "the next step is to determine , for a given list of inverse weights and the radius of clustering , the number of clusters needed .",
    "this task may be achieved in a hierarchical manner .",
    "after normalizing the inverse weights @xmath78 using eq .",
    "( [ iw.norm ] ) , one may sort the inverse weights in either ascending or descending order . for a given radius @xmath79 ,",
    "one starts to seek the pair of inverse weights that are closest but not identical , and check if it is smaller than the radius @xmath80 .",
    "if yes , one will merge that pair of inverse weights by using their average , weighted by number of occurrences , as the new center and continue the process till every inverse weights in the list is separated by a distance farther than @xmath80 .",
    "we use an example of @xmath81 to illustrate the idea .",
    "let the normalized inverse weights @xmath82 be @xmath83 where the number @xmath84 inside the pair of parentheses after @xmath85 simply indicates that there are two identical inverse weights @xmath85 to start with .",
    "assume that one chooses the radius of cluster @xmath80 to be @xmath86 , since every adjacent inverse weights are separated by more than @xmath86 , no further clustering procedures is needed and one ends up having seven effective clusters : one cluster with two identical inverse weights @xmath85 , and the rest of six clusters are all singletons .",
    "this corresponds to @xmath87 , @xmath88 , @xmath89 , @xmath90 .",
    "suppose one chooses the clustering radius @xmath80 to be @xmath91 .",
    "in the first step , we identify that @xmath85 and @xmath92 are the closet pair of inverse weights .",
    "the weighted average between them is @xmath93 the list of inverse weights then appears as @xmath94 the closest pair of inverse weights is now between @xmath95 and @xmath96 , and upon merging them we have the list now appears as @xmath97 next pair of closest inverse weights is then @xmath98 and @xmath99 .",
    "the weighted average leads to @xmath100 .",
    "after this step , the list of inverse weights appears as @xmath101 indicating that we have @xmath102 ( four clusters ) , with number of members being @xmath103 , @xmath104 , @xmath105 and @xmath106 .",
    "the centers of the four clusters are specified by the average inverse weights : @xmath107 .",
    "the distance between any two of the average inverse weights is now larger than @xmath91 .",
    "this is a good place for us to introduce some notation .",
    "we shall denote by @xmath108 the @xmath75th inverse weights of cluster @xmath13 , whose averaged inverse weight is @xmath78 . with this definition , for the example",
    "above , we have @xmath109 , @xmath110 , @xmath111 , @xmath112 , @xmath113 , @xmath114 , and @xmath115 .",
    "using the hierarchical protocol mentioned above , the number of clusters @xmath11 and the numbers of members @xmath14 associated with cluster @xmath13 are all obtained along with @xmath116 . following the derivation in section  [ sec : derivation ] , we obtain a probability density function very similar to ( [ f.1 ] ) f ( ) =",
    "( i ) ^_k=1^m n_k _",
    "-^ e^-it(q+i ) _ k=1^m .[f.2 ] from section  [ sec : derivation ] , we see that the ill - conditioned situations emerge when some weights are nearly degenerate and the source of difference in inverse weights comes from obtaining @xmath117 in ( [ f.unify.1 ] ) from @xmath118 in ( [ tf.def ] ) .",
    "therefore , one may leave the prefactor @xmath119 $ ] untouched and focus on the rest of the right hand side of eq .",
    "( [ f.2 ] ) . to proceed ,",
    "we write & = & ( 1 + ) ^-1 = e^-(1 + )   + & = & . consequently , we may write [ ykg.intro ] _ j=1^n_k = where [ ykg.def ] y_k;g _ j=1^n_k . the product in eq .",
    "( [ f.2 ] ) may now be formally written as [ prod.0 ] _",
    "k=1^m = .",
    "we now note a simplification by choosing @xmath78 to be the average inverse weight of the @xmath13th cluster . in this case",
    ", we have @xmath120 @xmath17 .",
    "that is , @xmath121 always .",
    "this allows us to write eq .",
    "( [ prod.0 ] ) as [ prod.1 ] _",
    "k=1^m = .",
    "the key idea here is to taylor expand the exponential and collect terms of equal number of @xmath122 .",
    "evidently , the first correction term starts with @xmath123 .",
    "furthermore , before the @xmath124 order , there is no mixing between different clusters .",
    "below , we rewrite eq .",
    "( [ f.2 ] ) to include the first few orders of correction terms & & = ( i ) ^_k=1^m n_k _",
    "-^ e^-it(q+i ) + & & = f ( ; \\ { n_l } _",
    "l=1^m ) + _",
    "k=1^m y_k;2 f ( ; \\ { n_lk , n_k+2 } ) + & & + _ k=1^m y_k;3 f ( ; \\ { n_lk , n_k+3 } ) + _ k=1^m ( y_k;4 + ) f ( ; \\ { n_lk , n_k+4 } ) + & & + _ ^m y_k;2 y_k;2 f ( ; \\ { n_lk , k , n_k+2,n_k+2 } ) + o(^5 ) .",
    "this immediately leads to & & = f ( ; \\ { n_l } _",
    "l=1^m ) + _ k=1^m y_k;2 f ( ; \\ { n_lk , n_k+2 } ) + & & + _",
    "k=1^m y_k;3 f ( ; \\ { n_lk , n_k+3 } ) + _ k=1^m ( y_k;4 + ) f ( ; \\ { n_lk , n_k+4 } ) + & & + _ ^m y_k;2 y_k;2 f ( ; \\ { n_lk , k , n_k+2,n_k+2 } ) + o(^5 ) .",
    "[ f.unify.expansion ]    note that when the cluster radius @xmath80 is chosen to be zero , the only clusters are from sets of _ identical _ weights , and all @xmath125 must be zero . in this case",
    ", only the first term on the right hand side of ( [ f.unify.expansion ] ) exists and the result derived in section  [ sec : derivation ] is recovered exactly . since all @xmath126 are finite positive quantities , the errors resulting from truncating the expression in eq .",
    "( [ f.unify.expansion ] ) at certain order of @xmath80 can be easily bounded .",
    "therefore , any desired precision may be obtained via including the corresponding number of higher order terms .",
    "as the main result of the current paper , our expansion provides a systematic , numerically stable method to achieve desired accuracy in computing combined @xmath0-values .",
    "* example  ( a ) * : this example , assuming @xmath102 , demonstrates how to compute the @xmath127 function present in eq .",
    "( [ f.unify.1 ] ) .",
    "let @xmath78 be the inverse weights associated with cluster @xmath13 .",
    "when combining multiple @xmath0-values with a prescribed clustering radius on the inverse weights , see ( [ iw.norm ] ) and the previously described clustering procedure , the @xmath78s and the deviations @xmath125 are obtained once and for all .",
    "the @xmath125 , through eq .",
    "( [ ykg.def ] ) , constitute the key expansion parameters @xmath128 that yield , upon multiplying by @xmath129 with different @xmath130 , the higher order terms in our key result ( [ f.unify.expansion ] ) .",
    "note that in eq .",
    "( [ f.unify.expansion ] ) , in the zeroth order term , the argument @xmath131 of @xmath126 represents the number of members associated with cluster @xmath132 . however , for higher order correction terms , the @xmath131s entering @xmath126 no longer carry the same meaning . therefore",
    ", in the example shown here , one does not assume that @xmath133 is the number of methods associated with cluster @xmath13 .",
    "we now illustrate how to open up the sum in eq .",
    "( [ f.unify.1 ] ) .",
    "the constraint @xmath134 implies that one only has @xmath135 independent @xmath136s .",
    "once @xmath135 @xmath136s are specified , the remaining one is also determined . to simplify the exposition ,",
    "let us introduce the following notation @xmath137    one then expand the sum in ( [ f.unify.1 ] ) as f ( ) = _ g_1=0^n_1 - 1 _ g_2=0,^n_1 - 1-g_1 ( g_2;2,1 ) _ g_3=0^n_1 - 1-g_1-g_2 ( g_3;3,1 ) ( g_4;4,1 ) + + _ g2=0^n_2 - 1 _ g_1=0^n_2 - 1-g_2 ( g_1;1,2 ) _ g_3=0^n_2 - 1-g_2-g_1 ( g_3;3,2 ) ( g_4;4,2 ) + + _ g3=0^n_3 - 1 _ g_1=0^n_3 - 1-g_3 ( g_1;1,3 ) _ g_2=0^n_3 - 1-g_3-g_1 ( g_2;2,3 ) ( g_4;4,3 ) + + _ g4=0^n_4 - 1 _ g_1=0^n_4 - 1-g_4 ( g_1;1,4 ) _ g_2=0^n_4 - 1-g_4-g_1 ( g_2;2,4 ) ( g_3;3,4 ) .",
    "[ example : a ]    * example  ( b ) * : this example illustrates the possibility of numerical instability associated with eqs .",
    "( [ comb.good ] ) and ( [ f.unify.1 ] ) when they are used to combine _",
    "p_-values with nearly equal weights .",
    "we also show how such instabilities are resolved by using eq .",
    "( [ f.unify.expansion ] ) . consider the case of combining five @xmath0-values , @xmath138 , weighted respectively by @xmath139 .",
    "using eq .",
    "( [ good_tau ] ) , one obtains @xmath140 .",
    "the combined @xmath0-value is then obtained as the probability of attaining a random variable @xmath6 , defined in eq .",
    "( [ good_q ] ) , such that is less than or equal to @xmath141 .    combining @xmath0-values using eq .",
    "( [ comb.good ] ) gives    & ( q_g _ g ) & = 1923475672.53812003 + 134195847.49348195 + & & - 3271698577.16100168 + 1726093852.57087326 - 512066795.44147670 + & & = -0.00000322 .",
    "when one uses equation  ( [ f.unify.1 ] ) , @xmath29 takes the value of @xmath141 and the random variable @xmath142 is simply @xmath6 , and the combined @xmath0-value becomes & ( q ) & = 170090507.09336647 + 21761086.68190728 + & & - 972903041.25101399 + 941269625.31004059 - 512066795.44252247 + & & = -0.00000006 .apparently , probability ca nt be negative and the negative values shown above illustrate how eqs .",
    "( [ comb.good ] ) and ( [ f.unify.1 ] ) may suffer from numerical instability when the weights are nearly degenerate .",
    "this numerical instability is removed by applying equation  ( [ f.unify.expansion ] ) which combines weighted @xmath0-values using a controlled expansion and yields , for this example , & ( q ) & = 5.379093 10 ^ -8 + 1.40730510 ^ -16 + & & -1.066323 10 ^ -21 + 1.634917 10 ^ -25 + o(10 ^ -29 ) + & & = 5.37909 10 ^ -8    * example  ( c ) * : one natural question to ask is that how well does eq .",
    "( [ f.unify.expansion ] ) work when one chooses a larger clustering radius and group weights that are clearly distinguishable into a few clusters ? to consider this case , let us use the five @xmath0-values from example ( b ) above but with weights chosen differently .",
    "let us assume that the inverse weights ( @xmath143 ) associated with these five @xmath0-values are @xmath144 .",
    "for this case , @xmath145 . combining @xmath0-value using formulas ( [ comb.good ] ) yields ( q ) & = & 2.187324 10 ^ -6 - 5.946040 10 ^ -7 + 2.131226",
    "10 ^ -13 + & & - 8.011644 10 ^ -14 + 7.639290 10 ^ -15 + & = & 1.59272 10 ^ -6 , while combining @xmath0-values using ( [ f.unify.1 ] ) yields identical results ( q ) & = & 1.725699 10 ^ -6 -3.049251 10 ^ -7 + 1.311524 10 ^ -13 + & & -6.162803 10 ^ -14 + 7.639290 10 ^ -15 + & = & 1.59272 10 ^ -6 .    when one uses @xmath146 as the clustering radius , one obtains two clusters : one with average inverse weight @xmath147 and the other with average inverse weight @xmath148 .",
    "if one then uses eq .",
    "( [ f.unify.expansion ] ) to combine @xmath0-values , one attains the following results ( q ) & = & 1.472453 10 ^ -6 + 1.171521 10 ^ -7 + 0 + & & + 2.584710 10 ^ -9 + 4.889899 10 ^ -10 + o(10 ^",
    "-12 ) + & = & 1.59268 10 ^ -6 , [ example.exp ] which contains no sign alternation and agrees well with the results from both ( [ comb.good ] ) and ( [ f.unify.1 ] ) .",
    "this illustrates the robustness of eq .",
    "( [ f.unify.expansion ] ) in combining @xmath0-values .",
    "note that the third term on the right hand side of ( [ example.exp ] ) is zero .",
    "this is because the multiplying factor @xmath149 is zero for both clusters . in general",
    ", @xmath149 measures the skewness of inverse weights associated with cluster @xmath13 and for our case here both cluster of inverse weights are perfectly symmetrical with respect to their centers , leading to zero skewness .",
    "if the inverse weights of cluster @xmath13 distribute perfectly symmetrically with respect to its center , it is evident from eq .",
    "( [ ykg.def ] ) that @xmath150 for odd @xmath151 .",
    "evidently if one chooses a large clustering radius @xmath80 and then uses eq .",
    "( [ f.unify.expansion ] ) to combine @xmath0-values , many higher order terms in the expansion will be required to achieve high accuracy in the final combined @xmath0-value .",
    "although the expression ( [ f.unify.0 ] ) provides access to exact statistics for a broader domain of problems and our expansion formula ( [ f.unify.expansion ] ) provides accurate and stable statistics even when nearly degenerate weights are present , there remain a few unanswered questions that should be addressed by the community in the near future . for example , even though we can accommodate any reasonable @xmath0-value weighting , thanks to ( [ f.unify.expansion ] ) , the more difficult question is how does one choose the right set of weights when combining statistical significance  @xcite .",
    "the weights chosen reflects how much does one wish to trust various obtained @xmath0-values .",
    "ideally , a fully systematic method should also provide a metric for choosing appropriate weights . how to obtain the best set of weights",
    "remains an open problem and definitely deserves further investigations .",
    "another limitation of ( [ f.unify.0 ] ) and ( [ f.unify.expansion ] ) , and consequently of fisher s and good s formulas , is that one must assume the @xmath0-values to be combined as independent . in real applications",
    ", it is foreseeable that @xmath0-values reported by various methods may exhibit non - negligible correlations . how to obtain the correlation  @xcite and",
    "properly take into account the existence of @xmath0-value correlations  @xcite is also a challenging problem that we hope to address in the near future .",
    "this work was supported by the intramural research program of the national library of medicine at national institutes of health .",
    "pearson , k. ( 1933 ) . on a method of determining whether a sample of size n supposed to have been drawn from a parent population having a known probability integral has probably been drawn at random .",
    "_ 25 _ , 379410 .",
    "yu , y .- k . , e.  m. gertz , r.  agarwala , a.  a. schaffer , and s.  f. altschul ( 2006 ) .",
    "retrieval accuracy , statistical significance and compositional similarity in protein sequence database searches .  _",
    "34_(20 ) , 596673 ."
  ],
  "abstract_text": [
    "<S> good s formula and fisher s method are frequently used for combining independent @xmath0-values . </S>",
    "<S> interestingly , the equivalent of good s formula already emerged in 1910 and mathematical expressions relevant to even more general situations have been repeatedly derived , albeit in different context . we provide here a novel derivation and show how the analytic formula obtained reduces to the two aforementioned ones as special cases . </S>",
    "<S> the main novelty of this paper , however , is the explicit treatment of nearly degenerate weights , which are known to cause numerical instabilities . </S>",
    "<S> we derive a controlled expansion , in powers of differences in inverse weights , that provides both accurate statistics and stable numerics . </S>"
  ]
}