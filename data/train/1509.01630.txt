{
  "article_text": [
    "consider the following fundamental problem in scheduling theory . we are given a set @xmath2 of @xmath3 independent jobs that must be scheduled without preemption on a collection @xmath4 of @xmath5 parallel machines . if job @xmath6 is scheduled on machine @xmath7 , the processing time required is @xmath8 , which is a positive integer , for every @xmath9 and @xmath10 .",
    "the total time used by machine @xmath11 , or the _ load _ on machine @xmath7 , is the sum of the processing times for the jobs assigned to @xmath7 , and the _ makespan _ of an assignment is the maximum load over all the machines .",
    "the objective is then to find a schedule , which assigns each job to exactly one machine , such that the makespan is minimized .",
    "the wide literature on scheduling often distinguishes between the following scheduling models .",
    "[ [ identical - machines . ] ] identical machines .",
    "job processing times are identical across the machines , i.e. , @xmath12 for all @xmath10 and @xmath11 .",
    "[ [ uniform - machines . ] ] uniform machines .",
    "each machine @xmath7 has a speed @xmath13 .",
    "the length of job @xmath6 on machine @xmath7 is some uniform processing time @xmath14 scaled by the speed @xmath13 , i.e. , @xmath15 for all @xmath16 and @xmath11 .",
    "[ [ unrelated - machines ] ] unrelated machines :    each job @xmath6 may have an arbitrary processing time @xmath17 on machine @xmath7 , for @xmath10 and @xmath11 . +   +",
    "while makespan minimization is known to be np - hard in all models ( even for @xmath18 ) @xcite , the first two models are considered somewhat easier , since the problem can be approximated efficiently in both up to some @xmath19 factor , for any @xmath20 ( see section [ chapter1 related work ] ) .",
    "in contrast , in the unrelated machines model , the problem becomes hard to approximate within a factor better than @xmath21 .",
    "moreover , since 1990 , when the state of the art @xmath22-approximation algorithm was presented by lenstra , shmoys and tardos @xcite , there was no significant improvement on either the upper or lower bound , although the problem was consistently investigated .",
    "this led researchers to consider special cases and improving the bound of @xmath22 , either by a constant factor , or by some function of the input parameters ( see review in section [ chapter1 related work ] ) .    in this work ,",
    "we consider the subclass of _ fully - feasible _ instances .",
    "we say that an instance is fully - feasible if job processing times , @xmath8 , do not exceed the length of the optimal schedule for the instance , for every job @xmath10 and machines @xmath11 .",
    "observe that an optimal schedule never assigns a job to machine on which its length is greater than the makespan of an optimal schedule ; thus , from an optimal scheduler s viewpoint , if @xmath8 exceeds the optimal makespan then @xmath8 is considered to be @xmath23 .",
    "we also consider instances that are almost fully - feasible , that is , for any job @xmath6 , the number of machines on which job @xmath6 is not feasible ( i.e. , has processing time larger than the length of the optimal makespan ) is relatively small .",
    "when considering real - life applications , the general model of unrelated machines , which makes no assumptions on job processing times , seems too broad .",
    "indeed , such applications usually deal with fully - feasible ( or almost fully - feasible ) workloads , as they commonly handle relatively large sets of jobs .",
    "let @xmath24 and @xmath25 denote the optimal makespan and the minimal average machine load over optimal assignments , respectively . for heterogeneous workloads of a huge number of jobs , in which the makespan is counted in months or even years , the processing time of a given job is negligible compared to the makespan ; for such workloads , we have @xmath26 . in this case ,",
    "an algorithm of @xcite , yields a schedule of makespan at most @xmath27 , where @xmath28 , is more suitable .",
    "however , for smaller sets of jobs , @xmath8 can be large relative to @xmath24 , such that @xmath29 , and for these instances our algorithm is the state of the art .",
    "relevant applications for such workloads are e.g. , job packing in warehouse - scale @xcite , large - scale clustering @xcite and applications in parallel design patterns such as fork - join and mapreduce ( see , e.g. , @xcite ) .",
    "[ [ identical - and - uniform - machines ] ] identical and uniform machines    the problem of makespan minimization on identical or uniform machines is known to be np - hard @xcite .",
    "a _ polynomial - time approximation scheme ( ptas ) _ is a family of algorithms @xmath30 , where @xmath31 is a @xmath32-approximation algorithm that runs in time polynomial in the input size but is allowed to be exponential in @xmath33 .",
    "efficient polynomial - time approximation scheme ( eptas ) _ is a ptas with running time @xmath34 , where @xmath35 is the input size , ( for some function @xmath36 ) , while a _ fully polynomial - time approximation scheme ( fptas ) _ runs in time @xmath37 . since the scheduling problem is np - hard in the strong sense already on identical machines ( as it contains bin packing and 3-partition as special cases ) @xcite",
    ", we can not hope for an fptas . for identical machines , hochbaum @xcite and alon et al .",
    "@xcite gave an eptas with running time @xmath38 , where @xmath36 is doubly exponential in @xmath33 , and for uniform machines , jansen @xcite gave an eptas with running time @xmath39 .",
    "[ [ unrelated - machines-1 ] ] unrelated machines    a classic result in scheduling theory is the lenstra - shmoys - tardos @xmath22-approximation algorithm for makespan minimization @xcite .",
    "they also proved that the problem is np - hard to approximate within a factor better than @xmath40 . gairing et al .",
    "@xcite presented a more efficient , combinatorial @xmath22-approximation algorithm based on flow techniques .",
    "shchepin and vakhania @xcite showed that the rounding technique used in @xcite can be modified to derive an improved ratio of @xmath41 .",
    "shmoys and tardos @xcite showed an approximation algorithm that yields a schedule of makespan at most the length of an optimal schedule plus the largest processing time of any job in the instance .    although makespan minimization on unrelated machines is a major open problem in scheduling theory , and",
    "is extensively studied , there was no significant progress on either the upper or lower bound for over two decades , since the publication of [ lst90 ] .",
    "this led researchers to consider interesting special cases and improving the upper bound for them .",
    "a well known special case is the _ restricted assignment problem _ , where jobs have processing times @xmath42 .",
    "svensson @xcite gave a polynomial - time algorithm that approximates the optimal makespan of the restricted assignment problem within a factor of @xmath43 for @xmath44 , and also presented a local search algorithm that will eventually find a schedule of the mentioned approximation guarantee , but is not known to converge in polynomial - time .",
    "gairing et al .",
    "@xcite presented a combinatorial @xmath45-approximation algorithm for the restricted assignment problem .",
    "ebenlendr et al .",
    "considered in @xcite the _ graph balancing _",
    "problem , a special case of the restricted assignment problem where each job @xmath6 has a finite processing time , @xmath46 , on at most two machines .",
    "the paper gives an elaborate @xmath47-approximation algorithm for the problem .",
    "the authors also show that the problem is hard to approximate within a factor less than @xmath21 even on bounded degree graphs , i.e. , when the maximum degree is some constant . in the _ unrelated graph balancing _",
    "problem , introduced by versache and weiss @xcite , each job can be assigned to at most two machines , but processing times are not restricted .",
    "they showed that this subclass of instances constitutes the core difficulty for the _ linear programming _ formulation of makespan minimization on unrelated machines , often used as a first step in obtaining approximate solutions .",
    "specifically , they showed that the strongest known lp - formulation , namely , the configuration - lp , has an integrality gap of @xmath22 .",
    "vakhania et al .",
    "@xcite considered makespan minimization on unrelated machines for the subclass of instances where job lengths can take only two values , @xmath48 and @xmath49 , which are fixed positive integers , such that @xmath50 .",
    "they presented a polynomial - time algorithm that uses linear programming with absolute approximation factor of @xmath49 ( i.e. , all schedules have makespan at most @xmath51 ) .",
    "page @xcite considered restricted assignment instances with processing times in a fixed interval , @xmath52 $ ] , and gave a @xmath53-approximation algorithm , and a @xmath21-approximation algorithm for the case where @xmath54 .",
    "chakrabarty et al .",
    "@xcite considered instances with two types of jobs : _ long _ and _ short _ , namely , @xmath55 for some @xmath20 .",
    "they obtained a @xmath56-approximation algorithm for such instances .    shmoys and tardos",
    "@xcite considered the _ generalized assignment problem ( gap ) _ , where each job @xmath6 incurs a cost of @xmath57 when assigned on machine @xmath7 , and the objective is to minimize the makespan and the total cost .",
    "the paper @xcite presents a polynomial - time algorithm that finds a schedule of makespan at most twice the optimum with optimal cost .",
    "a summary of the known results for unrelated machines is given in table [ table_unrelated ] .",
    ".known results for makespan minimization on unrelated machines .",
    "[ cols=\"^,^,^ \" , ]",
    "consider a scheduling instance @xmath58 , consisting of a set of @xmath5 machines @xmath4 and a set of @xmath3 jobs @xmath2 with non - negative integers @xmath8 denoting the processing time of job @xmath10 on machine @xmath11 .",
    "assignment _ of the jobs to the machines is a bijection @xmath59 where @xmath60 if and only if job @xmath6 is assigned to machine @xmath7 . for any assignment @xmath61 ,",
    "the _ load _ on machine @xmath7 under assignment @xmath61 , denoted as @xmath62 , is the sum of processing times for the jobs that were assigned to machine @xmath7 .",
    "thus , @xmath63 .",
    "the _ makespan _ of an assignment @xmath61 , denoted by @xmath64 , is the maximum load over all the machines .",
    "thus , @xmath65 .",
    "the _ average machine load _ of an assignment @xmath61 , denoted by @xmath66 , is given by @xmath67 .",
    "given an instance @xmath58 , we denote by @xmath24 the optimal makespan , i.e. , @xmath68 , and we denote by @xmath25 the minimum average machine load for an optimal assignment , i.e. , @xmath69",
    ".    given an instance @xmath58 , we say that a job @xmath6 is _ feasible _ on machine @xmath7 , if and only if @xmath70 . the _ feasibility parameter _ of @xmath71 , denoted @xmath72 , is the minimal fraction of feasible machines for any given job , i.e. , @xmath73 . thus , every job @xmath10 is feasible on at least @xmath74 machines . in this terms , an instance @xmath71 is _ fully - feasible _ if and only if @xmath75 .",
    "we often omit @xmath71 in the notation if it is clear from the context , and refer to the feasibility parameter as @xmath76 .",
    "given an instance @xmath58 , an assignment @xmath77 , two positive integers @xmath78 and @xmath79 and some real number @xmath80 , we denote by @xmath81 the subset of machines @xmath7 with @xmath82 , by @xmath83 the subset of machines @xmath7 with @xmath84 , and for all @xmath10 , by @xmath85 the set of machines from @xmath86 that are also legal for job @xmath6 .",
    "for every @xmath11 we denote by @xmath87 the job with the longest processing time , assigned , by @xmath61 , on machine @xmath7 .",
    "given positive integers @xmath78 and @xmath79 , let @xmath88 be an indicator to the assignment of job @xmath6 on machine @xmath7 . consider the following linear program .",
    "@xmath89    one can see that integer solutions to the above lp are in one to one correspondence with assignments @xmath90 of average machine load at most @xmath78 and makespan at most @xmath79 .",
    "[ initial assignment thm ] if @xmath91 is feasible for some @xmath92 , then there is a polynomial - time algorithm that yields a schedule @xmath61 with    1 .",
    "@xmath93 2 .",
    "@xmath94 , @xmath95    let @xmath96 be a fractional solution to @xmath91 .",
    "we round @xmath97 to an integer solution using the following classic rounding technique , also used in @xcite .",
    "let @xmath98 .",
    "each machine is partitioned into @xmath99 sub - machines @xmath100 , @xmath101 .",
    "an edge weighted , bipartite graph @xmath102 is constructed , where @xmath103 representing the jobs and @xmath104 representing the sub - machines .",
    "the edges are constructed in the following way .",
    "consider the nodes @xmath105 as bins of unit capacity and the nodes @xmath106 , as pieces of size @xmath88 .",
    "for every machine @xmath11 , consider the nodes in non - increasing order of the processing time of the corresponding job , on machine @xmath7 .",
    "for convenience , assume @xmath107 .",
    "an edge @xmath108 with cost @xmath8 is constructed if and only if a positive fraction of @xmath88 is packed in the bin @xmath105 .",
    "the packing of the bins ( and construction of the edges ) is done in the following way .",
    "the bins @xmath109 are packed one by one , with the pieces in the order @xmath110 . while @xmath105 is not totally packed ,",
    "( otherwise we consider the next bin ) we continue packing the next piece such that if its size , @xmath88 , fits @xmath105 ( without causing an overflow ) it is packed to @xmath105 , else , if it causes an overflow , only a fraction @xmath111 of @xmath88 is packed to @xmath105 , consuming all the remaining volume of @xmath105 , and the remaining part of @xmath112 is packed in @xmath113 .",
    "figure [ rounding ] gives a pictorial example of this construction .",
    "the rounding is done by finding a minimum - cost integer matching @xmath114 that matches all job nodes , and for every edge @xmath115 , set @xmath60 i.e. , assign job @xmath6 on machine @xmath7 .    by taking a minimum - cost integer matching",
    "it is guaranteed that @xmath116 , or @xmath93 . by the construction of the graph",
    "it is guaranteed that the load on machine @xmath7 , for every @xmath11 , is at most @xmath117 , where @xmath118 . since @xmath119 ( for a detailed proof , see @xcite ) , we get that @xmath120 for all @xmath11",
    ".    this result will be helpful in our approximation algorithm .",
    "recall that an instance @xmath71 is _ fully - feasible _ if and only if @xmath70 for every job @xmath10 and machine @xmath11 .",
    "although fully - feasible instances are hard to identify , we give a polynomial - time algorithm that yields for such instances an assignment whose makespan is better than twice the optimal makespan , the best known ratio for general instances .",
    "our main result is as follows .",
    "[ fully - feasible thm ] there is a polynomial - time algorithm that yields for fully - feasible instances an assignment of makespan at most @xmath121 .",
    "note that always @xmath122 .",
    "@xmath123 occurs only in case where _",
    "every _ optimal assignment is perfectly balanced ( i.e. , the load on all the machines equals @xmath24 ) .",
    "thus , in the typical case we get @xmath124 , which means that in the typical case our algorithm guaranteed a bound that is strictly better that twice the optimum .",
    "the following theorem shows that the problem remains hard already when considering only the class of fully - feasible instances .",
    "makespan minimization on unrelated machines is hard to approximate within factor @xmath125 , already in the class of fully - feasible instances .",
    "the proof of the hardness result follows from a reduction from @xmath126-dimensional matching as in @xcite .",
    "we prove a stronger result , that also shows that our result is robust under small violations of the feasibility constraints .",
    "namely , we show that we can get better bounds also when our instance is not fully - feasible but has the property that every job can be non - feasible on some _ small _ fraction of the machines . for this",
    ", we will need some definitions .",
    "job @xmath10 is feasible on machine @xmath11 if @xmath70    the feasibility parameter of instance @xmath71 is defined as @xmath127    in these terms , we have that every job @xmath10 is feasible on at least @xmath74 machines .",
    "moreover , an instance @xmath71 is fully - feasible if and only if @xmath75 .",
    "@xmath128    given an instance @xmath71 , we can fix @xmath78 and @xmath79 to be the minimal values such that @xmath91 is feasible in polynomial - time in the size of the input @xmath129 , using binary search on some feasible regions for @xmath78 and @xmath79 . at the end of this operation , @xmath78 and @xmath79 will satisfy @xmath92 , @xmath130 and @xmath131 .",
    "[ general main theorem ] there is a polynomial - time algorithm that , given the values @xmath92 , yields for instances @xmath71 with feasibility parameter @xmath132 , an assignment of makespan at most @xmath133    the statement of theorem [ fully - feasible thm ] follows directly from [ general main theorem ] , since the feasibility parameter of fully - feasible instances is @xmath134 .    given a general scheduling instance @xmath71 ,",
    "its optimal makespan , @xmath24 , nor its feasibility parameter , @xmath72 , can not be computed in polynomial - time , unless @xmath135 .",
    "however , let @xmath136 be the number of distinct processing times @xmath8 of an instance @xmath71 and w.l.o.g assume that @xmath137 are the distinct processing times of @xmath71 . if we denote @xmath138 , then we see that @xmath24 can belong to exactly one of the regions",
    "@xmath139 for some @xmath140 .",
    "if @xmath141 for some @xmath140 , then job @xmath10 is feasible on some machine @xmath11 if and only if @xmath142 .",
    "therefore , @xmath141 if and only if @xmath143 .",
    "@xmath144    we prove the theorem by describing an algorithm that admits the desired bound on the makespan , for instances with _",
    "large _ enough feasibility parameter .",
    "the first step of the algorithm is to find the minimal @xmath79 and @xmath78 such that @xmath91 is feasible .",
    "next , it obtains a fractional solution to @xmath91 and rounds it to obtain an initial assignment @xmath61 , such that @xmath93 and @xmath94 , @xmath95 , as in theorem [ initial assignment thm ] .",
    "then , for each guess of the optimal makespan region and the corresponding feasibility parameter , it tries to fix the initial assignment to achieve a new assignment of makespan at most @xmath145 ( and unless the feasibility parameter is too large , it will succeed for the right guess ) .",
    "this is done by balancing the initial assignment such as to reduce the load of the overloaded machines to meet the desired makespan .",
    "we first prove the following lemmas .    [ enough_good_machines ]",
    "let @xmath61 be an assignment for some instance @xmath58 such that @xmath93 , let @xmath146 and let @xmath80 .",
    ". then    1 .",
    "2 .   @xmath149 .",
    "each machine @xmath150 has load greater than @xmath151 , therefore @xmath152 .    1 .",
    "assume that @xmath153 , then + @xmath154 + the last inequality follows from the fact that @xmath155 .",
    "hence , the average machine load is greater than @xmath78 , a contradiction .",
    "it follows that @xmath148 .",
    "2 .   let @xmath156 .",
    "then , there are @xmath157 machines having loads greater than @xmath158 .",
    "assume that @xmath159 , then + @xmath160 + hence , the average machine load is greater than @xmath78 , a contradiction .",
    "it follows that @xmath161 .",
    "let @xmath162 be an instance with feasibility parameter @xmath76 .",
    "let @xmath61 be an assignment for @xmath71 with average machine load @xmath78 and let @xmath163 .",
    "if @xmath164 then for every subset @xmath165 , @xmath166 , where @xmath167 is the set of neighbors of @xmath168 in @xmath169 .",
    "let @xmath170 .",
    "since the number of illegal machines for any job @xmath6 is at most @xmath171 , the number of good machines for job @xmath6 is at least the number of good machines minus its illegal machines ( the worst case where all illegal machines for job @xmath6 are contained in @xmath172 ) .",
    "together with lemma [ enough_good_machines ] we have    @xmath173    the last inequality follows from the fact that @xmath174 .",
    "now , let @xmath175",
    ". then @xmath176 .",
    "recall that the set of neighbors of @xmath168 is the set of machines that are good for all the jobs @xmath177 , @xmath178 , i.e. , @xmath179 .",
    "obviously @xmath180 for some @xmath178 .",
    "it follows from the above that @xmath181 .",
    "since @xmath182 we have that @xmath166 .    by hall",
    "s theorem @xcite , there exist a perfect matching in @xmath169 if and only if for every @xmath165 , @xmath183 thus , we have    [ lemma : hall ] there exists a perfect matching in @xmath169 .    by the above discussion , we can modify the initial assignment @xmath61 , by finding a perfect matching in @xmath169 and then transferring jobs from bad machines to their matching good machines .",
    "we describe this formally in algorithm @xmath184 .    1 .   use binary search to find the minimal @xmath79 , such that @xmath185 is feasible .",
    "next , with that @xmath79 fixed , search for the minimal @xmath78 such that @xmath91 is feasible .",
    "2 .   solve the linear relaxation @xmath91 .",
    "3 .   round the solution to obtain an integral assignment @xmath61 using a rounding technique as given in theorem [ initial assignment thm ] .",
    "[ alg : step3 ] 4 .   for every @xmath186 , where @xmath136 is the number of distinct processing times of @xmath71 , guess that @xmath141 and that @xmath187",
    ". 1 .   if @xmath188 , continue",
    ". 2 .   otherwise , construct the bipartite graph @xmath189 and find a perfect matching of size @xmath190 , if one exists .",
    "if not , continue .",
    "3 .   obtain a resulting assignment @xmath191 from @xmath61 by transferring the longest job , @xmath177 from each machine @xmath192 , to its matching machine @xmath193 .",
    "return the assignment @xmath191 with minimal makespan .",
    "* proof of theorem [ general main theorem ] .",
    "* we show that the assignment output by algorithm @xmath184 satisfies the statement of the theorem .",
    "consider a general instance @xmath71 . by performing binary search on a feasible bounded region of the optimal makespan",
    "we can find the minimal @xmath79 for which @xmath185 is feasible , and then by performing binary search on a feasible bounded region of the optimal average machine load we can find the minimal @xmath78 for which @xmath91 is feasible .",
    "these integers satisfy that @xmath194 , @xmath130 and @xmath92 .    by theorem [ initial assignment thm ] , since @xmath91 is feasible then step [ alg : step3 ] is guaranteed to generate an assignment @xmath61 of @xmath93 and @xmath195 , for all @xmath11 .",
    "let @xmath164 be the feasibility parameter of @xmath71 .",
    "then for some @xmath186 , where @xmath136 is the number of distinct processing times in @xmath71 , @xmath196 . then , by corollary [ lemma : hall ] , there exists a perfect matching in @xmath189 and we will find it in step @xmath197 in @xmath184 .",
    "let @xmath198 and let @xmath199 be a perfect matching in @xmath189 .    for any machine @xmath200 , @xmath201 .",
    "let @xmath177 be the largest job processed by @xmath61 on machine @xmath7 .",
    "then , @xmath202 , thus removing @xmath177 from machine @xmath7 guarantees that the new load of machine @xmath7 will be at most @xmath79 .",
    "as for the good machines , if @xmath7 is a good machine for job @xmath6 then @xmath142 .",
    "therefore , transferring @xmath6 to @xmath7 will increase the load of @xmath7 by at most @xmath203 which is at most @xmath24 ( since @xmath141 ) . since the load of a good machine is at most @xmath204",
    ", we have that after such a job transfer the load will be at most @xmath205 .",
    "the load on the rest of the machines stays unchained , i.e. , @xmath206 , for all @xmath207 .",
    "thus , by performing the large - jobs transfers for all pairs @xmath208 , @xmath209 , we obtain a new assignment @xmath191 , with @xmath210 for all @xmath11 , which is at most @xmath211 , since @xmath130 and @xmath131 .",
    "@xmath212    the complexity of @xmath184 is @xmath213 .",
    "we will show that step 1 in @xmath214 is the bottle - neck of the algorithm . in this step",
    "we perform a binary search on the feasible regions of @xmath79 and @xmath78 while solving @xmath91 .",
    "since the feasible region for both @xmath79 and @xmath78 is @xmath215 $ ] , we solve the lp @xmath216 times . solving the lp",
    "can be done in time @xmath217 @xcite , so overall this operation runs in @xmath213 .",
    "the number of vertices in the bipartite graph @xmath218 equals to the number of bad and good machines , which is at most @xmath5 . from [ enough_good_machines ] , the number of bad machines is at most @xmath219 , thus the number of edges in the bipartite graph is at most @xmath220 ( the last two inequalities are due to @xmath221 ) . therefore finding a perfect matching in @xmath218",
    "can be done in time @xmath222 @xcite . in @xmath184",
    ", we find a perfect matching for every @xmath223 , where @xmath224 is the number of distinct processing times .",
    "thus , the complexity of step 4 sums to @xmath225 .",
    "step 2 is done in @xmath217 time and step 3 is done in @xmath226 @xcite .    therefore , the overall complexity of the algorithm is @xmath213 .      in this section",
    "we consider the restricted version of our problem , where @xmath227 , for each job @xmath10 , and each machine @xmath11 .",
    "this subclass is np - hard to approximate within a factor better than @xmath21 , which is also the best known lower bound for the general version @xcite . in the restricted version , any job @xmath6 with processing time @xmath228 is feasible on machine @xmath7 , since @xmath229 for every @xmath10 .",
    "hence , the feasibility parameter of a restricted instance @xmath71 is exactly @xmath230 , which can be computed efficiently .",
    "fully - feasible restricted instances correspond to the identical machines instances , hence we do not consider especially fully - feasible instances in this case . also , we say that an assignment @xmath231 is _ feasible _ if @xmath228 for every machine @xmath7 and job @xmath6 such that @xmath60 .    for this variant , we show that a better bound than in theorem [ general main theorem ] can be achieved by a much simpler and more efficient combinatorial algorithm , and for every feasibility parameter .",
    "denote by @xmath232 the largest processing time of some restricted instance @xmath233 .",
    "gairing et al .",
    "@xcite presented a @xmath45-approximation algorithm for the restricted assignment problem . using techniques from @xcite",
    ", we obtain an approximation algorithm which yields an assignment of makespan at most @xmath234 , where @xmath76 , is the feasibility parameter of the instance .",
    "[ [ sec : gairing overview ] ] overview of the algorithm of gairing et al .",
    "we describe below the procedure @xmath235 , used in @xcite .",
    "let @xmath71 be an instance for the restricted assignment problem .",
    "let @xmath236 be an integer that will be determined by binary search , to be a lower bound on @xmath24 .",
    "let @xmath61 be a feasible assignment and let @xmath237 be a directed bipartite graph where @xmath238 consists of the job nodes , and @xmath239 consists of the machine nodes .",
    "for any job node @xmath106 and any machine node @xmath240 , if @xmath60 there is an arc in @xmath241 oriented from @xmath240 to @xmath106 ; if @xmath242 and @xmath6 is feasible on machine @xmath7 , then there is an arc in @xmath241 oriented from @xmath106 to @xmath240 .    given a feasible assignment @xmath61 ,",
    "consider the partition of machines into three subsets : @xmath243 ( overloaded ) , @xmath244 ( underloaded ) , and @xmath245 ( all the remaining machines ) .",
    "a machine @xmath246 is overloaded if @xmath247 . a machine @xmath248 is underloaded if @xmath249 .",
    "the remaining machines , which are neither overloaded nor underloaded , form the set @xmath250 .",
    "the procedure @xmath251 starts with some initial feasible assignment of jobs to machines and iteratively improves the makespan until it obtains an assignment with makespan of @xmath252 , or declares that an assignment of makespan @xmath236 does not exist . in each iteration",
    ", the algorithm finds an augmenting path in @xmath253 , from an overloaded machine to an underloaded machine , and pushes jobs along this path , by performing a series of job reassignments between machines on that path .",
    "this results in balancing the load over the machines , i.e. , reducing the load of the source that is an overloaded machine , and increasing the load of the destination that is an underloaded machine , while preserving the load of all other machines .",
    "figure [ augmenting ] gives a pictorial example of this operation .",
    "@xmath254 terminates when there is no path from an overloaded machine to an underloaded machine in @xmath253 , and this occurs after @xmath255 steps , where @xmath256 .",
    "let @xmath257 be the resulting assignment after @xmath251 terminates .",
    "then , it is shown in @xcite that if @xmath258 , then @xmath259 .",
    "the procedure @xmath254 combined with a binary search over the possible range of values for @xmath236 , is used to identify the smallest @xmath236 such that a call to @xmath251 returns an assignment @xmath257 with @xmath260 .",
    "this yields the approximation ratio of @xmath261 .",
    "the running time of the approximation algorithm is factored by a value that is logarithmic in the size of the range in which we search for @xmath236 , e.g. , @xmath262 $ ] .",
    "thus , the algorithm of @xcite computes an assignment having makespan within a factor of @xmath261 from the optimal in time @xmath263 , where @xmath264 .",
    "let @xmath71 be an instance of the restricted assignment problem .",
    "the feasibility parameter of @xmath71 is exactly @xmath265 .",
    "let @xmath61 be an initial feasible assignment for @xmath71 , and consider the bipartite graph @xmath253 .",
    "note that any feasible assignment @xmath61 for an instance of the restricted assignment problem has an average machine load @xmath266 thus , @xmath267 for any instance @xmath71 .",
    "our algorithm proceeds as follows .    1 .",
    "fix @xmath268 .",
    "2 .   apply @xmath269 and return the resulting assignment .",
    "[ thm : approx_ratio_restricted ] for any instance @xmath71 with feasibility parameter @xmath270 , algorithm [ alg_restricted ] yields a schedule of makespan at most @xmath271 , in time @xmath272 .",
    "let @xmath233 , be an instances with feasibility parameter @xmath273 , for some @xmath274 .",
    "then algorithm [ alg_restricted ] yields a schedule of makespan at most @xmath275 .",
    "therefore , for instances with sufficiently large @xmath276 ( which is equivalent to a large feasibility parameter ) , namely @xmath276 such that @xmath277 , we get a schedule with a makespan better than twice the optimal makespan .",
    "let @xmath278 , then for instances with feasibility parameter @xmath279 such that @xmath280 , algorithm [ alg_restricted ] is a @xmath281-approximation algorithm .",
    "the correctness of theorem [ thm : approx_ratio_restricted ] follows from the next lemma .",
    "[ lemma : ubf ] let @xmath71 be an instance with feasibility parameter @xmath282 .",
    "let @xmath61 be an initial feasible assignment for @xmath71 .",
    "then @xmath283 terminates with @xmath284 .",
    "let @xmath257 be the assignment when @xmath285 terminates .",
    "at this point , there is no path from a machine in @xmath286 to a machine in @xmath287 in the graph @xmath288 .",
    "assume that @xmath289 .",
    "then there exists a machine @xmath290 with @xmath291 .",
    "denote by @xmath292 the set of machines @xmath7 such that @xmath240 is reachable from @xmath293 , then @xmath294 .",
    "obviously , there exists a job @xmath295 , such that @xmath296 .",
    "thus , there is an edge @xmath297 in @xmath288 .",
    "since @xmath76 is the feasibility parameter of @xmath71 , there exists at least @xmath298 machines on which @xmath299 is feasible , i.e. , there exists an edge from @xmath299 to each one of these machines . by appending each of these edges to @xmath297",
    "we get a directed path from @xmath293 to at least @xmath298 machines ( including @xmath293 ) .",
    "therefore , we conclude that @xmath300 .",
    "now , we compute a lower bound on the average machine load for @xmath257 , by summing the loads of all the machines @xmath301 .",
    "we have that @xmath302 , thus @xmath303 .",
    "also , there is no path from @xmath293 to machines in @xmath287 , and therefore @xmath304 .",
    "thus , for all @xmath305 it holds that @xmath306 .",
    "hence ,    @xmath307    we have shown that the sum of loads of the assignment @xmath257 is greater than @xmath308 . hence , the average load for @xmath257 is greater than @xmath25 . a contradiction . by [ avg_machin_load ] , the average load of any schedule , and in particular @xmath257 , can not exceed @xmath25 .",
    "* proof of theorem [ thm : approx_ratio_restricted ] .",
    "* let @xmath71 be an instance with feasibility parameter @xmath76 .",
    "let @xmath61 be some initial feasible assignment .",
    "by lemma [ lemma : ubf ] , when @xmath309 terminates , @xmath284 .",
    "therefore , the maximum load of the resulting assignment is at most @xmath310 .",
    "the running time of the algorithm equals to the running time of one call to @xmath254 , which is @xmath255 , where @xmath256 .",
    "since @xmath311 for every instance @xmath71 , the algorithm terminates after @xmath272 steps .",
    "note that our algorithm has better running time than the algorithm of @xcite , since we use a single call to the procedure @xmath254 , in contrast to the @xmath45-approximation algorithm of @xcite , which uses binary search to find the best value for @xmath236 , resulting in an overall running time of @xmath263 , where @xmath264 is the sum of processing times of all jobs .",
    "some problems can be solved exactly , or approximately , by algorithms that are exponential only in the size of a fixed parameter while polynomial in the size of the input .",
    "such an ( approximation ) algorithm is called a _",
    "fixed - parameter tractable ( fpt ) _ ( approximation ) algorithm , because the problem can be ( approximately ) solved efficiently for small values of the fixed parameter .",
    "problems in which some parameter @xmath313 is fixed are called parameterized problems . a parameterized problem that allows for such an fpt algorithm",
    "is said to be a _",
    "fixed - parameter tractable _ problem and belongs to the class fpt .",
    "we give some definitions formalizing this concept .",
    "a problem is said to be fpt if it can be solved by an algorithm @xmath314 that runs in time @xmath315 , for every instance @xmath71 with parameter @xmath313 , and where @xmath36 is a function independent of @xmath35 .",
    "the algorithm @xmath316 is called an fpt algorithm .",
    "we can similarly define fpt - approximation algorithms .",
    "a problem is said to have an @xmath281-fpt approximation algorithm , if there exists an @xmath281-approximation algorithm @xmath316 to the problem , that runs in time @xmath315 , for every instance @xmath71 with parameter @xmath313 , and where @xmath36 is a function independent of @xmath35 .    a family @xmath317 , where @xmath318 is a @xmath32-fpt approximation algorithm for all @xmath20 , is called a parametrized approximation scheme .",
    "consider the problem of minimizing the makespan on unrelated machines , i.e. , scheduling a set @xmath2 of @xmath3 jobs , @xmath319 , on a set @xmath4 of @xmath5 unrelated parallel machines , @xmath11 , where each job @xmath6 has a processing time of @xmath8 on machine @xmath7 and the objective is to find a schedule with minimum makespan .    our parameter @xmath313 of a scheduling instance is the number of machine - job pairs @xmath320 such that @xmath321 for some @xmath322 $ ] and a feasible value @xmath79 .",
    "we will show that by rounding a solution to the milp formulation of the problem where the @xmath313 variables @xmath88 such that @xmath321 are integral , we can get an assignment with makespan at most @xmath32 the optimal makespan .    given a positive integer @xmath79 ,",
    "let @xmath88 be an indicator to the assignment of job @xmath6 on machine @xmath7 .",
    "consider the following mixed integer linear program .",
    "@xmath323    one can see that integer solutions to the above milp are in one to one correspondence with assignments @xmath324 of makespan at most t , and that any feasible solution to @xmath325 has the property that the variables @xmath88 , such that @xmath326 , are integral .",
    "+    let @xmath71 be a scheduling instance , let @xmath327 $ ] and let @xmath79 be a positive integer such that @xmath328 is feasible .",
    "then an assignment of makespan at most @xmath329 can be found in time @xmath330 , where @xmath331 .",
    "let @xmath88 , @xmath200 , @xmath332 be a solution to @xmath333 .",
    "then for every pair @xmath320 such that @xmath321 , the corresponding @xmath88 is either 0 or 1 .",
    "let @xmath334 be the number of jobs @xmath6 for which @xmath321 on machine @xmath7 and such that the corresponding variable @xmath88 equals to @xmath134 .",
    "recall the rounding technique as in theorem [ initial assignment thm ] .",
    "then the first @xmath334 slots of machine @xmath7 are full and therefore the capacity left in the slots for the other jobs , with @xmath335 is @xmath336 . from theorem [ initial assignment thm ]",
    ", we get that the jobs that are assigned by the rounding to the remaining slots @xmath337 ( where @xmath98 ) contribute at most @xmath338 to the load of machine @xmath7 .",
    "therefore the load of machine @xmath7 is at most @xmath339 .",
    "now , @xmath340 , and therefore the total load of machine @xmath7 is at most @xmath329 .",
    "the algorithm runs in time @xmath330 , since the bottle - neck of the algorithm is obtaining a feasible solution to the milp .",
    "this is done by brute - force search of at most @xmath341 possible binary values for all the variables @xmath88 corresponding to @xmath342 , by fixing them and finding a solution for the resulting lp which can be done in polynomial - time in @xmath35 @xcite .      in this section",
    "we consider the special case of the restricted assignment problem , where each job can be assigned to at most two machines , with the same processing time on either machine .",
    "for this special case , ebenlendr et al.@xcite presented a 1.75-approximation algorithm for the minimum makespan problem .",
    "an instance of the scheduling problem can be modeled as an undirected , multi - graph , with @xmath5 nodes ( a node for each machine ) and @xmath3 edges , such that every job @xmath6 is associated with an edge of weight @xmath343 between both machine nodes on which it can be processed , or a loop of weight @xmath343 on the only machine node on which it can be processed .",
    "minimizing the makespan is then equivalent to the problem of _ graph - balancing _ , i.e. , of orienting each edge , such that the maximum weighted in - degree over all nodes is minimized .",
    "we exploit this graph representation of the problem to develop an fpt algorithm for this case .",
    "the maximum degree @xmath281 of an undirected graph @xmath344 is the maximum number of neighbors of any vertex , i.e. , @xmath345 , where @xmath346 .",
    "we give below an fpt algorithm for graph balancing , where the parameters are the width of the tree decomposition of the graph , and the maximum degree of the graph .",
    "note that we can not hope for obtaining an fpt algorithm with the fixed parameter being only the maximum degree of the graph , as from the hardness proof for general instance @xcite , if follows that he problem is hard to approximate within a factor less than @xmath21 even on bounded degree graphs , i.e. , when the maximum degree is some constant .",
    "intuitively , a tree decomposition represents the vertices of a given graph @xmath347 as subtrees of a tree , in such a way that vertices in the given graph are adjacent only when the corresponding subtrees intersect .",
    "[ tree_decomposition_def ] given a graph @xmath348 , a tree decomposition is a pair @xmath349 , where @xmath350 is a family of subsets of @xmath351 ( also called bags ) , and @xmath79 is a tree whose nodes are the subsets @xmath352 , satisfying the following properties :    1 .",
    "the union of all sets @xmath352 equals @xmath351 .",
    "that is , each graph vertex is associated with at least one tree node .",
    "2 .   for every edge @xmath353 in the graph",
    ", there is a subset @xmath352 that contains both @xmath354 and @xmath355 .",
    "that is , vertices are adjacent in the graph only when the corresponding subtrees have a node in common .",
    "if @xmath352 and @xmath356 both contain a vertex @xmath354 , then all nodes @xmath357 of the tree in the ( unique ) path between @xmath352 and @xmath356 contain @xmath354 as well",
    ". that is , the nodes associated with vertex @xmath354 form a connected subset of @xmath79 . it can be stated equivalently that if @xmath352 , @xmath356 and @xmath357 are nodes , and @xmath357 is on the path from @xmath352 to @xmath356 , then @xmath358 .",
    "the width of a tree decomposition is the size of its largest set @xmath352 minus one .",
    "the treewidth @xmath359 of a graph @xmath347 is the minimum width among all possible tree decompositions of @xmath347 .",
    "it is observed in @xcite , that many algorithmic problems that are np - complete for arbitrary graphs can be solved efficiently by dynamic programming for graphs of bounded treewidth , using the tree decompositions of these graphs .",
    "we show that the problem of graph balancing can be solved efficiently by dynamic programming for graphs of bounded treewidth and bounded vertex degree ( the maximum number of neighbors of a vertex ) .",
    "let @xmath347 be an undirected edge weighted multi - graph , with given tree decomposition @xmath360 of width @xmath355 .",
    "then the graph balancing problem parameterized by the graph treewidth and the maximum degree , @xmath281 , is solvable in time @xmath361 .",
    "we show how the problem can be solved using dynamic programing on the tree decomposition of @xmath347 .",
    "the idea is to examine for each bag @xmath362 all the possibilities of feasible assignments to the machines represented by the vertices in the bag @xmath352 , and the jobs represented by the edges of the subgraph @xmath363 $ ] , induced by the vertices in bag @xmath352 .",
    "this information is stored in a table @xmath364 corresponding to each bag @xmath352 . the tables will be updated in a post - order manner , starting at the leaves of the tree decomposition and ending at the root . during this update process , it is guaranteed that local solutions for each subgraph corresponding to a bag of the tree decomposition are combined into a global optimal solution for the overall graph @xmath347 .",
    "the algorithmic details are as follows .",
    "[ [ step-0 ] ] step 0 :    set an initial orientation on the edges of the graph @xmath347 . for",
    "each bag @xmath365 , @xmath366 , let @xmath367=\\{e_{1}^{i}, ...",
    ",e_{m_{i}}^{i}\\}$ ] , @xmath368}|=m_i$ ] .",
    "compute the following table of @xmath369 rows , and @xmath370 columns : +    @xmath371    the table consists of @xmath372 rows and @xmath373 columns .",
    "each row represents an assignment to the sub - problem induced by the subgraph @xmath363 $ ] .",
    "each row is a 0 - 1 sequence of length @xmath374 that determines which of the edges in @xmath363 $ ] is directed oppositely than its direction in the given initial orientation ( 1 if it is the opposite orientation , and 0 otherwise ) .",
    "formally , we can describe an assignment by a mapping @xmath375=\\{e_{i_{1}}, ... ,e_{i_{m_{i}}}\\}\\rightarrow\\{0,1\\}.\\ ] ] given the mapping @xmath376 , let @xmath377 denote the set of incoming edges for @xmath378 , for @xmath379 .",
    "the last column , @xmath380 , is the makespan of the assignment @xmath376 .",
    "[ [ step-1 ] ] step 1 :    table initialization .",
    "for every table @xmath364 and assignment @xmath381\\rightarrow\\{0,1\\}$ ] set @xmath382    for every @xmath383 , where @xmath384 is the cost of edge @xmath385 , which corresponds to the processing time of the job associated with the edge @xmath385 .",
    "[ [ step-2 ] ] step 2 :    dynamic programming .",
    "we now go through the tree decomposition of @xmath347 , from the leaves to the root , and compare the corresponding tables against each other .",
    "let @xmath7 be the parent node of @xmath6 .",
    "we show how the table for @xmath352 can be updated by the table for @xmath356 .",
    "assume that @xmath386 and @xmath387 , and that @xmath388=\\{e_{1}, .. ,e_{t},e_{1}^{i}, ... ,e_{m_{i}-t}^{i}\\}$ ] and @xmath389=\\{e_{1},",
    ".. ,e_{t},e_{1}^{j}, ... ,e_{m_{j}-t}^{j}\\}$ ] .    for each assignment @xmath390 , and each extension @xmath391\\rightarrow\\{0,1\\}$ ] of @xmath168 , we consider an assignment @xmath392 , which is an extension of @xmath168 , that minimizes the new makespan , i.e. , for each assignment @xmath392 , which is an extension of @xmath168 , we calculate @xmath393\\cap e[x_j]\\wedge e\\in in(u_k ) } c(e),\\ ] ] for @xmath394 .",
    "then , we calculate the makespan @xmath395\\ ] ] we update the entry for @xmath376 with @xmath396 and @xmath397 for @xmath398 .",
    "the values of @xmath399 , @xmath400 , and @xmath380 grows by the minimal value for the makespan of the assignment problem induced by all the vertices contained in the subtree rooted at node @xmath7 .",
    "if @xmath7 has several children @xmath401 , then table @xmath402 is updated successively against all tables @xmath403 in the same way .",
    "all this is repeated until the root node is finally updated .",
    "[ [ step-3 ] ] step 3 :    construction of a minimum makespan assignment .",
    "the length of a minimum makespan assignment is derived from the minimal entry of the last column , @xmath380 , of the root node table .",
    "the assignment of the corresponding row shows where to assign the jobs represented by the edges in the subgraph induced by the vertices of the root bag . by recording in step 2 how the respective minimum of each bag was determined by its children",
    ", one can easily determine the assignment of all edges in the graph .",
    "this concludes the description of the dynamic programming algorithm .",
    "it remains to show its correctness and running time .    1 .",
    "the first and second conditions in definition [ tree_decomposition_def ] , namely @xmath404 and @xmath405 $ ] , guarantee that every machine and job in the instance is considered through the computation .",
    "2 .   the third condition in definition [ tree_decomposition_def ] guarantees the consistency of the dynamic programming .",
    "if a vertex @xmath406 occurs in two different bags @xmath407 and @xmath408 , then it is guaranteed that for the computed minimum makespan assignment only one set of jobs can be scheduled on the machine associated with that vertex @xmath354 .    as for the running time of the algorithm , for each edge @xmath409 in the tree decomposition of @xmath347 , and for each of @xmath369 assignments @xmath376 , we go over all the assignments @xmath392 that agree with @xmath376 on the edges in @xmath388\\cap e[x_j]$ ] ( at most @xmath410 ) , and do a computation of time @xmath411 .",
    "this results in complexity of @xmath412 . since @xmath413 and @xmath414 for all @xmath415",
    ", we have that the complexity of the algorithm is @xmath416 .",
    "let @xmath417 and @xmath418 denote the makespan minimization problems on identical and uniform machines , respectively . in the _ reoptimization _ model developed in @xcite , we consider instances of the scheduling problem that can change dynamically over time . our goal is to compute assignments within some guaranteed approximation for the new problem instances , derived from the previous instances .",
    "since the transition from one assignment to another incurs some cost ( for example , the cost of pausing the execution of a process on one machine and resuming its execution on another ) , an additional goal is to have the solution for the new instance _ close _ to the original one ( under a certain distance measure ) .",
    "let @xmath419 ) be an instance of jobs and machines .",
    "let @xmath420 and @xmath421 and let @xmath422 be some initial assignment for @xmath423 .",
    "we denote by @xmath424 a new instance derived from @xmath423 by an admissible operation , e.g. , addition or removal of jobs and/or machines . for any job @xmath425 and a feasible assignment @xmath324",
    ", we are given the transition cost of @xmath6 when moving from the initial assignment @xmath426 to @xmath61 .",
    "we denote this transition cost by @xmath427 .",
    "the goal is to find an optimal assignment for @xmath71 , for which the total transition cost , given by @xmath428 , is minimized .",
    "recall that , given an optimization problem @xmath429 , we denote by @xmath430 the reoptimization version of @xmath429 .",
    "an algorithm @xmath431 yields an @xmath432-reapproximation for @xmath433 ( @xmath434 ) ) , for @xmath435 , if for any instance @xmath71 for @xmath417 ( @xmath418 ) , @xmath431 outputs an assignment of makespan at most @xmath436 times the minimal makespan for @xmath71 , and of total transition cost at most @xmath281 times the minimal transition cost to an optimal assignment for @xmath71 .",
    "we consider below the case where transition costs can take values in @xmath437 . in particular , job @xmath438 incurs a unit transition cost either if @xmath439 @xmath440 and is moved to a different machine in the schedule for @xmath441 , or @xmath442 @xmath443 , i.e. , @xmath6 is assigned to a machine for the first time in the schedule for @xmath71 .",
    "otherwise , the transition cost for job @xmath6 is equal to @xmath444 .",
    "formally , @xmath445 if @xmath446 , or if @xmath447 and @xmath448 ; otherwise , @xmath449 .    a polynomial time reapproximation scheme ( ptrs ) for @xmath450 is an algorithm that , given the inputs @xmath451 and @xmath452 for @xmath450 and parameters @xmath453 , yields a @xmath454-reapproximation for @xmath450 , in time polynomial in @xmath455 and @xmath129 .",
    "we present below a reapproximation algorithm , @xmath457 , for the problem of minimizing the makespan on identical machines .",
    "the algorithm uses a _",
    "relaxed _ packing of items in bins , where the items correspond to jobs , and the bins represent the set of machines .",
    "given a set of bins , each of capacity @xmath458 , and a set of items packed in the bins , we say that the packing is _",
    "@xmath459- relaxed _ , for some @xmath1 , if the total size of items assigned to each bin is at most @xmath460 .",
    "our algorithm for reoptimizaing makespan minimization on identical machines accepts as input the instances @xmath451 and @xmath71 , the initial assignment of jobs to the machines , @xmath461 , and an error parameter @xmath44 .",
    "the algorithm proceeds as follows .",
    "we apply a @xmath32-approximation algorithm @xcite on the new instance to obtain a solution of makespan @xmath462 .",
    "then , we split our instance into large and small jobs , round down the large jobs processing times ( to have a polynomial - size collection of feasible configurations of large jobs on the machines ) , such that the load of each machine does not exceed @xmath79 .",
    "then , we iterate on this collection in order to find the configuration that minimizes the transition cost from the original solution .",
    "we prove that after we inflate the rounded jobs to their original processing times , and greedily assign all the small jobs within the configuration , the resulting makespan is at most @xmath463 .",
    "+ we give below a detailed description of our algorithm , @xmath457 .",
    "let @xmath464 denote the minimum makespan for an instance @xmath71 .",
    "for simplicity of the presentation , for the case where @xmath465 , we assume w.l.o.g . that the omitted machines are @xmath466 .    1 .",
    "[ step : ams_1 ] let @xmath467 .",
    "use a ptas for makespan minimization on identical machines to find @xmath468 .",
    "[ step : ams_2 ] define @xmath469 for all @xmath425 , and represent each machine as a bin of unit capacity .",
    "consider the jobs as items whose sizes are @xmath470 $ ] .",
    "[ step : ams_3 ] an item @xmath438 is _ small _ if it has a size at most @xmath471 ; otherwise , item @xmath6 is _",
    "large_. 4 .",
    "[ step : ams_4 ] round down the sizes of the large items to the nearest multiple of @xmath472 . denote the rounded sizes @xmath473 , for every large item @xmath6 .",
    "[ step : ams_5 ] for any feasible assignment of rounded large items in the @xmath5 bins , given by the configuration @xmath474 , do : 1 .",
    "let @xmath475 .",
    "construct a complete bipartite graph @xmath476 , in which @xmath477 , and @xmath478 .",
    "each vertex @xmath479 corresponds to the initial configuration of machine i , given by @xmath480 , for @xmath481 ; if @xmath482 , set @xmath483 for all @xmath484 .",
    "if @xmath485 , set @xmath486 for all @xmath487 .",
    "define a cost on the edges @xmath488 , for all @xmath489 , as follows",
    "add the cost of large items that appear in @xmath490 but not in the initial configuration @xmath491 .",
    "2 .   add to @xmath490 all the small items that appear in @xmath491 but not in @xmath490 and then omit the largest small items until the total size of @xmath490 does not exceed @xmath134 .",
    "add the cost of the omitted items .",
    "for an empty configuration @xmath490 , the cost of the edge @xmath492 , for all @xmath493 is equal to @xmath444 .",
    "2 .   find a minimum cost perfect matching in the bipartite graph .",
    "3 .   add to the solution the omitted small items using first - fit .",
    "[ step : ams_6 ] choose the solution of minimum cost , and return the corresponding schedule of the jobs on the machines .",
    "[ thm : ams_ptrs ] for any @xmath20 , algorithm @xmath457 yields in polynomial time a @xmath456-reapproximation for @xmath494 ,    we prove the theorem using the next lemmas .",
    "[ sum of pieces lemma ] let @xmath424 be an instance of @xmath417 , for which the minimum makespan is @xmath495 , and let @xmath496",
    ". let @xmath497 , for all @xmath425 ; then , @xmath498 .",
    "we note that the minimum makespan satisfies @xmath499 .",
    "since @xmath496 , we have that @xmath500 for all @xmath425 , therefore , @xmath501    [ epsilon relaxed lemma ] let @xmath502 be a feasible assignment of rounded large items on the @xmath5 machines , given by the configuration @xmath503 , to which we add in each bin the small items that were not omitted in step 5 of @xmath457 .",
    "then @xmath502 can be expanded in polynomial time to an @xmath504-relaxed packing of all items in the input @xmath71 .",
    "let @xmath505 be a feasible configuration of the large rounded items , and let @xmath506 be the subsets of small items added in step 5 to the bins , to form @xmath502 .",
    "then @xmath502 yields a feasible packing , i.e. , for all @xmath507 , @xmath508 now , since @xmath509 for all @xmath510 , the number of large items in bin @xmath7 is bounded by @xmath511 .",
    "also , since @xmath512 , for all @xmath513 , we have that @xmath514 hence , the packing of @xmath502 is @xmath515-relaxed .",
    "now , we show that the packing remains @xmath515-relaxed after we add the small items using first - fit .",
    "let @xmath516 denote the sizes of the items packed in @xmath502 , and let @xmath517 be the sizes of the small unpacked items . by lemma [ sum of pieces lemma ] , we have @xmath518 we apply first - fit in the following _ relaxed _ manner .",
    "consider the next item in the unpacked list .",
    "starting from bin @xmath134 , we seek the first bin in which the item can be added , such that the overall size of the items packed in this bin is at most @xmath519 .",
    "let @xmath520 be the total size of the items packed in bin @xmath7 after adding the small items .",
    "assume that , after we apply first - fit , some small items remain unpacked ( i.e. , none of the bins can accommodate these items ) .",
    "let @xmath521 denote this subset of items .",
    "then , we have that @xmath522 for all @xmath523 and @xmath524 .",
    "it follows , that @xmath525 by the definition of @xmath520 , and since we packed all items up to @xmath526 , @xmath527 from ( [ eq : no_1 ] ) , we get that @xmath528 then , from ( [ eq : no_3 ] ) , we have @xmath529 from ( [ eq : no_2 ] ) and ( [ eq : no_4 ] ) , it follows that , for all @xmath530 , @xmath531 or , @xmath532 from ( [ eq : no_5 ] ) , and since @xmath533 for @xmath534 , we have that @xmath535 ; thus , @xmath536 .",
    "a contradiction , since @xmath537 for all @xmath6 .    hence , the above relaxed implementation of first - fit packs all of the remaining small items and yields a relaxed - packing of the original instance .",
    "let @xmath538 be an optimal solution , and let @xmath539 be the configuration of large items derived from @xmath538 .",
    "then , the cost of this optimal solution is at least the cost of the solution for @xmath540 in step 5 of @xmath457 .",
    "[ algvsopt lemma ]    @xmath540 is an optimal configuration , therefore @xmath540 is also a feasible configuration ( since @xmath541 ) .",
    "let @xmath542 be the solution for @xmath540 the algorithm generates in step 5 .",
    "assume that @xmath543 .",
    "note that the cost for the large items is the same in both solutions , and therefore the difference between the cost is caused by packing small items .",
    "we also note that , in the algorithm , the small items we pay for are those that are omitted from their original bin and transfered to a different one .",
    "since the transition costs are 1 , it means that the number of omitted small items in @xmath538 is smaller than in @xmath542 , or in other words , the number of small items that are packed in their original bin in @xmath538 is greater than their number in @xmath542 . therefore , there must exist a bin @xmath544 for which this holds .",
    "consider the small items packed in bin @xmath7 in each solution .",
    "denote by @xmath545 the sizes of small original items of bin @xmath7 that are packed in bin @xmath7 in both solutions , by @xmath546 and @xmath547 two distinct sets of small original items of bin @xmath7 that are packed in @xmath542 and in @xmath538 , respectively , but not in both . since the algorithm chooses to omit the largest small items first , the fact it chose to omit @xmath547 but to keep @xmath546 means that @xmath547 are not smaller than @xmath546 .",
    "in particular , let @xmath548 , then we have @xmath549    since @xmath550 , we get that @xmath551    the algorithm chose , in particular , to omit @xmath552 , hence @xmath553    but also @xmath554    by the above discussion , we also have that    @xmath555    from the last inequality , we have a contradiction to @xmath556 .",
    "hence , we have the statement of the lemma .",
    "@xcite let @xmath557 be a bipartite graph with @xmath558 and , and let @xmath559 be a cost function on the edges .",
    "a minimum cost perfect matching , i.e. a perfect matching @xmath560 for which @xmath561 is minimized , can be found in @xmath562 time .",
    "[ min cost perfect matching lemma ]    now , we are ready to prove the main theorem .    [",
    "[ proof - of - theorem - thm - ams_ptrs ] ] proof of theorem [ thm : ams_ptrs ] :    let @xmath563 be the configuration of large items derived from an optimal solution , @xmath538 .",
    "let @xmath542 be the packing obtained for @xmath540 in step 5 of the algorithm .",
    "by lemma [ algvsopt lemma ] , we have    @xmath564    let @xmath565 be the solution the algorithm outputs .    since @xmath566 , we have that @xmath567 .",
    "now , it is easy to see that if we transform @xmath565 to the schedule of the job on the machines ( by returning to the original processing times ) , we get a solution of makespan at most @xmath568 . since @xmath569 ,",
    "the algorithm is a @xmath570-approximation algorithm .",
    "we note that @xmath571 , thus the algorithm yields a @xmath0-approximation to @xmath495 .",
    "we conclude that @xmath457 is a @xmath572-reapproximation algorithm for the reoptimization problem .",
    "+ now , we prove that @xmath457 runs in polynomial time .    * in the first step , we run a ptas for the new instance @xmath233 , therefore , this part is polynomial in @xmath233 ( but exponential in @xmath573 ) .",
    "* steps 2,3 and 4 are clearly polynomial in @xmath574 . * for step 5 ,",
    "we first show that the number of feasible configuration of large rounded items is polynomial in @xmath233 .",
    "recall that the number of large rounded items in each bin can not exceed @xmath575 .",
    "since the rounded sizes of large items can be of at most @xmath576 different sizes , the number of feasible configurations is at most @xmath577 .",
    "there are at most @xmath5 bins , implying that the number of feasible configurations is at most @xmath578 which is polynomial in @xmath5 but exponential in @xmath573 .",
    "now , for each configuration , we construct the bipartite graph in time polynomial in @xmath574 and by @xcite we find a perfect minimum cost matching in time @xmath579 where @xmath580 , which is polynomial in @xmath574 . *",
    "packing of the small items in each iteration using first - fit is also done in time polynomial in @xmath574 and step 6 is clearly polynomial in @xmath574 .",
    "we present below a reapproximation algorithm , @xmath581 , for the problem of minimizing the makespan on uniform machines .",
    "the algorithm uses a _",
    "relaxed _ packing of items in bins , where the items correspond to jobs , and the bins represent the set of machines .",
    "given a set of @xmath5 bins , with positive capacities @xmath582 , and a set of items packed in the bins , we say that the packing is _",
    "@xmath19- relaxed _ , for some @xmath44 , if for every @xmath583 , the total size of items assigned to each bin is at most @xmath584 .",
    "our algorithm for reoptimizing the makespan on uniform machines accepts as input the instances @xmath451 and @xmath233 , the initial assignment of jobs to the machines , @xmath461 , and an error parameter @xmath44 .    in the previous section",
    ", it was convenient to convert the problem into a bin packing problem where all bins have equal size .",
    "we will consider the conversion to a bin packing problem also in the case of scheduling on unrelated machines , only here the bins will have variable sizes . in the generalization of the equal - size bin case to the variable - size case ,",
    "we come across a major obstacle .",
    "the size of the subintervals in which the pieces are partitioned depends on the size of the bins in which the pieces are to be packed .",
    "moreover , the definition of large and small pieces depends on the size of the bin in which the pieces are to be packed .",
    "hochbaum and shmoys @xcite presented a ptas for the problem of makespan minimization on uniform machines .",
    "they constructed , in polynomial time , a layered directed graph , with two nodes designated initial `` and success '' , such that there exists a path from initial `` to success '' in the graph if and only if there is a schedule with makespan at most @xmath585 times the minimal makespan . from this path",
    "one can also define the configuration of medium `` and large '' jobs on each machine , and it is guaranteed that the small `` jobs can be scheduled .",
    "we add suitable costs to the edges of the layered graph and show that a feasible solution with optimal cost can be obtained by finding the lightest path from initial '' to success `` in the layered graph .",
    "it is also guaranteed that if there is a path from initial '' to success \" in the graph , then there is enough space in the bins to add the remaining pieces ( e.g. , using first - fit ) , in the bins on which they are considered small . this way , as before",
    ", we can greedily pack the small pieces in their original bin ( as long as we do not exceed its capacity ) , and pay only for packing the rest .",
    "[ [ overview - of - the - ptas - of ] ] overview of the ptas of @xcite    assume that @xmath586 is the highest speed , and represent each machine @xmath7 as a bin of size @xmath13 . normalize the bin sizes by @xmath586 .",
    "consider the jobs as items whose sizes are in @xmath587 $ ] ( by normalizing them by some upper bound on the minimal makespan ) .",
    "round down piece sizes in @xmath588 $ ] to the nearest multiple of @xmath589 , for some integer @xmath590 .    for a bin of size",
    "@xmath591 $ ] define :    * pieces of sizes in @xmath592 $ ] are _ large _ for the bin .",
    "* pieces of sizes in @xmath593 $ ] are _ medium _ for the bin .",
    "* pieces of sizes less than or equal to @xmath589 are _ small _ for the bin .    for convenience , the interval @xmath592 $ ]",
    "is referred as interval @xmath313 . for pieces in interval @xmath313 ,",
    "a bin is _ large _ if it is in interval @xmath313 , _ huge _ if it is in interval @xmath594 , and _ enormous _ if it is in intervals @xmath595 .    a directed layered graph , @xmath596 , is then constructed , in which each node is labeled with a state vector describing the remaining pieces to be packed as large or medium pieces .",
    "the graph is grouped into stages , where a stage specifies the large and medium pack of bins in one interval @xmath592 $ ] .",
    "each layer within a stage corresponds to packing a bin in the corresponding interval .",
    "both the bins within the stage and the stages are arranged in order of decreasing bin size .",
    "the state vector associated with each node is of the form @xmath597 , where @xmath78 and @xmath598 are vectors , each describing a distribution of pieces in the subintervals of @xmath592 $ ] and @xmath593 $ ] respectively .",
    "there are two nodes designated initial `` and success '' , such that initial `` is connected to the initial state vectors of the first stage , and every final state vector of the final stage is connected to success '' . a path from initial `` to success '' in @xmath599 specifies a packing of the rounded medium and large pieces for every bin .",
    "we note that , after the large and medium pack of the bins in interval @xmath313 , we must allow for the packing of the remaining pieces in interval @xmath313 that will be packed as _",
    "small_. these pieces must be packed in enormous bins for them , therefore , we need to have sufficient unused capacity in the enormous bins to at least contain the total size of these unpacked pieces .",
    "this is represented by the value @xmath600 in the state vector ; it records the slack , or unused capacity in the partial packing of the enormous bins with large and medium pieces . for stages corresponding to intervals greater than @xmath313",
    ", we also need to have the unused capacity in the huge and large bins , and this is the role of @xmath601 and @xmath351 , respectively .",
    "since we must represent the possible values in some compact way , we consider the sizes of the pieces that will be packed as small pieces into this as - yet - unused capacity . for @xmath600 , pieces in interval @xmath313 are small , and thus all pieces to be packed into this unused capacity have rounded sizes that are multiples of @xmath602 ; as a result , it will be sufficient to represent @xmath603 as an integer multiple of @xmath589 .",
    "similarly , @xmath601 and @xmath351 will be represented as integer multiples of @xmath604 and @xmath605 , respectively .",
    "the following lemmas , due to @xcite , will be useful in analyzing our algorithm .",
    "[ graph_size lemma ] given @xmath1 , the layered graph @xmath599 has @xmath606 nodes and + @xmath607 edges .",
    "the number of nodes in each layer , which is the number of state vectors corresponding to packing the bins of that layer , is @xmath608 .",
    "[ correspondence_lemma ] for any @xmath1 , there is a one to one correspondence between paths from initial `` to success '' in the layered graph @xmath599 and @xmath19-relaxed packings .",
    "[ inflating_lemma ] given an @xmath459-relaxed packing of rounded piece sizes , for some @xmath20 , restoring the piece sizes to their original size yields a @xmath609-relaxed packing of the original pieces .",
    "we give below a detailed description of our algorithm , @xmath581 .",
    "let @xmath464 denote the minimum makespan for an instance @xmath71 .    1 .",
    "let @xmath1 .",
    "use a ptas for makespan minimization on uniform machines to find @xmath610 .",
    "2 .   let @xmath611 be the largest speed , and assume that @xmath612 is bounded from above by some given constant @xmath613 .",
    "normalize all the processing times by @xmath614 , and represent each machine as a bin of capacity @xmath615 .",
    "consider the jobs now as pieces with sizes in @xmath587 $ ] .",
    "denote the new bin sizes by @xmath616 , and denote the piece sizes by @xmath617 .",
    "[ step : aum_3 ] round down the piece sizes @xmath618 $ ] to the nearest multiple of @xmath589 .",
    "[ step : aum_4 ] construct the directed layered graph @xmath599 , and define edge costs as follows .",
    "consider the edge @xmath619 connecting a node of the @xmath620th layer to a node of the @xmath136th layer in some stage that corresponds to interval @xmath313 . @xmath619 describes the large and medium pack of the @xmath136th bin of stage @xmath313 .",
    "let @xmath621 be the set of pieces packed in that bin in the initial solution .",
    "fix the cost on that edge to be the number of large and medium pieces that appear in @xmath621 , but are not packed in the bin by @xmath619 .",
    "all other edges in @xmath599 are assigned the cost zero .",
    "[ step : aum_5 ] for every choice of exactly one update arc , at the end of each stage , do : 1 .   find the lightest path from initial `` to success '' in the graph ( if one exists ) .",
    "define the corresponding partial solution consisting of pieces that are packed as large or medium .",
    "2 .   add the remaining pieces greedily to the enormous bins for them : for each bin @xmath7 , let @xmath622 be the set of remaining pieces that belong to the bin in the initial solution and that are _ small _ for this bin .",
    "start packing the pieces in @xmath622 in bin @xmath7 , in increasing order of piece sizes , and stop after the total size of packed pieces exceeds for the first time the bin capacity .",
    "pack all the remaining pieces , as _ small _ , using first - fit .",
    "return the solution of minimum cost .",
    "[ thm : aum_ptrs ] for any @xmath1 , algorithm @xmath581 yields in polynomial time a @xmath572-reapproximation for @xmath623 .",
    "we prove the theorem using the next lemmas .",
    "[ greedy_pack_um lemma ] given the partial packing of medium and large pieces ( after step 5(i ) in @xmath581 ) , packing the remaining pieces greedily as small , in step 5(ii ) , incurs the minimal cost for packing these pieces .",
    "for the partial packing of medium and large pieces , let @xmath624 be the set of the remaining pieces . we show that packing the pieces in @xmath624 in enormous bins for them , by the greedy algorithm given in step 5(ii ) , results in the minimal cost for packing @xmath624 .",
    "the greedy algorithm first packs every bin with its original pieces that are small .",
    "it sorts them in non - decreasing order by piece size and packs them to the original bin by this order , until the bin capacity is exceeded for the first time ( or all pieces are packed ) . this way we guarantee that we pack to every bin the maximal number of small pieces that were originally packed in it .",
    "thus , the number of pieces , packed as small , _ not _ in their original bin , is minimized .",
    "this also implies a minimum packing cost for @xmath624 .",
    "let @xmath538 be an optimal solution .",
    "then , the cost of @xmath538 is at least the cost of the solution obtained by @xmath581 .",
    "[ algvsopt_um lemma ]    let @xmath539 be the configuration of large and medium items derived from @xmath538 . since @xmath540 is optimal , in particular , it is a truly feasible configuration of large and medium pieces that also leaves enough slackness for packing the remaining pieces as _ small _ , without exceeding the capacity of the bins .",
    "thus , by lemma [ correspondence_lemma ] , there is a path from initial `` to success '' in the layered graph , such that @xmath540 is the large and medium pack derived from it .",
    "this path also contains exactly one update arc after each stage .",
    "therefore , our algorithm , in particular , considers this choice of update arcs for which it finds a lightest path in the graph ( which clearly exists for this choice ) . by lemma [ greedy_pack_um lemma ] ,",
    "the cost of the solution output by the algorithm is at most the cost of the lightest path plus the minimal cost of packing all the remaining pieces as _ small _ , which is clearly at most the cost of @xmath538 .    for any partial solution of large and medium rounded pieces , derived from a path from initial `` to success '' in @xmath599",
    ", all the remaining rounded pieces can be packed in enormous bins for them , using the greedy algorithm in step 5(ii ) , such that the load on each bin of size @xmath13 is at most @xmath625 .",
    "[ small_pack_lemma ]    as shown in @xcite , the small - pack phase , which is done after every stage , is always successfully completed , since there is an update arc if and only if there is sufficient total slack to accommodate all pieces to be packed as small . using a similar argument",
    ", @xmath581 is able to pack all the remaining small pieces after packing all the large and medium pieces .",
    "consider the rounded pieces packed into a bin of size @xmath13 , which is in interval @xmath313 .",
    "focus on the small piece @xmath6 that , when added to the bin , exhausts the usable slack . then",
    ", piece @xmath6 is of size less than or equal to @xmath589 , and before piece @xmath6 was added , the rounded piece sizes did not exceed @xmath626 ( recall that the usable slack is rounded up to a multiple of @xmath627 ) . hence , the bin contains pieces of total ( rounded ) size at most @xmath628 .",
    "therefore , if @xmath364 is the set of pieces packed in bin @xmath7 , then the sum of the rounded piece sizes in @xmath364 is at most @xmath629 which is at most @xmath630 , since @xmath631 .",
    "the number of different choices for update arcs , one after each stage , is at most + @xmath632 , where @xmath633 is the number of stages in the graph .",
    "[ number_of_update_arcs_choices ]    between every two stages , there are @xmath608 update arcs , same as the number of state vectors in each layer ( lemma [ graph_size lemma ] ) . therefore , the number of possibilities for choosing one arc in each stage is @xmath632 .",
    "[ s_is_constant_lemma ] the number of stages @xmath633 in @xmath599 depends only on @xmath459 and on @xmath634 .    the number of stages in @xmath599 is the number of intervals @xmath313 that contain at least one bin .",
    "since the smallest bin size satisfies @xmath635 , @xmath633 is at most @xmath636 .",
    "now , we are ready to prove the main theorem .    [ [ proof - of - theorem - thmaum_ptrs ] ] proof of theorem [ thm : aum_ptrs ] :    by lemma [ algvsopt_um lemma ] , taking the best solution among all lightest paths ( one for each choice of update arcs ) , we have a solution whose transition cost is at most the transition cost of an optimal solution . by lemma [ small_pack_lemma ] , this solution is also an @xmath637-relaxed packing of the rounded pieces , and by lemma [ inflating_lemma ] , after inflating the pieces to their original sizes , we get a @xmath638-relaxed packing .",
    "hence , by fixing a suitable initial @xmath459 , e.g. , @xmath639 , we conclude that @xmath581 is a @xmath640-reapproximation algorithm for our reoptimization problem .",
    "+ we note that @xmath581 runs in polynomial time . constructing the graph @xmath596",
    "can be done in time linear in the graph size , which is @xmath641 and @xmath642 , by lemma [ graph_size lemma ] . by lemma [ number_of_update_arcs_choices ] , the number of different choices of update arcs , is @xmath643 , where @xmath633 is the number of stages in the graph . by lemma [ s_is_constant_lemma ] , @xmath633 depends only on @xmath459 and @xmath634 .",
    "therefore , the complexity of running e.g. , dijkstra s algorithm @xcite for finding a lightest path from initial `` to success '' and then greedily packing the small pieces , for every choice of update arcs , is @xmath644 .",
    "overall , we get that the complexity of the algorithm is @xmath644 , which is polynomial in the input size .",
    "in this work we studied the fundamental problem of makespan minimization on parallel machines . for the unrelated machines model , we derived an improved bound , which depends on the minimum average machine load and the feasibility parameter of the instance .",
    "our bound is strictly smaller than @xmath22 , the best known general upper bound , for a natural subclass of instances .",
    "we further studied the power of parameterization and presented an fpt algorithm and a parameterized approximation scheme for instances that are known to be hard to approximate within factor @xmath21 , based on classical complexity theory .",
    "finally , we initiated the study of the reoptimization variants of makespan minimization on identical and uniform machines , and derived approximation ratios that match the best known ratios in these models .",
    "while reducing the gap between the general lower bound of @xmath21 and the upper bound of @xmath22 remains a prominent open problem , it would be interesting to tighten these bounds for other non - trivial subclasses of instances , either by a constant , or by a function of the input parameters .",
    "another interesting direction is to study instances with a wider range of feasibility parameters . in this work",
    ", we explored instances having large feasibility parameter . on the other hand , ebenlendr et al .",
    "@xcite considered instances in which the feasibility parameter is at most @xmath645 .",
    "any results on other , intermediate values of this parameter , would shed more light on its role in obtaining better schedules .",
    "the problem of minimizing the makespan on unrelated machines is np - hard even if the number of machines or number of jobs is taken as a parameter @xcite , therefore no fpt algorithm exists with only these choices of parameters .",
    "in addition , we can not hope for obtaining an fpt algorithm for graph balancing with the fixed parameter being only the maximum degree of the graph .",
    "indeed , by the hardness proof of @xcite , the problem is hard to approximate within a factor less than @xmath21 even on bounded degree graphs , i.e. , when the maximum degree is some constant .",
    "the question whether we can find an fpt algorithm for graph balancing with the treewidth being the only parameter remains open .",
    "we list some of the questions arising from our results .",
    "can we obtain reapproximation algorithm with the same performance guarantees for general instances in the uniform machines model ?",
    "`` can we extend our results to arbitrary transition costs ? '' .",
    "finally , can we improve the running times of our reapproximation schemes , by adjusting the known eptass for identical and uniform machines to the reoptimization model ? \"        f. n. abu - khzam , j. egan , m. r. fellows , frances a. rosamond , and peter shaw . on the parameterized complexity of dynamic problems with connectivity constraints . \"",
    "_ combinatorial optimization and applications_. springer international publishing , 2014 .",
    "625 - 636 .",
    "m. a. bender , m. farach - colton , s. fekete , j. t. fineman , and s. gilbert .",
    "reallocation problems in scheduling . \" _ in proceedings of the twenty - fifth annual acm symposium on parallelism in algorithms and architectures _ , pp .",
    "271 - 279 .",
    "acm , 2013 .",
    "t. ebenlendr , m. kal , and j. sgall .",
    "graph balancing : a special case of scheduling unrelated parallel machines . \"",
    "proceedings of the nineteenth annual acm - siam symposium on discrete algorithms .",
    "society for industrial and applied mathematics , 2008 .",
    "m. gairing , t. lcking , m. mavronicolas , and b. monien . computing nash equilibria for scheduling on restricted parallel links . \"",
    "_ proceedings of the thirty - sixth annual acm symposium on theory of computing_. acm , 2004 .",
    "a. verma , l. pedrosa , m. korupolu , d. oppenheimer , e. tune , and j. wilkes .",
    "large - scale cluster management at google with borg . \" _ in proceedings of the tenth european conference on computer systems _ , p. 18 .",
    "acm , 2015 ."
  ],
  "abstract_text": [
    "<S> parallel machine scheduling has been extensively studied in the past decades , with applications ranging from production planning to job processing in large computing clusters . in this work </S>",
    "<S> we study some of these fundamental optimization problems , as well as their parameterized and reoptimization variants .    </S>",
    "<S> we first present improved bounds for job scheduling on unrelated parallel machines , with the objective of minimizing the latest completion time ( or , makespan ) of the schedule . </S>",
    "<S> we consider the subclass of _ fully - feasible _ instances , in which the processing time of each job , on any machine , does not exceed the minimum makespan . </S>",
    "<S> the problem is known to be hard to approximate within factor 4/3 already in this subclass . </S>",
    "<S> although fully - feasible instances are hard to identify , we give a polynomial time algorithm that yields for such instances a schedule whose makespan is better than twice the optimal , the best known ratio for general instances . </S>",
    "<S> moreover , we show that our result is robust under small violations of feasibility constraints .    </S>",
    "<S> we further study the power of parameterization . in a parameterized optimization problem , </S>",
    "<S> each input comes with a fixed parameter . </S>",
    "<S> some problems can be solved by algorithms ( or approximation algorithms ) that are exponential only in the size of the parameter , while polynomial in the input size . the problem is then called _ fixed parameter tractable ( fpt ) _ , since it can be solved efficiently ( by an fpt algorithm or approximation algorithm ) for constant parameter values . </S>",
    "<S> we show that makespan minimization on unrelated machines admits a _ parameterized approximation scheme _ , where the parameter used is the number of processing times that are large relative to the latest completion time of the schedule . </S>",
    "<S> we also present an fpt algorithm for the graph - balancing problem , which corresponds to the instances of the _ restricted assignment _ problem where each job can be processed on at most 2 machines .    finally , motivated by practical scenarios </S>",
    "<S> , we initiate the study of _ reoptimization _ in job scheduling on identical and uniform machines , with the objective of minimizing the makespan . </S>",
    "<S> we develop _ reapproximation _ algorithms that yield in both models the best possible approximation ratio of @xmath0 , for any @xmath1 , with respect to the minimum makespan . </S>"
  ]
}