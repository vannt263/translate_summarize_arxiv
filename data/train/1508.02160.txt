{
  "article_text": [
    "many simulation problems in finance and other applied fields can be written in the form @xmath2 , where @xmath3 is a measurable function on @xmath4 and @xmath5 is a standard normal vector , that is , @xmath6 is jointly normal with @xmath7 and @xmath8 .",
    "it is a trivial observation of surprisingly big consequences that @xmath9 for every orthogonal transform @xmath10 .",
    "while this reformulation does not change the simulation problem from the probabilistic point of view , it does sometimes make a big difference when quasi - monte carlo simulation is applied to generate the realizations of @xmath5 .",
    "examples are supplied by the well - known brownian bridge and pca constructions of brownian paths which will be detailed in the following paragraphs .",
    "assume that one wants to know @xmath11 where @xmath12 is a brownian motion with index set @xmath13 $ ] .",
    "in most applications this can be reasonably approximated by @xmath14 , where @xmath15 is a function on the set of discrete brownian paths .",
    "there are three classical methods for sampling from @xmath16 given a standard normal vector @xmath5 , namely the forward method , the brownian bridge construction and the principal component analysis construction ( pca ) .",
    "all of these constructions may be written in the form @xmath17 , where @xmath18 is an @xmath19 real matrix with @xmath20 for example , the matrix @xmath18 corresponding to the forward method is @xmath21 while pca corresponds to @xmath22 , where @xmath23 is the singular value decomposition of @xmath24 .",
    "a corresponding decomposition for the brownian bridge algorithm is given , for example , by larcher , leobacher & scheicher @xcite .",
    "it has been observed by papageorgiou@xcite that @xmath25 if and only if @xmath26 for some orthogonal matrix @xmath27 , so that every linear construction of @xmath16 corresponds to an orthogonal transform of @xmath4 . in that sense",
    "the forward method corresponds to the identity , pca corresponds to @xmath28 and brownian bridge corresponds to the inverse haar transform , see @xcite .",
    "thus our original simulation problem can be written , as @xmath29 with @xmath30 , and we interpret this as using the forward method .",
    "consequently , the same problem using the brownian bridge takes on the form @xmath31 , where @xmath32 is the matrix of the inverse haar transform , and has the form @xmath33 , with @xmath34 , @xmath35 , @xmath36 as above , when pca is used .    as an application one can generalize the classical constructions of discrete brownian paths to discrete lvy paths .",
    "see @xcite .",
    "+ there are some theories as to why an orthogonal transform might have the effect to make the problem more suitable for qmc .",
    "caflisch et al .",
    "@xcite introduce the concept of effective dimension of a function : consider a function @xmath37 with finite variance w.r.t .",
    "normal distribution , that is @xmath38 where @xmath6 is a vector of independent standard normal random variables .",
    "then @xmath39 may be written uniquely as the sum of functions @xmath40 , @xmath41 , where @xmath42 depends on the @xmath43-th coordinate only if @xmath44 and where @xmath45 for all @xmath46 and @xmath47 for @xmath48 , using the so - called anova decomposition of @xmath39 .",
    "furthermore it holds @xmath49 the effective dimension in the truncation sense at level @xmath50 is then the smallest integer @xmath51 such that @xmath52 see @xcite .",
    "typically @xmath53 is chosen as @xmath54 .",
    "therefore , a function with effective dimension @xmath51 is one that , in this sense , almost exclusively depends on the first @xmath51 variables and which therefore is more suitable for qmc .",
    "this is confirmed by empirical evidence .",
    "building on the concept of effective dimension of a function , owen @xcite gives definitions of effective dimensions of function spaces , thus connecting the concepts of effective dimension with that of tractability .",
    "now one can turn this around and try to put as much variance as possible to the first few coordinates , by concatenating @xmath39 with a suitable orthogonal transform .",
    "this is what has been done by imai & tan  @xcite and what we will do here , using a different approach .",
    "we shall see in section  [ sec : numeric ] that empirical evidence also supports the conjectured efficiency of our method .",
    "however , there is also a disadvantage of that approach : the computation of the orthogonal transform has a cost , which is in general of the order @xmath55 . for large @xmath1",
    "this cost is likely to swallow the potential gains from the transform .",
    "we therefore concentrate on orthogonal transforms which have cost of the order @xmath0 .",
    "examples include discrete sine and cosine transform , walsh and haar transform as well as the orthogonal matrix corresponding to the pca , see @xcite .",
    "+ imai & tan @xcite propose an algorithm to find a good orthogonal transform in the sense that it puts as much variance as possible to the first few dimensions .",
    "they propose to take the first order taylor expansion at some point @xmath56 , i.e.@xmath57 then the contribution of the @xmath43-th component of @xmath5 to @xmath58 is given by @xmath59 .",
    "the columns of the orthogonal transform are chosen by solving optimization problems of the form @xmath60 with @xmath61 .",
    "they suggest to perform this optimization only for the first few columns of the matrix @xmath18 . in this paper",
    "we improve on their algorithm in various directions .",
    "in particular we find a good orthogonal transform that is fast in that it can be computed even in linear time .",
    "+ the remainder of the paper is organized as follows .",
    "section [ sec : householder ] reviews basic properties of householder reflections and shows how they can be used to find fast versions of orthogonal transforms which put most variance on the first @xmath51 variables .",
    "the main part of our article , section [ sec : algo ] , describes algorithms for finding fast orthogonal transforms using again householder reflections .",
    "in contrast to the method of imai & tan @xcite we do not rely on differentiability .",
    "this makes the algorithm useful for barrier - type options .",
    "we further provide some theoretical results which indicate why the method serves to reduce the effective dimension .",
    "section  [ sec : numeric ] gives some numerical examples where the methods described earlier are applied to examples from finance .",
    "we will see that the new methods described in section  [ sec : algo ] are among the best , both with regard to speed and accuracy .",
    "we provide an appendix where we compute certain expectations depending on the maximum of a brownian path .",
    "this is useful for some of the numerical examples .",
    "we recall the definition and basic properties of householder reflections from golub & van loan @xcite .    a matrix of the form @xmath62 where @xmath63 ,",
    "is called a _",
    "householder reflection_. the vector @xmath64 is called the defining _",
    "householder vector_.    in the following proposition , @xmath65 denotes the first canonical basis vector in @xmath4 , @xmath66 .",
    "a householder reflection have the following properties :    1 .",
    "if @xmath67 is a vector then @xmath68 is the reflection of @xmath69 in the hyperplane @xmath70 . in particular",
    ", @xmath27 is orthogonal and symmetric , i.e. @xmath71 .",
    "2 .   given any vector @xmath72 we can find @xmath63 such that for the corresponding householder reflection @xmath27 we have @xmath73 .",
    "the computation of the householder vector uses @xmath74 floating point operations .",
    "the computation of the matrix - vector multiplication @xmath68 uses at most @xmath75 floating point operations .",
    "see chapter 5.1 of golub & van loan @xcite .",
    "our main application of householder reflections is the following : suppose we know that for a given integration problem @xmath2 some orthogonal transform @xmath76 reduces the effective dimension in the truncation sense to @xmath51 , that is , almost all of the variance of @xmath77 is captured by @xmath78 , @xmath79 .",
    "let @xmath80 , that is , @xmath81 is the @xmath82-th column of @xmath76 .",
    "we can find householder reflections @xmath83 such that @xmath84 , @xmath85 as follows :    * let @xmath86 be a householder reflection that maps @xmath65 to @xmath87 .",
    "@xmath86 also maps @xmath87 to @xmath65 . since the vectors @xmath81 are orthogonal we have @xmath88 .",
    "* therefore there exists a householder reflection @xmath89 operating on the last @xmath90 coordinates which maps @xmath91 to @xmath92 .",
    "thus @xmath93 , @xmath94 .",
    "* suppose householder reflections @xmath95 have been constructed such that @xmath96 , @xmath97 .",
    "* then there exists a householder reflection @xmath98 operating on the last @xmath99 coordinates which maps @xmath100 to @xmath101 .",
    "then @xmath102 , @xmath103 .",
    "write @xmath104 . by construction",
    "the first @xmath51 columns of @xmath27 coincide with those of @xmath76 . since",
    ", by assumption , @xmath78 capture almost all of the variance of @xmath77 , the same is true for @xmath105 .",
    "but for small @xmath51 the computational cost for computing @xmath106 is of the order @xmath107 , as compared to general matrix - vector multiplication which occurs a cost of order @xmath55 .",
    "+ imai & tan @xcite and wang & sloan @xcite give examples for which they find good orthogonal transforms @xmath76 that reduce the effective dimension .",
    "however they do not specify how those transforms are applied .",
    "we propose to approximate them using the above method",
    ".    however , the main topic of this paper is to present transforms that use only one householder reflection .",
    "this will by detailed in the next section .",
    "let @xmath108 be a measurable function with @xmath109 for a standard normal vector @xmath5 .",
    "we want to approximate @xmath3 by a linear function : @xmath110 where @xmath72 and @xmath111 .",
    "this can be done in different ways .",
    "for example , imai & tan @xcite take the first order taylor expansion of @xmath3 .",
    "in contrast , we take a `` linear regression '' approach , i.e.  we minimize @xmath112 first order conditions give @xmath113 therefore , minimizes the variance of the difference between @xmath3 and the linear approximation .",
    "so @xmath114 that is , @xmath115 measures the proportion of variance captured by the linear approximation .",
    "now there exists a unique householder reflection @xmath27 that maps @xmath65 to @xmath116 . with this transform",
    "we have @xmath117 and therefore @xmath118 therefore the linear part of the integration problem depends on the parameter @xmath119 alone .",
    "now , if the linear part constitutes a large part of the integration problem then we have succeeded in putting a large fraction of the variance into the first coordinate by composing @xmath3 with @xmath27 .",
    "let @xmath120 be independent standard normal variables .",
    "let @xmath3 be a function @xmath108 .    1 .",
    "@xmath121 for @xmath122 ; 2 .",
    "if @xmath123 define @xmath124 and go to 4 . ; 3 .",
    "else let @xmath27 be a householder reflection that maps @xmath65 to @xmath116 ; 4 .",
    "compute @xmath125 using qmc .",
    "a drawback of the algorithm is that in general the computation of the expectations in step 1 is no easier than the original problem . in some cases",
    "the expectation can be computed explicitly , though usually in that case also the original problem has an explicit solution .",
    "[ ex : sum_prod ] @xmath126 .",
    "it is easily verified that , with @xmath127 denoting the standard normal density , @xmath128 , @xmath129 therefore it holds that @xmath130 let us find out how much of the variance of @xmath131 is captured by @xmath132 :    we write @xmath133 .",
    "then @xmath134 where @xmath135 .    on the other hand , it is easy to see that @xmath136 and @xmath137",
    ". therefore we get for the variance of @xmath131 @xmath138 let us try some special values that are related to asian options : @xmath139 with @xmath140 , @xmath141 . for this choice",
    "we get @xmath142 , and @xmath143 .    for large @xmath1 the sums in equations and",
    "can be approximated by corresponding integrals such that @xmath144 table [ tbl : var - part ] shows the fraction @xmath145 for a few values of @xmath146 , @xmath147 and @xmath148 .",
    "c|cccccccc @xmath149&0.01&0.02&0.03&0.04 + 0.1&0.0025 & 0.0051 & 0.0076 & 0.0101 + 0.2&0.0026 & 0.0051 & 0.0077 & 0.0103 + 0.3&0.0026 & 0.0052 & 0.0078 & 0.0104 +    it can be concluded that in this example almost all of the variance of @xmath131 is captured by @xmath119 .",
    "in general we can not expect that @xmath150 can be computed explicitly .",
    "of course it is an option to compute @xmath150 using ( quasi-)monte carlo , though it is unlikely that this will lead to small overall computing times .",
    "but quite frequently , especially in financial applications , a problem can be written in the form , @xmath151 , where @xmath152 can be computed and @xmath153 is some relatively simple function @xmath154 .",
    "[ alg : main ] let @xmath120 be independent standard normal variables .",
    "let @xmath3 be a function @xmath108 , which is of the form @xmath155 where @xmath156 and @xmath157 .    1 .",
    "@xmath158 for @xmath122 ; 2 .   if @xmath123 define @xmath124 and go to 4 . ; 3 .",
    "else let @xmath27 be a householder reflection that maps @xmath65 to @xmath116 ; 4 .",
    "compute @xmath125 using qmc .    without additional assumptions on the functions @xmath153 and @xmath39 there is no guarantee that @xmath27 gives better convergence .",
    "nevertheless there are practical examples where this algorithm gives excellent results .",
    "[ ex : asianoption ] consider an arithmetic average value option written on some underlying @xmath34 , @xmath159 and @xmath160 here we have @xmath151 , where @xmath161 and @xmath153 is like in example [ ex : sum_prod ] with @xmath162 , @xmath163 , @xmath164 , @xmath165 .",
    "+    write @xmath166 , @xmath167 .",
    "then @xmath168 are uncorrelated , @xmath169 further , @xmath170 , such that @xmath171 as well , and therefore @xmath172 .",
    "[ th : decomp ] let @xmath173 be like in algorithm [ alg : main ] .",
    "write again @xmath166 , @xmath167",
    ".    then @xmath174 .",
    "we write @xmath175 and @xmath176 , so that we have to show @xmath177 . to that end",
    "it is sufficient to prove that @xmath178 and @xmath179 are uncorrelated : @xmath180 since @xmath181 , we have @xmath182 .",
    "we consider a special case that will rarely occur in practice but which gives a flavor of the best result possible .",
    "assume that @xmath39 is lipschitz continuous with constant @xmath183 .",
    "suppose further that @xmath184 and @xmath185 are not only uncorrelated , but even independent .",
    "denote by @xmath186 , @xmath187 the cumulative probability distribution functions of @xmath184 and @xmath185 , respectively .",
    "using independence we get @xmath188 noting that @xmath189 we thus get @xmath190 where we also have used the cauchy - schwarz inequality . thus with theorem [ th : decomp ] we get @xmath191 that is , @xmath192 so in this situation , if @xmath119 captures a large fraction of the variance of @xmath193 , then @xmath119 also captures a large fraction of the variance of @xmath131 provided that the lipschitz constant @xmath183 is not too big .",
    "we can also think of a variant of algorithm [ alg : main ] for slightly more complicated functions .",
    "we have been inspired by wang & sloan @xcite , where the authors consider functions of the form @xmath194 and show , that there is an orthogonal transform that makes this function @xmath195-dimensional .",
    "we give a slightly modified version of their argument which guarantees that the orthogonal transform is also fast to compute for small @xmath195 , that is for @xmath196 .",
    "let @xmath194 for @xmath197 .",
    "we may assume that @xmath198 is not the zero vector .",
    "let @xmath86 be a householder reflection which maps @xmath199 to @xmath200 .",
    "then @xmath201 and therefore @xmath202 next we write @xmath203 .",
    "that is , @xmath204 for some @xmath205 .",
    "assuming that @xmath206 , let @xmath207 be the householder reflection of @xmath208 that maps @xmath199 to @xmath209 and let @xmath210 then @xmath89 is a householder reflection of @xmath4 and @xmath211 for some @xmath212 . proceeding that way",
    "one arrives at @xmath213 for some @xmath214 ( we may have @xmath215 if at some stage all remaining @xmath216 are zero ) . + we propose a similar procedure for an integration problem of the form @xmath217 where @xmath218 can be computed explicitly ( or at least efficiently ) .",
    "[ alg : general ] let @xmath120 be independent standard normal variables .",
    "let @xmath3 be a function @xmath108 , which is of the form @xmath155 where @xmath219 and @xmath220 .    1",
    ".   start with @xmath221 and @xmath124 ; 2 .",
    "[ it : goto ] @xmath222 for @xmath223 ; 3 .",
    "@xmath224 for @xmath225 ; 4 .",
    "if @xmath226 define @xmath227 and go to [ it : final ] ; 5 .",
    "else let @xmath228 be a householder reflection that maps @xmath229 to @xmath230 ; 6 .",
    "@xmath231 ; 7 .   @xmath232 ; 8 .",
    "while @xmath233 , go back to [ it : goto ] ; 9 .",
    "[ it : final ] compute @xmath125 using qmc",
    ".    we will give a numerical example in section [ sec : numeric ] .",
    "in this section we will apply our method to examples from mathematical finance .",
    "the first numerical example we give is the evaluation of an asian call option with discrete arithmetic average in the black - scholes model , which has been discussed previously .",
    "since the payoff function @xmath3 is of the form @xmath234 with @xmath39 and @xmath153 as in example [ ex : asianoption ] , we apply algorithm [ alg : main ] to the integration problem @xmath235 where the vector @xmath236 follows from example [ ex : sum_prod ] , i.e. for every @xmath237 @xmath238 for the quasi - monte carlo simulation we use a sobol sequence of dimension @xmath239 with a random shift and we have @xmath240 as well as @xmath148 .",
    "we compute the standard deviation based on @xmath241 batches for @xmath242 sample paths , where the number of sample paths ranges from @xmath243 to @xmath244 .",
    "note that the standard deviation is different from the rqmc standard deviation defined in lecuyer & munger @xcite .    in figure",
    "[ fig : asian ] we compare the regression method with the forward method , the pca construction and the lt method of imai and tan .",
    "we see that pca , lt and the regression method yield similar results , but all of the three outperform the forward method .",
    "note that the regression method can be applied in @xmath245 .",
    "thus we can achieve the efficiency of the pca with the regression method with lower computational costs .",
    "moreover , it is interesting that the lt method and regression method yield nearly the same results",
    ".     runs on a @xmath246-scale , width=298,height=207 ]     runs on a @xmath246-scale , width=298,height=207 ]    the computation time required to price the asian option using quasi - monte carlo integration with @xmath244 paths is given in table [ tbl : comptime ] .",
    "note that pca is implemented using the discrete sine transform as discussed in leobacher @xcite .",
    "the lt method is implemented such that only the first @xmath247 columns are optimized and then the orthogonal transform is completed using householder reflections as we suggested in section [ sec : householder ] .",
    "c|cccc & & & & regression + & 0.08 & 0.64 & 1.94 & 0.15 +    furthermore it should be mentioned that the regression method as well as the lt method produce an overhead caused by determining the orthogonal transform .",
    "nevertheless the overhead time is rather small and is negligible for a large sample size .",
    "the computation times of the subsequent numerical examples are similar to the result regarding the asian option .",
    "we consider an asian basket call option with arithmetic average and a basket consisting of @xmath195 assets , an example taken from imai & tan @xcite .",
    "the @xmath43-th asset @xmath248 of the basket ( @xmath249 ) is given by @xmath250 where @xmath251 is the current price of the @xmath43-th asset , @xmath146 is the risk - free interest rate , @xmath252 is the volatility of the @xmath43-th asset and @xmath253 is an @xmath195-dimensional brownian motion .",
    "the correlation between @xmath254 and @xmath255 is denoted by @xmath256 .",
    "the payoff function of the asian basket option is given by @xmath257 where @xmath258 and where @xmath259 is an @xmath260matrix with @xmath261 and @xmath262 is an @xmath263matrix with @xmath264 for all @xmath43 and @xmath265 for @xmath266 .",
    "note that the discussion of the previous sections also holds for a discrete brownian path with covariance matrix @xmath267 .",
    "since the problem is of the form @xmath151 , algorithm [ alg : main ] can be applied .",
    "since the function @xmath153 is of the form considered in example [ ex : sum_prod ] , we can compute the corresponding vector @xmath236 analytically . furthermore , notice that the pca construction can be computed in this example efficiently by using the orthogonal transform @xmath268 where @xmath269 and @xmath270 .",
    "the parameters are @xmath271 and @xmath272 for @xmath273 .",
    "moreover , the volatility of the @xmath274 assets is equally spaced from @xmath275 to @xmath276 and we assume that @xmath277 for all @xmath249 . since we simulate every asset at @xmath278 time points , we take a sobol sequence in dimension @xmath279 with a random shift . in figure",
    "[ fig : asian ] we can observe the standard deviation based on @xmath241 batches of the forward method , the pca construction , the lt method and the regression method for @xmath242 sample paths with @xmath242 up to @xmath244 .      a digital ( up - and - in ) barrier option is a derivative which pays @xmath280 if the underlying asset breaks through a barrier @xmath281 on the time interval @xmath13 $ ] and pays @xmath282 otherwise .",
    "we intend to price the option in a discrete black - scholes model , where the path of the stock is given by @xmath283 with @xmath284 with current stock price @xmath285 , interest rate @xmath146 , volatility @xmath147 , brownian path @xmath286 where @xmath287 and standard normal vector @xmath288 .",
    "hence , the payoff function @xmath153 of the digital barrier option is @xmath289 which leads us to an integration problem of the form @xmath290 .",
    "we can use algorithm [ alg : main ] for solving this problem and therefore , we have to compute @xmath291 for @xmath292 . in the appendix",
    "we show how to calculate this expectation for a function depending on the maximum of a brownian motion with drift @xmath293 .",
    "we can adjust our problem by @xmath294 with @xmath295 , @xmath296 and @xmath297 .",
    "with @xmath298 we get that the vector @xmath236 in algorithm [ alg : main ] can be approximated by @xmath299 where @xmath34 is given by ( [ eq : summation - matrix ] ) , @xmath300 with @xmath301 , @xmath302 and @xmath303 .",
    "the computation of @xmath304 with @xmath292 can be reduced to a @xmath280-dimensional integration problem using ( [ eq : refl3 ] ) with @xmath305 and @xmath306 and formula ( [ eq : refl1 ] ) with @xmath307 simplifies @xmath308 .",
    "consequently , we end up with @xmath280-dimensional integrals which can be evaluated efficiently with an adaptive quadrature rule .    for the numerical test we use a sobol sequence of dimension @xmath309 with a random shift and the parameter set",
    "is chosen as @xmath310 and @xmath148 . the number of sample paths @xmath242 ranges from @xmath243 to @xmath244 and we compute the standard deviation for those @xmath242 based on @xmath241 batches . since it is not clear how to apply the lt method of imai and tan to barrier options , we compare the regression method with the forward method and the pca construction only . in figure",
    "[ fig : barrier ] we can observe that the difference between the forward method and the pca is smaller than in the previous examples .",
    "furthermore , we see that the regression method is slightly behind the pca , but this seems to be the best we can achieve by linear approximation",
    ".     runs on a @xmath246-scale , width=298,height=207 ]     runs on a @xmath246-scale , width=298,height=207 ]      the last example we provide is an asian ( up - and - in ) barrier option by which we mean that the payoff of the option is similar to an asian option as in the first numerical example , but is paid only if the underlying asset breaks through an upper barrier @xmath281 . the corresponding function",
    "is then given by @xmath311 where @xmath312 is as in ( [ eq : discretestock ] ) for @xmath313 .",
    "since the function @xmath3 is of the form @xmath314 with @xmath315 , @xmath316 and @xmath317 , we apply algorithm [ alg : general ] with @xmath318 to the problem .",
    "the computation of the vectors @xmath319 and @xmath320 is already discussed in the examples above , i.e.  @xmath319 is related to the digital barrier option and @xmath320 corresponds to the asian option .",
    "the numerical test is based on @xmath241 batches and we again compare the standard deviation of the forward method , the pca construction and the regression method for various numbers of sample paths @xmath242 , ranging from @xmath243 to @xmath244 .",
    "moreover , we use a sobol sequence in dimension @xmath321 with a random shift and the parameters are @xmath322 and @xmath148 .",
    "figure [ fig : barrier ] shows that the regression method yields slightly better results than the pca and that the forward method is behind the other two approaches .",
    "we give the computations needed for examples of barrier type , that is we want to compute @xmath152 where @xmath153 is some function of the maximum of a discrete brownian path with drift @xmath293 , i.e. @xmath323 and where @xmath324 .",
    "we make the approximation @xmath325 where @xmath326 denotes brownian motion with drift @xmath327 , i.e.  @xmath328 , @xmath329",
    ". moreover , let @xmath330 and @xmath331 .",
    "at first we compute @xmath332 for given @xmath333 and measurable @xmath3 with @xmath334 .",
    "then we show how the expectation for more general @xmath335 can be computed using the first result .",
    "we start with a simple calculation for a brownian motion @xmath12 with drift 0 and let @xmath336 .",
    "for @xmath337 we get , using the reflection principle for brownian motion , @xmath338 next we make a girsanov - type change of measure such that under the new measure @xmath339 the brownian motion @xmath326 with drift becomes a standard brownian motion .",
    "so with @xmath340 , that is @xmath341 @xmath342 the next step is to consider @xmath332 for @xmath343 .",
    "let @xmath344 denote the standard filtration of @xmath12 .",
    "@xmath345 we have already computed the first term . for the second term",
    "we note that by the markov property of brownian motion , @xmath346 we can use our earlier result ( [ eq : refl1 ] ) with @xmath347 to obtain @xmath348 let us write @xmath349 .",
    "then , using ( [ eq : refl1 ] ) and ( [ eq : refl2 ] ) we obtain @xmath350 note that the expectations can be computed explicitly for suitable @xmath3 .                  p.  lecuyer and d.  munger . on figures of merit for randomly - shifted lattice rules . in h.",
    "woniakowski and l.  plaskota , editors , _ monte carlo and quasi monte carlo methods 2010 _ , berlin , 2012 .",
    "springer.to appear .",
    "p.  lecuyer , j .- s .",
    "parent - chartier , and m.  dion .",
    "simulation of a lvy process by pca sampling to reduce the effective dimension . in _ proceedings of the 2008 winter simulation conference _ , pages 436443 .",
    "ieee press , 2008 ."
  ],
  "abstract_text": [
    "<S> there are a number of situations where , when computing prices of financial derivatives using quasi - monte carlo ( qmc ) , it turns out to be beneficial to apply an orthogonal transform to the standard normal input variables . </S>",
    "<S> sometimes those transforms can be computed in time @xmath0 for problems depending on @xmath1 input variables . among those are classical methods like the brownian bridge construction and principal component analysis ( pca ) construction for brownian paths .    </S>",
    "<S> building on preliminary work by imai & tan @xcite as well as wang & sloan @xcite , where the authors try to find optimal orthogonal transform for given problems , we present how those transforms can be approximated by others that are fast to compute .    </S>",
    "<S> we further present a new regression - based method for finding a householder reflection which turns out to be very efficient for a wide range of problems . </S>",
    "<S> we apply these methods to several very high - dimensional examples from finance . </S>"
  ]
}