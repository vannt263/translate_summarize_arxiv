{
  "article_text": [
    "large - scale object classification and visual recognition have seen rising interest in the recent years .",
    "data sets such as imagenet  @xcite have helped scale up the number of classes represented in tasks such as object classification or detection .",
    "many methods based on deep convolutional neural networks  @xcite have been developed recently to leverage the power of millions of training images distributed among thousands of classes .",
    "however , building a large data set , especially collecting large number of training images is very challenging and nevertheless this ends up representing only a fraction of the real visual world  @xcite .",
    "transfer learning is a practical solution to bridge this gap as it allows to leverage knowledge and experience obtained from existing data to new domains . specifically for object classification ,",
    "knowledge from object categories which have labeled image samples can be transferred to new unseen categories which do not have training images .",
    "this task is referred to as zero - shot learning ( zsl ) .",
    "there exist many directions in the literature to perform zsl .",
    "these primarily differ in the type of knowledge source they tap in order to establish the connection between the unseen classes and the available visual information  @xcite . among these directions ,",
    "attribute - based knowledge transfer shows impressive performance  @xcite . by learning an intermediate layer of semantic attributes (  colors or shapes ) , a novel class",
    "is then described with a subset of these attributes and its model is constructed accordingly based on the respective attribute classifiers .",
    "a major drawback of attribute - based approaches is that user supervision is needed to provide the description for each novel class .",
    "for example , for the new class `` leopard '' the user needs to describe it with a set of visual attributes in order to establish the semantic link with the learned visual vocabulary (  the leopard has part paws , it exhibits a spotted pattern but does not live in water ) .",
    "this amounts to providing manual class - attribute associations in the range of tens  @xcite to hundreds  @xcite of attributes for each new category .",
    "this is not only time consuming but often also requires domain - specific or expert knowledge  @xcite that the user is unlikely to have .",
    "it is more convenient and intuitive for the user to provide just the name of the unseen class rather than a lengthy description .",
    "our goal is to remove this need for attribute supervision when performing zero - shot classification .",
    "we aim to automatically link a novel category with the visual vocabulary and predict its attribute association without user intervention .",
    "thereby , we answer questions such as : does the leopard live in the jungle ? does it have a striped pattern ?",
    "( see  ) . to this end",
    ", we propose a novel approach that learns semantic relations and automatically associates an unseen class with our visual vocabulary (  the attributes ) based solely on the class name .",
    "using the predicted relations , we are able to construct a classifier of the novel class and conduct unsupervised zero - shot classification . moreover ,",
    "we demonstrate that our model is even able to automatically transfer the visual vocabulary itself across data sets which results in significant performance improvements at no additional cost .",
    "we demonstrate the effectiveness of such a model against state - of - the - art via extensive experiments .",
    "in zsl the set of train and test classes are disjoint .",
    "that is , while we have many labeled samples of the train classes to learn a visual model , we have never observed examples of the test class ( a.k.a . unseen class ) . in order to construct a visual model for the unseen class ,",
    "we first need to establish its relation to the visual knowledge that is obtained from the training data .",
    "one of the prominent approaches in the literature is attribute - based zsl .",
    "attributes describe visual aspects of the object , like its shape , texture and parts  @xcite .",
    "hence , the recognition paradigm is shifted from labeling to describing  @xcite . in particular , attributes act as an intermediate semantic representation that can be easily transferred and shared with new visual concepts  @xcite . in zsl , attributes have been used either directly  @xcite , guided by hierarchical information  @xcite , or in transductive settings  @xcite .    however , most attribute - based zsl approaches rely on the underlying assumption that for an unseen class the complete information about attribute associations are manually defined  @xcite or imported from expert - based knowledge sources  @xcite .",
    "this is a hindering assumption since the common user is unlikely to have such a knowledge or is simply unwilling to manually set hundreds of associations for each new category .    towards simplifying the required user involvement ,",
    "given an unseen class @xcite reduces the level of user intervention by asking the operator to select the most similar seen classes and then inferring its expected attributes .",
    "@xcite go a step further and propose an unsupervised approach to automatically learn the class - attribute association strength by using text - based semantic relatedness measures and co - occurrence statistics obtained from web - search hit counts .",
    "however , as web data is noisy , class and attribute terms can appear in documents in different contexts which are not necessarily related to the original attribute relation we seek .",
    "we demonstrate in this work , that the class - attribute relations are complex and it is hard to model them by simple statistics of co - occurrence .    in an effort to circumvent the need for manually defined associations , @xcite propose to extract pseudo attributes from wikipedia articles using tf - idf based embeddings to predict the visual classifier of an unseen class . in theory , an article can be extracted automatically by searching for a matching title to the class name .",
    "however , in practice manual intervention is needed when there is no exact match or the article is titled with a synonym or the scientific name of the category as reported by  @xcite .    in a different direction ,",
    "unsupervised zsl can be conducted by exploiting lexical hierarchies .",
    "for example , @xcite uses wordnet  @xcite to find a set of ancestor categories of the novel class and transfer their visual models accordingly .",
    "likewise , @xcite uses the hierarchy to transfer the attribute associations of an unseen class from its seen parent in the ontology . in  @xcite , wordnet is used to capture semantic similarity among classes in a structured joint embedding framework .",
    "however , categories that are close to each other in the graph (  siblings ) often exhibit similar properties to their ancestors making it hard to discriminate among them .",
    "moreover , ontologies like wordnet are not complete .",
    "many classes ( fine - grained ) are not present in the hierarchy .",
    "recently , @xcite proposed to learn a direct embedding of visual features into the semantic word space of categories .",
    "they leverage a powerful neural word embedding  @xcite that is trained on a large text corpus , and learn a mapping from the space of visual features to the word representation . at test time , they predict an image class by looking for the nearest category embedding to the one estimated by the neural network .",
    "@xcite  shows impressive results of this approach for large - scale zsl .",
    "@xcite improves upon @xcite by considering a convex combination of word embeddings weighted by classifiers confidences to estimate the unseen class embedding .",
    "however , we show in our evaluation that such word embedding approaches are less discriminative than their attribute - based counterpart .",
    "we propose an approach that goes beyond using web statistics , predefined ontologies and word embedding estimation .",
    "we provide an automatic framework to learn complex class - attribute relations and effectively transfer knowledge across domains for unsupervised zero - shot learning .",
    "0.32     0.32     0.32     we present an end - to - end approach to automatically predict class - attribute associations and use them for zero - shot classification .",
    "we begin by ( i ) finding suitable vector representations for words and use the learned embedding as a way to mathematically relate class and attribute names .",
    "these representations form the basis to model semantic relationships between classes and attributes .",
    "( ii ) we formulate the learning of these relations in a tensor factorization framework ( see ) and offer key insights to adapt such a model to our problem . finally , ( iii ) for an unseen class we show how to predict the set of its most confident attribute associations and carry out zero - shot classification .",
    "we start by defining the notation used throughout this paper .",
    "[ [ notation ] ] notation + + + + + + + +    let @xmath0 be a set of seen categories that are described with a group of attributes @xmath1 .",
    "the vector representation of a word is denoted by @xmath2 , and we use @xmath3 and @xmath4 for class @xmath5 and attribute @xmath6 respectively .",
    "the categories and attributes are related by a set of relations @xmath7 such that @xmath8 if @xmath5 is connected to @xmath6 by relation @xmath9 and @xmath10 otherwise ( @xmath11 ) .",
    "given only the name of an unseen class @xmath12 , our goal is to predict the attributes that are associated with the class ( @xmath13 ) and conduct zsl accordingly .      in order to model the relations between classes and attributes , we require a suitable representation that transforms names to vectors while at the same time preserves the semantic connotations of the words .",
    "hereof , we use the skip - gram model presented by mikolov  @xcite to learn vector space embeddings for words .",
    "the skip - gram model is a neural network that learns vector representations for words that best help in predicting the surrounding words .",
    "therefore , words that appear in a similar context ( neighboring words ) are represented with vectors that are close to each other in the embedding space .",
    "visualizes the obtained word vector representation for few classes and attributes in our data set using t - sne  @xcite .",
    "even in such a low - dimension it is clear that classes related to each other appear closer .",
    "this is evident for example from the group of dog breeds or feline in .",
    "similarly , we also see clusters in the attribute label space corresponding to colors , animal parts , and environment ( see ) .",
    "[ [ relations - in - embedding - space ] ] relations in embedding space + + + + + + + + + + + + + + + + + + + + + + + + + + + +    the skip - gram embeddings have gained popularity owing to their power in preserving useful linguistic patterns .",
    "an empirical evaluation  @xcite shows that syntactic / semantic relations can be represented by simple vector operations in the word embedding space .",
    "a great example is @xmath14 , where @xmath15 is the embedding for `` king '' . in other words ,",
    "the relation between  king \" and  man \" modeled by their displacement vector is similar to the displacement between  queen \" and  woman \" .",
    "however , modeling class - attribute relations by simple vector operations is inadequate . presents the t - sne representation for _ displacement vectors _ between each class - attribute pair (  @xmath16 ) .",
    "we see that displacement vectors for both positive existing relations _ and _ negative non - existing relations are inseparable .",
    "we empirically show in that class - attribute relations are more complicated and are not easily represented by simple vector operations .    to address this challenge",
    "we adopt a more sophisticated and comprehensive method to learn these relations while at the same time effectively exploit the powerful word embedding representation .    .",
    "each slice @xmath17 captures a relationship like has_shape or motion_type .",
    "the embeddings are obtained from a neural network trained on a large text corpus . ]",
    "we now model the complex relations between categories and their corresponding visual attributes . leveraging information based on these relations",
    ", we can predict the associations between a novel unseen class and our attribute vocabulary and build the corresponding zsl classifier .    we propose to model the class - attribute relations using a tensor factorization approach  @xcite . we represent the relations using a three dimensional tensor @xmath18 where @xmath19 is the dimension of the word embedding and",
    "@xmath20 the number of relations ( see ) .",
    "each slice @xmath21 in the tensor models a relation @xmath9 (  @xmath22 ) as a bilinear operator .",
    "the likelihood of class @xmath5 being associated with attribute @xmath6 through relation @xmath9 is : @xmath23 where @xmath24 is the vector embedding of word @xmath25 and @xmath26 is the logistic function .",
    "we learn @xmath27 by minimizing the negative log - likelihood of both positive ( @xmath28 ) and negative ( @xmath29 ) class - attribute associations for each slice @xmath30 :    @xmath31    note that there are two key components in .",
    "firstly , we take advantage of the powerful representation of skip - gram and learn word embeddings on a large text corpus to initialize the embeddings of our class ( @xmath32 ) and attribute ( @xmath33 ) entities .",
    "this gives our model the ability to generalize well to unseen classes and take advantage of the initial learned similarities among the attributes .",
    "secondly , in our case of zero - shot classification , the novel class name is not available during training and we have no information about how this unseen class is related with the visual attributes .",
    "consequently , we treat the set of categories as an _ open _ set and fix their embedding @xmath32 to the one learned in  . on the other hand , visual attributes @xmath34 are usually restricted to entities which we have seen before , and for which we have training images and learned models .",
    "this allows us to propagate gradients to @xmath33 during training and optimize the attributes embeddings which yields improved performance ( see model analysis in ) .",
    "[ [ limited - training - data ] ] limited training data + + + + + + + + + + + + + + + + + + + + +    learning @xmath27 directly from training data is not favorable since the number of class - attribute associations available for training are usually small .",
    "for example , a typical data set consisting of 40 categories and 80 attributes yields around 1500 positive associations compared to tens or even hundreds of thousands of parameters in @xmath27 .",
    "hence , in order to avoid overfitting we build on the ideas of  @xcite and reduce the number of parameters that are required to be learned , by representing the relation operator @xmath17 as a combination of @xmath35 latent factors : @xmath36 where @xmath37 is a sparse vector used to weight the contributions of the rank one latent factors @xmath38 . both @xmath39 and @xmath38 are learned while minimizing and constraining .",
    "the parameter @xmath40 controls the sparsity of @xmath39 , and hence the extent to which latent factors are shared across relations .",
    "modeling @xmath27 with latent factors has the benefit of allowing the learned relations to interact and exchange information through @xmath38 and hence improves the ability of the model to generalize .",
    "[ [ type - of - relations ] ] type of relations + + + + + + + + + + + + + + + + +    in order to train our model , we need to define the relations that link classes with the respective attributes .",
    "usually these relations are harvested through the process of collecting and annotating attributes ( what color is a bear ?",
    "what shape is a bus ? ) .",
    "we refer to this type of relations as _",
    "semantic relations_. however , while some data sets do provide such relation annotations  @xcite others do not  @xcite . an alternative approach to manual annotation is to automatically discover relations by utilizing the word embedding space . as described earlier in ,",
    "embeddings of semantically related entities tend to be close to each other ( see ) .",
    "hence , one can simply group attributes into several relations by clustering their embeddings ( @xmath20 = number of clusters ) .",
    "we refer to this type of relations as _ data driven relations_.      given an unseen class @xmath41 , we predict its associations with the attribute set @xmath34 : @xmath42 where thresholds @xmath43 and @xmath44 are learned to help select the most confident positive and negative associations while at the same time provide enough discriminative attributes to predict a novel class .",
    "assignment to @xmath45 discards the attribute for zsl since we are not confident about the type ( positive or negative ) of the association .",
    "we learn these thresholds using leave - k - class - out cross - validation so as to maximize zero - shot classification accuracy of the held out classes .",
    "[ [ zero - shot - learning ] ] zero - shot learning + + + + + + + + + + + + + + + + + +    the score for unseen class @xmath41 on image @xmath25 is estimated based on the predicted attribute associations @xmath46 using the direct attribute prediction ( dap )  @xcite method : @xmath47 where @xmath48 is the posterior probability of observing attribute @xmath6 in image @xmath25 .",
    "we assume identical class and attribute priors .",
    "[ sec : experiments ] in this section , we evaluate our model at : ( 1 ) predicting class - attribute associations and ( 2 ) unsupervised zero - shot classification .",
    "furthermore , we demonstrate the ability of our model to ( 3 ) transfer attributes across data sets without the cost of additional annotations .",
    "finally , ( 4 ) we show that the model is generic and can learn different types of relations and not only attribute - based ones . in the following ,",
    "we refer to our class - attribute association prediction model as .    [",
    "[ subsec : datasetup ] ] data setup + + + + + + + + + +    we use two publicly available data sets . +",
    "( i ) animals with attributes ( awa )  @xcite : consists of 50 animal classes that are described with 85 attributes .",
    "the classes are split into 40 seen and 10 unseen classes for zsl .",
    "+ ( ii ) apascal / ayahoo ( apay )  @xcite : contains 32 classes of artifacts , people and animals ; and they are described with 64 attributes .",
    "20 of these classes ( apascal ) come from the pascal challenge  @xcite and are used for training , while the rest 12 ( ayahoo ) are considered unseen and used for zsl .",
    ".performance of class - attribute association predictions for unseen classes , presented in map ( accuracy ) . [ cols=\"<,^,^\",options=\"header \" , ]      various approaches in the literature have reported the advantage of incorporating hierarchical information for zsl (  @xcite ) .",
    "our model can also learn hierarchical relations , for example to predict the ancestors of a category . to test this ,",
    "we query wordnet  @xcite with the awa categories and extract the respective graph relevant to the hypernym links .",
    "we then learn the _",
    "relation by generating triplets of the form @xmath49 using the information from the extracted graph .",
    "the evaluation on awa test set reveals that we can predict the ancestor relation of an unseen class with a map of 89.8% .",
    "interestingly , learning such a hierarchy - based relation can aid the learning of some attribute - based relations .",
    "the model allows the various relations to interact and exchange information at the level of the shared latent factors . among the improved attribute - based relations ,",
    "is has_pattern ( + 2.5% ) , and feeding_type ( + 2.1% ) .",
    "these relations correlate well with the hierarchical information of the classes (  carnivores tend to have similar pattern and feeding type ) .",
    "predicting such a hierarchical relation alleviates the need of a complete hierarchy or manual synonym matching since this is automatically handled by the word embedding and model .",
    "this keeps user intervention to the minimal requirement of providing class names .",
    "we expect that modeling more relations among the classes jointly with class - attribute relations can result in better performance .",
    "attribute - based zsl suffers from a major drawback of needing class - attribute associations to be defined manually . to counter this , we present an automatic approach to predict the associations between attributes and unseen classes .",
    "we model the associations using a set of relationships linking categories and their respective attributes in an embedding space .",
    "our approach effectively predicts the associations of novel categories and outperforms state - of - the - art in two tasks ; namely association prediction and unsupervised zsl .",
    "moreover , we demonstrate the ability of our model to transfer attributes between data sets at no cost .",
    "the transferred attributes enlarge the size of the description vocabulary , which results in more discriminative classifiers for zsl yielding an additional boost in performance ."
  ],
  "abstract_text": [
    "<S> collecting training images for all visual categories is not only expensive but also impractical . </S>",
    "<S> zero - shot learning ( zsl ) , especially using attributes , offers a pragmatic solution to this problem . </S>",
    "<S> however , at test time most attribute - based methods require a full description of attribute associations for each unseen class . </S>",
    "<S> providing these associations is time consuming and often requires domain specific knowledge . in this work </S>",
    "<S> , we aim to carry out attribute - based zero - shot classification in an unsupervised manner . </S>",
    "<S> we propose an approach to learn relations that couples class embeddings with their corresponding attributes . </S>",
    "<S> given only the name of an unseen class , the learned relationship model is used to automatically predict the class - attribute associations . </S>",
    "<S> furthermore , our model facilitates transferring attributes across data sets without additional effort . integrating knowledge from multiple sources results in a significant additional improvement in performance . </S>",
    "<S> we evaluate on two public data sets : animals with attributes and apascal / ayahoo . </S>",
    "<S> our approach outperforms state - of - the - art methods in both predicting class - attribute associations and unsupervised zsl by a large margin . </S>"
  ]
}