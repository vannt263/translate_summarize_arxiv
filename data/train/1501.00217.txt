{
  "article_text": [
    "this article concerns the problem of computing equilibrium averages of time homogeneous , ergodic markov chains in the presence of metastability .",
    "a markov chain is said to be _",
    "metastable _ if it has typically very long sojourn times in certain subsets of state space , called _",
    "metastable sets_. a new method , called the parallel replica method ( or parrep ) , is proposed for efficiently simulating equilibrium averages in this setting .",
    "markov chains are widely used to model physical systems . in computational statistical physics  the main setting for this article  markov chains are used to understand macroscopic properties of matter , starting from a mesoscopic or microscopic description .",
    "equilibrium averages then correspond to bulk properties of the physical system under consideration , like average density or internal energy .",
    "a popular class of such models are the markov state models  @xcite .",
    "markov chains also arise as time discretizations of continuous time models like the langevin dynamics  @xcite , a popular stochastic model for molecular dynamics . for examples of markov chain models",
    "not obtained from an underlying continuous time dynamics , see for example  @xcite .",
    "it should be emphasized that the discrete in time setting is generic  even if the underlying model is continuous in time , what must be simulated in practice is a time - discretized version .    in computational statistical physics ,",
    "metastability arises from entropic barriers , which are bottlenecks in state space , as well as energetic barriers , which are regions separating metastable states through which crossings are unlikely ( due to , for example , high energy saddle points in a potential energy landscape separating the states )",
    ". see figures  12 for simple examples of entropic and energetic barriers .",
    "the method proposed here is closely related to a recently proposed algorithm  @xcite , also called parrep , for efficient simulation of metastable markov chains on a coarsened state space .",
    "that algorithm can be considered an adaptation of a.f .",
    "voter s parallel replica dynamics  @xcite to a discrete time setting .",
    "( for a mathematical analysis of a.f .",
    "voter s original algorithm , see  @xcite . ) parrep was shown to be consistent with an analysis based on quasistationary distributions ( qsds ) , or local equilibria associated with each metastable set .",
    "parrep uses parallel processing to explore phase space more efficiently in real time .",
    "a cost of the parallelization is that only a _",
    "coarse _ version of the markov chain dynamics , defined on the original state space modulo the collection of metastable sets , is obtained . in this article",
    "it is shown that a simple modification of the parrep algorithm of  @xcite nonetheless allows for computation of equilibrium averages of the original , _ uncoarsened _ markov chain .",
    "-140pt     on state space @xmath0 with an entropic barrier .",
    "at each step , a direction up , down , left or right is selected at random , each with probability @xmath1 .",
    "then @xmath2 moves one unit in this direction , provided this does not result in crossing a barrier , i.e. , one of the edges of the two boxes pictured .",
    "the walk can cross from the left box to the right box only through the narrow pathways indicated .",
    "the metastable sets are @xmath3 . ]",
    "-130pt    -130pt     on state space @xmath4 with energy barriers .",
    "the random walk moves one unit left or right according to a biased coin flip : if @xmath5 and the slope of the pictured graph at @xmath6 is @xmath7 , then with probability @xmath8 , @xmath9 , and with probability @xmath10 , @xmath11 .",
    "the metastable sets are @xmath12 . ]",
    "-130pt    the parrep algorithm proposed here is very general .",
    "it can be applied to any markov chain , and gains in efficiency can be expected when the chain is metastable and the metastable sets can be properly identified ( either a priori or on the fly ) . in particular , it can be applied to metastable markov chains with both energetic and entropic barriers , and no assumptions about barrier heights , temperature or reversibility are required .",
    "while there exist many methods for sampling from a distribution , most methods , particularly in markov chain monte carlo  @xcite , rely on a priori knowledge of relative probabilities of the distribution .",
    "in contrast with these methods , parrep does not require _ any _ information about the equilibrium distribution of the markov chain .",
    "the article is organized as follows .",
    "section  [ sec : qsd ] defines the qsd and notation used throughout .",
    "section  [ sec : parrep ] introduces the parrep algorithm for computing equilibrium averages ( algorithm  [ alg1 ] ) . in section",
    "[ sec : numerics ] , consistency of the algorithm is demonstrated on the simple models pictured in figures  1 and  2 .",
    "a proof of consistency in an idealized setting is given in the appendix .",
    "some concluding remarks are made in section  [ sec : conclude ] .",
    "throughout , @xmath13 is a time homogeneous markov chain on a standard borel state space , and @xmath14 is the associated measure when @xmath15 , where @xmath16 denotes equality in law . all sets and functions are assumed measurable without explicit mention .",
    "the collection of metastable sets will be written @xmath17 , with elements of @xmath17 denoted by @xmath18 .",
    "formally , @xmath17 is simply a set of disjoint subsets of state space .",
    "[ d1 ] a probability measure @xmath19 with support in @xmath18 is called a quasistationary distribution ( qsd ) if for all @xmath20 and all @xmath21 , @xmath22    that is , if @xmath23 , then conditionally on @xmath24 , @xmath25 .",
    "it is not hard to check that , if for every probability measure @xmath26 supported in @xmath18 and every @xmath21 , @xmath27 then @xmath19 is the unique qsd in @xmath18 .",
    "informally , if   holds , then @xmath13 is close to @xmath19 whenever it spends a sufficiently long time in @xmath18 without leaving .",
    "of course @xmath19 depends on @xmath18 , but this will not be indicated explicitly .",
    "let @xmath13 be ergodic with equilibrium measure @xmath28 , and fix a bounded real - valued function @xmath29 defined on state space .",
    "the output of parrep is an estimate of the average of @xmath29 with respect to @xmath28 .",
    "the algorithm requires existence of a unique qsd in each metastable set , so it is assumed for each @xmath30 there is a unique @xmath19 satisfying  .",
    "this assumption holds under very general mixing conditions ; see  @xcite .",
    "the user - chosen parameters of the algorithm are the number of replicas , @xmath31 ; the decorrelation and dephasing times , @xmath32 and @xmath33 ; and a polling time , @xmath34 . the parameters @xmath32 and @xmath33 are closely related to the time needed to reach the qsd ; both may depend on @xmath30 . to emphasize this ,",
    "sometimes @xmath35 or @xmath36 are written .",
    "the parameter @xmath34 is a polling time at which the parallel replicas resynchronize .",
    "see below for further discussion .",
    "[ alg1 ] set the simulation clock to zero : @xmath37 , and set @xmath38 . then iterate the following :    * * _ decorrelation step . _ * + evolve @xmath13 from time @xmath39 until time @xmath40 , where @xmath41 is the smallest number @xmath42 such that there exists @xmath30 with @xmath43 .",
    "meanwhile , update @xmath44 then set @xmath45 and proceed to the dephasing step , with @xmath18 now the metastable state having @xmath46 . * * _ dephasing step . _",
    "* + generate @xmath31 independent samples , @xmath47 , of the qsd @xmath19 in @xmath18 . then proceed to the parallel step . * * _ parallel step .",
    "* + \\(i ) set @xmath48 and @xmath49 .",
    "let @xmath50 be replicas of @xmath13 , that is , markov chains with the same law as @xmath13 which are independent of @xmath13 and one another . set @xmath51 , ... , @xmath52",
    "+ \\(ii ) evolve all the replicas from time @xmath53 to time @xmath54 .",
    "+ \\(iii ) if none of the replicas leave @xmath18 during this time , update @xmath55 and return to ( ii ) above . otherwise , let @xmath56 be the smallest number such that @xmath57 leaves @xmath18 during this time , let @xmath58 $ ] be the corresponding first exit time , and update @xmath59 then update @xmath60 , set @xmath61 , and return to the decorrelation step",
    ".    see figure  3 for an illustration of the parallel step .",
    "the key quantity in the algorithm is the running average @xmath62 , which is an estimate of the average of @xmath29 with respect to the equilibrium measure @xmath28 : @xmath63 some remarks on algorithm  [ alg1 ] are in order .",
    "the crosses represent exits from @xmath18 .",
    "after @xmath64 loops internal to the parallel step , two of the replicas leave @xmath18 , with @xmath57 , the one among these having the smallest index @xmath56 , leaving at time @xmath65 .",
    "the trajectories of all the replicas can be concatenated into a single long trajectory of length @xmath66 .",
    "this single long trajectory is obtained by running through the columns of width @xmath34 from top to bottom , starting at the far left , in the order @xmath67 indicated .",
    "the time marginals of this long trajectory ( except its right endpoint ) are all distributed according to the qsd in @xmath18 . ]",
    "-70pt    * * the decorrelation step . *",
    "the purpose of the decorrelation step is to reach the qsd in some metastable set .",
    "indeed , the decorrelation step terminates exactly when @xmath68 has spent @xmath32 consecutive time steps in some metastable set @xmath18  so the position of @xmath68 at the end of the decorrelation step can be considered an approximate sample from @xmath19 , the qsd in @xmath18 . the error in this approximation",
    "is controlled by the parameter @xmath32 .",
    "larger values of @xmath32 lead to increased accuracy but lessened efficiency ; see the numerical tests in section  [ sec : numerics ] below , in particular figures  4 and  6 . during the decorrelation step ,",
    "the dynamics of @xmath13 is exact , so the contribution to @xmath69 from the decorrelation step is exact . * * the dephasing step . *",
    "the dephasing step requires sampling @xmath31 iid copies of the qsd in @xmath18 , where @xmath18 is the metastable set from the end of the decorrelation step .",
    "the practitioner has flexibility in sampling these points . essentially , one has to sample @xmath31 endpoints of trajectories of @xmath13 that have remained in @xmath18 for a long enough time , with this time being controlled by the parameter @xmath33 .",
    "for example , the dephasing step can be done with rejection sampling , keeping trajectories which have remained in @xmath18 for time @xmath33 .",
    "alternatively , the qsd samples may be obtained via techniques related to the fleming - viot process ; for details see  @xcite and  @xcite .",
    "this technique can be summarized as follows : @xmath31 replicas of @xmath13 , all starting in @xmath18 , are independently evolved until one or several leave @xmath18 ; then each replica which left @xmath18 is restarted from the current position of another replica still inside @xmath18 , chosen uniformly at random .",
    "after time @xmath33 this procedure stops and the current positions of the replicas are used as the @xmath31 required samples of @xmath19 .",
    "+ under mild mixing conditions , convergence to the qsd is very fast .",
    "more precisely , the limit in the right hand side of   converges to @xmath19 geometrically fast in total variation norm  @xcite .",
    "an analysis of the error associated with not exactly reaching the qsd will be the focus of another work . for an analysis of the error associated with not reaching",
    "the qsd in the original continuous - in - time version of the algorithm , see  @xcite . in the metastable",
    "setting considered here , the average time to ( approximately ) reach the qsd in @xmath18 is assumed much smaller than the average time , starting at the qsd , to leave @xmath18 .",
    "indeed , this assumption can be considered the very definition of metastability .",
    "gains in efficiency in parrep are limited by the degree of metastability ; see  @xcite and the discussion in section  [ sec : numerics ] below .",
    "+ it is emphasized that @xmath69 and @xmath70 are left unchanged during the dephasing step .",
    "contributions to @xmath69 and @xmath70 come only from the decorrelation and parallel steps . * * the parallel step . *",
    "the purpose of the parallel step is twofold .",
    "first , it simulates an exit event from @xmath18 , the metastable set from the end of the decorrelation step , starting from the qsd in @xmath18 .",
    "this is consistent with the exit event that would have been observed if , in the decorrelation step , @xmath13 had been allowed to continue evolving until leaving @xmath18 : + [ t0b]_(proposition  4.5 of  @xcite . )",
    "_ suppose the qsd sampling in the dephasing step of algorithm  [ alg1 ] is _",
    "exact_. then in the parallel step , @xmath71 , where @xmath72 , with @xmath19 the qsd in @xmath18 and @xmath73 . + the gain in efficiency in parrep , compared to direct serial simulation , comes from the use of parallel processing in the parallel step .",
    "the wall - clock time speedup  the ratio of average serial simulation time to the parrep simulation time of the exit event  scales like @xmath31 , though the gain in efficiency in parrep as a whole depends also on @xmath32 , @xmath33 and the degree of metastability of the sets in @xmath17 .",
    "+ second , the parallel step includes a contribution to @xmath69 .",
    "as the fine scale dynamics of @xmath68 in @xmath18 are not retained in the parallel step , this contribution is not exact .",
    "it is , however , consistent _ on average _ , which is sufficient for the computation of equilibrium averages .",
    "this can be understood as follows .",
    "concatenate all the trajectories of all the replicas into a single long trajectory by following the procedure indicated in figure  3 .",
    "the resulting trajectory has a probability law that is of course different from that of @xmath68 starting from the qsd @xmath19 in @xmath18 .",
    "however , in light of definition  [ d1 ] , the _ time marginals _ of this trajectory ( except the right endpoint ) are all distributed according to @xmath19 . moreover , from theorem  [ t0b ] , the total length of this concatenated trajectory has the same law as that of @xmath68 started from the qsd in @xmath18 and stopped at the first exit time from @xmath18 .",
    "so by linearity of expectation , the contribution to @xmath69 from the parallel step is consistent on average .",
    "see the appendix for proofs of these statements in an idealized setting . *",
    "* other remarks . *",
    "the parameter @xmath34 is a polling time at which the possibly asynchronous parallel processors in the parallel step resynchronize . for the parallel step to be finished correctly",
    ", one has to wait until the first @xmath56 processors have completed @xmath74 time steps .",
    "if the processors are nearly synchronous or communication between them is cheap , one can take @xmath75 .",
    "+ the metastable sets @xmath17 need not be known a priori . in many applications , they can be identified on the fly ; for example , when the metastable sets are the basins of attraction of a potential energy , they can be found efficiently on the fly by gradient descent .",
    "the reader is referred to  @xcite as well as  @xcite and references therein for examples of successful applications of related versions of parrep in this setting .",
    "consider the markov chain from figure 1 on state space @xmath0 .",
    "the markov chain evolves according to a random walk : at each time step it moves one unit up , down , left or right each with probability @xmath1 , provided the result is inside state space ; if not , the move is rejected and the position stays the same .",
    "there is one exception : if the current position is @xmath76 or @xmath77 and a move to the right is proposed , then the next position is @xmath78 or @xmath79 , respectively ; and if the current position is @xmath78 or @xmath79 and a move to the left is proposed , then the next position is @xmath76 or @xmath77 , respectively .",
    "this markov chain is ergodic with respect to the uniform distribution @xmath80 on state space .",
    "-110pt     in parrep simulations of the markov chain from example 1 , with @xmath81 .",
    "the straight lines correspond to exact values .",
    "parrep simulations were stopped when @xmath70 first exceeded @xmath82 , and error bars are standard deviations obtained from @xmath83 independent trials . ]    -110pt    -110pt    .",
    "parrep simulations were stopped when @xmath70 first exceeded @xmath84 , and error bars are standard deviations obtained from @xmath83 independent trials . ]",
    "-110pt    parrep was performed on this system with @xmath85 , @xmath86 , and @xmath3 .",
    "parameters were always chosen so that @xmath87 and @xmath88 , and qsd samples from the dephasing step were obtained using the fleming - viot - based technique described above .    with @xmath81 replicas and various values of @xmath89 ,",
    "parrep was used to obtain average @xmath6- and @xmath90-coordinates with respect to @xmath80 as well as the @xmath80-probability to be in the upper half of the right hand side box , denoted by : @xmath91 } \\,d\\mu_{unif}.\\end{aligned}\\ ] ] here @xmath92 denotes the indicator function of @xmath93 . see figure  4 .",
    "also computed was the average _ time speedup _ : namely , @xmath70 divided by the `` wall clock time , '' defined as follows . like @xmath70 , the wall clock time stars at zero .",
    "it increases by @xmath94 during each time step of @xmath13 in the decorrelation step ( consistent with @xmath70 ) , while it increases by @xmath74 in the parallel step ( unlike @xmath70 , which increases by @xmath66 ) .",
    "the wall clock time also increases by @xmath33 during the dephasing step ( where @xmath70 does not increase at all ) .",
    "informally , the wall clock time corresponds to true clock time in an idealized setting where all the processors always compute one time step of @xmath13 in exactly @xmath94 unit of time , and communication between processors takes zero time . as @xmath32 increases , the time speedup decreases , but accuracy increases .",
    "-110pt     in parrep simulations of the markov chain from example 2 , with @xmath81 .",
    "the straight lines correspond to exact values .",
    "parrep simulations were stopped when @xmath70 first exceeded @xmath95 , and error bars are standard deviations obtained from @xmath83 independent trials .",
    "for the smallest value of @xmath96 , the markov chain is typically close to the edges of @xmath97 , @xmath98 or @xmath99 , which results in shorter parallel steps and thus a smaller time speedup . ]",
    "-110pt    -110pt    .",
    "parrep simulations were stopped when @xmath70 first exceeded @xmath84 , and error bars are standard deviations obtained from @xmath83 independent trials . ]",
    "-110pt    figure  5 shows the dependence of time speedup on the number of replicas , @xmath31 , when @xmath100 . to illuminate",
    "the dependence of time speedup on @xmath31 , figure  5 also includes the average ( total ) number of decorrelation steps , parallel steps , and parallel loops ( i.e. , loops internal to the parallel step  in the notation of algorithm  [ alg1 ] , there are @xmath64 loops internal to the parallel step ) . as @xmath31 increases",
    ", the number of parallel loops decreases sharply , while the number of parallel steps and decorrelation steps remain nearly constant .",
    "thus , with increasing @xmath31 the wall clock time spent in the parallel step falls quickly .",
    "the time speedup , however , is limited by the wall clock time spent in the decorrelation step , and so it levels off with increasing @xmath31 . the value of @xmath31 at which this leveling off occurs depends on the degree of metastability in the problem , or slightly more precisely , the ratios , over all @xmath30 , of the time scale for leaving @xmath18 to the time scale for reaching the qsd in @xmath18 . in the limit",
    "as this ratio approaches infinity , the time speedup grows like @xmath31 .",
    "see  @xcite for a discussion of this issue in a continuous time version of parrep .",
    "consider the markov chain from figure  2 on state space @xmath101 .",
    "the markov chain evolves according to a biased random walk : if @xmath5 , then with probability @xmath102 , @xmath103 , while with probability @xmath104 , @xmath105 . here",
    ", @xmath106 the equilibrium distribution @xmath107 of this markov chain can be explicitly computed .",
    "parrep simulations were performed on this system with @xmath108 , @xmath109 , @xmath110 and @xmath12 .",
    "parameters were always chosen so that @xmath87 and @xmath111 , and qsd samples from the dephasing step were again obtained using the fleming - viot - based technique .    with @xmath81 replicas and various values of @xmath96 ,",
    "parrep was used to obtain the average @xmath6-coordinate with respect to @xmath107 as well as the @xmath107-probability to be in the right half of the interval , denoted by : @xmath112 } \\,d\\mu_{bias}.\\end{aligned}\\ ] ] also computed was the time speedup , defined exactly as above .",
    "simulations were stopped when @xmath70 first exceeded @xmath95 .",
    "see figure 6 .",
    "again , accuracy increases with @xmath32 , but the time speedup decreases with @xmath32 .    figure  7 shows the dependence of time speedup on the number of replicas , @xmath31 , when @xmath113 . also plotted are the average number of decorrelation steps , parallel steps , and parallel loops .",
    "the results are similar to example  1 , though the degree of metastability and time speedup are much larger .",
    "a new algorithm , parrep , for computing equilibrium averages of markov chains is presented .",
    "the algorithm requires no knowledge about the equilibrium distribution of the markov chain .",
    "gains in efficiency are obtained by asynchronous parallel processing . for these gains to be achievable in practice , the markov chain must possess some metastable sets .",
    "these sets need not be known a priori , but they should be identifiable on the fly ; for example , in many applications in computational chemistry , the metastable sets can be basins of attraction of a potential energy , identified on the fly by gradient descent .",
    "when metastable sets are present , the gains in efficiency are limited by the degree of metastability .",
    "see  @xcite for a discussion and an application of a related version of parrep in this setting .",
    "applications in computational chemistry seem numerous .",
    "nearly all popular stochastic models of molecular dynamics are markovian . even when these models are continuous in time , to actually simulate the models a time discretization is required and the result is a markov chain .",
    "generically , these models have many metastable sets associated with different geometric arrangements of atoms at distinct local minima of the potential energy or free energy . many times the equilibrium distributions of these models are unknown  for example if external forces are present  yet it is still of great interest to sample equilibrium . because of metastability it is often impractical or impossible to sample equilibrium with direct simulation .",
    "parrep may put such computations within reach .",
    "in this appendix , consistency of parrep is proved in an idealized setting .",
    "recall @xmath13 is a markov chain on a standard borel state space @xmath114 .",
    "the collect @xmath115 of disjoint sets is assumed finite , with a unique qsd @xmath19 associated to each metastable set @xmath18 .",
    "all probabilities , which may be associated to different spaces and random processes or variables , will be denoted by @xmath116 ; the meaning will be clear from context .",
    "probabilities associated with the initial distribution @xmath26 are denoted by @xmath14 .",
    "( if @xmath117 then @xmath118 is written instead . )",
    "the corresponding expectations are written @xmath119 , @xmath120 , or @xmath121 .",
    "the norm @xmath122 will always be total variation norm .",
    "in all the analysis below , an idealized setting is assumed .",
    "it is defined by two conditions : the qsd is sampled _ exactly _ in the dephasing step ( idealization  [ a0 ] ) , and the qsd is reached _ exactly _ by time @xmath32 ( idealization  [ a1 ] ) .",
    "these are idealizing assumptions in the sense that , in practice , the qsd is never exactly reached .    [ a0 ] in the dephasing step , the points @xmath123 are drawn independently and _ exactly _ from the qsd @xmath19 in @xmath18 .",
    "[ a1 ] for each @xmath30 there is a time @xmath124 such that , after spending @xmath32 consecutive time steps in @xmath18 , the markov chain @xmath13 is _ exactly _ distributed according to @xmath19 .",
    "that is , for every @xmath30 and every @xmath125 with @xmath126 , @xmath127    in practice , the word _",
    "exactly _ must be replaced with _",
    "approximately_. the error associated with not exactly reaching the qsd will not be studied here .",
    "see however  @xcite for an analysis of this error in the continuous in time setting . here",
    ", the idealized setting seems necessary to connect the parrep dynamics with those of the original markov chain .",
    "the idealizations allow these two dynamics to be synchronized after reaching the qsd , which is crucial in the analysis below .",
    "in particular , the analysis here can not be modified in a simple way to allow for inexact convergence to the qsd .    by idealization  [ a1 ] , at the end of each decorrelation step @xmath13 is distributed _ exactly _ according to the qsd . by idealization  [ a0 ] ,",
    "the parallel step is exact :    ( restated from  @xcite.)[t0 ] let idealization  [ a0 ] hold . then in the parallel step of algorithm  [ alg1 ] , @xmath71 , where @xmath72 , with @xmath19 the qsd in @xmath18 and @xmath73 .",
    "moreover , @xmath128 is a geometric random variable with parameter @xmath129 , and @xmath128 is independent of @xmath130 .    in particular , the first exit time from @xmath18 , starting at the qsd , is a geometric random variable which is independent of the exit position .",
    "this property is crucial for proving consistency of the parallel step ( see  @xcite ) , and will be useful below .    to prove the main result , a form of ergodicity for the original markov chain",
    "is required :    [ a2 ] the markov chain @xmath13 is uniformly ergodic : that is , there exists a ( unique ) probability measure @xmath28 on @xmath131 such that @xmath132 where the supremum is taken over all probability measures @xmath26 on @xmath131 .",
    "next , a doeblin - like condition is assumed :    [ a3 ] there exists @xmath133 , @xmath30 with @xmath134 , and a probability measure @xmath135 on @xmath114 supported in @xmath18 such that the following holds : for all @xmath136 and all @xmath137 with @xmath138 , @xmath139    finally , a lower bound is assumed for escape rates from metastable states .",
    "[ a4 ] there exists @xmath140 such that for all @xmath30 , @xmath141    this simply says that none of the metastable sets are absorbing .",
    "the following is the main result of this appendix :    [ maintheorem ] let idealizations  [ a0]-  [ a1 ] and assumptions  [ a2]-  [ a4 ] hold . then for any probability measure @xmath26 on @xmath131 and any bounded measurable function @xmath142 : @xmath143    the proof of theorem  [ maintheorem ] is in section  [ sec : proof ] below .",
    "it is emphasized that _",
    "idealizations  [ a0]-  [ a1 ] and assumptions  [ a2]-  [ a4 ] are assumed to hold throughout the remainder of the appendix .",
    "_ furthermore , for simplicity it is assumed that @xmath32 is the same for each @xmath30 .",
    "the first step in the proof is to show that theorem  [ maintheorem ] holds when the number of replicas is @xmath144 ( sections  [ sec : n1]-  [ sec : ep ] ) .",
    "then this will be generalized to any number of replicas ( section  [ sec : mp ] ) .",
    "it is known ( see chapter  7 of  @xcite ) that assumption  [ a2 ] is a sufficient condition for the following to hold :    [ l1 ] there exists a ( unique ) measure @xmath28 on @xmath114 such that for all probability measures @xmath26 on @xmath114 and all bounded measurable functions @xmath145 , @xmath146      consider a stochastic process @xmath147 which represents the underlying process in algorithm  [ alg1 ] when the number of replicas is @xmath148",
    ". loosely speaking , @xmath147 evolves like @xmath13 in the decorrelation step , and like @xmath149 in the parallel step ( and it does not evolve during the dephasing step ) .",
    "more precisely , @xmath147 can be defined in the following way ( writing @xmath18 for a generic element of  @xmath17 ) :    * if @xmath150 and @xmath151 do the following .",
    "if @xmath152 for some @xmath153 , pick @xmath154 from @xmath155 , let @xmath156 , update @xmath157 , and repeat .",
    "otherwise , update @xmath157 and proceed to 2 . *",
    "if @xmath150 and @xmath136 , pick @xmath158 from the qsd in @xmath18 , pick @xmath154 from @xmath159 , and let @xmath160 . if @xmath161 , update @xmath157 and return to 1 .",
    "otherwise , update @xmath157 and proceed to 3 . *",
    "if @xmath150 and @xmath136 , pick @xmath154 from @xmath155 , and let @xmath160 . if @xmath162 , update @xmath157 and repeat .",
    "otherwise , update @xmath157 and return to 1 .",
    "note that @xmath147 is not markovian , since the next value of the process depends on the history of the process .",
    "idealization  [ a1 ] , however , implies that @xmath2 and @xmath163 have the same law for each @xmath20 :    [ l2 ] if @xmath164 , then for every @xmath165 , @xmath166 .",
    "consider next an extended _ markovian _ process @xmath167 with values in @xmath168 , such that @xmath169 has the same law as @xmath147 , where @xmath170 is projection onto the @xmath171th component : @xmath172 loosely speaking , the second component of @xmath167 is a counter indicating how many consecutive steps the process has spent in a given state @xmath30 .",
    "the counter stops at @xmath32 , even if it continues to survive in @xmath18 .",
    "the first component of @xmath167 evolves exactly like @xmath13 , except when the second component is @xmath173 , in which case , starting at a sample of the qsd in @xmath18 , the process is evolved one time step .",
    "it is convenient to describe @xmath167 more precisely as follows ( writing @xmath18 for a generic element of @xmath17 ) :    * if @xmath174 with @xmath175 and @xmath176 , pick @xmath177 from @xmath178 . if @xmath179 , let @xmath180 ; otherwise let @xmath181 . * if @xmath182 with @xmath175 , pick @xmath158 from the qsd @xmath19 in @xmath18 , and pick @xmath177 from @xmath159 . if @xmath183 , let @xmath184 ; otherwise let @xmath181 . * if @xmath185 with @xmath175 , pick @xmath177 from @xmath178 . if @xmath183 , let @xmath184 ; otherwise let @xmath181 .",
    "the process @xmath167 is markovian on state space @xmath186 , where @xmath187 the following result is immediate from construction .",
    "[ l3a ] if @xmath188 and @xmath189 , then @xmath190 .    note that for the processes to have the same law , the counter of the extended process must start at zero .",
    "lemmas  [ l2]-  [ l3a ] give the following relationship between the extended process and the original markov chain :    [ l3 ] if @xmath191 and @xmath189 , then for every @xmath165 , @xmath192 .",
    "let @xmath193 be a markov chain on a standard borel state space @xmath194 .",
    "the process @xmath193 is a _",
    "harris chain _ if there exists @xmath195 , @xmath196 , and a probability measure @xmath197 on @xmath198 supported in @xmath199 such that    * for all @xmath200 , we have @xmath201 ; * for all @xmath202 and @xmath203 with @xmath204 , we have @xmath205 .",
    "see for instance chapter 5 of  @xcite .",
    "intuitively , starting at any point in @xmath93 , with probability at least @xmath206 , the process is distributed according to @xmath197 after one time step .",
    "this allows ergodicity of the chain to be studied using ideas similar to the case where the state space is discrete .",
    "the trick is to consider an auxiliary process @xmath207 with values in @xmath208 , where @xmath41 corresponds to being distributed according to @xmath197 on @xmath199 .",
    "more precisely :    * if @xmath209 and @xmath210 , pick @xmath90 from @xmath211 and let @xmath212 . * if @xmath209 and @xmath202 : with probability @xmath206 , let @xmath213 ; with probability @xmath214 , pick @xmath90 from @xmath215 and let @xmath212 . * if @xmath216 , pick @xmath6 from @xmath217 . then pick @xmath218 as in 1 - 2 .",
    "so @xmath207 is markov on @xmath219 , where @xmath220 consists of sets of the form @xmath221 and @xmath222 for @xmath203 .",
    "the following result ( see  @xcite ) relates the auxiliary process to the original process .",
    "[ l4 ] let @xmath223 be bounded and measurable , and define @xmath224 by @xmath225 then for any probability measure @xmath26 on @xmath226 and any @xmath165 , @xmath227 = { \\mathbb e}_{\\bar \\xi}[{\\bar f}({\\bar z}_n)],\\ ] ] where @xmath228 is the probability measure on @xmath229 defined by @xmath230 for @xmath231 , and @xmath232 .",
    "the following theorem gives sufficient conditions for the harris chain to be ergodic .",
    "note that the conditions are in terms of the auxiliary chain .",
    "[ l5 ] let @xmath193 be a harris chain on @xmath194 with auxiliary chain @xmath207 .",
    "assume that @xmath233 and @xmath234 then there exists a ( unique ) measure @xmath235 on @xmath198 such that for any probability measure @xmath26 on @xmath198 and any bounded measurable function @xmath236 , @xmath237 moreover , for any probability measure @xmath26 on @xmath198 , @xmath238    proof of lemma  [ l5 ] can be found in chapter  5 of  @xcite and chapter  7 of  @xcite .      in theorem  [ t2 ] below , ergodicity of the extended process @xmath167",
    "is proved . before proceeding , three preliminary results , lemmas  [ l6aa]-  [ l6 ] below , are required .",
    "define @xmath239 from lemma  [ l3 ] , @xmath128 can be thought of as the first time @xmath240 at which the law of @xmath241 synchronizes with that of @xmath2 .    [ l6aa ] for any probability measure @xmath26 on @xmath186 and any @xmath242 , @xmath243    let @xmath242 and define @xmath244 note that if @xmath245 , then @xmath246 and so @xmath247 .",
    "on the other hand , if @xmath248 , then @xmath249 and so @xmath250 .",
    "thus , @xmath251 by assumption  [ a3 ] , for any @xmath252 , @xmath253 where @xmath19 is the qsd in @xmath18 , with @xmath254 . combining   and   and using the fact that @xmath255 $ ] , @xmath256    for the remainder of section  [ sec : ee ] , fix @xmath30 satisfying assumption  [ a3 ] , and define @xmath257    [ l6a ] let @xmath26 be any probability measure on @xmath258 with support in @xmath259 .",
    "then for all @xmath260 , @xmath261    by assumption  [ a3 ] , @xmath262 whenever @xmath136 . by definition of the extended process @xmath167 , the following holds . first",
    ", for any @xmath136 and any @xmath263 , @xmath264 second , for any @xmath136 , @xmath265 third , for any @xmath136 , @xmath266 let @xmath260 .",
    "for any @xmath136 and @xmath267 , due to  ,   and  , @xmath268 where by convention the product and intersection from @xmath269 to @xmath270 do not appear above if @xmath271 and @xmath272 .",
    "lemmas  [ l6aa]-  [ l6a ] lead to the following .",
    "[ l6 ] there exists @xmath273 and @xmath274 such that for all probability measures @xmath26 on @xmath186 and all @xmath275 , @xmath276    fix a probability measure @xmath26 on @xmath186 . since @xmath277 , by assumption  [ a2 ] one may choose @xmath278 and @xmath279 such that for all probability measures @xmath280 on @xmath114 and all @xmath281 , @xmath282 let @xmath283 and define @xmath128 as in  . for @xmath284 , define probability measures @xmath285 on @xmath114 by , for @xmath125 , @xmath286 by lemma  [ l3 ] and  , for all @xmath287 and @xmath288 , @xmath289 so by lemma  [ l6aa ] , for all @xmath288 , @xmath290 let @xmath291 and fix @xmath275 .",
    "define a probability measure @xmath292 on @xmath258 with support in @xmath293 by , for @xmath125 and @xmath267 , @xmath294 by lemma  [ l6a ] and  , @xmath295 taking @xmath296 completes the proof .",
    "finally ergodicity of the extended process @xmath167 can be proved , using the tools of section  [ sec : harris ] .",
    "[ t2 ] there exists a ( unique ) measure @xmath297 on @xmath186 such that for any probability measure @xmath26 on @xmath186 and any bounded measurable function @xmath298 , @xmath299 moreover , for any probability measure @xmath26 on @xmath186 , @xmath300    first , it is claimed @xmath167 is a harris chain . recall that @xmath18 and @xmath301 are defined as in  .",
    "lemma  [ l6 ] shows that for any @xmath252 , @xmath302 define a probability measure @xmath197 on @xmath186 with support in @xmath301 by : for @xmath125 and @xmath267 , @xmath303 let @xmath304 with @xmath305 .",
    "then @xmath306 with @xmath125 , @xmath21 . from assumption  [ a3 ] , for any @xmath307 , @xmath308 one can check @xmath167 is a harris chain by taking @xmath309 , @xmath310 , and @xmath197 as above in the definition of harris chains in section  [ sec : harris ] .    next it is proved that @xmath167 is ergodic .",
    "let @xmath311 be the auxiliary chain defined as in section  [ sec : harris ] .",
    "note that @xmath312 this shows the second assumption of lemma  [ l5 ] holds , that is , @xmath313 since @xmath94 is in the set .",
    "consider now the first assumption .",
    "it must be shown that @xmath314 by lemma  [ l6 ] , one can choose @xmath315 and @xmath274 such for all probability measures @xmath26 on @xmath258 and all @xmath275 , @xmath316 define a probability measure @xmath317 on @xmath318 by @xmath319 and let @xmath26 be the probability measure on @xmath186 which is the restriction of @xmath317 to @xmath320 . by   and",
    "lemma  [ l4 ] with @xmath321 , for all @xmath322 , @xmath323 using  , for @xmath324 , @xmath325 now by  , for @xmath326 , @xmath327 thus   holds .",
    "the result now follows from lemma  [ l5 ] .",
    "next , ergodicity of @xmath147 , the parrep process with one replica , is proved .",
    "[ t3 ] for all probability measures @xmath26 on @xmath114 and all bounded measurable functions @xmath142 , @xmath328    fix a probability measure @xmath26 on @xmath131 and a bounded measurable function @xmath142 . define @xmath329 by @xmath330 and define a probability measure @xmath331 on @xmath258 by , for @xmath125 and @xmath267 , @xmath332 by theorem  [ t2 ] , there exists a ( unique ) measure @xmath297 on @xmath258 such that @xmath333 and @xmath334 define a measure @xmath335 on @xmath114 by , for @xmath125 , @xmath336 from this and the definition of @xmath337 , @xmath338 so by lemma  [ l3a ] and  , @xmath339 also , by lemma  [ l3 ] and  , @xmath340 using assumption  [ a2 ] one can conclude @xmath341 .",
    "so from  , @xmath342      here the main result , theorem  [ maintheorem ] , is finally proved .",
    "the idea is to use ergodicity of @xmath147 along with the fact that the _ average _ value of the contribution to @xmath69 from a parallel step of algorithm  [ alg1 ] does not depend on the number of replicas",
    ". a law of large numbers applied to the contributions to @xmath69 from all the parallel steps will then be enough to conclude .",
    "note that the law of @xmath343 depends on the number @xmath31 of replicas , but this is not indicated explicitly .",
    "fix a probability measure @xmath26 on @xmath131 and a bounded measurable function @xmath344 .",
    "define @xmath345 by @xmath346 let algorithm  [ alg1 ] start at @xmath26 .",
    "the quantity @xmath69 will be decomposed into contributions from the decorrelation step and the parallel step .",
    "let @xmath347 denote the contribution to @xmath69 from the decorrelation step up to time @xmath70 , and let @xmath348 denote the contribution to @xmath69 from the parallel step up to time @xmath70 .",
    "thus , @xmath349 let @xmath167 start at @xmath350 , with @xmath331 defined as in  . because the starting points @xmath123 sampled in the dephasing step are independent of the history of algorithm , each parallel step  in particular the pair @xmath351  is independent of the history of the algorithm .",
    "this and theorem  [ t0 ] imply that @xmath352 has the same law for every number of replicas @xmath31 .",
    "in particular when @xmath148 , from lemma  [ l3a ] , @xmath353 meanwhile , from the preceding independence argument , @xmath354 where @xmath355 are iid random variables and @xmath356 counts the number of sojourns of @xmath167 in @xmath357 by time @xmath70 : @xmath358 from idealization  [ a0 ] and definition  [ d1 ] , each term in the sum in   or   of the parallel step has expected value @xmath359 .",
    "so from linearity of expectation and theorems  [ t0 ] , for any number @xmath31 of replicas , @xmath360 & = \\left({\\mathbb e}[\\tau_{acc}]-1\\right)\\int_s f\\,d\\nu \\\\&=\\left({\\mathbb p}_\\nu(x_1 \\notin s)^{-1}-1\\right)\\int_s f\\,d\\nu.\\end{split}\\end{aligned}\\ ] ] combining  ,   and  , for any number @xmath31 of replicas , @xmath361 where it is assumed the processes on the left and right hand side of   are independent .",
    "let @xmath147 start at @xmath362 . from definition of @xmath147 and  , when the number of replicas is @xmath148 , @xmath363 where the processes in   are assumed independent . since @xmath167 is markov , the number of time steps @xmath240 for which @xmath364 is either finite almost surely , or infinite almost surely . by theorem",
    "[ t0 ] and assumption  [ a4 ] , the expected value of each of the sojourn times of @xmath167 in @xmath365 is @xmath366 , so the sojourn times are finite almost surely .",
    "this means that either @xmath167 has infinitely many sojourns in @xmath365 almost surely , or @xmath167 has finitely many sojourns in @xmath365 almost surely . thus : @xmath367 define @xmath368 and for @xmath369 , @xmath370 note that @xmath371 are iid and @xmath372 if @xmath373 almost surely as @xmath374 , then by the strong law of large numbers there is a constant @xmath375 ( depending on @xmath18 ) such that @xmath376 from  ,   and the strong law of large numbers , there is a constant @xmath377 such that @xmath378 and due to   this @xmath377 does not depend on the number of replicas @xmath31 . by using theorem  [ t3 ] along with   and , @xmath379 now using  ,   and  , for any number @xmath31 of replicas , @xmath380",
    "the author would like to acknowledge gideon simpson ( drexel university ) , tony lelivre ( ecole des ponts paristech ) and lawrence gray ( university of minnesota ) for fruitful discussions .",
    "metastability for markov chains : a general procedure based on renormalization group ideas . in g.",
    "grimmett , editor , _ probability and phase transition _ , volume 420 of _ nato asi series _ , pp .  303322 , springer verlag ( 1994 )"
  ],
  "abstract_text": [
    "<S> an algorithm is proposed for computing equilibrium averages of markov chains which suffer from metastability  the tendency to remain in one or more subsets of state space for long time intervals . </S>",
    "<S> the algorithm , called the parallel replica method ( or parrep ) , uses many parallel processors to explore these subsets more efficiently . </S>",
    "<S> numerical simulations on a simple model demonstrate consistency of the method . </S>",
    "<S> a proof of consistency is given in an idealized setting . </S>",
    "<S> the parallel replica method can be considered a generalization of a.f . </S>",
    "<S> voter s parallel replica dynamics , originally developed to efficiently simulate metastable langevin stochastic dynamics . </S>"
  ]
}