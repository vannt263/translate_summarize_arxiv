{
  "article_text": [
    "morphological computation is discussed in various contexts , such as dna computing and self - assembly ( see * ? ? ?",
    "* ; * ? ? ?",
    "* for an overview ) . in this publication , we are interested in quantifying morphological computation of embodied agents which are embedded in the sensorimotor loop .",
    "morphological computation , in this context , is described as the trade - off between morphology and control  @xcite , which means that a well - chosen morphology , if exploited , substantially reduces the amount of required control @xcite .",
    "hereby , a morphology refers to the agent s body , explicitly including all its physiological and physical properties ( shape , sensors , actuators , friction , mass distribution , etc . )",
    "the consensus is that morphological computation is the contribution of the morphology and environment to the behaviour , that can not be assigned to a nervous system or a controller .",
    "there are several examples from biology , which demonstrate how the behaviour of an agent relies on the interaction of the body and environment .",
    "a nice example is given by ( * ? ? ?",
    "* see p.  188 ) , who describes how `` active muscular forces can not entirely control the wing shape in flight .",
    "they can only interact dynamically with the aerodynamic and inertial forces that the wings experience and with the wing s own elasticity ; the instantaneous results of these interactions are essentially determined by the architecture of the wing itself [  ] ''    one of the most cited example from the field of embodied artificial intelligence is the passive dynamic walker by @xcite . in this example , a two - legged walking machine preforms a naturally appealing walking behaviour , as a result of a well - chosen morphology and environment , without any need of control .",
    "there is simply no computation available and the walking behaviour is the result of the gravity , the slope of the ground and the specifics of the mechanical construction ( weight and length of the body parts , deviation of the joints , etc . ) .",
    "if any parameter of the mechanics ( morphology ) or the slope ( environment ) is changed , the walking behaviour will not persist . in this context , we understand the exploitation of the body s and environment s physical properties as the embodiments effect on a behaviour .    theoretical work on describing morphological computation in the context of embodied artificial intelligence has been conducted by @xcite . in this publication ,",
    "we study an information - theoretic approach to quantifying morphological computation which is based on an information decomposition of the sensorimotor loop .",
    "this work is based on two of our previous publications in which we have investigated different quantifications of morphological computation @xcite and derived a general decomposition of a mutual information of three random variables into unique , shared , and synergistic information @xcite . in our previous work @xcite , we derived two concepts which both match the general intuition about morphological computation , but showed different results . in this publication",
    ", we will apply the information decomposition of @xcite to the setting of @xcite with the goal to unify the two previously derived concepts .",
    "the paper is organised in the following way .",
    "the next section discusses the sensorimotor loop and its representation as a causal graph .",
    "the third section describes the bivariate information decomposition from  @xcite .",
    "based on the information decomposition , the fourth section introduces the unique information as a measure for morphological computation in the sensorimotor loop .",
    "the fifth section presents numerical results , which are then discussed in the final section .",
    "an appendix explains how we computed our measure of morphological computation .",
    "our information theoretic decomposition of the mutual information requires a formal representation of the sensorimotor loop , which we will introduce in this section . in our understanding ,",
    "a cognitive system consists of a brain or controller , which sends signals to the system s actuators , thereby affecting the system s environment .",
    "we prefer the notion of the system s _ umwelt _",
    "@xcite , which is the part of the system s environment that can be affected by the system , and which itself affects the system .",
    "the state of the actuators and the _ umwelt _ are not directly accessible to the cognitive system , but the loop is closed as information about the _ umwelt _ and the body is provided to the controller through the sensors .",
    "in addition to this general concept of the sensorimotor loop , which is widely used in the embodied artificial intelligence community ( see e.g. * ? ? ?",
    "* ) we introduce the notion of _ world _ and by that we mean the system s morphology and the system s _",
    "umwelt_. we can now distinguish between the intrinsic and extrinsic perspective in this context .",
    "the world is everything that is extrinsic from the perspective of the cognitive system , whereas the controller , sensor and actuator signals are intrinsic to the system .",
    "this is analogous to the agent - environment distinction in the context of reinforcement learning @xcite , in which the environment is understood as everything that can not be controlled arbitrarily by the agent .",
    "the distinction between intrinsic and extrinsic is also captured in the representation of the sensorimotor loop as a causal or bayesian graph ( see fig .  [",
    "fig : binary_model ] ) . for simplicity",
    ", we only discuss the sensorimotor loop for reactive systems .",
    "this is plausible , because behaviours which exploit the embodiment are usually better described as reactive and not as deliberative .",
    "the most prominent examples are locomotion behaviours , e.g.  human walking , swimming , flying , etc . , which are all well - modelled as reactive behaviours .",
    "the random variables @xmath0 , @xmath1 , and @xmath2 refer to sensor , actuator , and world state , and the directed edges reflect causal dependencies between the random variables ( see * ? ? ?",
    "* ; * ? ? ?",
    "* ; * ? ? ?",
    "everything that is extrinsic is captured in the variable @xmath2 , whereas @xmath0 and @xmath1 are intrinsic to the agent .",
    "the random variables @xmath0 and @xmath1 are not to be mistaken with the sensors and actuators .",
    "the variable @xmath0 is the output of the sensors , which is available to the controller or brain , the action @xmath1 is the input that the actuators take .",
    "consider an artificial robotic system as an example .",
    "then the sensor state @xmath0 could be the pixel matrix delivered by some camera sensor and the action @xmath1 could be a numerical value that is taken by some motor controller to be converted in currents to drive a motor .    throughout this work ,",
    "we use capital letter ( @xmath3 , @xmath4 ,  ) to denote random variables , non - capital letter ( @xmath5 , @xmath6 ,  ) to denote a specific value that a random variable can take , and calligraphic letters ( @xmath7 , @xmath8 ,  ) to denote the alphabet for the random variables .",
    "this means that @xmath9 is the specific value that the random variable @xmath3 can take a time @xmath10 , and it is from the set @xmath11 .",
    "greek letters refer to generative kernels , i.e.  kernels which describe an actual underlying mechanism or a causal relation between two random variables .",
    "we abbreviate the random variables for better comprehension in the remainder of this work , as the information decomposition ( see next sections ) considers random variables of consecutive time indices .",
    "therefore , we use the following notation . random variables without any time index refer to time @xmath12 and hyphened variables to time @xmath13 . the two variables @xmath14 refer to @xmath15 and @xmath16 .",
    "formally , the sensorimotor loop is given by the probability distribution @xmath17 and the kernels @xmath18 , @xmath19 , and @xmath20 .",
    "to analyse the quality of our derived quantification , it is best to evaluate them in a fully controllable setting . for this purpose , we chose the same parameterisable binary model of the sensorimotor loop that was used in our previous publication @xcite .",
    "it allows to control the causal dependencies of @xmath0 , @xmath1 , and @xmath2 individually , and thereby , enables an evaluation of the information decomposition in the sensorimotor loop and compare it with our previous results .",
    "the model is shown in figure  [ fig : binary_model ] and given by the following set of equations : @xmath21 where @xmath22 and @xmath23 .",
    "as in @xcite , the following two assumptions are made without loss of generality .",
    "first , it is assumed that all world states @xmath24 occur with equal probability , i.e. @xmath25 .",
    "second , we assume a deterministic sensor , i.e.  @xmath26 , which means that the sensor is a copy of the world state",
    ". the first assumption does not violate the generality , because it only assures that the world state itself does not already encode some structure , which is propagated through the sensorimotor loop .",
    "the second assumption does not violate the generality of the model , because in a reactive system as in figure  [ fig : binary_model ] , the sensor state @xmath0 and @xmath1 can be reduced to a common state , with a new generative kernel @xmath27 .",
    "hence , keeping one of the two kernels deterministic and varying the other in the experiments below , does not reduce the validity of this model .",
    "this leaves four open parameters @xmath28 , and @xmath29 , against which the morphological computation measure is validated .",
    "next , we introduce the information decomposition that underlies our measure of morphological computation .",
    "we first explain this information decomposition in a general information theoretic setting and later explain how we use it in the sensorimotor loop .",
    "consider three random variables @xmath30 .",
    "suppose that a system wants to predict the value of the random variable  @xmath3 , but it can only access the information in  @xmath4 or  @xmath31 .",
    "how is the information that @xmath4 and  @xmath31 carry about  @xmath3 distributed over  @xmath4 and  @xmath31 ? in general , there may be _ redundant _ or _ shared _ information ( information contained both @xmath4 and  @xmath31 ) , but there may also be _ unique _ information ( information contained in only one of  @xmath4 or  @xmath31 ) .",
    "finally , there is also the possibility of _ synergystic _ or _ complementary _ information , i.e.  information that is only available when @xmath4 and  @xmath31 are taken together .",
    "the classical example for synergy is the xor function : if @xmath4 and @xmath31 are binary random variables and if  @xmath32 , then neither @xmath4 nor @xmath31 contain any information about  @xmath3 ( in fact , @xmath3 is independent of  @xmath4 and @xmath3 is independent of  @xmath31 ) , but when @xmath4 and  @xmath31 are taken together , they completely determine  @xmath3 ( in particular , @xmath3 is not independent from the pair @xmath33 ) .    the total information that @xmath33 contains about  @xmath3 can be quantified by the mutual information @xmath34 . however , there is no canonical way to separate these different kinds of informations .",
    "mathematically , one would like to have four functions @xmath35 ( `` shared information '' ) , @xmath36 ( `` unique information of  @xmath4 '' ) , @xmath37 ( `` unique information of  @xmath31 '' ) , @xmath38 ( `` complementary information '' ) that satisfy @xmath39 from the interpretation it is also natural to require @xmath40 a set of three functions @xmath41 , @xmath42 , and @xmath43 that satisfy   and   is called a _ bivariate information decomposition _ by  @xcite .",
    "it follows from the defining equations and the chain rule of mutual information that an information decomposition always satisfies @xmath44    equations   and   do not specify the functions @xmath41 , @xmath42 , and  @xmath43 .",
    "several different candidates have been proposed so far , for example by  @xcite and  @xcite .",
    "we will use the decomposition of  @xcite that is defined as follows :    let @xmath45 be the set of all possible joint distributions of @xmath3 , @xmath4 , and  @xmath31 . fix an element @xmath46 ( the `` true '' joint distribution of @xmath3 , @xmath4 , and  @xmath31 ) . define @xmath47 as the set of all joint distributions which have the same marginal distributions on the pairs @xmath33 and @xmath48 . then @xmath49 where @xmath50 denotes the co - information . here",
    ", a subscript @xmath51 in an information quantity means that the quantity is computed with respect to  @xmath51 as the joint distribution .",
    "one idea behind these functions is the following : suppose that the joint distribution @xmath52 of @xmath3 , @xmath4 , and @xmath31 is not known , but that just the marginal distributions of the pairs @xmath33 and  @xmath48 are known .",
    "this information is sufficient to characterize the set  @xmath53 , but we do not know which element of  @xmath53 is the true joint distribution .",
    "one can argue that the @xmath42 and @xmath41 should be constant on  @xmath53 ; that is , shared information and unique information should depend only on the interaction of  @xmath3 and  @xmath4 and the interaction on @xmath3 and  @xmath31 , but not on the way in which the three variables interact .    the second property that characterizes the information decomposition is that the set @xmath53 contains a distribution  @xmath51 such that @xmath54 . in other words , when only the marginal distributions of the pairs @xmath33 and  @xmath48 are known , then we can not know whether there is synergy or not .",
    "see  @xcite for a more detailed justification and a proof how these properties , determine the functions @xmath42 , @xmath41 , and  @xmath43 .    in  @xcite ,",
    "the formulas for  @xmath42 , @xmath43 , and  @xmath41 are derived from considerations about decision problems in which the objective is to predict the outcome of  @xmath3 . here , we want to apply the information decomposition in another setting : we will set @xmath55 , @xmath56 , and  @xmath57 . in our setting , @xmath2 and  @xmath1 not only have information about  @xmath58 , but they actually _ control _  @xmath58 .",
    "however , the situation is similar : in the sensorimotor loop , we also expect to find aspects of redundant , unique , and complementary influence of  @xmath2 and  @xmath1 on  @xmath58 . formally ,",
    "since everything is defined probabilistically , we can still use the same functions  @xmath42 , @xmath43 , and  @xmath41 .",
    "we believe that the arguments behind the definition of @xmath42 , @xmath43 and  @xmath41 remain valid in the setting of the sensorimotor loop where we need it .",
    "first , it is still plausible that unique and redundant contributions should only depend on the marginal distributions of the pairs @xmath59 and  @xmath60 .",
    "second , in order to decide whether @xmath2 and @xmath1 act synergistically , it does not suffice to know only these marginal distributions .",
    "therefore , we believe that the functions @xmath42 , @xmath43 , and @xmath41 have a meaningful interpretation . in particular , we hope to be able to use the information decomposition in order to measure morphological computation .",
    "this view is supported by our simulations below , which indicate that the functions @xmath42 , @xmath43 and @xmath41 do indeed lead to a reasonable decomposition of @xmath61 and that the unique information @xmath62 is a reasonable measure of morphological computation , at least in our simple model of the sensorimotor loop .",
    "the parameters of our model of the sensorimotor loop ( eqs   to  ) can also be interpreted in terms of an information decomposition .",
    "intuitively , @xmath63 corresponds to the unique influence of @xmath2 on  @xmath58 , @xmath64 corresponds to the unique influence of @xmath1 on  @xmath58 , and @xmath65 corresponds to the complementary influence . however , the role of the additional parameters  @xmath66 is not so clear , and it is not so easy to find a correspondence of redundant information .",
    "the information decomposition has the advantage , that its definition does not depend on a parametrization .",
    "observe that if the `` synergistic parameter '' @xmath67 vanishes , then it does not necessarily follow that  @xmath68 ( see fig .",
    "[ fig : mc ] ) .",
    "however , we do expect the complementary information to be small in this case .",
    "morphological computation was described as the contribution of the embodiment to a behaviour . in our previous work , we derived two concepts to quantify morphological computation , which are both based on the world dynamics kernel @xmath18 .",
    "the first concept assumes that the current action @xmath1 has no influence on the next world state @xmath58 , in which case the kernel @xmath18 reduces to @xmath69 .",
    "if this is the case , we would say that the systems shows maximal morphological computation , as the behaviour is completely determined by the world .",
    "to measure the amount of morphological computation present in a recorded behaviour , we calculated how much the data differed from the assumption by calculating the weighted kullback - leibler divergence @xmath70 , which is the conditional mutual information @xmath71 . because this quantity is zero if we have maximal morphological computation , we inverted and normalised in the following way : @xmath72 .",
    "the second concept started with the complementary assumption that the current world state @xmath2 had no influence on the next world state @xmath58 , i.e. , that the world dynamics kernel is given by @xmath73 .",
    "morphological computation was then quantified as the error from the assumption , given by the weighted kullback - leibler divergence @xmath74 , which equals the conditional mutual information @xmath75 .",
    "both concepts were analysed and quantifications were derived , which did nt require knowledge about the world , but could be calculated from intrinsically available information only . at that time , we could not determine which of the two concepts would capture morphological computation best , although both concepts and their intrinsic adaptations lead to different results in a specific configuration ( @xmath76 ) .",
    "our intention in this publication is to answer this question . for this purpose",
    ", we follow a different approach to quantify morphological computation , by starting with the mutual information of @xmath77 and decompose it into the shared , unique and synergistic information , as described in the previous section . rewriting the equation  , by replacing @xmath30 by @xmath78 , we obtain the following information decomposition : @xmath79 as show in equation  , our previous concept two , the conditional mutual information @xmath75 is given by the sum of the unique information @xmath80 and the synergistic information @xmath81 : @xmath82 the examples we have discussed in the introduction ( insect wing and passive dynamic walker ) suggest to use the unique information @xmath80 to quantify morphological computation , because it captures the information that the current and next world state @xmath14 share uniquely .",
    "the next section presents numerical simulations to investigate how the conditional mutual information @xmath75 and the unique information @xmath83 compare with respect to quantifying morphological computation .",
    "the experiments in this section are conducted on the parameterised model of the sensorimotor loop that was introduced in the second section ( see fig .  [",
    "fig : binary_model ] and eq .   to eq .  ) .",
    "as stated earlier , we set @xmath84 , which means that the world state @xmath2 is drawn with equal probability ( @xmath85 ) , and @xmath86 such that the sensor state @xmath0 is a copy of the world state @xmath2 .",
    "this leaves four parameters for variation , namely the three world dynamics kernel parameters @xmath87 and the policy parameter @xmath29 .",
    "we decided to plot the information theoretic quantities only for @xmath88 ( see fig .",
    "[ fig : mc ] and fig .",
    "[ fig : mc_2 ] ) , i.e. ,  for the case , in which the action @xmath1 is chosen independently of the current sensor value @xmath0 and with equal probability .",
    "this allows us to investigate the effect of the action @xmath1 on the next world state @xmath58 , without any influence of @xmath2 on @xmath1 .",
    "we also know from previous experiments ( see * ? ? ?",
    "* ) , that the conditional mutual information @xmath75 drops to zero for increasing @xmath29 .",
    "as the conditional mutual information is the sum of the unique and synergistic information , we know that both quantities will also decrease with increasing @xmath29 . if @xmath1 is deterministically dependent on @xmath2 , it also follows that the unique information @xmath89 is zero , because @xmath1 and @xmath2 are interchangeable .",
    "the only quantity that will be larger than zero is the shared information , which , by definition , is not of interest in the context of this work .",
    "we decided to plot the information decomposition for varying @xmath63 ( parameter of unique influence of @xmath2 on @xmath58 ) and @xmath64 ( parameter of unique influence of @xmath1 on @xmath58 ) for two different values of @xmath65 ( parameter of synergistic influence of @xmath90 on @xmath58 , see eq .  ) .",
    "figure  [ fig : mc ] shows the results for @xmath67 , while figure  [ fig : mc_2 ] shows the results for @xmath91 .",
    "we will first discuss the results for @xmath92 , as they are best comparable with our previous results from @xcite .    ]    [ [ vanishing - synergistic - parameter - omega0 ] ] vanishing synergistic parameter ( @xmath67 ) : + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    figure  [ fig : mc]a shows that synergistic information @xmath81 is small and only present if @xmath93 ( diagonal of the image ) .",
    "this is in agreement with our intuition that @xmath65 is the synergistic parameter .",
    "the unique information of the action @xmath1 and the next world state @xmath58 , denoted by @xmath89 , is shown in figure  [ fig : mc]b .",
    "the plot reveals that the unique information of the current action @xmath1 and the next world state @xmath58 is only present , whenever @xmath94 , and it is large , whenever @xmath64 is significantly larger than @xmath63 .",
    "figure  [ fig : mc]c shows analogous results for the unique information @xmath80 . in this case , the unique information is negligible , whenever @xmath95 and grows whenever @xmath63 is significantly larger then @xmath64 .",
    "these two plots show that the definition of the unique information , as proposed by @xcite , is able to extract the unique influence in a setting in which two random variables actually control a third random variable .",
    "[ fig : mc]d shows the conditional mutual information @xmath75 , which was the second concept of quantifying morphological computation in our previous work @xcite .",
    "as stated earlier , the conditional mutual information is given by the sum of the unique and synergistic information ( eq .  ) . hence , there is almost no difference between figure  [ fig : mc]b and figure  [ fig : mc]d , except on the diagonal , where the unique information @xmath80 drops faster to zero .    [",
    "[ positive - synergistic - parameter - omega2 ] ] positive synergistic parameter ( @xmath91 ) : + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    ]    to study the difference between the unique information @xmath96 and the conditional mutual information @xmath75 , and hence , compare the new quantification with our former concept , we conducted the same experiments with a value of  @xmath91 ( see figures  [ fig : mc_2 ] and  [ fig : mi_vs_ui ] ) .",
    "figures  [ fig : mc_2]a - c demonstrate how the information decomposition can distinguish between the synergistic information and the unique informations , which is exactly what we need to quantify morphological computation .",
    "the unique information @xmath80 captures only the information that the current world state @xmath2 and the next world state @xmath58 share , and therefore , captures the common understanding of morphological computation in the context of embodied artificial intelligence . in the introduction , we presented two examples of morphological computation , which described it as the contribution of the body and environment to a behaviour , that can not be assigned to any neural system or robot controller . the     and @xmath80 for @xmath91.,title=\"fig : \" ]   and @xmath80 for @xmath91.,title=\"fig : \" ]    unique information @xmath80 figure  [ fig : mc_2]b captures this notion of morphological computation best , because it vanishes if the synergistic information @xmath81 ( see fig .  [",
    "fig : mc_2]a ) or the unique information @xmath89 ( see fig .",
    "[ fig : mc_2]c ) increases . given eq .",
    ", it is clear that the conditional mutual information @xmath75 is positive ( see fig .",
    "[ fig : mc_2]d ) whenever the unique information @xmath89 or the synergistic information @xmath81 is positive .",
    "this is problematic for the following reason .",
    "figure  [ fig : mc_2]d show a positive conditional mutual information @xmath75 also for values of @xmath97 , which is counter - intuitive .",
    "furthermore , as figure  [ fig : mi_vs_ui ] shows ( note that the @xmath98 axes are rotated for better visibility ) , the conditional mutual information is indifferent for a large range of @xmath99 . additionally , the conditional mutual information increases for vanishing @xmath63 and  @xmath64 , which again is counter - intuitive , whereas the unique information @xmath80 ( see right - hand side of fig .  [ fig : mi_vs_ui ] ) nicely reflects our intuition .",
    "therefore , we conclude that the unique information @xmath80 is best suited to quantify morphological computation in the context of embodied artificial intelligence .",
    "this work proposes a quantification of morphological computation based on an information decomposition in the sensorimotor loop . in the introduction",
    ", morphological computation was described as the contribution of an agent s body and agent s _ umwelt _ to its behaviour .",
    "important to note is that both mentioned examples highlighted the contribution of the embodiment that resulted solely from interactions of the body and environment and that can not be attributed to any type of control by the agent .",
    "this is why we propose to use a decomposition of the mutual information @xmath77 into shared , unique and synergistic information .",
    "this allows us to separate contributions of the embodiment from contributions of the controller ( via its actions @xmath1 ) and contributions of both , controller and embodiment .",
    "we showed that the information decomposition is related to our previous work in the following way .",
    "the sum of the unique information @xmath80 and the synergistic information @xmath81 is equivalent the conditional mutual information @xmath75 , which is one of the two earlier concepts for morphological computation .",
    "this relation shows the difference of this work compared to our former results .",
    "we are now able to quantify exactly how much of the next world state @xmath58 is determined by the current world state  @xmath2 , thereby excluding any influence of the action  @xmath1 .",
    "therefore , we proposed @xmath80 as a quantification of morphological computation .    in two numerical simulations",
    ", we evaluated the decomposition in a parametrised , binary model of the sensorimotor loop .",
    "the world dynamics kernel @xmath18 was parametrised with three parameters , @xmath63 , @xmath64 , and @xmath65 , which roughly relate to the unique information @xmath80 , the unique information @xmath89 , and the synergistic information @xmath81 . for a fixed value of @xmath65 ,",
    "the two parameters @xmath63 and @xmath63 were varied to evaluate the information decomposition in the sensorimotor loop .",
    "it was shown that for a vanishing synergistic parameter @xmath67 , synergistic information was present only for @xmath100 .",
    "this explains why there is only a marginal difference between @xmath80 and @xmath75 in this setting . for a positive synergistic parameter @xmath91",
    ", we saw that the synergistic information was positive for a much larger domain , which led to a significant difference between @xmath80 and @xmath75 .",
    "in particular , the condition mutual information @xmath75 was positive for a larger range of parameter values @xmath64 and  @xmath63 .",
    "there is a domain @xmath99 , for which the conditional mutual information @xmath75 is positive and indifferent .",
    "one would expect to see a higher morphological computation mostly when @xmath101 , despite the fact that synergistic information is present .",
    "this shows that the @xmath80 is better suited to quantify morphological computation .    in",
    "@xcite it was proposed that a measure of morphological computation could be used as a guiding principle in an open - ended self - organised learning setting . for this to work ,",
    "this measure should only depend on information that is intrinsically available to the system .",
    "clearly , this is not the case for @xmath80 .",
    "therefore , future work will include derivations of the information decomposition , which only include intrinsically available information .",
    "it would also be interesting to investigate how much a formalisation of the information decomposition can benefit from a consideration of the causal information flow .",
    "the starting point for our decomposition was the mutual information @xmath102 , which is a correlational measure and not a measure of causal dependence , as e.g.  proposed by @xcite . in currently ongoing work , we are applying the quantification to motion capturing data of real robots .",
    "this work was partly funded by priority program autonomous learning ( dfg - spp 1527 ) of the german research foundation ( dfg ) .",
    "ay , n. and polani , d. ( 2008 ) .",
    "information flows in causal networks .",
    ", 11(1):1741 .",
    "bertschinger , n. , rauh , j. , olbrich , e. , jost , j. , and ay , n. ( 2014 ) . quantifying unique information .",
    ", 16(4):21612183 .",
    "clark , a. ( 1996 ) . .",
    "mit press , cambridge , ma , usa .",
    "fchslin , r.  m. , dzyakanchuk , a. , flumini , d. , hauser , h. , hunt , k.  j. , luchsinger , r.  h. , reller , b. , scheidegger , s. , and walker , r. ( 2012 ) .",
    "morphological computation and morphological control : steps toward a formal theory and applications .",
    ", 19(1):934 .",
    "harder , m. , salge , c. , and polani , d. ( 2013 ) .",
    "bivariate measure of redundant information .",
    ", 87:012130 .",
    "hauser , h. , ijspeert , a. , fchslin , r. , pfeifer , r. , and maass , w. ( 2011 ) . towards a theoretical foundation for morphological computation with compliant bodies .",
    ", 105:355370 .",
    "hauser , h. , sumioka , h. , fchslin , r.  m. , and pfeifer , r. ( 2012 ) .",
    "introduction to the special issue on morphological computation .",
    ", pages 18 .",
    "klyubin , a. , polani , d. , and nehaniv , c. ( 2004 ) .",
    "organization of the information flow in the perception - action loop of evolved agents . in _",
    "evolvable hardware , 2004 . proceedings .",
    "2004 nasa / dod conference on _ , pages 177180 .",
    "mcgeer , t. ( 1990 ) .",
    "passive dynamic walking .",
    ", 9(2):6282 .",
    "montfar , g. , ay , n. , and ghazi - zahedi , k. ( 2014 ) . a framework for cheap universal approximation in embodied systems .",
    ", abs/1407.6836 .",
    "pearl , j. ( 2000 ) . .",
    "cambridge university press .",
    "pfeifer , r. ( 2002 ) .",
    "embodied artificial intelligence - on the role of morphology and materials in the emergence of cognition . in schubert , s.  e. , reusch , b. , and jesse , n. , editors ,",
    "_ informatik bewegt : informatik 2002 - 32 . jahrestagung der gesellschaft fr informatik e.v .",
    "( gi ) _ , volume  19 , bonn .",
    "pfeifer , r. , lungarella , m. , and iida , f. ( 2007a ) .",
    "self - organization , embodiment , and biologically inspired robotics .",
    ", 318(5853):10881093 .",
    "pfeifer , r. , packard , n. , bedau , m. , and iida , f. , editors ( 2007b ) . .",
    "pfeifer , r. and scheier , c. ( 1999 ) . .",
    "mit press , cambridge , ma , usa .    sutton , r.  s. and barto , a.  g. ( 1998 ) . .",
    "mit press .",
    "von uexkuell , j. ( 1957 ( 1934 ) ) .",
    "a stroll through the worlds of animals and men . in schiller , c.  h. , editor , _ instinctive behavior _ , pages 580 .",
    "international universities press , new york .",
    "williams , p. and beer , r. ( 2010 ) .",
    "nonnegative decomposition of multivariate information . .",
    "wootton , r.  j. ( 1992 ) .",
    "functional morphology of insect wings . , 37(1):113140 .",
    "zahedi , k. and ay , n. ( 2013 ) . quantifying morphological computation .",
    ", 15(5):18871915 .",
    "zahedi , k. , ay , n. , and der , r. ( 2010 ) . higher coordination with less control  a result of information maximization in the sensori - motor loop .",
    ", 18(34):338355 .",
    "in this appendix we shortly explain how we computed the functions @xmath42 and  @xmath43 .",
    "the appendix of  @xcite explains how to parametrize the set  @xmath53 and how to solve the optimization problems in the definitions of @xmath42 , @xmath43 , and  @xmath41 . in our case , where all variables are binary , @xmath53 consists of all probability distributions @xmath103 with       the range of the two parameters @xmath104 is restricted in such a way that @xmath105 has no negative entries .",
    "since every entry @xmath106 involves only one of the two parameters , @xmath53 is a rectangle , bounded by the inequalities @xmath107"
  ],
  "abstract_text": [
    "<S> the question how an agent is affected by its embodiment has attracted growing attention in recent years . </S>",
    "<S> a new field of artificial intelligence has emerged , which is based on the idea that intelligence can not be understood without taking into account embodiment . </S>",
    "<S> we believe that a formal approach to quantifying the embodiment s effect on the agent s behaviour is beneficial to the fields of artificial life and artificial intelligence . </S>",
    "<S> the contribution of an agent s body and environment to its behaviour is also known as morphological computation . </S>",
    "<S> therefore , in this work , we propose a quantification of morphological computation , which is based on an information decomposition of the sensorimotor loop into shared , unique and synergistic information . in numerical simulation based on a formal representation of the sensorimotor loop , </S>",
    "<S> we show that the unique information of the body and environment is a good measure for morphological computation . </S>",
    "<S> the results are compared to our previously derived quantification of morphological computation . </S>"
  ]
}