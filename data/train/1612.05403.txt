{
  "article_text": [
    "hensel lifting techniques are at the basis of several polynomial factoring algorithms that are fast in practice .",
    "the classical algorithms are designed for generic bivariate polynomials over finite fields without reference to sparsity ( e.g. @xcite ) .",
    "the polytope method of @xcite is intended to factor sparse polynomials more efficiently , by exploiting the structure of their newton polygon .",
    "it promises to be significantly fast when the polygon has a few decompositions , and can help factor families of polynomials which possess the same newton polytope . while the pre - processing stages of the polytope method benefit from the sparsity of the input in reference to its newton polygon , the hensel lifting phase that pursues the boundary factorisations does not do so .",
    "our chain of work in @xcite reveals that the inner workings of hensel lifting remain oblivious to the sparsity of the input as well as fluctuations in the sparsity of intermediary output , so long as one is designing the hensel lifting phase using the dense model for polynomial representation .",
    "in contrast , the sparse distributed representation considers the problem size to be a function of the number of non - zero terms of the polynomails treated , which captures the fluctuation in sparsity throughout the factorisation process . in @xcite",
    ", we revised the analysis of the hensel lifting phase when polynomials are in sparse distributed representation .",
    "we derived that the asymptotic performance in work , space , and cache complexity is critically affected not only by the degree of the input polynomial , but also by the following factors : ( i ) the sparsity of each polynomial multiplication , and ( ii ) the sparsity of the resulting polynomial products to be merged into a final summand .",
    "we further showed that even with advanced additive ( merging ) data structures like the cache aware tournament tree or the cache oblivious @xmath0-merger , the asymptotic performance of the serialised version in all three metrics is still poor .",
    "this was a result of the straightforward implementation which performed polynomial products first off , to be followed by sums of those products , a process that we dubbed _",
    "serialised_. we remedied this by re - engineering the hensel lifting phase such that sums of polynomial products are computed simultaneously using a max priority queue .",
    "this generalises the approach of @xcite for a single polynomial multiplication .",
    "we derived orders of magnitude reduction in work , space , and cache complexity even against a serialised version that employs many possible enhancements , and succeeded in evading expression swell .",
    "hereafter , we label the serialised and the priority queue versions of hensel lifting as ser - hl and pq - hl respectively . more specifically and with regard s to the latter algorithm , we will denote by pq - hl@xmath1 the version that uses binary heap as a priority queue , and by pq - hl@xmath2 the version that uses funnel heap instead .",
    "our experiments in @xcite demonstrate that the polytope method is now able to adapt significantly more efficiently to sparse input when its newton polygon consists of a few edges , something not to have been observed when employing ser - hl .    in @xcite , we shifted to enhancing the overlapping algorithm pq - hl@xmath2 .",
    "the motivation lies in the fact that binary heap is not scalable , which , on a serial machine , is interpreted to say that its performance will deteriorate once data no longer fits in in - core memory , thus restricting the number of non - zero terms that input and intermediary output polynomials are permitted to possess . by performing priority queue operations using optimal cache complexity and in a cache oblivious fashion , funnel heap beats binary heap at large scale .",
    "the fact that funnel heap assumes no knowledge of the underlying parameters such as memory level , memory level size , or word length , makes it ideal for applications where polynomial arithmetic is susceptible to fluctuations in sparsity .",
    "however , all of those features can also be observed when adopting an alternate cache oblivious priority queue ( see for example , @xcite ) . as such",
    ", we pursued funnel heap for further attributes that can improve on its asymptotic performance , as well as exploit it at small scale , specifically for hensel lifting . in @xcite , we addressed the chaining optimisation , and how funnel heap can be tailored to implement it in a highly efficient manner .",
    "we exploited that funnel heap is able to identify equal order monomials `` for free '' as part of its inner workings whilst it re - organises itself over sufficiently many updates during one of its special operations known as the `` sweep '' . by this",
    "we were able to eliminate entirely the requirement for searching from the chaining process .",
    "we designed a batched mode for chaining that gets overlapped with funnel heap s mechanism for emptying its in - core components .",
    "in addition to also managing expression swell and irregularity in sparsity , batched chaining is sensitive to the number of distinct monomials residing in funnel heap , as opposed to the number of replicas chained .",
    "this allows the overhead due to batched chaining to decrease with increasing replicas . for sufficiently large input size with respect to the cache - line length , and also sufficiently sparse input and intermediary polynomials ,",
    "batched chaining that is `` search free '' leads to an implementation of hensel lifting that exhibits optimal cache complexity in the number of replicas found in funnel heap , and one that achieves an order of magnitude reduction in space , as well as a reduction in the logarithmic factor in work and cache complexity , when comparing against pq - hl@xmath1 of @xcite .",
    "we label as fh - hl the enhancement of hensel lifting using funnel heap and batched chaining .",
    "this paper extends all of the above work in garnering the prowess of funnel heap . to this end , we incorporate analytical as well as experimental algorithmics techniques as follows :    * in section [ proofs ] , we provide proofs of results introduced in @xcite pertaining to properties of funnel heap , several of which are of independent worth extending beyond hensel lifting . for example , we provide complete proofs for the following : * * we establish where the replicas will reside immediately after each insertion into funnel heap .",
    "* * we determine the number of times one is expected to call sweep on each link of funnel heap throughout a given sequence of insertions .",
    "* * given an upper bound on the maximum constituency of funnel heap at any one point in time across a sequence of operations , we compute the total number of links required by funnel heap . * * we establish that the cache complexity by which one performs batched chaining within fh - hl is optimal . * in section [ rank ] , we exploit that the work and cache complexity of an insert operation using funnel heap can be refined to depend on the rank of the inserted monomial product , where rank corresponds to its lifetime in funnel heap . by optimising on the pattern by which insertions and extractions occur during the hensel lifting phase of the polytope method , we are able to obtain an adaptive funnel heap that minimises all of the work , cache , and space complexity of this phase .",
    "this , in turn , maximises the chances of having all polynomial arithmetic performed in the innermost levels of the memory hierarchy , and observes _ nearly optimal _ spatial locality .",
    "we show that the asymptotic costs of such preprocessing can be embedded in the overall costs to perform hensel lifting with batched chaining ( fh - hl ) , independently of the amount of minimisation taking place .",
    "we call the resulting algorithm fh - rank . * in section [ experimental ] ,",
    "we develop the experimental algorithmics component to our work addressing various facets : * * we conduct a detailed empirical study confirming the scalability of funnel heap over the generic binary heap . by simulating out of core behaviour ,",
    "funnel heap is superior once swaps to external memory begin to take place , despite that it performs considerably more work than binary heap .",
    "this supports the notion that funnel heap should be employed even when performing a single polynomial multiplication or division once data grows out of core . * * we support the theoretical analysis of the cache and space complexity in @xcite using accounts of cache misses and memory consumption of fh - hl .",
    "this can be seen as an extension of @xcite , as the performance measures presented there capture only the real execution time . *",
    "* we benchmark fh - rank against several other variants of hensel lifting , which include pq - hl@xmath1 , pq - hl@xmath1 with the chaining method akin to @xcite , pq - hl@xmath2 , and fh - hl .",
    "our empirical account of time , space and cache complexity of fh - rank confirm the predicted asymptotic analysis in all three metrics . * * we demonstrate that funnel heap is a more efficient merger than the cache oblivious @xmath0-merger , which fails to achieve its optimal ( and amortised ) cache complexity when used for performing sums of products . we attribute this to the fact that the polynomial streams to be merged during hensel lifting can not be guaranteed to be of equal size ( as a result of fluctuating sparsity ) .",
    "this provides an empirical proof of concept that the overlapping approach for performing sums of products using one global funnel heap is more suited than the serialised approach , even when the latter uses the best merging structures available .",
    "we now begin with the following section on background literature and results .",
    "in the remainder of this paper , we will consider that in - core memory is of size @xmath3 .",
    "it is organised using cache lines ( disk blocks ) , respectively , each consisting of @xmath4 consecutive words .",
    "all words in a single line are transferred together between in - core and out - of - core memory in one round ( i / o operation ) referred to as a cache miss ( disk block transfer ) .",
    "funnel heap implements insert and extract - max operations in a cache oblivious fashion .",
    "for @xmath5 elements , funnel heap can perform these operations using amortised ( and optimal ) @xmath6 cache misses @xcite .    at the innermost level ,",
    "funnel heap is first constructed using simple binary mergers .",
    "each binary merger processes two input sorted streams and produces their final merge .",
    "the heads of the input streams and the tail of the output stream reside in buffers of a limited size .",
    "a binary merger is _ invoked _ using a fill function when merge steps are repetitively performed until its output buffer is full or both its input streams are exhausted .",
    "one can construct binary merge trees by letting the output buffer of one merger be an input buffer of another merger . now let @xmath7 for @xmath8 .",
    "a @xmath0-merger is a binary merge tree with exactly @xmath0 input streams .",
    "the size of the output buffer is @xmath9 , and the sizes of the remaining buffers are defined recursively in a van emde boas fashion ( see @xcite ) .",
    "funnel heap consists of a sequence @xmath10 of @xmath0-mergers , where @xmath0 increases doubly exponentially across the sequence .",
    "the @xmath11 s are linked together in a list , with the help of extra binary mergers and buffers at each juncture of the list . in fig .",
    "[ funnelheap ] , the circles are binary mergers , rectangles are buffers , and triangles are @xmath0-mergers .",
    "link @xmath12 in the linked list consists of a binary merger @xmath13 , two buffers @xmath14 and @xmath15 , and a merger @xmath11 with @xmath16 input buffers labeled as @xmath17 .",
    "link @xmath12 has an associated counter @xmath18 for which @xmath19 .",
    "initially , @xmath20 .",
    "it will be an invariant that @xmath21 are empty .",
    "the first structure in funnel heap is a buffer @xmath22 of extremely small size @xmath23 , dedicated for insertion .",
    "this buffer occupies in - core memory at all times .",
    "funnel heap is now laid out in memory in the order @xmath22 , link @xmath24 , link @xmath25 , etc . within link",
    "@xmath12 the layout order is @xmath18 , @xmath14 , @xmath13 , @xmath15 , @xmath11 , @xmath26 , @xmath27 , @xmath28 .",
    "+    the linked list of buffers and mergers constitute one binary tree @xmath29 with root @xmath30 and with sorted sequences of elements on the edges .",
    "this tree is heap - ordered : when traversing any path towards the root , elements will be passed in increasing order .",
    "if buffer @xmath31 is non - empty , the maximum element will reside in @xmath31 or in @xmath22 .",
    "the smaller mergers in funnel heap are meant to occupy primary memory , and can process sufficiently many insertions and extractions in - core before an expensive operation is encountered .",
    "in contrast , the larger mergers tend to be out of core , and contain elements that are least likely to be accessed in the near future . to perform an extract - max",
    ", we call fill on @xmath30 if buffer @xmath31 is empty . we return the largest element residing in both @xmath22 and @xmath31 . to insert into funnel heap , an element has to be inserted into @xmath22 .",
    "if @xmath22 is full , a sweep function is called .",
    "its purpose is to free the insertion buffer @xmath22 together with all the heavily occupied links in funnel heap which are closer to in - core memory . during a sweep , all elements residing in those dense links are extracted then merged into one single stream . this stream",
    "is then copied sufficiently downwards in funnel heap , towards the first link which has at least one empty input buffer . as a result of sweep ,",
    "the dense links are now free and funnel heap operations are resumed within in - core memory .",
    "the sweep kernel is considerably expensive , yet , sufficiently many insertions and all the extractions can be accounted for between any two sweeps .",
    "let @xmath32 denote a finite field of characteristic @xmath33 , and consider a polynomial @xmath34 $ ] with total degree @xmath35 .",
    "we wish to obtain a polynomial factorisation of @xmath36 into two factors @xmath37 and @xmath38 such that @xmath39 and @xmath37 , @xmath40 $ ] .",
    "let @xmath41 denote the newton polygon @xmath42 of @xmath36 defined as the convex hull of the support vector of @xmath36 .",
    "one identifies suitable subsets @xmath43 of edges belonging to @xmath41 , such that all lattice points can be accounted for by a proper translation of this set of edges .",
    "one then specialises terms of @xmath36 along each edge @xmath44 .",
    "those specialisations are derived from the nonzero terms of @xmath36 whose exponents make up integral points on each @xmath45 , and we label them as @xmath46 .",
    "these can be transformed into laurent polynomials in one variable . for at least one @xmath47 , the associated edge polynomials",
    "@xmath46 ought to be squarefree , for all @xmath48 .",
    "one then begins lifting using the boundary factorisations given by @xmath49 , for all @xmath48 .",
    "for each boundary factorisation , we determine the associated @xmath50 s and @xmath51 s that satisfy the hensel lifting equation @xmath52 for @xmath53 .      in @xcite we revised the analysis associated with the bottleneck in computation arising in eq .",
    "( [ maineq2 ] ) , using the sparse distributed representation . in this model of representation ,",
    "a polynomial is exclusively represented as the sum of its non - zero terms , sorted upon some decreasing monomial ordering .",
    "( [ maineq2 ] ) can be modeled using the input and output requirements shown in alg . 1 :    [ local - iter ]    an integer @xmath0 designating one iterative step in the hensel lifting process .",
    "two sets of univariate polynomials over @xmath32 , @xmath54 , @xmath55 , in sparse distributed monomial order representation .",
    "the polynomial @xmath56 , where @xmath57 .",
    "compute @xmath58 .",
    "compute @xmath59 .",
    "we distinguish between the serialised approach ( ser - hl ) and the overlapping approach ( pq - hl ) for performing the required arithmetic . in the serialised version ,",
    "one performs all polynomial multiplications first , and then merges all the resulting polynomial products . in the overlapping approach",
    ", one handles all arithmetic simultaneously using a single max priority queue . in @xcite , we analysed the work , space , and cache complexity , when polynomials are in sparse distributed representation .",
    "we derived that the performance of the serialised version in all three metrics is critically affected not only by the degree of the input polynomial , but also by the following factors : ( i ) the sparsity of each polynomial multiplication , and ( ii ) the sparsity of the resulting polynomial products to be merged into a final summand .",
    "we further showed that this remains the case even with advanced additive ( merging ) data structures like the cache aware tournament tree or the cache oblivious @xmath0-merger , for performing the sums of resulting polynomial products , and that the serialised approach is not able to fully exploit the cache efficiency of these structures .    in the overlapping approach",
    ", the priority queue is initialised using the highest order monomial products generated from each product @xmath60 .",
    "then , terms of @xmath61 are produced in decreasing order of degree , via successive invocations of extract - max upon the priority queue . in @xcite",
    ", we pursued funnel heap as an alternative to the generic binary heap for implementing the overlapping approach .",
    "beyond its cache oblivious nature and optimal cache complexity , we showed that funnel heap allows for a mechanism of chaining that significantly improves its overall performance .",
    "chaining replicas outside the priority queue following insertions is a well known technique ( e.g. see @xcite ) for the case of single polynomial multiplication using binary heap ) .",
    "it helps reduce several parameters tied to performance , such as the total number of extractions required to perform a single polynomial multiplication and the size of the priority queue . in turn , the latter results in reducing the number of monomial comparisons as well as the cache complexity required to perform each priority queue operation . in the straight - forward implementation",
    ", one has to search for a replica immediately after an insertion and then chain the newly inserted element to the end of a linked list tied to that replica in the priority queue .",
    "when using binary heap , chaining hinders performance critically .",
    "each insertion into the linked list denoting the chain incurs a random miss , whereas a single search query may require traversing the entire heap .",
    "it follows that the work and cache complexity of a single insertion amounts to that of traversal of @xmath5 elements for a heap of size @xmath5 .",
    "when employed in the priority queue that is implementing sums of products arising in hensel lifting , chaining becomes daunting as the size of the queue and the amount of replication change irregularly from one iteration to the other .",
    "in @xcite we showed how to exploit the expensive sweep kernel of funnel heap in order to develop a cache friendly batched chaining mechanism ( batched - chain ) that gets intertwined with the sweep s internal operations .",
    "the crux behind our approach lies in delaying chaining and performing it in batches , somehow at the `` right time '' . in the interim ,",
    "a prescribed amount of replication is tolerated , whose effect is shown to be insignificant at scale . here , we restrict chaining to only two specific phases in funnel heap s operations . if one is inserting a monomial product into the ( sorted ) insertion buffer @xmath22 , a replica that resides in @xmath22 is immediately identified and chaining can take place .",
    "one does not attempt to find a replica outside of @xmath22 .",
    "if such a replica exists , chaining will be deferred until @xmath22 is full .",
    "that is when sweep is invoked upon some link @xmath12 as well as one of its input buffers @xmath62 . in the duration of sweep",
    ", one is forming the stream @xmath63 which contains the merged output of all elements in the buffers leading from @xmath14 to @xmath62 together with all elements in links @xmath64 . during the merge",
    ", the replicas residing in those specified regions of funnel heap will be aligned consecutively and thus identified .",
    "one can then chain them all and at once outside of funnel heap .",
    "batched - chain eliminates entirely the need for searching for replicas , and lesser links would be allocated to funnel heap , which reduces garbage collection .",
    "batched - chain is further sensitive to the number of distinct monomials in funnel heap , and not the number of replicas chained .",
    "this can be understood to mean that the overhead due to chaining decreases with increasing replicas , which is intuitively appealing , since chaining is likely to be disabled once the number of replicas is lower than an acceptable threshold .",
    "when incorporating funnel heap and batched - chain into the priority queue algorithm for sums of products , alg .",
    "fh - hl was shown to be significantly fast .",
    "the timings reported in @xcite correspond to overall run - time , with the following percentages of improvement recorded , attained with increasing input size : about 90%-98% ( fh - hl to magma 2.18 - 7 ) , about 90%- 99% ( fh - hl to ser - hl ) , about 10%-60% ( fh - hl to pq - hl@xmath1 ) .",
    "the dramatic reduction in run - time over ser - hl is largely attributed to substantial expression swell , and that over pq - hl@xmath1 is attributed to batched - chain .",
    "in this section we revisit several claims made in @xcite and provide their complete proofs .",
    "those results pertain to the behaviour of funnel heap in general and not necessarily only in relation to hensel lifting , and thus are of independent worth .",
    "unless otherwise stated , all lemmas and corollaries in this specific section are stated in @xcite .",
    "we begin by the following invariant which identifies where the replicas will reside immediately after each insert into funnel heap :    let @xmath65 denote the index of the last link in funnel heap . using batched - chain , and immediately following each insertion , there will be no replication within the constituency of any buffer @xmath66 . as a result , a given element in some buffer @xmath67",
    "may only be replicated at most once in each of the preceding buffers @xmath68 in its own link or in each of the buffers @xmath69 in the larger links .",
    "[ noreplicas ]    consider the case when one is inserting immediately into the insertion buffer @xmath22 .",
    "batched - chain ensures that chaining is happening immediately , and so there will be no replicas in this particular buffer .",
    "now consider a random @xmath67 for @xmath70 .",
    "we know that one can only write elements to @xmath67 upon a call onto @xmath71 .",
    "this call produces the stream @xmath63 which merges the content of all links @xmath72 together with the content of the path @xmath33 leading from @xmath31 down to @xmath67 .",
    "since batched - chain employs chaining during the formation of @xmath63 , buffer @xmath67 will not contain any replicas .",
    "now , by the first claim above , each buffer @xmath67 in funnel heap contains distinct elements . when @xmath73 , it is straightforward to see that since @xmath22 has no buffers which precede it , each of its elements is replicated at most once in each of the following buffers .",
    "now take @xmath70 .",
    "we know that once sweep is called onto @xmath67 , each buffer @xmath74 in the @xmath12th link must be empty .",
    "also , as we form @xmath63  the end of which is written to @xmath67  we exclude the elements residing in each buffer that is also in the same link as @xmath67 but which precede it in that link .",
    "it follows that the only possible replicas of each element in @xmath67 will be in each of the buffers @xmath68 preceding it in its own link , as well as each of the buffers @xmath75 in the larger links .",
    "the following result captures the number of times one is expected to call sweep on each link of funnel hap throughout a given sequence of insertions and extractions :    let @xmath65 denote the index of the last link in funnel heap and let @xmath76 denote the total number of times sweep@xmath77 is called , across a given sequence of insertions and extractions .",
    "then @xmath78 [ totalsweeps ]    we proceed by backward induction on @xmath79 .",
    "take @xmath80 .",
    "link @xmath65 has @xmath81 input buffers .",
    "since this is the last link , not all of its input buffers @xmath67 may be written onto using sweep .",
    "in fact , exaclty @xmath82 of them will be so .",
    "we thus have @xmath83 .",
    "we now show that @xmath84 assuming the property holds for @xmath85 .",
    "observe that before any sweep on link @xmath86 has occurred , there should have preceded it exactly @xmath87 sweeps , in order to fill each of the input buffers in link @xmath79 . also , by the inductive hypothesis , the total number of sweeps on link @xmath86 is given by @xmath88 .",
    "combining , we get that there are @xmath89 sweeps on link @xmath79 .",
    "given an upper bound on the maximum constituency of funnel heap at any one point in time across a sequence of operations , we now determine the total number of links the heap requires :    let @xmath65 denote the index of the last link in funnel heap .",
    "then @xmath90 where @xmath91 designates the maximum number of elements residing in funnel heap at any point in time .",
    "[ last - versus - total ]    from @xcite we invoke the following proven results which we require for our proof :    1 .",
    "the space usage @xmath92 of each input buffer in link @xmath12 satisfies @xmath93 , where @xmath16 is the number of input buffers in link @xmath12 .",
    "the space usage of link @xmath12 is @xmath94 , i.e. it is dominated by the space usage of all of its @xmath16 input buffers .",
    "@xmath95    since link @xmath65 is the last link required by funnel heap to host all elements of its elements , those elements will consume at least one path leading to the first input buffer of link @xmath65 , and at most all @xmath81 such possible paths . by ( 2 )",
    "above , the space usage of each such path is dominated by the size of the input buffer itself and we thus have @xmath96 and @xmath97 .",
    "by @xmath98 we have : @xmath99 where the last equality follows by ( 3 ) above and by unrolling the recursive relation down to the base case . using @xmath100 and composing the logarithm function on the two bases 2 and 4/3 respectively ,",
    "we get @xmath101 .",
    "taking @xmath102 one can proceed analogously as above and obtain @xmath103 .",
    "this concludes the proof .    as in @xcite ,",
    "reasoning in the sparse distributed representation produces worst - case versus best case polynomial multiplication , depending on the structure of the output . in the worst case ,",
    "a given multiplication @xmath104 is sparse as it yields a product with @xmath105 non - zero terms , an incidence of a memory bound computation . at best , the multiplication is dense as it yields a product with @xmath106 terms .",
    "when the product has significantly fewer terms due to cancelation of terms , the operation is said to suffer from expression swell .",
    "we now establish that the cache complexity by which one performs batched - chain within fh - hl is optimal . for this",
    ", we require a few notations from @xcite that will be helpful in the forthcoming sections as well . let @xmath107 and @xmath108 , which denote the maximum number of non - zero monomials comprising each @xmath109 and @xmath110 respectively .",
    "let @xmath111 denote the fraction of reduction in the size of the heap during chaining , such that the largest size the priority queue attains during the @xmath0th lifting step is @xmath112 .",
    "let @xmath113 denote the fraction of replication in the total number of monomial products such that the total number of replicas chained during the @xmath0th hensel lifting step is @xmath114 .",
    "the two parameters @xmath111 and @xmath113 reflect , in an asymptotic sense , the changes in the size of the queue as a function of the amount of replicas . particularly , the bounds on @xmath111 and @xmath113 are as follows .",
    "when no replicas are encountered at all during any one lifting step , we have that @xmath115 and @xmath116 . in contrast , when each polynomial in the pair @xmath117 is totally dense and all resulting products in one lifting step are of the same degree , the heap will contain only one element , leading to @xmath118 and @xmath119 .",
    "we now have the following :    assume the sparse distributed representation for polynomials .",
    "assume further that @xmath120 .",
    "in the worst case analysis when each polynomial multiplication @xmath121 is sparse , the cache complexity by which one performs batched - chain within fh - hl is optimal .",
    "[ cor1 ]    following the analysis in prop .",
    "3.6 of @xcite , the cache complexity of fh - hl is split into two major parts .",
    "the first part accounts for all the insertions into funnel heap using @xmath122 cache misses .",
    "the second part accounts for the cost to perform batched - chain using @xmath123 cache misses .",
    "when @xmath120 , we get that the second summand in the cache complexity incurred by batched - chain is dominated by the cost to perform all the insertions into funnel heap , or that the cost for batched - chain is dominated by @xmath124 , where @xmath125 denotes the total number of replicas chained .",
    "it follows that the cache complexity of batched - chain corresponds to that of traversal , and hence is optimal .    in the following ,",
    "we provide a detailed proof that fh - hl , and thanks to batched - chain , outperforms pq - hl@xmath2 ( and thus by transitivity , also pq - hl@xmath1 ) .",
    "in other words , performing sums of products using funnel heap with batched - chain is provably more efficient in work , space , and cache complexity than if we were to resort to a standalone funnel heap implementation .",
    "assume the sparse distributed representation for polynomials , and assume further the conditions in cor .",
    "[ cor1 ] . in the worst case analysis",
    "when each polynomial multiplication @xmath121 is sparse , fh - hl achieves an order of magnitude reduction in space , as well as a reduction in the logarithmic factor in work and cache complexity , over pq - hl@xmath2 .",
    "[ cor2 ]    from @xcite , alg .",
    "pq - hl@xmath2 requires the following costs :    [ cols=\"^,^,^\",options=\"header \" , ]     [ k - ksq ]",
    "in this paper we presented a comprehensive design and analysis that extends the work in @xcite and @xcite .",
    "fh - rank exploits all the features of funnel heap for implementing sums of products arising in hensel lifting of the polytope method , when polynomials are in sparse distributed representation .",
    "those features involve a batched mechanism for chaining replicas as well as optimising on the sequence of insertions and extractions in order to minimise the size of the priority queue as well as the work and cache complexity .",
    "the competitive asymptotics are validated by empirical results , which , in addition to asserting the high efficieny of fh - rank whether or not data fits in in - core memory , help us derive two other main conclusions .",
    "firstly , we confirm that at a large scale , all polynomial arithmetic employing a priority queue will benefit substantially from using funnel heap over binary heap , even without the proposed mechanisms for chaining and/or optimising the sequence of insertions / extractions .",
    "secondly , funnel heap is confirmed to be superior in practice as a merger when tested against the provably optimal @xmath0-merger structure , despite having a higher work complexity .",
    "this is attributed to its ability to adapt to merging input streams of fluctuating density , which in turn , makes funnel heap ideal for performing polynomial arithmetic in the sparse distributed representation , where such fluctuation affects overall performance .",
    "this supports our argument that one should resort to the overlapping approach using a single priority queue , as opposed to handling each of the the local multiplications separately using a local priority queue , to be followed by additive merging of all polynomial streams .",
    "this conclusion remains valid whether or not expression swell is taking place .",
    "we thank the lebanese national council for scientific research and the university research board ",
    "american university of beirut , for supporting this work .",
    "50 natexlab#1#1url # 1`#1`urlprefix        abu salem , f.  k. , el - harake , k. , gemayel , k. , 2015 . cache oblivious sparse polynomial factoring using the funnel heap . in : proc .",
    "pasco 15 . vol .",
    "8660 of lecture notes in computer science .",
    "springer , pp .",
    "715 .",
    "brodal , g.  s. , fagerberg , r. , meyer , u. , zeh , n. , 2004 .",
    "cache - oblivious data structures and algorithms for undirected breadth - first search and shortest paths . in : proc . of swat 04 . vol .",
    "3111 of lecture notes in computer science .",
    "springer , pp . 480492 .",
    "monagan , m. , pearce , r. , 2007 .",
    "polynomial division using dynamic arrays , heaps , and packed exponent vectors . in : proc . of casc 07 .",
    "4770 of lecture notes in computer science .",
    "springer , pp ."
  ],
  "abstract_text": [
    "<S> this work is a comprehensive extension of @xcite that investigates the prowess of the funnel heap for implementing sums of products in the polytope method for factoring polynomials , when the polynomials are in sparse distributed representation . </S>",
    "<S> we exploit that the work and cache complexity of an insert operation using funnel heap can be refined to depend on the rank of the inserted monomial product , where rank corresponds to its lifetime in funnel heap . by optimising on the pattern by which insertions and extractions occur during the hensel lifting phase of the polytope method , we are able to obtain an adaptive funnel heap that minimises all of the work , cache , and space complexity of this phase . </S>",
    "<S> this , in turn , maximises the chances of having all polynomial arithmetic performed in the innermost levels of the memory hierarchy , and observes _ nearly optimal _ spatial locality . </S>",
    "<S> we provide proofs of results introduced in @xcite pertaining to properties of funnel heap , several of which are of independent worth extending beyond hensel lifting . additionally , we conduct a detailed empirical study confirming the superiority of funnel heap over the generic binary heap once swaps to external memory begin to take place . </S>",
    "<S> we support the theoretical analysis of the cache and space complexity in @xcite using accounts of cache misses and memory consumption , and compare the run - time results appearing there against adaptive funnel heap . </S>",
    "<S> we further demonstrate that funnel heap is a more efficient merger than the cache oblivious @xmath0-merger , which fails to achieve its optimal ( and amortised ) cache complexity when used for performing sums of products . </S>",
    "<S> this provides an empirical proof of concept that the overlapping approach for performing sums of products using one global funnel heap is more suited than the serialised approach , even when the latter uses the best merging structures available . </S>",
    "<S> our main conclusion is that funnel heap will outperform binary heap for performing sums of products , whether data fits in in - core memory or not .    </S>",
    "<S> hensel lifting , newton polytopes , polynomial factorisation , cache oblivious algorithms and data structures , cache complexity , priority queues , funnel heap </S>"
  ]
}