{
  "article_text": [
    "the best way to understand the subject of this paper is to have a glance at table  [ tab : problem ] on page   that illustrates the problem studied .",
    "table  [ tab : problem ] shows the grade - level and portfolio - wide default rates ( third column ) that were observed in 2009 for s&p - rated corporate entities together with the rating frequencies that were observed at the beginning of 2009 ( second column ) and at the beginning of 2010 ( fourth column ) .",
    "the question marks in the fifth column indicate the question this paper is intended to answer : how can grade - level default rates for a future time period be forecast on the basis of observations from an earlier period and the known rating profile at the beginning of the future period ?",
    "the question mark in the lower right corner of table  [ tab : problem ] indicates that we investigate this question both under the assumption that an independent forecast of the future portfolio - wide default rate is known and under the assumption that also the future portfolio - wide default rate has to be forecast .",
    ".s&p rating frequencies ( % ) and default rates ( % ) in 2009 and rating frequencies in 2010 .",
    "sources : , tables 51 to 53 , and , tables 50 to 52 . [ cols=\"<,>,>,>,^ \" , ]     according to table  [ tab : averageranks ] the ` scaled likelihood ratio ' approach performs best on average , followed by the ` scaled pds ' and ` invariant default profile ' approaches ( with little difference ) , while the average performance of ` invariant accuracy ratio ' is worst . hence , when compared with the observations from section  [ se : case4 ] , the ` scaled pds ' and ` invariant accuracy ratio ' approaches have swapped ranking positions .",
    "the poor performance of ` invariant accuracy ratio ' in the backtest could be a sign that the underlying assumption of a constant accuracy ratio over time is simply not right .",
    "the stronger than expected performance of the ` scaled pds ' approach could be owed to its conceptual similarity to the strong performing ` scaled likelihood ratio ' .",
    "accurate ( re-)calibration of a rating model requires careful consideration of a number of questions that include , in particular , the question of which model components can be assumed to be invariant between the estimation period of the model and the forecast period .",
    "looking at pd curve calibration as a problem of forecasting rating - grade level default rates , we have discussed a model framework that is suitable for the description of a variety of different forecasting approaches .",
    "we have then proceeded to present a number of pd curve calibration approaches and explored the conditions under which the approaches are fit for purpose .",
    "we have tested the approaches introduced by applying them to publicly available datasets of s&p and moody s rating and default statistics that can be considered typical for the scope of application of the approaches .",
    "one negative and one positive finding are the main results of our considerations :    * the popular ` scaled pds ' approach for ( re-)calibrating a rating model to a different target unconditional pd is not likely to deliver the best calibration results because it implicitly mixes up the unconditional pd of the estimation period and the target pd . * as shown by example , the ` scaled likelihood ratio ' approach to pd curve calibration avoids mixing up the unconditional pds from the estimation and the forecast periods and , on average , performs better than ` scaled pds ' and other approaches discussed in the paper . `",
    "scaled likelihood ratio ' is , therefore , a promising alternative to ` scaled pds ' .",
    "in this paper , we apply quasi moment matching ( qmm ) as suggested by @xcite for the smoothing of pd curves .",
    "qmm requires the numerical solution of a two - dimensional system of non - linear equations .",
    "the solution of such an equation system in general is much facilitated if a meaningful initial guess of the solution can be provided .",
    "the binormal model we discuss in the following subsection delivers such a guess .",
    "in addition , the binormal model provides the main motivation of the qmm technique . in subsection  [ se : qmm ] we describe the qmm technique itself .          *",
    "the distribution of @xmath0 conditional on the event @xmath1 ( the borrower defaults during the observation period ) is normal with mean @xmath2 and variance @xmath3 . *",
    "the distribution of @xmath0 conditional on the event @xmath4 ( the borrower remains solvent during the whole observation period ) is normal with mean @xmath5 and variance @xmath3 .",
    "* @xmath6 is the borrower s unconditional pd ( i.e.  the unconditional probability that the borrower defaults during the observation period ) .",
    "denote by @xmath7 and @xmath8 respectively the conditional densities of the binormal score @xmath0 .",
    "hence by assumption  [ as : binormal ] we have @xmath9 in the continuous case specified by assumption  [ as : binormal ] , bayes formula implies a pd curve @xmath10 $ ] similar to the discrete formula :    @xmath11 & =           \\frac{p\\,f_d(x)}{p\\,f_d(x ) + ( 1-p)\\,f_n(x ) } \\label{eq : key}\\\\          & = \\frac{1}{1+\\exp(\\alpha+\\beta\\,x)},\\label{eq : logit}\\\\ \\alpha & = \\frac{\\mu_d^2-\\mu_n^2}{2\\,\\sigma^2 } + \\log\\left(\\frac{1-p}{p}\\right),\\label{eq : alpha}\\\\      \\beta & = \\frac{\\mu_n-\\mu_d}{\\sigma^2}.\\label{eq : beta}\\end{aligned}\\ ] ]    note that from it follows that @xmath12}{d\\,x } \\ = \\ - \\beta\\,\\pr[d\\,|\\,x = x]\\ ,      \\bigl(1-\\pr[d\\,|\\,x = x]\\bigr).\\ ] ] hence the absolute value of the slope of the pd curve attains its maximum if and only if @xmath13 = 1/2 $ ] and then the maximum absolute slope is @xmath14 .",
    "denote by @xmath15 and @xmath16 independent random variables with @xmath17 and @xmath18 .",
    "then , under assumption  [ as : binormal ] , we also obtain a simple formula denotes the standard normal distribution function @xmath19 . ] for the discriminatory power of the score @xmath0 if it is measured as _ accuracy ratio _ ( see , for instance , * ? ? ?",
    "* ) :      in addition , it is easy to show how the unconditional mean @xmath21 and variance @xmath22 of the score @xmath0 can be described in terms of the means and variances of @xmath0 conditional on default and survival respectively :      a close inspection of equations , and shows that the conditional variance @xmath24 and the conditional means @xmath2 and @xmath25 can be written as functions of the unconditional mean , the unconditional variance and the accuracy ratio : @xmath26 from this , it follows by and that also the coefficients @xmath27 and @xmath28 in can be represented in terms of the unconditional mean @xmath21 of @xmath0 , the unconditional variance @xmath22 of @xmath0 , and the discriminatory power @xmath29 of @xmath0 . in particular , we have the following representation of @xmath28 in terms of the accuracy ratio and the dispersion of the conditional score distributions : @xmath30 these observations suggest the following three steps approach to identifying initial values for the qmm approach to pd curve smoothing :    1 .   calculate the mean @xmath21 and the standard deviation @xmath31 of the unconditional rating profile .",
    "2 .   use @xmath21 and @xmath31 together with the unconditional pd @xmath32 and the accuracy ratio @xmath29 implied by the rating profile and the observed grade - level default rates to calculate the conditional standard deviation @xmath33 and the conditional means @xmath2 and @xmath25 according to . 3 .",
    "use equations and to determine initial values for @xmath27 and @xmath28 .",
    "equation shows that the unconditional pd has a direct primary impact on the level of the pd curve .",
    "equation suggests that the ar of a rating model has a similar impact on the maximum slope of the pd curve .",
    "the two observations together suggest that in general a two - parameter pd curve can be fitted to match given unconditional pd and ar .",
    "it may be argued that for a suitably developed rating model based on carefully selected risk factors , the associated pd curve must be monotonic for economic reasons . under the assumption that the pd curve is monotonic , @xcite suggested the following robust version of the logistic curve for fitting the pd curve : @xmath34 & \\ \\approx \\ \\frac{1 }      { 1 + \\exp\\bigl(\\alpha + \\beta\\,\\phi^{-1}\\bigl(f_n(x)\\bigr)\\bigr ) } , \\\\",
    "f_n(x ) & \\ = \\ \\pr[x",
    "\\le x\\,|\\,n ] . \\end{split}\\ ] ] this approach may be considered a variant of the `` sigmoid model '' suggested by @xcite .",
    "the term @xmath35 in transforms the in general non - normal distribution of the ratings conditional on survival into another distribution that is approximately normal even if the rating distribution is not continuous .",
    "however , in the discontinuous case @xmath36 may occur which would entail @xmath37 = 0 $ ] .",
    "a suitable work - around to avoid this is to replace the distribution function @xmath38 by the average @xmath39 of @xmath38 and its left - continuous version : @xmath40+\\pr[x \\le x\\,|\\,n]}2.\\ ] ] define , in addition to @xmath38 , the distribution function @xmath41 of the rating variable @xmath0 conditional on default by @xmath42.\\ ] ] and denote by @xmath15 and @xmath16 independent random variables that are distributed according to @xmath41 and @xmath38 respectively .",
    "see @xcite for a discussion of why this definition of accuracy ratio ( or the related definition of the area under the roc curve ) is more expedient than the also common definition in geometric terms .",
    "definition of ar takes an ` ex post ' perspective by assuming the obligors states @xmath1 or @xmath4 at the end of the observation period are known and hence can be used for estimating the conditional ( on default and survival respectively ) rating distributions @xmath41 and @xmath38 .    in the case where @xmath0 is realised as one of a finite number of rating grades @xmath44",
    ", the accuracy ratio can be calculated from the pd curve as follows : @xmath45\\bigr)\\,\\pr[x = x]\\sum_{t=1}^{x-1 }       \\pr[d\\,|\\,x = t]\\,\\pr[x = t]\\\\      &    \\quad +       \\sum_{x=1}^k \\pr[d\\,|\\,x = x]\\,\\bigl(1-\\pr[d\\,|\\,x = x]\\bigr)\\,\\pr[x = x]^2\\big ) \\ - 1 , \\end{split}\\ ] ] where @xmath32 stands for the unconditional pd as given by .      1 .",
    "fix target values @xmath46 and @xmath47 for the unconditional portfolio pd and the accuracy ratio of the rating model .",
    "2 .   substitute @xmath46 and @xmath48 for the left - hand sides of equations and respectively .",
    "3 .   represent @xmath37 $ ] in and by the robust logistic curve ( with @xmath38 replaced by @xmath39 ) .",
    "determine @xmath39 by means of from the empirical unconditional rating profile , the grade - level default rates and the unconditional default rate .",
    "4 .   choose initial values for the parameters @xmath27 and @xmath28 according to , and , with @xmath49 $ ] and @xmath50 $ ] .",
    "solve numerically the equation system for @xmath27 and @xmath28 .              c.  elkan .",
    "the foundations of cost - sensitive learning . in b.",
    "nebel , editor , _ proceedings of the seventeenth international joint conference on artificial intelligence , ijcai 2001 _ , pages 973978 .",
    "morgan kaufmann , 2001 .",
    "k.  pearson . on the criterion",
    "that a given system of deviations from the probable in the case of a correlated system of variables is such that it can be reasonably supposed to have arisen from random sampling .",
    "_ philosophical magazine , series 5 _ , 500 ( 302):0 157175 , 1900 ."
  ],
  "abstract_text": [
    "<S> pd curve calibration refers to the transformation of a set of rating grade level probabilities of default ( pds ) to another average pd level that is determined by a change of the underlying portfolio - wide pd . </S>",
    "<S> this paper presents a framework that allows to explore a variety of calibration approaches and the conditions under which they are fit for purpose . </S>",
    "<S> we test the approaches discussed by applying them to publicly available datasets of agency rating and default statistics that can be considered typical for the scope of application of the approaches . </S>",
    "<S> we show that the popular ` scaled pds ' approach is theoretically questionable and identify an alternative calibration approach ( ` scaled likelihood ratio ' ) that is both theoretically sound and performs better on the test datasets . </S>",
    "<S> + keywords : probability of default , calibration , likelihood ratio , bayes formula , rating profile , binary classification . </S>"
  ]
}