{
  "article_text": [
    "for a good textbook on classical ( non - quantum ) shannon information theory ( sit ) , see , for example , ref.@xcite by cover and thomas . henceforth we will refer to it as c&t . for",
    "a good textbook on classical ( non - quantum ) bayesian networks , see , for example , ref.@xcite by koller and friedman .",
    "this paper begins with a discussion of integration over probability types ( p - types ) . after doing that ,",
    "the paper re - visits 3 mainstay problems of classical sit :    * source coding ( lossy compression ) without distortion * channel coding * source coding with distortion    the paper proves well - known , conventional results for each of these 3 problems .",
    "however , the proofs given for these results are not conventional .",
    "they are based on complex integration techniques ( approximations obtained by applying the method of steepest descent to p - type integrals ) instead of the usual delta & epsilon and typical sequences arguments .",
    "another unconventional feature of this paper is that we make ample use of classical bayesian networks ( cb nets ) .",
    "this paper showcases some of the benefits of using cb nets to do classical sit .",
    "p - types were introduce into sit by csiszr and krner ( see ref.@xcite ) .",
    "p - type integration is a natural , almost obvious consequence of the theory of p - types , although it is not spelled out explicitly in the book by csiszr and krner . in fact , all workers whose work i am familiar with , including csiszr and krner , use p - types frequently , but they do not use p - type integration . instead , they use delta & epsilon and typical sequences arguments to bound some finite sums which are discrete approximations of p - type integrals .    the conventional delta & epsilon arguments are more rigorous than the p - type integration arguments presented here .",
    "although less rigorous than traditional arguments , p - type integration arguments have the virtue that they are easier to understand and follow , especially by people who are not well versed in rigorous analysis . such is the case with many physicists and engineers .",
    "a similar problem occurs when teaching calculus .",
    "one can teach calculus with the full panoply of delta & epsilon arguments from a textbook such as the legendary one by w. rudin ( ref.@xcite ) . or one can teach calculus at the level and scope of a college freshman course for engineers .",
    "each approach appeals to a different audience and fulfils different needs .",
    "most of our results are not exact .",
    "they are leading order terms in asymptotic expansions for large @xmath0 , where @xmath0 is the number of letters in a codeword .",
    "these approximations become increasingly more accurate as @xmath1 .",
    "this paper is almost self contained , although a few times we assume certain inequalities and send the reader to c&t for a proof of them .",
    "in this section , we will describe some basic notation used throughout this paper .    as usual",
    ", @xmath2 will denote the integers , real numbers , and complex numbers , respectively .",
    "we will sometimes add superscripts to these symbols to indicate subsets of these sets .",
    "for instance , we ll use @xmath3 to denote the set of non - negative reals . for @xmath4 such that @xmath5 , let @xmath6 .",
    "let @xmath7 denote the kronecker delta function : it equals 1 if @xmath8 and 0 if @xmath9 .",
    "let @xmath10 denote the truth function : it equals 1 if statement @xmath11 is true and 0 otherwise . for example , @xmath12 .",
    "another example is the step function @xmath13 : it equals 1 if @xmath14 and is zero otherwise .    for any matrix @xmath15",
    ", @xmath16 will denote its complex conjugate , @xmath17 its transpose , and @xmath18 its hermitian conjugate .",
    "random variables will be denoted by underlined letters ; e.g. , @xmath19 .",
    "the ( finite ) set of values ( states ) that @xmath19 can assume will be denoted by @xmath20 .",
    "let @xmath21 .",
    "the probability that @xmath22 will be denoted by @xmath23 or @xmath24 , or simply by @xmath25 if the latter will not lead to confusion in the context it is being used .",
    "we will use @xmath26 to denote the set of all probability distributions with domain @xmath20 . for joint random variables",
    "@xmath27 , let @xmath28 .    sometimes , when two random variables @xmath29 and @xmath30 satisfy @xmath31 , we will omit the indices @xmath32 and @xmath33 and refer to both random variables as @xmath19 .",
    "we shall do this sometimes even if the random variables @xmath29 and @xmath30 are not identically distributed !",
    "this notation , _ if used with caution _ , does not lead to confusion and does avoid a lot of index clutter .",
    "suppose @xmath34 .",
    "we will often use the expectation operators @xmath35 , @xmath36 , and @xmath37 . note that @xmath38 .",
    "let p(x : y ) = .",
    "note that @xmath39 .",
    "suppose @xmath0 is any positive integer .",
    "let @xmath40 be the random variable that takes one values @xmath41 .",
    "the * rate of @xmath42 * is defined as @xmath43 .",
    "@xmath44 is said to be i.i.d .",
    "( independent , identically distributed ) if @xmath45 for all @xmath46 and there is a @xmath47 such that @xmath48 .",
    "when @xmath44 is i.i.d . , we will sometimes use @xmath49 to denote the more correct expression @xmath50 and say that @xmath51 is an i.i.d . source .",
    "suppose @xmath52 for all @xmath53 .",
    "@xmath54 is said to be a discrete memoryless channel ( dmc ) if @xmath55 .",
    "we will use the following measures of various types of information ( entropy ) :    * the ( plain ) entropy of the random variable @xmath42 is defined in the classical case by + h ( ) = e_x , which we also call @xmath56 , @xmath57 , and @xmath58 .",
    "this quantity measures the spread of @xmath59 .",
    "+ one can also consider plain entropy for a joint random variable @xmath60 .",
    "for @xmath61 with marginal probability distributions @xmath62 and @xmath63 , one defines a joint entropy @xmath64 and partial entropies @xmath65 and @xmath66 . * the conditional entropy of @xmath67 given @xmath42",
    "is defined in the classical case by + h(| ) & = & e_x , y + & = & h(,)-h ( ) , which we also call @xmath68 .",
    "this quantity measures the conditional spread of @xmath67 given @xmath42 . *",
    "the mutual information ( mi ) of @xmath42 and @xmath67 is defined in the classical case by + h ( : ) & = & e_x , y p(x : y)= e_x e_y p(x : y ) p(x : y ) + & = & h ( ) + h ( ) - h ( , ) , which we also call @xmath69 .",
    "this quantity measures the correlation between @xmath42 and @xmath67 . * the conditional mutual information ( cmi , which can be read as  see me \" ) of @xmath42 and @xmath67 given @xmath70 is defined in the classical case by : + h(:| ) & = & e_x , y , + & = & e_x , y , + & = & h(| ) + h(| ) - h(,| ) , which we also call @xmath71 .",
    "this quantity measures the conditional correlation of @xmath42 and @xmath67 given @xmath70 . *",
    "the relative information of @xmath72 divided by @xmath73 is defined by + d\\{p(x)//q(x)}_x = _ x p(x ) , which we also call @xmath74 .    note that we define entropies using natural logs .",
    "our strategy is to use natural log entropies for all intermediate analytical calculations , and to convert to base-2 logs at the end of those calculations if a base-2 log numerical answer is desired .",
    "such a conversion is of course trivial using @xmath75 and @xmath76    we will use the following well - known integral representation of the dirac delta function :    \\(x ) = _",
    "-^+ e^ikx .",
    "we will also use the following integral representation of the step function :    ( x>0 ) = _ -^+ , [ eq - theta - comp - int ] for some @xmath77 .",
    "eq.([eq - theta - comp - int ] ) follows because the integrand has a simple pole at @xmath78 .",
    "let @xmath79 .",
    "if @xmath14 , the integrand goes to zero in the upper half of the @xmath80 plane and it goes to infinity in the lower half plane , so we are forced to close the contour of integration in the upper half plane , which means the pole lies inside the contour . when @xmath81 , we are forced to close the contour in the lower half plane and thus the pole lies outside the contour .",
    "suppose @xmath82 is a real valued function that depends in a continuous manner on @xmath83 real variables @xmath84 .",
    "the following variational operator can be applied to @xmath82 :    = _ j v_j .",
    "the @xmath83-dimensional taylor expansion of @xmath82 about the point @xmath85 can be expressed as    f(v ) = f(0 ) + [ f(v)]_v=0 + [ ^2 f(v)]_v=0 + + [ ^3 f(v)]_v=0 +  .",
    "we will often use the following taylor expansions :    x^= e^x= 1 + x + ( x)^2 +  , [ eq - taylor - one ] and    ( 1+x)= x - +  ( |x|<1 ) .",
    "[ eq - taylor - two ]",
    "in this section , we will define integration over probability types ( p - types ) .",
    "the set of p - types for a given @xmath0 fills all of @xmath86 in an increasingly finer way as @xmath1 .",
    "thus , once the density of p - types at each point of @xmath86 is known , we can integrate that density over a particular region @xmath87 to get the number of p - types within @xmath88 .",
    "we will define integration over p - types that depend on a single variable ( univariate p - types ) , or multiple variables ( multivariate p - types ) .",
    "we will also define integration over conditional p - types .",
    "finally , we will define dirac delta functions for integration over p - types .      for",
    "any @xmath89 , denote the number of occurrences of @xmath90 within @xmath91 by @xmath92 .",
    "hence    n(x|x^n ) = _ j=1^n ( x_j = x ) .",
    "one can now say that two elements @xmath91 and @xmath93 of @xmath94 are equivalent if , for all @xmath90 , @xmath91 and @xmath93 both have the same number of occurrences of @xmath95 .",
    "this equivalence relation partitions @xmath96 into equivalence classes given by , for any @xmath53 ,    = \\{x^ns_^n :",
    "n(x|x^n)= n(x|x^n ) xs _ } . for each class",
    "@xmath97 $ ] and @xmath90 , we can define    \\(x ) = .",
    "clearly , @xmath98",
    ". we will refer to this probability distribution as a p - type .",
    "note that if @xmath99 is an i.i.d .",
    "source ,    q(x^n ) = _ j=1^n",
    "q(x_j ) , so    q(x^n ) = _ xs _ \\ { q(x)^n(x|x^n)}= e^ n_x ( x ) q(x ) .",
    "define the following integration operator :    = _ x \\ { _ 0 ^ 1 d(x ) } ( _ x ( x ) -1 ) .",
    "[ eq - p - type - int - measure ]    we will denote the number of elements in a class @xmath97 $ ] by    d_[x^n ] = |[x^n]| .    _",
    "x^n = _ [ x^n ] d_[x^n ] .",
    "the classes @xmath97 $ ] are non - overlapping and they cover all of @xmath96 .    for any @xmath89 , d_[x^n]= ( d_[x^n])_h=0e^nh ( ) , where    ( d_[x^n])_h=0= .",
    "let s_= \\{x(j ) : jz_1,n _ } and    r_j = n(x(j)|x^n ) for all @xmath100 .",
    "note that @xmath101 .",
    "recall stirling s formula :    n ! n^n e^-n for @xmath102 .",
    "combinatorics gives a value for @xmath103|$ ] in terms of factorials .",
    "if we approximate those factorials using stirling s formula , we get     & = & ( ) ^ e^-n + nn -_j\\{-r_j + r_jr_j }   + & = & .    _ [ x^n ] = n^n_-1 .",
    "[ eq - sum - xn ]    for any i.i.d .",
    "source @xmath99 , we have that    1 & = & _ x^nq(x^n ) + & = & _ [ x^n ] d_[x^n ] e^n_x ( x ) q(x ) + & = & , [ eq - one - is - int ] where @xmath104 is yet to be determined and    _ 0 = n _ x ( x )",
    ". we add to @xmath105 a lagrange multiplier term that constrains the components of the vector @xmath106 so that they sum to one :    = _ = _ 0 + n ( _ x ( x )",
    "-1 ) for any @xmath107 . our goal is to approximate the integral eq.([eq - one - is - int ] ) using the method of steepest descent .",
    "we just want to get the leading order term in an asymptotic expansion of the integral for large @xmath0 . to get this leading order term ,",
    "it is sufficient to approximate @xmath108 to second order in @xmath109 , about the point ( or points ) that have a vanishing first variation @xmath110 .",
    "thus , approximate    + + ^2 , where quantities with a tilde over them are evaluated at a tilde ( saddle ) point that satisfies    = 0 .",
    "it s easy to check that    = n _ x ( x ) ( ) , and    ^2= -n_x .",
    "next , for each @xmath95 , we set to zero the coefficient of @xmath109 in @xmath110 . after doing that ,",
    "we enforce the constraint that @xmath111 .",
    "this leads us to conclude that    \\(x ) = q(x ) . using this value of @xmath112 , we get    = 0 and    ^2= -n_x . from eq.([eq - one - is - int ] ) , we get    1= , where    = e^",
    "the final integral was performed using eq.([eq - p - type - int - over - gauss ] ) .",
    "this implies @xmath113 .",
    "note that eqs.([eq - sum - xn ] ) and ( [ eq - caldpx - one ] ) imply that    _ [ x^n ]",
    "1= so the number of p - types with a given @xmath0 in @xmath86 varies polynomial with @xmath0 .",
    "there exists a very natural 1 - 1 onto map from @xmath114 to @xmath115 , namely the one that identifies @xmath116 with @xmath117_{\\forall j}$ ] .",
    "thus , the definitions and claims given in the previous section for @xmath92 , @xmath97 $ ] , @xmath118 and @xmath119 generalize very naturally to give analogous definitions and claims for @xmath120 , @xmath121 $ ] , @xmath122 and @xmath123 .",
    "for example ,    n(x , y|x^n , y^n)=n ( (    cx + y    ) | (    cx^n + y^n    ) ) = _ j ( (    cx + y    ) = (    cx_j + y_j    ) )",
    ".    we will sometimes use @xmath124 $ ] as an abbreviation for a class .",
    "for example , we might abbreviate @xmath125 by @xmath126 .",
    "note that when @xmath127 in @xmath128 ,    ( x , y ) = _ y^x ( x ) .",
    "note also that we can express @xmath129 as follows    e^n_x , y ( x , y ) _ y^x & = & \\ {    l ( x , y ) _",
    "x^y= 0 ( x , y)0 + 1 ,    .",
    "+ & = & ( ( x , y ) : yx(x , y)= 0 ) + & = & _ x^n^y^n .      for any @xmath89 and @xmath130 , define conditional classes by    = \\{(x^n , y^n)s_^ns_^n : = ( x , y)s_s _ } and conditional probability types by    ( y|x ) = = for all @xmath90 and @xmath131 .    we will sometimes use @xmath124 $ ] as an abbreviation for a conditional class .",
    "for example , we might abbreviate @xmath132 by @xmath133 .",
    "define the following integration operator :    = _ x , y \\ { _ 0 ^ 1 d(y|x ) } _ x \\ { ( _ y ( y|x ) -1 ) } .",
    "[ eq - cond - p - type - int - measure ]    we will denote the number of elements in conditional class @xmath134 $ ] by    d_[y^n|x^n]= |[y^n|x^n]| .    [ claim - sum - xn - yn ] _",
    "x^n , y^n= _ [ x^n]d_[x^n ] _ [ y^n|x^n]d_[y^n|x^n ] .",
    "for any dmc @xmath135 , we must have    1=_[y^n|x^n]d_[y^n|x^n]q(y^n|x^n ) . if @xmath99 is an i.i.d source and @xmath136",
    ", then the last equation implies    1&=&_[x^n]d_[x^n]q(x^n ) _ [ y^n|x^n]d_[y^n|x^n]q(y^n|x^n ) + & = & _ [ x^n]d_[x^n ] _ [ y^n|x^n]d_[y^n|x^n]q(x^n , y^n ) . but also    1=_x^n , y^nq(x^n , y^n ) .",
    "since @xmath137 is an arbitrary i.i.d .",
    "source , the claim follows .",
    "[ claim - d - yn - cond - xn ] d_[y^n|x^n]= .",
    "combinatorics ?",
    "[ claim - sums - chain - rule ] _ [ x^n ] _ [ y^n|x^n ] = _ [ x^n , y^n ] .",
    "[ eq - sums - chain - rule ]    this follows from claims [ claim - sum - xn - yn ] and [ claim - d - yn - cond - xn ] and the fact that @xmath138 } d_{[x^n , y^n]}$ ] .",
    "alternatively , one could prove claim [ claim - sums - chain - rule ] by combinatorics and then prove claim [ claim - d - yn - cond - xn ] from claims [ claim - sum - xn - yn ] and [ claim - sums - chain - rule ] .",
    "[ claim - split - int - ptype ] ^n_- 1 = [ eq - split - int - ptype ]    let lhs and rhs denote the left hand side and right hand side of eq.([eq - split - int - ptype ] ) .",
    "recall that dirac delta functions obey @xmath139 .",
    "this proof hinges on that simple identity .",
    "= _ x \\ { _ 0 ^ 1 d(x ) } ( _ x ( x ) -1 ) and    _ 2 = _ x , y \\ { _ 0 ^ 1 d(y|x ) } _ x \\ { ( _ y ( y|x ) -1 ) } ^n_- 1 . then    lhs & = & _ 1_2 + & = & _ 1 _ x , y \\ { _ 0 ^ 1 d(x , y ) } _ x \\ { ( _ y ( x , y ) -(x ) ) } + & = & _ x , y \\ { _ 0 ^ 1 d(x , y ) } ( _ x , y ( x , y ) -1 ) + & = & rhs    this works because lhs has @xmath140 integrals and @xmath141 delta functions , for a total of @xmath142 degrees of freedom .",
    "rhs has @xmath143 integrals and one delta function for the _ same total _ of @xmath144 degrees of freedom .",
    "_ [ y^n|x^n ] & = & ^n_- 1 + & = & ( n ^g.m.)^n_n_- n _ , where    ^g.m.= ^ is the geometric mean of @xmath145",
    ".    substitute    = _ [ x^n ] , and    = _ [ x^n , y^n ] into eq.([eq - split - int - ptype ] ) and then compare the result with eq.([eq - sums - chain - rule ] ) .",
    "one occasionally finds it useful to use dirac delta functions for p - type integration .",
    "suppose @xmath146 and @xmath147 is a real number satisfying @xmath148 .",
    "let @xmath149 $ ] and @xmath150 $ ] .",
    "define    v_a = for any positive real number @xmath151 .",
    "we will refer to the following functions as dirac delta functions for setting @xmath152 and @xmath153 equal    ( , ) = ( =) ,    _ ( , ) = ( - _ x \\{p_(x ) - p_(x)}^2 ) ,    _",
    "( x^n , y^n ) = , and    _ ( p_-p _ ) = .",
    "( x^n , y^n ) = 1 , and    p _ _ ( p_- p _ ) = 1 .",
    "this follows from integration formula eq.([eq - p - type - int - over - gauss ] ) .",
    "we consider all source coding protocols that can be described by the following cb net    = + + [ o][f- ] , with @xmath154 and    p(x^n ) = _ j=1^n",
    "p_(x_j ) ,    p(m|x^n ) = ( m , m(x^n ) ) and    p(^n|m ) = ( ^n , ^n(m ) ) .",
    "assume that we are given a source @xmath155 .",
    "the encoding function @xmath156 and the decoding function @xmath157 are yet to be specified .",
    "by @xmath158 and the decoding function @xmath157 by @xmath159 . ]",
    "the probability of error is defined by    p_err = p(^n^n ) .",
    "we find it more convenient to work with the probability of success , which is defined by @xmath160 .",
    "one has    p_suc & = & 1 - p_err + & = & p(^n= ^n ) + & = & _ ^n , m , x^n ( ^n = x^n ) p(^n|m)p(m|x^n)p_(x^n ) + & = & _ x^n p_(x^n ) .    now it s time to decide what encoding and decoding functions we want to consider .",
    "suppose @xmath161 is a proper subset of @xmath96",
    ". one can give each element of @xmath161 an individual number ( its index ) from 1 to @xmath162 .",
    "assume , without loss of generality , that @xmath163 .",
    "as we shall see , the following encoding and decoding functions are good enough :    m(x^n ) = \\ {    ll x^n a & x^na + 0 & x^na    . , and    ^n(m ) = \\ {    ll m^-1(m ) & mz_1,|a| + 0^n & m=0    . , where the set @xmath161 is given by either    a_p_=\\ { x^n : r } = \\ { x^n : r_x ( x ) } , or    a_univ = \\ { x^n : rh ( ) } = \\ { x^n : r_x ( x ) } for some positive number @xmath88 yet to be specified .",
    "these two interesting options for the set @xmath161 can be considered simultaneously by defining    a = \\ { x^n : r_x ( x ) } , where    q(x ) = \\ {    ll p_(x ) & + ( x ) &    . .",
    "in the case of source dependent coding , @xmath164 ( and therefore the functions @xmath156 and @xmath157 ) depend on the source distribution @xmath59 . in the case of universal coding",
    ", @xmath164 is independent of the source .",
    "note that for this encoding and decoding functions , = ( x^na)= ( r_x ( x ) ) for all @xmath165 so    p_suc & = & _ x^n p_(x^n ) ( r_x ( x ) ) + & ~ & e^n _ x ( x ) ( r_x ( x ) ) + & & ( rh(p _ ) ) .",
    "[ eq - at - best - q ] eq.([eq - at - best - q ] ) follows because , as is easily proven , applying the method of steepest descent to the p - type integral yields a tilde point :    ( x)=p_(x ) .",
    "as mentioned in the notation section , we define @xmath166 by    r_= .",
    "so far , it s not clear what value to use for the constant @xmath88 that appears in the definition of set @xmath161 . in the next claim , we will show that it must equal @xmath166 for our arguments to be valid .",
    "r = r _ for consistency of our arguments .",
    "we must have    n_&= & _ x^n ( x^na ) + & ~ & e^ n _ x(x ) ( r>_x(x ) ) + & ~ & e^nr e^ n _ x(x ) ( r>_x(x ) ) + & ~ & e^nr(r > h(p _ ) ) .",
    "as long as @xmath167 , our approximations are valid and @xmath168 .",
    "we define a codebook @xmath169 as an @xmath170 matrix given by @xmath171 where @xmath172 for all @xmath173 .",
    "we consider all channel coding protocols that can be described by the following cb net    = + + [ o][f- ] , [ eq - ch - qbnet ] with    p(m ) = ,    p(x^n|m , ) = ( x^n , x^n(m ) ) ,    p(y^n | x^n ) = _ j",
    "p(y_j|x_j ) = e^n_x , y ( x , y)p(y|x ) ,    p()= , and    p(|y^n,)= .",
    "assume that we are given a channel @xmath174 for all @xmath90 .",
    "the encoding @xmath175 and decoding @xmath176 probability distributions are yet to be specified .",
    "it s convenient to define the coding rate @xmath166 by    r_= and the channel capacity @xmath177 by c = _ p _ h ( : ) .",
    "[ cl - ind - bd - mi](independence upper bound for mutual information of dmc ) if @xmath55 ( this is what is called a discrete memoryless channel , dmc ) , then    h(^n:^n)_j=0^n h(_j:_j ) .",
    "furthermore , equality holds iff the @xmath178 are mutually independent .",
    "assume @xmath179 for illustrative purposes .",
    "if the @xmath178 are not independent , we must consider the following cb net    c = + + [ o][f- ]    = \\",
    "{    c = + + [ o][f- ]    . .",
    "[ eq - xj - dependent ] if the @xmath178 are independent , then this becomes    c = + + [ o][f- ]    = \\",
    "{    c = + + [ o][f- ]    .    in the case of eq.([eq - xj - dependent ] ) , h(^n:^n ) & = & h(^n ) - h(^n|^n)= h(^n ) - _ j h(_j|_j ) [ eq - ub - a ] + & & _ j h(_j ) - _ j h(_j|_j ) [ eq - ub - b ] + & = & _ j h(_j:_j ) [ eq - ub - c ] eq.([eq - ub - b ] ) follows from the  subadditivity \" or  independence upper bound \" of the joint entropy , which says that @xmath180 for any random variables @xmath19 and @xmath181 .",
    "( see c&t for a proof of subadditivity ) .",
    "if the @xmath178 are mutually independent , then the @xmath182 must be mutually independent too , in which case eq.([eq - ub - b ] ) becomes an equality .",
    "conversely , if eq.([eq - ub - b ] ) is an equality , then the @xmath182 must be mutually independent so the @xmath178 must be too .",
    "optimality : @xmath183 , if @xmath184 an encoding and a decoding that satisfy @xmath185 for the cb net of eq.([eq - ch - qbnet ] ) , then @xmath186 .",
    "nr_&= & n_= h ( ) = h(^n : ) + h(| ^n ) [ eq - ch - a ] + & & h(^n : ) + n[eq - ch - b ] + & & h(^n : ^n ) + n[eq - ch - c ] + & & _",
    "j=1^n h(_j:_j ) + n[eq - ch - d ] + & & n(c + ) [ eq - ch - e ]    * this follows from fano s inequality .",
    "( see c&t for a proof of fano s inequality . )",
    "@xmath187 is some positive number that tends to zero as @xmath1 * this follows from the data processing inequalities .",
    "( see c&t for a proof of the data processing inequalities . ) * this follows from claim [ cl - ind - bd - mi ] .",
    "* this follows from the definition of channel capacity @xmath177 .",
    "achievability : @xmath183 , if @xmath186 , then @xmath184 an encoding and a decoding that satisfy @xmath185 for the cb net of eq.([eq - ch - qbnet ] ) .",
    "so far , the encoding and decoding probability distributions are unspecified . in this proof , we will use one possible choice for these distributions .",
    "this choice , although not very practical , turns out to yield optimal results . for @xmath175",
    "we choose what is called random coding :    p ( ) = p_(x^n())= _ m p_(x^n(m))= _ m , j p_(x_j(m ) ) for some source @xmath155 .",
    "for @xmath176 we choose a maximum likelihood decoder : we mean @xmath188 . ]",
    "p(|y^n , ) & = & _ m ( r < ) + & = & _ m ( r < ) for some @xmath189 .",
    "note that there is no guarantee that this definition of @xmath176 is a well defined probability distribution satisfying @xmath190 . in the next claim",
    ", we will prove that if @xmath191 , then @xmath176 is well defined .",
    "the probability of error is defined by    p_err = p ( ) .",
    "we find it more convenient to work with the probability of success , which is defined by @xmath160 .",
    "one has    p_suc & = & 1- p_err + & = & p(= ) + & = & _ , m (= m ) p",
    "( , m ) + & = & _ , m , y^n , x^n , ( = m ) p(|y^n , ) p(y^n|x^n ) ( x^n , x^n(m))p(m ) p ( ) + & = & _ _ p ( ) _ y^n p(|y^n , ) p(y^n| x^n ( ) ) .    the choice of @xmath192 does not matter .",
    "any choice would give the same answer for @xmath193 _ _ p ( ) = _ p ( ) = e_. thus    p_suc = e__y^n p(y^n|x^n ( ) ) _ m ( r < ) .[eq - ch - psuc - pre - int_k ]",
    "let    _ k ( ) = _ m \\ { _ -^+ } , [ eq - ch - oint - def ] and    k= _ m k(m ) .    expressing the @xmath194 functions in eq.([eq - ch - psuc - pre - int_k ] ) as integrals ( see eq.([eq - theta - comp - int ] ) ) , we get    p_suc = _ k ( ) e^-ikr _ y^n , x^n ( ) ( n _ ys_,x()s_^n _ ( y , x ( ) ) z(y , x ( ) ) ) , where    z(y , x ( ) ) = p(y|x ( ) ) _ m\\ { p_(x(m ) ) } _ m \\ { } .",
    "next we express the sum over @xmath195 as a p - type integral to get    p_suc = _ k ( ) e^-ikr n^n_+n_n_-1 ( d_[y^n , x^n()])_h=0 e^_0 , [ eq - ch - psuc - pre - p - type - int ] where    _ 0= n _ y , x ( ) ( y , x ( ) ) .",
    "we add to @xmath105 a lagrange multiplier term that constrains the components of the vector @xmath196 so that they sum to one :    = _ = _ 0 + n ( _ y , x ( ) ( y , x ( ) ) -1 ) for any @xmath107",
    ". it s easy to check that @xmath108 is maximized when    ( y , x())= . evaluating the integrand of the p - type integral in eq.([eq - ch - psuc - pre - p - type - int ] ) at this tilde point yields    p_suc = _ k ( ) e^-ikr e^ nz , [ eq - ch - psuc - pre - delta ] where    z = _ y , x()z(y , x ( ) ) . using the shorthand notations    e_y = _ y p(y ) , e_x(m ) = _ x(m ) p_(x(m ) ) , @xmath197 can be expressed as    z= e_y .",
    "[ eq - ch - z - exp ]    define z_0= [ z]_k(m)=0m= e_y e_x()[p^1+i(y : x ( ) ) ] .",
    "[ eq - ch - zo - exp ]    note that 1 equals    1 & = & _ -^+dk ( _ m \\{k(m)}-k ) + & = & _ -^+dk _ -^+ e^ih ( _ m\\{k(m)}-k ) .",
    "[ eq - ch - one - is ] multiplying @xmath193 by 1 certainly does nt change it .",
    "thus the right hand sides of eqs.([eq - ch - psuc - pre - delta ] ) and ( [ eq - ch - one - is ] ) can be multiplied to get    p_suc= _ -^+ _ -^+dk e^ik(-h - r ) _ k ( ) e^ih_mk(m ) e^ nz .",
    "[ eq - ch - pre - km - int ]    next we will assume that , for all @xmath198 , when doing the contour integration over @xmath199 in eq.([eq - ch - pre - km - int ] ) with @xmath197 given by eq.([eq - ch - z - exp ] ) , the @xmath200 can be evaluated at the value @xmath201 of the pole . ] symbolically , this means we assume    _ k ( ) e^ih_mk(m ) e^nz & = & e^nz_0 _ k ( ) e^ih_mk(m ) + & = & e^nz_0 ( h>0 ) .",
    "[ eq - ch - magic - contour - int ] applying eq.([eq - ch - magic - contour - int ] ) to eq.([eq - ch - pre - km - int ] ) gives    p_suc= _ -^+ ( h>0 ) _",
    "e^ik(-h - r ) e^ nz_0 .",
    "[ eq - ch - pre - exp - log ]    next we use eqs.([eq - taylor - one ] ) and ( [ eq - taylor - two ] ) to expand @xmath202 to second order in @xmath203 .",
    "this yields    z_0",
    "i a -b , where    a= h ( : ) , and    b&= & e_y e_x p(y : x)^2p(y : x ) -h^2 ( : ) + & = & e_y , x ^2 p(y : x ) - [ e_y , xp(y : x)]^2 + & & 0 ( the inequality follows from the identity @xmath204 where @xmath205 denotes an average and @xmath42 is any random variable . )    with the @xmath202 expanded to second order in @xmath203 , eq.([eq - ch - pre - exp - log ] ) becomes    p_suc= _ -^+ ( h>0 ) _ -^+dk e^ik(a - h - r ) -b . if we keep only the term linear in @xmath203 in the argument of the exponential , we immediately get    p_suc= ( r < h ( : ) ) .",
    "[ eq - ch - pre - c - limit ] if we also keep the term quadratic in @xmath203 , we get    p_suc = ( [ r - h ( : ) ] ) .    maximizing both sides of eq.([eq - ch - pre - c - limit ] ) with respect to the source @xmath59 , and using the definition of channel capacity @xmath177",
    ", we get that there is an encoding and a decoding for which    p_suc= ( r < c ) .",
    "[ cl - ch - r - is - rm ] r = r _ for consistency of our arguments .    rather than checking",
    "that @xmath206 , we will check that the total probability distribution for the whole cb net eq.([eq - ch - qbnet ] ) sums to one .",
    "we want    1 = _ , m , y^n , x^n , p(|y^n , ) p(y^n|x^n ) ( x^n , x^n(m))p(m ) p ( ) . using    _ , m = _ , m (= m ) + _ , m ( m ) , and    _ , m ( m ) p(m)_p()= _ p()n_e _ , we get for any pair @xmath207 such that @xmath208 ,    1 = p_suc + n_e _ _ y^n p(|y^n , ) p(y^n|x^n(m_0 ) ) . [ eq - no - dist -",
    "one - is - nm ] substituting into eq.([eq - no - dist - one - is - nm ] ) the specific values of the probability distributions @xmath209 and @xmath210 , we get    p_err = n__-^+ _ -^+dk e^ik(-h - r ) _ k ( ) e^ih_mk(m ) e^ nw , [ eq - ch - pre - w - to - wo ] where @xmath211 is defined as before ( see eq.([eq - ch - oint - def ] ) ) and where    w= e_y .",
    "[ eq - ch - w - def ]    let w_0 = [ w]_k(m)=0m= e_y e_x()[p^i(y : x ( ) ) ] .",
    "[ eq - ch - wo - def ]    next assume that _ k ( ) e^ih_mk(m ) e^nw & = & e^nw_0 _ k ( ) e^ih_mk(m ) + & = & e^nw_0 ( h>0 ) .",
    "[ eq - ch - w - to - wo ] applying eq.([eq - ch - w - to - wo ] ) to eq.([eq - ch - pre - w - to - wo ] ) yields    p_err = n__-^+ ( h>0 ) _ -^+dk e^ik(-h - r ) e^ nw_0 .",
    "[ eq - ch - wo - pre - shift ]    now we can make the following change of variables    kk -in .",
    "note that this change of variables changes @xmath212 defined by eq.([eq - ch - wo - def ] ) to @xmath213 defined by eq.([eq - ch - zo - exp ] ) . under this change of variables , eq.([eq - ch - wo - pre - shift ] ) becomes    p_err & = & n__-^+ ( h>0 ) e^n(-h - r ) _",
    "-^+dk e^ik(-h - r ) e^ nz_0   + & & n_e^-nr p_suc , or , equivalently ,    ( r > h(:))n_e^-nr(r < h ( : ) ) .",
    "thus , when @xmath88 equals ( or is very close to ) @xmath214 , we must have @xmath168 .",
    "assume that we are given a function @xmath215 that measures the distance between two letters of @xmath216 .",
    "assume @xmath217 and @xmath218 for all @xmath216 .",
    "assume that random variables @xmath42 and @xmath219 both have the same set of possible values @xmath220 .",
    "we define codebook @xmath169 as an @xmath170 matrix given by @xmath171 where @xmath172 for all @xmath173 .",
    "we define another codebook @xmath221 as an @xmath170 matrix given by @xmath222 where @xmath223 for all @xmath173 .",
    "we consider all source coding protocols that can be described by the following cb net :    = + + [ o][f- ] [ eq - dist - qbnet ] with @xmath154 and    p(x^n ) = _ j=1^n",
    "p_(x_j ) , p(m|x^n,)= ,    p()= ,    p(|)= _ m p_|(^n(m)|x^n(m ) ) = _ m , j p_|(_j(m)|x_j(m ) ) , and    p(^n|m , ) = ( ^n , ^n(m ) ) .",
    "assume that we are given a source @xmath224 and a channel @xmath225 for all @xmath90 .",
    "the encoding @xmath226 and decoding @xmath175 probability distributions are yet to be specified .    henceforth , we will use the following shorthand notations e_j= _ j=1^n , e_,x=_,x p_|(| x ) p_(x ) .    as usual",
    ", we define the * rate of * @xmath227 by @xmath228 .",
    "we define the probability of success by p_suc = p [ e_j d(_j , _ j)d ] [ eq - def - of - d ] where @xmath229 is called the * distortion*. note that when @xmath230 , @xmath231 , which is what we used previously when we considered source coding without distortion .    for any source @xmath59 and distortion @xmath232 , it is useful to define a * rate distortion function * @xmath233 by    h_(d)= _ p_| : e_,x d(,x ) < dh_p_| p _ ( : ) .    [ cl - props - rat - dis ] ( properties of @xmath233 )    * @xmath233 is a monotonically non - increasing , convex function of @xmath232 . * @xmath234 * @xmath235 , where @xmath236 , where @xmath237 such that @xmath238 for all @xmath95 .    proof of @xmath239 : monotonicity is obvious . to prove convexity , recall ( see c&t for a proof ) that the mutual information is a convex function of its joint probability .",
    "this means that for any @xmath240 $ ] and @xmath241 , if    p_(,x ) = p_1(,x ) + ( 1-)p_0(,x ) [ eq - p - lam - def ] for all @xmath242 , then    h_p _ ( : ) h_p_1 ( : ) + ( 1-)h_p_0 ( : ) .    for any @xmath243 $ ] , let @xmath244 and    d_= d_1 + ( 1-)d_0 .",
    "suppose @xmath245 such that @xmath246 for all @xmath95 and    h_(d_j)= h_p_j ( : ) for @xmath247 .",
    "define @xmath248 by eq.([eq - p - lam - def ] ) .",
    "then    h_(d _ ) & & h_p _ ( : ) + & & h_p_1 ( : ) + ( 1-)h_p_0 ( : ) + & = & h_(d_1 ) + ( 1-)h_(d_0 ) .",
    "proof of @xmath249 : if @xmath230 , then @xmath250 so @xmath251",
    ".    proof of @xmath252 : this follows from definition of @xmath233 .",
    "optimality : @xmath253 , if @xmath184 an encoding and a decoding that satisfy @xmath185 for the cb net of eq.([eq - dist - qbnet ] ) , then @xmath254 .",
    "nr_&= & n_= h ( ) = h(^n : ) + h(|^n ) [ eq - dis - a ] + & & h(^n : ) [ eq - dis - b ] + & & h(^n:^n ) [ eq - dis - c ] + & = & _ j h(_j : _",
    "j ) [ eq - dis - d ] + & & _ j h _ ( e__j , x_jd(_j , x_j ) ) [ eq - dis - e ] + & & n h _",
    "( _ j e__j , x_jd(_j , x_j ) ) [ eq - dis - f ] + & = & n h _ ( e_,xd(,x ) ) [ eq - dis - g ] + & & nh_(d ) [ eq - dis - h ]    * this follows from the data processing inequalities .",
    "( see c&t for a proof of the data processing inequalities . ) * this follows from claim [ cl - ind - bd - mi ] in the case of equality .",
    "we are assuming that @xmath255 is a dmc , and that @xmath175 is an i.i.d .",
    "this forces @xmath256 and @xmath257 with @xmath258 to be independent .",
    "* this follows from claim [ cl - props - rat - dis ] , part ( c ) .",
    "* this follows because @xmath233 is a convex function of @xmath232 .",
    "* this follows from using @xmath259 .",
    "* eq.([eq - def - of - d ] ) is the definition of @xmath232 . expressing eq.([eq - def - of - d ] ) in terms of p - types and using @xmath259 , we find that @xmath260 is necessary for success .",
    "then use the fact that @xmath233 is non - increasing .",
    "achievability : @xmath253 , if @xmath254 , then @xmath184 an encoding and a decoding that satisfy @xmath185 for the cb net of eq.([eq - dist - qbnet ] ) .",
    "so far , the encoding and decoding probability distributions are unspecified . in this proof , we will use one possible choice for these distributions . for decoder @xmath175",
    "we choose :    p ( ) = p_(x^n ( ) ) = _ m \\ { p_(x^n(m ) ) } = _ m , j \\ { p_(x_j(m ) ) } , and for encoder @xmath261 we choose :    p(m|x^n , ) & = & _ mm ( r > ) + & = & _ mm ( r > ) [ eq - dist - pm ] for some @xmath189 .",
    "note that there is no guarantee that this definition of @xmath261 is a well defined probability distribution satisfying @xmath262 . in the next claim",
    ", we will prove that if @xmath191 , then @xmath261 is well defined .",
    "( ) = _ p(|)p ( ) .    one has p_suc",
    "& = & p [ e_j d(_j , _ j)<d ]",
    "+ & = & _ ^n , x^n p(^n , x^n ) ( e_j d(_j , x_j)<d ) + & = & _ ^n , x^n , m , p(^n|m , ) p(m|x^n , ) p(x^n)p ( ) ( e_j d(_j , x_j)<d ) + & = & _ m e _ e_x^n p(m|x^n , ) ( e_j d(_j(m ) , x_j)<d ) .",
    "[ eq - dist - pre - m - is - one ]    consider what happens to @xmath261 in eq.([eq - dist - pre - m - is - one ] ) as @xmath263 .",
    "when @xmath263 , @xmath264 by virtue of eq.([eq - dist - pre - m - is - one ] ) .",
    "hence @xmath265 .",
    "furthermore , @xmath266 .",
    "thus    p(m|x^n , ) ( r > ) = ( x^na_p _ ) . hence ,",
    "when @xmath230 , the encoder @xmath261 in eq.([eq - dist - pre - m - is - one ] ) is the same as the one we used when we considered source coding without distortion .    for any @xmath267 such that @xmath238 for all @xmath95 , define _",
    "q(,x ) = _ q _ , = ( _ , xq(,x)d(,x)<d ) .",
    "note that    ( e_j d(_j(1 ) , x_j)<d ) = _ ( ( 1 ) , x ) .",
    "[ eq - theta - j - to - ptype ]    note that _",
    "m e_= n_e _ .",
    "hence , the choice of @xmath173 in eq.([eq - dist - pre - m - is - one ] ) does not matter .",
    "any choice would give the same answer for @xmath193 .",
    "thus , eq.([eq - dist - pre - m - is - one ] ) can be replaced by the following .",
    "assume @xmath268 and replace @xmath198 by 1 and @xmath269 by @xmath198 .",
    "also use eq.([eq - theta - j - to - ptype ] )",
    ". then    p_suc&= & n_e _ e_x^n _ m1 \\ { ( r > ) } _ ( ( 1 ) , x ) .",
    "[ eq - dist - psuc - pre - int_k ]    if we assume that our formalism will eventually justify the physically plausible assumption that @xmath270 , then we may replace @xmath271 by @xmath272 at this point .",
    "this would simplify the analysis below .",
    "instead , we will continue with @xmath271 and show that our formalism does indeed lead to the same result as if we had replaced @xmath271 by @xmath272 at this point .",
    "let _ k ( ) = _ m1 \\ { _ -^+ } , and    k= _ m1 k(m ) .    expressing the @xmath194 functions in eq.([eq - dist - psuc - pre - int_k ] ) as integrals",
    "( see eq.([eq - theta - comp - int ] ) ) , we get    p_suc = n__k ( ) e^ikr _ ^n ( ) , x^n ( n _ ( ) s_^n _ , xs _ ( ( ) , x ) z ( ( ) , x ) ) _ ( ( 1 ) , x ) , where    z ( ( ) , x ) = p(x ) _ m\\ { p((m ) ) } _ m1 \\ { } .",
    "next we express the sum over @xmath273 as a p - type integral to get    p_suc = n__k ( ) e^ikr n^n_(n_+1)-1 ( d_[^n ( ) , x^n])_h=0 e^_0 _ ( ( 1 ) , x ) , [ eq - dist - psuc - pre - doing - p - type - int ] where    _ 0=",
    "n _ ( ) , x ( ( ) , x ) .",
    "we add to @xmath105 a lagrange multiplier term that constrains the components of the vector @xmath274 so that they sum to one :    = _ = _ 0 + n ( _ ( ) , x ( ( ) , x ) -1 ) for any @xmath107 .",
    "it s easy to check that @xmath108 is maximized when    ( ( ) , x)= .",
    "evaluating the integrand of the p - type integral in eq.([eq - dist - psuc - pre - doing - p - type - int ] ) at this tilde point yields    p_suc = n__k ( ) e^ikr e^ nz _ ( ( 1 ) , x ) [ eq - dist - psuc - pre - delta ] where    z = _ ( ) , xz ( ( ) , x ) .",
    "@xmath197 can be expressed as    z= e_x .",
    "[ eq - dist - z - exp ]    define    z_0= [ z]_k(m)=0 m = e_x e_(1)[p^-i((1):x ) ] .",
    "[ eq - dist - zo - exp ]    note that 1 equals    1 & = & _ -^+dk ( _ m1 \\{k(m)}-k ) + & = & _ -^+dk _ -^+ e^ih ( _ m1\\{k(m)}-k ) .",
    "[ eq - dist - one - is ] multiplying @xmath193 by 1 certainly does nt change it .",
    "thus the right hand sides of eqs.([eq - dist - psuc - pre - delta ] ) and ( [ eq - dist - one - is ] ) can be multiplied to get    p_suc= n__-^+ _",
    "-^+dk e^ik(-h+r ) _ k ( ) e^ih_m1k(m ) e^ nz _ ( ( 1 ) , x ) .",
    "[ eq - dist - pre - km - int ] next we will assume that , for all @xmath198 , when doing the contour integration over @xmath199 in eq.([eq - dist - pre - km - int ] ) with @xmath197 given by eq.([eq - dist - z - exp ] ) , the @xmath275 can be evaluated at the value @xmath201 of the pole .",
    "] symbolically , this means we assume    _ k ( ) e^ih_m1k(m ) e^nz _ ( ( 1 ) , x ) & = & e^nz_0 _",
    "p^-i((1 ) , x ) _ k ( ) e^ih_m1k(m ) + & = & e^nz_0 _",
    "p^-i((1 ) , x ) ( h>0 ) .",
    "[ eq - dist - magic - contour - int ] applying eq.([eq - dist - magic - contour - int ] ) to eq.([eq - dist - pre - km - int ] ) gives    p_suc= n__-^+ ( h>0 ) _",
    "-^+dk e^ik(-h+r ) e^ nz_0 _",
    "p^-i((1 ) , x ) .",
    "[ eq - dist - post - km - int ]    next we make the following change of variables :    kk + in .",
    "let    w_0= [ z_0]_kk + in = e_x e_(1)[p^1-i((1):x ) ] .",
    "[ eq - dist - wo - exp ] under this change of variables , eq.([eq - dist - post - km - int ] ) becomes    p_suc= n__-^+ ( h>0 ) e^-n(-h+r ) _",
    "-^+dk e^ik(-h+r ) e^ nw_0 _",
    "p^1-i((1 ) , x ) .",
    "[ eq - dist - pre - exp - log ]    next we use eqs.([eq - taylor - one ] ) and ( [ eq - taylor - two ] ) to expand @xmath276 to second order in @xmath203 .",
    "this yields    w_0 -i a -b , where    a= h ( : ) , and    b&= & e _",
    "e_x p(:x)^2p(:x ) -h^2 ( : ) + & = & e_,x ^2 p(:x ) - [ e_,xp(:x)]^2 + & & 0 .    with the @xmath276",
    "expanded to second order in @xmath203 , and @xmath277 to zeroth order in @xmath203 , eq.([eq - dist - pre - exp - log ] ) becomes    p_suc= _ p _ , n__-^+ ( h>0 ) e^n(h - r ) _ -^+dk e^ik(-a - h+r ) -b .",
    "if we keep only the term linear in @xmath203 in the argument of the exponential , we immediately get    p_suc_p _ , n_e^-na(r > a ) n_e^-nr ( r > h ( : ) ) .",
    "[ eq - dist - pre - rate - dist - lim ]    minimizing both sides of eq.([eq - dist - pre - rate - dist - lim ] ) with respect to the channel @xmath278 and using the definition of the rate distortion function @xmath233 , we get that there is an encoding and a decoding for which    p_suc= n_e^-nr(r > h_(d ) ) .",
    "[ eq - dist - post - rate - dist - lim ]    r = r _ for consistency of our arguments .    for consistency , must have @xmath279 in eq.([eq - dist - post - rate - dist - lim ] ) .",
    "this appendix is a collection of integration formulas for doing integrals over polytope shaped regions .",
    "these formulas are useful for doing p - type integrations .                in sit , when doing p - type integrals for large @xmath0 , one often encounters integrals of sharply peaked gaussian functions integrated over polytope regions .",
    "since the gaussians are sharply peaked , as long as their peak is not near the boundary of the polytope region , the integrals can be easily evaluated approximately in a gaussian approximation which becomes increasingly accurate as @xmath0 increases .",
    "suppose @xmath286 , @xmath287 , and @xmath288 for all @xmath90",
    ". then p _ ( -_x_x(p_x)^2 ) , [ eq - p - type - int - over - gauss ] where @xmath289 .",
    "( if the @xmath290 are thought of as electrical resistances connected in parallel , then @xmath291 is the equivalent resistance . )",
    "when using many of the integration formulas presented in this appendix , it is necessary to calculate the inverse and determinant of a large matrix .",
    "i found the following formulas can often be helpful in doing this .              to prove eq.([eq - det - o - sum ] )",
    ", one may proceed as follows .",
    "we will assume @xmath308 for concreteness .",
    "the proof we will give generalizes easily to @xmath161 s of dimension different from 3 .",
    "let @xmath309 be the totally antisymmetric tensor with 3 indices .",
    "we will use einstein summation convention . let"
  ],
  "abstract_text": [
    "<S> this paper begins with a discussion of integration over probability types ( p - types ) . after doing that , the paper re - visits 3 mainstay problems of classical ( non - quantum ) shannon information theory ( sit ) : source coding without distortion , channel coding , and source coding with distortion . </S>",
    "<S> the paper proves well - known , conventional results for each of these 3 problems . </S>",
    "<S> however , the proofs given for these results are not conventional . </S>",
    "<S> they are based on complex integration techniques ( approximations obtained by applying the method of steepest descent to p - type integrals ) instead of the usual delta & epsilon and typical sequences arguments . </S>",
    "<S> another unconventional feature of this paper is that we make ample use of classical bayesian networks ( cb nets ) . </S>",
    "<S> this paper showcases some of the benefits of using cb nets to do classical sit . </S>"
  ]
}