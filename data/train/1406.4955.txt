{
  "article_text": [
    "belle  ii experiment is a @xmath0-factory experiment currently being set up at the site of the high energy accelerator research organization ( kek ) in tsukuba , japan , and will take its first physics data in 2016 .",
    "it will exploit the unprecedented luminosity ( @xmath1 ) of the superkekb accelerator , a fifty - fold increase over the predecessor kekb .",
    "the belle  ii experiment will collect a data set of exclusive @xmath2 events that is two orders of magnitude larger than that of the predecessor experiments babar and belle  @xcite .    for many existing studies from @xmath0-factories , larger data sets are desirable .",
    "collecting the huge amount of data required for precision physics poses a number of challenges that must be overcome in the experiment .",
    "first , the accelerator needs to reliably provide high instantaneous luminosity .",
    "the concurrent increase in physics data leads to a similar increase in the amount of data read out , subject to specific choices of triggers .",
    "the increase in luminosity is achieved on the one hand by roughly doubling the beam currents , on the other hand by a novel nano - beam scheme which leads to a beam size of order @xmath3 at the interaction point .",
    "the increased beam current and the more delicate optics lead to increased background levels in the detectors which are situated close to the beam line , the second challenge .",
    "these have to be dealt with at the high trigger rates foreseen .",
    "implemenation of the nano - beam scheme requires a reduced center - of - mass boost compared to the previous @xmath0 factory experiments  @xcite . in order to compensate the thus reduced spatial separation of the @xmath0-decay vertices ,",
    "the vertex detector is placed very close to the interaction point , again leading to increased background levels .",
    "the vertex detector ( vxd ) is composed of six layers of semiconductor detectors arranged on concentrical cylinders around the beam pipe .",
    "the two innermost layers ( pxd ) of the vxd consist of depfet - type pixel sensors  @xcite , situated at radii of @xmath4 and @xmath5 from the beam line , respectively . the outer four layers ( svd ) consist of double - sided silicon strip detectors  @xcite , situated at radii ranging from @xmath6 to @xmath7 from the beam line . in order to cover the full polar angular range of the remainder of the experiment , @xmath8 ,",
    "while significantly reducing the necessary amount of silicon , the three outermost layers employ a wedged geometry , where the part of the detector in the boost direction is angled towards the beam line .",
    "the vxd is surrounded by a large drift chamber ( cdc ) used for precise momentum determination of charged particle tracks and particle identification by energy loss measurements .",
    "further detectors for particle identification and neutral particle detection surround this ensemble of tracking detectors  @xcite .",
    "the layout of the vxd is shown in figs .",
    "[ fig : vxd - layout ] and  [ fig : vxd - layout-3d ] .            due to the proximity of the vxd , and especially the pxd , to the beam line",
    ", sophisticated background rejection has to be employed . given the expected average occupancy of the pxd of 3% , the amount of data would be overwhelming , exceeding 20 gb / s of raw pixel data , or roughly ten times the amount of data recorded by the remainder of the experiment .",
    "background suppression therefore has to take place before storing data to disk .",
    "additionally , the pxd is read out in frames with an integration time of @xmath9 .",
    "this is only a factor 5 below the average spacing of two triggered events at the expected trigger rate of @xmath10  @xcite .",
    "therefore , a single read - out frame can contain hits from more than one triggered event .",
    "these have to be correctly associated to the respective events .    in order to achieve these objectives ,",
    "the high - level trigger ( hlt ) of belle  ii performs online track finding and fitting in the svd and the cdc on standard linux pcs using the same software as in the offline processing .",
    "the hlt extrapolates the resulting tracks back to the pxd , and defines regions - of - interest ( rois ) based on the intersections of these tracks with the pxd surfaces .",
    "data contained in these rois is then read out and stored for offline processing . in parallel",
    ", the data - merging hardware performs track - reconstruction and roi definition in an fpga - based approach , which is developed as a fallback in case implementation of the hlt approach should not work out . for the final experiment , this approach will reduce the amount of recorded pxd data twenty - fold .    in this contribution",
    "we discuss the design and implementation of the software used in the online reconstruction of the hlt system and the results we obtained in a test beam experiment which took place in january of 2014 .",
    "a sector of the vxd was exposed to an electron beam at desy , and for the first time the whole system of pxd and svd was successfully integrated with the belle  ii daq system .",
    "the processing chain including the above - mentioned online reconstruction could be established during the test beam experiment .",
    "additionally , the detector was operated in a cooled environment , and slow control was handled with the slow control system foreseen for the final experiment .",
    "a number of other contributions at this conference dealt with other parts of the belle  ii daq .",
    "the global picture of the belle  ii daq system is given in s.  yamada s contribution os  1 - 1 ; the onsen system is discussed in more detail in t.  geler s contribution ps  3 - 1  @xcite ; the event - building process is explained in s.y .",
    "suzuki s contribution ps  3 - 56 ; the design and implementation of the digitization and readout hardware of the pxd is detailed in d.  levit s contribution ps  3 - 20  @xcite ; r.  itoh s contribution pfs  2 discusses more of the data processing .",
    "the demonstrator was operated in an electron beam at desy .",
    "the average beam momentum was in the @xmath11 range with a typical beam rate of a few khz .",
    "the beam passed through the coil of a solenoid magnet ( 1 t ) inside of which the detector assembly was installed .",
    "bremsstrahlung processes in the magnet coil lead to a broad momentum distribution of the particles entering the detector volume . a side view illustrating the detector positions and dimensions is shown in fig .  [ fig : setup ] .",
    "unlike the full vxd setup , only one pxd layer ( corresponding to pxd2 in the figure ) was installed .",
    "it contains a matrix of @xmath12 pixels of @xmath13 each and is thinned down to @xmath14 in the active area . as in the final experiment , the long side is parallel to the magnetic field , the bending direction is along the short side .",
    "digitization and readout asics are as close as possible to the final specifications for the belle  ii experiment , but in the final experiment the detectors will be @xmath15 thick . a second sensor of the final specifications could not be prepared in time . nevertheless , this setup allowed exercising the complete readout and processing chain with real data .",
    "downstream of the pxd layers , four svd layers were installed .",
    "the first layer had an active area of @xmath16 and a thickness of @xmath17 .",
    "the detector had @xmath18 strips , with pitches of @xmath19 and @xmath15 respectively .",
    "it was oriented in the same manner as the pxd layer .",
    "the other three svd layers had the same specifications , but @xmath20 strips and a corresponding active area of @xmath21 .",
    "the svd layers employed were previously subjected to tests of radiation hardness .",
    "this lead to localized hot areas which were masked during clusterization .",
    "the vxd assembly was contained inside a dry volume cooled with co@xmath22 .",
    "cooling as well as detector slow control was using the final belle  ii software .",
    "the cold volume is placed between the two arms of the eudet beam telescope  @xcite provided by the test beam facility .",
    "it was used for alignment purposes and efficiency studies .",
    "the system was triggered by a coincidence between two pairs of scintillators placed in front and behind the assembly , respectively .",
    "the telescope data was recorded along a separate data path and merged offline .",
    "the readout architecture is displayed in fig .",
    "[ fig : daq ] .",
    "we highlight a few details in the following .",
    "once the trigger logic unit ( tlu ) finds a coincidence between the scintillators , it assigns an event number and sends it together with a trigger signal to the telescope readout ( bottom left ) and the frontend timing switch ( ftsw ) .",
    "the ftsw is part of the pocket daq ( top left ) , a scaled down version of the common daq used by all belle  ii detectors save the pxd .",
    "once the pocket daq has collected the data and an event is built , it sends the data to the high level trigger ( hlt , top right ) whose operation will be discussed in detail below . the pxd readout ( middle left )",
    "is also initiated by the ftsw . upon receiving a trigger from the ftsw , the dhhc asic forwards data integrated by the pxd to the online selector node ( onsen ) , a buffer which has sufficient memory to store several seconds of data under typical conditions in the belle  ii experiment .",
    "the onsen system buffers the pxd data until the hlt ( discussed below ) or an fpga - based tracking implemented in the svd readout hardware ( not depicted ) finish calculating regions of interest ( rois ) , i.e. parts of the detector where tracks are expected to intersect the pxd .",
    "once the onsen system receives the list of rois for an event , it forwards the corresponding pixel data to the second event builder ( bottom right ) which merges the pxd data with the events received from the hlt .",
    "the data is then stored to disk . additionally , a fraction of events is forwarded to the expressreco , a fast reconstruction with the purpose of data quality inspection .",
    "this operation matches the data paths foreseen for the belle  ii experiment .",
    "in the test beam experiment , the following requirements had to be met by the hlt software :    1 .",
    "reading of detector data formats ; 2 .",
    "efficient track finding and fitting ; 3 .",
    "extrapolation of tracks to pxd planes ; 4 .",
    "definition of rois ; 5 .",
    "successful communication of rois to the onsen systems .",
    "it was thus a critical part of the test of the complete data - handling scheme .",
    "the hlt system consisted of five computing nodes in total .",
    "two twelve - core systems ( hltin and hltout ) handled the event - wise data distribution to the hlt worker nodes ( hltwn1 - 3 ) which were 24-core systems .",
    "the data distribution and processing was implemented in the belle  ii software framework , basf2  @xcite .",
    "this framework has a modular architecture , where individual data processing steps are implemented in a chain of independent modules .",
    "the means of communication between the modules is the so - called datastore , which consists of named and typed arrays where modules can read and write data .",
    "subsequent processing steps can read the datastore arrays provided by previous steps .",
    "the implementation is such that the datastore can be streamed to and from disk or over the network at any point in the processing chain . this way , processing tasks can be distributed over a network of computers or multiple processor cores with no further requirements on the implementation of individual steps . in the hlt in particular these facilities",
    "are used to distribute the processing of the individual events over the hlt network while concentrating communication tasks on separated nodes ( hltin and hltout in fig .",
    "[ fig : daq ] ) .",
    "common configuration data such as the detector geometry is held in a database , which was implemented by xml files during the test beam .",
    "the software employed on the hlt is the same software as is used for offline reconstruction .",
    "indeed , all software used during the testbeam were the then - current versions of the software for the belle  ii experiment .",
    "the hlt implementation in the test beam consisted of the following processing chain on each worker node ( fig .",
    "[ fig : dataflow ] ) : an unpacker for the svd data format converts the raw data to digits .",
    "it takes care of the conversion of channel numbers to row and column numbers and it also masks hot areas of the detectors . in the next step ,",
    "the digits are processed by clusterization algorithms .",
    "these combine the digits into clusters , evaluating the actual hit position while taking into account lorentz corrections to electron drift in the presence of a magnetic field .",
    "the clusters form the actual input for the track finder , discussed below .",
    "the track finder outputs track candidates which in turn are processed with a kalman fitter ( discussed below ) .",
    "finally the pxd interceptor module uses the fitted tracks to define the rois on the pxd . at this point the processed events is forwarded to the hltout node .",
    "it runs the roi sender module which takes care of the communication of the hlt with the onsen system .",
    "tracks are found in the svd by a cellular automaton ( ca ,  @xcite ) .",
    "the combinatorial problem of clustering hits to track candidates is mitigated by sequentially applied filters with increasing complexity .",
    "the cells of the ca are track segments that connect two hits in adjacent layers . in order to reduce the number of cells , only compatible hits are combined to cells ; this is the first filter stage .",
    "the compatibility of a pair of hits is determined by a look - up table , called the sector map , which is created by simulating a large number of tracks in the svd .",
    "two sector maps were used in the test beam experiment , one with and one without magnetic field .",
    "cells sharing a hit are defined to be neighbors if they fulfill certain geometrical requirements , for instance a cut on the angle between the cells ; this is the second filter stage .",
    "the appropriate cut values are again obtained from the sector map . in the ca , each cell is assigned a discrete state that is zero at the start and evolves in discrete time steps by checking the local neighborhood .",
    "more precisely , the state of a cell is incremented whenever it has a neighbor with the same state situated upstream .",
    "the final state of a cell is thus equal to its position along a chain of neighboring cells .",
    "track candidates ( tcs ) are collected by starting from the cells with the highest states and following the chain towards the origin of the track .",
    "the resulting tcs may still share hits .",
    "for each of them , a quality indicator ( qi ) is computed by a fast circle fit in the bending plane . the final best set of non - overlapping tcs",
    "is found by a hopfield network that uses the qis ; this is the third filter stage .",
    "it is possible to iterate the track finder by using several sector maps corresponding to several momentum ranges . in each iteration only tcs in a certain momentum range are found ; the hits of high - quality tcs are removed from the pool of available hits and are not used in the following iteration .",
    "this feature was , however , not enabled in the test beam experiment .    to determine the performance of the ca - tf",
    ", the data were scanned for events where the following condition was met :    * there was at least one hit loosely correlating with neighboring layers for the three upstream telescope layers , the pxd and the svd .",
    "the three downstream telescope layers had to provide an additional correlation .",
    "the surviving events were used for finding track candidates by creating all possible hit combinations and fitting the result .    only the best fit of an event was stored and used as the referencetc to measure the performance of the ca - tf . since the combinatorial problem of combining at least 8 + 3 layers is very severe , the fit procedure was aborted if it took too long .",
    "therefore not all events fulfilling the conditions mentioned above provided reference tcs . as a consequence , events with many hits did not give a reference tc , although the ca - tf did .",
    "a straightforward definition of efficiency  like the sum of the diagonal elements divided by the sum of all elements  is misleading , therefore a closer look is necessary . it should be kept in mind that for the purposes of the hlt , the ca - tf uses only hits in the svd to find track candidates .",
    "for a given run , a contingency table as shown in table  [ tab : contingency ] can be created .",
    "the sum @xmath23 of all elements in the table is equal to the number of events in the run .",
    "the table can be used to define a measure of efficiency of the ca - tf .",
    ".contingency table .",
    "[ cols=\"^,^,^\",options=\"header \" , ]     the frequency distributions of the average number of hits per layer in the svd are shown in figs .",
    "[ fig : clustermultiplicity470 ] and  [ fig : clustermultiplicity510 ] for runs 470 and 510 , respectively .",
    "taking the average over the layers as a rough benchmark , run 470 with magnet off provided an average number of about 1100 possible hit combinations per event .",
    "many secondary particles produce a high rate of ghost hits .",
    "this background is a good test for high track multiplicity .",
    "run 510 with magnet on provided an average number of only 32 possible combinations per event .",
    "this has a major impact on the execution time per event . during the beam test a maximum trigger rate of about 1khz limited the total time budget at the hlt demonstrator to about 40ms . to prevent bottle - necks for other processing steps such as track fitting and roi finding",
    ", the tf should use only 10% of the given budget , or @xmath24 .         magnetic field ) . ]        the speed of the ca - tf is mainly limited by the total number of _ accepted _ hit combinations per event , i.e. , the ones that are used as cells in the ca . to test the behavior of the ca - tf",
    "the chosen runs were analyzed with the following thresholds on the number of cells : 1250 , 1000 , 750 , 500 , 250 , 125 , 65 .",
    "events exceeding the threshold are skipped . in fig .",
    "[ fig : speedefficiency ] , the performance of the ca - tf is plotted as function of execution time per event for both runs . using the highest threshold results in the best efficiencies but requires the longest execution time per event .",
    "while run 510 can be analyzed with the highest threshold within the timing constraints , for run 470 the limit should be set to about 1000 in order to stay below the limit of 4ms . in both runs the ca - tf found tcs much more often than the reference , which can be partially explained by the terminating condition for high occupancy cases with the reference procedure . in the run with activated magnetic field the effect of high occupancy",
    "is less dominating .",
    "much fewer reference tcs were generated because the downstream telescope sensors ( not required by the ca - tf ) were not hit by particles that lost a significant fraction of their momentum before entering the detector volume ( see fig .",
    "[ fig : mom - spectra ] ) .",
    "the hit combinations together with an initial momentum estimate are stored as track candidates .",
    "these are then processed with a version of the genfit track fitting software  @xcite .",
    "this track fitting package has been largely overhauled to meet the requirements of the belle  ii experiment.genfit implements a flexible framework for the modelling , extrapolating and fitting of charged - particle trajectories in complex detector environments .",
    "for the purposes of definition of rois , the track candidates are fitted with the standard kalman fitter algorithm  @xcite . for the purposes of detector alignment the generalized broken lines ( gbl )  @xcite algorithm",
    "is employed offline .",
    "another track fitting algorithm implemented in genfit is the deterministic annealing filter .",
    "this is the standard algorithm used in belle  ii .",
    "the average time for the fit of a single track in the current experimental setup was @xmath25 on a typical laptop .",
    "computing time requirements of the hlt were thus easily fulfilled . in fig .",
    "[ fig : mom - spectra ] reconstructed momentum spectra for runs with three different beam momentum settings are shown .",
    "once tracks are fitted based on hits in the svd planes , the definition of the regions of interest ( rois ) takes place .",
    "these are defined by areas on the pxd planes which are likely to have been crossed by the fitted tracks .",
    "once the rois are determined by the hlt , they are forwarded to the online selector node system ( onsen ) which holds the pxd data until requested , and the onsen system in turn forwards the pxd data contained within the rois to the second event builder ( evb2 ) . here",
    "the pixel data is merged with the svd data ( and the data from the other detectors in the full experiment ) in order to assemble the complete events which are then stored to disk .",
    "the rois are found by the following procedure :    1 .",
    "find intercepts of all fitted tracks with the pxd planes .",
    "2 .   define rectangular arrays of pixels surrounding the intercept .",
    "the size of the array is determined by both the extrapolation errors and an allowance for systematic errors such as misalignment .",
    "a high efficiency of the roi determination is observed , leading to a more than twenty - fold reduction of the amount of pxd data .",
    "communication of the rois to the onsen system could be established , both transferring artificial rois ( full detector plane , patterns ) and real rois determined in the above manner .",
    "the procedure is illustrated for an example event in fig .",
    "[ fig : roi ] . a distribution of two - dimensional offsets between the measured pixel hits and the calculated intercepts is shown in fig .",
    "[ fig:2d - resid - lego ] .",
    "test beam events .",
    "the bins match the pxd pixels .",
    "a gaussian fit estimates the width of the central peak as @xmath26 and @xmath27 in the @xmath28 and @xmath29 directions , respectively . here",
    "@xmath29 denotes the bending direction . ]      for the purpose of alignment of the detector setup , the default alignment procedure developed for the belle  ii vertex detector was applied .",
    "the procedure is fully integrated into the belle  ii software and utilizes the millepede ii algorithm described in ref .",
    "data for millepede  ii are prepared by a refit of reference tracks ( provided by the track finder ) using the implementation of the general broken lines ( gbl ) algorithm  @xcite in the genfit package . in gbl , multiple scattering",
    "is taken into account representing thick scatterers by two equivalent thin scatterers at detector planes and in between .",
    "the alignment procedure is successfully applied for data obtained with and without magnetic field .",
    "alignment corrections determined for sensor displacements and rotations in their planes have typical uncertainties below @xmath30 / @xmath31 and differ usually by less than @xmath32 / @xmath33 from the nominal geometry .",
    "the only exception is the pxd sensor shifted by about 5 mm . as an example , in fig .",
    "[ fig : alignment ] changes of residual distributions of the second svd sensor after alignment in the magnetic field is presented .",
    "clear improvements of residuals after the alignment procedure are observed .",
    "( left ) and @xmath29 ( right ) directions of the second svd sensor using nominal ( blue ) and aligned ( red ) geometry .",
    "parameters of a gaussian fit ( black curve ) to the red histogram are given . ]",
    "during the test beam campaign which concluded in january 2014 the readout and data reduction scheme of the belle  ii vertex detector could be proven .",
    "a number of milestones were achieved :    1 .",
    "simultaneous operation of svd and pxd detectors ; 2 .",
    "common readout of all subsystems with the final belle  ii architecture ; 3 .",
    "online , real - time processing of svd data with the full reconstruction software also used for offline ; 4 .",
    "usage of the belle  ii software framework s network data distribution and parallel processing capabilities ; 5",
    ".   cellular automaton based track finding ; 6 .",
    "readout of the pxd could be successfully be driven by the svd data ; 7 .",
    "processing steps such as alignment could successfully be performed .",
    "this work would not have been possible without hard work by the belle ii pxd , svd and daq test beam teams , led by c.  marinas , c.  irmler and r.  itoh , respectively , nor would it have been possible without the desy test beam facilities ."
  ],
  "abstract_text": [
    "<S> the future belle  ii experiment will employ a computer - farm based data reduction system for the readout of its innermost detector , a depfet - technology based silicon detector with pixel readout . a large fraction of the background hits can be rejected by defining a set of regions of interest ( roi ) on the pixel detector sensors and then recording just the data from the pixels inside the roi . </S>",
    "<S> the rois are defined on an event by event basis by extrapolating back onto the pxd the charged tracks detected in the outer trackers ( a 4 layer double - sided silicon strip detector surrounded by a wire chamber ) . </S>",
    "<S> the tracks are reconstructed in real time on the high level trigger ( hlt ) . </S>",
    "<S> the pixel detector is then read out based on the roi information . </S>",
    "<S> a demonstrator of this architecture was under beam test earlier this year in desy ( hamburg , germany ) . </S>",
    "<S> the demonstrator was operated in an electron beam whose momentum was in the 2 - 6gev/_c _ range with a typical trigger rate of a few khz in a magnetic field of strength up to 1 t . </S>",
    "<S> the demonstrator consists of one pixel sensor and 4 silicon strip sensors arranged in a 5 layers configuration mimicking the belle  ii vertex detector . </S>",
    "<S> the detector readout was a scaled down version of the full belle  ii daq + hlt chain . </S>",
    "<S> the demonstrator was used to detect the particles , reconstruct in real time the trajectories , identify the rois on the pxd plane and record the pxd data within . </S>",
    "<S> we describe the requirements and the architecture of the final system together with the results obtained with the demonstrator .    </S>",
    "<S> vertex detectors , belle ii , tracking , data reconstruction , triggering </S>"
  ]
}