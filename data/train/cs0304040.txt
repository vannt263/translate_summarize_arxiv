{
  "article_text": [
    "-5 mm    the use of random choices in algorithms has been a suprisingly productive idea .",
    "many problems that have no known efficient deterministic algorithms have fast randomized algorithms , such as primality and polynomial identity testing .",
    "but to what extent is this seeming power of randomness real ?",
    "randomization is without doubt a powerful algorithm design tool , but does it dramatically change the notion of efficient computation ?    to formalize this question , consider @xmath1 , the class of problems solvable by bounded error probabilistic polynomial time algorithms .",
    "it is possible that @xmath0 , i.e. , randomness never solves new problems .",
    "however , it is also possible that @xmath2 , i.e. , randomness is a nearly omnipotent algorithmic tool .    unlike for @xmath3",
    ", there is no consensus intuition concerning the status of @xmath1 .",
    "however , recent research gives strong indications that adding randomness does not in fact change what is solvable in polynomial - time , i.e. , that @xmath0 .",
    "surprisingly , the problem is strongly connected to circuit complexity , the question of how many operations are required to compute a function .    _ a priori _ , possibilities concerning the power of randomized algorithms include :    1 .",
    "randomization always helps for intractable problems , i.e. , @xmath4 .",
    "2 .   the extent to which randomization helps is problem - specific . it can reduce complexity by any amount from not at all to exponentially .",
    "3 .   true randomness is never needed , and random choices can always be simulated deterministically , i.e. , @xmath0 .",
    "either of the last two possibilities seem plausible , but most consider the first wildly implausible . however , while a strong version of the middle possibility has been ruled out , the implausible first one is still open .",
    "recent results indicate both that the last , @xmath0 , is both very likely to be the case and very difficult to prove .",
    "more precisely :    1 .",
    "either no problem in @xmath5 has strictly exponential circuit complexity or @xmath0 .",
    "this seems to be strong evidence that , in fact , @xmath0 , since otherwise circuits can always shortcut computation time for hard problems .",
    "either @xmath2 , or any problem in @xmath1 has a deterministic sub - exponential time algorithm that works on almost all instances . in other words ,",
    "either randomness solves every hard problem , or it does not help exponentially , except on rare instances .",
    "this rules out strong problem - dependence , since if randomization helps exponentially for many instances of _ some problem _ , we can conclude that it helps exponentially for _ all intractible problems_. 3 .",
    "if @xmath6 , then either the permanent problem requires super - polynomial algebraic circuits or there is a problem in @xmath7 that has no polynomial - size boolean circuit . that is , proving the last possibility requires one to prove a new circuit lower bound , and so is likely to be difficult .",
    "the above are joint work with kabanets and wigderson , and use results from many others .",
    "all of these results use the hardness - vs - randomness paradigm introduced by yao @xcite : use a hard computational problem to define a small set of `` pseudo - random '' strings , that no limited adversary can distinguish from random . use these `` pseudo - random '' strings to replace the random choices in a probabilistic algorithm .",
    "the algorithm will not have enough time to distinguish the pseudo - random sequences from truly random ones , and so will behave the same as it would given random sequences .    in this paper , we give a summary of recent results relating hardness and randomness .",
    "we explain how the area drew on and contributed to coding theory , combinatorics , and structural complexity theory",
    ". we will use a very informal style .",
    "our main objective is to give a sense of the ideas in the area , not to give precise statements of results .",
    "due to space and time limitations , we will be omitting a vast amount of material . for a more complete survey",
    ", please see @xcite .",
    "-5 mm    the @xmath8 vs. @xmath1 question arises in the broader context of the robustness of models of computation . the famous church - turing thesis states that the formal notion of recursive function captures the conceptual notion of computation . while this is not in itself a mathematical conjecture , it has been supported by theorems proving that various ways of formalizing `` computability '' , e.g. , turing machines and the lambda calculus , are in fact equivalent .",
    "when one considers complexity as well as computability , it is natural to ask if a model also captures the notion of computation time . while it became apparant that exact computation time was model - dependent , simulations between models almost always preserved time up to a polynomial .",
    "the time - restricted church - turing thesis is that any two reasonable models of computation should agree on time up to polynomials ; equivalently , that the class of problems decideable in polynomial time be the same for both models . for many natural models ,",
    "this is indeed the case , e.g. ram computation , one - tape turing machines , multi - tape turing machines , and cobham s axioms all define the same class @xmath8 of poly - time decideable problems .",
    "probabilistic algorithms for a long time were the main challenge to this time - restricted church - turing thesis .",
    "if one accepts the notion that making a fair coin flip is a legitimate , finitely realizable computation step , then our model of poly - time computation seems to change .",
    "for example , primality testing @xcite and polynomial identity testing @xcite are now polynomial - time , whereas we do not know any deterministic polynomial - time algorithms .",
    "the @xmath8 vs. @xmath1 question seeks to formalize the question of whether this probabilistic model is actually a counter - example , or whether there is some way to simulate randomness deterministically .    as a philisophical question",
    ", the church - turing thesis has some ambiguities .",
    "we can distinguish at least two variants : a conceptual thesis that the standard model captures the conceptual notion of computation and computation time , and a physical thesis that the model characterizes the capabilities of physically - implementable computation devices . in the latter interpretation ,",
    "quantum physics is inherrently probabilistic , so probabilistic machines seem more realistic than deterministic ones as such a characterization .",
    "recently , researchers have been taking this one step further by studying models for quantum computation .",
    "quantum computation is probably an even more serious challenge to the time - limited church - turing thesis than probabilistic computation .",
    "this lies beyond the scope of the current paper , except to say that we do not believe that any analagous notion of pseudo - randomness can be used to deterministically simulate quantum algorithms .",
    "quantum computation is intrinsically probabilistic ; however , much of its power seems to come from interference between various possible outcomes , which would be destroyed in such a simulation .",
    "-5 mm    we assume familiarity with the standard deterministic and non - deterministic computation models ( see @xcite for background . ) to clarify notation , @xmath9@xmath10 is the class of decision problems solvable in deterministic polynomial time , @xmath11 is the class of such problems decideable in time exponential in the input length , and @xmath12 is the class of problems solvable in time exponential in a polynomial of the input length . @xmath13 and @xmath7 are the analogs for non - deterministic time",
    ". if @xmath14 and @xmath15 are complexity classes , we use @xmath16 to denote the class of complements to problems in @xmath14 , and @xmath17 to represent the problems solvable by a machine of the same type as normally accept @xmath14 , but which is also allowed to make oracle queries to a procedure for a fixed language in @xmath15 .",
    "( this is not a precise definition , and to make it precise , we would usually have to refer to the definition of @xmath14 .",
    "however , it is also usually clear from context how to do this . ) the _ polynomial hierarchy _",
    "@xmath18 is the union of @xmath19 .",
    "a _ probabilistic algorithm _ running in @xmath20 time is an algorithm @xmath21 that uses , in addition to its input @xmath22 , a randomly chosen string @xmath23 .",
    "thus , @xmath24 is a probability distribution on outputs @xmath25 as we vary over all strings @xmath26 .",
    "we say that @xmath21 _ recognizes _ a language @xmath27 if for every @xmath28 , @xmath29 > 2/3 $ ] and every @xmath30 , @xmath31 < 1/3 $ ] , where probabilities are over the random tape @xmath26 .",
    "@xmath1 is the class of languages recognized by polynomial - time probabilistic algorithms .",
    "the gap between probabilities for acceptance and rejection ensures that there is a statistically significant difference between accepting and rejecting distributions .",
    "setting the gap at 1/3 is arbitrary ; it could be anything larger than inverse polynomial , and smaller than @xmath32 an inverse exponential , without changing the class @xmath1 .",
    "however , it does mean that there are probabilistic algorithms , perhaps even useful ones , that do not accept any language at all .",
    "probabilistic heuristics might clearly accept on some inputs , clearly reject on others , but be undecided sometimes .    to handle this case",
    ", we can introduce a stronger notion of simulating probabilistic algorithms than solving problems in @xmath1 .",
    "let @xmath21 be any probabilistic algorithm .",
    "we say that a deterministic algorithm @xmath33 solves the _ promise problem _ for @xmath21 if , @xmath34 whenever @xmath29 > 2/3 $ ] and @xmath35 whenever @xmath29 < 1/3 $ ] .",
    "note that , unlike for @xmath1 algorithms , there may be inputs on which @xmath21 is basically undecided ; for these @xmath33 can output either @xmath36 or @xmath37 .",
    "we call the class of promise problems for probabilistic polynomial time machines @xmath38 . showing that @xmath39 is at least as strong and seems stronger than showing @xmath6 .",
    "( see @xcite for a discussion . )",
    "as happens frequently in complexity , the negation of a good definition for `` easy '' is not a good definition for `` hard '' . while @xmath4 is a good formalization of `` randomness",
    "always helps '' , @xmath40 is less convincing as a translation of `` randomness never helps '' ; @xmath39 is a much more robust statement along these lines .",
    "@xmath41 is the class of counting problems for polynomail - time verifiable predicates .",
    "i.e. , for each poly - time predicate @xmath42 and polynomial @xmath43 , the associated counting problem is : given input @xmath22 , how many @xmath44 with @xmath45 satisfy @xmath46 ?",
    "valiant showed that computing the permanent of a matrix is @xmath41-complete @xcite , and toda showed that @xmath47 @xcite .",
    "a class that frequently arises in proofs is @xmath48 , which consists of languages with probabilistically verifiable proofs of membership .",
    "formally , a language @xmath27 is in @xmath48 if there is a predicate @xmath49 in @xmath8 and a polynomial @xmath43 so that , if @xmath50 , @xmath51 so that @xmath52 > 2/3 $ ] and if @xmath53 , @xmath54 , @xmath55 < 1/3 $ ] .",
    "although @xmath48 combines non - determinism and probabilism , there is no direct connection known between derandomizing @xmath1 and derandomizing @xmath48 .",
    "this is because if @xmath28 , there still may be some poorly chosen witnesses @xmath44 which are convincing to @xmath33 about 1/2 the time .",
    "however , derandomizing @xmath38 also derandomizes @xmath48 , because we do nt need a strict guarantee .",
    "let @xmath56 be a class of time - computable functions closed under composition with polynomials . if @xmath57 $ ] then @xmath58 $ ] .",
    "-5 mm    the circuit complexity of a finite function measures the number of primitive operations needed to compute the function . starting with the input variables",
    ", a circuit computes a set of intermediate values in some order .",
    "the next intermediate value in the sequence must be computed as a primitive operation of the inputs and previous intermediate values .",
    "one or more of the values are labelled as outputs ; for one output circuits this is without loss of generality the last value to be computed .",
    "the size of a circuit is the number of values computed , and the circuit complexity of a function @xmath59 , @xmath60 , is the smallest size of a circuit computing @xmath59 .",
    "circuit models differ in the type of inputs and the primitive operations .",
    "boolean circuits have boolean inputs and the boolean functions on 1 or 2 inputs as their primitive operations .",
    "algebraic circuits have inputs taking values from a field @xmath61 and whose primitive operations are addition in @xmath61 , multiplication in @xmath61 , and the constants @xmath37 and @xmath62 .",
    "algebraic circuits can only compute polynomials .",
    "let @xmath63 represent the function @xmath59 restricted to inputs of size @xmath64 we use the notation @xmath65 to represent the class of functions @xmath59 so that the boolean circuit complexity of @xmath63 is bounded by a polynomial in @xmath64 ; we use the notation @xmath66 for the analagous class for algebraic circuits over the integers",
    ".    circuits are _ non - uniform _ in that there is no a priori connection between the circuits used to compute the same function on different input sizes .",
    "thus , it is as if a new algorithm can be chosen for each fixed input size .",
    "while circuits are often viewed as a combinatorial tool to prove lower bounds on computation time , circuit complexity is also interesting in itself , because it gives a concrete and non - asymptotic measure of computational difficulty .",
    "-5 mm    to derandomize an algorithm @xmath21 , we need to , given @xmath22 , estimate the fraction of strings @xmath26 that cause probabilistic algorithm @xmath25 to output 1 .",
    "if @xmath21 runs in @xmath20 steps , we can construct an approximately @xmath20 size circuit @xmath67 which on input @xmath26 simulates @xmath25 .",
    "so the problem reduces to : given a size @xmath68 circuit @xmath69 , estimate the fraction of inputs on which it accepts . note that solving this circuit - estimation problem allows us to derandomize @xmath38 as well as @xmath1 .",
    "we could solve this by searching over all @xmath70 @xmath68-bit strings , but we d like to be more efficient . instead , we ll search over a specially chosen small _ sample set _ @xmath71 of such strings .",
    "the average value over @xmath72 of @xmath73 approximate the average over all @xmath26 s for any small circuit @xmath67 .",
    "this is basically the same as saying that the task of distinguishing between a random string and a member of @xmath74 is so computationally difficult that it lies beyond the abilities of size @xmath68 circuits .",
    "we call such a sample set _ pseudo - random_. pseudo - random sample sets are usually described as the range of a function called a _ pseudo - random generator_. this made sense for the original constructions , which had cryptographic motivations , and where it was important that @xmath74 could be sampled from very quickly @xcite . however , we think the term pseudo - random generator for hardness vs. randomness is merely vestigial , and in fact has misleading connotations , so we will use the term _ pseudo - random sample set_.    we want to show the existence of a function with small    since we want distinguishing members of @xmath74 to be hard for all small circuits , we need to start with a problem @xmath59 of high circuit complexity , say @xmath75 for some constant @xmath76 .",
    "we assume that we have or compute the entire truth table for @xmath59 .    for the direct applications , we ll obtain @xmath59 as follows .",
    "start with some function @xmath77 defined on all input sizes , where @xmath78 is has circuit size at least @xmath79 for a super - polynomial function @xmath80 .",
    "pick @xmath81 so that @xmath82 and let @xmath83 .",
    "note that @xmath84 . since @xmath77",
    ", we can construct the truth - table for @xmath59 in time exponential in @xmath81 , which means polynomial time in the size of the truth - table , @xmath85 .",
    "other applications , in later sections , will require us to be able to use any hard function , not necessarily obtained from a fixed function in @xmath5 .",
    "we then construct from @xmath59 the pseudo - random sample set @xmath86 .",
    "given the truth table of @xmath59 , we list the members of @xmath87 in as small a deterministic time as possible",
    ". it will almost always be possible to do so in time polynomial in the number of such elements , so our main concern will be minimizing the size of @xmath87 .",
    "we then need to show that no @xmath68 gate circuit can distinguish between members of @xmath87 and truly random sequences .",
    "we almost always can do so in a very strong sense : given a test @xmath88 that distinguishes @xmath87 from the uniform distribution , we can produce a size @xmath89 size circuit using @xmath88 as an oracle , @xmath90 , computing @xmath59 .",
    "if such a test were computable in size @xmath68 , we could then replace the oracle with such a circuit , obtaining a circuit of size @xmath91 computing @xmath59 , a contradiction .",
    "the simulation is : choose @xmath81 .",
    "construct the truth table of @xmath83 .",
    "construct @xmath87 .",
    "run @xmath92 for each @xmath93 .",
    "return the majority answer . in almost all constructions ,",
    "the dominating term in the simulation s time is the size of @xmath87 . in the most efficient constructions , making the strongest hardness assumption , @xmath94 , @xcite obtain constructions with @xmath95 .",
    "this gives us the following theorem :    if there is an @xmath77 with @xmath96 then @xmath0 .",
    "@xcite gives an optimally efficient construction for any hardness , not just exponential hardness .",
    "-5 mm    the canonical outline for constructing the pseudo - random sample set was first put together in @xcite ; however , each of their three steps was at least implicit in earlier papers .",
    "later constructions either improve one of the steps , combine steps , or apply the whole argument recursively .",
    "however , a conceptual break - through that changed the way researchers looked at these steps is due to @xcite and will be explored in more detail in the next section .    1 .",
    "extension and random - self - reduction .",
    "construct from @xmath59 a function @xmath97 so that , if @xmath97 has a circuit that computes its value correctly on _ almost all _ inputs , then @xmath59 has a small circuit that is correct on _ all _ inputs .",
    "+ this is usually done by viewing @xmath59 as a multi - linear or low - degree polynomial over some field of moderate characteristic ( poly in @xmath81 ) . then that polynomial can be extrapolated to define it at non - boolean inputs , giving the extension @xmath97 .",
    "if we have a circuit that is almost always correct , we can produce a probabilistic circuit that is always correct as follows . to evaluate @xmath97 at @xmath98 ,",
    "pick a point @xmath99 at random , and evaluate the almost always correct circuit at random points on the line @xmath100 . since any point is on exactly one line with @xmath98 , these points are uniform , and chances are the circuit is correct on these points .",
    "@xmath97 restricted to @xmath101 can be viewed as a low - degree polynomial in the single variable @xmath22 .",
    "thus , we can interpolate this polynomial , and use its value at @xmath102 to give us the value @xmath103 .",
    "( @xcite is the first paper we know with this construction . )",
    "+ the key parameter that influences efficiency for this stage is @xmath104 , since the size of the truth - table for @xmath97 is @xmath105 .",
    "ideally , @xmath106 , so that @xmath107 , and we can construct @xmath97 in polynomial - time . 2 .   hardness amplification : from @xmath97 , construct a function @xmath108 on inputs of size @xmath109 so that , from a circuit that can predict @xmath108 with an @xmath110 advantage over guessing , we can construct a circuit that computes @xmath97 on almost all inputs .",
    "+ the prototypical example of a hardness amplification construction is the exclusive - or lemma @xcite . here",
    "efficiency for this stage is mostly minimizing @xmath104 .",
    "the @xmath112 construction above is not particularly efficient , so much work went into more efficient amplification .",
    "3 .   finding quasi - independent sequences of inputs .",
    "now we have a function whose outputs are almost as good as random bits at fooling a size - limited guesser . however , we need many output bits that look mutually random . in this step ,",
    "a small sets of input vectors @xmath113 is constructed so that for @xmath114 , guessing @xmath108 on @xmath115 is hard and in some sense independent of the guess for @xmath116 .",
    "+ then the sample set will be defined as : @xmath117 + the classical construction for this step is from @xcite .",
    "this construction starts with a _",
    "design _ , a family of subsets @xmath118 , |d_i|= \\overline{\\eta}$ ] , and @xmath119 for @xmath120 .",
    "then for each @xmath121 we construct @xmath122 , where @xmath115 is the bits of @xmath99 in @xmath123 , listed in order .",
    "intuitively , each @xmath115 is `` almost independent '' of the other @xmath116 , because of the small intersections .",
    "more precisely , if a test predicts @xmath124 from the other @xmath116 , we can restrict the parts of @xmath99 outside @xmath123 .",
    "then each restricted @xmath116 takes on at most @xmath125 values , but we havent restricted @xmath115 at all .",
    "we can construct a circuit that knows these values of @xmath97 and uses them in the predictor . +",
    "the size of @xmath87 is @xmath126 , so for efficiency we wish to minimize @xmath127 .",
    "however , our new predicting circuit has size @xmath128 , so we need @xmath129 .",
    "such designs are possible if and only if @xmath130 .",
    "thus , the construction will be poly - time if we can have @xmath131 .",
    "-5 mm    as mentioned before , @xcite changed our persective on hardness vs. randomness .",
    "we mentioned earlier that it was plausible that nature had truly probabilistic events .",
    "but is it plausible that we can physically construct a perfect fair coin ? many physical sources of randomness have imperfections and correlations . from the strong versions of hardness vs. randomness constructions",
    ", we can simulate a randomized algorithm without making the assumption that perfect random bits are available .",
    "say we are simulating a randomized algorithm using @xmath68 perfect random bits .",
    "( we do nt need to have a time bound for the algorithm ) .",
    "let @xmath88 be the set of random sequences on which the algorithm accepts .",
    "assume we have a physical source outputting @xmath64 bits , but all we know about it is that no single output occurs more than @xmath132 of the time , i.e. , that it has min - entropy at least @xmath133 . treating the output of the source as a function @xmath59 on @xmath134 bits ,",
    "we construct the sample set @xmath87 , and simulate the algorithm on the sample set .",
    "the min - entropy and a simple counting argument suffices to conclude that most outputs do not have small circuits relative to @xmath88 .",
    "therefore , most outputs of the source have about the right number of neighbors in @xmath88 , and so our simulation works with high probability .",
    "this connection has been amazingly fruitful , leading to better constructions of extractors as well as better hardness vs. randomness results .",
    "this construction is also interesting from the point of view of quasi - random graphs .",
    "think globally . instead of looking at the sample set construction on a single function @xmath59 ,",
    "look at it on all possible functions .",
    "this defines a bipartite graph , where on the right side , we have all @xmath135 functions on @xmath81 bits , and on the left side , we have all @xmath68 bit strings ; the edges are between each function @xmath59 and the members of the corresponding sample set @xmath87 .",
    "let @xmath88 be any subset of the left side .",
    "then we know that any function @xmath59 that has many more or fewer than @xmath136 neighbors in @xmath88 has small circuit complexity relative to @xmath88",
    ". in particular , there can not be too many such functions .",
    "contrapositively , any large set of functions must have about the right number of neighbors in @xmath88 .",
    "thus , we get a combinatorially interesting construction of an extremely homogenous bipartite graph from any hardness vs. randomness result .",
    "-5 mm    once we look at the hardness vs. randomness issue from the point of view of extracting randomness from a flawed source , we can simplify our thoughts about the various steps .",
    "any particular bits , and even most bits , from a flawed random source might be constant , because outputs might tend to be close in hamming distance .",
    "this problem suggests its own solution : use an error correcting code first .",
    "then any two outputs are far apart , so most bit positions will be random .",
    "in fact , in retrospect , what the first two steps of the standard hardness vs. randomness method are doing is error - correcting the function .",
    "we do not care very much about rate , unless the rate is not even inverse polynomial .",
    "however , we want to be able to correct even if there is only a slight correlation between the recieved coded message and the actual coded message .",
    "it is information - theoretically impossible to uniquely decode under such heavy noise , but it is sometimes possible to _ list decode _ , producing a small set of possible messages . at the end of the hardness amplification stage , this is in fact what we have done to the function .    however , there are some twists to standard error- correction that make the situation unique .",
    "most interestingly , we need decoding algorithms that are super - fast , in that to compute any particular bit of the original message can be done in poly - log time , assuming random access to the bits of the coded message .",
    "this kind of _ local decodability _ was implicit in @xcite , and applied to hardness vs. randomness in @xcite .",
    "in retrospect , much of the effort in hardness - vs - randomness constructions has been in making locally list - decodeable error - correcting codes in an ad hoc manner .",
    "@xcite showed that even natural ways of encoding can be locally list - decodeable .",
    "however , there might be some value in the ad hoc approaches .",
    "for example , many of the constructions assume the input has been weakly error - corrected , and then do a further construction to increase the amount of noise tolerated .",
    "thus , these constructions can be viewed as error - correction boosters : codes where , given a code word corrupted with noise at a rate of @xmath137 , one can recover not the original message , but a message of lower relative noise , i.e. hamming distance @xmath138 from the original message , where @xmath139 .",
    "these might either be known or of interest to the coding community .",
    "-5 mm    are circuit lower bounds necessary for derandomization ? some results that suggested they might not be are @xcite and @xcite , where average - case derandomization or derandomization vs. a deterministic adversary was possible based on a uniform or no assumption .",
    "however , intuitively , the instance could code a circuit adversary in some clever way , so worst - case derandomization based on uniform assumptions seemed difficult .",
    "recently , we have some formal confirmation of this : proving worst - case derandomization results automatically prove new circuit lower bounds .",
    "these proofs usually take the contrapositive approach .",
    "assume that a large complexity class has small circuits .",
    "show that randomized computation is unexpectedly powerful as a result , so that the addition of randomness to a class jumps up its power to a higher level in a time hierarchy .",
    "then derandomization would cause the time hierarchy to collapse , contradicting known time hierarchy theorems .",
    "an example of unexpected power of randomness when functions have small circuits is the following result from @xcite :    if @xmath140 , then @xmath141 .",
    "this did nt lead directly to any hardness from derandomization , because @xmath48 is the probabilistic analog of @xmath142 , not of @xmath8 .",
    "however , combining this result with kabanet s easy witness idea ( @xcite ) , @xcite managed to extend it to @xmath7 .    if @xmath143 , then @xmath144 .",
    "since as we observed earlier , derandomizing @xmath38 collapses @xmath48 with @xmath142 , it does follow that full derandomization is not possible without proving a circuit lower bound for @xmath7 .    if @xmath145 , then @xmath146 .",
    "a very recent unpublished observation of kabanets and impagliazzo is that the problem of , given an arithmetic circuit @xmath67 on @xmath147 inputs , does it compute the permanent function .",
    "is in @xmath1 .",
    "this is because one can set inputs to constants to set circuits that should compute the permanent on smaller matrices , and then use the schwartz - zippel test ( @xcite ) to test that each function computes the expansion by minors of the previous one .",
    "then assume @xmath148 .",
    "it follows that @xmath149 , because one could non - deterministically guess the algebraic circuit for perm and then verify one s guess in @xmath1 .",
    "thus , if @xmath150 ( or even @xmath151 ) and @xmath152 , then @xmath153 . if in addition , @xmath154 , we would have @xmath155 , a contradiction to the non - deterministic time hierarchy theorems . thus , if @xmath156 , either @xmath157 or @xmath158 . in either case , we would obtain a new circuit lower bound .",
    "-5 mm    this is an area with a lot of `` good news / bad news '' results . while the latest results seem pessimistic about finally resolving the @xmath8 vs. @xmath1 question , the final verdict is still out .",
    "perhaps @xmath159 is high enough in complexity that proving a circuit lower bound there would not require a major breakthrough , only persistance .",
    "perhaps derandomization will lead to lower bounds , not the other way around . in any case",
    ", derandomization seems to be a nexus of interesting connections between complexity and combinatorics .",
    "d.  beaver and j.  feigenbaum .",
    "hiding instances in multioracle queries . in _ proceedings of the seventh annual symposium on theoretical aspects of computer science _ ,",
    "volume 415 of _ lecture notes in computer science _ , 3748 , berlin , 1990 .",
    "springer verlag .",
    "h.  buhrman , l.  fortnow , and l.  thierauf . nonrelativizing separations . in _ proceedings of the thirteenth annual ieee conference on computational complexity _ , 812 , 1998 . m. blum and s. micali .",
    "`` how to generate cryptographically strong sequences of pseudo - random bits '' , _ siam j. comput .",
    "_ , vol .  13 , 850864 , 1984 . m.  clausen , a.  dress , j.  grabmeier , and m.  karpinsky .",
    "on zero - testing and interpolation of @xmath160-sparse multivariate polynomials over finite fields . , 84(2):151164 , 1991 .",
    "p.  gemmell , r.  lipton , r.  rubinfeld , m.  sudan , and a.  wigderson .",
    "self - testing / correcting for polynomials and for approximate functions . in _ proceedings of the twenty - third annual acm symposium on theory of computing _",
    ", 3242 , 1991 .",
    "r.  impagliazzo , v.  kabanets , and a.  wigderson . in search of an easy witness : exponential time vs.  probabilistic polynomial time . in _ proceedings of the sixteenth annual ieee conference on computational complexity _ , 111 , 2001 .",
    "r. impaglizzo , r. shaltiel , and a. wigderson , `` near - optimal conversion of hardness into pseudo - randomness '' , in _",
    "40th focs _ , 181190 , 1999 .",
    "r.  impagliazzo and a.  wigderson .",
    "p = bpp if e requires exponential circuits : derandomizing the xor lemma . in _ proceedings of the twenty - ninth annual acm symposium on theory of computing _ , 220229 , 1997 .",
    "r.  impagliazzo and a.  wigderson .",
    "randomness vs.  time : de - randomization under a uniform assumption . in _ proceedings of the thirty - ninth annual ieee symposium on foundations of computer science _",
    ", 734743 , 1998 .",
    "e.  kaltofen .",
    "polynomial factorization 19871991 . in i.",
    "simon , editor , _ proceedings of the first latin american symposium on theoretical informatics _ , lecture notes in computer science , 294313 .",
    "springer verlag , 1992 .",
    "( latin92 . )",
    "r. m. karp and r. j. lipton , `` turing machines that take advice '' , _",
    "lensignment mathematique _ , 28 , 191209 , 1982 .",
    "v.  kabanets , c.  rackoff , and s.  cook . efficiently approximable real - valued functions . , tr00 - 034 , 2000 .",
    "a.  klivans and d.  spielman .",
    "randomness efficient identity testing of multivariate polynomials . in _ proceedings of the thirty - third annual acm symposium on theory of computing _",
    ", 216223 , 2001 .",
    "e.  kaltofen and b.  trager .",
    "computing with polynomials given by black boxes for their evaluations : greatest common divisors , factorization , separation of numerators and denominators .",
    ", 9(3):301320 , 1990 .",
    "l. a. levin , `` one - way functions and pseudorandom generators '' , _ combinatorica _ , vol .",
    "4 , 357363 , 1987 . c.  lund , l.  fortnow , h.  karloff , and n.  nisan . algebraic methods for interactive proof systems . , 39(4):859868 , 1992 .",
    "r.  lipton .",
    "new directions in testing . in j.",
    "feigenbaum and m.  merrit , editors , _ distributed computing and cryptography _ , 191202 .",
    "dimacs series in discrete mathematics and theoretical computer science , volume 2 , ams , 1991 .",
    "a.  shamir . .",
    ", 39(4):869877 , 1992 .",
    "r.  solovay and v.  strassen , a fast monte carlo test for primality 6(1):8485 , 1979 .",
    "m.  sudan , l.  trevisan , and s.  vadhan .",
    "pseudorandom generators without the xor lemma .",
    ", 62(2):236266 , 2001 .",
    "( preliminary version in stoc99 . )",
    "r.  shaltiel and c.  umans .",
    "simple extractors for all min - entropies and a new pseudo - random generator . in _ proceedings of the forty - second annual ieee symposium on foundations of computer science _ , 648657 , 2001 .",
    "l.  valiant . why is boolean complexity theory difficult ? in m.s .",
    "paterson , editor , _ boolean function complexity _ ,",
    "volume 169 of _ london math .",
    "society lecture note series _ , 8494 .",
    "cambridge university press , 1992 .",
    "theory and applications of trapdoor functions . in",
    "_ proceedings of the twenty - third annual ieee symposium on foundations of computer science _ , 8091 , 1982 .",
    "probabilistic algorithms for sparse polynomials . in _ proceedings of an international symposium on symbolic and algebraic manipulation ( eurosam79 )",
    "_ , lecture notes in computer science , 216226 , 1979 ."
  ],
  "abstract_text": [
    "<S> we survey recent developments in the study of probabilistic complexity classes . while the evidence seems to support the conjecture that probabilism can be deterministically simulated with relatively low overhead , i.e. , that @xmath0 , it also indicates that this may be a difficult question to resolve . </S>",
    "<S> in fact , proving that probalistic algorithms have non - trivial deterministic simulations is basically equivalent to proving circuit lower bounds , either in the algebraic or boolean models .    </S>",
    "<S> 4.5 mm    * 2000 mathematics subject classification : * 68q15 , 68q10 , 68q17 , 68w20 .    * keywords and phrases : * probabilistic algorithms , derandomization , complexity classes , pseudo - randomness , circuit complexity , algebraic circuit complexity . </S>"
  ]
}