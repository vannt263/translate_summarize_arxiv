{
  "article_text": [
    "learning community structures in graphs is a central problem in machine learning , computer science and complex networks .",
    "increasingly , data is available about interactions among agents ( e.g. , social , biological , computer or image networks ) , and the goal is to infer from these interactions communities that are alike or complementary . as the study of community detection grows at the intersections of various fields , in particular computer science , machine learning , statistics and social computing , the notions of clusters , the figure of merits and the models vary significantly , often based on heuristics ( see @xcite for a survey ) . as a result , the comparison and validation of clustering algorithms remains a major challenge .",
    "key enablers to benchmark algorithms and to measure the accuracy of clustering methods are statistical network models .",
    "more specifically , the stochastic block model has been at the center of the attention in a large body of literature @xcite , as a testbed for algorithms ( see @xcite for a survey ) as well as a scalable model for large data sets ( see @xcite and reference therein ) . on the other hand",
    ", the fundamental analysis of the stochastic block model ( sbm ) is still holding major open problems , as discussed next .",
    "the sbm can be seen as an extension of the erdsrnyi ( er ) model @xcite . in the er model",
    ", edges are placed independently with probability @xmath0 , providing a models described by a single parameter .",
    "this model has been ( and still is ) a source of intense research activity , in particular due to its phase transition phenomena .",
    "it is however well known to be too simplistic to model real networks , in particular due to its strong homogeneity and absence of community structure .",
    "the stochastic block model is based on the assumption that agents in a network connect not independently but based on their profiles , or equivalently , on their community assignment .",
    "more specifically , each node @xmath8 in the graph is assigned a label @xmath9 , where @xmath10 denotes the set of community labels , and each pair of nodes @xmath11 is connected with probability @xmath12 , where @xmath13 is a fixed probability matrix . upon observing the graph ( without labels ) , the goal of community detection is to reconstruct the community assignments , with either full or partial recovery .    of particular interest is the sbm with two communities and symmetric parameters , also known as the planted bisection model , denoted in this paper by @xmath14 , with @xmath15 an even integer denoting the number of vertices . in this model",
    ", the graph has two clusters of equal size , and the probabilities of connecting are @xmath0 within the clusters and @xmath1 across the clusters ( see figure [ cluster - plot ] ) .",
    "of course , one can only hope to recover the communities up to a global flip of the labels , in other words , only the partition can be recovered .",
    "hence we use the terminology _ exact recovery _ or simply _ recovery _ when the partition is recovered correctly with high probability ( w.h.p . ) , i.e. , with probability tending to one as @xmath15 tends to infinity .",
    "when @xmath16 , it is clearly impossible to recover the communities , whereas for @xmath17 or @xmath18 , one may hope to succeed in certain regimes . while this is a toy model , it captures some of the central challenges for community detection .",
    ".5   within communities and @xmath19 across communities .",
    ", title=\"fig : \" ]    .5   within communities and @xmath19 across communities . ,",
    "title=\"fig : \" ]    a large body of literature in statistics and computer science @xcite has focused on determining lower - bounds on the scaling of @xmath2 for which efficient algorithms succeed in recovering the two communities in @xmath14 .",
    "we overview these results in the next section .",
    "the best bound seems to come from @xcite , ensuring recovery for @xmath20 , and has not be improved for more than a decade .",
    "more recently , a new phenomena has been identified for the sbm in a regime where @xmath21 and @xmath22 @xcite . in this regime ,",
    "exact recovery is not possible , since the graph is , with high probability , not connected .",
    "however , partial recovery is possible , and the focus has been shifted on determining for which regime of @xmath23 and @xmath24 it is possible to obtain a reconstruction of the communities which is asymptotically better than a random guess ( which gets roughly @xmath25 of accuracy ) . in other words , to recover only a proportion @xmath26 of the vertices correctly , for some @xmath27 .",
    "we refer to this reconstruction requirement as _",
    "detection_. in @xcite , it was conjectured that detection is possible if and only if @xmath28 .",
    "this is a particularly fascinating and strong conjecture , as it provides a necessary and sufficient condition for detection with a sharp closed - form expression .",
    "the study of this regime was initiated with the work of coja - oghlan @xcite , which obtains detection when @xmath29 using spectral clustering on a trimmed adjacency matrix .",
    "the conjecture was recently proved by massoulie @xcite and mossel et al .",
    "@xcite using two different efficient algorithms .",
    "the impossibility result was first proved in @xcite .    while the sparse regime with constant degree points out a fascinating threshold phenomena for the detection property , it also raises a natural question :",
    "does exact recovery also admit a similar phase transition ?",
    "most of the literature has been focusing on the scaling of the lower - bounds , often up to poly - logarithmic terms , and the answer to this question appears to be currently missing in the literature .",
    "in particular , we did not find tight impossibility results , or guarantees of optimality of the proposed algorithms .",
    "this paper answers this question , establishing a sharp phase transition for recovery , obtaining a tight bound with an efficient algorithm achieving it .",
    "there has been a significant body of literature on the recovery property for the stochastic block model with two communities @xmath14 , ranging from computer science and statistics literature to machine learning literature .",
    "we provide next a partial list of works that obtain bounds on the connectivity parameters to ensure recovery with various algorithms :    [ cols=\"<,^,^\",options=\"header \" , ]",
    "from an algorithmic point of view , the censored block model investigated in @xcite is also related to this paper .",
    "it considers the following problem : @xmath30 is a random graph from the @xmath31 ensemble , and each node @xmath8 is assigned an unknown binary label @xmath32 . for each edge",
    "@xmath33 in @xmath30 , the variable @xmath34 is observed , where @xmath35 are i.i.d .",
    "bernouilli(@xmath36 ) variables . the goal is to recover the values of the node variables from the @xmath37 variables . matching bounds are obtained in @xcite for @xmath38 close to @xmath39 , with an efficient algorithm based on sdp , which is related to the algorithm developed in this paper .    shortly after the posting of this paper on arxiv , a paper of mossel , neeman and sly @xcite , fruit of a parallel research effort ,",
    "was posted for the recovery problem in @xmath14 . in @xcite",
    ", the authors obtained a similar type of result as in this paper , slightly more general , allowing in particular for the parameters @xmath23 and @xmath24 to depend on @xmath15 as long as both parameters are @xmath40 .",
    "in this section we prove an information theoretic lower bound for exact recovery on the stochastic block model .",
    "the techniques are similar to the estimates for decoding a codeword on a memoryless channel with a specific structured codes .",
    "recall the @xmath14 stochastic block model : @xmath15 denotes the number of vertices in the graph , assumed to be even for simplicity , for each vertex @xmath41 $ ] , a binary label @xmath42 is attached , where @xmath43}$ ] are uniformly drawn such that @xmath44 : x_v = 1\\}|=n/2 $ ] , and for each pair of distinct nodes @xmath45 $ ] , an edge is placed with probability @xmath0 if @xmath46 and @xmath1 if @xmath47 , where edges are placed independently conditionally on the vertex labels . in the sequel , we consider @xmath48 and @xmath49 , and focus on the case @xmath50 to simplify the writing .    [ theorem : mainlowerbound ] let @xmath51 .",
    "if @xmath52 , or equivalently , if either @xmath53 or @xmath54 and @xmath55 , then ml fails in recovering the communities with probability bounded away from zero .    if @xmath56 , recovery is possibly if and only if there are no isolated nodes which is known to have a sharp threshold at @xmath57",
    "we will focus on @xmath58 .",
    "let @xmath59 and @xmath60 denote the two communities , each with @xmath61 nodes .",
    "let @xmath62 and let @xmath63 be a fixed subset of @xmath59 of size @xmath64 .",
    "we define the following events :    @xmath65    where @xmath66 is the number of edges between two sets .",
    "note that we identify nodes of our graph with integers with a slight abuse of notation when there is no risk of confusion .",
    "we also define @xmath67    [ lemma_faf ] if @xmath68 then @xmath69 .    by symmetry",
    ", the probability of a failure in @xmath60 is also at least @xmath70 so , by union bound , with probability at least @xmath71 both failures will happen simultaneously which implies that ml fails .",
    "[ lemma : reverseunionboundh ] if @xmath72 then @xmath69 .",
    "it is easy to see that @xmath73 and lemma  [ lemma : delta910 ] states that @xmath74 hence , @xmath75 which together with lemma [ lemma_faf ] concludes the proof .",
    "[ lemma : controlrhoisenough ] recall the definitions in ( [ def : events ] ) and ( [ definitionofrho ] ) .",
    "if @xmath76 then , for sufficiently large @xmath15 , @xmath69 .    we will use lemma [ lemma : reverseunionboundh ] and show that if @xmath77 then @xmath72 , for sufficiently large @xmath15 .",
    "@xmath78 are independent and identically distributed random variables so @xmath79 this means that @xmath72 is equivalent to @xmath80 .",
    "if @xmath81 is not @xmath82 than the inequality is obviously true , if @xmath83 then , @xmath84 where the last inequality used the hypothesis @xmath77 .",
    "[ def : definitionoft ] let @xmath85 be a natural number , @xmath86 $ ] , and @xmath87 , we define @xmath88 where @xmath89 are i.i.d .",
    "bernoulli@xmath90 and @xmath91 are i.i.d .",
    "bernoulli@xmath92 , independent of @xmath89 .",
    "[ lemma - conv ] let @xmath58 , then @xmath93    from the definitions in ( [ def : events ] ) and ( [ definitionofrho ] ) we have @xmath94 where @xmath89 are i.i.d .",
    "bernoulli@xmath95 and @xmath91 are i.i.d .",
    "bernoulli@xmath96 , all independent .",
    "since @xmath97 we get @xmath98 and lemma  [ lemma - conv ] implies @xmath99 hence @xmath77 , and the conclusion follows from lemma [ lemma : controlrhoisenough ] .",
    "we present now the main result of this section .    [ theorem : main_upperbound_2 ] if @xmath100 , i.e. , if @xmath101 and @xmath102 , then the maximum likelihood estimator exactly recovers the communities ( up to a global flip ) , with high probability .",
    "the case @xmath56 follows directly from the connectivity threshold phenomenon on erds - rnyi graphs so we will restrict our attention to @xmath103 .",
    "we will prove this theorem through a series of lemmas .",
    "the techniques are similar to the estimates for decoding a codeword on a memoryless channel with a specific structured codes . in what follows",
    "we refer to the true community partition as the ground truth .",
    "if the maximum likelihood estimator does not coincide with the ground truth , then there exists @xmath104 and a set @xmath105 and @xmath106 with @xmath107 such that @xmath108    recall that the maximum likelihood estimator finds two equally sized communities ( of size @xmath61 each ) that have the minimum number of edges between them , thus for it to fail there must exist another balanced partition of the graph with a smaller cut , let us call it @xmath109 and @xmath110 . without loss of generality @xmath111 and @xmath112 . picking @xmath113 and @xmath114",
    "gives the result .",
    "let @xmath115 be the event of the maximum likelihood estimator not coinciding with the ground truth .",
    "given @xmath116 and @xmath117 both of size @xmath118 , define @xmath119 as @xmath120    we have , by a simple union bound argument , @xmath121    let @xmath122 be a sequence of i.i.d . bernoulli@xmath123 random variables and @xmath124 an independent sequence of i.i.d .",
    "bernoulli@xmath125 random variables , note that ( cf .",
    "definition  [ def : definitionoft ] ) , @xmath126    lemma [ lemma : pnk_fromclt_itub ] in the appendix shows that : @xmath127    we thus have , combining ( [ eq : pf_unionbound_itub ] ) and ( [ eq : comesfrombernstein ] ) , and using @xmath128 , @xmath129 .",
    "\\label{eq : outsidelemmaboundpf5_it_ub}\\end{aligned}\\ ] ]    recall that @xmath115 is the event of the maximum likelihood estimator not coinciding with the ground truth .",
    "we next show that for @xmath130 , if , @xmath131 then there exists a constant @xmath132 such that @xmath133 combining ( [ eq : outsidelemmaboundpf5_it_ub ] ) and ( [ eq : with14epsilon_14 ] ) , we have @xmath134\\nonumber\\\\ & = &   \\sum_{k=1}^{n/4 }   \\exp\\left[k\\left (   - 2\\log 2k +   4\\frac{k}n\\log n - \\left(\\frac{1}2-\\frac{k}n\\right ) \\epsilon",
    "\\log n+2 \\right)\\right]\\nonumber\\\\ & \\leq &   \\sum_{k=1}^{n/4 }   \\exp\\left[k\\left (   - 2\\log 2k +   4\\frac{k}n\\log n - \\frac{1}4\\epsilon \\log n+2 \\right)\\right]\\\\ & = &   \\sum_{k=1}^{n/4 } n^{-\\frac{k}4\\epsilon } \\exp\\left[-2k\\left ( \\log 2k -   \\frac{2k}n\\log n + 1 \\right)\\right].\\nonumber\\end{aligned}\\ ] ] note that , for sufficiently large @xmath15 , @xmath104 we have @xmath135 and @xmath136 .",
    "hence , for sufficiently large @xmath15 , @xmath137,\\ ] ] which , together with the observation that @xmath138 = o(1)$ ] , concludes the proof of the theorem .",
    "we propose and analyze an algorithm , based in semidefinite programming ( sdp ) , to efficiently reconstruct the two communities .",
    "let @xmath139 be the observed graph , where edges are independently present , with probability @xmath140 if they connect two nodes in the same community and with probability @xmath141 if they connect two nodes in different communities , with @xmath5 .",
    "recall that there are n nodes in this graph and that with a slight abuse of notation , we will identify nodes in the graph by an integer in @xmath142 $ ] .",
    "our goal is to recover the two communities in @xmath143 .",
    "+ the proposed reconstruction algorithm will try to find two communities such that the number of within - community edges minus the across - community edges is largest .",
    "we will identify a choice of communities by a vector @xmath144 with @xmath145 entries such that the @xmath146 component will correspond to @xmath147 if node @xmath148 is in one community and @xmath149 if it is in the other . we will also define @xmath60 as the @xmath150 matrix with zero diagonal whose non diagonal entries are given by @xmath151",
    "the proposed algorithm will attempt to maximize the following @xmath152    our approach will be to consider a simple sdp relaxation to this combinatorial problem .",
    "the sdp relaxation considered here dates back to the seminal work of goemans and williamson  @xcite on the ` max - cut ` problem .",
    "the techniques behind our analysis are similar to the ones used by the first two authors on a recent publication  @xcite :    @xmath153    [ theorem : main_sdp_provenintheappendix ] if @xmath154 , the following holds with high probability : ( [ sdp : mainsdp ] ) has a unique solution which is given by the outer - product of @xmath155 whose entries corresponding to community @xmath59 are @xmath156 and community @xmath60 are @xmath149 . hence , if @xmath154 , full recovery of the communities is possible in polynomial time",
    ".    we will prove this result through a series of lemmas .",
    "recall that @xmath143 is the observed graph and that the vector @xmath157 corresponds to the correct choice of communities . as stated above , the optimization problem ( [ sdp : mainsdp ] ) is an sdp ( semidefinite program ) and any sdp can be solved in polynomial time using methods such as the interior point method .",
    "hence if we can prove that the solution of ( [ sdp : mainsdp ] ) is @xmath157 , then we will have proved that the algorithm can recover the correct choice of communities in polynomial time . + recall that the degree matrix @xmath158 of a graph @xmath30 is a diagonal matrix where each diagonal coefficient @xmath159 corresponds to the number of neighbours of vertex @xmath148 and that @xmath160 is the second smallest eigenvalue of a symmetric matrix @xmath161 .",
    "let @xmath162 ( resp .",
    "@xmath163 ) be a subgraph of @xmath143 that includes the edges that link two nodes in the same community ( resp .",
    "in different communities ) and @xmath59 the adjacency matrix of @xmath143 .",
    "we denote by @xmath164 ( resp .",
    "@xmath165 ) the degree matrix of @xmath162 ( resp .",
    "@xmath163 ) and define the stochastic block model laplacian to be @xmath166    [ lemma : lemma1sdp ] if @xmath167 then @xmath168 is the unique solution to the sdp ( [ sdp : mainsdp ] ) .",
    "we can suppose that @xmath169 wlog .",
    "first of all , we obtain a sufficient condition for @xmath168 to be a solution to sdp ( [ sdp : mainsdp ] ) by using the kkt conditions .",
    "this will give us the first part of condition ( [ sdp : condition ] ) .",
    "the primal problem of sdp ( [ sdp : mainsdp ] ) is @xmath170    the dual problem of sdp ( [ sdp : mainsdp ] ) is @xmath171    @xmath168 is guaranteed to be an optimal solution to sdp ( [ sdp : mainsdp ] ) under the following conditions :    * @xmath168 is a feasible solution for the primal problem * there exists a matrix @xmath172 feasible for the dual problem such that @xmath173 .    the first point being trivially verified , it remains to find such a @xmath172 ( known as a dual certificate ) .",
    "generally , one can also use complementary slackness to help find such a certificate but , in this case , it is equivalent to strong duality .",
    "define a correct ( resp .",
    "incorrect ) edge to be an edge between two nodes in the same ( resp .",
    "different ) community and a correct ( resp . incorrect ) non - edge to be the absence of an edge between two nodes in different ( resp .",
    "same ) communities .",
    "notice that @xmath174 counts positively the correct edges and non - edges incident from node @xmath148 and negatively incorrect edges and incorrect non edges incident from node @xmath148 .",
    "in other words @xmath175 hence : @xmath176 so @xmath177 verifies @xmath178 and , thus defined , is diagonal . as long as @xmath179 , or in other words , @xmath180 , we can then conclude that @xmath168 is an optimal solution for sdp ( [ sdp : mainsdp ] ) .",
    "+ the second part of condition ( [ sdp : condition ] ) ensures that @xmath168 is the unique solution to sdp ( [ sdp : mainsdp ] ) .",
    "suppose that @xmath181 is another optimal solution to sdp ( [ sdp : mainsdp ] ) , then @xmath182 from complementary slackness and @xmath183 . by assumption ,",
    "the second smallest eigenvalue of @xmath184 is non - zero .",
    "this entails that @xmath157 spans all of its null space . combining this with complementary slackness , the fact that @xmath183 and @xmath180",
    ", we obtain that @xmath181 needs to be a multiple of @xmath168 .",
    "since @xmath185 we must have @xmath186 .    given lemma ( [ lemma : lemma1sdp ] ) ,",
    "the next natural step would be to control the eigenvalues of @xmath187 when @xmath188 .",
    "we want to use benstein s inequality to do this ; to make its application easier , we rewrite @xmath184 as a linear combination of elementary deterministic matrices with random coefficients .",
    "define @xmath189 where the @xmath190 , @xmath191 are independent and independent of each other .",
    "define @xmath192 where @xmath193 ( resp .",
    "@xmath194 ) is the vector of all zeros except the @xmath146 ( resp .",
    "@xmath195 ) coefficient which is 1 . using these definitions ,",
    "we can then write @xmath184 as the difference of two matrices @xmath196 and @xmath197 where @xmath197 is a zero - expectation matrix and @xmath196 , a deterministic matrix that corresponds to the expectation , ie @xmath198 where @xmath199 notice that @xmath200=2{\\frac{\\alpha \\log(n)}{n}}-1 $ ] and @xmath201=2{\\frac{\\beta \\log(n)}{n}}-1 $ ] , hence @xmath202=0 $ ] . + condition ( [ sdp : condition ] ) is then equivalent to @xmath203 where @xmath204 ( resp .",
    "@xmath205 ) represents the projection of @xmath197 ( resp .",
    "@xmath196 ) onto the space @xmath206 . typically ,",
    "if we want to project @xmath197 onto the space spanned by the vector @xmath8 , then the projection matrix would be @xmath207 and @xmath208 .",
    "@xmath196 being determinstic , condition ( [ sdp : condition2 ] ) amounts to controlling the spectral norm of @xmath197 .",
    "this is what is exploited in lemma [ lemma : lemma2sdp ] in the appendix where it is shown that condition ( [ sdp : condition2 ] ) is verified if @xmath209 and @xmath210 for some @xmath130 .",
    "+ using bernstein to conclude , lemma [ lemma : proj1 ] in the appendix shows that @xmath209 for some @xmath211 when n is big enough and lemma [ lemma : projorth1 ] in the appendix shows that @xmath210 for some @xmath130 if @xmath212 .",
    "this concludes the proof of the theorem .      in this section",
    "we show how to leverage state of the art algorithms for partial recovery in the sparse case in order to construct an efficient algorithm that achieves exact recovery down to the optimal information theoretical threshold .",
    "+ the algorithm proceeds by splitting the information obtained in the graph into a part that is used by the partial recovery algorithm and a part that is used for the local steps .",
    "in order to make the two steps ( almost ) independent , we propose the following procedure : first take a random partition of the edges of complete graph on the @xmath15 nodes into 2 graphs @xmath213 and @xmath214 ( done independently of the observed graph @xmath143 ) .",
    "@xmath213 is an erdos - renyi graph on n nodes with edge probability @xmath215 , @xmath214 is the complement of @xmath213 .",
    "we then define @xmath216 and @xmath217 subgraphs of @xmath143 as @xmath218 and @xmath219 . in the second step ,",
    "we apply massoulie s  @xcite algorithm for partial recovery to @xmath216 .",
    "as @xmath216 is an sbm graph with parameters @xmath220 , this algorithm is guaranteed  @xcite to output , with high probability , a partition of the n nodes into two communities @xmath221 and @xmath222 , such that the partition is correct for at least @xmath223 nodes , where @xmath224 as @xmath225 .",
    "in other words , @xmath221 and @xmath222 coincide with @xmath59 and @xmath60 ( the correct communities ) on at least @xmath223 nodes .",
    "lastly , we flip some of the nodes memberships depending on the edges they have in @xmath217 . using the communities @xmath221 and @xmath222 obtained in the previous step , we flip the membership of a given node if it has more edges in @xmath217 going to the opposite community than it has to its own .",
    "if the the number of flips in each cluster is not the same , keep the clusters unchanged .",
    "0.33        0.33     if @xmath226 , then , there exists large enough @xmath196 ( depending only on @xmath227 and @xmath228 ) such that , with high probability , the algorithm described above will successfully recover the communities from the observed graph .    in the following",
    ", we will suppose that the partial recovery algorithm succeeds as described above w.h.p .",
    "and we want to show that when @xmath229 and @xmath230 small enough , the probability that there exists a node that does nt belong to the correct community , after the local improvements , goes to 0 when @xmath188 .",
    "our goal is to union bound over all possible nodes .",
    "we are thus interested in the probability that a node is mislabeled at the end of the algorithm .",
    "+ recall the random variables @xmath231 and @xmath232 iid and mutually independent bernoulli random variables with expectations respectively @xmath233 and @xmath234 .",
    "@xmath122 represents if there is an edge between two nodes in the same community and @xmath124 if there is an edge between two nodes in different communities .",
    "define @xmath235 and @xmath236 iid copies of @xmath231 and @xmath232 . for simplicity , we start by assuming that @xmath214 is the complete graph . in this case",
    "we have at most @xmath237 incorrectly labelled nodes ( ie @xmath238 nodes that are in a but belong to b and @xmath238 nodes that are in b but belong to a ) .",
    "a node in the graph is mislabeled only if it has at least as many connections to the wrong cluster as connections to the right one .",
    "this is illustrated in figure [ fig : failures ] .",
    "we can express the event with the random variables @xmath232 , @xmath231 , their copies , and @xmath239 .",
    "@xmath240 recall that we assumed that @xmath214 was a complete graph . in reality , using lemma [ prop : degh1 ] , it can be shown that the degree of any node in @xmath214 is at least @xmath241 w.h.p .  .",
    "taking this into consideration , we will loosely upperbound ( [ probfail ] ) by removing @xmath242 on both the rhs terms .",
    "notice that the removal of edges is independent of the outcome of the random variables and @xmath243 lemma [ failupperbound ] shows that ( [ looseprobfail ] ) can be upperbounded as follows @xmath244 where @xmath245 notice that @xmath246 is a function that converges continuously to @xmath247 when @xmath248 . in this particular case , this is verified as @xmath249 when @xmath250 . using a union bound on all nodes @xmath251 }",
    "p_e \\leq n^{1- g(\\alpha,\\beta , -\\gamma \\delta(c))-o(1 ) } + n^{-\\omega(1 ) } \\label{fail : last}\\end{aligned}\\ ] ] for @xmath239 small enough ( ie c large enough ) and @xmath252 , ( [ fail : last ] ) goes to 0 when @xmath188 .",
    ", scaledwidth=45.0% ]",
    "note that at high snr ( large @xmath253 ) , the sdp based algorithm succeeds in the regime of the optimal threshold obtained with ml , up to a factor @xmath254 .",
    "when running numerical simulations however , it would seem that the sdp based method achieves exact recovery all the way down to the optimal threshold . as a consequence ,",
    "the additional factor @xmath254 is likely a limitation of the analysis , in particular the matrix bernstein inequality , rather than the algorithm itself .",
    "it remains open to show that this algorithm ( or a spectral algorithm ) achieves the optimal bound @xmath255 .",
    "while we obtain that there is no gap between what can be achieved with an efficient algorithm and the maximum likelihood , as shown in section [ black ] using black - box algorithms for partial recovery and local improvement , obtaining direct algorithms would still be interesting .",
    "it would also be interesting to understand if efficient algorithms achieving the detection threshold can be used to achieve the recovery threshold and vice versa , or whether targeting the two different thresholds leads to different algorithmic developments .    finally , it is natural to expect that the results obtained in this paper extend to a much more general family of network models , with multiple clusters , overlapping communities @xcite and labelled edges @xcite .",
    "the authors are grateful to dustin g. mixon for thoroughly reading a preliminary version of this manuscript and providing useful comments , as well as to philippe rigollet and van vu for stimulating discussions on the efficient recovery via partial recovery .",
    "[ def : definitionoft ] let @xmath256 be a natural number , @xmath86 $ ] , and @xmath257 , we define @xmath258 where @xmath259 are i.i.d .",
    "bernoulli@xmath90 and @xmath260 are i.i.d .",
    "bernoulli@xmath92 , independent of @xmath259 .    for a better understanding of some of the proofs that follow , it is important to consider the behavior of @xmath261 when @xmath188 .",
    "it can be shown that @xmath262 this result is particularly interesting as one ca nt hope to obtain this bound using standard techniques such as central limit theorem approximations or chernoff bounds .",
    "this comes from the fact that when using these bounds , the error on the exponent is of order @xmath263 which is relevant here . in the same way ,",
    "when using an approximation of the binomial coefficients to prove ( [ behaviort ] ) , one has to rely on tight estimates .",
    "equation ( [ behaviort ] ) has been extended to other values of the parameters ( typically @xmath264 where @xmath36 is given ) but the main idea is contained in equation ( [ behaviort ] ) .",
    "+ the idea in the subsequent proofs will be to bound @xmath265 with its dominant term @xmath266 that we define below . as a consequence",
    ", it is particularly important to bound this dominant term as well , which is what is done in the following lemma .",
    "[ lemma1 ] we recall that @xmath267 and @xmath268 and we define : @xmath269 where @xmath270 .",
    "we also define the function @xmath271 then we have the following results for @xmath272 : + for @xmath273 and @xmath274 : @xmath275 for @xmath276 and @xmath274 : @xmath277          to prove ( [ lemma : result1 ] ) we upperbound the binomial coefficients using the following result : if @xmath282 , then @xmath283 and get @xmath284 we use ( [ bin1 ] ) and ( [ bin2 ] ) in ( [ expressionv1 ] ) and obtain @xmath285    to prove ( [ lemma : result2 ] ) we lowerbound the binomial coefficients using the following bound for the binomial coefficient , for @xmath286 ( see  @xcite for a nice presentation ) @xmath287 merging this inequality with @xmath288 gives @xmath289 given the condition on @xmath256 , we can use the previous inequality and we obtain @xmath290 we expand @xmath291 as @xmath292 to get @xmath293 and replacing ( [ dl1 ] ) in ( [ binom3 ] ) we get @xmath294 in the same way @xmath295 now using ( [ binom4 ] ) and ( [ binom5 ] ) in ( [ expressionv1 ] ) we get @xmath296    we now consider @xmath297 we minimize @xmath298 with respect to @xmath299 .",
    "we obtain @xmath300 we replace @xmath299 by @xmath301 in ( [ expressionv2 ] ) and ( [ expressionv3 ] ) and obtain the results given in the lemma .        by definition , @xmath305 is larger than the probability that @xmath306 is equal to @xmath230 , hence @xmath307 choosing @xmath308 , for @xmath309 , @xmath118 is in the range @xmath310 $ ] for @xmath15 sufficiently large @xmath311 where @xmath312 is defined as @xmath313 if @xmath314 is not an integer and @xmath315 .",
    "+ we use the result from lemma 1 with @xmath316 and @xmath317 and notice that @xmath318 hence @xmath319 and we conclude .",
    "[ lemma : pnk_fromclt_itub ] let @xmath122 be a sequence of i.i.d .",
    "bernoulli@xmath123 random variables and @xmath124 an independent sequence of i.i.d",
    ". bernoulli@xmath125 random variables .",
    "recall ( definition  [ def : definitionoft ] ) that @xmath320 the following bound holds for @xmath15 sufficiently large : @xmath321 where @xmath322 .    in the following , for clarity of notation , we have omitted the floor / ceiling symbols for numbers that are not integers but should be . recall that @xmath323\\end{aligned}\\ ] ] where @xmath324 is a binomial@xmath325 , @xmath326 is a binomial@xmath327 and @xmath267 , @xmath328 .",
    "+ the idea behind the proof is to bound @xmath329 with the dominant term @xmath330 when @xmath15 is large and then use lemma [ lemma1 ] .",
    "notice that @xmath331 , we split the proof into 2 parts based on the regime of @xmath256 .",
    "+ the first case corresponds to @xmath256 such that @xmath332 .",
    "what is important is that @xmath333 .",
    "we have @xmath334 notice that each term in the double - sum can be upper - bounded by @xmath335 as defined in ( [ lemma1 ] ) . hence @xmath336 and using ( [ lemma : result1 ] ) for @xmath337 @xmath338 as @xmath339 and @xmath340 , notice that @xmath341 and @xmath342    the second case corresponds to @xmath343 .",
    "we define @xmath344 and note that @xmath345 .",
    "notice that the same idea as in the proof above does not work when @xmath256 is @xmath346 .",
    "nevertheless a similar idea gives valid results by restricting ourselves to the first @xmath347 terms of the sum over @xmath256 , breaking @xmath348 as @xmath349 we want to control both terms in the above sum .",
    "we start off by upperbounding @xmath350 using bernstein .",
    "let us consider a sequence @xmath351 of @xmath352 centered random variables , the first @xmath256 given by @xmath353 and the last @xmath256 by @xmath354 .",
    "then @xmath355 and @xmath356,\\ ] ] also , @xmath357 we can hence apply bernestein s inequality and get , for any @xmath358 , @xmath359 here we take @xmath360 @xmath361 we now want to control @xmath362 , note that @xmath363 much as before we use bernstein inequality to upperbound @xmath364 and @xmath365 .",
    "recall that @xmath366 where @xmath367 ber@xmath368 .",
    "define @xmath369 we have @xmath370 hence in the same way as in ( [ bst1 ] ) @xmath371 similarly @xmath372 plugging ( [ bst2 ] ) , ( [ bst3 ] ) into ( [ smallsum ] ) we get @xmath373 and plugging ( [ bst1 ] ) and ( [ laststep ] ) into ( [ tdef ] ) we obtain @xmath374 from ( [ lemma : result1 ] ) and @xmath375 we get @xmath376    [ failupperbound ] let @xmath231 and @xmath232 be iid and mutually independent bernouillis with expectations respectively @xmath140 and @xmath141 .",
    "define @xmath235 and @xmath236 iid copies of @xmath231 and @xmath232 . then : @xmath377 where @xmath378 is defined in ( [ defg ] ) .",
    "trivially we have @xmath379 where @xmath380 .",
    "+ for the second part of ( [ sumoftwoterms ] ) , we upperbound using multiplicative chernoff .",
    "mutliplicative chernoff states @xmath381 in our case @xmath382 . to simplify notation",
    "we will write @xmath230 instead of @xmath239 in the following . @xmath383 for small enough @xmath230 .    for the first part of ( [ sumoftwoterms ] ) , we adapt lemma [ lemma : pnk_fromclt_itub ] .",
    "as shown in lemma [ lemma : pnk_fromclt_itub ] the second part of inequality ( [ inequality2 ] ) can be upperbounded in the following way @xmath385 we now upperbound the first part of inequality ( [ inequality2 ] ) in a similar way to lemma [ lemma : pnk_fromclt_itub ] .",
    "we group inequalities ( [ inequality2 ] ) and ( [ inequality3 ] ) , we then take the log and using ( [ lemma : result1 ] ) we obtain @xmath387 we conclude using ( [ inequality4 ] ) @xmath388        recall that @xmath390 is the event that in a graph with @xmath391 vertices where each pair of nodes is connected , independently , with probability @xmath392 , every node has degree strictly less than @xmath393 .",
    "let @xmath394 be the probability that the degree of node @xmath148 is smaller than @xmath393 .",
    "let @xmath395 be iid bernoulli@xmath396 random variables , then @xmath397 if we set @xmath398 = \\frac{n}{\\log^3n}\\frac{\\alpha\\log n}n = \\alpha\\frac1{\\log^2n}$ ] , the multiplicative chernoff bound gives , for any @xmath399 , @xmath400 we consider a slightly weaker version ( since @xmath401 ) @xmath402 this means that , by setting @xmath403 so that @xmath404 , we have @xmath405 by union bound we have , for any vertex @xmath148 , @xmath406\\\\            & = & \\exp\\left [ -2\\log n - 3\\log\\log n + \\frac{\\log n \\log(e\\alpha)}{\\log \\log n }   + \\frac{\\log n\\log\\log\\log n}{\\log \\log n }       \\right]\\\\    & = & \\exp\\left [ -\\left(2 - { o}\\left ( \\frac{\\log\\log\\log n}{\\log\\log n } \\right ) \\right)\\log n\\right ] , \\end{aligned}\\ ] ] which proves the lemma .                        [ theorem : matrixbernstein ] ( matrix bernstein ) consider a finite sequence @xmath417 of independent , random , self adjoint matrices with dimension d. assume that each random matrix satisfies @xmath418 then , for all @xmath419 : @xmath420        let @xmath130 .",
    "let @xmath422 be the projection matrix onto the @xmath412 space . then : @xmath423 using the fact that @xmath424 and the fact that @xmath425 .",
    "+ we have @xmath426 and @xmath427 \\right\\| \\\\ & = \\left\\|\\sum_{i",
    "< j , j \\notin s(i ) } \\frac{16}{n^2 } \\cdot 4 \\cdot { \\frac{\\beta \\log(n)}{n}}\\left(1-{\\frac{\\beta \\log(n)}{n}}\\right)q \\right\\| \\\\ & = 16 \\cdot { \\frac{\\beta \\log(n)}{n}}\\left(1-{\\frac{\\beta \\log(n)}{n}}\\right)\\end{aligned}\\ ] ]          @xmath434 where @xmath435 corresponds to @xmath436 and @xmath437 corresponds to @xmath438 .",
    "hence we take @xmath441 .",
    "+ @xmath442 where @xmath443 corresponds to @xmath436 and @xmath444 corresponds to @xmath438 .",
    "+ @xmath445 where @xmath446            let @xmath452 be a sequence of iid bernouilli random variables of parameter @xmath453 . consider a node v in @xmath213 .",
    "@xmath213 being an erdos - renyi graph on n vertices , we have that @xmath454 .",
    "define @xmath455 .",
    "we have @xmath456 hence if @xmath457 when @xmath188 , then @xmath458 when @xmath188 and we will have proved the result . + as @xmath459 \\forall$ ] @xmath148 and @xmath460 , using a chernoff bound we get @xmath461 where the right hand side goes to 0 when @xmath188 as c is fixed . hence using a union bound on all nodes @xmath462 when @xmath188 ."
  ],
  "abstract_text": [
    "<S> the stochastic block model ( sbm ) with two communities , or equivalently the planted bisection model , is a popular model of random graph exhibiting a cluster behaviour . in the symmetric case , </S>",
    "<S> the graph has two equally sized clusters and vertices connect with probability @xmath0 within clusters and @xmath1 across clusters . in the past two decades , </S>",
    "<S> a large body of literature in statistics and computer science has focused on providing lower - bounds on the scaling of @xmath2 to ensure exact recovery . in this paper </S>",
    "<S> , we identify a sharp threshold phenomenon for exact recovery : if @xmath3 and @xmath4 are constant ( with @xmath5 ) , recovering the communities with high probability is possible if @xmath6 and impossible if @xmath7 . in particular </S>",
    "<S> , this improves the existing bounds . </S>",
    "<S> this also sets a new line of sight for efficient clustering algorithms . </S>",
    "<S> while maximum likelihood ( ml ) achieves the optimal threshold ( by definition ) , it is in the worst - case np - hard . </S>",
    "<S> this paper proposes an efficient algorithm based on a semidefinite programming relaxation of ml , which is proved to succeed in recovering the communities close to the threshold , while numerical experiments suggest it may achieve the threshold . </S>",
    "<S> an efficient algorithm which succeeds all the way down to the threshold is also obtained using a partial recovery algorithm combined with a local improvement procedure . </S>"
  ]
}