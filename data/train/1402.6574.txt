{
  "article_text": [
    "in order to motivate the problem dealt in this paper , we have considered the results of an experiment carried out by doll and pygott ( 1952 ) to assess the factors influencing the rate of healing of gastric ulcers .",
    "two treatments groups were compared .",
    "patients in group 2 were treated in bed in hospital for four weeks .",
    "for the first two weeks they were given a moderate strict orthodox diet and for the last two weeks a more liberal one .",
    "they were then reexamined radiographically , discharged , recommended to continue on a convalescent diet and advised return to work as soon as they felt fit enough .",
    "patients in group 1 were discharged immediately .",
    "they were treated from the outset in the way that group 2 patients were treated after their month s stay in hospital . in table",
    "[ tttt1 ] , we present the results showed by doll and pygott ( 1952 , table iv ) for three months after starting the treatments .",
    "this article proposes new families of test - statistics when we are interested in studying the possibility that the ulcer treatment ( treatment @xmath0 ) is better than the control ( treatment @xmath1 ) .",
    "2.8pt @xmath2{lcccc}\\hline & larger & $ ] <",
    "@xmath3@xmath41@xmath52@xmath6    let @xmath7 denote the ordinal response variable and @xmath8 denote an ordinal explanatory variable with two categories .",
    "the variable @xmath7 takes the values @xmath1 , @xmath0 , @xmath9 and @xmath10 , which represent different levels of healing , from less to much capacity to heal the ulcer .",
    "the variable @xmath8 takes the values @xmath1 and @xmath0 according as the treatment group , @xmath1 is control and @xmath0 is the treatment group by itself .",
    "we shall initially focus on making statistical inference on the theoretical probabilities displayed in table [ ttt2 ] .",
    "2.8pt @xmath2{lcccc}\\hline & larger & $ ] <",
    "@xmath3@xmath41@xmath11(y=1|x=1)@xmath11(y=2|x=1)@xmath11(y=3|x=1)@xmath12(y=4|x=1)@xmath132@xmath11(y=1|x=2)@xmath11(y=2|x=2)@xmath11(y=3|x=2)@xmath12(y=4|x=2)@xmath14    there are several ways of formulating the statement the treatment is better than the control .",
    "initially , we shall consider that treatment @xmath0 is at least as good as treatment @xmath1 if the ratio @xmath15 increases as the response category , @xmath16 , increases , i.e.@xmath17 and treatment 2 is better than the treatment 1 if ( [ eq1 ] ) holds with at least one strict inequality .",
    "if we assume that treatment 2 is at least as good as treatment 1 , i.e. , ( [ eq1 ] ) holds , is there any evidence to support the claim that treatment @xmath0 is better ?",
    "in such a case null and alternative hypotheses may be    @xmath18    the null hypothesis means that both treatments are equally effective , while the alternative hypothesis means that treatment 2 is more effective than treatment 1 .",
    "note that if we multiply on the left and right hand side of ( [ eq2 ] ) and ( [ eq3 ] ) by @xmath19 we obtain    @xmath20    where @xmath21 is the number of ordered categories for response variable @xmath7 ,    @xmath22    are local odds ratios  associated with response category @xmath16 , and@xmath23 in case of considering the opposite inequalities given in ( [ eq3 ] ) or ( [ eq3b ] ) , the easiest way to carry out the test is to exchange the observation of the two rows in the contingency table ( in the example , treatment @xmath0 in the first row and treatment @xmath1 in the second row ) . in this way ,",
    "the mathematical background is not changed but the interpretation of the aim is changed . in the example",
    "however , there is no sense in considering that the control ( @xmath1 ) is better than the treatment ( @xmath0 ) , if the experiment is carried out with humans and it is assumed that the treatment will not harm these patients .",
    "the non - parametric statistical inference associated with the likelihood ratio ordering for two multinomial samples was introduced for the first time in dykstra et al .",
    "( 1995 ) using the likelihood ratio test - statistic . in the literature related to different types of orderings , in general",
    "there is not very clear what is the most appropriate ordering to compare two treatments according to a categorized ordinal variable . in the case of having two independent multinomial samples ,",
    "the likelihood ratio ordering is the most restricted ordering type ; for example , if the likelihood ratio ordering holds , then the simple stochastic ordering also holds .",
    "dardanoni and forcina ( 1998 ) proposed a new method for making statistical inference associated with different types of orderings . for unifying and comparing different types of orderings , they reparametrize the initial model .",
    "different ordering types can be considered to be nested models and the likelihood ratio ordering is the most parsimonious one .",
    "the advantage of nested models is that the most restricted models tend to be more powerful for the alternatives that belong to the most restricted alternatives . in this",
    "setting , our proposal in this paper is to introduce new test - statistics that provide substantially better power for testing ( [ eq2 ] ) against ( [ eq3 ] ) .",
    "the structure of the paper is as follows . in section [ sec : lm ] , we have considered the likelihood ratio order associated with a non - parametric model , as in dardanoni and forcina ( 1998 ) , but the specification of the model through a saturated loglinear model is substantially different .",
    "section [ sec : pd ] presents the phi - divergence test - statistics as extension of the likelihood ratio and chi - square test - statistics .",
    "the applied methodology in section [ sec : main results ] for proving the asymptotic distribution of the phi - divergence test - statistics , based on loglinear modeling , has been developed by following a completely new and meaningful method even for the likelihood ratio test . a numerical example is given in section [ sec : numerical example ] .",
    "the aim of section [ sec : simulation study ] is to study through simulation the behaviour of the phi - divergence test - statistics for small and moderate simple sizes .",
    "finally , we present an appendix in which we establish the part of the proofs of the results not shown in section [ sec : main results ] .",
    "we display the whole distribution of @xmath24 , given in ( [ eq5 ] ) , in a rectangular table having @xmath0 rows for the categories of @xmath8 and @xmath21 columns for the categories of @xmath7 ( for the initial example , table [ ttt2 ] ) and we denote the @xmath25 matrix @xmath26 , with two rows of probability vectors , @xmath27 , @xmath28 .",
    "we consider two independent random samples @xmath29 , @xmath28 , where sizes @xmath30 are prefixed and @xmath31 , that is the probability distribution of r.v .",
    "@xmath32 is product - multinomial .",
    "let@xmath33 be the joint probability distribution .",
    "since @xmath34 , i.e. @xmath35 , @xmath28 , where @xmath36 , we can express ( [ 2 ] ) also in terms of the joint probabilities@xmath37 let @xmath38 , with @xmath39 , @xmath28 , be the @xmath25 probability matrix and @xmath40 a probability vector obtained by stacking the columns of @xmath41  ( i.e. , the rows of matrix @xmath42 ) .",
    "note that the components of @xmath42 are ordered in lexicographical order in @xmath43 .",
    "the likelihood function of @xmath44 is @xmath45 , where @xmath46 is a constant which does not depend on @xmath43 and the kernel of the loglikelihood function@xmath47    in matrix notation , we are interested in testing @xmath48 where @xmath49  is the @xmath50-vector of @xmath1-s , @xmath51 . note that ( [ 4 ] ) involves @xmath52 non - linear constraints on @xmath43 , defined by ( [ 0 ] ) . in this article",
    "the hypothesis testing problem is formulated making a reparametrization of @xmath43 using the saturated loglinear model , so that some linear restrictions are considered with respect to the new parameters .",
    "this fact is important and interesting .",
    "focussed on @xmath43 , the saturated loglinear model with canonical parametrization is defined by @xmath53 with the identifiabilty restrictions@xmath54 it is important to clarify that we have used the identifiability constraints ( [ ident ] ) in order to make easier the calculations and this model formulation for making statistical inference with inequality restrictions with local odds - ratios has been given in this paper for the first time .",
    "similar conditions have been used for instance in lang ( 1996 , examples of section 7 ) and silvapulle and sen ( 2005 , exercise 6.25 in page 345 ) .",
    "let @xmath55 , @xmath56 denote subvectors of the unknown parameters @xmath57 .",
    "the components of @xmath58 are redundant parameters since the term @xmath59 can be expressed in function of @xmath60 using the fact that @xmath61 , i.e.@xmath62 and @xmath63 taking into account that @xmath64 , i.e.@xmath65 in matrix notation ( [ 3 ] ) is given by@xmath66 where @xmath67 is @xmath43  such that the components are defined by ( [ 3 ] ) , @xmath68 is a @xmath69 matrix with @xmath49  being the @xmath50-vector of ones , @xmath70  the @xmath50-vector of zeros , @xmath71 the kronecker product ; @xmath72 the full rank design matrix of size @xmath73 , such that@xmath74 with @xmath75  being the identity matrix of order @xmath50 , @xmath76  the matrix of size @xmath77 with zeros . the condition ( [ eq1 ] ) can be expressed by the linear constraint @xmath78 since@xmath79 condition ( [ 6 ] ) in matrix notation is given by @xmath80 , with @xmath81 , @xmath82 is the @xmath50-th unit vector and @xmath83 is a @xmath84  matrix with @xmath1-s in the main diagonal and @xmath85-s in the upper superdiagonal .",
    "observe that the restrictions can be expressed also as @xmath86 , and @xmath87  are @xmath88  are nuisance parameters because they do not take part actively in the restrictions .",
    "the kernel of the likelihood function with the new parametrization is obtained replacing @xmath43  by @xmath67 in ( [ 0b ] ) , i.e. @xmath89 hypotheses ( [ 4 ] ) can be now formulated as@xmath90 under @xmath91 , the parameter space is @xmath92 and the maximum likelihood estimator ( mle ) of @xmath60 in @xmath93 is @xmath94 .",
    "the overall parameter space is @xmath95 and the mle of @xmath60 in @xmath96 is @xmath97 .",
    "it is worthwhile to mention that the probability vectors for both parametric spaces , @xmath98 and @xmath99  can be obtained by following the invariance property of the mles first estimating @xmath60  and later plugging it into @xmath67 , however @xmath98 has an explicit expression,@xmath100 where @xmath101  ( see christensen ( 1997 ) , section 2.3 , for more details ) .",
    "the likelihood ratio statistic for testing ( [ 4 ] ) , equivalent to one given by dykstra et al .",
    "( 1995 ) but adapted for loglinear modeling , is@xmath102 where @xmath103 , @xmath28 , @xmath104 .",
    "taking into account the identifiability constraints ( [ ident ] ) and  @xmath105 , @xmath106 , @xmath107 , @xmath108  ( see formulas ( [ u])-([u1 ] ) ) , ( [ lrt ] ) can also be expressed as@xmath109 the chi - square statistic for testing ( [ 4 ] ) is@xmath110    the kullback - leibler divergence measure between two @xmath111-dimensional probability vectors @xmath43 and @xmath112 is defined as@xmath113 and the pearson divergence measure @xmath114 it is not difficult to check that @xmath115 and @xmath116 being @xmath117 the vector of relative frequencies .",
    "more general than the kullback - leibler divergence and pearson divergence measures are @xmath118-divergence measures , defined as @xmath119 where @xmath120 is a convex function such that@xmath121 from a statistical point of view , the first asymptotic statistical results based on divergence measures in multinomial populations were obtained in zografos et al .",
    "( 1990 ) . for more details about @xmath118-divergence measures",
    "see pardo ( 2006 ) and cressie and pardo ( 2002 ) .",
    "apart from the likelihood ratio statistic ( [ lrt ] ) and the chi - square ( [ cs ] ) statistic , we shall consider two new families of test - statistics based on @xmath118-divergence measures .",
    "the first new family is obtained by replacing in ( [ n1 ] ) the kullback divergence measure by a @xmath118-divergence measure,@xmath122 the second new family is obtained by replacing in ( [ n2 ] ) the pearson divergence measure by a @xmath118-divergence measure,@xmath123 if we consider @xmath124 in ( [ 5a ] ) , we get @xmath125 , and if we consider @xmath126 in ( [ 5a ] ) , we get @xmath127 .",
    "test - statistics based on @xmath118-divergence measures have been used in the framework of loglinear models for some authors , see cressie and pardo ( 2000 , 2002 , 2003 ) , martn and pardo ( 2006 , 2008b , 2011 ) .",
    "as starting point , we shall establish the observed fisher information matrix associated with @xmath60 , @xmath128 , for a loglinear model with product - multinomial sampling as@xmath129 where @xmath130  is the diagonal matrix of vector @xmath131 .",
    "to proof ( [ fim1 ] ) , we take into account that the overall observed fisher information matrix for product multinomial sampling is the weighted observed fisher information matrix associated with each multinomial sample , @xmath132 , @xmath28 , i.e.@xmath133 such that @xmath134 , @xmath135 and @xmath136 .",
    "when @xmath137 , we shall denote @xmath138  to be the true value of the unknown parameter under @xmath91 , and in such a case it holds @xmath139 , where @xmath140 is defined as the probability vector with the terms given in ( [ eq5 ] ) and related to the loglinear model through @xmath141 , @xmath28 .",
    "notice that @xmath140 is fixed as @xmath142 and we shall assume that@xmath143 is fixed but unknown , i.e. @xmath144 , @xmath28 .",
    "we shall also denote@xmath145 the @xmath146-dimensional vector obtained removing from @xmath147  the last element .",
    "focussing on the parameter structure @xmath148 , with @xmath55 , @xmath56 and the specific structure of @xmath72 , see ( [ w ] ) , we shall establish asymptotically the specific shape of ( [ fim1 ] ) , a fundamental result for the posterior theorems .",
    "the asymptotic fisher information matrix of @xmath60 , @xmath149 when @xmath137 is given by@xmath150    replacing @xmath60 by @xmath151 and the explicit expression of @xmath72  in the general expression of the finite sample size fisher information matrix for two independent multinomial samples , ( [ fim1 ] ) , we obtain through the property of the kronecker product given in ( 1.22 ) of harville ( 2008 , page 341 ) that@xmath152 and then@xmath153    the following theorem establishes that the asymptotic distribution of the families of test statistics ( [ 5a ] ) and ( [ 5b ] ) corresponds to a @xmath21-dimensional chi - bar squared random variable , a mixture of @xmath21 chi - squared distributions .",
    "let @xmath154 be the whole set of all row - indices of matrix @xmath155 , @xmath156 the family of all possible subsets of @xmath157 , and @xmath158 is a submatrix of @xmath155  with row - ndices belonging to @xmath159 .",
    "we must not forget that @xmath160 and therefore @xmath161 .",
    "we denote by @xmath162  the following @xmath163 tridiagonal matrix@xmath164 and by @xmath165 the submatrix of @xmath162  obtained by deleting from it the row - indices contained in the set @xmath166 and column - indices contained in the set @xmath167 .",
    "[ th1]under @xmath91 , the asymptotic distribution of @xmath168  and @xmath169  is@xmath170 where @xmath171 a.s .",
    "and @xmath172 is the set of weights such that @xmath173 and@xmath174 where@xmath175 @xmath176 and @xmath177 denotes the cardinal of the set @xmath178 .    by following similar arguments of martn and balakrishnan",
    "we obtain @xmath179 ( see appendix [ proofth1contra ] , for the details ) .",
    "in particular , @xmath180 with @xmath181 , i.e.@xmath182 where @xmath183 is ( [ if ] ) . by following the properties of the inverse of the kronecker product for calculating the inverse of ( [ if]),@xmath184 and replacing it in the previous expression of @xmath185,@xmath186 which is equal to ( [ h ] ) .    even though there is an equality in ( [ 4b ] ) ,",
    "@xmath60 is not a fixed vector under the null hypothesis since such an equality is effective only for @xmath187 ,  and thus @xmath88 is a vector of nuisance parameters .",
    "this means that we have a composite null hypothesis which requires estimation of @xmath137 , through @xmath188 and we can not use directly the results based on theorem [ th1 ] .",
    "the tests performed replacing the parameter @xmath151  of the asymptotic distribution by @xmath188 are called local tests  ( see dardanoni and forcina ( 1998 ) ) and they are usually considered to be good approximations of the theoretical tests .    in relation to the weights , @xmath189 , there are explicit expressions when @xmath190 based on the matrix given in ( [ h ] ) and formulas ( 3.24 ) , ( 3.25 ) and ( 3.26 ) in silvapulle and sen ( 2005 , page 80 ) . when @xmath191 , @xmath192 .",
    "when @xmath193 , the estimators of the weights are@xmath194{l}w_{0}(\\widehat{\\boldsymbol{\\theta}})=\\tfrac{1}{2}-w_{2}(\\widehat{\\boldsymbol{\\theta}}),\\\\ w_{1}(\\widehat{\\boldsymbol{\\theta}})=\\frac{1}{2},\\\\ w_{2}(\\widehat{\\boldsymbol{\\theta}})=\\tfrac{1}{2\\pi}\\arccos\\widehat{\\rho}_{12 } , \\end{array } \\right .",
    "\\label{weightsj=3}\\ ] ] where@xmath195 is the correlation associated with the @xmath196-th and @xmath16-th variable of a central random variable with variance - covariance matrix @xmath197 where @xmath198 . when @xmath199,@xmath194{l}w_{0}(\\widehat{\\boldsymbol{\\theta}})=\\tfrac{1}{4\\pi}\\left (   2\\pi -\\arccos\\widehat{\\rho}_{12}-\\arccos\\widehat{\\rho}_{13}-\\arccos\\widehat{\\rho } _ { 23}\\right )   , \\\\",
    "w_{1}(\\widehat{\\boldsymbol{\\theta}})=\\tfrac{1}{4\\pi}\\left (   3\\pi -\\arccos\\widehat{\\rho}_{12\\cdot3}-\\arccos\\widehat{\\rho}_{13\\cdot2}-\\arccos\\widehat{\\rho}_{23\\cdot1}\\right )   , \\\\ w_{2}(\\widehat{\\boldsymbol{\\theta}})=\\tfrac{1}{2}-w_{0}(\\widehat{\\boldsymbol{\\theta}}),\\\\ w_{3}(\\widehat{\\boldsymbol{\\theta}})=\\tfrac{1}{2}-w_{1}(\\widehat{\\boldsymbol{\\theta } } ) , \\end{array } \\right .",
    "\\label{weightsj=4}\\ ] ] which depend on the estimation of the marginal ( [ cor ] ) and conditional correlations@xmath200 associated with the @xmath196-th and @xmath16-th variable , given a value of the @xmath46-th variable , of a central random variable with variance - covariance matrix@xmath201 it is interesting to point out that the factor related to the sample size in each multinomial sample , @xmath202 , have no effect in the expression of estimator for the weights of the chi - bar squared distribution these formulas will be considered in the forthcoming sections .",
    "it is worthwhile to mention that the normal orthant probabilities for the weights given in ( [ eqw ] ) , can also be computed for any value of @xmath21 using the ` mvtnorm ` r package ( see http://cran.r-project.org/package=mvtnorm , for details ) .",
    "in this section the data set of the introduction ( table [ tttt1 ] ) , where @xmath199 , is analyzed .",
    "the sample , a realization of @xmath44 , is summarized in the following vector@xmath203 the order restricted mle under likelihood ratio order , obtained through the ` e04ucf ` subroutine of  ` nag ` fortran library ( http://www.nag.co.uk/numeric/fl/fldescription.asp ) , is@xmath204 the estimation of the probability vectors of interest is@xmath205 and the estimation of the weights , based on ( [ weightsj=4 ] ) , are@xmath206 in order to solve analytically the example we shall consider a particular function @xmath118 in ( [ 5a ] ) and ( [ 5b ] ) .",
    "taking@xmath207 we get the the power divergence family@xmath208 in such a way that for each @xmath209  a different divergence measure is obtained , and thus@xmath210 it is also possible to cover the real line for @xmath211 , by defining @xmath212 and by considering @xmath213 , @xmath214 , for @xmath215 , i.e. @xmath216 and @xmath217 it is well known that @xmath218 and @xmath219 , which is very interesting since @xmath125 and @xmath127 are members of the power divergence based test - statistics .",
    "it is also worthwhile to mention that @xmath220 .    in table",
    "[ t1 ] , the power divergence based test - statistics for some values of @xmath211 in @xmath221 , and their corresponding asymptotic @xmath222-values are shown . in all of them it is concluded , with a significance level equal to @xmath223 , that an equal effect of both treatments is rejected and hence the treatment is more effective than the control to heal the ulcer .    2.8pt @xmath2{cccccccccc}\\hline\\hline test - statistic & $ ] = -1.5@xmath11=-1@xmath11=-@xmath12=0@xmath11=@xmath11=1@xmath11=1.5@xmath12=2@xmath11=3@xmath224p@xmath225(t_)@xmath226p@xmath225(s_)@xmath227    the @xmath222-values given in table [ t1 ] were obtained by the following algorithm : let @xmath228 be the test - statistic associated with ( [ 4 ] ) . in the following steps",
    "the corresponding asymptotic @xmath222-value , based on the asymptotic distribution of theorem [ th1 ] , is calculated once it is suppose we have @xmath229 :    ` step 1 : using ` @xmath230 `  calculate ` @xmath98 `  taking into account ( [ ind]).``step 2 : using ` @xmath98 `  calculate value ` @xmath231 ` of test - statistic ` @xmath232 ` using the corresponding expression in ( [ pd1])-([pd6]).``step 3 : if ` @xmath233 ` then compute ` @xmath222@xmath234 ` and stop , otherwise compute ` @xmath222@xmath235.`step 4 : ` for @xmath236 ` , do ` @xmath222@xmath237@xmath238.`e.g",
    ". , the nag fortran library subroutine g01ecf can be useful . `",
    "recently , shan and ma ( 2014 ) have studied a similar problem as ( 2a)-(2b ) , but considering different alternative hypotheses , since they consider odds ratios based on cumulative probabilities .",
    "focussed on probabilities rather than cumulative probabilities , we are going to include the asymptotic version of their test - statistic in our numerical study as well as later , in the simulation study : the two sample wilcoxon test - statistic for discrete data ( ties ) , also known as wilcoxon mid - rank test - statistic .",
    "metha et al .",
    "( 1984 ) proposed such a test - statistic for solving exactly the same alternative hypothesis studied in this paper either as a permutation or as asymptotic test .",
    "our null and alternative hypotheses are a particular case of their hypotheses , taking in their section 4 @xmath239 .",
    "the expression of the wilcoxon mid - rank test - statistic is@xmath240 where @xmath241 and @xmath242 , @xmath243 , @xmath244 , and the corresponding asymptotic distribution is normal with mean @xmath245 and variance @xmath246 the wilcoxon mid - rank test - statistic for the data of table [ tttt1 ] is @xmath247  and with the corresponding @xmath222-value , @xmath248 , the same conclusion is obtained , i.e. rejecting the hypothesis of equal effect of both treatments with @xmath249 significance level .",
    "in this section we illustrate in what sense the likelihood ratio test given in ( [ lrt]),@xmath250 is different from the one for the non order restricted alternative hypothesis ( two sided test , in @xmath251 tables)@xmath252 for simplicity the case of @xmath191 is taken into account , where the ( simple null ) one sided test@xmath253 with @xmath254 , or    @xmath255 is tested with ( [ g 1 ] ) , and on the other hand the two sided test    @xmath256    or    @xmath257 is carried out with ( [ g bar ] )",
    ". the same procedure would be possible to perform for any @xmath118-divergence based test considered in this paper .",
    "we also consider the mid - rank wilcoxon test for both version of the alternative hypothesis . to clarify the parameter space in both tests ,",
    "we shall rewrite ( [ tt1 ] ) and ( [ tt2b ] ) as follows    @xmath258 where @xmath259 , @xmath260 ,    @xmath261 where @xmath262 .",
    "the parameter spaces for ( [ tt1 ] ) and ( [ tt2b ] )  are @xmath263 and @xmath264 , respectively .",
    "the same hypotheses in term of probabilities are given by    @xmath265 where @xmath266 , @xmath267 ,    @xmath268 where @xmath269 .",
    "the corresponding parameter spaces in term of probabilities are given by    @xmath270    the likelihood ratio test - statistics for ( [ tt1 ] ) and ( [ tt2b ] ) are different since in the numerator of ( [ g 1 ] ) , @xmath271 , is obtained maximizing the likelihood function in @xmath272 , while the numerator of ( [ g bar ] ) , @xmath273 , is maximized in @xmath274 .",
    "even though both estimators are different , in practice they require a similar computation:@xmath275 if @xmath276 , then @xmath277 and @xmath278;@xmath275 if @xmath279 , then @xmath280 and @xmath281.hence , taking into account the asymptotic distributions , i.e. @xmath282 for ( [ tt1 ] ) and @xmath283  for ( [ tt2b ] ) , we obtain@xmath284{ll}\\frac{1}{2}\\pr\\left (   \\chi_{1}^{2}>2{\\displaystyle\\sum\\limits_{i=1}^{2 } } { \\displaystyle\\sum\\limits_{j=1}^{2 } } n_{ij}\\log\\frac{n_{ij}/n_{i}}{n_{\\bullet j}/n}\\right )   , & \\text{if } \\frac{n_{11}}{n_{1}}>\\frac{n_{21}}{n_{2}},\\\\ 1 , & \\text{if } \\frac{n_{11}}{n_{1}}\\leq\\frac{n_{21}}{n_{2 } } , \\end{array } \\right.\\ ] ] and @xmath285 a third test is the composite null one sided test@xmath286 with @xmath287 $ ] and @xmath288 .",
    "for the corresponding test - statistic,@xmath289 @xmath275 if @xmath290 , then @xmath291 and @xmath292;@xmath275 if @xmath293 , then @xmath294 and @xmath295.hence , both one sided test - statistics , the composite null one , @xmath296 , and the simple null one , @xmath125 , are almost equal and @xmath297{ll}\\frac{1}{2}\\pr\\left (   \\chi_{1}^{2}>2{\\displaystyle\\sum\\limits_{i=1}^{2 } } { \\displaystyle\\sum\\limits_{j=1}^{2 } } n_{ij}\\log\\frac{n_{ij}/n_{i}}{n_{\\bullet j}/n}\\right )   , & \\text{if } \\frac{n_{11}}{n_{1}}\\geq\\frac{n_{21}}{n_{2}},\\\\ 1 , & \\text{if } \\frac{n_{11}}{n_{1}}<\\frac{n_{21}}{n_{2}}. \\end{array } \\right.\\ ] ]    the mid - rank @xmath298 test - statistic for ( [ tt1 ] ) and ( [ tt2b ] ) is the same , ( [ wilc ] ) , as well as the distribution under the null , but@xmath299   } { 12}}}\\right)\\ ] ] for ( [ tt1 ] ) and @xmath300   } { 12}}}\\right)\\ ] ]  for ( [ tt2b ] ) .",
    "2.8pt    [ c]ct1.pdf + t2.pdf + w.pdf    the following short simulation study considers @xmath301  realizations , @xmath302 , @xmath28 , @xmath303 , of@xmath304 with @xmath305 and @xmath306 and @xmath307 . in figure [ fighh ] a histogram of @xmath125 , @xmath308 and @xmath298",
    "is shown where the shape of the density function of each can be recognized . in table",
    "[ tthh ] , the simulated significance levels ( @xmath309 ) and powers ( @xmath310 ) are calculated as the proportion of statistics with @xmath222-values smaller than the nominal level @xmath311 .",
    "the test - statistic based on the hellinger distance @xmath312 , given in ( [ hel ] ) , is also included . from this simulation study",
    "it is concluded that the @xmath125 likelihood ratio test - statistic and the @xmath298  wilcoxon mid - rank test for @xmath251 contingency tables , are specific procedures for the one sided test ( [ tt1 ] ) since the parameter spaces are different , but are strongly related with the two sided test ( [ tt2b ] ) in the way of calculating the value of the test - statistic and the corresponding @xmath222-value .",
    "it is remarkable that the simulated significance level for the one - sided @xmath298  wilcoxon mid - rank test for @xmath251 contingency tables exhibits a slightly better approximation of the nominal level  in comparison with the likelihood ratio test @xmath125 for the one sided test ( [ tt1 ] ) , and the likelihood ratio test @xmath125 slightly better than the test - statistic based on the hellinger distance @xmath312 .",
    "the powers of the test - statistics are calculated for @xmath313 . the test - statistic based on the hellinger distance",
    "@xmath312 has the greatest power and the @xmath298  wilcoxon mid - rank test the smallest power for the one sided test ( [ tt1 ] ) . in section [ sim ] a more extensive simulation study is considered with a criterion to select the best test - statistic within a broader class of power divergence based test - statistics .",
    "finally , the two sided test - statistics , @xmath308 and @xmath298 , exhibit a worse power than the one sided test - statistics .",
    "this behaviour was obviously expected , since being @xmath314 or equivalently @xmath315 , the one sided tests have always a better power than the two sided tests .",
    "2.8pt    [ c]cccccccccccc & & @xmath312 ( one sided ) & & @xmath125 ( one sided ) & & @xmath308 ( two sided ) & & one sided @xmath298 & & two sided @xmath298 & + @xmath309 & & @xmath316 & & @xmath317 & & @xmath318 & & @xmath319 & & @xmath320 & + @xmath310 & & @xmath321 & & @xmath322 & & @xmath323 & & @xmath324 & & @xmath325 & +      in this section the performance of the power divergence test statistics ( [ pd1])-([pd6 ] ) is studied in terms of the simulated exact size and simulated power of the test , based on small and moderate sample sizes . a simulation experiment with seven scenarios is designed in table [ tt ] , taking into account the sample sizes of the two independent samples .",
    "the pairs of scenarios ( a , g ) , ( b , f ) and ( c , e ) should have very similar exact significance levels , since the sample sizes of the two samples are symmetrical ( the ratio of one sample is the inverse of the other one ) .",
    "with respect to the choice of @xmath211 , the parameters for the power divergence test statistics , the interest is focused on the interval @xmath326 $ ] .",
    "note that the test - statistics applied in the numerical example are covered as particular cases .",
    "@xmath2{cccccccc}\\hline scenarios & sc . a & sc .",
    "f & sc . g\\\\\\hline $ ] n_1@xmath1120@xmath1120@xmath1120@xmath1120@xmath1116@xmath1110@xmath114@xmath327n_2@xmath114@xmath1110@xmath1116@xmath1120@xmath1120@xmath1120@xmath1120@xmath3285@xmath112@xmath111.25@xmath111@xmath110.8@xmath110.5@xmath110.2@xmath329    the algorithm described in section [ sec : numerical example ] is taken into account to calculate the @xmath222-value of each test - statistic @xmath330}$ ] , with a sample @xmath44 , and this is repeated independently @xmath331 times .",
    "the simulated exact power was computed as@xmath332 for the probability vectors@xmath333 for @xmath334 .",
    "the simulated exact size was computed as@xmath335 for the probability vectors @xmath336 which corresponds to the case of @xmath337 for @xmath338 .    in table",
    "[ tt2 ] the local odds ratios,@xmath339 @xmath340 , are shown for @xmath341 .",
    "notice that in @xmath342  some of the components are further from @xmath343 ( null hypothesis ) , as the value of @xmath344 is further from @xmath345 .",
    "this means that a greater value of the estimation of the power function might be obtained , as @xmath344 is greater .",
    "this claim is supported by the fact that some values of the components of @xmath346 decrease as @xmath344 increases but more slowly than the others increase .",
    "in addition , for a fixed value of @xmath344 , it is expected a greater value of @xmath347 , as @xmath348 is greater ( the worst powers in scenario a and the best powers in scenario d ) .",
    "we have also added in table [ tt2 ]  the last three rows for two reasons , first , to show that for any fixed value of @xmath349 , @xmath350 is non - decreasing as @xmath16 , the ordinal category , increases and second , to clarify the meaning of the two asterisks contained in the table .",
    "it is clear that for a big value of @xmath349 , @xmath351 goes to zero on the right for @xmath28 , but in the practice , due to the empty cells in the contingency table , the estimator of the ratio @xmath352 becomes @xmath1 rather than @xmath353 ( and @xmath354 becomes @xmath1 ) .",
    "this was our experience when we used values of @xmath349 bigger than @xmath355 , i.e. the power becomes quite little in the practice .",
    "2.8pt    [ c]ccccccccccccc & & @xmath337 & & @xmath356 & & @xmath357 & & @xmath358 & & @xmath359 & & @xmath360 + @xmath361 & & @xmath362 & & @xmath363 & & @xmath364 & & @xmath365 & & @xmath366 & & @xmath367 + @xmath368 & & @xmath362 & & @xmath369 & & @xmath370 & & @xmath371 & & @xmath372 & & @xmath373 + @xmath352 & & @xmath374 & & @xmath375 & & @xmath376 & & @xmath377 & & @xmath378 & & @xmath379 + @xmath380 & & @xmath374 & & @xmath374 & & @xmath374 & & @xmath374 & & @xmath374 & & @xmath373 +    once a nominal size @xmath311 is established , table [ alfas ] summarizes the simulated exact sizes in all the scenarios for the test - statistic @xmath381 , with @xmath382 .",
    "we have plotted @xmath383 graphs in figures [ fig2]-[fig7 ] and we refer them as plots in three rows . in the first row of figures [ fig1]-[fig7 ]",
    "we can see on the left the exact power in all the scenarios for the test - statistic @xmath384}$ ] and on the right for the test - statistic @xmath385}$ ] . in order to make a comparison of exact powers",
    ", we can not directly proceed without considering the exact sizes . for this reason we are going to give a procedure based on two steps , for scenarios b - g .    _ step 1 _ : we are going to check for all the power divergence based test - statistics the criterion given by dale ( 1986 ) , i.e. , @xmath386 with @xmath387 .",
    "we only consider the values of @xmath211  such that @xmath388  satisfies ( [ con1 ] ) with @xmath389 , then we shall only consider the test - statistics such that @xmath390   $ ] , in all the scenarios .",
    "this criterion has been considered for some authors , see for instance cressie et al .",
    "( 2003 ) and martn and pardo ( 2012 ) .",
    "the cases satisfying the criterion are marked in bold in table [ alfas ] , and comprise those values in the abscissa of the plot between the dashed band ( the dashed line in the middle represents the nominal size ) , and we can conclude that we must not consider in our study @xmath391 .    _ step 2 _ : we compare all the test statistics obtained in step 1 with the classical likelihood ratio test ( @xmath392 ) as well as the classical pearson test statistic ( @xmath393 ) .",
    "to do so , we have calculated the relative local efficiencies@xmath394 in figures [ fig2]-[fig7 ] the powers and the relative local efficiencies are summarized .",
    "the second rows of the figures represent @xmath395 , while in the third row is plotted @xmath396 , on the left it is considered @xmath397}$ ] and @xmath398}$ ] on the right . in figure [ fig1 ]",
    "we show only one row since it represents the atypical case in which the exact powers are less that the exact significance level for the values of @xmath211 satisfying the dale s criterion and so , it does not make sense to compare the powers .    2.8pt    [ c]l@xmath2{ccccccccccc}\\hline\\hline sc & $ ] _",
    "t_-1.5@xmath11_t_-1@xmath12_t_-1/2@xmath11_t_0@xmath12_t_2/3@xmath11_t_1@xmath12_t_1.5@xmath11_t_2@xmath12_t_3@xmath11_w@xmath399a@xmath400b@xmath401c@xmath402d@xmath403e@xmath404f@xmath405g@xmath406 + @xmath2{ccccccccccc}\\hline\\hline sc & $ ] _",
    "s_-1.5@xmath11_s_-1@xmath12_s_-1/2@xmath11_s_0@xmath12_s_2/3@xmath11_s_1@xmath12_s_1.5@xmath11_s_2@xmath12_s_3@xmath11_w@xmath399a@xmath407b@xmath408c@xmath409d@xmath410e@xmath411f@xmath412g@xmath413    2.8pt    [ c]cc@xmath414 & @xmath415 + esca_potencia_t.pdf & esca_potencia_s.pdf    2.8pt    [ c]cc@xmath414 & @xmath415 + escb_potencia_t.pdf & escb_potencia_s.pdf + escb_eficiencias_t.pdf & escb_eficiencias_s.pdf + escb_eficiencias_asterisco_t.pdf & escb_eficiencias_asterisco_s.pdf    2.8pt    [ c]cc@xmath414 & @xmath415 + escc_potencia_t.pdf & escc_potencia_s.pdf + escc_eficiencias_t.pdf & escc_eficiencias_s.pdf + escc_eficiencias_asterisco_t.pdf & escc_eficiencias_asterisco_s.pdf    2.8pt    [ c]cc@xmath414 & @xmath415 + escd_potencia_t.pdf & escd_potencia_s.pdf + escd_eficiencias_t.pdf & escd_eficiencias_s.pdf + escd_eficiencias_asterisco_t.pdf & escd_eficiencias_asterisco_s.pdf    2.8pt    [ c]cc@xmath414 & @xmath415 + esce_potencia_t.pdf & esce_potencia_s.pdf + esce_eficiencias_t.pdf & esce_eficiencias_s.pdf + esce_eficiencias_asterisco_t.pdf & esce_eficiencias_asterisco_s.pdf    2.8pt    [ c]cc@xmath414 & @xmath415 + escf_potencia_t.pdf & escf_potencia_s.pdf + escf_eficiencias_t.pdf & escf_eficiencias_s.pdf + escf_eficiencias_asterisco_t.pdf & escf_eficiencias_asterisco_s.pdf    2.8pt    [ c]cc@xmath414 & @xmath415 + escg_potencia_t.pdf & escg_potencia_s.pdf + escg_eficiencias_t.pdf & escg_eficiencias_s.pdf + escg_eficiencias_asterisco_t.pdf & escg_eficiencias_asterisco_s.pdf    the plots are interpreted as follows:*a ) * in all the scenarios a similar pattern is observed when plotting the exact power , @xmath416 , for @xmath417 $ ] since a u shaped curve is obtained .",
    "this means that the exact power is higher in the corners of the interval in comparison with the classical likelihood ratio test ( @xmath392 ) as well as the classical pearson test statistic ( @xmath393 ) , contained in the middle.*b ) * if we pay attention on the local efficiencies with respect to @xmath125 and @xmath127 , @xmath395 and @xmath396 , to find positive values of them we need to consider @xmath418 or @xmath419 $ ] and thus it confirms what was said in a ) . on the other hand , comparing the left hand ( @xmath420 ) side of @xmath395 with the right side ( @xmath421 ) and doing the same for @xmath396 , a slightly higher values of the local efficiencies of @xmath415 are seen in comparison with @xmath414 .",
    "for this reason we consider that @xmath422 have a better performance than the classical test - statistics , @xmath125 and @xmath127 in scenarios b - e and @xmath423}$ ] have a better performance than the classical test - statistics , @xmath125 and @xmath127 in scenarios f - g .",
    "the wilcoxon test - statistic has in all the scenarios worse performance with respect to the best classical asymptotic statistic , @xmath125 for scenarios b - e and @xmath127 for scenarios f - g.*c ) * what is not so common in comparison with usual models of categorical data is to find small size sample sizes with so good performance in exact size as it happens in the case of the likelihood ratio order .",
    "moreover , the best test - statistic are not very common to be selected as those with better performance than the classical ones .",
    "the likelihood ratio ordering is a useful technique for comparing treatments in clinical trials , for this reason it is vitally important to provide test - statistics to improve the classical ones .",
    "having considered an asymptotic distribution for two order restricted treatments , the weights needed to manage the associated asymptotic chi - bar distribution are calculated in a simple way and the useful matrix for that , @xmath424 , has an easy interpretation in terms of log - linear modeling .",
    "the simulation study highlights the good performance of the all the proposed tests in relation to the exact size and the comparison is made in terms of the power . for small and moderate sample sizes",
    "there are better choices than the likelihood ratio test and the wilcoxon test - statistics inside the family of @xmath118-divergences .",
    "we think that this is a specific characteristic of the likelihood ordering , and this is the reason of having obtained as the best test - statistics a set of values of @xmath425 $ ] not very common in the literature of phi - divergence test - statistics . as exception ,",
    "notice that@xmath426 where@xmath427 is the hellinger distance between the probability vectors @xmath99  and @xmath98 .",
    "therefore , one of the test - statistic we are proposing in this paper is a function of the well - known hellinger distance , which has been used in many different statistical problems .",
    "we think that the reason why this happens is related to the robust properties of such a test - statistic , since when dealing with the likelihood ratio ordering , under the alternative hypothesis , on the left side of the contingency table empty cells tend to appear .",
    "in particular , the theoretical probability in the first cell for the second treatment , @xmath428 , is the smallest one and this circumstance does influence in the results obtained for skew sample sample sizes in both treatments .",
    "the authors acknowledge the referee .",
    "we modified and improved the manuscript according to comments and questions pointed by the referee .",
    "99    barlow , r. e. , bartholomew , d. j. and brunk , h.d .",
    "_ statistical inference under order restrictions_. wiley .",
    "bazaraa , m. s. , sherali , h. d. and shetty , c. m. ( 2006 ) .",
    "_ nonlinear programming : theory and algorithms _",
    "( 3rd edition ) .",
    "john wiley and sons .",
    "christensen , r. ( 1997 ) .",
    "_ log - linear models and logistic regression_. springer .",
    "cressie , n. and pardo , l. ( 2002 ) .",
    "phi - divergence statistics . _ encyclopedia of environmetrics _ ( a. h. elshaarawi and w. w. piegorich , eds . ) .",
    "volume 3 , 1551 - 1555 , john wiley and sons , new york .",
    "cressie , n. and pardo , l. ( 2003 ) .",
    "minimum phi - divergence estimator and hierarchical testing in loglinear models .",
    "_ statistica sinica _ , * 10 * , 867 - 884 .",
    "cressie , n. , pardo , l. and pardo , m.c .",
    "size and power considerations for testing loglinear models using @xmath118-divergence test statistics .",
    "_ statistica sinica _ , * 13 * , 550 - 570 .",
    "dale , j.r .",
    "asymptotic normality of goodness - of - fit statistics for sparse product multinomials .",
    "_ journal of the royal statistical society _ , * b * , 48 - 59 .",
    "dykstra , r. l. , kocbar , s. and robertson , t. ( 1995 ) .",
    "inference for likelihood ratio ordering in the two - sample problem .",
    "_ journal of the american statistical association _ ,",
    "* 90 * , 1034 - 1040 .    doll , r. and pygott , f. ( 1952 ) .",
    "factors influencing the rate of healing of gastric ulcers .",
    "_ lancet _ , *  259 * , 171 - 175 .",
    "harville , d. a. ( 2008 ) . _ matrix algebra from a statistician s perspective_. springer .",
    "ferguson , t. s. ( 1996 ) .",
    "_ a course in large sample theory_. chapman & hall .",
    "kud , a. ( 1963 ) . a multivariate analogue of the one - sided test . _ biometrika _ , * 50 * , 403 - 418 .",
    "lang , j. b. ( 1996 ) . on the comparison of multinomial and poisson log - linear models .",
    "_ journal of the royal statistical society series b _ , 58 , 253 - 266 .",
    "letierce ; a.,tubert - bitter , p. , kramar , a. and maccario , j. ( 2003 ) .",
    "two - treatment comparison based on joint toxicity and efficacy ordered alternatives in cancer trials . _",
    "statistics in medicine _ , * 22 * , 859868 .    martin , n. and pardo , l.(2006 ) . choosing the best phi - divergence goodness - of - fit statistic in multinomial sampling for loglinear models with linear constraints .",
    "_ kybernetika _ , * 42 * , 711722 .",
    "martin , n. and pardo , l.(2008a ) .",
    "new families of estimators and test statistics in log - linear models .",
    "_ journal of multivariate analysis , _ * 99*(8 ) , 15901609 .",
    "martin , n. and pardo , l. ( 2008b ) .",
    "phi - divergence estimators for loglinear models with linear constraints and multinomial sampling .",
    "_ statistical papers _ , * 49 * , 1536    martin , n. and pardo , l. ( 2011 ) .",
    "fitting dna sequences through log - linear modelling with linear constraints . _",
    "statistics : a journal of theoretical and applied statistics _ , * 45 * , 605 - 621 .",
    "martin , n. and pardo , l. ( 2012 ) .",
    "poisson - loglinear modeling with linear constraints on the expected cell frequencies .",
    "_ sankhya b _ , * 74*(2 ) , 238 - 267 .",
    "mehta , c.r . ,",
    "patel , n.r . and tsiatis , a.a .",
    "exact significance testing to establish treatment equivalence with ordered categorical data . _ biometrics _ , * 40*(3 ) , 819 - 825 .",
    "pardo , l. ( 2006 ) .",
    "_ statistical inference based on divergence measures_. statistics : series of textbooks and monograhps .",
    "chapman & hall / crc .",
    "sen , p. k. , singer , j. m. and pedroso de lima , a. c. ( 2010 ) .",
    "_ from finite sample to asymptotic methods in statistics_. cambridge university press .",
    "shan , g. and ma , c. ( 2004 ) .",
    "unconditional tests for comparing two ordered multinomials .",
    "statistical methods in medical research ( in press ) .",
    "doi : http://dx.doi.org/10.1177/0962280212450957    shapiro , a. ( 1985 ) .",
    "asymptotic distribution of test statistics in the analysis of moment structures under inequality constraints .",
    "_ biometrika _ , * 72 * , 133144 .",
    "shapiro , a. ( 1988 ) . toward a unified theory of inequality constrained testing in multivariate analysis .",
    "_ international statistical review _ , * 56 * , 4962 .",
    "silvapulle , m. j. and sen . , p. k. ( 2005 ) .",
    "_ constrained statistical inference .",
    "inequality , order , and shape restrictions_. wiley series in probability and statistics .",
    "wiley - interscience ( john wiley & sons ) .",
    "zografos , k. , ferentinos , k. and papaioannou , t. ( 1990 ) .",
    "@xmath118-divergence statistics : sampling properties and multinomial goodness of fit and divergence tests .",
    "_ communications in statistics - theory and methods _",
    ", * 19 * , 1785 - 1802 .",
    "suppose we are interested in testing @xmath91 : @xmath429 vs  @xmath430 and @xmath431 . with the complete notation ,",
    "our interest is,@xmath432 under @xmath91 , the parameter space is @xmath433 and the mle of @xmath60 in @xmath93 is given by @xmath94 .",
    "under the alternative hypothesis the parameter space is @xmath434 , where @xmath435 , that is , under both hypotheses , @xmath91  and @xmath436 , the parameter space is @xmath437 and the mle of @xmath60 in @xmath438 is @xmath439 . by following the same idea we used for building test - statistics ( [ 5a])-([5b ] ) we shall consider two family of test - statistics based on @xmath118-divergence measures,@xmath440 and@xmath441      under @xmath91 , @xmath442 the asymptotic distribution of ( [ 5ab ] )  and ( [ 5bb ] ) is @xmath443 with @xmath444@xmath445 .",
    "the second order taylor expansion of function @xmath446 about @xmath188 is@xmath447 where@xmath448 and @xmath128 was defined at the beginning of section [ sec : main results ] .",
    "let @xmath449 be the parameter vector such that @xmath450 , where @xmath451 , with @xmath452 , is the saturated log - linear model .",
    "in particular , for @xmath453 we have@xmath454 in a similar way it is obtained@xmath455 multiplying both sides of the equality by @xmath456 and taking the difference in both sides of the equality@xmath457 now we are going to generalize the three types of estimators by @xmath458 , understanding that for @xmath459 , @xmath460 , @xmath461 , for @xmath462 , @xmath463 , @xmath464 , and @xmath465 , @xmath466 and @xmath158 as originally defined .",
    "it is well - known that@xmath467 where @xmath151 is the true and unknown value of the parameter,@xmath468 is the variance covariance matrix of @xmath469 ,  and @xmath470 by the central limit theorem .",
    "we shall denote@xmath471 taking the differences of both sides of the equality in ( [ eq14 ] ) with cases @xmath459  and @xmath462 , we obtain@xmath472 with cases @xmath459  and @xmath465,@xmath473 and taking into account @xmath474,@xmath475 where@xmath476 with @xmath477 and @xmath478  is the cholesky s factorization matrix for a non singular matrix such a fisher information matrix , that is @xmath479 . in other words@xmath480 where the variance covariance matrix is idempotent and symmetric .",
    "following lemma 3 in ferguson ( 1996 , page 57 ) , @xmath481 is idempotent and symmetric , if only if @xmath482 is a chi - square random variable with degrees of freedom @xmath483 since@xmath484 the condition is reached .",
    "the effective degrees of freedom are given by@xmath485 regarding the other test - statistic @xmath486 , observe that if we take ( [ eq16 ] ) , in particular for @xmath487 it is obtained@xmath488 in addition , ( [ a])@xmath489([b ] ) is@xmath490 and taking into account @xmath474 and ( [ c ] ) , it follows ( [ d ] ) , which means from slutsky s theorem that both test - statistics have the same asymptotic distribution .",
    "let @xmath491 be a @xmath46-dimensional random variable with normal distribution @xmath492 with @xmath493 being a projection matrix , that is idempotent and symmetric , and let @xmath494 be the fixed @xmath46-dimensional vectors such that for them either @xmath495 or @xmath496 , @xmath497 , is true .",
    "then @xmath498 , where @xmath499 .",
    "this result can be found in several sources , for instance in kud ( 1963 , page 414 ) , barlow et al .",
    "( 1972 , page 128 ) and shapiro ( 1985 , page 139 ) .",
    "we shall perform the proof for @xmath500 .",
    "it suppose that it is true @xmath80 and we want to test @xmath501 ( @xmath91 ) .",
    "it is clear that if @xmath91 is not true is because there exists some index @xmath502 such that @xmath503 .",
    "let us consider the family of all possible subsets in @xmath157 , denoted by @xmath156 , then  we shall specify more thoroughly @xmath504 by @xmath505 when there exists @xmath159 such that@xmath506 it is clear that for a sample @xmath507 can be true only for a unique set of indices @xmath159 , and thus by applying the theorem of total probability@xmath508 from the karush - khun - tucker necessary conditions ( see for instance theorem 4.2.13 in bazaraa et al .",
    "( 2006 ) ) to solve the optimization problem @xmath509 s.t .",
    "@xmath80 , associated with @xmath504 ,    @xmath510    the only conditions which characterize the mle @xmath511 with a specific @xmath159 , are the complementary slackness conditions @xmath503 , for @xmath512 and @xmath513 , for @xmath514 , since @xmath515 , @xmath516,@xmath517 , for @xmath514 and @xmath518 , for @xmath512 are redundant conditions once we know that the karush - khun - tucker necessary conditions are true for all the possible sets @xmath159 which define @xmath511 . for this reason we can consider    @xmath519    where @xmath520 is the vector of the vector of karush - khun - tucker multipliers associated with estimator @xmath505 . furthermore , under @xmath91 , @xmath521 , because @xmath522 , hence@xmath523 where @xmath524 . on the other hand , ( [ kkt1 ] ) and",
    "( [ kkt2 ] ) are also true for @xmath525 according to the lagrange multipliers method .",
    "hence , @xmath526 and @xmath527 .",
    "it follows that:@xmath275 under @xmath528 , @xmath529 and taking into account proposition [ th1contr ] @xmath530 where @xmath531.@xmath532 under @xmath527 and from sen et al .",
    "( 2010 , page 267 formula ( 8.6.28))@xmath533 where@xmath534 @xmath275 under @xmath528 and from ( [ eq14])@xmath535 that is,@xmath536 where@xmath537 taking into account that @xmath538 and @xmath539 , by applying the lemma given in section [ lemcontra]@xmath540 where@xmath541 finally,@xmath542 and since @xmath543 , it holds @xmath544 which means that @xmath545 and @xmath546 are independent , that is@xmath547 where the expression of @xmath548 is ( [ eqw ] ) .",
    "we have also , @xmath549@xmath550 the proof of @xmath169 is almost immediate from the proof for @xmath500 and taking into account that for some @xmath159@xmath551",
    ".... ! -------------------------------------------------------------------------------- !",
    "this program is only valid for 2 by 4 contingency tables ! ( for other sizes some changes must be done : ! change the value of j and follow the formulas of the weights ) ! to run it , the nag library is required to have installed ! to change the sample go to line 18 ! the fortran program generates the outputs in 8 text files ! -------------------------------------------------------------------------------- module parglob integer fail integer , parameter : : i=2 , j=4 , nlam=9 double precision pr(i*j ) , w(i*j , i*j-1 ) , rr((i-1)*(j-1),i*(j-1 ) ) , betatil(i*(j-1 ) ) , &     phat(i*j ) , zz((i-1)*(j-1 ) ) , tbt((i-1)*(j-1),(i-1)*(j-1 ) ) , bb((i-1)*(j-1),(i-1)*(j-1 ) ) , &     we(0:(i-1)*(j-1 ) ) , k1((i-1),(i-1 ) ) , k2((j-1),(j-1 ) ) , hh((i-1)*(j-1),(i-1)*(j-1 ) ) , &     hinv((i-1)*(j-1),(i-1)*(j-1 ) ) , ntt , nu(i ) , ppi(j ) , nn(i*j ) , ppit(i , j ) , un , sample(i*j ) , &     odds(i-1,j-1 ) , nt(i ) double precision , parameter : : lamb(nlam)=(/-1.5d0,-1.d0,-0.5d0,0.d0,2.d0/3.d0,1.d0,1.5d0 , &     2.d0,3.d0/),del=0.0d0 , pi=3.14159265358979323846264338327950d0 , sample=(/11.d0,8.d0 ,     &     8.d0,5.d0,6.d0,4.d0,10.d0,12.d0/ ) end module parglob ! --------------------------------------------------------------------------------",
    "program example use parglob implicit none    integer n , m , ifail double precision estt , ests , pval , table(i , j ) , contt(nlam ) , conts(nlam ) , initheta(i*j-1 ) , &     ro(3,2 ) , marg(j ) , rank(j ) , wilc0 , wilc , meanwilc , sdwilc , pvalwilc , g01eaf    do n=1,i   do m=1,j    ppit(n , m)=(1.d0/3.d0)*((1.d0+n*(m-1.d0)*del)/(1.d0+n*del ) )   enddo enddo do n=1,i-1   do m=1,j-1    odds(n , m)=ppit(n , m)*ppit(n+1,m+1)/(ppit(n+1,m)*ppit(n , m+1 ) )   enddo enddo    marg = sample(1:j)+sample(j+1:2*j ) rank=0.d0 do n=2,j   rank(n)=rank(n-1)+marg(n-1 ) enddo rank = rank+(marg+1.d0)/2.d0 wilc0=sum(rank*sample(1:j ) ) nt(1)=sum(sample(1:j ) ) nt(2)=sum(sample(j+1:2*j ) ) ntt = sum(nt ) nu = nt / ntt meanwilc = nt(1)*(nt(1)+nt(2)+1.d0)/2.d0 sdwilc = nt(1)*nt(2)*(nt(1)+nt(2)+1.d0)/12.d0 sdwilc = sdwilc - nt(1)*nt(2)*sum(marg**3-marg)/(12.d0*(nt(1)+nt(2))*(nt(1)+nt(2)-1.d0 ) ) sdwilc = sqrt(sdwilc ) wilc=(wilc0-meanwilc)/sdwilc call designm ( ) call restricm ( )    nn = sample table = transpose(reshape(nn,(/j , i/ ) ) ) do m=1,j   ppi(m)=sum(table(:,m))/ntt enddo initheta=0.d0 call emvh01(initheta ) if ( fail.ne.0 ) then   initheta=0.1d0   call emvh01(initheta )   if ( fail.ne.0 ) then    initheta=-0.1d0    call emvh01(initheta )   endif endif    21 format ( 20f10.4 ) 22 format ( 20f15.10 )    open ( 10 , file = \" theta-tilde.dat \" , action=\"write\",status=\"replace \" ) write(10 , * ) \"     * *          theta tilde          * * \" write(10 , * ) \"     --------------------------------- \" write(10,21 ) ( betatil(m ) , m=1,i*(j-1 ) ) close(10 )    open ( 10 , file = \" p-bar.dat \" , action=\"write\",status=\"replace \" ) write(10 , * ) \"     * *     probability vector : p - bar     * * \" write(10 , * ) \"     ------------------------------------- \" write(10,21 ) ( nn(n)/(sum(nn ) ) , n=1,i*j ) close(10 )    open ( 10 , file = \" p-theta-tilde.dat \" , action=\"write\",status=\"replace \" ) write(10 , * ) \"     * *     probability vector : p - theta - tilde     * * \" write(10 , * ) \"     --------------------------------------------- \" write(10,21 ) ( pr(n ) , n=1,i*j ) close(10 )    call probvector2(nu , ppi ) open ( 10 , file = \" p-theta-hat.dat \" , action=\"write\",status=\"replace \" ) write(10 , * ) \"     * *     probability vector : p - theta - hat     * * \" write(10 , * ) \"     ------------------------------------------- \" write(10,21 ) ( phat(n ) , n=1,i*j ) close(10 )    call kmatrices ( ) call hmatrix ( )    ro(1,1)=hh(1,2)/sqrt(hh(1,1)*hh(2,2 ) ) ro(2,1)=hh(1,3)/sqrt(hh(1,1)*hh(3,3 ) ) ro(3,1)=hh(2,3)/sqrt(hh(2,2)*hh(3,3 ) ) ro(1,2)=(ro(1,1)-ro(2,1))/sqrt((1.d0-ro(2,1)*ro(2,1))*(1.d0-ro(3,1)*ro(3,1 ) ) ) ro(2,2)=(ro(2,1)-ro(1,1)*ro(3,1))/sqrt((1.d0-ro(1,1)*ro(1,1))*(1.d0-ro(3,1)*ro(3,1 ) ) ) ro(3,2)=(ro(3,1)-ro(2,1)*ro(1,1))/sqrt((1.d0-ro(2,1)*ro(2,1))*(1.d0-ro(1,1)*ro(1,1 ) ) ) we(0)=(2.d0*pi - acos(ro(1,1))-acos(ro(2,1))-acos(ro(3,1)))/(4.d0*pi ) we(1)=(3.d0*pi - acos(ro(1,2))-acos(ro(2,2))-acos(ro(3,2)))/(4.d0*pi ) we(2)=0.5d0-we(0 ) we(3)=0.5d0-we(1 )    ifail=-1 pvalwilc = g01eaf('l',wilc , ifail )    open ( 10 , file = \" t-tests.dat \" , action=\"write\",status=\"replace \" ) write(10 , * ) \"     * *      t - test statistics      * * \" write(10 , * ) \"     -------------------------------- \" write(10,21 ) ( lamb(n ) , n=1,nlam ) write(10 , * ) ' test - statistics ' write(10,21 ) ( estt(lamb(n ) ) , n=1,nlam ) write(10 , * ) ' p - values ' write(10,22 ) ( pval(estt(lamb(n ) ) ) , n=1,nlam ) write(10 , * ) \"     * *      wilcoxon statistics      * * \" write(10 , * ) \"     --------------------------------- \" write(10 , * ) ' test - statistic ' write(10,21 ) wilc0 write(10 , * ) ' p - value ' write(10,21 ) pvalwilc close(10 )    open ( 10 , file = \" s-tests.dat \" , action=\"write\",status=\"replace \" ) write(10 , * ) \"     * *      s - test statistics      * * \" write(10 , * ) \"     -------------------------------- \" write(10,21 ) ( lamb(n ) , n=1,nlam ) write(10 , * ) ' test - statistics ' write(10,21 ) ( ests(lamb(n ) ) , n=1,nlam ) write(10 , * ) ' p - values ' write(10,22 ) ( pval(ests(lamb(n ) ) ) , n=1,nlam ) write(10 , * ) \"     * *      wilcoxon statistics      * * \" write(10 , * ) \"     --------------------------------- \" write(10 , * ) ' test - statistic ' write(10,21 ) wilc0 write(10 , * ) ' p - value ' write(10,21 ) pvalwilc close(10 )    open ( 10 , file = \" weights.dat \" , action=\"write\",status=\"replace \" ) write(10 , * ) \"     * *      weights chi - bar      * * \" write(10 , * ) \"     ----------------------------- \" write(10 , * ) \" \" write(10,22 ) ( real(we(n ) ) , n=0,(i-1)*(j-1 ) ) write(10 , * ) \"     ---------------------------------------------------------- \" close(10 )    end program example !",
    "this soubrutine calculates the design matrix of a saturated log - linear model ! with canonical parametrization ! -------------------------------------------------------------------------------- subroutine designm ( ) use parglob implicit none    integer h    double precision one_i(i ) , one_j(j ) , a(i , i-1 ) , b(j , j-1 ) , w12(i*j,(i-1)*(j-1 ) ) , &                   w1(i*j , i-1 ) , w2(i*j , j-1 )    one_i=1.d0 one_j=1.d0 a=0.d0 do h=1,i-1   a(h , h)=1.d0 enddo b=0.d0 do h=1,j-1   b(h , h)=1.d0 enddo    call kronecker(i , i-1,a , j,1,one_j , w1 ) call kronecker(i,1,one_i , j , j-1,b , w2 ) call kronecker(i , i-1,a , j , j-1,b , w12 )    w(:,1:i-1)=w1 w(:,i : i+j-2)=w2 w(:,i+j-1:i*j-1)=w12     end subroutine designm ! --------------------------------------------------------------------------------    ! --------------------------------------------------------------------------------",
    "this soubrutines calculates the restriction matrix !",
    "-------------------------------------------------------------------------------- subroutine restricm ( ) use parglob implicit none    integer h double precision r2((i-1)*(j-1),j-1 ) , r12((i-1)*(j-1),(i-1)*(j-1 ) ) , gi(i-1,i-1 ) , &                   gj(j-1,j-1 )    gi=0.d0 do h=1,i-1    gi(h , h)=1.d0    if ( h.lt.i-1 ) then      gi(h , h+1)=-1.d0    endif enddo gj=0.d0 do h=1,j-1    gj(h , h)=1.d0    if ( h.lt.j-1 ) then      gj(h , h+1)=-1.d0    endif enddo r2 = 0.d0 call kronecker(i-1,i-1,gi , j-1,j-1,gj , r12 ) rr(1:(i-1)*(j-1),1:j-1 ) = r2 rr(1:(i-1)*(j-1),j : i*(j-1 ) ) = r12    end subroutine restricm ! --------------------------------------------------------------------------------    ! -------------------------------------------------------------------------------- ! given matrices a and b , this subroutines calculates c as the kronecker product ! a 's dimension n by m !",
    "b 's dimension p by q ! -------------------------------------------------------------------------------- subroutine kronecker(n , m , a , p , q , b , c ) implicit none    integer n , m , p , q double precision a(n , m ) , b(p , q ) , c(n*p , m*q ) integer i , j , k , d    do i=1,n   do j=1,m    do k=1,p     do d=1,q      c((i-1)*p+k,(j-1)*q+d ) = a(i , j)*b(k , d )     enddo    enddo   enddo enddo    end subroutine kronecker ! --------------------------------------------------------------------------------    ! -------------------------------------------------------------------------------- ! given !",
    "a ) vector theta !",
    "b ) the design matrix x=(1,w ) ! this subroutine calculates the probabilities of a log - linear model . !",
    "-------------------------------------------------------------------------------- subroutine probvector(beta ) use parglob implicit none    integer n double precision beta(i*(j-1 ) ) , theta(i*j-1 ) , u    theta(i : i*j-1)=beta u = log(nt(i))-log(ntt)-log(1.d0+sum(exp(beta(1:j-1 ) ) ) ) do n=1,i-1   theta(n)=log(nt(n))-log(ntt)-u - log(1.d0+sum(exp(beta(1:j-1)+ &            beta(n*(j-1)+1:(n+1)*(j-1 ) ) ) ) ) enddo    pr = exp(matmul(w , theta))*exp(u )    end subroutine probvector ! --------------------------------------------------------------------------------    ! -------------------------------------------------------------------------------- ! subroutine to calculate p(theta - hat ) !",
    "-------------------------------------------------------------------------------- subroutine probvector2(nnu , pppi ) use parglob implicit none    integer h , s double precision nnu(i ) , pppi(j ) , aux(i , j )    do h=1,i   do s=1,j     if ( pppi(s).gt.0.d0 ) then      aux(h , s)=nnu(h)*pppi(s )     else      aux(h , s)=1.d-5     endif   enddo enddo phat = reshape(transpose(aux),(/i*j/ ) )     end subroutine probvector2 ! --------------------------------------------------------------------------------    ! -------------------------------------------------------------------------------- ! subroutine to calculate theta_tilde . !",
    "--------------------------------------------------------------------------------    subroutine emvh01(x ) use parglob implicit none    integer , parameter : : n = i*j-1 , nclin = ( i-1)*(j-1 ) , ncnln = 0 , lda = nclin integer , parameter : : ldcj = 1 , ldr = n , liw= 3*n+nclin+2*ncnln , lw=530 integer   iter , ifail , istate(n+nclin+ncnln ) ,",
    "iwork(liw ) , iuser(1 ) , nstate double precision objf , a(nclin , n ) , user(1 ) , work(lw ) , r(ldr , n ) , c(ncnln ) , cjac(ldcj , n ) double precision clamda(n+nclin+ncnln ) , bl(n+nclin+ncnln ) , bu(n+nclin+ncnln ) , x(n ) , objgrd(n ) external confun , e04ucf , e04uef , objfun    a=0.d0 a(:,i : i*j-1)=rr bl(1:n)=-1.d6 bl(n+1:n+nclin)=0.d0 bu=1.d6 ifail = -1 call e04uef ( ' infinite bound size = 1.e5 ' ) call e04uef ( ' iteration limit = 250 ' ) call e04uef ( ' print level = 0 ' ) call e04ucf(n , nclin , ncnln , lda , ldcj , ldr , a , bl , bu , confun , objfun , iter , istate , c , &    cjac , clamda , objf , objgrd , r , x , iwork , liw , work , lw , iuser , user , ifail ) betatil = x(i : i*j-1 ) fail = ifail end subroutine emvh01    subroutine objfun(mode , n , x , objf , objgrd , nstate , iuser , user ) use parglob implicit none integer   mode , n , iuser(1 ) , nstate double precision objf , objgrd(n ) , x(n ) , user(1 )    call probvector(x(i : i*(j-1 ) ) ) if ( mode .eq.0 .or .",
    "mode .eq.2 ) then    objf = -sum(nn*log(pr ) ) endif if ( mode .eq.1 .or . mode .eq.2 ) then    objgrd = matmul(transpose(w),sum(nn)*pr - nn ) endif end    subroutine confun ( mode , ncnln , g , ldcj , needc , x , c , cjac , nstate , iuser , user ) integer mode , ncnln , g , ldcj , needc ( * ) , nstate , iuser ( * ) double precision x ( * ) , c ( * ) , cjac(ldcj , * ) , user ( * )    end    ! -------------------------------------------------------------------------------- !",
    "subroutine to calculate t - statistic . !",
    "--------------------------------------------------------------------------------    function estt(lan ) use parglob implicit none    double precision estt , lan , aux , n",
    "integer h    n = sum(nn ) aux=0.d0 if ( ( lan .ge .",
    "-1.d-9 ) .and .",
    "( lan .le .",
    "1.d-9 ) ) then     ! lan=0   do h=1,i*j    if ( ( pr(h).gt.0.d0).and.(phat(h).gt.0.d0 ) ) then     aux = aux+nn(h)*log(pr(h)/phat(h ) )    endif   enddo   estt=2.d0*aux else   if ( ( lan .ge .",
    "-1.d0 - 1.d-9 ) .and .",
    "( lan .le .",
    "-1.d0 + 1.d-9 ) ) then     !",
    "lan=-1    do h=1,i*j     if ( ( pr(h).gt.0.d0).and.(phat(h).gt.0.d0).and.(nn(h).gt.0.5d0 ) ) then      aux = aux+phat(h)*log((n*phat(h))/nn(h ) )      aux = aux - pr(h)*log((n*pr(h))/nn(h ) )     endif    enddo    estt=2.d0*n*aux   else      ! lan<>0 , lan<>-1    do h=1,i*j     if ( ( pr(h).gt.0.d0).and.(phat(h).gt.0.d0).and.(nn(h).gt.0.5d0 ) ) then      aux = aux+nn(h)*((nn(h)/(n*phat(h)))**lan-(nn(h)/(n*pr(h)))**lan )     endif    enddo    estt=2.d0*aux/(lan*(1.d0+lan ) )   endif endif    end function estt    ! -------------------------------------------------------------------------------- !",
    "subroutine to calculate s - statistic . !",
    "--------------------------------------------------------------------------------    function ests(lan ) use parglob implicit none    double precision ests , lan , aux , n integer",
    "h    n = sum(nn ) aux=0.d0 if ( ( lan .ge .",
    "-1.d-9 ) .and .",
    "( lan .le .",
    "1.d-9 ) ) then     ! lan=0   do h=1,i*j    if ( ( pr(h).gt.0.d0).and.(phat(h).gt.0.d0 ) ) then     aux = aux+pr(h)*log(pr(h)/phat(h ) )    endif   enddo   ests=2.d0*n*aux else   if ( ( lan .ge .",
    "-1.d0 - 1.d-9 ) .and .",
    "( lan .le .",
    "-1.d0 + 1.d-9 ) ) then     !",
    "lan=-1    do h=1,i*j     if ( ( pr(h).gt.0.d0).and.(phat(h).gt.0.d0 ) ) then      aux = aux+phat(h)*log(phat(h)/pr(h ) )     endif    enddo    ests=2.d0*n*aux   else      ! lan<>0 , lan<>-1    do h=1,i*j     if ( ( pr(h).gt.0.d0).and.(phat(h).gt.0.d0 ) ) then      aux = aux+(pr(h)**(lan+1.d0))/(phat(h)**lan )     endif    enddo    ests=2.d0*n*(aux-1.d0)/(lan*(1.d0+lan ) )   endif endif    end function ests    ! -------------------------------------------------------------------------------- !",
    "subroutine to calculate matrix k. ! --------------------------------------------------------------------------------    subroutine kmatrices ( ) use parglob implicit none    integer n    k1=0.d0 do n=1,i-1   k1(n , n)=(nu(n)+nu(n+1))/(nu(n)*nu(n+1 ) )   if ( n.ge.2 ) then     k1(n , n-1)=-1.d0/nu(n )   endif   if ( n.le.i-2 ) then     k1(n , n+1)=-1.d0/nu(n+1 )   endif enddo    k2=0.d0 do n=1,j-1   k2(n , n)=(ppi(n)+ppi(n+1))/(ppi(n)*ppi(n+1 ) )   if ( n.ge.2 ) then     k2(n , n-1)=-1.d0/ppi(n )   endif   if ( n.le.j-2 ) then     k2(n , n+1)=-1.d0/ppi(n+1 )   endif enddo    end subroutine kmatrices    ! -------------------------------------------------------------------------------- ! subroutine to calculate matrix h. !",
    "--------------------------------------------------------------------------------    subroutine hmatrix ( ) use parglob implicit none    call kronecker(i-1,i-1,k1,j-1,j-1,k2,hh )    end subroutine hmatrix     ! -------------------------------------------------------------------------------- ! soubrotine to calculate p - values in terms of a specific lambda : t(lam ) o s(lam ) ! --------------------------------------------------------------------------------    function pval(est )",
    "use parglob implicit none    integer n , ifail double precision pval , est , aux , g01ecf    if ( est.le.0.d0 ) then aux=1.d0 else   aux=0.d0   do n=1,(i-1)*(j-1 )    ifail=-1    aux = aux+g01ecf('u',est , n*1.d0,ifail)*we((i-1)*(j-1)-n )   enddo   if ( est.lt.0 ) then    aux = aux+we((i-1)*(j-1 ) )   endif endif pval = aux    end function pval ....",
    ".... ! -------------------------------------------------------------------------------- !",
    "this program is only valid for 2 by 3 contingency tables ! ( for other sizes some changes must be done : ! change the value of j and follow the formulas of the weights ) ! to run it , the nag library is required to have installed !",
    "the fortran program generates the outputs in several text files ! -------------------------------------------------------------------------------- module parglob integer fail integer , parameter : : i=2 , j=3 , nrr=25000 , nlam=301 double precision pr(i*j ) , w(i*j , i*j-1 ) , rr((i-1)*(j-1),i*(j-1 ) ) , betatil(i*(j-1 ) ) , &    phat(i*j ) , zz((i-1)*(j-1 ) ) , tbt((i-1)*(j-1),(i-1)*(j-1 ) ) , bb((i-1)*(j-1),(i-1)*(j-1 ) ) , &    we(0:(i-1)*(j-1 ) ) , k1((i-1),(i-1 ) ) , k2((j-1),(j-1 ) ) , hh((i-1)*(j-1),(i-1)*(j-1 ) ) , &    hinv((i-1)*(j-1),(i-1)*(j-1 ) ) , ntt , nu(i ) , ppi(j ) , nn(i*j ) , ppit(i , j ) , un , &    sample(nrr , i*j ) , odds(i-1,j-1 ) ,",
    "lamb(nlam ) double precision , parameter : : nt(i ) = ( /16.d0,20.d0/ ) , starting=-1.5d0 , ending=3.d0 , &    del=0.d0 , pi=3.14159265358979323846264338327950d0        !",
    "if nlam=1 , the program only consideres the ending end module parglob ! --------------------------------------------------------------------------------        do n=1,nlam-1   lamb(n)=starting+(ending - starting)*(n*1.d0 - 1.d0)/(nlam*1.d0 ) enddo lamb(nlam)=ending contt=0.d0 conts=0.d0 contw=0.d0 do n=1,i   do m=1,j    ppit(n , m)=(1.d0/3.d0)*((1.d0+n*(m-1.d0)*del)/(1.d0+n*del ) )   enddo enddo do n=1,i-1   do m=1,j-1    odds(n , m)=ppit(n , m)*ppit(n+1,m+1)/(ppit(n+1,m)*ppit(n , m+1 ) )   enddo enddo ntt = sum(nt ) nu = nt / ntt call designm ( )      call g05cbf(150 ) call generamult ( ) do rep=1,nrr   nn = sample(rep , : )   do n=1,i*j    if ( nn(n).le.0.d0 ) then     nn(n)=1.d-5    endif   enddo   marg = nn(1:j)+nn(j+1:2*j )   rank=0.d0   do kk=2,j    rank(kk)=rank(kk-1)+marg(kk-1 )   enddo   rank = rank+(marg+1.d0)/2.d0   wilc = sum(rank*nn(1:j ) )   meanwilc = nt(1)*(nt(1)+nt(2)+1.d0)/2.d0   sdwilc = nt(1)*nt(2)*(nt(1)+nt(2)+1.d0)/12.d0   sdwilc = sdwilc - nt(1)*nt(2)*sum(marg**3-marg)/(12.d0*(nt(1)+nt(2))*(nt(1)+nt(2)-1.d0 ) )   sdwilc = sqrt(sdwilc )   wilc=(wilc - meanwilc)/sdwilc   ifail=-1   pvalwilc = g01eaf('l',wilc , ifail )   table = transpose(reshape(nn,(/j , i/ ) ) )   do m=1,j    ppi(m)=sum(table(:,m))/ntt   enddo   initheta=0.d0   call emvh01(initheta )   if ( fail.ne.0 ) then    initheta=0.1d0    call emvh01(initheta )    if ( fail.ne.0 ) then     initheta=-0.1d0     call emvh01(initheta )    endif   endif         if ( pvalwilc.le.0.05d0 ) then    contw = contw+1.d0   endif   do n=1,nlam    if ( pval(estt(lamb(n))).le.0.05d0 ) then     contt(n)=contt(n)+1.d0    endif    if ( pval(ests(lamb(n))).le.0.05d0 ) then     conts(n)=conts(n)+1.d0    endif   enddo enddo   open ( 10 , file = \" signlevt-2s.dat \" , action=\"write\",status=\"replace \" )   write(10 , * ) \"     * *      significance levels for t - test statistics      * * \"   write(10 , * ) \"     ------------------------------------------------------- \"   do n=1,nlam    write(10,21 ) real(lamb(n)),real(contt(n)/(nrr*1.d0 ) )   enddo   close(10 )     open ( 10 , file = \" signlevs-2s.dat \" , action=\"write\",status=\"replace \" )   write(10 , * ) \"     * *      significance levels for s - test statistics      * * \"   write(10 , * ) \"     ------------------------------------------------------- \"   do n=1,nlam    write(10,21 ) real(lamb(n)),real(conts(n)/(nrr*1.d0 ) )   enddo   close(10 )     open ( 10 , file = \" wilcoxon-2s.dat \" , action=\"write\",status=\"replace \" )   write(10 , * ) \"     * *      significance level for wilcoxon statistics      * * \"   write(10 , * ) \"     ------------------------------------------------------- \"   write(10 , * ) real(contw/(nrr*1.d0 ) )   close(10 )    end program simulation ! -------------------------------------------------------------------------------- ! this soubrutine calculates the design matrix of a saturated log - linear model ! with canonical parametrization ! -------------------------------------------------------------------------------- subroutine designm ( ) use parglob implicit none integer h double precision one_i(i ) , one_j(j ) , a(i , i-1 ) , b(j , j-1 ) , w12(i*j,(i-1)*(j-1 ) ) , &                   w1(i*j , i-1 ) , w2(i*j , j-1 )             ! -------------------------------------------------------------------------------- ! -------------------------------------------------------------------------------- !",
    "this soubrutines calculates the restriction matrix ! -------------------------------------------------------------------------------- subroutine restricm ( ) use parglob implicit none integer h double precision r2((i-1)*(j-1),j-1 ) , r12((i-1)*(j-1),(i-1)*(j-1 ) ) , gi(i-1,i-1 ) , &                   gj(j-1,j-1 )    gi=0.d0 do h=1,i-1    gi(h , h)=1.d0    if ( h.lt.i-1 ) then      gi(h , h+1)=-1.d0    endif enddo gj=0.d0 do h=1,j-1    gj(h , h)=1.d0    if ( h.lt.j-1 ) then      gj(h , h+1)=-1.d0    endif enddo r2 = 0.d0 call kronecker(i-1,i-1,gi , j-1,j-1,gj , r12 ) rr(1:(i-1)*(j-1),1:j-1 ) = r2 rr(1:(i-1)*(j-1),j : i*(j-1 ) ) = r12    end subroutine restricm ! -------------------------------------------------------------------------------- ! -------------------------------------------------------------------------------- ! given matrices a and b , this subroutines calculates c as the kronecker product !",
    "a 's dimension n by m !",
    "b 's dimension p by q !",
    "-------------------------------------------------------------------------------- subroutine kronecker(n , m , a , p , q , b , c ) implicit none        end subroutine kronecker ! --------------------------------------------------------------------------------   ! -------------------------------------------------------------------------------- ! given !",
    "a ) vector theta !",
    "b ) the design matrix x=(1,w ) ! this subroutine calculates the probabilities of a log - linear model . !",
    "-------------------------------------------------------------------------------- subroutine probvector(beta ) use parglob implicit none          end subroutine probvector ! -------------------------------------------------------------------------------- ! -------------------------------------------------------------------------------- ! subroutine to calculate p(theta - hat ) ! -------------------------------------------------------------------------------- subroutine probvector2(nnu , pppi ) use parglob implicit none      do h=1,i   do s=1,j     if ( pppi(s).gt.0.d0 ) then      aux(h , s)=nnu(h)*pppi(s )     else      aux(h , s)=1.d-5     endif   enddo enddo ! nuestros vectores est\\'{a}n en orden lexicogr\\'{a}fico , por eso trasponemos phat = reshape(transpose(aux),(/i*j/ ) )",
    "end subroutine probvector2 ! -------------------------------------------------------------------------------- ! -------------------------------------------------------------------------------- ! subroutine to calculate theta_tilde . !",
    "--------------------------------------------------------------------------------      integer , parameter : : n = i*j-1 , nclin = ( i-1)*(j-1 ) , ncnln = 0 , lda = nclin integer , parameter : : ldcj = 1 , ldr = n , liw= 3*n+nclin+2*ncnln , lw=530 integer   iter , ifail , istate(n+nclin+ncnln ) ,",
    "iwork(liw ) , iuser(1 ) , nstate double precision objf , a(nclin , n ) , user(1 ) , work(lw ) , r(ldr , n ) , c(ncnln ) , cjac(ldcj , n ) double precision clamda(n+nclin+ncnln ) , bl(n+nclin+ncnln ) , bu(n+nclin+ncnln ) , x(n ) , &       objgrd(n ) external confun , e04ucf , e04uef , objfun    a=0.d0 a(:,i : i*j-1)=rr bl(1:n)=-1.d6 bl(n+1:n+nclin)=0.d0 bu=1.d6 ifail = -1 call e04uef ( ' infinite bound size = 1.e5 ' ) call e04uef ( ' iteration limit = 250 ' ) call e04uef ( ' print level = 0 ' ) call e04ucf(n , nclin , ncnln , lda , ldcj , ldr , a , bl , bu , confun , objfun , iter , istate , c , &   cjac , clamda , objf , objgrd , r , x , iwork , liw , work , lw , iuser , user , ifail ) betatil = x(i : i*j-1 ) fail = ifail end subroutine emvh01                ! -------------------------------------------------------------------------------- !",
    "subroutine to calculate t - statistic . !",
    "n = sum(nn ) aux=0.d0 if ( ( lan .ge .",
    "-1.d-9 ) .and .",
    "( lan .le .",
    "1.d-9 ) ) then     ! lan=0   do h=1,i*j    if ( ( pr(h).gt.0.d0).and.(phat(h).gt.0.d0).and.(nn(h).gt.0.d0 ) ) then     aux = aux+nn(h)*log(pr(h)/phat(h ) )    endif   enddo   estt=2.d0*aux else   if ( ( lan .ge .",
    "-1.d0 - 1.d-9 ) .and .",
    "( lan .le .",
    "-1.d0 + 1.d-9 ) ) then     !",
    "lan=-1    do h=1,i*j     if ( ( pr(h).gt.0.d0).and.(phat(h).gt.0.d0).and.(nn(h).gt.0.5d0 ) ) then      aux = aux+phat(h)*log((n*phat(h))/nn(h ) )      aux = aux - pr(h)*log((n*pr(h))/nn(h ) )     endif    enddo    estt=2.d0*n*aux   else      ! lan<>0 ,",
    "lan<>-1    do h=1,i*j     if ( ( pr(h).gt.0.d0).and.(phat(h).gt.0.d0).and.(nn(h).gt.0.5d0 ) ) then      aux = aux+nn(h)*((nn(h)/(n*phat(h)))**lan-(nn(h)/(n*pr(h)))**lan )     endif    enddo    estt=2.d0*aux/(lan*(1.d0+lan ) )   endif endif       ! -------------------------------------------------------------------------------- !",
    "subroutine to calculate s - statistic . !",
    "n = sum(nn ) aux=0.d0 if ( ( lan .ge .",
    "-1.d-9 ) .and .",
    "( lan .le .",
    "1.d-9 ) ) then     ! lan=0   do h=1,i*j    if ( ( pr(h).gt.0.d0).and.(phat(h).gt.0.d0 ) ) then     aux = aux+pr(h)*log(pr(h)/phat(h ) )    endif   enddo   ests=2.d0*n*aux else   if ( ( lan .ge .",
    "-1.d0 - 1.d-9 ) .and .",
    "( lan .le .",
    "-1.d0 + 1.d-9 ) ) then     !",
    "lan=-1    do h=1,i*j     if ( ( pr(h).gt.0.d0).and.(phat(h).gt.0.d0 ) ) then      aux = aux+phat(h)*log(phat(h)/pr(h ) )     endif    enddo    ests=2.d0*n*aux   else      !",
    "lan<>0 , lan<>-1    do h=1,i*j     if ( ( pr(h).gt.0.d0).and.(phat(h).gt.0.d0 ) ) then      aux = aux+(pr(h)**(lan+1.d0))/(phat(h)**lan )     endif    enddo    ests=2.d0*n*(aux-1.d0)/(lan*(1.d0+lan ) )   endif endif                  ! -------------------------------------------------------------------------------- ! subroutine to calculate matrix h. ! -------------------------------------------------------------------------------- subroutine hmatrix ( ) use parglob implicit none call kronecker(i-1,i-1,k1,j-1,j-1,k2,hh ) end subroutine hmatrix ! -------------------------------------------------------------------------------- !",
    "soubrotine to calculate p - values in terms of a specific lambda : t(lam ) o s(lam ) ! --------------------------------------------------------------------------------",
    "if ( est.le.0.d0 ) then aux=1.d0 else   aux=0.d0   do n=1,(i-1)*(j-1 )    ifail=-1    aux = aux+g01ecf('u',est , n*1.d0,ifail)*we((i-1)*(j-1)-n )   enddo   if ( est.lt.0 ) then    aux = aux+we((i-1)*(j-1 ) )   endif endif pval = aux      !",
    "soubrotine to generate multinomial samples with the parameters specified as ! global parameters ( first lines of this program ) ! --------------------------------------------------------------------------------        c=0.d0 sample=0.d0 do n=1,i   do h=1,j    c(n , h)=c(n , h-1)+ppit(n , h )   enddo enddo do s=1,nrr   do n=1,i    do m=1,int(nt(n ) )     un = g05caf(un )     h=1     dowhile ( .not.((un.ge.c(n , h-1)).and.(un.lt.c(n , h ) ) ) )      h = h+1     enddo     sample(s,(n-1)*j+h)=sample(s,(n-1)*j+h)+1.d0    enddo   enddo enddo"
  ],
  "abstract_text": [
    "<S> in this paper new families of test statistics are introduced and studied for the problem of comparing two treatments in terms of the likelihood ratio order . </S>",
    "<S> the considered families are based on phi - divergence measures and arise as natural extensions of the classical likelihood ratio test and pearson test statistics . </S>",
    "<S> it is proven that their asymptotic distribution is a common chi - bar random variable . </S>",
    "<S> an illustrative example is presented and the performance of these statistics is analysed through a simulation study . through a simulation study </S>",
    "<S> it is shown that , for most of the proposed scenarios adjusted to be small or moderate , some members of this new family of test - statistic display clearly better performance with respect to the power in comparison to the classical likelihood ratio and the pearson s chi - square test while the exact size remains closed to the nominal size . in view of the exact powers and significance levels </S>",
    "<S> , the study also shows that the wilcoxon test - statistic is not as good as the two classical test - statistics .    </S>",
    "<S> = 1    _ _ keywords and phrases _ _ * * : * * divergence measure , kullback divergence measure , inequality constrains , likelihood ratio order , loglinear models . </S>"
  ]
}