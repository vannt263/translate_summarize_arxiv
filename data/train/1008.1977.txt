{
  "article_text": [
    "let @xmath0 denote @xmath1 letters of a process where each letter is drawn from a finite set @xmath2 with joint probability mass function ( pmf ) @xmath3 .",
    "let @xmath4 be a realization and suppose that we wish to guess this realization by asking questions of the form `` is @xmath5 ? '' , stepping through the elements of @xmath6 until the answer is `` yes '' . we wish to do this using the minimum expected number of guesses .",
    "there are several applications that motivate this problem .",
    "consider cipher systems employed in digital television or dvds to block unauthorized access to special features .",
    "the ciphers used are amenable to such exhaustive guessing attacks and it is of interest to quantify the effort needed by an attacker ( merhav & arikan @xcite ) .",
    "massey @xcite observed that the expected number of guesses is minimized by guessing in the decreasing order of @xmath7-probabilities .",
    "define the _ guessing function _",
    "@xmath8 to be one such optimal guessing order .",
    "@xmath9 implies that @xmath4 is the @xmath10th guess .",
    "arikan @xcite considered the growth of @xmath11 $ ] as a function of @xmath1 for an independent and identically distributed ( iid ) source with marginal pmf @xmath12 and @xmath13 .",
    "he showed that the growth is exponential in @xmath1 ; the limiting exponent @xmath14\\ ] ] exists and equals @xmath15 with @xmath16 , where @xmath17 is the rnyi entropy of order @xmath18 for the pmf @xmath7 , given by @xmath19 malone & sullivan @xcite showed that the limiting exponent @xmath20 of an irreducible markov chain exists and equals the logarithm of the _ perron - frobenius eigenvalue _ of a matrix formed by raising each element of the transition probability matrix to the power @xmath18 . from their proof , one obtains the more general result that the limiting exponent exists for any source if the rnyi entropy _ rate _ of order @xmath18 , @xmath21 exists for @xmath16 .",
    "pfister & sullivan @xcite showed the existence of ( [ eqn : limitingexponent ] ) for a class of stationary probability measures , beyond markov measures , that are supported on proper subshifts of @xmath22 @xcite .",
    "a particular example is that of shifts generated by finite - state machines .",
    "for such a class , they showed that the guessing exponent has a variational characterization ( see ( [ eqn : erho - iid ] ) later ) . for unifilar sources",
    "sundaresan @xcite obtained a simplification of this variational characterization using a direct approach and the method of types .",
    "merhav & arikan remark that their proof in @xcite for the limiting guessing exponent is equally applicable to finding the limiting exponent of the moment generating function of compression lengths . moreover , the two exponents are the same .",
    "the latter is a problem studied by campbell @xcite .",
    "our contribution is to give a large deviations perspective to these results , shed further light on the aforementioned connection between compression and guessing , and unify all prior results on existence of limiting guessing exponents .",
    "specifically , we show that if the sequence of distributions of the _ information spectrum _",
    "@xmath23 ( see han @xcite ) satisfies the _ large deviation property _",
    ", then the limiting exponent exists .",
    "this is useful because several existing large deviations results can be readily applied .",
    "we then show that all but one previously considered cases in the literature satisfy this sufficient condition .",
    "see examples [ example : iid]-[example : mixed - source ] in section [ sec : examples ] .",
    "the large deviation theoretic ideas are already present in the works of pfister & sullivan @xcite and the method of types approach of arikan & merhav @xcite .",
    "our work however brings out the essential ingredient ( the sufficient conditions on the information spectrum ) , and enables us to see the previously obtained specific results under one light .    the quest for a general sufficient condition under which the information spectrum satisfies",
    "a large deviation property is a natural line of inquiry , and one of independent interest , in view of the shannon - mcmillan - breiman theorem which asserts that the information spectrum of a stationary and ergodic source converges to the shannon entropy almost surely and in @xmath24 , for all @xmath25 ; see for example @xcite . in particular ,",
    "the large deviation property implies exponentially fast convergence to entropy . in the several specific examples we consider ,",
    "the information spectrum does satisfy the large deviation property .",
    "one sufficient condition for the weaker property of exponentially fast convergence to entropy is the so - called _ blowing up property_. ( see marton & shields ( * ? ? ?",
    "2 ) , or the survey article by shields @xcite ) .",
    "one family of sources , that includes most of the sources we consider in this paper and goes beyond , is that of _ finitary encodings _ of memoryless processes , also called finitary processes .",
    "these are known to have the blowing - up property , and therefore exponentially fast convergence to entropy ( see marton & shields ( * ? ? ?",
    "it is an interesting open question to see if finitary processes , or what other sources with the blowing up property , satisfy the large deviation property .",
    "the rest of the paper is organized as follows .",
    "section ii studies the tight relationship between guessing and compression .",
    "section iii states the relevant large deviations results and the main sufficiency results .",
    "section iv re - derives prior results by showing that in each case the information spectrum satisfies the ldp .",
    "section v contains proofs and section vi contains some concluding remarks .",
    "in this section we relate the problem of guessing to one of source compression .",
    "an interesting conclusion is that robust source compression strategies lead to robust guessing strategies .    for ease of exposition ,",
    "let us assume that the message space is simply @xmath2 .",
    "the extension to strings of length @xmath1 is straightforward and will be returned to shortly .",
    "a guessing function @xmath26 is a bijection that denotes the order in which the elements of @xmath2 are guessed . if @xmath27 , then the @xmath10th guess is @xmath28 .",
    "let @xmath29 denote the set of natural numbers .",
    "a length function @xmath30 is one that satisfies kraft s inequality @xmath31 where we have used the notation @xmath32 . to each guessing function @xmath33 , we associate a pmf @xmath34 on @xmath2 and a length function @xmath35 as follows .",
    "given a guessing function @xmath33 , we say @xmath34 defined by @xmath36 is the pmf on @xmath2 associated with @xmath33 .",
    "the quantity @xmath37 in ( [ eqn : q_g ] ) is the normalization constant .",
    "we say @xmath35 defined by @xmath38 is the length function associated with @xmath33 .",
    "observe that @xmath39 and therefore the pmf in ( [ eqn : q_g ] ) is well - defined .",
    "we record the intimate relationship between these associated quantities in the following result .",
    "( this is also available in the proof of ( * ? ? ?",
    "* th . 1 , p.382 ) ) .",
    "[ prop : guessingbounds ] given a guessing function @xmath33 , the associated quantities satisfy @xmath40    the first equality in ( [ eqn : guessing - pmfbounds ] ) follows from the definition in ( [ eqn : q_g ] ) , and the second inequality from the fact that @xmath41 .",
    "the upper bound in ( [ eqn : guessing - lengthbounds ] ) follows from the upper bound in ( [ eqn : guessing - pmfbounds ] ) and from ( [ eqn : l_g ] ) .",
    "the lower bound in ( [ eqn : guessing - lengthbounds ] ) follows from @xmath42    we now associate a guessing function @xmath43 to each length function @xmath44 .",
    "[ defn : g_l ] given a length function @xmath44 , we define the associated guessing function @xmath43 to be the one that guesses in the increasing order of @xmath44-lengths .",
    "messages with the same @xmath44-length are ordered using an arbitrary fixed rule , say the lexicographical order on @xmath2 . we also define the associated pmf @xmath45 on @xmath2 to be @xmath46    [ prop : lengthbounds ] for a length function @xmath44 , the associated pmf and the guessing function satisfy the following :    1 .",
    "@xmath43 guesses messages in the decreasing order of @xmath45-probabilities ;",
    "@xmath47    the first statement is clear from the definition of @xmath43 and from ( [ eqn : q_l ] ) .",
    "letting @xmath48 denote the indicator function of an event @xmath49 , we have as a consequence of statement 1 ) that @xmath50 which proves the left inequality in ( [ eqn : g_lbounds ] ) .",
    "this inequality was known to wyner @xcite .",
    "the last inequality in ( [ eqn : g_lbounds ] ) follows from ( [ eqn : q_l ] ) and kraft s inequality ( [ eqn : kraftinequality ] ) as follows : @xmath51    let @xmath52 denote the set @xmath53 .",
    "we then have the following easy to verify corollary to propositions [ prop : guessingbounds ] and [ prop : lengthbounds ] .",
    "[ cor : inclusions ] for a given @xmath33 , its associated length function @xmath35 , and any @xmath54 , we have @xmath55    analogously , for a given @xmath44 , its associated guessing function @xmath43 , and any @xmath54 , we have @xmath56    the inequalities between the associates in ( [ eqn : guessing - lengthbounds ] ) and ( [ eqn : g_lbounds ] ) indicate the direct relationship between guessing moments and campbell s coding problem @xcite , and that the rnyi entropies are the optimal growth exponents for guessing moments , as highlighted in the following proposition .",
    "let @xmath44 be any length function on @xmath2 , @xmath57 the guessing function associated with @xmath44 , @xmath58 a pmf on @xmath2 , @xmath59 , @xmath60 the length function that minimizes @xmath61 $ ] , where the expectation is with respect to @xmath58 , @xmath62 the guessing function that proceeds in the decreasing order of @xmath58-probabilities and therefore the one that minimizes @xmath63 $ ] , and @xmath37 as in ( [ eqn : c ] ) .",
    "then @xmath64 } { \\mathbb{e } \\left [ g^*(x)^{\\rho } \\right ] }    \\leq \\frac{\\mathbb{e } \\left [ \\exp_2\\{\\rho l(x)\\ } \\right ] } { \\mathbb{e } \\left [ \\exp_2\\{\\rho l^*(x)\\ }    \\right ] } \\cdot \\exp_2\\{\\rho ( 1 + \\log_2 c ) \\}.\\ ] ] analogously , let @xmath33 be any guessing function , and @xmath35 its associated length function . then @xmath65 } { \\mathbb{e } \\left [ g^*(x)^{\\rho } \\right ] }    \\geq \\frac{\\mathbb{e } \\left [ \\exp_2\\{\\rho l_g(x)\\ } \\right ] } { \\mathbb{e } \\left [ \\exp_2\\{\\rho l^*(x)\\ }    \\right ] } \\cdot \\exp_2\\{- \\rho ( 1 + \\log_2 c ) \\}.\\ ] ] also , @xmath66    - \\frac{1}{\\rho } \\log_2 \\mathbb{e } \\left [ \\exp_2\\{\\rho l^*(x)\\ }    \\right ] \\right| \\leq 1 + \\log_2 c.\\ ] ]    observe that @xmath67 }    \\nonumber \\\\",
    "\\label{eqn:2a }    & \\geq & \\mathbb{e } \\left [ g_{l}(x)^{\\rho }    \\right ] \\\\    & \\geq & \\mathbb{e } \\left [ g^*(x)^{\\rho } \\right ] \\nonumber \\\\",
    "\\label{eqn:2b }    & \\geq & \\mathbb{e } \\left [ \\exp_2\\{\\rho l_{g^*}(x)\\ } \\right ] \\exp_2\\{-\\rho ( 1 + \\log_2 c ) \\ } \\\\",
    "\\label{eqn:2c }    & \\geq & \\mathbb{e } \\left [ \\exp_2\\ { \\rho l^*(x)\\ } \\right ] \\exp_2\\ { -\\rho ( 1 + \\log_2 c ) \\},\\end{aligned}\\ ] ] where ( [ eqn:2a ] ) follows from ( [ eqn : g_lbounds ] ) , and ( [ eqn:2b ] ) from the left inequality in ( [ eqn : guessing - lengthbounds ] ) .",
    "the result in ( [ eqn : ratioupperbound ] ) immediately follows .",
    "a similar argument shows ( [ eqn : ratiolowerbound ] ) . finally , ( [ eqn : g*l*relation ] ) follows from the inequalities leading to ( [ eqn:2c ] ) by setting @xmath68 .",
    "thus if we have a length function whose performance is close to optimal , then its associated guessing function is close to guessing optimal .",
    "the converse is true as well .",
    "moreover , the optimal guessing exponent is within @xmath69 of the optimal coding exponent for the length function .",
    "let us now consider strings of length @xmath1 .",
    "let @xmath6 denote the set of messages and consider @xmath70 .",
    "let @xmath71 denote the set of pmfs on @xmath6 . by a source ,",
    "we mean a sequence of pmfs @xmath72 , where @xmath73 .",
    "we replace the normalization constant @xmath37 in ( 7 ) by @xmath74 and observe that @xmath75 if we normalize both sides of equation ( [ eqn : g*l*relation ] ) by @xmath1 , the difference between two quantities as a function of @xmath1 decays as @xmath76 , and vanishes as @xmath1 tends to infinity .",
    "the following theorem follows immediately , with a change of base to natural logarithms .",
    "[ thm : guesscodelimit ] given @xmath77 , the limit @xmath78\\ ] ] exists if and only if the limit @xmath79\\ ] ] exists .",
    "furthermore , the two limits are equal .",
    "it is therefore sufficient to restrict our attention to the campbell s coding problem @xcite and study if the limit @xmath80\\ ] ] exists , where the infimum is taken over all length functions @xmath81 and exponentiation is with respect to the base of the natural logarithm .",
    "before we proceed to studying the limit , we make a further remark on the connection between _ universal _ strategies for guessing and universal strategies for compression .",
    "let @xmath82 denote a class of sources .",
    "for each source in the class , let @xmath7 be its restriction to strings of length @xmath1 and let @xmath83 denote an optimal length function that attains the minimum value @xmath84 $ ] among all length functions , the expectation being with respect to @xmath7 .",
    "on the other hand , let @xmath85 be a sequence of length functions for the class of sources that does not depend on the actual source within the class .",
    "suppose further that the length sequence @xmath85 is asymptotically optimal , i.e. , @xmath86 } \\\\    & = & \\lim_{n \\rightarrow \\infty } \\frac{1}{n \\rho } \\ln \\mathbb{e } \\left [ \\exp\\{(\\rho \\ln 2 ) l_n^*(x^n)\\ }    \\right],\\end{aligned}\\ ] ] for every source belonging to the class .",
    "@xmath85 is thus `` univeral '' for ( i.e. , asymptotically optimal for all sources in ) the class .",
    "an application of ( [ eqn : ratioupperbound ] ) with @xmath74 in place of @xmath37 followed by the observation @xmath87 shows that the sequence of guessing strategies @xmath88 is asymptotically optimal for the class , i.e. , @xmath89 } \\nonumber \\\\",
    "\\label{eqn : growthexponent }    & = & \\lim_{n \\rightarrow \\infty } \\frac{1}{n \\rho } \\ln \\mathbb{e } \\left [ g^*(x^n)^{\\rho } \\right ] \\nonumber.\\end{aligned}\\ ] ]    arikan and merhav @xcite provide a universal guessing strategy for the class of discrete memoryless sources ( dms ) . for the class of unifilar sources with a known number of states , the minimum description length encoding is asymptotically optimal for campbell s coding length problem ( see merhav @xcite ) .",
    "it follows as a consequence of the above argument that guessing in the increasing order of description lengths is asymptotically optimal .",
    "the left side of ( [ eqn : ratioupperbound ] ) is the extra factor in the expected number of guesses ( relative to the optimal value ) due to lack of knowledge of the specific source in class .",
    "sundaresan @xcite characterized this loss as a function of the uncertainty class .",
    "we begin with some words on notation . recall that @xmath71 denotes the set of pmfs on @xmath6 .",
    "the shannon entropy for a @xmath73 is @xmath90 and the rnyi entropy of order @xmath91 is ( [ eqn : re ] ) .",
    "the kullback - leibler divergence or relative entropy between two pmfs @xmath92 and @xmath7 is @xmath93 where @xmath94 means @xmath92 is absolutely continuous with respect to @xmath7 .",
    "recall that a source is a sequence of pmfs @xmath72 where @xmath73 .",
    "it is usually obtained via @xmath1-length marginals of some probability measure in @xmath95 .",
    "also recall the definitions of limiting guessing exponent in ( [ eqn : limitingexponent ] ) and rnyi entropy rate in ( [ eqn : rer ] ) when the limits exist .",
    "@xmath96 is an optimal guessing function for a pmf @xmath73 . from the results in section [ sec : guesscodeequivalence ] on the equivalence between guessing and compression , it is sufficient to focus on the campbell coding problem .",
    "our first contribution is a proof of the following implicit result of malone & sullivan @xcite . the proof is given in section [ subsec : prop1 ] .",
    "[ prop : renyi - guessing - equivalence ] let @xmath13 . for a source @xmath72 ,",
    "@xmath20 exists if and only if the rnyi entropy rate ( [ eqn : rer ] ) exists .",
    "furthermore , @xmath97 equals the rnyi entropy rate .",
    "the question now boils down to the existence of the limit in the definition of rnyi entropy rate .",
    "the theory of large deviations immediately yields a sufficient condition .",
    "we begin with a definition .",
    "ii.3.1 ) [ defn : ldp ] a sequence @xmath98 of probability measures on @xmath99 satisfies the _ large deviation property ( ldp ) _ with rate function @xmath100 $ ] if the following conditions hold :    * @xmath101 is lower semicontinuous on @xmath99 ; * @xmath101 has compact level sets ; * @xmath102 for each closed subset @xmath103 of @xmath99 ; * @xmath104 for each open set @xmath33 of @xmath99 .",
    "several commonly encountered sources satisfy the ldp with known and well - studied rate functions .",
    "we describe some of these in the examples treated subsequently .",
    "let @xmath105 denote the distribution of the information spectrum given by the real - valued random variable @xmath106 .",
    "the following proposition gives a sufficient condition for the existence of the limiting rnyi entropy rate ( and therefore the limiting guessing exponent ) .",
    "[ prop : ldpsufficientcondition ] let the sequence of distributions @xmath98 of the information spectrum satisfy the ldp with rate function @xmath101",
    ". then the limiting rnyi entropy rate of",
    "order @xmath107 exists for all @xmath13 and equals @xmath108 where @xmath109 .",
    "consequently , the limiting guessing exponent exists and equals @xmath110    the function @xmath111 is the legendre - fenchel dual of the rate function @xmath101 .",
    "proposition [ prop : ldpsufficientcondition ] says that , under the sufficient condition , the limiting guessing exponent equals @xmath112 , and is thus directly related to the large deviations rate function for information spectrum .",
    "this is however different from merhav & arikan s ( * ? ? ?",
    "2 ) for memoryless sources which states that the limiting guessing exponent is the legendre - fenchel dual of the source coding _",
    "error exponent _ function .",
    "we refer the reader to merhav and arikan ( * ? ? ?",
    "iv ) for further interesting connections between source coding error exponent , guessing exponent , and two other exponents related to lossy source coding .",
    "let us briefly discuss another approach to verify the existence of rnyi entropy rate ( see proposition [ prop : renyi - guessing - equivalence ] ) . with @xmath16 , we can rewrite @xmath113 times the rnyi entropy rate in ( [ eqn : rer ] ) as @xmath114 where @xmath115 and @xmath116 is the iid process on @xmath117 with uniform marginal on @xmath2 .",
    "one can then view @xmath118 as the inverse temperature ( when @xmath13 ) of a statistical mechanical system , @xmath119 as the energy of the configuration @xmath4 , and the right side of ( [ eqn : normalizedpartition ] ) as a scaled version of ( i.e. , @xmath18 times ) the specific gibbs free energy of the corresponding statistical mechanical system , if the limit exists .",
    "this view point is particularly useful because the iid process @xmath116 satisfies a sample path large deviation property . if the information spectrum sequence satisfies the continuity conditions in varadhan ( * ? ? ?",
    "3.4 ) , then the limiting specific gibbs free energy exists , and so does the rnyi entropy rate .",
    "our technical report @xcite treats an example via this more general approach .      in order to study the examples in section [ sec : examples ] , we state some additional results on ldp of transformed variables .",
    "( see ( * ? ? ?",
    "* sec . 4.2 ) ) , ( * ? ? ?",
    "* th . 6.12 and 6.14 ) ) .",
    "[ prop : contractionprinciple ] let @xmath120 denote a sequence of @xmath121-valued random variables where @xmath121 is a complete separable metric space ( polish space ) .",
    "let @xmath105 denote the distribution of @xmath122 for @xmath123 , and let the sequence of distributions @xmath98 on @xmath121 satisfy the ldp with rate function @xmath124 $ ] .",
    "let @xmath125 be a continuous function .",
    "the sequence of distributions of @xmath126 on @xmath99 also satisfies the ldp with rate function @xmath127 $ ] given by    @xmath128    [ prop : exponential approximation ] suppose that the sequence of distributions of @xmath120 satisfies the ldp with rate function @xmath101 on @xmath99 .",
    "assume also that the sequence of random variables @xmath129 is superexponentially close to @xmath120 in the following sense : for each @xmath130 @xmath131 then the sequence of distributions of @xmath129 also satisfies the ldp on @xmath99 with the same rate function @xmath101 .",
    "the condition in ( [ eqn : superexponential ] ) is satisfied if @xmath132 where @xmath133 is the underlying sample space .",
    "we are now ready to apply proposition 7 and related techniques to various examples . in first five examples that follow ,",
    "our goal is to show that the sufficient condition for the existence of the limiting guessing exponent holds , i.e. , that the sequence of distributions of the information spectrum satisfies the ldp .",
    "[ example : iid ] this example was first studied by arikan @xcite . recall that an iid source is one for which @xmath134 , where @xmath12 is the marginal of @xmath135 .",
    "it is then clear that the information spectrum can be written as a sample mean of iid random variables @xmath136 it is well - known that the sequence @xmath98 of distributions of this sample mean satisfies the ldp with rate function given by the legendre - fenchel dual of the cumulant of the random variable @xmath137 ( see for example ( * ? ? ?",
    "ii.4.1 ) or ( * ? ? ?",
    "( 1.9.66 - 67 ) ) ) : @xmath138 & = & \\ln \\left ( \\sum_{x \\in \\mathbb{x } } p_1(x)^{\\alpha } \\right ) \\\\    & = & ( 1 - \\alpha ) h_{\\alpha}(p_1).\\end{aligned}\\ ] ] the legendre - fenchel dual of the rate function is therefore the cumulant itself ( ( * ? ? ?",
    "vi.4.1.e ) ) .",
    "an application of proposition [ prop : ldpsufficientcondition ] yields that @xmath139 times this cumulant , given by @xmath15 , is the guessing exponent .",
    "we thus recover arikan s result @xcite .",
    "the rate function @xmath101 can also be obtained using the _ contraction principle _ ( proposition [ prop : contractionprinciple ] ) as follows .",
    "this method will provide a recipe to obtain the limiting guessing exponent in subsequent examples .",
    "consider a mapping that takes @xmath4 to its empirical pmf in @xmath140 .",
    "empirical pmf is then a random variable .",
    "the distribution of @xmath141 induces a pmf on @xmath140 .",
    "it is well - known that the sequence of distributions of these empirical pmfs , indexed by @xmath1 , satisfies the _ level-2 _ ldp ) of sample means , level-2 refers to sample histograms , and level-3 to sample paths . ] with rate function @xmath142 .",
    "see for example ( * ? ? ?",
    "* th ii.4.3 ) . observe that the mapping from the empirical pmf to the information spectrum random variable is continuous .",
    "we can therefore use the contraction principle to get a formula for @xmath101 in terms of @xmath143 as follows ( * ? ? ?",
    "* th ii.5.1 ) . for any @xmath144 in @xmath99 ,",
    "let @xmath145 i.e. , @xmath146 then @xmath147 using this , we can write @xmath148 thus yielding @xmath149 this formula extends to more general sources , as is seen in the next few examples .",
    "[ example : markov ] this example was studied by malone & sullivan @xcite .",
    "consider an irreducible markov chain taking values on @xmath2 with transition probability matrix @xmath150 .",
    "our goal is to verify that the sufficient condition holds and to calculate @xmath20 defined by ( [ eqn : limitingexponent ] ) for this source .",
    "let @xmath151 denote the set of _ stationary _ pmfs defined by @xmath152 denote the common marginal by @xmath153 and let @xmath154 we may then denote @xmath155 , where @xmath153 is the distribution of @xmath135 and @xmath156 the conditional distribution of @xmath157 given @xmath135 .",
    "it is once again well known that the empirical pmf random variable satisfies the level-2 ldp with rate function @xmath158 , given by @xcite @xmath159 as in example [ example : iid ] , the contraction principle then yields that the sequence of distributions of information spectrum satisfies the ldp with rate function @xmath101 given by @xmath160 where for @xmath144 in @xmath99 , @xmath161 is defined by @xmath162 by proposition [ prop : renyi - guessing - equivalence ] , the limiting guessing exponent exists . perron - frobenius theory ( seneta ( * ? ? ?",
    "1 ) , see also @xcite ) yields the cumulant directly as @xmath163 , where @xmath164 is unique largest eigenvalue ( perron - frobenius eigenvalue ) of a matrix formed by raising each element of @xmath150 to the power @xmath18 .",
    "( recall that @xmath16 and @xmath165 ) .",
    "thus @xmath166 , and we recover the result of malone & sullivan @xcite . it is useful to note that the steps that led to ( [ eqn : erho - iid ] ) hold in the markov case ( with appropriate changes to entropy and divergence terms ) and we may write @xmath167 where @xmath168 is the conditional entropy of @xmath157 given @xmath135 under the joint distribution @xmath169 , i.e. , @xmath170    [ example : unifilar ] this example was studied by sundaresan in @xcite .",
    "a unifilar source is a generalization of the markov source in example [ example : markov ] .",
    "let @xmath2 denote the alphabet set as before .",
    "in addition , let @xmath171 denote a set of finite states .",
    "fix an initial state @xmath172 and let the joint probability of observing @xmath173 be @xmath174 where @xmath175 is the joint probability of @xmath176 given the previous state @xmath177 .",
    "the dependence of @xmath7 on @xmath172 is understood .",
    "furthermore , assume that @xmath175 is such that @xmath178 , where @xmath179 is a deterministic function that is one - to - one for each fixed @xmath177 .",
    "such a source is called a unifilar source .",
    "@xmath180 and @xmath179 completely specify the process : the initial state @xmath181 is random with distribution that of marginal of @xmath182 in @xmath183 , the rest being specified by @xmath184 and @xmath179 .",
    "example [ example : markov ] is a unifilar source with @xmath185 , @xmath186 , and @xmath187 where @xmath153 is the stationary distribution of the markov chain .",
    "let @xmath188 denote the set of joint measures on the indicated space so that the resulting process @xmath189 is a stationary and irreducible markov chain .",
    "let a @xmath190 be written as @xmath155 .",
    "for any @xmath144 in @xmath99 , let @xmath191 then the sequence of distributions of information spectrum @xmath192 satisfies the ldp ( ( * ? ? ? * eqn .",
    "( 1.9.30 ) ) ) with rate function given ( once again via contraction principle ) by @xmath193 the limiting exponent therefore exists .",
    "following the same procedure that led to ( [ eqn : erho - iid ] ) in the iid case and ( [ eqn : erho - markov ] ) for a markov source , we get @xmath194 where @xmath168 and @xmath195 are analogously defined , and the result of sundaresan @xcite is recovered .",
    "[ example : stationary ] pfister & sullivan @xcite considered a class of stationary sources with distribution @xmath196 that satisfies two hypotheses h1 and h2 of ( * ? ? ?",
    "ii - b ) , which we will now describe .    let @xmath197 denote the set of sources that satisfy @xmath94 for all @xmath123 , where @xmath7 and @xmath92 are restrictions of @xmath58 and @xmath169 to @xmath1 letters .",
    "note that it may be possible that a @xmath198 is not absolutely continuous with respect to @xmath58 .",
    "also , let @xmath199 denote the subset of stationary sources with respect to the shift operator @xmath200 defined by @xmath201 hypothesis h1 of pfister & sullivan @xcite assumes that for any neighborhood of a stationary source @xmath202 and any @xmath203 , there exists an ergodic @xmath204 in that neighborhood such that @xmath205 , where @xmath206 is the shannon entropy rate of source @xmath169 .",
    "their hypothesis h2 is given by ( [ eqn : expodifference ] ) below .",
    "under these hypotheses , pfister & sullivan @xcite proved that @xmath20 exists , and provided a variational characterization analogous to ( [ eqn : erho - unifilar ] ) , i.e. , @xmath207 where @xmath208    en route to this result , pfister & sullivan @xcite showed that the sequence of distributions of the _ empirical process _ satisfies the _ level-3 _ ldp for sample paths .",
    "we first state this precisely , and then use this as the starting point to show the sufficient condition that the information spectrum satisfies the ldp .    for an @xmath209 given by @xmath210 ,",
    "we define @xmath211 as the first @xmath1 components of @xmath28 in the usual way .",
    "consider a stationary source @xmath58 whose letters are @xmath212",
    ". define the empirical process of measures @xmath213 this is a measure on @xmath214 that puts mass @xmath215 on the following strings : @xmath216 .",
    "pfister & sullivan showed that the distributions of the @xmath95-valued process @xmath217 satisfies the level-3 ldp with rate function @xmath218 under hypotheses h1 and h2 of their paper ( ( * ? ? ? * prop .",
    "2.2 - 2.3 ) ) . furthermore , @xmath219 so that we may restrict @xmath220 to @xmath221 .",
    "we next use this to show that the information spectrum satisfies the ldp .",
    "hypothesis h2 of pfister & sullivan assumes the existence of a continuous mapping @xmath222 satisfying @xmath223 where @xmath224 .    by the compactness of @xmath214 , @xmath225 is uniformly continuous . under the weak topology on the complete separable metric space @xmath226 ,",
    "the mapping @xmath227 defined by @xmath228 is a continuous mapping .",
    "hence by the contraction principle , by setting @xmath229 we get that the sequence of distributions of @xmath230 satisfies the ldp with rate function @xmath101 given by @xmath231 where the restriction of the infimum to @xmath221 follows from ( [ eqn : restrictiontostationary ] ) .",
    "furthermore , given hypothesis h2 and ( [ eqn : expodifference ] ) , an application of the exponential approximation principle ( proposition [ prop : exponential approximation ] ) indicates that the sequence of distributions of the information spectrum too satisfies the ldp with the same rate function @xmath101 , and we have verified that the sufficient condition holds .",
    "what remains is to calculate this rate function . for this , we return to pfister & sullivan s work and use @xmath232 ( * ? ? ?",
    "2.1 ) to write @xmath233    finally , the legendre - fenchel dual of the rate function is computed as in the steps leading to ( [ eqn : erho - iid])-([eqn : erho - unifilar ] ) , yielding ( [ eqn : erho - stationary ] ) .",
    "[ example : mixed - source ] consider a mixture of two iid sources with letters from @xmath2 .",
    "we may write @xmath234 where @xmath235 with @xmath236 the two marginal pmfs that define the iid components of the mixture .",
    "it is easy to see that the guessing exponent is the maximum of the guessing exponents for the two component sources .",
    "we next verify this using proposition [ prop : ldpsufficientcondition ] .",
    "the sequence of distributions of the information spectrum satisfies the ldp with rate function given as follows ( see han ( * ? ? ?",
    "( 1.9.41 ) ) ) .",
    "define @xmath237 and for @xmath238 @xmath239 the rate function ( via the contraction principle ) is given by @xmath240 from proposition [ prop : ldpsufficientcondition ] we conclude that the limiting guessing exponent exists .",
    "@xmath241 is then @xmath242 yielding @xmath243",
    "we now prove propositions [ prop : renyi - guessing - equivalence ] and [ prop : ldpsufficientcondition ] .      from theorem [ thm : guesscodelimit ]",
    "it is sufficient to show that the limit in ( [ eqn : campbell ] ) for campbell s coding problem exists if and only if the rnyi entropy rate exists , with the former @xmath244 times the latter .",
    "fix @xmath1 .",
    "in the rest of the proof , we use the notation @xmath245 $ ] for expectation with respect to distribution @xmath7 .",
    "the length function can be thought of as a bounded ( continuous ) function from @xmath6 to @xmath99 and therefore our interest is in the logarithm of its moment generating function of @xmath244 , the cumulant .",
    "the cumulant associated with a bounded continuous function ( here @xmath85 ) has a variational characterization ( * ? ? ?",
    "1.4.2 ) as the following legendre - fenchel dual of the kullback - leibler divergence , i.e. , @xmath246 } \\nonumber \\\\       & = & \\sup_{q_n \\in \\mathcal{m}(\\mathbb{x}^n)}\\big \\ { ( \\rho \\ln 2 ) \\mathbb{e}_{q_n}[l_n(x^n)]-d(q_n \\parallel p_n)\\big\\}. \\nonumber \\\\",
    "\\label{eqn : legendretransform}\\end{aligned}\\ ] ] taking infimum on both sides over all length functions , we arrive at the following chain of inequalities : @xmath247 } \\\\     & = & \\displaystyle \\inf_{l_n}\\displaystyle \\sup_{q_n \\in \\mathcal{m}(\\mathbb{x}^n)}\\big \\{\\mathbb{e}_{q_n}[(\\rho \\ln 2 ) l_n(x^n)]-d(q_n \\parallel p_n)\\big \\ } \\nonumber \\\\       & = & \\lefteqn { \\hspace*{-.1in}\\sup_{q_n \\in \\mathcal{m}(\\mathbb{x}^n ) }    \\inf_{l_n }   \\big \\{\\mathbb{e}_{q_n}[(\\rho \\ln 2 ) l_n(x^n)]-d(q_n \\parallel p_n)\\big \\ } } \\nonumber\\\\   \\label{eqn : sup - inf }   & & \\hspace{2in}+ \\theta(1)\\\\     \\label{eqn : entropy }     & = &   \\hspace*{-.1in}\\sup_{q_n \\in \\mathcal{m}(\\mathbb{x}^n ) } \\big \\ { \\rho h_n(q_n ) - d(q_n \\parallel p_n)\\big \\ } + \\theta(1 ) \\\\",
    "\\label{eqn : variational }     & = & \\rho h_{\\frac{1}{1 + \\rho}}(p_n ) + \\theta(1).\\end{aligned}\\ ] ] equation ( [ eqn : sup - inf ] ) follows because ( i ) the mapping",
    "@xmath248-d(q_n \\parallel p_n)\\ ] ] is a concave function of @xmath92 ; ( ii ) for fixed @xmath92 and for any two length functions @xmath249 and @xmath250 , for any @xmath251 $ ] , the function @xmath252 is also a length function and @xmath253= \\lambda \\mathbb{e}_{q_n}[l_n^{(1)}]+(1-\\lambda ) \\mathbb{e}_{q_n}[l_n^{(2)}]+ \\theta(1);\\ ] ] ( iii ) @xmath71 is compact and convex , and therefore the infimum and supremum may be interchanged upon an application of a version of ky fan s minimax result @xcite .",
    "this yields a compression problem , the infimum over @xmath85 of expected lengths with respect to a distribution @xmath92 .",
    "the answer is the well - known shannon entropy @xmath254 to within @xmath255 nats , and ( [ eqn : entropy ] ) follows .",
    "lastly , ( [ eqn : variational ] ) is a well - known identity which may also be obtained directly by writing the supremum term in ( [ eqn : entropy ] ) as @xmath256 \\\\   - ~ d(q_n \\parallel p_n ) \\big\\}\\end{aligned}\\ ] ] and then applying ( [ eqn : legendretransform ] ) with @xmath257 in place of @xmath258 to get the scaled rnyi entropy .",
    "normalize both ( [ eqn : unnormalizedcampbelleqn ] ) and ( [ eqn : variational ] ) by @xmath1 and let @xmath70 to deduce that ( [ eqn : campbell ] ) exists if and only if the limiting normalized rnyi entropy rate exists .",
    "this concludes the proof .",
    "this is a straightforward application of varadhan s theorem @xcite on asymptotics of integrals .",
    "recall that @xmath105 is the distribution of the information spectrum @xmath259 .",
    "define @xmath260 . since the @xmath98 sequence satisfies the ldp with rate function @xmath101 , varadhan s theorem ( see ellis ( * ? ? ?",
    "ii.7.1.b ) ) states that if @xmath261 then the limit @xmath262 holds .",
    "the integral on the left side in ( [ eqn : varadhan ] ) can be simplified by defining the finite cardinality set @xmath263 and by observing that @xmath264 take logarithms , normalize by @xmath1 , take limits , and apply ( [ eqn : varadhan ] ) to get the desired result .",
    "it therefore remains to prove ( [ eqn : suffconditionvaradhan ] ) .",
    "the event @xmath265 occurs if and only if @xmath266 the integral in ( [ eqn : suffconditionvaradhan ] ) can therefore be written as @xmath267 the sequence in @xmath1 on the left side of ( [ eqn : suffconditionvaradhan ] ) is then @xmath268 a constant sequence .",
    "take the limit as @xmath269 to verify ( [ eqn : suffconditionvaradhan ] ) .",
    "this concludes the proof .",
    "we first showed that the problem of finding the limiting guessing exponent is equal to that of finding the limiting compression exponent under exponential costs ( campbell s coding problem ) .",
    "we then saw that the latter limit exists if the sequence of distributions of the information spectrum satisfies the ldp ( sufficient condition ) .",
    "the limiting exponent was the legendre - fenchel dual of the rate function , scaled by an appropriate constant .",
    "it turned out to be the limit of the normalized cumulant of the information spectrum random variable .",
    "while some of these facts can be gleaned from the works of pfister & sullivan @xcite and merhav & arikan @xcite , our work sheds light on the key role played by the information spectrum .",
    "it will be of interest to find a rich class of sources beyond those listed in this paper for which the information spectrum satisfies the ldp ."
  ],
  "abstract_text": [
    "<S> the problem of guessing a random string is revisited . a close relation between guessing and compression </S>",
    "<S> is first established . </S>",
    "<S> then it is shown that if the sequence of distributions of the information spectrum satisfies the large deviation property with a certain rate function , then the limiting guessing exponent exists and is a scalar multiple of the legendre - fenchel dual of the rate function . </S>",
    "<S> other sufficient conditions related to certain continuity properties of the information spectrum are briefly discussed . </S>",
    "<S> this approach highlights the importance of the information spectrum in determining the limiting guessing exponent . </S>",
    "<S> all known prior results are then re - derived as example applications of our unifying approach .    </S>",
    "<S> guessing , length function , source coding , information spectrum , large deviations . </S>"
  ]
}