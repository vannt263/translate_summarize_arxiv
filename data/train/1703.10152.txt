{
  "article_text": [
    "one of the crucial tasks for researchers to carry out scientific investigations is to detect existing ideas that are related to their research topics .",
    "research ideas are usually documented in scientific publications .",
    "normally , there is one main idea stated in the abstract , explicitly presenting the aim of the paper .",
    "there are also other sub - ideas distributed across the entire paper .",
    "as the growth rate of scientific publication has been rising dramatically , researchers are overwhelmed by the explosive information .",
    "it is almost impossible to digest the ideas contained in the documents emerged everyday . therefore , computer assisted technologies such as document summarization are expected to play a role in condensing information and providing readers with more relevant short texts . unlike document summarization from news circles , where the task is to identify centroid sentences @xcite or to extract the first few sentences of the paragraphs @xcite , summarization of scientific articles involves extra text processing stage @xcite .",
    "after highest ranked texts are extracted , rhetorical status analysis will be conducted on the selected sentences .",
    "rhetorical sentence classification , also known as argumentative zoning ( az ) @xcite , is a process of assigning rhetorical status to the extracted sentences .",
    "the results of az provide readers with general discourse context from which the scientific ideas could be better linked , compared and analyzed .",
    "for example , given a specific task , which sentences should be shown to the reader is related to the features of the sentences .",
    "for the task of identifying a paper s unique contribution , sentences expressing research purpose should be retrieved with higher priority . for comparing ideas , statements of comparison with other works",
    "would be more useful .",
    "teufel et .",
    "@xcite introduced their rhetorical annotation scheme which takes into account of the aspects of argumentation , metadiscourse and relatedness to other works .",
    "their scheme resulted seven categories of rhetorical status and the categories are assigned to full sentences .",
    "examples of human annotated sentences with their rhetorical status are shown in table .  [",
    "table : examples ] .",
    "the seven categories are aim , contrast , own , background , other , basis and textual .    [ cols=\"^,^ \" , ]     [ table : results2 ]    the results were examined from the following aspects :    when the feature dimension is set to 100 and the training corpus is acl , the results generated by different models were compared ( avgwvec , + paravec and avgwvec+bswe for bas category only ) .",
    "looking at the f - measure , avgwvec performs better than paravec , but paravec gave a better precision results on several categories , such as aim , ctr , txt and own .",
    "the results showed that paravec model is not robust , for example , it performs badly for the category of bas .",
    "for specific category classification , take the bas category for example , the bswe model outperforms others in terms of f - measure .",
    "when the model is fixed to avgwvec and the training corpus is acl , the feature size impact ( 300 and 100 dimensions ) was investigated . from the f - measure , it can be seen that for some categories , 300-dimension features perform better than the 100-dimension ones , for example , ctr and bkg , but they are not as good as 100-dimension features for some categories , such as bas .",
    "when the model is set to avgwvec and the feature dimension is 100 , the results computed from different training corpus were compared ( acl+az , mixedabs and brown corpus ) .",
    "acl+az outperforms others and brown corpus is better than mixedabs for most of the categories , but brown corpus is not as good as mixedabs for the category of own .    finally , the results were compared between word embeddings and the methods of cuewords , teufel 2002 and baseline . to evaluate word embeddings on az ,",
    "the model avgwvec trained on acl+az was used for the comparison .",
    "it can be seen from the table .",
    "[ table : results1 ] , the model of word embeddings is better than the method using cuewords matching .",
    "it also outperforms teufel 2002 for most of the cases , except aim , bas and own .",
    "it won baseline for most of the categories , except own .",
    "the classification results showed that the type of word embeddings and the training corpus affect the az performance . as the simple model , @xmath0 performs better than others , which indicate averaging the word vectors in a sentence can capture the semantic property of statements . by training specific argumentation word embeddings ,",
    "the performance can be improved , which can be seen from the case of detecting bas status using @xmath1 model .",
    "feature dimension does nt dominate the results .",
    "there is no significant difference between the resutls generated by 300-dimension of features and 100 dimensions .",
    "training corpus affects the results .",
    "outperforming others indicates that the topics of the training corpus are important factors in argumentative zoning .",
    "although brown corpus has more vocabularies , it does nt win acl+az .    in general",
    ", the classification performance of word embeddings is competitive in terms of f - measure for most of the categories . but for classifying the categories aim , bas and own , the manually crafted features proposed by teufel et al .",
    "@xcite gave better results .",
    "in this paper , different word embedding models on the task of argumentative zoning were compared .",
    "the results showed that word embeddings are effective on sentence classification from scientific papers .",
    "word embeddings trained on a relevant corpus can capture the semantic features of statements and they are easier to be obtained than hand engineered features",
    ".    to improve the sentence classification for a specific category , integrating word specific embedding strategy helps .",
    "the size of the feature pool does nt matter too much on the results , nor does the vocabulary size . in comparison ,",
    "the domain of the training corpus affects the classification performance .",
    "d.  r. radev , h.  jing , and m.  budzikowska , `` centroid - based summarization of multiple documents : sentence extraction , utility - based evaluation , and user studies , '' in _ proceedings of the 2000 naacl - anlp workshop on automatic summarization_.1em plus 0.5em minus 0.4emassociation for computational linguistics , 2000 , pp .",
    "2130 .    c .- y .",
    "lin and e.  hovy , `` identifying topics by position , '' in _ proceedings of the fifth conference on applied natural language processing_.1em plus 0.5em minus 0.4emassociation for computational linguistics , 1997 , pp .",
    "283290 .",
    "z.  cao , f.  wei , l.  dong , s.  li , and m.  zhou , `` ranking with recursive neural networks and its application to multi - document summarization , '' in _ twenty - ninth aaai conference on artificial intelligence _",
    ", 2015 .",
    "t.  nasukawa and j.  yi , `` sentiment analysis : capturing favorability using natural language processing , '' in _ proceedings of the 2nd international conference on knowledge capture_.1em plus 0.5em minus 0.4emacm , 2003 , pp .",
    "7077 .",
    "s.  asur , b.  huberman _",
    "et  al . _",
    ", `` predicting the future with social media , '' in _ web intelligence and intelligent agent technology ( wi - iat ) , 2010 ieee / wic / acm international conference on _ , vol .",
    "1.1em plus 0.5em minus 0.4emieee , 2010 , pp .",
    "492499 .",
    "v.  sindhwani and p.  melville , `` document - word co - regularization for semi - supervised sentiment analysis , '' in _ data mining , 2008 .",
    "eighth ieee international conference on_.1em plus 0.5em minus 0.4emieee , 2008 , pp .",
    "10251030 .",
    "d.  h. widyantoro , m.  l. khodra , b.  riyanto , and a.  aziz , `` a multiclass - based classification strategy for rhetorical sentence categorization from scientific papers , '' _ formamente : rivista internazionale di ricerca sul futuro digitale _ ,",
    "3 - 2014 , p. 223",
    ", 2015 .",
    "p.  wang , b.  xu , j.  xu , g.  tian , c .-",
    "liu , and h.  hao , `` semantic expansion using word embedding clustering and convolutional neural network for improving short text classification , '' _ neurocomputing _ , 2015 .",
    "r.  socher , e.  h. huang , j.  pennin , c.  d. manning , and a.  y. ng , `` dynamic pooling and unfolding recursive autoencoders for paraphrase detection , '' in _ advances in neural information processing systems _ , 2011 , pp .",
    "801809 .",
    "d.  tang , f.  wei , n.  yang , m.  zhou , t.  liu , and b.  qin , `` learning sentiment - specific word embedding for twitter sentiment classification , '' in _ proceedings of the 52nd annual meeting of the association for computational linguistics _",
    ", vol .  1 , 2014 , pp . 15551565 .",
    "b.  xue , c.  fu , and z.  shaobin , `` a study on sentiment computing and classification of sina weibo with word2vec , '' in _ big data ( bigdata congress ) , 2014 ieee international congress on_.1em plus 0.5em minus 0.4emieee , 2014 , pp .",
    "358363 .",
    "j.  lilleberg , y.  zhu , and y.  zhang , `` support vector machines and word2vec for text classification with semantic features , '' in _ cognitive informatics & cognitive computing ( icci * cc ) , 2015 ieee 14th international conference on_.1em plus 0.5em minus 0.4emieee , 2015 , pp .",
    "136140 .",
    "h.  m. nguyen , e.  w. cooper , and k.  kamei , `` borderline over - sampling for imbalanced data classification , '' _ international journal of knowledge engineering and soft data paradigms _ , vol .  3 , no .  1 ,",
    "pp . 421 , 2011 ."
  ],
  "abstract_text": [
    "<S> in comparison with document summarization on the articles from social media and newswire , argumentative zoning ( az ) is an important task in scientific paper analysis . traditional methodology to carry on </S>",
    "<S> this task relies on feature engineering from different levels . in this paper , </S>",
    "<S> three models of generating sentence vectors for the task of sentence classification were explored and compared . </S>",
    "<S> the proposed approach builds sentence representations using learned embeddings based on neural network . </S>",
    "<S> the learned word embeddings formed a feature space , to which the examined sentence is mapped to . </S>",
    "<S> those features are input into the classifiers for supervised classification . using 10-cross - validation scheme , </S>",
    "<S> evaluation was conducted on the argumentative - zoning ( az ) annotated articles . </S>",
    "<S> the results showed that simply averaging the word vectors in a sentence works better than the paragraph to vector algorithm and by integrating specific cuewords into the loss function of the neural network can improve the classification performance . in comparison with the hand - crafted features , the word2vec method won for most of the categories . </S>",
    "<S> however , the hand - crafted features showed their strength on classifying some of the categories . </S>"
  ]
}