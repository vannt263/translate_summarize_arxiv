{
  "article_text": [
    "our approach begins with the mixed - membership stochastic block model ( mmsbm ) , which has been used to model networks with overlapping communities or groups . as in the original mmsbm  @xcite and in related models  @xcite , we assume that each node in the bipartite graph of users and items belongs to a mixture of groups .",
    "however , unlike in  @xcite , we do not assume that these group memberships affect the presence or absence of an link , i.e. , the event that a given user rates a given item .",
    "instead , we take the set of links as given , and attempt to predict the ratings .",
    "we do this with an mmsbm - like model where the rating a user gives an item is drawn from a probability distribution that depends on their group memberships .",
    "let us set down some notation .",
    "we have @xmath0 users and @xmath1 items , and a bipartite graph @xmath2 of links , where the link @xmath3 indicates that item @xmath4 was given a rating ( observed or unobserved ) by user @xmath5 . for each @xmath6",
    ", the rating @xmath7 belongs to some finite set @xmath8 such as @xmath9 . given a set @xmath10 of observed ratings ,",
    "our goal is to classify the users and the items , and to predict the rating @xmath7 of a link @xmath6 for which the rating is not yet known .",
    "our generative model for the ratings is as follows .",
    "there are @xmath11 groups of users and @xmath12 groups of items . for each pair of groups @xmath13 , there is a probability distribution @xmath14 over @xmath8 of the rating @xmath15 that @xmath5 gives @xmath4 , assuming that @xmath5 belongs entirely to group @xmath16 and @xmath4 belongs entirely to group @xmath17 .    to model mixed group memberships ,",
    "each user @xmath5 has a vector @xmath18 , where @xmath19 denotes the extent to which user @xmath5 belongs to group @xmath16 .",
    "similarly , each item @xmath4 has a vector @xmath20 .",
    "these vectors are normalized , i.e. , @xmath21 . given @xmath22 and @xmath23 , the probability distribution of the rating @xmath7 is then a convex combination , @xmath24 = \\sum_{k,\\ell } \\theta_{uk } \\eta_{i\\ell } p_{k\\ell}(r ) \\ , .",
    "\\label{eq : model}\\ ] ] abbreviating all these parameters as @xmath25 , the likelihood of the observed ratings is thus @xmath26 as we discuss below , we infer the values of the parameters @xmath27 that maximize this likelihood using an efficient expectation - maximization algorithm .",
    "we can then use the inferred model to predict unobserved ratings @xmath7 .",
    "our work is different from previous work on collaborative filtering in several ways .",
    "first , unlike matrix factorization approaches such as  @xcite or their probabilistic counterparts  @xcite , we do not think of the ratings @xmath28 as integers . as has been established in the literature",
    ", giving a movie a rating of 5 instead of 1 does not mean the user likes it five times as much  @xcite .",
    "our results suggest that it is better to think of different ratings simply as different labels that appear on the links of the network .",
    "moreover , our method yields a distribution over the possible ratings directly , rather than a distribution over integers or reals that must be somehow mapped to the space of possible ratings  @xcite . from this point of view",
    ", our model is a bipartite mmsbm with metadata ( or labels ) on the edges ; a similar model based on the stochastic block model ( sbm ) , where each user and item belongs to only one group , was given in  @xcite .",
    "an alternative approach would be to consider a multi - layer representation of the data as in  @xcite .",
    "second , we do not assume that the matrices @xmath29 have any particular structure .",
    "in particular , we do not assume homophily , where groups of individuals correspond to groups of items , and individuals prefer items that belong to their own group : that is , we do not assume that @xmath30 is larger on the diagonal for higher ratings @xmath15 .",
    "thus our model , and our algorithm , can learn arbitrary couplings between groups of individuals and groups of items , and do so independently for each possible rating .",
    "third , unlike some approaches that use inference methods similar to ours  @xcite , and as stated above , our goal is not to predict the _ existence _ of links . in particular",
    ", we do not assume that individuals only see movies ( say ) that they like , and we do not treat missing links as zeroes or low ratings .",
    "to put this differently , we are not trying to complete @xmath31 to a full matrix of ratings , but only to predict the unobserved ratings in @xmath32 .",
    "thus the only terms in the likelihood of our model correspond to observed ratings .",
    "as we describe below , our model also has the advantage of being mathematically tractable .",
    "it yields an expectation - maximization algorithm for fitting the parameters which is highly efficient : each iteration takes linear time as a function of the number of users , items , and observed links . as a result , we are able to handle quite large datasets , and achieve a higher accuracy than standard methods .",
    "in most practical situations , marginalizing exactly over the group membership vectors @xmath33 and @xmath34 and the probability matrices @xmath29 ( similar to ref .",
    "@xcite ) is too computationally expensive . as an alternative we propose to obtain the model parameters that maximize the likelihood   using an expectation - maximization ( em ) algorithm . in particular",
    ", we use a classic variational approach ( see methods ) to obtain the following equations for the model parameters that maximize the likelihood , @xmath35 here @xmath36 and @xmath37 denote the neighborhoods of @xmath5 and @xmath4 respectively ; @xmath38 and @xmath39 are the node degrees , i.e. , the number of observed ratings for user @xmath5 and item @xmath4 respectively ; and @xmath40 is the variational method s estimate of the probability that the rating @xmath7 is due to @xmath5 and @xmath4 belonging to groups @xmath16 and @xmath17 respectively .",
    "these equations can be solved iteratively with an em algorithm . starting with an initial estimate of @xmath33 , @xmath34 , and @xmath29 ,",
    "we repeat the following steps until the parameters converge :    1 .",
    "( expectation step ) use   to compute @xmath41 for @xmath42 , 2 .",
    "( maximization step ) use  - to compute @xmath33 , @xmath34 , and @xmath29 .    the number of parameters and terms in the sums in eqs .  -",
    "is @xmath43 . assuming that @xmath11 and @xmath12 are constant , this is @xmath44 , and",
    "hence linear in the size of the dataset ( see fig .",
    "s1 in supplementary materials ( sm ) ) . as the set of observed",
    "ratings @xmath10 is typically very sparse because only a small fraction of all possible user - item pairs have observed ratings , our algorithm is feasible even for very large datasets .",
    "we test the performance of our algorithm by considering six datasets : the movielens 100k and 10 m datasets with 100,000 and 10,000,000 ratings respectively , yahoo ! songs , amazon books  @xcite , and the dataset from libimseti.cz dating agency  @xcite , which we split into two datasets , consisting of males rating females and vice versa .",
    "these datasets are diverse in the types of items considered , the sizes @xmath45 of the sets of possible ratings , and the density of observed ratings ( see table  [ t - data ] ) . for each dataset",
    "we perform a five - fold cross - validation , splitting it into five equal subsets , and using each one as a test set after training the model on the union of the other four .",
    "we compare our algorithm to three benchmark algorithms ( see methods ) : a baseline naive algorithm that assigns to each test rating @xmath7 the average of the observed ratings for item @xmath4 ; the item - item algorithm , which predicts @xmath7 based on the observed ratings of user @xmath5 for items that are the most similar to @xmath4 ; and `` classical '' matrix factorization  @xcite .",
    "for all these benchmark algorithms we use the implementation in the lenskit package  @xcite .",
    "additionally , for the smallest datasets , we also use the ( un - mixed ) stochastic block model approach of ref .",
    "@xcite ; however , that algorithm does not scale well to larger datasets .",
    "for our algorithm , we set @xmath46 , i.e. , we assume that there are 10 groups of users and 10 groups of items ( recall that we do not assume any correspondence between these groups ) .",
    "we considered some other choices of @xmath11 and @xmath12 as well ( see fig .",
    "s2 in the sm ) . since iterating the em equation of eqs .",
    "- can lead to different solutions depending on the initial conditions , we perform sampling of 500 independent runs with random initial conditions .",
    "we average the predicted probabilities over the 500 runs because we typically do not observe that one solution has much higher likelihood than the others ( see fig .",
    "s3 of the sm for results obtained using the maximum likelihood solution ) . as a result , for each rating a user gives an item we have a probability distribution of ratings that results from the average of the probabilities for all the sampling set .",
    "therefore , we can choose how to make predictions from the probability distribution of ratings : the most likely rating , the mean or the median .",
    "in contrast , recommender systems like mf and item - item give only the most probable rating .",
    "we measure the performance in terms of accuracy , i.e. , the fraction of ratings that are exactly predicted by each algorithm , and the mean absolute error ( mae ) . for our algorithm",
    ", we find that the best estimator for the accuracy is the most likely rating from the probability distribution of ratings , while for the mae the best estimator is the median .    ]",
    "we find that in most cases our approach outperforms the item - item algorithm and matrix factorization ( fig .",
    "[ f.compare ] ) . indeed , when considering the accuracy , i.e. , the fraction of times an algorithm exactly predicts the correct rating , the mmsbm is significantly better than matrix factorization for all the datasets we tested , and better than the item - item algorithm in five out of six datasets , the only exception being the amazon books dataset . in terms of the mean absolute error ( mae )",
    ", the mmsbm is the most accurate in four out of the six datasets ( item - item and matrix factorization produce smaller mae in the amazon books and movielens 10 m datasets ) .",
    "interestingly , our approach produces results that are almost identical to those of the un - mixed sbm  @xcite for the two examples for which inference with the sbm is feasible .",
    "in particular , we achieve the same accuracy with @xmath46 in the mixed - membership model as with around @xmath47 groups in the un - mixed sbm .",
    "this suggests that many of the groups observed in  @xcite are in fact mixtures of a smaller number of groups , and that the additional expressiveness of the mmsbm allows us to succeed with a lower - dimensional model .",
    "matrix factorization ( mf ) is one of the most successful and popular approaches to collaborative filtering , both in its `` classical ''  @xcite and its probabilistic form  @xcite .",
    "however , as we have just discussed , our mmsbm gives consistently more accurate results for the ratings , often by a large margin .",
    "here , we analyze the origin of this improvement in performance .",
    "we start by giving an interpretation of matrix factorization in terms of our mmsbm .",
    "a matrix is of rank @xmath11 if and only if its entries can be written as inner products of @xmath11-dimensional vectors associated with its rows as columns .",
    "based on this idea , matrix factorization assumes that the expected rating that user @xmath5 gives item @xmath4 is @xmath48 , where @xmath49 and @xmath50 are @xmath11-dimensional vectors representing the user and the item respectively .",
    "one can apply a variety of noise models or loss functions , as well as regularization terms for the model parameters  @xcite , but this does not alter significantly the considerations that we present next .",
    "the limitations in expressiveness of matrix factorization become apparent when we interpret matrix factorization as a mixture model .",
    "assume that there are @xmath11 groups of users and that @xmath19 is the probability that user @xmath5 belongs to group @xmath16 .",
    "similarly , assume that there are @xmath11 groups of items and that @xmath51 is the probability that item @xmath4 belongs to group @xmath16 .",
    "finally , assume that users in group @xmath16 _ only _ like items in group @xmath16 ; in particular , users in @xmath16 assign a baseline rating of @xmath52 to items in group @xmath16 and a rating of @xmath53 to items in all other groups",
    ". finally , let @xmath54 and @xmath55 be user and item `` intensities '' that correct for the fact that some users rate on average higher than others , and that some items are generally more popular than others .",
    "then the expected ratings are given by @xmath56 identifying @xmath57 and @xmath58 , this becomes the matrix factorization model @xmath48 .",
    "thus ( nonnegative ) matrix factorization corresponds to a model where each group of users corresponds to a group of items , and users in a given group only like items in the corresponding group .",
    "we argue that these assumptions are too limiting to model user recommendations realistically .",
    "( note that our interpretation of matrix factorization as a mixture model is independent of attempts in the literature to combine matrix factorization with other mixture models @xcite . )",
    "our mmsbm relaxes these implausible assumptions by allowing the distribution of ratings to be given by arbitrary matrices @xmath29 , where the entry @xmath14 is the probability that a user in group @xmath16 gives an item in group @xmath17 the rating @xmath15 .",
    "matrix factorization is roughly equivalent to assuming that @xmath59 is diagonal , at least for high ratings .",
    "we believe that the improved performance of the mmsbm over matrix factorization is due to this greater expressive power .",
    "indeed , fig .",
    "[ f.pmatrices ] shows that the matrices @xmath29 inferred by our model are far from the purely diagonal structure implicitly underlying matrix factorization .",
    "moreover , the generality of the mmsbm allows it to account for many of the features of real ratings .",
    "for instance , the distribution of ratings is highly nonuniform : as shown in fig .",
    "[ f.pmatrices ] , @xmath60 is quite rare whereas @xmath61 is quite common .",
    "different groups of users have very different distributions of ratings : users in group @xmath62 rate most movies with @xmath63 , while those in group @xmath64 often give ratings @xmath60 .",
    "similarly , movies in group @xmath65 are consistently rated @xmath63 by most users , while movies in group @xmath66 are rated @xmath60 quite often .",
    "it is also interesting that some groups of users agree on some movies but disagree on others : for example , users in groups @xmath67 agree that most movies in group @xmath65 should be rated @xmath63 , but they disagree on movies in group @xmath66 , rating them @xmath60 and @xmath68 respectively .",
    "these observations highlight the limitation in expressiveness of matrix factorization , and explain why our approach based on mmsbm yields better predictions of the ratings .",
    "because in the mmsbm all terms have a clear and precise ( probabilistic ) interpretation , our approach can naturally deal with situations that are challenging for other algorithms .",
    "an example of this is the cold start problem , that is , a situation in which we want to predict ratings for users or items ( or both ) for which we do not have training data @xcite .    in the mmsbm ,",
    "the @xmath29 matrices are the same for all users and items ; in this sense , new users or items pose no particular difficulty .",
    "however , for a new user @xmath69 we need to calculate their group membership vector @xmath70 ( and analogously @xmath23 for a new item ) . since on average users tend to have a higher probability of belonging to some groups than to others , lacking all information about a user we can assume that they are proportionally more likely to belong to the same groups . in practice",
    ", this means that to any new user @xmath69 we can assign a group membership vector that is the average of the vectors of the observed users , @xmath71 this provides a principle method to deal with the cold start problem , without the need to add additional elements to the model  @xcite .     of cold start cases on average ; the movielens 10 m dataset ( @xmath72 ) ; men rating women ( m - w ) in the libimseti dataset ( @xmath73 ) ; women rating men ( w - m ) in the libimseti dataset ( @xmath74 ) ; and amazon books ( @xmath75 ) .",
    "we did not encounter any cold start cases in the cross - validation experiments with yahoo !",
    "songs ; this is to be expected since yahoo ! songs requires that users and songs have at least 20 ratings .",
    "the left column displays the accuracy for each dataset , and the right column the mean absolute error .",
    "the bars show the average of a five - fold cross - validation and the error bars show the standard error of the mean .",
    "[ f.coldstart ] ]    in fig .",
    "[ f.coldstart ] we show that , also in cold start situations , our mmsbm outperforms the alternatives in most cases . in terms of accuracy , mmsbm is always more accurate than mf ( although in one case the difference is not significant ) , and more accurate than just assigning the most common rating to an item in all cases but one . in terms of",
    "mean absolute error , our approach is more accurate than mf in four out of five cases ( in one , not significantly ) , and more accurate than using the most common rating in four out of five cases .",
    "finally , the expressiveness of the mmsbm enables us to investigate the social and psychological processes that determine user behaviors .",
    "to illustrate this idea , we analyze the user profiles in the movielens 100k dataset , which lists the age and gender of each user .",
    "specifically , we compare the user profiles of pairs of users @xmath76 by computing the cosine similarity @xmath77 .    , we compute the cosine similarity of their user profiles @xmath77 .",
    "panel a shows the average similarity for pairs of females ( f - f ) , pairs of males ( m - m ) and mixed gender pairs ( f - m ) .",
    "the boxes show the mean ( black line ) and one standard error of the mean ; the bars show two standard errors of the mean .",
    "panel b shows average user similarities among users in the same age group , as a function of age .",
    "note that there are no female users of age greater than @xmath78 .",
    "the data suggests that male users are slightly more similar to each other than female users are , and that for all gender pairs similarity decreases with age ( f - f : spearman s @xmath79 ; p - value@xmath80 ; m - m : spearman s @xmath81 , p - value@xmath82 ; spearman s @xmath83 , p - value@xmath84 ) . ]    figure  [ f.agesex ] shows that when when we divide users according to gender , pairs of male users have more similar profiles than pairs of female users or male - female pairs ( see fig .",
    "[ f.agesex]a ) .",
    "interestingly , when we combine gender and age to define user groups , we find that gender profile similarities are not independent of the age groups ( see fig .",
    "[ f.agesex]b ) .",
    "in fact , we observe the general tendency that young users within a gender group seem to have larger profile similarities than older users .",
    "interestingly , this tendency is more apparent for female users who are the group with larger similarity for ages 10 - 20 and the one with lower similarity for ages 40 - 50 .",
    "our results show that the mmsbm we propose , and its associated expectation - maximization algorithm , is a robust , well - performing , and scalable solution to predict user - item ratings in different contexts .",
    "additionally , the interpretability of its parameters enables the analysis of the underlying social behavior of users .",
    "for example , we found that the similarity of users behavior is correlated with their gender and their age .",
    "these findings could conceivably lead to extensions of the model that take such behavioral considerations into account , for example by adding metadata to users ( e.g. age and gender ) and items ( e.g. genre ) .",
    "in fact , stochastic block models with node metadata have recently been proposed  @xcite and may be a promising way to extend our approach .",
    "another advantage of the interpretability of our model and its parameters is that it can be readily applied to ( and performs well in ) situations that are challenging to other approaches , such as a cold start where no prior information is available about a new user or item .",
    "finally , the mmsbm outperforms matrix factorization in all the cases we consider , often by a large amount .",
    "as we have discussed , this is due to the fact that mmsbm is a more expressive generalization of the model underlying matrix factorization ; matrix factorization corresponds roughly to the special case of mmsbm where the matrices @xmath59 are diagonal , and where we assume the rating probabilities @xmath14 for different @xmath15 are strongly correlated ( corresponding to treating @xmath15 as a number rather than a symbol ) .",
    "matrix factorization is a widely used tool with many applications beyond recommender systems ; given our findings and the scalable expectation - maximization algorithm , it may make sense to use mmsbms in those other applications as well .",
    "in the mmsbm , each user @xmath5 has a vector @xmath19 describing how much she belongs to group @xmath16 , and each item @xmath4 has a vector @xmath85 describing how much it belongs to group @xmath17 .",
    "we treat these as probabilities , and normalize them as @xmath86 similarly , the matrices @xmath14 are normalized to give probability distributions of ratings over @xmath87 , @xmath88 we maximize the likelihood   as a function of @xmath25 using an expectation maximization ( em ) algorithm .",
    "we start with a standard variational trick that changes the log of a sum into a sum of logs , writing @xmath89 here @xmath41 is the estimated probability that a given ranking @xmath7 is due to @xmath5 and @xmath4 belonging to groups @xmath16 and @xmath17 respectively , and the lower bound in the third line is jensen s inequality @xmath90 .",
    "this lower bound holds with equality when @xmath91 giving us the update equation   for the expectation step .    for the maximization step ,",
    "we derive update equations for the paremeters @xmath25 by taken derivatives of the log - likelihood  . including lagrange multipliers for the normalization constraints  , we obtain @xmath92 where @xmath93 is the degree of the user @xmath5 .",
    "similarly , @xmath94 where @xmath95 is the degree of item @xmath4 .",
    "this completes the derivation of   and  . finally , including a lagrange multiplier for  , we have @xmath96 completing the derivation of  .",
    "[ cols=\"<,^,>,>,>,^\",options=\"header \" , ]     [ t - data ]    we perform experiments on six different datasets : the movielens 100k and 10 m datasets ( ) , yahoo ! songs ( , ) , amazon books ( ) , and the libimseti.cz dating agency ( ) . we split the libimseti.cz dataset into two datasets : women rating men ( w - m ) and men rating women ( m - w ) .",
    "we neglected the links of women rating women and men rating men ; unfortunately these links constituted only 1% of the dataset . in table",
    "[ t - data ] , we show the characteristics of each dataset in terms of the scale of ratings @xmath8 , the total number of users , the total number of items , the number of ratings and the average percentage of cold start cases . the movielens 100k dataset also provides demographic information for the users , namely the age in years and gender .",
    "* naive model * as a baseline for comparison , we consider a naive model .",
    "its prediction for a rating @xmath7 is simply the average of @xmath4 s observed ratings , @xmath97 * item - item * the item - item algorithm uses the cosine similarity between items , based on the @xmath0-dimensional vectors of ratings they have received , adjusted to remove user biases towards higher or lower ratings  @xcite .",
    "the cosine similarity of items @xmath4 and @xmath98 is then @xmath99 .",
    "the predicted rating @xmath7 is the similarity - weighted average of the @xmath16 closest neighbors of @xmath4 that user @xmath5 has rated .",
    "we use the default , optimized implementation of the algorithm in lenskit  @xcite with @xmath100 .",
    "* matrix factorization * one of the most widely used recommendation algorithms is matrix factorization ( mf )  @xcite . like the block model",
    ", the intuition behind matrix factorization is that there should be some latent features that determine how a user rates an item .",
    "however , it uses linear algebra to reduce the dimensionality of the problem .",
    "specifically , it assumes that the matrix of ratings @xmath31 ( with @xmath0 rows and @xmath1 columns ) is of rank @xmath16 , in which case it can be written @xmath101 where @xmath102 is a @xmath103 matrix and @xmath104 is a @xmath105 matrix .",
    "if we denote the rows of matrix @xmath102 as @xmath106 and the columns of @xmath104 as @xmath107 , then individual ratings are inner products @xmath108 .",
    "we then assume that some noise and/or bias has been applied to @xmath31 to produce the observed ratings @xmath10 .",
    "for example , some users rate items higher than others , and some items are systematically highly rated . in order to take this into consideration ,",
    "the unobserved ratings @xmath7 are estimated using @xmath109 where @xmath110 and @xmath111 are the biases of users and items respectively and @xmath112 is the average rating in @xmath10 . for the purpose of making recommendations ,",
    "it is convenient to pose the decomposition problem as an optimization one ; in particular , minimizing the @xmath113 error and applying a regularization term gives @xmath114 \\ , .",
    "\\end{split}\\ ] ] where @xmath115 is a regularization parameter . as funks",
    "originally proposed @xcite one can solve this problem numerically using stochastic gradient descent  @xcite .",
    "we use the lenskit implementation of the algorithm , with @xmath100 and a learning rate of @xmath116 as suggested in ref .",
    "@xcite .    * stochastic block model * the stochastic block model ( sbm )  @xcite assumes that the probability that two nodes form a link between them , such as a relationship between actors in a social network , depends on what groups they belong to .",
    "analogously , the sbm recommender algorithm  @xcite assumes that the probability of a rating @xmath7 of a user @xmath5 for an item @xmath4 depends on the groups @xmath117 , @xmath118 to which they belong ; unlike this paper , it assumes that each user or item belongs to a single group rather than a mixture .",
    "it uses a bayesian approach that deals rigorously with the uncertainty associated with the models that could potentially account for the observed ratings .",
    "mathematically , the problem is to estimate @xmath119 that the unobserved rating of item @xmath4 by user @xmath5 is @xmath120 given the observable ratings @xmath10 .",
    "this is an integral over all possible block models @xmath1 , @xmath121 where @xmath122 is the probability that @xmath120 if the ratings where actually generated using model @xmath1 , and @xmath123 is the probability of model @xmath1 given the observation ( assuming for simplicity that all models @xmath1 are equally likely a priori ) .",
    "this integral is over the continuous and discrete parameters of the block model . in particular",
    ", for each @xmath15 and each pair of groups @xmath124 we integrate over the continuous parameters @xmath125 = p_{k\\ell}(r)$ ] ; this part of the integral can be carried out analytically .",
    "however , the integral   also averages over all assignments @xmath126 of groups to users and items ; this expectation is estimated by metropolis - hastings sampling .",
    "finally the prediction for each rating is the maximum - marginal estimate , @xmath127    this work was supported by a james s. mcdonnell foundation research award ( rg , ms ) , spanish ministerio de economia y comptetitividad ( mineco ) grants fis2013 - 47532-c3 ( agl , rg , msp ) and fis2015 - 71563-erc ( rg ) , european union fet grant 317532 ( multiplex , rg , msp ) , the john templeton foundation ( cm ) and the aro under contract w911nf-12-r-0012 ( cm ) .",
    "30ifxundefined [ 1 ] ifx#1 ifnum [ 1 ] # 1firstoftwo secondoftwo ifx [ 1 ] # 1firstoftwo secondoftwo `` `` # 1''''@noop [ 0]secondoftwosanitize@url [ 0 ]",
    " + 12$12  & 12#1212_12%12@startlink[1]@endlink[0]@bib@innerbibempty link:\\doibase 10.1155/2009/421425 [ * * ,   ( ) ] @noop * * ,   ( ) link:\\doibase 10.1016/j.bbi.2008.05.010 [ * * ,   ( ) ] link:\\doibase 10.1103/physrevx.5.011033 [ * * ,   ( ) ] link:\\doibase 10.1155/2009/785152 [ * * ,   ( ) ] \\doibase    http://dx.doi.org/10.1016/j.csda.2006.11.006",
    "[ * * ,   ( ) ] @noop * * ,   ( ) http://hdl.handle.net/1853/20058[__ ] ,  ( ,  ) link:\\doibase 10.1073/pnas.0308531101 [ * * ,   ( ) ] ,   link:\\doibase 10.1103/physreve.84.036103 [ * * ,   ( ) ] @noop * * ,   ( ) in @noop _ _ ,  ( ,  ,  )  pp .",
    "link:\\doibase 10.1145/1390156.1390267 [ ( ) ] ( ,  ,  )  pp .",
    "link:\\doibase 10.1145/2043932.2043958 [ ( ) ] http://arxiv.org/abs/1311.1704 [ * * ( ) ] in  link:\\doibase 10.1145/2766462.2767755 [ _ _ ] ,   ( ,  , )  pp .   in link:\\doibase 10.1145/2783258.2783381",
    "[ _ _ ] ,   ( ,  , )  pp .   in  http://www.occamslab.com/petricek/papers/dating/brozovsky07recommender.pdf[__ ] ( ,  ,  ) in @noop _ _ ,  ( )  pp .   in @noop _",
    "_  ( ,  )  pp . in  @noop",
    "_ _  ( , )  pp .",
    "[ * * ( ) ] in  link:\\doibase 10.1145/371920.372071 [ _ _ ] ,  ( ,  ,  )  pp .   in  @noop",
    "_ _  ( )  pp .",
    "link:\\doibase 10.1016/0165 - 1684(84)90013 - 6 [ * * ,   ( ) ] @noop * * ,   ( ) @noop * * ,   ( ) link:\\doibase 10.1073/pnas.0908366106 [ * * ,   ( ) ]"
  ],
  "abstract_text": [
    "<S> with ever - increasing amounts of online information available , modeling and predicting individual preferences  for books or articles , for example  is becoming more and more important . </S>",
    "<S> good predictions enable us to improve advice to users , and obtain a better understanding of the socio - psychological processes that determine those preferences . </S>",
    "<S> we have developed a collaborative filtering model , with an associated scalable algorithm , that makes accurate predictions of individuals preferences . </S>",
    "<S> our approach is based on the explicit assumption that there are groups of individuals and of items , and that the preferences of an individual for an item are determined only by their group memberships . </S>",
    "<S> importantly , we allow each individual and each item to belong simultaneously to mixtures of different groups and , unlike many popular approaches , such as matrix factorization , we do not assume implicitly or explicitly that individuals in each group prefer items in a single group of items . </S>",
    "<S> the resulting overlapping groups and the predicted preferences can be inferred with a expectation - maximization algorithm whose running time scales linearly ( per iteration ) with the number of observed ratings . </S>",
    "<S> our approach enables us to predict individual preferences in large datasets , and is considerably more accurate than the current algorithms for such large datasets .    </S>",
    "<S> the goal of recommender systems is to predict what movies we are going to like , what books we are going to purchase , or even who we might be interested in dating . </S>",
    "<S> the rapidly growing amount of data on item reviews , ratings , and purchases from a growing number of online platforms holds the promise to facilitate the development of finer and more informed models for recommendation . at the same time </S>",
    "<S> , however , it poses the challenge of developing algorithms that can handle such large amounts of data both accurately and efficiently .    a plausible expectation when developing recommendation algorithms is that similar users relate to similar objects in a similar manner , i.e. , they purchase similar items and give the same item similar ratings . </S>",
    "<S> this means that we can use the rating history of a set of users to make recommendations , even without knowing anything about the characteristics of users or items ; this is the basic underlying assumption of collaborative filtering , one of the simplest and most common approaches in recommender systems  @xcite . </S>",
    "<S> however , most research in recommender systems has not focused on precisely formalizing these general assumptions into plausible and rigorous models , but rather on the development of scalable algorithms , often at the price of implicitly using models that are overly simplistic or unrealistic . for example </S>",
    "<S> , matrix factorization and latent feature approaches assume that users and items live in some abstract low - dimensional space , but whether such a space is expressive enough to accommodate for the rich variety of user behaviors is rarely discussed . as a result , </S>",
    "<S> such state - of - the - art scalable approaches have significantly lower accuracies than inference approaches based on models of user preferences that are socially more realistic  @xcite . </S>",
    "<S> on the other hand , these more realistic approaches do not scale well with dataset size , which makes them unpractical for large datasets .    here </S>",
    "<S> , we develop an approach to predict user ratings that makes explicit hypotheses about rating behavior . </S>",
    "<S> in particular , our approach is based on the assumption that there are groups of users and of items , and that the rating a given user assigns to a given item is determined probabilistically by their group memberships . </S>",
    "<S> importantly , we do not assign users and items to a specific group ; rather , we allow each user and each item to belong simultaneously to mixtures of different groups  @xcite . </S>",
    "<S> all of these elements are combined in a model with a precise probabilistic interpretation , which allows for rigorous inference algorithms . </S>",
    "<S> happily , the inference problem for our model can be solved very efficiently : specifically , we propose an expectation - maximization algorithm whose running time , per iteration , scales linearly with the number of observed ratings , and which appears to converge rapidly in practice .    </S>",
    "<S> we demonstrate that our model is more realistic than those implicit in other approaches ( particularly matrix factorization ) and that , as a consequence , our approach consistently outperforms state - of - the - art collaborative filtering approaches , often by a large margin . </S>",
    "<S> moreover , because our model has a clear interpretation , it can deal naturally with some situations that are challenging for other approaches ( for example , the cold start problem ) and can help to build theories about user behavior . </S>",
    "<S> we argue that our approach may also be suitable for other areas where matrix factorization is increasingly used such as image reconstruction , textual data mining , cluster analysis or pattern discovery @xcite . </S>"
  ]
}