{
  "article_text": [
    "polyanskiy et al .",
    "@xcite tightly characterized the back - off from capacity at short blocklengths without feedback by providing achievability and converse bounds on the maximum rate , along with a normal approximation using the channel dispersion ( i.e. , the stochastic variation of the channel ) that closely approximates both bounds .",
    "the results of @xcite show that there is a severe penalty in the maximum achievable rate for small blocklengths ( on the order of several hundred bits or less ) .    in @xcite ,",
    "polyanskiy et al . investigated how including feedback improves the maximum achievable rate at short blocklengths .",
    "noiseless feedback does not increase the asymptotic ( shannon ) capacity of memoryless channels @xcite , but it _ can _ significantly improve the achievable rate at short blocklengths . for ( even the best ) fixed - length block codes paired with an arq strategy ,",
    "the maximum rate is slow to converge to the asymptotic capacity .",
    "however , when _",
    "variable_-length coding is used on channels with noiseless feedback , the maximum rate can improve dramatically @xcite as compared to the no - feedback case for short average blocklength .    polyanskiy et al .",
    "considered two main categories of coding with feedback in @xcite : variable - length feedback ( vlf ) coding , in which the receiver decides when to terminate transmission based on a desired probability of error @xmath0 , and variable - length feedback coding with termination ( vlft ) , in which the receiver provides full , noiseless feedback to the transmitter , which uses an infinitely reliable feedforward channel to terminate the transmission when the receiver has decoded to the correct codeword .    in @xcite , we presented a vlft scheme based on a rate - compatible sphere - packing ( rcsp ) analysis and tail - biting convolutional codes .",
    "we showed that when constrained to limited decoding attempts , vlft implemented with rate - compatible , punctured , tail - biting convolutional codes can provide higher throughput than the random coding lower bound of @xcite .    in this paper",
    ", we focus on vlf codes and demonstrate a scheme that achieves a higher rate than the random coding achievability bound of @xcite .",
    "in particular , we show that trellis - based codes ( e.g. , convolutional codes ) in which decoding is attempted after each received symbol using the reliability output viterbi algorithm ( rova ) @xcite can deliver rates surpassing the vlf random coding bound .    the remainder of the paper proceeds as follows : sec .",
    "[ sec : vlf ] reviews the vlf results of @xcite .",
    "[ sec : rova ] presents the reliability output viterbi algorithm ( rova ) and its use in the vlf setting .",
    "[ sec : simulation_results ] shows simulation results for vlf using convolutional codes and the rova , comparing these results with finite - blocklength bounds on the maximum rate for both the binary symmetric channel ( bsc ) and additive white gaussian noise ( awgn ) channel .",
    "[ sec : conc ] concludes the paper .",
    "in the variable - length feedback ( vlf ) coding setting , the receiver attempts to decode the true message @xmath1 based on the sequence of @xmath2 symbols that have been received so far , @xmath3 .",
    "the receiver terminates the transmission when its estimate of the message @xmath4 is sufficiently reliable to satisfy the @xmath0 error requirement , i.e. , @xmath5 , where @xmath6 is the transmitted sequence corresponding to message @xmath7 .",
    "the transmitter is informed of the receiver s requests for additional coded symbols via noiseless ack / nacks , requiring only one bit of feedback per forward channel use ( i.e. , we are considering _ stop - feedback codes _",
    "@xcite , or _",
    "decision feedback _",
    "we denote average blocklength by @xmath8 , the cardinality of the message alphabet @xmath9 by @xmath10 , and the required average probability of message error by @xmath0 .",
    "polyanskiy et al.s achievability result for vlf follows :    for a scalar @xmath11 , there exists an @xmath12 vlf code satisfying    rcl & & [ ] , + & & ( m-1 ) [ | ] ,    where @xmath13 is used as a threshold for determining the hitting times @xmath14 and @xmath15 :    rcl & = & \\{n 0 : i(x^n;y^n ) } [ eqn : vlf_tau ] +     [ thm : achievability ]    this lower bound uses random coding to prove that some code exists with at least the given cardinality @xmath10 , though it does nt specify how to efficiently compute the information densities @xmath16 for each of the @xmath10 codewords , for @xmath17 .",
    "polyanskiy et al.s converse result for vlf(@xmath0 ) curves comes from ( * ? ? ?",
    "* lemmas 1 and 2 ) :    for an arbitrary dmc with capacity @xmath18 and @xmath19 , any @xmath12 vlf code satisfies :    rcl m & ,    where @xmath20 is the binary entropy function .",
    "[ thm : converse_awgn ]    when the maximal relative entropy @xmath21 is finite , we have the following converse result , which is tighter than thm .",
    "[ thm : converse_awgn ] :    for a dmc with @xmath22@xmath23@xmath18@xmath24@xmath21@xmath23@xmath25 and @xmath26 , any @xmath12 vlf code satisfies :    rcl & _ 0<1 - ,    where    rcl a & = & m - f_m ( ) - ( f_m ( ) , m ) , + b & = & | - |^+ , + c_1 & = & _ x_1,x_2 d ( _ y|x = x_1|_y|x = x_2 ) , + f_m(x ) & = & x ( m-1 ) + h_b(x ) , 0 x 1 , + _ 1 & = & _ y , x_1,x_2 ( 0,1 ) .",
    "[ thm : converse_bsc ]    as shown in fig .",
    "[ fig : rova_bsc_sims ] for the binary symmetric channel with crossover probability @xmath27=@xmath28 , there is a considerable gap between the lower ( achievability ) and upper ( converse ) bounds on the maximum rate at short blocklengths . in this paper",
    "we demonstrate that convolutional codes can deliver performance surpassing the lower bound , suggesting that other bounding techniques besides those based on random coding may be appropriate for especially short blocklengths .",
    "in order to use vlf codes in practice , the receiver must compute the probability that the codeword @xmath6 of length @xmath2 it has decoded is correct , @xmath29 .",
    "this can be calculated as    rcl ( x^n|y^n ) & = & + & = & ,    which can be further simplified if each of the codewords @xmath30 is _ a priori _ equally likely , i.e. , @xmath31 .",
    "this yields    rcl ( x^n|y^n ) & = .",
    "[ eqn : p_x_y ]    in general , the denominator in may be computationally intractable when the message set cardinality @xmath10 is large .",
    "however , in much the same way that the viterbi algorithm takes advantage of the trellis structure of convolutional codes to compute @xmath32 for maximum - likelihood decoding , an augmented viterbi decoder referred to as the reliability output viterbi algorithm ( rova ) @xcite can be used to compute @xmath29 exactly with relative efficiency .",
    "the complexity of the rova is linear in the blocklength and exponential in the constraint length of the code ( i.e. , it has complexity on the same order as that of the original viterbi algorithm ) .",
    "this probability can also be computed approximately by the simplified ( approximate ) rova @xcite .",
    "the rova can be used to compute the probability of word error for any finite - state markov process observed via memoryless channels ( e.g. , in maximum - likelihood sequence estimation for signal processing applications ) .      in @xcite ,",
    "fricke et al . proposed a reliability - based retransmission criteria for hybrid arq , using the word error probability calculated by the decoder . similarly , in order to investigate the maximum rate at short blocklengths , we use the rova to compute @xmath29 .",
    "if the computed word error probability is larger than the target error probability @xmath0 , our decoder signals that additional codeword symbols are required ( e.g. , sends a nack ) , and the transmitter sends another coded symbol . when @xmath29 is computed exactly , this scheme guarantees that the overall undetected error rate will converge to a value less than the target @xmath0 .",
    "as compared to setting aside some parity bits to be used only for error detection ( e.g. , in a crc ) , a reliability - based feedback approach allows all coded symbols to be used for both error correction and detection , improving throughput .",
    "hof et al .",
    "@xcite provides a modification to the viterbi algorithm which permits erasure decoding according to forney s generalized decoding rule @xcite , based upon a predetermined erasure threshold @xmath33 . using forney s rule , a decoder picks codeword @xmath34 if the following is satisfied :    rcl e^nt ,    which is equivalent to the following condition :    rcl ( x_m^n|y^n ) .",
    "we note that setting the threshold @xmath33 according to @xmath35 coincides with the rova , in which a target undetected error probability @xmath0 is specified . like that of the rova ,",
    "the complexity of hof s modified viterbi algorithm @xcite is linear in the blocklength and exponential in the constraint length .",
    "the algorithms are functionally equivalent , though the rova computes @xmath36 in order to yield @xmath37 , while hof s algorithm computes @xmath38",
    ".      bounds on the maximum rate in @xcite assume that an infinite - length codebook is available , i.e. , that an infinite number of coded symbols may be transmitted until the receiver makes a reliable decoding decision . while such infinite - length code constructions exist ( e.g. , rateless fountain codes ) , we demonstrate that the combination of decoding after every symbol and ack / nack feedback controlling additional transmissions delivers high rates at short blocklengths even when the codewords have finite length .",
    "similar behavior is seen in @xcite , which explores the effect of finite - length codewords on the achievable rates of vlft coding .",
    "we encode a message with @xmath39 message bits into a mother codeword of length @xmath40 .",
    "the initial transmission is accomplished by pseudo - random rate - compatible puncturing of the mother code @xcite , such that one symbol is transmitted at a time and the receiver uses all received symbols to decode .",
    "if the receiver requests additional redundancy after the @xmath40 symbols have been exhausted , the transmitter begins resending the original sequence of symbols and decoding starts from scratch .",
    "while some benefit can be accrued by retaining the @xmath40 already transmitted symbols ( for example , by chase code combining ) , we do not exploit this opportunity in our simulations for simplicity .    the latency @xmath8 ( i.e. , average number of channel uses , or average blocklength ) and the throughput @xmath41 of the proposed scheme are given by    rcl & = & , [ eqn : lambda_rova ] + r_t & = & ( 1 - p _ ) , [ eqn : rt_rova ]    where @xmath42 is the probability of a nack generated because the rova computed the probability of error to be larger than @xmath0 when @xmath43 coded symbols have been received , and @xmath44 is the overall probability of undetected error . both @xmath42 and @xmath44 depend on the target @xmath0 . and @xmath44 via simulation .",
    "] we have included the factor @xmath45 in the throughput expression to emphasize that we are only counting messages that are decoded successfully at the receiver ( i.e. , the goodput ) .",
    ".generator polynomials @xmath46 , @xmath47 , and @xmath48 corresponding to the rate @xmath49/@xmath50 convolutional codes used in the rova simulations .",
    "@xmath51 is the free distance , @xmath52 is the number of codewords with weight @xmath51 , and @xmath53 is the analytic traceback depth . [",
    "cols=\"^,^,^,^,^,^ \" , ]     [ tbl : conv_codes ]    table [ tbl : conv_codes ] lists the rate @xmath49/@xmath50 convolutional codes from ( * ? ? ?",
    "* table 12.1 ) that were used as mother codes for simulations .",
    "the codes selected have the optimum free distance @xmath51 , which is listed along with the analytic traceback depth @xmath53 @xcite .",
    "zero - tail trellis termination is used to facilitate the rova , resulting in rate loss ( compared to a tail - biting code with no termination bits ) at short blocklengths . for a code with @xmath54 memory elements and rate @xmath55 , the code s effective information rate is @xmath56 and the rate loss factor is @xmath57 .    as part of the rova",
    ", the original viterbi algorithm is used to compute the maximum - likelihood estimate of the transmitted sequence @xmath58 ( representing the mother codeword @xmath59 ) after each new symbol is received .",
    "as soon as the estimate is sufficiently reliable , i.e. , @xmath60 , transmission terminates and a new codeword is simulated .",
    "[ fig : rova_bsc_sims ] compares the results of vlf simulations using convolutional codes and the rova with polyanskiy et al.s upper bound and random - coding lower bound on rate for a bsc with crossover probability @xmath27=@xmath28 and target probability of error @xmath0@xmath61@xmath62 .",
    "the ( asymptotic ) capacity of the bsc with crossover probability @xmath27 is @xmath63 .",
    "the upper bound is from thm .",
    "[ thm : converse_bsc ] and the lower bound is from thm .  [ thm : achievability ] .",
    "though the upper and lower bounds for vlf codes coincide asymptotically , there is a considerable gap when latency is below 100 bits , a region in which convolutional codes can deliver high rates . at the shortest blocklengths , the 64-state code with the fewest memory elements performs best , due to the trellis - termination rate loss of the codes with larger constraint lengths .",
    "however , as the message size @xmath64 increases ( and the latency @xmath8 increases ) , the larger 1024-state code delivers superior throughput performance . as the latency continues to increase ,",
    "the codes throughputs fall below that of the vlf achievability bound .",
    "as the average latency grows , the power of random coding grows but the power of the convolutional codes does not improve significantly once the average latency is beyond twice the traceback depth @xmath53 of the convolutional code @xcite .",
    "[ fig : rova_bsc_sims ] also includes information - theoretic limits on the maximum rate attainable at short blocklengths without feedback .",
    "the  max .",
    "rate for fixed - length block code , no feedback \" curve uses the channel dispersion to compute the maximum rate , which tightly approximates both the achievability and converse bounds when there is no feedback @xcite .",
    "[ fig : rova_awgn_sims ] compares the results of vlf simulations using convolutional codes and the rova with polyanskiy et al.s upper bound and random coding lower bound on rate for the awgn channel with snr @xmath65 db and target @xmath0@xmath61@xmath62 .",
    "the ( asymptotic ) capacity of the awgn channel with snr @xmath66 is @xmath67 .",
    "the upper bound is from thm .",
    "[ thm : converse_awgn ] and the lower bound is from thm .",
    "[ thm : achievability ] , particularized to the gaussian channel .",
    "details of the vlf(@xmath0 ) computation for the awgn channel are provided in the appendix .",
    "the convolutional codes shown in fig .  [ fig : rova_awgn_sims ] assume transmission over a binary - input awgn ( bi - awgn ) channel ( i.e. , using bpsk signaling ) with soft - decision decoding , which has a maximum shannon capacity of 1 bit per channel use even when the snr @xmath66 is unbounded .",
    "however , we have compared the throughput of the rova simulations with the capacity @xmath68 and vlf bounds for the full awgn channel ( i.e. , with real - valued inputs drawn i.i.d .",
    "@xmath69 ) . for snr=2 db and capacity 0.6851",
    "this is a minor concern .",
    "however , simulations at higher snrs would require a higher order modulation ( e.g. , qam ) to achieve rates above 1 .",
    "for latencies ( average blocklengths ) on the order of 50 or 75 transmissions and less for the bsc and awgn channel , respectively , vlf simulations with convolutional coding and rova outperform the random coding bound on vlf codes . furthermore , every operation performed in the simulation is implementable and only one bit of feedback is required per decoding attempt . as discussed above ,",
    "the rova for computing the probability of error associated with the most likely codeword has the same order of complexity as the viterbi algorithm .      for comparison with the vlf random coding bounds , we focused attention to the case where decoding is attempted every symbol .",
    "decoding less frequently is more practical due to the round - trip delay inherent in the feedback loop and because of the complexity of performing the rova after each received symbol .",
    "decoding ( with the rova ) only after groups of symbols (  packet \" transmissions ) is a natural extension of this work . limiting the frequency of decoding increases latency , but",
    "the additional latency can be minimal if the decoding interval is well - chosen , as shown for vlft in @xcite .",
    "fricke et al .",
    "@xcite used this approach in a reliability - based hybrid arq scheme , though that work was not focused on the short - blocklength regime .",
    "convolutional codes were chosen based on their error - correcting performance at short blocklengths ( as compared to , for example , ldpc and turbo codes ) and relatively low decoding complexity . in our simulations ,",
    "throughput performance flattens after latency reaches about 75 symbols , consistent with the analytical traceback depths of @xmath70 . unlike ldpc codes and turbo codes",
    ", the power of a convolutional code does not increase with blocklength ; blocklengths greater than two or three times the analytical traceback depth wo nt significantly lower the error rate and hence wo nt improve throughput .",
    "the achievability of thm .",
    "[ thm : achievability ] is still valid ; some code with the specified performance exists , but convolutional codes are not likely candidates for achievability at moderate blocklengths .",
    "recent work by maiya et al .",
    "@xcite compared fixed - blocklength convolutional codes and ldpc codes without feedback to determine which codes yielded the best performance at low latencies ( not in an incremental redundancy setting ) .",
    "they showed that for a fixed target error rate ( e.g. , ber  @xmath61  @xmath71 ) and code rate ( e.g. , @xmath72 ) , viterbi - decoded convolutional codes offered the best performance at low latency ( e.g. , less than 100 bits ) and that ldpc codes decoded with iterative message passing offered the best performance for high latencies ( e.g. , greater than 220 bits ) . in an intermediate range of latencies ( e.g. , 100 to 220 bits ) , convolutional codes with stack sequential decoding were optimal .",
    "this suggests that in order to deliver throughput above the vlf lower bound at moderate blocklengths , ldpc codes or stack sequential decoding of convolutional codes may be suitable .",
    "for the memoryless awgn channel with snr @xmath66 , we have @xmath73@xmath74@xmath75 , @xmath76@xmath74@xmath77 , @xmath78@xmath74@xmath79 , and @xmath80@xmath74@xmath81 , where @xmath82 is the @xmath83 diagonal matrix .",
    "the awgn information density is :                                  for each value of @xmath2 , the term @xmath97 $ ] can be evaluated numerically using the expression for @xmath16 in . for the awgn channel ,",
    "this computation involves a 3-dimensional integral over the random variables @xmath89 , @xmath91 , and @xmath92 ."
  ],
  "abstract_text": [
    "<S> this paper presents a reliability - based decoding scheme for variable - length coding with feedback and demonstrates via simulation that it can achieve higher rates than polyanskiy et al.s random coding lower bound for variable - length feedback ( vlf ) coding on both the bsc and awgn channel . </S>",
    "<S> the proposed scheme uses the reliability output viterbi algorithm ( rova ) to compute the word error probability after each decoding attempt , which is compared against a target error threshold and used as a stopping criterion to terminate transmission . </S>",
    "<S> the only feedback required is a single bit for each decoding attempt , informing the transmitter whether the rova - computed word - error probability is sufficiently low . </S>",
    "<S> furthermore , the rova determines whether transmission / decoding may be terminated without the need for a rate - reducing crc . </S>"
  ]
}