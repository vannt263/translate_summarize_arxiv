{
  "article_text": [
    "the generalized linear model ( glm ) is heavily used by researchers and practitioners for regression analysis on categorical , count , and continuous outcomes @xcite .",
    "standard glm theory assumes an exponential family distribution , such as poisson to model counts and binomial to model success / failure data .",
    "these distributions are limited in the amount of variability they can express .",
    "glm users often encounter the issue of overdispersion , where the data exhibit variability which can not be expressed by the model . this can manifest itself in a number of ways , depending on the specific nature of the overdispersion and its departure from the model .",
    "for example , assuming independence in clustered data can result in standard error estimates which are too small and lead to tests with an inflated type i error rate ( * ? ? ?",
    "* chapter 1 ) .",
    "the objective of this paper is to extend the glm so that a finite mixture of @xmath0 simpler densities can be used as the distribution for the response .",
    "there is a well - established literature on finite mixtures of regressions , in which each component distribution of a finite mixture is linked to a separate regression @xcite .",
    "an analyst may employ a finite mixture of regressions model if heterogeneity is suspected in the relationship between covariate @xmath1 and response @xmath2 among sampled units , yet not enough is known to model the heterogeneity explicitly .",
    "specifying regressions for @xmath0 latent subpopulations may complicate model selection in practice .",
    "often , the interest may be in modeling the mean response , and heterogeneity is simply a nuisance rather than a target for inference .",
    "this motivates us to formulate the mixture link model , which uses a finite mixture to capture extra variation , but constrains the mean of the finite mixture to be linked to a single regression function .",
    "the mean of a finite mixture is composed of multiple parameters which may not appear directly in the likelihood .",
    "central to the development of mixture link is the set in which the link constraint is honored . in the case of positive - valued means ,",
    "this constraint set is a polytope , while for probability - valued means it is the intersection of a polyhedron and a unit cube . for real - valued means ,",
    "the constraint set is the basis of a linear space .",
    "a random effects structure is assumed on this set to complete specification of the likelihood . under poisson and normal outcome types ,",
    "the random effects can be integrated out to yield a tractable form for the density .",
    "the case of binomial outcomes is more computationally challenging .",
    "taking a bayesian approach to inference , a simple random - walk metropolis - hastings sampler can be used for the normal and poisson mixture link models . for binomial outcomes ,",
    "we consider a metropolis - within - gibbs sampler with data augmentation to avoid repeated evaluation of the marginal density .",
    "a number of methods have been established to handle overdispersion .",
    "@xcite provide an overview in the settings of count and categorical data .",
    "one common approach is to extend a basic distribution by assuming the presence of latent random variables , and then integrating them out .",
    "the beta - binomial  @xcite , zero - inflated binomial @xcite , and random - clumped binomial  @xcite distributions are all obtained in this way starting from the binomial distribution .",
    "similarly , the negative binomial and zero - inflated negative binomial distributions @xcite are obtained starting from the poisson distribution . in this same way",
    ", the t - distribution @xcite may be considered an overdispersion model relative to the normal distribution .",
    "generalized linear mixed models are obtained by adding random effects to the regression function  @xcite ; the marginal likelihood of the outcomes usually can not be written without an integral for non - normal outcomes .",
    "quasi - likelihood methods extend the likelihood in ways that do not yield a proper likelihood , but allow inference to be made on regression coefficients . a simple quasi - likelihood",
    "is obtained from placing a dispersion multiplier to the variance ( * ? ? ?",
    "* section  4.7 ) .",
    "the method of @xcite requires specification of only the mean - variance relationship to form a system of equations and carry out inference .",
    "generalized estimating equations ( gee ) is a quasi - likelihood method for grouped data where the analyst assumes a working correlation structure for observations taken within a subject  @xcite .",
    "some bayesian overdispersion methods are discussed in the collection assembled by @xcite ; for example , @xcite consider generalizing the link function of a glm to a mixture distribution and @xcite propose generalized exponential families for the outcome .",
    "more recently , @xcite proposed a bayesian approach to generalized additive models under the zero - inflated negative binomial model to estimate complicated regression functions .    the rest of the paper proceeds as follows .",
    "section  [ sec : mixlink - model ] formulates the mixture link general model .",
    "section  [ sec : mixlink - probs ] develops mixture link under probability - valued means , with special attention given to binomial outcomes .",
    "sections [ sec : mixlink - positive ] and [ sec : mixlink - real ] develop mixture link for positive- and real - valued means , respectively , and obtain specific models for poisson and normal outcomes .",
    "section  [ sec : data - examples ] presents example data analyses with mixture link binomial and mixture link poisson .",
    "finally , section  [ sec : conclusions ] concludes the paper .",
    "the package for ( available from http://cran.r-project.org ) provides much of the mixture link functionality discussed in this paper .",
    "the usual glm formulation is based on a density in the exponential dispersion family , @xmath3 where @xmath4 is the canonical parameter which influences the mean and @xmath5 is the dispersion parameter . here",
    "it can be shown that @xmath6 and @xmath7 , and expressions for the score vector and information matrix can be obtained ( * ? ? ?",
    "* section 4.4 ) .",
    "estimation can be carried out routinely , using newton - raphson or scoring algorithms to compute maximum likelihood estimates , or standard mcmc algorithms for a bayesian analysis .",
    "our objective is to modify this framework to allow a finite mixture as the outcome distribution , establishing a link between the mixture mean and a regression function of interest .",
    "because finite mixtures can support more variation than distributions of the form , this extension should naturally support variation beyond standard glms .",
    "we are especially interested in finite mixtures of three common glm outcome types : normal , binomial , and poisson .",
    "consider a random variable @xmath8 following the finite mixture distribution , @xmath9 here , the mixing proportions @xmath10 belong to the probability simplex @xmath11^j : \\lambda_j \\geq 0 , \\vec{\\lambda}^t \\vec{1 } = 1 \\}$ ] .",
    "the densities @xmath12 belong to a common family parameterized by @xmath13 , consisting of a mean parameter @xmath14 and where all other parameters are contained in @xmath15 .",
    "writing @xmath16 as the dominating measure for densities @xmath17 allows expectations over discrete and continuous random variables to be treated with a common integral notation .",
    "the overall expected value is @xmath18 .",
    "the @xmath19 may naturally be restricted to a subset of @xmath20 , depending on the outcome type .",
    "for example , if @xmath8 is a count , @xmath21 often represents a rate .",
    "alternatively , if @xmath8 is the number of successes among @xmath22 trials , which result in either success or failure , then @xmath23 $ ] can represent the probability of a success .",
    "in general , denote the natural space of @xmath19 as @xmath24 , so that @xmath25 is an element of @xmath26 .    in a regression",
    "setting , we observe a random sample @xmath27 from the finite mixture @xmath28 with an associated ( fixed ) predictor @xmath29 , for @xmath30 . as in the traditional glm",
    ", we wish to link @xmath31 to a regression function such as @xmath32 through an inverse link function @xmath33 . to simplify expressions in the rest of the paper , denote @xmath34 as the inverse - linked regression @xmath35",
    ". we will write @xmath36 for brevity when specifically referring to the @xmath37th observation , and @xmath38 in place of @xmath34 when not emphasizing a specific observation . with this notation ,",
    "our objective is to link @xmath39 the left - hand side of must vary with the observation for the link to be achievable . in this work , we will assume that subpopulation means @xmath40 are specific to the @xmath37th observation , but that mixing proportions @xmath41 are common across observations .",
    "in contrast to the traditional glm setting , @xmath42 is a composite parameter which does not appear directly in the density of @xmath43 .",
    "therefore , we can not simply plug @xmath44 into the likelihood .    to enforce , consider the set @xmath45 for a given @xmath46 and @xmath41 , restricting ourselves to @xmath47 is equivalent to enforcing the link .",
    "we will write @xmath48 as a shorthand for @xmath49 and @xmath50 for @xmath51 . our approach will be to take @xmath52 as a random effect drawn from set @xmath51 . in sections",
    "[ sec : mixlink - probs ] , [ sec : mixlink - positive ] , and [ sec : mixlink - real ] we will consider several commonly used choices of the space @xmath24the unit interval , the positive real line , and the real line respectively  to determine an appropriate distribution for @xmath52 .",
    "figure  [ fig : vertices ] displays an example of the set @xmath51 for each of these three cases .",
    "@xcite is a useful reference for basic concepts in the analysis of convex sets which emerge in the remainder of the paper .",
    "note that @xmath53 may be taken for all @xmath54 to yield a non - regression version of mixture link .",
    "selection of a distribution over @xmath49 determines the density of @xmath43 , @xmath55 here , @xmath56 represents the @xmath0-dimensional random effects density over @xmath51 and @xmath57 represents the marginal density of the @xmath58th coordinate . in the trivial case @xmath59",
    ", there is only a single point in @xmath51 , and @xmath60 simplifies to @xmath61 . in general , evaluating @xmath60 requires computation of @xmath0 univariate integrals , which can be achieved numerically using quadrature or other standard techniques .",
    "this can become a computational burden if @xmath60 must be computed many times ( e.g.  for a simulation or iterative estimation procedure ) or if @xmath62 is difficult to evaluate . by construction , @xmath63 , but variance and other moments",
    "depend on @xmath17 and the distribution of @xmath52 . as in more basic finite mixture models ,",
    "the value of density is invariant to permutations of the subpopulation labels @xmath64 .",
    ".32   in dimension @xmath65 : ( ) probability - valued means with @xmath66 and @xmath67 , ( ) positive means with @xmath68 and @xmath69 , ( ) real - valued means with @xmath66 and @xmath70.,title=\"fig:\",scaledwidth=95.0% ]    .32   in dimension @xmath65 : ( ) probability - valued means with @xmath66 and @xmath67 , ( ) positive means with @xmath68 and @xmath69 , ( ) real - valued means with @xmath66 and @xmath70.,title=\"fig:\",scaledwidth=95.0% ]    .32   in dimension @xmath65 : ( ) probability - valued means with @xmath66 and @xmath67 , ( ) positive means with @xmath68 and @xmath69 , ( ) real - valued means with @xmath66 and @xmath70.,title=\"fig:\",scaledwidth=95.0% ]",
    "consider the setting @xmath71 $ ] , which is useful for bernoulli or binomial data where means represent probabilities .",
    "it is straightforward to verify that @xmath72^j : \\vec{\\mu}^t \\vec{\\pi } = \\vartheta_i \\}$ ] is a bounded convex set in @xmath73 .",
    "therefore , we have the decomposition @xmath74 the @xmath75 matrix @xmath76 is composed of the columns @xmath77 which are vertices of @xmath51 .",
    "any element @xmath78 can be written as a convex combination of these vertices .",
    "the matrix @xmath76 depends on both @xmath41 and @xmath44 ; both its elements and the dimension @xmath79 may vary with the observation @xmath54 .",
    "the vector @xmath80 belongs to the probability simplex @xmath81 .",
    "the minkowski - weyl decomposition of a polyhedron is @xmath82 relative to extreme points @xmath83 ( i.e.  vertices ) and extreme directions @xmath84 of @xmath85 .",
    "the set @xmath50 in is a polytope , a bounded polyhedron not having extreme directions , for which we need only consider extreme points . assuming a distribution on the coefficients of the minkowski - weyl decomposition has been advocated by @xcite , who sought a class of priors to enforce biologically motivated polyhedral constraints in a bayesian analysis .",
    "a natural choice for a random effects distribution on @xmath86 is @xmath87 .",
    "however , this choice leads to each component of @xmath88 following the distribution of a linear combination of a @xmath89-dimensional dirichlet .",
    "this distribution is computationally impractical ; for example , its density has no known closed form for general @xmath89 @xcite . our approach will first be to state the model using a dirichlet random effect , then to state a more practical form of the model using beta random effects with matched first and second moments .",
    "this ensures , for example , that @xmath90 .",
    "the dirichlet formulation of the model is @xmath91 we restrict @xmath92 to the @xmath79-dimension vector @xmath93 so that all @xmath80 follow a symmetric dirichlet distribution parameterized by a single scalar @xmath94 ; this is done for several reasons .",
    "first , the dimension @xmath79 can vary with the observation so that an arbitrary @xmath95 would not be compatible with all observations .",
    "second , the ordering of the vertices in @xmath76 is somewhat arbitrary , and it is difficult to maintain a correspondence between individual vertices and the elements of @xmath95 .",
    "figure  [ fig : dirichletk3 ] plots the symmetric dirichlet density for several @xmath94 when @xmath96 .",
    "note that @xmath97 corresponds to the uniform distribution on the simplex , while @xmath98 results in more density focused toward the vertices , and @xmath99 focuses density toward the interior .    .40   density for several settings of @xmath94 .",
    "only @xmath100 and @xmath101 are plotted since @xmath102.,title=\"fig:\",scaledwidth=100.0% ]    .40   density for several settings of @xmath94 . only @xmath100 and @xmath101 are plotted since @xmath102.,title=\"fig:\",scaledwidth=100.0% ]    now , to obtain a mixture link density based on the more practical beta distribution , define @xmath103 and @xmath104 as the smallest and largest elements respectively of the @xmath58th row @xmath76 ; then @xmath105 forms the support of @xmath106 .",
    "the beta formulation of the model is @xmath107 to obtain @xmath108 and @xmath109 , we first compute @xmath110 next , for @xmath111 and @xmath112 denoting the @xmath58th row of @xmath76 , we can obtain @xmath113 where @xmath114 denotes the mean of @xmath112 .",
    "equating @xmath115 to @xmath116 and @xmath117 to @xmath118 and solving for @xmath108 and @xmath109 , we obtain that @xmath119 \\frac{u_{ij } - \\bar{v}_{j.}^{(i)}}{u_{ij } - \\ell_{ij } } - \\frac{\\bar{v}_{j.}^{(i ) } - \\ell_{ij}}{u_{ij } - \\ell_{ij } } , \\\\ b_{ij } & = a_{ij } \\left ( \\frac{u_{ij } - \\bar{v}_{j.}^{(i)}}{\\bar{v}_{j.}^{(i ) } - \\ell_{ij } } \\right ) .",
    "\\label{eqn : beta - moment - match}\\end{aligned}\\ ] ] in the special case that @xmath120 , we have @xmath121 = \\frac{1}{2 } \\left [ \\ell_{ij } + u_{ij } \\right ] , \\\\ % & \\bar{v}_{j.}^{(i ) } - \\ell_{ij } = u_{ij } - \\bar{v}_{j.}^{(i ) } , \\\\ % & \\vec{v}_{j.}^{(i)t } \\vec{v}_{j.}^{(i ) } = u_{ij}^2 + \\ell_{ij}^2,\\end{aligned}\\ ] ] from which it can be shown that @xmath122 and @xmath123 .    @xcite observes through simulation that , although the linear - combination - of - dirichlet density can differ substantially from the moment - matched beta density , the density of model   is a close approximation to the density of model  .",
    "we have paid specific attention to the marginal distributions of the coordinates of @xmath124 rather than the full joint distribution ; it is seen from that only the marginals influence the overall mixture link distribution . the density of model   is now given by @xmath125 where @xmath126 denotes the beta density and @xmath127 .",
    "computation of the mixture link density and its moments depends on the vertices of the set @xmath48 . for the case @xmath128",
    ", it is easy to identify the vertices of @xmath48 graphically by plotting the line @xmath129 , and visually identifying the points at which it intersects the unit rectangle .",
    "an illustration is given in figure  [ fig : hyperplane - j2 ] .",
    "formulas for the vertices in this case are stated now as a lemma .",
    "[ result : vertices - j2-probs ] suppose @xmath128 and @xmath48 has two distinct vertices @xmath130",
    ". then the vertices are given by @xmath131 where @xmath132 .",
    "using @xmath129 we have @xmath133 where @xmath134 $ ] and @xmath135 $ ] must hold .",
    "to obtain @xmath136 , take @xmath137 as large as possible noting expressions . if @xmath138 is a valid solution ( i.e. a point in @xmath48 ) , then @xmath139",
    "otherwise , take @xmath140 as small as possible to maximize @xmath137 ; this yields @xmath141 and @xmath142 . a similar argument taking @xmath137 as small as possible yields @xmath143 .",
    "we may also locate the vertices @xmath130 systematically in the following way .",
    "fix @xmath142 and solve for @xmath137 so that @xmath144 . then fix @xmath145 and solve for @xmath137 .",
    "then fix @xmath137 at the values 0 and 1 and solve for @xmath140 . at most two of these four solutions",
    "are contained in @xmath48 ; these are the vertices .",
    "we will soon see that this idea generalizes to @xmath146 .",
    "note that it is also possible to have @xmath147 vertices when @xmath128 .",
    "for example , if @xmath148 and @xmath149 , then @xmath150 is the only solution to @xmath129 in @xmath151 ^ 2 $ ] , and therefore @xmath48 is a singleton set .",
    "for the general ( @xmath152 ) case , lemma  [ result : extreme - points - probs ] characterizes points in @xmath48 which need to be considered when searching for the extreme points . in searching for extreme points",
    ", we must only consider those with at most one component not equal to 0 or 1 .",
    "[ result : extreme - points - probs ] suppose @xmath153 is a point in @xmath48 with two or more components strictly between 0 and 1 . then @xmath154 is not an extreme point of @xmath48",
    ".    suppose without loss of generality that @xmath155 with @xmath156 and @xmath157 .",
    "we have that @xmath158 where @xmath159 .",
    "we can now use lemma  [ result : vertices - j2-probs ] to obtain vertices , say @xmath160 and @xmath161 , of the line segment @xmath162^j : \\mu_1 \\pi_1 + \\mu_2 \\pi_2 = \\vartheta^ * \\right\\},\\end{aligned}\\ ] ] where @xmath163 are held fixed and only @xmath164 may vary . explicitly , we have @xmath165 by construction , we have that @xmath154 is in the line segment strictly between @xmath160 and @xmath161 , with @xmath166 .",
    "furthermore , since @xmath167 , we have that @xmath168 . therefore , @xmath154 can not be an extreme point of @xmath48 .",
    "this can be used to formulate a simple procedure to identify all extreme points of @xmath48 , which is given as algorithm  [ alg : find - vertices - probs ] .",
    "notice that it considers @xmath169 points ; this would be impractical for large @xmath0 , but is manageable for smaller values of @xmath0 that are commonly used in finite mixtures .",
    "@xmath170 @xmath171 $ ] @xmath172 @xmath173 if @xmath174 matrix @xmath175 with columns @xmath176    we will now formulate a mixture link binomial distribution .",
    "suppose @xmath177 so that @xmath178 represents a count of successes out of @xmath179 independent trials .",
    "model becomes @xmath180 to draw from this distribution ,    compute matrix @xmath175 given @xmath1 , @xmath46 , and @xmath41 .",
    "compute @xmath181 and @xmath182 for @xmath183 according to , and let @xmath184 be the minimum and maximum element , respectively , of the @xmath58th row of @xmath175 .",
    "let @xmath185 with @xmath186 , for @xmath183 .",
    "draw @xmath187 .",
    "draw @xmath188 .    here",
    ", @xmath189 denotes the discrete distribution with values @xmath190 and corresponding probabilities @xmath191 .",
    "moments of @xmath8 can be computed using moments of @xmath19 for @xmath183 . in particular , after some algebra , we obtain @xmath192 some remarks about the mixture link binomial distribution follow . and [ sec : mixlink - real ] .",
    "we have focused on the binomial case for brevity . ]    for the case @xmath193 where @xmath2 represents a single success or failure , @xmath194 implies @xmath195 , and mixture link simplifies to the usual bernoulli regression model . in this case , the distribution depends only on its @xmath46 parameter .",
    "when @xmath196 , this trivial simplification does not take place .",
    "note that because @xmath197 and @xmath198 , we have @xmath199 , yielding the bound @xmath200 , which is free of @xmath41 and @xmath94 .    the expression @xmath201 is non - increasing in @xmath94 .",
    "this can be seen from @xmath202    [ remark : binomial - case ]",
    "@xmath203 is a special case of mixture link binomial , when @xmath204 and @xmath205 .",
    "this can be seen directly from the dirichlet formulation of mixture link .",
    "let @xmath204 so that @xmath206^j : \\mu_1 + \\cdots + \\mu_j = j \\vartheta \\}$ ] .",
    "a vertex @xmath207 of @xmath208 is obtained by taking , say , the first @xmath209}^*$ ] to be 1 , @xmath210 + 1}^ * = j \\vartheta - [ j \\vartheta]$ ] , and the remaining elements of @xmath207 to be zero . here ,",
    "@xmath211 $ ] represents the integer part of a real number @xmath212 . by lemma  [ result : extreme - points - probs ]",
    ", @xmath207 is a vertex of @xmath208 .",
    "the remaining vertices can be obtained by permuting the elements of @xmath207 .",
    "if @xmath213 are the unique elements of @xmath207 with multiplicities @xmath214 , then there are @xmath215 unique permutations of @xmath207 to use as columns in the matrix @xmath175 .",
    "notice that , for any @xmath216 , the element @xmath217 appears in the @xmath58th row @xmath218 of @xmath175 exactly @xmath219 times . , keeping one of the elements fixed . ]",
    "then we have @xmath220 when @xmath205 , a draw @xmath221 becomes a point mass at its expected value @xmath222 so that gives @xmath223 .",
    "it can now be seen that @xmath224 is the @xmath203 distribution .",
    "[ remark : zi - case ] mixture link binomial becomes a zero- and/or @xmath22-inflated binomial model when @xmath225 . as in remark  [ remark : binomial - case ] , we will work directly from the dirichlet formulation .",
    "as @xmath225 , a draw @xmath221 behaves as a discrete uniform random variable on @xmath226 , the columns of the @xmath227 identity matrix which represent the vertices of the simplex @xmath81 . here , the mixture link distribution becomes @xmath228 recall from lemma  [ result : extreme - points - probs ] that , for each @xmath229 , at most one of @xmath230 can take on a value outside of @xmath231 .",
    "terms with @xmath232 represent a point mass at zero , while terms with @xmath233 represent a point mass at @xmath22 .",
    "mixture link binomial is closely related to two other binomial models for overdispersion .",
    "starting from , if we could take @xmath234 and @xmath235 , we would have @xmath236 therefore , mixture link binomial can be seen as a constrained form of a finite mixture of @xmath0 beta - binomial densities . also , recall the random - clumped binomial ( rcb ) distribution @xcite , whose density is given by @xmath237 where @xmath238 , @xmath239 , and @xmath240 , @xmath241 .",
    "the free parameters of the distribution are @xmath242 and @xmath243 .",
    "notice that @xmath244 , so that this particular choice of @xmath164 is in the set @xmath245 .",
    "therefore , rcb can be seen as a special case of mixture link binomial .",
    "the setting @xmath246 is commonly required for count data and time - to - event data . just as in section",
    "[ sec : mixlink - probs ] , the set @xmath247 is a closed convex hyperplane segment within @xmath73 .",
    "therefore , the decomposition also applies but the procedure to compute vertices is much simpler . first note that for @xmath128 , @xmath248 and @xmath249 are the vertices of @xmath48 . to see this ,",
    "suppose @xmath250 is an arbitrary point in @xmath48 .",
    "then we must have , for some @xmath251 $ ] , @xmath252 taking @xmath253 satisfies the first equation @xmath254 , and also gives @xmath255 to satisfy the second equation .",
    "similarly to lemma  [ result : extreme - points - probs ] , we characterize the extreme points of @xmath48 for the case of positive means by lemma  [ result : extreme - points - positive ] .",
    "the proof is similar to that of lemma  [ result : extreme - points - probs ] , and therefore omitted .",
    "[ result : extreme - points - positive ] suppose @xmath153 is a point in @xmath48 with two or more components which are strictly positive",
    ". then @xmath154 is not an extreme point of @xmath48 .",
    "now , if @xmath256 is a point in @xmath48 , @xmath257 implies @xmath258 .",
    "there are exactly @xmath0 such points in @xmath48 , yielding @xmath259 .",
    "poisson mixture link can now be formulated similarly as in section  [ sec : mixlink - probs ] . note that , in this case , the dirichlet and beta assumptions on @xmath260 lead to exactly the same model .",
    "taking @xmath261 , the model becomes @xmath262 expressions involving the vertices simplify in the case of positive means , with @xmath263 , @xmath234 , @xmath264 , @xmath265 , @xmath266 , @xmath267 , @xmath122 , and @xmath268 .",
    "recalling that the marginal distribution of a single coordinate of @xmath269 is @xmath270 , the mixture link density becomes @xmath271^{y_i}}{y_i ! } \\cdot \\frac{w^{\\kappa-1 } ( 1-w)^{\\kappa ( j-1 ) - 1}}{b(\\kappa , \\kappa ( j-1 ) ) } dw \\\\ % & = \\frac{\\vartheta_i^{y_i } \\gamma(y_i + \\kappa ) \\gamma(\\kappa j ) } { \\gamma(y_i + \\kappa j ) \\gamma(\\kappa ) \\gamma(y_i+1 ) } \\sum_{j=1}^j \\pi_j^{1 - y_i } \\cdot \\mathcal{f}\\left ( -\\frac{\\vartheta_i}{\\pi_j } ; y_i + \\kappa , y_i + j\\kappa \\right ) % \\label{eqn : mixture - link - density - poisson}\\end{aligned}\\ ] ] where @xmath272^{-1 } \\int_0 ^ 1 w^{a-1 } ( 1-w)^{b - a-1 } e^{xw } dw$ ] is the confluent hypergeometric function of the first order and @xmath273 is the beta function ( * ? ? ?",
    "* chapter 1 ) .",
    "implementations of @xmath274 are available in computing packages such as the gnu scientific library .",
    "the variance of @xmath8 becomes @xmath275 +   \\sum_{j=1}^j \\pi_j \\frac{\\vec{v}_{j.}^t \\vec{v}_{j .",
    "} - k(\\bar{v}_{j.})^2}{k ( 1 + \\kappa k ) } \\\\ % & = \\vartheta + \\vartheta^2 \\left [ \\frac { \\kappa+1}{j ( 1 + j \\kappa ) } \\sum_{j=1}^j \\frac{1}{\\pi_j } - 1 \\right].\\end{aligned}\\ ] ] drawing random variables from mixture link poisson is similar to the method given in section  [ sec : mixlink - probs ] for mixture link binomial :    compute matrix of vertices @xmath175 given @xmath1 , @xmath46 , and @xmath41 .",
    "let @xmath276 with @xmath277 , for @xmath183 .",
    "draw @xmath187 .",
    "draw @xmath188 .",
    "the expression @xmath201 is decreasing in @xmath94 since @xmath278",
    "in the case @xmath279 , the set @xmath280 forms a hyperplane in @xmath73 and can be decomposed as @xmath281 . for any @xmath282 in the subspace @xmath283 , we can write @xmath284 with @xmath285 unrestricted for @xmath286 .",
    "therefore a basis for the subspace is given by the @xmath287 matrix @xmath288 we can therefore represent any @xmath289 as @xmath290 a natural choice for a random effects distribution on @xmath49 is to take @xmath291 for @xmath286 .",
    "this leads to @xmath292 @xmath293 denotes the @xmath294 identity matrix , and @xmath295 .",
    "the mixture link density depends only on the diagonal terms of the random effect variance , @xmath296 where @xmath297 for @xmath286 and @xmath298 .    to obtain a mixture link analogue to the commonly used ordinary least squares model ,",
    "suppose @xmath299 .",
    "in this case , it can be shown that simplifies to the finite mixture @xmath300 where each of the subpopulations has a common mean .",
    "if the @xmath0 subpopulations are assumed to be homoskedastic , further simplifies to a finite mixture of two densities , @xmath301 focusing on the homoskedastic model , it is straightforward to draw from the distribution :    draw @xmath302 ,    draw @xmath43 from @xmath303 where @xmath304 .    an expression for the variance",
    "is given by @xmath305",
    "we now present two examples of data analysis with the mixture link distribution .",
    "the hiroshima data discussed in section  [ sec : data - hiroshima ] features a binomial outcome .",
    "the arizona medpar data has a count outcome , and is discussed in section  [ sec : data - azpro ] .    for a complete bayesian specification of mixture link binomial and mixture link poisson , we assume priors @xmath306 where the parameterization of gamma is taken to have @xmath307 . in the absence of a - priori knowledge , a somewhat vague choice of hyperparameters is @xmath308 , @xmath309 , and @xmath310 .    to diagnose the fit of models with non - normal outcomes , we make use of the randomized quantile residuals @xcite .",
    "interpretation of quantile residuals is similar to the routine residual analysis from ordinary least squares regression .",
    "quantile residuals from an adequate model fit appear to behave as an independent sample from the standard normal distribution . for @xmath178",
    "drawn independently from a continuous distribution @xmath311 with estimate @xmath312 , the quantile residual is defined as @xmath313 . for @xmath178",
    "drawn independently from a discrete distribution , there is an additional randomization where the residual is defined by @xmath314 , using @xmath315 drawn uniformly on the interval between @xmath316 and @xmath317 .",
    "a bayesian version of the quantile residual using draws @xmath318 from the posterior distribution @xmath319 is @xmath320 , where each @xmath321 is drawn uniformly on the interval between @xmath322 and @xmath323 .",
    "we will also evaluate models using prediction intervals computed from the posterior predictive distribution . recall that the posterior predictive distribution for a new sample @xmath324 given the observed sample @xmath325 is @xmath326 where @xmath16 denotes an appropriate dominating measure . then to sample from @xmath327 :    draw @xmath318 from posterior @xmath319 .",
    "draw @xmath328 from @xmath329 for @xmath330 .",
    "now @xmath331 is a draw from the posterior predictive distribution .",
    "a prediction for the @xmath37th observation is given by @xmath332 , and a prediction interval with coverage probability @xmath333 for the @xmath37th observation is given by the @xmath334 and @xmath335 quantiles of @xmath336 .",
    "label switching is a common issue in bayesian analysis of finite mixtures @xcite . for mixture link ,",
    "the @xmath41 parameters are susceptible to this problem .",
    "because finite mixtures are invariant to permutation of the labels , the parameters corresponding to labels @xmath64 can change during the course of an mcmc computation .",
    "therefore , special care must be taken when summarizing parameters using mcmc draws . in this work ,",
    "we take the simple approach of reordering the components within each draw @xmath337 , in ascending order , for each @xmath330 .",
    "@xcite and @xcite study the effects of radiation exposure on chromosome aberrations in survivors of the atomic bombs that were used in hiroshima and nagasaki .",
    "we consider a subset of the data , as presented in @xcite , on @xmath338 subjects in hiroshima .",
    "for the @xmath37th subject , a chromosome analysis has been carried out on @xmath179 circulating lymphocytes to determine the number @xmath178 containing chromosome aberrations .",
    "neutron and gamma radiation exposure ( measured in rads ) are available as potential covariates . as in @xcite",
    ", we consider the regression @xmath339 where @xmath340 is a normalized sum of neutron and gamma doses , and we take @xmath33 to be the logistic cdf ( as in logistic regression ) .    we compare six binomial - type models with as the regression function : binomial , random - clumped binomial ( rcb ) , beta - binomial ( bb ) , and mixture link with @xmath341 mixture components ( mixlinkj2 , mixlinkj3 , mixlinkj4 ) . because of the complicated manner in which parameters enter the mixture link binomial likelihood , conjugate priors leading to closed - form gibbs samplers do not appear possible .",
    "we considered a simple random walk metropolis - hastings ( rwmh ) sampler ( * ? ? ? * section 7.5 ) ; however , sampling with rwmh is time consuming because it requires computation of the likelihood to determine whether each proposed jump will be accepted .",
    "recall that , for mixture link binomial , evaluation of the likelihood consists of evaluating @xmath0 integrals numerically for each of the @xmath342 observations . alternatively , appendix  [ sec : appendix - mcmc - binomial ] proposes a metropolis - within - gibbs ( mwg ) sampler ( * ? ? ?",
    "* section 10.3 ) where @xmath343 are taken as augmented data @xcite to avoid the expensive integration .",
    "an rwmh sampler was used to obtain posterior draws under the binomial , rcb , and bb models , while the mwg sampler from appendix  [ sec : appendix - mcmc - binomial ] was used for mixture link . for each mixture link model",
    ", we carried out a preliminary `` pilot '' mcmc , which was used to tune the proposal distribution for a final mcmc run and achieve satisfactory mixing .",
    "mixing was assessed primarily through trace plots and autocorrelation plots of the saved draws .",
    "trace plots for the selected mixture link model are shown in figure  [ fig : hiroshima - trace ] .",
    "for all models , a multivariate normal proposal distribution was selected by hand to achieve acceptance rates between about 15% and 30% .",
    "final mcmc runs for mixture link were carried out for 55,000 iterations ; the first 5,000 were discarded as a burn - in sample , and 1 of every 50 remaining draws from the chain were saved . for binomial , bb , and rcb",
    ", we used 50,000 iterations overall with the first 5,000 discarded as burn - in and saved 1 of every 50 remaining .",
    "table  [ tab : hiroshima - model - selection ] shows the deviance information criterion ( dic ) for these models .",
    "the three mixture link models fit best according to dic ; bb has a smaller dic than rcb by a large margin , and binomial gives the worst fit as expected .",
    "table  [ tab : hiroshima - est ] reports means , standard deviations , 2.5% quantiles , and 97.5% quantiles for each parameter from the posterior draws .",
    "generally , signs and magnitudes of the @xmath46 estimates agree between models .",
    "standard deviations and credible intervals are a bit larger for bb and mixlink models than rcb and binomial .",
    "figure  [ fig : hiroshoma - rqres ] displays quantile residuals for the binomial , bb , and mixlinkj2 models . residuals from bb and mixlinkj2 are markedly closer to a @xmath344 sample than binomial residuals , as can be seen from the q - q plots .",
    "for all models , there is a systematic pattern in residuals vs.  predicted proportions , which is an indication that the mean is not fully explained by regression function  .",
    "finally , figure  [ fig : hiroshima - predict ] plots @xmath340 against observed @xmath345 , along with 95% prediction intervals for binomial , bb , and mixlinkj2 .",
    "the intervals computed by mixlinkj2 , and to a lesser extent bb , express variability from the observed data into wider prediction intervals .",
    ".dic for hiroshima models .",
    "[ cols= \" < , > \" , ]     0.32     0.32     0.32     0.32     0.32     0.32     0.49   for each of the 16 possible covariate values in the arizona medpar data .",
    "covariate values are displayed as a string representing ( procedure , sex , admit , age75 ) .",
    "for example , `` 1010 '' represents @xmath346 and @xmath347 .",
    "red dash - dot lines represent 95% prediction limits from poisson and blue dashed lines are from mixlink.,title=\"fig:\",scaledwidth=100.0% ] [ fig : azpro - pi - boxplot1 ]    0.49   for each of the 16 possible covariate values in the arizona medpar data .",
    "covariate values are displayed as a string representing ( procedure , sex , admit , age75 ) . for example , `` 1010 '' represents @xmath346 and @xmath347 .",
    "red dash - dot lines represent 95% prediction limits from poisson and blue dashed lines are from mixlink.,title=\"fig:\",scaledwidth=100.0% ] [ fig : azpro - pi - boxplot2 ]    0.32   [ fig : azpro - trace - beta0 ]    0.32   [ fig : azpro - trace - beta1 ]    0.32   [ fig : azpro - trace - beta2 ]    0.32   [ fig : azpro - trace - beta3 ]    0.32   [ fig : azpro - trace - beta4 ]    0.32   [ fig : azpro - trace - pi1 ]    0.32   [ fig : azpro - trace - pi2 ]    0.32   [ fig : azpro - trace - pi3 ]    0.32   [ fig : azpro - trace - pi4 ]    0.32   [ fig : azpro - trace - pi5 ]    0.32   [ fig : azpro - trace - pi6 ]    0.32   [ fig : azpro - trace - pi7 ]    0.32   [ fig : azpro - trace - pi8 ]    0.32   [ fig : azpro - trace - kappa ]",
    "regression on the mean is commonly carried out with exponential family distributions in the generalized linear model framework , but extending this idea to finite mixture distributions is not completely straightforward .",
    "this paper formulated the mixture link distribution , which establishes a link from a finite mixture mean to the regression function by assuming a random effects structure on the constrained parameter space .",
    "specific variants of mixture link were obtained for binomial , poisson , and normal outcomes .",
    "integrals in the general binomial case appeared not to have a tractable form , but the normal case could be integrated to yield another ( constrained ) normal finite mixture , and integrals in the poisson case were evaluated using the confluent hypergeometric function .",
    "some interesting connections were noted , for example , between mixture link binomial and the random - clumped binomial and beta - binomial distributions .",
    "example regression analyses using mixture link binomial and poisson models demonstrated utility in handling overdispersion .",
    "simpler models could adequately estimate the regression , yet failed to capture variability seen in the data .",
    "this became especially apparent in portions of analysis that depend heavily on the model , such as diagnosing model fit with quantile residuals or computing prediction intervals from the posterior predictive distribution .",
    "the fact that mixture link is completely likelihood - based ensures that such procedures are available ; this could be seen as an advantage over quasi - likelihood methods when a flexible mean - variance relationship is needed .",
    "code for the mixture link model is available in the package , available at http://cran.r-project.org .",
    "the mixture link approach leads to a novel class of distributions with an interesting set of challenges for practical use in data analysis .",
    "initial results in @xcite , @xcite , and the present paper appear promising , especially using bayesian inference , but more work is needed to determine the suitability of mixture link for wider application . in particular , it may be worthwhile to investigate analytical properties of mixture link models , such as differentiability , especially in the binomial case .",
    "such properties may be needed to establish appropriate methods for maximum likelihood estimation , large sample properties of maximum likelihood estimates , and approximation of the posterior distribution by a normal distribution .",
    "we thank professors thomas mathew , yi huang , and yaakov malinovsky at the university of maryland , baltimore county ( umbc ) for serving on the committee of the dissertation in which this work was initiated .",
    "we thank the umbc high performance computing facility for use of its computational resources , and for financial support of the first author through a multiple year graduate assistantship .",
    "an mcmc algorithm based on model can be formulated with @xmath348 as augmented data .",
    "this approach avoids expensive numerical integration needed to compute the likelihood .",
    "the joint distribution of all random quantities is @xmath349 and @xmath127 .",
    "gibbs steps to sample @xmath46 , @xmath41 , @xmath94 , and @xmath350 will not yield closed forms .",
    "instead , we will use simple random walk metropolis hastings ( * ? ? ?",
    "* section 7.5 ) to propose draws for each random quantity .    to obtain draws of the constrained parameters @xmath41 , @xmath94 , and @xmath351",
    ", we draw unconstrained random variables from the sampler and transform them to the constrained space . generally , denote @xmath352 as one of the constrained parameters whose full conditional density is @xmath353 , and let @xmath354 be a bijection from the space of @xmath352 to a euclidean space @xmath355 .",
    "the density of @xmath356 is then @xmath357 , where @xmath358 . starting from a given @xmath356",
    ", a proposed @xmath359 will be accepted with probability @xmath360    note that the function @xmath361 needs to be evaluated in each step . by computing @xmath362 in ,",
    "it is possible to improve the performance greatly over a pure @xcite implementation of our sampler .",
    "the package by @xcite , for example , greatly facilitates a hybrid implementation of and .",
    "consider the unnormalized density @xmath363 suppose @xmath364 is the current iterate of @xmath46 in the simulation and draw @xmath365 from the proposal distribution @xmath366 .",
    "draw @xmath367 , and let @xmath368      consider the unnormalized density @xmath369 suppose @xmath337 is the current iterate of @xmath41 in the simulation .",
    "denote @xmath370 as the probability simplex in dimension @xmath0 with typical element @xmath371 .",
    "note that the multinomial logit function @xmath372 is a bijection from @xmath370 to @xmath373 .",
    "therefore , we can draw @xmath359 from the proposal distribution @xmath374 on @xmath373 and let @xmath375 be the candidate for the next iterate .",
    "denote @xmath376 as the @xmath287 jacobian of the transformation from @xmath377 to @xmath41 , and let @xmath378 be the determinant ignoring the @xmath0th row .",
    "draw @xmath367 , and let @xmath379      consider the unnormalized density @xmath380 suppose @xmath381 is the current iterate of @xmath94 in the simulation .",
    "draw @xmath382 from the proposal distribution @xmath383 and let @xmath384 be the candidate for the next iterate .",
    "the jacobian of the transformation from @xmath5 to @xmath94 is @xmath385 .",
    "draw @xmath367 , and let @xmath386      consider the unnormalized density @xmath388 we can see that @xmath389 are independent conditional on the remaining random variables and we may therefore consider drawing one at a time .",
    "suppose @xmath390 is the current iterate of @xmath389 in the simulation .",
    "let @xmath33 be the cdf of the logistic distribution , which is a bijection from @xmath20 to the unit interval .",
    "denote @xmath391 .",
    "the jacobian of the transformation from @xmath377 to @xmath389 is @xmath392 where @xmath393 represents the logistic density .",
    "draw @xmath359 from the proposal distribution @xmath394 and let @xmath395 be the candidate for the next iterate .",
    "draw @xmath367 , and let @xmath396"
  ],
  "abstract_text": [
    "<S> finite mixture distributions arise in sampling a heterogeneous population . </S>",
    "<S> data drawn from such a population will exhibit extra variability relative to any single subpopulation . </S>",
    "<S> statistical models based on finite mixtures can assist in the analysis of categorical and count outcomes when standard generalized linear models ( glms ) can not adequately account for variability observed in the data . </S>",
    "<S> we propose an extension of glm where the response is assumed to follow a finite mixture distribution , while the regression of interest is linked to the mixture s mean . </S>",
    "<S> this approach may be preferred over a finite mixture of regressions when the population mean is the quantity of interest ; here , only a single regression function must be specified and interpreted in the analysis . </S>",
    "<S> a technical challenge is that the mean of a finite mixture is a composite parameter which does not appear explicitly in the density . </S>",
    "<S> the proposed model is completely likelihood - based and maintains the link to the regression through a certain random effects structure . </S>",
    "<S> we consider typical glm cases where means are either real - valued , constrained to be positive , or constrained to be on the unit interval . </S>",
    "<S> the resulting model is applied to two example datasets through a bayesian analysis : one with success / failure outcomes and one with count outcomes . supporting the extra variation </S>",
    "<S> is seen to improve residual plots and to appropriately widen prediction intervals . </S>"
  ]
}