{
  "article_text": [
    "the on - line social network twitter is a well known example of a complex real - world network with over @xmath0 million users .",
    "the topology of twitter network is highly directed , with each user following another ( with no requirement of reciprocity ) . by focusing on a popular user as a source ( such as lady gaga or justin bieber ,",
    "each of whom have over 11 million followers  @xcite ) , we may view the followers of the user as a certain large - scale _ hierarchical social network_. in such networks , users are organized on ranked levels below the source , with links ( and as such , information ) flowing from the source downwards to sinks",
    ". we may view hierarchical social networks as _ directed acyclic graphs _ , or _",
    "dags _ for short .",
    "hierarchical social networks appear in a wide range of contexts in real - world networks , ranging from terrorist cells to the social organization in companies ; see , for example  @xcite .    in hierarchical social networks ,",
    "information flows downwards from the source to sinks .",
    "disrupting the flow of information may correspond to halting the spread of news or gossip in on - line social network , or intercepting a message sent in a terrorist network .",
    "how do we disrupt this flow of information while minimizing the resources used ?",
    "we consider a simple model in the form of a vertex - pursuit game called seepage introduced in @xcite .",
    "seepage is motivated by the 1973 eruption of the eldfell volcano in iceland . in order to protect the harbour , the inhabitants poured water on the lava in order to solidify it and thus , halt its progress .",
    "the game has two players , the _ sludge _ and a set of _ greens _ (",
    "note that one player controls all the greens ) , a dag with one source ( corresponding to the top of the volcano ) and many sinks ( representing the lake ) .",
    "the players take turns , with the sludge going first by contaminating the top node ( source ) .",
    "then it is the greens turn , and they choose some non - protected , non - contaminated nodes to protect . on subsequent rounds",
    "the sludge moves a non - protected node that is adjacent ( that is , downhill ) to the node the sludge is currently occupying and contaminates it ; note that the sludge is located at a single node in each turn .",
    "the greens , on their turn , proceed as before ; that is , choose some non - protected , non - contaminated nodes to protect .",
    "once protected or contaminated , a node stays in that state to the end of the game .",
    "the sludge wins if some sink is contaminated ; otherwise the greens win , that is , if they erect a cutset of nodes which separates the contaminated nodes from the sinks .",
    "the name `` seepage '' is used because the rate of contamination is slow .",
    "the game is related to vertex - pursuit games such as cops and robbers ( for an introduction and further reading on such games , see  @xcite ) , although the greens in our case need not move to neighbouring nodes . for an example , see the dag in figure  [ seepageex1 ] .",
    "( we omit orientations of directed edges in the figure , and assume all edges point from higher nodes to lower ones . )",
    "[ h ]    to obtain the results in this paper , a number of different winning strategies are employed by the two players . in some cases",
    "one of the two players can play arbitrarily ( at least up to some point ) , whereas in other cases the optimal strategy is simply a `` greedy '' one ( for example , when the greens protect neighbours as close as possible to the current position of the sludge ) . in some other cases , much more sophisticated strategies have to be applied .    to date the only analysis of seepage was in @xcite , which presented results for dags .",
    "seepage may be extended to certain directed graphs with cycles , although we do not consider this variation here ( see also section  [ directions ] ) . in @xcite ,",
    "a characterization was given of directed trees where one green has a winning strategy , and bounds were given on the number of greens needed to win in truncated products of paths .",
    "see also chapter  9 of @xcite .",
    "seepage displays some interesting similarities to an approach used in mathematical counterterrorism , where cut sets in partially ordered sets ( which are just a special kind of dag ) are used to model the disruption of terrorist cells . as described in farley  @xcite ,",
    "the maximal elements of the poset are viewed as the leaders of the terrorist organization , who submit plans down via the edges to the nodes at the bottom ( the foot soldiers or minimal nodes ) .",
    "only one messenger needs to receive the message for the plan to be executed .",
    "farley considered finding minimum - order sets of elements in the poset , which when deleted , disconnect the minimal elements from the maximal one ( that is , find a _ minimum cut _ )",
    ". we were struck by the similarities in the underlying approaches in  @xcite and  @xcite ; for example , in seepage the greens are trying to prevent the sludge from moving to the sinks by blocking nodes .",
    "the main difference is that seepage is `` dynamic '' ( that is , the greens can move , or choose new sets of nodes each time - step ) , while the min - cut - set approach is `` static '' ( that is , find a cutset in one time - step ) .",
    "seepage is perhaps a more realistic model of counterterrorism , as the agents do not necessarily act all at once but over time .",
    "however , in both approaches deterministic graphs are used .",
    "we note that a stochastic model was presented for so - called _ network interdiction _ in  @xcite , where the task of the interdictor is to find a set of edges in a weighted network such that the removal of those edges would maximally increase the cost to an evader of traveling on a path through the network . a stochastic model for complex dags",
    "was given in  @xcite .",
    "for more on models of on - line social networks and other complex networks , see  @xcite .",
    "our goal in the present article is to analyze seepage and the green number when played on a random dag as a model of disrupting a given hierarchical social network .",
    "we focus on mathematical results , and give a precise formulation of our random dag model in section  [ sec : definitions ] .",
    "our model includes as a parameter the total degree distribution of nodes in the dag .",
    "this has some similarities to the @xmath1 model of random graphs with expected degree sequences ( see  @xcite ) or the pairing model ( see  @xcite ) .",
    "we study two cases : regular dags ( where we would expect each level of the dag to have nodes with about the same out - degree ) , and power law dags ( where the degree distribution is heavy tailed , with many more low degree nodes but a few which have a high degree ) .",
    "rigorous results are presented for regular dags in theorem  [ thm : main_d - reg ] , and for power law dags in theorem  [ thm : main_power - law ] .",
    "an overview of the main results is given in section  [ mainr ] .",
    "throughout , @xmath2 will represent a finite dag .",
    "for background on graph theory , the reader is directed to  @xcite .",
    "the total degree of a vertex is the sum of its in- and out - degrees .",
    "additional background on seepage and other vertex - pursuit games may be found in  @xcite .",
    "we denote the natural numbers ( including @xmath3 ) by @xmath4 , and the positive integers and real numbers by @xmath5 and @xmath6 , respectively . for an event @xmath7 on a probability space , we let @xmath8 denote the probability of @xmath7 . given a random variable @xmath9 , we let @xmath10 and @xmath11 be the expectation and the variance of @xmath9 , respectively .",
    "we now give a formal definition of our vertex - pursuit game .",
    "fix @xmath12 a node of @xmath2 .",
    "we will call @xmath13 the _ source_. for @xmath14 let @xmath15 where @xmath16 is the distance between @xmath17 and @xmath13 in @xmath18 in particular , @xmath19 . for a given @xmath20 and @xmath21 , let @xmath22 be the game played on graph @xmath2 with the source @xmath13 and",
    "the _ sinks _",
    "the game proceeds over a sequence of discrete time - steps .",
    "exactly @xmath24 new nodes are protected at time - step @xmath25 .",
    "( in particular , at most @xmath26 nodes are protected by the time @xmath25 . )",
    "note that if @xmath27 is an integer , then exactly @xmath27 nodes are protected at each time - step , so this is a natural generalization of seepage . to avoid trivialities , we assume that @xmath28 .",
    "the _ sludge _ starts the game on the node @xmath29 .",
    "the second player , the _ greens _ , can protect @xmath30 nodes of @xmath31 .",
    "once nodes are protected they will stay protected to the end of the game . at time @xmath32 , the sludge makes the first move by sliding along a directed edge from @xmath33 to @xmath34 , which is an out - neighbour of @xmath33 .",
    "after that the greens have a chance to protect another @xmath35 nodes . since the graph is finite and acyclic , the sludge will be forced to stop moving , and so the game will eventually terminate .",
    "if he reaches any node of @xmath23 , then the sludge wins ; otherwise , the greens win .",
    "if @xmath36 ( the maximum out - degree of @xmath2 ) , then the game @xmath22 can be easily won by the greens by protecting of all neighbours of the source .",
    "therefore , the following graph parameter , _ the green number _ , is well defined : @xmath37 it is clear that for any @xmath38 we have @xmath39 .",
    "there are two parameters of the model : @xmath40 and an infinite sequence @xmath41 of non - negative integers .",
    "note that the @xmath42 s may be functions of @xmath43 . the first layer ( that is , the source ) consists of one node : @xmath44 .",
    "the next layers are recursively defined . for",
    "the inductive hypothesis , suppose that all layers up to and including the layer @xmath45 are created , and let us label all nodes of those layers . in particular , @xmath46 where @xmath47 we would like the nodes of @xmath48 to have a total degree with the following distribution @xmath49 .",
    "however , it can happen that some node @xmath50 has an in - degree @xmath51 already larger than @xmath42 , and so there is no hope for the total degree of @xmath42 .",
    "if this is not the case , then the requirement can be easily fulfilled . as a result , @xmath52 , the desired degree distribution",
    ", will serve as a ( deterministic ) lower bound for the actual degree distribution we obtain during the ( random ) process .",
    "let @xmath53 be a new set of nodes of cardinality @xmath43 .",
    "all directed edges that are created at this time - step will be from the layer @xmath48 to a random subset of @xmath53 that will form a new layer @xmath54 .",
    "each node @xmath50 generates @xmath55 random directed edges from @xmath56 to @xmath53 .",
    "therefore , we generate @xmath57 random edges at this time - step .",
    "the destination of each edge is chosen uniformly at random from @xmath53 .",
    "all edges are generated independently , and so we perform @xmath58 independent experiments .",
    "the set of nodes of @xmath53 that were chosen at least once forms a new layer @xmath54 . note that it can happen that two parallel edges are created during this process",
    "however , this is a rare situation for sparse random graphs we are going to investigate in this paper .",
    "hence , our results on the green number will also hold for a slightly modified process which excludes parallel edges .",
    "in this paper , we focus on two specific sequences : regular and power law .",
    "we will describe them both and state the main results in the next two subsections .",
    "we consider asymptotic properties of the model as @xmath59 .",
    "we say that an event in a probability space holds _ asymptotically almost surely _",
    "( _ a.a.s .",
    "_ ) if its probability tends to one as @xmath43 goes to infinity .",
    "we consider a constant sequence ; that is , for @xmath60 we set @xmath61 , where @xmath62 is a constant . in this case",
    ", we refer to the stochastic model as _",
    "random @xmath63-regular dags_. since @xmath64 , observe that @xmath65 ( deterministically ) for any @xmath66 , since at most @xmath67 random edges are generated when @xmath23 is created .",
    "we will write @xmath68 for @xmath69 since the graph @xmath2 is understood to be a @xmath63-regular random graph , and @xmath70 .",
    "[ thm : main_d - reg ] let @xmath71 be any function that grows ( arbitrarily slowly ) as @xmath43 tends to infinity . for the random @xmath63-regular dags , we have the following .",
    "* a.a.s .  @xmath72 . *",
    "if @xmath73 , then a.a.s.@xmath74 * if @xmath75 , then a.a.s.@xmath76 * if @xmath77 for some @xmath78 , then a.a.s.@xmath79 * let @xmath78 , @xmath80 .",
    "there exists a constant @xmath81 such that if @xmath82 , then a.a.s.@xmath83    the whole section  [ sec : d - reg ] is devoted to prove this theorem",
    ". theorem  [ thm : main_d - reg ] tells us that the green number is slightly bigger than @xmath84 if the sinks are located near the source , and then it is @xmath84 for a large interval of @xmath66 .",
    "later , it might decrease slightly since an increasing number of vertices have already in - degree @xmath85 or more , but only for large @xmath66 ( part ( v ) ) we can prove better upper bounds than @xmath86 one interpretation of this fact is that the resources needed to disrupt the flow of information is in a typical regular dag is ( almost ) independent of @xmath66 , and relatively low ( as a function of @xmath66 ) .",
    "we have three parameters in this model : @xmath87 , @xmath88 , and @xmath89 . for a given set of parameters , let @xmath90 and @xmath91 finally , for @xmath92 let @xmath93 in this case",
    ", we refer to the model as _ random power law dags_.    we note that the sequence @xmath52 is decreasing ( in particular , the source has the largest expected degree ) .",
    "moreover , the number of coordinates that are at least @xmath45 is equal to @xmath94 and hence the sequence follows a power - law with exponent @xmath95 . from the same observation",
    "it follows that the maximum value is @xmath96 finally , the average of the first @xmath43 values is @xmath97 since @xmath98 .",
    "our main result on the green number @xmath99 in the case of power law sequences is the following .",
    "[ thm : main_power - law ] let @xmath100 if @xmath101 , and @xmath102 otherwise .",
    "let @xmath103 be the largest integer satisfying @xmath104 .",
    "let @xmath105 be the largest integer such that @xmath106 finally , let @xmath107    then , for @xmath108 we have that a.a.s .",
    "@xmath109 where @xmath110 , for @xmath111 , @xmath112 and for @xmath113 , @xmath114    in the power law case , theorem  [ thm : main_power - law ] tells us that the green number is smaller for large @xmath66 .",
    "this reinforces the view that intercepting a message in a hierarchical social network following a power law is more difficult close to levels near the source .",
    "before analyzing the game on random @xmath63-regular dags , we need a few lemmas .",
    "we will be using the following version of a well - known chernoff bound .",
    "[ lem : chernoff ] let @xmath9 be a random variable that can be expressed as a sum @xmath115 of independent random indicator variables where @xmath116 is a bernoulli random variable with success probability @xmath117 with ( possibly ) different @xmath118 .",
    "then the following holds for @xmath119 : @xmath120 in particular , if @xmath121 , then @xmath122    we will start by proving the threshold for appearance of vertices of in - degree @xmath45 .",
    "[ lem : layersize ] let @xmath71 be any function that grows ( arbitrarily slowly ) as @xmath43 tends to infinity . then a.a.s .",
    "the following properties hold .",
    "* @xmath123 for any @xmath124 .",
    "* for all @xmath125 , let @xmath126 for every @xmath127 , we have that @xmath128 if @xmath129 , and @xmath130 for some @xmath131 . in particular , the threshold for the appearance of vertices of in - degree @xmath45 is @xmath132 .",
    "* @xmath133 for @xmath134 .",
    "for ( i ) note that the probability that a given vertex @xmath135 has in - degree @xmath136 at level @xmath137 is at most @xmath138 thus , the expected number of vertices of in - degree @xmath45 at level @xmath66 is @xmath139 and , in particular , the expected number of vertices of in - degree @xmath85 or more at @xmath23 is @xmath140 .",
    "set @xmath141 . by markov s inequality , with probability at least @xmath142",
    "we derive that @xmath143 since @xmath144 we obtain that a.a.s",
    ".   holds for all values of @xmath145 .",
    "since we aim for a statement that holds a.a.s . , we can assume for @xmath145 that @xmath146 , so ( i ) holds for @xmath147 .",
    "suppose that ( i ) holds for all @xmath148 ; that is , @xmath149 . by   and",
    "the inductive hypothesis ( used recursively ) , we obtain that @xmath150 where @xmath151 note that @xmath152    we now prove ( ii ) and ( iii ) . by part ( i ) , the number of random edges @xmath153 emanating from @xmath154 is @xmath155 when layer @xmath66 is created , these edges are joined to random vertices in the set @xmath156 of cardinality @xmath43 . for any fixed @xmath125 and any fixed layer @xmath124 , we define the indicator variable @xmath157 to be @xmath158 if @xmath159 has in - degree @xmath45 and @xmath3 otherwise , for @xmath160 .",
    "let @xmath161 .    as observed in part ( i ) of this proof , @xmath162 and thus , @xmath163 .",
    "by markov s inequality , a.a.s .  for @xmath164 ,",
    "no vertices of in - degree @xmath45 are present . by considering the case",
    "@xmath165 , this shows that for @xmath166 , all vertices have in - degree @xmath158 a.a.s . , and",
    "thus , for such @xmath66 we have @xmath167 a.a.s .",
    "hence , ( iii ) holds .",
    "we find that @xmath168 thus , @xmath169 ^ 2 ( 1+o(1 ) ) + { \\mathbb e}(x ) \\\\",
    "& = & ( { \\mathbb e}(x))^2(1+o(1))+{\\mathbb e}(x).\\end{aligned}\\ ] ] hence , for @xmath170 , it follows from chebyshev s inequality that @xmath171 and hence , a.a.s .",
    "there are vertices of in - degree @xmath45 , proving part ( ii ) of the lemma .",
    "the lemma is enough to prove the first two parts of the main theorem .    by lemma  [ lem : layersize ]  ( iii ) for @xmath172 the game",
    "is played on a tree .",
    "part ( i ) is trivial , since the greens have to protect all vertices in @xmath173 , or they lose .    to derive the upper bound of ( ii ) , note that for @xmath174 we have that @xmath175 ( @xmath176 for @xmath177 ) .",
    "the greens can play arbitrarily during the first @xmath178 steps , and then block the sludge on level @xmath66 .",
    "if @xmath179 , then we have that @xmath84 is an upper bound of @xmath68 , and the upper bound of ( iii ) holds .    to derive the lower bound of ( ii ) , note that if @xmath180 , then exactly @xmath84 new vertices are protected at each time - step .",
    "without loss of generality , we may assume that the greens always protect vertices adjacent to the sludge ( since the game is played on the tree , there is no advantage to play differently ) .",
    "no matter how the greens play , there is always at least one vertex not protected and the sludge can reach @xmath23 .    for a given vertex @xmath181 and integer @xmath66 , let us denote by @xmath182 the subset of @xmath183 consisting of vertices at distance @xmath66 from @xmath13 ( that is , those that are in the @xmath66-th level of the subgraph whose root is @xmath13 ) .",
    "let @xmath184 be the subgraph of all vertices of depth @xmath66 pending at @xmath13 . call a vertex @xmath185 _ bad _ if @xmath186 and @xmath17 has in - degree at least @xmath85 ( recall , that @xmath53 is a set of @xmath43 vertices used in the process of generating a random graph ) .",
    "let @xmath187 be the total number of bad vertices in @xmath188 .",
    "in the next lemma , we estimate @xmath187 .",
    "[ lem : badvertices ] a.a.s .",
    "the following holds for some large enough constant @xmath189 for any @xmath181 , where @xmath190 , and any @xmath66 such that @xmath191 , @xmath192    fix @xmath181 and let @xmath66 be the maximum integer satisfying @xmath191 .",
    "since there are @xmath193 possible vertices to consider , it is enough to show that the bound holds with probability @xmath194 .    for @xmath185 ,",
    "let @xmath195 ( @xmath196 ) be the event that @xmath197 and @xmath17 is bad .",
    "in order for @xmath17 to be in @xmath198 , @xmath17 must receive at least one edge from a vertex in @xmath199 , and in order to be bad it must have at least one more edge from either @xmath199 or from another vertex at layer @xmath200 .",
    "thus , @xmath201 since there are @xmath202 edges emanating from @xmath199 , and there are @xmath203 edges emanating from @xmath200 . letting @xmath204 being the corresponding indicator variable , we have that @xmath205 note that @xmath206 , since @xmath207 ( for a fixed total number of edges , the probability for @xmath17 to be bad is smaller if another vertex @xmath208 is bad ) and , by the law of total probability , at least one of the two conditional probabilities has to be at most @xmath209 .",
    "thus , @xmath210 is bounded from above by @xmath211 , where the @xmath212 are independent indicator random variables with @xmath213 for some sufficiently large @xmath214 .",
    "the total number of bad vertices in the subgraph of depth @xmath66 pending at @xmath13 is @xmath215 since @xmath216 @xmath217 and by the chernoff bound given by  ( [ eq : ch1 ] ) , @xmath218 with probability @xmath219 for some @xmath220 large enough .",
    "we need one more lemma . for a given vertex @xmath181 and integer @xmath66 , a vertex @xmath185",
    "is called _ very bad _ if it has at least two incoming edges from vertices in @xmath199 . in particular , every very bad vertex is bad .",
    "let @xmath221 be the number of very bad vertices in @xmath188 .",
    "for a given @xmath222 , and any @xmath223 such that @xmath224 , we will consider the subgraph @xmath225 consisting of all vertices to which there is a directed path from some vertex in @xmath226 .",
    "for any @xmath227 , let @xmath228 be a subset of @xmath229 that is in @xmath225 .",
    "[ lem : notworoots ] let @xmath223 for some @xmath222 be such that @xmath230 .",
    "then a.a.s .  for any @xmath231 , where @xmath232 , and any integer @xmath66 with @xmath191 , we have that @xmath233 .",
    "fix any @xmath231 for some @xmath232 .",
    "as in lemma  [ lem : badvertices ] , by letting @xmath234 be the event that @xmath185 is very bad , we have @xmath235 letting @xmath236 be the corresponding indicator variable , we have that @xmath237 analogously as in the previous proof , define independent indicator random variables @xmath238 with @xmath239 .",
    "we have @xmath240 and so @xmath241 since @xmath191 .    as @xmath224",
    ", we have that @xmath242 and so the expected number of very bad vertices found in @xmath228 is @xmath243 . finally , the expected number of very bad vertices in any sublayer @xmath228 ( @xmath244 ) is @xmath245 , and the result holds by markov s inequality .",
    "we now come back to the proof of the main theorem for random regular dags .",
    "note that we already proved an upper bound of ( iii ) ( see the proof of parts ( i ) and ( ii ) ) . since @xmath68 is non - increasing as a function of @xmath66 , an upper bound of ( iv ) also holds .",
    "we will prove a lower bound of ( iv ) first .",
    "the lower bound of ( iii ) will follow easily from there .",
    "let @xmath78 and suppose that we play the game with parameter @xmath246 .",
    "if @xmath247 , then for every @xmath14 , we have that @xmath248 and @xmath249 otherwise .",
    "( for @xmath250 we find that @xmath251 for any @xmath25 . )",
    "suppose that the greens play _ greedily _",
    "( that is , they always protect vertices adjacent to the sludge ) and the graph is locally a tree .",
    "note that during the time between @xmath252 and @xmath253 , they can direct the sludge leaving him exactly one vertex to choose from at each time - step . however , at time - step @xmath254 , the sludge has 2 vertices to choose from .",
    "the sludge has to use this opportunity wisely , since arriving at a bad vertex ( see definition above ) when the greens can protect @xmath84 vertices would result in him losing the game .",
    "our goal is to show that the sludge can avoid bad vertices and , as a result , he has a strategy to reach the sink @xmath23 .",
    "since we aim for a statement that holds a.a.s .",
    "we can assume that all properties mentioned in lemmas  [ lem : layersize ] ,  [ lem : badvertices ] , and  [ lem : notworoots ] hold .    before we describe a winning strategy for the sludge , let us discuss the following useful observation .",
    "while it is evident that the greens should use a greedy strategy to play on the tree , it is less evident in our situation . perhaps instead of playing greedily , the greens should protect a vertex far away from the sludge , provided that there are at least two paths from the sludge to this vertex .",
    "however , this implies that the vertex is very bad and we know that very bad vertices are rare .",
    "it follows from lemma  [ lem : notworoots ] that there is no very bad vertex within distance @xmath66 , provided that the sludge is at a vertex in @xmath229 , @xmath255 and @xmath256 .",
    "( for early steps we know that the graph is locally a tree so there are no bad vertices at all . )",
    "therefore , without loss of generality , we can assume that at any time - step @xmath25 of the game , the greens protect vertices greedily or protect vertices at distance at least @xmath66 where @xmath66 is the smallest value such that @xmath257 .",
    "we call the latter protected vertices _ dangerous_. the sludge has to make sure that there are no nearby bad nor dangerous vertices .",
    "let @xmath258 where the constant @xmath214 will be determined soon and is sufficiently large such that the sludge is guaranteed to escape from all bad or dangerous vertices which are close to him .",
    "let @xmath259 during the first @xmath260 time - steps , the sludge chooses any arbitrary branch .",
    "since he is given this opportunity at least @xmath261 times and each time he cuts the number of possible destinations by a factor of @xmath262 , the number of possible vertices the sludge can reach at time @xmath260 is @xmath263 .",
    "from that point on , it follows from lemma  [ lem : notworoots ] that there are no nearby very bad vertices . at time @xmath264 , by lemma  [ lem : layersize ] , there are no bad vertices at distance @xmath265 from the sludge , and hence , no dangerous vertices within this distance .",
    "it follows from lemma  [ lem : badvertices ] that there are @xmath266 bad vertices at distance @xmath267 there are @xmath266 dangerous vertices within this distance ( since the total number of protected vertices during the whole game is of this order ) .",
    "thus , there are @xmath266 bad or dangerous vertices at a distance between @xmath268 and @xmath269 from the sludge .",
    "to derive a lower bound on the length of the game , we provide a strategy for the sludge that allows him to play for at least a certain number of steps , independently of the greens behaviour .",
    "in particular , his goal is to avoid these bad or dangerous vertices : as long as the sludge is occupying a vertex that is not bad , there is at least one vertex on the next layer available to choose from .",
    "more precisely , it follows from lemma  [ lem : notworoots ] , that from time @xmath260 onwards , locally there are no very bad vertices .",
    "let us call a _ round _ a sequence of @xmath270 time - steps .",
    "since all bad vertices are in distinct branches , in every @xmath271-th time - step the sludge can half the number of bad vertices .",
    "therefore , after one round the sludge can escape from all @xmath272 bad or dangerous vertices that are under consideration in a given round , provided that @xmath214 is large enough constant .",
    "( recall the constant @xmath273 is defined in lemma  [ lem : badvertices ] . )    using this strategy , at time @xmath274 there are no bad or dangerous vertices at distance @xmath275 to see this , note that since the sludge escaped from all bad or dangerous vertices , which at time @xmath276 were at distance @xmath277 , and he has advanced @xmath270 steps by now . using lemma  [ lem : badvertices ] again",
    ", we find that there are @xmath266 bad or dangerous vertices at distance @xmath278 arguing as before , we find that it takes another @xmath270 steps to escape from them .",
    "in general , at time @xmath279 , there are @xmath266 bad or dangerous vertices at a distance between @xmath280 and @xmath281 thus , as long as @xmath282 , the strategy of escaping from bad or dangerous vertices before actually arriving at that level is feasible .",
    "moreover , we can finish this round , and so the sludge is guaranteed to use this strategy until time @xmath283 , where @xmath284 is the smallest value such that @xmath285 . solving this for @xmath284",
    "we obtain that @xmath286 and so @xmath287 hence , @xmath288 finally , note that if @xmath284 is the smallest value such that @xmath289 , we get that @xmath290 and so @xmath291 .",
    "hence , another @xmath292 steps can be played , and the constant of the second order term can be improved from @xmath293 to @xmath294 , yielding part ( iv ) .",
    "part ( iii ) follows by taking @xmath271 to be a function of @xmath43 slowly growing to infinity .",
    "our next goal is to show that when @xmath295 , the value of @xmath68 is slightly smaller than @xmath84 , provided that @xmath296 is a sufficiently large constant .",
    "however , before we do it , we need one more observation .",
    "it follows from lemma  [ lem : layersize](i ) that a.a.s .",
    "@xmath297 for @xmath298 ( @xmath299 is any function tending to infinity with @xmath43 , as usual ) . however , this is not the case when @xmath300 . at this point of the process ,",
    "a positive fraction of vertices of @xmath229 are bad .",
    "this , of course , affects the number of edges from @xmath229 to @xmath301 .",
    "in fact , the number of edges between two consecutive layers converges to @xmath302 as shown in the next lemma .",
    "[ lem : edges_conv ] let @xmath303 be the constant satisfying @xmath304 for every @xmath305 , there exists a constant @xmath306 such that a.a.s .  for every @xmath307 , @xmath308 and",
    "the number of edges between @xmath229 and @xmath301 is at least @xmath309 and at most @xmath310 .",
    "suppose that the layer @xmath229 has in total @xmath311 random incoming edges , for some @xmath312 $ ] .",
    "then the probability that a vertex @xmath135 ( recall that @xmath53 is the set of cardinality @xmath43 used to create layer @xmath229 ) has in - degree @xmath313 ( that is , absorbs @xmath45 incoming edges , or attracts no edge if @xmath314 ) is @xmath315 note that each vertex of in - degree @xmath316 generates @xmath317 edges to the next layer .",
    "further , vertices of in - degrees @xmath45 or more do not have any offspring , and vertices of @xmath53 of in - degree zero are not in @xmath229 .",
    "therefore , the expected number of outgoing edges produced by all vertices in layer @xmath229 is @xmath318 the events considered here are almost independent ( one can compute higher moments and see that the @xmath45th moment is asymptotically equal to the @xmath45th power of the first moment ) , so for any @xmath319 it follows from chernoff bounds that with probability @xmath320 the number of vertices of degree @xmath45 is @xmath321 .",
    "thus , with the same probability , strong concentration also follows for the number of edges .",
    "if the number of incoming edges equals @xmath302 , then the expected number of outgoing edges equals @xmath322 if less than @xmath302 edges are incoming , then more will be going out , and vice versa .",
    "the process converges and so there exists a constant @xmath306 such that a.a.s .",
    "the number of edges between two consecutive layers @xmath229 and @xmath301 is between @xmath309 and @xmath310 for any @xmath25 such that @xmath307 .    finally , let us recall that the layer @xmath229 consists of vertices of @xmath53 with in - degree at least one .",
    "the number of in - degree @xmath3 vertices is concentrated around its expectation , and thus we have that a.a.s.@xmath323 the lemma is proved .",
    "the value of @xmath303 ( and so @xmath324 as well ) can be numerically approximated .",
    "it is straightforward to see that @xmath303 tends to @xmath325 ( hence , @xmath324 tends to @xmath158 ) when @xmath326 .",
    "we present below a few approximate values .",
    ".approximate values of @xmath303 and @xmath324 .",
    "[ cols=\"^,^,^,^,^,^\",options=\"header \" , ]     finally , we are ready to finish the last part of theorem  [ thm : main_d - reg ]",
    ".    _ proof of theorem  [ thm : main_d - reg](v)_. we assume that the game is played with parameter @xmath246 for some @xmath327 . for every @xmath14 , we have that @xmath248 , and @xmath328 , otherwise . to derive an upper bound of @xmath68 that holds a.a.s .",
    ", we need to prove that a.a.s .",
    "there exists no winning strategy for the sludge .",
    "we will use a combinatorial game - type argument .",
    "the greens will play _ greedily _ ( that is , they will always protect nodes adjacent to the sludge ) .",
    "suppose that the sludge occupies node @xmath329 for some @xmath14 ( at time @xmath330 he moves from @xmath13 to some node in @xmath229 ) and he has a strategy to win from this node , provided that no node in the next layers is protected by the greens .",
    "we will call such a node _ sludge - win_. note that during the time period between @xmath252 and @xmath253 , the greens can protect @xmath84 nodes at a time , so they can direct the sludge leaving him exactly one node to choose from at each time - step . therefore ,",
    "if there is a node of in - degree at least 2 in any of these layers , the greens can force the sludge to go there and finish the game in the next time - step .",
    "this implies that all nodes within distance @xmath331 from @xmath13 ( including @xmath13 itself ) must have in - degree 1 and so the graph is locally a tree .",
    "however , at time - step @xmath254 , the greens can protect @xmath332 nodes , one less than in earlier steps .",
    "if the in - degree of a node reached at this layer is at least 3 , then the greens can protect all out - neighbours and win .",
    "further , if the in - degree is 2 and there is at least one out - neighbour that is not sludge - win , the greens can force the sludge to go there and win by definition of not being sludge - win .",
    "finally , if the in - degree is 1 , the sludge will be given 2 nodes to choose from .",
    "however , if there are at least two out - neighbours that are not sludge - win , the greens can `` present '' them to the sludge and regardless of the choice made by the sludge , the greens win .",
    "we summarize now the implications of the fact that @xmath329 is sludge - win .",
    "first of all , all nodes within distance @xmath331 are of in - degree 1",
    ". nodes at the layer @xmath333 below @xmath13 have in - degree at most 2",
    ". if @xmath334 has in - degree 2 , then all of the @xmath84 out - neighbours are sludge - win . if @xmath334 has in - degree 1 , then all out - neighbours except perhaps one node are sludge - win . using this observation",
    ", we characterize a necessary condition for a node @xmath335 to be sludge - win . for a given @xmath335 that can be reached at time 1 ,",
    "we define a _ sludge - cut _ to be the following cut : examine each node of @xmath336 , and proceed inductively for @xmath60 .",
    "if @xmath337 has out - degree @xmath338 , then we cut away any out - neighbour and all nodes that are not reachable from @xmath13 ( after the out - neighbour is removed ) .",
    "the node that is cut away is called an _ avoided node_. after the whole layer @xmath336",
    "is examined , we skip @xmath339 layers and move to the layer @xmath333 .",
    "we continue until we reach the sink , the layer @xmath340 for some @xmath341 ( we stop at @xmath23 without cutting any further ) .",
    "the main observation is that if the sludge can win the game , then the following claim holds .    _",
    "claim_. there exists a node @xmath335 and a sludge - cut such that the graph left after cutting is a @xmath342-regular graph , where each node at layer @xmath336 , @xmath343 has out - degree @xmath84 , and all other nodes have out - degree @xmath338 . in particular , for any @xmath343 the graph induced by",
    "the set @xmath344 is a tree .",
    "it remains to show that a.a.s .",
    "the claim does not hold .",
    "( since there are at most @xmath63 nodes in @xmath173 it is enough to show that a.a.s .",
    "the claim does not hold for a given node in @xmath173 . )",
    "fix @xmath335 .",
    "the number of avoided nodes at layer @xmath345 is at most the number of nodes in @xmath336 ( after cutting earlier layers ) , which is at most @xmath346 in particular , @xmath347 , the number of nodes in the sink after cutting , is at most @xmath348 .",
    "it can be shown that a.a.s .",
    "@xmath349 for some @xmath350 .",
    "fix @xmath351 .",
    "we need to show that for this given @xmath347 the claim does not hold with probability @xmath194 .",
    "since each node in @xmath352 has in - degree at most 2 , the number of nodes in @xmath353 is at most @xmath354 ( as before , after cutting ) .",
    "since the graph between layer @xmath355 and @xmath353 is a tree , the number of nodes in @xmath352 is at most @xmath356 , which is an upper bound for the number of avoided nodes at the next layer @xmath357 . applying this observation recursively we obtain that the total number of avoided nodes up to layer @xmath358 is at most @xmath359 to count the total number of sludge - cuts of a given graph , observe that each avoided node corresponds to one out of @xmath338 choices .",
    "hence , the total number of sludge - cuts is at most @xmath360    we now estimate the probability that the claim holds for a given @xmath335 and a sludge - cut . to obtain an upper bound",
    ", we estimate the probability that all nodes in the layer @xmath353 are of in - degree 1 .",
    "conditioning on the fact that we have @xmath347 nodes in the last layer , we find that the number of nodes in @xmath353 is at least @xmath361 let @xmath341 be large enough such that we are guaranteed by lemma  [ lem : edges_conv ] that the number of edges between the two consecutive layers is at least @xmath362 .",
    "hence , the probability that a node in @xmath353 has in - degree 1 is at most @xmath363 where @xmath305 can be arbitrarily small by taking @xmath341 large enough .",
    "let @xmath364 be the probability in ( [ woo ] ) .",
    "we derive that @xmath365 , where @xmath366 is a large enough constant .",
    "conditioning under @xmath367 having in - degree @xmath158 , it is harder for @xmath368 to have in - degree @xmath158 than without this condition , as more edges remain to be distributed .",
    "thus , the probability that all nodes in @xmath353 have the desired in - degree is at most @xmath369 thus , by taking a union bound over all possible sludge - cuts ( the upper bound for the number of them is given by  ) , the probability that the claim holds is at most @xmath370 which can be made @xmath371 by taking @xmath372 small enough , provided that @xmath271 is large enough so that @xmath373 by considering the extreme case for the probability of having in - degree one when @xmath374 we obtain that @xmath375 for @xmath62 ( see table  [ tab : small_values ] ) .",
    "it is straightforward to see that @xmath80 will work for any @xmath62 , and @xmath376 for @xmath377 . @xmath378",
    "let us recall that we have three parameters in this model : @xmath87 , @xmath88 , and @xmath89 . for a given set of parameters , we defined @xmath379 finally , for @xmath92 we have that @xmath93    before we analyze the game for this model , let us focus on investigating some properties of the random graph we play on .",
    "we already mentioned that the sequence @xmath380 is decreasing but it is not obvious which weights we obtain for a given level @xmath23 .",
    "we start by providing a lower bound for the weight of vertices in each layer @xmath66 ( which will imply an upper bound for the previous layer @xmath178 ) .",
    "since the weight @xmath42 is a function of the index @xmath284 , it is enough to focus on the latter . for @xmath381 ,",
    "let @xmath382 be the smallest index among the vertices of layer @xmath23 . using the notation introduced in section  [ sec : definitions ] , @xmath383 .",
    "the maximum weight at @xmath23 is @xmath384 , the minimum one is @xmath385 .",
    "the first lemma investigates the behaviour of @xmath382 .",
    "[ lem : max_deg ] let @xmath100 if @xmath101 , and @xmath386 otherwise .",
    "let @xmath107    the following holds a.a.s .",
    "* @xmath387 , @xmath388 , and @xmath389 .",
    "+ in particular , @xmath390 , @xmath391 , and @xmath392 * for @xmath393 we have that @xmath394 in particular , @xmath395 * if @xmath396 , then , @xmath397 in particular , @xmath398 * let @xmath103 be the largest integer satisfying @xmath104 .",
    "let @xmath105 be the largest integer such that @xmath399 then for @xmath400 we have that @xmath401 in particular , for @xmath400 we have that @xmath402 * for any @xmath403 , the number of edges between @xmath154 and @xmath404 is @xmath405.    clearly , we have @xmath406 , @xmath407 ; ( i ) holds deterministically for @xmath408 .",
    "the number of vertices on levels @xmath3 and @xmath158 is at most @xmath409 but can be slightly smaller if there are some parallel edges ( which happens a.a.s .  if @xmath410 ) .",
    "we derive a deterministic upper bound for @xmath411 of @xmath412 but in fact , using the first moment method , we can show that a.a.s .",
    "@xmath413 . indeed ,",
    "the probability that a given vertex from @xmath53 has in - degree at least 2 is @xmath414 so we expect @xmath415 vertices of in - degree at least 2 .",
    "with probability @xmath416 we have @xmath417 of such vertices and so @xmath418 .",
    "the statement for @xmath419 holds , and hence , part ( i ) follows .",
    "now , let us generalize this observation .",
    "let @xmath420 and suppose that @xmath421 is already estimated .",
    "note that @xmath422 so it remains to estimate the size of @xmath154 .",
    "we obtain that @xmath423 note that @xmath424 is an upper bound for the number of edges between layer @xmath425 and @xmath154 ( and so an upper bound for @xmath426 ) , and we derive the equality @xmath427 if all vertices in @xmath154 and @xmath425 have in - degree  1 . arguing as before",
    ", we deduce that with probability @xmath416 the number of edges going to vertices in @xmath425 ( in @xmath154 ) that are of degree at least 2 is @xmath428 ( @xmath429 , respectively ) .",
    "each edge of this type directed to a vertex in @xmath425 affects its out - degree , and so decreases the number of vertices in @xmath154 by at most one .",
    "similarly , one edge going to a vertex in @xmath154 of in - degree at least 2 decreases by at most one the number of vertices of in - degree 1 .",
    "thus , with probability @xmath416 , by considering vertices of in - degree 1 only , we obtain that @xmath430 ( the last equality follows from the fact that @xmath431 , provided that @xmath432 .",
    "in fact , we consider values of @xmath66 at most @xmath433 for which it will be shown that @xmath434 and so @xmath435 . )",
    "this , together with the fact that @xmath422 , implies that @xmath436    if @xmath437 , then @xmath438 note that @xmath439 and @xmath440 .",
    "therefore this recursive formula is to be applied @xmath441 times only before the condition @xmath442 fails ( it may , of course , happen that it fails for @xmath443 so we do not apply it at all ) .",
    "we have that a.a.s .",
    "the statement holds for any value of @xmath66 such that @xmath444 ; that is , @xmath445 moreover , the error term can be estimated much better ; it is , in fact , @xmath446 for some @xmath305 .",
    "let us note one more time that it may happen that @xmath447 and so the condition fails for @xmath443 but then ( ii ) trivially holds .",
    "thus , part ( ii ) is finished .    for part ( iii ) , suppose that @xmath396 . since our goal is to show that the statement holds a.a.s .",
    ", we may assume that @xmath448 for some @xmath305 .",
    "from the assumption it follows that @xmath449 and @xmath450 are of the same order . by the relations between @xmath450 and @xmath451",
    ", we have @xmath452 .",
    "thus , @xmath453 , and hence , @xmath454 .",
    "it follows from  ( [ ar : equations ] ) that a.a.s .",
    "@xmath455 so ( iii ) holds .    for part ( iv ) , let @xmath103 be the largest integer satisfying @xmath104 .",
    "based on earlier parts , we may assume that @xmath456 .",
    "note that @xmath457 for some @xmath305 , and so @xmath458 for any @xmath459 , since @xmath382 is monotonic as a function of @xmath66 .",
    "fix @xmath460 .",
    "this time we derive from  ( [ ar : equations ] ) that with probability @xmath416@xmath461 provided that @xmath462 ( note that we have @xmath463 , and thus we obtain the first condition , coming from the term @xmath429 . )",
    "the first condition is equivalent to @xmath464 , and so both conditions combined together are equivalent to @xmath465 if this condition is satisfied , then we obtain that @xmath466 , or equivalently @xmath467 . by using the condition on @xmath468",
    ", we obtain the following slightly stronger condition ( where we ignore the factor of @xmath85 ) for @xmath382 : @xmath469    now , suppose that ( [ eq : cond ] ) is satisfied , and we rewrite the relation between @xmath382 and @xmath421 using the fact that @xmath470 : @xmath471 applying this argument recursively , we obtain that @xmath472 finally , since we will soon show that @xmath473 we derive by the previous cases that @xmath474 indeed , since @xmath475 the condition ( [ eq : cond ] ) fails for @xmath476 ( by taking @xmath214 large enough ) , and item ( iv ) follows .    finally , the proof of part ( v ) follows now by inspecting closely the parts ( ii ) , ( iii ) , and ( iv ) .",
    "in each case , @xmath477 is the size of @xmath23 and it follows from earlier parts that @xmath478 .",
    "this is clearly a lower bound for the number of edges we try to estimate . on the other hand , @xmath479 serves as an upper bound .",
    "hence , it remains to show that @xmath480 . if @xmath481 , then @xmath482 . by looking at part ( ii ) ,",
    "we see that the leading term of both @xmath483 and @xmath484 is @xmath485 , and the result follows for this case ( alternatively , in this case we can also observe @xmath486 , @xmath487 , and by the trivial bound on the degree , @xmath488 holds ) .",
    "next , if @xmath489 , then @xmath490 , and by the calculations of part ( iii ) , in both @xmath484 and in @xmath479 the leading term is of order @xmath491 , and the result follows also for this case .",
    "finally , if @xmath492 , then @xmath493 , @xmath494 , and as observed in part ( iv ) , @xmath495 , and thus @xmath496 , and part ( v ) follows .",
    "we are now ready to come back to investigating the green number .",
    "we provide some obvious bounds for the green number and after that we sketch the idea that could be used to estimate it precisely . however , we do not perform these calculations rigorously , since the approach is rather delicate .",
    "[ lem : green_power_law ] let @xmath497 and @xmath103 be defined as in lemma  [ lem : max_deg ] .",
    "that is , let @xmath100 if @xmath101 , and @xmath102 otherwise .",
    "let @xmath103 be the largest integer satisfying @xmath498 .",
    "moreover , let @xmath105 be the largest integer such that @xmath106 then , for @xmath499 we have that a.a.s .",
    "@xmath500    note that the definition of @xmath433 in lemma  [ lem : green_power_law ] is slightly modified compared to the one from lemma  [ lem : max_deg ] .",
    "however there is only a @xmath441 difference between these values ; in this case it is smaller .",
    "fix @xmath108 and suppose that the game is played with the sink @xmath23 .",
    "since the maximum total degree ( and thus , the maximum out - degree ) of vertices in @xmath154 is at most @xmath501 , the greens can easily win when the game is played with parameter @xmath502 .",
    "they can play arbitrarily at the beginning of the game when the sludge is moving towards the sink .",
    "once he reaches a vertex @xmath503 , the greens can block all out - neighbours and the game ends .",
    "we obtain that @xmath504 .    in order to derive a lower bound",
    ", we will need the following property that follows directly from the proof of lemma  [ lem : max_deg ] and holds a.a.s .",
    "let us note that for @xmath400 we have that @xmath505 for @xmath506 we have @xmath507 so in fact  ( [ eq : cond_ell ] ) holds for any @xmath508 .",
    "now let us play the game with parameter @xmath509 for some @xmath305 .",
    "we will show that a.a.s .",
    "the sludge can win the game , independently of the strategy of the greens .",
    "this will prove that @xmath510 a.a.s .  and",
    "the result will hold after taking @xmath511 . if @xmath147 , then for any @xmath512 , a.a.s .",
    "@xmath513 , and thus , the greens clearly can not win the game by protecting @xmath514 vertices .",
    "hence , we may assume that @xmath515 .",
    "suppose first that @xmath516 and @xmath517 .",
    "since in this case @xmath518 , by the formulas for @xmath382 given by lemma  [ lem : max_deg ] , for any @xmath517 , @xmath519 .",
    "moreover , by part ( v ) of lemma  [ lem : max_deg ] , the number of edges between @xmath154 and @xmath23 is at most @xmath520 , with @xmath521 .",
    "hence , for any vertex @xmath522 , @xmath523 where @xmath524 denoting by @xmath525 the number of out - neighbours of @xmath13 with in - degree @xmath85 or more , we have that @xmath526 . since @xmath527 is a fixed upper bound on the number of edges between two consecutive layers , for any two vertices @xmath528 , @xmath529 .",
    "consider now another stochastic process in which each vertex @xmath522 , has exactly @xmath530 out - neighbours , and for each out - neighbour @xmath531 of @xmath13 , independently of all other vertices , @xmath532 .",
    "denote by @xmath533 the number of out - neighbours of @xmath13 with in - degree @xmath85 or more in this new stochastic process . clearly , @xmath534 for any @xmath13 .",
    "furthermore , by the previous observation of negative correlation between vertices of in - degree @xmath85 or more ( in the original process ) , @xmath535 for any @xmath536 . set @xmath537 to be a sufficiently small constant .",
    "then , by lemma  [ lem : chernoff ] , for some @xmath538 we have that @xmath539 by taking a union bound over all @xmath193 vertices of the first @xmath540 layers , a.a.s .",
    "all vertices have at least a @xmath541 fraction of out - neighbours with in - degree @xmath158 .",
    "now , in order to show a lower bound on the green number , we can assume that all vertices with in - degree @xmath85 or more are already protected by the greens in the very beginning ( they are cut away from top to bottom together with the subgraphs pending at them ) , and thus , the sludge is playing on the remaining graph that is a tree .",
    "we showed that a.a.s .",
    "the minimum degree in the remaining tree is at least @xmath542 observe that in a tree the best strategy for the greens is always to protect neighbours of the vertex currently occupied by the sludge . indeed ,",
    "if they protect a vertex at distance @xmath85 or more from the vertex occupied by the sludge , they can consider the path between the vertex occupied by the sludge and the vertex originally protected , and instead protect the unique out - neighbour of the vertex occupied by the sludge .",
    "clearly , this is at least as good move as the original one .",
    "since the greens have only @xmath543 at their disposal , in each round at least @xmath544 neighbours remain unprotected , and the sludge can go to any of these , and finally reach the sink .",
    "suppose now that @xmath545 or @xmath546 .",
    "for any @xmath547 we have @xmath548 moreover , note that the formula is true if @xmath549 , but @xmath550 , and also in the case @xmath545 we have @xmath551 , and @xmath552 for some @xmath553 .",
    "thus , combining these statements , for any @xmath554 , or any @xmath555 in the case @xmath545 , @xmath556 .",
    "since @xmath557 is a monotonically decreasing sequence , any vertex up to ( and including ) layer @xmath425 has weight at least @xmath558    we will provide a strategy for the sludge and show that it guarantees him win a.a.s .",
    ", provided that the game is played with parameter @xmath559 , as before .",
    "the strategy is straightforward ; in particular , he always goes to any non - protected vertex @xmath17 with the property that no out - neighbour of @xmath17 is protected .",
    "note that the total number of vertices protected at the end of the game is @xmath560 .",
    "moreover , each protected vertex can only eliminate this vertex or its parents .",
    "the number of parents of a given vertex @xmath17 , the in - degree of @xmath17 , can be large but these parents are `` scattered '' across the whole layer , as we will show in the following claim .    _ claim . _",
    "the following holds a.a.s .",
    "the number of paths from any vertex @xmath13 ( a vertex possibly occupied by the sludge ) and vertex @xmath17 two layers below ( a vertex possibly protected by the greens ) is bounded by some universal constant @xmath561 .",
    "_ proof of the claim . _ fix @xmath562 to be an arbitrarily small constant .",
    "suppose first that @xmath66 is such that @xmath563 .",
    "then , by monotonicity of @xmath384 , the number of directed paths of length two starting at @xmath564 is at most @xmath565 .",
    "thus , the probability that for a given vertex @xmath566 there are @xmath561 paths of length two starting from @xmath13 , is at most @xmath567 . by taking a union bound over all @xmath43 vertices @xmath17 from @xmath568 and all starting vertices @xmath13 ( there are at most @xmath43 of them )",
    ", we see that @xmath569 for a sufficiently large constant @xmath561 .",
    "the claim then holds for this range of values of @xmath66 , by taking a union bound over @xmath570 possible values of @xmath66 .    on the other hand ,",
    "if @xmath66 is such that @xmath571 , then by the formulas for @xmath384 given in lemma  [ lem : max_deg ] we see that @xmath572 and so @xmath573 as well .",
    "( indeed , the exponent of @xmath43 in the formula for @xmath574 in lemma  [ lem : max_deg](iv ) can be made arbitrarily small by taking a sufficiently large constant @xmath575 . ) since @xmath573 , it follows from lemma  [ lem : max_deg ] that @xmath576 for some @xmath577 , and as shown in part ( v ) of lemma  [ lem : max_deg ] , the number of edges between @xmath154 and @xmath23 is at most @xmath578 thus , the number of paths of length two starting at @xmath564 is at most @xmath527 .",
    "hence , as before , the probability that for a given vertex @xmath566 there are @xmath561 paths of length two starting from @xmath13 , is at most @xmath579 , and as before , by taking a union bound over all @xmath580 pairs of vertices @xmath581 and over all @xmath540 , for @xmath561 sufficiently large , @xmath582 , and the claim follows .",
    "hence , by the claim , we obtain that the number of eliminated vertices is still @xmath583 .",
    "finally , since the degree of each vertex in layers up to and including the layer @xmath425 is @xmath584 , the sludge can easily reach the layer @xmath154 . since the minimum degree in this layer is @xmath585 and the game",
    "is played with parameter @xmath509 , no matter what the greens do in this very last move , the sludge reaches the sink .",
    "thus , @xmath510 a.a.s .",
    "as we already mentioned , the result follows by taking @xmath372 tending to zero .",
    "theorem  [ thm : main_power - law ] follows immediately from lemma  [ lem : max_deg ] and lemma  [ lem : green_power_law ] .",
    "we finish by remarking on how we can try to close the gap in the previous lemma .",
    "it follows from lemma  [ lem : green_power_law ] that for @xmath499 we have that a.a.s .",
    "suppose then that the game is played with parameter @xmath27 such that @xmath587 for some @xmath562 . clearly , the sludge tries to stay on vertices with as small label as possible ( that is , the largest possible total degree ) .",
    "the greens aim for the opposite , they want the sludge to go to large labels ( the smallest total degree ) . in the first round , the sludge is guaranteed to be able to go to a vertex with label at most @xmath588 and , in fact , the greens can force him to go to @xmath589 . in the next round , it might be the case that there are some `` shortcuts '' to vertices of degree at least 2 with small labels but , since the number of such edges is very small , the greens can easily prevent the sludge from using these edges . after securing these edges",
    ", the greens should protect the remaining neighbours of @xmath589 with small labels . however , this time this does not help much .",
    "the sludge is forced to ( but also is able to ) go to a vertex whose label is @xmath590 repeating this argument , and the calculations performed in the proof of lemma  [ lem : max_deg ] , we can compute the position of the sludge at time @xmath178 and based on that we can decide if he wins or looses this game . optimizing this with respect to the parameter @xmath27 would yield the asymptotic value of @xmath68 .",
    "we considered seepage played on regular dags in theorem  [ thm : main_d - reg ] , and in power law dags in theorem  [ thm : main_power - law ] .",
    "it would be interesting to analyze the game on random dags with other degree sequences ; for example , where the degree distribution remains the same at each level , or there are the same number of vertices at each level . while our emphasis was on asymptotic results for the green number in random dags , our results could be complemented by an analysis ( via simulations ) of the green number on small dags , say up to 100 vertices .",
    "we will consider such an approach in future work .",
    "finally , hierarchical social networks are not usually strictly acyclic ; for example , on twitter , directed cycles of followers may occur .",
    "seepage was defined in @xcite for dags , but it naturally extends to the setting with directed cycles ( here , the directed graphs considered must have at least one source and a set of sinks ; the game is then played analogously as before ) .",
    "a next step would be to extend our results , if possible , to a setting where such cycles occur , and analyze the green number on , say , their strongly connected components .",
    "one question is to determine if the green number change as a function of the number of backward edges .",
    "we would like to thank the anonymous referees for suggestions which improved the paper .",
    "a.  gutfraind , a.  hagberg , and f.  pan , optimal interdiction of unreactive markovian evaders , in : _ integration of ai and or techniques in constraint programming for combinatorial optimization problems _ , hoeve , willem - jan van ; hooker , john n. ( eds ) , ( springer berlin / heidelberg ) 2009 .",
    "wormald , models of random regular graphs , _ surveys in combinatorics _ , 1999 , j.d .",
    "lamb and d.a .",
    "preece , eds .",
    "london mathematical society lecture note series , vol 276 , pp .",
    "239298 . cambridge university press , cambridge , 1999"
  ],
  "abstract_text": [
    "<S> we examine a dynamic model for the disruption of information flow in hierarchical social networks by considering the vertex - pursuit game seepage played in directed acyclic graphs ( dags ) . in seepage , agents attempt to block the movement of an intruder who moves downward from the source node to a sink . the minimum number of such agents required to block the intruder is called the green number . </S>",
    "<S> we propose a generalized stochastic model for dags with given expected total degree sequence . </S>",
    "<S> seepage and the green number is analyzed in stochastic dags in both the cases of a regular and power law degree sequence . </S>",
    "<S> for each such sequence , we give asymptotic bounds ( and in certain instances , precise values ) for the green number .    </S>",
    "<S> [ section ] [ theorem]lemma [ theorem]definition [ theorem]remark [ theorem]conjecture [ theorem]proposition [ theorem]algorithm [ theorem]corollary [ theorem]observation [ theorem]open problem </S>"
  ]
}