{
  "article_text": [
    "we study the minima of a specific least squares problem using the second partial derivative test .",
    "the problem s origin is an optimization - based solution proposed in ( seel , schauer , and raisch 2012 ) to enable robust tracking of human limbs using imu sensors .",
    "the original problem works with 6 dof rigid - body limbs in three dimensional space , but we shall instead work on a planar version of it to simplify the analysis .",
    "this is harmless given that our purpose is to study the uniqueness of minima : if the minima are not unique in the planar case problem , they are also not so for the spatial one .",
    "we consider the nonlinear optimization problem of minimizing the sum of square errors objective function @xmath0 , where @xmath1 is the number of samples and @xmath2 are angles .",
    "each sample @xmath3 is a six dimensional vector that determines the sample s error and is denoted by @xmath4{w}{_{11}},\\tensor[^s]{w}{_{12}},\\tensor[^s]{w}{_{13}},\\tensor[^s]{w}{_{21}},\\tensor[^s]{w}{_{22}},\\tensor[^s]{w}{_{23}})$ ] .",
    "given the above , @xmath5 is given by    @xmath6{d}{}(\\theta_1,\\theta_2))^2 , \\\\",
    "\\tensor[^s]{d}{}(\\theta_1,\\theta_2 ) & = p(\\theta_1 , \\tensor[^s]{w}{_{1 } } ) - p(\\theta_2 , \\tensor[^s]{w}{_{2 } } ) , \\\\   p(\\theta_i , \\tensor[^s]{w}{_{i } } ) & = [ \\tensor[^s]{w}{_{i1 } } \\sin(\\theta_i ) - \\tensor[^s]{w}{_{i3 } } \\cos(\\theta_i)]^2 + ( \\tensor[^s]{w}{_{i2}})^2.\\end{aligned}\\ ] ]    this corresponds to equation ( 1 ) in ( seel , schauer , and raisch 2012 ) up to variable names after the switching to a two - dimensional planar hinge problem where only a single angle has to be determined , moving to spherical coordinates with    @xmath7    and application of trigonometric identities .",
    "we shall mostly skip the dependent variables for functions within expressions and move any indices that need to be retained under the letter .",
    "per example we shall write @xmath8 to mean @xmath9 .",
    "additionally , we shall employ newton s dot even for a partial derivative when there is no ambiguity .",
    "we now procede to finding the stationary points and characterizing them using the second partial derivative test .      despite the simplicity of the problem ,",
    "a direct attempt using symbolic mathematics software is undermined by the fact that the symbolic expressions generated for the relevant quantities for even the single - sample problem @xmath10 are unworkable for a human as one can judge from their length and form in the appendix .",
    "it is a fact that the sum of two equal period sinusoids is another sinusoid with the same period .",
    "such sinusoids are known in physics as @xmath11 , and the fact can be proved using trigonometric identities and is expressed by :    @xmath12).\\ ] ]    given this , let us define a number of functions that will prove helpful when applying the chain rule during differentiation :    @xmath13 ) .",
    "s(w_i ) & = ( w_{i1}^2 + w_{i3}^2 ) . \\\\",
    "t(\\theta_i , w_i ) & = w_{i1 } \\sin(\\theta_i ) - w_{i3 } \\cos(\\theta_i ) , \\\\   & = \\sqrt{s(w_i ) } \\cos(r(\\theta_i , w_i)).\\\\ p(\\theta_i , w_i ) & = t^2(\\theta_i , w_i ) + ( w_{i2})^2.\\end{aligned}\\ ] ]    due to the abundance of @xmath14 and @xmath15 where @xmath16 is an integer in what follows , we shall shorten such terms in this manner :    @xmath17,\\nonumber \\\\",
    "\\cos(k_1\\,r_i)\\,\\cos(k_2r_j ) & \\twoheadrightarrow \\left[{k_1 \\atop\\text{co}_i}{k_2 \\atop\\text{co}_j}\\right],\\nonumber\\end{aligned}\\ ] ]    and similarly for the sine function . in this notation ,",
    "the known half - angle trigonometric identities are    @xmath18 & = \\frac{1}{2 } \\left[{2k \\atop\\text{si}_i}\\right].\\nonumber\\\\   \\left[{k \\atop\\text{co}_i}\\right]^2 & = \\frac{1}{2 } + \\frac{1}{2 } \\left[{2k \\atop\\text{co}_i}\\right].\\nonumber\\end{aligned}\\ ] ]      [ [ first - partial - derivatives ] ] first partial derivatives + + + + + + + + + + + + + + + + + + + + + + + + +    @xmath19\\,\\dot{r_i}\\nonumber\\\\   & = ( -\\sqrt{s_i})\\,\\sin(r_i ) . \\nonumber\\\\ \\frac{\\partial p_i}{\\partial \\theta_i } & = 2\\,t_i\\,\\dot{t_i}\\nonumber \\\\   & = 2\\,[\\sqrt{s_i}\\,\\cos(r_i)]\\,[(-\\sqrt{s_i})\\,\\sin(r_i)]\\nonumber \\\\   & = ( -s_1)\\,\\sin(2r_i ) .",
    "\\nonumber\\\\ \\frac{\\partial d}{\\partial \\theta_1 } & = \\frac{\\partial ( p_1-p_2)}{\\partial \\theta_1}\\nonumber \\nonumber\\\\   & = ( -s_1)\\,\\sin(2r_1 ) .",
    "\\\\ \\frac{\\partial d}{\\partial \\theta_2 } & = \\frac{\\partial ( p_1-p_2)}{\\partial \\theta_2}\\nonumber \\nonumber\\\\   & = ( s_2)\\,\\sin(2r_2).\\nonumber \\\\ \\frac{\\partial o_1}{\\partial \\theta_1 } & = 2\\,d\\,\\frac{\\partial d}{\\partial \\theta_1}\\nonumber \\\\   & = -2s_1\\,d\\,\\sin(2r_1 ) .",
    "\\\\   \\frac{\\partial o_1}{\\partial \\theta_2 } & = 2\\,d\\,\\frac{\\partial d}{\\partial \\theta_2}\\nonumber \\\\    & = 2s_2\\,d\\,\\sin(2r_2).\\end{aligned}\\ ] ]    we are now in a position to write the jacobian as    @xmath20,\\,\\ , 2s_2\\,d\\left[{2\\atop\\text{si}_2}\\right ] \\right).\\ ] ]    let us additionally expand @xmath21 in terms of trigonometric functions for later use .",
    "@xmath22 + w_{12}^2 - \\frac{s_2}{2 } - \\frac{s_2}{2 } \\left[2\\atop\\text{co}_2\\right ] - w_{22}^2\\nonumber \\\\   & = \\frac{1}{2 } \\left ( c + s_1\\left[2\\atop\\text{co}_1\\right ] - s_2\\left[2\\atop\\text{co}_2\\right ] \\right).\\end{aligned}\\ ] ]    where    @xmath23.\\ ] ]    hence ,    @xmath24 - s_2\\left[2\\atop\\text{co}_2\\right ] \\right)\\right]\\left[2\\atop\\text{si}_1\\right]\\nonumber \\\\   & = ( -s_1)\\left[2\\atop\\text{si}_1\\right]\\left ( c + s_1\\left[2\\atop\\text{co}_1\\right ] - s_2\\left[2\\atop\\text{co}_2\\right]\\right ) , \\label{eq : note39}\\\\   & =   ( -s_1)\\left ( c\\left[2\\atop\\text{si}_1\\right ] + \\frac{1}{2}s_1\\left[{4\\atop\\text{si}_1}\\right ] - s_2\\left[{2\\atop\\text{si}_1}{2\\atop\\text{co}_2}\\right]\\right).\\end{aligned}\\ ] ]    similarly , we have for @xmath25 :    @xmath26\\left ( c + s_1\\left[2\\atop\\text{co}_1\\right ] - s_2\\left[2\\atop\\text{co}_2\\right]\\right),\\\\   & =   ( s_2)\\left ( c\\left[2\\atop\\text{si}_2\\right ] +   s_1\\left[{2\\atop\\text{co}_1}{2\\atop\\text{si}_2}\\right ] - \\frac{1}{2}s_2\\left[{4\\atop\\text{si}_2}\\right ] \\right).\\end{aligned}\\ ] ]    [ [ second - partial - derivatives ] ] second partial derivatives + + + + + + + + + + + + + + + + + + + + + + + + + +    making use of the various derivations from the last section we have :    @xmath27 , \\nonumber \\\\   & = ( -2s_1 ) \\left(2d\\left[2\\atop\\text{co}_1\\right ] -s_1\\left[2\\atop\\text{si}_1\\right]^2\\right ) , \\nonumber \\\\    & = ( -2s_1 ) \\left(2d\\left[2\\atop\\text{co}_1\\right ] -s_1\\left(1-\\frac{1}{2}-\\frac{1}{2}\\left[4\\atop\\text{co}_1\\right]\\right)\\right ) , \\nonumber \\\\   & =   ( -2s_1 ) \\left ( \\frac{-s_1}{2 } + 2d\\left[2\\atop\\text{co}_1\\right ] + \\frac{s_1}{2}\\left[4\\atop\\text{co}_1\\right]\\right).\\end{aligned}\\ ] ]    a full expansion of the expression along with the half - angle identity gives the alternative form    @xmath28 + s_1\\left[4\\atop\\text{co}_1\\right ] - s_2\\left[{2\\atop\\text{co}_1}{2\\atop\\text{co}_2}\\right ] \\right).\\ ] ]    in a similar vein we obtain the derivative relative to @xmath29 :    @xmath30 - \\frac{s_2}{2}\\left[4\\atop\\text{co}_2\\right]\\right ) , \\\\",
    "= ( 2s_2 ) \\left ( c\\left[2\\atop\\text{co}_2\\right ] - s_2\\left[4\\atop\\text{co}_2\\right ] + s_1\\left[{2\\atop\\text{co}_1}{2\\atop\\text{co}_2}\\right ] \\right).\\end{aligned}\\ ] ]    it is obvious that the order of differentiation does not matter when considering the partial derivative with respect to @xmath31 .",
    "this derivative is given by    @xmath32.\\end{aligned}\\ ] ]    finally , we denote the problem s hessian s determinant by    @xmath33{h}{}}\\rvert } } - \\underbrace { { \\left[\\frac{\\partial^2 o_1}{\\partial \\theta_1\\partial \\theta_2}\\right]}^2 } _ { { \\lvert{\\tensor * [ _ { r}]{h}{}}\\rvert } } , \\\\   & = { \\lvert{\\tensor * [ _ { l}]{h}{}}\\rvert } - 4 \\left ( s_1 \\left[2\\atop\\text{si}_1\\right ] \\right)^2 \\left ( s_2 \\left[2\\atop\\text{si}_2\\right ] \\right)^2.\\end{aligned}\\ ] ]      [ [ zeros - of - first - partials ] ] zeros of first partials + + + + + + + + + + + + + + + + + + + + + + +    the expressions of the first partials are the product of three terms , the values of @xmath2 at which we obtain zeros are the union of three sets . the first terms @xmath34 and @xmath35 are not a function of @xmath2 so we consider the case @xmath36 as degenerate going forward and ignore it ; since @xmath37 is non - negative by definition , we assume from now on that    @xmath38    this leaves us with two sets per partial . paying close attention to similarities and differences between the two partials , we denote the sets as    @xmath39{z } { } } & : \\{\\theta_i : \\left[2\\atop\\text{si}_i\\right ] = 0 \\ } , \\\\    { \\tensor*[^{\\theta_{}}_{2}]{z } { } } & : \\{(\\theta_1,\\theta_2 ) : \\left ( c + s_1\\left[2\\atop\\text{co}_1\\right ] - s_2\\left[2\\atop\\text{co}_2\\right]\\right ) = 0 \\}.\\end{aligned}\\ ] ]    as we shall see , the sets are more tersely described if we focus on @xmath40 instead of on @xmath2 and this is harmless since the former are merely offset and scaled functions of the latter . out of terseness",
    "as well we let    @xmath41 , \\\\",
    "\\beta(w ) & = 2w_{12}^2 - 2w_{22}^2.\\end{aligned}\\ ] ]    @xmath42{z } { } } $ ] has the simple solution    @xmath43    [ [ first - stationary - set ] ] first stationary set + + + + + + + + + + + + + + + + + + + +    the intersection of @xmath42{z } { } } $ ] directly gives us a first set of stationary points in the @xmath44 plane as    @xmath45{s } { } }    & : \\ { (   - \\alpha_1 + [ \\frac{k_1\\pi}{2 } ] , - \\alpha_2 + [ \\frac{k_2\\pi}{2 } ] ) : k_1,k_2 \\in \\mathbb{z } \\}.\\end{aligned}\\ ] ]    let us conduct the second partial derivative test on this set .",
    "we first find the cases to consider . since @xmath46 , all sines involved are zero .",
    "on the other hand the cosines fall in the set @xmath47 and we need to consider both cases .",
    "the first one is    @xmath48    the second is similar and we find that we need to consider the even and odd values of @xmath49 separately .",
    "this gives a total combination of four cases as follows :    @xmath50    treating all four cases simultaneously with the aid of an unorthodox but straightforward notation , we have that @xmath51{s } { } } } ] { \\lvert{\\tensor * [ _ { l}]{h } { } } } { } \\rvert } $ ] equals to{s } { } } } ] { \\lvert{\\tensor * [ _ { l}]{h } { } } } { } \\rvert } $ ] we mean @xmath52{\\lvert{\\tensor * [ _ { l}]{h } { } } } { } \\rvert } $ ] evaluated at points in @xmath53{s } { } } $ ] . ]",
    "@xmath54\\kern-0.5ex } + 2s_1 { \\kern-0.5ex\\left[\\kern-1.5ex \\begin{array}{c}\\scriptscriptstyle{1}\\\\\\scriptscriptstyle{1}\\\\\\scriptscriptstyle{1}\\\\\\scriptscriptstyle{1}\\end{array } \\kern-1.5ex\\right]\\kern-0.5ex } -2s_2 { \\kern-0.5ex\\left[\\kern-1.5ex \\begin{array}{c}\\scriptscriptstyle{+1}\\\\\\scriptscriptstyle{-1}\\\\\\scriptscriptstyle{+1}\\\\\\scriptscriptstyle{-1}\\end{array } \\kern-1.5ex\\right]\\kern-0.5ex } { \\kern-0.5ex\\left[\\kern-1.5ex \\begin{array}{c}\\scriptscriptstyle{+1}\\\\\\scriptscriptstyle{+1}\\\\\\scriptscriptstyle{-1}\\\\\\scriptscriptstyle{-1}\\end{array } \\kern-1.5ex\\right]\\kern-0.5ex } )    s_2 ( 2c { \\kern-0.5ex\\left[\\kern-1.5ex \\begin{array}{c}\\scriptscriptstyle{+1}\\\\\\scriptscriptstyle{+1}\\\\\\scriptscriptstyle{-1}\\\\\\scriptscriptstyle{-1}\\end{array } \\kern-1.5ex\\right]\\kern-0.5ex } - 2s_2 { \\kern-0.5ex\\left[\\kern-1.5ex \\begin{array}{c}\\scriptscriptstyle{1}\\\\\\scriptscriptstyle{1}\\\\\\scriptscriptstyle{1}\\\\\\scriptscriptstyle{1}\\end{array } \\kern-1.5ex\\right]\\kern-0.5ex } + 2s_1 { \\kern-0.5ex\\left[\\kern-1.5ex \\begin{array}{c}\\scriptscriptstyle{+1}\\\\\\scriptscriptstyle{-1}\\\\\\scriptscriptstyle{+1}\\\\\\scriptscriptstyle{-1}\\end{array } \\kern-1.5ex\\right]\\kern-0.5ex } { \\kern-0.5ex\\left[\\kern-1.5ex \\begin{array}{c}\\scriptscriptstyle{+1}\\\\\\scriptscriptstyle{+1}\\\\\\scriptscriptstyle{-1}\\\\\\scriptscriptstyle{-1}\\end{array } \\kern-1.5ex\\right]\\kern-0.5ex } ) \\\\ & = ( -s_1 s_2 ) ( 2s_1 + 2c { \\kern-0.5ex\\left[\\kern-1.5ex \\begin{array}{c}\\scriptscriptstyle{+1}\\\\\\scriptscriptstyle{-1}\\\\\\scriptscriptstyle{+1}\\\\\\scriptscriptstyle{-1}\\end{array } \\kern-1.5ex\\right]\\kern-0.5ex } -2s_2 { \\kern-0.5ex\\left[\\kern-1.5ex",
    "\\begin{array}{c}\\scriptscriptstyle{+1}\\\\\\scriptscriptstyle{-1}\\\\\\scriptscriptstyle{-1}\\\\\\scriptscriptstyle{+1}\\end{array } \\kern-1.5ex\\right]\\kern-0.5ex } ) ( -2s_2 + 2c { \\kern-0.5ex\\left[\\kern-1.5ex \\begin{array}{c}\\scriptscriptstyle{+1}\\\\\\scriptscriptstyle{+1}\\\\\\scriptscriptstyle{-1}\\\\\\scriptscriptstyle{-1}\\end{array } \\kern-1.5ex\\right]\\kern-0.5ex } + 2s_1 { \\kern-0.5ex\\left[\\kern-1.5ex \\begin{array}{c}\\scriptscriptstyle{+1}\\\\\\scriptscriptstyle{-1}\\\\\\scriptscriptstyle{-1}\\\\\\scriptscriptstyle{+1}\\end{array } \\kern-1.5ex\\right]\\kern-0.5ex } ) \\end{aligned}\\ ] ]    expanding @xmath55 we get after a few steps that    @xmath56{s } { } } } ] { \\lvert{\\tensor * [ _ { l}]{h } { } } } { } \\rvert }   & = ( -s_1 s_2 ) ( { \\kern-0.5ex\\left[\\kern-1.5ex \\begin{array}{c}\\scriptscriptstyle{4s_1}\\\\\\scriptscriptstyle{0}\\\\\\scriptscriptstyle{4s_1}\\\\\\scriptscriptstyle{0}\\end{array } \\kern-1.5ex\\right]\\kern-0.5ex } + { \\kern-0.5ex\\left[\\kern-1.5ex \\begin{array}{c}\\scriptscriptstyle{-4s_2}\\\\\\scriptscriptstyle{4s_2}\\\\\\scriptscriptstyle{0}\\\\\\scriptscriptstyle{0}\\end{array } \\kern-1.5ex\\right]\\kern-0.5ex } + { \\kern-0.5ex\\left[\\kern-1.5ex \\begin{array}{c}\\scriptscriptstyle{2\\beta}\\\\\\scriptscriptstyle{-2\\beta}\\\\\\scriptscriptstyle{2\\beta}\\\\\\scriptscriptstyle{-2\\beta}\\end{array } \\kern-1.5ex\\right]\\kern-0.5ex } ) ( { \\kern-0.5ex\\left[\\kern-1.5ex \\begin{array}{c}\\scriptscriptstyle{4s_1}\\\\\\scriptscriptstyle{0}\\\\\\scriptscriptstyle{-4s_1}\\\\\\scriptscriptstyle{0}\\end{array } \\kern-1.5ex\\right]\\kern-0.5ex } + { \\kern-0.5ex\\left[\\kern-1.5ex \\begin{array}{c}\\scriptscriptstyle{-4s_2}\\\\\\scriptscriptstyle{-4s_2}\\\\\\scriptscriptstyle{0}\\\\\\scriptscriptstyle{0}\\end{array } \\kern-1.5ex\\right]\\kern-0.5ex } + { \\kern-0.5ex\\left[\\kern-1.5ex \\begin{array}{c}\\scriptscriptstyle{2\\beta}\\\\\\scriptscriptstyle{2\\beta}\\\\\\scriptscriptstyle{-2\\beta}\\\\\\scriptscriptstyle{-2\\beta}\\end{array } \\kern-1.5ex\\right]\\kern-0.5ex } ) , \\nonumber \\\\    & = \\begin{drcases } ( - s_1 s_2 ) { \\kern-0.5ex\\left[\\kern-1.5ex \\begin{array}{c}\\scriptscriptstyle{+1}\\\\\\scriptscriptstyle{-1}\\\\\\scriptscriptstyle{-1}\\\\\\scriptscriptstyle{+1}\\end{array } \\kern-1.5ex\\right]\\kern-0.5ex } { \\kern-0.5ex\\left[\\kern-1.5ex \\begin{array}{c}\\scriptscriptstyle{(4s_1 - 4s_2 + 2\\beta)^2}\\\\\\scriptscriptstyle{(4s_2 - 2\\beta)^2}\\\\\\scriptscriptstyle{(4s_1 + 2\\beta)^2}\\\\\\scriptscriptstyle{(-2\\beta)^2}\\end{array } \\kern-1.5ex\\right]\\kern-0.5ex } \\quad \\end{drcases } \\begin{array}{c } { < 0}\\\\ { > 0}\\\\ { > 0}\\\\ { < 0}\\end{array}.\\end{aligned}\\ ] ]    since it is clear that @xmath51{s } { } } } ] { \\lvert{\\tensor * [ _ { r}]{h } { } } } { } \\rvert } $ ] amounts to zero unconditionally , we reach the result that @xmath51{s } { } } } ] { \\lvert{\\tensor * [ _ { } ] { h } { } } } { } \\rvert } $ ] does not depend on the sample s data . ignoring degenerate cases",
    ", we see that we have saddle points for the first and fourth cases , and extrema for the second and third .",
    "we continue the test and determine the nature of the extrema by examining the sign of @xmath57 , the expression of which we already worked out during the previous calculation and which is    @xmath58{s } { } } } ] { \\frac{\\partial^2 o_1}{\\partial \\theta_1 ^ 2 } } { } =   ( - s_1 ) { \\kern-0.5ex\\left[\\kern-1.5ex \\begin{array}{c}\\scriptscriptstyle{4s_1 - 4s_2 + 2\\beta}\\\\\\scriptscriptstyle{4s_2 - 2\\beta}\\\\\\scriptscriptstyle{4s_1 + 2\\beta}\\\\\\scriptscriptstyle{-2\\beta}\\end{array } \\kern-1.5ex\\right]\\kern-0.5ex } .\\ ] ]    let us derive for the extremal cases the conditions under which we obtain maxima , which is the relevant case as we shall see later .",
    "for the second case we require :    @xmath59 ) < 0 , \\\\   w_{21}^2+w_{23}^2 - w_{12}^2 + w_{22}^2 > 0 , \\\\   w_{12}^2 < w_{21}^2+w_{23}^2+w_{22}^2.\\end{aligned}\\ ] ]    we obtain a similar result for the third case and we conclude that the extrema are maxima under the elegant condition    @xmath60    pictorially , we obtain a simple grid of saddle points and maxima for @xmath53{s } { } } $ ] as shown in figure [ fig : note50 ] .    ; ; iin 0, ... ,3 ( -1,i )  ( -0.4,i ) ; ( -0.4,i )  ( 5.4,i ) ; ( 5.4,i )  ( 6,i ) ; iin 0, ... ,5 ( i,-1 )  ( i,-0.4 ) ; ( i,-0.4 )  ( i,3.4 ) ; ( i,3.4 )  ( i,4 ) ;    in 0,2 in 0,2,4 at ( , ) ; in 1,3,5 at ( , ) ; ( 6.2,0 )  ( 6.2,1 ) ; at ( 6.7,0.5 ) @xmath61 ;    ( 4,-1.3 )  ( 5,-1.3 ) ; at ( 4.5,-2.0 ) @xmath61 ;    in 1,3 in 1,3,5 at ( , ) ; in 0,2,4 at ( , ) ;    at ( 8,3 )    l    at ( 0,0 ) ;     +    at ( 0,0 ) ;    ;    [ [ second - stationary - set ] ] second stationary set + + + + + + + + + + + + + + + + + + + + +    unlike the discrete set above , the second set of zeros already implicitly links the two variables into a curve which we shall study . by this",
    "we have that @xmath62{s } { } } $ ] is identical to @xmath63{z } { } } $ ] and is characterized by    @xmath64    let us first study the set s existence , which is obviously determined by the condition that the right - hand - side of the equation above is within @xmath65 $ ] .",
    "we have that    @xmath66    and hence    @xmath67}}_{\\left[\\dfrac{-s_2}{s_1},\\dfrac{s_2}{s_1}\\right]}}_{}\\quad \\nonumber \\\\",
    "\\left[-1-\\frac{\\beta}{s_1 } , -1-\\frac{\\beta}{s_1}+\\frac{2s_2}{s_1}\\right].\\end{aligned}\\ ] ]    by this , we have a non - empty solution set if and only if    @xmath68    for the first predicate we require    @xmath69    the second predicate leads to a similar calculation and we obtain , ( harmlessly in our context ) making the inequalities strict , here again exactly the elegant condition ( [ eqn : note49 ] ) .",
    "by this we see that for the second and third cases of @xmath53{s } { } } $ ] , if the set contained minima it would also have to contain their related maxima , an altogether ` degenerate ' situation compared to the minima coming from the curves generated by @xmath62{s } { } } $ ] .",
    "it is because of this that we spared ourselves conducting the full second partial derivative test for that case .",
    "condition ( [ eqn : note49 ] ) is therefore a test for ` correct ' and ` useful ' samples .",
    "in fact there is a more direct explanation for the condition .",
    "it is easy to see that @xmath70 has its minimum at @xmath71 when @xmath72 is zero and its maximum at @xmath73 when the cosine is at an extremum . at the same time",
    ", the error function @xmath74 can only be zero when there are @xmath2 such that @xmath75 . but considering the ranges above , this is equivalent to our condition . in other words , samples that do not satisfy it",
    "are guaranteed to come from inexact measurements .",
    "it goes without saying that the converse is not necessarily true .",
    "what the condition and its relation to @xmath53{s } { } } $ ] also tells us is that the @xmath62{s } { } } $ ] must be a set of minima . despite that , we proceed to check this fact in a direct manner .    to do this",
    ", we feed the solution set into the relevant expressions by doing the substitution    @xmath76    by this we obtain for @xmath77 :    @xmath78 } } + 2s_1 { { \\left[\\kern-0.5ex{4}\\atop{{\\text{co}}_{1}}\\kern-0.5ex\\right ] } } -2 { { \\left[\\kern-0.5ex{2}\\atop{{\\text{co}}_{1}}\\kern-0.5ex\\right ] } } ( c + s_1 { { \\left[\\kern-0.5ex{2}\\atop{{\\text{co}}_{1}}\\kern-0.5ex\\right ] } } ) ] \\\\ = & ( -s_1 ) [ 2s_1 { { \\left[\\kern-0.5ex{4}\\atop{{\\text{co}}_{1}}\\kern-0.5ex\\right ] } } -2s_1 ( \\frac{1}{2 } + \\frac{1}{2 } { { \\left[\\kern-0.5ex{4}\\atop{{\\text{co}}_{1}}\\kern-0.5ex\\right ] } } ) ] \\\\ = & ( -s_1 ^ 2 ) ( { { \\left[\\kern-0.5ex{4}\\atop{{\\text{co}}_{1}}\\kern-0.5ex\\right ] } } -1).\\end{aligned}\\ ] ]    while for @xmath79 we have :    @xmath80 } } ] - 2s_2[s_2 { { \\left[\\kern-0.5ex{4}\\atop{{\\text{co}}_{2}}\\kern-0.5ex\\right ] } } ] + 2s_1 { { \\left[\\kern-0.5ex{2}\\atop{{\\text{co}}_{1}}\\kern-0.5ex\\right ] } } [ s_2 { { \\left[\\kern-0.5ex{2}\\atop{{\\text{co}}_{2}}\\kern-0.5ex\\right ] } } ] \\\\ = & \\underbrace{2c^2 + 4c s_1 { { \\left[\\kern-0.5ex{2}\\atop{{\\text{co}}_{1}}\\kern-0.5ex\\right ] } } } _ { a } + \\underbrace{2{s_1}^2 { { \\left[\\kern-0.5ex{2}\\atop{{\\text{co}}_{1}}\\kern-0.5ex\\right ] } } ^2}_{b } - \\underbrace{2s_2 [ s_2 { { \\left[\\kern-0.5ex{4}\\atop{{\\text{co}}_{2}}\\kern-0.5ex\\right ] } } ] } _ { c}.\\end{aligned}\\ ] ]    with    @xmath81 } } ) \\\\    & = { s_1}^2 + { s_1}^2 { { \\left[\\kern-0.5ex{4}\\atop{{\\text{co}}_{1}}\\kern-0.5ex\\right ] } } , \\end{aligned}\\ ] ]    and    @xmath82 } } { s_2 } { { \\left[\\kern-0.5ex{2}\\atop{{\\text{co}}_{2}}\\kern-0.5ex\\right ] } } - { s_2}^2 ) \\\\    & = 2(2 [ c+s_1 { { \\left[\\kern-0.5ex{2}\\atop{{\\text{co}}_{1}}\\kern-0.5ex\\right ] } } ] ^2 - { s_2}^2 ) \\\\    & = 4c^2 + 2b + 8c s_1 { { \\left[\\kern-0.5ex{2}\\atop{{\\text{co}}_{1}}\\kern-0.5ex\\right ] } } - 2 { s_2}^2 \\\\    & = 4c^2 + 2{s_1}^2 + 2{s_1}^2 { { \\left[\\kern-0.5ex{4}\\atop{{\\text{co}}_{1}}\\kern-0.5ex\\right ] } } + 8 c s_1 { { \\left[\\kern-0.5ex{2}\\atop{{\\text{co}}_{1}}\\kern-0.5ex\\right ] } } - 2 { s_2}^2.\\end{aligned}\\ ] ]    we then reach for @xmath79 the expression :    @xmath83 } } + s_1 { { \\left[\\kern-0.5ex{4}\\atop{{\\text{co}}_{1}}\\kern-0.5ex\\right ] } } ) , \\ ] ]    and consequently that    @xmath84{s } { } } } ] { \\lvert{\\tensor * [ _ { l}]{h } { } } } { } \\rvert } = & [ ( -s_1 ^ 2 ) ( { { \\left[\\kern-0.5ex{4}\\atop{{\\text{co}}_{1}}\\kern-0.5ex\\right ] } } -1 ) ] \\\\",
    "& \\quad[(-2c^2-s_1 ^ 2 + 2s_2 ^ 2 ) - ( -s_1 ) ( 4c { { \\left[\\kern-0.5ex{2}\\atop{{\\text{co}}_{1}}\\kern-0.5ex\\right ] } } + s_1 { { \\left[\\kern-0.5ex{4}\\atop{{\\text{co}}_{1}}\\kern-0.5ex\\right ] } } ) ] .\\end{aligned}\\ ] ]    for @xmath85{s } { } } } ] { \\lvert{\\tensor * [ _ { r}]{h } { } } } { } \\rvert } $ ] on the other hand , we obtain while skipping a number steps the expression    @xmath86 } } ) ^2(s_2 { { \\left[\\kern-0.5ex{2}\\atop{{\\text{si}}_{2}}\\kern-0.5ex\\right ] } } ) ^2 \\\\   = & 2 ( s_1 { { \\left[\\kern-0.5ex{2}\\atop{{\\text{si}}_{1}}\\kern-0.5ex\\right ] } } ) ^2 ( 2s_2 ^ 2-s_2 ^ 2-s_2 ^ 2 { { \\left[\\kern-0.5ex{4}\\atop{{\\text{co}}_{2}}\\kern-0.5ex\\right ] } } ) \\\\   = & s_1 ^ 2(1- { { \\left[\\kern-0.5ex{4}\\atop{{\\text{co}}_{1}}\\kern-0.5ex\\right ] } } ) s_2 ^ 2 ( 1- { { \\left[\\kern-0.5ex{4}\\atop{{\\text{co}}_{2}}\\kern-0.5ex\\right ] } } ) \\\\   = & s_1 ^ 2[1-{\\kern-0.5ex } { { \\left[\\kern-0.5ex{4}\\atop{{\\text{co}}_{1}}\\kern-0.5ex\\right ] } } { \\kern-0.2ex } ] [ ( -2c^2-{\\kern-0.5ex}s_1 ^ 2+{\\kern-0.5ex}2s_2 ^ 2 ) -{\\kern-0.5ex}s_1(4c{\\kern-0.5ex } { { \\left[\\kern-0.5ex{2}\\atop{{\\text{co}}_{1}}\\kern-0.5ex\\right ] } } { \\kern-0.8ex}-s_1{\\kern-0.7ex } { { \\left[\\kern-0.5ex{4}\\atop{{\\text{co}}_{1}}\\kern-0.5ex\\right ] } } ) ] .\\end{aligned}\\ ] ]    a swift comparison show that in fact this is the negative of @xmath85{s } { } } } ] { \\lvert{\\tensor * [ _ { r}]{h } { } } } { } \\rvert } $ ] and therefore    @xmath87{s } { } } } ] { \\lvert{\\tensor * [ _ { } ] { h } { } } } { } \\rvert } = 0.\\ ] ]    the test being inconclusive for our second stationary point set , we seek a different path . since this is a problem with a non - negative objective functions , let us check if there is a relation between the zeros of the objective function and the set at hand .",
    "the zeros of @xmath88 occur at    @xmath89 } } ^2 + w_{12}^2 ] - [ s_2 { { \\left[\\kern-0.5ex{1}\\atop{{\\text{co}}_{2}}\\kern-0.5ex\\right ] } } ^2 + w_{22}^2 ] \\right)^2 = 0 , \\nonumber \\\\ s_1(\\frac{1}{2}+\\frac{1}{2 } { { \\left[\\kern-0.5ex{2}\\atop{{\\text{co}}_{1}}\\kern-0.5ex\\right ] } } + w_{12}^2 = s_2(\\frac{1}{2}+\\frac{1}{2 } { { \\left[\\kern-0.5ex{2}\\atop{{\\text{co}}_{2}}\\kern-0.5ex\\right ] } } + w_{22}^2 , \\nonumber \\\\",
    "\\frac{s_1}{2 } { { \\left[\\kern-0.5ex{2}\\atop{{\\text{co}}_{1}}\\kern-0.5ex\\right ] } } - \\frac{s_2}{2 } { { \\left[\\kern-0.5ex{2}\\atop{{\\text{co}}_{2}}\\kern-0.5ex\\right ] } } = -\\frac{s_1}{2}-w_{12}^2+\\frac{s_2}{2}+w_{22}^2.\\end{aligned}\\ ] ]    multiplying the above by two gives exactly @xmath62{s } { } } $ ] and this confirms that this is a set of minima despite the inconclusive test .",
    "having done this , we proceed to a short study of the solution set s curve .",
    "since the cosine function is even , we notice that the curve must be symmetric about the origin of the @xmath90 plane as well as self - repeating with a period of @xmath91 . therefore to study it we only need to focus on the @xmath92 \\times [ 0,\\pi]$ ] patch of the aforementioned plane . within this patch , when a solution set exists , it is characterized by the monotone nature of @xmath93 since we then have    @xmath94    a canonical form of ( [ eq : np55 ] ) is    @xmath95    since the function is monotone it is sufficient for a qualitative but still exhaustive understanding of it to study its intersections with the lines that delimit the patch .",
    "they are the lines @xmath96 , @xmath97 , @xmath98 and @xmath99 .",
    "for @xmath96 we have an intersection if and only if @xmath100 $ ] has solutions which leads to the condition @xmath101 a similar calculation gives the following set of four individual conditions :    @xmath102    it is not very difficult to see that these conditions can be independent but finding out which combinations of intersections are possible points towards a dull path .",
    "we created a computer script ( using python ) to do the work . with the above conditions labelled as a , c , d , f , the results of the script are that 9 combinations are possible out of the total 16 .",
    "this makes sense since this is the effect of the fact that @xmath103 is positive , allowing only half of the combinations , ignoring the last ` degenerate ' one .",
    "the possible combinations along with witness parameters for @xmath103 and @xmath55 and witness curves are provided in figure ( [ fig : script1 ] )    finally note that a calculus analysis can provide the same result by showing that the slope of the curve within the patch is always positive .",
    "having obtained decent understanding of the single - sample problem and its characterizing solution curves we note that , in the absence of noise , insight into multi - sample problem can be gained by considering superpositions of the curves in the @xmath44 plane for each of the samples .",
    "we have seen that each @xmath62{s } { } } $ ] is symmetric about one of the @xmath53{s } { } } $ ] points . due to this",
    "it becomes relevant to pose the question of existence of samples that have unequal data , equal @xmath53{s } { } } $ ] grids , but different @xmath62{s } { } } $ ] curves .",
    "when such samples intersect within one of the four sectors of a patch around a maximum , they necessarily intersect within all others creating three false minima for each true one .",
    "if additionally the intersection point can be quite arbitrary , the distances between the so obtained minima would be arbitrarily small and this would make the problem ill - posed .",
    "we proceed to find such two samples .",
    "for any two samples @xmath104 and @xmath105 , looking first at @xmath53{s } { } } $ ] , we need @xmath106{r}{_{i } } } } ) = 0 $ ] if and only if @xmath107{r}{_{i } } } } ) = 0 $ ] , which reduces to    @xmath108{w}{_{i{1}}}}{\\tensor[^{\\scriptscriptstyle{a}}]{w}{_{i{3 } } } } } ] } = { \\text{atan}[{\\frac{\\tensor[^{\\scriptscriptstyle{b}}]{w}{_{i{1}}}}{\\tensor[^{\\scriptscriptstyle{b}}]{w}{_{i{3 } } } } } ] } , \\label{eqn : taneq}\\ ] ]    since we write @xmath109 when we really mean @xmath110 , this is equivalent to    @xmath111{w}{_{i{1 } } } } \\atop { \\tensor[^{\\scriptscriptstyle{a}}]{w}{_{i{3 } } } } \\right ) } = \\lambda_i{\\left ( { \\tensor[^{\\scriptscriptstyle{b}}]{w}{_{i{1 } } } } \\atop { \\tensor[^{\\scriptscriptstyle{b}}]{w}{_{i{3 } } } } \\right ) } + 2k_i\\pi,\\quad \\lambda_i > 0 .",
    "\\label{eqn : lbdaeq}\\ ] ]    this is then the condition for two samples to have identical @xmath53{s } { } } $ ] grids . having obtained this , we turn to @xmath62{s } { } } $ ] looking for a family of curves passing through a specific point which we force to lie on the @xmath112 line to simplify finding an explicit example . using the canonical form ( [ eq : s2canon ] )",
    "we have at the common point @xmath113 that    @xmath114    since the point is common to all curves its cosine must be equal in all of them so we have for two samples @xmath104 and @xmath105 that    @xmath115{v } { _ { } } } } { 1- { \\tensor[^{\\scriptscriptstyle{a}}]{u } { _ { } } } } & = \\frac { { \\tensor[^{\\scriptscriptstyle{b}}]{v } { _ { } } } } { 1- { \\tensor[^{\\scriptscriptstyle{b}}]{u } { _ { } } } } .",
    "\\nonumber \\\\ { \\tensor[^{\\scriptscriptstyle{b}}]{u } { _ { } } } & = 1- { \\tensor[^{\\scriptscriptstyle{b}}]{v } { _ { } } } \\left [ \\frac{1 + { \\tensor[^{\\scriptscriptstyle{a}}]{u } { _ { } } } } { { \\tensor[^{\\scriptscriptstyle{a}}]{v } { _ { } } } } \\right ]",
    "\\label{eqn : note122pp}.\\end{aligned}\\ ] ]    going back to the original form ( [ eq : np55 ] ) and baking in the condition ( [ eqn : lbdaeq ] ) ( while dropping the @xmath91 period since we are working within one patch ) we have the two relations :    @xmath116{v } { _ { } } } & = -1 + \\left(\\frac{{\\lambda_2}^2}{{\\lambda_1}^2}\\right)\\frac { { \\tensor[^{\\scriptscriptstyle{b}}]{s}{_{2 } } } } { { \\tensor[^{\\scriptscriptstyle{b}}]{s}{_{1 } } } } - \\frac { { \\tensor[^{\\scriptscriptstyle{a}}]{\\beta } { _ { } } } } { ( { \\lambda_1}^2 ) { \\tensor[^{\\scriptscriptstyle{b}}]{s}{_{1 } } } } , \\\\ { \\tensor[^{\\scriptscriptstyle{a}}]{u } { _ { } } } & = \\left(\\frac{{\\lambda_2}^2}{{\\lambda_1}^2}\\right ) \\frac { { \\tensor[^{\\scriptscriptstyle{b}}]{s}{_{2 } } } } { { \\tensor[^{\\scriptscriptstyle{b}}]{s}{_{1 } } } } .\\end{aligned}\\ ] ]    by ( [ eqn : note122pp ] ) we then require the follwing relation between the samples :    @xmath117{s}{_{2 } } } } { { \\tensor[^{\\scriptscriptstyle{b}}]{s}{_{1 } } } } = 1- \\left[\\frac { -1 + \\frac { { \\tensor[^{\\scriptscriptstyle{b}}]{s}{_{2 } } } } { { \\tensor[^{\\scriptscriptstyle{b}}]{s}{_{1 } } } } - \\frac { { \\tensor[^{\\scriptscriptstyle{b}}]{\\beta } { _ { } } } } { { { \\tensor[^{\\scriptscriptstyle{b}}]{s}{_{1 } } } } } } { -1 + \\left(\\frac{{\\lambda_2}^2}{{\\lambda_1}^2}\\right)\\frac { { \\tensor[^{\\scriptscriptstyle{b}}]{s}{_{2 } } } } { { \\tensor[^{\\scriptscriptstyle{b}}]{s}{_{1 } } } } - \\frac { { \\tensor[^{\\scriptscriptstyle{a}}]{\\beta } { _ { } } } } { ( { \\lambda_1}^2 ) { \\tensor[^{\\scriptscriptstyle{b}}]{s}{_{1 } } } } } \\right ] \\left [ 1 + \\left(\\frac{{\\lambda_2}^2}{{\\lambda_1}^2}\\right ) \\frac { { \\tensor[^{\\scriptscriptstyle{b}}]{s}{_{2 } } } } { { \\tensor[^{\\scriptscriptstyle{b}}]{s}{_{1 } } } } \\right ] \\label{eqn : note123}\\ ] ]    we denote    @xmath118{s}{_{2 } } } } { { \\tensor[^{\\scriptscriptstyle{b}}]{s}{_{1 } } } } , \\\\ r & = \\frac{{\\lambda_2}^2}{{\\lambda_1}^2},\\end{aligned}\\ ] ]    and tentatively set    @xmath119    which simplifies ( [ eqn : note123 ] ) to    @xmath120{\\beta } { _ { } } } } { { \\tensor[^{\\scriptscriptstyle{b}}]{s}{_{1 } } } } \\right ] \\left[\\frac{{(\\lambda_1}^2 ) { \\tensor[^{\\scriptscriptstyle{b}}]{s}{_{1 } } } } { - { \\tensor[^{\\scriptscriptstyle{a}}]{\\beta } { _ { } } } } \\right]\\ ] ]    again tentatively setting    @xmath121    we obtain    @xmath122{s}{_{1 } } } } { - { \\tensor[^{\\scriptscriptstyle{a}}]{\\beta } { _ { } } } } & = 2\\left[1-\\frac { { \\tensor[^{\\scriptscriptstyle{b}}]{\\beta } { _ { } } } } { { \\tensor[^{\\scriptscriptstyle{b}}]{s}{_{1 } } } } \\right ] , \\\\ { \\tensor[^{\\scriptscriptstyle{b}}]{\\beta } { _ { } } } & = { \\tensor[^{\\scriptscriptstyle{b}}]{s}{_{1 } } } - \\frac{1}{2{\\lambda_1}^2 } { \\tensor[^{\\scriptscriptstyle{a}}]{\\beta } { _ { } } } .\\end{aligned}\\ ] ]    to finally obtain our example we set    @xmath123{s}{_{1 } } } & = 4,\\\\ { \\lambda_1}^2 & = 4,\\\\ { \\tensor[^{\\scriptscriptstyle{a}}]{\\beta } { _ { } } } & = 4,\\\\ { \\lambda_2}^2 & = 2,\\\\\\end{aligned}\\ ] ]    this determines the two samples almost completely and by inspection we set    @xmath124{w}{_{22 } } } = { \\tensor[^{\\scriptscriptstyle{b}}]{w}{_{22 } } } = 0,\\ ] ]    to make the samples valid viz .",
    "satisfy ( [ eqn : note49 ] ) .",
    "the samples are then    @xmath116{w}{_{1 } } } , { \\tensor[^{\\scriptscriptstyle{a}}]{w}{_{2 } } } & = ( \\sqrt{12},\\sqrt{2},2),\\,(\\sqrt{2},0,\\sqrt{14 } ) , \\\\ { \\tensor[^{\\scriptscriptstyle{b}}]{w}{_{1 } } } , { \\tensor[^{\\scriptscriptstyle{b}}]{w}{_{2 } } } & = ( \\sqrt{3},\\sqrt{\\frac{7}{4}},1),\\,(1,0,\\sqrt{7 } ) , \\\\\\end{aligned}\\ ] ]    and the ensuing skinned cat figure ( [ fig : script2 ] ) confirms the result .    despite the barbarism of the attempt",
    ", we easily found our example .",
    "this indicates that a continuum of such curves almost certainly exists but we leave a proof of this as subject for further work .",
    "thence , we have shown that the problem is from the point of view of unique solutions , ill - posed or more exactly , only conditionally well - posed .",
    "very few sentences are used in ( seel , schauer , and raisch 2012 ) to explain the derivation of the objective function .",
    "we here attempt an explanation with the following intuitive perspective .",
    "consider a canonical hinge setup .",
    "it naturally leads to conceptually thinking of the whole three - dimensional space as the union of two .",
    "the ` hinge plane ' that is orthogonal to the hinge axis and in which the constrained bodies canonically lie , and it s complement .",
    "the part of the angular velocities that determine the planar rotation within the hinge plane is given by projecting them onto the hinge axis .",
    "this exhausts the hinge s single degree of freedom .",
    "the projection rests ( also called rejections ) must therefore be equal .",
    "another way to think about this is that any difference in the rejections would ` break ' the plane for the two canonical bodies would rotate such that they would not anymore lie in a common plane . by known vector projection and rejection formulas , with @xmath125 being the unit hinge axis , @xmath126 the hinge angle and @xmath127 being the angular velocities , we have :    @xmath128{w}{_{i } } } } + \\underbrace{a \\times ( w_i \\times a ) } _ { { \\tensor [ _ { \\perp}]{w}{_{i } } } } . \\\\ { \\tensor [ _ { \\parallel}]{w}{_{2 } } } - { \\tensor [ _ { \\parallel}]{w}{_{1 } } } = \\dot{\\theta}a . \\\\ { \\tensor [ _ { \\perp}]{w}{_{2 } } } - { \\tensor [ _ { \\perp}]{w}{_{1 } } } = 0 . \\end{split}\\ ] ]    all of this holding in any space",
    ", our objective function simply expresses the equality of rejections in two unknown spaces .",
    "since the spaces are unknown , the magnitude of both vectors is taken and the spaces that make the equality hold determine the sought for transformations .",
    "seel , thomas , thomas schauer , and jrg raisch . 2012 .",
    "`` joint axis and position estimation from inertial measurement data by exploiting kinematic constraints . '' in _ control applications ( cca ) , 2012 ieee international conference on _ , 4549 ."
  ],
  "abstract_text": [
    "<S> this paper is essentially an exercise in studying the minima of a certain least squares optimization using the second partial derivative test . </S>",
    "<S> the motivation is to gain insight into an optimization - based solution to the problem of tracking human limbs using imu sensors . </S>"
  ]
}