{
  "article_text": [
    "surface fit using two - variable orthogonal polynomials has reasonable advantages.@xmath0}$ ] one among many is not necessary to solve a normal equation which is probably ill - conditioned .",
    "a second one usually mentioned in literatures is that , the coefficients of orthogonal polynomials in the fitting expression do not depend on those of preceding polynomials .",
    "hence , fit with two - variable orthogonal polynomials has been widely used in the field such as image processing . while applying it to magnetization data , another advantage that might be worth mentioning but rarely mentioned",
    "is rooted in physics . when pressure in the sample chamber does not change , magnetization of the sample , @xmath1 , as one of the thermodynamic functions , can be completely determined as a function of two independent parameters , magnetic field @xmath2 and temperature @xmath3 .",
    "application of this method to magnetization data is not new .",
    "for example , a two - step category has been employed to fit the magnetization data of gadolinium , and the fitting expression is subsequently used to estimate the corresponding magnetic entropy change.@xmath4}$ ] the main features of our method are as follow .",
    "firstly , in recursively generating orthogonal polynomials with classical or modified gram - schmidt schemes , orthogonality of the polynomials will progressively deteriorate .",
    "so an iterating scheme is selected in order to preserve the orthogonality .",
    "( generally speaking , as has been pointed out before , one more orthogonalization process is sufficient to significantly improve the orthogonality . )    secondly , a regularization method is introduced . in previous fittings to magnetization data , the overfitting problem has rarely been taken into account .",
    "the reason for this probably originates in that not very - high - order polynomials are included in the final fitting expression .",
    "however , our numerical results suggest that fluctuations indeed appear between experimentally recorded data , and such fluctuations become even severer near to the boundaries .",
    "so , we are convinced that overfitting occurs and has to be addressed .",
    "that s why the regularization scheme is introduced to relieve the probable overfitting .",
    "although the specific formulations are different , the present idea of regularization is similar to that used in reference,@xmath5}$ ] which uses gridding and interpolation to obtain the normal equation to be solved .",
    "thirdly , a cross - validation scheme is employed to select out the proper regularization parameter .",
    "the main idea is to divide the experimentally recorded data into three groups , namely , the training , cross - validation , and test groups . among them ,",
    "the training group includes the most elements , and the other two have less data . for each of different regularization parameters , use the training group to generate orthogonal polynomials and determine the unknowns in the fitting expression by minimizing training error ;",
    "apply the cross - validation group to selecting out the optimal regularization parameter that corresponds to the minimum of cross - validation error ; and assess the applicability of the determined expression by computing test error . for orthogonal polynomials",
    "fitting , it s found that the common cross - validation method can not efficiently select out the proper regularization parameter . to overcome this problem , the concept of overfitting degree",
    "is introduced and used to monitor fitting performance .",
    "fourthly , two methods to implement sampling are provided . in principle , a good fitting expression should not be affected by the sample method to obtain the training group . however , our results show an apparent difference in the cross - validation performance , which is associated with the sampling with respect to magnetic field or temperature .",
    "the reason for the different performance is attributed to the ( dimensionless and size - normalized ) averaged increment of recorded magnetic fields unequal to that of recorded temperatures within the experimental measurement range .",
    "fifthly , an extended - precision version of the algorithm is used . on completely determining the fitting expression ,",
    "the magnetization at particular magnetic field and temperature calculated from the orthogonal polynomials , should not be different from the value estimated from the linearly independent functions , which are used to generate those orthogonal polynomials .",
    "however , in performing a double - precision version of the algorithm , we noticed in practice that the values obtained by the two methods are actually different .",
    "so , during recursively computing the values of linearly independent functions and subsequently generating orthogonal polynomials , the error accumulation is significant .",
    "that s why we implement the algorithm at an extended - precision level in spite of more computational time .",
    "sixthly , an equally - spaced distribution of both @xmath6 and @xmath7 is not a prerequisite to fit the magnetization data @xmath8 . in principle , our method is also suitable for magnetization data randomly distributed over the @xmath2-@xmath3 plane .    finally , after obtaining the fitting expression , it s ready to estimate the magnetocaloric quantities at arbitrary magnetic field and temperature within the measuring range , and comprehensively investigate magnetic - phase - transition properties including the order of transition , critical exponents , anomalous specific heat , and so forth .",
    "the rest of this paper is organized as follows : next section provides the general formulations and key algorithms used in this work ; section 3 applies the algorithm to magnetization data ; and conclusions are put in section 4 .",
    "following formulations are quite general and not restricted to magnetization data .",
    "so the experimental data are denoted by as @xmath9 , @xmath10 and @xmath11 instead of @xmath6 , @xmath12 and @xmath13 .      for experimental data",
    "@xmath14 with @xmath15 , two - variable orthogonal polynomials @xmath16 are defined as satisfy    @xmath17    where , @xmath18 is the kronecker @xmath19-symbol . by using the gram - schmidt orthogonalization process ( classical or modified scheme ) to the linearly independent functions",
    "@xmath20 with integer numbers @xmath21 .",
    "@xmath16 can be recursively generated as follows @xmath22 in above expression , @xmath23 is the largest index of the generated orthogonal polynomials .",
    "it is smaller than or equal to the number of created linear independent function @xmath24 .",
    "if we assign @xmath25 , coefficients @xmath26 and @xmath27 @xmath28 are determined as @xmath29 @xmath30    note that the orthogonal polynomials defined above are not normalized .",
    "the normalized version can be conveniently obtained through dividing coefficients @xmath27 @xmath31 by @xmath32-norm @xmath33^{1/2}$ ] as @xmath34^{-1 } , \\label{e3}\\ ] ] @xmath35      after the orthogonal polynomials are obtained , we can expand the fitting expression @xmath36 with @xmath37 as    @xmath38    where @xmath39 denotes the maximum index of orthogonal polynomials used in the fitting expression . by minimizing fitting error @xmath40 ^ 2 \\label{sigma1}\\ ] ] the coefficient of normalized orthogonal polynomials in the fitting expression",
    "is determined as @xmath41      using above orthogonalization processes , it s found that orthogonality becomes poorer and poorer .",
    "although it s better than the the classical ( cgs ) scheme , performance of the modified gram - schmidt ( mgs ) scheme unavoidably becomes poor with increasing the largest index of orthogonal polynomials , @xmath23 . since the orthogonality is closely related to fitting precision , we use the following iterating scheme ( igs ) to improve the orthogonality .",
    "* step 1 * recursively compute the values of linearly independent functions @xmath42 ( @xmath43 ; @xmath44 ) .",
    "( assume that the first @xmath45 polynomials @xmath46 with @xmath47 have been orthonormalized and assigned to @xmath48 with @xmath47 . estimate the value of the @xmath49-th orthonormalized polynomial @xmath50 and assign it to @xmath51 ; and save coefficients @xmath52 with @xmath53 and @xmath54 . )    * step 2 * re - orthogonalize @xmath51 and update @xmath55 .",
    "( 2-a ) compute the modification coefficient @xmath56 , @xmath57 ;    ( 2-b ) re - orthogonalize @xmath58 ;    ( 2-c ) update coefficients @xmath59 , @xmath60 ;    ( 2-d ) judge whether the orthogonality criterion is satisfied .",
    "if true then continue ; else go back to ( 2-a ) .",
    "* step 3 * normalize @xmath51 and update @xmath55 .",
    "( 3-a ) compute the 2-norm @xmath61 ;    ( 3-b ) normalize @xmath51 as @xmath62 ;    ( 3-c ) update coefficients @xmath63 ;    ( 3-d ) update coefficients @xmath64 , @xmath60 .",
    "* step 4 * compute coefficients of @xmath51 in the fitting expression @xmath65 .    * step 5 * judge whether fitting precision matches the criterion .",
    "if true then @xmath66 and break out the loop ; else continue .",
    "* step 6 * subtract the projection of @xmath48 from @xmath51 and update @xmath55 .",
    "( 6-a ) compute the coefficients of subsequent orthogonal polynomials @xmath67 , @xmath68 ;    ( 6-b ) subtract the projection of @xmath48 from @xmath51 @xmath69 , @xmath68 .",
    "* step 7 * update @xmath45 and go back to * step 2*.      if the largest index @xmath23 is not a big number , then the changing tendency of experimental data can not be properly reflected . now fitting error is large and underfitting happens . for decreasing fitting error ,",
    "more orthogonal polynomials are successively generated and added to the fitting expression until the wished precision is achieved .",
    "( the more orthogonal polynomials , the higher fitting precision . )",
    "however , too many polynomials will lead to strong local fluctuations in the fitted surface , and overfitting happens .",
    "the reason for this is that higher - order polynomials generally imply more inflection points .",
    "the degree of overfitting can be controlled by regularization like adding so - called penalty functions into the error expression , in order to strengthen the stiffness of fitted surfaces .",
    "in contrast to the method of using penalty functions , we implement the regularization by adding a laplace term to the error expression . in essence",
    ", the laplace method aims at suppressing the changing rate of curve slope . after adding a laplace term    @xmath70    with regularization parameter @xmath71 , the error expression ( [ sigma1 ] )",
    "is rewritten as    @xmath72 ^ 2 + \\lambda   \\left [ \\nabla^{2 } f(x_{i},y_{i } ) \\right]^2.\\label{sigma2}\\ ] ]    it s easy to see that the laplace term in ( [ sigma2 ] ) affects only coefficients @xmath73 . by minimizing ( [ sigma2 ] )",
    ", it is obtained that    @xmath74    where ,    @xmath75    with @xmath76 .",
    "we next examine whether the laplace method above really leads to regularization .",
    "firstly , when @xmath77 , equation([bt2 ] ) reduces to the non - regularized case ( [ bt1 ] ) . secondly , if @xmath78 , the laplace term has no contribution to @xmath73 since @xmath79 ( corresponding to linear fitting ) .",
    "thirdly , the laplace term starts to play its role when @xmath80 .",
    "if @xmath71 is large enough so that equations ( [ a1 ] ) and ( [ a2 ] ) are satisfied ,    @xmath81    then @xmath73 reduces to    @xmath82    namely , @xmath83    if we assume that @xmath84 when @xmath85 , then @xmath86 , which implies that @xmath87 since @xmath88 . hence , the laplace term introduced above makes @xmath73 rapidly decay with increasing @xmath89 , so that overfitting is avoided and regularization is realized .",
    "now , we invoke a cross - validation process to select out a proper regularization parameter @xmath71 .",
    "dividing the whole data into three groups , one of which includes much more data , labelled `` training group '' , and the other two has fewer data , labelled  cross - validation group \" and  test group \" , respectively . for each fixed value of @xmath71",
    ", the training group is used to determine coefficient @xmath90 by minimizing @xmath91 in ( [ sigma2 ] ) , and the corresponding training error is computed as    @xmath92 ^ 2 .",
    "\\label{err_tr}\\ ] ]    subsequently , the cross - validation group selects out the value of @xmath71 that minimizes the cross - validation error    @xmath93 ^ 2 .",
    "\\label{err_cv}\\ ] ]    finally , the test group assesses the applicability of the determined fitting expression by calculating the test error @xmath94 ^ 2.\\ ] ]    in contrast to the ordinary scheme used in the field such as machine learning , the model used here has two parameters that require determining , namely , the number of orthogonal polynomials @xmath23 and the regularization parameter @xmath71 .    by setting certain routine - terminating criterion , the optimal choice of @xmath23 can be determined by minimizing the training error @xmath95 .",
    "a useful criterion can be defined by assessing the changing tendency of fitting error .",
    "for example , on increasing @xmath23 from @xmath96 , if the fitting error is not apparently decreased , it is reasonable to consider @xmath96 to be the optimal value of @xmath23 .",
    "another task is to determine parameter @xmath71 . practically , we find that both @xmath95 and @xmath97 decrease with enlarging s at fixed @xmath71 or with increasing @xmath71 at fixed @xmath23 .",
    "thus , the optimal value of @xmath71 can not be identified to the one that minimizes @xmath97 .",
    "this motivates us to construct a new quantity to characterize the degree of overfitting ( and also underfitting ) .",
    "typically , when @xmath97 is approximately equal to @xmath95 , underfitting happens ; if @xmath97 is much larger than @xmath95 , overfitting occurs .",
    "we can define overfitting degree @xmath98 as @xmath99 it is identified as underfitting if @xmath100 , and overfitting when @xmath101 .",
    "it s noticed that the calculated value of fitting error depends on the measurement unit used for experimentally recorded data @xmath102 @xmath103 where @xmath104 $ ] , @xmath105 $ ] , and @xmath106 $ ] .",
    "for comparison purposes , we do size normalization as follow @xmath107 where , @xmath108 $ ] .",
    "hence , the fitting error is calculated from the after - transformed data . with an inverse transformation ,",
    "the physical quantities are obtained in the measurement unit .      in dividing the experimental data into three groups ,",
    "a uniform sampling algorithm is executed in order to optimize fitting performance .",
    "original experimental data are firstly sorted in terms of a sample parameter , @xmath109 or @xmath110 .",
    "then the uniform sample is executed on a pro - rata basis , which is regulated by the sampling factor , and the sorted data are put into the training , cross - validation , and test groups according to the sampling factor .",
    "numerical results show that difference appears between different sampling methods , which is attributed to the different data density along @xmath109 axis with that along @xmath110 axis .",
    "after coefficients @xmath27 and @xmath90 being determined , the functional value at arbitrary location @xmath112 within the measuring range can be estimated in a similar way to that used in the fitting routine .",
    "another method is to estimate from linearly independent functions as @xmath113 where @xmath114 is the coefficient of the @xmath89-th linearly independent functions in the fitting expression , and can be readily calculated from @xmath115 and @xmath73 .",
    "the latter scheme is recommended for lower computation cost .",
    "practically , in implementing a double - precision version of the algorithm , it s found that the fitting value calculated from linearly independent functions significantly differs from that computed from orthogonal polynomials , when the power exponent of the fitting expression is very high .",
    "after an extended - precision algorithm is applied , the difference decreases .",
    "if the extended - precision operation is also used to recursively generate linearly independent functions , the difference is not longer obvious .",
    "these facts suggest that round - off error is rapidly accumulated while recursively computing the linearly independent functions .",
    "hence , it is required to carefully consider the influence of error accumulations in fitting using two - variable orthogonal polynomials .",
    "since the fitting expression is essentially the linear combination linearly independent functions @xmath116 , utilizing recursive properties of the corresponding partial derivative and integral , it s quite convenient to compute the physical quantities of interest .",
    "followings are typical recursive algorithms at given @xmath117 and @xmath118 used in this work .",
    "@xmath120      @xmath122      @xmath124",
    "the formula given above are quite general . for application to magnetization data ,",
    "it s only needed to replace @xmath109 , @xmath110 , @xmath125 and their corresponding size normalizations with @xmath2 , @xmath3 , @xmath1 and @xmath126 , @xmath127 , @xmath128 . here",
    ", we fit the magnetization data of polycrystalline samples la@xmath129sr@xmath130mn@xmath131o@xmath132 obtained with physical property measurement system ( ppms ) of quantum design company .",
    "more details can be found in reference .",
    "@xmath133}$ ]      the total number of data used is @xmath134 .",
    "with one half of the data ( @xmath135 ) uses as the training group , the fitting results are shown in fig .",
    "1 . note that satisfactory fitting precision can be reached using two - variable orthogonal polynomials .",
    "however , one can not assess the degree of overfitting from the fitting precision , which suggests the necessity to introduce cross - validation .",
    "the whole data are uniformly sampled according to temperature and the sampling factor is set to @xmath136 , namely , two thirds of the data being put into the training group , half of the rest one third into the cross - validation group and half into the test group . by setting regularization parameter @xmath77 , we discuss the effect of the number of orthogonal polynomials ( @xmath23 ) on fitting performance .",
    "the calculated results are shown in table 1 . for reference",
    ", the overfitting degree corresponding to the test error is defined in a similar way with that in ( [ overfit1 ] ) @xmath137 it noted that both @xmath98 and @xmath138 reflect fitting performance , since the data in the cross - validation and test groups can be interchanged .",
    "with increasing @xmath23 , fitting error decreases and overfitting degree increases , which suggests that the overfitting degree can be used to monitor fitting performance , although it can not always select out the optimal regularization parameter .",
    "fitting errors and overfitting degrees without regularization ( @xmath139 ) . for comparison , the training error with @xmath140 ( i.e.",
    ", only @xmath141 is used ) is @xmath142 .    [ cols=\"^,^,^,^,^,^\",options=\"header \" , ]     table 3 summarizes the optimal fitting precision and corresponding overfitting degrees with different regularization parameter @xmath71 .",
    "the sampling factor is the same to preceding tables .",
    "it s noted that overfitting begins to occur at @xmath143 .",
    "since the cross - validation and test group can interchange data , one needs to compare @xmath98 with @xmath138 in order to select out the proper @xmath71 .",
    "here we discuss aspects that have not been mentioned above .",
    "first of all , the algorithm in this paper can be further optimized so that the computing efficiency is increased and memory decreased .",
    "for example , in the re - orthogonalization step of iterating orthogonalization , the projection of the just orthogonalized polynomial is subtracted from all those subsequent polynomials which are not orthogonalized yet ; this definitely increases the the computing cost since redundant polynomials are generated to ensure the fitting precision .    secondly ,",
    "if only physical quantities that are at experimental - recorded magnetic fields and temperatures are concerned , the computing results for the linearly independent functions and orthogonal polynomials used to fit can be saved to compute these physical quantities .",
    "thirdly , after the fitting expression obtained , uniform gridding and interpolation of the data can be readily achieved .",
    "thus , besides the iterative method used in this work , operations like numerical derivatives and integrals can be easily executed .",
    "fourthly , when the coefficients of linear independent functions in orthogonal polynomials and those of the orthogonal polynomials in the fitting expression are computed , we have not considered the effect of measuring errors .",
    "however , the measuring error is always there .",
    "what s more , the measuring error of experimental data at extremely weak field is usually bigger .",
    "because we have taken into accounted all experimental data with equal weight , the measuring error under weak field will do harm to global fitting performance . to solve this problem ,",
    "one method is to abandon the data under weak field ; another method is to introduce a local weight factor that depends on magnetic field and temperature so that the influence of experimental data is confined within a nearby area .",
    "fifthly , it s noted that in above fitting , rotational symmetry of magnetic systems has not been considered .",
    "because of this symmetry , the terms involving even - number powers of magnetic field should not appear in the analytic expression of magnetization .",
    "while talking about the properties closely associated with this symmetry , it needs eliminating such terms in the set of linearly independent functions .",
    "finally , since the algorithm considers only the dependence on magnetic field and temperature , the effect of other processes such as rotation of crystal grains and the change of sample volume are not adequate disclosed , that may be the reason for larger fitting error at weak fields .",
    "another issue not considered here is the influence of demagnetization factor whose value in polycrystalline materials is hard computed .",
    "to conclude , by adding the laplace term into the fitting error expression , the regularization method and corresponding cross - validation scheme are introduced to two - variable orthogonal polynomials fitting . after applying to magnetization data",
    ", it s found that the regularization scheme does play its role through rapidly suppressing the coefficients of higher - order terms in the fitting expression and therefore effectively relieving the overfitting problem . with the aid of the concept of overfitting degree , it s also shown that the cross validation scheme can be used to select out the proper regularization parameter .",
    "the influences of sampling parameter and sampling factor are also analysed .",
    "thus it offers the quite reliable base for the following investigations of the magnetic - entropy - change and phase - transition properties of magnetic functional materials .",
    "i would thank wu hong - ye for many helps in software usage and constructive discussions in developing the method in this work . and",
    "my thanks also give to wu ke - han and zhou min for providing experimental data before their paper published .",
    "leon s j , bjrck and gander w 2012 _ numer .",
    "linear algebra appl . _ * 20 * 492 - 532 li z t , wu p f , tao y q and mao d k 1999 _ acta phys . sin . _ * 48(s ) * s126 ( in chinese ) derrico j r 2006 _ understanding gridfit_. available : + http://www.mathworks.com/matlabcentral/fileexchange/8998-surface-fitting-using-gridfit .",
    "wu k h , wan s l , xu b , liu s b , zhao j j and lu y , to be published ."
  ],
  "abstract_text": [
    "<S> an obstacle encountered in applying orthogonal - polynomials fitting is how to select out the proper fitting expression . by adding a laplace term to the error expression and introducing the concept of overfitting degree , a regularization and corresponding cross validation scheme is proposed for two - variable polynomials fitting . </S>",
    "<S> while the fortran implementation of above scheme is applied to magnetization data , a satisfactory fitting precision is reached , and overfitting problem can be quantitatively assessed , which therefore offers the quite reliable base for future comprehensive investigations of magnetocaloric and phase - transition properties of magnetic functional materials . </S>"
  ]
}