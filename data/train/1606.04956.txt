{
  "article_text": [
    "several rich strands of work in the behavioral sciences have been concerned with characterizing the nature and sources of human error .",
    "these include the broad of notion of _ bounded rationality _ @xcite and the subsequent research beginning with kahneman and tversky on heuristics and biases @xcite . with the growing availability of large datasets containing millions of human decisions on fixed , well - defined , real - world tasks",
    ", there is an interesting opportunity to add a new style of inquiry to this research  given a large stream of decisions , with rich information about the context of each decision , can we algorithmically characterize and predict the instances on which people are likely to make errors ?",
    "this genre of question  analyzing human errors from large traces of decisions on a fixed task  also has an interesting relation to the canonical set - up in machine learning applications .",
    "typically , using instances of decision problems together with `` ground truth '' showing the correct decision , an algorithm is trained to produce the correct decisions in a large fraction of instances .",
    "the analysis of human error , on the other hand , represents a twist on this formulation : given instances of a task in which we have both the correct decision _ and _ a human s decision , the algorithm is trained to recognize future instances on which the human is likely to make a mistake .",
    "predicting human error from this type of trace data has a history in human factors research @xcite , and a nascent line of work has begun to apply current machine - learning methods to the question @xcite .",
    "[ [ model - systems - for - studying - human - error ] ] * model systems for studying human error * + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    as the investigation of human error using large datasets grows increasingly feasible , it becomes useful to understand which styles of analysis will be most effective .",
    "for this purpose , as in other settings , there is enormous value in focusing on model systems where one has exactly the data necessary to ask the basic questions in their most natural formulations .",
    "what might we want from such a model system ?",
    "* it should consist of a task for which the context of the human decisions has been measured as thoroughly as possible , and in a very large number of instances , to provide the training data for an algorithm to analyze errors .",
    "* so that the task is non - trivial , it should be challenging even for highly skilled human decision - makers . * notwithstanding the previous point ( ii ) , the `` ground truth ''  the correctness of each candidate decision  should be feasibly computable by an algorithm .",
    "guided by these desiderata , we focus in this paper on chess as a model system for our analysis . in doing so",
    ", we are proceeding by analogy with a long line of work in behavioral science using chess as a model for human decision - making @xcite .",
    "chess is a natural domain for such investigations , since it presents a human player with a sequence of concrete decisions  which move to play next  with the property that some choices are better than others . indeed , because chess provides data on hard decision problems in such a pure fashion , it has been described as the `` drosophila of psychology '' @xcite .",
    "( it is worth noting our focus here on _ human _ decisions in chess , rather than on designing algorithms to play chess @xcite .",
    "this latter problem has also , of course , generated a rich literature , along with a closely related tag - line as the `` drosophila of artificial intelligence '' @xcite . )",
    "[ [ chess - as - a - model - system - for - human - error ] ] * chess as a model system for human error * + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    despite the clean formulation of the decisions made by human chess players , we still must resolve a set of conceptual challenges if our goal is to assemble a large corpus of chess moves with ground - truth labels that classify certain moves as errors . let us consider three initial ideas for how we might go about this , each of which is lacking in some crucial respect for our purposes .",
    "first , for most of the history of human decision - making research on chess , the emphasis has been on focused laboratory studies at small scales in which the correct decision could be controlled by design @xcite . in our list of desiderata , this means that point ( iii ) , the availability of ground truth , is well under control , but a significant aspect of point ( i )  the availability of a vast number of instances  is problematic due to the necessarily small scales of the studies .    a second alternative would be to make use of two important computational developments in chess  the availability of databases with millions of recorded chess games by strong players ; and the fact that the strongest chess programs  generally referred to as _ chess engines _  now greatly outperform even the best human players in the world .",
    "this makes it possible to analyze the moves of strong human players , in a large - scale fashion , comparing their choices to those of an engine .",
    "this has been pursued very effectively in the last several years by biswas and regan @xcite ; they have used the approach to derive interesting insights including proposals for how to estimate the depth at which human players are analyzing a position .    for the current purpose of assembling a corpus with ground - truth error labels , however , engines present a set of challenges .",
    "the basic difficulty is that even current chess engines are far from being able to provide guarantees regarding the best move(s ) in a given position . in particular ,",
    "an engine may prefer move @xmath0 to @xmath1 in a given position , supplementing this preference with a heuristic numerical evaluation , but @xmath1 may ultimately lead to the same result in the game , both under best play and under typical play . in these cases , it is hard to say that choosing @xmath1 should be labeled an error .",
    "more broadly , it is difficult to find a clear - cut rule mapping an engine s evaluations to a determination of human error , and efforts to label errors this way would represent a complex mixture of the human player s mistakes and the nature of the engine s evaluations .    finally , a third possibility is to go back to the definition of chess as a deterministic game with two players ( white and black ) who engage in alternating moves , and with a game outcome that is either ( a ) a win for white ,",
    "( b ) a win for black , or ( c ) a draw .",
    "this means that from any position , there is a well - defined notion of the outcome with respect to optimal play by both sides  in game - theoretic terms , this is the _ minimax value _ of the position . in each position , it is the case that white wins with best play , or black wins with best play , or it is a draw with best play , and these are the three possible minimax values for the position",
    ".    this perspective provide us with a clean option for formulating the notion of an error , namely the direct game - theoretic definition : a player has committed an error if their move worsens the minimax value from their perspective .",
    "that is , the player had a forced win before making their move but now they do nt ; or the player had a forced draw before making their move but now they do nt .",
    "but there s an obvious difficulty with this route , and it s a computational one : for most chess positions , determining the minimax value is hopelessly beyond the power of both human players and chess engines alike .",
    "we now discuss the approach we take here .",
    "[ [ assessing - errors - using - tablebases ] ] * assessing errors using tablebases * + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    in our work , we use minimax values by leveraging a further development in computer chess  the fact that chess has been solved for all positions with at most @xmath2 pieces on the board , for small values of @xmath2 @xcite .",
    "( we will refer to such positions as _",
    "@xmath3@xmath2-piece positions_. ) solving these positions has been accomplished not by forward construction of the chess game tree , but instead by simply working backward from terminal positions with a concrete outcome present on the board and filling in all other minimax values by dynamic programming until all possible @xmath3@xmath2-piece positions have been enumerated .",
    "the resulting solution for all @xmath3@xmath2-piece positions is compiled into an object called a _",
    "@xmath2-piece tablebase _ , which lists the game outcome with best play for each of these positions .",
    "the construction of tablebases has been a topic of interest since the early days of computer chess @xcite , but only with recent developments in computing and storage have truly large tablebases been feasible .",
    "proprietary tablebases with @xmath4 have been built , requiring in excess of a hundred terabytes of storage @xcite ; tablebases for @xmath5 are much more manageable , though still very large @xcite , and we focus on the case of @xmath5 in what follows .    tablebases and traditional chess engines are thus very different objects .",
    "chess engines produce strong moves for arbitrary positions , but with no absolute guarantees on move quality in most cases ; tablebases , on the other hand , play perfectly with respect to the game tree  indeed , effortlessly , via table lookup  for the subset of chess containing at most @xmath2 pieces on the board .",
    "thus , for arbitrary @xmath3@xmath2-piece positions , we can determine minimax values , and so we can obtain a large corpus of chess moves with ground - truth error labels : starting with a large database of recorded chess games , we first restrict to the subset of @xmath3@xmath2-piece positions , and then we label a move as an error if and only it worsens the minimax value from the perspective of the player making the move . adapting chess terminology to the current setting , we will refer to such an instance as a _",
    "blunder_.    this is our model system for analyzing human error ; let us now check how it lines up with desiderata ( i)-(iii ) for a model system listed above .",
    "chess positions with at most @xmath5 pieces arise relatively frequently in real games , so we are left with many instances even after filtering a database of games to restrict to only these positions ( point ( i ) ) . crucially , despite their simple structure",
    ", they can induce high error rates by amateurs and non - trivial error rates even by the best players in the world ; in recognition of the inherent challenge they contain , textbook - level treatments of chess devote a significant fraction of their attention to these positions @xcite ( point ( ii ) ) . and",
    "they can be evaluated perfectly by tablebases ( point ( iii ) ) .",
    "focusing on @xmath3@xmath2-piece positions has an additional benefit , made possible by a combination of tablebases and the recent availability of databases with millions of recorded chess games .",
    "the most frequently - occurring of these positions arise in our data thousands of times .",
    "as we will see , this means that for some of our analyses , we can control for the exact position on the board and still have enough instances to observe meaningful variation .",
    "controlling for the exact position is not generally feasible with arbitrary positions arising in the middle of a chess game , but it becomes possible with the scale of data we now have , and we will see that in this case it yields interesting and in some cases surprising insights .    finally , we note that our definition of blunders , while concrete and precisely aligned with the minimax value of the game tree , is not the only definition that could be considered even using tablebase evaluations",
    ". in particular , it would also be possible to consider `` softer '' notions of blunders .",
    "suppose for example that a player is choosing between moves @xmath0 and @xmath1 , each leading to a position whose minimax value is a draw , but suppose that the position arising after @xmath0 is more difficult for the opponent , and produces a much higher empirical probability that the opponent will make a mistake at some future point and lose .",
    "then it can be viewed as a kind of blunder , given these empirical probabilities , to play @xmath1 rather than the more challenging @xmath0 .",
    "this is sometimes termed _ speculative play _",
    "@xcite , and it can be thought of primarily as a refinement of the coarser minimax value .",
    "this is an interesting extension , but for our work here we focus on the purer notion of blunders based on the minimax value .",
    "in formulating our analysis , we begin from the premise that for analyzing error in human decisions , three crucial types of features are the following :    * the skill of the decision - maker ; * the time available to make the decision ; and * the inherent difficulty of the decision .    any instance of the problem will implicitly or explicitly contain features of all three types : an individual of a particular level of skill is confronting a decision of a particular difficulty , with a given amount of time available to make the decision .    in our current domain , as in any other setting where the question of human error is relevant , there are a number of basic genres of question that we would like to ask .",
    "these include the following .",
    "* for predicting whether an error will be committed in a given instance , which types of features ( skill , time , or difficulty ) yield the most predictive power ? * in which kinds of instances does greater skill confer the largest relative benefit ? is it for more difficult decisions ( where skill is perhaps most essential ) or for easier ones ( where there is the greatest room to realize the benefit ) ?",
    "are there particular kinds of instances where skill does not in fact confer an appreciable benefit ? * an analogous set of questions for time in place of skill : in which kinds of instances does greater time for the decision confer the largest benefit ? is additional time more beneficial for hard decisions or easy ones ? and are there instances where additional time does not reduce the error rate ? * finally , there are natural questions about the interaction of skill and time : is it higher - skill or lower - skill decision - makers who benefit more from additional time ?",
    "these questions motivate our analyses in the subsequent sections .",
    "we begin by discussing how features of all three types ( skill , time , and difficulty ) are well - represented in our domain .",
    "our data comes from two large databases of recorded chess games .",
    "the first is a corpus of approximately 200 million games from the free internet chess server ( fics ) , where amateurs play each other on - line .",
    "the second is a corpus of approximately 1 million games played in international tournaments by the strongest players in the world .",
    "we will refer to the first of these as the fics dataset , and the second as the gm dataset .",
    "( gm for `` grandmaster , '' the highest title a chess player can hold . ) for each corpus , we extract all occurrences of @xmath3@xmath6-piece positions from all of the games ; we record the move made in the game from each occurrence of each position , and use a tablebase to evaluate all possible moves from the position ( including the move that was made ) .",
    "this forms a single instance for our analysis .",
    "since we are interested in studying errors , we exclude all instances in which the player to move is in a theoretically losing position  where the opponent has a direct path to checkmate  because there are no blunders in losing positions ( the minimax value of the position is already as bad as possible for the player to move ) .",
    "there are 24.6 million ( non - losing ) instances in the fics dataset , and 880,000 in the gm dataset .    we now consider how feature types ( a ) , ( b ) , and ( c ) are associated with each instance .",
    "first , for skill , each chess player in the data has a numerical rating , termed the _ elo rating _ , based on their performance in the games they ve played @xcite .",
    "higher numbers indicate stronger players , and to get a rough sense of the range : most amateurs have ratings in the range 1000 - 2000 , with extremely strong amateurs getting up to 2200 - 2400 ; players above 2500 - 2600 belong to a rarefied group of the world s best ; and at any time there are generally about fewer than five people in the world above 2800 .",
    "if we think of a game outcome in terms of points , with 1 point for a win and 0.5 points for a draw , then the elo rating system has the property that when a player is paired with someone 400 elo points lower , their expected game outcome is approximately @xmath7 points  an enormous advantage . , the expected score for the higher - ranked player under the elo system is @xmath8 . ]    for our purposes , an important feature of elo ratings is the fact that a single number has empirically proven so powerful at predicting performance in chess games .",
    "while ratings clearly can not contain all the information about players strengths and weaknesses , their effectiveness in practice argues that we can reasonably use a player s rating as a single numerical feature that approximately represents their skill .    with respect to temporal information ,",
    "chess games are generally played under time limits of the form , `` play @xmath9 moves in @xmath10 minutes '' or `` play the whole game in @xmath10 minutes . ''",
    "players can choose how they use this time , so on each move they face a genuine decision about how much of their remaining allotted time to spend . the fics dataset contains the amount of time remaining in the game when each move was played ( and hence the amount of time spent on each move as well ) ; most of the games in the fics dataset are played under extremely rapid time limits , with a large fraction of them requiring that the whole game be played in 3 minutes for each player . to avoid variation arising from the game duration ,",
    "we focus on this large subset of the fics data consisting exclusively of games with 3 minutes allocated to each side .",
    "our final set of features will be designed to quantify the difficulty of the position on the board  i.e. the extent to which it is hard to avoid selecting a move that constitutes a blunder .",
    "there are many ways in which one could do this , and we are guided in part by the goal of developing features that are less domain - specific and more applicable to decision tasks in general .",
    "we begin with perhaps the two most basic parameters , analogues of which would be present in any setting with discrete choices and a discrete notion of error  these are the number of legal moves in the position , and the number of these moves that constitute blunders .",
    "later , we will also consider a general family of parameters that involve looking more deeply into the search tree , at moves beyond the immediate move the player is facing .    to summarize , in a single instance in our data , a player of a given rating , with a given amount of time remaining in the game , faces a specific position on the board , and we ask whether the move they select is a blunder .",
    "we now explore how our different types of features provide information about this question , before turning to the general problem of prediction .",
    "we begin by considering a set of basic features that help quantify the difficulty inherent in a position .",
    "there are many features we could imagine employing that are highly domain - specific to chess , but our primary interest is in whether a set of relatively generic features can provide non - trivial predictive value .",
    "above we noted that in any setting with discrete choices , one can always consider the total number of available choices , and partition these into the number that constitute blunders and the number that do not constitute blunders .",
    "in particular , let s say that in a given chess position @xmath11 , there are @xmath12 legal moves available  these are the possible choices  and of these , @xmath13 are blunders , in that they lead to a position with a strictly worse minimax value .",
    "note that it is possible to have @xmath14 , but we exclude these positions because it is impossible to blunder .",
    "also , by the definition of the minimax value , we must have @xmath15 ; that is , there is always at least one move that preserves the minimax value .    , for the fics dataset.,scaledwidth=40.0% ]",
    "a global check of the data reveals an interesting bimodality in both the fics and gm datasets : positions with @xmath16 and positions with @xmath17 are both heavily represented .",
    "the former correspond to positions in which there is a unique blunder , and the latter correspond to positions in which there is a unique correct move to preserve the minimax value .",
    "our results will cover the full range of @xmath18 values , but it is useful to know that both of these extremes are well - represented .",
    "now , let us ask what the empirical blunder rate looks like as a bivariate function of this pair of variables @xmath18 . over all instances in which the underlying position @xmath11 satisfies @xmath19 and @xmath20 , we define @xmath21 to be the fraction of those instances in which the player blunders .",
    "how does the empirical blunder rate vary in @xmath12 and @xmath13 ?",
    "it seems natural to suppose that for fixed @xmath12 , it should generally increase in @xmath13 , since there are more possible blunders to make . on the other hand ,",
    "instances with @xmath17 often correspond to chess positions in which the only non - blunder is `` obvious '' ( for example , if there is only one way to recapture a piece ) , and so one might conjecture that the empirical blunder rate will be lower for this case .    in fact , the empirical blunder rate is generally monotone in @xmath13 , as shown by the heatmap representation of @xmath21 in figure [ fig : blunder - rate - heat - map ] .",
    "( we show the function for the fics data ; the function for the gm data is similar . ) moreover , if we look at the heavily - populated line @xmath17 , the blunder rate is increasing in @xmath12 ; as there are more blunders to compete with the unique non - blunder , it becomes correspondingly harder to make the right choice .",
    "-value defined in section [ subsec : difficulty].,title=\"fig:\",scaledwidth=23.0% ] -value defined in section [ subsec : difficulty].,title=\"fig:\",scaledwidth=23.0% ] + ( a ) gm data + -value defined in section [ subsec : difficulty].,title=\"fig:\",scaledwidth=23.0% ] -value defined in section [ subsec : difficulty].,title=\"fig:\",scaledwidth=23.0% ] + ( b ) fics data    [ [ blunder - potential ] ] * blunder potential * + + + + + + + + + + + + + + + + + + +    given the monotonicity we observe , there is an informative way to combine @xmath12 and @xmath13 : by simply taking their ratio @xmath22 .",
    "this quantity , which we term the _ blunder potential _ of a position @xmath11 and denote @xmath23 , is the answer to the question , `` if the player selects a move uniformly at random , what is the probability that they will blunder ? '' .",
    "this definition will prove useful in many of the analyses to follow .",
    "intuitively , we can think of it as a direct measure of the _ danger _ inherent in a position , since it captures the relative abundance of ways to go wrong .    in figure",
    "[ fig : blunder - rate - blunder - potential ] we plot the function @xmath24 , the proportion of blunders in instances with @xmath25 , for both our gm and fics datasets on linear as well as logarithmic @xmath10-axes .",
    "the striking regularity of the @xmath26 curves shows how strongly the availability of potential mistakes translates into actual errors .",
    "one natural starting point for interpreting this relationship is to note that if players were truly selecting their moves uniformly at random , then these curves would lie along the line @xmath27 .",
    "the fact that they lie below this line indicates that in aggregate players are preferentially selecting non - blunders , as one would expect .",
    "and the fact that the curve for the gm data lies much further below @xmath27 is a reflection of the much greater skill of the players in this dataset , a point that we will return to shortly .",
    "[ [ the - gamma - value ] ] * the @xmath28-value * + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    we find that a surprisingly simple model qualitatively captures the shapes of the curves in figure [ fig : blunder - rate - blunder - potential ] quite well .",
    "suppose that instead of selecting a move uniformly at random , a player selected from a biased distribution in which they were preferentially @xmath29 times more likely to select a non - blunder than a blunder , for a parameter @xmath30 .         if this were the true process for move selection , then the empirical blunder rate of a position @xmath11 would be @xmath31 we will refer to this as the _ @xmath28-value _ of the position @xmath11 , with parameter @xmath29 . using the definition of the blunder potential @xmath23 to write @xmath32",
    ", we can express the @xmath28-value directly as a function of the blunder potential : @xmath33 we can now find the value of @xmath29 for which @xmath34 best approximates the empirical curves in figure [ fig : blunder - rate - blunder - potential ] .",
    "the best - fit values of @xmath29 are @xmath35 for the fics data and @xmath36 for the gm data , again reflecting the skill difference between the two domains .",
    "these curves are shown superimposed on the empirical plot in the figure ( on the right , with logarithmic @xmath10-axes ) .",
    "we note that in game - theoretic terms the @xmath28-value can be viewed as a kind of _ quantal response _",
    "@xcite , in which players in a game select among alternatives with a probability that decreases according to a particular function of the alternative s payoff .",
    "since the minimax value of the position corresponds to the game - theoretic payoff of the game in our case , a selection rule that probabilistically favors non - blunders over blunders can be viewed as following this principle .",
    "( we note that our functional form can not be directly mapped onto standard quantal response formulations .",
    "the standard formulations are strictly monotonically decreasing in payoff , whereas we have cases where two different blunders can move the minimax value by different amounts  in particular , when a win changes to a draw versus a win changes to a loss  and we treat these the same in our simple formulation of the @xmath28-value . )           a key focus in the previous subsection was to understand how the empirical blunder rate varies as a function of parameters of the instance . here",
    "we continue this line of inquiry , with respect to the skill of the player in addition to the difficulty of the position .",
    "recall that a player s _ elo rating _ is a function of the outcomes of the games they ve played , and is effective in practice for predicting the outcomes of a game between two rated players @xcite .",
    "it is for this reason that we use a player s rating as a proxy for their skill .",
    "however , given that ratings are determined by which games a player wins , draws , or loses , rather than by the extent to which they blunder in @xmath3@xmath6-piece positions , a first question is whether the empirical blunder rate in our data shows a clean dependence on rating .",
    "in fact it does .",
    "figure [ fig : blunder - rate - rating ] shows the empirical blunder rate @xmath37 averaged over all instances in which the player has rating @xmath9 .",
    "the blunder rate declines smoothly with rating for both the gm and fics data , with a flattening of the curve at higher ratings .",
    "[ [ the - skill - gradient ] ] * the skill gradient * + + + + + + + + + + + + + + + + + + + +    we can think of the downward slope in figure [ fig : blunder - rate - rating ] as a kind of _ skill gradient _ , showing the reduction in blunder rate as skill increases .",
    "the steeper this reduction is in a given setting , the higher the empirical benefit of skill in reducing error .",
    "it is therefore natural to ask how the skill gradient varies across different conditions in our data .",
    "as a first way to address this , we take each possible value of the blunder potential @xmath38 ( rounded to the nearest multiple of @xmath39 ) , and define the function @xmath40 to be the empirical error rate of players of rating @xmath9 in positions of blunder potential @xmath38 .",
    "figure [ fig : blunder - rate - potential - rating ] shows plots of these curves for @xmath38 equal to each multiple of @xmath39 , for both the gm and fics datasets .",
    ".,scaledwidth=48.0% ]     +    we observe two properties of these curves .",
    "first , there is remarkably little variation among the curves .",
    "when viewed on a logarithmic y - axis the curves are almost completely parallel , indicating the same rate of proportional decrease across all blunder potentials .    a second , arguably more striking",
    ", property is how little the curves overlap in their ranges of @xmath10-values . in effect , the curves form a kind of `` ladder '' based on blunder potential : for every value of the discretized blunder potential , every rating in 1200 - 1800 range on fics has a lower empirical blunder rate at blunder potential @xmath38 than the best of these ratings at blunder potential @xmath41 . in effect , each additional @xmath42 increment in blunder potential contributes more , averaging over all instances , to the aggregate empirical blunder rate than an additional 600 rating points , despite the fact that 600 rating points represent a vast difference in chess performance .",
    "we see a similar effect for the gm data , where small increases in blunder potential have a greater effect on blunder rate than the enormous difference between a rating of 2300 and a rating of 2700 .",
    "( indeed , players rated 2700 are making errors at a greater rate in positions of blunder potential 0.9 than players rated 1200 are making in positions of blunder potential 0.3 . ) and we see the same effects when we separately fix the numerator and denominator that constitute the blunder potential , @xmath13 and @xmath12 , as shown in figure [ fig : skill - gradient ] .",
    "to the extent that this finding runs counter to our intuition , it bears an interesting relation to the _ fundamental attribution error _  the tendency to attribute differences in people s performance to differences in their individual attributes , rather than to differences in the situations they face @xcite .",
    "what we are uncovering here is that a basic measure of the situation  the blunder potential , which as we noted above corresponds to a measure of the _ danger _ inherent in the underlying chess position  is arguably playing a larger role than the players skill .",
    "this finding also relates to work of abelson on quantitative measures in a different competitive domain , baseball , where he found that a player s batting average accounts for very little of the variance in their performance in any single at - bat @xcite .",
    "we should emphasize , however , that despite the strong effect of blunder potential , skill does play a fundamental role role in our domain , as the analysis of this section has shown . and in general it is important to take multiple types of features into account in any analysis of decision - making , since only certain features may be under our control in any given application .",
    "for example , we may be able to control the quality of the people we recruit to a decision , even if we ca nt control the difficulty of the decision itself .",
    "[ [ the - skill - gradient - for - fixed - positions ] ] * the skill gradient for fixed positions * + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    grouping positions together by common @xmath18 values gives us a rough sense for how the skill gradient behaves in positions of varying difficulty .",
    "but this analysis still aggregates together a large number of different positions , each with their own particular properties , and so it becomes interesting to ask  how does the empirical blunder rate vary with elo rating _ when we fix the exact position on the board ? _    the fact that we are able to meaningfully ask this question is based on a fact noted in section [ sec : intro ] , that many non - trivial @xmath3@xmath6-piece positions recur in the fics data , exactly , several thousand times . for each such position @xmath11",
    ", we have enough instances to plot the function @xmath43 , the rate of blunders committed by players of rating @xmath9 in position @xmath11 .",
    "let us say that the function @xmath43 is _ skill - monotone _ if it is decreasing in @xmath9  that is , if players of higher rating have a lower blunder rate in position @xmath11 .",
    "a natural conjecture would be that every position @xmath11 is skill - monotone , but in fact this is not the case . among the most frequent positions , we find several that we term _ skill - neutral _ , with @xmath43 remaining approximately constant in @xmath9 , as well as several that we term _ skill - anomalous _ , with @xmath43 increasing in @xmath9 .",
    "figure [ fig : skill - gradient - position ] shows a subset of the most frequently occurring positions in the fics data that contains examples of each of these three types : skill - monotone , skill - neutral , and skill - anomalous . is described in forsyth - edwards notation ( fen ) above the panel in which its plot appears . ]",
    "the existence of skill - anomalous positions is surprising , since there is a no _ a priori _ reason to believe that chess as a domain should contain common situations in which stronger players make more errors than weaker players .",
    "moreover , the behavior of players in these particular positions does not seem explainable by a strategy in which they are deliberately making a one - move blunder for the sake of the overall game outcome . in each of the skill - anomalous examples in figure [ fig : skill - gradient - position ] , the player to move has a forced win , and the position",
    "is reduced enough that the worst possible game outcome for them is a draw under any sequence of moves , so there is no long - term value in blundering away the win on their present move .",
    "finally , we consider our third category of features , the time that players have available to make their moves .",
    "recall that players have to make their own decisions about how to allocate a fixed budget of time across a given number of moves or the rest of the game .",
    "the fics data has information about the time remaining associated with each move in each game , so we focus our analysis on fics in this subsection . specifically , as noted in section [ sec : features ] , fics games are generally played under extremely rapid conditions , and for uniformity in the analysis we focus on the most commonly - occurring fics time constraint  the large subset of games in which each player is allocated 3 minutes for the whole game .    as a first object of study ,",
    "let s define the function @xmath44 to be the empirical blunder rate in positions where the player begins considering their move with @xmath45 seconds left in the game .",
    "figure [ fig : blunder - rate - time - left ] shows a plot of @xmath44 ; it is natural that the blunder rate increases sharply as @xmath45 approaches @xmath46 , though it is notable how flat the value of @xmath44 becomes once @xmath45 exceeds roughly 10 seconds .",
    "[ [ the - time - gradient ] ] * the time gradient * + + + + + + + + + + + + + + + + + + +    this plot in figure [ fig : blunder - rate - time - left ] can be viewed as a basic kind of _ time gradient _ , analogous to the skill gradient , showing the overall improvement in empirical blunder rate that arises from having extra time available . here",
    "too we can look at how the time gradient restricted to positions with fixed blunder potential , or fixed blunder potential and player rating .",
    "we start with figure [ fig : blunder - rate - potential - time - left ] , which shows @xmath47 , the blunder rate for players within a narrow skill range ( 1500 - 1599 elo ) with @xmath45 seconds remaining in positions with blunder potential @xmath38 . in this sense , it is a close analogue of figure [ fig : blunder - rate - potential - rating ] , which plotted @xmath40 , and for values of @xmath45 above @xmath48 seconds , it shows a very similar `` ladder '' structure in which the role of blunder potential is dominant .",
    "specifically , for every @xmath38 , players are blundering at a lower rate with @xmath48 to @xmath49 seconds remaining at blunder potential @xmath38 than they are with over a minute remaining at blunder potential @xmath41 . a small increase in blunder potential",
    "has a more extensive effect on blunder rate than a large increase in available time .",
    "we can separate the instances further both by blunder potential and by the rating of the player , via the function @xmath50 which gives the empirical blunder rate with @xmath45 seconds remaining when restricted to players of rating @xmath9 in positions of blunder potential @xmath38 .",
    "figure [ fig : time - gradient ] plots these functions , with a fixed value of @xmath38 in each panel .",
    "we can compare curves for players of different rating , observing that for higher ratings the curves are steeper : extra time confers a greater relative empirical benefit on higher - rated players . across panels",
    ", we see that for higher blunder potential the curves become somewhat shallower : more time provides less relative improvement as the density of possible blunders proliferates .",
    "but equally or more striking is the fact that all curves retain a roughly constant shape , even as the empirical blunder rate climbs by an order of magnitude from the low ranges of blunder potential to the highest .",
    "comparing across points in different panels helps drive home the role of blunder potential even when considering skill and time simultaneously .",
    "consider for example ( a ) instances in which players rated 1200 ( at the low end of the fics data ) with 5 - 8 seconds remaining face a position of blunder potential 0.4 , contrasted with ( b ) instances in which players rated 1800 ( at the high end of the fics data ) with 42 - 58 seconds remaining face a position of blunder potential 0.8 . as the figure shows , the empirical blunder rate is lower in instances of type ( a )  a weak player in extreme time pressure is making blunders at a lower rate because they re dealing with positions that contain less danger .",
    "[ [ time - spent - on - a - move ] ] * time spent on a move * + + + + + + + + + + + + + + + + + + + + + +    thus far we ve looked at how the empirical blunder rate depends on the amount of time remaining in the game .",
    "however , we can also ask how the probability of a blunder varies with the amount of time the player actually spends considering their move before playing it .",
    "when a player spends more time on a move , should we predict they re less likely to blunder ( because they gave the move more consideration ) or more likely to blunder ( because the extra time suggests they did nt know what do ) ?",
    "the data turns out to be strongly consistent with the latter view : the empirical blunder rate is higher in aggregate for players who spend more time playing a move .",
    "we find that this property holds across the range of possible values for the time remaining and the blunder potential , as well as when we fix the specific position .",
    "we ve now seen how the empirical blunder rate depends on our three fundamental dimensions : difficulty , the skill of the player , and the time available to them .",
    "we now turn to a set of tasks that allow us to further study the predictive power of these dimensions .      in order to formulate our prediction methods for blunders",
    ", we first extend the set of features available for studying the difficulty of a position .",
    "once we have these additional features , we will be prepared to develop the predictions themselves .    thus far , when we ve considered a position s difficulty , we ve used information about the player s immediate moves , and then invoked a tablebase to determine the outcome after these immediate moves .",
    "we now ask whether it is useful for our task to consider longer sequences of moves beginning at the current position . specifically ,",
    "if we consider all @xmath51-move sequences beginning at the current position , we can organize these into a _ game tree _ of depth @xmath51 with the current position @xmath11 as the root , and nodes representing the states of the game after each possible sequence of @xmath52 moves .",
    "chess engines use this type of tree as their central structure in determining which moves to make ; it is less obvious , however , how to make use of these trees in analyzing blunders by human players , given players imperfect selection of moves even at depth 1 .",
    "let us introduce some notation to describe how we use this information .",
    "suppose our instance consists of position @xmath11 , with @xmath53 legal moves , of which @xmath54 are blunders",
    ". we will denote the moves by @xmath55 , leading to positions @xmath56 respectively , and we ll suppose they are indexed so that @xmath57 are the non - blunders , and @xmath58 are the blunders .",
    "we write @xmath59 for the indices of the non - blunders @xmath60 and @xmath61 for the indices of the blunders @xmath62 . finally ,",
    "from each position @xmath63 , there are @xmath64 legal moves , of which @xmath65 are blunders .",
    "the set of all pairs @xmath66 for @xmath67 constitutes a potentially useful source of information in the depth-2 game tree from the current position .",
    "what might it tell us ?    first",
    ", suppose that position @xmath63 , for @xmath68 , is a position reachable via a blunder @xmath69 .",
    "then if the blunder potential @xmath70 is large , this means that it may be challenging for the opposing player to select a move that capitalizes on the blunder @xmath69 made at the root position @xmath11 ; there is a reasonable chance that the opposing will instead blunder , restoring the minimax value to something larger .",
    "this , in turn , means that it may be harder for the player in the root position of our instance to see that move @xmath69 , leading to position @xmath63 , is in fact a blunder .",
    "the conclusion from this reasoning is that when the blunder potentials of positions @xmath63 for @xmath68 are large , it suggests a larger empirical blunder rate at @xmath11 .",
    "it is less clear what to conclude when there are large blunder potentials at positions @xmath63 for @xmath71  positions reachable by non - blunders .",
    "again , it suggests that player at the root may have a harder time correctly evaluating the positions @xmath63 for @xmath71 ; if they appear better than they are , it could lead the player to favor these non - blunders . on the other hand , the fact that these positions are hard to evaluate could also suggest a general level of difficulty in evaluating @xmath11 , which could elevate the empirical blunder rate .",
    "there is also a useful aggregation of this information , as follows .",
    "if we define @xmath72 and @xmath73 , and analogously for @xmath74 and @xmath75 , then the ratio @xmath76 is a kind of aggregate blunder potential for all positions reachable by blunders , and analogously for @xmath77 with respect to positions reachable by non - blunders .    in the next subsection",
    ", we will see that the four quantities @xmath78 , @xmath79 , @xmath74 , @xmath75 indeed contain useful information for prediction , particularly when looking at families of instances that have the same blunder potential at the root position @xmath11 .",
    "we note that one can construct analogous information at greater depths in the game tree , by similar means , but we find in the next subsection that these do not currently provide improvements in prediction performance , so we do not discuss greater depths further here .      we develop three nested prediction tasks : in the first task we make predictions about an unconstrained set of instances",
    "; in the second we fix the blunder potential at the root position ; and in the third we control for the exact position .",
    "[ [ task-1 ] ] * task 1 * + + + + + + + +    in our first task we formulate the basic error - prediction problem : we have a large collection of human decisions for which we know the correct answer , and we want to predict whether the decision - maker will err or not . in our context , we predict whether the player to move will blunder , given the position they face and the various features of it we have derived , how much time they have to think , and their skill level . in the process , we seek to understand the relative value of these features for prediction in our domain .    we restrict our attention to the 6.6 million instances that occurred in the 320,000 empirically most frequent positions in the fics dataset .",
    "since the rate of blundering is low in general , we down - sample the non - blunders so that half of our remaining instances are blunders and the other half are non - blunders .",
    "this results in a balanced dataset with 600,000 instances , and we evaluate model performance with accuracy . for ease of interpretation , we use both logistic regression and decision trees . since the relative performance of these two classifiers is virtually identical , but decision trees perform slightly better , we only report the results using decision trees here .    table  [ tab : features ] defines the features we use for prediction .",
    "in addition the notation defined thus far , we define : @xmath80 to be the skill features consisting of the rating of the player and the opponent ; @xmath81 for the number of non - blunders in position @xmath11 ; @xmath82 to be the difficulty features at depth 1 ; @xmath83 as the difficulty features at depth 2 defined in the previous subsection ; and @xmath45 as the time remaining .",
    ".features for blunder prediction .",
    "[ cols=\"<,<\",options=\"header \" , ]     in table  [ tab : task1results ] , we show the performance of various combinations of our features .",
    "the most striking result is how dominant the difficulty features are .",
    "using all of them together gives 0.75 accuracy on this balanced dataset , halfway between random guessing and perfect performance . in comparison , skill and time",
    "are much less informative on this task .",
    "the skill features @xmath84 only give 55% accuracy , time left @xmath45 yields 53% correct predictions , and neither adds predictive value once position difficulty features are in the model .",
    "the weakness of the skill and time features is consistent with our findings in section  [ sec : basic ] , but still striking given the large ranges over which the elo ratings and time remaining can extend .",
    "in particular , a player rated 1800 will almost always defeat a player rated 1200 , yet knowledge of rating is not providing much predictive power in determining blunders on any individual move . similarly",
    ", a player with 10 seconds remaining in the entire game is at an enormous disadvantage compared to a player with two minutes remaining , but this too is not providing much leverage for blunder prediction at the move level .",
    "while these results only apply to our particular domain , it suggests a genre of question that can be asked by analogy in many domains .",
    "( to take one of many possible examples , one could similarly ask about the error rate of highly skilled drivers in difficult conditions versus bad drivers in safe conditions . )",
    "another important result is that most of the predictive power comes from depth 1 features of the tree .",
    "this tells us the immediate situation facing the player is by far the most informative feature .    finally , we note that the prediction results for the gm data ( where we do not have time information available ) are closely analogous ; we get a slightly higher accuracy of @xmath85 , and again it comes entirely from our basic set of difficulty features for the position .",
    "p4.6cmp3 cm model & accuracy + random guessing & 0.50 + @xmath23 & 0.73 + @xmath86 & 0.73 + @xmath87 & 0.72 + @xmath88 & * 0.75 * + @xmath84 & 0.55 + @xmath89 & * 0.75 * + @xmath90 & 0.53 + @xmath91 & * 0.75 * + @xmath92 & * 0.75 * +    [ [ human - performance - on - a - version - of - task-1 ] ] * human performance on a version of task 1 * + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    given the accuracy of algorithms for task 1 , it is natural to consider how this compares to the performance of human chess players on such a task .    to investigate this question , we developed a version of task 1 as a web app quiz and promoted it on two popular internet chess forums .",
    "each quiz question provided a pair of @xmath36-piece instances with white to move , each showing the exact position on the board , the ratings of the two players , and the time remaining for each .",
    "the two instances were chosen from the fics data with the property that white blundered in one of them and not the other , and the quiz question was to determine in which instance white blundered .    in this sense , the quiz is a different type of chess problem from the typical style , reflecting the focus of our work here : rather than `` white to play and win , '' it asked `` did white blunder in this position ? '' . averaging over approximately 6000 responses to the quiz from 720 participants , we find an accuracy of @xmath93 , non - trivially better than random guessing but also non - trivially below our model s performance of @xmath94 .",
    "the relative performance of the prediction algorithm and the human forum participants forms an interesting contrast , given that the human participants were able to use domain knowledge about properties of the exact chess position while the algorithm is achieving almost its full performance from a single number  the blunder potential  that draws on a tablebase for its computation .",
    "we also investigated the extent to which the guesses made by human participants could be predicted by an algorithm ; our accuracy on this was in fact lower than for the blunder - prediction task itself , with the blunder potential again serving as the most important feature for predicting human guesses on the task .",
    "[ [ task-2 ] ] * task 2 * + + + + + + + +    given how powerful the depth 1 features are , we now control for @xmath13 and @xmath12 and investigate the predictive performance of our features once blunder potential has been fixed .",
    "our strategy on this task is very similar to before : we compare different groups of features on a binary classification task and use accuracy as our measure .",
    "these groups of features are : @xmath87 , @xmath84 , @xmath95 , @xmath90 , @xmath96 , and the full set @xmath97 . for each of these models",
    ", we have an accuracy score for every @xmath98 pair .",
    "the relative performances of the models are qualitatively similar across all @xmath98 pairs : again , position difficulty dominates time and rating , this time at depth 2 instead of depth 1 . in all cases ,",
    "the performance of the full feature set is best ( the mean accuracy is 0.71 ) , but @xmath87 alone achieves 0.70 accuracy on average .",
    "this further underscores the importance of position difficulty .    additionally , inspecting the decision tree models reveals a very interesting dependence of the blunder rate on the depth 1 structure of the game tree .",
    "first , recall that the most frequently occurring positions in our datasets have either @xmath99 or @xmath100 . in so - called `` only - move '' situations , where there is only one move that is not a blunder , the dependence of blunder rate on @xmath87 is as one would expect : the higher the @xmath78 ratio , the more likely the player is to blunder .",
    "but for positions with only one blunder , the dependence reverses : blunders are _ less _ likely with higher @xmath78 ratios .",
    "understanding this latter effect is an interesting open question .",
    "[ [ task-3 ] ] * task 3 * + + + + + + + +    our final prediction question is about the degree to which time and skill are informative once the position has been fully controlled for . in other words",
    ", once we understand everything we can about a position s difficulty , what can we learn from the other dimensions ?",
    "to answer this question , we set up a final task where we fix the position completely , create a balanced dataset of blunders and non - blunders , and consider how well time and skill predict whether a player will blunder in the position or not .",
    "we do this for all 25 instances of positions for which there are over 500 blunders in our data . on average , knowing the rating of the player alone results in an accuracy of 0.62 , knowing the times available to the player and his opponent yields 0.54 , and together they give 0.63 .",
    "thus once difficulty has been completely controlled for , there is still substantive predictive power in skill and time , consistent with the notion that all three dimensions are important .",
    "we have used chess as a model system to investigate the types of features that help in analyzing and predicting error in human decision - making .",
    "chess provides us with a highly instrumented domain in which the time available to and skill of a decision - maker are often recorded , and , for positions with few pieces , the set of optimal decisions can be determined computationally . through our analysis",
    "we have seen that the inherent difficulty of the decision , even approximated simply by the proportion of available blunders in the underlying position , can be a more powerful source of information than the skill or time available .",
    "we have also identified a number of other phenomena , including the ways in which players of different skill levels benefit differently , in aggregate , from easier instances or more time .",
    "and we have found , surprisingly , that there exist _ skill - anomalous _ positions in which weaker players commit fewer errors than stronger players .",
    "we believe there are natural opportunities to apply the paper s framework of skill , time , and difficulty to a range of settings in which human experts make a sequence of decisions , some of which turn out to be in error . in doing so",
    ", we may be able to differentiate between domains in which skill , time , or difficulty emerge as the dominant source of predictive information .",
    "many questions in this style can be asked . for a setting such as medicine ,",
    "is the experience of the physician or the difficulty of the case a more important feature for predicting errors in diagnosis ? or to recall an analogy raised in the previous section , for micro - level mistakes in a human task such as driving , we think of inexperienced and distracted drivers as a major source of risk , but how do these effects compare to the presence of dangerous road conditions ?    finally , there are a number of interesting further avenues for exploring our current model domain of chess positions via tablebases .",
    "one is to more fully treat the domain as a competitive activity between two parties .",
    "for example , is there evidence in the kinds of positions we study that stronger players are not only avoiding blunders , but also steering the game toward positions that have higher blunder potential for their opponent ?",
    "more generally , the interaction of competitive effects with principles of error - prone decision - making can lead to a rich collection of further questions .",
    "we thank tommy ashmore for valuable discussions on chess engines and human chess performance , the ficsgames.org team for providing the fics data , bob west for help with web development , and ken rogoff , dan goldstein , and sbastien lahaie for their very helpful feedback .",
    "this work has been supported in part by a simons investigator award , an aro muri grant , a google research grant , and a facebook faculty research grant .",
    "p.  jansen .",
    "problematic positions and speculative play . in _ computers , chess , and cognition _ , springer , 1990 .",
    "e. jones , v. harris .",
    "the attribution of attitudes",
    ". _ j. experimental social psych .",
    "_ , 3(1967 ) .",
    "d.  kopec .",
    "advances in man - machine play . in _ computers , chess , and cognition _ , springer , 1990 .",
    "h.  lakkaraju , j.  kleinberg , j.  leskovec , j.  ludwig , and s.  mullainathan . human decisions and machine predictions , 2016",
    ". working paper .              k.  w. regan and t.  biswas .",
    "psychometric modeling of decision making via game play . in _",
    "ieee conference on computational inteligence in games ( cig ) _ , 2013 .",
    "g.  salvendy and j.  sharit . human error . in _",
    "handbook of human factors and ergonomics_. john wiley & sons , 2006 ."
  ],
  "abstract_text": [
    "<S> an increasing number of domains are providing us with detailed trace data on human decisions in settings where we can evaluate the quality of these decisions via an algorithm . </S>",
    "<S> motivated by this development , an emerging line of work has begun to consider whether we can characterize and predict the kinds of decisions where people are likely to make errors .    to investigate what a general framework for human error prediction might look like , we focus on a model system with a rich history in the behavioral sciences : the decisions made by chess players as they select moves in a game . </S>",
    "<S> we carry out our analysis at a large scale , employing datasets with several million recorded games , and using _ chess tablebases _ to acquire a form of ground truth for a subset of chess positions that have been completely solved by computers but remain challenging even for the best players in the world .    </S>",
    "<S> we organize our analysis around three categories of features that we argue are present in most settings where the analysis of human error is applicable : the skill of the decision - maker , the time available to make the decision , and the inherent difficulty of the decision . </S>",
    "<S> we identify rich structure in all three of these categories of features , and find strong evidence that in our domain , features describing the inherent difficulty of an instance are significantly more powerful than features based on skill or time .    </S>",
    "<S> = 10000 = 10000    [ 1]>p#1 </S>"
  ]
}