{
  "article_text": [
    "this work addresses the problem of constructing error - correcting codes that can be efficiently decoded from a constant fraction of _ worst - case _ insertions and deletions .",
    "the main results generalize analogous results for the situation when errors are restricted to only deletions .",
    "coding for a constant fraction of adversarial insertions and deletions has been considered previously by schulman and zuckerman @xcite .",
    "they construct constant - rate binary codes that are efficiently decodable from a small constant fraction of worst - case insertions and deletions and can also handle a small fraction of transpositions .",
    "our work primarily builds off recent results by guruswami , bukh , and wang @xcite , which address the construction and efficient decoding of codes for constant fractions of deletions .",
    "these works establish three results , providing families of codes with each of the following parameters .    1 .   families with rate approaching 1 decoding a constant fraction of deletions 2 .   families with constant rate decoding a fraction of deletions approaching 1 3 .",
    "families over a fixed alphabet of size @xmath0 with constant rate and decoding a fraction of deletions approaching @xmath2 ( in particular , one gets binary codes for correcting a deletion fraction approaching @xmath3 . )    over an alphabet of size @xmath0 , it is impossible to have a constant rate code that corrects a @xmath4 fraction of deletions .",
    "the last result establishes that the maximum correctable fraction of deletions of a constant rate code is @xmath5 .",
    "combinatorially , decoding a given number of worst - case insertions and deletions is identical to decoding the same number of worst - case deletions .",
    "this is established in the following lemma , originally given by levenshtein @xcite .",
    "[ equivlemma ] let @xmath6^n$ ] be a code , and let @xmath7 be a positive integer .",
    "the following are equivalent .",
    "1 ) @xmath8 is decodable under up to @xmath9 insertions .",
    "2 ) @xmath8 is decodable under up to @xmath9 deletions .",
    "3 ) @xmath8 is decodable under up to @xmath9 insertions and deletions .",
    "lemma [ equivlemma ] establishes that the codes provided in the three constructions must also be capable of decoding both insertions and deletions .",
    "the task that remains , and which our work addresses , is to construct codes in the _ same parameter settings _ that can efficiently correct a combination of insertions _ and _ deletions .",
    "the regime under which errors are insertions and deletions is closely related to _ edit - distance _ ( also known as levenshtein distance ) , which measures errors of a code under insertions , deletions , and substitutions . a substitution can be viewed as a deletion followed by an insertion .",
    "thus , all results established in the insertion and deletion regime , both constructive and algorithmic , hold in the edit - distance regime when the number of errors is cut in half , and therefore in the traditional coding theory setting in which the only errors are substitutions . the edit - distance is a more challenging model , however ; while the gilbert - varshamov bound gives codes over size @xmath0 alphabets that can correct up to a fraction of substitutions approaching @xmath10 , the question of whether there exist positive rate codes capable of correcting a deletion fraction approaching @xmath4 is still open .",
    "furthermore , the same results with half as many errors must hold in the traditional coding theory setting in which the only errors are substitutions .",
    "the converse is not necessarily true , however .",
    "the gilbert - varshamov bound @xcite gives codes over size @xmath0 alphabets that can correct up to a fraction of substitutions approaching @xmath10 , but the question of whether there exist positive rate codes capable of correcting a deletion fraction approaching @xmath4 is still open .",
    "these are the efficiently decodable code constructions in the deletion - only regime that we are generalizing to the insertion / deletion regime .",
    "\\1 ) a binary code family of rate @xmath11 that can be efficiently decoded from an @xmath12 fraction of worst - case deletions , for all @xmath12 smaller than some absolute constant @xmath13 . furthermore",
    ", the codes are constructible , encodable , and decodable , in time @xmath14 , where @xmath15 is the block length .",
    "[ theorem 4.1 from @xcite ]    \\2 ) for any @xmath16 , a code family over an alphabet of size @xmath17 and rate @xmath18 that can be decoded from a @xmath19 fraction of worst - case deletions .",
    "furthermore , this code is constructible , encodable , and decodable in time @xmath14 . [ theorem 3.1 from @xcite ]    \\3 ) for all integers @xmath20 and all @xmath16 , a code family over alphabet size @xmath0 of positive rate @xmath21 that can be decoded from a @xmath22 fraction of worst - case deletions in @xmath23 time .",
    "there exists a constant @xmath24 such that the following holds .",
    "let @xmath25 .",
    "for infinitely many and sufficiently large @xmath15 , there is an explicit binary code @xmath26 with rate @xmath11 that can be efficiently decoded from an @xmath12 fraction of worst - case deletions .",
    "furthermore , this code is constructible , encodable , and decodable , in time @xmath14 .",
    "let @xmath27 .",
    "for infinitely many and sufficiently large @xmath15 , there is an explicit code @xmath8 with rate @xmath18 and alphabet size @xmath17 that can be decoded from a @xmath19 fraction of worst - case deletions .",
    "furthermore , this code is constructible , encodable , and decodable in time @xmath14 .",
    "fix an integer @xmath28 and @xmath29 . for infinitely many and sufficiently large",
    "@xmath15 , there is an explicit code @xmath6^n$ ] with rate @xmath30 over a size @xmath0 alphabet that can be decoded from a @xmath31 fraction of worst - case deletions .",
    "furthermore , this code is decodable in time @xmath32 and is constructible in time @xmath33 .",
    "our work constructs the following three families of codes .",
    "1 .   alphabet size : 2 , rate : @xmath11 , insertion / deletion fraction : @xmath12 , decoding time : @xmath14 .",
    "[ highratetheorem ] ) 2 .",
    "alphabet size : @xmath17 , rate : @xmath34 , insertion / deletion fraction : @xmath19 , decoding time : @xmath14 .",
    "[ higherrortwotheorem ] ) 3 .",
    "alphabet size : @xmath28 , rate : @xmath35 , insertion / deletion fraction : @xmath22 , decoding time : @xmath36 .",
    "( thm .  [ higherroronetheorem ] )",
    "theorem [ higherrortwotheorem ] gives constant rate codes that decode from a @xmath19 fraction of insertions / deletions .",
    "this also follows as a corollary from theorem [ higherroronetheorem ] . however , the rate of the construction in theorem [ higherroronetheorem ] is @xmath35 , which is far worse than @xmath37 .",
    "the main point of [ higherroronetheorem ] is to highlight the near - tight trade - off between alphabet size and insertion / deletion fraction .    at the expense of slightly worse parameters ,",
    "the construction and decoding complexities in theorems [ highratetheorem ] and [ higherrortwotheorem ] can be improved to @xmath38 .",
    "see theorems [ highratefasttheorem ] and [ higherrortwofasttheorem ] .",
    "theorems [ higherrortwotheorem ] and [ higherroronetheorem ] use the powerful idea of list decoding , exemplified in @xcite .",
    "a normal decoding algorithm is required to return the exact codeword , but a list decoding algorithm is allowed to return a list of codewords containing the correct codeword .",
    "the codes for both theorems are decoded by first applying a list decoding algorithm , and then noting that if the easier list decoding is gauranteed to succeed ( that is , returns a list containing the correct codeword ) , one can simply pass through the resulting list and choose the unique codeword that has sufficiently small distance from the received word .",
    "the codeword will be unique because the codes constructed are provably decodable under the required number of insertion / deletions according to the results in @xcite .",
    "the extent of difference between the insertion / deletion decoding algorithms and their deletion - only analogues varies depending on the parameter setting . for a @xmath22 fraction of insertions / deletions",
    ", the decoding algorithm uses the same list decoding approach as the deletion - only decoding algorithm in @xcite . for a @xmath19 fraction of insertions / deletions",
    ", we adopt the list decoding approach that in fact simplifies the construction presented in @xcite . for achieving a rate of @xmath19",
    ", we use the same code as in @xcite with different parameters , but considerably more bookkeeping is done to provide a provably correct decoding algorithm . in particular ,",
    "both theorem 4.1 from @xcite and theorem [ highratetheorem ] place chunks of 0s between inner codewords .",
    "however , while identifying buffers in the received word in the deletion - only case merely requires identifying long runs of 0s , identifying buffers in the insertion / deletion case requires identifying strings of fixed length with sufficiently small fraction of 1s .",
    "let @xmath39 $ ] denote the set @xmath40 . for a string @xmath41 ,",
    "let @xmath42 denote the length of the string .",
    "define @xmath43 to be the _ insertion / deletion distance _ between @xmath44 and @xmath45 , that is , the number of insertions / deletions needed to manipulate @xmath44 into @xmath45 . for two words",
    "@xmath46 , let @xmath47 be the length of the longest common subsequence of @xmath44 and @xmath45 .",
    "define @xmath48 .",
    "for the same reason that lemma [ equivlemma ] is true , we have @xmath49 .",
    "a code @xmath8 of block length @xmath50 over an alphabet @xmath51 is a subset @xmath52 .",
    "the rate of @xmath8 is defined to be @xmath53 .",
    "the encoding function of a code is a map @xmath54\\to\\sigma^n$ ] whose image equals @xmath8 ( with messages identified with @xmath55 $ ] in some canonical way ) , and the decoding function of a code is a map @xmath56 .",
    "a code is encodable in time @xmath57 if , for all elements of @xmath55 $ ] , the map @xmath58 can be computed in time @xmath57 .",
    "a code is decodable from @xmath9 ( or , a @xmath59 fraction of ) worst - case insertions and deletions in time @xmath57 if , for all @xmath60 , and for all @xmath41 such that @xmath61 ( or @xmath62 ) , @xmath63 can be computed in time @xmath57 and evaluates to @xmath44 . a code is constructible in time @xmath57 if descriptions of @xmath64 and @xmath58 can be produced in time @xmath57 .",
    "just as in @xcite , our constructions use the idea of code concatenation : if @xmath65 is an `` outer code '' with encoding function @xmath66 , and @xmath67 is an `` inner code '' with encoding function @xmath68 , then the concatenated code @xmath69 is a code whose encoding function first applied @xmath66 to the message , and then applied @xmath70 to each symbol of the resulting outer codeword .    thoughout the paper ,",
    "@xmath71 denote codewords , @xmath72 denote codewords modified under insertions and deletions , and @xmath73 denote inner codewords of concatenated codes .",
    "we let @xmath50 denote the block length of the code , unless we deal with a concatenated code , in which case @xmath50 denotes the block length of the outer code , @xmath74 denotes the block length of the inner code , and @xmath75 denotes the block length of the entire code .",
    "alphabet sizes are denoted by @xmath0 , and field sizes for outer reed solomon codes are denoted by @xmath76 .",
    "[ denseinnercodelemma ] let @xmath77 .",
    "then , for every @xmath74 , there exists a code @xmath78 of rate @xmath79 such that    * for every string @xmath80 , every interval of length @xmath81 in @xmath41 , contains at least @xmath82 1 s , * @xmath8 can be corrected from a @xmath59 fraction of worst - case deletions , and * @xmath8 can be found , encoded , and decoded in time @xmath83 .",
    "[ highratetheorem ] there exists a constant @xmath24 such that the following holds .",
    "let @xmath25 .",
    "there is an explicit binary code @xmath84 with rate @xmath85 that is decodable from an @xmath12 fraction of insertions / deletions in @xmath14 time .",
    "furthermore , @xmath8 can be constructed and encoded in time @xmath14 .",
    "with hindsight , let @xmath86 , and let @xmath25 .",
    "consider the concatenated construction with the outer code being a reed - solomon code that can correct a @xmath87 fraction of errors and erasures .",
    "for each @xmath88 , we replace the @xmath89th coordinate @xmath90 with the pair @xmath91 ; to ensure that this does nt affect the rate much , we take the rs code to be over @xmath92 , where @xmath93 is the block length and @xmath94 .",
    "we encode each outer symbol pair in the inner code , defined as follows .",
    "the inner code is a good binary insertion / deletion code @xmath95 of block length @xmath74 decoding a @xmath96 fraction of insertions and deletions , such that every interval of length @xmath97 in a codeword has at least @xmath98 fraction of 1s . this code can be found using lemma [ denseinnercodelemma ] .",
    "we also assume each codeword begins and ends with a 1 .",
    "now take our concatenated reed - solomon code of block length @xmath99 , and between each pair of adjacent inner codewords of @xmath95 , insert a _ chunk _ of @xmath100 0s .",
    "this gives us our final code @xmath8 with block length @xmath101 .",
    "the rate of @xmath8 is @xmath11 .",
    "the rate of the outer rs code is @xmath102 , and the rate of the inner code can be taken to be @xmath103 by lemma [ denseinnercodelemma ] . adding in the buffers reduces the rate by a factor of @xmath104 .",
    "combining these with our choice of @xmath59 gives us a total rate for @xmath8 of @xmath85 .",
    "the code @xmath8 can be decoded from an @xmath12 fraction of insertions and deletions in time @xmath14 .",
    "consider the following algorithm that runs in time @xmath14 for decoding the received word :    \\1 ) scan from the left of the received word .",
    "every time we encounter a substring of length exactly @xmath100 with at most @xmath105 fraction of 1s ( or @xmath106 1s ) , mark it as a _ decoding buffer_. then , continue scanning from the end of the buffer and repeat .",
    "this guarantees no two buffers overlap .",
    "this takes time @xmath107 .",
    "\\2 ) start with an empty set @xmath108 .",
    "the buffers divide the received word into strings which we call _ decoding windows_. for each decoding window , apply the decoder from lemma [ denseinnercodelemma ] to recover a pair @xmath109 .",
    "if we succeed , add this pair to @xmath108 .",
    "this takes @xmath110 time .",
    "\\3 ) if for any @xmath89 , @xmath108 contains multiple pairs with first coordinate @xmath89 , remove all such pairs from @xmath108 .",
    "@xmath108 thus contains at most one pair @xmath109 for each index @xmath89 .",
    "then apply the rs decoding algorithm to the string @xmath111 whose @xmath89th coordinate is @xmath112 if @xmath113 and erased otherwise .",
    "this takes time @xmath107 .    in the deletion",
    "only case , the decoding buffers are runs of at least @xmath114 contiguous zeros",
    ". runs of consecutive zeros are obviously a poor choice for decoding buffers in the presence of insertions , as we can destroy any buffer with a constant number of insertions .    note",
    "that the total number of insertions / deletions we can make is at most @xmath115 .",
    "suppose our received codeword is @xmath116 , where @xmath117 are the identified decoding buffers and @xmath118 are the decoding windows .",
    "then consider a canonical mapping from characters of @xmath44 to characters of @xmath41 where @xmath119 is mapped to by a substring @xmath120 of @xmath44 , @xmath121 is mapped to by a string @xmath122 , so that @xmath123 and @xmath124 .    with our canonical mapping",
    ", we can identify @xmath125 many characters in @xmath41 with characters in @xmath44 .",
    "intuitively , these are the characters that are uncorrupted when we transform @xmath44 into @xmath41 using insertions and deletions .",
    "call a received buffer @xmath121 in @xmath41 a _ good decoding buffer _ ( or _ good buffer _ for short ) if at least @xmath126 of its characters are identified with characters from a single chunk of @xmath100 0s in @xmath44 .",
    "call a decoding buffer _ bad _ otherwise .",
    "call a chunk of @xmath100 0s in @xmath44 _ good _ if at least @xmath127 of its zeros map to characters in single decoding buffer .",
    "note that there is a natural bijection between good chunks in @xmath44 and good decoding buffers in @xmath41 .",
    "[ bad - buffer - lemma ] the number of bad decoding buffers of @xmath41 is at most @xmath128 .",
    "suppose we have a bad buffer @xmath121 .",
    "it either contains characters from at least two different chunks of @xmath100 0s in @xmath44 or contains at most @xmath129 characters from a single chunk .    in the first case",
    ", @xmath122 must contain characters in two different chunks so its length must be at least @xmath74 , so @xmath121 must have been obtained from at least @xmath130 deletions from @xmath122 .    in the second case ,",
    "if @xmath122 has length at most @xmath131 then the insertion / deletion distance between @xmath122 and @xmath121 is at least @xmath132 . otherwise , @xmath122 has at least @xmath133 charaters in some inner codeword of @xmath44 , so @xmath122 has at least @xmath134 1s , so we need at least @xmath135 deletions to obtain @xmath121 from @xmath122 .    by a simple counting argument",
    ", the total number of bad buffers we can have is at most @xmath136 .",
    "[ good - buffer - lemma ] the number of good decoding buffers of @xmath41 is at least @xmath137 .",
    "it suffices to prove the number of good chunks of @xmath44 is at least @xmath138 .",
    "if a chunk is not mapped to a good buffer , at least one of the following is true .    1 .",
    "the chunk is `` deleted '' by inserting enough 1s .",
    "part of the chunk is mapped to a bad buffer that contains characters from @xmath139 other chunks .",
    "part of the chunk is mapped to a bad buffer that contains no characters from other chunks .    in the first case ,",
    "we need at least @xmath140 insertions to delete the chunk . in the second case , creating the bad buffer costs at least @xmath141 deletions , which is at least @xmath142 deletions per chunk . in the third case , creating the bad buffer costs at least @xmath143 edits by the argument in lemma [ bad - buffer - lemma ] .",
    "thus , we have at most @xmath136 bad chunks , so we have at least @xmath138 good chunks , as desired .",
    "since there are at least @xmath138 good decoding buffers and at most @xmath144 bad decoding buffers , there must be at least @xmath145 pairs of consecutive good decoding buffers .",
    "for any pair of consecutive good decoding buffers @xmath146 in @xmath41 , the corresponding two good chunks of @xmath100 0s in @xmath44 are consecutive unless there is at least one bad chunk in between the two good chunks , which happens for at most @xmath144 pairs .",
    "thus , there are at least @xmath147 pairs of consecutive good decoding buffers in @xmath41 such that the corresponding good chunks of 0s in @xmath44 are also consecutive .",
    "now suppose @xmath148 is an inner codeword between two good chunks with corresponding consecutive good decoding buffers , @xmath146 .",
    "the corresponding decoding window between the decoding buffers is @xmath149 , mapped to from @xmath150 , a substring of @xmath44 .",
    "we claim that most such @xmath148 are decoded correctly .    for all but @xmath151 choices of @xmath152",
    ", we have @xmath153 , @xmath154 , and @xmath155 .",
    "when we have an inner codeword @xmath148 and an index @xmath152 such that all these are true , we have @xmath156 , and each of @xmath157 shares at least @xmath129 characters with one of the chunks of @xmath100 0s neighboring @xmath148 .",
    "it follows that @xmath157 each contain at most @xmath158 characters of @xmath148 .",
    "additionally , by the definition of a good chunk , @xmath149 contains at most @xmath159 characters in each of the chunks neighboring @xmath148 .",
    "thus , we have @xmath160 , in which case , @xmath161 .",
    "thus , for at least @xmath162 inner words @xmath148 , there exists @xmath163 such that @xmath164 .",
    "therefore , our algorithm detects at least @xmath165 correct pairs @xmath109 .",
    "since our algorithm detects at most @xmath166 pairs total , we have at most @xmath167 incorrect pairs .",
    "thus , after removing conflicts , we have at least @xmath168 correct values , so our reed solomon decoder will succeed .",
    "our decoding algorithm succeeds as long as the inner code can correct up to a @xmath59 fraction of insertions / deletions and consists of codewords such that every interval of length @xmath97 has at least @xmath98 fraction of 1s .",
    "the time complexity of theorem [ highratetheorem ] can be improved using a more efficient inner code , at the cost of reduction in rate .    because of the addition of buffers , the code of theorem [ highratetheorem ] may not be dense enough to use as an inner code .",
    "the inner code needs to have @xmath98 fraction of 1s for every interval of length @xmath97 .",
    "however , we can modify the construction of the inner concatenated code so that the inner codewords of the inner code in theorem [ highratetheorem ] have at least @xmath169 fraction of 1s in every interval of length @xmath97 .",
    "this guarantees that the inner codewords of our two level construction have sufficiently high densities of 1s .",
    "this is summarized in the following theorem .",
    "[ highratefasttheorem ] there exists a constant @xmath24 such that the following holds .",
    "let @xmath170 .",
    "there is an explicit binary code @xmath26 that is decodable from an @xmath12 fraction of insertions / deletions with rate @xmath171{\\eps})$ ] in time @xmath172 .",
    "because our decoding algorithms for the @xmath19 and @xmath22 insertion / deletion constructions use the same list decoding technique , we abstract out the technical part of the decoding algorithm with the following theorem .",
    "[ insertion - deletion - thm ] let @xmath8 be a code over alphabet of size @xmath0 and length @xmath75 obtained by concatenating a reed - solomon @xmath173 of length @xmath50 with an inner code @xmath174 of length @xmath74 .",
    "suppose @xmath173 has rate @xmath111 and is over @xmath175 with @xmath93 .",
    "suppose @xmath176\\times\\ff_q\\to[k]^m$ ] can correct a @xmath177 fraction of insertions and deletions in @xmath178 for some function @xmath9 .",
    "then , provided @xmath8 is ( combinatorially ) decodable under up to @xmath179 fraction of insertions and deletions , it is in fact decodable in time @xmath180 .          1 .",
    "let @xmath186 denote the substring from indices @xmath187 to @xmath188 .",
    "2 .   by brute force search over @xmath189 ,",
    "find all pairs @xmath190 such that @xmath191 .",
    "if exactly one such pair @xmath190 exists , then add @xmath190 to @xmath192 .",
    "break the codeword @xmath198^{nm}$ ] of the concatenated code @xmath8 into @xmath50 inner blocks , with the @xmath89th block @xmath199^m$ ] corresponding to the inner encoding of the @xmath89th symbol @xmath200 of the outer reed - solomon code .",
    "for some fixed canonical way of forming @xmath41 out of @xmath44 , let @xmath201 be the block formed out of @xmath202 , so that @xmath203 partition the string @xmath41 .",
    "call an index @xmath89 _ good _ if it can be obtained from @xmath202 by at most @xmath204 insertions or deletions , and _ bad _ otherwise .",
    "the number of bad indices is at most @xmath205 , so the number of good indices is at least @xmath206 .    for any good index @xmath207",
    ", there exists some @xmath186 such that @xmath208 is a substring of @xmath186 and @xmath209 .",
    "since @xmath207 is good , the insertion / deletion distance between @xmath210 and @xmath208 is at most @xmath211 , and the insertion / deletion distance between @xmath208 and @xmath186 is less than @xmath212 , so the insertion / deletion distance between @xmath210 and @xmath186 is at most @xmath213 .",
    "since @xmath174 can handle up to @xmath213 insertions and deletions , it follows that @xmath210 is the unique codeword of @xmath174 such that @xmath214 . since @xmath210 is the encoding of @xmath215 under @xmath174",
    ", we conclude that for any good index @xmath207 , the pair @xmath215 will be included in @xmath192 .",
    "in particular , @xmath192 will have at least @xmath216 such pairs , so the correct @xmath217 will be in @xmath193 .",
    "we now check that step 3 of the algorithm will succeed .",
    "we have @xmath218 , and sudan s list decoding algorithm will give a list of degree - less - than-@xmath195 polynomials over @xmath175 such that @xmath219 for more than @xmath220 values of @xmath221 @xcite .",
    "furthermore , this list will have at most @xmath222 elements . for our choice of @xmath223",
    ", we have @xmath224 , so the list decoding will succeed .",
    "by above , there will be at least one polynomial in @xmath193 such that the longest common subsequence of its encoding with @xmath41 has length at least @xmath225 , namely the correct polynomial @xmath217 .",
    "since we assumed @xmath8 can decode up to a @xmath226 fraction of insertons / deletions , all other polynomials in @xmath193 will have longest common subsequence with @xmath41 smaller than @xmath225 .",
    "thus our algorithm returns the correct @xmath217 .",
    "we have @xmath227 intervals @xmath186 to check , and each one brute forces over @xmath228 terms of @xmath189 .",
    "encoding takes time @xmath229 by assumption and computing the longest common subsequence takes @xmath230 time , so in total the second step of the algorithm takes @xmath231 time . since @xmath232 for sufficiently large @xmath15 , the reed - solomon list decoding algorithm can be performed in time @xmath233 , see for instance @xcite .",
    "there are a constant number of polynomials to check at the end , and each one takes @xmath233 time using the longest common subsequence algorithm .",
    "thus , the overall runtime of the algorithm is @xmath234 .",
    "[ weakconcatlemma ] suppose have a code @xmath8 which is the concatenation of an outer code @xmath173 of length @xmath50 with an inner code @xmath174 of length @xmath74 .",
    "suppose further that for some @xmath235 , we have @xmath236",
    ". then @xmath237 .",
    "[ higherrorcorollarylemma ] let @xmath238 , and @xmath0 be a positive integer .",
    "for every @xmath74 , there exists a code @xmath6^m$ ] of rate @xmath239 that can correct a @xmath19 fraction of insertions / deletions in time @xmath240 , provided @xmath241 .",
    "[ higherrortwotheorem ] for any @xmath242 , there exists a family of codes over an alphabet of size @xmath17 and rate @xmath34 that can be efficiently decoded from a @xmath19 fraction of insertions / deletions .",
    "furthermore , this code is constructible , encodable , and decodable in time @xmath14 .",
    "let @xmath243 and @xmath244 .",
    "by lemma [ higherrorcorollarylemma ] , we can construct by brute force a code @xmath245^m$ ] that can be decoded from @xmath246 fraction of worst - case insertions and deletions .",
    "we can concatenate @xmath95 with an outer reed - solomon code of rate @xmath247 .      by lemma [ weakconcatlemma ] , @xmath250 ,",
    "so @xmath8 is capable of decoding up to @xmath19 fraction of insertions and deletions .",
    "encoding in @xmath95 is done by brute force in time @xmath14 , so by theorem [ insertion - deletion - thm ] , @xmath8 is capable of decoding up to @xmath251 fraction of worst - case insertions and deletions in time @xmath252 , as desired .",
    "our construction only requires that the inner code can be decoded from @xmath246 fraction of worst - case insertions and deletions . by using the concatenated code of theorem [ higherrortwotheorem ] as the inner code of the same construction ( thus giving us two levels of concatenation )",
    ", we can reduce the time complexity significantly , at the cost of a polynomial reduction in other parameters of the code , as summarized below .",
    "[ higherrortwofasttheorem ] for any @xmath242 , there exists a family of constant rate codes over an alphabet of size @xmath17 and rate @xmath253 that can be decoded from a @xmath19 fraction of insertions / deletions .",
    "furthermore , this code is constructible , encodable , and decodable in time @xmath172 .",
    "[ bg - theorem-12 ] fix an integer @xmath28 and @xmath254 .",
    "then there are infinitely many @xmath15 for which there is a concatenated reed solomon code @xmath6^n$ ] that has outer rate at least @xmath255 , has total rate at least @xmath256 , is decodable under @xmath257 fraction of insertions and deletions , has an inner code decodable under @xmath258 insertions and deletions , and is constructible in time @xmath259 .",
    "[ higherroronetheorem ] fix an integer @xmath28 and @xmath242 . for infinitely many and sufficiently large @xmath15 , there is an explicit code @xmath26 with rate @xmath260 over a size @xmath0 alphabet that can be decoded from a @xmath22 fraction of worst - case insertions and deletions in time @xmath261 .",
    "furthermore , this code is constructible in time @xmath262 .",
    "consider the codes @xmath8 given by lemma [ bg - theorem-12 ] with @xmath263 .",
    "@xmath8 has outer rate at least @xmath264 and total rate at least @xmath256 .",
    "furthermore , @xmath8 can decode up to @xmath257 fraction of insertions / deletions , and the inner code of @xmath8 can decode @xmath258 fraction of insertions / deletions .",
    "thus , by theorem [ insertion - deletion - thm ] , @xmath8 can efficiently decode up to @xmath265 fraction of insertions / deletions .",
    "b. bukh and v. guruswami .",
    "an improved bound on the fraction of correctable deletions . ,",
    "pages 1893 - 1901 , 2016 .",
    "v. guruswami and c. wang .",
    "deletion codes in the high - noise and high - rate regimes . , pages 867 - 880 , 2015 .",
    "v.  i. levenshtein .",
    "binary codes capable of correcting deletions , insertions , and reversals . , 163(4):845848 , 1965 .",
    "english translation in soviet physics doklady , 10(8):707 - 710 , 1966 .",
    "edgar  n. gilbert .",
    "a comparison of signalling alphabets .",
    ", 31:504522 , 1952 ."
  ],
  "abstract_text": [
    "<S> this work constructs codes that are efficiently decodable from a constant fraction of _ worst - case _ insertion and deletion errors in three parameter settings : ( i ) binary codes with rate approaching 1 ; ( ii ) codes with constant rate for error fraction approaching 1 over fixed alphabet size ; and ( iii ) constant rate codes over an alphabet of size @xmath0 for error fraction approaching @xmath1 . </S>",
    "<S> when errors are constrained to deletions alone , efficiently decodable codes in each of these regimes were constructed recently . </S>",
    "<S> we complete the picture by constructing similar codes that are efficiently decodable in the insertion / deletion regime . </S>"
  ]
}