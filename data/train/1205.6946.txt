{
  "article_text": [
    "in this paper we expand earlier results @xcite that show how stochastic control problems with a particular cost structure , involving a relative entropy term , admit a purely probabilistic solution , without the necessity of applying the dynamic programming principle .",
    "we provide two methods to compute an optimal control in this situation .",
    "the first method expresses the optimal control as a malliavin derivative .",
    "this enables us to solve control problems in which the dynamic programming principle fails .",
    "the second method transforms the problem of finding an optimal control into a linear pde .",
    "essential in our approach are the study of control problems by a change of measure technique @xcite and the useful properties of relative entropy ( * ? ? ?",
    "* section 1.4 ) .",
    "a well - known approach in solving optimal control problems is by means of the dynamic programming principle , leading in the stochastic , continuous time case to the hjb equation , a nonlinear pde @xcite .",
    "stochastic optimal control problems with a specific cost structure may be reduced to a linear pde @xcite , ( * ? ? ?",
    "* chapter vi ) .",
    "such a linear pde is obtained by a applying a logarithmic transform to the hamilton - jacobi - bellman ( hjb ) equation ; we will refer to this phenomenon as a linearization of the hjb equation .",
    "this observation gained new life in recent years as it was picked up by the physics and artificial intelligence community to obtain monte carlo methods for solving stochastic control problems @xcite . in this paper",
    "we show that this linearizing effect may also be obtained from a purely probabilistic perspective .",
    "in fact the linearization is only a special case of a much wider class of probabilistic optimization problems that are regularized by a relative entropy term @xcite . in the setting of markov chains the linearizing effect of relative entropy",
    "weighted optimization was , to our knowledge , first made in @xcite . by limiting arguments the connection with diffusions can be made . in section  [ sec : relation_classical_control ] we show how this result can be obtained without reference to dynamic programming and without the need for discretization .",
    "first we provide an alternative way of computing an optimal control by using malliavin derivatives , as we show in section  [ sec : control_as_malliavin_derivative ] .",
    "the main argument is as follows .",
    "let @xmath0 denote a probability space and suppose we are given a random variable @xmath1 on @xmath2 indicating cost .",
    "we may change this probability measure to a new probability measure @xmath3 but this operation is ` penalized ' by a positive factor @xmath4 times the relative entropy @xmath5 of the new probability measure with respect to the old probability measure .",
    "it is a result of direct computation that the ` optimal ' probability measure , i.e. the one that minimizes @xmath6 , has a density proportional to @xmath7 with respect to @xmath8 , as described in section  [ sec : re_optimization ] .",
    "this result may also be found in @xcite .",
    "if we specialize to the case where all the randomness is generated by a brownian motion , then an application of girsanov s theorem shows that a change in probability measure depending on some ` control process ' corresponds to a relative entropy equal to quadratic control costs .",
    "furthermore any probability density may be obtained using such a girsanov type change of measure , which holds in particular for the optimal probability measure with density proportional to @xmath7 with respect to @xmath8 .",
    "this result was obtained earlier by bou and dupuis @xcite .",
    "this material is explained in detail in section  [ sec : dynamic_re_optimization ] .",
    "the focus on this paper is on minimizing cost functionals depending on a brownian motion . as an exception , in section  [ sec : jumps ] an example",
    "is given of application of the theory to processes with jumps .",
    "an explicit expression of the optimal control process in terms of a malliavin derivative involving the cost random variable @xmath1 may be given ( section  [ sec : control_as_malliavin_derivative ] ) .",
    "this argument provides us with a new approach to solve a class of control probems with quadratic control costs . since the form of the cost random variable",
    "is not restricted this method may be applied in cases where dynamic programming ( i.e. the hjb equation ) fails .",
    "for example , it is shown that the maximum of a brownian motion with drift may be minimized by this method in section  [ sec : minimize_maximum ] , resulting in an explicit optimal control policy .",
    "this example clearly illustrates the novelty of our approach .",
    "the relation of our approach to classical stochastic optimal control ( as in @xcite ) is explained in section  [ sec : relation_classical_control ] .",
    "there it is shown that the solution of the state dependent optimal control problem may be expressed as the solution of a linear pde .",
    "this may be contrasted to the nonlinear hjb pde that is fundamental in classical stochastic control . as explained above this result",
    "was obtained earlier @xcite but derived in an entirely different way , namely by a logarithmic transformation of the nonlinear hjb equation .    to make the paper self contained we provided some background information on relative entropy ( appendix  [ app : relative_entropy ] ) .",
    "we denote the euclidean norm in @xmath9 by @xmath10 . for a matrix @xmath11",
    "we write @xmath12 for the usual matrix norm .",
    "the set of all borel measurable functions mapping a measurable space @xmath13 into a borel space @xmath14 is denoted by @xmath15 , and the set of all bounded borel measurable functions from @xmath13 into @xmath14 is denoted by @xmath16 .",
    "similarly @xmath17 denotes the space of continuous functions from @xmath18 into @xmath9 and @xmath19 denotes the space of continuous functions @xmath20 from @xmath21 into @xmath9 that are once differentiable with respect to @xmath22 and twice differentiable with respect to @xmath23 , with all these derivatives being continuous .",
    "if @xmath24 is a probability space we write @xmath25 for expectation with respect to the probability measure @xmath3 .",
    "let @xmath0 be a probability space .",
    "furthermore suppose a real - valued random variable @xmath1 , bounded from below , is given , indicating _",
    "cost_.    we wish to find a probability measure @xmath3 that    * is absolutely continuous with respect to @xmath8 ( denoted by @xmath26 ) , * minimizes the expected cost @xmath27 , but * has minimum deviation from the original probability measure @xmath8 .",
    "we take the relative entropy @xmath28\\ ] ] as a measure of this deviation ( see appendix  [ app : relative_entropy ] ) .    note",
    "that ( i ) is a constraint and ( ii ) and ( iii ) are conflicting optimization targets .",
    "weighing both the expected cost and the relative entropy , we arrive at the following problem :    [ prob : reoptimization ] let @xmath29 .",
    "find a probability measure @xmath26 such that @xmath3 minimizes the functional @xmath30.\\ ] ]    let @xmath31 denote the set of all probability measures @xmath3 on @xmath32 such that @xmath26 .",
    "then @xmath31 is a convex set .",
    "the following result , which may also be found in @xcite , says pretty much everything there is to say about this general situation .",
    "[ thm : re_optimization ] let @xmath33 be the measure given by @xmath34 then    * for any @xmath35 , we have @xmath36    in particular ,    * @xmath37 is a strictly convex function over @xmath31 , * @xmath33 solves problem  [ prob : reoptimization ] , and * @xmath38    we prove ( i ) ; the other results follow immediately from the properties of relative entropy ( proposition  [ prop : reproperties ] ) .",
    "write @xmath39 . to see  ,",
    "note that for @xmath40 , @xmath41 hence @xmath42",
    "in this section , we consider the important special situation where all randomness is generated by a multi - dimensional brownian motion . changes of measure ( satisfying mild conditions ) may in this case be expressed as a girsanov type transformation ( see lemma  [ lem : girsanov_density_exists ] below ) .",
    "the stochastic process appearing in the exponent of the girsanov density will constitute the ` control process ' .",
    "another crucial observation is that the relative entropy of such a transformation is given by the squared control costs ( proposition  [ prop : re_equalities ] ( i ) ) .",
    "also we will derive different ( but obviously related ) explicit expressions for the optimal control process , namely as a time derivative of an expectation ( proposition  [ prop : re_equalities](iii ) ) , as a malliavin derivative ( theorem  [ thm : control_as_malliavin_derivative ] ) and in the following section as the derivative of a solution to a pde ( theorem  [ thm : linearized_hjb_equation ] ) .",
    "let @xmath0 be a probability space .",
    "let @xmath43 define a @xmath8-standard brownian motion in @xmath44 .",
    "let @xmath45 denote the filtration generated by @xmath46 , and let @xmath47 .",
    "let @xmath48 denote the set of @xmath44-valued progressively measurable stochastic processes @xmath49 such that the process @xmath50 defined by @xmath51 is a martingale .",
    "in particular if @xmath49 satisfies the _ novikov condition _ , @xmath52 < \\infty,\\ ] ] then @xmath53 ( see ( * ? ? ? * proposition 3.5.12 ) ) .",
    "the set @xmath48 will be called the _ set of controls _ and @xmath53 will be a _",
    "control process_. by girsanov s theorem ( * ? ? ?",
    "* theorem 3.5.1 ) , there exists a probability measure @xmath54 defined by the radon - nikodm derivative @xmath55 with respect to which the process @xmath56 is a standard brownian motion .",
    "let @xmath57 be a shorthand notation for @xmath58 .",
    "suppose a random variable @xmath1 indicating cost is provided , which is bounded from below and square integrable with respect to @xmath8 .",
    "define the _ cost function _ by @xmath59,\\ ] ] where the equality is a result of proposition  [ prop : re_equalities ] ( i ) .",
    "we consider the following problem .",
    "[ prob : dynamic_re_optimization ] find the _ optimal value _",
    "@xmath60 defined by @xmath61 and , provided it exists , a unique minimizer @xmath62 .",
    "note the similarity to problem  [ prob : reoptimization ] .",
    "the main difference between the two problems is that in problem  [ prob : dynamic_re_optimization ] , we restrict the possible probability measures to those parametrized by @xmath53 , through their density given by  .",
    "we are now ready to state the main result of this section .",
    "first we collect the ingredients .",
    "[ hyp : dynamic_re_optimization ]    * let @xmath0 be a probability space , on which a @xmath63-dimensional standard brownian motion @xmath64 is defined ; * let @xmath65 be the filtration generated by @xmath46 ; * let @xmath1 be an @xmath66-measurable random variable which is bounded from below and such that @xmath67 ; * let @xmath29 .",
    "[ thm : dynamic_re_optimization ] suppose the conditions of hypothesis  [ hyp : dynamic_re_optimization ] are satisfied .",
    "then there exists a square integrable , @xmath65 adapted stochastic process @xmath68 that solves problem  [ prob : dynamic_re_optimization ] . the corresponding probability measure @xmath69 is given by   and the optimal value is given by  .",
    "in particular @xmath33 is optimal among all probability measures that are equivalent with @xmath8 , in the sense that it solves problem  [ prob : reoptimization ] .",
    "if @xmath70 is another stochastic process solving problem  [ prob : dynamic_re_optimization ] then @xmath71 and @xmath70 are indistinguishable .",
    "before we prove theorem  [ thm : dynamic_re_optimization ] we provide a key lemma that is most helpful in establishing the existence of an optimal @xmath49 .",
    "[ lem : girsanov_density_exists ] suppose @xmath0 is a probability space on which a @xmath72-dimensional standard brownian motion @xmath73 is defined .",
    "let @xmath65 be the complete filtration ( i.e. including all null - sets ) generated by @xmath73 .",
    "suppose a nonnegative random variable @xmath74 is given such that    * @xmath75 ; * @xmath74 is @xmath66-measurable .",
    "* @xmath76 .",
    "let @xmath3 be a probability measure with density @xmath74 with respect to @xmath8 , so @xmath77 , and define the conditional density process @xmath78 by @xmath79 $ ] , @xmath80 .",
    "then @xmath81 is @xmath8-a.s .",
    "furthermore there exists a unique @xmath82-valued , progressively measurable stochastic process @xmath83 such that    * the following expression holds : @xmath84 * the process @xmath85 , @xmath80 ,",
    "is a @xmath3-brownian motion .",
    "* @xmath83 is square integrable , and @xmath86 = - { \\mathbb e}^{{\\mathbb q } } \\ln z$ ] .",
    "define a uniformly integrable martingale @xmath78 by @xmath87 $ ] . by the martingale representation theorem for brownian martingales (",
    "* theorem 18.10 ) , @xmath78 is @xmath8-a.s .",
    "continuous ( and therefore progressively measurable ) and there exists a unique @xmath82-valued , progressively measurable process @xmath88 satisfying @xmath89 , @xmath8-a.s .",
    "such that @xmath90 the condition @xmath91 implies that @xmath92 , @xmath8-almost surely . by lemma  [ lem : density_process_positive ] , @xmath93 for all @xmath80 , @xmath8-almost surely",
    "ignoring the @xmath8-null set where @xmath94 , define @xmath95 for @xmath80 .",
    "note that @xmath83 is progressively measurable , since @xmath88 and @xmath74 are . with this choice of @xmath83",
    ", we have @xmath96 , for @xmath80 , with solution  , @xmath8-almost surely .",
    "part ( b ) is then a direct consequence of girsanov s theorem ( see ( * ? ? ?",
    "* theorem 18.19 ) ) . since @xmath91",
    "we may compute @xmath97 as @xmath98= { \\mbox{$\\frac 1 2$}}{\\mathbb e}^{{\\mathbb q } } \\int_0^{\\infty } |\\theta_s|^2 \\ d s.\\ ] ]    in the proof of lemma  [ lem : girsanov_density_exists ] we used the following lemma .",
    "[ lem : density_process_positive ] let @xmath99 be a filtered probability space and let @xmath74 be a @xmath8-density on @xmath100 , i.e. @xmath101 , @xmath102 , @xmath8-a.s . and @xmath103 .",
    "if @xmath92 , @xmath8-a.s . , then @xmath104 , @xmath8-a.s . , where @xmath105 $ ] .",
    "define @xmath3 by @xmath77 . by (",
    "* lemma 18.17 ) @xmath106 , @xmath3-a.s . for all @xmath107 .",
    "therefore @xmath108 is a @xmath3-null set .",
    "we have @xmath109 = { \\mathbb p}(a ) = 0 $ ] . if @xmath110 , then @xmath111 for @xmath8-almost all @xmath112 , which is a contradiction .",
    "hence @xmath113 .",
    "the condition @xmath91 excludes the situation where @xmath114 . note in particular if @xmath115 , @xmath8-a.s .",
    "for some @xmath116 , then by lemma  [ lem : girsanov_density_exists ] , we have @xmath117 . to illustrate the condition @xmath91 we provide an example where this condition is not satisfied , and find that @xmath118 and therefore the definition of @xmath83 becomes problematic .",
    "this should not be surprising , since the expression   can not become zero for well - behaved ( i.e. square integrable ) @xmath83 .",
    "suppose , for some @xmath119 and a standard brownian motion @xmath120 , @xmath121 where @xmath122 is a normalizing constant and @xmath123 .",
    "note that @xmath114 and hence @xmath124 .",
    "we compute @xmath125 = k \\left .",
    "{ \\mathbb q}(b_{t - t } \\geq a - x ) \\right|_{x = b_t } = \\frac k { \\sqrt{2 \\pi } } \\int_{\\frac{a -b_t}{\\sqrt{t - t}}}^{\\infty } \\exp\\left(-\\xi^2/2 \\right ) \\",
    "d \\xi , \\quad 0 \\leq t",
    "< t\\ ] ] and @xmath125 = \\left\\ { \\begin{array}{ll } 1 \\quad & \\mbox{if } \\",
    "b_t \\geq a \\\\ 0 \\quad & \\mbox{otherwise}.\\end{array } \\right . \\quad \\mbox{for $ t \\geq t$.}\\ ] ]    the following lemma will be used to establish uniqueness of the solution .",
    "[ lem : uniqueness_u ] suppose @xmath49 and @xmath70 are @xmath44-valued stochastic processes in @xmath48 .",
    "then @xmath126 in particular , if @xmath127 then @xmath49 and @xmath70 are indistinguishable .",
    "we compute , for simplicity in the case @xmath128 , @xmath129 = { \\mathbb e}^u \\left [ \\ln \\left ( \\frac { d { \\mathbb p}^u}{d { \\mathbb q } } \\frac{d { \\mathbb q}}{d{\\mathbb p}^v } \\right ) \\right ] \\\\ & = { \\mathbb e}^u \\left [ \\int_0^{\\infty } u_s \\ d w_s - { \\mbox{$\\frac 1 2$}}\\int_0^{\\infty } u_s^2 \\ d s -\\int_0^{\\infty } v_s \\ d w_s + { \\mbox{$\\frac 1 2$}}\\int_0^{\\infty } v_s^2 \\ ds   \\right ] \\\\ & = { \\mathbb e}^u \\left [ \\int_0^{\\infty } u_s \\ d w_s^u + { \\mbox{$\\frac 1 2$}}\\int_0^{\\infty } u_s^2 \\ d s - \\int_0^{\\infty } v_s \\ d w_s^u - \\int_0^{\\infty } u_s v_s \\",
    "d s + { \\mbox{$\\frac 1 2$}}\\int_0^{\\infty } v_s^2 \\right ] \\\\ & = { \\mathbb e}^u \\int_0^{\\infty } ( u_s - v_s)^2 \\ ds.\\end{aligned}\\ ] ]    as already noted , problem  [ prob : dynamic_re_optimization ] is a version of problem  [ prob : reoptimization ] but restricted to the set of probability measures with density @xmath54 for @xmath53 .",
    "so if we can find a square integrable @xmath53 for which @xmath54 has the density function given by  , i.e. one that solves problem  [ prob : reoptimization ] because of theorem  [ thm : re_optimization ] , then it only remains to show uniqueness of such a @xmath49 .",
    "therefore we simply define our candidate density function @xmath130 by  .",
    "note that @xmath130 is @xmath8-square integrable since @xmath1 is bounded from below .",
    "note that @xmath131 since @xmath1 is bounded from below . since @xmath132 it follows that @xmath133 , so that @xmath134",
    ". hence @xmath135 by lemma  [ lem : girsanov_density_exists ] there exists a square integrable , adapted , @xmath44-valued stochastic process @xmath71 such that @xmath136 $ ] has the form  . since by definition @xmath137 is a martingale , @xmath68 .",
    "by lemma  [ lem : uniqueness_u ] , @xmath71 is unique up to indistinguishability .",
    "the expression for the optimal value follows directly from theorem  [ thm : re_optimization ] .",
    "here we give some useful equalities , which hold for any @xmath53 ( so in particular for @xmath71 ) .    [",
    "prop : re_equalities ] the following relations hold for any @xmath53 .",
    "* @xmath138 $ ] ; * @xmath139 = z_t^u w_t + \\int_t^{r } { \\mathbb e}^{{\\mathbb q } } [ u_s z_s^u |\\mathcal f_t ] \\ d s$ ] for @xmath140 ; * @xmath141 \\right|_{r = t}}{z_t^u }   = \\frac{\\left .",
    "\\frac{d}{d r } { \\mathbb e}^{{\\mathbb q } } [ w_r z^u_r | \\mathcal f_t ] \\right|_{r = t}}{z_t^u}$ ] a.s .",
    "for @xmath80 ;    ( i ) : this is a direct consequence of lemma  [ lem : uniqueness_u ] , by taking @xmath142 .",
    "( ii ) : in the remainder of the proof we fix @xmath53 and omit the superscripts @xmath49 in @xmath143 etc .",
    "let @xmath80 and @xmath144 .",
    "define a stochastic process @xmath145 by @xmath146 and note that @xmath147 satisfies the equation @xmath148 for @xmath149 .",
    "the process @xmath150 is the stochastic exponential of @xmath151 , so @xmath152 . then using it s formula , @xmath153 so that @xmath154 & = { \\mathbb e}^{{\\mathbb q } } \\left [ z_{\\infty } y_{\\infty } | \\mathcal f_t \\right ] = z_t y_t + \\int_t^{\\infty } { \\mathbb 1}_{s \\leq r } { \\mathbb e}^{{\\mathbb q } } [ u_s z_s |\\mathcal f_t ] \\ d s = z_t w_t + \\int_t^r { \\mathbb e}^{{\\mathbb q } } [ u_s z_s |\\mathcal f_t ] \\ d s.\\end{aligned}\\ ] ]    ( iii ) : taking the derivative of relation ( ii ) with respect to @xmath155 and evaluating at @xmath156 , @xmath157 \\right|_{r = t } = \\left . { \\mathbb e}^{{\\mathbb q } } [ u_r z_r |\\mathcal f_t ] \\right|_{r = t } = u_t z_t.\\ ] ]",
    "we illustrate the theory developed so far on a simple example .",
    "let @xmath123 .",
    "let @xmath159 denote a standard brownian motion and consider the process @xmath160 .",
    "( after a girsanov change of measure , @xmath161 will have become a brownian motion with drift . ) for the cost variable @xmath162 , we have @xmath163 . letting @xmath164 denote a normalization constant , we compute @xmath165 & = \\frac 1 k { \\mathbb e}^{{\\mathbb q } } \\left [ \\left .",
    "\\exp\\left(-{\\mbox{$\\frac 1 2$}}\\beta ( w_t - x^*)^2 \\right )",
    "\\right| x_t \\right ] = \\left .",
    "\\frac 1 k { \\mathbb e}^{{\\mathbb q } } [ \\exp(-{\\mbox{$\\frac 1 2$}}\\beta ( w_{t - t } + x - x^*)^2 ) ] \\right|_{x = w_t}\\\\ & = \\frac 1 { k\\sqrt{\\rho(t ) } } \\exp \\left ( -{\\mbox{$\\frac 1 2$}}\\beta ( w_t -x^*)^2 / \\rho(t ) \\right)\\end{aligned}\\ ] ] where @xmath166 , @xmath167 . in this computation",
    "we used the markov property of @xmath46 and lemma  [ lem : gaussian_identities ] ( i ) .    using it s formula , @xmath168 or , equivalently , @xmath169 where @xmath170 , @xmath167 , so that @xmath171 .    by theorem  [ thm : dynamic_re_optimization ]",
    ", the process @xmath71 minimizes @xmath172,\\ ] ] over @xmath53 , where @xmath161 satisfies the sde @xmath173 with @xmath174 a brownian motion under @xmath54 .",
    "this is a first example where the optimal solution is computed without application of the hamilton - jacobi - bellman equation .",
    "the procedure to obtain a solution to a relative entropy weighted optimization problem may in principle be repeated for other stochastic processes , such as jump processes .",
    "we will illustrate this for an example .",
    "let @xmath175 be a poisson random measure on @xmath176 with intensity measure @xmath177 satisfying @xmath178 .",
    "let the cost variable be given by @xmath179 , where @xmath180 , for @xmath167 .",
    "let @xmath29 . by theorem  [ thm : re_optimization ] , the density @xmath181 is optimal in the sense that it solves problem  [ prob : reoptimization ] .",
    "we wish to see what effect this change of density has on the dynamics .",
    "we compute @xmath182 & = \\exp(- \\beta x_t ) \\sum_{n=0}^{\\infty } { \\mathbb p}\\left(n([t , t ] , { \\mathbb r } ) = n\\right ) \\prod_{j=1}^n \\int_{{\\mathbb r } } \\exp \\left(-\\beta \\gamma(z )",
    "\\right ) \\nu(dz ) / \\nu({\\mathbb r } ) \\\\   & = \\exp(-\\beta x_t ) \\sum_{n=0}^{\\infty }   \\frac{{\\mathrm e}^{-\\nu({\\mathbb r } ) ( t - t ) } ( \\nu(r)(t - t))^n}{n ! }",
    "\\left(\\int_{{\\mathbb r } } \\exp \\left(-\\beta \\gamma(z )",
    "\\right ) \\nu(dz ) / \\nu({\\mathbb r } ) \\right)^n \\\\ & = \\exp(-\\beta x_t -\\nu({\\mathbb r})(t - t ) ) \\sum_{n=0}^{\\infty } \\frac{\\left(\\int_{{\\mathbb r } } \\exp \\left(-\\beta \\gamma(z ) \\right ) \\nu(dz ) ( t - t ) \\right)^n}{n ! } \\\\ & = \\exp\\left(-\\beta \\int_0^t \\int_{{\\mathbb r } } \\gamma(z ) \\ n(ds , dz ) + ( t - t ) \\int_{{\\mathbb r } } \\left\\ { \\exp(-\\beta \\gamma(z ) ) - 1 \\right\\ } \\nu(dz ) \\right).\\end{aligned}\\ ] ] for the optimal density process",
    "this gives @xmath183 / { \\mathbb e}^{{\\mathbb q}}[\\exp(-\\beta c ) ] = \\exp\\left(-\\beta \\int_0^t \\int_{{\\mathbb r } } \\gamma(z ) \\",
    "n(ds , dz ) -t \\int_{{\\mathbb r } } \\left\\ { \\exp(-\\beta \\gamma(z ) ) - 1 \\right\\ } \\nu(dz ) \\right ) .\\ ] ] an application of girsanov s theorem for jump processes ( * ? ? ?",
    "* theorem 1.35 ) gives that the random measure @xmath184 is the compensated random measure corresponding to @xmath185 under the optimal probability measure @xmath33 ( as prescribed by theorem  [ thm : dynamic_re_optimization ] ) .",
    "in particular , the intensity measure of @xmath185 under @xmath33 is @xmath186 .",
    "the relative entropy of @xmath33 with respect to @xmath8 may be computed as @xmath187 \\\\ & = { \\mathbb e}^ * \\left [ -\\beta t   \\int_{{\\mathbb",
    "r } } \\gamma(z ) \\exp(-\\beta \\gamma(z ) ) \\nu(dz )   -t \\int_{{\\mathbb r } } \\left\\ { \\exp(-\\beta \\gamma(z ) ) - 1 \\right\\ } \\nu(dz )   \\right ] \\\\ & = t \\int_{{\\mathbb r } } 1 - \\exp(-\\beta \\gamma(z ) ) ( 1 + \\beta \\gamma(z))\\ \\nu(dz).\\end{aligned}\\ ] ]    a numerical experiment is shown in figure  [ fig : levy ] .",
    "note that the expression @xmath188 appears again in the expression for the optimal intensity measure . in this simple example",
    "explicit computations are possible .",
    "we aim to extend the theory developed in this paper to general stochastic processes in the near future .",
    "let @xmath189 be a probability space on which a @xmath63-dimensional standard brownian motion @xmath159 is defined , with @xmath190 .",
    "let @xmath65 be the filtration generated by @xmath46 .",
    "in this section we write @xmath191 for the malliavin derivative of an @xmath192-measurable random variable @xmath193 at time @xmath194 and @xmath195 for the domain of @xmath13 in @xmath196 , @xmath197 .",
    "see @xcite for details . the following lemma is a consequence of  ( * ? ? ?",
    "* proposition 1.2.8 ) .",
    "[ lem : conditional_expectation_and_malliavin_derivative ] suppose @xmath198 .",
    "then @xmath199 \\in \\mathbb d^{1,2}$ ] for @xmath167 and @xmath200 = { \\mathbb e}^{{\\mathbb q}}[d_t f|\\mathcal f_t]$ ] .",
    "[ thm : control_as_malliavin_derivative ] suppose @xmath3 is absolutely continuous with respect to @xmath8 with radon - nikodm derivative @xmath201 , where @xmath74 is @xmath192-measurable for some @xmath123 .",
    "let @xmath105 $ ] , @xmath167 , denote the density process .",
    "suppose @xmath202 .",
    "then @xmath203 for all @xmath167 .",
    "define a stochastic process @xmath70 by @xmath204}{{\\mathbb e}^{{\\mathbb q } } [ z | \\mathcal f_t ] } , \\quad 0 \\leq t \\leq t.\\ ] ] then @xmath205 .",
    "it is interesting to compare expression   to proposition  [ prop : re_equalities ] ( iii ) .",
    "note that @xmath206 = { \\mathbb e}^{{\\mathbb q } } [ d_s z_t | \\mathcal f_s ] { \\mathbb 1}_{[0,s]}(s ) = { \\mathbb e}^{{\\mathbb q}}[d_s z_t | \\mathcal f_s]\\quad \\mbox{for } \\ 0 \\leq s \\leq t \\in [ 0,t],\\ ] ] where the second equality is a consequence of lemma  [ lem : conditional_expectation_and_malliavin_derivative ] . by the clark - ocone representation formula (",
    "* proposition 1.3.14 ) @xmath207 \\ d w_s = 1 + \\int_0^t d_s z_s \\",
    "d w_s= \\int_0^t v_s z_s \\ d w_s\\ ] ] for @xmath208 . by the chain rule of malliavin calculus , (",
    "* proposition 1.2.3 ) , @xmath209 .",
    "using lemma  [ lem : conditional_expectation_and_malliavin_derivative ] again , we have @xmath210 = d_t { \\mathbb e}^{{\\mathbb q}}[z |\\mathcal f_t ] = d_t z_t$ ] which finishes the argument .",
    "an application of the chain rule of malliavin calculus also gives the following corollary .",
    "[ cor : control_as_malliavin_derivative ] suppose @xmath211 and let @xmath29 .",
    "then the stochastic process @xmath71 defined by @xmath212}{{\\mathbb e}^{{\\mathbb q } } \\left [ \\exp(-\\beta c ) | \\mathcal f_t \\right ] } , \\quad 0 \\leq t \\leq t,\\ ] ] solves problem  [ prob : dynamic_re_optimization ]",
    ".      we may apply corollary  [ cor : control_as_malliavin_derivative ] to the example of section  [ sec : example_brownian_bridge ] as an alternative way to compute the optimal control process @xmath71 . using the chain rule of malliavin calculus , @xmath214 and it is then straightforward to check ( using lemma  [ lem : gaussian_identities ] ( ii ) ) that @xmath215 / { \\mathbb e}^{{\\mathbb q } } \\left [ \\exp(-\\beta c ) | \\mathcal f_t \\right]\\ ] ] gives the same expression for @xmath216 as the one already obtained using it s formula .",
    "we will now apply the results of section  [ sec : control_as_malliavin_derivative ] to an example where it s formula fails .",
    "this example therefore shows the strength of the new approach .",
    "define @xmath218 and take @xmath219 for some @xmath123 .",
    "the optimal density function is @xmath181 and we wish to obtain the density process @xmath220 $ ] . for the distribution of @xmath221 we have ( by ( * ? ? ?",
    "* section 2.8.a ) ) @xmath222 conditional on @xmath223 , the event @xmath224 occurs when the maximum over @xmath225 $ ] does not exceed @xmath226 .",
    "this has the same probability as the event that the maximum over @xmath227 $ ] does not exceed @xmath228 , for @xmath229 , so @xmath230 for @xmath231 we compute @xmath232 therefore the density function of @xmath233 conditional on @xmath223 is equal to @xmath234    write @xmath235 $ ] .",
    "we will make use of the error function ( erf ) and complimentary error function ( erfc ) , defined by @xmath236 we compute @xmath237 = \\frac 1 k { \\mathbb e}^{{\\mathbb q } } \\left [ \\exp(-\\beta m_t ) | \\mathcal f_t \\right ] = \\frac 1 k { \\mathbb e}^{{\\mathbb q } } \\left [ \\exp(-\\beta m_t ) { \\mathbb 1}_{m_t = m_t } | \\mathcal f_t \\right ] + \\frac 1 k { \\mathbb e}^{{\\mathbb q } } \\left [ \\exp(-\\beta m_t ) { \\mathbb 1}_{m_t > m_t } | \\mathcal f_t \\right ] \\\\ & = \\frac 1 k \\exp(-\\beta m_t ) { \\mathbb q}(m_t = m_t | \\mathcal f_t ) + \\frac 1 k { \\mathbb e}^{{\\mathbb q } } \\left [ \\exp(-\\beta m_t ) { \\mathbb 1}_{m_t > m_t } | \\mathcal f_t \\right ] \\\\",
    "& = \\frac 1 k \\left [ \\exp(-\\beta m_t ) \\left(\\frac 2 \\pi \\right)^{1/2}\\int_0^{\\frac{m_t - w_t}{\\sqrt{t - t } } } \\exp ( - \\xi^2/2 ) \\ d \\xi + \\left ( \\frac 2 { \\pi(t - t ) } \\right)^{1/2 } \\int_{m_t}^{\\infty } \\exp(-\\beta \\xi ) \\exp\\left ( - \\frac{(\\xi - w_t)^2}{2 ( t - t ) } \\right ) \\",
    "d \\xi \\right ] \\\\ & = \\frac 1 k \\left [ \\exp(-\\beta m_t ) { \\mathrm{erf } \\ , } \\left ( \\frac{m_t - w_t}{\\sqrt{2 ( t - t ) } } \\right ) +   \\exp \\left ( -\\beta w_t + { \\mbox{$\\frac 1 2$}}\\beta^2(t - t ) \\right ) { \\mathrm{erfc } \\ , } \\left ( \\frac{m_t - w_t + \\beta(t - t)}{\\sqrt{2 ( t - t ) } } \\right ) \\right]\\end{aligned}\\ ] ] an expression for the malliavin derivative of @xmath233 is available : @xmath238}(t)$ ] , where @xmath239 is the a.s .",
    "unique point where @xmath46 attains its maximum .",
    "see ( * ? ? ?",
    "* exercise 1.2.11 ) .",
    "hence by the chain rule for the malliavin derivative , @xmath240}(t).\\ ] ] note that @xmath241 if and only if @xmath242 .",
    "we can compute @xmath243 & = - \\frac{\\beta}{k } { \\mathbb e}^{{\\mathbb q } } \\left [ \\left .",
    "\\exp(-\\beta m_t ) { \\mathbb 1}_{\\ { m_t > m_t \\ } } \\right| \\mathcal f_t \\right ] \\\\   & = -\\frac { \\beta}{k } \\left ( \\frac{2}{\\pi(t - t)}\\right)^{1/2 } \\int_{m_t}^{\\infty }   \\exp \\left ( -\\beta \\xi - \\frac{(\\xi - w_t)^2}{2 ( t - t ) } \\right ) \\",
    "d \\xi \\\\ & = - \\frac { \\beta } k \\exp \\left ( - \\beta w_t + { \\mbox{$\\frac 1 2$}}\\beta^2 ( t - t ) \\right ) { \\mathrm{erfc } \\ , } \\left ( \\frac{m_t - w_t + \\beta(t - t)}{\\left ( 2 ( t - t ) \\right)^{1/2 } } \\right).\\end{aligned}\\ ] ] by theorem  [ thm : control_as_malliavin_derivative ] , we conclude that for @xmath244 we have @xmath245 so that @xmath216 is the stochastic process which solves the optimization problem @xmath246 = { \\mathbb e}^u \\left [ \\max_{0 \\leq t \\leq t } \\left(w_t^u + \\int_0^t u_s \\ d s\\right )   + \\frac 1 { 2 \\beta } \\int_0^t u_s^2 \\right],\\ ] ] with @xmath247 a brownian motion under @xmath54 .",
    "note that @xmath248 and @xmath249 , and hence @xmath216 , are explicitly given in terms of @xmath194 , @xmath250 and @xmath221 .",
    "the process @xmath71 may be written ` succintly ' as @xmath251 , where @xmath252    an illustration of this control policy and its effect on a sample path of @xmath174 and @xmath253 is provided in figure  [ fig : minimizing_maximum ] .    ) .",
    "below : the control policy corresponding to the controlled brownian motion . ]",
    "this example illustrates how the theory applies to non - markovian processes , and therefore provides a method that applies where a naive application of dynamic programming ( i.e. the hjb equation ) would fail .    in this particular case , by augmenting the state to @xmath254",
    "the optimal control becomes markovian , but this requires a nonstandard application of the hjb equation ; see also remark  [ rem : skorohod ] and @xcite for a detailed analysis in a closely related class of examples .",
    "in this section we will link the theory of the previous sections to the classical theory of stochastic optimal control @xcite .",
    "we will list some instances of optimal control problems and explain how the theory of the previous sections can be applied .",
    "assume as before the conditions of hypothesis  [ hyp : dynamic_re_optimization ] , defining a filtered probability space @xmath255 on which a @xmath63-dimensional standard brownian motion @xmath46 is defined . in classical stochastic optimal control theory",
    "the notion of state is fundamental .",
    "the dynamics of the state will be described by a stochastic differential equation . for this",
    "we require the following additional assumptions .",
    "[ hyp : unique_solution_sde ] suppose @xmath256 and @xmath257 are    * _ locally lipschitz _ , i.e. for every bounded set @xmath258 and @xmath123 there exists a constant @xmath259 such that latexmath:[\\[|b(t , x ) - b(t , y)| \\leq k |x - y| , \\quad \\mbox{and } \\quad     * _ monotone _ in the following sense : for every @xmath123 there exists a positive constant @xmath259 such that for all @xmath261 and @xmath262 $ ] , @xmath263    note that the monotonicity condition ( ii ) above is less restrictive than the linear growth condition which is more commonly found in the literature .    under these assumptions , we will consider for @xmath261 the stochastic differential equation @xmath264 we may think of   as describing the _",
    "uncontrolled dynamics_. we make use of the following result on the existence of a unique strong solution to",
    ". see ( * ? ? ?",
    "* theorem 2.3.6 , theorem 2.4.1 ) .    under the conditions of hypothesis",
    "[ hyp : unique_solution_sde ] , for every @xmath261 there exists a unique solution ( up to indistinguishability ) , denoted by @xmath265 , to   satisfying @xmath266 for every @xmath123 and some constant @xmath267 depending on @xmath268 .",
    "such a process @xmath269 is called a _",
    "markov diffusion process_. note that in general the markov process is time inhomogeneous since the dynamics depends explicitly on time through @xmath270 and @xmath271 .",
    "if @xmath270 and @xmath271 do not depend explicitly on @xmath194 then @xmath269 is called a _ time homogeneous markov diffusion process_.    we consider the _ set of markov controls _ @xmath272 which consists of mappings @xmath273 such that for all @xmath261 the stochastic process @xmath274 defined by @xmath275 is in @xmath48 .",
    "for @xmath276 we will write @xmath277 , with @xmath274 as above , and similarly @xmath278 . note that @xmath279 depends on @xmath280 through the definition of @xmath281 .    for @xmath276 ,",
    "the process @xmath265 also satisfies the following sde , of which we can think of as the _ controlled dynamics _ :",
    "@xmath282 where by girsanov s theorem ( * ? ?",
    "* corollary 3.5.2 ) , as before , the process @xmath283 defined by @xmath284 is a standard brownian motion with respect to the probability measure @xmath279",
    ".    we will specialize to the situation where the cost random variable @xmath1 also depends on the initial condition and is a functional of the paths of the stochastic process @xmath269 for @xmath261 .",
    "we will write @xmath285 where @xmath286 for @xmath287 .",
    "the following examples of cost functionals are often used . here",
    "@xmath288 denotes any path in @xmath289 .    *",
    "_ finite time horizon problem _ : @xmath290 for some @xmath123 , with @xmath291 \\times { \\mathbb r}^n ; { \\mathbb r})$ ] , @xmath292 ; * _ infinite time horizon problem with exit from a region _ : @xmath293 , where @xmath294 with @xmath295 open , @xmath296 ;    the method outlined in the previous sections will enable us to find solutions to these problems , under certain conditions .",
    "these solutions will be compared to the solutions obtained by classical methods .",
    "define as before the _ total cost function _ by @xmath297,\\ ] ] for @xmath261 which is now specialized to markov controls @xmath276 .",
    "recall @xmath269 satisfies   with @xmath298 a standard brownian motion under @xmath279 . in this setting , we consider the following problem .",
    "[ prob : re_control ] find the value function @xmath299 , defined by @xmath300 and , in case it exists , the optimal control policy @xmath301 which satisfies @xmath302    it should now be clear that solving the relative entropy weighted problem  [ prob : re_control ] is equivalent to solving a classical stochastic optimal control problem with quadratic control costs and with dynamics given by  .    [ rem : skorohod ] we can not always expect to find markov controls that are optimal in the sense of the more general problem  [ prob : dynamic_re_optimization ] .",
    "for example , in section  [ sec : minimize_maximum ] , where a solution was computed for minimization of @xmath303 , the optimal stochastic process depends not only on time @xmath194 and the current state @xmath250 but also on the running maximum @xmath221 . by augmenting the state to @xmath254 the optimal control becomes markovian .",
    "however , the time evolution of @xmath304 can not be put in the shape of  .",
    "in fact , the process @xmath161 defined by @xmath305 , @xmath167 , has the same probability law as a brownian motion reflected at the origin and satisfies a skorohod equation ; see ( * ? ? ?",
    "* section 3.6.c ) .",
    "often in the theory of stochastic optimal control , the cost function @xmath306 is defined to depend explicitly on some starting time @xmath307 .",
    "this explicit dependence on starting time is useful in obtaining the optimal control through the dynamic programming principle ( i.e. the hamilton - jacobi - bellman equation ) .",
    "since we do not use the dynamic programming principle we do not need to consider the value function for all initial times @xmath307 . in our setup",
    "we always have @xmath308 to avoid confusion , without loss of generality .      in this section",
    "sufficient conditions are obtained in order for the optimal control @xmath71 to be a markov policy , so that @xmath309 .",
    "let @xmath295 be open and let @xmath310 denote the exit time from @xmath311 .",
    "note that @xmath312 is a stopping time . we will study two cases : the infinite horizon problem and the time homogeneous exit problem .",
    "let @xmath190 and define the stopping time @xmath313 .",
    "let @xmath314 with @xmath315 so that the integral exists and is finite .",
    "let @xmath316 denote the _ kolmogorov backward operator _ corresponding to  , given by @xmath317^{ij } \\frac{\\partial^2 f}{\\partial x^i x^j}(t , x)\\ ] ] for @xmath318 \\times { \\mathbb r}^n ; { \\mathbb r})$ ] .",
    "[ thm : linearized_hjb_equation ] let hypothesis  [ hyp : unique_solution_sde ] be satisfied .",
    "suppose that @xmath319 \\times { \\mathbb r}^n ; { \\mathbb r})$ ] satisfies the pde @xmath320 , x \\in g , \\\\",
    "y(t , x ) = \\exp(-\\beta \\psi(t , x ) ) , \\quad & x \\in \\partial g \\",
    "\\mbox{or } \\",
    "t = t. \\end{array } \\right.\\ ] ] suppose , @xmath8-almost surely , @xmath321 for @xmath322 and @xmath323 .",
    "define @xmath324 for all @xmath325 , g)$ ] for which @xmath326 .",
    "then any measurable extension of @xmath327 to @xmath328 \\times g$ ] solves problem  [ prob : re_control ] .",
    "furthermore the value function of problem  [ prob : re_control ] is given by @xmath329 , for @xmath323 .",
    "fix @xmath261 and omit the ` @xmath280'-superscripts in @xmath330 , @xmath331 etc and the ` @xmath332'-superscript in @xmath327 .",
    "define @xmath333 .",
    "then by it s formula , @xmath334 it may be checked that a solution for this sde is given by @xmath335 by the boundary condition , @xmath336 multiplying by @xmath337 yields @xmath338 by taking expectations , @xmath339 by the proof of theorem  [ thm : dynamic_re_optimization ] we may conclude that @xmath340 solves problem  [ prob : dynamic_re_optimization ] and therefore that @xmath341 solves problem  [ prob : re_control ] .",
    "assume for simplicity that @xmath342 and @xmath270 are globally lipschitz continuous and bounded , @xmath88 is bounded uniformly hlder continuous and @xmath343 is bounded continuous on @xmath344 \\times \\delta g ) \\cup ( t \\times \\overline g).$ ] note that under the following further assumptions   has a unique solution that may be represented by the feynman - kac formula , @xmath345,\\ ] ] ( where @xmath346 denotes expectation with respect to the law of @xmath161 satisfying   with initial condition @xmath347 ) :    * nondegenerate case : @xmath311 is open and bounded with smooth boundary , or @xmath348 , @xmath349 is uniformly elliptic , i.e. @xmath350 for some @xmath351 and all @xmath352 , @xmath262 $ ] and @xmath353 ( see ( * ? ? ?",
    "* theorems 2.8.2 and 2.8.3 ) ) ; or * degenerate case : @xmath348 , @xmath354 and @xmath343 are homogeneous in @xmath194 , in which case the markov semigroup corresponding to @xmath161 is a feller - dynkin semigroup corresponding to @xmath161 ( see ( * ? ? ?",
    "* theorems 21.11 and 24.11 ) ) .    in case",
    "holds , it follows immediately ( by boundedness of @xmath88 and @xmath343 ) that @xmath355 on its domain .",
    "the expression   may be seen as a linearized version of the hamilton - jacobi - bellman ( hjb ) equation .",
    "this linearized hjb equation may alternatively be obtained from the nonlinear hjb equation ( * ? ? ?",
    "* theorem 4.1 ) , by applying a logarithmic transform ( see @xcite ) .",
    "this observation formed the starting point for the research of this paper .",
    "note that if we do not restrict ourselves to markov controls , the value function is given by  , i.e. @xmath356 , which may be compared to  .",
    "theorem  [ thm : linearized_hjb_equation ] is therefore partly a restatement of the feynman - kac solution to the corresponding dirichlet and cauchy problems ( * ? ? ?",
    "* section 5.7 ) ( and the proof is largely similar ) . but note that the theorem also states the existence of a markov control and gives an expression for the optimal markov control @xmath327 in this case .",
    "we will now consider the time homogeneous case where @xmath270 and @xmath271 do not depend on @xmath194 , with @xmath311 a bounded open subset of @xmath9 with smooth boundary @xmath357 .",
    "let @xmath316 denote the time homogeneous kolmogorov backward operator corresponding to  , given by @xmath358^{ij } \\frac{\\partial^2 f}{\\partial x^i \\partial x^j } ( x)\\ ] ] for @xmath359 .",
    "define the cost random variable by @xmath360 .",
    "analogously to theorem[thm : linearized_hjb_equation ] the following result can be established .",
    "let hypothesis  [ hyp : unique_solution_sde ] be satisfied .",
    "suppose that @xmath361 satisfies the pde @xmath362 suppose furthermore that @xmath363 for @xmath353 .",
    "define @xmath364 for all @xmath323 .",
    "then @xmath327 solves problem  [ prob : re_control ] .",
    "furthermore the value function of problem  [ prob : re_control ] is given by @xmath365 , for @xmath323 .",
    "in particular , @xmath366 may be expressed as @xmath367 = { \\mathbb e}^{{\\mathbb q } } \\left [ \\exp \\left ( -\\beta \\int_0^{\\tau^x } \\phi(x_s^x ) \\",
    "d s - \\beta \\psi(x_{\\tau}^x ) \\right ) \\right].\\ ] ]    for example in the case of bounded @xmath311 , with uniform ellipticity of @xmath368 , with @xmath369 and @xmath270 globally lipschitz , @xmath88 bounded uniformly hlder continuous and nonnegative , and @xmath343 continuous on @xmath357 , by ( * ? ? ? * theorem 2.8.1 ) a unique solution to   exists and is hence given by   guaranteeing positivity of @xmath366 on @xmath370 .",
    "suppose , for all @xmath373 , that @xmath374 .",
    "we then say that @xmath177 is _ absolutely continuous _ with respect to @xmath371 .",
    "this is denoted as @xmath375 .",
    "if both @xmath376 and @xmath375 then we say that @xmath371 and @xmath177 are _",
    "equivalent_.      if @xmath375 then there exists a random variable @xmath377 such that @xmath378 this variable @xmath161 is called a version of the _ radon - nikodm derivative _ of @xmath177 relative to @xmath371 on @xmath372 , and different versions agree @xmath371-almost surely .",
    "we write @xmath379    we call a @xmath380-measurable nonnegative random variable @xmath381 a _ density ( function ) _ with respect to @xmath371 if there exists a probability measure @xmath177 that has radon - nikodm derivative @xmath381 relative to @xmath371 .",
    "relative entropy is also known as _ kullback - leibler divergence _ ; for this paper we use the term ` relative entropy ' since it seems to be better known in the mathematics community . in general , @xmath383 is not symmetric in @xmath371 and @xmath177 .",
    "the following proposition summarizes some useful properties of relative entropy .",
    "in particular , it indicates that relative entropy is a good indication of how similar two probability measures are .      *",
    "the relative entropy @xmath383 is well - defined ( i.e. the integrals exist ) and assumes its values within @xmath384 $ ] . *",
    "@xmath385 if and only if @xmath386 on @xmath387 , @xmath371-almost everywhere . * @xmath383 is strictly convex in @xmath371 .",
    "[ lem : gaussian_identities ] suppose @xmath147 is a real - valued random variable that is normally distributed with mean @xmath390 and variance @xmath391 .",
    "let @xmath392 and @xmath393 such that @xmath394 .",
    "then    * @xmath395 = \\frac 1 { \\rho^{1/2 } } \\exp \\left ( -\\frac { \\gamma \\mu^2 - 2 \\alpha \\mu - \\alpha^2 \\sigma^2}{2 \\rho } \\right)$ ] , * @xmath396 = \\frac { \\mu } { \\rho^{3/2 } } \\exp \\left ( -\\frac{\\gamma \\mu^2}{2 \\rho } \\right)$ ] .",
    "m.  h.  a. davis .",
    "martingale methods in stochastic control . in _",
    "stochastic control theory and stochastic differential systems ( proc .",
    "workshop , deutsch .",
    "bonn , bad honnef , 1979 ) _ , volume  16 of _ lecture notes in control and information sci .",
    "_ , pages 85117 .",
    "springer , berlin , 1979 .",
    "wendell  h. fleming .",
    "logarithmic transformations and stochastic control . in _ advances in filtering and optimal stochastic control ( cocoyoc , 1982 )",
    "_ , volume  42 of _ lecture notes in control and inform .",
    "_ , pages 131141 .",
    "springer , berlin , 1982 ."
  ],
  "abstract_text": [
    "<S> we expand earlier results by bou and dupuis @xcite where stochastic control problems with a particular cost structure , involving a relative entropy term , are shown to admit a solution by means of a change of measure technique . </S>",
    "<S> we provide methods of computing the corresponding optimal control process explicitly . </S>",
    "<S> our results enables us to find solutions for optimal control problems to which the dynamic programming principle can not be applied . </S>",
    "<S> the argument is as follows . </S>",
    "<S> minimization of the expectation of a random variable with respect to the underlying probability measure , penalized by relative entropy , may be solved exactly . in the case where the randomness is generated by a standard </S>",
    "<S> brownian motion , this exact solution can be written as a girsanov density . an explicit expression for the control process </S>",
    "<S> may be obtained in terms of the malliavin derivative of the density process . </S>",
    "<S> the theory is applied to the problem of minimizing the maximum of a brownian motion ( penalized by the relative entropy ) . </S>",
    "<S> the link to a linear version of the hamilton - jacobi - bellman equation is made for the case of diffusion processes . </S>"
  ]
}