{
  "article_text": [
    "qkd is the art of distributing provably - secure cryptographic keys in an insecure communication network  @xcite . unlike conventional cryptography",
    ", the security of qkd is based on the laws of quantum physics and thus is guaranteed to be secure against any unforeseen technological and algorithmic developments , _ e.g. _ , quantum computing .",
    "for this reason , qkd has attracted an enormous amount of interest since its discovery , and is now one of the most widely studied research field in quantum information science .",
    "in fact , provably - secure commercial qkd systems are now available at retail  @xcite .",
    "a qkd system generally consists of two main phases , namely a quantum key establishment phase and a classical post - processing phase  @xcite .  in the first phase ,",
    "the users first create an unprocessed ( raw ) key pair by performing local measurements on quantum signals which are exchanged via an untrusted quantum channel .  at this point ,",
    "the pair of raw keys are weakly correlated  due to noise in the quantum channel  and are partially secure .  to correct the errors and remove the adversary s information about the raw key pair",
    ", the users run an information reconciliation step and a privacy amplification step .",
    "the former requires the user to exchange a certain amount of public information about the key pair  which is then compensated for in the privacy amplification step .  finally , after the classical post - processing phase , the users are left with a correct and secure key pair  ( for details , see refs .",
    "@xcite ) .",
    "-4 mm    it is clear that information reconciliation is an important step of qkd , for it is necessary to correct the errors introduced by the quantum channel ( or the adversary ) .  in practice , the information reconciliation step is typically implemented using an iterative method known as cascade  @xcite .",
    "the cascade method is based on the random shuffling and dichotomic search of discrepancies based on announcements of sub - block parities via communication over the authenticated channel .",
    "a number of possible improvements have been proposed , but most of them are very expensive in terms of communication  @xcite .",
    "that is , despite the fact that different sub - blocks can be treated in parallel  @xcite , the cascade is still a highly interactive algorithm as the dichotomic search requires multiple rounds of communication between users .",
    "interactivity of cascade - based information reconciliation procedure can cost significant amount of authentication resources together with time delays and workload in qkd systems .",
    "another popular information reconciliation scheme is forward error correction with ldpc codes  @xcite , which uses a single message containing syndrome calculated for particular block of sifted key  @xcite .",
    "however , this scheme could fail and penalize the secret key throughput due to its inability to perform the syndrome decoding procedure .",
    "such failures appear if the syndrome decoding , based on iterative belief propagation algorithm , does not converge in the predefined number of iterations ( _ e.g. _ it could be caused by an inappropriate choice of the code rate relative to actual number of discrepancies in raw keys ) .",
    "the problem with convergence differs the traditional ldpc code - based error correction methods  @xcite from the cascade , where the dichotomic search is performed as long as all the sub - blocks in all the shuffling rounds will contain odd numbers of errors .",
    "then cascade can be considered as a _ guaranteed convergence _ method ( see fig .",
    "[ fig : comparison ] ) .",
    "it is important to note that guaranteed convergence does not imply _ guaranteed reconciliation_. in the case of cascade some of sub - blocks still can contain positive numbers of undetected error after implementation of the reconciliation procedure  @xcite . the analogous problem remains for all the ldpc code - based reconciliation protocols , where belief propagation decoding sometimes could converge to inappropriate codeword . in order to solve this problem ,",
    "an additional step of verification with universal hashing is usually considered  @xcite .",
    "therefore , an important task for optimizing the workflow of qkd is to provide a regime with guaranteed convergence of the information reconciliation scheme , but without significant expenditure of authentication and time resources .",
    "this can be achieved by combining the key advantages of the aforementioned schemes and by introducing some interactivity into error correction with ldpc codes .",
    "this technique is known as blind information reconciliation  @xcite and can operate without an a priori estimation of the quantum bit error rate ( qber ) .",
    "however , the blind information reconciliation protocol still does not guarantee convergence even despite the fact that the probability of convergence is significantly increased  @xcite .",
    "it comes from the fact the protocol occupies limited reserve of symbol positions that could be disclosed in additional communication rounds . in the case ,",
    "where belief propagation decoding does not converge after the disclose of all of these positions , the parties have to discard the corresponding blocks of the sifted keys and do not use them for the distillation of the secret keys .    in this work ,",
    "we demonstrate further improvements of error correction combining ldpc codes and interactivity .",
    "we show that the use of interactivity  by introducing symmetry in operations of parties and the consideration of results of unsuccessful belief propagation decodings  allows one to perform an efficient and convergence guaranteed information reconciliation procedure .  for practical qkd parameters ,",
    "simulation results show an average of about @xmath0 improvement in the efficiency and an average of about @xmath1 improvement in the number of information requests .",
    "we refer to our proposed method as the symmetric blind information reconciliation . for",
    "a comparison of the proposed information reconciliation procedure with existing solutions , see fig .",
    "[ fig : comparison ] .",
    "the paper is organized as follows . in sec .",
    "[ sec : basic ] , we explain concepts of the information reconciliation procedure . in sec .  [",
    "sec : blind ] , we present an improvement of blind information reconciliation with ldpc codes .",
    "we summarize our results and consider an illustrative example in sec .",
    "[ sec : conclusion ] .",
    "the goal of the information reconciliation procedure is to correct the errors between alice s and bob s raw keys by disclosing some key information over a public ( authenticated ) channel .",
    "each bit value of the bob s string is a result of a transmission of the corresponding bit from the alice s string through a binary symmetric channel ( bsc ) .",
    "the crossover probability @xmath2 of the channel is also known as the quantum bit error rate ( qber ) .",
    "one of the ways to perform error correction is to use a ldpc code which is a linear code with a sparse @xmath3 binary parity check matrix  @xcite .",
    "alice multiplies the parity - check matrix by a block of the raw key of length @xmath4 to obtain a syndrome of length @xmath5 , which is then sent to bob .",
    "then , bob performs syndrome decoding operation on his side using his raw key , the same sparse matrix and estimated level of qber , which comes from the preceding procedures .    in the best case scenario , the syndrome decoding procedure outputs the same key as it is on the alice s side .",
    "nevertheless , there is still a probability of undetected frame error . to ensure that the error correction procedure was performed properly ,",
    "an additional stage of error verification is applied  @xcite .",
    "it can be done using a universal hashing technique  @xcite , which guarantees correctness with a probability depending on the length of the hash code .",
    "there is also a possibility that the syndrome decoding based on belief propagation procedure does not converge in the specified number of iterations . then the parties have to discard the processed blocks of the raw key and go to the next ones .",
    "an important characteristic of merit for a reconciliation protocol is its efficiency @xmath6 .",
    "it is given by the redundancy of disclosed information to the theoretical limit necessary for successful reconciliation  @xcite .",
    "for a given bsc it is characterized by the shannon binary entropy of the qber  @xcite : @xmath7 thus , the efficiency of the considered information reconciliation with ldpc code can be represented as @xmath8 where @xmath9 is a rate of the given ldpc code .",
    "the importance of the efficiency @xmath6 is based on a fact that the value of disclosed information have to be removed from the key in the stage of privacy amplification .",
    "we also note that the efficiency larger than unity does not guarantee successful decoding .",
    "in fact , it depends on the specific parity - check matrix , the maximal number of iteration in decoding procedure and other factors .",
    "the straightforward implementation of the ldpc error correction suffers from the following drawback .",
    "the efficiency parameter @xmath6 is fixed by the dimension of the parity check matrix and the current level of the qber , according to eq .",
    "( [ eq : ffix ] ) .",
    "a naive way to perform information reconciliation with the desired efficiency is to choose or construct another parity - check matrix with a new rate , _",
    "i.e. _ , @xmath10 ratio .",
    "two elegant ways known as shortening and puncturing have been proposed to adjust the rate of the ldpc code to the desirable efficiency by modification of encoding and decoding vectors rather than through the parity check matrix  @xcite .",
    "the main idea is to perform syndrome coding and decoding with extended keys of length @xmath4 obtained from the original raw keys of length @xmath11 , by padding them with @xmath12 shortened and @xmath13 punctured bits .",
    "the shortened symbols are the ones which have values exactly known by alice and bob , as well as by the adversary .",
    "the values of punctured bits come from true random number generators ( trng ) , independently of the both sides . in this way ,",
    "the shortened ( punctured ) bits serve for lowering ( raising ) the average discrepancy between the extended keys .",
    "the positions for shortened and punctured bits could be chosen using a synchronized pseudo - random number generator ( prng ) , or depending on a particular parity - check matrix ( for example , via the untainted puncturing method  @xcite ) .",
    "after the construction of the extended keys , the parties perform information reconciliation in the same way as discussed above .",
    "the difference is that in the case of a successful decoding , bob excludes shortened and punctured bits from the result of decoding procedure to obtain a corrected version of his raw key .",
    "the efficiency of the described scheme is defined in the following form : @xmath14{h_\\mathrm{b}}(q)}.\\ ] ] thus , the artificial reduction ( increasing ) of discrepancies between extended keys by shortened ( punctured ) bits allows one to implement fine - tuning of efficiency in order to keep a tradeoff between a probability of failure for belief propagation decoding and information leakage .",
    "the above scheme implies a single message sent from alice to bob only .",
    "this is a crucial advantage as compared to the cascading method , which is highly interactive  @xcite .",
    "however , the cascading method demonstrates rather good efficiency , particularly at low values of the qber  @xcite .  also , cascade methods do not suffer from the inability to perform the error correction ,",
    "i.e. _ , it always converges to some result .",
    "therefore , the cascading method is widely used as an important benchmark for comparison of information reconciliation protocols  @xcite .    to combine `` the best of two worlds '' by linking interactivity and ldpc codes , a blind information reconciliation technique",
    "was suggested  @xcite .",
    "its title comes from the fact that it can operate without an a priori estimation of the qber ( a rough estimation of the qber for the belief propagation decoding one can be obtained directly from syndromes  @xcite ) .",
    "blind reconciliation is based on the hybrid automatic repeat request technique  @xcite with the ldpc codes with an essential presence of punctured symbols .",
    "the crucial difference is that , in the case of a decoding failure , parties try to implement the decoding procedure again by turning a number of punctured symbols into shortened ones instead of discarding their blocks .",
    "the values of these bits are transferred via the classical channel after a corresponding bob s request .",
    "the efficiency of the procedure after @xmath15 number of additional communication rounds is given by  @xcite : @xmath16{h_\\mathrm{b}}(q)},\\ ] ] where @xmath17 and @xmath18 are the initial number of punctured and shortened bits , @xmath19 is the number of disclosed bits in each additional round of blind reconciliation .",
    "the meaning of expression   in comparison with expression   is as follows : if the decoding procedure according to the rate adaptive scheme with efficiency   does not converge , then the parties increase @xmath6 in each additional communication round of the blind reconciliation to increase the probability of convergence .",
    "the main advantage of the blind reconciliation over rate - adaptive scheme is that it allows one to adjust the efficiency to the actual error ratio , which can significantly fluctuate around the average qber . in refs .",
    "@xcite it was shown the gradual disclosing of information can notably lower the mean value of @xmath6 together with frame error rate ( fer ) .",
    "these are benefits obtained by price of introducing of additional interactivity ( see fig .",
    "[ fig : comparison ] ) .",
    "we suggest an improvement of blind information reconciliation with ldpc codes .",
    "the proposed technique allows one to overcome the drawbacks of the aforementioned information reconciliation schemes by providing guaranteed belief propagation - based decoding with decreased information leakage and decreased number of communication rounds .",
    "our approach is based on applying information reconciliation with ldpc codes in a symmetric way . in particular , it consists of the following general steps ( the detailed description of the procedure is given in methods ) .",
    "first , in analogy to the rate - adaptive scheme , the parties choose the numbers and positions of the shortened and punctured bits and extend their blocks of raw keys .",
    "second , both alice and bob compute the syndrome of their extended raw keys and share them with each other . then they perform belief propagation decoding . in the case of success , one party ,",
    "say bob , correct the errors , and the procedure proceeds to the verification stage . in the case of a failure , the parties exchange the values of the fixed number of bits having maximal uncertainty according to log - likelihood ratio ( llr ) .",
    "after that , alice and bob repeat the belief propagation decoding procedure with the updated list of shortened and punctured positions . in this respect ,",
    "the proposed symmetric blind reconciliation is similar to the standard blind reconciliation .",
    "the novel ingredient is that the positions of additionally disclosed bits come not from the punctured positions but are decidedly indicated by unsuccessful belief propagation decoding algorithm .",
    "this removes the restrictions on a number of additionally disclosed bits and also makes it possible to perform interactive ldpc code - based reconciliation even in the absence of punctured bits .",
    "the latter allows the adjustment of current sets of ldpc codes to a broad range of qber values ( see appendix a ) .",
    "we also note that that in contrast to the standard blind reconciliation protocol , where the parties use two consecutive messages in each of communication rounds ( the request and the corresponding answer ) , in the symmetric blind reconciliation the messages between parties are transferred simultaneously    the convergence of proposed method is formally guaranteed by the fact that , in the worst case scenario , the parties reveal the entire extended key .",
    "clearly , in this case the block will be useless for the secret key distillation .  in practice",
    ", the convergence takes place after a relatively small number of additional communication rounds .",
    "the efficiency of the suggested method is given by : @xmath20{h_\\mathrm{b}}(q)},\\ ] ] where @xmath17 and @xmath18 is the initial number of punctured and shortened bits , @xmath15 is the number additional information reconciliation rounds , and @xmath19 is the number of disclosed bit values and each additional round .    the security analysis for blind information reconciliation has been considered in details in ref .",
    ". however , we restrict our consideration to the fact that the symmetric blind reconciliation protocol fits the definition of `` adaptive symmetric method for error correction '' , with the corresponding security proof presented in ref .  @xcite .  in more details",
    "the security analysis of symmetric blind reconciliation will be considered in detail in another place .    in order to demonstrate the improvements on the efficiency of the information reconciliation procedure",
    ", we perform a numerical simulation . in particular , we compare the proposed procedure to the standard blind reconciliation , as in most progressive ldpc based method for information reconciliation in the qkd systems .",
    "we use a set of four standard ldpc codes  @xcite with the rates @xmath21 with the block length fixed to @xmath22 . for each of these codes ,",
    "we obtain a list of bit positions according to the untainted puncturing technique  @xcite containing @xmath23 154 , 221 , 295 and 433 symbols , correspondingly .",
    "these codes are currently used in industrial qkd systems  @xcite .",
    "we simulate standard blind and symmetric blind reconciliation procedures with the absence of initially shortened bits and @xmath24 initially punctured bits for a range of qber values from @xmath25 up to @xmath26 ( typical range for bb84 implementations ) .",
    "in addition , we fix the fer to less than @xmath27 .    the number of bits to be disclosed in each additional round of the procedure is chosen according to a particular code rate @xmath28 and the heuristic expression @xmath29 where @xmath4 is the block length , @xmath30 is the auxiliary parameter , and @xmath31 is the standard ceiling operation .",
    "the simulation results for @xmath32 and @xmath33 are presented in fig .",
    "[ fig : blind_vs_sym ] .",
    "first , one can see that symmetric reconciliation improves both efficiency @xmath6 .",
    "this comes from the fact that the decoding procedure in the symmetric scheme has a faster convergence rate .",
    "moreover , it requires a smaller number of additional communication rounds .    from this data",
    ", we identify an average of @xmath0 improvement in the efficiency ( @xmath34 for @xmath35 , and @xmath36 for @xmath37 ) and an average of @xmath1 improvement in the number of information requests ( @xmath38 for @xmath32 , and @xmath39 for @xmath37 ) .",
    "moreover , the scheme does not suffer from the frame errors coming from unsuccessful belief propagation decodings .",
    "-2 mm     -3 mm    next we compare two sets of codes in the rate - adaptive regime under the assumption that the level of the qber is known .",
    "the first set of codes is the previously considered one with rates  ( [ eq : codeset ] ) and block length fixed to @xmath22 .",
    "the second set of codes has rates in the range @xmath40 with block length fixed to @xmath41 .",
    "it is constructed with the use of the improved edge growth algorithm  @xcite with the degree distribution polynomials given by ref .",
    "the initial numbers of shortened and punctured bits are chosen to obtain initial decoding efficiency @xmath42 ( see appendix b ) .",
    "for each code we also constructed a set of untainted puncturing positions  @xcite and use them if possible .",
    "the results of simulation for two sets of codes and two values of @xmath30 ( 0.5 and 1 ) are presented in fig .",
    "[ fig : full_qber ] .",
    "it is clearly seen that the use of codes with block length @xmath22 and @xmath37 gives roughly the same efficiency as the codes with the block length @xmath43 and @xmath32 .",
    "this observation suggests that the symmetric blind reconciliation procedure is able to perform a trade - off between the number of required communication rounds and information leakage .",
    "we have proposed an approach which significantly improves the blind information reconciliation technique  the most progressive ldpc codes - based method for information reconciliation in the qkd systems .",
    "the gain comes from employing information from unsuccessful decodings and making the whole information reconciliation process in a symmetric form .",
    "specifically , we have proposed to disclose a number of bits with the positions corresponding to maximal uncertainty of the values upon finishing of decoding procedure rather than certain bits in the punctured positions .",
    "we note that the shortcoming of the presented method is that it occupies computational resources on the both sides and make it impossible to parallelize two opposite one - way information reconciliation processes .",
    "the ability of symmetric blind reconciliation to obtain rather low values of efficiency with short - length codes is expected to realize an efficient throughput with hardware implemented syndrome decoding .",
    "we note that short - length ldpc codes have been used to show the results of our method .",
    "the fact is that a small block length leads to high fluctuations of actual number of discrepancies in raw keys even in the case of a constant qber . in turn , these fluctuations are crucial for successful belief propagation decoding .",
    "the feature of blind reconciliation is that it can treat fluctuations by disclosing adequate amount of information via public channel .",
    "the suggested method of information reconciliation can be essentially used for ldpc codes with large block lengths ( say , @xmath44 or @xmath45 ) . in the case of an adjustment to a proper level of initial efficiency",
    ", it can be used for the complete elimination of belief propagation decoding failures via relatively rare request of additional bit values .",
    "nevertheless , these requests could appear to be very useful in the case of fluctuations of the qber and especially in the case when error estimation is performed after the error correction ( similar to that in ref .",
    "@xcite ) .    in order to evaluate the performance of our proposed scheme in the context of industrial qkd systems",
    ", we consider an illustrative example based on the results of ref .",
    "@xcite . in this particular setup , the information reconciliation was performed with a straightforward implementation of the standard @xmath22 ldpc code  @xcite with @xmath46 using qber @xmath47 . according to the results presented in fig .",
    "[ fig : full_qber ] , an implementation of symmetric blind reconciliation may lead to a decrease of efficiency down to @xmath48 with approximately six additional communication rounds .",
    "it provides a @xmath27 increase of secure key rate ( we note that cascade implementation of the information reconciliation procedure in the same conditions requires about @xmath49 communication rounds  @xcite ) .",
    "moreover , in this qkd system an estimated level of qber was calculated via the comparison of a number of key blocks before and after error correction ( unverified blocks were conservatively assumed to have @xmath50 error rate ) .",
    "verification errors , resulted from unsuccessful belief propagation decodings and convergences to improper vectors , leaded to an overly pessimistic estimation of the qber : @xmath51 .",
    "thus , the suggested approach opens a way for qber estimation in a more accurate way together with a more economical utilization of generated raw keys .",
    "our source code for a proof - of - principle realization of the symmetric blind information reconciliation procedure for python 2.7 is freely available under gnu general public license ( gpl )  @xcite .",
    "a proof - of - principle realization of the suggested post - processing procedure is also available  @xcite .",
    "we thank n. gisin for a number of useful discussions and valuable comments .",
    "we thank j. martnez - mateo for numerous of important remarks and comments helping us to improve the manuscript .",
    "we acknowledge fruitful discussions with n. pozhar , m. anufriev , d. kronberg , and d. elkouss .",
    "we thank m. galchenkova for invaluable input in the initial phase of the project .",
    "the research leading to these results has received funding from ministry of education and science of the russian federation in the framework of the federal program ( agreement 14.582.21.0009 , i d rfmefi58215x0009 ) .",
    "c.c.w.l . acknowledges support from ornl laboratory directed research and development program ( ldrd ) , the u.s .",
    "department of energy cybersecurity for energy delivery systems ( ceds ) program program under contract m614000329 .",
    "here we give a detailed description of the workflow of the proposed symmetric blind reconciliation .",
    "the general scheme is presented in fig .",
    "[ fig : methods](a ) .",
    "-3 mm    first , we assume that alice and bob have an estimated value of qber @xmath52 , which comes from preceding error estimation step or previous rounds of post - processing procedure .",
    "parties start with choosing of the optimal code among set ( pool ) of available ldpc codes according to @xmath52 and desired starting efficiency @xmath53 ( in all our discussions it was set to unity ) . for each code , specified by its @xmath3 parity matrix @xmath54 ( with @xmath55 ) , parties calculate the number of shortened ( @xmath12 ) or punctured @xmath56 symbols that is required to obtain desired efficiency @xmath53 from not adaptable efficiency @xmath57 $ ] as follows : @xmath58 for @xmath59 , and @xmath60 for @xmath61 .    the particular code among the set is then chosen in such way that it has the maximal number of raw key bits in the extended key .",
    "we note that in our approach we use only shortened _ or _ punctured bits to obtain the desired efficiency @xmath53 [ see also fig .  [",
    "fig : methods](b ) ] .",
    "this method is quite different from the commonly used approach  @xcite , where the sum of numbers of shortened and punctured bits remains constant .",
    "then the parties take blocks of their raw keys @xmath62 and @xmath63 of length @xmath64 and pad them with shortened and punctured symbols obtaining extended keys @xmath65 and @xmath66 of code block length @xmath4 . in fig .",
    "[ fig : methods](a ) we denote this operation as @xmath67 , where @xmath68 and @xmath69 are list of positions for shortened and punctured symbols of length @xmath12 and @xmath13 correspondingly .",
    "if it is possible , parties choose @xmath69 using position from special list , generated in advance with untainted puncturing technique  @xcite . otherwise , the parties choose @xmath69 as well as @xmath68 with a synchronized prng .",
    "all shortened symbols obtains zero values , while the values of the punctured bits come from the trng ( independently on each side ) .",
    "the party that modifies its raw key ( in our case it is bob ) also keeps original positions of shortened and punctured symbols as @xmath70 and @xmath71 .",
    "these position are used in the final stage of the procedure .",
    "the subsequent part of the procedure aims at reconstruction of a vector @xmath72 , that we call an error pattern , such that @xmath73 in order to cope with this task , both alice and bob initialize supposed error pattern @xmath74 as the zero vector , calculate the syndromes @xmath75 and @xmath76 of their extended keys @xmath65 and @xmath66 , and share the obtained syndromes with each other .",
    "then each party performs belief propagation decoding with the relative syndrome @xmath77    we use an updated belief propagation decoding algorithm ( see below ) , which returns not only a resulting decoded vector @xmath72 ( that is ` none ' in the failure case ) , but also a set of bit positions @xmath78 of the fixed length @xmath19 which have the lowest log - likelihood ( llr ) values upon finishing of decoding . in other words ,",
    "the updated decoding procedure returns @xmath19 positions of symbols with the most uncertainty in their values .    due to the fact the both parties perform the same operation",
    ", they obtain the same output @xmath72 and @xmath78 . in the case of a failure ( @xmath79 ) , the parties share the values of bits in the positions of @xmath78 , update their supposed error pattern @xmath74 in the positions form @xmath78 according to received values : @xmath80 = { \\mathbf{x}_{\\mathrm{ext}}}[d]+{\\mathbf{y}_{\\mathrm{ext}}}[d]~(\\mathrm{mod}~2),\\ ] ] and try to perform the decoding process again marking positions in @xmath78 as shortened , that is crucial for the subsequent decoding procedure .",
    "this sequence of operations is repeated until a convergence of belief propagation decoding .",
    "then bob applies error correction according to the obtained error pattern @xmath81 by modulo 2 summation with his extended key @xmath63 .",
    "finally , bob excludes the symbols with initially shortened @xmath70 and punctured @xmath71 positions to obtain the corrected key @xmath82 [ we denote this operation as @xmath83 in fig .  [",
    "fig : methods](a ) ] , and parties move to the verification step with the original raw key @xmath62 on alice s side and its corrected version @xmath82 on the bob s one .",
    "we use belief propagation sum - product algorithm  @xcite based on a use of log - likelihood ratios ( llrs ) with some updates necessary for our implementation . for a given random bit variable @xmath84 , its llr is defined as @xmath85 one can see that sign of llr corresponds to the most likely value of @xmath84 ( 0 for positive llr and 1 for negative ) , and its absolute value exhibits confidence level of this particular value .",
    "the decoding algorithm is based on the representation of parity check matrix @xmath54 in the bipartite graph [ see fig .  [",
    "fig : methods](c ) ] .",
    "it consists of @xmath4 _ symbol nodes _ and @xmath5 _ check nodes _ that corresponds to rows and columns of parity check matrix @xmath54 .",
    "the @xmath86-th symbol node is connected by edge with the @xmath87-th check node if and only if the corresponding element of parity check matrix is nonzero : @xmath88=1 $ ] . process of a decoding can be described as exchanging of messages about symbol nodes .",
    "we consider the decoding procedure as follows : @xmath89 where @xmath90 is syndrome , @xmath74 is the vector of length @xmath4 have to be corrected , @xmath54 is the @xmath3 parity - check matrix , @xmath52 is the estimated level of crossover probability ( qber ) , @xmath68 and @xmath69 are positions of shortened and punctured bits , @xmath81 is the corrected version of @xmath74 , @xmath78 is list of positions for @xmath19 symbols with the lowest llr values , where @xmath19 is considered as an external constant .",
    "the workflow of the procedure is as follows .",
    "we start from calculation of initial llrs for all symbol nodes .",
    "the corresponding vector is denoted as @xmath91 and its elements are given by @xmath92 : = \\begin{cases }          ( -1)^{{\\mathbf{e}}[i ] } r_\\mathrm{k } , & i\\in k \\\\          ( -1)^{{\\mathbf{e}}[i ] } r_\\mathrm{s } , & i\\in s \\\\          0 , & i\\in p      \\end{cases},\\ ] ] where @xmath93 consists raw key positions , such that @xmath94 here @xmath95 is calculated using estimated value of qber @xmath96 : @xmath97 the llr value for shortened symbols @xmath98 and in our implementation we used @xmath99 .",
    "the llr for punctured symbols is zero as there is no information about their values , since they come from independent true rng    the initial messages from check nodes to symbol nodes are given by the initial values of corresponding llrs as follows : @xmath100.\\ ] ] here @xmath101 and @xmath102 , where @xmath103 is a set of symbol nodes connected with @xmath86-th symbol node .",
    "check nodes form messages back to symbol node is realized in the following way : @xmath104(-1)^{{\\mathbf{s}}[j]},\\ ] ] where @xmath105 and @xmath106 with @xmath107 being a set of symbol nodes connected to @xmath87-th check node .",
    "we note that @xmath108 does not taking into account @xmath109 .",
    "actually @xmath108 is llr of @xmath86-th bit value based on satisfying parity equation of @xmath87-th row of parity check matrix @xmath54 , and llrs of all other symbol nodes taking part in this equation [ see fig .  [",
    "fig : methods](d ) ] .",
    "symbol node updates its llr using all the messages coming from its check nodes : @xmath110 : = { \\mathbf{r}}^{(0)}[i]+\\sum_{j\\in a_i } { \\mathbf{m}}_{i\\leftarrow j}^{(k)}\\ ] ] and calculates current estimates of bit values @xmath111 : = \\begin{cases }          0 , & { \\mathbf{r}}^{(k)}[i]\\geq0 \\\\          1 , & { \\mathbf{r}}^{(k)}[i]<0      \\end{cases}.\\ ] ] if this estimate satisfies all parity equations , @xmath112 than the algorithm stops and returns decoded vector @xmath113    as a stopping criteria , we consider behavior of averaged magnitude llrs for symbols in non shortened positions : @xmath114|.\\ ] ] we stop the decoding and return ` none ' as decoded vector if for the current step @xmath115 the following inequality holds @xmath116 where we used @xmath117 .",
    "it can be interpreted as stop of a trend growth of our confidence in bits values .",
    "the algorithm also returns @xmath78 that is a list @xmath19 positions of symbols , which has minimal values of llr magnitude : @xmath118|\\leq |{\\mathbf{r}}^{(k)}[j]| ~\\forall j\\notin d \\ } , \\quad |d| = d.\\ ] ] otherwise , algorithm goes to the next step .    according to new llrs",
    ", we updated messages from symbol nodes to check nodes : @xmath119+\\sum_{j'\\in a_i / j } { \\mathbf{m}}_{i\\leftarrow j'}^{(k ) } \\\\      & = { \\mathbf{r}}^{(k)}[i]-{\\mathbf{m}}_{i\\leftarrow j}^{(k ) } \\end{split}\\ ] ] counter of iterations is incremented : @xmath120 [ see fig .",
    "[ fig : methods](e ) ] , and algorithm goes to the step with heck nodes form messages back to symbol node [ see eq .",
    "( [ eq : step3 ] ) ] .",
    "it is important to note that the most computationally expensive calculation  ( [ eq : mes ] ) can be optimized by using a technique suggested in ref .",
    "we also point out that eq .",
    "( [ eq : mes ] ) allows revealing some peculiarity of punctured symbols .",
    "zero llr of punctured symbol @xmath106 on the first step deactivates the @xmath87-th check node making all messages @xmath121 ( @xmath122 , @xmath123 ) to other symbol nodes to be zero .",
    "if there are no punctured bits in @xmath124 then @xmath125 and @xmath86th node become ` rescued ' after the first iteration and then participates in decoding procedure . however ,",
    "if there are a least of two punctured nodes connected to given @xmath87-th check node , then all messages @xmath126 are zero .",
    "there still a possibility that the punctures symbols will be rescued via another check nodes , but nonetheless such behavior indicates the importance of choosing a set of punctured symbols . to avoid this situation the special technique of untainted puncturing",
    "is used  @xcite .",
    "bennet and g. brassard , https://researcher.watson.ibm.com/researcher/files/us-bennetc/bb84highest.pdf[in _ proceedings of the ieee international conference on computers , systems and signal processing _",
    "bangalore , india ( ieee , new york , 1984 ) , p. 175",
    "] .          characteristics of commercial devices from https://www.idquantique.com[id quantique ( switzerland ) ] , https://www.sequrenet.com[sequrenet ( france ) ] , and the https://www.ait.ac.at/[austrian institute of technology ( austria ) ] are available .",
    "r. renner , https://dx.doi.org/10.1142/s0219749908003256[int .",
    "j. quantum inform .",
    "* 6 * , 1 ( 2008 ) ] ; _ security of quantum key distribution _",
    ", phd thesis , eth zurich ; https://arxiv.org/abs/quant-ph/0512258[arxiv:0512258 ( 2005 ) ] .",
    "n. walenta , a. burg , d. caselunghe , j. constantin , n. gisin , o. guinnard , r. houlmann , p. junod , b. korzh , n. kulesza , m. legr , c.c.w .",
    "lim , t. lunghi , l. monat , c. portmann , m. soucarros , p. trinkler , g. trolliet , f. vannel , and h. zbinden , https://dx.doi.org/10.1088/1367-2630/16/1/013047[new j. phys .",
    "* 16 * 013047 ( 2014 ) ] .",
    "o , maurhart , c. pacher , c. tamas , a. poppe , and m. peev , https://2015.qcrypt.net/wp-content/uploads/2015/09/poster51_oliver-maurhart.pdf[in _ proceedings of the 5th international conference on quantum cryptography _ ,",
    "tokyo , japan ] .",
    "d. elkouss , a. leverrier , r. alleaume , and j.j .",
    "boutros https://dx.doi.org/10.1109/isit.2009.5205475[in _ proceedings of the ieee international symposium on information theory _ , seoul ,",
    "south korea , ( 2009 ) , p. 1879 ]        d. elkouss , j. martnez - mateo , and v. martin , https://dx.doi.org/10.1109/isita.2010.5650099[in _ proceedings of the ieee international symposium on information theory and its applications ( isita ) _ , taichung , taiwan ( ieee , 2010 ) , p. 179 ] .",
    "hu , e. eleftheriou , d .-",
    "arnold , and a. dholakia , https://dx.doi.org/10.1109/glocom.2001.965575[in _ proceedings of global telecommunications conference _ , san antonio , tx , usa ( ieee , 2001 ) , p. 1879 ] ."
  ],
  "abstract_text": [
    "<S> quantum key distribution ( qkd ) is a quantum - proof key exchange scheme which is fast approaching the communication industry . </S>",
    "<S> an essential component in qkd is the information reconciliation step , which is used for correcting the quantum channel noise errors . </S>",
    "<S> the recently suggested blind reconciliation technique , based on low - density parity - check ( ldpc ) codes , offers remarkable prospectives for efficient information reconciliation without an a priori error rate estimation . in the present work , </S>",
    "<S> we suggest an improvement of the blind information reconciliation protocol allowing significant increase the efficiency of the procedure and reducing its interactivity . the proposed technique is based on introducing symmetry in operations of parties , and the consideration of results of unsuccessful belief propagation decodings . </S>"
  ]
}