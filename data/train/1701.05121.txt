{
  "article_text": [
    "one of the advantages of evolutionary algorithms is that these type of algorithms can be used to find novel solutions with a minimal amount of pre - structuring .",
    "that means that there is no inherent need to e.g.  a priori specify the structure of a neural network . in the context of",
    "embodied artificial intelligence , this means that for an embodied agent , only the number of sensors and motors need to be specified and everything else can be left open to evolution . in particular ,",
    "artificial evolution can be used to find optimal control structures by sequentially growing and pruning networks .",
    "we use the term optimal in the sense of  @xcite , i.e.  in the context of structurally minimal networks that solve a given set of tasks .",
    "furthermore , evolutionary algorithms can be used to co - evolve the brain and body of embodied agents .",
    "impressive examples date back to karl sim s work  @xcite , but can also be found in more recent work  ( e.g.  @xcite ) .    a common trait of almost all experiments ( early as well as contemporary ) in the context of evolutionary robotics are that the morphology or the behaviour is kept simple , while the other might vary . in cases of simple morphologies ,",
    "i.e.  wheel - driven robots , one can find examples of interesting behaviours such as predator - prey scenarios  @xcite .",
    "if the morphology is more complex , i.e.  walking machines , then evolved behaviours , mainly solve locomotion problems  ( e.g.  @xcite ) , which does not mean that the results are less impressive .",
    "yet , it indicates that it is a challenge to evolve complex behaviours for complex systems .",
    "we believe that these challenges result from two main problems . in the early days , genetic algorithms  @xcite ( gas )",
    "were used predominantly .",
    "gas were often applied to fully connected recurrent neural networks , which means that the string length would increased exponentially with every additional sensor or motor .",
    "hence , for simple systems with limited sensors and motors , the space of policies was small enough to search for interesting behaviours , whereas for complex morphologies , such as walking machines , evolving a robust walking behaviour already posed a challenge .",
    "a workaround was to use neural networks of particular structures , but then the question arose , what are best suited structures to learn a specific behaviour ?",
    "an interesting alternative , which is known as hyperneat , will be discussed below .",
    "the second problem , in our opinion , is that it is very difficult to add functionality to a network in an evolutionary setting .",
    "let us assume that we have evolved a locomotion network for a hexapod .",
    "how can we add the functionality to add e.g.  a light - seeking behaviour , while ensuring that the already learned behaviour is preserved .",
    "one can fixate the synaptic weights of the locomotion network , but how should the newly grown structure interface with the already existing locomotion structure ?",
    "nmode is specifically designed to address these two problems , i.e. , to reduce the search space for the evolution of neuro - modules in a meaningful way and to provide a principled way to interface new module , , on - top  of already evolved structures . before we introduce nmode , we first present contemporary algorithms and discuss why we did not choose to extend an existing framework instead of creating yet another artificial evolution algorithm .    to the best of the authors knowledge , there is only one algorithm that can be considered anything close to a standard in this context .",
    "hyperneat  @xcite is a very popular evolutionary algorithm that allows to simultaneously evolve morphologies and neural networks . to understand how hyperneat works , it is important to look at its predecessors , neat  @xcite and cppn  @xcite .",
    "neat is a very interesting algorithm to evolve neural networks of arbitrary structure .",
    "two key features of neat are its ability to allow for cross - over between to arbitrary structures and speciation as a method to protect innovations .",
    "cppns ( compositional pattern producing networks ) are neat networks which use a set of function instead of the standard sigmoidal transfer function .",
    "this means that one parameter of the neuron selects the transfer function from a set of possible functions ( sine wave , linear , saw tooth ,  ) .",
    "let us assume , that we have evolved a cppn with two inputs and a three outputs .",
    "let us further assume , that the two inputs are the @xmath0 and @xmath1 coordinates of a two - dimensional bounded plane and the three outputs are rgb colour values .",
    "this means that the cppn is now able to produce a picture .",
    "the picbreeder website  @xcite shows impressive examples of pictures that were evolved by visitors of the website .",
    "it is striking how cppns can make use of symmetries , repetitions , etc .",
    ", to create complex and appealing images .",
    "the website endless forms applies the same idea to 3d shapes  @xcite .",
    "the output of the cppn is now used to determine the boundary of geometric figures .",
    "hyperneat uses cppns to generate the synaptic weights in a layered neural network .",
    "each layer of a neural network is placed on a two - dimensional plane and two layers are fully connected , which means that every neuron in the input layer is connected with every neuron in the hidden layer and every neuron in the hidden layer is connected to every neuron in the output layer .",
    "a cppn is now fed with the geometric location of the pre- and post - synaptic neurons on their layers and the output of the cppn is the synaptic connection between the two neurons .",
    "although there are very interesting experiments published that use hyperneat  ( e.g.  @xcite ) , there are currently no publications that show a successful application of hyperneat to complex robotic systems . for example",
    ", hyperneat has not been used to evolve behaviours for non - trivial walking machines such as svenja or even heaxaboard , which is discussed in section  [ sec : hexaboard ] and section  [ sec : svenja ] .",
    "one reason is that hyperneat is very good at finding patterns , but not very good in fine tuning parameters  @xcite .    from our perspective",
    ", the significant reason not to use hyperneat is the its requirement to use a predefined neural network architecture .",
    "the number of layers and their respective connectivity must be specified by the experimenter before running the evolutionary algorithm .",
    "we are interested in finding minimal and optimal neural network architectures , which is why the structure of the network ( including the number of synapses and neurons ) must be be open to evolution .",
    "neat allows to evolve the structure of a network together with its parameters but does not allow for modularisation .",
    "one idea that will be followed in future work is to combine neat with the modular structure of nmode .",
    "this would allow to use cross - over operators not only on the level of modules ( see sec .",
    "[ sec : nmode ] ) but also allow cross - over between modules .",
    "besides neat , there are nt many algorithms that support the co - evolution of structure and parameters of a neural network .",
    "one of the first frameworks probably is isee ( integrated structure evolution environment ) , which is described in detail in  @xcite and based on the @xmath2 algorithm  @xcite .",
    "isee not only included software to evolve neural networks but also sophisticated tools to inspect the dynamics of neural network while they were operating in the sensorimotor loop as wells as _ ex vitro _ analysis of their dynamics .",
    "it has been applied very successfully in numerous experiments to evolve networks in simulation that were then used with minimal adaptation effort to control real robots ( see e.g.  @xcite ) .",
    "unfortunately , the initial implementation did not support the evolution of disjunct neuro - modules . as an example , consider the aibo^tm^ robot for which a behaviour was evolved in  @xcite .",
    "this system has a left - right symmetry that an evolutionary algorithm can take advantage of to reduce the search space . in isee , this required a few workarounds .",
    "nerd  @xcite is a full evolutionary environment , designed to overcome the limitations of isee with a lot of additional functionality .",
    "it allows to define neuro - modules with a rich repertoire of operators .",
    "an interesting feature is that nerd allows the definition of connection rules , e.g.  to force that a specific sensor has to be connected to a specific actuator .",
    "the software is very powerful , which comes with the cost that it is not easy to use out of the box .",
    "additionally , nerd is also unfortunately no longer maintained as the development has stopped .",
    "nmode s development was initiated to overcome isee limitations by adapting nerd s neuro - modular concept in a minimalistic and easy to use way , thereby adapting interesting ideas from neat .",
    "the novel idea that guided nmode s development is the principled way of augmenting already evolved networks by new modules , which we see as one of the biggest problems in the context of evolutionary robotics to achieve behaviours of higher complexity .",
    "if we look at the impressive work by karl sims  @xcite , then it is difficult to see a significant progress since these early experiments .",
    "otherwise stated , in the context of evolutionary robotics , we are still mostly working on the level of braitenberg vehicles  @xcite , which means that we mostly work with purely reactive systems . although the complexity of the morphology has clearly increased over the decades , the behaviours that these systems show are still mainly reactive . to the best of the authors knowledge ,",
    "there are currently no systems in which a non - trivial morphology has been evolved beyond the realms of reactive behaviours .",
    "this is where the development of nmode is targeted at ; evolving complex behaviours for complex morphologies .",
    "this requires a method to incrementally increase the complexity of the behaviours without loosing already gained functionality .",
    "the method of adding new functionality in this context is called incremental evolution and is it not a new concept  @xcite .",
    "the core ideas of nmode can be summarised in the following way .",
    "a neural network is decomposed into neuro - modules .",
    "neural networks are composed of modules and mutations can only the change the structure within a modules .",
    "in particular , this means that synaptic connection can not be created between neurones of different modules . instead , the interaction between two modules is controlled by interface neurones ( see next sec . ) .",
    "this allows to incrementally extend previously evolved modules with new modules in a controlled manor .",
    "nmode is not designed to be biologically plausible , but to allow to evolve neural networks for non - trivial behaviours of complex systems .",
    "the intention of this work is to introduce nmode and investigate how it works on a well - known morphology ( see sec .  [",
    "sec : hexaboard ] ) as well as a more complex , biologically motivated morphology ( see sec .  [",
    "sec : svenja ] ) .",
    "evolving non - reactive behaviours will be investigated in future publications .",
    "this work is organised in the following way .",
    "the next section discusses the neuro - modules and evolutionary algorithm in detail .",
    "the source code is freely available at  @xcite .",
    "the following section presents two experiments , before this work concludes with a discussion and outlook .",
    "evolutionary algorithms can generally be divided into four functions that each operate on a population of individuals , namely _ evaluation _ , _ selection _ , _ reproduction _ , and _",
    "mutation_. let @xmath3 be a population of individuals , and let @xmath4 , @xmath5 , @xmath6 , and @xmath7 be the _ evaluation _",
    ", _ selection _ , _ reproduction _ , and _ mutation _ functions .",
    "then , the evolution from one generation to the next can be written as @xmath8 where @xmath9 refers to the generation index .",
    "nmode is designed to reduce the search space by modularisation of the neural network structure .",
    "therefore , we will first discuss how the modularisation is specified , before we present the algorithmic details .",
    "the basic idea of nmode is that the morphology of an embodied agent can be used to determine how a neural network should be modularised .",
    "it is known from , e.g.  stick insects , that each leg has its own local controller and that the local leg controller are synchronised by a central nervous system  ( see e.g.  @xcite ) .",
    "hence , if we have a geometric description of an agent s morphology ( e.g.  fig .",
    "[ fig : experimental_platforms ] ) , which includes the pose of the segments and the location of the sensors and actuators , we can use that information to generate a geometric description of a neural network . by",
    "that we mean that neurons will have 3d coordinates that refer to their position in a global cartesian coordinate system .",
    "currently , this geometric description must be defined manually in nmode , but there is no reason why this could not be automatised in future versions .",
    "an example is the rosiml robot simulation mark - up language that is used by yars  @xcite to define an experiment .",
    "it contains the pose of each segment as well as the location of each actuator and sensor .",
    "gazeboo  @xcite uses a similar file structure that could also be used to automatically generate a neural network configuration .",
    "these files can be parsed for the names and location of segments , sensors and actuators and also determine symmetries and repetitions .",
    "a module in nmode contains six different types of neurons and a list of synapses .",
    "the next paragraph will describe each of them in detail , but we will first present the type of neuron model that is currently implemented .",
    "we use the standard additive neuron model , which is given by the following set of equations : @xmath10 where @xmath11 is the activation of neuron @xmath12 at time @xmath13 , @xmath14 is the output of neuron @xmath15 at time @xmath16 , @xmath17 is the synaptic strength between the pre - synaptic neuron @xmath18 and the post - synaptic neuron @xmath15 , and finally , @xmath19 is the transfer function .",
    "all neurons are updated synchronously , which means that first the activations @xmath20 are calculated based on the neuron outputs of the previous time step @xmath21 .",
    "once all activations are updated , the neuron outputs follow , i.e. , all outputs @xmath22 are calculated based on the updated actuators states @xmath20 .",
    "as already indicated , we currently work with time discrete neural networks . it must be noted here that the specification given in the nmode xml file is generic enough to allow nmode to be extended to work with any type of neural networks or graphical models .",
    "this is why we will sometimes refer to neurons as nodes and synapses as edges .",
    "currently , we support three type of transfer functions , namely @xmath23 , where @xmath24 is the identity function , @xmath25 is the standard sigmoid function , and finally @xmath26 is the hyperbolic tangent .",
    "next , we will discuss the six different types of nodes , which are ; _ sensor _ , _ actuator _ , _ hidden _ , _ input _ , _ output _ , and _",
    "connector_. the first three node types are well - known from other neural network contexts .",
    "sensor nodes receive input from the agent s sensors and are typically equipped with a linear ( i d ) transfer function .",
    "analogously , actuator nodes are directly connected to the actuators of the agent , and finally , hidden nodes are only connected to other nodes within the same module .",
    "actuator and hidden neurons are usually equipped with one of the two sigmoidal functions presented above .",
    "two of the new node types are named _",
    "input _ and _ output_. the role of these nodes is to function as connectors between modules .",
    "input nodes only allow connections from itself to other neurons within the module it is assigned to , whereas output nodes only allow connections from nodes of the corresponding module to itself . to connect a module with another module that has _ input _ and _ output _ nodes , the connecting module has to use a _ connector _ node .",
    "the _ connector _ node will copy the position and properties of the node it is referring to .",
    "in particular , this means that if a connector nodes refers to an input node , it will automatically become an output node of the connecting module .    as an example , consider the hexapod used in the first experiment presented below ( see sec .",
    "[ sec : hexaboard ] ) .",
    "its nmode structure is shown in figure  [ fig : hexaboard_nmode_specification ] .",
    "sensor nodes are shown in red , actuator nodes in green , input nodes in cyan , output nodes in purple , and finally , connector nodes in orange . in the experiment discussed below , only one leg module and one cpg module are evolved . by definition ,",
    "a leg module controls a leg , which means that requires needs sensor and actuator nodes to access the leg s state and control its movement . for a simple locomotion movement , the cpg does not require any sensor or actuator nodes .",
    "instead , the cpg only consists of connector nodes to interface with the evolved leg modules .",
    "because all legs are morphologically identical in this example , only one leg module has to be evolved , which is the used several times for the final controller ( see fig .  [",
    "fig : hexaboard_nmode_specification ] ) .",
    "we demonstrate the parameter reduction that results from this modularisation based on the hexapod example and with the assumption that the insertion of hidden units is not allowed .",
    "this allows us to calculate the maximal number of edge for a modularised and non - modularised neural network ( see fig .",
    "[ fig : hexaboard_nmode_specification ] ) , where the latter means that synapses can connect any two neurons .",
    "it must be noted , that sensor nodes can only have outgoing connections in the current implementation , i.e. , they only function as proxy for the sensor values .",
    "let @xmath27 be the number of sensor , actuator , input , output , and hidden nodes .",
    "for a fair comparison , we replace all pairs of input / output nodes by a single hidden node in the unrestricted configuration , which follows structure that was used in  @xcite",
    ". then the dimension of the weight matrices for the two configurations is given by tab .",
    "[ tab : hexapod_dimension ] ."
  ],
  "abstract_text": [
    "<S> modularisation , repetition , and symmetry are structural features shared by almost all biological neural networks . </S>",
    "<S> these features are very unlikely to be found by the means of structural evolution of artificial neural networks . </S>",
    "<S> this paper introduces nmode , which is specifically designed to operate on neuro - modules . </S>",
    "<S> nmode addresses a second problem in the context of evolutionary robotics , which is incremental evolution of complex behaviours for complex machines , by offering a way to interface neuro - modules . </S>",
    "<S> the scenario in mind is a complex walking machine , for which a locomotion module is evolved first , that is then extended by other modules in later stages . </S>",
    "<S> we show that nmode is able to evolve a locomotion behaviour for a standard six - legged walking machine in approximately 10 generations and show how it can be used for incremental evolution of a complex walking machine . </S>",
    "<S> the entire source code used in this paper is publicly available through github . </S>"
  ]
}