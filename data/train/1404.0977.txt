{
  "article_text": [
    "finding shortest paths and maximum flows are among the most fundamental optimization problems in graph theory .",
    "on planar graphs , these problems are intimately related and can all be solved in linear or near - linear time . obtaining strictly - linear time algorithms for these problems",
    "is one of the main current goals of the planar graphs community  @xcite .",
    "some of these problems are known to be solvable in linear time ( minimum spanning tree  @xcite , shortest - paths with non - negative lengths  @xcite , maximum flow with unit capacity  @xcite , undirected unweighted global min - cut  @xcite ) , but for many others , only nearly - linear time algorithms are known .",
    "these include shortest - paths with negative lengths  @xcite , multiple - source shortest - paths  @xcite , directed max - flow / min-@xmath12-cut  @xcite , and global min - cut  @xcite .",
    "many of the results mentioned above were achieved fairly recently , along with the development of more sophisticated shortest paths techniques in planar graphs . in this paper",
    "we show how to combines two of these techniques : the technique of henzinger , klein , rao , and subramanian for computing shortest paths with non - negative lengths in linear time  @xcite , and the technique of fakcharoenphol and rao to compute shortest paths on dense distance graphs in nearly linear time in the number of vertices  @xcite .",
    "the _ dense distance graph _",
    "( ddg ) is an important element in many of the algorithms mentioned above .",
    "it is a non - planar graph that represents ( exactly ) distances among a subset of the vertices of the underlying planar graph @xmath0 .",
    "more precisely , an @xmath1-division  @xcite of an @xmath13-vertex planar graph @xmath0 , for some @xmath2 , is a division of @xmath0 into @xmath14 subgraphs ( called _ regions _ ) @xmath15 , where each region has at most @xmath1 vertices and @xmath16 _ boundary _ vertices , which are vertices that the region shares with other regions .",
    "there exist @xmath1-divisions of planar graphs with the additional property that the boundary vertices in each region lie on a constant number of faces ( called _ holes _ )  @xcite .",
    "consider an @xmath1-division of @xmath0 for some @xmath2 .",
    "let @xmath17 be the complete graph on the @xmath16 boundary vertices of the region @xmath18 , where the length of arc @xmath19 is the @xmath20-to-@xmath21 distance in @xmath18 .",
    "the graph @xmath17 is called the ddg of @xmath18 .",
    "the union @xmath22 is called the ddg of @xmath0 ( or more precisely , the ddg of the given @xmath1-division of @xmath0).-divisions , but our algorithm does not necessarily apply in such cases . ]",
    "ddgs are useful for three main reasons .",
    "first , distances in the ddg of @xmath0 are the same as distances in @xmath0 .",
    "second , it is possible to compute shortest paths in ddgs in time that is nearly linear in the number of vertices of the ddg  @xcite ( fr - dijkstra ) .",
    "i.e. , in sublinear time in the number of vertices of @xmath0 .",
    "finally , ddgs can be computed in nearly linear time either by invoking fr - dijkstra recursively , or by using a multiple source shortest - path algorithm  @xcite ( mssp ) . until the current work , the latter method was faster in all cases .",
    "since it was introduced in 2001 , fr - dijkstra has been used creatively as a subroutine in many algorithms .",
    "these include algorithms for computing ddgs  @xcite , shortest paths with negative lengths  @xcite , maximum flows and minimum cuts  @xcite , and distance oracles  @xcite .",
    "improving fr - dijkstra is therefore an important task with implications to all these problems .",
    "for example , consider the minimum @xmath12-cut problem in undirected planar graphs .",
    "italiano et .",
    "al  @xcite gave an @xmath23 algorithm for the problem , improving the @xmath24 of reif  @xcite ( using  @xcite ) .",
    "three of the techniques used by italiano et al .",
    "are : ( i ) constructing an @xmath1-division with @xmath25 in @xmath26 time , ( ii ) fr - dijkstra , and ( iii ) constructing the ddg in @xmath26 . in a step towards a linear time algorithm for this fundamental problem ,",
    "klein , mozes and sommer gave an @xmath27 algorithm for constructing an @xmath1division  @xcite .",
    "this leaves the third technique as the only current bottleneck for obtaining min-@xmath12-cut in @xmath27 time .",
    "the work described in the current paper is motivated by the desire to obtain such a linear time algorithm , and partially addresses techniques ( ii ) and ( iii ) .",
    "it improves the running time of fr - dijkstra , and , as a consequence , implies faster ddg construction , although for a limited case which is not the one required in  @xcite .",
    "the linear time algorithm for shortest - paths with nonnegative lengths in planar graphs of henzinger , klein , rao , and subramanian  @xcite ( hkrs ) is another important result that has been used in many subsequent algorithms .",
    "hkrs  @xcite differs from dijkstra s algorithm in that the order in which we relax the arcs is not determined by the vertex with the current globally minimum label .",
    "instead , it works with a recursive division of the input graph into regions .",
    "it handles a region for a limited time period , and then skips to another region . within this time period",
    "it determines the order of relaxations according to the vertex with minimum label in the _ current _ region , thus avoiding the need to perform many operations on a large heap .",
    "planarity , or to be more precise , the existance of small recursive separators , guarantees that local relaxations have limited global effects . therefore , even though some arcs are relaxed by hkrs more than once , the overall running time can be shown ( by a fairly complicated argument ) to be linear . even though hkrs has been introduced roughly 20 years ago and has been used in many other algorithms , to the best of our knowledge , and unlike other important planarity exploiting techniques , it has always been used as a black box , and was not modified or extended prior to the current work .",
    "[ [ our - results . ] ] * our results . * + + + + + + + + + + + + + +    by combining the technique of henzinger et al . with a modification of the internal building blocks of fakcharoenphol and rao s dijkstra implementation ,",
    "we obtain a faster algorithm for computing shortest paths on dense distance graphs .",
    "this is the first asymptotic improvement over fr - dijkstra .",
    "specifically , for a ddg over an @xmath1division of an @xmath13-vertex graph , fr - dijkstra runs in @xmath5 .",
    "we remove the logarithmic dependency on @xmath13 , and present an algorithm whose running time is @xmath28 .",
    "this improvement is useful in algorithms that use an @xmath1-division when @xmath1 is small ( say @xmath25 ) .",
    "our overall algorithm resembles that of hkrs  @xcite .",
    "however , in our algorithm , the bottom level regions are not individual edges ( as is hkrs ) , but hyperedges , which are implemented by a suitably modified version of _ bipartite monge heaps_. the bipartite monge heap is the main workhorse of fakcharoenphol and rao s algorithm  @xcite .",
    "one of the main challenges in combining the two techniques is that the efficency of fakcharoenphol and rao s algorithm critically relies on the fact that the algorithm being implemented is dijkstra s algorithm , whereas hkrs does not implement dijkstra s algorithm . to overcome this difficulty we modify the implementation of the bipartite monge heaps .",
    "we develop new range minimum query ( rmq ) data structures , and a new way to use them to implement bipartite monge heaps .",
    "another difficulty is that both the algorithm and the analysis of hkrs had to be modified to work with hyperedges , and with the fact that the relaxations implemented by the bipartite monge heaps are performed implicitly . on the one hand ,",
    "using implicit relaxations causes limited availability of explicit and accurate distance labels . on the other hand ,",
    "such explicit and accurate labels are necessay for the progress of the hkrs algorithm as it shifts its limited attention span between different regions .",
    "we use an auxiliary construction and careful coordination to resolve this conflict between fast implicit relaxations and the need for explicit accurate labels .",
    "[ [ applications . ] ] * applications .",
    "* + + + + + + + + + + + + + + +    we believe that our fast shortest - path algorithm on the dense distance graph is a step towards optimal algorithms for the important and fundamental problems mentioned in the introduction .",
    "in addition , we describe two current applications of our improvement . in both applications ,",
    "we obtain a speedup over previous algorithms by decomposing a region of @xmath13 vertices using an @xmath1-division and computing distances among the boundary vertices of the region in @xmath29 time using our fast shortest - path algorithm .",
    "_ maximum flow when the source and sink are close .",
    "_ in directed weighted planar graphs , we show how to compute maximum @xmath12-flow ( and min-@xmath12-cut ) in @xmath30 time if there is some path from @xmath31 to @xmath32 with at most @xmath9 vertices .",
    "the parameter @xmath9 appears in the time bounds of several previous maximum flow and minimum cut algorithms  @xcite .",
    "our @xmath8 time bound matches the fastest previously known maximum flow algorithms in directed weighted planar graphs for @xmath33  @xcite and for @xmath34  @xcite , and is asymptotically faster than previous algorithms for all other values of @xmath9 .",
    "see section  [ section : maxflow ] .",
    "we believe that by combining our fast shortest - path algorithm with ideas from the @xmath8 time min-@xmath12-cut algorithm of kaplan and nussbaum  @xcite and from the @xmath35 time min-@xmath12-cut algorithm of italiano et al .",
    "@xcite , we can get an @xmath36 time min-@xmath12-cut algorithm for undirected planar graphs .",
    "the details , which we were not able to compile in time for this submission , will appear in a later version of this paper .",
    "_ fast construction of ddgs with few boundary vertices . _",
    "the current bottleneck in various shortest paths and maximum flow algorithms in planar graphs ( e.g. , min-@xmath12-cut in an undirected graph  @xcite , shortest paths with negative lengths  @xcite ) is computing all boundary - to - boundary distances in a graph with @xmath13 vertices and @xmath37 boundary vertices that lie on a single face .",
    "currently , the fastest way to compute these @xmath38 distances is to use the mssp algorithm  @xcite .",
    "after @xmath24 preprocessing , it can report the distance from any boundary vertex to any other vertex ( boundary or not ) in @xmath39 time , so all boundary - to - boundary distances can be found in @xmath40 time .",
    "we give an algorithm that computes the distances among the @xmath10 boundary vertices in @xmath41 time .",
    "this algorithm can be used to construct a ddg of a region with @xmath13 vertices and @xmath42 boundary vertices in @xmath41 time . in general , this does not improve the @xmath43 ddg construction time using mssp since typically @xmath44 .",
    "however , there is an improvement when @xmath10 is much smaller . for @xmath45 ,",
    "our algorithm takes @xmath46 time .",
    "we conclude this section by discussing the interesting open problem of computing a ddg of a region with @xmath13 vertices of which @xmath47 are boundary vertices .",
    "as we already mentioned , the conventional way of computing a ddg is applying klein s mssp algorithm  @xcite , which requires @xmath43 time regardless of the value of @xmath10 .",
    "the mssp algorithm implicitly computes all the shortest - path trees rooted at vertices of a face @xmath48 by going around the face @xmath48 and for every boundary vertex @xmath21 of @xmath48 identifying the _ pivots _ ( arc changes ) from the tree rooted at the vertex preceding @xmath21 on @xmath48 to the tree rooted at @xmath21 .",
    "eisenstat and klein  @xcite showed an @xmath49 lower bound on the number of comparisons between arc weights that any mssp algorithm requires for identifying all the pivots .",
    "lower bound by using a face @xmath48 with @xmath50 boundary vertices ; generalizing the same proof for a face with @xmath10 vertices gives the @xmath51 bound .",
    "] our algorithm can be used to compute the ddg of a region in @xmath41 time without computing all the pivots .",
    "note , however , that it does not break the @xmath49 lower bound . the ddg computation problem may be an easier problem than the mssp problem , since we are interested only in the @xmath52 distances among the boundary vertices and we are not required to compute the pivots . whether the ddg of a region can be computed in @xmath53 remains an open problem .",
    "[ [ roadmap . ] ] * roadmap . *",
    "+ + + + + + + + + +    we begin in section  [ ch : fr ] with a description of fakcharoenphol and rao s fr - dijkstra algorithm and the monge heap data structure .",
    "this description is essential since we modify the internal structure of the monge heaps to achieve our results . in section  [ warmup ]",
    "we give a warmup improvement of fr - dijkstra by introducing a new rmq data structure into the monge heaps .",
    "this improvement decouples the logarithmic dependency on @xmath13 from the logarithmic dependency on @xmath1 . in section  [ sec : hkrs - fr ]",
    "we eliminate the logarithmic dependency on @xmath13 altogether by combining the shortest - path algorithm of henzinger et al . with modified monge heaps similar to those described in the warmup .",
    "finally , in section  [ section : applications ] we give the details of two applications that use our algorithm .    for clarity of the presentation ,",
    "we defer to an appendix some of the proofs which are less essential for the overall understanding of our algorithm .",
    "in this section we overview fr - dijkstra that emulates dijkstra s algorithm on the dense distance graph . parts of our description slightly deviates from the original description of  @xcite and were adapted from  @xcite .",
    "we emphasize that this description is not new , and is provided as a basis for the modifications introduced in subsequent sections .",
    "recall dijkstra s algorithm .",
    "it maintains a heap of vertices labeled by estimates @xmath54 of their distances from the root . at each iteration , the vertex @xmath21 with minimum @xmath54",
    "is activated : it is extracted from the heap , and all its adjacent arcs are relaxed .",
    "fr - dijkstra implements extractmin and activate efficiently .    the vertices of @xmath17 correspond to the @xmath55 boundary vertices of a region @xmath56 of an @xmath1division with a constant number of holes . we assume in our description that @xmath56 has a single hole .",
    "there is a standard simple way to handle a constant number of holes using the single hole case with only a constant factor overhead ( cf .",
    "* section 5 ) , ( * ? ? ?",
    "* section 5.2 ) , and  ( * ? ? ? * section 4.4 ) ) .",
    "there is a natural cyclic order on the vertices of @xmath17 according to their order on the single face ( hole ) of the region @xmath56 .",
    "a matrix @xmath57 is a _ monge _ matrix if for any pair of rows @xmath58 and columns @xmath59 we have that @xmath60 .",
    "a _ partial _",
    "monge matrix is a monge matrix where some of the entries of @xmath57 are undefined , but the defined entries in each row and in each column are contiguous .",
    "it is well known ( cf .",
    "@xcite ) that the upper and lower triangles of the ( weighted ) incidence matrix @xmath57 of @xmath17 are _ partial _ monge matrices .    to implement extractmin and activate efficiently , each complete graph @xmath17 in the ddg is decomposed into complete bipartite graphs .",
    "the vertices of @xmath17 are first split into two consecutive halves @xmath61 and @xmath62 , the complete bipartite graph on @xmath61 and @xmath62 is added to the decomposition , and the same process is applied recursively on @xmath61 and on @xmath62 .",
    "each vertex of @xmath17 therefore appears in @xmath63 bipartite subgraphs .",
    "furthermore , and each bipartite subgraph of the decomposition corresponds to a submatrix of @xmath57 that is _ fully _ monge .     into complete bipartite graphs ( left )",
    "can also be viewed as a partition of the incidence matrix of @xmath17 into monge matrices ( right).,title=\"fig : \" ]    into complete bipartite graphs ( left ) can also be viewed as a partition of the incidence matrix of @xmath17 into monge matrices ( right).,title=\"fig : \" ] [ fig : bipartitemonge ]    let @xmath64 denote the set of all bipartite graphs in the decompositions of all @xmath17 s . note that @xmath65 .",
    "the algorithm maintains a data - structure @xmath66 , called a _",
    "monge heap _",
    ", for each bipartite graph @xmath67 .",
    "are aggregated into a single data structure which  @xcite call monge heap .",
    "we do not use this aggregation . ]",
    "let @xmath68 be the bipartition of @xmath69 s vertices .",
    "the monge heap supports :    = 1em    activate@xmath70 - sets the label of vertex @xmath71 to be @xmath72 , and implicitly relaxes all arcs incident to @xmath73 .",
    "this operation may be called at most once per vertex .",
    "findmin - returns the vertex @xmath74 with minimum label among the vertices not yet extracted .",
    "extractmin - removes the vertex @xmath75 with minimum label among the vertices not yet extracted .",
    "the minimum element of every monge heap @xmath66 is maintained in a regular global heap @xmath76 . in each iteration",
    ", a vertex @xmath21 with global minimum label is extracted from @xmath76 .",
    "the vertex @xmath21 is then extracted from the monge heap @xmath77 that contributed @xmath21 , and the new minimum vertex of @xmath77 is added to @xmath76 .",
    "note that since a vertex @xmath21 appears in multiple @xmath69 s , @xmath21 may be extracted as the minimum element of the global heap @xmath76 multiple times , once for each monge heap it appears in .",
    "instead , @xmath76 maintains only one representative for every region @xmath56 that is keyed by the minimum element of all ( bipartite ) monge heaps of @xmath56 .",
    "when this representative is the minimum in @xmath76 , they do not extract it form @xmath76 but instead increase its key to be the new ( next ) minimum of @xmath56 .",
    "in other words , at any point in time , fr hold @xmath78 elements in @xmath76 ( one element for each region ) and overall it performs @xmath79 increasekey operations , while in our description @xmath76 holds @xmath80 elements ( one element for each monge heap ) and overall we perform @xmath79 extractmin and insert operations .",
    "the overall @xmath81 running time is the same in both presentations . ] .",
    "however , the label @xmath82 of @xmath21 is finalized at the first time @xmath21 is extracted . at that time , and only at that time , the algorithm marks @xmath21 as finalized , activates @xmath21 using activate in _ all _ monge heaps such that @xmath83 , and updates the representatives of those monge heaps in @xmath76 .    [ [ analysis . ] ] * analysis . * + + + + + + + + + + +    since each vertex appears in @xmath63 bipartite graphs @xmath69 in @xmath84 , the number of times each vertex is extracted from the global heap @xmath85 is @xmath63 .",
    "since @xmath76 contains one representative element from each monge heap @xmath66 , a single call to extractmin on @xmath76 takes @xmath86 time .",
    "therefore , the total time spent on extracting vertices from @xmath76 is @xmath87 .    as for the cost of operations on the monge heaps , activate and extractmin are called at most once per vertex in each monge heap , and the number of calls to findmin is bounded by the number of calls to activate and extractmin .",
    "we next show how to implement each of these operations in @xmath63 time .",
    "since each vertex appears in @xmath63 monge heaps , the total time spent on operations on the monge heaps is @xmath88 .",
    "[ [ implementing - monge - heaps . ] ] * implementing monge heaps . *",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + +    let @xmath89 be the monge heap of a bipartite subgraph with columns @xmath61 and @xmath62 and a corresponding incidence matrix @xmath57 . for every vertex @xmath90",
    "we maintain a bit indicating whether @xmath21 has already been extracted from @xmath89 ( i.e. , finalized ) or not .",
    "the distance label of a vertex @xmath74 is defined to be @xmath91 and is not stored explicitly .",
    "instead , we say that @xmath92 is the _ parent _ of @xmath74 if @xmath93 is finite and @xmath94 .",
    "as the algorithm progresses , the distance labels @xmath93 of vertices @xmath95 ( hence the parents of vertices @xmath90 ) may change .",
    "we maintain a binary search tree @xmath96 of triplets @xmath97 indicating that @xmath73 is the current parent of all vertices of @xmath62 between @xmath98 and @xmath99 .",
    "note that a vertex @xmath100 may appear in more than one triplet because , after extracting vertices of @xmath62 , the non - extracted vertices of which @xmath73 is a parent might consist of several intervals .",
    "the monge property of @xmath57 guarantees that if @xmath73 precedes @xmath101 in @xmath61 then all intervals of @xmath73 precede all intervals of @xmath101 .",
    "finally , the monge heap structure also consists of a standard heap @xmath102 containing , for every triplet @xmath103 , a vertex @xmath104 between @xmath98 and @xmath99 that minimizes @xmath105 . by maintaining subtree minima at the vertices of @xmath96 . ]",
    "= 1em    findmin : return a vertex @xmath104 with minimum distance label in @xmath102 .",
    "extractmin : extract the vertex @xmath104 with minimum distance label from @xmath102 and mark @xmath104 as extracted .",
    "find the ( unique ) triplet @xmath106 containing @xmath104 in @xmath96 .",
    "let @xmath107 and @xmath108 be the members of @xmath62 that precede and follow @xmath104 , respectively , within this triplet .",
    "the algorithm replaces the triplet @xmath106 with two triplets @xmath109 and @xmath110 ( if these intervals are defined ) . in each of these new triplets",
    "it finds the vertex @xmath111 that minimizes @xmath112 and inserts @xmath111 into @xmath102 .",
    "the vertex @xmath111 is the minimum entry of @xmath57 in a given row and a range of columns and is found in @xmath63 time using a naive one - dimensional static rmq data structure on each column of @xmath57 .",
    "activate(@xmath113 ) : set @xmath114 and find the children of @xmath73 in @xmath62 .",
    "if @xmath73 is the first vertex in the monge heap for which this operation is applied then all the vertices of @xmath62 are children of @xmath73 .",
    "otherwise , we show how to find the children of @xmath73 whose current parent precedes @xmath73 in @xmath61 ( the ones whose current parent follows @xmath73 in @xmath61 are found symmetrically ) .    we traverse the triplets in @xmath96 one by one backwards starting with triplet @xmath115 such that @xmath116 precedes @xmath73 in @xmath61 .",
    "we continue until we reach a triplet @xmath117 such that @xmath118 .",
    "if @xmath119 we do nothing .",
    "if we scanned all triplets preceding @xmath32 without finding @xmath120 then the first child of @xmath73 must belong to the last triplet @xmath121 that we scanned .",
    "it is found by a binary search on the interval of @xmath62 between @xmath122 and @xmath123 .",
    "otherwise , the first child of @xmath73 must belong to the triplet @xmath121 following @xmath120 , and can again be found via binary search .",
    "let @xmath124 ( resp . ,",
    "@xmath125 ) be the first ( resp . , last ) child of @xmath73 in @xmath62 , as obtained in the preceding step .",
    "note that there are no extracted vertices between @xmath124 and @xmath125 in @xmath62 .",
    "this is because we find the distances in monotonically increasing order , and when we extract a vertex @xmath104 it is the minimum in the global heap @xmath85 so it will never acquire a new parent .",
    "we therefore insert a new triplet @xmath126 into @xmath96 .",
    "we remove from @xmath96 all other triplets containing vertices between @xmath124 and @xmath125 , and remove from @xmath102 the elements contributed by these triplets .",
    "let @xmath127 be the removed triplet that contains @xmath124 .",
    "if @xmath128 then we insert a new triplet @xmath129 where @xmath130 is the vertex preceding @xmath124 in @xmath62 .",
    "similarly , if @xmath131 is the removed triplet that contains @xmath125 and @xmath132 then we insert a new triplet @xmath133 where @xmath134 is the vertex following @xmath125 in @xmath62 .    finally , we update the three values that the new triplets @xmath135 and @xmath133 contribute to @xmath102 .",
    "we find these values by a range minimum query to the naive rmq data structure .",
    "[ [ analysis.-1 ] ] * analysis . *",
    "+ + + + + + + + + + +    clearly , findmin takes @xmath136 time .",
    "both extractmin and activate insert a constant number of new triplets to @xmath96 in @xmath63 time , make a constant number of range - minimum queries in @xmath63 time , and update the representatives of the new triplets in the heap @xmath102 in @xmath63 time .",
    "activate(@xmath137 ) , however , may traverse many triplets to identify the children of @xmath73 .",
    "since all except at most two of the triplets that it traverses are removed , we can charge their traversal and removal to their insertion in a previous extractmin or activate .",
    "in this section we show how to modify fr - dijkstra from @xmath138 to @xmath139 .",
    "this improves fr - dijkstra for small values of @xmath1 and is obtained by avoiding the vertex copies in the global heap @xmath76 using a decremental rmq data structure .",
    "recall that , at any given time , the global heap @xmath76 of fr - dijkstra maintains @xmath140 items  one item for each monge heap .",
    "however , each vertex has copies in @xmath63 monge heaps so overall @xmath141 items are extracted from @xmath76 .",
    "each extraction takes @xmath86 time so the complexity of fr - dijkstra is @xmath142 . in our modified algorithm",
    "the global heap @xmath143 contains , for each vertex @xmath21 , a single item whose key is the minimum label over all copies of @xmath21 . in other words",
    ", @xmath76 maintains a total of @xmath140 items throughout the entire execution .",
    "an item that corresponds to a vertex @xmath21 is extracted from @xmath143 only once in @xmath39 time , but when it is extracted it may incur @xmath63 calls to decreasekey .",
    "we use a fibonacci heap  @xcite for @xmath76 that only takes constant time for decreasekey . note that the total number of operations on @xmath143 is still @xmath144 .",
    "the main problem with having one copy is that a triplet @xmath126 might now contain extracted vertices between @xmath124 and @xmath125 in @xmath62 .",
    "the original implementation of fr - dijkstra uses an elementary rmq data structure ( a binary search tree for each row of the @xmath145 matrix @xmath57 ) .",
    "this data structure is only queried on intervals @xmath146 $ ] that have no extracted vertices . for such queries",
    "one may also use the rmq data structure of kaplan et al .",
    "@xcite , which has the same @xmath63 query time and requires only @xmath147 construction time and space . to cope with query intervals @xmath146 $ ] that have extracted vertices we next present a",
    "_ dynamic _",
    "rmq data structure that can handle extractions .",
    "[ lemma : rmq ] given an @xmath148 partial monge matrix @xmath57 , one can construct in @xmath24 time a dynamic data structure that supports the following operations : ( 1 ) in @xmath149 time , set all entries of a given column as inactive ( 2 ) in @xmath149 time , set all entries of a given column as active ( 3 ) in @xmath150 time , report the minimum active entry in a query row and a contiguous range of columns ( or @xmath151 if no such entry exists ) .",
    "+ for a decremental data structure in which only operations 1 and 3 are allowed , operation 1 can be supported in amortized @xmath152 time and operation 3 in worst case @xmath153 time .",
    "the proof of lemma  [ lemma : rmq ] appears in appendix  [ ap : rmqproof ] . note that we stated the above lemma for partial monge matrices and not full monge matrices",
    "this is because we apply the rmq data structure to the upper and lower triangles of the @xmath154 incidence matrix @xmath57 of @xmath17 ( which are partial monge ) as opposed to fr - dijkstra that uses a separate rmq for each bipartite subgraph ( whose corresponding submatrix is full monge ) of @xmath17 s decomposition . in this section",
    "we only deactivate columns of @xmath57 and never activate columns .",
    "therefore , we use the second data structure in the lemma . the first data structure in lemma  [ lemma : rmq ] is used in section  [ sec : hkrs - fr ] .    [ [ modifying - fr - dijkstra . ] ] * modifying fr - dijkstra . *",
    "+ + + + + + + + + + + + + + + + + + + + + + + +    we already mentioned that we want @xmath76 to be a fibonacci heap and to include one item per boundary vertex @xmath21 .",
    "we also change the monge heaps so that @xmath102 now contains , for every triplet @xmath106 , a vertex that minimizes @xmath155 among vertices @xmath104 between @xmath98 and @xmath99 that where _ not yet extracted from @xmath76_. if all vertices between @xmath98 and @xmath99 were already extracted then the triplet has no representative in @xmath102 .",
    "as before , in each iteration , a minimum item , corresponding to a vertex @xmath21 is extracted from @xmath76 in @xmath39 time . in fr - dijkstra , @xmath21 is then extracted from the ( unique ) monge heap @xmath77 that contributed @xmath21 and the new minimum vertex of @xmath77 is added to @xmath76 . in our algorithm ,",
    "@xmath21 s extraction from @xmath76 affects all the @xmath63 @xmath77 s that include @xmath21 in their @xmath62 . before handling any of them",
    "we apply operation ( 1 ) of the rmq data structure of lemma  [ lemma : rmq ] in @xmath156 time .",
    "then , for each such @xmath157 , if @xmath21 was the minimum of some triplet @xmath106 then we apply the following operations : ( i ) remove @xmath21 from @xmath102 in @xmath158 time , ( ii ) query in @xmath159 time the rmq data structure of lemma  [ lemma : rmq ] for vertex @xmath160 , ( iii ) insert @xmath111 into @xmath102 in @xmath63 time .",
    "note that we do not replace the triplet @xmath106 with two triplets as fr do in extractmin .",
    "finally , if @xmath21 was also the minimum of @xmath102 then let @xmath116 be the new minimum of @xmath102 .",
    "if @xmath116 s value in @xmath76 is larger than in @xmath102 then we update it in @xmath76 using decreasekey in constant time .",
    "next , we need to activate @xmath21 in all @xmath77 s that have @xmath21 in their @xmath61 .",
    "this is done exactly as in fr - dijkstra by removing ( possibly many ) triplets from @xmath96 and inserting three new triplets .",
    "we now find the minimum in each of these three triplets by querying the rmq data structure of lemma  [ lemma : rmq ] .",
    "finally , we update @xmath102 and if this changes the minimum element @xmath116 of @xmath102 and @xmath116 s value in @xmath76 is larger than in @xmath102 then we update it in @xmath76 using decreasekey in constant time .    to summarize",
    ", each vertex @xmath21 of the @xmath140 vertices is extracted once from @xmath76 in @xmath39 time . for each such extraction",
    "we do a single rmq column deactivation in @xmath161 time , we do @xmath63 rmq queries in total @xmath161 time incurring @xmath63 decreasekey operations on @xmath76 in total @xmath63 time , we activate @xmath21 in @xmath162 time , and finally we do @xmath63 updates to @xmath102 in total @xmath162 time incurring @xmath63 decreasekey operations on @xmath76 in total @xmath63 time .",
    "the overall complexity is thus @xmath163 .",
    "in this section we describe our main result : combining the modified fr - dijkstra from the previous section with hkrs  @xcite to obtain a shortest - path algorithm that runs in @xmath164 time .",
    "our algorithm first performs the following preprocessing steps ( described below in more detail ) .",
    "@xmath0 is an @xmath13-vertex directed planar graph with non - negative arc lengths and degree at most 3 .",
    "let @xmath166 be such that @xmath167 and @xmath168 for every @xmath169 .",
    "compute a recursive @xmath170division of @xmath0 with a constant number of holes compute the dense distance graph of @xmath56 initialize all bipartite monge heaps of @xmath56    a recursive @xmath170division with @xmath166 is a decomposition tree of @xmath0 in which the root corresponds to the entire graph @xmath0 and the nodes at height @xmath171 correspond to regions that form an @xmath172division of @xmath0 . throughout the paper we use @xmath1-divisions with a constant number of holes .",
    "our algorithm differs from hkrs  @xcite in our choice of @xmath173 ( in hkrs @xmath174 ) .",
    "this results in a decomposition tree of height roughly @xmath175 ( in hkrs it is roughly @xmath176 ) . for @xmath177",
    ", the regions of the @xmath172division are called height-@xmath171 regions .",
    "the height of a vertex @xmath21 is defined as the largest integer @xmath171 such that @xmath21 is a boundary vertex of a height-@xmath171 region .",
    "our algorithm computes the recursive @xmath170division in linear time using the algorithm of  @xcite .",
    "we assume the input graph @xmath0 has degree at most three . with this assumption the algorithm of  @xcite",
    "can be easily modified to return an @xmath170division in which , for every @xmath171 , each vertex @xmath21 belongs to at most 3 height-@xmath171 regions .",
    "we next describe the height-0 regions . in  @xcite ,",
    "height-0 regions comprise of individual edges .",
    "we define height-0 regions differently .",
    "consider a height-1 region @xmath56 ( that is , @xmath56 is a region with @xmath178 edges and @xmath179 boundary vertices ) .",
    "the ddg of @xmath56 is a complete weighted graph over the boundary vertices of @xmath56 , so it has @xmath16 vertices and @xmath180 edges .",
    "consider the set of monge heaps ( mhs ) of @xmath56 .",
    "each mh corresponds to a bipartite graph with left side @xmath61 and right side @xmath62 .",
    "each boundary vertex @xmath21 of @xmath56 appears in @xmath63 mhs . for each occurrence of @xmath21 on the @xmath62 side of some mh @xmath181",
    ", we create a copy @xmath182 of @xmath21 .",
    "vertices of @xmath0 such as @xmath21 are called _ natural vertices _ , and we say that @xmath182 is called a _ copy _ of @xmath21 ( each natural vertex has @xmath63 copies ) .",
    "we add a zero length arc from every @xmath182 to @xmath21 .",
    "each of these newly added arcs is the single element in a distinct height-0 region @xmath56 .",
    "the label of such an arc ( and hence the label of the corresponding region @xmath56 ) is defined ( as in  @xcite ) to be the label of its tail , and is initialized to infinity .",
    "denote the bipartition of the vertex set of an mh @xmath181 by @xmath183 .",
    "let @xmath181 be a mh .",
    "for every vertex @xmath184 , we construct a hyperarc @xmath185 ( directed hyperedge ) whose tail is @xmath21 and whose heads are @xmath186 .",
    "we associate @xmath185 with the mh @xmath181 .",
    "each hyperarc @xmath185 is the single element in a distinct height-0 region of @xmath56 .",
    "the label of this height-0 region is defined to be the label of the tail of @xmath185 , and it is initialized to infinity .",
    "note that our construction is such that the arcs of the ddg do not belong to any region @xmath56 in the algorithm .",
    "rather , an arc of the ddg is represented in the algorithm in two ways ; by a hyperarc , and by the monge heap to which it belongs .",
    "therefore , from now on we may refer to and think of an arc @xmath187 of the ddg as an arc @xmath188 , and to a vertex @xmath189 as the copy @xmath190 .",
    "[ obs : height0 ] the height of every copy vertex @xmath182 is 0 .    the construction is such that all arcs and hyperarcs incident to a vertex @xmath182 correspond to height-0 regions of the same height-1 region @xmath56 .",
    "therefore , @xmath182 is not a boundary vertex of @xmath56 , so the height of @xmath182 is 0 .",
    "let @xmath191 be the constants such that an @xmath1-division of an @xmath13-vertex graph has at most @xmath192 regions , each having at most @xmath193 boundary vertices .",
    "let @xmath194 be the constant such that there are at most @xmath195 height-0 regions involving @xmath21 .",
    "[ lem : num-0-regions ] the number of height-0 regions is @xmath196    there are at most @xmath197 regions @xmath56 of height-1 .",
    "a height-1 region @xmath56 has at most @xmath198 boundary vertices .",
    "each boundary vertex @xmath21 of @xmath56 appears in @xmath199 mhs , so it has @xmath200 copies .",
    "hence there are @xmath199 height-0 regions that correspond to individual arcs @xmath201 , and @xmath199 height-0 regions that correspond to individual hyperarcs whose tail is @xmath21 .",
    "there are at most @xmath195 height-0 regions involving @xmath21 .",
    "the total number of height-0 regions is therefore @xmath196 .",
    "let @xmath181 be a mh .",
    "the arcs of the ddg represented by @xmath181 all have their tails in @xmath202 and heads in @xmath203 .",
    "let @xmath82 denote the current label of vertex @xmath21 , and let @xmath204 denote the length of the @xmath21-to-@xmath116 arc in the ddg .",
    "each vertex @xmath205 has an associated set of consecutive vertices in @xmath203 such that @xmath206 we have @xmath207 .",
    "the vertices of @xmath203 in the interval associated with a vertex @xmath21 of @xmath202 are called _ the children of @xmath21 _ , and @xmath21 is called _ the parent _ of these vertices . at any given time",
    "a vertex @xmath208 is the child of exactly one vertex @xmath205 ( the only exception is that upon initialization , no vertex is assigned a parent ) .",
    "a vertex @xmath208 can be either _ active _ or _",
    "inactive_. initially all vertices are active .",
    "a mh supports the following operations :    * fr - relax@xmath209 - implicitly relax all arcs of mh @xmath181 emanating from vertex @xmath205 .",
    "internally , adds to the set of children of @xmath21 all the vertices in @xmath203 whose labels decreased because of these relaxations .",
    "this operation activates any of the newly acquired children of @xmath21 that were inactive . *",
    "fr - getminchild@xmath209 - returns the active child @xmath190 of @xmath21 in mh @xmath181 minimizing @xmath210 . *",
    "fr - extract@xmath211 - makes vertex @xmath182 inactive in mh @xmath181 .",
    "let @xmath20 be the parent of @xmath182 in mh @xmath181 .",
    "returns the active child @xmath190 of @xmath20 in @xmath181 minimizing @xmath212 .",
    "we discuss two implementations of these monge heaps in appendix  [ ap : mhimplement ] .",
    "these implementations are summarized in the following lemma .",
    "[ lem : hkrs - rmq ] there exist two implementations of the above mh with the following construction time ( for all mhs of all regions in an @xmath1division of an @xmath13-vertex graph ) , and operation times :    1 .",
    "@xmath164 construction time and @xmath213 time per operation .",
    "@xmath214 construction time and @xmath63 time per operation .    in some applications , in particular in those that work with _ reduced lengths _ ( such as the maximum flow algorithm of section  [ section : maxflow ] ) ,",
    "shortest path computations on the ddg are performed multiple times with slightly different ddgs . in each time , the new ddg can be obtained quickly but the rmq data structure needs to be built from scratch . for such applications , the fast construction time of",
    "the first implementation is crucial . for other applications which perform multiple shortest path computations on the same ddg such as the application in section  [ sec : ddgapp ] ,",
    "the second implementation is appropriate , and yields slightly faster shortest paths computations .",
    "the @xmath26-time construction is not a bottleneck of such applications since it is performed once , and matches the currently fastest known construction of the ddg . in what follows",
    "we denote the time to perform an mh operation as @xmath215 where the constant @xmath216 is either 3 or 1 depending on the implementation choice .",
    "the pseudocode of the algorithm is given below .",
    "parts of the pseudocode appear in black font and parts in blue font .",
    "the black parts describe our algorithm , and at this point in the paper it is enough to focus only on them .",
    "the blue parts are additions to the algorithm that should not ( and in fact can not ) be implemented .",
    "they will be used later ( section  [ sec : analysis ] ) for the analysis .",
    "the algorithm maintains a label @xmath82 for each vertex @xmath21 .",
    "initially all labels are infinite , except the label of the source @xmath31 , which is 0 .",
    "for each height-@xmath171 region @xmath56 , the algorithm maintains a heap @xmath217 ( implemented using fibonacci heaps  @xcite ) containing the height-(@xmath218 ) subregions of @xmath56 . for a height-0 region @xmath56",
    ", @xmath217 contains the single element ( arc or hyperarc ) @xmath185 comprising the region @xmath56 .",
    "if @xmath21 is the tail of @xmath185 , then the key of this single element is @xmath82 if @xmath185 is not relaxed , and infinity otherwise .",
    "for @xmath219 a height-@xmath171 region @xmath56 , the key of a subregion @xmath220 of @xmath56 in @xmath217 is @xmath221 .",
    "such heaps were also used in  @xcite but they were not implemented by fibonacci heaps .",
    "the heaps support the following operations : @xmath222 .",
    "the first four operations take constant amortized time , and the fourth takes logarithmic amortized time .",
    "let @xmath21 be the tail of @xmath185 let @xmath181 be the monge heap to which @xmath185 belongs @xmath223 [ line : frrelax ] @xmath224 fr - getminchild@xmath223 [ line : minchild ] [ line : hyperdebt ] @xmath225 length of arc @xmath187 in the ddg of @xmath181 [ line : minchild - relax ] let @xmath220 be the height-0 region consisting of the arc @xmath226 update@xmath227 [ line : minchild - update ] @xmath228 @xmath229 [ line : v - relax ] update@xmath230 [ line : update ] @xmath231 fr - extract@xmath211 [ line : frextract ] [ line : arcdebt ] @xmath225 length of arc @xmath187 in the ddg of @xmath181 [ line : minchild_a ] let @xmath220 be the height-0 region consisting of the arc @xmath226 update@xmath227 [ line : minchild_b ] @xmath232 @xmath233 process@xmath234 [ line : proc ] @xmath235[line : updater ] [ line : stable ]       @xmath56 is a region , @xmath124 is an item of @xmath217 , @xmath10 is a key value .",
    "@xmath236 [ line : entry ] @xmath237 [ line : upd1 ] [ line : upd2 ]    as in  @xcite , the main procedure of the algorithm is the procedure process , which processes a region @xmath56 .",
    "the algorithm repeatedly calls process on the region @xmath238 corresponding to the entire graph , until @xmath239 is infinite , at which point the labels @xmath54 are the correct shortest path distances . as in  @xcite , processing a height-@xmath171 region @xmath56 for @xmath177 consist of calling process on at most @xmath240 subregions @xmath220 of @xmath56 ( line  [ line : proc ] ) . processing a region",
    "@xmath220 may change @xmath221 , so the algorithm updates the key of @xmath220 in @xmath217 in line  [ line : updater ] .",
    "( and hence keys ) only change by relaxations or by setting to infinity , @xmath221 may only increase when processing @xmath220 . therefore updating the key of @xmath220 in @xmath217 is done using @xmath241 . ]",
    "our algorithm differs from  @xcite in processing height-0 regions .",
    "let us first recall how  @xcite processes height-0 regions .",
    "each height-0 region @xmath56 corresponds to a single arc @xmath19 , and processing @xmath56 consists of relaxing @xmath19 .",
    "if the relaxation decreases @xmath82 , then all arcs whose tail is @xmath21 become unrelaxed . for every such arc @xmath242 the key of the corresponding height-0 region @xmath220 corresponding to @xmath242 needs to be updated to @xmath82 .",
    "doing so may require updating the keys of ancestor regions of @xmath220 .",
    "the procedure update performs this chain of updates .    in our case",
    ", the height-0 regions may correspond to single arcs or to single hyperarcs .",
    "if a height-0 region @xmath56 consists of a single hyperarc @xmath185 whose tail is @xmath21 , then processing @xmath56 implicitly relaxes all the arcs of the ddg represented by @xmath185 by calling fr - relax ( line  [ line : frrelax ] ) .",
    "we can only afford to update explicitly the label of a single child of @xmath21 .",
    "we do so for the child @xmath190 of @xmath21 with minimum label ( line  [ line : minchild - relax ] ) .",
    "since @xmath190 is a copy vertex of a natural vertex @xmath116 , there is exactly one arc whose tail is @xmath190 ( namely , @xmath243 ) , and no hyperarcs whose tail is @xmath190 .",
    "the arc @xmath243 is now unrelaxed , so the key of the height-0 region corresponding to @xmath243 needs to be updated by a call to update ( line  [ line : minchild - update ] ) .",
    "if a height-0 region @xmath56 consists of a single arc @xmath201 , then , as in  @xcite , processing @xmath56 explicitly relaxes all elements ( hyperarcs in our case ) , whose tail is @xmath21 , and calls update to update the keys in the heaps of the corresponding height-0 regions and their ancestor regions ( lines  [ line : v - relax]  [ line : update ] ) . similarly to the implementation of fr - dijkstra , since at this point the vertex @xmath182 has no outgoing unrelaxed arcs , the algorithm extracts @xmath182 from the monge heap @xmath181 to which it belongs ( so @xmath182 becomes inactive ) . among the children of @xmath21",
    "there is now a new minimum active child @xmath190 ( @xmath182 may have been the previous minimum , but it has just become inactive ) .",
    "the algorithm handles @xmath190 , as in the previous case , by updating the key of the height-0 region corresponding to @xmath243 with a call to update ( line  [ line : minchild_b ] ) .",
    "distances in the input graph and in the graph constructed by our algorithm are identical since duplicating vertices and adding zero - length arcs between the copies does not affect distances .",
    "we note that the correctness of the algorithm in  @xcite does not depend on the choice of attention span ( the parameters @xmath240 ) .",
    "these parameters only affect the running time .",
    "in particular , an implementation of that algorithm in which the attention span is not fixed would yield the correct distances upon termination .",
    "we argue the correctness of our algorithm by considering such a variant of the algorithm of  @xcite on the graph constructed by our algorithm , where each hyperarc is represented by the individual arcs forming it .",
    "we refer to this variant as algorithm h. in what follows we still refer to hyperarcs to make the grouping of the individual arcs clear .",
    "we say that an arc @xmath188 belongs to hyperarc @xmath185 if @xmath188 is one of the arcs forming @xmath185 .",
    "let @xmath185 be a hyperarc whose tail is @xmath21 .",
    "let @xmath56 be the height-1 region containing @xmath185 . consider a time in the execution of algorithm h when @xmath56 is processed and chooses to process a height-0 region corresponding to a single arc @xmath188 that belongs to @xmath185 .",
    "this implies that the label of @xmath188 is the minimum among all height-0 regions ( edges ) in @xmath56 .",
    "observe that at this time all other arcs of @xmath185 have the same label as that of @xmath188 ( they might have infinite label if they have already been processed ) .",
    "furthermore , since lengths are non - negative , processing @xmath188 can not decrease the label of @xmath190 below that of @xmath21 .",
    "we define algorithm h to process all arcs corresponding to @xmath185 one after the other , regardless of the attention span .",
    "the above discussion implies that algorithm h terminates with the correct distance labels for all vertices in the graph .",
    "we now show that algorithm h and our algorithm relax exactly the same arcs , and in the same order .",
    "the only difference between algorithm h and our algorithm is that our algorithm performs implicit relaxations using monge heaps , while algorithm h performs all relaxations explicitly . in particular ,",
    "when relaxing a hyperarc @xmath185 whose tail is @xmath21 , our algorithm only updates the label of the minimum child of @xmath21 ( lines  [ line : minchild][line : minchild - relax ] ) , whereas algorithm h updates the labels of all children of @xmath21 .",
    "we call a vertex @xmath190 _ latent _ if its label does not reflect prior relaxations of arcs @xmath188 incident to it ( because those relaxations were implicit ) .",
    "a vertex that is not latent is _",
    "accurate_. note that whenever the label of a vertex @xmath190 is updated by our algorithm ( i.e. , @xmath190 becomes accurate ) , the label of the height-0 region consisting of the unique arc @xmath243 is also updated ( lines  [ line : minchild][line : minchild - update ] ) .    to establish that the order of relaxations is the same in both algorithms , it suffices to establish the following lemma :    the following invariants hold :    1 .",
    "every latent vertex is active .",
    "2 .   let @xmath181 be an mh , and let @xmath21 be a vertex in @xmath202 .",
    "let @xmath244 be the set of active children of @xmath21 with minimum label .",
    "if @xmath244 is non - empty then there is a vertex in @xmath244 that is accurate .",
    "if the key of a height-0 region consisting of a single arc @xmath243 is finite then @xmath190 is active .",
    "the proof is by induction on the calls to process on height-0 regions performed by our algorithm .",
    "initially there are no latent vertices , all the vertices on the @xmath62 side of any mh are active , and all height-0 regions consisting of a single arc have infinite labels , so all invariants trivially hold .",
    "the inductive step consists of two cases .",
    "suppose first that the height-0 region being processed consists of a single hyperarc @xmath185 .",
    "this hyperarc is implicitly relaxed in line  [ line : frrelax ] .",
    "all the vertices whose label should be changed by the relaxation are guaranteed to become active ( by the specification of fr - relax ) . among these vertices , @xmath190 , the vertex with minimum label , is explicitly relaxed ( lines  [ line : minchild][line : minchild - relax ] ) , so it is accurate .",
    "all the others are latent .",
    "this establishes that the first two invariants are maintained . in line  [ line : minchild - update ]",
    "the key of the height-0 region @xmath220 consisting of the unique arc whose tail is @xmath190 is set to a finite value . since @xmath190 has just become active , the third invariant is also maintained .",
    "suppose now that the height-0 region being processed consists of a single arc @xmath201 . by the third invariant",
    ", @xmath182 is active . by the second invariant",
    ", @xmath182 must be accurate .",
    "the arc @xmath201 is explicitly relaxed , which does not create any new latent vertices . in line  [ line :",
    "frextract ] , @xmath182 is deactivated .",
    "this is the only case where a vertex is deactivated . since @xmath182 is accurate , invariant  1 is maintained .",
    "let @xmath20 be the parent of @xmath182 in mh @xmath181 . by the specification of fr - extract",
    ", it returns an active child @xmath190 of @xmath20 whose label is minimum among all of @xmath20 s active children .",
    "the label of @xmath190 is explicitly updated in line  [ line : minchild_a ] , so invariant  2 is maintained .",
    "the height-0 region whose label is set to a finite value in line  [ line : minchild_b ] consists of the single arc @xmath243 . since @xmath190 is active , invariant  3 is maintained .",
    "note that invariants  1 and  2 guarantee that in every monge heap @xmath181 , if there exists a latent vertex @xmath190 then there exists an accurate vertex @xmath245 whose label is at most the correct label of @xmath190 ( by correct label we mean the label that @xmath190 would have gotten had we performed the relaxations explicitly ) .",
    "this implies that as long as a vertex is latent , its label does not affect the running of the algorithm . to see this ,",
    "let @xmath56 be the height-1 region that contains both @xmath190 and @xmath245 . by observation  [ obs : height0 ] ,",
    "neither @xmath190 or @xmath245 are boundary vertices of @xmath56 . since the label of @xmath245 is smaller than that of @xmath190 no arc whose tail is @xmath190 would become the minimum of the heap @xmath217 as long as @xmath190 is latent .",
    "this implies , by a trivial inductive argument , that for any @xmath177 , for any height-@xmath171 region @xmath56 , the minimum elements in the heap @xmath217 in our algorithm and in algorithm h have the same label , and in fact correspond to the same arc ( or to a hyperarc @xmath185 in our algorithm and to one of the arcs that belong to @xmath185 in algorithm h ) .",
    "it follows that the two algorithms perform the same relaxations and in the same order .",
    "hence our algorithm produces the same labels as algorithm h , and is therefore correct .",
    "the analysis follows that of hkrs  @xcite .",
    "we use the more recent description of the charging scheme in  @xcite , which differs from the original one in  @xcite in the organization and presentation of the charging scheme , but in essence is the same .",
    "since our algorithm only differs from that of  @xcite in the implementation of height-0 regions , large parts of the analysis , and in particular parts that do not rely on the choice of parameters ( namely , the choice of region sizes @xmath172 , and attention span @xmath240 ) remain valid without any change .",
    "the most important of these is the payoff theorem ( the charging scheme invariant  ( * ? ? ?",
    "* lemma 3.15 ) ) , whose proof only depends on processing elements with ( locally ) minimum labels , and on the fact that processing a region @xmath56 only decreases labels of vertices that belong to @xmath56 . since our analysis relies on the details of the original analysis , we include some of the definitions and statement of lemmas from  @xcite .",
    "we define an _ entry vertex _ of a region @xmath56 ( denoted @xmath246 ) as follows .",
    "the only entry vertex of the region @xmath238 ( the region consisting of the entire graph @xmath0 ) is @xmath31 ( the source ) itself . for any other region @xmath56",
    ", @xmath21 is an entry vertex if @xmath21 is a boundary vertex of @xmath56 .",
    "we define the height of a vertex @xmath21 to be the largest integer @xmath171 such that @xmath21 is an entry vertex of a height-@xmath171 region .",
    "when the algorithm processes a region @xmath56 , it finds shorter paths to some of the vertices of @xmath56 and so reduces their labels .",
    "suppose one such vertex @xmath21 is a boundary vertex of @xmath56 .",
    "the result is that the shorter path to @xmath21 can lead to shorter paths to vertices in a neighboring region @xmath220 for which @xmath21 is an entry vertex . in order to preserve the property that the minimum key of @xmath247 reflects the labels of vertices of @xmath220",
    "the algorithm might need to update @xmath247 .",
    "updating the queues of neighboring regions is handled by the update procedure .",
    "the reduction of @xmath221 ( which can only occur as a result of a reduction in the label of an entry vertex @xmath21 of @xmath220 ) is a highly significant event for the analysis .",
    "we refer to such an event as a _ foreign intrusion of region @xmath220 via entry vertex @xmath21 .",
    "_    because of the recursive structure of process , each initial invocation process@xmath248 is the root of a tree of invocations of process and update , each with an associated region @xmath56 .",
    "parents , children , ancestors , and descendants of recursive invocations are defined in the usual way .    for an invocation @xmath61 of process on region @xmath56",
    ", we define @xmath249 and @xmath250 to be the values of @xmath251 just before the invocation starts and just after the invocation ends , respectively .    to facilitate the analysis we augment the pseudocode of process and update to keep track of the costs of the various operations .",
    "these additions to the pseudocode are shown in blue .",
    "note that these additions are purely an expository device for the purpose of analysis ; the additional blue code is not intended to be actually executed .",
    "in fact , line  [ line : stable ] of process can not be executed since it requires knowledge of the future !",
    "amounts of cost are passed around by update and process via return values and arguments .",
    "we think of these amounts as _",
    "debt obligations_. the running time of the algorithm is dominated by the time for priority - queue operations and for operations on the monge heaps .",
    "new debt is generated for every such call in lines  [ line : hyperdebt ] ,  [ line : arcdebt ] , and  [ line : proc ] of process , and in lines  [ line : upd1 ] and  [ line : upd2 ] of update .",
    "these debt obligations travel up and down the forest of invocations .",
    "an invocation passes down some of its debt to its children in hope they will pay this debt .",
    "a child , however , may pass unpaid debt ( inherited from the parent or generated by its descendants ) to its parent .",
    "debts are eventually charged by invocations of process to pairs @xmath252 where @xmath56 is a region and @xmath21 is an entry vertex of  @xmath56 .",
    "we say an invocation @xmath61 of process is _ stable _ if , for every invocation @xmath253 , the start key of @xmath62 is at least the start key of @xmath61 . if an invocation is stable , it pays off the debt by withdrawing the necessary amount from an account , the account associated with the pair @xmath254 where @xmath21 is the value of @xmath246 at the time of the invocation .",
    "this value is set by update whenever a foreign intrusion occurs ( line  [ line : entry ] ) .",
    "initially the entries in the table are undefined . however , for any region @xmath56 , the only way that @xmath251 can become finite is by an intrusion .",
    "we are therefore guaranteed that , at any time at which @xmath251 is finite , @xmath255 $ ] is an entry vertex of  @xmath56 .",
    "any invocation whose region is the whole graph is stable because there are no foreign intrusions of that region .",
    "therefore , such an invocation never tries to pass any debt to its nonexistent parent .",
    "we are therefore guaranteed that all costs incurred by the algorithm are eventually charged to accounts .",
    "the following theorem , called the payoff theorem , is the main element in the analysis .",
    "as we already noted , the theorem , as well as its original proofs in  @xcite , apply to our algorithm .",
    "[ thm : henzinger - payoff ] for each region @xmath56 and entry vertex @xmath21 of @xmath56 , the account @xmath252 is used to pay off a positive amount at most once .",
    "the remainder of the analysis consists of bounding the total debt charged from all accounts .",
    "the original analysis in  @xcite proved a bound on the debt that is linear in the number of arcs of the planar graph @xmath0 , which is also linear in the number of vertices of @xmath0 . in our case however , the number of arcs in the ddg is @xmath27 , but we need a bound that is linear in the number of vertices of the ddg , which is @xmath140 . to obtain a stronger bound we need to choose different parameters for the sizes of regions in the @xmath256division than those used in  @xcite .",
    "the analysis is rather technical so the details are deferred to appendix  [ appendix : analysis ] .",
    "the final bounds of our algorithm are summarized by the following theorem .",
    "[ thm : analysis ] a shortest path computation on the dense distance graph of an @xmath1division of an @xmath13-vertex graph can be done in @xmath29 time after @xmath26 preprocessing , or in @xmath257 time after @xmath29 preprocessing .",
    "in this section we give two applications of our fast shortest - path algorithm . in both applications ,",
    "we obtain a speedup over previous algorithms by decomposing a region of @xmath13 vertices using an @xmath1-division and computing distances among the boundary vertices of the region in @xmath29 time using our fast shortest - path algorithm .",
    "let @xmath0 be a directed planar graph , and let @xmath48 be a face of @xmath0 with @xmath10 vertices on its boundary .",
    "we consider the problem of computing the @xmath52 distances among all @xmath10 boundary vertices of @xmath48",
    ". there are two previously known solutions for this problem .",
    "first , it is possible to compute the shortest - path tree from each of the @xmath10 boundary vertices .",
    "this solution takes @xmath258 time using the shortest - path algorithm of henzinger et al .",
    "second , we can compute the distances by applying klein s multiple - source shortest - path algorithm ( mssp )  @xcite in @xmath259 time .",
    "we use our fast shortest - path algorithm and give an algorithm that computes the all - pair distances among the @xmath10 boundary vertices in @xmath41 time , when @xmath260 . for larger values of @xmath10 , note that the mssp solution is upper bounded by @xmath261 since @xmath262 .",
    "therefore , we get an upper bound of @xmath261 for computing the all - pair distances among the @xmath10 boundary vertices of a given face , for any value of @xmath10 .",
    "we consider the entire graph @xmath0 as a single region of an @xmath13-division of some other , larger graph ( the large graph itself is not relevant for our algorithm ) .",
    "we define the face @xmath48 to be a hole of the region @xmath0 , and the @xmath10 vertices of @xmath48 to be boundary vertices of the region @xmath0 .",
    "note that our definition of the boundary of @xmath0 is valid for a region in an @xmath13-division with a constant number of holes since we assume that @xmath263 .",
    "we further decompose the region @xmath0 using an @xmath1-division , for some value of @xmath1 to be defined later .",
    "this decomposition maintains the property that the @xmath10 vertices of @xmath48 are boundary vertices of the regions of the @xmath1-division that contain them .",
    "we compute this @xmath1-division in linear time using the algorithm of klein et al .",
    "then , we compute the ddg of the @xmath1-division in @xmath264 time , using the mssp algorithm of klein  @xcite .    the @xmath10 boundary vertices of @xmath48 are all vertices of the ddg . we apply our fast shortest - path algorithm from each of the @xmath10 vertices , and retrieve the required all - pair distances among them .",
    "applying our algorithm @xmath10 times requires @xmath265 time .",
    "the total running time of our algorithm is @xmath266 .",
    "we choose @xmath267 ; note that since @xmath260 we have that @xmath268 , and an @xmath1-division of @xmath0 is indeed defined .",
    "we get that the running time of our algorithm is @xmath41 , as required .      in this section",
    ", we use our fast shortest - path algorithm to show an @xmath8 maximum @xmath12-flow algorithm in directed planar graphs .",
    "the parameter @xmath9 , first introduced by itai and shiloach  @xcite , is defined to be the minimum number of faces that a curve @xmath269 from @xmath31 to @xmath32 passes through .",
    "note that the parameter @xmath9 depends on the specific embedding of the planar graph .    if @xmath270 then the graph is _",
    "@xmath12-planar_. in this case , the maximum flow algorithm of hassin  @xcite , with the improvement of henzinger et al .",
    "@xcite runs in @xmath27 time . for @xmath271 ,",
    "itai and shiloach  @xcite gave an @xmath272 time maximum flow algorithm when the value of the flow is known .",
    "johnson and venkatesan  @xcite obtained the same running time without knowing the flow value in advance . using the shortest - path algorithm of henzinger et al .",
    "@xcite , it is possible to implement the algorithm of johnson and venkatesan in @xmath273 time .",
    "borradaile and harutyunyan  @xcite gave another @xmath273 time maximum flow algorithm for planar graphs .",
    "for undirected planar graphs , kaplan and nussbaum  @xcite showed how to find the minimum @xmath274 cut in @xmath8 time .",
    "our @xmath8 time bound matches the fastest previously known maximum flow algorithms for @xmath275  @xcite and for @xmath276  @xcite , and is asymptotically faster than previous algorithms for other values of @xmath9 .",
    "we assume that @xmath277 , for larger values of @xmath9 the @xmath24 maximum flow algorithm of borradaile and klein  @xcite already runs in @xmath8 time .",
    "[ [ preliminaries . ] ] * preliminaries .",
    "* + + + + + + + + + + + + + + + +    a planar flow network consists of : ( 1 ) a directed planar graph @xmath0 ; ( 2 ) two vertices @xmath31 and @xmath32 of @xmath0 designated as a _ source _ and a _ sink _ , respectively ; and ( 3 ) a _ capacity _ function @xmath278 defined over the arcs of @xmath0 .",
    "we assume that for every arc @xmath279 , the arc @xmath280 is also in the graph ( if this is not the case , then we add @xmath280 with capacity @xmath281 ) , such that the two arcs are embedded in the plane as a single edge .",
    "function @xmath282 assigns a flow value to the arcs of @xmath0 such that : ( 1 ) for every arc @xmath279 , @xmath283 ; ( 2 ) for every arc @xmath279 , @xmath284 ; and ( 3 ) for every vertex @xmath285 , the amount of flow that enters @xmath21 equals to the amount of flow that leaves @xmath21 .",
    "maximum flow _ is a flow in which the total amount of flow that enters the sink is maximal . in a _",
    "preflow _ some of the vertices of @xmath0 ( in addition to @xmath32 ) may have more incoming flow than outgoing flow ( an _ excess _ ) .",
    "maximum preflow _ is a preflow in which the total amount of flow that enters the sink is maximal .",
    "finally , we _ add _ a flow @xmath286 to a flow @xmath282 by setting @xmath287 for every arc @xmath185 .",
    "the _ dual graph _",
    "@xmath288 of @xmath0 is is a planar graph such that every face @xmath48 of @xmath0 has a vertex @xmath289 in @xmath288 , and every arc @xmath185 of @xmath0 with a face @xmath290 to its left and a face @xmath291 to its right has an arc @xmath292 in @xmath288 .",
    "we now describe our maximum flow algorithm .",
    "we first describe an @xmath293-time algorithm and then show how to improve it to @xmath8 using ideas of borradaile et al .  @xcite together with our fast shortest - path algorithm .",
    "[ [ an - onp - algorithm . ] ] * an @xmath293 algorithm . *",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    without loss of generality , we may assume that the curve @xmath269 from @xmath31 to @xmath32 crosses @xmath0 only at vertices , say @xmath294 , where @xmath295 and @xmath296 . therefore , we can embed in the graph a path @xmath297 between @xmath31 and @xmath32 consisting of @xmath9 edges @xmath298 for @xmath299 ( note that some of the edges of @xmath297 may be parallel to original edges of the graph ) .",
    "we set the capacities of the arcs of @xmath297 to @xmath281 , so the value of the maximum flow is not affected by adding @xmath297 to the graph .",
    "intuitively , our algorithm iterates over the vertices of @xmath297 , from @xmath295 until the last vertex before @xmath32 , @xmath300 . at each iteration",
    ", the algorithm pushes forward the excess flow of the current vertex of @xmath297 to the vertices of @xmath297 that follow it , where the excess of @xmath31 is @xmath151 , and the excess of any other vertex @xmath301 of @xmath297 is the excess flow remaining at @xmath301 following the previous iterations .",
    "this is a special case of an algorithm of borradaile et al .  for balancing flow excesses and flow deficits of vertices along a path  @xcite .",
    "we obtain a speedup over the algorithm of borradaile et al .  by using our fast shortest - path algorithm , in a way similar to the one in the previous section , for computing distances among boundary vertices of a face .",
    "our algorithm works as follows . for every arc @xmath302 , for @xmath299",
    ", we set @xmath303 .",
    "we initialize a flow @xmath282 by setting @xmath304 for every arc of the graph .",
    "then , at iteration @xmath305 , we send a flow from @xmath306 to @xmath301 in the residual graph of @xmath282 .",
    "the flow we send is as large as possible , but not larger than the excess of @xmath306 . for @xmath307 ,",
    "the excess of @xmath295 is @xmath151 . for @xmath308 ,",
    "the excess of @xmath306 is the value of the flow that we sent in the previous iteration from @xmath309 to @xmath306 .",
    "in fact , at iteration @xmath171 we actually send as much flow as possible from @xmath306 to _ all _ vertices of @xmath297 that follow it . this is because each such vertex @xmath310 is connected to @xmath301 with a path of infinite capacity so any flow that we can send to @xmath310 is routed to @xmath301 .",
    "note that each iteration is actually a flow computation in an @xmath12-planar graph , so we can implement in @xmath27 time using hassin s algorithm  @xcite .",
    "after we compute the flow from @xmath306 to @xmath301 , we add it to @xmath282 and continue to the next iteration .    following the last iteration , @xmath282 is a maximum preflow from @xmath31 to @xmath32 .",
    "note that only vertices of @xmath297 may have excess .",
    "we discard the arcs of @xmath297 from the graph .",
    "then , we convert the maximum preflow @xmath282 to a maximum flow using the following procedure of johnson and venkatesan .",
    "first , we make the flow acyclic using the algorithm of kaplan and nussbaum  @xcite in @xmath27 time .",
    "then , we find a topological ordering of the vertices such that if an arc @xmath19 carries a positive amount of flow , then @xmath20 precedes @xmath21 in the ordering .",
    "finally , in @xmath27 time , we return the excess from vertices with an excess flow to @xmath31 backwards along this topological ordering .",
    "since each iteration takes @xmath27 time , the total running time of the algorithm is @xmath293 .",
    "the bottleneck of the algorithm is applying hassin s maximum flow algorithm for @xmath12-planar graphs @xmath9 times .",
    "we next use a technique of borradaile et al .  to execute hassin s algorithm implicitly .",
    "[ [ an - onlog - p - algorithm . ] ] * an @xmath311 algorithm . * + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    we start by reviewing hassin s maximum flow algorithm for @xmath12-planar graphs . the input for the algorithm is a flow network @xmath0 with a source @xmath31 and a sink @xmath32 , such that @xmath31 and @xmath32 are on the boundary of a common face .",
    "we embed an arc @xmath312 with infinite capacity in @xmath0 .",
    "let @xmath48 be the face of @xmath0 on the left - hand side of @xmath312 .",
    "we compute shortest path distances in @xmath288 from @xmath289 , where the length of a dual arc equals the capacity of the corresponding primal arc .",
    "let @xmath313 denote the distance in @xmath288 from @xmath289 to @xmath314 .",
    "the function @xmath315 , which we call a _ potential function _ , defines a _ circulation _",
    "@xmath316 in @xmath0 as follows . for an arc @xmath185 with a face @xmath317 to its left and a face @xmath318 to its right",
    ", the flow along @xmath185 is @xmath319 .",
    "hassin showed that after we drop the extra arc @xmath312 , we remain with a maximum flow @xmath316 from @xmath31 to @xmath32 in the original graph .",
    "following borradaile et al .",
    "we apply hassin s algorithm with two modifications .",
    "first , we compute a maximum flow with a prescribed bound @xmath124 on its value .",
    "we obtain such a flow by setting the capacity of @xmath312 to @xmath124 rather than to @xmath151  @xcite .",
    "second , we do not wish to add and remove the arc @xmath312 , since we do not want to modify the embedding of the graph . in our case ,",
    "the arc @xmath312 already exists in the graph , this is the arc @xmath302 with capacity @xmath281 . instead of adding a new arc , with capacity @xmath124 , from the sink to the source , we set the capacity of @xmath302 to @xmath124 . instead of removing the arc following the flow computation , we set the _ residual capacity _ of @xmath302 and @xmath298 back to @xmath281 , by setting their capacities to @xmath320 and @xmath321 , respectively .",
    "we do not maintain a flow @xmath282 throughout our algorithm , we rather use the potential function @xmath315 to represent the flow @xmath316 .",
    "this gives us the implementation of our maximum flow algorithm in algorithm  [ alg : flow ] below .",
    "embed the path @xmath322 , where @xmath295 and @xmath296 , with @xmath303 and @xmath323 for every @xmath299 @xmath324 for every face @xmath325 of @xmath0 @xmath326 @xmath327 @xmath328 the distance from @xmath329 to @xmath314 in @xmath288 , for every face @xmath325 , where @xmath330 is the face to the left of @xmath302 , and for every arc @xmath185 the length of @xmath331 is the residual capacity of @xmath185 with respect to @xmath316 [ line : flow - sp ] @xmath332 , for every face @xmath325 [ line : accumulate ] @xmath333 ; @xmath334 [ line : reweight ] @xmath335 discard the path @xmath297 from the graph [ line : after - for ] convert the maximum preflow @xmath316 into a maximum flow @xmath282 @xmath282    if we implement the shortest path computation at line  [ line : flow - sp ] using the algorithm of henzinger et al .",
    ", then the running time of our algorithm is @xmath293 .",
    "borradaile et al",
    ".  noticed that we do not have to compute and maintain the value of the potential function @xmath315 for all faces of @xmath0 prior to line  [ line : after - for ] . until this point",
    ", it suffices to compute the value of the potential function only for the faces incident to the arcs of @xmath297 .",
    "this way , borradaile et al .  computed the distances in @xmath288 using fr - dijkstra on a ddg that contains the dual vertices of all of these faces , and executed line  [ line : flow - sp ] faster .",
    "we follow this approach , and compute the distances at line  [ line : flow - sp ] in a way similar to the algorithm of the previous section . only after the last iteration of the loop that computes @xmath315 ,",
    "we compute explicitly the value of @xmath315 for all faces of the graph .",
    "we now give the details of this improvement .",
    "consider the graph @xmath288 , the dual graph of @xmath0 ( including the arcs of @xmath297 ) .",
    "let @xmath336 be the set of vertices of @xmath288 that correspond to faces of @xmath0 incident to arcs of @xmath297 .",
    "the set @xmath336 is the set of vertices for which we compute distances at line  [ line : flow - sp ] .",
    "we define the region @xmath337 to be the region of @xmath288 that contains the dual arcs of the original arcs of @xmath0 , excluding the arcs of @xmath297 .",
    "the boundary vertices of @xmath337 are exactly the vertices of @xmath336 , and they all lie on a single face of @xmath337 ( which may have other vertices on its boundary ) .",
    "let @xmath338 be the region of @xmath288 that contains the arcs dual to arcs of @xmath297 , these are the arcs of @xmath288 that are not in @xmath337",
    ". see figure  [ fig : flownetwork ] .",
    "( _ solid _ edges ) and the dual network @xmath288 ( _ dashed _ edges ) .",
    "the path @xmath297 from @xmath31 to @xmath32 is _ bold _ , the region @xmath338 is _ dashed and bold_. the set of dual vertices @xmath336 ( _ boxes _ ) separates between @xmath338 and @xmath337 ( the dual edges that are not in @xmath338 ) , they are all on the boundary of a single face of @xmath337 . to make the illustration simpler , some of the arcs incident to the dual vertex of the infinite face are omitted . ]",
    "we decompose @xmath337 using an @xmath1-division , similar to the way we did in the previous section , such that the vertices of @xmath336 remain boundary vertices of every region containing them .",
    "we choose @xmath339 for reasons that will become clear later .",
    "note that @xmath2 , so an @xmath1-division is well defined .",
    "the region @xmath338 has @xmath180 vertices and @xmath16 boundary vertices ( actually it has much less vertices than @xmath1 and much less boundary vertices than @xmath340 ) . therefore ,",
    "the regions of the @xmath1-division of @xmath337 together with the region @xmath338 are an @xmath1-division of @xmath288 , in which all vertices of @xmath336 are boundary vertices .",
    "we compute a ddg for this @xmath1-division in @xmath264 time .",
    "initially , the lengths of the arcs of @xmath337 are defined by the capacities of the corresponding primal arcs . at each invocation of line  [ line :",
    "accumulate ] , we update the potential function @xmath315 , and thereby also the residual capacities of the arcs of @xmath0 .",
    "since the length of a dual arc equals to the residual capacity of the corresponding primal arc , we update the lengths of the arcs of @xmath56 as well . as borradaile et al .",
    "noticed , we can use @xmath315 also as a _ price function _ that represents the change in the lengths of the arcs of @xmath337 and defines _ reduced lengths_. that is , if the distance from @xmath341 to @xmath342 with respect to the original capacity of the graph is @xmath72 , then the distance from @xmath343 to @xmath344 with respect to the residual capacities of @xmath316 is @xmath345 .",
    "we conclude that we compute the ddgs of the regions that compose @xmath337 only once and use @xmath315 as a price function for these ddgs .    at line  [ line : reweight ] of the algorithm",
    ", we update the lengths of @xmath302 and @xmath298 .",
    "this update causes a change in the ddg of @xmath338 . since @xmath338 contains only @xmath9 vertices , we can recompute the ddg in @xmath346 time .",
    "we implement line  [ line : flow - sp ] by applying our fast shortest - path algorithm to the ddg of @xmath288 .",
    "we use the variant of our algorithm that allows a price function and supports reduced lengths ( i.e , the variant with @xmath347 whose preprocessing time is @xmath348 running time is @xmath349 , see theorem  [ thm : analysis ] and section  [ section : mh - spec ] ) . thus , the total time for running the loop is @xmath350 .",
    "since we set @xmath339 , the running time of the loop is @xmath8 .",
    "it remains to show how to obtain the value of the potential function @xmath315 for all faces of @xmath0 prior to line  [ line : after - for ] .",
    "recall that , for a face @xmath325 of @xmath0 , @xmath313 is the distance in @xmath288 from the dual vertex of the face @xmath351 to the left of @xmath352 to @xmath314 , where the length of each dual arc is defined by the capacity of the corresponding primal arc .",
    "therefore , we can compute @xmath315 using a shortest - path algorithm .",
    "we do not apply a shortest - path algorithm for the entire graph @xmath288 , since the arcs dual to arcs of @xmath297 may have negative lengths ( which set the residual capacities of the primal arcs with respect to @xmath316 to @xmath281 ) .",
    "instead , we initialize the labels of the vertices of @xmath336 according to the values of @xmath315 that we have already computed , and apply the shortest - path algorithm of henzinger et al .  to @xmath337 , which contains only non - negative length arcs .",
    "this is analogous to the way borradaile et al .",
    "handle the same issue .",
    "we conclude that the total running time of our algorithm is @xmath8 as required .",
    "the correctness of our algorithm follows from the correctness of the algorithm of borradaile et al .",
    ", since our algorithm is a special case of it .",
    "the differences between our algorithm and the one of borradaile et al .",
    "are that we decompose the region @xmath337 using an @xmath1-division and that we apply our fast shortest - path algorithm .",
    "we thank philip klein for discussions and for allowing us to use large parts of his description  @xcite of the algorithm of henzinger et al .  @xcite as the basis for our description in section  [ sec : hkrs - fr ] .",
    "first , as we show in  @xcite : the blank entries in a partial monge matrix @xmath57 can be implicitly replaced so that @xmath57 becomes fully monge and each entry @xmath353 can be returned in @xmath136 time .",
    "we can therefore assume that @xmath57 is fully monge . to make the presentation clear ( and compatible with  @xcite ) , we prove the lemma on the transpose of @xmath57 ( i.e. , we activate and deactivate rows and a query is a column and a range of rows ) .",
    "furthermore , although the lemma states that @xmath57 is an @xmath354 matrix , we consider @xmath57 an an @xmath355 matrix for some @xmath356 .",
    "denote @xmath357 if the minimum element of @xmath57 in column @xmath358 lies in row @xmath171 . the _ upper envelope _ @xmath359 of all the rows of the monge matrix @xmath57 consists of the @xmath13 values",
    "since @xmath57 is monge we have that @xmath361 and so @xmath359 can be implicitly represented in @xmath362 space by keeping only the @xmath363s of @xmath362 columns called _ breakpoints_. breakpoints are the columns  @xmath358 where @xmath364 .",
    "the minimum element @xmath365 of an entire column @xmath315 can then be retrieved in @xmath366 time by a binary search for the first breakpoint column @xmath358 after @xmath315 , and setting @xmath367 .",
    "the tree @xmath368 presented in  @xcite is a full binary tree @xmath368 whose leaves are the rows of @xmath57 .",
    "a node @xmath20 whose subtree contains @xmath10 leaves ( i.e. , @xmath10 rows ) stores the @xmath369 breakpoints of the @xmath370 matrix @xmath371 defined by these @xmath10 rows and all @xmath13 columns of @xmath57 ( each breakpoint also stores its appropriate row index ) .",
    "a leaf represents a single row and requires no computation . for an internal node @xmath20 ,",
    "we compute its list of breakpoints by merging the breakpoint lists of its left child @xmath372 and its right child @xmath373 , where @xmath372 is the child whose rows have lower indices .    by the monge property ,",
    "@xmath20 s list of breakpoints starts with a prefix of @xmath372 s breakpoints and ends with a suffix of @xmath373 s breakpoints . between these",
    "there is possibly one new breakpoint @xmath358 ( the _ transition _ breakpoint ) .",
    "the prefix and suffix parts can be found easily in @xmath369 time by linearly comparing the relative order of the upper envelopes of @xmath374 and @xmath375 .",
    "this allows us to find an interval of columns containing the transition column @xmath358 . over this interval ,",
    "the transition row is in one of two rows ( a row in @xmath374 and a row in @xmath375 ) , and so @xmath358 can be found in @xmath39 time via binary search .",
    "summing @xmath376 over all nodes of @xmath368 gives @xmath43 time .",
    "the total size of @xmath368 is @xmath377 .",
    "a query to @xmath368 is performed as follows .",
    "the minimum entry in a query column @xmath315 and a contiguous range of rows @xmath56 is found by identifying @xmath366 _ canonical nodes _ of @xmath368 .",
    "a node @xmath20 is canonical if @xmath20 s set of rows is contained in @xmath56 but the set of rows of @xmath20 s parent is not . for each such canonical node @xmath20 , the minimum element in column @xmath315 amongst all the rows of @xmath20",
    "is found in @xmath366 time via binary search on @xmath20 s list of breakpoints .",
    "the output is the smallest of these .",
    "the total query time is thus @xmath378 .",
    "[ [ a - dynamic - data - structure . ] ] * a dynamic data structure . * + + + + + + + + + + + + + + + + + + + + + + + + + + +    the above @xmath368 data structure was used in  @xcite in a static version and so the query time was improved from @xmath378 to @xmath366 using fractional cascading  @xcite . in order to allow activating / deactivating of a row we slightly modify this data structure and do not use fractional cascading .",
    "every node @xmath20 of @xmath368 , instead of storing all its breakpoints , will now only store its single transition breakpoint . this way , in order to find the minimum element in column @xmath315 of @xmath371",
    ", we need to find the predecessor breakpoint of @xmath315 in @xmath371 .",
    "this is done in @xmath366 time by following a path in @xmath20 s subtree starting from @xmath20 and ending in a leaf .",
    "given a query column and a contiguous range of rows we again identify @xmath366 canonical nodes .",
    "each of them now requires following a path of length @xmath366 for a total of @xmath378 time .    in order to deactivate an entire row @xmath1",
    ", we mark this row s leaf in @xmath368 as inactive and then fix the breakpoints bottom - up on the entire path from @xmath1 to the root of @xmath368 . for each node @xmath20 on this path",
    ", we assume that the transition breakpoints for all descendants of @xmath20 are correct and we find the new transition breakpoint @xmath358 of @xmath20 as follows : if @xmath20 has left child @xmath372 and right child @xmath373 then @xmath358 should be placed between a breakpoint @xmath379 of @xmath374 and a breakpoint @xmath380 of @xmath375 . here ,",
    "@xmath374 and @xmath375 correspond to the _ active _ rows in @xmath372 s and @xmath373 s subtrees .",
    "if there are no active rows in @xmath372 s or @xmath373 s subtrees then finding @xmath358 is trivial .",
    "if both have active rows then we now show how to find @xmath379 , finding @xmath380 is done similarly .    to find @xmath379",
    ", we follow a path from @xmath372 downwards until we reach a leaf or a node whose subtree contains no active rows as follows .",
    "recall that the node @xmath372 stores a single breakpoint ( a row index @xmath381 and a column index @xmath382 ) .",
    "since @xmath383 is the minimum entry in column @xmath382 of @xmath374 we want to compare it with @xmath384 = the minimum entry in column @xmath382 of @xmath375 . if @xmath385<m[i'',j']$ ] then we know that @xmath386 and",
    "so we can proceed from @xmath372 to @xmath372 s right child . similarly , if @xmath385\\ge m[i'',j']$ ] then @xmath387 and we proceed from @xmath372 to @xmath372 s left child .",
    "the problem is we do not know @xmath388 . to find it , we need to find the minimum entry in column @xmath382 of @xmath375 .",
    "we have already seen how to do this in @xmath366 time by following a downward path from @xmath373 .",
    "we therefore get that finding @xmath379 ( and similarly @xmath380 ) can be done in @xmath378 time . after finding @xmath379 and @xmath380",
    "we find where @xmath358 is between them in @xmath39 time via binary search .",
    "the overall time for deactivating an entire row @xmath1 is thus @xmath389 .    in order to activate an entire row @xmath1 we mark its leaf in @xmath368 as active and",
    "fix the breakpoints from @xmath1 upwards using a similar process as above .",
    "this completes the proof of the dynamic data structure .",
    "[ [ a - decremental - data - structure . ] ] * a decremental data structure . * + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    we now proceed to proving the decremental data structure in which inactive rows never become active .",
    "we take advantage of this fact by maintaining , for each node @xmath20 of @xmath368 , not only its transition breakpoint but all the active breakpoints of @xmath371 .",
    "since breakpoints are integers bounded by @xmath13 , we can maintain @xmath20 s @xmath10 active breakpoints in an @xmath369-space @xmath390 amortized query - time predecessor data structure such as y - fast - tries  @xcite .",
    "given a query column and a contiguous range of rows , we identify @xmath366 canonical nodes in @xmath368 and then only need to do a predecessor search on each of them in total @xmath391 time .    in order to deactivate a row @xmath1",
    ", we mark @xmath1 s leaf in @xmath368 as inactive and fix the predecessor data structures of @xmath1 s ancestors . for each node @xmath20 on the @xmath1-to - root path",
    "we may need to change @xmath20 s transition breakpoint as well as insert ( possibly many ) new breakpoints into @xmath20 s predecessor data structure @xmath392 .",
    "we show how to do this assuming @xmath20 s left child @xmath372 is the ancestor of @xmath1 and we ve already fixed its predecessor data structure @xmath393 .",
    "the case where @xmath20 s right child @xmath373 is the ancestor of @xmath1 is handled symmetrically .",
    "note that , if @xmath1 is a descendent of @xmath372 , then the transition breakpoint and the predecessor data structure @xmath394 of @xmath373 undergo no changes .",
    "the first thing we do is we check if @xmath20 s old transition breakpoint has row index @xmath1 . if not then we do nt need to change @xmath20 s transition breakpoint .",
    "if it is , then we delete @xmath20 s old transition breakpoint from @xmath392 and we find the new transition breakpoint @xmath358 of @xmath20 via binary search .",
    "the binary search takes @xmath153 time since each comparison requires to query @xmath393 and @xmath394 in @xmath390 time . after finding the new transition breakpoint @xmath358",
    "we insert it into @xmath392 .",
    "finally , we need to insert to @xmath392 ( possibly many ) new breakpoints , each in @xmath390 time .",
    "these breakpoints are precisely all the breakpoints in @xmath393 that are to the left of @xmath358 and to the right of predecessor(@xmath358 ) in @xmath392 as well as all the breakpoints in @xmath394 that are to the right of @xmath358 and to the left of successor(@xmath358 ) in @xmath392 .",
    "we claim that the above procedure requires @xmath152 amortized time .",
    "first note that finding the new transition breakpoints of all @xmath366 nodes on the @xmath1-to - root path takes @xmath395 time .",
    "inserting these new breakpoints into the predecessor data structures and deleting the old one takes @xmath391 time .",
    "next , we need to bound the overall number of breakpoints that are ever inserted into predecessor data structures . in the beginning , all rows are active and the total number of breakpoints in all predecessor data structures is @xmath396 .",
    "then , whenever we deactivate a row , each node @xmath20 on the leaf - to - root path in @xmath368 may insert a new transition breakpoint @xmath358 into @xmath392 .",
    "this breakpoint @xmath358 might consequently be inserted into every @xmath397 where @xmath21 is an ancestor of @xmath20 .",
    "let @xmath398 denote the depth of the highest ancestor of @xmath20 to which we will consequently insert the breakpoint @xmath358 .",
    "note that we might also insert to @xmath392 other breakpoints but that only means that their @xmath399 value would decrease .",
    "since every @xmath399 value is at most @xmath366 and since top values only ever decrease this means that over all the @xmath400 row deactivations only @xmath401 breakpoints are ever inserted .",
    "this means that all insertions take @xmath402 time .",
    "in this section we describe two implementations of the monge heaps specified in section  [ section : mh - spec ] , thus proving lemma  [ lem : hkrs - rmq ] .",
    "[ [ implementation-1 ] ] implementation 1 + + + + + + + + + + + + + + + +    this implementation in the statement of the lemma is similar to that of section  [ warmup ] and differs only in the use of rmq . in section  [ warmup ]",
    "we used one rmq data structure for all mhs of a region @xmath56 .",
    "here , each mh requires an rmq data structure of its own .",
    "this means that for @xmath403 , a region @xmath56 requires @xmath404 rmq data structures for @xmath405 matrices .",
    "furthermore , in section  [ warmup ] we only deactivated vertices and so we could use the decremental rmq of lemma  [ lemma : rmq ] . here , an inactive vertex can become active again and so we use the ( slower ) dynamic rmq of lemma  [ lemma : rmq ] .    to implement fr - getminchild@xmath209 we simply query the rmq data structure of @xmath181 in @xmath162 time . to implement fr - extract@xmath211",
    "we first deactivate @xmath182 in the rmq of @xmath181 in @xmath213 time ( notice that the deactivation is done only in @xmath181 as opposed to section  [ warmup ] where a deactivation applies to all mhs that contain the vertex ) .",
    "then , we find @xmath190 by querying the rmq of @xmath181 in @xmath162 time . to implement fr - relax@xmath209 we first perform the same procedure as in section  [ warmup ] that creates one new triplet and destroys possibly many triplets .",
    "this takes amortized @xmath63 time since destroying a triplet is paid for by that triplet s creation ( note that as opposed to section  [ warmup ] here a triplet of vertex @xmath21 can be destroyed and then created again multiple times ) .",
    "then , activating all the new children of @xmath21 that were inactive takes amortized @xmath136 time since we can charge the activation of a vertex to the time it was deactivated ( in a prior call to fr - extract ) .",
    "constructing the dynamic rmq of lemma  [ lemma : rmq ] for an @xmath406 matrix takes @xmath407 time .",
    "therefore all rmq data structures of a region @xmath56 are constructed in @xmath408 time , and so over all regions we need @xmath164 time .",
    "[ [ implementation-2 ] ] implementation 2 + + + + + + + + + + + + + + + +    the second implementation in the statement of lemma  [ lem : hkrs - rmq ] is based on the following simple rmq .",
    "given an @xmath148 monge matrix @xmath57 , one can construct in @xmath409 time and @xmath410 space a data structure that supports the following operations in @xmath39 time : ( 1 ) mark an entry as inactive ( 2 ) mark an entry as active ( 3 ) report the minimum active entry in a query row and a contiguous range of columns ( or @xmath151 if no such entry exists ) .",
    "the data structure is a very nave one .",
    "we simply store , for each row of @xmath57 , a separate balanced binary search tree keyed by column number where each node stores the minimum value in its subtree .",
    "deactivating ( resp . activating ) an entry",
    "is done by deletion ( resp .",
    "insertion ) into the tree , and a query is done by taking the minimum value of @xmath39 canonical nodes identified by the query s endpoints .",
    "notice that the above nave rmq data structure activates and deactivates single entries in @xmath57 while the specification of fr - extract seems to require deactivating and not entire columns of @xmath57 ( the specification is to make @xmath182 inactive in the entire mh @xmath181 ) .",
    "however , deactivating a single element suffices .",
    "this is because each vertex @xmath411 appears in exactly one triplet at any given time .",
    "therefore , whether it is active or inactive is only important in the rmq of the vertex @xmath412 whose triplet contains @xmath182 .",
    "whenever an inactive @xmath182 changes parents , we make @xmath182 active by reintroducing the corresponding element into the rmq if it was previously deleted , and charge the activation to the time @xmath182 was deactivated in a prior call to fr - extract ) .",
    "constructing the nave data structure on all mhs of a region @xmath56 takes @xmath413 time , and so over all regions we need @xmath214 time . each operation on the rmq now takes only @xmath63 time .",
    "this means that fr - relax , fr - getminchild , and fr - extract can all be done in @xmath63 amortized time .",
    "in this section we give the complete running - time analysis of our algorithm by bounding the total debt withdrawn from all accounts during the execution of the algorithm .",
    "the total debt depends on the parameters @xmath414 of the recursive @xmath256-division and on the parameters @xmath415 that govern the number of iterations per invocation of process .",
    "recall that @xmath167 and @xmath168 for @xmath169 .",
    "define @xmath416 and @xmath417 for @xmath418 .",
    "the proof is by reverse induction on @xmath171 . in the base case ,",
    "each top - height invocation clearly inherits no debt at all .",
    "suppose the lemma holds for @xmath171 , and consider a height-@xmath171 invocation on a region @xmath56 . by the inductive hypothesis",
    ", this invocation inherits at most @xmath420 debt .",
    "an @xmath421 fraction of this debt is passed down to each child .",
    "in addition , each child @xmath220 inherits a debt of @xmath422 to cover the cost of the @xmath423 and @xmath241 operations on @xmath217 required for invoking the call to process on @xmath220 .",
    "overall we get that each child inherits @xmath424 which by the choice of @xmath240 is @xmath425 .",
    "we next wish to bound the number of descendant invocations incurred by an invocation of process .",
    "define @xmath426 for @xmath427 .",
    "define @xmath428 to be 1 for @xmath429 , and 0 for @xmath58 . by definition ,",
    "@xmath430      note that only height-0 invocations incur debt .",
    "let @xmath431 be a constant such that a monge heap operation takes @xmath432 time .",
    "the debt incurred by the algorithm by a step of process is called the _ process debt_.      by the payoff theorem , the @xmath433 account is used at most once .",
    "let @xmath61 be the invocation of process that withdraws the payoff from that account .",
    "each dollar of process debt paid off by @xmath61 was sent back to @xmath61 from some descendant invocation who inherited or incurred that dollar of debt .",
    "since only height-0 invocations incur debt , to account for the total amount of process debt paid off by @xmath61 we consider each of its descendant invocations . by lemma  [",
    "lem : beta ] , @xmath61 has @xmath428 descendants of height  @xmath358 , each of which inherited a debt of at most @xmath435 dollars , by lemma  [ lem : debt - inherited ] .",
    "in addition , each of the @xmath436 descendant height-0 invocations incurs a debt of at most @xmath432 .",
    "[ lem : number - of - region - vertex - pairs ] let @xmath13 be the number of edges of the input graph",
    ". for any nonnegative integer @xmath171 , there are at most @xmath437 pairs @xmath433 where @xmath56 is a height-@xmath171 region and @xmath124 is an entry vertex of @xmath56 .        the cost incurred by the algorithm by a step of update",
    "is called _",
    "update debt_. the event ( in lines  [ line : minchild - relax ] ,  [ line : v - relax ] , and  [ line : minchild_a ] of process ) of reducing a vertex @xmath124 s label @xmath439 initiates a chain of calls to update in lines  [ line : minchild - update ] , [ line : update ] , and  [ line : minchild_b ] , respectively , for each outgoing arc @xmath440 .",
    "we say the debt incurred is _ on behalf of @xmath124_.              for the first case , the call to update is in line  [ line : update ] . in this case",
    ", @xmath56 corresponds to a single arc @xmath201 .",
    "consider the chain of calls to update , and let @xmath444 be the corresponding regions .",
    "@xmath445 corresponds to a single hyperarc @xmath185 whose tail is @xmath21 .",
    "note that @xmath446 .",
    "the cost of each call is @xmath136 since we use fibonacci heaps .",
    "since @xmath447 contains @xmath185 but ( by lemma  [ lem : update - debt ] ) does not contain @xmath201 , we get that @xmath21 is a boundary vertex of @xmath447 , so @xmath448 .    for the second case , the call is update@xmath449 , either in line  [ line : minchild - update ] , or in line  [ line : minchild_b ] .",
    "in the former case @xmath56 corresponds to a single hyperarc incident to @xmath190 . in the latter case",
    "@xmath56 corresponds to a single arc @xmath201 . in both cases @xmath450 and @xmath451 is the same height-1 region @xmath452 , and the key of @xmath220 is at least the key of @xmath56 .",
    "since at the time the call to update is made @xmath453 , the call update@xmath449 does not decrease @xmath454 , so this chain of calls to update consists of exactly two calls . since we use fibonacci heaps , each call costs @xmath136 .",
    "[ lem : update - debt - bound ] let @xmath455 be nonnegative integers , and let @xmath56 be a region of height @xmath171 .",
    "the total amount of update debt incurred on behalf of vertices of height at most @xmath358 and paid off from accounts @xmath456 is at most @xmath457    the number of entry vertices @xmath124 of @xmath56 is at most @xmath458 . for each",
    ", the payoff theorem ensures that all the debt paid off from account @xmath433 comes from descendants of a single invocation @xmath61 of process .",
    "the number of height-0 descendants of @xmath61 is @xmath436 .",
    "consider such a height-0 descendant @xmath443 whose region is @xmath445 .",
    "if @xmath445 consists of a single hyperarc , then the height of the vertex @xmath190 on whose behalf the call to update is made in line  [ line : minchild - update ] is 0 ( see observation  [ obs : height0 ] ) . by lemma  [ cor :",
    "cost - per - update - chain ] the cost of this chain of calls is at most @xmath459 .",
    "if @xmath445 consists of a single arc @xmath201 , then @xmath21 has height at least 1 .",
    "suppose the height of @xmath21 is at most @xmath358 .",
    "in each of the three height-1 regions to which @xmath21 belongs , it participates in at most @xmath460 monge heaps .",
    "hence , in each of these regions there are at most @xmath460 hyperarcs whose tail is @xmath21 for which a call to update is made in line  [ line : update ] . since all of these calls are made with the same key , exactly one of them may cause a chain of update whose length is at most @xmath358 . by lemma  [ cor :",
    "cost - per - update - chain ] the cost of such a chain is at most @xmath461 .",
    "the other calls only cause a chain of updates whose length is 2 .",
    "hence , all calls made in line  [ line : update ] on behalf of @xmath21 cost at most @xmath462 .",
    "there is an additional call to update in line  [ line : minchild_b ] .",
    "as before , since this call is made on behalf of a height-0 vertex , its cost is at most 2 .",
    "we have therefore established that the total amount of update debt incurred on behalf of vertices of height at most @xmath358 and paid off from accounts @xmath463 is at most @xmath464 , which is at most @xmath465 .      to each unit of update debt , we associate two integers : @xmath171 is the height of the region @xmath56 such that the debt is paid off from an account @xmath433 , and @xmath358 is the height of the vertex @xmath21 on whose behalf the debt was incurred . if @xmath467 , we refer to the debt as _ type  1 _ debt , and if @xmath468 , we refer to it as _ type  2 _ debt .",
    "first we bound the type-1 debt .",
    "for each integer  @xmath418 , there are at most @xmath469 regions @xmath56 of height  @xmath171 . by lemma  [ lem :",
    "update - debt - bound ] , these contribute to the total type-1 debt @xmath470 .    by lemma  [ lem : num-0-regions ] , there number of height  0 regions is @xmath196 , each with a single entry vertex .",
    "an invocation on such a region makes at most one call to update that is on behalf of a height-0 vertex . by lemma  [ cor :",
    "cost - per - update - chain ] the cost of such a call is at most 2 .",
    "therefore , the contribution of height-0 regions to type-1 debt is @xmath471 .",
    "we get that the total type-1 debt is at most @xmath472    now we bound the type-2 debt ( i.e. , @xmath473 ) . for each integer",
    "@xmath358 ( since @xmath473 , @xmath358 must be at least 1 ) , the number of regions of height  @xmath358 is at most @xmath474 and each has at most @xmath475 entry vertices , so the total number of vertices of height  @xmath358 is at most @xmath476 .",
    "consider each such vertex @xmath21 .",
    "we handle separately the cases @xmath418 and @xmath477 .    * for any @xmath418 , every vertex ( and in particular @xmath21 ) belongs to at most 3 height-@xmath171 regions .",
    "hence , by lemma  [ lem : update - debt - bound ] , the total type-2 debt for @xmath478 is @xmath479 * we next consider the case @xmath477 .",
    "for @xmath480 , there are @xmath481 vertices of height @xmath358 .",
    "each such vertex @xmath21 belongs to at most 3 height-1 regions , and hence to at most @xmath482 height-0 regions .",
    "hence , by lemma  [ lem : update - debt - bound ] , the total type-2 debt for @xmath477 is @xmath483      we are now prepared to bound the total running time of our algorithm to @xmath484 .",
    "the following two lemmas bound the total process debt to @xmath485 and the total update debt to @xmath486 . using the naive rmq data structure with @xmath487",
    "we obtain the claimed running time .                    *",
    "the first term is clearly @xmath500 .",
    "* by  , the second term is @xmath501 recall that @xmath489 , so @xmath490 . since the @xmath172 s increase doubly exponentially , we have that @xmath502 and so the term is bounded by @xmath499 . *",
    "similarly to the derivation of  , @xmath503 substituting   into the third term we get @xmath504 .",
    "since the @xmath172 s increase doubly exponentially , we have that @xmath505 and so the term is bounded by @xmath500 . *",
    "we need to bound the fourth term , which is @xmath506 we first focus on the second sum .",
    "@xmath507 in the last step we again used the exponential increase of the @xmath172 s .",
    "the fourth term is therefore bounded by @xmath508 again , this sum is dominated by the leading term , so it is @xmath509 . * the fifth term we need to bound is @xmath510 using  , it is bounded by @xmath511 * in the sixth term @xmath512 , the sum is also bounded by its leading term , so we get @xmath513 . * similarly , in the seventh term @xmath514 , the sum is bounded by its leading term so we get @xmath515 .",
    "g.  borradaile , p.  n. klein , s.  mozes , y.  nussbaum , and c.  wulff - nilsen .",
    "multiple - source multiple - sink maximum flow in directed planar graphs in near - linear time . in _ proceedings of the 52nd annual symposium on foundations of computer science ( focs ) _ , pages 170179 , 2011 .",
    "g.  borradaile , p.  sankowski , and c.  wulff - nilsen .",
    "min @xmath12-cut oracle for planar graphs with near - linear preprocessing time . in _ proceedings of the 51st annual symposium on foundations of computer science ( focs ) _ , pages 601610 , 2010 .",
    "chalermsook , j.  fakcharoenphol , and d.  nanongkai . a deterministic near - linear time algorithm for finding minimum cuts in planar graphs . in _ proceedings of the 14th annual symposium on discrete algorithms ( soda ) _ ,",
    "pages 828829 , 2004 .",
    "d.  eisenstat and p.  n. klein .",
    "linear - time algorithms for max flow and multiple - source shortest paths in unit - weight planar graphs . in _ proceedings of the 45th acm symposium on theory of computing , ( stoc ) _ , pages 735744 , 2013 .",
    "g.  f. italiano , y.  nussbaum , p.  sankowski , and c.  wulff - nilsen . improved algorithms for min cut and max flow in undirected planar graphs . in _ proceedings of the 43rd acm symposium on theory of computing , ( stoc ) _ , pages 313322 , 2011 .",
    "h.  kaplan , s.  mozes , y.  nussbaum , and m.  sharir .",
    "submatrix maximum queries in monge matrices and monge partial matrices , and their applications . in _ proceedings of the 23rd annual acm - siam symposium on discrete mathematics ( soda ) _ ,",
    "pages 338355 , 2012 .",
    "h.  kaplan and y.  nussbaum .",
    "minimum @xmath31-@xmath32 cut in undirected planar graphs when the source and the sink are close . in _ proceedings of the 28th international symposium on theoretical aspects of computer science ( stacs ) _ , pages 117128 , 2011 .",
    "p.  n. klein , s.  mozes , and c.  sommer .",
    "structured recursive separator decompositions for planar graphs in linear time . in _ proceedings of the 44th acm symposium on theory of computing , ( stoc )",
    "_ , pages 505514 , 2012 ."
  ],
  "abstract_text": [
    "<S> we show how to combine two techniques for efficiently computing shortest paths in directed planar graphs . </S>",
    "<S> the first is the linear - time shortest - path algorithm of henzinger , klein , subramanian , and rao [ stoc94 ] . </S>",
    "<S> the second is fakcharoenphol and rao s algorithm [ focs01 ] for emulating dijkstra s algorithm on the _ dense distance graph _ ( ddg ) . </S>",
    "<S> a ddg is defined for a decomposition of a planar graph @xmath0 into regions of at most @xmath1 vertices each , for some parameter @xmath2 . </S>",
    "<S> the vertex set of the ddg is the set of @xmath3 vertices of @xmath0 that belong to more than one region ( boundary vertices ) . </S>",
    "<S> the ddg has @xmath4 arcs , such that distances in the ddg are equal to the distances in @xmath0 . </S>",
    "<S> fakcharoenphol and rao s implementation of dijkstra s algorithm on the ddg ( nicknamed _ fr - dijkstra _ ) runs in @xmath5 time , and is a key component in many state - of - the - art planar graph algorithms for shortest paths , minimum cuts , and maximum flows . by combining these two techniques we remove the @xmath6 dependency in the running time of the shortest - path algorithm , making it @xmath7 .    </S>",
    "<S> this work is part of a research agenda that aims to develop new techniques that would lead to faster , possibly linear - time , algorithms for problems such as minimum - cut , maximum - flow , and shortest paths with negative arc lengths . as immediate applications , </S>",
    "<S> we show how to compute maximum flow in directed weighted planar graphs in @xmath8 time , where @xmath9 is the minimum number of edges on any path from the source to the sink . </S>",
    "<S> we also show how to compute any part of the ddg that corresponds to a region with @xmath1 vertices and @xmath10 boundary vertices in @xmath11 time , which is faster than has been previously known for small values of @xmath10 . </S>"
  ]
}