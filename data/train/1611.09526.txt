{
  "article_text": [
    "in the past few years , the research community has put significant efforts in designing feature representations for acoustic sound recognition .",
    "good features should improve the performance of various audio analytic tasks such as classification and detection .",
    "traditionally , features are heuristically designed , based on the understanding of spectral characteristics of natural sounds . meanwhile , since this process is separate from the classification process  @xcite , heuristically designed features do not always contain enough information to obtain a high classification accuracy .",
    "thanks to the development of deep learning methods and rich dataset for sound , deep learning is increasingly becoming a popular candidate for acoustic recognition tasks  @xcite .",
    "recently , cnn has shown the superior performance in feature extraction and classification in visual  @xcite and acoustic domain  @xcite , especially in speech recognition  @xcite .",
    "it could not only reduce the dimension of data and but also could extract features as well .",
    "however , training a cnn model requires huge computational effort .",
    "therefore , we leverage human experience ( i.e. domain knowledge ) , to design the deep learning model , understand the features from the model , and finally use the learned features to improve the audio recognition tasks performance .    currently , most works in sound recognition area use log - mel filter banks as features .",
    "these features are not optimized for a particular audio recognition task at hand , and thus might not lead to high accuracy  @xcite . in this paper , we design our feature extractor by the studying the procedure of designing log - mel filter banks . we build a special filter bank learning layer and concatenate it with a cnn architecture . after training , the weight of the filter bank learning layer is post - processed with human experience",
    ". then , the filter bank learning layer is re - initialized with the processed weight .",
    "the weight could be iteratively improved for feature extraction .",
    "this process is shown in fig .",
    "[ fig1:framework ] .",
    "we call it as experience guided learning . to our knowledge",
    ", this is the first attempt to infuse domain knowledge of feature design to a deep learning pipeline for acoustic recognition tasks .",
    "[ fig1:framework ]        by using this method , the accuracy of recognition for the _ urbansound8k _ sound  @xcite increases at least 1.5% accuracy based on the human designed filter bank under different settings , such as triangular window for mfcc .",
    "the rest of the paper is structured as follows : section 2 introduces the related work by using various methods to improve sound recognition tasks .",
    "section 3 describes the special layer , a layer that could extract log - mel features and the cnn architecture in our work in detail . the experimental setup and result",
    "are shown in section 4 .",
    "finally , conclusion to our work can be found in section 5 .",
    "there is a wide range of studies related with sound recognition , especially in speech recognition .",
    "@xcite provided a detailed implementation of the hidden markov model ( hmm ) on speech recognition by using the linear predictive coding ( lpc ) features .",
    "@xcite applied the hmm model on the mfcc features for speech recognition . with the advancement of deep learning , people applied different deep learning techniques , cnn in particular , for recognition .",
    "@xcite applied convolutional deep belief networks to audio data and evaluated them on various audio classification tasks by using the mfcc feature .",
    "their feature representations trained from unlabeled audio data showed very good performance .",
    "however , the mfcc feature is not generalized and not learned for improving different task objectives .",
    "@xcite thus proposed a filter learning layer to adaptively learn filter banks from the spectrum , and obtained good result in speech recognition .",
    "however , this learning layer is complex ( multiple non - linear operations ) and requires pre - estimation of the spectrum features mean and standard deviation . therefore , in this study , we propose a new filter learning layer based on the procedure of designing log - mel filter banks .",
    "the mechanism of the filter bank learning layer is similar to the design of log - mel spectrogram  @xcite , which has been widely used in automatic speech recognition . in general , there are several steps to calculate this feature :    1 .",
    "perform fourier transform to calculate power spectrogram 2 .",
    "apply the mel filter banks to all power spectrogram 3 .",
    "take the logarithm of all filter banks energy    similar to this process , we design the network layer as following : the filter bank learning layer takes power spectrogram of a waveform as input .",
    "the layer generates the mel - features by multiplying the filters and individual spectrum .",
    "the number of filters is a hyper - parameter that represents the number of features to be learned .",
    "after that , we take the logarithm of these features and input into a cnn architecture that has high performance in sound recognition . the filter bank learning layer s weight",
    "is not randomly initialized .",
    "similar to triangular window or gamma - tone filter window , each row of the weight is activated once ( non - zeros value ) within a localized frequency range .    mathematically , the filter bank learning layer is described by the following equation : @xmath0 where @xmath1 is the individual power spectrum of the acoustic clip at time @xmath2 , @xmath3 is the weight of @xmath4 filter bank .",
    "@xmath5 represents each individual element .",
    "this operation s output is the energy of the filter bank .",
    "then , we take the logarithm of @xmath6 to get the log - mel filter coefficient for filter bank @xmath7 @xmath8 here , to prevent the @xmath9 non positive number error , the equation is further developed as : @xmath10 where linear rectified units @xmath11 and @xmath12 is a small constant ( e.g. @xmath13 ) . in order to optimize the objective function @xmath14 , the filter bank learning layer s weight",
    "is gradually updated by taking the derivative of the objective function with respect to the weight .",
    "the update equation is : @xmath15 here , @xmath16 is the learning rate and @xmath14 is the loss . by taking the derivative of the weight .",
    "the derivative function could be calculated through chain rule : @xmath17 and here , @xmath18 is the loss gradient from previous layers .",
    "the filter bank learning layer could adaptively extract features from the power spectrogram .",
    "combining domain knowledge , the learned filter bank s weight could be further developed into generic filters .",
    "different from @xcite s work , our filter bank learning layer does not require estimating the mean and standard deviation of the input beforehand .",
    "also , our method incurs less computation cost .",
    "in this study , the training of the cnn model is performed on the natural sounds dataset , the _ urbansound8k",
    "_  @xcite .",
    "this dataset contains 8732 labeled sound excerpts ( @xmath19 ) of urban sounds from 10 classes : air conditioner , car horn , children playing , dog bark , drilling , engine idling , gun shot , jackhammer , siren , and street music .",
    "they are evenly divided into 10 folds .",
    "the original sound is at 44.1khz , we down sample it to 22.5khz and 8khz . for the 22.5khz sound , due to the dimension of raw waveform",
    ", we divide it into 1 second each clip ( in this case , we use majority voting method to obtain the output ) . after that",
    ", we take the power spectrogram of the sound by using librosa  @xcite(nfft equals to sampling rate , default hop length ) .",
    "the weight of the filter bank learning layer is initialized by triangular filter banks of mfcc .",
    "we build two cnn architectures , one is deep vgg architecture  @xcite while the other one is shallow as shown in fig .",
    "[ fig2:arch ] .",
    "the parameters are as following .",
    "the optimizer is default adam optimizer  @xcite with learning rate 0.001 .",
    "the learning rate decays every three epochs with the decay rate 0.006 .",
    "the update function is : @xmath20 where , @xmath21 is the learning rate .",
    "[ fig2:arch ]        after each layer , we apply leakyrelu@xcite with parameter 0.33 .    the baseline is around 70%  @xcite by using svm with rbf kernel and 73.7% @xcite .",
    "we also test the @xcite s filter bank learning layer for comparison .",
    "the result is shown in table 2 .",
    "the proposed method could provide a modest 0.4% of improvement in the classification accuracy .",
    "we take out the weight of the filter bank learning layer and use the savitzky - golay function  @xcite to smooth it .",
    "we then re - initialize the filter bank layer with the smoothed weight .",
    "after retraining the model , the accuracy is improved by 1.5% .",
    "we did nt concanate the 4 second clip for the 22.5khz sound , but we expect improvement compared to the 8khz result .",
    "we also test the filter bank learning layer proposed in  @xcite , but the accuracy is lower than other baselines .",
    "this might be caused by the complex non - linearity of this layer and our estimation of input s mean and standard deviation might be too rough . to our knowledge , our method obtains the highest accuracy of _",
    "urbansound8k _ dataset .",
    "we also notice that the sampling rate of the sound affect the detection accuracy . for natural sound ,",
    "different events happen at different frequency levels .",
    "therefore , a relatively high sampling rate is essential for natural sound recognition tasks .",
    "lllllll & & & & & & +   + t & 1 & 128 & fix & 1 & 22.5 & 71.88 + t & 1 & 128 & trained & 1 & 22.5 & 72.21 + t & 1 & 128 & improved & 1 & 22.5 & 73.63 + t & 1 & 128 & fix & 4(mv ) & 22.5 & 78.34 + t & 2 & 40 & fix & 4 & 8 & 69.03 + t & 2 & 40 & trained & 4 & 8 & 69.43 + t & 2 & 40 & improved & 4 & 8 & 71.41 +      the purpose of this work is to understand the mechanism of filter bank and further facilitate the design of filter banks to generate better feature extractors . here , we visualize the filter banks from the triangular window , and smoothed weight from the trained filter bank learning layer that is trained by fold 1 - 9 in the following picture .",
    "as we can notice , the first few learned filter banks ( 1st row ) conform with the triangle filter banks , which means these triangular filter banks capture most information in low frequency range .",
    "however , in the second row , we notice that the learned filter banks are activated around 0.4khz to 0.5khz and 0.75khz to 0.9khz , while frequency between 0.6 to 0.7 khz is less interested .",
    "[ fig1:filter ]        in triangular windows , the bandwidth of filters increases as the frequency level increases .",
    "contrary to this , the learned filters show smaller bandwidth at relatively high frequency area .",
    "fig.3 also shows there are several new peaks within the original single window , which means more filter banks are required .",
    "for instance , in the last row , the third picture shows that there are three different frequency ranges that are activated and their bandwidths are relatively small .",
    "this information could provide more intuition for audio experts to design new filters .",
    "one problem with these learned filter banks is that they have a lot of serration along the the shape .",
    "this is primarily due to the bias of the model . by smoothing the learned filter banks ,",
    "the model could be generalized , however , more expert experience would be beneficial to improve the recognition accuracy . here",
    ", we apply the savitzky - golay function , however , different smooth function might result to different performance .",
    "also , adding some regularization on model s parameters would smooth these filters as well .",
    "in this paper , we explore the possibility of using the deep learning methods to facilitate the design of filter banks by incorporating human expert knowledge .",
    "we first design a filter bank learning layer that takes in frequency features .",
    "the output of the layer is fed to two different cnn architectures .",
    "this layer is designed according to the design procedure of the log - mel - spectrogram . by taking the weight of the filter bank learning layer",
    ", we apply a smooth function on the weight .",
    "this gives us at least 1.5% accuracy improvement on the _ urbansound8k _ dataset .",
    "we further investigate the learned filter banks , and they provide us some intuitions to facilitate the feature design for the recognition task .",
    "justin salamon , christopher jacoby , and juan  pablo bello , `` a dataset and taxonomy for urban sound research , '' in _ proceedings of the 22nd acm international conference on multimedia_. acm , 2014 , pp .",
    "10411044 .",
    "tara  n sainath , brian kingsbury , abdel - rahman mohamed , and bhuvana ramabhadran , `` learning filter banks within a deep neural network framework , '' in _ automatic speech recognition and understanding ( asru ) , 2013 ieee workshop on_. ieee , 2013 , pp .",
    "297302 .",
    "geoffrey hinton , li  deng , dong yu , george  e dahl , abdel - rahman mohamed , navdeep jaitly , andrew senior , vincent vanhoucke , patrick nguyen , tara  n sainath , et  al . , `` deep neural networks for acoustic modeling in speech recognition : the shared views of four research groups , '' , vol .",
    "6 , pp . 8297 , 2012 .",
    "george  e dahl , tara  n sainath , and geoffrey  e hinton , `` improving deep neural networks for lvcsr using rectified linear units and dropout , '' in _ 2013 ieee international conference on acoustics , speech and signal processing_. ieee , 2013 , pp .",
    "86098613 .",
    "hans - gnter hirsch and david pearce , `` the aurora experimental framework for the performance evaluation of speech recognition systems under noisy conditions , '' in _",
    "asr2000-automatic speech recognition : challenges for the new millenium isca tutorial and research workshop ( itrw ) _ , 2000 .",
    "honglak lee , peter pham , yan largman , and andrew  y ng , `` unsupervised feature learning for audio classification using convolutional deep belief networks , '' in _ advances in neural information processing systems _ , 2009 , pp .",
    "10961104 .",
    "brian mcfee , matt mcvicar , colin raffel , dawen liang , oriol nieto , eric battenberg , josh moore , dan ellis , ryuichi yamamoto , rachel bittner , douglas repetto , petr viktorin , joo  felipe santos , and adrian holovaty , `` librosa : 0.4.1 , '' oct .",
    "2015 .",
    "karol  j piczak , `` environmental sound classification with convolutional neural networks , '' in _ 2015 ieee 25th international workshop on machine learning for signal processing ( mlsp)_. ieee , 2015 , pp ."
  ],
  "abstract_text": [
    "<S> designing appropriate features for acoustic event recognition tasks is an active field of research . </S>",
    "<S> expressive features should both improve the performance of the tasks and also be interpret - able . </S>",
    "<S> currently , heuristically designed features based on the domain knowledge requires tremendous effort in hand - crafting , while features extracted through deep network are difficult for human to interpret . in this work </S>",
    "<S> , we explore the experience guided learning method for designing acoustic features . </S>",
    "<S> this is a novel hybrid approach combining both domain knowledge and purely data driven feature designing . </S>",
    "<S> based on the procedure of log mel - filter banks , we design a filter bank learning layer . </S>",
    "<S> we concatenate this layer with a convolutional neural network ( cnn ) model . after training the network , </S>",
    "<S> the weight of the filter bank learning layer is extracted to facilitate the design of acoustic features . </S>",
    "<S> we smooth the trained weight of the learning layer and re - initialize it in filter bank learning layer as audio feature extractor . for the environmental sound recognition task based on the _ urbansound8k _ dataset  @xcite , </S>",
    "<S> the experience guided learning leads to a 2% accuracy improvement compared with the fixed feature extractors ( the log mel - filter bank ) . </S>",
    "<S> the shape of the new filter banks are visualized and explained to prove the effectiveness of the feature design process .    </S>",
    "<S> filter bank , feature learning , experience guide learning , data driven , neural network </S>"
  ]
}