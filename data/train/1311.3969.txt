{
  "article_text": [
    "in the simplest random - effects model of meta - analysis involving , say , @xmath0 studies the data is supposed to consist of treatment effect estimators @xmath1 , which have the form @xmath2 here @xmath3 is an unknown common mean , @xmath4 is zero mean between - study effect with variance @xmath5 , @xmath6 , and @xmath7 represents the measurement error of the @xmath8th study , with variance @xmath9 .",
    "then the variance of @xmath10 is @xmath11 . in practice @xmath12",
    "is often treated as a given constant , @xmath13 , which is the reported standard error or uncertainty of the @xmath8th study .",
    "the considered here problem is that of estimation of the common mean @xmath3 and of the heterogeneity variance @xmath5 from the statistical decision theory point of view under normality assumption . if @xmath5 is known , then the best unbiased estimator of @xmath3 is the weighted means statistic , @xmath14 , with the normalized weights , @xmath15 @xmath16 .",
    "its variance has the form @xmath17 ^{-1}.\\ ] ] when @xmath5 is unknown , to estimate @xmath3 the common practice uses a plug - in version of @xmath18 , @xmath19 so that an estimator @xmath20 of @xmath5 is required in the first place .    usually such an estimator is obtained from a moment - type equation @xcite .",
    "for example , the dersimonian ",
    "laird @xcite estimator of @xmath5 is @xmath21 with @xmath22 denoting the graybill ",
    "deal estimator of @xmath3 .",
    "the popular dersimonian ",
    "laird @xmath3-estimator is obtained from ( [ es ] ) by using the positive part of @xmath23 .",
    "similarly the estimator of @xmath5 , @xmath24 leads to the hedges estimator of @xmath3 .",
    "the paper questions the wisdom of using under all circumstances the tradition of plugging in @xmath5 estimators to get @xmath3 estimators .",
    "indeed the routine of plug - in estimators may lead to poor procedures .",
    "for example , by replacing the unknown @xmath5 by @xmath25 in the above formula for @xmath26 , one can get a flagrantly biased estimator which leads to inadequate confidence intervals for @xmath3 .",
    "a large class of weighted means statistics is motivated by the form of bayes procedures derived in section  [ qe ] .",
    "these statistics which typically _ do not _ admit the representation ( [ es ] ) induce estimators of the weights ( [ we ] ) which shows the primary role of @xmath3-estimation .",
    "the main results of this work are based on a canonical representation of the restricted likelihood function in terms of independent normal random variables and possibly of some @xmath27-random variables .",
    "an important relationship between the weighted means statistics with weights of the form ( [ we ] ) and linear combinations of @xmath28 s , which are shift invariant and independent , follows from this fact .",
    "our representation transforms the original problem to that of estimating curve - confined expected values of independent heterogeneous @xmath29-random variables .",
    "this reduction makes it possible to describe the risk behavior of the weighted means statistics whose weights are determined by a quadratic form .",
    "we make use of the concept of permissible estimators which can not be uniformly improved in terms of the differential inequality in section  [ inad ] .",
    "this inequality shows that the sample mean exhibits the stein - type phenomenon being an inadmissible estimator of @xmath3 under the quadratic loss when @xmath30 .",
    "a risk function for the weights in a weighted means statistic whose main purpose is @xmath3-estimation is suggested in section  [ rrisk ] .",
    "it is shown there that under this risk the sample mean is not even minimax .",
    "section  [ mini ] discusses the case of approximately equal uncertainties , and section  [ exa ] gives an example .",
    "the derivation of the canonical representation of the likelihood function is given in the ; the proof of theorem  [ th1 ] is delegated to the electronic supplement  @xcite .",
    "the setting with the common mean @xmath3 and the heterogeneity variance @xmath5 described in section  [ in ] is a special case of a mixed linear model where statistical inference is commonly based on the restricted ( residual ) likelihood function .",
    "the ( negative ) restricted log - likelihood function ( @xcite , section  6.6 ) has the form @xmath31.\\ ] ] it is possible that some of @xmath32 are equal ; let @xmath32 have the multiplicity @xmath33 , so that @xmath34",
    ". then with the index @xmath8 now taking values from @xmath35 to @xmath36 , @xmath37.\\ ] ] here , @xmath38 denotes the number of pairwise different @xmath32 , @xmath39 represents the average of @xmath40 @xmath28 s corresponding to the particular @xmath41 , and @xmath42 is their sample variance when @xmath43 . to simplify the notation",
    ", we write @xmath10 for @xmath44 , so that @xmath45 . in our problem @xmath46 and @xmath47 , @xmath48 ,",
    "form a sufficient statistic for @xmath3 and @xmath5 .    throughout this paper ,",
    "we assume that @xmath49 .",
    "otherwise all @xmath3-estimators reduce to the sample mean ( but see section  [ mini ] where @xmath5-estimation for equal uncertainties is considered ) .",
    "the results in the relate the likelihood function @xmath50 to the joint density of @xmath51 independent normal , zero mean random variables @xmath52 .",
    "the @xmath53-dimensional normal random vector @xmath54 which is a linear transform of @xmath28 has zero mean ( no matter what @xmath3 is ) and the covariance matrix , @xmath55 , with @xmath56 larger than @xmath57 .    to find these numbers , we introduce the polynomial @xmath58 of degree @xmath0 , and its minimal annihilating polynomial @xmath59 which has degree @xmath38 .",
    "define @xmath60 thus @xmath61 is a polynomial of degree @xmath51 which has only real ( negative ) roots , denoted by @xmath62 ( coinciding with the roots of @xmath63 different from @xmath64 ) .",
    "thus @xmath65 .",
    "note that @xmath66 .",
    "when @xmath67 , @xmath68 , and @xmath69 .",
    "according to ( [ def ] ) , @xmath70 so that by using ( [ co7 ] ) one gets @xmath71 \\\\[-8pt ] & & \\hphantom{\\mathcal{l } = \\frac{1}{2 } \\biggl[}+\\sum _ i \\frac{(\\nu_i-1 ) u_i^2}{\\tau^2+s_i^2 } + \\sum_i ( \\nu_i-1)\\log \\bigl(\\tau^2+s_i^2 \\bigr ) + \\log n \\biggr ] .",
    "\\nonumber\\end{aligned}\\ ] ]    the representation ( [ rl ] ) of the restricted likelihood function very explicitly takes into account one degree of freedom used for estimating @xmath3 , as it corresponds to @xmath51 independent zero mean , normal random variables @xmath72 with variances @xmath73 . in addition , this likelihood includes independent @xmath42 , each being a multiple of a @xmath29-random variable with @xmath74 degrees of freedom . when @xmath48 , @xmath42 is an unbiased estimator of @xmath75 , @xmath76 . for @xmath77 , @xmath78 with probability one .",
    "according to the sufficiency principle , all statistical inference about @xmath5 involving the restricted likelihood can be based exclusively on @xmath79 and @xmath80 .",
    "their joint distribution forms a curved exponential family whose natural parameter is formed by @xmath81 ( and perhaps by some @xmath82 ) .",
    "evaluation of the restricted maximum likelihood estimator ( reml ) @xmath20 is considerably facilitated by employing @xmath83 and @xmath84 .",
    "indeed ( [ rl ] ) shows that this estimator can be determined by simple iterations as @xmath85 with @xmath23 as a good starting point , and truncation at zero if the iteration process converges to a negative number .",
    "thus , @xmath20 is related to a quadratic form whose coefficients are inversely proportional to the estimated variances of @xmath86 and of @xmath87 ( cf .",
    "@xcite , section  8) .",
    "the form of the likelihood function @xmath88 also motivates the moment - type equations based on general quadratic forms , @xmath89 with positive constants @xmath90 .",
    "the moment - type equation written in terms of random variables @xmath83 and @xmath84 is @xmath91 = \\biggl [ \\sum_j q_j + \\sum _ i ( \\nu_i-1)r_i\\biggr ] \\tau^2 + \\sum_j q_j t_j^2 + \\sum_i ( \\nu_i-1)r_i s_i^2.\\ ] ] then the estimator of @xmath5 by the method of moments is @xmath92 unless @xmath5 is large , the probability that @xmath93 takes negative values is non - negligible .",
    "non - negative statistics @xmath94 are used to get @xmath3-estimators of the form ( [ es ] ) .",
    "the representations of two traditional statistics in section  [ in ] easily follow , @xmath95 and @xmath96    a different method - of - moments procedure suggested by paule and mandel @xcite is based on solving the equation , @xmath97 which has a unique positive solution , @xmath98 , provided that @xmath99 . if this inequality does not hold , @xmath100 .",
    "because of ( [ co7 ] ) , the equation can be rewritten in terms of @xmath101 s and @xmath102 s as @xmath103 this representation allows for an explicit form of @xmath104 in some cases .",
    "indeed , when @xmath105 , @xmath106 $ ] , which is also the reml .",
    "when @xmath107 , @xmath108 , @xmath109    we conclude this section by noticing that the widely used heterogeneity index @xmath110 ( @xcite , page  117 ) in terms of @xmath101 s and @xmath111 s takes the from @xmath112      let us look now at the generalized bayes estimator of @xmath3 when @xmath113 is a prior distribution for @xmath114 while @xmath3 has the uniform ( non - informative ) prior . under the quadratic loss this estimator has the form with",
    "@xmath88 given in ( [ rl ] ) @xmath115 thus @xmath116 is a weighted means statistic with normalized weights , @xmath117^{-1 } \\exp\\{-\\mathcal{l}\\ } \\,\\mathrm{d}\\lambda(\\tau^2)$ ] , @xmath118 , which are shift invariant , @xmath119 for any real @xmath120 .",
    "( any function of @xmath52 is shift invariant . ) indeed the use of restricted likelihood is tantamount to the practice of weighted means statistics with invariant weights as @xmath3 estimators .",
    "@xcite , section  9.2 ) .",
    "formula ( [ rep ] ) in the gives @xmath121 with @xmath72 discussed in section  [ ba ] .",
    "positive coefficients @xmath122 ( the diagonal elements of the diagonal matrix @xmath123 defined in lemma  [ lem ] ) can be found from ( [ co6 ] ) or rather from ( [ co5 ] ) ; @xmath124 is the posterior mean of @xmath81 , @xmath125 with @xmath126 .",
    "thus positive @xmath124 is designed to estimate @xmath81 , @xmath127 , and as a function of @xmath128 , @xmath124 decreases .",
    "the inequalities , @xmath129 , and @xmath130 , are equivalent",
    ".    if @xmath131 and the support of @xmath113 has at least two points , @xmath116 does not admit representation ( [ es ] ) which suggests a more general class of @xmath3-estimators .",
    "namely , we propose to use weighted means statistics @xmath132 with weights @xmath133 .",
    "the bayes weights belong to a smaller part of this polyhedron , namely to the convex hull of the vectors with coordinates @xmath134 for @xmath6 . if @xmath20 is an estimate of @xmath5 , the weights corresponding to ( [ es ] ) , @xmath135 lie on the boundary of this convex hull . a corner point",
    ", @xmath136 , of the convex hull always is an inner point of the polyhedron .",
    "thus the focus in this paper is on estimators @xmath116 of @xmath3 , which admit the representation , @xmath137 with @xmath138 and @xmath122 as defined above .",
    "the last term in the right - hand side of ( [ ne ] ) can be viewed as an arguably necessary heterogeneity correction to @xmath139 .",
    "notice that ( [ ne ] ) does not need an estimate of @xmath5 as a prerequisite . since @xmath124 is an approximation to @xmath81 , when @xmath140 , the form of the reml @xmath20 in section  [ ba ] suggests such an estimator : @xmath141_+/\\sum w_j^2 $ ] .",
    "if some of the multiplicities exceed one , an estimator of @xmath142 can be derived from @xmath124 by replacing @xmath143 by @xmath32 . according to ( [ rep ] ) , @xmath18 as well as @xmath139 , has the form ( [ ne ] ) .",
    "in fact , all traditional statistics ( [ es ] ) admit this representation .",
    "we look now at the quadratic risk behavior of @xmath3-estimators of the form ( [ ne ] ) .",
    "if @xmath144 is such an estimator with positive normalized weights @xmath145 which are shift invariant functions of @xmath146 , then it is unbiased .",
    "its variance does not depend on @xmath3 and can be written as @xmath147 ^{-1 } + e ( \\delta-{\\hat{\\mu}_{\\mathrm{opt}}})^2\\ ] ] by independence of @xmath18 and @xmath148 .",
    "this and more general decompositions of the mean squared error are discussed by harville @xcite . the second term in the right - hand side of this identity is an important variance component which shows how well @xmath116 approximates the optimal but unavailable @xmath18 , and which relates our setting to the classical estimation problem of the multivariate @xmath53-dimensional normal mean .",
    "[ pro2.1 ] if the coefficients @xmath149 defining the estimator ( [ ne ] ) are piecewise differentiable in @xmath101 s , then @xmath150 where @xmath151 .",
    "when @xmath152 , @xmath139 is an inadmissible estimator of @xmath3 under the quadratic loss .",
    "the omitted proof of proposition  [ pro2.1 ] is based on ( [ rep ] ) , ( [ co5 ] ) , and on familiar integration by parts technique .",
    "it demonstrates linkage of our situation to the differential inequality of a statistical estimation problem @xcite .",
    "namely , if for some vector @xmath153 , @xmath154 , then @xmath155 is an unbiased estimate of @xmath156 .",
    "therefore @xmath157 , @xmath158 , improves on @xmath159 , @xmath160 , as a @xmath153-estimator provided that for all values @xmath161 , @xmath162 following @xcite , let us call a ( piecewise differentiable ) vector function @xmath163 _ permissible _ if ( [ per ] ) does not have any solutions @xmath164 providing a strict inequality at some point .",
    "thus , @xmath165 is a permissible estimator of the vector normal mean @xmath153 if and only if the corresponding scalar @xmath3-estimator , @xmath166 , can not be improved upon in the sense of differential inequality ( [ per ] ) .",
    "since for @xmath152 , @xmath167 is not a permissible function , the sample mean @xmath139 is inadmissible in the original setting .",
    "indeed the left - hand side of ( [ per ] ) is negative for @xmath168 proving this statement .",
    "the differential operator in ( [ per ] ) does not involve @xmath102 s or @xmath169 s , but in our problem only functions @xmath170 such that @xmath171 and @xmath172 are of interest .",
    "since @xmath81 is positive and can not exceed @xmath173 , according to the first equality in proposition  [ pro2.1 ] , @xmath124 can be improved by @xmath174 $ ] .",
    "the proof of theorem  1 in @xcite shows that any permissible @xmath124 in our situation is of the form @xmath175\\ ] ] with some piecewise differentiable positive function @xmath176 .",
    "when @xmath140 and @xmath177 for a positive quadratic form @xmath178 , one gets @xmath179 $ ] .",
    "if there are multiplicities exceeding one , the quadratic form @xmath180 is to be replaced by @xmath181 .",
    "for example , the function , @xmath182 , leads to the estimator ( [ ne ] ) with @xmath183.\\ ] ]    the statistic @xmath184 , corresponding to @xmath185 , when @xmath140 is similar to the positive part of the stein estimator of the vector normal mean which improves over  @xmath186 .",
    "however , in the meta - analysis context it is desirable having the coefficients @xmath187 of the same ordering as @xmath173 , and this condition may not hold for @xmath188 . as a matter of fact , despite doing better than @xmath189 or @xmath190 , the weights @xmath191 do not produce a good estimator of @xmath3 .",
    "the same is true for many other procedures ( [ wco ] ) satisfying condition ( [ xbar ] ) of theorem  [ th1 ] in the next section .",
    "this theorem shows that if @xmath192 , @xmath139 is an inadmissible estimator of @xmath3 although the function @xmath167 is permissible then .      according to ( [ qr ] ) the variance of estimator ( [ ne ] )",
    "is completely determined by the term , @xmath194 , which can be interpreted as a cost of not knowing @xmath5 when estimating @xmath3 , or as a new risk of @xmath116 viewed as a procedure providing approximations to @xmath195 .",
    "more conveniently , with @xmath196 , define @xmath197 ^ 2 } { ( { \\tau^2+s^2})/{n}- [ \\sum_i { \\nu_i}/ ( { \\tau^2+s_i^2 } ) ] ^{-1}}\\ ] ] to be the @xmath193-risk of @xmath116 . because of ( [ rep ] ) and ( [ ne ] ) , the ensuing random loss function has the form , @xmath198^{-1 } } = \\frac{\\sum_j   ( w_j -{1}/({\\tau^2+t_j^2 } ) ) ^2 b_j y_j^2}{\\sum_j   { b_j}/ ( { \\tau^2+t_j^2 } ) } .\\ ] ] this loss is invariant under a scale change of @xmath199 ( or of @xmath200 ) . for @xmath201 , @xmath202^{-1 }",
    "\\sim\\frac{\\sum_i \\nu_i(s_i^2- s^2)^2}{n^2 \\tau^2 } , \\ ] ] so that the normalizing factor in the definition of @xmath203 amplifies the error in approximating @xmath18 when @xmath5 is large .",
    "the results of this section show that for estimators @xmath116 satisfying conditions of the following theorem  [ th1 ] , @xmath204 \\bigl[r\\bigl(\\delta , \\tau^{2}\\bigr)-1\\bigr ] = \\frac{\\tau^2+s^2}{n } + \\mathrm{o } \\biggl ( \\frac{1 } { \\tau^2 } \\biggr)\\ ] ] when @xmath205 .",
    "thus , @xmath206 is the dominating contribution to the variance of @xmath116 when @xmath5 is large .",
    "the @xmath193-risk is a useful tool for the comparison of estimators ( [ ne ] ) , as unlike the normalized quadratic risk , @xmath207 , it removes this linear in @xmath5 term .",
    "if @xmath208 with an invariant @xmath20 , then @xmath209 can be interpreted as a conventional risk of the estimator @xmath20 . however under this risk large values of @xmath20",
    "are not penalized very much no matter what @xmath5 is .",
    "indeed @xmath20 is not designed to estimate @xmath5 itself , but rather @xmath210 estimates @xmath211 ( cf .",
    "@xcite , page 329 ) . when @xmath105 , the estimator @xmath139 , which corresponds to @xmath212 , is even admissible which of course can not happen for any unbounded loss function .",
    "this circumstance explains why an estimator @xmath20 may have a large quadratic risk , while the associated estimator @xmath213 in ( [ es ] ) has a small variance .",
    "that phenomenon is known to happen in the case of the dersimonian ",
    "laird procedure @xcite .",
    "the estimator @xmath214 has a constant risk , @xmath215 , which raises the question of its @xmath193-minimaxity , i.e. , if @xmath216 .",
    "in contrast , for the graybill ",
    "deal estimator , @xmath217 /[\\sum b_j ( \\tau^2 + t_j^2)^{-1}]$ ] , so that its @xmath193-risk , which vanishes when @xmath218 , grows quadratically in @xmath5 .",
    "the next result gives a large class of estimators with bounded @xmath193-risk improving on @xmath139 when @xmath219 .",
    "[ th1 ] under notation of section  [ ba ] , let for @xmath220 , @xmath221 be a quadratic form with positive coefficients @xmath90 . if @xmath116 has the form ( [ ne ] ) such that for @xmath222 , then @xmath223\\quad\\quad\\ \\ \\\\ & \\geq&\\frac{2}{n-1 } , \\nonumber\\end{aligned}\\ ] ] where independent standard normal @xmath224 are independent of @xmath225 . equal coefficients @xmath226 ( and only they ) provide the asymptotically optimal quadratic form . if @xmath227 , the optimal choice is @xmath228 .",
    "the sample mean @xmath139 is not @xmath193-minimax , any estimator ( [ ne ] ) with weights ( [ wco ] ) improves on it",
    "if @xmath229 \\sum_j b_j q_j } { \\max [ \\max_j q_j^2 t_j^ 4 , \\max_{i : \\nu_i \\geq2 } r_i^2 s_i^4 ] \\sum_j b_j q_j^2}.\\ ] ]    theorem  [ th1 ] shows that the traditional weights ( [ weig ] ) with @xmath230 are not asymptotically optimal unless the quadratic form @xmath231 coincides ( up to a positive factor ) with @xmath232 , and @xmath233 .",
    "only then ( [ isr ] ) is an equality .",
    "thus , the hedges estimator for which @xmath234 and @xmath235 , is not asymptotically optimal albeit its performance is the best when @xmath5 is large . for the mandel ",
    "paule estimator from section  [ ba ] , as well as for the reml , ( [ isr ] ) also holds with the same quadratic form and the same @xmath236 .",
    "the dersimonian ",
    "laird estimator is defined by the quadratic form @xmath237 with @xmath238 .",
    "therefore , these three statistics are not optimal for large @xmath5 either .",
    "the case when @xmath105 was studied in @xcite . then @xmath139 is admissible ( so that it is automatically minimax under @xmath193 ) .",
    "any estimator ( [ ne ] ) has the form ( [ es ] ) with some @xmath239 , and its @xmath193-risk grows linearly in @xmath240 , @xmath241 for @xmath242 , as @xmath205 , @xmath243 ( see electronic supplement ) . by analogy with the stein phenomenon , admissibility of the sample mean when @xmath244 is expected .      when @xmath220 , the minimax value , @xmath245 , ( which does not exceed one since @xmath246 ) can not be smaller than @xmath247 .",
    "indeed for any estimator @xmath116 , @xmath248 this fact can be proven by constructing a sequence of proper prior densities for @xmath5 such that the corresponding sequence of the bayes @xmath193-risks converges to @xmath247 .",
    "thus for large @xmath5 , the estimators ( [ ne ] ) with @xmath249 , @xmath233 , can not be improved upon .",
    "the most natural of these statistics , say , @xmath250 has the form ( [ ne ] ) with @xmath251 another modified hedges estimator , @xmath252 , has the form ( [ es ] ) with @xmath253_+$ ] and also is asymptotically optimal although in general its performance is worse than that of ( [ del ] ) .    if @xmath254 , so that all @xmath143 and @xmath32 tend to @xmath255 , @xmath256 , @xmath257 ^ 2 \\,\\mathrm{d}g_{n+1 } \\biggl ( \\frac{v } { \\tau^2+s^2 } \\biggr).\\ ] ] here and further @xmath258 is the distribution function of @xmath29-law with @xmath259 degrees of freedom .",
    "thus if @xmath260 , our problem is that of estimation of the reciprocal of the scale parameter @xmath261 under the restriction , @xmath262 .",
    "the `` data '' @xmath263 in this problem is @xmath29-distributed , @xmath264 , and the invariant loss function , @xmath265 , corresponds to the @xmath193-risk .",
    "then the minimax value , @xmath247 , is the same as in the non - restricted ( @xmath266 ) parameter case @xcite . as in unrestricted scale parameter estimation ,",
    "the generalized prior , @xmath267 , @xmath262 , or @xmath268 , provides a least favorable distribution .",
    "see also @xcite for more general results .",
    "thus in meta - analysis problems with @xmath32 exhibiting little variation , the minimax value is expected to stay close to @xmath247 .",
    "indeed when @xmath269 , @xmath270 , @xmath271 the formula ( [ rar ] ) shows that the estimator ( [ del ] ) is minimax unlike @xmath252 for which @xmath272_+ /(n-3 ) + s^2 \\}^{-1}$ ] .",
    "the dersimonian ",
    "laird rule , @xmath273_+ /(n-1 ) + s^2 \\ } ^{-1 } , \\alpha = n-1 $ ] , coincides in this situation with the reml and the hedges estimator . for the proper maximum likelihood estimator of @xmath274 , @xmath275 .",
    "none of these procedures is minimax which indicates that their good properties in meta - analysis may be attributable to a large number of individual studies ( large @xmath0 ) or to lack of interest in high heterogeneity ( small @xmath5 ) .",
    "figure  [ fi1 ] shows the graphs of the @xmath193-risk in ( [ rar ] ) when @xmath276 .",
    "it suggests that the estimator @xmath250 performs quite well for small / medium @xmath0 s .",
    "indeed this estimator is better than other procedures except for small @xmath5 in which case @xmath277 dominates @xmath252 ( at the price of higher risk for larger values of @xmath5 ) .",
    "-risks of estimators corresponding to @xmath278 ( dash - dotted line ) , @xmath252 ( line marked by diamonds ) and @xmath250 ( line marked by @xmath279 ) when @xmath280 ( left panel ) , and of the same risks when @xmath281 ( right panel ) .",
    "the straight line depicts the minimax value @xmath282 . ]",
    "when there are only two different values @xmath284 and @xmath285 with multiplicities @xmath286 and @xmath287 , @xmath288 , @xmath289 and if @xmath290 , @xmath291 any estimator ( [ ne ] ) has the form ( [ es ] ) for some @xmath20 , @xmath292    for @xmath250 , @xmath293_+ , q^\\infty = y^2+(\\nu_1 - 1)u_1 ^ 2+(\\nu_2 - 1)u_2 ^ 2 $ ] . the modified hedges estimator @xmath252 with @xmath294_+$ ] typically has its @xmath193-risk at @xmath218 larger than that of @xmath250 .",
    "( the exact condition for @xmath252 to have a smaller @xmath193-risk at @xmath218 than @xmath295 is : @xmath296 , and if @xmath297 , then @xmath298 , @xmath299 s_2 ^ 2 \\geq [ n(n-4)-\\nu_1(2n-5 ) ] s_1 ^ 2 $ ] . )    the @xmath193-risk of @xmath250 at @xmath218 can be larger than @xmath300 . indeed @xmath301 where @xmath302 is the distribution function of @xmath303 . with @xmath304^{1/(n+1)}$ ] , according to the okamoto inequality @xcite , @xmath305 .",
    "thus , since @xmath306 ^ 2 $ ] is an increasing function of @xmath307 , @xmath308}{n-1 } \\\\ & & { } + \\frac { ( n-3)a^2[1-g_{n-3}(a(n-3))]}{n-1}.\\end{aligned}\\ ] ] this inequality shows that @xmath309 , if @xmath310 , where @xmath311 is monotonically increasing to @xmath35 in @xmath312 for small @xmath313 , @xmath250 can not have its risk at the origin smaller than @xmath282 .",
    "for example , when @xmath314 , @xmath315 if and only if @xmath316 , i.e. , iff @xmath317 .",
    "the dersimonian ",
    "laird estimator @xmath277 with @xmath318 , has its @xmath193-risk at @xmath218 of the form @xmath319 ^ 2 \\,\\mathrm{d}g_{n+1}(v)\\ ] ] with @xmath320 $ ] .    for the estimator @xmath321 defined by ( [ ne ] ) , @xmath322 so that @xmath323_+$ ] .",
    "its risk at @xmath218 , @xmath324 is always smaller than that of @xmath250 .",
    "but @xmath321 is also competitive against @xmath277 .",
    "indeed @xmath325 if and only if @xmath326 , that is , iff @xmath327 thus provided that @xmath328}$ ] , @xmath329 improves upon @xmath277 for small @xmath5 .",
    "if , say , @xmath330 , this domination means that @xmath331 .",
    "thus , when one study reports a smaller uncertainty than all other studies whose standard errors are approximately equal , @xmath321 improves upon the dersimonian ",
    "laird estimator for small @xmath5 .    however , there is no uniform domination as the condition , @xmath332 , means that for large @xmath333 .",
    "author s attempt was to give a perspective of a meta - analysis setting from the point of view of the statistical decision theory .",
    "although concepts like admissibility or minimaxity have not so far generated much interest among meta - analysts , there is a realization that different desirable qualities of the employed procedures call for different loss functions . the quadratic loss for the mean effect estimators from a wide class leads in a natural way to the @xmath193-risk suggested and studied in this paper .",
    "this risk strongly recommends against the use of the sample mean as a consensus estimate which still happens in some collaborative studies .",
    "moreover , the @xmath193-risk questions well recognized excellent properties of the dersimonian ",
    "laird estimator @xmath277 in the situation when @xmath13 are almost equal , or when one study claims a high precision while all other studies report larger uncertainties which are about the same . the unsatisfactory performance of the graybill ",
    "deal estimator @xmath334 is well known in the latter case .",
    "it is of interest that @xmath321 improves on the dersimonian ",
    "laird estimator for moderate / small @xmath5 .",
    "inference on the overall effect can be obtained before the heterogeneity variance is estimated , but even in the simplest cases considered here there is no unique rule dominating all others .",
    "this paper is dedicated to the memory of george casella who was always interested in implications of the statistical decision theory results to practical estimation problems @xcite .",
    "let @xmath335 denote unit coordinates vector whose dimension is clear from the context , and put @xmath336 , @xmath337 . in the used here notation of section  [ ba ] the vector @xmath28 has the diagonal covariance matrix , @xmath338 .",
    "[ lem ] for any @xmath263 different from @xmath339 , and for any @xmath340 , @xmath341",
    "^{-1}= \\frac{\\nu_i } { n } -\\sum _ { j } \\frac { a_{ij } } { v+t_j^2},\\ ] ] where @xmath342 for any @xmath343 , @xmath344 if the @xmath345 matrix @xmath346 is determined by its elements @xmath347 in ( [ coe ] ) , then @xmath348 and @xmath349 the matrices @xmath350 and @xmath351 are diagonal , and @xmath352 with @xmath353 , @xmath354 and @xmath355    by the definition of the polynomial @xmath61 in section  [ ba ] , @xmath356 ^{-1 } & = & \\frac{\\nu_i } { n } - \\frac{\\nu_i p(v ) } { ( v+s_i^2 ) p^\\prime(v ) } \\\\ & = & \\frac{\\nu_i } { n } -\\frac{\\nu_i m(v ) } { ( v+s_i^2 ) q ( v)}= \\frac { \\nu_i [ \\prod_j ( v+t_j^2 ) - \\prod_{k \\neq i } ( v+s_k^2 ) ] } { q(v)}\\end{aligned}\\ ] ] with the right - hand side of this identity being the ratio of two polynomials of degree @xmath357 and @xmath51 , respectively . the formulas ( [ coo ] ) and ( [ coe ] ) easily follow from the classical result on partial fraction decomposition for such ratios .      by equating coefficients at @xmath361 of @xmath362 and @xmath363 , one gets @xmath364 .",
    "the comparison of coefficients at @xmath365 of two equal polynomials , @xmath366 and @xmath367 $ ] , shows that @xmath368 which implies ( [ co2 ] ) .          to prove ( [ co3 ] ) , observe that for @xmath377 , the @xmath378th element of the matrix @xmath379 has the form , @xmath380=- \\frac{\\nu_i \\nu _ k}{n}.\\end{aligned}\\ ] ] here we used the facts that @xmath381 , and @xmath382 .        to prove ( [ co10 ] ) for fixed @xmath386 , multiply ( [ coo ] ) by @xmath387 , divide by @xmath388 , and sum up over @xmath8 to get the following expression for the @xmath389th element of the matrix @xmath390 , @xmath391,\\ ] ] where @xmath392 is the kronecker symbol ( @xmath393 , if @xmath394 otherwise ) .",
    "it is easy to see that @xmath395 , unless there are at least two equal indices among @xmath396 .",
    "when all three of these indices coincide , @xmath397 ^ 3 } \\sum_i \\frac{\\nu_i } { ( s_i^2-t_j^2)^3 } \\\\ & = & -\\frac { m(-t_j^2 ) [ q^{\\prime\\prime } ( -t_j^2 ) m(-t_j^2)- 2 q^\\prime ( -t_j^2 ) m^\\prime ( -t_j^2 ) ] } { 2 [ q^\\prime ( -t_j^2)]^3 } \\\\ & = & \\frac { b_j [ q^{\\prime\\prime } ( -t_j^2 ) m(-t_j^2)- 2 q^\\prime ( -t_j^2 ) m^\\prime ( -t_j^2 ) ] } { 2 [ q^\\prime ( -t_j^2)]^2 } = - \\frac { b_j^2 q^{\\prime\\prime } ( -t_j^2)+ 2 b_j m^\\prime ( -t_j^2)}{2 q^\\prime ( -t_j^2)}.\\end{aligned}\\ ] ] if , say , @xmath398 , @xmath399 ^ 2 q^{\\prime}(-t_\\ell^2 ) } \\sum_i \\frac{\\nu _",
    "i } { ( s_i^2-t_j^2)^2 ( s_i^2-t_\\ell^2 ) } \\\\ & = & - \\frac { m^2(-t_j^2 ) m(-t_\\ell^2 ) } { [ q^{\\prime } ( -t_j^2)]^2 q^{\\prime}(-t_\\ell^2 ) ( t_j^2-t_\\ell^2 ) } \\sum_i \\frac{\\nu_i } { ( s_i^2-t_j^2)^2 } \\\\ & = & \\frac { m(-t_j^2 ) m(-t_\\ell^2 ) } { q^{\\prime } ( -t_j^2 ) q^{\\prime } ( -t_\\ell^2 ) ( t_j^2-t_\\ell^2 ) } = \\frac { b_j b_\\ell}{t_j^2-t_\\ell^2}.\\end{aligned}\\ ] ]",
    "the last formula shows that off - diagonal elements of @xmath400 , for @xmath401 have the form @xmath402 \\\\ & & \\quad= \\biggl(\\sum_i \\frac{\\nu_i}{\\tau^2+s_i^2 } \\biggr)\\frac{b_j b_\\ell } { ( \\tau^2 + t_j^2 ) ( \\tau^2 + t_\\ell^2)},\\end{aligned}\\ ] ] that is , ( [ co10 ] ) holds for the off - diagonal elements .      define the polynomial @xmath405 by the formula , @xmath406 then the degree of @xmath407 is @xmath357 , and this polynomial is determined by its values at @xmath408 : @xmath409 , and @xmath410 .",
    "it follows that @xmath411 indeed , the polynomial in the right - hand side has degree @xmath357 . since @xmath412 it assumes the same values as @xmath407 at @xmath413 , which establishes ( [ co10 ] ) .    because of ( [ co3 ] ) and ( [ coe ] ) , @xmath414x + ( { \\rho}^{\\mathrm{t } } a^{\\mathrm{t } } x )   e $ ] .",
    "thus the quadratic form in the left - hand side of ( [ co7 ] ) can be written as @xmath415^{\\mathrm{t } } c^{-1 } \\bigl[j^{-1}a \\bigl(a^{\\mathrm{t } } j^{-1}a\\bigr)^{-1 } a^{\\mathrm{t } } x+   e   { \\rho}^{\\mathrm{t } } a^{\\mathrm{t } } x\\bigr ] \\\\ & & \\quad = y^{\\mathrm{t } } \\bigl [ \\bigl(a^{\\mathrm{t } } j^{-1}a \\bigr)^{-1/2 } a^{\\mathrm{t } } j^{-1}+\\bigl(a^{\\mathrm{t } } j^{-1}a\\bigr)^{1/2 } { \\rho}e ^{\\mathrm{t}}\\bigr ] \\\\ & & \\qquad{}\\times c^{-1}\\bigl [ j^{-1}a \\bigl(a^{\\mathrm{t } } j^{-1}a \\bigr)^{-1/2 } +   e   { \\rho}^{\\mathrm{t } } \\bigl(a^{\\mathrm{t } } j^{-1}a\\bigr)^{1/2 } \\bigr]y \\\\ & & \\quad= y^{\\mathrm{t } } \\operatorname{diag}({\\rho})y,\\end{aligned}\\ ] ] where the second equality follows from ( [ co10 ] ) and ( [ co9 ] ) .    the following important representation for @xmath18 @xmath416 is a consequence of lemma  [ lem ] . here",
    "@xmath417 are independent normal , zero mean random variables with the variances @xmath418 . indeed the normal random vector @xmath419 has the covariance matrix @xmath420 . since @xmath421 , @xmath18 and @xmath72",
    "are independent implying independence of @xmath18 and @xmath148 in section  [ inad ] .",
    "the coefficients @xmath347 provide a simple expression for @xmath422 .",
    "indeed , by dividing ( [ coo ] ) by @xmath40 and multiplying it by @xmath423 , one gets after summing up over all @xmath8 and @xmath371 and using ( [ co0 ] ) , ( [ co2 ] ) , @xmath424 ^{-1 } -\\frac { \\tau^2+s^2}{n } = -\\sum_{i , j } \\frac{a_{ij}^2}{\\nu_i ( \\tau^2 + t_j^2)}.\\end{aligned}\\ ] ] this formula can be written in the form , @xmath425 which provides the representation of the left - hand side of ( [ co5 ] ) as a ratio of two polynomials of degree @xmath357 and @xmath51 , respectively and which allows numerical evaluation of @xmath426 s without calculating @xmath347 ."
  ],
  "abstract_text": [
    "<S> in the random - effects model of meta - analysis a canonical representation of the restricted likelihood function is obtained . </S>",
    "<S> this representation relates the mean effect and the heterogeneity variance estimation problems . </S>",
    "<S> an explicit form of the variance of weighted means statistics determined by means of a quadratic form is found . </S>",
    "<S> the behavior of the mean squared error for large heterogeneity variance is elucidated . </S>",
    "<S> it is noted that the sample mean is not admissible nor minimax under a natural risk function for the number of studies exceeding three . </S>"
  ]
}