{
  "article_text": [
    "insurance cash flows are valued using the risk - free yield curve .",
    "first , today s yield curve needs to be estimated from government bonds , swap rates and corporate bonds and , second , future yield curves then need to be predicted .",
    "this prediction is a complex task because , in general , it involves the forecast of infinite dimensional random vectors and/or random functions . in the present paper",
    "we tackle the problem of yield curve prediction using a non - parametric approach , which is based on ideas presented in ortega et al .",
    "in contrast to @xcite we are heading for long term predictions as needed in insurance industry .",
    "assume @xmath0 denotes time in years .",
    "choose @xmath1 and denote , at time @xmath2 , the price of the ( default - free ) zero coupon bond ( zcb ) that pays one unit of currency at maturity date @xmath3 by @xmath4 .",
    "the yield curve at time @xmath2 for maturity dates @xmath1 is then given by the continuously - compounded spot rate defined by @xmath5    * aim and scope . *    model stochastically the yield curves @xmath6 for future dates @xmath7 such that :    \\(i ) the model is free of arbitrage ;    \\(ii ) explains past yield curve observations ;    \\(iii ) allows to predict the future yield curve development .",
    "in contrast to standard literature on prediction of yield curves we insist that models should be free of arbitrage .",
    "this requirement is crucial when it comes to the prediction of highly correlated prices as it is the case for interest rates .",
    "otherwise it is possible to `` artificially '' shift p&l distributions .",
    "more precisely , if a prediction model admits arbitrage then implementing this arbitrage portfolio yields an always positive p&l . in practice adding such an arbitrage portfolio can then be used to shift p&l distributions of general portfolios , which is an undesired effect from the point of view of valuation and risk management , see figure [ arbitrage ] and section [ sec.arbitrage ] .",
    "* organization of the paper .",
    "* the remainder of the paper is organized as follows : in section 2 we propose our discrete time model for ( discretized ) yield curve evolution . in section 3",
    "we describe the ubiquitous no arbitrage conditions for our modeling setup . in section 4",
    "we describe the actual calibration procedure and in section 5 we present a concrete calibration to real market data .",
    "choose a fixed grid size @xmath8 for @xmath9 .",
    "we consider the discrete time points @xmath10 and the maturity dates @xmath11 .",
    "for example , the choice @xmath12 corresponds to a yearly grid , @xmath13 to a quarterly grid , @xmath14 to a monthly grid , @xmath15 to a weekly grid and @xmath16 to a business days grid .       the filtered probability space is denoted by @xmath17 with real world probability measure @xmath18 and ( discrete time ) filtration @xmath19 .",
    "we assume that the zcbs exist at all time points @xmath20 for all maturity dates @xmath21 with times to maturity @xmath22 .",
    "thus , we can consider the discrete time yield curves @xmath23 for all time points @xmath24 .",
    "assume that @xmath25 is @xmath26-adapted , that is , @xmath27 is observable at time @xmath2 and this information is contained in the @xmath28-field @xmath29 .",
    "our aim is ( as described above ) to model and predict @xmath30 .",
    "we assume that there exists an equivalent martingale measure @xmath31 for the bank account numeraire discount @xmath32 and , in a first step , we describe @xmath30 directly under this equivalent martingale measure @xmath33 .",
    "notice here that the bank account numeraire is actually a discrete time roll - over portfolio , as will be seen in the next section",
    ".       * remark . *",
    "the assumption that the yield curve is given at any moment @xmath34 for sufficiently many maturities is a very strong one . in practice",
    "the yield curve is inter- and extrapolated every day from quite different traded quantities like coupon bearing bonds , swap rates , etc .",
    "this inter- and extrapolation allows for a lot of freedom , often parametric families are used , e.g.  the nelson - siegel @xcite or the svensson @xcite family , but also non - parametric approaches such as splines are applied ( see filipovi @xcite ) .",
    "assume the initial yield curve @xmath35 at time @xmath36 is given . for @xmath37",
    "we make the following model assumptions : assume there exist deterministic functions @xmath38 and @xmath39 such that the yield curve has the following stochastic representation @xmath40 where the innovations @xmath41 are @xmath29-measurable and independent of @xmath42 under @xmath33 . in general , the innovations @xmath41 are multivariate random vectors and the last product in needs to be understood in the inner product sense",
    ".       * remark .",
    "* the first two terms on the right - hand side of will exactly correspond to the no - arbitrage condition in a deterministic interest rate model ( see ( 2.2 ) in filipovi @xcite ) .",
    "the fourth term on the right - hand side of described by @xmath43 adds the stochastic part to the future yield curve development .",
    "finally , the third term @xmath44 will be recognized as a heath - jarrow - morton @xcite ( hjm ) term that makes the stochastic model free of arbitrage .",
    "this term is going to be analyzed in detail in lemma [ hjm yield condition ] below .",
    "this approach allows us to separate conceptually the task of estimating volatilities , i.e.  estimating @xmath45 , and estimating the market price of risk , i.e.  the difference of @xmath46 and @xmath47 .",
    "assumption implies for the price of the zcb at time @xmath2 with time to maturity @xmath48 @xmath49 in order to determine the hjm term @xmath44 we define the discrete time bank account value for an initial investment of 1 as follows : @xmath50 and for @xmath51 @xmath52 the process @xmath53 considers the roll over of an initial investment 1 into the ( discrete time ) bank account with grid size @xmath54 .",
    "note that @xmath55 is previsible , i.e.  @xmath56 is @xmath42-measurable for all @xmath51 .",
    "absence of arbitrage is now expressed in terms of the following @xmath57-martingale property ( under the assumption that all the conditional expectations exist ) .",
    "we require for all @xmath58 @xmath59~\\stackrel{!}{=}~ b_{t-\\delta}^{-1}~ p(t-\\delta , t+m).\\ ] ] the necessity of such a martingale property is due to the fundamental theorem of asset pricing ( ftap ) derived in delbaen - schachermayer @xcite . for notational convenience we set @xmath60 = \\e^\\ast\\left[\\left.\\cdot \\right|{\\cal f}_t\\right]$ ] for @xmath24 .",
    "the no - arbitrage condition immediately provides the following lemma .",
    "[ hjm yield condition ] under the above assumptions the absence of arbitrage condition implies @xmath61.\\ ] ]    this solves item ( i ) of the aim and scope list .",
    "we rewrite as follows ( where we use assumption of the yield curve development and the appropriate measurability properties ) @xmath62 ~=~ p ( t-\\delta , t)~ \\e^\\ast_{t-\\delta } \\left [ p(t , t+m ) \\right ] \\\\ & & = ~p(t-\\delta , t+m)~\\exp \\left\\{- { \\alpha}_\\delta(t , m,(\\mathbf{y}_s)_{s\\le t-\\delta } ) \\right\\ } \\e^\\ast_{t-\\delta } \\left [ \\exp \\left\\{- \\mathbf{v}_\\delta(t , m,(\\mathbf{y}_s)_{s\\le t-\\delta})~ \\boldsymbol{\\varepsilon}^\\ast_t   \\right\\ } \\right]\\\\ & & \\stackrel{!}{=}~p(t-\\delta , t+m).\\end{aligned}\\ ] ] solving this requirement proves the claim of lemma [ hjm yield condition ] .",
    "we need to discuss the choices @xmath63 and @xmath41 as well as the description of the equivalent martingale measure @xmath64 .",
    "then , the model and the prediction is fully specified through lemma [ hjm yield condition ] .",
    "assume we would like to study a finite set @xmath65 of times to maturity .",
    "we specify below necessary properties of @xmath66 for yield curve prediction . for these times to maturity choices we define for @xmath51 @xmath67 that is , in contrast to @xmath68 the random vectors @xmath69 and @xmath70 only consider the times to maturity @xmath48 and @xmath71 for @xmath72 .",
    "note that @xmath70 is @xmath42-measurable and @xmath69 is @xmath73-measurable .",
    "our aim is to model the change from @xmath70 to @xmath69 . in view of we",
    "define the vector @xmath74 we set the dimension @xmath75 . for @xmath76",
    "we then choose a @xmath77-dimensional standard gaussian distribution with independent components under the equivalent martingale measure @xmath33 .",
    "* we are aware that the choice of multivariate gaussian innovations @xmath41 is only a first step towards more realistic innovation processes .",
    "however , we believe that already in this model , with suitably chosen estimations of the instantaneous covariance structure , the results are quite convincing  additionally chosen jump structures might even improve the situation .",
    "the independence assumption with respect to the martingale measure is an additional strong assumption which could be weakened .",
    "thus , we re - scale the volatility term with the grid size @xmath54 and assume that at time @xmath2 it only depends on the last observation @xmath78 : define @xmath39 by @xmath79 where the function @xmath80 does not depend on the grid size @xmath54 .",
    "lemma [ hjm yield condition ] implies for these choices for the hjm term @xmath81 = \\frac{\\delta}{2}~ \\left\\| \\boldsymbol{\\sigma}(t , m,\\mathbf{y } _ { t,- } ) \\right\\|^2 .\\ ] ] from we then obtain for @xmath51 and @xmath72 under @xmath33 @xmath82 + \\sqrt{\\delta}~\\boldsymbol{\\sigma}(t , m,\\mathbf{y } _ { t,-})~ \\boldsymbol{\\varepsilon}^\\ast_t.\\ ] ] note that @xmath83 is a @xmath77-dimensional process , thus , we need a @xmath77-dimensional gaussian random vector @xmath76 for obtaining full rank and no singularities .",
    "next , we specify explicitly the @xmath77-dimensional function @xmath80 . we proceed similar to ortega et al .",
    "@xcite , i.e.  we directly model volatilities and return directions .",
    "assume that for every @xmath84 there exists an invertible and linear map @xmath85 in the sequel we identify the linear map @xmath86 with the corresponding ( invertible ) matrix @xmath87 which generates this linear map , i.e.  @xmath88 .",
    "in the next step , we choose vectors @xmath89 and define the matrix @xmath90\\in \\r^{d\\times d}$ ] .",
    "moreover , for @xmath84 we set @xmath91 using vector form we make the following model specification for :    [ model assumptions 1 ] we choose the following model for the yield curve at time @xmath51 with time to maturity dates @xmath66 : @xmath92 + \\sqrt{\\delta}~ \\varsigma({\\mathbf{y}_{t , -}})~{\\lambda }   ~ \\boldsymbol{\\varepsilon}_{t}^\\ast,\\ ] ] with @xmath93 and @xmath94 denotes the @xmath77-dimensional vector that contains the diagonal elements of the matrix @xmath95 .    for the @xmath96-th maturity @xmath97",
    "we have done the following choice @xmath98_j~ { \\varepsilon}^\\ast_{t , i}.\\ ] ] the linear map @xmath99 describes the _ volatility scaling factors _ , @xmath89 specify the _ return directions _ , and the volatility choice does not depend on the grid size @xmath54 .",
    "our aim is to calibrate these terms .",
    "* remark.*[remark1 ] the volatility scaling factors @xmath99 mimic how volatility for different maturities scales with the level of yield at this maturity .",
    "several approaches have been discussed in the literature .",
    "the choice of a square - root dependence seems to be quite robust over different maturities and interest rate regimes , but for small rates  as we face it for the swiss currency chf ",
    "linear dependence seems to be a good choice , too , see choice .",
    "[ lemma 3.2 ] under model assumptions [ model assumptions 1 ] , the random vector @xmath100 has a @xmath77-dimensional conditional gaussian distribution with the first two conditional moments given by @xmath101&= &   \\delta\\left[-\\mathbf{y}(t-\\delta , t)+\\frac{1}{2 } ~{\\rm sp}(\\sigma_{\\lambda } ( { \\mathbf{y}_{t , - } } ) ) \\right],\\\\ { \\rm cov}^\\ast_{t-\\delta } \\left ( \\boldsymbol{\\upsilon}_t\\right)&= & \\delta ~ \\sigma_{\\lambda }   ( { \\mathbf{y}_{t , -}}).\\end{aligned}\\ ] ]      in order to calibrate our model we need to choose the volatility scaling factors @xmath99 and we need to specify the return directions @xmath89 which provide the matrix @xmath102 . in fact we do not need to specify the direction @xmath89 themselves , but rather @xmath103 , which we shall do in the sequel .",
    "assume we have observations @xmath104 , @xmath105 , and @xmath106 .",
    "we use these observations to predict / approximate the random vector @xmath107 at time @xmath108 .",
    "for @xmath84 we define the matrices @xmath109_j \\right)_{j=1,\\ldots , d ; ~k=1 , \\ldots , k}\\in \\r^{d\\times k},\\\\ s_{(k)}(\\mathbf{y})&= & \\varsigma(\\mathbf{y})~ c_{(k)}~c'_{(k)}~\\varsigma'(\\mathbf{y})\\in \\r^{d\\times d}.\\end{aligned}\\ ] ] choose @xmath110 .",
    "note that @xmath111 is @xmath42-measurable .",
    "for @xmath112 we define the @xmath77-dimensional random vector @xmath113 with @xmath114 is independent of @xmath42 , @xmath29-measurable , independent of @xmath41 and a @xmath115-dimensional standard gaussian random vector with independent components under @xmath33 .",
    "[ lemma 3.3 ] the random vector @xmath116 has a @xmath77-dimensional gaussian distribution with the first two conditional moments given by @xmath117&= & - \\delta~\\mathbf{x}+\\frac{1}{2}~ { \\rm sp}\\left(s_{(k)}(\\mathbf{y})\\right),\\\\ { \\rm cov}^\\ast_{t-\\delta } \\left ( \\boldsymbol{\\kappa}_t\\right)&= & s_{(k)}(\\mathbf{y}).\\end{aligned}\\ ] ]    our aim is to show that the matrix @xmath118 is an appropriate estimator for @xmath119 and then lemmas [ lemma 3.2 ] and [ lemma 3.3 ] say that @xmath120 is an appropriate stochastic approximation to @xmath121 , conditionally given @xmath42 .       * remark . * the random vector @xmath120 can be seen as a filtered historical simulation where @xmath114 re - simulates the @xmath115 observations which are appropriately historically scaled through the matrix @xmath111 .",
    "we calculate the expected value of @xmath118 under @xmath33 .",
    "choose @xmath122 and define the function @xmath123\\left[-\\mathbf{z}+\\frac{1}{2}{\\rm sp}\\left ( \\sigma_{\\lambda } ( { \\mathbf{y } } ) \\right ) \\right]'\\left(\\varsigma(\\mathbf{y})^{-1}\\right)'.\\ ] ] note that this function does _ not _ depend on the grid size @xmath54 .",
    "lemma [ lemma 3.2 ] then implies that @xmath124~\\e^\\ast_{t-\\delta } \\left [ \\boldsymbol{\\upsilon}_t\\right ] ' \\left(\\varsigma(\\mathbf{y}_{t , -})^{-1}\\right)',\\ ] ] where the left - hand side only depends on @xmath54 through the fact that the yield curve @xmath125 is observed at time @xmath126 , however otherwise it does not depend on @xmath54 ( as a scaling factor ) .",
    "[ theorem unbiased ] under model assumptions [ model assumptions 1 ] we obtain for all @xmath127 and @xmath84 @xmath128 = \\delta~ \\sigma_{\\lambda }   ( \\mathbf{y})+\\delta^2~ \\varsigma(\\mathbf{y } ) \\left(\\frac{1}{k}\\sum_{k=1}^k \\e^\\ast_{0}\\left [ f_\\lambda(\\mathbf{y}(\\delta(k-1),\\delta k),\\mathbf{y}_{\\delta k , -})\\right ] \\right )   \\varsigma(\\mathbf{y})'.\\ ] ]    * interpretation . * using @xmath118 as estimator for @xmath129 provides , under @xmath130 , a bias given by @xmath131 \\right )   \\varsigma(\\mathbf{y})'.\\ ] ] if we choose @xmath132 fixed and assume that the term in the bracket is uniformly bounded for @xmath133 then we see that @xmath134 = \\delta~ \\sigma_{\\lambda }   ( \\mathbf{y})+\\delta^2 ~o(\\mathbf{1}),\\qquad \\text { for } \\delta\\to 0.\\ ] ] that is , for small grid size @xmath54 the second term should become negligible .       the only term that still needs to be chosen is the invertible and linear map @xmath135 , i.e.  the volatility scaling factors . for @xmath136",
    "we define that function @xmath137 as already remarked in subsection [ remark1 ] in the literature one often finds the square - root scaling , however for small rates a linear scaling can also be appropriate . for the swiss currency chf it turns out below that the linear scaling is appropriate for a threshold of @xmath138 .",
    "in addition , we define the function @xmath139 as above to guarantee that the processes do not explode for large volatilities and small grid sizes .",
    "assume that there exist constants @xmath140 , then we set for @xmath141 @xmath142 basically , volatility is scaled according to the actual observation @xmath143 .",
    "this choice implies @xmath144_j \\right)_{j=1,\\ldots , d ; ~k=1 , \\ldots , k}\\\\ & = & \\frac{1}{\\sqrt{k}}~ { \\rm diag}(h(y_1),\\ldots ,   h(y_d))~ \\left(\\left [   { \\rm diag}(h(\\mathbf{y}_{\\delta k,-}))^{-1}~ \\boldsymbol{\\upsilon}_{\\delta k}\\right]_j \\right)_{j=1,\\ldots , d ; ~k=1 , \\ldots , k},\\end{aligned}\\ ] ] thus , the constants @xmath140 do not need to be estimated because they are already ( implicitly ) contained in the observations and , hence , in @xmath102 .",
    "therefore , we set them to 1 and we choose @xmath145 these assumptions now allow to directly analyze the bias term given in . therefore , we need to evaluate the function @xmath146 in theorem [ theorem unbiased ]",
    ". however , to this end we would need to know @xmath147 , i.e.  we obtain from theorem [ theorem unbiased ] an implicit solution ( quadratic form ) that can be solved for @xmath147 .",
    "we set @xmath148 and then obtain from theorem [ theorem unbiased ] @xmath149 & = & \\sigma_{\\lambda }   ( \\mathbf{1})+\\delta   \\left(\\frac{1}{k}\\sum_{k=1}^k \\e^\\ast_{0}\\left [ f_\\lambda(\\mathbf{y}(\\delta(k-1),\\delta k),\\mathbf{y}_{\\delta k , -})\\right ] \\right).\\end{aligned}\\ ] ] note that @xmath150 , thus under its elements are given by @xmath151 , @xmath152 , where we have defined @xmath153 .",
    "let us first concentrate on the diagonal elements , i.e.  @xmath154 , and assume that time to maturity @xmath155 corresponds to index @xmath156 .",
    "@xmath157\\right)_{ii } & = & s_{ii}+ \\frac{\\delta}{k}\\sum_{k=1}^k \\bigg ( \\e^\\ast_{0}\\left [ \\left(\\frac{y(\\delta(k-1),\\delta k ) } { h(y(\\delta(k-1),\\delta k+m_i))}\\right)^2\\right ] \\\\ & & + ~\\frac{1}{4 } \\e^\\ast_{0}\\left[h(y(\\delta(k-1),\\delta k+m_i))^2\\right]s^2_{ii } -\\e^\\ast_{0}\\left[y(\\delta(k-1),\\delta k)\\right]s_{ii}\\bigg).\\end{aligned}\\ ] ] this is a quadratic equation that can be solved for @xmath158 . define @xmath159,\\\\ \\label{b calculation } b&= & 1- \\frac{\\delta}{k}\\sum_{k=1}^k\\e^\\ast_{0}\\left[y(\\delta(k-1),\\delta k)\\right ] , \\\\ \\label{c_i calculation } c_i&= & -\\delta^{-1}\\left ( \\e^\\ast_{0}\\left[{s_{(k)}(\\mathbf{1})}\\right]\\right)_{ii } + \\frac{\\delta}{k}\\sum_{k=1}^k \\e^\\ast_{0}\\left [ \\left(\\frac{y(\\delta(k-1),\\delta k ) } { h(y(\\delta(k-1),\\delta k+m_i))}\\right)^2\\right],\\end{aligned}\\ ] ] then we have @xmath160 which provides the solution @xmath161 thus , the bias terms of the diagonal elements are given by @xmath162\\right)_{ii } -s_{ii},\\ ] ] which we are going to analyze below for the different maturities @xmath163 . for the off - diagonals @xmath164 and the corresponding maturities @xmath155 and",
    "@xmath165 we obtain @xmath166\\right)_{ij } & = & s_{ij}+ \\frac{\\delta}{k}\\sum_{k=1}^k \\bigg ( \\e^\\ast_{0}\\left [ \\frac{y(\\delta(k-1),\\delta k ) } { h(y(\\delta(k-1),\\delta k+m_i ) ) } \\frac{y(\\delta(k-1),\\delta k ) } { h(y(\\delta(k-1),\\delta k+m_j ) ) } \\right ] \\\\\\nonumber & & \\qquad + \\frac{1}{4 } \\e^\\ast_{0}\\left[h(y(\\delta(k-1),\\delta k+m_i ) ) h(y(\\delta(k-1),\\delta k+m_j))\\right ] s_{ii}s_{jj}\\\\&&\\label{s_ij calculation } \\qquad -\\frac{1}{2}\\e^\\ast_{0}\\left[y(\\delta(k-1),\\delta k ) \\frac{y(\\delta(k-1),\\delta k+m_i ) } { h(y(\\delta(k-1),\\delta k+m_j))}\\right]s_{ii } \\\\&&\\nonumber \\qquad -\\frac{1}{2}\\e^\\ast_{0}\\left[y(\\delta(k-1),\\delta k ) \\frac{y(\\delta(k-1),\\delta k+m_j ) } { h(y(\\delta(k-1),\\delta k+m_i ) ) } \\right]s_{jj } \\bigg).\\end{aligned}\\ ] ] this can easily be solved for @xmath167 for given @xmath158 and @xmath168 .",
    "for the time - being we assume that @xmath169 , i.e.  we assume that the market price of risk is identical equal to 0 .",
    "this simplifies the calibration and as a consequence we can directly work on the observed data .",
    "the choice of the drift term will be discussed below .",
    "the first difficulty is the choice of the data .",
    "the reason therefore is that risk - free zcbs do _ not _ exist and , thus , the risk - free yield curve needs to be estimated from data that has different spreads such as a credit spread , a liquidity spread , a long - term premium , etc .",
    "we calibrate the model to the swiss currency chf . for short times to maturity",
    "( below one year ) one typically chooses either the libor ( london interbank offered rate ) or the sar ( swiss average rate ) , see jordan @xcite , as ( almost ) risk - free financial instruments .",
    "the libor is the rate at which highly - credit banks borrow and lend money at the inter - bank market .",
    "the sar is a rate determined by the swiss national bank at which highly - credited institutions borrow and lend money with securization .",
    "we display the yields of these two financial time series for instruments of a time to maturity of 3 months , see figure [ figure 1 ] .",
    "we see that the sar yield typically lies below the libor yield ( due to securization ) . therefore , we consider the sar to be less risky and we choose it as approximation to a risk - free financial instrument with short time to maturity .    for long times to maturity ( above one year ) one either chooses government bonds ( of sufficiently highly rated countries ) or swap rates . in figure",
    "[ figure 2 ] we give the time series of the swiss government bond and the chf swap yields both for a time to maturity of 5 years .",
    "we see that the rate of the swiss government bond is below the swap rate ( due to lower credit risk and maybe an illiquidity premium coming from a high demand ) and therefore we choose swiss government bonds as approximation to the risk - free yield curve data for long times to maturity .",
    "we mention that these short terms and long terms data are not completely compatible which may give some difficulties in the calibration .",
    "we will also see this in the correlation matrices below .",
    "thus , for our analysis we choose the sar for times to maturity @xmath170 and the swiss government bond for times to maturity @xmath171 .",
    "we choose time grid @xmath172 ( i.e.  a weekly time grid ) and then we calculate @xmath121 for our observations . note",
    "that we can not directly calculate @xmath173 for all @xmath72 because we have only a limited set of observed times to maturity .",
    "therefore , we make the following interpolation : assume @xmath174 $ ] for @xmath175 , then approximate @xmath176 in figure [ figure 3 ] we give the time series of these estimated @xmath177 and in figure [ figure 4 ] we give the component - wise ordered time series obtained from @xmath178 .",
    "we observe that the volatility is increasing in the time to maturity due to scaling with time to maturity .",
    "using we calculate @xmath179_j \\right)_{j=1,\\ldots , d ; ~k=1 , \\ldots , k}\\in \\r^{d\\times k}\\ ] ] for our observations . in figures",
    "[ figure 5 ] and [ figure 6 ] we plot the time series @xmath180 and @xmath181_m= \\upsilon_{t , m}/h(y(t-\\delta , t+m))$ ] for illustrative purposes only for maturities @xmath182 and @xmath183 .",
    "we observe that the scaling @xmath184 gives more stationarity for short times to maturity , however in financial stress periods it substantially increases the volatility of the observations , see figure [ figure 5 ] . for longer times to maturity",
    "one might discuss or even question the scaling because it is less obvious whether it is needed , see figure [ figure 6 ] .",
    "next figures will show that this scaling is also needed for longer times to maturity .",
    "we then calculate the observed matrix @xmath185 as a function of the number of observations @xmath115 ( we set @xmath186 ) .",
    "moreover , we calculate the bias correction terms given in - where we simply replace the expected values on the right - hand sides by the observations . formulas - then provide the estimates @xmath187 for @xmath167 as a function of the number of observations @xmath115 .",
    "the bias correction term is estimated by @xmath188 we expect that for short times to maturity the bias correction term is larger due to more dramatic drifts .",
    "the results for selected times to maturity @xmath189 are presented in figures [ figure 7]-[figure 11 ] .",
    "let us comment these figures :    * times to maturity in the set @xmath190 look similar to @xmath182 ( figure [ figure 7 ] ) ; @xmath191 corresponds to figure [ figure 8 ] ; times to maturity in the set @xmath192 look similar to @xmath193 ( figures [ figure 9]-[figure 10 ] ) ; times to maturity @xmath194 look similar to @xmath195 ( figure [ figure 11 ] ) .",
    "* times to maturity in @xmath196 seem to have converged , for @xmath197 the convergence picture is distorted by the last financial crisis , where volatilities relative to yields have substantially increased , see also figure [ figure 5 ] .",
    "one might ask whether during financial crisis we should apply a different scaling ( similar to regime switching models ) . for @xmath198",
    "the convergence picture suggest that we should probably study longer time series ( or scaling should be done differently ) .",
    "concluding , this supports the choice of the function @xmath199 in .",
    "only long times to maturity @xmath200 might suggest a different scaling .",
    "* for times to maturities in @xmath201 we observe that the bias term given in is negligible , see figures [ figure 9]-[figure 11 ] , that is , @xmath202 is sufficiently small for times to maturity @xmath203 . for times to maturities in @xmath204",
    "it is however essential that we do a bias correction , see figure [ figure 7]-[figure 8 ] .",
    "this comes from the fact that for small times to maturity the bias term is driven by @xmath205 in @xmath206 which then is of similar order as @xmath158 .    in table",
    "[ table 1 ] we present the resulting estimated matrix @xmath207 which is based on all observations in @xmath208 .",
    "we observe that the diagonal @xmath209 is an increasing function in the time to maturity @xmath155 .",
    "therefore , in order to further analyze this matrix , we normalize it as follows ( as a correlation matrix ) @xmath210 now all the entries @xmath211 live on the same scale and the result is presented in figure [ figure 12 ] .",
    "we observe two different structures , one for times to maturity less than 1 year , i.e.  @xmath212 , and one for times to maturity @xmath213 .",
    "the former times to maturity @xmath214 were modeled using the observations from the sar , the latter @xmath215 with observations from the swiss government bond .",
    "this separation shows that these two data sets are not completely compatible which gives some , , additional independence  ( diversification ) between @xmath216 and @xmath217 .",
    "if we calculate the eigenvalues of @xmath218 we observe that the first 5 eigenvalues explain 95% of the total observed cross - sectional volatility ( we have a @xmath219 dimensional space ) .",
    "thus , a principal component analysis says that we should at least choose a 5-factor model .",
    "these are more factors than typically stated in the literature ( see brigo - mercurio @xcite , section 4.1 ) .",
    "the reason therefore is again that the short end @xmath216 and the long end @xmath217 of the estimated yield curve behave more independently due to different choices of the data ( see also figure [ figure 12 ] ) .",
    "if we restrict this principal component analysis to @xmath217 we find the classical result that a 3-factor model explains 95% of the observed cross - sectional volatility .",
    "in the next step we analyze the assumption of the independence of @xmath220 from the grid size @xmath54 .",
    "similar to the analysis above we estimate @xmath221 for the grid sizes @xmath222 ( weekly , bi - weekly , 4-weekly , quarterly grid size ) .",
    "the first observation is that the bias increases with increasing @xmath54 ( for illustrative purposes one should compare figure [ figure 9 ] with @xmath223 and @xmath172 and figure [ figure 9_3 ] with @xmath223 and @xmath224 ) .",
    "of course , this is exactly the result expected .    in table",
    "[ table 2 ] we give the differences between the estimated matrices @xmath207 on the weekly grid @xmath172 versus the estimates on a quarterly grid @xmath225 ( relative to the estimated values on the quarterly grid ) .",
    "of course , we can only display these differences for times to maturity @xmath226 because in the latter model the times to maturity in @xmath227 do not exist .",
    "we observe rather small differences within @xmath217 which supports the independence assumption from the choice of @xmath54 within the swiss government bond yields .",
    "for the sar in @xmath197 this picture does not entirely hold true which has also to do with the fact that the model does not completely fit to the data , see figure [ figure 8 ] .",
    "thus , we only observe larger difference for covariances that have a bigger difference in times to maturity compared .",
    "the pictures for @xmath228 are quite similar which justify our independence choice .",
    "[ conclusions ]    we conclude that the independence assumption of @xmath221 from @xmath54 is not violated by our observations and that the bias terms @xmath229 are negligible for maturities @xmath230 and time grids @xmath231 , therefore we can directly work with model to predict future yields for times to maturity in @xmath217 .      in this subsection we back - test our model against the observations .",
    "we therefore choose a fixed - term annuity with nominal payments of size 1 at maturity dates @xmath232 .",
    "the present value of this annuity at time @xmath2 is given by @xmath233 our back - testing setup is such that we try to predict @xmath234 based on the observations @xmath235 and then ( one period later ) we compare this forecast with the realization of @xmath234 . in view of conclusions [ conclusions ]",
    "we directly work with @xmath111 for small time grids @xmath54 ( for @xmath110 ) .",
    "moreover , the taylor approximation @xmath236 to @xmath237 is used in order to avoid ( time - consuming ) simulations . here",
    "a first order taylor expansion is sufficient since the portfolio s variance will be  due to high positive correlation ",
    "quite large in comparison to possible second order  drift like  correction terms .",
    "such an approximation does not work for short - long portfolios .",
    "for the approximation ( under @xmath33 ) @xmath238 we obtain an approximate forecast to @xmath236 given by ( denote the cardinality of @xmath239 by @xmath240 ) @xmath241 where @xmath242 .",
    "thus , the conditional distribution of @xmath243 under @xmath33 , given @xmath42 , is a gaussian distribution with conditional mean and conditional variance given by @xmath244 we calculate these conditional moments for @xmath245 based on the @xmath28-fields @xmath42 generated by the data in @xmath246 , for @xmath247 ( weekly and monthly grid ) . from these",
    "we can calculate the observable residuals @xmath248 the sequence of these observable residuals should approximately look like an i.i.d .",
    "standard gaussian distributed sequence .",
    "the result for @xmath172 is given in figure [ residuals 1 ] and for @xmath249 in figure [ residuals 2 ] .",
    "at the first sight this sequence @xmath250 seems to fulfill these requirements , thus the out - of - sample back - testing provides the required results . in figure [ qq plot ]",
    "we also provide the q - q - plot for the residuals @xmath250 against the standard gaussian distribution for @xmath251 .",
    "also in this plot we observe a good fit , except for the tails of the distribution .",
    "this suggests that one may relax the gaussian assumption on @xmath252 by a more heavy - tailed model ( this can also be seen in figure [ residuals 1 ] where we a few outliers ) .",
    "we have already mentioned this in section [ modelling_na ] but for this exposition we keep the gaussian assumption .    if we calculate the auto - correlation for time lag @xmath54 between the residuals @xmath253 we obtain 5% which is a convincingly small value .",
    "this supports the assumption having independent residuals .",
    "the same holds true if we consider the auto - correlation for time lag @xmath54 between the absolute values @xmath254 of the residuals resulting in 11% . the only observation which may contradict the i.i.d .",
    "assumption is that we observe slight clustering in figure [ residuals 1 ] .",
    "this non - stationarity might have to do with that we calculate the residuals under the equivalent martingale measure @xmath33 , however we make the observations under the real world probability measure @xmath18 .",
    "if these measures coincide the statements are the same .",
    "the classical approach is that one assumes that the two probability measures are equivalent , i.e.  @xmath31 , with density process @xmath255 with @xmath256 is independent of @xmath42 , @xmath73-measurable and a @xmath257-dimensional standard gaussian random vector with independent components under @xmath18 .",
    "moreover , it is assumed that @xmath258 is @xmath77-dimensional and previsible , i.e.  @xmath42-measurable .",
    "note that this density process @xmath259 is a strictly positive and normalized @xmath260-martingale . for any @xmath33-integrable and @xmath29-measurable random variable @xmath261 we have , @xmath18-a.s .",
    ", @xmath262= \\frac{1}{\\xi_{t-\\delta}}~\\e_{t-\\delta } \\left[\\xi_t x_t\\right].\\ ] ] this implies that @xmath263 @xmath258 is called market price of risk at time @xmath2 and reflects the difference between @xmath264 and @xmath265 . under model assumptions [ model assumptions 1 ] we",
    "then obtain under the real world probability measure @xmath18 @xmath92 + \\sqrt{\\delta}~ \\varsigma({\\mathbf{y}_{t , -}})~{\\lambda }   ~ \\boldsymbol{\\lambda}_{t } + \\sqrt{\\delta}~ \\varsigma({\\mathbf{y}_{t , -}})~{\\lambda }   ~ \\boldsymbol{\\varepsilon}_{t},\\ ] ] i.e.  we have a change of drift given by @xmath266 .",
    "thus , under the ( conditional ) real world probability measure @xmath265 the approximate forecast @xmath243 has a gaussian distribution with conditional mean and conditional covariance given by @xmath267 for an appropriate choice of the market price of risk @xmath258 we obtain residuals @xmath268 which should then form an i.i.d .  standard gaussian distributed sequence under the real world probability measure @xmath18 .",
    "in order to detect the market price of risk term , we look at residuals for individual times to maturity @xmath72 , i.e.  we replace the indicators @xmath269 in by indicators @xmath270 . we denote the resulting residuals by @xmath271 and the corresponding volatilities by @xmath272 . in figures [ maturity 1 ] ,",
    "[ maturity 5 ] and [ maturity 10 ] we show the results for @xmath273 .",
    "the picture is similar to figure [ residuals 1 ] , i.e.  we observe clustering but not a well - defined drift .",
    "this implies that we suggest to set the market price of risk @xmath274 for the prediction of future yield curves ( we come back to this in section [ section vasicek ] ) .",
    "we compare our findings to the results in the vasiek model @xcite .",
    "the vasiek model is the simplest short rate model that provides an affine term structure for interest rates ( see also filipovi @xcite ) , and hence a closed - form solution for zcb prices .",
    "the price of the zcb in the vasiek model takes the following form @xmath275 where the short rate process @xmath276 evolves as an ornstein - uhlenbeck process under @xmath33 , and @xmath277 and @xmath278 are constants only depending on the time to maturity @xmath48 and the model parameters @xmath279 , @xmath280 and @xmath281 ( see for instance ( 3.8 ) in brigo - mercurio @xcite ) .",
    "the short rate @xmath282 is then under @xmath264 normally distributed with conditional mean and conditional variance given by @xmath283 & = & r_{t-\\delta}~e^{-\\delta \\kappa^\\ast } + \\theta^\\ast\\left(1-e^{-\\delta \\kappa^\\ast}\\right),\\\\ { \\rm var}^\\ast_{t-\\delta}(r_t)&= & \\frac{g^2}{2\\kappa^\\ast}\\left[1-e^{-2\\kappa^\\ast\\delta}\\right].\\end{aligned}\\ ] ] thus , the approximation @xmath236 has under @xmath264 a normal distribution with conditional mean @xmath284 = \\sum_{m\\in { \\cal m}_3 }",
    "\\left(1 + a(m ) - \\e^\\ast_{t-\\delta}[r_t ] ~b(m)\\right),\\ ] ] and conditional variance @xmath285 as in the previous section we assume @xmath286 , i.e.  we set the market price of risk @xmath274 : ( i ) this allows to estimate the model parameters @xmath279 , @xmath280 and @xmath281 , for instance , using maximum likelihood methods ( see ( 3.14)-(3.16 ) in brigo - mercurio @xcite ) ; ( ii ) makes the model comparable to the calibration of our model .",
    "we will comment on this `` comparability '' below .",
    "thus we estimate these parameters and obtain parameter estimates @xmath287 , @xmath288 and @xmath289 from which we get the estimated functions @xmath290 and @xmath291 .",
    "this then allows to estimate the conditional mean and variance of @xmath236 , given @xmath42 . from these",
    "we calculate the observable residuals @xmath292 } { \\widehat{{\\rm var}}^\\ast_{t-\\delta}(\\widetilde{\\pi}_t)^{1/2}}.\\ ] ] in figure [ residuals_3 ] we plot the time series @xmath253 and @xmath293 for @xmath294 .",
    "the observation is that @xmath293 is far too small !",
    "the explanation for this observation lies in the assumption @xmath286 , i.e.  @xmath274 .",
    "since the vasiek prices are calculated by conditional expectations of the _ entire _ future development of the short rate @xmath282 until expiry of the zcb , the choice of the market price of risk @xmath258 has a huge influence on the resulting zcb price in the vasiek model .",
    "thus , the calibration of @xmath290 and @xmath295 is completely wrong if we set @xmath274 .",
    "compare @xmath296 conditionally , given @xmath42 , we model the development from @xmath297 to @xmath298 for the study of . that is , we model a change of the yield curve @xmath125 at time @xmath126 to @xmath68 at time @xmath2 .",
    "since the yield curve @xmath125 already corresponds to market prices it already contains the actual market risk aversion , and thus the market price of risk @xmath299 in only influences one single period in our consideration .    the ( pricing )",
    "functions @xmath300 and @xmath301 in , however , are calculated completely within the vasiek model by a forward projection of @xmath282 until maturity date @xmath302 .",
    "if this forward projection is done under the wrong measure @xmath18 , then these pricing components completely miss the market risk aversion and hence are not appropriate .",
    "thus , in general , we should have @xmath303 and @xmath304 which requires a detailed knowledge of the market price of risk @xmath258 and , thus , the vasiek model reacts much more sensitively to non - appropriately calibrated equivalent martingale measures @xmath33 .",
    "note that this is true for all models where zcb prices are entirely determined by the short rate process @xmath276 .",
    "* we conclude that the hjm models ( similar to model assumptions [ model assumptions 1 ] ) are much more robust against inappropriate choices of the market price of risk compared to short rate models , because in the former we only need to choose the market price of risk for the one - step ahead for the prediction of the zcb prices at the end of the period ( i.e.  from @xmath126 to @xmath2 ) whereas for short rate models we need to choose the market price of risk appropriately for the entire life time of the zcb ( i.e.  from @xmath126 to @xmath302 ) . *",
    "our hjm model ( model assumptions [ model assumptions 1 ] ) always captures the actual yield curve , whereas this is not necessarily the case for short rate models .      for the calibration of the model and for yield curve prediction",
    "we have chosen a restricted set @xmath66 of times to maturity . in most applied cases one has to stay within such a restricted set because there do not exist observations for all times to maturity .",
    "we propose that we predict future yield curves within these families @xmath66 and then approximate the remaining times to maturity using a parametric family like the nelson - siegel @xcite or the svensson @xcite family , see also filipovi @xcite .",
    "finally , we demonstrate the absence of arbitrage condition given in lemma [ hjm yield condition ] . at the end of section [ section introduction ]",
    "we have emphasized the importance of the no - arbitrage property of the prediction model .",
    "let us choose an asset portfolio @xmath305 for two different times to maturity @xmath306 and @xmath307 .",
    "we approximate this portfolio by a taylor expansion up to order @xmath308 and set @xmath309 under our model assumptions , the returns of both terms @xmath310 in portfolio @xmath236 have , conditionally given @xmath42 , a gaussian distribution term with standard deviations given by @xmath311 if we choose @xmath312 then the returns of the gaussian parts of both terms in portfolio @xmath236 have the same variance and , thus , under the gaussian assumption have the same marginal distributions .",
    "since the conditional expectation of the second order term in the taylor expansion cancels the no - arbitrage drift term ( up to a small short rate correction ) we see that the returns of the portfolio @xmath313 should provide zero returns conditionally . in figure [ arbitrage ]",
    "we give an example for times to maturity @xmath314 and @xmath315 .",
    "the correlation between the prices of these zcbs is high , about 85% , i.e.  their prices tend to move simultaneously .",
    "the resulting weights @xmath316 are in the range between 1.4 and 1.9 . in figure [ arbitrage ] we plot the aggregated realized gains of the portfolio @xmath317 minus their prognosis including and excluding the hjm correction term . recall that the predicted gains should be zero conditionally on the current information .",
    "we observe that the model without the hjm term clearly drifts away from zero , which opens the possibility of arbitrage .",
    "therefore , we insist on a prediction model that is free of arbitrage .",
    "in the first step we apply the tower property for conditional expectation which decouples the problem into several steps .",
    "we have @xmath318 = \\e^\\ast_0 \\left[\\e^\\ast_{\\delta(k-1)}\\left[s_{(k)}(\\mathbf{y})\\right]\\right]$ ] .",
    "thus , we need to calculate the inner conditional expectation @xmath319 $ ] of the @xmath320 matrix @xmath118 . we define the auxiliary matrix @xmath321_j \\right)_{j=1,\\ldots , d ; ~k=1 , \\ldots , k}\\in \\r^{d\\times k}.\\ ] ] this implies that we can rewrite @xmath322 .",
    "moreover , we rewrite the matrix @xmath323 as follows @xmath324,\\ ] ] with @xmath325 is @xmath326-measurable .",
    "this implies the following decomposition @xmath327 \\left[\\widetilde{c}_{(k-1 ) } , \\varsigma(\\mathbf{y}_{\\delta k,-})^{-1}~ \\boldsymbol{\\upsilon}_{\\delta k } \\right]'\\varsigma(\\mathbf{y})'\\\\ & = & \\frac{1}{k}~ \\varsigma(\\mathbf{y } ) \\left(\\widetilde{c}_{(k-1)}~\\widetilde{c}'_{(k-1 ) } + \\left(\\varsigma(\\mathbf{y}_{\\delta k,-})^{-1}~ \\boldsymbol{\\upsilon}_{\\delta k } \\right ) \\left(\\varsigma(\\mathbf{y}_{\\delta",
    "k,-})^{-1}~ \\boldsymbol{\\upsilon}_{\\delta k } \\right)'\\right)\\varsigma(\\mathbf{y } ) ' \\\\ & = & \\frac{k-1}{k}~s_{(k-1)}(\\mathbf{y } ) + \\frac{1}{k}~ \\varsigma(\\mathbf{y})~ \\varsigma(\\mathbf{y}_{\\delta k,-})^{-1}~ \\boldsymbol{\\upsilon}_{\\delta k}~   \\boldsymbol{\\upsilon}_{\\delta k } ' \\left(\\varsigma(\\mathbf{y}_{\\delta k,-})^{-1}\\right)'~ \\varsigma(\\mathbf{y})'.\\end{aligned}\\ ] ] this implies for the conditional expectation of @xmath118 @xmath328 = \\frac{k-1}{k}~s_{(k-1)}(\\mathbf{y } ) + \\frac{1}{k}~ \\varsigma(\\mathbf{y})~ \\varsigma(\\mathbf{y}_{\\delta k,-})^{-1}~ \\e^\\ast_{\\delta(k-1)}\\left [ \\boldsymbol{\\upsilon}_{\\delta k}~   \\boldsymbol{\\upsilon}_{\\delta k}'\\right ] \\left(\\varsigma(\\mathbf{y}_{\\delta k,-})^{-1}\\right)'~ \\varsigma(\\mathbf{y})'.\\ ] ] we calculate the conditional expectation in the last term , we start with the conditional covariance . from lemma [ lemma 3.2 ]",
    "we obtain @xmath329 this implies @xmath330 & = & \\frac{k-1}{k}~\\e^\\ast_{0}\\left[s_{(k-1)}(\\mathbf{y})\\right]+ \\frac{\\delta}{k}~ \\sigma_{\\lambda } ( \\mathbf{y } ) \\\\ & & + \\frac{1}{k}~ \\varsigma(\\mathbf{y})~ \\e^\\ast_{0}\\left [ \\varsigma(\\mathbf{y}_{\\delta k,-})^{-1}~ \\e^\\ast_{\\delta(k-1)}\\left [ \\boldsymbol{\\upsilon}_{\\delta k}\\right]~   \\e^\\ast_{\\delta(k-1)}\\left[\\boldsymbol{\\upsilon}_{\\delta k}\\right ] ' \\left(\\varsigma(\\mathbf{y}_{\\delta k,-})^{-1}\\right)'\\right]~ \\varsigma(\\mathbf{y})'\\\\ & = & \\frac{k-1}{k}~\\e^\\ast_{0}\\left[s_{(k-1)}(\\mathbf{y})\\right]+ \\frac{\\delta}{k}~ \\sigma_{\\lambda } ( \\mathbf{y } ) + \\frac{\\delta^2}{k}~ \\varsigma(\\mathbf{y})~ \\e^\\ast_{0}\\left [ f_\\lambda(\\mathbf{y}(\\delta(k-1),\\delta k),\\mathbf{y}_{\\delta k , -})\\right]~ \\varsigma(\\mathbf{y})'.\\end{aligned}\\ ] ] iterating this provides the result ."
  ],
  "abstract_text": [
    "<S> we present an arbitrage - free non - parametric yield curve prediction model which takes the full ( discretized ) yield curve as state variable . </S>",
    "<S> we believe that absence of arbitrage is an important model feature in case of highly correlated data , as it is the case for interest rates . furthermore , the model structure allows to separate clearly the tasks of estimating the volatility structure and of calibrating market prices of risk . </S>",
    "<S> the empirical part includes tests on modeling assumptions , back testing and a comparison with the vasiek short rate model . </S>"
  ]
}