{
  "article_text": [
    "the data we processed and analyzed in this study stemmed from norc s computer - assisted telephone interviewing ( cati ) system .",
    "the cati network can automatically retrieve and dial a household phone number from a random sample , drawn from a comprehensive vendor - prepared phone list , so norc can conduct surveys and collect data on topics of public interest , and compute statistics representative of the relevant population .",
    "survey data , traditionally , consist of relatively small samples and are often analyzed by statistical techniques ( wolter 2007 ) .",
    "more recently , as sizes , varieties , and complexities of survey data grow faster than ever , novel machine learning methods especially those applicable to text data are sought after for knowledge discovery and predictive analysis at a large scale ( see murphy et al .",
    "2014 , for instance ) , an example being topic models ( blei et al .  2003 ) applied to cluster survey responses by wang and mulrow ( 2014 ) .",
    "our work here using naive bayes method to classify machine messages is another attempt in such a direction .",
    "the norc cati system is a vendor - developed black box ; we do not have access to the codebase .",
    "it is a distributed system and the infrastructure environment is complex , mostly maintained by norc s information technology department on a daily basis .",
    "the system has a front - end interface running on a web browser with whom an interviewer interacts to initiate , conduct , and complete a phone survey .",
    "there are backend servers that persist important and sometimes personally identifiable data into databases and machine messages into rolling log files . at any moment during a business hour , there is data traffic over our secure network going back and forth among front - end and backend components .",
    "these data are typically text , numeric , voice and image files to and from interactive dynamic webpages called http frames .",
    "the smallest components of network data are known as _",
    "packets_. for the purpose of performance profiling , we collect information from http frames down to the level of packets , as well as machine log files and sql database trace tables .",
    "norc has two large call centers across the u.s .",
    "continent : one is located in chicago , illinois and the other one in las vegas , california . at full capacity , there are as many as  500 interviewers working with multiple application servers and sql databases in chicago .",
    "figure  [ fig : packframe ] is a simplified pictorial representation of norc s distributed cati network .",
    "on june  4 ,  2014 , during a regular business hour , our network and database engineers collected web transactions and packet information on three client machines in our network .",
    "for the three clients , two were in chicago and one was in las vegas ; the configuration was made to gauge the effects of latency , i.e. , the delay in time incurred in transferring data over a long distance .",
    "the http frames and packet data were compressed ( saz , pcap ) files .",
    "we also collected server log files and database trace tables .",
    "for ease of analysis , we decompressed all files and if necessary transformed them into text format . as a result , during that test - data collection hour , we amassed almost  30 gigabytes ( gb ) of data .",
    "it is a potential source of big data coming to norc at high velocity and high volume .",
    "here is a quick summary of our collected machine data :    1 .   raw data ( compressed ) : 1.8 gb ; 267 files . 1 .",
    "http frames : 86.9 mb ( megabytes ) 2 .",
    "packets data : 1.7 gb 3 .",
    "server log : 31.5 mb 4 .",
    "database trace table : 685 mb 2 .",
    "decompressed data ( text ) : 28.9 gb ; 27,785 files .",
    "analysis results ( text ) : 15.7 mb ; 15 files .",
    "we applied various methods for analyzing the datasets for causes of bottleneck performance in the system that sometimes occur during a phone connection process .",
    "in addition , from machine - generated time stamps , we measured the time lapses between comparable web transactions and log messages ; and we learnt about the significant effects of latency ( choi et al .",
    "2014 ) though we will not go into further details . in the rest of this report",
    ", we focus on natural language processing ( nlp ) and machine - learning methods we applied on the collected data .    here is an outline of this report : in section  [ sec : data ] , we detail some of the characteristics and challenges of server log data . in section  [ sec :",
    "model ] , we develop data preprocessing methods , model building process , and performance evaluation criteria .",
    "concrete examples are included for illustration in section  [ sec : ex ] .",
    "lastly , we conclude with a few comments and thoughts of future work in section  [ sec : con ] .",
    "in the absence of dictionary and metadata , we set out to learn about the characteristics of the cati machine language .",
    "in particular , we focused on messages in the collected server log files , one of the four key components of the raw data ( see section  [ intro ] ) . over the server side ,",
    "such communication is of high frequency and is captured in text files .",
    "the messages are usually intended for network administrators and application programmers for performance tuning or problem shooting .",
    "these log messages are lines after lines of records about the internal states of the servers during run - time ( e.g. , key variable values , memory usage ) and traces of interactions and communication of the server with other network components . at times when a server experiences stress due to , say , resource shortage , or not behaving as programmed , it will issue warnings or error messages .",
    "these log events are typically semi - structured , starting with a _ time stamp _ , followed by some text of heterogeneous data , which consist of _ message type _ that may take on values such as fine , debug , info , warning , error , or fatal . sometimes after the message type , we see a few additional _ optional fields _ such as program filename , method name , class name , and line number at which the message is defined .",
    "lastly we have the technical _ content _ of the message event . hence applying nlp techniques and machine learning methods for analysis seems fitting .    in the following log message , ` 20140604 103903.913 `",
    "is the time stamp of the format ` yyyymmdd hhmmss.ttt ` , where ` yyyy ` represents year in four digits ; ` mm ` and ` dd ` for month and day , respectively ; ` hhmmss ` for hour , minutes , and seconds ; ` ttt ` for milliseconds . `",
    "error ` is the message type , which is followed by the message content indicating the occurrence of an undesirable timeout event ( not receiving any or an expected response from a user or a network component within a time window ) :    .... 20140604 103903.913 error : prontoeventserver .",
    "pe_client removed on   duration 8453ms timeout 502ms stacksize 90 ....    in our cati system , message fields are , however , not always standardized , rendering some messages appearing irregular and harder to read than usual by human experts or computer programs .",
    "we give a few examples immediately below for illustration of such difficulties .",
    "each of the message field sometimes has missing or extra components . in this example , the time stamp has no year information and there is an extra slash between the month and the day , followed by a five - digit sequence ( @xmath0 below ) , which is unclear to us what it means .    ....",
    "06/04 142452.865|02488|error | calarmfilter |general |onxmlread >   xml element \" alarms \" is ignored ....    in this example , the optional fields appear after  instead of before  the message content .",
    "their order and formats could appear quite different in other messages .    ....",
    "20140604 063402.441 error : dcb_open(dcbb1d1,null)=success ( # = 0 )   instancename = tdialogicdevice dcbb1d1   classname = tdialogicconferencedevice methodname = initialize filename=.\\dialogicdeviceconference.cpp linenumber=138 ....    among all message types , errors are of particular importance to system administrators or software engineers .",
    "they are the distress signals whereas messages of other types may be considered `` white noise . '' nonetheless , it is not always a straightforward matter to tell whether a message is an error in our cati log files .",
    "example  [ eg2.4 ] below lists some of the abnormal cases we encountered .",
    "[ eg2.4 ] message type in the following log event is ` criticalerror ` , which may , or may not , indicate a more serious kind of error :    .... 20140604 120353.022 criticalerror : report : sql exception : query :   sp_pronto_addagentactivity   ....    in other cases , an error message may have no mention of the word `` error '' anywhere , or the value of message type is missing .",
    "the following are two such examples , where the first one seems to be an error whereas the second one is not :    .... 20140604 144846.946 04776 a:006 line 5 still in dialing mode .",
    "sending error 27 to dial command before ending the session ....    .... 20140604 064238.541 11de6b80 : linecallspecificline(1 ) return   advr_no_error ....    the next example is a message that concludes with `` no error . ''",
    "hence the appearance of the word `` error '' in message content may not necessarily represent an erroneous event :    .... 06/04 145011.634|01384 | debug |dispatcher |l:000 |logmetaeventinfo > e = gcev_answered ( 802h ) : gc_resultinfo()=0h ; gcval=500h , normal   completion ccid=6h , gc_dm3cc_lib ccval=0h , no error   ....",
    "the discussion so far has led to the question , among others , that in the presence of aforementioned or other abnormalities , how a log event could be accurately classified as an error or a non - error .",
    "one approach is to learn about the machine log features associated with known errors and characteristics of recognized non - errors , and then build a model to perform a binary classification of a message of unknown type as an error or not .",
    "we note that the notion of `` error '' here can be generalized to any event of interested outcome that can be annotated by human experts or inferred by computer programs .",
    "the problem of error classification is not necessarily too difficult , but it comes with some challenges for our cati system , to name a few :    1 .",
    "software code is not available for tracing or modification .",
    "2 .   lack of ( updated ) documentation .",
    "the machine language , that is programmers language , in log files is often incomprehensible .",
    "the log messages often contain many unreadable , unnatural variable names and values .",
    "no dictionary or sufficient metadata are available to us for lookup .",
    "the event of interest , error , occurs rarely ( @xmath1 of all events ) because we do have a well - maintained and highly functional production system .",
    "previous works on extensive log analysis include xu ( 2010 ) and xu et al .",
    "( 2010 ) , which apply principal component analysis ( pca ) for anomaly detection and decision trees for visualization .",
    "however , our problem appears to be more onerous due to lack of access to source code .",
    "our analysis consists of seven basic programmatic steps .",
    "the first three steps belong to the domain natural language processing .",
    "the last four steps are related to machine learning ; we repeat them and adjust the input parameters ( @xmath2 , @xmath3 , and @xmath4 below ) if necessary , until the model performance in step  [ s7 ] is satisfactory .    1 .",
    "read every event line of a log file into three fields : time stamp , message type , and message content .",
    "if optional fields such as filename or method name are available , we consider them parts of the message content . to enhance the effectiveness of our reading task , we employ regular expressions in python .",
    "2 .   assign a class to every event by looking at value of message type , i.e. , set an outcome variable ` iserror ` to ` true ` if message type contains the word `` error '' ( case insensitive ) , and ` false ` otherwise .",
    "3 .   reduce all messages into tokens of words .",
    "select top @xmath2 most frequently seen words as features .",
    "5 .   learn on a time - consecutive training set of messages whose size , @xmath3 , is user chosen .",
    "classify a test set of  @xmath4 messages that happened after the training set messages .",
    "[ s7 ] evaluate performance of the prediction model .",
    "our machine - learning method of choice in this study is naive bayes classification  it could have been decision tree , random forest , or other models ; see , for example , han et al .",
    "( 2012 ) for an overview of these methods . here",
    "we give a succinct summary of the naive bayes classifier . given a training dataset @xmath5 and each item @xmath6 s class label @xmath7 .",
    "suppose each @xmath6 has @xmath2 given feature values @xmath8 .",
    "when a new data point @xmath9 with its property values @xmath10 come in , we want to classify it by estimating the probabilities of it belonging to each class @xmath11 given its features .",
    "in particular , when @xmath12 , we have a binary classification problem .",
    "we use the shorthand @xmath13 .",
    "then , by the bayes theorem and assuming class conditional independence , we have @xmath14 product of the probabilities of the item s features given a class and the proportion of the class , both estimated from the training set .",
    "the algorithm simply classifies the new data point to be in class  @xmath15 such that @xmath16 .",
    "note that the quantity @xmath17 in ( [ eqn : naive ] ) can be omitted in the optimization process as it is the same across all classes .",
    "the naive bayes classifier is in practice a very efficient and robust algorithm even when the assumption of conditional independence may not hold for an input dataset ; see , for example , lpez et al .",
    "when at a future time we know for certain about the class true value , @xmath18 , of the data point @xmath9 , we can then compare @xmath18 with the model s previously predicted value  @xmath19 , and update the confusion matrix @xmath20}}$ ] , where @xmath21 and @xmath22 are respectively the true positive and true negative counts , whereas @xmath23 and @xmath24 are the false positive and false negative counts .",
    "note that @xmath25 , the size of test set . we can then proceed to compute the prediction model s accuracy and precision , which are defined as @xmath26 and @xmath27 , respectively , as they are among the most common performance measures for a prediction model ; see , for example , han et al .",
    "( 2012 ) .",
    "we use an open - source python package called natural language toolkit , or nltk in short ; see bird et al .",
    "we started with a simple adaptation of the nltk examples .",
    "unfortunately it resulted in poor accuracy , memory exhaustion , and slow performance .",
    "there are a few strategies in implementation that we have found useful in overcoming the performance problems and generally resulting in better model predictiveness .    1",
    ".   [ p1 ] exclude stop words ( e.g. , prepositions such as `` of '' and `` from '' ) from the features because such frequently seen words are not predictive of errors or non - errors . 2 .   [ p2 ]",
    "change all words to lowercase in tokenization and feature selection processes .",
    "this reduces number of features without sacrificing predictive power of the model .",
    "[ p3 ] exclude numbers from features .",
    "this strategy is found to be helpful in our study but may not always be effective in other cases .",
    "[ p4 ] preallocate a significant number of features for learning from error messages .",
    "we can not emphasize enough that this is the most important and effective strategy of all in our experience .",
    "since error events are rare , features were quickly filled up by non - error content , and consequently the model would not have accumulated enough information about error events , resulting in poor predictive accuracy due to too small values of @xmath28 and @xmath29 in ( [ eqn : naive ] ) .    a common technique that we have not used is simulation or over - sampling of rare events during the training stage so as to increase the values of @xmath30 and @xmath29 .",
    "for a comprehensive discussion of challenges and strategies for learning rare events , we refer readers to a recent review by lpez et al .",
    "in this section , we present two examples . built on nltk ( version  3.0.0 ) , we developed an object - oriented class in python ( version 2.7.10 ) called ` norc_class ` with simple interfaces for reading a text log file ; tokenizing messages with nltk s function ` word_tokenize ( ) ` ; assigning labels ; picking features ; building models mainly based on methods ` train ( ) ` and ` classify_many ( ) ` in the nltk class ` naivebayesclassifier ` ; and last but not least , displaying results .",
    "we built a learning and prediction model with @xmath31 features selected from a training set of size @xmath32 .",
    "the following results show that , on a test set of size @xmath33 , with less than one percent errors , the trained classifier predicted only one error message incorrectly as non - error , given a total of  @xmath34 error events ; that is to say , the prediction model s accuracy was  @xmath35 and its precision was  @xmath36 .",
    "the two most predictive words of errors were `` circuit '' and `` pronto '' .",
    "the absence of the words `` failure '' and `` dialogic '' , or the presence of `` * dlggctelapi '' were most predictive of a non - error event ( we use an asterisk to mask the vendor name ) .    .... len(documents ) = 71210 len(features ) = 562 len(train_set ) = 20000 len(test_set ) = 51210 n_errs = 697 , percentage = 0.98    confusion matrix = [   109      1 ] [ 2340 48760 ] accuracy [ 0 - 1 ] = 0.95 .",
    "precision [ 0 - 1 ] = 0.99   most informative features                   circuit = true           true : false   =   12799.6 : 1.0                    pronto = true           true : false   =     163.4 : 1.0                    failed = false         false : true    =     128.8 : 1.0                  dialogic = false         false : true    =     122.4 : 1.0              * dlggctelapi = true          false : true    =      95.3 : 1.0 ....    in this example , the number of sample messages in the dataset was @xmath37 and about merely one percent were error messages .",
    "the first @xmath38 messages were used to build a naive bayes classifier with @xmath39 features . on the test set consisting of the remaining @xmath40 messages , the model predicted error events at an accuracy of @xmath41 and a precision of @xmath42 .",
    "the most predictive words of error messages were `` exception '' , `` page '' , `` intweb'',``putting '' , and `` list '' .    ....",
    "len(documents ) = 97832 len(features ) = 2000 len(train_set ) = 88049 len(test_set ) = 9783 n_errs = 1117 , percentage = 1.14     confusion matrix = [ 100     2 ] [ 243 9438 ] accuracy [ 0 - 1 ] = 0.97 .",
    "precision [ 0 - 1 ] = 0.98   most informative features                 exception = true            true : false   =    4311.8 : 1.0                      page = true            true : false   =    3569.3 : 1.0                    intweb = true            true : false   =    2141.6 : 1.0                   putting = true            true : false   =    1189.8 : 1.0                      list = true            true : false   =     973.5 : 1.0 ....",
    "we developed systematic ways of collecting and parsing data in norc s distributed cati production network . by examples of event messages in server log files , despite their highly technical nature , we built performant supervised models for classification of rare error .",
    "the key enabling data preprocessing technique here is preallocation of features in memory dedicated to learning most frequently seen words of rare event messages .    for future work",
    ", we shall continue to refine and automate the naive bayes classification model , making it incremental and with less memory and computational requirements .",
    "we could employ more robust techniques such as @xmath43-fold cross validation and roc curves for model quality evaluation ( han et al .",
    "when the work is mature , we could port our prototype to hadoop or spark servers for large - scale ( near ) real - time analysis .",
    "we may also adapt our model to predict other events of business interests such as long wait time before a call is connected or delays in inbound calls .",
    "lastly , it would be valuable to predict occurrence of a positive event _ in advance_. our preliminary models that learnt about each example as a brief time window of messages unfortunately yielded low accuracy ( around the value of 0.6 ) .",
    "the approach was not effective probably because many attributes from events leading up to errors became intermixed with those associated with non - errors  better models have yet to be developed .",
    "we thank the inputs and feedback from our colleagues at norc : kennon copeland , rick kelly , matt krump , robert montgomery , edward mulrow , josh seeger , benjamin skalland , sean ware , kirk wolter , patrick van kessel , patrick zukosky , as well as members of norc s telephone surveys and support operations , social media analytics group , and last but not least , the innovation days committee .",
    "any mistakes in the paper are however ours to own ."
  ],
  "abstract_text": [
    "<S> this is a machine learning application paper involving big data . </S>",
    "<S> we present high - accuracy prediction methods of rare events in semi - structured machine log files , which are produced at high velocity and high volume by norc s computer - assisted telephone interviewing ( cati ) network for conducting surveys . </S>",
    "<S> we judiciously apply natural language processing ( nlp ) techniques and data - mining strategies to train effective learning and prediction models for classifying uncommon error messages in the log  without access to source code , updated documentation or dictionaries . in particular , our simple but effective approach of features preallocation for learning from imbalanced data coupled with naive bayes classifiers can be conceivably generalized to supervised or semi - supervised learning and prediction methods for other critical events such as cyberattack detection .    </S>",
    "<S> big data , imbalanced data , rare events , natural language processing , machine learning    _ we dedicate this article to fritz scheuren , asa fellow and former asa president , + on the occasion of his 75th birthday . _ </S>"
  ]
}