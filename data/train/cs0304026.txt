{
  "article_text": [
    "a @xmath0-uniform hypergraph @xmath6 consists of a set of vertices @xmath7 and a collection @xmath8 of @xmath0-element subsets of @xmath7 called hyperedges .",
    "vertex cover _ of @xmath9 is a subset @xmath10 such that every hyperedge in @xmath8 intersects @xmath11 , i.e. , @xmath12 for each @xmath13 .",
    "independent set _ in @xmath14 is a subset whose complement is a vertex cover , or in other words a subset of vertices that contains no hyperedge entirely within it .",
    "the e@xmath0-vertex - cover problem is the problem of finding a minimum size vertex cover in a @xmath0-uniform hypergraph .",
    "this problem is alternatively called the minimum hitting set problem with sets of size @xmath0 ( and is equivalent to the set cover problem where each element of the universe occurs in exactly @xmath0 sets ) .    the e@xmath0-vertex - cover",
    "problem is a fundamental np - hard optimization problem which arises in numerous settings . for @xmath15 , it is just the famous vertex cover problem on graphs .",
    "owing to its np - hardness , one is interested in how well it can be approximated in polynomial time .",
    "a very simple algorithm that is invariably taught in a typical undergraduate algorithms class is the following : greedily pick a maximal set of pairwise disjoint hyperedges and then include all vertices in the chosen hyperedges in the vertex cover .",
    "it is easy to show that this gives a factor @xmath0 approximation algorithm for e@xmath0-vertex - cover .",
    "state of the art techniques yield only a tiny improvement , achieving a @xmath16 approximation ratio @xcite .",
    "this raises the question whether achieving an approximation factor of @xmath17 for any constant @xmath3 could be np - hard .    in this paper",
    ", we prove a nearly tight hardness result for e@xmath0-vertex - cover . specifically , we prove that e@xmath0-vertex - cover  is indeed np - hard to approximate within factor @xmath1 for any @xmath18 , thus explaining why no efficient algorithm with performance guarantee much better than @xmath0 has been found .",
    "the vertex - cover problem on hypergraphs where the size of the hyperedges is unbounded is nothing but the set - cover problem . for this problem",
    "there is a @xmath19 approximation algorithm  @xcite , and a matching @xmath20 hardness result due to feige  @xcite .",
    "the first explicit hardness result shown for e@xmath0-vertex - cover  was due to trevisan  @xcite who considered the approximability of bounded degree instances of several combinatorial problems , and specifically showed an inapproximability factor of @xmath21 for e@xmath0-vertex - cover .",
    "holmerin  @xcite showed that e@xmath22-vertex - cover is np - hard to approximate within @xmath23 .",
    "independently , goldreich  @xcite showed a direct ` fglss'-type  @xcite reduction ( involving no use of the long - code , a crucial component in most recent pcp constructions ) attaining a hardness factor of @xmath23 for e@xmath0-vertex - cover for some constant @xmath0 .",
    "later , holmerin  @xcite showed that e@xmath0-vertex - cover is np - hard to approximate within a factor of @xmath24 , and also that it is np - hard to approximate e@xmath25-vertex - cover within factor @xmath26 .",
    "somewhat surprisingly , more recently dinur , guruswami and khot gave a fairly _ simple _ proof of an @xmath27 hardness result for e@xmath0-vertex - cover , ( for some @xmath28 ) .",
    "the proof takes a combinatorial view of holmerin s construction and instead of fourier analysis uses some properties concerning intersecting families of finite sets .",
    "the authors also give a more complicated reduction that shows a factor @xmath29 hardness for e@xmath0-vertex - cover . the crucial impetus for that work came from the recent result of dinur and safra  @xcite on the hardness of approximating vertex cover ( on graphs ) , and as in @xcite the notion of biased long codes and some extremal combinatorics relating to intersecting families of sets play an important role .",
    "in addition to ideas from @xcite , the factor @xmath29 hardness result also exploits the notion of covering complexity introduced by guruswami , hstad and sudan  @xcite .",
    "both the @xmath27 and the @xmath30 results have not been published ( an eccc manuscript exists , @xcite ) since they have been subsumed by the work presented herein .      in this paper",
    "we improve upon all the above hardness results by proving a factor @xmath1 inapproximability result for e@xmath0-vertex - cover . already for @xmath31 ,",
    "this is an improvement from @xmath32 to @xmath33 .",
    "extending our result from @xmath34 to @xmath17 appears highly non - trivial and in particular would imply a factor @xmath33 hardness for vertex - cover on graphs , a problem that is notoriously difficult .",
    "while our proof shares some of the extremal combinatorics flavor of @xcite and @xcite , it draws its strength mainly from a new multilayered outer verifier system for np languages .",
    "this multilayered system is constructed using the raz verifier  @xcite as a building block .",
    "the raz verifier , which serves as the starting point or `` outer verifier '' in most if not all recent hardness results , can be described as follows .",
    "there are two sets of ( non - boolean ) variables @xmath35 and @xmath36 , and for certain pairs of @xmath37 and @xmath38 , a constraint @xmath39 .",
    "the constraints are projections , i.e. , for each assignment to @xmath40 there exists exactly one assignment to @xmath41 such that the constraint @xmath42 is satisfied .",
    "the goal is to find an assignment @xmath43 to the variables so that a maximum number of constraints @xmath44 are satisfied , i.e. , have the property @xmath45 .",
    "the pcp theorem  @xcite along with the parallel repetition theorem  @xcite imply that for any @xmath3 it is np - hard to distinguish between the case where all the constraints can be satisfied and the case where no more than a fraction @xmath46 of the constraints can be satisfied .    in @xcite ,",
    "the @xmath47 hardness result is obtained by replacing every @xmath35 variable by a block of vertices ( representing its long - code ) .",
    "hyperedges connect @xmath48-vertices to @xmath49-vertices only if there is some @xmath50 such that @xmath51 are constraints in the system .",
    "this construction has an inherent symmetry between blocks which deteriorates the projection property of the constraints , limiting the hardness factor one can prove to at most @xmath52 .",
    "another way of reducing the raz verifier to e@xmath0-vertex - cover  is by maintaining the asymmetry between @xmath35 and @xmath36 , introducing a block of vertices for each variable in @xmath35 and in @xmath36 ( representing their long - code ) .",
    "each constraint @xmath39 can be emulated by a set of hyperedges , where each hyperedge consists of both @xmath40-vertices and @xmath41-vertices .",
    "the hyperedges can be chosen so that if the initial pcp instance was satisfiable , then taking a certain @xmath53 of the vertices in each block will be a vertex - cover . however",
    ", this reduction has a basic ` bipartiteness ' flaw : the underlying constraint graph , being bipartite with parts @xmath35 and @xmath36 , has a vertex cover of size at most one half of the number of vertices .",
    "taking all the vertices of , say , the @xmath36 variables will be a vertex cover for the hypergraph regardless of whether or not the initial pcp instance was satisfiable .",
    "this , once again , limits the gap to no more than @xmath52 .",
    "we remark that this ` bipartiteness ' flaw naturally arises in other settings as well .",
    "one example is approximate hypergraph coloring , where indeed our multilayered pcp construction has been successfully used for showing hardness , see @xcite .",
    "+ * the multilayered pcp .  * we overcome the @xmath52 limit by presenting a new , multilayered pcp . in this construction",
    "we maintain the projection property of the constraints that is a strong feature of the raz verifier , while overcoming the ` bipartiteness ' flaw . in the usual raz verifier we have two ` layers ' , the first containing the @xmath35 variables and the second containing the @xmath36 variables .",
    "in the multilayered pcp , we have @xmath54 layers containing variables @xmath55 respectively . between every pair of layers @xmath56 and @xmath57",
    ", we have a set of projection constraints that represent an instance of the raz verifier . in the multilayered pcp",
    ", it is np - hard to distinguish between ( i ) the case where there exists an assignment that satisfies _ all _ the constraints ( between every pair of layers ) , and ( ii ) the case where for _ every _ @xmath58 it is impossible to satisfy more than a fraction @xmath46 of the constraints between @xmath59 and @xmath60 .",
    "in addition , we prove that the underlying constraint graph no longer has the ` bipartiteness ' obstacle , i.e. it no longer has a small vertex cover and hence a large independent set .",
    "indeed we show that the multilayered pcp has a certain ` weak - density ' property : for any set containing an @xmath46 fraction of the variables there are many constraints between variables of the set .",
    "this guarantees that `` fake '' independent sets in the hypergraph ( i.e. , independent sets that occur because there are no constraints between the variables of the set ) contain at most @xmath46 of the vertices .",
    "hence , the minimum vertex cover must contain vertices in almost all of the blocks .",
    "we mention that the pcp presented by feige in @xcite has a few structural similarities with ours .",
    "most notably , both have more than two types of variables .",
    "however , while in our construction the types are layered with decreasing domain sizes , in feige s construction the different types are all symmetric .",
    "furthermore , and more importantly , the constraints tested by the verifier in feige s construction are not projections while this is a key feature of our multilayered pcp , crucially exploited in our analysis .",
    "we view the construction of the multilayered pcp as a central contribution of our paper , and believe that it could be a powerful tool to reduce from in other hardness of approximation results as well .",
    "in fact , as mentioned above , our multilayered construction has already been used in obtaining strong hardness results for coloring @xmath25-uniform hypergraphs  @xcite ( namely the hardness of coloring a @xmath61-colorable @xmath25-uniform hypergraph using an arbitrary constant number of colors ) , a problem for which no non - trivial inapproximability results are known using other techniques .",
    "we anticipate that this new outer verifier will also find other applications besides the ones in this paper and in @xcite .",
    "our hypergraph construction relies on the long - code that was introduced in @xcite , and more specifically , on the biased long - code defined in @xcite .",
    "thus , each pcp variable is represented by a block of vertices , one for each ` bit ' of the biased long - code .",
    "more specifically , in @xmath62 s block we have one vertex for each subset of @xmath63 , where @xmath63 is the set of assignments for the variable @xmath62 .",
    "however , rather than taking all vertices in a block with equal weight , we attach weights to the vertices according to the @xmath64-biased long - code .",
    "the weight of a subset @xmath65 is set to @xmath66 , highlighting subsets of cardinality @xmath67 .",
    "thus we actually construct a weighted hypergraph which can then be easily translated , by appropriate duplication of vertices , to a non - weighted one ( see , e.g. , @xcite ) .",
    "the vertex cover in the hypergraph is shown to have relative size of either @xmath68 in the good case or almost @xmath69 in the bad case .",
    "choosing large @xmath70 , yields the desired gap of @xmath71 between the good and bad cases .",
    "the reduction uses the following property : _ a family of subsets of a set @xmath63 , where each subset has size @xmath72 , either contains very few subsets , or it contains some @xmath73 subsets whose common intersection is very small .",
    "_ we will later show that this property holds for @xmath74 and therefore we obtain a gap of @xmath34 . as can be seen",
    ", this property does not hold for @xmath75 and therefore one can not improve the @xmath34 result by simply increasing @xmath64 .",
    "all our hardness results have the gap between sizes of the vertex cover at the `` strongest '' location .",
    "specifically , to prove a factor @xmath1 hardness we show that it is hard to distinguish between @xmath0-uniform hypergraphs that have a vertex cover of weight @xmath76 from those whose minimum vertex cover has weight at least @xmath77 .",
    "this result is stronger than a gap of about @xmath78 achieved , for example , between vertex covers of weight @xmath79 and @xmath80 .",
    "in fact , by adding dummy vertices , our result implies that for any @xmath81 it is np - hard to distinguish between hypergraphs whose minimum vertex - cover has weight at least @xmath82 from those which have a vertex - cover of weight at most @xmath83 .",
    "put another way , our result shows that for @xmath0-uniform hypergraphs , for @xmath84 , there is a fixed @xmath85 such that for arbitrarily small @xmath18 , it is np - hard to find an independent set consisting of a fraction @xmath46 of the vertices even if the hypergraph is promised to contain an independent set comprising a fraction @xmath85 of vertices .",
    "we remark that such a result is not known for graphs and seems out of reach of current techniques .",
    "( the recent @xmath86 hardness result for vertex cover on graphs due to dinur and safra  @xcite , for example , shows that it is np - hard to distinguish between cases when the graph has an independent set of size @xmath87 and when no independent set has more than @xmath88 vertices . )",
    "we begin in section  [ sec : combin ] by developing the machinery from extremal combinatorics concerning intersecting families of sets that will play a crucial role in our proof . in section  [ sec : layeredpcp ]",
    "we present the multilayered pcp construction . in section  [ sec : reduction ] we present our reduction to a gap version of e@xmath0-vertex - cover  which allows us to prove a factor @xmath1 inapproximability result for this problem .",
    "in this section we describe certain properties of @xmath4-wise @xmath5-intersecting families . for a comprehensive survey , see @xcite .",
    "denote @xmath89={\\left\\ { 0,1,\\ldots , n-1 \\right\\}}$ ] and @xmath90 } = { \\left\\ {   f \\ | \\ f \\subseteq [ n ] \\right\\}}$ ] .",
    "a family @xmath91}$ ] is called _",
    "@xmath4-wise @xmath5-intersecting _ if for every @xmath4 sets @xmath92 , we have @xmath93    we are interested in bounding the size of such families , and for this purpose it is useful to introduce the notion of a left - shifted family .",
    "performing an @xmath94-shift on a family consists of replacing the element @xmath95 with the element @xmath96 in all sets @xmath97 such that @xmath98 , @xmath99 and @xmath100 .",
    "a left - shifted family is a family which is invariant with respect to @xmath94-shifts for any @xmath101 . for any family @xmath102 , by iterating the @xmath94-shift for all @xmath103 we eventually get a left - shifted family which we denote by @xmath104 .",
    "the following simple lemma summarizes the properties of the left - shift operation ( see , e.g. , @xcite , p. 1298",
    ", lemma 4.2 ) :    [ basic_left_shift ] for any family @xmath105}$ ] , there exists a one - to - one and onto mapping @xmath106 from @xmath102 to @xmath104 such that @xmath107 for every @xmath97 .",
    "in other words , left - shifting a family maintains its size and the size of the sets in the family .",
    "moreover , if @xmath102 is an @xmath4-wise @xmath5-intersecting family then so is @xmath104 .",
    "the next lemma states that a subset @xmath65 in a left - shifted @xmath4-wise @xmath5-intersecting family , can not be ` sparse ' on all of its prefixes @xmath108,\\;\\forall j\\ge 0 $ ] .",
    "[ property_left_shift ] let @xmath102 be a left - shifted @xmath4-wise @xmath5-intersecting family .",
    "then , for every @xmath97 , there exists a @xmath109 with @xmath110|\\ge t+(s-1)j$ ] .",
    "[ def : biasedmu ] for a bias parameter @xmath111 , and a ground set @xmath63 , the weight of a set @xmath112 is @xmath113 when @xmath63 is clear from the context we write @xmath114 for @xmath115 .",
    "the weight of a family @xmath116 is @xmath117 .",
    "the weight of a subset is precisely the probability of obtaining this subset when one picks every element in @xmath63 independently with probability @xmath64 .",
    "the following is the main lemma of this section .",
    "it shows that for any @xmath118 , a family of non - negligible @xmath114-weight ( i.e. , @xmath119 ) can not be @xmath4-wise @xmath5-intersecting for sufficiently large @xmath5 .    [ intersecting_lemma ] for any @xmath120 with @xmath121 , there exists a @xmath122 such that for any @xmath4-wise @xmath5-intersecting family @xmath105}$ ] , @xmath123 .",
    "the proof follows from lemma [ property_left_shift ] ( see @xcite , p. 1311",
    ", theorem 8.4 ) .",
    "let @xmath102 be an @xmath4-wise @xmath5-intersecting family where @xmath5 will be determined later . according to lemma  [ basic_left_shift ] , @xmath104 is also @xmath4-wise @xmath5-intersecting and @xmath124 .",
    "by lemma  [ property_left_shift ] , for every @xmath125 , there exists a @xmath109 such that @xmath110|\\ge t+(s-1)j$ ] .",
    "we can therefore bound @xmath126 from above by the probability that such a @xmath95 exists for a random set chosen according to the distribution @xmath114 .",
    "we now prove an upper bound on this probability , which will give the desired bound on @xmath126 and hence also on @xmath127 .",
    "let @xmath128 .",
    "then , for any @xmath109 , @xmath129|\\ge t+(s-1)j~]$ ] is at most @xmath130| - p(t+sj ) \\ge \\delta(t+sj)~ ] \\le e^{-2(t+sj)\\delta^2 } \\ .\\ ] ] by the chernoff bound  @xcite .",
    "summing over all @xmath109 we get : @xmath131 which is smaller than @xmath46 for large enough @xmath5 .",
    "as is the case with many inapproximability results ( e.g. , @xcite , @xcite , @xcite , @xcite ) , we begin our reduction from the raz verifier described next .",
    "let @xmath132 be a collection of two - variable constraints , where the variables are of two types , denoted @xmath35 and @xmath36 .",
    "let @xmath133 denote the range of the @xmath35-variables and @xmath134 the range of the @xmath36-variables , where @xmath135 $ ] and @xmath136 $ ] for some number @xmath137 of repetitions . ] .",
    "assume each constraint @xmath138 depends on exactly one @xmath37 and one @xmath50 , furthermore , for every value @xmath139 assigned to @xmath40 there is exactly one value @xmath140 to @xmath41 such that the constraint @xmath141 is satisfied .",
    "therefore , we can write each constraint @xmath138 as a function from @xmath133 to @xmath134 , and use notation @xmath142 . furthermore , we assume that the underlying constraint graph is bi - regular , i.e. , every @xmath35-variable appears in the same number of constraints in @xmath132 , and every @xmath36-variable appears in the same number of constraints in @xmath132 .",
    "the following theorem follows by combining the pcp theorem with raz s parallel repetition theorem .",
    "the pcp given by this theorem will be called the raz s verifier henceforth .",
    "[ thm : raz - pcp ]  ( pcp theorem @xcite + raz s parallel repetition theorem @xcite )",
    "let @xmath132 be as above .",
    "there exists a universal constant @xmath143 such that for every ( large enough ) constant @xmath144 it is np - hard to distinguish between the following two cases :    * * yes :* there is an assignment @xmath145 , @xmath146 such that all @xmath147 are satisfied by @xmath43 , i.e. , @xmath148 . *",
    "* no :* no assignment can satisfy more than a fraction @xmath149 of the constraints in @xmath132 .    as discussed in the introduction , a natural approach to build a hypergraph from the pcp @xmath132",
    "is to have a block of vertices for every variable @xmath40 or @xmath41 and define hyperedges of the hypergraph so as to enforce the constraints @xmath150 . for every constraint @xmath150",
    ", there will be hyperedges containing vertices from the block of @xmath40 and the block of @xmath41 .",
    "however , this approach is limited by the fact that the constraint graph underlying the pcp has a small vertex cover . since each hyperedge contains vertices from both the @xmath35 and @xmath36 ` sides ' , the subset of all vertices on the @xmath35 ( resp .",
    "@xmath36 ) ` side ' , already covers all of the hyperedges regardless of whether the initial pcp system was satisfiable or not . and",
    "@xmath36 sides can not help either since we wish to ensure a small vertex cover in the completeness case . hence picking all vertices on , say , the @xmath36 side , together with the small vertex cover that hits all edges entirely within",
    "the @xmath35 side ( such a small cover must exist due to the completeness case ) will again give a vertex cover of weight close to @xmath151 . ]",
    "this difficulty motivates our construction of a multilayered pcp where we have many types of variables ( rather than only @xmath35 and @xmath36 ) and the resulting hypergraph is _",
    "multipartite_. the multilayered pcp is able to maintain the properties of theorem [ thm : raz - pcp ] between _ every _ pair of layers .",
    "moreover , the underlying constraint graph has a special ` weak - density ' property that roughly guarantees it will have only tiny independent sets ( thus any vertex cover for it must contain almost all of the vertices ) .",
    "let @xmath152 .",
    "let us begin by defining an @xmath54-layered pcp .",
    "in an @xmath54-layered pcp there are @xmath54 sets of variables denoted by @xmath153 .",
    "the range of variables in @xmath154 is denoted @xmath155 , with @xmath156 . for every @xmath157",
    "there is a set of constraints @xmath158 where each constraint @xmath159 depends on exactly one @xmath160 and one @xmath161 .",
    "for any two variables we denote by @xmath162 the constraint between them if such a constraint exists .",
    "moreover , the constraints in @xmath158 are projections from @xmath62 to @xmath163 , that is , for every assignment to @xmath62 there is exactly one assignment to @xmath163 such that the constraint is satisfied .",
    "in addition , as mentioned in the introduction , we would like to show a certain ` weak - density ' property of our multilayered pcp :    [ def : weak - density ] an @xmath54-layered pcp is said to be _ weakly - dense _ if for any @xmath164 , given @xmath165 layers @xmath166 and given any sets @xmath167 for @xmath168 $ ] such that @xmath169 , there always exist two sets @xmath170 and @xmath171 such that the number of constraints between them is at least a @xmath172 fraction of the constraints between the layers @xmath173 and @xmath174 .    [ pcp_thm ] there exists a universal constant @xmath143 , such that for any parameters @xmath175 , there is a weakly - dense @xmath54-layered pcp @xmath176 such that it is np - hard to distinguish between the following two cases :    * * yes :* there exists an assignment that satisfies all the constraints . * * no :* for every @xmath177 , not more than @xmath178 of the constraints in @xmath158 can be satisfied by an assignment .",
    "let @xmath132 be a constraint - system as in theorem  [ thm : raz - pcp ] .",
    "we construct @xmath179 as follows .",
    "the variables @xmath154 of layer @xmath180 $ ] are the elements of the set @xmath181 , i.e. , all @xmath54-tuples where the first @xmath96 elements are @xmath36 variables and the last @xmath182 elements are @xmath35 variables . the variables in layer @xmath96 have assignments from the set @xmath183 corresponding to an assignment to each variable of @xmath132 in the @xmath54-tuple .",
    "it is easy to see that @xmath184 for any @xmath180 $ ] and that the total number of variables is no more than @xmath185 . for any @xmath186",
    "we define the constraints in @xmath158 as follows .",
    "a constraint exists between a variable @xmath187 and a variable @xmath188 if they contain the same @xmath132 variables in the first @xmath96 and the last @xmath189 elements of their @xmath54-tuples .",
    "moreover , for any @xmath190 there should be a constraint in @xmath132 between @xmath191 and @xmath192 .",
    "more formally , denoting @xmath193 for @xmath194 , @xmath195 \\setminus \\{i+1,\\ldots , j\\ } , x_{i , k}=x_{j , k } \\\\ & & \\qquad    \\forall k\\in\\{i+1,\\ldots , j\\ } , { \\pi_{x_{i , k}\\to x_{j , k}}}\\in \\psi \\biggr\\ }   \\ .\\end{aligned}\\ ] ] as promised , the constraints @xmath196 are projections .",
    "given an assignment @xmath197 to @xmath198 , we define the consistent assignment @xmath199 to @xmath200 as @xmath201 for @xmath202 and @xmath203 for all other @xmath0 .",
    "the completeness of @xmath204 follows easily from the completeness of @xmath132 .",
    "that is , assume we are given an assignment @xmath205 that satisfies all the constraints of @xmath132 .",
    "then , the assignment @xmath206 defined by @xmath207 is a satisfying assignment .",
    "for the soundness part , assume that there exist two layers @xmath177 and an assignment @xmath208 that satisfies more than a @xmath178 fraction of the constraints in @xmath158 .",
    "we partition @xmath154 into classes such that two variables in @xmath154 are in the same class iff they are identical except possibly on coordinate @xmath95 . the variables in @xmath209",
    "are also partitioned according to coordinate @xmath95 . since more than @xmath178 of the constraints in @xmath158 are satisfied , it must be the case that there exist a class @xmath210 in the partition of @xmath154 and a class @xmath211 in the partition of @xmath209 between which there exist constraints and the fraction of satisfied constraints is more than @xmath178 .",
    "we define an assignment to @xmath132 as @xmath212 for @xmath37 and as @xmath213 for @xmath50 .",
    "notice that there is a one - to - one and onto correspondence between the constraints in @xmath132 and the constraints between the two chosen classes in @xmath204 .",
    "moreover , if the constraint in @xmath204 is satisfied , then the constraint in @xmath132 is also satisfied . therefore , @xmath43 is an assignment to @xmath132 that satisfies more than @xmath178 of the constraints .    to prove that this multilayered pcp is _ weakly - dense _ , we recall the bi - regularity property mentioned above , i.e.",
    ", each variable @xmath37 appears in the same number of constraints and also each @xmath50 appears in the same number of constraints .",
    "therefore , the distribution obtained by uniformly choosing a variable @xmath37 and then uniformly choosing one of the variables in @xmath50 with which it has a constraint is a uniform distribution on @xmath36 .    take any @xmath214 layers @xmath166 and sets @xmath167 for @xmath168 $ ] such that @xmath169 .",
    "consider a random walk beginning from a uniformly chosen variable @xmath215 and proceeding to a variable @xmath216 chosen uniformly among the variables with which @xmath217 has a constraint .",
    "the random walk continues in a similar way to a variable @xmath218 chosen uniformly among the variables with which @xmath219 has a constraint and so on up to a variable in @xmath220 .",
    "denote by @xmath221 the indicator variable of the event that the random walk hits an @xmath170 variable when in layer @xmath173 . from the uniformity of @xmath132 it follows that for every @xmath95 , @xmath222 \\ge \\delta$ ] .",
    "moreover , using the inclusion - exclusion principle , we get : @xmath223   \\ge \\sum_j \\mbox{pr}[e_j ]   - \\sum_{j < k } \\mbox{pr}[e_j \\wedge e_k ] \\\\   & & ~\\ge ~\\lceil \\frac{2}{\\delta } \\rceil \\cdot \\delta - { m\\choose 2 } \\mbox{max}_{j < k } \\mbox{pr}[e_j \\wedge e_k ] \\\\ & &     ~\\ge 2 - { m\\choose 2 } \\mbox{max}_{j < k } \\mbox{pr}[e_j \\wedge e_k]\\end{aligned}\\ ] ] which implies @xmath224   \\ge 1/{m\\choose 2 } \\ge \\frac{\\delta^2}{4}\\ ] ]    fix @xmath95 and @xmath0 such that @xmath225 \\ge \\frac{\\delta^2}{4}$ ] and consider a shorter random walk beginning from a random variable in @xmath173 and proceeding to the next layer and so on until hitting layer @xmath226 . since @xmath221 is uniform on @xmath173 we still have that @xmath225\\ge \\frac{\\delta^2}{4}$ ] where the probability is taken over the random walks between @xmath173 and @xmath227 . also , notice that there is a one - to - one and onto mapping from the set of all random walks between @xmath173 and @xmath227 to the set @xmath228 . therefore ,",
    "at least a fraction @xmath172 of the constraints between @xmath173 and @xmath227 are between @xmath170 and @xmath229 , which completes the proof of the weak - density property .",
    "for any @xmath84 it is np - hard to approximate the vertex - cover on a @xmath0-uniform hypergraph within any constant factor less than @xmath73 .",
    "fix @xmath84 and arbitrarily small @xmath3 .",
    "define @xmath230 .",
    "let @xmath204 be a pcp instance with layers @xmath153 , as described in theorem  [ pcp_thm ] , with parameters @xmath231 and @xmath63 large enough to be chosen later .",
    "we present a construction of a @xmath0-uniform hypergraph @xmath232 .",
    "we use the long code introduced by bellare et al .",
    "a long code over domain @xmath63 has one bit for every subset @xmath233 .",
    "an encoding of element @xmath234 assigns bit - value @xmath69 to the sets @xmath235 s.t .",
    "@xmath236 and assigns @xmath237 to the sets which do not contain @xmath62 . in the following , the bits in the long code will be vertices of the hypergraph .",
    "the vertices that correspond to a bit - value @xmath237 are ( supposedly ) the vertices of a vertex cover",
    ".    vertices . for each variable @xmath62 in layer @xmath154",
    "we construct a block of vertices @xmath238 $ ] .",
    "this block contains a vertex for each subset of @xmath239 . throughout this section we slightly abuse notation by writing a vertex rather than the set it represents .",
    "the weight of the vertices inside the block @xmath238 $ ] is according to @xmath240 , i.e. the weight of a subset @xmath241 is proportional to @xmath242 as in definition  [ def : biasedmu ] .",
    "all blocks in the same layer have the same total weight and the total weight of each layer is @xmath243 .",
    "formally , the weight of a vertex @xmath244 $ ] where @xmath160 is given by @xmath245    hyperedges .",
    "we construct hyperedges between blocks @xmath238 $ ] and @xmath246 $ ] such that there exists a constraint @xmath247 .",
    "we connect a hyperedge between any @xmath248 $ ] and @xmath249 $ ] whenever @xmath250 .",
    "let @xmath251 denote the weight of vertices contained in the largest independent set of the hypergraph @xmath14 .",
    "if @xmath204 is satisfiable then @xmath252 .",
    "let @xmath43 be a satisfying assignment for @xmath204 , i.e. , @xmath43 maps each @xmath180 $ ] and @xmath160 to an assignment in @xmath239 such that all the constraints are satisfied .",
    "let @xmath253 contain in the block @xmath238 $ ] all the vertices that contain the assignment @xmath254 , @xmath255 \\left|\\ ; v \\ni a(x ) \\right .",
    "\\right\\ } } \\,.\\ ] ]    we claim that @xmath256 is an independent set",
    ". take any @xmath257 in @xmath258 $ ] and a vertex @xmath137 in @xmath259 $ ] .",
    "the vertices @xmath260 intersect on @xmath254 and therefore the projection of their intersection contains @xmath261 .",
    "since @xmath137 is in @xmath262 $ ] it must contain @xmath263 . the proof is completed by noting that inside each block , the weight of the set of all vertices that contain a specific assignment is exactly @xmath64 .",
    "we now turn to the soundness of the construction .    if @xmath264 then @xmath204 is satisfiable .",
    "this lemma completes the proof of our main result since the ratio between the sizes of the vertex cover in the yes and no cases is @xmath265 which can be arbitrarily close to @xmath73 .",
    "let @xmath256 be an independent set of weight @xmath46 .",
    "we consider the set @xmath266 of all variables @xmath62 for which the weight of @xmath258 $ ] in @xmath238 $ ] is at least @xmath267 .",
    "a simple averaging argument shows that the weight of @xmath268 $ ] is at least @xmath269 .",
    "another averaging argument shows that in at least @xmath270 layers , @xmath266 contains at least @xmath271 fraction of the variables . using the weak - density property of the pcp ( see definition  [ def : weak - density ] ) ,",
    "we conclude that there exist two layers @xmath154 and @xmath209 such that @xmath272 fraction of the constraints between them are constraints between variables in @xmath266 .",
    "let us denote by @xmath273 the variables in @xmath274 and by @xmath35 the variables in @xmath275 .",
    "for any variable @xmath276 , consider the vertices in @xmath277 $ ] .",
    "according to lemma  [ intersecting_lemma ] there exists a @xmath278 and @xmath73 vertices in @xmath279 $ ] that intersect in less than @xmath5 assignments .",
    "we denote these vertices by @xmath280 and their intersection by @xmath281 .    in the following",
    "we define an assignment to the variables in @xmath273 and @xmath35 such that many of the constraints between them are satisfied .",
    "then theorem [ pcp_thm ] would imply that @xmath204 must be satisfiable ( provided @xmath63 is chosen large enough ) . for a variable @xmath276",
    "we choose a random assignment from the set @xmath281 . for a variable @xmath37",
    "we choose the assignment @xmath282 i.e. , the assignment that is contained in the largest number of projections of @xmath281 .    before continuing , we need the following simple claim :    [ popular_claim ] let @xmath283 be a collection of @xmath284 sets of size at most @xmath285 such that no element is contained in more than @xmath0 sets .",
    "then , there are at least @xmath286 disjoint sets in this collection .    we prove by induction on @xmath284 that there are at least @xmath287 disjoint sets in the collection .",
    "the claim holds trivially for @xmath288 .",
    "otherwise , consider all the sets that intersect @xmath289 .",
    "since no element is contained in more than @xmath0 sets , the number of such sets ( including @xmath289 ) is at most @xmath290 . removing these sets we get , by using the induction hypothesis , a collection that contains @xmath291 disjoint sets .",
    "we conclude the induction step by adding @xmath289 to the disjoint sets .",
    "consider a variable @xmath292 and a variable @xmath62 such that the constraint @xmath293 exists .",
    "there are no hyperedges of the form @xmath294 for any vertex @xmath295 $ ] .",
    "therefore , every vertex @xmath296 $ ] must intersect @xmath297 . now consider the family of projections @xmath297 for all the variables @xmath62 such that the constraint @xmath293 exists .",
    "let @xmath298 denote the maximum number of disjoint sets inside this family .",
    "note that every disjoint set reduces the weight of the vertices in @xmath259 $ ] by a factor of @xmath299 . because the weight of @xmath259 $ ] is at least @xmath271",
    ", we obtain that @xmath298 is at most @xmath300 .",
    "claim  [ popular_claim ] implies that there exists an assignment for @xmath40 that is contained in at least a fraction @xmath301 of the projections @xmath297 .",
    "therefore , the expected fraction of constraints satisfied between @xmath273 and @xmath35 is at least @xmath302 which is a constant that does not depend on @xmath63 .",
    "we complete the proof by choosing the range @xmath63 of the pcp large enough so that this fraction is larger than @xmath178 and applying theorem [ pcp_thm ] .",
    "this completes the soundness proof .",
    "we would like to thank noga alon for his help with @xmath4-wise @xmath5-intersecting families .",
    "i. dinur , v. guruswami and s. khot .",
    "vertex cover on @xmath0-uniform hypergraphs is hard to approximate within factor @xmath29 . _",
    "electronic colloquium on computational complexity , technical report tr02 - 027 _ , 2002 .",
    "u. feige , s. goldwasser , l. lov@xmath303sz , s. safra and m. szegedy .",
    "interactive proofs and the hardness of approximating cliques .",
    "_ journal of the acm _ ,",
    "43(2):268 - 292 , march 1996 . o. goldreich . using the fglss - reduction to prove inapproximability results for minimum vertex cover in hypergraphs . _",
    "eccc technical report tr01 - 102 _ , december 2001 .",
    "v. guruswami , j. hstad and m. sudan .",
    "hardness of approximate hypergraph coloring .",
    "_ proceedings of the 41st annual ieee symposium on foundations of computer science ( focs ) _ , pages 149 - 158 , november 2000 .",
    "e. halperin .",
    "improved approximation algorithms for the vertex cover problem in graphs and hypergraphs .",
    "_ proceedings of the 11th annual acm - siam symposium on discrete algorithms _ , pages 329 - 337 , january 2000 .",
    "j. holmerin .",
    "improved inapproximability results for vertex cover on k - uniform hypergraphs .",
    "_ proc . of the 29th international colloquium on automata , languages and programming ( icalp ) _ , pages 1005 - 1016 , july 2002 ."
  ],
  "abstract_text": [
    "<S> given a @xmath0-uniform hyper - graph , the e@xmath0-vertex - cover problem is to find the smallest subset of vertices that intersects every hyper - edge . </S>",
    "<S> we present a new multilayered pcp construction that extends the raz verifier . </S>",
    "<S> this enables us to prove that e@xmath0-vertex - cover is np - hard to approximate within factor @xmath1 for any @xmath2 and any @xmath3 . </S>",
    "<S> the result is essentially tight as this problem can be easily approximated within factor @xmath0 . </S>",
    "<S> our construction makes use of the biased long - code and is analyzed using combinatorial properties of @xmath4-wise @xmath5-intersecting families of subsets .    </S>",
    "<S> * keywords : * pcp , multilayered outer verifier , hardness of approximation , hypergraph vertex cover , long code . </S>"
  ]
}