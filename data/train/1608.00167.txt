{
  "article_text": [
    "in a recent paper @xcite a new perspective for the general problem of data analysis , in the context of big data and complex systems , has been advanced . by probing the data space encoded as a set of correlation functions , the information content of a phenomenological setting",
    "is embedded into a _ field theory of data _ based on an underlying topological space .",
    "this idea is deeply rooted into concepts that have originated from theoretical physics .",
    "general relativity , to mention one of the examples , is the gravitational field theory that describes the motion of particles through space - time where their dynamics is fully determined by the underlying curvature .",
    "we propose here a very simplified realisation of that program that capitalises on the equivalence of field theories with classical statistical mechanics @xcite with the purpose of testing it using the inverse problem approach .",
    "the models we consider are hard - core interacting polymer systems on high - dimensional networks ( hypergraphs ) .",
    "the choice of this class of models is due to the diversity and richness of the phenomena they describe that span from physics @xcite , biology @xcite , computer science @xcite , and social sciences @xcite .",
    "we have in mind , in particular , applications in the the socio - technical setting of novel communication systems where groups of people are present in chambers like those of the messaging systems , voip conference calls etc . from a mathematical point of view",
    "those are aggregation models of particles that can not occupy at the same time more than one state ( hard - core constraint ) : in the specific example of the messaging systems an individual is either silent , the monomer state , in a two body conversation , the dimer state , in a three body conversation state called trimer and so on . while the old style phone calls were well described by a standard monomer - dimer model the novel technologies allow for the contemporary presence of multiple individuals in the same virtual room thus requiring higher order objects like hypergraphs for the underlying space and polymers for the fields that represent their state .    in our model the configurations of the system",
    "are determined by the occupation number on the elements of the hypergraph ( vertices , edges and faces ) that takes only two values @xmath0 and @xmath1 .",
    "we limit the analysis to the rank three case ( conversation with maximum three bodies in the mentioned example ) but the generalisation to higher ranks is straightforward .",
    "the model is assigned by a set of positive weights , the activities , associated to each hyperedge .",
    "these weights describe the strength of connections and identify the topology of the hypergraph trough , for instance , the persistent topology methods developed in @xcite , in @xcite and used in @xcite",
    ". a threshold for the activities could be decided , and the hyperedges below this threshold deleted from the original hypergraph . instead of studying the topology at an arbitrary threshold ,",
    "the persistent topology approach consists in exploring the whole filtration of hypergraphs obtained by varying the threshold . quoting @xcite , `` this filtration process identifies those topological features which persist over a significant parameter range , qualifying them as candidates to be considered as signal , while those that have short - lived features",
    "can be assumed to characterize noise '' .",
    "afterwards this topological signal can be used to compare and classify different datasets .",
    "our first result is of rigorous mathematical nature : the identification of an iterative relation for the partition function of the model which generalises the heilmann - lieb identity @xcite .",
    "while this relation is introduced in a hypergraph theoretical setting we show that it implies a set of identities directly expressible in terms of the correlation functions of the associated probability measure .",
    "they act as a constitutive family of equations for the model that we use in our test and turn out to be an essential tool toward an efficient control of the inverse problem , i.e. the basic question : from a ( full or partial ) set of the correlation functions can we recover the value of the activities for all the hyperedges ?    this work provides a positive answer to the previous question together with the possible limitations and contains two conceptually different numerical methods which can be used to extract activities from the experimental correlations . the first inversion method is based on the maximisation of the _ likelihood _ function and works through a recursive gradient - descent algorithm partially inspired by the one used for the learning process in boltzmann machines @xcite .",
    "we tested its performance and found that it converges exponentially at a speed that does not depend on the size of the hypergraph but is influenced by the magnitude of the activities .",
    "in particular the convergence speed decreases at higher values of the activities , as expected when reaching the full packing regime .",
    "the second method is based on the maximisation of the _ pseudo - likelihood _ function when additional experimental correlations are known .",
    "this has the advantage that it can be applied in a much simpler manner since it provides an explicit expression for the activities .",
    "finally we study the effects of the presence of a further interaction acting among monomers in the hypergraph . in socio - technical systems",
    "this kind of interaction generated by peer - to - peer effects is often very relevant .",
    "the extra structure that comes with it is codified by another hypergraph built on the same set of vertices which , in general , is different and independent from the previous one .",
    "the two networks indeed can be seen as a bilayer structure like those analysed in @xcite .",
    "we concentrated on the problem of probing the presence of such an interaction from the set of experimental correlations , and found that the comparison between the two previously introduced inversion methods provides a good test for the detection of the interaction .",
    "moreover , in the high interaction limit , we show how the same comparison can also be used to numerically estimate the parameter magnitude .",
    "let @xmath2 be a _",
    "hypergraph _ of rank 3 , that is a set of vertices @xmath3 and hyperedges @xmath4 where @xmath5 is an union of edges @xmath6 and faces @xmath7 ( our notation naturally generalises to arbitrary rank ) . on this topological space",
    "we consider configurations of _ polymers _ , precisely monomers ( single particles occupying a vertex ) , dimers ( 2-particles occupying an edge ) , trimers ( 3-particles occupying a face ) . polymers",
    "display mutual hard - core interaction : no region of the space can be touched by more than one polymer . at the same time",
    "we require all the vertices of the hypergraph to be covered by either a monomer or one of the vertices of a polymer .",
    "this last condition that we call _ filling _ , fully specifies the ensemble and should not be confused with the _ full - packing _",
    "one where monomers are not allowed .",
    "a suitable way to represent the allowed configurations is to introduce the _ occupancy variables _ @xmath8 with the _ hard - core filling _",
    "condition @xmath9 notice that because of , for any vertex @xmath10 the quantity @xmath11 , that represents the monomer occupancy of the vertex @xmath12 , can always be expressed as a function of the dimer and trimer occupancy variables .",
    "it is convenient to introduce the admissibility characteristic function @xmath13 defined as @xmath14 to fully specify the model we introduce the _ polymer activity _ of each hyperedge , that is a positive number that measures the propensity of the hyperedge to be occupied by a corresponding polymer .",
    "one can show with an elementary computation that the vertex activities can be reabsorbed into the remaining parameters or factorised out of the partition function .",
    "we denote by @xmath15 the _ edge activities _ ( or _ dimer activities _ ) and by @xmath16 the _ face activities _ ( or _ trimer activities _ ) .",
    "the topological and analytical data , namely @xmath17 and @xmath18 , fully determine a _ probability measure _ associated to configurations : @xmath19 where @xmath20 is the normalisation factor usually called _",
    "partition function_. we denote by @xmath21 the average w.r.t .",
    "the probability measure .",
    "+ 0.2 cm    defining @xmath22 the set of edges with one vertex in @xmath12 and @xmath23 the set of faces with one vertex in @xmath12 , one can prove that the following iterative relation holds : @xmath24 which generalises the heilmann - lieb relation for monomer - dimer systems @xcite . in eq .",
    ", @xmath25 denotes the hypergraph where the vertex @xmath12 has been removed together with the hyperedges in @xmath26 ; @xmath27 stands for @xmath28 where @xmath29 ; @xmath30 stands for @xmath31 where @xmath32 .",
    "+ the previous family of relations for the partition function of the model implies the following _ topological constraint relations _ for the correlation functions . for every edge @xmath33 and for every observable @xmath34 that does not depend on @xmath35 , @xmath36 and @xmath37",
    "it holds : _ e g = z_e _ i_j",
    "g . similarly ,",
    "for every face @xmath38 and for every observable @xmath34 that does not depend on @xmath39 , @xmath40 , @xmath41 and @xmath42 it holds : _ f g = z_f _ i_j_l g .",
    "in particular for @xmath43 one obtains an explicit expression of the activities in terms of correlations @xmath44",
    "in the last few years several new ideas and techniques have been developed @xcite for the _ inverse problem _ of the ising model .",
    "we will discuss the inverse problem for the class of hard - core polymer models introduced in the previous section .",
    "the general task is to extract the parameters of a given theoretical model from experimental measures on the observables .",
    "the problem clearly displays different features according to the types of data that become available . in this work",
    "we will focus on two experimental database settings . in the first one the dataset is composed by the empirical densities of dimers and trimers , while in the second one some empirical correlations for the monomers are also included :    * the _ empirical polymer densities _ , that is @xmath45 for very edge @xmath46 and @xmath47 for every face @xmath48 ; * the previous _ empirical polymer densities _ plus the _ empirical monomer correlations _ , that is @xmath49 for every edge @xmath50 and @xmath51 for every face @xmath52 .",
    "the symbol @xmath53 denotes the empirical average , that is if @xmath54 polymer configurations @xmath55 are observed independently then @xmath56 .      in case",
    "a ) the _ maximum likelihood estimation _ ( mle ) can be used .",
    "let us denote by @xmath57 and by @xmath58 respectively the probability measure defined by and the associated expectation .",
    "it is possible to prove ( see appendix ) that the mle of the polymer activities @xmath59 satisfies the following set of @xmath60 conditions [ mlestimation ]    _ e_z^ * & = _ e _ , ee + _ f_z^ * & = _ f _ , ff .",
    "the set of equations determines implicitly the activities .",
    "we approach its solution by means of a gradient descent algorithm since the maximum likelihood function is a concave function . precisely at step @xmath61 ( @xmath62 )",
    "we update the vector of polymer activities @xmath63 as follows [ eq : bl ] z^(n+1 ) = z^(n ) - ^(n+1 ) .",
    "the vector @xmath64 is the gradient of the kullback - leibler divergence @xmath65 , defined by : [ eq : blgrad ] _",
    "k(z ) = - and it gives to the update step @xmath66 the direction of the gradient of the likelihood function , or equivalently the direction of minus the kullback - leibler divergence gradient ( see appendix for the details ) . the positive number @xmath67 tunes the magnitude of the update steps @xmath68 . by fixing @xmath69 , the speed of convergence of relation is linear , while it can be improved by introducing an adaptive learning rate defined iteratively as : [ eq : eta ] ^(n+1 ) = ^(n ) \\ { } @xmath70 is a positive parameter to be chosen .",
    "the relation is based on the scalar product between two consequent updates of the activities .",
    "if it is positive , which means that the last update steps @xmath71 , @xmath72 were performed along similar directions , then the next update @xmath73 will have a greater magnitude . if it is negative , which means that the last two updates were performed along opposite directions",
    ", then we are in proximity of the solution and a greater precision is needed , so the magnitude of the next update step is diminished .",
    "the recursion stops when the value of the activities @xmath74 is sufficiently close to the exact mle solution of the inverse problem @xmath75 . in our case",
    "we used two different stopping criteria .",
    "the first one can be used only when testing the performance of the algorithm on a priori known models , since it requires the knowledge of the exact values of the activities . in this case a value of precision @xmath76 is chosen , and the recursion stops when the maximum relative error over the set of activities is less than @xmath77 : [ crit1 ] ^(n_f ) = _ k k    problem on experimental data , since it does not assume the knowledge of the exact value of the activities . again",
    "a final precision value @xmath78 is chosen , and the recursion stops as soon as the set of equations is satisfied with precision of at least @xmath79 : [ crit2 ] ^(n_f ) = _ kk|_k _ z^(n_f)-_k _ | < _ f .    * numerical tests*. in order to assess the reliability and stability of this method we performed numerical tests on the speed of convergence of the algorithm to the solution of the equation on random hypergraphs .",
    "in particular we made use of a class of random hypergraph which represents the extension of the notion of erds - rny random graph .",
    "this choice allows us to test the performance of our algorithm over different topologies .",
    "moreover , real - world data is often constituted by many similar instances of the model , whose topologies can be considered as extracted from some random distribution ( see @xcite for instance ) .",
    "we observed that the convergence of the algorithm is exponentially fast in the number of iterations @xmath80 ( figure [ fig : learning_plot ] ) .",
    "moreover the distribution of the speed of convergence does not seem to depend on the number of vertices @xmath81 in the random hypergraph ( figure [ fig : fit_vs_n ] ) .",
    "anyway we stress the fact that the larger @xmath81 is , the longer it takes to compute each step of the algorithm , since the evaluation of @xmath82 is more demanding . on the contrary",
    "the speed of convergence depends on the intensity of the activities ( figure [ fig : fit_vs_z_uniform ] ) .",
    "in particular in the limit of large polymer activity the exponential rate of convergence vanishes .",
    "this limit is equivalent to the _ full - packing _",
    "regime , in fact when polymer activities are high the presence of monomers is repressed in favour of higher order particles .    precisely , to obtain these results , we have generated data as follows :    * a random hypergraph @xmath83 over @xmath81 vertices is generated by placing each hyperedge independently .",
    "each 2-edge is present with probability @xmath84 and each 3-edge with probability @xmath85 . *",
    "an activity @xmath86 is assigned to each hyperedge @xmath87 . for simplicity when generating the dataset we chose @xmath88 constant for all @xmath87 .",
    "details of this choice are specified in each case . * all the possible monomer - dimer - trimer configurations @xmath89 on the hypergraph are computed .",
    "we assign to each configuration its probability and we evaluate the expectations @xmath90 .",
    "the gradient descent algorithm was then applied , using as input parameters @xmath91 .",
    "clearly , this choice entails that @xmath18 solves eq .",
    "and the recursion converges to the value @xmath92 .",
    "we set @xmath93 for all @xmath87 and @xmath94 .",
    "we used eq . as stopping criterion setting @xmath95 .     versus number of iterations @xmath80 ( red curve , linear - log scale ) .",
    "_ the convergence is exponentially fast in the number of iterations _ : to test this hypothesis we performed a linear fit ( blue line ) according to the relation @xmath96 .",
    "we chose a random hypergraph with @xmath97 , @xmath98 and @xmath99 for all @xmath100 .",
    "the fit is performed on the data after removing the initial @xmath101 of iterations . ]",
    "it is important to notice that in case b ) the number of observables is two times the number of degrees of freedom of the model defined by , since the dataset contains the _ empirical polymer densities _ @xmath102 and the _ empirical monomer correlations _ @xmath103 while the model is determined only by the activities @xmath86 , @xmath100 .",
    "a possible way to deal with this overdetermined case is to consider the _ maximum pseudo - likelihood estimation _ ( mple ) .",
    "this method can be seen as an approximation of the mle where the joint distribution is replaced with a suitable conditional probability : we look at the probability to observe an occupied hyperedge conditionally on the states of all the others . it can be proven ( see appendix ) that the mple of the activities @xmath104 satisfies the following set of @xmath60 conditions [ mplestimation ]    _ e _ & = z^**_e _ i_j_,e=\\{i , j}e + _ f _ & = z^**_f _ i_j_l_,f=\\{i , j , l}f .",
    "we observe two important features : the analogy between and the exact relations and the fact that these relations provide an explicit form for the activities .",
    "+ another way to exploit the additional information given by the empirical monomer correlations is to modify the model defined in by introducing a new family of parameters @xmath105 that tune the monomer correlations : @xmath106 we denote by @xmath107 the average with respect to this probability measure . while this fact could appear as a mere technical device , it has instead a deep phenomenological meaning",
    ": the monomers can indeed directly interact beyond the hard - core repulsion , a situation largely expected in socio - technical systems due to the peer - to - peer effect among individuals .",
    "in other words in the experiments the presence of a coupling @xmath108 between monomers can not be excluded _",
    "a priori_. for this reason in this second part of our work we have generated the _ empirical polymer densities _ and _ empirical monomer correlations _ according to a perturbed distribution @xmath109 .",
    "the following extension of the heilmann - lieb identity for the partition function of the measure holds :    [ eq : liebj ] z_h = z_h - v^ * + _ kkkv z_k z_h - k , vv where in the partition function @xmath110 a monomer activity @xmath111 is introduced on every vertex @xmath112 which was connected to @xmath12 .",
    "we call _ hypertree _ a hypergraph @xmath17 such that , after having removed the edges included in some face , its line graph is a tree . on hypertrees",
    "the relation provides the following useful estimate : [ eq : stima ] = _ k , kk where the term @xmath113 goes to @xmath1 as @xmath114 vanishes for every polymer @xmath115 at distance @xmath1 from @xmath116 , and even better : 1 _ k _ ( 1+_z_p  _",
    "e^-j_q ) .",
    "as said before , we have generated data @xmath102 , @xmath103 according to the distribution in the presence of an interaction @xmath117 : the quantities @xmath118 and @xmath119 have been computed exactly on random hypergraphs , following a procedure analogous to section [ sec : kl ] .",
    "starting from these data we have computed the mle and mple as if the interaction was not present .",
    "we guessed that while the two resulting estimates @xmath120 and @xmath104 of the activities agree in case @xmath121 , they may differ when @xmath117 , and thus they may be used to probe the presence of an interaction . to make this guess more precise",
    ", we performed the following test , which could be applied also to real data .    *",
    "the gradient descent algorithm is executed using as input @xmath122 .",
    "if the algorithm converges , its limit is a vector of activities @xmath120 such that : _",
    "k _ z^ * = _ k _ z , j , kk . we set @xmath93 and @xmath94 .",
    "we used eq .",
    "as stopping criterion setting @xmath123 , together with a bound for the number of iterations that stops the recursion at @xmath124 even if the precision @xmath125 has not been reached yet .",
    "* the closed inversion formula is applied , as if the coupling potential was not present : z_k^ * * = , kk . *",
    "we study the parameter = _ kk ( z_k^ * * - z_k^ * ) . for zero coupling potential @xmath126",
    "is close to zero , since both @xmath127 and @xmath128 equal the true value of the activity @xmath86 ( up to the precision of the gradient descent algorithm ) .",
    "we observed that @xmath126 , together with the final precision @xmath129 , can indeed be used as a test - parameter to understand whether the real system obeys a pure hard - core interaction or there are other types of non - negligible interactions .",
    "in fact it allows to distinguish between the following three regimes ( fig .",
    "[ fig : j delta ] ) :    * for @xmath130 the gradient descent algorithm is not guaranteed to converge in the prescribed number of iterations since the precision @xmath129 ranges from @xmath131 to @xmath132 . the value of @xmath126 is negative and its modulus grows linearly with @xmath108 . * for @xmath133 the convergence of the gradient descent method",
    "is attained .",
    "the parameter @xmath126 is close to zero , positive , and shows a non - monotonic behaviour in @xmath108 . * for @xmath134",
    "the convergence of the gradient descent method becomes abruptly poor and for @xmath108 sufficiently large @xmath129 is larger that @xmath135 .",
    "@xmath126 is positive and exhibits a large variance over different random hypergraphs .",
    "when @xmath108 is positive and sufficiently large , we propose a method to estimate its value .",
    "compare the relations for the measure @xmath109 with the exact relations for the measure @xmath136 .",
    "it becomes clear that if the experimental parameter @xmath137 shows a correlation with the number of hyperedges intersecting @xmath116 , @xmath138 , then the system presents other interactions beyond the hard - core one .",
    "in particular in the case of constant @xmath108 and @xmath18 , the equation gives [ eq : stima2 ] _",
    "k(z , j ) z - j_k , kk when @xmath139 is sufficiently large with respect to @xmath140 , for all hyperedges @xmath141 intersecting @xmath116 and all vertices @xmath12 neighbouring @xmath116 .",
    "therefore @xmath108 and @xmath18 can be found by performing a linear fit between @xmath142 and @xmath143 ( fig .",
    "[ fig : j fit ] ) .",
    "with the purpose to investigate the possibility to discover topological information from the data space we introduced in this work a model in which polymers are deposited on the hyperedges of an hypergraph with a probability determined according to the hyperedges activities .",
    "the idea underlying the model is that simple graphs are no longer able to account for the structure of many modern socio - technical systems , such as those of virtual messaging systems or voip calls . in these systems",
    "the communications do not occur only between pairs of users , but may involve larger groups @xcite .",
    "we believe that this context may give rise to new interesting behaviours , where topology plays a crucial role .    with these applications in mind we tackled the inverse problem .",
    "after finding an extension of the heilmann - lieb relations that fits the higher - dimensional case , we introduced the _ maximum likelihood estimation _ ( mle ) and the _ maximum pseudo - likelihood estimation _ ( mple ) solutions of the inverse problem . while the latter constitutes a more rough estimate but has an explicit form in terms of experimental quantities , the former provides a more precise but implicit solution , which can nonetheless be numerically evaluated by the gradient descent algorithm we proposed .",
    "we found that by introducing a variable update step size the algorithm converges with exponential precision in the number of steps .",
    "however we stress that the time it takes to compute each step of the algorithm grows with the size of the hypergraph , since all the admissible configurations have to be computed exactly .",
    "a possible solution to this problem could be to evaluate average quantities through markov chain monte carlo sampling .",
    "we tested the algorithm on toy models for different values of the parameters , and found that while the exponential convergence does not seem to be influenced by the number of vertices in the hypergraphs , it does depend on the values of the activities .",
    "a further analysis of this dependence could be performed , for example with respect to the variance of the activity distribution .",
    "we then considered the presence of an interaction between the monomers in the configurations .",
    "the meaning of this interactions can be understood by thinking to the social systems that our model tries to describe : in the context of virtual social interactions peer - to - peer effects are to be expected .",
    "we found that a comparison between the mle and the mple solution of the inverse problem can be used to detect the presence of such an interaction .",
    "the same comparison can moreover lead to the estimation of the interaction magnitude in the `` strong interaction '' regime .",
    "the next step and most natural continuation of this work would be the application of such a model on real - world data . by testing the model on data",
    "we could verify whether it is able to accurately describe the behaviour of users in virtual messaging services and what type of predictive ability it comes with .",
    "for instance , this could be done by measuring the kullback - leibler distance between the experimental probability distribution and the probability distribution resulting from the maximum likelihood estimation . in case",
    "the model is accurate it would allow us to measure of user activities in chatrooms , and even determine whether the system is subject to peer - to - peer monomer interactions .    0.5 cm    * aknowledgments * the authors are deeply indebted to mario rasetti for inspiring this work and for many illuminating discussions .",
    "we also thank massimo ferri , giovanni petri , federico ricci - tersenghi , alina srbu and francesco vaccarino for interesting discussions .",
    "this work was partially supported by firb ( grant number rbfr10n90w ) , prin ( grant number 2010hxaw77 ) and indam - gnfm ( progetto giovani 2015 ) .",
    "we shortly present here the application of the maximum likelihood and the maximum pseudo - likelihood methods to our model .",
    "the general framework is the following : fix the hypergraph @xmath17 and assume the model is described by an unknown value of the activities @xmath18 to be determined . consider a set of @xmath54 observations of polymer configurations @xmath144 , where @xmath145 and @xmath146 encodes the presence / absence of a polymer on the hyperedge @xmath116 in the @xmath147 experimental observation .",
    "suppose that @xmath148 is a set of independent observations sampled from the same probability distribution @xmath57 , for a certain value of the activities @xmath149 .",
    "we use two standard methods that give an optimal value @xmath120 to fit the dataset @xmath148 : the _ maximum likelihood estimation _ ( mle ) and the _ maximum pseudo - likelihood estimation _ ( mple ) .",
    "let us briefly recall these methods .",
    "the optimal estimate @xmath120 in the mle sense maximizes the _ likelihood function _ defined as @xmath150 standard computations show that @xmath151 is a concave function in the variables @xmath152 and it attains its maximum at the point @xmath120 satisfying the following system of @xmath60 equations : [ amlestimation ] _ k_z^*=_k _ , kk = ef , where @xmath153 is the experimental average value of the presence of a polymer in the hyperedge @xmath116 .",
    "this approach naturally fits the experimental situation where the available data is the set of _ empirical polymer densities_. let us observe that the likelihood function @xmath154 is strictly related to the kullback - leibler divergence of the measure @xmath136 from the empirical measure @xmath155 , defined as d_(_z|^ * ) = _ ^ * ( ) where @xmath156 .",
    "precisely the following relations holds : ( z;| ) = - d_(_z|^ * ) + c with @xmath157 .",
    "now let us consider the pseudo - likelihood instead of the likelihood .",
    "the optimal estimate @xmath120 in the mple sense maximizes the _ pseudo - likelihood function _ defined as @xmath158 where , for a given sample @xmath159 and hyperedge @xmath116 , @xmath160 encodes the experimental observation of a polymer on all the hyperedges different from @xmath116 .",
    "it is possible to show that @xmath161 attains its maximum at the point @xmath104 explicitly defined by the following @xmath60 conditions : [ amplestimation ] _ k _ = z^**_k _ vk _ v _ , kk = ef where @xmath162 denotes the experimental observations of a monomer on the vertex @xmath12 in the @xmath163 trial and @xmath164 is the empirical monomer correlation of the vertices in @xmath116 .",
    "10                                    m  rasetti and e  merelli .",
    "topological field theory of data : mining data beyond complex networks . in contucci and giardina , editors ,",
    "_ advances in disordered systems , random processes and some applications_. cambridge university press , 2016 ."
  ],
  "abstract_text": [
    "<S> following a newly introduced approach by rasetti and merelli we investigate the possibility to extract topological information about the space where interacting systems are modelled . from the statistical datum of their observable quantities , like the correlation functions , </S>",
    "<S> we show how to reconstruct the activities of their constitutive parts which embed the topological information . </S>",
    "<S> the procedure is implemented on a class of polymer models on hypergraphs with hard - core interactions . </S>",
    "<S> we show that the model fulfils a set of iterative relations for the partition function that generalise those introduced by heilmann and lieb for the monomer - dimer case . after translating those relations into structural identities for the correlation functions we use them to test the precision and the robustness of the inverse problem . </S>",
    "<S> finally the possible presence of a further interaction of peer - to - peer type is considered and a criterion to discover it is identified . + * keywords * : networks , hypergraphs , inverse problem , complex systems . </S>"
  ]
}