{
  "article_text": [
    "whereas classical statistical inference is performed in a centralized manner , many modern scientific problems and engineering systems are inherently _ decentralized _ : data are distributed , and can not be aggregated due to various forms of communication constraints .",
    "an important example of such a decentralized system is a sensor network  @xcite : a set of spatially - distributed sensors collect data about the environmental state ( e.g. , temperature , humidity or light ) .",
    "typically , these networks are based on ad hoc deployments , in which the individual sensors are low - cost , and must operate under very severe power constraints ( e.g. , limited battery life ) . in statistical terms ,",
    "such communication constraints imply that the individual sensors can not transmit the raw data ; rather , they must compress or quantize the data  for instance , by reducing a continuous - valued observation to a single bit  and can transmit only this compressed representation back to the fusion center .    by now , there is a rich literature in both information theory and statistical signal processing on problems of decentralized statistical inference .",
    "a number of researchers , dating back to the seminal paper of tenney and sandell  @xcite , have studied the problem of hypothesis testing under communication - constraints ; see the survey papers  @xcite and references therein for overviews of this line of work .",
    "the hypothesis - testing problem has also been studied in the information theory community , where the analysis is asymptotic and shannon - theoretic in nature  @xcite",
    ". a parallel line of work deals with problem of decentralized estimation .",
    "work in signal processing typically formulates it as a quantizer design problem and considers finite sample behavior  @xcite ; in contrast , the information - theoretic approach is asymptotic in nature , based on rate - distortion theory  @xcite . in much of the literature on decentralized statistical inference",
    ", it is assumed that the underlying distributions are known with a specified parametric form ( e.g. , gaussian ) .",
    "more recent work has addressed non - parametric and data - driven formulations of these problems , in which the decision - maker is simply provided samples from the unknown distribution  @xcite .",
    "for instance , nguyen et al .",
    "@xcite established statistical consistency for non - parametric approaches to decentralized hypothesis testing based on reproducing kernel hilbert spaces .",
    "luo  @xcite analyzed a non - parametric formulation of decentralized mean estimation , in which a fixed but unknown parameter is corrupted by noise with bounded support but otherwise arbitrary distribution , and shown that decentralized approaches can achieve error rates that are order - optimal with respect to the centralized optimum .",
    "this paper addresses a different problem in decentralized non - parametric inference  namely , that of estimating an arbitrary quantile of an unknown distribution . since there exists no unbiased estimator based on a single sample ,",
    "we consider the performance of a network of @xmath0 sensors , each of which collects a total of @xmath9 observations in a sequential manner .",
    "our analysis treats the standard fusion - based architecture , in which each of the @xmath0 sensors transmits information to the fusion center via a communication - constrained channel . more concretely , at each observation round , each sensor is allowed to transmit a single bit to the fusion center , which in turn is permitted to send some number @xmath1 bits of feedback . for a decentralized protocol with @xmath10 bits of feedback , we prove that the algorithm achieves the order - optimal rate of the best centralized method ( i.e. , one with access to the full collection of raw data ) .",
    "we also consider a protocol that permits only a single bit of feedback , and establish that it achieves the same rate .",
    "this single - bit protocol is advantageous in that , with for a fixed target mean - squared error of the quantile estimate , it yields longer sensor lifetimes than either the centralized or full feedback protocols .    the remainder of the paper is organized as follows .",
    "we begin in section  [ secdecent ] with background on quantile estimation , and optimal rates in the centralized setting .",
    "we then describe two algorithms for solving the corresponding decentralized version , based on @xmath11 and @xmath12 bit of feedback respectively , and provide an asymptotic characterization of their performance .",
    "these theoretical results are complemented with empirical simulations .",
    "section  [ sectheory ] contains the analysis of these two algorithms . in section  [ secext ] ,",
    "we consider various extensions , including the case of feedback bits @xmath13 varying between the two extremes , and the effect of noise on the feedforward link .",
    "we conclude in section  [ secdiscussion ] with a discussion .",
    "in this section , we begin with some background material on ( centralized ) quantile estimation , before introducing our decentralized algorithms , and stating our main theoretical results .",
    "we begin with classical background on the problem of quantile estimation ( see serfling  @xcite for further details ) .",
    "given a real - valued random variable @xmath14 , let be its cumulative distribution function ( cdf ) , which is non - decreasing and right - continuous . for any @xmath15 , the @xmath16-quantile of @xmath14 is defined as @xmath17 .",
    "moreover , if @xmath18 is continuous at @xmath19 , then we have @xmath20 . as a particular example , for @xmath21 , the associated quantile is simply the median .",
    "now suppose that for a fixed level @xmath22 , we wish to estimate the quantile @xmath23 .",
    "rather than impose a particular parameterized form on @xmath18 , we work in a non - parametric setting , in which we assume only that the distribution function @xmath18 is differentiable , so that @xmath14 has the density function @xmath24 ( w.r.t lebesgue measure ) , and moreover that @xmath25 for all @xmath26 . in this",
    "setting , a standard estimator for @xmath27 is the _ sample quantile _",
    "@xmath28 where @xmath29 denotes the empirical distribution function based on i.i.d .",
    "samples @xmath30 . under the conditions given above",
    ", it can be shown  @xcite that @xmath31 is strongly consistent for @xmath27 ( i.e. , @xmath32 ) , and moreover that asymptotic normality holds @xmath33 so that the asymptotic mse decreases as @xmath34 , where @xmath35 is the total number of samples .",
    "although this @xmath36 rate is optimal , the precise form of the asymptotic variance   need not be in general ; see zielinski  @xcite for in - depth discussion of the optimal asymptotic variances that can be obtained with variants of this basic estimator under different conditions .",
    "we consider the standard network architecture illustrated in figure  [ fignetwork ] .",
    "there are @xmath0 sensors , each of which has a dedicated two - way link to a fusion center .",
    "we assume that each sensor @xmath37 collects independent samples @xmath38 of the random variable @xmath39 with distribution function we consider a sequential version of the quantile estimation problem , in which sensor @xmath40 receives measurements @xmath41 at time steps @xmath42 , and the fusion center forms an estimate @xmath43 of the quantile .",
    "the key condition  giving rise to the decentralized nature of the problem  is that communication between each sensor and the central processor is constrained , so that the sensor can not simply relay its measurement @xmath38 to the central location , but rather must perform local computation , and then transmit a summary statistic to the fusion center .",
    "more concretely , we impose the following restrictions on the protocol . first , at each time step @xmath44 , each sensor @xmath45 can transmit a single bit @xmath46 to the fusion center .",
    "second , the fusion center can broadcast @xmath47 bits back to the sensor nodes at each time step .",
    "we analyze two distinct protocols , depending on whether or     sensors .",
    "each sensor is permitted to transmit a @xmath12-bit message to the fusion center ; in turn , the fusion center is permitted to broadcast @xmath1 bits of feedback.,title=\"fig : \" ]      for each protocol , all sensors are initialized with some fixed @xmath48 .",
    "the algorithms are specified in terms of a constant @xmath49 and step sizes @xmath50 that satisfy the conditions @xmath51 the first condition ensures infinite travel ( i.e. , that the sequence @xmath52 can reach @xmath27 from any starting condition ) , whereas the second condition ( which implies that @xmath53 ) is required for variance reduction .",
    "a standard choice satisfying these conditions  and the one that we assume herein  is @xmath54 . with this set - up",
    ", the @xmath11-bit scheme consists of the steps given in table  [ tabmbf ] .",
    "although the most straightforward feedback protocol is to broadcast back the @xmath55 received bits @xmath56 , as described in step ( c ) , in fact it suffices to transmit only the @xmath57 bits required to perfectly describe the binomial random variable @xmath58 in order to update @xmath43 . in either case , after the feedback step",
    ", each sensor knows the value of the sum @xmath59 , which ( in conjunction with knowledge of @xmath55 , @xmath60 and @xmath61 ) allow it to compute the updated parameter @xmath62 . finally ,",
    "knowledge of @xmath62 allows each sensor to then compute the local decision   in the following round .",
    "the 1-bit feedback scheme detailed in table  [ tab1bf ] is similar , except that it requires broadcasting only a single bit ( @xmath63 ) , and involves an extra step size parameter @xmath64 , which is specified in the statement of theorem  [ thm1bf ] .",
    "after the feedback step of the 1-bf algorithm , each sensor has knowledge of the aggregate decision @xmath63 , which ( in conjunction with @xmath61 and the constant @xmath65 ) allow it to compute the updated parameter @xmath62 .",
    "knowledge of this parameter suffices to compute the local decision  .",
    "we now state our main results on the convergence behavior of these two distributed protocols . in all cases , we assume the step size choice @xmath66 . given fixed @xmath22 , we use @xmath27 to denote the @xmath60-level quantile ( i.e. , such that @xmath67 ) ; note that our assumption of a strictly positive density guarantees that @xmath27 is unique .",
    "[ thmmbf ] for any @xmath22 , consider a random sequence @xmath68 generated by the @xmath55-bit feedback protocol .",
    "then    \\(a ) for all initial conditions @xmath48 , the sequence @xmath43 converges almost surely to the @xmath60-quantile @xmath27 .",
    "\\(b ) moreover , if the constant @xmath69 is chosen to satisfy @xmath70 , then @xmath71 } \\",
    "; \\frac{1}{{\\ensuremath{m}}}\\right),\\ ] ] so that the asymptotic mse is @xmath72 .",
    "_ remarks : _",
    "after @xmath2 steps of this decentralized protocol , a total of @xmath73 observations have been made , so that our discussion in section  [ secbackground ] dictates ( see equation  ) that the optimal asymptotic mse is @xmath74 .",
    "interestingly , then , the @xmath57-bit feedback decentralized protocol is order - optimal with respect to the centralized gold standard .    before stating the analogous result for the 1-bit feedback protocol , we begin by introducing some useful notation .",
    "first , we define for any fixed @xmath75 the random variable @xmath76 note that for each fixed @xmath77 , the distribution of @xmath78 is binomial with parameters @xmath55 and @xmath79 .",
    "it is convenient to define the function @xmath80 with domain @xmath81 \\times [ 0,1]$ ] . with this notation",
    ", we have @xmath82 again , we fix an arbitrary @xmath22 and let @xmath27 be the associated @xmath60-quantile satisfying    [ thm1bf ] given a random sequence @xmath68 generated by the @xmath12-bit feedback protocol , we have    1 .   for any initial condition , the sequence @xmath83 .",
    "2 .   suppose that the step size @xmath84 is chosen such that or equivalently such that @xmath85 then @xmath86}{2 \\gamma_{{\\ensuremath{m}}}({\\ensuremath{\\theta^ * } } ) - 1 } \\right)\\ ] ] 3 .",
    "if we choose a _ constant step size _",
    "@xmath87 , then as the asymptotic variance behaves as @xmath88,\\ ] ] so that the asymptotic mse is @xmath89 .",
    "4 .   if we choose a _ decaying step size _",
    "@xmath90 , then @xmath91,\\ ] ] so that the asymptotic mse is @xmath92 .",
    "it is interesting to compare the performance of each proposed decentralized algorithm to the centralized performance .",
    "considering first the @xmath57-bf scheme , suppose that we set @xmath93 .",
    "using the formula   from theorem  [ thmmbf ] , we obtain that the asymptotic variance of the @xmath55-bf scheme with this choice of @xmath94 is given by @xmath95 , thus matching the asymptotics of the centralized quantile estimator  .",
    "in fact , it can be shown that the choice @xmath96 is optimal in the sense of minimizing the asymptotic variance for our scheme , when @xmath94 is constrained by the stability criterion in theorem  [ thmmbf ] . in practice , however , the value @xmath97 is typically not known , so that it may not be possible to implement exactly this scheme .",
    "an interesting question is whether an adaptive scheme could be used to estimate @xmath97 ( and hence the optimal @xmath94 simultaneously ) , thereby achieving this optimal asymptotic variance .",
    "we leave this question open as an interesting direction for future work .",
    "turning now to the algorithm @xmath12-bf , if we make the substitution @xmath98 in equation  , then we obtain the asymptotic variance @xmath99 } \\ ; \\frac{1}{{\\ensuremath{m}}}.\\ ] ] since the stability criterion is the same as that for @xmath6-bf , the optimal choice is @xmath100 . consequently , while the @xmath101)$ ] rate is the same as both the centralized and decentralized @xmath55-bf protocols , the pre - factor for the @xmath12-bf algorithm is @xmath102 times larger than the optimized @xmath55-bf scheme .",
    "however , despite this loss in the pre - factor , the @xmath12-bf protocol has substantial advantages over the @xmath55-bf ; in particular , the network lifetime scales as @xmath103 compared to @xmath104 for the @xmath57-bf scheme .",
    "we now provide some simulation results in order to illustrate the two decentralized protocols , and the agreement between theory and practice .    [ cols=\"^,^,^ \" , ]      we now briefly consider the effect of communication noise on our algorithms .",
    "there are two types of noise to consider : ( a ) _ feedforward _ , meaning noise in the link from sensor node to fusion center , and ( b ) _ feedback _ , meaning noise in the feedback link from fusion center to the sensor nodes . here",
    "we show that feedforward noise can be handled in a relatively straightforward way in our algorithmic framework . on the other hand",
    ", feedback noise requires a different analysis , as the different sensors may loose synchronicity in their updating procedure .",
    "although a thorough analysis of such asynchronicity is an interesting topic for future research , we note that assuming noiseless feedback is not unreasonable , since the fusion center typically has greater transmission power .",
    "focusing then on the case of feedforward noise , let us assume that the link between each sensor and the fusion center acts as a binary symmetric channel ( bsc ) with probability @xmath105 .",
    "more precisely , if a bit @xmath106 is transmitted , then the received bit @xmath107 has the ( conditional ) distribution @xmath108 with this bit - flipping noise , the updates ( both equation   and  ) need to be modified so as to correct for the bias introduced by the channel noise . if @xmath60 denotes the desired quantile , then in the presence of bsc(@xmath109 noise , both algorithms should be run with the modified parameter @xmath110 note that @xmath111 ranges between @xmath60 ( for the noiseless case @xmath112 ) , to a quantity arbitrarily close to @xmath113 , as the channel approaches the extreme of pure noise ( @xmath114 ) .",
    "the following lemma shows that for all @xmath115 , this adjustment   suffices to correct the algorithm .",
    "moreover , it specifies how the resulting asymptotic variance depends on the noise parameter :    [ propnoise ] suppose that each of the @xmath55 feedforward links from sensor to fusion center are modeled as i.i.d .",
    "bsc channels with probability @xmath116",
    ". then the @xmath55-bf or @xmath12-bf algorithms , with the adjusted @xmath111 , are strongly consistent in computing the @xmath60-quantile . moreover , with appropriate step size choices , their asymptotic mses scale as @xmath117 with respective pre - factors given by    [ eqndefnvnoise ] @xmath118 } \\\\",
    "\\label{eqndefnvnoise1 } v_1({\\ensuremath{\\epsilon } } ) & { \\ensuremath { : \\ , = } } & \\left [ \\frac{{\\ensuremath{k}}^2 \\sqrt{2 \\pi { \\ensuremath{\\widetilde{\\alpha}({\\ensuremath{\\epsilon}})}}(1-{\\ensuremath{\\widetilde{\\alpha}({\\ensuremath{\\epsilon}})}})}}{8 { \\ensuremath{k}}(1 - 2 { \\ensuremath{\\epsilon } } ) p_x({\\ensuremath{\\theta^ * } } ) - 4\\sqrt{2 \\pi { \\ensuremath{\\widetilde{\\alpha}({\\ensuremath{\\epsilon}})}}(1-{\\ensuremath{\\widetilde{\\alpha}({\\ensuremath{\\epsilon } } ) } } ) } } \\right].\\end{aligned}\\ ] ]    in both cases , the asymptotic mse is minimal for @xmath112 .    _",
    "proof : @xmath119_if sensor node @xmath40 transmits a bit @xmath120 at round @xmath121 , then the fusion center receives the random variable @xmath122 where @xmath123 is bernoulli with parameter @xmath124 , and @xmath125 denotes addition modulo two .",
    "since @xmath123 is independent of the transmitted bit ( which is bernoulli with parameter @xmath126 ) , the received value @xmath127 is also bernoulli , with parameter @xmath128 consequently , if we set @xmath111 according to equation  , both algorithms will have their unique fixed point when @xmath129 , so will compute the @xmath60-quantile of @xmath14 .",
    "the claimed form of the asymptotic variances follows from by performing calculations analogous to the proofs of theorems  [ thmmbf ] and  [ thm1bf ] .",
    "in particular , the partial derivative with respect to @xmath77 now has a multiplicative factor @xmath130 , arising from equation   and the chain rule . to establish that the asymptotic variance is minimized at @xmath112",
    ", it suffices to note that the derivative of the mse with respect to @xmath124 is positive , so that it is an increasing function of @xmath124 .",
    "@xmath131    of course , both the algorithms will fail , as would be expected , if @xmath132 corresponding to pure noise",
    ". however , as summarized in proposition  [ propnoise ] , as long as @xmath133 , feedforward noise does not affect the asymptotic rate itself , but rather only the pre - factor in front of the @xmath117 rate .",
    "figure  [ figlevels](b ) shows how the asymptotic variances @xmath134 and @xmath135 behave as @xmath124 is increased towards @xmath136 .",
    "in this paper , we have proposed and analyzed different approaches to the problem of decentralized quantile estimation under communication constraints .",
    "our analysis focused on the fusion - centric architecture , in which a set of @xmath0 sensor nodes each collect an observation at each time step .",
    "after @xmath9 rounds of this process , the centralized oracle would be able to estimate an arbitrary quantile with mean - squared error of the order @xmath137 . in the decentralized formulation considered here ,",
    "each sensor node is allowed to transmit only a single bit of information to the fusion center .",
    "we then considered a range of decentralized algorithms , indexed by the number of feedback bits that the fusion center is allowed to transmit back to the sensor nodes . in the simplest case",
    ", we showed that an @xmath138-bit feedback algorithm achieves the same asymptotic variance @xmath139 as the centralized estimator .",
    "more interestingly , we also showed that that a @xmath12-bit feedback scheme , with suitably designed step sizes , can also achieve the same asymptotic variance as the centralized oracle .",
    "we also showed that using intermediate amounts of feedback ( between @xmath12 and @xmath55 bits ) does not alter the scaling behavior , but improves the constant .",
    "finally , we showed how our algorithm can be adapted to the case of noise in the feedforward links from sensor nodes to fusion center , and the resulting effect on the asymptotic variance .",
    "our analysis in the current paper has focused only on the fusion center architecture illustrated in figure  [ fignetwork ] .",
    "a natural generalization is to consider a more general communication network , specified by an undirected graph on the sensor nodes .",
    "one possible formulation is to allow only pairs of sensor nodes connected by an edge in this communication graph to exchange a bit of information at each round . in this framework",
    ", the problem considered in this paper effectively corresponds to the complete graph , in which every node communicates with every other node at each round .",
    "this more general formulation raises interesting questions as to the effect of graph topology on the achievable rates and asymptotic variances .",
    "we would like to thank prof .",
    "pravin varaiya for some discussion that led to the initial ideas on this subject .",
    "rr was supported by the california department of transportation through the california path program .",
    "mjw was partially supported by nsf grant dms-0605165 and an nsf career award ccf-0545862 .            _",
    "proof : @xmath119_first notice that by definition : @xmath142 \\big ] , \\ ] ] where @xmath14 is a @xmath143 random variable .",
    "note that if @xmath144 , with @xmath145 , then certainly @xmath146meaning that @xmath147 stochastically dominates @xmath14 . for any constant @xmath148 , @xmath149",
    "furthermore , by the quantizer is , by definition , a monotonically non - decreasing function .",
    "consequently , a standard result on stochastic domination  @xcite implies that @xmath150 .",
    "differentiability follows from the definition of the function .",
    "the finiteness of the variance of the quantization step is clear by construction ; more specifically , a crude upper bound is @xmath151 .",
    "thus , analogous to the previous theorems , lemma  [ fq_mon_dec ] is used to establish almost sure convergence .",
    "now , some straightforward algebra using the results of lemma  [ f_mon_rate ] shows that the partial derivative @xmath152 is @xmath153 - { \\mathbb{e}}[x ] \\ ; { \\ensuremath{\\mathbb{p}}}\\left[x - s_{k+1 } \\leq \\frac{x}{{{\\ensuremath{m } } } } \\leq x - s_{k } \\right ] \\right \\},\\ ] ]    this will be used next . to compute the asymptotic variance , we again exploit asymptotic normality ( see equation  ) as before : @xmath154 & = & { \\mathbb{e}}\\left[x { \\mathbb{i}}\\left(-\\sqrt{m}s_{k+1}\\leq \\frac{x-{\\ensuremath{\\alpha^*}}{{\\ensuremath{m } } } } { \\sqrt{m } } \\leq -\\sqrt{{{\\ensuremath{m}}}}s_{k}\\right)\\right]\\nonumber\\\\ & = & \\sqrt{m}{\\mathbb{e}}\\left[(z+{\\ensuremath{\\alpha^*}}\\sqrt{{{\\ensuremath{m}}}}){\\mathbb{i}}\\left(-\\sqrt{m}s_{k+1}\\leq z \\leq -\\sqrt{{{\\ensuremath{m}}}}s_{k}\\right)\\right]\\nonumber\\\\ & = & \\sqrt{m}{\\mathbb{e}}\\left[z { \\mathbb{i}}\\left(-\\sqrt{m}s_{k+1}\\leq z \\leq    -\\sqrt{{{\\ensuremath{m}}}}s_{k}\\right)\\right]+s\\nonumber\\\\ & \\rightarrow & -\\sqrt{{{\\ensuremath{m}}}}\\int_{\\sqrt{m}s_{k}}^{\\sqrt{m}s_{k+1 } } z \\frac{\\exp\\left(\\frac{-z^2}{2a}\\right)}{\\sqrt{2\\pi a } } dz+s \\nonumber\\\\ s & { \\ensuremath { : \\ , = } } & { \\mathbb{e}}[x]p({{\\ensuremath{m}}}(x - s_{k+1})\\leq x\\leq { { \\ensuremath{m}}}(x - s_{k}))\\end{aligned}\\ ] ]            a side note is that if one chooses @xmath158 , we are guaranteed that at least one @xmath159 does not go to zero in a fixed quantizer ( i.e. a quantizer where the levels @xmath160 do not depend on @xmath55 ) .",
    "but the correction factor expression , and as a matter of fact , the optimum quantization of gaussian , suggests that the levels @xmath161 scale as @xmath162 . in this case , the factor is a constant , independent of @xmath55 .",
    "the rate with respect to @xmath55 is the same , independent of quantization .",
    "it is clear from previous analysis that if the best quantizers are chosen @xmath171 .",
    "obviously @xmath169 over the class of optimal quantizers is a decreasing function of @xmath172 ."
  ],
  "abstract_text": [
    "<S> we consider the following problem of decentralized statistical inference : given i.i.d . </S>",
    "<S> samples from an unknown distribution , estimate an arbitrary quantile subject to limits on the number of bits exchanged . we analyze a standard fusion - based architecture , in which each of @xmath0 sensors transmits a single bit to the fusion center , which in turn is permitted to send some number @xmath1 bits of feedback . supposing that each of @xmath0 sensors receives @xmath2 observations , the optimal centralized protocol yields mean - squared error decaying as @xmath3)$ ] . </S>",
    "<S> we develop and analyze the performance of various decentralized protocols in comparison to this centralized gold - standard . </S>",
    "<S> first , we describe a decentralized protocol based on @xmath4 bits of feedback that is strongly consistent , and achieves the same asymptotic mse as the centralized optimum . </S>",
    "<S> second , we describe and analyze a decentralized protocol based on only a single bit ( @xmath5 ) of feedback . for step sizes independent of @xmath6 , it achieves an asymptotic mse of order @xmath7 $ ] , whereas for step sizes decaying as @xmath8 , it achieves the same @xmath3)$ ] decay in mse as the centralized optimum . </S>",
    "<S> our theoretical results are complemented by simulations , illustrating the tradeoffs between these different protocols .    </S>",
    "<S> * keywords : * decentralized inference ; communication constraints ; distributed estimation ; non - parametric estimation ; quantiles ; sensor networks ; stochastic approximation . </S>"
  ]
}