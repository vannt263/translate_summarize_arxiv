{
  "article_text": [
    "many vision applications are aimed at assisting in interacting with the environment . in military as well as in civilian applications , moving in an environment requires topographical knowledge : either in order to avoid obstacles or to engage targets . since",
    "this information is often inaccessible in advance , the real - time computation of a 3d map is a goal that has kept the research community busy for many years .",
    "for example , environment reconstruction is tightly related to the slam problem @xcite , which is addressed by nonlinear filtering of observed key feature locations ( e.g. @xcite ) , or by bundle adjustment @xcite . however , estimating a sparse point cloud is often insufficient , yet the transition between a discrete local distribution of 3d locations to a continuous depth estimation of the surroundings is an ongoing research topic .",
    "dynamical systems provide interesting means for incrementally estimating depth information based on the output of vision sensors , since only the current estimates are required , and image batch processing is avoided .    for our work , we are interested in recovering in real - time the depth field around the carrier under the assumptions of known camera motion and known projection model for the onboard monocular camera . the problem of designing an observer to estimate the depth of _ single or isolated keypoints _ has raised a lot of interest , specifically in the case where the relative motion of the carrier is described by constant known @xcite , constant unknown @xcite or time - varying known @xcite affine dynamics . from a different perspective , the seminal paper of @xcite performs incremental depth field refining for the whole field of view via _ iconic _ ( pixel - wise ) kalman filtering .",
    "video systems , typically found on autonomous vehicles , have successfully used this approach for refining the disparity values obtained by stereo cameras in order to estimate the free space ahead @xcite .",
    "average optical flow estimations over planar surfaces have also been used for terrain following , in order to stabilize the carrier at a certain pseudo - distance @xcite . yet , none of these methods provide an accurate dense depth estimation in a general setting concerning the environment and the camera dynamics .",
    "we propose a novel frame of methods relying on a system of partial differential equations describing the @xmath0-invariant dynamics of the brightness perceived by the camera and of the depth field of the environment .",
    "based on this invariant kinematic model and the knowledge of the camera motion , these methods provide dense estimations of the depth field at each time - step and exploit such @xmath0-invariance .",
    "the present paper is structured as follows .",
    "the invariant equations governing the dynamics of the brightness and depth fields are recalled in section  [ sec : probstat ] and their formulation in pinhole coordinates is given . in section  [ sec :",
    "varmeth ] , we adapt the horn - schunck algorithm to a variational method providing depth estimation .",
    "in section  [ sec : observer ] , we propose two asymptotic observers for depth field estimations : the first one is based on standard optical flow measures and the second one enables the refinement of rough or inaccurate depth estimations ; we prove their convergence under geometric assumptions concerning the camera dynamics and the environment . in section  [ sec : implement ] , we test these methods on synthetic data and compare their accuracy , their robustness to noise and their convergence rate ; tested on real data , this approach gives promising results .",
    "the model is based on geometric assumptions introduced in @xcite .",
    "we consider a spherical camera , whose motion is known .",
    "linear and angular velocities @xmath2 and @xmath3 are expressed in the camera frame .",
    "position of the optical center in the reference frame @xmath4 is denoted by @xmath5 .",
    "orientation versus @xmath4 is given by the quaternion @xmath6 : any vector @xmath7 in the camera frame corresponds to the vector @xmath8 in the reference frame @xmath4 using the identification of vectors as imaginary quaternions .",
    "we have thus : @xmath9 .",
    "a pixel is labeled by the unit vector @xmath10 in the camera frame : @xmath10 belongs to the sphere @xmath11 and receives the brightness @xmath12 .",
    "thus at each time @xmath13 , the image produced by the camera is described by the scalar field @xmath14 .",
    "the scene is modeled as a closed , @xmath15 and convex surface @xmath16 of @xmath17 , diffeomorphic to @xmath11 .",
    "the camera is inside the domain @xmath18 delimited by @xmath19 . to",
    "a point @xmath20 corresponds one and only one camera pixel : if the points of @xmath16 are labeled by @xmath21 , for each time @xmath13 , a continuous and invertible transformation @xmath22 enables to express @xmath10 as a function of @xmath23 : @xmath24 .",
    "the density of light emitted by a point @xmath25 does not depend on the direction of emission ( @xmath16 is a lambertian surface ) and is independent of @xmath13 ( the scene is static ) .",
    "this means that @xmath12 depends only on @xmath23 : thus @xmath26 can be seen either as a function of @xmath27 or , via the transformation @xmath28 , as a function of @xmath23 .",
    "the distance @xmath29 between the optical center and the object seen in the direction @xmath24 is denoted by @xmath30 , and its inverse by @xmath31 .",
    "fig.[fig : notations ] illustrates the model and the notations .",
    "we assume that @xmath32 is a @xmath15 function .",
    "for each @xmath13 , @xmath33 is @xmath15 since @xmath16 is a @xmath15 surface of @xmath17 .        under these assumptions",
    ", we first have : @xmath34 then @xmath35 where @xmath36 is any scalar field defined on @xmath11 and @xmath37 its gradient with respect to the riemannian metric on @xmath38 .",
    "the value of @xmath37 at @xmath39 is identified with a vector of @xmath17 tangent to the sphere at the point @xmath10 also identified to a unitary vector of  @xmath17 in the camera moving frame .",
    "the euclidean scalar product of two vectors @xmath40 and @xmath41 in @xmath17 is denoted by @xmath42 and their wedge product by @xmath43 . by differentiation ,",
    "the identity @xmath44 , where @xmath45 denotes conjugation and @xmath10 is identified to an imaginary quaternion , yields @xmath46 since the vector @xmath47 corresponds to the imaginary quaternion @xmath48 . therefore , the intensity @xmath12 and the inverse depth @xmath49 satisfy the following equations : @xmath50 @xmath51 equations and are @xmath0-invariant : they remain unchanged by any rotation described by the quaternion @xmath52 and changing @xmath53 to @xmath54 .",
    "equation is the well - known optical flow equation that can be found under different forms in numerous papers ( see @xcite or @xcite for example ) , while is less standard ( see e.g. , @xcite ) .      to use this model with camera data",
    ", one needs to write the invariant equations   and   with local coordinates on @xmath1 corresponding to a rectangular grid of pixels .",
    "one popular solution is to use the pinhole camera model , where the pixel of coordinates @xmath55 corresponds to the unit vector @xmath39 of coordinates in @xmath17 : @xmath56 .",
    "the optical camera axis ( pixel @xmath57 ) corresponds here to the direction @xmath58 .",
    "directions @xmath59 and @xmath60 correspond respectively to the horizontal axis from left to right and to the vertical axis from top to bottom on the image frame .",
    "the gradients @xmath61 and @xmath62 must be expressed with respect to @xmath63 and @xmath64 .",
    "let us detail this derivation for @xmath26 .",
    "firstly , @xmath61 is tangent to @xmath38 , thus @xmath65 .",
    "secondly , the differential @xmath66 corresponds to @xmath67 and to @xmath68 . by identification",
    ", we get the cartesian coordinates of @xmath61 in @xmath17 .",
    "similarly we get the three coordinates of @xmath69 . injecting these expressions in   and ,",
    "we get the following partial differential equations ( pde ) corresponding to   and   in local pinhole coordinates : @xmath70 \\nonumber\\\\             & - { { \\frac{\\partial y}{\\partial z_2 } } } \\left[\\begin{array}{c}(1+{z_2}^2)\\omega_1-z_1z_2\\omega_2-z_1\\omega_3\\\\ + \\gamma\\sqrt{1+z_{1}^2+z_{2}^2}(-v_2+z_2v_3)\\end{array}\\right]\\nonumber   \\label{eq : flotcart } \\end{aligned}\\ ] ]    @xmath71\\nonumber\\\\             & - { { \\frac{\\partial \\gamma}{\\partial z_2 } } } \\left[\\begin{array}{c}(1+{z_2}^2)\\omega_1-z_1z_2\\omega_2-z_1\\omega_3\\\\ + \\gamma\\sqrt{1+z_{1}^2+z_{2}^2}(-v_2+z_2v_3)\\end{array}\\right]\\nonumber\\\\ & + \\gamma^2(z_1v_1+z_2v_2+v_3)\\nonumber   \\label{eq : profcart } \\end{aligned}\\ ] ]    where @xmath72 , @xmath73 , @xmath74 , @xmath75 , @xmath76 , @xmath77 are the components of linear and angular velocities in the camera frame .",
    "in  @xcite , horn and schunck described a method to compute the optical flow , defined as `` the distribution of apparent velocities of movement of brightness patterns in an image '' .",
    "the entire method is based on the optical flow constraint written in the compact form @xmath78 identification with   yields @xmath79 with @xmath80 for each time @xmath13 , the apparent velocity field @xmath81 is then estimated by minimizing versus @xmath82 the following cost ( the image @xmath83 is a rectangle of @xmath84 here ) @xmath85 where @xmath86 is the gradient operator in the euclidian plane @xmath55 , @xmath87 is a regularization parameter and the partial derivatives @xmath88 , @xmath89 and @xmath90 are assumed to be known .    such horn - schunk estimation of @xmath91 at time @xmath13 is denoted by @xmath92 for each time @xmath13 , usual calculus of variation yields the following pde s for @xmath93 : @xmath94 with boundary conditions @xmath95 ( @xmath96 the normal to @xmath97 ) . here @xmath98 is the laplacian operator in the euclidian space @xmath55 .",
    "the numerical resolution is usually based on    * computations of @xmath89 , @xmath90 and @xmath88 via differentiation filters ( sobel filtering ) directly from the image data at different times around @xmath13 .",
    "* approximation of @xmath99 and @xmath100 by the difference between the weighted mean @xmath101 and @xmath102 of @xmath103 and @xmath104 on the neighboring pixels and their values at the current pixel ; * iterative resolution ( jacobi scheme ) of the resulting linear system in @xmath103 and @xmath104 .",
    "the convergence of this numerical method of resolution was proven in @xcite .",
    "three parameters have a direct impact on the speed of convergence and on the precision : the regularization parameter @xmath105 , the number of iterations for the jacobi scheme and the initial values of @xmath103 and @xmath104 at the beginning of this iteration step . to be specific , @xmath105",
    "should neither be too small in order to filter noise appearing in differentiation filters applied on @xmath26 , nor too large in order to have @xmath93 close to @xmath91 when @xmath106 .      instead of minimizing the cost @xmath107 given by   with respect to any @xmath108 and @xmath109 ,",
    "let us define a new invariant cost @xmath110 , @xmath111 and minimize it with respect to any depth profile @xmath112 .",
    "the time @xmath13 is fixed here and @xmath113 is the riemannian infinitesimal surface element on @xmath1 .",
    "@xmath114 is the domain where @xmath26 is measured and @xmath87 is the regularization parameter .",
    "the first order stationary condition of @xmath110 with respect to any variation of @xmath115 yields the following invariant pde characterizing the resulting estimation @xmath116 of @xmath117 : @xmath118 @xmath119 where @xmath120 is the laplacian of @xmath116 on the riemannian sphere @xmath11 and @xmath121 is the boundary of @xmath122 , assumed to be piece - wise smooth and with unit normal vector @xmath96",
    ".    in pinhole coordinates @xmath55 , we have @xmath123    where @xmath124 consequently , the first order stationary condition   reads in @xmath55 coordinates : @xmath125 \\end{split } \\label{eq : intrinsicedp}\\ ] ] on the rectangular domain @xmath126\\times [ -\\bar z_2,\\bar z_2]$ ] ( @xmath127 with @xmath128 ) .",
    "the right term of   corresponds to the laplacian operator on the riemannian sphere @xmath1 in pinhole coordinates .",
    "the numerical resolution of this scalar diffusion providing the estimation @xmath116 of @xmath117 is similar to the one used for the horn - schunck estimation @xmath93 of @xmath91 .",
    "the functional @xmath129 defined in is minimized with respect to two varying parameters @xmath108 and @xmath109 while there is really only one unknown function in this problem : the depth field @xmath117 . on the contrary ,",
    "the functional @xmath130 takes full advantage of the knowledge of the camera dynamics since the only varying parameter here is @xmath115 .",
    "from any optical flow estimation , such as @xmath93 , it is reasonable to assume that we have access for each time @xmath13 , to the components in pinhole coordinates of the vector field @xmath131 appearing in  .",
    "this vector field can be considered as a measured output for  , expressed as @xmath132 , where @xmath133 and @xmath134 are the vector fields @xmath135 this enables us to propose the following asymptotic observer for @xmath136 since it obeys to @xmath137 : @xmath138 where @xmath139 , @xmath133 and @xmath134 are known time - varying vector fields on @xmath1 and @xmath140 is a tuning parameter .",
    "this observer is trivially @xmath0 invariant and reads in pinhole coordinates : @xmath141 where @xmath91 is given by any optical flow estimation and @xmath142 are defined by  .",
    "as assumed in the first paragraphs of subsection  [ subsec : pds ] , for each time @xmath13 , there is a one to one smooth mapping between @xmath39 attached to the camera pixel and the scene point @xmath143 corresponding to this pixel .",
    "this means that , for any @xmath144 , the flow @xmath145 defined by @xmath146 defines a time varying diffeomorphism on @xmath1 .",
    "let us denote by @xmath147 the inverse diffeomorphism : @xmath148 .",
    "assume that @xmath149 , @xmath2 and @xmath150 are uniformly bounded for @xmath144 and @xmath39 .",
    "this means that the trajectory of the camera center @xmath5 remains strictly inside the convex surface @xmath16 with minimal distance to @xmath16 .",
    "these considerations motivate the assumptions used in the following theorem .",
    "[ thm : error ]    consider @xmath49 associated to the motion of the camera inside the domain @xmath151 delimited by the scene @xmath16 , a @xmath15 , convex and closed surface as explained in sub - section  [ subsec : pds ] .",
    "assume that exist @xmath152 , @xmath153 , @xmath154 and @xmath155 such that @xmath156 then , for @xmath144 , @xmath49 is a @xmath15 solution of  .",
    "consider the observer   with a @xmath15 initial condition versus @xmath10 , @xmath157 .",
    "then we have the following implications :    * @xmath158 , the solution @xmath159 of   exists , is unique and remains @xmath15 versus @xmath10 . moreover @xmath160 is decreasing ( @xmath161 stability ) . * if additionally for all @xmath21 , @xmath162 , then we have for all @xmath163 , @xmath164 ( convergence in any @xmath165 topology ) * if additionally there is @xmath166 and @xmath167 such that , for all @xmath168 and @xmath21 , @xmath169 , then we have , for all @xmath168 , @xmath170 ( exponential convergence in @xmath161 topology ) .    assumptions on @xmath171 can be seen as a condition of persistent excitations",
    ". it should be satisfied for generic motions of the camera .",
    "the facts that @xmath172 , @xmath173 and @xmath117 are bounded and that the scene surface @xmath16 is @xmath15 , closed and convex , ensure that the mapping @xmath24 and its inverse @xmath174 are @xmath15 diffeomorphism on @xmath1 with bounded derivatives versus @xmath23 and @xmath10 for all time @xmath175 . therefore , @xmath117 is also a function of @xmath176 .",
    "set @xmath177 : in the @xmath176 independent variables the partial differential equation   becomes a set of ordinary differential equations indexed by @xmath23 : @xmath178 that reads also @xmath179 with @xmath180 .",
    "thus @xmath181 .",
    "consequently , @xmath182 is @xmath15 versus @xmath23 and thus @xmath117 is @xmath15 versus @xmath10 .",
    "set @xmath183 . then @xmath184 set @xmath185 and @xmath186 .",
    "then @xmath187 consequently , @xmath188 is well defined for any @xmath175 and @xmath15 versus @xmath23 .",
    "thus @xmath189 and consequently @xmath190 are also well defined for all @xmath175 and are @xmath15 versus @xmath10 .    since for any @xmath23 and @xmath191 we have @xmath192 , we have also @xmath193 thus , taking the max versus @xmath23 , we get @xmath194    since @xmath195 we have ( @xmath196 ) . @xmath197 take @xmath198",
    ". then @xmath199 by assumption @xmath200 is bounded .",
    "thus exists @xmath201 such that @xmath202    when @xmath162 , for each @xmath23 we have @xmath203 .",
    "moreover @xmath204 is uniformly bounded by the @xmath205 function @xmath206 . by lebesgue",
    "dominate convergence theorem @xmath207 .",
    "previous inequality leads to @xmath208 .",
    "when , for @xmath209 , @xmath210 , we have , for all @xmath21 , @xmath211 .",
    "thus , for all @xmath21 we get @xmath212 . since @xmath213 is a diffeomorphism of @xmath1 , we get finally , for all @xmath39 , @xmath214 .",
    "this proves @xmath215 .      instead of relying the observer on estimation @xmath93",
    ", we can base it on @xmath116 . then   becomes ( @xmath140 )",
    "@xmath216 that reads in pinhole coordinates @xmath217 for this observer we have the following convergence result .",
    "[ thm : error_bis ] take assumptions of theorem  [ thm : error ] concerning the scene surface @xmath16 , @xmath218 , @xmath172 and @xmath173 .",
    "consider the observer   where @xmath116 coincides with @xmath117 and where the initial condition is @xmath15 versus @xmath10 .",
    "then @xmath158 , the solution @xmath159 of   exists , is unique , remains @xmath15 versus @xmath10 and @xmath219 ( exponential convergence in @xmath161 topology )    the proof , similar to the one of  theorem  [ thm : error ] , is left to the reader .",
    "the non - linear asymptotic observers described in section [ sec : observer ] are tested on a sequence of synthetic images characterized by the following :    * _ virtual camera _ : the size of each image is 640 by 480 pixels , the frame rate of the sequence is 60 hz and the field of view is 50 deg by 40 deg ; * _ motion of the virtual camera _ : it consists of two combined translations in a vertical plane ( @xmath220 ) , and the velocity profiles are sinusoids with magnitude 1  @xmath221 , and different pulsations ( @xmath222 for @xmath72 and @xmath223 for @xmath73 ) ; * _ virtual scene _ : it consists of a 4 @xmath224-plane placed at 3  m and tipped of an angle of 0.3 rad with respect to the plane of camera motion ; the observed plane is virtually painted with a gray pattern , whose intensity varies in horizontal and vertical directions as a sinusoid function ; * _ generation of the images _ : each pixel of an image has an integer value varying from @xmath59 to @xmath225 , directly depending on the intensity of the observed surface in the direction indexed by the pixel , to which a normally distributed noise varying with mean 0 and standard deviation @xmath52 is added .",
    "the virtual setup used to generate the sequence of images is represented in fig.[fig : synthetic_film_setup ] .",
    ", scaledwidth=70.0%,scaledwidth=70.0% ]    to compare the performances of both methods , we use the global error rate in the estimation of @xmath226 , defined as @xmath227 where @xmath226 is the true value of the depth field , @xmath228 is the estimation computed by any of the proposed methods and @xmath83 is the image frame .",
    "we test on the sequence described in [ ssec : sequence ] the depth estimation characterized by the partial differential equation . the optical flow input @xmath93 ( @xmath229 and @xmath230 components ) is computed by a classical horn - schunck method .",
    "note that convergence theorem  [ thm : error ] assumes that the domain of definition of the image was the entire unit sphere @xmath1 . here",
    "the field of view of our virtual camera limits this domain to a portion of the sphere @xmath83 .",
    "however , the motion of our virtual camera ensures that most of the points of the scene appearing in the first image stay in the field of view of the camera during the whole sequence .",
    "the convergence of the method is only ensured for these points , and neumann boundary conditions are chosen at the borders where optical flow points toward the inside of the ] the observer gain @xmath140 is chosen in accordance with scaling considerations .",
    "setting @xmath231 @xmath232 provides a rapid convergence rate : we see on fig .",
    "[ fig : errobs1sigma1total ] that after a few frames , the initial relative error ( blue curve ) is reduced by @xmath233 . setting @xmath234 @xmath232 is more reasonable when dealing with noisy data : on fig .",
    "[ fig : errobs1sigma20total ] initial relative error is reduced by @xmath233 after around @xmath235 frames .",
    "more precisely , the standard deviation @xmath52 of the noise added to the synthetic sequence of images is 1 .",
    "the gains @xmath231 and @xmath236 are successively tested , and the associated error rates for @xmath228 are plotted in fig .",
    "[ fig : errobs1sigma1total ] .",
    "as expected , the convergence is more rapid for a larger gain but at convergence , i.e. , after 40 frames , the relative errors are similar and below 1.5% .     estimated by the asymptotic observer filtering the optical flow input @xmath93 obtained by horn - schunck method , for different correction gains k. the noise corrupting the image data is normally distributed , with mean @xmath237 and standard deviation @xmath238 . ]    to test robustness when dealing with noisy data , the standard deviation @xmath52 is magnified by 20 .",
    "the correction gain is tuned to @xmath234 @xmath232 .",
    "the converged errors after @xmath239 frames significantly increases and yet stays between 12 and 14 % .",
    "note that such permanent errors can not decrease since such noise level first affects the optical flow estimation @xmath93 that feeds the asymptotic observer .",
    "compared to its true value @xmath91 , the error level for @xmath93 is about 15 % .",
    "these results underline the fact that this approach is sensitive to input optical flow measures , but not directly to noise corrupting the image data .",
    "estimated by the asymptotic observer filtering the optical flow input @xmath93 obtained by horn - schunck method.the noise corrupting the image data is normally distributed , with mean @xmath237 and standard deviation @xmath240 . ]      subsequently , the observer described by was applied to the same sequence .",
    "the input depth field @xmath116 is obtained as the output of . to adapt the numerical method to this model",
    ", we make the small - angle approximation by neglecting the second order terms @xmath241 ( we neglect the curvature of @xmath1 and consider that the camera image corresponds to a small part of @xmath1 that can be approximated by a small euclidean rectangle ; the error of this approximation is smaller than 3% for such rectangular image ) : becomes @xmath242 @xmath243 and @xmath244 are computed using angular and linear velocities , @xmath173 and @xmath172 , and differentiation ( sobel ) filters directly applied on the image data @xmath245 .",
    "@xmath246 is approximated by the difference between the weighted mean @xmath247 of @xmath117 on the neighboring pixels and its value at the current pixel .",
    "the resulting linear system in @xmath117 is solved by the jacobi iterative scheme , with an initialization provided by the previous estimation .",
    "the regularization parameter @xmath105 is chosen accordingly to scaling considerations and taking into account the magnitude of noise : @xmath248 @xmath221 provides a convergence in about 5 or 6 frames for relatively clean image data . as for the observer , the correction gain @xmath234 @xmath249 enables a convergence in around 20 frames .    as in section [ ssec : obs1 ] , we test the observer for different levels of noise corrupting the image data . for @xmath238 ,",
    "the error rates associated to the input depth @xmath116 and to the estimated depth @xmath228 are plotted in fig .",
    "[ fig : errobs2sigma1total ] .",
    "after only 6 images of the sequence , the error rate for @xmath116 is smaller than 4% and stays below this upper bound for the rest of the sequence . on the downside , the error rate stays larger than 2.5% . on the contrary , the error rate associated to @xmath228 keeps decreasing , and reaches the minimal value of 0.5 % .",
    "( blue ) , using the depth estimation inspired by horn - schunck , described in [ ssec : hsdepth ] and of @xmath226 ( red ) estimated by the asymptotic observer filtering @xmath116.the noise corrupting the image data is normally distributed , with mean @xmath237 and standard deviation @xmath238 . ]    for @xmath240 , the error rates associated to the input depth @xmath116 and to the estimated depth @xmath228 are plotted in fig .",
    "[ fig : errobs2sigma20total ] . for the computation of @xmath116 , the diffusion parameter @xmath105",
    "is increased to @xmath250 @xmath221 to take into account such stronger noise .",
    "the observer filters the error associated to @xmath116 ( between 4 and 8 % ) to provide a 3 % accuracy .",
    "the results show a good robustness to noise for this observer .",
    "( blue ) , using the depth estimation inspired by horn - schunck , described in [ ssec : hsdepth ] and of @xmath226 ( red ) estimated by the asymptotic observer filtering @xmath116.the noise corrupting the image data is normally distributed , with mean @xmath237 and standard deviation @xmath240 . ]      to realize the experiments , a camera was fixed on a motorized trolley traveling back and forth on a 2 meter - linear track in about 6 seconds .",
    "the resolution of the encoder of the motor enables to know the position and the speed of the trolley with a micrometric precision .",
    "the camera is a flea2 - point grey research vga video cameras ( 640 by 480 pixels ) acquiring data at 20.83 fps , with a cinegon 1.8/4.8 c - mount lens , with an angular field of view of approximately 50 by 40 deg , and oriented orthogonally to the track .",
    "the scene is a static work environment , with desks , tables , chairs , lamps , lit up by electric light plugged on the mains , with frequency 50 hz .",
    "the acquisition frame rate of the cameras produces an aliasing phenomenon on the video data at 4.17 hz . in other words ,",
    "the light intensity in the room is variable , at a frequency that can not be easily ignored , which does not comply with the initial hypothesis .",
    "however , the impact of this temporal dependence in the equations can be reduced by a normalization of the intensity of the images such as @xmath251 where @xmath252 and @xmath26 are the horizontal and vertical indexes of the pixels in the image , @xmath253 is the intensity of this pixel and @xmath254 is the mean intensity on the entire image .",
    "the depth field was estimated via the asymptotic observer   based on optical flow measures .",
    "the components of the optical flow were computed using a high quality algorithm based on tv-@xmath255 method ( see @xcite for more details ) .",
    "the correction gain was tuned to @xmath236  @xmath232 .",
    "an example of image data is shown in fig.[fig : film ] , and the depth estimate associated to that image at the same time @xmath256 is shown in fig.[fig : depth_film ] . at that specific time @xmath257",
    "s , the trolley already traveled once along the track and is on its way back toward its starting point .",
    "some specific estimates are extracted from the whole depth field ( two tables , two chairs , a screen , two walls ) and highlighted in black ; they are compared to real measures taken in the experimental room ( in red ) : the estimate depth profile @xmath258 exhibits a strong correlation with these seven punctual reference values of @xmath259 ; the global appearance of the depth field looks very realistic .        .",
    "depth is associated to a gray level , whose scale in meters is on the right .",
    "some estimates are extracted from the entire field ( in black ) and compared to real measures ( in red ) . ]",
    "in section  [ sec : probstat ] , we recalled a system of partial differential equations , describing the invariant dynamics of brightness and depth smooth fields under the assumptions of a static and lambertian environment .",
    "we proposed in section  [ sec : varmeth ] an adaptation of optical flow algorithms that take the best advantage of the @xmath0-invariance of these equations and the knowledge of camera dynamics : it yielded an @xmath0-invariant variational method to directly estimate the depth field . in section",
    "[ sec : observer ] , we proposed two asymptotic observers , respectively based on optical flow and on depth estimates .",
    "we proved their convergence under geometric and persistent excitation assumptions . on synthetic images",
    ", we showed in section  [ sec : implement ] that the variational method converges rapidly , but its performance is highly dependent of the noise level whereas both asymptotic observers filter this noise .",
    "these asymptotic obersevers based on image processing of the entire field of view of the camera seems to be an interesting tool to dense range estimation and a complement to methods based on feature tracking .",
    "m.  montemerlo , s.  thrun , d.  koller , and b.  wegbreit , `` fastslam 2.0 : an improved particle filtering algorithm for simultaneous localization and mapping that provably converges , '' in _ international joint conference on artificial intelligence ijcai _ , 2003 .",
    "d.  karagiannis and a.  astolfi , `` a new solution to the problem of range identification in perspective vision systems , '' _ automatic control , ieee transactions on _ , vol .",
    "50 , no .  12 , pp . 2074  2077 , dec . 2005 .          c.  hoilund , t.  moeslund , c.  madsen , and m.  trivedi , `` improving stereo camera depth measurements and benefiting from intermediate results , '' in _ ieee intelligent vehicles symposium _ , 2010 ,"
  ],
  "abstract_text": [
    "<S> in this paper , we use known camera motion associated to a video sequence of a static scene in order to estimate and incrementally refine the surrounding depth field . </S>",
    "<S> we exploit the so(3)-invariance of brightness and depth fields dynamics to customize standard image processing techniques . </S>",
    "<S> inspired by the horn - schunck method , we propose a so(3)-invariant cost to estimate the depth field . at each time step , this provides a diffusion equation on the unit riemannian sphere that is numerically solved to obtain a real time depth field estimation of the entire field of view . </S>",
    "<S> two asymptotic observers are derived from the governing equations of dynamics , respectively based on optical flow and depth estimations : implemented on noisy sequences of synthetic images as well as on real data , they perform a more robust and accurate depth estimation . </S>",
    "<S> this approach is complementary to most methods employing state observers for range estimation , which uniquely concern single or isolated feature points . </S>"
  ]
}