{
  "article_text": [
    "during the last years some biological features of real neurons have been incorporated into the hopfield model @xcite in order to make it more realistic and trying to improve its performance .",
    "suitable modifications of the original model taking into account biological ingredients such as thermal noise , dilution , asymmetry , dynamical delays , among others , have been vastly analized in the literature @xcite .",
    "although they usually deteriorate the retrieval ability , it has been shown they enable the implementation of new tasks , such as recognition of temporal sequences@xcite and categorization @xcite .    one crucial biological element originally absence in the hopfield model is the so called _ refractory period _ @xcite .",
    "real neurons take about 1 - 2 milliseconds to complete a cycle from the emission of a spike in the pre - sinaptic neuron to the emission of a spike in the post - sinaptic neuron . after this time , the neuron need again about 2 milliseconds to recover , and during this time , called _ absolute refractory period _ ( arp ) , it is insensitive to afferent activiy ( i.e.,it can not emit a second spike , no matter how large the post - synaptic potential ( psp ) may be ) . following this short arp ,",
    "the neuron enters in a new regime of about 5 - 7 milliseconds , in which it partially recovers the capacity of emitting spikes , but now with a greater excitation threshold which decreases with time .",
    "this is called the _ relative refractory period _ ( rrp ) . following this somewhat longer rrp",
    ", the threshold tends to return to its rest value and the neuron can fire again with typical intra - network potentials .",
    "the simplest way one can introduce these periods into the dynamics of the hopfield model is by means of a time dependent threshold acting as an external field , which depends on the recent history of the neuron .",
    "since we want this threshold to mimic the effects of fatigue observed in real neurons @xcite , it should act only after the cell has emitted an electric signal .",
    "so , we expect that the threshold depends on the mean activity of the neuron in the previous time .",
    "the main effect on the dynamics of the model is to introduce a tendency to destabilize the fixed point attractors , allowing the appearance of oscillatory behaviors . in the last years",
    "different threshold functions have been studied@xcite , showing that they enable the system to wander through the phase space , eventually visiting different basins of attraction and simulating the process by which the brain recognizes temporal sequences of patterns . on the other hand ,",
    "oscillating and chaotic trajectories in the phase space seem to be more realistic than fixed points attractors from a biological point of view ( see @xcite and references therein ) .    in this work",
    "we analyze , using a mean field approach and through numerical simulations , the behavior of the hopfield model for associative memory when the effect of these refractory periods are taken into account in the dynamics of the system . instead of considering a fatigue like threshold function that would depend on the large term history of the neuron @xcite",
    ", we introduce a threshold that depends only on the state of the neuron in the previous time , i.e. , it is activated only when the neuron fires a spike . in the section [ model ] , we introduce the model and describe how the refractory periods are incorporated into its dynamics . in section [ fixed ] , we obtain an equation for the value of the superposition between the state of the system and one of the memories ( which is only valid for fixed points dynamics ) , from which we can study the retrieval properties of the model in this region . in section",
    "[ numerical ] , we obtain a complete phase diagram and identified the regions of fixed points , cyclic orbits and chaotic orbits .",
    "we have used a synchronous parallel updating , which allows an efficient use of modern parallel - processing computers .",
    "finally , in section [ conclution ] , we discuss the main results .",
    "as in the little @xcite and hopfield models we consider a network of @xmath3 binary neurons , each one modeled by an ising variable @xmath4 which take the values @xmath5 , representing the passive and active states , respectively . in order to take into account the effect of the refractory period in the neuron @xmath6",
    "we add a threshold that depends on the time , but only through the value of the state @xmath7 of the neuron @xmath6 .",
    "so the post - synaptic potential at time @xmath8 is given by : @xmath9 where @xmath10 is the usual hopfield post - synaptic potential : @xmath11 here @xmath12 is the hopfield synaptic matrix connecting the pre and post - synaptic neurons @xmath13 and @xmath6 and whose elements have the form : @xmath14 the @xmath15 are random independent variables which take the values @xmath16 with the same probability and the n - bits words @xmath17 stand for the @xmath1 stored configurations ( @xmath18 ) .",
    "the dynamics of the network is governed by a monte carlo heat bath dynamics : @xmath19 where all the neurons are updated simultaneously ( like in the little model ) .",
    "the parameter @xmath20 measures the noise level of the net and in the noiseless limit ( @xmath21 ) we recover the deterministic dynamics : @xmath22 from this expression we can easily understand the effect of this extra field : if the neuron @xmath6 fires a spike at time @xmath8 ( @xmath23 ) , it will requires an extra contribution @xmath24 to the psp in order to fire again . on the other hand , if this neuron was at rest at time @xmath8 ( @xmath25 ) , then it will work like an usual hopfield neuron .",
    "observe that this model does not distinguish between absolute and relative periods neither includes any fatigue like effect ( long time history ) . as usual , we will characterize the recognition ability by calculating the long time behavior of the overlap @xmath26 between the state of the system @xmath27 and the stored patterns , defined as : @xmath28 where @xmath29 means a thermal average at temperature @xmath20 .",
    "we say that the system recognizes a pattern every time it evolves to an attractor for which only one overlap is non - zero and all the others vanish as ( @xmath30 ) .",
    "the two relevant parameters in our model are then @xmath31 and @xmath32 ( the ratio between the number of stored patterns ( @xmath1 ) and the total number of neurons of the network ( @xmath3 ) ) . in the following sections we analyze the behavior of the model on the ( @xmath31,@xmath32 ) plane .",
    "following the statistical method developed by geszti @xcite ( see also @xcite ) , we give in this section a heuristic derivation of the critical capacity @xmath33 as a function of the parameter @xmath24 for the stochastic version of the model . by taking the limit @xmath34",
    "we obtain a noiseless phase diagram in the ( @xmath31,@xmath32 ) plane which will be compared with numerical simulations in the next section .",
    "let us suppose that the initial state of the system is such that @xmath35 is the only macroscopically non - zero overlap and so @xmath36 for any @xmath37 .",
    "furthermore , we will assume that although the threshold tends to destabilize the fixed point attractors , its effect is not strong enough to anable the system to visit different basins of attractors .",
    "so , since initially only the first overlap was non zero , let us suppose that this will be valid for any time @xmath8 .",
    "this a priori assumption will be justified in the next section by the numerical simulation , where we will find that in the region where the system recognizes ( that is , where @xmath38 ) the dynamics of the model is dominated by fixed point attractors .",
    "we then start considering the overlap between the state of the system and the first pattern , that can be rewritten as : @xmath39 since we are storing an extensive number of pattern , we can not neglect any more the effect of the others @xmath40 overlaps : @xmath41    in order to make an self - consistent treatment for the overlap @xmath42 we need to introduce two other parameters , namely : @xmath43 where @xmath44 is the edwards - anderson order parameter and @xmath45 is indentified as the mean square overlap of the system configuration with the nonretrieved patterns @xcite .",
    "after some standard calculations we get the following set of equation for the values of @xmath42 , @xmath44 and @xmath45 _ in the attractor _ : @xmath46 where @xmath47 and @xmath48    notice that for the particular case @xmath49 we recover the equations obtained for the hopfield model @xcite which also agree with those obtained by amit et al @xcite through a thermodynamical mean - field study ( which unlike this method requires the use of the replica trick ) .",
    "we start analyzing the noiseless case @xmath50 for which we have performed numerical simulations . in this limit",
    "our equations take the following form : @xmath51 in fig .",
    "1 we display @xmath42 as function of @xmath32 for several values of @xmath31 . for any value of @xmath52 there",
    "always exists a critical value @xmath53 below which the system recovers the stored patterns with a non - zero fraction of errors @xmath54 . at @xmath55",
    "the systems undergoes a discontinuos transition from the retrieval phase ( in which the dynamics is governed by the fixed point attractors ) to a non - retrieval phase where our analytical approach is no longer valid , since the self - consistent equation does not predict a fixed point attractor ( which was our original assumption ) .",
    "observe that @xmath53 decreases as @xmath31 increases .",
    "as @xmath56 the fraction of errors at the transition @xmath57 goes to @xmath58 accordingly to the following expression : @xmath59 we have also analyzed the fixed point equations in the presence of noise . in fig .",
    "2 we present the @xmath60 phase diagram for different values of @xmath24 .",
    "for @xmath49 we recover the phase diagram obtained in @xcite . along the lines",
    "@xmath61 the system undergoes a discontinuos transition from the retrieval phase ( below ) to the non - retrieval phase ( above ) .",
    "notice that the recognition phase decreases as @xmath62 increases ; i.e. , the main effect of introducing this refractory periods seems to be a degradation of the retrieval properties of the model . in fig .",
    "3 we present the critical line @xmath20 versus @xmath24 for @xmath63 . for @xmath64",
    "the system undergoes a second order transition while for @xmath65 the transition is discontinuos ( the point @xmath66 separates both lines ) . in the inset",
    "we show the behavior the retrieval overlap around the critical point as function of @xmath20 .",
    "in this section we present a numerical study of both recognition ability and dynamical properties of the model at @xmath21 and compare it with the analitical results obtained in the previous section .",
    "the simulations were performed on systems of @xmath67 , @xmath68 and @xmath69 neurons and the network was updated synchronously . setting the initial configuration as the first stored pattern , we let the system evolve until it reaches the attractor .    in order to characterize the dynamical behavior we first determined whether the system was in a periodic orbit or not , by waiting until it returned to a given configuration that was stored after a transient .",
    "depending on the value of the parameters and on the size of the system it could also happen that the system did not return to the initial configuration after a given period of time ( typically 100 monte carlo steps ) . in such cases , we said that the system follows a chaotic orbit , although we have not performed a through analysis in order to determine whether these were really chaotic orbits or orbits with large periods .    to analyze the recognition ability we calculated for each sample a temporal average between the stored patterns and the state of the system in the attractor .",
    "if the system reached a cyclic orbit of period @xmath70 , we measured ( in the attractor ) the following quantity : @xmath71 since the initial state was chosen to be always the first memory , we say that the network recognizes when @xmath72    in order to make a configurational average of @xmath42 , for any value of the parameters we repeated this procedure over @xmath73 different samples using different memories , initial configurations and random number sequences . to characterize the dynamical behavior we present the frequency with which each kind of attractor appears and also the mean activity , defined as the average number of active neurons , in the attractor .",
    "@xmath74    in fig .",
    "4 we display the phase diagram @xmath24 vs. @xmath0 for @xmath75 . for @xmath76",
    "the system presents only fixed points ( fp ) . for fixed @xmath0 , as @xmath24 increases we found that :    1 .   for low values of @xmath31 the dynamics",
    "is governed only by fixed points attractors .",
    "the full circle indicates where this kind of behavior disappears ; 2 .",
    "the region between the two full triangles indicate the region where cycles of order two ( c2 ) appear ; 3 .",
    "the hollow circle indicates the value of @xmath31 above which chaotic orbit ( ch ) emerges .",
    "observe that there are many region of coexistence of attractors .",
    "in fact , between the c2 and the ch we have also found cyclic orbits ( oc ) of order greater than two , but they are not indicated in the diagram .    independently of the dynamical behavior , we have also studied the critical recognition capacity .",
    "the dashed line separates the recognition phase ( below ) from the non - retrieval phase ( above ) obtained numerically and the full line corresponds to the analytical results obtained in the previous section .",
    "the simulation curve fits very well the analytical result only for small values of @xmath32 .    in order to understand why the analytical and the numerical curves do not agree ,",
    "we have carefully analyzed the behavior of the system along two cuts with fixed @xmath32 , namely @xmath77 and @xmath78 . in fig .",
    "5 we plot both @xmath42 ( top ) and the frequency with which each kind of orbits appears ( bottom ) as a function of @xmath31 .",
    "the first thing we note is that the fp region coincides with the retrieval phase , and that the c2 region corresponds to the non - retrieval phase . in such cases , where the systems only recognizes through fp ,",
    "the analytical curve predicts very well the transition . on the other hand , in fig .",
    "6 we present the same curves for @xmath79 .",
    "notice now that the recognition phase presents two different dynamical behaviors : for small values of @xmath31 the system evolves to fp while for intermediate values it goes to c2 . unlike the @xmath80 case , now the theoretical curve does not predict correctly the retrieval non - retrieval phase transition , but the fp to c2 transition . in both cases",
    "we have studied the finite - size effects by working with three different sizes , namely , @xmath67 , @xmath68 and @xmath69 . in figs . 5 and 6 we present the overlaps as function of @xmath31 for all these system sizes .",
    "note that as @xmath3 increases the numerical simulation tends to display a more abrupt decay of @xmath42 at the transition , resembling the first order transition found in the analytical calculation .    finally , in fig .",
    "7 we show the mean activity as function of @xmath24 for @xmath81 and @xmath78 . we can notice that where there are fixed points and periodic orbits with recognition within , the mean activity remains around the value @xmath82 ( random variables ) and it only decreases in the transition to non - retrieval phase .",
    "this shows that the parameter @xmath24 not only damages the recognition ability but also destabilizes the tendency of the system to evolve to fixed point attractors , allowing the appearence of more complicated retrieval attractors .",
    "in this work we study analytically and through of numerical simulations a model for associative memory where we have incorporated in the dynamics of the network a new kind of threshold that simulate the effect of the refractory period .",
    "the main result is that the parameter @xmath31 that activates this threshold yields to the appearing of chaotic and periodic attractors . nevertheless , the system seems to recognizes only through fixed point and cycles of order two . only in a small region",
    "the system recognizes with higher order cycles and with chaotic trajectories , but this behavior appears just in the boundary between the retrieval and the non - retrieval phases",
    ". it would be interesting to make a more detailed study to elucidate whether this kind of trajectories are due to finite size effects or not .",
    "as much as we could see , as @xmath3 increases they do not seem to dissapear , so we suspect that they will exist also in the thermodynamical limit .    in the recognition phase ( small values of @xmath24 ) , the psp is strong enough to drive the system to stable attractors , fp and periodic orbits , where the average overlap in each regime is of the order @xmath83 . for large values of @xmath31 the performance is drastically damaged , and in these regions the dynamics is dominated by very large cycles or chaotic trajectories .",
    "the numerical simulation fits very well the analytical results only for small values of @xmath0 , where the transition occur from fixed point fp to cycle order two c2 .",
    "actually , the analytical curve seems to fit only the line where the fixed point behavior disappears .",
    "we also observe that in the transition the mean activity decreases with the increase of @xmath24 .",
    "3 we acknowledge to d. a. stariolo and f. s. de menezes for fruitful discussion .",
    "we thank the supercomputing center of the universidade federal do rio grande do sul ( cesup - ufrgs ) for use of the cray ymp-2e .",
    "this work was supported by brazilian agencies cnpq and finep .",
    "plot of @xmath42 versus @xmath0 at @xmath21 for different values of @xmath24 . at @xmath84",
    "the system undergoes a discontinuous transition from the recognition phase to non - retrieval phase . +",
    "* figure 2 .",
    "* phase diagram @xmath20 versus @xmath0 for @xmath85 and @xmath86 .",
    "below of the critical lines the system recognizes with fixed point and the transition to non - retrieval phase is discontinuos . +",
    "* figure 3 . * the critical line @xmath87 for @xmath88 . for @xmath64",
    "the transition is of second order ( full line ) while for @xmath65 the transition is discontinuos ( dashed line ) .",
    "@xmath66 is a critical point . +",
    "* figure 4 . * the numerical phase diagram @xmath24 versus @xmath0 at @xmath21 and @xmath75 , showing the regions fp ( below full circles ) , periodic ( between the two full triangles ) and ch ( above hollow circles ) .",
    "the simulation ( dashed line ) and analytical ( full line ) curves separetes the recognition phase ( below ) from non - retrieval phase ( above ) . +",
    "* figure 5 .",
    "* plot of @xmath42 ( top ) and of the frequency ( bottom ) in the which each kind of orbits appears as a function of @xmath24 for @xmath89 .",
    "the full line corresponds to the analytical curve . + * figure 6 .",
    "* plot of @xmath42 ( top ) and of the frequency ( bottom ) in the which each kind of orbits appears as a function of @xmath24 for @xmath90 .",
    "the full line corresponds to the analytical curve .",
    "+ * figure 7 . * the mean activity vs. @xmath24 for @xmath89 and @xmath90 .",
    "j. hopfield , _ proc .",
    "usa _ * 79 * , 91 ( 1982 ) .",
    "d. j. amit , h. gutfreund and h. sampolinsky , _ phys . rev .",
    "a. _ * 32 * , 1007 ( 1985 ) .",
    "d. j. amit , h. gutfreund and h. sampolinsky , _ phys . rev .",
    "_ * 55 * , 1530 ( 1985 ) .",
    "d. amit , j. gutfreund and h. sompolinsky , _ ann .",
    "phys . _ * 173*,30 ( 1987 ) .",
    "b. derrida , e. gardner and a. zippelius , _ europhys .",
    "lett . _ * 4 * , 167 ( 1987 ) .",
    "t. l. h. watkin and d. sherrington , _ j. phys . a : math .",
    "* 24 * , 5427 ( 1991 ) .",
    "h. gutfreund and m. mezard , _ phys .",
    "* 61 * , 235 ( 1988 ) .",
    "h. sompolinsky and i. kanter , _ phys .",
    "_ * 57 * , 2861 ( 1986 ) .",
    "j. buhmann k. schulten , _ europhys .",
    "lett . _ * 4 * , 1205 ( 1987 ) .",
    "david kleinfeld , _ proc .",
    "usa _ * 83 * , 9469 ( 1986 ) .",
    "d. horn and m. usher , _ phys .",
    "rev . a _ * 40 * , 1036 ( 1989 ) ; d. horn , _ physica a _ * 200 * , 594 ( 1993 )",
    ". f. zertuche , r. lpes - pea and h. waelbroech , _ j. phys . a : math .",
    "* 27 * , 5879 ( 1994 ) .",
    "j. f. fontanari , _",
    "j. physique i _ * 51*,2412 ( 1990 ) .",
    "d. a. stariolo and t. a. tamarit , _ phys .",
    "* 43 * , 5249 ( 1992 ) . c. r.",
    "da silva , f. a. tamarit , n. lemke , j. j. arenzon and e. m. f. curado , _ j. phys . a : math .",
    "_ * 28 * , 1593 ( 1995 ) .",
    "d. j. amit _ modeling brain function_,(cambridge university press , cambridge,1989 ) . j. buhmann k. schulten , _ biol . cybern . _ * 54 * , 319 ( 1986 ) .",
    "k. airaha , t.takabe and m. toyoda , _ phys.lett .",
    "a _ * 144 * , 333 ( 1990 ) .",
    "j. moreira and d. auto , _ europhys .",
    "* 21 * 693 ( 1993 ) .",
    "i. opris , _ phys .",
    "e _ * 51 * , 2619 ( 1995 ) .",
    "k. e. krten , _ phys.lett . a _ * 129 * , 157 ( 1988 ) . w. a. little._math .",
    "* 19 * , 101 ( 1974 ) .",
    "t. geszti , _ physical models of neural network _ , ( singapure : world scientific , 1990 ) .",
    "p. peretto , _ j. phys",
    ". france _ * 49 * , 711 ( 1998 ) .",
    "j. hertz , a. krogh and r. g. palmer _ introduction to the theory of neural computation _",
    "( reading , ma : addison - wesley 1991 ) .",
    "f. zertuche , r. lpes and h. waelbroech , _ j. phys . a : math .",
    "gen . _ * 27 * , 1575 ( 1994 ) c. m. marcus , f. r. waugh and r. m. westervelt , _ phys .",
    "a _ * 41 * , 3355 ( 1990 ) ."
  ],
  "abstract_text": [
    "<S> we study both analytically and numerically the effects of including refractory periods in the hopfield model for associative memory . </S>",
    "<S> these periods are introduced in the dynamics of the network as thresholds that depend on the state of the neuron at the previous time . </S>",
    "<S> both the retrieval properties and the dynamical behaviour are analized , and we found that depending on the value of the thresholds and on the the ratio @xmath0 between the number of stored memories ( @xmath1 ) and the total number of neurons @xmath2 ) , the system presents not only fixed points but also chaotic or ciclic orbits . </S>",
    "<S> keywords : neural networks , refractory periods , chaotic orbits pacs : 87.10+e  64.60c  </S>",
    "<S> 75.10hk    - 0.5 in </S>"
  ]
}