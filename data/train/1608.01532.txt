{
  "article_text": [
    "a substantial literature approaches dyadic interactions between agents by means of models featuring agent - specific parameters .",
    "the bradley - terry model for paired comparisons of @xcite and @xcite and the @xmath0-model for network formation with degree heterogeneity ( @xcite ; @xcite ) are two classic examples .",
    "the use of fixed - effect models for network data is now widespread in empirical work .",
    "applications include studies of risk sharing ( @xcite ) , sorting between workers and firms in the labor market ( @xcite ) , and the interaction between students and teachers ( @xcite ; @xcite ) , as well as the analysis of trade flows ( @xcite ; @xcite ) .    the structure of the network , that is , who interacts with whom and to which extent , differs strongly across applications . while rather dense networks might be observed in the analysis of financial markets ( @xcite ) , sparse networks  i.e . , networks with relatively few links ",
    "are typically the norm in networks of friendship or trust @xcite .",
    "the network structure is also an important determinant of the accuracy of statistical inference .",
    "one important illustration is given by fixed - effect regressions of log wages on matched employer - employee data @xcite .",
    "there , estimated worker and firm effects are typically found to be negatively correlated ( @xcite ; @xcite ) , which is in contrast with economic intuition .",
    "the origin of this negative assortative matching puzzle is limited - mobility bias ( @xcite ; @xcite ) , that is , the fact that , throughout their working history , workers are employed in only few firms . moreover , even though linked data sets are typically very large , the worker fixed effects are estimated from very small subsamples .",
    "we are not aware of studies of the statistical accuracy of fixed - effect estimators in the network literature .",
    "a chief reason would appear to be that the structure of a network becomes complex very fast and so it is rather difficult to see how data carries information about certain parameters . in this paper",
    "we analyze this issue in the context of a linear version of the @xcite model .",
    "the linear regression model contains all the main features of the typical models for network data , yet is sufficiently simple to lend itself to careful analysis .",
    "we use results from graph theory to show that the variance of the fixed - effect estimator is related to the laplacian of the network . a bound on the variance of the fixed - effect estimator",
    "is obtained that depends inversely on the smallest non - zero eigenvalue of the ( normalized ) laplacian .",
    "this eigenvalue is a measure of connectivity of the network .",
    "the larger it is , the more dense is the network",
    ". one interesting consequence of this bound is that consistent estimation is possible even if the network becomes less connected as the sample grows .",
    "eigenvalues of network matrices have previously been found to be important in determining equilibrium conditions in games on networks @xcite but our result seems the first to uncover their importance for statistical inference .",
    "we next refine the variance bound to uncover how the local structure of the network around a given vertex influences the variance of the vertex - specific parameter estimator .",
    "clearly , the variance of such an estimator is decreasing in the degree of the vertex  the number of edges that originate or arrive in it  that is , the number of neighbors of the vertex . the improved bounds , however , uncover the sensitivity of the variance with respect to the degree of the neighbors of the vertex .",
    "a potential issue with a global connectivity measure such as the smallest non - zero eigenvalue is that it can lead to variance bounds that are overly conservative .",
    "a leading situation where this will be the case is when the network consists of clusters , so that units within a cluster are strongly connected , but the clusters are connected by relatively few links with each other . to deal with such cases we consider within - between decompositions of the network as a way to characterize the variance in terms of the eigenvalues within each cluster and the number of links across clusters .    in section [ sec:2 ]",
    "we introduce the model and estimator under study . in section [ sec:3 ]",
    "we derive bounds on the variance of the estimator . in section [ sec:4 ]",
    "we provide corresponding bounds for parameter differences .",
    "in section [ sec:5 ] we present our results on within - between decompositions of the network . in section",
    "[ sec : weighted ] we discuss weighted graphs .",
    "concluding remarks end the paper .",
    "an [ app : secondorderbound ] contains additional results .",
    "all technical proofs are available as supplementary material .",
    "consider a graph @xmath1 where @xmath2 edges are placed between @xmath3 vertices .",
    "we will work with a simple undirected graph without loops . without loss of generality",
    "we label the vertices by natural numbers , so @xmath4 .",
    "the set @xmath5 contains the @xmath6 unordered pairs @xmath7 from the product set @xmath8 that are connected by an edge , where we assume throughout that @xmath9 .",
    "vertices @xmath10 and @xmath11 are said to be connected if @xmath12 contains a path from @xmath10 to @xmath11 , and the graph @xmath12 is said to be connected if every pair of vertices in the graph is connected .",
    "our interest lies in estimating a linear regression model where outcomes are labelled by elements of @xmath5 . for each @xmath13",
    ", we observe the real - valued outcome @xmath14 where @xmath15 are vertex - specific parameters to be estimated and the @xmath16 are unobserved disturbances with unknown variance @xmath17 .",
    "equation is overparametrized , so we impose that @xmath18 the choice of normalization on the @xmath19 is not unique but is conventional ( see , e.g. , @xcite ) and will prove convenient for our purposes .",
    "equation is similar to a regression version of the classic @xcite model for paired comparisons .",
    "consider an extended version of the classic @xcite model , where the probability that team @xmath10 wins against team @xmath11 equals @xmath20 for @xmath21 .",
    "the odds ratio is @xmath22 this equation fits with @xmath23 and is estimable provided the @xmath24 are observed ( or estimable ) .",
    "one situation where this model arises is in repeated interactions in the bradley - terry setting .",
    "suppose that teams @xmath10 and @xmath11 meet multiple times and that , at encounter @xmath25 , @xmath26 where @xmath27 .",
    "then @xmath24 can be recovered nonparametrically @xcite .",
    "note that , here , @xmath19 and @xmath28 represent team - specific heterogeneity while @xmath29 captures heterogeneity that is specific to the match - up .",
    "[ ex : workerfirm ] partition @xmath30 as @xmath31 and consider a bipartite graph .",
    "that is , suppose that @xmath5 is a subset of the product set @xmath32",
    ". then edges are formed between the vertex sets @xmath33 and @xmath34 but not within @xmath33 and @xmath34 .",
    "so , for an edge @xmath7 we necessarily have that @xmath35 and @xmath36 .",
    "a leading example of a regression model here are wage regressions as in @xcite , where the log wage of worker @xmath10 in firm @xmath11 decomposes as @xmath37 for worker effects @xmath38 and firm effects @xmath39 . to obtain we set @xmath40 choosing the sign in front of @xmath41 is without loss of generality here because the graph under consideration is bipartite ;",
    "links are only formed between , but never within , @xmath33 and @xmath34 .",
    "we extend this example to panel data , where workers and firms are observed over multiple time periods , later .",
    "the literature on estimation of fixed - effect models for network data typically assumes that @xmath42 , that is , that each vertex is connected to all other vertices by a path of length one ; see @xcite and @xcite for results on the @xcite model , @xcite and @xcite for work on network - formation models , and @xcite for two - way models for panel data . in this case ,",
    "distribution theory for the maximum - likelihood estimator of the @xmath19 in would be rather standard , with the estimator of each of the @xmath19 being unbiased , normally distributed , and converging at the @xmath43-rate . in this paper we specifically study the case of an incomplete graph .",
    "our aim is to see how the structure of @xmath12 affects the precision of statistical inference .",
    "as of yet , this is an unexplored issue in the literature .",
    "allowing for incomplete graphs is important , as data , where all vertices interact , is rare . in country - level data on bilateral trade , for example , only around half of the potential trade flows are realized .",
    "similarly , in the bipartite graphs of workers and firms in example  [ ex : workerfirm ] , each worker is related to at most a handful of firms .",
    "finally , friendship networks are typically sparse ; see , for example , the data of @xcite .",
    "while the model in may appear overly restrictive , we note that certain features are not essential to the following analysis . for example",
    ", the presumption of normality and the assumption of homoskedastic disturbances could easily be dispensed with .",
    "they are introduced here as they allow us to focus on exact finite - sample inference . also , everything to follow",
    "can be modified to hold for weighted graphs .",
    "one example would be a situation where we observe multiple outcomes for each @xmath13 .",
    "we will come back on each of these issues in more detail at a later stage .",
    "our choice of is motivated by a desire to concentrate on a setting that contains all essential features of a fixed - effect model for random graphs while at the same time connecting as much as possible to the literature on graph theory .      in the following",
    "we will work under the convention that @xmath44 for @xmath45 .",
    "this choice imposes an orientation on the graph @xmath12 , and the corresponding oriented incidence matrix of @xmath12 is the @xmath46 matrix @xmath47 with entries @xmath48 the incidence matrix fully describes @xmath12 .",
    "note that the oriented incidence matrix is unique up to negation of any of the columns , since negating the entries of a rows corresponds to reversing the orientation of an edge .",
    "moreover , the analysis to follow is invariant to our choice of orientation . indeed",
    ", changing the orientation of the edge @xmath7 jointly with the sign of @xmath49 leaves model   invariant . throughout , the network structure",
    "is treated as fixed , that is , @xmath47 is conditioned on .",
    "let @xmath50 .",
    "collect all outcomes in the @xmath51-vector @xmath52 and all regression errors in the @xmath51-vector @xmath53 .",
    "write @xmath54 for the @xmath55-vector of ones and @xmath56 for the @xmath57 identity matrix . equations ",
    "can then be written as @xmath58 subject to @xmath59 because of normality of @xmath53 , the maximum - likelihood estimator of @xmath60 is equal to the ( ordinary ) least - squares estimator , that is , @xmath61 where @xmath62 denotes the euclidean norm .",
    "we first address existence and uniqueness of @xmath63 . here and later",
    ", we let @xmath64 denote the moore - penrose pseudoinverse of matrix @xmath65 .    [ lemma : existence ] let @xmath12 be connected .",
    "then @xmath66 and is unique .",
    "equals @xmath67 , and so the expression for the estimator could be shortened .",
    "our choice to highlight the longer formulation in the lemma is motivated by the developments to follow , where the matrix @xmath68 features prominently . ]",
    "the need for a pseudoinverse arises because @xmath69 is singular , as @xmath70 .",
    "the use of the moore - penrose pseudoinverse follows from our normalization choice on @xmath60 , that is , @xmath71 .",
    "the result of the lemma is intuitive .",
    "if @xmath12 is connected , then @xmath72 must hold , and the zero eigenvalue of @xmath68 has multiplicity one and corresponding eigenvector @xmath73 ; see our discussion of the laplacian matrix below .",
    "if @xmath12 is disconnected our analysis for @xmath63 could be applied separately to each connected component .",
    "the following theorem is immediate .",
    "[ thm : ols ] let @xmath12 be connected .",
    "then @xmath74 for any @xmath55 .",
    "the main implication of theorem [ thm : ols ] is the sampling distribution of the conventional @xmath75-statistic for testing linear hypotheses on @xmath60 .",
    "[ cor : inference ] let @xmath76 be an @xmath77 matrix of maximal column rank that is linearly independent of @xmath54 .",
    "if @xmath12 is connected , then @xmath78 follows an @xmath75-distribution with parameters @xmath79 and @xmath80 .",
    "the @xmath75-statistic can be used to test the null hypothesis that @xmath81 against the alternative that @xmath82 .",
    "the requirement that @xmath76 is linearly independent of @xmath54 is needed because @xmath83 holds by construction .",
    "the degrees of freedom being @xmath80 rather than @xmath84 is for the same reason .",
    "corollary [ cor : inference ] shows that test statistics and confidence bounds constructed in the usual way will have correct coverage .",
    "this is a direct consequence of theorem [ thm : ols ] .",
    "these results , however , do not aid in understanding when test statistics will have low power or when confidence bounds will be wide . in the sequel we aim to understand how the structure of the network affects the standard error of the least - squares estimator .",
    "such an analysis is also a useful aid when setting up sampling designs .",
    "furthermore , it also yields conditions for consistent estimation and asymptotically - valid inference under non - normality for sequences of growing networks .",
    "theorem [ thm : ols ] shows that , up to the scalar factor @xmath17 , the variance of @xmath63 is completely determined by the @xmath85 laplacian matrix of @xmath12 , @xmath86 where @xmath87 is the degree matrix and @xmath88 is the @xmath85 adjacency matrix of @xmath12 , with entries @xmath89 note that @xmath90 , the degree of @xmath10 , equals the number of vertices that vertex @xmath10 is connected to",
    ".    it will be convenient to work with the normalized laplacian @xmath91 we have @xmath92 , and so @xmath93 equation highlights the importance of the degree @xmath90 , which is the effective number of observations that are used to infer @xmath19 .",
    "however , does not imply that @xmath94 shrinks as @xmath95 , nor would it give a convergence rate if it did , as the normalized laplacian matrix of @xmath12 , too , changes when @xmath55 grows .      to make progress on bounding the variance ,",
    "let @xmath96 denote the @xmath10th eigenvalue of @xmath97 , arranged in increasing order ; so , @xmath98 . from ( * ? ?",
    "* lemma 1.7 ) we have @xmath99 and @xmath100 .",
    "zero is always an eigenvalue of @xmath97 because @xmath101 , but , if @xmath12 is connected , it has multiplicity one . that is , @xmath102 is the smallest non - zero eigenvalue of the normalized laplacian when @xmath12 is connected . as a simple example , @xmath103 when @xmath12 is complete , that is , when @xmath42 .    the following result bounds the variance of @xmath104 as a function of @xmath105 .",
    "[ thm : eigenvaluebound ] let @xmath12 be connected .",
    "then @xmath106    the theorem follows from and the fact that @xmath107 , where @xmath108 refers to the spectral norm ; see the proof in the supplementary material for further details .",
    "we note that , analogous to lemma  [ thm : eigenvaluebound ] , we can also show that @xmath109 where @xmath110 is the smallest non - zero eigenvalue of the ( unnormalized ) laplacian @xmath111 . in the graph literature , the spectrum of @xmath111 has been the subject of more study than that of @xmath97 .",
    "however , @xmath112 thus , @xmath110 may be very small  and the corresponding bound on @xmath113 very large  as soon as a single vertex in @xmath30 has a small degree , making it an unattractive quantity for our purposes .    to interpret the bound",
    "it is useful to connect it to the cheeger constant , @xmath114 the constant @xmath115 $ ] reflects how difficult it is to disconnect @xmath12 by removing edges .",
    "moreover , a larger value of @xmath116 implies a more strongly - connected graph . from (",
    "* theorems 2.1 and 2.3 ) , @xmath117 hence , theorem  [ thm : eigenvaluebound ] states that inference will be more precise when the graph is more strongly connected .",
    "theorem [ thm : eigenvaluebound ] also allows to derive some asymptotic properties under sequences of growing networks @xmath118 .",
    "first , we find the pointwise consistency result @xmath119 this result allows @xmath120 as @xmath121 .",
    "second , letting @xmath122 be the harmonic mean of the sequence @xmath123 , we have @xmath124 and so @xmath125 by an application of markov s inequality .",
    "[ ex : er ] consider the @xcite random - graph model , where edges between @xmath55 vertices are formed independently with probability @xmath126 .",
    "the threshold on @xmath126 for @xmath12 to be connected is @xmath127 .",
    "that is , if @xmath128 for a constant @xmath129 , then , as @xmath130 , with probability approaching one , @xmath12 is disconnected if @xmath131 and connected if @xmath132 @xcite . in the former case , @xmath120",
    "while , in the latter case , @xmath133 , almost surely ; see ( * ? ?",
    "? * theorem 1.1 ) . and ( * ? ? ?",
    "* corollary 1.2 ) .",
    "we next proceed by refining the variance bound in theorem  [ thm : eigenvaluebound ] to take into account the local structure of the graph around vertex @xmath10 .",
    "a refinement of theorem  [ thm : eigenvaluebound ] takes into account the connectivity of the direct neighbors of @xmath10 . here",
    ", we call a direct neighbor , or a path - one neighbor , a vertex to which @xmath10 is connected via a path of length one .",
    "similarly , we will call those vertices that have geodesic distance equal to two from @xmath10 path - two neighbors of @xmath10 .",
    "the collection of direct neighbors of vertex @xmath10 is @xmath134 : = \\lbrace j\\in v : ( i , j)\\in e \\text { or } ( j , i)\\in e \\rbrace;\\ ] ] note that @xmath135 \\rvert = d_i$ ] . let @xmath136 } \\frac{1}{d_j } \\right)^{-1 } ,      \\label{defharmonicmean}\\end{aligned}\\ ] ] the harmonic mean of the degrees of all @xmath137 $ ]",
    ". note that , for a given vertex @xmath10 , @xmath138 is increasing in the degree of its direct neighbors .",
    "[ thm : firstorderbound ] let @xmath12 be connected .",
    "then @xmath139    theorem [ thm : firstorderbound ] states that , for a given degree @xmath90 and global connectivity measure @xmath105 , the upper bound on the variance of @xmath140 is smaller if the direct neighbors of vertex @xmath10 are themselves more strongly connected to other vertices in the network .",
    "another implication of the theorem is the rate refinement @xmath141 provided that @xmath142 as @xmath143 .",
    "furthermore , the parametric rate is achievable even if @xmath105 is not treated as fixed",
    ".    in the [ app : secondorderbound ] we present a refinement of theorem [ thm : firstorderbound ] that accounts for the dependence on @xmath138 in the lower bound as well , and also adjusts the upper bound for overlap between @xmath144 $ ] and the sets @xmath145,\\ldots,[j_{d_i}]$ ] for @xmath146 $ ] , that is , for common neighbors .",
    "these bounds can be particularly useful when @xmath138 is small , but are vacuous when all path - two neighbors of vertex @xmath10 are also path - one neighbors .",
    "this is the case , for example , in the complete graph , where all vertices are direct neighbors .",
    "we illustrate the usefulness of improving on theorem [ thm : eigenvaluebound ] in our running example of a random graph .",
    "[ ex : er]consider the @xcite random - graph model with @xmath147 for @xmath132 .",
    "let @xmath10 be a randomly chosen vertex .",
    "then , as @xmath130 , we have , almost surely , @xmath148 consequently , @xmath149 follows from theorem [ thm : firstorderbound ] .",
    "the next example deals with an analytically - tractable case where @xmath150 as @xmath143 .",
    ".5     .5     [ ex : hypercube ] consider the @xmath151-dimensional hypercube , where each of @xmath152 vertices is involved in @xmath151 edges ; see the left hand side of figure [ fig : hypercubes ] .",
    "this is an @xmath151-regular graph  that is , @xmath153 for all @xmath10  with the total number of edges in the graph equaling @xmath154 . here",
    ", @xmath155 thus , @xmath156 is constant in @xmath55 .",
    "an application of theorem [ thm : firstorderbound ] yields @xmath157 from this , we obtain the convergence rate result @xmath158 , but the bounds are not sufficient to determine the leading order asymptotic variance of @xmath159 .",
    "however , using the bound in theorem  [ thm : secondorderbound ] of the [ app : secondorderbound ] one obtains @xmath160 , that is , holds .",
    "see the [ app : secondorderbound ] for details .",
    "theorem [ thm : firstorderbound ] allows to establish the convergence rate for the hypercube , but the conditions are too stringent to obtain .",
    "this is so because @xmath138 does not increase fast enough to ensure that @xmath161 .",
    "the following example illustrates that despite @xmath150 we can still have @xmath161 .",
    "start with the @xmath151-dimensional hypercube @xmath118 from the previous example and add edges between all path - two neighbors in @xmath118 ; see the right hand side of figure [ fig : hypercubes ] for an example .",
    "the resulting graph still has @xmath152 vertices , but now has @xmath162 edges . here ,",
    "@xmath163 so that @xmath161 holds , despite @xmath150 as @xmath130 .",
    "theorem  [ thm : firstorderbound ] therefore implies in this example .",
    "the next example illustrates that the first - order bounds can still be informative in situations where @xmath138 does not converge to infinity .    .5 .,title=\"fig : \" ]",
    ".5 .,title=\"fig : \" ]    [ ex : star ] consider a star graph around the central vertex @xmath164 , that is , the graph with @xmath55 vertices and edges @xmath165 see the left hand side of figure [ fig : starwheel ] . here , @xmath166 for any @xmath55 while @xmath167 , @xmath168 and @xmath169 , @xmath170 for @xmath171 .",
    "for @xmath172 one finds that the bounds in theorem  [ thm : firstorderbound ] imply that @xmath173 , and so @xmath174 in contrast , for @xmath175 we find @xmath161 and thus , although holds , these @xmath19 can not be estimated consistently as @xmath176 .",
    "our last example shows the effect on the upper bound in theorem [ thm : firstorderbound ] when neighbors themselves are more strongly connected .",
    "[ ex : wheel ] the wheel graph is obtained on combining a star graph centered at vertex @xmath164 with a cycle graph on the remaining @xmath177 vertices ; see the right hand side of figure [ fig : starwheel ] .",
    "thus , a wheel graph contains strictly more edges than the underlying star graph , although none of these involve the central vertex directly . from @xcite",
    ", we have @xmath178 which satisfies @xmath179 only for @xmath180 , and converges to @xmath181 at an exponential rate .",
    "however , while , as in the star graph , @xmath167 , we now have that @xmath182 for all @xmath171 .",
    "hence , @xmath183 for any finite @xmath55 and the upper bound in theorem [ thm : firstorderbound ] is strictly smaller than in the star graph .",
    "the bounds in theorem  [ thm : firstorderbound ] continue to hold when the errors in are non - normal , as the variance of @xmath140 depends only on the first and second moments of the data .",
    "the asymptotic statements obtained in the previous subsection , too , carry over .",
    "we now want to briefly discuss how the results can be extended to also allow for heteroskedasticity and correlation in the error term . if we only assume that @xmath184 we have the following result .",
    "[ thm : firstordergeneralized ] suppose that is weakened by imposing only .",
    "let @xmath12 be connected .",
    "then @xmath185 } u_{ij } + \\epsilon_i \\ , , \\ ] ] where @xmath186 and @xmath187 .",
    "it follows that @xmath188 if @xmath189 } u_{ij } \\overset{d}{\\rightarrow } \\mathcal{n}(0,\\omega_i^2)$ ] for finite @xmath190 , provided @xmath191 , which follows from @xmath142 and @xmath192 .",
    "thus , the key asymptotic condition that @xmath142 is unchanged compared to the previous subsection . the corresponding discussion and examples are thus also applicable to the more general situation of heteroscedastic and weakly correlated errors , but now with @xmath190 featuring in the asymptotic variance .",
    "our focus thus far has been inference on the @xmath19 , under the constraint in , @xmath193 .",
    "an alternative to normalizing the parameters that may be useful in certain applications is to focus directly on the differences @xmath194 for all @xmath195 @xcite .",
    "we give corresponding versions of theorem  [ thm : eigenvaluebound ] and theorem [ thm : firstorderbound ] here .",
    "the resistance distance between vertices @xmath10 and @xmath11 in @xmath12 is @xmath196 @xcite , and is a metric on the set @xmath30 @xcite .",
    "it is linked to the commute distance , say @xmath197 , which is the expected time it takes for a random walk to travel from @xmath10 to @xmath11 and back again , through the relation @xmath198 see , e.g. , @xcite .",
    "for example , vertices in different clusters of a graph have a large commute distance , relative to vertices in the same cluster of the graph .",
    "the precise connection between the magnitude of these quantities and the precision of statistical inference is @xmath199 this is the equivalent of for differences .",
    "the counterpart to theorem  [ thm : eigenvaluebound ] is intuitive .",
    "[ thm : eigenvaluebound2 ] let @xmath12 be connected .",
    "then @xmath200 for all @xmath195 .",
    "let @xmath201 \\cap [ j ] \\right|$ ] be the number of vertices that are neighbors of both @xmath10 and @xmath11 . write @xmath202 \\cap [ j ] }    \\frac 1 { d_k } \\bigg)^{-1 }    & \\text{for $ d_{ij } \\neq 0 $ } , \\\\",
    "\\infty & \\text{for $ d_{ij } = 0 $ } , \\end{array } \\right.\\end{aligned}\\ ] ] for the corresponding harmonic mean of the degrees of the vertices @xmath203 \\cap [ j]$ ] .",
    "we have the following theorem .",
    "[ thm : firstorderbound2 ] let @xmath12 be connected .",
    "then @xmath204    one implication of the theorem is that , when @xmath144=[j]$ ] but @xmath205 $ ] and @xmath205 $ ] , that is , when vertices @xmath10 and @xmath11 share exactly the same neighbors and are not connected themselves , we have @xmath206 as , in that case , both @xmath207 and the second term in the upper bound in theorem [ thm : firstorderbound2 ] are zero .",
    "theorem [ thm : firstorderbound2 ] is related to work on the amplified commute distance by @xcite , which they propose as an alternative to the commute distance in large graphs .",
    "however , their results are restricted to the class of random geometric graphs and are purely asymptotic in nature . here ,",
    "we provide finite - sample bounds for arbitrary connected graphs , using @xmath105 as a measure of global connectivity .",
    "the variance bounds obtained so far depend on @xmath105 , which is a global measure of connectivity .",
    "moreover , for a given vertex @xmath10 , we require @xmath208 for our bounds to yield the first - order asymptotic variance .",
    "the value of @xmath105 may be rather low even if most vertices are rather densely connected .",
    "consequently , theorem [ thm : firstorderbound ] and theorem [ thm : firstorderbound2 ] may be overly conservative .",
    "a leading situation where this will be the case is when the network consists of clusters , so that units within a cluster are strongly connected but the clusters themselves are connected by relatively few links . as a remedy , in this section",
    "we obtain bounds on the variance of @xmath140 that are based on partitioning the graph into subgraphs .",
    "consider a graph @xmath209 .",
    "partition @xmath30 into @xmath210 non - empty subsets @xmath211 . for each @xmath212 , let @xmath213 , the set of edges connecting all vertices in @xmath214 , so that @xmath215 denotes the subgraph of @xmath12 that is induced by @xmath214 .",
    "note that none of these subgraphs have a vertex in common . throughout this section",
    "we assume that @xmath12 and each of @xmath216 are connected .",
    "let @xmath217 and @xmath218 . the graph @xmath12 can then be decomposed as @xmath219 for @xmath220 and @xmath221 this is what we call a within - between decomposition of the graph @xmath12 ; the graph @xmath222 consists of @xmath210 connected components , @xmath216 , and the graph @xmath223 connects these @xmath210 isolated components",
    ". we will let @xmath224 and denote by @xmath225 the number of edges in @xmath226 .",
    "our variance bounds in terms of @xmath105 turn out to be conservative when @xmath227 is small .",
    "[ ex:2split ] partition @xmath30 into two sets @xmath33 and @xmath34 .",
    "an example is given in figure [ fig : partition2 ] .",
    "using , we find @xmath228 suppose that @xmath229 , so that all degrees grow at the same rate as @xmath121",
    ". then @xmath142 requires that @xmath230 in this section we show that the actually - required condition for the rate result in in this setting is @xmath231 which is considerably weaker .",
    "[ ex : er]specialize example [ ex:2split ] by assuming that @xmath232 and @xmath233 are both erds - rnyi graphs with @xmath234 of equal size , that is , @xmath235 .",
    "then @xmath236 which highlights the importance of the improvement of over .    to make use of the partitioning @xmath237 we decompose @xmath238 accordingly .",
    "we let @xmath239 for all @xmath240 and each @xmath212 . we let",
    "@xmath241 and @xmath242 .",
    "the relation between both these vectors and @xmath243 can then be succinctly stated as @xmath244 this decomposition gives an alternative ( infeasible ) estimator of @xmath60 based on estimators of the within parameter @xmath245 and the between parameter @xmath246 .",
    "the estimator of @xmath245 is simply the least - squares estimator applied to the subgraph @xmath222 , subject to the proper normalization constraints , namely @xmath247 similarly , an ( infeasible ) least - squares estimator for @xmath248 , which assumes @xmath249 to be known , equals @xmath250 where we write @xmath251 to denote the map @xmath252 that satisfies @xmath253 .",
    "note that these estimators are statistically independent of each other .",
    "the sampling variability of these estimators can be studied , and can be used to sharpen our results on the statistical accuracy of @xmath63 .",
    "let @xmath254 and @xmath255 be the @xmath256 laplacian matrices of the graphs @xmath257 and @xmath258 , respectively .",
    "we also introduce @xmath259 and the @xmath260 matrix @xmath261 which is the laplacian matrix of the multigraph @xmath262 with vertex set @xmath263 , obtained from @xmath118 by edge contraction of the subgraphs @xmath264 , @xmath265 .",
    "analogous to theorem  [ thm : ols ] for @xmath63 one can show the following lemma .",
    "[ lemma : var_decomposition ] let @xmath118 and @xmath216 be connected . then @xmath266 for @xmath267 . is a pseudoinverse of @xmath268 , but unless @xmath269 it is not the moore - penrose pseudoinverse . ]",
    "if we label the elements of @xmath30 such that @xmath270 , @xmath271 , etc , then @xmath254 is a block - diagonal matrix with @xmath210 non - zero blocks given by @xmath272 , the laplacian of @xmath264 , @xmath212 .",
    "the moore - penrose inverse @xmath273 is also block - diagonal with @xmath210 non - zero blocks given by @xmath274 .",
    "the first part of lemma  [ lemma : var_decomposition ] therefore is simply theorem  [ thm : ols ] applied separately to each of the connected components of @xmath257 , and all our results from the previous sections apply .",
    "for example , with @xmath275 the degree of vertex @xmath10 in @xmath222 , @xmath276 the corresponding harmonic mean , and @xmath277 the second - smallest eigenvalue of the normalized laplacian of @xmath278 , we have @xmath279 provided that @xmath280 as @xmath143 . the second part of the lemma deals with the between component of the graph .",
    "the following example illustrates the result for the case where @xmath281 .",
    "[ ex:2split ] when @xmath30 is partitioned into two sets @xmath33 and @xmath34 we have that @xmath282 lemma  [ lemma : var_decomposition ] then yields @xmath283 as one would expect , the variance of @xmath284 crucially depends on the magnitude of @xmath225 , but also on the relative size @xmath285 and @xmath286 of the two graph components .",
    "the following theorem allows us to use lemma  [ lemma : var_decomposition ] to bound the variance of our estimator of interest , @xmath63 . to state the result",
    "we introduce @xmath287 where , analogous to @xmath275 , we denote by @xmath288 the degree of vertex @xmath10 in the graph @xmath223 . if @xmath289 for all @xmath265 , then we define @xmath290 .",
    "[ th : decomposition ] let @xmath118 and @xmath216 be connected .",
    "then , for any @xmath291 , @xmath292^{1/2 }     \\\\ & \\qquad \\qquad   \\qquad            \\leq \\ ,            { \\rm var}\\left ( { \\mathbold v } ' \\widehat { \\mathbold \\alpha } \\right )             - \\left [ { \\rm var}\\left (   { \\mathbold v } ' \\widehat { { \\mathbold \\beta } }      \\right )             + { \\rm var}\\left (    { \\mathbold v } ' { \\mathbold p } ' \\widehat { { \\mathbold   \\gamma } }   \\right )    \\right ]      \\\\ & \\qquad \\qquad   \\qquad \\qquad \\qquad \\qquad          \\leq \\ ,   \\kappa \\ ,   { \\rm var}\\left (    { \\mathbold v } ' { \\mathbold p } ' \\widehat { { \\mathbold   \\gamma } }",
    "\\right )   +         2 \\kappa^{1/2 } \\left [   { \\rm var}\\left (   { \\mathbold v } ' \\widehat { { \\mathbold \\beta } }     \\right )   { \\rm var}\\left (    { \\mathbold v } ' { \\mathbold p } ' \\widehat { { \\mathbold   \\gamma } } \\right )   \\right]^{1/2 } .",
    "\\end{aligned}\\ ] ]    the theorem shows that , if @xmath293 is small , the variance of @xmath63 is close the the variance of an infeasible estimator of @xmath60 constructed from , which equals @xmath294 one can also show that not only their variances but actually the estimators @xmath295 and @xmath296 themselves are close to each other when @xmath293 is small ; see section [ sup : decompositiongeneralized ] of the supplementary material .",
    "only components with @xmath297 enter into the definition of @xmath293 .",
    "for those components we need @xmath298 , uniformly over @xmath299 , for @xmath293 to be small .",
    "this requires that for every vertex @xmath299 the number of between edges is much smaller than the number of within edges , that is , the vertices need to be much more connected within components than between components .",
    "[ ex:2split ] consider the example with two components , @xmath300 .",
    "assume that the @xmath225 edges between @xmath33 and @xmath34 are chosen such that @xmath301 .",
    "for example , if the vertices of those edges are drawn without repetition from @xmath33 and @xmath34 , then we have @xmath302 , but this requires @xmath303 .",
    "if we furthermore assume that @xmath304 , then we have @xmath305 .",
    "this also implies that @xmath306 , so that holds . applying theorem  [ th : decomposition ] we then find , as @xmath130 , @xmath307 and @xmath308 where we write @xmath90 instead of @xmath309 , because @xmath310 under our assumptions .",
    "thus , if @xmath311 , then our original first - order results still holds . for @xmath225 values that are smaller the asymptotic variance needs to be adjusted . finally ,",
    "if @xmath312 and @xmath313 , then the asymptotic variance is completely dominated by the weak global connectivity of @xmath118 , and the local structure of the graph is no longer of first - order relevance .",
    "[ ex:3split ] consider an analogous situation as in example  [ ex:2split ] , only now with @xmath314 partitions , each of which containing many vertices ; as in figure [ fig : partition3 ] . for @xmath315 , with @xmath316 , let @xmath317 be the number of edges between @xmath214 and @xmath318",
    ". then @xmath319 for the pseudo - inverse @xmath320 we calculate @xmath321 and @xmath322 thus , if we again assume that @xmath301 and @xmath304 , applying theorem  [ th : decomposition ] for @xmath323 and @xmath324 we have @xmath325 and @xmath326 the asymptotic result for @xmath327 again depends not only on @xmath328 , @xmath329 and @xmath330 , but also on the relative component sizes @xmath285 , @xmath286 and @xmath331 , while those component sizes do not matter at all for the asymptotic result on @xmath332 .",
    "our original first - order results for @xmath332 still holds if , for example , either @xmath333 or @xmath334 .",
    "an interesting special case is @xmath335 , where the result simplifies to @xmath336 this simple formula generalizes to four and more components .",
    "for example , for @xmath337 with @xmath338 we find for @xmath323 and @xmath339 under the asymptotic assumptions above that @xmath340 .",
    "theorem  [ th : decomposition ] is also applicable if @xmath341 for some @xmath265 , as the following example illustrates .     and @xmath342 . ]",
    "take the setup of example  [ ex:3split ] but now set @xmath343 this situation is depicted in figure [ fig : partition3b ] .",
    "this is a setting where one vertex @xmath344 provides the only connection between @xmath33 and @xmath345 ; the degree of this connecting vertex is @xmath346 .",
    "for @xmath347 we again assume @xmath348 and @xmath349 .",
    "application of theorem  [ th : decomposition ] then gives the same asymptotic conclusions as in examples  [ ex:3split ] , in particular for @xmath323 and @xmath324 we again find @xmath350 this example can again be extended .",
    "if we introduce an additional vertex @xmath351 that also connects the subgraphs @xmath33 and @xmath345 , and we have @xmath352 and @xmath353 , then applying theorem  [ th : decomposition ] with @xmath337 , @xmath323 and @xmath324 yields @xmath354 the result for three and more connecting vertices is analogous .",
    "so far we have considered simple graphs .",
    "our variance bounds generalize to weighted graphs .",
    "let @xmath12 be an undirected weighted graph with associated ( weighted ) adjacency matrix @xmath88 .",
    "a simple example is a multigraph , which differs from a simple graph in that multiple edges may exist between vertices . in this case",
    ", @xmath207 equals the number of edges between @xmath10 and @xmath11 .",
    "more generally , @xmath88 is symmetric , has diagonal entries equal to zero , and has off - diagonal entries that are non - negative .",
    "our variance bounds generalize to situations where an estimator @xmath355 , constructed from @xmath12 , has variance @xmath356 for @xmath357 where , as before , @xmath358 is a diagonal ( weighted ) degree matrix with entries @xmath359 .",
    "a symmetric matrix @xmath360 is such a laplacian matrix if and only if    1 .",
    "all off - diagonal elements of @xmath360 are negative ; 2 .",
    "all column sums of @xmath360 are equal to zero ; 3 .",
    "@xmath361 .",
    "the variance bounds in theorems  [ thm : eigenvaluebound][th : decomposition ] continue to apply , on setting @xmath362 and redefining the harmonic means @xmath363 with @xmath364 .",
    "our proofs of the theorems fully cover the weighted - graph case .",
    "we give some examples of weighted graphs .",
    "[ ex : wls ] we generalize the least - squares estimator in to situations where @xmath13 interact on @xmath365 occasions and errors are heteroskedastic across meetings . using obvious notation ,",
    "the weighted least - squares estimator of @xmath60 equals @xmath366 let @xmath367 be the weighted adjacency matrix with entries @xmath368 and let @xmath369 be the associated laplacian matrix .",
    "then theorem [ thm : ols ] can be suitably extended to yield @xmath370    [ ex : profiling ] consider a bipartite graph @xmath118 , where @xmath30 is partitioned as @xmath371 and edges are formed between @xmath33 and @xmath34 but not within these sets .",
    "let @xmath372 and @xmath373 .",
    "the laplacian is @xmath374 where @xmath375 and @xmath376 are @xmath377 and @xmath378 diagonal degree matrices and @xmath379 is the @xmath380 upper - right block of the adjacency matrix of the graph .",
    "decompose @xmath60 accordingly as @xmath381 .",
    "the corresponding estimator @xmath63 is defined in for the case of a simple graph , but the following construction works for any estimator that satisfies @xmath382 , with @xmath383 being the laplacian matrix of a simple , weighted or multigraph , as described above ( we may simply have @xmath362 ) .",
    "we also define @xmath384 corresponding to the natural normalization @xmath385 . by the block - inversion formula we find @xmath386 this is the variance formula after profiling - out all the parameters corresponding to vertices in @xmath33 .",
    "it can be verified that @xmath387 satisfies the conditions ( i)(iii ) .",
    "the adjacency matrix of the corresponding graph , say @xmath388 , that involves only the vertices in @xmath34 is given by the off - diagonal part of @xmath389 .",
    "thus , even when starting with a simple bipartite graph @xmath118 we naturally obtain a weighted graph @xmath388 when profiling out some of the parameters . moreover ,",
    "two vertices in @xmath388 are connected if and only if they are path - two neighbors in the original graph @xmath118 .",
    "an interesting application of example  [ ex : profiling ] is example [ ex : workerfirm ] .",
    ".5   ( left ) with links between @xmath33 ( red vertices ) and @xmath34 ( yellow vertices ) , and the induced weighted graph @xmath390 ( right ) on @xmath34 alone resulting from profiling out the parameters associated with @xmath33 .",
    ", title=\"fig : \" ]    .5   ( left ) with links between @xmath33 ( red vertices ) and @xmath34 ( yellow vertices ) , and the induced weighted graph @xmath390 ( right ) on @xmath34 alone resulting from profiling out the parameters associated with @xmath33 .",
    ", title=\"fig : \" ]    [ ex : workerfirm][matched employer - employee data ] consider the wage regression with panel data , where the log wage of worker @xmath10 in firm @xmath11 at time @xmath391 equals @xmath392 to maintain focus , assume that the @xmath393 are i.i.d . then , with @xmath394 as discussed before , the pooled ( ordinary ) least squares estimator satisfies @xmath395 where @xmath111 is the laplacian associated with the adjacency matrix @xmath396 this illustration is interesting because , here , the @xmath38 can not be estimated precisely due to limited cross - firm mobility @xcite .",
    "it therefore makes sense to focus on the @xmath39 , that is , on the firm effects .",
    "profiling - out @xmath397 and letting @xmath398 where @xmath373 is the number of firms , application of example  [ ex : profiling ] gives @xmath399 where @xmath400 is the @xmath378 laplacian matrix associated with the weighted @xmath378 adjacency matrix @xmath401 \\cap [ k ] }   \\frac{m_{ij }   \\ , m_{ik } } { d_i }   & \\text { for $ j \\neq k$ , }      \\\\[5pt ] 0 & \\text {   for $ j = k$ , } \\end{array }   \\right.\\ ] ] where @xmath402 is the degree of @xmath323 , that is , the total number of observations for that worker , and @xmath403 \\cap [ k]$ ] is the set of all workers for which wages are observed both in firm @xmath11 and in firm @xmath25 .",
    "in this example the vertex set of of the weighted graph @xmath388 are the firms .",
    "two firms are connected by an edge if there is at least one worker who has worked in both firms .",
    "the weight @xmath404 of the edge is larger the more workers there are connecting firms @xmath11 and @xmath25 , and the longer these workers have worked in both firms .",
    "figure [ fig : weighted ] provides an illustration of a simple bipartite graph ( with all @xmath405 ) for workers ( red vertices ) and firms ( yellow vertices ) , given in the left plot , and the induced weighted graph featuring only firms , given in the right plot .",
    "the thickness of the edge between @xmath406 in the plot of @xmath390 reflects the magnitude of the weight @xmath407 .",
    "the model we have discussed has the feature that each observed outcome depends on exactly two fixed - effect parameters , and we accordingly consider the graph @xmath118 where each parameter is a vertex and observations are edges connecting those vertices .",
    "examples are the @xcite model for paired comparisons , wage regressions with worker and firm fixed effects ( e.g.  @xcite ) , gravity equations with exporter and importer fixed effects ( e.g.  @xcite ) , and panel data models with individual specific fixed effects and time dummies . in applications of such models",
    "it is often the case that not all possible pairings of parameters are actually observed in the data , implying that the underlying @xmath118 is not a complete graph or a complete bipartite graph , but has a more complicated connectivity structure .",
    "we have derived bounds on the variance of the fixed - effect estimators for such network data applications .",
    "the bounds highlight the role of both global and local measures of network connectivity on the precision of statistical inference .",
    "the local - connectivity measures that are relevant for our first - order variance bounds on the estimator @xmath408 of the fixed effect @xmath19 are the degree @xmath90 , that is , the number of observations that depend on the parameter @xmath19 , and the harmonic mean @xmath138 of the degrees of the direct neighbors of vertex  @xmath10 . for the second - order bound ( given in the appendix )",
    "the degrees of the path - two neighbors are also important as local measures of connectivity .",
    "these are very natural descriptors of the local connectivity of the vertex @xmath10 .    for most of our variance",
    "bounds the global connectivity of the graph is described by the second - smallest eigenvalue of the normalized graph laplacian matrix , which is well studied in the graph theory literature ( e.g.  @xcite ) , and is closely related to other conventional connectivity measures like the cheeger constant .",
    "we also discuss cases where our bounds based on those global connectivity measures are crude , and we derive more precise variance bounds for situations where the graph consists of well - connected clusters that are only connected by relatively few observations with each other .",
    "our variance bounds provide new insight into the potential for accurate statistical inference from network data that highlight the structure of the network .",
    "this can aid when deciding on sampling design or when performing sample selection .",
    "the bounds also readily yield conditions for consistent estimation and asymptotically valid inference under non - normality .",
    "we have focused on linear models in this paper . in ongoing work",
    "we are extending our analysis to nonlinear models , such as the original @xcite model . in that case , again , the variance of the estimator takes the form of ( the inverse of ) a weighted laplacian . a complication , however , is the presence of bias in the estimator coming from the nonlinearity . like the variance ,",
    "the magnitude of the bias is driven by the structure of the network , and so requires careful analysis .",
    "for example , it is not guaranteed that , even in regular problems , the bias is small relative to the standard deviation .",
    "a restriction of our model is that each observation involves only two model parameters , which enter complementarily ( that is , the off - diagonal hessian elements have the opposite sign from the diagonal hessian elements , implying that the hessian of the log - likelihood can be interpreted as a graph laplacian ) .",
    "focusing on such a model allows us to connect very closely with the graph - theory literature , in particular with the results on global - connectivity measures for graphs .",
    "models where more than two fixed - effect parameters determine one observation would lead to hypergraphs . extrapolating our results",
    ", one would again expect that the precision of statistical inference in such models is governed by the local and global connectivity of the underlying hypergraph , but formalizing this relation is left for future research .",
    "this section discusses an improvement on the bounds in theorem  [ thm : firstorderbound ] .",
    "recall that @xmath409\\cap [ j ] \\rvert$ ] denotes the number of vertices that are direct neighbors of both vertex @xmath10 and vertex @xmath11 . for @xmath410 $ ] , let @xmath411 , the number of direct neighbors of @xmath11 that are not also direct neighbors of @xmath10 .",
    "the following example illustrates that @xmath412 can be a more relevant measure than @xmath413 for the dependence of @xmath414 on the connectedness of a neighbor @xmath11 of @xmath10 .",
    "[ ex : star ] and [ ex : wheel ] both for the star and for the wheel graph example above one finds @xmath415 by direct calculation .",
    "thus , the additional edges in the wheel graph between the neighbors of vertex @xmath172 relative to the star graph do not lower the variance of @xmath416 . for @xmath175",
    "we have @xmath169 for the star graph but @xmath417 for the wheel graph , while for both graphs we have @xmath418 .",
    "let @xmath134_2 : = \\bigcup_{j \\in [ i ] }    [ j ] \\setminus \\{i\\ } , \\ ] ] the set of all path - two neighbors of vertex @xmath10 .",
    "analogous to the definition of the harmonic mean @xmath138 above we let @xmath419 }    \\frac 1 { \\underline{d}_{j , i } }    \\right)^{-1 }   ,   &   h_{i;2 } & : = \\left ( \\frac 1 { \\left| [ i]_2 \\right| }   \\sum_{j \\in [ i]_2 }   \\frac 1 { d_j } \\right)^{-1 } .\\end{aligned}\\ ] ] in addition , for @xmath420 we define the set @xmath421 which is the set of all triplets @xmath422 such that @xmath423 is a closed walk in @xmath118 that reaches distance two from @xmath10 ( thus ruling out @xmath424 ) .",
    "notice that we may have @xmath425 , that is , the closed walk need not be a simple cycle .",
    "[ thm : secondorderbound ] let @xmath12 be connected and let @xmath426 .",
    "then @xmath427 where @xmath428 .",
    "including the factor @xmath429 in the definition of @xmath430 guarantees that @xmath430 is naturally scaled in many examples ; see below .",
    "an asymptotic implication of theorem  [ thm : secondorderbound ] is that @xmath431 provided @xmath432 as @xmath130 and @xmath433 for some constant @xmath434 independent of @xmath55 .",
    "notice that this does not require that @xmath435 , and the refinement obtained here relative to the first order asymptotic result is in fact particularly important for those cases where @xmath138 and @xmath436 are small .",
    "the term @xmath430 requires further discussion .",
    "notice that @xmath437 implies @xmath438 $ ] and @xmath439_2 $ ] , and for any tensor @xmath440 we have @xmath441_2 } \\ ; \\sum_{j \\in [ i ] \\cap [ k ] } \\ ; \\sum_{\\ell \\in [ i ] \\cap [ k ] } a_{ijk\\ell }",
    ".        \\label{rewritesum}\\end{aligned}\\ ] ] applying this to @xmath442 and using that @xmath443 \\cap [ k ] } = d_{ik}$ ] we obtain @xmath444_2 }   d_{ik}^2 .\\end{aligned}\\ ] ] thus , the number of elements in @xmath445 depends on the number of path - two neighbors of @xmath10 and on the typical number of neighbors that @xmath10 has in common with one of its path - two neighbors .",
    "the cases of interest in the following are those where the typical value of @xmath446 is small compared to the degree @xmath90 for @xmath439_2 $ ] , so that the ratio between @xmath447 and @xmath448_2 |$ ] is not large .",
    "this is true in many interesting examples .",
    "applying to @xmath430 gives @xmath449_2 }   \\frac 1 { d_k } \\left (   \\sum_{j \\in [ i ] \\cap [ k ] } \\frac 1 { \\underline d_{j , i } } \\right)^2      \\\\       & =    \\frac { \\left| [ i]_2 \\right| } { d_i \\ ,   \\underline h_i }    \\left [ \\frac 1 { \\left| [ i]_2 \\right| }    \\sum_{k \\in [ i]_2 }   d_{ik}^2     \\left ( \\frac { h_{i;2 } } { d_k } \\right ) \\left ( \\frac 1 { d_{ik } }   \\sum_{j \\in [ i ] \\cap [ k ] }      \\frac { \\underline h_i } { \\underline d_{j , i } } \\right)^2    \\ ; \\right ] .\\end{aligned}\\ ] ] using the last result we want to argue that @xmath430 is of order one in cases where @xmath446 is not large for @xmath439_2 $ ] . to do so , first notice that the sums in the last expression for @xmath430 are all self - normalized ( i.e. , divided by the number of terms that is summed over ) .",
    "we also typically have @xmath450_2 \\right| } { d_i \\ ,   \\underline h_i } = o(1)$ ] , because @xmath451_2 \\right| } { d_i }       & \\leq \\frac 1 { d_i } \\sum_{j \\in [ i ] }   \\underline d_{j , i }   , \\end{aligned}\\ ] ] and one expects the arithmetic mean @xmath452 }   \\underline d_{j , i } \\right ) $ ] to be of the same order as the harmonic mean @xmath453 .    in the following",
    "we present concrete examples where @xmath446 is relatively small for @xmath439_2 $ ] and thus @xmath430 is of order one asymptotically .",
    "[ ex : er ] consider the @xcite random - graph model with @xmath454 .",
    "let @xmath132 to guarantee that the graph is connected as @xmath130",
    ". in this model for randomly picked @xmath45 we have @xmath455 $ ] , that is , the difference between @xmath456 and @xmath90 is typically very small .",
    "also , for randomly picked @xmath420 and @xmath439_2 $ ] we have @xmath457 , and therefore @xmath458_2 | \\ , [ 1+o(n p_n^2 ) ] = n^2 p_n^2 + o(n^3 p_n^4)$ ] . we therefore have @xmath133 , @xmath459 , @xmath460 , @xmath461 , @xmath462 , @xmath463 and @xmath464 , almost surely , as @xmath130 .",
    "applying theorem  [ thm : secondorderbound ] thus gives @xmath465 which is simpler than , because in this example 3-cycles are relatively rare , implying that @xmath466 and @xmath436 are typically very close to each other .",
    "[ ex : workerfirm][matched employer - employee data ] in the worker - firm example the graph @xmath118 is bipartite , so that two neighboring vertices have no direct neighbors in common , implying that @xmath467 and @xmath468 .",
    "let @xmath344 be a firm .",
    "then , @xmath410 $ ] are workers , and the number of observations @xmath413 for workers are typically small in this application , so that the harmonic mean @xmath138 is typically small . also , @xmath410_2 $ ] are firms , and the number of observations @xmath413 for firms are often large in this application , so the harmonic mean @xmath469 is often large . therefore",
    ", the second - order bound in theorem  [ thm : secondorderbound ] is particularly simple in this example ( because the distinction between @xmath470 and @xmath90 is irrelevant ) , and is also particularly important ( because @xmath468 is small , so that the improvement relative to the first - order bound is very relevant ) . for simplicity , we consider the case of a simple graph where @xmath471 for all workers @xmath472 .",
    "log wage observations and the graph is simple . ] then , for @xmath344 the bounds in theorem  [ thm : secondorderbound ] become @xmath473 where @xmath474_2 }   \\frac { d_{ij}^2 } { d_j }            \\leq      \\frac 1 2 \\max_{j \\in [ i]_2 } d_{ij}^3 \\ ; , \\ ] ] where for the last inequality we used the definition of @xmath469 and @xmath475_2 \\right|   \\leq",
    "d_i   \\max_{j \\in [ i]_2 } d_{ij}$ ] . for example , if any two firms are connected by at most two workers , then we have @xmath476 and therefore @xmath477 .",
    "thus , the leading order asymptotic variance is increased by a factor of two compared to the first order result in .",
    "it is also possible that theorem  [ thm : secondorderbound ] can not be used to obtain a refinement of the variance as in but that it can justify the first - order rate in for cases where this first - order asymptotic variance of @xmath408 does not follow from theorem  [ thm : firstorderbound ] .",
    "the following example illustrates this .",
    "[ ex : hypercube ] for @xmath478 consider the @xmath151-dimensional hypercube graph , which has @xmath152 edges , as introduced above . in that case , firstly , we have @xmath479 for all @xmath420 .",
    "secondly , there are no edges among the vertices in @xmath144 $ ] , implying that @xmath480 and @xmath481 for all possible @xmath482 .",
    "thirdly , we have @xmath448_2 | = n ( n-1)/2 $ ] , and for all @xmath420 and @xmath439_2 $ ] we have @xmath483 implying that @xmath484_2 | = 2 n ( n-1)$ ] .",
    "we thus find @xmath485 .",
    "the bounds in theorem  [ thm : secondorderbound ] thus become @xmath486 because @xmath487 we thus find , @xmath488 as @xmath489 .",
    "aaronson , d.  l. , l.  barrow , and w.  sander ( 2007 ) . teacher and student achievement in the chicago public high schools .",
    "_ 25 _ , 95135 .",
    "abowd , j. , f.  kramarz , p.  lengermann , and s.  perez - duarte ( 2004 ) .",
    "are good workers employed by good firms ?",
    "a test of a simple assortative matching model for france and the united states .",
    "abowd , j.  m. , f.  kramarz , and d.  n. margolis ( 1999 ) .",
    "high wage workers and high wage firms .",
    "_ 67 _ , 251333 .",
    "acemoglu , d. , a.  ozdaglar , and a.  tahbaz - salehi ( 2015 ) . systemic risk and stability in financial networks .",
    "_ 105 _ , 564608 .    anderson , j.  e. and e.  van wincoop ( 2003 ) .",
    "gravity with gravitas : a solution to the border puzzle .  _ 93",
    "_ , 170192 .",
    "andrews , m.  j. , l.  gill , t.  schank , and r.  upward ( 2008 ) .",
    "high wage workers and low wage firms : negative assortative matching or limited mobility bias .  _ 171",
    "_ , 673697 .",
    "barth , e. and h.  dale - olsen ( 2003 ) .",
    "assortative matching in the labour market",
    "? stylised facts about workers and plants .",
    "berry , s.  t. ( 1994 ) .",
    "estimating discrete - choice models of product differentiation .",
    "_ 25 _ , 242262 .",
    "bradley , r.  a. and m.  e. terry ( 1952 ) .",
    "ank analysis of incomplete block designs : i.  the method of paired comparisons .",
    "_ 39 _ , 324325 .",
    "bramboull , y. , r.  kranton , and m.  damours ( 2014 ) . strategic interaction and networks .",
    "_ 104 _ , 898930 .    butler , s. ( 2016 ) .",
    "algebraic aspects of the normalized laplacian . in a.",
    "beveridge , j.  r. griggs , l.  hogben , g.  musiker , and p.  tetali ( eds . ) , _ recent trends in combinatorics _ , pp .",
    "springer .",
    "chung , f. r.  k. ( 1997 ) . .",
    "volume 92 of cbms regional conference series in mathematics , american mathematical society .",
    "dzemski , a. ( 2014 ) .",
    "an empirical model of dyadic link formation in a network with unobserved heterogeneity .",
    "erds , p. and a.  rnyi ( 1959 ) . on random graphs .",
    "_ 6 _ , 290297 .",
    "erds , p. and a.  rnyi ( 1960 ) . on the evolution of random graphs .",
    "_ 5 _ , 1761 .",
    "fafchamps , m. and f.  gubert ( 2007 ) . risk sharing and network formation .  _ 97 _ , 7579 .",
    "fernndez - val , i. and m.  weidner ( 2016 ) .",
    "individual and time effects in nonlinear panel data models with large @xmath151 , @xmath490 .  _ 192",
    "_ , 291312 .",
    "goux , d. and e.  maurin ( 1999 ) .",
    "persistence of interindustry wage differentials : a re - examination using matched worker - firm data .",
    "_ 17 _ , 492533 .",
    "graham , b.  s. ( 2015 ) .",
    "an econometric model of link formation with degree heterogeneity .",
    "harrigan , j. ( 1996 ) .",
    "openness to trade in manufactures in the oecd .",
    ", 2339 .",
    "hoffman , c. , m.  kahle , and e.  paquette ( 2013 ) .",
    "spectral gaps of random graphs and applications to random topology .",
    "jackson , m.  o. , t.  rodriguez - barraquer , and x.  tan ( 2012 ) .",
    "social capital and social quilts : network patterns of favor exchange .  _ 102",
    "_ , 18571897 .",
    "klein , d.  j. ( 2002 ) .",
    "resistance - distance sum rules .",
    "_ 75 _ , 633649 .",
    "klein , d.  j. and m.  j. randi ( 1993 ) .",
    "resistance distance .",
    "_ 12 _ , 8195 .",
    "kolokolnikov , t. , b.  osting , and j.  von brecht ( 2014 ) . .",
    "rivkin , s.  g. , e.  a. hanushek , and j.  f. kain ( 2005 ) .",
    "teachers , schools , and academic achievement .  _ 73",
    "_ , 417458 .",
    "simons , g. and y .- c . yao ( 1999 ) .",
    "asymptotics when the number of parameters tends to infinity in the bradley - terry model for paired comparisons .",
    "_ 27 _ , 10411060 .",
    "von luxburg , u. , a.  radl , and m.  hein ( 2010 ) . getting lost in space : large sample analysis of the resistance distance . in _ advances in neural information processing systems",
    "_ , pp . 26222630 .",
    "von luxburg , u. , a.  radl , and m.  hein ( 2014 ) .",
    "hitting at commute times in large random neighborhood graphs .",
    "_ 15 _ , 17511798 .",
    "yan , t. and j.  xu ( 2013 ) .",
    "a central limit theorem in the @xmath0-model for undirected random graphs with a diverging number of vertices .",
    "_ 100 _ , 519524 .",
    "zermelo , e. ( 1929 ) .",
    "die berechnung der turnier - ergebnisse als ein maximumproblem der wahrscheinlichkeitsrechnung .",
    "_ 29 _ , 436460 .     * supplementary material for + ` fixed - effect regressions on network data ' *",
    "[ [ proof - of - lemmalemmaexistence - existence ] ] proof of lemma  [ lemma : existence ] ( existence ) + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    the estimator is defined by the constraint minimization problem in . for convenience",
    "we express the constraint in quadratic form , @xmath491 . by introducing the lagrange multiplier @xmath492",
    "we can write @xmath493 solving the corresponding first - order condition we obtain @xmath494 here , the matrix @xmath495 is invertible , because @xmath496 only has a single zero eigenvalue ( because we assume the graph to be connected ) with eigenvector @xmath54 , so that adding @xmath497 gives a non - degenerate matrix .",
    "the matrices @xmath498 and @xmath499 commute , and by properties of the moore - penrose inverse we thus have @xmath500 we furthermore have @xmath501 and , because @xmath502 , the contribution from @xmath503 drops out of the above formula for @xmath504 , and we obtain @xmath505 .",
    "this concludes the proof .",
    "[ [ proof - of - theoremthmols - sampling - distribution ] ] proof of theorem  [ thm : ols ] ( sampling distribution ) + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    as @xmath506 , lemma [ lemma : existence ] gives @xmath507 conditional on @xmath47 , @xmath508 , and so @xmath509 where the variance expression follows from properties of the moore - penrose pseudoinverse .",
    "this concludes the proof .",
    "[ [ proof - of - corollarycorinference - inference ] ] proof of corollary  [ cor : inference ] ( inference ) + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    the result follows from theorem [ thm : ols ] by standard arguments on the @xmath75-statistic in linear regression models . here , the degrees - of - freedom correction from @xmath84 to @xmath80 arises , because the projection matrix @xmath510 has rank @xmath80 .",
    "notice that although @xmath47 has @xmath55 columns , we have that @xmath511 .",
    "this concludes the proof .",
    "[ [ proof - of - theoremsthmeigenvaluebound - andthmeigenvaluebound2-zero - order - bounds ] ] proof of theorems  [ thm : eigenvaluebound ] and  [ thm : eigenvaluebound2 ] ( zero - order bounds ) + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    there are no isolated vertices , because @xmath12 is connected and @xmath512 .",
    "that is , @xmath513 for all @xmath10 , and so @xmath358 is invertible . from theorem  [ thm : ols ] and the definition of the normalized laplacian @xmath97 we find @xmath514 in the following we write @xmath515 for symmetric matrices",
    "@xmath516 and @xmath517 to indicate that @xmath518 is positive semi - definite .",
    "we have @xmath519 , because @xmath105 is the smallest non - zero eigenvalue of @xmath97 .",
    "therefore , @xmath520 this result implies that , for any vector @xmath521 , @xmath522 the bound in theorem [ thm : eigenvaluebound ] follows on setting @xmath523 , the @xmath10th unit vector .",
    "the corresponding bound for the differences in theorem [ thm : eigenvaluebound2 ] follows on setting @xmath524 for @xmath195 .",
    "this concludes the proof .",
    "[ [ proof - of - theoremsthmfirstorderbound - andthmfirstorderbound2-first - order - bounds ] ] proof of theorems  [ thm : firstorderbound ] and  [ thm : firstorderbound2 ] ( first - order bounds ) + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    we first show that , if @xmath12 is connected , then @xmath525          \\leq    \\frac{\\sigma^2 } { \\lambda_2 }              \\mathbold{d}^{-1 }   \\mathbold{a }   \\mathbold{d}^{-1 }     \\mathbold{a }   \\mathbold{d}^{-1 } .          \\label{boundfirstodermatrix }        \\end{aligned}\\ ] ] theorems  [ thm : firstorderbound ] and  [ thm : firstorderbound2 ] will then follow readily . first note that , because @xmath12 is connected , we know that the zero eigenvalue of the laplacian matrix @xmath526 has multiplicity one , and the corresponding eigenvector is given by @xmath527 .",
    "the moore - penrose pseudoinverse of @xmath526 therefore satisfies @xmath528 where the right hand side is the idempotent matrix that projects orthogonally to @xmath54 . using that @xmath529 and solving this equation for @xmath356 gives",
    "@xmath530 the laplacian is symmetric , and so transposition gives @xmath531 replacing @xmath356 on the right - hand side of by the expression for @xmath532 given by yields @xmath533 where we have also used the fact that @xmath534 . re - arranging this equation allows us to write @xmath535 because @xmath536 and by the arguments in the preceding proof we also have the bounds @xmath537 put together this yields @xmath538 and multiplication with @xmath539 gives the bounds stated in .    to show theorems  [ thm : firstorderbound ] and  [ thm : firstorderbound2 ] we calculate , for @xmath195 , @xmath540       { \\mathbold e}_i ' \\ ,   \\mathbold{d}^{-1 } \\ ,       { \\mathbold e}_i       & = d_i^{-1 } , \\\\       { \\mathbold e}_i ' \\ ,   \\mathbold{d}^{-1 } \\ ,       { \\mathbold e}_j       & = 0,\\\\       { \\mathbold e}_i '   \\ , \\mathbold{d}^{-1 } \\mathbold{a }   \\mathbold{d}^{-1 }   \\ ,   { \\mathbold e}_i       & = 0 , \\\\       { \\mathbold e}_i '   \\ , \\mathbold{d}^{-1 } \\mathbold{a }   \\mathbold{d}^{-1 }   \\ ,   { \\mathbold e}_j       & = d_i^{-1 } d_j^{-1 }   ( { \\mathbold a})_{ij }   , \\end{aligned } \\qquad\\qquad \\begin{aligned}[c ]       { \\mathbold e}_i '   \\ , \\mathbold{d}^{-1 } \\mathbold{a }   \\mathbold{d}^{-1 }    \\mathbold{a }   \\mathbold{d}^{-1 } \\ ,   { \\mathbold e}_i       & =   d_i^{-1 }   h_i^{-1 } ,     \\\\",
    "{ \\mathbold e}_i '   \\ , \\mathbold{d}^{-1 } \\mathbold{a }   \\mathbold{d}^{-1 }    \\mathbold{a }   \\mathbold{d}^{-1 } \\ ,   { \\mathbold e}_j       & = d_i^{-1 } d_j^{-1 }   d_{ij }   h_{ij}^{-1 } ,       \\\\",
    "{ \\mathbold e}_i ' \\ ,    \\mathbold{\\iota}_n \\mathbold{\\iota}'_n \\mathbold{d}^{-1 }   \\ ,       { \\mathbold e}_i       & =   \\mathbold{\\iota}'_n \\mathbold{d}^{-1 }   \\ ,       { \\mathbold e}_i = d_i^{-1 } ,       \\\\       { \\mathbold e}_i ' \\ ,    \\mathbold{\\iota}_n \\mathbold{\\iota}'_n \\mathbold{d}^{-1 }   \\ ,       { \\mathbold e}_j       & =   \\mathbold{\\iota}'_n \\mathbold{d}^{-1 }   \\ ,       { \\mathbold e}_j = d_j^{-1}. \\end{aligned}\\ ] ] combining these results with gives the bounds on @xmath541 and @xmath542 stated in the theorems and concludes the proof .",
    "[ [ proof - of - theoremthmfirstordergeneralized - generalized - approximation ] ] proof of theorem  [ thm : firstordergeneralized ] ( generalized approximation ) + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    from the proof of lemma  [ lemma : existence ] , the least - squares estimator satisfies the first - order condition @xmath543 using that @xmath544 and that @xmath545 this yields @xmath546 where @xmath547 note that this is the vector version of the expression for @xmath548 as given in the theorem . from @xmath549",
    "it follows that @xmath550 while from the assumption that @xmath551 we have that @xmath552 as in the preceding proofs , we still have that @xmath553 , and so @xmath554 from this we find @xmath555 thus , if @xmath556 as @xmath121 , then by markov s inequality we have @xmath557 . by the continuous mapping theorem we therefore have @xmath558 }   u_{ij}.\\ ] ] moreover , if @xmath559 }   u_{ij}$ ] is asymptotically normal , then so is @xmath560 .",
    "this concludes the proof .",
    "[ [ proof - of - lemmalemmavar_decomposition - variance - of - component - estimators ] ] proof of lemma  [ lemma : var_decomposition ] ( variance of component estimators ) + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    [ [ additional - notation . ] ] additional notation .",
    "+ + + + + + + + + + + + + + + + + + + +    without loss of generality we relabel the elements of @xmath30 such that @xmath561 we decompose @xmath562 and @xmath563 , where each @xmath564 and @xmath565 are @xmath566 column vectors . note that the laplacian matrix @xmath254 is block - diagonal ; moreover , @xmath567 where @xmath568 is the laplacian of the graph @xmath278 .",
    "we also decompose @xmath569 , where @xmath570 and @xmath571 are the adjacency matrix of @xmath257 and @xmath258 , respectively , and write @xmath572 and @xmath573 for the corresponding degree matrices .",
    "we have @xmath574 and @xmath575 .",
    "we also relabel the elements of @xmath5 such that @xmath576 and correspondingly we decompose @xmath577 , where @xmath578 and @xmath579 are @xmath580 and @xmath581 matrices , respectively , whose rows correspond to edges in @xmath223 and @xmath222 , respectively .",
    "we then have @xmath582 .",
    "[ [ inverse - expressions . ] ] inverse expressions .",
    "+ + + + + + + + + + + + + + + + + + + +    notice that , under the conventions from above , @xmath583 is simply given by @xmath584 we define the block - diagonal @xmath256 matrix @xmath585 some useful relations are @xmath586 , @xmath587 , @xmath588 , @xmath589 , @xmath590 , and thus also @xmath591 .",
    "the various pseudo - inverses that appear in the following satisfy @xmath592 where on the right - hand side always appears the projector orthogonal to the null - space of the respective matrix , e.g. we have @xmath593 . using",
    "that @xmath594 and the definition of @xmath595 we find that @xmath596    [ [ proof - of - lemmalemmavar_decomposition . ] ] proof of lemma  [ lemma : var_decomposition ] .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    we derive the result for @xmath597 first . by applying theorem  [ thm : ols ] to each @xmath278",
    "separately we obtain @xmath598 for @xmath599 .",
    "note that we do not rule out @xmath289 ( i.e. , @xmath278 may be a graph with one vertex and no edges ) , but in this case we simply have @xmath600 , so the result for @xmath601 holds trivially .",
    "independence of the errors @xmath29 across observations implies independence of @xmath602 and @xmath603 for all @xmath316 .",
    "we thus find @xmath604 which is the result in the theorem .",
    "now turn to @xmath605 .",
    "analogous to the proof of lemma  [ lemma : existence ] we can write the minimization problem for @xmath606 as @xmath607 where @xmath608 is a lagrange multiplier . solving the corresponding first - order condition",
    "gives @xmath609    ,    \\\\         & =       { \\mathbold{\\gamma } }         +    \\left ( \\mathbold{p }   \\mathbold{b}_b ' \\mathbold{b}_b \\mathbold{p } '         + \\lambda   \\ ,   \\mathbold{p }   \\mathbold{\\iota}_n \\mathbold{\\iota}_n '    \\mathbold{p } '   \\right)^{-1 }        \\mathbold{p }   \\mathbold{b}_b '   \\mathbold{u }   , \\end{aligned}\\ ] ] where in the second step we used the model @xmath610 , and we added a term proportional to @xmath611 in the square brackets , which is zero due to the normalization of @xmath612 , which can be written as @xmath613 .",
    "notice that @xmath614 .",
    "however , compared to the proof of lemma  [ lemma : existence ] the difficulty is that , here , the matrices @xmath615 and @xmath616 do not commute . to resolve this problem we rewrite the last result as @xmath617 now , the matrices @xmath618 and @xmath619 commute , because the zero eigenvalue of @xmath618 has multiplicity one ( as we assume @xmath223 to be connected ) with eigenvector given by @xmath620 , namely we have @xmath621 .",
    "here , we used @xmath622 , which follows from the definition of @xmath623 and @xmath624 .",
    "we therefore have @xmath625 and the last term does not contribute to @xmath626 because we have @xmath627 .",
    "we therefore have , independent from the choice of @xmath611 , that @xmath628 using @xmath629 we thus find @xmath630 because @xmath631 is a linear combination of the jointly normal errors it is also normally distributed , so we have @xmath632 .",
    "this concludes the proof .",
    "[ [ proof - of - theoremthdecomposition - graph - partitioning ] ] proof of theorem  [ th : decomposition ] ( graph partitioning ) + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    throughout the proof we maintain the same notational conventions as for the proof of lemma [ lemma : var_decomposition ] . recall that the variance of @xmath63 is @xmath633 . the variance of the infeasible estimator based on equals @xmath634 we show below that @xmath635 for matrices @xmath636 and @xmath637 we also establish that @xmath638 and that @xmath639 for any @xmath291 . combining these results yields that , for any @xmath291 , @xmath640^{1/2 }    \\nonumber   \\\\    & \\qquad \\qquad   \\leq            { \\mathbold v } '    \\left (   { \\mathbold l}^\\dagger - { \\mathbold l}_w^\\dagger - { \\mathbold p } '      { \\mathbold l}_*^{\\rm inv }   { \\mathbold p } \\right )   { \\mathbold v }",
    "\\leq       \\nonumber \\\\    &   \\qquad \\qquad \\qquad \\qquad        \\kappa \\ ; { \\mathbold v } ' { \\mathbold p } '      { \\mathbold l}_*^{\\rm inv }   { \\mathbold p } \\ ,   { \\mathbold v }         +   2 \\kappa^{1/2 }        \\left [    \\left ( { \\mathbold v } '   { \\mathbold l}_w^\\dagger { \\mathbold v }   \\right )          \\left({\\mathbold v } ' { \\mathbold p } '      { \\mathbold l}_*^{\\rm inv }   { \\mathbold p } \\ ,   { \\mathbold v}\\right ) \\right]^{1/2 } .",
    "\\end{aligned}\\ ] ] by lemma [ lemma : var_decomposition ] this is the result of theorem [ th : decomposition ] .",
    "it remains only to show , , and , which we do , in turn , next .",
    "[ [ proof - of- . ] ] proof of .",
    "+ + + + + + + + + +    start with the upper bound .",
    "because @xmath641 and @xmath642 , it holds that @xmath643 expanding those terms , and using that @xmath644 , and @xmath645 , and @xmath646 , we obtain @xmath647 using that @xmath648 , and @xmath649 , and @xmath650 and also the transpose of the last result , we obtain @xmath651 because @xmath652 we thus find @xmath653 which is the upper bound given in the lemma .    now turn to the lower bound . introduce @xmath654 we then have @xmath655 plugging this in the equality @xmath656 we obtain @xmath657 bringing @xmath658 to the right - hand side , multiplying with @xmath659 from the left , and using the last equality in , we obtain @xmath660 the matrices @xmath661 and @xmath662 commute , and we therefore have @xmath663 using this as well as @xmath664 and @xmath665 we find that the equation in becomes @xmath666 taking the transpose of this last equation gives @xmath667 replacing @xmath668 on the right - hand side of the last equation by the expression for @xmath668 in we get @xmath669 using the definition of @xmath670 we obtain @xmath671 and the last result on @xmath672 can therefore be rewritten as @xmath673 because @xmath674 the last expression is positive semi - definite , which gives the lower bound on @xmath675 in the lemma .",
    "this concludes the proof .",
    "[ [ proof - of-.-1 ] ] proof of .",
    "+ + + + + + + + + +    let @xmath676 where we set @xmath677 if @xmath341 .",
    "then @xmath678 . has non - negative elements but may be non - invertible as , for @xmath289 , we have @xmath679 , with @xmath299 . we therefore write",
    "@xmath680 instead of just @xmath681 . ] also define the symmetrically normalized laplacian of @xmath258 because we may have @xmath682 for some @xmath420 . ]",
    "@xmath683 from ( * ? ? ?",
    "* lemma 1.7 ) we know @xmath684 , which can also be written as @xmath685 .",
    "we have @xmath686 , and thus find @xmath687 .",
    "the diagonal matrix @xmath688 has @xmath10th diagonal element equal to @xmath689 for @xmath690 , @xmath299 , and equal to zero otherwise . from the definition of @xmath293 in the main text we thus find @xmath691 and therefore @xmath692",
    "the matrix @xmath693 is similar to @xmath694 , and so they share the same eigenvalues .",
    "and @xmath695 are similar if there exists an invertible matrix @xmath696 such that @xmath697 .",
    "two similar matrices have the same eigenvalues . ]",
    "we therefore have that @xmath698 holds .    using the inequalities @xmath685 and @xmath687 along with and we obtain @xmath699 and @xmath700 these yield the inequalities stated in .",
    "this concludes the proof .    [",
    "[ proof - of-.-2 ] ] proof of .",
    "+ + + + + + + + + +    recall that @xmath701 applying the cauchy - schwarz inequality @xmath702 with @xmath703 and @xmath704 , and using we find @xmath705 which gives .",
    "this concludes the proof .",
    "[ [ proof - of - theoremthmsecondorderbound - second - order - bound ] ] proof of theorem  [ thm : secondorderbound ] ( second - order bound ) + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    [ [ proof - of - theoremthmsecondorderbound . ] ] proof of theorem  [ thm : secondorderbound ] .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    we start with the lower bound given in the theorem .",
    "let @xmath706 $ ] ; then @xmath707 .",
    "without loss of generality we fix @xmath172 and relabel the elements of @xmath30 so that @xmath708 .",
    "let @xmath709 } \\end{array}\\right ) , \\qquad   \\mathbold{l}_{[i ] } : = \\mathbold{d}_{[i]}-   \\mathbold{a}_{[i]},\\ ] ] using obvious notation for the @xmath710 degree and adjacency matrices in the latter definition .",
    "now , by the inversion formula for partitioned matrices , @xmath711}^{-1 } { \\mathbold \\iota}_{d_i } }         \\left ( \\begin{array}{cc }               1                &     { \\mathbold \\iota}_{d_i } '   { \\mathbold l}_{[i]}^{-1 }    \\\\                    { \\mathbold l}_{[i]}^{-1 } { \\mathbold \\iota}_{d_i }    &                  \\left [                  \\frac { { \\mathbold l}_{[i ] } - d_i^{-1 }      { \\mathbold \\iota}_{d_i } { \\mathbold \\iota}_{d_i } ' }                  { d_i - { \\mathbold \\iota}_{d_i } '   { \\mathbold l}_{[i]}^{-1 } { \\mathbold \\iota}_{d_i } } \\right]^{-1 }          \\end{array } \\right ) .",
    "\\end{aligned}\\ ] ] below we show that @xmath712}^{-1 } { \\mathbold \\iota}_{d_i }     \\right )      \\right ]      } { d_i - { \\mathbold \\iota}_{d_i } ' { \\mathbold l}_{[i]}^{-1 } { \\mathbold \\iota}_{d_i } }      \\right\\ }      & \\leq \\frac{\\sigma^2 \\ ,        { \\mathbold \\iota}_{d_i } '   { \\mathbold l}_{[i]}^{-1 }           ( { \\mathbold a}_{\\circ \\ # } )   { \\mathbold d}^{-1}_{\\ # }   ( { \\mathbold a}_{\\circ \\ # } ) '    { \\mathbold l}_{[i]}^{-1 } { \\mathbold \\iota}_{d_i }          }      { \\lambda_2 \\left ( d_i - { \\mathbold \\iota}_{d_i } ' { \\mathbold l}_{[i]}^{-1 } { \\mathbold \\iota}_{d_i } \\right)^2 }   ,         \\label{boundblockintermediate }   \\end{aligned}\\ ] ] where @xmath713 is the upper left @xmath714 block of @xmath715 , @xmath716 is the upper right @xmath717 block of  @xmath718 , and @xmath719 is the lower right @xmath720 block of @xmath721 . to make further progress , note that the expansion @xmath722}^{-1 } & =   \\sum_{q=0}^{\\infty }    \\left (   { \\mathbold d}_{[i]}^{-1 } { \\mathbold a}_{[i ] }    \\right)^{q } { \\mathbold d}_{[i]}^{-1}\\end{aligned}\\ ] ] is convergent , because we have @xmath723}^{-1 } { \\mathbold a}_{[i ] }   \\rvert_\\infty < 1 $ ] , where @xmath724 denotes the maximum absolute row sum matrix norm .",
    "we therefore have @xmath725}^{-1 } { \\mathbold \\iota}_{d_i }      & = { \\mathbold \\iota}_{d_i } '    { \\mathbold d}_{[i]}^{-1 } { \\mathbold \\iota}_{d_i }         + { \\mathbold \\iota}_{d_i } '   \\sum_{q=1}^{\\infty }    \\left (   { \\mathbold d}_{[i]}^{-1 } { \\mathbold a}_{[i ] }    \\right)^{q } { \\mathbold d}_{[i]}^{-1 }           { \\mathbold \\iota}_{d_i }      \\nonumber \\\\      & \\geq        { \\mathbold \\iota}_{d_i } '    { \\mathbold d}_{[i]}^{-1 } { \\mathbold \\iota}_{d_i }        = \\sum_{j \\in [ i ] }    d_j^{-1 }    ,     \\label{boundlowerint }    \\end{aligned}\\ ] ] where we used that @xmath726}^{-1 } { \\mathbold a}_{[i ] }    \\right)^{q } { \\mathbold d}_{[i]}^{-1 }           { \\mathbold \\iota}_{d_i } \\geq 0 $ ] , because this is a product and sum of vector and matrices that all have non - negative entries .",
    "define the @xmath714 diagonal matrix @xmath727 } = { \\rm diag } ( \\underline{d}_{j , i } : j \\in [ i ] ) $ ] .",
    "we have @xmath728 }   - \\underline { \\mathbold d}_{[i ] }        & = { \\rm diag } ( { \\mathbold a}_{[i ] } { \\mathbold \\iota}_{d_i } ) - { \\mathbold a}_{[i ] }       \\geq 0 ,      \\label{bound1111 }   \\end{aligned}\\ ] ] because @xmath729 } { \\mathbold \\iota}_{d_i } ) - { \\mathbold a}_{[i]}$ ] can be expressed as a sum of matrices of the form @xmath730 embedded into an @xmath714 matrix .",
    "we therefore have @xmath731}^{-1 } \\leq \\underline { \\mathbold d}^{-1}_{[i]}$ ] , implying @xmath732}^{-1 } { \\mathbold \\iota}_{d_i }        & \\leq    { \\mathbold \\iota}_{d_i } '   \\underline { \\mathbold d}^{-1}_{[i ] } { \\mathbold \\iota}_{d_i }        = \\sum_{j \\in [ i ] }    \\underline{d}_{j , i}^{-1 }   .",
    "\\label{boundupperint }      \\end{aligned}\\ ] ] combining , and gives @xmath733 }    \\underline{d}_{j , i}^{-1 } \\right ) \\right ] }      { \\sum_{j \\in [ i ] } \\left ( 1 - d_j^{-1 } \\right ) } = \\frac{\\sigma^2}{d_i ( 1- h^{-1}_{i } ) } \\left(1 - \\frac{2}{n } - \\frac{2}{n } \\frac{d_i}{\\underline h_{i}}\\right ) ,   \\end{aligned}\\ ] ] which is the lower bound stated in the theorem .    to show the upper bound ,",
    "consider the the graph @xmath734 , with @xmath735 { \\times}[i]$ ] .",
    "that is , we construct @xmath736 by deleting all edges between neighbors of @xmath10 from @xmath12 . note that @xmath737 is still connected , because all vertices in @xmath144 $ ] are connected through @xmath10 .",
    "let @xmath738 be the estimator for @xmath739 obtained for @xmath737 , in the same way that @xmath295 was obtained for @xmath118 .",
    "let @xmath740 be the laplacian matrix of @xmath737 .",
    "analogous to we have @xmath741 , and therefore @xmath742 .",
    "the result holds for any connected graph , and so can equally be applied to @xmath737 , we only need to replace @xmath743 by @xmath744 and @xmath715 by @xmath745 .",
    "the matrices @xmath716 and @xmath746 are identical for @xmath737 and @xmath118 . however ,",
    "for @xmath737 we find @xmath747 } = \\underline { \\mathbold d}_{[i]}$ ] , because the degree of vertex @xmath11 is given by @xmath456 , and we have @xmath748}=0 $ ] , because there are no edges that connect elements in @xmath144 $ ] .",
    "we thus have @xmath749 } = \\widetilde { \\mathbold d}_{[i ] } - \\widetilde { \\mathbold a}_{[i ] } = \\underline { \\mathbold d}_{[i]}$ ] .",
    "therefore , @xmath750}^{-1 } { \\mathbold \\iota}_{d_i }     \\right )      \\right ]      } { d_i - { \\mathbold \\iota}_{d_i } '   \\underline { \\mathbold d}_{[i]}^{-1 } { \\mathbold \\iota}_{d_i } }      + \\frac{\\sigma^2 \\",
    ",        { \\mathbold \\iota}_{d_i } '    \\underline { \\mathbold d}_{[i]}^{-1 }           ( { \\mathbold a}_{\\circ \\ # } )   { \\mathbold d}^{-1}_{\\ # }   ( { \\mathbold a}_{\\circ \\ # } ) '     \\underline { \\mathbold d}_{[i]}^{-1 } { \\mathbold \\iota}_{d_i }          }      { \\lambda_2 \\left ( d_i - { \\mathbold \\iota}_{d_i } '   \\underline { \\mathbold d}_{[i]}^{-1 } { \\mathbold \\iota}_{d_i } \\right)^2 }   , \\end{aligned}\\ ] ] and evaluating the right - hand side of the last inequality gives the upper bound on @xmath751 in the theorem .",
    "this concludes the proof .",
    "[ [ proof - of-.-3 ] ] proof of .",
    "+ + + + + + + + + +    we prove the following more general result .",
    "let @xmath12 be connected .",
    "choose @xmath752 with @xmath753 , and let @xmath754 .",
    "let @xmath755 and @xmath756 .",
    "relabel the elements in @xmath30 such that @xmath757 .",
    "let @xmath758 , @xmath713 be the upper left @xmath714 block of @xmath715 , @xmath716 be the upper right @xmath717 block of  @xmath718 , and @xmath719 be the lower right @xmath720 block of @xmath721 .",
    "then , @xmath759      & \\leq \\frac{\\sigma^2}{\\lambda_2 }   { \\mathbold l}_\\circ^{-1 }   ( { \\mathbold a}_{\\circ \\ # } )   { \\mathbold d}^{-1}_{\\ # }   ( { \\mathbold a}_{\\circ \\ # } ) '   { \\mathbold l}_\\circ^{-1 }   \\end{aligned}\\ ] ] holds .    to show the result ,",
    "define the @xmath256 matrices @xmath760 with obvious definition of @xmath761 such that @xmath762 . because the graph is connected the pseudo - inverse @xmath763 satisfies @xmath764 .",
    "plugging @xmath762 into this expression we obtain @xmath765 using the transposed of this last equation to replace @xmath766 on the right - hand side of that same equation we obtain @xmath767 where in the last step we have used that @xmath768 , which follows from @xmath769 . evaluating the last result for the upper left @xmath714 block gives @xmath770 with obvious definition of @xmath771 .",
    "we obtain the result searched for for @xmath772 by also using @xmath773 .",
    "this concludes the proof .",
    "here we strenghten the result of theorem  [ th : decomposition ] by showing that the estimator @xmath295 is close to the ( infeasible ) estimator @xmath296 when @xmath293 is small .",
    "we also provide a corresponding result for the feasible version @xmath774 , where @xmath775 our focus in the main text is on the infeasible estimator .",
    "this is so because we use it as a devise to analyze the variance of @xmath63 , and @xmath605 is independent of @xmath597 while its feasible version is clearly not .",
    "if an alternative estimator to @xmath63 is desired , @xmath774 will obviously be of interest .",
    "note , however , that @xmath776 by the gauss - markov theorem ( this , in fact , yields the upper bound given in ) .",
    "[ th : estimatordecomposistion ] let @xmath118 and @xmath216 be connected . for @xmath420 define @xmath777 by @xmath778",
    "we then have @xmath779 ,          &           \\mathbb{e }   ( r_{i}^2 ) \\ , & \\leq \\ , \\kappa \\ ,     { \\rm var } (   \\widehat   \\gamma_{r(i ) }   ) .",
    "\\end{aligned}\\ ] ]    the theorem shows that , if @xmath293 is small , then the differences between @xmath780 and @xmath781 , and between @xmath780 and @xmath782 , are both small compared to the stochastic variability of @xmath783 and @xmath784 themselves .",
    "thus , the result of theorem  [ th : decomposition ] generalizes from the variances to the estimators themselves .",
    "the result ( and its proof ) also immediately extends to a setting as in theorem  [ thm : firstordergeneralized ] , where the errors @xmath29 can be non - normal , heteroscedastic , or correlated .",
    "one only needs to replace @xmath785 by @xmath786 and @xmath787 by @xmath788 , where @xmath789 is a bound on the largest eigenvalue of @xmath790 .    in vector notation",
    "the estimator decompositions reads @xmath791 analogous to the proof of lemma  [ lemma : existence ] and lemma  [ lemma : var_decomposition ] above we can use the first - order conditions of their respective minimization problem to obtain explicit formulas for @xmath792 , @xmath793 and @xmath794 .",
    "we thus find @xmath795 and @xmath796 it is easy to verify that @xmath797 and @xmath798 , and therefore @xmath799 using this we find @xmath800,\\end{aligned}\\ ] ] where in the second to last inequality we used the lower bound for @xmath801 in above , and in the last inequality we used results from the proof of theorem  [ th : decomposition ] .",
    "we have thus shown the result for @xmath802 in the theorem .",
    "similarly we find @xmath803 which implies the result for @xmath804 in the theorem .",
    "this concludes the proof ."
  ],
  "abstract_text": [
    "<S> this paper studies inference on fixed effects in a linear regression model estimated from network data . </S>",
    "<S> we derive bounds on the variance of the fixed - effect estimator that uncover the importance of the smallest non - zero eigenvalue of the ( normalized ) laplacian of the network and of the degree structure of the network . </S>",
    "<S> the eigenvalue is a measure of connectivity , with smaller values indicating less - connected networks . </S>",
    "<S> these bounds yield conditions for consistent estimation and convergence rates , and allow to evaluate the accuracy of first - order approximations to the variance of the fixed - effect estimator .    </S>",
    "<S> _ keywords : _ fixed effects , graph , laplacian , network data , variance bound _ jel classification : _ </S>",
    "<S> c23 , c55    # 1    1    1    0    1    * fixed - effect regressions on network data * </S>"
  ]
}