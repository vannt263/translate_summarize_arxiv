{
  "article_text": [
    "in an earlier paper  @xcite we introduced the pde ( probability density estimation ) method , an essentially non - parametric and multivariate method designed for identifying small signals among large backgrounds .",
    "the method makes use of kernel density estimates for signal and background probability densities , and a simple discriminant function is then used to classify candidate events .",
    "the pde method was applied successfully to the search for the top quark at the fermilab tevatron , and it is an integral part of a general search strategy  @xcite for analyzing data from high - energy physics experiments .    in this paper",
    "we present , an extension of the pde method designed for parameter estimation , where @xmath0 represents a vector of parameters to be estimated . in many applications",
    "@xmath0 is a single parameter , such as the mass of an unstable particle detected through its decay products .",
    "this non - parametric and multivariate method may be particularly applicable to problems such as determining the mass of the top quark in the upcoming collider run ( run ii ) of the fermilab tevatron .",
    "multivariate methods are now widely recognized as being more powerful than univariate methods , and a non - parametric method has the advantage that one need not make assumptions about the forms of probability distributions . those who feel uneasy about the `` black - box '' quality of neural networks should welcome the straightforward manipulation of probability densities used in this method , and the intuitive graphical interpretation that results . because probability densities are constructed and manipulated directly , obtaining any additional statistical information",
    " bayesian credible intervals , for example  is a straightforward exercise .",
    "a typical parameter estimation problem is described in sec .",
    "[ sec : problem ] ; our recipe for solving it is provided in sec .",
    "[ sec : recipe ] .",
    "the salient features of the method and its potential advantages are summarized in sec .",
    "[ sec : conclusions ] .",
    "the next decade of high energy collider physics will emphasize measurements and searches for new phenomena at the scale of several hundred gev .",
    "the existence of a new particle at this scale can be convincingly demonstrated by observing a peak in an invariant mass distribution , but the signature may be such that more indirect methods of establishing the particle s existence , and subsequently measuring parameters such as its mass and couplings , are required .",
    "we introduce  with an example of this nature : the determination of the top quark mass .",
    "top quarks are pair - produced at the fermilab tevatron , each decaying promptly to a @xmath1 boson and a @xmath2 quark .",
    "each @xmath1 boson in turn decays either to a charged lepton and a neutrino , or to two quarks .",
    "quarks hadronize , appearing in the detector as collimated flows of energy ( jets ) .",
    "the characteristic experimental signature for a top quark event is therefore a final state containing either an energetic lepton , missing transverse energy , and several energetic jets , or a final state containing two energetic leptons , missing transverse energy , and a pair of jets ; decays to six jets are difficult to distinguish from events in which no top quark was produced .",
    "the application of selection criteria favoring events with jets originating from @xmath2 quarks enhances the fraction of top quark events in the sample .    for the sake of simplicity",
    "we assume that two variables @xmath3 have been identified for this analysis .",
    "this pair might be the transverse energies of the lepton and the leading jet ; it might be the invariant mass of the sub - leading jets and the transverse momentum of the @xmath1 boson ; it might be the scalar sum of all jet transverse energies and the output of a neural network built with event - shape variables .",
    "no special assumptions about the nature of these variables need be made .",
    "the goal is to construct a method that performs as well as ( or better than ) such popular algorithms as neural networks , but to keep the method sufficiently simple that it reads like a recipe .",
    "the recipe follows .",
    "this method has its roots in bayesian statistics , and as a result it has the advantage ( disadvantage ) of enabling ( requiring ) the specification of a function @xmath5 that encodes prior beliefs about the value of the top quark mass @xmath6 .",
    "@xmath7 here is used in standard bayesian notation to represent all assumptions implicit in our specification of this prior probability .",
    "the basic assumptions contained in @xmath7 will not change , so we drop it from here on , writing simply @xmath4 . a natural choice for @xmath4 , used when there is strong belief that the true mass must lie somewhere between @xmath8 and @xmath2 but no reason to prefer any value within that range over any other , is the flat prior : @xmath9 for @xmath10 , and @xmath11 elsewhere .",
    "monte carlo events are generated with top quark masses @xmath6 pulled from the distribution @xmath4 specified above .",
    "that is , the probability that an event with a top quark mass between @xmath6 and @xmath12 is generated is @xmath13 . for each monte carlo event",
    "we calculate the two variables @xmath14 .",
    "a histogram in @xmath15 filled with the generated events approximates the joint density @xmath16 .",
    "this function has the property that , given an event in which a top quark is produced and decays to the observed final state , the probability that the top quark mass was between @xmath6 and @xmath12 , the first variable between @xmath17 and @xmath18 , and the second variable between @xmath19 and @xmath20 , is simply @xmath21 .",
    "each of the @xmath23 monte carlo events just generated is characterized by three numbers : the value of @xmath17 , the value of @xmath19 , and the top quark mass @xmath6 .",
    "the monte carlo events are labeled with the index @xmath24 ( @xmath25 ) ; the three numbers corresponding to the @xmath26 event are then @xmath27 , @xmath28 , and @xmath29 .",
    "define the _ event vector _",
    "@xmath30 for the @xmath26 monte carlo event by @xmath31 and define the _ training array _ @xmath22 for the entire set of monte carlo events by @xmath32 here and below @xmath24 ranges from 1 to @xmath23 and indexes the monte carlo events ; @xmath33 ranges from 1 to 3 and indexes the components of the event vector @xmath34 .",
    "having defined the event vector @xmath34 , calculate the _",
    "mean event vector _ @xmath35 and construct the _ training covariance matrix _ @xmath36 in the standard way .",
    "@xmath37 is a 3 by 3 symmetric matrix , with @xmath38 , @xmath39 , and so on .      in sec .",
    "[ sec : generatemontecarlo ] we imagined filling a three - dimensional histogram in @xmath34 with monte carlo events , and we recognized that the resulting histogram represents an estimation of a probability density .",
    "a well - known technique in multivariate statistics involves estimating a probability density not by filling a histogram , but rather by summing kernels of probability placed around each point .",
    "due to its familiarity and smoothness properties , a favorite kernel choice is the multivariate gaussian :    @xmath41    the vector @xmath34 is the same three - component vector defined above , and @xmath42 is the inverse of the training array covariance matrix @xmath37 .",
    "the parameter @xmath43 is known in the language of density estimation as a _ smoothing parameter _ ; it controls the width of the kernels placed around each point .",
    "theoretical arguments suggest an optimal choice of @xmath44 as a function of the number of data points @xmath23 and the dimensionality @xmath45 of the variable space . depends on assumptions about the probability density that we have not made explicit , and is not exact  @xcite . in practice",
    ", @xmath43 may be optimized for any set of monte carlo events by constructing and minimizing some appropriate error estimate @xmath46 . for @xmath47 and @xmath48 ,",
    "the optimal choice for @xmath43 is roughly 0.20 . ]",
    "an estimate of the joint probability density @xmath40 is then obtained simply by summing kernels centered about each of the @xmath23 data points @xmath30 , so that    @xmath49      a physicist attempting to measure the top quark mass is interested in the _ posterior density _",
    "@xmath50 for @xmath6 . in words , @xmath50 is the probability that the top quark mass is @xmath6 given that we have observed an event with variable values @xmath51 .",
    "this posterior density is easily obtained .",
    "the probability of obtaining both @xmath51 and @xmath6 is equal to the probability of obtaining @xmath51 multiplied by the probability of obtaining @xmath6 given that you have obtained @xmath51 : @xmath52 and the probability of obtaining @xmath51 is given by integrating the probability of obtaining both @xmath51 and @xmath6 over all values of @xmath6 : @xmath53 thus the posterior density @xmath50 is related to the joint density @xmath54 simply by @xmath55      in the bayesian view , the posterior density is the natural result of this recipe .",
    "nonetheless , it is often convenient to reduce the posterior density @xmath50 to a single number @xmath56 representing the _ best estimate _ of the parameter in question . among the natural choices for the best estimate",
    "are the mean , median , and mode of the posterior distribution . adopting the last for the purposes of this discussion",
    ", we solve the equation @xmath57 numerically for @xmath56 . since the denominator of eq .",
    "[ eqn : posteriordensity ] is independent of @xmath6 , maximizing the posterior density @xmath50 is equivalent to maximizing the joint density @xmath54 , which we have constructed explicitly .",
    "the extent to which the posterior density @xmath50 peaks around the value @xmath56 depends , of course , on how strongly the variables @xmath51 correlate with the true mass @xmath6 .",
    "we note that this method can be modified to produce results that obey the frequentist notion of coverage .",
    "assume that a 68% confidence region is desired .",
    "starting with @xmath58 , draw for each fixed @xmath6 the contour @xmath59 in @xmath51-space enclosing 68% of the density and minimal area . then upon observing @xmath51 in the data ,",
    "the 68% confidence region for @xmath6 is the union of all values of @xmath6 for which @xmath51 lies inside @xmath59 .",
    "1.0 cm    extension to the case of an ensemble of data events is treated in appendix  [ sec : bkgevents ] .",
    "the analysis method described here is quite general , and can be used in the context of any parameter estimation problem .",
    "the non - parametric approach used to estimate probability densities is helpful when the distributions under consideration do not lend themselves to an obvious parameterization .  allows the use of several measured variables , and enables the simultaneous estimation of several parameters .",
    "the generalization to arbitrary dimension is provided in appendix  [ sec : arbitrarydimension ] .",
    "bayesian credible intervals and moments are easily obtained from simple manipulations of the joint probability density .",
    "for pedagogical reasons ,  has been introduced through a specific example  determining the mass @xmath6 of the top quark from two measured quantities @xmath17 and @xmath19  and the expressions in the text are therefore specific to that example . in this appendix",
    "we provide the formulae for the general case .    in the general case , let each event be characterized by @xmath60 known variables @xmath51 and @xmath61 unknown parameters @xmath0 .",
    "let @xmath62 , and let the @xmath45-dimensional event vector be @xmath63 .",
    "the @xmath26 monte carlo event is now described by the event vector @xmath64 and the entire monte carlo sample is described by the training array @xmath65 where @xmath33 now ranges from 1 to @xmath45 .",
    "the mean event vector is @xmath66 and the training covariance matrix is @xmath67 as before , and the general multivariate gaussian is given by @xmath68 finally , in eqs .",
    "[ eqn : posteriordensity ] and  [ eqn : max ] , @xmath6 should be replaced by the vector @xmath0 .    in practice ,",
    "limited computing resources place an upper bound on @xmath23 , and hence an upper bound on @xmath45 .",
    "the optimal accuracy of the kernel estimate is of order @xmath69 , where @xmath70 is a positive integer that reflects the assumed smoothness of the unknown density , and a typical assumption of continuous and square integrable derivatives up to second order corresponds to @xmath71  @xcite .",
    "in this appendix we describe a modification to the procedure described in the text if practical constraints prevent the generation of events pulled from a continuous prior @xmath4 , but allow the generation of events at @xmath72 discrete values @xmath73 , where @xmath74 .",
    "two changes are required in the first five steps of the recipe ( secs .",
    "[ sec : prior][sec : jointdensity ] ) .",
    "first , it is assumed that practical constraints require monte carlo events to be generated at the discrete masses @xmath73 , rather than as described in sec .",
    "[ sec : generatemontecarlo ] .",
    "second , the function calculated in eq .",
    "[ eqn : jointdensity ] , which may no longer be interpreted as a joint density , should be re - labeled . for lack of a better alternative ,",
    "call it @xmath75 .",
    "we now add a step 5@xmath76 between secs .",
    "[ sec : jointdensity ] and  [ sec : posterior ] .",
    "the function @xmath75 is clearly not an appropriate density .",
    "if events have been generated assuming five different masses @xmath73 , a graph of @xmath75 might appear as shown in fig .",
    "[ fig : fig1 ] .",
    "we see that the density has ridges along the values of @xmath6 for which events have been generated , with corresponding valleys in the regions between these values .",
    "an appropriately rescaled probability density @xmath54 can be generated by multiplying @xmath75 by a normalizing @xmath6-dependent factor @xmath77 : @xmath78 this normalizing factor will correct for the fact that valleys have been introduced into the density by only generating events at specific masses @xmath73 .",
    "the requirement that @xmath79 determines this normalizing factor uniquely .",
    "the desired joint probability density @xmath40 is then given by @xmath80 and the final step ( sec .  [ sec : posterior ] ) is exactly as before . the rescaled density of fig .",
    "[ fig : fig1 ] is shown in fig .",
    "[ fig : fig2 ] .",
    "we mention briefly a useful shortcut when calculating integrals such as that appearing in the denominator of eq .",
    "[ eqn : gdef ] .",
    "multidimensional integrals are difficult to calculate in general , but this integral can be handled analytically provided one uses gaussian kernels .",
    "assume as in appendix  [ sec : arbitrarydimension ] that the vector of known variables @xmath51 is of @xmath60 dimensions , that the vector of unknown variables @xmath81 is of @xmath61 dimensions , and that the monte carlo has a covariance matrix @xmath37 .",
    "then the relevant formula is @xmath82 where @xmath83 is the @xmath61 by @xmath61 sub - matrix of @xmath84 formed by retaining elements with row and column numbers larger than @xmath60 .",
    "in the text we considered the problem of determining the top quark mass @xmath6 for one candidate event . in a real analysis there will be @xmath85 such events , and of those some fraction @xmath2 are expected to be background events  events that do not contain a top quark at all .",
    "this appendix shows how to apply  to a complete analysis .",
    "signal and background monte carlo events are generated and used to construct the signal density @xmath86 , as described in secs .",
    "[ sec : prior][sec : jointdensity ] , and the background density @xmath87 , which is independent of @xmath0 . from a careful analysis of background efficiencies",
    "we determine the probability @xmath88 that a fraction @xmath2 of our events are background events . in previous sections of this article @xmath89",
    "referred to monte carlo events ; in this section we change notation and label the @xmath85 observed data events by @xmath90 .",
    "the goal is to compute the posterior density @xmath91 .",
    "since the observations @xmath92 are assumed to be independent , @xmath93 factors into a product : @xmath94 the probability @xmath95 for the @xmath26 data event can be written in terms of the signal and background probability densities as @xmath96 where @xmath97 . integrating out the _ nuisance parameter _",
    "@xmath2 in eq .",
    "[ eqn : eqn15 ] leaves @xmath98}\\right ) p(b)\\,db},\\ ] ] where @xmath99 is a normalization factor ensuring that @xmath100 , and @xmath101 is assumed .",
    "the most likely values of the parameters @xmath0 are then those for which @xmath102 achieves its maximum , and the uncertainty on these values can be estimated from the width of the peak . other frequently - used best estimates and their errors are easily computed , if desired , from straightforward manipulation of the posterior density @xmath102 ."
  ],
  "abstract_text": [
    "<S> we present , a new multivariate analysis technique for parameter estimation . </S>",
    "<S> the method is based on a direct construction of joint probability densities of known variables and the parameters to be estimated . </S>",
    "<S> we show how posterior densities and best - value estimates are then obtained for the parameters of interest by a straightforward manipulation of these densities . </S>",
    "<S> the method is essentially non - parametric and allows for an intuitive graphical interpretation . </S>",
    "<S> we illustrate the method by outlining how it can be used to estimate the mass of the top quark , and we explain how the method is applied to an ensemble of events containing background .    parameter estimation , density estimation , multivariate 02.50.sk , 02.50.ph , 02.50.rj </S>"
  ]
}