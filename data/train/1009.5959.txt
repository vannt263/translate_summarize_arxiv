{
  "article_text": [
    "the relay channel , originally proposed in @xcite , models a communication scenario where there is a relay node that can help the information transmission between the source and the destination .",
    "two fundamentally different relay strategies have been developed in @xcite for such channels , which , depending on whether the relay decodes the information or not , are generally known as _ decode - and - forward _ and _ compress - and - forward _ respectively .",
    "the compress - and - forward relay strategy is used when the relay can not decode the message sent by the source , but still can help by compressing and forwarding its observation to the destination .",
    "specifically , consider the relay channel depicted in fig .",
    "the relay compresses its observation @xmath0 into @xmath1 , and then forwards @xmath1 to the destination via @xmath2 . to reduce the rate loss caused by the delay , block markov coding was used in @xcite , and more blocks leads to less loss .        in this paper , based on the differences in the detailed encoding / decoding processes ,",
    "the following five different compress - and - forward relay schemes will be considered .    * cumulative encoding / block - by - block forward decoding / compression - message successive decoding ; * cumulative encoding / block - by - block forward decoding / compression - message joint decoding ; * repetitive encoding / all blocks united decoding / compression - message joint decoding ; * cumulative encoding / block - by - block backward decoding / compression - message successive decoding ; * cumulative encoding / block - by - block backward decoding / compression - message joint decoding .",
    "the cumulative encoding / block - by - block forward decoding / compression - message successive decoding refers to the original compress - and - forward scheme developed in @xcite .",
    "the encoding is `` cumulative '' in the sense that in each new block , a new piece of information is encoded at the source .",
    "this distinguishes from a `` repetitive '' encoding process recently proposed in @xcite , where the same information is encoded in each block .",
    "the decoding is named `` block - by - block forward '' to distinguish from the other two choices , where the decoding starts only after all the blocks have been finished , either by decoding with all the blocks together , or by decoding block - by - block backwardly .",
    "the decoding is also called `` compression - message successive '' in the sense that the destination first decodes the compression of the relay s observation , and then decodes the original message .",
    "the compression @xmath1 can be first recovered at the destination , as long as the following constraint is satisfied : @xmath3 then , based on @xmath1 and @xmath4 , the destination can decode the original message @xmath5 if the rate of the original message satisfies @xmath6    the above two - step compression - message successive decoding process requires @xmath1 to be decoded first .",
    "this facilitates the decoding of @xmath5 , but is not a requirement of the original problem . recognizing this , a joint compression - message decoding process was proposed in @xcite , where , instead of successively , the destination decodes @xmath1 and @xmath5 together .",
    "it turns out that the decoding of @xmath5 can be helped even if @xmath1 can not be decoded first .",
    "in fact , with joint decoding , the constraint is not necessary , and instead of , the achievable rate is expressed as @xmath7 moreover , although @xmath1 is not even required to be decoded eventually , it can be more easily decoded by joint decoding , and instead of , we need a less strict constraint : @xmath8 where , it is clear to see the assistance provided by @xmath5 .",
    "similar formulas as have been derived with different arguments in @xcite-@xcite . , and were later corrected in @xcite . ]    therefore , compared to successive decoding , joint compression - message decoding provides more freedom in choosing the compression @xmath1 .",
    "however , the question remains whether joint decoding achieves strictly higher rates for the original message than successive decoding .",
    "for the single relay case , it has been proved in @xcite that the answer is negative , and any rate achievable by either of them can always be achieved by the other . in this paper , we are going to further consider the case of multiple relays as depicted in fig .",
    "[ fig2 ] , and demonstrate that joint decoding wo nt be able to achieve any higher rates either .",
    "more interestingly , we will show that any compressions not supporting successive decoding will actually result in strictly lower achievable rates for the original message .",
    "therefore , to optimize the achievable rate , the compressions should always be chosen so that successive decoding can be carried out .        recently",
    ", a different encoding process was proposed in @xcite , where instead of piece by piece , all the information is encoded in each block , and different blocks use independent codebooks to transmit the same information .",
    "compared to cumulative encoding , this repetitive encoding process appears to introduce collaboration among all the blocks , so that all the blocks can unitedly contribute to the decoding of the same message .",
    "this repetitive encoding / all blocks united decoding process was combined with joint compression - message decoding in @xcite , and although no improvement was shown in the single relay case , some interesting improvement on the achievable rate was obtained in the case of multiple relays . in this paper , we will show that actually it is not necessary to use repetitive encoding to introduce such collaboration among the blocks . the same rate can be achieved with cumulative encoding as long as the decoding starts after all the blocks have been finished .",
    "we will show that either by all blocks united decoding , or by block - by - block backward decoding , the same achievable rate can be obtained . therefore , in terms of complexity , cumulative encoding / block - by - block backward decoding provides the simplest way to achieve the highest rate in the case of multiple relays .    similarly , for these new encoding / decoding schemes , we will also show that the optimal compressions must be able to support successive compression - message decoding , and any compressions not supporting successive decoding will necessarily lead to strictly lower achievable rates than the optimal .",
    "therefore , for any of these compress - and - forward relay schemes mentioned above , we can restrict our attention to successive compression - message decoding in the search for the optimal compressions of the relays observations .",
    "of course , it should be noted that any compressions supporting successive decoding also support joint decoding .",
    "although the compressions supporting successive decoding can be explicitly characterized as we will show later , it is also of interest to consider other compressions not supporting successive decoding .",
    "for example , in a network with multiple destinations , when a relay is simultaneously helping more than one destinations , it is very likely that different destinations require different optimal compressions from the relay . in such a situation",
    ", the relay may have to find a tradeoff between these requirements , i.e. , adopting a compression which may be too coarse for some destinations , but too fine , thus not supporting successive decoding , for the others .",
    "an example of this tradeoff to optimize the sum rate was given for the two - way relay channel in @xcite .",
    "another possibility of using too coarse or too fine compressions is when there is channel uncertainty , e.g. , in wireless fading channels , so that it is impossible to accurately determine the optimal compressions even with explicit formulas .",
    "therefore , it is of interest to study how coarser or finer compressions than the optimal affect the achievable rate of the original message @xcite .",
    "it is not surprising that coarser compressions than the optimal do not fully exploit the capability of the relay , thus leading to lower achievable rates for the original message .",
    "however , it may not be so obvious why finer compressions will also lead to lower achievable rates . for this",
    ", one needs to realize that a relay s observation not only carries information about the original message , but also reflects the dynamics of the source - relay link , which is unrelated to the original message .",
    "thus , compared to the direct link between the source and the destination , the support by the relay - destination link is not so pure .",
    "when the compression is too fine so that only joint compression - message decoding can be carried out , i.e. , the direct source - destination link has to sacrifice , the gain does not make up for the loss .",
    "furthermore , to the extreme , when the compression can not be decoded even with joint decoding , the relay - destination link becomes useless , and the destination would rather simply treat the relay s input as purely noise in the decoding , as we will demonstrate in the paper .",
    "the remainder of the paper is organized as the following . in section [ s :",
    "mainresults ] , we formally state our problem setup and summarize the main results . then , in section [ s : b - bforward ] and section [ s : decodingallblocks ] , detailed proofs of the achievability results as well as thorough discussions on the optimal choice of the relays compressions , are presented , under the two different frameworks of block - by - block forward decoding and decoding after all the blocks have been finished , respectively . finally , some concluding remarks are included in section [ conclusion ] .",
    "consider the multiple - relay channel depicted in fig . [ fig2 ] , which can be denoted by @xmath9 where , @xmath10 are the transmitter alphabets of the source and the relays respectively , @xmath11 are the receiver alphabets of the destination and the relays respectively , and a collection of probability distributions @xmath12 on @xmath13 , one for each @xmath14 .",
    "the interpretation is that @xmath15 is the input to the channel from the source , @xmath16 is the output of the channel to the destination , and @xmath17 is the output received by the @xmath18-th relay .",
    "the @xmath18-th relay sends an input @xmath19 based on what it has received : @xmath20 where @xmath21 can be any causal function .    before presenting the main results , we introduce some simplified notations .",
    "denote the set @xmath22 , and for any subset @xmath23 , let @xmath24 , and use similar notations for other variables .",
    "the main results of the paper are presented in the following two different decoding frameworks : i ) block - by - block forward decoding ; ii ) decoding after all the blocks have been finished , which includes all blocks united decoding and block - by - block backward decoding .      under the block - by - block",
    "forward decoding framework , the achievable rate with successive compression - message decoding and the achievable rate with joint compression - message decoding are presented in theorems [ cfs ] and [ cfj ] respectively .",
    "then the optimality of successive decoding is stated in theorem [ optcf ] , and it is shown that the optimal rate can be achieved only if the compressions at the relays are chosen such that they can be first decoded at the destination , i.e. , successive compression - message decoding can be carried out .",
    "all the related proofs are presented in section [ s : b - bforward ] .",
    "[ cfs ] for the multiple - relay channel depicted in fig .",
    "[ fig2 ] , by the cumulative encoding / block - by - block forward decoding / compression - message successive decoding scheme , a rate @xmath25 is achievable if for some @xmath26 there exists a rate vector @xmath27 satisfying @xmath28 for any subset @xmath29 , such that for any subset @xmath30 , @xmath31 and @xmath32    [ cfj ] for the multiple - relay channel depicted in fig .",
    "[ fig2 ] , by the cumulative encoding / block - by - block forward decoding / compression - message joint decoding scheme , a rate @xmath33 is achievable if for some @xmath26 there exists a rate vector @xmath27 satisfying @xmath34 for any subset @xmath29 , such that for any subset @xmath30 , @xmath35    let @xmath36 and @xmath37 be the supremum of the achievable rates stated in theorems [ cfs ] and [ cfj ] respectively .",
    "[ optcf ] @xmath38 , and @xmath37 can be obtained only when the distribution @xmath39 is chosen such that there exists a rate vector @xmath27 satisfying - .      it was shown in @xcite that the original cumulative encoding / block - by - block forward decoding / compression - message successive decoding scheme developed in @xcite can be improved to achieve higher rates in the case of multiple relays , although no improvement was obtained in the case of a single relay . in their new compress - and - forward relay scheme @xcite , cumulative encoding",
    "was replaced by repetitive encoding , and block - by - block forward decoding was replaced by all blocks united decoding .",
    "they also used joint instead of successive compression - message decoding .",
    "for the single - source multiple - relay channel depicted in fig .",
    "[ fig2 ] , their theorem 1 in @xcite can be re - stated as the following theorem .    [ t : ruj ] for the multiple - relay channel depicted in fig .",
    "[ fig2 ] , a rate @xmath40 is achievable if there exists some @xmath26 such that @xmath41    in this paper , we will show that the improvement is not a result of replacing cumulative encoding by repetitive encoding , but actually , is a benefit obtained when the decoding is delayed , i.e. , only starts after all the blocks have been finished . besides all blocks united decoding",
    ", we will show that block - by - block backward decoding also achieves the same improvement since it also starts the decoding after all the blocks have been finished .",
    "similar to the framework of block - by - block forward decoding , we will also show that for these new schemes with decoding after all the blocks have been finished , the optimal rate can be achieved only when the compressions at the relays are chosen such that successive compression - message decoding can be carried out .",
    "thus , in terms of complexity , cumulative encoding / block - by - block backward decoding / compression - message successive decoding is the simplest choice in achieving the highest rate in the case of multiple relays .",
    "the corresponding achievable rate is presented in the following theorem .",
    "[ t : cbs ] for the multiple - relay channel depicted in fig .",
    "[ fig2 ] , a rate @xmath42 is achievable if there exists some @xmath26 such that for any subset @xmath30 , @xmath43 and @xmath44    let @xmath45 and @xmath46 be the supremum of the achievable rates stated in theorem [ t : ruj ] and [ t : cbs ] respectively , i.e. , @xmath47 and @xmath48 the optimality of successive decoding is demonstrated in the following theorem .",
    "[ t : optallblocks ] @xmath49 , and @xmath45 can be obtained only when the distribution @xmath39 is chosen such that holds .",
    "0.5 cm    as mentioned in the introduction , although the optimal rate is achieved only when successive decoding can be supported , there are situations where it is of interest to consider other compressions not supporting successive decoding . hence , more generally , we will use the cumulative encoding / block - by - block backward decoding / compression - message joint decoding .",
    "the corresponding achievable rate is given in the following theorem .",
    "[ t : cbj ] for the multiple - relay channel depicted in fig .",
    "[ fig2 ] , with a given distribution @xmath26 a rate @xmath50 is achievable if @xmath51 where @xmath52 is the unique largest subset of @xmath53 satisfying @xmath54 for any nonempty @xmath55 .",
    "in addition , @xmath56 can be decoded jointly with @xmath5 .",
    "there also exists a unique largest subset @xmath57 satisfying @xmath58 for any @xmath59 .",
    "it will be clear from the proof of theorem [ t : cbj ] that the compressions of the relays in @xmath60 are not decodable even jointly with the message .",
    "0.5 cm    on the other hand , the achievable rate can be more generally expressed as @xmath61 if we only consider a subset of relays @xmath62 for the decoding , while treating the other inputs as purely noise .",
    "interestingly , the following theorem implies that @xmath63 may not be the optimal choice to maximize the r.h.s .",
    "( right - hand - side ) of , i.e. , sometimes , it is better to consider only a subset of relays .",
    "[ t : equi ] for any @xmath64 , among all the choices of @xmath62 , the r.h.s . of is maximized when @xmath65 or @xmath66 , but is strictly less than the maximum when @xmath67 .",
    "here , @xmath52 and @xmath68 are defined as in and .",
    "therefore , not only the compressions of the relays in @xmath60 are not decodable , but also including them in the formula , i.e. , choosing @xmath67 , will even strictly lower the achievable rate .    by comparing and with @xmath65 , theorem [ t : equi ] also implies that for any compressions chosen at the relays , the cumulative encoding / block - by - block backward decoding / compression - message joint decoding scheme achieves the same rate as the repetitive encoding / all blocks united decoding / compression - message joint decoding scheme .",
    "the proofs of theorems [ t : cbs]-[t : equi ] are presented in section [ s : decodingallblocks ] .",
    "we first prove the achievability results stated in theorems [ cfs ] and [ cfj ] respectively .    in both the cumulative encoding / block - by - block forward decoding / compression - message successive decoding and the cumulative encoding / block - by - block forward decoding / compression - message joint decoding schemes ,",
    "the codebook generation and encoding processes are exactly the same as the classical way , i.e. , the way in the proof of theorem 6 of @xcite .",
    "the difference between these two schemes is only on the decoding process at the destination : i ) in successive decoding , the destination first finds , from the specific bins sent by the relays via @xmath69 , the unique combination of @xmath70 sequences that is jointly typical with the @xmath4 sequence received , and then finds the unique @xmath5 sequence that is jointly typical with the @xmath4 sequence received , and also with the previously recovered @xmath70 sequences .",
    "ii ) in joint decoding , the destination finds the unique @xmath5 sequence that is jointly typical with the @xmath4 sequence received , and also with some combination of @xmath70 sequences from the specific bins sent by the relays via @xmath69 .      to make the presentation easier to follow , we introduce a simplified channel model as depicted in fig .",
    "[ fig4 ] , where , the relays are connected to the destination via error - free digital links with capacities @xmath71 , where @xmath72 are chosen based on .",
    "the @xmath18-th digital link plays the same role as the @xmath73 link in fig .",
    "[ fig2 ] , for any @xmath74 .",
    "such a replacement will not lead to any essential variation of the original coding scheme , since under the original coding framework , the @xmath73 link is used as a separate link to forward digital information .",
    "the benefit of directly replacing it by a digital link is that the codebook construction for @xmath75 can be simplified , since no @xmath76 needs to be considered . for this simplified model , and simplify to @xmath77 and @xmath78        the basic idea of the compress - and - forward strategy is for the relay to compress its observations into some approximations , which can be represented by fewer number of bits , and thus , can be forwarded to the destination . to deal with delay at the relay ,",
    "block markov coding was used , where the total time is divided into a sequence of blocks of equal length @xmath79 , and coding is performed block by block .",
    "for example , each relay compresses its observations of each block at the end of the block , and forwards the approximations in the next block .",
    "therefore , to decode the message sent by the source in any block , it is not until the end of the next block , has the destination received the help from the relay .",
    "the encoding process is exactly the same as that in the proof of theorem 6 of @xcite .",
    "we only emphasize that the @xmath18-th relay needs to generate @xmath80 many @xmath75 sequences , and randomly throws them into @xmath81 bins . at the end of each block",
    ", the relay finds a @xmath75 sequence which is jointly typical with the @xmath82 sequence it received during the block , and in the next block , informs the destination the index of the bin that contains the @xmath75 sequence .",
    "the decoding process operates in a successive way . at the end of each block @xmath83",
    ", the destination first finds , from the bins forwarded by the relays during block @xmath84 , the unique combination of @xmath85 sequences that is jointly typical with the @xmath4 sequence received , i.e. , @xmath86    error occurs if the true @xmath87 does not satisfy , or a false @xmath87 satisfies . according to the properties of typical sequences , the true @xmath87 satisfies with high probability .",
    "the probability of a false @xmath87 with some false @xmath88 but true @xmath89 being jointly typical with @xmath90 can be upper bounded by @xmath91 there are @xmath92 false @xmath93 from the bins , thus the probability of finding such a false @xmath87 can be upper bounded by @xmath94 which tends to zero for sufficiently small @xmath95 as @xmath96 , if @xmath97<0.\\end{aligned}\\ ] ] leting @xmath98 , we have @xmath99 plugging this into , we obtain . ''",
    "can be included since does nt include `` @xmath100 '' .",
    "the same consideration applies throughout the paper . ]",
    "given that is satisfied , the destination can recover @xmath87 at the end of block @xmath84 .",
    "then , based on @xmath87 and @xmath90 , @xmath101 can be recovered if holds .",
    "similarly , we consider the simplified model as depicted in fig .",
    "[ fig4 ] , where the rates @xmath72 are chosen based on .",
    "then , simplifies to @xmath102    in cumulative encoding / block - by - block forward decoding / compression - message joint decoding , the encoding part is exactly the same as that in the proof of theorem [ cfs ] , and the decoding process operates as the following . at the end of each block @xmath83",
    ", the destination finds the unique @xmath5 sequence that is jointly typical with the @xmath4 sequence received during block @xmath103 , and also with some @xmath85 sequences from the bins forwarded by the relays during block @xmath84 , i.e. , @xmath104    error occurs if the true @xmath101 does not satisfy , or a false @xmath105 satisfies . according to the properties of typical sequences , the true @xmath101 satisfies with high probability .",
    "the probability of a false @xmath105 being jointly typical with @xmath90 and some false @xmath88 but true @xmath89 can be upper bounded by @xmath106 there are @xmath107 false @xmath108 , and @xmath92 false @xmath93 from the bins , thus the probability of finding such a false @xmath105 can be upper bounded by @xmath109 which tends to zero for sufficiently small @xmath95 as @xmath96 , if holds .      to make the proof of theorem [ optcf ] easier to follow",
    ", we still consider the simplified model depicted in fig .",
    "then , @xmath36 and @xmath37 can be respectively written as @xmath110 and @xmath111    before proceeding to the proof of theorem [ optcf ] , we first introduce some useful notations and lemmas .",
    "let @xmath112 then , we have the following lemmas , whose proofs are given in appendix [ a : a ] .",
    "[ l : union ] 1 ) if @xmath113 , @xmath114 , and @xmath115 , @xmath116 , then @xmath117 , @xmath118    \\2 ) if @xmath113 , @xmath114 , and @xmath119 , @xmath116 , then @xmath117 , @xmath118    [ l : largestd ] under any @xmath120 , there exists a unique set @xmath121 , which is the largest subset of @xmath53 satisfying @xmath122    [ l : exsit ] if @xmath123 for some nonempty @xmath124 , then there exists some nonempty @xmath125 such that @xmath126 .",
    "[ l : aub ] for any @xmath127 and @xmath124 with @xmath128 , @xmath129    we are now ready to prove theorem [ optcf ] .",
    "we show @xmath130 by showing that @xmath131 and @xmath132 respectively . under any @xmath120 such that @xmath133 , @xmath134 , we have @xmath135 and thus @xmath131 .    to show @xmath132 , it is sufficient to show that @xmath37 can be achieved only with @xmath120 such that @xmath136 , @xmath134 .",
    "we will show this by two steps as follows : i ) we first show that under any @xmath120 , if @xmath137 , then @xmath138 and @xmath139 , where @xmath121 is defined as in lemma [ l : largestd ] and @xmath140 .",
    "ii ) we then argue that , under the optimal @xmath120 , @xmath141 must be @xmath142 , i.e. , @xmath121 must be @xmath53 , and thus by the definition of @xmath121 , @xmath143 .",
    "\\i ) assuming @xmath137 throughout part i ) , we show @xmath138 and @xmath139 .",
    "\\1 ) we first show @xmath144 by using a contradiction argument .",
    "suppose @xmath145 , i.e. , @xmath146 .",
    "then , by lemma [ l : exsit ] , we have that there exists some nonempty @xmath147 such that @xmath148 , @xmath149 .",
    "this will further imply , by part 2 ) of lemma [ l : union ] , that @xmath150 .",
    "this is contradictory with the definition of @xmath121 , and thus @xmath144 .",
    "\\2 ) we show that @xmath151 and @xmath152 , @xmath153 , and thus @xmath154 .",
    "the proof is still by contradiction .",
    "suppose that there exists some @xmath155 and @xmath152 such that @xmath156 .",
    "then @xmath157 , i.e. , @xmath158 again by lemma [ l : exsit ] and [",
    "l : union ] successively , we can conclude that there exists some nonempty @xmath159 , such that @xmath150 , which is in contradiction .",
    "therefore , @xmath160 .",
    "\\3 ) we prove that @xmath161 with @xmath162 and @xmath163 , @xmath154 .",
    "let @xmath164 and @xmath165 .",
    "then , we have , by lemma [ l : aub ] , that @xmath166 since @xmath167 by 2 ) and @xmath168 we have @xmath169 .",
    "\\4 ) we prove that @xmath161 with @xmath162 and @xmath170 , @xmath171 .",
    "letting @xmath164 , we have @xmath172    combining 2)-4 ) , we can conclude that @xmath138 and @xmath139 .",
    "\\ii ) we now argue that under the optimal @xmath120 that achieves @xmath173 , if @xmath137 , then @xmath173 is not optimal ; and hence @xmath141 must be @xmath142 . the argument is extended from that in @xcite and the detailed analysis is as follows .",
    "suppose @xmath137 at the optimum .",
    "then , @xmath138 and @xmath139 . therefore , @xmath174 and similarly , @xmath175 for any @xmath176 , @xmath177 .",
    "we argue that higher rate can be achieved .",
    "consider @xmath178 , where @xmath179 for any @xmath180 , and @xmath179 with probability @xmath181 and @xmath182 with probability @xmath183 for any @xmath184 .",
    "when @xmath185 , the achievable rate with @xmath178 is @xmath173 . as @xmath181 decreases from 1 , it can be seen from and that both @xmath186 and @xmath187 will increase , where @xmath176 , @xmath177 .",
    "thus , no matter how @xmath188 will change as @xmath181 decreases for @xmath189 , it is certain that there exists a @xmath190 such that the achievable rate by using @xmath178 is larger than @xmath173 .",
    "this is in contradiction with the optimality of @xmath173 , and thus at the optimum , @xmath141 must be @xmath142 , i.e. , @xmath136 , @xmath134 .",
    "this completes the proof of theorem [ optcf ] .",
    "in this section , our discussion transfers to the compress - and - forward schemes with decoding after all blocks have been finished .",
    "the focus here is on the cumulative encoding / block - by - block backward decoding , since it is the simplest scheme to achieve the highest rate in the general multiple - relay channel , as mentioned before ; for the repetitive encoding / all blocks united decoding , see the proof of theorem 1 in @xcite .",
    "cumulative encoding / block - by - block backward decoding can be combined with either compression - message successive decoding or compression - message joint decoding . in the following",
    ", we will first present the cumulative encoding / block - by - block backward decoding / compression - message successive decoding scheme to establish the achievable rate in theorem [ t : cbs ] , and demonstrate the optimality of successive decoding in the sense of theorem [ t : optallblocks ] .",
    "then , the cumulative encoding / block - by - block backward decoding / compression - message joint decoding scheme will be used to prove theorem [ t : cbj ] , and the necessity of joint decodablity is demonstrated in the sense that only those relay nodes , whose compressions can be eventually decoded by joint decoding , are helpful to the decoding of the original message .      in cumulative encoding",
    "/ block - by - block backward decoding , the encoding process is similar to that in the proof of theorem 6 in @xcite ( except that the binning at the relay is not needed here ) , but the decoding process operates backwardly .",
    "this scheme , combined with compression - message successive decoding , proves theorem [ t : cbs ] as follows .",
    "_ codebook generation : _ fix @xmath64 .",
    "consider @xmath191 blocks , where the source will transmit information in the first @xmath192 blocks and keep silent in the last @xmath193 blocks , and @xmath194 such that the rate loss can be made arbitrarily small .",
    "we randomly and independently generate a codebook for each block .",
    "for each block @xmath195 $ ] , randomly and independently generate @xmath196 sequences @xmath197 , @xmath198 $ ] ; for each block @xmath195 $ ] and each relay node @xmath199 , randomly and independently generate @xmath200 sequences @xmath201 , @xmath202 $ ] , where @xmath203 ; for each relay node @xmath199 and each @xmath201 , @xmath202 $ ] , randomly and conditionally independently generate @xmath200 sequences @xmath204 , @xmath205 $ ] .",
    "this defines the codebook for any block @xmath195 $ ] , @xmath206 , l_{i , b},l_{i , b-1 } \\in   [ 1:2^{t\\hat r_i } ] , i\\in \\nn           \\}.\\ ] ]    _ encoding : _ let @xmath207 be the message vector to be sent and let @xmath208 be the dummy message for any @xmath209 $ ] . for any block @xmath195 $ ] , each relay node @xmath199 , upon receiving @xmath210 at the end of block @xmath84 , finds an index @xmath211 such that @xmath212 , where @xmath213 by convention .",
    "the codewords @xmath214 and @xmath215 are transmitted in block @xmath84 , @xmath195 $ ] .    _",
    "decoding : _ i ) the destination first finds a unique combination of the relays compression indices @xmath216 and some @xmath217 , where @xmath218 , @xmath219 $ ] , such that for any @xmath220 , @xmath221    specifically , this can be done backwards as follows :    \\a ) the destination finds the unique @xmath222 such that there exists some @xmath217 satisfying ( [ e : check1 ] ) for any @xmath223 .",
    "assume the true @xmath224 .",
    "then , error occurs if @xmath225 does not satisfy with any @xmath226 for any @xmath223 , or a false @xmath227 satisfies with some @xmath226 for any @xmath223 . since @xmath224 satisfies for any @xmath223 with high probability according to the properties of typical sequences , we only need to bound @xmath228 , where @xmath229 is defined as the event that @xmath222 satisfies with some @xmath226 for any @xmath223 . for any @xmath230 ,",
    "define @xmath231 as the event that @xmath230 satisfies .",
    "then , we have @xmath232 \\end{array } } \\bigcup_{\\mathbf{l}_b \\neq \\mathbf{1}}\\bigcap_{b = b+1}^{b+m } \\mathcal{a}_{b}(\\mathbf{l}_{b-1},\\mathbf{l}_b))\\nonumber \\\\ \\leq & \\sum_{j=1}^{m-1 } \\mbox{pr}(\\bigcup_{\\mathbf{l}_{b+1}^{b+m } : \\mathbf{l}_{b+j}=\\mathbf{1 } } \\bigcup_{\\mathbf{l}_b \\neq \\mathbf{1 } } \\bigcap_{b = b+1}^{b+m } \\mathcal{a}_{b}(\\mathbf{l}_{b-1},\\mathbf{l}_b ) ) + \\mbox{pr}(\\bigcup _ { \\scriptsize \\begin{array}{c } \\mathbf{l}_{b+1}^{b+m } : \\mathbf{l}_{b+j}\\neq \\mathbf{1 } , \\\\",
    "\\forall j\\in[1:m-1 ] \\end{array } } \\bigcup_{\\mathbf{l}_b \\neq \\mathbf{1 } } \\bigcap_{b = b+1}^{b+m } \\mathcal{a}_{b}(\\mathbf{l}_{b-1},\\mathbf{l}_b)).\\label{e : following } \\ ] ]    let us first consider the second term in . for any @xmath233 , let @xmath234 .",
    "note @xmath235 only depends on @xmath236 , so we also write it as @xmath237 .",
    "define @xmath238 as @xmath239 , and similarly define @xmath240 and @xmath241 .",
    "then , @xmath242 is independent of @xmath243 , and @xmath244 can be upper bounded by @xmath245 where @xmath246 and @xmath247 as @xmath248 .",
    "then , we have @xmath249 \\end{array } } \\bigcup_{\\mathbf{l}_b \\neq \\mathbf{1 } } \\bigcap_{b = b+1}^{b+m } \\mathcal{a}_{b}(\\mathbf{l}_{b-1},\\mathbf{l}_b))\\\\ \\leq &   \\sum _ { \\scriptsize \\begin{array}{c } \\mathbf{l}_{b+1}^{b+m } : \\mathbf{l}_{b+j}\\neq \\mathbf{1 } , \\\\",
    "\\forall j\\in[1:m-1 ] \\end{array } } \\sum_{\\mathbf{l}_b \\neq \\mathbf{1 } } \\prod_{b = b+1}^{b+m } \\mbox{pr}(\\mathcal{a}_{b}(\\mathbf{l}_{b-1},\\mathbf{l}_b ) )   \\\\ \\leq & \\sum_{\\mathbf{l}_{b+m } } \\sum_{\\scriptsize \\begin{array}{c } \\mathbf{l}_{b+1}^{b+m-1 } : \\mathbf{l}_{b+j}\\neq \\mathbf{1 } , \\\\",
    "\\forall j\\in[1:m-1 ] \\end{array } } \\sum_{\\mathbf{l}_b \\neq \\mathbf{1 } }   \\prod_{b = b+1}^{b+m } 2^{-t ( \\ii(\\ss_{b}(\\mathbf{l}_{b-1 } ) )     -\\epsilon '            ) }   \\\\ \\leq & \\sum_{\\mathbf{l}_{b+m } } \\sum _ { \\scriptsize \\begin{array}{c } \\ss_{b+1},\\ldots,\\ss_{b+m } : \\\\ \\ss_{b+j}\\neq \\emptyset , \\forall j\\in [ 1:m ] \\end{array } } \\sum _ { \\scriptsize \\begin{array}{c } \\mathbf{l}_b^{b+m-1}:\\ss_{b}(\\mathbf{l}_b^{b+m-1})=\\ss_{b } , \\\\   \\forall b\\in [ b+1:b+m ] \\end{array } }   \\prod_{b = b+1}^{b+m } 2^{-t ( \\ii(\\ss_{b}(\\mathbf{l}_{b-1 } ) )     -\\epsilon '            ) }   \\\\ \\leq & \\sum_{\\mathbf{l}_{b+m } } \\sum _ { \\scriptsize \\begin{array}{c } \\ss_{b+1},\\ldots,\\ss_{b+m } : \\\\ \\ss_{b+j}\\neq \\emptyset , \\forall j\\in [ 1:m ] \\end{array } } \\prod_{b = b+1}^{b+m } 2^{t ( \\sum_{i \\in \\ss_{b}}(i(y_i;\\hat y_i|x_i)+\\epsilon ) ) } \\prod_{b = b+1}^{b+m } 2^{-t ( \\ii(\\ss_{b } )     -\\epsilon '            ) }    \\\\ \\leq & \\sum_{\\mathbf{l}_{b+m } } \\sum _ { \\scriptsize \\begin{array}{c } \\ss_{b+1},\\ldots,\\ss_{b+m } : \\\\ \\ss_{b+j}\\neq \\emptyset , \\forall j\\in [ 1:m ] \\end{array } } \\prod_{b = b+1}^{b+m } 2^{-t ( i(x_{\\ss_b } ; \\hat y_{\\ss_b^c},y|x_{\\ss_b^c } ) -   i(y_{\\ss_b};\\hat y_{\\ss_b}|x_\\nn , y , \\hat y_{\\ss_b^c } ) -\\epsilon '' ) }   \\\\ \\leq & \\sum_{\\mathbf{l}_{b+m } } \\sum _ { \\scriptsize \\begin{array}{c } \\ss_{b+1},\\ldots,\\ss_{b+m } :",
    "\\\\ \\ss_{b+j}\\neq \\emptyset , \\forall j\\in [ 1:m ] \\end{array } } 2^{-t\\sum_{b = b+1}^{b+m } ( i(x_{\\ss_b } ; \\hat y_{\\ss_b^c},y|x_{\\ss_b^c } ) -   i(y_{\\ss_b};\\hat y_{\\ss_b}|x_\\nn , y , \\hat y_{\\ss_b^c } ) -\\epsilon '' ) }   \\\\ \\leq & \\sum_{\\mathbf{l}_{b+m } } ( 2^n)^m 2^{-tm(\\min_{\\ss \\subseteq \\nn : \\ss \\neq \\emptyset}\\ { i(x_{\\ss } ; \\hat y_{\\ss^c},y|x_{\\ss^c } ) -   i(y_{\\ss};\\hat y_{\\ss}|x_\\nn , y , \\hat y_{\\ss^c } ) -\\epsilon ''   \\ } ) } \\\\ \\leq & 2^{t(\\sum_{i\\in \\nn}(i(\\hat y_i;y_i|x_i)+\\epsilon ) ) }   2^{nm } 2^{-tm(\\min_{\\ss \\subseteq \\nn : \\ss",
    "\\neq \\emptyset}\\ { i(x_{\\ss } ; \\hat y_{\\ss^c},y|x_{\\ss^c } ) -   i(y_{\\ss};\\hat y_{\\ss}|x_\\nn , y , \\hat y_{\\ss^c } ) -\\epsilon ''   \\})}\\end{aligned}\\ ] ] where @xmath250 as @xmath248 .",
    "thus , as both @xmath79 and @xmath193 go to infinity , the second term in goes to 0 , if holds .",
    "now consider the first term in .",
    "for any @xmath251 $ ] , we have @xmath252 note @xmath253 is the probability that there exists a false @xmath227 satisfies with some @xmath254 for any block @xmath255 $ ] , where @xmath256 is true",
    ". we can show this probability goes to 0 with the idea of backward decoding as follows .    specifically , backwards and sequentially from block @xmath257 to block @xmath258",
    ", the destination finds the unique @xmath236 , such that @xmath259 satisfies , where @xmath260 has already been recovered due to the backwards property of decoding . at each block @xmath261",
    ", error occurs if the true @xmath236 does not satisfy , or a false @xmath236 satisfies . according to the properties of typical sequences , the true @xmath236 satisfies with high probability .    for a false @xmath236 with false @xmath262 but true @xmath263 ,",
    "@xmath264 is independent of @xmath265 , and the probability that @xmath259 satisfies can be upper bounded by @xmath266 since the number of such false @xmath236 is upper bounded by @xmath267 , with the union bound , it is easy to check that the probability of finding such a false @xmath236 goes to zero as @xmath268 , if holds .",
    "therefore , if holds , the first term in also goes to 0 as @xmath268 , and @xmath222 can be decoded .",
    "\\b ) given that @xmath222 has been recovered , the destination performs the backward decoding similar with above .",
    "that is , backwards and sequentially from block @xmath269 to block @xmath270 , the destination finds the unique @xmath236 , such that @xmath259 satisfies , where @xmath260 has already been recovered . from the above analysis , it follows that at each block @xmath271 , the probability of decoding error goes to zero as @xmath268 , if holds .",
    "this combined with a ) implies that @xmath272 can be decoded , if holds .",
    "\\ii ) then , based on the recovered @xmath272 , the destination finds the unique @xmath273 such that for any @xmath274 , @xmath275 obviously , the probability of decoding error will tend to zero if @xmath276 .",
    "we are now in a position to prove theorem [ t : optallblocks ] .",
    "to facilitate the proof , we introduce some notations and lemmas .",
    "let @xmath277 then , we have the following lemmas , whose proofs will be presented in appendix [ a : b ] .",
    "[ l : irrunion ] 1 ) if @xmath278 , @xmath114 , and @xmath279 , @xmath116 , then @xmath280 , @xmath118    \\2 ) if @xmath278 , @xmath114 , and @xmath281 , @xmath116 , then @xmath280 , @xmath118    [ l : irrlargestd ] under any @xmath64 , there exists a unique set @xmath121 , which is the largest subset of @xmath53 satisfying @xmath282    [ l : irrexsit ] if @xmath283 for some nonempty @xmath124 , then there exists some nonempty @xmath125 such that @xmath284 .",
    "[ l : irraub ] for any @xmath127 and @xmath124 with @xmath128 , @xmath285 where @xmath286    the proof of theorem [ t : optallblocks ] is similar to the proof of theorem [ optcf ] , and the details are as follows .",
    "@xmath46 and @xmath45 can be respectively written as @xmath287 and @xmath288    we show @xmath289 by showing that @xmath290 and @xmath291 respectively . under any @xmath64 such that @xmath292 , @xmath134 , we have @xmath293 and thus @xmath290 .    to show @xmath294 , it is sufficient to show that @xmath45 can be achieved only with the distribution @xmath64 such that @xmath292 , @xmath134 .",
    "we will show this by two steps as follows : i ) we first show that under any @xmath64 , if @xmath137 , then @xmath295 and @xmath296 , where @xmath121 is defined as in lemma [ l : irrlargestd ] and @xmath297 .",
    "ii ) we then argue that , under the optimal @xmath64 , @xmath141 must be @xmath142 , i.e. , @xmath121 must be @xmath53 , and thus by the definition of @xmath121 , @xmath298 .",
    "\\i ) assuming @xmath137 throughout part i ) , we show @xmath295 and @xmath296 .",
    "\\1 ) we first show @xmath299 by using a contradiction argument .",
    "suppose @xmath300 , i.e. , @xmath301 . then ,",
    "by lemma [ l : irrexsit ] , we have that there exists some nonempty @xmath147 such that @xmath302 , @xmath149 .",
    "this will further imply , by part 2 ) of lemma [ l : irrunion ] , that @xmath303 .",
    "this is contradictory with the definition of @xmath121 , and thus @xmath299 .",
    "\\2 ) we show that @xmath151 and @xmath152 , @xmath304 , and thus @xmath305 .",
    "the proof is still by contradiction .",
    "suppose that there exists some @xmath155 and @xmath152 such that @xmath306 .",
    "then @xmath307 , i.e. , @xmath308 again by lemma [ l : irrexsit ] and [ l : irrunion ] successively , we can conclude that there exists some nonempty @xmath159 , such that @xmath303 , which is in contradiction",
    ". therefore , @xmath309 .",
    "\\3 ) we prove that @xmath161 with @xmath162 and @xmath163 , @xmath310 .",
    "let @xmath164 and @xmath165 .",
    "then , we have , by lemma [ l : irraub ] , that @xmath311 since @xmath312 by 2 ) , to show @xmath310 , we only need to show @xmath313 .",
    "let @xmath314 .",
    "then , we have @xmath315 thus , we have @xmath316 .",
    "\\4 ) we prove that @xmath161 with @xmath162 and @xmath170 , @xmath317 .",
    "letting @xmath164 , we have @xmath318 thus , to show @xmath317 , we only need to show @xmath319 . for this",
    ", we have @xmath320 and thus @xmath317 .    combining 2)-4 )",
    ", we can conclude that @xmath295 and @xmath296 .",
    "\\ii ) we now argue that under the optimal @xmath64 that achieves @xmath321 , if @xmath137 , then @xmath321 is not optimal ; and hence @xmath141 must be @xmath142 .",
    "suppose @xmath137 at the optimum .",
    "then , @xmath295 and @xmath296 .",
    "therefore , @xmath322 for any @xmath323 , @xmath177 .",
    "we argue that higher rate can be achieved .",
    "consider @xmath178 , where @xmath179 for any @xmath180 , and @xmath179 with probability @xmath181 and @xmath182 with probability @xmath183 for any @xmath184 .",
    "when @xmath185 , the achievable rate with @xmath178 is @xmath321 .",
    "as @xmath181 decreases from 1 , in and , both @xmath324 and @xmath325 will increase , where @xmath323 , @xmath177 .",
    "thus , no matter how @xmath326 will change as @xmath181 decreases for @xmath327 , it is certain that there exists a @xmath190 such that the achievable rate by using @xmath178 is larger than @xmath321 .",
    "this is in contradiction with the optimality of @xmath321 , and thus at the optimum , @xmath141 must be @xmath142 , i.e. , @xmath292 , @xmath134 .",
    "this completes the proof of theorem [ t : optallblocks ] .",
    "some notations and lemmas are introduced to facilitate the later discussion .",
    "let @xmath328    [ union ] 1 ) if @xmath329 , for any nonempty @xmath330 , and @xmath331 , for any nonempty @xmath332 , then @xmath333 , for any nonempty @xmath334    \\2 ) if @xmath329 , for any nonempty @xmath330 , and @xmath335 , for any nonempty @xmath332 , then @xmath333 , for any nonempty @xmath334    [ l : largest ] under any @xmath64 , there exists a unique set @xmath52 , which is the largest subset of @xmath53 satisfying @xmath336    [ exsit ] if @xmath337 for some nonempty @xmath124 , then there exists some nonempty @xmath125 such that @xmath338 , for any nonempty @xmath339    [ l : runion ] for any disjoint @xmath127 and @xmath340 , and any @xmath341 , let @xmath342 and @xmath343 .",
    "then , we have :    \\1 ) @xmath344 .",
    "\\2 ) specially , when @xmath345 , @xmath346    lemmas [ union]-[exsit ] can be proved along the same lines as the proofs of lemmas [ l : irrunion]-[l : irrexsit ] respectively , while the proof of lemma [ l : runion ] is given in appendix [ a : c ] .",
    "the cumulative encoding / block - by - block backward decoding / compression - message joint decoding scheme is presented in the following proof .    the uniqueness of @xmath52 has been established in lemma [ l : largest ] .",
    "below , we focus on showing that i ) the rate in is achievable , and ii ) the compressions in the set @xmath52 can be decoded jointly with @xmath5 . to make the presentation easier to follow",
    ", we first consider the case when @xmath347 , i.e. , the case when @xmath348 and show that @xmath349 is achievable .",
    "the case of @xmath350 will follow immediately after the case of @xmath347 is treated .",
    "fix @xmath64 .",
    "assume holds .",
    "the codebook generation and encoding process here are exactly the same as those in the proof of theorem [ t : cbs ] , and hence omitted .",
    "for the decoding , the destination finds the unique message vector @xmath207 and some @xmath351 such that for any @xmath220 , @xmath352 where @xmath208 is dummy message for all @xmath209 $ ] .",
    "again , this can be done backwardly as follows .",
    "\\a ) the destination first finds the unique @xmath222 such that there exists some @xmath217 satisfying for any @xmath223 . through the similar lines as in the proof of theorem [ t : cbs ] with",
    "@xmath353 $ ] taken into account and treated as known signals , it follows that @xmath222 can be decoded if holds .",
    "\\b ) backwards and sequentially from block @xmath269 to block @xmath354 , the destination finds the unique pair @xmath355 , such that @xmath356 satisfies , where @xmath260 has already been recovered due to the backwards property of decoding .    at each block @xmath357",
    ", error occurs with @xmath358 if the true @xmath358 does not satisfy with any @xmath236 , or a false @xmath358 satisfies with some @xmath236 . according to the properties of typical sequences , the true @xmath355 satisfies with high probability .    for a false @xmath358 and a @xmath236 with false @xmath262 but true @xmath263 , @xmath359 and @xmath264 and @xmath265",
    "are mutually independent , and the probability that @xmath356 satisfies can be upper bounded by @xmath360 since the number of such false @xmath355 is upper bounded by @xmath361 , with the union bound , it is easy to check that the probability of finding a false @xmath358 goes to zero as @xmath268 , if holds .",
    "then , based on the recovered @xmath358 and @xmath260 , again from the proof of theorem [ t : cbs ] with @xmath362 taken into account and treated as known signal , it follows that @xmath236 can be decoded if holds .    combining a ) and",
    "b ) , we can conclude that both @xmath273 and @xmath272 can be decoded if both and hold .",
    "if under @xmath64 , @xmath350 , then through the same line as above with @xmath53 replaced by @xmath52 , it readily follows that @xmath363 is achievable ; and @xmath56 , or more strictly , @xmath364 , can be decoded jointly with @xmath5 since @xmath365 for any nonempty @xmath55 .",
    "now , we demonstrate that only those relay nodes , whose compressions can be eventually decoded , are helpful to the decoding of the original message .",
    "[ proof of theorem [ t : equi ] ] the uniqueness of @xmath52 has been treated in lemma [ l : largest ] , while the uniqueness of @xmath68 can be established along the same lines . to prove theorem [ t : equi ] , in terms of the notations defined in this section",
    ", we will sequentially prove that : i ) @xmath366 ; ii ) @xmath367 , for any @xmath67 ; iii ) @xmath368 .",
    "\\i ) we prove @xmath366 by proving that : 1 ) for any @xmath369 , @xmath370 , @xmath371 .",
    "2 ) for any @xmath372 , @xmath373 , and thus @xmath374 by 1 ) .",
    "the details are as follows .",
    "\\1 ) assume @xmath369 , @xmath370 .",
    "we show @xmath371 by showing that for any @xmath55 , @xmath375 .    for any @xmath55 , by part 2 ) of lemma [ l : runion ] , we have @xmath376 we argue @xmath377 by contradiction .",
    "suppose @xmath378 .",
    "then , by lemma [ exsit ] , we have that there exists some nonempty @xmath379 such that @xmath380 , for any nonempty @xmath339 this will further imply , by part 2 ) of lemma [ union ] , that @xmath381 , for any nonempty @xmath382 which is in contradiction with the definition of @xmath52 .",
    "thus , we must have @xmath377 , and @xmath375 .",
    "\\2 ) assume @xmath372 . for any @xmath383 ,",
    "let @xmath384 and @xmath385 .",
    "by part 1 ) of lemma [ l : runion ] , we have @xmath386 and then , @xmath387 where the last inequality follows from the fact that @xmath388 , for any nonempty @xmath389 .",
    "\\ii ) we can prove @xmath390 , for any @xmath67 by two similar steps as follows .",
    "\\1 ) through the similar lines as in step 1 ) of part i ) , we can prove @xmath367 , for any @xmath391 , @xmath392 .",
    "the only difference is that here the inequality is strict , but it can be easily justified by noting that `` @xmath100 '' is included in the definition of @xmath68 .",
    "\\2 ) from step 2 ) of part i ) , it can be similarly proved that for any @xmath393 , @xmath394 .",
    "therefore , if , further , @xmath67 , then by 1 ) we have @xmath395    \\iii ) from part ii ) , we have 1 ) @xmath367 , for any @xmath391 , @xmath392 , and 2 ) for any @xmath393 , @xmath396 . thus , it follows immediately that @xmath397 .",
    "this completes the proof of theorem [ t : equi ] .",
    "joint compression - message decoding introduced more freedom in selecting the compressions at the relays .",
    "motivated by it , we have investigated the problem of finding the optimal compressions in maximizing the achievable rate of the original message .",
    "we have studied several different compress - and - forward relay schemes , and the unanimous conclusion is that the optimal compressions should always support successive compression - message decoding . in situations where compressions not supporting successive decoding have to be used , we have found that only those that can be jointly decoded are helpful to the decoding of the original message .",
    "we have also developed a backward block - by - block decoding scheme . compared to the repetitive encoding / all blocks united decoding scheme recently proposed in @xcite , which improved the achievable rate in the multiple - relay case ,",
    "we have realized that the key to the improvement comes from delaying the decoding until all the blocks have been finished .",
    "in retrospect , the multiple - relay case is different from the single - relay case in that it may take multiple blocks for the relays to help each other before their compressions can finally reach the destination .",
    "hence , the block - by - block forward decoding scheme , which is sufficient for the single - relay case , may not work satisfactorily for multiple relays in general .    finally , we need to point out that our discussion of optimality is restricted to the few selected compress - and - forward relay schemes",
    ". in generalizing the classical compress - and - forward relay scheme in @xcite to the case of multiple relays , there could be many other choices of coding considerations @xcite .",
    "even for the single - relay case , the optimality of the original compression method used in @xcite remains an open question ( @xcite ) .",
    "for any @xmath398 , let @xmath342 and @xmath399 . then , @xmath400    if @xmath113 , @xmath114 , and @xmath115 , @xmath116 , then following , @xmath117 , @xmath118 if @xmath113 , @xmath114 , and @xmath119 , @xmath116 , then following , @xmath117 , @xmath118    let @xmath401 and @xmath402 .",
    "suppose there are more than one element in @xmath403 , say , @xmath404 , where @xmath405 .",
    "then based on 1 ) of lemma [ l : union ] , @xmath406 also satisfies that @xmath407 , which is in contradiction , and hence lemma [ l : largestd ] is proved .    if @xmath408 , @xmath149 , then this lemma obviously holds",
    ". otherwise , if there exists some @xmath409 , @xmath410 , such that @xmath411 , then we have @xmath412 , i.e. , @xmath413 now , we arrive at the same situation as in the original assumption with @xmath340 replaced by @xmath414 .",
    "continue applying this argument , and we must be able to reach a nonempty @xmath415 , such that @xmath416 , @xmath417 .    for any disjoint @xmath127 and @xmath340 ,",
    "@xmath418 which proves the lemma .      for any @xmath398 , let @xmath342 and @xmath399",
    ". then , @xmath419\\nonumber \\\\ & -i(y_{\\ss_2 } ; \\hat y_{\\ss_2}|x_{\\mathcal{a}\\cup \\mathcal{b } } , \\hat y_{\\ss_1},\\hat y_{(\\mathcal{a}\\cup \\mathcal{b } ) \\setminus \\ss},y )     \\nonumber \\\\ = & [ i(x_{\\ss_1 } ; \\hat y_{(\\mathcal{a}\\cup \\mathcal{b } ) \\setminus \\ss},y|x_{(\\mathcal{a}\\cup \\mathcal{b } ) \\setminus \\ss})- i(y_{\\ss_1 } ; \\hat y_{\\ss_1}|x_{\\mathcal{a } } , \\hat y_{\\mathcal{a}\\setminus \\ss_1},y)]\\nonumber \\\\ & + [ i(x_{\\ss_2 } ; \\hat y_{(\\mathcal{a}\\cup \\mathcal{b } ) \\setminus \\ss},y|x_{\\ss_1},x_{(\\mathcal{a}\\cup \\mathcal{b } ) \\setminus \\ss})+i(\\hat y_{\\ss_1};x_{\\mathcal{b}\\setminus \\mathcal{a}},\\hat y_{\\mathcal{b}\\mathcal{a}^c\\setminus \\ss_2}|x_{\\mathcal{a}},\\hat y_{\\mathcal{a}\\setminus \\ss_1},y)]\\nonumber \\\\ & -i(y_{\\ss_2 } ; \\hat y_{\\ss_2}|x_{\\mathcal{a } } ,",
    "x_{\\mathcal{b}},\\hat y_{\\mathcal{a}},\\hat y_{\\mathcal{b } \\setminus \\ss_2},y )     \\nonumber \\\\ \\geq&[i(x_{\\ss_1 } ; \\hat y_{\\mathcal{a } \\setminus \\ss_1},y|x_{\\mathcal{a } \\setminus \\ss_1})- i(y_{\\ss_1 } ; \\hat y_{\\ss_1}|x_{\\mathcal{a } } , \\hat y_{\\mathcal{a}\\setminus \\ss_1},y)]\\nonumber \\\\ & + [ i(x_{\\ss_2 } ; \\hat y_{(\\mathcal{a}\\cup \\mathcal{b } ) \\setminus \\ss},y|x_{\\ss_1},x_{(\\mathcal{a}\\cup \\mathcal{b } ) \\setminus \\ss})+i(\\hat y_{\\ss_1};x_{\\mathcal{b}\\setminus \\mathcal{a}},\\hat y_{\\mathcal{b}\\mathcal{a}^c\\setminus \\ss_2}|x_{\\mathcal{a}},\\hat y_{\\mathcal{a}\\setminus \\ss_1},y)]\\nonumber \\\\ & -i(y_{\\ss_2 } ; \\hat y_{\\ss_2}|x_{\\mathcal{a } } , x_{\\mathcal{b}},\\hat y_{\\mathcal{a}},\\hat y_{\\mathcal{b } \\setminus \\ss_2},y )     \\nonumber \\\\ = & [ i(x_{\\ss_2 } ; \\hat y_{(\\mathcal{a}\\cup \\mathcal{b } ) \\setminus \\ss},y|x_{\\ss_1},x_{(\\mathcal{a}\\cup \\mathcal{b } ) \\setminus \\ss})+i(\\hat y_{\\ss_1};x_{\\mathcal{s}_2},x_{\\mathcal{b}\\mathcal{a}^c \\setminus \\ss_2 } , \\hat y_{\\mathcal{b}\\mathcal{a}^c\\setminus \\ss_2}|x_{\\mathcal{a}},\\hat y_{\\mathcal{a}\\setminus \\ss_1},y)]\\nonumber \\\\ & -i(y_{\\ss_2 } ; \\hat y_{\\ss_2}|x_{\\mathcal{a } } ,",
    "x_{\\mathcal{b}},\\hat y_{\\mathcal{a}},\\hat y_{\\mathcal{b } \\setminus \\ss_2},y)+j_{\\mathcal{a}}(\\ss_1 )   \\nonumber \\\\ \\geq & [ i(x_{\\ss_2 } ; \\hat y_{(\\mathcal{a}\\cup \\mathcal{b } ) \\setminus \\ss},y|x_{\\mathcal{a}},x_{\\mathcal{b } \\setminus \\ss_2})+i(\\hat y_{\\ss_1};x_{\\mathcal{s}_2}|x_{\\mathcal{a}},x_{\\mathcal{b}\\mathcal{a}^c \\setminus \\ss_2 } , \\hat y_{\\mathcal{b}\\mathcal{a}^c\\setminus \\ss_2},\\hat y_{\\mathcal{a}\\setminus \\ss_1},y)]\\nonumber \\\\ & -i(y_{\\ss_2 } ; \\hat y_{\\ss_2}|x_{\\mathcal{a } } , x_{\\mathcal{b}},\\hat y_{\\mathcal{a}},\\hat y_{\\mathcal{b } \\setminus \\ss_2},y)+j_{\\mathcal{a}}(\\ss_1 )   \\nonumber \\\\ = & i(x_{\\ss_2 } ; \\hat y_{\\mathcal{a}},\\hat",
    "y_{\\mathcal{b } \\setminus \\ss_2},y|x_{\\mathcal{a}},x_{\\mathcal{b } \\setminus \\ss_2 } ) -i(y_{\\ss_2 } ; \\hat y_{\\ss_2}|x_{\\mathcal{a } } ,",
    "x_{\\mathcal{b}},\\hat y_{\\mathcal{a}},\\hat y_{\\mathcal{b } \\setminus \\ss_2},y)+j_{\\mathcal{a}}(\\ss_1 )   \\nonumber \\\\ = & j_{\\mathcal{a}}(\\ss_1)+j_{\\mathcal{a},\\mathcal{b}}(\\ss_2)\\label{e : irrfol1}\\\\ \\geq & j_{\\mathcal{a}}(\\ss_1)+j_{\\mathcal{b}}(\\ss_2 ) .",
    "\\label{e : irrfol2}\\end{aligned}\\ ] ]    if @xmath278 , @xmath114 , and @xmath279 , @xmath116 , then following , @xmath280 , @xmath118 if @xmath278 , @xmath114 , and @xmath281 , @xmath116 , then following , @xmath280 , @xmath118    let @xmath420 and @xmath402 .",
    "suppose there are more than one elements in @xmath403 , say , @xmath404 , where @xmath405 .",
    "then based on 1 ) of lemma [ l : irrunion ] , @xmath406 also satisfies that @xmath421 , which is in contradiction , and hence lemma [ l : irrlargestd ] is proved .    if @xmath422 , @xmath149 , then this lemma obviously holds",
    "otherwise , if there exists some @xmath409 , @xmath410 , such that @xmath423 , then we have @xmath424 , i.e. , @xmath425 now , we arrive at the same situation as in the original assumption with @xmath340 replaced by @xmath414 . continue applying this argument , and we must be able to reach a nonempty @xmath415 , such that @xmath426 , @xmath417 .    for any disjoint @xmath127 and @xmath340 ,",
    "@xmath427 which proves the lemma .",
    "for any disjoint @xmath127 and @xmath340 , and any @xmath341 , let @xmath342 and @xmath343 .",
    "then , we have @xmath428\\nonumber   \\\\ = & i(x , x_{\\ss_1 } ; \\hat y_{\\mathcal{a } \\setminus \\ss_1},y|x_{\\mathcal{a } \\setminus \\ss_1 } ) + i(x , x_{\\ss_1};x_{\\mathcal{b } \\setminus \\ss_2 } , \\hat y_{\\mathcal{b } \\setminus \\ss_2}|x_{\\mathcal{a } \\setminus \\ss_1},\\hat y_{\\mathcal{a } \\setminus \\ss_1},y )   \\nonumber   \\\\ & -[i(y_{\\mathcal{s}_1 } ; \\hat y_{\\mathcal{s}_1}|x , x_{\\mathcal{a } } , \\hat y_{\\mathcal{a } \\setminus \\ss_1},y ) -i(x_\\bb,\\hat y_{\\mathcal{b } \\setminus \\ss_2 } ; \\hat y_{\\mathcal{s}_1}|x , x_{\\mathcal{a } } ,   \\hat y_{\\mathcal{a } \\setminus \\ss_1},y)]\\nonumber   \\\\ & + i(x_{\\ss_2 } ; \\hat y_{\\mathcal{a } \\setminus \\ss_1},\\hat y_{\\mathcal{b } \\setminus \\ss_2},y|x , x_{\\mathcal{a } } , x_{\\mathcal{b } \\setminus \\ss_2 } ) -i(y _ { \\ss_2 } ; \\hat y _ { \\ss_2}|x , x_{\\mathcal{a } } , x_\\bb , \\hat y_{\\mathcal{a}},\\hat y_{\\mathcal{b } \\setminus \\ss_2},y)\\nonumber   \\\\ = & [ i(x , x_{\\ss_1 } ; \\hat y_{\\mathcal{a } \\setminus \\ss_1},y|x_{\\mathcal{a } \\setminus \\ss_1})-i(y_{\\mathcal{s}_1 } ; \\hat y_{\\mathcal{s}_1}|x , x_{\\mathcal{a } } , \\hat y_{\\mathcal{a } \\setminus \\ss_1},y ) ] \\nonumber   \\\\ & + i(x , x_{\\ss_1};x_{\\mathcal{b } \\setminus \\ss_2 } , \\hat y_{\\mathcal{b } \\setminus \\ss_2}|x_{\\mathcal{a } \\setminus",
    "\\ss_1},\\hat y_{\\mathcal{a } \\setminus \\ss_1},y ) + i(x_\\bb,\\hat y_{\\mathcal{b } \\setminus \\ss_2 } ; \\hat y_{\\mathcal{s}_1}|x , x_{\\mathcal{a } } ,   \\hat y_{\\mathcal{a } \\setminus \\ss_1},y)\\nonumber   \\\\ & + i(x_{\\ss_2 } ; \\hat y_{\\mathcal{a } \\setminus \\ss_1},\\hat y_{\\mathcal{b } \\setminus \\ss_2},y|x , x_{\\mathcal{a } } , x_{\\mathcal{b } \\setminus \\ss_2 } ) -i(y _ { \\ss_2 } ; \\hat y _ { \\ss_2}|x , x_{\\mathcal{a } } , x_\\bb , \\hat y_{\\mathcal{a}},\\hat y_{\\mathcal{b } \\setminus \\ss_2},y)\\nonumber \\\\ = & r_{\\mathcal{a}}(\\ss_1 ) + i(x , x_{\\ss_1};x_{\\mathcal{b } \\setminus \\ss_2 } , \\hat y_{\\mathcal{b } \\setminus \\ss_2}|x_{\\mathcal{a } \\setminus \\ss_1},\\hat",
    "y_{\\mathcal{a } \\setminus \\ss_1},y ) + i(x_\\bb,\\hat y_{\\mathcal{b } \\setminus \\ss_2 } ; \\hat y_{\\mathcal{s}_1}|x , x_{\\mathcal{a } } ,   \\hat y_{\\mathcal{a } \\setminus \\ss_1},y)\\nonumber   \\\\ & + i(x_{\\ss_2 } ; \\hat y_{\\mathcal{a } \\setminus \\ss_1},\\hat y_{\\mathcal{b } \\setminus \\ss_2},y|x , x_{\\mathcal{a } } , x_{\\mathcal{b } \\setminus \\ss_2 } ) -i(y _ { \\ss_2 } ; \\hat y _ { \\ss_2}|x , x_{\\mathcal{a } } , x_\\bb , \\hat y_{\\mathcal{a}},\\hat y_{\\mathcal{b } \\setminus \\ss_2},y)\\label{e : lemmafollow}.\\end{aligned}\\ ] ]                        x. wu and l .- l",
    ". xie , `` on the optimality of successive decoding in compress - and - forward relay schemes , '' in _ proc .",
    "48th annual allerton conference on communication , control , and computing _ , monticello ,",
    "illinois , september 29-october 1 , 2010 .",
    "x. wu and l .- l .",
    "xie , `` asymptotic equipartition property of output when rate is above capacity , '' submitted to _",
    "ieee trans .",
    "inform . theory _",
    ", august 2009 , available online at http://arxiv.org/abs/0908.4445 ."
  ],
  "abstract_text": [
    "<S> in the classical compress - and - forward relay scheme developed by ( cover and el gamal , 1979 ) , the decoding process operates in a successive way : the destination first decodes the compression of the relay s observation , and then decodes the original message of the source . recently , </S>",
    "<S> several modified compress - and - forward relay schemes were proposed , where , the destination jointly decodes the compression and the message , instead of successively . </S>",
    "<S> such a modification on the decoding process was motivated by realizing that it is generally easier to decode the compression jointly with the original message , and more importantly , the original message can be decoded even without completely decoding the compression . thus , </S>",
    "<S> joint decoding provides more freedom in choosing the compression at the relay .    </S>",
    "<S> however , the question remains whether this freedom of selecting the compression necessarily improves the achievable rate of the original message . </S>",
    "<S> it has been shown in ( el gamal and kim , 2010 ) that the answer is negative in the single - relay case . in this paper , it is further demonstrated that in the case of multiple relays , there is no improvement on the achievable rate by joint decoding either . </S>",
    "<S> more interestingly , it is discovered that any compressions not supporting successive decoding will actually lead to strictly lower achievable rates for the original message . </S>",
    "<S> therefore , to maximize the achievable rate for the original message , the compressions should always be chosen to support successive decoding . </S>",
    "<S> furthermore , it is shown that any compressions not completely decodable even with joint decoding will not provide any contribution to the decoding of the original message .    </S>",
    "<S> the above phenomenon is also shown to exist under the repetitive encoding framework recently proposed by ( lim , kim , el gamal , and chung , 2010 ) , which improved the achievable rate in the case of multiple relays . here </S>",
    "<S> , another interesting discovery is that the improvement is not a result of repetitive encoding , but the benefit of delayed decoding after all the blocks have been finished . </S>",
    "<S> the same rate is shown to be achievable with the simpler classical encoding process of ( cover and el gamal , 1979 ) with a block - by - block backward decoding process . </S>"
  ]
}