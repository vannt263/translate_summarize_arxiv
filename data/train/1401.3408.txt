{
  "article_text": [
    "suppose @xmath0 is a discrete - time process which becomes available sequentially and define @xmath1 to be the associated filtration with @xmath2 the @xmath3-algebra generated by the observations up to time @xmath4 .",
    "let @xmath5 denote a _ changetime _ and assume that the observations follow the probability measure @xmath6 up to and including @xmath7 , while after @xmath7 the probability measure switches to @xmath8 .",
    "if the change in statistics takes place at @xmath9 then this induces a probability measure which we denote with @xmath10 while @xmath11 $ ] is reserved for the corresponding expectation .",
    "we would like to stress that , here , @xmath7 denotes the _ last _ time instant under the nominal regime and _ not _ the first under the alternative which is the usual practice .",
    "this slight difference allows to view @xmath7 as a _ stopping time _ ( the time the observations _ stop _ following the nominal statistics ) , property which can be analytically very convenient ( see moustakides @xcite ) .",
    "we are interested in detecting the occurrence of the changetime @xmath7 with the help of a stopping time @xmath12 adapted to the filtration @xmath13 that will signal the change as soon as possible avoiding , at the same time , making frequent false alarms .",
    "the effectiveness of a detection scheme is commonly quantified through the average detection delay .",
    "there are , of course , various possibilities depending on the prior knowledge we have and the model we adopt for the changetime .",
    "in particular , assuming @xmath7 to be random , independent from the observations , with a known prior , shiryaev @xcite proposed the following measure @xmath14 .",
    "\\label{eq : shiryaev}\\ ] ] if we consider @xmath9 to be deterministic and unknown we can then follow a worst - case analysis and consider the performance measure proposed by lorden @xcite @xmath15 .",
    "\\label{eq : lorden}\\ ] ] finally , assuming again that @xmath9 is deterministic and unknown we can alternatively define @xmath16 , \\label{eq : pollak}\\ ] ] which is the criterion introduced by pollak @xcite .",
    "the three measures depicted in , , are the most common criteria encountered in the literature and , as noted in @xcite , they can be recovered from a general definition that treats @xmath7 as a stopping time .",
    "an optimum stopping rule @xmath12 is then specified by minimizing these performance measures subject to suitable false alarm constraints .",
    "we observe from , , that no hard limit is imposed on the detection delay .",
    "consequently , this quantity can become arbitrarily large .",
    "as reported in gupi et al .",
    "@xcite and in references therein there are several applications in practice where unbounded delays can be undesirable and one would rather detect the change within a pre - specified time window , _ after _ the change has occurred corresponds to false alarm . ] . in other words we like to have @xmath17 , for given @xmath18 .",
    "stopping within the prescribed interval constitutes a desirable event while if @xmath19 this is _ not _ considered as successful detection .",
    "similarly to , , , we can now propose the following alternatives of the three classical performance measures @xmath20 as we can see , instead of focusing on the average detection delay , we now pay attention to the detection probability .",
    "consequently , here , we need to replace the minimization of the worst - case average detection delay of the classical approach with the _ maximization of the worst - case detection probability_.    bojdecki @xcite was the first to adopt this probability maximizing idea by considering the maximization of the probability @xmath21 .",
    "the complete solution to this problem was offered for the case @xmath22 and for the bayesian formulation with the changetime @xmath7 following a geometric prior .",
    "the optimum stopping time turned out to be the simple test introduced by shewhart in @xcite and which will also become our main focus in the analysis that follows .",
    "we should mention that @xmath22 corresponds to the maximization of the probability of the event @xmath23 , namely that detection is achieved by using just _",
    "the first observation under the alternative regime_. a point we need to make is that bojdecki , in his approach , did not attempt to control false alarms in any sense . following similar ideas , sarnowski and szajowski @xcite extended this result to the dependent observations case ; while very recently pollak and krieker @xcite considered the i.i.d .",
    "case but with the data after the change distributed according to a parametric family of pdfs and the parameters following a known prior . pollak and krieker @xcite also adopted a semi - bayesian approach where the changetime @xmath7 is deterministic and unknown while the post - change density , as before , is a parametric family with the parameters distributed according to a known prior . in the current work , unlike @xcite and @xcite , we follow the common practice of the classical formulation and , as in the semi - bayesian approach of @xcite , we impose suitable constraints for false alarm control .    before continuing with the detailed presentation of the various formulations , we first recall the form of the shewhart test @xcite that we are going to adopt for our analysis .",
    "consider observations @xmath24 that are independent but not necessarily identically distributed before and after the change and denote with @xmath25 the corresponding sequence of likelihood ratios .",
    "we are then interested in the following form of the shewhart test to avoid unnecessary technical complications , throughout our work , we are going to assume that the cdfs of all likelihood ratios @xmath26 , under both probability measures , are continuous and strictly increasing functions . ] @xmath27 the threshold sequence @xmath28 is deterministic and its exact form depends on the criterion we adopt and the statistics of the observations .",
    "having defined the shewhart stopping time of interest , we briefly recall an optimality result for this test which has already been established in moustakides @xcite . in particular , in the next subsection",
    "we discuss the fact that the shewhart test _ matches _ cusum as long as the average false alarm period does not exceed a specific value .      in the case of i.i.d .",
    "observations before and after the change with corresponding pdfs @xmath29 and @xmath30 , in @xcite it was proved that cusum solves the following constrained optimization problem proposed by lorden @xcite @xmath31;~~\\text{over all}~t:~{{\\sf e}}_\\infty[t]\\geq\\gamma\\geq1 .",
    "\\label{eq : lorden_opt}\\end{gathered}\\ ] ] the cusum stopping time @xmath32 is defined in @xcite as follows : for @xmath33 let @xmath34 where @xmath35 is the cusum statistic , while the constant threshold @xmath36 is selected so that the false alarm constraint is satisfied with equality .",
    "it is interesting to note that , customary , the cusum statistic @xmath37 is specified in the literature slightly differently , namely , @xmath38 . when @xmath39 , the two statistics give rise to exactly the same stopping time @xmath32 .",
    "however , when @xmath40 , by adopting the classical definition we are forced to stop at @xmath41 , while results in a nontrivial stopping time .",
    "it is in fact for these values of the threshold , that is , @xmath42 $ ] that cusum is reduced to the shewhart test .",
    "indeed note from that , as long as we do not stop at @xmath43 , we have @xmath44 .",
    "consequently when @xmath45 this immediately implies that @xmath46 suggesting that cusum is reduced to the shewhart rule with constant threshold @xmath47 .",
    "let us identify the range of false alarm rates for which cusum is equivalent to the shewhart test .",
    "since under each probability measure the sequence @xmath25 is i.i.d",
    ".  we can conclude @xmath48=\\sum_{t=0}^\\infty{{\\sf p}}_i({\\mathcal{s}}>t)=\\sum_{t=0}^\\infty{{\\sf p}}_i(\\ell_{1}<\\nu;\\ell_{2}<\\nu;\\cdots;\\ell_{t}<\\nu)\\\\ = \\sum_{t=0}^\\infty\\big({{\\sf p}}_i(\\ell_1<\\nu)\\big)^t=\\frac{1}{{{\\sf p}}_i(\\ell_1\\ge\\nu)},~~i=0,\\infty .",
    "\\label{eq : average}\\end{gathered}\\ ] ] from the previous equality we deduce that the largest value of the false alarm rate @xmath49 , for which @xmath50 , is achieved when @xmath51 .",
    "this implies that for @xmath52 $ ] we can find a threshold @xmath42 $ ] such that cusum is reduced to the shewhart rule .",
    "it is also clear that the classical definition of cusum can not accommodate any false alarm rate within the same interval .",
    "the previous range of false alarm rates can become more pronounced if we consider the exponential penalty criterion proposed by poor @xcite , that is , @xmath53,~0<c,~c\\neq1.\\ ] ] it is easy to see that from the previous criterion we can recover by letting @xmath54 . as in we are interested in minimizing @xmath55 over all stopping times that satisfy the same false alarm constraint @xmath56\\geq\\gamma\\geq1 $ ] . the optimum stopping time ( see @xcite ) has the following cusum - like form @xmath57 we can then verify that @xmath58 is reduced to the shewhart test when @xmath59 $ ] . if @xmath60 , the previous interval is clearly larger than the one obtained in the classical @xmath61 case .",
    "the range of false alarm rates just specified can be quite significant if the two pdfs differ drastically , namely when we have `` large changes '' .",
    "let us demonstrate this fact with a simple example .",
    "example 1 : consider the detection of a change in the mean of a gaussian i.i.d .",
    "process of unit variance , from 0 to @xmath62 .",
    "we can then see that when @xmath63 where @xmath64 is the cdf of a standard gaussian , cusum is reduced to shewhart with corresponding maximal average detection delay satisfying @xmath65 if we select @xmath66 such that @xmath67 , resulting in @xmath68 , this allows for average false alarm periods in the interval @xmath69 , when the corresponding detection delay is , at worst , equal to 1.001 ; performance which , undoubtedly , can satisfy any exigent user .",
    "our previous discussion corroborates what is already known in the literature , namely , that the shewhart test behaves extremely well when changes are `` large '' while in the case of `` small '' changes one needs to resort to cusum . actually , it is clear that this optimal behavior of the shewhart test is inherited from the optimality of cusum .    even though the previous result concerning the shewhart test is interesting , it is nevertheless theoretically restricted since it covers only a limited range of false alarm rates . in the next section",
    "we will demonstrate that this simple detection rule is in fact optimum according to a number of intriguing criteria .",
    "we would also like to mention that in section[ssec:4.1 ] we will return to this optimality property of shewhart and extend it to the case of multiple possibilities under the post - change regime .",
    "let us now adopt the alternative performance measures introduced in section[ssec:1.0 ] and analyze the special case @xmath70 . as mentioned , this corresponds to the probability of the event that detection will be achieved with the first observation under the alternative regime .",
    "therefore we consider @xmath71 corresponding to , , respectively , with @xmath72 . in the previous measures we define the value of the conditional probability to be 1 when @xmath73 or @xmath74 ( hence also @xmath23 or @xmath75 respectively ) is the empty set .",
    "additionally , we note that in the case of shiryaev s modified measure , due to the existence of the prior probability , it is possible to distinguish between the events @xmath76 and @xmath77 . in the former case",
    "the soonest we can hope to detect the change is at time 0 .",
    "this is the reason why in our criterion we use @xmath78 instead of @xmath79 . in the other two measures this modification is unnecessary since",
    ", due to lack of prior information , a change before 0 can not be distinguished from a change at 0 .",
    "regarding now the stopping time @xmath12 , we need to properly enrich the @xmath3-algebra @xmath80 so as randomization is permitted at time 0 . in particular , at time 0 , with probability @xmath81 we decide to stop at 0 and take no samples and with probability @xmath82 to employ a standard stopping time that requires sampling .",
    "probability @xmath81 is selected independently from the observations .",
    "this slight modification in the definition of our stopping time is absolutely necessary for shiryaev s formulation while for the lorden and pollak setup it is needed only for technical reasons .",
    "we continue our presentation by examining various optimality problems defined with the help of the previous performance measures in combination with proper false alarm constraints .",
    "we start with shiryaev s bayesian setup .",
    "shiryaev @xcite considered the changetime @xmath7 to be random , independent from the observations , with a zero modified exponential prior of the form is the last time instant under the nominal regime , whereas in the literature @xmath7 is conventionally considered as the first instant under the alternative . ] : @xmath83 and @xmath84 ; where @xmath85 $ ] and @xmath86 $ ] .",
    "combining with the classical constraint on the false alarm probability used in baysian approaches , we propose the following constrained optimization problem @xmath87 where @xmath88 is a prescribed false alarm level .",
    "the next theorem identifies the optimum scheme that solves .",
    "[ th:1 ] the optimum detection rule that solves is defined as follows :    i )  @xmath89 : with probability @xmath90 stop at 0 without taking any samples .",
    "ii )  @xmath91 where @xmath92 : with probability @xmath93-\\frac{1-p}{p}{{\\sf p}}_\\infty(\\ell_1\\geq\\nu^*),\\ ] ] decide between stopping at 0 and using the shewhart stopping time with constant threshold @xmath94 .",
    "iii )  @xmath95 : the optimum is the shewhart stopping time with constant threshold @xmath47 computed from @xmath96 and with randomization probability @xmath97 .",
    "the proof of theorem[th:1 ] is presented in the appendix .",
    "the exponential prior model is theoretically very appealing because it leads to well defined optimal stopping problems .",
    "however one of its key weaknesses is the need to properly specify the parameter pair @xmath98 .",
    "if the two quantities are unknown and can not be defined explicitly , a possible means to overcome this problem is to _ adopt a worst - case analysis _",
    "with respect to these two parameters . we should point out that this idea , detailed in the next subsection , has no equivalent in the existing literature for the classical shiryaev criterion .",
    "consider , as before , @xmath7 to be distributed according to a zero modified exponential with unknown parameters @xmath99 .",
    "let us denote our performance measure as @xmath100 making explicit its dependence on the parameter pair @xmath98 .",
    "adopting a max - min approach , we are interested in the following constrained optimization problem @xmath101\\geq\\gamma\\geq1 , \\label{eq : shiryaev3}\\end{gathered}\\ ] ] as we can see , we have replaced the false alarm probability constraint , used in the previous formulation , with a constraint on the average period between false alarms , commonly encountered in min - max approaches .",
    "the next theorem presents the optimum detection rule .",
    "[ th:2 ] let @xmath47 be the solution of the equation @xmath102 then is solved by randomizing with probability @xmath103 between stopping at 0 and using the shewhart stopping time with constant threshold @xmath47 .",
    "the resulting stopping rule is an equalizer over all parameter pairs @xmath98 ; while the worst - case zero modified exponential prior is the degenerate uniform obtained by selecting @xmath104 and letting @xmath105 .",
    "the proof of theorem[th:2 ] can be found in the appendix .",
    "it is surprising that a worst - case analysis results in an optimum stopping rule that requires non - trivial randomization at 0 .",
    "this is quite uncommon in min - max approaches .",
    "it is basically due to the fact that , even though we follow a worst - case approach with respect to the two parameters , the underlying setup is still bayesian thus accepting randomized optimum solutions , as was demonstrated in theorem[th:1 ] .",
    "let us now continue our presentation with the max - min criteria introduced in , .",
    "we propose the following optimization problem @xmath106\\geq\\gamma\\geq1 , \\label{eq : lorden2}\\end{gathered}\\ ] ] where we maximize lorden s modified measure under the classical constraint on the average false alarm period . similarly for pollak s modified criterion , we have @xmath107\\geq\\gamma\\geq1 .",
    "\\label{eq : pollak2}\\end{gathered}\\ ] ] the following theorem offers the solution to both problems .    [ th:3 ] the optimum stopping time that solves the max - min problems in and is the shewhart test with constant threshold @xmath47 computed from the equation @xmath108 .    the proof for ( actually under a more general semi - bayesian setting )",
    "is given in pollak and krieger @xcite , while the one for is detailed in the appendix .",
    "we note that in the case of pollak s modified measure we have an _ exact _ optimality result .",
    "this should be compared with the original criterion @xmath109 in where ( third - order ) asymptotically optimum detection rules are available ( see @xcite,@xcite ) .",
    "the simplicity of the probability maximizing approach allows for the straightforward solution of problems which , in the classical changepoint literature ( involving expected delays ) , have been open for many years .",
    "it is worth analyzing two such characteristic cases in detail and develop the corresponding optimal solutions .",
    "let @xmath110 , @xmath111 denote two pdf sequences and consider the case where the observation process @xmath24 is independent but not identically distributed , following the first pdf sequence up to some changetime @xmath7 and switching to the second after @xmath7 .",
    "we are interested in detecting the change optimally following the max - min approach proposed in or .",
    "we recall that the likelihood ratio @xmath112 has now time - varying statistics .",
    "we have the following theorem that provides the optimum solution to both problems .",
    "[ th:4 ] the optimum stopping time that solves and for the case of independent and non - identically distributed observations , is the shewhart stopping time @xmath113 , where the sequence of thresholds @xmath114 is obtained by solving the equations @xmath115 with parameter @xmath116 . assuming for each @xmath117 that @xmath118 this parameter is specified by requiring the false alarm constraint to be satisfied with equality , that is , @xmath119=1+\\sum_{t=1}^\\infty\\prod_{l=1}^t{{\\sf p}}_{\\infty , l}\\big(\\ell_l<\\nu_l(\\beta)\\big)=\\gamma .",
    "\\label{eq : th4.2}\\ ] ]    the proof of theorem[th:4 ] can be found in the appendix .    due to the time - varying statistics",
    ", the threshold sequence needs to be time - varying as well . with",
    "we assure that the shewhart test is an equalizer over time , a very important property for proving its optimality .",
    "this is indeed true since @xmath120 .",
    "of course this condition still generates an ambiguity since @xmath117 is unknown .",
    "this last parameter is then specified by forcing the shewhart stopping time to satisfy the false alarm constraint with equality through .",
    "condition guarantees summability of the series in and also simplifies , considerably , the proof of our theorem .",
    "it can be relaxed but at the expense of a far more involved analysis .",
    "0.2 cm example 2 : consider the case where @xmath121 is time invariant gaussian with mean 0 and variance 1 , while @xmath122 is gaussian with mean @xmath123 and variance 1 .",
    "the sequence of thresholds then becomes @xmath124 and @xmath125 denotes the inverse cdf of a standard gaussian .",
    "assumption is valid if the sequence of means @xmath126 is upper bounded by a finite constant . to find @xmath117 , we observe that @xmath127 .",
    "since there is a one - to - one correspondence between @xmath116 and @xmath128 , we can instead solve for @xmath129 , that is , @xmath130 and compute the optimum performance as @xmath131 .",
    "consider now the change detection problem with more than one post - change possibilities .",
    "our observation sequence @xmath24 is i.i.d .  before and after the change with a common pdf @xmath29 before the change and two different pdf possibilities @xmath132 after the change .",
    "following a pure non - bayesian approach ( see pollak and krieger @xcite for semi - bayesian formulations ) we extend the definition of our performance measures in order to account for the multiple post - change distributions .",
    "define @xmath133 where @xmath134 is the measure induced by a change at time @xmath4 with the alternative pdf being @xmath135 .",
    "consequently in our criterion we include an additional minimization over the possible alternative measures .",
    "limiting , again , ourselves to the special case @xmath70 , we are interested in solving the following constrained optimization problems @xmath136\\ge\\gamma\\geq1 , \\label{eq : lorden4}\\end{gathered}\\ ] ] for the lorden and @xmath137\\ge\\gamma\\geq1 , \\label{eq : pollak4}\\end{gathered}\\ ] ] for the pollak criterion .",
    "we note that we have two sequences of likelihood ratios , namely @xmath138 and @xmath139 defined as @xmath140 . for each @xmath141 $ ]",
    "we define a threshold @xmath142 , so that the following version of the shewhart test @xmath143 satisfies the equation @xmath144 the next theorem demonstrates that by proper selection of the parameter @xmath145 , the corresponding stopping time solves both optimization problems .",
    "[ th:5 ] for the solution of and we distinguish three cases :    \\i ) if @xmath146 , then the optimum test is @xmath147 .",
    "\\ii ) if @xmath148 then the optimum test is @xmath149 .",
    "\\iii ) if there is @xmath150 such that @xmath151 then the optimum test is @xmath152 . for each @xmath153 , only one of i ) , ii ) and iii ) applies .",
    "the proof of theorem[th:5 ] can be found in the appendix .",
    "we can use the previous outcome to find solutions for lorden s _ original _ criterion involving average detection delays when there are multiple post - change probabilities .",
    "the goal is to obtain a result similar to the one presented in section[ssec:1.1 ] for the shewhart rule of theorem[th:5 ] .",
    "consider the lorden criterion in properly extended to cover multiple post - change probability distributions . in particular we propose @xmath154.\\ ] ] we are then interested in the following min - max constrained optimization problem @xmath155\\\\ \\text{over all}~t:~{{\\sf e}}_\\infty[t]\\geq\\gamma\\geq1 .",
    "\\label{eq : lorden_m}\\end{gathered}\\ ] ]    this problem has been open for many years .",
    "existing results typically refer to the two - sided cusum ( 2-cusum ) and demonstrate that this rule exhibits different levels of asymptotic optimality .",
    "for example in hadjiliadis and moustakides @xcite and hadjiliadis and poor @xcite , it is proved that specially designed 2-cusum tests enjoy second and third order asymptotic optimality when detecting changes in the constant drift of a brownian motion .",
    "dragalin @xcite provides first order asymptotically optimum 2-cusum rules for the case of single parameter exponential families .    with the next theorem we present the analog of section[ssec:1.1 ] for the case of two post - change probability measures .",
    "in particular we demonstrate that the shewhart test of theorem[th:5 ] can be the _ exact _ solution to provided threshold @xmath47 ( hence parameter @xmath49 ) takes values within a range that we explicitly identify .",
    "the next theorem presents the precise form of our claim .",
    "we recall that the two likelihood ratios @xmath156 are known functions of the observation @xmath157 .",
    "[ th:6 ] with @xmath152 defined in and , we distinguish three cases that can provide partial solution to :    \\i ) if @xmath158 with @xmath159 , then the optimum test is @xmath147 .",
    "\\ii ) if @xmath160 with @xmath161 , then the optimum test is @xmath149 .",
    "\\iii ) if there is @xmath150 with @xmath162 such that @xmath163 and @xmath164 where @xmath165 and @xmath166 its complement , then the optimum test is @xmath152",
    ".    the proof of theorem[th:5 ] can be found in the appendix .    even though the extent of this result is clearly limited",
    ", it is nontheless the first time we have a nonasymptotic solution for lorden s formulation when there are multiple distributions under the alternative regime .",
    "theorem[th:6 ] also establishes that 2-cusum is _ not _ strictly optimum ( at least not in the sense of ) despite its very strong asymptotic optimality properties .",
    "finally we need to mention that it is not possible to recover the same non - asymptotic result by assigning specific prior probabilities to the post - change measures ( i.e. following the semi - baysian idea of @xcite ) . the extra freedom enjoyed by considering each probability measure separately is critical in demonstrating the optimality of the shewhart test in the sense of lorden .    0.2 cm example 3 : consider the gaussian case where under the nominal regime the samples are i.i.d . with mean 0 and variance 1",
    "whereas under the alternative they can have two possible means @xmath167 with unit variance .",
    "let us apply case  iii ) of theorem[th:6 ] .",
    "due to symmetry it is sufficient to select @xmath168 to satisfy .",
    "the two likelihood ratios @xmath169 as functions of the observation @xmath170 are equal to @xmath171 and the sets of interest are @xmath172 and @xmath173 .",
    "we can now compute the critical range for threshold @xmath47 from . since @xmath174 and @xmath175",
    ", we have @xmath176 .",
    "this interval is nonempty when @xmath177 and gives rise to the following range for @xmath49 @xmath178 with the worst - case average detection delay satisfying @xmath179 using the same numerical value we adopted in example1 for the one - sided case , namely , @xmath68 , we obtain @xmath180 while the optimum detection delay becomes , at worst , 1.001 .",
    "compared to example1 , as we can see , the range of @xmath49 where the shewhart test is optimum is reduced to half .    0.2 cm remark :",
    "because with the maximizing probability approach we focus on a single sample after the change , it turns out that shewhart is optimum for _ transient changes _ as well .",
    "specifically , the same proofs go through for any type of change provided _ it lasts at least one sample _ ( which is necessary for a change to exist ) .",
    "clearly this is an additional distinct optimality characteristic enjoyed by this simple detection rule .",
    "as we know , the shiryaev , cusum and shiryaev - roberts tests lose their optimality if the change does not last indefinitely after its occurrence .",
    "proof of theorem [ th:1 ] .",
    "we begin our analysis by writing the performance measure in a more detailed form .",
    "we have @xmath181 since @xmath182 , for the numerator we can write @xmath183\\\\ = \\pi\\varpi+\\frac{(1-\\pi)p}{(1-p)}{{\\sf e}}_\\infty[(1-p)^t\\ell_t{\\mathbbm{1}_{\\{t>0\\}}}]\\\\ = \\pi\\varpi+\\frac{(1-\\pi)p}{(1-p)}{{\\sf e}}_\\infty[(1-p)^t\\ell_t|t>0]{{\\sf p}}(t>0)\\\\ = \\pi\\varpi+\\frac{(1-\\pi)p}{(1-p)}{{\\sf e}}_\\infty[(1-p)^t\\ell_t|t>0](1-\\varpi ) .",
    "\\label{eq : sh_num}\\end{gathered}\\ ] ] similarly for the denominator , since @xmath184 and @xmath182 , we have @xmath185\\\\ = \\pi+(1-\\pi){{\\sf e}}_\\infty[1-(1-p)^t]=\\pi+(1-\\pi){{\\sf e}}_\\infty\\left[\\big(1-(1-p)^t\\big){\\mathbbm{1}_{\\{t>0\\}}}\\right]\\\\ = \\pi+(1-\\pi){{\\sf e}}_\\infty[1-(1-p)^t|t>0]{{\\sf p}}(t>0)\\\\ = \\pi+(1-\\pi)\\{1-{{\\sf e}}_\\infty[(1-p)^{t}|t>0]\\}(1-\\varpi ) , \\label{eq : sh_den}\\end{gathered}\\ ] ] with the third last equality being true because @xmath186 . combining and we have the following form for the modified shiryaev measure @xmath187(1-\\varpi)}{\\pi+(1-\\pi)\\{1-{{\\sf e}}_\\infty[(1-p)^t|t>0]\\}(1-\\varpi)}. \\label{eq : sh_analytic}\\ ] ]    next , we distinguish different possibilities depending on the value of @xmath188 . for case",
    "i ) where @xmath189 by selecting @xmath90 , in other words stopping at 0 with probability 1 , as we can see from , yields @xmath190 which is the maximum possible value for our criterion ( since it is a probability ) . on the other hand the denominator , which is the complement of the false alarm probability , from is equal to @xmath191 .",
    "this means that the false alarm probability is @xmath192 thus satisfying the constraint .",
    "let now @xmath193 .",
    "since the stopping time @xmath12 must satisfy the false alarm constraint , this suggests that the denominator , by being the complement of the false alarm probability , is no smaller than @xmath194 .",
    "we are going to show that in order to maximize the performance measure it is sufficient to limit ourselves to stopping times that satisfy the false alarm constraint with equality .",
    "this equality will be achieved by modifying the randomization probability @xmath81 in a way that will improve ( increase ) the value of the criterion @xmath195 .",
    "as we can see from both , the numerator and the denominator are linear functions of @xmath81 and the ratio takes its maximal value ( equal to 1 ) for @xmath90 . we can therefore conclude that the ratio is an increasing function of @xmath81 . if @xmath12 is such that the denominator is strictly greater than @xmath194 and since we are in the case where @xmath196 , this suggests that",
    ", necessarily , we have @xmath197>1-\\alpha$ ] .",
    "consequently by replacing @xmath81 with a _ larger _",
    "value @xmath198 we can make the denominator exactly equal to @xmath194 . making the same change in the numerator , due to the monotonicity with respect to @xmath81 this will result in an overall increase of our performance measure .",
    "therefore , without loss of generality , we may limit ourselves to stopping times that satisfy the false alarm constraint with equality .",
    "the previous observation suggests that we can maximize the numerator in subject to the constraint that the denominator is equal to @xmath199 . using the lagrange multiplier technique we define the following criterion @xmath200 that combines the numerator and the constraint @xmath201(1-\\varpi)\\\\ & ~~~+\\lambda\\left\\{\\pi\\varpi+\\{1-(1-\\pi){{\\sf e}}_\\infty[(1-p)^{t}|t>0]\\}(1-\\varpi)\\right\\}\\\\ & = \\pi(1+\\lambda)\\varpi\\\\ & ~~~+\\left\\{\\lambda+(1-\\pi){{\\sf e}}_\\infty\\left[(1-p)^{t}\\left(\\frac{p}{1-p}\\ell_{t}-\\lambda\\right)|t>0\\right]\\right\\}(1-\\varpi),\\end{aligned}\\ ] ] with @xmath202 being the corresponding lagrange multiplier .",
    "the goal , now , is first to maximize @xmath200 over @xmath203 and then over the randomization probability @xmath204 $ ] .",
    "fixing @xmath81 and maximizing over @xmath203 means that we need to maximize the expression @xmath205.\\ ] ] for @xmath206 consider the following specific value of the lagrange multiplier @xmath207 using standard optimal stopping theory it is then straightforward to show that @xmath208 is maximized by the shewhart stopping time defined in with constant threshold @xmath47 . the corresponding optimum performance",
    "can then be computed as follows @xmath209^{t-1}\\left\\{\\frac{p}{1-p}{{\\sf p}}_0(\\ell_1\\geq\\nu)-\\lambda{{\\sf p}}_\\infty(\\ell_1\\geq\\nu)\\right\\}\\\\ = \\frac{p{{\\sf p}}_0(\\ell_1\\geq\\nu)-\\lambda(1-p){{\\sf p}}_\\infty(\\ell_1\\geq\\nu)}{1-(1-p){{\\sf p}}_\\infty(\\ell_1<\\nu)}= \\frac{p}{1-p}\\nu-\\lambda.\\end{gathered}\\ ] ] the last equality can be verified by directly substituting the definition of the lagrange multiplier @xmath202 . using this result in the original measure",
    ", we end up with the following inequality @xmath210(1-\\varpi ) .",
    "\\label{eq : gopt}\\end{gathered}\\ ] ] from , we can also compute the corresponding false alarm probability which must be set equal to @xmath188 ( we must satisfy the constraint with equality ) @xmath211    we are now left with the definition of the randomization probability @xmath81 . selecting @xmath81 optimally",
    "amounts to maximizing the right hand side in over @xmath81 .",
    "we observe that the corresponding expression is a convex combination of the value @xmath212 , which is the gain obtained when stopping at 0 , and @xmath213 , which is the gain resulting by employing @xmath214 for @xmath33 .",
    "clearly we are going to put all the probability mass on the largest gain .",
    "consequently , when @xmath215 the gain provided by @xmath214 exceeds the gain obtained by stopping at 0 , therefore in this case we select @xmath97 .",
    "of course @xmath47 must be such that the shewhart test satisfies the false alarm constraint with equality .",
    "from by substituting @xmath97 we can see that the constraint is satisfied when @xmath47 is computed through equation .",
    "this equation has always a solution that exceeds @xmath94 as long as @xmath188 takes values in the interval specified in case iii ) .",
    "when @xmath216 , stopping at 0 provides exactly the same gain as the shewhart test @xmath214 with threshold @xmath94 .",
    "therefore we can randomize between the two possibilities with any probability @xmath81 .",
    "however , since we need to satisfy the false alarm constraint with equality , from with @xmath216 we can solve for @xmath81 , and obtain the optimum @xmath81 depicted in case  ii ) .",
    "the resulting value corresponds to a legitimate probability @xmath204 $ ] when @xmath188 is within the limits prescribed for this case .",
    "this concludes our proof",
    ".    0.2 cm proof of theorem [ th:2 ] .",
    "the proof will rely on the analysis we applied in the proof of theorem[th:1 ] . in order to solve the max - min problem defined in our theorem",
    "it is sufficient to show the existence of a tripple @xmath217 such that the following saddle - point relation holds @xmath218 for all stopping times @xmath12 that satisfy the false alarm constraint .",
    "it is well known that whenever a saddle - point solution exists it is also max - min optimum .",
    "indeed note that if @xmath219 satisfies then we can write @xmath220 where the first inequality is obvious ; the second corresponds to the left hand side inequality in and the last equality is equivalent to the right hand side inequality in .",
    "consequently @xmath219 solves the max - min problem and the parameter pair @xmath221 corresponds to the worst - case ( least - favorable ) exponential prior .    to show ,",
    "let us first define our candidate optimum stopping time @xmath219 .",
    "consider , and observe that for @xmath222 the left hand side tends to 0 , whereas for @xmath223 the same expression tends to @xmath224 .",
    "furthermore the ratio is a strictly increasing and continuous function of @xmath47 ( see footnote [ foot:3 ] ) . due to this continuity and strict monotonicity",
    "the equation has a unique solution @xmath47 . with the help of this threshold value our candidate detection rule @xmath219",
    "consists in randomizing with probability @xmath225 between stopping at 0 and using the shewhart test @xmath214 with constant threshold @xmath47 .",
    "for @xmath219 we observe that @xmath226=(1-\\varpi^*){{\\sf e}}_\\infty[{\\mathcal{s}}]={{\\sf p}}_0(\\ell_1<\\nu)/{{\\sf p}}_\\infty(\\ell_1\\geq\\nu)=\\gamma$ ] , suggesting that it satisfies the false alarm constraint with equality .",
    "we first demonstrate that @xmath219 satisfies the right hand side in . for any parameter pair @xmath98 , after recalling that on @xmath227 we have @xmath228 , we can verify using , that @xmath229(1-\\varpi^*)}{\\pi\\varpi^*+\\{1-(1-\\pi){{\\sf e}}_\\infty[(1-p)^{{\\mathcal{s}}}]\\}(1-\\varpi^*)}={{\\sf p}}_0(\\ell_1\\geq\\nu).\\ ] ] the last equality is true since we can immediately compute @xmath230=(1-p){{\\sf p}}_0(\\ell_1\\geq\\nu)/\\{1-(1-p){{\\sf p}}_\\infty(\\ell_1<\\nu)\\}$ ] and @xmath231=(1-p){{\\sf p}}_\\infty(\\ell_1\\geq\\nu)/\\{1-(1-p){{\\sf p}}_\\infty(\\ell_1<\\nu)\\}$ ] .",
    "as we realize , the resulting performance of @xmath219 is independent from @xmath98 therefore the stopping rule is an equalizer with respect to the two parameters .",
    "this , in turn , suggests that the right hand side in is trivially satisfied with equality .",
    "showing the left hand side inequality requires more work .",
    "note that we need to define the worst - case parameter pair @xmath221 .",
    "unfortunately this pair turns out to be a limiting case corresponding to an exponential prior that tends to a degenerate uniform .",
    "more specifically , for @xmath232 we solve for @xmath191 the following equation @xmath233 resulting in @xmath234 .",
    "the parameter pair @xmath235 with @xmath105 yields the worst - case exponential prior we are interested in",
    ". consequently for the left hand side inequality we need to prove that @xmath236 over all @xmath12 satisfying the false alarm constraint @xmath56=(1-\\varpi){{\\sf e}}_\\infty[t|t>0]\\geq\\gamma$ ] .",
    "fix a sufficiently small @xmath237 so that @xmath238 .",
    "define the false alarm level @xmath239 and the class of stopping rules @xmath240 it is then straightforward to verify that @xmath241 and that for any probability @xmath242 , the quantities @xmath243 are such that case  ii ) of theorem[th:1 ] applies .",
    "this suggests that when @xmath244 is maximized over the class @xmath245 , the optimum stopping time is to randomize between stopping at 0 and the shewhart test @xmath214 with threshold @xmath47 using the randomization probability @xmath246 .",
    "the latter is a direct consequence of the specific definition of @xmath247 and @xmath248 .",
    "call the resulting optimal stopping time @xmath249 . note also that this optimality property is true for all @xmath250 . using the definitions of @xmath247 , @xmath248 and",
    ", we can verify that the class @xmath245 in can be equivalently written as @xmath251\\geq\\frac{\\gamma-\\frac{\\epsilon}{{{\\sf p}}_\\infty(\\ell_1\\geq\\nu)}}{1+p\\gamma}\\right\\ } , \\label{eq : classa2}\\ ] ] where we also used .",
    "fix a @xmath12 that satisfies the false alarm constraint @xmath56=(1-\\varpi){{\\sf e}}_\\infty[t|t>0]\\geq\\gamma$ ] . as we argued",
    "before , our goal is to prove . from monotone convergence",
    "we have @xmath252=(1-\\varpi){{\\sf e}}_\\infty[t|t>0]\\geq\\gamma.\\ ] ] consequently , for any @xmath253 $ ] , where @xmath254 sufficiently small , we can write @xmath255\\geq\\gamma-\\frac{\\epsilon}{{{\\sf p}}_\\infty(\\ell_1\\geq\\nu)}.\\ ] ] the previous inequality , comparing with , suggests that @xmath256 for all @xmath257 .",
    "a direct consequence of this fact is that @xmath258 for all @xmath257 . taking the limit as @xmath105 and using monotone convergence",
    ", we obtain @xmath259}{\\nu+(1-\\varpi^*_\\epsilon){{\\sf e}}_\\infty[{\\mathcal{s } } ] } , \\label{eq : b.4}\\end{gathered}\\ ] ] since @xmath260=1/{{\\sf p}}_\\infty(\\ell_1\\geq\\nu)$ ] , @xmath261={{\\sf p}}_0(\\ell_1\\geq\\nu)/{{\\sf p}}_\\infty(\\ell_1\\geq\\nu)$ ] and @xmath262 , we conclude that @xmath261\\leq\\varpi^*_\\epsilon{{\\sf e}}_\\infty[{\\mathcal{s}}]$ ] . substituting in yields @xmath263 because this inequality is true for any sufficiently small @xmath237 , we have validity of .",
    "this concludes our proof",
    ".    0.2 cm proof of theorem [ th:3 ] . if @xmath12 is such that @xmath56=\\infty$ ]",
    ", then we can define a sufficiently large integer @xmath264 so that @xmath265\\geq\\gamma$ ] where @xmath266 .",
    "since for @xmath267 we have @xmath268 and @xmath269 , we conclude @xmath270 . on the other hand for @xmath271",
    "it is true that @xmath272 , suggesting that @xmath273 .",
    "this means that @xmath274 .",
    "the last inequality implies that we can limit ourselves to stopping times @xmath12 that satisfy @xmath275\\geq\\gamma$ ] .    from lorden s modified measure",
    "we conclude that for all @xmath276 we can write @xmath277 multiplying both sides with @xmath278 and taking expectation with respect to the nominal measure yields @xmath279 .",
    "\\label{eq : c.0}\\ ] ] summing over all @xmath276 we obtain @xmath280\\leq{{\\sf e}}_\\infty[\\ell_t],\\ ] ] where we define @xmath281 . from the previous inequality",
    "we conclude @xmath282}{{{\\sf e}}_\\infty[t]}=\\frac{(1-\\varpi){{\\sf e}}_\\infty[\\ell_t|t>0]}{(1-\\varpi){{\\sf e}}_\\infty[t|t>0]}=\\frac{{{\\sf e}}_\\infty[\\ell_t|t>0]}{{{\\sf e}}_\\infty[t|t>0]}.\\ ] ]    let us examine the ratio @xmath283/{{\\sf e}}_\\infty[t]$ ] over all @xmath12 that satisfy the constraint .",
    "note that when @xmath275=(1-\\varpi){{\\sf e}}_\\infty[t|t>0]>\\gamma$ ] we can replace @xmath81 with a larger value @xmath284 so that @xmath285=\\gamma$ ] without changing the value of the ratio ( since it does not depend on @xmath81 ) .",
    "this in turn suggests that any value attained by this ratio can also be achieved by a stopping time that satisfies the constraint with equality . using this observation we can write @xmath286\\geq\\gamma}{\\mathscr{j}}_{\\rm l}(t)\\leq \\sup_{t:{{\\sf e}}_\\infty[t]=\\gamma}\\frac{{{\\sf e}}_\\infty[\\ell_t]}{{{\\sf e}}_\\infty[t]}=\\gamma^{-1}\\sup_{t:{{\\sf e}}_\\infty[t]=\\gamma}{{\\sf e}}_\\infty[\\ell_t ] .",
    "\\label{eq : c.1}\\ ] ]    to maximize @xmath283 $ ] over all stopping times that satisfy the constraint with equality , we reduce the optimization problem into an unconstraint one using the lagrange multiplier technique .",
    "in particular we consider the maximization of @xmath287=(1-\\varpi){{\\sf e}}_\\infty[\\ell_t-\\lambda t|t>0].\\ ] ] to find the optimum stopping time we will first optimize over @xmath203 and then identify the optimum randomization probability @xmath81 .",
    "let @xmath206 be the solution of the equation @xmath108 .",
    "define @xmath288 . using standard optimal stopping theory we",
    "can then conclude that @xmath200 for @xmath203 is optimized by the shewhart test with threshold @xmath47 . since @xmath260=1/{{\\sf p}}_\\infty(\\ell_1\\geq\\nu)=\\gamma$ ] and @xmath261={{\\sf p}}_0(\\ell_1\\geq\\nu)/{{\\sf p}}_\\infty(\\ell_1\\geq\\nu)=\\gamma{{\\sf p}}_0(\\ell_1\\geq\\nu)$ ] ,",
    "if we also use the definition of @xmath202 we conclude that @xmath289\\leq(1-\\varpi){{\\sf e}}_\\infty[\\ell_{{\\mathcal{s}}}-\\lambda { \\mathcal{s}}]=(1-\\varpi)\\nu\\leq\\nu.\\ ] ] the last inequality suggests that the optimum randomization probability is @xmath97 . from the previous result we have that for any @xmath12 satisfying the false alarm constraint with equality",
    ", we can write @xmath290-\\lambda \\gamma={{\\sf e}}_\\infty[\\ell_t-\\lambda t]\\leq{{\\sf e}}_\\infty[\\ell_{{\\mathcal{s}}}-\\lambda { \\mathcal{s}}]= { { \\sf e}}_\\infty[\\ell_{{\\mathcal{s}}}]-\\lambda\\gamma,\\ ] ] which implies @xmath283\\leq{{\\sf e}}_\\infty[\\ell_{{\\mathcal{s}}}]=\\gamma{{\\sf p}}_0(\\ell_1\\geq\\nu)$ ] . observing also that for every @xmath276 we have @xmath291 , this means that shewhart is an equalizer , consequently @xmath292 . using these two facts in leads to @xmath293\\geq\\gamma}{\\mathscr{j}}_{\\rm l}(t)\\leq\\gamma^{-1}\\sup_{t:{{\\sf e}}_\\infty[t]=\\gamma}{{\\sf e}}_\\infty[\\ell_t]\\\\ \\leq\\gamma^{-1}\\{\\gamma{{\\sf p}}_0(\\ell_1\\geq\\nu)\\}={{\\sf p}}_0(\\ell_1\\geq\\nu)={\\mathscr{j}}_{\\rm l}({\\mathcal{s}}),\\end{gathered}\\ ] ] which proves optimality for @xmath214 and concludes the proof .",
    "exactly the same analysis applies to .",
    "in fact , we can simply start the proof from , which is immediately satisfied by pollak s modified measure .",
    "0.2 cm proof of theorem [ th:4 ] .",
    "let @xmath117 and @xmath114 be such that , , are satisfied .",
    "if we define @xmath294 , then assumption is equivalent to @xmath295 for simplicity , from now on , we drop the dependence of @xmath296 and @xmath297 on @xmath117 . for @xmath276",
    "define the two sequences @xmath298 @xmath299=1+\\sum_{n = t+1}^\\infty\\prod_{l = t+1}^n{{\\sf p}}_{\\infty , l}(\\ell_{l}<\\nu_{l})~\\text{and}~c_{t}=\\frac{\\omega_{t+1}}{\\nu_{t+1}}.\\ ] ] also set @xmath300 and @xmath281 . from the definition of @xmath301 and comparing with",
    "we conclude that @xmath302 .",
    "note that @xmath303 satisfies the backward recursion @xmath304 from we have @xmath305 suggesting that @xmath306 .",
    "furthermore @xmath307\\leq\\nu_t,\\ ] ] from which we conclude that @xmath308 . in other words both sequences @xmath298",
    "are uniformly bounded from above by some finite constant .",
    "consider first .",
    "the function @xmath309 is decreasing in @xmath117 with @xmath310 and @xmath311 . from assumption",
    "we have validity of which allows for the use of bounded convergence to show that @xmath312 is continuous in @xmath117 .",
    "this suggests that has a nonnegative solution .    as in the previous theorem",
    "we can write @xmath313.\\ ] ] multiplying both sides with @xmath314 , which is nonnegative , and summing over @xmath276 we deduce that for any @xmath203 we have @xmath315}{{{\\sf e}}_\\infty[\\sum_{t=0}^{t-1}c_t]}.\\ ] ] enlarging the class of stopping times @xmath12 by allowing randomization at time 0 with probability @xmath81 , recalling that @xmath281 and using similar arguments as in the proof of theorem[th:3 ] , we can show that @xmath286\\geq\\gamma}{\\mathscr{j}}_{\\rm l}(t)\\leq\\sup_{t:{{\\sf e}}_\\infty[t]=\\gamma}\\frac{{{\\sf e}}_\\infty[\\ell_tc_{t-1}]}{{{\\sf e}}_\\infty[\\sum_{t=0}^{t-1}c_t ] } , \\label{eq : d.0}\\ ] ] namely , to maximize the upper bound it suffices to limit ourselves to stopping times that satisfy the false alarm constraint with equality .",
    "we will show that the upper bound can not exceed @xmath117 .",
    "fix @xmath12 with @xmath56=(1-\\varpi){{\\sf e}}_\\infty[t|t>0]=\\gamma$ ] and consider the expression @xmath316\\\\ = ( 1-\\varpi){{\\sf e}}_\\infty\\left[\\ell_tc_{t-1}+\\sum_{t=0}^{t-1}(1-\\beta c_t)|t>0\\right ] .",
    "\\label{eq : d.1}\\end{gathered}\\ ] ] note that @xmath90 is not an acceptable value since then @xmath12 can not satisfy the false alarm constraint with equality .",
    "therefore @xmath317 .",
    "this suggests that @xmath318=\\gamma/(1-\\varpi)<\\infty$ ] .",
    "we first examine the part @xmath203 , namely the expression @xmath319.\\ ] ] we observe that @xmath320=\\sum_{t=1}^\\infty{{\\sf e}}_\\infty[\\ell_t{\\mathbbm{1}_{\\{t = t\\}}}|t>0]\\leq\\sum_{t=1}^\\infty{{\\sf e}}_\\infty[\\ell_t{\\mathbbm{1}_{\\{t > t-1\\}}}|t>0]\\\\ = \\sum_{t=1}^\\infty{{\\sf e}}_\\infty\\left[{{\\sf e}}_\\infty[\\ell_t|{\\mathscr{f}}_{t-1}]{\\mathbbm{1}_{\\{t > t-1\\}}}|t>0\\right]={{\\sf e}}_\\infty[t|t>0]<\\infty.\\end{gathered}\\ ] ] since @xmath321 is uniformly bounded and because of the previous observation , this suggests that for every @xmath237 we can find sufficiently large integer @xmath264 so that @xmath322 , where @xmath266 .",
    "this implies @xmath323 we can now maximize @xmath324 over @xmath325 with the optimization performed over the finite time horizon @xmath326 $ ] . from standard optimal stopping theory",
    "we can define the sequence of optimal costs with the help of the backward recursion @xmath327\\};~t = m-1,\\ldots,0,\\ ] ] starting with @xmath328 .",
    "since @xmath329 , using induction we can show that @xmath330 for all @xmath331 . indeed , the inequality is true for @xmath332 .",
    "assume it is true for @xmath333 , we will then prove it for @xmath4 .",
    "note that @xmath334\\}\\\\ \\leq\\max\\{\\ell_tc_{t-1},(1-\\beta c_{t})+{{\\sf e}}_\\infty[\\max\\{\\ell_{t+1}c_t,\\omega_{t+1}\\}]\\}\\\\ = \\max\\{\\ell_tc_{t-1},(1-\\beta c_{t})+c_t{{\\sf p}}_{0,t+1}(\\ell_{t+1}\\geq\\nu_{t+1})+\\omega_{t+1}{{\\sf p}}_{\\infty , t+1}(\\ell_{t+1}<\\nu_{t+1})\\}\\\\ = \\max\\{\\ell_tc_{t-1},1+\\omega_{t+1}{{\\sf p}}_{\\infty , t+1}(\\ell_{t+1}<\\nu_{t+1})\\}=\\max\\{\\ell_tc_{t-1},\\omega_{t}\\}.\\end{gathered}\\ ] ] the inequality above is due to the induction assumption ; furthermore , in the last three equalities we used the definition of @xmath335 , namely , @xmath336 ; the fact that by construction of the sequence @xmath28 we have @xmath337 ; and we also used recursion .",
    "we thus conclude that @xmath330 . applying it for @xmath338 yields @xmath339 , because @xmath340 is defined to be 0 and , as we argued , @xmath302 . from optimal stopping theory",
    "we have @xmath341 , consequently @xmath342 . using this in we obtain @xmath343 which implies @xmath344 .",
    "substituting in and maximizing over @xmath81 , we have @xmath345 with the optimum randomization being @xmath97 .",
    "using the definition of @xmath200 from and the fact that we consider @xmath12 with @xmath56=\\gamma$ ] we have @xmath346-\\beta{{\\sf e}}_\\infty\\left[\\sum_{t=0}^{t-1}c_t\\right]+{{\\sf e}}_\\infty[t]\\ ] ] which directly implies @xmath347}{{{\\sf e}}_\\infty\\left[\\sum_{t=0}^{t-1}c_t\\right]}\\leq\\beta.\\ ] ] shewhart , by construction , is an equalizer , hence we have @xmath348 . from and",
    "the previous inequality we can then write @xmath349\\geq\\gamma}{\\mathscr{j}}_{\\rm l}(t)\\leq\\sup_{t:{{\\sf e}}_\\infty[t]=\\gamma } \\frac{{{\\sf e}}_\\infty[\\ell_tc_{t-1}]}{{{\\sf e}}_\\infty\\left[\\sum_{t=0}^{t-1}c_t\\right]}\\leq\\beta={\\mathscr{j}}_{\\rm l}({\\mathcal{s}}),\\ ] ] thus proving the desired optimality for lorden s criterion .",
    "similar proof applies in the case of pollak s measure",
    ".    0.2 cm proof of theorem [ th:5 ] . when @xmath350 or @xmath351 then @xmath352 is continuous and strictly decreasing in @xmath47 ( see footnote[foot:3 ] ) .",
    "if @xmath150 we observe @xmath353 consequently if we use the continuity and strict monotonicity with respect to @xmath47 of the first probability under the integral and bounded convergence we can prove continuity and strict monotonicity of @xmath354 as a function of @xmath47 for all @xmath141 $ ] .",
    "this probability is equal to 1 and 0 for @xmath355 and @xmath223 respectively therefore there exists unique @xmath142 that satisfies the false alarm constraint with equality .",
    "consider now @xmath356 as a function of @xmath145 .",
    "we like to show that this function is continuous .",
    "fix @xmath357 then for @xmath358 we will show @xmath359 . recall that @xmath356 is constructed so that for all @xmath141 $ ] we have @xmath360 . taking the limit with respect to @xmath358 and using we have @xmath361 where for the second equality we used bounded convergence and the continuity of the cdf of @xmath362 .",
    "since @xmath363 but also from the definition of @xmath364 that @xmath365 , we can claim that @xmath359 because for each @xmath145 , as we argued before , the threshold that satisfies the false alarm constraint with equality is unique .",
    "similar proof ( with one - sided limits ) applies for @xmath366 .",
    "let us now prove the validity of our theorem when the condition of case  i ) is true .",
    "we have @xmath367 where the second inequality comes from the fact that @xmath147 is optimum when the post - change probability measure is @xmath368 , and the last equality is the result of @xmath147 being an equalizer under @xmath368 .",
    "note now that @xmath369 the inequality being the condition of case  i ) and the equality that follows is the result of @xmath147 being an equalizer under @xmath370 as well .",
    "completing what was started in , we can write @xmath371 which proves the claim of case  i ) . similar proof applies in case  ii ) .",
    "suppose now that neither the condition of case  i ) nor of case  ii ) is valid .",
    "this suggests that we simultaneously have @xmath372 and @xmath373 .",
    "define the following difference as a function of @xmath145 @xmath374 we observe that @xmath375 and @xmath376 , furthermore @xmath377 is continuous because we can show using and the continuity of @xmath356 that the probabilities @xmath378 are continuous in @xmath145 .",
    "hence there exists @xmath150 so that @xmath379 . for this specific @xmath145 the corresponding shewhart stopping rule",
    "@xmath152 is by construction an equalizer across time and across post - change probabilities .",
    "furthermore for each @xmath12 and @xmath276 , as in , we have @xmath380 suggesting @xmath381.\\end{gathered}\\ ] ] summing over @xmath276 we obtain the following upper bound @xmath382}{{{\\sf e}}_\\infty[t]}.\\ ] ] the proof continues along the same lines of the proof of theorem[th:3 ] . basically we show that the upper bound is optimized by @xmath152 , furthermore this optimal value is also attained by @xmath383 because @xmath152 is an equalizer across time and across post - change probabilities .",
    "this establishes the desired optimality for @xmath152 .",
    "what is now left to demonstrate is that for each @xmath49 , only one of the three cases can be valid .",
    "call @xmath384 then we know that @xmath385 is maximized by @xmath147 and @xmath386 by @xmath149 . in fact no other stopping time can attain the same optimal value unless it is equal , with probability 1 , to the corresponding shewhart test .",
    "if case  i ) applies then we will show that it is not possible the condition of case  ii ) to be true .",
    "indeed , if both conditions were valid simultaneously , then we could write @xmath387 where the first inequality comes from case  i ) , the second inequality from the fact that @xmath149 optimizes @xmath386 and the third inequality is the condition of case  ii ) . from the above we",
    "conclude that @xmath149 has a better @xmath388 performance than @xmath147 which optimizes @xmath388 , leading to contradiction .",
    "actually since @xmath149 is not equal to @xmath147 with probability 1 , its corresponding performance is strictly smaller than the optimum .    similarly it is not possible to have the conditions of case  i ) and case  iii ) be satisfied at the same time .",
    "again if this were true then @xmath389 with the first inequality due to case  i ) and the second due to the fact that the convex combination of the two measures is maximized by @xmath152 .",
    "finally the last equality is true because of case  iii ) namely that the stopping time @xmath152 is an equalizer for the two post - change measures .",
    "again this is a contradiction since @xmath152 has larger @xmath388 measure than @xmath147 which is the optimum .",
    "therefore case  i ) and case  iii ) can not be valid at the same time . similarly we can show that case  ii ) and case  iii ) are incompatible .    since we have shown that when neither case  i ) nor case  ii ) is valid , we necessarily have case  iii ) being true",
    ", this suggests that , for each value of @xmath49 , exactly one of the three cases applies .",
    "this concludes the proof for lorden s criterion .",
    "similar proof applies in the case of pollak s measure",
    ".    0.2 cm proof of theorem [ th:6 ] .",
    "let case  i ) be true , then we can write @xmath390\\\\ \\geq\\sup_{t\\geq0}{\\text{ess}\\,\\!\\sup}{{\\sf e}}_t^1[{\\mathcal{s}}(0)-t|{\\mathscr{f}}_t,{\\mathcal{s}}(0)>t]={{\\sf e}}_0 ^ 1[{\\mathcal{s}}(0)]=\\frac{1}{{{\\sf p}}_0 ^ 1(\\ell_1\\geq\\nu(0 ) ) } , \\label{eq : f.1}\\end{gathered}\\ ] ] where the first inequality is obvious and the second comes from the fact that if @xmath391 then the shewhart stopping time @xmath147 , according to section[ssec:1.1 ] , optimizes lorden s original criterion for the post - change probability measure @xmath368 .",
    "the second last equality comes from the fact that shewhart , exactly as cusum , is an equalizer and the last equality is true due to .",
    "we also have @xmath392={{\\sf e}}_0 ^ 2[{\\mathcal{s}}(0)]=\\frac{1}{{{\\sf p}}_0 ^ 2\\big(\\ell_1\\geq\\nu(0)\\big)},\\ ] ] because @xmath147 is an equalizer under @xmath370 as well .",
    "since by assumption , @xmath393 this suggests that @xmath394 . using this last observation in",
    "we conclude that @xmath395 , thus proving optimality of @xmath147 . in a similar way we can prove optimality for @xmath149 under the condition of case  ii ) .",
    "assume now that we are in case  iii ) then @xmath396={{\\sf e}}_t^i\\left[\\sum_{n = t}^\\infty{\\mathbbm{1}_{\\{t > n\\}}}|{\\mathscr{f}}_t , t >",
    "t\\right]\\\\ = \\sum_{n = t}^\\infty{{\\sf e}}_t^i[{\\mathbbm{1}_{\\{t > n\\}}}|{\\mathscr{f}}_t , t > t]=\\sum_{n = t}^\\infty{{\\sf e}}_\\infty\\left[{\\mathbbm{1}_{\\{t > n\\}}}\\prod_{m = t+1}^n\\ell_m^i|{\\mathscr{f}}_t , t > t\\right]\\\\ { { \\sf e}}_\\infty\\left[\\sum_{n = t}^{t-1}\\prod_{m = t+1}^n\\ell_m^i|{\\mathscr{f}}_t , t > t\\right],\\end{gathered}\\ ] ] where we applied a change of measures and used the fact that @xmath397 is @xmath398-measurable .",
    "we also define @xmath399 and @xmath400 when @xmath401 while we recall that @xmath402 is defined to be 0 .",
    "multiplying both sides of the previous inequality with @xmath403 which is nonnegative and @xmath404-measurable and taking expectation with respect to the nominal measure , we obtain @xmath405\\geq { { \\sf e}}_\\infty\\left[\\sum_{n = t}^{t-1}{\\mathbbm{1}_{\\{t > t\\}}}\\prod_{m",
    "= t+1}^n\\ell_m^i(1-\\ell_t^i)^+\\right]\\\\ \\geq{{\\sf e}}_\\infty\\left[\\sum_{n = t}^{t-1}{\\mathbbm{1}_{\\{t >",
    "t\\}}}\\prod_{m = t+1}^n\\ell_m^i(1-\\ell_t^i)\\right]\\\\ = { { \\sf e}}_\\infty\\left[\\sum_{n = t}^{t-1}{\\mathbbm{1}_{\\{t > t\\}}}\\left(\\prod_{m = t+1}^n\\ell_m^i-\\prod_{m = t}^n\\ell_m^i\\right)\\right].\\end{gathered}\\ ] ] summing over all @xmath276 and recalling that @xmath406 , @xmath407 , yields @xmath408 \\geq{{\\sf e}}_\\infty\\left[\\sum_{t=0}^{t-1}\\sum_{n = t}^{t-1}\\left(\\prod_{m = t+1}^n\\ell_m^i-\\prod_{m = t}^n\\ell_m^i\\right)\\right]\\\\ = { { \\sf e}}_\\infty\\left[\\sum_{n=0}^{t-1}\\sum_{t=0}^{n}\\left(\\prod_{m = t+1}^n\\ell_m^i-\\prod_{m = t}^n\\ell_m^i\\right)\\right]={{\\sf e}}_\\infty\\left[\\sum_{n=0}^{t-1}1\\right]={{\\sf e}}_\\infty[t].\\end{gathered}\\ ] ] finally multiplying the previous inequality for @xmath409 with @xmath410 and the one for @xmath411 with @xmath145 and adding the resulting expressions we obtain the following lower bound",
    "@xmath412}{{{\\sf e}}_\\infty\\left[\\sum_{t=0}^{t-1}(1-q)(1-\\ell_t^1)^+ + q(1-\\ell_t^2)^+\\right]}.\\ ] ]    following the usual methodology we have adopted in the previous proofs , in order to minimize the lower bound , with the help of the randomization probability @xmath81 we can show that we can limit ourselves to stopping times that satisfy the false alarm constraint with equality .",
    "consequently @xmath413\\geq\\gamma}{\\mathcal{j}}_{\\rm l}(t)\\\\ \\geq\\inf_{t:{{\\sf e}}_\\infty[t]=\\gamma}\\frac{{{\\sf e}}_\\infty[t]}{{{\\sf e}}_\\infty\\left[\\sum_{t=0}^{t-1}(1-q)(1-\\ell_t^1)^+ + q(1-\\ell_t^2)^+\\right]}\\\\ = \\frac{\\gamma}{\\displaystyle\\sup_{t:{{\\sf e}}_\\infty[t]=\\gamma}{{\\sf e}}_\\infty\\left[\\sum_{t=0}^{t-1}(1-q)(1-\\ell_t^1)^+ + q(1-\\ell_t^2)^+\\right]}. \\label{eq : f.2}\\end{gathered}\\ ] ] for simplicity denote @xmath414 , then maximizing the denominator subject to the equality constraint is straightforward . using a lagrange multiplier with value @xmath415\\ ] ] and applying standard optimal stopping theory",
    ", we can conclude that the optimum stopping time is @xmath416    for @xmath417 we will show that @xmath418 is in fact equivalent to @xmath152 under condition . indeed notice that when @xmath418 stops we have @xmath419 which implies @xmath420 suggesting @xmath421 ( because @xmath152 is the _ first _ time instant the above inequality is true ) . for any @xmath422 we have @xmath423",
    "because @xmath356 satisfies we will show that the previous inequality can be true only when @xmath424 , that is , when the likelihood ratios @xmath425 and @xmath426 are simultaneously no larger than 1 . indeed from we have that the upper bound of @xmath356 is no larger than 1 , consequently in the two likelihood ratios can not be larger than 1 simultaneously .",
    "let @xmath427 and @xmath428 then becomes @xmath429 or @xmath430 .",
    "but the latter is again not possible because of the left hand side inequality of .",
    "the same is true when @xmath431 and @xmath432 .",
    "hence can be valid only when both likelihood ratios are smaller than 1 .",
    "this means that when @xmath422 , is equivalent to @xmath433 this observation suggests that @xmath422 combined with implies @xmath434 , therefore @xmath435 or @xmath436 .",
    "consequently @xmath437 , which means that @xmath152 optimizes the lower bound in .    to compute the optimum value of the lower bound , since before stopping both likelihood ratios",
    "are no larger than 1 , we note @xmath438 = \\gamma-{{\\sf e}}_\\infty\\left[\\sum_{t=0}^{{\\mathcal{s}}(q)-1}(1-q)\\ell_t^1 + q\\ell_t^2\\right]\\\\ = \\gamma\\big\\{(1-q){{\\sf p}}_0 ^ 1\\big((1-q)\\ell_t^1 + q\\ell_t^2\\geq\\nu(q)\\big)+q{{\\sf p}}_0 ^ 2\\big((1-q)\\ell_t^1 + q\\ell_t^2\\geq\\nu(q)\\big)\\big\\}\\\\ = \\gamma{{\\sf p}}_0 ^ 1\\big((1-q)\\ell_t^1 + q\\ell_t^2\\geq\\nu(q)\\big)=\\gamma{{\\sf p}}_0 ^ 2\\big((1-q)\\ell_t^1 + q\\ell_t^2\\geq\\nu(q)\\big),\\end{gathered}\\ ] ] where we used the fact that @xmath439=1/{{\\sf p}}_\\infty((1-q)\\ell_t^1 + q\\ell_t^2\\geq\\nu(q))$ ] and that we are in case  iii ) with condition being valid .",
    "consequently @xmath440\\geq\\gamma}{\\mathcal{j}}_{\\rm l}(t ) \\geq\\frac{1}{{{\\sf p}}_0^i\\big((1-q)\\ell_t^1 + q\\ell_t^2\\geq\\nu(q)\\big)}.\\ ] ] now it is straightforward to verify that the lower bound is attainable by the lorden measure of the shewhart stopping time @xmath152 .",
    "this is clearly due to the fact that @xmath152 is an equalizer across time and across post - change measures .",
    "this concludes our proof .",
    "hadjiliadis , o. and moustakides , g. v. ( 2006 ) .",
    "optimal and asymptotically optimal cusum rules for change point detection in the brownian motion model with multiple alternatives , _ theory probab appl .",
    "_ , * 50*(1 ) 7585 .",
    "tartakovsky , a. g. , pollak m. and polunchenko a. s. ( 2012 ) .",
    "third - order asymptotic optimality of the generalized shiryaev - roberts changepoint detection procedures , _ theory probab .",
    "appl . _ * 56*(3 ) 457484 ."
  ],
  "abstract_text": [
    "<S> for the problem of sequential detection of changes , we adopt the probability maximizing approach in place of the classical minimization of the average detection delay , and propose modified versions of the shiryaev , lorden and pollak performance measures . for these alternative formulations , </S>",
    "<S> we demonstrate that the optimum sequential detection scheme is the simple shewhart rule . </S>",
    "<S> interestingly , we can also solve problems which under the classical setup have been open for many years , as optimum change detection with time varying observations or with multiple post - change probability measures . </S>",
    "<S> for the last case , we also offer the exact solution for lorden s original setup when the average false alarm period is within certain limits . </S>"
  ]
}