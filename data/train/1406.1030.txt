{
  "article_text": [
    "the thermodynamics of information processing is a very active area of research .",
    "whereas central concepts in this field have been developed a while ago @xcite , more recently the fluctuation relation obtained by sagawa and ueda @xcite has shown that stochastic thermodynamics @xcite provides a convenient framework to study the relation between information and thermodynamics . moreover , ingenious experiments with small systems @xcite verifying second law inequalities that involve information have played an important role in triggering the recent avalanche of papers .",
    "these works deal with the derivation of fluctuation relations and second law inequalities @xcite and the study of specific models @xcite .    in finite - time thermodynamics",
    "the issue of optimal protocols is of central importance .",
    "a recent result within stochastic thermodynamics has been the observation that the optimal protocol has discontinuities at the beginning and end of the finite - time process @xcite . in information processing ,",
    "optimal protocols have so far been analyzed for the maximal work extraction in a feedback driven system described by an one - dimensional over - damped langevin equation @xcite and for the minimum dissipated heat in an erasure process @xcite .    in this paper",
    "we study a paradigmatic discrete two - state model @xcite , where the work extraction , performed by lifting and lowering one energy level , is driven by feedback . besides applying the optimal protocol leading to the maximal work during one period",
    ", this information machine will also be optimized in the sense that the protocol takes the whole history of measurements into account .",
    "we show that this optimized feedback strategy leads to more work extraction in comparison to a simple memory - less machine .",
    "moreover , we observe a phase transition , where in one phase the machine always lifts the state indicated by the last measurement as empty and in the other phase the state measured as occupied is lifted with a certain frequency .",
    "the extracted work is observed to be bounded by two quantities : the familiar mutual information between system and controller and the change of the entropy of the system .",
    "while the second bound is valid for every measurement trajectory , the first becomes valid only after an average over measurement trajectories is taken . finally , we show that the memory - less model allows for a different physical interpretation of the system interacting with a tape , i.e. , a sequence of bits .",
    "this memory - less model then corresponds to a generalization of the model recently introduced in @xcite ( see also @xcite ) .",
    "the paper is organized as follows . in sec .",
    "[ sec2 ] we obtain the optimal protocol for a single period .",
    "the full feedback driven models are defined in sec .",
    "[ sec3 ] . the phase transition and gain parameter for the optimized model",
    "are studied in sec .",
    "[ sec4 ] . in sec .",
    "[ sec5 ] the different second law inequalities valid for the model are analyzed .",
    "we conclude in sec .",
    "the model analyzed in this paper is a two - state system where the time dependent energy of the upper level @xmath0 can be controlled by an external protocol in the time interval @xmath1 .",
    "the lower level has always energy zero .",
    "this system is connected to a heat bath at temperature @xmath2 and a work reservoir .",
    "we consider a finite - time process with duration @xmath3 , where both energy levels are zero immediately before starting @xmath4 and immediately after finishing @xmath5 , see fig .",
    "these initial and final jumps of @xmath6 are a generic feature of optimal protocols @xcite .    , the entropy of the system is @xmath7 . at @xmath8 the level with lower probability @xmath9",
    "is lifted . for @xmath10 this energy level is lowered with protocol @xmath6 . at time @xmath11",
    "this energy level is set from @xmath12 back to @xmath13 extracting work @xmath12 if this level had been occupied at @xmath14 . ]    denoting the occupation probability of the upper level by @xmath15 , the time derivative of the average internal energy reads @xmath16 where the dot represents a time derivative throughout the paper .",
    "this is the first law of thermodynamics , where @xmath17 is identified as the rate of extracted work and @xmath18 as the rate of absorbed heat .",
    "this identification means that if a jump occurs heat is exchanged with the heat bath and if the energy level changes work is exchanged with the work reservoir .",
    "the extracted work in the time interval @xmath3 then becomes @xmath19 where the boundary terms comes from the discontinuities in @xmath6 represented in fig .",
    "since the variation of the internal energy is zero , the extracted work equals the heat absorbed from the heat bath , i.e. , @xmath20 even though the system is connected to a single heat bath and the variation of the internal energy is zero , it is still possible to extract work due to the increase in the entropy of the system .",
    "more precisely , the second law for such isothermal process establishes that the extracted work is bounded by the change of the entropy of the system , i.e. , @xmath21 , \\label{secondh}\\ ] ] where @xmath22 . in this paper",
    "we set @xmath23 and , in order to have work extraction , we restrict to the case @xmath24 .",
    "the optimal protocol @xmath6 that leads to the maximal work extraction for given time interval @xmath3 and initial occupation probability @xmath25 is calculated in the remaining of this section .",
    "the master equation reads @xmath26 , \\label{eq : masterequation}\\ ] ] where @xmath27 ( @xmath28 ) is the time dependent transition rate to ( from ) the upper level .",
    "these rates must fulfill the detailed balance relation @xmath29 . for convenience ,",
    "we choose @xmath30 following the analysis for a symmetric choice of rates @xcite , the optimal protocol and the corresponding maximal extracted work is found by considering the lagrangian @xmath31 where the work is then written as @xmath32 since @xmath33 does not explicitly depend on @xmath34 , we have the following constant of motion , @xmath35 introducing the variable @xmath36 , equation ( [ eq : k_def ] ) becomes @xmath37 the solution of this equation is @xmath38 where @xmath39 is the lower branch of product logarithm @xcite . using relations @xmath40 , @xmath41 $ ] , and ( [ eq : dglq ] ) , the extracted work ( [ eq : work_int ] ) becomes a function of the single variable @xmath42 .",
    "the maximal work is then obtained for @xmath43 , where @xmath44 . in this way , @xmath45 is given by the solution of the transcendental equation @xmath46 + 1\\right)-f_t(a)=\\frac{a(a-1)}{p_0}. \\label{transc}\\ ] ]    for convenience the optimal protocol and corresponding maximal work are simply denoted by @xmath47 and @xmath48 , respectively . from ( [ eq : work_int ] ) the maximal work that can be extracted for fixed @xmath3 and @xmath25 is @xmath49}{1-p_0}\\right)+p_0\\left[\\ln\\left(\\frac{p_0a}{(1-p_0)(a-1)}\\right ) + a^{-1 } \\right ] , \\label{maxwork}\\ ] ] and the corresponding optimal protocol reads @xmath50 where @xmath45 is given by the solution of equation ( [ transc ] ) . in fig .",
    "[ fig2 ] , we plot the maximal work , the power and the discontinuities of the optimal protocol as a function of @xmath25 for given @xmath3 .",
    "the optimal work is a decreasing function of @xmath25 , with full knowledge of the initial state leading to the maximal work extraction for fixed @xmath3 . by increasing @xmath3 ,",
    "the work increases whereas the power @xmath51 decreases , going to zero in the limit @xmath52 .",
    "the initial and final energy jumps decrease with @xmath25 , being maximal for @xmath53 .",
    "the initial jump @xmath54 increases with @xmath3 , while the final jump @xmath55 decreases with @xmath3 .",
    "more precisely , for @xmath56 we have @xmath57 and the difference between the jumps grows with @xmath3 , with @xmath54 reaching its maximal value and @xmath58 for @xmath52 .    finally it is useful for the following discussion to give @xmath59 for the optimal protocol explicitly as @xmath60 .",
    "\\label{pt}\\ ] ]     for different values of @xmath3 on the left , with the power @xmath51 plotted in the inset .",
    "the initial energy jump @xmath54 and the final energy jump @xmath55 in the inset are plotted on the right.,scaledwidth=99.0% ]",
    "an information driven machine periodically repeats the process explained in the previous section using feedback control .",
    "measurements and feedback drive the work extraction by resetting the entropy of the system at the end of the time interval .",
    "we denote the state of the system just before starting period @xmath61 by @xmath62 and the measurement by @xmath63 , where @xmath64 ( @xmath65 ) means that the left ( right ) state is occupied while @xmath66 ( @xmath67 ) corresponds to measuring the left ( right ) state as being occupied .",
    "the conditional probability of the measurement is defined as @xmath68 where @xmath69 is the measurement error .",
    "the machine never knows the real state of the system @xmath62 and has access only to the history of measurements @xmath70 .",
    "hence , in all calculations that follow the state of the system is always averaged out .",
    "first we consider a feedback procedure with a protocol taking the whole measurement trajectory @xmath70 into account .",
    "we are interested in the probability of being at state @xmath62 given the history of measurements @xmath71 , which is denoted @xmath72 . for this feedback scheme",
    "the initial occupation probability of the level that will be raised at the beginning of period @xmath61 is @xmath73 this means that contrary to the naive procedure of lifting the level @xmath74 independent of the measurement history it is also possible to make the unusual choice of lifting the level @xmath63 . in this second case ,",
    "the level indicated by the last measurement as occupied is lifted : the measurement is judged to be not reliable .",
    "moreover , the machine applies the protocol @xmath75 , which takes into account the whole history of measurements by using the history dependent initial probability @xmath76 .    in [ appa ]",
    "we show that the initial probability @xmath76 fulfills a nonlinear recursion relation .",
    "denoting by @xmath77 the probability at the end of the period @xmath78 that is obtained from the function ( [ pt ] ) with initial probability @xmath79 , we define the functions @xmath80 and @xmath81 where @xmath82 the recursion relation for @xmath76 then reads @xmath83 as explained in [ appa ] , the variable @xmath84 has the purpose of identifying whether the measurement outcome @xmath63 corresponds to the upper or the lower level of the interval @xmath78 , with @xmath85 if the upper level is @xmath63 and @xmath86 if the lower level is @xmath63 .",
    "we call this machine taking the history of measurements @xmath71 into account the optimized machine because , as we will see in sec .",
    "[ sec4 ] , it leads to more work extraction then a simple memory - less machine which we define next .",
    "a memory - less feedback scheme that only takes the last measurement into account would be to simply apply a protocol for which the level raised for the next period is just the state measured as empty .",
    "hence , for a measurement outcome @xmath63 , the level @xmath74 is lifted at the beginning of period @xmath61 .",
    "as we show in [ appb ] , where the memory - less machine is more explicitly defined , the average initial occupation probability of the upper level is @xmath69 , independent of the protocol .",
    "therefore , the appropriate choice for a protocol that must be independent from the whole measurement history and corresponds to the memory - less version of the optimized machine is @xmath87 , which is obtained from ( [ protopt ] ) with @xmath88 .",
    "the work extracted during period @xmath61 with the optimized machine is denoted by @xmath89 . for a given measurement realization",
    "@xmath90 we define @xmath91 the average work @xmath92 is obtained by considering the limit @xmath93 and averaging over all measurement trajectories , where the brackets denote this average over measurement trajectories .",
    "numerical simulations for large enough @xmath94 indicate that @xmath95 ( and other observables we calculate below ) is independent of the numerically generated measurement history , i.e. , self - averaging .",
    "therefore , we calculate the average work by generating a single long measurement history .    for the memory - less machine",
    "the average work is just @xmath96 , as demonstrated in [ appb ] .",
    "the improvement of the optimized in relation to the memory - less machine is quantified by the gain parameter @xmath97 naively one expects the optimized machine that takes the history of measurements into account to extract more work than the simple machine .",
    "this expectation is confirmed by numerical simulations , from which we observe that @xmath98 . for @xmath99",
    "the work extraction in the memory - less model would be the same as in the optimized model and for @xmath100 the work extraction is much higher with the optimized model . in fig .",
    "[ fig3 ] , we plot @xmath101 in the @xmath102-plane .",
    "the gain approaches @xmath103 for small @xmath3 and @xmath69 close to @xmath104 , where non - reliable measurements are more likely to occur .",
    "( left ) and the order parameter @xmath105 ( right ) as functions of the time interval @xmath3 and the measurement error @xmath69 .",
    "the results are obtained by numerically generating a measurement trajectory of length @xmath106 .",
    "the full black critical line is obtained analytically from ( [ eqcrit ] ) and the dotted line on the right panel from ( [ eqdot ] ) . ]",
    "it turns out that the optimized model displays a phase transition .",
    "the order parameter for this transition @xmath105 is the frequency at which the state @xmath63 is lifted , i.e. , @xmath107 where @xmath108 if the measurement is not reliable and @xmath109 if the measurement is reliable ( see [ appa ] for a precise definition ) .",
    "the numerical calculation of this order parameter is also shown in fig . [ fig3 ] .",
    "we can clearly see a phase transition with @xmath110 below a critical threshold @xmath111 .",
    "numerics indicates a second order phase transition .",
    "the optimized machine has two advantages in relation to the memory - less machine : it lifts the level @xmath63 if the last measurement is not reliable and it uses a history dependent protocol @xmath75 . by comparing @xmath101 with @xmath105 in fig .",
    "[ fig3 ] , we see that in the phase @xmath112 there is a substantial gain .",
    "this means that the first advantage is the key feature leading to more work extraction for the optimized feedback scheme .",
    "moreover , as shown in [ appa ] , in the phase @xmath113 the average initial occupation probability is @xmath69 .",
    "hence , @xmath114 in this phase arises from the fact that the function @xmath48 plotted in fig .",
    "[ fig2 ] is convex , implying @xmath115 , where the average @xmath116 is defined in ( [ defavgi ] ) .",
    "as we show in [ appc ] , the critical line @xmath111 can be obtained analytically from the transcendental equation ( [ eqcrit ] ) .",
    "it is in perfect agreement with numerical results , as shown in fig .",
    "the second law for feedback driven systems @xcite states that the average extracted work is bounded by the average mutual information between system and controller due to measurements .",
    "the mutual information between the system and the controller due to the measurement @xmath63 is defined as @xmath117 we denote the average mutual information by @xmath118 , so that the efficiency of the optimal machine reads @xmath119     and the average power @xmath120 as functions of the time interval @xmath3 and the measurement error @xmath69 .",
    "the results are obtained by numerically generating a measurement trajectory of length @xmath106 . ]    in fig .",
    "[ fig6 ] we show the numerically calculated efficiency @xmath121 and power @xmath120 for the optimized model in the @xmath102-plane .",
    "increasing the time period @xmath3 increases the efficiency but decreases the power of the machine . for fixed @xmath3 ,",
    "the efficiency increases for increasing measurement error @xmath69 .",
    "hence , maximum power is obtained for small @xmath69 and small @xmath3 , which is , however , a rather inefficient case with @xmath122 .",
    "another bound on the extracted work is provided by the shannon entropy change , as expressed in ( [ secondh ] ) , which for the optimized model can be written as @xmath123 where the shannon entropy change in interval @xmath61 is @xmath124 the inequality ( [ boundw ] ) is then valid for a fixed measurement trajectory , whereas the standard second law for feedback driven systems @xmath125 is valid only after an average over measurement trajectories is taken . by numerical inspection we observe that @xmath126 ( or @xmath127 ) can be smaller than @xmath128 .",
    "furthermore , by taking the average for large @xmath94 we find @xmath129 within numerical errors .",
    "this equality can be demonstrated with the following heuristic argument .",
    "rearranging the terms in the mutual information we get @xmath130 where the average @xmath131 is defined in ( [ defavgi ] ) . from this equation",
    "it is clear that the average mutual information and the average shannon entropy change differ only by boundary terms , which for large @xmath94 should be irrelevant , implying @xmath129 .      as in [ appb",
    "] we now consider a memory - less machine using an arbitrary protocol @xmath132 .",
    "equation ( [ iedh ] ) is also valid for the memory - less case and , therefore , the average shannon entropy change should be equal to the average mutual information for large @xmath94 .",
    "this result was confirmed numerically for the protocol @xmath133 and for @xmath134 , which corresponds to the energy level held fixed during the whole time interval .",
    "similar to ( [ mutuopt ] ) , the mutual information depending on @xmath135 reads @xmath136 where @xmath137 is defined in ( [ qtilde ] ) .",
    "denoting by @xmath138 the solution of the master equation ( [ eq : masterequation ] ) with protocol @xmath132 and initial probability @xmath69 we define @xmath139 where @xmath140 .",
    "since @xmath141 ( and @xmath142 ) is linear in @xmath143 , it follows that @xmath144 , where the average @xmath145 is defined in ( [ avgdum ] ) . from the fact that the shannon entropy is concave we obtain that @xmath146 provides an upper bound on the average mutual information @xmath147    as the average extracted work is equal to the work extracted in the first period ( see [ appb ] ) ,",
    "if before the first measurement both states are equally probable , the average extracted work is also bounded by the shannon entropy change in the first period @xmath148 comparing with the other bounds we have @xmath149 and , numerically , for the protocols @xmath133 and @xmath134 , we observe @xmath150 . we conjecture that this entropy change provides the strongest bound on the extracted work .",
    "the inequality @xmath151 for the protocol @xmath134 has been recently studied in @xcite . in this reference",
    "it has been shown that the two - state model can also be interpreted as a tape , i.e. , a sequence of bits , interacting with a thermodynamic system . in this interpretation",
    "the entropy change is dumped to a tape or information reservoir .",
    "the inequality ( [ inegen ] ) means that the extracted work is bounded by the shannon entropy change of the tape , which is initially @xmath152 and becomes @xmath153 after the system has written information to it .",
    "this model for a tape interacting with a thermodynamic system has been introduced by mandal and jarzynski @xcite , for a model with six instead of two states and a protocol that is also held fixed during the whole time interval . by showing that inequality ( [ inegen ] )",
    "is valid also for arbitrary @xmath132 protocols , we thus obtain that their model can be generalized to arbitrary time - dependent protocols .",
    "we have studied a two - state finite - time optimized information - driven machine .",
    "besides utilizing the optimal protocol , this machine is also optimized in the sense that the feedback scheme takes into account the whole history of measurements .",
    "we have shown that the optimized machine leads to more work extraction in comparison to a simple memory - less machine that does not take the full measurement trajectory into account .",
    "this optimized model displays a phase transition with the frequency at which non - reliable measurements occur being the order parameter . in the region of the phase diagram where non - reliable measurements occur with a higher frequency the gain parameter , characterizing the improvement of the optimized in relation to the memory - less machine ,",
    "was found to be high .",
    "hence the possibility of lifting the state last measured as occupied if the measurement is non - reliable is the key feature that makes the optimized model perform better .",
    "moreover , analyzing the recursion relations for the initial occupation probability of the upper level we have obtained the critical line exactly .",
    "we have shown that the work extraction is bounded both by the shannon entropy change and the mutual information .",
    "while the first bound is valid for every measurement trajectory the second is valid only after averaging over the measurements . in this case , both bounds become the same .",
    "moreover , for the memory - less model we have demonstrated that the average extracted work is bounded by the shannon entropy change of the first period .",
    "this inequality allows for an interpretation of the model as a thermodynamic system interacting with a tape , thus generalizing the model introduced in @xcite .",
    "in this appendix , we obtain the nonlinear recursive relation for the initial occupation probability of the upper level of the optimized machine ( [ recursion ] ) . from relations",
    "@xmath154 and @xmath155 we obtain @xmath156 , \\label{errorh}\\end{aligned}\\ ] ] where we used the definition of measurement error ( [ error ] ) . using the relation @xmath157 the conditional probability @xmath72",
    "can then be written as @xmath158 } & \\quad \\textrm{if $ x_i = m_i$ } , \\\\",
    "\\frac{\\epsilon[1-p(x_i = m_i|m_1^{i-1})]}{p(x_i = m_i|m_1^{i-1})+\\epsilon[1 - 2p(x_i = m_i|m_1^{i-1 } ) ] } & \\quad \\textrm{if $ x_i =- m_i$}.   \\end{array}\\right.\\ , \\label{choicehistory}\\ ] ] depending on the past measurements the probability @xmath159 on the right side of this equation is either @xmath77 or @xmath160 , where @xmath77 is obtained from @xmath79 and equation ( [ pt ] ) . from equation ( [ defp0i ] ) , the state indicated by the measurement as occupied @xmath63 is lifted provided @xmath161 , which from ( [ choicehistory ] ) is equivalent to @xmath162 .",
    "since @xmath163 , a necessary condition for lifting the state @xmath63 at the beginning of period @xmath61 is that @xmath164 .",
    "it is convenient to define the variables @xmath165 , for @xmath166 , and @xmath167 , which takes the value @xmath103 ( @xmath168 ) if the level @xmath74 ( @xmath63 ) is lifted at the beginning of period @xmath61 , i.e. , @xmath169 furthermore , we define @xmath170 .",
    "this last variable identifies whether for given @xmath63 the probability @xmath159 is @xmath77 or @xmath160 : @xmath171 in words , this equation means that if @xmath86 ( @xmath85 ) then @xmath63 corresponds to the lower ( upper ) level of period @xmath78 .    for the initial condition before the first period we assume that the states are equally probable , hence , @xmath172 and @xmath173 .",
    "numerical simulations of the measurement trajectory are then performed with the following algorithm :    1 .   for period @xmath61",
    "randomly choose a measurement according to the probability @xmath174 given by equations ( [ errorh ] ) and ( [ pmx ] ) ; 2 .   with @xmath77 ,",
    "the variable @xmath84 , and equations ( [ defp0i ] ) , ( [ choicehistory ] ) and ( [ pmx ] ) calculate @xmath167 and @xmath76 ; 3 .   from relation ( [ pt ] ) and @xmath76 calculate @xmath175 .",
    "go back to the first step with the substitution @xmath176 .",
    "this algorithm can be translated into a recursion relation for the initial probability . using ( [ choicehistory ] ) and ( [ pmx ] ) , relation ( [ defp0i ] )",
    "becomes @xmath177 where @xmath80 and @xmath81 with @xmath178 .",
    "note that the function @xmath179 is minimal when @xmath180 , which implies @xmath181 . only in this case",
    ", the state measured as occupied @xmath63 can be lifted at the beginning of period @xmath61",
    ".    moreover , from ( [ errorh ] ) , ( [ pmx ] ) , and ( [ iteapp ] ) , the average initial occupation probability conditioned on @xmath135 is @xmath182 if the machine never lifts the level @xmath63 , i.e. , @xmath180 for all periods , the above average becomes @xmath183 .",
    "for the memory - less machine we denote the initial occupation probability at period @xmath61 by @xmath143 .",
    "the final occupation probability at period @xmath61 is @xmath142 : as the memory - less machine does not use the optimal protocol , @xmath142 is not obtained from ( [ pt ] ) but rather it is the solution of the master equation ( [ eq : masterequation ] ) for a given protocol @xmath132 and initial condition @xmath143 .",
    "another difference in relation to the optimized model considered in [ appa ] is that the variable @xmath167 is not necessary for the memory - less machine , since here @xmath109 for all @xmath61 .",
    "hence , for the memory - less machine , equation ( [ pmx ] ) becomes @xmath184 the iterative relation ( [ iteapp ] ) then simplifies to @xmath185 where @xmath186 and @xmath187 with @xmath188    similar to ( [ defavgi ] ) , the average initial probability for fixed measurement history is @xmath189 we denote by @xmath190 the work that is obtained from ( [ eq : work_in ] ) with protocol @xmath132 and initial probability @xmath143 .",
    "the average work is then given by @xmath191 where in the first equality we used the fact that @xmath190 is linear in @xmath143 . since , @xmath192 is independent of the history @xmath135 , it follows that the average work is simply @xmath192 . for the memory - less machine",
    "we compare with the optimized one @xmath193 , which is given by ( [ protopt ] ) , and the average work is @xmath96 , which is given by ( [ maxwork ] ) .",
    "moreover , assuming that before the first measurement both states are equally probable , which leads to @xmath194 , the average work equals the work extracted in the first period .",
    "we now obtain the critical line exactly by analyzing the iterative relation for @xmath76 ( [ recursion ] ) .",
    "as discussed in [ appa ] , the level @xmath63 will be lifted at the beginning of interval @xmath61 only if @xmath180 .",
    "hence , in the phase @xmath113 the condition @xmath195 must be fulfilled .",
    "the fixed points of these nonlinear maps are obtained from @xmath196 and @xmath197 .",
    "the possible trajectories in the cobweb diagram for the first five iterations of relation ( [ recursion ] ) are shown in fig .",
    "it is clear that @xmath76 does not go below the fixed point @xmath198 .",
    "therefore , the critical line @xmath111 can be obtained analytically by setting @xmath199 which leads to a cumbersome transcendental equation . solving this equation we obtain the full black line in fig [ fig3 ] , in perfect agreement with the numerical simulations .",
    ", of the relation ( [ recursion ] ) . in the left panel @xmath200 and @xmath201 , in the central panel @xmath202 and @xmath203 , and in the right panel @xmath204 and @xmath203 .",
    "for the first two cases @xmath113 , whereas in the third case @xmath112 . ]    moreover , the phase @xmath205 can be further separated by two distinct regions , where the line ( dotted line in fig .",
    "[ fig3 ] ) separating these two regions is obtained from @xmath206 in the region closer to the critical line with @xmath207 the machine does not lift the state measured as occupied because @xmath208 is not small enough , i.e. , @xmath209 ( see fig . [ fig4 ] ) . however , in this region depending on the initial condition the machine might lift the state measured as occupied during some initial transient .",
    "10 url # 1#1urlprefix[2][]#2 szilard l , 1929 _ z. phys .",
    "_ http://dx.doi.org/10.1007/bf01341281[*53 * 840  856 ]"
  ],
  "abstract_text": [
    "<S> we analyze a periodic optimal finite - time two - state information - driven machine that extracts work from a single heat bath exploring imperfect measurements . </S>",
    "<S> two models are considered , a memory - less one that ignores past measurements and an optimized model for which the feedback scheme consists of a protocol depending on the whole history of measurements . </S>",
    "<S> depending on the precision of the measurement and on the period length the optimized model displays a phase transition to a phase where measurements are judged as non - reliable . </S>",
    "<S> we obtain the critical line exactly and show that the optimized model leads to more work extraction in comparison to the memory - less model , with the gain parameter being larger in the region where the frequency of non - reliable measurements is higher . </S>",
    "<S> we also demonstrate that the model has two second law inequalities , with the extracted work being bounded by the change of the entropy of the system and by the mutual information .    </S>",
    "<S> i d </S>"
  ]
}