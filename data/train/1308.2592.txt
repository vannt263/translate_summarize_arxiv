{
  "article_text": [
    "compressed sensing has recently been a focus of intensive researches in the signal processing community .",
    "it aims at reconstructing a signal by assuming that the original signal is sparse @xcite .",
    "the core idea used in this area is to introduce a sparsity index in the optimization .",
    "the sparsity index of a vector @xmath1 is defined by the amount of nonzero elements in @xmath1 and is usually denoted by @xmath2 , called the `` @xmath3 norm . '' the compressed sensing decoding problem is then formulated by least squares with @xmath3-norm regularization .",
    "the associated optimization problem is however hard to solve , since it is a combinatorial one .",
    "thus , it is common to introduce a convex relaxation by replacing the @xmath3 norm with the @xmath4 norm @xcite . under some assumptions ,",
    "the solution of this relaxed optimization is known to be exactly the same as that of the @xmath3-norm regularization @xcite .",
    "that is , by minimizing the @xmath4-regularized least squares , or by _",
    "@xmath0 optimization _",
    ", one can obtain a sparse solution .",
    "moreover , recent studies have examined fast algorithms for @xmath0 optimization @xcite .",
    "the purpose of this paper is to investigate the use of sparsity - inducing techniques for remote control @xcite , see @xcite for an alternative approach . in remote - controlled systems ,",
    "control information is transmitted through bandwidth - limited channels such as wireless channels @xcite or the internet @xcite .",
    "there are two approaches to reduce the number of bits transmitted on a wireless link , _ source coding _ and _ channel coding _ approaches @xcite . in the former ,",
    "information compression techniques reduce the number of bits to be transmitted . in the latter , efficient forward error - correcting codes",
    "reduce redundant data ( i.e. , parity ) in channel - coded information . in this paper , we study the former approach and propose a sparsity - inducing technique to produce sparse representation of control commands , which can reduce the number of bits in transmitted data .",
    "our optimization to obtain sparse representation of control commands is formulated as follows : we measure the tracking error in the output trajectory of a controlled system by its @xmath5 norm , and add an @xmath4 penalty to achieve sparsity of transmitted vector .",
    "this is an @xmath4-regularized @xmath5-optimization , or shortly @xmath0-optimization , which is effectively solved by the iterative shrinkage method mentioned above .",
    "the problem of command generator has been solved when the penalty is taken solely as an @xmath5 norm , the solution of which is given by a linear combination of base functions , called control theoretic splines @xcite . in this work , we also present a simple method for achieving sparse control vectors when the control commands are assumed to be in a subspace of these splines .",
    "an example illustrates the effectiveness of our method compared with the @xmath5 optimization .      for a vector @xmath6^\\top\\in{{\\mathbb{r}}}^n$ ] , the @xmath4 and @xmath5 norms are respectively defined by @xmath7 and @xmath8 . for a real number @xmath9 , @xmath10",
    "we denote the determinant of a square matrix @xmath11 by @xmath12 , and the maximum eigenvalue of a symmetric matrix @xmath11 by @xmath13 .",
    "let @xmath14 $ ] be the set of lebesgue square integrable functions on @xmath15 $ ] . for @xmath16 $ ] ,",
    "the inner product is defined by @xmath17",
    "let us consider the following linear siso ( single - input single - output ) plant : @xmath18 where @xmath19 , @xmath20 and @xmath21 .",
    "we assume that the system @xmath22 is stable and the state space realization ( [ eq : system ] ) is reachable and observable .",
    "the output reference signal is given by data points @xmath23 , where @xmath24 s are time instants such that @xmath25 .",
    "our objective here is to design the control signal @xmath26 such that the output trajectory @xmath27 is close to the data points @xmath28,  ,@xmath29 at @xmath30 , that is , @xmath31 , @xmath32 . to measure the difference between @xmath33 and @xmath34",
    ", we adopt the square - error cost function @xmath35 where we have made the dependence of @xmath36 on @xmath37}$ ] through the system equation ( [ eq : system ] ) .    in principle",
    ", one can achieve perfect tracking , that is , @xmath38 , by some input signal ) and ( [ eq : theta2 ] ) in section [ sec : l2 ] , with @xmath39 . ] .",
    "however , the optimal input for perfect tracking has very large gain especially when the number @xmath40 is very large , and may lead to oscillation between the sampling instants @xmath41 .",
    "this phenomenon is known as overfitting @xcite . to avoid this",
    ", one can adopt a _ regularization _ or _ smoothing _ technique .",
    "this method is to add a regularization term @xmath42 to the cost function @xmath43 .",
    "we formulate our problem as follows :    given data @xmath44 , find a control signal @xmath45 which minimizes the regularized cost function @xmath46 , where @xmath47 is the regularization parameter which specifies the tradeoff between minimization @xmath43 and the smoothness by @xmath42 .",
    "a well - known regularization is to use @xmath48 function for @xmath42 , called the _",
    "control theoretic smoothing spline _",
    "we review this in the next section .",
    "for the problem given in section [ sec : prob ] , the following @xmath48-regularized cost function was considered in @xcite : @xmath49 the optimal control @xmath50 which minimizes @xmath51 is given by a linear combination of the following functions called control theoretic splines @xcite :    0.1 in    ( 31.0000 , 11.2000 ) ( 1.3400,-11.2000 ) ( 11.5400,-10.0000)(0,0)[lt]@xmath24(16.3400,-6.8000)(0,0)[lb]@xmath52(5.2200,-2.8800)(0,0)[lb](3.1400,-10.0000)(0,0)[rt]@xmath53    @xmath54    see fig .",
    "[ fig : base_function ] .",
    "more precisely , the optimal control for ( [ eq : j2 ] ) is given by @xmath55 where @xmath56^\\top$ ] , @xmath57^\\top$ ] , and @xmath58 is the grammian matrix of @xmath59 , defined by @xmath60_{ij}:={\\langle g_i , g_j \\rangle}$ ] , @xmath61 .",
    "0.1 in    ( 30.1500 , 4.8000 ) ( 3.0000 , -6.0000 )    ( 11.0000,-4.0000)(0,0)@xmath62(3.0000,-3.5000)(0,0)[lb]@xmath63(17.0000,-3.5000)(0,0)[lb]@xmath64(24.4000,-3.5000)(0,0)[lb]@xmath65(32.6500,-3.5000)(0,0)[lb]@xmath66(22.0500,-4.0000)(0,0)@xmath67(28.1500,-4.0000)(0,0)@xmath22",
    "in remote - controlled systems , we transmit the control input @xmath37}$ ] to the system @xmath22 through a communication channel .",
    "since @xmath68}$ ] is a continuous - time signal , we should discretize it .",
    "an easy way to communicate information on the input signal is to transmit the data @xmath63 itself , and produce the input @xmath26 by the formulae ( [ eq : optimal_u2 ] ) and ( [ eq : theta2 ] ) at the receiver side .",
    "the vector @xmath63 is just an @xmath40-dimensional one , and much easier to transmit than the infinite - dimensional vector @xmath68}$ ] .",
    "an alternative method consists in transmitting the coefficient vector @xmath64 given in ( [ eq : theta2 ] ) instead of the continuous - time signal @xmath45 .",
    "this procedure is shown in fig .",
    "[ fig : rc_system ] . in this procedure",
    ", we fix the sampling instants @xmath41 and the vector @xmath63 is given .",
    "we first compute the parameter vector @xmath64 by ( [ eq : theta2 ] ) , and transmit this through a communication channel .",
    "the transmitted vector is received at the receiver , and then the control signal @xmath69 is computed by ( [ eq : optimal_u2 ] ) , and applied to the plant @xmath22 .",
    "we assume that the time instants @xmath41 are shared at the transmitter and the receiver .",
    "a problem of the above - mentioned strategies is that the communication channel is band - limited and therefore the vector to be transmitted has to be first quantized and encoded . to solve this",
    ", we will seek a _ sparse representation _ of the transmitted vector @xmath70 in accordance with the notion of compressed sensing @xcite .",
    "define a subspace @xmath71 of @xmath14 $ ] by @xmath72 : u = \\sum_{j=1}^m \\theta_j \\phi_j,~ \\theta_i \\in { { \\mathbb{r}}}\\right\\ } ,   \\label{eq : vm}\\ ] ] where @xmath73 are linearly independent vectors in @xmath14 $ ] .",
    "note that if @xmath74 and @xmath75 , @xmath76 defined in ( [ eq : gi ] ) , the optimal control @xmath69 in ( [ eq : optimal_u2 ] ) belongs to this subspace are linearly independent @xcite . ] .",
    "we assume that the control @xmath45 is in @xmath71 , that is , we find a control @xmath45 in this subset . under this assumption ,",
    "the squared - error cost function @xmath43 is represented by @xmath77 where @xmath78_{ij}={\\langle g_i , \\phi_j \\rangle}$ ] , @xmath76 , @xmath79 . to induce sparsity in @xmath70",
    ", we adopt @xmath4 penalty on @xmath70 and introduce the following mixed @xmath0 cost function : @xmath80 note that if @xmath81 for @xmath79 , then the cost function ( [ eq : j1 ] ) is an upper bound of the following @xmath82-@xmath48 cost function : @xmath83    as mentioned in the introduction , the @xmath4-regularized least - squares optimization is a good approximation to one regularized by the @xmath3 norm which counts the nonzero elements in @xmath70 .",
    "although the solution which minimizes @xmath84 can not be represented analytically as in ( [ eq : optimal_u2 ] ) , we can compute an approximated solution by using a fast numerical algorithm .",
    "the algorithm is described in the next section . by using this solution ,",
    "say @xmath85 , the optimal control @xmath86 can be obtained from @xmath87.\\ ] ]",
    "we here describe a fast algorithm for obtaining the optimal vector @xmath85 .",
    "first , we consider a general case of optimization .",
    "next , we simplify the design procedure in a special case .",
    "the cost function ( [ eq : j1 ] ) is convex in @xmath88 and hence the optimal value @xmath85 uniquely exists .",
    "however , an analytical expression as in ( [ eq : theta2 ] ) for this optimal vector is unknown except when the matrix @xmath89 is unitary . to obtain the optimal vector @xmath85",
    ", one can use an iteration method .",
    "recently , a very fast algorithm for the optimal @xmath0 solution has been proposed , which is called _ iterative shrinkage _",
    "@xcite .",
    "this algorithm is given by the following : give an initial value @xmath90\\in{{\\mathbb{r}}}^m$ ] , and let @xmath91=1 $ ] , @xmath92={{\\boldsymbol{\\theta}}}[0]$ ] .",
    "fix a constant @xmath93 such that @xmath94 .",
    "execute the following iteration : @xmath95 & = { \\mathcal{s}}_{\\kappa / c}\\left(\\frac{1}{c}\\phi^\\top({{{\\boldsymbol{y}}}_{\\text{ref}}}-\\phi{{\\boldsymbol{\\theta}}}'[j])+{{\\boldsymbol{\\theta}}}'[j]\\right),\\\\    \\beta[j+1 ] & = \\frac{1+\\sqrt{1 + 4\\beta[j]^2}}{2},\\\\    { { \\boldsymbol{\\theta}}}'[j+1 ] & = { { \\boldsymbol{\\theta}}}[j ] + \\frac{\\beta[j]-1}{\\beta[j+1]}({{\\boldsymbol{\\theta}}}[j ] - { { \\boldsymbol{\\theta}}}[j-1]),\\\\    j & = 1,2,\\ldots ,   \\end{split } \\label{eq : fista}\\ ] ] where the function @xmath96 is defined for @xmath97^\\top$ ] by @xmath98 the nonlinear function @xmath99 in @xmath96 is shown in fig .",
    "[ fig : nonlinear ] .    0.1 in    ( 24.8000 , 20.4000 ) ( -0.8000,-20.0000 )    ( 14.5000,-10.5000)(0,0)[lt]@xmath53(18.5000,-10.5000)(0,0)[lt]@xmath100(10.0000,-9.5000)(0,0)[rb]@xmath101(24.0000,-9.5000)(0,0)[lb]@xmath88    if @xmath102 , the above algorithm converges to the optimal solution minimizing the @xmath0 cost function ( [ eq : j1 ] ) for any initial value @xmath90\\in{{\\mathbb{r}}}^{m}$ ] with a worst - case convergence rate @xmath103 @xcite .",
    "the above algorithm is very simple and fast ; it can be effectively implemented in digital devices , which leads to a real - time computation of a sparse vector @xmath85 .    0.1 in    ( 30.1500 , 4.8000 ) ( 3.0000 , -6.0000 )    ( 11.0000,-4.0000)(0,0)fista(3.0000,-3.5000)(0,0)[lb]@xmath63(16.4000,-3.5000)(0,0)[lb]@xmath85(24.4000,-3.5000)(0,0)[lb]@xmath86(32.6500,-3.5000)(0,0)[lb]@xmath66(22.0500,-4.0000)(0,0)@xmath67(28.1500,-4.0000)(0,0)@xmath22      we here assume @xmath74 and @xmath75 , @xmath105 , that is , @xmath104 .",
    "since @xmath106 are linearly independent vectors in @xmath14 $ ] , the grammian matrix @xmath104 is non - singular .",
    "let the control input @xmath45 be @xmath107 and let @xmath108 .",
    "then , by ( [ eq : l2error ] ) we have @xmath109 consider the following @xmath0 cost function : @xmath110 the optimal solution @xmath111 minimizing this cost function is given analytically by @xmath112 then we transmit this optimal vector @xmath111 , and at the receiver we reconstruct the optimal control by @xmath113 . fig .",
    "[ fig : rc_system_1 ] shows the remote - controlled system with the optimizer @xmath111 .    0.1 in    ( 30.0000 , 4.2000 )",
    "( 5.0000 , -6.0000 )    ( 30.0000,-4.0000)(0,0)@xmath22(24.0000,-4.0000)(0,0)@xmath67(18.0000,-4.0000)(0,0)@xmath114(10.0000,-4.0000)(0,0)@xmath115(5.0000,-3.5000)(0,0)[lb]@xmath63(12.3000,-3.5000)(0,0)[lb]@xmath111(26.2500,-3.5000)(0,0)[lb]@xmath86(33.5000,-3.5000)(0,0)[lb]@xmath66    in this case , we compute ( [ eq : etas ] ) only one time , while in the general case considered in section [ subsec : sparse - general ] we should execute the iteration algorithm ( [ eq : fista ] ) .",
    "we here show an example of the sparse command generator .",
    "the state - space matrices of the controlled plant @xmath22 is assumed to be @xmath116 note that the transfer function of the plant @xmath22 is @xmath117 .",
    "the sampling instants are given by @xmath118 , @xmath119 , and the data @xmath120 is given by @xmath121 , that is , we try to track the sine function @xmath122 in one period @xmath123 $ ] .",
    "we assume the base functions @xmath124 in the subspace @xmath71 in ( [ eq : vm ] ) are the same as @xmath125 s , that is , we consider the case @xmath104 discussed in section [ subsec : special - case ] .",
    "we design three signals to be transmitted : the @xmath5-optimized vector @xmath64 in ( [ eq : theta2 ] ) , the sparse vector @xmath85 given in subsection [ subsec : sparse - general ] , and the sparse vector @xmath111 in ( [ eq : etas ] ) .",
    "we set the regularization parameters @xmath126 , @xmath127 , and @xmath128 , see equations ( [ eq : j2 ] ) , ( [ eq : j1 ] ) and ( [ eq : jzeta ] ) .    the obtained vectors are shown in table [ table : vectors ] .",
    "tbp    .designed vectors [ cols=\"^,^,^,^\",options=\"header \" , ]     -optimal @xmath129 ( dash ) , @xmath0-optimal @xmath130 ( solid ) , and simple @xmath0-optimal @xmath131 ( dash - dots ) . ]",
    "in this paper , we have proposed to use sparse representation for command generation in remote control by @xmath0 optimization .",
    "an example illustrates the effectiveness of the proposed method .",
    "future work may include the study of advantages of sparse representation in view of information theory .",
    "99 a. beck and m. teboulle , a fast iterative shrinkage - thresholding algorithm for linear inverse problems , _ siam j. imaging sciences _ , vol .  2 , no .  1 , 183/202 ( 2009 ) e. j. candes and m. b. wakin , an introduction to compressive sampling , _ ieee signal processing mag .",
    "_ , vol .  25 , 21/30 ( 2008 ) s. s. chen , d. l. donoho , and m. a. saunders , atomic decomposition by basis pursuit , _ siam journal on sci",
    "_ , vol .  20 , no .  1 ,",
    "pp .  3361 ( 1998 )",
    "t. m. cover and j. a. thomas , _ elements of information theory _ , 2nd edition , wiley ( 2006 ) i. daubechies , m. defrise , and c. de mol , an iterative thresholding algorithm for linear inverse problems with a sparsity constraint , _ communications on pure and applied mathematics _ , vol .",
    "57 , no .  11 , pp .  14131457 ( 2004 ) m. egerstedt and c.f .",
    "martin , _ control theoretic splines _ , princeton university press ( 2010 ) m. elad , _ sparse and redundant representations _ , springer ( 2010 ) m. elad and a. bruckstein , a generalized uncertainty principle and sparse representation in pairs of bases , _ ieee trans .",
    "theory _ , vol .",
    "48 , no .  9 , pp .",
    "25582567 ( 2002 ) r. c. luo and t. m. chen , development of a multibehavior - based mobile robot for remote supervisory control through the internet , _",
    "ieee / asme trans .",
    "_ , vol .  5 , no .  4 ( 2000 )",
    "m. nagahara and d. e. quevedo , sparse representation for packetized predictive networked control , _ ifac world congress _ ( 2011 ) ( to be presented ) c. sayers , _ remote control robotics _ , springer ( 1999 ) b. schlkopf and a. j. smola , _ learning with kernels _ , the mit press ( 2002 ) s. sun , m. b. egerstedt , and c. f. martin , control theoretic smoothing splines , _ ieee trans",
    ".  automat .",
    "_ vol .  45 , no .  12 , 2271/2279 ( 2000 ) a. f. t. winfield and o. e. holland , the application of wireless local area network technology to the control of mobile robots , _ microprocessors and microsystems _ , vol .",
    "23 , pp .",
    "597607 ( 2000 ) m. zibulevsky and m. elad , l1-l2 optimization in signal and image processing , _ ieee signal processing mag .",
    "_ , vol .  27 , 76/88 ( 2010 )"
  ],
  "abstract_text": [
    "<S> in this article , we consider remote - controlled systems , where the command generator and the controlled object are connected with a bandwidth - limited communication link . in the remote - controlled systems , </S>",
    "<S> efficient representation of control commands is one of the crucial issues because of the bandwidth limitations of the link . </S>",
    "<S> we propose a new representation method for control commands based on compressed sensing . in the proposed method , </S>",
    "<S> compressed sensing reduces the number of bits in each control signal by representing it as a sparse vector . </S>",
    "<S> the compressed sensing problem is solved by an @xmath0 optimization , which can be effectively implemented with an _ iterative shrinkage algorithm_. a design example also shows the effectiveness of the proposed method . </S>"
  ]
}