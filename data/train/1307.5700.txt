{
  "article_text": [
    "one of the key science projects of several next - generation radio telescopes is to explore the nature of the dynamic radio sky with ever increasing spectral and temporal resolution .",
    "the speed at which blind surveys for radio transients can be performed is on the increase as well , with multiple beams capable of scanning different parts of the sky in parallel .",
    "such surveys generate large amounts of data , in the order of gigabtyes per second , which makes the notion of saving all this incoming data for future processing unfeasible .",
    "real - time systems have to be employed to filter this data and only save segments containing potentially interesting events .",
    "such systems also offer the possibility of reacting to such events in real - time , possibly taking control of the telescope s monitoring system and perform tracking observations using a subset of the beams .",
    "the idea of triggering other telescopes operating across the entire electromagnetic spectrum and performing joint follow - up observations is also an attractive and realizable one .",
    "these concepts have been among the driving forces for several real - time transient detection prototypes , such as the gmrt digital backend which is implemented on standard , commercial , off - the - shelf components @xcite . due to the high computational requirement for blind transient surveys ,",
    "alternative hardware architectures are also being investigated , with significant focus on graphics processing units ( gpus ) , which are the main components of several prototypes being developed , such as the ones at the parkes radio telescope @xcite and low frequency array ( lofar ) single stations @xcite . in this work",
    "we expand on the system developed in @xcite and transform it into a standalone , scalable , high - throughput transient detection system .",
    "we consider the case where beamformed data is processed to extract astrophysical radio bursts of short duration . @xcite",
    "have thoroughly discussed the range of potential events which can produce such transients , ranging from individual neutron star emissions to extragalctic millisecond bursts @xcite .",
    "we deploy this system on the best-2 array in medicina , where filterbank data is received from an fpga - based digital beamformer implemented on roach - boards    apart from the high computational requirements for an online transient detection pipeline , there are also two major issues which need to be tackled : mitigation of signals induced by terrestrial radio sources , and an accurate event detection mechanism which reduces the data output of the system whilst minimising as much as possible the detection of false positives . depending on the degree and type of radio frequency interference ( rfi ) different mitigation techniques might need to be used . we choose to implement a simple thresholding mechanism that removes any spectra or frequency slices which exceed a certain threshold . in order to avoid the risk of thresholding high - power dispersed radio pulses",
    "the algorithm will allow low power rfi to seep through .",
    "these events will then be classified in the detection stage , which first clusters data points in _ dm - snr - time _ space and then applies a filter to generate transient candidates and remove clusters caused by rfi events .",
    "this filter will compare each cluster s _ dm - snr _ signature with one generated analytically and will classify them depending on the error difference between the two .",
    "this paper is organized as follows : in section [ best2array ] we give an overview of the best-2 array and the digital backend in section [ transientpipeline ] we describe in some detail the implementation of our gpu - based processing pipeline , while in section [ benchmarks ] we benchmark the entire pipeline . in section [ deployment ]",
    "we describe the deployment setup as well as some initial test observation conducted using the system , and in section [ conclusion ] we present our conclusions .",
    "the best-2 @xcite testedbed at the radiotelescopi di medicina , located near bologna , italy , is composed of eight east - west oriented cylindrical concentrators each having 64-dipole receivers critically sampled at 408 mhz with a bandwidth of 16 mhz .",
    "signals from these dipoles are combined in groups of 16 using analog circuitry , resulting in four analog channels per cylinder , providing a total of 32 effective elements positioned on a 4 x 8 grid .",
    "these signals are fed to the roach - based digital backend developed by @xcite and @xcite , where they are digitized and channelized into a total of 1024 single - polarization frequency channels .",
    "the digital backend processed 20 mhz of bandwidth , even though only 16 mhz are useful .",
    "a spatial fourier transform is then performed to create 128 beams , after which 8 beams are selected for output as 16-bit complex values over a 10gbe interface using a custom spead packet format .",
    "the spead protocol aims to standardise the udp datastream format as output by radio astronomy instruments , defining the datastream as self describing , meaning that transmit and receive code can be used for multiple telescopes since the layout of the packets are well defined .",
    "the output rate of a single beam from the beamformer is 640 mbps excluding packet headers , which is calculated using @xmath1 , where c is the number of frequency channels , @xmath2 is the number of time samples per second and @xmath3 is the word length . in our case ,",
    "@xmath4 = 1024 , @xmath2 = 19531.25 ( 20 mhz processable bandwidth channelized into 1024 channels ) and @xmath3 = 32 bits ( 16 bits for each complex component ) .",
    "a total output bandwidth of 5.12 gbps is required to send out all 8 beams , which is manageable over a single 10gige link . in this paper",
    "we will only concern ourselves with the technical specification of this setup and how the outgoing data can be processed on a single processing server .",
    ". ]    we have designed and implemented a real - time , gpu - based , transient detection pipeline for the best-2 array .",
    "we extended the pipeline design adopted in @xcite to include a fast buffering system , the ability to write streamed data to disk at different stages in the pipeline , the ability to process multiple beams concurrently and an online candidate selection mechanism to separate rfi events from astrophysical ones .",
    "the main design emphasis was high - performance and scalability across many beams .",
    "the high - level architecture of this pipeline is depicted in figure [ architecturefigure ] , which is split into three main processing stages : the data reception and buffering stage , the gpu - based processing pipeline stage and the post - processing stage .",
    "each beam is processed on a single gpu , having an associated cpu tread , where a gpu is capable of processing multiple beams depending on the amount of processing required .. the current implementation assumes that beams are identical ( same observation and survey parameters ) , however this can be extended to allow the possibility of performing different operations on each beam .",
    "packet reception , interpretation and buffering is performed on the cpu , which then forwards the data to the gpu where it is passes through several processing stages including : power calculation , bandpass correction , rfi thresholding , dedispersion and optional post - processing and normalization , after which the dedispersed time - series are copied back to cpu memory and passed through a detection stage where it is thresholded , clustered and classified .",
    "any data - points belonging to interesting clusters ( having a high probability that they re not due to rfi events ) are written to disk , together with the unprocessed data buffer after being quantized to 8 or 4 bits depending on whether the data has been converted to a channelized power - series in the receiver thread .",
    "there is also the possibility of writing the entire data stream to disk , including buffers without interesting events , after passing through an encoding and quantization stage , provided that the disk drives can manage the data rate .",
    "all operating parameters are provided by an xml configuration file .",
    "the medicina beamformer packetizes the channelized beamformed data using a custom spead packet format designed to reduce the overhead of heap generation and data movement on the receiver side .",
    "a heap consists of a time - slice containing several spectra ( composed of 16-bit complex values sampled for all channels ) from multiple beams , organized in beam / channel / time order which maps directly to the data organization in gpu memory , thus considerably reducing the overhead for memory re - arrangement .",
    "figure [ packetformatfigure ] describes in further detail the data organization of a heap and how this maps to the packet format .",
    "the udp transmission protocol is used to send the packet stream since it is lightweight and the probability of losing packets , or receiving them out of order , is very small and can be easily handled using simple error checking routines on the receiver side where heap buffers provide a small time window during which an out - of - order packet can still be processed correctly .",
    "the heap size is set by the digital backend .",
    "the incoming udp stream is received and buffered for processing using two cpu threads , the _ network thread _ and the _ buffering thread_. the network thread is responsible for reading and interpreting udp packets , and its performance is limited by the packet size and number of operations required per packet .",
    "the latter is alleviated by using raw sockets and allocating a circular frame buffer in kernel memory which is mapped to the process user memory . when a new ethernet frame is received , the kernel notifies the busy waiting network thread by changing appropriate values in this memory space , thus drastically reducing the number of system calls required .",
    "a 4 kb packet size is used to further reduce overhead costs .",
    "the received frame is then stripped from several protocol headers and the underlying spead packet is extracted .",
    "the spead header defines the heap it belongs to and where its payload should be placed within the heap , after which it is copied to the specified offset .",
    "this requires a heap buffer which is kept local to the network thread until the entire heap has been received .",
    "a circular heap buffer is shared between the network and buffering threads , allowing their operations to overlap and minimize locking overheads .",
    "when a heap is fully read , the buffering thread is notified and a new heap buffer is returned to the network thread , which starts receiving the next heap .",
    "if a packet from the next heap is received before the current heap is fully populated , then all missing packets are considered dropped , thus resulting in zeroed - out `` gaps '' in the heap , which are then handled by the rfi thresholding stage . increasing the number of slots in the circular buffer",
    "reduces the probability that the network thread is kept waiting for the buffering thread to free up slots , which might happen when cpu - intensive tasks are scheduled on the same core as the buffering thread .",
    "the buffering thread s main function is to create larger data buffers to be copied directly to gpu memory , composed of multiple heaps . to overlap the creation of these buffers with gpu execution ,",
    "a double - buffering system is used .",
    "heaps from the circular buffer are separated into chunks containing a time - slice from a single channel per beam , and these are copied to their respective locations within the gpu buffer .",
    "when this is fully populated , the main pipeline thread is notified and the pipeline is advanced by one iteration after all the gpu - based processing has finished for the previous one .",
    "the main pipeline consists of several processing modules which run on the gpu , with a single managing thread taking care of initialization and synchronization .",
    "execution is parallelized across beams , where a separate processing thread is initialized for each beam and is associated with a particular gpu .",
    "each processing thread takes care of copying its input data from cpu to gpu memory and vice versa , which maximizes the pcie - bandwidth used during these operations on multi - gpu systems .",
    "the cpu imprint of these threads is almost negligible and mostly consists of kernel timing and synchronization , and a one - off @xmath5-order polynomial fit over @xmath6 values per iteration .",
    "the processing threads execution passes through several kernel launches which perform specific functions .",
    "although we could get a potential speedup by combining some of these kernels into monolithic functions , separating functionality this way makes it easier to add intermediary stages as well as disabling certain functionality when required .",
    "terrestrial rfi , and methods to try and mitigate or correct for it , is one of the major problems in transient surveys , especially for radio telescopes which are close to urban centers , such as medicina .",
    "several methods have been investigated to cater for this ( for example , @xcite ) , the major challenge being to try and remove as much rfi as possible without affecting any true astrophysical dispersed pulses which might be present in the data .",
    "we implement a simple rfi - thresholding process which limits the amount of strong , bursty rfi , whose effectiveness can be tweaked by applying different thresholding factors .",
    "any undetected rfi will result in incorrect detections after dedispersion .",
    "although these are never welcome , it would be more advantageous to allow some low - power rfi to seep through rather than increasing the probability of thresholding astrophysical events .",
    "the detection and classification stage should then be able to discern between real and terrestrial signals .",
    "not performing any rfi mitigation would result in a large number of incorrect detections as well as a higher variance in the data , which lowers the probability of detecting weak astrophysical signals .",
    "the thresholding process consists of the three stages described below , and figure [ medicinarfifigure ] depicts some examples of rfi events which occurred during test observations and the resultant waterfall plots after rfi rejection .",
    "order polynomial ( blue ) and the rmse of the two is used to generate channel thresholds ( green ) .",
    "this threshold is then applied to subsets of spectra of size @xmath7 and any chunk exceeding it will be replaced with the channel s fitted bandpass value , as is the case for the channels marked in red in this plot . ]    * bandpass correction : * a @xmath5-order polynomial is fitted to an averaged bandpass in each iteration , providing a smoothed , approximate description of the telescope s response to the frequency band being processed . accumulation and averaging is performed on the gpu , mainly consisting of a reduction sum across the frequency channels , resulting in @xmath6 values which are copied back to cpu memory",
    ". channels containing high power rfi will distort the bandpass fit , so these channels are masked beforehand by replacing their values with the mean of the neighboring channels , thus interpolating the bandpass .",
    "the resulting bandpass is then fitted using least - squares .",
    "the root mean square error ( rmse ) between the fitted bandpass and the averaged , interpolated bandpass is then computed and used as a thresholding factor for the channel thresholding stage , whilst the mean and standard deviation are used for the spectrum thresholding stage .",
    "the fitted bandpass is then subtracted from all the spectra on the gpu , generating corrected spectra , having the effect of equalizing the telescope s response .",
    "this also has the effect of moving the mean to , or near , 0 .",
    "* channel thresholding : * each frequency channel should have a uniform power level across short time spans , and if it experiences a sudden change it can generally be attributed to narrow - band rfi ( or alternatively , a very strong astrophysical burst ) .",
    "first a non - overlapping sliding window of width @xmath7 is applied to each frequency channel , thereby partitioning them into chunks of width @xmath7 .",
    "the mean of each chunk is calculated , and if this exceeds a threshold then it , together with its immediate neighbors , is flagged as rfi .",
    "after the flagging stage is complete the values of any flagged chunk is replaced with the frequency channel s fitted bandpass value .",
    "this is preferred to setting these values to 0 since the effect on the statistical properties of the data is minimized .",
    "@xmath7 depends on the rfi environment , the observing parameters and the width of astrophysical transient being searched for .",
    "* spectrum thresholding : * in this stage , the mean of each full - band spectrum is calculated and compared to the spectrum threshold .",
    "if the mean exceeds this threshold then the entire spectrum is substituted with the fitted bandpass .",
    "dispersed pulses should not be affected by this process , unless the threshold is exceptionally low , since their power is distributed across multiple spectra depending on the pulses dm value .",
    "the threshold is empirically set such that time spectra are rarely affected by this stage , although this will depend in the rfi environment .      by far",
    "the most time - consuming processing stage is dedispersion , which corrects for the frequency - dependent dispersion experienced by electromagnetic radiation emitted from a source as it travels through the inter - stellar medium ( ism ) .",
    "this dispersion obeys the cold plasma dispersion law , where the time - delay between two frequencies @xmath8 and @xmath9 is given by the quadratic relation @xcite : @xmath10 where dm is the dispersion measure in pc @xmath11 and @xmath8 and @xmath9 are in mhz .",
    "astrophysical objects have a signature dm value associated with them , which is related to the direction - dependent distance from the observer .",
    "brute - force dedispersion is an @xmath12 operation , where @xmath6 is the number of frequency channels and @xmath13 is the number of input spectra , which for real - time streaming applications can be seen as infinite . during a blind transient survey",
    "this operation has to be performed over a large number of dm values , depending on the observation and survey parameters ( see ( * ? ? ?",
    "* section 2 ) , for an explanation of how to generate search parameters ) .",
    "we use the dedispersion kernel developed in @xcite where each gpu thread block is responsible for processing an area of @xmath14 space , maximizing data locality in the fastest memory locations .      the dedispersed time series",
    "are then passed through a post - processing stage , which smoothens and normalizes the data .",
    "this is mostly done using two techniques :    * median filtering : * noisy , isolated outliers in the time series can be suppressed by replacing the value @xmath15 with one which is calculated using neighboring points : @xmath16 where @xmath17 represents a neighborhood centered around the location @xmath18 , and @xmath19 is the averaging function used .",
    "we chose to use the median of the neighborhood points , since it better preserves the edges of the signal than the mean .",
    "we have implemented a windowed - median filter on the gpu , where thread blocks are split across a 2d grid with each row processing one dedispersed time series , for a single dm value , partitioned along the columns of the grid .",
    "each thread block loads a subset of the series to shared memory , including some overlapping values at the edges , and each thread computes the median of its associated data point neighborhood and stores this value back to global memory .",
    "* detrending and normalization : * the mean power of the incoming data stream can change gradually in time , the rate of which depends on the cause of this change , such as steady temperature changes in telescope electronics , sky temperature variations , or an astrophysical radio source moving toward , or away from , the beam center .",
    "this effect can be alleviated by subtracting a best - fit line to the dedispersed time series , which effectively centers the series to a mean of 0 .",
    "the detrending process is also performed on the gpu , where a thread block is associated with one time series and the best - fit line is computed using linear regression .",
    "the kernel requires two passes of the data , one to calculate the regression parameters and one to subtract the trend - line from the series . during this pass ,",
    "the standard deviation is also computed , and a third pass is performed to normalise the data .    after this stage , the post - processed dedispersed time series are copied back to cpu memory and forwarded to the event detection stage , which is started as soon as all the beams have been processed ( and a new input data buffer is available for processing ) .      during the first stage of event detection",
    ", the dedispersed time series are thresholded using a suitable threshold value ( @xmath20 ) .",
    "this value should be low enough to allow low snr pulses to pass through , even at the cost of incorrect rfi detections , which will be filtered in the clustering stage .",
    "a list of detections is generated for each beam , containing @xmath21 triplets .",
    "astrophysical transients , as well as rfi signals , will result in a number of entries in this list which should be grouped together and treated as a single candidate .",
    "this is the main function of the clustering stage .",
    "we start by applying a density - based clustering technique , dbscan @xcite , to group neighboring data points together .",
    "its definition of a cluster is based on the underlying estimated density distribution of the dataset .",
    "the shape of the clusters is determined by the choice of the distance function for two points . the _ eps - neighborhood _ of a point @xmath22 , denoted by @xmath23",
    "is defined by @xmath24 where @xmath25 is an argument defining the neighborhood extent of a point , @xmath26 is the set of points and @xmath27 is the distance function for points @xmath22 and @xmath28 .",
    "dbscan distinguishes between two types of cluster points , points inside the cluster ( _ core points _ ) and points on the border of the cluster ( _ border points _ ) which generally have less points in their neighborhood .",
    "a point @xmath22 is _ directly density - reachable _ from @xmath28 if @xmath29 and @xmath30 .",
    "a point @xmath22 is _ density reachable _ from a point @xmath28 if there is a chain of points @xmath31 , @xmath32 , @xmath33 such that @xmath34 is directly density - reachable from @xmath35 .",
    "border points within the same cluster might not be density - reachable from each other , but they are _ density - connected _ if there is a point @xmath36 such that both of them are density - reachable from @xmath36 . following these definitions , a _ cluster _",
    "is defined as a non - empty subset of @xmath26 satisfying the following two conditions :    _ maximality _ : @xmath37    _ connectivity _ : @xmath38    any points which do not belong to a cluster are regarded as noise : @xmath39 , where @xmath40 is the set of noise points , @xmath41 are the clusters in @xmath26 and @xmath42 with @xmath43 being the total number of clusters .",
    "this technique has several advantages which makes it a suitable candidate for clustering detections :    it does not require a seed to specify the number of clusters in the dataset , which is a desirable property since the number of events occurring within a time - frame , be they astrophysical transients or rfi , is unknown unless a cluster approximation step is performed beforehand    it has a notion of noise    it is also capable of separating overlapping clusters having different density distributions , such as when an rfi signal overlaps a transient event , if the input arguments are sensitive enough    the main drawback of this technique is its runtime complexity , dominated by the neighborhood calculation for every point , which is of order @xmath44 unless an indexing structure is used or a distance matrix is computed beforehand , however this needs @xmath44 memory , which is unfeasible for large datasets . to counter this",
    "we implement a faster , albeit less accurate , version of the algorithm , fdbscan @xcite , which only uses a small a subset of representative points in a core point s neighborhood as seeds for cluster expansion , reducing the number of region query calls .",
    "the representative points are chosen to be at the border of a core point s neighborhood , two for each dimension , one for each direction when placing the core point at the origin . due to this approximation",
    ", some points might be lost , and in some cases clusters might be split apart , however the probability of this happening is very low ( see @xcite ) .",
    "the distance function used in our implementation assigns a different value to each dimension ( @xmath45 , @xmath46 , @xmath47 ) .",
    "detections after dedispersion will have a specific shape along the time dimension due to incorrect dedispersion , with higher dm values detecting events before lower ones .",
    "the width of a cluster will also reflect the true pulse width , being narrower near the true dm .",
    "the value of @xmath45 should depend on the lowest pulse width being searched for",
    ". a higher @xmath45 might result in pulses close in time to be fused together into one cluster .",
    "the value of @xmath46 and @xmath47 should be large enough to allow clusters to encompass the entire range , whilst allowing dbscan to distinguish between core and border points .",
    "the output of the clustering stage is a list of detected clusters .",
    "the main challenge is then to discern between rfi - induced clusters and transient candidates . in the case of transients",
    "the highest snr detections will be centered around the pulse s true dm , dimishing in power when moving away from the value until the threshold level is reached due to dedispersion at an incorrect dm value . following @xcite , assuming a rectangular bandpass function , which should resemble the telescope s bandpass shape after bandpass correction , a gaussian - shaped pulse with fwhm width @xmath3 in milliseconds , the ratio of measured peak flux density @xmath48 to true peak flux @xmath49 for a dm error @xmath50 dm is    @xmath51    where @xmath52    comparing this model with a cluster s dm - snr signature provides us with a classification mechanism .",
    "our implementation performs the following processes for each detected cluster :    1 .",
    "generate its dm - snr signature by collapsing the time dimension 2 .",
    "smoothen this signature by running a @xmath43-element moving average 3 .",
    "find the dm value containing the highest number of detections and its maximum snr .",
    "if this dm value is less than 1.0 then it is assumed that it was caused by broadband rfi and the cluster is discarded 4 .",
    "approximate the pulse s fwhm by computing the difference between the pulse s start and end time at the maximum snr value .",
    "normalise snr - dm signature 6 .",
    "compue the analytical curve for incorrect dedispersion using equation [ incorrectdedispersion ] 7 .",
    "calculate the rmse between the modelled curve and pulse s dm - snr signature 8 .",
    "if the mse exceeds a preset threshold , then the cluster is discarded ( rfi ) , otherwise classify as a potential candidate .",
    "this threshold can be set empirically through test observations or by using simulated data .",
    "this procedure is most effective for detecting relatively strong pulses and differentiating them from rfi .",
    "the classification of clusters having a small number of detections can be incorrect if the width of the pulse can not be determined . to increase the likelihood of detecting lower - snr pulses ,",
    "the detection threshold during the first stage of event detection should be lower than typically used for similar searches in order to allow more pulse detections to be clustered together .",
    "this will result in a higher number of background noise detections , however these will be filtered out by dbscan .",
    "figure [ classificationfigure ] depicts the output of this process when applied to detections during a test observation with best-2 ( see section [ deployment ] ) .",
    "selected candidates are flagged and the data buffer in which they were found is persisted to disk together with cluster information .      the pipeline can either write the entire incoming data stream to disk or dump data buffers containing interesting detections when triggered by the event detection stage , for future off - line processing . the data rates being processed can go up to 650 mb / s , which is much faster than what conventional hard drives can process , so the data has to be quantized first .",
    "this data can be in two formats : complex channelized time series , in which case 16-bit complex values are quantized to 4-bits with two complex components packed into one byte , or channelized power series , where each 32-bit single - precision floating point value is quantized to 8 bits .    in both cases",
    ", although the dynamic range can potentially span the entire bit - range , most of the values will typically be distributed across a small range around a mean level ( in the simplest case , complex channelized series will be normally distributed , while channelized power series will follow a half - normal distribution ) . using",
    "a linear quantizer would result in a loss in sensitivity within this region , whilst clipping the range would reduce the snr of any potential pulses in the data .",
    "for this reason , we use a logarithmic quantizer , specifically a @xmath53-law quantizer , adapted from the g.711.0 standard @xcite : @xmath54}{log\\left[1+\\mu\\right]}sign\\left[x\\right]\\ ] ] where @xmath55 represents points in the data series , @xmath56 is the maximum value in this series , @xmath53 is the compression factor and @xmath57 is the quantized data series",
    ". a higher compression factor will result in more output bits being allocated to the high data point concentration range of the input distribution , as depicted in figure [ mulawfigure ] .",
    "the data buffer is first encoded using this mapping and then the output values are quantized and dumped to disk .",
    "this is performed on the cpu , so as not to interfere with the main processing pipeline and induce delays .",
    "a precomputed lookup table for @xmath58 values is used to speed - up processing .",
    "the data series is split across multiple openmp threads , whose processing is interleaved with file i / o calls , in order to overlap cpu - processing and i / o .",
    "| p3.2 cm | r | p3.2 cm | r |   + & + bandpass fitting & 36.79 ms & thresholding & 690.96 ms + rfi filtering & 74.97 ms & clustering & 1148 ms + dedispersion & 3863 ms & classification & 168.64 ms + median filtering & 135.11 ms & clusters to file & 728.73 ms + detrending & 59.06 ms & quantization & 3532 ms +   +   +    . during test observations the central e - w row of beams",
    "is chosen , so that a transient source will transit through as many beams as possible .",
    "the figure above shows the folded pulse profiles from an observation of psr b0329 + 54 , which transits all the beams during a 1800s observation , its trajectory depicted by the dashed line at a dec of 54.57@xmath59 .",
    "the channelized complex data from each beam was quantized and persisted to disk , after which the integrated pulse profile for each beam were generated using 50 profiles .",
    "the differences between the profiles can be attributed to some rfi events which occurred during the observation . ]",
    "this pipeline can be thought of as a soft real - time system , where all the parallel stages should keep up with the incoming data stream for maximum quality of service , however if for some reason one of them does not meet a processing deadline the system does not become unstable but rather the buffering stage will drop heaps until the pipeline progresses by one iteration .",
    "these processing hiccups might happen when , for example , a very high - power rfi spike induces a large number of detections resulting in a large number of data points to cluster .",
    "the gpu processing times are fixed regardless of the quality of the data , so these issues are only applicable to cpu threads .",
    "for this reason , a pipeline iteration should be limited by the gpu processing time .",
    "figure [ cputimingfigure ] shows the scaling performance for the two most time consuming stages on the cpu , clustering and quantization , when being performed by a single host thread .",
    "the number of samples which need to be quantized for a single pipeline iteration is fixed ( @xmath60 ) , while the number of data points which need to be clustered depends on the number of signals in the data stream , however empirical testing and initial observations show that this number rarely exceeds @xmath61 .",
    "both stages are capable of processing the full data stream in real - time for best-2 observation parameters using a single cpu thread per stage .",
    "table [ timingtable ] lists the timings for all the processing stages for one pipeline iteration when processing 8 full bandwidth ( 20 mhz ) beams .",
    "a simulated data file containing a 500ms periodic pulse with 1% duty cycle and an snr of 3 was input to the system , with the data copied to all the beams in @xmath05s buffers , this length being limited by the amount of gpu memory available .",
    "the host system on which the benchmark tests were conducted consists of 2 intel xeon e5 - 2630 2.3 ghz processors , 2 nvidia gtx 660 ti gpus with 3 gb of gddr5 ram , 32 gb ddr3 - 1600 system ram and a fujitsu d3118 system board .",
    "the table is split into two columns which work in parallel , the gpu - based processing stages and the cpu - based processing stages , with data transfer to and from the two performed at synchronization barriers .",
    "it is clear that the processing bottleneck is the dedispersion kernel , which takes up 93% of the gpus processing time , while the rest of the kernels have a negligible effect on the overall running time of the pipeline .",
    "the number of dm values which can be processed during an observation is limited by this as well , and currently this value is around 640 dms , which can be doubled when processing half the bandwidth ( see section [ deployment ] ) .",
    "the dm step and maximum dm do not have a large performance impact , although a higher dm value would require a larger temporary gpu buffer to store the shifted samples and would limit the number of time spectra which can be processed in each iteration . for a single beam",
    ", the tradeoff between the number of spectra and dispersional measure trials which can be processed can be calculated as follows : @xmath62 where @xmath63 is the number of time samples , @xmath64 is the number of frequency channels , @xmath65 is the number of dm trials , @xmath66 is the amount of gpu global memory in 32-bit words , @xmath67 is the dispersion shift in time samples between the edges of the observing band for the largest dm value , @xmath68 is the input bitwidth and @xmath69 represents other smaller buffers which are required ( such as the shift buffer for dedispersion and fitted bandpass buffer for bandpass correction ) .",
    "a gpu server ( hardware specifications listed in section [ benchmarks ] ) was deployed at the medicina best-2 array and connected to the digital backend via a single 10gige link .",
    "initial test observations indicated that the full 20mhz bandwidth contained significant narrowband rfi , with the edges of the bandpass having negligible snr .",
    "for this reason , half of the band was discarded and 10 mhz were used for the rest of the observations , from 413.9 mhz to 403.9 mhz .",
    "the bandpass shape is depicted in figure [ bandpassfigure ] .",
    "the beamformer creates a 2d grid of beams within the primary beam , out of which eight can be selected for output .",
    "these beam were chosen to create a `` strip '' along the e - w direction ( along ra ) so that pointing towards a transient source would result in it transiting across multiple beams , which is useful for testing the digital beamformer , the pipeline setup as well as the data transmission between the two .",
    "280s observation of pulsar psr b0329 + 54 , which enters the beam at around 100s with the pulse snr increasing as the pulsar moves towards the center of the beam .",
    "this plot shows the output generated by the clustering and candidate selection stages , partitioning the data into noise ( red ) , rfi - induced clusters ( black ) and selected candidates ( blue ) .",
    "some of these clusters are also depicted in figure [ classificationfigure ] . ]",
    "several test observations were performed on known bright pulsars , especially psr b0329 + 54 , which is the brightest transient source that can be observed with best-2 , located at ra 20:18:03.8333 and dec + 28:39:54.212 . the beam configuration for these observations",
    "is shown in figure [ beamconfigurationfigure ] , where the central row of beams is selected for output ( colored in red ) .",
    "the pipeline was used in `` persistence mode '' , where all the channelized complex - voltages from all the beams are quantized and persisted to disk .",
    "the integrated pulse profiles were then generated for each beam using 50 profiles .",
    "the differences between the profiles can be attributed to rfi events which occurred during the observation , sometimes resulting in a recalculation of the quantization factors ( this only happens when an extremely large rfi event occurs , as was the case during this observation ) .",
    "the integrated pulse profiles for psr b0329 + 54 and , through a separate observation , psr b2016 + 28 are shown in figure [ profilesfigure ] , each generated by folding 200 profiles offline with raw observation data persisted to disk from a single beam .",
    "figure [ b0329figure ] represents the output of the pipeline for the previous observation for a single beam .",
    "the pulsar enters the beam at @xmath0100s , with pulses getting stronger as it moves towards the beam s center .",
    "several rfi events were also detected , the most noticeable of them being three broadband events ( the large detections at dm @xmath70 0 ) and a bright narrowband event at around 215s which was detected across the entire dm range .",
    "figure [ classificationfigure ] provides visual snapshots of four clusters during the classification stage , with two clusters originating from pulse detections from b0329 + 54 and two additional clusters attributed to rfi .",
    "both these rfi clusters were correctly filtered .",
    "we have developed a gpu - based , real - time transient detection pipeline capable of processing multiple beams simultaneously , with data streamed via a 10gige link from a digital beamformer .",
    "this pipeline consists of several processing stages , including : rfi mitigation using simple thresholding techniques , brute - force dedispersion , density - based clustering for grouping related detections together and cluster classification to filter out rfi - induced clusters .",
    "interesting events , as well as the entire incoming data stream , can be persisted to disk at any time during the pipeline s execution .",
    "a gpu server was deployed at the medicina best-2 array near bologna , italy , where several benchmarks and test observations were performed , with the digital backend capable of streaming 8 single polarization 20mhz beams at 5.12 gbps . with this setup",
    ", the pipeline could process the 8 beams on two nvidia gtx 660ti cards for a maximum of 640 dm values , with dedispersion step and maximum dm having a negligible effect on performance .",
    "the bandwidth - limited dedispersion step is the slowest part of the pipeline , taking up 93% of the gpu processing time . for this reason ,",
    "improving this stage and implementing faster versions of the algorithm is an ongoing effort .",
    "the current implementation    the pipeline architecture parallelizes processing across beams , so when a single server is not capable of processing the total number of beams output by a beamformer multiple servers can be used if the data can be streamed to different destinations ( through an intermediary switch or different interfaces on the backend system ) .",
    "wider bandwidths require more processing and so decrease the number of beams which can be processed .",
    "this assumes homogeneous server configuration , otherwise a load - balancing intermediary server will be required to split the data streams .",
    "this parallelization philosophy make this prototype a viable system for processing beamformed data as long as a single beam can be processed on one gpu , and the ever - increasing processing power of these devices makes this notion very realizable for future radio telescopes .",
    "we would like to thank stelio montebugnoli , jader monari , germano bianco and all the staff at the medicina radio observatory for their invaluable help on - site during deployment and observing sessions .",
    "we would also like to thank the system designers for the digital backend , especially griffin foster , for their help in designing the interfacing protocol between the digital backend and host system , as well as for hours of support .",
    "bhat , n. d. r , chengalur , j. n. , cox , p. j. , gupta , y. , prasad , j. , roy , j. , bailes , m. , burke - spolaor , s. , kudale , s. s. , and van staren , w. [ 2013 ] _ accepted for publication in the astrophysical journal _"
  ],
  "abstract_text": [
    "<S> radio transient discovery using next generation radio telescopes will pose several digital signal processing and data transfer challenges , requiring specialized high - performance backends . </S>",
    "<S> several accelerator technologies are being considered as prototyping platforms , including graphics processing units ( gpus ) . in this paper </S>",
    "<S> we present a real - time pipeline prototype capable of processing multiple beams concurrently , performing radio frequency interference ( rfi ) rejection through thresholding , correcting for the delay in signal arrival times across the frequency band using brute - force dedispersion , event detection and clustering , and finally candidate filtering , with the capability of persisting data buffers containing interesting signals to disk . </S>",
    "<S> this setup was deployed at the best-2 ska pathfinder in medicina , italy , where several benchmarks and test observations of astrophysical transients were conducted . </S>",
    "<S> these tests show that on the deployed hardware eight 20mhz beams can be processed simultaneously for @xmath0640 dispersion measure ( dm ) values . </S>",
    "<S> furthermore , the clustering and candidate filtering algorithms employed prove to be good candidates for online event detection techniques . </S>",
    "<S> the number of beams which can be processed increases proportionally to the number of servers deployed and number of gpus , making it a viable architecture for current and future radio telescopes .    ; ; ; </S>"
  ]
}