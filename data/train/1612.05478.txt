{
  "article_text": [
    "in this work , we focus on the problem of propagating structured information across video frames",
    ".  this problem appears in many forms ( e.g. , semantic segmentation or depth estimation ) and is a pre - requisite for many applications .",
    "an example instance is shown in fig .  [ fig : illustration ] . given an accurate object mask for the first frame ,",
    "the problem is to propagate this mask forward through the entire video sequence .",
    "propagation of semantic information through time and video colorization are other problem instances .",
    "videos pose both technical and representational challenges .",
    "the presence of scene and camera motion lead to the difficult association problem of optical flow .",
    "video data is computationally more demanding than static images .",
    "a naive per - frame approach would scale at least linear with frames .",
    "these challenges complicate the use of standard convolutional neural networks ( cnns ) for video processing . as a result , many previous works for video propagation use slow optimization based techniques .",
    "frame to other video frames . ]",
    "[ fig : illustration ]    we propose a generic neural network architecture that propagates information across video frames .",
    "the main innovation is the use of image adaptive convolutional operations that automatically adapt to the video stream content .",
    "this allows the network to adapt to the changing content of the video stream .",
    "it can be applied to several types of information , e.g. , labels , colors , etc . and runs online , that is , only requiring current and previous frames .",
    "our architecture is composed of two components ( see fig .  [",
    "fig : illustration ] ) . a temporal _ bilateral network _ that performs image - adaptive spatial - temporal dense filtering .",
    "this part allows to connect densely all pixels from current and previous frames and to propagate associated pixel information to the current frame .",
    "the bilateral network allows the specification of a metric between video pixels and allows a straight - forward integration of temporal information .",
    "this is followed by a standard _ spatial cnn _ on the filter output to refine and predict for the present video frame .",
    "we call this combination a _ video propagation network ( vpn)_. in effect we are combining a filtering technique with rather small spatial cnns which leads to a favorable runtime compared to many previous approaches .",
    "vpns have the following suitable properties for video processing :    [ [ general - applicability ] ] general applicability : + + + + + + + + + + + + + + + + + + + + + +    vpns can be used for propagating any type of information content i.e. , both discrete ( e.g. , semantic labels ) and continuous ( e.g. , color ) information across video frames .",
    "[ [ online - propagation ] ] online propagation : + + + + + + + + + + + + + + + + + + +    the method needs no future frames and so can be used for online video analysis .",
    "[ [ long - range - and - image - adaptive ] ] long - range and image adaptive : + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    vpns can efficiently handle a large number of input frames and are adaptive to the video .    [",
    "[ end - to - end - trainable ] ] end - to - end trainable : + + + + + + + + + + + + + + + + + + + + +    vpns can be trained end - to - end , so they can be used in other deep network architectures .",
    "[ [ favorable - runtime ] ] favorable runtime : + + + + + + + + + + + + + + + + + +    vpns have favorable runtime in comparison to several current best methods , also making them amenable for learning with large datasets .",
    "empirically we show that vpns , despite being generic , perform better than published approaches on video object segmentation and semantic label propagation while being faster .",
    "vpns can easily be integrated into sequential per - frame approaches and require only a small fine - tuning step that can be performed separately .",
    "the literature on propagating information across video frames contains a vast and varied number of approaches . here , we only discuss those works that are related to our technique and applications .",
    "[ [ general - propagation - techniques ] ] general propagation techniques + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    techniques for propagating content across image / video pixels are predominantly optimization based or filtering techniques .",
    "optimization based techniques typically formulate the propagation as an energy minimization problem on a graph constructed across video pixels or frames .",
    "a classic example is the color propagation technique from  @xcite which uses graph structure that encodes prior knowledge about pixel colors in a local neighborhood .",
    "although efficient closed - form solutions  @xcite exists for certain scenarios , optimization tends to be slow due to either large graph structures for videos and/or the use of complex connectivity resulting in the use of iterative optimization schemes .",
    "fully - connected conditional random fields ( crfs )  @xcite open a way for incorporating dense and long - range pixel connections while retaining fast inference .",
    "filtering techniques  @xcite aim to propagate information with the use of image or video filters resulting in fast runtimes compared to optimization techniques .",
    "bilateral filtering  @xcite is one of the popular filters for long - range information propagation .",
    "a popular application is joint bilateral upsampling  @xcite that upsamples a low - resolution signal with the use of a high - resolution guidance image .",
    "the works of  @xcite showed that one can back - propagate through the bilateral filtering operation for learning filter parameters  @xcite or doing optimization in the bilateral space  @xcite . recently , several works proposed to do upsampling in images by learning cnns that mimic edge - aware filtering  @xcite or that directly learn to upsample  @xcite .",
    "most of these works are confined to images and are either not extendable or computationally too expensive for videos .",
    "we leverage some of these previous works and propose a scalable yet robust neural network based approach for video content propagation .",
    "we will discuss more about bilateral filtering , that forms the core of our approach , in section  [ sec : bilateralfiltering ] .",
    "[ [ video - object - segmentation ] ] video object segmentation + + + + + + + + + + + + + + + + + + + + + + + + +    prior work on video object segmentation can be broadly categorized into two types : semi - supervised methods that require manual annotation to define what is foreground object and unsupervised methods that does segmentation completely automatically .",
    "unsupervised techniques such as  @xcite use some prior information about the foreground objects such as distinctive motion , saliency etc . and",
    ", they typically fail if these assumptions do not hold in a video .",
    "[ fig : filter_illustration ]    in this work , we focus on the semi - supervised task of propagating the foreground mask from the first frame to the entire video .",
    "existing works predominantly use graph - based optimization frameworks that perform graph - cuts  @xcite on video data .",
    "several of these works  @xcite aim to reduce the complexity of graph structure with clustering techniques such as spatial - temporal superpixels and optical flow  @xcite .",
    "another direction was to estimate correspondence between different frame pixels  @xcite by using nearest neighbor fields  @xcite or optical flow  @xcite and then refine the propagated masks with the use of local classifiers .",
    "closest to our technique are the works of  @xcite and  @xcite .",
    "@xcite proposed to use fully - connected crf over the refined object proposals across the video frames .",
    "@xcite proposed a graph - cut in the bilateral space .",
    "our approach is similar in the regard that we also use a bilateral space embedding . instead of graph - cuts , we learn propagation filters in the high - dimensional bilateral space with cnns .",
    "this results in a more generic architecture and allows integration into other deep learning frameworks .",
    "two contemporary works  @xcite proposed cnn based approaches for video object segmentation . both works rely on fine - tuning a deep network using the first frame annotation of a given test sequence .",
    "this could potentially result in overfitting to the test background .",
    "in contrast , the proposed approach relies only on offline training and thus can be easily adapted to different problem scenarios .",
    "[ [ semantic - video - segmentation ] ] semantic video segmentation + + + + + + + + + + + + + + + + + + + + + + + + + + +    earlier methods such as  @xcite use structure from motion on video frames to compute geometrical and/or motion features .",
    "more recent works  @xcite construct large graphical models on videos and enforce temporal consistency across frames .",
    "@xcite used dynamic temporal links in their crf energy formulation .",
    "@xcite proposes to use perturb - and - map random field model with spatial - temporal energy terms based on potts model and @xcite propagate predictions across time by learning a similarity function between pixels of consecutive frames .    in the recent years",
    ", there is a big leap in the performance of semantic image segmentation  @xcite with the use of cnns but mostly applied to images .",
    "recently ,  @xcite proposed to retain the intermediate cnn representations while sliding the image based cnn across the frames .",
    "another approach , which inspired our work , is to take unary predictions from cnn and then propagate semantic information across the frames .",
    "a recent prominent approach in this direction is of  @xcite which proposes a technique for optimizing feature spaces for fully - connected crf .",
    "we briefly review the background of bilateral filtering and the extensions that we will need to build a bilateral network for videos .",
    "bilateral filtering has its roots in image denoising  @xcite and has been developed as an edge - preserving filter .",
    "it has found numerous applications  @xcite and recently found its way into neural network architectures  @xcite . in this work",
    ", we will use this filtering at the core of our approach and make use of the image / video - adaptive connectivity as a way to cope with scenes in motion .",
    "the most used bilateral filter kernel is a gaussian filter , we make use of the recent work of  @xcite that generalizes this filter to a full parameterized operation .    bilateral filtering of a vector @xmath0 can be viewed as a matrix - vector multiplication operation with a matrix @xmath1    @xmath2 where the filter weights @xmath3 depend on features @xmath4 of every input index @xmath5 .",
    "for example a gaussian bilateral filter amounts to a particular choice of @xmath1 as @xmath6 .",
    "the choice of features @xmath7 define the effect of the filter , the way it adapts to image content . to use only positional features , @xmath8",
    ", the bilateral filter operation reduces to a spatial gaussian filter , with width controlled by @xmath9 .",
    "a common choice for edge - preserving filtering is to choose color and position features @xmath10 .",
    "this results in image smoothing without blurring across the edges .    the filter values @xmath1 change for every pixel pairs @xmath5 and depend on the image / video content .",
    "therefore , a naive implementation of the vector - product computation in eq .",
    "[ eq : wtimesv ] is prohibitive . due to the importance of this filtering operation , several fast algorithms",
    "@xcite have been proposed , that make use of the structure of @xmath1 and @xmath0 , not building up the matrix altogether but computing the multiplication result directly .",
    "one natural view that inspired several implementations was offered by  @xcite , who viewed the bilateral filtering operation as a computation in a higher dimensional space .",
    "their observation was that filtering can be implemented by 1 .",
    "projecting @xmath0 into a high - dimensional grid ( _ splatting _ ) , 2 .",
    "high - dimensional filtering ( _ convolving _ ) and 3 .",
    "projecting down the result at the points of interest ( _ slicing _ ) .",
    "the high - dimensional grid is also called _ bilateral space / grid_. all these three operations are linear @xmath11    where , @xmath12 and @xmath13 denotes the mapping to - from image pixels and bilateral grid , and @xmath14 denotes convolution ( traditionally gaussian ) in the bilateral space .",
    "the problem with this approach is that a standard @xmath15 convolution on a regular grid requires handling of an exponential number of grid points .",
    "this was circumvented by a special data structure , the permutohedral lattice as proposed in  @xcite .",
    "effectively permutohedral filtering scales linearly with dimension , resulting in fast execution time .",
    "the recent work of  @xcite then generalized the bilateral filter in the permutohedral lattice and demonstrated how it can be learned via back - propagation .",
    "this allowed the construction of image - adaptive filtering operations into deep learning architectures , which we will build upon .",
    "see fig .",
    "[ fig : filter_illustration ] for a 2d illustration of permutohedral lattices .",
    "refer to  @xcite for more details on bilateral filtering using permutohedral lattice and refer to  @xcite for details on learning general permutohedral filters via back - propagation .",
    "we aim to adapt the bilateral filtering operation to predict information forward in time , across video frames . formally , we work on a sequence of @xmath16 ( color or grayscale ) images @xmath17 and denote with @xmath18 a sequence of outputs , one per frame .",
    "consider as an example a sequence @xmath19 of foreground masks for a moving object in the scene .",
    "our goal is to develop an online propagation method , that is , a function that has no access to the future frames .",
    "formally we predict @xmath20 , having observed the video up to frame @xmath21 and possibly previous @xmath22 @xmath23    if training examples @xmath24 with full or partial knowledge of @xmath0 are available , it is possible to learn @xmath25 and for a complex and unknown relationship between input and output , a deep cnn is a natural design choice .",
    "however , any learning based method has to face the main challenge : the scene and camera motion and its effect on @xmath0 . since no motion in two different videos is the same , fixed - sized static receptive fields of cnn units are insufficient .",
    "we propose to resolve this with video - adaptive convolutional component , an adaption of the bilateral filtering to videos .",
    "our bilateral network ( section  [ sec : bilateralnetwork ] ) has a connectivity that adapts to video sequences , its output is then fed into a common spatial network ( section  [ sec : spatialcnn ] ) that further refines the desired output .",
    "the combined network layout of this video propagation network is depicted in fig .",
    "[ fig : net_illustration ] .",
    "it is a sequence of learnable bilateral and spatial filters that is efficient , trainable end - to - end and adaptive to the video input .",
    "[ fig : net_illustration ]      in this section , we describe the extension of the learnable bilateral filtering to video data .",
    "several properties of bilateral filtering make it a perfect candidate for information propagation in videos .",
    "in particular , our method is inspired by two main ideas that we extend in this work : joint bilateral upsampling  @xcite and learnable bilateral filters  @xcite .",
    "although , bilateral filtering has been used for filtering video data before  @xcite , its use has been limited to fixed filter weights ( say , gaussian ) .",
    "* fast bilateral upsampling across frames * the idea of joint bilateral upsampling  @xcite is to view upsampling as a filtering operation .",
    "a high resolution guidance image is used to up - sample a low - resolution result . in short , a smaller number of input points are given @xmath26 , for example a segmentation result @xmath27 at a lower resolution .",
    "this is then scaled to a larger number of output points @xmath28 using the bilateral filtering operation , that is to compute eq .",
    "[ eq : wtimesv ] , where the sum runs over all @xmath29 points and the output is computed for all @xmath30 positions .",
    "we will use this idea to propagate content from previous frames to the current frame ( all of which have the same dimensions ) , using the current frame as a guidance image .",
    "this is illustrated in fig .",
    "[ fig : filter_illustration ] .",
    "we take all previous frame results @xmath22 and splat them into a lattice using the features computed on video frames @xmath31 . a filtering ( described below )",
    "is applied to every lattice point and the result is then sliced back using the current frame @xmath32 .",
    "this result need not be the final @xmath20 , in fact we compute a filter bank of responses and continue with further processing as will be discussed .    for videos , we need to extend bilateral filtering to temporal data , and there are two natural choices .",
    "first , one can simply attach a frame index @xmath21 as an additional time dimension to the input data , yielding a six dimensional feature vector @xmath33 for every pixel in every frame .",
    "the summation in eq .",
    "[ eq : wtimesv ] now runs over _ all _ previous frames and pixels .",
    "imagine a video where an object moves to reveal some background .",
    "pixels of the object and background will be close spatially @xmath34 and temporally @xmath35 but likely be of different color @xmath36 .",
    "therefore they will have no strong influence on each other ( being splatted to distant positions in the six - dimensional bilateral space ) . in summary",
    ", one can understand the filter to be adaptive to color changes across frames , only pixels that are static and have similar color have a strong influence on each other ( end up nearby in the lattice space ) .",
    "the second possibility is to use optical flow .",
    "if the perfect flow is available , the video frames could be warped into a common frame of reference .",
    "this would resolve the corresponding problem and make information propagation much easier .",
    "we can make use of an optical flow estimate by warping pixel positions @xmath34 by their displacement vector @xmath37 to @xmath38 .",
    "another property of permutohedral filtering that we exploit is that the _ input points need not lie on a regular grid _ since the filtering is done in the high - dimensional lattice . instead of splatting millions of pixels on to the lattice , we randomly sample or use superpixels and perform filtering using these sampled points as input to the filter . in practice",
    ", we observe that this results in big computational gains with minor drop in performance ( more in section  [ sec : videoseg ] ) .    * learnable bilateral filters * the property of propagating information forward using a guidance image through filtering solves the problem of pixel association .",
    "but a gaussian filter may be insufficient and further , we would like to increase the capacity by using a filter bank instead of a single fixed filter .",
    "we propose to use the technique of  @xcite to learn the filter values in the permutohedral lattice using back - propagation .",
    "the process works as follows .",
    "a input video is used to determine the positions in the bilateral space to splat the input points @xmath39 i.e. , the features @xmath7 ( e.g. @xmath40 ) define the splatting matrix @xmath12 .",
    "this leads to a number of vectors @xmath41 , that lie on the permutohedral lattice , with dimensionality @xmath42 . in effect , the splatting operation groups points that are close together , that is , they have similar @xmath4 .",
    "all lattice points are now filtered using a filter bank @xmath43 which results in @xmath44 dimensional vectors on the lattice points .",
    "these are sliced back to the @xmath30 points of interest ( present video frame ) .",
    "the values of @xmath14 are learned by back - propagation .",
    "general parametrization of @xmath14 from  @xcite allows to have any neighborhood size for the filters .",
    "since constructing the neighborhood structure in high - dimensions is time consuming , we choose to use @xmath45 filters for speed reasons .",
    "this makes up one _ bilateral convolution layer ( bcl ) _ which we will stack and concatenate to form a bilateral network .",
    "see fig .",
    "[ fig : filter_illustration ] for an illustration of a bcl .    * bnn architecture * the bilateral network ( bnn ) is illustrated in the green box of fig .",
    "[ fig : net_illustration ] .",
    "the input is a video sequence @xmath46 and the corresponding predictions @xmath47 up to frame @xmath21 .",
    "those are filtered using two bcls with @xmath48 filters each . for both bcls",
    ", we use the same features @xmath7 but scale them with different diagonal matrices @xmath49 .",
    "the feature scales are found by cross - validation .",
    "the two @xmath48 dimensional outputs are concatenated , passed through a relu non - linearity and passed to a second layer of two separate bcl filters that uses same feature spaces @xmath50 .",
    "the output of the second filter bank is then reduced using a @xmath51 spatial filter ( c-1 ) to map to the original dimension of @xmath0 .",
    "we investigated scaling frame inputs with an exponential time decay and found that , when processing frame @xmath21 , a re - weighting with @xmath52 with @xmath53 improved the performance a little bit .    in the experiments ,",
    "we also included a simple bnn variant , where no filters are applied inside the permutohedral space , just splatting and slicing with the two layers @xmath54 and @xmath55 and adding the results .",
    "we will refer to this model as _ bnn - identity _ , it corresponds to an image adaptive smoothing of the inputs @xmath47 .",
    "we found this filtering to have a positive effect and include it as a baseline in our experiments .",
    "the bnn was designed to propagate the information from the previous frames , respecting the scene and object motion .",
    "we then add a small spatial cnn with 3 layers , each with @xmath48 filters of size @xmath56 , interleaved with relu non - linearities .",
    "the final result is then mapped to the desired output of @xmath20 using a @xmath51 convolution .",
    "the main role of this spatial cnn is to refine the information in frame @xmath21 .",
    "depending on the problem and the size of the available training data , other network designs are conceivable .",
    "we use the same network architecture shown in fig .",
    "[ fig : net_illustration ] for all the experiments to demonstrate the generality of vpns .",
    "we evaluated vpn on three different propagation tasks : foreground masks , semantic labels and color information in videos .",
    "our implementation runs in caffe  @xcite using standard settings .",
    "we used adam  @xcite stochastic optimization for training vpns , multinomial - logistic loss for label propagation networks and euclidean loss for training color propagation networks .",
    "runtime computations were performed using a nvidia titanx gpu and a 6 core intel i7 - 5820k cpu clocked at 3.30ghz machine .",
    "we will make available all the code and experimental results .",
    "the task of class - agnostic video object segmentation aims to segment foreground objects in videos .",
    "since the semantics of the foreground object is not pre - defined , this problem is usually addressed in a semi - supervised manner .",
    "the goal is to propagate a given foreground mask of the first frame to all the video frames .",
    "object segmentation in videos is useful for several high level tasks such as video editing , summarization , rotoscoping etc .",
    "[ [ dataset ] ] dataset + + + + + + +    we use the recently published davis dataset  @xcite for experiments on this task .",
    "the davis dataset consists of 50 high - quality ( 1080p resolution ) unconstrained videos with number of frames in each video ranging from 25 to 104 .",
    "all the frames come with high - quality per - pixel annotation of the foreground object .",
    "the videos for this dataset are carefully chosen to contain motion blur , occlusions , view - point changes and other occurrences of object segmentation challenges .",
    "for robust evaluation and to get results on all the dataset videos , we evaluate our technique using 5-fold cross - validation .",
    "we randomly divided the data into 5 folds , where in each fold , we used 35 images for training , 5 for validation and the remaining 10 for the testing .",
    "for the evaluation , we used the 3 metrics that are proposed in  @xcite : intersection over union ( iou ) score , contour accuracy ( @xmath25 ) score and temporal instability ( @xmath57 ) score .",
    "the widely used iou score is defined as @xmath58 , where tp : true positives ; fn : false negatives and fp : false positives .",
    "please refer to  @xcite for the definition of the contour accuracy and temporal instability scores .",
    "we are aware of some other datasets for this task such as jumpcut  @xcite and segtrack  @xcite , but we note that the number of videos in these datasets is too small for a learning based approach .",
    "p2.0cm > p0.6 cm > p0.6cm > p0.6cm > p0.6cm > p0.6 cm > p0.6 cm & f-1 & f-2 & f-3 & f-4 & f-5 & all + [ 0.1 cm ] bnn - identity & 56.4 & 74.0 & 66.1 & 72.2 & 66.5 & 67.0 + vpn - stage1 & 58.2 & 77.7 & 70.4 & 76.0 & 68.1 & 70.1 + vpn - stage2 & * 60.9 * & * 78.7 * & * 71.4 * & * 76.8 * & * 69.0 * & * 71.3 * +   +    [ tbl : davis - folds ]    p3.2cm > p0.6 cm > p0.6cm > p0.6cm > p1.2 cm & _ iou@xmath59 _ & @xmath60 & @xmath61 & _ runtime_(s ) + [ 0.1 cm ] bnn - identity & 67.0 & 67.1 & 36.3 & 0.21 + vpn - stage1 & 70.1 & 68.4 & 30.1 & 0.48 + vpn - stage2 & 71.3 & 68.9 & 30.2 & 0.75 + & + deeplab & 57.0 & 49.9 & 47.8 & 0.15 + vpn - deeplab & * 75.0 * & * 72.4 * & 29.5 & 0.63 + ofl  @xcite & 71.1 & 67.9 & 22.1 & @xmath6260 + bvs  @xcite & 66.5 & 65.6 & 31.6 & 0.37 + nlc  @xcite & 64.1 & 59.3 & 35.6 & 20 + fcp  @xcite & 63.1 & 54.6 & 28.5 & 12 + jmp  @xcite & 60.7 & 58.6 & * 13.2 * & 12 + hvs  @xcite & 59.6 & 57.6 & 29.7 & 5 + sea  @xcite & 55.6 & 53.3 & 13.7 & 6 +   +    [ tbl : davis - main ]    [ [ vpn - and - results ] ] vpn and results + + + + + + + + + + + + + + +    in this task , we only have access to foreground mask for the first frame @xmath63 . for the ease of training vpn",
    ", we obtain initial set of predictions with _ bnn - identity_. we sequentially apply _ bnn - identity _ at each frame and obtain an initial set of foreground masks for the entire video .",
    "these bnn - identity propagated masks are then used as inputs to train a vpn to predict the refined masks at each frame .",
    "we refer to this vpn model as _ vpn - stage1_. once vpn - stage1 is trained , its refined training mask predictions are in - turn used as inputs to train another vpn model which we refer to as _ vpn - stage2_. this resulted in further refinement of foreground masks . training further stages did not result in any improvements .",
    "2 million points from the previous 5 frames . ]",
    "[ fig : acc_vs_points ]        [ fig : video_seg_visuals ]    following the recent work of  @xcite on video object segmentation , we used scaled features @xmath64 with ycbcr color features for bilateral filtering . to be comparable with the one of the fastest state - of - the - art technique  @xcite , we do not use any optical flow information .",
    "first , we analyze the performance of bnn - identity by changing the number of randomly sampled input points .",
    "figure  [ fig : acc_vs_points ] shows how the segmentation iou changes with the increase in the number of sampled points ( out of 2 million points ) from the previous frames .",
    "the iou levels out after sampling 25% of points . for further computational efficiency , we used superpixel sampling instead of random sampling .",
    "usage of superpixels reduced the iou slightly ( 0.5% ) , while reducing the number of input points by a factor of 10 in comparison to a large number of randomly sampled points .",
    "we used 12000 slic  @xcite superpixels from each frame computed using the fast gpu implementation from  @xcite . for predictions at each frame , we input mask probabilities of previous 9 frames into vpn as we observe no significant improvements with more frames .",
    "we set @xmath65 to @xmath66 and the feature scales for bilateral filtering are presented in tab .",
    "[ tbl : parameters_supp ] .",
    "table  [ tbl : davis - folds ] shows the iou scores for each of the 5 folds and tab .",
    "[ tbl : davis - main ] shows the overall scores and runtimes of different vpn models along with the best performing segmentation techniques .",
    "the performance improved consistently across all 5 folds with the addition of new vpn stages .",
    "bnn - identity already performed reasonably well . and with 1-stage and 2-stage vpns",
    ", we outperformed the present fastest bvs method  @xcite by a significant margin on all the performance measures of iou , contour accuracy and temporal instability scores , while being comparable in runtime .",
    "we perform marginally better than ofl method  @xcite while being at least 80@xmath67 faster and ofl relies on optical flow whereas we obtain similar performance without using any optical flow .",
    "further , vpn has the advantage of doing online processing as it looks only at previous frames whereas bvs processes entire video at once .",
    "one can obtain better vpn performance with using better superpixels and also incorporating optical flow , but this increases runtime as well .",
    "figure  [ fig : video_seg_visuals ] shows some qualitative results and more are present in figs .  [ fig : video_seg_small_supp ] ,  [ fig : video_seg_pos_supp ] .",
    "a couple of failure cases are shown in fig .",
    "[ fig : video_seg_neg_supp ] .",
    "visual results indicate that learned vpn is able to retain foreground masks even with large variations in viewpoint and object size .",
    "[ [ augmenation - of - pre - trained - models ] ] augmenation of pre - trained models : + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    one of the main advantages of the proposed vpn architecture is that it is end - to - end trainable and can be easily integrated into other deep neural network architectures . to demonstrate this , we augmented vpn architecture with standard deeplab segmentation architecture from  @xcite .",
    "we replaced the last classification layer of deeplab - largefov model from  @xcite to output 2 classes ( foreground and background ) in our case and bi - linearly up - sampled the resulting low - resolution probability map to the original image dimension .",
    "5-fold fine - tuning of the deeplab model on davis dataset resulted in the iou of 57.0 and other scores are shown in tab .",
    "[ tbl : davis - main ] .",
    "then , we combine the vpn and deeplab models in the following way : the outputs from the deeplab network and the bilateral network are concatenated and then passed on to the spatial network .",
    "in other words , the bilateral network propagates label information from previous frames to the present frame , whereas the deeplab network does the prediction for the present frame .",
    "the results of both are then combined and refined by the spatial network in the vpn architecture .",
    "we call this ` vpn - deeplab ' model .",
    "we trained this model end - to - end and observed big improvements in performance .",
    "as shown in tab .",
    "[ tbl : davis - main ] , the vpn - deeplab model has the iou score of 75.0 and contour accuracy score of 72.4 resulting in significant improvements over the published results . since deeplab has also fast runtime , the total runtime of vpn - deeplab is only 0.63s which makes this also one of the fastest video segmentation systems .",
    "a couple of visual results of vpn - deeplab model are shown in fig .",
    "[ fig : video_seg_visuals ] and more are present in figs .",
    "[ fig : video_seg_small_supp ] ,  [ fig : video_seg_pos_supp ] and  [ fig : video_seg_neg_supp ] .",
    "a semantic video segmentation assigns a semantic label to every video pixel .",
    "since the semantics between adjacent frames does not change radically , intuitively , propagating semantic information across frames should improve the segmentation quality of each frame . unlike mask propagation in the previous section where the ground - truth mask for the first frame is given , we approach semantic video segmentation in a fully automatic fashion . specifically , we start with the unary predictions of standard cnns and use vpn for propagating semantics across the frames .",
    "[ [ dataset-1 ] ] dataset + + + + + + +    we use the camvid dataset @xcite that contains 4 high quality videos captured at 30hz while the semantically labeled 11-class ground truth is provided at 1hz . while the original dataset comes at a resolution of 960@xmath67720 , similar to previous works  @xcite , we operate on a resolution of 640@xmath67480 .",
    "we use the same splits proposed in  @xcite resulting in 367 , 100 and 233 frames with ground truth for training , validation and testing .",
    "following common practice , we report the iou scores for evaluation .    [ [ vpn - and - results-1 ] ] vpn and results + + + + + + + + + + + + + + +    since we already have cnn predictions for every frame , we train a vpn that takes the cnn predictions of previous _ and _ present frames as input and predicts the refined predictions for the present frame .",
    "we compare with the state - of - the - art crf approach for this problem  @xcite which we refer to as fso - crf .",
    "following  @xcite , we also experimented with optical flow in our framework and refer that model as _ vpn - flow_. we used the fast optical flow method that uses dense inverse search  @xcite to compute flows and modify the positional features of previous frames .",
    "we used the superpixels method of dollar et al .",
    "@xcite for this dataset as gslicr  @xcite has introduced artifacts .",
    "p3.5cm > p1.2cm > p1.5 cm & _ iou _ & _ runtime_(s ) + [ 0.1 cm ] cnn from  @xcite & 65.3 & 0.38 + + fso - crf  @xcite & 66.1 & * * @xmath62**10 + + bnn - identity & 65.3 & 0.31 + + bnn - identity - flow & 65.5 & 0.33 + + vpn ( ours ) & 66.5 & 0.35 + + vpn - flow ( ours ) & * 66.7 * & 0.37 + cnn from  @xcite & 68.9 & 0.30 + + vpn - flow ( ours ) & * 69.5 * & 0.38 +   +    [ tbl : camvid ]    we experimented with predictions from two different cnns : one is with dilated convolutions  @xcite ( cnn-1 ) and another one  @xcite ( cnn-2 ) is trained with the additional data obtained from a video game , which is the present state - of - the - art on this dataset . for cnn-1 and cnn-2 , using 2 and 3 previous frames respectively as input to vpn is found to be optimal .",
    "other parameters of the bilateral network are presented in tab .",
    "[ tbl : parameters_supp ] .",
    "table  [ tbl : camvid ] shows quantitative results on this dataset . using bnn - identity",
    "only slightly improved the cnn performance whereas training the entire vpn significantly improved the cnn performance by over 1.2% iou , with both vpn and vpn - flow networks .",
    "moreover , vpn is at least 25@xmath67 faster , and simpler to use compared to the optimization based fso - crf which relies on ldof optical flow  @xcite , long - term tacks  @xcite and edges  @xcite .",
    "we further improved the performance of the state - of - the - art cnn  @xcite with the use of vpn - flow model .",
    "using better optical flow estimation might give even better results .",
    "figure  [ fig : semantic_visuals ] shows some qualitative results and more are presented in fig .",
    "[ fig : semantic_visuals_supp ] .",
    "[ fig : semantic_visuals ]      we also evaluate vpns on a different kind of information and experimented with propagating color information in a grayscale video .",
    "given the color image for the first video frame , the task is to propagate the color to the entire video .",
    "note that this task is fundamentally different from automatic colorization of images for which recent cnn based based methods have become popular . for experiments on this task",
    ", we again used the davis dataset  @xcite with the first 25 frames from each video .",
    "we randomly divided the dataset into 30 train , 5 validation and 15 test videos .",
    "we work with ycbcr representation of images and propagate cbcr values from previous frames with pixel intensity , position and time features as guidance for vpn .",
    "the same strategy as in object segmentation is used , where an initial set of color propagated results was obtained with bnn - identity and then used to trained a vpn - stage1 model .",
    "training further vpn stages did not improve the performance .",
    "table  [ tbl : color ] shows the psnr results .",
    "we use 300k randomly sampled points from previous 3 frames as input to the vpn network .",
    "we also show a baseline result of  @xcite that does graph based optimization and uses optical flow .",
    "we used fast dis optical flow  @xcite in the baseline method  @xcite and we did not observe significant differences with using ldof optical flow  @xcite .",
    "figure  [ fig : color_visuals ] shows a visual result with more in fig .  [ fig : color_visuals_supp ] . from the results ,",
    "vpn works reliably better than  @xcite while being 20@xmath67 faster .",
    "the method of  @xcite relies heavily on optical flow and so the color drifts away with incorrect flow .",
    "we observe that our method also bleeds color in some regions especially when there are large viewpoint changes .",
    "we could not compare against recent video color propagation techniques such as  @xcite as their codes are not available online .",
    "this application shows general applicability of vpns in propagating different kinds of information .",
    "p2.5cm > p1.2cm > p1.5 cm & _ psnr _ & _ runtime_(s ) + [ 0.1 cm ] bnn - identity & 27.89 & 0.29 + vpn - stage1 & * 28.15 * & 0.90 + levin et al .",
    "@xcite & 27.11 & 19 +   +    [ tbl : color ]        [ fig : color_visuals ]",
    "we proposed a fast , scalable and generic neural network based learning approach for propagating information across video frames .",
    "the video propagation network uses bilateral network for long - range video - adaptive propagation of information from previous frames to the present frame which is then refined by a standard spatial network .",
    "experiments on diverse tasks show that vpns , despite being generic , outperformed the current state - of - the - art task - specific methods . at the core of our technique",
    "is the exploitation and modification of learnable bilateral filtering for the use in video processing .",
    "we used a simple and fixed network architecture for all the tasks for showcasing the generality of the approach .",
    "depending on the type of problems and the availability of data , using more filters and deeper layers would result in better performance . in this work",
    ", we manually tuned the feature scales which could be amendable to learning . finding optimal yet fast - to - compute bilateral features for videos together with the learning of their scales is an important future research direction .",
    "in this appendix , we present experiment protocols and additional qualitative results for experiments on video object segmentation , semantic video segmentation and video color propagation . table  [ tbl : parameters_supp ] shows the feature scales and other parameters used in different experiments .",
    "figures  [ fig : video_seg_small_supp ] ,  [ fig : video_seg_pos_supp ] show some qualitative results on video object segmentation with some failure cases in fig .",
    "[ fig : video_seg_neg_supp ] .",
    "figure  [ fig : semantic_visuals_supp ] shows some qualitative results on semantic video segmentation and fig .",
    "[ fig : color_visuals_supp ] shows results on video color propagation .",
    "l3.2 cm l3.0 cm l2.8 cm l2.8 cm c0.5 cm c1.0 cm l1.2 cm * experiment * & * feature type * & * feature scale-1 , @xmath68 * & * feature scale-2 , @xmath69 * & * @xmath65 * & * input frames * & * loss type * + * video object segmentation * & ( @xmath70 ) & ( 0.02,0.02,0.07,0.4,0.4,0.01 ) & ( 0.03,0.03,0.09,0.5,0.5,0.2 ) & 0.5 & 9 & logistic + * semantic video segmentation * & & & & & + * with cnn1  @xcite - noflow * & ( @xmath71 ) & ( 0.08,0.08,0.2,0.2,0.2,0.04 ) & ( 0.11,0.11,0.2,0.2,0.2,0.04 ) & 0.5 & 3 & logistic + * with cnn1  @xcite - flow * & ( @xmath72 ) & ( 0.11,0.11,0.14,0.14,0.14,0.03 ) & ( 0.08,0.08,0.12,0.12,0.12,0.01 ) & 0.65 & 3 & logistic + * with cnn2  @xcite - flow * & ( @xmath72 ) & ( 0.08,0.08,0.2,0.2,0.2,0.04 ) & ( 0.09,0.09,0.25,0.25,0.25,0.03 ) & 0.5 & 4 & logistic + * video color propagation * & ( @xmath73 ) & ( 0.04,0.04,0.2,0.04 ) & no second kernel & 1 & 4 & mse +   +"
  ],
  "abstract_text": [
    "<S> in this paper we propose a technique that propagates information forward through video data . </S>",
    "<S> the method is conceptually simple and can be applied to tasks that require the propagation of structured information , such as semantic labels , based on video content . </S>",
    "<S> we propose a _ video propagation network _ that processes video frames in an adaptive manner . </S>",
    "<S> the model is applied online : it propagates information forward without the need to access future frames other than the current ones . </S>",
    "<S> in particular we combine two components , a temporal bilateral network for dense and video adaptive filtering , followed by a spatial network to refine features and increased flexibility . </S>",
    "<S> we present experiments on video object segmentation and semantic video segmentation and show increased performance comparing to the best previous task - specific methods , while having favorable runtime . </S>",
    "<S> additionally we demonstrate our approach on an example regression task of propagating color in a grayscale video . </S>"
  ]
}