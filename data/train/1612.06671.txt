{
  "article_text": [
    "authors write texts in a location , about something in a location ( or about the location itself ) , reside and conduct their business in various locations , and have a background in some location .",
    "some texts are personal , anchored in the here and now , where others are general and not necessarily bound to any context .",
    "texts written by authors reflect the above facts explicitly or implicitly , through explicit author intention or incidentally .",
    "when a text is locational , it may be so because the author mentions some location or because the author is contextually bound to some location . in both cases ,",
    "the text may or may not have explicit mentions of the context of the author or mention other locations in the text .    for some applications , inferring the location of a text or its author automatically is of interest .",
    "we present in this paper how establishing the location of a text can be done by the locational qualities of the terminology used by its author . here , we investigate the utility of doing so for two distinct use cases .",
    "firstly , for detecting regional language usage for the purposes of real - time dialectology .",
    "the issue here is to find differences in term usage across locations and to investigate whether terminological variation differs across regions . in this case , the ultimate objective is to collect sizeable text collections from various regions of a linguistic area to establish if a certain term or turn of phrase is used more or less frequently in some specific region .",
    "the task is then to establish where the author of a text originally is from .",
    "this has hitherto been investigated by manual inspection of text collections .",
    "* e.g. )    secondly , for monitoring public opinion of e.g. brands , political issues , or other topic of interest . in this case",
    "the ultimate objective is to find whether there is a regional variation for the occurrence of opinionated mentions for the topic or topical target under consideration .",
    "the task is then to establish the location where a given text is written , or , alternatively , what location the text refers to .    in both cases ,",
    "the system is presented with a body of text with the task of assigning a likely location to it . in the former task ,",
    "typically the body of text is larger and noisier ( since authors may refer to other locations than their immediate context ) ; in the second task , the text may be short and have little evidence to work from . both tasks , that of identifying the location of an author , or that of a text , have been addressed by recent experiments with various points of departure : knowledge - based , making use of recorded points of interest in a location , modelling the geographic distribution of topics , or using social network analysis to find additional information about the author .",
    "this set of experiments focuses on the text itself and on using distributional semantics to refine the set of terms used for locating a text .",
    "most words contribute little or not at all to positioning text .",
    "some words are dead giveaways : an author may mention a specific location in the text . frequently , but not always , this is reasonable evidence of position .",
    "some words are less patently locational , but contribute incidentally , such as the name of some establishment or some characteristic feature of a location .",
    "some locational terms are polysemous ; some inspecific ; some are vague .",
    "as indicated in figure  [ termtypes ] , the term _ falkping _ unambiguously indicates a town in _ southern sweden _ , which in turn is a vague term without a clear and well defined border to other bits of sweden . the term _ sdermalm _ is polysemous and refers to a section of town in several swedish towns ; the term _ sprvagn _ ( `` tram '' ) is indicative of one of several swedish towns with tram lines .",
    "we call both of these latter types of term _ polylocational _ and allow them to contribute to numerous places simultaneously .",
    "other words contribute variously to location of a text .",
    "some words are less patently locational than named places , but contribute incidentally , such as the name of some establishment , some characteristic feature of a location , some event which takes place in some location , or some other topic the discussion of which is more typical in one location than in another .",
    "we will estimate the _ placeness _ of words in these experiments .",
    "we , as has been done in previous experiments , collect the geographic distribution of word usage through collecting microblog posts , some of which have longitude and latitude , from twitter . posts with location information are distributed over a map in what amounts to a continuous representation .",
    "the words from posts can be collected and associated with the positions they have been observed in .",
    "first experiments which use similar training data to ours have typically assigned the posts and thus the words they occur in directly to some representation of locations - a word which occurs in tweets at @xmath0 $ ] and @xmath1 $ ] will have both observations recorded to be in the same city @xcite . an alternative and later approach by e.g. @xcite is to aggregate all observations of a word over a map and assign a named location to the distribution , rather than to each observation , deferring the labeling to a point in the analysis where more understanding of the term distribution is known .",
    "another approach is to model _ topics _ as inferred from vocabulary usage in text across their geographical distribution , and then , for each text , to assess the topic and thus its attendant location visavi the topic model most likely to have generated the text in question @xcite .",
    "we have found that topic models as implemented are computationally demanding , do not add accuracy to prediction , and have little explanatory value to aid the understanding of localised language use .    in these experiments",
    "we will compare using a list of known places with a model where we aggregate the locational information provided by words ( and potentially other linguistic items such as constructions ) trained on longitude and latitude either by letting the words vote for place or by averaging the information on a word - by - word basis .",
    "the latter model defers the mapping to place until some analysis has been performed ; the former assigns place to the words earlier in the process .",
    "these experiments have focused on swedish - language material and on swedish locations .",
    "most swedish - speakers live in sweden ; swedish is mainly written and spoken in sweden and in finland .",
    "sweden is a roughly rectangular country of about @xmath2 as shown in figure  [ swedenmap ] .",
    "sweden has since 1634 been organised into 22 counties or _ ln _ of between @xmath3 and @xmath4 .",
    "the median size of a county is @xmath5 which would , assuming quadratic counties , give a side of @xmath6 for a typical county .",
    "we measure accuracy of textual location using the _ haversine distance _ ,",
    "the great - circle distance between two points on a sphere .",
    "we report averages , both mean and median , as well as percentage of texts we have located within @xmath6 from their known position .",
    "our test data set is composed of social media texts .",
    "firstly , 18 gb of blog text from major swedish blog and forum sites , with self - reported location by author - variously , home town , municipality , village , or county .",
    "the texts are mainly personal texts with authors of all ages but with a preponderance of pre - teens to young adults .",
    "the data are from 2001 and onward , with more data from the latest years .",
    "the data are concatenated into one document per blog , totalling to @xmath7 documents from unique sources .",
    "somewhat more than a third , 35% , have more than 10k characters .",
    "secondly , 37 gb of blog text without any explicit indication of location .",
    "a target task for these experiments is to enrich these 37 gb of non - located data with predicted location , in order to address data sparsity for unusual dialectal linguistic items .",
    "for a list of known places we used a list of 1  956 swedish cities and 2  920 towns and villages as defined by statistics sweden ] in 2010 .    as the most obvious baseline , we identify all tokens found in the gazetteer .",
    "each such token is converted to a position through the geoencoding api offered by google ] .",
    "the position with largest observed frequency of occurrence in the text is assumed to be the position of the text .",
    "other approaches have taken this as a useful approach for identifying features such as places of interest mentioned in texts @xcite .",
    "we call this approach the gazetteer approach .",
    "as a basis for learning how words were used we used geotagged microblog data from twitter .",
    "about 2% of swedish twitter posts have latitude and longitude explicitly given , typically those that have been posted from a mobile phone .",
    "we gathered data from twitter s streaming api during the months of may to august of 2014 , saving posts with latitude and longitude and with sweden explicitly given as point of origin .",
    "this gave us 4  429  516 posts of about 630 mb .",
    "given a set of geographically located texts , we record for each linguistic item  meaning word , in these experiments  the locations from the metadata of every text it occurs in .",
    "this gives each word a mapped geographic distribution of latitude - longitude pairs .",
    "we model these observed distributions using gaussian 2-d functions , as defined by @xcite .",
    "a 2-d gaussian function will assume a peak at some position and allow for a graceful inclusion of hits at nearby positions into the model in a bell - like distribution .",
    "in contrast to the original definition and and other similar following approaches , we want to be able to handle polylocational words . after testing various models on a subset of our data we find that fitting more than one gaussian function  in effect , assuming that locationally interesting words refer to several locations ",
    "yields better results than fitting all locational data into one distribution .",
    "after some initial parameter exploration as shown in figure  [ polygauss ] , we settle on three gaussian functions as a reasonable model : words with more than three distributional peaks are likely to be of less utility for locating texts .",
    "we consequently fit each word with three gaussian functions to allow a word to contribute to many locations for the texts it is observed in .",
    "in keeping with previous research on geolocational terms such as @xcite , we rank candidate words for their locational specificity . from the gaussian mixture model representation ,",
    "we take the log probability @xmath8 in the mean of the gaussian and transform it into a _ placeness _",
    "score by @xmath9 .",
    "this is done for every word , for all three gaussians .",
    "the score is then used to rank words for locational utility .",
    ".example words and their log placeness [ cols=\"^,^,^,^,^ \" , ]     0.35     0.35     0.75     0.75",
    "we run one experimental setting with all words of a set , only filtered for placeness .",
    "we call this approach the total approach .    as a more informed model ,",
    "we filter the words in the feature set to find the most locationally appropriate terms , in order to reduce noise and computational effort , but above all , in keeping with our hypothesis that the locational signal is present in only part of the texts . @xcite and following them , @xcite , using similar data as we do , also limit their analyses to `` local '' rather than `` non - local '' words in the text matter they process , modeling word locality through observed occurrences , modulated with some geographical smoothing . to find the most appropriate localised linguistic items , we bootstrap from the gazetteer and collect the most distinctive distributional contexts of gazetteer terms .",
    "for this , we used context windows of six words before ( @xmath10 ) , around ( @xmath11 ) , and after ( @xmath12 ) each target word .",
    "these context windows were tabulated and the most frequently occurring constructions are then ranked based on their ability to return words with high placeness . for each construction ,",
    "the percentage of words returned with @xmath13 is used as a ranking criterion . using this ranking ,",
    "the top 150 constructions are retained as a paradigmatic filter to generate usefully locational words .",
    "constructions such as lives in < location > will be at the top of the list .",
    "examples are given in figure  [ patternexamples ] .",
    "0.23 mellan + varit i < location > + bor i < location > + var",
    "i < location > + vi till < location > + in till < location > + ska till < location > + < location > centrum + av till < location > + det av till < location > + hemma",
    "i < location > + till < location > + upp till < location >    0.20 between + been in < location > + live(s ) in < location > + was in < location > + we to < location >",
    "+ in to < location >",
    "+ going to < location > + < location > centre + off to < location > + go to < location > + home in < location > + to < location > + up to < location >    words found in the slot of the constructions are frequency filtered with respect to @xmath14 , the length of the text under analysis , with thresholds set by experimentation to @xmath15 .",
    "this reduces the number of gaussian models to evaluate drastically .",
    "each text under consideration was then filtered to only include words found through the above procedure , reducing the size of the texts to about 6% of the original .",
    "the filtered texts are now processed in two different ways .",
    "every unique word token in the twitter dataset has a gaussian mixture model @xmath16 based on its observed occurrences , as shown in section  [ placeness ] .",
    "this is represented by the three mean coordinates @xmath17 and their corresponding _",
    "placenesses _ @xmath18 .",
    "@xmath19    we compute a centroid for these coordinates , as an average best guess for geographic signal for a text .",
    "we do this with an arithmetic weighted mean",
    ". given @xmath20 words :    @xmath21    where @xmath22 is the dot product for this specific case . ] .",
    "we call this model filtered centroid    alternatively , we do not average the coordinates , but select by weighted majority vote .",
    "we divide sweden into a grid of roughly 50x50 km cells .",
    "the placeness score of every locational word in a text is added to its cell .",
    "the centerpoint of the cell with highest score is assigned to the text as a location .",
    "we call this model filtered vote .    figure  [ gridexample ] shows how filtering improves results , here illustrated by the filtered vote model .",
    "the top map shows how every word of a text contributes votes , weighted by their placeness , to give a prediction ( ) .",
    "the bottom map shows how when only words filtered through the distributional model are used , the voting yields a correct result in comparison with the gold standard ( ) given by the metadata .",
    "as shown in table  [ testspec ] and figure  [ comptests ] , the gaussian models filtered centroidand filtered voteoutperform the gazetteer modelhandily . filtering words distributionally , in addition to reducing processing ,",
    "improves results further .",
    "the filtered centroid modelis slightly better than the filtered vote model , providing support for late discretization of locational information",
    ". a closer look at the effect , shown in table  [ testspec2 ] and in figure  [ compthresholds ] , of feature selection with the placeness threshold shows the precision - recall tradeoff contingent on reducing the number of accepted locational words .",
    "these results are well comparable with the results reported by others : while direct comparison with other linguistic and geographic areas is difficult , @xcite set a 100-mile ( @xmath23 160 km ) success criterion for a similar task of geo - locating microblog authors ( not single posts ) .",
    "they find that about 10% of microblog users can be localised within their 100-mile radius .",
    "@xcite found they could on average achieve a 900 km accuracy for texts or a 24% accuracy on a us state level .",
    "returning to our use case we now use the filtered centroid modelto position and thus enrich a further 38% of our unlabeled blog collection with a location tag ( setting the placeness threshold @xmath24 ) .",
    "this gives a noticeably better resolution for studying regional word usage as shown in figure  [ cousinmap ] : the term for `` second cousin '' varies across dialects , and given the enriched data set we are able to gain better frequencies and a more distinct image of usage .",
    "we find that    * modelling geographical distribution of linguistic items with multiple ( in this case , three ) peaks proved useful ; * filtering locationally indicative linguistic items using distributional constructions proved useful ; * modelling the placeness of locational linguistic items for thresholding proved useful ; * training a locational model on positionally annotated microblog posts was a useful bootstrap for assigning location to texts of an entirely different genre ; * we are able to detect and explore regional variation in terminological usage .",
    "this work was in part supported by the grant sinus ( spridning av innovationer i nutida svenska ) from vetenskapsrdet , the swedish research council .        zhiyyan cheng , james caverlee , and kyumin lee .",
    "you are where you tweet : a content - based approach to geo - locating twitter users . in _ proceedings of the 19th acm international conference on information and knowledge management _",
    "( cikm ) acm , 2010 .",
    "jacob eisenstein , brendan oconnor , noah  a smith , and eric  p xing . a latent variable model for geographic lexical variation .",
    "in _ proceedings of the conference on empirical methods in natural language processing _ , ( emnlp ) .",
    "acl , 2010 .",
    "liangjie hong , amr ahmed , siva gurumurthy , alexander  j smola , and kostas tsioutsiouliklis .",
    "discovering geographical topics in the twitter stream . in _ proceedings of the 21st international conference on the www_. acm , 2012 .",
    "sheila kinsella , vanessa murdock , and neil ohare .",
    "i m eating a sandwich in glasgow : modeling locations with tweets . in _ proceedings of the 3rd international workshop on search and mining user - generated contents_. acm , 2011 .",
    "jalal mahmud , jeffrey nichols , and clemens drews .",
    "where is this tweet from ? inferring home locations of twitter users . in _ proceedings of the 6th international aaai conference on web and social media _",
    ", 2012 .",
    "reid priedhorsky , aron culotta , and sara  y del  valle . inferring the origin locations of tweets with quantitative confidence . in _ proceedings of the 17th acm conference on computer",
    "supported cooperative work & social computing _ , acm , 2014 ."
  ],
  "abstract_text": [
    "<S> for the purposes of computational dialectology or other geographically bound text analysis tasks , texts must be annotated with their or their authors location . </S>",
    "<S> many texts are locatable but most have no explicit annotation of place . </S>",
    "<S> this paper describes a series of experiments to determine how positionally annotated microblog posts can be used to learn location indicating words which then can be used to locate blog texts and their authors . a gaussian distribution is used to model the locational qualities of words . </S>",
    "<S> we introduce the notion of placeness to describe how locational words are .    </S>",
    "<S> we find that modelling word distributions to account for _ several locations _ and thus several gaussian distributions per word , defining a filter which picks out words with high placeness based on their _ local distributional context _ , and aggregating locational information in a _ centroid _ for each text gives the most useful results . </S>",
    "<S> the results are applied to data in the swedish language . </S>"
  ]
}