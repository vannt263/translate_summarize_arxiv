{
  "article_text": [
    "the calculation of confidence intervals in case of presence of systematic uncertainties is an open problem .",
    "systematic uncertainties are those uncertainties present in parameters which will affect the calculated confidence interval , but which are not of prime interest , so called _ nuisance parameters .",
    "_ examples for nuisance parameters are the efficiency or the predicted background rate . + in 1992",
    "cousins & highland @xcite proposed a method which is based on a bayesian treatment of the nuisance parameters .",
    "they proposed to perform a frequentist construction ( following neyman @xcite ) and to replace the probability density function ( pdf ) describing the statistical process of prime interest with a pdf which is obtained by a convolution the original pdf with the one describing the uncertainties in the nuisance parameters : @xmath0 where @xmath1 is the true value of the nuisance parameter , @xmath2 denotes its estimate and @xmath3 and @xmath4 symbolize the signal hypothesis and the experimental outcome respectively .",
    "+ highland & cousins only treated the case of gaussian uncertainties in the signal efficency .",
    "the method has since been generalized to operate with the modern unified ordering scheme proposed by feldman & cousins @xcite and taking into account several nuisance parameters ( efficiencies and background ) and correlations @xcite .",
    "this generalized method has already been used in a number of particle and astroparticle physics experiments ( e.g. @xcite @xcite @xcite , @xcite , @xcite ) . + the most crucial property of methods for confidence interval construction is the coverage , which states : +   + _ a method is said to have coverage ( 1-@xmath5 ) if , in infinitely many repeated experiments the resulting confidence interval includes the true value with probability ( 1-@xmath5 ) irrespective of what the true value is . _ +   + 100(1-@xmath5)% is hereby commonly taken to be 68% 90% , 95% etc .",
    "recently , the coverage properties of a fully frequentist method , the profile likelihood method , have been studied @xcite .",
    "the profile likelihood method was found to have surprisingly good coverage properties with a small ( mostly negligible ) amount of undercoverage .",
    "+ in this note we undertake a systematic study of the coverage of the bayesian method in order to give more substance to further recommendations on what method to use to calculate confidence intervals in presence of systematic uncertainties .",
    "previous studies @xcite of this method dealt only with certain limiting cases and were constrained by computational requirements .",
    "+ the note is organized as follows : in the next section we will review the frequentist construction of confidence intervals , in particular the likelihood ratio ordering scheme . we will describe the bayesian method to incorporate systematics in section [ sec::sys ] .",
    "the c++ library used to perform the calculations is described in section [ sec::pole ] .",
    "coverage tests and connected subtleties are discussed in section [ sec::cov ] .",
    "the final section is devoted to discussion and conclusion .",
    "let us consider a poisson probability density function ( pdf ) , @xmath6 , for a fixed but unknown signal , @xmath3 , in the presence of a known background with mean @xmath7 .",
    "for every value of @xmath3 we can find two values @xmath8 and @xmath9 such that @xmath10 where @xmath11 denotes the confidence level ( usually quoted as a 100(1-@xmath5)% confidence interval ) . since we assume a poisson distribution , the equality will generally not be fulfilled exactly .",
    "a set of intervals @xmath12 $ ] is called a _",
    "confidence belt_. graphically , upon a measurement , @xmath13 , the _ confidence interval _ @xmath14 $ ] is determined by the intersection of the vertical line drawn from the measured value @xmath13 and the boundary of the confidence belt .",
    "the probability that the confidence interval will contain the true value @xmath3 is @xmath15 , since this is true for all @xmath3 per construction .",
    "the choice of the @xmath8 and @xmath9 is , however , not unique to define the confidence belt .",
    "an additional criterion has to be applied . the currently recommended ordering scheme  @xcite  @xcite of the elements in the sum in equation ( [ eq : neyman0 ] )",
    "is based on likelihood ratios .",
    "this approach automatically provides central confidence intervals when motivated and upper limits when necessary , therefore it is often denoted as the `` unified approach '' .",
    "the following algorithm is applied in solving equation ( [ eq : neyman0 ] ) : + for each @xmath4 the @xmath16 is found which maximizes the likelihood @xmath17 . in case of a simple poisson distribution with known background , @xmath16 is given by @xmath18 .",
    "then for a fixed @xmath3 the ratio @xmath19 is computed for each @xmath4 , and all @xmath4 s are consequently ranked according to the value of this ratio .",
    "values of @xmath4 are included in the confidence belt starting with the @xmath4 with the highest rank ( largest @xmath20 ) and then decreasing rank until @xmath21 .",
    "after the confidence belt has been constructed in this way , the confidence interval @xmath14 $ ] is found as described above .",
    "the ordering schemes are unaffected by the way of treating systematic uncertainties considered here . as mentioned earlier , the pdf describing the statistical process will however be modified .",
    "two concrete examples are the following : in the case that the only uncertainty present is a theoretical ( assumed gauss - shaped ) uncertainty of the background process the pdf is modified to : @xmath22 here @xmath7 is the estimated background level , and @xmath23 is the uncertainty in the background estimation . if , in addition to the theoretical uncertainty for background , there is the need to include the uncertainty in the signal detection efficiency the expression for @xmath24 might be extended to : @xmath25 where @xmath26 is the uncertainty in the detection efficiency expressed in _ relative _ terms with respect to the nominal efficiency .",
    "it is important to realize that the integration variables , here @xmath1 and @xmath27 , are the possible `` true '' ( but unknown ) values of nuisance parameter .",
    "this indicates that this method is based on bayesian statistics .",
    "+ some examples for confidence intervals computed by this method are shown in table [ tab::sys ] .",
    "for the coverage studies presented in this paper a reasonably fast and efficient code is required .",
    "hence , a user - friendly and flexible c++ library of classes was developed based on the fortran routine presented in @xcite .",
    "the library is independent of external libraries and consists of two main classes , _ pole _ and _ coverage_. the first class takes as input the number of observed events , the efficiency and background with uncertainties and calculates the limits using the method described in this paper .",
    "the integrals are solved analytically .",
    "_ coverage _ generates user - defined pseudoexperiments and calculates the coverage using _",
    "pole_. presently the library supports gauss and log - normal distributed pdf for description of the nuisance parameters .",
    "flat and used - defined pdfs are about to be implemented as well as correlations for the gauss case . the class is dynamically optimized depending on if one wishes to calculate single ( or few ) confidence intervals or if one wants to perform a coverage study . without these optimisations",
    "the calculation of a single interval takes about 1 second ( wall clock time ) on a 1 ghz pentium iii processor .",
    "the duration of a full coverage study ( typically requiring the calculation of @xmath28 confidence intervals ) ranges between a couple of minutes for small uncertainties and small signal hypotheses to order of 10 hours for large uncertainties and high signal hypotheses .",
    "the perfomance of a coverage study thus seems feasable for the particular set of systematic uncertainties that may appear in real experiments .",
    "the pole++ library can be obtained from http://cern.ch/tegen/statistics.html",
    "the coverage of the method is studied using mc simulations of pseudo - experiments with given true value of the prime parameter ( signal ) or nuisance parameter ( efficiency , background ) .",
    "the _ estimated _ values of the nuisance parameters were assumed to be gaussian or log - normal distributed around the given true value .",
    "the outcome of one experiment thus consisted of a number of observed events ( following a poisson distribution with known background and depending on the true efficiency and true background ) and the estimate of the nuisance parameter(s ) .",
    "+ figure [ fig::sigeff ] shows the coverage to distinguish it from the nominal coverage @xmath29 as a function of signal hypothesis for two different sizes of uncertainties ( 5 % and 40 % ) .",
    "the uncertainty considered is in the signal efficiency and assumed to be gauss - shaped .",
    "it can be seen that the bayesian method causes over - coverage which is larger for larger systematic uncertainty .",
    "this is also reflected in figure [ fig::meanc ] where the mean coverage ( mean taken over all tested signal hypotheses ) is shown as a function of assumed uncertainty .",
    "for gaussian uncertainties in the signal efficiency we find an increase in mean coverage by @xmath30 1% in the uncertainty range between 10 % and 40 % .",
    "+ the see - saw structure which is generally seen in the no - uncertainty case ( due to the discrete experimental outcome ) is considerably smoothened when systematic uncertainties are introduced .",
    "this is exemplified in figure [ fig::nounc ] , which compares the coverage curve with 5 % uncertainties on the signal efficiency with the zero uncertainties case . to quantify this further we present the rms of the coverage together with the mean in figure [ fig::meanc ] .",
    "the smoothing is due to the fact that we add a continuous variable to the problem , meaning there are more degrees of freedom to fulfil the sum condition of equation [ eq : neyman0 ] .",
    "the effect of the smoothing is that whereas for some signal hypothesis the coverage is increased for others it is decreased with respect to the zero uncertainty case .",
    "the mean coverage is therefore only rather weakly dependent on the systematic uncertainties . for higher signal hypotheses , where the effect of the smoothing is less pronounced",
    ", the effect of the uncertainties is therefore stronger . taking the mean over signal hypotheses",
    "@xmath316 the mean coverage increases from 92 % ( at zero uncertainties ) to 94 % ( at 40 % uncertainties ) .",
    "a side effect is that the introduction of rather small uncertainties seems to improve the coverage with respect to the zero uncertainty case for parts of the tested hypothesis space ( see e.g. figure [ fig::nounc ] ) .",
    "+ figure [ fig::bgeff ] shows the coverage for two different sizes of gaussian uncertainty on the background estimate . except for the smoothing effect",
    "the coverage is seemingly independent of the size of the uncertainties .",
    "an uncertainty in the background will yield similar results to an uncertainty in the signal efficiency only in the regime were the signal hypotheses are of similar size as the background expectation . for larger signal hypotheses the coverage curve for the uncertainty in the background",
    "will be approaching the zero uncertainty case , which is reflected in a slight slope of the coverage curve for high uncertainty in figure [ fig::bgeff ] .",
    "the result is thus that a mean coverage depending on uncertainties in the background will be less affected than the corresponding curve with uncertainties in the signal efficiency .",
    "we show the mean coverage as well as the rms in figure [ fig::meanb ] . + in figure [ fig::bgcor ] the effect of having to consider uncertainties both in signal and background detection efficiency is visible . at large signal hypotheses the coverage plot is dominated by the uncertainty in signal efficiency , at low signal hypotheses coverage benefits from the smoothing effect , since we added yet another degree of freedom . + it should be noted that for large uncertainties the gaussian model is not appropriate .",
    "the reason is that a gaussian model will then significantly extent to the unphysical region of the space of experimental outcomes . in the bayesian treatment",
    "this case is dealt with by truncating the gauss distribution at zero , and this is consequently the way it is dealt with during the coverage test . considering the coverage test",
    "there is an additional subtlety : in order for the measured efficiency to be a maximum likelihood estimate of the true efficiency we would have to renormalize the gauss distribution to the truncated gauss distribution in order to obtain the correct pdf .",
    "however , instead of doing this a posteriori fix , it is more reasonable to use a log - normal distribution to model the uncertainty in the efficiency .",
    "the coverage for the log - normal distribution is shown in figure [ fig::logn ] . as can be seen for the highest uncertainties considered in this note ,",
    "the gauss distribution is still a very good approximation to the log normal model .",
    "in this note we presented coverage studies for the bayesian treatment of systematic uncertainties .",
    "one overall conclusion is that the bayesian treatment leads some over - coverage .",
    "however , introducing a continuous nuisance parameter into the discrete poisson problem results in a smoothing of the coverage curves .",
    "the mean coverage is therefore only weakly affected by the bayesian treatment of nuisance parameters and under certain circumstances even improves with respect to the zero uncertainty case .",
    "+ in a frequentist approach the meaured estimate of a nuisance parameter is considered to be distributed around a given true value , which is consequently the way coverage was calculated . the bayesian method on the other hand views the true value as distributed around the measured value .",
    "the underlying assumption for going from one approach to the other is ( at least in case of a gauss - distribution ) a flat prior probability of hypotheses .",
    "the present study indicates that this assumption does not lead to a violation ( except for over - coverage ) of the coverage requirement .",
    "+ the routines used for the presented calculations are reasonably fast and publicly available .",
    "a coverage study is therefore feasable for each problem at hand .",
    "the confidence level required for the confidence intervals could then in principle be adjusted to recover correct coverage .",
    "the authors thank robert cousins for a very useful discussion .    00 r.  d.  cousins and v.   l.  highland , nucl .",
    "a320 * , 331 , ( 1992 ) .",
    "j.  neyman , phil .",
    "royal soc .",
    "london * a * , 333 , ( 1937 ) .",
    "g.  j.  feldman and r.  d.  cousins , phys .",
    "rev * d57 * , 3873 , ( 1998 ) .",
    "a.  stuart and j.  k.  ord : kendall s advanced theory of statistics , vol .",
    "2 , classical inference and relationship , oxford university press , new york ( 1991 ) .",
    "j.  conrad , o.  botner , a.  hallgren and c.  perez de los heros , phys .",
    "d * 67 * ( 2003 ) 012002 [ arxiv : hep - ex/0202013 ] .",
    "b.  abbott _ et al . _",
    "[ ligo collaboration ] , phys .",
    "d * 69 * ( 2004 ) 102001 .",
    "y.  chao _ et al . _ [ belle collaboration ] , phys .",
    "d * 69 * ( 2004 ) 111102 [ arxiv : hep - ex/0311061 ] .",
    "k.  eguchi _ et al .",
    "_ [ kamland collaboration ] , phys .",
    "* 92 * ( 2004 ) 071301 [ arxiv : hep - ex/0310047 ] .",
    "i.  abt _ et al . _ [ hera - b collaboration ] , arxiv : hep - ex/0405059 .",
    "j.  ahrens [ amanda collaboration ] , phys .",
    "* 92 * ( 2004 ) 071102 [ arxiv : astro - ph/0309585 ] .",
    "w.  a.  rolke , a.  m.  lopez , j.  conrad and f. james arxiv : physics/0403059 .",
    "098301 , ( 2000 ) .",
    "j.  conrad , o.  botner , a.  hallgren and c.  perez de los heros , published in proc . of conference on",
    "advanced statitical techniques in particle physics , durham , england , march 2002 j.  conrad , computer physics communications * 158 * 117 - 123 ( 2004 )",
    ".[tab::sys]examples of likelihood ratio 90% confidence intervals with bayesian treatment of systematic uncertainties .",
    "uncertainties are assumed to be gauss distributed in the signal efficiency .",
    "[ cols= \" < , < , < , < , < \" , ]"
  ],
  "abstract_text": [
    "<S> in high energy physics , a widely used method to treat systematic uncertainties in confidence interval calculations is based on combining a frequentist construction of confidence belts with a bayesian treatment of systematic uncertainties . in this note we present a study of the coverage of this method for the standard likelihood ratio ( aka feldman & cousins ) construction for a poisson process with known background and gaussian or log - normal distributed uncertainties in the background or signal efficiency . for uncertainties in the signal efficiency of upto 40 % we find over - coverage on the level of 2 to 4 % depending on the size of uncertainties and the region in signal space . </S>",
    "<S> uncertainties in the background generally have smaller effect on the coverage . </S>",
    "<S> a considerable smoothing of the coverage curves is observed . </S>",
    "<S> a software package is presented which allows fast calculation of the confidence intervals for a variety of assumptions on shape and size of systematic uncertainties for different nuisance parameters . </S>",
    "<S> the calculation speed allows experimenters to test the coverage for their specific conditions .    and    confidence intervals , systematic uncertainties , frequentist methods , bayesian methods 06.20.dk , 07.05.kf </S>"
  ]
}