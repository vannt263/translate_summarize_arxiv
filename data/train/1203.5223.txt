{
  "article_text": [
    "given a linear model y = x+where @xmath1 and @xmath2 is a random vector with gaussian distribution @xmath3 the lasso estimator is given by [ lasso ] & = & argmin_r^p 12 y - x_2 ^ 2+_1 .",
    "this estimator was first proposed in the paper of tibshirani @xcite .",
    "the lasso estimator @xmath4 is often used in the high dimensional setting where @xmath5 is much larger than @xmath6 . as can be expected , when @xmath7 , estimation of @xmath8 is hopeless in general unless some additional property of @xmath8 is assumed . in many practical situations ,",
    "it is considered relevant to assume that @xmath8 is sparse , i.e. has only a few nonzero components , or at least compressible , i.e. the magnitude of the non zero coefficients decays with high rate .",
    "it is now well recognized that the @xmath0 penalization of the likelihood often promotes sparsity under certain assumptions on the matrix @xmath9 .",
    "we refer the reader to the book @xcite and the references therein for a state of the art presentation of the lasso and the tools involved in the theoretical analysis of its properties .",
    "one of the main interesting properties of the lasso estimator is that it is a solution of a convex optimization problem and it can be computed in polynomial time , i.e. very quickly in the sense of computational complexity theory .",
    "this makes a big difference with other approaches based on variable selection criteria like aic @xcite , bic @xcite , foster and george s risk inflation criterion @xcite , etc , which are based on enumeration of the possible models , or even with the recent proposals of dalalyan , rigollet and tsybakov @xcite , @xcite , although enumeration is replaced with a practically more efficient monte carlo markov chain algorithm .    in the problem of estimating @xmath10 , i.e. the prediction problem",
    ", it is often believed that the price to pay for reducing the variable selection approach to a convex optimization problem is a certain set of assumptions on the design matrix @xmath9 .",
    ", in @xcite , @xcite .",
    "] one of the main contributions of @xcite is that no particular assumption on @xmath9 is required for the prediction problem , as opposed to the known results concerning the lasso such that @xcite , @xcite , @xcite and @xcite , and the many references cited in these works .",
    "an impressive amount of work has been done in the recents years in order to understand the properties of @xmath4 unded various assumptions on @xmath9 .",
    "see the recent book by p. buhlmann and s. van de geer @xcite for the state of the art .",
    "two well known assumptions on the design matrix are    * small coherence @xmath11 * small restricted isometry constant @xmath12    where the coherence @xmath11 is defined as ( x ) & = & _ j , j^    @xmath12 is the smallest @xmath13 such that [ rip ] ( 1- ) _",
    "t_2 x_t _ t_2 ( 1 + ) _ t_2 for * all * subset @xmath14 with cardinal @xmath15 and all @xmath16 .",
    "other conditions are listed in @xcite ; see figure 1 in that paper for a diagram summarizing all relationships between them .",
    "the restricted isometry property is very stringent and implies almost other conditions .",
    "moreover , the restricted isometry constant is np - hard to compute for general matrices . on the other hand",
    ", the coherence only requires of the order @xmath17 elementary operations .",
    "however , it was proved in @xcite that a small coherence , say of the order of @xmath18 , is sufficient to prove a property very close to the restricted isometry property : ( [ rip ] ) holds for a large proportion of subsets @xmath19 , @xmath20 ( of the order @xmath21 , @xmath22 ) .",
    "this result was later refined in @xcite with better constants using the recently discovered non - commutative deviation inequalities @xcite .",
    "less stringent properties are the restricted eigenvalue , the irrepresentable and the compatibility properties .",
    "the goal of this short note is to show that , using a very simple trick , one can prove prediction bounds similar to ( * ? ? ?",
    "* theorem 2.1 ) without any assumption on the design matrix @xmath9 at the low expense of appending to @xmath9 a random matrix with independent columns uniformly distributed on the sphere .    for this purpose ,",
    "we introduce a new index for design matrices , denoted by @xmath23 that allows to obtain novel adaptive bounds on the prediction error .",
    "this index is defined for any @xmath24 and @xmath25 as _",
    "s,_-(x ) & = & _ v b(0,1 ) _ i s_s,_- x_i^t v _ , where @xmath26 is the family of all @xmath27 of @xmath28 with cardinal @xmath29 , such that @xmath30 .",
    "the meaning of the index @xmath31 is the following : for any @xmath32 , we look for the `` almost orthogonal '' family inside the set of columns of @xmath9 with cardinal @xmath15 , which is the most orthogonal to @xmath33 .",
    "one major advantage of this new parameter is that imposing the condition that @xmath31 is small is much less stringent than previous criteria required in the litterature . in particular , many submatrices of @xmath9 may be very badly conditioned or even singular without altering the smallness of @xmath31 .",
    "computing the new index @xmath23 for random matrices with independent columns uniformly distributed on the sphere , .",
    "] shows that a prediction bound involving @xmath23 can be obtained which is of the same order as the bound of ( * ? ? ?",
    "* theorem 2.1 ) .",
    "one very nice property of the index @xmath31 is that it decreases after the operation appending any matrix to a given one . as a very nice consequence of this observation",
    ", the results obtained for random matrices can be extended to any matrix @xmath9 to which a random matrix is appended .",
    "this trick can be used to prove new prediction bounds for a modified version of the lasso obtained by appending a random matrix to any given design matrix .",
    "this simple modification of the lasso retains the fundamental property of being polynomial time solvable unlike the recent approaches based on non - convex criteria for which no computational complexity analysis is available .",
    "the plan of the paper is as follows . in section [ mainres ]",
    "we present the index @xmath31 for @xmath9 and provide an upper bound on this index for random matrices with independent columns uniformly distributed on the sphere , holding with high probability .",
    "then , we present our prediction bound in theorem [ main ] : we give a bound on the prediction squared error @xmath34 which depends linearly on @xmath15 .",
    "this result is similar in spirit to ( * ? ? ?",
    "* theorem 1.2 ) .",
    "the proofs of the above results are given in section [ pf ] . in section [ gaussappend ] , we show how these results can be applied in practice to any problem with a matrix for which @xmath31 is unknown by appending to @xmath9 an @xmath35 random matrix with i.i.d .",
    "columns uniformly distributed on the unit sphere of @xmath36 and with only @xmath37 columns .",
    "an appendix contains the proof of some intermediate results .",
    "a vector @xmath8 in @xmath38 is said to be @xmath15-sparse if exactly @xmath15 of its components are different from zero .",
    "let @xmath39 be a positive real number . in the sequel",
    ", we will denote by @xmath26 the family of all index subsets @xmath27 of @xmath28 with cardinal @xmath29 , such that for all @xmath40 , @xmath30 .",
    "[ defgam ] the index @xmath23 associated with the matrix @xmath9 in @xmath41 is defined by _",
    "s,_-(x ) & = & _ v b(0,1 ) _",
    "i s_s,_- x_i^t v_.    an important remark is that the function @xmath42 is nonincreasing in the sense that if we set @xmath43 $ ] , where @xmath44 is a matrix in @xmath45 , then @xmath46 .    unlike the coherence @xmath11",
    ", for fixed @xmath6 and @xmath15 , the quantity @xmath23 is very small for @xmath5 sufficiently large , at least for random matrices such as normalized standard gaussian matrices as shown in the following proposition .",
    "[ gamtheo ] assume that @xmath9 is random matrix in @xmath41 with i.i.d .",
    "columns with uniform distribution on the unit sphere of @xmath36 .",
    "let @xmath39 and @xmath47 , @xmath48 and @xmath49 .",
    "set k _ & = & ( ( 1+c _ ) ( 1 + 2)+c_+ ( ) ) .",
    "assume that @xmath6 , @xmath50 and @xmath15 satisfy & n 6 , +   + [ kappa ] & = \\ { 4 e^-2((2)-1 ) ,  ( ) ^2 ^2(p_0 ) ( c_n ) } , +   + [ n ] & n \\{()^2,}. then , we have _",
    "s,_-(x ) & & 80   with probability at least @xmath51 .",
    "notice that the constraints ( [ kappa ] ) and ( [ n ] ) together imply the following constraint on @xmath15 : [ s ] & s & c_sparsity   with c_sparsity & = &  .      in the remainder of this paper",
    ", we will assume that the columns of @xmath9 are @xmath53-normalized .",
    "the main result of this paper is the following theorem .",
    "[ main ] let @xmath54 .",
    "let @xmath55 be a positive real such that [ nu ]  _ n,_-(x ) .",
    "assume that @xmath56 .",
    "assume that @xmath8 has support @xmath27 with cardinal @xmath15 and that [ asslamb ] & + & ( b_x,,_-  _ _ ( x_t ) + ) with b_x,,_- & = & .",
    "then , with probability greater than @xmath57 , we have 12 x(-)_2 ^ 2 & & s  c_n , p,_- , , , with c_n , p,_- , , , & = & ( + )      equation ( [ nu ] ) in theorem [ main ] requires that [ condgam ] _",
    "n,_-(x ) & < & _ - . proposition [ gamtheo ] proves that for random matrices with independent columns uniformly drawn on the unit sphere of @xmath58 ( i.e. normalized i.i.d .",
    "gaussian matrices ) , _",
    "s,_-(x ) & & 80   with high probability . the case of general design matrices",
    "can be treated using a simple trick .",
    "it will be studied in section [ gaussappend ] .",
    "the main advantage of using the parameter @xmath59 is that it allows @xmath9 to contain extremely badly conditioned submatrices , a situation that may often occur in practice when certain covariates are very correlated .",
    "this is in contrast with the restricted isometry property or the incoherence condition , or other conditions often required in the litterature . on the other hand ,",
    "the parameter @xmath59 is not easily computable .",
    "we will see however in section [ gaussappend ] how to circumvent this problem in practice by the simple trick consisting of appending a random matrix with @xmath60 columns to the matrix @xmath9 in order to ensure that @xmath9 satisfies ( [ condgam ] ) with high probability .",
    "finally , notice that unlike in ( * ? ? ?",
    "* theorem 2.1 ) , we make no assumption on the sign pattern of @xmath8 . in particular , we do not require the sign pattern of the nonzero components to be random .",
    "moreover , the extreme singular values of @xmath61 are not required to be independent of @xmath6 nor @xmath5 and the condition ( [ condgam ] ) is satisfied for a wide range of configurations of the various parameters involved in the problem .",
    "take @xmath63 .",
    "we construct an outer approximation @xmath64 of @xmath62 into which we be able to extract the set @xmath62 .",
    "we procede recursively as follows : until @xmath65 , for some positive real number @xmath50 to be specified later , do    * choose @xmath66 and set @xmath67 * choose @xmath68 and set @xmath69 * @xmath70 * choose @xmath71 and set @xmath72 .",
    "if we denote by @xmath74 the quantity @xmath75 and by @xmath76 the @xmath77 order statistic , we get that x^t_v _ & = & z_(s ) . since the @xmath78 s are assumed to be i.i.d . with uniform distribution on the unit sphere of @xmath36 , we obtain that the distribution of @xmath76 is the distribution of the @xmath77 order statistics of the sequence @xmath79 , @xmath80 . by ( 5 )",
    "p.147 @xcite , @xmath79 has density @xmath81 and cdf @xmath82 given by g(z ) & = 1 ( 1-z^2 ) ^2 g(z ) = & 2  _",
    "0^z g ( )  d. thus , f_z_(r)(z ) & = & ( br ) where @xmath83 is a binomial variable @xmath84 .",
    "our next goal is to find the smallest value @xmath85 of @xmath86 which satisfies [ devorder ] f_z_(s)(z_0 ) & & 1-p_0 ^ -n .",
    "we have the following standard concentration bound for @xmath83 ( e.g. @xcite ) : p ( b ( 1- ) e[b ] ) & & ( -12  ^2 e[b ] ) which gives p ( b ( 1- ) p_0g(z ) ) & & 1-(-12  ^2 p_0 g(z ) ) we thus have to look for a root ( or at least an upper bound to a root ) of the equation g(z ) & = & 112  ^2   ( p_0 ) .",
    "notice that g(z ) & = & 2  1  _ 0^z  ( 1-^2 )",
    "^2  d , + & & 1  z for @xmath87 . by a straightforward application of stirling s formula ( see e.g. ( 1.4 ) in @xcite ) , we obtain & &  . thus , any choice of @xmath85 satisfying [ left ] z_0 & &  112  ^2   ( p_0 ) is an upper bound to the quantile for @xmath88-order statistics at level @xmath89 .",
    "we now want to enforce the constraint that ( 1- ) p_0 g(z_0 ) & & s. by again a straightforward application of stirling s formula , we obtain g(z ) & & 1   z for @xmath90 .",
    "thus , we need to impose that [ right ] z_0 & &   .",
    "notice that the constraints ( [ left ] ) and ( [ right ] ) are compatible if & &    ( p_0 ) .",
    "take @xmath91 and obtain [ quantunifsph0 ] ( x^t_v _    ( p_0 ) ) & & p_0 ^ -n for & = & for any @xmath60 such that @xmath92 , which is clearly the case as soon as @xmath93 for @xmath24 as assumed in the proposition .",
    "if @xmath94 , we can simplify ( [ quantunifsph0 ] ) with [ quantunifsph ] ( x^t_v_80   ) & & p_0",
    "^ -n      the method for extracting @xmath96 from @xmath95 uses random column selection . for this purpose , we will need to control the coherence and the norm of @xmath95 .",
    "* step 1 : the coherence of @xmath95*. let us define the spherical cap c(v , h ) & = & \\{w ^n v , wh } .",
    "the area of @xmath97 is given by area(c(v , h ) ) & = & area ( s(0,1 ) ) _ 0 ^ 2h - h^2 t^2(1-t)^12 dt .",
    "thus , the probability that a random vector @xmath98 with haar measure on the unit sphere @xmath99 falls into the spherical cap @xmath97 is given by ( wc(v , h ) ) & = & + & = & .",
    "the last term is the cdf of the beta distribution .",
    "using the fact that ( x_j c(x_j^,h ) ) & = & ( x_j^ c(x_j , h ) ) the union bound , and the independence of the @xmath78 s , the probability that @xmath100 for some @xmath101 in @xmath102 can be bounded as follows ( _ jj^=1^p_0 \\ { x_j c(x_j^,h ) } ) & = & ( _ j < j^=1^p_0 \\ { x_j c(x_j^,h ) } ) + & & _ j < j^=1^p_0 ( \\ { x_j c(x_j^,h ) } ) + & = & _ j < j^=1^p_0 + & = & 2 _ 0 ^ 2h - h^2 t^2(1-t)^12 dt . our next task is to choose @xmath103 so that 2 _ 0 ^ 2h - h^2 t^2(1-t)^12 dt & & p_0 ^ -n",
    ". let us make the following crude approximation 2 _ 0 ^ 2h - h^2 t^2(1-t)^12 dt & & 2 ( 2h)^2 ( 2h-0 ) .",
    "thus , taking h & & 12  ( - 2  ( ( p_0)+ ) ) will work .",
    "moreover , since @xmath104 , we deduce that [ mutilde ] ( x _ ) & & 12  p_0 ^ -2 with probability at least @xmath105 .",
    "* step 2 : the norm of @xmath95*. the norm of any submatrix @xmath106 with @xmath6 rows and @xmath107 columns of @xmath9 has the following variational representation x_s & = & _  v^t x_s w. we will use an easy @xmath2-net argument to control this norm . for any @xmath63 , @xmath108 , @xmath109 is a sub - gaussian random variable satisfying ( |v^t x_j| u ) & & 2 ( -c n  u^2 ) , for some constant @xmath110 .",
    "therefore , using the fact that @xmath111 , we have that (    of rudelson and vershynin .",
    "the first one gives a bound on the covering number of spheres .",
    "( ( * ? ? ?",
    "* proposition 2.1 ) ) . [ net ] for any positive integer @xmath112 , there exists an @xmath2-net of the unit sphere of @xmath113 of cardinality 2d ( 1 + 2)^d-1 .",
    "the second controls the approximation of the norm based on an @xmath2-net .",
    "( ( * ? ? ?",
    "* proposition 2.2 ) ) .",
    "[ rv2 ] let @xmath114 be an @xmath2-net of the unit sphere of @xmath113 and let @xmath115 be an @xmath116-net of the unit sphere of @xmath117 .",
    "then for any linear operator @xmath118 , we have a & & _ |v^t",
    "let @xmath114 ( resp .",
    "@xmath115 ) be an @xmath2-net of the unit sphere of @xmath119 ( resp . of @xmath36 ) .",
    "on the other hand , we have that ( _ |v^t aw|u ) & & 2|n||n^| ( -c n  u^2 ) , + & & 8  n s ( 1 + 2)^n+s-2 ( -c n  u^2 ) , which gives ( _ |v^t aw|u ) & & 8   ( -(c n  u^2 -(n+s ) ( 1 + 2 ) ) ) . using proposition ( [ rv2 ] ) , we obtain that ( x_s u ) & & ( _ |v^t aw| u ) . thus , we obtain ( x_s u ) & & 8   ( -(c n  ( 1-)^4  u^2-(n+s ) ( 1 + 2 ) ) ) . to conclude , let us note that ( x_u ) & & ( _ x_s u ) + & & p_0  8   ( -(c n  ( 1-)^4  u^2-(n+s ) ( 1 + 2 ) ) ) . and using the fact that & & ( ) ^s , one finally obtains ( x_u ) & & 8   ( -(c n  ( 1-)^4  u^2-(n+s ) ( 1 + 2)- s ( ) - ( ) ) )",
    ". the right hand side term will be less than @xmath120 when n ( p_0 ) & & c n  ( 1-)^4  u^2-(n+s ) ( 1 + 2)- s ( ) - ( ) .",
    "this happens if u^2 & & 1c ( 1-)^4 ( n + ( 1 + ) ( 1 + 2)+ ( ) + 1n ( ) ) .",
    "notice that [ sn ] & & ( 1 + ) ( 1 + 2)+ ( ) + 1n ( ) + & & ( 1+c _ ) ( 1 + 2)+c_+1n ( ) , + & & k _  , since @xmath121 .",
    "now , since & ( p_0 ) & ( p_0 ) , we finally obtain [ normbnd ] ( x _ ( p_0 ) ) & & 8p_0^n .    *",
    "step 3*. we will use the following lemma on the distance to identity of randomly selected submatrices .",
    "[ submat ] let @xmath122 .",
    "let @xmath6 , @xmath50 and @xmath15 satisfy conditions ( [ n ] ) and ( [ kappa ] ) assumed in proposition [ gamtheo ] .",
    "let @xmath123 be a random support with uniform distribution on index sets with cardinal @xmath15 .",
    "then , with probability greater than or equal to @xmath124 on @xmath9 , the following bound holds : [ sing ] ( x^t_x_-_s r x ) & < & 1 .",
    "see appendix .",
    "taking @xmath125 , we conclude from lemma [ submat ] that , for any @xmath15 satisfying ( [ s ] ) , there exists a subset @xmath126 of @xmath64 with cardinal @xmath15 such that _",
    "( x_)_- .",
    "recalling proposition [ net ] , there exists an @xmath2-net @xmath127 covering the unit sphere in @xmath36 with cardinal |n | & & 2n ( 1 + 2)^n-1 . combining this with ( [ quantunifsph ] )",
    ", we have that & ( _ vn _",
    "is_s,_- x_i^tv    ) + [ netcontrol ] & 2n ( 1 + 2)^n-1  p_0 ^ -n+9  p^-n .      for any @xmath128",
    ", one can find @xmath129 with @xmath130 .",
    "thus , we have x_i^tv^ _ & & x_i^t v",
    "_ + x_i^t ( v^-v ) _ + & & x_i^t v _ + _ ji |x_j,(v^-v ) | + & & x_i^t v _ + _ ji x_j_2 v^-v_2 + [ sph ] & & x_i^t v _ + . taking & = & 80  , we obtain from ( [ sph ] ) and ( [ netcontrol ] ) that & ( _ v_2=1 _ is_s,_- x_i^tv 80  ) + & 20  n ( 1+)^n-1  p_0 ^ -n+9  p_0 ^ -n and thus , & ( _ v_2=1 _ is_s,_- x_i^tv 80  ) + & 5  + 9  p_0 ^ -n , for @xmath131 .",
    "the optimality conditions for the lasso are given by [ opt ] -x^t(y - x)+g=0 for some @xmath132 .",
    "thus , we have x^tx(-)=x^t -g .",
    "from which one obtains that , for any index set @xmath133 with cardinal @xmath15 , [ optinf1 ] x_^tx(- ) _ & & + x_^t _ ,      as is well known , even when the solution of the lasso optimization problem is not unique , there always exists a vector @xmath4 whose support has cardinal @xmath6 .",
    "the argument is divided into three steps .    _",
    "first step_. equation ( [ optinf1 ] ) implies that [ optinf2 ] x_^tx_s(_s-_s ) _ & & + x_^t _ + x_^tx_(_-_)_.    _ second step_.",
    "we now choose @xmath135 as a solution of the following problem & = & _ _ ji |x_j , x _",
    "( _ -_)| subject to _ ( x_i ) & & _ - . by definition [ defgam ] , & & _",
    "s,_-(x )   x_(_-_)_2 and thus , & & _",
    "s,_-(x )  _ ( x _ ) _ -__2",
    "s,_-(x )  _ ( x _ ) _ -__1 which gives [ varth ] & & _",
    "s,_-(x )  _ ( x _ ) ( _ _ 1+__1 ) .",
    "_ third step_. combining ( [ optinf2 ] ) and ( [ varth ] ) , we obtain x_^tx_s(_s-_s ) _ & & + x_^t _ + _ s,_-(x )  _ ( x _ ) ( _ _ 1+__1 ) . using the fact that x_^t _ & & x^t _ and since ( x^t _ ) & & p^- , we obtain that x_^tx_s(_s-_s ) _ & & + + & & + _ s,_-(x )  _ ( x _ ) ( _ _ 1+__1 ) [ bdlinf ] with probability greater than @xmath136 .",
    "the definition of @xmath4 gives 12 y - x_2 ^ 2+_1 & & 12 y - x_2 ^ 2+_1 therefore , we have that 12 -x(-)_2 ^ 2+_1 & & 12 _ 2 ^ 2+_1 which implies that 12 x(-)_2 ^ 2 & & , x_s(_s-_s)+ , x_(_- _ ) + & & + ( _ s_1-_s_1)-__1+__1 .",
    "this can be further written as [ basic ] 12 x(-)_2 ^ 2 & & , x_s(_s-_s)+ x_^t , _ - _ + & & + ( _ s_1-_s_1)-__1+__1 .",
    "the argument is divided into two steps .    _",
    "first step_. we have , x_s(_s-_s ) & = & x_s^t,_s-_s + & & x_s^t _",
    "_ s-_s_1 + & &  x_s^t _ _ s-_s_2 and , using the fact that @xmath138 , , x_s(_s-_s ) & &  x_s^t _",
    "x_^t x_s(_s-_s)_.    _ second step_. since the columns of @xmath9 have unit @xmath53-norm , we have ( x_s^t _ ) & & p^- , which implies that [ noise ] , x_s(_s-_s ) & &  x_^t x_s(_s-_s ) _ with probability at least @xmath57 .",
    "we have [ sc ] x_^t , _ - _ & & x_^t _ _ -__1 .",
    "on the other hand , we have ( x_^t _ ) & & p^- , which , combined with ( [ sc ] ) , implies that x_^t , _ - _ & & ( _ _ 1+__1 ) with probability at least @xmath57 .",
    "the subgradient inequality gives _",
    "s_1-_s_1 & & ( _ s),_s-_s .",
    "we deduce that _",
    "s_1-_s_1 & & -sign(_s ) _",
    "_ s-_s_1 + & & x_^tx_s ( _ s-_s)_2 which implies [ sign ] _",
    "s_1-_s_1 & &  x_^tx_s ( _ s-_s)_.      combining ( [ basic ] ) with ( [ noise ] ) , ( [ sign ] ) and ( [ bdlinf ] ) , the union bound gives that , with probability @xmath141 , 12 x(-)_2 ^ 2 & & ( + ) ( + + & & + _ s,_-(x )  _ ( x _ ) ( _ _ 1+__1 ) ) + & & + ( _ _ 1+__1 ) + & & + ( _ _ 1-__1 ) which gives , 12 x(-)_2 ^ 2 & & s   ( + ) + & & + ( ( + ) _",
    "s,_-(x )  _ ( x _ ) + & & + - ) _ _ 1 + & & + ( ( + ) _",
    "s,_-(x )  _ ( x _ ) + & & + + ) _ _ 1 . using the assumption that @xmath56",
    ", we obtain 12 x(-)_2 ^ 2 & & s   ( + ) + & & + ( ( + ) _",
    "s,_-(x )  _ ( x _ ) + & & + - ) _ _ 1 + & & + ( ( + ) _",
    "s,_-(x )  _ ( x _ ) + & & + + ) _ _ 1 .",
    "since , as recalled in section [ supp ] , the support of @xmath4 has cardinal less than or equal to @xmath6 , we have _ ( x _ ) & & _ _ ( x_t ) , and the proof is completed .",
    "we have computed the index @xmath31 for the random matrix with independent columns uniformly distributed on the unit sphere of @xmath58 in theorem [ gamtheo ] .",
    "the goal of this section is to show that this result can be used in a simple trick in order to obtain prediction bounds similar to ( * ? ? ?",
    "* theorem 2.1 ) without conditions on the design matrix @xmath9 .",
    "this idea is of course to use theorem [ main ] above .",
    "however , the values of @xmath142 and @xmath143 are of course usually not known ahead of time and we have to provide easy to compute bounds for these quantities .",
    "the coherence @xmath11 can be used for this purpose . indeed , for any positive integer @xmath144 and any @xmath19 with @xmath145 , we have ( x ) & = & x^tx - i_1,1 + & = & _ w_=1 _ w^_1=1 w^t(x^tx - i)w^ + & & 1 _ _",
    "w^t(x^tx - i)w^. thus , we obtain that 1-(x ) & _ ( x_t ) _ ( x_t ) & 1+(x )",
    ". however , the lower bound on @xmath142 obtained in this manner may not be accurate enough .",
    "more precise , polynomial time computable , bounds have been devised in the litterature .",
    "the interested reader can find a very useful semidefinite relaxation of the problem of finding the worst possible value of @xmath146 over all subsets @xmath14 of @xmath28 with a given cardinal ( related to the restricted isometry constant ) in @xcite .",
    "assuming we have a polynomial time computable a priori bound @xmath147 on @xmath146 ( resp .",
    "@xmath148 on @xmath149 ) , our main result for the case of general design matrices is the following theorem .",
    "let @xmath9 be an matrix in @xmath150 with @xmath53-normalized columns and let @xmath151 be a random matrix with independent columns uniformly distributed on the unit sphere of @xmath36 .",
    "let @xmath152 denote the matrix corresponding to the concatenation of @xmath9 and @xmath151 , i.e. @xmath153 $ ] .",
    "let @xmath154 denote the lasso estimator with @xmath9 replaced with @xmath152 in ( [ lasso ] ) .",
    "let @xmath54 .",
    "let @xmath55 be a positive real .",
    "assume that @xmath60 is such that [ indconcat ] 80   & < & l  _ - for some @xmath155 .",
    "assume moreover that @xmath60 is sufficiently large so that the second inequality in ( [ n ] ) is satisfied .",
    "assume that @xmath8 has support @xmath27 with cardinal @xmath15 and that & & ( b^_x,,_-  _ ^ * + ) with b^_x,,_- & = & .",
    "assume that @xmath15 satisfies the first inequality in ( [ n ] ) and that @xmath56 . then , with probability greater than @xmath156 , we have 12 x(_#-)_2 ^ 2 & & s  c^_n , p,_- , , , with c^_n , p,_- , , , & = & ( + )    since the index @xmath157 does not increase after appending a matrix with @xmath53- normalized columns , the matrix @xmath158 has at most the same index as that of @xmath151",
    ". then ( [ indconcat ] ) ensures that the index @xmath159 is sufficiently small . the rest of the proof is identical to the proof of theorem [ main ]",
    "for any index set @xmath160 with cardinal @xmath15 , define @xmath161 as the diagonal matrix with ( r_s)_i , i & = &      notice that we have x_s^tx_s - i & = & r_shr_s with @xmath162 . in what follows , @xmath163 simply denotes a diagonal matrix with i.i.d .",
    "diagonal components @xmath164 , @xmath165 with bernoulli @xmath166 distribution .",
    "let @xmath167 be an independent copy of @xmath168 .",
    "assume that @xmath27 is drawn uniformly at random among index sets of @xmath169 with cardinal @xmath15 .",
    "by an easy poissonization argument , similar to ( * ? ? ?",
    "* claim @xmath170 p.2173 ) , we have that [ poisse ] ( r_shr_sr )  2  ( rhrr ) , and by proposition 4.1 in @xcite , we have that [ dec ] ( rhrr ) & & 36  ( rhr^r/2 ) . in order to bound the right hand side term",
    ", we will use ( * ? ? ?",
    "* proposition 4.2 ) . set @xmath171 . assuming that @xmath172 and @xmath173",
    ", the right hand side term can be bounded from above as follows : [ inv_bound ] ( rhrr^ ) & & 3  s  v(s,[r^,u , v ] ) , with v(s,[r^,u , v ] ) & = & ( e ) ^ + ( e ) ^u^2/m^2 + ( e ) ^v^2/(m)^2 . using ( [ mutilde ] ) and ( [ normbnd ] )",
    ", we deduce that with probability at least @xmath174 , we have v(s,[r^,u , v ] ) & = & ( e ) ^ + ( e ) ^ + & & + ( e ) ^. take @xmath50 , @xmath175 and @xmath33 such that v^2 & = & r^^2  1(c _",
    "n ) +   + u^2 & = & c_v  ( ( p_0))^2 , +   + & & e^3   ( ( p_0))^2 + for some @xmath176 possibly depending on @xmath15 .",
    "since @xmath177 , this implies in particular that [ kap ] & & e^3   ( ( p_0))^2 .",
    "thus , we obtain that v(s,[r^,u , v ] ) & = & ( ) ^(c_n ) + ( ) ^c_v + ( ) ^. using ( [ poisse ] ) , ( [ dec ] ) and ( [ inv_bound ] ) , we obtain that ( r_shr_sr^ ) & & 236 3 s ( ( ) ^(c_n ) + ( ) ^c_v + ( ) ^ ) .",
    "take [ cv ] c_v & = & ( c_n ) and , since @xmath178 and @xmath179 , we obtain & & ( r_shr_sr^ ) + [ probe ] & & 236 3 s ( ( ) ^(c_n ) + ( ) ^(c_n)+ ( ) ^ ) .",
    "replace @xmath180 by @xmath181 .",
    "since it is assumed that @xmath182 and @xmath183 , it is sufficient to impose that c_^2 n^2 & & ( 236 3 s3)^1(e^2 ) , in order for the right hand side of ( [ probe ] ) to be less than one . since @xmath184",
    ", it is sufficient to impose that c_^2 n^2 & & 236 3  c_n3 , or equivalently , c_n & & 236 3 3 .",
    "this is implied by ( [ n ] ) in the assumptions . on the other hand ,",
    "combining ( [ kap ] ) and ( [ cv ] ) implies that one can take & = &  ( ) ^2 ^2(p_0 ) ( c_n ) , which is nothing but ( [ kappa ] ) in the assumptions .",
    "wainwright , martin j. , sharp thresholds for high - dimensional and noisy sparsity recovery using @xmath0-constrained quadratic programming ( lasso ) .",
    "ieee trans .",
    "theory 55 ( 2009 ) , no . 5 , 21832202 ."
  ],
  "abstract_text": [
    "<S> the lasso estimator is an @xmath0-norm penalized least - squares estimator , which was introduced for variable selection in the linear model . when the design matrix satisfies , e.g. the restricted isometry property , or has a small coherence index , the lasso estimator has been proved to recover , with high probability , the support and sign pattern of sufficiently sparse regression vectors . under similar assumptions </S>",
    "<S> , the lasso satisfies adaptive prediction bounds in various norms . </S>",
    "<S> the present note provides a prediction bound based on a new index for measuring how favorable is a design matrix for the lasso estimator . </S>",
    "<S> we study the behavior of our new index for matrices with independent random columns uniformly drawn on the unit sphere . using the simple trick of appending such a random matrix ( with the right number of columns ) to a given design matrix , </S>",
    "<S> we show that a prediction bound similar to ( * ? ? ? </S>",
    "<S> * theorem 2.1 ) holds without any constraint on the design matrix , other than restricted non - singularity .    </S>",
    "<S> * keywords : * lasso ; coherence ; restricted isometry property ; @xmath0-penalization ; high dimensional linear model . </S>"
  ]
}