{
  "article_text": [
    "we are interested in solving inverse problems which can be formulated as the operator equation @xmath1 where @xmath2 is an operator between two banach spaces @xmath3 and @xmath4 with domain @xmath5 ; the norms in @xmath3 and @xmath4 are denoted by the same notation @xmath6 that should be clear from the context .",
    "a characteristic property of inverse problems is their ill - posedness in the sense that their solutions do not depend continuously on the data . due to errors in the measurements ,",
    "one never has the exact data in practical applications ; instead only noisy data are available .",
    "if one uses the algorithms developed for well - posed problems directly , it usually fails to produce any useful information since noise could be amplified by an arbitrarily large factor .",
    "let @xmath7 be the only available noisy data to @xmath8 satisfying @xmath9 with a given small noise level @xmath10 .",
    "how to use @xmath7 to produce a stable approximate solution to ( [ 1.1 ] ) is a central topic , and regularization methods should be taken into account .    when both @xmath3 and @xmath4 are hilbert spaces , a lot of regularization methods have been proposed to solve inverse problems in the hilbert space framework ( @xcite ) . in case @xmath11",
    "is a bounded linear operator , nonstationary iterated tikhonov regularization is an attractive iterative method in which a sequence @xmath12 of regularized solutions is defined successively by @xmath13 where @xmath14 is an initial guess and @xmath15 is a preassigned sequence of positive numbers . since",
    "@xmath12 can be written explicitly as @xmath16 where @xmath17 denotes the adjoint of @xmath11 , the complete analysis of the regularization property has been established ( see @xcite and references therein ) when @xmath15 satisfies suitable property and the discrepancy principle is used to terminate the iteration , this method has been extended in @xcite to solve nonlinear inverse problems in hilbert spaces .",
    "regularization methods in hilbert spaces can produce good results when the sought solution is smooth .",
    "however , because such methods have a tendency to over - smooth solutions , they may not produce good results in applications where the sought solution has special features such as sparsity or discontinuities . in order to capture the special features , the methods in hilbert spaces",
    "should be modified by incorporating the information of suitable adapted penalty functionals , for which the theories in hilbert space setting are no longer applicable .",
    "the nonstationary iterated tikhonov regularization has been extended in @xcite for solving linear inverse problems in banach spaces setting by defining @xmath18 as the minimizer of the convex minimization problem @xmath19 for @xmath20 successively , where @xmath21 , @xmath22 and @xmath23 denotes the bregman distance on @xmath3 induced by the convex function @xmath24 .",
    "when @xmath3 is uniformly smooth and uniformly convex , and when the method is terminated by the discrepancy principle , the regularization property has been established if @xmath15 satisfies @xmath25 .",
    "the numerical simulations in @xcite indicate that the method is efficient in sparsity reconstruction when choosing @xmath26 with @xmath27 close to @xmath28 on one hand , and provides robust estimator in the presence of outliers in the noisy data when choosing @xmath29 on the other hand .",
    "however , since @xmath3 is required to be uniformly smooth and uniformly convex and since @xmath23 is induced by the power of the norm in @xmath3 , the result in @xcite does not apply to regularization methods with @xmath0 and total variation like penalty terms that are important for reconstructing sparsity and discontinuities of sought solutions .",
    "the total variational regularization was introduced in @xcite , its importance was recognized immediately and many successive works were conducted in the last two decades . in @xcite an iterative regularization method based on bregman distance and total variation was introduced to enhance the multi - scale nature of reconstruction .",
    "the method solves ( [ 1.1 ] ) with @xmath11 linear and @xmath4 a hilbert space by defining @xmath12 in the primal space @xmath3 and @xmath30 in the dual space @xmath31 via @xmath32 where @xmath33 $ ] is a proper convex function , @xmath34 is an initial guess , @xmath35 is in the sub - gradient of @xmath36 at @xmath37 , and @xmath38 denotes the bregman distance induced by @xmath36 .",
    "this method was extended in @xcite to solve nonlinear inverse problems .",
    "extensive numerical simulations were reported in @xcite and convergence analysis was given , with special attention to the case that @xmath39 and @xmath40 , where @xmath41 denotes the total variation , when the iteration is terminated by a discrepancy principle and @xmath15 satisfies the condition @xmath42 for two positive constants @xmath43 . the analysis in @xcite , however , is somewhat preliminary since it provides only the boundedness of @xmath44 which guarantees only weak convergence for a subsequence of @xmath45 , where @xmath46 denotes the stopping index determined by the discrepancy principle .",
    "it is natural to ask if the whole sequence converges strongly and in bregman distance .",
    "we point out that the method ( [ obgxy ] ) is equivalent to the augmented lagrangian method introduced originally in @xcite and developed further in various directions , see @xcite and reference therein .",
    "one may refer to @xcite for some results on convergence and convergence rates of the augmented lagrangian method applied to linear inverse problems in hilbert spaces with general convex penalty term .",
    "when @xmath3 and @xmath4 are hilbert spaces and @xmath47 , ( [ obgxy ] ) is exactly the nonstationary iterated tikhonov regularization . in this paper",
    "we formulate an extension of the nonstationary iterated tikhonov regularization in the spirit of ( [ obgxy ] ) to solve ( [ 1.1 ] ) with both @xmath3 and @xmath4 being banach spaces and present the detailed convergence analysis when the method is terminated by the discrepancy principle . in the method we allow @xmath15 to vary in various ways so that geometric decreasing sequence can be included ; this makes it possible to terminate the method in fewer iterations .",
    "moreover , we allow the penalty term @xmath36 to be general uniformly convex functions on @xmath3 so that the method can be used for sparsity reconstruction and discontinuity detection .",
    "most importantly , we obtain @xmath48 and give a characterization of the limit @xmath49 , which significantly improve the known convergence results .    this paper is organized as follows . in section 2",
    "we give some preliminary results on banach spaces and convex analysis . in section 3 , we then formulate the method in banach spaces with uniformly convex penalty term for solving linear and nonlinear inverse problems , and present the main convergence results . in section 4",
    "we first prove a convergence result for the method when the data is given exactly ; we then show that , if the data contains noise , the method is well - defined and admits some stability property ; by combining these results we finally obtain the proof of the main convergence theorems . finally , in section 5 we present some numerical simulations on linear integral equations of first kind and parameter identification problems in partial differential equations to test the performance of the method .",
    "let @xmath3 be a banach space with norm @xmath6 .",
    "we use @xmath31 to denote its dual space .",
    "given @xmath50 and @xmath51 we write @xmath52 for the duality pairing . we use  @xmath53 \" and  @xmath54 \" to denote the strong convergence and weak convergence respectively .",
    "if @xmath4 is another banach space and @xmath55 is a bounded linear operator , we use @xmath56 to denote its adjoint , i.e. @xmath57 for any @xmath50 and @xmath58 .",
    "we use @xmath59 to denote the null space of @xmath60 and define @xmath61 when @xmath3 is reflexive , there holds @xmath62 where @xmath63 denotes the range space of @xmath64 and @xmath65 denotes the closure of @xmath63 in @xmath31 .    for a convex function @xmath33",
    "$ ] , we use @xmath66 to denote its effective domain .",
    "we call @xmath36 proper if @xmath67",
    ". given @xmath50 we define @xmath68 any element @xmath69 is called a subgradient of @xmath36 at @xmath70 .",
    "the multi - valued mapping @xmath71 is called the subdifferential of @xmath36 .",
    "it could happen that @xmath72 for some @xmath73 .",
    "let @xmath74 for @xmath75 and @xmath76 we define @xmath77 which is called the bregman distance induced by @xmath36 at @xmath70 in the direction @xmath78 .",
    "clearly @xmath79 .",
    "by straightforward calculation one can see that @xmath80 for all @xmath81 , @xmath76 , @xmath82 and @xmath83 .    a proper convex function",
    "@xmath33 $ ] is called uniformly convex if there is a continuous function @xmath84 , with the property that @xmath85 implies @xmath86 , such that @xmath87 for all @xmath88 and @xmath89 .",
    "if @xmath90 in ( [ eq:7.29.1 ] ) can be taken as @xmath91 for some @xmath92 and @xmath93 , then @xmath36 is called @xmath94-uniformly convex",
    ". it can be shown ( ( * ? ? ?",
    "* theorem 3.5.10 ) ) that @xmath36 is uniformly convex if and only if there is a strictly increasing continuous function @xmath95 with @xmath96 such that @xmath97 for all @xmath98 , @xmath99 and @xmath76 .    on a banach space @xmath3",
    ", we consider for @xmath100 the convex function @xmath101 .",
    "its subdifferential at @xmath70 is given by @xmath102 which gives the duality mapping @xmath103 with gauge function @xmath104 .",
    "we call @xmath3 uniformly convex if its modulus of convexity @xmath105 satisfies @xmath106 for all @xmath107 .",
    "if there are @xmath92 and @xmath108 such that @xmath109 for all @xmath110 , then @xmath3 is called @xmath111-uniformly convex .",
    "we call @xmath3 uniformly smooth if its modulus of smoothness @xmath112 satisfies @xmath113",
    ". one can refer to @xcite for many examples of banach spaces , including the sequence spaces @xmath114 , the lebesgue spaces @xmath115 , the sobolev spaces @xmath116 and the besov spaces @xmath117 with @xmath100 , that are both uniformly convex and uniformly smooth .",
    "it is well known that any uniformly convex or uniformly smooth banach space is reflexive . on a uniformly smooth banach space @xmath3 ,",
    "every duality mapping @xmath118 with @xmath100 is single valued and uniformly continuous on bounded sets ; for each @xmath100 we use @xmath119 to denote the bregman distance induced by the convex function @xmath120 .",
    "furthermore , on a uniformly convex banach space , any sequence @xmath121 satisfying @xmath122 and @xmath123 must satisfy @xmath124 as @xmath125 .",
    "this property can be easily generalized for uniformly convex functions which we state in the following result .",
    "[ lem : kadec ] let @xmath126 $ ] be a proper , weakly lower semi - continuous , and uniformly convex function .",
    "then @xmath36 admits the kadec property , i.e. for any sequence @xmath127 satisfying @xmath128 and @xmath129 there holds @xmath124 as @xmath125 .    assume the result is not true .",
    "then , by taking a subsequence if necessary , there is an @xmath130 such that @xmath131 for all @xmath132 . in view of the uniformly convexity of @xmath36 ,",
    "there is a @xmath133 such that @xmath134 using @xmath135 we then obtain @xmath136 on the other hand , observing that @xmath137 , we have from the weakly lower semi - continuity of @xmath36 that @xmath138 therefore @xmath139 , which is a contradiction . @xmath140    in many practical applications , proper , weakly lower semi - continuous , uniformly convex functions can be easily constructed .",
    "for instance , consider @xmath141 , where @xmath142 and @xmath143 is a bounded domain in @xmath144 .",
    "it is known that the functional @xmath145 is uniformly convex on @xmath146 ( it is in fact @xmath94-uniformly convex ) .",
    "consequently we obtain on @xmath146 the uniformly convex functions @xmath147 where @xmath148 , @xmath149 , and @xmath150 denotes the total variation of @xmath70 over @xmath143 that is defined by ( @xcite ) @xmath151 for @xmath152 and @xmath153 the corresponding function is useful for sparsity reconstruction ( @xcite ) ; while for @xmath154 and @xmath155 the corresponding function is useful for detecting the discontinuities , in particular , when the solutions are piecewise - constant ( @xcite ) .",
    "we now return to ( [ 1.1 ] ) , where @xmath156 is an operator between two banach spaces @xmath3 and @xmath4 .",
    "we will always assume that @xmath3 is reflexive , @xmath4 is uniformly smooth , and ( [ 1.1 ] ) has a solution . in general",
    ", the equation ( [ 1.1 ] ) may have many solutions . in order to find the desired one ,",
    "some selection criteria should be enforced . choosing a proper convex function @xmath36 ,",
    "we pick @xmath157 and @xmath158 as the initial guess , which may incorporate some available information on the sought solution .",
    "we define @xmath159 to be the solution of ( [ 1.1 ] ) with the property @xmath160    we will work under the following conditions on the convex function @xmath36 and the operator @xmath161 .",
    "[ a0 ] @xmath36 is a proper , weakly lower semi - continuous and uniformly convex function such that ( [ pconv ] ) holds , i.e. there is a strictly increasing continuous function @xmath95 with @xmath96 such that @xmath162 for @xmath98 , @xmath99 and @xmath76 .    [ a1 ]    1 .   * @xmath163 is convex , and @xmath161 is weakly closed , i.e. for any sequence @xmath164 satisfying @xmath165 and @xmath166 there hold @xmath167 and @xmath168 ; * there is @xmath169 such that ( [ 1.1 ] ) has a solution in @xmath170 , where @xmath171 ; * @xmath161 is frchet differentiable on @xmath163 , and @xmath172 is continuous on @xmath163 , where @xmath173 denotes the frchet derivative of @xmath161 at @xmath70 ; * there exists @xmath174 such that @xmath175 for all @xmath176 .    when @xmath3 is a reflexive banach space , by using the weakly closedness of @xmath161 and the weakly lower semi - continuity and uniformly convexity of @xmath36 it is standard to show that @xmath49 exists .",
    "the following result shows that @xmath49 is in fact uniquely defined .",
    "[ lem existence and uniqueness of xdag ] let @xmath3 be reflexive , @xmath36 satisfy assumption [ a0 ] , and @xmath161 satisfy assumption [ a1 ] . if @xmath49 is a solution of @xmath177 satisfying ( [ eq definition of xdag ] ) with @xmath178 then @xmath49 is uniquely defined .",
    "assume that ( [ 1.1 ] ) has two distinct solutions @xmath179 and @xmath49 satisfying ( [ eq definition of xdag ] ) .",
    "then it follows from ( [ eq:20.10june ] ) that @xmath180 by using assumption [ a0 ] on @xmath36 we obtain @xmath181 and @xmath182 . since @xmath183 , we can use assumption [ a1 ] ( d ) to derive that @xmath184 .",
    "let @xmath185 for @xmath186",
    ". then @xmath187 and @xmath188 .",
    "thus we can use assumption [ a1 ] ( d ) to conclude that @xmath189 since @xmath190 , this implies that @xmath191 .",
    "consequently , by the minimal property of @xmath49 we have @xmath192 on the other hand , it follows from the strictly convexity of @xmath36 that @xmath193 for @xmath186 which is a contradiction to ( [ eq:20.7june ] ) .",
    "@xmath140    we are now ready to formulate the nonstationary iterated tikhonov regularization with penalty term induced by the uniformly convex function @xmath36 . for the initial guess @xmath194 and @xmath195 , we take a sequence of positive numbers @xmath196 and define the iterative sequences @xmath197 and @xmath198 successively by @xmath199 for @xmath200 , where @xmath201 and @xmath202 denotes the duality mapping of @xmath4 with gauge function @xmath104 which is single - valued and continuous because @xmath4 is assumed to be uniformly smooth . at each step , the existence of @xmath203 is guaranteed by the reflexivity of @xmath3 and @xmath4 , the weakly lower semi - continuity and uniformly convexity of @xmath36 , and the weakly closedness of @xmath161 .",
    "however , @xmath18 might not be unique when @xmath161 is nonlinear ; we will take @xmath18 to be any one of the minimizers . in view of the minimality of @xmath18",
    ", we have @xmath204 . from the definition of @xmath203",
    ", it is straightforward to see that @xmath205 we will terminate the iteration by the discrepancy principle @xmath206 with a given constant @xmath207 .",
    "the output @xmath208 will be used to approximate a solution of ( [ 1.1 ] ) .    in order to understand the convergence property of @xmath209",
    ", it is necessary to consider the noise - free iterative sequences @xmath121 and @xmath210 , where each @xmath211 and @xmath212 with @xmath200 are defined by ( [ eq method ] ) with @xmath7 replaced by @xmath8 , i.e. , @xmath213 in section [ noise - free ] we will give a detailed convergence analysis on @xmath121 ; in particular , we will show that @xmath121 strongly converges to a solution of ( [ 1.1 ] ) . in order to connect such result with the convergence property of @xmath209",
    ", we will make the following assumption .",
    "[ a2 ] @xmath211 is uniquely defined for each @xmath132 .",
    "we will give some sufficient condition for the validity of assumption [ a2 ] .",
    "this assumption enables us to establish some stability results connecting @xmath18 and @xmath211 so that we can finally obtain the convergence property of @xmath209 in the following result .",
    "[ th2 ] let @xmath3 be reflexive and @xmath4 be uniformly smooth , let @xmath36 satisfy assumption [ a0 ] , and let @xmath161 satisfy assumptions [ a1 ] and [ a2 ] .",
    "assume that @xmath100 , @xmath214 and that @xmath196 is a sequence of positive numbers satisfying @xmath215 and @xmath216 for all @xmath132 with some constant @xmath217 .",
    "assume further that @xmath218 then , the discrepancy principle   terminates the method ( [ eq method ] ) after @xmath219 steps .",
    "moreover , there is a solution @xmath220 of ( [ 1.1 ] ) such that @xmath221 as @xmath222 . if , in addition , @xmath223 for all @xmath224 , then @xmath225 .    in this result",
    ", the closeness condition ( [ eq:20.8june ] ) is used to guarantee that @xmath18 is in @xmath226 for @xmath227 so that assumption [ a1 ] ( d ) can be applied .",
    "this issue does not appear when @xmath228 is a bounded linear operator .",
    "furthermore , assumption [ a2 ] holds automatically for linear problems when @xmath36 is strictly convex .",
    "consequently , we have the following convergence result for linear inverse problems .",
    "[ th3 ] let @xmath229 be a bounded linear operator with @xmath3 being reflexive and @xmath4 being uniformly smooth , let @xmath36 be proper , weakly lower semi - continuous , and uniformly convex , let @xmath100 , and let @xmath196 be such that @xmath215 and @xmath216 for all @xmath132 with @xmath217 .",
    "then , the discrepancy principle with @xmath207 terminates the method after @xmath219 steps . moreover , there hold @xmath48 as @xmath222 .    in the next section",
    ", we will give the detailed proof of theorem [ th2 ] .",
    "it should be pointed out that the convergence @xmath230 does not imply @xmath231 directly since @xmath36 is not necessarily continuous .",
    "the proof of @xmath232 relies on additional observation .",
    "when applying our convergence result to the situation that @xmath39 and @xmath233 with @xmath148 , we can obtain @xmath234 this significantly improves the result in @xcite in which only the boundedness of @xmath235 was derived and hence only weak convergence for a subsequence of @xmath45 can be guaranteed .",
    "we conclude this section with some sufficient condition to guarantee the validity of assumption [ a2 ] .",
    "[ a3 ] there exist @xmath236 and @xmath237 such that @xmath238^{1-\\kappa } \\left[\\delta_r(f(\\bar x)-y , f(x)-y)\\right]^\\kappa\\end{aligned}\\ ] ] for all @xmath239 with @xmath99 and @xmath240 , where @xmath241 denotes the bregman distance on @xmath4 induced by the convex function @xmath242 .",
    "when @xmath4 is a @xmath111-uniformly convex banach space , @xmath36 is a @xmath94-uniformly convex function on @xmath3 with @xmath93 , and @xmath243 , assumption [ a3 ] holds with @xmath244 if there is a constant @xmath245 such that @xmath246 for @xmath247 , which is a slightly strengthened version of assumption  [ a1 ]  ( d ) .",
    "[ lem : a3 ] let @xmath3 be reflexive and @xmath4 be uniformly smooth , let @xmath100 , let @xmath36 satisfy assumption [ a0 ] , let @xmath161 satisfy assumptions [ a1 ] and [ a3 ] , and let @xmath15 satisfy @xmath25 .",
    "assume that @xmath248^{1-\\frac{1}{r } } < 1\\end{aligned}\\ ] ] with @xmath249 .",
    "then assumption [ a2 ] holds , i.e. @xmath211 is uniquely defined for each @xmath132 .",
    "we will prove lemma [ lem : a3 ] at the end of section [ subsect4.1 ] by using some useful estimates that will be derived during the proof of the convergence of @xmath121 .",
    "we prove theorem [ th2 ] in this section .",
    "we first obtain a convergence result for the noise - free iterative sequences @xmath121 and @xmath210 .",
    "we then consider the sequences @xmath12 and @xmath30 corresponding to the noisy data case , and show that the discrepancy principle indeed terminates the iteration in finite steps .",
    "we further establish a stability result which in particular implies that @xmath250 as @xmath222 for each fixed @xmath132 . combining all these results",
    "we finally obtain the proof of theorem [ th2 ] .",
    "[ subsect4.1 ]    we first consider the noise - free iterative sequences @xmath121 and @xmath210 defined by ( [ eq : method ] ) and obtain a convergence result that is crucial for proving theorem [ th2 ] .",
    "our proof is inspired by @xcite .",
    "[ thm1 ] let @xmath3 be reflexive and @xmath4 be uniformly smooth , let @xmath100 , let @xmath36 satisfy assumption [ a0 ] , let @xmath161 satisfy assumption [ a1 ] , and let @xmath15 satisfy @xmath25 .",
    "assume that @xmath251 then there exists a solution @xmath252 of ( [ 1.1 ] ) in @xmath253 such that @xmath254 if in addition @xmath255 for all @xmath224 , then @xmath225 .",
    "we first show by induction that for any solution @xmath179 of ( [ 1.1 ] ) in @xmath253 there holds @xmath256 this is trivial for @xmath257 .",
    "assume that it is true for @xmath258 for some @xmath259 , we will show that it is also true for @xmath260 . from ( [ 4.3.1 ] ) we have @xmath261 by dropping the first term on the right which is non - positive and using the definition of @xmath262 we can obtain @xmath263 in view of the properties of the duality mapping @xmath118 it follows that @xmath264 in order to proceed further ,",
    "we need to show that @xmath265 so that assumption [ a1 ] ( d ) on @xmath161 can be employed . using the minimizing property of @xmath266 , the induction hypothesis , and ( [ 21.1june ] ) we obtain @xmath267 with the help of assumption [ a0 ] on @xmath36 , we have @xmath268 therefore @xmath269 . thus we may use assumption [ a1 ] ( d ) to obtain from ( [ 5.4.1 ] ) that @xmath270 this and the induction hypothesis imply ( [ 7.7.1 ] ) with @xmath260 .    as an immediate consequence of ( [ 7.7.1 ] ) , we know that ( [ 7.7.2 ] ) is true for all @xmath271 .",
    "consequently @xmath272 and @xmath273 by using the monotonicity of @xmath274 with respect to @xmath132 , we obtain @xmath275 since @xmath276 as @xmath125 , we have @xmath277 as @xmath125 .",
    "next we show that @xmath121 converges to a solution of ( [ 1.1 ] ) . to this end , we show that @xmath121 is a cauchy sequence in @xmath3 .",
    "for @xmath278 we have from ( [ 4.3.1 ] ) that @xmath279 by the definition of @xmath212 we have @xmath280 by using assumption [ a1 ] ( d ) on @xmath161 and the monotonicity of @xmath274 we can obtain @xmath281 therefore , by using ( [ 8.4.2012 ] ) , we have with @xmath282 that @xmath283 consequently @xmath284 since @xmath285 is monotonically decreasing , we obtain @xmath286 as @xmath287 . in view of the uniformly convexity of @xmath36",
    ", we can conclude that @xmath121 is a cauchy sequence in @xmath3 .",
    "thus @xmath288 for some @xmath289 as @xmath125 .",
    "since @xmath277 as @xmath125 , we may use the weakly closedness of @xmath161 to conclude that @xmath290 and @xmath291 .",
    "we remark that @xmath292 because @xmath293 .",
    "next we show that @xmath294 from the convexity of @xmath36 and @xmath295 it follows that @xmath296 in view of ( [ 5.5.1 ] ) we have @xmath297 since @xmath288 as @xmath125 , by using the weakly lower semi - continuity of @xmath36 we obtain @xmath298 this implies that @xmath220 .",
    "we next use ( [ 5.5.1 ] ) to derive for @xmath299 that @xmath300 by taking @xmath125 and using @xmath288 we can derive that @xmath301 where @xmath302 whose existence is guaranteed by the monotonicity of @xmath303 .",
    "since the above inequality holds for all @xmath304 , by taking @xmath305 we obtain @xmath306 using ( [ 5.5.3 ] ) with @xmath179 replaced by @xmath252 we thus obtain @xmath307 . combining this with ( [ 5.5.2 ] )",
    "we therefore obtain @xmath308 .",
    "this together with ( [ 5.5.6.1 ] ) then implies that @xmath309",
    ".    finally we prove @xmath225 under the additional condition @xmath255 for @xmath224 .",
    "we use ( [ 5.5.3 ] ) with @xmath179 replaced by @xmath49 to obtain @xmath310 by using ( [ 5.5.1 ] ) , for any @xmath311 we can find @xmath312 such that @xmath313 we next consider @xmath314 . according to the definition of @xmath212 we have @xmath315 .",
    "since @xmath3 is reflexive and @xmath316 , we have from ( [ eq:28.1june ] ) that @xmath317 .",
    "thus we can find @xmath318 and @xmath319 such that @xmath320 where @xmath321 is a constant such that @xmath322 for all @xmath132 .",
    "consequently @xmath323\\right|\\\\ & \\le \\sum_{j=1}^{l_0 } \\left(\\|v_j\\| \\|f'(x^\\dag ) ( x_n - x^\\dag)\\| + \\|\\beta_j\\| \\|x_n - x^\\dag\\|\\right)\\\\ & \\le ( 1+\\eta ) \\sum_{j=1}^{l_0 } \\|v_j\\| \\|f(x_n)-y\\| + \\frac{\\varepsilon}{3}.\\end{aligned}\\ ] ] since @xmath277 as @xmath125 , we can find @xmath324 such that @xmath325 therefore @xmath326 for all @xmath327 .",
    "since @xmath311 is arbitrary , we obtain @xmath328 . by taking @xmath125 in ( [ 5.5.7 ] ) and using @xmath329",
    "we obtain @xmath330 according to the definition of @xmath49 we must have @xmath331 .",
    "a direct application of lemma [ lem existence and uniqueness of xdag ] gives @xmath225 .",
    "@xmath140    as a byproduct , now we can use some estimates established in the proof of theorem [ thm1 ] to prove lemma [ lem : a3 ] .",
    "0.15 cm _ proof of lemma [ lem : a3 ] .",
    "_ we assume that the minimization problem in ( [ eq : method ] ) has two minimizers @xmath211 and @xmath332 .",
    "then it follows that @xmath333 with the help of the definition of @xmath212 we can write @xmath334 therefore @xmath335 since @xmath336 as shown in the proof of theorem [ thm1 ] , we may use assumption [ a3 ] and the young s inequality to obtain @xmath337^{1-\\kappa } \\left[\\delta_r ( f(\\hat{x}_n)-y , f(x_n)-y)\\right]^\\kappa\\\\ & \\ge \\a_n d_{\\xi_n } \\theta(\\hat{x}_n , x_n ) - ( 1-\\kappa ) \\kappa^{\\frac{\\kappa}{1-\\kappa } } c_0^{\\frac{1}{1-\\kappa } } \\|f(x_n)-y\\|^{\\frac{r-1}{1-\\kappa } } d_{\\xi_n } \\theta(\\hat{x}_n , x_n).\\end{aligned}\\ ] ] recall that in the proof of theorem [ thm1 ] we have established @xmath338 since @xmath339 and @xmath340 , we therefore obtain @xmath341 with @xmath249 .",
    "thus we may use the second condition in ( [ 21.11june ] ) to conclude that @xmath342 and hence @xmath343 .",
    "@xmath140      in this subsection we show that the method is well - defined , in particular we prove that , when the data contains noise , the discrepancy principle ( [ dp ] ) terminates the iteration in finite steps , i.e. @xmath344 .    [ lem stop ] let @xmath3 be reflexive and @xmath4 be uniformly smooth , let @xmath36 satisfy assumption [ a0 ] , and let @xmath161 satisfy assumption [ a1 ] .",
    "let @xmath100 and @xmath214 , and let @xmath15 be such that @xmath345 .",
    "assume that ( [ 21.1june ] ) holds .",
    "then the discrepancy principle   terminates the iteration after @xmath219 steps . if @xmath346 , then for @xmath347 there hold @xmath348 if , in addition , @xmath349 for all @xmath132 with some constant @xmath217 and @xmath350 then there holds @xmath351 where @xmath179 denotes any solution of ( [ 1.1 ] ) in @xmath253 and @xmath352 $ ] .    to prove the first part , we first show by induction that @xmath353 this is trivial for @xmath257 .",
    "next we assume that ( [ eq:20.4june ] ) is true for @xmath258 for some @xmath354 and show that ( [ eq:20.4june ] ) is also true for @xmath260 . by the minimizing property of @xmath355 and",
    "the induction hypothesis we have @xmath356 since @xmath357 , we can obtain @xmath358 because @xmath207 , this implies that @xmath359 by assumption [ a0 ] and the condition ( [ 21.1june ] ) , we can derive that @xmath360 . in view of the induction hypothesis",
    "we also have @xmath361 .",
    "thus @xmath362 .",
    "we are now able to use assumption [ a1 ] ( d ) and the similar argument for deriving to obtain that @xmath363 using again @xmath364 , we can conclude that @xmath365 since @xmath214 , we obtain @xmath366 in view of this inequality with @xmath367 and the induction hypothesis , we obtain the second result in ( [ eq:20.4june ] ) with @xmath260 . by using again assumption",
    "[ a0 ] and ( [ 21.1june ] ) we have @xmath368 and @xmath182 which imply that @xmath369 .",
    "we therefore complete the proof of ( [ eq:20.4june ] ) .",
    "as a direct consequence , we can see that ( [ 20.6june ] ) holds for all @xmath370 which implies ( [ eq decrease2 ] ) and ( [ eq decrease22 ] ) .    in view of   and the monotonicity ( [ mono ] ) of @xmath371 with respect to @xmath132",
    ", it follows that @xmath372 since @xmath373 for @xmath374 and @xmath375 as @xmath376 , we can conclude that @xmath46 is a finite integer .",
    "finally we prove the second part , i.e. the inequality ( [ eq ndelta ] ) . since ( [ eq7.21 ] ) is true for @xmath377 , we have @xmath378 recall from ( [ eq:20.6june ] ) that @xmath379 . since @xmath380 , we can derive that @xmath381 it then follows from assumption [ a0 ] and ( [ eq:20.5june ] ) that @xmath382 . since @xmath383 we obtain @xmath384 .",
    "thus we can employ assumption [ a1 ] ( d ) to conclude that ( [ eq:19.5june ] ) is also true for @xmath377 . by setting @xmath377 in ( [ eq:19.5june ] ) and using @xmath385",
    ", we can obtain .",
    "@xmath140    as a byproduct of the proof of lemma [ lem stop ] , we have the following result which will be used to show @xmath386 in the proof of theorem [ th2 ] .",
    "[ lem 19june ] let all the conditions in lemma [ lem stop ] hold , and let @xmath179 be any solution of ( [ 1.1 ] ) in @xmath253 .",
    "then for all @xmath387 there holds @xmath388 where @xmath389 and @xmath390 $ ] .    by the definition of @xmath391 and the property of the duality mapping @xmath118 ,",
    "we can obtain , using the similar argument for deriving ( [ eq:19.6june ] ) , that @xmath392 with the help of assumption [ a1 ] ( d ) and the monotonicity ( [ mono ] ) of @xmath371 with respect to @xmath132 , similar to the derivation of ( [ eq:20.1june ] ) we have for @xmath393 that @xmath394 therefore @xmath395 since @xmath396 and @xmath397 for @xmath398 , we thus obtain @xmath399 in view of ( [ eq decrease22 ] ) in lemma [ lem stop ] , we can see that @xmath400 combining this inequality with ( [ eq:19.7june ] ) gives the desired estimate .",
    "we will prove some stability results on the method which connect @xmath12 with @xmath121 .",
    "these results enable us to use theorem [ thm1 ] to complete the proof of theorem [ th2 ] .",
    "[ lem xdelta ] let @xmath3 be reflexive and @xmath4 be uniformly smooth , let @xmath36 satisfy assumption [ a0 ] , and let @xmath161 satisfy assumptions [ a1 ] and [ a2 ] .",
    "then for each fixed @xmath132 there hold @xmath401 as @xmath402 .",
    "we show this result by induction .",
    "it is trivial when @xmath257 since @xmath403 and @xmath404 . in the following",
    "we assume that the result is proved for @xmath258 and show that the result holds also for @xmath260 .",
    "we will adapt the argument from @xcite .",
    "let @xmath405 be a sequence of data satisfying @xmath406 with @xmath407 . by the minimizing property of @xmath408 we have @xmath409 by the induction hypothesis",
    ", we can see that the right hand side of the above inequality is uniformly bounded with respect to @xmath410 .",
    "therefore both @xmath411 and @xmath412 are uniformly bounded with respect to @xmath410 .",
    "consequently @xmath413 is bounded in @xmath4 and @xmath414 is bounded in @xmath3 ; here we used the uniformly convexity of @xmath36 . since both @xmath3 and @xmath4 are reflexive , by taking a subsequence if necessary , we may assume that @xmath415 and @xmath416 as @xmath417 .",
    "since @xmath161 is weakly closed , we have @xmath418 and @xmath419 . in view of the weakly lower semi - continuity of banach space norm we have @xmath420 moreover , by using @xmath421 , the weakly lower semi - continuity of @xmath36 , and the induction hypothesis",
    ", we have @xmath422 the inequalities ( [ eq use2 ] ) and ( [ eq use1 ] ) together with the minimizing property of @xmath408 and the induction hypothesis imply @xmath423 according to the definition of @xmath266 and assumption [ a2 ] , we must have @xmath424 .",
    "therefore @xmath425 , @xmath426 , and @xmath427    next we will show that @xmath428 let @xmath429 in view of , it suffices to show @xmath430 .",
    "assume to the contrary that @xmath431 . by taking a subsequence if necessary",
    ", we may assume that @xmath432 it then follows from ( [ eq:18june ] ) that @xmath433 which is a contradiction to ( [ eq use2 ] ) .",
    "we therefore obtain ( [ eq lim ] ) .    by using the induction hypothesis and @xmath425",
    ", we obtain from ( [ eq lim ] ) that @xmath434 since @xmath425 and since @xmath36 has the kadec property , see lemma [ lem : kadec ] , we obtain that @xmath435 as @xmath417 . finally , from the definition of @xmath436 , the induction hypothesis , and the continuity of the map @xmath172 , and the continuity of the duality mapping @xmath118 , it follows that @xmath437 as @xmath417 .",
    "the above argument shows that for any sequence @xmath405 converging to @xmath8 , the sequence @xmath414 always has a subsequence , still denoted as @xmath408 , such that @xmath435 , @xmath438 and @xmath439 as @xmath440 .",
    "therefore , we obtain ( [ eq 3convergence ] ) with @xmath260 as @xmath441 .",
    "the proof is complete .",
    "@xmath140      since",
    "other parts have been proved in lemma [ lem stop ] , it remains only to show the convergence result ( [ eq : convergence ] ) , where @xmath252 is the limit of @xmath121 which exists by theorem [ thm1 ] .",
    "assume first that @xmath405 is a sequence satisfying @xmath442 with @xmath407 such that @xmath443 as @xmath417 for some integer @xmath444 .",
    "we may assume @xmath445 for all @xmath410 .",
    "from the definition of @xmath446 , we have @xmath447 since lemma [ lem xdelta ] implies @xmath448 , by letting @xmath440 we have @xmath449 .",
    "this together with the definition of @xmath211 implies that @xmath450 for all @xmath451 .",
    "since theorem [ thm1 ] implies @xmath288 as @xmath376 , we must have @xmath452 .",
    "consequently , we have from lemma [ lem xdelta ] that @xmath453 , @xmath454 and @xmath455 as @xmath440 .",
    "assume next that @xmath405 is a sequence satisfying @xmath442 with @xmath407 such that @xmath456 as @xmath440 .",
    "we first show that @xmath457 let @xmath130 be an arbitrary number . since theorem [ thm1 ] implies @xmath458 as @xmath125 , there exists an integer @xmath459 such that @xmath460 . on the other hand ,",
    "since lemma [ lem xdelta ] implies @xmath461 , @xmath462 and @xmath463 as @xmath417 , we can pick an integer @xmath464 large enough such that for all @xmath465 there hold @xmath466 and @xmath467 therefore , it follows from lemma [ lem stop ] that @xmath468 for all @xmath469 .",
    "since @xmath130 is arbitrary , we thus obtain ( [ eq:19june ] ) . with the help of",
    ", we then obtain @xmath470 in view of we have @xmath471 since @xmath472 , we can conclude from ( [ eq:19june ] ) that @xmath473 . since @xmath474",
    ", we must have @xmath475 as @xmath440 . in view of and",
    "( [ eq:20.2june ] ) , we can obtain @xmath476 which together with the uniformly convexity of @xmath36 implies that @xmath477 as @xmath440 .",
    "finally we show that @xmath478 as @xmath479 . in view of ( [ eq:19.8june ] ) , it suffices to show that @xmath480 recall that @xmath329 and @xmath481 as @xmath482 which have been established in theorem [ thm1 ] and its proof .",
    "thus , for any @xmath130 , we can pick an integer @xmath312 such that @xmath483 then , using ( [ eq:19.9june ] ) in lemma [ lem 19june ] , we can derive @xmath484 by using the definition of bregman distance and ( [ eq:19.10june ] ) we have @xmath485 + \\left [ \\theta(x_{l_0 } ) -\\theta(x_{l_0}^{\\d_i})\\right ]   - \\l \\xi_{l_0 } , x_*-x_{l_0}\\r \\\\ & \\quad \\",
    ", -\\l \\xi_{l_0 } , x_{l_0 } -x_{l_0}^{\\d_i}\\r   - \\l \\xi_{l_0}^{\\d_i}-\\xi_{l_0 } , x_*-x_{l_0}^{\\d_i}\\r\\\\ & \\le 2\\epsilon + \\left| \\theta(x_{l_0 } ) -\\theta(x_{l_0}^{\\d_i})\\right| + \\left|\\l \\xi_{l_0 } , x_{l_0 } -x_{l_0}^{\\d_i}\\r\\right| + \\left| \\l \\xi_{l_0}^{\\d_i}-\\xi_{l_0 } , x_*-x_{l_0}^{\\d_i}\\r \\right|.\\end{aligned}\\ ] ] therefore @xmath486 in view of lemma [ lem xdelta ] and the facts that @xmath487 and @xmath477 as @xmath440 which we have established in the above , we can conclude that there is an integer @xmath488 such that for all @xmath489 there hold @xmath490 and @xmath491 . since @xmath130 is arbitrary ,",
    "we thus obtain ( [ eq:19.11june ] ) .",
    "when @xmath46 denotes the integer determined by the discrepancy principle ( [ dp ] ) , from lemma [ lem stop ] we can see that the bregman distance @xmath492 is decreasing up to @xmath493 .",
    "this monotonicity , however , may not hold at @xmath494 . therefore , it seems reasonable to consider the following variant of the discrepancy principle .",
    "[ rule4.1 ] let @xmath207 be a given number .",
    "if @xmath495 , we define @xmath496 ; otherwise we define @xmath497 i.e. , @xmath46 is the integer such that @xmath498    we point out that the argument for proving theorem [ th2 ] can be used to prove the convergence property of @xmath209 for @xmath46 determined by rule [ rule4.1 ] , we can even drop the condition @xmath216 on @xmath196 in theorem [ th2 ] .",
    "in fact we have the following result .    [ th4 ]",
    "let @xmath3 be reflexive and @xmath4 be uniformly smooth , @xmath36 satisfy assumption [ a0 ] , and @xmath161 satisfy assumptions [ a1 ] and [ a2 ] .",
    "let @xmath100 and @xmath214 , and let @xmath196 be such that @xmath215 . assume further that @xmath499 then , the integer @xmath46 defined by rule [ rule4.1 ] is finite .",
    "moreover , there is a solution @xmath220 of ( [ 1.1 ] ) such that @xmath500 as @xmath222 .",
    "if , in addition , @xmath223 for all @xmath224 , then @xmath225 .",
    "the proof of lemma [ lem stop ] can be used without change to show that @xmath344 and that ( [ eq decrease2 ] ) and ( [ eq decrease22 ] ) hold for @xmath501 . consequently , ( [ eq:19.9june ] ) in lemma [ lem 19june ] becomes @xmath502    in order to prove the convergence result ( [ eq : convergence222 ] ) , as in the proof of theorem [ th2 ] we consider two cases .",
    "assume first that @xmath405 is a sequence satisfying @xmath442 with @xmath407 such that @xmath443 as @xmath417 for some integer @xmath444 .",
    "we may assume @xmath445 for all @xmath410 .",
    "by rule [ rule4.1 ] we always have @xmath503 . by letting @xmath417",
    ", we obtain @xmath504 .",
    "this together with the definition of @xmath211 implies that @xmath505 for all @xmath506 .",
    "it then follows from theorem [ thm1 ] that @xmath507 .",
    "we claim that @xmath508 . to see this , by using the definition of @xmath509 ,",
    "we have @xmath510 therefore @xmath511 this and the strictly convexity of @xmath36 imply that @xmath508 .",
    "consequently @xmath452 . a simple application of lemma [ lem xdelta ]",
    "then gives the desired conclusion .",
    "assume next that @xmath405 is a sequence satisfying @xmath512 with @xmath407 such that @xmath513 as @xmath417 .",
    "we can follow the argument for deriving ( [ eq:19june ] ) to show that @xmath514 which in turn implies that @xmath477 by the uniformly convexity of @xmath36",
    ". then we can use ( [ eq:22.1june ] ) and follow the same procedure in the proof of theorem [ th2 ] to obtain @xmath515 as @xmath440 .",
    "in this section we present some numerical simulations to test the performance of our method by considering a linear integral equation of the first kind and a nonlinear problem arising from the parameter identification in partial differential equations .",
    "we consider the linear integral equation of the form @xmath516,\\end{aligned}\\ ] ] where @xmath517 it is clear that @xmath518\\to \\y:=l^2[0,1]$ ] is a compact operator .",
    "our goal is to find the solution of by using some noisy data @xmath519 instead of @xmath8 .",
    "we assume that the exact solution is @xmath520 , \\\\           1 , &       t\\in[0.500,0.508 ] , \\\\           0.7 , & t\\in [ 0.700 , 0.708],\\\\           0 , & \\mbox{elsewhere }               \\end{array }             \\right.\\end{aligned}\\ ] ] let @xmath521 which is the exact data . for a given noise level @xmath522",
    ", we add random gaussian noise to @xmath8 to obtain @xmath7 satisfying @xmath523 } = \\d$ ] which is used to reconstruct @xmath49 when the iteration is terminated by the discrepancy principle ( [ dp ] ) .    in our numerical simulations , we take @xmath524 and @xmath525 , we divide @xmath526 $ ] into @xmath527 subintervals of equal length , approximate any integrals by the trapezoidal rule , and solve the involved minimization problems by the modified fletcher - reeves cg method in @xcite . in figure [ linear1 ]",
    "we present the reconstruction results by taking @xmath528 and @xmath529 with @xmath530 in the discrepancy principle ( [ dp ] ) .",
    "figure [ linear1](a ) reports the result via the method with @xmath531 .",
    "it is clear that the reconstructed solution is rather oscillatory and fails to capture the sparsity of the exact solution @xmath159 .",
    "figure [ linear1](b ) gives the result of the method with @xmath532 and @xmath533 . during the computation ,",
    "@xmath534 is replaced by a smooth one @xmath535 with @xmath536 .",
    "the sparsity reconstruction is significantly improved .",
    "[ ex4 ] we next consider the identification of the parameter @xmath537 in the boundary value problem @xmath538 from an @xmath539-measurement of the state @xmath540 , where @xmath541 , @xmath542 , is a bounded domain with lipschitz boundary , @xmath543 and @xmath544 .",
    "we assume that the sought solution @xmath545 is in @xmath539 .",
    "this problem reduces to solving an equation of the form ( [ 1.1 ] ) if we define the nonlinear operator @xmath546 by @xmath547 , where @xmath548 denotes the unique solution of ( [ pde ] ) .",
    "this operator @xmath161 is well defined on @xmath549 for some positive constant @xmath550 .",
    "it is well known that @xmath161 is frchet differentiable ; the frchet derivative of @xmath161 and its adjoint are given by @xmath551 for @xmath552 , where @xmath553 is defined by @xmath554 which is an isomorphism uniformly in a ball @xmath555 for any @xmath556 with small @xmath169 .",
    "it has been shown ( see @xcite ) that for any @xmath557 there holds @xmath558 therefore , assumption [ a1 ] and the condition ( [ a1-s ] ) hold if @xmath169 is small enough .    in our numerical simulation , we consider the two dimensional problem with @xmath559\\times[0,1]$ ] and @xmath560\\times [ 0.2,0.5]$ ; } \\\\      0 , & \\hbox{elsewhere .",
    "}    \\end{array } \\right.\\end{aligned}\\ ] ] we assume @xmath561 and add noise to produce the noisy data @xmath562 satisfying @xmath563 .",
    "we take @xmath564 and @xmath529 .",
    "the partial differential equations involved are solved approximately by a finite difference method by dividing @xmath143 into @xmath565 small squares of equal size . and the involved minimization problems are solved by the modified nonlinear cg method in @xcite .",
    "we take the initial guess @xmath566 and @xmath525 , and terminate the iteration by the discrepancy principle with @xmath567 .",
    "figure [ nonlinear2](a ) plots the exact solution @xmath568 .",
    "figure [ nonlinear2](b ) shows the result for the method with @xmath569 .",
    "figure [ nonlinear2 ] ( c ) and ( d ) report the reconstruction results for the method with @xmath570 for @xmath533 and @xmath571 respectively ; the term @xmath572 is replaced by a smooth one @xmath573 with @xmath536 during computation .",
    "the reconstruction results in ( c ) and ( d ) significantly improve the one in ( b ) by efficiently removing the notorious oscillatory effect and indicate that the method is robust with respect to @xmath574 .",
    "we remark that , due to the smaller value of @xmath574 , the reconstruction result in ( d ) is slightly better than the one in ( c ) as can be seen from the plots ; the computational time for ( d ) , however , is longer .",
    "0.3 cm * acknowledgements * q jin is partly supported by the grant de120101707 of australian research council , and m zhong is partly supported by the national natural science foundation of china ( no.11101093 ) ."
  ],
  "abstract_text": [
    "<S> we consider the nonstationary iterated tikhonov regularization in banach spaces which defines the iterates via minimization problems with uniformly convex penalty term . the penalty term is allowed to be non - smooth to include @xmath0 and total variation ( tv ) like penalty functionals , which are significant in reconstructing special features of solutions such as sparsity and discontinuities in practical applications . </S>",
    "<S> we present the detailed convergence analysis and obtain the regularization property when the method is terminated by the discrepancy principle . in particular we establish the strong convergence and the convergence in bregman distance which sharply contrast with the known results that only provide weak convergence for a subsequence of the iterative solutions . some numerical experiments on linear integral equations of first kind and parameter identification in differential equations are reported .    </S>",
    "<S> example.eps    gsave newpath 20 20 moveto 20 220 lineto 220 220 lineto 220 20 lineto closepath 2 setlinewidth gsave .4 setgray fill grestore stroke grestore    [ section ] [ section ] [ section ]         </S>"
  ]
}