{
  "article_text": [
    "a key challenge in artificial intelligence is how to effectively learn to make a sequence of good decisions in stochastic , unknown environments .",
    "reinforcement learning ( rl ) is a subfield specifically focused on how agents can learn to make good decisions given feedback in the form of a reward signal . in many important applications such as robotics , education , and healthcare",
    ", the agent can not directly observe the state of the environment responsible for generating the reward signal , and instead only receives incomplete or noisy observations .",
    "one important measure of an rl algorithm is its sample efficiency : how much data / experience is needed to compute a good policy and act well .",
    "one way to measure sample complexity is given by the probably approximately correct framework ; an rl algorithm is said to be pac if with high probability , it selects a near - optimal action on all but a number of steps ( the sample complexity ) which is a polynomial function of the problem parameters .",
    "there has been substantial progress on pac rl for the fully observable setting  @xcite , but to our knowledge there exists no published work on pac rl algorithms for partially observable settings .",
    "this lack of work on pac partially observable rl is perhaps because of the additional challenge introduced by the partial observability of the environment . in fully observable settings ,",
    "the world is often assumed to behave as a markov decision process ( mdp ) .",
    "an elegant approach for proving that a rl algorithm for mdps is pac is to compute finite sample error bounds on the mdp parameters .",
    "however , because the states of a partially observable mdp ( pomdp ) are hidden , the naive approach of directly treating the pomdp as a history - based mdp yields a state space that grows exponentially with the horizon , rather than polynomial in all pomdp parameters  @xcite .",
    "on the other hand , there has been substantial recent interest and progress on method of moments and spectral approaches for modeling partially observable systems  @xcite .",
    "the majority of this work has focused on inference and prediction , with little work tackling the control setting .",
    "method of moments approaches to latent variable estimation are of particular interest because for a number of models they obtain global optima and provide finite sample guarantees on the accuracy of the learned model parameters .",
    "inspired by the this work , we propose a pomdp rl algorithm that is , to our knowledge , the first pac pomdp rl algorithm for episodic domains ( with no restriction on the policy class ) .",
    "our algorithm is applicable to a restricted but important class of pomdp settings , which include but are not limited to information gathering pomdp rl domains such as preference elicitation  @xcite , dialogue management slot - filling domains  @xcite , and medical diagnosis before decision making  @xcite .",
    "our work builds on method of moments inference techniques , but requires several non - trivial extensions to tackle the control setting . in particular",
    ", there is a subtle issue of latent state alignment : if the models for each action are learned as independent hidden markov models ( hmms ) , then it is unclear how to solve the correspondence issue across latent states , which is essential for performing planning and selecting actions .",
    "our primary contribution is to provide a theoretical analysis of our proposed algorithm , and prove that it is possible to obtain near - optimal performance on all but a number of episodes that scales as a _ polynomial",
    "_ function of the pomdp parameters .",
    "similar to most fully observable pac rl algorithms , directly instantiating our bounds would yield an impractical number of samples for a real application .",
    "nevertheless , we believe understanding the sample complexity may help to guide the amount of data required for a task , and also similar to pac mdp rl work , may motivate new practical algorithms that build on these ideas .",
    "the inspiration for pursuing pac bounds for pomdps came about from the success of pac bounds for mdps  @xcite . while algorithms have been developed for pomdps with finite sample bounds  @xcite , unfortunately these bounds are not pac as they have an exponential dependence on the horizon length .",
    "alternatively , bayesian methods  @xcite are very popular for solving pomdps . for mdps",
    ", there exist bayesian methods that have pac bounds  @xcite ; however there have been no pac bounds for bayesian methods for pomdps .",
    "that said , bayesian methods are optimal in the bayesian sense of making the best decision given the posterior over all possible future observations , which does not translate to a frequentist finite sample bound .",
    "we build on method of moments ( mom ) work for estimating hmms  @xcite in order to provide a finite sample bound for pomdps .",
    "mom is able to obtain a global optimum , and has finite sample bounds on the accuracy of their estimates , unlike the popular expectation - maximization ( em ) that is only guaranteed to find a local optima , and offers no finite sample guarantees .",
    "mle approaches for estimating hmms  @xcite also unfortunately do not provide accuracy guarantees on the estimated hmm parameters .",
    "as pomdp planning methods typically require us to have estimates of the underlying pomdp parameters , it would be difficult to use such mle methods for computing a pomdp policy and providing a finite sample guarantee - length observation sequences has a bounded kl - divergence from the true probability of the sequence under the true parameters , which is expressed as a function of the number of underlying data samples used to estimate the hmm parameters .",
    "we think it may be possible to use such estimates in the control setting when modeling hidden state control systems as psrs , and employing a forward search approach to planning ; however , there remain a number of subtle issues to address to ensure such an approach is viable and we leave this as an interesting direction for future work . ] .    aside from the mom method in @xcite ,",
    "another popular spectral method involves using predictive state representations ( psrs ) @xcite , to directly tackle the control setting ; however it only has asymptotic convergence guarantees and no finite sample analysis .",
    "there is also another method of moments approach to transfer across a set of bandits tasks , but the latent variable estimation problem is substantially simplified because the state of the system is unchanged by the selected actions  @xcite .",
    "fortunately , due to the polynomial finite sample bounds from mom , we can achieve a pac ( polynomial ) sample complexity bound for pomdps .",
    "we have provided a pac rl algorithm for an important class of episodic pomdps , which includes many information gathering domains . to our knowledge",
    "this is the first rl algorithm for partially observable settings that has a sample complexity that is a polynomial function of the pomdp parameters .",
    "there are many areas for future work .",
    "we are interested in reducing the set of currently required assumptions , thereby creating pac porl algorithms that are suitable to more generic settings .",
    "such a direction may also require exploring alternatives to method of moments approaches for performing latent variable estimation .",
    "we also hope that our theoretical results will lead to further insights on practical algorithms for partially observable rl ."
  ],
  "abstract_text": [
    "<S> many interesting real world domains involve reinforcement learning ( rl ) in partially observable environments . </S>",
    "<S> efficient learning in such domains is important , but existing sample complexity bounds for partially observable rl are at least exponential in the episode length . </S>",
    "<S> we give , to our knowledge , the first partially observable rl algorithm with a polynomial bound on the number of episodes on which the algorithm may not achieve near - optimal performance . </S>",
    "<S> our algorithm is suitable for an important class of episodic pomdps . </S>",
    "<S> our approach builds on recent advances in method of moments for latent variable model estimation . </S>"
  ]
}