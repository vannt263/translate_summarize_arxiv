{
  "article_text": [
    "there are many problems that involve solving a set of simultaneous linear equations . in many instances , the coefficients of the variables are uncertain and these uncertainties need to be taken into account in the final solution .",
    "the results presented in this paper are general and can be applied to any problem involving the solution of linear equations .",
    "moreover the full covariance matrix is calculated .",
    "the use of the covariance formula is illustrated using an example where a number of branching ratios of a given particle were simultaneously measured .",
    "a recent paper reporting results on the decay of the tau lepton @xcite used a matrix inversion technique to solve for several branching ratios simultaneously . in that paper , the treatment of the statistical uncertainties assumed only diagonal errors .",
    "this paper develops a formula for the covariance of the inverse matrix elements .",
    "the treatment follows the propagation of errors formalism @xcite for small errors .",
    "a full treatment of the covariance matrix is necessary because the off - diagonal errors can be significant .",
    "the fraction of time a particle decays into a given final state is defined to be the branching ratio .",
    "the branching ratios of a particle decaying into a set of @xmath1 possible final states may be determined by finding @xmath1 selection criteria that have an efficiency for selecting the desired decay channel .",
    "the selection criteria are usually not fully efficient so a set of linear equations results , @xmath2 where @xmath3 is the @xmath4 unknown branching ratio , @xmath5 is the fraction of events chosen by the @xmath6 selection from a measured sample with an efficiency @xmath7 .",
    "the fractions are usually corrected for background using monte carlo estimates .    the efficiency is typically calculated by applying the same selections to a monte carlo sample of events .",
    "thus , the efficiency is given by @xmath8 where @xmath9 is the number of events of decay channel @xmath10 selected by selection @xmath11 and @xmath12 is the total number events of type @xmath10 in the monte carlo sample .",
    "as can be seen from equation  [ eqteff ] , the elements of @xmath7 are positive definite and less than or equal to one .",
    "an uncertainty for each efficiency matrix element can be determined from the monte carlo statistics .",
    "the simultaneous equations given by equation  [ ref_lin_eqtns ] can be written in matrix form , @xmath13 the vector of branching ratios can be solved from the matrix equation , @xmath14 where @xmath15 is the inverse of the efficiency matrix .",
    "the matrix @xmath16 must be nonsingular in order for the inverse to exist or equivalently the determinant must be nonzero . a singular @xmath16 signals an ill defined set of selections or event types .",
    "the uncertainty of the branching ratios , @xmath17 , can be written in terms of the uncertainties on the elements of the matrices @xmath18 and @xmath15 .",
    "the errors for @xmath18 are determined from the data and the estimates of the background .",
    "the errors on @xmath15 can be calculated in terms of the covariances of the elements of @xmath16 .",
    "the error formulae for @xmath15 used in the literature are described in section  2 .",
    "a more general treatment of the errors taking into account the full covariance matrix is presented in section  3 whilst the detailed derivations are given in appendix  a.    an analytical example based on matrices of order @xmath0 is developed in appendix  b and a monte carlo study based on the @xmath0 case is discussed in sections  4  and  5 .",
    "the monte carlo studies will illustrate that the formula is only realistic when the efficiency matrix is sufficiently far away from being singular .",
    "the calculation of the covariances becomes more reliable as the ratio of the value of the determinant of the efficiency matrix , to the value of the uncertainty on the determinant becomes larger .",
    "a formula for the uncertainty of a determinant is derived in appendix  c. the paper concludes with some general observations .",
    "errors are often estimated by ignoring the off - diagonal elements of the covariance matrix .",
    "this is the correct procedure if the quantities are independent of each other .",
    "a calculation of the uncertainty on the branching ratios , assuming the elements of the inverted matrix are statistically independent of each other , yields , @xmath19^{2}_{i } = [ \\epsilon^{-1}]^{2}_{ij}[\\sigma_{f}]^{2}_{j }         + [ \\sigma_{{\\epsilon}^{-1}}]^{2}_{ij}[f]^{2}_{j } \\ : ,                                                                \\label{eqtbasic}\\ ] ] where the uncertainties are denoted by @xmath20 and a sum over repeated indices is assumed unless otherwise noted .",
    "the errors on the elements of the inverted efficiency matrix , @xmath21 , are calculated from the known errors on the efficiency matrix .",
    "the uncertainties on the inverse efficiencies , have been determined ( see for example reference  @xcite ) by differentiating the matrix equation @xmath22 and then applying a matrix analogy to the error propagation formula to yield , @xmath23_{ij}^2 =   \\mid [ \\epsilon^{-1}]_{im}[\\sigma_\\epsilon]_{mn } [ \\epsilon^{-1}]_{nj } \\mid ^{2}\\ : ,                  \\label{eqtsimple}\\ ] ] which has the same form as a transformation to a new basis @xcite .",
    "equation  [ eqtsimple ] is a reasonable approximation but is not correct .",
    "it also neglects any correlations between the elements of the inverse matrix , @xmath15 , which can be significant , as shown in the next section .",
    "matrix inversion is a nonlinear operation .",
    "it is always possible to write the inverse of a matrix in terms of the matrix of cofactors divided by the determinant  @xcite .",
    "one sees explicitly in appendix  c that each element of an inverse matrix has elements of the original matrix in common .",
    "therefore the inverse matrix elements clearly are correlated .",
    "consider the @xmath24 matrix elements @xmath7 with uncertainties given in the most general case by the @xmath25 covariances @xmath26 .",
    "the inverse matrix elements @xmath27 , in general , have covariances @xmath28 , which can be written as , @xmath29 the full derivation of this equation is given in appendix a ( see equation  [ eqtfinal ] ) .",
    "the usual case where there are no correlations between the elements of the efficiency matrix ( see equations  [ eqtadiag ] , [ eqtdiagonal ] and [ eqtfull_cov_diag ] ) is given by @xmath30^{2}_{ij }   \\delta_{ik}\\delta_{jl } \\ : \\:\\",
    ": \\mathrm { ( no \\ : \\ : summation ) } .",
    "\\label{eqt_diag}\\ ] ] hence the full set of covariances of @xmath15 are given by @xmath31_{\\alpha i}[\\epsilon^{-1}]_{a i } ) [ \\sigma_{\\epsilon}]^2_{ij } ( [ \\epsilon^{-1}]_{j \\beta}[\\epsilon^{-1}]_{j b } ) \\ : , \\label{eqtfulldiagcov}\\ ] ] where there is no sum in this case over repeated indices inside the parentheses .",
    "the variance of an element of the inverse efficiency matrix can be written as , @xmath32_{\\alpha\\beta}^2            \\equiv    \\mathrm{cov}(\\epsilon^{-1}_{\\alpha\\beta},\\epsilon^{-1}_{\\alpha\\beta } )     =   [ \\epsilon^{-1}]_{\\alpha i}^2 [ \\sigma_{\\epsilon}]^2_{ij }               \\label{eqt_diag_var } [ \\epsilon^{-1}]_{j \\beta}^2 \\:.\\ ] ] this equation is exact and replaces the approximate equation  [ eqtsimple ] .",
    "note that each term of equation  [ eqt_diag_var ] is squared before making the sum whereas in equation  [ eqtsimple ] the sum is done first .    the complete expression for the uncertainties on the branching ratios",
    "can then be calculated from , @xmath33 where the measured fractions of events are often uncorrelated , @xmath34 ^ 2_k \\delta_{kl }   \\ : \\:\\ :",
    "\\mathrm { ( no \\ : \\ : summation ) } .\\ ] ] equation  [ eqtwholething ] is a generalization of equation  [ eqtbasic ] , including all of the covariances .",
    "the properties of equation  [ eqtfulldiagcov ] have been studied using a monte carlo simulation of a @xmath0 matrix .",
    "relatively small errors have been used to satisfy the small error approximation used to derive the error propagation formula  @xcite .",
    "the results of the monte carlo calculations directly can be compared to the analytic formulae developed in appendix  b.    given an initial efficiency matrix @xmath16 , and the variance on each element , @xmath35^{2}_{ij}$ ] , the @xmath36 random instance of the matrix is generated by @xmath37_{ij } = \\epsilon_{ij } +       \\gamma_{m } \\cdot [ \\sigma_{\\epsilon}]_{ij } \\:,\\ ] ] where @xmath38 is a normally distributed pseudorandom deviate with a mean of zero and a standard deviation of one .",
    "a set of @xmath39 matrices are created , are then inverted .",
    "the covariances are calculated from @xmath40 where @xmath41 is the mean of the quantity enclosed in the brackets .    a sample of @xmath42 instances of the matrix @xmath43 where ,",
    "@xmath44 were generated with each element of @xmath16 normally distributed about the central values with the one percent errors , @xmath45 , indicated .",
    "the inverse of the matrix @xmath16 is given by @xmath46 and the determinant , @xmath47   the covariances can be calculated using only the inverse matrix , @xmath15 , and the error matrix , @xmath45 .",
    "the numerical values for the 16 covariances of @xmath15 , calculated from the monte carlo and analytically using equation  [ eqtfulldiagcov ] , are given in table  [ tblsingularcov1 ] .",
    "the symmetry of the covariance operation implies there should be 10 unique numbers as is apparent from the table .",
    "& & +   + @xmath48 & @xmath49 & @xmath50 & @xmath51 & @xmath52 & @xmath53 + @xmath54 & @xmath55 & @xmath56 & @xmath57 & @xmath58 & @xmath52 +   + @xmath49 & @xmath59 & @xmath51 & @xmath60 & @xmath53 & @xmath61 + @xmath62 & @xmath63 & @xmath57 & @xmath64 & @xmath65 & @xmath66 +   + @xmath54 & @xmath62 & @xmath56 & @xmath57 & @xmath58 & @xmath65 + @xmath67 & @xmath68 & @xmath69 & @xmath70 & @xmath58 & @xmath65 +   + @xmath55 & @xmath63 & @xmath57 & @xmath64 & @xmath52 & @xmath66 + @xmath68 & @xmath71 & @xmath70 & @xmath72 & @xmath73 & @xmath74 +    figure  [ figcorr2d ] shows a contour plot of the element @xmath75 versus @xmath76 generated from the monte carlo .",
    "the contours are approximate lines of constant probability density .",
    "the entries are distributed around the values of the calculated inverse matrix elements and are clearly correlated .",
    "the slope of the error ellipses has been calculated by substituting the analytical values of the covariances from table  [ tblsingularcov1 ] into a formula derived from reference  @xcite .",
    "the calculated slope is in good agreement with the slope of the major axis of the error ellipses .",
    "recall that the efficiency matrix must be nonsingular in order to invert it . in the monte carlo calculation",
    "the individual elements of @xmath16 are varied and hence , if the variations are large enough , it is possible for the determinant to become zero .",
    "figure  [ fignonsingdet]a shows a histogram of the monte carlo calculation of the determinant .",
    "the mean value is @xmath77 as expected with a root mean square deviation of @xmath78  .",
    "the shape of the distribution is normal , see figure  [ fignonsingdet ] , also as expected given the determinant is the sum of products of normally distributed quantities . in this particular case",
    "the mean value of the determinant is @xmath79 standard deviations from zero .",
    "increasing the errors or reducing the determinant will both produce a higher likelihood of the determinant fluctuating nearer to zero .    as noted",
    "earlier the inverse matrix elements all have a common factor of @xmath80",
    ". therefore values of the determinant near zero produce very large values for the inverse matrix elements .",
    "moreover , the reciprocal of a normal distribution is not normally distributed but is instead asymmetric with a tail towards large values . in figure  [ fignonsingdet]b one sees that any tails are insignificant for determinants many standard deviations away from zero .",
    "figure  [ figsingdet ] shows an identical analysis for the matrix , @xmath81 in this case @xmath82 and its root mean square deviation , due to the one percent errors , is @xmath83  . now the distribution of the reciprocal determinants , seen in fugure  [ figsingdet]b , is clearly skewed .",
    "table  [ tblsingularcov2 ] lists the values of the covariance matrix calculated for each element of the inverse matrix , @xmath84 , using the monte carlo method , equation   [ eqtmvcov ] and the analytic expression , equation  [ eqtfulldiagcov ] .    in table",
    "[ tblsingularcov1 ] the percent difference between the monte carlo and the analytic formula has a mean value of approximately one percent averaged over the 10 independent values of the covariance .",
    "this is consistent with the precision expected for a 10,000 event monte carlo and demonstrates that the analytic expression reproduces the covariances well for the far from singular case .",
    "however , the same mean for the values in table  [ tblsingularcov2 ] is eleven percent .",
    "moreover , the magnitude of the monte carlo value is larger than the analytic value for each covariance .",
    "the analytic expression becomes less accurate and no longer appropriate to use as the matrix becomes closer to being singular .",
    "& & +   + @xmath85 & @xmath86 & @xmath87 & @xmath88 & @xmath89 & @xmath89 + @xmath90 & @xmath91 & @xmath92 & @xmath93 & @xmath94 & @xmath94 +   + @xmath86 & @xmath95 & @xmath88 & @xmath96 & @xmath89 & @xmath97 + @xmath91 & @xmath98 & @xmath93 & @xmath99 & @xmath94 & @xmath94 +   + @xmath90 & @xmath91 & @xmath92 & @xmath93 & @xmath94 & @xmath94 + @xmath100 & @xmath101 & @xmath102 & @xmath103 & @xmath104 & @xmath104 +   + @xmath91 & @xmath98 & @xmath93 & @xmath99 & @xmath94 & @xmath97 + @xmath101 & @xmath105 & @xmath103 & @xmath106 & @xmath104 & @xmath107 +",
    "in order to explore the range of uncertainty on how well the analytic expression models the covariances , the monte carlo simulation described in part  1 was modified .",
    "instead of specifying a particular @xmath0 matrix for analysis , 5000 @xmath0 matrices were generated by choosing the elements of each matrix from a uniform distribution in the interval @xmath108 $ ]  .",
    "each of the randomly generated matrices was then analyzed using exactly the same procedure previously discussed .",
    "one percent errors were used as before .    none of the matrix inversions actually failed .",
    "however , many cases involved determinants close to zero . figure  [ figdiff](a ) shows the fractional difference between the monte carlo and the analytic calculation for @xmath109 , @xmath110 plotted against the determinant of @xmath16 divided by its uncertainty , @xmath111 .",
    "the number of sigmas the determinant may be from zero can be shown to be @xmath112 for one percent errors .",
    "the fractional differences between the monte carlo and analytic evaluations are distributed around approximately zero for large numbers of sigma . however , near 10 sigmas the monte carlo calculated covariance becomes very large and the distribution becomes centred around one . under the scatter plot is figure  [ figdiff](b ) .",
    "this is a plot of the mean value of the fractional difference plotted against the number of sigmas the determinant is away from zero .",
    "the error bars are the root mean square deviation of the distribution . the means for @xmath113",
    "are not plotted .",
    "the largest deviation , for the bin 1020 , is less than four percent .",
    "the sigmas are approximately two percent .",
    "hence , the analytic formula does a very good job of estimating the covariance as long as the determinant of the matrix is at least 10 sigmas from zero . a simple expression to calculate the error on a determinant",
    "is given in appendix  c.    ( 160,160)(0,0 ) ( 5,45 ) ( 5,0 )",
    "the covariances of inverse matrix elements are nonzero in general . therefore , the propagation of errors for formulae that depend on inverted matrices requires using the covariances of the inverse matrix elements . a concise formula is developed in the small error limit for the covariance of the inverted matrix elements .",
    "it is shown to work for nonsingular matrices .",
    "in particular the determinant must not become zero when the matrix elements are allowed to vary within their uncertainties .",
    "an attempt was made to study how well the formula estimates the covariances for a random set of @xmath114 matrices with positive elements between zero and one . on the average the formula was accurate to better than four percent with a root mean square deviation equal to two percent for matrices that have determinants more than ten sigmas from zero .",
    "this project was supported by grants from the natural science and engineering research council of canada .",
    "9 the opal collaboration , k. ackerstaff et al .",
    "phys . j. _ * c4*(1998)193206 .",
    "the particle data group , c. caso et al . , section 29 , _ eur .",
    "phys . j. _ * c3*(1998)1794 .",
    "l. lyons , statistics for nuclear and particle physics , cambridge university press , 1989 .",
    "s. lipschutz theory and problems of linear algebra , schaum s outline series , 1968 .",
    "the formal solution to the system of real linear equations , @xmath115 where @xmath116 are the unknowns and @xmath117 is a real @xmath118 matrix , is given by @xmath119 a sum over repeated indices is assumed unless otherwise noted .",
    "the uncertainties on the elements of @xmath117 are assumed to be known and given by @xmath120 the covariance of @xmath121 and @xmath122 .",
    "if each element of @xmath117 is an independent random quantity , then only the terms @xmath123 are nonzero . in other words",
    ", each element of the matrix will have an associated variance .",
    "similarly the uncertainties on the elements of @xmath124 are assumed to be known and given by @xmath125 .",
    "again , if the elements of @xmath124 are independent , the off - diagonal terms will be zero .",
    "the most general form of the covariance for the @xmath116 is given by the error propagation formula , @xmath126 the partial derivatives are given by : @xmath127 where @xmath128 is the kronecker delta .",
    "therefore , after relabelling summed - over indices , equation [ eqtfullcov ] becomes @xmath129 the only unknown quantity is @xmath130 .",
    "the inverse matrix elements can be considered as functions of the original matrix elements , @xmath131 the error propagation formula yields @xmath132 hence the terms @xmath133 are required .",
    "consider the identity , @xmath134 taking the derivative with respect to @xmath135 yields , @xmath136 making the substitutions , @xmath137 and @xmath138 yields @xmath139 contracting with @xmath140 and using @xmath141 gives @xmath142 which can be relabelled as @xmath143    hence , equation [ covpartial ] becomes @xmath144 this is the fundamental formula of this paper .",
    "an important case is when matrix elements @xmath121 are uncorrelated .",
    "if each element of @xmath121 has associated with it a variance @xmath145}^{2}_{ij}$ ] then @xmath146^{2}_{ij } \\delta_{ik}\\delta_{jl } \\ : \\ : \\ : \\mathrm{(no \\ summation)}. \\label{eqtadiag}\\ ] ] note that a corrected version of equation  [ eqtsimple ] now can be calculated as the variance @xmath147^{2}_{\\alpha \\beta}$ ] for each element of @xmath148 , @xmath149^{2}_{\\alpha\\beta } \\equiv \\mathrm{cov }   ( a^{-1}_{\\alpha \\beta } , a^{-1}_{\\alpha \\beta } )   = [ a^{-1}]^{2}_{\\alpha i } [ \\sigma_{a}]^{2}_{ij } [ a^{-1}]^{2}_{j \\beta}\\ : .",
    "\\label { eqtdiagonal}\\ ] ]    finally , the full covariance formula for uncorrelated @xmath121 is given by @xmath150 ^ 2_{ij } ( a^{-1}_{j \\beta } a^{-1}_{j b } ) \\label{eqtfull_cov_diag}\\ ] ] where there is no sum inside the parentheses .",
    "for an @xmath151 matrix there are @xmath152 covariances . from symmetry of the covariance operation",
    "one sees that there are @xmath153 independent covariance terms of which @xmath154 are diagonal , i.e. variances , and @xmath155 are `` off - diagonal '' .",
    "the two dimensional case is very instructive because it is simple enough to derive analytically . consider @xmath156 where @xmath157 and @xmath158 is the determinant of @xmath117 .",
    "the matrix elements of @xmath117 have uncertainties given by @xmath159 the uncertainty on @xmath160 , for example , can be calculated using the error propagation formula , @xmath161 the partial derivatives can be calculated from equation  [ eqtinverse2d ] as for example , @xmath162 for completeness the required derivatives are : @xmath163 and therefore @xmath164 this result can be compared directly with the results from equation  [ eqtdiagonal ] , where @xmath165 , @xmath166^{2}_{1 1 }   = [ a^{-1}]^{2}_{1 i } [ \\sigma_{a}]^{2}_{ij } [ a^{-1}]^{2}_{j 1}\\:,\\ ] ] which on substitution for the elements of @xmath167 and @xmath168 yields equation  [ eqtexplicitvar ] .",
    "similarly an explicit example of an `` off - diagonal '' covariance can be calculated , @xmath169 where the partial derivatives with respect to beta are given by , @xmath170 therefore the covariance of @xmath171 and @xmath172 is given by , @xmath173 this result is identical with equation  [ eqtfull_cov_diag ] where @xmath174 , @xmath175 and @xmath176 .",
    "note , that in general , the covariance is not zero .",
    "let a be an @xmath118 matrix with elements @xmath121 .",
    "the determinant is given by , @xmath177 where @xmath178 for cyclic permutations of @xmath179 , a factor of -1 is applied each time any two indices are exchanged , hence @xmath180 is zero if any two indices are the same .",
    "this can be rewritten by defining new matrices by removing from @xmath117 the elements of its @xmath181 row and @xmath182 column .",
    "the determinant of the remaining @xmath183 matrix is called  @xcite the minor of @xmath121 . if the minor of @xmath121 is denoted by @xmath184 then the cofactor of @xmath121 is given by",
    ", @xmath185 the matrix of all cofactors is @xmath186 .",
    "the determinant of @xmath117 can now be written as , @xmath187 for @xmath11 fixed .",
    "the error on @xmath188 is given by , @xmath189 from equation  [ eqt_det ] one gets , @xmath190 since @xmath191 is fixed and @xmath192 is independent of @xmath193 for all @xmath10 . therefore , one obtains the very compact result , @xmath194"
  ],
  "abstract_text": [
    "<S> a formula is given for the propagation of errors during matrix inversion . </S>",
    "<S> an explicit calculation for a @xmath0 matrix using both the formula and a monte carlo calculation are compared . </S>",
    "<S> a prescription is given to determine when a matrix with uncertain elements is sufficiently nonsingular for the calculation of the covariances of the inverted matrix elements to be reliable . </S>",
    "<S> +    * propagation of errors for matrix inversion * +    _ key words : _ matrix inversion ; error propagation ; branching ratios </S>"
  ]
}