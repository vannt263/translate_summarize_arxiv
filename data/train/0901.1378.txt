{
  "article_text": [
    "adaptive markov chain monte carlo ( amcmc ) is an approach to markov chain monte carlo ( mcmc ) simulation where the transition kernel of the algorithm is allowed to change over time as an attempt to improve efficiency .",
    "it grows out of the seminal works of @xcite .",
    "let @xmath3 be the distribution of interest .",
    "the problem is to sample efficiently from @xmath3 given a family of markov kernels @xmath6 .",
    "this can be solved adaptively using a joint process @xmath7 such that the conditional distribution of @xmath8 given the information available up to time @xmath9 is @xmath10 and where @xmath11 is adaptively tuned over time . some general sufficient conditions for the convergence of such algorithms can be found in @xcite .",
    "it is also shown in @xcite that under some regularity conditions , if a `` best '' limiting kernel @xmath12 exists , the marginal chain @xmath13 in the joint adaptive process behaves in many ways like a standard markov chain with transition kernel @xmath12 . in all the above - mentioned papers ,",
    "the assumption that each @xmath14 has invariant distribution @xmath3 plays an important role .",
    "more recently , interest has emerged in building monte carlo algorithms where the transition kernel @xmath1 used at time @xmath9 has invariant distribution @xmath2 not necessarily equal to @xmath3 .",
    "these algorithms are designed such that as @xmath4 , @xmath1 converges to a transition kernel @xmath5 which is invariant with respect to @xmath3 .",
    "this limiting kernel @xmath5 is typically a very efficient kernel that would be difficult to implement otherwise .",
    "the interest of this approach is that as @xmath4 , @xmath1 approaches @xmath5 and one expects the algorithm to inherit the good convergence properties of @xmath5 .",
    "the equi - energy ( ee ) sampler of @xcite is an example .",
    "another example based on importance resampling appeared independently in @xcite and @xcite .",
    "this paper provides a detailed analysis of the law of large numbers and central limit theorem for the ee sampler .",
    "it is also an attempt to address the question of whether such algorithms can deliver the same performance as their limiting kernel  @xmath5 .",
    "we give a negative answer .",
    "we show , in the case of the ee sampler , that its asymptotic variance is always at least as large as the asymptotic variance of the limiting transition kernel @xmath5",
    ". the difference can be substantial and we illustrate this with a simulation example .    on the related literature , the law of large numbers for of the ee sampler has been studied in @xcite but using different techniques than those in this work .",
    "we also mention a new class of interacting mcmc algorithms proposed by @xcite for solving numerically some discrete - time measure - valued equations .",
    "these algorithms share the same framework with the ee sampler . in these two papers ,",
    "the authors develop a number of asymptotic results for interacting mcmc including a strong law of large numbers and a central limit theorem .",
    "the paper is organized as follows . in section [ secalgo ]",
    "we present the ee sampler and ir - mcmc in a slightly more general framework .",
    "the limit theorems are developed in section [ limittheory ] and proved in section [ proof ] .",
    "the main ingredient of the proofs is the martingale approximation method .",
    "we present a simulation example in section [ ex1 ] comparing these algorithms to a random walk metropolis algorithm .",
    "let @xmath15 be a reference polish space equipped with its borel @xmath16-algebra @xmath17 and a @xmath16-finite measure @xmath18 and @xmath19 an integer .",
    "we denote by @xmath20 the set of all probability measure on @xmath21 .",
    "let @xmath22 be probability measures on @xmath21 such that @xmath23 for some measurable functions @xmath24 .",
    "@xmath25 ( assumed finite ) is the normalizing constant .",
    "we study a class of monte carlo algorithms to sample from the family @xmath26 .",
    "these algorithms will generated an ergodic random process @xmath27 on @xmath28 with limiting distribution @xmath29 .",
    "we introduce some notation in order to describe the algorithm .",
    "whenever necessary and without further notice , any subset of @xmath30 will be equipped with its borel @xmath16-algebra .",
    "if @xmath31 and @xmath32 are two measurable spaces , a kernel from @xmath33 to @xmath32 is any function @xmath34 $ ] such that @xmath35 is a probability measure on @xmath36 for all @xmath37 and @xmath38 is a measurable map for all @xmath39 . if @xmath40 , we call @xmath5 a kernel on @xmath32",
    ". if @xmath5 is a kernel from @xmath31 to @xmath32 , @xmath41 a measurable function and @xmath37 , we shall use the notation @xmath42 or @xmath43 to denote the integral @xmath44 whenever it is well defined .",
    "let @xmath45 be kernels on @xmath21 such that @xmath46 is the invariant distribution of @xmath47 .",
    "let @xmath48 be kernels from @xmath49 to @xmath21 , @xmath50 positive real - valued measurable functions defined on @xmath49 and @xmath51 for @xmath52 .",
    "for @xmath53 and @xmath52 , we define the following kernel on @xmath21 : @xmath54\\\\[-8pt]\\hspace*{20pt } & & { } + ( 1-\\theta_l)\\frac{\\int\\mu ( dy)\\omega^{(l ) } ( y , x)t^{(l)}(y , x , a)}{\\int\\mu(dy)\\omega^{(l)}(y , x)},\\qquad x\\in{\\mathcaligr{x}},a\\in{\\mathcaligr{b}}.\\nonumber\\end{aligned}\\ ] ] for @xmath55 , we introduce the maps @xmath56 defined as @xmath57 , where @xmath58 is the dirac measure .",
    "let @xmath59 be the nonhomogeneous markov chain on @xmath60 [ defined on some probability space @xmath61 that can be taken as the canonical space @xmath62 with sequence of transition kernels @xmath63 given by @xmath64 throughout , we denote @xmath65 the natural filtration of the process .",
    "we will assume that the initial value of the process is fixed .",
    "for simplicity we take @xmath66 . finally , we call @xmath67 and @xmath68 the probability distribution and expectation of the process .",
    "algorithmically , @xmath69 can be described as follows .",
    "[ algo ] at time @xmath9 and given @xmath70 :    1 .",
    "generate @xmath71 .",
    "2 .   for @xmath52 , generate independently @xmath72 from @xmath73 as given by  ( [ pmu ] ) .",
    "3 .   for @xmath74 ,",
    "set @xmath75    the heuristic of the algorithm is the following . by construction",
    ", @xmath76 is a markov chain with kernel @xmath77 and invariant distribution @xmath78 .",
    "if this chain is ergodic , then as @xmath4 , @xmath79 , will converge to @xmath80 where @xmath81 is given by @xmath82\\\\[-8pt ] & & { } + ( 1-\\theta_l)\\frac{1}{z^{(l)}(x)}\\int_{{\\mathcaligr{x}}}\\pi^{(l-1)}(dy)\\omega ^{(l)}(x , y)t^{(l)}(y , x , a),\\nonumber\\end{aligned}\\ ] ] where @xmath83 .",
    "we will discuss below two ways of choosing @xmath84 and @xmath85 so that @xmath81 has invariant distribution @xmath46 . with these choices",
    "we can reasonably expect @xmath86 to be ergodic with limiting distribution @xmath87 .",
    "the same argument can then be repeated . in other words , with appropriate choice of @xmath84 and @xmath85 , the marginal process @xmath88 can be used for monte carlo simulation from @xmath46 .      for @xmath52 define the importance function @xmath89 in algorithm [ algo ] we can take @xmath90 and @xmath91 , where @xmath92 is some kernel on @xmath21 with invariant distribution @xmath46 .",
    "this leads to the ir - mcmc algorithm ( @xcite ) . in this case",
    ", step  2 of algorithm  [ algo ] can be described as follows : with probability @xmath93 we sample @xmath94 from @xmath95 and with probability @xmath96 , we obtain @xmath97 by resampling from @xmath98 with weights @xmath99 and then propose @xmath100 .",
    "the @xmath101th limiting kernel here takes the form @xmath102 has invariant distribution @xmath46 and has better mixing than @xmath47 . but",
    "direct sampling from @xmath81 is impossible as it requires that we be able to sample from @xmath46 which is the problem that we are trying to solve in the first place .",
    "taking @xmath103 and @xmath104 in ( [ pmu ] ) , we get the ee sampler ( @xcite ) . in this case",
    "the limiting kernel becomes @xmath105\\\\[-8pt ] & = & \\theta_lp^{(l)}(x , a)+(1-\\theta_l)r^{(l)}(x , a),\\nonumber\\end{aligned}\\ ] ] where @xmath106 is the kernel of the metropolis ",
    "hastings algorithm with proposal @xmath107 and target distribution @xmath46 : @xmath108 \\mathbf{1}_a(x).\\end{aligned}\\ ] ] clearly , @xmath81 has invariant distribution @xmath46 . in general @xmath81",
    "will converge faster than @xmath47 .",
    "for example if @xmath109 is bounded from below it is easy to show that @xmath81 is always uniformly ergodic , independently of @xmath47 .",
    "for the ee sampler , step  2 of algorithm [ algo ] can now be described as follows . with probability",
    "@xmath93 we sample @xmath94 from @xmath110 and with probability @xmath96 , we obtain @xmath97 by resampling uniformly from @xmath111 .",
    "then @xmath97 is accepted with probability @xmath112 in which case we set @xmath113 ; otherwise @xmath97 is rejected and we set @xmath114 .",
    "actually the ee sampler described above is a simplified version of @xcite .",
    "their original algorithm uses an idea of partitioning .",
    "let @xmath115 be a partition of @xmath116 ( in @xcite , @xmath117 and they take @xmath118 for some predefined valuse @xmath119 ) .",
    "define the function @xmath120 if @xmath121 ; so @xmath122 represents the component of the partition to which @xmath123 belongs .",
    "now set @xmath124 and @xmath85 as in ( [ tlee ] ) and we get the ee sampler of @xcite . in this general case , the limiting kernel has the same form as in ( [ plimee ] ) but where @xmath106 is now a metropolis ",
    "hastings algorithm with target distribution @xmath125 and proposal kernel @xmath126 . partitioning the state space and using the proposal",
    "@xmath126 works well in practice as it can allow large jumps in the state space to be accepted .",
    "but it does not add any significant feature to the algorithm from the theoretical standpoint .",
    "therefore and to simplify the analysis , we only consider the case where no partitioning is used ( @xmath127 for all @xmath128 ) .",
    "for the remaining of the paper , we restrict our attention to the ee sampler . in other words",
    ", we consider the process defined in section [ secalgo ] with @xmath103 and @xmath85 as defined in ( [ tlee ] ) .",
    "we start with some notation .",
    "if @xmath129 are kernels on @xmath21 , the product @xmath130 is the kernel @xmath131 .",
    "if @xmath132 is a signed measure on @xmath21 , we write @xmath133 to denote the integral @xmath134 and we will also use @xmath132 to denote the linear functional on the space of @xmath135-valued functions on @xmath21 thus induced . similarly , we will write @xmath136 for @xmath137 . let @xmath138 be given . for @xmath139 , we define its @xmath140-norm as @xmath141 and we introduce the space @xmath142 of measurable real - valued functions defined on @xmath116 such that @xmath143 .",
    "for a signed measure @xmath132 on @xmath21 we define by @xmath144 .",
    "we equip @xmath20 , the set of all probability measures on @xmath21 , with the metric @xmath145 and the borel @xmath16-algebra @xmath146 induced by @xmath147 . whenever @xmath140 is understood , we will write @xmath148 instead of @xmath149 . for a linear operator @xmath150 from @xmath151 into itself , we define its operator norm by @xmath152 .",
    "we assume that @xmath46 is of the form @xmath153 for some continuous function @xmath154 that is bounded from below and @xmath155 is a decreasing sequence of positive numbers ( temperatures ) . in addition , we make the following assumption .",
    "[ assum1 ] for @xmath52 , there exist a set @xmath156 , a probability measure @xmath157 such that @xmath158 an integer @xmath159 and constants @xmath160 , @xmath161 , @xmath162 $ ] such that for @xmath163 and @xmath164 , @xmath165^{n_0}(x , a)\\geq{\\varepsilon}_l\\phi_l(a)\\mathbf{1}_{c_l}(x)\\ ] ] and @xmath166 where @xmath167 for some finite constants @xmath168 and @xmath169 and @xmath170 .",
    "moreover @xmath171    the drift and minorization conditions ( [ mino])([drift ] ) of assumption  [ assum1 ] can be checked for many practical examples . if each @xmath47 is a random walk metropolis kernel or a metropolis adjusted langevin kernel then ( [ mino ] ) and ( [ drift ] ) are known to hold under some regularity conditions on the energy function @xmath172 ( see @xcite ) . in these cases , it is always possible to choose @xmath173 small enough to satisfy @xmath174 .    the condition ( [ condkappa ] ) is a technical condition that quantifies the idea that the rate of resampling @xmath96 should not be too large .",
    "it is needed to guarantee that the geometric drift condition ( [ drift ] ) on @xmath47 transfers to kernels of the type @xmath175 that drive the ee sampler .",
    "we consider an arbitrary pair @xmath176 .",
    "we will show that under assumption  [ assum1 ] , if @xmath177 satisfies a strong law of large numbers , then so does @xmath178 .",
    "then we use the fact that @xmath179 is an ergodic markov chain to derive a law of large numbers for any @xmath88 .",
    "[ thm1]assume assumption  [ assum1 ] holds and let @xmath180 .",
    "let @xmath181 be a measurable function such that @xmath182 suppose that there exists a finite constant @xmath183 such that for any @xmath184 , @xmath185 suppose also that for any @xmath186 , @xmath187 and that there exists @xmath188 , @xmath189 such that for each sample path @xmath190 , @xmath191 converges to @xmath192 as @xmath4 for all @xmath128 .",
    "then @xmath193    see section  [ proofthm1 ] .",
    "the following corollary is then immediate .",
    "assume assumption  [ assum1 ] holds and suppose that @xmath194 is a @xmath195-irreducible aperiodic markov chain with invariant distribution @xmath78 and @xmath196 .",
    "let @xmath197 , @xmath180 .",
    "then for any @xmath198 , @xmath199      we now turn to central limit theorems .",
    "it can be shown that the kernel @xmath175 admits a unique invariant distribution @xmath200 .",
    "since the conditional distribution of @xmath201 given @xmath202 is @xmath203 , it is natural to consider a central limit theorem for @xmath204 in which @xmath205 is centered around @xmath206 .",
    "this is done in the next theorem .",
    "@xmath207 denotes weak convergence and @xmath208 denotes the gaussian distribution on @xmath135 with mean @xmath132 and variance  @xmath209 .",
    "[ thm2 ] assume assumption  [ assum1 ] holds .",
    "let @xmath210 , @xmath211 be such that @xmath212 .",
    "define @xmath213^kf(x),\\ ] ] where @xmath81 is given by ( [ plimee ] ) .",
    "assume that @xmath214 .",
    "then there exists a random sequence @xmath215 , @xmath216 ( almost surely ) as @xmath4 such that @xmath217\\rightarrow\\mathcaligr{n}(0,1)\\qquad \\mbox{as } n\\to\\infty.\\ ] ]    see section [ proofthm2 ] .",
    "we now derive a central limit theorem for @xmath204 around @xmath218 which gives more insight in the efficiency of the method as a monte carlo sampler from @xmath46 .",
    "we restrict ourselves to the case where @xmath219 ; that is , we only consider the pair @xmath220 .",
    "moreover , we assume in this section that @xmath116 is a compact subset of @xmath30 ( equipped with its euclidean metric ) . more precisely :    [ assum ] @xmath116 is a compact subset of @xmath30 . for @xmath221",
    ", there exist an integer @xmath159 , a constant @xmath162 $ ] a probability measure @xmath157 such that for @xmath222 and @xmath164 , @xmath223^{n_0}(x , a)\\geq{\\varepsilon}_l\\phi_l(a ) .\\ ] ]    let @xmath224 be the space of all continuous functions from @xmath225 .",
    "we endowed @xmath224 with the uniform metric @xmath226 and its borel @xmath16-algebra .",
    "let @xmath227 be the subset of lipschitz functions of @xmath224 [ we say that @xmath228 is lipschitz if there exists @xmath229 such that for any @xmath230 , @xmath231 .",
    "for @xmath232 bounded measurable , define the function @xmath233 the solution to the poisson equation for @xmath234 and @xmath235 . to simplify the notations , we omit the dependence of @xmath236 on @xmath234 .",
    "notice that @xmath237 is the limiting kernel in the ee sampler , denoted @xmath80 in ( [ plimee ] ) .",
    "clearly , assumption  [ assum ] implies as shown in lemma [ drminoee ] below that the kernel @xmath238 is also uniformly ergodic , uniformly in @xmath132 . in particular @xmath239 .",
    "we assume that the function @xmath236 is lipschitz whenever @xmath234 is lipschitz : @xmath240    we comment on ( [ lipassump ] ) below .",
    "let @xmath241 such that @xmath242 .",
    "consider the partial sum @xmath243 .",
    "since @xmath236 satisfies the poisson equation @xmath244 , we can rewrite @xmath245 as @xmath246 where @xmath247 is a martingale and @xmath248 .",
    "we introduce the function @xmath249\\\\[-8pt ] & & \\hspace*{-10.8pt}=\\int t^{(1)}(y , x , dz)u(z)-\\int\\pi^{(0)}(dy)\\int t^{(1)}(y , x , dz)u(z).\\nonumber\\end{aligned}\\ ] ] since @xmath250 , we have @xmath251 so that we can rewrite @xmath245 as @xmath252 where @xmath253 is the random field @xmath254 we will see that @xmath253 is a @xmath224-valued random element . to describe its asymptotic behavior",
    "we introduce the function @xmath255^jh_x(y),\\ ] ] where for a kernel @xmath256 , @xmath257 and the covariance function @xmath258\\pi^{(0)}(dz).\\ ] ] if @xmath259 , with an abuse of notation we will also write @xmath260 for the quantity @xmath261\\pi^{(0)}(dz),\\ ] ] where @xmath262^jf(x)$ ] .    [ thm3 ] assume assumption  [ assum ] and ( [ lipassump ] ) hold and suppose that @xmath263 .",
    "let @xmath264 such that @xmath265 .",
    "then @xmath266 where @xmath267 and @xmath268    see section [ proofthm3 ] .",
    "notice from ( [ hxfun ] ) that @xmath269 .",
    "thus theorem [ thm3 ] shows that the asymptotic variance of the ee sampler is the sum of the asymptotic variance in estimating @xmath270 as if the limiting kernel @xmath271 is known [ the term @xmath272 plus the asymptotic in using the chain @xmath273 to estimate the expectation under @xmath78 of the function @xmath274 . in their analysis",
    "@xcite arrive at a similar clt for interacting mcmc algorithms .",
    "notice also that @xmath275 .",
    "thus in most cases , the function @xmath274 will typically take large values and the asymptotic variance in estimating its expectation will also tend to be large particularly if the kernel @xmath77 mixes poorly .",
    "theorem [ thm3 ] thus suggests that for the ee sampler to be effective in practice it is important that the initial chain @xmath179 enjoys a very fast mixing .",
    "a remaining question is to know whether @xmath276 $ ] converges to @xmath277 .",
    "unfortunately the answer is no in general as shown by the following example :    [ propasympvar ] assume assumption  [ assum ] holds .",
    "suppose that @xmath278 and @xmath279 .",
    "let @xmath232 be a bounded measurable function such that @xmath280",
    ". then @xmath281=\\sigma_\\star^2(f ) + 2(1-\\theta_1)^2\\gamma(\\bar g,\\bar g).\\ ] ] in the present case @xmath282 and @xmath283    see section [ proofpropasympvar ] .",
    "assumption ( [ lipassump ] ) can often be easily checked .",
    "indeed , we have @xmath284 , where @xmath285 , where @xmath286 is the independent metropolis  hastings algorithm with target @xmath287 and proposal @xmath78 .",
    "let us assume that @xmath288 is also a metropolis ",
    "hastings kernel with target @xmath87 and proposal @xmath289 .",
    "denote @xmath290 [ resp . @xmath291 the acceptance probability of @xmath288 [ resp .",
    "@xmath286 ] , and denote @xmath293 [ resp . @xmath294 the average acceptance probability at @xmath123 for @xmath288 [ resp . for @xmath286 ] .",
    "then we have @xmath295 thus if @xmath296 and @xmath297 such that @xmath298 and @xmath299 remains bounded away from@xmath300 and the integral operators @xmath301 and @xmath302 transform bounded measurable functions into lipschitz functions , then ( [ lipassump ] ) hold .",
    "for example , if @xmath303 and @xmath297 are all positive on @xmath116 and of class @xmath304 then ( [ lipassump ] ) hold .",
    "the result developed above relies heavily on the lipschitz continuity assumption . under that assumption ,",
    "we show that the stochastic process @xmath305 lives in the polish space @xmath224 which allows us to use the standard machinery of weak convergence in polish spaces . if @xmath234 is only assumed measurable the theorem above no longer hold . but",
    "a similar result can still be obtained using weak convergence techniques in nonseparable metric spaces .",
    "but we do not pursue this here .",
    "consider the following example .",
    "suppose that we want to sample from the bivariate normal distribution @xmath306 , with covariance matrix @xmath307.\\ ] ] for this problem , we compare a random walk metropolis ( rwm ) algorithm , the ee sampler , the mcmc algorithm based on the limiting kernel of ee sampler ( call it limit ee sampler ) , ir - mcmc and the mcmc algorithm based on the limiting kernel of ir - mcmc ( limit ir - mcmc sampler ) .",
    "for the rwm sampler , the proposal kernel is @xmath308 , where @xmath309 is the @xmath310-dimensional identity matrix .",
    "for the adaptive chains , we use four chains with @xmath311 , @xmath312 , @xmath313 and @xmath314 .",
    "we take @xmath315 and @xmath47 is taken to be a rwm algorithm with target @xmath46 and proposal @xmath316 .",
    "it can be checked that assumption  [ assum1 ] holds for this problem .",
    "we simulate each of the five samplers for @xmath317 iterations .",
    "we compare the samplers on their mean square errors ( mse ) in estimating the first two moments of the two components of the distribution @xmath3 .",
    "we calculate the mses by repeating the simulations @xmath318 times .",
    "the results are reported in table  [ table1 ] .    from these results we see ( as expected ) that the limit ee sampler is @xmath319 to @xmath320 times more efficient than the rwm sampler , and the limit ir - mcmc sampler is @xmath321 to @xmath322 more efficient than the rwm sampler . but ir - mcmc itself is hardly more efficient than the rwm sampler .",
    "if we take the computation times into account , it becomes hard to make the case that any of these adaptive sampler is better than the plain rwm .",
    "similar conclusions can be drawn for the ee sampler .",
    "@lcd2.4d2.4d2.4d2.4@ & & & & & + rwm & mse & 0.0099&0.0803 & 0.0091 & 0.5525 + & ratios & 1.0 & 1.0 & 1.0 & 1.0 + ir - mcmc & mse & 0.0098 & 0.0774 & 0.0047 & 0.2962 + & ratios & 1.00 & 1.04 & 1.95 & 1.87 + limit ir - mcmc & mse & 0.0002 & 0.0017 & 0.0006 & 0.0296 + & ratios & 48.43 & 46.20 & 14.18 & 18.66 + ee & mse & 0.0057 & 0.0435 & 0.0045 & 0.2810 + & ratios & 1.74 & 1.84 & 2.02 & 1.97 + limit ee & mse & 0.0004 & 0.0030 & 0.0034 & 0.1966 + & ratios & 25.99 & 26.36 & 2.67 & 2.81 +",
    "for a probability measure  @xmath324 and @xmath52 , let @xmath325 as in ( [ pmu ] ) with @xmath326 and @xmath85 as in ( [ tlee ] ) .",
    "the following lemma shows that @xmath327 satisfies a drift and a minorization conditions with constant that actually do not depend on @xmath324 .",
    "[ drminoee ] assume assumption  [ assum1 ] holds .",
    "then there exists @xmath328 that does not depend on @xmath324 such that for @xmath163 and @xmath164 : @xmath329^{n_0}(x , a)\\geq\\theta _ l{\\varepsilon}_l\\phi_l(a)\\mathbf{1}_{c_l}(x)\\ ] ] and @xmath330 where @xmath331 , @xmath157 , @xmath332 , @xmath333 and @xmath140 are as in assumption  [ assum1 ] .",
    "we have @xmath334 .",
    "therefore ( [ mino2 ] ) follows from the minorization condition ( [ mino ] ) .",
    "define @xmath335 .",
    "we will show that @xmath336 given the drift condition ( [ drift ] ) , this will imply @xmath337 where @xmath338 by the condition on @xmath173 in assumption  [ assum1 ] .",
    "observe that @xmath339 , @xmath340 and @xmath167 , @xmath341 .",
    "this implies that @xmath342 if and only if @xmath343 .",
    "denote @xmath344 and @xmath345 .",
    "then we have @xmath346\\\\ & & \\qquad\\leq v(x)\\frac{\\kappa}{1/t_{l}-1/t_{l-1}-\\kappa}.\\end{aligned}\\ ] ] in the last line we use the following inequality : for @xmath347 : @xmath348 .    from lemma [ drminoee ]",
    ", we deduce that for any probability measure @xmath324 , @xmath327 has an invariant distribution @xmath349 such that @xmath350 see @xcite , theorems 15.0.1 and 14.3.7 .",
    "the lemma also implies that for any @xmath351 $ ] , there exist constants @xmath352 and @xmath353 that does not depend on @xmath324 such that @xmath354^k(x,\\cdot ) -\\pi^{(l)}_{\\nu}(\\cdot)\\big\\vert_{v^\\beta}\\leq",
    "c_\\beta\\rho_\\beta ^kv^\\beta(x),\\qquad k\\geq0 , x\\in{\\mathcaligr{x}}.\\ ] ] see , for example , @xcite for a proof .",
    "the following lemma holds .",
    "[ stabee]fix @xmath355 $ ] and @xmath132 and @xmath356 two probability measures on @xmath21 @xmath357    for @xmath358 such that @xmath359 , we have @xmath360 where @xmath361",
    ". therefore @xmath362    now for @xmath359 , @xmath363 for all @xmath128",
    ". therefore @xmath364    for @xmath365 , define the kernel @xmath366    [ lemunifcont ] let @xmath132 be a probability measure on @xmath21 .",
    "for @xmath367 , and @xmath368 , @xmath355 $ ] @xmath369\\\\[-8pt ] & & \\qquad\\leq { \\vert f \\vert}_{v^\\beta}\\big\\vert e^{\\tau e(x_1)}-e^{\\tau e(x_2)}\\big\\vert \\bigg\\vert\\int\\mu(dy)e^{-(\\tau-\\kappa\\beta)e(y)}\\bigg\\vert\\nonumber\\end{aligned}\\ ] ] with @xmath370 and @xmath173 as in assumption  [ assum1 ]",
    ".    fix @xmath371 and @xmath372 and define @xmath373 .",
    "on @xmath374 , @xmath375 . on @xmath376",
    ", @xmath377 similarly , on @xmath378 , @xmath379 putting the three parts together yields the lemma .",
    "lemma [ lemunifcont ] will be useful in deriving a uniform law of large numbers for @xmath380 .",
    "actually , this lemma shows that if the function @xmath172 is continuous then the kernel @xmath381 is a strong feller kernel that transforms a bounded function @xmath234 into a continuous bounded function @xmath381 ( uniformly in @xmath132 ) .",
    "we will use this later .",
    "a straightforward consequence of section  [ drminoee ] is that for any @xmath382 , @xmath351 $ ] the function @xmath383 ^kf(x)\\ ] ] is well defined and @xmath384 where @xmath183 is finite and does not depend on @xmath324 nor @xmath234 .",
    "@xmath385 satisfies the ( poisson ) equation @xmath386 lemmas [ drminoee ] and [ stabee ] implie that for all @xmath387 $ ] , and @xmath388 probability measures on @xmath21 : @xmath389 for @xmath358 , @xmath390 and @xmath391 the inequalities ( [ stabpiee ] ) , ( [ stabuee ] ) and ( [ stabuee ] ) can be derived , for example , by adapting the proofs of proposition 3 of @xcite .",
    "we omit the details .",
    "an important point is the fact that the constant @xmath183 ( whose actual value can change from one equation to the other ) does not depend on @xmath234 nor @xmath392 .",
    "let @xmath181 be a measurable function .",
    "we will use the notation @xmath393 when evaluating @xmath234 .",
    "we introduce the partial sum associated to @xmath88 : @xmath394 using the poisson equation ( [ poisson ] ) , we have the decomposition @xmath395\\\\[-8pt ] m_n^{(l)}(f ) & = & \\sum_{k=1}^nd_k^{(l)}(f),\\nonumber\\end{aligned}\\ ] ] where @xmath396 and @xmath397    [ theo2:lem1 ] @xmath398    this is a straightforward consequence of the ( uniform in @xmath356 ) drift condition on @xmath323 .",
    "[ theo2:lem2]let @xmath399 such that @xmath400 .",
    "there exists a finite constant @xmath183 such that @xmath401\\leq c ( \\log n ) ^p.\\ ] ] moreover @xmath402 converges @xmath67-almost surely to @xmath300 .",
    "we use ( [ stabuee ] ) , ( [ bounduee ] ) and ( [ eq1keyergothmee ] ) to obtain @xmath403\\\\[-8pt ] & & \\qquad\\leq c\\sup_{\\nu\\in{\\mathcaligr{m } } } { \\vert f_\\nu \\vert}_{v^\\beta}^p\\big\\vert\\mu ^{(l-1)}_{n}-\\mu^{(l-1)}_{n-1}\\big\\vert ^p_{v^\\beta}v^{\\beta p}\\bigl(x_k^{(l)}\\bigr).\\nonumber\\end{aligned}\\ ] ] but @xmath404 and we get @xmath405 in view of lemma [ theo2:lem1 ] and since @xmath400 , @xmath406\\leq c$ ] for some finite constant @xmath183 that does not depend on @xmath9 .",
    "therefore , given  ( [ eq1lemiiee ] ) and ( [ eq1keyergothmee ] ) , we can use minkowski s inequality to conclude the first part of the lemma .",
    "for the second part , by kronecker s lemma , it is enough to show that the series @xmath407 converges almost surely .",
    "this will follow if we show that @xmath408 is finite .",
    "but from the above calculations , we have seen that @xmath409 the lemma thus follows .",
    "[ theo2:lem3]let @xmath399 such that @xmath410",
    ". then @xmath411<\\infty.\\ ] ] moreover for any @xmath412 , @xmath413\\to0\\qquad \\mbox{as } n\\to\\infty.\\ ] ]    the first part is a direct consequence of  ( [ eq1keyergothmee ] ) and ( [ bounduee ] ) .",
    "for the second part , by markov s inequality , we see that @xmath414 & \\leq & \\delta^{-p}{\\mathbb{e}}\\biggl[\\sum_{m\\geq n}m^{-p } \\big|r_{m,1}^{(l)}(f)\\big |^p \\biggr]\\\\ & \\leq & c\\delta^{-p}\\sum_{m\\geq n}m^{-p}\\to0\\qquad \\mbox{as } n\\to \\infty.\\end{aligned}\\ ] ]    [ theo2:lem4 ] let @xmath415 such that @xmath400 .",
    "there exists a finite constant @xmath183 such that @xmath416\\leq cn^{\\max(1,p/2)}.\\ ] ]    by burkeholder s inequality applied to the martingale @xmath417 , we get @xmath418\\leq c{\\mathbb{e}}\\biggl [ \\biggl(\\sum_{k=1}^n \\big|d_{k-1}^{(l)}(f)\\big |^2 \\biggr)^{p/2 } \\biggr].\\ ] ] if @xmath419 , we apply minkowski s inequality and use ( [ bounduee ] ) to conclude that @xmath418\\leq c \\biggl\\{{\\mathbb{e}}\\biggl[\\sum_{k=1}^n{\\mathbb{e}}^{2/p } \\bigl(v^{p\\beta } \\bigl(x_{k-1}^{(l)}\\bigr ) \\bigr ) \\biggr ] \\biggr\\}^{p/2}\\leq cn^{p/2}.\\ ] ] if @xmath420 , we use the inequality @xmath421 valid for all @xmath422 , @xmath423 $ ] to write @xmath424&\\leq & c{\\mathbb{e}}\\biggl(\\sum_{k=1}^n \\big|d_k^{(l)}(f ) \\big|^p \\biggr)\\\\ & \\leq&c\\sum_{k=1}^n{\\mathbb{e}}\\bigl(v^{p\\beta}\\bigl(x_{k-1}^{(l)}\\bigr ) \\bigr)\\leq cn.\\end{aligned}\\ ] ]    to deal with the remaining term , we will rely on the following result which is also of some independent interest .",
    "[ lemlast]let @xmath425 be a sequence of probability measures on a measurable space @xmath21 such that @xmath426 for all @xmath164 and let @xmath427 be a sequence of measurable real - valued functions defined on @xmath21 such that @xmath428 and @xmath429 for all @xmath128 for some measurable function @xmath430 such that @xmath431 and @xmath432 for some @xmath433 .",
    "then @xmath434    by @xcite , chapter 11 , proposition 18 , we only need to prove that @xmath435 . by @xcite ,",
    "chapter 11 , proposition 17 , we already have @xmath436 .",
    "now we show that @xmath437 which will prove the lemma .    since @xmath438 , there exists a sequence of nonnegative simple measurable functions @xmath439 that converges increasingly to @xmath140 @xmath132-a.s . for @xmath440 , @xmath441 , define @xmath442 , for some @xmath443 . clearly , @xmath444 and @xmath445 as @xmath446 for any @xmath440 .",
    "fix @xmath447 .",
    "then for any @xmath55 and any @xmath448 , we have @xmath449 & = & \\mu_n(v_p)+ \\int_{e_{k , n}}\\mu_n(dx ) \\bigl(v(x)-v_p(x ) \\bigr)\\nonumber\\\\[-1.5pt ] & & { } + \\int _ { e_{k , n}^c}\\mu_n(dx ) \\bigl(v(x)-v_p(x ) \\bigr)\\\\[-1.5pt ] & \\leq & \\mu_n(v_p)+\\int_{e_{k , n}}\\mu_n(dx)v(x)+\\frac{1}{k}\\nonumber \\\\[-1.5pt ] & \\leq&\\mu_n(v_p)+c ( \\mu_n(e_{k , n } ) ) ^q+\\frac{1}{k},\\nonumber\\end{aligned}\\ ] ] with @xmath450 for some finite constant @xmath183 .",
    "the last inequality uses the inequality of holder and the assumption that @xmath451 for some @xmath433 . since @xmath452 is simple , @xmath453 .",
    "also @xmath454 . with these and letting @xmath4 and @xmath455 in ( [ eq1lemlast ] ) , we have by monotone convergence @xmath456 letting @xmath446 and then @xmath457 , we get @xmath458 .",
    "[ lemlastlast ] @xmath459 as @xmath460 with @xmath67 probability one .    to simplify the notations ,",
    "we write @xmath461 , @xmath462 and @xmath463 instead of @xmath464 , @xmath465 and @xmath466 respectively . for @xmath128 , and @xmath467",
    ", we have @xmath468 using ( [ ratepn ] ) .",
    "we will show next that there exists @xmath469 , with @xmath470 such that for each path @xmath471 , @xmath472 converges to @xmath473 as @xmath4 for all @xmath128 , all @xmath474 .",
    "then , going back to ( [ llnstareq ] ) , we can conclude that for each @xmath471 , @xmath475 and the proof will be finished by letting @xmath476 .",
    "we can rewrite @xmath477 as @xmath478 where @xmath479 and @xmath480 .    by the law of large numbers assumed for @xmath481 , and since @xmath21 is polish",
    ", there exists a dense countable subset @xmath482 in @xmath116 , a countable generating algebra @xmath483 of @xmath17 and @xmath484 , @xmath189 such that for all @xmath485 and all @xmath486 : @xmath487    we can also choose @xmath488 such that the convergence of @xmath489 to @xmath192 for all @xmath128 which is assumed in the theorem hold for all @xmath190 .",
    "if we fix a sample path @xmath490 , and we fix @xmath485 , the convergence in ( [ eqstar1 ] ) can actually be extended to all @xmath164 by a classical measure theory argument .",
    "also , again for @xmath190 and @xmath164 fixed , we can extend the convergence in  ( [ eqstar1])([eqstar2 ] ) to hold for all @xmath128 . to see why ,",
    "take @xmath128 arbitrary .",
    "lemma [ lemunifcont ] and the continuity of @xmath172 implies that @xmath491 is a continuous function of @xmath123 uniformly in @xmath132 . since @xmath482 is dense , for all @xmath440 , there is @xmath492 such that @xmath493 for all @xmath132 .",
    "in particular , @xmath494 for all @xmath55 .",
    "as@xmath4 , it follows that @xmath495 .",
    "as@xmath457 , by the continuity of @xmath496 ( lemma [ lemunifcont ] ) , we see that@xmath497 .",
    "similarly , we obtain@xmath498 .",
    "so that @xmath499 .",
    "similarly , @xmath500 .",
    "this shows that for each sample path @xmath190 , @xmath477 converges to @xmath501 for all @xmath128 all @xmath164 . by a successive application of lemma  [ lemlast ] ( with @xmath502 ) , we can therefore conclude that for each sample path @xmath190 @xmath503\\\\[-8pt ] & & \\qquad \\mbox{as } n\\to\\infty \\mbox { for all } x\\in{\\mathcaligr{x } } , a\\in{\\mathcaligr{b } } , m\\geq0.\\nonumber\\end{aligned}\\ ] ]    since @xmath504 ( @xmath180 ) and @xmath505 is uniformly bounded in @xmath132 and @xmath506 , we can apply lemma [ lemlast ] again to conclude that for each @xmath507 , @xmath508 converges to @xmath473 for all @xmath128 , all @xmath474 , which ends the proof .",
    "proof of theorem [ thm1 ] we are now in position to prove theorem [ thm1 ] . since @xmath509 , we can take @xmath510 in lemmas  [ theo2:lem2 ] and [ theo2:lem3 ] to conclude that @xmath511 , @xmath67-a.s . for @xmath512 and by the strong law of large numbers for martingales @xcite , we conclude that @xmath513 , @xmath67-a.s .",
    "we finish the proof using lemma [ lemlastlast ] .",
    "take @xmath514 ( since @xmath211 ) . by the martingale approximation ( [ martapprox ] ) , @xmath515 as above",
    ", we will simplify the notations by writing @xmath516",
    "instead of@xmath517 and similarly for @xmath518 , etc .    by lemmas [ theo2:lem2][theo2:lem3 ] , @xmath519=o ( ( \\log(n))^p ) $ ] .",
    "we then deduce that @xmath520 and it remains to show that a central limit theorem hold for the martingale @xmath521 .",
    "we need to show that the lindeberg condition holds : @xmath522\\stackrel{p}{\\to } 0\\qquad \\mbox{for all } { \\varepsilon}>0 \\mbox { as } n\\to\\infty\\ ] ] and that @xmath523\\stackrel{p}{\\to}\\sigma^2(f),\\ ] ] where @xmath524 $ ] . since @xmath525 for @xmath526 , it follows that the lindeberg condition ( [ lindee ] ) holds .    for the law of large numbers , we need some notations .",
    "let @xmath527 denote the fundamental kernel of the limiting kernel @xmath81 and define the functions @xmath528 and @xmath529 ^ 2 $ ] .",
    "simularly , define @xmath530 and @xmath531 ^ 2 $ ] . then we can rewrite @xmath532 ^ 2\\\\ & & \\qquad = \\frac{1}{n}\\sum_{k=1}^n\\delta_{k-1}^{(1)}\\bigl(x_{k-1}^{(l)}\\bigr)+\\delta _ { k-1}^{(2)}\\bigl(x_{k-1}^{(l)}\\bigr).\\end{aligned}\\ ] ] fix @xmath358 .",
    "we have seen in the proof of theorem [ thm1 ] that @xmath533 converges almost surely to @xmath534 . combined with  ( [ eq1thm4ee ] ) and using dominated convergence",
    "it follows that there is @xmath188 , @xmath535 such that for all sample path @xmath190 , @xmath536 converges to @xmath537 for all @xmath128 . by virtue of lemma [ lemlast ]",
    ", it follows that for all @xmath190 , @xmath538 converges to @xmath539 for all @xmath128 , @xmath540 .",
    "then the strong law of large numbers ( theorem [ thm1 ] ) , implies that @xmath541 converges almost surely to @xmath542 ^ 2 ) $ ] which is equal to @xmath543 $ ] .",
    "we continue with the notations of section [ secthm3 ] .",
    "[ lemholdergam ] under the assumptions of theorem [ thm3 ] , there exists a finite constant @xmath544 such that @xmath545    given the expression of @xmath546 in ( [ gamma ] ) , it is enough to show that @xmath547 .",
    "but since @xmath548^j \\bigl(h_x(y)-h_{x_1}(y ) \\bigr ) \\bigg|\\leq c |h_x - h_{x_1 } |_\\infty\\ ] ] ( where for a kernel @xmath5 with invariant distribution @xmath3 , @xmath549 ) , the lemma follows if we show that there exists a finite constant @xmath544 such that for any @xmath550 , @xmath551 it is easy to check as in lemma [ lemunifcont ] that for any @xmath550 , @xmath552 now the result follow from ( [ lipassump ] ) , the lipschitz assumption on @xmath172 and the compactness of @xmath116 .    under the assumptions of theorem [ thm3 ]",
    ", @xmath553 converges weakly in @xmath224 to a mean zero gaussian process @xmath554 with covariance function  @xmath546 and sample paths in @xmath224 and @xmath555    the existence of @xmath554 and the bound ( [ boundg ] ) follows from lemma [ lemholdergam ] and dudley s theorem on the existence of gaussian processes with continuous sample paths ( see , e.g. , @xcite , theorem 6.1.2 ) .",
    "indeed , if @xmath556 denotes the pseudo - metric associated to @xmath546 , lemma [ lemholdergam ] implies that @xmath557 and since @xmath116 is compact , this in turn implies that @xmath558 for some finite constant @xmath559 , where @xmath560 is the metric entropy of @xmath116 under @xmath561 .",
    "we now show that @xmath253 converges weakly in @xmath224 to a mean zero gaussian process with continuous sample path and covariance function @xmath546 .",
    "indeed , the convergence of the finite - dimensional distribution is given by the standard central limit for uniformly ergodic markov chains .",
    "we use a moment criterion to check that the family @xmath305 is tight ( @xcite , corollary 16.9 ) .",
    "it suffices to check that :    for some @xmath562 , @xmath563 is tight .    for some positive finite constant @xmath564 ,",
    "@xmath565\\leq c_0|x_1-x_2|^{d+b}\\qquad \\mbox{for all } x_1,x_2\\in{\\mathcaligr{x } } , n\\geq0 .\\ ] ]    the condition ( i ) is trivially true . to check ( ii )",
    ", we use the resolvent @xmath566 to write @xmath567 .",
    "it follows that @xmath568 where @xmath569 and @xmath570 .",
    "the term @xmath571 is a martingale and @xmath572 is bounded in @xmath9 by a constant . by burkholder s inequality and some additional straightforward arguments it follows that for any @xmath573 @xmath574\\leq c\\big|u_{x_1}^{(0)}-u_{x_2}^{(0)}\\big|_\\infty^a\\leq c|x_1-x_2|^{a}.\\ ] ] then it suffices to take @xmath575 .",
    "we will also need the following simple result .",
    "[ lemtech1]if @xmath576 is a sequence of real numbers such that @xmath577 as @xmath4 then @xmath578 as @xmath579 .",
    "take @xmath580 .",
    "let @xmath581 s.t .",
    "@xmath582 implies @xmath583 . then for @xmath582 , @xmath584 . letting @xmath4 and @xmath585 yields the result .",
    "proof of theorem [ thm3 ] for the rest of the proof , let @xmath554 be a mean zero gaussian process on @xmath116 with covariance function @xmath546 and almost surely continuous sample paths .",
    "we take @xmath554 independent from the process @xmath586 . from the gaussian process",
    "@xmath554 , we define @xmath587 as follows . for each sample path @xmath588 ,",
    "if @xmath589 is continuous then @xmath590 .",
    "otherwise , we set @xmath591 . since @xmath592 is a continuous map from @xmath593 , @xmath594 is a well - defined random variable .    back to the partial sum @xmath245",
    ", we have seen that @xmath595 where @xmath596 and @xmath597 .",
    "clearly @xmath598 thus the term @xmath599 is negligible .",
    "that is , @xmath600 in the above , we denote @xmath601 any random variable @xmath602 such that @xmath603 converges in probability to zero . to deal with the term @xmath604",
    ", we use the skorohod representation of weak convergence . first note that @xmath605    by the skorohod representation theorem , there exists a version @xmath606of @xmath554 and a version @xmath607 of the random process @xmath305such that @xmath608 a.s .",
    "therefore , by lemma [ lemtech1],@xmath609 converges almost surely and thus in probability to zero .",
    "it follows that @xmath610 converges also in probability to zero .",
    "we thus arrive at @xmath611    to deal with the term @xmath612 , we introduce @xmath613 and @xmath614 : @xmath615 we deduce that @xmath616 for almost every path @xmath588 , @xmath589 is a continuous function from @xmath225 .",
    "therefore , by the independence assumption and the law of large numbers of theorem  [ thm1 ] , @xmath617 converges in @xmath618 to zero . using lemma  [ lemtech1 ] again , we conclude that @xmath619 converges also in @xmath618 to zero .",
    "the term @xmath620 converges to @xmath310 .",
    "we thus arrive at @xmath621 proceeding as in the proof of theorem [ thm2 ] , we see that @xmath622 converges weakly to @xmath623 , where @xmath624 and is independent from @xmath554 .",
    "we thus conclude that @xmath625 converges weakly to @xmath626 , where @xmath623 and @xmath627 are independent .",
    "since @xmath592 is a continuous bounded function from @xmath593 , it follows from the above that @xmath628 converges weakly to @xmath594 .",
    "but @xmath629 . by the central limit theorem for the uniformly ergodic chain @xmath273 ,",
    "the latter term@xmath630 converges weakly to @xmath631 , where@xmath632 and we are finished .      in the present case",
    ", one can check that @xmath633 and @xmath634 .",
    "then the resolvent function @xmath566 becomes @xmath635which allows use to write @xmath636 , where @xmath637 and @xmath638 .",
    "thus we have @xmath639 where @xmath640 .",
    "the term @xmath641 is negligible and is suffices to study the limit of @xmath642 & = & { \\mathbb{e}}(m_n^2 ) + ( 1-\\theta_1)^2{\\mathbb{e}}\\biggl [ \\biggl(\\sum_{k=1}^nk^{-1}m_k^{(0 ) } \\biggr)^2 \\biggr ] \\\\ & & { } + 2(1-\\theta _ 1){\\mathbb{e}}\\biggl[m_n\\sum_{k=1}^nk^{-1}m_k^{(0 ) } \\biggr].\\end{aligned}\\ ] ] define @xmath643 and @xmath644 .",
    "it is easy to see that for any @xmath645 , @xmath646 .",
    "from which we deduce that @xmath647=0 $ ] .",
    "we write @xmath648 and since the terms @xmath649 are martingale differences , we get @xmath650\\\\ & & \\qquad= { \\mathbb{e}}\\biggl [ \\biggl(\\sum_{j=1}^n \\biggl(\\sum_{k = j}^nk^{-1 } \\biggr)d^{(0)}\\bigl(x_{j-1}^{(0)},x_j^{(0)}\\bigr ) \\biggr)^2 \\biggr]\\\\ & & \\qquad=\\sum_{j=1}^n \\biggl(\\sum_{k = j}^nk^{-1 } \\biggr)^2{\\mathbb{e}}\\bigl [ \\bigl(d^{(0)}\\bigl(x_{j-1}^{(0)},x_j^{(0)}\\bigr ) \\bigr)^2 \\bigr]\\\\ & & \\qquad=\\int\\pi(dx)\\int p(x , dy)\\bigl(d^{(0)}(x , y)\\bigr)^2\\sum_{j=1}^n \\biggl(\\sum _ { k = j}^nk^{-1 } \\biggr)^2 \\\\ & & \\qquad\\quad{}+ \\sum_{j=1}^n \\biggl(\\sum_{k = j}^nk^{-1 } \\biggr)^2 \\biggl({\\mathbb{e}}\\bigl [ \\bigl(d^{(0)}\\bigl(x_{j-1}^{(0)},x_j^{(0)}\\bigr ) \\bigr)^2 \\bigr]\\\\ & & \\qquad\\quad{}\\hspace*{84pt}-\\int\\pi(dx)\\int p(x , dy)\\bigl(d^{(0)}(x , y)\\bigr)^2 \\biggr).\\end{aligned}\\ ] ] since @xmath651 is a bounded continuous function and @xmath652 is uniformly ergodic , the second term on the r.h.s .",
    "divided by @xmath9 converges to zero .",
    "then we notice that @xmath653 and we conclude that @xmath654",
    "the author is grateful to eric moulines and gersende fort for helpful discussions and to an anonymous referee for helping improve the quality of this work ."
  ],
  "abstract_text": [
    "<S> there is a growing interest in the literature for adaptive markov chain monte carlo methods based on sequences of random transition kernels @xmath0 where the kernel @xmath1 is allowed to have an invariant distribution @xmath2 not necessarily equal to the distribution of interest @xmath3 ( target distribution ) . </S>",
    "<S> these algorithms are designed such that as @xmath4 , @xmath1 converges to @xmath5 , a kernel that has the correct invariant distribution @xmath3 . typically , @xmath5 is a kernel with good convergence properties , but one that can not be directly implemented . </S>",
    "<S> it is then expected that the algorithm will inherit the good convergence properties of @xmath5 . the equi - energy sampler of [ _ ann . </S>",
    "<S> statist . </S>",
    "<S> _ * 34 * ( 2006 ) 15811619 ] is an example of this type of adaptive mcmc . </S>",
    "<S> we show in this paper that the asymptotic variance of this type of adaptive mcmc is always at least as large as the asymptotic variance of the markov chain with transition kernel @xmath5 . </S>",
    "<S> we also show by simulation that the difference can be substantial .    .    </S>"
  ]
}