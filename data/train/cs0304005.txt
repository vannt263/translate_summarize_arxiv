{
  "article_text": [
    "quantum computation is a computation model based on quantum physics . assuming that the laws of nature as we know them are true",
    ", this might allow us to build computers that are able to perform tasks that classical computers can not perform in any reasonable time .",
    "one task which quantum algorithms are known to perform much better than classical algorithm is that of factoring large integers .",
    "the importance of this problem stems from its ubiquitous use in cryptographic applications . while there are no known polynomial time classical algorithms for this problem , a groundbreaking result of shor from 1994  @xcite showed a polynomial time quantum algorithm for factoring integers . in the same paper , shor showed an algorithm for finding the discrete log .",
    "however , despite enormous effort , we have only a few other problems for which quantum algorithms provide an exponential speedup ( e.g. , @xcite ) . other notable quantum algorithms such as deutsch and jozsa s algorithm  @xcite and simon s algorithm  @xcite operate in the black box model .",
    "algorithm  @xcite provides a square root speedup over classical algorithms .",
    "the current search for new quantum algorithms concentrates on problems which are not known to be @xmath1-hard .",
    "these include the graph isomorphism problem and lattice problems . in this paper",
    "we are interested in lattice problems or specifically , the unique shortest vector problem ( svp ) . a lattice is a set of all integral linear combinations of a set of @xmath2 linearly independent vectors in @xmath3 .",
    "this set of @xmath2 vectors is known as a basis of the lattice . in the svp",
    "we are interested in finding the shortest nonzero vector in a lattice . in the @xmath4-unique - svp",
    "we are given the additional promise that the shortest vector is shorter by a factor of at least @xmath4 from all other non parallel vectors .",
    "this problem also has important applications in cryptography .",
    "namely , ajtai and dwork s cryptosystem  @xcite and the recent cryptosystem by regev  @xcite are based on the hardness of this lattice problem .",
    "a central problem in quantum computation is the hidden subgroup problem ( hsp ) . here",
    ", we are given a black box that computes a function on elements of a group @xmath5 .",
    "the function is known to be constant and distinct on left cosets of a subgroup @xmath6 and our goal is to find @xmath7 .",
    "interestingly , almost all known quantum algorithms which run super - polynomially faster than classical algorithms solve special cases of the hsp on abelian groups .",
    "also , it is known that solving the hsp on the symmetric group leads to a solution to graph isomorphism  @xcite .",
    "this motivated research into possible extensions of the hsp to noncommutative groups ( see , e.g. , @xcite ) . however , prior to this paper the hsp on groups other than the symmetric group and abelian groups had no known applications .    in this paper we will be interested in the hsp on the dihedral group .",
    "the dihedral group of order @xmath8 , denoted @xmath9 , is the group of symmetries of an @xmath10-sided regular polygon .",
    "it is isomorphic to the abstract group generated by the element @xmath11 of order @xmath2 and the element @xmath12 of order 2 subject to the relation @xmath13 .",
    "although the dihedral group has a much simpler structure than the symmetric group , no efficient solution to the hsp on the dihedral group is known .",
    "ettinger and hyer  @xcite showed that one can obtain sufficient statistical _ information _ about the hidden subgroup with only a polynomial number of queries .",
    "however , there is no efficient algorithm that solves the hsp using this information .",
    "currently , the best known algorithm is due to kuperberg @xcite and runs in subexponential time @xmath14 .",
    "the following is the main theorem of this paper .",
    "the dihedral coset problem is described in the following paragraph .",
    "[ theorem_svp ] if there exists a solution to the dihedral coset problem with failure parameter @xmath15 then there exists a quantum algorithm that solves the @xmath16-unique - svp .",
    "the input to the dihedral coset problem ( dcp ) is a tensor product of a polynomial number of registers .",
    "each register is in the state @xmath17 for some arbitrary @xmath18 and @xmath19 is the same for all registers .",
    "these can also be thought of as cosets of the subgroup @xmath20 in @xmath9 .",
    "our goal is to find the value @xmath19 .",
    "in addition , we say that the dcp has a failure parameter @xmath15 if each of the registers with probability at most @xmath21 is in the state @xmath22 for arbitrary @xmath23 instead of a coset state .",
    "we note that any algorithm that solves the dihedral hsp by sampling cosets also solves the dcp for some failure parameter @xmath24 .",
    "the reason is that since the algorithm samples only a polynomial number of cosets , we can take @xmath15 to be large enough such that with high probability all the registers are coset states .",
    "this is summarized in the following corollary .",
    "if there exists a solution to the dihedral hsp that samples cosets ( e.g. , any solution using the ` standard method ' ) then there exists a quantum algorithm that solves @xmath25-unique - svp .",
    "the following is the second main theorem of this paper . in the subset sum problem",
    "we are given two integers @xmath26 and a set of numbers .",
    "we are asked to find a subset of the numbers that sums to @xmath27 modulo @xmath10 .",
    "a legal input is an input for which such a subset exists ( a formal definition appears in section  [ section_two_point ] ) and we are interested in algorithms that solve a non - negligible part of the inputs :    [ theorem_two_point ] if there exists an algorithm @xmath28 that solves @xmath29 of the legal subset sum inputs with parameter @xmath10 then there exists a solution to the dcp with failure parameter @xmath30 .    as shown in  @xcite , the dihedral hsp can be reduced to the case where the subgroup is of the form @xmath20 .",
    "then , by sampling cosets we obtain states of the form @xmath17 with no error .",
    "hence ,    if there exists an algorithm @xmath28 that solves @xmath29 of the legal subset sum inputs with parameter @xmath10 then there exists a solution to the dihedral hsp .",
    "finally , the following is an immediate corollary of the two previous theorems :    if there exists an algorithm that solves @xmath29 of the legal subset sum inputs with parameter @xmath10 then there exists a quantum algorithm for the @xmath0-unique - svp .",
    "this result is known as a worst case to average case quantum reduction .",
    "such reductions are already known in the classical case @xcite .",
    "the exponent @xmath31 in our reduction is better than the one in @xcite .",
    "however , the reduction in @xcite , which appeared after the original publication of the current paper , further improves the exponent to @xmath32 and hence subsumes our reduction .",
    "in addition , unlike the classical reductions , our subset sum problems have a density of one , i.e. , the size of the input set is very close to @xmath33 .",
    "therefore , some cryptographic applications such as the one by impagliazzo and naor  @xcite can not be used .      before proceeding to the main part of the paper",
    ", we describe our methods in a somewhat intuitive way .",
    "first , let us describe the methods used in solving the unique - svp . recall that our solution is based on a solution to the dcp .",
    "we begin by showing how such a solution can be used to solve a slightly different problem which we call the two point problem . instead of a superposition of two numbers with a fixed difference , our input consists of registers in a superposition of two @xmath2-dimensional vectors with a fixed difference .",
    "then , the idea is to create an input to the two point problem in the following way .",
    "start by creating a superposition of many lattice points and collapse the state to just two lattice points whose difference is the shortest vector . repeating this procedure creates an input to the two point problem whose solution is the shortest vector .",
    "collapsing the state is performed by partitioning the space into cubes . assume the partition has the property that in each cube there are exactly two lattice points whose difference is the shortest vector .",
    "then , we compute the cube in which each point is located and measure the result .",
    "the state collapses to a superposition of just the two points inside the cube we measured .",
    "the important thing is to make sure that exactly two points are located in each cube .",
    "first , in order to make sure that the cubes are not aligned with the lattice , we randomly translate them .",
    "the length of the cubes is proportional to the length of the shortest vector .",
    "although the exact length of the shortest vector is unknown , we can try several estimates until we find the right value .",
    "since the lattice has a unique shortest vector , all other nonparallel vectors are considerably longer and do not fit inside a cube .",
    "therefore we know that the difference between any two points inside the same cube is a multiple of the shortest vector . still , this is not good enough since instead of two points inside each box we are likely to have more points aligned along the shortest vector .",
    "hence , we space out the lattice : instead of creating a superposition of all the lattice points we create a superposition of a subset of the points .",
    "the set of points created by this technique has the property that along the direction of the shortest vector there are pairs of points whose difference is the shortest vector and the distance between two such pairs is much larger than the shortest vector .",
    "as before , this can be done without knowing the shortest vector by trying several possibilities .",
    "the second part of the paper describes a solution to the dcp with failure parameter 1 which uses a solution to the average case subset sum problem .",
    "recall that we are given registers of the form @xmath17 where @xmath34 is arbitrary and we wish to find @xmath35 .",
    "consider one such register .",
    "we begin by applying the fourier transform to the second part of the register ( the one holding @xmath36 and @xmath37 ) and then measuring it .",
    "if @xmath38 is the value we measured , the state collapses to a combination of the basis states @xmath39 and @xmath40 such that their phase difference is @xmath41 .",
    "if we were lucky enough to measure @xmath42 , then the phase difference is @xmath43 and by measuring this phase difference we can obtain an estimation on @xmath19 .",
    "this , however , happens with exponentially small probability .",
    "since the phase is modulo @xmath44 , extracting the value @xmath19 is much harder when @xmath38 is larger .",
    "instead , we perform the same process on @xmath45 registers and let @xmath46 be the values we measure . the resulting tensor state includes a combination of all @xmath47 different @xmath48 sequences .",
    "the phase of each sequence can be described as follows . by ignoring a fixed phase",
    ", we can assume that the phase of the sequence @xmath49 is @xmath50 .",
    "then , the phase of the sequence @xmath51 is @xmath52 and in general , the phase of the sequence @xmath53 is @xmath43 multiplied by the sum of the values @xmath54 for which @xmath55 .",
    "this indicates that we should try to measure the phase difference of two sequences whose sums differ by @xmath56 .",
    "however , although we can estimate the phase difference of one qubit , estimating the phase difference of two arbitrary sequences is not possible .",
    "we proceed by choosing @xmath45 to be very close to @xmath33 .",
    "this creates a situation in which for almost every @xmath57 there is a subset whose sum modulo @xmath10 is @xmath27 and in addition , there are not too many subsets that sum to the same @xmath27 modulo @xmath10 .",
    "assume for simplicity that every @xmath27 has exactly one subset that sums to @xmath27 modulo @xmath10 .",
    "we calculate for each sequence the value @xmath58 where @xmath27 is its sum . after measuring the result ,",
    "say @xmath59 , we know that the state is a superposition of two sequences : one that sums to @xmath60 and one that sums to @xmath61 . notice that since @xmath46 are uniformly chosen between @xmath62 we can use them as an input to the subset sum algorithm .",
    "the key observation here is that the subset sum algorithm provides the reverse mapping , i.e. , from a value @xmath27 to a subset that sums to @xmath27 .",
    "so , from @xmath59 we can find the sequence @xmath63 that sums to @xmath60 and the sequence @xmath64 that sums to @xmath61 .",
    "since we know that the state is a superposition of @xmath65 and @xmath66 we can use a unitary transformation that transforms @xmath65 to @xmath39 and @xmath66 to @xmath40 .",
    "now , since the two states differ in one qubit , we can easily measure the phase difference and obtain an estimate on @xmath19 .",
    "this almost completes the description of the dcp algorithm .",
    "the estimate on @xmath19 is only polynomially accurate but in order to find @xmath19 we need exponential accuracy .",
    "hence , we repeat the same process with pairs whose difference is higher .",
    "so , instead of choosing pairs of difference @xmath56 we choose pairs of difference @xmath67 to get an estimate on @xmath68 , then @xmath69 to get an estimate on @xmath70 and so on .",
    "nevertheless , we can measure enough multiples of the phase to guarantee exponential accuracy . ] .",
    "the next section contains some notations that are used in this paper .",
    "the two main sections of this paper are independent . in section  [ section_svp ]",
    "we prove theorem  [ theorem_svp ] and section  [ section_two_point ] contains the proof of theorem  [ theorem_two_point ] .",
    "we denote the imaginary unit by @xmath71 and use the notation @xmath72 . occasionally , we omit the normalization of quantum states .",
    "we use the term @xmath2-ball to refer to the @xmath2-dimensional solid body and the term sphere to refer to its surface .",
    "we denote the set @xmath73 by @xmath74 $ ] .",
    "all logarithms are of base 2 unless otherwise specified .",
    "we use @xmath75 to denote the kronecker delta , i.e. , 1 if @xmath76 and 0 otherwise .",
    "a sequence @xmath77 is identified with the set @xmath78 .",
    "several constants appear in our proofs . to make it easier to follow , we denote constants with a subscript that is somewhat related to their meaning .",
    "specifically , in section  [ section_svp ] , @xmath79 is related to the cubes that partition the space , @xmath80 is related to the radius of the balls , and @xmath81 appears in the guarantee of the unique shortest vector .",
    "also , in section  [ section_two_point ] we use @xmath82 in the definition of the parameter @xmath45 , @xmath83 in our assumptions on the subset sum subroutine and @xmath84 when we prove the existence of matchings .",
    "the following is the formal definition of the dcp :    the input to the dcp with failure parameter @xmath15 consists of @xmath85 registers .",
    "each register is with probability at least @xmath86 in the state @xmath87 on @xmath88 qubits where @xmath18 is arbitrary and @xmath19 is fixed . otherwise , with probability at most @xmath21 , its state is @xmath22 where @xmath89 and @xmath18 are arbitrary .",
    "we call such a register a ` bad ' register .",
    "we say that an algorithm solves the dcp if it outputs @xmath19 with probability @xmath90 and time @xmath85 .",
    "in this section we prove theorem  [ theorem_svp ] . we begin by showing a simple reduction from the two point problem to the dcp in section [ sec_2pp ] .",
    "we then prove a weaker version of theorem  [ theorem_svp ] with @xmath91 instead of @xmath16 in section [ sec_first_alg ] .",
    "we complete the proof of theorem  [ theorem_svp ] in section [ sec_improved_alg ] . throughout this section",
    ", we use a failure parameter @xmath92 in order to make our results more general .",
    "the reader might find it easier to take @xmath30 .",
    "the input to the two point problem with failure parameter @xmath15 consists of @xmath93 registers .",
    "each register is with probability at least @xmath94 in the state @xmath95 on @xmath96 qubits where @xmath97 are arbitrary such that @xmath98 is fixed . otherwise , with probability at most @xmath99 , its state is @xmath100 where @xmath89 and @xmath101 are arbitrary .",
    "we say that an algorithm solves the two point problem if it outputs @xmath98 with probability @xmath102 and time @xmath93 .",
    "[ n_dimensional_2pp ] if there exists an algorithm that solves the dcp with failure parameter @xmath103 then there is an algorithm that solves the two point problem with failure parameter @xmath103 .",
    "consider the following mapping from @xmath104 to @xmath105 : @xmath106 given an input to the two point problem , we create an input to the dcp by using the above mapping on the last @xmath107 qubits of each register .",
    "hence , each register is with probability at least @xmath108 in state @xmath109 the difference @xmath110 is @xmath111 and is therefore fixed .",
    "otherwise , with probability at most @xmath112 the register is in the state @xmath113 for arbitrary @xmath114 .",
    "this is a valid input to the dcp with @xmath115 since the probability of a bad register is at most @xmath116 .    using the dcp algorithm with the above input we obtain the difference @xmath117 where @xmath118 . in order to extract the @xmath119 s we add @xmath120 .",
    "extracting @xmath119 from @xmath121 is possible since each @xmath122 is an integer in the range @xmath56 to @xmath123 .",
    "the solution to the two point problem is the vector @xmath124 .",
    "we recall several facts about an lll - reduced basis . such a basis can be found for any lattice by using a polynomial time algorithm  @xcite .",
    "given a basis @xmath125 , let @xmath126 be its gram - schmidt orthogonalization .",
    "that is , @xmath127 is the component of @xmath128 orthogonal to the subspace spanned by @xmath129 .",
    "an lll reduced basis @xmath130 satisfies that @xmath131 and that for @xmath132 , @xmath133 .",
    "in addition , recall that @xmath134 is a lower bound on the length of the shortest vector . since @xmath135 and @xmath136 we get that the vector @xmath137 is at most @xmath138 times longer than the shortest vector .",
    "consider the representation of the lll basis in the orthonormal basis @xmath139 .",
    "the vector @xmath128 can be written as @xmath140 .",
    "notice that @xmath141 and that @xmath142 for every @xmath132 . in the following",
    ", @xmath143 denotes the shortest vector .",
    "[ svp_coordinates ] consider the representation of the shortest vector @xmath143 in the lll - reduced lattice basis @xmath144 .",
    "then , @xmath145 for @xmath146 $ ] .     changing to the orthonormal basis , @xmath147 .",
    "in addition , we know that @xmath148 . hence , @xmath149 for every @xmath150 $ ] . by taking @xmath151",
    "we get that @xmath152 is at most @xmath153 .",
    "we continue inductively and show that @xmath154 .",
    "assume that the claim holds for @xmath155 .",
    "then , @xmath156 . by the triangle inequality ,",
    "@xmath157 be any fixed prime .",
    "the following is the main lemma of this section :    [ main_lattice_lemma ] for any @xmath92 let @xmath158 be the shortest lattice vector in a @xmath159-unique lattice where @xmath160 is a constant .",
    "if there exists a solution to the two point problem with failure parameter @xmath15 then there exists a quantum algorithm that given this lattice and three integers @xmath161 returns @xmath162 with probability @xmath163 if the following conditions hold : @xmath164 , @xmath165 and @xmath166 .",
    "we first show how this lemma implies theorem  [ theorem_svp ] with @xmath91 by describing the svp algorithm . according to lemma  [ n_dimensional_2pp ] and the assumption of the theorem",
    ", there exists a solution to the two point problem with failure parameter @xmath15 .",
    "hence , lemma  [ main_lattice_lemma ] implies that there exists an algorithm that given the right values of @xmath161 outputs @xmath162 .",
    "the value @xmath167 is an estimate of the length of the shortest vector @xmath143 . because the lll algorithm gives a @xmath138-approximation to the length of the shortest vector , one of @xmath168 different values of @xmath167 is as required .",
    "in addition , since @xmath143 is the shortest vector , @xmath169 can not be a lattice vector and therefore there exists an @xmath170 such that @xmath171 .",
    "hence , there are only @xmath172 possible values for @xmath173 and @xmath170 . with each of these values the svp algorithm",
    "calls the algorithm of lemma  [ main_lattice_lemma ] a polynomial number of times . with high probability in one of these",
    "calls the algorithm returns the vector @xmath162 from which @xmath143 can be extracted . the results of the other calls can be easily discarded because they are either longer lattice vectors or non - lattice vectors .",
    "( of lemma  [ main_lattice_lemma ] ) we start by applying the lll algorithm to the unique lattice in order to create a reduced basis .",
    "denote the resulting basis by @xmath125 .",
    "let @xmath174 be the standard orthonormal basis of @xmath3 .",
    "let @xmath175 be @xmath2 real values in @xmath176 and let @xmath177 .",
    "assume without loss of generality that @xmath178 .",
    "the function @xmath103 is defined as @xmath179 where @xmath180 and @xmath181 .",
    "it maps the elements of @xmath182 to lattice points .",
    "in addition , consider a lattice vector @xmath183 represented in the orthonormal basis @xmath184 .",
    "the function @xmath185 maps @xmath183 to the vector @xmath186 in @xmath187 where the constant @xmath188 will be specified later .    in the following ,",
    "we describe a routine that creates one register in the input to the two point problem that hides the difference @xmath162 .",
    "we call the routine @xmath189 times in order to create a complete input to the two point problem .",
    "we then call the two point algorithm and output its result .",
    "this completes the proof of the lemma since with probability @xmath190 our output is correct .",
    "the routine starts by choosing @xmath191 uniformly from @xmath176 .",
    "we create the state @xmath192 then , we compute the function @xmath193 and measure the result , say @xmath194 .",
    "the state collapses to ( normalization omitted ) @xmath195 this completes the description of the routine .",
    "its correctness is shown in the next two claims .",
    "for every @xmath196 , there is at most one element of the form @xmath197 and at most one element of the form @xmath198 that get mapped to @xmath199 by @xmath200 .",
    "moreover , if both @xmath197 and @xmath198 get mapped to @xmath199 then @xmath98 is the vector @xmath201 .",
    "consider two different lattice points in the image of @xmath103 , @xmath202 and @xmath203 , that get mapped to @xmath199 by @xmath185 .",
    "let @xmath204 and @xmath205 be their representation in the orthonormal basis . if @xmath206 is not a multiple of the shortest vector , then @xmath207 .",
    "therefore , there exists a coordinate @xmath146 $ ] such that @xmath208 and for @xmath209 this implies @xmath210 no matter how @xmath175 are chosen .",
    "hence , @xmath211 for some integer @xmath212 . by considering the first coordinate of @xmath206 in the lattice basis we get that @xmath213 .",
    "this implies that @xmath214 .",
    "if @xmath215 then @xmath216 which implies that @xmath217 .",
    "thus , @xmath218 and again , @xmath219 .",
    "this proves the first part of the claim . for the second part ,",
    "let @xmath220 and @xmath221 .",
    "then , @xmath222 .",
    "as before , this can only happen when @xmath223 and hence the second part of the claim holds .",
    "hence , it is enough to show that the probability that this register is bad is low enough .",
    "the probability of measuring @xmath224 equals @xmath225 .",
    "notice that this probability is the same as the probability that @xmath226 for randomly chosen @xmath27 and @xmath227 .",
    "hence , we consider a randomly chosen @xmath27 and @xmath227 . if @xmath220 , let @xmath228 and if @xmath229 let @xmath230 .",
    "with probability at least @xmath231 , for randomly chosen @xmath27 and @xmath227 , @xmath232 is in @xmath233 and @xmath234 .",
    "we assume that @xmath220 , the proof for @xmath229 is similar . according to lemma  [ svp_coordinates ] , @xmath235 . hence , unless there exists an @xmath236 for which @xmath237 or @xmath238 , @xmath232 is guaranteed to be in @xmath233 .",
    "this happens with probability at most @xmath239 because @xmath227 is a random element of @xmath233 .",
    "notice that @xmath240 .",
    "since @xmath175 are randomly chosen , the probability that @xmath241 and @xmath242 differ on the @xmath236th coordinate is at most @xmath243 by the union bound , the probability that @xmath244 is at most @xmath245 where we used the fact that the @xmath246 norm of a vector is at most @xmath247 times its @xmath248 norm .",
    "the sum of the two error probabilities @xmath249 is at most @xmath250 for @xmath79 large enough .",
    "this concludes the proof of lemma  [ main_lattice_lemma ] .      in this section",
    "we complete the proof of theorem  [ theorem_svp ] .",
    "the algorithm we describe has many similarities with the one in the previous section .",
    "the main difference is that it is based on @xmath2-dimensional balls instead of cubes .",
    "the idea is to construct a ball of the right radius around lattice points and to show that if two lattice points are close then the two balls have a large intersection while for any two far lattice points the balls do not intersect . for technical reasons",
    ", we will assume in this section that the lattice is a subset of @xmath187 .",
    "any lattice with rational points can be scaled so that it is a subset of @xmath187 .",
    "we begin with some technical claims :    [ ball_intersection ] for any @xmath251 , let @xmath252 be the ball of radius @xmath253 centered around the origin in @xmath3 and let @xmath254 for some vector @xmath255 be a shifted ball .",
    "then , the relative @xmath2-dimensional volume of their intersection is at least @xmath256 , i.e. , @xmath257    consider a point @xmath258 such that @xmath259 , i.e. , a point which is closer to the center of @xmath260 than to the center of @xmath252 .",
    "notice that @xmath261 implies @xmath262 .",
    "in other words , the cap @xmath263 of @xmath252 given by all such points @xmath264 is contained in @xmath265 . by using a symmetric argument for points @xmath258 such that @xmath266 we get , @xmath267 we can lower bound the volume of @xmath263 by half the volume of @xmath252 minus the volume of an @xmath2-dimensional cylinder of radius @xmath253 and height @xmath268 : @xmath269 where @xmath270 is the @xmath271-ball of radius @xmath253 .",
    "we complete the proof by using the estimate @xmath272 , @xmath273    in the algorithm we will actually represent the balls using points of a fine grid .",
    "therefore , we would like to say that the above claim still holds if we consider the number of grid points inside @xmath252 , @xmath260 and @xmath274 instead of their volumes . the following claim is more than enough for our needs :    [ lattice_points_volume ] let @xmath275 be an integer and consider the scaled integer grid @xmath276 .",
    "then , for any convex body @xmath277 that contains a ball of radius @xmath278 , @xmath279    [ ball_intersection_cor ] let @xmath280 and consider the scaled integer grid @xmath281 .",
    "for any @xmath282 , let @xmath252 be the ball of radius @xmath253 centered around the origin in @xmath3 and let @xmath254 for some vector @xmath255 such that @xmath283 .",
    "then , the relative number of grid points in their intersection is at least @xmath284 , i.e. , @xmath285    we first note that @xmath252 , @xmath260 and @xmath274 all contain the ball of radius @xmath286 centered around @xmath287 . using claim [ lattice_points_volume ]",
    "we obtain that the number of grid points in these bodies approximates their volume up to a multiplicative error of @xmath288 .",
    "we complete the proof by using claim [ ball_intersection ] .",
    "let @xmath289 denote the trace distance between two quantum states @xcite .",
    "it is known that the trace distance represents the maximum probability of distinguishing between the two states using quantum measurements .",
    "we need the following simple bound on the trace distance :    [ trace_distance_tensor ] for all @xmath290 and density matrices @xmath291 , @xmath292    using the triangle inequality , @xmath293    in addition , we will need the following lemma :    [ quantum_superposition ] for any @xmath294 , let @xmath295 be the uniform superposition on grid points inside a ball of radius @xmath253 around the origin where @xmath280 .",
    "then , for any @xmath296 , a state @xmath297 whose trace distance from @xmath298 is at most @xmath299 can be efficiently computed .    in order to bound the trace distance",
    ", we will use the fact that for any two pure states @xmath300 , @xmath301 the first equality appears in @xcite and the inequality follows by a simple calculation .    consider the ( continuous ) uniform probability distribution @xmath302 over @xmath252 .",
    "then one can define its discretization @xmath303 to the grid @xmath281 as @xmath304^n } q(\\bar{y } ) d\\bar{y}\\ ] ] for @xmath305 .",
    "in other words , @xmath306 is proportional to the volume of the intersection of @xmath252 with the cube @xmath307^n$ ] .",
    "notice that for points @xmath264 such that @xmath307^n$ ] is completely contained in @xmath252 , @xmath308 .",
    "we claim that the state @xmath309 is exponentially close to @xmath298 .",
    "intuitively , this holds since the two differs only on points which are very close to the boundary of the ball , namely , of distance @xmath310 from the boundary .",
    "the number of such points is negligible compared to the number of points in the interior of the ball .",
    "more formally , define @xmath311 using equation [ equ : trace_distance ] , @xmath312 the first term is at most @xmath313 according to claim  [ lattice_points_volume ] . for the second term , notice that the amplitudes of @xmath314 and @xmath298 are the same except possibly on points @xmath264 of distance @xmath310 from the boundary . using claim  [ lattice_points_volume ]",
    "again we get that the fraction of such points is closely approximated by one minus the ratio of volumes of the ball of radius @xmath315 and the ball of radius @xmath253 .",
    "this ratio of volumes is @xmath316 .    in the following",
    "we show how to approximate the state @xmath317 .",
    "this idea is essentially due to grover and rudolph @xcite .",
    "let @xmath318 be large enough so that @xmath252 is contained in the cube @xmath319^n$ ] .",
    "using our assumption on @xmath253 , @xmath320 for some @xmath321 .",
    "we represent @xmath264 using @xmath322 qubits , i.e. , a block of @xmath323 qubits for each dimension .",
    "hence , we can write @xmath317 as @xmath324    we now show an equivalent way of writing @xmath317 .",
    "let us extend the definition of @xmath303 in the following way : for any @xmath325 and any @xmath326 define @xmath327 as the sum of @xmath328 over all sequences @xmath329 . notice that @xmath327 corresponds to the volume of the intersection of @xmath252 with a certain cuboid ( also known as a rectangular parallelepiped ) .",
    "for example , @xmath330 since they represent the intersection of @xmath252 with two halves of the cube @xmath331^n$ ] . using the definition @xmath332 and for @xmath333 , @xmath334",
    "we see that @xmath335    the algorithm starts with all @xmath336 qubits in the state @xmath39 and sets one qubit at a time .",
    "the first qubit is rotated to the state @xmath337 .",
    "assume we are now in the @xmath338th step after setting the state of qubits @xmath339 .",
    "we use the fact that there exists a classical algorithm for approximating the volume of a convex body up to any @xmath163 error ( see @xcite and references therein ) .",
    "the body should be provided by a  well - guaranteed weak membership oracle \" , i.e. , a sphere containing the body , a sphere contained in the body , both of non - zero radius and an oracle that given a point decides if it is inside the body or not .",
    "it is easy to construct such two spheres and an oracle for a body given by the intersection of a ball with a cuboid .",
    "hence , we can compute two values @xmath340 and @xmath341 such that @xmath342 and @xmath343 for @xmath344 and some constant @xmath345 which will be chosen later .",
    "then , we rotate the @xmath236th qubit to the state @xmath346 . this completes the description of the procedure .    notice that the amplitude of each basis state @xmath347 in the resulting state @xmath297 is given by @xmath348",
    "hence the inner product @xmath349 is at least @xmath350    using equation [ equ : trace_distance ] , @xmath351 for a large enough @xmath345 .",
    "let @xmath352 be any fixed prime .",
    "the following is the main lemma of this section .",
    "it essentially replaces lemma  [ main_lattice_lemma ] and hence implies theorem  [ theorem_svp ] .",
    "[ improved_main_lattice_lemma ] for any @xmath92 let @xmath158 be the shortest lattice vector in a @xmath353-unique lattice where @xmath160 is a constant . if there exists a solution to the two point problem with failure parameter @xmath15 then there exists a quantum algorithm that given this lattice and three integers @xmath161 returns @xmath162 with probability @xmath163 if the following conditions hold : @xmath164 , @xmath165 and @xmath166 .    as",
    "before , let @xmath125 be an lll reduced basis , let @xmath177 and assume that @xmath178",
    ". we also define @xmath354 as before .",
    "assume that the number of registers needed by the two point algorithm is at most @xmath355 for some constant @xmath356 .",
    "the algorithm starts by calling the routine of claim [ quantum_superposition ] @xmath355 times with accuracy parameter @xmath357 and @xmath358 for some constants @xmath359 .",
    "the state we obtain is @xmath360 where each @xmath361 has a trace distance of at most @xmath357 from @xmath298 .",
    "according to claim  [ trace_distance_tensor ] , the above tensor product has a trace distance of at most @xmath362 from @xmath363 . in the following",
    "we show that the algorithm succeeds with probability at least @xmath364 for some @xmath365 given the state @xmath363 .",
    "this would complete the proof since given the state in equation [ equ_approx_state ] , the algorithm succeeds with probability at least @xmath366 for large enough @xmath345 .",
    "we describe a routine that given the state @xmath298 creates one register in the input to the two point problem . in order to produce a complete input to the two point problem",
    ", the algorithm calls this routine @xmath355 times , each time with a new @xmath298 register .",
    "it then calls the two point algorithm and outputs the result .",
    "as required , the success probability is @xmath367 for some @xmath365 .    given @xmath298 , the routine creates the state @xmath368 or equivalently , @xmath369 where @xmath252 is the ball of radius @xmath253 around the origin and @xmath280 .",
    "we add the value @xmath354 to the last register , @xmath370 finally , we measure the last register and if @xmath371 denotes the result , the state collapses to @xmath372    for every @xmath371 , there is at most one element of the form @xmath197 and at most one element of the form @xmath198 such that @xmath373",
    ". moreover , if there are two such elements @xmath197 and @xmath198 then @xmath98 is the vector @xmath201 .",
    "consider two different lattice points in the image of @xmath103 , @xmath202 and @xmath203 , such that @xmath371 is both in @xmath374 and @xmath375 .",
    "this implies that @xmath376 . for @xmath377",
    "this means that @xmath378 for some integer @xmath212 . as before , by considering the first coordinate of @xmath206 in the lattice basis we get that @xmath379 .",
    "hence , @xmath214 . if @xmath215 then @xmath216 and therefore @xmath217 which contradicts the above upper bound on the distance between @xmath183 and @xmath380 .",
    "this proves the first part of the claim . for the second part ,",
    "let @xmath220 and @xmath221 .",
    "then , @xmath222 . as before",
    ", this can only happen when @xmath223 and hence the second part of the claim holds .",
    "notice that the probability of measuring @xmath371 is the same as that obtained by first choosing random @xmath27 and @xmath227 and then choosing a random point in @xmath381 .",
    "let us define for any @xmath27 and @xmath227 the vector @xmath232 as before .    with probability at least @xmath231 , for randomly chosen @xmath27 and @xmath227 and a random point @xmath371 in @xmath381 ,",
    "@xmath232 is in @xmath233 and @xmath371 is also in @xmath382 .",
    "according to lemma  [ svp_coordinates ] , @xmath235 . hence , unless there exists an @xmath236 for which @xmath237 or @xmath238 , @xmath232 is guaranteed to be in @xmath233 .",
    "this happens with probability at most @xmath239 because @xmath227 is a random element of @xmath233 .",
    "fix @xmath383 .",
    "we would like to show that if @xmath371 is chosen uniformly from @xmath381 then with high probability it is also in @xmath384 . by translating both sets by @xmath385",
    "we get the equivalent statement that if @xmath371 is chosen uniformly from @xmath386 then with high probability it is also in @xmath387 .",
    "since we assumed that our lattice is a subset of @xmath187 , @xmath388 and the latter set equals @xmath389 . using corollary [ ball_intersection_cor ] and the fact that @xmath390 , we get that the required probability is at least @xmath391    the sum of the two error probabilities @xmath392 is at most @xmath393 for @xmath80 large enough .",
    "this concludes the proof of lemma  [ improved_main_lattice_lemma ] .",
    "we begin this section with a description of the average case subset sum problem .",
    "we describe our assumptions on the subroutine that solves it and prove some properties of such a subroutine . in the second subsection we present an algorithm that solves the dcp with calls to an average case subset sum subroutine .",
    "the subset sum problem is defined as follows .",
    "an input is a sequence of numbers @xmath394 and two numbers @xmath26 .",
    "the output is a subset @xmath395 $ ] such that @xmath396 .",
    "let a legal input be an input for which there exists a subset @xmath397 with @xmath396 .",
    "for a constant @xmath398 , we fix @xmath45 to be @xmath399 since we will only be interested in such instances .",
    "first we show that there are many legal inputs :    [ many_legal ] for randomly chosen @xmath400 in @xmath62 , the probability that there is no @xmath395 $ ] such that @xmath396 is at most @xmath401 .",
    "fix a value of @xmath27 .",
    "define a random variable @xmath402 for every @xmath403 as @xmath56 if @xmath404 and @xmath50 otherwise . since for every @xmath405 the sum @xmath406 has any value modulo @xmath10 with the same probability , the expectation of @xmath402 is @xmath407 and its variance is @xmath408 .",
    "hence , @xmath409 = \\sum_{\\bar{b } } e[x_{\\bar{b } } ] = \\frac{2^r-1}{n}\\ ] ] given two different sequences @xmath410 we show that @xmath402 and @xmath411 are independent .",
    "let @xmath236 be such that @xmath412 and assume without loss of generality that @xmath413 and @xmath414 .",
    "then , @xmath415 & = & e_{a_2,\\ldots , a_r}[pr_{a_1}[x_{\\bar{b } } = 1~\\wedge~x_{\\bar{b } ' } = 1 ] ]   \\\\ & = & e_{a_2,\\ldots , a_r}[1/n\\cdot \\delta_{x_{\\bar{b}'},1 } ] \\\\ & = & pr_{a_1,\\ldots , a_r}[x_{\\bar{b } } = 1]pr_{a_1,\\ldots , a_r}[x_{\\bar{b } ' } = 1]\\end{aligned}\\ ] ] where the second equality holds because @xmath411 does not depend on @xmath416 and @xmath402 is 1 with probability @xmath417 for any @xmath418 .",
    "a similar argument holds for other values of @xmath402 and @xmath411 .",
    "therefore , the random variables are pairwise independent and by the chebyshev bound , @xmath419 \\le 4\\cdot\\frac{n}{2^r-1 } \\le \\frac{8}{2^ { { { c_{\\sf { r } } } } } } .\\ ] ] in particular , the probability of @xmath420 , that is , the probability that there is no @xmath397 such that @xmath396 is at most @xmath421 for @xmath422 .",
    "we assume that we are given a subroutine that answers a @xmath423 fraction of the legal subset sum inputs with parameter @xmath10 where @xmath424 is any constant .",
    "as can be seen from the previous lemma , this implies that the subroutine answers a non - negligible fraction of all inputs ( and not just the legal inputs ) .",
    "in addition , we assume that the subroutine is deterministic .",
    "we denote by @xmath425 the result of the subroutine @xmath28 on the input @xmath426 and we omit @xmath10 .",
    "this result can either be a set or an error .",
    "let @xmath427 denote the set of @xmath27 s for which the subroutine returns a set and not an error , i.e. , @xmath428 .",
    "[ big_sa ] for randomly chosen @xmath46 in @xmath62 , @xmath429 = \\omega(\\frac{1}{\\log^ { { { c_{\\sf { s } } } } } n})$ ] where @xmath394 .    since @xmath430 only when @xmath431 is a legal input , @xmath432 & = & pr_{a , t}[~s(a , t)\\neq error ~\\wedge~ ( a , t)~\\mbox{is legal}~ ] \\\\&= & pr_{a , t}[~s(a , t)\\neq error ~|~ ( a , t)~\\mbox{is legal}~ ] \\cdot pr_{a , t}[~(a , t)~\\mbox{is legal}~ ] \\ge \\frac{1}{2\\log^ { { { c_{\\sf { s } } } } } n}.\\end{aligned}\\ ] ] in addition , @xmath432 & = & e_a[~\\frac{|s(a)|}{n}~ ] \\\\&\\le &     pr_a[~|s(a)|\\ge \\frac{n}{4\\log^ { { { c_{\\sf { s } } } } } n}~ ] + pr_a[~|s(a)| < \\frac{n}{4\\log^ { { { c_{\\sf { s } } } } } n}~ ] \\cdot \\frac{1}{4\\log^ { { { c_{\\sf { s } } } } } n }     \\\\&\\le &     pr_a[~|s(a)|\\ge \\frac{n}{4\\log^ { { { c_{\\sf { s } } } } } n}~ ] + \\frac{1}{4\\log^ { { { c_{\\sf { s } } } } } n}.\\end{aligned}\\ ] ] by combining the two inequalities we obtain the corollary",
    ".    [ finding_q_prime ] let @xmath433 be a set such that @xmath434 for a certain @xmath59 . then , for any @xmath435 there exists @xmath436 such that the number of pairs @xmath437 that are both in @xmath438 is @xmath439 .",
    "define the partition of @xmath438 into sets @xmath440 as @xmath441 at least @xmath442 of the sets are of size at least @xmath443 since their union is @xmath438 and @xmath444 .",
    "let @xmath445 be such a set and for @xmath446 consider the values @xmath447 .",
    "therefore , the number of @xmath448 such that none of these values is in @xmath445 is less than @xmath449 because @xmath450 .",
    "therefore , more than @xmath451 of the elements @xmath446 are such that one of @xmath447 is also in @xmath445 . summing over all sets @xmath445 such that",
    "@xmath452 , there are at least @xmath453 elements @xmath454 for which one of @xmath447 is also in @xmath438 .",
    "thus , there exists a @xmath455 such that the number of @xmath454 for which @xmath456 is at least @xmath457 .",
    "a partial function @xmath458 is called a matching if for all @xmath236 such that @xmath459 is defined , @xmath460 and @xmath461 .",
    "a matching is a @xmath302-matching if for all @xmath236 such that @xmath459 is defined , @xmath462 .",
    "we define an equal partition of the domain of a matching @xmath103 by @xmath463 and @xmath464 .",
    "the intersection of a matching @xmath103 and a set @xmath465 is the set @xmath466 .    for any @xmath302",
    "we define the following @xmath302-matchings :    @xmath467    [ lemma_matching ] there exists a constant @xmath84 such that for any integer @xmath468 there exists a matching @xmath103 among the @xmath469 matchings @xmath470 such that with probability at least @xmath471 on the choice of @xmath472 , the intersection of @xmath103 and @xmath427 is @xmath473 .",
    "we call such an @xmath103 a _ good _ matching .",
    "according to corollary  [ big_sa ] , @xmath474 of the possible values of @xmath472 satisfy @xmath475 . for such @xmath472 , lemma  [ finding_q_prime ] with @xmath476 implies that there exists a value @xmath477 such that the number of pairs @xmath437 that are both in @xmath427 is @xmath478 .",
    "therefore , for such @xmath472 and @xmath303 , the size of the intersection of one of the matchings @xmath479 and @xmath427 is @xmath478 .",
    "this implies that one of the @xmath480 matchings considered must have an intersection of size @xmath478 with at least @xmath481 of the possible values of @xmath472 .",
    "we conclude the proof by choosing @xmath482 .",
    "we begin with the following simple claim :    [ to_one_qubit ] for any two basis states @xmath483 and @xmath484 , @xmath485 , there exists a routine such that given the state @xmath486 outputs the state @xmath487 .",
    "consider the function @xmath103 defined as @xmath488 and @xmath489 otherwise .",
    "it is reversible and can therefore be implemented as a quantum routine .",
    "we now describe the main routine in the dcp algorithm .",
    "[ routine_a ] there exist routines @xmath490 such that given a @xmath302-matching @xmath103 and an input for the dcp with failure parameter @xmath56 , they either output a bit or they fail . conditioned on non - failure ,",
    "the probability of the bit being 1 is @xmath491 for @xmath492 and @xmath493 for @xmath494 .",
    "moreover , if @xmath103 is a good matching , the success probability is @xmath495 .",
    "the routines begin by performing a fourier transform on the last @xmath33 qubits of each input register .",
    "consider one register .",
    "assuming it is a good register , the resulting state is @xmath496 we measure the last @xmath33 qubits and let @xmath497 be the result .",
    "the state collapses to @xmath498 if it is a bad register , it is in the state @xmath22 where both @xmath499 and @xmath36 are arbitrary .",
    "after the fourier transform the state is @xmath500 and after measuring @xmath38 in the last @xmath501 qubits , the state is @xmath502 .",
    "notice that in both cases any value @xmath38 in @xmath62 has an equal probability of being measured .",
    "we choose the number of input registers to be @xmath45 .",
    "let @xmath394 be the sequence of values measured in the above process .",
    "notice that this sequence is uniform and hence can be used as an input to the average case subset sum algorithm . in the following ,",
    "we assume that @xmath59 of the @xmath45 registers are bad .",
    "later we will claim that with good probability , none of the registers is bad .",
    "yet , we have to show that even if one of the registers is bad , the routine does not return erroneous results . without loss of generality ,",
    "assume that the first @xmath59 registers are bad .",
    "the resulting state is : @xmath503\\bigotimes_{i = s+1}^{r}[\\frac{1}{\\sqrt{2}}e(a_i x_i / n ) ( { { |{0 } \\rangle } } + e(a_id / n ) { { |{1 } \\rangle } } ) { { |{a_i } \\rangle } } ] .\\ ] ] or , by omitting the multiplication by the fixed phase and the @xmath504 fixed qubits , @xmath505\\bigotimes_{i = s+1}^{r}[\\frac{1}{\\sqrt{2 } } ( { { |{0 } \\rangle } } + e(a_id / n ) { { |{1 } \\rangle } } ) ] .\\ ] ] denote these @xmath45 qubits by @xmath506 .",
    "we add @xmath507 new qubits , @xmath508 and @xmath509 .",
    "let @xmath510 denote the sum @xmath511 .",
    "next , we perform the following operations :    in order to describe the state after the above procedure , we define the following subsets of @xmath512 : @xmath513 @xmath514 @xmath515 using the order @xmath516 , the resulting state is : @xmath517    now we measure @xmath518 and @xmath509 . if @xmath519 , the routine failed .",
    "otherwise , the state of @xmath520 is ( omitting the fixed @xmath518 and @xmath509 ) : @xmath521 notice that since @xmath518 is known and @xmath522 can be easily found by calling @xmath28 , we can transform this state to the state @xmath523 by using claim  [ to_one_qubit ] . by omitting some qubits",
    ", we can assume that this is a state on one qubit . by using the hadamard",
    "transform the state becomes @xmath524 we measure the qubit and the probability of measuring @xmath56 is @xmath525 this completes the description of @xmath492 .",
    "the routine @xmath494 applies the transform @xmath526 before the hadamard transform and thus the state becomes @xmath527 and the probability of measuring @xmath56 becomes @xmath528 .",
    "from the previous description , it is clear that the probability of measuring 1 conditioned on a non - failure is correct .",
    "thus , it remains to prove that when @xmath103 is a good matching the failure probability is low .",
    "the success probability equals the probability of measuring @xmath529 which is @xmath530 .",
    "assume that none of the @xmath45 registers is bad .",
    "then , @xmath531 and @xmath532 becomes @xmath533 .",
    "notice that the size of this set equals @xmath534 which , according to the definition of a good matching , is at least @xmath535 .",
    "therefore the probability of success conditioned on all of the registers being good is @xmath536 .",
    "this concludes the proof since with probability at least @xmath537 none of the registers is bad .",
    "[ sincos_estimate ] given an approximation @xmath36 of @xmath538 and an approximation @xmath539 of @xmath540 with additive error @xmath541 , we can find @xmath542 up to an additive error of @xmath543 .",
    "assume @xmath544 and let @xmath545 .",
    "a simple calculation shows that @xmath546 is an estimate of @xmath547 up to an additive error of at most @xmath548 .",
    "the estimate on @xmath549 is @xmath550 .",
    "since the absolute value of the differential of @xmath551 is at most @xmath56 , this is an estimate of @xmath552 with an additive error of at most @xmath553 .",
    "when @xmath554 we compute an estimate of @xmath555 .",
    "there exists a routine @xmath556 such that with probability exponentially close to @xmath56 , given any @xmath557 finds a value @xmath558 and an estimate @xmath36 such that @xmath559~(\\mod~n)$ ] .",
    "assume we are given a @xmath303-matching @xmath103 .",
    "we call routines @xmath492 and @xmath494 @xmath560 times .",
    "if the number of successful calls to one of the routines is less than @xmath561 , we fail .",
    "otherwise , let @xmath562 $ ] be the average of the successful calls to @xmath492 and @xmath563 $ ] be the average of the successful calls to @xmath494 . according to the chernoff bound , @xmath564 <         2e^{-2 \\log^{2 { { c_{\\sf { m } } } } + 3}n / ( { { { c_{\\sf { e } } } } } ^2\\log^{2 { { c_{\\sf { m } } } } + 2}n)}\\ ] ] which is exponentially low in @xmath33 for any constant @xmath565 .",
    "a similar bound holds for @xmath539 .",
    "hence , we can assume that @xmath566 and @xmath567 are approximations of @xmath568 and of @xmath569 respectively up to an additive error of @xmath570 .",
    "according to claim  [ sincos_estimate ] , this translates to an estimate of @xmath571 with an additive error of @xmath572 for @xmath573 large enough .    by repeating the above procedure with all the matchings that appear in lemma  [ lemma_matching ] ,",
    "we are guaranteed to find a good matching . according to lemma  [ routine_a ] , a call to routine @xmath492 or to routine @xmath494 with a good matching succeeds with probability at least @xmath574 for a certain @xmath575 .",
    "the probability that none of @xmath576 calls to the subroutine succeeds is @xmath577 which is exponentially small .",
    "thus , for one of the matchings , with probability exponentially close to @xmath56 we have @xmath561 successful calls to routines @xmath492 and @xmath494 and routine @xmath556 is successful .",
    "we conclude the proof of theorem  [ theorem_two_point ] with a description of the algorithm for finding @xmath19 .",
    "we begin by using routine @xmath556 with the value @xmath56 to obtain an estimate @xmath578 and a value @xmath579 such that @xmath580~(\\mod~n)$ ] where @xmath581 denotes @xmath582 . in",
    "the following we find @xmath581 exactly by calling @xmath556 with multiples of @xmath583 .",
    "the algorithm works in stages . in stage",
    "@xmath236 we have an estimate @xmath584 and a value @xmath585 .",
    "the invariant we maintain is @xmath586~(\\mod~q_i n)$ ] .",
    "we begin with @xmath578 as above and @xmath587 .",
    "assume that the invariant holds in stage @xmath236 .",
    "we use routine @xmath556 with the value @xmath588 to obtain an estimate @xmath36 with a value @xmath589 such that @xmath590~(\\mod~n)$ ] where @xmath591 .",
    "notice that our previous estimate @xmath584 satisfies @xmath592~(\\mod~q_{i+1}n)$ ] .",
    "since this range is much smaller than @xmath10 , we can combine the estimate @xmath36 on @xmath593 and the estimate @xmath594 on @xmath595 to obtain @xmath596 such that @xmath597 ~(\\mod~q_{i+1}n)$ ] .",
    "the last stage is when @xmath598 .",
    "then , @xmath581 can be found by rounding @xmath599 to the nearest integer .",
    "given @xmath581 there are at most @xmath579 possible values for @xmath302 .",
    "since this is only a polynomial number of options we can output one randomly .",
    "i would like to thank dorit aharonov , noga alon , andris ambainis , irit dinur , sean hallgren , alexei kitaev , hartmut klauck , ashwin nayak , cliff smyth and avi wigderson for many helpful discussions and comments .",
    "m.  ajtai and c.  dwork . a public - key cryptosystem with worst - case / average - case equivalence . in _ proc .",
    "29th acm symp . on theory of computing _ ,",
    "pages 284293 , 1997 .",
    "vailable from eccc at http://www.uni - trier.de / eccc/.              m.  grigni , l.  j. schulman , m.  vazirani , and u.  v. vazirani . quantum mechanical algorithms for the nonabelian hidden subgroup problem . in _ proc .",
    "33rd acm symp . on theory of computing _ , pages 6874 , 2001 ."
  ],
  "abstract_text": [
    "<S> we present the first explicit connection between quantum computation and lattice problems . </S>",
    "<S> namely , we show a solution to the unique shortest vector problem ( svp ) under the assumption that there exists an algorithm that solves the hidden subgroup problem on the dihedral group by coset sampling . moreover </S>",
    "<S> , we solve the hidden subgroup problem on the dihedral group by using an average case subset sum routine . by combining the two results </S>",
    "<S> , we get a quantum reduction from @xmath0-unique - svp to the average case subset sum problem . </S>"
  ]
}