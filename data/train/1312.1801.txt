{
  "article_text": [
    "evolutionary biologists study how the distribution of observable characteristics of individuals in a population changes over generations .",
    "these observable characteristics are called traits or phenotypes and can be qualitative , such as body color in a specific environment , or quantitative .",
    "a quantitative phenotype can be a scalar such as mass at a specified age , or a vector such as mass at several specified ages , or a function such as mass at a continuum of ages .",
    "changes in the distribution of traits can occur via many processes , including mutation , selection and genetic drift ( the change in the distribution of genotypes that can occur in a finite population when mating and reproduction are modeled as random processes ) .",
    "here we consider changes caused by selection .",
    "we consider changes within only one generation .",
    "we characterize changes by the expected change in phenotype , and we assume that the population under selection is , in essence , infinite .",
    "the selection process determines which individuals in a population are likely to produce viable offspring .",
    "selection can occur naturally , when , for instance , small individuals are more vulnerable to predation , or artificially , as in the selective breeding of race horses .",
    "selection causes the trait distribution of the subpopulation of breeding individuals to differ from that of the original population .",
    "this difference will persist into the offspring population provided the trait has some genetic component .",
    "to understand the role of selection and genetics in evolution , consider the following simple example .",
    "suppose that , in a population , individuals taller than a certain height do not reproduce .",
    "thus , the breeding subpopulation will have a smaller mean height than the original population .",
    "the breeding parents offspring also will have a smaller mean height provided height has some genetic basis .",
    "in this case , we say that selection on height leads to the evolution of height .",
    "thus , evolution requires both a selection process and a genetic component .",
    "the selection process must involve a trait with a genetic component . that genetic component must differ between breeding and nonbreeding individuals .",
    "clearly , genetic variation plays an important role in evolution .",
    "as we will see , the amount of genetic variation actually determines the speed at which selection causes evolutionary change . in nature , traits with substantial genetic variation will respond rapidly , allowing the species to adapt rapidly to changing conditions .",
    "genetic variation is likewise a critical variable for plants and animals that are used in agriculture . artificial selection ( or selective breeding )",
    "has been used for millennia to improve domesticated species , and it continues to be one of the most important tools for increasing agricultural yield .",
    "the amount of genetic variation present is one of the key criteria used by animal and plant breeders to choose the traits for artificial selection . in both natural and domesticated populations , traits with little or no genetic variation",
    "are not able to respond much or at all to selection .",
    "these traits are said to be _ genetically constrained _ , and these constraints play an important role in determining how populations adapt [ see @xcite ] .    in this paper",
    "we propose methods to explore genetic constraints in vector - valued traits .",
    "the next section contains biology background , including a model for selection and a characterization of genetic constraints as eigenvectors of the genetic covariance matrix corresponding to zero eigenvalues .",
    "sections [ sectanalysis ] and [ sectsimplicitybasis ] describe our proposed methodology for studying genetic constraints .",
    "data analyses appear in section [ sectdata ] and a simulation study in section [ sectsimulation ] .",
    "biologists model an individual s quantitative trait in terms of components , the simplest model involving two components : a genetic component , @xmath0 , inherited from parents , and an environmental component , @xmath1 , such as availability of food . in this simple model ,",
    "the true phenotype is @xmath2 and the observed phenotype , @xmath3 , is @xmath4 where @xmath5 is additional sampling variation .",
    "we denote the expected value of @xmath0 by @xmath6 and its variance / covariance by @xmath7 . if @xmath0 is scalar",
    ", then @xmath7 is its variance .",
    "if @xmath0 is a vector of length @xmath8 , then @xmath7 is the @xmath8 by @xmath8 covariance matrix with @xmath9th entry equal to the covariance between the @xmath10th and @xmath11th component of @xmath0 .",
    "if @xmath0 is a function , say , if @xmath12 is mass at age @xmath13 , then @xmath7 is a bivariate function , with @xmath14 being the covariance between mass at age @xmath15 and mass at age @xmath13 .",
    "the environmental effect @xmath1 is a mean zero random component with variance / covariance @xmath16 , with @xmath17 defined in an analogous way as @xmath7 .",
    "the random components @xmath0 , @xmath1 and @xmath5 are defined so as to be uncorrelated , so the covariance of the true phenotype is @xmath18 and the covariance of the observed phenotype is @xmath19 plus the variance / covariance of @xmath5 .",
    "the marginal distributions of @xmath0 and @xmath1 are population and generation dependent , while the marginal distribution of @xmath5 depends on the method of measuring the phenotypes .",
    "the heritability of a scalar phenotype is the proportion of its variance that is attributable to genetics , that is , the heritability is simply @xmath20 . throughout , we assume that @xmath21^{-1}$ ] exists . to understand the role of heritability in evolution ,",
    "consider our simple example where the selection mechanism prevents tall individuals from producing offspring .",
    "first suppose that height has zero heritability in the population , that is , all variability in height is simply due to environmental effects",
    ". then , intuitively , the distribution of heights in the next generation will be the same as the distribution in the original population , provided both generations are raised in similar environments . however ,",
    "if height has nonzero heritability , that is , if the genetic component of height varies across individuals , then the distribution of heights in the next generation will be different from the distribution in the original population .",
    "one would expect that the larger the heritability in the original population , the bigger the change in the distribution of heights in the next generation .",
    "the mathematical theory that supports this reasoning , that links heritability and evolution of a trait from one generation to the next , is contained in the _ breeder s equation_. to define this equation , let @xmath22 be the expected phenotype in the original population , @xmath23 the expected phenotype of the reproducing adults , and @xmath24 the expected phenotype of their offspring .",
    "the breeder s equation gives @xmath25 , the expected response to selection : @xmath26^{-1 } \\times(\\mu_{p^ * } - \\mu_p).\\ ] ] in our height example , @xmath23 is less than @xmath27 and so the breeder s equation tells us that the mean height in the offspring population is less than or equal to that in the original population .",
    "how much less depends on the value of the heritability ( @xmath28^{-1}$ ] ) and the strength of selection .",
    "the strength of selection determines if particular individuals will reproduce . in our simple height example",
    ", the strength of selection is determined by the height cutoff for reproducing .",
    "thus , the strength of selection determines @xmath29 .",
    "biologists define the _ selection differential _ as @xmath30 .",
    "the breeder s equation also holds for multivariate phenotypes , where , if the phenotype is a vector of @xmath8 values , then @xmath31 and @xmath32 are @xmath8-vectors and @xmath7 and @xmath17 are @xmath33 covariance matrices . for a generalization of the breeder s equation to function - valued traits ,",
    "see @xcite .",
    "biologists rewrite the breeder s equation in terms of the _ selection gradient _ , denoted @xmath34 .",
    "the selection gradient is defined in terms of a population s expected fitness , that is , its ability to reproduce , under the specified selection mechanism .",
    "we can think of the selection gradient as the change in @xmath22 that selection appears to be making when `` choosing '' the breeding individuals in the original population .",
    "this is not , in general , equal to @xmath35 , the change that actually occurs . to see the distinction between @xmath34 and @xmath15 , consider once again our simple height example , but suppose that the phenotype is a vector in @xmath36 with components height and weight .",
    "selection is only acting on height , not on weight , so the selection gradient s second component is zero .",
    "however , the second component in @xmath15 is not 0 since height and weight are positively correlated : the selection on height means that both the heights and weights of the reproducing individuals will , on average , be smaller than those in the original population .",
    "one can show that the selection gradient @xmath34 and the selection differential @xmath15 are related via the equation @xmath37 \\beta$ ] .",
    "this yields an alternative expression for the expected response to selection in the breeder s equation in ( [ breeders ] ) : @xmath38 we consider the amount of genetic variation explained by the direction of a unit vector @xmath39 .",
    "this amount of variation is the magnitude of @xmath40 , that is , the magnitude of the expected response to selection when @xmath39 is the selection gradient .    for more details on the breeder s equation , the selection gradient and the selection differential ,",
    "see lande ( @xcite ) , @xcite or , for a statistician - friendly exposition , @xcite . for an extension of ( [ breedersbeta ] ) to function - valued traits , see @xcite and @xcite .    from ( [ breedersbeta ] ) , we can see the importance of an eigenanalysis of @xmath7 in understanding a population s ability to evolve under selection .",
    "the magnitude of @xmath25 will be largest when the selection gradient , @xmath34 , points in the same direction as the leading eigenvector of @xmath7",
    ". the value of @xmath25 will be zero if selection acts in the direction corresponding to a zero eigenvalue of @xmath7 .",
    "that is , the population s mean phenotype will not evolve if selection acts in the direction of an eigenvector of @xmath7 corresponding to a zero eigenvalue .",
    "these directions are called _",
    "genetic constraints_. eigenvectors corresponding to small but nonzero eigenvalues are also of interest .",
    "@xcite provide tools to determine what eigenvalues are considered small : they model demography and evolution in a population experiencing selection due to changing environmental conditions .",
    "they identify critical levels of genetic variability , levels low enough to effectively prevent the adaptive evolution that might result from selection .",
    "to better understand the directions of genetic variability , we partition the sample space of @xmath0 into two subspaces , the _ model space _ and the _ nearly null space_. the model space is a `` high genetic variance '' subspace spanned by eigenvectors of @xmath41 with large eigenvalues . the nearly null space is the orthogonal complementary `` low genetic variance '' subspace .",
    "visualizing the nearly null space provides information about the existence and interpretation of genetic constraints .",
    "this partitioning and the associated visualization tools were introduced in @xcite .    to explicitly define the model space and the nearly null space of a covariance matrix @xmath7 , let @xmath42 be the eigenvalues of @xmath7 , and @xmath43 the corresponding orthonormal eigenvectors .",
    "we decide which @xmath44 s to consider as large values , say , @xmath45 , and assume that @xmath46 is strictly greater than @xmath47 .",
    "we define the model space as the space spanned by @xmath48 and the nearly null space as the space spanned by the remaining eigenvectors . from the breeder s equation  ( [ breedersbeta ] ) , we see that @xmath25 is large if @xmath34 lies in the model space .",
    "specifically , for @xmath34 in the model space , @xmath49 and is largest when @xmath34 is a constant times @xmath50 .",
    "conversely , if @xmath34 lies in the nearly null space , then @xmath51 will never exceed @xmath52 .",
    "interpreting the nearly null space is challenging since , typically , eigenvectors corresponding to small eigenvalues are `` rough '' and may simply represent noise . to study the nearly null space , we construct a new basis for this space , ordered by simplicity .",
    "if the simplest basis vectors are interpretable , biologists can then study the possibility of genetic constraints .",
    "if the simplest basis vectors are not interpretable , then biologists might consider the nearly null space to represent noise .",
    "clearly , the choice of @xmath53 is important in the definition of the model space and nearly null space .",
    "one might carry out a sequence of hypothesis tests to choose  @xmath53 , using the procedures of @xcite , @xcite or @xcite .",
    "these authors consider testing for the dimension of @xmath7 when data come from a half - sibling design , that is , where data are from independent families and each family consists of half - siblings .",
    "such data can be modeled as an easy - to - analyze multivariate one - way classification with random effects [ @xcite ] .",
    "hypothesis testing to determine @xmath53 in more complicated designs might be challenging .",
    "however , we do not recommend this hypothesis testing approach , preferring instead an exploratory approach grounded in the biology .",
    "we recommend the usual techniques of calculating the proportion of genetic variance explained , studying scree plots and considering the interpretability of the associated eigenvectors , combined with the calculations of critical levels as defined in @xcite .",
    "[ dickdavidcritical ] we also recommend that subject area specialists examine results for a range of values of @xmath53 , to examine the interplay between proportion of variance explained and biological interpretability of the resulting model space and nearly null space .",
    "these subject area opinions can provide a more biologically meaningful and thus more compelling explanation of a choice of reasonable values of @xmath53 than any test of significance or other algorithmic approach .",
    "in addition , studying a range of values of @xmath53 allows the user to consider small - scale and large - scale genetic variabilities .",
    "[ flip ]            in summary , we use principal components analysis and simplicity measures to define biologically interpretable directions of low genetic variation , allowing biologists to explore the possibility of the existence of genetic constraints .",
    "we apply our method to two data sets , one of the heights of jewelweed plants ( _ impatiens capensis _ ) measured at six ages , the other of growth rate measurements of the caterpillar _",
    "pieris rapae _ at six temperatures .",
    "the jewelweed data are described in @xcite and the caterpillar data in @xcite .",
    "the two data sets are displayed in figures [ jwdatasun ] and [ catdata ] .",
    "descriptions of the data and the purpose of the experiments , along with data analysis and discussion , are given in section  [ sectdata ] .",
    "a simplicity basis for a linear subspace @xmath54 of @xmath55 is an orthonormal basis @xmath56 , where the @xmath57 s are ordered according to some simplicity measure : @xmath58 is the `` simplest '' element of unit length in @xmath54 , @xmath59 is the `` simplest '' unit - length element of @xmath60 that is orthonormal to @xmath58 , @xmath61 is the `` simplest '' unit - length element of @xmath60 that is orthonormal to @xmath58 and @xmath59 , and so forth . such a basis may help us to understand @xmath54 since simple vectors are usually the most interpretable .",
    "we consider quadratic simplicity measures , that is , measures equal to @xmath62 .",
    "we assume throughout that @xmath63 is a nonnegative definite symmetric matrix and , for interpretability , that @xmath63 is defined so that the simpler the vector the higher the simplicity score .",
    "if this is not the case , that is , if @xmath62 is small when @xmath39 is simple , we can instead use the simplicity measure @xmath64 , where i is the identity matrix and @xmath65 is some number greater than or equal to the largest eigenvalue of @xmath63 .",
    "examples of quadratic simplicity measures can be found in smoothing and penalized regression .",
    "see , for instance , @xcite or @xcite . in the examples that follow ,",
    "we think of the elements of a vector @xmath39 as evaluations of a function @xmath66 : @xmath67 . in these examples",
    ", we used a simplicity measure based on first divided differences : @xmath68 which is a good approximation of @xmath69 . to transform this to a measure that is large for simple @xmath39 s",
    ", we use the result of @xcite that @xmath70 for all @xmath39 s .",
    "our simplicity measure is equal to @xmath71 which lies between 0 and 4 inclusive .",
    "the simplicity measure ( [ eqfirstdivided ] ) is just one of many possible smoothing - based measures .",
    "another good choice might be the measure used in cubic smoothing spline regression , where a function @xmath66 s simplicity is defined as @xmath72 , with a low value signifying simplicity .",
    "this integral can be approximated using a rieman sum of second divided differences , yielding a quadratic form in @xmath73 .",
    "the simplicity basis of the subspace @xmath54 for the simplicity measure associated with a nonnegative definite symmetric matrix @xmath63 is easy to calculate .",
    "let @xmath74 be an orthonormal basis of @xmath54 and let @xmath75 be the @xmath76 matrix with @xmath11th column equal to @xmath77 .",
    "so @xmath75 is a projection matrix onto @xmath60 .",
    "let @xmath78 be the eigenvectors of @xmath79 with corresponding eigenvalues @xmath80 .",
    "then it is straightforward to show that @xmath81 is a simplicity basis of @xmath54 , ordered from most simple to least simple . when the eigenvalues are distinct , the basis is unique , not dependent on the choice of @xmath75 .",
    "however , if , for example , @xmath82 , then the `` simplest subspace '' of @xmath54 is the span of @xmath83 and @xmath84 , and this subspace does not depend on the @xmath75 that we choose .",
    "for well - designed evolutionary biology studies such as those presented here , the covariance matrix @xmath41 is identifiable , estimable and consistent .",
    "typical methods of estimation are via manova , maximum likelihood or restricted maximum likelihood ( reml ) .",
    "see , for instance , @xcite and @xcite .",
    "these estimates take into account the dependence in the data caused by individuals relatedness .    for each data",
    "set , we carry out a principal components analysis of the estimate of @xmath7 and , for all possible values of @xmath53 , we study the model space of dimension @xmath53 and the corresponding nearly null space . for our data sets ,",
    "@xmath53 ranges from 0 to 6 .",
    "the supplementary material for this paper contains all seven plots of the caterpillar analysis and all seven plots of the jewelweed analysis . here",
    ", we present just two of the seven plots for each data set .",
    "the details and interpretations of figures [ figcatpca ] through [ figjewelsimplicity4 ] are in sections [ sectioncaterpillar ] and  [ sectionjewelweed ] , but we provide an overview here . figures [ figcatpca ] and [ figjewelpca ] show the principal component vectors for the two data sets , corresponding to choosing @xmath85 , for a six - dimensional model space and a zero - dimensional nearly null space .",
    "these figures are shown so we can contrast insight from a usual pc analysis with the insight obtained from figures [ figcatsimplicity2 ] and [ figjewelsimplicity4 ] .",
    "figure [ figcatsimplicity2 ] shows the four - dimensional model space and two - dimensional nearly null space for the caterpillar data .",
    "figure [ figjewelsimplicity4 ] shows the two - dimensional model space and four - dimensional nearly null space for the jewelweed data .     except that the left - hand side shows the pc basis for the four - dimensional model space ( blue ) and the simplicity basis for the two - dimensional nearly null space ( red dashed ) . the simplest nearly null space vector is labeled with a red 1 .",
    "the amount of genetic variance explained by the simplest nearly null vector is 0.007 and by the second simplest 0.001 . ]    .",
    "the amounts of genetic variance explained by vectors 1 through 6 are , respectively , 48.98 , 0.82 , 0.33 , 0.08 , 0 and 0 . ]    .",
    "the amounts of genetic variance explained by simplicity vectors 1 through 4 are , respectively , 0.02 , 0.22 , 0.15 and 0.02 . ]",
    "the six plots in the left sides of figures [ figcatpca ] through [ figjewelsimplicity4 ] show six orthonormal basis vectors for @xmath86 .",
    "the first @xmath53 , in solid blue lines , are the first @xmath53 principal component vectors , labeled with a blue 1 for the first principal component , a blue 2 for the second principal component , etc .",
    "the remaining ( 6@xmath53 ) basis vectors  the dashed red lines which only appear in figures [ figcatsimplicity2 ] and [ figjewelsimplicity4]form the simplicity basis for the nearly null space",
    ". the simplest basis vector is labeled with a red 1 , the next simplest with a red 2 , etc .",
    "the simplicity measure is that in ( [ eqfirstdivided ] ) , with large values of the measure being most simple . we have arranged the plots of the six basis vectors so that the top row contains what are arguably the most interesting basis vectors : the eigenvector corresponding to the largest eigenvector and the nearly null space s simplest vector .",
    "nearly null space vectors are plotted counter - clockwise in order of simplicity , while eigenvectors are plotted clockwise in order of the corresponding eigenvalues .",
    "each of the six basis vectors , when used as a selection gradient , produces an expected response to selection , as given in equation ( [ breedersbeta ] ) .",
    "a natural estimate of the expected response to selection for a selection gradient @xmath34 is simply @xmath87 , where @xmath88 is the estimate of the genetic covariance matrix .",
    "the captions under figures [ figcatpca ] through [ figjewelsimplicity4 ] list the six vector norms of @xmath89 , one for each of the six basis vectors .",
    "note that , if @xmath34 is a unit - length eigenvector of @xmath90 , then the norm of @xmath87 is simply equal to the associated eigenvalue .",
    "the norm of @xmath91 is maximal when @xmath34 is the eigenvector associated with the largest eigenvalue of @xmath88 .",
    "the norms of the expected responses to selection can also be reported as proportions of genetic variance , simply by reporting each norm divided by the sum of the norms .",
    "these proportions of genetic variance are plotted on the horizontal axes in the upper right panels of figures [ figcatpca ] through [ figjewelsimplicity4 ] , with simplicity scores on the vertical axes .",
    "the numbering and color - coding correspond to the plots on the left .",
    "the panel in the lower right shows the total genetic variance explained by the model space and by the nearly null space.=-1      kingsolver , ragland and shlichta ( @xcite ) estimated genetic variation in short - term growth rates of caterpillars at several temperatures ranging from 11@xmath92c to 40@xmath92c .",
    "the type of caterpillar was _ pieris rapae _ , which develops into the small cabbage white butterfly .",
    "the caterpillars cause extensive damage to crops such as cabbage and broccoli , so understanding their growth is important for commercial agriculture .",
    "the goal of the study was to quantify patterns of genetic variation in growth rate across temperatures , and explore how these patterns might affect evolutionary responses to selection in changing temperature conditions in nature .",
    "for instance , if there was little genetic variability in growth rates at high temperatures , rising temperatures could cause extinction of small cabbage white butterflies . alternatively ,",
    "if growth rate at high temperatures is negatively genetically correlated with growth rate at low temperatures , then rising temperatures could lead to reductions in growth rate at low temperatures.=1    caterpillars were reared individually from hatching on artificial diet in diurnally fluctuating conditions of temperature ( 1135@xmath92c ) and light ( 15 hours of light , 9 hours of dark ) until the start of the developmental stage known as the 4th larval instar .",
    "the studies focused on the 4th instar because more than 85% of all growth occurs during the 4th and 5th instars ; measurements were concentrated within a single instar to quantify effects of temperature on larval growth ( mass increase ) as distinct from development ( molting , or the developmental processes involved in the transitions between instars ) .",
    "see @xcite for details of the measurements and methods .",
    "briefly , the short - term growth rate of each caterpillar was measured at six different temperatures between 11@xmath92c and 40@xmath92c ( 11 , 17 , 23 , 29 , 35 and 40@xmath92c ) , during the first two days of the 4th instar ( figure [ catdata ] ) . to reflect the natural diurnal cycle typically experienced by caterpillars in nature , measurements at higher temperatures",
    "were done during the day ( light phase ) and at lower temperatures during the night ( dark phase ) ; growth rate was calculated as the net change in mass over the measurement period . because exposure to 40@xmath92c is potentially stressful and could affect subsequent feeding and growth , measurements at this temperature were done last for each caterpillar .",
    "measurements of 1088 individuals from 90 independent families of full siblings were completed .",
    "these data were used to estimate the genetic variance  covariance matrix @xmath41 for growth rate at the six temperatures , using the reml software _ dfreml _ described by @xcite .",
    "to study the nearly null space , we define simplicity via ( [ eqfirstdivided ] ) with @xmath93 for @xmath94 and @xmath95 .",
    "figure [ figcatpca ] shows the principal components decomposition ( six - dimensional model space , 0-dimensional null space ) of the matrix @xmath41 .",
    "the first pc , explaining 59.5% of the variation , is dominated by strong loadings of opposite sign for growth rate at 35@xmath92c and 40@xmath92c , reflecting the strong negative genetic covariance between growth at these two temperatures .",
    "this first pc has a low simplicity score .",
    "in contrast , the second pc has a much higher simplicity score and reflects loadings of the same sign and similar magnitude for growth across most temperatures ( 1740@xmath92c ) .",
    "note that the first three pcs , totaling over 93% of the variation , have small loadings for growth rate at 11@xmath92c , reflecting the low genetic variation at the lowest temperature .",
    "figures 1 to 7 in the supplementary material [ @xcite ] illustrate results for these data for model and null spaces of different dimensionality ( from 0 to 6 dimensions ) . for purposes of discussion we focus on results for the four - dimensional model space and two - dimensional null space ( figure [ figcatsimplicity2 ] ) : here the null space includes less than 1% ( 0.7% ) of the total genetic variance , sufficiently small to strongly constrain rates of evolutionary responses .",
    "the simplest vector in the null space is a contrast between large loadings at lower temperatures ( 1123@xmath96c ) and smaller loadings of opposite sign at higher temperatures ( 3540@xmath92c ) .",
    "we can interpret this direction in the genetic null space in terms of lack of evolutionary response to selection : simultaneous selection for increased growth rate at lower temperatures and for decreased growth rate at high temperatures would result in very little evolutionary change , because of the lack of genetic variation in this direction .",
    "it is also informative to consider the simplicity decomposition of the @xmath41-matrix , in this case when the null - space is six - dimensional ( supplementary figure 7 ) .",
    "for example , about 18% of the variance is associated with the simplest possible direction , for which loadings are equal across all temperatures .",
    "this direction represents variation in overall growth rate independent of temperature [ @xcite ] .",
    "because overall growth rate may be positively related to fitness in a variety of situations , selection in this direction may occur frequently in nature ; the simplicity analysis quantifies the genetic variation and the predicted evolutionary response to such selection .      in a study of the genetic variability of height in different environments",
    ", @xcite measured the heights of individuals of the north american annual plant _ impatiens capensis _ ( jewelweed ) in ten different greenhouse environments gotten from all combinations of two light treatments ( sun and shade ) and five density environments ranging from 64 plants per square meter to 1225 plants per square meter .",
    "individuals heights were measured to the nearest millimeter at six time points : 18 , 26 , 33 , 39 , 47 and 57 days .    here",
    "we analyze just one portion of the data : height as a function of time for plants grown in sun at density 1225 plants per square meter .",
    "the analysis appears in more detail in @xcite .",
    "our purpose is to study the genetic variability in growth curves in this environment .",
    "genetic variability will allow the plants to adapt to a range of conditions , such as sunlight ( taller than average plants are typically favored ) or the presence of high winds .",
    "the estimate of @xmath7 , the genetic covariance matrix , was produced using sas proc mixed . although the estimate is called a reml estimate , no restrictions were placed on the estimate to ensure it would be nonnegative definite .",
    "the resulting estimate of @xmath7 had two eigenvalues that were negative but close to 0 ( values of @xmath970.21 and @xmath970.55 ) , very small compared to the value of the largest eigenvalue ( value of 183.7 ) .",
    "we set the two negative eigenvalues equal to 0 and calculated our final estimate of @xmath7 , using the eigen - expansion based on the remaining four eigenvalues and eigenvectors .",
    "figures 8 through 14 in the supplementary material [ @xcite ] illustrate our results for null spaces of dimension 0 through  6 .",
    "the first principal component explains 97.5% of the variance and the first and second principal components explain 99.2% of the variance .",
    "based on the interpretability of the first two pcs and the proportion of variance explained , we recommend using a two - dimensional model space and four - dimensional nearly null space , displayed in figure [ figjewelsimplicity4 ] . to find the simplicity basis of the nearly null space , we define simplicity via ( [ eqfirstdivided ] ) with the @xmath98 s equal to 8 , 7 , 6 , 8 and 10 , the differences in the time points .",
    "the first principal component ( see figure [ figjewelpca ] ) has a very small loading on early ages with loadings increasing as the plant ages .",
    "thus , using just the first principal component , we see that , in a sunny dense environment , the population will be able to evolve and adapt to a wide range of forces of selection that act on late - age heights",
    ". such genetic variation would be important if late season height is under natural selection  for example , if plants that are larger late in the season are able to acquire more light and more successfully mature their seeds .",
    "the second principal component indicates that there is some genetic variability at young ages .",
    "the simplest direction in the nearly null space , labeled with a red 1 in figure [ figjewelsimplicity4 ] , shows that there is little genetic variation in the contrast of late / early life heights to mid - life heights . with this lack of genetic variation",
    ", the species will not be able to adapt when the variability of environmental conditions is in the form of a contrast between early / late season and mid - season .",
    "for instance , if a typical season begins and ends with little sunshine , but has high winds in mid - season , selection might favor plants that are taller than average at the beginning and end of the season , but shorter than average mid - season ; that this combination of traits is in the null space , however , suggests that there would be little to no evolutionary response to such seasonal conditions .    note the additional insight gained by considering the simplicity basis over simply considering pc analysis , shown in figure [ figjewelpca ] . interpreting pcs 3 through 6 is much harder than interpreting the simplest element of their span , that is , the simplest element of the nearly null space .",
    "while one might infer from pcs 1 and 2 that the simplest vector in the nearly null space is close to a parabola , our more rigorous approach confirms that ad hoc insight .",
    "in addition , the graphical plot in figure  [ figjewelsimplicity4 ] gives equal importance to the structure of the first few pcs and the structure of the nearly null space .",
    "we carried out a simulation study to get insight about the effects of sampling variation , in particular , how it affects the shape of the simplest vector and predictions about selection response .",
    "to reduce computational burden , our design and our estimate of the genetic covariance were very simple .",
    "we used a balanced design with @xmath99 independent families and @xmath100 half - siblings within each family .",
    "we estimated the genetic covariance matrix via the classic anova / method of moments .",
    "see chapter 18 of @xcite .",
    "this method leads to a closed form estimate of the genetic covariance matrix , but can only be used in simple designs .",
    "we generated data for individual @xmath101 of family @xmath10 according to @xmath102 , where @xmath103 , @xmath104 and @xmath105 were independent normal vectors of length @xmath106 , with means equal to the zero vector and with covariance matrices denoted @xmath107 , @xmath108 and @xmath109i , respectively .",
    "we set all parameters equal to the estimates from the caterpillar study of @xcite , as described in section [ sectioncaterpillar ] .",
    "we simulated 200 data sets and studied three - dimensional nearly null spaces .",
    "each simulated data set yielded an estimated genetic covariance matrix with its eigenvalues and eigenvectors , an estimated nearly null space , the simplest vector in that estimated nearly null space and the expected response to selection under a selection gradient equal to the simplest vector .",
    "the anova method can lead to a negative definite genetic covariance matrix estimate . for our estimated 6 by 6 genetic covariance matrices ,",
    "all 200 had the first five eigenvalues positive but for 170 of the 200 , the smallest eigenvalue was negative .",
    "we adjusted these 170 estimates of @xmath107 by setting the 170 smallest eigenvalues to 0 .",
    "as the magnitudes of the negative eigenvalues were small ( the smallest eigenvalue was @xmath970.068 ) , this adjustment had little impact .",
    "note that resetting the eigenvalues leaves the eigenvectors unchanged .",
    "figure [ figdatafamily ] provides information from one of the 200 simulated data sets .",
    "the upper left plot shows the simulated data from three of the one hundred families , color - coded by family .",
    "the upper right plot shows four vectors in the estimated nearly null space : the black line is the simplest vector and the remaining lines are the fourth , fifth and sixth principal components of the estimated genetic covariance matrix .",
    "the lower left plot shows the expected response to selection when using the four depicted vectors in the nearly null space as selection gradients . the expected response to selection",
    "is calculated using the `` true genetic covariance matrix , '' that is , the genetic covariance matrix used to generate the simulated data .",
    "the magnitudes of the vectors of expected responses to selection are 0.012 for the simplest vector and 0.067 , 0.022 and 0.021 for the three principal components .",
    "the largest possible magnitude of the expected response to selection is the largest eigenvalue of the true genetic covariance matrix , that is , 0.618 .",
    "figures [ figvectors ] and [ figresponses ] contain the results of our simulation study . in figure [ figvectors ]",
    "the upper left plot shows the 200 simplest vectors in the estimated nearly null space .",
    "the other three plots in that figure show the eigenvectors that span the estimated nearly null space .",
    "the upper right plot contains the 200 `` fourth eigenvectors , '' that is , those corresponding to the fourth largest eigenvalues of the estimated genetic covariance matrices .",
    "the lower left plot contains the 200 `` fifth eigenvectors '' and the lower right plot contains the 200 `` sixth eigenvectors . ''    .",
    "multipliers have been chosen so that the vectors in the above plots are similar . ]        in figure [ figresponses ] , the upper right plot contains the 200 expected responses to selection calculated using the 200 simplest vectors of figure [ figvectors ] as selection gradients and the `` true '' genetic covariance matrix .",
    "the remaining plots contain the expected responses to selection calculated using the eigenvectors shown in figure [ figvectors ] as selection gradients .    from figures [ figdatafamily ] to [ figresponses ]",
    ", we can see that the simplest vectors in the estimated nearly null spaces are always interpretable and send the same clear message .",
    "in contrast , the fourth principal components ( the `` dominant '' component in the estimated nearly null spaces ) are difficult to interpret , as we expected .",
    "the simplest vectors vary little from data set to data set and , when used as selection gradients , the simplest vectors yield expected responses to selection that are close to 0 , with little variability ( mean length of the response vectors is 0.032 with standard deviation 0.001 ) .",
    "in contrast , when the fourth eigenvector is the selection gradient , the magnitudes of the expected response vectors are larger and more variable , with mean length 0.091 and standard deviation 0.007 .",
    "the asymptotic consistency of our method follows directly from consistency of the estimated genetic covariance matrix . under conditions ,",
    "the reml estimate @xmath88 is asymptotically equivalent to the maximum likelihood estimate , which converges in probability to @xmath7 , the true genetic covariance matrix [ @xcite , page 181 ] . in this case , the eigenvalues of @xmath88 converge to those of @xmath7 , since eigenvalues are defined as solutions of the characteristic polynomial , and the coefficients of the characteristic polynomial of @xmath90 converge to those of @xmath7 .",
    "thus , for many common methods of estimating the dimension @xmath53 of the model space , the dimension of the estimated model space converges to @xmath53 , with , possibly , the requirement that @xmath110 .",
    "for instance , the convergence of estimated eigenvalues implies that the proportion of variance explained by the first @xmath53 eigenvectors of @xmath88 will converge to the proportion of variance explained by the first @xmath53 eigenvectors of @xmath7.=-1    showing convergence of estimated eigenspaces requires more care due to the complication of defining distances between subspaces and due to the possibility of multiplicity of the roots of the characteristic polynomial and the resulting nonuniqueness of eigenvectors .",
    "see @xcite , who shows that , under conditions , the nearly null space of the usual sample covariance matrix converges to that of the true covariance matrix . to define convergence",
    ", gaydos defines the squared distance between two subspaces as the sum of the squared sines of the canonical angles between the two subspaces .",
    "see @xcite for a discussion of canonical angles .",
    "we have proposed simplicity measures and developed accompanying graphical tools to explore and visualize directions of low variability in vector - valued traits .",
    "the techniques allow us to more directly study the space spanned by the lowest variance pcs .",
    "when examined individually , these pcs typically have little structure . considering them jointly as a subspace allows us to find the simplest structure within that subspace .",
    "our graphical tools allow us to consider subspaces of different dimensions , easily seeing the simplicity and variance explained by the subspace and individual vectors .    here",
    ", we have studied the nearly null space by defining a simplicity basis with the simplicity of a vector @xmath39 of the form @xmath62 , and we have analyzed data with the simplicity of @xmath39 defined in terms of first divided differences of the components of @xmath39 .",
    "instead of using such a smoothing - based simplicity measure , one could consider a sparseness measure , deeming a vector to be simple if it has many zero components . in a modification of principal components , @xcite",
    "define sparseness of a vector in terms of the number of its nonzero components .",
    "another sparseness measure , used in the varimax method of factor rotation in factor analysis [ @xcite ] , defines a quadratic measure of sparseness of the vector @xmath39 , namely , @xmath111 , with large values indicating greater simplicity .",
    "an @xmath112 measure of sparseness , namely , @xmath113 , is used in the lasso technique for regression [ @xcite ] , with small values indicating greater simplicity .",
    "our methodology can , in principle , be extended to function - valued traits .",
    "genetic constraints can be defined for function - valued traits via the work of @xcite , @xcite and @xcite , who showed the validity of the breeder s equation in ( [ breeders ] ) and ( [ breedersbeta ] ) when the phenotype is a function .",
    "the advantages of functional data analysis techniques over multivariate techniques are well known in the statistical literature .",
    "for instance , functional data analysis does not require that individuals be measured at the same time points or even at the same number of times .",
    "furthermore , functional data analysis uses the smoothness underlying the data to avoid high - dimensional analysis problems caused by a large number of observations per individual .",
    "the advantages of functional data analysis are only just catching hold in the biological literature .",
    "see , for instance , @xcite and @xcite .    defining a simplicity basis for the nearly null space is especially useful in the analysis of functional data . to see this ,",
    "suppose that the genetic component @xmath0 is a continuous time random process .",
    "then , under conditions , we can write @xmath0 in terms of its karhunen  love expansion : @xmath114 , where the @xmath115 s are orthonormal functions and the @xmath116 s are independent with mean zero and variances @xmath117 .",
    "see , for instance , @xcite or @xcite .",
    "if our model for @xmath0 allows a countably infinite number of these variances to be positive , then the true model space for @xmath0 is infinite dimensional .",
    "however , since any particular data set is finite dimensional , estimates of @xmath0 always lie in a finite - dimensional space .",
    "hence , the estimated model space is finite dimensional and its orthogonal complement is infinite dimensional .",
    "a natural way to study this infinite - dimensional subspace is by finding its simplest directions and seeing if these directions have any interpretable structure .",
    "studying the structure of low variance subspaces can provide biologists with insights into the existence of genetic constraints .",
    "but the notion of a simplicity basis and the associated visualization tools may be useful in other contexts , in particular , in providing modeling tools in the analysis of smooth high - dimensional data ."
  ],
  "abstract_text": [
    "<S> principal components analysis ( pca ) is a common way to study the sources of variation in a high - dimensional data set . </S>",
    "<S> typically , the leading principal components are used to understand the variation in the data or to reduce the dimension of the data for subsequent analysis . </S>",
    "<S> the remaining principal components are ignored since they explain little of the variation in the data . </S>",
    "<S> however , evolutionary biologists gain important insights from these low variation directions . </S>",
    "<S> specifically , they are interested in directions of low genetic variability that are biologically interpretable . </S>",
    "<S> these directions are called _ genetic constraints _ and indicate directions in which a trait can not evolve through selection . here , we propose studying the subspace spanned by low variance principal components by determining vectors in this subspace that are simplest . our method and accompanying graphical displays </S>",
    "<S> enhance the biologist s ability to visualize the subspace and identify interpretable directions of low genetic variability that align with simple directions .    </S>",
    "<S> ,    ,    ,    ,    ,     + </S>"
  ]
}