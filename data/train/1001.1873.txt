{
  "article_text": [
    "compressed sensing research has the aim of improving the efficiency and reliability of source estimation when the number of measurements taken is smaller than the number of degrees of freedom in the source .",
    "although somewhat counterintuitive , it turns out that , given some special structure in the source , it is possible to reconstruct accurately all source components  @xcite .    owing to the fundamental nature of the problem , it is not surprising that research and methodology span a number of fields such as image processing , topology , multi - user detection , and convex optimization  @xcite . in this article",
    "we also apply methods developed initially within physics , that have recently been applied to compressed sensing  @xcite .    in the canonical model",
    ", a real - valued vector @xmath1 constitutes observations of a real - valued source vector @xmath2 via a measurement matrix @xmath3 as @xmath4 the dimension of @xmath1 is @xmath5 and the dimension of @xmath2 is @xmath6 .",
    "the parameter @xmath7 quantifies the number of observations per the degree of freedom of the source , and we call it the compression rate",
    ". the problem of compressed sensing is to reconstruct the source @xmath2 from the observations @xmath1 and the measurement matrix @xmath3 .    when the compression rate @xmath8 is smaller than one , the problem amounts to solving an ill - conditioned set of linear equations and hence its solution is not unique",
    "however , if the source is suitably structured , then such structural information may be utilized to overcome the ill - conditionedness .",
    "one example is sparsity , whereby the source has many zero components . for reconstruction of sparse sources",
    "it is now well known that provided @xmath8 is not too small an accurate reconstruction of the source @xmath2 may be achieved by minimizing the @xmath0 norm @xmath9 subject to the constraint @xmath10 .",
    "this minimization problem can be solved efficiently by casting it into a problem of linear programming .",
    "it has recently been shown that @xmath0 minimization also allows perfect reconstruction of sparse sources  @xcite with high probability for large systems provided that the compression rate @xmath8 is larger than a certain threshold value @xmath11 .",
    "furthermore a sharp transition between perfect and imperfect reconstruction is observed at @xmath12 , which we call the compression threshold .",
    "we shall consider weighted norms , in which each component in the sum ( [ eq : l1norm ] ) has a different coefficient ( weight ) .",
    "the consideration of non - uniform weights has been motivated by bayesian and topological arguments , algorithmic studies and much empirical evidence .",
    "numerous results indicate that use of non - uniform weights can reduce the compression threshold , guarantee optimality in a probabilistic sense , or otherwise improve algorithmic performance  @xcite . a topology based method able to place bounds on weighted reconstruction",
    "was recently proposed , and demonstrated for the case of a source with two blocks of distinct density of non - zero components  @xcite .",
    "the problem we address is the following : given a mean density of non - zero components , and some additional prior information on the distribution of non - zero components , how can the weights be chosen so as to minimize the number of measurements required to reliably reconstruct the source using weighted @xmath0 norm ( w-@xmath0 ) minimization .",
    "we assume a standard model framework in which components of @xmath3 are independent and identically - distributed random variables ; drawn from a symmetric distribution of finite variance and higher - order moments without finite probability mass at the origin , the gaussian distribution being one intuitive case .",
    "the observations @xmath1 are also random variables , determined as functions of the measurement matrix and a random source through ( [ eq : yax ] ) .    in the standard sparse problem a fraction @xmath13 of all source components are non - zero , this subset being selected uniformly at random .",
    "it is instead assumed in this article that a ( potentially distinct ) marginal probability is known for every component in the source , so that @xmath14 is non - zero with probability @xmath15 independently of other components .",
    "we call the parameter @xmath16 the density of component @xmath17 .",
    "the prior is therefore @xmath18 \\label{eq : trueprior}\\;,\\ ] ] where @xmath19 is the conditional prior of @xmath14 given that it is non - zero .",
    "the conditional prior @xmath19 is assumed unknown to the observer , but it should have finite moments and should not have finite probability weight at @xmath20 .",
    "the densities @xmath21 encode prior information about sparsity of the source , are assumed available to the observer , and will be called marginal density information .",
    "this definition covers the case of block - structured sources , wherein a source is divided into sets of components according to their densities , including two blocks as a special case .    to each source component",
    "is also associated a weight @xmath22 .",
    "the estimate of the source is obtained as a solution to an optimization problem : minimization of the weighted @xmath0 norm @xmath23    we note irrespective of weighting a trivial lower bound on the compression required for perfect reconstruction : @xmath24 . the lower bound",
    "is easily achieved , by a matrix inverse operation , when the positions of all zeros in the source are known  or equivalently all the densities @xmath16 are extremal , @xmath25 or @xmath26 . any variation from these extremal values for",
    "fixed @xmath27 increases the uncertainty in the source values , and so will increase the compression threshold .",
    "the principal results in this article are regarding :    1 .   the compression threshold @xmath11 for perfect reconstruction , with high probability , given a set of weights ; 2 .",
    "the assignment of weights , as a function of the marginal densities , that achieves a minimal @xmath11 , and the value of this minimum .",
    "rather than directly finding and classifying minima of the w-@xmath0 minimization problem , an auxiliary probability distribution may be introduced , for which the _ maximum a posteriori _ ( map ) solutions are equivalent to the solutions of the optimization problem .",
    "a parameter @xmath28 is introduced to soften the probability distribution and to allow application of analytic methods , and this is finally taken to be large so as to recover the posterior mean coincident with the map solution as well as the solution of the w-@xmath0 minimization .",
    "the probability is the model posterior @xmath29 where @xmath30 is the normalization for the probability distribution . in the limit of large @xmath28",
    "the probability measure will be concentrated on values @xmath31 that solve the weighted minimization problem ( [ eq : wl1min ] ) . we further define a generating function in the large - system limit and its expectation value with respect to measurements @xmath32\\label{eq : f}\\;.\\ ] ] the function @xmath33 is linearly related to a generalized version of the mutual information between the source and the observations  @xcite .",
    "statistics on w-@xmath0 solutions are extracted from @xmath34 , or @xmath35 , by adding small perturbations to the model posterior and taking derivatives .",
    "consider adding a small perturbation @xmath36 to the exponent of ( [ eq : px ] ) , whereby the normalization @xmath30 now depends on @xmath37 as well .",
    "here , @xmath38 denotes the @xmath39 norm . the normalized mean square error ( mse ) with respect to the model posterior ( [ eq : px ] ) is given by @xmath40 = \\lim_{h\\rightarrow 0 } \\frac{\\partial}{\\partial h } f(\\beta , n)\\;,\\ ] ] which in the limit @xmath41 gives the normalized mse of the w-@xmath0 solution .",
    "if mse is evaluated to be zero , this implies that the w-@xmath0 minimization is sufficient for perfect reconstruction .",
    "an analysis of @xmath34 is problematic owing to its definition in terms of random measurement parameters , but we mitigate for this by studying the asymptotics .",
    "many interesting statistics , such as mse , are found to be _ self - averaging _  the statistics derived from @xmath34 for almost all @xmath1 and @xmath3 converge to those derived from @xmath35 for large @xmath42 .",
    "we thus analyze the expectation value @xmath43 in place of the random object @xmath34 , expressing the former in an analytic form at leading orders in @xmath42 and @xmath28 , thereby demonstrating conditions for perfect reconstruction .    in our analysis",
    "we assume , besides the self - averaging property , the validity of exchanging order of limits . we will solve the problem by the replica method , which introduces further heuristic assumptions - the _ replica symmetric _",
    "( rs ) solution is developed .",
    "we are unable to verify rigorously each assumption , but the methodology is a standard one  @xcite , and a catalogue of successes indicates the results herein should be treated as exact . some closely related results in compressed sensing  @xcite are already known to coincide with those of rigorous methodologies  @xcite .      the expectation with respect to the random variables ( [ eq : f ] ) is taken by a standard approach .",
    "the generating function may finally be expressed in an extremization form , as @xmath44 \\right\\rbrace \\label{eq : var_f}\\;,\\end{aligned}\\ ] ] where @xmath45 is a standard gaussian measure , where @xmath46=n^{-1}\\sum_{i=1}^n(\\cdots)$ ] is an empirical average with respect to the densities and weights of source components , and where the function @xmath47 is defined as @xmath48 a solution is the extremum where the partial derivatives with respect to the six order parameters are zero , and the set of self - consistent equations describing the order parameters are called the saddle - point equations . note that for the special case of uniform weights and gaussian @xmath19 , ( [ eq : var_f ] ) becomes identical to results derived in the absence of marginal prior knowledge  @xcite .",
    "the order parameters for the correct solution of ( [ eq : var_f ] ) coincide with informative quantities : @xmath49 is the mean - squared estimate @xmath50 $ ] ; @xmath51 is the overlap of source and estimate @xmath52 $ ] ; and @xmath53 is a statistic on the pair correlation functions .",
    "the mean square error is @xmath54={\\bar \\rho } - 2{m}+ { q}$ ] .",
    "the six saddle - point equations are easily reduced to three equations on the conjugate parameters ( denoted by hat ) @xmath55 , @xmath56 and @xmath57 , and further to two equations by identifying @xmath58 .",
    "given a specific parameterization of the weights and measurement process these might be solved numerically .",
    "however , given our noiseless model ( [ eq : yax ] ) it is known that the mean square error will be zero in some range of large @xmath8 , and reasonable weights .",
    "this perfect reconstruction solution was found in the unweighted case with @xmath59  @xcite , and generalizes to the weighted case .",
    "we can solve the equations to leading order in @xmath60 . at leading order many features of @xmath19 , the prior on non - zero components , are inconsequential .",
    "it is convenient to define two functions of @xmath57 @xmath61 \\label{eq : f1}\\;,\\ ] ] where @xmath62 is a rescaled weight , and @xmath63 - { \\mathop{\\mathbb{e}}\\nolimits}\\left[(1-\\rho_i ) { u_i}\\frac{2\\exp\\left ( - { u_i}^2/2 \\right)}{\\sqrt{2\\pi}}\\right ] \\nonumber\\\\ & + { \\mathop{\\mathbb{e}}\\nolimits}\\left[(1-\\rho_i ) ( 1 + ( { u_i})^2 ) 2\\mathcal{q}({u_i})\\right ] \\label{eq : f2}\\;,\\end{aligned}\\ ] ] where @xmath64 is the conventional q - function .",
    "the two saddle - point equations may be expressed at leading order as @xmath65 and @xmath66 where the latter equation can be solved numerically .      for the rs solution of the replica method a local stability analysis",
    "gives necessary criteria for the validity of any solutions found , and can be studied by three eigenvalues derived from the full , rather than rs ( [ eq : var_f ] ) , saddle - point form  @xcite .",
    "two eigenvalues relate to instabilities consistent with the rs saddle - point equation ( [ eq : var_f ] ) , and can be evaluated within the rs framework , by analysis of ( [ eq : kappa ] ) and ( [ eq : gamma ] ) .",
    "the final replicon eigenvalue can indicate a failure of the rs assumption yielding ( [ eq : var_f ] ) , but can not be derived from ( [ eq : var_f ] ) .",
    "when the rs assumption fails in this sense , a symmetry breaking approximation should be required .",
    "stability within the rs framework requires that a small fluctuation in the order parameters of the right - hand side of ( [ eq : kappa ] ) and ( [ eq : gamma ] ) decays to zero under iteration of the equations .",
    "small fluctuations in @xmath57 and @xmath67 about the perfect reconstruction solution are stable provided that @xmath68 it can be seen that for large @xmath8 and small @xmath69 these conditions will be met .",
    "the replicon eigenvalue is consistent with the stability of the solution .",
    "stability and uniqueness of the perfect reconstruction solution implies success of w-@xmath0 reconstruction up to errors of order @xmath70 , with high probability .",
    "the instability criterion is met as @xmath8 is decreased from one so that there exists a compression threshold @xmath71 .",
    "a pair of equations describe the threshold in terms of only one order parameter @xmath57 @xmath72 the latter equality is a consequence of ( [ eq : gamma ] ) combined with ( [ eq : stability ] ) , and is independent of @xmath11 . aside from the explicit dependence on @xmath57 ,",
    "there is a dependence on the densities and weights .",
    "the two equations  ( [ eq : f3 ] ) provide implicit expressions for the dependences of the compression threshold @xmath11 on the set @xmath73 of densities and weights .",
    "if one assumes uniform weights , the compression threshold @xmath11 is described as an implicit function of @xmath74 by @xmath75\\label{eq : alphac}\\;,\\ ] ] and @xmath76 for an inhomogeneous system of fixed @xmath69 , any knowledge of the marginal densities constitutes additional information .",
    "incorporation of non - uniform weights introduces additional degrees of freedom in the model that can be exploited to reduce @xmath11 .",
    "it also means that it is necessary to specify the weights according to the given set of densities in order to find the optimum value of @xmath11 .      in order to select optimally the weights",
    ", we consider the optimization problem of minimizing the compression threshold with respect to the weights .",
    "for this purpose we can take @xmath57 and @xmath21 to be fixed parameters and minimize @xmath77 with respect to the weights @xmath78 subject to the constraint that @xmath79 is zero ( see ( [ eq : f3 ] ) ) .",
    "the constraint can be dealt with via the lagrange multiplier method as @xmath80 the derivative with respect to @xmath81 leads to the following criteria @xmath82 combined with the derivative with respect to @xmath83 , which reads @xmath84 \\left(\\frac{1+\\lambda}{\\lambda}- 2\\right ) = 0\\label{eq : lambda}\\;,\\ ] ] yielding @xmath85 .",
    "therefore the set of equations ( [ eq : wb ] ) , each of which determines one weight , are independent given @xmath57 and @xmath16 .    using this independence it is possible to optimally set the weights for an arbitrary density distribution @xmath21 by the following procedure .",
    "solve ( [ eq : wb ] ) for @xmath86 , and the solution is a function of @xmath16 only .",
    "the set of solutions @xmath87 defines the optimal weights up to the overall scaling",
    ". observing that the w-@xmath0 minimization problems are invariant under the overall scaling , every weight can be assigned straightforwardly as @xmath88 .",
    "this set of weights will minimize @xmath11 .    to evaluate the minimum of @xmath11 , one observes from ( [ eq : f1 ] ) and ( [ eq : f3 ] ) that @xmath89 $ ] holds , where @xmath90 .",
    "this expression can be understood as if each component of the source , with density @xmath91 , would require a compression rate at least @xmath92 for its perfect reconstruction , and the lower bound of the total compression rate is the empirical average of this componentwise bound over all components .",
    "this interpretation would further suggest a possibly fundamental importance of the quantity @xmath92 as a measure of some sort of information associated with a random variable that takes non - zero values with probability @xmath91 .",
    "one can also confirm , by particularizing our results to the unweighted system , that @xmath92 gives the compression threshold of the unweighted system with density @xmath91 .",
    "thus , evaluation of @xmath11 for the weighted system only requires the densities @xmath21 of the system and the curve @xmath92 for the unweighted system .",
    "moreover , the curve for the unweighted system is convex upward , so that jensen s inequality tells us that @xmath11 is below @xmath93 , except when the density distribution is concentrated at a single point , implying that the w-@xmath0 minimization improves the compression threshold over the unweighted counterpart .",
    "it should also be noted that , when a block structure can be assumed for the source , the minimum @xmath11 is equal to the compression rate that would be achievable if each block were measured separately with the optimum compression rate for that block and then reconstructed individually from other blocks .",
    "this observation implies that introduction of optimal weights successfully compensates degradation due to intermixing of blocks of different densities in measurements .",
    "finally we can note an interesting asymptotic in the result applicable in the case that @xmath69 is close to one ( @xmath57 small ) . in this case",
    "the optimal weights are assigned according to a simplified form of ( [ eq : wb ] ) @xmath94",
    "as a simple case we consider the source consisting of two equally - sized blocks labeled @xmath95 , such that components in the block @xmath96 are non - zero with some uniform lower probability than components of block @xmath97 . a corresponding asymmetry in the weights can be assumed , but weights must also be uniform within any block .",
    "this case allows a deal of intuition and has been studied previously owing to its simple structure  @xcite .",
    "let the density and the weight of block @xmath98 be @xmath99 and @xmath100 , respectively , with @xmath101 .",
    "figure  [ fig : variousweights ] demonstrates the result for a variety of weight asymmetry @xmath102 given a density asymmetry @xmath103 . since the density in each block must be in @xmath104 the relevant values of @xmath69 are confined to the interval @xmath105 .",
    "curves for @xmath106 are plotted , with four labeled cases , the uppermost curve being the unweighted case .",
    "it can be seen that the compression threshold is reduced by allowing asymmetric weights , and that the lower envelope of all curves indicates the achievable performance by optimal selection amongst the weights .     as a function of density @xmath107 for various @xmath102 .",
    "four curves are highlighted from a range @xmath106 .",
    "the lower hull of all curves indicates the minimum @xmath11 achievable by optimal weight selection .",
    "inset : the hull of all curves ( corresponding to the maximum compression ) can be constructed from the unweighted ( @xmath108 ) curve by a simple linear construction . ]    for the system @xmath109 the midpoint of the line connecting @xmath110 and @xmath111 coincides with the lower envelope at @xmath112 corresponding to the optimal compression rate for the two - block model .      to test the theory we have generated a number of instances of the problem for various system sizes and solved these by linear programming .",
    "components of @xmath3 and non - zero components of @xmath2 were sampled from normal distributions .",
    "optimally weighted , and unweighted , @xmath0 minimization problems were solved to determine the compression threshold where optimal reconstruction failed .",
    "figure  [ fig : optimalweights ] demonstrates result for a two - block system with a uniform weighting @xmath113 and optimized weighting .",
    "it can be seen that the thresholds are distinct with a significant improvement in performance for the optimally weighted case .",
    "results of fitting these numerical data with second - order polynomials in @xmath70 , obtained by @xmath114 regression , are also plotted in fig .",
    "[ fig : variousweights ] .",
    "extrapolation to @xmath115 yields an estimate of the compression threshold @xmath116 for the optimally weighted case , which is in agreement with the analytical result @xmath117 .",
    "the extrapolated result for the unweighted case @xmath118 is also in agreement with the analytical result @xmath119 .     for unweighted ( @xmath120 ) versus",
    "optimally weighted ( @xmath121 ) reconstruction for a two - block model ( @xmath122 , @xmath123 ) for various system sizes .",
    "each symbol represents the mean threshold from @xmath124 trials each with independently generated measurements , error bars are small by comparison with symbol size .",
    "the data is fitted by @xmath114 regression . ]",
    "this paper has demonstrated a method for optimal selection of weights in the w-@xmath0 minimization utilizing prior knowledge about densities , and thereby providing the optimal threshold for compression .",
    "the result is a simple one with decoupling structure for source components , and described by a single order parameter in the case of perfect reconstruction .",
    "the threshold in the compression rate for which perfect reconstruction is possible in a system of known marginal densities can be straightforwardly derived from the threshold curve for the unweighted system with a simple graphical procedure .",
    "this work should in future be extended to consider the effect of noise and of correlations between the source components .",
    "the method relied on the replica method and a saddle - point formulation , which although complicated in origin provides a concise and intuitive saddle - point framework from which to derive results .",
    "the analysis presented has been verified in experiment and provides a mechanism that may be immediately incorporated in practical problems where marginal density information is available .",
    "a complete description of the replica analysis and various extensions will be forthcoming in an article under preparation .",
    "support from the grant - in - aid for scientific research on priority areas `` deepening and expansion of statistical - mechanical informatics '' by the ministry of education , culture , sports , science and technology , japan ( no .",
    "18096010 ) , is acknowledged .",
    "j.r . is supported in part by research grants council of hong kong ( grant no .",
    "hkust 604008 ,  603607 ) ."
  ],
  "abstract_text": [
    "<S> compressed sensing of sparse sources can be improved by incorporating prior knowledge of the source . in this paper </S>",
    "<S> we demonstrate a method for optimal selection of weights in weighted @xmath0 norm minimization for a noiseless reconstruction model , and show the improvements in compression that can be achieved . </S>"
  ]
}