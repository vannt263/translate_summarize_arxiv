{
  "article_text": [
    "with the fairly recent arrival of low - cost multi - core cpus , institutes often have significant computing power at their disposal .",
    "mathematica 7 , whose main motto is parallel computing , makes it relatively simple to send a calculation to the fellow cores on the same machine , though still not exactly straightforward to distribute a calculation on a larger cluster .",
    "the package we present in the following fills this gap .",
    "after a one - time setup of the cluster , it allows to easily distribute calculations to as many hosts as there are mathematica licenses available ( both ordinary licenses and mathematica 7 s sublicenses ) .",
    "we certainly do not propose to parallelize ` atomic ' mathematica operations , like @xmath2 , which is a daunting task even at the conceptual level .",
    "rather , we focus on lengthy evaluations of one function over many arguments , for example the evaluation of a cross - section for many points in phase and/or parameter space . incidentally , our package is not restricted to numerical evaluations , but can handle any kind of mathematica expressions .",
    "many physicists would argue that at least numerical evaluations of a certain volume should be done in a compiled language for performance reasons .",
    "this is at best partially true , as mathematica has a formidable arsenal of functions , e.g.  for numerical analysis , which are not easily available elsewhere , and it is the choice of algorithm that influences the computation time much more than the speed of a single evaluation .",
    "furthermore , in conjunction with mathlink , e.g.  through formcalc s mathematica interface @xcite , the execution speed is essentially that of a compiled language and mathematica s part is ` governing ' the calculation .",
    "the package we present in this paper is remarkably short and contains one main function @xmath3 which substitutes @xmath4 in serial calculations .",
    "[ sect : usage ] describes usage of the package , sect .",
    "[ sect : ref ] provides a function reference , and sect .",
    "[ sect : setup ] describes installation and system setup .",
    "the multicore package is loaded with    ....",
    "< < multicore ` ....    the next step is to add cores on which evaluations can be distributed .",
    "this can be done directly with e.g.     ....",
    "addcore[\"pc123.mppmu.mpg.de \" ] ....    or ,",
    "if login under a different username is required ,    ....     addcore[\"batman@pc123.mppmu.mpg.de \" ] ....    this explicit method becomes cumbersome , however , if many cores with varying loads are involved .",
    "the alternate invocation    ....     addcore[10 ] ....    takes up to ten of the currently ` free ' cores .",
    "this information is supplied by the @xmath5 shell script ( part of the multicore package ) which in turn reads the admissible cores from a @xmath6 file and invokes @xmath7 to determine the load .",
    "the @xmath6 file has the simple syntax    ....",
    "pc380    4     pc381    4     pc339b   2     pc472 ....    where the optional integer behind the hostname indicates the number of cores the host has .",
    "the machines should be listed in descending cpu speed , i.e.  fastest on top , to optimize performance .",
    "each remote host should be running an @xmath8 daemon , since then its load will be reported through @xmath7 and @xmath5 will use only the free cores .    in the case of a linux cluster ,",
    "the @xmath6 file can be generated ( more or less ) automatically , with the help of the @xmath9 script , as in :    ....     ./setupcores > $ home/.submitrc ....    this script assumes that the hosts are listed via @xmath7 , that a password - free login via @xmath10 is possible , and that each host is running a flavour of linux where @xmath11 can meaningfully be read out .",
    "the file generated in this way constitutes a ` raw ' version and should be reviewed by hand .",
    "each core launched requires a mathematica license , i.e.  a kernel license . from mathematica 7 on",
    ", each ( main ) license includes four sublicenses and it is possible to use these sublicenses for parallelization ( cf .",
    "sect.[sect : sublicense ] , @xmath12 ) .",
    "one can further take care not to invoke more slave processes than licenses available . to this end @xmath13",
    "is invoked with an integer @xmath14 , meaning that it should spawn at most so many slaves that @xmath15 ( main ) licenses are left for other users .",
    "also one can provide a second integer argument @xmath16 to leave @xmath17 sublicenses unused .",
    "this mode really makes sense only for network licenses . for non - network licenses ,",
    "@xmath13 silently assumes that the other machines listed in @xmath6 have similar licenses .",
    "multicore generally works in a master  slave model , requiring one license ( but hardly any cpu time ) for the master and one main or sublicense for each slave .",
    "we assume that all cores in the cluster run the same mathematica version , in particular that the master s version number is the same as all slaves. in particular we assume that subkernels on slave cores can be launched if and only if the master is running mathematica 7 .    quitting",
    "the master s mathematica kernel automatically closes all links , so explicitly ` removing ' registered cores is usually not necessary unless one wants to free mathematica licenses .",
    "each slave session is characterized by an identifier of the form @xmath18}$ ] , where @xmath19 is the host name and @xmath20 an integer link i d .",
    "the syntax for @xmath21 is    ....",
    "removecore[host ]     removecore[host[id ] ] ....    where both @xmath19 and @xmath20 may be a pattern .",
    "thus , @xmath22}$ ] closes all slaves on host @xmath23 and @xmath24}$ ] closes all current slave sessions .",
    "once the cores are registered , the only necessary substitution is to replace @xmath4 ( @xmath25 ) by @xmath3 to make multiple evaluations execute in parallel .    * important : * the only slightly non - straightforward aspect is the remote definition of the function being evaluated .",
    "@xmath3 sends the definition of this function to the slave as much as the @xmath26 function would save it in a file .",
    "this _ fails to work _ ( for both @xmath3 and @xmath26 ) if the function depends on a @xmath27 in the master s session , i.e.  if the function is or invokes a mathlink function .",
    "even if the slave session has the same mathlink executable installed , it will in general not communicate via the syntactically same @xmath27 .    to work around such cases ,",
    "the @xmath13 function has an optional second argument .",
    "this argument is sent to the slave upon opening of the link as an initialization command . in our opinion",
    "the best procedure in the mathlink case mentioned above is not to install the mathlink executable in the master s session at all , to prevent sending any explicit @xmath27 pointing to the master s installed mathlink executables , and instead include the @xmath28 statement in the @xmath13 invocation , as in    ....",
    "addcore[0 , install[\"looptools \" ] ] ....    also , if the function has a very lengthy definition one might want to place it in a file and load that via the initialization command , e.g.     ....     addcore[0 , < < myfunction.m ] ....    of course one would have to submit this file to each slave first if they do not have access to the master s filesystem .",
    "note , however , that the slaves working directory is the user s home directory , not the current working directory on the master . in other words ,",
    "the file to be loaded must include a path unless it resides in the home directory anyway .",
    "@xmath3 tries to have the given points calculated as quickly as possible .",
    "therefore it distributes more ( less ) than @xmath29 points to faster ( slower ) cores by evaluating its internal timing statistics .",
    "once all points of the list are distributed , @xmath3 redistributes the unfinished points until the result for all points are available .",
    "it automatically decreases the patchsize according to the remaining list size , too .",
    "although due to the competition @xmath30 cores are not yet finished when @xmath3 returns , the time until all slaves are again ready is negligible .",
    "the identifier @xmath31 helps @xmath3 to distinguish between new and old data of multiply distributed points .      especially during long parallized calculations of many cpu - time - expensive points , link error handling plays an important role .",
    "if the link to one host , i.e.  one or more cores , is lost , @xmath3 redistributes the as yet uncalculated points to the remaining hosts , executes the equivalent @xmath21 call and prints a warning message .",
    "after @xmath3 has returned one might want to add the lost host by re - invoking @xmath32 .",
    "@xmath13 adds ( registers ) cores , i.e.  opens links to remote machines for subsequent distributed evaluation with @xmath3 .",
    "it is invoked in one of the following ways :    * @xmath33}$ ] adds one core on @xmath34 using a main license . * @xmath35}$ ] adds one core on @xmath34 using a sublicense . *",
    "@xmath36}$ ] ( @xmath37 , integer ) adds up to @xmath38 cores using the @xmath5 script ( described below ) using a ratio @xmath12 : 1 of sublicenses to main licenses ( cf .",
    "[ sect : sublicense ] ) .",
    "* @xmath36}$ ] ( @xmath39 , integer ) adds as many cores as there are main licenses using @xmath5 , but leaves at least @xmath40 main licenses for other users . *",
    "@xmath41}$ ] ( @xmath42 integer ) same as above , with @xmath38 for main licenses and @xmath43 for sublicenses .",
    "the last two invocations really make sense only for network licenses . for non - network licenses",
    ", it is silently assumed that the information taken from @xmath44 and @xmath45 ( in the master s session ) holds also for the remote cores .",
    "each link corresponds to one core on a remote machine .",
    "it is hence permissible to add the same host more than once , to account for its number of cores .",
    "the links are identified , apart from the hostname , by a unique integer link i d .",
    "this i d is also sent to each slave process as @xmath46 and can be used to e.g.  construct unique filenames .",
    "core additions are cumulative .",
    "links are released either through explicit removal with @xmath21 or by quitting the master s mathematica kernel .",
    "the @xmath5 script is part of the multicore package .",
    "it needs a @xmath6 file in which the admissible cores for distributed computing are listed .",
    "each line has the syntax    ....     hostname    [ # of cores ] ....    comment lines starting with a @xmath47 are allowed .",
    "cores are processed in sequential order , i.e.  the fastest machine should appear at the top of this list . the @xmath6 file is searched for in the following order :    * @xmath48 , * @xmath49 , * @xmath50 , * @xmath51 .",
    "@xmath5 invokes @xmath7 to determine the load on a remote machine .",
    "this works only if the remote machine is running an @xmath8 daemon .",
    "if not , the load is assumed to be zero , i.e.  all cores are taken .",
    "@xmath21 removes ( unregisters ) cores from the internal list , shuts down the corresponding remote kernels and closes the links .",
    "each core is identified by two quantities , the hostname and the link i d .",
    "calling @xmath21 is usually not necessary , as quitting the master s mathematica kernel automatically closes all links .",
    "* @xmath52}$ ] removes all cores matching @xmath34 and @xmath53 , where either may contain a pattern .",
    "for example , @xmath24}$ ] removes all links , and @xmath54}$ ] removes all links to @xmath55 . *",
    "@xmath56}$ ] is equivalent to @xmath57}$ ] .",
    "@xmath58 lists the currently registered cores .",
    "* @xmath59}$ ] lists all cores matching @xmath34 and @xmath53 , where either may contain a pattern .",
    "@xmath60}$ ] thus lists all cores . *",
    "@xmath61}$ ] is equivalent to @xmath62}$ ] .",
    "@xmath3 is the main function of the multicore package .",
    "it substitutes @xmath4 in serial calculations .",
    "* @xmath63}$ ] distributes the computation of @xmath64 for all items in @xmath65 to the cores previously registered with @xmath13 .",
    "the integer argument @xmath29 is optional ( default value : 5 ) and tells @xmath3 how many points on average should be sent to each core .",
    "as every set of results returned by a slave contains timing information , the master distributes points according to the slaves performance . until the master has gathered enough statistics about the slaves timings it sends exactly @xmath29 points to each core .",
    "the larger the computation time for a single point is , the smaller @xmath29 should be chosen",
    ". a smaller value may also be profitable if the participating cores have significant differences in speed .",
    "a @xmath29 of 1 achieves the best load - levelling but incurs the highest communication overhead .",
    "we have generally found the communication overhead to be negligible if the computation time for one patch is several seconds or more ( see also performance tests in section [ sect : performance ] ) .",
    "@xmath66 encodes the invocation of a remote mathematica kernel .",
    "it receives one arguments and one flag , the hostname and the type of license which shall be used while launching the kernel .",
    "if required one can define different invocation strings for different hosts .",
    "* @xmath67 : = { \\ensuremath{\\mathit{remotestring}}}}$ ] defines @xmath68 as the command for invoking a remote mathematica kernel on @xmath69 .",
    "options for the remote kernel are given in @xmath70 , which is presently restricted to @xmath71 for launching a subkernel .",
    "the default command is    .... ssh ( host ) ' exec /bin / sh -lc \\    \" test ` uname -s ` = darwin & & nice -19 mathkernel ( opt ) -mathlink \\                              || nice -19 math ( opt ) -mathlink \" ' ....    this is an @xmath10 command which starts a remote login shell that executes , with nice 19 , @xmath72 on macos and @xmath73 on other systems . starting",
    "a login shell is important as it sources the shell s initialization files , which may modify the path .",
    "if the mathematica kernel executable can not be started using this command because it is not on the path , we recommend adding the appropriate directories to the path on the remote system rather than modifying the @xmath66 definition .      with @xmath74 one",
    "can specify a mapping function which shall be applied on all remote hosts , i.e.  slave sessions , to the point patches they receive from the master .",
    "its default    .... remotemap[f _ , points _ ] : = map[f , points ] ....    is the usual @xmath4 function .",
    "this may be overwritten with an individual function which must have the same argument structure as @xmath75}$ ] .",
    "this feature could for example be used to leave a part of the parallelization to mathematica 7 using the @xmath76 function . in that case one of course would set the number of cores in @xmath6 to 1 for all hosts .",
    "@xmath77 contains the full path to the @xmath5 script , including ( if necessary ) any options .",
    "the full syntax of @xmath5 is :    ....     findcores [ -f rcfile ] [ -h ruptimehost ] ....    where @xmath78 specifies the explicit location of the @xmath79 file ( see sect .",
    "[ sect : addcore ] ) and @xmath80 specifies the host on which to invoke @xmath7 to find out the load of the machines listed in the @xmath79 file .",
    "the latter is necessary if running the master process on a machine not connected to the cluster , e.g.  a laptop .",
    "note : changing @xmath77 modifies subsequent invocations of @xmath13 only , i.e.  links once established are not changed by a different value of @xmath77 .",
    "@xmath81 specifies how verbose the master  slave communication is reported on screen .",
    "* @xmath82 sets the message level to @xmath38 .",
    "+ the default message level is 1 , which just reports the adding and removing of cores as well as link failures .",
    "@xmath46 is unique identifier for each slave session .",
    "* @xmath46 ( in the master s session ) is the i d of the last slave session spawned .",
    "this number should not be tampered with .",
    "* @xmath46 ( in the slave s session ) is a unique identifier of the session .",
    "@xmath31 is available in both the master and slave session . in the master session",
    "it counts the total number of calls to @xmath3 . in the slave session",
    "it identifies that certain call to @xmath3 which invoked the last computation on this slave .",
    "note that they do not have to be equivalent ( see sect .",
    "[ sect : concurrency ] ) .",
    "the integer @xmath12 is a global parameter in the master session which is set to 4 if the mathematica version is 7 or above , and 0 otherwise .",
    "only @xmath36}$ ] with @xmath83 makes use of it to decide how many sublicenses should be used launching a kernel before using another ( rare ) main license .",
    "setting @xmath12 manually only makes sense if one uses mathematica 7 and wants to optimize it to the mean ratio of unused sublicenses to unused main licenses which might be greater than 4 in some cluster networks .",
    "@xmath84 is available in the slave session only .",
    "this list contains the positions of the points in the original list which are to be evaluated by the slave .",
    "both @xmath31 and @xmath84 can e.g.  be used to construct unique filenames .",
    "for example , if a single evaluation is very costly in cpu time , one may want to store each result immediately after computation .",
    "this could be solved through a wrapper function    .... remotemap[f _ , points _ ] : =    mapthread[store[f ] , { points , $ listpositions } ]    store[f _ , dir_:\"results\"][x _ , i _ ] : = block [ { file = tofilename[dir , tostring[i ] ] } ,    if [ filetype[file ] = = = file ,      get[file ] ,    ( * else * )      if [ filetype[dir ] = = = none , createdirectory[dir ] ] ;      ( put [ # , file ] ; # ) & @ f[x ] ] ] ....    results for each point would be stored in @xmath85 , where @xmath38 is each point s index in the original list .",
    "in addition to @xmath84 one could use @xmath31 to generate unique filenames over multiple invokations of @xmath3 in the same master session .",
    "we tested the performance and scalability properties of multicore on both a homogeneous and inhomogeneous cluster of 25 cores for different evaluation times per point ( tpp ) and different patchsizes .",
    "as a testing function we used a simple pause directive    ....    f[p_][x _ ] : = ( pause[p ] ; x ) ....    and mapped it over 10000 resp .  1000 arbitrary points for different numbers of cores ranging from 0 ( local evaluation ) , 1 ( slave ) to 25 ( slaves ) and pausing times @xmath86 seconds .",
    "in case of the homogeneous cluster we assumed a constant ` evaluation ' time per point for each core . in the ideal case one would expect the total time to be inversely proportional to the number of cores .",
    "the three inverse plots on the left - hand side of figure [ fig : perf ] illustrate this ideal connection ( blue line ) and the deviation of the measured timings for different patchsizes .",
    "we took the average of ten independent runs for each point .",
    "as one can see , multicore s performance in a homogeneous cluster barely depends on the ( reasonable choosen ) patchsize .",
    "it shows an almost perfect scaling behaviour for evaluation timings per point of around 0.1 seconds or more . for smaller tpp s one would better choose a bigger patchsize .    to simulate an inhomogeneous cluster we linearly spread the tpp s from e.g.  1.0 to 4.0 seconds over the range of the 25 cores . on a subset of e.g.  14 cores we of course added the 14 fastest ones . due to",
    "the different evaluation timings the ideal curve is no longer a line . instead , in the ideal case the total time @xmath87 depends on the number and performance of the added cores : @xmath88 with @xmath89 being the tpp of core @xmath90 and @xmath91 the number of cores and @xmath92 the total number of points .",
    "the three plots on the right hand side of figure [ fig : perf ] show the testing results for different tpp s ( of the fastest core ) and for different patchsizes .",
    "again , the patchsize is not a crucial parameter . as before ,",
    "deviations occur for the small tpp = 0.01 sec .",
    "the scaling behaviour for large numbers of cores seems to be at most satisfactory since multicore s parallalizing takes about twice as long as the ideal case predicts .",
    "but if one compares the total timings of 25 unequal cores to the corresponding timings on the left hand side , one sees that it takes only about 10 cores from the homogeneous cluster to do the same job .",
    "therefore one principally has to consider the performance gain before joining much slower cores to one s cluster .    [",
    "cols=\"^,^ \" , ]",
    "the multicore package is available from @xmath93 .",
    "installation is as simple as unpacking the tar file .",
    "multicore requires mathematica versions 5 and up ( version 7 preferred ) .    to be able to load multicore regardless of the current directory",
    ", the multicore installation directory has to be added to mathematica s @xmath94 , for example by placing a statement like    ....     prependto[$path , \" /my / path / to / multicore \" ] ....    in @xmath95 , where @xmath96 is one of    * @xmath97 ( system - wide , linux ) , * @xmath98 ( user - specific , linux ) , * @xmath99 ( system - wide , macos ) , * @xmath100 ( user - specific , macos ) , * @xmath101 ( system - wide , cygwin ) , * @xmath102 ( user - specific , cygwin ) .",
    "the package has been tested under linux , macos , and windows / cygwin , both as master and as slave .",
    "the communication with remote mathematica kernels requires attention to a few details that may not be obvious :    * an @xmath103 daemon must be running on the remote machine and access not restricted by a firewall .",
    "on cygwin one has to start @xmath103 once with `` @xmath104 '' ( as administrator ) and on macos one has to open the ssh port in the firewall ( system preferences  sharing  remote login ) .",
    "* ssh access to remote machines must be possible without password authentication .",
    "this requires that a host key is generated with @xmath105 and the public part of it ( typically @xmath106 ) copied to @xmath107 . *",
    "if remote access other than by ssh is required , one needs to redefine the @xmath66 function , which encodes the command string used to execute remote mathematica kernels ( see sect .  [",
    "sect : remotemath ] ) .",
    "this can either be done in the master session before any @xmath13 invocations , or once and forever in @xmath108 .",
    "the multicore package provides a simple mechanism to distribute ( parallelize ) evaluations of a single functions over many points . after setting up the cores participating in the calculation with @xmath13 ,",
    "the single replacement of @xmath4 by @xmath3 suffices to distribute the calculation .",
    "@xmath3 is not limited to numerical evaluations , but can handle any type of mathematica expression .    from mathematica 7 on , parallelization on several cores of a single host",
    "is a built - in functionality .",
    "distributing calculations over more than one host is not straightforward , however , but can be done with the same ease using the @xmath109 package .",
    "the package is open source and is licensed under the gpl .",
    "it can be downloaded from @xmath93 and runs on mathematica versions 5 and up ( version 7 recommended ) .",
    "we thank a.  hoang for playing our guinea pig in the beta stage and apologize to the mpi users for using up too many mathematica licenses during testing ."
  ],
  "abstract_text": [
    "<S> we present a simple package for distributing evaluations of a mathematica function for many arguments on a cluster of computers . after setting up the hosts , </S>",
    "<S> the only change is to replace @xmath0}$ ] by @xmath1}$ ] . </S>"
  ]
}