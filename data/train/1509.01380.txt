{
  "article_text": [
    "this paper revisits the @xmath0-user gaussian broadcast channel ( bc ) ( * ? ? ?",
    "* section  5.5 ) in which a single transmitting node @xmath1 would like to send information to two receiving nodes @xmath2 and @xmath3 .",
    "the channel outputs corresponding to the input @xmath1 are @xmath4 where @xmath5 and @xmath6 are gaussian noise components , each with zero mean and with variances @xmath7 and @xmath8 respectively .",
    "this channel is a popular model for the downlink of a cellular system . when information is sent over @xmath9 uses of the channel , the peak power of the input codeword @xmath10 is constrained to satisfy @xmath11 with probability one for some admissible power @xmath12 .    assuming that @xmath13 ( so the channel is degraded in favor of the first receiver ) , the capacity region of this channel is well - known and is given by the set of all rate pairs @xmath14 satisfying @xmath15 for some @xmath16 $ ] , where @xmath17 and @xmath18 is the signal - to - noise ratio ( snr ) of the @xmath19-th user . the achievability part is proved using superposition coding , an idea that originates from cover  @xcite .",
    "the converse part was proved by bergmans @xcite using the entropy power inequality  @xcite .",
    "see ( * ? ? ?",
    "* section  5.5 ) for a modern exposition for the proof of the capacity region of the gaussian bc .",
    "one potential drawback of the existing outer bound is the fact that it is only a _ weak converse _ , proved using fano s inequality  ( * ? ? ?",
    "* section  2.1 ) .",
    "this implies that it only guarantees that for all rate pairs not belonging to the capacity region , the average error probability in decoding the transmitted messages is bounded away from zero as the blocklength of any code tends to infinity . in information theory , it is also important to establish _ strong converses _ as such definitive statements indicate that there is a sharp phase transition between rate pairs that are achievable and those that are not .",
    "a strong converse indicates that for all codes with rate pairs that are in the exterior of the capacity region , the error probability must necessarily tend to one .",
    "the contrapositive of this statement can roughly be stated as follows : all codes operated at a fixed rate pair that result in an error probability not exceeding @xmath20 as the blocklength grows , i.e. , @xmath21-reliable codes , must be such that the rate pair belongs to the capacity region .",
    "this is clearly a stronger statement than the weak converse , which is a special case where @xmath22 .",
    "the main contribution of the present work is a proof of the strong converse for the gaussian bc .",
    "that is , we prove that for the gaussian bc , its @xmath21-capacity region ( the set of all rate pairs for which there exists a sequence of codes whose asymptotic average error probability does not exceed @xmath21 ) is the region given in . in other words , if one operates at a pair of rates in the exterior of the capacity region , the average error probability must necessarily tend to one as the blocklength grows .",
    "thus , the boundary of the capacity region presents a sharp phase transition .",
    "our technique hinges on a fundamental inequality in probability theory known as the _ gaussian poincar inequality _",
    "@xcite ( also see @xcite ) , a particular instance of a logarithmic sobolev inequality .",
    "this inequality says that for any @xmath9 independent and identically distributed standard gaussian random variables @xmath23 and any differentiable mapping @xmath24 where @xmath25<\\infty$ ] and @xmath26<\\infty$ ] , @xmath27 \\le \\e\\left[\\|\\nabla f(z^n ) \\|^2\\right].\\ ] ] in shannon theory , this inequality has been used by polyanskiy and verd  ( * ? ? ?",
    "* theorem  8) to bound the relative entropy between the empirical distribution of a code for an additive white gaussian channel and the @xmath9-fold product of the capacity - achieving output distribution .",
    "however , it has not been explicitly used in other problems in shannon theory , for example , to establish strong converses .",
    "we find it useful in the context of the gaussian bc to bound the variance of a certain log - likelihood ratio ( information density ) .",
    "an auxiliary and important contribution of our work is the following .",
    "consider all optimal codes for the gaussian bc whose rate pairs approach a specific point on the boundary of the capacity region .",
    "we show that if the average error probability @xmath21 is non - vanishing , those rate pairs converge to the boundary at a rate of @xmath28 , where @xmath9 is the length of the code .",
    "the achievability part is a direct consequence of the central limit theorem , similarly to works on second - order asymptotics  @xcite and in particular , the gaussian multiple access channel with degraded message sets  @xcite .",
    "however , the converse part is more involved and indeed the strong converse must first be established .",
    "the estimates obtained from the various bounding techniques contained herein , including the gaussian poincar inequality , allows us to assert the @xmath28 speed of convergence .",
    "nailing down the exact speed of convergence and the corresponding constant would be a fruitful but ambitious avenue for further research .",
    "the blowing - up lemma  @xcite is the standard technique to establish the strong converse for some network information theory problems .",
    "these include the discrete memoryless degraded bc  ( * ? ? ?",
    "* theorem  16.3 ) ( * ? ? ? * theorem  4 ) , the lossless one - help - one source coding problem  ( * ? ? ?",
    "* theorem  16.4 ) , the discrete memoryless multiple access channel  @xcite , and the gelfand - pinsker channel  @xcite .",
    "see ( * ? ? ?",
    "* section  3.6 ) for an exposition of the use of the blowing - up lemma for establishing the strong converse for the discrete memoryless degraded bc , and for bounding the relative entropy between the empirical distribution of good channel codes with non - vanishing error probabilities and the @xmath9-fold product of the capacity - achieving output distribution .",
    "similarly to logarithmic sobolev inequalities , the blowing - up lemma is also a result in the study of concentration of measure  @xcite .",
    "however , its use in shannon theory is tailored to systems where the alphabets of the underlying systems are discrete ( finite ) .",
    "it is unclear , at least to the authors , how one can adapt the use of the blowing - up lemma , or more generally , transportation inequalities  @xcite , to establish strong converses for continuous - alphabet systems , such as the gaussian bc .      in the next subsection",
    ", the notation of this paper is stated .",
    "section  [ sectiondefinition ] contains the formulation of the gaussian bc and our main result .",
    "section  [ sectioninfospec ] states some useful preliminary results that are used to prove the main theorem .",
    "these include some information spectrum bounds as well as an important bound based on the gaussian poincar inequality .",
    "section  [ sectionproofmainresult ] presents the proof of our main result .",
    "proofs of auxiliary results are deferred to the appendices .",
    "we use @xmath29 to represent the probability of an event  @xmath30 , and we let @xmath31 be the characteristic function of @xmath30 . we use a capital letter  @xmath1 to denote an arbitrary random variable with alphabet @xmath32 , and use the small letter @xmath33 to denote a realization of  @xmath1",
    ". we use @xmath34 to denote a random tuple @xmath35 , where the components @xmath36 have the same alphabet  @xmath32 .",
    "the following notations are used for any arbitrary random variables  @xmath1 and  @xmath37 and any real - valued mapping @xmath38 whose domain includes @xmath32 .",
    "we let @xmath39 and @xmath40 denote the probability distribution of @xmath1 and the conditional probability distribution of @xmath37 given @xmath1 respectively .",
    "we let @xmath41 denote @xmath42 for any real - valued function  @xmath38 and any real constant @xmath43 .",
    "the expectation and the variance of  @xmath44 are denoted as @xmath45 $ ] and @xmath46\\triangleq \\e_{p_x}[(g(x)-\\e_{p_x}[g(x)])^2]$ ] respectively .",
    "we let @xmath47 denote the joint distribution of @xmath48 , i.e. , @xmath49 for all @xmath33 and @xmath50 . we let @xmath51 be the probability density function of a gaussian random variable denoted by  @xmath52 whose mean and variance are @xmath53 and @xmath54 respectively such that @xmath55 similarly , we let @xmath56 be the joint probability density function of  @xmath9 independent copies of  @xmath57 such that @xmath58 we will take all logarithms to base @xmath59 throughout this paper , so all information quantities have units of nats .",
    "the set of natural numbers , integers , real numbers and non - negative real numbers are denoted by @xmath60 , @xmath61 , @xmath62 and @xmath63 respectively . the euclidean norm of a tuple @xmath64 is denoted by @xmath65 .",
    "we consider the gaussian broadcast channel ( bc ) where a source  @xmath66 wants to transmit a message to two destinations denoted by  @xmath67 and @xmath68 respectively in  @xmath9 time slots ( channel uses ) as follows .",
    "source  @xmath66 chooses a message @xmath69 destined for  @xmath70 for each @xmath71 where @xmath72 denotes the size of message @xmath73 . for notational convenience ,",
    "we let @xmath74 . in each time slot",
    "@xmath75 , @xmath66 transmits @xmath76 based on  @xmath77 , and  @xmath70 receives @xmath78 for each @xmath79 where @xmath80 are  @xmath9 independent copies of the gaussian random variable whose mean and variance are @xmath81 and @xmath82 respectively . without loss of generality , we assume throughout the paper that @xmath83 after the  @xmath9 time slots ,  @xmath70 declares  @xmath84 to be the transmitted  @xmath73 based on @xmath85 .",
    "every codeword @xmath86 transmitted by node  @xmath66 should always satisfy the peak power constraint @xmath87 , where @xmath88 denotes the power available to  @xmath66 .",
    "the definitions of the bc and the codes defined on it are formally given below .",
    "[ defcode ] an @xmath89-code , where @xmath90 , consists of the following :    1 .",
    "a message set @xmath91 for each @xmath79 .",
    "message @xmath77 is uniform on @xmath92 , i.e. , @xmath93 for all @xmath94 ( which implies the independence between @xmath95 and @xmath96 ) .",
    "an encoding function @xmath97 where @xmath98 is the encoding function at  @xmath66 such that @xmath99 the _ codebook _ is defined to be @xmath100 .",
    "in addition , the peak power constraint @xmath101 should be satisfied for each @xmath94 .",
    "3 .   a decoding function @xmath102 for each @xmath79 where @xmath103 is the decoding function at  @xmath70 such that @xmath104 . for each @xmath79 and each @xmath105 ,",
    "the _ decoding region of @xmath106 _ is defined to be @xmath107    [ defbcchannel ] a gaussian broadcast channel ( bc ) is characterized by the probability density function @xmath108 satisfying @xmath109 where @xmath110 such that the following holds for any @xmath89-code : for each @xmath111 , @xmath112 for all @xmath113 , @xmath114 , @xmath115 and @xmath116 , where @xmath117 since @xmath118 does not depend on  @xmath75 by , the channel is stationary .    to simplify notation , we let @xmath119 for any random variables @xmath120 , and let @xmath121 for any random variables @xmath122 . for",
    "any @xmath89-code defined on the bc , let @xmath123 be the joint distribution induced by the code .",
    "we can factorize @xmath124 as follows : @xmath125 where ( a ) follows from definition  [ defcode ] that @xmath84 is a function of @xmath85 for each @xmath126 .",
    "[ deferrorprobability ] for an @xmath89-code defined on the bc , we define according to the _ average probability of decoding error _ as @xmath127 we call an @xmath89-code with average probability of decoding error no larger than @xmath21 an @xmath128-code . similarly , we define _ maximal probability of decoding error _ as @xmath129 we call an @xmath89-code with maximal probability of decoding error no larger than @xmath21 an @xmath130-code .",
    "[ defachievablerate ] let @xmath131 be a real number .",
    "a rate pair @xmath14 is _",
    "@xmath21-achievable _ for the bc if there exists a sequence of @xmath132-codes on the bc such that @xmath133 for each @xmath79 and @xmath134    [ defcapacity ] the @xmath21-capacity region of the bc , denoted by @xmath135 , is defined to be the set of @xmath21-achievable rate pairs .",
    "define @xmath136 for all @xmath137 , and let @xmath138}\\left\\{(r_1 , r_2)\\in \\mathbb{r}_+^2\\left| \\parbox[c]{1.2in}{$r_1\\le   \\mathrm{c}\\left(\\frac{\\alpha p}{\\sigma_1 ^ 2}\\right ) \\vspace{0.04 in } \\\\r_2\\le \\mathrm{c}\\left(\\frac{(1-\\alpha)p}{\\alpha p + \\sigma_2 ^ 2}\\right)$ } \\right.\\right\\}. \\label{defrbc}\\ ] ]      the following theorem is the main result of this paper .",
    "the proof of this theorem is deferred to section  [ sectionproofmainresult ] .",
    "[ thmmainresult ] for all @xmath139 @xmath140    it is well - known ( * ? ? ?",
    "* theorem 5.3 ) that @xmath141 therefore theorem  [ thmmainresult ] implies the strong converse for the gaussian bc , i.e. , that for every @xmath131 , @xmath142 before presenting the proof of theorem  [ thmmainresult ] , we would like to make the following two remarks .    for each @xmath139 and each @xmath143 $ ] ,",
    "define the _ @xmath144-sum capacity _ as @xmath145}\\left\\{\\lambda \\mathrm{c}\\left(\\frac{\\alpha p}{\\sigma_1 ^ 2}\\right ) + ( 1-\\lambda)\\mathrm{c}\\left(\\frac{(1-\\alpha)p}{\\alpha p + \\sigma_2 ^ 2}\\right)\\right\\}.\\ ] ] theorem  [ thmmainresult ] implies that for all @xmath146 , @xmath147 for all @xmath143 $ ] .",
    "in fact , our analysis gives us a useful estimate of the optimal @xmath144-sum rate at finite blocklengths . from the proof of theorem  [ thmmainresult ] , and specifically the inequalities and",
    ", we may assert the following for each @xmath148 , each @xmath143 $ ] and each sequence of @xmath149-codes : there exists a constant @xmath150 that depends on @xmath21 and @xmath88 ( but not  @xmath9 ) such that @xmath151 on the other hand , for each @xmath148 , each @xmath143 $ ] , it follows from the standard achievability proof involving superposition coding ( * ? ? ? * chapter  5 ) using i.i.d .",
    "gaussian codewords with average power @xmath152 and a generalization of shannon s non - asymptotic achievability bound  @xcite that there exists a sequence of @xmath149-codes which satisfies the following : there exists a @xmath153 that depends on @xmath21 and @xmath88 ( but not  @xmath9 ) such that @xmath154 if we define @xmath155 to be an optimal pair of message sizes that satisfies @xmath156 it then follows from and that @xmath157 for each @xmath148 and each @xmath143 $ ] .",
    "this result is not unexpected in view of recent works on second - order asymptotics for network information theory problems  @xcite .",
    "however , even establishing the strong converse is not trivial .",
    "moreover , characterizing the order of the most significant term in the @xmath158 notation in appears to be a formidable problem .",
    "[ remark1 * ] as described at the beginning of this subsection , theorem  [ thmmainresult ] implies the strong converse under the setting of _ union average error probability _ as defined in definition  [ deferrorprobability ] .",
    "our proof technique can also be used to prove the strong converse under the setting of _ separate maximal error probability _ as described below .",
    "fix any @xmath159 and any @xmath160 .",
    "if we follow the setting of the discrete memoryless degraded bc in ( * ? ?",
    "* section 1 ) and define the @xmath161-capacity region as the set of @xmath161-achievable rate pairs where @xmath162 denotes the maximal probability of decoding error for message  @xmath79 , then a slight modification of the proof steps for theorem  [ thmmainresult ] in section  [ sectionproofmainresult ] ( ignoring the step of codebook expurgation ) will imply that the @xmath161-capacity region is contained in @xmath163 , thus establishing the strong converse for the setting of separate maximal error probability .",
    "the following lemma is a modification of verd - han s non - asymptotic converse bound ( * ? ? ?",
    "* theorem 4 ) for obtaining a lower bound on the maximal probability of decoding error .",
    "note that the original verd - han bound pertains to the average probability of error , but the maximal probability of error is more useful for our context .",
    "[ lemmais ] fix an @xmath130-code with decoding regions @xmath164 and @xmath165 .",
    "let @xmath166 denote the probability distribution induced by the code .",
    "for each @xmath79 and each @xmath167 , fix a real number @xmath168 .",
    "then , we have for each @xmath169 @xmath170    fix a pair @xmath171 , a @xmath167 and a real number @xmath168 .",
    "we first consider the case for @xmath172 . in order to show for @xmath172",
    ", we consider the following chain of inequalities : @xmath173 where ( a ) follows from the union bound . in order to bound the first term in , we consider @xmath174 which implies that @xmath175 the second term in can be upper bounded as @xmath176 because the maximal probability of decoding error of the code is @xmath21 . combining , and , we obtain for @xmath172 . by symmetry , holds for @xmath177 .",
    "the following corollary is a direct consequence of lemma  [ lemmais ] with an appropriate choice of @xmath168 .",
    "[ corollaryis ] fix an @xmath139 and fix an @xmath130-code with decoding regions @xmath164 and @xmath165 .",
    "let @xmath166 denote the probability distribution induced by the code .",
    "fix a pair @xmath169 .",
    "then we have for each @xmath178 @xmath179-\\sqrt{\\frac{2}{1-\\varepsilon}\\var_{p_{y_i^n|w_\\mathcal{i } = w_\\mathcal{i}}}\\left[\\log\\frac{p_{y_i^n|w_i}(y_i^n|w_i)}{p_{y_i^n}(y_i^n)}\\right]}\\right ) } \\notag\\\\   & \\qquad +   \\mathbf{1}\\left\\{m_1^{(n)}m_2^{(n)}\\!\\!\\int_{\\mathcal{d}_i^{(n)}(w_i)}p_{y_i^n}(y_i^n ) p_{w_j|w_i , y_i^n}(w_j|w_i , y_i^n ) \\mathrm{d}y_i^n > n^2 \\right\\ } . \\label{corollarystatement }   \\end{aligned}\\ ] ]    for each @xmath79 and each @xmath178 , define @xmath180-\\sqrt{\\frac{2}{1-\\varepsilon}\\var_{p_{y_i^n|w_\\mathcal{i } = w_\\mathcal{i}}}\\left[\\log\\frac{p_{y_i^n|w_i}(y_i^n|w_i)}{p_{y_i^n}(y_i^n)}\\right]}\\ , .",
    "\\label{defgammai}\\ ] ] fix a pair @xmath169 . by chebyshev s inequality",
    ", we have for each @xmath178 @xmath181}{\\left(\\log m_i^{(n ) } - \\gamma_i(w_\\mathcal{i})-\\e_{p_{y_i^n|w_\\mathcal{i } = w_\\mathcal{i}}}\\left[\\log\\frac{p_{y_i^n|w_i}(y_i^n|w_i)}{p_{y_i^n}(y_i^n)}\\right]\\right)^2 } \\ , \\\\   & \\quad \\stackrel{\\eqref{defgammai}}{= } 1-\\frac{1-\\varepsilon}{2}\\ , .",
    "\\label{corollaryinproof }   \\end{aligned}\\ ] ] combining in lemma  [ lemmais ] , and , we obtain .",
    "the following proposition guarantees that for any @xmath130-code , the last term in equals one for only a small fraction of codewords .",
    "[ propositionis * ] fix an @xmath130-code with decoding regions @xmath164 and @xmath165 , and let @xmath166 denote the probability distribution induced by the code . for each @xmath182 , define @xmath183 then , we have for each @xmath182 @xmath184 in addition , if @xmath185 , then the following holds for each @xmath182 and each @xmath186 : @xmath187+\\sqrt{\\frac{2}{1-\\varepsilon}\\var_{p_{y_i^n|w_\\mathcal{i } = w_\\mathcal{i}}}\\left[\\log\\frac{p_{y_i^n|w_i}(y_i^n|w_i)}{p_{y_i^n}(y_i^n)}\\right ] } + 3\\log n\\ , .",
    "\\label{propositionis*st2}\\ ] ]    let @xmath166 denote the probability distribution induced by the @xmath130-code . fix a pair @xmath182 and consider the following chain of inequalities : @xmath188 \\\\ & \\stackrel{\\eqref{uniformdistribution}}{= } \\frac{1}{n}\\ , \\sum_{w_1\\in\\mathcal{w}_1}\\sum_{w_2\\in\\mathcal{w}_2}\\int_{\\mathcal{d}_i^{(n)}(w_i)}p_{y_i^n}(y_i^n ) p_{w_j|w_i , y_i^n}(w_j|w_i , y_i^n ) \\mathrm{d}y_i^n   \\\\ & = \\frac{1}{n}\\ , \\sum_{w_i\\in\\mathcal{w}_i}\\int_{\\mathcal{d}_i^{(n)}(w_i ) } p_{y_i^n}(y_i^n ) \\sum_{w_j\\in\\mathcal{w}_j } p_{w_j|w_i , y_i^n}(w_j|w_i , y_i^n ) \\mathrm{d}y_i^n   \\\\ & = \\frac{1}{n}\\ , \\sum_{w_i\\in\\mathcal{w}_i}\\int_{\\mathcal{d}_i^{(n)}(w_i ) } p_{y_i^n}(y_i^n ) \\mathrm{d}y_i^n   \\\\",
    "& \\stackrel{\\text{(c)}}{\\le } \\frac{1}{n}\\ , \\int_{\\mathbb{r}^n } p_{y_i^n}(y_i^n ) \\mathrm{d}y_i^n   \\\\ & = \\frac{1}{n } \\label{propositionisproof1}\\end{aligned}\\ ] ] where    1",
    ".   follows from markov s inequality .",
    "2 .   follows from markov s inequality .",
    "3 .   follows from that for each @xmath71 , @xmath189 consists of disjoint decoding regions .    using and ,",
    "we obtain .",
    "we will prove the second statement of the proposition in the rest of the proof . to this end",
    ", we first assume @xmath190 then , it follows from corollary  [ corollaryis ] and that for each @xmath186 , @xmath191-\\sqrt{\\frac{2}{1-\\varepsilon}\\var_{p_{y_i^n|w_\\mathcal{i } = w_\\mathcal{i}}}\\left[\\log\\frac{p_{y_i^n|w_i}(y_i^n|w_i)}{p_{y_i^n}(y_i^n)}\\right]}\\right)},\\end{aligned}\\ ] ] which implies from that @xmath192-\\sqrt{\\frac{2}{1-\\varepsilon}\\var_{p_{y_i^n|w_\\mathcal{i } = w_\\mathcal{i}}}\\left[\\log\\frac{p_{y_i^n|w_i}(y_i^n|w_i)}{p_{y_i^n}(y_i^n)}\\right]}\\right ) } \\le n^3,\\end{aligned}\\ ] ] which then implies .      in the proof of the main theorem",
    ", we need to use the following lemma to bound the variance term in , which is based on the gaussian poincar inequality .",
    "the proof of the following lemma is contained in ( * ? ? ?",
    "* section iii - c ) , and for the sake of completeness , we provide an self - contained proof in appendix  [ appendixlemmaupperbound ] .",
    "[ lemmaupperbound ] let @xmath9 be a natural number and @xmath54 be a positive number .",
    "let @xmath193 be a probability distribution defined on some finite set @xmath194 , and let @xmath195 be a mapping .",
    "in addition , define @xmath196 to be the distribution of @xmath9 independent copies of the zero - mean gaussian random variable with variance @xmath54 , i.e. , @xmath197 for all @xmath198 .",
    "suppose there exists a  @xmath199 such that @xmath200 then , we have @xmath201\\ , \\right ]   \\le 2\\left(n+\\frac{\\kappa}{\\sigma^2}\\right ) .",
    "\\label{lemmaupperboundst1}\\end{aligned}\\ ] ]    note that the upper bounds on @xmath202 and @xmath203 in proposition  [ propositionis * ] do not necessarily hold for all @xmath178 .",
    "therefore in the proof of the main theorem , we need to obtain other upper bounds on @xmath202 and @xmath203 for those @xmath178 which do not satisfy the assumption in proposition  [ propositionis * ] .",
    "consequently , we need the following upper bounds on @xmath202 and @xmath203 which hold for all @xmath178 . since the proof of the following upper bounds is standard ( by the use of fano s inequality  ( * ? ? ?",
    "* section  2.1 ) ) , it is relegated to appendix  [ appendixpropositionupperboundfano ] .",
    "[ propositionupperboundfano ] fix an @xmath130-code .",
    "then , we have for each @xmath79 @xmath204",
    "it suffices to prove @xmath205 for @xmath206 due to .",
    "fix an arbitrary @xmath207 and let @xmath14 be an @xmath21-achievable rate pair .",
    "then there exists a sequence of @xmath132-codes for the bc such that @xmath208 for each @xmath79 and @xmath209 by , there exists an @xmath210 such that for all sufficiently large  @xmath9 , @xmath211 by expurgating appropriate codewords from each @xmath132-code as suggested in ( * ? ? ?",
    "* problem 8.11 ) , we can obtain for each sufficiently large  @xmath9 an @xmath212-code such that @xmath213 for each @xmath79 .",
    "fix a sufficiently large @xmath214 and the corresponding @xmath212-code such that and hold . since the @xmath212-code is also an @xmath215-code by and definition  [ deferrorprobability ]",
    ", we will regard the @xmath212-code as the @xmath215-code in the rest of the proof .",
    "let @xmath166 denote the probability distribution induced by the @xmath215-code .",
    "for each @xmath182 , define @xmath216 using proposition  [ propositionis * ] and , we have for each @xmath182 and each @xmath186 @xmath217 and @xmath218+\\sqrt{\\frac{2}{1-\\bar \\varepsilon}\\var_{p_{y_i^n|w_\\mathcal{i } = w_\\mathcal{i}}}\\left[\\log\\frac{p_{y_i^n|w_i}(y_i^n|w_i)}{p_{y_i^n}(y_i^n)}\\right ] } + 3\\log n\\ , .    \\label{eqn2mainproof}\\ ] ] following and letting @xmath98 be the encoding function of the @xmath215-code ( cf .  definition  [ defcode ] ) , we consider the following chain of inequalities for each @xmath178 : @xmath219 \\notag\\\\ & = \\var_{p_{y_1^n|w_\\mathcal{i } = w_\\mathcal{i}}}\\left[\\log \\sum_{\\tilde w_2\\in \\mathcal{w}_2}\\frac{1}{\\bar m_2^{(n ) } } p_{y_1^n|w_1 , w_2}(y_1^n|w_1 , \\tilde w_2)\\right ] \\\\ & \\stackrel{\\text{(a)}}{= } \\var_{p_{y_1^n|x^n = f^{(n)}(w_\\mathcal{i})}}\\left[\\log \\sum_{\\tilde w_2\\in \\mathcal{w}_2}\\frac{1}{\\bar m_2^{(n ) } } p_{y_1^n|x^n}(y_1^n|f^{(n)}(w_1 , \\tilde w_2))\\right ] \\\\ & = \\var_{p_{y_1^n|x^n = f^{(n)}(w_\\mathcal{i})}}\\left[\\log \\sum_{\\tilde w_2\\in \\mathcal{w}_2}\\frac{1}{\\bar m_2^{(n ) } } p_{y_1^n|x^n}(y_1^n|f^{(n)}(w_\\mathcal{i})-(f^{(n)}(w_\\mathcal{i})-f^{(n)}(w_1 , \\tilde w_2)))\\right ] \\\\ & \\stackrel{\\text{(b)}}{= } \\int_{\\mathbb{r}^n } \\mathcal{n}(z^n;0 , \\sigma_1 ^ 2 ) \\left ( \\log \\sum_{\\tilde",
    "w_2\\in \\mathcal{w}_2}\\frac{1}{\\bar m_2^{(n ) } } \\mathcal{n}(z^n + f^{(n)}(w_\\mathcal{i } ) - f^{(n)}(w_1 , \\tilde w_2);0 , \\sigma_1 ^ 2 ) \\right)^2 \\mathrm{d}z^n \\nonumber\\\\ & \\qquad - \\left ( \\int_{\\mathbb{r}^n } \\mathcal{n}(z^n;0 , \\sigma_1 ^ 2 ) \\log \\sum_{\\tilde w_2\\in \\mathcal{w}_2}\\frac{1}{\\bar m_2^{(n ) } } \\mathcal{n}(z^n + f^{(n)}(w_\\mathcal{i})-f^{(n)}(w_1 , \\tilde w_2);0 , \\sigma_1 ^ 2 )   \\mathrm{d}z^n\\right)^2 \\label{eqn3mainproofstepb } \\\\   & \\stackrel{\\text{(c)}}{\\le } 2\\left(n+ \\frac{1}{\\sigma_1 ^ 2}\\max_{\\tilde w_2\\in\\mathcal{w}_2}\\|f^{(n)}(w_\\mathcal{i})-f^{(n)}(w_1 , \\tilde w_2)\\|^2\\right)\\\\   & \\stackrel{\\text{(d)}}{\\le } 2\\left(n+ \\frac{2}{\\sigma_1 ^ 2 } \\left(\\max_{\\tilde w_2\\in\\mathcal{w}_2 }   \\|f^{(n)}(w_\\mathcal{i})\\|^2 + \\|f^{(n)}(w_1 , \\tilde w_2)\\|^2 \\right)\\right)\\\\   & \\stackrel{\\eqref{powerconstraint}}{\\le } 2n\\left(1+\\frac{4p}{\\sigma_1 ^ 2}\\right ) ,   \\label{eqn3mainproof}\\end{aligned}\\ ] ] where    1",
    ".   follows from the fact that for each @xmath167 and each @xmath220 , @xmath221 2",
    ".   follows from letting @xmath222 and from definition  [ defbcchannel ] that for each @xmath223 and each @xmath220 , @xmath224 3",
    ".   follows from viewing the difference of two terms in as @xmath225\\right]\\ ] ] and from lemma  [ lemmaupperbound ] by letting @xmath226 and @xmath227 4 .",
    "follows from the fact that @xmath228 for any @xmath229 .",
    "following similar procedures for obtaining , we obtain for all @xmath167 @xmath230   \\notag\\\\ * & \\quad=   \\var_{p_{y_1^n|w_\\mathcal{i } = w_\\mathcal{i}}}\\left[\\log \\sum_{\\tilde w_\\mathcal{i}\\in \\mathcal{w}_\\mathcal{i}}\\frac{1}{\\bar m_1^{(n)}\\bar m_2^{(n ) } } p_{y_1^n|w_\\mathcal{i}}(y_1^n|\\tilde w_\\mathcal{i})\\right]\\\\ & \\quad\\le 2n\\left(1+\\frac{4p}{\\sigma_1 ^ 2}\\right),\\end{aligned}\\ ] ] which implies from that @xmath231 , \\var_{p_{y_1^n|w_\\mathcal{i } = w_\\mathcal{i}}}\\left[\\log p_{y_1^n}(y_1^n)\\right ]   \\right\\}\\le 2n\\left(1+\\frac{4p}{\\sigma_1 ^ 2}\\right ) .",
    "\\label{eqn3mainproof*}\\end{aligned}\\ ] ] since holds , it follows by symmetry that @xmath232 , \\var_{p_{y_2^n|w_\\mathcal{i } = w_\\mathcal{i}}}\\left[\\log p_{y_2^n}(y_2^n)\\right ]   \\right\\}\\le 2n\\left(1+\\frac{4p}{\\sigma_2 ^ 2}\\right ) .",
    "\\label{eqn3mainproof**}\\end{aligned}\\ ] ] for each @xmath182 and each @xmath186 , since @xmath233 \\notag\\\\ & \\quad \\le 2 ( \\var_{p_{y_i^n|w_\\mathcal{i } = w_\\mathcal{i}}}\\left[\\log p_{y_i^n|w_i}(y_i^n|w_i)\\right ]   + \\var_{p_{y_i^n|w_\\mathcal{i } = w_\\mathcal{i}}}\\left[\\log p_{y_i^n}(y_i^n)\\right ] ) \\\\ & \\quad \\stackrel{\\text{(a)}}{\\le } 8n\\left(1+\\frac{4p}{\\sigma_i^2}\\right)\\end{aligned}\\ ] ] where ( a ) follows from and , it follows from that @xmath218+\\sqrt{\\left(\\frac{4}{1-\\bar \\varepsilon}\\right)\\left(1+\\frac{4p}{\\sigma_i^2}\\right)n } + 3\\log n. \\label{eqn4mainproof}\\ ] ] consider the following chain of equalities for each @xmath182 : @xmath234+\\sqrt{\\left(\\frac{4}{1-\\bar \\varepsilon}\\right)\\left(1+\\frac{4p}{\\sigma_i^2}\\right)n } + 3\\log n\\right ) \\notag\\\\ & \\qquad + \\sum_{w_\\mathcal{i}\\in\\mathcal{w}_\\mathcal{i}\\setminus \\mathcal{a}_{(i , j)}}p_{w_\\mathcal{i}}(w_\\mathcal{i})\\log \\bar m_i^{(n)}\\\\ & =   \\e_{p_{w_\\mathcal{i},y_i^n}}\\left[\\log\\frac{p_{y_i^n|w_i}(y_i^n|w_i)}{p_{y_i^n}(y_i^n)}\\right]+\\sqrt{\\left(\\frac{4}{1-\\bar \\varepsilon}\\right)\\left(1+\\frac{4p}{\\sigma_i^2}\\right)n } + 3\\log n   + \\sum_{w_\\mathcal{i}\\in\\mathcal{w}_\\mathcal{i}\\setminus \\mathcal{a}_{(i ,",
    "j)}}p_{w_\\mathcal{i}}(w_\\mathcal{i})\\log \\bar m_i^{(n ) } \\notag\\\\ * & \\qquad - \\sum_{w_\\mathcal{i}\\in\\mathcal{w}_\\mathcal{i}\\setminus \\mathcal{a}_{(i , j)}}p_{w_\\mathcal{i}}(w_\\mathcal{i } ) \\left(\\e_{p_{y_i^n|w_\\mathcal{i } = w_\\mathcal{i}}}\\left[\\log\\frac{p_{y_i^n|w_i}(y_i^n|w_i)}{p_{y_i^n}(y_i^n)}\\right]+\\sqrt{\\left(\\frac{4}{1-\\bar \\varepsilon}\\right)\\left(1+\\frac{4p}{\\sigma_i^2}\\right)n } + 3\\log n\\right ) \\\\ & \\le \\e_{p_{w_\\mathcal{i},y_i^n}}\\left[\\log\\frac{p_{y_i^n|w_i}(y_i^n|w_i)}{p_{y_i^n}(y_i^n)}\\right]+\\sqrt{\\left(\\frac{4}{1-\\bar \\varepsilon}\\right)\\left(1+\\frac{4p}{\\sigma_i^2}\\right)n } + 3\\log n   + \\sum_{w_\\mathcal{i}\\in\\mathcal{w}_\\mathcal{i}\\setminus \\mathcal{a}_{(i , j)}}p_{w_\\mathcal{i}}(w_\\mathcal{i } ) \\log \\bar m_i^{(n ) } \\notag\\\\ * & \\qquad - \\sum_{w_\\mathcal{i}\\in\\mathcal{w}_\\mathcal{i}\\setminus \\mathcal{a}_{(i , j)}}p_{w_\\mathcal{i}}(w_\\mathcal{i } ) \\left ( \\e_{p_{y_i^n|w_\\mathcal{i } = w_\\mathcal{i}}}\\left[\\log\\frac{p_{y_i^n|w_i}(y_i^n|w_i)}{p_{y_i^n}(y_i^n)}\\right ]   \\right ) . \\label{eqn4mainproof*}\\end{aligned}\\ ] ] in order to obtain a lower bound for the @xmath235 $ ] term in , we consider the following two chains of inequalities for each @xmath169 , each @xmath178 and each @xmath236 : @xmath237 and @xmath238 following , we bound @xmath235 $ ] for each @xmath182 and each @xmath178 as below : @xmath239 \\notag\\\\ & \\quad \\stackrel{\\text{(a)}}{\\ge } -\\frac{n}{2}\\log ( 2\\pi e \\sigma_i^2 ) - \\log \\bar m_j^{(n ) } + \\e_{p_{y_i^n|w_\\mathcal{i } = w_\\mathcal{i}}}\\left[\\log p_{y_i^n|w_\\mathcal{i}}(y_i^n|w_\\mathcal{i})\\right ]   \\\\ &   \\quad=   -\\frac{n}{2}\\log ( 2\\pi e \\sigma_i^2 ) - \\log \\bar m_j^{(n ) } - \\e_{p_{y_i^n|w_\\mathcal{i } = w_\\mathcal{i}}}\\left[\\log \\frac{1}{p_{y_i^n|w_\\mathcal{i}}(y_i^n|w_\\mathcal{i})}\\right]\\\\ &   \\quad\\stackrel{\\eqref{pygivenw}}{= } -\\frac{n}{2}\\log ( 2\\pi e \\sigma_i^2 ) - \\log \\bar m_j^{(n ) } - \\e_{p_{y_i^n|x^n = f^{(n)}(w_\\mathcal{i})}}\\left[\\log \\frac{1}{p_{y_i^n|x^n}(y_i^n|f^{(n)}(w_\\mathcal{i}))}\\right]\\\\ & \\quad \\stackrel{\\eqref{eqnygivenx}}{= } -n\\log(2\\pi e \\sigma_i^2)- \\log \\bar m_j^{(n ) } \\label{eqn4mainproof****}\\end{aligned}\\ ] ] where ( a ) follows from and . combining and , we obtain for each @xmath182 @xmath240+\\sqrt{\\left(\\frac{4}{1-\\bar \\varepsilon}\\right)\\left(1+\\frac{4p}{\\sigma_i^2}\\right)n } + 3\\log n \\notag\\\\ * &",
    "\\qquad + \\sum_{w_\\mathcal{i}\\in\\mathcal{w}_\\mathcal{i}\\setminus \\mathcal{a}_{(i , j)}}p_{w_\\mathcal{i}}(w_\\mathcal{i})\\left(\\log \\bar m_1^{(n)}+\\log \\bar m_2^{(n)}+ n\\log(2\\pi e\\sigma_i^2)\\right).\\label{eqn5mainproof}\\end{aligned}\\ ] ]",
    "following , we consider for each @xmath171 @xmath241 where    1 .   follows from and that @xmath242 2",
    ".   follows from proposition  [ propositionupperboundfano ] .    defining @xmath243 and @xmath244 and recalling @xmath245 = i_{p_{w_i , y_i^n}}(w_i;y_i^n)\\ ] ] for each @xmath79",
    ", it follows from and that for each @xmath79 @xmath246 for each @xmath79 , since @xmath247 it follows from that @xmath248 following the procedures for obtaining the upper bound of @xmath249 and @xmath250 in the weak converse proof for the gaussian bc ( * ? ? ?",
    "* section 5.5.2 ) , we conclude that there exists an @xmath251 such that @xmath252 and @xmath253 combining , and , we obtain @xmath254 and @xmath255 where @xmath256 , @xmath257 , @xmath258 and @xmath259 are constants that do not depend on  @xmath9 by and , which implies from that @xmath260 and @xmath261 which then implies that @xmath262 since holds for any @xmath21-achievable @xmath14 , it follows from definition  [ defcapacity ] that @xmath205 .",
    "define @xmath263 for all @xmath264 .",
    "it follows from and that @xmath265 consider the following chain of inequalities : @xmath266\\ , \\right ]   \\notag\\\\ * & \\quad \\stackrel{\\eqref{lemmaupperboundst*}}{= } \\var_{p_{z^n}}\\left [ \\ , \\log \\e_{p_{x^n}}\\left [ p_{z^n}(z^n + x^n)|z^n\\right]\\ , \\right ] \\\\ & \\quad = \\int_{\\mathbb{r}^n } \\mathcal{n}(z^n;0 , \\sigma^2 ) \\left ( \\log \\e_{p_{x^n}}\\left [ \\mathcal{n}(z^n + x^n;0 , \\sigma^2)\\right ] \\right)^2 \\mathrm{d}z^n \\nonumber\\\\ * & \\qquad\\qquad - \\left ( \\int_{\\mathbb{r}^n } \\mathcal{n}(z^n;0 , \\sigma^2 ) \\log \\e_{p_{x^n}}\\left [ \\mathcal{n}(z^n + x^n;0 , \\sigma^2)\\right ]   \\mathrm{d}z^n\\right)^2 \\\\   & \\quad \\stackrel{\\eqref{normalrvvector}}{= } \\int_{\\mathbb{r}^n } \\mathcal{n}(z^n;0 , 1 ) \\left ( \\log \\e_{p_{x^n}}\\left [ \\mathcal{n}\\left(z^n + \\frac{x^n}{\\sqrt{\\sigma^2}}\\,;0 , 1\\right)\\right ] \\right)^2 \\mathrm{d}z^n \\notag \\\\ * & \\qquad \\qquad - \\left ( \\int_{\\mathbb{r}^n } \\mathcal{n}(z^n;0 , 1 ) \\log \\e_{p_{x^n}}\\left [ \\mathcal{n}\\left(z^n + \\frac{x^n}{\\sqrt{\\sigma^2}}\\ , ; 0 , 1\\right)\\right ]   \\mathrm{d}z^n\\right)^2 \\\\   & \\quad \\stackrel{\\text{(a)}}{\\le } \\int_{\\mathbb{r}^n } \\mathcal{n}(z^n;0 , 1 ) \\sum_{k=1}^n \\left(\\frac{\\e_{p_{x^n}}\\left[-\\left(z_k + \\frac{x_k}{\\sqrt{\\sigma^2}}\\right)\\mathcal{n}\\left(z^n + \\frac{x^n}{\\sqrt{\\sigma^2}};0 , 1\\right)\\right]}{\\e_{p_{x^n}}\\left [ \\mathcal{n}\\left(z^n + \\frac{x^n}{\\sqrt{\\sigma^2}};0 , 1\\right)\\right]}\\right)^2 \\mathrm{d}z^n \\\\ & \\quad = \\int_{\\mathbb{r}^n } \\mathcal{n}(z^n;0 , 1 ) \\sum_{k=1}^n \\left(-z_k -\\frac{\\e_{p_{x^n}}\\left[\\frac{x_k}{\\sqrt{\\sigma^2}}\\mathcal{n}\\left(z^n + \\frac{x^n}{\\sqrt{\\sigma^2}};0 , 1\\right)\\right]}{\\e_{p_{x^n}}\\left [ \\mathcal{n}\\left(z^n + \\frac{x^n}{\\sqrt{\\sigma^2}};0 , 1\\right)\\right]}\\right)^2 \\mathrm{d}z^n \\\\ & \\quad \\stackrel{\\text{(b)}}{\\le } 2\\int_{\\mathbb{r}^n } \\mathcal{n}(z^n;0 , 1 ) \\sum_{k=1}^n \\left ( z_k^2   + \\left(\\frac{\\e_{p_{x^n}}\\left[\\frac{x_k}{\\sqrt{\\sigma^2}}\\mathcal{n}\\left(z^n + \\frac{x^n}{\\sqrt{\\sigma^2}};0 , 1\\right)\\right]}{\\e_{p_{x^n}}\\left [ \\mathcal{n}\\left(z^n + \\frac{x^n}{\\sqrt{\\sigma^2}};0 , 1\\right)\\right]}\\right)^2\\right ) \\mathrm{d}z^n   \\\\ & \\quad \\stackrel{\\text{(c)}}{= } 2n + 2 \\int_{\\mathbb{r}^n } \\mathcal{n}(z^n;0 , 1 ) \\sum_{k=1}^n \\left(\\frac{\\e_{p_{x^n}}\\left[\\frac{x_k}{\\sqrt{\\sigma^2}}\\mathcal{n}\\left(z^n + \\frac{x^n}{\\sqrt{\\sigma^2}};0 , 1\\right)\\right]}{\\e_{p_{x^n}}\\left [ \\mathcal{n}\\left(z^n + \\frac{x^n}{\\sqrt{\\sigma^2}};0 , 1\\right)\\right]}\\right)^2 \\mathrm{d}z^n \\label{lemmaupperboundeq1}\\end{aligned}\\ ] ] where    1",
    ".   follows from the gaussian poincar inequality ( * ? ? ?",
    "* equation ( 2.16 ) ) , which states that for an @xmath9-dimensional tuple @xmath267 consisting of independent standard gaussian random variables and any differentiable mapping @xmath268 such that @xmath269<\\infty$ ] and @xmath270<\\infty$ ] where @xmath271 denotes the gradient of @xmath272 , @xmath273 \\le \\e_{p_{z^n}}\\left[\\| \\nabla f(z^n ) \\|^2\\right].\\ ] ] 2",
    ".   follows from the fact that @xmath274 for all real numbers  @xmath275 and  @xmath276 .",
    "3 .   follows from the fact that @xmath277=n$ ] when @xmath267 is distributed according to @xmath278 .",
    "following and defining for each @xmath198 the distribution @xmath279 as @xmath280 } , \\label{deftildepx}\\ ] ] we consider the following chain of inequalities for each @xmath198 : @xmath281}{\\e_{p_{x^n}}\\left [ \\mathcal{n}(z^n + \\frac{x^n}{\\sqrt{\\sigma^2 } } ; 0 , 1)\\right]}\\right)^2 \\notag\\\\ & \\quad \\stackrel{\\eqref{deftildepx}}{= } \\sum_{k=1}^n \\left(\\e_{\\tilde p_{x^n|z^n = z^n}}\\left[\\frac{x_k}{\\sqrt{\\sigma^2}}\\right]\\right)^2   \\\\ & \\quad \\le \\sum_{k=1}^n \\e_{\\tilde p_{x^n|z^n = z^n}}\\left[\\frac{x_k^2}{\\sigma^2}\\right ]   \\\\ &    \\quad = \\frac{1}{\\sigma^2}\\e_{\\tilde p_{x^n|z^n = z^n}}\\left[\\|x^n\\|^2\\right ]   \\\\ & \\quad \\stackrel{\\text{(a)}}{\\le } \\frac{\\kappa}{\\sigma^2 } \\label{lemmaupperboundeq2}\\end{aligned}\\ ] ] where ( a ) follows from and . combining and , we obtain .",
    "let @xmath166 denote the probability distribution induced by the @xmath130-code . for each @xmath169",
    ", consider the following chain of inequalities : @xmath282 where    1",
    ".   follows from that @xmath73 is uniform on @xmath283 .",
    "2 .   follows from fano s inequality .",
    "3 .   follows from that @xmath95 and @xmath96 are independent .",
    "4 .   follows from that @xmath36 is a function of @xmath284 .",
    "5 .   follows from that @xmath285 forms a markov chain when they are distributed according to  @xmath286 .",
    "following and defining @xmath287 for each @xmath126 , we consider the following chain of inequalities for each @xmath79 : @xmath288\\right)- \\frac{1}{2}\\log ( 2\\pi e \\sigma_i^2 ) \\right ) \\\\ & \\quad \\stackrel{\\text{(c)}}{= } \\sum_{k=1}^n \\frac{1}{2}\\log\\left(1+\\frac{\\var_{p_{x_k}}[x_k]}{\\sigma_i^2}\\right)\\\\ & \\quad \\le \\sum_{k=1}^n \\frac{1}{2}\\log\\left(1+\\frac{\\e_{p_{x_k}}[x_k^2]}{\\sigma_i^2}\\right)\\\\ & \\quad \\stackrel{\\text{(d)}}{\\le }   \\frac{n}{2}\\log\\left(1+\\frac{\\e_{p_{x^n}}[\\frac{1}{n}\\sum_{k=1}^nx_k^2]}{\\sigma_i^2}\\right)\\\\ & \\quad \\stackrel{\\eqref{powerconstraint}}{\\le }    \\frac{n}{2}\\log\\left(1+\\frac{p}{\\sigma_i^2}\\right),\\label{eqn7appendix }   \\end{aligned}\\ ] ] where    1",
    ".   follows from and that @xmath289 and @xmath290 have the same distribution when @xmath289 is distributed according to @xmath291 and @xmath292 is distributed according to @xmath293 .",
    "2 .   follows from the fact that the differential entropy of a random variable @xmath1 is always upper bounded by that of the zero - mean gaussian random variable whose variance is equal to @xmath294 $ ] .",
    "3 .   follows from that @xmath295=\\var_{p_{x_{k}}}\\left[x_{i , k}\\right ] + \\sigma_i^2 $ ] .",
    "4 .   follows from jensen s inequality .",
    "the authors are supported by an nus grant ( r-263 - 000-a98 - 750/133 ) , an nus young investigator award ( r-263 - 000-b37 - 133 ) , and a ministry of education ( moe ) tier 2 grant ( r-263 - 000-b61 - 112 ) .",
    "the authors would like to thank prof .",
    "shun watanabe for pointing out a possible extension of our result , which leads to remark  [ remark1 * ] .",
    "m.  raginsky and i.  sason , `` concentration of measure inequalities in information theory , communications and coding , '' _ foundations and trends@xmath297@xmath298 in communications and information theory _ ,",
    "10 , no . 12 , 2013 .",
    "v.  y.  f. tan , `` asymptotic estimates in information theory with non - vanishing error probabilities , '' _ foundations and trends@xmath297@xmath298 in communications and information theory _ , vol .  11 , no . 12 , 2014 .",
    "r.  ahlswede , p.  gcs , and j.  krner , `` bounds on conditional probabilities with applications in multi - user communication , '' _ z. wahrscheinlichkeitstheorie verw .",
    "gebiete _ , vol .",
    "34 , no .  3 , pp .",
    "157177 , 1976 .",
    "h.  tyagi and p.  narayan , `` the gelfand - pinsker channel : strong converse and upper bound for the reliability function , '' in _ proc . of the ieee intl .",
    "symp . on inf .",
    "theory _ , seoul , korea , jun .",
    "2009 , pp .",
    "1954  1957 ."
  ],
  "abstract_text": [
    "<S> we prove that @xmath0-user gaussian broadcast channels admit the strong converse . </S>",
    "<S> this implies that every sequence of block codes with an asymptotic average error probability smaller than one is such that all the limit points of the sequence of rate pairs must lie within the capacity region derived by cover and bergmans . </S>",
    "<S> the main mathematical tool required for our analysis is a logarithmic sobolev inequality known as the gaussian poincar inequality .    </S>",
    "<S> gaussian broadcast channel , strong converse , information spectrum , gaussian poincar inequality , logarithmic sobolev inequality </S>"
  ]
}