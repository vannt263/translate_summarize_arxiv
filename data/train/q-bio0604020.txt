{
  "article_text": [
    "analysis of electroencephalogram time series , though perhaps not conclusive yet , suggest that some of the brain high level tasks might require chaotic activity and itinerancy @xcite . as a matter of fact , following the observation of constructive chaos in many natural systems @xcite , it has been reported some evidence that chaos may , for example , enhance sensitivity by inducing a critical state of synchronization during expectation and attention hansel2 , and perhaps provide an efficient means to discriminate different ( e.g. ) olfactory stimuli @xcite .",
    "consequently , there has recently been some effort in incorporating constructive chaos in neural network modeling @xcite .",
    "concluding on the significance of chaos in neurobiological systems is still an open issue @xcite , however .    as a new effort towards better understanding this problem , in the present paper we present , and study",
    "both analytically and numerically , a _ neural automaton _ which exhibits chaotic behavior .",
    "more specifically , it shows sort of _ dynamic _ associative memory , consisting of chaotic hopping between the stored memories , which mimics the brain states of attention and searching . the model is a neurobiologically inspired cellular automaton , in which dynamics concerns the whole , which is simultaneously updated instead of sequentially updating a small neighborhood at each time step . this automaton ( or _",
    "little dynamics _ ) strategy has already revealed efficient in modeling several aspects of associative memory @xcite .",
    "interesting enough , concerning this property , neural automata often exhibit more interesting behavior than their hopfield  like , sequentially  updated counterparts , in spite of the fact that any two successive states are stronger correlated in the sequential case .",
    "therefore , we extend here to cellular automata our recent study of the effects of synaptic noise  on the stability of attractors in hopfield  like networks @xcite .",
    "we demonstrate that , in our automaton , a certain type of synaptic fluctuations determine an interesting retrieval process .",
    "the model synaptic fluctuations are coupled to the presynaptic activity in such a way that _",
    "synaptic depression _ occurs .",
    "this phenomenon , which has been observed in actual systems , consists in a lowering of the neurotransmitters release after a period of intense presynaptic activity @xcite .",
    "our model fluctuations happen to destabilize the memory attractors and are shown to induce , eventually , regular and even chaotic dynamics between the stored patterns .",
    "confirming expectations mentioned above , we also show that our model behavior implies a high adaptability to a changing environment , which seems to be one of the nature strategies for efficient computation @xcite .",
    "let a set of @xmath0 binary neurons , @xmath1 connected by synapses of intensity:@xmath2here , @xmath3 stands for a random variable , and @xmath4 is an average weight .",
    "the specific choice for the latter is not essential here but , for simplicity and reference purposes , we shall consider a hebbian _ learning rule _ @xcite .",
    "that is , we shall assume in the following that synapses _ store _ a set of @xmath5 binary patterns , @xmath6 @xmath7 according to the prescription , @xmath8    the set @xmath9 of random variables is intended to model some reported fluctuations of the synaptic weights . to be more specific , the multiplicative noise in ( [ w ] ) , which was recently used to implement a variation of the hopfield model @xcite , may have different competing causes in practice , ranging from short  length stochasticities , e.g. , those associated with the opening and closing of the vesicles and with local variations in the neurotransmitters concentration , to time lags in the incoming long  length signals @xcite .",
    "these effects will result in short ",
    "time , i.e. , relatively fast microscopic noise . as a matter of fact",
    ", the typical synaptic variability is reported to occur on a time scale which is small compared with the characteristic system relaxation @xcite .",
    "therefore , as far as @xmath10 corresponds to microscopic fast noise , neurons will evolve as in presence of a steady distribution , say @xmath11 it follows that such noise will modify the _ local fields _",
    ", @xmath12 i.e. , the total presynaptic current which arrives to the postsynaptic neuron @xmath13 which one may assume to be given in practice by@xmath14this , which is a main feature of our automaton , amounts to assume that each neuron endures an effective field which is , in fact , the average contribution of all possible different realizations of the actual field bibi .",
    "this situation has been formally discussed in detail in refs.torres2,marro .",
    "it may be noticed that , consistently with the choice of a binary , @xmath15 code for the neurons activity , we are assuming zero thresholds , @xmath16 @xmath17 in the following ; this is relevant when comparing this work with some related one , as discussed below .",
    "next , one needs to model the noise steady distribution .",
    "motivated by some recent neurobiological findings , we would like this to mimic short  term _",
    "synaptic depression _",
    "this refers to the observation that the synaptic weight decreases under repeated presynaptic activation .",
    "the question is how such mechanism may affect the automata ( and , in turn , actual systems ) dynamics . for simplicity",
    ", we shall assume factorization of the noise distribution , i.e. , we assume the simplest case @xmath18 and @xmath19 \\mathrm{\\ \\ } % \\delta ( x_{j}-1 ) .",
    "\\label{bimod}\\]]here , @xmath20 stands for the overlap vector of components @xmath21 and @xmath22 is an increasing function of @xmath23 to be determined .",
    "the choice ( [ bimod ] ) amounts to assume that , with probability @xmath24 i.e. , more likely the larger @xmath25 is , which implies a larger net current arriving to the postsynaptic neurons , the synaptic weight will be depressed by a factor @xmath26 otherwise , the weight is given the chosen average value , see equation ( w ) .",
    "interesting enough , ( [ bimod ] ) clearly induces some non  trivial correlations between synaptic noise and neural activity .",
    "this is an additional bonus of our choice , as it conforms the general expectation that processing of information in a network will depend on the noise affecting the communication lines and vice versa @xcite .",
    "looking for an increasing function of the total presynaptic current with proper normalization , a simple choice for the probability in ( [ bimod ] ) is @xmath27 ^{2},$ ] where @xmath28 is the load parameter or network capacity .",
    "it then follows after some simple algebra that the resulting fields are@xmath29 ^{2}\\right\\ } \\sum_{\\nu } \\xi _ { i}^{\\nu } m^{\\nu } \\left ( \\mathbf{s}\\right ) ,   \\label{lfaprox}\\]]where @xmath30 notice that this precisely reduces for @xmath31 to the local fields in the hopfield model in which the synaptic weights do not fluctuate but are constant in time @xcite .",
    "time evolution is due to competition between these fields , which contain the effects of synaptic _ noise , _ and some additional natural stochasticity of the neural activity . in accordance with a familiar hypothesis",
    ", we shall assume this stochasticity controlled by a temperature  parameter , @xmath32 which characterizes an underlying thermal bath  @xcite .",
    "consequently , evolution is by the stochastic equation @xmath33 where the probability per unit time of a transition is@xmath34for simplicity and concreteness , we take @xmath35 , $ ] where @xmath36 and @xmath37 independent of @xmath38 , which is a good approximation for a sufficiently large network ( technically , this is an exact property in the _ thermodynamic limit _",
    "@xmath39 ) .",
    "the function @xmath40 is arbitrary except that , in order to obtain well defined limits , we require that @xmath41 @xmath42 and @xmath43 which holds for a normalized exponential function @xcite . then , consistent with the condition @xmath44 we",
    "take@xmath45\\left [ 1+\\psi \\left ( 2\\beta _ { i}s_{i}^{\\prime } \\right ) \\right ] ^{-1}.   \\label{tnorm}\\ ] ]",
    "it is obvious that the above may be adapted to cover other , more involved cases @xcite , but this is enough to our purposes here . in fact , monte carlo simulations reveal some new interesting facts as compared with the case of sequential updating @xcite . to begin with",
    ", figure figure1 illustrates a much varied landscape , namely , the occurrence of fixed points , cycles , regular and irregular hopping between the attractors .",
    "this may also be obtained analytically in the mean  field approximation @xmath46 @xmath47 @xcite .",
    "we then obtain for @xmath48 a discrete map which describes time evolution of the overlap @xmath49 as@xmath50\\}.   \\label{mfdeo1p}\\]]as one varies here the temperature  @xmath51 and the depressing parameter @xmath52 it follows a varying situation in perfect agreement with the monte carlo simulations , as one should have expected for a fully connected network . in particular , figure [ figure2 ] shows the occurrence of chaos in a case in which thermal fluctuations are small compared to the synaptic noise .",
    "that is , the lyapunov exponent , @xmath53 corresponding to the dynamic mean  field map shows different chaotic windows , i.e. , @xmath54 as one varies @xmath55 for a fixed @xmath56 as illustrated also in figure [ figure2 ] , dynamics is stable for @xmath57 , i.e. , in the absence of any synaptic noise , and the only solutions then correspond to the ones that characterize the familiar hopfield case with parallel updating . as @xmath55 is increased , however , the system tends to become unstable , and transitions between @xmath58 and @xmath59 then eventually occur that are fully chaotic .",
    "there is also chaotic hopping between the attractors when the system stores several patterns , i.e. , for @xmath60 in this case , we obtain the more complex , multidimensional map : @xmath61 \\quad \\forall \\nu=1,\\ldots m.\\ ] ] this is to be numerically iterated .",
    "the simplest order parameter to monitor this is:@xmath62this is shown in figure [ figure3 ] as a function of @xmath63 the graph clearly illustrates a region of irregular behavior which has a width @xmath64 defined as the distance , in terms of @xmath52 from the first bifurcation to the last one .",
    "interesting enough , we find that the width of this region is practically independent of the number of patterns ; that is , we find that @xmath65 as @xmath5 is varied within the range @xmath66 .$ ] this suggests that the chaotic behavior which occurs for depressing fast synaptic fluctuations , i.e. , for any @xmath67 does not critically depend on the automaton capacity but the model properties are rather robust and perhaps independent of the number of stored patterns within a wide range .",
    "one may expect , however , that some of the interesting model properties will tend to wash out as the load parameter increases macroscopically , i.e. , as @xmath68",
    "motivated by the fact that analysis of brain waves provides some indication that the chaos  theory concept of _ strange attractor _ may be relevant to describe some of the neural activity , we presented here a neurobiologically  inspired model which exhibits chaotic behavior .",
    "the model is a ( microscopic ) cellular automaton with only two parameters , @xmath51 and @xmath69 which control the thermal stochasticity of the neural activity and the depressing effect of ( coupled ) fast synaptic fluctuations , respectively .",
    "our system reduces to the hopfield case with little dynamics ( parallel updating ) only for @xmath70    our main result is that , as described in detail in the previous section , the automaton eventually exhibits chaotic behavior for @xmath71 but not for @xmath72 nor in the case of sequential , single  neuron updating irrespective of the value of @xmath55 @xcite .",
    "it also follows from our analysis above that further study of this system and related automata is needed in order to determine other conditions for chaotic hopping .",
    "for example , one would like to know if synchronization of all variables is required , and the precise mechanism for moving from regular to irregular behavior as @xmath55 is slightly modified .",
    "we are pursuing the present effort along this line @xcite , and present some related preliminary conclusions below .",
    "this is not the first time in which chaos is reported to occur during the retrieval process in attractor neural networks ; see , for instance , wang , bolle , domin2,poon , caro2,mai , kata .",
    "one may say , however , that we provide in this paper a more general and microscopic setting than before and , in fact , the onset of chaos here could not be phenomenologically predicted .",
    "that is , the same microscopic mechanism , namely ( [ w ] ) and ( [ bimod ] ) , does not imply chaotic behavior if updating is by a sequential single ",
    "variable process @xcite .",
    "another possible comparison is by noticing that , in any case , whether one proceeds more or less phenomenologically , the result is a map @xmath73 we obtained the gain function @xmath74 after coarse graining of ( [ lfaprox])([tnorm ] ) , and the monte carlo simulations fitting the map behavior just involve neurons subject to the local fields ( [ heff ] ) , so that we are only left in the two cases with the noise parameter @xmath55 to be tuned . in contrast , some related works , in order to deepen more directly on the possible origin of chaos , use the gain function itself as a parameter .",
    "it is also remarkable that , e.g. , in @xcite and some related work @xcite , the gain function is phenomenologically controlled by tuning the neuron threshold for firing , @xmath75 the threshold function thus becomes a relevant parameter , and it ensues that any meaningful chaos in this context requires non  zero threshold .",
    "this is because , in these cases , the local fields and , consequently , the overlaps , are lineal , which forces one to induce chaos by other means .",
    "interesting enough , our gain function in ( [ mfdeo1p ] ) has either a sigmoid shape or an oscillating one , as illustrated for @xmath76 in figure [ figure4 ] .",
    "only the latter case allows for hopping between the attractors and , eventually , for chaotic behavior .",
    "finally , we demonstrate an interesting property of our automaton during retrieval .",
    "this is the fact that , in the chaotic regime , the system is extremely susceptible to external influences .",
    "a rather stringent test of this is its behavior concerning mixture or _ spin ",
    "glass _ steady states , which are unsuited in relation with associative memory . even though these states may occur at low @xmath32 this system unlike other cases easily escapes from them under a very small external stimulus .",
    "this is illustrated in figure [ figure5 ] which also demonstrates a general feature , namely , some strong correlation between chaos and a vivid response to the environment .",
    "this nicely conforms expectations mentioned above , in the introduction of this paper , that chaotic itinerancy might be a rather general strategy of nature .",
    "we acknowledge with thanks very useful discussions with david r.c .",
    "domnguez , pedro l. garrido , sabine hilfiker and hilbert j. kappen , and financial support from meyc and feder , project no .",
    "fis2005 - 00791 .",
    "amit , d.  j. ( 1989 ) . .",
    "cambridge university press .",
    "ashwin , p. and timme , m. ( 2005 ) . when instability makes sense .",
    ", 56:3637 .",
    "barrie , j.  m. , freeman , w.  j. , and lenhart , m. ( 1996 ) .",
    "modulation by discriminative training of spatial patterns of gamma eeg amplitude and phase in neocortex of rabbits .",
    ", 76:520539 .",
    "bibitchkov , d. , herrmann , j.  m. , and geisel , t. ( 2002 ) . pattern storage and processing in attractor networks with short - time synaptic dynamics . , 13:115129 .",
    "bolle , d. and vink , b. ( 1996 ) . on the dynamics of analogue neurons with nonsigmoidal gain functions .",
    ", 223:293308 .",
    "caroppo , d. , mannarelli , m. , nardulli , g. , and stramaglia , s. ( 1999 ) .",
    "chaos in neural networks with a nonmonotonic transfer function .",
    ", 60:21862192 .",
    "cortes , j.  m. , garrido , p.  l. , marro , j. , and torres , j.  j. ( 2004 ) .",
    "switching between memories in neural automata with synaptic noise . , 58 - 60:6771 .",
    "cortes , j.  m. , torres , j.  j. , marro , j. , garrido , p.  l. , and kappen , h.  j. ( 2006 ) .",
    "effects of fast presynaptic noise in attractor neural networks . , 13:614633 .",
    "dominguez , r. r.  c. and theumann , w. ( 1997 ) . generalization and chaos in a layered neural network .",
    ", 30:14031414 .",
    "faure , p. and korn , h. ( 2001 ) .",
    "is there chaos in the brain ?",
    "i. concepts of nonlinear dynamics and methods of investigation . , 324:773793 .",
    "franks , k.  m. , stevens , c.  f. , and sejnowski , t.  j. ( 2003 ) .",
    "independent sources of quantal variability at single glutamatergic synapses .",
    ", 23:31863195 .",
    "freeman , w.  j. ( 2003 ) .",
    "evidence from human scalp electroencephalograms of global chaotic itinerancy .",
    ", 13:10671077 .",
    "ganguly , n. , das , a. , maji , p. , sikdar , b.  k. , and chaudhuri , p.  p. ( 2003 ) . evolving cellular automata based associative memory for pattern recognition . in monien , b. , prasanna ,",
    "v. , and vajapeyam , s. , editors , _ high performance computing - hipc 2001 : 8th international conference _ ,",
    "volume 2228 , pages 115124 .",
    "springer - verlag .",
    "hansel , d. and sompolinsky , h. ( 1996 ) .",
    "chaos and synchrony in a model of a hypercolumn in visual cortex .",
    ", 3:734 .",
    "kaneko , k. and tsuda , i. ( 2001 ) . .",
    "springer .",
    "katayama , k. , sakata , y. , and horiguchi , t. ( 2003 ) .",
    "layered neural networks with non - monotonic transfer functions . , 317:270298 .",
    "kiel , l.  d. and elliot , e. , editors ( 1996 ) . .",
    "the university of michigan press .",
    "korn , h. and faure , p. ( 2003 ) .",
    "is there chaos in the brain ?",
    "ii . experimental evidence and related models .",
    ", 326:787840 .",
    "lu , q. , shen , g. , and yu , r. ( 2003 ) . a chaotic approach to maintain the population diversity of genetic algorithm in network training .",
    ", 27:363371 .",
    "mainieri , m. and jr . , r.  e. ( 2002 ) .",
    "retrieval and chaos in extremely diluted non - monotonic neural networks .",
    ", 311:581589 .",
    "marro , j. and dickman , r. ( 1999 ) . .",
    "cambridge university press .",
    "pantic , l. , torres , j.  j. , kappen , h.  j. , and gielen , s. c. a.  m. ( 2002 ) .",
    "associative memory with dynamic synapses .",
    ", 14:29032923 .",
    "poon , c.  s. and barahona , m. ( 2001 ) .",
    "titration of chaos with added noise .",
    ", 98:71077112 .",
    "rabinovich , m.  i. and abarbanel , h. d.  i. ( 1998 ) .",
    "the role of chaos in neural systems .",
    ", 87:514 .",
    "schweighofer , n. , doya , k. , fukai , h. , chiron , j.  v. , furukawa , t. , and kawato , m. ( 2004 ) .",
    "chaos may enhance information transmission in the inferior olive .",
    ", 101:46554660 .",
    "strogatz , s. ( 2003 ) . .",
    "hyperion , n.y .",
    "torres , j.  j. , garrido , p.  l. , and marro , j. ( 1997 ) .",
    "neural networks with fast time - variation of synapses . , 30:78017816 .",
    "tsodyks , m.  v. , pawelzik , k. , and markram , h. ( 1998 ) .",
    "neural networks with dynamic synapses . , 10:821835 .",
    "tsuda , i. ( 2001 ) . toward an interpretation of dynamic neural activity in terms of chaotic dynamical systems .",
    ", 24:793810 .",
    "wang , l. , pichler , e.  e. , and ross , j. ( 1990 ) .",
    "oscillations and chaos in neural networks : an exactly solvable model . , 87:94679471 .",
    "zador , a. ( 1998 ) .",
    "impact of synaptic unreliability on the information transmitted by spiking neurons .",
    ", 79:12191229 .",
    "* figure 1 : * monte carlo time  evolution of the overlap between the automaton current state and the given stored pattern for @xmath77 @xmath78@xmath79 neurons , @xmath80 and different values of @xmath52 as indicated .",
    "this illustrates , from top to bottom , the fixed point solution in the absence of any synaptic noise , i.e. , @xmath81 , a cyclic behavior , the onset of irregular periodic behavior , and fully irregular and regular jumping between the two attractors corresponding , respectively , to the given pattern , @xmath82 and its _ anti  pattern _",
    "@xmath59 the only possibilities in this case with @xmath83 +   + * figure 2 : * bifurcation diagram and associated lyapunov exponent demonstrating chaotic activity for some ( but not all ) values of the depressing coefficient @xmath63 the upper graph shows , for @xmath77 the steady overlap between the current state and the given pattern as a function of @xmath63 this is from monte carlo simulations of a network with @xmath84 neurons .",
    "the bottom graph depicts the corresponding lyapunov exponent , @xmath85 , as obtained from the map ( [ mfdeo1p ] ) .",
    "this confirms the existence of _ chaotic windows , _ in which @xmath86 .",
    "the _ temperature _ parameter is set @xmath87 in both cases ; this is low enough so that the effect of thermal fluctuations is negligible compared to that of synaptic noise .",
    "+   + * figure 3 : * the function @xmath88 as defined in the main text , obtained from monte carlo simulations at @xmath89  for @xmath90  neurons and @xmath91  stored patterns generated at random .",
    "a region of irregular behavior which extends for @xmath92  as indicated , is depicted .",
    "the insets show the time evolution of four out of the 20 overlaps within the irregular region , namely , for @xmath93 +   + * figure 4 : * the gain function in ( [ mfdeo1p ] ) versus @xmath94 for @xmath95 and different values of @xmath55 , as indicated .",
    "it is to be remarked that this function is non - sigmoidal , namely , oscillatory , which allows for hopping between the attractors for @xmath96 while it is monotonic in the hopfield case @xmath70 +   + * figure 5 : * time evolution of the overlap @xmath97 in a monte carlo simulation with @xmath9810@xmath99 neurons , @xmath100 stored ( random ) patterns , @xmath101 and , from top to bottom , @xmath102 @xmath103 @xmath104 and @xmath105 this illustrates that , under regular behavior ( as for the first two top graphs and the bottom one ) , the system is unable to respond to a week external stimulus .",
    "this is simulated as an extra local field , @xmath106 , where @xmath107 and @xmath108 changes @xmath109 @xmath110 @xmath111 @xmath112 @xmath113 every 40 mcs as indicated by p@xmath114 above the top graph .",
    "the situation is qualitatively different when the regime is chaotic , as for @xmath115 in this figure .",
    "after some wandering in the evolution that we show here , the system activity is trapped in a mixture state around @xmath116 mcs .",
    "however , the external stimulus induces jumping to the more correlated attractor , and so on .",
    "that is , chaos importantly enhances the network sensitivity . to obtain a similar behavior during the regular regimes",
    ", one needs to increase considerably the external force @xmath117"
  ],
  "abstract_text": [
    "<S> we present a neurobiologically  inspired stochastic cellular automaton whose state jumps with time between the attractors corresponding to a series of stored patterns . </S>",
    "<S> the jumping varies from regular to chaotic as the model parameters are modified . </S>",
    "<S> the resulting irregular behavior , which mimics the _ state of attention _ in which a systems shows a great adaptability to changing stimulus , is a consequence in the model of short  time presynaptic noise which induces _ </S>",
    "<S> synaptic depression_. we discuss results from both a mean  field analysis and monte carlo simulations . </S>"
  ]
}