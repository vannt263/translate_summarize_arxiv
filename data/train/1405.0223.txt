{
  "article_text": [
    "this article describes a computationally efficient method for constructing symmetric factorization of large dense matrices .",
    "the symmetric factorization of large dense matrices is important in several fields , including , among others , data analysis  @xcite , geostatistics  @xcite , and hydrodynamics  @xcite .",
    "for instance , several schemes for multi - dimensional monte carlo simulations require drawing covariant realizations of multi - dimensional random variables . in particular , in the case where the marginal distribution of each random variable is normal ,",
    "the covariant samples can be obtained by applying the _ symmetric factor _ of the corresponding covariance matrix to independent normal random variates .",
    "the symmetric factorization of a symmetric positive definite matrix can be computed as the factor @xmath6 in @xmath7 .",
    "one of the major computational issues in dealing with these large covariance matrices is that they are often dense .",
    "conventional methods of obtaining a symmetric factorization based on the cholesky decomposition are expensive , since the computational cost scales as @xmath8 for a @xmath9 matrix .",
    "relatively recently , however , it has been observed that large dense ( full - rank ) covariance matrices can be efficiently represented using hierarchical decompositions  @xcite .",
    "taking advantage of this underlying structure , we derive a novel symmetric factorization for large dense hierarchical off - diagonal low - rank ( hodlr ) matrices that scales as @xmath10 .",
    "i.e. , for a given @xmath11 matrix @xmath3 , we decompose it as @xmath0 . a major difference of our scheme versus the cholesky decomposition is the fact that the matrix @xmath6 is no longer a triangular matrix . in fact , the matrix @xmath6 is a product of matrices that are block low - rank updates of the identity matrix , and the cost of applying the factor @xmath6 to a vector scales as @xmath12 .",
    "hierarchical matrices were first introduced in the context of integral equations  @xcite arising out of elliptic partial differential equations and potential theory . since then , it has been observed that a large class of dense matrices arising out of boundary integral equations  @xcite , dense fill - ins in finite element matrices  @xcite , radial basis function interpolation  @xcite , kernel density estimation in machine learning , covariance structure in statistic models  @xcite , bayesian inversion  @xcite , kalman filtering  @xcite , and gaussian processes  @xcite can be efficiently represented as data - sparse hierarchical matrices . after a suitable ordering of columns and rows , these matrices can be recursively sub - divided using a tree structure and certain sub - matrices at each level in the tree can be well - represented by low - rank matrices .",
    "we refer the readers to  @xcite for more details on these matrices . depending on the tree structure and low - rank approximation technique ,",
    "different hierarchical decompositions exist .",
    "for example , the original fast multipole method  @xcite accelerates the calculation of long - range gravitational forces for @xmath13-body problems by hierarchically compressing ( via a quad- or oct - tree ) certain interactions in the associated matrix operator using analytical low - rank considerations .",
    "the low - rank sparsity structure of these hierarchical matrices can be exploited to construct fast dense linear algebra schemes , including direct inversion , determinant computation , symmetric factorization , etc .",
    "most of the existing results relevant to symmetric factorization of low - rank modifications to the identity are based on rank @xmath14 or rank @xmath15 modifications to the cholesky factorization , which are computationally expensive , i.e. , their scaling is at least @xmath16 .",
    "we do not seek to review the entire literature here , except to direct the readers to a few references  @xcite . to our knowledge ,",
    "the scheme presented in this paper is the first symmetric factorization for hierarchical matrices that scales nearly linearly .",
    "in fact , replacing the hodlr structure with other ( more stringent ) hierarchical structures would yield linear schemes .",
    "this extension is currently under investigation .",
    "it is worth pointing out that xia and gu  @xcite discuss a cholesky factorization for @xmath9 hierarchically semi - separable ( hss ) matrices that scales as @xmath17 .",
    "the paper is organized as follows : section  [ section_symfactor_lowrank ] contains the key idea behind the algorithm discussed in this paper : a fast , symmetric factorization for low - rank updates to the identity .",
    "section  [ section_hierarchical ] extends the formula of section  [ section_symfactor_lowrank ] to a nested product of block low - rank updates to the identity .",
    "the details of the compatibility of this structure with hodlr matrices is discussed .",
    "section  [ section_numerical ] contains numerical results , accuracy and complexity scaling , of applying the factorization algorithms to matrices relevant to problems in statistics , interpolation and hydrodynamics .",
    "section  [ section_conclusion ] summarizes the previous results and discusses further extensions and areas of ongoing research .",
    "almost all of the hierarchical factorizations are typically based on incorporating low - rank perturbations in a hierarchical manner . in this section ,",
    "we briefly discuss some well - known identities which allow for the rapid inversion and determinant computation of low - rank updates to the identity matrix .",
    "if the inverse of a matrix @xmath18 is already known , then the inverse of subsequent low - rank updates , for @xmath19 and @xmath20 , can be calculated as @xmath21 where we should point out that the quantity @xmath22 is only a @xmath23 matrix .",
    "this formula is known as the sherman - morrison - woodbury ( smw ) formula . further simplifying , in the case where @xmath24 , we have @xmath25 note that the smw formula shows that the inverse of a low - rank perturbation to the identity matrix is also a low - rank perturbation to the identity matrix . furthermore , the row - space and column - space of the low - rank perturbation and its inverse are the same .",
    "the main advantage of equation   is that if @xmath26 , we can obtain the inverse ( or equivalently solve a linear system ) of a rank @xmath27 perturbation of an @xmath9 identity matrix at a computational cost of @xmath28 . in general ,",
    "if @xmath29 is a low - rank perturbation of @xmath30 , then the inverse of @xmath31 is also a low - rank perturbation of the inverse of @xmath3 .",
    "it is also worth noting that if @xmath3 and @xmath31 are well - conditioned , then the sherman - morrison - woodbury formula is numerically stable  @xcite .",
    "the smw formula has found applications in , to name a few , kalman filters  @xcite , recursive least - squares  @xcite , and fast direct solvers for hierarchical matrices  @xcite .",
    "calculating the determinant of an @xmath9 matrix @xmath3 , classically , using a cofactor expansions requires @xmath32 operations .",
    "however , if the @xmath33 or eigenvalue decomposition is obtained , this cost is reduced to @xmath34 .",
    "recently  @xcite , it was shown that the determinant of hodlr matrices could be calculated in @xmath35 time using sylvester s determinant theorem  @xcite , a formula relating the determinant of a low - rank update of the identity to the determinant of a smaller matrix .",
    "determinants of matrices are very important in probability and statistics , in particular in bayesian inference , as they often serve as the normalizing factor in likelihood calculations and in the evaluation of the conditional evidence .",
    "sylvester s determinant theorem states that for @xmath36 , @xmath37 where the determinant on the right hand side is only of a @xmath38 matrix .",
    "hence , the determinant of a rank @xmath27 perturbation to an @xmath39 identity matrix , where @xmath26 , can be computed at a computational cost of @xmath28 .",
    "this formula has recently found applications in bayesian statistics for computing precise values of gaussian likelihood functions ( which depend on the determinant of the corresponding covariance matrix )  @xcite and computing the determinant of large matrices in random matrix theory  @xcite .      in the spirit of the sherman - morrison - woodbury formula and sylvester s determinant theorem",
    ", we obtain a formula that enables the symmetric factorization of a rank @xmath27 perturbation to the @xmath9 identity at a computational cost of @xmath28 . in particular ,",
    "for a symmetric positive definite ( from now on abbreviated as spd ) matrix of the form @xmath40 , where @xmath41 is an @xmath9 identity matrix , @xmath42 , @xmath43 , and @xmath44 , we obtain the factorization @xmath45 we now state this as the following theorem .",
    "[ thm_main ] for rank @xmath27 matrices @xmath46 and @xmath47 , if the matrix @xmath40 is spd then it can be symmetrically factored as @xmath48 where @xmath49 is obtained as @xmath50 the matrix @xmath51 is the symmetric factor of @xmath52 , and @xmath53 is the symmetric factor of @xmath54 , i.e. , @xmath55    we first prove two lemmas related to the construction of @xmath49 in equation  , which directly lead to the proof of theorem  [ thm_main ] . in the subsequent discussion , we will assume the following unless otherwise stated :    1 .",
    "@xmath41 is the identity matrix .",
    "2 .   @xmath26 .",
    "@xmath46 is of rank @xmath27 .",
    "4 .   @xmath43 is of rank @xmath27 .",
    "@xmath40 is spd .",
    "it is easy to show that the last item implies that the matrix @xmath56 is symmetric .",
    "the first lemma we prove relates the positivity of the smaller matrix @xmath57 to the positivity of the larger @xmath9 matrix , @xmath40 .",
    "[ prop_2 ] let @xmath58 denote a symmetric factorization of @xmath52 , where @xmath59 .",
    "if the matrix @xmath4 is spd ( semi - definite ) , then @xmath54 is also spd ( semi - definite ) .    to prove that @xmath54 is spd , it suffices to prove that given any non - zero @xmath60 , we have @xmath61 . note that since @xmath62 is full rank , the matrix @xmath52 is invertible .",
    "we now show that given any @xmath60 , there exists an @xmath63 such that @xmath64 .",
    "this will enable us to conclude that @xmath65 is positive definite since @xmath40 is positive definite .",
    "in fact , we will directly construct @xmath66 such that @xmath67 .",
    "let us begin by choosing @xmath68 .",
    "then , the following two criteria are met :    1 .",
    "@xmath69 2 .",
    "@xmath70    expanding the norm of @xmath71 we have : @xmath72 this proves criteria ( i ) .",
    "furthermore , by our choice of @xmath71 , we also have that @xmath73 . therefore",
    ", @xmath74 this proves criteria ( ii ) . from the above",
    ", we can now conclude that @xmath75 hence , if @xmath4 is spd , so is @xmath54 .",
    "an identical calculation proves the positive semi - definite case .",
    "we now state and prove a lemma required for solving a quadratic matrix equation that arises in the subsequent factorization scheme .",
    "[ prop_3 ] a solution @xmath49 to the quadratic matrix equation @xmath76 with @xmath77 and @xmath51 a full rank matrix is given by @xmath78 where @xmath79 is a symmetric factorization of @xmath80 , that is , @xmath81 .",
    "first note that from lemma  [ prop_2 ] , since @xmath80 is positive definite , the symmetric factorization @xmath82 exists .",
    "now the easiest way to check if equation   satisfies equation   is to plug in the value of @xmath49 from equation   in equation  .",
    "this yields : @xmath83 further simplifying the expression , we have : @xmath84 therefore , we have that @xmath85    we are now ready to prove the main result , theorem  [ thm_main ] .",
    "( proof of theorem  [ thm_main ] ) the proof follows immediately from the previous two lemmas . with @xmath49 and @xmath51",
    "as previously defined as in equation  , we have @xmath86 since @xmath87 and @xmath88 , from lemma  [ prop_3 ] we have that @xmath89 . substituting in the previous equation",
    ", we get @xmath90 this proves the symmetric factorization .",
    "a slightly more numerically stable variant of factorization   is : @xmath91 where @xmath92 is a unitary matrix such that @xmath93 .",
    "even though the previous theorem only addresses the symmetric factorization problem with no restrictions on the symmetric of the factors , we can also easily obtain a _ square - root factorization _ in a similar manner . by this",
    "we mean that for a given symmetric positive definite matrix @xmath3 , one can obtain a symmetric matrix @xmath94 such that @xmath95 .",
    "the key ingredient is obtaining a square - root factorization of a low - rank update to the identity : @xmath96 where @xmath49 is a symmetric matrix and satisfies @xmath97 the solution to equation   is given by @xmath98 where @xmath51 and @xmath53 are symmetric square - roots of @xmath52 and @xmath99 : @xmath100 these factorizations can easily be obtained via a singular value or eigenvalue decomposition .",
    "this can then be combined with the recursive divide - and - conquer strategy discussed in the next section to yield an @xmath1 algorithm for computing square - roots of hodlr matrices .",
    "theorem  [ thm_main ] has the two following useful corollaries .    [ cor_1 ] if @xmath101 , i.e. , the perturbation to the identity in equation   is of rank @xmath14 , then @xmath102 where @xmath103 .",
    "this result can also be found in  @xcite .",
    "corollary  [ cor_2 ] extends low - rank updates to spd matrices _ other _ than the identity .",
    "[ cor_2 ] given a symmetric factorization of the form @xmath104 , where the inverse of @xmath6 can be applied fast ( i.e. , the linear system @xmath105 can be solved fast ) , then a symmetric factorization of a spd matrix of the form @xmath106 , where @xmath107 and @xmath26 , can also be obtained fast . for instance , if the linear system @xmath105 can be solved at a computational cost of @xmath5 , then the symmetric factorization @xmath108 can also be obtained at a computational cost of @xmath5 .    a numerical example demonstrating corollary  [ cor_2 ]",
    "is contained in section  [ sec - fast ] .",
    "note that the factorizations in equations   and   are similar to the sherman - morrison - woodbury formula ; in each case , the symmetric factor is a low - rank perturbation to the identity .",
    "furthermore , the row - space and column - space of the perturbed matrix are the same as the row - space and column - space of the symmetric factors .",
    "another advantage of the factorization in equations   and   is that the storage cost and the computational cost of applying the factor to a vector , which is of significant interest as indicated in the introduction , scales as @xmath109 .",
    "we now describe a computational algorithm for finding the symmetric factorization described in theorem  [ thm_main ] .",
    "algorithm  [ algorithm_main ] lists the individual steps in computing the symmetric factorization and their associated computational cost .",
    "the only computational cost is the in the computation of the matrix @xmath49 in equation  .",
    "note that the dominant cost is the matrix - matrix product of an @xmath110 matrix with a @xmath111 matrix .",
    "the rest of the steps are performed on a lower @xmath27-dimensional space .    [ cols=\"^,<,^\",options=\"header \" , ]     note that since the rpy tensor is singular , on @xmath112d and @xmath113d manifolds the ranks of the off - diagonal blocks would grow as @xmath114 and @xmath115 , respectively . since the computational cost of the symmetric factorization scales as @xmath28 , the computational cost for the symmetric factorization to scale as @xmath17 and @xmath116 on @xmath112d and @xmath113d manifolds , respectively .",
    "the numerical benchmarks also validate this scaling of our algorithm in all three configurations .",
    "the article discusses a fast symmetric factorization for a class of symmetric positive definite hierarchically structured matrices .",
    "our symmetric factorization algorithm is based on two ingredients : a novel formula for the symmetric factorization of a low - rank update to the identity , and a recursive divide - and - conquer strategy compatible with hierarchically structures matrices .    in the case where the hierarchical structure present is that of hierarchically off - diagonal low - rank matrices , the algorithm scales as @xmath117 .",
    "the numerical benchmarks for dense covariance matrix examples validate the scaling .",
    "furthermore , we also applied the algorithm to the mobility matrix encountered in brownian - hydrodynamics , elements of which are computed from the rotne - prager - yamakawa tensor . in this case , since the ranks of off - diagonal blocks scale as @xmath115 , when the particles are on a three - dimensional manifold , the algorithm scales as @xmath116 .",
    "obtaining an @xmath5 symmetric factorization for the mobility matrix is a subject of ongoing research within our group .",
    "it is also worth noting that with nested low - rank basis of the off - diagonal blocks , i.e. , if the hodlr matrices are assumed to have an hierarchical semi - separable structure instead , then the computational cost of the algorithm would scale as @xmath28 .",
    "extension to this case is relatively straightforward .",
    "sivaram ambikasaran , arvind  krishna saibaba , eric  f darve , and peter  k kitanidis .",
    "ast algorithms for bayesian inversion . in",
    "_ computational challenges in the geosciences _ , pages 101142 .",
    "springer , 2013 .",
    "matthieu geist and olivier pietquin .",
    "statistically linearized recursive least squares . in _",
    "machine learning for signal processing ( mlsp ) , 2010 ieee international workshop on _",
    ", pages 272276 .",
    "ieee , 2010 .                                            dingding wang , tao li , shenghuo zhu , and chris ding .",
    "multi - document summarization via sentence - level semantic analysis and symmetric matrix factorization . in",
    "_ proceedings of the 31st annual international acm sigir conference on research and development in information retrieval _ , pages 307314 .",
    "acm , 2008 ."
  ],
  "abstract_text": [
    "<S> we present a fast direct algorithm for computing symmetric factorizations , i.e. @xmath0 , of symmetric positive - definite hierarchical matrices with weak - admissibility conditions . </S>",
    "<S> the computational cost for the symmetric factorization scales as @xmath1 for hierarchically off - diagonal low - rank matrices . </S>",
    "<S> once this factorization is obtained , the cost for inversion , application , and determinant computation scales as @xmath2 . </S>",
    "<S> in particular , this allows for the near optimal generation of correlated random variates in the case where @xmath3 is a covariance matrix . </S>",
    "<S> this symmetric factorization algorithm depends on two key ingredients . </S>",
    "<S> first , we present a novel symmetric factorization formula for low - rank updates to the identity of the form @xmath4 . this factorization can be computed in @xmath5 time , if the rank of the perturbation is sufficiently small . </S>",
    "<S> second , combining this formula with a recursive divide - and - conquer strategy , near linear complexity symmetric factorizations for hierarchically structured matrices can be obtained . </S>",
    "<S> we present numerical results for matrices relevant to problems in probability & statistics ( gaussian processes ) , interpolation ( radial basis functions ) , and brownian dynamics calculations in fluid mechanics ( the rotne - prager - yamakawa tensor ) .    </S>",
    "<S> symmetric factorization , hierarchical matrix , fast algorithms , covariance matrices , direct solvers , low - rank , gaussian processes , multivariate random variable generation , mobility matrix , rotne - prager - yamakawa tensor .    15a23 , 15a15 , 15a09 </S>"
  ]
}