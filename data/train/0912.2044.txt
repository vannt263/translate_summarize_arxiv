{
  "article_text": [
    "there is a large class of results dealing with random variables ( or measures ) defined in terms of a parameter ( say , a point on the sphere ) , which say that for a large measure of these parameters , the behavior of the random variable is well - approximated by some model distribution .",
    "early work in this direction was done by sudakov @xcite , who showed that under some relatively mild conditions , most one - dimensional marginals of a high - dimensional measure are close to each other .",
    "this line of research was further developed by von weiszcker @xcite , who showed that the canonical distribution around which one - dimensional marginals tend to cluster is close to a mixture of gaussian distributions . in both @xcite and @xcite ,",
    "the results are about the limiting behavior of one - dimensional projections , as the ambient dimension tends to infinity , although von weiszcker points out that one could extend the methods to deal with higher fixed - dimensional projections , as the ambient dimension tends to infinity .",
    "more recent work in this area was done by bobkov @xcite , who obtained concentration results for the distance from a one - dimensional projection of an isotropic log - concave random vector to a gaussian distribution .",
    "the purpose of this paper is to prove multivariate versions of such theorems ; that is , to consider rank @xmath5 projections of random vectors , instead of just rank one .",
    "moreover , the approach yields results of a sufficiently quantitative nature to allow not only @xmath5 fixed , but @xmath5 growing with the ambient dimension . the general case of approximating random @xmath5-dimensional projections of probability measures on @xmath7",
    "is considered , and is illustrated with an application to graphical projection pursuit .",
    "in particular , it is shown that typical @xmath5-dimensional projections of @xmath6 data points in @xmath7 are close to gaussian for @xmath6 and @xmath1 large ; the precise quantitative nature of the results yields limit theorems even for @xmath10 for a small constant @xmath9 .",
    "this result generalizes the following univariate limit result of diaconis and freedman .",
    "[ limit ] let @xmath11 be deterministic vectors in @xmath7 .",
    "suppose that @xmath6 , @xmath1 and the @xmath12 depend on a hidden index @xmath13 , so that as @xmath13 tends to infinity , so do @xmath6 and @xmath1 .",
    "suppose that there is a @xmath14 such that , for all @xmath15 , @xmath16 and suppose that @xmath17 let @xmath18 be distributed uniformly on the sphere , and consider the random measure @xmath19 which puts mass @xmath20 at each of the points @xmath21 .",
    "then as @xmath13 tends to infinity , the measures @xmath19 tend to @xmath22 weakly in probability .",
    "the method of proof here is described in a fairly specific context : random measures indexed by points in the stiefel manifold ( one could equivalently take points in the grassman manifold ) , approximated by gaussian distributions .",
    "however , the approach is quite general and could in principle be adapted to a family of random measures indexed by points in a metric probability space possessing the concentration of measure phenomenon .",
    "further , one could easily adapt the program to deal with non - gaussian limits .",
    "in particular , stein s method has been used to prove approximation results for many other limiting distributions , e.g. poisson @xcite ; gamma @xcite ; chi - square @xcite ; uniform on the discrete circle @xcite ; the semi - circle law @xcite ; the binomial and multinomial distributions @xcite ; and the hypergeometric distribution @xcite ; these approaches could be combined with what is done here in order to approximate by non - gaussian distributions .    before outlining the approach , some notation is needed .",
    "the euclidean length of a vector @xmath23 is denoted @xmath24 . for an @xmath25 matrix @xmath26_{i , j=1}^n$ ] ,",
    "the hilbert - schmidt norm is defined by @xmath27 the wasserstein distance between two random vectors @xmath0 and @xmath28 is defined by @xmath29 the bounded - lipschitz distance is defined by @xmath30 where @xmath31    the class of @xmath32-times continuously differentiable functions on @xmath33 is denoted @xmath34 , and has a norm defined by @xmath35 here , @xmath36 denotes the symmetric @xmath5-linear form given in components by @xmath37 where @xmath38 . for an intrinsic definition of @xmath36 ,",
    "see federer @xcite .",
    "the ball of radius @xmath39 in @xmath34 with respect to @xmath40 is denoted @xmath41 .",
    "the stiefel manifold @xmath42 is defined by @xmath43 with metric @xmath44^{1/2}$ ] .",
    "there is a unique rotation - invariant probability measure ( haar measure ) on @xmath42 ; one way to construct it is by choosing @xmath45 uniformly from @xmath46 , then @xmath47 uniformly from the orthogonal complement of @xmath45 in @xmath46 , and so on .",
    "now , suppose that a family of random vectors @xmath2 in @xmath48 is indexed by @xmath49 .",
    "the following is an outline of an approach to show that most @xmath2 are approximately gaussian .    _",
    "1 . prove an approximation result for the average distribution .",
    "_ if @xmath2 is defined fairly explicitly in terms of @xmath4 , one can first try to use the following abstract normal approximation theorem to show that the average distribution of the @xmath2 ( averaged over @xmath4 distributed according to haar measure on @xmath42 ) is close to gaussian .",
    "[ cont ] let @xmath0 be a random vector in @xmath48 and for each @xmath50 let @xmath51 be a random vector such that @xmath52 , with the property that @xmath53 almost surely .",
    "let @xmath54 be a standard normal random vector in @xmath48 .",
    "suppose there is a function @xmath55 and a random matrix @xmath56 such that the following conditions hold .",
    "1 .   @xmath57 \\xrightarrow[\\epsilon\\to0]{l_1}- x.\\]][first - diff ] 2 .",
    "@xmath58\\xrightarrow[\\epsilon\\to0]{l_1}\\sigma^2i_k+{\\mathbb{e}}\\left[f\\big|x\\right].\\ ] ] [ second - diff ] 3 .   for each @xmath59 , @xmath60=0.\\]][lindeberg ]    then @xmath61    it should be pointed out that while this theorem is sufficiently general for the applications carried out here , there is a more general version ( see @xcite or @xcite ) allowing for approximations by gaussian distributions with non - trivial covariance matrices .",
    "furthermore , condition [ first - diff ] need only hold approximately ; see @xcite .    in order to apply this theorem , an auxiliary random variable @xmath62 must be constructed .",
    "a natural construction which makes use of the symmetry of @xmath42 is to let @xmath63 be a `` small random rotation '' of @xmath4 ( this is made explicit in the applications to follow ) .",
    "then @xmath64 is an exchangeable pair of random points of @xmath42 by the rotation invariance of the distribution of @xmath4 , and so the random variables @xmath65 are also exchangeable and thus have the same distribution .",
    "furthermore , as @xmath66 , @xmath67 almost surely , and so if @xmath2 is a continuous function of @xmath4 , it will be true that @xmath68 almost surely .",
    "_ 2 . use the concentration of measure on @xmath42 to show that for some distance @xmath69 , @xmath70 is close to its mean .",
    "_ it is shown in @xcite that for @xmath71 and @xmath72 , for any @xmath73 with median @xmath74 and modulus of continuity @xmath75 , @xmath76<c_1e^{-c_2\\eta^2 d}.\\label{stiefel}\\ ] ] here , @xmath77 is the rotation - invariant probability measure on @xmath78 described above . the median",
    "@xmath74 is a median with respect to this measure .",
    "again , if the random variable @xmath2 is a sufficiently regular function of @xmath4 , this theorem can be applied to the function @xmath79 where @xmath80 is the conditional bounded - lipschitz distance from @xmath2 to @xmath81 , given @xmath4 .",
    "standard arguments allow the median @xmath74 to be replaced by the mean @xmath82 , with only minor loss .",
    "_ 3 . use entropy methods to bound @xmath83 . _",
    "consider the stochastic process @xmath84 indexed by the class of functions @xmath85 ( or by some sub - class ) , where @xmath86 denotes expectation with respect to @xmath0 only ; that is , conditional expectation with respect to the distribution of @xmath87 , conditioned on @xmath4 .",
    "thus the bounded - lipschitz distance from @xmath2 ( given @xmath4 ) to its average distribution can be viewed as the supremum of a stochastic process .",
    "the same approach used to prove a concentration result for @xmath80 can be used to show that @xmath88 satisfies a sub - gaussian increment condition of the type @xmath89\\le c_1e^{-\\frac{c_2\\epsilon^2}{\\|f - g\\|_1 ^ 2}},\\ ] ] for some constants @xmath90 and @xmath91 .",
    "for such a process , dudley s entropy bound can be used to estimate its supremum .",
    "specifically , dudley showed the following .",
    "let @xmath92 be a stochastic process indexed by a metric space @xmath93 with distance @xmath1 .",
    "suppose that there is a constant @xmath9 such that @xmath94 satisfies the increment condition @xmath95\\le c\\exp\\left(-\\frac{u^2 } { 2d(s , t)^2}\\right).\\ ] ] then there is a constant @xmath96 such that @xmath97 where @xmath98 is the @xmath99-covering number of @xmath93 with respect to the distance @xmath1 .",
    "one can apply this theorem not to the index set @xmath85 ( which has infinite @xmath99-covering number with respect to @xmath100 for @xmath101 ) , but to a more restricted indexing set @xmath102 of test functions .",
    "one may then be able to obtain a bound on @xmath83 by approximation of functions @xmath103 with @xmath104 by functions from @xmath102 , together with the approximation for the average distribution proved in step 1 .",
    "in this section , the method outlined in the introduction is applied in the case that @xmath0 is a random vector in @xmath7 , @xmath105 , and @xmath2 is the projection of @xmath0 onto the span of @xmath4 ; that is @xmath106 if @xmath4 is chosen randomly from @xmath42 ( according to the rotation - invariant probability measure described in the introduction ) , then the distributions of the @xmath2 are a family of random measures on @xmath48 indexed by @xmath4 .    to apply the method of the introduction , consider the random variable @xmath2 defined above , in the case that @xmath4 is chosen at random and independent of @xmath0 .",
    "the following results describe the behavior of @xmath2 , both on average and conditioned on @xmath4 .",
    "[ meanx ] let @xmath0 be a random vector in @xmath107 , with @xmath108 , @xmath109=\\sigma^2d$ ] , and @xmath110 .",
    "if @xmath4 is a random point of @xmath42 and @xmath2 is defined above , @xmath111    [ concx ] suppose that @xmath112 is defined by @xmath113 for @xmath49 , let @xmath114-    { \\mathbb{e}}f(\\sigma z_1,\\ldots,\\sigma z_k)\\right|;\\ ] ] that is , @xmath80 is the conditional bounded - lipschitz distance from @xmath2 to @xmath81 , conditioned on @xmath4 .",
    "then for @xmath115 , and @xmath4 a random point of @xmath42 @xmath116\\le \\sqrt{\\frac{\\pi}{2}}e^{-\\frac{d\\epsilon^2}{32 b}}.\\ ] ]    [ dist - bdx ] there is a constant @xmath117 such that @xmath118    observe that together , theorems [ concx ] and [ dist - bdx ] show that for @xmath119 , @xmath120\\le\\sqrt{\\frac{\\pi}{2 } } e^{-\\frac{d\\epsilon^2}{2 ^ 7b}}.\\ ] ] note that the bound on the right tends to zero as @xmath121 for any @xmath99 in this range .",
    "observe first that @xmath122 by symmetry and @xmath123 { \\mathbb{e}}\\left[x_{r}x_{s}\\right]=\\frac{\\delta_{ij}}{d}{\\mathbb{e}}\\left[|x|^2\\right ] = \\delta_{ij}\\sigma^2,\\end{split}\\ ] ] where the second - last equality follows from @xmath124=\\frac{1}{d}\\delta_{ij}\\delta_{rs}.$ ]    to apply the theorem [ cont ] to @xmath2 , one first has to construct @xmath125 .",
    "let @xmath126 where @xmath127 .",
    "let @xmath128 be a random orthogonal matrix , independent of @xmath0 , and define @xmath129 ; the pair @xmath130 is exchangeable by the rotation invariance of the distribution of @xmath4 , and so @xmath131 .",
    "let @xmath132 be the @xmath133 matrix given by the first two columns of @xmath134 and let @xmath135 ; define the matrix @xmath136_{i , j=1}^d = kck^t.$ ] then , writing @xmath137 and @xmath138 @xmath139&={\\mathbb{e}}\\left [ { \\left\\langle ( ua_\\epsilon u^t - i)\\theta_j , x \\right\\rangle}\\big|x,\\theta \\right]\\\\&=\\epsilon{\\mathbb{e}}\\left[{\\left\\langle q\\theta_j , x \\right\\rangle}\\big|x,\\theta\\right]-\\frac { \\epsilon^2}{2}{\\mathbb{e}}\\left[{\\left\\langle kk^t\\theta_j , x \\right\\rangle}\\big|x,\\theta\\right]+ o(\\epsilon^4 ) .",
    "\\end{split}\\ ] ] recall that @xmath140 and @xmath132 are determined by @xmath134 alone , and that @xmath134 is independent of @xmath87 .",
    "it is easy to show that @xmath141= 0_d$ ] and @xmath142=\\frac{2}{d}i_d$ ] , thus @xmath143=-\\frac{\\epsilon^2 } { d}x_\\theta+o(\\epsilon^4).\\ ] ] condition [ first - diff ] of theorem [ cont ] is thus satisfied with @xmath144 and @xmath145 .",
    "it is elementary but tedious to show that @xmath146 $ ] ( the computation is carried out in detail in @xcite ) .",
    "making use of this yields @xmath147\\\\ & \\qquad\\qquad= \\epsilon^2{\\mathbb{e}}\\left[{\\left\\langle q      \\theta_j , x \\right\\rangle}{\\left\\langle q\\theta_\\ell , x \\right\\rangle } \\big|x,\\theta\\right]+ o(\\epsilon^3)\\\\&\\qquad\\qquad=\\epsilon^2\\sum_{r , s , t , v=1}^d{\\mathbb{e}}\\left[q_{rs}q_{tv }    \\theta_{js}\\theta_{\\ell      v}x_rx_{t}\\big|x,\\theta\\right]+o(\\epsilon^3)\\\\ & \\qquad\\qquad=\\frac{2\\epsilon^2}{d(d-1)}\\left [    \\sum_{r , s=1}^d\\theta_{js}\\theta_{\\ell      s}x_{r}^2-\\sum_{r , s=1}^d\\theta_{js } \\theta_{\\ell      r}x_{r}x_{s}\\right]+o(\\epsilon^3)\\\\&\\qquad\\qquad = \\frac{2\\epsilon^2}{d(d-1)}\\left[\\delta_{j\\ell}|x|^2-x^\\theta_j    x^\\theta_\\ell\\right]+ o(\\epsilon^3)\\\\&\\qquad\\qquad=\\frac{2\\epsilon^2\\sigma^2}{d}\\delta_{j\\ell}+\\frac{2    \\epsilon^2}{d(d-1)}\\left[\\delta_{j\\ell}\\big(|x|^2-\\sigma^2d\\big)+\\delta_{j\\ell }    \\sigma^2-x^\\theta_jx^\\theta_\\ell\\right]+o(\\epsilon^3 ) .",
    "\\end{split}\\ ] ] the random matrix @xmath56 of theorem [ cont ] is thus defined by @xmath148.\\ ] ] it follows from the theorem that @xmath149\\\\&\\le\\frac{\\sigma\\sqrt{k}(a+1)+",
    "\\sigma k}{d-1}.\\end{split}\\ ] ]    define a function @xmath73 by @xmath150 where @xmath86 denotes the expectation with respect to the distribution of @xmath0 only ; that is , @xmath151.\\ ] ]    to apply the concentration of measure on @xmath42 , it is necessary to determine the modulus of continuity of @xmath56 .",
    "first , observe that for @xmath103 with @xmath104 given , @xmath152\\\\&\\le&{\\mathbb{e}}\\left[\\big|\\big({\\left\\langle x , \\theta_1'-\\theta_1 \\right\\rangle},\\ldots , { \\left\\langle x , \\theta_k'-\\theta_k \\right\\rangle}\\big)\\big|\\big|\\theta,\\theta'\\right ] \\\\&\\le&\\sqrt{\\sum_{j=1}^k|\\theta_j'-\\theta_j|^2{\\mathbb{e}}{\\left\\langle x , \\frac { \\theta_j'-\\theta_j}{|\\theta_j'-\\theta_j| } \\right\\rangle}^2}\\\\&\\le & \\rho(\\theta,\\theta')\\sqrt{b}.\\end{aligned}\\ ] ] it follows that @xmath153 thus @xmath80 is a lipschitz function on @xmath154 , with lipschitz constant @xmath155 . applying",
    "the concentration of measure inequality from inequality of the introduction then implies that @xmath156<\\sqrt{\\frac { \\pi}{2}}e^{-\\frac{\\epsilon^2d}{8b}}.\\ ] ]    now , if @xmath157 is a haar - distributed random point of @xmath42 , then @xmath158dt\\\\&\\le\\int_0^\\infty \\sqrt{\\frac{\\pi}{2}}e^{- \\frac{dt^2}{8b}}dt = \\pi\\sqrt{\\frac{b}{d}}. \\end{split}\\ ] ] so as long as @xmath159 replacing the median of @xmath56 with its mean only changes the constants : @xmath160\\le { \\mathbb{p}}\\big[\\big|f(\\theta)-m_f&\\big|>\\epsilon-\\big|m_f-{\\mathbb{e}}f(\\theta ) \\big|\\big]\\\\&\\le{\\mathbb{p}}\\left[\\left|f(\\theta ) -m_f\\right|>\\frac{\\epsilon}{2}\\right]\\le \\sqrt{\\frac{\\pi}{2 } } e^{-\\frac{d\\epsilon^2}{32b}}. \\end{split}\\ ] ]    what has just been shown is that @xmath80 is concentrated about its mean ; it remains to give a bound for this mean ( theorem [ dist - bdx ] ) .    as indicated in the introduction , theorem [ dist - bdx ]",
    "is proved making use of dudley s entropy bound for bounding the expected value of the supremum of a stochastic process .",
    "let @xmath161 .",
    "then @xmath162 is a stochastic process ( each @xmath163 is a random variable depending on @xmath4 ) indexed by a family of functions @xmath103 .",
    "the same type of concentration argument used above can be used to show that this process is sub - gaussian .",
    "let @xmath164 be lipschitz with lipschitz constant @xmath165 and consider the function @xmath166 defined on @xmath42 by @xmath167.\\ ] ] the same argument as above shows that @xmath168 is lipschitz on @xmath46 with lipschitz constant @xmath169 .",
    "it thus follows from that @xmath170\\le \\sqrt{\\frac{\\pi}{2 } } e^{-\\frac{d\\eta^2}{8l^2b}},\\]]and if @xmath171 @xmath172 & \\le\\sqrt{\\frac{\\pi}{2}}e^{-\\frac{d\\epsilon^2}{32l^2b}}. \\end{split}\\ ] ] observe that , for @xmath4 a haar - distributed random point of @xmath173 , @xmath174 , and so can be restated as @xmath175\\le \\sqrt{\\frac{\\pi}{2}}\\exp\\left[-\\frac{d\\epsilon^2}{2 ^ 7l^2b}\\right].\\ ] ]    note that @xmath176 thus for @xmath177 , for @xmath178 the lipschitz constant of @xmath179 , @xmath180\\le{\\mathbb{p}}\\left[x_{f - g}>\\epsilon \\right]\\le\\sqrt{\\frac{\\pi}{2}}\\exp\\left[\\frac{-d\\epsilon^2}{2 ^ 7[l(f - g)]^2b } \\right]\\le\\sqrt{\\frac{\\pi}{2}}\\exp\\left[\\frac{-d\\epsilon^2}{2 ^ 7\\|f - g\\|_1 ^ 2b } \\right].\\ ] ] the condition on @xmath99 may be removed by replacing the factor of @xmath181 in the bound above by , e.g. , @xmath182 .",
    "the process @xmath183 therefore satisfies the sub - gaussian increment condition for the distance @xmath184    consider the class @xmath185 of functions @xmath103 which are supported on @xmath186 such that @xmath187 it is proved in the appendix that for @xmath101 and @xmath188 , the @xmath99-covering number for this set with respect to the norm @xmath100 is bounded by @xmath189\\ ] ] with @xmath190 it follows that the @xmath99-covering number with respect to the distance @xmath191 is bounded by @xmath192^{\\frac{k}{m -1}}}{\\left[\\epsilon\\sqrt{d}\\right]^{\\frac{k}{m-1}}}}\\right.\\right .",
    "\\\\&\\qquad\\qquad\\left.\\left.+\\frac{2\\log(2)(m+4)\\left[\\sqrt{\\pi}(r+1)\\right]^k \\left[40\\sqrt{b}\\right]^{\\frac{k}{m-1}}}{k\\gamma\\left(\\frac{k}{2}\\right)\\left [ \\epsilon\\sqrt{d}\\right]^{\\frac{k}{m-1}}}\\right)e^{k+m-2}\\right ] . \\end{split}\\ ] ]    since functions @xmath193 have in particular @xmath194 , this class also satisfies the sub - gaussian increment condition with respect to the metric @xmath191 .",
    "note that the diameter of @xmath185 with respect to @xmath191 is bounded above by @xmath195 it follows from dudley s entropy bound that there is a constant @xmath96 such that @xmath196 $ ] is bounded above by @xmath197^k\\left[40\\sqrt{b}\\right]^{\\frac{k}{m-1 } } } { k\\gamma\\left(\\frac{k}{2}\\right)\\left[\\epsilon\\sqrt{d}\\right]^{\\frac{k}{m-1 } } } } d\\epsilon.\\ ] ] making the substitution @xmath198 then gives an upper bound of @xmath199^k(5)^{\\frac{k}{m-1 } } } { k\\gamma\\left(\\frac{k}{2}\\right)s^{\\frac{k}{m-1}}}}ds\\ ] ] for another constant @xmath200 .",
    "looking at the first two summands and the third separately , as long as @xmath201 , this implies that there is an absolute constant @xmath96 such that @xmath196 $ ] is bounded by @xmath202 or , as will be needed in what follows , @xmath203\\le \\sqrt{\\frac{b}{d}}\\left(\\frac{mc^{k+m}r^{k/2 }    m^{3/2}}{(2m - k-2)\\sqrt{k\\gamma\\left(\\frac{k}{2}\\right)}}\\right).\\ ] ] from this bound , one can obtain a bound on @xmath204 as follows .",
    "let @xmath205 that is , @xmath206 is a radially symmetric cut - off function with @xmath207 , supported on @xmath208 and with @xmath209 on @xmath210 . for @xmath211 , let @xmath212 . then @xmath213 since @xmath214 if @xmath215 and @xmath216 for all @xmath23 , @xmath217\\le \\frac{1}{r^2}\\sum_{i=1}^k{\\mathbb{e}}\\big [ { \\left\\langle x , \\theta_i \\right\\rangle}^2\\big]\\le\\frac{bk}{r^2},\\ ] ] and the same holds if @xmath86 is replaced by @xmath218 .",
    "it follows that @xmath219    next , let @xmath220 be a @xmath221 bump function , such that @xmath222 for all @xmath223 , @xmath224 for @xmath225 , @xmath226 for @xmath227 , and such that @xmath228 for all @xmath229 ( the existence of such a function is guarranteed by theorem 1.4.2 of @xcite ) . for @xmath23",
    ", define @xmath230 where @xmath231 is a constant depending only on @xmath5 , such that @xmath232 observe that it follows from the bounds that @xmath233 for @xmath234 , let @xmath235 let @xmath236 be a random vector in @xmath48 with density @xmath237 , independent of @xmath87 . then one can write @xmath238 and the same with @xmath218 in place of @xmath86 . since @xmath234",
    ", it follows that @xmath239 from which it follows that @xmath240 furthermore , by young s inequality , for @xmath241 , @xmath242 now , integrating in polar coordinates , @xmath243 it follows that @xmath244 for all @xmath23 , and so @xmath245 . finally , if @xmath246 is supported on @xmath208 , then it is easy to see that @xmath247 is supported on @xmath248 .",
    "it now follows from , and that @xmath249&\\le { \\mathbb{e}}\\left(\\sup_{f\\in    c^1_1({\\mathbb{r}}^k)}\\left[\\left|x_f - x_{f_r }    \\right|+\\left|x_{f_r}-x_{(f_r)_t}\\right|+x_{(f_{r})_t}\\right]\\right)\\\\&\\le \\frac{2bk}{r^2}+8t+\\sqrt{\\frac{b}{d}}\\left(\\frac{2^{k+1}m^{2 m }    c^{k+m}(r+1 + 2t)^{k/2}m^{3/2}}{(2m - k-2)t^m\\sqrt{k\\gamma\\left(\\frac{k}{2 }      \\right)}}\\right)\\\\&\\le\\frac{2bk}{r^2}+8t+\\sqrt{\\frac{b}{d } } \\left(\\frac{c^{k+m}m^{2m}r^{k/2}m^{3/2}}{(2m - k-2)t^m\\sqrt{k\\gamma\\left(\\frac{k}{2 }      \\right)}}\\right ) .",
    "\\end{split}\\ ] ] choosing @xmath250 yields @xmath251\\le\\frac{(2b+8)k}{r^2}+ \\sqrt{\\frac{b}{d}}\\left(\\frac{c^{k+m}m^{2m}r^{2m+k/2}m^{3/2 } } { ( 2m - k-2)k^m\\sqrt{k\\gamma\\left(\\frac{k}{2}\\right)}}\\right).\\ ] ] now choosing @xmath252 and applying stirling s formula to @xmath253 yields @xmath254 \\le\\frac{(2b+8)k}{r^2}+ \\sqrt{\\frac{b}{d}}\\left[\\big(ck^{3/4}\\big)^{k}r^{9k/2}\\right].\\ ] ] setting @xmath255 yields @xmath256\\le\\frac{c^kb}{d^{\\frac{2}{9k+4}}}.\\ ] ] finally , by theorem [ meanx ] and , @xmath257",
    "in this section , the theorems of the previous section are applied to prove a quantitative , higher - dimensional version of a result of diaconis and freedman @xcite .",
    "let @xmath11 be deterministic vectors in @xmath7 ; write @xmath258 define @xmath259 by the condition @xmath260 , and define @xmath261 and @xmath112 by @xmath262 and @xmath263 .",
    "observe that @xmath264 . also , if @xmath0 is distributed uniformly over the points @xmath265 , then these definitions of @xmath266 , @xmath261 , and @xmath112 correspond to those in the previous section .",
    "let @xmath157 be a random point in @xmath42 , distributed according to the rotation - invariant probability measure described in the introduction , and consider the family of random measures @xmath267 defined in terms of @xmath4 by @xmath268 that is , @xmath267 puts equal mass at the projections of each of the @xmath12 onto the span of @xmath78 .    in diaconis and freedman",
    "@xcite it was shown that , in the case @xmath269 , the measures @xmath270 converge weakly in probability to gaussian as @xmath6 and @xmath1 tend to infinity , under the conditions that , for some @xmath14 such that , for all @xmath15 , @xmath271 and @xmath272 here , @xmath6 , @xmath1 , and the @xmath12 depend on a hidden index @xmath13 such that as @xmath13 tends to infinity , so do @xmath6 and @xmath1",
    ". a reasonable quantitative analog would be to require @xmath261 and @xmath112 above to be bounded , independent of @xmath6 and @xmath1 .",
    "one could also allow them to grow slowly , as is clear from the statements of the theorems below .",
    "recall that @xmath273 so if @xmath112 is to remain bounded as @xmath1 tends to infinity , @xmath6 must tend to infinity at least as fast as @xmath1 .    in recent work of the author @xcite , a quantitative version of the diaconis - freedman result was proved , giving an explicit bound on @xmath274,$ ] where @xmath275 is the gaussian distribution on @xmath276 with mean zero and variance @xmath277 .",
    "the results of section [ projections - sec ] apply immediately to the random vector @xmath0 uniformly distributed on the @xmath6 points @xmath278 to give the following @xmath5-dimensional extensions .",
    "[ mean ] if @xmath4 is a random point of @xmath42 and @xmath2 is distributed according @xmath267 , then @xmath111    [ conc]for @xmath49 , let @xmath279 that is , @xmath80 is the conditional bounded - lipschitz distance from @xmath2 to @xmath81 , conditioned on @xmath4 .",
    "then for @xmath115 , and @xmath4 a random point of @xmath42 @xmath280\\le \\sqrt{\\frac{\\pi}{2}}e^{-\\frac{d\\epsilon^2}{32 b}}.\\ ] ]    [ dist - bd ] there is a constant @xmath117 such that @xmath118    observe that together , theorems [ conc ] and [ dist - bd ] show that for @xmath281 , @xmath120\\le\\sqrt{\\frac{\\pi}{2 } } e^{-\\frac{d\\epsilon^2}{2 ^ 7b}}.\\ ] ] note that the bound on the right tends to zero as @xmath121 for any @xmath99 in this range . in particular , if @xmath261 and @xmath112 are bounded and @xmath15 fixed , if @xmath10 , where @xmath9 is a sufficiently small constant ( depending on @xmath99 ) , then @xmath282 $ ] decays exponentially as @xmath1 tends to infinity .",
    "consider the class @xmath34 of @xmath32-times continuously differentiable functions on @xmath33 with norm defined by @xmath284 here , @xmath36 denotes the symmetric @xmath5-linear form given in components by @xmath37 where @xmath38 . for an intrinsic definition of @xmath36 ,",
    "see federer @xcite .",
    "let @xmath283 be the ball of radius @xmath285 of @xmath34 with respect to @xmath40 ; in this section , the @xmath99-covering number of @xmath286 with respect to the norms @xmath287 ( defined the usual way ; in our notation , this is @xmath288 ) and @xmath289 is calculated for @xmath188 .",
    "the proof closely follows the approach in van der vaart and wellner @xcite but uses the definition of @xmath290 as a @xmath5-linear form instead of working in coordinates with the partial derivatives of @xmath103 .",
    "first , choose a @xmath291-net @xmath292 of @xmath293 , with @xmath294 to be determined .",
    "one can choose such a net so that @xmath295 where @xmath296 .",
    "now , associate to each @xmath297 an @xmath298 array of operators in the following way . in the space of symmetric @xmath5-linear forms on @xmath7 , choose a @xmath299-net @xmath300 , with respect to the operator norm .",
    "the @xmath301-th entry of the array @xmath302 associated to @xmath103 is chosen to be the closest point in the appropriate net to the @xmath303-linear form @xmath304 .",
    "one can choose @xmath305 and @xmath306 such that if @xmath307 have @xmath308 ( with respect to either the @xmath305 or the @xmath306 nets ) , then @xmath309 for @xmath305 and @xmath310 for @xmath306 , as follows .",
    "for @xmath311 given , choose @xmath312 with @xmath313 .",
    "by taylor s theorem applied to @xmath179 , @xmath314 with @xmath315 . since @xmath308",
    ", it follows that @xmath316 for @xmath317 , thus by the expansion above , @xmath318 since @xmath319 .",
    "it follows that choosing @xmath320 means that if @xmath308 then @xmath321    to choose @xmath306 , apply taylor s theorem to @xmath322 : if @xmath323 , @xmath324 ( with @xmath325 occurring @xmath326 times ) , and @xmath327 . as above , this implies @xmath328 and thus @xmath329 if @xmath330    to bound the size of an @xmath99-net for @xmath331 , it now only remains to count the number of possible arrays @xmath302 for @xmath297 .",
    "begin by counting the number of possibilities for the first column . since @xmath332 is approximated in the @xmath5 - 1 entry of @xmath302 by a point from a @xmath299-net , the size of such a net is needed .",
    "the space of symmetric @xmath5-linear forms is a finite - dimensional normed space , and the size of a net for the unit ball of such a space is given in milman and schechtman @xcite , in terms of the dimension of the space . to define an element @xmath93 of this space",
    ", it suffices to define @xmath333 where @xmath334 appears @xmath335 times with @xmath336 for each @xmath337 and @xmath338 .",
    "the number of such vectors @xmath339 is well - known ( see , e.g. , @xcite ) to be @xmath340 .",
    "it follows from the bound in @xcite that there is a @xmath341-net of the space of symmetric @xmath5-linear forms of size not greater than @xmath342 assuming that @xmath343 .",
    "since the only interesting case is @xmath344 ( since @xmath345 for @xmath346 automatically ) , this is no restriction . the number of possibilities for the first column of @xmath302 is thus bounded by @xmath347\\\\&\\le\\exp\\left[\\left(\\log(5)-m\\log(\\delta)\\right)e^{m+d-2 } \\right ] , \\end{split}\\ ] ] since @xmath343 and @xmath348 . to bound the number of possibilities in the remaining columns ,",
    "assume that the @xmath312 have been ordered such that for all @xmath349 , there is an @xmath350 with @xmath351 .",
    "now , for unit vectors @xmath352 , define the function @xmath353 where the dependence of @xmath56 on the @xmath354 has been suppressed . by taylor",
    "s theorem , @xmath355 with @xmath356 .",
    "let @xmath357 denote the @xmath303-@xmath337-th entry of the array @xmath302 .",
    "then @xmath358 that is , given the information in the previous columns , the symmetric @xmath5-linear form @xmath359 is within a ball of radius @xmath360 with respect to the operator norm . by the same argument that bounds the size of the original @xmath299-net in the space , the number of points of the net within this ball of radius @xmath361 is bounded by @xmath362 it follows that the number of possibilities for the column entries of @xmath302 after the first column is specified is bounded by @xmath363^{\\frac{{\\mathop{\\mathrm{vol}}}({\\mathcal{x}}_1)}{\\delta^d}}\\\\&\\qquad=\\exp\\left [ \\frac{{\\mathop{\\mathrm{vol}}}({\\mathcal{x}}_1)}{\\delta^d}\\sum_{k=0}^{m-1}\\binom{k+d-1}{k } \\big((m - k+4)\\log(2)\\big)\\right]\\\\&\\qquad\\le\\exp\\left [ \\frac{{\\mathop{\\mathrm{vol}}}({\\mathcal{x}}_1)\\big((m+4)\\log(2)\\big)}{\\delta^d}\\sum_{k=0}^{m-1 } \\frac{1}{k!}(d+m-2)^k\\right]\\\\&\\qquad\\le\\exp\\left [ \\frac{{\\mathop{\\mathrm{vol}}}({\\mathcal{x}}_1)\\big((m+4)\\log(2)\\big)}{\\delta^d}e^{d+m-2}\\right ] .",
    "\\end{split}\\ ] ] it now follows that the total number of possible entries of @xmath302 is bounded by @xmath364.\\ ] ] recall that @xmath305 and @xmath306 were chosen such that @xmath365 and @xmath366 .",
    "the @xmath99-covering number ( for @xmath101 ) of @xmath331 with respect to @xmath367 is thus bounded by @xmath368\\ ] ] with @xmath369 the @xmath99-covering number of @xmath331 for @xmath101 and @xmath188 with respect to @xmath100 is bounded by @xmath370\\ ] ] with @xmath371                  persi diaconis .",
    "stein s method for markov chains : first examples . in _ stein s method : expository lectures and applications _ , volume  46 of _ ims lecture notes monogr .",
    "_ , pages 2743 .",
    "inst . math .",
    "statist . ,",
    "beachwood , oh , 2004 .",
    "f.  gtze and a.  n. tikhomirov .",
    "limit theorems for spectra of random matrices with martingale structure . in _ stein s method and applications _ , volume  5 of _ lect .",
    "notes ser .",
    "_ , pages 181193 .",
    "singapore univ . press , singapore , 2005 .",
    "susan holmes .",
    "stein s method for birth and death chains . in _",
    "stein s method : expository lectures and applications _ , volume  46 of _ ims lecture notes monogr .",
    "_ , pages 4567 .",
    ", beachwood , oh , 2004 ."
  ],
  "abstract_text": [
    "<S> let @xmath0 be a @xmath1-dimensional random vector and @xmath2 its projection onto the span of a set of orthonormal vectors @xmath3 . </S>",
    "<S> conditions on the distribution of @xmath0 are given such that if @xmath4 is chosen according to haar measure on the stiefel manifold , the bounded - lipschitz distance from @xmath2 to a gaussian distribution is concentrated at its expectation ; furthermore , an explicit bound is given for the expected distance , in terms of @xmath1 , @xmath5 , and the distribution of @xmath0 , allowing consideration not just of fixed @xmath5 but of @xmath5 growing with @xmath1 . </S>",
    "<S> the results are applied in the setting of projection pursuit , showing that most @xmath5-dimensional projections of @xmath6 data points in @xmath7 are close to gaussian , when @xmath6 and @xmath1 are large and @xmath8 for a small constant @xmath9 . </S>"
  ]
}