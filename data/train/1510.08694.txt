{
  "article_text": [
    "statistical depth generally is a measure of centrality with respect to a multivariate distribution or a data cloud .",
    "it is shown to have many useful data - driven features for developing statistical inference methods and applications .",
    "for example , among other features , it can also yield a center - outward ordering , and thus order statistics and ranks for multivariate data . with its rapid and broad advances ,",
    "statistical depth has emerged to be a powerful alternative approach in multivariate analysis .",
    "there exist many different notions of statistical depth ; see , for example , @xcite and @xcite and the references therein .",
    "but the so - called geometric depths such as the half - space depth @xcite and the simplicial depth @xcite are often preferred in many nonparametric inference methods and applications for their intrinsic desirable properties , as seen in @xcite , liu and singh ( @xcite ) , @xcite , @xcite , @xcite , @xcite , @xcite , @xcite and many others .    in practice ,",
    "the empirical versions of the half - space depth and the simplicial depth , however , suffer from the problem of vanishing value outside the convex hull of the data .",
    "this problem is inherent in any depth function that uses empirical counts based on the data to compute its value .",
    "it renders the empirical version of such a depth useless outside the data cloud , and limits its utility in applications involving extreme outlying probability mass .",
    "a successful resolution to this problem can avert such limitations and greatly enhance the utility of depth functions . in investigating this problem",
    ", we observe that the half - space depth involves projecting data points onto unit vectors , and thus naturally lends itself in the framework of extreme value theory .",
    "therefore , we propose to refine the empirical half - space depth by applying extreme value statistics to `` the tail . ''",
    "the aim of this paper is to present this proposal , and assess and demonstrate the improvement achieved by the proposal , in theory and applications .    to be more precise ,",
    "let @xmath0 be i.i.d .",
    "random vectors taking values in @xmath1 .",
    "denote the common probability measure with @xmath2 and the empirical measure with @xmath3 ; denote closed half - spaces with @xmath4 .",
    "then the half - space depth at @xmath5 is defined by @xmath6 observe that the infimum can be restricted to half - spaces @xmath4 with @xmath7 on their boundary .",
    "we can also write @xmath8 with @xmath9 the radius or @xmath10-norm of a vector .",
    "the classical nonparametric way to estimate @xmath11 is with the empirical half - space depth : @xmath12    it follows that for any @xmath7 outside the convex hull of the data @xmath13 .",
    "this might seem a minor problem .",
    "indeed , when the data are univariate , the probability that a new observation falls outside the convex hull is at most @xmath14 , but in higher dimensions this probability can be quite sizable .",
    "for example , for the multivariate normal distribution and @xmath15 this probability is 8.8% in dimension 2 and 21.7% in dimension 3 .",
    "even when @xmath16 is as large as 500 , these probabilities are still 2.1% ( @xmath17 ) and 6.5% ( @xmath18 ) ; see , for example , @xcite . outside the data hull , @xmath19 makes no distinction between different points and provides hardly information about @xmath2 .",
    "this inability of distinguishing points in a sizable subspace can severely restrict the utility of half - space depth in many of its applications , such as statistical process control and classification ( see section  [ sec3 ] ) .",
    "note that the problem is not restricted to @xmath19 being exactly 0 : if @xmath20 is positive but very small , it might not adequately estimate @xmath11 due to the scarcity of useful data points .",
    "somewhat related , due to the discrete nature of @xmath19 , ties occur often .",
    "for example , @xmath21 for _ all _ the data on the boundary of the data hull , that is , all these data form one tie and can not be ranked effectively .",
    "( for the normal distribution in dimension 3 and @xmath22 this tie , on average , has a size of about 32 . )",
    "this phenomenon renders rank procedures based on depth less precise and less efficient .",
    "the goal of this paper is to refine the definition of empirical half - space depth @xmath19 in the tail , that is , for values @xmath7 where @xmath20 is zero or quite small .",
    "the proposed refined estimator will be called @xmath23 ( see section  [ sec2 ] for the definition ) and is based on extreme value theory .",
    "the estimator @xmath23 is equal to @xmath19 in the central region , where the depth is relatively high .",
    "outside this region @xmath23 is positive , smooth and it improves substantially on @xmath19 .",
    "therefore , the aforementioned weaknesses of @xmath19 are `` repaired . ''    as an illustration , we consider the estimation of the depth contour at level @xmath24 , that is , we want to estimate the set @xmath25 , based on a random sample of size @xmath16",
    ". using @xmath19 , it is usually estimated with the boundary of the data hull , where indeed @xmath26 , almost surely .",
    "we also estimate it using our refined estimator by @xmath27 .",
    "we consider as an example the bivariate spherical cauchy distribution ( see section [ sec2.3 ] ) and simulate one random sample of size @xmath22 ; see figure  [ bestplotever ] . (",
    "the computation of these depth contours is discussed in remark  [ re6 ] of section  [ sec2.2 ] . )",
    "it clearly shows that @xmath23 greatly improves @xmath19 ; @xmath19 fails completely here , whereas @xmath23 performs well .",
    "this indicates that our refined estimator can be very useful in practice .",
    "in the next section , we will define @xmath23 and show , under appropriate conditions , its uniform ratio consistency ( considering @xmath28 ) on a very large region , much larger than the data hull .",
    "in contrast , @xmath29 is not uniformly close to 1 _ on _ the data hull .",
    "we further show through simulations that these asymptotic differences between @xmath23 and @xmath19 are clearly present for finite samples , that is , that @xmath23 substantially outperforms @xmath19 in the tail . in section  [ sec3 ]",
    ", we investigate the impact of these theoretical improvements in real applications of data depth using examples in statistical process control ( spc ) and classification .",
    "both applications obtain substantial improvements by using @xmath23 . finally , we provide some concluding remarks in section  [ sec4 ] .",
    "all proofs are deferred to section  [ sec5 ] .",
    "we first consider refining @xmath19 in the one - dimensional case , particularly since it serves as a building block for us to refine @xmath19 in higher dimensions .",
    "let @xmath30 be i.i.d .",
    "random variables with common continuous distribution function @xmath31 with @xmath32 .",
    "write @xmath33 .",
    "let @xmath34 be the ( right - continuous ) empirical distribution function and define @xmath35 .",
    "the half - space depth and its empirical counterpart in the one - dimensional case are simply @xmath36 and @xmath37 , respectively .",
    "it is clear that the aforementioned shortcomings of @xmath19 are due to the inadequacy of the empirical distribution function as an estimator in the tails . since extreme value statistics",
    "is well suited for inference problems in this setting , we propose applying it to refine @xmath19 in the tails .     based on @xmath38 ( circle ) , @xmath19 ( dashed ) and @xmath23 ( solid ) for a standard bivariate spherical cauchy random sample ; @xmath22 . ]    in extreme value theory , it is assumed that there exist a location function @xmath39 and a scale function @xmath40 such that @xmath41 \\\\[-8pt ] \\eqntext{1+\\gamma y > 0.}\\end{aligned}\\ ] ] here , @xmath42 is the limiting extreme value distribution and @xmath43 is the extreme value index . if ( [ aaa ] ) holds , @xmath31 is said to be in the max domain of attraction of @xmath44 .",
    "see , for example , @xcite .",
    "the above assumption guarantees that @xmath31 has a `` regular '' tail and makes extrapolation outside the data range possible .",
    "if @xmath31 is in the max - domain of attraction of @xmath42 , by setting @xmath45 and @xmath46 in ( [ aaa ] ) , we obtain for large @xmath47 and large @xmath48 @xmath49 let @xmath50 and @xmath51 be estimators for @xmath52 and @xmath53 , respectively .",
    "define @xmath54 , where @xmath55 denotes the @xmath56th order statistic of @xmath30 . plugging these estimators into ( [ eq2_4 ] ) ,",
    "we obtain the following estimator for the right - tail probability @xmath57 : @xmath58 \\biggr)^{-1/\\hat{\\gamma}}.\\ ] ] to estimate the left - tail probability , we can define @xmath59 similarly as @xmath60 by using the @xmath61 .",
    "the general idea of estimating @xmath38 with our refined estimator is the following .",
    "for a given @xmath62 , we define the central region to be @xmath63 . for @xmath48 in this central region",
    ", we define @xmath64 , that is , we use the classical empirical half - space depth . in the right tail , that is , when @xmath65 , we refine @xmath19 by defining @xmath66 and similarly , when @xmath67 ( the left tail ) , we set @xmath68 . at the `` glue - up '' points @xmath69 and @xmath70 , we have @xmath71 in the following , we study the asymptotic properties of our refined empirical half - space depth @xmath23 . throughout",
    "we assume that @xmath72 is an intermediate sequence : a sequence of positive integers satisfying @xmath73 we need a second - order condition in both the left tail and the right tail ; for simplicity , we will only specify it for the right tail .",
    "let @xmath74 , be the tail quantile function .",
    "we can and will take the location function @xmath75 .",
    "we assume that the derivative @xmath76 exists and that for some eventually positive or eventually negative function @xmath77 with @xmath78 and for some @xmath79 we have @xmath80 this condition implies ( for @xmath81 ) @xmath82 this limit relation is somewhat similar to lemma  4.3.5 in @xcite .",
    "a proof can be given along the lines of the proof of that lemma ; the proof uses in particular theorem  2.3.9 in @xcite , with @xmath83 and @xmath52 there replaced by @xmath76 and @xmath84 , respectively .",
    "we can and will take the scale function @xmath85 .",
    "we assume @xmath86 we will also assume that the estimators @xmath50 and @xmath87 are such that @xmath88 this condition is known to hold for various estimators of @xmath52 and @xmath89 ; see de haan and ferreira [ ( @xcite ) , chapters  3 and 4 ] . define @xmath90 note that , as @xmath91 , @xmath92    [ th:1d ] let @xmath93 be a sequence of numbers in @xmath94 such that @xmath95 as @xmath96 .",
    "assume that ( [ aaa ] ) and its left - tail counterpart hold ; also assume @xmath97 as @xmath96 .",
    "then , if ( [ bbb ] ) , ( [ ccc ] ) , ( [ ddd ] ) and ( [ eee ] ) hold , we have @xmath98    the condition on @xmath93 and @xmath62 specializes to @xmath99    [ re1 ] the main focus of this paper is on the tails where both @xmath23 and @xmath38 are small , and as such , @xmath100 ( just like @xmath101 ) is inherently small as well .",
    "this implies that the usual consistency statement @xmath102 is not particularly meaningful for assessing the performance of @xmath23 as an estimator of @xmath38 .",
    "instead , we consider the ratio consistency in terms of @xmath28 as stated in theorem  [ th:1d ] .",
    "note that , in addition to the usual consistency latexmath:[$\\sup_x    for @xmath19 , when @xmath104 , but _ not _ when @xmath105 tends to a nonnegative constant ; cf .",
    "( [ sw ] ) below .",
    "this shows that the region for which @xmath106 is close to 1 ( for large @xmath16 and with high probability ) is much greater than that for @xmath29 .",
    "[ re2 ] it is natural to consider an asymptotic normality result instead of the consistency result in theorem  [ th:1d ] , but note that the convergence rate ( @xmath107 , say , with , @xmath108 ) for the process @xmath28 in such a result will be determined by @xmath109-values with @xmath110 ; at a fixed @xmath48 the weak limit of @xmath111 will be 0 .",
    "this means that a proper refinement of theorem  [ th:1d ] , specifying the rate of convergence and providing a nondegenerate limit , is not possible . on the other hand , if we consider a single @xmath112 in the right tail such that @xmath113 , then it follows from theorem  4.4.1 in @xcite ( under the assumptions there ) that for some @xmath114 and @xmath115 @xmath116 since @xmath117 , see ( [ eq4 ] ) , with probability tending to one",
    "indeed , the convergence rate here is slower than for fixed @xmath48 : @xmath118 .",
    "we next consider constructing the refined half - space depth estimator in the more interesting , multivariate case , that is , @xmath119 .",
    "let @xmath0 be i.i.d .",
    "random vectors drawn from a common continuous distribution function @xmath31 . to refine @xmath19",
    "we need now some more structure for @xmath31 .",
    "more precisely , we assume multivariate regular variation for @xmath31 , that is , there exists a measure @xmath120 such that @xmath121 for every borel set @xmath122 on @xmath123 that is bounded away from the origin and satisfies @xmath124 ; see , for example , @xcite .",
    "note that the choice of the `` spherical '' @xmath10-norm is not relevant : any other norm can be used instead .",
    "this implies that for some @xmath125 @xmath126 the parameter @xmath127 is called the tail index and @xmath128 is the extreme value index .",
    "note that , for all @xmath40 , @xmath129 .",
    "we further require @xmath130 this simple condition in effect replaces the second - order condition of the univariate case , although it is a slightly weaker condition ; cf .",
    "cai , einmahl and de  haan ( @xcite ) , page 1807 .",
    "we also assume that @xmath131 and that , with @xmath132 , @xmath133 note that the continuity of the @xmath134 implies the continuity of @xmath38 . also , observe that the multivariate regular variation condition ( [ nu ] ) implies that for every unit vector @xmath135 , @xmath134 is in the univariate max domain of attraction with the same @xmath136 : as @xmath91 , @xmath137    recall that the half - space depth , relative to @xmath138 , is defined as @xmath139 to estimate @xmath11 , we only need to estimate the one - dimensional tail probabilities @xmath140 along each projection direction @xmath135 .",
    "since we already know how to construct the refined estimator for a tail probability in the one - dimensional case , we are now ready to define our refined empirical half - space depth @xmath23 in dimension  @xmath141 .    more specifically , fix a direction ( a unit vector ) @xmath135 . consider the univariate data @xmath142 , @xmath143 .",
    "we can refine the tail probability estimator of the @xmath144 similarly as in the previous subsection , but since @xmath145 we can use @xmath146 .",
    "this leads , for @xmath147 , to a simplified estimator of the right - tail probabilities : @xmath148 cf .",
    "( [ eq2_4 ] ) and ( [ eq4 ] ) .",
    "the estimator @xmath149 will be based on the @xmath150 .",
    "we will assume that @xmath50 is such that @xmath151 for @xmath152 an estimator of @xmath153 is simply @xmath154 , with @xmath155 the empirical distribution function of @xmath156 .",
    "denote the thus obtained estimator of @xmath157 with @xmath158 .",
    "this leads to the refined estimator of @xmath11 : @xmath159 next , we present the analogue of theorem  [ th:1d ] for the multivariate @xmath23 . note that it is much more complicated to analyze @xmath23 here than in dimension one , since for every @xmath5 we have infinitely many directions @xmath135 instead of only two .",
    "[ 2 ] let @xmath93 be a sequence of numbers in @xmath94 such that @xmath95 as @xmath96 .",
    "also assume @xmath160 as @xmath96 .",
    "then , if ( [ nu ] ) , ( [ bbb ] ) , ( [ radi ] ) , ( [ fff ] ) , ( [ inf ] ) and ( [ gamma ] ) hold , we have @xmath161    [ re3 ] it is known that the half - space depth is affine invariant .",
    "this means that the depth value does not change under a linear transformation .",
    "specifically , @xmath162 , where @xmath163 indicates the depth value based on the sample @xmath164 . here , @xmath165 is a @xmath166 nonsingular matrix and @xmath167 .",
    "although this property does not hold for @xmath23 exactly , it holds approximately through ( [ theo2 ] ) .",
    "[ re4 ] the class of multivariate regularly varying distributions [ see ( [ nu ] ) ] is quite broad .",
    "it contains , for example , all elliptical distributions with a heavy tailed radial distribution ( such as multivariate @xmath168-distributions ) and all distributions in the sum domain of attraction of a multivariate ( nonnormal ) stable distribution ; see , for example , @xcite , part iii .",
    "some examples are seen in section  [ sec2.3 ] .",
    "note in particular that the extreme density contours of such distributions can have more or less arbitrary shapes , not only spheres or ellipsoids .",
    "two such distributions , with nonconvex or asymmetric extreme density contours , can be found in cai , einmahl and de  haan ( @xcite ) .",
    "it is also worth noting that the multivariate regular variation condition can be verified using the test in @xcite .",
    "[ re5 ] for @xmath169 the statement of theorem  [ 2 ] holds when @xmath104 [ see ( [ i ] ) below ] but _ not _ when @xmath105 tends to a nonnegative constant , which again shows that @xmath106 is close to 1 ( for large @xmath16 and with high probability ) on a much larger region than where @xmath29 is .",
    "[ re6 ] ( i ) _ computation of @xmath23 _ : recall that when @xmath19 or @xmath170 is at least @xmath171 , then they are equal .",
    "let @xmath7 be such that @xmath172 and let @xmath173 with @xmath174 .",
    "based on ( [ eq : md ] ) , we obtain @xmath175 combination of both properties enables us to calculate @xmath23 readily by utilizing any available algorithm for computing @xmath19 .",
    "\\(ii ) _ computation of depth contour based on @xmath23 in figure  [ bestplotever ] _ : write @xmath176 .",
    "we need to find @xmath177 such that @xmath178 for all @xmath179 . for any",
    "fixed @xmath180 , similar to the above procedure for computing @xmath23 , we first find @xmath181 such that @xmath182 . then based on ( [ eq : rm6 ] ) , @xmath183 and @xmath178 .",
    "the @xmath23-depth contour in figure  [ bestplotever ] is drawn using 500 evenly distributed @xmath180 s in @xmath184 .",
    "[ re7 ] our estimator @xmath23 involves @xmath62 and its performance obviously will be affected by the choice of @xmath62 .",
    "the problem of choosing optimal @xmath62 is an inherent one in extreme value statistics .",
    "various approaches have been proposed in the literature .",
    "one commonly used heuristic approach is to plot the relevant estimator versus @xmath62 , visually identify the first ( or earliest ) stable ( approximately constant ) region in the plot , and then choose the midpoint of this region as @xmath62 .",
    "this approach is the one we used in our numerical studies below .",
    "we find more or less the same value of @xmath62 in the first few samples .",
    "for some specific problem settings , procedures for determining the optimal @xmath62 have been developed .",
    "it would be worthwhile developing such a procedure for @xmath23 .",
    "meanwhile , we note that even with the present choice of @xmath62 , which may well be only suboptimal , @xmath23 already clearly outperforms  @xmath19 .      in this section ,",
    "wepresent a simulation study to compare the performance of our refined empirical half - space depth @xmath23 with the performance of the original empirical half - space depth @xmath19 .",
    "we consider the following distributions in our simulation study :    * standard normal distribution .",
    "this is a light - tailed distribution with @xmath185 . * cauchy distribution",
    "this is a very heavy - tailed distribution with @xmath186 and @xmath187.[page11 ] * @xmath168-distribution with 2 degrees of freedom .",
    "this is a heavy - tailed distribution with @xmath188 and @xmath189 . * burr - type distribution , which is a symmetric distribution about 0 with density @xmath190 this distribution is less heavy - tailed with @xmath191 and @xmath187 . *",
    "standard bivariate normal distribution .",
    "this is a light - tailed distribution with @xmath192 .",
    "* bivariate spherical cauchy distribution with density @xmath193 this is a very heavy - tailed distribution with @xmath186 .",
    "* bivariate elliptical distribution with density ( @xmath194 ) @xmath195 this is a less heavy - tailed distribution with @xmath191 .",
    "* bivariate `` clover '' distribution with density ( @xmath196 ) @xmath197 this is again a less heavy - tailed distribution with @xmath191 , however , it is not an elliptical distribution ; see cai , einmahl and de  haan ( @xcite ) .",
    "* trivariate spherical cauchy distribution with density @xmath198 this is a very heavy - tailed distribution with @xmath186 . * quadrivariate spherical cauchy distribution with density @xmath199 this is again a very heavy - tailed distribution with @xmath186 .",
    "the first four distributions will be used to assess the finite sample performance of theorem  [ th:1d ] ( although for the standard normal distribution @xmath81 does not hold ) , and the last five distributions are used to assess the finite sample performance of theorem  [ 2 ] .    for each of the above distributions , we first generate a random sample of size 500 .",
    "based on this random sample , @xmath23 and @xmath19 are then calculated for a point @xmath7 where the theoretical depth @xmath11 is @xmath200 , @xmath201 , @xmath202 and @xmath203 , respectively .",
    "to calculate @xmath23 , an estimator of @xmath136 ( and @xmath89 ) is needed . for the univariate distributions , we use the moment estimator of @xcite for estimating @xmath52 and for @xmath89 we use a corresponding estimator ; see formula ( 4.2.4 ) in @xcite . for the multivariate distributions ( except the bivariate normal ) , since we assume that @xmath145 , we use the @xcite estimator , based on the @xmath150 . for the bivariate normal distribution , because it does not satisfy the conditions of theorem  [ 2 ] , we use ( [ eq4 ] ) instead of ( [ eq : md ] ) to estimate the right - tail probability of the @xmath144 .",
    "in other words , @xmath204 \\biggr)^{-1/\\hat\\gamma},\\ ] ] where @xmath205 is the moment estimator based on the @xmath150 , @xmath206 , and @xmath207 is again as in ( 4.2.4 ) in @xcite . since ( [ eq : rm6 ] )",
    "does not hold for this case any more , we follow @xcite to approximate @xmath23 using 500 @xmath135 s that are uniformly and independently distributed on the unit sphere . for all 10 distributions the value of @xmath62 is selected by searching visually for the first stable part in the plots , based on 3 to 5 samples , as described in more detail in remark  [ re7 ] .",
    "this leads to values of @xmath62 ranging from 50 to 100 : 6 times 50 , twice 75 and twice 100 .",
    "( left ) and @xmath106 ( right ) at 4 decreasing levels under normal distribution ; burr - type distribution ; @xmath168-distribution with 2 degrees of freedom ; cauchy distribution . ]",
    "( left ) and @xmath106 ( right ) at 4 decreasing levels under bivariate normal distribution ; bivariate spherical cauchy distribution ; bivariate elliptical distribution ; bivariate clover distribution ; trivariate spherical cauchy distribution ; quadrivariate spherical cauchy distribution . ]",
    "we carry out the above simulation 100 times for each of the distributions .",
    "the boxplots of @xmath208 and @xmath209 for each of the four depth levels from the 100 simulations for different distributions are plotted in figures  [ fig:1d ] and [ fig:2d ] .",
    "as we can see from those boxplots , for all the four depth levels and all the distributions except the bivariate normal distribution , the @xmath210 are all well centered at 1 . in contrast , the original empirical halfspace depth @xmath19 can only provide a reasonable estimate of @xmath38 when @xmath38 is not too small .",
    "when @xmath11 is small relative to @xmath16 , most of the @xmath20 are zero .",
    "these results support the theoretical findings that @xmath23 is a better estimator than @xmath19 in the tail . for the bivariate normal distribution , although it does not satisfy the assumptions of theorem  [ 2 ] , the performance of @xmath23 is still much better than the performance of @xmath19 .",
    "in this section , we present two applications where @xmath23 significantly improves the performance of the depth based procedures over @xmath19 .",
    "the first one is statistical process control ( spc ) .",
    "spc is the application of statistical methods to the monitoring of a process outcome in order to detect abnormal variations of the process from a specified in - control distribution .",
    "it has many applications in manufacturing processes .",
    "a typical setup for spc is the following .",
    "there are @xmath16 i.i.d .",
    "historical ( reference ) data for the monitored process outcome , denoted by @xmath0 @xmath211 @xmath212 , from the in - control process .",
    "let @xmath213 be the underlying distribution of the @xmath214 , also referred to as the in - control distribution .",
    "let @xmath215 be future observations of the process outcome , under the distribution @xmath216 .",
    "the task of spc is to determine if @xmath216 is the same as @xmath213 and if not , to signal when @xmath216 changes from @xmath213 as early as possible .    when the process outcome is multivariate and follows a multivariate normal distribution , an spc procedure with a false alarm rate @xmath127 can be defined as follows : @xmath217 is out of control if @xmath218 , where @xmath219 , @xmath220 , @xmath221 , and @xmath222 is the upper @xmath127 quantile of an @xmath31 distribution with @xmath141 and @xmath223 degrees of freedom .",
    "the above procedure requires that the process outcome follows a multivariate normal distribution .",
    "therefore , we refer to it as the parametric spc procedure hereafter . in many real world applications , the normality assumption may not hold .",
    "therefore , a nonparametric spc procedure is more desirable . following @xcite , a nonparametric spc procedure with a false alarm rate @xmath127 can be defined as follows : @xmath217 is out of control if @xmath224 , where @xmath38 is the depth with respect to @xmath213 . since the in - control",
    "distribution is usually unknown in practice , @xmath38 in the above procedure is usually replaced by @xmath19 , the empirical depth with respect to the historical data , @xmath0 .    due to its completely nonparametric nature and its capability of characterizing the geometric structure of the underlying distribution ,",
    "the half - space depth is a popular choice in the above depth based spc procedure .",
    "because the future process outcomes @xmath217 that lie in the outskirts of the historical data are more of concern in this spc procedure , how close the achieved false alarm rate to the nominal level @xmath127 depends on how well the empirical half - space depth @xmath19 estimates the theoretical half - space depth @xmath38 for those points . as shown in this paper , this estimation is not satisfactory when @xmath16 is not large enough",
    ". therefore , the achieved false alarm rate can severely deviate from its nominal level @xmath127 when @xmath19 is used . to overcome this drawback of using @xmath19",
    ", we use our refined halfspace depth @xmath23 in the above spc procedure instead . based on the results in section  [ sec2 ]",
    ", we expect the above depth based spc procedure will achieve the nominal false alarm rate if @xmath23 is used .    to demonstrate the performance of the @xmath23 based spc procedure , we carry out the following simulation .",
    "we first generate @xmath22 historical data @xmath214 from the standard bivariate normal distribution .",
    "we then generate another @xmath225 future observations @xmath217 from the same bivariate normal distribution .",
    "we apply to the 5000 @xmath217 the following three spc procedures : the parametric procedure , the @xmath19 based procedure and the @xmath23 based procedure .",
    "we calculate @xmath23 for the bivariate normal distribution as described in the previous section .",
    "the nominal false alarm rate @xmath127 for each procedure is set to be at 0.0027 ( the false alarm rate for the popular 3-sigma procedure in the univariate normal setting ) . the achieved false alarm rate for each procedure is then calculated as the proportion of @xmath217 being labeled as out - of - control by its spc procedure .",
    "we repeat this simulation 100 times .",
    "the boxplots of the achieved false alarm rates from these 100 simulations for different spc procedures are shown in figure  [ fig : qc0](a ) .    as we can see from the plot",
    ", the parametric procedure can achieve the nominal false alarm rate as expected , since the normality assumption is satisfied in this case .",
    "in contrast , the achieved false alarm rate for the @xmath19 based procedure is far higher than the target value 0.0027 .",
    "it is not surprising since all the @xmath217 outside the convex hull of the @xmath214 will have zero @xmath19 and will be labeled as out - of - control , but some of those @xmath217 may have nonzero @xmath38 and may have been labeled as in - control if @xmath38 was used . from the plot , we can see that our @xmath23 based procedure can successfully correct the inflated false alarm rate of the @xmath19 based procedure and yields the false alarm rate near the target value 0.0027 .",
    "we run the same simulations as above on the data generated from the bivariate elliptical distribution of section  [ sec2.3 ] .",
    "since the bivariate elliptical distribution satisfies the conditions of theorem  [ 2 ] , here we use @xmath23 based on ( [ eq : md ] ) . figure  [ fig : qc0](b )",
    "shows the corresponding boxplots of the achieved false alarm rates from 100 simulations for different spc procedures . as seen from the plot",
    ", the parametric procedure can no longer achieve the nominal false alarm rate since the normality assumption does not hold in this case .",
    "the @xmath19 based procedure still yields a far higher false alarm rate than the nominal level , while our @xmath23 based procedure can achieve the nominal false alarm rate as expected .",
    "based procedure and the @xmath23 based procedure under bivariate normal distribution ; bivariate elliptical distribution . ]    to demonstrate the detection power of our @xmath23 based procedure for process changes , we also carry out the following simulations .",
    "similar to the above false alarm rate study , we first generate @xmath22 historical data @xmath214 from the standard bivariate normal distribution .",
    "we then generate @xmath225 future observations @xmath217 from another bivariate normal distribution mimicking the following three process changes : ( i ) location change from @xmath226 to @xmath227 ; ( ii ) scale increase from 1 to 2 ; ( iii ) both changes in ( i ) and ( ii ) .",
    "since the @xmath19 based procedure fails to achieve the nominal false alarm rate , we only compare the detection power of the parametric procedure and our @xmath23 based procedure . to benchmark the performance",
    ", we also include the procedure based on the theoretical @xmath38 ( @xmath38 based procedure ) in the comparison . in spc , a common way to measure the detection power of spc procedures is through the average run length ( arl ) .",
    "arl is the expected number of times a process needs to be sampled until a specified change in the process is detected as out - of - control by the control chart in use .",
    "figure  [ fig : qc2 ] shows the boxplots of the arls from 100 simulations for the three procedures under the three process changes . as we can see from the plots , the parametric procedure and the @xmath38 based procedure perform very similarly . our @xmath23 based procedure yields slightly smaller arls than the @xmath38 based procedure . this can be explained by @xmath23 s slightly larger false alarm rate than the nominal one in figure  [ fig : qc0](a ) .",
    "based procedure , the parametric procedure and the @xmath23 based procedure under bivariate normal distribution for location change from @xmath226 to @xmath227 ; scale increase from 1 to 2 ; both changes in and . ]    we repeat the above arl study on the data generated from the bivariate elliptical distribution . similarly , we consider the following three process changes : ( i ) location change from @xmath226 to @xmath228 ; ( ii ) scale increase from 1 to 2 ; ( iii ) both changes in ( i ) and ( ii ) .",
    "since the parametric procedure does not achieve the nominal false alarm rate in this bivariate elliptical setting , we only compare the arls of the @xmath38 based procedure and our @xmath23 based procedure .",
    "figure  [ fig : qc1 ] shows the boxplots of arls of the two procedures under different process changes . as expected , our @xmath23 based procedure performs well compared with the impractical procedure based on the unknown @xmath38 .     based procedure and the @xmath23 based procedure under bivariate elliptical distribution for location change from @xmath226 to @xmath228 ; scale increase from 1 to 2 ;  both changes in and . ]",
    "another application in which the refined half - space depth @xmath23 helps improve the performance is the classification problem .",
    "classification is one of the most practical subjects in statistics .",
    "it has many important applications in different fields . for simplicity",
    ", we only focus on two - class classification problem here .",
    "in this case , we observe two training samples @xmath229 and @xmath230 from distributions @xmath31 and @xmath231 , respectively .",
    "the goal of the classification problem is to assign the future observation @xmath232 to either @xmath31 or @xmath231 based on some classification rule built on the two training samples .",
    "recently @xcite developed a nonparametric classification procedure , called _ dd_-classifier , using the _ dd_-plot ( depth vs. depth plot ) introduced in @xcite .",
    "for any two samples , the _",
    "the depth values of those pooled sample points with respect to one sample against their depth values with respect to the other sample . the basic idea behind the _",
    "dd_-classifier is to look for a curve that best separates the two samples in their _ dd_-plot .",
    "since the best separating curve in the _ dd_-classifier is required to pass through the origin in the _",
    "dd_-plot , any future observations having zero depth values with respect to both samples will be on the separating curve , indicating that they can be from either sample .",
    "therefore , those observations will be randomly assigned to either sample . when the @xmath19 of the half - space depth is used in constructing the _ dd_-plot , any point which lies outside of the convex of both samples will have zero half - space depths with respect to both samples .",
    "based on the _",
    "dd_-classifier , those points will be randomly assigned to either of the two samples , which will yield roughly a @xmath233 misclassification rate for those points .",
    "this simply implies that when using @xmath19 in the _ dd_-classifier one loses all the information contained in those points .",
    "next , we present a simulation study showing that the misclassification rate of those points can be improved by using @xmath23 instead of @xmath19 in the _ dd_-classifier .",
    "the first simulation setting we consider is when both @xmath31 and @xmath231 are bivariate normal distributions .",
    "we set @xmath31 as the standard bivariate normal distribution , and @xmath231 is another bivariate normal distribution which differs from @xmath31 in ( i ) location ; ( ii )  scale ; ( iii ) both location and scale .",
    "( the location difference is 2 for both coordinates ; the scale difference is also 2 for both coordinates . ) for each of the three choices of @xmath231 , we generate a training set consisting of @xmath234 and @xmath22 observations from @xmath31 and @xmath231 , respectively . based on this training set",
    ", we obtain the linear _",
    "dd_-classifier using @xmath23 to construct the _ dd_-plot .",
    "another 5000 test observations ( 2500 from each group ) are then generated . among those 5000 observations ,",
    "the misclassification rate for the points which have zero @xmath19 values with respect to both training samples are computed .",
    "this experiment is repeated 100 times and the misclassification rates for those points are then summarized in a boxplot for each choice of @xmath231 in figure  [ fig : cl](a ) .     under bivariate normal distribution ; bivariate elliptical distribution . ]",
    "we repeat this simulation on the data where both @xmath31 and @xmath231 are bivariate elliptical distributions ; @xmath31 corresponds to the elliptical density of section  [ sec2.3 ] . again",
    "three kinds of differences are considered : ( i ) @xmath31 and @xmath231 differ in location ; ( ii ) @xmath31 and @xmath231 differ in scale ; ( iii ) @xmath31 and @xmath231 differ in both location and scale .",
    "( the location difference is 4 for both coordinates ; the scale difference is 2 for both coordinates . )",
    "the boxplots of the misclassification rates for the test observations which have zero @xmath19 values with respect to both training samples are shown in figure  [ fig : cl](b ) .    as mentioned earlier , if @xmath19 is used in the _",
    "dd_-classifier , the misclassification rate for the points which lie outside of the convex hull of both samples is roughly @xmath233 .",
    "therefore , as seen from figure  [ fig : cl ] , the _ dd_-classifier paired with @xmath23 substantially improves the classification results for those points .",
    "we have seen that both applications of the half - space depth in spc and classification gain substantially from the proposed refinement @xmath23 . in general",
    ", we can expect similar gains from using @xmath23 in statistical inference methods involving depth ranks or extreme depth contours , for example , determining @xmath235-values using depth in @xcite ; constructing multivariate spacings and tolerance regions in @xcite .",
    "there are many other well - known depth functions [ e.g. , the spatial depth @xcite , the mahalanobis depth @xcite , the projection depth @xcite , etc . ] which are not computed from the empirical distribution function , and hence they do not have the said problem in this paper . while these depths are useful for many applications , they are either parametric in nature or lack of the needed distributional properties to ensure the desired probability masses associated with the central regions formed by the depth ranks or contours . when these properties are essential , the applications may be better served by using the two geometric depths .",
    "case in point are the examples mentioned in the preceding paragraph .",
    "this in part explains the importance in refining the empirical half - space depth .",
    "it is easy to see that the problem we faced in this paper stems from the use of the empirical distribution in computing the half - space probabilities .",
    "a natural solution then would be to consider instead a smoothed version of the empirical distribution that does not have point masses and is supported on the entire @xmath123 .",
    "it is worth noting that our proposed refinement is in fact such a smoothed version of the empirical distribution function in the tail , with the smoothing done by way of extreme value statistics .",
    "this extreme - value - theory based smoothing not only has the advantages of both breaking ties in the tail and yielding positive values , but , most importantly , it also produces a statistically much better estimator of the half - space depth in the tail , as shown in our theorems and applications",
    ".    it would be worthwhile to investigate whether the extreme - value - theory approach proposed in this paper can be modified to refine the empirical simplicial depth or other depth functions that also use the empirical counts based on the data .",
    "the modifications , if any , would seem quite nontrivial , since those depth functions do not have such a clear form of univariate projections as that of the half - space depth .",
    "proof of theorem  [ th:1d ] write @xmath236 for the quantile function , the left - continuous inverse of @xmath31 .",
    "we split the region over which the supremum is taken into three regions : @xmath237 $ ] , @xmath238 , and @xmath239 $ ] .",
    "because of symmetry , the first and last region can be dealt with similarly . therefore , we only consider the latter two regions .    for @xmath240 , we easily see that @xmath241 \\\\[-8pt ] \\nonumber & \\leq&\\max \\biggl(\\frac{f_n(x)}{f(x ) } , \\frac { s_n(x ) } { s(x ) } \\biggr).\\end{aligned}\\ ] ] we have that @xmath242 see , for example , shorack and wellner [ ( @xcite ) , page  424 ] .",
    "since @xmath243 and @xmath244 with probability tending to one ( @xmath245 ) , it follows from ( [ sw ] ) and ( [ mm ] ) that @xmath246    hence , it remains to consider the supremum over the region @xmath247 $ ] .",
    "we have with probability tending to one , as @xmath245 , @xmath248 write @xmath249",
    ". then we have @xmath250 ; see , for example , theorem  2.4.1 in @xcite .",
    "therefore , to complete the proof of this theorem it suffices to show @xmath251    first , we consider the case @xmath252 .",
    "write @xmath253 .",
    "also , set @xmath254 we have @xmath255 \\biggr)^{-1/\\hat\\gamma } \\\\ & & \\qquad = d_n \\biggl(1+y_n \\biggl[(1+sa ) \\bigl(d_n^\\gamma-1\\bigr)-\\frac{\\hat b- b } { a}\\gamma \\biggr ] \\biggr)^{-1/\\hat\\gamma } \\\\ & & \\qquad= \\biggl(d_n^{-\\hat\\gamma}+y_nd_n^{-\\hat\\gamma}(1+sa ) \\bigl(d_n^\\gamma -1\\bigr)-\\frac{\\hat b- b } { a}\\gamma y_n d_n^{-\\hat\\gamma } \\biggr)^{-1/\\hat \\gamma } \\\\ & & \\qquad= \\biggl[d_n^{\\gamma-\\hat\\gamma } \\biggl(d_n^{-\\gamma } \\biggl[1-y_n(1+sa)-\\frac{\\hat b- b } { a}\\gamma y_n \\biggr]+y_n(1+sa ) \\biggr ) \\biggr]^{-1/\\hat \\gamma } \\\\ & & \\qquad= : \\bigl [ t_1(t_2+t_3 ) \\bigr]^{-1/\\hat\\gamma}.\\end{aligned}\\ ] ] we will now prove that @xmath256 , all _",
    "uniformly for @xmath48 such that @xmath257 _ [ @xmath258 . this will yield ( [ compl ] ) for @xmath252 .",
    "we have @xmath259 observe that @xmath260 hence , @xmath261 .",
    "consider @xmath262 .",
    "we have @xmath263 and @xmath264 .",
    "hence , ( [ finite ] ) yields @xmath265 .",
    "finally , @xmath266-b_n",
    "\\gamma y_n \\biggr ) \\\\ & = & \\frac{(ns(x))^\\gamma}{k^{\\gamma+1/2}}o_p(1)=o_p(1).\\end{aligned}\\ ] ]    consider now the case @xmath192 . by convention @xmath267 now .",
    "write @xmath268 \\biggr)^{-1/\\hat\\gamma } \\\\",
    "& = & d_n \\biggl(1+\\hat\\gamma\\frac{a}{\\hat a}(\\log d_n ) ( 1+sa)-\\hat\\gamma \\frac{b_n } { \\sqrt{k } } \\frac{a}{\\hat a } \\biggr)^{-1/\\hat\\gamma}.\\end{aligned}\\ ] ] hence , @xmath269 we obtain @xmath270 hence , @xmath271 , uniformly for @xmath48 such that @xmath272 ( @xmath273 ) .",
    "this proves ( [ compl ] ) for @xmath192 .    for the proof of theorem  [ 2 ] , we need two lemmas . in the sequel , we assume that the conditions of theorem  [ 2 ] are in force .",
    "write @xmath274 for the unit sphere .",
    "[ l1 ] for all @xmath275 , @xmath276    fix @xmath275 . combining ( [ nu ] ) and ( [ radi ] ) we have that for all @xmath277",
    ", @xmath278 assume this convergence does not hold uniformly in @xmath277 .",
    "then there exist sequences @xmath279 and @xmath280 such that @xmath281 w.l.o.g .",
    "we assume that @xmath282 .",
    "we show that ( [ nocon ] ) can not hold by showing , for @xmath277 , @xmath283 because if the latter convergence holds , then if @xmath284 , @xmath285    hence , it remains to show ( [ ep ] ) .",
    "write @xmath286 .",
    "then @xmath287 . we have @xmath288 hence , @xmath289 similarly , we have @xmath290 and @xmath291 this completes the proof of ( [ ep ] ) .",
    "define the function @xmath292 by @xmath293 and let @xmath294 , be the tail quantile function corresponding to @xmath134 .",
    "[ l3 ] we have @xmath295    lemma  [ l1 ] , with @xmath296 , yields @xmath297 observe that @xmath298 implies @xmath299 .",
    "hence @xmath300 also observe that assumption ( [ inf ] ) and @xmath301 , yield @xmath302 combining this with ( [ uf ] ) and ( [ unif ] ) easily yields ( [ u ] ) .    proof of theorem  [ 2 ] we will prove that , as @xmath303 , @xmath304 to show that ( [ i ] ) and ( [ ii ] ) imply ( [ theo2 ] ) , it is sufficient to show that ( [ i ] ) implies @xmath305 and to recall that if @xmath306 or @xmath307 , then @xmath308 .",
    "assume ( [ i ] ) holds .",
    "it follows from @xcite , that@xmath309 , with probability 1 .",
    "hence , for large @xmath16 , any point @xmath310 with maximum depth @xmath19 , satisfies @xmath311 and , with probability tending to one , @xmath312 , because of the uniform consistency of @xmath19 .",
    "now assume for some @xmath7 , @xmath306 and @xmath313 .",
    "then , with probability tending to one , we can find @xmath314 on the straight line connecting @xmath310 and @xmath7 , such that @xmath315 and because of ( [ i ] ) , @xmath316 .",
    "it is well known that @xmath19 has the `` monotonicity relative to deepest point '' property [ see , e.g. , @xcite ] , and hence @xmath317 .",
    "hence ( [ c ] ) .",
    "it remains to prove ( [ i ] ) and ( [ ii ] ) .",
    "we begin with ( [ i ] ) .",
    "first , we show that @xmath318 define @xmath319 .",
    "lemma  [ l1 ] yields that , uniformly in @xmath277 , @xmath320 hence , for small enough @xmath321 and uniformly in @xmath277 , @xmath322 . for @xmath277",
    ", let @xmath323 be the smallest @xmath324 such that @xmath325 . then for small enough @xmath321 , @xmath326 .",
    "hence , by ( [ nu ] ) and ( [ radi ] ) , @xmath327 which implies ( [ alex ] ) .    using ( [ alex ] ) , we obtain from theorem  5.1 in @xcite , with the @xmath328 there equal to @xmath329 , that @xmath330    denote with @xmath331 a half - space with @xmath7 on its boundary .",
    "we have @xmath332 and , with @xmath333 , for some @xmath334 , @xmath335 this , in combination with ( [ alexth ] ) , yields ( [ i ] ) .    finally , we consider ( [ ii ] ) .",
    "write @xmath336 .",
    "we first show @xmath337 write @xmath338",
    ". then @xmath339 \\\\[-8pt ] \\nonumber & = & \\biggl(d_\\u^{-1/\\widehat\\alpha}(w ) \\frac{w}{v_\\u({n}/{k } ) } \\biggr)^{-\\widehat\\alpha } \\biggl(\\frac{v_\\u({n}/{k})}{w_{n - k : n } } \\biggr)^{-\\widehat\\alpha}.\\end{aligned}\\ ] ] it follows from lemmas [ l1 ] and [ l3 ] that @xmath340",
    "using this , ( [ gamma ] ) and @xmath160 , we obtain @xmath341 denote with @xmath342 the empirical distribution function of the uniform-@xmath343 random variables @xmath344 , and with @xmath345 the corresponding quantile function .",
    "it follows from ( [ alexth ] ) by routine arguments that @xmath346 and hence , by lemma  [ l3 ] and ( [ gamma ] ) , that @xmath347 combination of ( [ pdp2 ] ) , ( [ ratio ] ) and ( [ g ] ) , yields ( [ pdp ] ) .",
    "now we turn to ( [ ii ] ) .",
    "let @xmath7 be such that @xmath348 .",
    "then @xmath349 \\\\[-8pt ] \\nonumber & \\geq&\\frac{\\inf_{\\u\\in\\theta :   p_{n,\\u}(\\u^t\\x)<k / n }    p_{n,\\u}(\\u ^t\\x)}{\\inf_{\\u\\in\\theta :   p_{n,\\u}(\\u^t\\x)<k / n }     p_{\\u}(\\u^t\\x ) } \\geq\\inf_{\\u\\in\\theta :   p_{n,\\u}(\\u^t\\x)<k / n } \\frac{p_{n,\\u}(\\u^t\\x ) } { p_{\\u}(\\u^t\\x)}.\\end{aligned}\\ ] ] next , we show that with probability tending to one ( @xmath96 ) , @xmath350 assume for some @xmath7 and @xmath277 , @xmath351 and @xmath352 .",
    "then there exists an @xmath314 of the form @xmath353 , for some @xmath354 , such that @xmath355 .",
    "hence , with probability tending to one because of ( [ pdp ] ) , @xmath356 and , therefore , @xmath357 . contradiction .",
    "hence , we have ( [ z ] ) . combining ( [ z ] ) with ( [ geq ] ) and ( [ pdp ] ) , yields @xmath358    let @xmath359 and let @xmath7 be such that @xmath348 and @xmath360 .",
    "we have for some @xmath361 that @xmath362 with @xmath363 . if @xmath364 , then with probability tending to one , ( [ pdp ] ) yields that @xmath365 , and hence that @xmath366 . in case @xmath367",
    ", we have , using ( [ max ] ) , that with probability tending to one that @xmath368 .",
    "hence , combining @xmath369 with ( [ alexth ] ) and ( [ pdp ] ) , we obtain that with probability tending to one , @xmath370 .",
    "hence , we have shown @xmath371 this , in combination with ( [ max ] ) , yields ( [ ii ] ) .",
    "we thank an associate editor and three referees for many insightful questions and comments , which helped improve greatly this paper .",
    "we also thank laurens de haan for his helpful discussions , in particular about the univariate second - order condition .",
    "hallin , m. , paindaveine , d.  and iman , m. ( 2010 ) .",
    "multivariate quantiles and multiple - output regression quantiles : from @xmath372 optimization to halfspace depth ( with discussion ) . _",
    "the annals of statistics _ * 38 * 635703 ."
  ],
  "abstract_text": [
    "<S> statistical depth measures the centrality of a point with respect to a given distribution or data cloud . </S>",
    "<S> it provides a natural center - outward ordering of multivariate data points and yields a systematic nonparametric multivariate analysis scheme . </S>",
    "<S> in particular , the half - space depth is shown to have many desirable properties and broad applicability . </S>",
    "<S> however , the empirical half - space depth is zero outside the convex hull of the data . </S>",
    "<S> this property has rendered the empirical half - space depth useless outside the data cloud , and limited its utility in applications where the extreme outlying probability mass is the focal point , such as in classification problems and control charts with very small false alarm rates . to address this issue </S>",
    "<S> , we apply extreme value statistics to refine the empirical half - space depth in `` the tail . '' </S>",
    "<S> this provides an important linkage between data depth , which is useful for inference on centrality , and extreme value statistics , which is useful for inference on extremity . </S>",
    "<S> the refined empirical half - space depth can thus extend all its utilities beyond the data cloud , and hence broaden greatly its applicability . the refined estimator is shown to have substantially improved upon the empirical estimator in theory and simulations . </S>",
    "<S> the benefit of this improvement is also demonstrated through the applications in classification and statistical process control .    </S>",
    "<S> ./style / arxiv - general.cfg    , </S>"
  ]
}