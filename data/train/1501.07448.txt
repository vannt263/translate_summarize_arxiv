{
  "article_text": [
    "network complexity pervades biology and medicine @xcite , and the human organism can be considered as an integrated complex network of different physiological systems @xcite such as circulatory and respiratory systems , visual system , digestive and endocrine systems , etc .",
    ", which are coordinated by autonomic and central nervous systems including the brain .",
    "the dynamics of the sleep - wake transitions during the sleep of humans and other mammals @xcite presents one of important examples of such complex dynamics . in turn , functioning of the human brain presents is essence a network activity of the coupled and interrelated neurons surrounded by glia cells .",
    "the immense complexity of this subject matter @xcite does not exclude , but rather invites thinking in terms of simple physical modeling approaches , see e.g. in ref .",
    "@xcite , since even very simple physical models can display very complex behavior .",
    "the models of critical dynamical phenomena such as self - organized criticality ( soc ) @xcite are especially important in this respect @xcite .",
    "physical modeling can help to discriminate the physical and biological complexity from the complexity of mental processes , the `` form within '' @xcite , which is mediated but not determined in fine features by the background physical processes .",
    "the recently discovered complexity of the critical brain dynamics @xcite in essence does not have anything in common with the complexity of mental processes as it is already displayed by organotypic networks of neurons formed by cortical slices on a multi - electrode array @xcite .",
    "such physical complexity is in essence the complexity of crude matter that got self - organized following the physical laws .",
    "it thus belongs to statistical physics or system biophysics .",
    "physical models such as soc are especially important and helpful here .    the wilson and cowan model @xcite presents one of the well - established models of neuronal network dynamics @xcite .",
    "it incorporates individual elements in a simplest possible fashion as two - state stochastic oscillators with one quiescent state and one excited state , and random transitions between these two states which are influenced by the mutual coupling among the network elements .",
    "the model has been introduced in the deterministic limit of huge many coupled elements in complete neglect of the intrinsic mesoscopic noise and became immensely popular with the years @xcite , being used e.g. to describe neuronal oscillations in visual cortex within a mean - field approximation @xcite .",
    "recently , the previously neglected mesoscopic noise effects were incorporated in this model for a finite - size network @xcite .",
    "such a noise has been shown to be very important , in particular , for the occurrence of the critical avalanche dynamics @xcite absent in the deterministic wilson - cowan model and also for the emergence of oscillatory noisy dynamics @xcite . at the first glance ,",
    "such a noisy dynamics can look like a chaotic deterministic one .",
    "deterministic chaos influenced by the noise can also be a natural feature of a higher - dimensional dynamics , beyond the original two - dimensional wilson - cowan mean field model .",
    "indeed , deterministic chaos has been found in the brain dynamics some time ago @xcite .",
    "however , it can not be described within the memoryless wilson - cowan model because the minimal dimension for chaos is three @xcite .",
    "stochastic mesoscopic noise effects due to a finite number of elements in finite size systems attract substantial attention over several decades , especially with respect to chemical reactions on the mesoscale @xcite , being especially pertinent to the physico - chemical processes in living cells @xcite . in particular , such intrinsic noise can cause and optimize spontaneous spiking ( coherence resonance @xcite ) in the excitable clusters of ionic channels in cell membranes , which are globally coupled through the common membrane potential , or the response of such systems to periodic external signals ( stochastic resonance @xcite ) within a stochastic hodgkin - huxley model @xcite .",
    "finite - size networks of globally coupled bistable stochastic oscillators were also considered without relation to the wilson - cowan model @xcite , including non - markovian memory effects @xcite .    in this paper",
    ", we consider a class of higher - dimensional generalizations of the stochastic wilson - cowan model aimed to incorporate non - markovian memory effects in the dynamics of individual neurons .",
    "such effects are caused by the existence of a refractory period or inactivated state from which the neuron can not be excited immediately .",
    "first , we discuss a general class of such models .",
    "then , we apply the simplest two - state non - markovian model of this class , embedded as a three - state markovian model with one inactivated state , to study a critical avalanche dynamics in a balanced network of the excitatory and inhibitory neurons within a mean - field approximation . here , we restrict ourselves to the simplest example of a fully connected network with all - to - all coupling of its elements .",
    "in particular , we derive the power law exponents characterizing the critical self - organized dynamics of the network from the precise numerical simulations done with the dynamic monte carlo , or gillespie algorithm .",
    "we also compare these results with similar results obtained within approximate stochastic langevin dynamics , or , equivalently , within a diffusional approximation to the discrete state dynamics . here",
    ", we reveal a profound difference .",
    "let us depart from the markovian model of a neuron possessing one activated or excited state `` a '' , and a quiescent state `` q '' , see fig .",
    "[ fig1 ] , a. the excitation of the neuron occurs with the rate @xmath1 , where @xmath2 is a rate constant and @xmath3 is a dimensionless transfer function which depends on the states of the other neurons , and will be discussed below .",
    "let us assume for a while that @xmath3 is not explicitely time dependent .",
    "from the point of view of the theory of continuous time random walks ( ctrws ) or renewal processes @xcite , such a two state neuron can be completely characterized by the residence time distributions ( rtds ) in its two states , @xmath4 , and @xmath5 , correspondingly ( assuming that no correlations between the residence time intervals is present  the renewal or semi - markovian assumption ) .",
    "rtds define completely the trajectory realizations of such a renewal process . in the markovian case ,",
    "the rtds are strictly exponential , @xmath6 , and @xmath7 , where we denoted @xmath8 .",
    "then , such a trajectory description corresponds to the markovian balance or master equations for the probabilities to populate the states `` a '' and `` q '' , @xmath9 and @xmath10 , correspondingly . due to the probability conservation , @xmath11 , @xmath12 \\;.\\end{aligned}\\ ] ] the memory effect due to a delay of a new excitation event after the neuron comes into the quiescent state , or the existence of some refractory period @xmath13 , can be captured within the trajectory description by a non - exponential rtd @xmath5 .",
    "this transforms the corresponding master equation into a generalized master equation ( gme ) with memory , where the term @xmath14 is replaced by @xmath15 , with a memory kernel @xmath16 . here",
    ", @xmath17 is the starting time , @xmath18 , if not a different one is explicitely stated .",
    "hence , eq . ( [ markov1 ] )",
    "is replaced by @xmath19dt'\\;.\\end{aligned}\\ ] ] in the ctrw theory it is well - known how the memory kernel @xmath16 and the residence time distribution @xmath5 are related @xcite ( see also appendix of @xcite ) .",
    "namely , their laplace - transforms [ denoted as @xmath20 , for any function @xmath21 are related as @xmath22    in neurosciences , a delayed exponential , or delayed poissonian model is popular @xcite .",
    "it is featured by the absolute refractory period @xmath13 , i.e. @xmath23 , for @xmath24 , and the exponential distribution , @xmath25 $ ] , for @xmath26 , see in fig .",
    "this model corresponds to @xmath27 , and the memory kernel @xmath28 $ ] .",
    "the numerical inverse laplace transform of this memory kernel is depicted in the inset of fig .",
    "[ fig2 ] , b. notice that it does not correspond to the memory kernel @xmath29 , which would correspond to the master equation with the deterministic delay @xcite @xmath30 \\;.\\end{aligned}\\ ] ] however , this memory kernel is strongly peaked at @xmath31 , and can thus be approximated , with @xmath32 , which is the inverse mean time of the delayed poissonian distribution @xmath5 . in the corresponding markovian approximation , eq .",
    "( [ markov1 ] ) is restored with a renormalized transfer function , @xmath33 this is the simplest way to account for the delay effects .",
    "obviously , any delay should suppress excitability within this approximation , because @xmath34 .",
    "however , suppression of the excitability of the inhibitory neurons may enhance the excitability of the whole network consisting of both excitatory and inhibitory neurons .",
    "hence , possible effects are generally nontrivial even in this approximation . moreover , eq . ( [ renorm ] )",
    "makes it immediately clear that the delay effects are generally expected to be very substantial for @xmath35 .    , and two , @xmath36 , inactivated states in fig .",
    "[ fig1 ] , b , and fig .",
    "[ fig1 ] , c , with @xmath36 , correspondingly .",
    "inset in part ( b ) shows also the cases @xmath37 , @xmath38 , and @xmath39 ( delayed exponential ) .",
    "time @xmath40 is in the units of @xmath41 , and @xmath42 .",
    "numerical results in the inset were obtained by numerical inversion of the corresponding laplace - transform using the gaver - stehfest method with arbitrary precision @xcite to arrive at convergent results.,title=\"fig:\",height=181 ] , and two , @xmath36 , inactivated states in fig .",
    "[ fig1 ] , b , and fig .",
    "[ fig1 ] , c , with @xmath36 , correspondingly .",
    "inset in part ( b ) shows also the cases @xmath37 , @xmath38 , and @xmath39 ( delayed exponential ) .",
    "time @xmath40 is in the units of @xmath41 , and @xmath42 .",
    "numerical results in the inset were obtained by numerical inversion of the corresponding laplace - transform using the gaver - stehfest method with arbitrary precision @xcite to arrive at convergent results.,title=\"fig:\",height=181 ]      it is well - known that in many cases non - markovian ctrw dynamics can be embedded as some markovian dynamics in a higher - dimensional , possibly infinite dimensional space @xcite . given a non - trivial form of the memory kernel for the delayed exponential distribution of the quiescent times , we can ask the question : what is the simplest non - markovian model and the corresponding markovian embedding to account for the memory effects ?",
    "from the point of view of gme , it is @xmath43 , i.e. an exponentially decaying memory kernel . the corresponding memory kernel with @xmath44 , and",
    "@xmath45 corresponds to @xmath5 , which is the time convolution of two exponential distributions , @xmath46 , and @xmath47 .",
    "it corresponds to a compound state `` @xmath48 '' in fig .",
    "[ fig1 ] , b. indeed , the laplace transform of the corresponding compound distribution is just the product of the laplace - transforms of two exponential distributions , i.e. , @xmath49 $ ] . by eq .",
    "( [ laplace - kernel ] ) it corresponds precisely to the stated exponential memory kernel .",
    "the corresponding @xmath50/(\\nu-\\gamma)$ ] has a maximum at the most probable time interval @xmath51 , see fig .",
    "[ fig2 ] , a , reflecting the most probable stochastic time delay .",
    "this simplest non - markovian model with memory allows , however , for a very simple markovian embedding by introduction of an intermediated refractory state `` i '' shown in fig .",
    "[ fig1 ] , b , with the population probability @xmath52 and the exponential rtd given above .",
    "it has the mean refractory time @xmath53 , and the relative standard deviation , or the coefficient of variation , @xmath54 . using the conservation law , @xmath55 ,",
    "the corresponding master equations can be written either as @xmath56 or as    @xmath57    from ( [ 3state2b ] ) follows @xmath58dt'\\;.\\end{aligned}\\ ] ] after substitution of this equation into ( [ 3state2a ] ) one obtains indeed eq .",
    "( [ non - markov1 ] ) with the discussed exponential memory kernel provided that @xmath59 .",
    "the latter condition is natural because every sojourn in the compound quiescent state `` @xmath60 '' starts from the substate `` i '' ( resetting memory of this neuron to zero ) , and @xmath61 is the probability of the compound quiescent state within the two - state non - markovian reduction of the three - state markovian problem .",
    "here , one can also see the origin of a profound problem with the description of the whole network dynamics of interacting non - markovian renewal elements as a hyper - dimensional renewal process .",
    "obviously , the behavior of the whole network can not be considered as a renewal process , because after each and every de - excitation event only one element is reset .",
    "then it starts with zero memory , while all others keep their memory until they are reset . hence",
    ", any gillespie type simulation of the whole network of interacting non - markovian elements must account for the `` age '' of each network element separately .",
    "markovian embedding allows to circumvent this problem and dramatically accelerate simulations within the mean - field approximation , see below .",
    "the considered three - state markovian cyclic model presents one of the fundamental kinetic models in biophysics .",
    "it provides , in particular , a paradigm for non - equilibrium steady state cycling .",
    "for example , the cyclic kinetics of an enzyme @xmath62 , which binds a substrate molecule @xmath63 , converts it to a product @xmath64 , and releases it afterwards can be represented as a three - state cycle , @xmath65 .",
    "this model was used e.g. in ref .",
    "@xcite for an excitable unit .",
    "furthermore , three - state non - markovian models can be used with a non - exponential distribution @xmath66 .",
    "for example , if to use the deterministically delayed @xmath67 , and exponential @xmath5 within the three - state cyclic model , then one obtains the delayed exponential distribution within the two - state reduced model , which was discussed above .",
    "in addition , @xmath4 can also be non - exponential . for @xmath68 in the excited state of the three - state non - markovian model ,",
    "one obtains the model used in refs .",
    "@xcite .",
    "one can also introduce many delayed substates as shown in fig .",
    "[ fig1 ] , c. within the three - state non - markovian model this can be considered as having one delayed state `` i '' characterized by the special erlangian distribution @xcite , @xmath69 , with the laplace - transform @xmath70 reflecting the corresponding multiple convolution .",
    "such a non - markovian three - state model has been considered in @xcite , and a non - markovian two - state model with the erlangian distribution of the quiescent times has been studied in @xcite .",
    "the compound quiescent state corresponding to the model in @xcite is characterized by @xmath71 $ ] .",
    "the mean delay time is the same @xmath41 for any @xmath72 , and the coefficient of variation becomes ever smaller with increasing @xmath72 , @xmath73 , i.e. the distribution of the refractory times becomes ever more sharpened .",
    "the laplace - transformed memory kernel is @xmath74 $ ] .",
    "some corresponding @xmath5 and @xmath16 are shown in fig .",
    "[ fig2 ] . already for @xmath36 ,",
    "the memory kernel starts to show a peaked structure .",
    "notice that in the limit @xmath39 , the above delayed exponential ( or poissonian ) model immediately follows with @xmath41 . for any @xmath72 ,",
    "the inverse mean time in the quiescent state is given by @xmath75 with @xmath76 in ( [ renorm ] ) .",
    "increasing @xmath72 yields an ever better approximation for the delayed poissonian model .",
    "however , it can be considered as a useful model in itself .",
    "the corresponding markovian embedding master equation reads ( with @xmath77 excluded by the probability conservation law ) : @xmath78 with , @xmath79 , for @xmath80 , initially . with a different initial condition ,",
    "the corresponding gme obtained upon projection of the multi - dimensional dynamics onto the subspace of @xmath81 and @xmath77 variables will contain a dependence on this initial condition in the subspace of hidden markovian variables . on the level of non - markovian dynamics",
    "this can be accounted for by a different choice of the residence time distribution @xmath82 for the first sojourn in the quiescent state .",
    "it depends on how long this state has been populated before the dynamics started @xcite .",
    "the gme ( [ non - markov1 ] ) , ( [ laplace - kernel ] ) corresponds to the particular choice , @xmath83 .",
    "we mention in passing also that it is straightforward to consider a power - law distributed delay , both within a semi - markovian model and within an approximate finite - dimensional markovian embedding .",
    "also a stochastic model for bursting neurons can be introduced immediately .",
    "we shall not , however , consider these possibilities in the present work .      following wilson and cowan , we consider a network of @xmath84 excitatory and @xmath85 inhibitory neurons , with the probabilities of neurons to be in their excited states @xmath86 and @xmath87 , correspondingly .",
    "the neuron @xmath88 can influence the neuron @xmath89 and possibly itself ( @xmath90 ) , by excitation , or inhibition with the coupling constants , @xmath91 , @xmath92 for the excitatory neuron @xmath88 , and @xmath93 , @xmath94 , for the inhibitory neuron @xmath88 .",
    "the absolute value of the coupling constant reflects the synaptic strength .",
    "each excitatory neuron @xmath89 thus obtains an averaged input @xmath95 , and the inhibitory neuron @xmath96 receives the input @xmath97 , where @xmath98 and @xmath99 , etc .",
    "is the number of inputs which the @xmath100th neuron obtains from the excitatory and inhibitory neurons , correspondingly .",
    "the constants @xmath101 and @xmath102 serve to fix the spontaneous spiking rates , @xmath103 , @xmath104 , in the absence of coupling , @xmath105 .",
    "coupling can either enhance , or suppress these rates .",
    "phenomenologically , this is accounted for by the transfer function @xmath106 , which we assume to be the same for all neurons .",
    "some common biophysically motivated popular choices of the transfer function @xmath106 are @xmath107 where @xmath108 is the heaviside step function , and @xmath109\\;.\\end{aligned}\\ ] ] both are bounded as @xmath110 . evidently , this is a very rich model even for the simplest two - state model of neurons , in the absence of memory effects .",
    "the simplest further approximation to describe the collective dynamics of neurons is to invoke the mean field approximation @xcite .",
    "it is equivalent to assuming that all the coupling constants like @xmath111 , etc . , thresholds @xmath101 , etc . , and rates @xmath112 , @xmath113 , are equal within a subpopulation , @xmath114 , @xmath115 , @xmath116 , or @xmath117 , etc .",
    "furthermore , one can introduce the occupation numbers of the excited neurons in each population , @xmath118 , and @xmath119 , and consider the dynamics of these variables .",
    "they present the fractions of neurons which are excited .",
    "we restrict our treatment in the rest of this paper to the simplest two state non - markovian model within the three state markovian embedding and introduce the occupation numbers of neurons , @xmath120 , and @xmath121 , in the corresponding delayed states .",
    "then , in the deterministic limit @xmath122 , one obtains a 4-dimensional nonlinear dynamics , @xmath123 notice that unlike the original two - dimensional mean - field wilson - cowan dynamics in the deterministic limit , the considered 4-dimensional dynamics can in principle be chaotic , for some parameters ( which remains an open question ) .",
    "dynamical chaos might emerge already when only one sort of neurons , e.g. inhibitory neurons , exhibits delayed dynamics , since the minimal dimension for nonlinear chaotic dynamics is three",
    ". then , in the macroscopic deterministic limit , @xmath124 however , we shall not investigate the possibility of a deterministic chaos emerging due to a delay within the minimal extensions of the wilson - cowan model in the present work , but rather focus on the mesoscopic intrinsic noise effects caused by finite @xmath84 and @xmath85 .",
    "then , the occupational numbers are random variables ( at any fixed time @xmath40 ) .      for a very large number of neurons",
    ", one can account for the mesoscopic noise effect within the langevin dynamics , or the diffusional approximation of the discrete state birth - and - death process describing the evolution of the network .",
    "this procedure is standard , by analogy with the stochastic theory of chemical reactions @xcite .",
    "since we have only direct `` reactions '' like @xmath125 , @xmath126 , @xmath127 , for two type of neurons , one must introduce six variables and six independent zero - mean white gaussian noise sources @xmath128 , @xmath129 .",
    "stochastic dynamics is , however , effectively 4-dimensional because of two probability conservation laws , which allow to exclude two variables out of six : @xmath130 in the limit @xmath122 , the deterministic description in eq .",
    "( [ 4dim ] ) is restored .",
    "the noise is multiplicative and the langevin equations must be ito - interpreted , as it is always the case if the langevin dynamics results from the standard diffusional approximation to a birth - and - death process , or chemical master equation @xcite .",
    "notice that such a langevin stochastic description can become problematic , if any of the variables @xmath131 becomes temporally zero or one . even if some of the noise terms do vanish at the boundaries , where there corresponding rates vanish , the others do not , when a particular boundary is hit .",
    "hence , the occupational numbers can in principle become temporally negative , or larger than one .",
    "this unphysical feature is produced by the standard diffusional approximation .",
    "however , this problem can be fixed in the numerical simulations by introduction of the corresponding reflecting boundaries and taking sufficiently small integration time steps , as done e.g. in ref .",
    "@xcite for stochastic hodgkin - huxley equations .",
    ".transitions and rates [ cols=\"<,<,<\",options=\"header \" , ]     within the mean - field approximation of markovian dynamics , it suffices to count the numbers of neurons in the corresponding activated , @xmath132 and @xmath133 , and refractory , @xmath134 and @xmath135 states .",
    "then , we are dealing with a random walk on a 4-dimensional lattice @xmath136 with the discrete variables @xmath132 , and @xmath134 taking values in the range from zero to @xmath84 , and the variables @xmath133 and @xmath135 in the range from zero to @xmath85 , so that also @xmath137 and @xmath138 . from the site @xmath136",
    "six different transitions are possible .",
    "they are enlisted in table [ table1 ] with the corresponding transition rates .",
    "the master equation governing this birth - and - death process can be readily written .",
    "however , it is bulky and not very insightful . for this reason",
    ", it is not presented here .",
    "the corresponding stochastic process can be easily simulated with the dynamical monte carlo or gillespie algorithm @xcite , which is exact .",
    "namely , on each step one draws two random numbers . the first one , @xmath139 , is drawn from the exponential distribution characterized by the total rate @xmath140 .",
    "it gives a random time interval at which the network state is updated .",
    "given a uniformly distributed random variable @xmath141 , @xmath142 , @xmath143 .",
    "then , one of the transitions in table   [ table1 ] is chosen in accordance with its probability @xmath144 .",
    "for this , one generates a uniformly distributed random variable @xmath145 bounded as @xmath146 . if @xmath147 , then the first transition is chosen .",
    "if @xmath148 , then the second transition is chosen , etc .",
    ", i.e. in accordance with the length of the corresponding interval @xmath149 , @xmath150 .",
    "notice that an attempt to generalize this scheme towards a non - markovian renewal walk on a 4-dimensional lattice to account for the memory in the inactivated state is logically inconsistent because in such a case accomplishing each step would mean reset , or renewal of _ all _ neurons , and not the only one which actually makes transition .",
    "however , each non - markovian element has its individual memory . in a direct simulation of the network of non - markovian elements",
    "one must therefore consider them individually , even within the mean - field approximation .",
    "then , one has to consider ctrw on a hyper - dimensional lattice of huge dimensionality , which will dramatically slow down simulations imposing computational restrictions on the maximal size of the network .",
    "of course , beyond the mean field approximation one must also simulate each element separately . here , a direct semi - markovian approach can be preferred . in this work ,",
    "we restrict ourselves to the mean - field dynamics within the markovian embedding framework , which allows for exact simulations of very large networks within a reasonable computational time .",
    "plane for deterministic dynamics and for stochastic dynamics , @xmath151 , @xmath152 , with @xmath153 , ( b ) time - dependence of the @xmath81 variable for ( a ) .",
    "( c ) limiting cycle in the @xmath154 plane for deterministic dynamics and for stochastic dynamics with @xmath155 , and ( d ) the corresponding time - dependence of the @xmath81 variable .",
    "langevin simulations are done with the stochastic euler algorithm using time step @xmath156 in ( a ) and ( b ) , and @xmath157 in ( c ) and ( d).,title=\"fig:\",height=181 ]   plane for deterministic dynamics and for stochastic dynamics , @xmath151 , @xmath152 , with @xmath153 , ( b ) time - dependence of the @xmath81 variable for ( a ) .",
    "( c ) limiting cycle in the @xmath154 plane for deterministic dynamics and for stochastic dynamics with @xmath155 , and ( d ) the corresponding time - dependence of the @xmath81 variable .",
    "langevin simulations are done with the stochastic euler algorithm using time step @xmath156 in ( a ) and ( b ) , and @xmath157 in ( c ) and ( d).,title=\"fig:\",height=181 ] +     plane for deterministic dynamics and for stochastic dynamics , @xmath151 , @xmath152 , with @xmath153 , ( b ) time - dependence of the @xmath81 variable for ( a ) .",
    "( c ) limiting cycle in the @xmath154 plane for deterministic dynamics and for stochastic dynamics with @xmath155 , and ( d ) the corresponding time - dependence of the @xmath81 variable .",
    "langevin simulations are done with the stochastic euler algorithm using time step @xmath156 in ( a ) and ( b ) , and @xmath157 in ( c ) and ( d).,title=\"fig:\",height=181 ]   plane for deterministic dynamics and for stochastic dynamics , @xmath151 , @xmath152 , with @xmath153 , ( b ) time - dependence of the @xmath81 variable for ( a ) .",
    "( c ) limiting cycle in the @xmath154 plane for deterministic dynamics and for stochastic dynamics with @xmath155 , and ( d ) the corresponding time - dependence of the @xmath81 variable .",
    "langevin simulations are done with the stochastic euler algorithm using time step @xmath156 in ( a ) and ( b ) , and @xmath157 in ( c ) and ( d).,title=\"fig:\",height=181 ]    first , we test our stochastic simulations done with xppaut @xcite against nonlinear deterministic dynamics for a very large network size with @xmath158 and @xmath159 . for this , departing from the parameter set in ref .",
    "@xcite ( the case of without delay ) we use a set of parameters , where an oscillatory dynamics emerges : @xmath160 , @xmath161 , @xmath162 , @xmath163 , @xmath164 , @xmath165 , @xmath166 , @xmath167 , @xmath168 , @xmath169 , @xmath170 , @xmath171 , and the transfer function in eq .",
    "( [ t2 ] ) .",
    "time is in milliseconds and the rate constants are in inverse milliseconds .",
    "the difference is barely detectable in fig .",
    "[ fig3 ] , a , b , where we present the results of stochastic simulations done both with the exact gillespie algorithm and within the approximate langevin dynamics .",
    "however , stochastic effects become immediately seen in fig .",
    "[ fig3 ] , c , d , where we reduced the number of neurons to @xmath172 and @xmath173 .",
    "we also compare in fig .",
    "[ fig3 ] , a , b , the results for the considered dynamics and its two - variable markovian approximation given by the standard wilson - cowan model in which , however , the transfer functions are renormalized in accordance with eq .",
    "( [ renorm ] ) , where the parameter @xmath174 is replaced by @xmath175 and @xmath176 , correspondingly .",
    "the deviations are visible , but small .",
    "however , the differences become very pronounced for small @xmath177 corresponding to the mean refractory period @xmath178 of 10 msec .",
    "then , the markovian approximation fails completely , see in fig .",
    "[ fig4 ] , especially in part ( b ) , revealing that neither the form of the oscillations , not their period are reproduced even approximately . especially remarkable",
    "is that contrary to intuition the increase of the refractory period of a single neuron does not increase the period of oscillations , as the markovian approximation predicts , but rather makes it smaller  the tendency is opposite !",
    "therefore , non - markovian memory effects generally do matter and one should take such effects seriously into account . with a small further decrease of @xmath179 to @xmath180 with @xmath181",
    "the oscillations are terminated by a supercritical hopf bifurcation ( not shown ) .",
    "interestingly , markovian approximation also predicts such a termination , but at a slightly larger critical value @xmath182 with critical @xmath183 .",
    "this makes clear that the phase transitions between the quiescent network and the network undergoing synchronized oscillations are possible with respect to the length of the refractory period used as a control parameter .    .",
    "other parameters are the same as in fig .",
    "the deviation in ( b ) indicates that the markovian approximation fails completely.,title=\"fig:\",height=181 ] .",
    "other parameters are the same as in fig .",
    "the deviation in ( b ) indicates that the markovian approximation fails completely.,title=\"fig:\",height=181 ] +       and ( a ) @xmath184 , ( b ) @xmath185 , ( c ) @xmath177 . in ( d ) , ( e ) , and ( f ) , @xmath184 , however , the network size is increased to ( d ) @xmath186 , ( e ) @xmath187 , and ( f ) @xmath153 .",
    "for the fixed @xmath155 , the maximal @xmath188 in ( a ) is @xmath189 , i.e. about 76% of maximally possible . with the increase of refractory time it diminishes to @xmath190 ( about 66% ) in ( b ) , and to @xmath191 ( about 58.5% ) in ( c ) .",
    "for a fixed refractory time , but with the increase of the network size the maximal number of active neurons is @xmath192 ( @xmath19364% ) in ( d ) , @xmath194 ( @xmath19331% ) in ( e ) , and @xmath195 ( @xmath19311% ) in ( f ) . with the increase of network size ,",
    "the relative size of avalanches decreases .",
    "notice also that the minimal number of active neurons is @xmath196 in ( e ) , and @xmath197 in ( f ) .",
    "this must be taken into account when one defines avalanches in large networks .",
    "otherwise , one can come to incorrect conclusion that the avalanches cease to exist , which is manifestly refuted in ( f ) for a very large number of neurons which seems to be macroscopically large , and nevertheless fluctuations are still very important , even though they do vanish in the strict limit @xmath122 .",
    "experimentally , one also defines the start and end of an avalanche by crossing a threshold of basal activity upwards , and downwards , correspondingly .",
    "simulations are done with the gillespie algorithm.,title=\"fig:\",width=188 ]   and ( a ) @xmath184 , ( b ) @xmath185 , ( c ) @xmath177 . in ( d ) , ( e ) , and ( f ) , @xmath184 , however , the network size is increased to ( d ) @xmath186 , ( e ) @xmath187 , and ( f ) @xmath153 . for the fixed @xmath155 ,",
    "the maximal @xmath188 in ( a ) is @xmath189 , i.e. about 76% of maximally possible . with the increase of refractory time it diminishes to @xmath190 ( about 66% ) in ( b ) , and to @xmath191 ( about 58.5% ) in ( c ) . for a fixed refractory time , but with the increase of the network size the maximal number of active neurons is @xmath192 ( @xmath19364% ) in ( d ) , @xmath194 ( @xmath19331% ) in ( e ) , and @xmath195 ( @xmath19311% ) in ( f ) . with the increase of network size ,",
    "the relative size of avalanches decreases .",
    "notice also that the minimal number of active neurons is @xmath196 in ( e ) , and @xmath197 in ( f ) .",
    "this must be taken into account when one defines avalanches in large networks .",
    "otherwise , one can come to incorrect conclusion that the avalanches cease to exist , which is manifestly refuted in ( f ) for a very large number of neurons which seems to be macroscopically large , and nevertheless fluctuations are still very important , even though they do vanish in the strict limit @xmath122 .",
    "experimentally , one also defines the start and end of an avalanche by crossing a threshold of basal activity upwards , and downwards , correspondingly .",
    "simulations are done with the gillespie algorithm.,title=\"fig:\",width=188 ]   and ( a ) @xmath184 , ( b ) @xmath185 , ( c ) @xmath177 . in ( d ) , ( e ) , and ( f ) , @xmath184 , however , the network size is increased to ( d ) @xmath186 , ( e ) @xmath187 , and ( f ) @xmath153 . for the fixed @xmath155 ,",
    "the maximal @xmath188 in ( a ) is @xmath189 , i.e. about 76% of maximally possible . with the increase of refractory time it diminishes to @xmath190 ( about 66% ) in ( b ) , and to @xmath191 ( about 58.5% ) in ( c ) . for a fixed refractory time , but with the increase of the network size the maximal number of active neurons is @xmath192 ( @xmath19364% ) in ( d ) , @xmath194 ( @xmath19331% ) in ( e ) , and @xmath195 ( @xmath19311% ) in ( f ) . with the increase of network size ,",
    "the relative size of avalanches decreases .",
    "notice also that the minimal number of active neurons is @xmath196 in ( e ) , and @xmath197 in ( f ) .",
    "this must be taken into account when one defines avalanches in large networks .",
    "otherwise , one can come to incorrect conclusion that the avalanches cease to exist , which is manifestly refuted in ( f ) for a very large number of neurons which seems to be macroscopically large , and nevertheless fluctuations are still very important , even though they do vanish in the strict limit @xmath122 .",
    "experimentally , one also defines the start and end of an avalanche by crossing a threshold of basal activity upwards , and downwards , correspondingly .",
    "simulations are done with the gillespie algorithm.,title=\"fig:\",width=188 ] +   and ( a ) @xmath184 , ( b ) @xmath185 , ( c ) @xmath177 . in ( d ) , ( e ) , and ( f ) , @xmath184 , however , the network size is increased to ( d ) @xmath186 , ( e ) @xmath187 , and ( f ) @xmath153 . for the fixed @xmath155 ,",
    "the maximal @xmath188 in ( a ) is @xmath189 , i.e. about 76% of maximally possible . with the increase of refractory time it diminishes to @xmath190 ( about 66% ) in ( b ) , and to @xmath191 ( about 58.5% ) in ( c ) . for a fixed refractory time , but with the increase of the network size the maximal number of active neurons is @xmath192 ( @xmath19364% ) in ( d ) , @xmath194 ( @xmath19331% ) in ( e ) , and @xmath195 ( @xmath19311% ) in ( f ) . with the increase of network size ,",
    "the relative size of avalanches decreases .",
    "notice also that the minimal number of active neurons is @xmath196 in ( e ) , and @xmath197 in ( f ) .",
    "this must be taken into account when one defines avalanches in large networks .",
    "otherwise , one can come to incorrect conclusion that the avalanches cease to exist , which is manifestly refuted in ( f ) for a very large number of neurons which seems to be macroscopically large , and nevertheless fluctuations are still very important , even though they do vanish in the strict limit @xmath122 .",
    "experimentally , one also defines the start and end of an avalanche by crossing a threshold of basal activity upwards , and downwards , correspondingly .",
    "simulations are done with the gillespie algorithm.,title=\"fig:\",width=188 ]   and ( a ) @xmath184 , ( b ) @xmath185 , ( c ) @xmath177 . in ( d ) , ( e ) , and ( f ) , @xmath184 , however , the network size is increased to ( d ) @xmath186 , ( e ) @xmath187 , and ( f ) @xmath153 . for the fixed @xmath155 ,",
    "the maximal @xmath188 in ( a ) is @xmath189 , i.e. about 76% of maximally possible . with the increase of refractory time it diminishes to @xmath190 ( about 66% ) in ( b ) , and to @xmath191 ( about 58.5% ) in ( c ) . for a fixed refractory time , but with the increase of the network size the maximal number of active neurons is @xmath192 ( @xmath19364% ) in ( d ) , @xmath194 ( @xmath19331% ) in ( e ) , and @xmath195 ( @xmath19311% ) in ( f ) . with the increase of network size ,",
    "the relative size of avalanches decreases .",
    "notice also that the minimal number of active neurons is @xmath196 in ( e ) , and @xmath197 in ( f ) . this must be taken into account when one defines avalanches in large networks .",
    "otherwise , one can come to incorrect conclusion that the avalanches cease to exist , which is manifestly refuted in ( f ) for a very large number of neurons which seems to be macroscopically large , and nevertheless fluctuations are still very important , even though they do vanish in the strict limit @xmath122 . experimentally",
    ", one also defines the start and end of an avalanche by crossing a threshold of basal activity upwards , and downwards , correspondingly .",
    "simulations are done with the gillespie algorithm.,title=\"fig:\",width=188 ]   and ( a ) @xmath184 , ( b ) @xmath185 , ( c ) @xmath177 . in ( d ) , ( e ) , and ( f ) , @xmath184 , however , the network size is increased to ( d ) @xmath186 , ( e ) @xmath187 , and ( f ) @xmath153 . for the fixed @xmath155 ,",
    "the maximal @xmath188 in ( a ) is @xmath189 , i.e. about 76% of maximally possible . with the increase of refractory time it diminishes to @xmath190 ( about 66% ) in ( b ) , and to @xmath191 ( about 58.5% ) in ( c ) . for a fixed refractory time , but with the increase of the network size the maximal number of active neurons is @xmath192 ( @xmath19364% ) in ( d ) , @xmath194 ( @xmath19331% ) in ( e ) , and @xmath195 ( @xmath19311% ) in ( f ) . with the increase of network size ,",
    "the relative size of avalanches decreases .",
    "notice also that the minimal number of active neurons is @xmath196 in ( e ) , and @xmath197 in ( f ) .",
    "this must be taken into account when one defines avalanches in large networks .",
    "otherwise , one can come to incorrect conclusion that the avalanches cease to exist , which is manifestly refuted in ( f ) for a very large number of neurons which seems to be macroscopically large , and nevertheless fluctuations are still very important , even though they do vanish in the strict limit @xmath122 .",
    "experimentally , one also defines the start and end of an avalanche by crossing a threshold of basal activity upwards , and downwards , correspondingly .",
    "simulations are done with the gillespie algorithm.,title=\"fig:\",width=188 ] +    in the remainder , we investigate the influence of memory effects on the avalanche dynamics .",
    "as it has been shown in @xcite , in order to have avalanche dynamics the excitatory and inhibitory processes should be nearly balanced , and the network should have a so - called feedforward structure .",
    "then , one can achieve a sort of self - organized critical ( soc ) state @xcite sustained due to intrinsic mesoscopic fluctuations . very different from other soc models , here",
    "fluctuations play a major role and in the deterministic limit avalanches disappear , i.e. they are of mesoscopic nature . the nullclines of 2d deterministic dynamics in the absence of memory effects , @xmath198 and @xmath199 , should cross at a very small angle in the @xmath154 plane , so that fluctuations can produce large amplitude outbursts of the @xmath81 and @xmath200 variables moving synchronously but randomly , i.e. the subpopulations of excitatory and inhibitory neurons are synchronized exhibiting stochastic dynamics at the same time @xcite . in the same spirit , we choose @xmath201 , @xmath202 , @xmath203 , @xmath204 , so that @xmath205 , and overall excitation slightly dominates over inhibition .",
    "furthermore , we choose @xmath206 , and the transfer function in eq .",
    "( [ t1 ] ) , as in ref .",
    "the rates @xmath207 , @xmath208 and the number of neurons were varied .",
    "large @xmath184 corresponds to a small refractory time of @xmath209 msec , whereas @xmath177 corresponds to a profound delay with @xmath210 msec , so that the individual spiking rate of neurons can not exceed 100 hz being limited by the refractory period .",
    "typical avalanche dynamics is shown in fig .",
    "[ fig5 ] for @xmath211 with @xmath155 , and ( a ) @xmath184 , ( b ) @xmath185 , ( c ) @xmath177 .",
    "furthermore , in fig . [ fig5 ] , d , e , f",
    ", we show the influence of an increasing number of neurons on the avalanche dynamics .",
    "the following tendencies are clear . first , the increase of refractory period reduces the maximal amount of neurons involved in spiking , from about 76% in fig .",
    "[ fig5 ] , a to 58.5% in fig .",
    "[ fig5 ] , c. such a tendency is already expected from the renormalization of the transfer function in the markovian approximation , cf .",
    "( [ renorm ] ) . however , this tendency is in fact much weaker since @xmath212 in the part ( c ) , and the renormalization argumentation would predict almost complete suppression of avalanches for such a delay .",
    "even more astonishing is that avalanches still did not vanish even for a very large @xmath213 , see fig .",
    "[ fig5 ] , f. this is very different from the oscillatory dynamics of a network of the same size , cf . fig .",
    "[ fig3 ] , a , and b , which is practically deterministic .",
    "of course , with increasing network size , the relative amplitude of avalanches becomes ever smaller , and there also emerges a minimal number of neurons excited , i.e. the network activity never goes down to zero .",
    "however , this is also so in the real neuronal dynamics .",
    "such a dominance of mesoscopic fluctuations in a system of millions elements with a special ( feedforward ) structure of coupling is really astonishing .",
    "this is a feature of some critical state , as we know from statistical physics .    .",
    "other parameter are given in the text.,title=\"fig:\",width=264 ] .",
    "other parameter are given in the text.,title=\"fig:\",width=264 ] .",
    "other parameter are given in the text.,title=\"fig:\",width=264 ]    to statistically characterize the avalanche size distribution and their duration we proceed in accordance with the procedure outlined in ref .",
    "it reflects , in part , also the experimental procedure @xcite .",
    "namely , we first discretize the time series with a time bin of the size @xmath214 , which corresponds to the averaged interspike time distance in a particular simulation . then , an avalanche is defined by its start , when the spiking activity crosses some threshold level @xmath215 , and its end , when the network activity drops to ( @xmath216 ) or below @xmath217 after some time , which defines the avalanche duration .",
    "the size is defined as the sum of the number of neurons active in each time bin during the avalanche .",
    "it is also defined experimentally in such a way .",
    "in essence , the size @xmath63 of an avalanche is the integral of the network activity in fig .",
    "[ fig5 ] over the time during each avalanche period divided by the time bin width .",
    "of course , as also in experiments the critical exponents discussed below depend both on the time bin width and on the basal level of neuronal activity @xmath215 . however , this dependence is weak for a truly critical dynamics . by doing statistical analysis",
    ", we first find the survival probability @xmath218 , or , equivalently , the cumulative probability @xmath219 from the numerical data .",
    "then , the distribution density follows as @xmath220 .",
    "let us start from the case without any time delay , @xmath221 .",
    "the survival probability for the avalanche size distribution @xmath218 is shown in fig .",
    "[ fig6],a , for the time bin @xmath222 and @xmath216 .",
    "it shows three characteristic features : ( 1 ) an initial weibull distribution , @xmath223)$ ] , with @xmath224 and @xmath225 ; ( 2 ) an intermediate power law @xmath226 , with @xmath227 , and ( 3 ) an exponential tail @xmath228 with @xmath229 and @xmath230 .",
    "the size distribution @xmath231 is , therefore , initially approximately a power law with negative exponent @xmath232 , followed by a power law with negative exponent @xmath233 .",
    "the latter one extends over approximately two size decades and ends with an exponential tail characterized by a cutoff size , @xmath234 .",
    "the corresponding survival probability @xmath235 for the avalanche durations @xmath236 is shown in fig .",
    "[ fig6 ] , b. it can be well fitted by a sum of two exponentials , @xmath237 however , it also seems to display an intermediate power law over about one time decade , from 1 to 10 ms , with the power exponent @xmath238 , and the cutoff time @xmath239 ms .",
    "hence , the probability distribution @xmath240 also appears to reflect an intermediate power law @xmath241 with @xmath242 .",
    "interestingly , the duration of avalanches in experiments with organotypic cortical neuronal systems has a similar cutoff time of about 10 - 20 ms , with a maximal avalanche duration of about 40 - 80 ms , which is restricted by the period of @xmath243oscillations @xcite .",
    "the intermediate power law also extends over about one time decade in the experiments .",
    "however , the experimental power law exponent is different , @xmath244 .",
    "it should be mentioned in this respect that the time bin in the experiments is also very different , @xmath245 ms .",
    "one electrode measures in experiments a contribution of many neurons .",
    "in fact , coarse graining over some unknown @xmath246 should be done .",
    "the experimental size exponent @xmath247 is also different , @xmath248 .",
    "it is not , however , the goal of this paper to provide a model fully consistent with the experimental observations , which are subject of ongoing research work and some controversy in the literature @xcite . in this respect",
    ", a bi - exponential dependence can be perceived as a power law over one intermediate time decade , as our fit also shows .    as an additional characteristics of the avalanches size",
    ", one can also consider the maximal number of neurons activated at once during an avalanche , or the avalanche peak with a distribution density @xmath249 . the corresponding survival probability , @xmath250 , also exhibits a power law , @xmath251 , with @xmath252 , in fig .",
    "[ fig6 ] , c. hence , @xmath253 , with @xmath254 , which only slightly differs from @xmath255 meaning that the avalanche size is roughly proportional to its peak . however , the cutoff of @xmath250 is super - exponentially sharp , because the maximal number of neurons involved in an avalanche at the same time is restricted by the total number of neurons in the network .",
    "furthermore , @xmath256 reveals a very large portion of avalanches whose peak does not exceed 10 , which explains the initial stretched exponential dependence in fig .",
    "[ fig6 ] , a. strictly speaking , this part of the size distribution ( with @xmath216 ) reflects a background or basal noise , where neurons practically do not interact with each other , and there are no avalanches of spontaneously increased activity , which are characterized by a power law distribution .    .",
    "other parameters are the same as in fig .",
    "the cutoff size of avalanches @xmath234 becomes slightly smaller than in fig .",
    "[ fig6 ] , and the characteristic power law exponents are also slightly changed .",
    ", title=\"fig:\",width=264 ] .",
    "other parameters are the same as in fig .",
    "the cutoff size of avalanches @xmath234 becomes slightly smaller than in fig .",
    "[ fig6 ] , and the characteristic power law exponents are also slightly changed .",
    ", title=\"fig:\",width=264 ] .",
    "other parameters are the same as in fig .",
    "the cutoff size of avalanches @xmath234 becomes slightly smaller than in fig .",
    "[ fig6 ] , and the characteristic power law exponents are also slightly changed . ,",
    "title=\"fig:\",width=264 ]    . here ,",
    "the other parameters remain the same .",
    "the cutoff size of avalanches , @xmath258 , is now visibly smaller than one without delay , @xmath259 in fig .",
    "the cutoff time @xmath260 is increased with respect to @xmath261 in figs .",
    "[ fig6 ] , [ fig7 ] , i.e. the avalanches last longer .",
    "the power law exponents here deviate slightly in the opposite direction from the one in fig .",
    "they become closer to the case without delay in fig .",
    "this indicates that the time delay does not affect significantly the power law exponents .",
    ", title=\"fig:\",width=264 ] . here , @xmath257 .",
    "the other parameters remain the same .",
    "the cutoff size of avalanches , @xmath258 , is now visibly smaller than one without delay , @xmath259 in fig .",
    "the cutoff time @xmath260 is increased with respect to @xmath261 in figs .",
    "[ fig6 ] , [ fig7 ] , i.e. the avalanches last longer . the power law exponents here deviate slightly in the opposite direction from the one in fig .",
    "they become closer to the case without delay in fig .",
    "this indicates that the time delay does not affect significantly the power law exponents .",
    ", title=\"fig:\",width=264 ] . here , @xmath257 .",
    "the other parameters remain the same .",
    "the cutoff size of avalanches , @xmath258 , is now visibly smaller than one without delay , @xmath259 in fig .",
    "the cutoff time @xmath260 is increased with respect to @xmath261 in figs .",
    "[ fig6 ] , [ fig7 ] , i.e. the avalanches last longer .",
    "the power law exponents here deviate slightly in the opposite direction from the one in fig .",
    "they become closer to the case without delay in fig .",
    "this indicates that the time delay does not affect significantly the power law exponents . , title=\"fig:\",width=264 ]    , on the distributions depicted in figs .",
    "[ fig7 ] , [ fig8 ] . here , @xmath262 , and the other parameters",
    "are not changed .",
    "@xmath234 drops further to @xmath263 , and @xmath264 slightly increases to @xmath265 .",
    "the power law exponents exhibit , however , merely some fluctuations without any systematic trend in figs .",
    "[ fig6]-[fig9 ] . ,",
    "title=\"fig:\",width=264 ] , on the distributions depicted in figs .",
    "[ fig7 ] , [ fig8 ] . here , @xmath262 , and the other parameters",
    "are not changed .",
    "@xmath234 drops further to @xmath263 , and @xmath264 slightly increases to @xmath265 .",
    "the power law exponents exhibit , however , merely some fluctuations without any systematic trend in figs .",
    "[ fig6]-[fig9 ] . ,",
    "title=\"fig:\",width=264 ] , on the distributions depicted in figs .",
    "[ fig7 ] , [ fig8 ] . here , @xmath262 , and the other parameters",
    "are not changed .",
    "@xmath234 drops further to @xmath263 , and @xmath264 slightly increases to @xmath265 .",
    "the power law exponents exhibit , however , merely some fluctuations without any systematic trend in figs .",
    "[ fig6]-[fig9 ] . ,",
    "title=\"fig:\",width=264 ]    next , we like to clarify how robust these features are for networks with a time delay . for this , we study the influence of the mean delay time by decreasing the rates @xmath266 from @xmath267 through @xmath268 to @xmath209 in figs .",
    "[ fig7 ] , [ fig8 ] , [ fig9 ] , respectively . the mean delay time increases , accordingly , from @xmath209 through @xmath268 to @xmath267 ms .",
    "even though the parameters of the distributions do change , these changes are not dramatical .",
    "in particular , the corresponding critical size exponent @xmath247 changes from @xmath269 ( no delay ) , to @xmath270 , @xmath271 and @xmath272 , respectively .",
    "accordingly , the critical time exponent @xmath273 changes from @xmath274 ( no delay ) to @xmath275 , @xmath276 , and @xmath277 , respectively .",
    "such changes are not statistically significant , and one can not detect any systematic tendency upon a variation of @xmath13 . the point is that these exponents are also changed a bit , if we use e.g. @xmath278 , or @xmath279 for the time bin ( not shown ) .",
    "they also depend on the threshold @xmath215 . in this respect ,",
    "if to change @xmath215 from @xmath280 to @xmath267 , the initial stretched exponential part of the size distribution practically disappears .",
    "however , there appears an initial power law instead , see in fig .",
    "[ fig10 ] . remarkably , the intermediate power law exponent remains rather robust .",
    "it is changed from @xmath281 in fig .",
    "[ fig7],a to @xmath282 in fig",
    ". [ fig10 ] , a. this is a small variation .",
    "notice , however , that the results in fig . [ fig10 ] , b in fact reject the hypothesis that there is an intermediate power law in the time distribution of avalanches .",
    "first , the power law region changes from larger to smaller times , and also ( more important ! ) the corresponding time exponent changes from @xmath283 in fig .",
    "[ fig7 ] , b to @xmath284 in fig .",
    "[ fig10 ] , b. clearly , such a strong influence of the choice of @xmath215 on the `` power law '' exponent @xmath273 makes it clear that this is not a power law .",
    "in fact , the time distribution is clearly biexponential .     on the distributions of avalanche sizes ( a ) and time durations ( b ) . here",
    ", @xmath285 is used for the data analysis instead of @xmath216 in fig .",
    "[ fig7 ] , for the same data .",
    "noticeably , the initial stretched exponential part of the size distribution in fig .",
    "[ fig7 ] , a disappears .",
    "instead , there appears initially another power law dependence .",
    "the intermediate power law exponent @xmath286 is , however , pretty robust , @xmath287 here versus @xmath288 in fig .",
    "in contrast with this , the intermediate power law exponent in the time distribution is changed dramatically from @xmath283 in fig .",
    "[ fig7 ] to @xmath284 .",
    "this fact disproves the hypothesis of an intermediate power law in the time distribution .",
    "it is clearly bi - exponential , eq .",
    "( [ bi ] ) .",
    ", title=\"fig:\",width=264 ]   on the distributions of avalanche sizes ( a ) and time durations ( b ) . here",
    ", @xmath285 is used for the data analysis instead of @xmath216 in fig .",
    "[ fig7 ] , for the same data .",
    "noticeably , the initial stretched exponential part of the size distribution in fig .",
    "[ fig7 ] , a disappears .",
    "instead , there appears initially another power law dependence .",
    "the intermediate power law exponent @xmath286 is , however , pretty robust , @xmath287 here versus @xmath288 in fig .",
    "in contrast with this , the intermediate power law exponent in the time distribution is changed dramatically from @xmath283 in fig .",
    "[ fig7 ] to @xmath284 .",
    "this fact disproves the hypothesis of an intermediate power law in the time distribution .",
    "it is clearly bi - exponential , eq .",
    "( [ bi ] ) .",
    ", title=\"fig:\",width=264 ]     _ vs. _ @xmath289 in fig .",
    "the other parameters are the same .",
    "the power law regime in the size distribution extends by an order of magnitude , with the cutoff size increased to @xmath290 , accordingly .",
    "the corresponding power law exponent varies insignificantly .",
    "the time cutoff @xmath264 increases in ( b ) to @xmath291 from @xmath265 in fig .",
    "[ fig9 ] , i.e. the avalanches last longer .",
    ", title=\"fig:\",width=264 ]   _ vs. _ @xmath289 in fig .",
    "the other parameters are the same .",
    "the power law regime in the size distribution extends by an order of magnitude , with the cutoff size increased to @xmath290 , accordingly .",
    "the corresponding power law exponent varies insignificantly .",
    "the time cutoff @xmath264 increases in ( b ) to @xmath291 from @xmath265 in fig .",
    "[ fig9 ] , i.e. the avalanches last longer .",
    ", title=\"fig:\",width=264 ]     _ vs. _ @xmath289 in fig .",
    "other parameters are the same . the power law regime in the size distribution shrinks by an order of magnitude , with the cutoff form changed from the exponential in fig . [ fig9 ] , a , to the gaussian here . the intermediate power law exponent is not changed , however , strongly .",
    "the time cutoff @xmath264 decreases in ( b ) to @xmath292 from @xmath265 in fig .",
    "[ fig9 ] , b , i.e. the avalanches become significantly shorter .",
    ", title=\"fig:\",width=264 ]   _ vs. _ @xmath289 in fig .",
    "other parameters are the same . the power law regime in the size distribution shrinks by an order of magnitude , with the cutoff form changed from the exponential in fig . [ fig9 ] , a , to the gaussian here . the intermediate power law exponent is not changed , however , strongly . the time cutoff @xmath264 decreases in ( b ) to @xmath292 from @xmath265 in fig .",
    "[ fig9 ] , b , i.e. the avalanches become significantly shorter .",
    ", title=\"fig:\",width=264 ]    though plausible until this point , it remains , however , strictly speaking , still not quite clear if @xmath247 is indeed a critical exponent . if true , the extension of the power law domain of the whole size - distribution and the cutoff size @xmath234 should increase with the system size accordingly . indeed , if we increase the system size tenfold keeping the other parameters the same as in fig .",
    "[ fig9 ] , the power law domain in the size distributions also increases by an order of size magnitude , see in fig .",
    "[ fig11 ] , a. the time cutoff @xmath264 also increases in fig .",
    "[ fig11 ] , b , i.e. the avalanches become longer . also with decreasing the system size tenfold the power law domain shrinks accordingly in size , see fig .",
    "[ fig12 ] , a , and the avalanches become essentially shorter , as indicated by the decreased cutoff time @xmath264 in fig .",
    "[ fig12 ] , b. such scaling dependencies on the system size are typical in experiments . from this",
    "we can conclude that the size exponent @xmath247 is indeed a critical exponent .",
    "however , within the considered model the avalanches do gradually vanish with an increase of the system size .",
    "therefore , the adjective `` critical '' should be used also with respect to the exponent @xmath247 with some reservations .",
    "we consider a rather atypical soc model , even though the exponent @xmath247 is by chance close to that of the sandpile model @xcite .",
    "it should also be noticed that the initial distributions of the sizes and times and the tail functional dependencies can be sensitive to both the system size and the choice of the threshold @xmath215 .",
    "for example , the size distribution exhibits a gaussian tail in fig .",
    "[ fig12 ] , a , for a small system size .",
    "the intermediate power law in the size distribution is , however , rather robust , with @xmath247 being in the range @xmath293 $ ] for the data presented , with the average @xmath294 .      within the langevin approximation of the discrete state dynamics , the avalanches look very similar to the ones depicted in fig .",
    "however , their statistics is very different .",
    "we performed the corresponding langevin simulations for the same parameters as in figs .",
    "[ fig7 ] , [ fig10 ] with the time step taken to be the same @xmath295 as the time bin used to produce the results in figs .",
    "[ fig7 ] , [ fig10 ] .",
    "we also used @xmath285 to analyze the data , as in fig .",
    "[ fig10 ] .",
    "the results shown in fig .",
    "[ fig13 ] reveal similar intermediate power laws both in the size and the time distributions yielding @xmath296 , @xmath297 . however , these results differ essentially from the results obtained within the exact dynamic monte carlo simulations , compare fig . [ fig13 ] with fig .",
    "[ fig10 ] .",
    "this indicates that the gauss - langevin or diffusional approximation of the genuine discrete state dynamics can deliver incorrect results for the fluctuation - induced avalanche dynamics .",
    "this fact makes any analytical theory for the numerical results presented in this work especially challenging .",
    "it is almost hopeless to develop such a theory for the discrete state avalanche dynamics within the studied model .",
    "multi - dimensional birth - and - death processes are very difficult for any analytical treatment . within the langevin dynamics approximation , or the equivalent multi - dimensional fokker - planck equation description",
    "an analytical treatment is more feasible .",
    "however , such a theory will not help to understand the critical features of the discrete state dynamics , as our numerical results imply .",
    ", obtained with @xmath285 . notice the dramatical changes.,title=\"fig:\",width=264 ] , obtained with @xmath285 .",
    "notice the dramatical changes.,title=\"fig:\",width=264 ]",
    "in this paper , we studied a generalization of the stochastic wilson - cowan model of neuronal network dynamics aimed to incorporate a refractory period delay on the level of individual elements .",
    "considered as stochastic bistable elements such model neurons exhibit non - markovian dynamics with memory , which can be characterized by a non - exponential residence time distribution in the resting state of the neuron ( semi - markovian description ) , or , alternatively , by the related memory kernel within a generalized master equation description .",
    "such a non - markovian description generally allows for a markovian embedding by enlarging the dynamical space upon introduction of new state variables .",
    "the simplest two - state non - markovian model with an exponentially decaying memory kernel can be embedded as a three state cyclic markovian model , where the refractory period is exponentially distributed .",
    "multi - state markovian embedding also allows to treat a special erlangian distribution of the refractory periods , which can be sharply peaked at a characteristic delay time .",
    "moreover , models of bursting neurons and neurons with a power law distributed memory can , in principle , be considered in this generic markovian embedding setup .",
    "the approach of markovian embedding is especially suitable to treat the mean - field dynamics of the network , which presents a markovian renewal process in the enlarged space of collective network variables .",
    "this is the simplest kind of network , where all the elements are virtually connected in all - to - all fashion . in this respect ,",
    "the mean field dynamics of a network of non - markovian renewal elements does not represent a renewal process in the reduced space of non - markovian collective variables .",
    "then , all the elements must be treated individually , keeping trace of their individual memory .",
    "the methodology of markovian embedding allows to circumvent this problem for the mean - field dynamics .    in the wilson - cowan model ,",
    "two different sorts of interacting neurons are considered , excitatory and inhibitory .",
    "we focused on the simplest non - markovian generalization of this model , where the observed two - state non - markovian dynamics of a single neuron is embedded as a three state cyclic markovian process .",
    "the corresponding nonlinear mean - field dynamics is four dimensional .",
    "it has two dimensions more than in the original model .",
    "moreover , it is stochastic and includes mesoscopic fluctuations due to a finite network size . for a sufficiently large system size",
    ", stochastic dynamics can be described within a langevin equation approximation following the so - called chemical langevin equation approach , with the noise terms vanishing in the deterministic limit of infinite size .",
    "we also exactly simulated the underlying dynamics as a continuous time markovian random walk on a four - dimensional lattice using the well - known dynamical monte carlo ( gillespie ) algorithm .",
    "the results of both stochastic approaches agree well with the deterministic dynamics within an oscillatory regime for a very large number of elements ( several millions ) . here",
    ", we showed that non - markovian effects can be very essential .",
    "in particular , even deterministic dynamics with an exponentially decaying memory in the space of observable variables can be very different from the dynamics obtained within the markovian approximation utilizing a delay - renormalized transfer function  the simplest approach to account for the delay effects .",
    "however , already the simplest approach allows to describe a dynamical phase transition from the silent network to coherent nonlinear oscillations of synchronized neurons upon a change of the delay period .",
    "this important feature is absent in the original wilson - cowan model .    in more detail , we investigated the avalanche dynamics in a critically balanced network , where the processes of excitation and inhibition nearly compensate each other in the deterministic limit , where no avalanches are possible within the model considered .",
    "mesoscopic noise fluctuations make , however , avalanches possible even in large networks with millions of neurons , where the deterministic description becomes completely inadequate , very differently from the oscillatory dynamics in such large networks .",
    "this result goes beyond the results in ref .",
    "@xcite , where the avalanches cease to exist for already several tens of thousands elements . even though a large delay should suppress avalanches by a transfer function renormalization if to think within the markovian approximation , in reality the suppression is much weaker .",
    "moreover , it turns out that the power law characterizing the distribution of avalanche sizes is very robust with respect to variation of both the delay period , and the system size , over several orders of magnitude , as well as the choice of the avalanche threshold .",
    "the latter fact proves that this is a real power law originated due to critical dynamics .",
    "it is characterized by a power - law exponent around @xmath298 which is similar to the size exponent of the critical sandpile dynamics ( though the both models are not really comparable ) . however , it is different from the critical exponent @xmath299 found in ref.@xcite , though for different network parameters .",
    "the distribution of the avalanches durations is , however , biexponential .",
    "we disproved that it presents a power law within our model , even though it can look like a power law over one time decade , as in experiments . in this respect ,",
    "experiments @xcite seem to reveal a real power law with the critical size exponent @xmath300 because its range extends with the growing system size",
    ". however , the experimental power law in the time duration does not show this important property . as a matter of fact",
    ", it extends over merely one time decade being restricted by the period of @xmath243oscillations .",
    "any power law extending over one time or spatial decade can be fitted by a sum of just two exponentials , as we also show in this work for the time distribution .",
    "a further research is , therefore , required to clarify the nature of the apparent power law feature in the avalanche time distribution for the observed neuronal avalanches .",
    "also very important is that the langevin or diffusional approximation does change the critical exponents of the studied avalanche dynamics .",
    "there appears a power law in the time distribution , which is absent in the exact simulations , with the critical langevin exponent @xmath301 .",
    "also the critical langevin size exponent is different , @xmath302 .",
    "this feature should be kept in mind while doing diffusional approximations in other models of critical dynamics .",
    "it may deliver incorrect results even for a large number of elements .",
    "we believe that the results of this work have methodological value and can be extended onto the dynamics of other networks with delay .",
    "they can serve also as a basis for further investigations of the role of non - markovian memory effects in the dynamics of wilson - cowan type neuronal networks , including networks of bursting neurons , and networks with nontrivial topology , which we plan to investigate in future .",
    "financial support by the deutsche forschungsgemeinschaft , grant go 2052/1 - 2 is gratefully acknowledged ."
  ],
  "abstract_text": [
    "<S> we consider a simple markovian class of the stochastic wilson - cowan type models of neuronal network dynamics , which incorporates stochastic delay caused by the existence of a refractory period of neurons . from the point of view of the dynamics of the individual elements </S>",
    "<S> , we are dealing with a network of non - markovian stochastic two - state oscillators with memory </S>",
    "<S> which are coupled globally in a mean - field fashion . </S>",
    "<S> this interrelation of a higher - dimensional markovian and lower - dimensional non - markovian dynamics is discussed in its relevance to the general problem of the network dynamics of complex elements possessing memory . the simplest model of this class </S>",
    "<S> is provided by a three - state markovian neuron with one refractory state , which causes firing delay with an exponentially decaying memory within the two - state reduced model . </S>",
    "<S> this basic model is used to study critical avalanche dynamics ( the noise sustained criticality ) in a balanced feedforward network consisting of the excitatory and inhibitory neurons . </S>",
    "<S> such avalanches emerge due to the network size dependent noise ( mesoscopic noise ) . </S>",
    "<S> numerical simulations reveal an intermediate power law in the distribution of avalanche sizes with the critical exponent around @xmath0 . </S>",
    "<S> we show that this power law is robust upon a variation of the refractory time over several orders of magnitude . however , the avalanche time distribution is biexponential </S>",
    "<S> . it does not reflect any genuine power law dependence . </S>"
  ]
}