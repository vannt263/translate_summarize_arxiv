{
  "article_text": [
    "stochastic dynamical systems arise in many areas of science , with much recent interest focusing on biomolecular reaction networks that control the behavior of individual cells @xcite . for instance , the expression levels of different genes in a single cell are often coupled by direct or indirect regulation and are subject to intrinsic ( reaction ) noise as well as extrinsic ( parametric ) noise @xcite .",
    "models of such systems can be based on a wide range of different approaches and mathematical tools @xcite . a full treatment of noise effects on the single - molecule level requires an approach based on the chemical master equation @xcite .",
    "however , many noise phenomena can also be understood and quantitatively analyzed within a more coarse - grained continuum description based on stochastic differential equations or , equivalently , the associated fokker - planck equations @xcite .",
    "for instance , such a description is adequate to describe the excitable system behavior of a natural genetic circuit whose excitations are triggered by noise @xcite , or the synchronizing effect of a coupling between noisy synthetic `` repressilators '' @xcite .",
    "a recurrent problem in the analysis of these systems is that the quantitative behavior of the theoretical models must be computed not only once , but for a large number of different parameter values .",
    "one common situation is that , for a given model , one would like to determine a `` phase diagram '' of system behaviors over the entire parameter space , in order to understand the model on a theoretical level .",
    "similarly , when models are leveraged for the interpretation of experiments , model fitting to data is required to infer system parameters or to discriminate between different variants of the model . in quantitative biology , there is currently a clear need for systematic and efficient methods to reverse engineer models from a limited number of noisy experimental observations @xcite .",
    "any such method requires as an essential ingredient an efficient technique for the forward simulation of the observables . for discrete stochastic models based on the chemical master equation ,",
    "recent progress in this direction has been made by using spectral methods @xcite or efficient cutoff schemes @xcite .",
    "also , efficient sampling techniques have been developed for rare event problems @xcite .",
    "here , we focus on continuum models and develop an approximation scheme that can efficiently capture the stochastic dynamics of the `` typical events '' even in larger dynamical systems .    for a given nonlinear stochastic system , we consider the dynamics of its probability distribution over state space .",
    "our scheme is reminiscent of the linear noise approximation @xcite in that it approximates the probability distribution at each point in time by a gaussian distribution .",
    "the essential difference is in the criterion used to match the gaussian approximation to the true distribution . in our method",
    ", we take a more global stance at the matching process , by invoking the kullback - leibler divergence  @xcite as accuracy measure .",
    "we minimize the kullback - leibler divergence at each point in time to obtain a set of ordinary differential equations for the parameters of the gaussian distribution which best approximates , in this sense , the current probabilistic state of the system .",
    "we refer to our matching condition as entropic matching .",
    "it was recently proposed as a general method to construct simulation schemes for partial differential equations @xcite . here , we develop and test this idea for the case of stochastic differential and fokker - planck equations . for the examples considered here ,",
    "we find the method to be more accurate and robust than the linear noise approximation , while the computational complexity is comparable . in the following ,",
    "we first formulate the theoretical problem , then describe the method in detail , and finally illustrate and test it on simple example systems .",
    "at the most fundamental level a biochemical reaction network can be represented by a stochastic jump process @xcite .",
    "a specific system state is described by a vector @xmath0 which represents the number of molecules for each of the @xmath1 different molecular species .",
    "the transition rates are represented by a linear operator @xmath2 , where an element @xmath3 is the transition rate for a specific jump ( from state @xmath4 to @xmath5 ) .",
    "the nonlinearity of the underlying dynamical system is reflected in the nonlinear dependence of @xmath3 on @xmath4 , @xmath5 . at each time",
    "step the probability to be in a given system state is represented by @xmath6 and its evolution is given by the chemical master equation @xmath7 generally it is not possible to solve this equation analytically , but there are a number of approaches to efficiently solve it numerically  @xcite .",
    "however , even these efficient approaches become prohibitive when the total number of molecules @xmath8 is large .    for a large number of molecules , a well - suited approximation of the discrete stochastic process",
    "is by a continuous drift and diffusion process @xcite .",
    "this description bridges the microscopic stochastic picture with the macroscopic deterministic picture and provides important insights for a regime in which particle numbers are high but stochasticity still plays an important role in the system dynamics  @xcite . in this framework",
    "the system state is described by a set of continuous concentrations @xmath9 .",
    "the interactions between the molecular species are specified by a set of nonlinear dynamical equations , which depend on numerous parameters denoted henceforth as @xmath10 .",
    "the dynamical equations can be written as stochastic differential equations ( sde ) @xmath11 where @xmath12 is the nonlinear function regulating each node of the biomolecular network and @xmath13 represents a random process characterizing the system s intrinsic fluctuations .",
    "we can think of a single trajectory obtained by solving eq .",
    "( with one realization of the noise process @xmath14 ) as the biochemical trajectory of a single cell , and an ensemble of such trajectories as the corresponding dynamics for a population of cells .",
    "this picture relies on the assumption that different cells trajectories are uncorrelated , i.e. that there is no intercellular communication . within the framework of sde s , extrinsic",
    "cell - to - cell noise would need to be accounted for by specifying a probability distribution for the parameters @xmath10 , which can either be static or have a dynamics by itself . for simplicity",
    ", we will ignore extrinsic noise in the following . from the sde system",
    "one can then directly obtain @xcite a fokker - plank equation ( fpe ) of the form @xmath15 + \\tfrac{1}{2 } \\partial_{c}^2 \\left [ \\mathcal{x } \\,p(c , t ) \\right ]      \\;,\\end{aligned}\\ ] ] where @xmath16 represents the covariance of the random process denoted by @xmath13 in eq .  .",
    "note that @xmath16 generally depends on @xmath17 .",
    "we have suppressed this dependence to simplify the notation .",
    "this fpe can be solved analytically only in a very restricted number of cases , such as when @xmath12 and @xmath16 are linear .",
    "note that instead of deriving the fpe from a phenomenological set of sde s , one could have also started from the chemical master equation   and applied an appropriate limiting procedure to recover the fpe @xcite .",
    "the fpe could be solved numerically using traditional algorithms for partial differential equations such as finite elements and finite differences .",
    "since these methods rely on spatial and temporal discretization , the grid size grows exponentially with the number of dimensions which makes them impractical for systems with several chemical species .",
    "another possibility is to simulate many individual trajectories of the sde system , eq .  , using numerical algorithms for stochastic differential equations @xcite , and reconstruct the probability density function from these trajectories .",
    "however , as dimensionality increases , each individual path will cover an increasingly smaller portion of phase space , which means a huge number of paths must be simulated to obtain sufficient statistics .",
    "therefore , this method is also impractical for larger systems .",
    "however , in our test applications below ( which are small systems ) , we use this exact approach as a reference for our approximation scheme .",
    "the method here proposed relies on describing the probability distribution by only a small set of parameters , which evolve through time . to implement this idea ,",
    "let us approximate the distribution @xmath18 at each time point by a gaussian distribution , @xmath19 here , @xmath20 and @xmath21 is a scalar product over the space of network state vectors . in the gaussian approximation , knowledge of the temporal dynamics of its average @xmath22 and",
    "covariance matrix @xmath23 is sufficient , which enormously simplifies all calculations .",
    "the proposed method consists of calculating @xmath24 and @xmath25 such that the gaussian approximation best represents @xmath26 in an information theoretic sense .",
    "the resulting equations for @xmath24 and @xmath25 can be efficiently solved numerically .",
    "how well the true non - gaussian probability distribution can be approximated by distribution is of course critical to the performance of our approach , as will become clear in our test applications .",
    "since we are approximating the probability distribution by the gaussian , only the time evolution of the first two moments needs to be calculated .",
    "hence we seek closed ordinary differential equations ( odes ) for the average and the covariance matrix , instead of solving a partial differential equation for the full probability distribution .",
    "these odes are specified by two functions , @xmath27 and @xmath28 such that @xmath29 the simplest approach is the so - called linear noise approximation @xcite , where the evolution of the covariance is determined strictly locally , by the jacobian @xmath30 of the function @xmath12 at the current average concentration @xmath24 , @xmath31 in our test applications below , we use this linear noise approximation as a reference for comparison to our proposed method .    for our method",
    ", we now derive evolution equations of the general form that go beyond the strictly local treatment of the linear noise approximation .",
    "thereby , we seek to better preserve the characteristics of the original nonlinear stochastic system .",
    "we will construct @xmath27 and @xmath28 using the concept of entropic matching for evolving distributions @xcite .",
    "roughly , our procedure is to assume an initial gaussian distribution for @xmath17 , evolve it according to the nonlinear function @xmath12 , and then find the gaussian distribution which best matches it in an information theoretic sense .",
    "a gaussian distribution @xmath32 characterized by @xmath33 and @xmath34 will evolve according to the dynamics described by the nonlinear function @xmath12 and the noise covariance @xmath16 . for now , we focus on the deterministic part of this evolution and add the intrinsic noise below . after an infinitesimal time step @xmath35",
    ", the evolved distribution function @xmath36 will be @xmath37 according to the rule of change of variables for probabilities , where @xmath38 and thus @xmath39 to leading order in @xmath35 .",
    "@xmath36 is a normalized probability distribution , although it is in general not of gaussian functional form .",
    "obviously a representation such as @xmath40 with an updated @xmath41 and @xmath42 at @xmath43 is no longer exact .",
    "however , we can determine values for @xmath44 and @xmath45 such that the information content of @xmath36 is represented as well as possible .",
    "information theoretical considerations @xcite single out the maximum entropy principle for this process .",
    "this principle is equivalent to requiring a minimal kullback - leibler ( kl ) divergence @xcite of @xmath46 to @xmath47 , or a minimal relative gibbs free energy @xcite .",
    "all these measures ( relative entropy , kullback - leibler divergence , and gibbs free energy ) can be regarded as a measure of the information theoretical distance between two distributions , although they are not a metric in the strict mathematical sense due to their asymmetry with respect to the different roles of the matching and matched distributions .",
    "the kullback - leibler divergence is defined by @xmath48 where @xmath49 and @xmath50 are probability distributions .",
    "it is possible to symmetrize the kl divergence in order to obtain a proper metric .",
    "however in this work we have chosen to use the original kl divergence due to the different roles each of the arguments play in entropic matching : @xmath51 is the approximative distribution matched ( by changing its free parameters ) to @xmath52 , which is fixed ( and assumed to be correct for the purpose of matching ) . in this setting , @xmath52 plays the role of a prior in phase space .",
    "then the kl divergence represents the information loss entailed by approximating @xmath50 with the distribution @xmath49 . by constraining @xmath49 to be gaussian and allowing its parameters to vary freely ,",
    "we obtain the gaussian distribution with the highest information content about q. furthermore , this functional form allows for analytical calculations and the derivation of an explicit expression for the evolution of the gaussian parameters , whereas the symmetrized kl divergence would not .",
    "specifically , in our method , we match the parameters of the gaussian @xmath53 to the time evolved distribution @xmath47 by minimizing the kl divergence , @xmath54 we can consider this expression as a functional to be minimized with respect to all degrees of freedom of our matching distribution , or simply as a function of the parameters @xmath55 and @xmath45 to be minimized with respect to their finite number of degrees of freedom . the minimum will define a gaussian distribution which has maximal information content about the time evolved distribution @xmath47 subject to a deterministic nonlinear evolution .    defining @xmath56 , since the kullback - leibler divergence is now a function only of the parameters of the gaussian , eq .   is explicitly @xmath57 \\ ; , \\end{split}\\ ] ] where @xmath47 was expressed as a function of @xmath58 .",
    "this representation is obtained by expressing @xmath59 as a finite difference , and becomes exact in the limit of @xmath60 which is taken below to derive the differential equation .",
    "thus the entropic divergence between the gaussian @xmath53 and the time evolved former gaussian @xmath47 , eq .",
    ", can be brought into the form @xmath61\\\\      & + \\frac{1}{2 } ( \\bar{c}'-\\bar{c})^t c^{-1 } ( \\bar{c}'-\\bar{c})- \\delta t ( \\bar{c}'-\\bar{c})^t c^{-1 } \\left\\langle f(c ' ) \\right\\rangle_{c'},\\\\ \\end{split}\\ ] ] where @xmath62 denotes the expectation value with respect to @xmath63 .",
    "the desired values of @xmath44 and @xmath45 are obtained via minimization of eq .",
    ", i.e. by setting the derivative of @xmath64 with respect to @xmath44 and @xmath45 to zero , leading to @xmath65    we can now add the effect of the intrinsic noise .",
    "the noise added to the stochastic variable @xmath17 over the infinitesimal time @xmath35 has a gaussian distribution with covariance matrix @xmath66 .",
    "therefore , the probability distribution for @xmath55 including noise is the convolution of this noise gaussian with our maximally informative gaussian with the parameters , @xmath67 by performing this convolution and taking the limit @xmath60 , we obtain the final odes for the evolution of the gaussian approximation of our system , @xmath68 these are the general equations for our method .",
    "they are similar in form to the linear noise approximation but with a key difference : in our method , the function @xmath69 and its jacobian are averaged over the current ( gaussian ) probability distribution .",
    "as we have seen , this form follows from the maximum entropy principle .    in general ,",
    "the gaussian expectation value of a nonlinear function is not analytically accessible in a closed form .",
    "one option for the numerical implementation of our method is to calculate these averages , at each time point , by numerical integration .",
    "alternatively , one can reduce the numerical effort using analytical approximations of the averages . towards this end , we expand the function @xmath69 around @xmath22 , @xmath70 and calculate the average of @xmath12 and its derivatives separately for each term , @xmath71 which is justified when the spread of the pdf around its average is not too large .",
    "if we were to take only the @xmath72 and @xmath73 terms of the expansion , we would recover the linear noise approximation .",
    "however , our derivation based on the maximum entropy principle suggests that the linear noise approximation can be improved by keeping additional terms in this series .",
    "our test applications below show that with only the leading corrections included , i.e. those explicitly shown in , significant improvements are already obtained over the linear approximation .",
    "this is also plausible intuitively , since the leading correction introduces the feedback from the evolution of the covariance on the evolution of the mean .",
    "clearly , we expect that in cases in which the dynamical equations are highly nonlinear or have several fixed points , the method will fail as the gaussian approximation can not accurately represent , for instance , a multimodal probability distribution .",
    "it is thus important to quantify the error made by the method .",
    "unfortunately , as for the linear noise approximation , a simple _ a priori _ error estimate is not readily available for our method .",
    "it appears that the only reliable way to determine whether the time evolved approximate distribution faithfully represents the exact distribution is a comparison to full stochastic simulations , which could be performed at least at a selected small set of points in the parameter space of the stochastic dynamical system .",
    "these points can be selected based upon a nonlinear dynamics analysis of the deterministic dynamical equations defined by @xmath12 ( fixpoint and stability analysis ) .",
    "to illustrate the benefits and limitations of our method , we now apply it to several test cases . in these applications , we integrated the odes of with the adams - moulton method @xcite .",
    "this implicit integration scheme is appropriate here due to its numerical robustness , which can successfully deal with the stiffness of the odes in the general nonlinear case . we compared the results to stochastic simulations of the system dynamics using the stochastic analogue of the euler scheme , and also to the linear noise approximation .      as a convenient initial test case",
    ", we chose a system of van der pol oscillators @xcite , which exhibits limit cycle behavior . here , a single parameter controls the strength of the nonlinearity , which facilitates our study of the method s performance as a function of this nonlinearity strength .",
    "furthermore , it has the convenient property that we can calculate the expectation values in exactly , since the taylor expansion of its function @xmath12 terminates at the third order .",
    "thus , in this case our method yields the optimal gaussian approximation ( in the sense of minimal kullback - leibler divergence ) and the only approximation consists of the fact that it enforces a gaussian shape for the probability distribution .",
    "the dynamics of our stochastic van der pol system are described by the stochastic differential equations @xmath74 where the parameter @xmath75 controls the nonlinearity , the matrix @xmath76 controls the coupling between the different degrees of freedom ( indexed by @xmath77 , with @xmath78 here ) , and the vector @xmath79 sets the oscillation frequency of each oscillator .",
    "we assumed constant and independent noise @xmath80 for each oscillator by taking the diagonal covariance matrix @xmath81 in all calculations and simulations .",
    "the system is transformed to a system of first order stochastic differential equations in the usual way by considering the vectors @xmath82 and @xmath83 as the dynamic variables .",
    "the parameter values used in the examples were : for the coupling , @xmath84 except @xmath85 , @xmath86 , @xmath87 ; and for the frequencies , @xmath88 . for the nonlinearity parameter @xmath75 , we used two different values , @xmath89 and @xmath90 , corresponding to weak and moderate nonlinearity , respectively .",
    "as initial condition , @xmath91 and @xmath92 for the deterministic part and added noise according to .",
    "we first considered the case of weak nonlinearity ( @xmath93 ) .",
    "[ fig : osc1traj ] ( top ) shows exemplary trajectories of the coordinate @xmath94 from our full stochastic simulations of the system .",
    "the mean and variance of @xmath94 over 1000 trajectories is shown in the middle and bottom panel , respectively , as a solid line . superimposed",
    "are the corresponding curves for the linear noise approximation ( dotted line ) and our method ( dashed line ) . with both methods",
    ", we used the same initial values for the averages and initialized the covariance matrix by the value of the intrinsic noise level .",
    "both approximations describe the simulation very well ( the agreement in the case of the mean value in the middle panel is so close that the individual curves appear indistinguishable ) .",
    "this behavior is expected , since for @xmath93 the system is almost linear",
    ".     runs ( some individual runs are plotted ) of system and corresponding average value for the first species of a system with @xmath95 and @xmath78 .",
    "middle panel : comparison of stochastic average value ( solid ) with prediction using eq .",
    "( dashed ) and eq .",
    "( dotted ) .",
    "bottom panel : comparison of standard deviation for the stochastic simulation ( solid ) with prediction using eq .",
    "( dashed ) and eq .",
    "( dotted).,width=321 ]    in terms of computational effort , the full stochastic simulation consisted of @xmath96 runs of the system with time step @xmath97 .",
    "such a small time step was necessary to ensure correct results with the euler method .",
    "for the approximation methods , we performed a single run of the adams - moulton method with @xmath98 . in this case , however , decreasing @xmath35 to @xmath99 had no effect on the accuracy of the obtained trajectories .",
    "in practice , the approximation methods were two orders of magnitude faster than the stochastic simulations at the same time step ( which could be safely reduced for the former , to obtain a further significant reduction of computational effort ) .    to compare the approximations with the full simulation also on the level of the probability distributions , the first three panels of fig .",
    "[ fig : osc1hist ] show the distributions for @xmath100 , @xmath101 , and @xmath102 at time @xmath103 ( histograms from the stochastic simulation .",
    "superimposed are the gaussian distributions ( solid lines ) obtained from our method , which describe the histograms well .",
    "since we can visualize only projections of the full multivariate distribution , we also calculated the @xmath104 ( chi - square ) probability distribution , which can help to verify if the full distribution does indeed match a gaussian with the predicted center and correlation matrix : if the prediction matches the simulation , a histogram of @xmath105 , where @xmath106 and @xmath107 are the predicted average and covariance , should match the chi - square distribution for a gaussian @xmath108 with @xmath1 degrees of freedom , where @xmath1 is the number of dimensions of the system .",
    "the bottom panel of fig .",
    "[ fig : osc1hist ] shows that this is indeed the case for @xmath93 .",
    "runs of system with @xmath95 and @xmath78 and the corresponding gaussian ( solid line ) predicted by our method at the final time @xmath109 ( in this case @xmath110 ) .",
    "the first three panels show the distributions of @xmath100 , @xmath101 , and @xmath102 , respectively .",
    "bottom panel : histogram of chi squared distribution for the stochastic simulation data compared to the @xmath104 distribution with 3 degrees of freedom.,width=321 ]    we then considered the case of moderately strong nonlinearity ( @xmath111 ) .",
    "[ fig : osc3traj ] is the equivalent of fig .  [",
    "fig : osc1traj ] for this case .",
    "the middle panel shows that there is now a significant deviation between the mean trajectory from the simulations and the predictions of the approximation schemes .",
    "when comparing the result of the linear noise approximation ( dotted line ) with that of the entropically matched scheme ( dashed line ) , it is apparent that entropic matching performs better .",
    "we attribute this to the dampening caused by progressive loss of synchronization between individual stochastic trajectories .",
    "this feedback effect from the dynamics of the covariance onto the dynamics of the mean is included only in our method .",
    "it becomes evident by working out eq .",
    "explicitly for the van der pol system , revealing damping terms proportional to the magnitude of the fluctuations .",
    "but for moderately strong nonlinearity ( @xmath111).,width=321 ]    the behavior of the variance shown in the bottom panel of fig .",
    "[ fig : osc3traj ] is consistent with this interpretation . in the linear noise approximation ,",
    "the estimate for the variance strongly oscillates around the true value , under or overestimating it , until finally losing synchrony .",
    "in contrast , our method consistently underestimates the variance ( inherent to the gaussian approximation , since the true distribution exhibits more significant tails , see fig .  [",
    "fig : osc3hist ] , first panel ) but always remains synchronous with the true value .",
    "thus we consider the estimate produced by entropic matching to be more robust .",
    "also , we found that in some parameter regimes , the covariance matrix diverges within the linear noise approximation while the entropically matched scheme still produces finite estimates .",
    "[ fig : osc3hist ] shows the distributions as in fig .",
    "[ fig : osc1hist ] , now for our case of moderately strong nonlinearity .",
    "we note that the distribution remains unimodal for two components of the system while it becomes bimodal for one . even though the unimodal distributions are non gaussian our method still approximates their average and standard deviation well , which is the intended behavior . in the chi - square distribution of the bottom panel , it is also visible that the multivariate gaussian no longer captures the shape of the distribution .",
    "this illustrates that the chi - square histogram is indeed a good indicator for the extent to which a multidimensional distribution has gaussian shape .",
    "more generally , the chi - square distribution can be a very convenient measure for the quality at which our approximation describes the full stochastic dynamics of a higher - dimensional system .",
    "but for moderately strong nonlinearity ( @xmath111).,width=321 ]    taken together , this test application has illustrated that our method can still lead to a fair description of a stochastic dynamical system with moderately strong nonlinearity , considerably better than the linear noise approximation at similar computational effort , and much less computational effort than full simulation .      as a second test application",
    ", we studied a simple model for a genetic circuit .",
    "the model consists of a system of mutually repressing genes inspired by the `` repressilator '' @xcite , which exhibits noisy oscillations in a certain range of the parameter regime . in the model , gene regulation",
    "is described by hill - type regulation functions , where each gene is repressed by another in the circuit , such that @xmath112 where @xmath113 ( and @xmath114 represents the modulo operator ) , @xmath115 is the expression level of the input gene at which the target is repressed by @xmath116 , and @xmath4 is the binding cooperativity or hill exponent ( with increasing @xmath4 making the regulation more nonlinear , i.e. step - like ; in the following , we assume @xmath117 ) .    for the case of gene regulation",
    ", the noise can not be assumed to be constant , but rather scales with the mean level . in the case of intrinsic noise , which we assume here , @xmath118 , i.e. the variance increases linearly with the mean @xcite .",
    "as mentioned above , we assume concentrations large enough such that @xmath119 can be regarded as continuous . in order to enable us to apply the exact same mathematical framework as in the previous section",
    ", we perform a change of variables by introducing a new variable @xmath120 such that @xmath121 where now the noise @xmath122 has constant variance ( @xmath123 in our numerical example ) .",
    "we again assume a gaussian white noise process for @xmath122 , which means that the distribution of @xmath119 obtains a log - normal shape .",
    "note that the precise shape of the distribution is not important here , since we are not trying to describe a specific experiment , but use as a toy model for illustration .",
    "in contrast to the previous test application , our approximation of the averages ( again truncated after the leading correction to the linear noise approximation ) is not exact in this example . therefore , the genetic circuit example also serves us to test whether this approximation significantly degrades the benefits of the method .",
    "[ fig : genetraj ] characterizes the stochastic nonlinear dynamics of this model and the performance of the approximation schemes in the same way as fig .",
    "[ fig : osc1traj ] does for the van der pol oscillator system .",
    "the exemplary individual trajectories from the stochastic simulation , shown in the top panel , clearly convey how significant the noise is in the regime of our simulation .",
    "but for the genetic circuit model with @xmath117 and @xmath78.,scaledwidth=50.0% ]    the middle and bottom panels show that entropic matching again leads to a better description of the simulation than the linear noise approximation , with similar behaviour as in the previous case .",
    "this indicates that enforcing the probability distribution to be gaussian constitutes a more drastic approximation than neglecting the higher sub - leading orders in the expansion . from the histograms in fig .",
    "[ fig : genehist ] we can see that the distributions remain unimodal , but are slightly asymmetrical . however , the gaussian approximation is still relatively good , as evidenced also by the chi - squared distribution in the bottom panel .",
    "runs of genetic circuit model with @xmath117 and @xmath78 .",
    ", scaledwidth=50.0% ]",
    "this paper proposes an approximation method to predict the evolution of stochastic nonlinear systems such as biochemical networks .",
    "the method is based on entropic matching strategy @xcite developed to construct simulation schemes based on the information theoretical concept of the maximum entropy principle . for each step in the time evolution of a system ,",
    "the probability distribution describing the state of the system is matched to a gaussian and odes for the first and second moments of the distribution are derived ( eq .  [ eq : solution ] ) .",
    "the evolution of these moments then tracks the average and covariance of the system parameters .",
    "we have implemented these equations numerically employing a series expansion to compute the gaussian expectation values in .",
    "we found that this scheme leads to a more accurate approximation method , which is useful in a wider parameter regime than the linear noise approximation . in the cases where the system s intrinsic noise is very low or",
    "the network dynamics are approximately linear , both methods work equally well . for moderate noise and weak nonlinearity ,",
    "our method outperforms the linear noise approximation .",
    "just as the linear noise approximation , our method is much faster than full stochastic simulation due to a number of factors . to begin with , numerical algorithms for",
    "the solution of sdes can not guarantee convergence as fast as standard ode routines . as an example",
    ", the commonly used stochastic euler scheme has an order of convergence of merely @xmath124 whereas the adams - moulton method we use has an order of convergence of @xmath125 .",
    "algorithms with even faster convergence orders are available and simple to implement .",
    "on the other hand , more advanced algorithms for sdes yield marginally better convergence at the cost of high complexity in terms of implementation  @xcite .",
    "the upshot is that much smaller time steps must be used for a stochastic simulation , thereby increasing run time .",
    "a second important point is the issue of sampling statistics . to sample from the probability distribution of interest with good accuracy , one must obtain thousands of paths from the sde simulation with variance scaling as @xmath126 .",
    "importance sampling can mitigate this problem somewhat , but the number of paths required is still very high . on the other hand ,",
    "the linear noise approximation and our scheme both require only one evaluation .",
    "a complication with our method ( compared to the linear noise approximation ) is the calculation of higher order derivatives .",
    "however , algorithmic differentiation methods@xcite allow to calculate derivative tensors of any order very efficiently .",
    "the calculation of these tensors is comparable in complexity to the calculation of the original function , being slower by only a fixed constant depending on the order of the derivative .    in the case of strong nonlinearities ,",
    "stochastic simulations are still the preferred method .",
    "clearly , multimodal or highly asymmetric target distributions will be poorly approximated by a multivariate gaussian . to remedy this",
    ", a possibility would be the use of a gaussian mixture to represent the different modes of the probability distribution .",
    "however , this approach brings with it a number of problems as the entropic divergence can not be computed analytically in this case .",
    "additionally the number of parameters to be determined would scale at least as @xmath127 , where @xmath128 is the number of gaussian mixture components .",
    "this can become unfeasible for a large number of mixture components .",
    "we envisage that an important application of our method will be the reverse engineering of genetic regulation networks ( see , e.g. @xcite ) , where the values for the parameters @xmath10 will represent the network structure and kinetic parameters . to infer the parameter values from the data ,",
    "it is necessary to calculate the posterior density @xmath129 where @xmath130 represents the prior knowledge about the parameters of the system .",
    "thus , the posterior density can be obtained once we have calculated the likelihood or `` forward probability '' @xmath131 for all relevant time points .",
    "the proposed method may be sufficient to derive an efficient inference scheme for stochastic nonlinear networks , an issue left for the future ."
  ],
  "abstract_text": [
    "<S> the simulation of complex stochastic network dynamics arising , for instance , from models of coupled biomolecular processes remains computationally challenging . </S>",
    "<S> often , the necessity to scan a models dynamics over a large parameter space renders full - fledged stochastic simulations impractical , motivating approximation schemes . </S>",
    "<S> here we propose an approximation scheme which improves upon the standard linear noise approximation while retaining similar computational complexity . </S>",
    "<S> the underlying idea is to minimize , at each time step , the kullback - leibler divergence between the true time evolved probability distribution and a gaussian approximation ( entropic matching ) . </S>",
    "<S> this condition leads to ordinary differential equations for the mean and the covariance matrix of the gaussian . for cases of weak nonlinearity , </S>",
    "<S> the method is more accurate than the linear method when both are compared to stochastic simulations . </S>"
  ]
}