{
  "article_text": [
    "the theory of nonlinear filtering concerns the estimation of a signal corrupted by white noise , and has diverse applications in target tracking , signal processing , automatic control , finance , and so on .",
    "the basic setting of the theory involves a markov signal process , for example , the solution of a ( nonlinear ) stochastic differential equation or a finite - state markov process , observed in independent corrupting noise .",
    "the calculation of the resulting filters is a classical topic in stochastic analysis @xcite .",
    "of course , the filtering equations will depend explicitly on the model chosen for the signal process and observations ; in almost all realistic applications , however , the model that underlies the filter is only an approximation of the true system that generates the observations . in order for the theory to be practically useful ,",
    "it is important to establish that the filtered estimates are not too sensitive to the choice of underlying model .",
    "continuity with respect to the model parameters of nonlinear filtering estimates on a fixed _ finite _ time interval is well established , for example , @xcite ; generally speaking , it is known that the error incurred in a finite time interval due to the choice of incorrect model parameters can be made arbitrarily small if the model parameters are chosen sufficiently close to those of the true model . as",
    "the corresponding error bounds grow rapidly with the length of the time interval , however , such estimates are of little use if we are interested in robustness of the filter over a long period of time .",
    "one would like to show that the approximation errors do not accumulate , so that the error remains bounded uniformly over an _ infinite _ time interval .",
    "the model robustness of nonlinear filters on the infinite time horizon was investigated in discrete time in @xcite .",
    "the key idea that allows one to control the accumulation of approximation errors is the asymptotic stability property of many nonlinear filters , which is the focus of much recent work ( see @xcite and the references therein ) and can be summarized as follows .",
    "the optimal nonlinear filter is a recursive equation that is initialized with the true distribution of the signal process at the initial time .",
    "if the filter is initialized with a different distribution , then the resulting filtered estimates are no longer optimal ( in the least - squares sense ) .",
    "the filter is called asymptotically stable if the solution of the wrongly initialized filter converges to the solution of the correctly initialized filter at large times ; that is , the filter `` forgets '' its initial condition after a period of observation .    using an approximate filter rather than",
    "the optimal filter is equivalent to using the optimal filter where we make an approximation error after every time step .",
    "now suppose the optimal filter forgets its initial condition at an exponential rate ; then also the approximation error at each time step is forgotten at an exponential rate , and the errors can not accumulate in time .",
    "if the approximation error at each time step is bounded ( finite time robustness ) , then the total approximation error will be bounded uniformly in time .",
    "model robustness on the infinite time horizon is thus a consequence of finite time robustness together with the exponential forgetting property of the filter .",
    "this is precisely the method used in @xcite , and its implementation is fairly straightforward once bounds on the exponential forgetting rate of the filter have been obtained .",
    "however , the method used there does not extend to nonlinear filtering in continuous time ; even the continuous time model with point process observations studied in @xcite , though more involved , reduces essentially to discrete ( but random ) observation times .",
    "the continuous time case requires different tools , which we develop in this paper in the setting of nonlinear filtering of a finite - state markov signal process .",
    "( we also mention @xcite , where a different but related problem is solved . )",
    "we consider the following filtering setup .",
    "the signal process @xmath0 is a continuous time , homogeneous markov chain with values in the finite alphabet @xmath1 , transition intensities matrix @xmath2 and initial distribution @xmath3 .",
    "the observation process @xmath4 is given by @xmath5 where @xmath6 is the observation function [ we will also write @xmath7 and @xmath8 is a wiener process that is independent of @xmath9 .",
    "the filtering problem for this model concerns the calculation of the conditional probabilities @xmath10 from the observations @xmath11 , where @xmath12 .",
    "it is well known that @xmath13 satisfies the wonham equation @xcite @xmath14 where @xmath15 denotes the transpose of @xmath16 and @xmath17 .",
    "note that the wonham equation is initialized with the true distribution of @xmath18 ; we will denote by @xmath19 the solution of the wonham equation at time @xmath20 with an arbitrary initial distribution @xmath21 , and by @xmath22 the solution of the wonham equation at time @xmath23 with the initial condition @xmath24 . in @xcite",
    "the exponential forgetting property of the wonham filter was established as follows : the @xmath25-distance @xmath26 decays exponentially a.s . , provided the initial distributions are equivalent @xmath27 and that the _ mixing condition _ @xmath28 @xmath29 is satisfied",
    ". now consider the wonham filter with incorrect model parameters : @xmath30 where @xmath31 and @xmath32 denote a transition intensities matrix and observation function that do not match the underlying signal - observation model @xmath33 , @xmath34 , and we denote by @xmath35 the solution of this equation with initial condition @xmath36 and by @xmath37 the solution with @xmath38 .",
    "the following is the main result of this paper .",
    "[ thm : mainresult ] suppose @xmath39 @xmath40 and @xmath41 @xmath42 .",
    "then @xmath43 where @xmath44 and the quantities @xmath45 are bounded on any compact subset of parameters @xmath46 . additionally we have the asymptotic estimate @xmath47 in particular , this implies that if @xmath48 @xmath40 , @xmath28 @xmath42 , then @xmath49    let us sketch the basic idea of the proof . rather than considering the wonham filter ,",
    "let us demonstrate the idea using the following simple caricature of a filtering equation .",
    "consider a smooth `` observation '' @xmath50 and a `` filter '' whose state @xmath51 is propagated by the ordinary differential equation @xmath52 .",
    "similarly , we consider the `` approximate filter '' @xmath53 and assume that everything is sufficiently smooth , so that for fixed @xmath54 both equations generate a two - parameter flow @xmath55 , @xmath56 .",
    "the following calculation is straightforward : @xmath57\\,ds\\\\ \\\\ & = & \\int_0^t d\\tilde\\varphi^y_{s ,",
    "t}(\\varphi^y_{0,s}(x))\\cdot \\bigl(f(\\varphi^y_{0,s}(x),y_s)-\\tilde f(\\varphi^y_{0,s}(x),y_s)\\bigr)\\,ds,\\end{aligned}\\ ] ] where @xmath58 denotes the directional derivative of @xmath59 in the direction @xmath60",
    ". hence we obtain the following estimate on the approximation error : @xmath61 , where @xmath62 as @xmath63 ; this is an expression of finite - time robustness , as it ensures that @xmath64 ( for fixed @xmath20 ) as @xmath63 .",
    "suppose furthermore that we can establish a bound of the form @xmath65 , that is an infinitesimal perturbation to the initial condition is forgotten at an exponential rate",
    ". then the estimate above is uniformly bounded and converges to zero uniformly in time as @xmath63 .",
    "conceptually this is similar to the logic used in discrete time , but we have to replace the exponential forgetting of the initial condition by the requirement that the derivative of the filter with respect to its initial condition decays exponentially .",
    "returning to the wonham filter , this procedure can be implemented in a fairly straightforward way if @xmath66 . in this case",
    ", most of the work involves finding a suitable estimate on the exponential decay of the derivative of the filter with respect to its initial condition ; despite the large number of results on filter stability , such estimates are not available in the literature to date .",
    "we obtain estimates by adapting methods from @xcite , together with uniform estimates of the concentration of the optimal filter near the boundary of the simplex .",
    "the general case with @xmath67 is significantly more involved .",
    "the problem is already visible in the simple demonstration above .",
    "note that the integrand on the right - hand side of the error estimate is not adapted ; it depends on the observations on the entire interval @xmath68 $ ] .",
    "as the wonham filter is defined in terms of an it - type stochastic integral , this will certainly get us into trouble .",
    "when @xmath66 the stochastic integral cancels in the error bound and the problems are kept to a minimum ; in the general case , however , we are in no such luck . nonetheless this problem is not prohibitive , but it requires us to use the stochastic calculus for anticipating integrands developed by nualart and pardoux @xcite using skorokhod integrals rather than it integrals and using malliavin calculus tools",
    ".    an entirely different application of the malliavin calculus to problems of filter stability can be found in @xcite .",
    "the remainder of this paper is organized as follows . in section [ sec : prelims ]",
    "we prove some regularity properties of the solution of the wonham equation .",
    "we also demonstrate the error estimate discussed above in the simpler case @xmath66 , and comment on the more general applicability of such a bound . in section [ sec :",
    "forgetting ] we obtain exponential bounds on the derivative of the wonham filter with respect to its initial condition .",
    "section [ sec : robustness ] treats the general case @xmath67 using anticipative stochastic calculus ; some of the technical estimates appear in appendix [ sec : proofs ] .",
    "finally , appendix [ sec : malliavin ] contains a brief review of the results from the malliavin calculus and anticipative stochastic calculus that are needed in the proofs .",
    "the signal - observation pair @xmath33 is defined on the standard probability space @xmath69 .",
    "the expectation with respect to @xmath70 is denoted by @xmath71 or sometimes @xmath72 . for @xmath73 ,",
    "we denote by @xmath74 the @xmath25-norm , by @xmath75 the @xmath76-norm , and by @xmath77 the @xmath78-norm .",
    "we write @xmath79 ( resp .",
    "@xmath80 ) if @xmath81 ( @xmath82 ) @xmath40 .",
    "the following spaces will be used throughout .",
    "probability distributions on @xmath83 are elements of the simplex @xmath84 .",
    "usually , we will be interested in the interior of the simplex @xmath85 .",
    "the space of vectors tangent to @xmath86 is denoted by @xmath87 .",
    "finally , we will denote the positive orthant by @xmath88 .",
    "equation ( [ eq : wonham ] ) is a nonlinear equation for the conditional distribution @xmath13 .",
    "it is well known however ( e.g. @xcite ) that @xmath13 can also be calculated in a linear fashion : @xmath89 , where the unnormalized density @xmath90 is propagated by the zakai equation @xmath91 we will repeatedly exploit this representation in what follows . as before @xmath92 and @xmath93 ( @xmath23 ) denote the solution of the zakai equation at time @xmath20 with the initial condition @xmath94 and @xmath95 , respectively , and @xmath96 .",
    "we also recall the following interpretation of the norm @xmath97 of the unnormalized conditional distribution .",
    "if we define a new measure @xmath98 through @xmath99 then under @xmath100 the observation process @xmath101 is an @xmath102-wiener process .",
    "this observation will be used in section [ sec : robustness ] to apply the malliavin calculus .",
    "the main goal of this section is to establish some regularity properties of the solutions of the wonham and zakai equations . in particular , as we will want to calculate the derivative of the filter with respect to its initial condition , we have to establish that @xmath22 is in fact differentiable",
    ". we will avoid problems at the boundary of the simplex by disposing of it alltogether : we begin by proving that if @xmath103 , then a.s .",
    "@xmath104 for all times @xmath105 .",
    "@xmath106 .",
    "the following variant on the pathwise filtering method reduces the zakai equation to a random differential equation .",
    "first , we write @xmath107 where @xmath108 is the diagonal matrix with @xmath109 .",
    "note that the matrix @xmath110 has only nonnegative entries .",
    "we now perform the transformation @xmath111 where @xmath112 then @xmath113 satisfies @xmath114 let @xmath115 , @xmath116 be a set such that @xmath117 is continuous for every @xmath118 . then @xmath119 , @xmath120 are continuous in @xmath20 and have strictly positive diagonal elements for every @xmath118 . by standard arguments",
    ", there exists for every @xmath118 , @xmath121 and @xmath122 a unique solution @xmath113 to equation ( [ eq : robustfilt ] ) where @xmath123 is a @xmath124-curve .",
    "moreover , note that @xmath125 has nonnegative matrix elements for every @xmath118 , @xmath126 . hence if @xmath127 then clearly @xmath113 must be nondecreasing , that is , @xmath128 for every @xmath129 and @xmath118 .",
    "but then @xmath130 must be forward invariant under equation ( [ eq : robustfilt ] ) for every @xmath118 , and as @xmath131 has strictly positive diagonal elements the result follows .",
    "@xmath132 .",
    "let us now investigate the map @xmath93 . as this map is linear in @xmath133 , we can write @xmath134 a.s .  where the @xmath135 matrix @xmath136 is the solution of @xmath137 the following lemma establishes that @xmath136 defines a linear stochastic flow in @xmath138 .",
    "[ lem : zakaiflow ] for a.e .",
    "@xmath134 for all @xmath140 ; _ ( ii ) _",
    "@xmath136 is continuous in @xmath141 ; _ ( iii ) _",
    "@xmath136 is invertible for all @xmath140 , where @xmath142 is given by @xmath143 _",
    "( iv ) _ @xmath144 ( and hence @xmath145 ) for all @xmath146 .",
    "continuity of @xmath136 ( and @xmath142 ) is a standard property of solution of lipschitz stochastic differential equations .",
    "invertibility of @xmath147 for all @xmath148 is established in @xcite , page 326 , and it is evident that @xmath149 satisfies equation ( [ eq : zakaiprop ] ) .",
    "the remaining statements follow , where we can use continuity to remove the time dependence of the exceptional set as in the proof of @xcite , page 326 .",
    "we now turn to the properties of the map @xmath22 .",
    "the wonham filter generates a smooth stochastic semiflow in @xmath86 , that is , the solutions @xmath22 satisfy the following conditions :    1 .   for a.e .",
    "@xmath139 , @xmath150 for all @xmath146 and @xmath133 .",
    "2 .   for a.e . @xmath139 , @xmath22 is continuous in @xmath151 .",
    "3 .   for a.e . @xmath139 , the injective map @xmath152 is @xmath153 for all @xmath140 .    for @xmath154 define @xmath155 , so that @xmath156 ( @xmath103 ) . note that @xmath157 is smooth on @xmath130 .",
    "hence continuity in @xmath151 and smoothness with respect to @xmath133 follow directly from the corresponding properties of @xmath93 .",
    "the semiflow property @xmath158 follows directly from lemma [ lem : zakaiflow ] .",
    "it remains to prove injectivity .",
    "suppose that @xmath159 for some @xmath160 .",
    "then @xmath161 , and as @xmath136 is invertible we have @xmath162 . but as @xmath133 and @xmath163 must lie in @xmath86 , it follows that @xmath164 .",
    "hence @xmath165 is injective .",
    "the results in this section hold identically if we replace @xmath166 by @xmath31 , @xmath167 by @xmath32 .",
    "we will use the obvious notation @xmath37 , @xmath168 , @xmath169 , and so on .",
    "we finish this section by obtaining an expression for the approximation error in the case @xmath66 ; in fact , we will demonstrate the bound for this simple case in a more general setting than is considered in the following .",
    "rather than considering the approximate wonham filter with modified @xmath166 , consider the equation @xmath170 where @xmath171 is chosen in such a way that this equation has a strong solution and @xmath172 a.s . in the sequel we consider the case @xmath173 , which clearly satisfies the requirements .",
    "we formulate the more general result here , as it might be of interest in other contexts ( see remark [ rem : projf ] ) .    [",
    "pro : simplebound ] let @xmath174 be as above . then the difference between @xmath174 and the wonham filter started at @xmath133 is a.s .  given by @xmath175 where @xmath176 is the derivative of @xmath22 in the direction @xmath177 .",
    "define the ( scalar ) process @xmath178 by @xmath179 using it s rule , we evaluate @xmath180 multiplying both sides by @xmath147 , we obtain @xmath181 now introduce as before the map @xmath182 , @xmath155 , which is smooth on @xmath183 . define the matrix @xmath184 with elements @xmath185^{ij}=\\frac{\\partial\\sigma^i(x)}{\\partial x^j}= \\frac{1}{|x|}[\\delta_{ij}-\\sigma^i(x)].\\ ] ] note that @xmath186 for any @xmath187 .",
    "hence @xmath188 but then we have , using @xmath189 ( @xmath187 ) , @xmath190 on the other hand , we obtain from the representation @xmath191 @xmath192 note that @xmath193 as we required that @xmath171 , so that @xmath194 . finally , note that @xmath195 and the proof is complete .",
    "[ cor : filterapproximation ] the following estimate holds : @xmath196 .",
    "moreover @xmath197    [ rem : projf ] corollary",
    "[ cor : filterapproximation ] suggests that the method used here could be applicable to a wider class of filter approximations than those obtained by misspecification of the underlying model . in particular , in the infinite - dimensional setting it is known @xcite that by projecting the filter onto a properly chosen finite - dimensional manifold , one can obtain finite - dimensional approximate filters that take a form very similar to equation ( [ eq : filterapproximation ] ) . in order to obtain useful error bounds for such approximations one would need to have a fairly tight estimate on the derivative of the filter with respect to its initial condition .",
    "unfortunately , worst - case estimates of the type developed in section [ sec : forgetting ] are not sufficiently tight to give quantitative results on the approximation error , even in the finite - state case . in the remainder of the article we will restrict ourselves to studying the robustness problem .    in the following",
    ", it will be convenient to turn around the role of the exact and approximate filters in corollary [ cor : filterapproximation ] , that is , we will use the estimate @xmath198 which holds provided @xmath66 .",
    "the proof is identical to the one given above .",
    "in order for the bound equation ( [ eq : simplebound ] ) to be useful , we must have an exponential estimate for @xmath199 .",
    "the goal of this section is to obtain such an estimate .",
    "we proceed in two steps .",
    "first , we use native filtering arguments as in @xcite to obtain an a.s .",
    "exponential estimate for @xmath200 .",
    "as the laws of the observation processes generated by signals with different initial distributions and jump rates are equivalent , we can extend this a.s.bound to @xmath201 .",
    "we find , however , that the proportionality constant in the exponential estimate depends on @xmath133 and diverges as @xmath133 approaches the boundary of the simplex .",
    "this makes a pathwise bound on @xmath202 difficult to obtain , as @xmath203 can get arbitrarily close to the boundary of the simplex on the infinite time interval .",
    "instead , we proceed to find a uniform bound on @xmath204 .",
    "we begin by recalling a few useful results from @xcite .",
    "assume @xmath205 are in the interior of the simplex .",
    "then @xmath206    define a new measure @xmath207 through @xmath208 it is not difficult to verify that under @xmath209 , @xmath210 is still a finite - state markov process with intensities matrix @xmath166 but with initial distribution @xmath211 .",
    "hence evidently @xmath212 . using the usual change of measure formula for conditional expectations ,",
    "we can write @xmath213 the result now follows immediately .",
    "for the proof of the following lemma we refer to @xcite , lemma 5.7 , page 662 .",
    "[ lem : smoothingestimate ] define @xmath214 .",
    "assume that @xmath28 @xmath42 .",
    "then for any @xmath215 we have the a.s . bound @xmath216",
    "we are now ready to obtain some useful estimates .",
    "[ pro : jacoboundsimple ] let @xmath28 @xmath42 and @xmath217 , @xmath218 .",
    "then a.s . @xmath219    we can calculate directly the directional derivative of ( [ eq : wronginirep ] ) : @xmath220 setting @xmath164 , we obtain after some simple manipulations @xmath221 the result follows from lemma [ lem : smoothingestimate ] .    to obtain this bound we had to use the true initial distribution @xmath163 , jump rates @xmath222 and observation function @xmath167 .",
    "however , the almost sure nature of the result allows us to drop these requirements .",
    "[ cor : forgetting ] let @xmath223 @xmath42 and @xmath103 , @xmath177 . then a.s",
    "@xmath224 moreover , the result still holds if @xmath225 are @xmath226-measurable random variables with values a.s . in @xmath86 and @xmath227 , respectively .",
    "note that we can write @xmath228 , where @xmath229 is the measure under which @xmath210 has transition intensities matrix @xmath31 and initial distribution  @xmath133 , and @xmath230 where @xmath231 is a wiener process independent of  @xmath210 . but",
    "@xmath229 and @xmath70 are equivalent measures ( by the girsanov theorem and @xcite , section  iv.22 ) , so that the result for @xmath232 follows trivially from proposition [ pro : jacoboundsimple ] .",
    "the result for @xmath233 follows directly as the wonham equation is time homogeneous .    to show that the result still holds when @xmath225 are random , note that @xmath234 only depends on the observation increments in the interval @xmath235 $ ] , that is , @xmath236 is @xmath237}^y$]-measurable where @xmath237}^y= \\sigma\\{y_r - y_s\\dvtx s\\le r\\le t\\}$ ] . under the equivalent measure @xmath100 introduced in section [ sec : prelims ]",
    ", @xmath238 is a wiener process and hence @xmath237}^y$ ] and @xmath239 are independent .",
    "it follows from the bound with constant @xmath225 that @xmath240 where @xmath241 is the right - hand side of ( [ eq : forgetting ] ) .",
    "hence @xmath242 , and the statement follows from @xmath243 .",
    "[ pro : forgetting ] let @xmath223 @xmath42 and @xmath244 .",
    "@xmath245 where @xmath246 .",
    "define @xmath247 , @xmath248 $ ] .",
    "then @xmath249 we can thus estimate @xmath250}\\big|d\\tilde\\pi_{s , t}\\bigl(\\mu_1+u(\\mu_2-\\mu_1)\\bigr)\\cdot ( \\mu_2-\\mu_1)\\big|.\\ ] ] the result now follows from corollary [ cor : forgetting ] .",
    "corollary [ cor : forgetting ] and proposition [ pro : forgetting ] are exactly what we need to establish boundedness of equation ( [ eq : simplebound ] ) .",
    "note , however , that the right - hand side of ( [ eq : forgetting ] ) is proportional to @xmath251 , and we must estimate @xmath202 . though we established in section [",
    "sec : prelims ] that @xmath203 can not hit the boundary of the simplex in finite time , it can get arbitrarily close to the boundary during the infinite time interval , thus rendering the right - hand side of equation ( [ eq : forgetting ] ) arbitrarily large .",
    "if we can establish that @xmath252 , however , then we can control @xmath204 to obtain a useful bound .",
    "we begin with an auxiliary integrability property of @xmath13 :    [ lem : finiteexpect ] let @xmath217 and @xmath253 .",
    "then @xmath254    applying it s rule to the wonham equation gives @xmath255 where the innovation @xmath256 is an @xmath102-wiener process .",
    "the application of it s rule is justified by a standard localization argument , as @xmath13 is in @xmath86 for all @xmath215 a.s .  and",
    "@xmath257 is smooth in @xmath258 . as @xmath259 for @xmath260",
    ", we estimate @xmath261 but as @xmath262 is bounded , novikov s condition is satisfied and hence @xmath263 estimating the time integral , we obtain @xmath264 the lemma now follows by the fubini  tonelli theorem , as @xmath265 a.s .",
    "we are now in a position to bound @xmath266 .",
    "[ prop : inf ] let @xmath217 and suppose that @xmath28 @xmath42 . then @xmath267    by it s rule and using the standard localization argument",
    ", we obtain @xmath268 where @xmath269 is the innovations wiener process . using lemma [ lem : finiteexpect ] we find @xmath270 so the expectation of the stochastic integral term vanishes . using the fubini  tonelli theorem , we can thus write @xmath271 taking the derivative and estimating each of the terms , we obtain @xmath272 where we have written @xmath273 and we have used @xmath274 by jensen s inequality . using the estimate @xmath275 we now obtain @xmath276 where @xmath277 . consequently we obtain @xmath278 we can now estimate @xmath279 which is what we set out to prove",
    ".    we can now prove theorem [ thm : mainresult ] for the special case @xmath66 .",
    "using equation ( [ eq : simplebound ] ) , corollary [ cor : forgetting ] , proposition [ pro : forgetting ] and proposition [ prop : inf ] , we obtain @xmath280 where @xmath281 .",
    "thus @xmath282 where we have written @xmath283 .",
    "the result follows directly using @xmath284 .",
    "we are now ready to proceed to the general case where the initial density , the transition intensities matrix and the observation function can all be misspecified .",
    "the simplicity of the special case @xmath66 that we have treated up to this point is due to the fact that in the calculation of equation ( [ eq : itodropsout ] ) , the stochastic integral term drops out and we can proceed with the calculation using only ordinary calculus . in the general case",
    "we can not get rid of the stochastic integral , and hence we run into anticipativity problems in the next step of the calculation .",
    "we solve this problem by using anticipative stochastic integrals in the sense of skorokhod , rather than the usual it integral ( which is a special case of the skorokhod integral defined for adapted processes only ) . though the skorokhod integral is more general than the it integral in the sense that it allows some anticipating integrands , it is less general in that we have to integrate against a wiener process ( rather than against an arbitrary semimartingale ) , and that the integrands should be functionals of the driving wiener process . in our setup ,",
    "the most convenient way to deal with this is to operate exclusively under the measure @xmath100 of section  [ sec : prelims ] , under which the observation process @xmath238 is a wiener process . at the end of the day we can calculate the relevant expectation with respect to the measure @xmath70 by using the explicit expression for the radon  nikodym derivative @xmath285 .",
    "the fact that the integrands must be functionals of the underlying wiener process is not an issue , as both the approximate and exact filters are functionals of the observations only .",
    "our setup is further detailed in appendix [ sec : malliavin ] , together with a review of the relevant results from the malliavin calculus and anticipative stochastic calculus . below we will use the notation and results from this appendix without further comment .",
    "we will also refer to appendix [ sec : proofs ] for some results on smoothness of the various integrands we encounter ; these results are not central to the calculations , but are required for the application of the theory in appendix [ sec : malliavin ] .",
    "we begin by obtaining an anticipative version of proposition [ pro : simplebound ] .",
    "note that this result is precisely of the form one would expect .",
    "the first two lines follow the formula for the distance between two flows as one would guess , for example , from the discussion in the ; the last line is an it correction term which contains second derivatives of the filter with respect to its initial condition .",
    "[ pro : anticipativediff ] the difference between @xmath13 and @xmath286 satisfies @xmath287\\,dr \\\\ & & { } + \\tfrac{1}{2}\\int_0^t[d^2\\tilde\\pi_{r , t}(\\pi_r)\\cdot(h - h^*\\pi_r)\\pi_r -d^2\\tilde\\pi_{r , t}(\\pi_r)\\cdot(\\tilde h-\\tilde h^*\\pi_r)\\pi_r]\\,dr,\\end{aligned}\\ ] ] where the stochastic integral is a skorokhod integral and we have written @xmath288 , @xmath289 , and @xmath290 is the directional derivative of @xmath291 with respect to @xmath103 in the direction @xmath177 .    fix some @xmath292 .",
    "we begin by evaluating , using it s rule and equation ( [ eq : zakaiinv ] ) , @xmath293 now multiply from the left by @xmath294 ; we wish to use lemma [ lem : bringintoskor ] to bring @xmath294 into the skorokhod integral term , that is , we claim that @xmath295 to justify this expression we need to verify the integrability conditions of lemma  [ lem : bringintoskor ] .",
    "note that all matrix elements of @xmath169 are in @xmath296 @xmath297 , and that @xmath298 $ , \\cr \\tilde u_{r , t}\\tilde h\\tilde u_{s , r } , & \\quad\\mbox{a.e . } $ r\\in[s , t]$.}\\ ] ] this follows directly from proposition [ pro : sdemalliavin ] and lemma [ lem : zakaiflow ] ( note that the same result holds for @xmath136 if we replace @xmath299 by @xmath300 and @xmath301 by @xmath302 ) .",
    "once we plug this result into the expression above , the corresponding integrability conditions can be verified explicitly , see lemma [ lem : msqintg ] , and hence we have verified that @xmath303 next we would like to apply the anticipating it rule , proposition [ pro : anticipatingito ] , with the function @xmath304 , @xmath155 . to this end",
    "we have to verify a set of technical conditions , see lemma [ lem : canapplyito ] .",
    "we obtain @xmath305 we need to evaluate @xmath306 . using proposition [ pro : chainrulesmooth ] ,",
    "we calculate @xmath307 and similarly @xmath308 after some rearranging , we obtain @xmath309 from this point onward we will set @xmath310",
    ". we will need ( on @xmath130 ) @xmath311 recall that @xmath189 ; it follows that also @xmath312 for @xmath187 . using these expressions with @xmath313",
    ", we get @xmath314 next we want to express the integrands in terms of @xmath315 , and so on , rather than in terms of @xmath184 .",
    "recall that @xmath316 when @xmath177 .",
    "similar terms appear in the expression above , but , for example , @xmath317 . to rewrite the expression in the desired form",
    ", we use that @xmath318 .",
    "hence @xmath319 and similarly for the other terms .",
    "note also that @xmath320 substituting this into the expression for @xmath321 and rearranging , we obtain @xmath322\\,dr \\\\ & & \\hspace*{-1pt}\\qquad\\phantom{= } { } + \\frac{1}{2}\\sum_{k,\\ell}\\int_0^t\\frac{\\partial^2\\sigma } { \\partial x^k\\,\\partial x^\\ell } ( \\tilde u_{r , t}\\pi_r)\\bigl(\\tilde u_{r , t}(h - h^*\\pi_r)\\pi_r\\bigr)^k \\bigl(\\tilde u_{r , t}(h - h^*\\pi_r)\\pi_r\\bigr)^\\ell\\,dr \\\\ & & \\hspace*{-1pt}\\qquad\\phantom{= } { } -\\frac{1}{2}\\sum_{k,\\ell}\\int_0^t\\frac{\\partial^2\\sigma } { \\partial x^k\\,\\partial x^\\ell } ( \\tilde u_{r , t}\\pi_r)\\bigl(\\tilde u_{r , t}(\\tilde",
    "h-\\tilde h^*\\pi_r)\\pi_r\\bigr)^k \\bigl(\\tilde u_{r , t}(\\tilde h-\\tilde h^*\\pi_r)\\pi_r\\bigr)^\\ell\\,dr.\\end{aligned}\\ ] ] it remains to note that we can write @xmath323 the result follows immediately .",
    "we have allowed misspecification of most model parameters of the wonham filter .",
    "one exception is the observation noise intensity : we have not considered observations of the form @xmath324 with @xmath325 ; in other words , the quadratic variation of @xmath101 is assumed to be known @xmath326_t = t$ ] .",
    "we do not consider this a significant drawback as the quadratic variation can be determined directly from the observation process @xmath101 . on the other hand ,",
    "the model parameters @xmath327 are `` hidden '' and would have to be estimated , making these quantities much more prone to modeling errors .",
    "if we allow misspecification of @xmath328 , we would have to be careful to specify in which way the filter is implemented : in this case , the normalized solution of the misspecified zakai equation no longer coincides with the solution of the misspecified wonham equation .",
    "hence one obtains a different error estimate depending on whether the normalized solution of the misspecified zakai equation , or the solution of the misspecified wonham equation , is compared to the exact filter .",
    "both cases can be treated using similar methods , but we do not pursue this here .    let @xmath329 .",
    "we wish to estimate the norm of @xmath330 .",
    "unfortunately , we can no longer use the triangle inequality as in section [ sec : prelims ] due to the presence of the stochastic integral ; instead , we choose to calculate @xmath331 , which is readily estimated .    [ lem : filtererror ] the filtering error can be estimated by @xmath332 where @xmath333 .",
    "we wish to calculate @xmath334 .",
    "using proposition [ pro : anticipativediff ] , we obtain @xmath335 \\\\ & & \\qquad\\phantom{= } { } -\\int_0^t \\mathbf{e_p}\\,e_t^*d\\tilde\\pi_{r , t}(\\pi_r)\\cdot [ h^*\\pi_r\\,(h - h^*\\pi_r)\\pi_r- \\tilde h^*\\pi_r\\,(\\tilde h-\\tilde h^*\\pi_r)\\pi_r]\\,dr \\\\ & & \\qquad\\phantom{= } { } + \\tfrac{1}{2}\\int_0^t \\mathbf{e_p } e_t^*[d^2\\tilde\\pi_{r , t}(\\pi_r)\\cdot(h - h^*\\pi_r)\\pi_r \\\\ & & \\hspace*{90pt}{}-d^2\\tilde\\pi_{r , t}(\\pi_r)\\cdot(\\tilde h-\\tilde h^*\\pi_r)\\pi_r]\\,dr.\\end{aligned}\\ ] ] the chief difficulty is the stochastic integral term . using equation ( [ eq : refmeasure ] )",
    ", we can write @xmath336 \\\\ & & \\qquad = \\mathbf{e_q}\\biggl[|u_{0,t}\\nu|\\,e_t^ * \\int_0^t d\\tilde\\pi_{r , t}(\\pi_r)\\cdot\\delta_h(\\pi_r)\\,dy_r\\biggr].\\end{aligned}\\ ] ] we would like to apply equation ( [ eq : malladjoint ] ) to evaluate this expression .",
    "first , we must establish that the integrand is in @xmath337 ; this does not follow directly from proposition [ pro : anticipativediff ] , as the anticipative it rule which was used to obtain that result can yield integrands which are only in @xmath338 .",
    "we can verify directly , however , that the integrand in this case is indeed in @xmath337 , see lemma [ lem : skorisreal ] .",
    "next , we must establish that @xmath339 is in @xmath340 for every @xmath341 .",
    "note that @xmath342 , so @xmath343 is in @xmath296 .",
    "moreover , we establish in lemma [ lem : regularpis ] that @xmath344 and that @xmath345 is a bounded random variable for every @xmath20 .",
    "hence it follows from proposition [ pro : chainrule ] that @xmath346 .",
    "consequently we can apply equation ( [ eq : malladjoint ] ) , and we obtain @xmath347 \\\\ & & \\qquad = \\int_0^t\\mathbf{e_q}[(|u_{0,t}\\nu|\\,{\\boldsymbol{\\sf d}}_re_t^*+ { \\boldsymbol{\\sf d}}_r|u_{0,t}\\nu|\\,e_t^ * ) d\\tilde\\pi_{r , t}(\\pi_r)\\cdot\\delta_h(\\pi_r)]\\,dr \\\\ & & \\qquad = \\int_0^t\\mathbf{e_q}[|u_{0,t}\\nu|\\,({\\boldsymbol{\\sf d}}_r\\pi_t-{\\boldsymbol{\\sf d}}_r\\tilde\\pi_t)^ * d\\tilde\\pi_{r , t}(\\pi_r)\\cdot\\delta_h(\\pi_r)]\\,dr \\\\ & & \\qquad\\phantom{= } { } + \\int_0^t\\mathbf{e_q}\\biggl[\\sum_i(u_{r , t}hu_{0,r}\\nu)^i\\,e_t^ * d\\tilde\\pi_{r , t}(\\pi_r)\\cdot\\delta_h(\\pi_r)\\biggr]\\,dr.\\end{aligned}\\ ] ] now note that @xmath348 , and that by lemma [ lem : regularpis ] @xmath349 furthermore we can estimate @xmath350 where we have used a.s .",
    "nonnegativity of the matrix elements of @xmath351 and @xmath352 ( this must be the case , as , for example , @xmath353 has nonnegative entries for any vector @xmath133 with nonnegative entries ) . hence we obtain @xmath354 \\\\ & & \\qquad \\le \\biggl(2\\max_k|h^k|+\\max_k|\\tilde h^k|\\biggr )",
    "\\int_0^t\\mathbf{e_q}|u_{0,t}\\nu| |d\\tilde\\pi_{r , t}(\\pi_r)\\cdot\\delta_h(\\pi_r)|\\,dr.\\end{aligned}\\ ] ] the result follows after straightforward manipulations .    unlike in the case @xmath66",
    ", we now have to deal also with second derivatives of the filter with respect to its initial condition .",
    "these can be estimated much in the same way as we dealt with the first derivatives .",
    "[ lem : secondderivs ] let @xmath223 @xmath42 and @xmath103 , @xmath355 . then a.s .",
    "@xmath356 moreover , the result still holds if @xmath357 are @xmath226-measurable random variables with values a.s . in @xmath86 and @xmath227 , respectively .    proceeding as in the proof of proposition [ pro : jacoboundsimple ]",
    ", we can calculate directly the second derivative of ( [ eq : wronginirep ] ) : @xmath358 setting @xmath164 and using the triangle inequality , we obtain @xmath359 another application of the triangle inequality and using proposition [ pro : jacoboundsimple ] gives @xmath360 we can now repeat the arguments of corollary [ cor : forgetting ] to establish that the result still holds if we replace @xmath361 by @xmath234 , @xmath362 by @xmath363 , and @xmath364 by @xmath226-measurable random variables @xmath357 .",
    "this completes the proof .",
    "we are now ready to complete the proof of theorem [ thm : mainresult ] .",
    "proof of theorem [ thm : mainresult ] set @xmath283 .",
    "let us collect all the necessary estimates .",
    "first , we have @xmath365 .",
    "next , we obtain @xmath366 using corollary [ cor : forgetting ] . using the triangle inequality",
    ", we can estimate this by @xmath367 next , we estimate using corollary [ cor : forgetting ] @xmath368 where we have used the estimate @xmath369 next we estimate using lemma [ lem : secondderivs ] @xmath370 we have now estimated all the terms in lemma [ lem : filtererror ] , and hence we have bounded @xmath371 . it remains to allow for misspecified initial conditions . to this end",
    ", we estimate @xmath372 hence we obtain using the equivalence of finite - dimensional norms @xmath373 @xmath374 where we have used that the simplex is contained in the @xmath375-dimensional unit sphere , so @xmath376 @xmath377 .",
    "the statement of the theorem now follows directly from lemma [ lem : filtererror ] , proposition [ pro : forgetting ] and the estimates above .",
    "the goal of this appendix is to recall briefly the main results of the malliavin calculus , skorokhod integrals and anticipative stochastic calculus that are needed in the proofs . in our application of the theory",
    "we wish to deal with functionals of the observation process @xmath378}$ ] , where @xmath110 is some finite time ( usually we will calculate integrals from @xmath379 to @xmath20 , so we can choose any @xmath292 ) .",
    "recall from section  [ sec : prelims ] that @xmath238 is an @xmath102-wiener process under the measure @xmath100 ; it will thus be convenient to work always under @xmath100 , as this puts us directly in the framework used , for example , in @xcite . as the theory described below",
    "is defined @xmath100-a.s . and as @xmath243 , the corresponding properties under @xmath70 are unambiguously obtained by using equation ( [ eq : refmeasure ] ) .",
    "we will presume this setup whenever the theory described here is applied .",
    "a smooth random variable @xmath380 is one of the form @xmath381 , where @xmath382 denotes the wiener integral of the deterministic function @xmath383)$ ] with respect to @xmath238 and @xmath384 is a smooth function which is of polynomial growth together with all its derivatives . for smooth @xmath380",
    "the malliavin derivative @xmath385 is defined by @xmath386 the malliavin derivative @xmath387 can be shown @xcite , page 26 , to be closeable as an operator from @xmath388 to @xmath389))$ ] for any @xmath390 , and we denote the domain of @xmath387 in @xmath391 by @xmath392 [ for notational convenience we will drop the measure @xmath100 and @xmath328-algebra @xmath393 throughout this section , where it is understood that @xmath391 denotes @xmath388 , etc . ] . more generally , we consider iterated derivatives @xmath394^k))$ ] defined by @xmath395 , and the domain of @xmath396 in @xmath391 is denoted by @xmath397 .",
    "the domains @xmath397 can also be localized ( @xcite , pages 4445 ) , and we denote the corresponding localized domains by @xmath398 . finally , we define the useful class @xmath399 .",
    "we will use two versions of the chain rule for the malliavin derivative .    [",
    "pro : chainrule ] let @xmath400 be @xmath124 and @xmath401 be a random vector with components in @xmath340",
    ". then @xmath402 and @xmath403 if @xmath404 and @xmath405)$ ] , then @xmath406 .",
    "these results still hold if @xmath380 a.s",
    ". takes values in an open domain @xmath407 and @xmath408 is @xmath409 .",
    "the first ( local ) statement is @xcite , proposition 2.9 ; the second statement can be proved in the same way as @xcite , lemma a.1 , and the proofs are easily adapted to the case where @xmath380 a.s . takes values in some domain .",
    "the next result is from @xcite , page 62 :    [ pro : chainrulesmooth ] let @xmath400 be a smooth function which is of polynomial growth together with all its derivatives , and let @xmath401 be a random vector with components in @xmath296",
    ". then @xmath410 and the usual chain rule holds .",
    "this implies that @xmath296 is an algebra , that is , @xmath411 for @xmath412 .",
    "the following result follows from @xcite , page 32 ( here @xmath235^c=[0,t]\\backslash [ s , t]$ ] ) .",
    "[ lem : adapted ] if @xmath413 is @xmath414}$]-measurable , then @xmath415 a.e . in @xmath416^c$ ] .",
    "it is useful to be able to calculate explicitly the malliavin derivative of the solution of a stochastic differential equation .",
    "consider @xmath417 , @xmath418 , where @xmath419 and @xmath420 are smooth functions of @xmath16 with bounded derivatives of all orders .",
    "it is well known that such equations generate a smooth stochastic flow of diffeomorphisms @xmath421 @xcite .",
    "we now have the following result .",
    "[ pro : sdemalliavin ] all components of @xmath51 belong to @xmath296 for every @xmath422 $ ] .",
    "we have @xmath423 a.e .",
    "@xmath424 , where @xmath425 is the jacobian matrix of the flow , and @xmath426 a.e . @xmath427 .",
    "the first statement is given in @xcite , theorem 2.2.2 , page 105 , the second on @xcite , equation ( 2.38 ) , page 109 , the third follows from adaptedness ( lemma [ lem : adapted ] ) .",
    "we now consider @xmath387 as a closed operator from @xmath428 to @xmath429)$ ] with domain @xmath340 .",
    "its hilbert space adjoint @xmath430 is well defined in the usual sense as a closed operator from @xmath429)$ ] to @xmath428 , and we denote its domain by @xmath431 . the operator @xmath432 is called the skorokhod integral , and coincides with the it integral on the subspace @xmath433)\\subset \\operatorname{dom}\\bolds\\delta$ ] of adapted square integrable processes ( @xcite , proposition 1.3.4 , page 41 ) .",
    "@xmath432 is thus an extension of the it integral to a class of possibly anticipative integrands . to emphasize this point",
    "we will write @xmath434}\\bigr)=\\int_s^tu_r\\,dy_r,\\qquad ui_{[s , t]}\\in \\operatorname{dom}\\bolds\\delta.\\ ] ] the skorokhod integral has the following properties .",
    "first , its expectation vanishes @xmath435 if @xmath436 .",
    "second , by its definition as the adjoint of @xmath387 we have @xmath437\\ ] ] if @xmath436 , @xmath413 .",
    "we will also use the following result , the proof of which proceeds in exactly the same way as its one - dimensional counterpart ( @xcite , page 40 ) .",
    "[ lem : bringintoskor ] if @xmath438 is an @xmath439-vector of processes in @xmath431 and @xmath380 is an of random variables in @xmath340 such that @xmath440 , then @xmath441 in the sense that @xmath442 iff the right - hand side of this expression is in @xmath428 .",
    "as it is difficult to obtain general statements for integrands in @xmath431 , it is useful to single out restricted classes of integrands that are easier to deal with . to this end , define the spaces @xmath443;\\mathbb{d}^{k , p})$ ] for @xmath444 , @xmath445 .",
    "note that @xmath446 @xcite , page 38 .",
    "moreover , the domains @xmath447 can be localized to @xmath448 ( @xcite , pages 4345 ) .",
    "we can now state an it change of variables formula for skorokhod integrals , see @xcite .",
    "the extension to processes that a.s .",
    "take values in some domain is straightforward through localization .",
    "[ pro : anticipatingito ] consider an @xmath449-dimensional process of the form @xmath450 where we assume that @xmath51 has a continuous version and @xmath451 , @xmath452 , and @xmath453 .",
    "let @xmath454 be a @xmath455 function .",
    "then @xmath456 where @xmath457 , @xmath458,@xmath459 .",
    "the result still holds if @xmath460 a.s .",
    "takes values in an open domain @xmath407 @xmath461 $ ] and @xmath408 is @xmath462 .",
    "[ lem : msqintg ] the following equality holds : @xmath463 the integral on the left - hand side is an it integral , on the right - hand side a skorokhod integral .",
    "we have already established in the proof of proposition [ pro : anticipativediff ] that the matrix elements of @xmath294 are in @xmath464 .",
    "moreover , @xmath465 where we have used the cauchy ",
    "schwarz inequality and @xmath466 for @xmath217 .",
    "here @xmath467 is the elementwise @xmath468-norm of @xmath302 , @xmath469 is the usual matrix @xmath470-norm , and @xmath471 matches the norms @xmath472 ( recall that all norms on a finite - dimensional space are equivalent ) . as @xmath473",
    "are solutions of linear stochastic differential equations , standard estimates give for any integer @xmath445 @xmath474 and we obtain @xmath475 hence we can apply lemma [ lem : bringintoskor ] to obtain the result . by a similar calculation",
    "we can establish that the right - hand side of the expression in lemma [ lem : bringintoskor ] for our case is square integrable , so that the skorokhod integral is well defined .",
    "clearly the skorokhod integral term has a.s .",
    "continuous sample paths , as both @xmath476 and the time integrals do ; moreover , @xmath477 . in order to be able to apply proposition [ pro : anticipatingito ] , it remains to check the technical conditions @xmath478 , @xmath479 .",
    "as @xmath296 is an algebra , @xmath480 and @xmath481 take values in @xmath296 .",
    "moreover , we can establish exactly as in the proof of lemma [ lem : msqintg ] that @xmath438 and @xmath60 are in @xmath482)$ ] . to complete the proof",
    "we must establish that @xmath483^{2}\\,dr<\\infty , \\\\ & & \\sum_i\\int_0^t\\mathbf{e_q}\\biggl[\\int_0^t ( { \\boldsymbol{\\sf d}}_sv_r^i)^2\\,ds \\biggr]^{2}\\,dr<\\infty,\\end{aligned}\\ ] ] thus ensuring that @xmath484 , and @xmath485^{2}\\,dr<\\infty\\ ] ] which ensures that @xmath486 . using the cauchy ",
    "schwarz inequality we have @xmath483^{2}\\,dr \\\\ & & \\qquad \\le t\\int_0^t\\int_0^t\\mathbf{e_q}\\|{\\boldsymbol{\\sf d}}_su_r\\|_4 ^ 4\\,ds\\,dr \\le t^3\\sup_{0\\le r , s\\le t}\\mathbf{e_q}\\|{\\boldsymbol{\\sf d}}_su_r\\|_4 ^ 4,\\end{aligned}\\ ] ] and similarly for @xmath60",
    ". moreover , we obtain @xmath485^{2}\\,dr\\le t^5\\sup_{0\\le r , s,\\sigma\\le t } \\mathbf{e_q}\\|{\\boldsymbol{\\sf d}}_\\sigma{\\boldsymbol{\\sf d}}_su_r\\|_4 ^ 4.\\ ] ] but using the chain rule proposition [ pro : chainrulesmooth ] we can easily establish that @xmath487 and similarly @xmath488 the desired estimates now follow as in the proof of lemma [ lem : msqintg ] .",
    "we use the notation @xmath489 .",
    "the skorokhod integral in question is @xmath490 to establish @xmath491 , it suffices to show that @xmath492 .",
    "we begin by showing @xmath493 where we have used the triangle inequality , @xmath494 for any @xmath154 , and the fact that @xmath352 and @xmath495 have nonnegative entries a.s .",
    "hence @xmath496 is a bounded process .",
    "similarly , we will show that @xmath497 is a bounded process .",
    "note that @xmath496 is a smooth function on @xmath130 of positive random variables in @xmath296 ; hence we can apply the chain rule proposition [ pro : chainrule ] .",
    "this gives @xmath498 proceeding exactly as before , we find that @xmath499 ^ 2)$ ] .",
    "but then by proposition [ pro : chainrule ] we can conclude that @xmath500 for a.e .",
    "@xmath501 ^ 2 $ ] , and in particular @xmath492 .",
    "hence the proof is complete .",
    "[ lem : regularpis ] @xmath502 a.e .",
    "@xmath503 , @xmath504 a.e .",
    "moreover @xmath506 for every @xmath341 .",
    "the equivalent results hold for @xmath507 .",
    "in particular , this implies that @xmath203 and @xmath508 are in @xmath340 .",
    "the case @xmath505 is immediate from adaptedness of @xmath203 . for @xmath503 , apply the chain rule to @xmath509 .",
    "boundedness of the resulting expression follows , for example , as in the proof of lemma [ lem : skorisreal ] , and hence it follows that @xmath510 .",
    "kunita , h. ( 1984 ) .",
    "stochastic differential equations and stochastic flows of diffeomorphisms .",
    "_ cole dt de probabilits de saint - flour xii1982 .",
    "lecture notes in math .",
    "_ * 1097 * 143303 .",
    "springer , berlin .",
    "le  gland , f. and oudjane , n. ( 2003 ) . a robustification approach to stability and to uniform particle approximation of nonlinear filters : the example of pseudo - mixing signals .",
    "_ stochastic process .",
    "appl . _ * 106 * 279316 ."
  ],
  "abstract_text": [
    "<S> we investigate the robustness of nonlinear filtering for continuous time finite state markov chains , observed in white noise , with respect to misspecification of the model parameters . </S>",
    "<S> it is shown that the distance between the optimal filter and that with incorrect model parameters converges to zero uniformly over the infinite time interval as the misspecified model converges to the true model , provided the signal obeys a mixing condition . </S>",
    "<S> the filtering error is controlled through the exponential decay of the derivative of the nonlinear filter with respect to its initial condition . </S>",
    "<S> we allow simultaneously for misspecification of the initial condition , of the transition rates of the signal , and of the observation function . </S>",
    "<S> the first two cases are treated by relatively elementary means , while the latter case requires the use of skorokhod integrals and tools of anticipative stochastic calculus .    and    .    . </S>"
  ]
}