{
  "article_text": [
    "years have seen an unprecedented growth in wireless data traffic and this growth is not slowing down . compared to 2016 , aggregate smartphone traffic is expected to increase almost tenfold by 2020 @xcite .",
    "one promising technology to help meet the needs of heavily loaded future cellular networks is _ device - to - device _ ( d2d ) communications .",
    "the major benefit of d2d is that it allows for direct communication between proximate user equipment without the need of base stations , hence potentially offering higher data transfer speeds , lower latency , decreased interference , increased spectral efficiency and lower overall power consumption @xcite .",
    "another uprising technology is wireless _ caching _ at either directly on user terminals @xcite , or both user terminals and base stations @xcite .",
    "wireless d2d caching is an enticing future technology where data could be stored and distributed directly between mobile terminals  especially if the involved mobile terminals are geographically close to each other and can thus form d2d _ clusters _ @xcite .",
    "geographically constrained caching is of particular interest since the popularity of data is highly location dependent @xcite .",
    "wireless content caching and data distribution through direct links have been proposed in several works such as @xcite , where delay - tolerant networking is considered for message dissemination and forwarding . in @xcite a wireless peer - to - peer type of application is studied and it is shown that caching can greatly increase the application - level throughput .",
    "the potential of coded wireless d2d caching is investigated in @xcite , while @xcite shows that d2d caching can improve the throughput of wireless video transmission .",
    "a method for minimizing the energy consumption of d2d caching nodes is analyzed in @xcite , whereas a joint transmission and caching policy that reduces both the total energy consumption at the base station and the economical cost for the operator is presented in @xcite . in @xcite , the authors study clusters - centric d2d networks and demonstrate significant improvements in the network performance .",
    "joint use of caching and erasure coding for d2d clusters has been proposed in our previous work @xcite for instantaneous repairs .",
    "this work has been extended in @xcite to efficiently scheduled repairs .",
    "further work on distributed storage with d2d communications has been done in @xcite , where a combination of d2d and social networks is considered . in @xcite",
    "we looked for a way to strictly minimize the amount of data traffic in caching clusters and found that repetition coding yields the best results for the considered system model .",
    "we then found in @xcite that the optimal coding method , _",
    "i.e. _ , the coding method which minimized a predetermined cost function , highly depends on the popularity of the file .",
    "a clear drawback of geographically constrained wireless caching is unconstrained user mobility  when a caching node moves away from the caching cluster , its content is lost . to avoid this ,",
    "we introduce erasure coding to ensure data availability .",
    "the focus of this article is studying the performance of such coded caching clusters . the main contributions of this article can be summarized as follows :    * we construct a system model for a clustered wireless d2d caching community based on stochastic geometry .",
    "* closed - form expressions for the expected energy cost based on signal attenuation of both uncoded and coded d2d caching methods are derived , and we further examine under which conditions coded caching outperforms uncoded caching without redundancy .",
    "* it is shown that coded caching can yield significant cost savings in terms of both the overall energy consumption and economical cost savings from a operator s point of view .",
    "the rest of this paper is organized as follows . in section  [ sec : d2d ] , we present the system model used throughout this work . in section  [ sec : methods ] , we introduce the proposed caching methods .",
    "analytical cost estimates are derived in section section  [ sec : cost ] , while simulation results are presented , and compared with the analytical results , in section  [ sec : analysis ] .",
    "finally , conclusions are drawn in section  [ sec : conclu ] .",
    "we begin by introducing the system model assumed throughout the paper .",
    "we model a cluster of mobile terminals with data storage capabilities  or _ nodes _  by a disk of radius @xmath0 .",
    "the expected number of nodes present in the cluster is denoted by @xmath1 , and the nodes are assumed to be uniformly distributed inside the disk .",
    "a single base station is located at a distance @xmath2 from the center of the cluster .",
    "a graphical representation of the model is displayed in figure  [ fig : cluster ] .",
    "( 0,0 ) circle ( 4 cm ) ; ( v0 ) at ( 111:.5 ) @xmath3 ; ( v1 ) at ( 8.4:.8 ) @xmath3 ; ( v3 ) at ( 192:1.5 ) @xmath3;(v4 ) at ( 213:2.3 ) @xmath3 ; ( v5 ) at ( 262:1.5 ) @xmath3 ; ( v6 ) at ( 282:3.1 ) @xmath3 ; ( v7 ) at ( 102:3.3 ) @xmath3 ; ( v8 ) at ( 12:3.6 ) @xmath3 ; ( v9 ) at ( 352:1.6 ) @xmath3 ; ( v10 ) at ( 220:3.1 ) @xmath3 ; ( v11 ) at ( 174:2.3 ) @xmath3 ; ( v12 ) at ( 102:2.0 ) @xmath3 ; ( v13 ) at ( 201:.4 ) @xmath3 ; ( v14 ) at ( 112:2.5 ) @xmath3 ; ( v15 ) at ( 232:2.1 ) @xmath3 ; ( v16 ) at ( 63:2.5 ) @xmath3 ; ( v17 ) at ( 300:2.7 ) @xmath3 ; ( v18 ) at ( 300:2.7 ) @xmath3 ; ( v19 ) at ( 80:1 ) @xmath3 ; ( v20 ) at ( 135:1.47 ) @xmath3 ; ( v21 ) at ( 331:1.27 ) @xmath3 ; ( v21 ) at ( 341:2.47 ) @xmath3 ; ( v21 ) at ( 135:3.00 ) @xmath3 ; ( bs )    ( base ) bs ; ( base.100 )  ( base.80 )  ( base.110 ) ",
    "( base.70 ) ",
    "( base.north west ) ",
    "( base.north east ) ; ( base.100 )  ( base.70 ) ( base.110 )  ( base.north east ) ; ( [ yshift=0pt]base.north ) [ antenna=1 ] ;    ; ( cen ) at ( 225:.15 ) @xmath3 ; ( bor ) at ( 45:4.15 ) @xmath3 ; ( bs1 ) at ( 200.8978:11.7745 ) ; ( bs2 ) at ( 269:4.2 ) ;    ( v11 ) ",
    "node[above ] ( v3 ) ; ( v0 )  node[above ] ( v3 ) ; ( v4 )  node[left ] @xmath3 ( v3 ) ; ( v5 )  node[above ] @xmath3 ( v3 ) ; ( bs )  node[above ] @xmath3 ( v3 ) ; ( cen )  node[above ] @xmath0 ( bor ) ; ( bs1 )  node[above ] @xmath4 ( bs2 ) ;    the nodes inside the cluster form a d2d caching community .",
    "we assume that each node knows about the content stored in every other node , and any two nodes can communicate data .",
    "we further assume that all data transmission links are error - free .",
    "the time dynamics of the system are modeled as follows .",
    "the time that an arbitrary node remains active in the cluster follows an exponential distribution with expected value @xmath5 .",
    "we define a _ failure _ as the event when a node becomes inactive by leaving the system and denote the _ node failure rate _ by @xmath6 . with these parameters , we can model the instantaneous state of the system via an m / m/@xmath7 markov model ( cf . figure  [ fig : markov_system ] ) , which has been widely used to model wireless cellular systems with exponential dwell times @xcite . in this work ,",
    "we only consider the steady state of the chain with @xmath1 nodes in the cluster on average .",
    "hence , the probability that the system is in state @xmath8 , _ i.e. _ , that there are @xmath8 nodes in the cluster , can be written as @xcite @xmath9    = [ fill = white , draw = black , thick , text = black , minimum width=1.5 cm ] ( a ) @xmath10 ; ( b ) [ right of = a ] @xmath1 ; ( c ) [ right of = b ] @xmath11 ; ( d1)[left of = a ] @xmath12 ; ( d2)[right of = c ] @xmath12 ; ( a ) edge[bend left=50,above ] node@xmath13 ( b ) edge[bend left=50,below ] node@xmath14 ( d1 ) ( b ) edge[bend left=50,above ] node@xmath13 ( c ) edge[bend left=50,below ] node@xmath13 ( a ) ( c ) edge[bend left=50,above ] node@xmath13 ( d2 ) edge[bend left=50,below ] node@xmath15 ( b ) ( d1 ) edge[bend left=50,above ] node@xmath13 ( a ) ( d2 ) edge[bend left=50,below ] node@xmath16 ( c ) ;    we henceforth consider a single data file of unit size without loss of generality .",
    "each user in the cluster can request the file anytime .",
    "the request interval of a user follows an exponential distribution with expected value @xmath17 , where we call @xmath18 the _ request rate _ or , by slight abuse of terminology , the _ file popularity_. we concentrate on the case @xmath19 as we assume that the vast majority of the users request the file only once during their visit to the cluster .",
    "in this article , we consider three different methods to cache the file on the nodes .",
    "these caching methods are introduced in the following subsections .    [",
    "[ simple - caching ] ] simple caching + + + + + + + + + + + + + +    a single node stores a full copy of the file .",
    "the file is not protected against storage node failures since no redundancy is enabled .",
    "as soon as the caching node leaves the system , the data file is lost from the caching community and the next requesting node needs to download the entire file from the base station .",
    "this node then automatically becomes the new caching node and , as long as it remains active in the cluster , all file requests from other nodes are served by this node through d2d communications .",
    "the system can be modeled with a markov chain as depicted in figure  [ fig : markov_caching ] .",
    "= [ fill = white , draw = black , thick , text = black , minimum width=1.5 cm ] ( a ) @xmath20 ; ( b ) [ right of = a , below=0.4 cm of a ] @xmath21 ; ( c ) [ right of = a , above=0.4 cm of a ] @xmath22 ; ( d ) [ right of = b ] @xmath23 ; ( e ) [ right of = c ] @xmath24 ; ( d2 ) [ right of = d ] @xmath25 ; ( d3 ) [ right of = e ] @xmath26 ; ( d4)[right of = d3 ] @xmath12 ; ( d5)[right of = d2 ] @xmath12 ;    \\(a ) edge[bend left=30,left ] node@xmath13 ( c ) ( b ) edge[bend left=30,above ] node@xmath13 ( d ) edge[bend left=30,below ] node@xmath27 ( a ) ( c ) edge[bend left=30,above ] node@xmath13 ( e ) edge[bend left=30,below ] node@xmath27 ( a ) edge[bend left=0,right ] node@xmath18 ( b ) ( d ) edge[bend left=30,above ] node@xmath13 ( d2 ) edge[bend left=-10,right ] node@xmath27 ( c ) edge[bend left=30,below ] node@xmath27 ( b ) ( e ) edge[bend left=30,above ] node@xmath13 ( d3 ) edge[bend left=30,below ] node@xmath28 ( c ) edge[bend left=0,right ] node@xmath29 ( d ) ( d2 ) edge[bend left=30,above ] node@xmath13 ( d5 ) edge[bend left=30,below ] node@xmath28 ( d ) edge[bend left=-10,right ] node@xmath27 ( e ) ( d3 ) edge[bend left=30,below ] node@xmath30 ( e ) edge[bend left=0,right ] node@xmath31 ( d2 ) edge[bend left=30,above ] node@xmath13 ( d4 ) ( d4 ) edge[bend left=30,below ] node@xmath32 ( d3 ) ( d5 ) edge[bend left=30,below ] node@xmath30 ( d2 ) edge[bend left=-10,right ] node@xmath27 ( d3 ) ;    the steady state probabilities of the upper chain are @xmath33 and the lower chain @xmath34 , where @xmath35 are the m / m/@xmath7 probabilities from , and @xmath34 fulfil the recursion @xmath36 with @xmath37 .",
    "note that , for the purposes of this article , we do not need to find the steady state probabilities .",
    "instead , in section [ subsec : savings_general ] , we derive an approximation of the performance metric .",
    "we use the chain of figure [ fig : markov_caching ] only to model the behavior of the system with computer simulations in order to empirically measure the performance of simple caching .",
    "this will be done later in section [ sec : analysis ] .",
    "another way to cache and disseminate the file in the cluster would be to store a replica of the file on each of the nodes that requests it .",
    "however , it is easy to see that in order for this method to work and the cluster to fill up with replicas , the file request rate should be higher than the node passing rate , i.e. , @xmath38 .",
    "this in turn would mean that the average user downloads the file more than once during its stay in the cluster .",
    "we focus on the more realistic case where the average number of requests per node lifetime is less than one , i.e. , @xmath19 , which means that redundancy must be actively maintained or else the cached data will be lost .",
    "[ [ replication ] ] replication + + + + + + + + + + +    the most elementary way of adding redundancy to the system is simply to store multiple copies of the entire file on separate nodes .",
    "we refer to this strategy as @xmath39-replication , where @xmath40 nodes store a replica of the file .",
    "when the system operates under this method , the file can be retrieved , or a lost node repaired , by contacting simply one of the storage nodes .",
    "the obvious downside of replication is that it consumes more storage space than coded storage .",
    "furthermore , the _ repair bandwidth _ , that is , the amount of data traffic that replacing a lost storage node incurs , is equal to the size of the entire file .",
    "hence , the repair bandwidth is equal to the _ reconstruction bandwidth _ , which we define as the amount of data traffic incurred when a users downloads and reconstructs the data file .",
    "[ [ regenerating - codes ] ] regenerating codes + + + + + + + + + + + + + + + + + +    we interpret the considered system as a _ distributed storage system _ ( dss ) which is composed of @xmath41 storage nodes the number of nodes storing a replica in case of @xmath39-replication , and the length of an @xmath42 mds code used for the dss .",
    "the meaning of @xmath39 will always be clear from the context or clarified otherwise . ] .",
    "the original data file is encoded into @xmath39 coded fragments of size @xmath43 each .",
    "storage nodes are assigned one of the coded fragments , and the entire file can be recovered by contacting any @xmath44 storage nodes , a feature also referred to as the _ maximum distance seperability _ ( mds ) property of a code .",
    "this property is what allows the system to be resistant against arbitrary failure sequences .    to maintain redundancy ,",
    "whenever a storage node fails , it is instantly replaced with a _ newcomer _ node that is randomly chosen from the empty nodes present in the cluster .",
    "this newcomer node contacts any @xmath45 storage nodes , downloads @xmath46 units of data from each and stores @xmath43 units of data .",
    "note that the new content in the newcomer node does not need to be exactly the data that were lost in the failed node .",
    "hence , we consider _ functional repair _ , which ensures that both the mds and the regeneration property hold after an arbitrary failure .    throughout this paper ,",
    "we assume instant repair after failures so that no matter which coding method is used , there are always @xmath39 caching nodes in the cluster as long as the markov chain in figure [ fig : markov_system ] never goes to a state lower than @xmath39 , which we deem a valid assumption as we only investigate the case @xmath41 , and thus the probability of finding the chain in small states is extremely small and @xmath47 , values which we will later use in our simulations , the probability that the number of nodes in the cluster drops to @xmath39 or below is approximately @xmath48 . ] .",
    "a dss is determined by the tuple @xmath49 , whereof the triple @xmath42 consists of the _ storage degree _ , _ reconstruction degree _ and _ repair degree_. in other words , reconstructing the data file requires contacting @xmath50 out of total @xmath39 storage nodes , while repairing the contents of a lost node requires contacting @xmath51 nodes .",
    "in addition , the parameter tuple @xmath52 consists of the fragment size @xmath43 stored in each of the @xmath39 storage nodes , and the _ repair bandwidth _ @xmath53 , that is the total number of units of data that a newcomer needs to download for repairing a lost node .",
    "note that when repairing , each storage node involved in the repair process transmits @xmath46 units of data to the newcomer node , so that @xmath54 .    a given tuple of parameters @xmath49 is _ feasible _ if a code with such @xmath43 and @xmath53 exists .",
    "for a result on the existence of feasible parameter tuples , we refer to ( * ? ? ? * thm .  1 ) .",
    "more importantly , there is a natural tradeoff between @xmath43 and @xmath53 given by a piecewise linear function .",
    "codes lying on this tradeoff curve are called regenerating codes .",
    "hence , regenerating codes offer an optimal tradeoff between storage space consumption and repair bandwidth , while maintaining the mds property .",
    "furthermore , any @xmath51 nodes can be contacted to resurrect a lost node while maintaining these properties after repairs .",
    "hence , regenerating codes are an attractive choice .    in this work , we consider two types of regenerating codes : codes attaining one of the two extremal points , _",
    "i.e. _ , the points where either the storage space consumption or repair bandwidth is minimized .",
    "these codes are known as _ minimum storage regenerating _",
    "( msr ) codes and _ minimum bandwidth regenerating _",
    "( mbr ) codes , respectively . for a file of unit size",
    ", these points are achieved by the pairs @xcite @xmath55 it has been shown that , in the typical case @xmath56 which we assume throughout this work , code constructions exists for both the msr and the mbr point , see _ e.g. _ , @xcite .",
    "note that the reason we do not consider traditional mds erasure codes , such as reed - solomon codes , is that , for the purpose of this work , they are merely a special case of msr codes with @xmath57 .",
    "in order to compare the three considered methods , we need to determine a reference function which measures the overall expected costs in terms of transmission energy .",
    "we start by establishing a general underlying model .",
    "the main performance metric of the system is the overall energy _ cost _ , which we define as the sum of the _ transmission cost _ and the _ storage cost_. we refer to the transmission cost of a transmission scheme as the sum of the expected overall transmission costs ,",
    "that is , the transmit power consumption of the base station and d2d community caused by data traffic of a fixed file of unit size , both due to data retrieval or repair . in addition , we also establish a storage cost , so that neglectfully caching large amounts of data is not a viable option . wasting storage space would result in a waste of transmission energy as the short - distance d2d links could not be efficiently utilized if only a few different files fit on the storage space of the caching community , and consequently , the traditional downlink with the base station would be needed more often .",
    "hence , we _ translate storage into transmit power_.    we represent the cost of storing a unit of data by a constant @xmath58 .",
    "finding the data transmission costs requires analyzing the stochastic geometrical properties of the cluster , which we will do in the following to derive the cost of reconstruction and repair .",
    "as depicted in figure  [ fig : cluster ] , our system consists of a base station located at a distance @xmath4 away from the center of the caching cluster , and a cluster of nodes , uniformly distributed in a disk of radius @xmath59 .",
    "we implement full channel inversion at the transmitter , which implies that the expected required downlink transmit power to communicate one unit of data over distance @xmath60 becomes @xmath61 , where @xmath62 is the pathloss exponent .",
    "we consider two different pathloss exponents for the pathloss between the base station and a node in the cluster , and @xmath63 for the pathloss between two nodes in the d2d community , when numerical values are needed similarly to , _",
    "e.g. _ , @xcite . ]",
    ": one for the downlink from the base station to the nodes in the cluster ( @xmath64 ) , and another for communications in d2d mode ( @xmath65 ) .",
    "the expected required transmit power for communication between two nodes in the cluster is denoted by @xmath66 , which is the expected @xmath67 power of the distance from an arbitrary node in the disk to its @xmath68 nearest caching node , assuming that there are @xmath39 uniformly distributed storage nodes present in a disk of radius @xmath0 .",
    "in other words , @xmath66 is also the expected cost of transmitting a unit of data between two nodes in the disk .",
    "thus , the first step towards estimating the transmission costs of the individual methods is to derive the quantity @xmath69 .",
    "to that end , we will need the following result .",
    "_ let two circles of radii @xmath70 and @xmath71 be separated by distance @xmath4 .",
    "for any triple @xmath72 , the intersection area @xmath73 of the two circles is given by the function _",
    "@xmath74 where @xmath75 for further details on circle intersection calculations , see _",
    "e.g. _ @xcite .",
    "now let @xmath76 be a node in the cluster , where @xmath77 denotes its distance from the origin of the disk . using the computed area of intersection",
    ", we can find the probabilities needed for our calculations . of interest for our purposes",
    "is the expected distance between the node @xmath76 and it s @xmath78 nearest node out of @xmath39 nodes , which can be computed as ( see @xcite for further details ) @xmath79    moreover , we are interested in the expected value of the @xmath80 power of the distance between @xmath76 and its @xmath78 nearest neighbor , which becomes @xmath81 the expected value of which is given by @xmath82 where we have used the probability density function @xmath83 corresponding to the random variable representing the distance between a randomly chosen point in a disk of radius @xmath0 and the center of the disk .",
    "lastly , to measure the performance of simple caching , we find the expectation of the @xmath84 power of the distance from a node in the cluster to the base station by integrating the complementary cumulative density function of the distance : @xmath85 for clarity , the notation is summarized in the appendix in table  [ tab : parameters ] .",
    "we begin by finding the costs of each of the considered caching methods .",
    "we only consider the expectations of the costs and thus directly use the expected numbers of nodes to perform calculations .",
    "we later verify the validity of this approach with computer simulations in section  [ sec : analysis ] .    1 .",
    "the dynamics of the system under simple caching are modeled according to the markov chain in figure  [ fig : markov_caching ] . instead of a full steady state analysis of the chain , for the sake of simplicity",
    ", we derive an approximation for the expected cost in the following .",
    "when the file is cached , there is one node caching the entire file with no redundancy , so the cost of repair vanishes .",
    "there are , on average , @xmath10 nodes in the cluster generating requests as the single caching node does not need to download the file itself .",
    "thus , the expected number of requests during the lifetime of the caching node is @xmath86 .",
    "once the caching node leaves the cluster , the next file request will be directed to the base station .",
    "the expected time in which this happens is approximately and @xmath1 is large , though , this approximation is accurate enough for our purposes as will be demostrated later by the numerical results . ]",
    "@xmath87 , and an expected number of @xmath88 requests , including the local file retrievals in the cluster and the remote retrieval from the base station , are generated in time @xmath89 .",
    "the cost of retrieving the file from the caching node is @xmath90 , whereas the cost of retrieving it from the base station is @xmath91 .",
    "further , as long as the file is cached , it incurs a storage cost of @xmath58 . using the approximation centered at the point @xmath92 when @xmath93 has support on @xmath94 .",
    "this expansion can be truncated to @xmath95 @xcite . in the interest of space , instead of providing a full analysis of the error term",
    ", we will demonstrate the predictive ability of our estimate through numerical simulations , see figures [ fig : sim ] , [ fig : simmsrrocks ] and [ fig : reprules ] . ]",
    "@xmath96 , where @xmath97 are two random variables and @xmath98 denotes expectation , the cost of simple caching can be approximated as @xmath99 + the accuracy of this approximation , in the special cases considered in this work , is verified by numerical results in section  [ sec : analysis ] .",
    "note that there is nothing we can optimize about this caching method  we use only as a baseline to measure the improvement achieved by storage coding methods  replication \" and  regenerating codes \" which will be introduced in the following .",
    "when replication is used , we assume @xmath39 storage nodes storing an entire replica of the file . on average , there are @xmath100 empty nodes each of which generates file requests at rate @xmath18 .",
    "for reconstructing the file , the requesting node contacts the nearest storage node , so that the reconstruction cost is @xmath101 , so the reconstruction cost becomes @xmath102 to repair a failed node , the newcomer node contacts the nearest out of the surviving @xmath103 storage nodes .",
    "the repair cost is hence given by @xmath104 .",
    "thus , as there are @xmath39 storage node each failing at rate @xmath27 , the reconstruction cost becomes @xmath105 the storage cost in this scenario is simply @xmath106 .",
    "now recall that each node in the cluster generates requests at rate @xmath18 , and each node passes through the cluster at rate @xmath27 .",
    "therefore , the cost of replication becomes @xmath107 the only parameter to be optimized for replication is the number of replicas @xmath39 .",
    "examining , it is a straightforward , yet important observation that increasing @xmath39 decreases the expected distances between the nodes and the number of empty nodes that request the file , but increases the total failure rate , and consequently the total repair cost , and the total storage cost .",
    "note that similar observations have been made before for similar distance - dependent cost functions , see _",
    "e.g. _ @xcite and references therein .",
    "for the purposes of our work we emphasize that to minimize the cost of replication it is crucial to find a suitable value of @xmath39 , as will be demonstrated later in this work .",
    "3 .   in a system operating under this scheme ,",
    "there are both storage nodes storing a fragment of the data file and empty nodes present in the cluster .",
    "we hence need to consider two types of requests .",
    "when one of the @xmath39 storage nodes requests the file , it contacts @xmath108 out of the remaining @xmath103 storage nodes and downloads @xmath43 units of data from each , which yields cost @xmath109 when one of the empty nodes requests the file , @xmath50 out of the @xmath39 storage nodes need to be contacted , thus yielding a cost @xmath110 since the expected number of empty nodes in the cluster is @xmath100 .",
    "+ when a storage node is lost , one of the empty nodes acts as the newcomer , contacts @xmath51 of the remaining @xmath103 surviving nodes , and downloads @xmath46 units of data from each , generating a total repair bandwidth of @xmath54 .",
    "thereby , the repair cost becomes @xmath111 the storage cost using regenerating codes is simply @xmath112 , so the total cost of using regenerating codes amounts to + align =  & n_i=1^k-1l_r,_(i , n-1 ) + ( m - n)_i=1^kl_r,_(i , n ) + & + n_i=1^dl_r,_(i , n-1 ) +",
    "n , [ regeequ ]    where @xmath43 and @xmath46 are functions of @xmath113 and are given by for msr and for mbr codes .",
    "we immediately see that the same observations about varying the storage degree @xmath39 that we made for replication apply to as well .",
    "further , for regenerating codes we also need to choose the optimal values of @xmath50 and @xmath51 , as well as either the msr or mbr point , to minimize the cost for given system parameters and file popularity .",
    "maximizing the repair degree @xmath51 minimizes both @xmath43 and @xmath46 for mbr and @xmath46 for msr , and maximizing the reconstruction degree @xmath50 minimizes the amount of redundancy for msr .",
    "however , high values of @xmath50 and @xmath51 imply that distant nodes need to be contacted , and as the transmission cost is proportional to the @xmath80 power of the distance , we conclude that naively ignoring the distance - dependency and only optimizing with regard to the amount of data traffic does not necessarily imply the lowest cost .",
    "so far we have been only concerned with saving overall transmission power by taking advantage of both caching on devices and direct data transmission between users .",
    "however , users in the cluster can be selfish in nature and thus may not have a motive for sharing their storage and battery to enable a caching system such as the one presented in this work .",
    "thus , we now focus on the case where we assume that users sharing their resources are rewarded by the operator with lower charges if maintaining the community implies economical savings for the operator .",
    "similar incentives have been proposed earlier in the literature @xcite .",
    "it is a natural question to ask whether from an operator s point of view the maintenance  or _ upkeep _  of such a d2d community pays off . to measure economical profit , we consider the ratio of the costs of downlink transmissions , and d2d traffic and upkeep costs .",
    "deriving the cost of traditional downlink communications is straightforward .",
    "there are @xmath1 nodes generating requests at frequency @xmath18 , and this cost thus amounts to @xmath114 where @xmath91 is as in .    to weigh the costs of d2d data transmission and storage",
    ", we say that transmitting a unit of data in d2d mode over unit distance incurs a cost @xmath115 for the operator , while storing a unit of data costs @xmath58 .",
    "in other words , these are the incentives offered to a caching user : @xmath115 represents the economical benefit that a caching user gains from distributing data by using transmit power and @xmath58 represents the benefit that a caching user gains when storing data . now similarly to , and , we find the upkeep costs to be @xmath116 in other words , when data are distributed and cached redundantly , the operator avoids the cost of data transmission from the base station altogether , but has to pay a cost of @xmath115 for each transmitted unit of data over unit distance and @xmath58 for each unit of data cached on a user equipment .",
    "we now define the caching gain of an operator as @xmath117 which we call _ operator gain_. in the next section , we present numerical results of both operator gains and overall energy consumption cost savings .",
    "in this section , we illustrate the performance of the four considered caching methods with respect to the derived performance metric with the help of numerical results . we investigate three cases : low , moderate and high storage cost , while the parameters of replication ( @xmath39 ) and regenerating codes @xmath42 are chosen from a small interval so that the cost function is minimized .",
    "further , we study the operator gains for short and long distances from the cluster to the base station .    for all cases in this section , we fix @xmath118 , @xmath119 , @xmath120 , @xmath121 and @xmath122 , while @xmath58 is varied . for the overall energy consumption results we fix @xmath123 , while two values , @xmath124 and @xmath123 , are considered for the operator gain .",
    "we choose @xmath125 $ ] for replication , and @xmath126 $ ] for regenerating codes , so that the cost is minimized for a given @xmath18 .",
    "the theoretical curves ( solid lines ) in the figures are numerical values using the derived cost functions , and , while the simulated values ( dots ) are obtained by computing steady state averages of long monte carlo simulations for the markov chains depicted in figure  [ fig : markov_caching ] for simple caching and figure  [ fig : markov_system ] for regenerating codes and replication to verify the theoretical calculations .",
    "for all simulations , the initial number of nodes in the cluster is @xmath118 and the file is cached when the simulation starts .",
    "the simulation length is @xmath127 expected node lifetimes @xmath128 for each data point .    in the setting of figure  [ fig : sim ] , each of the four caching methods becomes useful depending on the value of @xmath18 .",
    "when the file popularity is low , maintaining redundancy wastes more transmission energy than is saved by d2d requests , and thus simple caching is preferred .      for a higher popularity , in the magnified range in the figure",
    ", we see that mbr coding is the optimal method as it has a lower repair bandwidth than msr coding .",
    "this is where maintaining redundancy starts to pay off , and the cost function is dominated by the cost of repair as requests and thus file reconstructions are relatively rare compared to node failures .",
    "when the popularity grows even larger , file requests become more abundant , and the cost of reconstruction starts dominating the cost function . due to its low reconstruction bandwidth , msr coding outperforms the other methods in this range of @xmath18 .",
    "finally , when the popularity is very high , replication yields the lowest cost .",
    "the reason why replication outperforms msr , even though the reconstruction bandwidths are equal for both methods , is because replication only requires contacting the nearest storage node , while msr requires contacting several nodes and the transmission energy cost increases proportionally to the fourth power of the distance ."
  ],
  "abstract_text": [
    "<S> we consider a geographically constrained caching community where popular data files are cached on mobile terminals and distributed through device - to - device ( d2d ) communications . further , to ensure availability , data files are protected against user mobility , or _ </S>",
    "<S> churn _ , with erasure coding . </S>",
    "<S> communication and storage costs ( in units of energy ) are considered . </S>",
    "<S> we focus on finding the coding method that minimizes the overall cost in the network . </S>",
    "<S> closed - form expressions for the expected energy consumption incurred by data delivery and redundancy maintenance are derived , and it is shown that coding significantly decreases the overall energy consumption  by more than 90% in a realistic scenario . </S>",
    "<S> it is further shown that d2d caching can also yield notable economical savings for telecommunication operators . </S>",
    "<S> our results are illustrated by numerical examples and verified by extensive computer simulations .    </S>",
    "<S> device - to - device communications , regenerating codes , wireless caching , markov processes , distributed data storage </S>"
  ]
}