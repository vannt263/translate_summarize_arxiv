{
  "article_text": [
    ", extremely low error probability has been required in many application areas such as wireless communication systems without feedback and data storage systems . low - density parity - check ( ldpc ) codes@xcite,@xcite have become one of promising error - correcting codes in these areas due to their near capacity - approaching performance . however , since finite - length ldpc codes show a serious error - floor problem@xcite in high signal to noise ratio ( snr ) region , it may be difficult to achieve an extremely good error correction performance .",
    "many researches on the iterative decoding of ldpc codes ( e.g. @xcite -@xcite ) have been made to achieve good error correction performance by improving only the decoding algorithm while not changing the code structure .",
    "however , the requirement for the performance and complexity of decoder is getting more strict .",
    "thus , more powerful decoding schemes for ldpc codes are required .    in this paper",
    ", we propose a decoding scheme for ldpc codes using simple product code structure to improve the error correction performance together with error floor .",
    "the proposed decoding scheme is based on combining two independently received soft - decision data for an unsuccessfully decoded codeword , which achieves good decoding performance with relatively low additional decoding complexity . in the encoding procedure of the proposed scheme ,",
    "codewords of the ldpc codes are stacked in rows as horizontal codewords of the product codes .",
    "then vertical codes which are used to help decoding of the ldpc codewords are applied to the stack of ldpc codewords , which results in a codeword matrix like product code structure . in the decoding procedure ,",
    "decoding of each horizontal ldpc codeword in a codeword matrix is performed firstly according to decoding algorithm of ldpc codes .",
    "if some codewords fail to be successfully decoded , re - decoding based on combining two received soft - decision data for the same codeword will be performed .",
    "also , we define and analyze the decoding capability of the proposed decoding scheme using the parity - check matrices of vertical codes and derive the _ combined - decodability _ for the case of single parity - check ( spc ) and hamming codes being used as vertical codes .",
    "especially , the proposed decoding scheme shows better error - correcting capability in high snr region .",
    "any linear codes can be used as vertical codes in the proposed scheme . however , since vertical codes are only used to help decoding of ldpc codes in the proposed scheme , short codes with high rate are preferable as vertical codes .",
    "thus , simple algebraic codes such as spc or hamming codes are appropriate for the vertical codes .",
    "even though the vertical codes are assumed to be systematic in this paper , they do not have to be systematic for the proposed decoding scheme .",
    "the proposed decoding scheme can be applied to any other linear codes with soft - decision decoding than ldpc codes . however , undetected errors in the horizontal codewords cause a serious problem for the proposed scheme . if undetected errors seldom occur and soft - decision decoding is used for the horizontal codes such as ldpc and turbo codes@xcite , the proposed decoding scheme can be effectively applied .",
    "this paper is organized as follows : in section  [ sec : proposedscheme ] , after introducing and defining some notations and operations , a new decoding scheme for ldpc codes using simple product code structure is proposed .",
    "two simple examples for the proposed decoding scheme are given in section  [ sec : simpleexamples ] . in section  [ sec : correctioncapability ] , the combined - decodability of the proposed decoding scheme is analyzed .",
    "the numerical results are shown in section  [ sec : simulationresults ] and the conclusion is given in section  [ sec : conclusions ] .",
    "in this section , we propose a new decoding scheme for ldpc codes using the concept of product codes . in the proposed scheme ,",
    "ldpc codes act as horizontal codes of the product codes and simple codes such as spc or hamming codes are used for vertical codes of the product code to help the decoding of the horizontal codes .",
    "product codes are serially concatenated codes @xcite , which were introduced in @xcite . by using the concept of product codes ,",
    "a long block code can be easily constructed by using two or more short block codes .",
    "now , we consider two systematic linear block codes , @xmath0 with parameters @xmath1 and @xmath2 with parameters @xmath3 , where @xmath4 , and @xmath5 denote the code length , the number of information bits , and the minimum hamming distance , respectively .",
    "the product code @xmath6 is obtained by the following steps as illustrated in fig .",
    "[ fig : structureprod ] :    1 .   placing @xmath7 information bits in an array of @xmath8 rows and @xmath9 columns ; 2 .   encoding each of @xmath8 rows using code @xmath2 ; 3 .   encoding each of @xmath10 columns using code @xmath0 .    the codes @xmath0 and @xmath2 are also called as vertical code and horizontal code of the product code @xmath11 , respectively",
    ". the parameters of the product code @xmath11 are @xmath12 and the code rate is given as @xmath13 , where @xmath14 and @xmath15 are the code rates of @xmath0 and @xmath2 , respectively .",
    "in this paper , for simplicity , only binary block codes are considered but the proposed decoding scheme can be directly applied to the nonbinary codes .",
    "let @xmath16 and @xmath17 , @xmath18 , be the number of unsuccessfully decoded horizontal codewords in a codeword matrix after first decoding of each @xmath19 horizontal codewords .",
    "parity - check matrix and its modifications of a vertical code in the product code are defined as :    * @xmath20 : @xmath21 parity - check matrix of a vertical code in the product code ; * @xmath22 : @xmath23 extended parity - check matrix whose rows are all possible nonzero linear combinations of rows in @xmath20 ; * @xmath24 : @xmath25 punctured parity - check matrix constructed by selecting @xmath17 columns from @xmath22 .",
    "it can be assumed that @xmath20 contains no all - zero column .",
    "it is clear that the length @xmath19 of the vertical code also denotes the number of horizontal codewords in a codeword matrix of the product code .",
    "the column indices of @xmath24 are same as the row indices of the unsuccessfully decoded horizontal codewords in the codeword matrix .",
    "let @xmath26 , @xmath27 , denote @xmath19 binary horizontal codewords and @xmath28 denote the _ soft - decision vector _ for @xmath29 , where @xmath30 is the log likelihood ratio ( llr ) for @xmath31 calculated from the corresponding received data @xmath32 defined by @xmath33 then , the check equations ( or rows ) in @xmath34 $ ] describe all possible relations among @xmath29 s , that is , @xmath35 .",
    "note that these check equations ( or rows ) of @xmath22 are not linearly independent .",
    "since the vertical code is a systematic code , we can use @xmath36 , @xmath37 , and @xmath38 , to denote the _",
    "systematic ( horizontal ) codewords _ including the systematic part of the vertical code and the _ parity ( horizontal ) codewords _ including the parity part of the vertical code as given in fig .",
    "[ fig : structureprod ] , respectively .",
    "special algebra for llr values in @xcite can be used with small modification .",
    "we use the operation @xmath39 for combining two llr values defined as @xmath40 let @xmath41 , @xmath27 , denote the vector of llr values computed from the horizontal codeword @xmath29 itself , i.e. , @xmath42 if @xmath43 and @xmath44 if @xmath45",
    ". then it is easy to show that @xmath46 can be calculated using the sign change operation as @xmath47      in the proposed decoding scheme , the received codewords of the ldpc codes are stacked as horizontal codewords for the product code .",
    "the number of codewords in a stack is determined by the vertical codes which are used to help decoding of the horizontal codes .",
    "next , we attempt to decode each horizontal codeword in the codeword matrix .",
    "if all the systematic codewords @xmath48 , @xmath49 , are successfully decoded , the decoding process will be successfully finished . however , if some horizontal codewords fail to be decoded , then re - decoding of the horizontal codewords using @xmath24 of the vertical codes will be performed .",
    "the details of this procedure are explained below .",
    "suppose that there are @xmath17 unsuccessfully decoded horizontal codewords in a codeword matrix and the @xmath50-th row of @xmath24 of the vertical codes has the minimum nonzero hamming weight @xmath51 among all rows of @xmath24 .",
    "clearly , it implies that @xmath51 unsuccessfully decoded horizontal codewords corresponding to the nonzero elements are involved in the @xmath50-th check equation of @xmath22 of the vertical code , which is the check equation affected by the minimum number of unsuccessfully decoded horizontal codewords .",
    "therefore , @xmath24 is used to decide which check equation of @xmath22 is most easily solvable , i.e. , which check equation contains the fewest unsuccessfully decoded horizontal codewords . in the proposed decoding scheme ,",
    "the check equation which contains the fewest unsuccessfully decoded horizontal codewords is first utilized for re - decoding .    according to the value of @xmath51 ,",
    "the proposed decoding scheme is performed by considering the following three cases .",
    "case 1 ) @xmath52 :    if there is only one unsuccessfully decoded horizontal codeword participating in a check equation of @xmath22 , say the @xmath50-th row of @xmath22 , of the vertical code , we can correct it simply by the modulo 2 addition ( denoted by @xmath53 ) of the other successfully decoded horizontal codewords participating in the same check equation .",
    "let @xmath29 be the unsuccessfully decoded horizontal codeword participating in the @xmath50-th check equation of @xmath22 of the vertical code .",
    "then we can recover @xmath29 by @xmath54 where @xmath55 is the set of indices of the nonzero elements in the @xmath50-th row of @xmath22 .",
    "as @xmath29 is successfully decoded , the corresponding column of @xmath24 is removed and the number of columns in @xmath24 reduces by one .",
    "this process is repeatedly applied to the check equations which satisfy the @xmath56 condition for updated @xmath24 .",
    "case 2 ) @xmath57 :    if there are only two unsuccessfully decoded horizontal codewords participating in a check equation ( i.e. , a row ) of @xmath22 of the vertical code , we can re - decode the combined vector of two independently received soft - decision vectors for the same horizontal codeword similar to the type - i hybrid - automatic repeat request ( h - arq ) scheme @xcite .",
    "we already know that among horizontal codewords participating in a check equation of @xmath22 , any codeword is equivalent to the sum of all the other codewords .",
    "thus we can derive two independently received soft - decision vectors for any of two unsuccessfully decoded horizontal codewords ; ( a ) one from an unsuccessfully decoded horizontal codeword , ( b ) the other one from the soft - decision vector of the other unsuccessfully decoded horizontal codeword by changing signs of its elements according to the successfully decoded horizontal codewords participating in the same check equation .",
    "let @xmath58 and @xmath59 be the unsuccessfully decoded horizontal codewords participating in the @xmath50-th check equation of @xmath22 of the vertical code .",
    "then , from  , we can have @xmath60    in addition to the soft - decision vector @xmath61 for @xmath58 , we can derive the other soft - decision vector for @xmath58 by using the relation as @xmath62 since it can be regarded that the horizontal codeword @xmath58 is independently received twice through the channel , we can just add two soft - decision vectors as @xmath63\\ ] ] and re - decode it by achieving approximately 3db performance gain similar to type - i h - arq scheme . if the re - decoding is successful , then the @xmath50-th check equation of @xmath22 contains only one unsuccessfully decoded horizontal codeword @xmath59 and it can be recovered by the method in case 1 ) .",
    "case 3 ) @xmath64 :    if there are three or more unsuccessfully decoded horizontal codewords participating in a check equation of @xmath22 of the vertical code , combining the soft - decision vectors for further re - decoding is still possible .",
    "first of all , the unsuccessfully decoded horizontal codewords participating in the same check equation of @xmath22 are partitioned into two groups and a soft - decision vector for each group is obtained by summing all the unsuccessfully decoded soft - decision vectors in that group using the operation .",
    "then , for these two soft - decision vectors , the same method for two unsuccessfully decoded horizontal codewords in case  2 ) is applied .",
    "we can try this process to all possible partitioning of unsuccessfully decoded horizontal codewords until the decoding succeeds and then reduces the number of unsuccessfully decoded codewords in the same check equation .",
    "however , it should be noted that more combined horizontal codewords result in less performance gain .",
    "let @xmath65 be the @xmath66 unsuccessfully decoded horizontal codewords participating in the @xmath50-th check equation of @xmath22 of the vertical code . then can be rewritten as @xmath67 two soft - decision vectors for @xmath68 can be obtained as @xmath69 and @xmath70 since it can be regarded that one horizontal codeword is independently received twice through the channel , we can add two soft - decision vectors in and and re - decode it . if the re - decoding succeeds , then @xmath71 and @xmath72 are known . by repeating the previous process , @xmath73",
    "can also be split into two groups as @xmath74 and the same process can be applied to decode @xmath75 .",
    "if the re - decoding is unsuccessful , then different grouping of the unsuccessfully decoded codewords can be tried .",
    "this process is repeatedly performed until all errors are corrected .",
    "the flowchart of the proposed decoding scheme is shown in fig .",
    "[ fig : flowchart_main ] , where only @xmath76 is considered .",
    "this flowchart is based on the assumption that the vertical code is a linear systematic code .",
    "note that four steps in the left bottom part of fig .",
    "[ fig : flowchart_main ] are equivalent to the erasure decoding under binary erasure channel .",
    "it is well known that the _ error correctability _",
    "@xmath77 of the vertical code is determined by the minimum hamming distance @xmath78 of the code , i.e. , @xmath79 under binary erasure channel .",
    "assume that an spc code with length @xmath19 is used as a vertical code of the product code and an ldpc code is used as a horizontal code .",
    "then , the parity - check matrix @xmath20 of the vertical code and its @xmath22 can be written as @xmath80 from the parity - check matrix , it holds @xmath81 after decoding each of @xmath19 horizontal codewords , there may exist @xmath17 unsuccessfully decoded horizontal codewords .",
    "since @xmath20 , @xmath22 , and @xmath24 have only one row whose entries are all 1 , @xmath51 is always equal to @xmath17 .",
    "if @xmath82 and the unsuccessfully decoded codeword is parity codeword @xmath83 , we already successfully decode the whole systematic horizontal codewords @xmath84 . if @xmath82 and the unsuccessfully decoded codeword is a systematic codeword @xmath48 , this codeword can be easily corrected by the even parity condition for the vertical code as @xmath85 if @xmath86 and two systematic codewords @xmath87 and @xmath88 are unsuccessfully decoded , can be rewritten as @xmath89 we can exactly calculate @xmath90 because all these codewords are successfully decoded . with this result and the soft - decision vector for @xmath88 , we have another independently received soft - decision vector @xmath91 for a codeword @xmath87 as @xmath92 similar to the type - i h - arq , we can add two soft - decision vectors @xmath61 and @xmath91 and then re - decode it to obtain @xmath87 .",
    "if one of two unsuccessfully decoded codewords is @xmath83 , it is easy to show that the same procedure can be applied .",
    "if @xmath93 and three systematic codewords @xmath87 , @xmath88 , and @xmath94 are unsuccessfully decoded , can be rewritten as @xmath95 then , we can combine the soft - decision vectors for @xmath88 and @xmath94 by and exactly calculate @xmath96 . by using these vectors , we derive another independently received soft - decision vector @xmath91 for the codeword @xmath87 as @xmath97 finally , we add two soft - decision vectors @xmath61 and @xmath91 and re - decode it for @xmath87 .",
    "if the re - decoding fails , then we can retry the same decoding procedure for @xmath88 or @xmath94 instead of @xmath87 . in the case of @xmath98",
    ", the similar process can be applied .",
    "assume that a @xmath99 hamming code is used as a vertical code of the product code and an ldpc code is used as a horizontal code .",
    "then , the parity - check matrix @xmath20 of the vertical code and its @xmath22 can be written as @xmath100          1 & 1 & 1 & 0 & 0 & 1 & 0 \\\\[-3 mm ]          0 & 1 & 1 & 1 & 0 & 0 & 1 \\\\      \\end{bmatrix } \\rightarrow      h_e =       \\begin{bmatrix }          1 & 0 & 1 & 1 & 1 & 0 & 0 \\\\[-3 mm ]          1 & 1 & 1 & 0 & 0 & 1 & 0 \\\\[-3 mm ]          0 & 1 & 1 & 1 & 0 & 0 & 1 \\\\[-3 mm ]          0 & 1 & 0 & 1 & 1 & 1 & 0 \\\\[-3 mm ]          1 & 1 & 0 & 0 & 1 & 0 & 1 \\\\[-3 mm ]          1 & 0 & 0 & 1 & 0 & 1 & 1 \\\\[-3 mm ]          0 & 0 & 1 & 0 & 1 & 1 & 1 \\\\      \\end{bmatrix}.\\ ] ]    then , the rows of @xmath22 give the following check equations for 7 horizontal codewords @xmath101 , @xmath102 , @xmath103 , @xmath104 , @xmath83 , @xmath105 , and @xmath106 ;    @xmath107    after decoding each of seven horizontal codewords , there may exist @xmath17 horizontal codewords , @xmath108 , which fail to be correctly decoded . if @xmath109 , at least one check equation from @xmath110 contains that unsuccessfully decoded horizontal codeword , which can be easily corrected .",
    "it is easy to see that selecting proper check equation to correct an erroneous horizontal codeword is equivalent to finding a weight-1 row in @xmath24 .",
    "the same approach can be used to correct more than one error .",
    "for example , let @xmath101 , @xmath102 , and @xmath103 be three unsuccessfully decoded horizontal codewords .",
    "then , we have @xmath111          1 & 1 & 1 \\\\[-3 mm ]          0 & 1 & 1 \\\\[-3 mm ]          0 & 1 & 0 \\\\[-3 mm ]          1 & 1 & 0 \\\\[-3 mm ]          1 & 0 & 0 \\\\[-3 mm ]          0 & 0 & 1 \\\\      \\end{bmatrix}\\ ] ] and each recovery process for @xmath101 , @xmath102 , and @xmath103 can be conducted using , , and , which correspond to the sixth , the fourth , and the last rows of @xmath24 , respectively .",
    "however , for three unsuccessfully decoded codewords @xmath101 , @xmath102 , and @xmath104 , there is no weight-1 row in the following @xmath24 constructed by selecting the first , second , and fourth columns of @xmath22 , which has @xmath57 as @xmath111          1 & 1 & 0 \\\\[-3 mm ]          0 & 1 & 1 \\\\[-3 mm ]          0 & 1 & 1 \\\\[-3 mm ]          1 & 1 & 0 \\\\[-3 mm ]          1 & 0 & 1 \\\\[-3 mm ]          0 & 0 & 0 \\\\      \\end{bmatrix}.\\ ] ] instead , as the case 2 ) in the subsection [ sec : proposedscheme]-b , by using corresponding to the first row of the above @xmath24 , we can modify the sign of each element of the soft - decision vector of @xmath104 using the correctly decoded codewords @xmath103 and @xmath83 , which results in another soft - decision vector for @xmath101 .",
    "this newly created soft - decision vector can be added to the original soft - decision vector for @xmath101 and the re - decoding can be performed for this combined vector .",
    "if the re - decoding fails , we can try the same decoding procedure for another check equation corresponding to a weight-2 row in @xmath24 .",
    "now , we consider more severe case , for example , there is only one successfully decoded horizontal codeword in a codeword matrix ( @xmath112 ) , say @xmath103 .",
    "using , we have the following re - decoding steps :    1 .",
    "combine the soft - decision vectors of @xmath104 and @xmath83 using the operation to have the soft - decision vector for @xmath113 ; 2 .",
    "modify the sign of each element of the resulting soft - decision vector using @xmath103 to obtain the soft - decision vector for @xmath114 .",
    "the resulting soft - decision vector for @xmath114 can be considered as the other independently received vector for @xmath101 .",
    "thus this newly created soft - decision vector can be added to the original soft - decision vector for @xmath101 and the re - decoding can be performed for this combined soft - decision vector .",
    "if the decoding is successful , then it gives @xmath115 case .",
    "if the decoding is not successful , we can also try other check equation until the decoding is successful or there is no remaining check equation available .",
    "in this section , the combined - decodability of the proposed decoding scheme is defined and the relation between the combined - decodability of the proposed decoding scheme and the vertical code with parity - check matrix @xmath20 is investigated .",
    "although the soft information combining of the proposed decoding scheme can be applied for any value of @xmath51 , the analysis of combined - decodability is performed by only considering the cases of @xmath116 in this section .      for a given @xmath20 of a vertical code @xmath0 and a fixed @xmath117 ,",
    "if every possible @xmath118 matrix @xmath24 contains at least one row of hamming weight one or two , the vertical code @xmath0 is said to be @xmath117 _",
    "combinable_.    if a vertical code @xmath0 is @xmath117 combinable for all @xmath119 , then @xmath0 is said to be @xmath120 _ combined - decodable_. if @xmath0 is not @xmath121 combined - decodable but @xmath120 combined - decodable , then @xmath120 is called the combined - decodability of @xmath0 .    using the above definitions , the length of vertical code can be bounded as in the following lemmas and theorems .",
    "+    if a vertical code @xmath0 with a parity - check matrix @xmath20 is @xmath117 combinable , any vertical code @xmath122 whose parity - check matrix @xmath123 is constructed by selecting @xmath117 or more columns from @xmath20 is also @xmath117 combinable .",
    "a set of all possible @xmath124 s which are constructed by selecting @xmath117 columns from @xmath125 is contained in the set of all possible @xmath24 s which are constructed by selecting @xmath117 columns from @xmath22 .",
    "all vertical codes @xmath0 are @xmath126 and @xmath127 combinable .    since there is no all - zero column in the parity - check matrix @xmath20 of any vertical code @xmath0 , all vertical codes @xmath0 are both @xmath126 and @xmath127 combinable .",
    "if a vertical code @xmath0 with an @xmath21 parity - check matrix @xmath20 is @xmath128 combinable , then @xmath129 , where @xmath130 .",
    "moreover , when @xmath131 , @xmath0 is @xmath128 combinable if and only if @xmath20 is constructed by using every nonzero @xmath132-tuple column vector exactly twice as its columns .",
    "if @xmath133 , there should exist three identical columns in @xmath22 .",
    "if these three identical columns are selected to construct @xmath24 , each row weight of @xmath24 is either zero or three .",
    "thus @xmath0 can not be 3 combinable .",
    "+ ( only if part ) : for a parity - check matrix @xmath20 of a 3 combinable code @xmath134with @xmath135 , suppose that all the nonzero @xmath132-tuple column vectors do not appear exactly twice in @xmath20 . then @xmath22 should have at least three identical columns .",
    "if these three identical columns are selected to construct @xmath24 , it contradicts the assumption that @xmath0 is 3 combinable . + ( if part ) : clearly , @xmath131 because the number of nonzero @xmath132-tuple column vectors is @xmath136 .",
    "if we construct @xmath24 by choosing any three columns from @xmath22 , there should be at least one distinct column from the others and therefore we can always find a row of weight one or two in @xmath24 .    from lemmas 4 and 5 , the following theorem can be stated without proof .",
    "+    the combined - decodability of spc codes is two .    in order to find the combined - decodability of hamming codes ,",
    "the following lemmas are needed .",
    "+    if a vertical code @xmath0 with an @xmath21 parity - check matrix @xmath20 is 4 combinable , then @xmath137 , where @xmath130 .",
    "moreover , when @xmath138 , @xmath0 is @xmath139 combinable if and only if @xmath20 is constructed by using every nonzero @xmath132-tuple column vector exactly three times as its columns .",
    "if @xmath140 , there should exist four identical columns in @xmath22 .",
    "if these four identical columns are selected to construct @xmath24 , each row weight of @xmath24 is either zero or four .",
    "thus @xmath0 can not be 4 combinable .",
    "+ ( only if part ) : for a parity - check matrix @xmath20 of a 4 combinable code @xmath0 with @xmath141 , suppose that all the nonzero @xmath132-tuple column vectors do not appear exactly three times in @xmath20 .",
    "then @xmath22 should have at least four identical columns .",
    "if those four identical columns are selected to construct @xmath24 , there is no row of weight one or two in @xmath24 .",
    "thus it contradicts the assumption that @xmath0 is 4 combinable . + ( if part ) : since each nonzero @xmath132-tuple column vector appears exactly three times in @xmath20 , @xmath138 .",
    "if we choose any four columns from @xmath22 , there should be at least one distinct column from the others .",
    "suppose that there is neither a weight-1 row nor a weight-2 row in @xmath24 for @xmath142 .",
    "since both @xmath22 and @xmath24 are closed under the row - wise addition , @xmath24 can be of two distinct types , that is , the first type has @xmath143 as its nonzero rows and the second type has one 4-tuple of weight three , say @xmath144 , as its nonzero rows such that @xmath145          \\vdots & \\vdots & \\vdots & \\vdots \\\\[-3 mm ]          0 & 0 & 0 & 0 \\\\[-3 mm ]          1 & 1 & 1 & 1 \\\\[-3 mm ]          \\vdots & \\vdots & \\vdots & \\vdots \\\\[-3 mm ]          1 & 1 & 1 & 1 \\\\      \\end{bmatrix } ~\\textrm{or}~      \\begin{bmatrix }          0 & 0 & 0 & 0 \\\\[-3 mm ]          \\vdots & \\vdots & \\vdots & \\vdots \\\\[-3 mm ]          0 & 0 & 0 & 0 \\\\[-3 mm ]          1 & 1 & 1 & 0 \\\\[-3 mm ]          \\vdots & \\vdots & \\vdots & \\vdots \\\\[-3 mm ]          1 & 1 & 1 & 0 \\\\      \\end{bmatrix}.\\ ] ] however , note that the latter matrix can not be obtained because there is no all - zero column in @xmath24 .",
    "therefore the former matrix is the only possible matrix for @xmath24 to have rows of weight zero or four .",
    "based on this result , we can see that there should be a row of weight one or two in @xmath24 .",
    "the following corollary is given without proof .",
    "+    if a vertical code @xmath0 is 3 combinable , then @xmath0 is also 4 combinable and thus @xmath0 is 4 combined - decodable .",
    "suppose that vertical code @xmath0 has minimum distance @xmath146 which is larger than or equal to 3 . if @xmath0 with an @xmath21 parity - check matrix @xmath20 is 5 combinable , then @xmath147 , where @xmath130 .",
    "moreover , when @xmath148 , @xmath0 is 5 combinable if and only if @xmath20 is constructed by using every nonzero @xmath132-tuple column vector only once as its columns .",
    "since @xmath146 is larger than or equal to 3 , @xmath20 should not contain identical columns .",
    "therefore , @xmath149 is trivial and the first part is proved .",
    "+ ( only if part ) : for @xmath148 and @xmath150 , @xmath20 is uniquely constructed by using every nonzero @xmath132-tuple column vector only once as its columns . + ( if part ) : suppose that there is neither a weight-1 row nor a weight-2 row in @xmath24 for @xmath151 .",
    "since both @xmath22 and @xmath24 are closed under the row - wise addition , there are only two types of @xmath24 such as    1 .",
    "@xmath24 should contain @xmath152 as its only nonzero rows ; 2 .",
    "@xmath24 should contain @xmath153 , @xmath154 , and @xmath155 at least once as its nonzero rows .",
    "note that the second type represents all the cases of three nonzero rows having 1 , 2 , and 2 zeros in distinct positions , respectively .",
    "then we have @xmath156          \\vdots & \\vdots & \\vdots & \\vdots & \\vdots \\\\[6 mm ]          0 & 0 & 0 & 0 & 0 \\\\[-3 mm ]          1 & 1 & 1 & 1 & 1 \\\\[6 mm ]          \\vdots & \\vdots & \\vdots & \\vdots & \\vdots \\\\[6 mm ]          1 & 1 & 1 & 1 & 1 \\\\      \\end{bmatrix } ~~\\textrm{or}~~      \\begin{bmatrix }          0 & 0 & 0 & 0 & 0 \\\\[-3 mm ]          \\vdots & \\vdots & \\vdots & \\vdots & \\vdots \\\\[-3 mm ]          0 & 0 & 0 & 0 & 0 \\\\[-3 mm ]          1 & 1 & 1 & 1 & 0 \\\\[-3 mm ]          \\vdots & \\vdots & \\vdots & \\vdots & \\vdots \\\\[-3 mm ]          1 & 1 & 1 & 1 & 0 \\\\[-3 mm ]          1 & 1 & 0 & 0 & 1 \\\\[-3 mm ]          \\vdots & \\vdots & \\vdots & \\vdots & \\vdots \\\\[-3 mm ]          1 & 1 & 0 & 0 & 1 \\\\[-3 mm ]          0 & 0 & 1 & 1 & 1 \\\\[-3 mm ]          \\vdots & \\vdots & \\vdots & \\vdots & \\vdots \\\\[-3 mm ]          0 & 0 & 1 & 1 & 1 \\\\      \\end{bmatrix}.\\ ] ] therefore , in order for @xmath0 to be 5 combinable , @xmath20 should contain neither five identical columns nor two distinct pairs of columns .",
    "if @xmath20 is constructed by using every nonzero @xmath132-tuple column vector only once as its columns , it is clear that @xmath20 has neither five identical columns nor two distinct pairs of columns and @xmath0 is 5 combinable . thus the proof is done .",
    "+    for 5 combinable vertical code @xmath0 without restriction on the minimum distance , it is not difficult to verify that the upper bound in lemma 9 becomes @xmath157 .",
    "this bound can be proved by similar method used in the proof of lemma 9 .      in this subsection",
    ", we will derive the combined - decodability of hamming codes .",
    "hamming codes as vertical codes are neither 6 combinable nor 7 combinable .    for a @xmath99 hamming code",
    ", @xmath22 is given in subsection  [ sec : examplehamming ] .",
    "the first three rows in @xmath22 show all possible nonzero column vectors of length 3 and the rows in @xmath22 are all possible linear combinations of the first three rows except all - zero row .",
    "since all rows in @xmath24 have weight four , a @xmath99 hamming code is not 7 combinable .    for a @xmath158 hamming code , the parity - check matrix consists of all nonzero @xmath132-tuple column vectors . using only column permutation",
    ", we can reorder the parity - check matrix as @xmath159          \\vdots & \\vdots & \\vdots & \\vdots & \\vdots & \\vdots & \\vdots & \\cdots \\\\[-3 mm ]          0 & 0 & 0 & 0 & 0 & 0 & 0 & \\cdots \\\\[-3 mm ]          1 & 0 & 1 & 1 & 1 & 0 & 0 & \\cdots \\\\[-3 mm ]          0 & 1 & 0 & 1 & 1 & 1 & 0 & \\cdots \\\\[-3 mm ]          0 & 0 & 1 & 0 & 1 & 1 & 1 & \\cdots \\\\[-3 mm ]      \\end{bmatrix}.\\ ] ] note that the first seven column vectors have zeros in the first @xmath160 positions and they should be all different from each other . since there is no all - zero column vector in @xmath20 , there should appear all nonzero 3-tuple column vectors in the last three rows corresponding to the first seven columns .",
    "then , we can construct @xmath22 by using all possible non - trivial linear combinations of rows in @xmath20 , and @xmath24 by selecting the first seven columns from @xmath22 .",
    "it is clear that such @xmath24 is made up of all - zero rows and the rows of @xmath22 for a @xmath99 hamming code .",
    "since the weight of rows of @xmath24 is either 0 or 4 , hamming codes are not 7 combinable .",
    "it is also easy to check that hamming codes are not 6 combinable because we can always find an @xmath24 for @xmath161 which consists of weight-0 , weight-3 , and weight-4 rows by choosing any 6 columns from the above @xmath24 for @xmath162 .",
    "the combined - decodability of hamming codes as vertical codes is five .    from lemmas 3 , 4 , 5 , 7 and 9 ,",
    "hamming codes are 5 combined - decodable .",
    "the theorem is directly proved by this result and lemma 10 .",
    ".distribution of @xmath24 for all possible horizontal codeword errors in the proposed decoding scheme with hamming codes [ cols=\"^,^,^,^,^ \" , ]     table  [ tab : distributionhamming ] shows the distribution of @xmath24 for all possible unsuccessfully decoded horizontal codewords when hamming codes are used as vertical codes .",
    "it clearly shows that combined - decodability of any hamming code is five .",
    "table  [ tab : distributionnonhamming ] shows the distribution of @xmath24 for all possible unsuccessfully decoded horizontal codewords when double parity - check ( dpc ) codes are used as vertical codes .",
    "it shows that the combined - decodabilities of @xmath163 and @xmath164 dpc codes are four and two , respectively . to analyze the combined - decodability of the proposed decoding scheme , some simple linear codes such as spc , dpc , and hamming codes are considered as vertical codes , the parameters of which are listed in table  [ tab : candidates ] .",
    "in this section , numerical analysis of the proposed decoding scheme is performed .",
    "the performance of ldpc codes with @xmath165 and @xmath166 in two different lengths @xmath167 and @xmath168 in ieee  802.16e standard@xcite are compared with that of the proposed decoding scheme . the maximum number of iterations for iterative belief propagation ( bp ) decoding is set to 50 for the entire simulations .    for the proposed decoding scheme , the @xmath169 spc code is selected as the vertical code .",
    "to maintain the same overall code rate , the ldpc codes obtained by puncturing the above codes in ieee  802.16e standard are used as the horizontal codes . by using the puncturing rate @xmath170 , the overall code rates for the proposed decoding scheme",
    "are also set to @xmath171 and @xmath172 .",
    "+    fig .",
    "[ fig : performance ] shows that the proposed decoding scheme with @xmath169 spc vertical code outperforms the conventional ldpc codes in ieee802.16e standard for @xmath165 and @xmath166 , especially in high snr region , where ` proposed-@xmath17 ' means that up to @xmath17 horizontal codeword errors are combined - decoded .",
    "error correction performance of each decoding scheme is shown in fig .",
    "[ fig : performance ] by word error rate ( wer ) of ldpc codewords for the conventional scheme and horizontal ldpc codewords for the proposed scheme . even though the proposed decoding scheme does not correct all error patterns of @xmath17 or less horizontal codeword errors , fig .",
    "[ fig : performance ] shows remarkable performance improvement .",
    "the simulation results also show that both the waterfall and error - floor performance of the ldpc code can be improved by constructing a product code and performing the proposed decoding scheme .    additional computational complexity for the proposed decoding scheme may be significant for low snr region .",
    "however , for high snr region , decoding failure of more than one horizontal codeword in a codeword matrix is rarely occurred .",
    "thus , in spite of remarkable performance improvement , additional computational complexity per codeword becomes negligible for high snr region .",
    "we showed the numerical results only for the case of spc codes being used as vertical codes .",
    "also , some of possible grouping methods for the erroneous horizontal codewords , i.e. , grouping into one codeword and others , are considered for the case of @xmath173 .",
    "if we use more powerful codes such as hamming codes as vertical codes or consider more various grouping methods for the erroneous horizontal codewords , the performance of the proposed decoding scheme is believed to be improved but their decoding complexity increases .",
    "a new decoding scheme for ldpc codes using simple product code structure is proposed based on combining two independently received soft - decision data for the same codeword .",
    "the proposed decoding scheme can achieve very low error probability , which is very difficult to achieve only by using single channel coding scheme .",
    "especially , the proposed decoding scheme can achieve better error - correcting capability in high snr region .",
    "also , the decoding capability of the proposed decoding scheme is analyzed using parity - check matrices of vertical codes and the _ combined - decodability _ is exactly derived when spc and hamming codes are used as vertical codes .",
    "it should be noted that the proposed decoding scheme can be applied to any other linear codes with soft - decision decoding than ldpc codes and will work well for the codes which rarely have undetected errors such as ldpc codes",
    ".    1 r.  g.  gallager , low density parity check codes .",
    "cambridge , ma : mit press , 1963 .",
    "d.  mackay and r.  m.  neal , `` near shannon limit performance of low - density parity - check codes , '' _ elec .",
    "1645- 1646 , aug .",
    "t.  richardson , `` error floors of ldpc codes , '' in _ proc .",
    "allerton conf .",
    "commun . , control , comput .",
    "1426 - 1435 , oct .",
    "m. p. c. fossorier , m. mihaljevic , and h. imai , `` reduced complexity iterative decoding of low - density parity check codes based on belief propagation , '' _ ieee trans . commun .",
    "673 - 680 , may 1999 .",
    "m. p. c. fossorier ,",
    "`` iterative reliability - based decoding of low - density parity check codes , '' _ ieee j. sel .",
    "908 - 917 , may 2001 .",
    "j. chen and m. p. c. fossorier , `` near optimum universal belief propagation based decoding of low - density parity check codes , '' _ ieee trans .",
    "3 , pp . 406 - 414 , mar .",
    "m. r. yazdani , s. hemati , and a. h. banihashemi , `` improving belief propagation on graphs with cycles , '' _ ieee commun .",
    "_ , vol . 8 , no . 1 , pp .",
    "57 - 59 , jan . 2004 .",
    "s. laendner and o. milenkovic , `` algorithmic and combinatorial analysis of trapping sets in structured ldpc codes , '' in _ proc .",
    "wireless networks ( wirelesscomm2005 ) _ , vol .",
    "630 - 635 , dec . 2005 .",
    "y. han and w. e. ryan , `` low - floor decoders for ldpc codes , '' _ ieee trans .",
    "57 , no . 6 , pp . 1663 - 1673 , jun .",
    "s. k. chilappagari , m. chertkov , m. g. stepanov , and b. vasic , `` instanton - based techniques for analysis and reduction of error floors of ldpc codes , '' _ ieee j. sel .",
    "27 , no . 6 , pp .",
    "855 - 865 , aug . 2009 .",
    "s. k. planjery , d. declercq , s. k. chilappagari , and b. vasic , `` multilevel decoders surpassing belief propagation on the binary symmetric channel , '' in _ proc .",
    "inform . theory _ , pp .",
    "769 - 773 , jun . 2010 .",
    "r. asvadi , a. h. banihashemi , and m. ahmadian - attari , `` lowering the error floor of ldpc codes using cyclic liftings , '' _ ieee trans .",
    "inform . theory _",
    "2213 - 2224 , apr . 2011 .",
    "s. k. planjery , d. declercq , l. danjean , and b. vasic , `` finite alphabet iterative decoders for ldpc codes surpassing floating - point iterative decoders , '' _ elec .",
    "919 - 921 , aug . 2011 . c.  berrou , a.  glavieux , and p.  thitimajshima , `` near shannon limit error - correcting coding and decoding : turbo codes , '' in _ proc .",
    "_ , 1993 , pp",
    ". 1064 - 1070",
    ". f. j. macwilliams and n. j. a. sloane , _ the theory of error - correcting codes .",
    "_ amsterdam , the netherlands : north - holland , 1978 , pp .",
    "567 - 580 .",
    "p. elias , `` error - free coding , '' _ ire trans .",
    "inform . theory _",
    "it-4 , pp .",
    "29 - 37 , sep .",
    "j. hagenauer , e. offer , and l. papke , `` iterative decoding of binary block and convolutional codes , '' _ ieee trans .",
    "inform . theory _",
    "429 - 445 , mar .",
    "s. lin , d. costello , and m. miller , `` automatic - repeat - request error - control schemes , '' _ ieee commun . mag .",
    "12 , pp . 5 - 17 , dec",
    "802.16 , `` ieee standard for local and metropolitan area network part 16 : air interface for fixed and mobile broadband access systems , '' 2004 ."
  ],
  "abstract_text": [
    "<S> in this paper , a new decoding scheme for low - density parity - check ( ldpc ) codes using the concept of simple product code structure is proposed based on combining two independently received soft - decision data for the same codeword . </S>",
    "<S> ldpc codes act as horizontal codes of the product codes and simple algebraic codes are used as vertical codes to help decoding of the ldpc codes . </S>",
    "<S> the decoding capability of the proposed decoding scheme is defined and analyzed using the parity - check matrices of vertical codes and especially the _ combined - decodability _ is derived for the case of single parity - check ( spc ) and hamming codes being used as vertical codes . </S>",
    "<S> it is also shown that the proposed decoding scheme achieves much better error - correcting capability in high signal to noise ratio ( snr ) region with low additional decoding complexity , compared with a conventional decoding scheme .    </S>",
    "<S> b. shin : new decoding scheme for ldpc codes based on simple product code structure    combined - decodability , decoding , hamming codes , low - density parity - check ( ldpc ) codes , product codes , single parity - check ( spc ) codes . </S>"
  ]
}