{
  "article_text": [
    "mobile communication systems , such as cellular phone systems , are now used every day by millions of people worldwide .",
    "code - division multiple - access ( cdma ) is a digital modulation system that employs spreading codes to enable access to a mobile communication system by multiple users @xcite . in the multipoint - to - point communication framework",
    ", cdma allows several users to share a single communication channel to a base station .",
    "each user first modulates one s own information sequence using the spreading code assigned to the user , and then the modulated sequence is transmitted to the base station .",
    "the base station receives a mixture of the transmitted signals and additional channel noise . using the users spreading codes",
    ", a demodulator at the base station extracts the original information sequense from the received noise - degraded mixture signal .",
    "this process is called a detection .",
    "tanaka has evaluated the detection problem by the replica method @xcite .",
    "however , the detection process can not be treated by the replica method .",
    "the detection process of cdma has drawn much attention from theoretical as well as practical viewpoints @xcite .",
    "tanaka and okada have applied a dynamical theory of hopfield model @xcite to the detection process @xcite .",
    "their method is equivalent to the density evolution ( de ) framework in the field of information theory @xcite . in the de framework , a local field , which is a matched filter output that the estimated parallel interference is subtracted from ,",
    "is separated into a signal part for the detection and a remaining noise part .",
    "furthermore , it is assumed that the noise part follows a gaussian distribution with mean zero .",
    "the predictions of de can fairly explain the detection dynamics only in the case where the detection dynamics converge @xcite .",
    "however , at transients the predictions of de systematically deviate from computer simulation results .",
    "the gaussian assumption of the local field has a more serious influence , when the detection dynamics fail to converge .",
    "in such a case , the deviation of the predictions of de from the results of numerical experiments becomes large @xcite . on the other hand ,",
    "generating functional analysis ( gfa ) @xcite does not need the gaussian assumption . in this paper",
    ", we present gfa to evaluate the detection dynamics for cdma multiuser detection , applied to a randomly spread , fully synchronous base - band uncoded cdma channel model with additive white gaussian noise ( awgn ) under perfect power control . in order to confirm the validity of our analysis ,",
    "we have performed computer simulations for some typical system load and channel noise conditions .",
    "we will focus on the basic fully syncronous @xmath0-user baseband binary phase - shift - keying ( bpsk ) cdma channel model with perfect power control as @xmath1 where @xmath2 is the recieved signal at chip interval @xmath3 , and where @xmath4 and @xmath5 are the bpsk - modulated information bit and the spreading code of user @xmath6 at chip interval @xmath7 , respectively .",
    "figure [ fig : model ] shows this cdma communication model .",
    "the gaussian random variable @xmath8 , where @xmath9 , represents channel noise whose variance is @xmath10 .",
    "the spreading codes are independently generated from the identical unbiased distribution @xmath11 .",
    "the factor @xmath12 is introduced in order to normalize the power per symbol to 1 . using these normalisations , the signal to noise ratio",
    "is defined as @xmath13 . the ratio @xmath14 is called system load .    the goal of multiuser detection is to simultaneously infer the information bits @xmath15 after recieving the base - band signals @xmath16 .",
    "the updating rule for the tentative decision @xmath17 of bit signal @xmath18 at stage @xmath19 is @xmath20 where @xmath21 is the output of the matched filter for user @xmath22 : @xmath23 and @xmath24 is the @xmath25-element of the sample correlation matrix @xmath26 of the spreading code : @xmath27 the function @xmath28 denotes the sign function taking 1 for @xmath29 and -1 for @xmath30 .",
    "this iterative detection algorithm is called the parallel interference canceller ( pic ) @xcite . as for initialization",
    ", we assume the matched filter stage , i.e. , @xmath31 .",
    "this initialization is easily treated by formally assuming @xmath32 for all @xmath22 .",
    "the widely used measure of the performance of a demodulator is the bit error rate ( ber ) @xmath33 , which is given by @xmath34/2 $ ] , where @xmath35 is the overlap between the information bits vector @xmath36 and the tentative decision vector @xmath37 .",
    "the operator @xmath38 denotes the transpose . without loss of generality ,",
    "we assume that the true information bits are all 1 , i.e. , @xmath39 for all @xmath22 , because the spreading codes are unbiased .",
    "we analyse the detection dynamics in the large system limit where @xmath40 , while the system load @xmath41 is kept finite . for generating functional analysis",
    ", we introduce inverse temperature @xmath42 . the stochastic updating rule for the tentative decision @xmath17 of bit signal @xmath18 at stage @xmath19",
    "is given by @xmath43=\\frac 12 \\biggl ( 1-\\tanh \\gamma \\hat{b}_k(t+1 ) u_k(t ) \\biggr ) , \\label{eq : updating_rule}\\ ] ] where @xmath44 which is called a local field .",
    "in the limit where @xmath45 , this updating rule is equivalent to ( [ eq : deterministic_updating_rule ] ) . the term @xmath46 is a time - dependent external field which is introduced in order to define a response function .",
    "the inverse temperature and the external field are set @xmath45 and @xmath47 in the end of analysis .    to analyse the dection dynamics of the system we define a generating functional @xmath48 $ ] : @xmath49=\\sum_{\\hat{{\\mbox{\\boldmath $ b$}}}(-1),\\cdots,\\hat{{\\mbox{\\boldmath $ b$}}}(t ) } p[\\hat{{\\mbox{\\boldmath $ b$}}}(-1),\\cdots,\\hat{{\\mbox{\\boldmath $ b$}}}(t ) ] e^{-i\\sum_{s=-1}^t\\hat{{\\mbox{\\boldmath $ b$}}}(s)\\cdot{\\mbox{\\boldmath $ \\psi$}}(s ) } \\label{eq : def_z}\\ ] ]",
    "where @xmath50 , @xmath51 .",
    "in familiar way @xcite , one can obtain from @xmath48 $ ] all averages of interest by differenriation , e.g. , @xmath52}{\\partial \\psi_k(s ) } , \\\\",
    "c_{kk'}(s , s')&=&<\\hat{b}_k(s)\\hat{b}_{k'}(s')>=-\\lim_{{\\mbox{\\boldmath $ \\psi$}}\\to{\\mbox{\\boldmath $ 0$}}}\\frac{\\partial z[{\\mbox{\\boldmath $ \\psi$}}]}{\\partial \\psi_k(s ) \\partial \\psi_{k'}(s ' ) } , \\\\",
    "g_{kk'}(s , s')&=&\\frac{\\partial < \\hat{b}_k(s)>}{\\partial \\theta_{k'}(s')}=i\\lim_{{\\mbox{\\boldmath $ \\psi$}}\\to{\\mbox{\\boldmath $ 0$}}}\\frac{\\partial z[{\\mbox{\\boldmath $ \\psi$}}]}{\\partial \\psi_k(s ) \\partial \\theta_{k'}(s')}.\\end{aligned}\\ ] ] the dynamics ( [ eq : updating_rule ] ) is a markov chain , so the path probability @xmath53 $ ] are simply given by products of the individual transiton probabilities @xmath54 $ ] of the chain : @xmath55=p[\\hat{{\\mbox{\\boldmath $ b$}}}(-1)]\\prod_{s=-1}^{t-1}\\rho[\\hat{{\\mbox{\\boldmath $ b$}}}(s+1)|\\hat{{\\mbox{\\boldmath $ b$}}}(s ) ] ,   \\label{eq : def_path_probability}\\ ] ] where these transition probabilities are given by @xmath56=\\prod_{k=1}^k \\frac{e^{\\gamma\\hat{b}_k(s+1)u_k(s)}}{2\\cosh \\gamma u_k(s)}. \\label{eq : def_transition_probability}\\ ] ] since the initial state is given by ( [ eq : initial_state ] ) , the initial state probability becomes @xmath57=\\prod_{k=1}^k p[\\hat{b}_k(-1)=0]=1 $ ] .",
    "we separate the local field at any stage by inserting a following delta - distributions : @xmath58 } , \\label{eq : local_field}\\ ] ] where @xmath59 and @xmath60",
    ". we can express ( [ eq : def_z ] ) as @xmath61 & = & \\sum_{\\hat{{\\mbox{\\boldmath $ b$}}}(-1),\\cdots,\\hat{{\\mbox{\\boldmath $ b$}}}(t ) } p[\\hat{{\\mbox{\\boldmath $ b$}}}(-1 ) ] \\int \\delta{\\mbox{\\boldmath $ u$}}\\delta\\hat{{\\mbox{\\boldmath $ u$ } } } \\nonumber \\\\ & & \\quad \\times e^{i \\sum_{s=-1}^{t-1 } \\sum_{k=1}^k \\hat{u}_k(s ) \\",
    "{ u_k(s)-\\hat{b}_k(s)-\\theta_k(s ) \\ } -i\\sum_{s=-1}^t \\sum_{k=1}^k \\hat{b}_k(s)\\psi_k(s ) } \\nonumber \\\\ & & \\quad \\times e^{\\sum_{s=0}^t \\sum_{k=1}^k \\ { \\gamma \\hat{b}_k(s ) u_k(s ) - \\ln 2 \\cosh",
    "\\gamma u_k(s-1 ) \\ } } \\nonumber \\\\ & & \\quad \\times e^{- i \\sqrt{\\beta } \\sigma_0 \\sum_{\\mu=1}^n \\sum_{s=-1}^{t-1 } [ \\frac1{\\sqrt{k } } \\sum_{k=1}^k \\hat{u}_k(s)s_k^\\mu ] n^\\mu } \\nonumber \\\\ & & \\quad \\times e^{- i \\beta \\sum_{\\mu=1}^n \\sum_{s=-1}^{t-1 } [ \\frac1{\\sqrt{k } } \\sum_{k=1}^k \\hat{u}_k(s)s_k^\\mu ] [ \\frac1{\\sqrt{k } } \\sum_{k'=1}^k s_{k'}^\\mu \\ { 1-\\hat{b}_{k'}(s ) \\ } ] } .",
    "\\label{eq : z1}\\end{aligned}\\ ] ] in order to average the generating functional with respect to the disorder @xmath62 and @xmath63 , we isolate the spreading codes by introducing the variables @xmath64 : @xmath65 } , \\\\ 1 & = & \\int \\delta{\\mbox{\\boldmath $ w$}}\\delta\\hat{{\\mbox{\\boldmath $ w$ } } } \\prod_{s=-1}^{t-1 } \\prod_{\\mu=1}^n e^{i\\hat{w}_\\mu(s ) [ w_\\mu(s ) - \\frac1{\\sqrt{k } } \\sum_{k=1}^k s_k^\\mu \\ { 1-\\hat{b}_k(s ) \\ } ] } , \\end{aligned}\\ ] ] where @xmath66 , @xmath67 , @xmath68 , and @xmath69 .",
    "the term in ( [ eq : z1 ] ) containing the disorder becomes @xmath70 n^\\mu } } \\nonumber \\\\ & & \\quad \\overline { \\times e^{- i \\beta \\sum_{\\mu=1}^n \\sum_{s=-1}^{t-1 } [ \\frac1{\\sqrt{k } } \\sum_{k=1}^k \\hat{u}_k(s)s_k^\\mu ] [ \\frac1{\\sqrt{k } } \\sum_{k'=1}^k s_{k'}^\\mu \\ { 1-\\hat{b}_{k'}(s ) \\ } ] } } \\nonumber \\\\ & = & \\int \\delta{\\mbox{\\boldmath $ v$}}\\delta\\hat{{\\mbox{\\boldmath $ v$}}}\\delta{\\mbox{\\boldmath $ w$}}\\delta\\hat{{\\mbox{\\boldmath $ w$ } } } e^{i \\sum_{\\mu=1}^n \\sum_{s=-1}^{t-1 } \\{\\hat{v}_\\mu(s)v_\\mu(s)+\\hat{w}_\\mu(s)w_\\mu(s)-\\beta v_\\mu(s)w_\\mu(s)\\ } } \\nonumber \\\\ & & \\quad \\times e^{-\\frac12 \\sum_{\\mu=1}^n \\sum_{s=-1}^{t-1 } \\sum_{s'=-1}^{t-1 } \\beta\\sigma_0 ^ 2v_\\mu(s)v_\\mu(s ' ) } \\nonumber \\\\ & & \\quad \\times e^{-\\frac12 \\sum_{\\mu=1}^n \\sum_{s=-1}^{t-1 } \\sum_{s'=-1}^{t-1 } \\hat{v}_\\mu(s ) [ \\frac 1k \\sum_{k=1}^k \\hat{u}_k(s ) \\hat{u}_k(s ' ) ] \\hat{v}_\\mu(s ' ) } \\nonumber \\\\ & & \\quad \\times e^{-\\frac12 \\sum_{\\mu=1}^n \\sum_{s=-1}^{t-1 } \\sum_{s'=-1}^{t-1 } \\hat{v}_\\mu(s ) [ \\frac 1k \\sum_{k=1}^k \\hat{u}_k(s ) - \\frac 1k \\sum_{k=1}^k \\hat{u}_k(s)\\hat{b}_k(s ' ) ] \\hat{w}_\\mu(s ' ) } \\nonumber \\\\ & & \\quad \\times e^{-\\frac12 \\sum_{\\mu=1}^n \\sum_{s=-1}^{t-1 } \\sum_{s'=-1}^{t-1 } \\hat{w}_\\mu(s ) [ \\frac 1k \\sum_{k=1}^k \\hat{u}_k(s ' ) - \\frac 1k \\sum_{k=1}^k \\hat{u}_k(s')\\hat{b}_k(s ) ] \\hat{v}_\\mu(s ' ) } \\nonumber \\\\ & & \\quad \\times e^{-\\frac12 \\sum_{\\mu=1}^n \\sum_{s=-1}^{t-1 } \\sum_{s'=-1}^{t-1 } \\hat{w}_\\mu(s ) [ 1 -\\frac 1k \\sum_{k=1}^k \\hat{b}_k(s ) -\\frac 1k \\sum_{k=1}^k \\hat{b}_k(s ' ) - \\frac 1k \\sum_{k=1}^k \\hat{b}_k(s)\\hat{b}_k(s ' ) ] \\hat{w}_\\mu(s ' ) } ,   \\label{eq : z2}\\end{aligned}\\ ] ] where @xmath71 denotes averaging over the disorder @xmath62 and @xmath63 .",
    "we separate the relevant one - stage and two - stage order parameters by inserting : @xmath72 } , \\\\ 1 & = & \\biggl(\\frac k{2\\pi}\\biggr)^{t+1 } \\int d{\\mbox{\\boldmath $ k$}}d\\hat{{\\mbox{\\boldmath $ k$ } } } e^{i k \\sum_{s=-1}^{t-1 } \\hat{k}(s ) [ k(s ) - \\frac1{\\sqrt{k } } \\sum_{k=1}^k \\hat{u}_k(s ) ] } , \\\\ 1 & = & \\biggl(\\frac k{2\\pi}\\biggr)^{(t+1)^2 } \\int d{\\mbox{\\boldmath $ q$}}d\\hat{{\\mbox{\\boldmath $ q$ } } } e^{i k \\sum_{s=-1}^{t-1 } \\sum_{s'=-1}^{t-1 } \\hat{q}(s , s ' ) [ q(s , s ' ) - \\frac1{\\sqrt{k } } \\sum_{k=1}^k \\hat{b}_k(s ) \\hat{b}_k(s ' ) ] } , \\\\ 1 & = & \\biggl(\\frac k{2\\pi}\\biggr)^{(t+1)^2 } \\int d{\\mbox{\\boldmath $ q$}}d\\hat{{\\mbox{\\boldmath $ q$ } } } e^{i k \\sum_{s=-1}^{t-1 } \\sum_{s'=-1}^{t-1 } \\hat{q}(s , s ' ) [ q(s , s ' ) - \\frac1{\\sqrt{k } } \\sum_{k=1}^k \\hat{u}_k(s ) \\hat{u}_k(s ' ) ] } , \\\\ 1 & = & \\biggl(\\frac k{2\\pi}\\biggr)^{(t+1)^2 } \\int d{\\mbox{\\boldmath $ l$}}d\\hat{{\\mbox{\\boldmath $ l$ } } } e^{i k \\sum_{s=-1}^{t-1 } \\sum_{s'=-1}^{t-1 } \\hat{l}(s , s ' ) [ l(s , s ' ) - \\frac1{\\sqrt{k } } \\sum_{k=1}^k \\hat{b}_k(s ) \\hat{u}_k(s ' ) ] } .\\end{aligned}\\ ] ] since the initial state probability is factorisable , the disorder - averaged generating functional factorises into single - site contributions .",
    "the disorder - averaged generating functional is for @xmath73 dominated by a saddle - point .",
    "we can thus simplify the saddle - point problem to @xmath74 = \\int   d{\\mbox{\\boldmath $ m$}}d\\hat{{\\mbox{\\boldmath $ m$ } } } d{\\mbox{\\boldmath $ k$}}d\\hat{{\\mbox{\\boldmath $ k$ } } } d{\\mbox{\\boldmath $ q$}}d\\hat{{\\mbox{\\boldmath $ q$ } } } d{\\mbox{\\boldmath $ q$}}d\\hat{{\\mbox{\\boldmath $ q$ } } } d{\\mbox{\\boldmath $ l$}}d\\hat{{\\mbox{\\boldmath $ l$ } } } e^{k(\\psi+\\phi+\\omega)+o(\\ln k ) } \\label{eq : z3}\\ ] ] in which the functions @xmath75 are given by @xmath76 \\int \\delta u \\delta\\hat{u } e^{\\sum_{s=0}^t",
    "\\ { \\gamma \\hat{b}(s ) u(s-1 ) - \\ln 2 \\cosh",
    "\\gamma u(s-1 ) \\ } } \\nonumber \\\\ & & \\quad \\times e^{- i \\sum_{s=-1}^{t-1 } \\sum_{s'=-1}^{t-1 } \\ { \\hat{q}(s , s ' ) \\hat{b}(s ) \\hat{b}(s ' ) + \\hat{q}(s , s ' ) \\hat{u}(s ) \\hat{u}(s ' ) + \\hat{l}(s , s ' ) \\hat{b}(s ) \\hat{u}(s ' ) \\ } } \\nonumber \\\\ & & \\quad \\times e^{i \\sum_{s=-1}^{t-1 } \\hat{u}(s ) \\ { u(s ) - \\hat{b}(s ) - \\theta_k(s ) - \\hat{k}(s ) \\ } - i \\sum_{s=-1}^{t-1 } \\hat{b}(s ) \\hat{m}(s ) - i \\sum_{s=-1}^t \\hat{b}(s ) \\psi_k(s ) } \\biggr\\ } \\\\ \\omega & \\equiv & \\frac 1k \\ln \\int \\delta{\\mbox{\\boldmath $ v$}}\\delta\\hat{{\\mbox{\\boldmath $ v$}}}\\delta{\\mbox{\\boldmath $ w$}}\\delta\\hat{{\\mbox{\\boldmath $ w$ } } } e^{i \\sum_{\\mu=1}^n \\sum_{s=-1}^{t-1 } \\ { \\hat{v}_\\mu(s )",
    "v_\\mu(s ) + \\hat{w}_\\mu(s ) w_\\mu(s ) - \\beta v_\\mu(s ) w_\\mu(s ) \\ } } \\nonumber \\\\ & & \\quad \\times e^{- \\frac 12 \\sum_{\\mu=1}^n \\sum_{s=-1}^{t-1 } \\sum_{s'=-1}^{t-1 } \\ { \\beta \\sigma_0 ^ 2 v_\\mu(s ) v_\\mu(s ' ) + \\hat{v}_\\mu(s ) q(s , s ' ) \\hat{v}_\\mu(s ' ) \\ } } \\nonumber \\\\ & & \\quad \\times e^{- \\frac 12 \\sum_{\\mu=1}^n \\sum_{s=-1}^{t-1 } \\sum_{s'=-1}^{t-1 } \\ { \\hat{v}_\\mu(s ) [ k(s ) - l(s',s ) ] \\hat{w}_\\mu(s ' ) + \\hat{w}_\\mu(s ) [ k(s ' ) - l(s , s ' ) ] \\hat{v}_\\mu(s ' ) \\ } } \\nonumber \\\\ & & \\quad \\times e^{- \\frac 12 \\sum_{\\mu=1}^n \\sum_{s=-1}^{t-1 } \\sum_{s'=-1}^{t-1 } \\ { \\hat{w}_\\mu(s ) [ 1 - m(s ) - m(s ' ) + q(s , s ' ) ] \\hat{w}_\\mu(s ' ) \\ } } \\end{aligned}\\ ] ] where @xmath77 and @xmath78 .",
    "we have arrived at a single - site saddle - point problem . using normalization condition and @xmath79=1 $ ] , we obtain field derivatives of the generating functional as follows : @xmath80 where @xmath81 is kronecker s delta taking 1 if @xmath82 and 0 otherwise and @xmath83 denotes @xmath84 with @xmath85 e^{\\sum_{s=0}^t \\ { \\gamma \\hat{b}(s ) u(s-1 ) - \\ln 2 \\cosh",
    "\\gamma u(s-1 ) \\ } } \\nonumber \\\\ & & \\quad \\times e^{- i \\sum_{s=-1}^{t-1 } \\sum_{s'=-1}^{t-1 } \\ { \\hat{q}(s , s ' ) \\hat{b}(s ) \\hat{b}(s ' ) + \\hat{q}(s , s ' ) \\hat{u}(s ) \\hat{u}(s ' ) + \\hat{l}(s , s ' ) \\hat{b}(s ) \\hat{u}(s ' ) \\ } } \\nonumber \\\\ & & \\quad \\times e^{i \\sum_{s=-1}^{t-1 } \\hat{u}(s ) \\ { u(s ) - \\hat{b}(s ) - \\theta_k(s ) - \\hat{k}(s ) \\ } - i \\sum_{s=-1}^{t-1 } \\hat{b}(s ) \\hat{m}(s ) } |_{saddle}. \\end{aligned}\\ ] ] the evaluation @xmath86 denotes an evaluation of a function @xmath87 at the dominating saddle point .",
    "therefore we see the order parameters are essentially single - site ones .      in the limit @xmath73 , the integral ( [ eq : z3 ] )",
    "will be dominated by the saddle point of the extensive exponent @xmath88 .",
    "we first calculate the remaining gaussian integral in @xmath89 : @xmath90 where @xmath91 , @xmath92 and @xmath93 are matrices having matrix elements @xmath94 and @xmath95 , respectively .",
    "the saddle - point equations are derived by differentiation with respect to integration variables @xmath96 .",
    "these equations will involve the average single - site correlation @xmath97 and the average single - site response function @xmath98 : @xmath99 straightforward differentiation by usage of causality , leads us to the following saddle - point equations : @xmath100 where @xmath101 , @xmath102 , @xmath103 and @xmath104 are matrices having matrix elements @xmath105 , @xmath106 , @xmath107,\\ ] ] and @xmath108 respectively . substituting ( [ eq : sp1])-([eq : sp2 ] ) into ( [ eq : < > * ] ) and introducing a simple rescaling of local fields and conjugate local fields , the term @xmath109 becomes @xmath110 , \\end{aligned}\\ ] ] in the limit @xmath45 , where @xmath111 , @xmath112 and @xmath113 .",
    "the terms @xmath114 and @xmath115 can also be calculated in a similar way .",
    "let us summarize our calculation .",
    "some macroscopic integration variables are found to vanish in the relevant physical saddle - point : @xmath116 .",
    "the remainig ones can all be expressed in terms of three macroscopic observables , namely the overlaps @xmath117 , the single - site correlation functions @xmath97 and the single - site response functions @xmath98 . finally ,",
    "setting @xmath45 and @xmath118 , we then arrive at the following saddle - point equations in the thermodynamic limit , i.e. , @xmath73 : @xmath119 the bit error rate is obtained by @xmath120 the average over the effective path measure is given by @xmath121 , \\\\ { \\cal d}{\\mbox{\\boldmath $ v$ } } & \\equiv & \\frac{d{\\mbox{\\boldmath $ v$}}e^{-\\frac 12{\\mbox{\\boldmath $ v$}}\\cdot { \\mbox{\\boldmath $ r$}}^{-1}{\\mbox{\\boldmath $ v$}}}}{\\sqrt{|2\\pi { \\mbox{\\boldmath $ r$}}| } } , \\\\ { \\rm tr } & \\equiv & \\sum_{\\hat{b}(-1)\\in\\{0\\ } , \\hat{b}(0),\\cdots,\\hat{b}(t)\\in\\ { -1,1\\ } } , \\\\ u(s)&=&\\hat{k}(s)+v(s)+({\\mbox{\\boldmath $ \\gamma$ } } \\hat{{\\mbox{\\boldmath $ b$}}})(s ) , \\label{eq : final_local_field } \\\\ { \\mbox{\\boldmath $ r$ } } & = & ( { \\mbox{\\boldmath $ 1$}}+\\beta { } ^\\dagger { \\mbox{\\boldmath $ g$}})^{-1 } { \\mbox{\\boldmath $ d$ } } ( { \\mbox{\\boldmath $ 1$}}+\\beta { \\mbox{\\boldmath $ g$}})^{-1 } , \\\\ { \\mbox{\\boldmath $ \\gamma$ } } & = & ( { \\mbox{\\boldmath $ 1$}}+\\beta { \\mbox{\\boldmath $ g$}})^{-1}\\beta { \\mbox{\\boldmath $ g$ } } , \\\\",
    "\\hat{k}(s ) & = & |{\\mbox{\\boldmath $ \\lambda$}}_s| , \\\\ d(s ,",
    "s ' ) & \\equiv & \\sigma_0 ^ 2 + \\beta [ 1-m(s)-m(s')+c(s , s ' ) ] , \\\\ \\lambda_s(s',s '' ) & = & \\left\\ { \\begin{array}{ll } \\delta_{s',s '' } + \\beta g(s'',s ' ) , & { \\rm for } \\ ; s'\\ne s \\\\ 1 , & { \\rm for } \\ ; s ' = s. \\\\ \\end{array } \\right .",
    "\\label{eq : sp_lambda}\\end{aligned}\\ ] ] the terms @xmath122 and @xmath123 denote the @xmath124th element of the vector @xmath125 and @xmath126,respectively . equations ( [ eq : sp_m])-([eq : sp_lambda ] ) entirely describe the dynamics of the system . in the limit where @xmath127 , the term @xmath123 in ( [ eq : final_local_field ] ) can be regarded as a self - interaction and corresponds to the onsager reaction term in equilibrium statistical mechanics .",
    "therefore , in this paper , we call this term the onsager reaction term .",
    "in order to validate the results obtained above , we performed numerical experiments in an @xmath128 system .",
    "figure [ fig : beta=05 ] shows the first few stages of the detection dynamics obtained from 100 experiments for the cases @xmath129 7.0 , 9.0 [ db ] , predicted by generating functional analysis ( gfa ) and density evolution ( de ) @xcite , where @xmath130 [ db ] denotes @xmath131 ( see appendix [ app : de ] ) .",
    "the system load is @xmath132 , where @xmath133 is the critical system load defined as the minimum system load at which the dynamics fail to convergence .",
    "figure [ fig : beta=07 ] shows the first few stages of the detection dynamics obtained from 100 experiments for the cases @xmath129 5.5 , 7.5 [ db ] , predicted by gfa and de with the system load @xmath134 .",
    "oscillation of the detection dynamics was observed , when @xmath135 .",
    "in such a case , both gfa and de predicted the failure of convergence of the dynamics .",
    "however , the de results has residual deviations in figures [ fig : beta=05 ] and [ fig : beta=07 ] due to the lack of the onsager reaction term and the assumption that the local field follows a gaussian distribution . in particular",
    ", the deviation of the de predictions from the simulation results becomes large when @xmath135 .",
    "in contrast , gfa exhibits good consistency with the simulation results for any system load .",
    "the difference between de and gfa appears also in a signal term with respect to the information bit of the local field .",
    "the signal terms of de and gfa at stage @xmath19 represent @xmath136 and @xmath137 , respectively ( see appendix [ app : de ] ) .",
    "the signal term @xmath137 derived by gfa contains all response functions @xmath98 with @xmath138 . on the other hand",
    ", the signal term @xmath136 derived by de contains only the response functions of adjacent stages .",
    "this difference appears from stage @xmath139 .",
    "the signal term @xmath140 of gfa is , @xmath141 while the signal term @xmath142 of de is @xmath143 as you can easily see , the @xmath142 contains only @xmath144 and @xmath145 , which correspond to @xmath146 and @xmath147 of gfa respectively , while the @xmath140 has the response function between stage 1 and stage -1 as @xmath148 .     from 100 experiments for the cases @xmath129 7.0 [ db ] ( upper ) , 9.0 [ db ] ( lower ) .",
    "the system load is @xmath132 for both cases . ]     from 100 experiments for the cases @xmath129 5.5 [ db ] ( upper ) , 7.5 [ db ] ( lower ) .",
    "the system load is @xmath134 for both cases . ]",
    "we presented the generating functional analysis to describe the detection dynamics of pic for cdma multiuser detection .",
    "the predictions of de can qualitatively explain the detection dynamics only when the detection dynamics converge .",
    "furthermore , the deviation of the predictions of de from the results of numerical experiments becomes large when the detection dynamics fail to convergence .",
    "in contrast , the predictions of gfa are in good agreement with computer simulation result of pic for any system load and channel noise level , even if the dynamics fail to converge .    * acknowledgement *    this work was partially supported by a grant - in - aid for scientific research on priority areas no .",
    "14084212 , and for scientific research ( c ) no .",
    "16500093 from the ministry of education , culture , sports , science and technology of japan .",
    "density evolution is a useful tool to analyze nonlinear dynamics @xcite . by means of density evolution ,",
    "the bit error rate @xmath33 of hard decisions @xmath149 $ ] at the @xmath19th stage is given by @xmath150 where @xmath151 are to be evaluated by the following recursive formulas for @xmath136 , @xmath152 , @xmath151 , @xmath153 and @xmath154 : @xmath155 where @xmath156 .",
    "the initializations are @xmath157 , @xmath158 , @xmath159 , @xmath160 , @xmath161 , and @xmath162 .",
    "the physical meaning of the parameters @xmath136 , @xmath152 , @xmath151 , @xmath153 and @xmath154 is @xmath163 , \\\\",
    "c_{t,\\tau}&=&{\\rm cov } [ u_k(t),u_k(\\tau ) ] , \\\\",
    "m_{t+1}&=&\\frac1k\\sum_{k=1}^k{\\,{\\rm sgn}\\,}[u_k(t ) ] , \\\\ u_{t+1}&=&\\frac1k\\sum_{k=1}^k{\\,{\\rm sgn}\\,}'[u_k(t ) ] , \\\\",
    "q_{t+1,\\tau+1}&=&\\frac1k\\sum_{k=1}^k{\\,{\\rm sgn}\\,}[u_k(t)]{\\,{\\rm sgn}\\,}[u_k(\\tau ) ] . \\end{aligned}\\ ] ] the detailed derivation is available in the appendix of the paper @xcite . in the derivation by means of density evolution",
    ", it is assumed that the local field @xmath164 follows the gaussian distribution with mean @xmath136 and covariance @xmath152 .",
    "furthermore , the onsager reaction term is ignored .",
    "the signal term @xmath136 contains only the response functions of adjacent stages ."
  ],
  "abstract_text": [
    "<S> we investigate the detection dynamics of the parallel interference canceller ( pic ) for code - division multiple - access ( cdma ) multiuser detection , applied to a randomly spread , fully syncronous base - band uncoded cdma channel model with additive white gaussian noise ( awgn ) under perfect power control in the large - system limit . </S>",
    "<S> it is known that the predictions of the density evolution ( de ) can fairly explain the detection dynamics only in the case where the detection dynamics converge . at transients , </S>",
    "<S> though , the predictions of de systematically deviate from computer simulation results . furthermore </S>",
    "<S> , when the detection dynamics fail to convergence , the deviation of the predictions of de from the results of numerical experiments becomes large . as an alternative , generating functional analysis ( gfa ) can take into account the effect of the onsager reaction term exactly and does not need the gaussian assumption of the local field . </S>",
    "<S> we present gfa to evaluate the detection dynamics of pic for cdma multiuser detection . </S>",
    "<S> the predictions of gfa exhibits good consistency with the computer simulation result for any condition , even if the dynamics fail to converge . </S>"
  ]
}