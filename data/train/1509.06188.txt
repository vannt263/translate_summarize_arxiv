{
  "article_text": [
    "the group testing problem was introduced by dorfman @xcite in the 1940s , and captures the idea of efficiently isolating a small subset @xmath0 of defective items in a larger set containing @xmath1 items .",
    "the models used vary slightly , but the fundamental setting is that we perform a sequence of tests , each defined by a testing pool of items .",
    "the outcome of the test depends on the number of defective items in the pool .",
    "the most basic model , which we refer to as ` standard noiseless group testing ' is that the test outcome equals 1 if and only if the testing pool contains at least one defective item .",
    "given @xmath2 tests , the group testing problem requires us to design test pools and estimation algorithms to maximise @xmath3 , the success probability ( probability of recovering the defective set exactly ) .",
    "this paper focuses on converse results , giving upper bounds on the @xmath3 that can be achieved by any algorithm given @xmath2 tests .",
    "we generalize the following strong result proved by baldassini , johnson and aldridge ( * ? ? ?",
    "* theorem 3.1 ) :    [ thm : bja ] suppose the defective set @xmath0 is chosen uniformly from the @xmath4 possible sets of given size @xmath5 . for adaptive or non - adaptive standard noiseless group testing :",
    "we extend this result to a variety of settings .",
    "we first discuss four dichotomies in the modelling of the group testing problem ; ( i ) combinatorial vs probabilistic",
    "( ii ) binary vs non - binary ( iii ) noisy vs noiseless ( iv ) adaptive vs non - adaptive .",
    "there are a number of further variations beyond these , as described in an ever - increasing body of literature .    1 .    * [ combinatorial vs probabilistic ] * the first categorisation concerns the way the defective items are chosen .",
    "combinatorial group testing ( see for example @xcite ) is the model from theorem [ thm : bja ] : we suppose there is a fixed number @xmath5 of defective items , and the defective set @xmath0 is chosen uniformly from the @xmath4 possible sets of this size . in probabilistic group testing ( see for example @xcite ) the @xmath7th item is defective independently with probability @xmath8 ( with @xmath8 not necessarily identical ) .",
    "in fact , we put both these models in a common setting : + we write @xmath9 for the ( random ) defectivity vector , where component @xmath10 is the indicator of the event that the @xmath7th item is defective . for any vector @xmath11 write @xmath12 , and define entropy @xmath13 + for the two models as described above : 1 .   for combinatorial group testing , since @xmath14 is uniform over @xmath4 outcomes , the entropy @xmath15 .",
    "2 .   for probabilistic group testing , the entropy @xmath16 , where @xmath17 is the binary entropy function .",
    "if @xmath18 then @xmath19 .",
    "+ however , corollary [ cor : inforate ] below shows that results resembling theorem [ thm : bja ] can be proved for general sources satisfying the shannon - mcmillan - breiman theorem .",
    "this includes settings where the defectivity vector is generated by a stationary ergodic markov chain , which is a natural model of a setting where nearest neighbours are susceptible to infection .",
    "[ binary vs non - binary ] * the second variation comes in terms of the set of outcomes @xmath20 that each test can produce .",
    "we refer to @xmath20 as the alphabet , since in this paper ( as in @xcite and other papers ) we consider an analogy between group testing and the channel coding problem .",
    "it is most standard to consider the binary case , where @xmath21 , though other models are possible ( see for example ( * ? ? ?",
    "* section 6.3 ) for a detailed review ) . for brevity",
    "we will only consider the binary case in this paper ( though our techniques will be valid in a more general setting ) .",
    "we write @xmath22 for the outcome of the group testing process .",
    "[ noisy vs noiseless ] * the third difference concerns the way in which the outcome of each test is formed . to fix notation",
    ", we perform a sequence of @xmath2 tests defined by test pools @xmath23 , where each @xmath24 .",
    "we represent this by a binary test matrix @xmath25 , where @xmath26 if and only if item @xmath7 is included in the @xmath27th pool ( a concatenation of column vectors given by the indicator functions of the @xmath2 test pools ) .",
    "since the test design may be random , we write @xmath28 for a random variable giving a test matrix of this form .",
    "+ for a test matrix @xmath28 and defectivity vector @xmath29 , a key object of interest is the vector @xmath30 . here",
    ", the @xmath27th component of @xmath31 is @xmath32 , the total number of defective items appearing in the @xmath27th test . observe that @xmath33 is a deterministic function of @xmath29 and @xmath34 ( and does not depend on any other variables ) .",
    "it is useful to define @xmath35 via @xmath36 . + we assume that the group testing model is static , memoryless and satisfies the ` only defects matter ' property introduced by aldridge @xcite : + [ def : odm ] we assume that the @xmath27th test outcome @xmath37 is a random function of @xmath33 ( so @xmath38 is conditionally independent of @xmath14 given @xmath31 , and @xmath37 is conditionally independent of @xmath39 given @xmath33 ) .",
    "further , for some fixed transition matrix @xmath40 , we assume @xmath41 + note that definition [ def : odm ] includes the noiseless standard group testing case , where we simply take @xmath42 . to understand definition [ def : odm ] , we can consider the case where @xmath35 is fed ( symbol by symbol ) through a memoryless noisy channel , independent of the defectivity vector @xmath14 , and any randomness in the group testing design . in the notation of",
    ", we assume that @xmath43 for all @xmath44 ; in the noiseless case we take @xmath45 and @xmath46 .",
    "however , definition [ def : odm ] allows a wider range of noise models , including the dilution channel of atia and saligrama @xcite , where we take @xmath47 for some @xmath48 .",
    "+ for a fixed test matrix @xmath49 , as in @xcite , in the noiseless case the testing procedure naturally defines a mapping @xmath50 .",
    "that is , given defectivity vector @xmath51 , we write the vector function @xmath52 with components given by scalar function @xmath53 , in the form @xmath54 where @xmath55 .",
    "[ adaptive vs non - adaptive ] * the final distinction is whether we design the test matrix using an adaptive or a non - adaptive strategy . in the non - adaptive case the entire test matrix @xmath49 needs to be chosen in advance of the tests .",
    "in contrast , in the adaptive case , the @xmath56st test pool @xmath57 is chosen based on a knowledge of previous test pools @xmath58 and test outcomes @xmath59 .",
    "we can think ( see @xcite ) that adaptive group testing corresponds to channel coding with feedback , and non - adaptive group testing to coding with no feedback . clearly ( see @xcite )",
    ", we can do no worse in the adaptive setting than for non - adaptive group testing , but it remains an open and interesting question to determine precisely by how much adaptivity can improve performance .",
    "+ we argue that a key tool in understanding adaptive group testing is directed information theory .",
    "this was first introduced by marko @xcite in the 1970s , with interest revived by the work of massey @xcite in the 1990s , and developed further by authors such as kramer @xcite and schreiber @xcite . in particular , as described by massey @xcite , many authors make an incorrect probabilistic formulation of such simple objects as discrete memoryless channels with feedback .",
    "a correct formulation requires the use of the causal conditional probability distribution as studied for example by kramer @xcite .",
    "we use the notation of the review paper ( * ? ? ?",
    "* equation ( 7 ) ) , that for sequences @xmath60 and @xmath61 , and subsequences @xmath62 , @xmath63 note that for any fixed @xmath64 , the fact that it is formed as a product of probability distributions means that @xmath65 . using this probability distribution implies the form of the directed information of marko @xcite ( see also the later definition of transfer entropy by schreiber @xcite ) .",
    "+ in lemma [ lem : jointprob ] below , assuming the only defects matter property definition [ def : odm ] , we decompose the joint probability of @xmath66 in the general adaptive setting , using the term @xmath67 , which is defined in . here",
    "we use the causal conditional probability notation above , with superscript @xmath68 referring to the fact that there is a lag in the index of @xmath64 in compared with ( we choose the set @xmath69 based on a knowledge of the previous sets @xmath70 and test outcomes @xmath71 ) . + the decomposition in lemma [ lem : jointprob ] shows that the @xmath27th output symbol @xmath37 is conditionally independent of @xmath14 , given values @xmath72 and previous outputs @xmath73 .",
    "this is precisely the definition of a causal system between @xmath31 and @xmath38 given by massey in ( * ? ? ?",
    "* equation ( 8) ) , under which condition the capacity of a discrete memoryless channel is not increased by feedback .",
    "regardless of these variations , we always make an estimate @xmath74 , based only on a knowledge of outputs @xmath75 and test matrix @xmath49 , using a probabilistic estimator ( decoder ) that gives @xmath76 with probability @xmath77    the main results of the paper are theorem [ thm : ppvmain ] , which gives an upper bound on @xmath3 in the non - adaptive case , and proposition [ prop : basic ] , which gives the corresponding result in the adaptive case . the strength of these results is illustrated in results such as examples [ ex : bsc ] and [ ex : adaptivenoisy ] , where we calculate bounds on the success probability in the case where @xmath35 forms the input and @xmath38 the output of a binary symmetric channel with error probability @xmath78 .",
    "we illustrate these bounds in figure [ fig : bscadaptive ] , where the upper bounds on @xmath3 in both adaptive and non - adaptive cases are plotted in the finite blocklength case of combinatorial group testing with @xmath79 , @xmath80 , @xmath81 .",
    "the structure of the paper is as follows . in section [ sec : existing ] we review existing results concerning group testing converses . in section [ sec : hyptest ] we use an argument based on the paper by polyanskiy , poor and verd @xcite to prove theorem [ thm : ppvmain ] , giving a strong converse for non - adaptive group testing , and discuss the bounds for the binary symmetric channel case . in section",
    "[ sec : adaptive ] we discuss the adaptive case , by extending arguments first given for channels with feedback by kemperman @xcite , kesten @xcite and wolfowitz @xcite ( see also gallager @xcite ) .",
    "we prove a bound ( proposition [ prop : basic ] ) which specializes in the noiseless case to give a result ( theorem [ thm : noiseless ] ) which generalizes theorem [ thm : bja ] .",
    "we consider examples of this noiseless result in the probabilistic case in section [ sec : noiselessexamples ] .",
    "finally in section [ sec : adaptivenoisy ] we apply proposition [ prop : basic ] in the noisy adaptive case .",
    "the proofs of the main theorems are given in appendices .",
    "while this paper only considers group testing , we remark that this problem lies in the area of sparse inference , which includes problems such as compressed sensing and matrix completion , and it is likely that results proved here will extend to more general settings .",
    "the paper @xcite gives a review of links between group testing and other sparse inference problems .",
    "group testing itself has a number of applications , including cognitive radios @xcite , network tomography @xcite and efficient gene sequencing @xcite .",
    "the bounds proved here should provide fundamental performance limits in these contexts .",
    "it is clear from information - theoretic considerations that to find all the defectives in the noiseless case will require at least @xmath82 ( the `` magic number '' ) tests . in the language of channel coding ,",
    "the focus of this paper is on converse results ; that is given @xmath83 tests , we give strong upper bounds on the success probability @xmath3 of any possible algorithm .",
    "there has been considerable work on the achievability part of the problem , in developing group testing algorithms and proving performance guarantees .",
    "early work on group testing considered algorithms which could be proved to be order optimal ( see for example the analysis of @xcite ) , often using combinatorial properties such as separability or disjunctness .",
    "more recently there has been interest ( see for example @xcite ) in finding the best possible constant , that is to find algorithms which succeed with high probability using @xmath84 tests , for @xmath85 as small as possible . in this context",
    ", the paper @xcite defined the capacity of combinatorial group testing problems , a definition extended to both combinatorial and probabilistic group testing in @xcite .",
    "we state this definition for both weak and strong capacity in the sense of wolfowitz :    [ def : capacity ] consider a sequence of group testing problems where the @xmath7th problem has defectivity vector @xmath86 , and consider algorithms which are given @xmath87 tests .",
    "we think of @xmath88 ( the number of bits of information learned per test ) as the rate of the algorithm and refer to a constant @xmath89 as the weak group testing capacity if for any @xmath90 :    1 .",
    "any sequence of algorithms with @xmath91 has success probability @xmath3 bounded away from 1 , 2 .",
    "and there exists a sequence of algorithms with @xmath92 with success probability @xmath93 .",
    "we call @xmath89 the strong capacity if @xmath94 for any sequence of algorithms satisfying .    for example , in @xcite we prove that noiseless adaptive combinatorial group testing has strong capacity 1 .",
    "this result is proved by combining hwang s generalized binary splitting algorithm @xcite ( which is essentially optimal  see also @xcite for a discussion of this ) with the converse result theorem [ thm : bja ] . however , even in the noiseless non - adaptive case the optimal algorithm remains unclear , although some results are known in some regimes , under assumptions about the distribution of @xmath28 ( see for example @xcite ) .    in general , capacity results",
    "are asymptotic in character , whereas we will consider the finite blocklength regime ( in the spirit of @xcite ) and prove bounds on @xmath3 for any size of problem .",
    "we briefly review existing converse results .",
    "first , we mention that results ( often referred to as folklore ) can be proved using arguments based on fano s inequality .    using @xmath2 tests :    1 .   for combinatorial group testing chan et al .",
    "* theorem 1 ) give @xmath95 2 .",
    "for probabilistic group testing",
    "* theorem 1 ) give @xmath96    in order to understand the relationship between and theorem [ thm : bja ] ; fix @xmath97 and use @xmath98 tests , in a regime where @xmath99 and hence @xmath100 .",
    "chan et al.s result gives that @xmath101 , whereas implies @xmath102 . in the language of definition [ def : capacity ] , chan et al .",
    "@xcite give a weak converse whereas baldassini , johnson and aldridge @xcite give a strong converse .",
    "in fact , shows that the success probability converges to zero exponentially fast .    to understand why chan et",
    "al s result is not as strong as theorem [ thm : bja ] , we examine the proof in @xcite . at the heart of it",
    "lies an argument based on fano s inequality , bounding the entropy @xmath103 using the decomposition @xmath104 where @xmath105 is the indicator of the error event @xmath106 . in @xcite this last term is bounded by @xmath107 , since a priori @xmath14 could be any defective set other than @xmath108 .",
    "however , in practice , this is a significant overestimate .",
    "for example , in the noiseless case there is a relatively small collection of defective sets that a particular defective set @xmath14 can mistakenly be estimated as ( referred to as @xmath109 later in this paper ) . in this case , using inferences such as those in the ` dd ` algorithm of @xcite , any item which appears in a test pool @xmath110 giving result @xmath111 can not be defective .",
    "essentially , theorem [ thm : bja ] exploits this type of fact .",
    "however results corresponding to theorem [ thm : bja ] were not previously known even for noiseless probabilistic group testing , let alone more general settings , including noisy channels and other models for defectivity .",
    "tan and atia ( * ? ? ?",
    "* theorem 2 ) do prove a strong converse for combinatorial group testing , however , they do not achieve exponential decay . since the result of the test only depends on whether the items in the defective set @xmath0 are present , we can restrict our attention to the submatrix @xmath112 indexed by subsets @xmath113 .",
    "write @xmath114 and @xmath115 .",
    "if the components of @xmath28 are independent and identically distributed then for each @xmath116 , then @xmath2 ( the number of tests required to achieve the given probability of success ) satisfies : @xmath117    rearranging , and writing @xmath118 we obtain @xmath119 taking @xmath120 for @xmath121 .",
    "this gives a strong converse , though not the exponential decay achieved in above .",
    "however tan and atia s results @xcite are valid in a variety of settings and noise models .",
    "pedagogically , it is worth noting a parallel between these various approaches and treatments of the channel coding problem in the literature .",
    "that is , due to chan et al .",
    "@xcite , is proved using an argument based on fano s inequality , parallelling the proof of shannon s noisy coding theorem exemplified for example in ( * ? ? ?",
    "* section 8.9 ) .",
    "the argument of tan and atia @xcite is based on marton s blowing up lemma , mirroring the treatment of shannon s theorem in the book of csiszr and krner ( * ? ? ?",
    "* section 6 ) .",
    "our work in the non - adaptive case is based on the more recent work of polyanskiy , poor and verd @xcite , which has been adapted to the problem of data compression in @xcite .",
    "the paper @xcite , written by the same authors as @xcite , extends their approach to channels with feedback , which corresponds to the adaptive case of group testing .",
    "we prefer to give bounds based on older works of gallager @xcite , kemperman @xcite , kesten @xcite and wolfowitz @xcite .",
    "note that in the non - adaptive case , as described in ( * ? ? ?",
    "* section iii.g ) , the results of polyanskiy et al .",
    "are stronger than the results of wolfowitz @xcite and gallager @xcite type .",
    "however , in the adaptive case , these earlier results appear easier to modify in the group testing context .",
    "we first state a result , theorem [ thm : ppvmain ] , which implies strong converse results that generalize theorem [ thm : bja ] in the non - adaptive case .",
    "the key observation comes from polyanskiy , poor and verd @xcite who found a relationship between channel coding and hypothesis testing . since the neyman - pearson lemma gives us the optimal hypothesis test , the paper @xcite deduces strong bounds on coding error probabilities .",
    "write @xmath122 for the smallest possible type ii error for hypothesis tests ( with type i error probability @xmath123 ) deciding between @xmath40 and @xmath124 .",
    "our contribution in this section is to use this same analogy for the group testing problem , given a process generating random chosen defective sets @xmath14 ( a source ) .",
    "to some extent this is simply a question of adapting the notation of @xcite .",
    "however , one generalization which is important for us is that we do not require that @xmath14 is uniform ( allowing us to consider probabilistic as well as combinatorial group testing ) .",
    "this was not considered in @xcite , largely because for channel coding it seems less natural to consider non - uniform @xmath14 .",
    "since we consider non - adaptive group testing , we fix @xmath49 in advance .",
    "we write @xmath125 for the joint probability distribution of @xmath31 and @xmath38 and consider an algorithm which estimates ( decodes ) the defective set @xmath74 , using only outputs @xmath38 and test matrix @xmath49 . since @xmath49 is fixed , we simplify the notation of above and write @xmath126 for the probability that the estimator gives @xmath76 when @xmath75 .",
    "we prove the following key result :    [ thm : ppvmain ] suppose that the group testing model satisfies the only defects matter property , definition [ def : odm ] . for any non - adaptive choice of test design , any estimation rule @xmath127 and probability mass function @xmath128 : @xmath129 where @xmath130 is the probability that @xmath131 is decoded to @xmath108 and @xmath132 .",
    "see appendix [ sec : proofppvmain ] .    in the noiseless non - adaptive case",
    "consider any defective set distribution @xmath133 .",
    "taking @xmath134 , the optimal rule is to accept @xmath135 with probability @xmath136 if @xmath137 , and to reject @xmath135 otherwise ( this corresponds to taking @xmath138 and @xmath139 in example [ ex : bsc ] above ) .",
    "we obtain by theorem [ thm : ppvmain ] that @xmath140    1 .   *",
    "[ uniform case ] * in particular , if the @xmath141 for some set @xmath142 of size @xmath143 , the rhs of becomes @xmath144 , this means that ( exactly as in ( * ? ? ? * theorem 27 ) ) : @xmath145 we deduce from theorem [ thm : ppvmain ] that @xmath146 confirming theorem [ thm : bja ] ( under the additional assumption of non - adaptivitity ; we discuss how to remove this assumption in theorem [ thm : noiseless ] below ) .",
    "2 .   [ ex : noiseless ] * [ general case ] * in general , in the noiseless non - adaptive case , we write @xmath147 for the sum of the largest @xmath148 values of @xmath149 . for each defective set @xmath14",
    ", we write @xmath150 . for a particular @xmath64 , we write @xmath151 for the defective sets that get mapped to @xmath64 by the testing procedure .",
    "we write @xmath152 for the maximum probability in @xmath153 and @xmath154 for the collection of defective sets achieving this probability . for each @xmath155 , pick a string @xmath156 in any arbitrary fashion ; and note that there are up to @xmath157 strings @xmath158 , which are distinct , since they each map to a different value under @xmath53 .",
    "these various definitions are illustrated in figure [ fig : setfigure ] .",
    "+ in general using we deduce that @xmath159 here follows since for given @xmath64 the success probability is maximised by restricting to @xmath126 supported on the set @xmath160 , so we know that @xmath161 .",
    "follows since there are at most @xmath157 separate messages @xmath162 , so at most @xmath157 distinct values @xmath158 .",
    "this result generalizes .",
    "note that ( as expected ) the success probability is maximised by the maximum likelihood decoder @xmath127 which places all its support on members of @xmath163 . in theorem",
    "[ thm : noiseless ] below we extend the result to hold even in the adaptive case , extending theorem [ thm : bja ] .",
    "theorem [ thm : ppvmain ] gives a converse for the non - adaptive binary symmetric channel case :    [ ex : bsc ] suppose the output of standard combinatorial noiseless non - adaptive group testing @xmath35 is fed through a memoryless binary symmetric channel with error probability @xmath164 to produce @xmath38 .",
    "we write @xmath165 , and observe that @xmath166 , where @xmath167 represents the hamming distance . hence if @xmath134 , the likelihood ratio is @xmath168 by the neyman - pearson lemma , the optimal rule is to accept @xmath135 if @xmath169 , to accept @xmath135 with probability @xmath170 if @xmath171 and to reject @xmath135 otherwise . in calculations which are essentially the same as in (",
    "* theorem 35 ) , we can find @xmath172 and @xmath170 using : @xmath173 then , for this value of @xmath172 we write that @xmath174 in figure [ fig : bscnonadaptive ] , we plot this in the case @xmath79 , @xmath175 , @xmath81 , and for comparison plot the fano bound taken from ( * ? ? ?",
    "* theorem 2 ) : @xmath176 in figure [ fig : bscnonadaptiverates ] we give the group testing analogue of ( * ? ? ? * figure 1 ) .",
    "we use the regime of @xcite ; that is , we vary @xmath1 and take @xmath177 , where @xmath178 ( this gives the value @xmath175 for @xmath79 ) . again taking @xmath81 , we fix @xmath179 , and use the lower bound on @xmath2 corresponding to the analysis above .",
    "this gives an upper bound on the rate @xmath180 , which we plot in figure [ fig : bscnonadaptiverates ] .",
    "note that in this finite size regime , exactly as in ( * ? ? ?",
    "* figure 1 ) , the resulting rate bound is significantly smaller than the capacity @xmath181 , which we only approach asymptotically .     and",
    "@xmath175 , where the output @xmath35 of standard noiseless group testing is fed into a memoryless binary symmetric channel with @xmath81 .",
    "we vary the number of tests @xmath2 between 70 and 165 , and plot the success probability on the @xmath182 axis .",
    "we plot the upper bound on @xmath3 given by example [ ex : bsc ] using @xmath183 . for comparison , we plot the ( weaker ) fano bound taken from @xcite as @xmath184 .",
    "[ fig : bscnonadaptive],width=377 ]     and @xmath185 , where the output @xmath35 of standard noiseless group testing is fed into a memoryless binary symmetric channel with @xmath81 . in each case",
    "we choose @xmath2 large enough such that the success probability @xmath179 .",
    "we plot the upper bound on the rate given by example [ ex : bsc ] , and observe that this is significantly lower than the value of the capacity @xmath186 in this finite blocklength regime .",
    "[ fig : bscnonadaptiverates],width=377 ]",
    "we now consider adaptive group testing , and give a result ( proposition [ prop : basic ] ) which implies a strong converse , assuming that a concentration inequality is satisfied . for any @xmath27",
    ", we write @xmath187 and @xmath188 . we first prove the following representation result for the joint probability distribution of @xmath189 under the model of adaptivity :    [ lem : jointprob ] assuming the only defects matter property ( definition [ def : odm ] ) with transition matrix @xmath190 for all @xmath191 , we can write @xmath192 where @xmath193 is the number of defectives in the @xmath27th test and @xmath194 is the causal conditional probability , with the key property that for any fixed @xmath64 : @xmath195    we write ( omitting the subscripts on @xmath196 for brevity ) a collapsing product of the form : @xmath197 where we remove the conditioning from the terms in since @xmath198 is the result of sending @xmath199 through a memoryless channel ( the output of which is independent of previous test designs and their output ) and since the choice of the @xmath27th test pool @xmath110 is conditionally independent of @xmath14 , given the previous tests and their output .",
    "next we adapt arguments given by wolfowitz @xcite which give strong converses for symmetric channels ( even with feedback ) .",
    "wolfowitz s book @xcite reviews earlier work of his @xcite , and results of kemperman @xcite and kesten @xcite .",
    "wolfowitz @xcite and kemperman @xcite use chebyshev s inequality to bound tail probabilities ; the fact that stronger results than chebyshev could be used for the case without feedback was stated as ( * ? ? ?",
    "* exercise 5.35 ) .",
    "note the similarity of proposition [ prop : basic ] to ( * ? ? ?",
    "* theorem 5.8.5 ) , a result originally due to wolfowitz and discussed for example as ( * ? ? ? * theorem 10 ) .",
    "[ def : typset ] fix a probability mass function @xmath128 on @xmath200 . define the typical set @xmath201 by @xmath202 ( note that this set can be expressed in terms of the information density @xmath203 of @xcite ) .",
    "write @xmath204 for the probability that some algorithm estimates the defective set as @xmath205 when the group testing process with test matrix @xmath49 returns @xmath206 .",
    "[ prop : basic ] take any probability mass function @xmath128 on @xmath200 .",
    "for any model of group testing ( adaptive or non - adaptive ) , the success probability satisfies @xmath207 where we write @xmath208 .    see section [ sec : proofbasic ] .",
    "note that by , we know that @xmath209 is a probability mass function since : @xmath210 we use proposition [ prop : basic ] to prove a result which extends theorem [ thm : bja ] for general defective set distributions @xmath133 in the noiseless binary case .",
    "this result applies to both adaptive and non - adaptive group testing .",
    "[ thm : noiseless ] for noiseless adaptive binary group testing , if we write @xmath147 for the sum of the largest @xmath148 values of @xmath149 then @xmath211    see section [ sec : proofnoiseless ] .    for combinatorial group testing",
    ", since @xmath133 is uniform on a set of size @xmath4 , theorem [ thm : noiseless ] implies that @xmath212 and we recover theorem [ thm : bja ] .",
    "we show how sharp this result is in figure [ fig : bja ] , which is reproduced from ( * ? ? ?",
    "* figure 1 ) .     and @xmath213 ( these numbers are chosen to match the regime @xmath214 , as in figure [ fig : bscnonadaptiverates ] ) . the upper bound on success probability of theorem [ thm : bja ] is plotted in red , and the upper bound ( from ( * ? ? ?",
    "* equation ( 6 ) ) ) in blue .",
    "the dotted vertical line is at @xmath107 ( the magic number ) . to illustrate how sharp theorem [ thm : bja ] is , we compare this with simulated ( empirical ) results of practical algorithms .",
    "the empirical success probability of the hgbsa of hwang @xcite is plotted as a bright green line , and the related algorithm analysed in ( * ? ? ?",
    "* section iv ) is plotted in dark green .",
    "[ fig : bja],width=453 ]    [ cor : inforate ] consider a sequence @xmath86 of defectivity vectors of length @xmath7 , generated as independent realisations of a stationary ergodic stochastic process of entropy rate @xmath215 .",
    "given @xmath216 tests to solve the @xmath7th noiseless adaptive group testing problem , the success probability tends to zero .",
    "( hence the strong capacity can not be more than 1 ) .",
    "we define the typical set @xmath217 by the shannon - mcmillan - breiman theorem ( aep ) ( see for example ( * ? ? ?",
    "* theorem 15.7.1 ) ) , the probability @xmath218 .",
    "then , in theorem [ thm : noiseless ] , the @xmath219 strings of largest probability will certainly be contained in a list containing the elements of @xmath220 and the @xmath219 strings of largest probability in @xmath221 . since",
    ", by definition , any string in @xmath221 has probability less than @xmath222 , we deduce that @xmath223 given a quantitative form of the shannon - mcmillan - breiman theorem ( proved for example using the concentration inequalities described in @xcite ) , we can deduce an explicit ( exponential ) rate of convergence to zero of @xmath3 .",
    "we give more explicit bounds which show how theorem [ thm : noiseless ] can be applied in the noiseless probabilistic case in section [ sec : noiselessexamples ] below .",
    "section [ sec : adaptivenoisy ] contains an illustrative example of results that can be proved using proposition [ prop : basic ] , in the noisy adaptive case where @xmath14 is uniformly distributed on a set @xmath142 of size @xmath224 and there is a binary symmetric channel with error probability @xmath78 between @xmath35 and @xmath38 .",
    "baldassini s thesis @xcite developed and analysed algorithms in the noisy adaptive case .",
    "however , it remains an open problem to find capacity - achieving algorithms , even for examples such as the binary symmetric channel .",
    "in this section , we give examples of bounds which can be proved using theorem [ thm : noiseless ] for noiseless adaptive probabilistic group testing .",
    "note the similarity between the calculations in examples [ ex : bsc ] and [ ex : idprob ] ; in the former case we control concentration of channel probabilities , in the latter we control source probabilities ( see also ( * ? ? ?",
    "* theorem 35 ) ) .",
    "note that the control of the source strings with highest probabilities is an operation that lies at the analysis of the finite blocklength data compression problem in @xcite .",
    "[ ex : idprob ] we consider the identical probabilistic case , where @xmath225 , so @xmath226 , where @xmath227 is the hamming weight of @xmath108 .",
    "write @xmath228 and define @xmath229 via @xmath230 meaning the @xmath157 highest probability defective sets are all of those of weight @xmath231 , plus @xmath232 of weight @xmath233 .",
    "we evaluate @xmath234 in this case to obtain a bound which we plot in figure [ fig : bernoulli ] : @xmath235    , @xmath236 .",
    "we vary the number of tests @xmath2 between 0 and 100 , and plot the success probability on the @xmath182 axis .",
    "we plot the upper bound on @xmath3 given by using @xmath183 . for comparison ,",
    "we plot the ( weaker ) fano bound of @xcite as @xmath184 .",
    "the approximation is plotted as @xmath237 .",
    "[ fig : bernoulli],width=453 ]    we give a gaussian approximation to the bound , in the spirit of @xcite .",
    "since we need to control tail probabilities we use the approximation given by chernoff bounds ( see theorem [ thm : chernoff ] ) .",
    "in particular , if we take @xmath238 and @xmath239 then gives that @xmath240 giving an approximate solution to as required .",
    "substituting in we obtain @xmath241 using a second normal approximation .",
    "for example , if @xmath242 then @xmath243 ( the magic number ) and @xmath244 , and @xmath245 .    indeed using the chernoff",
    "bound , we use to deduce a strong capacity result :    noiseless binary probabilistic group testing has strong capacity @xmath246 in any regime where @xmath247 and @xmath248 .    for any @xmath249 and @xmath90",
    ", we consider the asymptotic regime where @xmath250 as @xmath251 .",
    "choosing @xmath252 , we know that using standard bounds ( see for example ( * ? ? ?",
    "* equation ( 12.40 ) ) ) @xmath253 which is larger than @xmath157 in the asymptotic regime .",
    "hence , summing over the strings of weight @xmath254 will give at least the @xmath157 strings of highest probability , and we deduce by theorem [ thm : chernoff ] that @xmath255 which tends to zero exponentially fast .",
    "this complements the performance guarantee proved in @xcite , strengthening the result of ( * ? ? ?",
    "* corollary 1.5 ) where the corresponding weak capacity result was stated using .      in the case of probabilistic group testing , for non - identical @xmath8 ,",
    "the analysis is more complicated , and the form of the tightest bounds depends on the distribution of values of @xmath8 .",
    "we assume that @xmath256 and write @xmath257 . for a given value of @xmath85",
    ", we write @xmath258 for the collection of defective sets with probability @xmath259 .",
    "that is @xmath260 the key idea is to find a value @xmath85 , such that we can guarantee that @xmath261 ( we discuss how to do this in lemma [ lem : findc ] below ) .",
    "then , we use concentration inequalities to bound the total probability @xmath262 from above ( this is done in lemma [ lem : tailbound ] ) .",
    "then by construction we know that @xmath263 , and we deduce an upper bound on the success probability , stated in theorem [ thm : final ] .",
    "the details are given in section [ sec : prooffinal ] .",
    "[ thm : final ] non - identical probabilistic group testing has success probability bounded by @xmath264 where @xmath265 and we write @xmath266    see section [ sec : prooffinal ] .",
    "we now use proposition [ prop : basic ] to prove a bound on @xmath3 in a noisy example . for simplicity we state the following example in the case of uniform @xmath14 .",
    "further generalizations ( in the spirit of theorem [ thm : noiseless ] ) are possible by adapting the proofs along the lines of section [ sec : proofnoiseless ] .",
    "[ ex : adaptivenoisy ] suppose @xmath14 is uniformly distributed on a set @xmath142 of size @xmath224 . and the noise channel between @xmath35 and @xmath38 forms a binary symmetric channel . recall that states that @xmath267 we write @xmath268 for the shannon capacity of the binary symmetric channel , and take @xmath269 . by , since @xmath270 the first term of becomes @xmath271 . since @xmath272 , and the channel matrix @xmath273 is constant for values of @xmath44 , it collapses down to a channel matrix from @xmath274 to @xmath182 .",
    "further , taking @xmath134 , for @xmath164 , the event that @xmath275 we deduce results , both in the asymptotic ( capacity ) sense and the finite blocklength regime .    1 .",
    "consider a sequence of group testing problems , where the @xmath7th problem has @xmath86 uniformly distributed on a set @xmath276 of size @xmath277 , we can deduce that any sequence of algorithms using @xmath87 tests has @xmath278 has success probability @xmath94 , and hence strong capacity bounded above by @xmath89 .",
    "this follows by the considerations above , since tells us that becomes @xmath279 where @xmath280 , and we deduce ( exponential ) convergence to zero , using the chernoff bound theorem [ thm : chernoff ] below . 2 .   for any @xmath172",
    ", we can consider the set @xmath281 which ( by ) corresponds to taking @xmath282",
    ". then becomes @xmath283 . \\;\\;\\;\\ ;   \\label{eq : toplotbscadap}\\end{aligned}\\ ] ] we illustrate this bound in figure [ fig : bscadaptive ] , where we compare it with the bounds derived in the adaptive case in example [ ex : bsc ] .     and @xmath175 , where the output @xmath35 of standard noiseless group testing is fed into a memoryless binary symmetric channel with @xmath81 .",
    "we vary the number of tests @xmath2 between 70 and 165 , and plot the success probability on the @xmath182 axis .",
    "we plot the bound ( from example [ ex : adaptivenoisy ] ) on the success probability for adaptive algorithms as @xmath284 . since this is exactly the same scenario as figure [ fig : bscnonadaptive ] , we add the points from that figure for comparison .",
    "that is , we plot the upper bound on @xmath3 for non - adaptive algorithms given by example [ ex : bsc ] using @xmath183 , showing a small adaptivity gap between upper bounds .",
    "again , we plot the ( weaker ) fano bound taken from @xcite as @xmath184 .",
    "[ fig : bscadaptive],width=377 ]",
    "we use an argument based on @xcite , adapted to the scenario where @xmath14 need not be uniform . consider a hypothesis testing problem where we are given a pair @xmath285 and asked to test the null hypothesis that it comes from joint distribution @xmath135 against an alternative of some other specific @xmath286 .",
    "this is a counterfactual exercise ; in group testing we do not know @xmath31 , however , it is helpful to imagine a separate user who is asked to make inference using this information , and uses the following hypothesis testing rule :    _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ given pair @xmath285",
    "send @xmath64 to the decoder to produce @xmath108 , and then accept @xmath135 with probability @xmath287 _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _    the key is to notice that @xmath288 form a markov chain , so for estimation algorithm @xmath127 we obtain @xmath289 using this , there is an equivalence betwen error probability and @xmath290 since @xmath291 { { \\mathbb i } } (   { { \\mathbf{w } } } = { { \\mathbf{z } } } ) \\nonumber \\\\ & = & \\sum_{{{\\mathbf{k}}},{{\\mathbf{y } } } }   { p_{{{\\mathbf{k}}}}\\left ( { { \\mathbf{k } } } \\right ) }    { p_{{{\\mathbf{y|k}}}}\\left ( { { \\mathbf{y|k } } } \\right ) }   \\sum_{{{\\mathbf{z}}},{{\\mathbf{w } } } } { { \\mathbb i } } (   { { \\mathbf{w } } } = { { \\mathbf{z } } } )    { p_{{{\\mathbf{z|y}}}}\\left ( { { \\mathbf{w|y } } } \\right ) } \\frac { { p_{{{\\mathbf{u}}}}\\left ( { { \\mathbf{z } } } \\right ) } { p_{{{\\mathbf{k|u}}}}\\left ( { { \\mathbf{k|z } } } \\right)}}{{p_{{{\\mathbf{k}}}}\\left ( { { \\mathbf{k } } } \\right ) } }   \\nonumber \\\\ & = & \\sum_{{{\\mathbf{k}}},{{\\mathbf{y } } } }   { p_{{{\\mathbf{ky}}}}\\left ( { { \\mathbf{k , y } } } \\right ) }     \\sum_{{{\\mathbf{z } } } }    { p_{{{\\mathbf{z|y}}}}\\left ( { { \\mathbf{z|y } } } \\right ) } \\frac { { p_{{{\\mathbf{u}}}}\\left ( { { \\mathbf{z } } } \\right ) } { p_{{{\\mathbf{k|u}}}}\\left ( { { \\mathbf{k|z } } } \\right)}}{{p_{{{\\mathbf{k}}}}\\left ( { { \\mathbf{k } } } \\right ) } } \\label{eq : todeal } \\\\ & = & \\sum_{{{\\mathbf{k}}},{{\\mathbf{y } } } }   { p_{{{\\mathbf{ky}}}}\\left ( { { \\mathbf{k , y } } } \\right ) }    \\sum_{{{\\mathbf{z } } } } { p_{{{\\mathbf{z|y}}}}\\left ( { { \\mathbf{z|y } } } \\right ) }   { p_{{{\\mathbf{u|k}}}}\\left ( { { \\mathbf{z|k } } } \\right ) }   \\nonumber \\\\ & = & \\sum_{{{\\mathbf{k}}},{{\\mathbf{y } } } }   { p_{{{\\mathbf{ky}}}}\\left ( { { \\mathbf{k , y } } } \\right ) }   { { \\mathbb p}}(\\mbox{accept $ { p_{{{\\mathbf{ky}}}}}$ given pair $ ( { { \\mathbf{k } } } , { { \\mathbf{y}}})$ } ) \\nonumber \\\\ & = & 1 - { { \\mathbb p } } ( \\mbox{\\;type i error\\ ; } ) \\nonumber\\end{aligned}\\ ] ] where we use the expression to deal with .",
    "we find the probability of a type ii error in the same way .",
    "we focus on the case where @xmath292 ( so @xmath31 and @xmath38 are independent under @xmath286 ) , where @xmath293 hence , since @xmath294 gives the minimum type ii error , we deduce the proposition .      in general , in the noiseless case , for each defective set @xmath14 , we write @xmath305 . for a particular @xmath75 and @xmath49 , we write @xmath306 for the defective sets that get mapped to @xmath64 by the testing procedure defined by @xmath298 .",
    "we write @xmath307 for the maximum probability in @xmath308 and @xmath309 for the collection of defective sets achieving this probability . for each @xmath64 , pick a string @xmath310 in any arbitrary fashion ; and note that there are up to @xmath157 strings @xmath311 , which are distinct , since they each map to a different value under @xmath312 .",
    "these definitions are illustrated in figure [ fig : setfigure ] .",
    "we use the bound from proposition [ prop : basic ] , taking @xmath313 and @xmath314 in , so that @xmath315 , which holds automatically . that is , the set @xmath316 is the empty set and so the second term in vanishes .",
    "we analyse the first term in repeating arguments from example [ ex : noiseless ] to obtain : @xmath317 here follows since for given @xmath64 the success probability is maximised by restricting to @xmath318 supported on the set @xmath319 , so we know that @xmath161 .",
    "follows using .",
    "follows since there are at most @xmath157 separate messages @xmath75 , so at most @xmath157 distinct values @xmath320 .",
    "note the striking fact that exactly matches .",
    "that is , although they are proved by very different methods , our best results in the noiseless adaptive and non - adaptive cases coincide .",
    "this may suggest that there is not an ` adaptivity gap ' ( in the language of @xcite ) in this case , though of course stronger converses may be possible .",
    "[ lem : findc ] for each @xmath321 with @xmath322 , we find a set @xmath258 with @xmath261 , and where @xmath323 we write @xmath324 .",
    "given @xmath321 , we take @xmath325 to be the set of items with the @xmath321 largest values of @xmath8 , and form defective sets using @xmath326 only . using equation ,",
    "we know that we can find at least @xmath157 defective sets by just using subsets of @xmath326 with weight @xmath327 .",
    "the smallest probability of such a set is given in equation .",
    "note that for @xmath328 , we need @xmath329 , and obtain @xmath330 . in the iid case , for @xmath331 , we take sets of weight @xmath233 and recover example [ ex : idprob ] above .",
    "[ lem : tailbound ] given @xmath85 , we can bound the probability @xmath332 where @xmath333 and @xmath224 are defined in .",
    "we apply bernstein s inequality ( see for example ( * ? ? ?",
    "* theorem 2.8 ) ) to the sum of zero mean random variables @xmath334 .",
    "we write @xmath295 for the event @xmath296 and consider @xmath297 we write @xmath29 , @xmath298 and @xmath64 as indices of summation for brevity , to refer to sums over @xmath51 , @xmath299 and @xmath300 .",
    "using the fact that for the estimation algorithm @xmath301 @xmath302 the first term of becomes : @xmath303 { p_{{{\\mathbf{u}}}}\\left ( { { \\mathbf{u } } } \\right ) } { p_{{\\mathsf{x } } \\| { { \\mathbf{y}}}^- } \\left ( { { \\mathcal{x } } } \\| { { \\mathbf{y}}}^- \\right)}{q_{{{\\mathbf{y}}}}\\left ( { { \\mathbf{y } } } \\right ) } \\\\ & = & \\exp(t \\beta ) \\sum_{{{\\mathbf{z } } } } { p_{{{\\mathbf{u}}}}\\left ( { { \\mathbf{z } } } \\right ) } \\sum _ { { { \\mathbf{y } } } , { { \\mathcal{x } } } }    { p_{{{\\mathbf{z|y,{\\mathsf{x}}}}}}\\left ( { { \\mathbf{z|y , { { \\mathcal{x } } } } } } \\right ) }   { p_{{\\mathsf{x } } \\| { { \\mathbf{y}}}^- } \\left ( { { \\mathcal{x } } } \\| { { \\mathbf{y}}}^- \\right)}{q_{{{\\mathbf{y}}}}\\left ( { { \\mathbf{y } } } \\right ) }   \\\\ & = & \\exp(t \\beta ) \\sum_{{{\\mathbf{z } } } }    { p_{{{\\mathbf{u}}}}\\left ( { { \\mathbf{z } } } \\right ) } { q^*\\left ( { { \\mathbf{z } } } \\right ) } \\end{aligned}\\ ] ] where we write @xmath304 .",
    "we require an exponential bound in terms of relative entropy .",
    "there is a wide literature on this subject , and we take a one - sided form of the chernoff bound stated as ( * ? ? ?",
    "* theorem 5 ) ( for @xmath249 , we take @xmath335 and @xmath336 in the result stated there ) :    [ thm : chernoff ] for @xmath337 , we bound the probability @xmath338 where we write @xmath339 for the relative entropy from a bernoulli(@xmath340 ) random variable to a bernoulli(@xmath78 ) , calculated using logarithms to base 2 .",
    "since this is generally a tight bound , we use it to motivate the following approximation , which comes from writing @xmath341 . for any @xmath333",
    "we deduce that @xmath342 if we take @xmath238 and @xmath239 we deduce that @xmath343",
    "the author thanks matthew aldridge , leonardo baldassini and thomas kealy for useful discussions regarding the group testing problem , and vanessa didelez for help in understanding causal conditional probability .      c.  aksoylar , g.  atia , and v.  saligrama . sparse signal processing with linear and non - linear observations : a unified shannon theoretic approach . in _ proceedings of the 2013 ieee information theory workshop _ , pages 15 , sept 2013 .",
    "g.  atia , s.  aeron , e.  ermis , and v.  saligrama . on throughput",
    "maximization and interference avoidance in cognitive radios . in _ consumer communications and networking conference , 2008 .",
    "ccnc 2008 .",
    "5th ieee _ , pages 963967 .",
    "ieee , 2008 .",
    "l.  baldassini , o.  t. johnson , and m.  p. aldridge . the capacity of adaptive group testing . in _ proceedings of the 2013 ieee international symposium on information theory , istanbul turkey ,",
    "july 2013 _ , pages 26762680 , 2013 .      c.  l. chan , p.  h. che , s.  jaggi , and v.  saligrama .",
    "non - adaptive probabilistic group testing with noisy measurements : near - optimal bounds with efficient algorithms . in _ proceedings of the 49th annual allerton conference on communication , control , and computing _",
    ", pages 1832 1839 , sept .",
    "2011 .",
    "t.  kealy , o.  t. johnson , and r.  piechocki .",
    "the capacity of non  identical adaptive group testing . in _ proceedings of the 52nd annual allerton conference on communication , control and computing _ , pages 101108 , 2014 .",
    "m.  malyutov .",
    "recovery of sparse active inputs in general systems : a review . in _",
    "computational technologies in electrical and electronics engineering ( sibircon ) , 2010 ieee region 8 international conference on _ , pages 1522 .",
    "ieee , 2010 .",
    "m.  malyutov .",
    "search for sparse active inputs : a review . in _ information theory , combinatorics and search theory _ ,",
    "volume 7777 of _ lecture notes in computer science _ , pages 609647 .",
    "springer , london , 2013 ."
  ],
  "abstract_text": [
    "<S> we prove new strong converse results in a variety of group testing settings , generalizing a result of baldassini , johnson and aldridge . </S>",
    "<S> these results are proved by two distinct approaches , corresponding to the non - adaptive and adaptive cases . in the non - adaptive case </S>",
    "<S> , we mimic the hypothesis testing argument introduced in the finite blocklength channel coding regime by polyanskiy , poor and verd . in the adaptive case </S>",
    "<S> , we combine a formulation based on directed information theory with ideas of kemperman , kesten and wolfowitz from the problem of channel coding with feedback . in both cases , we prove results which are valid for finite sized problems , and imply capacity results in the asymptotic regime . </S>",
    "<S> these results are illustrated graphically for a range of models . </S>"
  ]
}