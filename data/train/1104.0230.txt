{
  "article_text": [
    "consider the problem of transmitting two correlated gaussian sources over a gaussian broadcast channel with two receivers , each of which desires only to recover one of the sources . in @xcite",
    ", it was proven that analog ( uncoded ) transmission , the simplest possible scheme , is actually optimal when the signal - to - noise ratio ( snr ) is below a threshold for the case of matched source and channel bandwidth . to solve the problem for other cases , various hybrid digital / analog ( hda ) schemes",
    "have been proposed in @xcite , and @xcite .",
    "in fact , the hda scheme in @xcite achieves optimal performance for matched bandwidth whenever pure analog transmission does not , thereby leading to a complete characterization of the achievable power - distortion tradeoff . for the bandwidth - mismatch case ,",
    "the hda schemes proposed in @xcite and @xcite comprise of different combinations of previous schemes using either superposition or dirty - paper coding .    in all the aforementioned work ,",
    "authors also compared achieved performances with that of separate source - channel coding .",
    "since the channel is degraded , source coding boils down to sending a `` common '' message to both decoders and a `` refinement '' message to the decoder at the end of the better channel . in both of the two source coding schemes proposed in @xcite ,",
    "the first source is encoded as the common message , but one scheme encodes ( as the refinement message ) the second source independently , and the other after _ de - correlating _ it with the first source . in @xcite , on the other hand , the second source is encoded after it is de - correlated with the _ reconstruction _ of the first source .",
    "although this approach provably yields a better performance than the schemes in @xcite , it is still not optimal . in @xcite",
    ", it was shown that the optimal rate - distortion ( rd ) tradeoff in this source coding scenario is in fact achieved by a scheme called successive coding , whereby both common and refinement messages are generated by encoding both sources jointly , instead of using any kind of de - correlation .",
    "although successive coding is a special case of successive refinement in its general sense , _ computation _ of the rd tradeoff , even for gaussians , turned out to be non - trivial .",
    "a shannon - type lower bound derived for the problem was rigorously shown to be tight , yielding an analytical characterization of the rd tradeoff .    in this paper",
    ", we investigate the performance of separate source and channel coding for any bandwidth compression / expansion ratio .",
    "as discussed in the previous paragraph , the source coding method to be used for optimal performance is successive coding .",
    "we first show that this separate coding scheme achieves the optimal power - distortion tradeoff when one receiver requires almost lossless recovery , and the other requires a small enough distortion . comparing with best - known schemes and outer bounds , we then show that this scheme is competitive in other cases as well .",
    "our results imply that with a ( sometimes marginal ) sacrifice of power - distortion performance , we can design separate source and channel codes , and thus enjoy the advantages such as simple extension to different bandwidth compression / expansion ratios .    in section",
    "ii , the problem is formally defined .",
    "our main results are proved in section iii and the separate coding scheme is compared with other separation - based schemes and hybrid schemes in section iv .",
    "as depicted in fig . [ fig : system ] , a pair of correlated gaussian sources @xmath0 are broadcast to two receivers , and receiver @xmath1 , @xmath2 , is only to reconstruct @xmath3 . without loss of generality",
    ", we assume the source sequences are generated in an i.i.d .",
    "fashion by @xmath4 , where @xmath5\\ ] ] and @xmath6 $ ] .",
    "the transmitter encodes the source sequences to @xmath7 and thus can be described mathematically as @xmath8 .",
    "we define bandwidth compression / expansion ratio @xmath9 with the unit of channel uses per source symbol .",
    "the channel also has an average input power constraint , given by @xmath10 \\leq p \\ ; .\\ ] ] at receiver @xmath1 , @xmath7 is corrupted by i.i.d .",
    "additive gaussian noise @xmath11 , which satisfies @xmath12 , where we assume that @xmath13 .",
    "the channel output @xmath14 is then a gaussian sequence given by @xmath15 .",
    "decoder @xmath16 reconstructs @xmath17 from the channel output @xmath18 and can be described as a function @xmath19 .",
    "analogously , decoder @xmath20 computes @xmath21 .",
    "the reconstruction quality is measured with squared - error distortion , i.e. , @xmath22 for any source block @xmath23 and reconstruction block @xmath24 .",
    "the problem is to find the optimal tradeoff between the channel input power constraint @xmath25 and the expected distortion pair @xmath26 achieved at the receivers .    in @xcite ,",
    "an outer bound to the distortion region is obtained for @xmath27 by assuming full knowledge of @xmath28 at the second ( strong ) receiver . in @xcite , that outer bound is extended to bandwidth - mismatched case , in the form of    @xmath29 where @xmath30 $ ] and @xmath31 .",
    "several separation - based schemes have been previously proposed , differing only in their source coding strategy . in the first separation - based scheme , termed scheme a in @xcite , sources @xmath28 and @xmath32",
    "are encoded as if they are independent , resulting in the distortion region given by @xmath33 in scheme b in @xcite , the second source is written as @xmath34 , where @xmath35 , and @xmath28 and @xmath36 are treated as two new independent sources .",
    "hence we obtain @xmath37    in the scheme introduced in @xcite , which we call scheme c , @xmath28 is quantized to @xmath38 and @xmath32 is then encoded conditioned on @xmath38 .",
    "the resultant distortion region becomes @xmath39 \\left ( 1+\\frac{\\bar{\\eta } p}{n_2 } \\right ) ^ { -\\kappa}\\ ; .",
    "\\label{eq : tiand2}\\end{aligned}\\ ] ]    of the three , it is obvious that scheme c achieves the best performance .",
    "however , it is still not optimal as we will show in section iv .",
    "the optimal strategy is in fact what is called successive coding in @xcite , whereby the sources are encoded jointly at both the common and the refinement layers .",
    "the rd tradeoff for successive coding of gaussian sources with squared - error distortion was given in @xcite parametrically with respect to @xmath40 $ ] as , the optimal strategy degenerates into sending only a common message and estimating @xmath41 solely from @xmath42 .",
    "so this trivial case is excluded from the discussion in the sequel . ]",
    "@xmath43^+\\ ; , \\end{aligned}\\ ] ] where @xmath44 , @xmath45^+ = \\max\\{x , 0\\}$ ] , and @xmath46 with @xmath47 , and @xmath48 is the unique root of @xmath49 in the interval @xmath50 $ ] .",
    "we first show the rd region of successive coding can be simplified by eliminating both the parameter @xmath51 and the need to find the roots of the cubic polynomial @xmath52 .",
    "the achievable source coding rate pair @xmath53 , for any distortion pair @xmath26 , is given by @xmath54^+\\ ; , \\label{eq : sourcerate2}\\end{aligned}\\ ] ] where @xmath55 $ ] .",
    "the proof is deferred to appendix a. in separate coding , the region of all achievable @xmath56 triplets can be determined using one of two methods .",
    "the conventional method fixes @xmath25 and searches for the lower envelope of all @xmath26 whose source rate region intersects with the capacity region given in @xcite .",
    "alternatively , we can fix @xmath26 and search for the minimum @xmath25 whose corresponding capacity region intersects with the source rate region given in lemma @xmath16 .",
    "we find this alternative both more convenient and more meaningful .",
    "more specifically , it is easier to compare schemes based on the minimum power they need to achieve the same distortion pair , and the ratio of minimum powers yields a single number as a quality measure .    to be able to use this alternative , first we need to find out the minimum required power for any given source coding rate pair @xmath57 .    for any source coding rate pair @xmath57 ,",
    "the minimal required power is given by @xmath58    for a gaussian broadcast channel where the better receiver is the second one , @xmath59 and @xmath60 , rates of common and private information , respectively , can be achieved if and only if there exists @xmath61 such that @xmath62 where @xmath31 .",
    "this , in turn , implies that @xmath25 is achievable if and only if there exists @xmath63 such that @xmath64 since the terms in the maximum exhibit opposite monotonicity with respect to @xmath65 with asymptotes at @xmath66 and @xmath67 , the minimum power is achieved when the two terms are equal , that is , when @xmath68 and has the form in ( [ eq : mismatchedp ] ) .    by substituting ( [ eq : sourcerate1 ] ) and ( [ eq : sourcerate2 ] ) into ( [ eq : mismatchedp ] ) , we obtain the minimum power required for the separate coding scheme as a function of @xmath69 : @xmath70^ { 1/ \\kappa } -1\\right )   \\\\",
    "+ n_2\\left [ \\left ( \\frac{1-\\nu^2 \\delta}{d_2 } \\right ) ^ { 1/ \\kappa } -1\\right ] \\left [ \\frac{1-\\rho^2}{d_1(1-\\nu^2 \\delta ) - ( \\rho-\\nu \\delta)^2 } \\right]^ { 1 / \\kappa }   \\ ; . \\label{eq : pnu}\\end{gathered}\\ ] ]    for bandwidth - matched case , the minimum power of separate coding @xmath71 can actually be found analytically for any @xmath72 .",
    "we omit the details here .",
    "the following theorem is our first main result .",
    "separate source - channel coding achieves optimal power - distortion tradeoff when @xmath26 satisfies either of the following conditions    1 .",
    "@xmath73 and @xmath74 , 2 .",
    "@xmath75 and @xmath76 .",
    "we first find the minimum power the outer bound ( [ eq : ob1 ] ) and ( [ eq : ob2 ] ) requires .",
    "note that when @xmath77 , ( [ eq : ob2 ] ) will hold for any @xmath30 $ ] , and hence the minimum power is obtained solely from ( [ eq : ob1 ] ) , whereas when @xmath74 , the minimum power satisfies equality in both ( [ eq : ob1 ] ) and ( [ eq : ob2 ] ) .",
    "combining the two cases , we obtain the concise expression @xmath78^+ + n_1(d_1^{-1/\\kappa } -1 )   \\ ; .",
    "% & = \\frac { -(d_1d_2)^{1/\\kappa } n_1 + d_2^{1/\\kappa } ( n_1-n_2 ) + n_2 ( 1-\\rho^2)^{1/\\kappa } } { ( d_1d_2)^{1/\\kappa } } \\ ; . \\end{split}\\ ] ] on the other hand , from ( [ eq : pnu ] ) , we have @xmath79 d_1^ { - 1 / \\kappa }   \\\\ = n_2d_1^{-1/\\kappa } \\left [ \\left(\\frac{d_2}{1-\\rho^2 \\delta } \\right)^{- 1 / \\kappa } - 1 \\right ] + n_1(d_1^{-1 / \\kappa }",
    "-1 )   \\ ; .\\ ] ] since @xmath44 , it is easy to see that when @xmath74 @xmath80 and since @xmath81 is feasible , the minimum power of separate coding satisfies @xmath82",
    ". therefore the performance of separate coding scheme approaches the outer bound , or @xmath83 similarly , by setting @xmath84 , we have @xmath85^ { 1 / \\kappa}-1\\right)\\\\ & + n_2\\left [ \\left ( \\frac{1-\\frac{\\rho^2 } { \\delta}}{d_2 } \\right ) ^ { 1 / \\kappa } -1\\right ] \\left [ \\frac{1-\\rho^2}{d_1(1-\\frac{\\rho^2 } { \\delta } ) } \\right]^ { 1 / \\kappa }   \\ ; , \\end{split}\\ ] ] and when @xmath75 , @xmath86 .",
    "note when @xmath87 , @xmath88 , which again implies @xmath89 , thus proving the second part of the theorem .",
    "here we proved that the outer bound is tight in the region of @xmath87 when either @xmath90 or @xmath91 goes to @xmath92 , and the performance of separate coding approaches the outer bound .",
    "the condition that either @xmath90 or @xmath91 goes to @xmath92 translates to infinite channel snr .",
    "in fact , as we show in the following theorem , separate coding is approximately optimal for the entire region @xmath87 , in the sense that the power ratio @xmath93 can be upper - bounded universally in @xmath94 .    when @xmath87 , @xmath95 } { ( 1+\\rho)^{1/ \\kappa}-(1-\\rho)^{1/ \\kappa } } , \\\\",
    "\\left ( \\frac{(1+\\rho)^2}{1 + 2\\rho } \\right)^{1 / \\kappa } + \\frac{\\left ( \\frac{(1+\\rho)^2}{1 + 2\\rho } \\right)^{1 / \\kappa } - 1}{(1-\\rho^2)^{-1/ \\kappa } - 1}\\bigg\\ }   \\ ; .\\end{gathered}\\ ] ]    the first half is true because @xmath96 + d_2^{1/ \\kappa } ( 1- d_1^{1/ \\kappa})}{\\frac{n_2}{n_1}\\left [ ( 1-\\rho^2)^{1/ \\kappa }   - d_2^{1/ \\kappa } \\right ] + d_2^{1/ \\kappa } ( 1- d_1^{1/ \\kappa } ) }   \\\\ & \\stackrel{(b)}{\\leq } & \\frac{(1-\\rho^2 \\delta)^{1/ \\kappa } - ( d_1 d_2)^{1/ \\kappa } } { ( 1-\\rho^2)^{1/ \\kappa } - ( d_1 d_2)^{1/ \\kappa } }   \\\\ & \\stackrel{(c)}{\\leq } & \\frac{(1-\\rho^2 \\delta)^{1/ \\kappa } - ( 1-\\rho)^{2/ \\kappa}}{(1-\\rho^2)^{1/ \\kappa } - ( 1-\\rho)^{2/ \\kappa } } \\\\ &",
    "\\stackrel{(d)}{\\leq } & 1+\\frac{(1+\\rho)^{1/ \\kappa } \\left [ ( 1+\\rho^2)^{1/ \\kappa}-1 \\right ] } { ( 1+\\rho)^{1/ \\kappa}-(1-\\rho)^{1/ \\kappa}}\\ ; , \\end{aligned}\\ ] ] where @xmath97 follows since @xmath81 is feasible , @xmath98 by @xmath99 , @xmath100 follows since @xmath101 , and @xmath102 since @xmath103 .    by relaxing @xmath104 to @xmath105",
    ", the second half of the bound can be obtained in a similar way .",
    "the detailed proof is omitted here due to lack of space .",
    "+    as illustrated in @xcite for @xmath106 , the outer bound in ( [ eq : ob1 ] ) and ( [ eq : ob2 ] ) is not always tight .",
    "nevertheless , we can still compare @xmath104 and @xmath107 for any @xmath72 , which provides an upper bound to the ratio of the minimum separate and joint coding power levels . to show the optimality of our separate coding scheme",
    ", we also compare our scheme with scheme c , which provides the best performance among the three separation - based schemes mentioned earlier .",
    "the minimum required power of scheme c can be obtained from ( [ eq : tiand1 ] ) and ( [ eq : tiand2 ] ) as @xmath108 d_1^{-1/\\kappa } -n_1   \\ ; .",
    "p_c =   n_2d_1^{-1/\\kappa}\\left [ \\left(\\frac{d_2}{1-\\rho^2 \\delta } \\right)^{-1/\\kappa } -1 \\right ] + n_1(d_1^{-1/\\kappa } -1 )   \\ ; .",
    "% \\label{eq : pc}\\ ] ] note that @xmath109 in the non - trivial distortion regions , so it is immediately clear that the successive coding scheme outperforms scheme c. as an example with bandwidth compression , we show the power ratio between our separate coding scheme and the outer bound in figure [ fig : tian ] , and that between scheme c and our separate coding scheme in figure [ fig : tian ] , both in db . for reference ,",
    "the black curves illustrate the different distortion regions for a related problem in @xcite , where only one receiver is in presence and interested in reconstructing both sources .",
    "the lower left corner region is actually @xmath87 , where , in general , small db differences are observed , as implied by the two theorems above .",
    "as can be seen from the figure , even for highly correlated sources , the optimum separate coding scheme does not require too much extra power in most of the @xmath72 plane .",
    "again , since the outer bound is not always tight , the large power difference in some regions may be dramatically reduced when the outer bound is replaced by the optimum performance . for smaller @xmath110 values ,",
    "we observe that the power difference is very small in the entire plane , as an example illustrates in the next section .",
    "this is a natural result because separate coding is optimal for independent sources and small @xmath110 value means the sources are not highly dependent .",
    "there is also noticeable power difference between our scheme and scheme c , and we numerically observe large db values near the point @xmath111 and @xmath112 , for which we can obtain analytically the power ratio .    when @xmath113 and @xmath75 , @xmath114    the proof uses the fact that the power of our separate coding scheme goes to that of the outer bound when approaching this point .",
    "when the two receivers have the same noise level , i.e. , @xmath115 , it can be shown that our separate coding scheme achieves the corresponding rate - distortion function @xmath116 in @xcite , whereas none of the three separate coding schemes mentioned earlier has the same performance .",
    "+    in @xcite and @xcite , a group of hybrid digital / analog ( hda ) schemes were proposed for bandwidth - mismatched case , where analog , digital , and hybrid schemes are layered with superposition or dirty - paper - coding .",
    "the achievable distortion region can be found by varying power allocation and scaling coefficients . in @xcite , an hda scheme from @xcite for broadcasting a common source with bandwidth expansion",
    "was adapted for the problem of broadcasting correlated sources and is termed the rfz scheme . in addition , a scheme , termed the hwz scheme , containing an analog layer and two digital layers each with a wyner - ziv coder and a channel coder , was also proposed .",
    "it is argued by an example in @xcite that the hwz scheme performs similar to the rfz scheme .",
    "here we compare our separate coding scheme with the outer bound and the rfz / hwz scheme in figure [ fig : hamid ] . for this comparison",
    ", we revert to the more familiar @xmath72 plot for the exact same @xmath117 as those used in the examples in @xcite .",
    "as seen in figure [ fig : hamid ] , when @xmath110 is small , the separate coding scheme almost coincides with the outer bound and outperforms rfz / hwz schemes . when the sources are highly correlated as in figure [ fig : hamid ] , the separate coding scheme is still better than the rfz / hwz schemes when @xmath91 is lower than a certain value , and also provides competitive performance when it is higher .",
    "we observed similar performance behavior when we compared the separate coding scheme to the layered schemes in @xcite for bandwidth compression .",
    "the performance of optimum separate source - channel coding scheme for broadcasting two correlated gaussians is analyzed . the minimum power required for a given distortion pair",
    "is used as a tool to compare performances of different schemes .",
    "it is illustrated that this separate coding scheme outperforms other known separate schemes , and is competitive in general in the sense that its minimum required power is close to the power implied by the outer bound .",
    "also , in a certain `` low distortion '' region , the power difference is analytically bounded .",
    "in fact , within this region , in the extreme cases of almost lossless reconstruction of either source , the separate scheme is provably optimal .",
    "the cubic function in @xcite is @xmath118 and when @xmath119 , it can be re - written as @xmath120 }   \\ ; .\\ ] ] it will be shown that varying @xmath121 in @xmath122 $ ] is equivalent with varying @xmath69 in @xmath123 $ ] , by showing @xmath121 is a monotonically decreasing function of @xmath69 .",
    "when @xmath124 , @xmath125 and also note @xmath126 when @xmath127 , respectively .",
    "we examine @xmath128 instead of @xmath121 , and @xmath129 the right hand side is a quadratic function of @xmath69 centered at @xmath84 and the maximum value is @xmath130 .",
    "( when @xmath81 , the function value is @xmath131 . )",
    "similarly , when @xmath132 , we have @xmath133 and in this case , @xmath126 when @xmath134 .",
    "we examine @xmath135 and thus have @xmath136 the right hand side is centered at @xmath137 and the maximum value is @xmath138 . @xmath139",
    "h.  behroozi , f.  alajaji , and t.  linder , `` hybrid digital - analog joint source - channel coding for broadcasting correlated gaussian sources , '' _ proc .",
    "inf . theory ( isit 2009 ) _ ,",
    "seoul , korea , june 2009 .",
    "c.  tian , s.  diggavi , and s.  shamai , `` the achievable distortion region of bivariate gaussian source on gaussian broadcast channel , '' _ proc .",
    "theory ( isit 2010 ) _ , austin , tx , june 2010 ."
  ],
  "abstract_text": [
    "<S> the problem of broadcasting a pair of correlated gaussian sources using optimal separate source and channel codes is studied . </S>",
    "<S> considerable performance gains over previously known separate source - channel schemes are observed . </S>",
    "<S> although source - channel separation yields suboptimal performance in general , it is shown that the proposed scheme is very competitive for any bandwidth compression / expansion scenarios . </S>",
    "<S> in particular , for a high channel snr scenario , it can be shown to achieve optimal power - distortion tradeoff . </S>"
  ]
}