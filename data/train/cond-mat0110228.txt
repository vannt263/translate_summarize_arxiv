{
  "article_text": [
    "computational mechanics ( cm ) @xcite has a formalism @xcite that has been proved to construct the minimal model capable of statistically reproducing all the resolvable causal structure of any infinite sequence of discrete measurements ( be they scalar , vector , tensor , or descriptive)@xcite .",
    "the size of a model so defined , measured by a quantity termed statistical complexity , @xmath0 , @xcite is a reliable and falsifiable indication of the amount of structure the data contain@xcite .",
    "the particular strengths of this approach are that it enables the complexities and structures of different sets of data to be quantifiably compared and that it directly discovers detailed causal structure within those data . by examining data in this way it is possible to appreciate , in a well - defined abstract sense , how a system actually functions and what scales are most important to it .",
    "this information can then be used to optimise the efficiency of physically plausible models@xcite .    as with all other analytical tools , cm has some limitations in the face of certain real - world problems that affect the information content of the signal under study .",
    "these problems may include :    1 .",
    "gaps in the data 2 .",
    "noise 3 .",
    "restricted sequence length 4 .",
    "correlations at a very wide range of scales .",
    "the problem of correlations at a wide range of scales is particularly interesting and relevant to geophysical and other natural time series because of their typically power law ( coloured noise ) fourier spectra @xcite .",
    "theoretically , the minimum resolvable scale will be constrained by the data sampling interval and the maximum resolvable scale by the length of the data series . in practice",
    ", the range of resolvable scales will also be set by the available computational resources .",
    "thus , the range of resolvable scales may be less than those necessary to evaluate correlations on all relevant scales .",
    "consequently , it is important to understand how structural analysis is affected by unresolved structure due to correlation .    in this paper",
    ", we address these issues in detail . in section  [ method ] ,",
    "we discuss how the ideal formalism of cm can be adapted to apply to a non - infinite series of corrupted and correlated data .",
    "in particular , three concepts are defined and discussed : ( 1 ) a tolerance parameter @xcite to account for the statistical uncertainty introduced by a non - infinite series that destroys the exact equivalence of different causal states sharing the same outcome .",
    "( 2 ) a new expletive filter that removes signal corruption by assuming that corruption creates rare causal states or words that are not in the dictionary of the true signal . (",
    "3 ) the new concept of effective soficity in which a data series has a finite set of equivalent causal states that is stable to small changes in the effective memory of those states .",
    "the latter concept distinguishes between unresolvable  random \" structure and resolvable structure whose discovery is only prevented by the effective memory being used and by the length of the data series .    in section  [ examples ]",
    ", we apply the cm algorithm with these additional concepts to the analysis of structure in four simulated time series : ( 1 ) uncorrelated , white noise .",
    "( 2 ) periodic signal with white noise corruption . ( 3 ) a biased poisson switch ( i.e. , a sequence of pulses whose pulse durations and inter - pulse intervals are determined by stationary poisson processes ) . ( 4 ) a sequence of bursts similar to ( 3 ) but with fixed pulse duration .",
    "the structure of the time series is analysed by searching for regions of effective soficity in maps of statistical complexity over the parameter space of the cm model .",
    "the simulated time series represent four types of signal thought to be present in time series measurements of the geomagnetic field . in section",
    "[ application ] , we use the cm algorithm to examine a real geomagnetic time series measured at halley , antarctica , in which deflections of the earth s magnetic field are due mainly to electrical currents in the ionosphere .",
    "the cm analysis yields a structural model that comprises a diurnal component corresponding to the oscillation of the measuring apparatus with the rotation of the earth and a poisson - switched , fixed - duration , pulse component that is likely associated with the magnetospheric substorm @xcite .    in section  [ discussion ] , we discuss some general principles that have been learnt in applying cm to the analysis of structure in real data , and draw conclusions in section  [ conclusion ] .",
    "here we give an introduction to the practical use of cm in the analysis of real data .",
    "we concentrate only on describing in detail the formalism for the parsing structure that we have used in the analyses . for a fuller description of the potential intricacies of the method see reference@xcite . defining some new terminology ,",
    "we highlight the difficulties associated with analysing experimental data in this way , and explain solutions to these problems .    to start with , one has a set of measurements - either a spatial or temporal series where the separation between each point is known .",
    "the total time or length for which data exist is their span , @xmath1 .",
    "after coarse - graining at a fixed scale @xmath2 , the series has @xmath3 equally spaced measurements .",
    "next , we digitise the signal amplitude . for reasons that will be apparent later",
    ", the number of possible digits should be low unless the series length is extremely large .",
    "the digitised sequence is then a concatenation of @xmath4 letters @xmath5 , where there are @xmath6 types of such letters , ranging from @xmath7 up to @xmath8 . in order to maximize the prior probable information content of the processed sequence , digitisation",
    "should normally be performed such that there are equal numbers of each letter present .",
    "for example , in the case of binarisation ( where @xmath9 ) , this would mean that the threshold for letter @xmath10 would be the median value of the data .",
    "it should be noted , though , that the best way to digitise the sequence is that which _ actually _ maximises the information content of the result ; but that this can not usually be guessed .",
    "another approach that has been suggested@xcite is to use the formalism of maximum entropy .",
    "the next step is to parse the sequence .",
    "one begins by composing words from each group of @xmath11 consecutive letters ; the @xmath12th word , @xmath13 , is defined by : @xmath14 thus there are @xmath15 possible words , each represented by a unique scalar , @xmath16 : @xmath17 the total number of words generated from the sample is @xmath18 .",
    "we now introduce some terminology ; any word @xmath13 may be called a _ proword _ , @xmath19 when followed by any word @xmath20 .",
    "this latter is called the _ epiword _ , @xmath21 .",
    "for this sentence we digress slightly to note that it may sometimes be beneficial to perform the initial digitisation on each separate block of data @xmath22 letters long rather than the entire dataset .",
    "we now proceed to capture causal structure in the word sequence by compiling a tally of epiwords following each proword .",
    "this means going through the sequence incrementing an array @xmath23 accordingly . representing summation over an index by its omission",
    ", we see that the total tally is @xmath24 . thus , contracting over epiwords gives a tally of prowords only : @xmath25 and the fractional prevalence of each proword in the sequence is therefore contained in the vector @xmath26 finally , the fractional _ profile _ of each proword by epiword is given by the array @xmath27 where the repeated indices in the division are not summed over .",
    "given a particular proword , this tells us the likelihoods of transitions to the various epiwords .",
    "the crux of the technique now lies in identifying prowords with equivalent epiword profiles .",
    "such prowords are said to belong to the same `` equivalence class '' or `` causal state '' - i.e. they share statistically equivalent probabilistic futures ( at the level of analysis one has been pursuing ) .",
    "the identification is made via an equivalence relation , denoted by @xmath28 .",
    "for an infinite sequence , @xmath28 can demand exact correspondence between profiles , in which case it is always transitive ( meaning @xmath29 ) . in a practical situation , where even the finite length of the sequence introduces fluctuations in the calculated profiles@xcite ,",
    "it is not possible to be so exact .",
    "we therefore introduce a tolerance parameter , @xmath30 , within the bounds of which the profiles of words in the same equivalence class are allowed to vary : two prowords , @xmath31 and @xmath32 , are in the same equivalence class if , @xmath33 @xmath34 ; @xmath35 where the large vertical bars signify absolute magnitude .",
    "although this appears to destroy the formal transitive property of @xmath28 , it is postulated here that after some finite sequence length is surpassed , there always exists a definite range of values for @xmath30 within which the transitive property is observed correctly .",
    "the transitive property can be enforced where @xmath28 is not transitive  by grouping equivalence classes defined by @xmath28 that share at least one word .",
    "having identified the words lying within each equivalence class , a model which outputs a series of letters statistically equivalent to the original can be constructed .",
    "it is a particular strength of the technique that the model generated is always a minimal representation of the data s statistical structure for the amount of memory the analysis employs@xcite .",
    "the model is easiest to describe in terms of its representation as a labelled  diagraph \" .",
    "two very simple labelled diagraphs , with extracts from their outputs , are presented in figure  [ twzrcmplxtdgrphs ] .",
    "a more complicated labelled diagraph , also representing a minimal model , is shown in figure  [ mrcmplctddgrph ] .",
    "each diagraph comprises a node or nodes , indicated by a circle with a number in it , and lines joining one node to another or to itself .",
    "each numbered node of a diagraph represents a causal state corresponding to each of the model s equivalence classes , while each line ( unidirectionally ) joining two nodes is labelled with the string of letters ( the word ) that is output when that line is followed .",
    "in addition , each line is associated with a probability .",
    "the word output on going from one causal state to another is in the equivalence class of the future state .",
    "the probability of each word s output may therefore be trivially given by @xmath36 .",
    "it should be held in mind that only a subset of all possible labelled diagraphs represent minimal models .",
    "even so , an arbitrary diagraph s output can naturally be used to construct the appropriate minimal model .",
    "models like this are useful for three reasons :    1 .",
    "their minimality allows the structure of two sets of data to be directly compared .",
    "once a model has been synchronized with current data it optimizes one s ability to forecast the behaviour of the system in the future .",
    "3 .   the information concerning scales of causal structure in the data can be used to optimize the performance of more physically plausible models .",
    "if a recursive decomposition is employed@xcite , diagraphs labelled with words to output can be reformed into equivalent diagraphs labelled with single letters .",
    "this is perhaps a mathematically aesthetic thing to do .",
    "however , because any real analysis is performed with an effective memory of only @xmath11 symbols , only the last @xmath11 symbols are of any use for prediction .",
    "this fact is not manifest in the single - letter diagraph obtained through the decomposition of the transition matrix , @xmath37 .",
    "moreover , it is necessary to synchronise a single - letter diagraph to an input stream of data before it is of any use for the purpose of prediction . in this paper",
    "we concentrate only upon the identification of proword equivalence classes , because it is a powerful tool for pattern discovery in its own right .    a measure of the structure of such models is given by the statistical complexity@xcite : @xmath38 where logarithms are canonically taken to base @xmath39 and the prevalence @xmath40 of equivalence class @xmath12 is given by the sum of the prevalences of the words in that class . for example",
    ", the models represented by the labelled diagraphs in figure  [ twzrcmplxtdgrphs ] both have a statistical complexity of zero because they only have one causal state ( and therefore one equivalence class ) each .",
    "this is sensible because they both output noise .",
    "the model represented in figure  [ mrcmplctddgrph ] , though , has four causal states with equal prevalences and a correspondingly higher statistical complexity of two bits : @xmath41    @xmath0 is extremely important , not only because it reflects the complexity of the system , but also because it does not converge until the data have been fully characterized .",
    "it is a hard fact that if the sequence length @xmath4 is too small , full characterization will not be possible .",
    "this is because fluctuations in the proword profiles will corrupt the identification of equivalence classes . in this text the resultant unresolvable structure",
    "is called _ noise_. in contrast , resolvable but as yet unresolved structure is described as _ random _ @xcite .",
    "such random structure is likely to be encountered in analysing data sets with correlation lengths comparable to or exceeding the maximum wordlength .",
    "making this distinction is very important , even though it is not possible to discern whether unresolved structure is noisy or random until further computation has resolved it . in other words ,",
    "the data appear to be noisy until the series is found to be _ effectively sofic _ , at which point @xmath0 attains its correct value and the model is complete .",
    "we note that sofic sequences are those which still have a finite number of equivalence classes when @xmath4 is infinite and @xmath11 is semi - infinite ( see badii and politi@xcite , page 80 for a longer explanation ) .",
    "_ effective _ soficity is here defined to mean that a sequence has equivalence classes that are stable to an increase in wordlength .",
    "thus , a sequence could be effectively sofic at one range of wordlengths but not at another where either more or less structure is in the process of being identified .",
    "both random structure and noise will redistribute the original tally from what would be expected if only resolved structure was present , raising @xmath0 from the value corresponding to resolved structure alone and increasing the complexity of its model .",
    "a simple one - parameter model for the corruption process is to assume that the probability that any letter is corrupted to any other letter is @xmath42 .",
    "then the probability any letter stays as it is is @xmath43 and the corruption will have been governed by the redistribution function @xmath44 where @xmath45 reads , _ the pure word @xmath46 , when corrupted by noise in a certain way , is identical to the corrupt word @xmath47_. the label `` pure '' implies effective soficity .",
    "thus , assuming the corruption of prowords and epiwords are independent we have @xmath48 where @xmath49 where @xmath50s is a kronecker delta and the corruption of letters is assumed to be independent .",
    "it happens that arbitrarily corrupted distributions can be uniquely deconvolved as long as one knows @xmath42 , but this is not usually the case in an experimental situation .",
    "we have two alternative options .",
    "the first is to scan through @xmath42 , deconvolving the proword prevalences each time .",
    "this will produce a drastic decrease in the statistical complexity at some point , signifying correct parameterization of @xmath42 . a good guess for @xmath42",
    "might be the first value which results in a single proword having a prevalence of zero .    whilst the assumption of independent corruption of letters is likely to be a good model of noise , it is unlikely to be a good model of the uncharacterised correlated structure that we call random .",
    "consequently , a second option is to ignore the details of any corruption and simply assume that the prevalence of any expletive ( corrupted word ) is below a certain expletive prevalence , @xmath51 .",
    "we scan through @xmath51 , eradicating any prowords whose prevalence is less than @xmath51 , and recalculate @xmath0 each time .",
    "this procedure can alternatively be performed after the identification of preliminary equivalence classes to eradicate expletive equivalence classes . in any case",
    ", the approach can only work when the actual structure - to - noise ratio ( snr ) is high enough to ensure that expletives are eradicated before meaningful words are .",
    "if the pure proword prevalence distribution is very uneven this method can not work .",
    "in general , a combined method would probably be most successful - that is , where one first attempts the deconvolution after making some bold assumptions and then removes the resulting low - prevalence words completely . it is always possible to determine all the resolvable structure of a sequence for which the snr is arbitrarily small , so @xmath0 is independent of snr .",
    "of course though , if the snr is zero , so is @xmath0 , because the model suddenly collapses to a single equivalence class .",
    "note that deconvolution can always be achieved by inversion of an assumed convolution matrix , but that this is not always easy .",
    "in particular , if one knew the actual matrix then the `` noise '' would not be noise at all , but resolved structure .",
    "the only deconvolution that is strictly necessary is that which removes the noise ( unresolvable structure ) from the signal .",
    "it should therefore assume that the redistribution is gaussian .",
    "in practice though , some random ( resolvable ) structure may be so computationally difficult to identify that a messy deconvolution is required to remove it , allowing the analysis of more easily resolvable structure to proceed .",
    "it is admissible to remove expletives from the prevalence distribution because they destroy the effective soficity of the data .",
    "it is instructive at this point to go through the uncertainties present in the profile and prevalence distributions . when the sequence length is large compared to @xmath15 the probability that any individual word has been corrupted is approximately @xmath52 .",
    "following the definition of the prevalence distribution , we find that the uncertainty in the prevalence of a proword @xmath53 is governed by an inequality : @xmath54 where the lower limit corresponds to uncorrelated errors and the upper limit to systematic errors .",
    "we indeed expect the uncertainty to be somewhere in this range because the errors are due to unresolved structure .",
    "the uncertainty in the prevalence of a single epiword within a particular proword s profile is expected to be greater : @xmath55 these inequalities go some way to justifying the use of the blanket tolerance @xmath30 to identify the equivalence classes , because we know nothing about the nature of the errors . in some cases",
    "it is conceivable that @xmath30 would have to be scaled by @xmath56 , where @xmath57 in order to correctly identify equivalence relations between profiles . in such cases @xmath58 is an extra parameter .",
    "we now turn to the analysis of test sets of data by the algorithm described in detail above .",
    "the test data represent signal types thought to be present in time series measurements of the geomagnetic field that we shall study in the next section .      a white noise ( temporally uncorrelated ) signal was generated by a sequence of 5000 independent samples from a uniform distribution and converted to binary by setting those values above the median to unity and those below the median to zero .",
    "figure  [ rndmsttstclcmplxt ] shows the variation of statistical complexity , @xmath0 , versus word length , @xmath11 , and tolerance , @xmath30 , for this signal .",
    "the absence of a plateau in this graph indicates that , for the range of memories ( wordlengths ) tested , the analysis does not discern any structure at all in the signal .",
    "the linear variation of @xmath0 with @xmath11 for @xmath59 represents models with as much arbitrariness as is possible at each level of memory used in the analysis .",
    "these models collapse to a single equivalence class as the tolerance parameter is increased .",
    "an increasing amount of tolerance is required for this collapse for increasing wordlength , as expected from equation  [ uncertainty ] .",
    "thus , no complex models at all were constructed for this noisy sequence at any time during this analysis .",
    "this was expected ; we would have been disappointed with the random number generator that was used to construct the sequence ( the idl ",
    "randomu \" function , see also@xcite ) if we had easily found correlations .",
    "figure  [ 10prcntnsbnrprd4sttstcclcmplxt ] shows the result of the analysis on a binary period four sequence ( i.e. , 00110011 ... ) of length 5000 , where 10% of the bits have been randomly flipped .",
    "this graph has a stable , but rather jagged , plateau at @xmath60 which begins at wordlength 4 for tolerances in the range @xmath61 .",
    "this plateau corresponds to a group of models that capture the essential structure in the signal . in the absence of noise the statistical complexity of a binary period",
    "four signal should be @xmath62 .",
    "the apparently anomalously high level of the plateau is caused by both the noise and the finite sequence length corrupting the identification of the equivalence classes .",
    "it is not entirely flat because the corruption is different at each value of wordlength and tolerance .",
    "in fact , there is a gentle downward trend which would converge to @xmath63 in the limit of the extra , spurious , states decreasing in prevalence at longer and longer wordlengths , if the sequence was long enough .",
    "note that the gradient of the increase of statistical complexity with wordlength changes at a memory equal to half the period of the structure in this signal .",
    "this is the point at which the structure is first discovered : it is important to note that the convergence of @xmath0 is not immediate , suggesting an analogue of the nyquist sampling theorem for cm .",
    "note also steep drops in @xmath0 where previously distinguishable equivalence classes have suddenly collapsed together as the tolerance parameter @xmath30 exceeds some critical value , supporting our earlier postulate that there is a definite range of @xmath30 within which a true transitive property is observed .",
    "figure  [ 10prcntnsbnrprd4sttstcclcmplxtx075 ] shows results of a similar analysis on the same sequence , excepting that this time , words of prevalence less than @xmath51 ( the expletive prevalence parameter ) were eradicated from the probability distributions .",
    "@xmath51 was chosen to be 0.075 for this graph .",
    "as we can see , this approach was entirely successful in the respect that @xmath0 converges to a plateau for a broad range of the tolerance parameter @xmath30 .",
    "a minimal model that was capable of outputting sequences with statistical structure identical to that characterized from the input was effectively constructed at every point on this plateau .",
    "the value of @xmath0 for periodic sequences was always found to directly reflect the amount of memory required by the system to produce such data : a sequence with a sole period , @xmath64 , has a statistical complexity of @xmath65 ( in this case the period four signal has a statistical complexity of @xmath66 ) .",
    "moreover , we can appreciate that the analysis only yields a convergent value after the wordlength has exceeded at least half the period of the sequence .",
    "more generally ; convergence begins when an analysis first has greater memory than a system .",
    "if the system has certain structure with greater memory than it may be feasible to analyse , for example , a red noise signal that consists of many fourier modes with a power law distribution of amplitudes and random phases , @xmath0 will not ever truly converge",
    ". however , there may be stages where the analysis has enough memory to identify _ some _ structure , and this is indicated by approximately flat regions , or , at the very least , dips in the gradient of @xmath0 with increasing wordlength .",
    "we next turned to more detailed analyses of two other illustratively important diagraph s outputs .",
    "the first we considered was the biased poisson switch@xcite , represented as a labelled diagraph in figure  [ pssnswtchdgrph ] .",
    "the circled states , @xmath67 and @xmath10 may each generate either a one or a zero with the probabilities shown .    in the figure , @xmath68 and @xmath69 .",
    "note that when @xmath70 the output sequence is no longer biased .",
    "it turns out that the values of @xmath0 we can derive for different values of @xmath71 and @xmath72 provide some nice insights into the nature of information and the optimization of measurement processes .",
    "the measure has two distinct regimes : where @xmath73 , and where they do not .",
    "since the diagraph only has two states , it is clear that as far prediction of the next epiword is concerned , only the last bit of any proword can ever matter .",
    "therefore , all words usually separate into two equivalence classes ( corresponding to odd and even words ) .",
    "if , however , @xmath73 then @xmath74 and @xmath75 .",
    "this always results in the two equivalence classes collapsing into one , giving a statistical complexity of zero , corresponding to pure noise .",
    "this is appropriate because in this degenerate situation the possible outcomes of node 0 in figure  [ pssnswtchdgrph ] are identical to those of node 1 and the diagraph collapses to a single state too ( see inset ) , and can only produce noise anyway .",
    "if the diagraph does not collapse in this way there will always be two equivalence classes .",
    "their prevalences are found to be @xmath76 and @xmath77 .",
    "thus , when @xmath78 , we have : @xmath79 } \\log_{2}\\left (   \\frac{\\alpha}{\\beta}+1\\right ) +   \\frac{1}{\\left [ \\frac{\\beta}{\\alpha}+1\\right ] } \\log_{2}\\left (   \\frac{\\beta}{\\alpha}+1\\right)\\end{aligned}\\ ] ] and if @xmath80 , @xmath0 is always zero . a graph of this function is shown in figure  [ pssnswtchsttstcclcmplxtvrssbs1 ] .",
    "note that it always evaluates to unity when @xmath81 , except when @xmath71 = @xmath82 .",
    "if @xmath71 does not equal @xmath72 ( and @xmath78 ) then it is less than unity .",
    "in fact , as the switch becomes more and more biased the statistical complexity goes down and down , reaching zero when only one digit is ever output .",
    "this is to be expected because a biased data set ( e.g. more ones than zeros ) is a symptom of an inefficient measurement apparatus : if one symbol is more prevalent than any other then the system is under - characterised by the alphabet in use . in the parlance of shannon s",
    "theory of communication this statistical complexity is equivalent to the maximum rate of information .    given that the collapse discussed above takes a slice out of the graph in figure  [ pssnswtchsttstcclcmplxtvrssbs1 ] , we would expect sequences generated by certain poisson switches to be more difficult to characterize .",
    "for example , sequences produced by a switch with @xmath83 have a statistical complexity of unity , but it is difficult to distinguish them from noise ( where @xmath84 ) because they are so close to the collapse at @xmath85 .",
    "such a sequence , 5000 symbols long , was analysed up to a wordlength of @xmath86 at 100 equal intervals between @xmath87 and @xmath88 , without assuming any noise was present ( i.e. @xmath89 and @xmath90 ) .",
    "the results are presented in figure  [ ab49pssnswtchsttstcclcmplxt ] .",
    "the plateau corresponding to the optimal model is that which has a statistical complexity of unity .",
    "we can see that it is difficult to construct this model because the plateau is radically constricted at higher wordlengths .",
    "on one side of it @xmath30 is too small to identify the equivalence classes , so every proword occupies its own equivalence class and @xmath91 , its maximum value at any wordlength @xmath11 . on the other side",
    ", @xmath30 is too large , so the two equivalence classes collapse together , producing degenerate models that would output noise .",
    "the @xmath92 plateau has a distinct end at @xmath93 because the sequence is not long enough to support analysis at a wordlength of @xmath94 .",
    "at the latter wordlength statistical fluctuations in every proword profile mean that the correct classification of equivalence classes is no longer possible at any range of @xmath30 .",
    "we are not too concerned about this here because we have already identified the optimal model which was stable from @xmath95 to @xmath93 .",
    "in fact , a `` more optimal '' model would be able to predict the flipping of the switch itself to some extent .",
    "the construction of such a model would probably need a lot of computation and would probably require @xmath4 to be very large .",
    "these things depend on how random or noisy the switch is .",
    "if a set of data is very complicated , no stable model might be identified before the wordlength becomes too large to be statistically supportable by the sequence length .",
    "the only solution is to gather more data .",
    "the alternative is to settle with models that are either inadequate or arbitrarily complicated .",
    "although the latter models reproduce structure well ( and are therefore most useful to engineers ) , studying them can reveal little about underlying processes .",
    "they are scientifically unaesthetic .",
    "in contrast , one can tell a lot about the intricacies of a system from the minimal adequate model associated with it at a certain level of analysis .",
    "this is the concern of scientists .",
    "the next class of labelled diagraphs we consider produce binary sequences that are simple models of a process with bursts .",
    "these sequences have the structure of sustained switches - that is , when the switch is down it has a constant probability of switching up , and when up , it stays up for a fixed count , @xmath96 .",
    "when the sequence is unbiased the up - switching probability is @xmath97 .",
    "see figure  [ 4smblsstndswtchdgrph ] for an example of this kind of labelled diagraph .",
    "the exact statistical complexities of such unbiased sustained switches are given by @xmath98 \\nonumber   \\\\ & = & \\frac{1}{\\ln(2)}\\left[\\ln(2u)-\\left(\\frac{u+1}{2u}\\right)\\ln(u+1)\\right]\\end{aligned}\\ ] ]    we now investigate the practical analysis of a sequence one million binary symbols long that was produced by a sustained switch with @xmath99 .",
    "the statistical complexities of the models constructed by the analysis are shown in figure  [ 4smblsstndswtchsttstcclcmplxt ] .",
    "it can be seen that the first convergent values are at wordlengths one greater than @xmath96 .",
    "that is to say , good models can be constructed when the analysis first has a greater memory than the system .",
    "the plateau identifiable with a model of the form shown in figure  [ 4smblsstndswtchdgrph ] begins at a wordlength of @xmath100 and extends laterally from @xmath101 to @xmath102 .",
    "the remarkable thing about this plateau is that , although it is very flat , it is not _",
    "entirely _ flat .",
    "it begins at @xmath103 which is significantly higher than the theoretical statistical complexity of : @xmath104\\approx1.54879   $ ] and subsequently oscillates around this value while it converges to it ( e.g. @xmath105 ) .",
    "this behaviour is caused by the phase ambiguity due to the absence of information concerning the synchronisation of a burst when a word is composed entirely of `` up '' symbols .",
    "for example , at wordlength six , the profile of word @xmath106 , ( i.e. , @xmath107 in binary ) , is a superposition of the profiles of sequences like @xmath108 $ ] , @xmath109 $ ] and @xmath110 $ ] , from each of which it can not be distinguished at that level of analysis .",
    "therefore , in this case , the profile of word @xmath106 does not match that of any other word , and is allocated its own equivalence class . although the prevalence of this word , and thence its class , is very low , it is sufficient to distort the statistical complexity .    in an analysis with recourse to infinite memory ,",
    "the prevalence of an infinite sequence of `` up '' symbols is zero .",
    "thus , the @xmath96 causal states of such a sequence would be correctly identified , and the statistical complexity of the model constructed would match exactly with the theoretical value .",
    "of course , in practice no analysis can have infinite memory .",
    "if one wishes to retain optimal predictability of future data then it is necessary to accept whatever model is actually constructed by an analysis with finite memory .",
    "the test data examples analysed in the previous section represent signal types thought to be present in time series measurements of the geomagnetic field .",
    "if this is true , we may expect to see similar structure emerging from a cm analysis of a real geomagnetic time series .    the cm analysis detailed in section  [ method ]",
    "was performed on 3-hour averaged measurements of the variation of the east - west component of the geomagnetic field at halley , antarctica , from three separate years : 24 february - 16 december , 1995 , 26 january - 28 december , 1998 , and 2 january - 30 december 2000 . a graph of the data from 26 january to 28 december 1998 is shown in figure  [ mgntcdflctn1998 ] .",
    "it can be seen that the magnetic deflections have both a linear trend and a high frequency signal with an annual amplitude modulation that maximises in the austral summer .",
    "the linear trend is caused by the movement of the ice shelf upon which halley is situated and was removed by subtracting the result of a linear regression for each of the three years .",
    "the detrended time series was then binarised with respect to the median , giving three sequences of 2352 , 2688 , and 2896 symbols , respectively .",
    "these series were then analysed up to a wordlength of 10 and with tolerances varying in 80 equal steps from 0.05 to 0.25 .",
    "words with prevalences less than @xmath111 were eradicated .",
    "the graph of statistical complexity , @xmath0 , is shown in figure  [ 180mntmgntcdflctnsttstcclcmplxt ] .",
    "two plateaus are evident , one at @xmath112 , covering a wide range of tolerances and between word lengths of 1 and 3 , and the other plateau at @xmath113 , at the top left - hand corner of the graph , between tolerances of about 0.05 and 0.07 and at word lengths of 8 or more .",
    "the convergence of statistical complexity at a word length of 8 corresponds to a time scale of 8 x 3 = 24 hours .",
    "such a diurnal variation is well known and is primarily caused by the rotation of the observing station with the earth under the so - called sq ionospheric current system that is driven by pressure gradients caused by solar heating and is thus fixed in the sun - earth frame @xcite .",
    "the variation can be seen in the raw data , as illustrated by plotting a typical month of halley geomagnetic data in figure  [ mgntcdflctn199802 ] .",
    "the associated ground magnetic variation has neither a pure sinusoidal shape nor a fixed period of exactly 24 hours , that is likely to account for the higher observed statistical complexity of @xmath114 compared to the expected @xmath115 for a pure binary period 8 signal .",
    "the other plateau in figure  [ 180mntmgntcdflctnsttstcclcmplxt ] at word lengths of 1 to 3 indicates the presence of significant structure at 3 to 9  h time scales .",
    "this plateau has a statistical complexity of approximately 0.9 and an overall structure similar to that of figure  [ ab49pssnswtchsttstcclcmplxt ] , suggesting the possibility of some random pulse - like process .",
    "such a possibility is intriguing because pulse - like geomagnetic perturbations on hour time scales ( known as magnetic bays ) are particularly prominent during the nighttime at high ( auroral zone ) latitudes and are associated with magnetospheric substorms @xcite whose occurrence has been argued to be a stationary poisson process with mean recurrence time of 5 h @xcite .",
    "figure  [ mgntcdflctn19980616 ] shows a single day of halley geomagnetic data that illustrates the presence of such pulse - like disturbances on hour time scales sitting on top of the diurnal variation .    to investigate this further",
    ", an analysis was made of a 40-minute averaged time series of the east - west component of the geomagnetic field at halley from 00:00 ut , 25 january , 1998 to 00:00 ut , 26 december , 1998 .",
    "after removing the linear trend in the data due to the movement of the ice shelf , the time series was binarised with respect to the median , giving a sequence of 12011 symbols .",
    "the series was analysed up to a word length of 11 for tolerances in 60 equal steps between 0.00 and 0.15 .",
    "words with prevalences less than @xmath116 were eradicated .",
    "the graph obtained for @xmath0 is shown in figure  [ 40mntmgntcdflctnsttstcclcmplxt ] .",
    "the plateaus in this graph are stable to variation of @xmath51 .",
    "the higher plateaus have models that are more useful for prediction of future data , if they are stable to an increase in the amount of data available to the analysis .",
    "the lower plateaus have models that show the most dominant structures  and are easier to understand and interpret physically .",
    "it can be seen from the graph that , at a tolerance between @xmath117 and @xmath118 , more structure is identified between wordlengths six and eight than it was possible to resolve with a memory of only five symbols . the model which corresponds to this plateau",
    "is represented , for a wordlength of seven , in figure  [ 40mntmgntcdflctndgrph ] .",
    "the details of the model are in the appendix .",
    "comparing with figure  [ pssnswtchdgrph ] , the transitions between states 0 and 1 of this diagraph are an approximately poisson - switched process with a timescale of about five hours .",
    "this value is given by the range of wordlengths capable of resolving this structure from the sequence within this range of @xmath30 ( @xmath119 ) ; at @xmath86 the characteristic timescale is @xmath120 .",
    "it was thought that the other states and transitions in figure  [ 40mntmgntcdflctndgrph ] would be caused by the diurnal variation of the data alone .",
    "this was investigated by analysing , in exactly the same way , a pure binary sequence with a period of 36 symbols  corresponding to a period of one day if each symbol were to represent a 40-minute average . the principal transitions of the model constructed for this sequence are shown in the diagraph drawn in figure  [ prd36dgrph ] .",
    "the structural similarities and differences between this diagraph and the one in figure  [ 40mntmgntcdflctndgrph ] are obvious , and support the idea that the transitions between states 0 and 1 of figure  [ 40mntmgntcdflctndgrph ] are due to substorm activity , rather than merely being an artifact of a partially characterised 24-hour period .",
    "in the previous sections , we have demonstrated how cm can measure the statistical complexity of linear data sequences and construct the minimal model necessary to describe the data .",
    "the reader may have noticed that there are seven degrees of freedom in making such a model :    1 .",
    "digitisation method ( binary , trinary , etc ) 2 .",
    "coarse - graining scale , @xmath2 3 .   sequence length , @xmath6 4 .",
    "wordlength , @xmath11 5 .",
    "tolerance , @xmath30 6 .",
    "corruption frequency , @xmath42 7 .",
    "expletive frequency , @xmath51    these degrees of freedom express the level of information in the data and the depth of knowledge with which the model is probing the system from which the data are measured .",
    "for example , increasing the sequence length , @xmath6 , reducing the coarse - graining scale , @xmath2 , or increasing the digitisation from binary to trinary , all provide increased information and thereby increased knowledge of the system that the data represent .",
    "conversely , increasing the tolerance or the expletive frequency reduces information by admitting different states to be equivalent or to be omitted , respectively , thereby reducing knowledge of the system .",
    "consequently , we might anticipate that the best model of the system is the model corresponding to the region of the multi - dimensional parameter space in which information is maximised .",
    "whilst such a model is the most accurate description of the data sequence with the greatest information content , it is not necessarily the optimal model of the system .",
    "this is because any data sequence is not a complete representation of the system it is measured from . in particular , it is limited in two important respects : first , there is structure in a data sequence , that we have termed noise , that can not be resolved under any amount of computation .",
    "this will create differences in the profiles of words that are statistically insignificant and should be ignored by allowing some non - zero value of tolerance , corruption frequency or expletive frequency .",
    "second , there is structure in a data sequence , that we have termed random , that has not been resolved at a certain level memory or wordlength but that is resolvable at a greater wordlength .",
    "recognising these sources of structure , we advance a hypothesis about model construction :    _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ given enough data relevant to a system , there exists at least one connected region of finite size in the space of parameters used to construct models from those data within which an optimal model of the system is constructed .",
    "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _    in other words , meaningful models of the data can only be found within certain , usually finite , zones of the parameter space@xcite . within each zone , @xmath0 is constant and the model is both stable and minimal . outside this zone , the model is either too degenerate or overly complicated .",
    "for example , it will be degenerate ( and @xmath0 will be too low ) if @xmath30 is set too large .",
    "this is because equivalence classes will collapse into one another .",
    "similarly , the model will be unnecessarily complicated ( and @xmath0 will be too high ) if @xmath30 is set too small .",
    "this is because distinctions will be made between words on the basis of insignificant differences in their profiles .",
    "an analogy is the construction of a vocabulary for the structure of speciation of feline animals .",
    "if one is too fussy about the tail , manx cats can not be classed as domestic cats .",
    "if one s sole criterion is purring or a meow , a lion cub may be misclassed as a domestic cat .",
    "the correct classification of feline animals needs a finite amount of information to fall within the boundaries of a finite number of provisos .    in the case of computational mechanics",
    "we interpret effectively sofic models to be optimal .",
    "thus we seek plateaus in the multi - dimensional parameter space .",
    "generally , this space can contain many plateaus , the heights of which are the corresponding models statistical complexities .",
    "if we want to forecast the data most accurately , we are looking for the highest plateau , which has the most stringent conditions@xcite .",
    "more physically understandable models may exist on some lower plateaus where only the more dominant causal structures are preserved .",
    "thus , in the end , the success of the analysis depends upon the existence of effectively sofic plateaus of statistical complexity in the multi - dimensional parameter space and our ability to discover them .",
    "this is contingent upon the data that are supplied and how much computing power is available .",
    "it is important to bear in mind that the data are not only a function of the physical system s behaviour , but also of the measurement apparatus and any pre - processing .",
    "there are four main pitfalls ( represented by corresponding model parameters ) :    1 .",
    "mischaracterization of the system by the measurement apparatus ( @xmath121 ) 2 .",
    "degradation of data prior to the analysis by processing ( @xmath2 ) 3 .",
    "insufficient data to resolve all structure present ( @xmath6 ) 4 .",
    "insufficient computing power to resolve random structure ( @xmath122 )    the apparatus may easily mischaracterize the system , either by introducing structure to the data which is foreign to the system s behaviour , or by neglecting to transcribe structure that should be present .",
    "this situation is most apparent when the apparatus is clearly only taking measurements from a cross - section of the system .",
    "nevertheless , if it is reasonable to assume in a particular case that the apparatus is capable of providing a good representation , then identified structure can be attributed to the system . in such cases we would also expect the statistical complexity to scale with the system s true complexity .",
    "naturally , this is not valid when the cross - section happens to be an exact sub - system .",
    "although all processing degrades data , it may still be possible to correctly characterize all the structure present .",
    "this is because the degradation will usually produce noise , which can be ignored .",
    "a graver problem is when ( uncharacterizable ) noise represents some of the system s structure .",
    "the only solution may be to collect more data , but other preliminary approaches are to use a finer scale when coarse - graining and/or to digitise more finely .",
    "however , it is always necessary to choose sensible margins for the parameter search because some regions of the parameter space are computationally very costly to explore .",
    "for example , a trinary sequence is about seven hundred times as hard to fully analyse at a word length of eight than a binary sequence .",
    "you must have a good reason not to use binary .",
    "an alternative approach may be useful when the data have a number of widely separated scales with structure ; it may be more computationally efficient to construct higher - level equivalence classes than to persist with using longer and longer words .",
    "if this is the case there will be a change in the constant increase of @xmath0 with wordlength at the wordlength where the lower scale of structure is found , but the gradient will thereafter remain constant ( until the next scale of structure is reached ) .",
    "classes on the next highest level are found by applying the same analysis method to the sequence expressed in terms of a set of primary level causal states for which @xmath0 has not yet converged .",
    "all information between the scales @xmath123 and @xmath124 is lost in this process .",
    "even so , it is a more preferable approach than simply further coarse - graining the data to intervals of @xmath123 if one has reason to believe that the system s degrees of freedom at the two scales are coupled .",
    "the total statistical complexity is the sum of those calculated at each level , so it is in fact possible to test for such coupling by comparing the coarse - grained @xmath0 with the hierarchical value .",
    "there is actually no reason why the prowords and epiwords should not come from different sequences , enabling the direct causal correlation of two systems , such as the solar wind and the magnetosphere .",
    "computational mechanics is an intuitive and powerful way to study complicated linear outputs from physical systems .",
    "this is because the analysis identifies causal structure from data presented to it and constructs the minimal adequate model that fits these data .",
    "the information about this structure , and in particular its scales , can then be used to optimise more physically plausible models . in this paper",
    "we have discussed in detail how the original formalism has to be used when applied to non - infinite sequences .",
    "the main conclusion is that models constructed by computational mechanics are good if , and only if , they are stable to the variation of the parameters used to construct them from the data . in addition , various more general postulates and definitions are made .",
    "these concern the general constructibility of models from a set of observations :    1 .",
    "structure which can not be resolved from a set of data under any amount of computation is most usefully called _ noise _ 2 .",
    "structure which has not been resolved at a certain level of computation or memory , but which is resolvable from the set of data is usefully called _ random _ 3 .   given enough data relevant to a system , there exists at least one connected region of finite size in the space of parameters used to construct models from those data within which an optimal model of the system is constructed .",
    "the prior undecidability of whether unresolved structure is noise or randomness is a direct parallelism of gdel s famous theorem . for a proof relating the two fields , but in a slightly different context , see g.j .  chaitin@xcite .",
    "the method developed in this paper was applied to magnetometer measurements of ionospheric currents for the years 1995 , 1998 and 2000 .",
    "the technique successfully constructed models , the simplest of which comprised a diurnal component and a poisson - switched process with a timescale of about five hours that likely relates to the occurrence of magnetic substorms .",
    "the most complicated model could be used to forecast space weather .",
    "a similar method was also proposed to characterize the causal relationship of any two systems , such as the solar wind and the magnetosphere .",
    "details of the simple stable model at wordlength seven , @xmath125 .",
    "@xmath116 , at which value 114 of 128 words are cut .",
    "+       word number ( class ) & word & probability + 0 ( 0 ) & 0000000 & 0.481382 + 1 ( 1 ) & 0000001 & 0.0759726 + 3 ( 1 ) & 0000011 & 0.0729505 + 7 ( 1 ) & 0000111 & 0.0641128 + 15 ( 1 ) & 0001111 & 0.0540634 + 31 ( 1 ) & 0011111 & 0.0546018 + 63 ( 1 ) & 0111111 & 0.0532191 + 64 ( 0 ) & 1000000 & 0.0338069 + 96 ( 0 ) & 1100000 & 0.0234980 + 127 ( 2 ) & 1111111 & 0.0514929 +     word number ( class ) & word & probability + 0 ( 0 ) & 0000000 & 0.0423272 + 64 ( 0 ) & 1000000 & 0.0291209 + 96 ( 0 ) & 1100000 & 0.0209377 + 112 ( 0 ) & 1110000 & 0.0209523 + 120 ( 0 ) & 1111000 & 0.0293505 + 124 ( 0 ) & 1111100 & 0.0442261 + 126 ( 0 ) & 1111110 & 0.0822315 + 127 ( 2 ) & 1111111 &",
    "0.684994 +     word number ( class ) & word & probability + 0 ( 0 ) & 0000000 & 0.0789801 + 64 ( 0 ) & 1000000 & 0.0907960 + 96 ( 0 ) & 1100000 & 0.0945274 + 112 ( 0 ) & 1110000 & 0.103234 + 120 ( 0 ) & 1111000 & 0.108831 + 124 ( 0 ) & 1111100 & 0.105721 + 126 ( 0 ) & 1111110 & 0.101990 + 127 ( 2 ) & 1111111 & 0.268035 +     class & average word & probability + 0 & [ 0.161 , 0.102 , 0.061 , 0.040 , 0.027 , 0.009 , 0.000 ] & 0.573587 + 1 & [ 0.000 , 0.142 , 0.288 , 0.432 , 0.603 , 0.797 , 1.000 ] & 0.374920 + 2 & [ 1.000 , 1.000 ,",
    "1.000 , 1.000 , 1.000 , 1.000 , 1.000 ] & 0.051493 +     class & average word & probability + 0 & [ 0.843 , 0.735 , 0.657 , 0.579 , 0.470 , 0.306 , 0.000 ] & 0.269146 + 1 & [ 0.000 , 0.309 , 0.444 , 0.590 , 0.714 , 0.906 , 1.000 ] & 0.045860 + 2 & [ 1.000 , 1.000 , 1.000 , 1.000 , 1.000 , 1.000 , 1.000 ] & 0.684994 +     class & average word & probability + 0 & [ 0.885 , 0.752 , 0.614 , 0.463 , 0.304 , 0.149 , 0.000 ] & 0.684080 + 1 & [ 0.000 , 0.117 , 0.221 , 0.325 , 0.532 , 0.701 , 1.000 ] & 0.047886 + 2 & [ 1.000 , 1.000 , 1.000 , 1.000 ,",
    "1.000 , 1.000 , 1.000 ] & 0.268035 +                                          for the unbiased poisson switch , see the discussions of the  random telegraph \" in j.s .",
    "bendat , principles and applications of random noise theory , john wiley and sons , new york , 1958 , and of the poisson switch in h.j .",
    "jensen , self - organized criticality , cambridge university press , 1998 .",
    "if we had been considering infinite sofic sequences this zone would be always be infinitely big because all structure would be resolved after a certain wordlength , and would continue to be resolvable .",
    "this does not usually apply to finite sofic sequences because beyond a certain threshold wordlength statistical fluctuations in the profiles are able to destroy the equivalence classes .",
    "engineers would usually settle for that model constructed by the highest level of analysis , whether of not it is on a plateau .",
    "this is not acceptable from a scientific perspective because there is no way to justify that such models are not totally arbitrary ."
  ],
  "abstract_text": [
    "<S> we discuss how the ideal formalism of computational mechanics can be adapted to apply to a non - infinite series of corrupted and correlated data , that is typical of most observed natural time series </S>",
    "<S> . specifically , a simple filter that removes the corruption that creates rare unphysical causal states is demonstrated , and the new concept of effective soficity is introduced . </S>",
    "<S> we believe that computational mechanics can not be applied to a noisy and finite data series without invoking an argument based upon effective soficity . </S>",
    "<S> a related distinction between noise and randomness is also defined : noise can only be eliminated by increasing the length of the time series , whereas the resolution of random structure only requires the finite memory of the analysis to be increased . </S>",
    "<S> the benefits of these new concepts are demonstrated on simulated times series by ( a ) the effective elimination of white noise corruption from a periodic signal using the expletive filter and ( b ) the appearance of an effectively sofic region in the statistical complexity of a biased poisson switch time series that is insensitive to changes in the wordlength ( memory ) used in the analysis . the new algorithm </S>",
    "<S> is then applied to analysis of a real geomagnetic time series measured at halley , antarctica . </S>",
    "<S> two principal components in the structure are detected that are interpreted as the diurnal variation due to the rotation of the earth - based station under an electrical current pattern that is fixed with respect to the sun - earth axis and the random occurrence of a signature likely to be that of the magnetic substorm . in conclusion , </S>",
    "<S> a hypothesis is advanced about model construction in general . </S>"
  ]
}