{
  "article_text": [
    "large - scale structure statistics , especially power spectra , provide precise constraints on cosmological theories .",
    "accurate measurements are now possible with large - volume surveys and advancing computational power .",
    "however , the measured power spectrum is not the only required ingredient for estimating cosmological parameters ; the covariance matrix also carries a great deal of information that is vital for properly estimating parameter values and their confidence intervals .",
    "observational effects such as the survey geometry , redshift - space distortions , and non - linear clustering make theoretical modeling of the covariance matrix difficult , and often simulations are used to study them in detail .",
    "covariance matrices estimated from a finite number of simulations will contain noise .",
    "cosmological parameter estimation requires the inverse of the covariance matrix to properly weight the measurements .",
    "matrix inversion is an inherently non - linear operation that is sensitive to the noise of all the elements .",
    "@xcite showed that when the off - diagonal elements of a covariance matrix are excessively noisy it is better for parameter estimation to use a diagonal approximation of the covariance .",
    "this reduces the effects of noise , but ignores important information in the covariance .",
    "covariance matrices for large - scale structure measurements are often estimated using the unbiased empirical covariance matrix , @xmath0 ( see equation  [ eq : cov ] ) , a close relative of the maximum - likelihood estimator , @xmath1 .",
    "these estimators work well in the regime where the number of repeat observations , @xmath2 , is much greater than the number of parameters measured for each observation , @xmath3 .",
    "however , in the regimes where @xmath4 or @xmath5 the covariance matrix estimates become ill - conditioned and unstable during inversion , which is necessary for optimal weighting of the data .",
    "this is an indication that these estimators do not produce good approximations of the true underlying covariance matrix in these regimes .",
    "@xcite provides some insight into the difference between maximum - likelihood as a _",
    "summarizer _ and as an _",
    "estimator_. maximum - likelihood is an excellent summarizer of data in the sense of trying to represent the important statistical information about a dataset in a small set of numbers . though maximum - likelihood is asymptotically optimal for estimation in the limit of infinite data , the use of this summary of information for the purpose of making estimates with a finite set of data is not always the best option .",
    "@xcite proved that one can construct estimators in high - dimensional ( @xmath6 ) inference problems that outperform maximum - likelihood estimators in the sense of minimizing the _ total _ mean squared error .",
    "maximum - likelihood produces the best estimates of individual parameters , but the alternatives can often reduce the error on many of the parameters while only slightly increasing the error on a few , resulting in an overall improvement .",
    "@xcite also showed that the maximum likelihood estimator has the best performance among estimators that transform correctly under translation , implying that any estimator that outperforms maximum - likelihood will necessarily involve an arbitrary choice .",
    "@xcite employ a method known as _ shrinkage estimation _ to construct covariance matrices for functional genomics measurements in the @xmath5 regime .",
    "their technique optimally combines a high - dimensional estimate that has little or no bias with a low - dimensional estimate that may be biased but has much less variance .",
    "the result minimizes the total mean squared error , which is the sum of bias ( squared ) and variance .",
    "they argue that their method can also perform some amount of regularization , resulting in a covariance matrix that has a full set of positive - definite eigenvalues and is well - conditioned ( i.e. , the ratio of the largest to smallest eigenvalue is not so large that inversion becomes unstable ) .",
    "they employ a lemma from @xcite to analytically calculate the optimal linear combination of the low and high dimensional estimates .    in this paper",
    "our goal is to provide a simple recipe for using shrinkage estimation to improve the covariance matrix of the matter power spectrum from a limited number of simulations over the ubiquitous sample covariance estimator .",
    "our method aims to reduce the total noise while retaining as much information about real covariance in the simulations as possible .",
    "shrinkage estimation achieves this by optimally combining a theoretical model with the empirical estimate .",
    "we will assess the improvements our method offers by examining the performance of the covariance matrices through inversion and use in cosmological parameter estimation .",
    "although we focus on the matter power spectrum , the shrinkage technique is relevant for many studies in large - scale structure and cosmology .",
    "the outline of this paper is as follows : in section  [ sec : shrink ] we introduce shrinkage estimation and describe its application to covariance matrices . section  [ sec : toy ] applies the shrinkage technique to several toy problems before moving to a more complicated example involving galaxy clustering .",
    "we describe our technique for measuring matter power spectra from n - body simulations in section  [ sec : sims ] . in section  [ sec : results ] we construct several estimates of the power spectrum covariance matrix and compare their performance by estimating cosmological parameters .",
    "finally we review our results , make recommendations , and discuss future directions of this project in section  [ sec : disc ] .",
    "much of this section summarizes the introduction to shrinkage estimation given in @xcite .",
    "suppose we are estimating a vector @xmath7 ( of length @xmath3 ) from a set of @xmath2 measurements using two different models .",
    "one of the models has many free parameters and produces an estimate , @xmath8 , with little ( or no ) bias , but the variance may be significant due to the number of free parameters . the second model ( called the _ target _ ) has many fewer ( or no ) free parameters and produces an estimate , @xmath9 , which will have smaller variance but may be biased .",
    "we construct a new estimate , @xmath10 , from a linear combination of these two models , given by @xmath11 where @xmath12 $ ] is called the _",
    "shrinkage intensity_. the question now becomes how to choose @xmath13 in an optimal way . a common way to optimize an estimator",
    "is to minimize the expected mean squared error , given by the risk function @xmath14 where the angle brackets indicate the expectation value .",
    "@xcite introduced an analytic solution for the optimal shrinkage intensity , @xmath15 . prior to this solution shrinkage estimation was much less practical because numerically complicated and expensive methods were necessary to find the optimal shrinkage intensity .",
    "the analytic solution is @xmath16 where @xmath17 , @xmath18 , and @xmath19 are the true variance , covariance , and bias , respectively . for a practical estimator ,",
    "@xcite suggest estimating @xmath20 as @xmath21 where @xmath22 , @xmath23 , and @xmath24 are the unbiased sample estimates of @xmath17 , @xmath18 , and @xmath19 , respectively . the @xmath19 term can be ignored if @xmath8 is an unbiased estimator .",
    "[ cols= \" < , < , < , < , < , < , < , < , < , < , < , < , < , < \" , ]     the mean and standard deviation of the estimates of the maximum - likelihood estimate , @xmath25 , and the one - sigma error bar , @xmath26 , using different methods to estimate the covariance matrix .      as a reference we estimate the covariance matrix of our power spectrum measurement by applying equation  [ eq : cov ] to our measurements from all 4096 sub - volumes",
    ". there are @xmath27 independent elements in the covariance matrix , thus we are in the regime where we have many more realizations than elements to be estimated and the usual covariance estimator should give reasonable results . the solid black line in fig .  [ fig : s8mc ] is a histogram of the results of estimating @xmath25 using the reference covariance matrix and the power spectra measured from each of the 4096 sub - volumes .",
    "the upper panel shows the distribution of @xmath25 and the lower panel shows the distribution of the error bar estimates ( absolute value of both upper and lower ) .",
    "the mean and standard deviation of these histograms is presented in table  [ tab : s8 ] .",
    "the agreement between the width of the best - fit distribution , @xmath28 , and the mean error bar estimate , @xmath29 , indicates that the covariance matrix is properly estimating the likelihood distribution .",
    "the width of the error bar distribution , @xmath30 , is small , indicating that the error bar estimate is usually very close to the correct value .",
    "the mean of the maximum - likelihood estimates , @xmath31 , is @xmath32 instead of our known input value of @xmath33 , but we know that our modeling of the power spectrum into the non - linear regime is not perfect so this small offset is not worrisome for our purposes . for the remainder of this section",
    "we assume that the results using the reference covariance matrix are a good approximation to those that would be obtained using the true underlying covariance matrix .",
    "see section  [ sec : disc ] for further discussions .      , and error bar , @xmath26 , estimates for the reference , monte carlo ( mc ) , monte carlo target only ( target ) , and the monte carlo + shrinkage ( mc+s ) covariance matrix estimates . ]",
    "next we test covariance matrices estimated with equation  [ eq : cov ] but using a small number of sub - volumes , which we call the monte carlo method .",
    "we use sets of 40 ( randomly chosen , non - overlapping ) sub - volumes to test the regime where we have more simulations than diagonal elements of the covariance matrix ( 18 ) , but fewer simulations than independent elements ( 171 ) . from 4096 sub - volumes",
    "we can create 102 separate covariance matrix estimates . to obtain smooth histograms in fig .",
    "[ fig : s8mc ] we test each covariance matrix estimate against 40 randomly chosen @xmath34 measurements from other sub - volumes . the statistics in table  [ tab : s8 ]",
    "are calculated using one randomly chosen @xmath34 measurement per covariance matrix .",
    "the statistics do not depend on how many randomly chosen @xmath34 measurements are used for each covariance matrix estimate .",
    "the upper panel of fig .  [ fig : s8mc ] shows that the distribution of @xmath25 is too wide , indicating that a parameter analysis using a covariance matrix estimated with this method will often return a value far from the mean .",
    "the lower panel of fig .",
    "[ fig : s8mc ] shows that the error bar is typically underestimated by @xmath35 .",
    "the width of the estimated error bar distribution is also much wider than for the reference covariance matrix estimate .",
    "these effects are the result of using a very noisy estimate of the covariance matrix .",
    "our first test of the shrinkage approach is to apply shrinkage estimation to the monte carlo method described in the previous section .",
    "first we need to choose a target covariance matrix , @xmath36 . in linear theory",
    "we expect the covariance matrix of the power spectrum to be diagonal .",
    "off - diagonal terms arise in practice from the survey window function and non - linear clustering effects .",
    "we use a diagonal target matrix to simulate a situation where we have some idea about the structure of the covariance matrix but we know our model is not exact . our target matrix takes the form @xmath37",
    "^ 2/n_i & \\langle k_i \\rangle",
    "\\leq 0.14~{\\rm h / mpc}\\\\ s_{ii } & \\langle k_i \\rangle > 0.14~{\\rm h / mpc } \\end{array } \\right .",
    "\\label{eq : target}\\ ] ] where we use a different method in the linear and non - linear regimes . for bins in the linear regime",
    "we use our convolved model for the power spectrum , @xmath38 , and the number of @xmath39 modes in each bin , @xmath40 , to predict the covariance ( e.g. , * ? ? ?",
    "in the non - linear regime we use the diagonal of the empirically estimated covariance from the 40 sub - volumes .",
    "[ fig : cov ] shows the diagonal elements of the reference covariance matrix , the linear theory model , and the 102 target matrices .",
    "inset is the reference correlation matrix , @xmath41 , showing that the covariance matrix is strongly diagonal until well into the non - linear regime .",
    "our results are robust to changes in the non - linear cutoff by several bins in either direction .",
    "we calculate the optimal shrinkage intensity , @xmath20 , for each of the 102 monte carlo estimates , @xmath0 , according to equation  [ eq : lshat ] .",
    "we apply the @xmath42 term to the diagonal elements of @xmath36 that are taken from @xmath0 .",
    "we find values for @xmath20 distributed evenly between @xmath43 and @xmath44 ( see fig .  [",
    "fig : lambda ] ) .",
    "we produce each of our 102 new estimates of the covariance matrices , @xmath45 , from a linear combination of @xmath0 and @xmath36 according to equation  [ eq : scov ] .",
    "we perform the same tests as described in section  [ sub : mc ] and compare the results in fig .",
    "[ fig : s8mc ] and table  [ tab : s8 ] .",
    "the most striking result is that the maximum - likelihood estimates , @xmath25 , follow a very similar distribution to that for the reference matrix , indicating that the parameter values are now correctly estimated .",
    "the error bars are still underestimated , but the distribution is very similar to that for the normal monte carlo estimator .",
    "[ fig : s8mc ] and table  [ tab : s8 ] also show results using only the diagonal target .",
    "the values of @xmath25 follow the correct distribution , indicating that the estimated parameter values are fine , but the error bars are much more severely underestimated .",
    "this is expected because our target matrix is diagonal and we are using information from far enough into the non - linear regime to know that we are missing some important covariance .",
    "it is now clear that the estimated error bar distribution of the shrinkage estimator is a combination of the monte carlo and target distributions .",
    "the shrinkage intensity can serve as a proxy for whether the estimated error bars are likely to be similar to those for the monte carlo or the target .",
    "see section  [ sec : disc ] for further discussions .    in summary ,",
    "the shrinkage of the empirically estimated covariance against our target matrix outperforms either matrix by itself . using just the empirically estimated covariance brings in too much noise which causes error in the estimation of @xmath25 itself .",
    "using only the diagonal target mitigates the noise problems , but ignores important covariance .",
    "the shrinkage estimator uses the best aspects of both , keeping the part of the covariance that is well estimated but drastically reducing the total amount of noise .      , and error bar , @xmath26 , estimates for the reference , jackknife ( jk ) , jackknife target only ( target ) , and the jackknife + shrinkage ( jk+s ) covariance matrix estimates . ]",
    "recently a resampling technique know as the jackknife method has been used to estimate covariance matrices for large - scale structure measurements from the data set itself .",
    "the method works by dividing the data volume into @xmath2 cells of roughly the same size and recalculating the measurement @xmath2 times , each time with a different cell left out .",
    "the variance between the measurements can be adjusted to try and calculate the variance corresponding to the entire volume . in practice one",
    "replaces equation  [ eq : wkij ] with @xmath46 and then calculates the covariance matrix with equation  [ eq : wcov ] , resulting in the usual @xmath47 we divided each sub - volume into @xmath48 cells and modified our code to calculate the power spectrum with one cell removed .",
    "our code incorporates a volume correction , the lowest order edge correction in fourier space . for each of the 4096 sub - volumes we estimate @xmath25 and @xmath26 using the power spectrum and the jackknife covariance matrix from the same sub - volume .",
    "the results are compared to the reference case in fig .",
    "[ fig : s8jk ] and listed in table  [ tab : s8 ] .",
    "the distribution of @xmath25 is much wider than for the reference covariance matrix , indicating that the noise in the covariance estimate causes incorrect parameter estimation .",
    "this is similar to the result for the monte carlo method .",
    "the jackknife estimates of @xmath25 also peak at a noticeably lower value than for the reference covariance , though the two histograms are in roughly @xmath49 agreement given the width of the distribution for the jackknife case .",
    "the error bars estimated in the jackknife case are typically underestimated by a factor of almost three compared to the reference covariance matrix and nearly an order of magnitude compared to the actual width of the jackknife distribution of @xmath25 .      our final method of estimating the covariance matrix applies shrinkage to the jackknife estimator to see if we can achieve enhanced robustness .",
    "we use the same method to construct a target matrix as described in section  [ sub : mcs ] , using the diagonal of the jackknife estimated covariance matrix in the non - linear regime .",
    "we calculate the shrinkage intensity , @xmath20 , and covariance estimate for each of the 4096 covariance matrices as described in section  [ sub : shrinkcov ] , but substituting equation  [ eq : jkwkij ] for equation  [ eq : wkij ] throughout .",
    "we find values for @xmath20 distributed evenly between @xmath50 and @xmath44 ( see fig .",
    "[ fig : lambda ] ) .",
    "we run the same tests as described in section  [ sub : jk ] and the results are shown in fig .",
    "[ fig : s8jk ] and table  [ tab : s8 ] .    as with the shrinkage version of the monte carlo estimator , the shrinkage version of the jackknife estimator shows significant improvement in the actual estimated parameter , @xmath25 .",
    "however , the central value and width are not quite as good as for the reference case .",
    "there is some improvement in the estimation of the error bar , though the error bars are still systematically underestimated by a factor of roughly two compared to the reference .",
    "[ fig : s8jk ] and table  [ tab : s8 ] also show the results of estimating @xmath25 and @xmath26 using only the diagonal targets used in the shrinkage version of the jackknife estimator .",
    "again , the diagonal target matrix does well for estimating @xmath25 due to the lack of noise , but it gives the worst estimates of the error bars .    in this case , the shrinkage version of the jackknife estimator did the best job of estimating the error bars , and it was only slightly worse than the diagonal approximation at recovering the distribution of @xmath25 .",
    "again , shrinkage estimation is doing an excellent job of keeping information about covariance while reducing the total noise .",
    "we have introduced shrinkage as a technique for improving estimates of the covariance matrix for power spectrum measurements .",
    "we tested our methods on dark matter simulations and showed improvement over the empirically estimated covariance matrix from a limited number of simulations or jackknife resamplings . in order to clearly assess the potential improvement from using shrinkage estimation , we chose an intentionally difficult scenario where traditional methods of estimating the covariance were unlikely to yield satisfactory results .",
    "all of these methods would perform better if we allowed ourselves more simulations per monte carlo estimate or if we did not push as far into the non - linear clustering regime .",
    "the shrinkage technique would still outperform the other methods , but perhaps the differences would be less obvious .",
    "a good estimate of the covariance matrix of a power spectrum measurement is essential for extracting cosmological information via parameter fitting . including the covariance between different bins is a good step towards properly estimating the confidence intervals on cosmological parameters .",
    "however , the increased number of free parameters of a full covariance estimate ( as opposed to a diagonal approximation ) can cause the covariance estimate to be noisy if only a relatively small number of simulations are available",
    ". this noise can adversely affect the estimate of the parameter itself . a diagonal approximation to the covariance",
    "can be more easily constrained with a limited number of simulations , leading to better estimates of the parameter values .",
    "however , the confidence intervals can be severely underestimated if actual covariance is ignored . neither alternative is appealing .",
    "if a similar measurement was performed with the two - point correlation function , the fourier dual of the power spectrum , a full covariance matrix is especially important as bins will be strongly correlated , even in the linear clustering regime .",
    "realistic survey geometries will also cause additional covariance on large scales for the power spectrum .",
    "shrinkage estimation is an optimal way of combining a model with many degrees of freedom and a model with few degrees of freedom to minimize the total error on the covariance estimate . in our example",
    "the shrinkage versions of the monte carlo and jackknife estimators clearly outperformed their counterparts without shrinkage , with the shrinkage version of the monte carlo estimator producing the best results .",
    "the lemma of @xcite as employed by @xcite allows a mathematically and numerically simple way of calculating the optimal shrinkage intensity .",
    "this means that there is minimal addition work required to use a shrinkage version of a covariance estimator .",
    "shrinkage estimation can result in a massive improvement in the limit of a small number of simulations and will not adversely affect the covariance estimate in the limit of a large number of simulations .",
    "for these reasons we always recommend the use of the shrinkage versions of covariance estimators in all regimes .",
    "we briefly investigated the effects of shrinkage estimation in the limit of a large ( though not infinite ) number of simulations .",
    "we applied shrinkage estimation to our reference covariance matrix estimated from all 4096 sub - volumes using the target from equation  [ eq : target ] and found an optimal shrinkage intensity @xmath51 .",
    "this number is the same order as the relative noise we expect in each element of the matrix , @xmath52 .",
    "we then calculated the eigensystems of both matrices .",
    "the dot products of the corresponding eigenvectors always exceeded @xmath53 , indicating that they are essentially identical .",
    "the ( sorted ) eigenvalue spectra are shown in fig .",
    "[ fig : eigen ] .",
    "the eigenvalues are the same to within @xmath54 for the first 10 eigenmodes .",
    "after the tenth eigenmode the eigenvalues from the reference matrix become increasingly smaller compared to the shrinkage version . by the final eigenmode the difference is @xmath55 .",
    "the shrinkage version of the reference matrix should be a more accurate estimate of the true underlying covariance matrix .",
    "the non - linear nature of matrix inversion can cause errors @xmath56 even when individual elements of the covariance matrix are estimated to @xmath57 .",
    "we ran our parameter estimation test using the shrinkage version of the reference matrix and found that @xmath31 moved by less than @xmath58 .",
    "this is small compared to the width of the distribution , which is @xmath59 .",
    "the average minimum @xmath60 did improve from @xmath61 to @xmath62 with the shrinkage version of the covariance matrix , though this is still large for @xmath63 degrees of freedom .",
    "the remaining discrepancy is dominated by bias from problems with modeling the power spectrum into the non - linear regime or power loss in the simulation at smaller scales due to low resolution , not a grossly inaccurate estimate of the variances .",
    "the amplitude is mainly sensitive to smooth eigenmodes , which have large eigenvalues , so there is little change in the estimated value .",
    "parameters that are more sensitive to the shape of the power spectrum may be more sensitive to the lower eigenvalue modes and show more than a @xmath54 change . the impact of these differences could be estimated with a study of the information content of the power spectrum covariance in terms of cosmological parameter confidences ( i.e. , @xcite ) , but this is beyond the scope of this paper .",
    "we employed a very simple diagonal target matrix in this paper , but better targets can clearly improve the efficiency of the shrinkage technique . a much more realistic model for covariance on small scales",
    "could be constructed using the halo model . for realistic measurements",
    "it may also be advantageous to model some of the effects of survey geometries , redshift - space distortions , and clustering bias .",
    "targets that depend on a small number of free parameters may be very useful for some of these effects ( e.g. , clustering bias ) .",
    "targets can also be developed for a wide range of large - scale structure measurements in addition to the power spectrum .",
    "the exploration of more sophisticated targets is beyond the scope of this paper and is left to future studies .",
    "ultimately we would like to develop more diagnostics of the performance of our covariance estimates .",
    "[ fig : lambda ] shows the estimated error bar , @xmath26 , as a function of the shrinkage intensity , @xmath20 , for the shrinkage versions of the monte carlo and jackknife estimators .",
    "there is clearly some correlation for the shrinkage version of the monte carlo estimator , so knowledge of @xmath20 could help one gauge how much the error bars are underestimated .",
    "the exploration of such diagnostics should proceed as better targets are developed .",
    ", as a function of the shrinkage intensity , @xmath20 , for the shrinkage versions of the monte carlo ( mc+s ) and jackknife ( jk+s ) methods",
    ". for clarity all of the mc+s error bars are plotted as positive and all of the jk+s as negative . ]    the difficulties in estimating the power spectrum covariance matrix in the context of making precision cosmological measurements are of even greater concern for higher - order clustering measurements .",
    "higher - order clustering measurements have a configuration space with more degrees of freedom than the power spectrum ( or two - point correlation function ) .",
    "even a lower resolution measurement will have more bins and a much larger covariance matrix , and noise will cause larger deviations in the inverse matrix .",
    "theoretical modeling of the covariance matrix for an n - point correlation function generally involves correlations up to the 2n - point ( e.g. , * ? ? ?",
    "* ) , making the models more uncertain .",
    "the ability to optimally combine simulations and a theoretical model with a small number of free parameters will make dramatic improvements .",
    "shrinkage estimators could also be used for covariance matrices of measurements outside of large - scale structure , including the cosmic microwave background power spectrum .",
    "finally , we note that section  [ sub : shrink ] makes no specific references to covariance matrices and that shrinkage is a general estimation technique .",
    "we are studying additional applications of shrinkage estimation for cosmological measurements .",
    "the authors thank mark neyrinck and gang chen for discussions about the covariance matrix of the power spectrum and the effects of noise .",
    "the authors are grateful for support nasa grant nng06ge71 g and nsf grant ams04 - 0434413 ."
  ],
  "abstract_text": [
    "<S> we seek to improve estimates of the power spectrum covariance matrix from a limited number of simulations by employing a novel statistical technique known as shrinkage estimation . </S>",
    "<S> the shrinkage technique optimally combines an empirical estimate of the covariance with a model ( the _ target _ ) to minimize the _ total _ mean squared error compared to the true underlying covariance . </S>",
    "<S> we test this technique on n - body simulations and evaluate its performance by estimating cosmological parameters . using a simple diagonal target , we show that the shrinkage estimator significantly outperforms both the empirical covariance and the target individually when using a small number of simulations . </S>",
    "<S> we find that reducing noise in the covariance estimate is essential for properly estimating the values of cosmological parameters as well as their confidence intervals . </S>",
    "<S> we extend our method to the jackknife covariance estimator and again find significant improvement , though simulations give better results . even for thousands of simulations we still find evidence that our method improves estimation of the covariance matrix . because our method is simple , requires negligible additional numerical effort , and produces superior results , we always advocate shrinkage estimation for the covariance of the power spectrum and other large - scale structure measurements when purely theoretical modeling of the covariance is insufficient .    </S>",
    "<S> methods : statistical  large - scale structure of the universe . </S>"
  ]
}