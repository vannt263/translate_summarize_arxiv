{
  "article_text": [
    "consider the high - dimensional matrix trace regression model @xmath1 where the @xmath2 s are random noise variables , independent of the random design matrices @xmath3 , and where the matrix @xmath4 is the object of inferential interest .",
    "we denote the law of @xmath5 given @xmath4 by @xmath6 . to reflect the structure of the main application we have in mind  quantum tomography , introduced in detail below ",
    "we assume that @xmath3 and @xmath4 are both @xmath7 square matrices , and study the case where the number @xmath8 of measurements taken may be smaller than the effective parameter dimension @xmath9 .",
    "recovery of @xmath4 in such situations is still possible by compressed sensing techniques @xcite , under two main structural assumptions on the model : 1 ) the matrix @xmath4 is of low rank and 2 ) the measurement matrices @xmath3 satisfy the restricted isometry ( or a related coherence ) property . in this case recovery of a rank @xmath10 matrix @xmath4",
    "is possible in frobenius distance @xmath11 by , e.g. , the matrix lasso @xmath12 : for any @xmath13 and with high @xmath6-probability , @xmath14 where @xmath15 is the so - called ` polylog ' function .",
    "the design used in quantum tomography is such that the @xmath3 are randomly drawn from a basis @xmath16 of the space of @xmath7 matrices , and one samples fewer than all @xmath9 basis coefficients @xmath17 without losing recovery guarantees for low rank matrices @xmath4 . in experimental settings ( e.g. , @xcite ) ,",
    "@xmath18 where @xmath19 is a possibly large number of particles , but @xmath4 will represent an approximately pure quantum state , motivating the low rank hypothesis and explaining the interest of quantum information theorists in dimension reduction methods ( see the appendix and @xcite ) .    in practice the implementation of the compressed sensing paradigm requires a way to decide how many measurements @xmath8 should be taken .",
    "the preceding theoretical bound @xmath20 is not useful for this because it may involve unspecified constants , but also , more importantly , because the rank @xmath10 of @xmath4 is typically not known . instead one can try to find a _ data driven stopping rule _",
    "@xmath0 that guarantees that recovery with precision @xmath21 occurs after @xmath0 measurements , with high probability . in the quantum tomography context",
    "such stopping rules are called ` certificates ' ( see section iv in @xcite ) , as they certify the reconstruction of the true quantum state @xmath4 .",
    "it is not difficult to see , and will be made precise below , that the construction of such stopping rules is intimately connected to the construction of a ( sequential ) confidence region for the unknown parameter @xmath4 , and due to its importance in applications this topic has received considerable attention recently by physicists , see @xcite .",
    "none of the previous constructions has succeeded , however , in constructing an _ optimal _ stopping rule for which @xmath22 holds with high probability .",
    "the main contribution of the present paper is to construct optimal non - asymptotic frobenius norm confidence regions for low rank parameters in the model ( [ model ] ) , and to use them to devise optimal sequential data driven stopping rules @xmath0 ( ` certificates ' ) for the measurement process .",
    "that such procedures exist may at first look surprising in view of negative results in the ` sparse ' compressed sensing setting in @xcite , but our results reveal the more favourable information - theoretic structure of the matrix model . while our techniques are based on unbiased risk estimation ideas that were first used in nonparametric statistics ( see @xcite , and also @xcite ) and that apply in a general setting , we lay out the details for a basic ( sub- ) gaussian design and noise model , as well as for the pauli observation scheme relevant in quantum tomography ( see @xcite and condition [ design]b ) below ) .",
    "we shall also address the more difficult question of constructing confidence regions for a quantum state matrix in the stronger nuclear norm .",
    "relationships between our findings and the recent literature on confidence regions for high - dimensional statistical parameters are discussed at the end .",
    "we also investigate the performance of our procedures in basic simulation study .",
    "denote by @xmath23 the space of @xmath7 matrices with entries in @xmath24 or @xmath25 .",
    "we write @xmath11 for the usual frobenius norm on @xmath23 arising from the inner product @xmath26 .",
    "moreover let @xmath27 be the set of all hermitian matrices ( equal to the set of all symmetric @xmath7 matrices when @xmath28 ) .",
    "the norm symbol @xmath29 denotes the standard euclidean norm on @xmath30 arising from the euclidean inner product @xmath31 .",
    "we denote the usual operator norm on @xmath23 by @xmath32 .",
    "for @xmath33 let @xmath34 be the eigenvalues of @xmath35 ( which are all real - valued and positive ) .",
    "the @xmath36-schatten , _ trace _ , or _ nuclear _ norm of @xmath37 is defined as @xmath38 note that for any matrix @xmath37 of rank @xmath39 , @xmath40    we will consider parameter subspaces of @xmath27 described by low rank constraints on @xmath4 , and denote by @xmath41 the space of all hermitian @xmath7 matrices that have rank at most @xmath10 , @xmath42 . in quantum tomography applications , we may assume an additional ` shape constraint ' , namely that @xmath4 is a density matrix of a quantum state , and hence contained in _ state space _",
    "@xmath43 where @xmath44 means that @xmath4 is positive semi - definite .",
    "in fact , in most situations , we will only require the bound @xmath45 which holds for any @xmath4 in @xmath46 .",
    "we now specify assumptions on the design matrices @xmath3 used in our observation model ( [ model ] ) . when @xmath4 has real - valued entries we shall restrict to design matrices @xmath3 with real - valued entries too , and for general @xmath47 we shall assume @xmath48 . this way ,",
    "in either case , the measurements @xmath49 s and hence the @xmath50 s are all real - valued .",
    "note that in part a ) below the design matrices are not hermitian but our results can easily be generalised to symmetrised sub - gaussian ensembles ( as those considered in ref .",
    "part b ) corresponds to the quantum tomography measurement model used in @xcite  we refer to the appendix for a detailed derivation .",
    "[ design ]    * * @xmath51 , ` isotropic ' sub - gaussian design : * the random variables @xmath52 , @xmath53 generating the entries of the random matrix @xmath3 are i.i.d .",
    "distributed across all indices @xmath54 with mean zero and unit variance . moreover , for every @xmath55 such that @xmath56 the real random variables @xmath57 are sub - gaussian : for some fixed constants @xmath58 independent of @xmath4 , @xmath59 * * @xmath60 , random sampling from a basis ( ` pauli design ' ) : * let @xmath61 be a basis of @xmath62 that is orthonormal for the scalar product @xmath63 and such that the operator norms satisfy , for all @xmath64 , @xmath65 for some @xmath66 .",
    "[ in the pauli basis case we have @xmath67 . ]",
    "assume the @xmath3 , @xmath68 are draws from the finite family @xmath69 sampled uniformly at random .",
    "the above examples all obey the _ matrix restricted isometry property _ , that we describe now .",
    "note first that if @xmath70 is the linear ` sampling ' operator @xmath71 so that we can write the model equation ( [ model ] ) as @xmath72 , then in the above examples we have the ` expected isometry ' @xmath73 indeed , in the isotropic design case we have @xmath74 and in the ` basis case ' we have , from parseval s identity and since the @xmath3 s are sampled uniformly at random from the basis , @xmath75 the restricted isometry property ( rip ) requires that this ` expected isometry ' holds , up to constants and with probability @xmath76 , for a given realisation of the sampling operator , and for all @xmath7 matrices @xmath4 of rank at most @xmath10 : @xmath77 where @xmath78 are some constants that may depend , among other things , on the rank @xmath10 and the ` exceptional probability ' @xmath79 . for the above examples of isotropic and pauli basis design inequality ( [ rip ] ) can be shown to hold with @xmath80 where @xmath81 as @xmath82 is a fixed constant .",
    "@xcite for these results .",
    "we still have to specify the distribution of the errors @xmath2 in the model ( [ model ] ) . in the quantum tomography",
    "setting of condition [ design]b ) , if we fix an element @xmath83 for the moment , then as detailed in the appendix the observations @xmath84 are themselves an average of repeated samples from a bernoulli random variable @xmath85 taking values @xmath86 with probabilities given by @xmath87 more precisely , @xmath88 where @xmath89 is the effective error arising from the measurement procedure making use of @xmath90 preparations to estimate each quantum mechanical expectation value",
    ". we could work with this bernoulli error model directly , but since the @xmath2 s are themselves sums of independent random variables , an approximate gaussian error model will be appropriate , too .",
    "note further that @xmath91 are bounded by @xmath92 .",
    "a natural assumption is then    [ gausse ] the @xmath93 are i.i.d .",
    "@xmath94 where @xmath95 for some known constant @xmath96 .",
    "this unifies the exposition for both designs considered in condition [ design ] , but we note that our proofs are valid in the exact bernoulli error model as well , see remark [ bernprf ] below .      assuming the matrix rip from ( [ rip ] ) to hold and gaussian noise @xmath97 , one can show that the minimax risk for recovering a hermitian rank @xmath10 matrix is @xmath98 where @xmath99 denotes two - sided inequality up to universal constants . for the upper bound one can use the nuclear norm minimisation procedure or matrix dantzig selector from cands and plan @xcite ( see also @xcite for the case of pauli - design ) , and needs @xmath8 to be large enough so that the matrix rip holds with @xmath100 where @xmath101 is a small enough numerical constant .",
    "such an estimator @xmath102 then satisfies , for every @xmath103 and those @xmath104 for which @xmath100 , @xmath105 with probability @xmath106 , and with the constant @xmath107 depending on @xmath79 and also on @xmath101 ( suppressed in the notation ) .",
    "note that the results in @xcite use a different scaling in sample size in their theorem 2.4 , but eq .",
    "( ii.7 ) in that reference explains that this is just a matter of renormalisation .",
    "the same bound holds for the bernoulli noise model from subsection [ bernoulli ] , see @xcite .",
    "we now turn to the problem of quantifying the uncertainty of estimators @xmath102 that satisfy the risk bound ( [ cplan ] ) . in fact",
    "the procedures we construct could be used for any estimator of @xmath4 , but the conclusions are most interesting when used for minimax optimal estimators @xmath102 .      from a statistical point of view",
    "the problem at hand is the one of constructing a confidence set for @xmath4 : a data - driven subset @xmath108 of @xmath62 that is ` centred ' at @xmath102 , that satisfies @xmath109 for a chosen ` coverage ' or significance level @xmath110 , and such that the frobenius norm diameter @xmath111 reflects the accuracy of estimation , that is , it satisfies , with high probability , @xmath112 in particular such a confidence set provides , through its diameter @xmath111 , a data - driven estimate of how well the algorithm has recovered the true matrix @xmath4 in frobenius - norm loss , and in this sense provides a quantification of the uncertainty in the estimate .    in an experimental situation confidence sets @xmath113 can be used to decide sequentially whether more measurements should be taken ( to improve the recovery rate ) , or whether a satisfactory performance has been reached .",
    "concretely , for given @xmath8 we check if @xmath114 , and continue to take further measurements if not .",
    "assuming @xmath102 satisfies the minimax optimal risk bound @xmath115 from ( [ cplan ] ) , we expect to need , ignoring constants , @xmath116 measurements",
    ". note that we also need the rip to hold with @xmath78 from ( [ tau ] ) less than a small constant @xmath101 , which requires the same number of measurements , increased by a further poly - log factor of @xmath117 ( and independently of @xmath118 ) .",
    "the goal is then to prove that a sequential procedure based on @xmath108 does _ not _ require more than approximately @xmath119 samples ( with high probability ) .",
    "this is made precise in the following definition , where we recall that @xmath41 denotes the set of @xmath7 hermitian matrices of rank at most @xmath42 .",
    "[ alg ] let @xmath120 be given constants .",
    "an algorithm @xmath121 returning a @xmath7 matrix @xmath122 after @xmath123 measurements in model ( [ model ] ) is called an @xmath124 - adaptive sampling procedure if , with @xmath125-probability greater than @xmath126 , the following properties hold for every @xmath103 and every @xmath127 : @xmath128 and , for some positive constants @xmath129 the stopping time @xmath0 satisfies @xmath130    such an algorithm provides recovery at given accuracy level @xmath21 with @xmath0 measurements of minimax optimal order of magnitude ( up to a poly - log factor ) , and with probability greater than @xmath126 .",
    "the sampling algorithm is adaptive since it does not require the knowledge of @xmath10 , and since the number of measurements required depends only on @xmath10 and not on the ` worst case ' rank @xmath117 .",
    "our first main result is the following theorem , whose proof relies on the construction of non - asymptotic confidence sets @xmath108 for @xmath4 at any sample size @xmath8 , given in the next subsection .",
    "[ adsamp ] consider observations in the model ( [ model ] ) under conditions [ design]b ) and [ gausse ] , and where @xmath131 .",
    "then an adaptive sampling algorithm in the sense of definition [ alg ] exists for any @xmath132 .",
    "the result above holds for isotropic design from condition [ design]a ) too , without the constraint @xmath131 , see remark [ mod ] below . for pauli design",
    "the assumption @xmath131 ( instead of just @xmath133 ) is , however , necessary : else the example of @xmath134 or @xmath135  where @xmath136 is an arbitrary element of the pauli basis  demonstrates that the number of measurements has to be at least of order @xmath9 : otherwise with positive probability @xmath136 is not drawn at a fixed sample size . on this event both the measurements and @xmath122 coincide under the laws @xmath137 and @xmath138 , so we can not have @xmath139 and @xmath140 simultaneously for every @xmath13 , disproving existence of an adaptive sampling algorithm .",
    "in fact , the crucial condition for theorem [ adsamp ] to work is that the nuclear norms @xmath141 are bounded by an absolute constant ( here @xmath142 ) , which is violated by @xmath143 .        we suppose that we have two samples at hand , the first being used to construct an estimator @xmath102 , such as the one from ( [ cplan ] ) .",
    "we freeze @xmath102 and the first sample in what follows and all probabilistic statements are under the distribution @xmath125 of the second sample @xmath145 of size @xmath104 , conditional on the value of @xmath102 .",
    "we define the following residual sum of squares ( rss ) statistic @xmath146 which satisfies @xmath147 in the model ( [ model ] ) under conditions [ design ] and [ gausse ] ( see the proof of theorem [ rssthm ] below ) .",
    "we assume for now that @xmath118 is known , see subsection [ novar ] below for a discussion of the necessary modifications in the general case .",
    "given @xmath148 , let @xmath149 be quantile constants such that @xmath150 ( these constants converge to the quantiles of a fixed normal distribution as @xmath151 ) , let @xmath152 and , for @xmath153 a fixed constant to be chosen , define the confidence set @xmath154 where @xmath155 note that in the ` quantum shape constraint ' case @xmath131 we can always upper bound @xmath156 in the definition of @xmath157 , which gives a confidence set that is easier to compute and of only marginally larger overall diameter . in some situations ,",
    "however , the quantity @xmath158 is of smaller order than @xmath159 , and the more complicated expression above is generally preferable .",
    "it is not difficult to see ( using that @xmath160 implies @xmath161 ) that the mean square frobenius norm diameter of @xmath108 is of order @xmath162 whenever @xmath163  so as long as at most @xmath144 measurements have been taken ",
    "the deviation terms are of smaller order than @xmath164 for any @xmath165 , and hence @xmath108 has minimax optimal expected squared diameter whenever the estimator @xmath102 is minimax optimal as in ( [ cplan ] ) .",
    "the following result shows that @xmath108 is a valid confidence set for arbitrary hermitian @xmath7 matrices ( without any rank constraint ) .",
    "note that the result is non - asymptotic  it holds for every @xmath104 .",
    "[ rssthm ] let @xmath60 be arbitrary and let @xmath125 be the distribution of @xmath145 from model ( [ model ] ) under condition [ gausse ] .",
    "\\a ) assume the design satisfies condition [ design]a ) and let @xmath108 be given by ( [ rssconf ] ) with @xmath166 . we then have for every @xmath104 that @xmath167 where @xmath168 is a numerical constant . in the case of standard gaussian design , @xmath169 is admissible .",
    "\\b ) assume the design satisfies condition [ design]b ) with constant @xmath66 , let @xmath108 be given by ( [ rssconf ] ) with @xmath170 and assume also that @xmath131 and @xmath171 ( that is , both satisfy the ` quantum shape constraint ' ) .",
    "then for every @xmath104 , @xmath172 where @xmath173 $ ] .",
    "in part a ) , if we want to control the coverage probability at level @xmath110 , @xmath8 needs to be large enough so that the third deviation term is controlled at level @xmath174 . in the gaussian design case with @xmath175",
    ", @xmath176 is sufficient , for smaller sample sizes one can use the confidence region from the next subsection .",
    "the bound in b ) is entirely non - asymptotic for suitable choices of @xmath177 .",
    "also note that the quantile constants @xmath178 all scale at least as @xmath179 in the desired coverage level @xmath180 .    as mentioned above",
    ", the confidence set from theorem [ rssthm ] is optimal whenever the desired performance of @xmath181 is no better than of order @xmath159 , corresponding to the important regime @xmath144 for sequential sampling algorithms .",
    "refinements for measurement scales @xmath182 are also of interest - we present two optimal approaches in the next two subsections for the designs from condition [ design ] .",
    "consider isotropic i.i.d  design from condition [ design]a ) , and an estimator @xmath102 based on an initial sample of size @xmath8 ( all statements that follow are conditional on that sample ) .",
    "collect another @xmath8 samples to perform the uncertainty quantification step .",
    "define the @xmath183-statistic @xmath184 whose @xmath185-expectation , conditional on @xmath102 , equals @xmath186 in view of @xmath187 define @xmath188 where @xmath189 and @xmath190 with @xmath191 constants depending on @xmath192 and the upper bound @xmath96 for @xmath118 from condition [ gausse ] .",
    "note that if @xmath131 then @xmath56 can be used as an upper bound in @xmath193 . in practice",
    "the constants @xmath191 can be calibrated by monte carlo simulations ( see the implementation section below ) , or chosen based on concentration inequalities for @xmath183-statistics ( see ref .",
    "@xcite , theorem 4.4.8 ) .",
    "this confidence set has expected diameter @xmath194 and hence is compatible with any minimax recovery rate @xmath195 from ( [ cplan ] ) , where @xmath165 is now arbitrary .",
    "for suitable choices of @xmath191 we now show that @xmath108 also has non - asymptotic coverage .",
    "[ ustatkill ] assume conditions [ design]a ) and [ gausse ] , and let @xmath108 be as in ( [ uconf ] ) . for every @xmath148 we can choose @xmath196 large enough so that for every @xmath104 we have @xmath197      for the design from condition [ design]b ) where we sample uniformly at random from a ( scaled ) basis @xmath199 of @xmath62 , the @xmath183-statistic approach from theorem [ ustatkill ] appears not to be viable , and",
    "thus for @xmath200 the existence of an optimal confidence region still needs to be ensured .",
    "when @xmath200 we are taking @xmath198 measurements , and there is no need to sample at _ random _ from the basis as we can measure each individual coefficient , possibly even multiple times . repeatedly sampling a basis coefficient",
    "@xmath201 leads to a reduction of the variance of the measurement by averaging .",
    "more precisely , when taking @xmath202 measurements for some ( for simplicity integer ) @xmath203 , and if @xmath204 are the measurements @xmath50 corresponding to the basis element @xmath205 , we can form averaged measurements @xmath206 we can then define the new measurement vector @xmath207 ( using also @xmath208 ) @xmath209 and the statistic @xmath210 which estimates @xmath211 with precision @xmath212 hence , for @xmath213 the quantiles of a @xmath214 distribution and @xmath149 as in ( [ quantile ] ) with @xmath9 replacing @xmath8 there , we can define a confidence set @xmath215 which has non - asymptotic coverage @xmath216 for every @xmath104 , by similar ( in fact , since lemma [ bernstein ] is not needed , simpler ) arguments as in the proof of theorem [ rssthm ] below .",
    "the expected diameter of @xmath217 is by construction @xmath218 now compatible with _ any _ rate of recovery @xmath219 .",
    "the case of unknown variance is discussed in the next subsection .",
    "the @xmath183-statistic based confidence set from ( [ uconf ] ) does not require knowledge of @xmath118 but works only for the design from condition [ design]a ) . for pauli design from condition [ design]b ) we can use the confidence sets @xmath108 in theorem [ rssthm ] or @xmath217 in ( [ liconf ] ) , but",
    "these do require exact knowledge of the noise variance @xmath220 .",
    "as described before ( [ bernbds ] ) above , in the pauli case @xmath220 can be apriori bounded by @xmath92 , where @xmath90 is the number of preparations used to measure each individual pauli observable . if @xmath221 then the statistics @xmath222 and @xmath223 from ( [ rss0 ] ) and ( [ rss2 ] ) above can be used without subtracting @xmath220 and @xmath224 , respectively , in their definitions .",
    "the coverage proofs then go through with minor modifications simply by noting that these centerings are of sufficiently small order of magnitude @xmath225 and @xmath226 compared to the minimax rate of estimation , and by using the upper bound @xmath227 in all relevant constants featuring in the definition of @xmath228 .",
    "typically preparing @xmath221 measurements of a fixed pauli observable is not a major problem in experimental situations .",
    "if for some reason this can not be done , one can make sure that each @xmath229 is at least measured twice ( so @xmath230 ) , say in batches @xmath231 and @xmath232 , and then use the modified statistic @xmath233 in the construction of the confidence set .",
    "arguments similar to above , using concentration inequalities for gaussian chaos of order two ( theorem 3.1.9 in @xcite ) then allow for the construction of a confidence region that does neither require knowledge of @xmath95 nor @xmath221 .",
    "details are omitted .",
    "the confidence sets from the previous subsections are all valid in the sense that they contain information about the recovery of @xmath4 by @xmath102 in frobenius norm @xmath11 .",
    "it is of interest to obtain results in stronger norms , such as for instance the nuclear norm @xmath234 , which is particularly meaningful for quantum tomography problems since it then corresponds to the total variation distance on the set of ` probability density matrices ' .",
    "the absence of the ` hilbert space geometry ' induced by the relationship of the frobenius norm to the inner product @xmath63 makes this problem significantly harder , both technically and from an information - theoretic point of view .",
    "in particular the quantum shape constraint @xmath131 is crucial to obtain any results whatsoever . for the theoretical results presented here it will be more convenient to perform an asymptotic analysis where @xmath235 ( with @xmath236-notation to be understood accordingly ) .    instead of condition [ design ]",
    "we now consider more generally any design @xmath237 in model ( [ model ] ) that satisfies the matrix rip ( [ rip ] ) with @xmath238 we shall still use the convention discussed before condition [ design ] that @xmath4 and the matrices @xmath3 are such that @xmath239 is always real - valued .",
    "in contrast to the results from the previous section we shall now assume a minimal low rank constraint on the parameter space :    [ consistent ] @xmath240 for some @xmath10 satisfying @xmath241    this in particular implies that the rip holds with @xmath242 .",
    "given this minimal rank constraint @xmath243 , we now show that it is possible to construct a confidence set @xmath108 that adapts to any low rank @xmath244 . here",
    "we may choose @xmath245 but note that this forces @xmath246 ( for condition [ consistent ] to hold with @xmath245 ) .",
    "we assume that there exists an estimator @xmath247 that satisfies , uniformly in @xmath248 for any @xmath249 and for @xmath8 large enough , @xmath250 where @xmath251 depends on @xmath79 , and where so - defined @xmath252 will be used frequently below .",
    "such estimators exist as has already been discussed before ( [ cplan ] ) .",
    "we shall in fact require a little more , namely the following oracle inequality : for any @xmath10 and any matrix @xmath253 of rank @xmath254 , with high probability and for @xmath8 large enough , @xmath255 which implies ( [ risk ] ) .",
    "such inequalities exist assuming the rip and condition [ consistent ] , see , e.g. , theorem 2.8 in ref . @xcite . starting from @xmath247 one can construct ( see theorem [ estcond ] below ) an estimator that recovers @xmath103 in nuclear norm at rate @xmath256 , which is again optimal from a minimax point of view , even under the quantum constraint ( as discussed , e.g. , in ref .",
    "we now construct an adaptive confidence set for @xmath4 centred at a suitable projection of @xmath247 onto @xmath46 .    in the proof of theorem [ main ] below we",
    "will construct estimated eigenvalues @xmath257 of @xmath4 ( see after lemma [ pcaell1 ] ) . given those eigenvalues and @xmath247",
    ", we choose @xmath258 to equal the smallest integer @xmath259 such that there exists a rank @xmath258 matrix @xmath260 for which @xmath261 is satisfied .",
    "such @xmath258 exists with high probability ( since the inequalities are satisfied for the true @xmath4 and @xmath262 s , as our proofs imply ) .",
    "define next @xmath263 to be the @xmath63-projection of @xmath247 onto @xmath264 and note that , since @xmath265 , @xmath266 finally define , for @xmath267 a constant chosen below , @xmath268    [ main ] assume condition [ consistent ] for some @xmath127 , and let @xmath269 be given . assume that with probability greater than @xmath270 , a ) the rip ( [ rip ] ) holds with @xmath78 as in ( [ mrip ] ) and b ) there exists an estimator @xmath247 for which ( [ oracle ] ) holds .",
    "then we can choose @xmath271 large enough so that , for @xmath108 as in the last display , @xmath272 moreover , uniformly in @xmath273 and with @xmath125-probability greater than @xmath126 , @xmath274    theorem [ main ] shows how the quantum shape constraint allows for the construction of an optimal nuclear norm confidence set that adapts to the unknown low rank structure .",
    "a careful study of certain hypothesis testing problems ( combined with lower bound techniques for confidence sets as in @xcite ) shows that the assumption @xmath275 in the above theorem is actually necessary , and can not be relaxed to @xmath103 .",
    "see @xcite , theorem 4 .      we have constructed adaptive confidence regions for matrix parameters @xmath4 in the trace regression model ( [ model ] ) .",
    "these confidence regions contract at the minimax optimal rates for low rank parameters , either in frobenius or nuclear norm , and are ` honest ' ( in the sense of @xcite , see also @xcite ) .",
    "the conditions employed are naturally compatible with quantum tomography applications - where @xmath4 is the density matrix of a quantum state , and where the noise variance has an a priori upper bound that can be controlled experimentally .",
    "this in turn can be used to demonstrate the existence of fully adaptive sequential sampling protocols that generate valid certificates for the recovery of unknown low rank quantum states .    while it can be shown on the one hand ( see theorem 4 in @xcite ) that our results for the nuclear norm ( theorem [ main ] ) fundamentally rely on the ` quantum shape constraint ' @xmath131 , our results for the frobenius norm on the other hand are valid in a general compressed sensing inference setting .",
    "this may seem surprising in light of negative results in @xcite , where it is shown that in the related ` sparse ' high - dimensional linear model , signal strength assumptions ( inspired by the nonparametric statistics literature , @xcite ) are generally necessary for the existence of @xmath276-confidence regions for the entire parameter vector .",
    "however , the information theoretic structure of the matrix inference problem is different , as is also illustrated by the fact that the signal detection rates in the model ( [ model ] ) in frobenius norm do _ not _ depend on the low rank structure at all ( see theorem 1 in @xcite ) . in this sense ,",
    "our findings in the matrix regression model form a remarkable exception to the rule that uncertainty quantification methodology does not generally exist for high - dimensional adaptive algorithms , unless one restricts the inferential interest to a simple semi - parametric low - dimensional functional ( @xcite ) .",
    "in order to illustrate the methods from this paper , we present some numerical simulations .",
    "the setting of the experiments is as follows : a random matrix @xmath277 of norm @xmath278 is generated according to two distinct procedures that we will specify later , and the observations are now @xmath279 where the @xmath2 are i.i.d .",
    "gaussian of mean @xmath280 and variance @xmath281 .",
    "the observations are reparametrised so that @xmath282 represents the ` estimation error ' @xmath283 , and we investigate how well the statistics @xmath284 estimate the ` accuracy of estimation ' @xmath285 , conditional on the value of @xmath122 .",
    "we will choose @xmath282 in order to illustrate two extreme cases : a first one where the nuclear norm @xmath286 is ` small ' , corresponding to a situation where the quantum constraint is fulfilled ; and a second one where the nuclear norm is large , corresponding to a situation where the quantum constraint is _ not _ fulfilled .",
    "more precisely we generate the parameter @xmath282 in two ways :    * ` random dirac ' case : set a single entry ( with position chosen at random on the diagonal ) of @xmath282 to @xmath287 , and all the other coordinates equal to @xmath280 .",
    "* ` random pauli ' case : set @xmath282 equal to a pauli basis element chosen uniformly at random and then multiplied by @xmath287 .",
    "the designs that we consider are the gaussian design , and the pauli design , described in condition 1 .",
    "we perform experiments with @xmath288 , @xmath289 and @xmath290 note that @xmath291 , so that the first four choices of @xmath8 correspond to the important regime @xmath292 .",
    "our results are plotted as a function of the number @xmath8 of samples in figures  [ fig : gd ] , [ fig : gp ] , [ fig : pd ] , [ fig : pp ] .",
    "the solid red an blue curves are the median errors of the normalised estimation errors @xmath293 after @xmath294 iterations , and the dotted lines are respectively , the ( two - sided ) @xmath295 quantiles .",
    "we also report ( see tables  [ tab : gd ] , [ tab : gp ] , [ tab : pd ] , [ tab : pp ] ) how well the confidence sets based on these estimates of the norm perform in terms of coverage probabilities , and of diameters .",
    "the diameters are computed as @xmath296 for the u - statistic approach and @xmath297 for the rss approach , where we have chosen @xmath298 , @xmath299 and @xmath300 for all experiments calibrated to a @xmath301 coverage level . from these numerical results ,",
    "several observations can be made :    \\1 ) in gaussian random designs , the results are insensitive to the nature of @xmath282 ( see figures  [ fig : gd ] and  [ fig : gp ] and tables  [ tab : gd ] and  [ tab : gp ] ) .",
    "this is not surprising since the gaussian design is ` isotropic ' .",
    "\\2 ) for pauli designs with the quantum constraint ( see figure  [ fig : pd ] and table  [ tab : pd ] ) the rss method works quite well even for small sample sizes . but the u - stat method is not very reliable  indeed we see no empirical evidence that theorem [ ustatkill ] should also hold true for pauli design .",
    "\\3 ) for pauli design and when the quantum shape constraint is _ not _ satisfied our methods cease to provide reliable results ( see figure  [ fig : pp ] and in particular table  [ tab : pp ] ) .",
    "indeed , when the matrix @xmath282 is chosen itself as a random pauli ( which is the hardest signal to detect under pauli design ) both the rss and the u - stat approach perform poorly . the confidence set are not honest anymore , which is in line with the theoretical limitations we observe in theorem [ rssthm ] .",
    "figure  [ fig : pp ] illustrates that the methods do not detect the signal , since the norm of @xmath282 is largely under - evaluated for small sample sizes .",
    "these limitations are less pronounced when @xmath198 . in this case",
    "one could use alternatively the re - averaging approach from subsection [ reav ] ( not investigated in the simulations ) to obtain honest results without the quantum shape constraint .",
    ".gaussian design , and random dirac ( a single entry , chosen at random , is non - zero on the diagonal ) @xmath282 , with @xmath302 ( left table ) and @xmath303 ( right table ) . [",
    "cols=\"^,^,^,^,^,^,^,^,^,^,^,^,^ \" , ]",
    "before we define the algorithm and prove the result , a few preparatory remarks are required : our sequential procedure will be implemented in @xmath304 potential steps , in each of which @xmath305 measurements are taken . the arguments below will show that we can restrict the search to at most @xmath306 steps .",
    "we also note that from the discussion after ( [ rip ] )  in particular since @xmath307 from ( [ tau ] ) is @xmath308  a simple union bound over @xmath309 implies that the rip holds with probability @xmath310 , _ simultaneously _ for every @xmath309 satisfying @xmath311 , and with @xmath312 , where @xmath313 is a constant that depends on @xmath314 only .",
    "the maximum over @xmath315 terms is absorbed in a slightly enlarged poly - log term .",
    "hence , simultaneously for all such sample sizes @xmath316 , a nuclear norm regulariser exists that achieves the optimal rate from ( [ cplan ] ) with @xmath317 and for every @xmath42 , with probability greater than @xmath318 . projecting this estimator onto",
    "@xmath46 changes the frobenius error only by a universal multiplicative constant ( arguing as in ( [ projk ] ) below ) , and we denote by @xmath319 the resulting estimator computed from a sample of size @xmath320 .",
    "we now describe the algorithm at the @xmath321-th step : split the @xmath322 observations into two halves and use the first subsample to construct @xmath319 satisfying ( [ cplan ] ) with @xmath125-probability @xmath323 .",
    "then use the other @xmath320 observations to construct a confidence set @xmath324 for @xmath4 centred at @xmath325 : if @xmath326 we take @xmath324 from ( [ rssconf ] ) and if @xmath327 we take @xmath324 from ( [ liconf ] )  in both cases of non - asymptotic coverage at least @xmath328 [ if @xmath118 is unknown we proceed as described in subsection [ novar ] ] . if @xmath329 we terminate the procedure ( @xmath330 , @xmath331 , @xmath332 ) , but if @xmath333 we repeat the above procedure with @xmath334 new measurements , etc .",
    ", until the algorithm terminates , in which case we have used @xmath335 measurements in total .    to analyse this algorithm ,",
    "recall that the quantile constants @xmath336 appearing in the confidence sets ( [ rssconf ] ) and ( [ liconf ] ) for our choice of @xmath337 grow at most as @xmath338 .",
    "in particular in view of ( [ cplan ] ) and ( [ diameter ] ) or ( [ diameter2 ] ) the algorithm necessarily stops at a ` maximal sample size ' @xmath339 in which the squared frobenius risk of the maximal model ( @xmath245 ) is controlled at level @xmath21 .",
    "such @xmath340 is @xmath341 and depends on @xmath342 , hence can be chosen by the experimenter .    to prove that this algorithms works",
    "we show that the event @xmath343 has probability at most @xmath344 for large enough @xmath345 . by the union",
    "bound it suffices to bound the probability of each event separately by @xmath346 . for the first : since @xmath0 has been selected we know @xmath347 and since @xmath348 the event @xmath349 can only happen when @xmath350 .",
    "therefore @xmath351 for @xmath352 , whenever @xmath103 and for all @xmath353 for which @xmath354 , we have , as discussed above , from ( [ diameter ] ) or ( [ diameter2 ] ) and ( [ cplan ] ) that @xmath355 where @xmath356 is a constant . in the last inequality the expectation is taken under the distribution of the sample used for the construction of @xmath324 , and it holds on the event on which @xmath325 realises the risk bound ( [ cplan ] ) .",
    "then let @xmath345 be large enough so that @xmath357 and let @xmath358 be the smallest integer such that @xmath359 then , for @xmath360 large enough and since @xmath361 , @xmath362 by markov s inequality , completing the proof .",
    "[ isotropic sampling ] [ mod ] the proof above works for isotropic design from condition [ design]a ) likewise . when @xmath327 we replace the confidence set ( [ liconf ] ) in the above proof by the confidence set from ( [ uconf ] ) . assuming also that @xmath363 for some fixed constant @xmath37 we can construct a similar upper bound for @xmath90 and the above proof applies directly ( with @xmath90 of slighter larger but still small enough order ) .      by lemma [ bernstein ] below with @xmath364 the @xmath125-probability of the complement of the event @xmath365",
    "is bounded by the deviation terms @xmath366 and @xmath367 , respectively ( note @xmath166 in case a ) ) .",
    "we restrict to this event in what follows",
    ". we can decompose @xmath368 since @xmath369 for any random variables @xmath370 we can bound the probability @xmath371 by the sum of the following probabilities @xmath372 @xmath373 @xmath374 the first probability @xmath375 is bounded by @xmath376 about term @xmath377 : conditional on @xmath378 the variable @xmath379 is centred gaussian with variance @xmath380",
    ". the standard gaussian tail bound then gives by definition of @xmath157 , and conditional on @xmath378 , @xmath381 since , on the event @xmath382 , @xmath383 the overall bound for @xmath377 follows from integrating the last but one inequality over the distribution of @xmath384 .",
    "term @xmath385 is bounded by @xmath174 by definition of @xmath386 .",
    "[ bernprf ] if instead of gaussian errors we work with the error model from subsection [ bernoulli ] , we require a modified treatment of the terms @xmath387 in the above proof . for the pure noise term @xmath385",
    "we modify the quantile constants slightly to @xmath388 .",
    "if the number @xmath90 of preparations satisfies @xmath389 then chebyshev s inequality and ( [ bernbds ] ) give @xmath390 for the ` cross term ' we have likewise with @xmath391 and @xmath392 that , on the event @xmath382 , @xmath393 just as at the end of the proof of theorem [ rssthm ] , so that coverage follows from integrating the last inequality w.r.t .  the distribution of @xmath384 .",
    "the scaling @xmath394 is similar to the one discussed in theorem 3 in ref .",
    "@xcite .",
    "[ bernstein ] a ) for isotropic design from condition [ design]a ) and any fixed matrix @xmath395 we have , for every @xmath104 , @xmath396 in the standard gaussian design case we can take @xmath169 .",
    "\\b ) in the ` pauli basis ' case from condition [ design]b ) we have for any fixed matrix @xmath395 satisfying the schatten-1-norm bound @xmath397 and every @xmath104 , @xmath398 where @xmath399 $ ] , and where @xmath400 is the coherence constant of the basis .",
    "we first prove the isotropic case . from ( [ isoexp ] )",
    "we see @xmath401 where the @xmath402 are sub - gaussian random variables .",
    "then the @xmath403 are sub - exponential and we can apply bernstein s inequality ( prop .",
    "4.1.8 in ref .",
    "@xcite ) to the last probability . we give the details for the gaussian case and derive explicit constants . in this case",
    "@xmath404 so the last probability is bounded , using theorem 4.1.9 in ref .",
    "@xcite , by @xmath405 and the result follows .    under condition [ design]b )",
    ", if we write @xmath406 we can reduce likewise to bound the probability in question by @xmath407 where the @xmath408 are i.i.d .  bounded random variables . using @xmath409 from condition [ design]b ) and the quantum constraint @xmath410 we can bound @xmath411 as well as @xmath412 bernstein s inequality for bounded variables ( e.g. , theorem 4.1.7 in ref .",
    "@xcite ) applies to give the bound @xmath413 after some basic computations , by distinguishing the two regimes of @xmath414 and @xmath415 .      since @xmath416",
    "we have from chebyshev s inequality @xmath417 now @xmath418 is a centred u - statistic and has hoeffding decomposition @xmath419 where @xmath420)(\\theta_{m , k}-\\tilde \\theta_{m , k})\\ ] ] is the linear part and @xmath421)(y_j x^i_{m , k } - { \\mathbb e}[y_j   x^i_{m , k}])\\ ] ] the degenerate part .",
    "we note that @xmath422 and @xmath423 are orthogonal in @xmath424 .",
    "the linear part can be decomposed into @xmath425 where @xmath426 and @xmath427 now by the i.i.d .",
    "assumption we have @xmath428 moreover , by transposing the indices @xmath429 and @xmath430 in an arbitrary way into single indices @xmath431 , @xmath432 , respectively , basic computations given before eq .  ( 28 ) in ref .",
    "@xcite imply that the variance of the second term is bounded by @xmath433 where @xmath168 is a constant that depends only on @xmath434 ( which is finite since the @xmath435 are sub - gaussian in view of condition [ design]a ) ) .",
    "moreover , the degenerate term satisfies @xmath436 in view of standard @xmath183-statistic computations leading to eq .",
    "( 6.6 ) in ref .",
    "@xcite , with @xmath432 , and using the same transposition of indices as before .",
    "this proves coverage by choosing the constants in the definition of @xmath437 large enough .",
    "we prove the result for symmetric matrices with real entries  the case of hermitian matrices requires only minor ( mostly notational ) adaptations .    given the estimator @xmath247 , we can easily transform it into another estimator @xmath102 for which the following is true .",
    "[ estcond ] there exists an estimator @xmath102 that satisfies , uniformly in @xmath103 , for any @xmath42 and with @xmath125-probability greater than @xmath270 , @xmath438 as well as , @xmath439 and then also @xmath440    let @xmath247 and let @xmath102 be the element of @xmath441 with smallest rank @xmath442 such that @xmath443 such @xmath102 exists and has rank @xmath444 , with probability @xmath445 , since @xmath103 satisfies the above inequality in view of ( [ risk ] ) .",
    "the @xmath446-loss of @xmath102 is no larger than @xmath447 by the triangle inequality @xmath448 and this completes the proof of the third claim in view of ( [ l1l2 ] ) .",
    "the rest of the proof consists of three steps : the first establishes some auxiliary empirical process type results , which are then used in the second step to construct a sufficiently good simultaneous estimate of the eigenvalues of @xmath4 . in step",
    "iii the coverage of the confidence set is established .",
    "* step i *    let @xmath449 and let @xmath102 be the estimator from theorem [ estcond ] . then with probability @xmath445 , and if @xmath450 , we have @xmath451 and that @xmath452 for the rest of the proof we restrict in what follows to the event of probability greater than or equal to @xmath270 described by a ) and b ) in the hypothesis of the theorem .",
    "write @xmath453 for the ` new observations ' @xmath454 for any @xmath455 matrix @xmath456 we set @xmath457 which estimates @xmath458 let now @xmath183 be any unit vector in @xmath459 . then in the above notation ( @xmath460 ) we can write @xmath461 if @xmath462 denotes the @xmath7 matrix @xmath463 , the last quantity can be written as @xmath464 we can hence bound , for @xmath465 @xmath466    the right hand side on the last inequality is , with probability greater than @xmath126 , of order @xmath467    the first term in the bound corresponds to the first supremum on the right hand side of the last inequality , and follows directly from the matrix rip ( and lemma [ pythagoras ] ) . for the second term",
    "we argue conditionally on the values of @xmath378 and on the event for which the matrix rip is satisfied .",
    "we bound the supremum of the gaussian process @xmath468 indexed by elements @xmath183 of the unit sphere @xmath469 of @xmath459 , which satisfies the metric entropy bound @xmath470 by a standard covering argument .",
    "moreover @xmath471 and hence for any pair of vectors @xmath472 we have that @xmath473 . from the rip we deduce for every fixed @xmath472 that @xmath474 since @xmath475 and since @xmath476 hence any @xmath79-covering of @xmath469 in @xmath29 induces a @xmath477 covering of @xmath469 in the intrinsic covariance @xmath478 of the ( conditional on @xmath378 ) gaussian process @xmath479 ,",
    "i.e. , @xmath480 with constants independent of @xmath384 . by dudley s metric entropy bound ( e.g. , ref .",
    "@xcite ) applied to the conditional gaussian process we have for @xmath481 some constant @xmath482 and hence we deduce that @xmath483 with constants independent of @xmath384 , so that the result follows from applying markov s inequality .",
    "* step ii : *    define the estimator @xmath484 then we can write , using @xmath485 , @xmath486 and from the previous lemma we conclude , for any unit vector @xmath183 that with probability @xmath76 , @xmath487 let now @xmath122 be any symmetric positive definite matrix such that @xmath488 such a matrix exists , for instance @xmath275 , and by the triangle inequality we also have @xmath489 let @xmath37 be a symmetric positive definite @xmath7 matrix with eigenvalues @xmath262 s ordered such that @xmath490 . for",
    "any @xmath491 consider an arbitrary collection of @xmath492 orthonormal vectors @xmath493 in @xmath459 .",
    "then we have @xmath494 and @xmath495    the proof of this lemma is basic and given in the appendix .",
    "let now @xmath496 be the rotation that diagonalises @xmath122 such that @xmath497 ordered such that @xmath498 @xmath499 .",
    "moreover let @xmath500 be the rotation that does the same for @xmath4 and its eigenvalues @xmath262 .",
    "we apply the previous lemma with @xmath501 and @xmath502 equal to the column vectors @xmath503 of @xmath500 to obtain , for any fixed @xmath504 , @xmath505 and also that @xmath506 from ( [ thetahat ] ) we deduce , that @xmath507 as well as @xmath508 with probability @xmath76 . combining these bounds",
    "we obtain @xmath509    * step iii *    we show that the confidence sets covers the true parameter on the event of probability @xmath76 on which steps i and ii are valid , and for the constant @xmath267 chosen large enough .",
    "let @xmath510 be the projection operator onto @xmath511 .",
    "we have @xmath512 we have , using ( [ evbd ] ) and lemma [ lem : mati2 ] below @xmath513 for @xmath267 large enough .",
    "moreover , using the oracle inequality ( [ oracle ] ) with @xmath514 and ( [ projk ] ) , @xmath515 we finally deal with the approximation error : note @xmath516 by ( [ evbd ] ) we know that @xmath517 hence out of the @xmath518 s with indices @xmath519 there have to be less than @xmath258 coefficients which exceed @xmath520 . since the eigenvalues are ordered this implies that the @xmath518 s with indices @xmath521 are all less than or equal to @xmath520 , and hence the quantity in the last but one display is bounded by ( since @xmath522 ) , using again ( [ evbd ] ) and the definition of @xmath258 , @xmath523 overall we get the bound @xmath524 for @xmath267 large enough , which completes the proof of coverage of @xmath108 by collecting the above bounds .",
    "the diameter bound follows from @xmath525 ( in view of the defining inequalities of @xmath258 being satisfied , for instance , for @xmath526 , whenever @xmath527 . )",
    "we conclude with the following auxiliary results used above .",
    "[ pythagoras ] under the rip ( [ rip ] ) we have for every @xmath528 that , with probability at least @xmath529 , @xmath530    the matrix rip can be written as @xmath531 for a suitable @xmath532 .",
    "the above bound then follows from applying the cauchy - schwarz inequality to @xmath533    the proof of the following basic lemma is left to the reader .",
    "[ lem : mati2 ] let @xmath534 with positive eigenvalues @xmath535 ordered in decreasing order . denote with @xmath536 the projection onto @xmath537 .",
    "then for any @xmath538 we have @xmath539    * acknowledgements . *",
    "this work has been supported by the eu ( siqs , raquel ) , the erc ( taq , uqmsi ) and the dfg ( spp1798 , musyad emmy noether grant ) .",
    "ac worked on this project while a postdoc at the university of cambridge .",
    "we also acknowledge discussions with c. riofrio .",
    "10    l.  artiles , r.  gill , and m.  guta . an invitation to quantum tomography . , 67:109 , 2005 .",
    "k.  m.  r. audenaert and s.  scheel . . ,",
    "11(2):023028 , 2009 .",
    "r.  blume - kohout .",
    "robust error bars for quantum tomography , 2012 .",
    "arxiv:1202.5270 .",
    "a.d . bull and r.  nickl .",
    "adaptive confidence sets in @xmath540 . , 156:889919 , 2013 .",
    "e.  j. cands and y.  plan .",
    "tight oracle inequalities for low - rank matrix recovery from a minimal number of noisy random measurements . , 57(4):23422359 , 2011 .",
    "a.  carpentier and a.  kim . .",
    ", 2015 .",
    "a.  carpentier and r.  nickl . .",
    ", to appear , 2015 .",
    "m.  christandl and r.  renner .",
    "reliable quantum state tomography .",
    ", 109:120403 , 2012 .",
    "r.  de  eq . .",
    ", 1:120 , 2008 .",
    "s.  t flammia , d.  gross , y .- k .",
    "liu , and j.  eisert .",
    "quantum tomography via compressed sensing : error bounds , sample complexity and efficient estimators .",
    ", 14(9):095022 , 2012 .",
    "e.  gin and r.  nickl .",
    "confidence bands in density estimation . , 38:11221170 , 2010 .",
    "e.  gin and r.  nickl . .",
    "to appear , cambridge university press , 2015 .",
    "d.  gross . recovering low - rank matrices from few coefficients in any basis .",
    ", 57(3):15481566 , 2011 .",
    "d.  gross , y .- k .",
    "liu , s.  t flammia , s.  becker , and j.  eisert .",
    "quantum state tomography via compressed sensing .",
    ", 105(15):150401 , 2010 .    m.  guta , t.  kypraios , and i.  dryden .",
    "rank - based model selection for multiple ions quantum tomography .",
    ", 14:105002 , 2012 .",
    "h.  haeffner , w.  haensel , c.  f. roos , j.  benhelm , d.  c. al  kar , m.  chwalla , t.  koerber , u.  d. rapol , m.  riebe , p.  o. schmidt , c.  becher , o.  ghne , w.  dur , and r.  blatt .",
    "scalable multi - particle entanglement of trapped ions .",
    ", 438:643 , 2005 .    m.  hoffmann and r.  nickl . on adaptive inference and confidence bands .",
    ", 39:23822409 , 2011 .    a.  s. holevo . .",
    "springer , 2001 .",
    "y.  i. ingster , tsybakov  a. b. , and n.  verzelen .",
    "detection boundary in sparse regression .",
    ", 4:14761526 , 2010 .",
    "a.  javanmard and a.  montanari .",
    "confidence intervals and hypothesis testing for high - dimensional regression . , 15(1):28692909 , 2014 .",
    "v.  koltchinskii .",
    "von neumann entropy penalization and low - rank matrix estimation . , 39(6):29362973 , 2011 .",
    "v.  koltchinskii , k.  lounici , and a.  b. tsybakov .",
    "nuclear - norm penalization and optimal rates for noisy low - rank matrix completion .",
    ", 39(5):23022329 , 2011 .",
    "u.  leonhardt . .",
    "cambridge university press , cambridge , 2005 .",
    "honest confidence regions for nonparametric regression . , 17:10011008 , 1989 .",
    "_ , pages 16381646 , 2011 .",
    "r.  nickl and s.  van  de geer .",
    "confidence sets in sparse regression . , 41(6):28522876 , 2013 .",
    "m.  a. nielsen and i.  l. chuang . .",
    "cambridge university press , cambridge , 2000 .",
    "a.  peres . .",
    "springer , berlin , 1995 .",
    "b.  recht , m.  fazel , and p.  a. parrilo .",
    "guaranteed minimum - rank solutions of linear matrix equations via nuclear norm minimization .",
    ", 52:471 , 2010 .",
    "j.  robins and a.w . van  der vaart .",
    "adaptive nonparametric confidence sets . , 34:229253 , 2006 .",
    "j.  shang , h.  k. ng , a.  sehrawat , x.  li , and b .-",
    "optimal error regions for quantum state estimation . , 15(12):123026 , 2013 .",
    "a.  smith , c.  a. riofrio , b.  e. anderson , h.  sosa - martinez , i.  h. deutsch , and p.  s. jessen .",
    "quantum state tomography by continuous measurement and compressed sensing .",
    ", 87:030102(r ) , 2013 .",
    "k.  temme and f.  verstraete .",
    "quantum chi - squared and goodness of fit testing .",
    ", 56(1):012202 , 2015 .    s.  van  de geer , p.  bhlmann , y.  ritov , and r.  dezeure . on asymptotically optimal confidence regions and tests for high - dimensional models",
    ", 42(3):11661202 , 2014 .",
    "zhang and s.  s. zhang .",
    "confidence intervals for low dimensional parameters in high dimensional linear models . , 76(1):217242 , 2014 .",
    "this work was partly motivated by a problem arising in present - day physics experiments that aim at estimating quantum states .",
    "conceptually , a quantum mechanical experiment involves two stages : a _ source _ ( or _ preparation procedure _ ) that emits quantum mechanical systems with unknown properties , and a _ measurement device _ that interacts with incoming quantum systems and produces real - valued measurement outcomes , e.g.  by pointing a dial to a value on a scale .",
    "quantum mechanics stipulates that both stages are completely described by certain matrices .",
    "the properties of the source are represented by a positive semi - definite unit trace matrix @xmath4 , the _ quantum state _",
    ", also referred to as _",
    "density matrix_. in turn , the measurement device is modelled by a hermitian matrix @xmath384 , which is referred to as an _ observable _ in physics jargon .",
    "a key axiom of the quantum mechanical formalism states that if the measurement @xmath384 is repeatedly performed on systems emitted by the source that is preparing @xmath4 , then the real - valued measurement outcomes will fluctuate randomly with expected value @xmath541 the precise way in which physical properties are represented by these matrices is immaterial to our discussion ( cf .  any textbook , e.g.ref .",
    "we merely note that , while in principle _ any _ hermitian @xmath384 can be measured by some physical apparatus , the required experimental procedures are prohibitively complicated for all but a few highly structured matrices .",
    "this motivates the introduction of _ pauli designs _",
    "below , which correspond to fairly tractable ` spin measurements ' .    the _ quantum state estimation _ or _ _ quantum tomography _ _ have no technical connection to classical tomographic reconstruction algorithms .",
    "] problem is to estimate an unknown density matrix @xmath4 from the measurement of a collection of observables @xmath542 .",
    "this task is of particular importance to the young field of quantum information science @xcite .",
    "there , the sources might be carefully engineered components used for technological applications such as quantum key distribution or quantum computing . in this",
    "context , quantum state estimation is the process of characterising the components one has built  clearly an important capability for any technology .",
    "a major challenge lies in the fact that relevant instances are described by @xmath7-matrices for fairly large dimensions @xmath117 ranging from 100 to 10.000 in presently performed experiments @xcite .",
    "such high - dimensional estimation problems can benefit substantially from structural properties of the objects to be recovered .",
    "fortunately , the density matrices occurring in quantum information experiments are typically well - approximated by matrices of _ low rank _",
    "in fact , in the practically most important applications , one usually even aims at preparing a state of unit rank  a so - called _ pure quantum state_.      we now introduce a paradigmatic set of quantum measurements that is frequently used in both theoretical and practical treatments of quantum state estimation ( see , e.g. , refs .",
    "@xcite ) . for a more general account",
    ", we refer to standard textbooks @xcite .",
    "the purpose of this section is to motivate the ` pauli design ' case ( condition [ design]b ) of the main theorem , as well as the approximate gaussian noise model described in subsection [ bernoulli ] .",
    "we start by describing ` spin measurements ' on a single ` spin-@xmath544 particle ' .",
    "such a measurement corresponds to the situation of having @xmath545 . without worrying about the physical significance",
    ", we accept as fact that on such particles , one may measure one of three properties , referred to as the ` spin along the @xmath546 , or @xmath177-axis ' of @xmath547 .",
    "each of these measurements may yield one of two outcomes , denoted by @xmath548 and @xmath549 respectively .",
    "the mathematical description of these measurements is derived from the _ pauli matrices _",
    "@xmath550,\\ ,      \\sigma^2=\\left [      \\begin{array}{cc }      0 & -i\\\\      i & 0      \\end{array }      \\right],\\ ,      \\sigma^3 = \\left [      \\begin{array}{cc }      1 & 0\\\\      0 & -1      \\end{array }      \\right]\\ ] ] in the following way .",
    "recall that the pauli matrices have eigenvalues @xmath551 . for @xmath552 and @xmath553 ,",
    "we write @xmath554 for the normalised eigenvector of @xmath555 with eigenvalue @xmath492 .",
    "the spectral decomposition of each pauli spin matrix can hence be expressed as @xmath556 with @xmath557 denoting the projectors onto the eigenspaces .",
    "now , a physical measurement of the ` spin along direction @xmath558 ' on a system in state @xmath4 will give rise to a @xmath559-valued random variable @xmath560 with @xmath561 where @xmath562 .",
    "using eq .",
    "( [ eqn : spectral ] ) , this is equivalent to stating that the expected value of @xmath560 is given by @xmath563    next , we consider the case of joint spin measurements on a collection of @xmath19 particles .",
    "for each , one has to decide on an axis for the spin measurement .",
    "thus , the joint _ measurement setting _ is now described by a word @xmath564 .",
    "the axioms of quantum mechanics posit that the joint state @xmath4 of the @xmath19 particles acts on the tensor product space @xmath565 , so that @xmath566 .    likewise , the _ measurement outcome _ is a word @xmath567 , with @xmath568 the value of the spin along axis @xmath569 of particle @xmath570 . as above ,",
    "this prescription gives rise to a @xmath571-valued random variable @xmath560 .",
    "again , the axioms of quantum mechanics imply that the distribution of @xmath560 is given by @xmath572 note that the components of the random vector @xmath560 are not necessarily independent , as @xmath4 will generally not factorise it is often convenient to express the information in eq .",
    "( [ eqn : multispectral ] ) in a way that involves tensor products of pauli matrices , rather than their spectral projections . in other words",
    ", we seek a generalisation of eq.([eqn : singlepauli ] ) to @xmath19 particles . as a first step toward this goal ,",
    "let @xmath573 be the _",
    "parity function_. then one easily verifies @xmath574 in this sense , the tensor product @xmath575 describes a measurement of the parity of the spins along the respective directions given by @xmath558 .",
    "in fact , the entire distribution of @xmath560 can be expressed in terms of tensor products of pauli matrices and suitable parity functions . to this end , we extend the definitions above .",
    "write @xmath576\\ ] ] for the identity matrix in @xmath577 .",
    "for every subset @xmath253 of @xmath578 , define the ` parity function restricted to @xmath253 ' via @xmath579",
    "lastly , for @xmath580 and @xmath581 , the _ restriction of @xmath558 to @xmath253 _ is @xmath582 then for every such @xmath583 one verifies the identity @xmath584 in other words , the distribution of @xmath560 contains enough information to compute the expectation value of all observables @xmath585 that can be obtained by replacing the pauli matrices on an arbitrary subset @xmath253 of particles by the identity @xmath586 .",
    "the converse is also true : the set of all such expectation values allows one to recover the distribution of @xmath560 .",
    "the explicit formula reads @xmath587 and can be verified by direct computation .",
    "[ note that @xmath588 is effectively a fourier coefficient ( over the group @xmath589 ) of the distribution function of the @xmath590-valued random variable @xmath560 .",
    "equation  ( [ eqn : invft ] ) is then nothing but an inverse fourier transform . ]    in this sense , the information obtainable from joint spin measurements on @xmath19 particles can be encoded in the @xmath591 real numbers @xmath592 indeed , every such @xmath593 arises as @xmath594 for some ( generally non - unique ) combination of @xmath558 and @xmath253 .",
    "this representation is particularly convenient from a mathematical point of view , as the collection of matrices @xmath595 forms an ortho - normal basis with respect to the @xmath63 inner product .",
    "thus the terms in eq .",
    "( [ eqn : pauliexpansion ] ) are just the coefficients of a basis expansion of the density matrix @xmath4 . , without first measuring the spin of every particle and then computing a parity function .",
    "in fact , the ability to perform such correlation measurements is crucial for _ quantum error correction protocols _ @xcite .",
    "for practical reasons these setups are used less commonly in tomography experiments , though . ]",
    "following @xcite we use eq .",
    "( [ eqn : pauliexpansion ] ) as our model for quantum tomographic measurements .",
    "note that the @xmath596 satisfy condition [ design]b ) with coherence constant @xmath67 and @xmath18 . in the model ( [ model ] ) under condition [ design]b ) we wish to approximate @xmath597 for a fixed observable @xmath596 ( we fix the random values of the @xmath3 s here ) and for @xmath18 . if @xmath594 for some setting @xmath558 and subset @xmath253 , then the parity function @xmath598 has expected value @xmath599 ( see eqs .",
    "( [ expsam ] ) and ( [ pauldef ] ) ) , and itself is a bernoulli variable taking values @xmath86 with @xmath600 note that @xmath601 so indeed @xmath602 $ ] and the variance satisfies @xmath603 this is precisely the error model described in subsection [ bernoulli ] .",
    "* a ) : * consider the subspaces @xmath604 and @xmath605 of @xmath459 , where the @xmath606 s are the eigenvectors of the @xmath7 matrix @xmath37 corresponding to eigenvalues @xmath262 . since @xmath607 , we know that @xmath608 is not empty and there is a vectorial sub - space of dimension @xmath281 in the intersection .",
    "take @xmath609 such that @xmath610 .",
    "since @xmath611 , it can be written as @xmath612 for some coefficients @xmath613 . since the @xmath614 s are orthogonal eigenvectors of the symmetric matrix @xmath37 we necessarily have @xmath615 and thus @xmath616 since the @xmath617 s are all non - negative and ordered in decreasing absolute value , one has @xmath618 taking the supremum in @xmath183 yields the result .    *",
    "b ) : * for each @xmath619 , let us write the decomposition of @xmath620 on the basis of eigenvectors @xmath621 of @xmath37 as @xmath622 since the @xmath623 are the eigenvectors of @xmath37 we have @xmath624 where @xmath625 and @xmath626 , since the @xmath627 are orthonormal .",
    "the last expression is maximised in @xmath628 and under these constraints , when @xmath629 and @xmath630 if @xmath631 ( since the @xmath632 are in decreasing order ) , and this gives @xmath633"
  ],
  "abstract_text": [
    "<S> we construct minimax optimal non - asymptotic confidence sets for low rank matrix recovery algorithms . </S>",
    "<S> these are employed to devise sequential sampling procedures that guarantee recovery of the true matrix in frobenius norm after a data - driven stopping time @xmath0 for the number of measurements that have to be taken . with high probability , this stopping time is minimax optimal . </S>",
    "<S> we detail applications to quantum tomography problems where measurements arise from pauli observables . </S>",
    "<S> we also give a theoretical construction of a confidence set for the density matrix of a quantum state that has optimal diameter in nuclear norm . </S>",
    "<S> the non - asymptotic properties of our confidence sets are investigated in a simulation study .    _ </S>",
    "<S> key words : low rank recovery , quantum information , confidence sets _    ,    , + </S>"
  ]
}