{
  "article_text": [
    "forecasters are often faced with an ensemble of simulations which are to be interpreted as making quantitative predictions .",
    "indeed , ensembles of initial conditions have been operational in weather centers in both america  @xcite and europe  @xcite since the early nineties and there is a significant literature on their interpretation  @xcite .",
    "there is significantly less work on the design and interpretation of ensembles over model structures , although such ensembles are formed on weather ( tigge  @xcite ) , seasonal ( ensembles  @xcite ) and climate ( cmip5  @xcite ) forecast lead - times .",
    "this paper focuses on the interpretation of multi - model ensembles in situations where data are precious , that is where the forecast - outcome archive is relatively small .",
    "archives for seasonal forecasts fall into this category , typically limited to between 32 and 64 forecast - outcome pairs . at times",
    "the forecaster has only an  ensemble of convenience \" composed by collecting forecasts made by various groups for various purposes ; alternatively , multi - model ensembles could be formed in collaboration using an agreed experimental design .",
    "this paper was inspired by the ensembles project  @xcite , in which seven seasonal models were run in concert , with nine initial condition simulations under each model  @xcite .",
    "small archive parameters ( sap ) forecast systems are contrasted with large archive parameters ( lap ) forecast systems using the lessons learned in experimental design based on the results originally reported by higgins  @xcite .",
    "this is illustrated using a relatively simple chaotic dynamical system .",
    "specifically , the challenges posed when evaluation data are precious are illustrated by forecasting a simple one - dimensional system using four imperfect models .",
    "a variety of ensemble system designs are considered : the selection of parameters , including model weights , and the relative value of  more \" ensemble members from the  best \" model are discussed . in the large forecast - archive",
    "limit , the selection of model weights is shown to be straightforward and the results are robust ; when a unique set of weights are not well defined , the results remain robust in terms of predictive performance .",
    "it is shown that when the forecast - outcome archive is nontrivial but small , as it is in seasonal forecasting , uncertainty in model weights is large .",
    "the parameters of the individual model probability forecasts vary widely in the sap case ; they do not in the lap case . this does not guarantee that the forecast skill of sap is significantly inferior to that of lap , but it is shown that in this case the sap forecast systems are significantly ( several bits ) less skillful .",
    "the goal of this paper is to refocus attention on this issue ; not claim to have resolved it given only sap is made .",
    "turning to the question of forming a multi - model forecast system , it is shown that ( a ) the model weights assigned given sap are significantly inferior to those under lap ( and , of course , to the using ideal weights ) .",
    "( b ) estimating the best model in sap is problematic when the models have similar skill .",
    "( c ) multi - model  out of sample \" performance is often degraded due to the assignment of low ( zero ) weights to useful models .",
    "potential approaches to this challenge , beyond waiting many decades , are discussed .",
    "the ensembles project considered seasonal forecasts from seven different models ; an initial condition ensemble of 9 members was made for each model and launched four times a year ( in the months of february , may , august and november ) .",
    "the maximum lead time was 7 months , except for the november launch which extended to 14 months .",
    "details of the project can be found in  @xcite    the models are not exchangeable in terms of the performance of their probabilistic forecasts .",
    "construction of predictive functions via kernel dressing and blending with climatology ( see  @xcite and appendix a ) for each initial condition ensemble of simulations is discussed in  @xcite ( under various levels of cross validation ) . throughout this paper , ij good s logarithmic score",
    "is used  @xcite , this score is sometimes referred to as ignorance ( ign )  @xcite .",
    "ign is the only proper and local score for continuous variables  @xcite , it is defined by : @xmath1 where @xmath2 is the outcome and @xmath3 is the probability of the outcome @xmath2 . in practice ,",
    "given @xmath4 forecast - outcome pairs @xmath5 , the empirical average ignorance score of a forecast system is then @xmath6",
    "without any suggestion that probabilistic forecasting of a one - dimensional chaotic map reflects the complexity or the dynamics of seasonal forecasting of the earth system , this paper draws parallels between challenges to probability forecasting of scalar outcomes using multiple models with different structural model errors when the forecast - outcome archive from the system is small ; these challenges occur both in low dimensional systems and in high dimensional systems . whether or not suggestions inspired by the low - dimensional case below generalise to high dimensional cases ( or other low dimensional cases , for that matter ) , would have to be evaluated on a case by case basis .",
    "the argument below is that the challenges themselves can be expected in high - dimensional cases , leading to the suggestion that they should be considered in the design of all multi - model forecast experiments .",
    "the system used throughout this paper is the moran - ricker map  @xcite given in equation  [ eq : mr ] .",
    "selection of a simple mathematical system allows the option of examining the challenges of a small forecast - outcome archive in the context of results based on huge archives .",
    "this is rarely possible for a physical system ( see however  @xcite ) . in this section the mathematical structure of the system and",
    "four imperfect models are specified .",
    "the specific structure of these models reflects a refined experimental design in light of the results of  @xcite .",
    "let @xmath7 be the state of moran - ricker map at time @xmath8 .",
    "the evolution of the system state @xmath9 is given by the moran - ricker map , i.e. @xmath10 in the experiments presented in this paper , @xmath11 , where the system is somewhat ",
    "less chaotic \" than using the value adopted in @xcite ( figure 1 shows the lyapunov exponent as a function of system parameter @xmath12  @xcite ) , in order to build models with comparable forecast skills .",
    "define the observation at time @xmath13 to be @xmath14 , where the observational noise , @xmath15 , is independent normally distributed ( @xmath16 ) .",
    "four one - dimensional deterministic models are constructed as imperfect models of the moran - ricker system . in experiments presented here , the focus is on designing ensemble scheme and ensemble parameter selection for producing predictive distribution , therefore the imperfect models as well as their parameter values are fixed .",
    "these four models share the same state space as the system , and the observations are complete . note in practice , it is almost always the case that the model state @xmath17 lies in a different space from the system state @xmath9 .",
    "the models are :    * * model i * , @xmath18 , is built by first expanding the exponential term in equation  [ eq : mr ] to @xmath19 order : @xmath20 the coefficient of each polynomial term is then truncated at the @xmath21 decimal place : @xmath22 * * model ii * , @xmath23 , is derived by first taking the log of equation  [ eq : mr ] and expanding to the @xmath24 order : @xmath25 the coefficient of each polynomial term is then truncated at the @xmath26 decimal place : @xmath27 * * model iii * , @xmath28 , is obtained by expanding the right hand side of equation  [ eq : mr ] in a fourier series over the range @xmath29 .",
    "this series is then truncated at the @xmath30 order to yield + @xmath31 , \\nonumber\\end{aligned}\\ ] ] + where the coefficients @xmath32 and @xmath33 are obtained by @xmath34 * * model iv * , @xmath35 , is defined by + @xmath36 + where @xmath37 is taken to be 0.02 .",
    "technically , the addition of @xmath37 means model iv is a case of parameter uncertainty , * not * structural model error .",
    "notice that the order of the truncation for model i , ii and iii are different .",
    "the order of the truncation for the first three models and also the parameter @xmath37 for model iv are chosen so that those models present the system dynamics well and the scales of their forecast skill are comparable .",
    "figure  [ fig : maperr1 ] plots the model dynamics of each model together with the system dynamics .",
    "figure  [ fig : histerr1 ] presents the histogram of the 1-step model error over 2048 different initial conditions .",
    "it appears that model i simulates the system dynamics well except when the initial condition is near the maximum value of the system . for model",
    "ii , the difference between model dynamics and system dynamics appears only when the initial condition is near the minimum value of the system .",
    "model iii does nt match the system dynamics well where @xmath38 and where @xmath39 reaches the maximum value of the map .",
    "model iv mapping the initial condition to lower values comparing with the system , the larger the images are , the more differences .    figure  [ fig : maperr2 ] plots the two - step model error for each model , while figure  [ fig : histerr2 ] presents the histogram of the 2-step model error .",
    "generally the structure of the model error is different .",
    "different models have different scales of model error in different state space .",
    "again , there is , of course , no suggestion that the moran - ricker system resembles the dynamics of the earth .",
    "rather , the framework presented here ( and in  @xcite ) provides probability forecasts from structurally flawed models ; both the model - based forecasts ( and an ideal probability forecast given the system ) differ nontrivially from each other , and as the models are nonlinear the forecast distributions are non - gaussian .",
    "it is these challenges to multi - model forecast system development which are illustrated in this paper , which should ( of course ) not be taken to present an actual geophysical forecast system ; indeed the computational requirements and length of the observational record would arguably preclude examination of lap of  state of the art \" geophysical models .",
    "in the experiments presented in this paper , each model produces its ensemble forecasts by iterating an ensemble of initial conditions ( ic ) .",
    "the initial condition ensemble is formed by perturbing the observation with random draws from a normal distribution , @xmath40 .",
    "the perturbation parameter @xmath41 is chosen to minimize the ignorance score at lead time @xmath42 .",
    "when making medium - range forecasts , ecmwf selects a perturbation size such that the rms error between the ensemble members and ensemble mean at a lead time of two days is roughly equal to the rms of ensemble mean and the outcome at two days .    in experiments presented here , each initial condition ensemble will contain @xmath43 members , following the ensembles protocol .",
    "consider first the case of a large archive , with @xmath44 .",
    "for a given @xmath45 and lead time @xmath42 , the kernel dressing and climatology - blend parameter values are fitted using a training forecast - outcome set which contains 2048 forecast - outcome pairs .",
    "the ignorance score is then calculated using an independent testing forecast - outcome set which also contains 2048 forecast - outcome pairs .",
    "figure  [ fig : kappa]a shows the best found perturbation parameter @xmath45 for each model varies with lead time .",
    "the ignorance score for each model at different lead time , using the values of @xmath45 in figure  [ fig : kappa ] a , is shown in figure  [ fig : kappa ] b. as seen in figure 6a , for each model the preferred value of @xmath45 varies significantly ( about a factor of 2 ) between different lead times . defining a @xmath46 member forecast system requires selecting a single value of @xmath45 for each model . in this paper ,",
    "the value of @xmath45 for each model is chosen by optimizing the forecast ignorance score at lead time 1 .",
    "sensitivity tests have been conducted and the ignorance score at other lead times is much less sensitive to @xmath45 than that at lead time 1 .",
    "knowledge of the relationship between ensemble size and forecast quality aids forecast system design .",
    "the cost of increasing the number of ensemble members is typically small relative to the cost of developing a new model .",
    "the cost of increasing the ensemble size increases only ( nearly ) linearly .",
    "as the number of ensemble members increases , the true limits of the model structure become more apparent .",
    "figure  [ fig : ens_size ] shows forecast ignorance varies as ensemble size increases .",
    "improvement from additional ensemble members can be noted , especially at shorter lead times .",
    "as the size of the forecast - outcome archive , @xmath47 , increases one expects robust results since large training sets and large testing sets can be considered . to examine this ,",
    "512 different training sets are produced , each contains 2048 forecast - outcome pairs . and",
    "for each archive , the kernel width @xmath48 and climatology - blend weight @xmath49 for each model forecasts are fitted at different lead time .",
    "figures  [ fig : largeset]a and  [ fig : largeset]b show the fitted values of dressing parameters and climatology - blend weights .",
    "the error bars reflect the central @xmath50 percentile over 512 samples .",
    "the variation of the weight assigned to the model appears small .",
    "the variation of the fitted kernel width is small at short lead time and large at long lead time . especially at lead time",
    "@xmath51 , the fitted value for model iv has relatively large variation .",
    "this , however , does not indicate the estimate is not robust but suggests the ignorance score function in the parameter space is relatively flat near the minimum . to demonstrate this the empirical ignorance",
    "is calculated for each archive of kernel width and climatology - blend weight based on the same testing set which contains another 2048 forecast - outcome pairs .",
    "figure  [ fig : largeset]c plots the ignorance score and its @xmath50 percentile as a function of lead time .",
    "notice the @xmath50 percentile ranges are very narrow all the time .",
    "there are many ways in which forecast distributions , generated from ensembles of individual model runs can be combined to produce a single probabilistic multi - model forecast distribution .",
    "one approach may be to assign equal weight to each model and simply sum the distributions generated from each model to obtain a single probabilistic distribution ( see @xcite ) .",
    "in general , different forecast models do not provide equal amounts of information , one may want to weight the models according to some measure of past performance , see for example  @xcite .",
    "the combined multi - model forecast is the weighted linear sum of the constituent distributions , @xmath52 where the @xmath53 is the forecast distribution from model @xmath54 and @xmath55 its weight , with @xmath56 .",
    "the weighting parameters may be chosen by minimizing the ignorance score for example , although fitting @xmath55 in this way can be costly and is typically complicated by different models sharing information . and",
    ", of course , the weights of individual models are expected to vary as a function of lead time .    to avoid ill fitting model weights ,",
    "a simple iterative method to combine models is used below instead of fitting all the weights simultaneously . for each lead time , the best ( in terms of ignorance ) model is first combined with the second best model to form a combined forecast distribution ( by assigning weights to both models ) .",
    "the combined forecast distribution is then combined with the third best model to update the combined forecast distribution .",
    "repeat this process until the worst model is considered .",
    "figure  [ fig : largeset]d shows the weights assigned to each model as a function of lead time .",
    "the cyan line in figure  [ fig : largeset]c shows the variation of ignorance score for the multi - model forecast given those estimated model weights is very small .      when given a small forecast - outcome archive ( e.g. @xmath57 year seasonal forecast - outcome archive ) , one does nt have the luxury of exploring a large collection of independent training and testing sets .",
    "cross validation is often approached by adopting a leave - one - out approach .",
    "the robustness of fitting in such cases is of more concern . to examine such robustness ,",
    "a large number of forecast - outcome archives are considered , each archive contains the same numbers of forecast - outcome pairs . for each archive ,",
    "the parameter values are fitted via leave - one - out cross - validation .",
    "the distribution of fitted values over these small forecast - outcome archives are then compared with the fitted value from @xmath58 large forecast - outcome archives above .",
    "figure  [ fig : alpha_small ] plots the histograms of the fitted climatology - blend weights given 512 forecast - outcome archives each contain @xmath59 forecast - outcome pairs .",
    "notice that in most of the cases the distributions are very wide although they cover the value fitted given the large training set .",
    "there are some cases in which about 90 percent of the estimates are larger or smaller than the values fitted by large archive , e.g. lead time 1 of model i and model ii , lead time 4 of model iii and lead time 5 of model iv .",
    "it appears that _ the robustness of fitting varies with lead time and the model_. for shorter lead time however the weights are more likely over fitted and for longer lead time the weights are more likely under fitted .",
    "this is because at short lead time the model forecasts are relatively good ; only a few forecasts are worse than the climatological forecast , and small forecast - outcome archives may not contain any model busts and so over estimate the weights .",
    "the longer lead time case can be similarly explained .",
    "figure  [ fig : segma_small ] plots the histogram of fitted kernel widths .",
    "again observe there is much larger variation of the estimates than fitting with large forecast - outcome archives .",
    "poor estimation of the kernel width and climatology - blend weight will cause the forecast to lose skill .",
    "given the 512 fitted kernel width and climatology - blend weights , the ignorance scores for them is calculated over the same testing set of 2048 forecast - outcome pairs .",
    "figure  [ fig : ign_small ] plots the histogram of the ignorance score for each model . using parameters fitted with small archives often results in significant degrading ( @xmath60 bit ) of the ignorance score of the forecasts . correctly blended with the climatological distribution would yield a forecast score which , in expectation , is never worse than the climatology ; when the blending parameter is determined using the small archive , however , the relative ignorance can be worse than climatology out of sample at long lead time ( see for example in figure  [ fig : ign_small ] ) .",
    "figure  [ fig : weights_small ] plots the histogram of multi - model weights .",
    "clearly the variation of the model weights based on small archive are much larger , weights of zero are often assigned to models forecast which contain useful information .",
    "it is sometimes said that a multi - model ensemble forecast is more skillful than any of its constituent single - model ensemble forecasts ( see  @xcite ) .",
    "a common  explanation \" for this is the claim that the multi - model ensemble forecast reduces an apparent overconfidence in any one model ( see for example  @xcite ) .",
    "as shown in section 6 , single model sap forecast systems are typically between half a bit and two bits less skillful than a lap system based on the same model ; can a multi - model forecast system regain some of this potential skill ?",
    "figure  [ fig : weights_small ] shows that this is unlikely , as the determination of model - weights given sap varies tremendously relative to their lap values .",
    "again , it is the performance of the combination of weights that determine the skill of the forecasts , so this variation need not always deadly .    figure  [ fig : mme_bm ] shows skill of the multi - model systems relative to a system based on single best model .",
    "both sap and lap forecast systems show the multi - model system usually outperforms the single model . comparing sap multi - model systems with the single best model sap system ( figure  [ fig : mme_bm]b ) ,",
    "the advantage of the multi - model system(s ) is stronger when the best model ( as well as all the parameters : model weights and dressing and climatologicy - blended parameters ) are ill - identified . comparing sap multi - model systems with the single best model lap system ( figure  [ fig : mme_bm]c ) , however , the advantage of the multi - model system(s ) is weaker ; multi - model systems do * not * always outperform the single best model , especially at longer lead times .    at this point ,",
    "one faces questions of resource distribution , a fair comparison of the multi - model forecast system would be against a single model with n - times larger ensemble .",
    "( this , of course , ignores the operational fact that it is much more demanding to maintain an ensemble of models than to maintain a large ensemble under one model . ) secondly , note that for each model @xmath45 was a function of lead time , at the cost of making ensemble members non - exchangeable one could draw ensembles from distinct groups , and weight these members differently for each lead time .",
    "finally , one could develop methods which treat the raw ensemble members from each of the models as non - exchangeable and use a more complex interpretation to form the forecast . while the simple forecast framework of this paper is an ideal place to explore such questions , they lie beyond the scope of this paper .",
    "instead , it is concluded by considering the extent to which the multi - model forecast system is more misleading than the single model systems .",
    "a significant challenge to the design of seasonal probability forecasting has been discussed and illustrated in a simple system where multiple models can easily be explored in long time limits .",
    "there is no statistical fix to challenges of  lucky strikes \" when a generally poor model places an ensemble member near an outcome by chance , and that particular outcome was not well predicted by the other forecast systems",
    ". similarly  hard busts \" in a small archive can distort the parameters of the forecast systems based on it : when an outcome occurs relatively far from each ensemble member , wider kernels and/or heavier weighting on the climatology results .",
    "this may be due to structural model failure , or merely to  rare \" event , where rare would be related to the ensemble size .    in short , the brief duration of the forecast - outcome archive , typically less than 40 years in seasonal forecast ,",
    "limit the clarity both with which probability distributions can be derived from individual models and with which model weights can be determined .",
    "no clear solution to this challenge has been proposed , and while improvements on current practice can be made , it is not clear that this challenge can be met . over long periods , like the 512 years",
    ", the climate may not be well approximated as stationary ; in any event both observational systems and the models themselves will evolve significantly , perhaps beyond recognition .",
    "one avenue open to progress is in determining the relative skill of  the best model \" ( or a small subset ) and the full diversity of models .",
    "following  @xcite it is argued that a large ensemble , forecast system under the best model , may well outperform the multi - model ensemble forecast system when both systems are given the same total computer power ; to test this in practice requires access to larger ensembles under the best model .",
    "a second avenue is to reduce the statistical uncertainty of model fidelity within available archive .",
    "this can be done by running large ensembles ( much greater than  9 \" , indeed greater than might be operationally feasible ) under each model .",
    "this would allow identification of which models have significantly different probabilities distributions , and the extent to which they are ( sometimes ) complementary .",
    "tests with large ensembles also reveal the  bad busts \" due to small ensemble size to be what they are ; it can also suggest that those which remain are indeed due to structural model error .",
    "it is suggested that perhaps the most promising way forward is to step away from the statistics of the ensembles , and example the physical realism of the individual trajectories .",
    "one can look for shadowing trajectories in each model , and one can attempt to see what phenomena limit the models ability to shadow . identifying these phenomena , and those that cause them in turn , would allow model improvement independent of the probabilistic skill of ensemble systems .",
    "this approach is not new of course , but the traditional physical approach to model improvement which dates back to charney .",
    "modern forecasting methods do offer some new tools  @xcite , and the focus on probabilistic forecasting is well placed in terms of prediction ; the point here is merely that probabilistic forecast skill , while a sharp tool for decision support , may prove a blunt tool for model improvement when the data are precious .",
    "* appendix *",
    "an ensemble of simulations is transformed into a probabilistic distribution function by a combination of kernel dressing and blending with climatology ( see @xcite ) . an @xmath61-member ensemble at time @xmath13",
    "is given as @xmath62 $ ] , where @xmath63 is the value of a observable quantity for the @xmath64 ensemble member .",
    "for simplicity , ensemble members under given a model are considered exchangeable .",
    "kernel dressing defines the model - based component of the density as : @xmath65 where @xmath66 is a random variable corresponding to the density function @xmath67 and @xmath4 is the kernel , taken here to be @xmath68 thus each ensemble member contributes a gaussian kernel centred at @xmath69 . for a gaussian kernel ,",
    "the kernel width @xmath48 is simply the standard deviation determined empirically as discussed below .    for any finite ensemble",
    ", there remains the chance of @xmath70 that the outcome lies outside the range of the ensemble even when the outcome is selected from the same distribution as the ensemble itself .",
    "given the nonlinearity of the model , such outcomes can be very far outside the range of the ensemble members .",
    "in addition to @xmath61 being finite , the simulations are not drawn from the same distribution as the outcome as the ensemble simulation system is not perfect . to improve the skill of the probabilistic forecasts ,",
    "the kernel dressed ensemble may be blended with an estimate of the climatological distribution of the system ( see  @xcite for more details , @xcite for an alternative kernels and  @xcite for a bayesian approach ) .",
    "the blended forecast distribution is then written as @xmath71 where @xmath72 is the density function generated by dressing the model ensemble and @xmath73 is the estimate of climatological density .",
    "the blending parameter @xmath49 determines how much weight is placed in the model . specifying both values",
    "( kernel width @xmath48 , and climatology blended parameter @xmath49 ) at each lead time defines the forecast distribution .",
    "both parameters are fitted simultaneously by optimising the empirical ignorance score in the training set .",
    "this research was supported by the lse s grantham research institute on climate change and the environment and the esrc centre for climate change economics and policy , funded by the economic and social research council and munich re ; it was also funded as part of the epsrc - funded blue green cities ( ep / k013661/1 ) .",
    "additional support for h.d .",
    "was also provided by the national science foundation award no . 0951576",
    " dmuu : center for robust decision making on climate and energy policy ( rdcep ) \" .",
    "l.a.s . gratefully acknowledges the continuing support of pembroke college , oxford .",
    "990 a. alessandri , a. borrelli , a. navarra , a. arribas , m. dqu , p. rogel , and a. weisheimer .",
    "evaluation of probabilistic quality and value of the ensembles multimodel seasonal forecasts : comparison with demeter .",
    "monthly weather review , 139 , 2 ( 2011 ) .      bougeault , p. , z. toth , c. bishop , b. brown , d. burridge , d. chen , e. ebert , m. fuentes , t. hamill , k. mylne , j. nicolau , t. paccagnella , y .- y .",
    "park , d. parsons , b. raoult , d. schuster , p. silva dias , r. swinbank , y. takeuchi , w. tennant , l. wilson and s. worley , the thorpex interactive grand global ensemble ( tigge ) .",
    "amer . met .",
    "soc . , 91 , 10591072 , ( 2010 ) .",
    "f. j. doblas - reyes , a. weisheimer , t. n. palmer , j. m. murphy and d. smith . forecast quality assessment of the ensembles seasonal - to - decadal stream 2 hindcasts . technical memorandum ( ecmwf ) , 621 ( 2010 ) .",
    "b. p. kirtman , d. min , j. m. infanti , j. l. kinter iii , d. a. paolino , q. zhang , h. van den dool , s. saha , m. p. mendez , e. becker , p. peng , p. tripp , j. huang , d. g. dewitt , m. k. tippett , a , g. barnston , s. li , a. rosati , s. d. schubert , m. rienecker , m. suarez , z. e. li , j. marshak , y .- k .",
    "lim , j. tribbia , k. pegion , w. j. merryfield , b. denis , and e. f. wood . the north american multi - model ensemble ( nmme ) : phase-1 seasonal to interannual prediction , phase-2 toward developing intra - seasonal prediction .",
    "bulletin of the american meteorological society , ( 2013 ) .",
    "t. n. palmer , a. alessandri , u. andersen , p. cantelaube , m. davey , p. dlcluse , m. dqu , e. diez , f. j. doblas - reyes , h. feddersen , r. graham , s. gualdi , j .- f .",
    "gurmy , r. hagedorn , m. hoshen , n. keenlyside , m. latif , a. lazar , e. maisonnave , v. marletto , a. p. morse , b. orfila , p. rogel , j .-",
    "terres , m. c. thomson .",
    "development of a european multimodel ensemble system for seasonal - to - interannual prediction ( demeter ) .",
    "bulletin of the american meteorological society , 85 , 853 - 872 ( 2004 ) .",
    "a. p. weigel , m. a. liniger , and c. appenzeller .",
    "can multi - model combination really enhance the prediction skill of probabilistic ensemble forecasts ?",
    "quarterly journal of the royal meteorological society , 134(630):241c260 ( 2008 ) .",
    "a. weisheimer , f. j. doblas - reyes , t. n. palmer , a. alessandri , a. arribas , m. dqu , n. keenlyside , m. macvean , a. navarra , and p. rogel .",
    "ensembles : a new multi - model ensemble for seasonal - to - annual predictions and skill and progress beyond demeter in forecasting tropical pacific ssts . geophysical research letters , 36(21 )"
  ],
  "abstract_text": [
    "<S> probability forecasting is common in the geosciences , the finance sector , and elsewhere . </S>",
    "<S> it is sometimes the case that one has multiple probability - forecasts for the same target . </S>",
    "<S> how is the information in these multiple forecast systems best  combined \" ? </S>",
    "<S> assuming stationary , then in the limit of a very large forecast - outcome archive , each model - based probability density function can be weighted to form a  multi - model forecast \" which will , in expectation , provide the most information . in the case </S>",
    "<S> that one of the forecast systems yields a probability distribution which reflects the distribution from which the outcome will be drawn , then bayesian model averaging will identify this model as the number of forecast - outcome pairs goes to infinity . </S>",
    "<S> in many applications , like those of seasonal forecasting , data are precious : the archive is often limited to fewer than @xmath0 entries . and no perfect model is in hand . in this case , it is shown that forming a single  multi - model probability forecast \" can be expected to prove misleading . </S>",
    "<S> these issues are investigated using probability forecasts of a simple mathematical system , which allows most limiting behaviours to be quantified . </S>"
  ]
}