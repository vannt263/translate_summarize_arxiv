{
  "article_text": [
    "entangled states are an essential resource for various quantum information processings@xcite . hence , it is required to generate maximally entangled states .",
    "however , for a practical use , it is more essential to guarantee the quality of generated entangled states .",
    "statistical hypothesis testing is a standard method for guaranteeing the quality of industrial products .",
    "therefore , it is much needed to establish the method for statistical testing of maximally entangled states .",
    "quantum state estimation and quantum state tomography are known as the method of identifying the unknown state@xcite .",
    "quantum state tomography @xcite has been recently applied to obtain full information of the @xmath0 density matrix . however , if the purpose is testing of entanglement , it is more economical to concentrate on checking the degree of entanglement .",
    "such a study has been done by tsuda et al @xcite as optimization problems of povm .",
    "however , an implemented quantum measurement can not be regarded as an application of a povm to a single particle system or a multiple application of a povm to single particle systems . in particular , in quantum optics , the following measurement is often realized , which is not described by a povm on a single particle system .",
    "the number of generated particles is probabilistic .",
    "we prepare a filter corresponding to a projection @xmath1 , and detect the number of particle passing through the filter .",
    "if the number of generated particles obeys a poisson distribution , as is mentioned in section [ s2 ] , the number of detected particles obeys another poisson distribution whose average is given by the density and the projection @xmath1 .    in this kind of measurements , if any particle is not detected , we can not decide whether a particle is not generated or it is generated but does not pass through the filter .",
    "if we can detect the number of generated particles as well as the number of passing particles , the measurement can be regarded as the multiple application of the povm @xmath2 . in this case , the number of applications of the povm is the variable corresponding to the number of generated particles .",
    "also , we only can detect the empirical distribution .",
    "hence , our obtained information almost discuss by use of the povm @xmath2 .    however , if it is impossible to distinguish the two events by some imperfections , it is impossible to reduce the analysis of our obtained information to the analysis of povms .",
    "hence , it is needed to analyze the performance of the estimation and/or the hypothesis testing based on the poisson distribution describing the number of detected particles .",
    "if we discuss the ultimate bound of the accuracy of the estimation and/or the hypothesis testing , we do not have to treat such imperfect measurements .",
    "since several realistic measurements have such imperfections , it is very important to optimize our measurement among such a class of imperfect measurements .    in this paper , our measurement",
    "is restricted to the detection of the number of the particle passing through the filter corresponding to a projection @xmath1 .",
    "we apply this formulation to the testing of maximally entangled states on two qubit systems ( two - level systems ) , each of which is spanned by two vectors @xmath3 and @xmath4 .",
    "since the target system is a bipartite system , it is natural to restrict to our measurement to local operations and classical communications ( locc ) . in this paper , for a simple realization , we restrict our measurements to the number of the simultaneous detections at the both parties of the particles passing through the respective filters . we also restrict the total measurement time @xmath5 , and optimize the allocation of the time for each filters at the both parties .    as our results , we obtain the following characterizations .",
    "if the average number of the generated particles is known , our choice is counting the coincidence events or the anti - coincidence events .",
    "when the true state is close to the target maximally entangled state @xmath6 ( that is , the fidelity between these is greater than @xmath7 ) , the detection of anti - coincidence events is better than that of coincidence events .",
    "this result implies that the indistinguishability between the coincidence events and the non - generation event loses less information than that between the anti - coincidence events and the non - generation event .",
    "this fact also holds even if we treat this problem taking into account the effect of dark counts . in this discussion , in order to remove the bias concerning the direction of the difference , we assume the equal time allocation among the vectors @xmath8 , which corresponds to the anti - coincidence events , and that among the vectors @xmath9 , which corresponds to the coincidence events , where @xmath10 , @xmath11 , @xmath12 , @xmath13 .",
    "indeed , barbieri et al @xcite proposed to detect the anti - coincidence events for measuring an entanglement witness , they did not prove the superiority of detecting the anti - coincidence events in the framework of mathematical statistics .",
    "however , the average number of the generated particles is usually unknown . in this case",
    ", we can not estimate how close the true state is to the target maximally entangled state from the detection of anti - coincidence events .",
    "hence , we need to count the coincidence events as additional information . in order to resolve this problem",
    ", we usually use the equal allocation between anti - coincidence events and coincidence events in the visibility method , which is a conventional method for checking the entanglement .",
    "however , since we measure the coincidence events and the anti - coincidence events based on one or two bases in this method , there is a bias concerning the direction of the difference . in order to remove this bias ,",
    "we consider the detecting method with the equal time allocation among all vectors @xmath8 and @xmath9 , and call it the modified visibility method .    in this paper",
    ", we also examine the detection of the total flux , which can be realized by detecting the particle without the filter .",
    "we optimize the time allocation among these three detections .",
    "we found that the optimal time allocation depends on the fidelity between the true state and the target maximally entangled state .",
    "if our purpose is estimating the fidelity @xmath14 , we can not directly apply the optimal time allocation .",
    "however , the purpose is testing whether the fidelity @xmath14 is greater than the given threshold @xmath15 , the optimal allocation at @xmath15 gives the optimal testing method .",
    "if the fidelity @xmath14 is less than a critical value , the optimal allocation is given by the allocation between the anti - coincidence vectors and the coincidence vectors ( the ratio depends on @xmath14 . ) otherwise , it is given by the allocation only between the anti - coincidence vectors and the total flux .",
    "this fact is valid even if the dark count exists .",
    "if the dark count is greater than a certain value , the optimal time allocation is always given by the allocation between the anti - coincidence vectors and the coincidence vectors .",
    "further , we consider the optimal allocation among anti - coincidence vectors when the average number of generated particles .",
    "the optimal allocation depends on the direction of the difference between the true state and the target state .",
    "since the direction is usually unknown , this optimal allocation dose not seems useful .",
    "however , by adaptively deciding the optimal time allocation , we can apply the optimal time allocation .",
    "we propose to apply this optimal allocation by use of the two - stage method .",
    "further , taking into account the complexity of testing methods and the dark counts , we give a testing procedure of entanglement based on the two - stage method .",
    "in addition , proposed designs of experiments were demonstrated by hayashi et al .",
    "@xcite in two photon pairs generated by spontaneous parametric down conversion ( spdc ) .    in this article ,",
    "we reformulate the hypothesis testing to be applicable to the poisson distribution framework , and demonstrate the effectiveness of the optimized time allocation in the entanglement test .",
    "the construction of this article is following .",
    "section [ s2 ] defines the poisson distribution framework and gives the hypothesis scheme for the entanglement .",
    "section [ s3 ] gives the mathematical formulation concerning statistical hypothesis testing .",
    "sections [ s4 ] and [ s5 ] give the fundamental properties of the hypothesis testing : section [ s4 ] introduces the likelihood ratio test and its modification , and section [ s5 ] gives the asymptotic theory of the hypothesis testing .",
    "sections [ s6]-[s9 ] are devoted to the designs of the time allocation between the coincidence and anti - coincidence bases : section [ s6 ] defines the modified visibility method , section [ s7 ] optimize the time allocation , when the total photon flux @xmath16 is unknown , section [ s8 ] gives the results with known @xmath16 , and section [ s9 ] compares the designs in terms of the asymptotic variance .",
    "section [ s10 ] gives further improvement by optimizing the time allocation between the anti - coincidence bases .",
    "appendices give the detail of the proofs used in the optimization .",
    "let @xmath17 be the hilbert space of our interest , and @xmath1 be the projection corresponding to our filter . if we assume generation process on each time to be identical but individual , the total number @xmath18 of generated particles during the time @xmath5 obeys the poisson distribution @xmath19 .",
    "hence , when the density of the true state is @xmath20 , the probability of the number @xmath21 of detected particles is given as @xmath22        in fact , if we treat the fock space generated by @xmath17 instead of the single particle system @xmath17 , this measurement can be described by a povm . however , since this povm dooes not have a simple form , it is suitable to treat this measurement in the form ( [ 5 - 8 - 1 ] ) .",
    "further , if we errorly detect the @xmath23 particles with the probability @xmath24 , the probability of the number @xmath21 of detected particles is equal to @xmath25 this kind of incorrect detection is called dark count .",
    "further , since we consider the bipartite case , i.e. , the case where @xmath26 , we assume that our projection @xmath1 has the separable form @xmath27 .    in this paper , under the above assumption",
    ", we discuss the hypothesis testing when the target state is the maximally entangled @xmath28 state while usami et al.@xcite discussed the state estimation under this assumption . here",
    "we measure the degree of entanglement by the fidelity between the generated state and the target state : @xmath29 the purpose of the test is to guarantee that the state is sufficiently close to the maximally entangled state with a certain significance .",
    "that is , we are required to disprove that the fidelity @xmath14 is less than a threshold @xmath15 with a small error probability . in mathematical statistics , this situation is formulated as hypothesis testing ; we introduce the null hypothesis @xmath30 that entanglement is not enough and the alternative @xmath31 that the entanglement is enough : @xmath32 with a threshold @xmath15 .",
    "visibility is an indicator of entanglement commonly used in the experiments , and is calculated as follows : first , a s measurement vector @xmath33 is fixed , then the measurement @xmath34 is performed by rotating b s measurement vector @xmath35 to obtain the maximum and minimum number of the counts , @xmath36 and @xmath37 .",
    "we need to make the measurement with at least two bases of a in order to exclude the possibility of the classical correlation .",
    "we may choose the two bases @xmath38 and @xmath39 as @xmath33 , for example .",
    "finally , the visibility is given by the ratio between @xmath40 and @xmath41 with the respective a s measurement basis @xmath33 .",
    "however , our decision will contain a bias , if we choose only two bases as a s measurement basis @xmath33 .",
    "hence , we can not estimate the fidelity between the target maximally entangled state and the given state in a statistically proper way from the visibility .",
    "since the equation @xmath42 holds , we can estimate the fidelity by measuring the sum of the counts of the following vectors : @xmath43 obeys the poisson distribution with the expectation value @xmath44 , where the measurement time for each vector is @xmath45 .",
    "we call these vectors the coincidence vectors because these correspond to the coincidence events .",
    "however , since the parameter @xmath16 is usually unknown , we need to perform another measurement on different vectors to obtain additional information .",
    "since @xmath46 also holds , we can estimate the fidelity by measuring the sum of the counts of the following vectors : @xmath47 obeys the poisson distribution @xmath48 , where the measurement time for each vector is @xmath49 . combining the two measurements",
    ", we can estimate the fidelity without the knowledge of @xmath16 .",
    "we call these vectors the anti - coincidence vectors because these correspond to the anti - coincidence events",
    ".    we can also consider different type of measurement on @xmath16 .",
    "if we prepare our device to detect all photons , i.e. , the case where the projection is @xmath50 , the detected number @xmath51 obeys the distribution @xmath52 ) with the measurement time @xmath53 . we will refer to it as the total flux measurement . in the following ,",
    "we consider the best time allocation for estimation and test on the fidelity , by applying methods of mathematical statistics .",
    "we will assume that @xmath16 is known or estimated from the detected number @xmath51 .",
    "in this section , we review the fundamental knowledge of hypothesis testing for probability distributions@xcite .",
    "suppose that a random variable @xmath54 is distributed according to a probability measure @xmath55 identified by the unknown parameter @xmath56 .",
    "we also assume that the unknown parameter @xmath56 belongs to one of mutually disjoint sets @xmath57 and @xmath58 .",
    "when we want to guarantee that the true parameter @xmath56 belongs to the set @xmath58 with a certain significance , we choose the null hypothesis @xmath30 and the alternative hypothesis @xmath31 as @xmath59 then , our decision method is described by a test , which is described as a function @xmath60 taking values in @xmath61 ; @xmath30 is rejected if @xmath62 is observed , and @xmath30 is not rejected if @xmath63 is observed .",
    "that is , we make our decision only when @xmath62 is observed , and do not otherwise .",
    "this is because the purpose is accepting @xmath31 by rejecting @xmath30 with guaranteeing the quality of our decision , and is not rejecting @xmath31 nor accepting @xmath31 .",
    "therefore , we call the region @xmath64 the rejection region . the test @xmath65 can be defined by the rejection region .",
    "in fact , we choosed the hypothesis that the fidelity is less than the given threshold @xmath66 as the null hypothesis @xmath30 in section [ s2 ] .",
    "this formulation is natural because our purpose is guaranteeing that the fidelity is not less than the given threshold @xmath66 .    from theoretical viewpoint ,",
    "we often consider randomized tests , in which we probabilistically make the decision for a given data .",
    "such a test is given by a function @xmath65 mapping to the interval @xmath67 $ ] .",
    "when we observe the data @xmath68 , @xmath30 is rejected with the probability @xmath60 . in the following , we treat randomized tests as well as deterministic tests .    in the statistical hypothesis testing , we minimize error probabilities of the test @xmath65 .",
    "there are two types of errors .",
    "the type one error is the case where @xmath30 is rejected though it is true .",
    "the type two error is the converse case , @xmath30 is accepted though it is false .",
    "hence , the type one error probability is given @xmath69 @xmath70 , and the type two error probability is given @xmath71 @xmath72 , where @xmath73 it is in general impossible to minimize both @xmath69 and @xmath71 simultaneously because of a trade - off relation between them . since we make our decision with guaranteeing its quality only when @xmath62 is observed , it is definitively required that the type one error probability @xmath69 is less than a certain constant @xmath74 .",
    "for this reason , we minimize the type two error probability @xmath71 under the condition @xmath75 .",
    "the constant @xmath74 in the condition is called the risk probability , which guarantees the quality of our decision .",
    "if the risk probability is large enough , our decision has less reliability . under this constraint for the risk probability ,",
    "we maximize the probability to reject the hypothesis @xmath30 when the true parameter is @xmath76 .",
    "this probability is given as @xmath69 , and is called the power of @xmath65 .",
    "hence , a test @xmath65 of the risk probability @xmath74 is said to be most powerful ( mp ) at @xmath77 if @xmath78 holds for any test @xmath79 of the risk probability @xmath74 .",
    "then , a test is said to be uniformly most powerful ( ump ) if it is mp at any @xmath77 .      in the hypothesis testing , we usually fixed our test before applying it to data .",
    "however , we sometimes focus on the minimum risk probability among tests in a class @xmath80 rejecting the hypothesis @xmath30 with a given data .",
    "this value is called the p - value , which depends on the observed data @xmath68 as well as the subset @xmath57 to be rejected .",
    "in fact , in order to define the p - value , we have to fix a class @xmath81 of tests .",
    "then , for @xmath68 and @xmath57 , p - value is defined as @xmath82 since the p - value expresses the risk for rejecting the hypothesis @xmath30 , hence , this concept is useful for comparison among several designs of experiment .",
    "note that if we are allowed to choose any function @xmath65 as a test , the above minimum is attained by the function @xmath83 : @xmath84 in this case , the p - vale is @xmath85 .",
    "however , the function @xmath83 is unnatural as a test .",
    "hence , we should fix a class of tests to define p - value .",
    "in mathematical statistics , the likelihood ratio tests is often used as a class of standard tests@xcite .",
    "this kind of tests often provide the ump test in some typical cases . when both @xmath57 and @xmath58 consist of single elements as @xmath86 and @xmath87 , the likelihood ratio test @xmath88 is defined as @xmath89 where @xmath90 is a constant , and the ratio @xmath91 is called the likelihood ratio . from the definition ,",
    "any test @xmath65 satisfies @xmath92    when a likelihood ratio test @xmath88 satisfies @xmath93 the test @xmath88 is mp of level @xmath74 .",
    "indeed , when a test @xmath65 satisfies @xmath94 , @xmath95 hence , @xmath96 .",
    "this is known as neyman - pearson s fundamental lemma[multiblock footnote omitted ] .",
    "the likelihood ratio test is generalized to the cases where @xmath57 or @xmath58 has at least two elements as @xmath97 usually , in order to guarantee a small risk probability , the likelihood ratio @xmath90 is choosed as @xmath98 .      in cases",
    "where the hypothesis is one - sided , that is , the parameter space @xmath99 is an interval of @xmath100 and the hypothesis is given as @xmath101 we often use so - called interval tests for its optimality under some conditions as well as for its naturalness .",
    "when the likelihood ratio @xmath102 is monotone increasing concerning @xmath68 for any @xmath103 such that @xmath104 , the likelihood ratio is called monotone . in this case , the likelihood ratio test @xmath88 between @xmath105 and @xmath106 is ump of level @xmath107 , where @xmath108 is an arbitrary element satisfying @xmath109 .",
    "indeed , many important examples satisfy this condition .",
    "hence , it is convenient to give its proof here .    from the monotonicity , the likelihood ratio test @xmath88 has the form @xmath110 with a threshold value @xmath111 .",
    "since the monotonicity implies @xmath112 for any @xmath113 , it follows from neyman pearson lemma that the likelihood ratio test @xmath88 is mp of level @xmath74 . from ( [ 2 - 14 - 1 ] ) , the likelihood ratio test @xmath88 is also a likelihood ratio test between @xmath105 and @xmath114 , where @xmath115 is another element satisfying @xmath116 .",
    "hence , the test @xmath88 is also mp of level @xmath74 .    from the above discussion",
    ", it is suitable to treat p - value based on the class of likelihood ratio tests . in this case , when we observe @xmath111 , the p - value is equal to @xmath117      in mathematical statistics , exponential families are known as a class of typical statistical models@xcite .",
    "a family of probability distributions @xmath118 is called an exponential family when there exists a random variable @xmath68 such that @xmath119 where @xmath120 .",
    "it is known that this class of families includes , for example , the poisson distributions , normal distributions , binomial distributions , etc . in this case , the likelihood ratio @xmath121 is monotone concerning @xmath68 for @xmath122 .",
    "hence , the likelihood ratio test is ump in the hypothesis ( [ eq : hypo - int ] ) .",
    "note that this argument is valid even if we choose a different parameter if the family has a parameter satisfying ( [ 2 - 17 - 3 ] ) .",
    "for example , in the case of the normal distribution @xmath123 , the ump test @xmath124 of the level @xmath74 is given as @xmath125 where @xmath126    the @xmath18-trial binomial distributions @xmath127 are also an exponential family because another parameter @xmath128 satisfies that @xmath129 .",
    "hence , in the case of the @xmath18-trial binomial distribution , the ump test @xmath130 of the level @xmath74 is given as the randomized likelihood ratio test : @xmath131 where @xmath132 is the maximum value @xmath23 satisfying @xmath133 , and @xmath134 is defined as @xmath135 therefore , when @xmath21 is observed , the p - value is @xmath136 .",
    "when @xmath18 is sufficiently large , the distribution @xmath137 can be approximated by the normal distribution with variance @xmath138 .",
    "hence , the ump test @xmath130 of the level @xmath74 is approximately given as @xmath139 the p - value is also approximated to @xmath140    the poisson distributions @xmath141 are also an exponential family because another parameter @xmath142 satisfies @xmath143 .",
    "the ump test @xmath124 of the level @xmath74 is characterized similarly to ( [ 5 - 4 - 1 ] ) .",
    "when the threshold @xmath144 is sufficiently large and the hypothesis is given @xmath145 the ump test @xmath124 of the level @xmath74 is approximately given as @xmath146 the p - value is also approximated to @xmath147    next , we consider testing the following hypothesis in the case of the binomial poisson distribution poi(@xmath148 ) : @xmath149 in this case , as is shown at ( [ 5 - 14 - 1 ] ) and ( [ 5 - 14 - 2 ] ) in section [ s4d ] , the likelihood ratio test @xmath88 is characetrized by the likelihood ratio test of the binomial distributions as @xmath150 hence , it is suitable to employ the likelihood ratio test @xmath151 with the level @xmath74 .",
    "this is because the conditional distribution @xmath152 is equal to the binomial distribution @xmath153 .",
    "therefore , when we observe @xmath154 , the p - value of this class of likelihood ratio tests is equal to @xmath155 .",
    "when the total number @xmath156 is sufficiently large , the test @xmath157 of the level @xmath74 is approximately given as @xmath158 the p - value is also approximated to @xmath159      in the one - parameter case , ump tests can be often characterized by likelihood ratiotests . however , in the multi - parameter case , this type characterization is impossible generally , and the ump test does not always exist . in this case , we have to choose our test among non - ump tests .",
    "one idea is choosing our test among likelihood ratio tests because likelihood ratio tests always exist and we can expect that these tests have good performances .",
    "generally , it is not easy to give an explicit form of the likelihood ratio test .",
    "when the family is a multi - parameter exponential family , the likelihood ratio test has a simple form .",
    "a family of probability distributions @xmath160 is called an @xmath161-parameter exponential family when there exists @xmath161-dimensional random variable @xmath162 such that @xmath163 where @xmath164 . however , this form is not sufficiently simple because its rejection region is given by the a nonlinear constraint .",
    "hence , a test with a simpler form is required . in the following ,",
    "we discuss the likelihood ratio test in the case of multi - nomial poisson distribution .",
    "after this discussion , we propose an alternative test .    in an @xmath161-parameter exponential family",
    ", the likelihood ratio test @xmath88 has the form @xmath165 where the divergence @xmath166 is defined as @xmath167 and @xmath168 is defined by @xcite @xmath169 this is because the logarithm of the likelihood function is calculated as @xmath170 in addition , @xmath168 coincides with the mle when @xmath171 is observed .",
    "hence , when @xmath172 , the likelihood ratio test with the ratio @xmath173 is given by the rejection region : @xmath174    in the case of the multi - nomial poisson distributions poi@xmath175 , which is an exponential family , the divergence is calculated as @xmath176 where @xmath177 is the divergence between the multinomial distributions @xmath178 and @xmath179 .",
    "when the hypothesis is given by ( [ eq : hypo - int-2 ] ) and @xmath180 , we have @xmath181 where @xmath55 is the binomial distribution with one observation and @xmath182 is the binomial distribution with @xmath18 observations .",
    "then , the likelihood ratio test is given by the likelihood ratio test of the binomial distributions .",
    "in the following , we treat two hypotheses given as @xmath183 with the condition @xmath184 , using the formula ( [ 5 - 14 - 3 ] ) , and ( [ eq : hypo - int-3 ] ) , we can calculate the likelihood ratio test for a given ratio @xmath90 .",
    "now , we calculate the p - value concerning the class of likelihood ratio tests when we observe the data @xmath185 . when @xmath186 , this p - value is equal to @xmath187 where @xmath188 because the minimum @xmath189 satisfying @xmath190 is @xmath191 .",
    "since the calculation of ( [ 3 - 7 - 7 ] ) is not so easy , we consider its upper bound .",
    "for this purpose , we define the set @xmath192 as @xmath193 where @xmath194 are defined as follows : @xmath195 where @xmath196 and @xmath197 .",
    "note that @xmath194 is a monotone decreasing function of @xmath189 .",
    "as is shown in appendix [ 3 - 6 - 10 ] , @xmath198 then , the p - value concerning likelihood ratio tests is upperly bounded by @xmath199    however , it is difficult to choose the likelihood @xmath90 such that the p - value is equal to a given risk probability @xmath74 because the set @xmath200 is defined by a non - linear constraint . in order to resolve this problem , we propose to modify the likelihood ratio test by using the set @xmath192 instead of the set @xmath200 because @xmath192 is defined by a linear constraint while @xmath200 is by a non - linear constraint . that is , we define the modified test @xmath201 as the test with the rejection region @xmath202 . among this kind of tests",
    ", we can choose the test @xmath203 with the risk probability @xmath74 by choosing @xmath204 in the following way : @xmath205 indeed , the calculation of the probability @xmath206 is easier than that of the probability @xmath207 because of the linearity of the constraint condition of @xmath192 .",
    "next , we calculate the p - value of the set of the modified tests @xmath208 . for an observed data @xmath209 ,",
    "we choose @xmath210 as @xmath211 satisfying @xmath212 the lhs is monotone increasing for @xmath211 because each @xmath213 is monotone decreasing for @xmath211 .",
    "thus , @xmath210 is the maximum @xmath211 such that @xmath214 .",
    "then , the p - value is equal to @xmath215 .",
    "further , the relation ( [ 5 - 2 - 1 ] ) implies @xmath216 .",
    "hence , @xmath217 , which implies @xmath218 .",
    "therefore , the p - value @xmath219 concerning the modified tests @xmath208 is smaller than the upper bound @xmath220 of p - value concerning the likelihood ratio tests .",
    "this test @xmath221 coincides with the likelihood ratio test in the one - parameter case .",
    "assume that the data @xmath222 obeys the identical and independent distribution of the same distribution family @xmath223 and @xmath18 is sufficiently large .",
    "when the true parameter @xmath56 is close to @xmath66 , it is known that the meaningful information for @xmath56 is essentially given as the random variable @xmath224 , where the logarithmic derivative @xmath225 is defined by @xmath226 in this case , the random variable @xmath227 can be approximated by the normal distribution with the expectation value @xmath228 and the variance @xmath229 , where the fisher information @xmath230 is defined as @xmath231 .",
    "hence , the testing problem can be approximated by the testing of this normal distribution family @xcite .",
    "that is , the quality of testing is approximately evaluated by the fisher information @xmath232 at the threshold @xmath66 .    in the case of poisson distribution family poi@xmath233",
    ", the parameter @xmath56 can be estimated by @xmath234 .",
    "the asymptotic case corresponds to the case with large @xmath5 . in this case",
    ", fisher information is @xmath235 .",
    "when @xmath54 obeys the unknown poisson distribution family poi@xmath233 , the estimation error @xmath236 is close to the normal distribution with the variance @xmath237 , _",
    "i.e. _ , @xmath238 approaches to the random variables obeying the normal distribution with variance @xmath56 .",
    "that is , fisher information corresponds to the inverse of variance of the estimator .",
    "this approximation can be extended to the multi - parameter case @xmath239 .",
    "similarly , it is known that the testing problem can be approximated by the testing of the normal distribution family with the covariance matrix @xmath240 , where the fisher information matrix @xmath241 is given by @xmath242 when the hypotheses is given by ( [ eq : hypo - int ] ) , the testing problem can be approximated by the testing of the normal distribution family with variance @xmath243 ,    indeed , the same fact holds for the multinomial poisson distribution family poi@xmath244 .",
    "when the random variable @xmath245 is the @xmath246-th random variable , the random variable @xmath247 converges to the random variable obeying the normal distribution with the variance @xmath248 in distribution : @xmath249 this convergence is compact uniform concerning the parameter @xmath250 . in this case , the fisher information matrix @xmath251 is the diagonal matrix with the diagonal elements @xmath252 .",
    "when our distribution family is given as a subfamily poi@xmath253 , the fisher information matrix is @xmath254 , where @xmath255 .",
    "hence , when the hypotheses is given by ( [ eq : hypo - int-3 ] ) , the testing problem can be approximated by the testing of the normal distribution family with variance @xmath256 in the following , we call this value fisher information .",
    "based on this value , the quality can be compared when we have several testing schemes .      in the following , we treat testing of the hypothesis ( [ eq : hypo - int-3 ] ) in the multinomial poisson distribution poi(@xmath250 ) by using normal approximation . in this case , by using @xmath257 defined in ( [ 2 - 6 - 12 ] ) and ( [ 2 - 6 - 11 ] ) , the upper bound ( [ 2 - 6 - 13 ] ) of the p - value concerning the likelihood ratio tests is approximated to @xmath258 because this convergence ( [ 3 - 7 - 1 ] ) is compact uniform concerning the parameter @xmath250 .",
    "letting @xmath259 and @xmath260 , we have @xmath261 where @xmath262 is the convex hull of @xmath263 . as is shown in appendix [ a5 ] , this value is simplified to @xmath264 where @xmath265 where    @xmath266    that is , our upper bound of p - value concerning the likelihood ratio tests is given by @xmath267    next , we approximately calculate the test with the risk probability @xmath74 proposed in section[s4d ] .",
    "first , we choose @xmath268 by @xmath269 then , our test is given by the rejection region @xmath270 . using the same discussion ,",
    "the p - value concerning the proposed tests is equal to @xmath271",
    "in the following sections , we apply the discussions in sections [ s3 ] - [ s5 ] to the hypothesis ( [ 5 - 5 - 2 ] ) . that is , we consider how to reject the null hypothesis @xmath272 with a certain risk probability @xmath74 .    in the usual visibility",
    ", we usually measure the coincidence events only in the one direction or two directions .",
    "however , in this method , the number of the counts of coincidence events be reflected not only by the fidelity but also by the direction of difference between the true state of target maximally entangled state . in order to remove the bias based on such a direction",
    ", we propose to measure the counts of the coincidence vectors @xmath273 and the given state @xmath20 , using the total number of counts of the coincidence events ( the total count on coincidence event ) @xmath274 and the total number of counts of the anti - coincidence events ( the total count on anti - coincidence events ) @xmath275 obtained by measuring on all the vectors with the time @xmath276 .",
    "when the dark count is negligible , the total count on coincidence events @xmath274 obeys poi@xmath277 , and the count on total anti - coincidence events @xmath275 obeys the distribution poi@xmath278 .",
    "these expectation values @xmath279 and @xmath280 are given as @xmath281 and @xmath282 .",
    "hence , fisher information matrix concerning the parameters @xmath14 and @xmath16 is @xmath283 where the first element corresponds to the parameter @xmath14 and the second one does to the parameter @xmath16 .",
    "then , we can apply the test @xmath284 given in the end of subsection [ 2 - 7 - 5 ] .",
    "that is , based on the ratio @xmath285 , we estimate the fidelity using the ratio @xmath286 as @xmath287 .",
    "based on the discussion in subsection [ 2 - 7 - 4 ] , its variance is asymptotically equal to @xmath288 hence , similarly to the visibility , we can check the fidelity by using this ratio .    indeed , when we consider the distribution under the condition that the total count @xmath156 is fixed to @xmath18 , the random variable @xmath275 obeys the binomial distribution with the average value @xmath289 .",
    "hence , we can apply the likelihood ratio test of the binomial distribution . in this case , by the approximation to the normal distribution , the likelihood ratio test with the risk probability @xmath74 is almost equal to the test with the rejection region : @xmath290 concerning the null hypothesis @xmath272 .",
    "the p - value of this kind of tests is @xmath291 .",
    "in this section , we consider the problem of testing the fidelity between the maximally entangled state @xmath292 and the given state @xmath20 by performing three kinds of measurement , coincidence , anti - coincidence , and total flux , with the times @xmath293 and @xmath53 , respectively . when the dark count is negligible , the data @xmath294 obeys the multinomial poisson distribution poi@xmath295 with the assumption that the parameter @xmath16 is unknown . in this problem , it is natural to assume that we can select the time allocation with the constraint for the total time @xmath296 .",
    "the performance of the time allocation @xmath297 can evaluated by the variance ( [ 2 - 16 - 5 ] ) .",
    "the fisher information matrix concerning the parameters @xmath14 and @xmath16 is @xmath298 where the first element corresponds to the parameter @xmath14 and the second one does to the parameter @xmath16 .",
    "then , the asymptotic variance ( [ 2 - 16 - 5 ] ) is calculated as @xmath299 we optimize the time allocation by minimizing the variance ( [ 2 - 16 - 10 ] ) .",
    "we perform the minimization by maximizing the inverse : @xmath300 . applying lemmas [ 2 - 24 - 6 ] and [ 2 - 18 - 6 ] shown in appendix [ app1 ] to the case of @xmath301 , @xmath302 , @xmath303 , @xmath304",
    ", we obtain @xmath305 and @xmath306 then , these relations give the optimal time allocations between ( i ) coincidence and total flux measurements , ( ii ) anti - coincidence and total flux measurements , and ( iii ) coincidence and anti - coincidence measurements , respectively .",
    "the ratio of ( [ 2 - 19 - 3 ] ) to ( [ 2 - 19 - 1 ] ) is equal to @xmath307 as shown in appendix [ 2 - 24 - 10 ] .",
    "that is , the optimal measurement using the coincidence and the anti - coincidence always provides better test than that using the coincidence and the total flux .",
    "hence , we compare ( ii ) with ( iii ) , and obtain @xmath308 where the critical point @xmath309 is defined by @xmath310 the approximated value of the critical point @xmath311 is @xmath312 . the equation ( [ 2 - 24 - 11 ] )",
    "is derived in appendix [ 2 - 24 - 12 ] .",
    "[ ratio1 ] shows the ratio of the optimal fisher information based on the anti - coincidence and total flux measurements to that based on the coincidence and anti - coincidence measurements .",
    "when @xmath313 , the maximum fisher information is attained by @xmath314 , @xmath315 , @xmath316 . otherwise , the maximum is attained by @xmath317 , @xmath318 , @xmath319 . the optimal time allocation shown in fig .",
    "[ ratio1 ] implies that we should measure the counts on the anti - coincidence vectors preferentially over other vectors .    .",
    "the measurement time is divided into three periods : coincidence @xmath320 ( plus signs ) , anti - coincidence @xmath321 ( circles ) , and total flux @xmath322 ( squares ) , which are normalized as @xmath323 in the plot.,width=302 ]    the optimal asymptotic variance is @xmath324 when the threshold @xmath15 is less than the critical point @xmath311 .",
    "this asymptotic variance is much better than that obtained by the modified visibility method .",
    "the ratio of the optimal asymptotic variance is given by @xmath325    in the following , we give the optimal test of level @xmath74 in the hypothesis testing ( [ eq : hypo ] ) .",
    "assume that the threshold @xmath15 is less than the critical point @xmath311 . in this case",
    ", we can apply testing of the hypothesis ( [ eq : hypo - int-2 ] ) .",
    "first , we measure the count on the coincidence vectors for a period of @xmath326 , to obtain the total count @xmath327 .",
    "then , we measure the count on the anti - coincidence vectors for a period of @xmath328 to obtain the total count @xmath329 .",
    "note that the optimal time allocation depends on the threshold of our hypothesis .",
    "finally , we apply the ump test of @xmath74 of the hypothesis : @xmath330 with the binomial distribution family @xmath331 to the data @xmath274 . in this case , the likelihood ratio test with the risk probability @xmath74 is almost equal to the test with the rejection region : @xmath332 concerning the null hypothesis @xmath272 . the p - value of this kind of tests is @xmath333 .",
    "we can apply a similar testing for @xmath334 .",
    "it is sufficient to replace the time allocation to @xmath335 @xmath336 , @xmath337 . in this case , the likelihood ratio test with the risk probability @xmath74 is almost equal to the test with the rejection region : @xmath338 concerning the null hypothesis @xmath272 .",
    "the p - value of this kind of tests is @xmath339 .",
    "next , we consider the case where the dark count parameter @xmath340 is known but is not negligible , the fisher information matrix is given by    @xmath341    hence , from ( [ 2 - 16 - 5 ] ) , the inverse of the minimum variance is equal to @xmath342 then , we apply lemmas [ 2 - 24 - 6 ] and [ 2 - 18 - 6 ] in appendix [ app1 ] to @xmath343 with @xmath344 , @xmath345 , @xmath346 , @xmath347 , and obtain the optimized value : @xmath348 and    @xmath349    the ratio of ( [ 2 - 24 - 14 ] ) to ( [ 2 - 24 - 16 ] ) is @xmath350    where the final inequality is derived in appendix [ 2 - 24 - 10 ] .",
    "therefore , the measurement using the coincidence and the anti - coincidence provides better test than that using the coincidence and the total flux , as in the case of @xmath351 .",
    "define @xmath352 and the critical point @xmath353 for the normalized dark count @xmath354 as @xmath355 the parameter @xmath352 is calculated to be @xmath356 .",
    "as shown in appendix [ 2 - 24 - 12 ] , the measurement using the coincidence and the anti - coincidence provides better test than that using the anti - coincidence and the total flux , if the fidelity is smaller than the critical point @xmath353 : @xmath357 the optimal time allocation is given by @xmath314 , @xmath358 , and @xmath359 for @xmath360 , and @xmath361 , @xmath362 , @xmath319 for @xmath363 .",
    "the critical point @xmath353 for optimal time allocation increases with the normalized dark count as illustrated in fig .",
    "[ thresh1 ] .     for optimal time allocation as a function of normalized dark counts @xmath364.,width=302 ]",
    "in this section , we consider the case where @xmath16 is known . then , the fisher information is @xmath365 the maximum value is calculated as @xmath366 the above optimization shows that when @xmath367 , the count on anti - coincidence @xmath368 is better than the count on coincidence @xmath369 .",
    "in fact , barbieri _",
    "et al._@xcite measured the sum of the counts on the anti - coincidence vectors @xmath370 to realize the entanglement witness in their experiment . in this case , the variance is @xmath371 .",
    "when we observe the sum of counts on anti - coincidence @xmath275 , the estimated value of @xmath14 is given by @xmath372 , which is the solution of @xmath373 .",
    "the likelihood ratio test with the risk probability @xmath74 can be approximated by the test with the rejection region : @xmath374 concerning the null hypothesis @xmath272 , which is also the ump test .",
    "the p - value of likelihood ratio tests is @xmath375 .    when @xmath376 , the optimal time allocation is @xmath377 , @xmath378 .",
    "the fidelity is estimated by @xmath379 .",
    "its variance is @xmath380 .",
    "the likelihood ratio test with the risk probability @xmath74 of the poisson distribution is almost equal to the test with the rejection region : @xmath381 concerning the null hypothesis @xmath272 , which is also the ump test .",
    "the p - value of likelihood ratio tests is @xmath382 .",
    "we compare the asymptotic variances of the following designs for time allocation , when the dark count @xmath340 parameter is zero .",
    "( i ) : :    modified visibility : the asymptotic variance is    @xmath383 .",
    "( iia ) : :    design i ( @xmath16 unknown )",
    ". optimal time allocation    between the counts on anti - coincidence and coincidence : the asymptotic    variance is @xmath384 .",
    "( iib ) : :    design i ( @xmath16 unknown ) , optimal time allocation    between the counts on anti - coincidence and the total flux : the    asymptotic variance is    @xmath385 .",
    "( iiia ) : :    design ii ( @xmath16 known ) , estimation from the count on    anti - coincidence : the asymptotic variance is    @xmath386 .",
    "( iiib ) : :    design ii ( @xmath16 known ) , estimation from the count on    coincidence : the asymptotic variance is    @xmath387 .",
    "[ fig : relent9 ] shows the comparison , where the asymptotic variances in ( iia)-(iiib ) are normalized by the one in ( i ) .",
    "the anti - coincidence measurement provides the best estimation for high ( @xmath388 ) fidelity .",
    "when @xmath16 is unknown , the measurement with the counts on anti - coincidence and the coincidence is better than that with the counts anti - coincidence and the total flux for @xmath389 . for higher fidelity ,",
    "the counts on anti - coincidence and total flux turns to be better , but the difference is small .",
    "the comparison in the previous section shows that the measurement on the anti - coincidence vectors yields a better variance than the measurement on the coincidence vectors , when the fidelity is greater than @xmath7 and the parameters @xmath16 and @xmath340 are known .",
    "we will explore further improvement in the measurement on the anti - coincidence vectors . in the previous sections ,",
    "we allocate an equal time to the measurement on each of the anti - coincidence vectors . here",
    "we minimize the variance by optimizing the time allocation @xmath390 , @xmath391 , @xmath392 , @xmath393 , @xmath394 , and @xmath395 between the anti - coincidence vectors @xmath396 , @xmath397 , @xmath398 , @xmath399 , @xmath400 , and @xmath401 , under the restriction of the total measurement time : @xmath402 . the number of the counts @xmath403 obeys poisson distribution poi(@xmath404 ) with unknown parameter @xmath405 .",
    "then , the fisher information matrix is the diagonal matrix with the diagonal elements @xmath406 since we are interested in the parameter @xmath407 , the variance is given by @xmath408 as mentioned in section [ 2 - 7 - 4 ] . under the restriction of the total measurement time ,",
    "the minimum value of ( [ 2 - 24 - 30 ] ) is @xmath409 which is attained by the optimal time allocation @xmath410 which is called neyman allocation and is used in sampling design@xcite .",
    "the variance with the equal allocation is @xmath411 the inequality ( [ 2 - 25 - 11 ] ) @xmath412 ( [ 2 - 25 - 10 ] ) can be derived from schwartz s inequality of the vectors @xmath413 and @xmath414 .",
    "the equality holds if and only if @xmath415 .",
    "therefore , the neyman allocation has an advantage over the equal allocation , when there is a bias in the parameters @xmath416 . in other words ,",
    "the neyman allocation is effective when the expectation values of the counts on some vectors are larger than those on other vectors .",
    "the optimal time allocation derived above is not applicable in the experiment , because it depends on the unknown parameters @xmath417 @xmath418 @xmath419 @xmath420 @xmath421 and @xmath422 .",
    "in order to resolve this problem , we introduce a two - stage method , where the total measurement time @xmath5 is divided into @xmath423 for the first stage and @xmath424 for the second stage under the condition of @xmath425 . in the first stage , we measure the counts on each vectors for @xmath426 and estimate the expectation value for neyman allocation on measurement time @xmath424 . in the second stage ,",
    "we measure the counts on a vector @xmath427 according to the estimated neyman allocation .",
    "the two - stage method is formulated as follows .",
    "+ ( i ) the measurement time for each vector in the first stage is given by @xmath426 + ( ii ) in the second stage , we measure the counts on a vector @xmath427 with the measurement time @xmath428 defined as @xmath429 where @xmath430 is the observed count in the first stage .",
    "+ ( iii ) define @xmath431 and @xmath432 as @xmath433 where @xmath434 is the number of the counts on @xmath427 for @xmath428 . then , we can estimate the fidelity by @xmath435 .",
    "+ ( iv ) finally , we apply the test @xmath436 given in section [ s4d ] to the two hypotheses given as @xmath437 where @xmath438 and @xmath439 .",
    "we have formulated the hypothesis testing scheme to test the entanglement in the poisson distribution framework .",
    "our statistical method can handle the fluctuation in the experimental data more properly in a realistic setting .",
    "it has been shown that the optimal time allocation improves the test : the measurement time should be allocated preferably to the anti - coincidence vectors .",
    "this test is valid even if the dark count exists .",
    "this design is particularly useful for the experimental test , because the optimal time allocation depends only on the threshold of the test .",
    "we do nt need any further information of the probability distribution and the tested state .",
    "the test can be further improved by optimizing time allocation between the anti - coincidence vectors , when the error from the maximally entangled state is anisotropic .",
    "however , this time allocation requires the expectation values on the counts on coincidence , so that we need to apply the two stage method .",
    "the authors would like to thank professor hiroshi imai of the erato - sorst , qci project for support .",
    "they are grateful to dr .",
    "tohya hiroshima , dr .",
    "yoshiyuki tsuda for useful discussions .",
    "in this section , we maximize the quantities appearing in fisher information .    [ 2 - 24 - 6 ] the equation @xmath440 holds and",
    "the maximum value is attained when @xmath441 , @xmath442 .",
    "letting @xmath443 , we have @xmath444 . then , @xmath445 hence , the maximum is attained at @xmath446 , _",
    "@xmath447 and @xmath448 .",
    "thus , @xmath449    [ 2 - 18 - 6 ] the equation @xmath450 holds , and this maximum value is attained when @xmath451 , @xmath452 .",
    "letting @xmath453 , we have @xmath454 and    @xmath455 . then , @xmath456 hence , the maximum is attained at @xmath457 , _",
    "@xmath451 and @xmath452 .",
    "thus , @xmath458    further , three - parameter case can be maximized as follows .    the maximum value @xmath459 is equal to the maximum among three values @xmath460 , @xmath461 , @xmath462 .",
    "define two parameters @xmath463 and @xmath464 .",
    "then , the range of @xmath68 and @xmath465 forms a convex set . since @xmath466 hence , @xmath467 where @xmath468 , @xmath469 . applying lemma [ 2 - 18 - 6-a ] , we obtain this lemma .",
    "[ 2 - 18 - 6-a ] define the function @xmath470 on a closed convex set @xmath471 .",
    "the maximum value is realized at the boundary @xmath472 .",
    "the condition can be classified to two cases : i ) @xmath473 , ii ) @xmath474 . in the case",
    "i ) , when fix @xmath68 is fixed , @xmath475 .",
    "then , we obtain @xmath476 . in the case",
    "ii ) , when @xmath477 , @xmath478 . hence ,",
    "@xmath479 this maximum is attained at @xmath480 or @xmath481 .",
    "these point belongs to the boundary @xmath472 .",
    "further , @xmath482 .",
    "thus , the proof is completed .",
    "it is sufficient to show @xmath483 by putting @xmath484 , the lhs is evaluated as @xmath485 since @xmath486 , we have @xmath487 further , the function @xmath488 @xmath489)$ ] has the minimum @xmath490 at @xmath491 .",
    "hence , @xmath492 .",
    "it is sufficient to show that @xmath493 if and only if @xmath494 and @xmath495 . by putting @xmath484 , the lhs of ( [ 2 - 24 - 4 ] )",
    "is evaluated as @xmath496 since @xmath486 and @xmath497 , @xmath498 if and only if @xmath499 and @xmath360 .",
    "define @xmath257 by @xmath500 in fact , when @xmath501 , @xmath502 this value is monotone decreasing concerning @xmath503 . when @xmath504 , this value is @xmath505 .",
    "hence , the value @xmath257 coincides with the the value @xmath257 defined by ( [ 2 - 6 - 12 ] ) and ( [ 2 - 6 - 11 ] ) .",
    "thus , the relation ( [ 5 - 2 - 1 ] ) follows from the relation @xmath506 we choose @xmath507 such that @xmath508 .",
    "then , the above inequality follows from lemma [ le-3 - 12 ] in the following way : @xmath509    [ le-3 - 12 ] any real number @xmath510 and any four sequence of positive numbers @xmath511 , @xmath512 , @xmath513 , and @xmath514 satisfy @xmath515    it is sufficient to show @xmath516 the convexity of @xmath517 implies that @xmath518 hence , @xmath519",
    "considering the shape of the graph @xmath520 , we can show that the minimum value @xmath521 can be attained by the boundary of @xmath471 .",
    "hence the boundary of the convex set @xmath262 is included by the union @xmath522 of the lines @xmath523 .",
    "taking the derivative of @xmath524 concerning @xmath5 , we obtain @xmath525 } \\frac{t x_i(r)+(1-t)x_j(r ) } { \\sqrt{t y_i(r)+(1-t)y_j(r ) } } = z_{i , j}(r).\\end{aligned}\\ ] ] hence , we obtain ( [ 5 - 5 - 1 ] )",
    ".    99 c.h .",
    "bennett , g. brassard , c. crpeau , r. jozsa , a. peres , and w. k. wootters , _ phys .",
    "lett . _ * 70 * , 1895 ( 1993 ) .",
    "briegel , w. dur , j.i .",
    "cirac , and p. zoller , _ phys .",
    "_ , * 81 * , 5932 ( 1998 ) . c. w. helstrom , _ quantum detection and estimation theory",
    ", academic press ( 1976 ) .",
    "m.  barbieri , f.  de  martini , g.  di  nepi , p.  mataloni , g.  m.  dariano , and c.  macchiavello , _ phys .",
    "_ , * 91 * , 227901 ( 2003 ) .",
    "y.  tsuda , k.  matsumoto , and m.  hayashi .",
    "`` hypothesis testing for a maximally entangled state , '' quant - ph/0504203 .",
    "p.  g.  kwiat , e.  waks , a.  g.  white , i.  appelbaum , and p.h .",
    "eberhard , _ phys .",
    "a _ , * 60 * , 773(r ) ( 1999 ) . k. usami , y. nambu , y. tsuda , k. matsumoto , and k. nakamura , `` accuracy of quantum - state estimation utilizing akaike s information criterion , '' _ phys .  rev .",
    "a _ , * 68 * , 022314 ( 2003 ) ."
  ],
  "abstract_text": [
    "<S> a hypothesis testing scheme for entanglement has been formulated based on the poisson distribution framework instead of the povm framework . </S>",
    "<S> three designs were proposed to test the entangled states in this framework . </S>",
    "<S> the designs were evaluated in terms of the asymptotic variance . </S>",
    "<S> it has been shown that the optimal time allocation between the coincidence and anti - coincidence measurement bases improves the conventional testing method . </S>",
    "<S> the test can be further improved by optimizing the time allocation between the anti - coincidence bases . </S>"
  ]
}