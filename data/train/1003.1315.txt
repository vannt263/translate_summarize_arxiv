{
  "article_text": [
    "computer simulators are often used to model complex physical and engineering processes that are either too expensive or time consuming to observe .",
    "a simulator is said to be deterministic if the replicate runs of the same inputs will yield identical responses .",
    "for the last few decades , the deterministic simulators have been widely used to model physical processes .",
    "for instance , kumar and davidson ( 1978 ) used deterministic simulation models for comparing the performance of highly concurrent computers ; su et al .",
    "( 1996 ) used generalized linear regression models to design a lamp filament via a deterministic finite - element computer code ; aslett et al .",
    "( 1998 ) discuss an optimization problem for a deterministic circuit simulator ; several deterministic simulators are being used for analyzing biochemical networks ( see bergmann and sauro 2008 for references ) . on the other hand , there are cases where stochastic ( non - deterministic ) simulators are preferred due to unavoidable biases ( e.g. , poole and raftery 2000 ) . in spite of the recent interest in stochastic simulators , deterministic simulators are still being actively used . for instance , medina , moreno and royo ( 2005 ) demonstrate the preference of deterministic traffic simulators over its stochastic counterpart . in this paper , we assume that the simulator under consideration is deterministic up to the working precision and the statistician is confident of the choice of the emulator .    sacks , welch , mitchell and wynn ( 1989 ) proposed modeling ( or emulating ) such an expensive deterministic simulator as a realization of a gaussian stochastic process ( gp ) .",
    "an emulator of a deterministic simulator is desired to be an interpolator of the observed data ( e.g. , sacks et al .",
    "1989 ; van beers and kleijnen 2004 ) . for the problem that motivated this work ,",
    "the objective is to emulate the average extractable tidal power as a function of the turbine locations in the bay of fundy , nova scotia , canada .",
    "the computer simulator for the tidal power model is a numerical solver of a complex system of partial differential equations and is deterministic ( i.e. , we are not allowed to question the accuracy of the simulator itself ) .    in this paper",
    ", we discuss a computational issue in building the gp based emulator for a deterministic simulator . fitting a gp model to @xmath0 data points using either a maximum likelihood technique or a bayesian approach",
    "requires the computation of the determinant and inverse of several @xmath1 correlation matrices , @xmath2 .",
    "although the correlation matrices are positive definite by definition , near - singularity ( also referred to as ill - conditioning ) of these matrices is a common problem in fitting gp models .",
    "ababou , bagtzoglou and wood ( 1994 ) study the relationship of a uniform grid to the ill - conditioning and quality of model fit for various covariance models .",
    "barton and salagame ( 1997 ) study the effect of experimental design to the ill - conditioning of kriging models .",
    "jones , schonlau and welch ( 1998 ) used the singular value decomposition method to overcome the near - singularity of @xmath2 . booker ( 2000 ) used the sum of independent gps to overcome near - singularity for multi - stage adaptive designs in kriging models . a more popular solution to overcome near - singularity",
    "is to introduce a _ nugget or jitter _",
    "parameter , @xmath4 , in the model ( e.g. , sacks et al . 1989 ; neal 1997 ; booker et al .",
    "1999 ; santner , williams and notz 2003 ; gramacy and lee 2008 ) that is estimated along with other model parameters .",
    "however , adding a nugget to the model introduces additional smoothing in the predictor and as a result the predictor is no longer an interpolator .    here",
    ", we first propose a lower bound on the nugget ( @xmath5 ) that minimizes the additional over - smoothing .",
    "second , an iterative approach is developed to enable the construction of a new predictor that further improves the prediction accuracy .",
    "we also show that the proposed predictor converges to an interpolator .",
    "although an arbitrary nugget @xmath6 can be used in the iterative approach , the rate of convergence ( i.e. , the number of iterations required to reach certain tolerance ) depends on the magnitude of the nugget . to this effect , the proposed lower bound",
    "@xmath5 significantly reduces the number of iterations required .",
    "this feature is particularly desirable for implementation .",
    "the paper is organized as follows .",
    "section  [ sec : motivating ] presents the tidal power modeling example . in section  [ sec : background ] , we review the gp model , a computational issue in fitting the model , and the popular approach to overcome near - singularity .",
    "section  [ sec : nugget ] presents the new lower bound for the nugget that is required to achieve well - conditioned correlation matrices and minimize unnecessary over - smoothing . in section  [ sec : iterative ] , we develop the iterative approach for constructing a more accurate predictor .",
    "several examples are presented in section  [ sec : examples ] to illustrate the performance of our proposed predictor over the one obtained using the popular approach .",
    "finally , we conclude the paper with some remarks on the numerical issues and recommendations for practitioners in section  [ sec : discussion ] .",
    "the bay of fundy , located between new brunswick and nova scotia , canada , with a small portion touching maine , usa , is world famous for its high tides . in the upper portion of the bay of fundy ( see figure  [ fig : bof1](a ) ) , the difference in water level between high tide and low tide can be as much as 17 meters .",
    "the high tides in this region are a result of a resonance , with the natural period of the bay of fundy very close to the period of the principal lunar tide .",
    "this results in very regular tides in the bay of fundy with a high tide every 12.42 hours .",
    "the incredible energy in these tides has meant that the region has significant potential for extracting tidal power ( greenberg 1979 ; karsten , mcmillan , lickley and haynes 2008 ( hereafter kmlh ) ) .    though the notion of harnessing tidal power from the bay of fundy is not new , earlier proposed methods of harvesting the much needed green electrical energy involved building a barrage or dam . but this method was considered infeasible for a variety of economic and environmental reasons .",
    "recently , there has been rapid technological development of in - steam tidal turbines .",
    "these devices act much like wind turbines , with individual turbines placed in regions of strong tidal currents .",
    "individual turbines can be up to 20 m in diameter and can produce over 1 mw of power .",
    "ideally , these turbines would produce a predictable and renewable source of power with less of an impact on the environment than a dam .",
    "kmlh examined the power potential of farms of such turbines across the minas passage ( figure  [ fig : bof1](b ) ) where the tidal currents are strongest .",
    "they found that the potential extractable power is much higher than previous estimates and that the environmental impacts of extracting power can be greatly reduced by extracting only a portion of the maximum power available .",
    "the simulations in kmlh did not represent individual turbines and left open the question of how to optimally place turbines . in this paper",
    ", we emulate the kmlh numerical model to examine the placement of turbines to maximize the power output .",
    "we numerically simulate the tides as in kmlh by essentially solving the 2d shallow water equations using the finite - volume coastal ocean model ( fvcom ) with a triangular grid on the upper bay of fundy ( see figure [ fig : bof1a ] ) .",
    "since the grid triangles differ in size and orientation , the @xmath7-th turbine was modeled on the set of all triangular elements whose center lie within 250 m of @xmath8 .",
    "a typical turbine is shown in ( see figure [ fig : bof1b ] ) .",
    "the triangular grid was developed by david greenberg and colleagues at the bedford institute of oceanography , ns , canada . the details of fvcom can be found in chen et al .",
    "( 2006 ) .    using this set up ,",
    "the estimate of the electric power that can be harnessed through a turbine at a particular grid location @xmath9 over a tidal cycle @xmath10 hours is obtained by the simulator in kmlh .",
    "the average tidal power at the grid location @xmath8 is given by @xmath11 where @xmath12 is the extractable power output at time @xmath13 and location @xmath8 .",
    "the process is deterministic up to the machine precision , and the main objective is to emulate @xmath14 .",
    "it turns out that the gp model fitted to the simulator output at @xmath15 points ( chosen using a space - filling design criterion ) with the popular approach is not an interpolator and results in over - smoothed emulator ( see example  4 for details ) .",
    "this is undesirable as the ocean modelers are interested in the emulator that interpolates their simulator .",
    "this emulator will be used to obtain estimates of both the maximizer of the power function ( i.e. , the location where to put the turbine ) and the extractable power at such location .",
    "since the manufacturing and installation cost of each turbine is roughly 20 million dollars , a good approximation of the attainable power function can save the cost of a few turbines when targeting for a fixed amount of power .",
    "example  4 shows that the proposed approach leads to more accurate estimate of the maximum extractable power .",
    "let the @xmath7-th input and output of the computer simulator be denoted by a @xmath16-dimensional vector , @xmath17 , and the univariate response , @xmath18 , respectively .",
    "the @xmath19 experiment design matrix , @xmath20 , is the matrix of the input trials .",
    "the outputs of the simulation trials are held in the @xmath0-dimensional vector @xmath21 .",
    "the simulator output , @xmath22 , is modeled as @xmath23 where @xmath24 is the overall mean , and @xmath25 is a gp with @xmath26 , @xmath27 , and cov@xmath28 . in general",
    ", @xmath29 has multivariate normal distribution , @xmath30 , where @xmath31 , and @xmath32 is a @xmath33 vector of all ones ( see sacks et al .",
    "1989 , and jones et al .",
    "1998 for details ) .",
    "although there are several choices for the correlation function , we focus on the gaussian correlation because of its properties like smoothness ( or differentiability in mean square sense ) and popularity in other areas like machine learning ( radial basis kernels ) and geostatistics ( kriging ) . for a detailed discussion on correlation functions",
    "see stein ( 1999 ) , santner , williams and notz ( 2003 ) , and rasmussen and williams ( 2006 ) .",
    "the gaussian correlation function is a special case ( @xmath34 for all @xmath35 ) of the power exponential correlation family @xmath36 where @xmath37 is the vector of hyper - parameters , and @xmath38 $ ] is the smoothness parameter . as discussed in section  7 , the results developed in this paper may slightly vary when other correlation structures are used instead of the gaussian correlation .",
    "we use the gp model with gaussian correlation function to predict responses at any non - sampled design point @xmath39 . following the maximum likelihood approach ,",
    "the best linear unbiased predictor ( blup ) at @xmath39 is @xmath40 r^{-1}y,\\end{aligned}\\ ] ] with mean squared error @xmath41 where @xmath42 , @xmath43 , and @xmath44 is such that @xmath45 . in practice",
    ", the parameters @xmath46 and @xmath47 are replaced with the estimates ( see sacks et al .",
    "1989 , santner , williams and notz 2003 , for details ) .",
    "fitting a gp model ( [ gasp ] ) - ( [ shat ] ) to a data set with @xmath0 observations in @xmath16-dimensional input space requires numerous evaluations of the log - likelihood function for several realizations of the parameter vector @xmath48 .",
    "the closed form estimators of @xmath24 and @xmath49 , given by @xmath50 are often used to obtain the profile log - likelihood @xmath51,\\ ] ] for estimating the hyper - parameters @xmath52 , where @xmath53 denotes the determinant of @xmath2 . recall from ( [ corr ] ) , that the correlation matrix @xmath2 depends on @xmath47 and the design points .",
    "an @xmath1 matrix @xmath2 is said to be near - singular ( or , ill - conditioned ) if its condition number @xmath54 is too large ( see section  4 for details on  how large is large ? \" ) , where @xmath55 denotes a matrix norm ( we will use the @xmath56norm ) .",
    "although these correlation matrices are positive definite by definition , computation of @xmath53 and @xmath57 can sometimes be unstable due to ill - conditioning .",
    "this prohibits precise computation of the likelihood and hence the parameter estimates .",
    "ill - conditioning of @xmath2 often occurs if any pair of design points are very close in the input space , or @xmath58 s are close to zero , i.e. , @xmath59 .",
    "the distances between neighboring points in space - filling designs with large @xmath0 ( sample size ) and small @xmath16 ( input dimension ) can be very small .",
    "near - singularity is more common in the sequential design setup ( e.g. , expected improvement based designs , see jones et al . 1998 ; schonlau et al .",
    "1998 ; oakley 2004 ; huang et al . 2006 ; ranjan et al . 2008 ; taddy et al .",
    "2009 ) , where the follow - up points tend to  pile up \" near the pre - specified features of interest like the global maximum , contours , quantiles , and so on .      a popular approach to overcome near - singularity of @xmath2 is to introduce a nugget , @xmath60 , in the gp model by replacing @xmath2 with a non - singular ( well - behaved ) @xmath61 . or equivalently ,",
    "introduce an independent white noise process in the model @xmath62 where @xmath63 are i.i.d .",
    "@xmath64 . that is ,",
    "@xmath65 for @xmath66 .",
    "note that @xmath67 represents more numerical uncertainty than the process uncertainty , which is certainly undesirable from a statistical perspective .",
    "the resulting predictor ( also the blup ) is given by @xmath68 ( r+ \\delta i)^{-1}y,\\ ] ] and the associated mean squared error @xmath69 is @xmath70 where @xmath71 is such that @xmath72 .    theoretically , it is straightforward to see that the use of a positive nugget in the gp model produces a non - interpolator .",
    "jones et al . ( 1998 ) show that the gp fit given by ( [ yhat ] ) and ( [ shat ] ) is an interpolator because for @xmath73 , @xmath74 , where @xmath75 is the @xmath76-th unit vector , @xmath77 and @xmath78 .",
    "if we use a @xmath79 in the model ( i.e. , replace @xmath2 with @xmath80 ) , then @xmath81 and thus @xmath82 and @xmath83 . from a practitioner s viewpoint , one could sacrifice the exact interpolation if the prediction accuracy of the fit is within the desired tolerance , but it is not always achievable ( see section  [ sec : examples ] for illustrations ) .    the nugget parameter @xmath4 is often estimated along with the other model parameters . however , one of the major concerns in the optimization is that the likelihood ( modified by replacing @xmath2 with @xmath80 ) computation fails if the candidate nugget @xmath84 is not large enough to overcome ill - conditioning of @xmath80 . to avoid this problem in the optimization , it is common to fix an _",
    "ad - hoc _ boundary value on the nugget parameter .",
    "the resulting maximum likelihood estimate is often close to this boundary value and the fit is not an interpolator of the observed data ( i.e. , the prediction error is more than the desired tolerance ) .",
    "even if the estimated nugget is not near the boundary , the use of a nugget in the model in this manner may introduce unnecessary over - smoothing from a practical standpoint ( section  [ sec : examples ] presents several illustrations ) . in the next section ,",
    "we propose a lower bound on the nugget that minimizes the unnecessary over - smoothing .",
    "recall from section  3.2 that an @xmath1 matrix @xmath2 is said to be ill - conditioned or near - singular if its condition number @xmath85 is too large .",
    "thus , we intend to find @xmath4 such that @xmath86 is smaller than a certain threshold .",
    "our main objective here is to compute the condition number of @xmath80 and the threshold that classifies @xmath80 as well - behaved .",
    "let @xmath87 be the eigenvalues of @xmath2 then , in the @xmath56norm , @xmath88 ( golub and van loan 1996 ) .",
    "the addition of @xmath4 along the main diagonal of @xmath2 shifts all of the eigenvalues of @xmath2 by @xmath4 .",
    "that is , the eigenvalues of @xmath61 are @xmath89 , @xmath90 , where @xmath91 is the @xmath7-th smallest eigenvalue of @xmath2 .",
    "thus , @xmath80 is well - conditioned if @xmath92 where @xmath93 and @xmath94 is the desired threshold for @xmath86 .",
    "note that @xmath5 is a function of the design points and the hyper - parameter @xmath47 .",
    "the closed form expressions for the eigenvalues and hence the condition number of a gaussian correlation matrix @xmath2 , in ( [ corr ] ) , for arbitrary @xmath47 and design @xmath95 is yet unknown as of our knowledge .",
    "if @xmath96 and @xmath97 , closed form expressions of the expected eigenvalues of @xmath2 are known ( see section 4.3 in rasmussen and williams 2006 ) . in our case , @xmath98^d$ ] , and the design points are often chosen using a space - filling criterion ( e.g. , latin hypercube with properties like maximin distance , minimum correlation , oa ; uniform designs , and so on ) . in such cases , at the most , one may assume @xmath99 for @xmath100 .",
    "in fact , the objectives of building efficient emulators for computer simulators often include estimating pre - specified process features of interest , and sequential designs ( e.g. , expected improvement based designs ) are preferred to achieve such goals . in such designs , the follow - up points tend to  pile up \" near the feature of interest .",
    "the distributions of such design points is not uniform and can be non - trivial to represent in analytical expressions . in conclusion , it is almost infeasible to obtain the closed form expressions for the eigenvalues of such @xmath2 .",
    "nonetheless , one can compute these quantities numerically .",
    "we use matlab s built - in function _",
    "eig.m _ to compute the maximum eigenvalue of @xmath2 and _ cond.m _ to approximate the condition number @xmath101 in the expression of @xmath5 .    another important component of the proposed lower bound is the threshold for getting well - behaved non - singular correlation matrices .",
    "as one would suspect , the near - singularity of such a correlation matrix depends on @xmath0 , @xmath16 , the distribution of @xmath102^d$ ] and @xmath103 .",
    "we now present the key steps of the simulation algorithm used for estimating the threshold under a specific design framework .",
    "the results are averaged over the distribution of @xmath95 and @xmath47 , and thus it is sufficient to find the threshold of @xmath85 .    for several combinations of @xmath0 and @xmath16 we generate @xmath104 correlation matrices with randomly chosen @xmath47 and @xmath95 under the maximin latin hypercube design scheme ( stein 1987 ) , and then compute the proportion of matrices that are near - singular ( see the contours in the left panel of figure  [ fig : nearsingular_lhs ] ) .",
    "we used matlab s built - in function _",
    "lhsdesign.m _ to generate the design points and _ chol.m _ to check whether or not a matrix @xmath2 was near - singular under the working precision .",
    "+    we also computed the condition numbers of these @xmath104 correlation matrices ( using matlab s built - in function _ cond.m _ ) .",
    "the right panel of figure  [ fig : nearsingular_lhs ] presents the contours of the average of @xmath105 for different combinations of @xmath0 and @xmath16 .",
    "the shaded region in the left panel corresponds to @xmath106 .",
    ", title=\"fig:\",width=307,height=312 ]   values .",
    "the shaded region in the left panel corresponds to @xmath106 .",
    ", title=\"fig:\",width=307,height=312 ]    from figure  [ fig : nearsingular_lhs ] , it is clear that @xmath107 can be used as the threshold for @xmath108 of a well - behaved correlation matrix @xmath80 . also note that the proportion of near - singular cases , denoted by the contours in the left panel of figure  [ fig : nearsingular_lhs ] , decreases rapidly with the increment in the input dimension .",
    "this is somewhat intuitive because the volume of the void ( or unexplored region ) increases exponentially with the dimension , and a really large space - filling design is needed to jeopardize the conditioning of the correlation matrices in high dimensional input space . for other design schemes , one can follow these steps to estimate the threshold for the condition number of well - behaved correlation matrices .",
    "the lower bound on the nugget is only a sufficient condition and not a necessary one for @xmath80 to be well - conditioned .",
    "for instance , a correlation matrix with 100 designs points in @xmath109 chosen using a space - filling criterion may lead to a well - behaved @xmath2 if @xmath47 is very large .",
    "if the correlation matrix is well - conditioned , @xmath2 should be used instead of @xmath80 , i.e. , @xmath110[delta_lb ] that is , when @xmath2 is well - behaved our approach allows @xmath5 to be zero and hence a more accurate surrogate can be obtained as compared to the popular approach ( section  3.3 ) where a non - zero nugget is forced in the model which may lead to undesirable over - smoothing .",
    "this could be of concern in high dimensional input space , because the proportion of near - singular cases decreases with the increment in the input dimension .",
    "example  3 demonstrates the performance of the proposed methodology over the popular approach for an eight - dimensional simulator .",
    "although the use of @xmath5 in the gp model minimizes the over - smoothing , @xmath5 may not be small enough to achieve the desired prediction accuracy ( see examples  1 and 2 for illustrations ) , and choosing @xmath111 may lead to ill - conditioned @xmath2 .",
    "this may not be a big issue if one believes that the simulator is somewhat noisy and/or the statistical emulator is biased due to miss - specification in the correlation structure or model assumptions . in such cases , a little smoothing might be a good idea .",
    "however , controlling the amount of smoothing is a non - trivial task and requires more attention . on the other hand , over - smoothing is undesirable if the experimenter believes that the computer simulator is deterministic and the statistician is confident about the choice of the emulator ( we consider the gp model with gaussian correlation structure ) . under these assumptions ,",
    "we now propose a new predictor that can achieve the desired level of prediction accuracy .",
    "in this section , we propose a predictor that is based on the iterative use of a nugget @xmath84 .",
    "this approach does not depend severely on the magnitude of the nugget , and the results developed here are based on an arbitrary @xmath112 large enough to ensure @xmath80 well - behaved .",
    "however , choosing @xmath113 may require more iterations to attain the desired prediction accuracy , and we recommend using @xmath5 .",
    "we also show that the proposed predictor converges to an interpolator ( [ yhat ] ) and ( [ shat ] ) .",
    "recall that the key problem here is the inaccurate computation of @xmath53 and @xmath57 due to ill - conditioning of @xmath2 .",
    "the main idea of the new approach is to rewrite the profile log - likelihood as @xmath114,\\ ] ] and replace the ill - conditioned @xmath57 with a well - behaved quantity .",
    "this modified profile log - likelihood can then be optimized to get the parameter estimates .",
    "next , we describe how to find the appropriate well - behaved substitute for @xmath57 .    in the same spirit as the popular approach",
    ", we attempt to evaluate @xmath115 by solving @xmath116 , under the assumption that @xmath2 can not be inverted accurately ( i.e. , @xmath2 is near - singular ) while there exists a @xmath117 such that @xmath118 is well - conditioned . in an attempt to find an interpolator of the simulator ( up to certain accuracy ) ,",
    "our objective is to find @xmath119 that is a better approximation of @xmath120 as compared to @xmath121 , suggested by the popular approach . to achieve this goal",
    ", we propose to use _ iterative regularization _",
    "( e.g. , tikhonov 1963 , neumaier 1998 ) , a technique for solving ill - conditioned systems of equations .",
    "let @xmath122 and @xmath123 , be a sequence of vectors obtained by recursively solving the system of equations given by @xmath124 then , the estimate of @xmath125 after the @xmath7-th iteration ( @xmath126 ) of regularization is given by    @xmath127    where @xmath128 is a vector of zeros .",
    "the final solution with @xmath129 iterations of regularization , @xmath130 requires only one direct inversion ( or one cholesky decomposition ) of @xmath61 , followed by @xmath129 forward and backward substitutions .",
    "the proposed approximation of @xmath125 is @xmath131 for @xmath132 chosen to satisfy the prediction accuracy requirement .",
    "lemma  [ lemma : taylor ] shows that the iterative regularization approach in ( [ eq : iter_s ] ) and ( [ eq : iter_t ] ) leads to a solution that is a generalization of the popular approach outlined in section  3.3 .",
    "[ lemma : taylor ] let @xmath2 be a @xmath1 positive definite correlation matrix , @xmath133 be the @xmath1 identity matrix , and @xmath134 be a constant , then @xmath135    the convergence of this infinite series follows from the von - neumann series ( the matrix version of the taylor series , lebedev 1997 ) expansion of @xmath136 around @xmath137 : @xmath138 setting @xmath139 , we get @xmath140 and thus the proposed solution obtained using the iterative regularization is the @xmath129-th order von - neumann approximation of @xmath57 .",
    "the predictor @xmath141 in the popular approach ( [ eq : yhat_delta ] ) uses @xmath142 , the first order von - neumann approximation , and hence our proposed approach is a generalization of the popular approach .    to implement the proposed regularization in model fitting , the modified profile log - likelihood to be optimized is @xmath143,\\ ] ] where @xmath144 .",
    "closed form expressions for @xmath145 and @xmath146 are the same as in ( [ muhat ] ) subject to @xmath57 replaced by @xmath147 .",
    "the new regularized predictor @xmath148 at @xmath149 is    @xmath150 r^{-1}_{\\delta , m}y,\\ ] ]    and the corresponding mse @xmath151 is given by @xmath152 where @xmath153 is such that @xmath154 .",
    "lemmas  [ lemma:1 ] and [ lemma:2 ] establish the convergence results for an arbitrary @xmath155 .",
    "[ lemma:1 ] let @xmath2 be a near - singular correlation matrix as defined in ( [ corr ] ) , and @xmath134 be a nugget such that @xmath156 is well - behaved .",
    "then , for every @xmath157^d$ ] , @xmath158 where @xmath159 and @xmath160 are defined in ( [ yhat ] ) and ( [ eq : yhat_new ] ) respectively .",
    "the proof follows from lemma  [ lemma : taylor ] and using @xmath161 in ( [ eq : yhat_new ] ) .",
    "it is straightforward to show that @xmath162 in ( [ eq : shat_new ] ) converges to @xmath44 in ( [ shat ] ) as @xmath163 .",
    "this also proves the next result on the convergence of the mean squared error for the proposed predictor .",
    "[ lemma:2 ] let @xmath2 be a near - singular correlation matrix as defined in ( [ corr ] ) , and @xmath134 be a nugget such that @xmath156 is well - behaved .",
    "then , for every @xmath164^d$ ] , @xmath165 where @xmath166 and @xmath167 are defined in ( [ shat ] ) and ( [ eq : shat_new ] ) respectively .",
    "lemmas  [ lemma:1 ] and [ lemma:2 ] prove that even if a few pairs of points are too close together in the input space , or @xmath58 s are close to zero to cause near - singularity of @xmath2 , the proposed iterative predictor converges to an interpolator as @xmath129 increases ( i.e. , for @xmath168 , @xmath169 and @xmath170 as @xmath163 ) . + * remark : * in practice , when a pre - specified prediction accuracy is desired , the proposed iterative approach suggests refitting the gp model ( i.e. , optimization of ( [ final - profile - likelihood ] ) ) for different choices of @xmath171 .",
    "note that the parameter estimates change with @xmath129 which allows for the extra flexibility in the model that adjusts the over - smoothed portion of the surrogate .",
    "first of all , the computational cost of fitting this model increases with @xmath129 .",
    "secondly , the combined cost of refitting the model for different values of @xmath129 can be quite large .",
    "although the numerical stability in computing @xmath147 does not change with @xmath129 , computation of @xmath172 can become less numerically stable with increasing @xmath129 .",
    "this is because @xmath173 as @xmath163 and the computation of @xmath174 is assumed to unstable .",
    "considering these issues , we recommend optimizing the profile log - likelihood ( [ final - profile - likelihood ] ) with @xmath175 to obtain @xmath176 and then use it to compute @xmath148 and @xmath177 for any @xmath132 by following the iterative regularization steps outlined above .",
    "+ the convergence results in lemmas  [ lemma : taylor ] , [ lemma:1 ] and [ lemma:2 ] do not depend on the choice of @xmath47 and @xmath4 in @xmath61 , and so the predictor obtained is still an interpolator .",
    "the key steps required for the implementation of the proposed approach are as follows :    1 .",
    "computation of the profile log - likelihood ( [ new - profile - likelihood ] ) for the estimation of @xmath47 . 1 .",
    "choose a candidate @xmath47 in @xmath178 and compute @xmath2 .",
    "2 .   compute the lower bound of nugget @xmath5 in ( 9 ) . note that @xmath5 is a function of the hyper - parameters @xmath47 , the design matrix and the threshold .",
    "3 .   replace @xmath57 with @xmath179 in the likelihood ( [ new - profile - likelihood ] ) .",
    "2 .   obtain the parameter estimates @xmath180 and @xmath181 by optimizing the profile log - likelihood .",
    "then compute @xmath182 and @xmath183 .",
    "3 .   use the parameter estimates @xmath180 , @xmath181 , @xmath182 and @xmath183 to compute the regularized emulator given by @xmath184 and @xmath185 in ( [ eq : yhat_new ] ) and ( [ eq : shat_new ] ) respectively .    the number of iterations @xmath186 depends on the desired prediction accuracy , and one can build stopping rules for attaining the pre - specified accuracy in ( [ eq : yhat_new ] ) .",
    "the first quantity @xmath187 measures how close the approximation is to an exact interpolator .",
    "we define another quantity @xmath188 that measures the relative improvement in the prediction by increasing the number of terms in the von - neumann approximation .",
    "lemmas  [ lemma:1 ] and [ lemma:2 ] show that both @xmath189 and @xmath190 goes to @xmath191 as @xmath35 increases , however , as we will see in example  1 , the rates of convergence of @xmath189 and @xmath190 may differ .",
    "the convergence of @xmath190 means that the predictor is converging to the blup , but the convergence of @xmath189 implies that the predictor @xmath192 has stabilized .",
    "that is , both of these measures ( @xmath190 and @xmath189 ) can be used in practice to choose appropriate @xmath129 for achieving the desired prediction accuracy .",
    "the next section illustrates that even the best choice of @xmath4 can lead to over - smooth emulators , and the iterative approach is advantageous .",
    "to illustrate the proposed approach we first present a few simulated examples .",
    "the performance of the new iterative predictor is also compared with the popular approach .",
    "then , we revisit the tidal power modeling example .",
    "let @xmath193 $ ] , and the underlying deterministic simulator output be generated using the goldprice function ( andre , siarry and dognon 2000 ) ,    @xmath194*\\ ] ] @xmath195.\\ ] ]    for illustration purpose , we intentionally select a maximin latin hypercube design ( stein 1987 ) with @xmath196 points that leads to an ill - conditioned correlation matrix for small @xmath197 .",
    "it turns out that for this particular design ( see figure  3 ) , the correlation matrix @xmath2 is ill - conditioned if @xmath198 .",
    "figure  [ fig : eg2_iter](a ) presents the contours ( at heights @xmath199 and @xmath200 ) of the true simulator ( solid curve ) and the gp surrogate fit ( obtained using the methodology outlined in sections  3.1 and 3.3 ) . for successful implementation of the popular approach , we optimized the likelihood in the parameter space @xmath201 and @xmath202 .",
    "the parameter estimates for the gp fit are @xmath203 and @xmath204 .",
    "note that @xmath205 is close to the boundary and the fitted surrogate is significantly different than the reality in the central part of the input space .    when the proposed method ( as outlined in sections  4 and 5 ) was used to fit the gp model , the parameter estimates were @xmath206 and @xmath207 .",
    "the fitted surrogate for @xmath175 , in figure  [ fig : eg2_iter](b ) , shows a much better fit .",
    "moreover , the iterative approach leads to further improvement on the fitted gp surrogate ( see figure  [ fig : eg2_iter](c ) and [ fig : eg2_iter](d ) ) .",
    "the overall convergence of @xmath189 and @xmath190 is shown in figure  [ fig : eg2_conv ] .",
    "note that @xmath189 converges to @xmath191 at a faster rate as compared to @xmath190 .",
    "[ exam : exam2 ]     ( dashed curve - right axis ) and @xmath208 ( solid curve - left axis).,title=\"fig:\",width=432,height=216 ] +    table  [ tab : goldprice ] summarizes the comparison results from a more detailed simulation study based on several combinations of run - sizes of the space - filling design and the boundary values of @xmath4 in the likelihood optimization . for fair comparison between the two methodologies ,",
    "first we use the proposed model with only one term in von - neumann approximation ( i.e. , @xmath175 ) and the popular method with @xmath205 .",
    "then we increase the number of iterations to measure the performance of the iterative approach in improving the prediction accuracy .",
    "the results in table  [ tab : goldprice ] are summarized over model fits with @xmath209 random maximin latin hypercube designs .",
    "the table entries are @xmath210 , where @xmath211 denotes the @xmath212-th percentile of @xmath213 values obtained from the model fits .",
    ".median and @xmath214 of @xmath213 values for the proposed approach ( denoted by `` @xmath215 '' ) and the popular approach ( denoted by `` @xmath216 '' ) applied to the goldprice function . [ cols=\"^,^,^,^,^\",options=\"header \" , ]     [ tab : borehole ]    as expected , the relative prediction error of the gp fits obtained using the popular approach slightly decreases by lowering the boundary value of the nugget parameter ( from @xmath217 to @xmath218 ) in the optimization problem .",
    "the proposed method leads to predictors with significantly higher prediction accuracy .",
    "the percentiles of @xmath213 in the last row of table  [ tab : borehole ] also suggest that most of the correlation matrices are well - conditioned for the @xmath47 values near @xmath176 , and @xmath219 .",
    "that is , the iterative approch is not needed to further improve the prediction accuracy .",
    "we now revisit the tidal power example in section  2 . the computer simulator ( a version of fvcom )",
    "is expensive and can not be evaluated at numerous coordinates .",
    "each of the runs presented here required approximately one hour to run on @xmath220 processors in parallel on the atlantic computational excellence network ( acenet ) mahone cluster . while this is not particularly onerous on a large cluster , the grid resolution used in kmlh is about 200 m ( length of a side in a triangle ) .",
    "a realistic model of 20 m sided triangular grid and with 10 vertical layers to model 3d flow would increase the computational expense by a factor of @xmath221 , making each individual simulator run roughly @xmath222 times more costly than the generation of the entire data set examined here .",
    "the ocean modelers believe that the simulator is deterministic up to the machine precision and they are interested in the emulator that interpolates the simulator .    a total of @xmath223 runs ( on a @xmath224 grid )",
    "were used to obtain the data displayed in figure  [ fig : mp_coarse_grid ] .",
    "we use this data to compare our results .",
    "the goal is to build an emulator of the computer model using a fraction of the budget ( @xmath223 runs ) that provides the best approximation of the simulator .",
    "+    we used a maximin based coverage design ( johnson , moore and ylvisaker 1990 ) to choose a subset of @xmath15 points from these @xmath223 points to constitute a space - filling design .",
    "the contours from both the predicted surface and the true simulator ( based on the @xmath224 grid ) are shown in figure  [ fig : motivating_eg_iter ] .",
    "for successful implementation of the popular approach outlined in sections  3.1 and 3.3 , the likelihood optimization took place in the parameter space @xmath201 and @xmath202 , and the parameter estimates for the gp fit are @xmath225 and @xmath226 ( see figure  6(a ) ) .",
    "the parameter estimates for the gp model fitted using the proposed approach with @xmath175 are @xmath227 and @xmath228 ( see figure  6(b ) ) .",
    "[ exam : exam3 ]    figure  [ fig : motivating_eg_iter ] shows that the gp based emulator obtained using the proposed approach ( figure  [ fig : motivating_eg_iter](b ) ) is less smooth as compared to that obtained via the popular approach ( figure  [ fig : motivating_eg_iter](a ) ) .",
    "the relative prediction errors for the gp fits with the popular method and the proposed approach are @xmath229 and @xmath230 respectively .",
    "that is , the proposed approach leads to significantly better approximation of the iterpolator of the simulator .",
    "moreover , when using the popular approach , the maximum predicted power obtained by evaluating @xmath231 is approximately @xmath232 w with the maximizer being ( 0.7850 , 0.4500 ) , whereas if we use the proposed approach the maximum predicted power is approximately @xmath233 w observed at ( 0.7900 , 0.4500 ) .",
    "assuming that the underlying computer simulator is deterministic up to the machine precision and the statistician is confident about the choice of the simulator ( i.e. , gp model with gaussian correlation ) , fitting the model to a data set with @xmath0 points in @xmath16-dimensional input space requires computation of the determinant and inverse of @xmath1 correlation matrices for several @xmath47 values . in section  [ sec : nugget ] , we conducted a simulation study to explore space - filling designs ( specifically maximin latin hypercube designs ) for different combinations of @xmath234 that can lead to near - singular correlation matrices . in section",
    "[ sec : iterative ] , we proposed an iterative approach , that is also a generalization of the popular approach , to construct a new predictor @xmath235 that has higher prediction accuracy compared to @xmath141 - the one with the popular approach .",
    "lemmas  1 , 2 and 3 show that @xmath235 converges to the blup as the number of iterations ( @xmath129 ) increases .",
    "the lower bound @xmath5 , proposed in section  [ sec : nugget ] , also allows us to use a non - zero nugget only when required , and minimizes the number of iterations when required ( i.e. , @xmath236 ) to reach the desired tolerance of prediction accuracy .",
    "there are a few important remarks worth noting .",
    "first , the methodology developed here can also be adapted in the bayesian framework . for computing the posterior distribution of the parameters and the predictor",
    ", @xmath57 needs to be computed for several realizations of @xmath47 , and a nugget is often used to overcome the near - singularity problem ( e.g. , taddy et al .",
    "the proposed lower bound @xmath5 can be used for defining a prior for @xmath4 , i.e. , the search should be limited to @xmath237 , because @xmath238 may lead to near - singular cases .",
    "one can also use the iterative approach to further improve the prediction accuracy .",
    "second , we used the squared exponential correlation ( @xmath34 for all @xmath35 ) in the gp model because of its popularity and good theoretical properties .",
    "it turns out the gp model with other power exponential correlation function ( i.e. , @xmath239 ) may lead to predictors with larger mse and sometimes worse fits as compared to that of the gp models with the gaussian correlation function .",
    "the ill - conditioning problem may also occur when other power exponential correlation functions ( i.e. , @xmath239 ) are used .",
    "recall that the near - singularity of @xmath2 occurs because ( a ) at least two of the design points ( say @xmath240 and @xmath241 ) are close together in the input space , and/or ( b ) the hyper - parameters @xmath242 are very close to zero , i.e. , @xmath243 .",
    "this makes a few of the rows of @xmath2 very similar , and will happen even if the power @xmath244 is less than two .",
    "a closer investigation reveals that even with @xmath245 , near - singular cases occur very frequently in the sequential design setup .",
    "however , for the space - filling designs , it is rather fascinating that the occurrence of near - singular cases is substantially reduced by even a small reduction in the power from @xmath246 to @xmath247 .",
    "we suspect this is due to the limiting behaviour of the gaussian correlation in the family of power exponential correlation functions @xmath248 $ ] .    in conclusion , when fitting a gp model to a data set obtained from a deterministic computer model",
    "if the correlation matrices are near - singular , we recommend using @xmath5 - the lower bound on the nugget , along with the iterative approach with the number of iterations , @xmath129 , chosen according to the desired prediction accuracy .",
    "we would like to thank the ae and two anonymous referees for many useful comments and suggestions that lead to significant improvement of the paper .",
    "this work was partially supported by discovery grants from the natural sciences and engineering research council of canada .",
    "booker , a. j. , dennis jr .",
    ", j. e. , frank , p. d. , serafini , d. b. , torczon , v. trosset , m. w. ( 1999 ) . a rigorous framework for optimization of expensive functions by surrogates .",
    "_ structural and multidisciplinary optimization _ , 17 , 1 - 13 .",
    "karsten , r. , mcmillan , j. , lickley , m. haynes , r. ( 2008 ) .",
    "assessment of tidal current energy for the minas passage , bay of fundy .",
    "_ proceedings of the institution of mechanical engineers , part a : journal of power and energy _ , 222 , 493 - 507 .",
    "medina , j.s . ,",
    "moreno , m.g .",
    "royo , e.r .",
    "stochastic vs deterministic traffic simulator .",
    "comparative study for its use within a traffic light cycles optimization architecture , _ in proc . iwinac _",
    "( 2 ) , 622  631 .",
    "neal , r. m. ( 1997 ) .",
    "monte carlo implementation of gaussian process models for bayesian regression and classification .",
    "technical report vol .",
    "9702 , _ department of statistics , university of toronto , canada_.                  schonlau , m. , welch , w. jones , d. ( 1998 ) .",
    "global versus local search in constrained optimization of computer models .",
    "_ new developments and applications in experimental design , institute of mathematical statistics lecture notes , hayward , california _ , 34 , 11 - 25              van beers , w. c. m. , kleijnen , j. p.c .",
    "kriging interpolation in simulation : a survey . _ in proceedings of the 2004 winter simulation conference _ , ed .",
    "ingalls , m.d .",
    "rossetti , j.s .",
    "smith , and b.a .",
    "peter , 113 - 121 .",
    "piscataway , new jersey : institute of electrical and electronics engineers ."
  ],
  "abstract_text": [
    "<S> for many expensive deterministic computer simulators , the outputs do not have replication error and the desired metamodel ( or statistical emulator ) is an interpolator of the observed data . </S>",
    "<S> realizations of gaussian spatial processes ( gp ) are commonly used to model such simulator outputs . fitting a gp model to @xmath0 data points </S>",
    "<S> requires the computation of the inverse and determinant of @xmath1 correlation matrices , @xmath2 , that are sometimes computationally unstable due to near - singularity of @xmath2 . </S>",
    "<S> this happens if any pair of design points are very close together in the input space . </S>",
    "<S> the popular approach to overcome near - singularity is to introduce a small nugget ( or jitter ) parameter in the model that is estimated along with other model parameters . </S>",
    "<S> the inclusion of a nugget in the model often causes unnecessary over - smoothing of the data . in this paper </S>",
    "<S> , we propose a lower bound on the nugget that minimizes the over - smoothing and an iterative regularization approach to construct a predictor that further improves the prediction accuracy . </S>",
    "<S> we also show that the proposed predictor converges to the gp interpolator . </S>",
    "<S> + key words : @xmath3 computer experiment ; matrix inverse approximation ; regularization . </S>"
  ]
}