{
  "article_text": [
    "the analysis of the geographical variations of a disease and their representation on a map is an important step in epidemiology .",
    "the goal is to identify homogeneous regions in terms of disease risk and to gain better insights into the mechanisms underlying the spread of the disease .",
    "it has long ago become clear that spatial dependencies had to be taken into account when analyzing such location dependent data .",
    "most statistical methods for risk mapping of aggregated data [ e.g. , @xcite ] are based on a poisson log - linear mixed model and follow the one proposed by @xcite .",
    "the so - called bym model introduced by @xcite , extended by @xcite and called the convolution model by @xcite , is one of the most popular approaches and is used extensively in this context .",
    "this model is based on a hidden markov random field ( hmrf ) model where the latent intrinsic risk field is modeled by a markov field with continuous state space , namely , a gaussian conditionally auto - regressive ( car ) model . in particular ,",
    "recent developments in this context concern spatio - temporal mapping [ @xcite ] and multivariate disease mapping [ @xcite ] . for all these procedures ,",
    "the model inference therefore results in a real - valued estimation of the risk at each location and one of the main reported limitations [ e.g. , by @xcite ] is that local discontinuities in the risk field are not modeled , leading to potentially oversmoothed risk maps .",
    "also , in some cases , coarser representations where areas with similar risk values are grouped are desirable [ e.g. , @xcite ] .",
    "grouped representations have the advantage of providing clearly delimited areas for different risk levels .",
    "this can be helpful for decision - makers to interpret the risk structure and determine protection measures such as reinforced surveillance , movement restriction , mass vaccination or culling ( applied in the bovine spongiform encephalopathy ( bse ) example we present ) . from an exploratory point of view",
    ", more focused studies could also be conducted in specific risk regions , in particular , high risk regions , to better understand the disease determinants .",
    "these areas at risk can be viewed as clusters as in @xcite , but we prefer to interpret them as risk classes , as in the seminal work of @xcite and @xcite , and with additional spatial constraints by @xcite and @xcite , since geographically separated areas can have similar risks and be grouped in the same class . consequently , the classes can be less numerous than the clusters and their interpretation by decision - makers easier in terms of risk value . using the bym model ,",
    "it is possible to derive such a grouping from the output , using either fixed risk ranges ( usually difficult to choose in practice ) or more automated clustering techniques [ e.g. , @xcite ] . in any case , this post - processing step is likely to be suboptimal . in contrast , in this work we investigate procedures that include such a risk classification .",
    "there have been several attempts to take into account the presence of discontinuities in the spatial structure of the risk . within hierarchical approaches ,",
    "one possibility is to move the spatial dependence one level higher in the hierarchy .",
    "@xcite proposed replacing the continuous risk field by a partition model , involving the introduction of a finite number of risk levels and allocation variables to assign each area under study to one of these levels .",
    "spatial dependencies are then taken into account by modeling the allocation variables as a discrete state - space markov field , namely , a spatial potts model .",
    "this results in a discrete hmrf modeling . in the same spirit , in @xcite ,",
    "the spatial dependence is pushed yet one level higher . of course , the higher the spatial dependencies in the hierarchy , the more flexible the model , but also the more difficult the parameter estimation .",
    "as regards inference , these various attempts all use mcmc techniques which can seriously limit , and even prevent , their application to large data sets in a reasonable time .",
    "following the idea of using a discrete hmrf model for disease mapping , we build on the standard hidden markov field model used in @xcite and @xcite by considering a more general formulation that is able to encode more complex interactions than the standard potts model ( section [ hmrf ] ) . in particular , we are able to encode the fact that risk levels in neighboring regions can not be too different , whereas the standard potts model penalizes neighboring risks equally , whatever the amplitude of their difference .",
    "we then ( section [ emalgo ] ) propose to use for inference , as an alternative to simulation based techniques , an expectation maximization ( em ) framework [ @xcite ] combined with some variational approximation for tractability in the case of markov dependencies .",
    "an attempt in this direction has been recently made by @xcite but with a rather limited consideration for experimental validation and robustness of their setting .",
    "the approach in @xcite has been tested on a single data set regarding human heart disease and no difficulties regarding initialization and model selection have been reported . in this paper",
    "we investigate the model behavior in detail .",
    "we pay special attention to one of the main inherent issues when using em procedures , namely , algorithm initialization ( section [ stra ] ) . we show that in contrast to the example in @xcite , simple initializations do not always work , especially for rare diseases for which the risks are small , in low population size , as can occur in animal epidemiology .",
    "we then propose and compare different initialization strategies in order to determine a robust initialization strategy for most situations that arise in practice .",
    "the model selection issue , for example , the determination of the number of classes , is addressed using previous work [ @xcite ] in which a mean field approximation of the bayesian information criterion ( bic ) is provided for hmrf models .",
    "results are reported on both simulated data sets ( section [ expe ] ) and a real data set ( section [ esb ] ) concerning the bse epidemic in france .",
    "the bse example is typical of the difficulties that can be encountered .",
    "it is a very rare disease ( the global risk in france is about @xmath0 ) and concerns a very heterogeneous cow population [ see figure [ cattlehistopop](a ) ] , where many geographical units have a very low population ( sometimes only one cow ) , for example , in the french riviera .",
    "a discussion ends the paper ( section [ discu ] ) .",
    "in order to draw interpretable maps , with clearly delimited zones , we recast the disease mapping issue as a clustering task . based on count data for a rare phenomenon observed in a predefined set @xmath1 of @xmath2 areas ( e.g. , geographical regions ) , the goal is to assign to each region a risk level among a finite set of @xmath3 possible levels @xmath4 when these risk levels are themselves unknown and need to be estimated . in general ,",
    "risks are expected to be more similar in nearby areas than in areas that are far apart .",
    "the idea is to exploit the risk information from neighboring areas to provide more reliable risk estimates in each area . in each area ,",
    "two values are usually available , the number @xmath5 ( @xmath6 ) of observed cases of the given disease and the population size @xmath7 .",
    "a common assumption is that for an area indexed by @xmath8 , the number of cases @xmath9 is a realization of a poisson distribution whose parameter depends on the risk level assigned to the area .",
    "it is then convenient to consider the risk assignment for area @xmath10 as @xmath11 in a set of @xmath3-dimensional indicator vectors @xmath12 , where each @xmath13 has all its components set to 0 except the @xmath14th which is 1 .",
    "therefore , the data is naturally divided into observed data @xmath15 and unobserved or missing membership data @xmath16 .",
    "the latter are considered as random variables denoted by @xmath17 .",
    "the dependencies between neighboring @xmath18 s are then modeled by further assuming that the joint distribution of \\{@xmath19 } is a discrete mrf on the graph connecting contiguous locations ( i.e. , regions @xmath10 and @xmath20 are neighbors if they are spatially contiguous ) : @xmath21 where @xmath22 is a set of parameters , @xmath23 is a normalizing constant and @xmath24 is a function restricted to pair - wise interactions , @xmath25 where we write @xmath26 for the transpose of vector @xmath11 and @xmath27 when areas @xmath28 and @xmath29 are neighbors .",
    "the set of parameters @xmath30 consists of two sets @xmath31 .",
    "parameter @xmath32 is a @xmath3-dimensional vector which acts as weights for the different values of @xmath11 .",
    "when @xmath32 is zero , no risk level is favored , that is , for a given area @xmath28 , if no information on the neighboring areas is available , then all risk levels have the same probability .",
    "then @xmath33 is a @xmath34 matrix that encodes interactions between the different classes .",
    "if in addition to a null @xmath35 , @xmath36 where @xmath37 is a real scalar and @xmath38 is the @xmath39 identity matrix , parameters @xmath40 reduce to a single scalar interaction parameter @xmath37 and we get the potts model traditionally used for image segmentation .",
    "note that the standard potts model is often appropriate for classification since it tends to favor neighbors that are in the same class ( i.e. , have the same risk level ) .",
    "however , this model penalizes pairs that have different risk levels with the same penalty , regardless of the values of these risk levels . in practice",
    ", it may be more appropriate , from a disease mapping point of view , to encode higher penalties when the risk levels are further apart .",
    "this models the undesirability of abrupt changes in neighboring risk levels , as it is unlikely to observe a very low risk area next to a very high risk area .    in practice",
    ", these parameters can be tuned according to experts , a priori knowledge , or they can be estimated from the data . in the disease mapping context , we propose to use for @xmath41 a matrix with three nonzero diagonals defined for some positive real value @xmath42 by @xmath43 the idea is to favor neighbors in the same risk class first , and then neighbors in risk classes that are close , with all other pairs of risk classes being equally weighted .",
    "this is the simplest nonstandard @xmath41 structure that can encode smooth variations in the risk level .",
    "we tested other forms with less null values in @xmath41 and it appeared that allowing nonzero entries for pairs of classes more than 1 risk level apart was not penalizing enough .",
    "more generally , when prior knowledge indicates that , for example , two given classes are likely to be next to each other , this can be encoded in the matrix with a higher entry for this pair .",
    "conversely , when there is enough information in the data , a full free @xmath41 matrix can be estimated and will reflect the class structure ( i.e. , which class is next to which as indicated by the data ) and will then mainly serve as a regularizing term to encode additional spatial information . however , a full @xmath41 matrix is not a good idea in our rare disease situation with poorly separated classes , considering the potentially ambiguous information contained in the observations",
    ". the fine design of @xmath41 may be important in such a case .    for the model to be fully defined ,",
    "the observation model needs then also to be specified .",
    "typically in rare disease mapping , a poisson distribution is used as the class dependent distribution : @xmath44 where @xmath45 is the population size in area @xmath10 and @xmath46 with @xmath47^t$ ] is a vectorial notation that indicates the dependence on the specific value of @xmath11 which determines the risk level . for the distribution of the observed variables @xmath48",
    "given the classification @xmath49 , the usual conditional independence assumption leads to @xmath50 .",
    "it follows that the conditional probability of the hidden field @xmath49 given the observed field @xmath48 is @xmath51 the parameters of this model are then denoted by @xmath52 .",
    "the question of interest is to recover the unknown assignment map @xmath49 .",
    "to do so , we consider a maximum posterior marginal ( mpm ) principle consisting of assigning each region @xmath28 to the class @xmath53 that maximizes @xmath54 . in this paper , to deal with the missing data and the spatial dependence structure , we use the em algorithm [ @xcite ] with some of the approximations presented in @xcite based on the mean field principle .",
    "when the model is a hidden markov model with parameters @xmath55 , there are two difficulties in evaluating the expectation of the complete log - likelihood required in the em algorithm .",
    "both the normalizing constant @xmath23 in ( [ pgibbs ] ) and the conditional probabilities @xmath56 and @xmath57 for @xmath58 can not be computed exactly .",
    "the approximate em we consider decomposes into an e - step that consists of computing approximate posteriors denoted by @xmath59 and an m - step in which the risk updates are available in closed - form : @xmath60 in contrast , the mrf prior parameters @xmath22 need to be computed numerically ( see details in appendix a of the supplemental article [ @xcite ] ) . once the parameters are estimated , the area @xmath10 is assigned to the class @xmath14 for which the posterior probability is the highest .",
    "the likelihood function to be maximized generally possesses many stationary points of different natures .",
    "consequently , convergence to the global maximum with the em algorithm may strongly depend on the starting parameter values .",
    "this is be particularly true in our context where the discrete distributions and the low risks increase the estimation difficulty . to anticipate this initialization issue , as in @xcite , we adopt a three stage search / run / select strategy whose goal is to identify the highest likelihood in a reasonable amount of time :    _ search . _",
    "build a search method for generating @xmath61 sets of initial parameter values .",
    "these sets can be either generated at random or using some initialization strategy ( see section [ stra ] ) .",
    "_ for each initial position from the search step , run the variational em algorithm described in the previous paragraph until a stopping criterion is satisfied",
    ".    _ select .",
    "_ select the set of estimated parameter values that provides the highest likelihood among the @xmath61 trials .",
    "we focus below on the search step and describe the initialization strategy we propose for a more efficient exploration of the parameter space .",
    "to overcome the sensitivity of the em algorithm to starting values , different initialization strategies have been proposed and investigated in the context of independent gaussian mixtures [ see , e.g. , @xcite , chapter 2 , or @xcite ] .",
    "other initialization strategies have been investigated in @xcite for both gaussian and poisson mixtures , leading also to the conclusion that it was advisable to start from several different initial values to ensure more reliable results .",
    "most strategies can be divided into two categories : those based on initial parameter values and those based on an initial partition of the data . for the former , however , as observed by @xcite for the standard nonspatial gaussian case , at each iteration of the algorithm , the e and m steps produce estimated values that are not arbitrary but linked through some equations .",
    "the sequence of such estimates corresponds then to an em trajectory in the parameter space .",
    "parameter values randomly drawn do not necessarily belong to an em trajectory and this can result in computationally inefficient strategies , as the maximum likelihood solution necessarily belongs to one of the possible em trajectories .",
    "when using random partitions of the data into @xmath3 groups , starting values are obtained by computing the parameter estimates in each group , here the risk level as the ratio of the observed counts in the group over the population size of the group .",
    "they are by construction in the em trajectory space , but they tend to provide values close to each others and then not to explore the space efficiently ( see figure 1(d ) in the supplemental article [ @xcite ] for an illustration ) .    in the disease mapping context , the initialization issue has not really been addressed . in this context ,",
    "@xcite use 500 runs of a short - length cem algorithm before their approximate em .",
    "they report satisfying results with this initialization procedure , although it is mentioned in @xcite that this choice is generally not a stable strategy because cem is actually more sensitive to the starting value than em itself .",
    "we suspect then that the example in @xcite is so that there is no real initialization problem and any strategy would provide a satisfying solution .",
    "unfortunately , this is not the case for the bse data set under consideration in section  [ esb ] , for which we observed a high sensitivity to initialization . in this paper , we address initialization following the em trajectory - based idea developed in @xcite . compared to the work in @xcite , our task is complicated by the addition of a spatial markov prior whose parameters need also to be initialized .",
    "our first approach is then to focus on the initialization of the risks , that is , poisson distributions parameters @xmath62 .",
    "it is interesting to note that whatever the model for the spatial prior , an equation similar to that in @xcite can be found that links the @xmath63 s values .",
    "let @xmath64 be the total population size .",
    "at each iteration @xmath65 , we denote by @xmath66 the quantity @xmath67 which can be interpreted as the proportion of the population in the @xmath14th risk level .",
    "it follows easily that @xmath68 . using then equation ( [ riskup ] ) for the current risk level estimations , we get @xmath69 @xmath70",
    "can be interpreted as an average risk and has the property to depend on the observed data only . at each iteration of the algorithm ,",
    "the current parameter estimates @xmath71 satisfy this equation .",
    "consequently , all em trajectories are included in the space defined by this equation .",
    "the idea is then to produce values for the @xmath63 s by sampling in this space . a simple way to achieve",
    "this is to follow the simulation steps below :    _ step _ 1 .",
    "values for the @xmath72 s are first drawn using a dirichlet distribution @xmath73 , with @xmath74 for a uniform sampling on the space defined by @xmath75 .",
    ". then @xmath14 is chosen at random in the set @xmath76 and the @xmath77 s for @xmath78 are drawn uniformly and without replication in the sample @xmath79 .",
    "the last @xmath80 is set to verify : @xmath81 .",
    "the number of initial values generated this way is set by the user .",
    "note , however , that as in @xcite for gaussian parameters , the later equation in step 2 does not guarantee that @xmath82 is strictly positive .",
    "if this is not the case , the simulated sample is discarded and the procedure restarted from step 1 .",
    "the proposed strategy is illustrated in appendix b of the supplemental article [ @xcite ] .",
    "we show its ability to explore the parameter space more efficiently compared to other standard initializations .",
    "to complete our _ search _ procedure , we need in addition starting positions for the markov prior parameters @xmath83 .",
    "when @xmath41 reduces to some value @xmath42 [ definition  ( [ bdef ] ) ] , our full _ search _ procedure decomposes then in two steps :    _ search _ 1 .",
    "generate @xmath61 starting values @xmath84 using the two steps above .",
    "_ search _ 2 . for each initial value @xmath84 ,",
    "set @xmath85 ( equal class proportions ) , @xmath86 and run our variational em until the chosen stopping criterion is satisfied , with @xmath42 kept fixed to its initial value . only @xmath62 and @xmath35 are updated .",
    "we propose to use a stopping criterion based on a relative change in log - likelihood .",
    "the idea in adding the second step is to prevent undesirable behavior of the algorithm in the case of complex or very noisy data ( see figure 2 in the supplemental article [ @xcite ] ) .",
    "we observed in our real data set ( see section [ esb ] ) that imposing a certain amount of spatial structure first could help to avoid converging to meaningless solutions .",
    "this is typically done by fixing @xmath87 for a number of iterations before letting all the parameters free .",
    "this strategy is a simple solution we found to deal with very low risk values and poorly separated poisson mixture components , as can be observed in epidemiology . in practice",
    ", @xmath42 needs not to be fixed exactly to 1 .",
    "the appropriate range for @xmath42 depends on the number of neighbors in the underlying spatial structure . for 4 to 8 neighbors , values around 1",
    "have been observed , mainly in the 2d image segmentation context , to lead to reasonable spatial interactions . in our context , we observe that the @xmath35 values can become very small , probably when the model is trying to _ remove _ classes difficult to distinguish using the observed data .",
    "the model then seems to compensate for a small @xmath35 by increasing @xmath42 .",
    "fixing @xmath42 for some iterations at first is a way to favor reasonable estimations of the @xmath35 s , which in turn prevent an overestimation of @xmath42 . in a fully bayesian approach ,",
    "another way to prevent overestimation would be to use an exponential prior on @xmath42 .",
    "this choice is convenient in that it does not change much the numerical procedure used to estimate @xmath42 , but the choice of the hyperparameter also has to be fixed . note",
    "that in simpler better separated cases , the search  2 step is usually not necessary .",
    "our goal is to address the analysis of typical rare animal disease data for which the observed cases and the risk values may be very low , typically less than 10 cases among a small population size of few hundreds . in our illustrations ( both simulated and real data ) , the underlying structure is derived from the french territory .",
    "france is divided into @xmath88 hexagons each of width @xmath89 km ( @xmath90 km@xmath91 ) .",
    "the neighborhood structure is based on adjacent hexagons . for each hexagon ,",
    "the population size @xmath45 is set to the corresponding cattle population in france in the years 20012005 : the @xmath45 s vary from @xmath92 to 32,039 [ figure [ cattlehistopop](a ) , ( d ) ] .",
    "we consider then different simulated count data @xmath48 .        for comparison",
    "we consider three different strategies to provide an estimation of the unknown parameters and mapping into regions of homogeneous risk levels .",
    "two of them , denoted , respectively , by @xmath93 and @xmath94 , correspond to search / run / select decompositions as introduced in section [ emalgo ] . a  third one denoted by @xmath95",
    "represents commonly used strategies when dealing with initialization issues . in particular",
    ", it is close to the strategy used in @xcite .",
    "the only difference is that in this later work the nonspatial em is replaced by a nonspatial cem ( classification em ) .",
    "we rather use em since cem is known to be even less stable than em with respect to initialization [ @xcite ] . more specifically :    _ @xmath93 strategy _ : @xmath61 initial values for all the parameters are generated using the em trajectory properties and the full search procedure described in section [ stra ] .",
    "our variational em is then run for each parameter set until convergence and the parameter values corresponding to the highest likelihood are selected .    _",
    "@xmath94 strategy _ :",
    "this strategy differs from the previous one only in the way the @xmath61 initial @xmath62 values are generated .",
    "they are generated at random ( uniformly between 0 and 1.5 in our disease mapping context ) .    _",
    "@xmath95 strategy _ : @xmath61 initial values for @xmath62 are generated uniformly at random , @xmath35 is initialized to the null vector and @xmath42 is fixed to 0 ( nonspatial case ) . the standard em algorithm with no spatial interaction",
    "is run until convergence for each parameter set .",
    "the estimate parameter values with the highest likelihood are then selected and used as initial values for our variational em with spatial interaction .",
    "focusing then on the @xmath93 strategy , we investigate variations in the hidden mrf part .",
    "we compare the interaction model we propose [ equation ( [ bdef ] ) ] to the standard potts model ( @xmath96 ) and to another variant for which @xmath41 is so that @xmath97 .",
    "note that for @xmath98 the formula above leads to the standard potts model and for @xmath99 to our model .",
    "it distinguishes from our choice for @xmath100 and we will refer to it as the _ smooth gradation model_. the idea behind such a comparison is to show that three nonzero diagonals in the @xmath41 interaction matrix ( our model ) are enough to account for smooth gradation constraints .",
    "comparison with standard independent mixtures ( @xmath101 ) is not reported , but we observed , as expected , that such nonspatial models did not provide satisfying risk maps .",
    "regarding variational em , we investigated both the so - called _ mean field _ and _ simulated field _ variants .",
    "in contrast to some other studies [ @xcite ] , we observed that for the type of data sets under consideration , the _ mean field _",
    "algorithm was providing better and more stable results .",
    "this is probably due to the fact that this variant tends to smooth the data more , which is here an advantage to better recover the spatial structure . in the following sections ,",
    "results are then reported only for the _ mean field _ algorithm .",
    "we consider two synthetic risk maps with , respectively , @xmath102 and @xmath103 risk classes [ see figure [ cattlehistopop](b ) , ( c ) ] . in the 3-class case , risk levels are set to @xmath104 , @xmath105 and @xmath106 . in the 5-class case ,",
    "the risks are set to @xmath104 , @xmath107 , @xmath108 , @xmath109 and @xmath110 , corresponding to diseases as rare as bse . from the population counts ( @xmath45 s ) , the _ true _ risk values above , the known classes , we can easily simulate the counts @xmath9 s from the poisson distribution in ( [ poissind ] ) .",
    "examples of such counts are shown in figure [ cattlehistopop](e ) , ( f ) .",
    "figures [ res3class ] and [ res5class](a)(c ) show the corresponding classifications obtained with the three strategies @xmath93 , @xmath94 and @xmath95 , with @xmath111 assuming @xmath99 and @xmath112 , respectively .",
    "the classification obtained with the bym method [ @xcite ] and with the two other @xmath41 models mentioned above are also reported [ figures [ res3class](d ) , ( e ) and [ res5class](d ) , ( e ) , ( f ) , resp . ] .",
    "the performance is evaluated considering both classification performance and risk value estimation . for classification performance , we consider for each class the dice similarity coefficient ( dsc ) [ @xcite ] .",
    "this coefficient measures the overlap between a segmentation result and the ground truth .",
    "denoting by @xmath113 the number of true positives for class @xmath14 , @xmath114 the number of false positives and @xmath115 the number of false negatives , the dsc is given by @xmath116 and @xmath117 takes its value in @xmath118 $ ] , where @xmath92 represents the perfect agreement .",
    "table [ extable1 ] shows these dsc values and the estimated risk values .    ,",
    "@xmath94 and @xmath95 strategy . : risk map obtained with the bym model . : risk map obtained with the standard potts model using @xmath93 . ]    , @xmath94 ,  @xmath95 , starting from 1000 initial positions , with the bym model , using the standard potts model and the _ smooth gradation model_. risk maps obtained starting from 10 initial positions with the @xmath93 , @xmath94 and @xmath95 strategies . ]    for both the 3 and 5 class examples , the bym model is clearly not providing satisfying mappings .",
    "in particular , the highest risk regions are found in regions with very few cattle populations ( e.g. , south  east of france ) . in terms of risk estimation",
    ", bym tends to overestimate risk levels , especially the lowest ones . for high risks ,",
    "the overestimation is not as large , but the corresponding regions are not properly identified .",
    "note , however , that this model has not been originally designed to handle data simulated from a small number of constant risk values .",
    "this type of data clearly favors hmrf - based models such as ours , although we suspect the bym limitations mainly come from its difficulties in handling low population size ( see a similar conclusion in the bse case )",
    ".    to consider cases more favorable to the bym model and put our model at comparative disadvantage , we also simulated a data set similar to that in @xcite , with a north  south gradient corresponding to risks smoothly ( linearly ) decreasing from north to south from @xmath119 to @xmath120 .",
    "the true risk map , the corresponding simulated data and the bic values for the potts and our models are shown , respectively , in figure 3(a ) , ( b ) and table 1 of the supplemental article [ @xcite ] . the selected @xmath3 is 5 for both models .",
    "the resulting maps for @xmath121 and 7 are then also shown in figure 3 for the potts ( e ) , ( h ) , ( k ) , the bym ( f ) , ( i ) , ( l ) and our models ( d ) , ( g ) , ( j ) .",
    "the discrete hmrf models ( potts and ours ) show satisfying results with some better risk estimations and region shapes obtained with our model [ see , e.g. , figures ( g ) , ( j ) ] .",
    "the bym model does well in estimating high risk regions in the north [ figure 3(l ) ] but wrongly classifies as high risk the south  east [ figure 3(c ) , ( f ) , ( i ) , ( l ) ] . this surprising good behavior of discrete hmrf models has already been observed by @xcite ( section 4.7 ) , where they mention that the models perform competitively to the bym model .",
    "similar conclusions are drawn for simulations generated according to the bym model [ see section 4.7 in @xcite ] .",
    "going back to our first experiment , in the 3-class case ( table [ extable1 ] ) , all strategies give reasonable results , for the high and medium risk regions , both in terms of estimation and classification .",
    "the main differences are observed for the low risk region . our proposed strategy @xmath93 performs better than @xmath95 at estimating the low risk value .",
    "it is also better , although comparable to the @xmath94 strategy . in terms of mapping ,",
    "@xmath94 and @xmath93 clearly outperform @xmath95 .",
    "the @xmath94 result looks visually better , but in terms of classification rates ( table [ extable1 ] ) this is the case only for the low and medium risk regions .    in the 5-class case ( table [ extable1 ] )",
    ", all strategies have trouble separating the low and very low risk regions and tend to lose a class .",
    "for the @xmath95 strategy we can visualize the 5 classes , but this is due to the division of the true high risk region into two classes which correspond to almost the same risk values ( @xmath122 and @xmath123 for high risk ) .",
    "the low risk region is not better identified in this case and two classes are separated although they correspond to the same risk value .",
    "we will see in what follows ( table [ lbd53class ] ) that this seems to be a tendency of the @xmath95 strategy . in terms of classification , the @xmath93 strategy outperforms the other strategies for the high and very high risk regions , which correspond to the risk levels of importance in epidemiology .",
    "indeed , for immediate control purposes , it is crucial to detect regions where the disease is more developed , while low risk regions may help afterward to envisage protection factors by comparing , for instance , the differences in a number of covariates between these regions and the high risk ones .    @lccc@",
    "* true risk level * & * strategy * & * dsc * & * estimated risks * +   + _ low _ & @xmath94 & 0.84 ( 0.25 ) & @xmath124 @xmath125 + @xmath126 & @xmath95 & 0.53 ( 0.33 ) & @xmath127 @xmath128 + & @xmath93 & 0.79 ( 0.25 ) & @xmath129 @xmath130 + [ 4pt ] _ medium _ & @xmath94 & 0.88 ( 0.20 ) & @xmath131 @xmath132 + @xmath133 & @xmath95 & 0.44 ( 0.41 ) & @xmath134 @xmath135 + & @xmath93 & 0.77 ( 0.30 ) & @xmath136 @xmath137 + [ 4pt ] _ high _ & @xmath94 & 0.99 ( 0.09 ) & @xmath138 @xmath139 + @xmath140 & @xmath95 & 0.93 ( 0.18 ) & @xmath141 @xmath142 + & @xmath93 & 0.96 ( 0.10 ) & @xmath143 @xmath144 + [ 6pt ] + [ 4pt ] _ very low _ & @xmath94 & 0.42 ( 0.29 ) & @xmath145 @xmath146 + @xmath147 & @xmath95 & 0.36 ( 0.24 ) & @xmath148 @xmath149 + & @xmath93 & 0.56 ( 0.20 ) & @xmath150 @xmath151 + [ 4pt ] _ low _ & @xmath94 & 0.29 ( 0.19 ) & @xmath152 @xmath153 + @xmath154 & @xmath95 & 0.22 ( 0.18 ) & @xmath155 @xmath156 + & @xmath93 & 0.29 ( 0.17 ) & @xmath157 @xmath158 + [ 4pt ] _ medium _ & @xmath94 & 0.38 ( 0.25 ) & @xmath159 @xmath160 + @xmath161 & @xmath95 & 0.16 ( 0.21 ) & @xmath162 @xmath163 + & @xmath93 & 0.09 ( 0.18 ) & @xmath164 @xmath165 + [ 4pt ] _ high _ & @xmath94 & 0.51 ( 0.33 ) & @xmath166 @xmath167 + @xmath168 & @xmath95 & 0.55 ( 0.33)&@xmath169 @xmath170 + & @xmath93 & 0.66 ( 0.38 ) & @xmath171 @xmath172 + [ 4pt ] _ very high _ & @xmath94 & 0.44 ( 0.18 ) & @xmath173 @xmath174 + @xmath175 & @xmath95 & 0.65 ( 0.34 ) & @xmath176 @xmath177 + & @xmath93 & 0.83 ( 0.17 ) & @xmath178 @xmath179 +    to emphasize the difference between the @xmath93 and @xmath94 strategies , we consider the same 5-class data set but reduce the number of starting values to @xmath180 .",
    "this can typically be necessary with a limited amount of computational resources . as mentioned in section [ stra ] and illustrated in figure 1(e)(g ) , in the supplemental article [ @xcite ] this should benefit to our @xmath93 strategy which is more efficient in exploring the parameter space and in finding good initializations . indeed , we observe more satisfying mapping results [ see figure [ res5class](g)(i ) ] with @xmath93 than with @xmath94 for similar estimations of the different risk levels .",
    "@xmath93 is clearly better at identifying the very high risk regions but also in this case the low risk ones .",
    "@xmath95 is clearly providing less satisfying results in this case .",
    "additional maps obtained with the other mentioned @xmath41 models show that both the _ smooth gradation model _ and our model improve over the standard potts model that does not include constraints on risk level gradation . in terms of dsc values ,",
    "our model outperforms the _ smooth gradation model _ in the 5-class example ( table  [ extable1 ] ) .    to illustrate the robustness of our model to nonsmooth risk level gradation , we considered two additional simulations using the same synthetic risk partitions [ figure [ cattlehistopop](b ) , ( c ) ] but with permuted risk levels . in the 3-class example , @xmath181 , @xmath182 and @xmath183 so that we locate now the highest risk next to the lowest one .",
    "in the 5-class case , similarly the risk levels are permuted to @xmath184 , @xmath185 , @xmath186 , @xmath187 and @xmath188 .",
    "results obtained with the bym model and both the potts and our models are shown in figure 4 of the supplemental article [ @xcite ] .",
    "the potts and our model provide similar results ( see also the dice scores in table 2 of the supplemental article [ @xcite ] ) more satisfying than bym . in the 3-class example",
    ", the particularity of our model appears clearly at the border of two of the classes with some wrongly classified hexagons .",
    "paradoxically , overall the hmrf models performance is better than in the smooth gradation case . the fact that neighboring risk levels are now more different induces better separated classes and makes the classification easier .",
    "the very low values of the risk levels induce some difficulty in interpreting the results and are responsible for some instability . to further investigate the algorithms , we repeat the simulations above a hundred times with the same true risk values . for the true values of @xmath3 , the performance",
    "is then evaluated considering both average classification performance and risk value estimation .",
    "table [ lbd53class ] shows for the 3- and 5-class cases , the mean and standard deviation of the dsc values for the 100 simulated data sets .",
    "it also shows the mean and standard deviation of the estimated risk values .    for the 3-class example , the average estimation of the risk values is in general close to the real parameter values for the three strategies .",
    "however , @xmath95 tends to overestimate low risks . @xmath93 and @xmath94 give similar results . in terms of dsc values",
    ", @xmath94 outperforms @xmath93 on average and shows smaller variances .",
    "however , the boxplots of figure 5(a)(c ) in the supplemental article [ @xcite ] show that the median risk values are very close for both strategies . in the 5-class case",
    ", @xmath93 provides better average risks for the high and very high risk values . in terms of dsc values , the average values are higher and the variances generally lower for @xmath93 . for estimated risks ,",
    "it is also the case for medium to very high risks .",
    "the @xmath93 strategy seems to provide better and more stable results for higher risk values , which is a desirable feature in epidemiology .",
    "the boxplots in figure 5(d)(h ) in the supplemental article [ @xcite ] show that this is generally compensated by a worse estimation of the medium risk class compared to @xmath94 [ figure  5(f ) ] .    for the 3-class case",
    ", we can notice that the estimator @xmath189 predicts observations of the parameter @xmath62 with good accuracy .",
    "however , the estimation of parameters associated to the highest risk region is much more precise than for lowest risk . for the 5-class case ,",
    "larger variations are observed for the class which disappears in general ( @xmath190 ) .",
    "the estimation is also more precise for higher risks than for the lowest ones .",
    "we then also consider the issue of selecting the right number of classes . in this case",
    "@xmath3 is not fixed .",
    "for each simulation in the 3-class case , we run our algorithm with the @xmath93 initialization , for @xmath98 and @xmath99 .",
    "we observed that for @xmath191 , the algorithm systematically loses a class and these values of @xmath3 are never selected .",
    "we then used the mean field approximation of the bayesian information criterion ( bic ) , as described in @xcite for hidden markov models , to select @xmath3 among @xmath98 or 3 . for the @xmath93 strategy",
    ", it follows that among the 100 simulations , @xmath99 was selected 75 times and @xmath98 was selected 25 times .",
    "similarly , in the 5-class example , we used the approximate bic to select a value of @xmath3 from 2 to 7 .",
    "@xmath112 was selected 46 times , @xmath192 was selected 42 times , @xmath99 was selected 12 times and @xmath193 were never selected .",
    "similar results were observed for the other strategies .",
    "it confirms especially in the 5-class case that the data we have to deal with do not correspond to an easy well - separated case .",
    "focusing then again on the @xmath93 initialization , we compare the model used in ( [ bdef ] ) with the standard potts model and the so - called _ smooth gradation model _ in terms of classification rate and risk estimation .",
    "the results are shown in table [ pottsvartable ] .",
    "@lccc@ @xmath41 * model * & * risk level * & * dsc * & +   + _ standard potts _ & low & 0.40 ( 0.34 ) & @xmath194 @xmath195 + @xmath196 & medium & 0.43 ( 0.37 ) & @xmath197 @xmath198 + & high & 0.92 ( 0.22 ) & @xmath199 @xmath200 + [ 4pt ] _ smooth gradation _ & low & 0.79 ( 0.25 ) & @xmath201 @xmath202 + and _ our model _ & medium & 0.77 ( 0.30 ) & @xmath203 @xmath204 + @xmath205 & high & 0.96 ( 0.10 ) & @xmath206 @xmath207 + [ 6pt ] + [ 4pt ] _ standard potts _ & very low & 0.19 ( 0.21 ) & @xmath208 @xmath209 + @xmath196 & low & 0.25 ( 0.21 ) & @xmath210 @xmath211 + & medium & 0.32 ( 0.25 ) & @xmath212 @xmath213 + & high & 0.48 ( 0.32 ) & @xmath214 @xmath215 + & very high & 0.57 ( 0.25 ) & @xmath216 @xmath217 + [ 4pt ] _ smooth gradation _ & very low & 0.40 ( 0.24 ) & @xmath218 @xmath219 + @xmath205 & low & 0.19 ( 0.19 ) & @xmath220 @xmath221 + & medium & 0.14 ( 0.28 ) & @xmath222 @xmath223 + & high & 0.75 ( 0.32 ) & @xmath224 @xmath225 + & very high & 0.89 ( 0.07 ) & @xmath226 @xmath227 + [ 4pt ] _ our model _ & very low & 0.56 ( 0.20 ) & @xmath228 @xmath229 + @xmath230_+$ ] & low & 0.29 ( 0.17 ) & @xmath231 @xmath232 + & medium & 0.09 ( 0.18 ) & @xmath164 @xmath165 + & high & 0.66 ( 0.38 ) & @xmath171 @xmath172 + & very high & 0.83 ( 0.17 ) & @xmath178 @xmath179 +    overall , we observe that the three strategies are recovering more easily the high risk regions than the low risk regions . in general , when classes disappear , they correspond to the regions of lowest risks . the @xmath93 strategy performs satisfyingly compared to other strategies .",
    "in particular , the proportions of correctly allocated hexagons is improved . also , with a limited amount of computational resource",
    ", the @xmath93 is more likely to provide satisfying results with a better exploration of the parameter space .",
    "additional experiments on the hidden mrf part confirm that both the _ smooth gradation model _ and our model improve over the standard potts model and suggest that compared to the _ smooth gradation model _ our model will be less likely to lose the more problematic lowest risk classes as illustrated in figure  [ res5class](f ) .",
    "the bovine spongiform encephalopathy ( bse ) is a noncontagious neurodegenerative disease in cattle .",
    "this sudden and unexpected disease threatened bovine production in europe and has been intensively studied , in particular , for spatial patterns [ @xcite ] .",
    "it is transmitted by meat and bone meal .",
    "since there is no direct transmission and no vector , spatial analysis is important to understand and explain the geographical localization of the cases . in our data",
    "set , the numbers of observed cases are available for each hexagonal geographical unit in france .",
    "these cases occurred between july 1 , 2001 and december 31 , 2005 , although at that time meat and bone meal , the main risk factor , had been already forbidden for cattle in france .",
    "figure [ bseres](b ) shows the corresponding observed map , and figure [ bseres](c ) the standard mortality rate .",
    "we first apply our model initialized with the @xmath93 strategy described in section [ stra ] . regarding the number of classes , the approximated bic of @xcite suggests to select @xmath99 . for comparison",
    ", we also consider the bym model widely used in epidemiology .",
    "since this model only provides continuous estimated values for the risk level in each hexagon , some additional post - processing is required to obtain the mapping into a prescribed number @xmath3 of risk levels .",
    "such a mapping can be obtained by applying some clustering procedure on the estimated continuous values . a commonly used method for that",
    "is the em algorithm for gaussian mixtures .",
    "figure [ bseres](d ) , ( f ) shows the mapping obtained        with the bym model and our model .",
    "the fact that bym provides continuous risk values is then not necessarily an issue for users .",
    "as illustrated in a recent paper by @xcite , it is natural to consider such models , as they can have reasonable unusual risk detection behavior and can be relatively easy to fit .",
    "also , bayesian approaches represent a whole family of methods for disease mapping .",
    "cluster detection methods are another important class of methods .",
    "our data are aggregated , but we can also consider our data as point data to apply such cluster detection methods .",
    "the objective of cluster detection methods for point data is to identify , if they exist , the zones in which the concentration of events is abnormally high , usually named clusters . to assess the significance of a supposed cluster , the observed concentration",
    "is usually compared with the concentration observed under the null hypothesis @xmath233 that the events are sampled independently from the underlying population density , generally a poisson distribution in epidemiology ( as in the bym model and our model ) .",
    "one of the most popular approaches is the scan statistic adapted to the spatial setting by @xcite .",
    "it relies on the generalized likelihood - ratio test statistic of @xmath233 against a piecewise constant density alternative . to apply this method",
    ", one needs to set the family of the possible clusters , for example , all the discs centered on a point of a predefined grid . the radius of each circle is generally set to vary continuously from zero to an upper limit ( e.g. , less than @xmath234 of the total area ) .",
    "this predefined shape of the cluster can be an important limitation since , in the real world , an excess of events may be recorded along a river , for example . an alternative has been proposed more recently : @xcite investigated a wide family of elliptic windows with predetermined shape , angle and center .",
    "the ultimate solution would be to consider all the convex envelopes including any subset of the events locations .",
    "however , this becomes computationally infeasible when the number of events is large .",
    "the statistical significance of the largest likelihood ( for positive clusters or the lowest likelihood for negative clusters ) is assessed by determining its distribution under the null hypothesis through monte carlo simulation .",
    "this method is implemented in the satscan software [ @xcite , http://www.satscan.org/ ] . for the bse data set",
    ", we then also include the results [ figure [ bseres](h ) , ( i ) ] using the spatial scan statistic for circular and ellipsoidal clusters . for comparison , we indicate the corresponding average risk value in each detected cluster .",
    "positive clusters are indicated using a dark grey color , while negative clusters are in white .",
    "when comparing the four maps obtained with the expert knowledge related to the bse disease in france , the result from our model appears to be very satisfying .",
    "three regions are clearly delimited and correspond to the regions expected by the experts and highlighted in previous works [ @xcite ] .",
    "indeed , in the bse case it is known that high risks regions are located in brittany , in the center , in the south  west of france and in the alps .",
    "the localization of these regions is shown in figure [ bseres](a ) .",
    "geography and topography are not , however , important explanatory factors for the disease which should rather be related to local agricultural traditions . in these regions",
    "there is a high density of monogastric species [ @xcite ] , for example , pigs and poultry , and meat and bone meal were used to feed these species [ @xcite ] .",
    "it is suspected that the bse risk can be explained by cross - contamination with an ingredient used in poultry or pig feed .",
    "cross - contamination may occur at the factory , if food chains for monogastrics and ruminants are not clearly distinct , during the shipment of feed to the farms , or on the farms , especially on mixed farms with both cattle and pig or poultry operations [ @xcite ] .",
    "our analysis , detecting coherent risk regions , supports this hypothesis .    in the bym map ,",
    "additional high risk regions are highlighted but with boundaries that are more doubtful , sometimes including too few hexagons or including regions known for low risk .",
    "typically , the alps region ( known as high risk ) is not clearly identified but merged with the south  east region ( known as low risk ) . moreover",
    ", the french riviera appears as a higher risk region than the alps and the south ",
    "west , although it is known that on this very urban coast the cattle population is low and no cases are observed [ @xcite ] .",
    "our hmrf mapping is in that sense much more reliable with the french riviera identified as a low risk region , as it should .",
    "we suspect that this bad feature of bym may come from the strength of its spatial prior in the absence of strong information on the spatial structure in the observed data .",
    "we presume this is the case for the bse data set so that the resulting map using bym may also mainly reflect the prior rather than the observations .",
    "it can then be seen from the scan statistic maps in figure [ bseres](h ) , ( i ) that with this method , among the four known regions at risk , only brittany ( west ) is retrieved as a positive cluster .",
    "the center , the alps ( east ) and the south  west are not detected as positive clusters . moreover ,",
    "these zones considered at risk are partly included in the negative clusters detected , that is , highlighted as having a low bse risk .",
    "this may be related to the fixed shapes of the clusters . regarding the higher risk values ,",
    "they are lower than the ones estimated with bym and our model .",
    "it is interesting to note a closer similarity of the ellipsoidal cluster map with the map obtained with the standard potts model displayed in figure [ bseres](g ) . in both maps ,",
    "the high risk region in the west is too large and a similar diagonal low risk region is recovered .",
    "however , the potts model is also able to recover high risk regions in the alps and south  west .",
    "when studying diseases , in particular , emerging diseases , the ability of our method to accurately recover high risk regions is an essential feature , as it is important to clearly identify the regions where important and quick decisions have to be taken to control diseases and to implement prevention measures . during the bse epidemic in france ,",
    "every herd where a case had been detected was killed .",
    "for such a culling protection measure , with important economical consequences , a better knowledge of risk regions could be employed to try to limit the culling procedures . in the case of bse",
    ", the regions highlighted as showing a higher risk of bse through the spatial analysis would have focused the veterinary services inquiries and possibly led to earlier detection of the cross - contamination factor .    using the same initialization and computing bic , we selected also @xmath99 for both the standard potts model and _ smooth gradation model _ equivalent to our model in this case . comparing all bic values",
    "( see table 3 in the supplemental article [ @xcite ] ) , the best scores for these two models and ours are equivalent , but the risk map provided by the _",
    "smooth gradation _ and our models [ figure [ bseres](c ) ] clearly makes more sense than the one obtained with the standard potts model [ figure [ bseres](g ) ] .",
    "once again , we prefer the method that more accurately recovers high risk regions , that is , the generalization of the potts model we propose .",
    "in this paper we propose an unsupervised method for automatically classifying geographical units into risk classes , in order to draw interpretable maps , with clearly delimited zones .",
    "such risk zones may be useful to focus posterior disease surveillance , control procedures and epidemiological studies .",
    "to do so , we recast the disease mapping issue into a clustering task using a discrete hidden markov model and poisson class - dependent distributions .",
    "the designed hidden markov prior is nonstandard and consists of a variation of the potts model where the interaction parameter can depend on the risk classes .",
    "one advantage of our discrete hrmf modeling is that the classification step is part of the model instead of being a post - processing step , as in most methods currently used by animal epidemiologists .",
    "the model parameters are then estimated using an em algorithm and a mean field approximation principle .",
    "this provides a way to face the intractability of the standard em in this spatial context , with a computationally efficient alternative to more intensive mcmc procedures .",
    "one advantage is then that analysis is possible on large data sets in a reasonable time .",
    "but one typical limitation is that the uncertainty in both the risk estimated and classification is likely to be underestimated .",
    "variational approximation techniques often show competitive estimations when compared to their mcmc counterparts , but they are also said to be overly optimistic by underestimating variability .",
    "we then focused on challenges presented by very low risk values and small numbers of observed cases and population sizes , as can occur with rare diseases , and as observed in our real data set regarding bse in france .",
    "in particular , we addressed the problem of finding good initial parameter values which can be critical in this context .",
    "we developed a new initialization strategy appropriate for spatial poisson mixtures in the event of poorly separated classes , as encountered in animal disease risk analysis .",
    "our discrete hmrf - based method provides risk maps more reliable than the traditional bym method , with less classification errors and more clearly delimited at risk zones .",
    "our generalized potts model also shows a better ability to recover risk regions than the standard potts model .",
    "our experiments show that our model performs well in determining high risk regions , both in terms of accurate localization of these regions and estimation of the associated risk levels .",
    "this is an important point since these high risk regions are of primary interest in practice when the goal is to eventually impose safety procedures .",
    "the low risk regions are more difficult to delineate , especially when they are not in areas of large population size .",
    "but their practical interest is less crucial , as they are essentially used afterward to consider protections factors .",
    "overall , our experiments suggest that the usual bym method , in its simplest version , is not adapted to rare diseases in very inhomogeneous populations , as it tends to estimate high risks in regions with very low population .",
    "the solution we propose instead is a flexible model whose parameters are easy to interpret and to adapt to other situations involving spatial count data .",
    "in particular , the interpretation of the pair - wise potential functions in terms of neighborhood interaction allows users to define their own spatial smoothing depending on the targeted task .",
    "as regards disease mapping , we show that a simple convenient design for the interaction matrix @xmath41 was provided by our choice of a three nonzero diagonal matrix , which accounts for smooth risk gradation while producing satisfying delineations for both high and low risk regions .",
    "also , the definition of the neighborhood , simply based on geographical proximity in this paper , can be adapted to the context and potentially include nonspatial information through some measures of similarity between sites based on nongeographical features .",
    "typically , for the bse example , sites could be set as neighbors if they share the same animal food provider , information known to be of major importance regarding the bse risk [ @xcite ] .",
    "a second example is the possibility to introduce interactions to account for an ecological gradient , such as wind dissemination that could be important , for example , for diseases transmitted by mosquitoes .",
    "in addition , to better understand the mechanisms underlying the spread of a disease , it is possible to introduce covariates at various stages of the hierarchy without changing too much the structure of the model .",
    "the use of a mean field principle for inference generalizes easily in this case and has the advantage to maintain the model tractability .",
    "then , the model applies naturally to all kinds of graphical structures and can therefore adapt easily to integrate temporal information such as given , for instance , by observations corresponding to cases for the same area but at different periods of time .",
    "further investigations for such a spatio - temporal analysis are planned ."
  ],
  "abstract_text": [
    "<S> current risk mapping models for pooled data focus on the estimated risk for each geographical unit . a risk classification , </S>",
    "<S> that is , grouping of geographical units with similar risk , is then necessary to easily draw interpretable maps , with clearly delimited zones in which protection measures can be applied . as an illustration , we focus on the bovine spongiform encephalopathy ( bse ) disease that threatened the bovine production in europe and generated drastic cow culling . </S>",
    "<S> this example features typical animal disease risk analysis issues with very low risk values , small numbers of observed cases and population sizes that increase the difficulty of an automatic classification . </S>",
    "<S> we propose to handle this task in a spatial clustering framework using a nonstandard discrete hidden markov model prior designed to favor a smooth risk variation . </S>",
    "<S> the model parameters are estimated using an em algorithm and a mean field approximation for which we develop a new initialization strategy appropriate for spatial poisson mixtures . using </S>",
    "<S> both simulated and our bse data , we show that our strategy performs well in dealing with low population sizes and accurately determines high risk regions , both in terms of localization and risk level estimation .    ,    ,    , </S>"
  ]
}