{
  "article_text": [
    "the description of a complex , multidimensional , stochastic process is often simplified by projecting it on one or a few variables @xcite . during such dimensionality reduction one",
    "may lose some information ; hence the variables should be optimally selected to preserve the information of interest .",
    "here we are interested in the selection of variables that preserve the information about the dynamics .",
    "one aims to select a coordinate such that the dynamics projected on the coordinate is approximately markovian , i.e. , it is independent from the dynamics along other degrees of freedom . in other words ,",
    "the current value of the coordinate alone determines the future dynamics of the coordinate .",
    "such dynamics are often described as diffusion on a free energy profile with a position dependent diffusion coefficient , which can be determined from the coordinate time series @xcite .",
    "the folding ( splitting or committor ) probability is considered to be an optimal coordinate @xcite for the description of transition dynamics between any two chosen boundary states , i.e. , a reaction .",
    "the name comes from the protein folding field , where this coordinate is equal to the probability of reaching the folded state before reaching the unfolded state starting from the current configuration @xcite .",
    "the projection on the coordinate preserves some properties of the dynamics , in particular , the equilibrium flux between the boundary states , and the committor probability , by construction .",
    "these properties can be computed exactly by simulating diffusive dynamics with the determined free energy landscape and diffusion coefficient @xcite .",
    "the coordinate , however is exact only for the description of the equilibrium transition dynamics between two boundary states .",
    "the dynamics inside the boundary states , or dynamics in general , without defining two end states , can not be described .",
    "it may seem unlikely that a single coordinate , even though optimally selected , can give a complete description of multidimensional complex dynamics .",
    "classical mechanics , however , provides an example .",
    "the action or the hamilton s principal function @xmath0 gives complete description of the dynamics of a system governed by the deterministic equations of classical mechanics .",
    "here we suggest a class of optimal coordinates for the description of stochastic dynamics in general .",
    "we show that under some conditions the equations for the optimal coordinate , suggested here , are reduced to the hamilton - jacobi equation for the action function .",
    "in other words , the suggested optimal coordinate can be considered as a generalization of the action function to stochastic dynamics .",
    "the problem of the determination of such an optimal coordinate is closely related to two other problems .    * the eigen - modes for stochastic dynamics . *",
    "the decomposition of the dynamics of a multidimensional harmonic oscillator on normal modes is an example of a markovian projection on coordinates .",
    "each mode evolves independently .",
    "the phase of each normal mode can be considered as an optimal coordinate .",
    "a quantum mechanical wave function , which is a linear combination of basis eigen - functions , is another example .",
    "can one introduce analogous concepts for equilibrium stochastic dynamics ?",
    "the conventional decomposition of the probability distribution on the eigenvectors of the master equation is not appropriate . since all the eigenvalues ( but the first ) have negative real part @xcite the projection on each eigenvector exponentially decay with time .",
    "thus after a finite amount of time only the equilibrium eigenvector survives .",
    "the latter does not describe dynamics .",
    "however , if one observes a particular dynamical trajectory of the process , the dynamics becomes stationary but never stops . which leads us to the second problem .",
    "can one define such eigen - modes that can be used to describe stationary stochastic dynamics .",
    "the folding probability optimal coordinate which monitors progress of the folding reaction , increases as the system comes closer to the folded state .",
    "it is natural to expect that an optimal coordinate that monitors progress of the dynamics in general , without any relation to boundary states , steadily increases . in particular",
    ", it should increase whenever the system changes its state .",
    "a variable which always increases , whenever the system changes its state is time . which leads us to the third problem .",
    "* the reconstruction of time .",
    "* assume that we observe a stochastic process , generated by an unknown transition probability or transition rate matrix .",
    "we have access to all the variables representing the state of the system apart from the time variable ( which is external to the system ) .",
    "for example , one is given a trajectory of the system sampled with random unknown time intervals .",
    "can one reconstruct the time variable ?",
    "such reconstruction can be useful , for example , if one wants to determine the transition probability matrix .",
    "let @xmath1 be such a function of coordinates that can be used to reconstruct the time interval as @xmath2 , where @xmath3 is a trajectory .",
    "since the dynamics is stochastic , such estimates fluctuate around a true value .",
    "thus , to determine time accurately , one needs to average it over an ensemble of trajectories .",
    "the time interval can be estimated more precisely as @xmath4 $ ] , where the average is taken over an ensemble of trajectories @xmath5 ( @xmath6 ) leading from an initial distribution @xmath7 to a final distribution @xmath8 and @xmath9 .    any such function that allows accurate time reconstruction",
    "can be considered as an optimal coordinate .",
    "the trajectory projected on such a coordinate has simple dynamics .",
    "there is no need to compute the free energy profile and the diffusion coefficient .",
    "starting from the current position @xmath10 , its position after a time interval @xmath11 is equal ( on average ) to @xmath12 , i.e. , it depends only on the current position .",
    "while the optimal coordinate @xmath1 describes the stochastic dynamics in a simple way , it might be useful to be able to map this description back to the original dynamics . in principle , one can invert the relationship .",
    "given @xmath7 and @xmath13 , one may attempt to determine @xmath8 . since we have just a single equation to determine the final distribution @xmath8 , the problem is ill - defined .",
    "it can , however , be solved in the following cases .",
    "the first case , when one is interested in a single parameter of the distribution , for example , an average of some operator like the mean position .",
    "the time dependence of a single parameter can be determined from the single equation .",
    "the second case , if the initial distribution is an eigen mode of the dynamics , then ( by construction ) the distribution does not change with time .",
    "the only changing parameter is the `` phase '' which can be determined from the single equation .",
    "the general solution is then obtained as a superposition of all such eigen - modes .",
    "this case corresponds to the conventional way of solving a linear equation by decomposing it onto a sum of eigen - modes , i.e. , it provides the solution to the second problem .    here",
    "we introduce a general method to solve the three problems .",
    "briefly , the main difference between the proposed method and the conventional one is to seek the solution of the master equation in the form @xmath14 , instead of conventional @xmath15 .",
    "the new solution has a number of interesting , peculiar and counter - intuitive properties .",
    "for example , the optimal coordinate is a multi - valued function . to familiarize the reader with the new concepts we extensively use illustrative examples .",
    "we start by deriving the equations for the optimal coordinate by requiring it to be an ideal clock .",
    "* equilibrium optimal coordinate*. to illustrate counter intuitive properties of the optimal coordinate we first consider a more straightforward case of an equilibrium optimal coordinate . consider an * ideal system * where a point performs a random walk along x with constant a diffusion coefficient and zero mean displacement . in this case",
    "the mean square displacement grows with time as @xmath16 .",
    "if one is given snapshots of the position of the point ( trajectory ) @xmath17 , one may estimate the time intervals between the snapshots ( reconstruct the time ) as @xmath18 ^ 2/2d$ ] . since the process is random such estimate fluctuates around the true value . to improve the accuracy",
    "one may consider an ensemble of identical systems .",
    "given an ensemble of trajectories @xmath19 ( @xmath6 ) sampled at the same ( unknown ) time points @xmath20 , the time interval between the snapshots can be reconstructed with arbitrary accuracy as @xmath21 ^ 2\\end{gathered}\\ ] ] for a * real system * where the diffusion coefficient or the potential energy surface depends on the coordinate , @xmath22 does not grow strictly linear with time .",
    "however , for any such system one can find a coordinate @xmath23 ( an optimal coordinate ) , so that the mean square displacement of the coordinate @xmath24 , computed for an equilibrium ensemble of trajectories , grows linearly with time @xcite .",
    "conversely , define the optimal coordinate as such coordinate whose mean square displacement grows linearly with time .",
    "let us introduce some notation @xcite .",
    "consider a markov process with transition matrix @xmath25 , where @xmath26 is the probability of transition from state @xmath27 to @xmath28 after time interval @xmath11 @xmath29 the transition probability matrix for time interval @xmath30 is @xmath31 .",
    "consider a stationary ( steady - state ) ensemble of trajectories @xmath19 ( @xmath6 ) , generated by a markov process ( eq . [ markov ] ) .",
    "we assume that the configuration space of the system is discrete and is represented by a ( possibly infinite ) set of integer numbers , i.e. , indexes .",
    "if the original system s dynamics are defined in a continuous configuration space , we assume that the space has been discretized . thus , each trajectory @xmath19 is just a sequence of such indexes denoting current state .",
    "such a representation is manifestly invariant with respect to the choice of the coordinate system .",
    "if trajectories are sampled with a constant time interval @xmath11 one can determine the transition matrix @xmath32 , which equals the number of transitions from state i to state j. @xmath33 is the number of times state i has been visited , which is proportional to @xmath34 , the stationary ( steady - state ) probability distribution @xmath35 based on @xmath36 and @xmath32 , the transition probability matrix can be estimated as @xmath37 .",
    "let superscript t denote properties associated with the ensemble of time - reversed trajectories , i.e. , trajectories are read in opposite direction , from the end to the start .",
    "these trajectories can be considered as a realization of a markov process with @xmath38 , where @xmath39 and @xmath40 @xcite .",
    "if w is such that for every @xmath27 @xmath41 then @xmath42 we prove by induction .",
    "assume that the statement is valid for n , then @xmath43=\\\\ \\sum_{jk } p_{jk}(\\delta t)p^{st}_k(w_j&-w_k)^2+\\\\ 2\\sum_{ik } p_{ki}(n\\delta t)p^{st}_i(&w_k - w_i)\\sum_jp_{jk}(\\delta t ) ( w_j - w_k)+\\\\\\sum_{ik } p_{ki}(n\\delta",
    "t)p^{st}_i&(w_k - w_i)^2=\\\\ & \\langle\\delta w^2(\\delta t)\\rangle+n\\langle\\delta w^2(\\delta t)\\rangle\\end{aligned}\\ ] ] analogously , from eq .",
    "[ rceq ] it follows that for all @xmath44 @xmath45 i.e. , the optimal coordinate is the same for the dynamics , sampled with a different constant sampling interval .",
    "we prove by induction .",
    "assume that @xmath46 , then @xmath47    the transition matrix for a trajectory sampled with random intervals is the average @xmath48 , where @xmath49 is the probability of having interval of @xmath30 .",
    "averaging eq .",
    "[ npfold ] with @xmath49 one finds that the optimal coordinate can be found from @xmath50 in summary , given a stationary ensemble of trajectories @xmath19 ( @xmath6 ) , sampled at unknown time points @xmath20 , one can determine the averaged transition matrix @xmath51 and thus the optimal coordinate @xmath23 with eq . [ rceqvardt ] . using the optimal",
    "coordinate the time interval between two time points can be reconstructed ( up to a constant factor determined by d ) @xmath52 ^ 2 .",
    "\\label{seqdt}\\end{gathered}\\ ] ] here @xmath53 denotes the value of the optimal coordinate @xmath54 at state @xmath55 , which is attained by trajectory @xmath56 at time instant @xmath57 .",
    "note that given both direct and time - reversed trajectories , eq . [ seqdt ] predicts only increase in time , which is in agreement with equilibrium statistical mechanics , where there is no difference between forward and time - reversed processes .",
    "* the optimal coordinate can have neither a maximum nor a minimum . * the equation for the optimal coordinate ( eq . [ rceq ] ) can be satisfied for every @xmath27 , only if for every @xmath27 there are such @xmath28 that @xmath58 and such @xmath28 that @xmath59 because @xmath60 . for systems with infinite configuration space",
    "this does not seem to be a problem , e.g. , for a random walk on the ( infinite ) line @xmath61 , whereas systems with finite configuration space require special consideration , because they have a finite set of values of @xmath54 and hence have maximum and minimum @xmath54 . consider a random walk on a ring , with probability 1/2 to jump left or right .",
    "the transition matrix is @xmath62 .",
    "consider the optimal coordinate as a function of angle @xmath63 for @xmath64 .",
    "then the equation for the optimal coordinate is @xmath65 , which means that points @xmath54 are placed equidistantly on the ring @xmath66 .",
    "if one starts from @xmath67 and uses the equation to consequently determine @xmath68 from @xmath54 along the ring , then when one completes the loop and returns to the first node one obtains @xmath69 .",
    "after the second loop @xmath70 and so on .",
    "thus , to satisfy eq . [ rceq ] for all @xmath27 , * the optimal coordinate has to be a multi - valued function*. for the ring @xmath71 , for @xmath72 is the phase angle that covers the ring periodically .",
    "the inverse function , the mapping from the optimal coordinate to the states , is periodic .",
    ". [ rceq ] can be rewritten for a single - valued function @xmath54 restricted to any branch , as @xmath73 where @xmath74 denotes the increment in the coordinate between two branches of the multi - valued function . for a random walk on a ring @xmath75 and otherwise @xmath76 .",
    "[ rceqd ] is the conventional system of linear equations on a single valued function , and can be solved by linear algebra methods .",
    "note that , since the equation defines the solution up to a constant @xmath77 , to solve it on a computer , one should supplement it with an equation which fixes the constant , for example , @xmath67 .    similar construction can be made for the dynamics on a segment between two boundary states a and b. using the folding probability ( @xmath78 ) as an optimal coordinate the segment is mapped onto the @xmath79 $ ] segment , so that eq .",
    "[ rceq ] is satisfied for all the points but a and b , which are mapped to @xmath80 and @xmath81 , respectively @xcite . to make the equation valid at points a and b , the @xmath79 $ ] segment and its mirror copy @xmath82 $ ]",
    "are joined together to form a ring , @xmath80 ends are joined together and @xmath81 ends are joined together .",
    "[ pfold0110]a visualizes the construction as a drawing on the surface of a cylinder ; the joint profile wraps the cylinder .",
    "[ rceq ] is satisfied for nodes a and b due to symmetry .",
    "[ pfold0110]b shows a schematic realization of the mirroring construction along an infinite periodic optimal coordinate of the ring .",
    "for such a coordinate eq .",
    "[ dw2 ] is valid for all n. a practical realization of the procedure during an analysis of a reaction coordinate time - series is as follows .",
    "whenever the system reaches either a or b , a new current branch is selected out of the two with equal probability of 0.5 . an alternative way to make eq .",
    "[ dw2 ] valid is to modify the counting scheme by considering the transition paths @xcite , which is not discussed here .",
    "on this we finish the discussion of the equilibrium optimal coordinate and switch to a more powerful method which can be applied to non - equilibrium ensembles of trajectories and can estimate the change of time in both positive and negative directions .",
    "* non - equilibrium optimal coordinate . *",
    "consider * an ideal system * where a point performs random jumps to the right with distance @xmath83 and rate @xmath84 . in this case",
    "the average distance the system transits during time @xmath11 is @xmath85 .",
    "accordingly , the time interval between two snapshots of the trajectory separated by distance @xmath86 can be estimated as @xmath87 . for a realistic system , where the rate and jump distance can vary",
    ", @xmath87 is no longer valid .",
    "again , for any system an optimal coordinate @xmath23 can be constructed so that time intervals can be determined as @xmath88 , where @xmath89 is a constant , with dimension of frequency ; w is dimension - less .    *",
    "left additive eigenvector .",
    "* let @xmath90 and @xmath89 be a solution of @xmath91 or @xmath92 which can be considered as the definition of the left _ additive _ eigenvector @xmath93 where @xmath94 is an _ additive _ eigenvalue . for a system with @xmath44 states eq .",
    "[ wldef2 ] consists of n equations , which together with the equation that fixes the origin of the eigenvector ( e.g. , @xmath95 ) makes it @xmath96 equations for @xmath96 variables . the multiplication by ( the transpose of ) matrix * p * changes the components of the vector @xmath97 in a simple way by adding a constant .",
    "it is easy to see that @xmath98 or @xmath99 for example , for n=2 : @xmath100 if the transition matrix @xmath101 is the average of the transition matrix with random distribution of steps @xmath49 ( a trajectory sampled with random intervals ) , then @xmath90 is also the solution of @xmath102 where @xmath103 is the average sampling interval .",
    "multiplying eqs .",
    "[ wlndt ] and [ wlrandt ] by @xmath36 one obtains @xmath104 and @xmath105 thus , given an ensemble of trajectories @xmath19 ( @xmath6 ) , sampled at unknown time points @xmath20 , one can determine the averaged transition matrix @xmath106 and thus the optimal coordinate @xmath90 with eq . [ wlrandt2 ]",
    "* right additive eigenvector .",
    "* it is useful to define the right _ additive _ eigenvector as a solution of equation @xmath107 or , equivalently @xmath108 and @xmath109 where @xmath110 .",
    "it is easy to see that @xmath111 and @xmath112 note that @xmath113 is not a stochastic matrix , i.e. , @xmath114 , however @xmath115 .",
    "if detailed balance holds , i.e. , @xmath116 then @xmath117 .",
    "given an ensemble of trajectories @xmath19 ( @xmath6 ) , which describes stationary dynamics of the system , one can define the following averages to measure time intervals .",
    "averaging over the entire ensemble of trajectories @xmath118   \\label{ensall}\\ ] ] averaging over the subset of trajectories starting from a particular state at time @xmath119 ( or a subset of states ) @xmath120a_{x_\\alpha(t_1)}}{\\sum_\\alpha a_{x_\\alpha(t_1 ) } } \\label{ensstart}\\ ] ] where a is the indicator function of the subset of states , i.e. , @xmath121 if x is in the chosen subset of states and zero otherwise .",
    "for a single state @xmath27 , @xmath122 , the kronecker symbol .",
    "averaging over the subset of trajectories ending in a particular state at time @xmath123 ( or a subset of states ) @xmath120a_{x_\\alpha(t_2)}}{\\sum_\\alpha a_{x_\\alpha(t_2)}}. \\label{ensend}\\ ] ] eqs .",
    "[ ensstart ] and [ ensend ] reduce to eq .",
    "[ ensall ] for @xmath121 for all x.    multiplying eq . [ wlndt2 ] by @xmath124 and summing over @xmath27 one finds that * the left eigenvector can be used to measure time for trajectories starting from a set of states * @xmath125a_{x_\\alpha(t_1)}}{\\sum_\\alpha a_{x_\\alpha(t_1 ) } } \\label{dtensstart}\\ ] ] multiplying eq .",
    "[ wrndt2 ] by @xmath124 and summing over @xmath27 one finds that * the right eigenvector can be used to measure time for trajectories ending in a set of states * @xmath126a_{x_\\alpha(t_2)}}{\\sum_\\alpha a_{x_\\alpha(t_2 ) } } \\label{dtensend}\\ ] ] for stationary processes , the averaging in eqs .",
    "[ ensall]-[dtensend ] may include averaging over time , e.g. , for eq .",
    "[ dtensstart ] one has @xmath127a_{x_\\alpha(t)}}{\\sum_{\\alpha , t } a_{x_\\alpha(t)}}. \\label{dtensstart2}\\ ] ] * time - reversed trajectories . *",
    "the equation for left eigenvector of time - reversed trajectories is @xmath128 which can be transformed to eq .",
    "[ wrdef ] with negative @xmath11 @xmath129 i.e. , the right eigenvector for forward trajectories can be taken as the left eigenvector for time - reversed trajectories and vice - versa .",
    "* time - dependent reaction coordinate . * by introducing @xmath130 and @xmath131 eqs .",
    "[ wldef2 ] and [ wrdef ] can be written as @xmath132=0 \\notag \\\\ \\sum_{j } n_{ij}[s^r_i(t+\\delta t)-s^r_j(t)]=0 \\label{sdef}\\end{aligned}\\ ] ] these equations can be considered as a generalization of the equation for the @xmath78 reaction coordinate ( eq . [ rceq ] ) to time dependent reaction coordinates @xmath133 and @xmath134 .",
    "for @xmath135 , when the coordinates do not change with time and @xmath136 the single valued solutions equal @xmath137 .",
    "the equations , as well as eq .",
    "[ rceq ] , mean that the average change of the ( time dependent ) optimal coordinates along a trajectory is zero .",
    "so far we have assumed that the optimal coordinate is a function of the state index @xmath27 .",
    "such a description is invariant with respect to the choice of the coordinate system .",
    "as shown in the illustrative examples below , it might be useful to embed the index in spatial coordinates , so that the optimal coordinate becomes a function of position @xmath1 .",
    "for example , in the one - dimensional case , one assigns position @xmath138 to state @xmath27 and assumes that @xmath139 , where @xmath140 has the meaning of the wave number and @xmath141 is the wavelength ; the dimension of @xmath142 is inverse of @xmath143 to keep w dimensionless . in this case",
    "the change of the optimal coordinate can be written in the form where space and time are on an equal footing .",
    "@xmath144    * symmetric or relativistic coordinate . * according to eqs .",
    "[ dtensstart ] and [ dtensend ] one needs to use two different optimal coordinates @xmath134 and @xmath133 ( or two additive eigenvectors ) to describe incoming and outgoing or forward and time - reversed subsets of trajectories",
    ". it might be useful to introduce a single coordinate to describe all the subsets .",
    "the procedure is analogous to the simmetrization of the transition probability matrix @xmath145 in the conventional case , which leads to the left and right eigenvectors being equal .",
    "let @xmath146 be two optimal coordinates that describe a stationary solution .",
    "let @xmath147 , then @xmath148 introduce @xmath149 i.e. , the change of @xmath150 is the geometric mean of the changes of @xmath133 and @xmath134 . then @xmath151 or , if @xmath152 is known , @xmath153 or @xmath154 introducing @xmath155 one obtains @xmath156 or @xmath157 or @xmath158@xmath159 is not an additive eigenvector , meaning that eqs .",
    "[ slrs]-[wsdef3 ] are valid only in the limit of @xmath160 .",
    "they are not valid for an arbitrarily large @xmath11 , as we show later , since the symmetrized matrix is not a stochastic matrix .",
    "however , such a coordinate can be used in the limit of small @xmath11 to measure time for both starting and ending subsets of trajectories as @xmath161a_{x_\\alpha(t_1)}r^{-1}_{x_\\alpha(t_2)}r^{-1}_{x_\\alpha(t_1)}}{\\sum_\\alpha a_{x_\\alpha(t_1)}r^{-1}_{x_\\alpha(t_2)}r^{-1}_{x_\\alpha(t_1)}}/\\nu^s \\label{wsdtensstart}\\ ] ] and @xmath162a_{x_\\alpha(t_2)}r^{-1}_{x_\\alpha(t_2)}r^{-1}_{x_\\alpha(t_1)}}{\\sum_\\alpha a_{x_\\alpha(t_2)}r^{-1}_{x_\\alpha(t_2)}r^{-1}_{x_\\alpha(t_1)}}/\\nu^s   \\label{wsdtensend}\\ ] ] eq .",
    "[ slrs ] can be used to determine @xmath150 and @xmath163 from @xmath133 and @xmath134 .    * equations for the rate matrix . * to derive the equations for the rate matrix we let @xmath164 , where @xmath165 is the rate of going from state @xmath27 to state @xmath28 and @xmath166 . @xmath167",
    "similarly one obtains @xmath168 where @xmath169 . for the symmetric coordinate one obtains @xmath170 which shows that @xmath159 and @xmath171 become independent of @xmath11 in the limit of @xmath160 , where eq .",
    "[ wsdef ] reads @xmath172 or , if @xmath173 is known , @xmath174      to illustrate the introduced concepts , consider the following example . consider a system that moves to the right with rate @xmath175 .",
    "for a small @xmath11 only @xmath176 and @xmath177 are non zero .",
    "for such a system the number of transitions from @xmath27 to @xmath178 is constant : @xmath179 , and @xmath180 , where @xmath181 is flux . for the number of transitions from @xmath27 to @xmath27",
    "one has : @xmath182 for the left eigenvector optimal coordinate one finds ( eq . [ wldef2 ] ) @xmath183 for the right eigenvector optimal coordinate one obtains ( eq . [ wrdef ] ) @xmath184 i.e. , it is different from the left eigenvector . + the same result can be found using eq .",
    "[ wrrate ] .",
    "hence , @xmath186 for the symmetrized ( relativistic ) optimal coordinate one finds using eqs .",
    "[ wsrate ] ( @xmath187 ) @xmath188 or , if one knows @xmath189 , then eq . [ wsrate2 ] can be used to find both @xmath190 and @xmath191 : @xmath192    eq .",
    "[ ex1wl ] defines the optimal coordinate as a function of index @xmath27 .",
    "index @xmath27 can be embedded into a spatial coordinate , i.e. , each state ( @xmath27 ) can be given a position @xmath138 , so that the optimal coordinate is a function of the position .",
    "for example , if @xmath138 are selected as @xmath193 , where @xmath194 is a constant with dimension of velocity , then @xmath195 , @xmath196 , and @xmath197 describes a wave moving to the right with constant velocity of @xmath194 . for the right coordinate one has @xmath198 ,",
    "i.e. , both coordinates can not be simultaneously embedded to keep @xmath194 constant .",
    "* numerical example . * consider a system with @xmath199 .",
    "10000 trajectories have been simulated by monte carlo ( with times step of @xmath200 ) starting from @xmath201 until the system reached @xmath202 .",
    "[ recontime ] shows time reconstructed from the trajectories using left , right and symmetric optimal coordinates for @xmath203 by applying corresponding variants of eq .",
    "[ dtensstart2 ] .",
    "panel * a * shows that time reconstructed for trajectories starting from @xmath204 , agrees with actual time if reconstruction is performed with the left coordinate and disagrees significantly if performed with the right coordinate .",
    "panel * b * shows that time reconstructed for a subset of trajectories ending in @xmath204 is accurate if the right coordinate is used and not if the left one is used .",
    "the relativistic coordinate reconstructs time accurately for both sets of trajectories but only for relatively short time intervals . at longer time intervals",
    "the reconstructed time deviates from the actual one . to accurately reconstruct time for long time intervals using the relativistic coordinate",
    ", the trajectory needs to be divided into short segments , time for which can be accurately reconstructed and then the total time can be found as their sum .",
    "the left and right coordinates reconstruct times accurately for their corresponding sets of trajectories for arbitrary long trajectory segments .",
    "panels * c * and * d * show results for time - reversed trajectories , where the left and right coordinates exchange their function .",
    "from now on we consider only systems with stationary dynamics where detailed balance holds @xmath136 and where , correspondingly , @xmath205 and @xmath206 . for such systems ,",
    "as can be easily seen , straightforward computation of right or left _ additive _ eigenvectors leads to @xmath135 .",
    "for example , by summing up over @xmath27 eqs [ wldef2 ] one obtains @xmath207 thus , solutions with nonzero @xmath89 , necessary for the estimation of time intervals are not possible ( in the space of single valued functions ) .",
    "solutions with @xmath208 become possible , however , if one assumes that @xmath54 is not a single valued function , i.e. , that the next time the system visits the same state @xmath27 , @xmath54 can be different .",
    "one can suggest multiple reasons for that .",
    "for example , if a system moves on a line , it has to move in the reverse direction to return to the same point .",
    "the optimal coordinates that describe the motion in the backward and forward directions should not necessary be the same .",
    "so each time the system changes direction , it may be described by a new coordinate . for systems moving on a ring",
    "the situation is more familiar .",
    "for example , for a random walk on a ring , considered above , the optimal coordinate equals @xmath63 , the angular position ( phase ) on the ring , which covers the ring periodically .",
    "when the system returns to the same point by completing a cycle around the ring , the change in @xmath54 is analogous to the increase in the @xmath63 by @xmath209 .",
    "the classical action function is yet another example .",
    "note that the multivaluedness may lead to the following counter - intuitive property @xmath210 if @xmath54 in different brackets belong to different branches .",
    "it seems that ( to the best of my knowledge ) the theory of such multivalued solutions for left and right additive eigenvectors has not been developed .",
    "i will present below some examples , where particular solutions can be found in a straightforward manner .      while the equations on optimal coordinates are just simple systems of linear equations , they can not be solved with conventional linear algebra methods because the coordinates are multivalued functions .",
    "assume that , for example , based on physical intuition , one knows where the transition between different branches of the multivalued function happens and that the difference between the branches is always the same ( the solution is periodic ) .",
    "for example , if a new branch is reached at transition from @xmath27 to @xmath28 and the value at a new branch is related to the value at an old branch as @xmath211 , then eq .",
    "[ wldef ] and eq .",
    "[ wrdef2 ] can be rewritten for values at one ( old ) branch as @xmath212 where @xmath213 are the differences ( in phase ) between different branches of the multivalued functions .",
    "the values at any branch can be taken since the solution is invariant to constant shift @xmath77 . assume further that any solution with many nonzero @xmath213 can be represented as a linear combination of basis solutions with few or even single nonzero @xmath213 . since the solution is defined up to a factor , for the latter case we can set the non - zero @xmath214 .",
    "for the rate matrix one obtains @xmath215 for relativistic optimal coordinate , for example eq . [ wsrate2 ] one obtains @xmath216    alternatively , one can explicitly introduce multivaluedness by introducing variable @xmath217 that describes the current branch .",
    "the optimal coordinate becomes a function of two variables @xmath218 , where one further assumes @xmath219 .",
    "for such defined optimal coordinates eq .",
    "[ nonzero ] is no longer counter - intuitive @xmath220      consider a system with dynamics described by the following master equation @xmath221 we assume that an optimal coordinate changes branches when the system makes transition @xmath222 .",
    "the coordinate is taken in the form @xmath223 .",
    "for the left additive eigenvector one obtains ( eq . [ wlrate ] ) @xmath224-\\nu / r_1=0\\\\ [ w^l_1 + 1-w^l_2]-\\nu / r_2=0\\\\ \\nu=1/(1/r_1 + 1/r_2)\\\\ w^l_1=0\\\\ w^l_2=\\nu / r_1\\end{gathered}\\ ] ] thus , one has @xmath225 , @xmath226 and @xmath227 because @xmath228 in the second bracket belongs to the next branch . + for stationary ( equilbirum ) populations one has @xmath229 and @xmath230 , and @xmath231 , @xmath232",
    ". for the right additive eigenvector one finds ( eq . [ wrrate ] ) . @xmath233 thus while @xmath89 for both coordinates is the same , @xmath234 . + * explicit symmetrization*. for the symmetric rate matrix one obtains @xmath235 .",
    "@xmath159 can be found as a left or right eigenvector of the symmetric rate matrix @xmath236 * implicit symmetrization*. the equation on the relativistic coordinate eq .",
    "[ wsrate2 ] reads @xmath237 after substitution @xmath238 one finds both @xmath191 and @xmath190 @xmath239    * numerical example .",
    "* 1000 trajectories ( time series of @xmath240 ) each of length @xmath241 were simulated by mc with time steps of @xmath242 and saved with time interval of @xmath243 .",
    "the transition rates are @xmath244 and @xmath245 .",
    "[ rtime_r1r2 ] shows the reconstructed time vs the actual time .",
    "for forward trajectories , starting from a state , time can be reconstructed only by the left coordinate and conversely for forward trajectories ending in a state , time can be reconstructed only by the right coordinate .",
    "the relativistic coordinate can be used to reconstruct time in both cases but only for short time intervals .",
    "consider a particle that jumps in a constant direction , and changes direction with rate @xmath84 .",
    "the model can be considered as a discrete version of the stochastic model of the telegraphers equation @xcite .",
    "we assume that every time the direction is changed the dynamics is described by a new coordinate .",
    "dynamics in the positive direction are described by coordinates @xmath246 , while that in the negative directions are described by coordinates @xmath247 .",
    "thus we have the following set of transitions : + @xmath248 to @xmath249 with probability @xmath250 or to @xmath251 with probability @xmath252 .",
    "@xmath253 to @xmath251 with probability @xmath250 or to @xmath254 with probability @xmath252 . for the left additive eigenvector one has ( eq . [ wldef ] ) @xmath255+\\\\&r \\delta t[w^l_{2l+2,i-1}-w^l_{2l+1,i } -\\nu \\delta t]=0 \\\\     ( 1-r \\delta t)[w^l_{2l+2,i-1}&-w^l_{2l+2,i}-\\nu \\delta",
    "t]+\\\\&r \\delta t[w^l_{2l+3,i+1}-w^l_{2l+2,i } -\\nu \\delta t]=0\\end{aligned}\\ ] ] we assume that the ( basis ) solutions are periodic , i.e. , @xmath256 , in particular , we consider the case where @xmath257 .",
    "let @xmath258 , @xmath259 , i.e. , index @xmath27 is considered to be embedded into coordinate @xmath143 as @xmath260 and @xmath261 .",
    "after substitution one finds @xmath262 -\\nu \\delta t=0\\\\       -(1-r \\delta t){\\mathchar'26\\mkern-9mu k}\\delta",
    "x+r \\delta t [ w_1 + 1-w_2]-\\nu \\delta t=0\\\\       \\nu = r\\end{aligned}\\ ] ] we assume that @xmath263 , where @xmath194 is a constant , so that the limit @xmath264 exists .",
    "we let @xmath265 and find @xmath266 in the limit @xmath267 and , correspondingly , @xmath268 @xmath269 for the right additive eigenvector @xmath270+\\\\&r \\delta t[w^r_{2l+1,i}-w^r_{2l , i-1 } -\\nu \\delta t]=0\\\\       ( 1-r \\delta t)[w^r_{2l+2,i}&-w^r_{2l+2,i+1}-\\nu \\delta",
    "t]+\\\\&r \\delta t[w^r_{2l+2,i}-w^r_{2l+1,i+1 } -\\nu \\delta t]=0\\\\\\end{aligned}\\]]one analogously finds @xmath271 -\\nu",
    "\\delta t=0\\\\       -(1-r \\delta t){\\mathchar'26\\mkern-9mu k}\\delta x+r \\delta t [ w_2 + 1-w_1]-\\nu \\delta t=0\\\\       \\begin{align * } \\nu&=r\\\\ w_1&=0\\\\ w_2&=(1-r \\delta t ) c{\\mathchar'26\\mkern-9mu k}/\\nu\\\\ w^r_{2l+1,i}&=2l+1 + { \\mathchar'26\\mkern-9mu k}i \\delta x \\\\ w^r_{2l+2,i}&=2l+2 + { \\mathchar'26\\mkern-9mu k}(i+1 ) \\delta x    + ( 1-r \\delta t)c{\\mathchar'26\\mkern-9mu k}/\\nu \\\\ w^r_{2l+1,x}&=2l+1 + { \\mathchar'26\\mkern-9mu k}x \\\\ w^r_{2l+2,x}&=2l+2 + { \\mathchar'26\\mkern-9mu k}x + c{\\mathchar'26\\mkern-9mu k}/\\nu , \\end{align*}\\end{gathered}\\ ] ] i.e. , @xmath272 .",
    "note , that equations for the left and right additive eigenvectors allow more complex solutions with quadratic dependence on x , but we do not consider them here .    * the relativistic coordinate . *",
    "since the left and right additive eigenvectors are different , it is useful to find the relativistic coordinate .",
    "note , however , that the situation is slightly different from the one considered before .",
    "here the transition matrix is symmetric and the left and right additive eigenvectors at @xmath273 ( in the rest frame ) are equal .",
    "they differ in a moving frame .",
    "we proceed analogously .",
    "let the left and right optimal coordinates be @xmath274 where @xmath275 .",
    "we introduce the symmetric ( relativistic ) reaction coordinate as @xmath276 such a definition makes the comparison with the conventional relativistic equations of physics more straightforward .",
    "the equation is identical to eq .",
    "[ slrs ] if one makes substitution @xmath277 ( or exchanges @xmath133 and @xmath134 ) .",
    "one obtains @xmath278 or @xmath279 the time intervals can be estimated as ( substitute @xmath277 in eqs .",
    "[ wsdtensstart ] and [ wsdtensend ] )    @xmath162a_{x_\\alpha(t_1)}r_{x_\\alpha(t_2)}r_{x_\\alpha(t_1)}}{\\sum_\\alpha a_{x_\\alpha(t_1)}r_{x_\\alpha(t_2)}r_{x_\\alpha(t_1)}}/\\nu^s   \\label{ws2dtensstart}\\ ] ]    and @xmath162a_{x_\\alpha(t_2)}r_{x_\\alpha(t_2)}r_{x_\\alpha(t_1)}}{\\sum_\\alpha a_{x_\\alpha(t_2)}r_{x_\\alpha(t_2)}r_{x_\\alpha(t_1)}}/\\nu^s   \\label{ws2dtensend}\\ ] ] from eq .",
    "[ ws2def ] @xmath280+\\\\r \\delta t&\\frac{r_{2l+2,i-1}}{r_{2l+1,i}}[w^s_{2l+2,i-1}-w^s_{2l+1,i } -\\nu^s \\delta t]=0\\\\       ( 1-r \\delta t)&\\frac{r_{2l+2,i-1}}{r_{2l+2,i}}[w^s_{2l+2,i-1}-w^s_{2l+2,i } -\\nu^s \\delta t]+\\\\r",
    "\\delta t&\\frac{r_{2l+3,i+1}}{r_{2l+2,i}}[w^s_{2l+3,i+1}-w^s_{2l+2,i } -\\nu^s \\delta t]=0\\\\       ( 1-r \\delta t)&\\frac{r_{2l+1,i-1}}{r_{2l+1,i}}[w^s_{2l+1,i}-w^s_{2l+1,i-1 } -\\nu^s \\delta t]+\\\\r \\delta t&\\frac{r_{2l , i-1}}{r_{2l+1,i}}[w^s_{2l+1,i}-w^s_{2l , i-1 } -\\nu^s \\delta t]=0\\\\ ( 1-r \\delta t)&\\frac{r_{2l+2,i+1}}{r_{2l+2,i}}[w^s_{2l+2,i}-w^s_{2l+2,i+1 } -\\nu^s \\delta t]+\\\\r \\delta t&\\frac{r_{2l+1,i+1}}{r_{2l+2,i}}[w^s_{2l+2,i}-w^s_{2l+1,i+1 } -\\nu^s \\delta t]=0\\end{aligned}\\ ] ] assume that optimal coordinates are periodic for index @xmath217 with period 2 , meaning @xmath281 , @xmath282 . since the system is translation invariant @xmath283 , @xmath284 .",
    "we assume , again , that @xmath285 , @xmath286 and @xmath263 .",
    "after substitution and taking the limit @xmath264 ( the equation for the relativistic coordinate is valid only in this limit ) @xmath287 we dropped superscript s to simplify the notation . by subtracting the third equation from the first , one finds that @xmath288 , which we can set to 0 , since the coordinate is defined up to a constant .",
    "then one finds @xmath289 i.e. , the infinite set of solutions , parametrized by @xmath290 with relativistic relation between @xmath89 and @xmath290 , which is the reason behind naming the coordinate relativistic .",
    "the stochastic dynamics projected on the optimal relativistic coordinate is described by @xmath197 , which describes a plane wave running in ( l , x ) space with the phase velocity along @xmath143 of @xmath291 . to compute the group velocity",
    ", we consider a `` wave packet '' - two solutions with close but different values of @xmath290 @xcite .",
    "let their phases be equal at some point @xmath292 .",
    "the equation for the phase agreement at the new position ( @xmath293 ) at next time instant ( @xmath294 ) is @xmath295 .",
    "hence @xmath296 , or @xmath297 .",
    "thus , one obtains @xmath298 , @xmath299 and @xmath300 , @xmath301 . by introducing @xmath302 , @xmath303 , @xmath304 , where @xmath305 has the meaning of the planck constant",
    ", one obtains the more familiar @xmath306 , @xmath307 , @xmath308 and @xmath309 .    interpreting @xmath147 , where @xmath310",
    "are the stationary probabilities one can compute the mean velocity @xmath311 , which equals the group velocity .",
    "the relativistic coordinate can be found from the left and right additive eigenvectors using eqs .",
    "[ s2lrs ] . from @xmath312 one computes @xmath313 where we used shorthand notation for @xmath314 .",
    "@xmath315 , since @xmath316 and hence @xmath317 , where @xmath318 .",
    "analogously @xmath319 and @xmath320 . for transitions with the reversal of direction @xmath321 the obtained coordinate differs from the relativistic coordinate found before by an overall factor of @xmath322 , as can be seen by , e.g. , computing @xmath323 . by rescaling the coordinate @xmath324 , @xmath325 and",
    "@xmath326 one finds that @xmath327    * numerical example . * 1000 trajectories ( time series of @xmath240 ) each of length @xmath241 were simulated by mc with time steps of @xmath242 and saved with time interval of @xmath243 .",
    "the reversal rate is @xmath328 .",
    "[ rtime_1de ] shows times reconstructed with the optimal coordinates with @xmath329 .",
    "relativistic coordinates with larger values of @xmath290 correctly reconstruct time at shorter time intervals .",
    "[ 1dewavepacket ] shows the dynamics of a wave packet .",
    "an additive eigenvector is modified by matrix multiplication as @xmath330 , where @xmath331 is a vector where all components equals @xmath141 .",
    "an additive eigenvector is a multi - valued function of position , meaning that @xmath28 as a function of @xmath332 is a periodic function similar to @xmath333 .",
    "a conventional eigenvector is modified by matrix multiplication as @xmath334 .",
    "eigenvectors of the master equation are often periodic functions .",
    "all this suggests that there might be a relation between an additive eigenvector and a phase ( or logarithm ) of a conventional eigenvector .",
    "indeed , as we show below , under certain conditions it is possible to establish the correspondence .",
    "it , however , requires a certain modification of the acting operator , and correspondingly the underlying dynamics .",
    "the correspondence is similar to that between the classical action function and the wave function in quantum mechanics .",
    "let @xmath335 , @xmath336 be the solutions of equations @xmath337 where @xmath338 , or the corresponding continuous time equations . if @xmath339 , where @xmath340 is the corresponding eigenvalue , then @xmath341 assume that @xmath342 are always close to 0 or some other integer number , i.e. , @xmath343 , where @xmath74 is an integer , then one can expand the exponent and obtain eq .",
    "[ wldefdij ] .",
    "\\sum_j p_{ji}(\\delta t ) ( s^l_j(t+\\delta t)-s^l_i(t ) + d_{ji})\\\\ \\sum_j p_{ji}(\\delta t ) ( w^l_j - w^l_i+d_{ji}-\\nu \\delta t ) \\approx 0\\end{aligned}\\ ] ]    for the right eigenvector @xmath345 one obtains eq .",
    "[ wrdefdij ] @xmath346    numerical analysis of the eigenvectors and eigenvalues of the system from illustrative example 1 , shows that the relation is accurate for small eigenvalues and becomes inaccurate for large eigenvalues . to investigate the reason we consider the case @xmath347 analytically .",
    "@xmath348 the equation reduces to @xmath349 only in the limit of @xmath350 or @xmath351 .",
    "one way to make it work for finite @xmath89 is to make the transition from @xmath352 to @xmath28 gradual by introducing intermediate states @xmath353 , where @xmath354 , so that corresponding @xmath355 for @xmath356 , while @xmath332 and @xmath89 stay the same .",
    "let the time interval @xmath11 be further divided into @xmath44 sub - intervals .",
    "instead of making a single jump from @xmath352 to @xmath28 with rate @xmath84 during @xmath11 , the system makes n jumps from @xmath357 to @xmath353 with ( yet unknown ) rate @xmath83 each during @xmath358 .",
    "the equations for the additive eigenvector are @xmath359 summing the equations for @xmath354 one finds that @xmath360 .",
    "the master equation is @xmath361 for @xmath354 .",
    "let @xmath362 , then in the limit @xmath356 one can approximate the finite differences by derivatives and obtain : @xmath363 where @xmath364 .",
    "the eigenfunction of the equation is @xmath365 .",
    "thus , we have found the equation with ( multiplicative ) eigenfunction and eigenvalue , which correspond exactly to _ additive _ eigenvector and eigenvalue .",
    "however , in order to do that it was necessary to modify the underlying dynamics of the system .",
    "first , the dynamics is nor longer stochastic .",
    "the differential operator describes a deterministic running wave .",
    "second , the configuration space of the system has been extended . instead of being integer @xmath366 it became real @xmath367 .",
    "it seems reasonable to name operators such as in eq .",
    "[ vop1 ] virtual operators , since they describe virtual dynamics , not the actual dynamics of the system and are just a mathematical tool to obtain ( multiplicative ) eigenfunction and eigenvalue , which correspond exactly to _ additive _ ones .    for the relativistic coordinate the correspondence is established analogously .",
    "let @xmath368 be such that the solutions of eqs .",
    "[ kolmeq ] can be expressed as @xmath369 then @xmath370,\\end{gathered}\\ ] ] where imaginary part equals @xmath371 for the left eigenvector one obtains @xmath372 the two equations are the multi - valued rate matrix versions of eq .",
    "[ ws2def ] .",
    "consider system with dynamics described by the following master equation @xmath373 where @xmath374 and @xmath375 are the probabilities to be in state 1 and 2 , respectively , which is equivalent to the system considered in illustrate example 2 if one sets @xmath376 .",
    "for this system , the left , right and relativistic coordinates are the same @xmath377 , @xmath378 and @xmath379 .",
    "the equation has two eigenvalues @xmath380 and @xmath381 , which correspond to ( @xmath382 ) @xmath135 and @xmath383 .",
    "the eigenvector of the second eigenvalue is @xmath384 and @xmath385 , in agreement with the additive eigenvectors .",
    "the second eigenvalue is not in correspondence because @xmath386 is not small and the exponent can not be expanded just to linear terms .",
    "since after two steps the systems returns to itself , each step corresponds to rotation on @xmath387 radians . to make the linear exponent expansion accurate , for the correspondence to be valid",
    ", each step should be made infinitesimally small .",
    "analogous to the above , one way to do this , is to make the rotation gradual , i.e. , instead of rotation on @xmath387 radians with rate @xmath84 , make @xmath44 rotations on @xmath388 radians with rate @xmath389 where @xmath356 .",
    "let time interval @xmath11 be further divided into @xmath44 sub - intervals and let @xmath390 represent the intermediate values , representing rotation by angle of @xmath388 .",
    "the equation for the additive eigenvector are @xmath391 for @xmath392 .",
    "master equation is @xmath393 if @xmath44 is large , one can expand the finite - difference equation and obtain @xmath394 where @xmath395 is the rotation angle .",
    "the equation has eigenfunction @xmath396 with eigenvalue @xmath397 corresponding to @xmath379 .",
    "the eigenfunction at points @xmath398 and @xmath399 corresponds to @xmath400 and @xmath401 .",
    "thus , in order to obtain the correct correspondence between the additive and multiplicative eigenvector and eigenvalue the stochastic process had to be modified .",
    "the new process consists of infinitesimal jumps instead of finite jumps and it describes deterministic rotation instead of the original stochastic dynamics .",
    "the new process suggests that the system can have any @xmath63 , while in the original process only @xmath398 and @xmath402 are possible .    in the previous construction",
    "many intermediate @xmath390 were introduced to explicitly represent the rotation by a small angle of @xmath388 .",
    "the rotation can be also represented by a rotation matrix in some ( @xmath403 , @xmath404 ) basis . as @xmath403 and",
    "@xmath404 one can take unit vectors associated with @xmath374 and @xmath405 .",
    "@xmath375 corresponds to @xmath406 and can not be taken as basis vector because a rotation can not be represented as a linear sum of @xmath403 and @xmath406 .",
    "each @xmath407 is a linear combination of the basis vectors with coefficients @xmath408 .",
    "since @xmath143 and @xmath409 are coordinates and not probabilities , they can be negative .",
    "when the system makes transition from @xmath410 to @xmath390 , @xmath408 coordinates are changed by the rotation matrix @xmath411 so the master equation is    @xmath412    the rotation matrix for angle @xmath413 is taken to express @xmath410 from @xmath390 .",
    "expanding the equation one obtains @xmath414 the equation is similar to the one - dimensional relativistic dirac equation for an electron in its rest frame .",
    "however , the original system operates only with @xmath374 and @xmath375 ; @xmath405 can not be observed . to alleviate this , the original cycle ( @xmath415 )",
    "can be extended to cycle @xmath416 , where state 3 is identical to 1 and 4 to 2 .",
    "the additive eigenvalue and eigenvector are @xmath417 , and @xmath377 , @xmath418 , @xmath419 and @xmath420 . in this system @xmath421 and @xmath422",
    "are associated with @xmath374 and @xmath375 , and the virtual operator is ( the rotation rate now is @xmath423 ) @xmath424 the eigenvalue @xmath425 corresponds to the additive eigenvalue of @xmath417 , and eigenfunction is @xmath426 , @xmath427 , @xmath428 and @xmath429 , which is in correspondence with the additive eigenvector .",
    "the dynamics described by the stochastic telegraphers equations is the superposition of constant motion to the left or to the right and change with rate @xmath84 between the two motions ( directions ) .",
    "hence the virtual operator for this equation is the superposition of eqs .",
    "[ vop1 ] and [ vop2 ] @xmath430 which is equivalent to the one dimensional dirac equation , if one denotes @xmath431 as @xmath432 or @xmath433 .",
    "the eigenvector of the virtual operator @xmath434 where @xmath435 is in agreement with the optimal coordinate ( eq . [ rel1 ] ) .",
    "the factor of 4 , compare to the solution given by eq .",
    "[ rel1 ] , is due to different normalization of optimal coordinates @xmath436 vs @xmath437 .",
    "note that two reversals of the direction @xmath438 ( which result in the original direction ) lead to the change of sign @xmath439 .",
    "it requires four reversals of the direction to return to the original sign , analogous to the transformation of a spinor under @xmath209 or @xmath440 rotation .",
    "thus , the change of direction during a random walk can be transformed to the virtual continuous operator representing rotation ( in internal space ) .",
    "every equilibrium stochastic dynamics , by definition , contains movements in opposite directions , meaning that virtual operators representing rotations are ubiquitous .",
    "the strategy of finding the virtual operator can be summarized as follows .",
    "the correspondence holds if @xmath441 is such that @xmath442 and @xmath89 is real .",
    "if it is not the case , then the configuration space is expanded with intermediate states ( denoted by fractional index @xmath443 ) on which virtual dynamics described by a virtual operator @xmath444 is introduced , such that @xmath445 with @xmath356 , while @xmath446 and @xmath89 do not change .",
    "for such an operator the correspondence between the additive and multiplicative eigenvectors and eigenvalues is exact .",
    "hence , the correspondence is exact between the additive eigenvectors and eigenvalues of the original @xmath447 and the conventional eigenvectors and eigenvalues of the virtual operator @xmath448 on the original configuration space ( integer index ) .",
    "let the reversal rate now be a function of the position ( @xmath449 ) , corresponding to a random walk in a potential .",
    "@xmath450+\\\\r_i \\delta t\\frac{r_{2l+2,i-1}}{r_{2l+1,i}}&[w^s_{2l+2,i-1}-w^s_{2l+1,i } -\\nu^s \\delta t]=0\\\\       ( 1-r_i \\delta t)\\frac{r_{2l+2,i-1}}{r_{2l+2,i}}&[w^s_{2l+2,i-1}-w^s_{2l+2,i } -\\nu^s \\delta t]+\\\\r_i \\delta t\\frac{r_{2l+3,i+1}}{r_{2l+2,i}}&[w^s_{2l+3,i+1}-w^s_{2l+2,i } -\\nu^s \\delta t]=0\\\\       ( 1-r_i \\delta t)\\frac{r_{2l+1,i-1}}{r_{2l+1,i}}&[w^s_{2l+1,i}-w^s_{2l+1,i-1 } -\\nu^s \\delta t]+\\\\r_i \\delta t\\frac{r_{2l , i-1}}{r_{2l+1,i}}&[w^s_{2l+1,i}-w^s_{2l , i-1 } -\\nu^s \\delta t]=0\\\\ ( 1-r_i \\delta t)\\frac{r_{2l+2,i+1}}{r_{2l+2,i}}&[w^s_{2l+2,i}-w^s_{2l+2,i+1 } -\\nu^s \\delta t]+\\\\r_i \\delta t\\frac{r_{2l+1,i+1}}{r_{2l+2,i}}&[w^s_{2l+2,i}-w^s_{2l+1,i+1 } -\\nu^s \\delta t]=0\\end{aligned}\\ ] ] let @xmath281 , @xmath282 , @xmath451 , @xmath452 and @xmath453 .",
    "assume that @xmath449 changes slowly with @xmath27 ( fine discretization ) , meaning @xmath454 and @xmath455 , then one arrives at ( we dropped superscript s ) @xmath456 -\\nu=0\\\\       -{\\mathchar'26\\mkern-9mu k}_ic+r_i\\frac{r_{1,i+1}}{r_{2,i}}[w_{2l+3,i+1}-w_{2l+2,i } ] -\\nu=0\\\\       { \\mathchar'26\\mkern-9mu k}_ic+r_i\\frac{r_{2,i-1}}{r_{1,i}}[w_{2l+1,i}-w_{2l , i-1 } ] -\\nu=0\\\\ -{\\mathchar'26\\mkern-9mu k}_ic+r_i\\frac{r_{1,i+1}}{r_{2,i}}[w_{2l+2,i}-w_{2l+1,i+1 } ] -\\nu=0\\end{aligned}\\ ] ] @xmath457 since @xmath458 changes slowly with @xmath27 one can use continuous representation , where @xmath459 and the last equation becomes @xmath460 or for @xmath461 @xmath462 the ( dimensionless ) relativistic hamilton - jacobi equation with mass that is a function of coordinate .",
    "in the derivation it was , again , assumed that @xmath463 , which can be considered as the property of the stochastic model .",
    "if one , however , assumes that the stochastic model is a microscopic model of ( one - dimensional ) general relativity , then the speed of light is the universal constant only in local inertial frames of reference . for small velocities , i.e. , small potential @xmath464 , where @xmath465 , the relativistic effects are negligible . in this case",
    "@xmath466 , where @xmath467 , and one obtains for @xmath468 @xmath469 the classical ( dimensionless ) hamilton - jacobi equation .",
    "the dimensionality can be restored by multiplying @xmath23 and @xmath470 by @xmath305 and replacing @xmath471 , @xmath472 , @xmath473 .",
    "consider a random walk on the line , where a system jumps to the nearby left or right state with rate r. coordinate @xmath474 describes movement to the right or when the system stays in the same state , and @xmath475 describes movement to the left or when the system stays in the same state . in other words the optimal coordinate changes together with the direction .",
    "equations on the relativistic coordinate are ( superscript s is omitted )    @xmath476+(1 - 2r \\delta t)\\times \\\\ [ - \\nu \\delta t]+r\\delta & t\\frac{r_{2l+2,i-1}}{r_{2l+1,i}}[w_{2l+2,i-1}-w_{2l+1,i}-\\nu \\delta t ] = 0\\\\       r\\delta t\\frac{r_{2l , i-1}}{r_{2l , i}}&[w_{2l , i-1}-w_{2l , i}-\\nu \\delta t]+(1 - 2r \\delta t)\\times \\\\ [ -\\nu \\delta t]+r\\delta & t\\frac{r_{2l+1,i+1}}{r_{2l , i}}[w_{2l+1,i+1}-w_{2l , i}-\\nu \\delta t ] = 0\\\\       r\\delta t\\frac{r_{2l+1,i-1}}{r_{2l+1,i}}&[w_{2l+1,i}-w_{2l+1,i-1}-\\nu \\delta t]+(1 - 2r \\delta t)\\times \\\\ [ -\\nu \\delta t]+r\\delta & t\\frac{r_{2l , i-1}}{r_{2l+1,i}}[w_{2l+1,i}-w_{2l , i-1}-\\nu \\delta t ] = 0\\\\ r\\delta t\\frac{r_{2l+2,i+1}}{r_{2l+2,i}}&[w_{2l+2,i}-w_{2l+2,i+1}-\\nu \\delta t]+(1 - 2r \\delta t)\\times\\\\ [ -\\nu \\delta t]+r\\delta & t\\frac{r_{2l+1,i+1}}{r_{2l+2,i}}[w_{2l+2,i}-w_{2l+1,i+1}-\\nu \\delta t ]   = 0\\end{aligned}\\ ] ]    analogous with the above we assume @xmath477 , @xmath478 and @xmath479 and @xmath480 .",
    "@xmath481 -\\nu=0\\\\",
    "-r{\\mathchar'26\\mkern-9mu k}\\delta x + rr_1/r_2[w_1 + 1-w_2 ] -\\nu=0\\\\       r{\\mathchar'26\\mkern-9mu k}\\delta x + rr_2/r_1[w_1 + 1-w_2 ] -\\nu=0\\\\ -r{\\mathchar'26\\mkern-9mu k}\\delta x + rr_1/r_2[w_2 + 1-w_1]-\\nu=0\\end{aligned}\\ ] ] solving , one finds @xmath482 , i.e. , the relativistic spectrum of a particle with mass 1 , where @xmath84 and @xmath86 define the temporal and spatial scales . or , analogous to the above , @xmath483 if one denotes @xmath484 .",
    "thus , the obtained results are not a peculiarity of the telegraphers model .",
    "the problem of determining an optimal coordinate that describes dynamics in general has been considered .",
    "it has been shown that the problem is closely related to the problem of reconstructing time from a trajectory and the problem of defining the eigen - modes for stochastic dynamics .",
    "they are solved by introducing _",
    "additive _ eigenvectors .",
    "the eigenvectors are modified under the action of a stochastic matrix in a simple way @xmath485 .",
    "such left and right additive eigenvectors can be used to reconstruct time from ensembles of trajectories starting or ending in a set of states , respectively .",
    "the symmetric or relativistic coordinate can be introduced .",
    "it allows one to reconstruct time for both ensembles of trajectories , but only for relatively small time intervals . for the dynamics with detailed balance the additive eigenvectors are multi - valued functions .",
    "it was shown that it is possible to establish a correspondence between an additive eigenvector and an eigenvalue and a conventional eigenvector and an eigenvalue of a virtual operator .",
    "the virtual operator , however , describes different dynamics in an extended configuration space . in particular",
    ", the virtual operator for a random walk on the line corresponds to the one - dimensional dirac equation .",
    "the close relation between the equations describing stochastic dynamics and that of quantum mechanics is well known @xcite . in particular , analytical continuation , e.g. , @xmath486 , is a straightforward way to obtain the schrdinger equation from the diffusion equation or the one - dimensional dirac equation from the telegraphers equation @xcite .",
    "the presented results differ in the following .",
    "first , no analytic continuation is performed .",
    "second , the resulting dirac equation is a virtual operator , i.e. , it does not describe the actual dynamics , it is just a mathematical tool to match the eigenvectors and eigenvalues .",
    "third , the results are valid for generic one - dimensional random walks , no specific stochastic process is selected .",
    "interestingly , the @xmath217 coordinate that explicitly keeps track of the branches of the multi - valued functions ( or rather its continuous analog ) seems analogous to the action coordinate in the 5 optics of rumer @xcite . in the 5 optics",
    "all physical quantities are periodic along the action coordinate and its period equals the planck constant ( or 1 in dimensionless units ) .",
    "equations with detailed balance have no additive eigenvectors with @xmath208 in the space of single valued functions .",
    "in order to obtain solutions with @xmath208 we postulate that additive eigenvectors are multi - valued functions , i.e. , we have enlarged the configuration space of the solutions . in particular , by introducing an additional variable which explicitly describes the branches of the multi - valued function .",
    "the whole construction may seem artificial at first .",
    "however , it could be viewed as being analogous to the introduction of complex numbers .",
    "complex numbers have real and imaginary parts and are necessary to describe all the solutions of a polynomial equation just with real coefficients . as illustrated above , @xmath54 and @xmath190 can be considered as the polar representation of a complex number .",
    "the purpose of an optimal coordinate being multi - valued and the difference from the conventional description can be illustrated as follows .",
    "consider a system that stochastically transits between two states 1 and 2 ( illustrative example 2 ) .",
    "let an ensemble of such systems be initially in state 1 .",
    "with time some systems will transit to state 2 and then some of them will return to state 1 .",
    "state 1 now contains two sets of systems : the systems which came back there from state 2 and the systems which never left state 1 .",
    "the future dynamics of the two sets are described by the same set of equations and , conventionally , one considers them identical and count them together .",
    "however after such mixing , the information about the past dynamics ( which was different ) is lost , one can not reconstruct dynamics back in time . the multi - valuedness ( of an optimal coordinate )",
    "is used to distinguish the two sets .",
    "the systems which came back from state 2 now belong to a different branch and thus the two sets can be distinguished .",
    "the branches of the optimal coordinate can be straightforwardly computed from the system trajectory if it is known with sufficiently fine temporal resolution .",
    "that is how it was done in the numerical examples and how it can be done in a real - life experiment . if an experimental system does not allow the observation of a trajectory with sufficient temporal resolution , then , in principle , one may attempt to infer the branches from auxiliary variables .",
    "for example , the dynamics of a molecular motor or an enzyme might be described by an optimal coordinate with ring topology .",
    "the auxiliary variables for such systems could be the position of the motor along a track or the number of atp / substrate / product molecules .",
    "the transition to the next branch of an optimal coordinate when a system returns to a state visited before can be compared to the phenomenon of the geometric phase , i.e. , the increment of the phase acquired when a quantum mechanical @xcite or stochastic system @xcite is undergoing adiabatic cyclic evolution in parameter space . in the case of stochastic systems",
    "one considers the dynamics to be described by the master equation with detailed balance .",
    "the equilibrium net flux between any two states is therefore zero .",
    "if the parameters ( rates ) of the master equation are changing in a periodic manner ( while detailed balance is still satisfied at any time moment ) a system may exhibit a nonzero net flux .",
    "if the change is adiabatic ( slow ) , then the net flux does not depend on the speed with which the parameters are changed and determined only by the trajectory in parameter space .",
    "while the analogy is clear , there are the following differences . in order to have a non - zero additive eigenvalue we postulate that the phase increment may happen whenever the system returns to a previously visited state .",
    "the parameters are kept constant .",
    "an optimal coordinate is a multi - valued function _",
    "per se _ , not due to a periodic evolution of parameters .",
    "the geometric phase and the net flux are completely determined by the trajectory in the parameter space .",
    "the equations for the optimal coordinate are more flexible , they just specify that the optimal coordinate is a multi - valued function , without specifying the exact details ; any solution with non - zero @xmath89 can be used .",
    "the solutions presented in the illustrative examples represent a subset of all possible solutions for very simple systems .",
    "for example , the equation for the optimal coordinate for a random walk on the line allows other solutions , e.g. , solutions with longer periodicity @xmath487 for @xmath488 , which were not considered . to fully appreciate the properties of the derived equations , it is necessary to fully develop the mathematical formalism similar to the conventional eigenvector decomposition , which would allow one to obtain all the solutions of the equations and to answer the following general questions as the completeness and properties of the basis of additive eigenvectors , the definition of orthogonality or a scalar product .",
    "the correspondence between the additive and multiplicative eigenvectors could be useful as a guiding principle .",
    "two other generic questions for the method are obvious .",
    "what are the microscopic models for other relativistic equations of physics and which virtual operators correspond to various stochastic master equations ?",
    "it seems that while the solutions using relativistic or symmetric optimal coordinate are closer to the conventional physical picture , the solutions using left and right eigenvectors are more flexible .",
    "consider for example a random walk in many dimensions . to describe it",
    "one can partition the configuration space and compute a transition matrix .",
    "one can expect that while at very short time intervals the description by the transition matrix may deviate from the actual dynamics , it will closely approximate it at longer time intervals , when the fine - grained structure of the partitioning can be neglected .",
    "the partitioning can be done in many ways , provided that it is sufficiently fine - grained . thus if one can use sufficiently long time",
    "intervals the description of dynamics should be independent of the chosen partition . in particular , if a system performs a random walk along the edges of a cubic lattice , one should be able to accurately describe the dynamics by using any other lattice , i.e. , at longer time intervals the space becomes isotropic .",
    "the description with the relativistic coordinate , however , is exact only in the limit of @xmath160 , when the original anisotropy of space partitioning is evident .",
    "the fact that we were able to derive model relativistic equations can be explained as follows .",
    "the description of dynamics using markov state models with the master equations is manifestly invariant with respect to the choice of spatial coordinates , since the states are defined only by an index .",
    "the new method allows one to reconstruct time , meaning now the temporal coordinate can also be represented just by an index and the description becomes invariant with respect to the choice of spatial - temporal coordinates .",
    "such a description can be used to describe dynamics of an arbitrary system using an arbitrary moving frame of reference in an invariant way . by observing a systems trajectory",
    ", one can reconstruct time . having the trajectory as a function of time one can reconstruct the transition probability ( or rate ) matrix and",
    "thus obtain the complete description of the system dynamics .",
    "alternatively , the dynamics can be described by an optimal coordinate , which can be determined directly from the averaged matrix ( eqs .",
    "[ wlrandt ] or [ wlrandt2 ] ) . to predict a future state of the system as a function of time",
    ", one can use an auxiliary system as a clock .",
    "note that the equivalent description which uses two coordinates - the left and right additive eigenvectors , does not exhibit any explicit relativistic effects , in particular , @xmath89 is independent of @xmath290 .      * in conclusion , * we have suggested a general method for the description of stochastic dynamics .",
    "the dynamics is described by using optimal coordinates or _ additive _ eigenvectors .",
    "while , the mathematical formalism is not yet developed to completely characterize the solution space , we believe that we have demonstrated the self - consistency of the method and its potential ."
  ],
  "abstract_text": [
    "<S> a general method to describe stochastic dynamics of markov processes is suggested . </S>",
    "<S> the method aims to solve three related problems . </S>",
    "<S> the determination of an optimal coordinate for the description of stochastic dynamics . </S>",
    "<S> the reconstruction of time from an ensemble of stochastic trajectories . </S>",
    "<S> the decomposition of stationary stochastic dynamics on eigen - modes which do not decay exponentially with time . </S>",
    "<S> the problems are solved by introducing additive eigenvectors which are transformed by a stochastic matrix in a simple way - every component is translated on a constant distance . </S>",
    "<S> such solutions have peculiar properties . for example , an optimal coordinate for stochastic dynamics with detailed balance is a multi - valued function . </S>",
    "<S> an optimal coordinate for a random walk on the line corresponds to the conventional eigenvector of the one dimensional dirac equation . the equation for the optimal coordinate in a slow varying potential reduces to the hamilton - jacobi equation for the action function . </S>"
  ]
}