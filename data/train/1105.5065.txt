{
  "article_text": [
    "let @xmath0 be independent random variables collected along observation points @xmath1 according to the model @xmath2 where the @xmath3 s are i.i.d .",
    "symmetric random variables with distribution @xmath4 . in _",
    "isotonic regression _ the trend term @xmath5 is monotone non - decreasing , i.e. , @xmath6 , but it is otherwise arbitrary . in this set - up ,",
    "the classical estimator of @xmath5 is the function @xmath7 which minimizes the @xmath8 distance between the vector of observed and fitted responses , i.e , it minimizes , @xmath9^{2 } \\label{eqn : l2}\\ ] ] in the class @xmath10 of non - decreasing piecewise continuous functions .",
    "it is trivial but noteworthy that equation ( [ eqn : l2 ] ) posits a finite dimensional convex constrained optimization problem .",
    "its solution was first proposed by brunk ( 1958 ) and has received extensive attention in the statistical literature ( see e.g. , robertson , wright and dyskra ( 1988 ) for a comprehensive account ) .",
    "it is also worth noting that any piecewise continuous non - decreasing function which agrees with the optimizer of ( [ eqn : l2 ] ) at the @xmath11 s will be a solution .",
    "for that reason , in order to achieve uniqueness , it is traditional to restrict further the class @xmath12 to the subset of piecewise constant non - decreasing functions .",
    "another valid choice consists in the interpolation at the knots with non - decreasing cubic splines or any other piecewise continuous monotone function , e.g. , meyer ( 1996 ) .",
    "we will call this estimator the _ _ l__@xmath13 _ isotonic estimator_.     the sensitivity of this estimator to extreme observations ( outliers ) was noted by wang and huang ( 2002 ) , who propose minimizing instead using the @xmath14 norm , i.e. , minimizing@xmath15 this estimator will be call here _ _",
    "isotonic estimator_. wang and huang ( 2002 ) developed the asymptotic distribution of the trend estimator at a given observation point @xmath17 and obtained the asymptotic relative efficiency of this estimator compared with the classical l@xmath18estimator .",
    "interestingly , this efficiency turned out to be @xmath19 , the same as in the i.i.d .  location problem .    in this paper we will propose instead a robust  _ isotonic m - estimator _ aimed at balancing robustness with efficiency .",
    "specifically we shall seek the minimizer of @xmath20 where @xmath21 is a an estimator of the error scale previously obtained and @xmath22  satisfies the following properties    a1 : :    \\(i ) @xmath23 is non - decreasing in @xmath24 ,    ( ii ) @xmath25 , ( iii ) @xmath22 is even , ( iv )    @xmath23 is strictly increasing for @xmath26 and    ( v ) @xmath22 has two continuous derivatives and    @xmath27 is bounded and monotone    non - decreasing .",
    "clearly , the @xmath8 choice corresponds to taking @xmath28 while the @xmath14 option is akin to opting for @xmath29 .",
    "these two estimators do no require the scale estimator @xmath30    note that the class of m - estimators satisfying a1 does not include estimators with a redescending choice for * @xmath31*. we believe that the strict differentiability conditions on @xmath22  required in a1 are not strictly necessary , but they make the proofs for the asymptotic theory simpler .",
    "moreover , some functions @xmath22 which are not twice differentiable everywhere * such * as @xmath24 or the huber**s * * functions defined below in ( [ hubfam ] ) can be approximated by functions satisfying a1 .",
    "the asymptotic distribution of the l@xmath18 isotonic estimators at a given point was found by brunk ( 1970 ) and wright ( 1981 ) and the one of the l@xmath16 estimator by wang ( 2002 ) .",
    "they prove that the distribution of these estimators conveniently normalized converge to the distribution of the slope at zero of the greatest convex minorant of the two - sided brownian motion with parabolic drift . in this paper",
    ", we prove a similar result for isotonic m - estimators .",
    "the focus of this paper is on estimation of the trend term at a single observation point @xmath17 .",
    "we do not address the issue of distribution of the whole stochastic process @xmath32 .",
    "recent research along those lines are given by kulikova and lopuha ( 2006 ) and a related result with smoothing was also obtained simultaneously in pal and woodroofe ( 2006 ) .",
    "this article is structured as follows . in section [ sec : rire ] we propose the robust isotonic m - estimator . in section",
    "[ sec : ad ] we obtain the limiting distribution of the isotonic m - estimator when the error scale is known . in section [ scaleeq ]",
    "we prove that  under general conditions the m - estimators with estimated scale have the same  asymptotic distribution than when the scale is known . in section",
    "[ sec : if ] we define an influence function which measures the sensitivity of the isotonic m - estimator to an infinitesimal amount of pointwise contamination . in section [ sec",
    ": bp ] we calculate the breakdown point  of the isotonic m - estimators . in section [ simul ]",
    "we compare by monte carlo simulations the finite sample variances of the estimators for two error distributions : normal and student with three degrees of freedom . in section [ sec",
    ": gw ] we analyze two real dataset using the l@xmath18 and the isotonic m - estimators .",
    "section [ appendix ]  is an appendix containing the proofs .",
    "in similarity with the classical setup , we consider isotonic m - estimators that minimize the objective function ( [ eqn : mrepres ] ) within the class @xmath12 of piecewise constant non - decreasing functions . as in the l@xmath18 and l@xmath16 cases ,",
    "the isotonic m - estimator is a step function with knots at ( some of ) the @xmath11 s . in robertson and waltman ( 1968 )",
    "it is shown that maximum - likelihood - type estimation under isotonic restrictions can be calculated via _ min - max _ formulae .",
    "assume first that we know that the scale parameter ( e.g. ,  the mad , of the @xmath33s ) is @xmath34 .",
    "since we  are considering m - estimators with @xmath31 non - decreasing ( see a1 ) , they can be view as the maximum likelihood estimators corresponding to errors with density @xmath35   } \\ ] ] then we can compute  the isotonic m - estimator at a point @xmath36 using the min - max calculation formulae @xmath37 where @xmath38 is the unrestricted m - estimator which minimizes @xmath39 where @xmath40 . alternatively ,",
    "if @xmath22 is convex and differentiable , as we are assuming , the terms @xmath38 in ( [ eqn : minmax ] ) can be represented uniquely as a zero of @xmath41 in particular , when @xmath42 where @xmath7 is a probability density , the isotonic m - estimator coincides with the maximum likelihood estimator when is @xmath43 is assumed to have density @xmath7 . in particular",
    "if @xmath7 is the n@xmath44 density , the mle is the m - estimator which defined by @xmath45 and therefore it coincides with the classical @xmath8 estimator .",
    "when @xmath7 is the density of a double exponential distribution , the mle is the m - estimator defined  by @xmath46 and therefore it coincides with the l@xmath16 isotonic estimator . in these two cases the estimators are independent of the value of @xmath47",
    "one popular family of @xmath31 functions to define m - estimators is the huber family@xmath48    clearly , when @xmath34 is replaced by @xmath49 equations ( [ eqn : minmax])-([eqn : partialsums ] ) still holds with @xmath34 replaced by @xmath30 since @xmath31 is non - decreasing , the function @xmath50 defined in equation ( [ eqn : partialsums ] ) is non - increasing as a function of @xmath51 .",
    "this entails the fundamental identities given below @xmath52  these identities will be very useful in the development of the asymptotic distribution .",
    "in this section we derive the asymptotic distribution of the isotonic m - estimator @xmath53 of @xmath54 we first make the sample size @xmath55 explicit in the formulation of the model by postulating @xmath56 where the errors @xmath57 form a triangular array of i.i.d .",
    "random variables with distribution @xmath4 and @xmath58 is a triangular array of observation points .",
    "their exact location is described by the function @xmath59 .",
    "the values @xmath60 may be fixed or random but we will assume that there exists a continuous distribution function @xmath61  which has as support a finite closed interval such that@xmath62  without loss of generality we shall assume in the sequel it is the interval @xmath63 $ ] .",
    "we will study the asymptotic distribution of @xmath53 where @xmath17 is an interior point of @xmath63.$ ] the classical l@xmath18 isotonic estimator @xmath64 with @xmath17 at the boundary of the support of @xmath65 is known to suffer from the so - called _ spiking problem _",
    "( e.g. , sun and woodroofe , 1999 ) , i.e. , @xmath53 is not even consistent .",
    "we further make the following assumptions .",
    "a2 : :    the function @xmath61 is continuously differentiable in a    neighborhood of @xmath17 with    @xmath66 .",
    "a3 : :    for a fixed @xmath17 , we assume the function    @xmath5 has two continuous derivatives in a neighborhood    of @xmath17 , and @xmath67 .",
    "a4 : :    the error distribution @xmath4 has a density @xmath7    symmetric and continuous with @xmath68 .    we consider first the case where @xmath34 is known .",
    "our first aim is to show that isotonic m - estimation is asymptotically a local problem .",
    "specifically , we will see in lemma [ lemma : rao1 ]  that @xmath53 depends only on those @xmath69 corresponding to observation points @xmath11 lying in a neighborhood of order @xmath70 about @xmath17 .",
    "this result is similar to prakasa rao ( 1969 ) , lemma 4.1 , who stated it in the context of density estimation .",
    "our treatment here will parallel that of wright ( 1981 ) , who worked on the asymptotics of  the @xmath8 isotonic regression estimator when the smoothness of the underlying trend function @xmath71 is specified via the number of its continuous derivatives .    specifically , since @xmath72 we may choose for an arbitrary @xmath73 and @xmath55 sufficiently large , positive numbers @xmath74 and @xmath75 for which @xmath76 with this , define the",
    "_ localized version _ of the isotonic m - estimator as @xmath77 then we have the following lemma    [ lemma : rao1 ] assume a1-a4 and ( [ condh ] ) .",
    "then if @xmath53 is defined by ( [ eqn : minmax ] ) , we have , @xmath78=0 .",
    "\\label{eqn : rao}\\ ] ]    is is also noteworthy that the estimator in equation ( [ eqn : modest ] ) is not computable , for @xmath79 and @xmath80 depend on the distribution @xmath61 which is generally unknown . for computational purposes",
    "this implies that the calculation of these estimators will indeed be global for fixed sample sized .",
    "lemma [ lemma : rao1 ] is , however , crucial to study the asymptotic properties of @xmath81 .    given an stochastic process @xmath82 , we denote by `` @xmath83 $ ] '' the random variable that corresponds to the slope at zero of the greatest convex minorant of @xmath84 the following theorem gives the asymptotic distribution of @xmath53 .",
    "assume a1-a4 and ( [ condh ] ) , let @xmath53 be given by ( [ eqn : minmax ] ) , then @xmath85^{2}}\\right ] ^{-1/3}n^{1/3}\\left (   \\hat{\\mu}_{n}(t_{0})-\\mu(t_{0})\\right )   \\rightarrow \\text{\\textrm{slogcm}}\\left (   \\mathbb{w}(v)+v^{2}\\right )   , \\label{eqn : slogcm}\\ ] ] where @xmath86 is a two - sided standard brownian motion .",
    "notice that in the case of the l@xmath18 isotonic estimator the function @xmath28 , so @xmath87 and @xmath88 so that @xmath89(@xmath90 and @xmath91",
    ". then the standardizing constant is given by @xmath92 as it is known for the l@xmath18 isotonic estimator .",
    "in the case of l@xmath16 isotonic regression notice that in the function @xmath29 , so @xmath93sign@xmath94 for @xmath95 or else is left undefined .",
    "our method is thus not applicable as the assumptions on @xmath31 do not hold .",
    "however , consider a sequence of functions @xmath96 for which @xmath97 and so that there is continuity of the first 3 derivatives everywhere ; for a construction of such type of functions it is enough to consider quartic splines ( e.g. , de boor , 2001 ) . in this setup",
    "we get @xmath98 = 2g^{\\prime}(0).\\end{aligned}\\ ] ] letting @xmath99 and @xmath100 so that @xmath101 , we obtain @xmath102^{2}}h^{\\prime}(t_{0}),\\ ] ] as it is known in the case of l@xmath16 isotonic regression ( see wang and huang , 2002 ) .    a similar construction to equation ( [ eqn : approxpsi ] )",
    "may be applied to the functions @xmath103 in the huber s family .",
    "we will consider now the more realistic case where @xmath34 is not known and it is replaced by an estimator @xmath21 previously calculated . then , in order to obtain an scale equivariant estimator we should replace @xmath34 in ( [ eqn : locmin ] ) and ( [ eqn : partialsums ] ) by a robust scale equivariant estimator @xmath30 in remarks [ rescalem ] and [ rescalemed ] below we give some possible choices for @xmath30    in the next theorem it is shown that under suitable regularity conditions , it can be proved that if @xmath21 converges to @xmath34 fast enough , both isotonic m - estimators , the one using the fixed scale @xmath34 and the one using the scale @xmath21 , have the same asymptotic distribution .  making explicit the scale in the notation , denote the isotonic m - estimator of @xmath5 based on a fixed scale @xmath104 by @xmath105 then@xmath106 where @xmath107 solves @xmath108 over @xmath109 .",
    "we need the following additional assumptions :    a5 : :    there exists @xmath110 such that    @xmath111 for @xmath112 and    @xmath113 if @xmath114 a6 : :    the estimator @xmath115  satisfies    @xmath116    then we have the following theorem :    [ scaleest ] assume a1-a6  then @xmath117 assume also that ( [ condh ] ) holds , then both estimators have the same asymptotic distribution .",
    "[ rescalem]in the context of nonparametric regression ghement , ruiz and zamar ( 2008 ) propose to use as scale estimator @xmath21 given by @xmath118 where @xmath119 is an m - estimator of scale , i.e. , @xmath120 is defined as the value @xmath119 satisfying @xmath121 where @xmath122 is a function  which is even , non - decreasing for @xmath43 @xmath123 bounded and continuous . the right hand side is generally taken so that if @xmath43 is n(0,1 ) , @xmath124 this condition makes the estimator converging to the standard deviation when applied to a random sample of the n(0,1 ) distribution . a popular family of functions  @xmath125 to compute scale m - estimators is the bisquare family given by @xmath126{ccc}1-\\left (   1-(\\frac{u}{c})^{2}\\right )   ^{3 } & \\text{if } & |u|\\leq c,\\\\ 1 & \\text{if } & |u|>c .",
    "\\end{array } \\right .   \\label{bisqro}\\ ] ]  ghement et al .",
    "( 2008 ) prove that if @xmath5 is continuous  under general conditions on @xmath125 condition a6 is satisfied  with @xmath34 defined by@xmath127 @xmath128    [ rescalemed ] an alternative scale estimator , which does not require the continuity of @xmath129 is provided by@xmath130 where @xmath131 are the residuals corresponding to the l@xmath16isotonic  estimator .",
    "we conjecture but we do not have a proof that this estimator converges also with rate @xmath132 to @xmath133median@xmath134",
    "in order to obtain the influence function of the isotonic m - estimator at a given point @xmath36 we need to assume that the pair @xmath135 is random . in this case",
    "the isotonic regression model assumes that @xmath136 where @xmath43 is independent of @xmath36 and @xmath5 is non - decreasing .",
    "we assume that the error term @xmath43 has a symmetric density @xmath7 , and that the observation point @xmath36 has a distribution with density @xmath137 .",
    "we start assuming that @xmath34 is known and suppose that we want to estimate @xmath54 given an arbitrary distribution @xmath138 of @xmath139 , the isotonic _",
    "m - estimating functional _ of @xmath140 which we henceforth denote by @xmath141 is defined in three steps as follows .",
    "first for @xmath142 let @xmath143 be defined  as the value @xmath144 satisfying @xmath145  let @xmath146  and then @xmath141 is defined by @xmath147 let @xmath148 be the empirical distribution of @xmath149 , then if @xmath81 is the estimator defined in ( [ eqn : minmax ] ) , we have @xmath150    it is immediate that if @xmath151 is the joint distribution corresponding to model ( [ eqn : model ] ) we have @xmath152 so that the isotonic m - estimator is fisher - consistent .",
    "consider now the contaminated distribution @xmath153 where @xmath154 represents a point mass at @xmath155 . in this case",
    "we define the influence function of @xmath156 by @xmath157  then , we have the following theorem :    [ inffun]consider the isotonic regression model given in ( [ eqn : model ] ) and let @xmath156 be an isotonic m - estimating functional ,  where @xmath17 is an interior observation point . then , under assumptions a1-a4 we have@xmath158{ccc}\\dfrac{2\\mu^{\\prime}(t_{0})\\sigma_{0}\\left\\vert \\psi((x-\\mu(t_{0}))/\\sigma _ { 0})\\right\\vert } { h(t_{0})\\text{\\textrm{e}$_{g}$}(\\psi^{\\prime}(u/\\sigma _ { 0 } ) ) } & \\text{if } & t^{\\ast}=t_{0},\\\\ 0 & \\text{if } & t^{\\ast}\\neq t_{0}. \\end{array } \\right .   \\label{if*}\\ ] ]    notice that in the numerator of ( [ eqn : cuadinf ] ) appears the square of the bias instead of the plain bias as in the classical definition of hampel ( 1974 ) .",
    "therefore for the isotonic m - estimator @xmath156 the bias caused by a point mass contamination @xmath159 is of order @xmath160 instead of the usual order of @xmath161 .",
    "alternatively , it is also of interest to know what happens when we are estimating @xmath140 and contamination takes place at a point @xmath162 according to ( [ if * ] ) , the influence function in this case is zero .",
    "this occurs because in this case for @xmath161 sufficiently small @xmath163 .",
    "it is easy to show that when we use a scale @xmath164 defined by a continuous functional , the influence function of the isotonic m - estimator is still given by ( [ if * ] ) .",
    "roughly speaking the breakdown point of an estimating functional @xmath156 of @xmath140 is the smallest fraction of outliers which suffices to drive @xmath165 to infinity .",
    "more precisely , consider the contamination neighborhood @xmath166 of the distribution @xmath151 of size @xmath161 defined as @xmath167 where @xmath168 is an arbitrary distribution of @xmath135 such that @xmath36 takes values in @xmath63 $ ] and @xmath169 in @xmath170 .",
    "the asymptotic breakdown point of @xmath156 at @xmath151 is defined by @xmath171 we start considering the case that @xmath34 is known .",
    "then we have the following theorem .",
    "consider the isotonic regression model given in ( [ eqn : model ] ) and let @xmath156 be an isotonic m - estimating functional where @xmath17 is an interior observation point .",
    "then under assumptions a1-a4 we have@xmath172 in the special case when @xmath61 is uniform , this becomes @xmath173 which takes a maximum value of @xmath174 at @xmath175     in the case that @xmath34 is replaced by an estimator @xmath176 derived from a  continuous functional @xmath177 it can be proved that the breakdown point of @xmath156 satisfies @xmath178    ghement et al .",
    "( 2008 ) showed that if @xmath21 is defined as in remark [ rescalem ] , where @xmath119 is defined by ( [ scalem])-([limssca ] ) with @xmath179 and @xmath180then @xmath181 .",
    "moreover in this case @xmath34 coincides with the standard deviation when the error has a normal distribution .",
    "[ inmorta]in this section we consider data on infant mortality across countries .",
    "the dependent variable , the number of infant deaths per each thousand births is assumed decreasing in the country s per capita income .",
    "these data are part of the r package faraway  and was used in faraway ( 2004 ) .",
    "the manual of this package only mentions that the data are not recent but it does not give information on the year and source . in figure [ morinf ]",
    "we compare the l@xmath18 isotonic regression estimator with the isotonic m - estimator computed with the huber s function with @xmath182  and @xmath21 as in remark 2 , where @xmath119 is defined by ( [ scalem])-([limssca ] ) with @xmath179 and @xmath183 there are four countries with mortality above 250 : saudi arabia ( 650 ) , afghanistan ( 400 ) , libya ( 300 ) and zambia ( 259 ) . these countries , specially saudi arabia and libya due to their higher relative income per capita ,",
    "exert a large impact on the l@xmath18 estimator .",
    "the robust choice , on the other hand , appears to resistant to these outliers and provides a good fit .",
    "[ ptb ]    morewm.emf    we reconsider the global warming dataset first analyzed in the context of isotonic regression by wu , woodroofe and mentz  ( 2001 ) from a classical perspective and subsequently analyzed from a bayesian perspective in alvarez and dey ( 2009 ) .",
    "the original data is provided by jones _",
    "( see http//cdiac.esd.ornl.gov / trends / temp / jonescru / jones.html ) containing annual temperature anomalies from 1858 to 2009 , expressed in degrees celsius and are relative to the 1961 - 1990 mean .",
    "even though the global warming data , being a time series , might be affected by serial correlation , e.g. fomby and vogelsang  ( 2002 ) , we opted for simplicity as an illustration to ignore that aspect of the data and model it as a sequence of i.i.d .  observations .    [ ptb ]    gw3.eps    _ _ in figure [ fig : gw1 ] we plot the l__@xmath18 _ _ isotonic estimator , which for these data is identical to the isotonic m - estimate with k=0.98 .",
    "visual inspection of the plot shows a moderate outlier corresponding to the year 1878 ( shown as a solid circle ) . that apparent outlier , however , has no effect on the estimator due to the isotonic character of the regression.the fact that the l__@xmath18 _ and the isotonic m - estimates coincide for these data seems to indicate that the phenomenon of global warming is not due to isolated outlying anomalies , but it is due instead to a steady increasing trend phenomenon . in our view , that validates from the point of view of robustness , the conclusions of other authors on the same data ( e.g.  wu , woodroofe and mentz ( 2001 ) , and lvarez and dey ( 2009 ) ) who have rejected the hypothesis of constancy in series of the worlds annual temperatures in favor of an increasing trend . _",
    "interestingly the limiting distribution of the isotonic _ m_-estimator is based on the ratio @xmath184 as in the the i.i.d .",
    "location problem ( e.g.  maronna , martin and yohai , 2006 )",
    ". the slower convergence rate , however , entails that the respective asymptotic relative efficiencies are those of the location situation taken to the power @xmath185 .",
    "specifically , note that from theorem 1 for any isotonic m - estimator @xmath186 \\right\\ } \\\\ &   = \\left [   \\frac{1}{2}\\mu^{\\prime}(t_{0})h^{\\prime}(t_{0})\\frac { \\mathrm{e}_{g}[\\psi(u)^{2}]}{[\\mathrm{e}_{g}\\psi^{\\prime}(u)]^{2}}\\right ] ^{2/3}\\text{var}[\\text{slogcm}\\left (   \\mathbb{w}(v)+v^{2}\\right )   ] , \\end{aligned}\\ ] ] where avar stands for asymptotic variance and var for variance .    in order to determine the finite sample behavior of the isotonic m - estimators we have performed a monte carlo study .",
    "we took i.i.d .",
    "samples from the model ( [ eqn : model ] ) with trend term @xmath187 and where the distribution @xmath4 is n(0,1 ) and student with three degrees of freedom .",
    "the values @xmath188 corresponds to a uniform limiting distribution @xmath189 for @xmath190 .",
    "we estimated @xmath140 at @xmath191 , the true value of which is @xmath192 using three isotonic estimators : the l@xmath18 isotonic estimator , the l@xmath16 isotonic estimator and the same isotonic m - estimator that was used in the examples .",
    "we performed @xmath193 replicates at two sample sizes , @xmath194 and @xmath195 .",
    "dykstra and carolan ( 1998 ) have established that the variance of the random variable @xmath196  is approximately 1.04 . using this value , we present in table 1 sample mean square errors ( mse )  times @xmath197 as well as the corresponding asymptotic variances .",
    "@xmath198{ccccccc|}\\hline estimator & \\multicolumn{2}{c}{n = 100 } & \\multicolumn{2}{c}{n=500 } & \\multicolumn{2}{c|}{avar}\\\\\\cline{2 - 7 } & normal & student$_{3}$ & normal & student$_{3}$ & normal & student$_{3}$\\\\\\hline l$_{2}$ & 1.93 & 3.78 & 1.85 & 3.65 & 1.92 & 3.98\\\\ l$_{1}$ & 2.38 & 2.89 & 2.67 & 2.76 & 2.59 & 2.89\\\\ m & 2.04 & 2.86 & 2.11 & 2.51 & 2.06 & 2.53\\\\\\hline \\end{tabular } \\ \\ \\ ] ]    table 1 .",
    "sample mse and avar for isotonic regression estimators .",
    "we note that for  both distributions , the empirical mses  for @xmath199 are close to the avar values .  we also see that under both distributions  the m - estimator is more efficient that the l@xmath16 one , that the m- estimator is more efficient than the l@xmath16 one  for both distributions and that the l@xmath16 estimator is slightly less efficient than the l@xmath18 estimator for the normal case but much more efficient for the student distribution .  in summary ,  the isotonic m - estimate seems to have a good behavior under both distributions .",
    "without loss of generality  we can assume that @xmath200 given @xmath201 , for sufficiently large @xmath55 there exist positive numbers @xmath202 and @xmath203 for which @xmath204 as in wright ( 1981 ) , we first argue that @xmath205\\leq \\mathrm{p}(\\omega_{1n})+\\mathrm{p}(\\omega_{2n}),\\ ] ] where @xmath206\\right .",
    "< \\left .",
    "\\max_{u\\leq t_{0}-\\alpha_{l}(n)}\\hat{\\mu}_{n}[u , t_{0}-\\beta_{l}(n)]\\right\\ }   , \\label{omega1}\\\\ \\omega_{2n }   &   = \\left\\ {   \\max_{u\\leq t_{0}}\\hat{\\mu}_{n}[u , t_{0}+\\beta _ { u}(n))\\right .   > \\left .",
    "\\min_{v\\geq t_{0}+\\alpha_{u}(n)}\\hat{\\mu}_{n}[t_{0}+\\beta_{u}(n),v]\\right\\ }   .",
    "\\label{eqn : omega2}\\ ] ] to see this , note that the complement of @xmath207 is the set in which , for all @xmath208 and all @xmath209 we have that @xmath210\\right\\ }   $ ] .",
    "since @xmath31 is non - decreasing we can write @xmath211.\\ ] ]  this in turn entails that in @xmath212 @xmath213.\\ ] ] using the fact that the maximum and the minimum may be reversed in computing these estimators ( e.g.  robertson and waltman , 1968 ) and a similar argument for @xmath214 in equation ( [ omega1 ] ) one can show that @xmath215 so we need to prove that @xmath216 we will prove @xmath217  the result for @xmath207 can be obtained in a similar manner .",
    "let @xmath218<\\mu(t_{0}-\\beta_{l}(n))\\right\\ }   , \\label{eqn : bound1}\\\\ \\lambda_{2n }   &   = \\left\\ {   \\max_{u\\leq t_{0}-\\alpha_{l}(n)}\\hat{\\mu}_{n}[u , t_{0}-\\beta_{l}(n)]>\\mu(t_{0}-\\beta_{l}(n))\\right\\ }   .",
    "\\label{eqn : bound2}\\ ] ]  since @xmath219 it will be enough to prove that@xmath220 since the proofs of ( [ lama1 ] ) for @xmath221 and @xmath222  are similar , ( [ lama1 ] ) will be only proved for @xmath223 by the fundamental identity ( [ eqn : equivs ] ) we have @xmath224 in the sequel in order to simplify notation we will omit the subindex @xmath55 writing @xmath225 , @xmath226 and @xmath227 making it explicit only when there is a risk of confusion .",
    "we can write@xmath228 and by a taylor expansion we get@xmath229   , \\ ] ] where @xmath230 .",
    "put @xmath231 , then @xmath232 thus , since @xmath5 is increasing we get @xmath233 put @xmath234 .",
    "as @xmath235 , we obtain @xmath236 therefore the event @xmath237 defined in ( [ eqn : l ] ) is included in the event @xmath238 defined by @xmath239 the equation above can be rewritten in terms of integrals with respect to the empirical distribution of the @xmath36 s as @xmath240 since @xmath241 are i.i.d .",
    ", relabelling the @xmath242 s on the left hand side we get that @xmath243 where @xmath244  adding and subtracting @xmath245 we can write @xmath246dh_{n}(s )   & = \\int_{t_{0}-\\beta_{l}(n)}^{t_{0}}[\\mu(s)-\\mu(t_{0}-\\beta_{l}(n))]dh(s)\\nonumber\\\\ &   + \\int_{t_{0}-\\beta_{l}(n)}^{t_{0}}[\\mu(s)-\\mu(t_{0}-\\beta_{l}(n))]d(h_{n}(s)-h(s ) ) . \\label{decomp}\\ ] ] using ( [ condh ] ) , for @xmath55 large enough , the second term in the above equation is bounded by @xmath247dh_{n}(s)-h(s))\\right\\vert   &   \\leq2\\left (   \\mu(t_{0})-\\mu ( t_{0}-\\beta_{l}(n)\\right )   \\sup_{t}|h_{n}(t)-h(t)|\\\\ &   \\leq2\\mu^{\\prime}(t_{0})\\beta_{l}(n)n^{-1/3}o(1),\\end{aligned}\\ ] ] and since by the inverse function theorem @xmath248^{-1}n^{-1/3}[1+o(1)]$ ] , we obtain that for some constant @xmath249 which does not depend on @xmath73 we can write @xmath250d(h_{n}(s)-h(s))\\right\\vert \\leq acn^{-2/3}o(1 ) .",
    "\\label{intbrav1}\\ ] ] consider now the first term in the right hand side of equation ( [ decomp ] ) . using ( [ condh ] ) we have@xmath251 }   &   [ \\mu(s)-\\mu(t_{0}-\\beta _ { l}(n))]dh(s)\\\\ &   = \\int_{t_{0}-\\beta_{l}(n)}^{t_{0}}[\\mu(t_{0})-\\mu(t_{0}-\\beta _ { l}(n))]dh(s)-\\int_{t_{0}-\\beta_{l}(n)}^{t_{0}}[\\mu(t_{0})-\\mu(s)]dh(s)\\\\ &   = [ \\mu(t_{0})-\\mu(t_{0}-\\beta_{l}(n))][h(t_{0})-h(t_{0}-\\beta_{l}(n))]-\\int_{t_{0}-\\beta_{l}(n)}^{t_{0}}[\\mu(t_{0})-\\mu(s)]dh(s)\\\\ &   \\leq\\left (   \\frac{\\mu(t_{0})-\\mu(t_{0}-\\beta_{l}(n))}{\\beta_{l}(n)}\\right ) \\left (   \\frac{h(t_{0})-h(t_{0}-\\beta_{l}(n))}{\\beta_{l}(n)}]\\right )   \\beta _ { l}(n)^{2}\\\\ &   = \\mu^{\\prime}(t_{0})[1+o(1)]h^{\\prime}(t_{0})[1+o(1)]\\beta_{l}(n)^{2}\\\\ &   = \\mu^{\\prime}(t_{0})[h^{\\prime}(t_{0})]^{-1}c^{2}n^{-2/3}[1+o(1)].\\end{aligned}\\ ] ] therefore @xmath252dh_{n}(s)\\\\ &   \\leq\\mu^{\\prime}(t_{0})c^{2}[h^{\\prime}(t_{0})]^{-1}n^{-2/3}(1+o(1))+2\\mu ^{\\prime}(t_{0})c[h^{\\prime}(t_{0})]^{-1}n^{-2/3}o(1)\\\\ &   \\leq\\mu^{\\prime}(t_{0})c^{\\star}[h^{\\prime}(t_{0})]^{-1}n^{-1/3}\\left\\ { n^{-1/3}[1+o(1)]+2n^{-1/3}o(1)\\right\\}\\end{aligned}\\ ] ] with @xmath253 .",
    "then , for some constant @xmath254 which does not depend on @xmath73 we can write @xmath255dh_{n}(s)\\leq bc^{\\star}n^{-1/3}. \\label{intb}\\ ] ]  from ( [ eqn : l ] ) , ( [ eqn : boundd ] ) , ( [ delta1 < ] ) , ( [ eqn : eqsum ] ) , ( [ decomp ] ) , ( [ intbrav1 ] ) and ( [ intb ] ) we derive that there exists a constant @xmath256 independent of @xmath73 such that for @xmath55 large enough and @xmath257 @xmath258 at this point , we use the hjek - renyi maximal inequality ( e.g. , shorack , 2000 ) which asserts that for a sequence @xmath259 of independent random variables with mean @xmath260 and finite variances and for a positive non - decreasing real sequence @xmath261 , @xmath262 using this inequality from ( [ eqn : tohr ] ) we get that @xmath263  approximating the riemann sum we obtain @xmath264 and since by ( [ condh ] ) @xmath265 , for @xmath55 large enough we have @xmath266 from ( [ file1 ] ) , ( [ file2 ] ) and ( [ file3 ] ) we derive that for @xmath267 large enough @xmath268 then the lemma follows immediately .      without loss of generality",
    "we can assume that @xmath200since @xmath269^{-1}n^{-1/3}[1+o(1)]$ ] , and @xmath73 is arbitrary , we will consider the localized estimator @xmath270 where @xmath271 is defined as the root of @xmath272 over @xmath273 .",
    "note that the localized estimator depends on the @xmath11 s that lie on a neighborhood about @xmath17 which shrinks at a rate @xmath274 . to proceed with",
    "the development of the asymptotic distribution let now @xmath275 , @xmath276 and @xmath277 . with this notation ,",
    "@xmath271 is a root of the partial sums in the parametrization @xmath278 where @xmath279\\}$ ] .",
    "so that the relabelling implies @xmath280 .",
    "consequently , @xmath281 now a taylor expansion of @xmath282 around @xmath17 for any @xmath283 gives @xmath284 which entails that @xmath285  using the equivariance of m - estimators , the monotonicity of @xmath31 and the fact that @xmath286 is bounded , it can be proved that @xmath287 where @xmath288 solves @xmath289 and@xmath290 thus , using that the @xmath291 are bounded over @xmath292 we have @xmath293 this entails that @xmath294=\\max_{r\\leq0}\\min_{v\\geq0}n^{1/3}\\tilde{\\mu}_{n}^{c}(r , s)+o_{rs}^{\\ast}(1),\\ ] ] where@xmath295 then , we  only need to obtain the asymptotic distribution of @xmath296    let @xmath297 be the solution of @xmath298 since @xmath299 we have that @xmath300 where@xmath301 we will approximate now @xmath302 as follows@xmath128@xmath303\\nonumber\\\\ &   + [ h(t_{0}+sn^{-1/3})-h(t_{0}-rn^{-1/3})]-[h_{n}(t_{0})-h(t_{0})]\\nonumber\\\\ &   = h^{\\prime}(t_{0})(s - r)n^{-1/3}+o(n^{-1/3})\\nonumber\\\\ &   = n^{-1/3}h^{\\prime}(t_{0})(s - r)[1+o(1 ) ] , \\label{nrsfor}\\ ] ] and therefore@xmath304 , \\label{nrsfor2}\\]]@xmath305 and@xmath306 then , taking @xmath307 and applying the law of large numbers is easy to show that @xmath308 a.s . and therefore by ( [ dnrs1 ] ) and ( [ dnrs2 ] ) @xmath309 too .",
    "since @xmath288 satisfies ( [ murs ] ) , by a taylor expansion of @xmath310 we get @xmath311 from here we obtain @xmath312 and then@xmath313 by ( [ murs ] ) , the law of the large numbers , @xmath314 and @xmath315 bounded we have@xmath316@xmath317@xmath318 and @xmath319 then , ( [ largui1 ] ) entails@xmath320 let @xmath321 by ( [ nrsfor3 ] ) and the central limit theorem we have that for any set of finite numbers @xmath322,@xmath323 the random vector @xmath324 converges in distribution to n(0 , @xmath325 where @xmath326 with @xmath327 moreover , using standard arguments , it can be proved that @xmath328 is tight .",
    "then , we have @xmath329 where @xmath254 is a two sided brownian motion    as for the second term in the right hand side of ( [ nosac ] ) define @xmath330 for @xmath331 we can write@xmath332 and then @xmath333 integrating by parts we get @xmath334 and by ( [ condh ] ) we have @xmath335 we can write @xmath336 and by([condh ] ) we get @xmath337 therefore by ( [ lan2 ] ) , ( [ lan3 ] ) and ( [ lan4 ] ) we get@xmath338 and for ( [ lan1 ] ) we get that for @xmath331 @xmath339    now we compute the variance of @xmath340 from ( [ lan0 ] ) we have@xmath341 @xmath342 then by ( [ lan5 ] ) we obtain @xmath343 similarly we can prove that @xmath344 therefore from ( [ nosac ] ) , ( [ bns ] ) , ( [ bnsac1 ] ) , ( [ bnsac2 ] ) , ( [ bnscac3 ] ) and ( [ bnsac4 ] ) we get that@xmath345 now the rest of the proof is as in wright ( 1981 ) .",
    "we require the following lemma    assume a1-a5 then , @xmath346  proof    taking the first derivative of equation ( [ eqn : zsigma ] ) with respect to @xmath104 yields @xmath347 and then@xmath348 let @xmath349 then by a5 we obtain@xmath350 therefore @xmath351     * proof of theorem 2 *    by the mean value theorem@xmath352 where @xmath353 is some intermediate point between @xmath104 and @xmath115 .",
    "hence , by lemma 2 we have @xmath354 and a6 implies @xmath355      without loss of generality we can assume that @xmath200 we consider first the case @xmath356 assume that @xmath357 .",
    "then @xmath358 represents a contamination model where an outlier is placed at the observation point @xmath17 with value @xmath359 which is below the trend @xmath140 at the point .",
    "let @xmath360 be the value such that @xmath361 it is immediate that @xmath362 then @xmath363 should be the value of @xmath144 satisfying @xmath364 and , since by ( [ 1 ] ) @xmath365 we have@xmath366 applying the mean value theorem to the first term of ( [ befapp ] ) we can find @xmath367 such that@xmath368    as for the second term in ( [ befapp ] ) we also have that @xmath369 where @xmath370 . since @xmath31 is odd and @xmath7 even , @xmath371 , so that the first term above vanishes . as for the second term , notice that @xmath372   \\left [   \\int\\limits_{-\\infty}^{\\infty}\\psi^{\\prime}(u+\\gamma)g(u)du\\right ]   .",
    "\\label{6}\\ ] ] the first integral factor in the right hand side of the above display can be further approximated . by the mean value theorem",
    ", there exists @xmath373 such that @xmath374 and @xmath375   _ { t_{0}-k(\\varepsilon)}^{t_{0}}\\nonumber\\\\ &   = \\frac{1}{2}\\mu^{\\prime}(t_{0})h(t_{0})k^{2}(\\varepsilon ) .",
    "\\label{7}\\ ] ]    from expressions ( [ 3])-([7 ] ) we obtain that equation ( [ befapp ] ) , can be written as @xmath376   + ( 1-\\varepsilon)\\frac{1}{2}\\mu^{\\prime}(t_{0})h(t_{0})k^{2}(\\varepsilon)\\int\\limits_{-\\infty}^{\\infty}\\psi^{\\prime } ( u)g(u+\\gamma)du=0.\\ ] ] dividing both sides of this equation by @xmath161 and using that @xmath377 @xmath128  and @xmath378 when @xmath379 we obtain @xmath380 finally ,  according to ( [ 1 ] )  and using the mean value theorem , we can write @xmath381 where @xmath382 . then using equation ( [ 8 ] ) we obtain that@xmath383    the proof in the case the that @xmath357 is similar    we consider now the case @xmath384 to prove this part of the theorem is enough to show that  there exists @xmath385 , so that @xmath386 implies @xmath387 and to prove this is enough to show that @xmath388 when @xmath389 this is immediate .",
    "consider the case that @xmath357    clearly for @xmath390@xmath391  it is also easy to show that @xmath392 implies@xmath393 and for @xmath394 and  for all @xmath119@xmath395 then , using ( [ hinch1])-([hinch3 ] )  and the fact that @xmath396 in order to prove ( [ impeq ] ) , it is enough to show that @xmath397 recall that @xmath398 is the solution of @xmath399 where@xmath400 clearly @xmath401 and since @xmath402 and @xmath403 @xmath404 are both increasing in @xmath36 we get @xmath405then , since @xmath31 is bounded , we can find @xmath406 so that for @xmath407 we have@xmath408 and therefore @xmath409 then ( [ enough1 ] ) holds and this proves the theorem for the case @xmath384 the proof for the case @xmath410 is similar .",
    "without loss of generality we can assume that @xmath200 it is easy to see that the least favorable contaminating distribution is @xmath168 concentrated at @xmath411 where @xmath412 tends to @xmath413 or to @xmath414    a necessary and sufficient condition for @xmath407 is that the equation @xmath415 have a bounded solution @xmath144  solution for all @xmath416 and that the equation @xmath417 have a solution for all @xmath418 .",
    "taking @xmath422 we obtain that a sufficient condition for the existence of solution of ( [ bdp2 ] ) for all @xmath418 is that @xmath423 and this equivalent to@xmath424 the theorem follows from ( [ bdp1 ] ) and ( [ bdp2 ] ) ."
  ],
  "abstract_text": [
    "<S> in this paper we propose a family of  robust estimates for isotonic regression : isotonic m - estimators . </S>",
    "<S> we show that their asymptotic distribution is , up to an scalar factor , the  same as that of brunk s  classical isotonic estimator . </S>",
    "<S> we also derive the influence function and the breakdown point of these estimates . </S>",
    "<S> finally we perform a monte carlo study that shows that the proposed family includes estimators that are simultaneously highly efficient under gaussian errors and highly robust when the error distribution has heavy tails .     </S>",
    "<S> * keywords * : isotonic regression , m - estimators , robust estimates . </S>"
  ]
}