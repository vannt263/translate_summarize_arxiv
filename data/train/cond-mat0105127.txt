{
  "article_text": [
    "there is increasing evidence that far from being noisy and unreliable , spiking neurons can encode information about the outside world precisely in individual spike timings  @xcite , @xcite , @xcite .",
    "estimates of the information transmitted by sensory neurons have often found them to be highly informative , sending  2 to 5 bits per spike , and quite reliable , using roughly half of the total entropy available in their spike trains ( @xcite ( monkey ) , @xcite ( cricket ) , @xcite and  @xcite ( frog ) , [ berry et.al . ,",
    "1998 ] ( retina ) , @xcite ( blowfly h1 ) , @xcite ( retina ) , [ reinagel et.al . , 1998 ] ( cat ) ",
    "see @xcite for a discussion and review . )",
    "so it is possible that there are behavioral regimes where information theory will be a powerful tool for predicting the structure of neural codes , provided the costs and constraints of biological computation are properly incorporated .",
    "therefore , as a step towards a biologically relevant information theory , we examine the effect of energetic costs on the coding and transmission of information by discrete symbols , following important prior work by levy  @xcite and sarpeshkar  @xcite .",
    "we have in mind a model of a sensory system where signals from the natural world are detected and encoded , and pass through a noisy channel before arriving at a decision making receiver .",
    "our results are equally relevant to low power electronic devices , such as mobile telephones , that are constrained by finite battery life .    in general terms ,",
    "the role of a sensory system in the process of information use by an organism is summarized in fig .  1 .",
    "information about the environment is detected by sensors and encoded for transmission through an information channel to a control system .",
    "for example , the retina detects patterns of light , which are encoded by ganglion cells for transmission through the optic nerve to the brain .",
    "we might expect evolution ( or engineering ) to produce systems which make an `` optimal '' choice for both the _ amount _ of information to transmit , and given the amount , for the _ kind _ of information to transmit .",
    "the amount of information is quantified in classical information theory by the mutual information @xmath7 , and by the rate @xmath8 during a period in which @xmath9 symbols are transmitted  @xcite .",
    "as we will describe , information theory can be used to determine the minimum power necessary to transmit at a given rate @xmath10 , or the minimum energy needed to transmit a given amount @xmath11 of information .",
    "the rate at which the organism should operate is determined by a tradeoff between the value and cost of the transmitted information .",
    "we outline two different behavioural regimes in which these tradeoffs leads to different coding strategies .",
    "[ [ immediate - regime ] ] immediate regime : + + + + + + + + + + + + + + + + + +    in some activities an organism is engaged in a time - critical task involving rapidly changing environmental states , and its performance depends strongly on its rate of sensory information acquisition @xmath10 .",
    "for example , a cheetah s effectiveness in catching a gazelle , and hence in procuring metabolic gains from food , might be expected to improve with increasing @xmath10 . however , acquiring sensory information also incurs a metabolic cost at some rate @xmath12 , and unless the resulting rate of metabolic gain for the organism @xmath13 is great enough , the expenditure may not be worthwhile .",
    "while numerous factors affect the value of information , we will focus on how it varies with the rate @xmath10 and consider a value function @xmath14 with all other variables held constant .",
    "in general , we expect that the value @xmath14 of sensory information will increase monotonically , but not linearly , with @xmath10 . at a low enough rate of acquisition ,",
    "the sensory modality will be of no use to the organism .",
    "for instance , if the cheetah sees half as well , it will not capture half as many gazelles - it will starve .",
    "conversely , at a high enough information rate the value should saturate , as there is only so much meat in a gazelle . balancing the marginal increase in value to the organism , @xmath15",
    ", against the marginal increase in energy expense , @xmath16 , yields some optimal rate @xmath17 for such an _ immediate regime_. alternatively , there may be some structural constraints , such as signal - to - noise ratio of the sensory modality or processing speed of the biological circuitry , that limit the attainable rate @xmath18 .",
    "we can not compute @xmath17 without knowing the value function @xmath14 , and we can not compute @xmath18 without knowing the structural constraints . however , the smaller of these two values will set the organism s rate of sensory information acquisition , _ and whatever it is , an optimal code will minimize the energy cost for this rate .",
    "_ to study the structure of such codes we can simply ask how to minimize the power required to transmit at a given information rate . as we shall see",
    ", @xmath19 is an increasing convex function , so this is equivalent to determining that maximum rate @xmath20 of information transmission given a constraint of average energy @xmath12 per symbol .",
    "( see fig .  2 . )",
    "[ [ exploratory - regime ] ] exploratory regime : + + + + + + + + + + + + + + + + + + + +    in many other situations , the relevant environmental state is changing slowly and an organism is not faced with any urgent tasks . here",
    ", it is free to choose the rate at which it surveys its surroundings , as well as the time it spends before taking a behavioral decision that changes its environment .",
    "the quality of exploration will depend on the _ total _ amount of sensory information acquired .",
    "better exploration will allow the organism to achieve more appropriate behavior , but continued exploration will involve a cost in metabolic energy as well as in opportunities for other behavior .",
    "therefore , there will be an optimal amount of information , @xmath21 , that the organism should acquire , where the marginal value of exploration matches its marginal cost .",
    "we can not compute @xmath21 without knowing the value of exploration achievable using an amount @xmath11 of information .",
    "however , _ whatever the value of @xmath21 , and independently of the details of the activity , an `` optimal '' sensory system will transmit that information at the rate which minimizes the cumulative energy cost @xmath22 . _",
    "the convexity of @xmath19 implies that this is achieved by a sensory system that transmits at a fixed rate , as any variations in the rate will result in a higher cumulative energy cost .",
    "this optimal rate of sensory information acquisition will minimize @xmath23 , or equivalently , maximize @xmath24 .",
    "[ [ low - power - devices ] ] low power devices : + + + + + + + + + + + + + + + + + + +    both the immediate and the exploratory regimes apply to low power electronic devices , such as mobile telephones or laptop computers .",
    "the finite battery lifetime of these devices puts a premium on energy efficiency .",
    "the immediate regime is equivalent to an `` on - line '' mode , where the information rate of the device is determined by the application but the total amount of information is variable .",
    "the exploratory regime is equivalent to an `` off - line '' or `` batch '' mode , where the total amount of information to transmit is set , but the rate is variable .",
    "[ [ summary ] ] summary : + + + + + + + + +    a system operating at any given information rate @xmath10 should transmit using the minimimum energy @xmath19 required for that rate , all other constraints being held equal . in immediate activities the optimal rate is determined by the tradeoff between gain realizable at rate @xmath10 and the cost @xmath19 .",
    "however , in an exploratory regime , the optimal rate maximizes @xmath24 , independently of the details of the activity .",
    "the next sections describe the general structure of energy efficient codes .",
    "in this section we consider the consequences of metabolic efficiency in information transmission .",
    "we will not address the problem of determining _ what _ information to transmit , but abstract the mapping @xmath25 in fig .  1 as performing this task .",
    "from this point of view , we can treat @xmath26 as a sequence of symbols to be encoded into a sequence @xmath27 of channel inputs , which get transmitted to produce an output sequence @xmath28 .",
    "denote the elements of these sequences at a specific time as @xmath29 , @xmath30 , and @xmath31 .",
    "channel transmission is both noisy and energetically costly .",
    "assume a discrete memoryless channel , modeled by cross - over probabilities @xmath32 giving the probability that a channel input symbol @xmath33 results in a channel output @xmath34 .",
    "the organism as a whole incurs a variety of energetic expenditures at all times , but we will focus on the costs of operating the sensory system , these being relevant to the optimization considered here . the energetic cost of transmitting information can be referred to either the input @xmath27 , the output @xmath28 , or may even be a function of both @xmath26 and @xmath27 .",
    "however , we choose to associate energy costs @xmath35 with input symbols @xmath36 .",
    "this entails no loss of generality , since for arbitrary costs @xmath37 depending on both input @xmath33 and output @xmath34 we may simply take @xmath38 as the expected cost @xmath39 for use of symbol @xmath33 .    our goal is to find , for any given energy @xmath12 , the maximum achievable mutual information @xmath40 between the signal @xmath26 and the channel output @xmath28 , with expected energy cost @xmath41 .",
    "however , it can be shown that @xmath42 , with equality when @xmath26 can be completely determined from @xmath27  @xcite . intuitively , the encoding from @xmath26 to @xmath27 should exploit the channel characteristics , but without loss of information about @xmath26 . assuming the mapping from @xmath26 to @xmath27 is indeed lossless",
    ", maximizing @xmath40 reduces to maximizing @xmath43 .",
    "correlations within the sequence @xmath27 will always decrease the total amount of transmitted information , since this is bounded above by the entropy of @xmath27 .",
    "so to maximize @xmath43 we can assume that the symbols of @xmath27 are independently drawn from a distribution @xmath44 over the channel inputs .",
    "but both @xmath43 and @xmath45 depend upon @xmath44 ; so , formally , the problem is to determine the function @xmath46 where @xmath47 is called the _ channel capacity - cost function _",
    "it is evident from ( [ capdef ] ) and the statistical independence of symbols in @xmath27 that @xmath48 where @xmath20 is the constrained transmission rate discussed earlier .",
    "the channel coding theorems of classical information theory assert that reliable transmission of information is possible at any rate less than @xmath10 , and at no rate greater than @xmath10 .",
    "our focus is not on reliable transmission _ per se _ , but simply on the maximum per symbol rate @xmath20 at which mutual information @xmath43 can be established given the constraint @xmath49 .",
    "we now address , first in the noiseless case , then for a noisy channel , the related problems of : ( 1 ) characterizing @xmath47 , ( 2 ) determining the distribution @xmath50 which achieves @xmath47 , and ( 3 ) finding the maximum of @xmath51 .",
    "the first two problems are of interest because an energy - optimal device or organism should achieve @xmath47 for whatever energy @xmath12 it is operating at , requiring a very particular distribution over @xmath30 .",
    "the third problem is interesting because it allows us to determine both the rate @xmath52 and energy @xmath53 at which an energy - optimal organism would operate in the exploratory regime , regardless of the details of its activity .      in the absence of noise ,",
    "the channel input and output are equal ( @xmath54 ) , and the mutual information @xmath43 equals the channel input entropy @xmath55 .",
    "so , finding the capacity at fixed energy reduces to maximizing the entropy of @xmath27 at fixed energy .",
    "correlations within the sequence @xmath27 will always decrease the entropy , so we can assume that the symbols in @xmath27 are drawn independently from some distribution @xmath56 .",
    "the purpose of the encoding process @xmath57 is to implement a deterministic map between the signal @xmath26 and the channel input @xmath27 , in such a way that the symbols of @xmath27 are statistically independent and have a distribution @xmath56 .",
    "we will not dicuss how this encoding is performed in practice and will focus instead on the structure of the optimal distribution @xmath56 . and @xmath27  @xcite .",
    "most such algorithms are not biologically plausible and it would be very interesting to determine whether suitable encoding algorithms can be implemented by biological hardware .",
    "] then the per - symbol information rate ( or entropy ) and energy involved in the transmission are @xmath58 and @xmath59 , where @xmath60 . in the immediate regime",
    "we maximize @xmath61 at fixed @xmath45 , while in the exploratory regime we maximize @xmath62 .",
    "[ [ immediate - regime-1 ] ] immediate regime : + + + + + + + + + + + + + + + + + +    entropy maximization at fixed average cost is a classic problem , solvable using the method of lagrange multipliers by defining the function @xmath63 and setting its derivatives with respect to @xmath64 , @xmath65 , and all the @xmath66 equal to zero .",
    "setting @xmath67 ensures that the @xmath56 remains a probability distribution .",
    "the conditions @xmath68 can be solved simultaneously to yield @xmath69 where the normalization factor @xmath70 is known as the partition function and @xmath64 is implicitly determined by demanding that the average energy be @xmath12 .",
    "we are simply recovering the commonplace fact of statistical physics that entropy is maximized at fixed average energy by a boltzmann distribution with an `` inverse temperature '' @xmath64 defined by ( [ boltz ] ) .",
    "standard results about boltzmann distributions then tell us that the maximum information rate at fixed energy @xmath71 is a convex function of @xmath12 , increasing from @xmath72 at @xmath73 to a maximum @xmath74 at @xmath75 .",
    "( in the language of statistical physics , the `` heat capacity '' is positive . )",
    "larger energies ( @xmath76 ) lower the entropy .",
    "( see fig .  2 . )",
    "[ [ exploratory - regime-1 ] ] exploratory regime : + + + + + + + + + + + + + + + + + + + +    in the exploratory regime , we maximize the information transmitted per energy cost .",
    "so we should extremize @xmath77 with respect to @xmath65 and all the @xmath66 .",
    "if @xmath78 is maximized by some distribution @xmath79 , there is a corresponding information rate @xmath80 and power consumed @xmath81 .",
    "we have already shown that for fixed @xmath81 the information rate is maximized by the boltzmann distribution ( [ boltz ] ) .",
    "so @xmath79 must be boltzmann for some inverse temperature @xmath82 .",
    "this reduces the multi - variable optimization problem of maximizing @xmath78 to a single equation ",
    "choose @xmath56 to be boltzmann as in ( [ boltz ] ) and demand that @xmath83 .",
    "it is easy to solve this condition in terms of the partition function ( [ boltz ] ) and @xmath84 .",
    "maximizing with respect to @xmath64 gives the condition @xmath85 .",
    "solutions which maximize @xmath78 satisfy @xmath86 thus , information transmission is optimized in the exploratory regime by a boltzmann distribution with unit partition function .",
    "this selects a particular energy @xmath53 and associated entropy @xmath87 . despite the ubiquity of the partition function in statistical physics ,",
    "this is the only instance , insofar as the authors are aware , of a clear physical meaning assigned to a particular numerical value of @xmath70 .",
    "now consider the noisy channel .",
    "once again , the capacity will be maximized when the symbols of the sequence @xmath27 are chosen independently from some @xmath44 because correlations reduce transmitted information . with this assumption , and the channel crossover probabilities defined in sec .",
    "[ metcap ] , the channel capacity ( [ capdef ] ) at a fixed transmission energy becomes @xmath88 \\ , , \\label{c1}\\ ] ] where @xmath89 is given by @xmath90 the maximization is complicated by the dependency of @xmath91 on @xmath66 .",
    "an insight due to arimoto  @xcite and blahut  @xcite , which still applies despite the energy constraint , is that ( [ c1 ] ) can also be written as the double maximization @xmath92 \\ , , \\label{ccdblmax}\\ ] ] where we define @xmath93 .",
    "the advantage of this form is that the capacity can be computed numerically by an iterative algorithm which alternately maximizes with respect to @xmath66 and @xmath94 while holding the other variable fixed .",
    "each of these maximizations can be carried out using lagrange multipliers , as in the previous derivations .",
    "the resulting algorithm can be summarized as :    1 .",
    "choose arbitrary nonzero @xmath95 2 .   for @xmath96 repeat",
    "@xmath97 2 .",
    "@xmath98 with @xmath64 chosen so @xmath99 3 .",
    "if @xmath100 close to @xmath101 stop    the correctness of this generalization of the classic arimoto - blahut algorithm is discussed in  @xcite . in maximizing with respect to @xmath56 in step ( 2b ) , @xmath102 and",
    "the energy costs play identical roles .",
    "indeed , @xmath102 is essentially the average cost due to information loss in noise , leading to the boltzmann distribution in step ( 2b ) .",
    "this algorithm yields the capacity at fixed energy @xmath47 , and the associated distribution @xmath50 .",
    "in the exploratory regime , numerical optimization of @xmath51 gives an optimal energy @xmath53 , associated capacity @xmath52 and distribution @xmath103 .",
    "[ [ summary-1 ] ] summary : + + + + + + + + +    given the channel noise and the symbol energies , the capacity function @xmath47 can be computed . in the noiseless case , it is achieved by a boltzmann distribution . for a noisy channel , @xmath47",
    "is computed numerically , and in all cases the distributions produced by the algorithm above achieve metabolically optimal transmission . in the exploratory regime , the rate should be chosen to maximize @xmath51 which is achieved in the noiseless case when @xmath104 equals @xmath0 .",
    "we have not discussed the implementation of the encoding from @xmath26 into @xmath27 , which may be realized by either arithmetic or block coding methods  @xcite .",
    "how well this mapping can be approximated by biological organisms is a question for investigation .",
    "in this section , we consider some of the properties of energy efficient codes .",
    "first , we show that the optimal code is invariant under certain changes in the symbol energies .",
    "then we illustrate some of the effects of adding noise .",
    "the metabolically efficient distribution on code symbols is invariant under some transformations of the energy model in both the immediate and exploratory regimes .",
    "regardless of whether the energy costs are assigned to the channel inputs @xmath105 or the channel outputs @xmath106 , the optimal immediate symbol distributions are independent of a constant shift in the energies ( @xmath107 ) . in the exploratory regime ,",
    "the optimal distribution is independent of rescalings of the energies ( @xmath108 ) .",
    "this is shown as follows .",
    "[ [ immediate - regime-2 ] ] immediate regime : + + + + + + + + + + + + + + + + + +    in the immediate regime we fix the average transmission energy ( @xmath12 ) , and carry out the arimoto - blahut optimization algorithm in sec .",
    "[ effnoisy ] .",
    "first suppose that symbol energies @xmath38 have been assigned to the channel inputs .",
    "we choose an arbitrary starting distribution @xmath95 for the channel inputs and iteratively perform steps ( a ) and ( b ) of the algorithm to find improved distributions @xmath100 .",
    "step ( a ) leaves @xmath101 unchanged . step ( b ) , which computes @xmath100 ,",
    "is manifestly invariant under a constant shift of the input energies @xmath109 , accompanied by a shift of the average transmission energy @xmath110 .",
    "so the energy - optimal immediate distribution is invariant under a simultaneous constant shift of all the symbol energies and the average energy .",
    "next suppose that symbol costs @xmath111 have been assigned to the channel outputs @xmath34 .",
    "the average energy expended by a channel input @xmath33 is @xmath112 .",
    "since this relation is linear , a constant shift by @xmath113 of the output energies @xmath111 translates to a constant shift by @xmath113 of the input energies @xmath38 , leaving the optimal immediate distribution invariant .",
    "[ [ exploratory - regime-2 ] ] exploratory regime : + + + + + + + + + + + + + + + + + + + +    suppose the channel inputs have energy @xmath38 and that @xmath47 is the channel capacity at fixed transmission energy @xmath12 .",
    "we compute the exploratory regime optimum by setting @xmath114 it follows from the arimoto - blahut algorithm that the optimal input distribution at fixed transmission energy is invariant under a combined rescaling of both the input symbol energies and the average transmission energy ( @xmath115 and @xmath116 ) . to see this , observe that step ( a ) of the algorithm does not change the distribution while the condition in step ( b ) is solved for the new energies by rescaling @xmath117 . since the capacity is a function of only the distribution of code symbols and not directly of the symbol energies , we conclude that the capacity for the system with rescaled energies , @xmath118 , satisfies the relation @xmath119 to find the optimal exploratory distribution with the rescaled energies we must solve @xmath120 .",
    "changing variables to @xmath121 and using ( [ capinv ] ) we find that @xmath122 since this equation is proportional to ( [ expcond1 ] ) , the optimal exploratory distribution is invariant under a rescaling of the input energies .",
    "if we assign costs @xmath111 to the output symbols , linearity of the relation @xmath112 between input and output costs implies that rescaling the output energies rescales the effective input energies and again leaves the exploratory optimum invariant .",
    "in general , an energy - efficient code should suppress the use of expensive symbols .",
    "however , noise can have a dramatic effect , since conveying information requires the use of reliable symbols .",
    "in fact , the noisiness of a cheaper symbol can easily lead to its suppression relative a more expensive , but reliable , symbol .",
    "this sort of effect is particularly important in applications to biological systems , and is illustrated in the toy examples below .    consider a noisy channel in which six symbols @xmath123 are transmitted as symbols @xmath124 with channel crossover ( noise ) probabilities @xmath125 as in sec .",
    "[ metcap ] .",
    "furthermore , let the output symbol @xmath126 have a transmission energy of @xmath127 .",
    "then the average energy of the channel input symbol is @xmath128 . in the absence of any noise at all , @xmath129 and so @xmath130 and the channel input and channel output distributions for the exploratory regime",
    "are both given by : @xmath131 in other words , the channel input and output distributions are both exponential and the weight in the exponential is determined by the condition @xmath132 . in this case",
    "we find @xmath133 .",
    "next suppose that we have `` nearest neighbour noise '' : @xmath134 here @xmath135 is the entry in the j@xmath136 row and k@xmath136 columns of the matrix @xmath137 .",
    "3 shows the optimal exploratory regime distribution on channel output symbols , for several values of noise parameter @xmath138 .",
    "notice the marked deviation of the optimal output distribution from a pure exponential as the noise increases .",
    "for @xmath139 , the least energetic symbol @xmath140 , with @xmath141 , is suppressed so strongly that it is less likely than symbol @xmath142 , with @xmath143 . among the various intricate effects",
    "we have observed in the optimal distribution as a function of noise is a `` phase - transition - like '' behaviour where the probability of a symbol evolves smoothly until the noise reaches some critical value , and then drops suddenly to essentially zero .",
    "4 shows such effects for the input distribution to the channel ( [ chanmat ] ) .    in statistical physics ,",
    "phase transitions occur due to tradeoffs between energy and entropy .",
    "physical systems at finite temperature try to minimize their energy but maximize their entropy , leading to sharp transitions , such as the melting of ice , at a critical temperature . in our case ,",
    "information lost to noise decreases the mutual information between the channel input and output , and this reduction in mutual information competes against energy minimization in the optimization .",
    "the sharp transitions as a function of noise ( fig .",
    "4 ) are a result of this tradeoff .",
    "since biological signal processing systems are noisy , it is important for applications of our formalism that the noise be carefully measured and included in the model .",
    "our primary motivation in analyzing energy efficient information transmission is to provide a formalism which can make quantitative predictions about the detailed structure of neural codes . to this end",
    ", we must identify circumstances in which the neural code can be thought of as a sequence of discrete symbols with distinct energies .",
    "given such a set of symbols as well as a characterization of their transmission noise and energy cost , we can predict the unique symbol distribution that maximizes information transmitted per unit metabolic energy and compare this against the measured symbol distribution .",
    "the vertebrate retina provides a particularly good example .",
    "its input is a visual image projected by the optics of the eye ; its output consists of easily - measured action potentials .",
    "the optic nerve , which connects the eye with the brain , represents the visual world with many fewer neurons than at any other point in the visual pathway , suggesting that principles of efficient coding may be relevant .",
    "in addition , patterns of light with particular behavioral importance , for instance the image of a tiger , are distributed over many photoreceptor cells , the primary light sensors of the retina .",
    "this makes it difficult for any single retinal neuron to evaluate the behavioral significance of an overall image .",
    "therefore , we expect that the value of the signal transmitted by a given optic nerve fibre is closely related to its information content in bits .    previous studies  @xcite have shown that ganglion cells , the output neurons of the retina whose axons form the optic nerve , often transmit visual information to the brain using a discrete set of coding symbols . in these experiments ,",
    "the retina was stimulated with a wide variety of temporal and spatial patterns of light drawn from a white noise ensemble  @xcite . under these stimulus conditions ,",
    "ganglion cells responded with discrete bursts of several spikes separated by long intervals of silence .",
    "the reproducibility of these firing events was very high : the timing of the first spike jittered by @xmath144 ms from one stimulus trial to the next and the total number of spikes varied by @xmath145 spike .",
    "this precision implies that each event is highly informative and that events with different numbers of spikes can reliably represent different stimulus patterns .",
    "in addition , correlations between successive firing events were very weak , implying that each firing event is an independent coding symbol that carries a discrete visual message .",
    "this suggests that the size of each firing event ( i.e. , the number of spikes it contains ) may be treated as a discrete symbol @xmath9 in the retinal code . a short duration of silence",
    "may likewise be discretized to a symbol @xmath72 . the experimentally measured sequence of retinal ganglion cell events , discretized in this manner ,",
    "is represented in our model as the output sequence @xmath28 .",
    "in addition , @xmath146 is the visual stimulus to the retina , @xmath26 is output of the photoreceptors , and @xmath27 is an internal retinal variable representing the ideal retinal output prior to the addition of noise",
    ". repeated presentations of the same stimulus produces a distribution of ganglion cell events with a sharp peak at a certain symbol , and a width that we attribute to noise . interpreting the peak of the distribution as the intended noiseless output @xmath27 , the distribution of actual ganglion cell outputs yields the channel noise matrix required by our model .",
    "given a measurement or an estimate for the energy consumption by events of different sizes ( see below ) , our framework then predicts a specific optimal distribution of event sizes .",
    "comparison of this distribution against the experimentally measured event distribution is a quantitative check of the relevance of metabolically efficient coding to the retina .",
    "more generally , our methods may be applied in any system where a suitable discretization of the neural code is available , along with a description of noise and costs .",
    "the all - or - nothing character of action potentials makes such discretization possible : by choosing an appropriate time bin , a spiking neuron s activity becomes a sequence of integer spike counts .",
    "the choice of time bin and independent `` codewords '' will depend on the neuron being studied .",
    "the noise can be measured experimentally by repetition of an identical stimulus and observation of the resulting distribution of output symbols .",
    "the symbol energy is more difficult to access experimentally .",
    "however , siesjo [ siesjo , 1978 ] and laughlin et.al .",
    "@xcite have argued that the dominant energy cost for a neuron arises in the pumps that actively transport ions across the cell membrane .",
    "if this is true , then the symbol energy can be found by simulating the known ionic currents in a neuron to find the total charge transported during different time periods , as this charge flow must be reversed by active transport in order to maintain equilibrium . because ionic currents are large during an action potential , the symbol energy is likely to be given by a baseline metabolic cost plus an additional increment per spike , @xmath147 , where @xmath148 is the ratio of spiking cost to baseline cost during the time bin . the baseline cost has components due to leak currents , synaptic currents and other cellular metabolism .",
    "estimates of @xmath148 vary , and depend on the neuron in question . while a variety of measurements indicate that electrical activity accounts for roughly half of the brain s total metabolism  @xcite , the parameter @xmath148 may still be small . in any case , since cellular metabolism is difficult to estimate , and because it is unclear in the present context whether pre - synaptic and post - synaptic costs should be bundled into the expense of producing a spike , @xmath148 can be treated as a free parameter for each neuron , and varied to find the energy - efficient code that best agrees with the neuron s distribution of coding symbols .",
    "direct determination of metabolic activity is possible for an entire tissue by measurements of oxygen consumption or heat production .",
    "furthermore , the metabolic activity of a single neuron could be obtained by measuring the uptake of a radioactively - labeled metabolic precursor , such as glucose , during stimulation of the neuron at different firing rates .",
    "such measurements could fix or place bounds on the possible values of @xmath148 .",
    "[ [ summary-2 ] ] summary : + + + + + + + +    we have outlined how the formalism developed in this paper can be applied to real neurons , with particular emphasis on retinal ganglion cells .",
    "discrete output symbols may be defined by counting the number of spikes produced within a fixed time window .",
    "the noise in each symbol can be experimentally measured , and the energy cost can be estimated .",
    "finally , the optimal distribution of spike counts in a symbol can be computed using our methods and compared to the actual distribution used by the neuron .",
    "such a test would determine whether the metabolic cost of information transmission is an important constraint in the structure of a neural code .",
    "we have described energy efficient codes in two different regimes : an immediate regime , where a system s _ rate _ of information transmission is set by external constraints , and an exploratory regime , where the total _ amount _ of information transmission is set by external constraints .",
    "the optimal codes in these cases are closely related , both following a boltzmann distribution in the symbol energies , @xmath149 , when there is no noise . in the immediate regime , the inverse temperature , @xmath64 , is set to yield the imposed information rate , while in the exploratory regime , @xmath64 is set to make the partition function , @xmath70 , equal to one . with the addition of noise , the optimal code must be obtained numerically , but can always be found using a straight - forward iterative scheme .    in delineating the immediate and exploratory regimes",
    ", we do not expect that all of an organism s behavior can be neatly assigned to one or the other category .",
    "instead , we propose here that they apply to _ some _ behaviors .",
    "we have argued for an immediate regime in which the transmission rate is set by the need to respond rapidly to environmental pressures .",
    "however , there will certainly also be situations where the rate is determined instead by complex interactions involving the internal needs and constraints of the organism .",
    "there are also subtleties in identifying regimes of behaviour that are `` exploratory '' .",
    "we have described an idealized situtation where an organism acquires a certain amount of sensory information before executing a single behavior .",
    "more realistically , the organism simultaneously acquires sensory information relevant to many possible behaviors , and the interplay between sensation and behavior is ongoing .",
    "this can be analyzed within our framework by determining the different amounts of optimal information @xmath21 associated with each behaviour , and then requiring that the total amount of data be gathered simultaneously .",
    "the exploratory regime optimization continues to determine the total rate at which the information should be gathered .",
    "the essential point is that in this regime the organism s behavior is open - ended : it has sufficient time to choose a rate of sensory information acquisition that achieves energy efficiency , while still being able to acquire enough information to make a `` good '' behavioral decision among the available choices .    we have described how our formalism can be applied to a biological system , like the retina .",
    "our methods should also be useful in the analysis of low power engineered systems , such as mobile telephones or laptop computers which use discrete , independent coding symbols . in this case",
    ", the engineer controls the particular choice of coding symbols , as well as the design of the encoding algorithm and the transmission channel .",
    "the energy and noise characteristics of the channel can therefore be precisely determined as inputs to our theoretical analysis .",
    "perhaps such an exercise will help in designing low power devices that can perform for longer times before running down their batteries .",
    "m.b . was supported by a national research service award from the national eye institute .",
    "was initially supported by the harvard society of fellows and the milton fund of harvard university .",
    "v.b . and d.k .",
    "are grateful to the xerox palo alto research center , the institute for theoretical physics at santa barbara and the aspen center for physics for hospitality at various stages of this work .",
    "f.  rieke , d.  bodnar and w.  bialek .",
    "naturalistic stimuli increase the rate and efficiency of information transmission by primary auditory neurons .",
    ". royal society of london series b , 262:259 - 265 , 1995 .",
    "schematic of energy optimization .",
    "the information rate ( thick line ) is a convex function of the energy rate until @xmath150 .",
    "the exploratory regime optimum ( @xmath17 , @xmath53 ) is given by the intersection of the tangent from the origin ( thin line ) with @xmath20 .",
    "the effects of noise .",
    "probability distribution of channel output symbols as a function of increasing nearest neighbour noise .",
    "the values of @xmath138 and the associated optimal @xmath64 displayed above are @xmath151 , @xmath152 , @xmath153 , and @xmath154",
    ".      sharp transitions in symbol probabilities due to noise . shown here",
    "is the probability of channel input symbols as a function of noise .",
    "top row , left to right : @xmath140 , @xmath142 , @xmath155 ; bottom row , left to right : @xmath156 , @xmath157 , @xmath158 .",
    "notice the different vertical scales in each panel ."
  ],
  "abstract_text": [
    "<S> energy efficient information transmission may be relevant to biological sensory signal processing as well as to low power electronic devices . </S>",
    "<S> we explore its consequences in two different regimes . in an `` immediate '' regime </S>",
    "<S> , we argue that the information rate should be maximized subject to a power constraint , while in an `` exploratory '' regime , the transmission rate _ per _ power cost should be maximized . in the absence of noise , </S>",
    "<S> discrete inputs are optimally encoded into boltzmann distributed output symbols . in the exploratory regime , the partition function of this distribution is numerically equal to @xmath0 . the structure of the optimal code is strongly affected by noise in the transmission channel . </S>",
    "<S> the arimoto - blahut algorithm , generalized for cost constraints , can be used to derive and interpret the distribution of symbols for optimal energy efficient coding in the presence of noise . </S>",
    "<S> we outline the possibilities and problems in extending our results to information coding and transmission in neurobiological systems .    </S>",
    "<S> * metabolically efficient information processing *    * vijay balasubramanian@xmath1 , don kimber@xmath2 and michael j. berry ii@xmath3 , *    .5 cm    @xmath4__david rittenhouse laboratories , university of pennsylvania , _ _    </S>",
    "<S> _ philadelphia , pa 19104 , usa _    .5 cm    @xmath5 _ fx palo alto laboratory _    _ 3400 hillview avenue _    </S>",
    "<S> palo alto , ca 94304 , usa    .5 cm    @xmath6 _ department of molecular biology , _    _ princeton university , _    _ princeton , nj 08544 , usa _ </S>"
  ]
}