{
  "article_text": [
    "there are many situations where conventional mcmc can not be used because the quantity that determines the weight of a state @xmath4 is , itself , the average of a fluctuating quantity .",
    "specifically , we consider the case of weight functions fluctuating according to a bernoulli process , i.e. in an intermittent manner , although our approach is not limited to bernoulli processes .",
    "examples that we consider are ` committor ' functions , or the outcome of a stochastic minimisation procedure .",
    "equally interesting are examples where a mcmc algorithm would be employed to steer a ( high throughput ) experiment where we aim to optimise an output ( e.g. crystal nucleation ) that is only determined in a probabilistic sense by the initial conditions ( typically specified by a large number of parameters ) . yet another example would be an experiment that aims to find optimal solutions based on stochastic outcomes ( e.g. finding the biologically most functional and/or least harmful composition of a multi - drug cocktail ) .",
    "problems of this nature  and there are many of them  are , at present not tackled using mcmc sampling .",
    "yet , there is no doubt mcmc sampling is the method of choice to explore high - dimensional parameter space .",
    "note that the problem that we are discussing here is different from the case considered by ceperley and dewing ( cd )  @xcite .",
    "cd analysed the problem of performing mcmc sampling of boltzmann weights in cases where the energy function is noisy .",
    "we come back to this point later : suffice it to say that in the case studied in ref .",
    ", the crucial point is that the boltzmann weight is a nonlinear function of the energy and that therefore the boltzmann factor corresponding to the average energy is not the same as the average of the boltzmann factor obtained by sampling over energy fluctuations .",
    "ref .   showed how to construct an approximate algorithm for such cases , which becomes exact if the fluctuations are normally distributed .",
    "here we consider the case where the probability to sample a point is given rigorously by the average of the stochastic estimator of the weight function .    to give a specific example ,",
    "we consider the problem of computing the volume of the basin of attraction of a particular energy minimum @xmath4 in a high - dimensional energy landscape  @xcite .",
    "the algorithms developed in refs .   rely on the fact that , for every point @xmath19 in configuration space , we can determine unambiguously whether or not it belongs to the basin of attraction of minimum @xmath4 : if a ( steepest - descent or similar ) trajectory that start at point @xmath19 ends in minimum @xmath4 , the ` oracle function ' @xmath20 , and otherwise it is zero",
    ".    however , many minimizers are not deterministic  and hence the oracle function is probabilistic .",
    "( in fact , historical evidence suggests that ancient oracles were probabilistic at best ) . in that case , if we start a number of minimisations at point @xmath19 , some will have @xmath20 and others have @xmath21 .",
    "we denote with @xmath22 the average value of the bernoulli process defined by the oracle function @xmath23 . in words :",
    "@xmath22 is the probability that the oracle function associated with point @xmath19 has a value of one .",
    "we now redefine the basin volume ( probability mass ) of minimum @xmath4 as @xmath24 where @xmath25 denotes the coordinate in @xmath26-dimensional space . clearly , @xmath27 where @xmath28 is the number of distinct minima .",
    "this equation expresses the fact that every trajectory must end up somewhere .",
    "hence , we now have an algorithm that allows us to define basin ` clouds ' rather than basin volumes , but for the rest the language stays the same .      if we consider a large number of trial moves form point @xmath19 to point @xmath29 , the average acceptance probability is @xmath30 .",
    "if we consider a large number of trial moves in the reverse direction , the acceptance probability is @xmath31 . in steady state",
    ", the populations should be such that detailed balance holds .",
    "if we denote the ` density ' of sampled points by @xmath32 , then @xmath33 hence if we choose the acceptance probability to be equal to the ( instantaneous ) value of the oracle function in the trial state , then @xmath34 or @xmath35 in words : points are sampled with a probability proportional to the value of the oracle function .",
    "note that in this naive version of the algorithm , the acceptance rule is _ not _ the metropolis rule that considers the ratio of two weights .",
    "here it is the probability itself .",
    "hence , whenever the probability becomes very low , the acceptance of moves decreases proportionally .",
    "there is another class of problems that can be sampled with this algorithm : those that are deterministic but for which the domain where the oracle function is one is highly non - compact . in this case ,",
    "the key requirement is that the sampling algorithm is ergodic : it should avoid getting stuck in small islands where the oracle function is one .",
    "if that can be achieved , then we can use exactly the same approach as before , be it that now the oracle function behaves like a more or less random telegraph function in space .",
    "still , we can define @xmath36 as before .      in the way it has been formulated above",
    ", there is a problem with this approach : as the system moves into a region where @xmath37 is very low , the acceptance of moves becomes very small and hence the ` diffusion coefficient ' that determines the rate at which configuration space is sampled , would become small .",
    "as a consequence , sampling of the wings of the distribution may not converge .    one way to mitigate",
    "the sampling problem is to use an approach that resembles configurational bias mc ( cbmc ) @xcite , but is different in some respects .",
    "the key point to note is that , if we know all random numbers that determine the value of the oracle function  including the random numbers that control the behaviour of the stochastic minimiser  then in the extended space of coordinates and random numbers , the value of the oracle function is always the same for a given point .",
    "one way to exploit this would be to generate a random walk between points that are surrounded by a ` cloud ' of @xmath38 points where we compute the oracle function ( @xmath38 is arbitrary , but as we shall see later , it may pay to make it large ) .",
    "we denote the central point ( i.e. the one to which or from which moves are attempted ) by @xmath39 , where ` b ' stands for ` backbone ' .",
    "the reason for calling this point a ` backbone ' point is that we will be sampling the @xmath38 points connected to it , but we will not compute the oracle function at this very point . hence , @xmath39 may even be located in a region where the oracle function is strictly zero .",
    "the coordinates of the @xmath38 cloud points around @xmath39 are given by : @xmath40 with @xmath41 .",
    "the vectors @xmath42 are generated by some stochastic protocol : e.g. the vectors may be uniformly distributed in a hypersphere with radius @xmath43 .",
    "the precise choice of the protocol does not matter , as long as the rules are not changed during the simulation . for a fixed protocol",
    ", the set @xmath44 is uniquely determined by a set of random numbers @xmath45 .",
    "it is convenient ( but not essential ) to choose the protocol such that any acceptable trial direction about a backbone point is equally likely to be generated .",
    "finally , we note that the value of the oracle function @xmath46 for a given point @xmath44 is uniquely determined by another set of random numbers @xmath47 .",
    "we now define an extended state space @xmath48 in this space , the oracle functions are no longer fluctuating quantities .",
    "we can now construct a mcmc to visit ( but not sample ) backbone points .",
    "to this end , we compute the ` rosenbluth weight ' of point @xmath49 as @xmath50 where @xmath51 and @xmath52 is some arbitrary ( boltzmann ) bias .    we can then construct a mcmc algorithm where the acceptance of a trial move from the ` old ' @xmath53 to the ` new ' @xmath54 is given by @xmath55    as the probabilities to generate the trial directions for forward and backward moves , and the generation of random numbers that determine the value of the oracle function are also uniform , the resulting mc algorithm satisfies super - detailed balance and a given backbone point @xmath49 will be visited with a probability proportional to @xmath56 .",
    "note that during a trial move , the state of the old point is not changed , hence it retains the same trial directions and the same set @xmath57 .",
    "if the trial move is rejected , it is this ` extended point ' that is sampled again .",
    "` cloud ' sampling : illustration of the configurational bias approach for a simple oracle defined by the gray shaded region , such that @xmath58 inside the gray boundary and @xmath59 outside .",
    "blue and red squares are the accepted and rejected backbone points @xmath60 , respectively .",
    "the ` cloud ' points @xmath61 are represented by orange circles . in this example",
    "we randomly sample @xmath62 ` cloud ' points from a circle of fixed radius centred on the backbone point ( dotted circles ) .",
    "each ` cloud ' is sampled with probability proportional to the rosenbluth weight defined in eqn .",
    "[ eq : rosenbluth ] .",
    "note that valid backbone points are not required to fall in the region where @xmath58 since the rosenbluth weight does not depend on the value of the oracle at the backbone point . ]    to discuss sampling , it is best to first discuss a ` thought - algorithm ' _ i.e. _ a valid algorithm that we can construct , but that we would never use in practice . in our thought algorithm , we consider the transition between one particular point , say @xmath63 in the cloud around the old backbone position and another point @xmath64 in the cloud around the new backbone position .",
    "note that the statistical weight of these points depends on @xmath65 and @xmath66 , respectively .",
    "we denote these statistical weights by @xmath67 and @xmath68 .",
    "we can now write down the detailed balance condition : @xmath69 where @xmath70 denotes the probability to select point @xmath64 from among the cloud of points around @xmath71 ( and similarly , for @xmath72 ) .",
    "we now make the following choice for @xmath73 : @xmath74 with this definition of the selection probability , we can write : @xmath75 where we have used the fact that the generation probabilities for forward and backward moves are equal and we have inserted eqn .",
    "[ eq : acceptance ] for the ratio of the acceptance probabilities .",
    "[ eq : detbal ] implies that in equilibrium , the probability to occupy state @xmath63 is proportional to @xmath76 , where it should be stressed that the value of the oracle function depends on both the spatial coordinates of point @xmath63 and on the set of random numbers @xmath57 that , together , determine the value of @xmath77 .",
    "if we were to average over all possible values of the random numbers @xmath57 then it is clear that the probability to sample a state with the spatial coordinates of the point @xmath63 is proportional to @xmath78 . in other words ,",
    "the algorithm described above samples all points in configuration space with a probability proportional to the local average of the oracle function and to the ( usually boltzmann ) bias evaluated at that point .    whilst the above description of the sampling strategy allows us to establish that all points in space are sampled with the correct frequency ,",
    "it is not an efficient algorithm .",
    "the reason is obvious : in order to compute the weights @xmath79 , the oracle function must be computed for @xmath38 points , and yet in the naive version of the algorithm , only one point is sampled . in practice , we take steps between backbone points sampled according to eqn .  [",
    "eq : acceptance ] and keep all @xmath38 cloud points for all the accepted backbone points , as described below .",
    "an illustration of the method is given in fig .",
    "[ fig::cloud_sampling ] .",
    "efficiency can be further improved using the approach underlying ` waste - recycling ' monte carlo  @xcite , we can in fact include all points in the sampling , even if the actual trial backbone move is rejected .",
    "for every backbone point @xmath49 visited , we can compute the observable ( say @xmath80 ) of the set of @xmath38 cloud points as follows : @xmath81 the average of @xmath80 during a mcmc simulation of @xmath82 steps is : @xmath83 where the index @xmath7 labels the different backbone states visited .",
    "parallel tempering ( pt ) @xcite is a monte carlo scheme that targets the slow equilibration of systems characterised by large free energy barriers that prevent the efficient equilibration of a mcmc random walk . in pt",
    ", @xmath84 replicas of the system are simulated simultaneously at different temperatures , different chemical potentials @xcite or different hamiltonians @xcite .",
    "configurations are then swapped among replicas , thus making ` high temperature ' regions available to ` low temperature ' ones and _ vice versa_. in the basin volume calculations of refs .",
    ", hamiltonian pt is essential to achieving fast equilibration of the replicas mcmc random walks performed inside the body of the basin with different applied biases .    the configurational bias approach to ` cloud ' sampling embodied by eqn .  [ eq : acceptance ]",
    "can be easily generalised to pt to find an acceptance rule for the swap of configurations between replicas @xmath4 and @xmath7 @xmath85 where we defined the rosenbluth weight @xmath86 .",
    "it is important to note that pt is truly an equilibrium monte carlo method : the microscopic equilibrium of each ensemble is not disturbed by the swaps .      using a cbmc - style approach would increase the speed with which the relevant configuration space is explored .",
    "however , it has the drawback that it may be wasteful : generating a trial move involves computing @xmath38 oracle functions and , in normal cbmc the points this generated would not be sampled at all if the trial move is rejected .",
    "however , we can do better by using ` waste - recycling ' mc  @xcite . in that case",
    "we can combine the information of the accepted and the rejected states in our sampling .",
    "specifically , we denote the probability to accept a move from an old state @xmath0 to a new state @xmath1 by @xmath87 , then , normally we would sample @xmath88 if the move is accepted and @xmath89 otherwise . however , we can do better by combining the information and sample @xmath90 a_{\\text{sampled}}(o)\\ ] ] where @xmath91 denotes the acceptance probability for _ any _ valid mcmc algorithm ( not just metropolis ) .",
    "in fact , it is convenient to use the symmetric ( barker ) rule  @xcite to compute @xmath91 . in that case",
    ", we would sample @xmath92 hence , all @xmath93 points that have been considered are included in the sampling .",
    "deterministic oracle : volume calculation for an @xmath1-ball with radius @xmath94 and @xmath95 $ ] .",
    "numerical results ( symbols ) were obtained by the configurational bias approach of eqn .",
    "[ eq : acceptance ] and eqn .",
    "[ eq : pt_acceptance ] ( pt ) , with @xmath38 ` cloud ' points , and mbar .",
    "inset : mean square displacement computed by eqn .",
    "[ eq : mc_average ] .",
    "solid blue lines are analytical results and error bars refer to twice the standard error ( as estimated by mbar for the volume ) . ]",
    "stochastic oracle : volume calculation for the oracle defined in eqn .",
    "[ eq : sphere_exp_decay ] with radius @xmath94 , @xmath96 and dimensions @xmath95 $ ] .",
    "symbols ( lines are guide to the eye ) are numerical results obtained by the configurational bias approach of eqn .",
    "[ eq : acceptance ] and eqn .",
    "[ eq : pt_acceptance ] ( pt ) , with @xmath38 ` cloud ' points , and mbar .",
    "solid blue line is the analytical result and error bars refer to twice the standard error as estimated by mbar . at large @xmath1 accuracy increases by increasing @xmath38 as the random walker diffuses more efficiently through regions of space where @xmath97 .",
    "implementing pt also improves equlibration for small @xmath38 by allowing the walker to escape low density regions when stuck . ]",
    "transition state finding : the simple case of one dimensional barrier crossing is defined ( symmetrically ) by the stochastic oracle in eqn .",
    "[ eq : barrier_crossing ] .",
    "a series of random walks are performed according to eqn .",
    "[ eq : acceptance ] with different number of ` cloud ' points @xmath38 .",
    "the walkers are constrained to reject moves for which the energy is below that of the initial position , thus excluding reactants and products from the sampling .",
    "the figure shows the position of the walker backbone along the reaction coordinate as a function of the number of mcmc steps . for increasing @xmath38",
    "the random walkers diffuse more efficiently and therefore converge faster to the transition state .",
    "traditional single - point sampling does not move at all from the initial condition . ]",
    "we test the proposed configurational bias approach by numerically computing the basin volume ( probability mass ) for a stochastic oracle function as defined in eqn .",
    "[ eq : volume_integral ] .",
    "we choose a few simple oracle functions , for which the integral in eqn .  [ eq : volume_integral ] can be solved analytically .",
    "the volume calculations are performed using the multistate - bennett acceptance ratio method ( mbar )  @xcite as described in ref .  .",
    "in essence , we compute the dimensionless free energy difference between a region of known volume @xmath98 and the equilibrium distribution of points sampled uniformly within the basin @xmath99 , estimated by mbar up to a multiplicative constant @xmath100 . since @xmath101 is known , we obtain the basin volume as @xmath102 .",
    "we use @xmath103 replicas with positive coupling constants for all examples discussed herein , see ref .   for details of the method .",
    "first , we test the method for a deterministic oracle , namely a simple @xmath1-ball of known volume @xmath104 with radius @xmath94 and @xmath95 $ ] . as shown in fig .",
    "[ fig::sphere ] we correctly recover the volume and the mean square displacement using the acceptance rule defined in eqn .",
    "[ eq : acceptance ] for @xmath105 ` cloud ' points , with and without parallel tempering swap moves , with acceptance rule defined in eqn .",
    "[ eq : pt_acceptance ] .",
    "hence , the algorithm is clearly sampling the correct equilibrium distributions .",
    "we test the method for a stochastic oracle function defined as @xmath106 < \\exp[-(|{\\mathbf{x}}|-r)/\\lambda ] & \\quad \\text{if $ |{\\mathbf{x}}| \\geq r$ }    \\end{array } \\right.\\,\\ ] ] with volume @xmath107 where @xmath108 is the incomplete gamma function .",
    "results for dimensions @xmath109 $ ] , @xmath94 and @xmath96 are shown in fig .",
    "[ fig::sphere_exp_decay ] .",
    "note that , despite the volume being finite , the basin is unbounded in the sense that the average value of the oracle only tends to zero as as @xmath110 . as the dimensionality of the basin increases ,",
    "all of the volume will concentrate away from the centre of mass in regions of space where the oracle has a high probability of returning @xmath111 .",
    "hence , it becomes more difficult for a random walker to diffuse efficiently as the dimensionality of space increases .",
    "we can verify this in fig .",
    "[ fig::sphere_exp_decay ] : for @xmath112 results seem to be independent of the number of ` cloud ' points and of whether pt swaps are implemented .",
    "however , growing deviations are observed for increasing @xmath1 and accuracy increases significantly for growing number of ` cloud ' points @xmath38 and with the use of pt , whose non - local moves allow the walker to escape regions of low density ( for which @xmath97 ) when stuck .      in this example we show that our approach can be used to efficiently identify the transition state along a known reaction coordinate .",
    "note that points in the transition - state ensemble ( in the one - dimensional case : just one point ) are characterised by the property that the committor has an average value of 0.5 .",
    "however , any individual trajectory will either be crossing ( `` 1 '' ) or non - crossing ( `` 0 '' ) .",
    "hence , the ` signal ' is stochastic . as an illustration",
    ", we consider the ( trivial ) one - dimensional case of a particle with kinetic energy @xmath113 sampled according to the 1-dimensional maxwell boltzmann distribution , crossing a gaussian barrier with height @xmath114 and variance @xmath115 .",
    ", hence in our reduced units @xmath116 we define the oracle symmetrically such as @xmath117 and constrain the walk to reject moves for which the energy is below that of the initial position , such that @xmath59 if @xmath118 ; we choose @xmath119 . by thus constraining the sampling",
    ", we are excluding the ` reactant ' and ` product ' states from our sampling . in fig .",
    "[ fig::barrier_crossing ] we show results for backbone step - size @xmath120 , ` cloud ' radius @xmath120 and varying number of ` cloud ' points @xmath38 .",
    "one can clearly see that as the number of ` cloud ' points increases the system diffuses faster towards the transitions state whilst for the traditional single - point sampling the walker does not move at all from the initial position .",
    "in their 1999 paper , ceperley and dewing  @xcite consider a different situation where normal ` metropolis ' sampling fails , namely the case where the calculation of the energy function is subject to statistical errors ( with zero mean ) . in that case , we can not use the conventional metropolis rule @xmath121 , where @xmath122 is the instantaneous value of the energy difference , because what is needed to compute the correct acceptance probability is @xmath123 , but what is sampled is @xmath124 .",
    "ceperley and dewing showed that if the fluctuations in the energy of the individual states , and therefore the fluctuations in @xmath125 are normally distributed , and if the variance in energy is the same for all states , then we can still get an algorithm that samples the correct boltzmann distribution , if we use as acceptance rule @xmath126\\}\\ ] ] where @xmath127 , with @xmath128 denoting the variance in the energy of the individual states .",
    "note that the situation considered in ref .",
    "is very different from the case that we consider here , as we focus on the situations where the average of the ( fluctuating ) oracle functions is precisely the weight function that we wish to sample .",
    "however , the current approach allows us to rederive the cd result .",
    "we note that , as before , we can consider extended states characterised by the spatial coordinates of the system and by the random variables that characterise the noise in the energy function .",
    "first , we note the average boltzmann factor of extended state @xmath4 is @xmath129 \\exp[+(\\beta\\sigma_s)^2/2]\\ ] ] and therefore @xmath130\\ ] ] hence , the average boltzmann factor of any state @xmath4 is still proportional to the correct boltzmann weight .",
    "however , an mcmc algorithm using the instantaneous boltzmann weights would not lead to correct sampling as super - detailed balance yields @xmath131\\ ] ] and hence @xmath132\\ ] ] which is not equal to @xmath130\\ ] ] if , however we would use the cd acceptance rule , we would get @xmath133\\times \\exp[-(\\beta\\sigma)^2/2 ] \\\\ & = \\exp[-\\beta\\langle \\delta u \\rangle]= { \\left\\langle p_n\\right\\rangle \\over \\left\\langle p_o\\right\\rangle } \\end{split}\\ ] ] hence , with this rule the states would ( on average ) be visited with the correct probability .",
    "note that , as the noise enters non - linearly in the acceptance rule , the cd algorithm is very different from the one that we derived above . note also that the present derivation makes it clear that the cd algorithm can be easily generalised to cases where the noise in the energy is not normally distributed , as long as the distribution of the noise is state - independent .",
    "thus far the algorithm described above was presented as a method to perform monte carlo sampling in cases where the weight function itself is fluctuating .",
    "however , the method might also be used to control certain experiments that study stochastic events ( e.g. crystal nucleation , cell death or even the effect of advertising ) .",
    "often , the occurrence of the desired event depends on a large number of variables ( temperature , pressure , @xmath134 , concentration of various components ) and we would like to select the optimal combination .",
    "however , as the desired event itself is stochastic , individual measurements provide little guidance",
    ". one might aim to optimise the conditions by accumulating sufficient statistics for individual state points .",
    "however , such an approach is expensive .",
    "the procedure described in the preceding sections suggests that it may be better to perform experiments in a ` cloud ' of state points around a backbone point .",
    "we could then accept or reject the trial move to a new backbone state using the same rule as in eqn .",
    "[ eq : acceptance ] .",
    "d. f. acknowledges support by epsrc programme grant ep / i001352/1 and epsrc grant ep / i000844/1 .",
    "k. j. s. acknowledges support by the swiss national science foundation ( grant no .",
    "p2ezp2 - 152188 and no .",
    "p300p2 - 161078 ) .",
    "s. m. acknowledges financial support from the gates cambridge scholarship ."
  ],
  "abstract_text": [
    "<S> conventional monte carlo simulations are stochastic in the sense that the acceptance of a trial move is decided by comparing a computed acceptance probability with a random number , uniformly distributed between 0 and 1 . here </S>",
    "<S> we consider the case that the weight determining the acceptance probability itself is fluctuating . </S>",
    "<S> this situation is common in many numerical studies . </S>",
    "<S> we show that it is possible to construct a rigorous monte carlo algorithm that visits points in state space with a probability proportional to their average weight . </S>",
    "<S> the same approach has the potential to transform the methodology of a certain class of high - throughput experiments or the analysis of noisy datasets .    </S>",
    "<S> dynamic monte carlo simulations aim to sample the states of the system under study such that the frequency with which a given state is visited is proportional to the weight ( often ` boltzmann ' weight ) of that state . </S>",
    "<S> the equilibrium distribution of a system , i.e. the distribution for which every state occurs with a probability proportional to its ( boltzmann ) weight , is invariant under application of single monte carlo step . </S>",
    "<S> algorithms that satisfy this criterion are said to satisfy ` balance '  @xcite . </S>",
    "<S> usually , we impose a stronger condition : ` detailed balance ' , which implies that the average rate at which the system makes a transition from an arbitrary ` old ' state ( @xmath0 ) to a ` new ' state ( @xmath1 ) is exactly balanced by the average rate for the reverse rate . </S>",
    "<S> the detailed balance condition is a very useful tool to construct valid markov chain monte carlo ( mcmc ) algorithms . </S>",
    "<S> we can write the detailed balance condition as follows ; @xmath2 where @xmath3 denotes the equilibrium probability that the system is in state @xmath4 ( in this case , @xmath4 can stand for @xmath0 or @xmath1 ) characterised by a ( usually high - dimensional ) coordinate @xmath5 . </S>",
    "<S> @xmath6 denotes the probability to generate a trial move from state @xmath4 to state @xmath7 . in the simplest case </S>",
    "<S> , this may be the probability to generate a random displacement that will move the system from @xmath8 to @xmath9 , but in general the probability to generate a trial move may be much more complex ( see e.g. ref .  </S>",
    "<S> @xcite ) . </S>",
    "<S> finally @xmath10 denotes the probability that a trial move from state @xmath4 to state @xmath7 will be accepted .    </S>",
    "<S> many simple mc algorithms satisfy in addition microscopic reversibility , which means that @xmath11 . in that case </S>",
    "<S> , detailed balance implies that @xmath12 there are many acceptance rules that satisfy this criterion . </S>",
    "<S> the most familiar one is the so - called metropolis rule  @xcite : @xmath13 the acceptance for the reverse move follows by permuting @xmath0 and @xmath1 . in the specific case of boltzmann sampling of configuration space , where the equilibrium distribution is proportional to the boltzmann factor @xmath14 , where @xmath15 is the potential energy of the system in the state characterised by the coordinate @xmath8 </S>",
    "<S> , @xmath16 is the absolute temperature and @xmath17 is the boltzmann constant . in that case </S>",
    "<S> , we obtain the familiar result @xmath18 \\right\\}\\ ] ] </S>"
  ]
}