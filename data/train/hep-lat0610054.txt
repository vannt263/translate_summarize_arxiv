{
  "article_text": [
    "lattice qcd , an industrial - range computing project , is in its fourth decade .",
    "it has basically two major computing problems : simulation of qcd path integral and calculation of quark propagators . generally , these problems lead to very intensive computations and require high - end computing platforms .    however , we wish to make a clear distinction between lattice qcd test and production codes .",
    "this is very important in order to develop a compact and easily managable computing project .",
    "while this is obvious in theory , it is less so in lattice qcd practicing : those who write lattice codes are focused primary on writing production codes .",
    "what is usually called test code is merely a test of production codes .",
    "the code of a small project is usually small , runs fast , it is easy to access , edit and debug .",
    "can we achieve these features for a lattice test code ? or , can we modify the goals of the lattice project in order to get such features ?",
    "in our opinion , this is possible for a _ minimal test code , a test code constisting of a minimal possible code which is able to test gross features of the theory and algorithms at shortest possible time and largest acceptable errors on a standard computing platform_. this statement needs more explanation :    * although it is hard to give sharp constraints on the number of lines of the test code , we would call `` minimal '' that code which is no more than a few printed pages . *",
    "the run time depends on computing platforms and algorithms , and the choice of lattice action and parameters .",
    "it looks like a great number of degrees of freedom here , but in fact there are hardly good choices in order to reduce the run time of a test code without giving up certain features of the theory .",
    "again , it is tremendously difficult to give run times .",
    "however , a `` short '' run time should not exceed a few minutes of wall - clock time .",
    "* we consider a computing platform as being `` standard '' if its cost is not too high for an academic computing project .",
    "* we call simulation errors to be the `` largest acceptable '' if we can distinguish clearly signal form noise and when gross features of the theory are not compromised by various approximations or choices .",
    "* approximations should not alter basic features of the theory .",
    "the quenched approximation , for example , should not be considered as an acceptable approximation when studying qcd with light quarks .",
    "a test code with these characteristics should _ signal the rapid advance in the field _ , in which case , precision lattice computations are likely to happen in many places around the world . writing a minimal test code is a _ challenge of three smarts _ : smart computers , smart languages and smart algorithms .    in this paper",
    "we introduce the first version of qcdlab , qcdlab 1.0 , a collection of matlab functions for the simulation of lattice schwinger model .",
    "this is part of a larger project for algorithmic development in lattice qcd .",
    "it can be used as a small laboratory to test and validate algorithms .",
    "in particular , qcdlab 1.0 serves as an illustration of the minimal test code concept .",
    "qcdlab can also be used for newcomers in the field .",
    "they can learn and practice lattice projects which are based on short codes and run times .",
    "this offers a `` learning by doing '' method , perhaps a quickest route into answers of many unknown practical questions concerning lattice qcd simulations .",
    "the next two sections describe basic algorithms for simulation of lattice qcd and foundations of krylov subspace methods .",
    "then , we present the functions followed by examples of simple computing projects .",
    "the last section outlines the future plans of the qcdlab project .",
    "lattice gague fields @xmath0 , our basic degrees of freedom , are defined on oriented links of a four dimensional hypercubic lattice with @xmath1 sites and lattice spacing @xmath2 . here , @xmath3 is a four component index labeling the lattice sites , @xmath4 labels dierctions in the euclidean space , and @xmath5 is the unit vector along @xmath6-direction .",
    "algebraically , a lattice gauge field is an order 3 , complex valued unitary matrix with determinant one , an element of the @xmath7 colour group .",
    "the basic computational task in lattice qcd is the generation of ensembles of guage field configurations according to probability density : @xmath8 where @xmath9 is the lattice dirac operator , @xmath10 is the gauge action , @xmath11 is the gauge - boson coupling constant , and @xmath12 is the _ plaquette _ in @xmath13 plane , a 4-link product defined as in the figure .",
    "( 100,180)(0,0 ) ( 150 , 40 ) ( 1 , 0)100 ( 250 , 40 ) ( 0 , 1)100 ( 250,140)(-1 , 0)100 ( 150,140 ) ( 0,-1)100 ( 150 , 30)@xmath3 ( 250 , 30)@xmath14 ( 250,140)@xmath15 ( 120,140)@xmath16 ( 190 , 20)@xmath0 ( 260 , 80)@xmath17 ( 190,150)@xmath18 ( 120 ,",
    "80)@xmath19    we have assumed here a fermion theory with two degenerate flavours of quark masses which suffices for the purpuse of this paper .",
    "there are two main formulations of lattice fermions : wilson @xcite and kogut - susskind @xcite , called also staggered , discretizations of the dirac operator .",
    "wilson operator , linking sites @xmath3 and @xmath20 , is given by @xmath21\\ , \\ ] ] whereas kogut - susskind operator is given by @xmath22 here @xmath23 is the bare quark mass , @xmath24 are anticommuting hermitian _ gamma - matrices _ acting on dirac space @xmath25 and @xmath26 denotes the direct or kronecker product of matrices .",
    "hence , wilson and kogut - susskind operators are complex valued matrices of order @xmath27 and @xmath28 with @xmath29 and @xmath30 nonzero elements respectively .",
    "note that the difficulty of handling the determinat of a huge matrix can be softened using the gaussian integral expression : @xmath31 where @xmath32 is a complex valued field , a _",
    "pesudofermion _ field .",
    "thus , the determinant is traded for the inversion .",
    "all we need now is to generate ensembles according to the new density : @xmath33      the hmc algorithm @xcite starts by introducing @xmath34 conjugate momenta @xmath35 to @xmath7 lattice gauge fields .",
    "hence , the classical hamiltonian can be written in the form @xmath36 whereas expanded probability density is @xmath37    the idea of the hmc algorithm is as follows :    * use global heatbath for pseudofermion field update .",
    "if @xmath38 is a gaussian pseudofermion field , the new field is updated according to the equation @xmath39 * integrate numerically classical equations of motion . * correct numerical integration error using metropolis _",
    "et al _ algorithm .",
    "the first first equation of motion is defined using conjugate momenta : @xmath40 for the second equation one writes down the total derivative of the hamiltonian : @xmath41 substituting for @xmath42 the first equation of motion and using @xmath43 one finds the second equation of motion @xmath44 from @xmath45 expression , it is clear that in order to evaluate the force @xmath46 , one must calculate @xmath47 .",
    "the widely used algorithm for solving equations of motions is the leapfrog algorithm @xmath48 where the primed fields are those advanced by @xmath49 and @xmath50 are half - step momenta .",
    "the algorithm starts at @xmath51 , where momenta are taken to be gaussian noise .",
    "then it continues up to time @xmath52 for @xmath53 number of steps .",
    "it is easy to show that this scheme is reversible and preserves infinitesimal area of the phase space .",
    "reversibility guarantees detailed balance of hmc , whereas area preservation ensures that there are no corrections due to integration measure .",
    "however , hamiltonian is not conserved since @xmath54      the hmc algorithm ends up accepting or rejecting the proposed gauge field @xmath55 using metropolis _ et al _ algorithm @xcite . the acceptance probability for this algorithm is @xmath56 on rejection , one goes back to time @xmath51 and refreshes momenta .",
    "calculation of forces and quark propagators requires the solution of linear systems @xmath57 where @xmath9 is a the lattice dirac operator and @xmath58 the right hand side . as we noted earlier",
    ", @xmath9 is a large and sparse matrix . for these matrices , _ krylov subspace methods _ provide the most efficient inversion algorithms @xcite .",
    "such an algorithm is the conjugate gradients ( cg ) algorithm @xcite .",
    "given an approximation @xmath59 , the algorithm starts with computation of the _ residual vector _",
    "@xmath60 , @xmath61 and initialisation of a vector @xmath62 to the starting residual , @xmath63 .",
    "note that cg assumes that @xmath64 is a _ positive definite _ and hermitian matrix .",
    "then , the algorithm iterates these vectors using recursions @xmath65 where @xmath66      since the lattice dirac operator is neither positive definite nor hermitian one takes @xmath67 and solves for the _ normal equations _",
    "@xmath68 then , we get what we call the conjugate gradients algorithm on normal equations ( cgne ) . as with standard cg ,",
    "given an approximation @xmath59 , the algorithm computes starting residual @xmath60 , @xmath69 and initialises @xmath62 to @xmath60 .",
    "additionally , a new vector @xmath70 is initialised using @xmath71 .",
    "the cgne algorithm recursions are @xmath72 where @xmath73 and @xmath74      it can be theoretically proven that cgne algorithm converges _ linearly _",
    ", i.e. @xmath75 where @xmath76 denotes the euclidean norm and @xmath77 is the _ condition number _ of the dirac operator . in terms of _ singluar values _ of @xmath9 , @xmath78 , the condition number is given by @xmath79 if @xmath9 is rescaled such that @xmath80 we get ( see @xcite , p52 ) @xmath81 it can be shown that cgne calculates a solution of the minimisation problem @xmath82 but for non - normal matrices , such as the wilson - dirac operator , this solution is _ sub - optimal_. unlike cgne , the general minimised residual ( gmres ) algorithm calculates the _ optimal _ solution of this problem . both methods convegre according to the law described above .",
    "however , @xmath83 is traded for the spectral gap , which is larger ( for non - normal matrices ) . as we will show later",
    ", gmres algorithm is more expensive and often prohibitive in terms of computer resources .",
    "a krylov subspace is the space built from the pair @xmath84 : @xmath85 where @xmath86 , with @xmath23 being the rank of @xmath9 .",
    "the simpliest example consists of the pair @xmath60 and the identity matrix @xmath87 , in which case @xmath88 and the krylov subspace is simply the vector @xmath60 . in this case",
    "we have to do with an _ invariant subspace _ : further multiplications of @xmath60 by @xmath89 will not increase the subspace .",
    "iterative methods which seek solutions @xmath90 in @xmath91 are called krylov subspace methods .",
    "if @xmath92 $ ] is a basis of othonormal vectors of @xmath91 , the approximate solution can be written as @xmath93 in order to compute it one has to compute first @xmath94 .",
    "there are two general approaches to compute @xmath95 , namely    * galerkin approach : choose @xmath95 such that the residual vector @xmath96 is orthogonal to @xmath91 . *",
    "minimal residual approach : choose @xmath95 such that @xmath97 is minimal .",
    "the method is a modified gram - schmidt orthogonalisation of @xmath91 , in which the next vector is computed by @xmath98 and where the coefficients @xmath99 are chosen such that the vectors come mutually orthonormal : @xmath100 from this condition we get @xmath101 the algorithm that facilitates this process is called _ arnoldi algorithm _",
    "@xcite .",
    "@xmath102 @xmath103 @xmath104 @xmath105 @xmath106 @xmath107 stop @xmath108    having basis vectors one can construct two linear solvers , which are described in the following .",
    "if we denote @xmath109 the matrix with elements @xmath110 , the result of arnoldi decomposition can be written in matrix form : @xmath111 approximate solution can also be written as @xmath112 for the residual error vector one can write : @xmath113 the galerkin approach requires the next residual to be orthonormal to all previous vectors @xmath114 which is @xmath115 using orthonormality of @xmath116 , @xmath117 one obtains the linear system @xmath118 note that @xmath109 is an upper hessenberg matrix and that the size of the problem depends on the value of @xmath119 , which is usually a much smaller than @xmath1 , the order of the original problem .",
    "arnoldi recurrences can be written also in the form : @xmath120 where now @xmath121 is an upper hessenberg @xmath122 matrix , or the matrix @xmath109 appended by the row @xmath123 . with this notations",
    "the residual error vector can be written as @xmath124 the minimal residual strategy of gmres @xcite requires that @xmath125 substituting @xmath126 and @xmath127 we get @xmath128 since @xmath129 is orthonormal , it can be ignored and we get the smaller least squares problem : @xmath130      in fact , the approximate solution in the krylov subspace @xmath131 can be described as a degree @xmath132 polynomial applied to @xmath60 : @xmath133 then , the residual vector is a degree @xmath119 polynomial applied to @xmath60 : @xmath134r_0\\\\ & \\equiv & r_k(d)r_0\\ .\\end{aligned}\\ ] ] hence , gmres solves the constrained minimisation problem : find the polynomial @xmath135 such that @xmath136 in fact , this is a characterisation of krylov subspace methods .",
    "one speaks of _ optimal polynomials _ generated in this way .",
    "... gmres requires to store all arnoldi vectors and its work grows proportionally to @xmath137 .",
    "one can limit this growth of resources by restarting the algorithm after a given number of steps . using this strategy ,",
    "robustness is lost and sometimes convergence as well . going back to normal equations , @xmath138 we know that the optimal polynomial is computed for @xmath139 and _ not _ for @xmath9 itself .",
    "however , computing resources remain constant in this case , an important advantage over gmres .",
    "therefore , a great deal of research has been devoted to methods which are as cheap as cgne and yet have similar convergence to gmres .",
    "one of these methods is the specialisation of the biconjugate gradients ( bicg ) algorithm in the case of the wilson operator , which is @xmath140-hermitian ( see @xcite p47 ) : @xmath141 the method , coined bicg@xmath140 , can be formally obtained from cg by inserting a @xmath140 operator whenever a scalar product occurs : @xmath142 since , @xmath140 is a nondefinite operator , this scalar product may not exist , and a premature breakdown may occur . in practice",
    "we see an irregular behaviour of the residual vector norm history .",
    "biconjugate grandients stabilised algorithm , or bicgstab @xcite replaces the redundant recursion of bicg for a local minimiser of the residual vector norm , thus giving a general and robust solver for non - hermitian systems .",
    "qcdlab is designed to be a high level language interface for lattice qcd computational procedures .",
    "it is based on the matlab and octave language and environment .",
    "while matlab is a product of the mathworks , octave is its clone , a free software under the terms of the gnu general public license .",
    "matlab / octave is a technical computing environment integrating numerical computation and graphics in one place , where problems and solutions look very similar and sometimes almost the same as they are written mathematically .",
    "main features of matlab / octave are :    * vast build - in mathematical and linear algebra functions . * many functions form blas , lapack , minpack , etc",
    ". libraries .",
    "* state - of - the - art algorithms .",
    "* interpreted language .",
    "* dynamically loaded modules from other languages like c / c++ , fortran . *",
    "ability to compile octave codes using the startego octave compiler , octave-compiler.org .",
    "hence , qcdlab offers a two level language system : a higher level language , which is very popular for numerical work and a lower level translation to c++ .",
    "in fact , if required the lower level can be further optimised for the particular hardware in place .    the first version of qcdlab is intended for work on the higher level only .",
    "qcdlab 1.0 contains the following matlab / octave functions :    we divide them in two groups : simulation and inversion algorithms .",
    "we begin below with the description of simulation algorithms .",
    "this section introduces qcdlab 1.0 simulation tools of lattice qed2 . in this case ,",
    "lattice gauge fields @xmath0 can be expressed using angles @xmath143 , @xmath144 whereas gauge action is given by @xmath145\\ , \\ ] ] where @xmath146 , and electron charge @xmath147 .      in case of wilson fermions",
    "the dirac operator is given by @xmath148\\ , \\ ] ] with @xmath149 being pauli matrices , @xmath150 qcdlab defines spin projection operators in terms of these matrices @xmath151 they are computed using this code :    .... % form spin projection operators p1_plus = [ 1,1;1,1]/2 ; p1_minus = [ 1,-1;-1,1]/2 ; p2_plus = [ 1,-i;i,1]/2 ; p2_minus = [ 1,i ;- i,1]/2 ; ....    given the quark mass , mass , the number of lattice sites along each direction , n , the total number of lattice sites , n2 , the gauge field configuaration , u1 , and spin projector operators as input , dirac_w returns wilson matrix , a1 :    .... a1=dirac_w(mass , n , n2,u1,p1_plus , p2_plus , p1_minus , p2_minus ) ; ....    for staggered fermions we have @xmath152 where @xmath153 dirac_ks below returns the staggered matrix :    .... a1=dirac_ks(mass , n , n2,u1 ) ; ....      in order to compute the force it is convenient to have ready a nearest neighbours list for each lattice site .",
    "the code that implement forward kp and backward km lists is given below .",
    ".... % make nearest neighbours list for j2=0:n-1 ; for j1=0:n-1 ;    k        = 1 +             j1 +             j2*n ;    kp(k,1 ) = 1 + mod(j1 + 1   , n ) +             j2*n ;    kp(k,2 ) = 1 +             j1 + mod(j2 + 1   , n)*n ;    km(k,1 ) = 1 + mod(j1 - 1+n , n ) +             j2*n ;    km(k,2 ) = 1 +             j1 + mod(j2 - 1+n , n)*n ; end end ....    in case of two degenerate wilson fermions , the force is given by @xmath154 where pseudofermion fields are two - component complex valued vectors .",
    "force_w returns both gauge pg and fermion pf pieces .",
    "its arguments are : number of lattice sites , n2 , forward neighbour list , kp , backward neighbour list , km , angles , theta1 , pseudofermion fields , eta , chi , gauge field , u1 , and spin projector operators .",
    ".... [ pf , pg]=force_w(n2,kp , km , theta1,eta , chi , u1,p1_plus , p2_plus , p1_minus , p2_minus ) ; ....    in case of four degenerate kogut - susskind fermions the force is @xmath155 where pseudofermion fields are complex values numbers . as in wilson case ,",
    "force_ks returns gauge pg and fermion pf forces .",
    ".... [ pf , pg]=force_ks(n2,kp , km , theta1,eta , chi , u1 ) ; ....      qcdlab s simulation tools are hmc_w and hmc_ks .",
    "their arguments are :    * iconf : set to zero for _ hot _ start , * theta1 : starting angles .",
    "on completion they return :    * a2 : dirac operator on theta2 background , * plaq : plaquette history , * q_top : topological charge history , * wloop : ten smallest wilson loops history , * theta2 : output angles , * stat : a four column array of metropolis test history .",
    "one trajectory of hybrid monte carlo algorithm consists of steps given in algorithm [ hmc_traj_algor ] .",
    "* heatbath update of pseudofermion fields phi = a1*eta0 ; * heatbath update of momenta p = randn(n2,2 ) ; * compute hamiltonian h1 .",
    "* invert dirac operator chi = a1`\\`eta0 ; * advance momenta half step p = p+pdot*deltat/2 ; * start molecular dynamics loop . *",
    "* advance angles full step theta2=theta2+p*deltat ; * * compute inversions eta = a2`\\`phi ; chi = a2`\\`eta ; * * advance momenta full step p = p+pdot*deltat ; * advance angles full step theta2=theta2+p*deltat ; * compute inversions eta = a2`\\`phi ; chi = a2`\\`eta ; * advance momenta half step p = p+pdot*deltat/2 ; * compute hamiltonian h2 . * perform metropolis test .    in case of a successful test ,",
    "the function computes topological charge , @xmath156 and @xmath157 wilson loops , @xmath158 hmc_w and hmc_ks functions are called in the form given below .    .... [ a2,plaq , q_top , wloop , theta2 , stat ] = hmc_w(theta1,iconf ) ; [ a2,plaq , q_top , wloop , theta2 , stat ] = hmc_ks(theta1,iconf ) ; ....      wloop returns ten smallest wilson loops .",
    "angles @xmath159 are implemented using arrays tleg1,tleg2 ... tlog10 .",
    "these are summed over to give arrays wleg1,wleg2 ... wlog10 .",
    "then , each of these arrays is used to compute the corresponding wilson loop around a square .",
    "the function is called using :    .... wlp = wloop(n , n2,kp , km , theta1 ) ; ....      when measuring an observable , such as plaquette , we get time series of data in the form @xmath160 .",
    "standard error estimation procedures rely on the assumption that data are _ decorrelated_.",
    "this can be checked by measuring the autocorrelation function @xmath161 where @xmath162 is called _ exponential autocorrelation time_. autocorel , which implements @xmath163 , has two arguments : the data vector , x , and the maximal time interval , t :    .... y = autocorel(x , t ) ; ....    in fact , a quick way to estimate the error is to block or ` bin ' data . in this case one",
    "computes block averages and estimates the error of averages for increasing block size .",
    "binning does exactly that .",
    "one must specify the original data , x , and the maximal block size , t. it returns a @xmath164-element vector err , containing error estimates for block sizes @xmath165 :    .... err = binning(x , t ) ; ....    a simple recipe is to take @xmath166 and choose the maximum value of err .",
    "the best way to test qcdlab capabilities is to set up a simple computing project like the following : _ compute square wilson loops and topological charge using hmc_ks .",
    "graph wilson loops as a function of the linear size .",
    "do you get a perimeter law ?",
    "plot the histogram of the topological charge . how is it distributed ?",
    "_    as usuall , one opens two windows , one running matlab / octave , and one text editor where hmc_ks.m file is located .",
    "we present here an exmaple of running octave with model and algorithmic parameters as in the listing . entering    .... [ a2,plaq , q_top , wloop , theta2,stat]=hmc_ks([],0 ) ; ....    one gets an output stream that looks something like :    .... ans =      3.00000    0.33333    0.57985   -1.25858   ans =      16.00000     0.12500     0.76736    -0.92516   ans =      20.00000",
    "0.15000     0.75921    -0.27965 ....    we have displayed here only the first three lines .",
    "columns of the stream display trajectory number , acceptance , plaquette and topological charge . one can store the angle output , theta2 , and feed it into the next run :    .... theta1=theta2 ; [ a2,plaq , q_top , wloop , theta2,stat]=hmc_ks(theta1,1 ) ; ....    in our example project we ran seven batches of hmc_ks and analysed results of the last batch .",
    "we computed and plotted autocorelation functions of five wilson loops :    .... auto = autocorel(wloop(:,1),20 ) ; semilogy(auto ) hold auto = autocorel(wloop(:,2),20 ) ; semilogy(auto ) auto = autocorel(wloop(:,3),20 ) ; semilogy(auto ) auto = autocorel(wloop(:,4),20 ) ; semilogy(auto ) auto = autocorel(wloop(:,5),20 ) ; semilogy(auto ) xlabel('t ' ) ylabel('autocorel ' ) replot gset terminal postscript gset out ' auto.ps ' replot gset terminal x11 hold",
    "....    then we computed central values of wilson loops :    .... w = mean(wloop ) ; ....    the errors are estimated using binning with the largest block size set to 10 :    .... sw = max(binning(wloop(:,1),10 ) ) ; sw=[sw , max(binning(wloop(:,2),10 ) ) ] ; sw=[sw , max(binning(wloop(:,3),10 ) ) ] ; sw=[sw , max(binning(wloop(:,4),10 ) ) ] ; sw=[sw , max(binning(wloop(:,5),10 ) ) ] ; sw=[sw , max(binning(wloop(:,6),10 ) ) ] ; sw=[sw , max(binning(wloop(:,7),10 ) ) ] ; sw=[sw , max(binning(wloop(:,8),10 ) ) ] ; sw=[sw , max(binning(wloop(:,9),10 ) ) ] ; sw=[sw , max(binning(wloop(:,10),10 ) ) ] ; ....    then , to plot wilson loops we entered :    .... semilogyerr(w(1:5),sw(1:5 ) ) hold axis([0,6,1e-4,1 ] ) semilogy(w(1:5 ) ) axis([0,6,1e-3,1 ] ) xlabel('linear size ' ) ylabel('wloop ' ) replot gset terminal postscript gset out ' wloop.ps ' replot gset terminal x11 hold ....    finally , to produce the histogram plot of topological charge is very easy :    .... hist(q_top,30 ) xlabel('q_top ' ) ylabel('frequency ' ) gset terminal postscript gset out ' q_top.ps ' replot gset terminal x11 hold ....      in this section we list qcdlab functions which implement basic krylov subspace inverters for use in lattice guage theories . in this version",
    "the whole matrix a , be it sparse or dense , should be supplied as an argument , together with the right hand side b , the approximate soluction x_0 , the tolerance tol and the maximum number of iterations nmax .",
    "cg.m and cgne.m functions below return solution x and _ recursive _ residual vector norm history rr .    ....",
    "[ x , rr ] = cg(a , b , x0,tol , nmax ) ; [ x , rr ] = cgne(a , b , x0,tol , nmax ) ; ....    fom.m and gmres.m return _ true _ residual instead of recursive residual and arnoldi matrix h as well . this can be used to compute approximate egienvalues of the original matrix @xmath64 .",
    ".... [ z , rt , h ] = fom(a , b , z0,tol , nmax ) ; [ z , rt , h ] = gmres(a , b , z0,tol , nmax ) ; ....      the bicgg5 function may be used for @xmath140-hermitian operators :    .... [ x , rr ] = bicgg5(a , b , x0,tol , nmax ) ; ....    it uses a special inner product , a pseudo - scalar which does not lead to a vector norm .",
    "hence , the algorithm can break down prematurely .",
    "there are _ look ahead _ strategies which cure this problem .",
    "we do nt employ them . however , to avoid a starting breakdown the recipe is to use a non - trivial initial solution .",
    "bicgstab is a general non - hermitian solver .",
    "it inherits from bicg the premature breakdown problem . in order to avoid a starting breakdown we use a random initial _ left lanczos vector _ y0 .    ....",
    "[ z , rr]=bicgstab(a , b , z0,tol , nmax ) ; ....      the counterpart of arnoldi algorithm for hermitian matrices is lanczos algorithm @xcite . from arnoldi",
    "algorithm we have @xmath167 if @xmath64 is hermitian we can write @xmath168 since @xmath109 is upper hessenberg and hermitian , it must be tridiagonal",
    ". it is commonly denoted by @xmath169 . this way ,",
    "after @xmath119 lanczos steps we have @xmath170 where @xmath171    qcdlab function lanczos arguments are matrix a , starting vector b and maximal number of steps nmax .",
    "it returns lanczos vectors q and matrix t :    .... [ q , t]=lanczos(a , b , nmax ) ; ....      in this section we illustrate qcdlab inverter functions for wilson fermions .",
    "the matrix @xmath64 , a function argument , is an output of hmc_w .",
    "having an angle configuration , one can generate it using dirac_r function : given the quark mass mass , the wilson parameter r , the lattice size n , the total number of lattice sites n2 , and the angle configuration theta1 as arguments , it returns the wilson - dirac matrix a1 :    .... a1=dirac_r(mass , r , n , n2,theta1 ) ; ....    note that knowing @xmath64 is not essential . indeed ,",
    "any user supplied procedure of matrix - vector multiplication can be called whenever = a * occurs in the function .",
    "future releases of qcdlab will provide capabilities that implement this .      in our example project here",
    ", we used an angle configuration on a @xmath172 lattice .",
    "we loaded this configuration and created a right hand side and a starting solution .",
    "then we generated three wilson - dirac matrices of three different fermion masses :    .... load theta16 n=16;n2=n^2;b = zeros(2*n2,1);x0=b;b(1)=1 ; a1=dirac_r(-0.1,1,n , n2,theta2 ) ; a2=dirac_r(-0.05,1,n , n2,theta2 ) ; a3=dirac_r(0,1,n , n2,theta2 ) ; ....    a first thing to do is to compute and plot eigenvalues of the massless operator :    .... e3=eig(a3 ) ; plot(e3,'o ' ) ....    in order to compare gmres and cgne convergence one calls respective solvers for each fermion mass as follows :    .... tol=1e-13;nmax=2*n2 ; [ x_gmres1,r_gmres1,h1 ] = gmres(a1,b , x0,tol , nmax ) ; [ x_gmres2,r_gmres2,h2 ] = gmres(a2,b , x0,tol , nmax ) ; [ x_gmres3,r_gmres3,h3 ] = gmres(a3,b , x0,tol , nmax ) ; [ x_cgne1,r_cgne1 ] = cgne(a1,b , x0,tol , nmax ) ; [ x_cgne2,r_cgne2 ] = cgne(a2,b , x0,tol , nmax ) ; [ x_cgne3,r_cgne3 ] = cgne(a3,b , x0,tol , nmax ) ; ....    then one plots the residual norm history as a function of matrix - vector multiplications calls :    .... k_gmres1=max(size(r_gmres1 ) ) ; k_gmres2=max(size(r_gmres2 ) ) ; k_gmres3=max(size(r_gmres3 ) ) ; k_cgne1=2*max(size(r_cgne1 ) ) ; k_cgne2=2*max(size(r_cgne2 ) ) ; k_cgne3=2*max(size(r_cgne3 ) ) ; semilogy(1:k_gmres1,r_gmres1,';gmres1 ; ' ) hold semilogy(1:k_gmres2,r_gmres2,';gmres2 ; ' ) semilogy(1:k_gmres3,r_gmres3,';gmres3 ; ' ) semilogy(1:2:k_cgne1,r_cgne1,';cgne1 ; ' ) semilogy(1:2:k_cgne2,r_cgne2,';cgne2 ; ' ) semilogy(1:2:k_cgne3,r_cgne3,';cgne3 ; ' ) xlabel ( ' # matrix - vector ' ) ylabel('residual norm ' ) replot gset terminal postscript gset out ' conv_hist.ps ' replot gset terminal x11 hold ....    note that gmres has an additional overhead which grows like @xmath173 , rendering the algorithm useless for large @xmath3 .",
    "hence , the gmres convergence , measured in terms of matrix - multiplication number , should be considered as a theoretically ideal result and a benchmark for the performance of short - recurrences algorithms .",
    "the difficulty of gmres exploding resources can be avoided using bicgg5 and bicgstab functions .",
    "employing the lightest mass one can compare convergence history of all solvers :    .... x0=rand(2*n2,1 ) ; [ x_gmres1,r_gmres1,h1 ] = gmres(a1,b , x0,tol , nmax ) ; [ x_cgne1,r_cgne1 ] = cgne(a1,b , x0,tol , nmax ) ; [ x_bicg1,r_bicg1 ] = bicgg5(a1,b , x0,tol , nmax ) ; [ x_bicgstab1,r_bicgstab1]=bicgstab(a1,b , x0,tol , nmax ) ; k_gmres1=max(size(r_gmres1 ) ) ; k_cgne1=2*max(size(r_cgne1 ) ) ; k_bicg1=max(size(r_bicg1 ) ) ; k_bicgstab1=2*max(size(r_bicgstab1 ) ) ; semilogy(1:k_gmres1,r_gmres1,';gmres1 ; ' ) hold semilogy(1:2:k_cgne1,r_cgne1,';cgne1 ; ' ) semilogy(1:k_bicg1,r_bicg1,';bicg1 ; ' ) semilogy(1:2:k_bicgstab1,r_bicgstab1,';bicgstab1 ; ' ) xlabel ( ' # matrix - vector ' ) ylabel('residual norm ' ) replot gset terminal postscript gset out ' all_solver_conv_hist.ps ' replot gset terminal x11 hold ....    as seen from the plot , the best short - recurrences solver ( for this particular example ) is bicgg5 .",
    "it converges at about the same matrix - vector multiplications as gmres and yet avoiding its pitfalls .",
    "its irregular convergence history can be softened to the level of bicgstab using the _ quasiminimal residual approach _ , or qmr algorithm , which is not described here .",
    "staggered operator is anti - hermitian as can be illustrated below : first create the staggered matrix ; then typing norm(a+a ) , the answer will be zero .",
    "since i*a is hermitian , its eigenvalues will be real .",
    "we plotted the eigenvalues as sorted from the eig function .    ....",
    "u1=cos(theta2)+sqrt(-1)*sin(theta2 ) ; n=16;n2=n^2 ; a = dirac_ks(0,n , n2,u1 ) ; norm(a+a ' ) ea = eig(i*a ) ; plot(ea,'o;ea ; ' ) ....    theory tells that for normal matrices , such as staggered operator , cgne is an optimal solver .",
    "the following plot compares gmres and cgne convergence history as a function of matrix - vector multiplications counter .    ....",
    "b = zeros(n2,1);x0=b;b(1)=1 ; tol=1e-13;nmax = n2 ; [ x_gmres , r_gmres , h ] = gmres(a , b , x0,tol , nmax ) ; [ x_cgne , r_cgne ] = cgne(a , b , x0,tol , nmax ) ; k_cgne = max(size(r_cgne ) ) ; semilogy(r_gmres,';gmres ; ' ) hold semilogy(1:2:2*k_cgne , r_cgne,';cgne ; ' ) xlabel ( ' # matrix - vector ' ) ylabel('residual norm ' ) replot gset terminal postscript gset out ' conv_hist_ks.ps ' replot gset terminal x11 hold ....      as another application , one can use lanczos algorithm to solve the linear system @xmath174 for wilson matrix @xmath9 . taking the lightest mass from the previous exmaple and setting maximal iteration number to k_cgne3 :    .... [ q , t]=lanczos(a3'*a3,a3'*b , k_cgne3 ) ;",
    "....    one can construct the solution using :    .... x_lanczos3=q(:,1:k_cgne3)*(t\\[norm(a3'*b);zeros(k_cgne3 - 1,1 ) ] ) ; ....    comparison to x_cgne3 yields :    .... norm(x_cgne3-x_lanczos3 ) ans =   2.5537e-14 ....    this example illustrates the theoretical result that cg and lanczos algorithms are equivalent linear solvers in exact arithmetic .      in this section",
    "we describe qcdlab functions for use with lattice chiral fermions .",
    "a chiral lattice dirac operator satisfies the gisnparg - wilson relation @xcite : @xmath175 one solution to this relation is the nueberger overlap operator @xcite , @xmath176 where @xmath177 is the signum function , @xmath178 . for the signum function to be nontrivial , the wilson - dirac operator should be indefinite , which is the case if its bare mass @xmath179 is sufficiently negative .",
    "this is usually taken to be in the interval @xmath180 .",
    "another form of the neuberger operator is @xmath181 if we express @xmath182 in terms of its singular values and vectors , @xmath183 we get @xmath184 since @xmath185 and @xmath186 are unitary operators , so it is @xmath187 . hence , the overlap operator is a shifted unitary operator .",
    "iterative inverters for such operators can be simplified as we show below . before doing this",
    "we give an iterative method in order to compute the overlap operator .      in order to apply the overlap operator to a vector @xmath58",
    "one should first perform the inversion @xmath188 and then apply @xmath182 to x. the calculation is based on the following integral representation for the inverse square root @xcite : @xmath189 from the previous section we know that one can use the lanczos algorithm to solve the linear systems , such as @xmath190 where @xmath191 . since by shifting the matrix @xmath192 one obtains the same lanczos vectors , we can write @xmath193 using the above integral representation again , but now for lanczos matrix @xmath169 we get @xmath194 to summarise , in order to find @xmath90 one computes :    * @xmath116 and @xmath169 using the lanczos function on @xmath192 and @xmath58 , * then computes @xmath195 , * and finally @xmath196 .    using the a3,b pair of the last example one can enter these commands :    .... b = rand(2*n2,1 ) ;",
    "rho = norm(b ) ; [ q , t]=lanczos((a3-eye(512))'*(a3-eye(512)),b,200 ) ; [ n , k]=size(q ) ; e1=zeros(k-1,1 ) ; e1(1)=1 ; y = sqrtm(t)\\e1*rho ; x=(a3-eye(512))*q(:,1:k-1)*y ; ....    in case",
    "@xmath116 vectors are too large to be stored in the main memory of the computer , one can modify lanczos such that it does not accumulate lanczos vectors into q. in this case , one calculates @xmath197 and then repeats the lanczos iteration in order to form @xmath90 .",
    "this is the so called _ double pass algorithm_.    for small problems , as it is usually the case for qed2 on the lattice , one can compute the overlap operator using the singular value decomposition :    .... [ u_w , s_w , v_w]=svd(a3-eye(512 ) ) ; v = u_w*v_w ' ; z = v*b ; norm(z - x ) d = eye(512)+v ; eigd = eig(d ) ; plot(eigd,'+ ' ) ....    in this case it is easy to compute @xmath9 eigenvalues using direct methods , such as eig function .",
    "the following plot shows the eignevalues of the massless overlap operator @xmath9 .",
    "having computed @xmath9 the next step is its inversion . before discussing this , we note that @xmath139 is optimally inverted using the ggne algorithm , the reason being the normality of @xmath9 , i.e. @xmath198 . hence , for dynamical fermion simulations , which require @xmath139 inversions , cgne is the prefered method . for propagator calculations the situation is less clear .",
    "this has to do with differing spectral properties of @xmath139 and @xmath9 .",
    "we know that gmres is the optimal method for non - hermitian operators .",
    "we know also that gmres requires very often prohibitive computer resources .",
    "however , for unitary matrices one can do better . exploiting this fact",
    ", one can construct the sumr or the shifted unitary minimal residual algorithm @xcite , which is charaterised by short - recurrences and at the same time benefit from the optimal properties of gmres :    .... [ rr , x ] = sumr(b , v , rho , zeta , tol , imax ) ; ....      we know that the fom is the counterpart of gmres for the galerkin approach to linear system solvers .",
    "likewise one can construct the counterpart of sumr for shifted unitary systems .",
    "this can be done using a new arnoldi process for unitary matrices , the arnoldi unitary process . in the coupled recurrences variant ,",
    "the search directions of the algorithm are _",
    "semiconjugate_. therefore , the algorithm is called the semiconjugate gradients ( scg ) algorithm @xcite :    .... [ x , rr ] = scg(a , b , x0,tol , nmax ) ; ....      in this section we compare cgne , sumr and scg algorithms in the same background u(1 ) gauge field as before and the same wilson - dirac matrix a3 :    .... m=0.0001 ; d=(1+m)/2*eye(512)+(1-m)/2*v ; b = zeros(512,1);b(1)=1 ; [ x , rr ] = cgne(d , b , zeros(512,1),1e-12,200 ) ; semilogy(1:2:2*max(size(rr)),rr,'-;cgne ; ' ) hold [ x , rr ] = scg(d , b , zeros(512,1),1e-12,200 ) ; semilogy(rr,'-.;scg ; ' ) [ rr , x ] = sumr(b , v,(1+m)/2,(1-m)/2,1e-12,200 ) ; semilogy(rr,':;sumr ; ' ) xlabel ( \" # matrix - vector \" ) ylabel(\"residual norm \" ) replot gset terminal postscript gset out \" gw_conv_hist.ps \" replot gset terminal x11 hold ....    the result of this comparison is shown in the following figure .",
    "one observes the optimal properties of sumr , as expected .",
    "we note that scg is doing worse at the begining until it reaches the asymtotic regime of sumr .",
    "both sumr and scg are 25% faster then cgne .",
    "in the previous sections we described version 1.0 of qcdlab . its simulation functionality is limited to the qed2 on the lattice , a very good laboratory for algorithmic and ideas exploration in lattice qcd .",
    "we plan to extend functionality of qcdlab 1.0 further .",
    "we are in the designing phase of qcdlab 2.0 which will be totaly devoted to lattice qcd simulation .",
    "the gross features of this future version are expected to be :    * dynamically linked functions to already exsisting procedures in other languages .",
    "* ability to compile matlab / octave codes using the startego octave compiler , octave-compiler.org .",
    "* scalability on various computing platforms using the above compiler . *",
    "extended functionality , in particular simulation functions for lattice qcd and matrix - vector multiplication procedures for various fermion operators ."
  ],
  "abstract_text": [
    "<S> this paper introduces qcdlab , a design and research tool for lattice qcd algorithms . </S>",
    "<S> the tool , a collection of matlab functions , is based on a `` small - code '' and a `` minutes - run - time '' </S>",
    "<S> algorithmic design philosophy . </S>",
    "<S> the present version uses the schwinger model on the lattice , a great simplification , which shares many features and algorithms with lattice qcd . </S>",
    "<S> a typical computing project using qcdlab is characterised by short codes , short run times , and the ability to make substantial changes in a few seconds . </S>",
    "<S> qcdlab 1.0 can be downloaded from the qcdlab project homepage http://phys.fshn.edu.al/qcdlab.html . </S>"
  ]
}