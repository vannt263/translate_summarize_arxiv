{
  "article_text": [
    "determining the degree of anisotropy in the sky distribution of astronomical objects , background radiation fields , and transient events is often key in unveiling the hidden nature of an astronomical phenomenon .",
    "a number of tests for particular anisotropic patterns are available in the literature such as spherical harmonic decomposition , tests for specific angular scale fluctuations ( multipole - specific tests ) , 2pt correlation function , high - order correlation functions , and so forth .",
    "different types of tests are more useful depending on the character of the anisotropy .",
    "some areas of astronomical study are characterized by small fluctuations on a largely isotropic background ( such as the cosmic microwave background , e.g. , @xcite ; the large - scale structure of galaxy distributions , e.g. , @xcite ; neutrino astronomy , e.g. , @xcite , and the extragalactic gev gamma - ray background , e.g. , @xcite ) , while other areas see deviations from isotropy with very sparsely populated datasets ( such as the sky distribution of pulsars , e.g. , @xcite ; gamma - ray bursts before the compton gamma - ray observatory , e.g. , @xcite ; and the current data on trans - gzk ultra - high energy cosmic rays , e.g. , @xcite ) .",
    "here we focus on a new method designed for the sparsely sampled type of datasets .",
    "this case is often challenging as with small datasets false positives are easier to encounter , and guarding against them by increasing the test significance when a signal is treated as real or at least interesting reduces the power of the tests ( an extreme example : the single - point dataset is maximally anisotropic , yet fully consistent with isotropy ! ) .",
    "one way that has been used to overcome these difficulties is to use insight and guidance from theoretical expectations to define appropriate tests for very specific types of anisotropy expected out of a dataset , for example tests that look for distributions of datapoints that follow the distribution of known catalogs ( e.g. , @xcite ) .",
    "however , one would like to define a test that would be `` democratic '' in its treatment of angular scales , `` free '' of any underlying assumption about the type of anisotropy , and as powerful as possible",
    ". clearly not all requirements above can be maximized at the same time , so what we propose here is a reasonable compromise .    in this work we present a statistical test which aims to quantify , in a manner as general as possible , how ( in)frequently a particular realization of the positions of @xmath0 points on a sphere arises from isotropy ( i.e. , from an underlying spatial distribution with a flat probability density function ) .",
    "the outcome of the proposed test for a particular `` observed '' data set will be a significance , expressing the fraction of datasets of @xmath0 points drawn from an isotropic distribution that returns a value for the estimator ( test statistic ) which is equally or more rare than the ",
    "observed one , in the limit that the experiment is repeated @xmath1 times .",
    "if this fraction is very low , then the observer can claim either that the `` observed '' dataset is a very rare realization of isotropy , or that the underlying _ ansatz _ of isotropy is not valid .    for the purposes of this test ,",
    "quantitatively _ model isotropy on a sphere as follows : when @xmath0 points are drawn from an isotropic distribution on a sphere , then the probability points . ] that @xmath2 points out of the total @xmath0 lie within the boundaries of an arbitrary surface ( @xmath3 ) follows the binomial distribution : @xmath4 where @xmath5=@xmath6 , and @xmath7 is the surface of the sphere ( 4@xmath8 for the sphere of radius 1 ) .",
    "our aim is to build a test that is comparably sensitive to fluctuations on a wide range of angular scales , for @xmath0 as low as @xmath9 up to a maximum value limited by the available computing power ( currently , computations for @xmath0 as high as @xmath10 are accessible using a desktop computer ) . to check the sensitivity of the test we use mock anisotropic realizations sampled from a",
    "_ small _ number of equal flux point sources distributed isotropically and spherical harmonics with _ low _ multipole moment , l. the test is expected to be sensitive in the case of mock maps drawn from a small number of point sources ( which have power on small angular scales ) and also for distributions with low multipole moments ( which have power on large angular scales ) .",
    "these two cases cover the two extremes of fluctuations when classified in angular scale .",
    "another commonly used statistical test for small datasets is based on the two - point ( 2pt ) correlation function . for this test , the angular distances between pairs of points are calculated , and some measure of the deviation of their distribution from what is expected from isotropy is used as an estimator .",
    "the distribution of angular distances between 1225 pairs ( @xmath11 ) drawn from an isotropic distribution ( test repeated for 1000 realizations ) is shown in the left panel of fig .",
    "[ alpha ] . here , @xmath12 is the angular distance between two points in rad , while the number of pairs for a data set of @xmath0 events is @xmath13 .",
    "higher correlation functions can also be calculated , but it is not straightforward to extract the independent information contained in these higher order terms . instead , here we build upon the 2pt test , by considering two new variables in addition to @xmath12 , which are also related to pairs of points but are _ uncorrelated _ with @xmath12 .",
    "the additional information used in this 2pt test motivates the name 2pt+ .",
    "( left panel ) and @xmath14 ( right panel ) in 1000 realizations of 50 events ( 1225 pairs ) drawn from isotropy .",
    "the values of @xmath14 are consistent with originating from a uniform distribution . , width=528 ]",
    "fig . [ coordinatescheme ]",
    "schematically depicts the definitions of the variables that we use in this work .",
    "the left panel shows the vector between two points on a sphere , subtending an angle @xmath12 , which we aim to describe using three independent variables .",
    "there is an intrinsic degeneracy in the definition of this vector , as either one of the points in the pair can be regarded as the vector origin . in this work",
    ", we always choose the point of origin so that the @xmath15component of the vector is positive .",
    "the vector between two events translated to the origin of coordinates , can be described using the following 3 variables as in the right panel of fig .",
    "[ coordinatescheme ] :    1 .",
    "@xmath14 , which is a measure of the length of the vector ; 2 .",
    "@xmath16 , which is the cosine of the vector s polar angle ; and 3 .",
    "@xmath17 , which is the vector s azimuthal angle .",
    "the distribution of the values of these variables for 1000 realizations of 50 events and 1225 pairs drawn from an underlying isotropic spatial distribution is shown in the right panel of fig .",
    "[ alpha ] and in fig .",
    "[ betagamma ] .",
    "these plots show that the frequency distribution of the three variables is consistent , to the accuracy of our testing , with being uniform ( equal fraction of draws for all bin values ) .",
    "the two new variables introduced here in addition to the angular distance between pairs ( @xmath16,@xmath17 ) are sensitive to the orientation of the pairs and therefore to features in the sky that have preferential directions , such as a plane in the sky , a network of overdense regions , and filamentary structures .     between two events .",
    "here , the drawn sphere corresponds to the observed celestial sphere .",
    "the black vectors correspond to vectors extending from the origin ( observer ) to each of the two events .",
    "the blue vectors represent the two choices for the definition of the vector _ between _ events . in this work",
    ", we always use the vector with a positive @xmath15component ( in the case depicted here , the vector pointing from right to left ) .",
    "@xmath12 is the angle subtended by the two event vectors .",
    "right panel : angles @xmath18 and @xmath17 . here ,",
    "the vectors _ between _ events have been transported to the origin , and each of the two vectors corresponds to a different pair between events .",
    "the length of each vector depends on @xmath12 , so the radii of the two spheres drawn here quantify the angular distance between each pair of events .",
    "the angles @xmath18 and @xmath17 for one of the pairs ( the one represented by the blue vector ) are shown in the figure .",
    ", width=528 ]     ( left panel ) and @xmath17 ( right panel ) in 1000 realizations of 50 events ( 1225 pairs ) drawn from isotropy .",
    "the values of both quantities are consistent with originating from uniform distributions.,width=528 ]    fig .",
    "[ corr ] shows two - dimensional histograms of the values of our three variables in pairs of two , for draws from isotropy . in this way",
    ", we visualize any potential correlation between each pair of our three variables , when averaged over many realizations , which is clearly very small .",
    "the lack of correlation between @xmath14 and our two additional variables , @xmath16 and @xmath17 , implies that the two new variables encode independent information that we add to the power of the standard two - point correlation function by incorporating them into our estimator .",
    "in addition , the lack of correlation between the two variables indicates that each brings to the test independent pieces of information , and the power of the test is maximized by incorporating both .",
    "-@xmath16 , @xmath14-@xmath17 and @xmath16-@xmath17 values for draws from isotropy .",
    "no apparent pattern or correlation between any of the variable pairs is seen .",
    ", width=528 ]    however , it should be noted that there is a major difference between @xmath14 and ( @xmath16,@xmath17 ) : the set of @xmath14 values for a data set is independent of the reference system in which it is calculated , while the values of ( @xmath16,@xmath17 ) are not .",
    "any reference system on the sphere is related to each other through a rotation and any statistical test should be invariant under rotations . if we consider a particular data set in the plane ( @xmath16,@xmath17 ) ( right panel in fig .",
    "[ corr ] ) , a rotation is a one - to - one mapping , and neighbouring points remain neighbouring ( and their angular distances remain unchanged ) after the transformation .",
    "therefore , to minimize any possible dependence on rotations we adopt the following strategy : first , a binned likelihood test is applied to assess the flatness of the @xmath14 distribution , and a significance ( @xmath19 ) is obtained from it .",
    "then , a second binned likelihood test is applied to assess the flatness of the distribution in the ( @xmath20,@xmath17 ) plane , obtaining a significance @xmath21 .",
    "the two significances are combined using fisher s method .",
    "any remaining dependence on rotations will be quantified below .",
    "to calculate @xmath19 and @xmath21 , binned likelihood estimators are used . a data set with @xmath0 events",
    "is a collection of @xmath22 values of @xmath14 and ( @xmath23,@xmath17 ) . since the distributions are flat , if we divide the phase space into equal parts we expect on average the same number of events in each one .",
    "in the case of @xmath14 we divide the phase space ( -1,1 ) into equal parts in such a way that the expected number of events for each bin is @xmath24 ( thus , the number of bins @xmath25 is the integer closest to @xmath26 ) .",
    "a similar approach is used for the ( @xmath16,@xmath17 ) plane , but since this is a two dimensional distribution , the number of bins in each axis is the integer closest to @xmath27 .",
    "the two pseudo - likelihood estimators are defined as follows : @xmath28 where @xmath29 ( @xmath30 ) is the poisson distribution with mean @xmath24 and @xmath31 ( @xmath32 ) observed number of pairs in the @xmath33 @xmath14 bin ( @xmath34 ( @xmath23,@xmath17 ) bin ) .",
    "we have verified through monte carlo simulations that the distribution in each bin is sufficiently similar to poisson .",
    "[ iso - estimators ] shows the distribution of the two estimators for an isotropic distribution with @xmath0=50 and @xmath24=5 .",
    "it should be noted that the number of factors entering the calculation of @xmath35 and @xmath36 ( see eq . [ eqnestim ] ) are the same .",
    "therefore , if each one is completely independent from each other , the distribution of the two estimators should be the same .",
    "this is not the case , reflecting correlations introduced when considering event pairs as the observable instead of the individual points on the sphere .",
    "the small correlations can be easily corrected for as we discuss below ( see fig .",
    "[ iso - sgf ] ) .",
    "( solid line ) and @xmath36(dotted line ) , for event draws from an isotropic distribution .",
    "if the two estimators were truly independent , the distributions would be identical .",
    "small correlations are introduced by considering pairs instead of events on the sphere , causing the deviation of their fisher - combined significance from a random variable uniformly distributed between 0 and 1 , as seen in fig .",
    "[ iso - sgf ] .",
    ", width=336 ]    to calculate the significance for a given realization , we integrate the normalized distributions in fig .",
    "[ iso - estimators ] , obtaining @xmath19 and @xmath21 .",
    "if these significances quantify _ truly independent experiments _ , the combined significance can be calculated analytically using fisher s method .",
    "the method suggests that if 2 independent tests , each yielding a significance ( p - value ) , @xmath19 and @xmath37 , are combined , then the variable @xmath38 is distributed as chi - square with @xmath39 degrees of freedom , and the combined significance can be obtained by integrating under the tail of this distribution above its `` observed '' value defined by the two individually measured significances .",
    "the probability distribution function ( pdf ) of the chi - square with 4 degrees of freedom , if the random variable is @xmath40 , is @xmath41/4 $ ] , and the significance for an observed value @xmath42 ( i.e. , the pdf integral for @xmath40values above @xmath42 ) is @xmath43\\,.\\ ] ] substituting @xmath44 we get @xmath45 this is simply the probability that the product of two random variables uniformly distributed between ( 0,1 ) is smaller or equal than the observed product .    the left panel in fig .",
    "[ iso - sgf ] shows the distribution of log@xmath46 ( solid histogram ) together with the distribution of log@xmath47 ( dotted histogram ) , where @xmath48 is a random number between ( 0,1 ) .",
    "deviations for significances smaller than 10@xmath49 are apparent and caused by a small correlation between @xmath35 and @xmath36 . the combined significance @xmath50 is then corrected using monte carlo calculations .",
    "the distribution of the corrected significance , @xmath51 , is shown in the right panel of fig .",
    "[ iso - sgf ] , and is indeed consistent with a uniform distribution .",
    "( solid line ) compared with the expected distribution if the two estimators are completely independent ( dotted line ) .",
    "right panel : the distribution of @xmath51 for 50 events and @xmath24 = 5.,width=528 ]      the least straight - forward part in a binned likelihood is setting the value of @xmath24 to be used , i.e. , the bin size .",
    "if we have @xmath0 random numbers distributed between 0 and 1 , the maximum number of independent questions to be asked is @xmath0 .",
    "therefore , the number of bins should be smaller than @xmath0 , i.e. , @xmath24 ( the expectation value for points per bin ) should be equal to or larger than 1 . in the present case ,",
    "since @xmath0 is the number of pairs and enhanced correlations are present , @xmath24 should be clearly larger than 1 .",
    "a binned likelihood test is only sensitive to fluctuations at scales larger than the bin size .",
    "that is the reason why the bin size should be kept as small as possible when there is no _ a priori _ reason setting a lower - limit to its size .",
    "however , the sensitivity to fluctuations at increasingly larger scales decreases because the information about coherent fluctuations of bins is lost in the binned likelihood method .",
    "a possible approach is to modify the binned likelihood to include the information about correlations between bins .",
    "however , in this work we adopt a more conservative approach : we keep the bin size as low as possible and consider the resulting sensitivity as a _ lower bound _ to what can in principle be achieved .",
    "to select the minimum reasonable @xmath24 , we generate mock anisotropic realizations of 50 events sampled from : a ) @xmath52 point sources isotropically distributed , and b ) multipoles with low values of l. each case is evaluated 5000 times and each time @xmath19 , @xmath21 and @xmath53 are calculated .",
    "we use the fraction of realizations with a significance smaller than 10@xmath49 ( hereafter @xmath54 ) as a measure of the sensitivity to each case .",
    "is used to calculate the significances .",
    "results shown are for @xmath55 and @xmath56 .",
    "the solid curve is for 25 events from 20 equal flux point sources isotropically distributed over a 50% isotropic background ( i.e. , 25 isotropic events ) .",
    "the dashed line is for a dipole with 20% ( i.e. , 10 events ) of the events from an isotropic background.,width=432 ]    fig .",
    "[ smearing ] shows @xmath54 for two cases with @xmath55 : the solid line is for 20 equal flux point sources distributed isotropically with 50% isotropic background ( i.e. , 25 events from point sources and 25 events from the background ) ; while the dashed line shows events sampled from a spherical harmonic , @xmath57 , with ( l , m)=(2,0 ) with 20% ( 10 events ) from an isotropic background .",
    "each event is smeared with a gaussian distribution of variable width indicated in the @xmath58 axis .",
    "this smearing is representative of the angular resolution of the experiment ( or physical smearing , e.g. , due to lensing ) .",
    "the value of @xmath54 is calculated using only @xmath19 .",
    "it is clear from the multipole case that if the anisotropy manifests itself at angular scales larger than the smearing angle , the sensitivity of the test does depend on the smearing .",
    "the dependence is strong in the case of point sources .",
    "realizations of isotropy would correspond to a flat line with @xmath54=@xmath59 , i.e. , outside of the range shown .",
    "the value of @xmath24 used is 5 , showing that for this particular value we are sensitive to fluctuations at very different angular scales .",
    "( see text ) to calculate @xmath35 .",
    "results shown are for @xmath55 .",
    "left panel shows @xmath54 from @xmath19 as a function of smearing angle of 20 point sources for @xmath24= 3 ( solid ) , 5 ( dashed ) , and 10 ( dotted ) .",
    "right panel shows @xmath54 from @xmath19 as a function of @xmath24 for spherical harmonics with ( l , m)=(1,0 ) solid , ( 2,0 ) dashed , and ( 4,0 ) dotted lines.,width=528 ]     from @xmath21 as a function of @xmath24 for spherical harmonics with ( l , m)=(1,0 ) solid , ( 2,0 ) dashed , and ( 4,0 ) dotted lines .",
    "results shown are for @xmath55.,width=432 ]    the left panel in fig .",
    "[ binning1 ] shows @xmath54 as a function of the smearing angle for 3 choices of @xmath24 ( 3 , 5 , and 10 ) , where only @xmath19 is used to calculate @xmath54 .",
    "the mock samples correspond to 20 point sources and 50% isotropic background .",
    "the trend is clear : for larger smearing angles , larger values of @xmath24 lead to increasing sensitivities .    the right panel in fig .",
    "[ binning1 ] shows @xmath54 calculated with @xmath19 as a function of @xmath24 for realizations sampled from multipoles with different values of ( l , m ) .",
    "( in the figure ( l , m ) is ( 1,0 ) for the solid line , ( 2,0 ) for the dashed line and ( 4,0 ) for the dotted line respectively ) .",
    "the sensitivity increases for values of @xmath24 between 3 and 10 and is roughly constant after that .",
    "[ binning2 ] shows @xmath54 as a function @xmath24 for realizations sampled from the same multipoles as in the right panel of fig .",
    "[ binning1 ] .",
    "this time @xmath21 is used to calculate @xmath54 .",
    "the dependence on @xmath24 is also mild above 5 .    after this exercise ,",
    "it is clear that @xmath24=5 is a rather conservative value to be used either for @xmath14 or ( @xmath60 ) , and it is the one used in this work from now on .",
    "we are currently developing an unbinned likelihood estimator that bypasses the problem of selecting @xmath24 .",
    "the results of this analysis will be reported in a future publication .      as discussed above ,",
    "the set of ( @xmath60 ) values depends on the coordinate system used to evaluate them . to check the sensitivity of the test to the coordinate system",
    ", we calculate @xmath21 using a reference coordinate system @xmath61 and another , randomly chosen coordinate system @xmath62 . fig .",
    "[ rot ] shows the result for realizations sampled from a multipole with ( l , m)=(2,0 ) .",
    "the two significances are not numerically equal , however they show excellent correlation with a spread in log@xmath63 of @xmath64 .",
    "this spread , when propagated to the final significance @xmath53 is further reduced ( to @xmath65 ) .",
    "so we can conclude that the dependence on the chosen coordinate system in not very significant .    .",
    "left panel : correlation between @xmath21 calculated in each coordinate system .",
    "right panel : distribution of the dispersion of the two significances around the diagonal.,width=528 ]",
    "[ dim ] shows the sensitivity of the test as a function of the number of events in the sphere for 4 anisotropic cases .",
    "three spherical harmonics with 20% isotropic background are shown ( ( l , m ) = ( 1,0 ) solid , ( 2,0 ) dashed , ( 4,0 ) dotted lines ) and the case of 20 point sources with 50% background is shown in the dot - dashed line .",
    "the evolution of @xmath54 is different for different cases but in all of them there is an increase of sensitivity when the number of events is increased .",
    "the test seems to show good sensitivity for number of events between 25 and 100 with anisotropies at rather different angular scales .",
    "[ enhance ] demonstrates the sensitivity improvement of the 2pt+ test with respect to the standard 2pt test , which only considers information encoded in @xmath12 . in this figure",
    "we logarithmically plot , for a low - multipole underlying distribution ( l , m = 2,0 ) over a 20% isotropic background , the significance using information in @xmath12 alone , @xmath19 , as a function of @xmath51 for the same realization .",
    "the experiment is performed for @xmath11 and with a bin size @xmath56 .",
    "we see that @xmath19 is in almost all cases higher ( worse ) than @xmath50 .",
    "the 2pt+ test is systematically more sensitive than the 2pt test for this type of anisotropy .     alone ) , for a low - multipole ( l=2 ) anisotropy with a 20% isotropic background .",
    "each realization corresponds to @xmath11 and @xmath56.,width=432 ]    fig .",
    "[ vcv_sens ] similarly demonstrates the sensitivity improvement of the 2pt+ over the standard 2pt test for a type of anisotropy motivated by recent results from the pierre auger observatory on the sky distribution of events with energies above @xmath66 ev @xcite .",
    "the distribution of the 27 highest energy events were found to depart from isotropy through a test which shows a correlation of ultra - high energy cosmic ray events with nearby active galactic nuclei ( agn ) selected from the veron - cetty & veron catalog of quasars and active galactic nuclei ( 12th ed . )",
    "@xcite ( vcv ) with redshift @xmath67 and a gaussian 3.2 degree smearing .",
    "this recent result is one of the most prominent cases of sparsely - sampled datasets that need to be tested for compatibility with an isotropic distribution on the sky , and a natural application for the 2pt+ test .    on the left panel of fig .",
    "[ vcv_sens ] , the 2pt+ and the classic 2pt ( here implemented using @xmath19 alone ) are shown for a mock catalog with varying number of events ( from 20 to 60 ) drawn from the vcv catalog of agn with the same parameters chosen by the auger results .",
    "the right panel shows the same functions for the same catalog plus an isotropic background with 50% of the events .",
    "the black and blue solid lines correspond to the median significance of the 2pt and 2pt+ tests as a function of @xmath0 respectively , while the bands around these lines correspond to the behavior of @xmath68 of sets around the median . in both cases the test performs better than the classic 2pt test .",
    "the relative improvement _ increases _ with increasing number of events .",
    "in addition , in the case where the anisotropic signal is added to a 50% isotropic background ( lower panel ) , the median significance of the 2pt+ test reaches sub - percent levels above 100 events , while hardly any overall improvement in significance is seen with the 2pt test : for the case of a mild signal over a substantial isotropic background , the 2pt+ test can pick up the deviation from isotropy with samples so sparse that the 2pt test would show no sensitivity whatsoever .    finally , in fig .",
    "[ vcv_dist ] we plot , for @xmath69 and for the signal corresponding to the lower panel of fig .",
    "[ vcv_sens ] , a histogram of the significance values returned for different realizations of the specific experiment by the 2pt ( black line ) and the 2pt+ ( red line ) tests : not only is the peak ( most frequent ) significance of the 2pt+ test translated to smaller values compared to the 2pt test , but also the very - low - value tails are systematically more populated .          and 3.2 deg smearing angle , summed to 50% isotropic component , and taking into account the auger south exposure . , width=288 ]",
    "the test can be also used to reject a hypothesis other than isotropy .",
    "quantitatively , any hypothesis can be expressed as a probability density function @xmath70 where @xmath71 and @xmath72 are the polar angles on the sphere . for a sphere of unit radius and",
    "the isotropic ansatz the probability density function is : @xmath73 .",
    "if the underlying probability density function is not flat , correlations between @xmath14 , @xmath16 and @xmath17 would appear , complicating the implementation of the test .",
    "our proposed approach to deal with non - flat distributions is to apply a change of coordinates to a reference system for which @xmath73 . for any hypothesis , a point on the sphere @xmath74",
    "is mapped into another position on the sphere with the following polar coordinates : @xmath75 this transformation has the following nice property : if we have @xmath0 points on the sphere , we can draw @xmath0 parallels and meridians in such a way that each one passes through a point .",
    "this determines a grid on the sphere .",
    "the transformation proposed deforms the grid , changing the area of each cell , but introduces no caustics .",
    "this transformation effectively separates ( brings closer together ) the points in overdense ( underdense ) regions of the sphere .",
    "this approach is simple and general , and overcomes the difficulties of dealing with each case in particular .",
    "we recommend the use of this approach even when the sphere is not complete .",
    "we have presented a novel statistical test optimized for testing sparsely sampled datasets ( with as few as 20 datapoints ) for compatibility with an isotropic distribution on the sky .",
    "the test is an enhanced version of the classic 2pt test , incorporating all the information utilized in the 2pt test ( the angular distances between events , or , equivalently , the _ length _ of the vector connecting event pairs ) , as well as additional , independent information about the _ orientation _ of each vector connecting event pairs .",
    "we call this new test the 2pt+ test .",
    "we propose here a specific method for the implementation of this test , based on distinct pseudo - likelihood estimators on a binned parameter space .",
    "the individual significances from each estimator are then combined using fisher s method .",
    "because of small correlations introduced by working in pair space rather than event space , the resulting quantity is not uniformly distributed as required for a true significance , so the final result we quote as significance is first corrected ( its distribution is first rendered uniform ) by monte - carlo simulations .",
    "we additionally discuss a proposed methodology for utilizing the 2pt+ test to assess the compatibility of an event set with a distribution different from isotropy .",
    "we have tested the behavior of the test as a function of parameter space binning , number of events , and type of anisotropy . based on these tests ,",
    "we recommend a binning choice of @xmath76 .",
    "the sensitivity of the test increases with increasing number of events , and , depending on the type of anisotropy , the method can saturate to significances better than @xmath59 for as few as 60 events .    we have also compared the sensitivity of the 2pt+ test with that of the 2pt test for different types of anisotropy and have found that the additional information encoded in the 2pt+ test results in yielding consistently better significances over the 2pt test .",
    "we thank the pierre auger collaboration for inspiring this work and for many discussions about testing isotropy with sparsely sample spherical datasets . this work was supported in part by nsf phy-0758017 and by the kicp under nsf phy-0551142 at the university of chicago .",
    "vp acknowledges support by nasa through the glast fellowship program , nasa cooperative agreement : nng06do90a .",
    "tv acknowledges support by the nsf graduate research fellowship program ."
  ],
  "abstract_text": [
    "<S> we introduce a new method for testing departure from isotropy of points on a sphere based on an enhanced form of the two - point correlation function that we named 2pt+ . </S>",
    "<S> this method uses information from the two extra variables that define the vector between two points on a sphere . </S>",
    "<S> we show that this is a powerful method to test departure from isotropy of a distribution of points on a sphere especially when the number of events is small . </S>",
    "<S> we apply the method to a few examples in astronomy and discuss the relevance for limited datasets , such as the case of ultra - high energy cosmic rays . </S>"
  ]
}