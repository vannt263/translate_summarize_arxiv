{
  "article_text": [
    "predictive analysis of networked data is a fast - growing research area whose application domains include document networks , online social networks , and biological networks . in this work",
    "we view networked data as weighted graphs , and focus on the task of node classification in the transductive setting , i.e. , when the unlabeled graph is available beforehand .",
    "standard transductive classification methods , such as label propagation  @xcite , work by optimizing a cost or energy function defined on the graph , which includes the training information as labels assigned to training nodes .",
    "although these methods perform well in practice , they are often computationally expensive , and have performance guarantees that require statistical assumptions on the selection of the training nodes .",
    "a general approach to sidestep the above computational issues is to sparsify the graph to the largest possible extent , while retaining much of its spectral properties see , e.g. , @xcite .",
    "inspired by  @xcite , this paper reduces the problem of node classification from graphs to trees by extracting suitable _ spanning trees _ of the graph , which can be done quickly in many cases .",
    "the advantage of performing this reduction is that node prediction is much easier on trees than on graphs .",
    "this fact has recently led to the design of very scalable algorithms with nearly optimal performance guarantees in the online transductive model , which comes with no statistical assumptions . yet",
    ", the current results in node classification on trees are not satisfactory .",
    "the treeopt  strategy of  @xcite is optimal to within constant factors , but only on _ unweighted _ trees .",
    "no equivalent optimality results are available for general weighted trees . to the best of our knowledge , the only other comparable result is wta  by  @xcite , which is optimal ( within log factors ) only on weighted lines .",
    "in fact , wta  can still be applied to weighted trees by exploiting an idea contained in  @xcite .",
    "this is based on linearizing the tree via a depth - first visit . since linearization loses most of the structural information of the tree , this approach yields suboptimal mistake bounds .",
    "this theoretical drawback is also confirmed by empirical performance : throwing away the tree structure negatively affects the practical behavior of the algorithm on real - world weighted graphs .",
    "the importance of weighted graphs , as opposed to unweighted ones , is suggested by many practical scenarios where the nodes carry more information than just labels , e.g. , vectors of feature values . a natural way of leveraging this side information is to set the weight on the edge linking two nodes to be some function of the similariy between the vectors associated with these nodes . in this work ,",
    "we bridge the gap between the weighted and unweighted cases by proposing a new prediction strategy , called shazoo , achieving a mistake bound that depends on the detailed structure of the weighted tree .",
    "we carry out the analysis using a notion of learning bias different from the one used in  @xcite and more appropriate for weighted graphs .",
    "more precisely , we measure the regularity of the unknown node labeling via the weighted cutsize induced by the labeling on the tree ( see section [ s : lower ] for a precise definition ) .",
    "this replaces the unweighted cutsize that was used in the analysis of wta .",
    "when the weighted cutsize is used , a cut edge violates this inductive bias in proportion to its weight .",
    "this modified bias does not prevent a fair comparison between the old algorithms and the new one : shazoo  specializes to treeopt  in the unweighted case , and to wta  when the input tree is a weighted line . by specializing shazoo s analysis to the unweighted case",
    "we recover treeopt s optimal mistake bound .",
    "when the input tree is a weighted line , we recover wta s mistake bound expressed through the weighted cutsize instead of the unweighted one .",
    "the effectiveness of shazoo  on any tree is guaranteed by a corresponding lower bound ( see section [ s : lower ] ) .",
    "shazoo  can be viewed as a common nontrivial generalization of both treeopt  and wta . obtaining this generalization while retaining and extending the optimality properties of the two algorithms",
    "is far from being trivial from a conceptual and technical standpoint . since shazoo  works in the online transductive model",
    ", it can easily be applied to the more standard train / test ( or `` batch '' ) transductive setting : one simply runs the algorithm on an arbitrary permutation of the training nodes , and obtains a predictive model for all test nodes .",
    "however , the implementation might take advantage of knowing the set of training nodes beforehand .",
    "for this reason , we present two implementations of shazoo , one for the online and one for the batch setting",
    ". both implementations result in fast algorithms .",
    "in particular , the batch one is linear in @xmath0 .",
    "this is achieved by a fast algorithm for weighted cut minimization on trees , a procedure which lies at the heart of shazoo .    finally , we test shazoo  against wta , label propagation , and other competitors on real - world weighted graphs . in _",
    "almost all _ cases ( as expected ) , we report improvements over wta  due to the better sensitivity to the graph structure . in some cases , we see that shazoo  even outperforms standard label propagation methods .",
    "recall that label propagation has a running time per prediction which is proportional to @xmath1 , where @xmath2 is the graph edge set . on the contrary , shazoo  can typically be run in _ constant _",
    "amortized time per prediction by using wilson s algorithm for sampling random spanning trees  @xcite . by disregarding edge weights in the initial sampling phase , this algorithm is able to draw a random ( unweighted ) spanning tree in time proportional to @xmath0 on most graphs .",
    "our experiments reveal that using the edge weights only in the subsequent prediction phase causes in practice only a minor performance degradation .",
    "let @xmath3 be an undirected and weighted tree with @xmath4 nodes , positive edge weights @xmath5 for @xmath6 , and @xmath7 for @xmath8 .",
    "a binary labeling of @xmath9 is any assignment @xmath10 of binary labels to its nodes .",
    "we use @xmath11 to denote the resulting labeled weighted tree .",
    "the online learning protocol for predicting @xmath11 is defined as follows .",
    "the learner is given @xmath9 while @xmath12 is kept hidden .",
    "the nodes of @xmath9 are presented to the learner one by one , according to an unknown and arbitrary permutation @xmath13 of @xmath14 . at each time",
    "step @xmath15 node @xmath16 is presented and the learner must issue a prediction @xmath17 for the label @xmath18 . then @xmath18 is revealed and the learner knows whether a mistake occurred .",
    "the learner s goal is to minimize the total number of prediction mistakes .",
    "following previous works @xcite , we measure the regularity of a labeling @xmath12 of @xmath9 in terms of @xmath19-edges , where a @xmath19-edge for @xmath11 is any @xmath6 such that @xmath20 .",
    "the overall amount of irregularity in a labeled tree @xmath11 is the * weighted cutsize * @xmath21 , where @xmath22 is the subset of @xmath19-edges in the tree .",
    "we use the weighted cutsize as our learning bias , that is , we want to design algorithms whose predictive performance scales with @xmath23 . unlike the @xmath19-edge count @xmath24 , which is a good measure of regularity for unweighted graphs , the weighted cutsize takes the edge weight @xmath25 into account",
    "typically encodes the strength of the connection @xmath26 .",
    "in fact , when the nodes of a graph host more information than just binary labels , e.g. , a vector of feature velues , then a reasonable choice is to set @xmath25 to be some ( decreasing ) function of the distance between the feature vectors sitting at the two nodes @xmath27 and @xmath28 .",
    "see also remark [ r:2 ] . ] when measuring the irregularity of a @xmath19-edge @xmath26 . in the sequel , when we measure the distance between any pair of nodes @xmath27 and @xmath28 on the input tree @xmath9 we always use the resistance distance metric @xmath29 , that is , @xmath30 , where @xmath31 is the unique path connecting @xmath27 to @xmath28 .",
    "graph    cluster : maximal connected subgraph of @xmath32 ( or @xmath9 ) uniformly labeled .",
    "`` closest '' : the default metric distance is the resistance distance metric on the tree .",
    "hinge - node : labeled node or fork ( come in treeopt )    hinge - line : path connecting two hinge nodes such that no internal node is a hinge - node ( come in treeopt )    hinge - tree : each of the component of the forest obtained by removing all edges incident to the hinge nodes .",
    "( quasi come in sel - pred . in sel - pred la foresta era ottenuta eliminando anche gli hinge - nodes ; definendo le cose in questo modo semplifichiamo le cose per questo paper )    @xmath33 : hinge - tree containing @xmath27 .",
    "a connection node of a hinge - tree @xmath34 is any hinge node adjacent to one of node of @xmath34 .",
    "( come in sel - pred )    fork : unlabeled node connected by ( at least ) three edge - disjoint path to ( at least ) three distinct labeled nodes ( come in sel - pred ) .",
    "connection fork : connection node which is fork .",
    "@xmath31 = path connecting node @xmath27 and @xmath28 .",
    "@xmath19-free edge .",
    "@xmath35 : predicted label of @xmath27 .",
    "in this section we show that the weighted cutsize can be used as a lower bound on the number of online mistakes made by any algorithm on any tree . in order to do so ( and unlike previous papers on this specific subject see , e.g. , @xcite ) ,",
    "we need to introduce a more refined notion of adversarial  budget \" .",
    "given @xmath3 , let @xmath36 be the maximum number of edges of @xmath9 such that the sum of their weights does not exceed @xmath37 , @xmath38 we have the following simple lower bound ( all proofs are omitted from this extended abstract ) .",
    "[ th : lb ] for any weighted tree @xmath3 there exists a randomized label assignment to @xmath14 such that any algorithm can be forced to make at least @xmath39 online mistakes in expectation , while @xmath40 .",
    "specializing  ( * ? ? ?",
    "* theorem  1 ) to trees gives the lower bound @xmath41 under the constraint @xmath42 .",
    "the main difference between the two bounds is the measure of label regularity being used : whereas theorem  [ th : lb ] uses @xmath23 , which depends on the weights , ( * ? ? ?",
    "* theorem  1 ) uses the weight - independent quantity @xmath43 .",
    "this dependence of the lower bound on the edge weights is consistent with our learning bias , stating that a heavy @xmath19-edge violates the bias more than a light one .",
    "since @xmath44 is nondecreasing , the lower bound implies a number of mistakes of at least @xmath45 .",
    "note that @xmath46 for any labeled tree @xmath11 .",
    "hence , whereas a constraint @xmath47 on @xmath43 implies forcing at least @xmath41 mistakes , a constraint @xmath37 on @xmath23 allows the adversary to force a potentially larger number of mistakes .    in the next section",
    "we describe an algorithm whose mistake bound nearly matches the above lower bound on any weighted tree when using @xmath48 as the measure of label regularity .",
    "in this section we introduce the shazoo  algorithm , and relate it to previously proposed methods for online prediction on unweighted trees ( treeopt  from @xcite ) and weighted line graphs ( wta  from @xcite ) .",
    "in fact , shazoo  is optimal on any weighted tree , and reduces to treeopt  on unweighted trees and to wta  on weighted line graphs .",
    "since treeopt  and wta  are optimal on _ any _ unweighted tree and _ any _ weighted line graph , respectively , shazoo  necessarily contains elements of both of these algorithms .    in order to understand our algorithm",
    ", we now define some relevant structures of the input tree @xmath9 .",
    "see figure  [ fig : hinge - trees_shazoo ] ( left ) for an example .",
    "these structures evolve over time according to the set of observed labels .",
    "first , we call * revealed * a node whose label has already been observed by the online learner ; otherwise , a node is * unrevealed*. a * fork * is any unrevealed node connected to at least three different revealed nodes by edge - disjoint paths . a * hinge node *",
    "is either a revealed node or a fork .",
    "a * hinge tree * is any component of the forest obtained by removing from @xmath9 all _ edges _ incident to hinge nodes ; hence any fork or labeled node forms a @xmath49-node hinge tree . when a hinge tree @xmath34 contains only one hinge node , a * connection node * for @xmath34 is the node contained in @xmath34 . in all other cases ,",
    "we call a connection node for @xmath34 any node outside @xmath34 which is adjacent to a node in @xmath34",
    ". a * connection fork * is a connection node which is also a fork .",
    "finally , a * hinge line * is any path connecting two hinge nodes such that no internal node is a hinge node .",
    "* left : * an input tree .",
    "revealed nodes are dark grey , forks are doubly circled , and hinge lines have thick black edges .",
    "the hinge trees not containing hinge nodes ( i.e. , the ones that are not singletons ) are enclosed by dotted lines . the dotted arrows point to the connection node(s ) of such hinge trees . *",
    "middle : * the predictions of shazoo  on the nodes of a hinge tree .",
    "the numbers on the edges denote edge weights . at a given time @xmath50",
    ", shazoo  uses the value of @xmath51 on the two hinge nodes ( the doubly circled ones , which are also forks in this case ) , and is required to issue a prediction on node @xmath16 ( the black node in this figure ) .",
    "since @xmath16 is between a positive @xmath51 hinge node and a negative @xmath51 hinge node , shazoo  goes with the one which is closer in resistance distance , hence predicting @xmath52 . *",
    "right : * a simple example where the mincut prediction strategy does not work well in the weighted case . in this example",
    ", mincut mispredicts all labels , yet @xmath53 , and the ratio of @xmath23 to the total weight of all edges is about @xmath54 .",
    "the labels to be predicted are presented according to the numbers on the left of each node .",
    "edge weights are also displayed , where @xmath55 is a very small constant . ]",
    "given an unrevealed node @xmath27 and a label value @xmath56 , the * cut function * @xmath57 is the value of the minimum weighted cutsize of @xmath9 over all labelings @xmath58 consistent with the labels seen so far and such that @xmath59 . define @xmath60 if @xmath27 is unrevealed , and @xmath61 , otherwise .",
    "the algorithm s pseudocode is given in algorithm [ alg : shazoo ] . at time @xmath50 , in order to predict the label @xmath18 of node @xmath16 , shazoo  calculates @xmath62 for all connection nodes @xmath27 of @xmath63 , where @xmath63 is the hinge tree containing @xmath16 .",
    "then the algorithm predicts @xmath18 using the label of the connection node @xmath27 of @xmath63 which is closest to @xmath16 and such that @xmath64 ( recall from section  [ sec : prel ] that all distances / lengths are measured using the resistance metric ) .",
    "ties are broken arbitrarily .",
    "if @xmath65 for all connection nodes @xmath27 in @xmath63 then shazoo  predicts a default value ( @xmath66 in the pseudocode ) .",
    "* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *    let @xmath67 be the set of the connection nodes @xmath27 of @xmath63 for which @xmath64 let @xmath28 be the node of @xmath67 closest to @xmath16 set @xmath68 set @xmath52    [ alg : shazoo ]    * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * if @xmath16 is a fork ( which is also a hinge node ) , then @xmath69 . in this case",
    ", @xmath16 is a connection node of @xmath63 , and obviously the one closest to itself .",
    "hence , in this case shazoo  predicts @xmath70 simply by @xmath71 .",
    "see figure [ fig : hinge - trees_shazoo ] ( middle ) for an example .",
    "on unweighted trees , computing @xmath62 for a connection node @xmath27 reduces to the fork label estimation procedure in ( * ? ? ?",
    "* lemma 13 ) . on the other hand ,",
    "predicting with the label of the connection node closest to @xmath16 in resistance distance is reminiscent of the nearest - neighbor prediction of wta  on weighted line graphs @xcite .",
    "in fact , as in wta , this enables to take advantage of labelings whose @xmath19-edges are light weighted .",
    "an important limitation of wta  is that this algorithm linearizes the input tree .",
    "on the one hand , this greatly simplifies the analysis of nearest - neighbor prediction ; on the other hand , this prevents exploiting the structure of @xmath9 , thereby causing logaritmic slacks in the upper bound of wta .",
    "the treeopt  algorithm , instead , performs better when the unweighted input tree is very different from a line graph ( more precisely , when the input tree can not be decomposed into long edge - disjoint paths , e.g. , a star graph ) .",
    "indeed , treeopt s upper bound does not suffer from logaritmic slacks , and is tight up to constant factors on any unweighted tree .",
    "similar to treeopt , shazoo  does not linearize the input tree and extends to the weighted case treeopt s superior performance , also confirmed by the experimental comparison reported in section [ s : exp ] .    in figure",
    "[ fig : hinge - trees_shazoo ] ( right ) we show an example that highlights the importance of using the @xmath51 function to compute the fork labels .",
    "since @xmath51 predicts a fork @xmath16 with the label that minimizes the weighted cutsize of @xmath9 consistent with the revealed labels , one may wonder whether computing @xmath51 through mincut based on the number of @xmath19-edges ( rather than their weighted sum ) could be an effective prediction strategy .",
    "figure [ fig : hinge - trees_shazoo ] ( right ) illustrates an example of a simple tree where such a @xmath51 mispredicts the labels of all nodes , when both @xmath23 and @xmath43 are small .    [ r:1 ] we would like to stress that shazoo  can also be used to predict the nodes of an arbitrary _ graph _ by first drawing a random spanning tree @xmath9 of the graph , and then predicting optimally on @xmath9 see , e.g. ,  @xcite .",
    "the resulting mistake bound is simply the expected value of shazoo s mistake bound over the random draw of @xmath9 . by using a fast spanning tree sampler  @xcite , the involved computational overhead amounts",
    "to constant amortized time per node prediction on `` most '' graphs .",
    "[ r:2 ] in certain real - world input graphs , the presence of an edge linking two nodes may also carry information about the extent to which the two nodes are _ dissimilar _ , rather than similar .",
    "this information can be encoded by the sign of the weight , and the resulting network is called a _ signed",
    "graph_. the regularity measure is naturally extended to signed graphs by counting the weight of _ frustrated edges _  ( e.g.,@xcite ) , where @xmath26 is frustrated if @xmath72 .",
    "many of the existing algorithms for node classification @xcite can in principle be run on signed graphs .",
    "however , the computational cost may not always be preserved .",
    "for example ,",
    "mincut  @xcite is in general np - hard when the graph is signed  @xcite .",
    "since our algorithm sparsifies the graph using trees , it can be run efficiently even in the signed case .",
    "we just need to re - define the @xmath51 function as @xmath73 , where @xmath74 is the minimum total weight of frustrated edges consistent with the labels seen so far . the argument contained in section  [ s : impl ] for the positive edge weights ( see , e.g. , eq .",
    "( [ eq : cut ] ) therein ) allows us to show that also this version of @xmath51 can be computed efficiently .",
    "the prediction rule has to be re - defined as well : we count the parity of the number @xmath75 of negative - weighted edges along the path connecting @xmath16 to the closest node @xmath76 , i.e. , @xmath77 .    in",
    "@xcite the authors note that treeopt  approximates a version space ( halving ) algorithm on the set of tree labelings .",
    "interestingly , shazoo  is also an approximation to a more general halving algorithm for weighted trees .",
    "this generalized halving gives a weight to each labeling consistent with the labels seen so far and with the sign of @xmath78 for each fork @xmath79 .",
    "these weighted labelings , which depend on the weights of the @xmath19-edges generated by each labeling , are used for computing the predictions .",
    "one can show ( details omitted due to space limitations ) that this generalized halving algorithm has a mistake bound within a constant factor of shazoo s .",
    "we now show that shazoo  is nearly optimal on every weighted tree @xmath9 .",
    "we obtain an upper bound in terms of @xmath23 and the structure of @xmath9 , nearly matching the lower bound of theorem  [ th : lb ] .",
    "we now give some auxiliary notation that is strictly needed for stating the mistake bound .    given a labeled tree @xmath11 , a * cluster * is any maximal subtree whose nodes have the same label .",
    "an * in - cluster line graph * is any line graph that is entirely contained in a single cluster .",
    "finally , given a line graph @xmath80 , we set @xmath81 , i.e. , the ( resistance ) distance between its terminal nodes .",
    "[ th : ub ] for any labeled and weighted tree @xmath82 , there exists a set @xmath83 of @xmath84 edge - disjoint in - cluster line graphs such that the number of mistakes made by shazoo  is at most of the order of @xmath85    the above mistake bound depends on the tree structure through @xmath83 .",
    "the sum contains @xmath84 terms , each one being at most logarithmic in the scale - free products @xmath86 .",
    "the bound is governed by the same key quantity @xmath87 occurring in the lower bound of theorem  [ th : lb ] .",
    "however , theorem  [ th : ub ] also shows that shazoo  can take advantage of trees that can not be covered by long line graphs .",
    "for example , if the input tree @xmath9 is a weighted line graph , then it is likely to contain long in - cluster lines .",
    "hence , the factor multiplying @xmath87 may be of the order of @xmath88 .",
    "if , instead , @xmath9 has constant diameter ( e.g. , a star graph ) , then the in - cluster lines can only contain a constant number of nodes , and the number of mistakes can never exceed @xmath84 . this is a log factor improvement over wta  which , by its very nature , can not exploit the structure of the tree it operates on . ) and lower ( theorem [ th : lb ] ) bounds exists due to the extra factors depending on @xmath89 .",
    "one way to get around this is to follow the analysis of wta  in  @xcite .",
    "specifically , we can adapt here the more general analysis from that paper ( see lemma 2 therein ) that allows us to drop , for any integer @xmath47 , the resistance contribution of @xmath47 arbitrary non-@xmath19 edges of the line graphs in @xmath83 ( thereby reducing @xmath90 for any @xmath80 containing any of these edges ) at the cost of increasing the mistake bound by @xmath47 .",
    "the details will be given in the full version of this paper . ]    as for the implementation , we start by describing a method for calculating @xmath91 for any unlabeled node @xmath92 and label value @xmath93 .",
    "let @xmath94 be the maximal subtree of @xmath9 rooted at @xmath92 , such that no internal node is revealed .",
    "for any node @xmath27 of @xmath94 , let @xmath95 be the subtree of @xmath94 rooted at @xmath27 .",
    "let @xmath96 be the minimum weighted cutsize of @xmath95 consistent with the revealed nodes and such that @xmath59 .",
    "since @xmath97 , our goal is to compute @xmath98 .",
    "it is easy to see by induction that the quantity @xmath99 can be recursively defined as follows , where @xmath100 is the set of all children of @xmath27 in @xmath94 , and @xmath101 if @xmath102 is revealed , and @xmath103 , otherwise : @xmath104 now , @xmath98 can be computed through a simple depth - first visit of @xmath94 . in all backtracking steps of this visit",
    "the algorithm uses ( [ eq : cut ] ) to compute @xmath99 for each node @xmath27 , the values @xmath105 for all children @xmath28 of @xmath27 being calculated during the previous backtracking steps .",
    "the total running time is therefore linear in the number of nodes of @xmath106 .",
    "next , we describe the basic implementation of shazoo  for the on - line setting .",
    "a batch learning implementation will be given at the end of this section .",
    "the online implementation is made up of three steps .",
    "* 1 . find the hinge nodes of subtree * @xmath107 . recall that a hinge - node is either a fork or a revealed node .",
    "observe that a fork is incident to at least three nodes lying on different hinge lines .",
    "hence , in this step we perform a depth - first visit of @xmath107 , marking each node lying on a hinge line . in order to accomplish this task , it suffices to single out all forks marking each labeled node and , recursively , each parent of a marked node of @xmath107 . at the end of this process",
    "we are able to single out the forks by counting the number of edges @xmath26 of each marked node @xmath27 such that @xmath28 has been marked , too .",
    "the remaining hinge nodes are the leaves of @xmath107 whose labels have currently been revealed .",
    "* 2 . compute * @xmath108 * for all connection forks of @xmath63*. from the previous step we can easily find the connection node(s ) of @xmath63 . then",
    ", we simply exploit the above - described technique for computing the cut function , obtaining @xmath108 for all connection forks @xmath27 of @xmath63 .    *",
    "3 . propagate the labels of the nodes of @xmath109 ( only if @xmath16 is not a fork)*. we perform a visit of @xmath63 starting from every node @xmath110 . during these visits",
    ", we mark each node @xmath28 of @xmath63 with the label of @xmath111 computed in the previous step , together with the length of @xmath112 , which is what we need for predicting any label of @xmath63 at the current time step .    the overall running time is dominated by the first step and the calculation of @xmath62 .",
    "hence the worst case running time is proportional to @xmath113 .",
    "this quantity can be quadratic in @xmath0 , though this is rarely encountered in practice if the node presentation order is not adversarial .",
    "for example , it is easy to show that in a line graph , if the node presentation order is random , then the total time is of the order of @xmath114 . for a star graph",
    "the total time complexity is always linear in @xmath0 , even on adversarial orders .    * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * let @xmath107 be the maximal subtree of @xmath9 containing node @xmath16 such that none of its internal node labels have been revealed before time @xmath50 . hence ,",
    "the leaves of @xmath107 are the only nodes of @xmath107 whose label may be revealed before time @xmath50 .",
    "we now consider tree @xmath107 as rooted at @xmath16 and we denote by @xmath115 the subtree of @xmath107 formed by @xmath27 and all its descendants .",
    "notice that , by definition of @xmath115 , at time @xmath50 the algorithm does not know any label of its internal nodes .",
    "let @xmath116 be the minimal cutsize of @xmath115 consistent with the labels of its leaves that have been revealed before time @xmath50 , conditioned on the the fact that label @xmath117 is revealed and it is equal to @xmath93 .",
    "let now @xmath118 the set of all children of @xmath27 in @xmath107 .",
    "it is easy to see that @xmath119 depends on @xmath120 and @xmath121 for each @xmath122 .",
    "in fact , one can formally give a recursive definition of @xmath119 .",
    "for each tree @xmath9 , @xmath123 , label @xmath124 and node @xmath27 of @xmath107 , @xmath116 satisfies @xmath125 when @xmath27 is a leaf of @xmath107 .",
    "@xmath126 when @xmath27 is an internal node of @xmath107 , where @xmath101 if @xmath102 is already revealed , and @xmath127 otherwise .    by induction on the height of @xmath27 .",
    "term @xmath128 takes into account the contribution of edge @xmath26 to the cutsize .",
    "let now @xmath129 be the set of labels that one can assign to node @xmath27 for minimizing the cutsize contribution of ( i ) the edge set of @xmath130 , together with ( ii ) the edge connecting @xmath27 with its parent @xmath131 in @xmath107 , if we set @xmath132 , i.e. @xmath133 let @xmath134 be the version space of @xmath115 consistent with all labels revealed at time @xmath50 , setting @xmath59 . as stated by the following lemma",
    ", the cardinality of @xmath134 can be expressed in terms of @xmath135 for all @xmath122 .",
    "for each tree @xmath9 , @xmath123 , label @xmath124 and unlabeled node @xmath27 of @xmath115 , @xmath136 satisfies @xmath137 when @xmath27 is a leaf of @xmath107 .",
    "@xmath138 when @xmath27 is an internal node of @xmath107 .",
    "by induction on the height of @xmath27    the basic implementation of this algorithm consists of a simple depth - first visit of tree @xmath115 . in all backtracking steps of this visit",
    "the algorithm calculates , for each node @xmath27 , @xmath119 and @xmath136 using equation [ cutsize ] and [ card_s ] respectively .",
    "in fact , equation [ cutsize ] defines @xmath119 in terms of @xmath139 for all children @xmath28 of @xmath27 , which have therefore been already calculated during the previous backtracking steps .",
    "similarly , equation [ card_s ] defines @xmath136 in terms of @xmath119 and @xmath140 for all children @xmath28 of @xmath27 ( see figure  [ f : halving_online ] ) .",
    "label @xmath70 is predicted with @xmath141 if @xmath142 , or @xmath143 otherwise .",
    "[ f : halving_online ]    * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * +    in many real - world scenarios , one is interested in the more standard problem of predicting the labels of a given subset of _ test _ nodes based on the available labels of another subset of _ training _ nodes .",
    "building on the above on - line implementation , we now derive an implementation of shazoo  for this train / test ( or `` batch learning '' ) setting .",
    "we first show that computing @xmath144 and @xmath145 for all unlabeled nodes @xmath27 in @xmath9 takes @xmath146 time .",
    "this allows us to compute @xmath147 for all forks @xmath92 in @xmath146 time , and then use the first and the third steps of the on - line implementation .",
    "overall , we show that predicting _ all _ labels in the test set takes @xmath146 time",
    ". consider tree @xmath148 as rooted at @xmath27 .",
    "given any unlabeled node @xmath27 , we perform a visit of @xmath148 starting at @xmath27 . during the backtracking steps of this visit we use ( [ eq : cut ] ) to calculate @xmath149 for each node @xmath28 in @xmath148 and label @xmath124 .",
    "observe now that for any pair @xmath150 of adjacent unlabeled nodes and any label @xmath124 , once we have obtained @xmath151 , @xmath152 and @xmath153 , we can compute @xmath154 in constant time , as @xmath155 .",
    "in fact , all children of @xmath28 in @xmath148 are descendants of @xmath27 , while the children of @xmath27 in @xmath148 ( but @xmath28 ) are descendants of @xmath28 in @xmath156 .",
    "shazoo  computes @xmath151 , we can compute in constant time @xmath154 for all child nodes @xmath28 of @xmath27 in @xmath148 , and use this value for computing @xmath157 . generalizing this argument , it is easy to see that in the next phase we can compute @xmath158 in constant time for all nodes @xmath159 of @xmath148 such that for all ancestors @xmath160 of @xmath159 and all @xmath124 , the values of @xmath161 have previously been computed .",
    "the time for computing @xmath162 for all nodes @xmath163 of @xmath148 and any label @xmath93 is therefore linear in the time of performing a breadth - first ( or depth - first ) visit of @xmath148 , i.e. , linear in the number of nodes of @xmath148 .",
    "since each labeled node with degree @xmath29 is part of at most @xmath29 trees @xmath148 for some @xmath27 , we have that the total number of nodes of all distinct ( edge - disjoint ) trees @xmath148 across @xmath164 is linear in @xmath0 .",
    "finally , we need to propagate the connection node labels of each hinge tree as in the third step of the online implementation . since also this last step takes linear time , we conclude that the total time for predicting all labels is linear in @xmath0 .",
    "let now @xmath28 any child of @xmath27 in @xmath148 and let @xmath165 be the subtree obtained by eliminating @xmath166 and edge @xmath167 from @xmath165 , where @xmath159 is a child of @xmath28 .",
    "let @xmath168 be the minimal cutsize of @xmath169 consistent with the labels of its leaves that have been revealed at time @xmath50 , setting @xmath170 , i.e. @xmath171 notice that @xmath168 can be easily calculated in constant time once we obtain @xmath172 , @xmath173 and @xmath174 .",
    "since all children of @xmath28 in @xmath148 are descendants of @xmath27 , we can calculate @xmath175 for each label @xmath124 reusing the value of @xmath176 for all nodes @xmath163 of @xmath148 previously computed , in the following way :    @xmath177    where in the second equality we used the fact that ( i ) @xmath178 and ( ii ) the children of @xmath27 in @xmath148 are descendants of @xmath28 in @xmath156 .",
    "term @xmath179 takes into account the contribution of edge @xmath26 to the cutsize .",
    "hence we can calculate the value of @xmath180 in constant time for all children @xmath28 of @xmath27 . applying the same formulas it is easy to verify that , in a subsequent phase",
    ", we can compute @xmath158 in constant time for all nodes @xmath159 of @xmath148 such that @xmath181 .",
    "more precisily we can calculate @xmath162 for each node @xmath163 in constant time once we obtain @xmath182 for all nodes @xmath183 such that @xmath184 .",
    "the time for computing @xmath162 for all nodes @xmath163 of @xmath148 is therefore linear in the time of performing a breadth - first visit of @xmath148 , i.e. linear in the number of nodes of @xmath148 .",
    "since each labeled node with degree @xmath29 is part of at most @xmath29 tree @xmath148 for some @xmath27 , we deduce that the sum of the number of nodes of all trees @xmath148 for @xmath164 is linear in @xmath0 .",
    "hence , we can conclude that the total time for predicting all labels is linear in @xmath0 .",
    "we tested our algorithm on a number of real - world weighted graphs from different domains ( character recognition , text categorization , bioinformatics , web spam detection ) against the following baselines : * online majority vote * ( omv ) .",
    "this is an intuitive and fast algorithm for sequentially predicting the node labels is via a weighted majority vote over the labels of the adjacent nodes seen so far .",
    "namely , omv  predicts @xmath18 through the sign of @xmath185 , where @xmath163 ranges over @xmath186 such that @xmath187 . both the total time and space required by omv  are @xmath188 .",
    "* label propagation * ( labprop ) .",
    "@xmath189  @xcite is a batch transductive learning method computed by solving a system of linear equations which requires total time of the order of @xmath190 .",
    "this relatively high computational cost should be taken into account when comparing labprop  to faster online algorithms .",
    "recall that @xmath191 can be viewed as a fast `` online approximation '' to labprop .    * weighted tree algorithm * ( wta ) .",
    "as explained in the introductory section , wta  can be viewed as a special case of shazoo .",
    "when the input graph is not a line , wta  turns it into a line by first extracting a spanning tree of the graph , and then linearizing it . the implementation described in @xcite runs in constant amortized time per prediction whenever the spanning tree sampler runs in time @xmath192 .",
    "the graph perceptron algorithm  @xcite is another readily available baseline .",
    "this algorithm has been excluded from our comparison because it does not seem to be very competitive in terms of performance ( see , e.g. , @xcite ) , and is also computationally expensive .    in our experiments , we combined shazoo  and wta  with spanning trees generated in different ways ( note that omv  and labprop  do not need to extract spanning trees from the input graph ) .",
    "* random spanning tree * ( rst ) .",
    "following ch .  4 of  @xcite , we draw a weighted spanning tree with probability proportional to the product of its edge weights",
    ". we also tested our algorithms combined with random spanning trees generated uniformly at random ignoring the edge weights ( i.e. , the weights were only used to compute predictions on the randomly generated tree ) we call these spanning trees nwrst  ( no - weight @xmath193 ) . on most graphs",
    ", this procedure can be run in time linear in the number of nodes  @xcite .",
    "hence , the combinations shazoo+nwrst  and wta+nwrst  run in @xmath194 time on most graphs .    * minimum spanning tree * ( mst ) .",
    "this is the spanning tree minimizing the sum of the resistors on its edges .",
    "this tree best approximates the original graph in terms of the trace norm distance of the corresponding laplacian matrices .    following  @xcite , we also ran shazoo  and wta  using committees of spanning trees , and then aggregating predictions via a majority vote .",
    "the resulting algorithms are denoted by @xmath159*shazoo  and @xmath159*wta , where @xmath159 is the number of spanning trees in the aggregation .",
    "we used either @xmath195 or @xmath196 , depending on the dataset size .",
    "for our experiments , we used five datasets : rcv1 , usps , krogan , combined , and webspam .",
    "webspam is a big dataset ( 110,900 nodes and 1,836,136 edges ) of inter - host links created for the web spam challenge 2008  @xcite .",
    "krogan ( 2,169 nodes and 6,102 edges ) and combined ( 2,871 nodes and 6,407 edges ) are high - throughput protein - protein interaction networks of budding yeast taken from  @xcite see  @xcite for a more complete description .",
    "finally , usps and rcv1 are graphs obtained from the usps handwritten characters dataset ( all ten categories ) and the first 10,000 documents in chronological order of reuters corpus vol .  1 ( the four most frequent categories ) , respectively . in both cases",
    ", we used euclidean @xmath197-nearest neighbor to create edges , each weight @xmath198 being equal to @xmath199 .",
    "we set @xmath200 , where @xmath201 is the average squared distance between @xmath27 and its @xmath197 nearest neighbours .",
    "following previous experimental settings @xcite , we associate binary classification tasks with the five datasets / graphs via a standard one - vs - all reduction . each error rate is obtained by averaging over ten randomly chosen training sets ( and ten different trees in the case of rst  and nwrst ) .",
    "webspam is natively a binary classification problem , and we used the same train / test split provided with the dataset : 3,897 training nodes and 1,993 test nodes ( the remaining nodes being unlabeled ) .    in the below table",
    ", we show the macro - averaged classification error rates ( percentages ) achieved by the various algorithms on the first four datasets mentioned in the main text . for each dataset we trained ten times over a random subset of 5% , 10% and 25% of the total number of nodes and tested on the remaining ones .",
    "in boldface are the lowest error rates on each column , excluding labprop  which is used as a `` yardstick '' comparison .",
    "standard deviations averaged over the binary problems are small : most of the times less than 0.5% .    [ cols=\"<,^,^,^,^,^,^,^,^,^,^,^,^ \" , ]     our empirical results can be briefly summarized as follows :    * 1 .",
    "* without using committees , shazoo  outperforms wta  on all datasets , irrespective to the type of spanning tree being used . with committees ,",
    "shazoo  works better than wta  almost always , although the gap between the two reduces .",
    "the predictive performance of shazoo+mst  is comparable to , and sometimes better than , that of labprop , though the latter algorithm is slower .",
    "* @xmath159*shazoo , with @xmath202 ( or @xmath203 on webspam ) seems to be especially effective , outperforming labprop , with a small ( e.g. , 5% ) training set size .",
    "nwrst  does not offer the same theoretical guarantees as rst , but it is extremely fast to generate ( linear in @xmath0 on most graphs  e.g. , @xcite ) , and in our experiments is only slightly inferior to rst .    10    n.  alon , c.  avin , m.  kouck , g.  kozma , z.  lotker , and m.r .",
    "many random walks are faster than one . in _ proc .",
    "20th symp . on parallel algo . and architectures _ , pages 119128 .",
    "springer , 2008 .",
    "m.  belkin , i.  matveeva , and p.  niyogi .",
    "regularization and semi - supervised learning on large graphs . in _ proceedings of the 17th annual conference on learning theory _ , pages 624638 .",
    "springer , 2004 .",
    "y.  bengio , o.  delalleau , and n.  le roux . label propagation and quadratic criterion . in _ semi - supervised learning _ , pages 193216 .",
    "mit press , 2006 .",
    "a.  blum and s.  chawla .",
    "learning from labeled and unlabeled data using graph mincuts . in _ proceedings of the 18th international conference on machine learning_. morgan kaufmann , 2001 .    n.  cesa - bianchi , c. gentile , and f.vitale .",
    "fast and optimal prediction of a labeled tree . in _ proceedings of the 22nd annual conference on learning theory _",
    ", 2009 .",
    "n.  cesa - bianchi , c.  gentile , f.  vitale , and g.  zappella .",
    "random spanning trees and the prediction of weighted graphs . in _ proceedings of the 27th international conference on machine learning _",
    ", 2010 .",
    "n.  cesa - bianchi , c.  gentile , f.  vitale , and g.  zappella .",
    "active learning on trees and graphs . proc . of the 23rd conference on learning theory ( colt 2010 ) .    c.  altafini g.  iacono .",
    "monotonicity , frustration , and ordered response : an analysis of the energy landscape of perturbed large - scale biological networks . , 4(83 ) , 2010 .",
    "m.  herbster and g.  lever .",
    "predicting the labelling of a graph via minimum @xmath131-seminorm interpolation . in _ proceedings of the 22nd annual conference on learning theory_. omnipress , 2009 .",
    "m.  herbster , g.  lever , and m.  pontil .",
    "online prediction on large diameter graphs . in _ advances in neural information processing systems",
    "22_. mit press , 2009 .",
    "m.  herbster , m.  pontil , and s.  rojas - galeano . fast prediction on a tree . in _ advances in neural information processing systems 22_. mit press , 2009 .",
    "f.  r. kschischang , b.  j. frey , and h.  a. loeliger .",
    "factor graphs and the sum - product algorithm .",
    ", 47(2):498519 , 2001 .",
    "r.  lyons and y.  peres .",
    "probability on trees and networks .",
    "manuscript , 2008 .",
    "s.  t. mccormick , m.  r. rao , and g.  rinaldi .",
    "easy and difficult objective functions for max cut . , 94(2 - 3):459466 , 2003 .",
    "g.  pandey , m.  steinbach , r.  gupta , t.  garg , and v.  kumar .",
    "association analysis - based transformations for protein interaction networks : a function prediction case study . in _ proceedings of the 13th acm sigkdd international conference on knowledge discovery and data mining _ ,",
    "pages 540549 .",
    "acm press , 2007 .    yahoo ! research and laboratory of  web algorithmics university  of milan",
    ". web spam collection .",
    "/ webspam / datasets/.    d.  a. spielman and n.  srivastava .",
    "graph sparsification by effective resistances . in _ proc .",
    "of the 40th annual acm symposium on theory of computing ( stoc 2008)_. acm press , 2008 .",
    "wilson . generating random spanning trees more quickly than the cover time . in",
    "_ proceedings of the 28th acm symposium on the theory of computing _ , pages 296303 .",
    "acm press , 1996 .",
    "x.  zhu , z.  ghahramani , and j.  lafferty .",
    "semi - supervised learning using gaussian fields and harmonic functions . in _ proceedings of the 20th international conference on machine learning _ , 2003 .",
    "pick any @xmath204 such that @xmath205 .",
    "let @xmath206 be the forest obtained by removing from @xmath9 all edges in @xmath207 .",
    "draw an independent random label for each of the @xmath208 components of @xmath206 and assign it to all nodes of that component .",
    "then any online algorithm makes in expectation at least half mistake per component , which implies that the overall number of online mistakes is @xmath209 in expectation . on the other hand",
    ", @xmath40 clearly holds by construction .",
    "we first give additional definitions used in the analysis , then we present the main ideas , and finally we provide full details .    recall that , given a labeled tree @xmath11 , a * cluster * is any maximal subtree whose nodes have the same label . let @xmath210 be the set of all clusters of @xmath9 . for any cluster @xmath211 ,",
    "let @xmath212 be the subset of all nodes of @xmath213 on which shazoo  makes a mistake .",
    "let @xmath214 be the subtree of @xmath9 obtained by adding to @xmath213 all nodes that are adjacent to a node of @xmath213 .",
    "note that all edges connecting a node of @xmath215 to a node of @xmath213 are @xmath19-edges .",
    "let @xmath216 be the set of @xmath19-edges in @xmath214 and let @xmath217 .",
    "let @xmath218 be the total weight of the edges in @xmath216 .",
    "finally , recall the notation @xmath81 , where @xmath80 is any line graph .",
    "recall that an * in - cluster line graph * is any line graph that is entirely contained in a single cluster .",
    "the main idea used in the proof below is to bound @xmath219 for each @xmath211 in the following way .",
    "we partition @xmath212 into @xmath220 groups , where @xmath221 .",
    "then we find a set @xmath222 of edge - disjoint in - cluster line graphs , and create a bijection between lines in @xmath222 and groups in @xmath212 .",
    "we prove that the cardinality of each group is at most @xmath223 , where @xmath224 is the associated line .",
    "this shows that the subset @xmath225 of nodes in @xmath9 which are mispredicted by shazoo   satisfies @xmath226 where @xmath227 .",
    "then we show that @xmath228 by the very definition of @xmath44 , and using the bijection stated above , this implies @xmath229 thereby resulting in the mistake bound contained in theorem 2 .",
    "according to shazoo  prediction rule , when @xmath16 is not a fork and @xmath230 , the algorithm predicts @xmath18 using the label of any @xmath76 closest to @xmath16 . in this case , we call @xmath28 an * r - node * ( reference node ) for @xmath16 and the pair @xmath231 , where @xmath232 is the edge on the path between @xmath28 and @xmath16 , an * rn - direction * ( reference node direction )",
    ". we use the shorthand notation @xmath233 to denote an r - node for @xmath27 . in the special case when all connection nodes @xmath27 of the hinge tree containing @xmath16 have @xmath65 ( i.e. , @xmath234 ) , and @xmath16 is not a fork , we call any closest connection node @xmath235 to @xmath16 an r - node for @xmath16 and we say that @xmath236 is a rn - direction for @xmath16 .",
    "clearly , we may have more than one node of @xmath212 associated with the same rn - direction .",
    "given any rn - direction @xmath231 , we call * r - line * ( reference line ) the line graph whose terminal nodes are @xmath28 and the first ( in chronological order ) node @xmath237 for which @xmath231 is a rn - direction , where @xmath232 lies on the path between @xmath235 and @xmath28 .. ] we denote such an r - line by @xmath238 .    in the special case",
    "where @xmath239 and @xmath240 we say that the r - line is associated with the @xmath19-edge of @xmath216 included in the line - graph .",
    "in this case we denote such an r - line by @xmath241 , where @xmath242 .",
    "figure  [ fig : rn - direction ] gives a pictorial example of the above concepts .",
    "we illustrate an example of r - node , rn - direction and r - line .",
    "the numbers near the edge lines denote edge weights . in order to predict @xmath243 , shazoo  uses the r - node @xmath244 and the rn - direction @xmath245 . after observing @xmath243 ,",
    "the hinge line connecting @xmath244 with @xmath246 ( the thick black line ) is created , which is also an r - line , since at the beginning of step @xmath247 the algorithm used @xmath245 . in order to predict @xmath248 , we still use the r - node @xmath244 and the rn - direction @xmath245 . after the revelation of @xmath248 ,",
    "node @xmath79 becomes a fork . ]",
    "* @xmath249 is the set of all forks in @xmath212 .",
    "* @xmath250 is the subset of @xmath212 containing the nodes @xmath27 whose reference node @xmath233 belongs to @xmath213 ( if @xmath27 is a fork , then @xmath251 ) . note that this set may have a nonempty intersection with the previous one",
    "* @xmath252 is the subset of @xmath212 containing the nodes @xmath27 such that @xmath233 does not belong to @xmath213 .",
    "* @xmath253 is the subset of all forks @xmath254 such that @xmath255 at some step @xmath50 . since we assume the cluster label is @xmath256 ( see below ) , and",
    "since a fork @xmath257 is mistaken only if @xmath258 , we have @xmath259 .",
    "* @xmath260 is the subset of all nodes in @xmath212 that , when revealed , create a fork that belongs to @xmath253 .",
    "since at each time step at most one new fork can be created , a new fork @xmath28 is created when the number of edge - disjoint paths connecting @xmath28 to the labeled nodes increases .",
    "this event occurs only when a new hinge line @xmath261 is created .",
    "when this happens , the only node for which the number of edge - disjoint paths connecting it to labeled nodes gets increased is the terminal node @xmath28 of the newly created hinge line .",
    "] we have @xmath262 .",
    "the proof of the theorem relies on the following sequence of lemmas that show how to bound the number of mistakes made on a given cluster @xmath263 .",
    "a major source of technical difficulties , that makes this analysis different and more complex than those of treeopt  and wta , is that on a weighted tree the value of @xmath62 on forks @xmath27 can potentially change after each prediction .",
    "for the sake of contradiction , assume @xmath267 .",
    "let @xmath268 be the maximal subtree of @xmath9 rooted at @xmath79 such that no internal node of @xmath268 is revealed . now , consider the cut given by the edges of @xmath269 belonging to the hinge lines of @xmath268 .",
    "this cut separates @xmath79 from any revealed node labeled with @xmath66 .",
    "the size of this cut can not be larger than @xmath218 . by definition of @xmath270 , this implies @xmath271 .",
    "however , also @xmath272 can not be larger than @xmath218 . because @xmath273 must hold independent of the set of nodes in @xmath274 that are revealed before time @xmath50 , this entails a contradiction .",
    "let now @xmath275 be the restriction of @xmath44 on the subtree @xmath214 , and let @xmath276 be the set of all distinct rn - directions which the nodes of @xmath250 can be associated with .",
    "the next lemmas are aimed at bounding @xmath277 and @xmath278 .",
    "we first need to introduce the superset @xmath279 of @xmath276 .",
    "then , we show that for any @xmath213 both @xmath280 and @xmath277 are linear in @xmath281 .    in order to do so ,",
    "we need to take into account the fact that the sign of @xmath51 for the forks in the cluster can change many times during the prediction process .",
    "this can be done via lemma  [ lm : delta ] , which shows that when all labels in @xmath215 are revealed then , for all fork @xmath282 , the value @xmath78 does not increase .",
    "thus , we get the largest set @xmath276 when we assume that the nodes in @xmath215 are revealed before the nodes of @xmath213 .    given any cluster @xmath213 , let @xmath283 be the order in which the nodes of @xmath214 are revealed .",
    "let also @xmath284 be the permutation in which all nodes in @xmath213 are revealed in the same order as @xmath283 , and all nodes in @xmath215 are revealed at the beginning , in any order .",
    "now , given any node revelation order @xmath283 , @xmath279 can be defined by describing the three types of steps involved in its incremental construction supposing @xmath284 was the actual node revelation order .    1 .",
    "after the first @xmath285 steps , @xmath279 contains all node - edge pairs @xmath286 such that @xmath27 is a fork and @xmath26 is an edge laying on a hinge line of @xmath214 .",
    "recall that no node in @xmath213 is revealed yet .",
    "2 .   for each step",
    "@xmath287 when a new fork @xmath79 is created such that @xmath255 just after the revelation of @xmath18 , we add to @xmath279 the three node - edge pairs @xmath288 , where the @xmath289 are the edges contained in the three hinge lines terminating at @xmath79 .",
    "3 .   let @xmath163 be any step where : ( i ) a new hinge line @xmath290 is created , ( ii ) node @xmath291 is a fork , and ( iii ) @xmath292 at time @xmath293 . on each such step",
    "we add @xmath294 to @xmath279 , for @xmath28 in @xmath290 .",
    "it is easy to verify that , given any ordering @xmath283 for the node revelation in @xmath214 , we have @xmath295 .",
    "in fact , given an rn - direction @xmath296 , if @xmath26 lies along one of the hinge lines that are present at time @xmath297 according to @xmath298 , then @xmath286 must be included in @xmath279 during one of the steps of type 2 above , otherwise @xmath286 will be included in @xmath279 during one of the steps of type 2 or type 3 .",
    "assume nodes are revealed according to @xmath284 .",
    "let @xmath301 be the subtree of @xmath214 made up of all nodes in @xmath214 that are included in any path connecting two nodes of @xmath215 . by their very definition ,",
    "the forks at time @xmath302 are the nodes of @xmath303 having degree larger than two in subtree @xmath301 .",
    "consider @xmath301 as rooted at an arbitrary node of @xmath215 .",
    "the number of the leaves of @xmath301 is equal to @xmath304 .",
    "this is in turn @xmath305 because @xmath306 now , in any tree , the sum of the degrees of nodes having degree larger than two can not is at most linear in the number of leaves .",
    "hence , at time @xmath299 both the number of forks in @xmath213 and the cardinality of @xmath279 are @xmath307 .",
    "[ incr_cutsize ] let @xmath50 be a step when a new hinge line @xmath310 is created such that @xmath311 .",
    "if just after step @xmath50 we have @xmath312 , then @xmath313 , where @xmath314 is the lightest edge on @xmath310 .",
    "since @xmath312 and @xmath310 is completely included in @xmath213 , we must have @xmath312 just before the revelation of @xmath18 .",
    "this implies that the difference @xmath315 can not be smaller than the minimum cutsize that would be created on @xmath310 by assigning label @xmath66 to node @xmath316 .",
    "[ dc_second ] assume nodes are revealed according to @xmath284 .",
    "then the cardinality of @xmath253 and the total number of elements added to @xmath279 during the steps of type 2 above are both linear in @xmath281 .",
    "let @xmath317 be the set of forks in @xmath274 such that @xmath318 at some time @xmath319 .",
    "recall that , by definition , for each fork @xmath320 there exists a step @xmath321 such that @xmath255 .",
    "hence , lemma [ lm : delta ] implies that , at the same step @xmath321 , for each fork @xmath320 we have @xmath318 .",
    "since @xmath253 is included in @xmath317 , we can bound @xmath277 by @xmath322 , i.e. , by the number of forks @xmath264 such that @xmath323 , under the assumption that @xmath284 is the actual revelation order for the nodes in @xmath214 .",
    "now , @xmath322 is bounded by the number of forks created in the first @xmath285 steps , which is equal to @xmath300 plus the number of forks @xmath79 created at some later step and such that @xmath255 right after their creation . since nodes in @xmath214 are revealed according to @xmath284 , the condition @xmath324 just after the creation of a fork @xmath79 implies that we will never have @xmath255 in later stages .",
    "hence this fork @xmath79 belongs neither to @xmath317 nor to @xmath253 .",
    "in order to conclude the proof , it suffices to bound from above the number of elements added to @xmath279 in the steps of type 2 above . from lemma [ incr_cutsize ]",
    ", we can see that for each fork @xmath79 created at time @xmath50 such that @xmath255 just after the revelation of node @xmath16 , we must have @xmath325 , where @xmath314 is the lightest edge in @xmath261 .",
    "hence , we can injectively associate each element of @xmath253 with an edge of @xmath326 , in such a way that the sum of the weights of these edges is bounded by @xmath218 . by definition of @xmath44",
    ", we can therefore conclude that the total number of elements added to @xmath279 in the steps of type 2 is @xmath300 .    with the following lemma we bound the number of nodes of @xmath327 associated with every rn - direction and",
    "show that one can perform a transformation of the r - lines so as to make them edge - disjoint .",
    "this transformation is crucial for finding the set @xmath83 appearing in the theorem statement .",
    "observe that , by definition of r - line , we can not have two r - lines such that each of them includes only one terminal node of the other .",
    "thus , let now @xmath328 be the forest where each node is associated with an r - line and where the parent - child relationship expresses that ( i ) the parent r - line contains a terminal node of the child r - line , together with ( ii ) the parent r - line and the child r - line are not edge - disjoint .",
    "@xmath328 is , in fact , a forest of r - lines .",
    "we now use @xmath329 for bounding the number of mistakes associated with a given rn - direction @xmath330 or with a given @xmath19-edge @xmath232 .",
    "given any connected component @xmath331 of @xmath328 , let finally @xmath332 be the total number of nodes of @xmath327 associated with the rn - directions @xmath333 of all r - lines @xmath334 of @xmath331 .",
    "* the number of nodes in @xmath327 associated with a given rn - direction @xmath335 is of the order of @xmath336 . *",
    "the number of nodes in @xmath337 associated with a given @xmath19-edge @xmath338 is of the order of @xmath339 .",
    "* let @xmath340 be the r - line associated with the root of any connected component @xmath331 of @xmath328 .",
    "@xmath332 must be at most of the same order of @xmath341 where @xmath342 is a set of @xmath343 edge - disjoint line graphs completely contained in @xmath340 .",
    "we will prove only ( i ) and ( iii ) , ( ii ) being similar to ( i ) .",
    "let @xmath16 be a node in @xmath327 associated with a given rn - direction @xmath335 .",
    "there are two possibilities : ( a ) @xmath16 is in @xmath238 or ( b ) the revelation of @xmath18 creates a fork @xmath79 in @xmath238 such that @xmath344 for all steps @xmath345 .",
    "let now @xmath346 be the next node ( in chronological order ) of @xmath327 associated with @xmath335 .",
    "the length of @xmath347 can not be smaller than the length of @xmath348 ( under condition ( a ) ) or smaller than the length of @xmath349 ( under condition ( b ) ) .",
    "this clearly entails a dichotomic behaviour in the sequence of mistaken nodes in @xmath327 associated with @xmath335 .",
    "let now @xmath131 be the node in @xmath238 which is farthest from @xmath28 such that the length of @xmath350 is not larger than @xmath23 . once a node in @xmath350 is revealed or becomes a fork @xmath79 satisfying @xmath344 for all steps @xmath345 , we have @xmath351 for all subsequent steps",
    "( otherwise , this would contradict the fact that the total cutsize of @xmath9 is @xmath23 ) .",
    "combined with the above sequential dichotomic behavior , this shows that the number of nodes of @xmath327 associated with a given rn - direction @xmath335 can be at most of the order of @xmath352 part ( iii ) of the statement can be now proved in the following way .",
    "suppose now that an r - line @xmath353 , having @xmath28 and @xmath235 as terminal nodes , includes the terminal node @xmath354 of another r - line @xmath355 , having @xmath354 and @xmath356 as terminal nodes .",
    "assume also that the two r - lines are not edge - disjoint .",
    "if @xmath355 is partially included in @xmath353 , i.e. , if @xmath356 does not belong to @xmath353 , then @xmath355 can be broken into two sub - lines : the first one has @xmath354 and @xmath159 as terminal nodes , being @xmath159 the node in @xmath353 which is farthest from @xmath354 ; the second one has @xmath159 and @xmath356 as terminal nodes .",
    "it is easy to see that @xmath353 must be created before @xmath355 and @xmath235 is the only node of the second sub - line that can be associated with the rn - direction @xmath357 .",
    "this observation reduces the problem to considering that in @xmath331 each r - line that is not a root is completely included in its parent .",
    "consider now the simplest case in which @xmath331 is formed by only two r - lines : the parent r - line @xmath359 , which completely contains the child r - line @xmath360 .",
    "let @xmath163 be the step in which the first node @xmath160 of @xmath359 becomes a hinge node .",
    "after step @xmath163 , @xmath359 can be vieved as broken in two edge - disjoint sublines having @xmath361 and @xmath362 as terminal node sets , where @xmath235 is one of the terminal of @xmath359 .",
    "@xmath363 generalizing this argument for every component @xmath331 of @xmath328 , and using the above observation about the partially included r - lines , we can state that , for any component @xmath331 of @xmath328 , @xmath332 is of the order of @xmath364 where @xmath365 .",
    "this entails that we can define @xmath366 as the union of @xmath367 and @xmath368 , which concludes the proof .",
    "assume nodes are revealed according to @xmath284 , and let @xmath163 be any type-3 step when a new element is added to @xmath279 .",
    "there are two cases : ( a ) @xmath292 at time @xmath163 or ( b ) @xmath369 at time @xmath163 .",
    "case ( a ) .",
    "lemma [ incr_cutsize ] combined with the fact that all hinge - lines created are edge - disjoint , ensures that we can injectively associate each of these added elements with an edge of @xmath326 in such a way that the total weight of these edges is bounded by @xmath218 .",
    "this in turn implies that the total number of elements added to @xmath326 is @xmath307 .",
    "case ( b ) . since we assumed",
    "that nodes are revealed according to @xmath284 , we have that @xmath370 is positive for all steps @xmath371 .",
    "hence we have that case ( b ) can occur only once for each of such forks @xmath291 .",
    "since this kind of fork belongs to @xmath253 , we can use lemma  [ dc_second ] and conclude that ( b ) can occur at most @xmath372 times .          theorem  2",
    "let @xmath375 be the union of @xmath328 over @xmath376 .",
    "using lemma  [ lm : number_rnd ] we deduce @xmath377 , where the term @xmath378 takes into account that at most one r - line of @xmath328 may be associated with each @xmath19-edge of @xmath214 .",
    "let now @xmath382 be the set of components of @xmath375 .",
    "given any tree @xmath383 , let @xmath384 be the r - line root of @xmath331 .",
    "recall that , by part ( iii ) of lemma  [ lm : m_l ] for any tree @xmath383 we can find a set @xmath385 of @xmath343 edge - disjoint line graphs all included in @xmath384 such that @xmath332 is of the order of @xmath386 .",
    "let now @xmath387 be equal to @xmath388 .",
    "thus we have @xmath389 observe that @xmath387 is not an edge disjoint set of line graphs included in @xmath9 only because each @xmath19-edge may belong to two different lines of @xmath387 . by definition of @xmath390 , for any line graphs @xmath80 and @xmath391 , where @xmath391 is obtained from @xmath80 by removing one of the two terminal nodes and the edge incident to it , we have @xmath392 .",
    "if , for each @xmath19-edge shared by two line graphs of @xmath387 , we shorten the two line graphs so as no one of them includes the @xmath19-edge , we obtain a new set of edge - disjoint line graphs @xmath83 such that @xmath393 .",
    "hence , we finally obtain @xmath394 , where in the last equality we used the fact that @xmath395 for all line graphs @xmath391 ."
  ],
  "abstract_text": [
    "<S> predicting the nodes of a given graph is a fascinating theoretical problem with applications in several domains . </S>",
    "<S> since graph sparsification via spanning trees retains enough information while making the task much easier , trees are an important special case of this problem . although it is known how to predict the nodes of an unweighted tree in a nearly optimal way , in the weighted case a fully satisfactory algorithm is not available yet . </S>",
    "<S> we fill this hole and introduce an efficient node predictor , shazoo , which is nearly optimal on any weighted tree . moreover , </S>",
    "<S> we show that shazoo  can be viewed as a common nontrivial generalization of both previous approaches for unweighted trees and weighted lines . </S>",
    "<S> experiments on real - world datasets confirm that shazoo  performs well in that it fully exploits the structure of the input tree , and gets very close to ( and sometimes better than ) less scalable energy minimization methods . </S>"
  ]
}