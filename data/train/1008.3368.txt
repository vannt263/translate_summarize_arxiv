{
  "article_text": [
    "lyapunov characteristic exponents ( lce ) measure the rate of exponential divergence between neighbouring trajectories in the phase space .",
    "the standard method of calculation of lce for dynamical systems is based on the variational equations of the system .",
    "however , solving these equations is very difficult or impossible so the determination of lce also needs to be carried out numerically rather than analytically .",
    "the most popular methods which are used as an effective numerical tool to calculate the lyapunov spectrum for smooth systems relies on periodic gram - schmidt orthonormalisation of lyapunov vectors ( solutions of the variational equation ) to avoid misalignment of all the vectors along the direction of maximal expansion ( @xcite , @xcite ) .    in some approaches , usually involving a new differential equation instead of the variational one , the procedure of re - orthonormalisation is not used @xcite ",
    "these are usually called the continuous methods .",
    "they are usually found to be slower than the standard ones due to the underlying equation being more complex than the variational one .",
    "a comparison of various methods with and without orthogonalisation can be found in @xcite and a recent general review in @xcite .",
    "the main goal of this paper is to present a new algorithm for obtaining the lce spectrum without the rescaling and realigning .",
    "this application is a consequence of the equation satisfied by the lyapunov matrix or operator ( see below ) which was discovered in one of the authors phd thesis @xcite .",
    "the particular numerical technique introduced here is the first attempt and is open to further development so it still bears the disadvantages of the usual continuous methods .",
    "however , in our opinion , the main advantages of the approach lie in its founding equations and are as follows :    * the whole description of the lce is embedded in differential geometry from the very beginning , so that and it is straightforward to assign any metric to the phase space including one with non - trivial curvature .",
    "* as the rate of growth is described by an operator ( endomorphism ) on the tangents space , and the equation it satisfies is readily expressed with the absolute derivative , the approach is explicitly covariant .",
    "( the exponents are obviously invariants then , although their transformation properties still seem to be a live issue , see e.g. @xcite . ) * there is no need for rescaling and realignment , as the main matrix is at most linear with time , and encodes the full spectrum of lce . *",
    "since we make no assumptions on the eigenvalues , there are no problems with the degenerate case encountered in some other methods .",
    "* we rely on a single coordinate - free matrix equation , which reduces the method s overall complexity . *",
    "the fundamental equation is not an approximation but rather the differential equation satisfied by the so - called time - dependent lyapunov exponents .",
    "this opens potential way to analytic studies of the exponents .",
    "it should be noted that the last points imply a hidden cost ( in the current implementation ) of diagonalising instead of reorthonormalising , due to the complex matrix functions involved .",
    "fortunately , this procedure needs to be carried out on symmetric matrices for which it is stable .",
    "the natural domain of application of this method might be the general relativity and dynamical systems of cosmological origin  already formulated in differential geometric language @xcite .",
    "of course this still requires the resolution of the question of the time parameter , and natural metric in the whole phase space ( not just the configuration space which corresponds to the physical space - time ) .",
    "regardless of that choice , however , the fundamental equation of our method will remain the same  whether one chooses to consider the proper interval as the time parameter , or find some external time for an eight dimensional phase space associated to the four dimensional space - time .",
    "this stems from the fact that our approach works on any manifold .    here",
    ", we wish to focus on the numerical aspect of the method , providing the rough first estimates of its effectiveness .",
    "this is a natural question , after the theoretical motivation for a given method has been established , namely how well it performs numerically .",
    "there are obviously many ways of translating the method into code , and we hope for future improvements , nevertheless , the presented implementation can be considered a complete , ready - to - use tool . in the next sections we review the derivation of the main equation and",
    "then proceed to the simple mechanical examples for testing and results .",
    "for a given system of @xmath0 ordinary differential equations @xmath1 the variational equations along a particular solution @xmath2 are defined as @xmath3 and the largest lyapunov exponent can be defined as @xmath4 for almost all initial conditions of @xmath5 . from now on we take the norm to be @xmath6 where @xmath5 is treated as a column vector , and @xmath7 denotes transposition . that is to say the metric in the tangent space is euclidean , as is usually assumed for a given physical systems .",
    "this needs not be the case , and a fully covariant derivation of the main equation can be found in @xcite .",
    "the above definitions are intuitively based on the fact that for a constant @xmath8 , the solution of is of the form @xmath9 and @xmath10 is the greatest real part of the eigenvalues of @xmath8 . in the simplest case of a symmetric @xmath8 ,",
    "the largest exponent is exactly the largest eigenvalue . to extend this to the whole spectrum",
    ", we note that any solution of is given in terms of the fundamental matrix @xmath11 so that @xmath12 then ( if the limit exists ) , the exponents are @xmath13 since @xmath14 is a symmetric matrix with non - negative eigenvalues , the logarithm is well defined .",
    "the additional factor of 2 in the denominator results from the square root in the definition of the norm above .    as we expect @xmath11 to diverge exponentially",
    ", there is no point in integrating the variational equation in itself , but rather to look at the logarithm . to this end",
    "we introduce the two matrices @xmath15 and @xmath16 : @xmath17 clearly @xmath15 has the same eigenvalues as @xmath14 to which it is connected by a similarity transformation , and the eigenvalues of @xmath16 behave as @xmath18 for large times @xmath19 that is why we call @xmath16 the lyapunov matrix .    to derive the differential equation satisfied by @xmath16 we start with the derivative of @xmath15 and use the property of the matrix ( operator ) exponential @xmath20 where we have introduced a concise notation for the the adjoint of @xmath16 acting on any matrix @xmath21 as @xmath22,\\ ] ] and used its property @xmath23 next , the integral",
    "is evaluated taking the integrand as a formal power series in @xmath24 @xmath25 where the fraction is understood as a power series also , so that there are in fact no negative powers of @xmath24 .",
    "alternatively one could justify the above by stating that the function @xmath26 is well behaved on the spectrum of @xmath24 which is contained in @xmath27 . as @xmath28 is never zero for a real argument , we can invert the operator on the left - hand side of to get @xmath29 where the symmetric and antisymmetric parts of @xmath8 are @xmath30 this allows for the final simplification to @xmath31      \\label{main_eq}\\ ] ] the function @xmath32 should be understood as the appropriate limit at @xmath33 , so that it is well behaved for all real arguments . as was proven in @xcite ,",
    "the above equation is essentially the same in general coordinates : @xmath34,\\ ] ] where @xmath35 is the vector field associated with , and @xmath36 is the covariant derivative .",
    "note that in this form it is especially easy to obtain the known result for the sum of the exponents .",
    "since trace of any commutator is zero , the only term left is the `` constant '' term of @xmath37 which is 1 ( or rather the identity operator ) so that @xmath38 where @xmath39 is the volume of the parallelopiped formed by @xmath0 independent variation vectors .",
    "another simple consequence occurs when the @xmath40 matrix is zero , the whole equation becomes a lax equation @xmath41,\\ ] ] which preserves the spectrum over time , so that @xmath42 tends to zero at infinity .",
    "another way of looking at it is that it is a linear equation in @xmath16 and the matrix of coefficients @xmath43 is antisymmetric in the adjoint representation , so that the evolution is orthogonal and the matrix norm ( frobenius norm to be exact ) of @xmath16 is constant which means @xmath42 tends to the zero matrix .",
    "the simplest example of this is the harmonic oscillator or any critical point of the centre type .",
    "the variations are then vectors of constant length and the evolution becomes a pure rotation .",
    "the authors are not aware of any complex or non - linear system that would exhibit such simple behaviour . already for the mathematical pendulum",
    "such picture is achieved only asymptotically for solutions around its stable critical point .",
    "one could expect that a system with identically zero exponents might not be `` interesting '' enough to incur this kind of research .",
    "we have thus arrived at a dynamical system determining @xmath16 , with right - hand side being given as operations of the adjoint of @xmath16 on time dependent ( through the particular solution ) matrices @xmath40 and @xmath44 .",
    "the next section deals with the practical application of the above equation .",
    "the main difficulty in using is the evaluation of the function of the adjoint operator . since we will be integrating the equation to obtain the elements of the matrix @xmath16",
    ", it would be best to have the right - hand side as an explicit expression in those elements .",
    "this can be done for the @xmath45 case , but already for @xmath46 one has dozens of terms on the right , and for higher dimensions the number of terms is simply too large for such an approach to be of practical value . an alternative",
    "( although equivalent ) dynamical system formulation for the mentioned low dimensionalities have been studied in @xcite , but again the complexity of the equations increases so fast with the dimension that the practical value is questionable .",
    "our method , on the other hand , can be made to rely on the same equation for all dimensions , and the only complexity encountered will be the diagonalisation of a symmetric matrix of increasing size .",
    "another problem lies in the properties of the @xmath47 function which , although finite for real arguments , has poles at @xmath48 .",
    "this means that a series approximation is useless , as it would converge only for eigenvalues smaller than @xmath49 in absolute value , whereas we expect them to grow linearly with time and need the results for @xmath50 . on the other hand ,",
    "@xmath51 for large @xmath52 but , unfortunately , the adjoint operator always has @xmath0 eigenvalues equal to zero , and for hamiltonian systems it is also expected that two eigenvalues tend to zero .",
    "thus , as we require the knowledge of @xmath37 for virtually any symmetric matrix @xmath16 , and we are going to integrate the equation numerically anyway , we will resort to numerical method for this problem . because the matrix @xmath16 is symmetric ( hermitian in an appropriate setting )",
    "so is its adjoint @xmath24 , and the best numerical procedure to evaluate its functions is by direct diagonalisation @xcite .",
    "obviously this is the main disadvantage of the implementation method as even for symmetric matrices , finding the eigenvalues and all the eigenvectors is time - consuming .",
    "so far the authors have only been able to find one alternative routine which is to numerically integrate not @xmath16 itself but rather the diagonal matrix of its eigenvalues and the accompanying transformation matrix of eigenvectors .",
    "however , due to the increased number of matrix multiplications the latter method does not seem any faster than the former .    with this in mind",
    ", let us see how the diagonal form of @xmath16 simplifies the equation .",
    "first , we need to regard @xmath24 as an operator , and since it is acting on matrices we will adopt a representation where any @xmath53 matrix becomes a @xmath54 matrix , i.e. a @xmath55 element vector constructed by writing all the elements of successive rows as one column .",
    "@xmath24 is then a @xmath56 matrix .",
    "fortunately , one does not need to diagonalise @xmath24 but only @xmath16 itself . as can be found by direct calculation",
    ", the eigenvalues of the adjoin are all the differences of the eigenvalues of @xmath16 .",
    "for example @xmath57 where the subscript @xmath58 denotes `` diagonal ''",
    ".    now let us assume we also have the transformation matrix such that @xmath59 then , instead of bringing the whole equation to the eigenbasis of @xmath16 , one can only deal with the @xmath40 matrix in the following way @xmath60 of course , the other term of equation can be evaluated as the standard commutator . for the above example",
    "the @xmath37 part would be @xmath61 and converting @xmath62 to a vector we get @xmath63 which corresponds to the usual 2 by 2 matrix of @xmath64 where @xmath65 are the differences of the eigenvalues of @xmath16 . in general the appropriate ( @xmath53 ) matrix elements read @xmath66_{ij } =      \\psi_2(\\delta_{ij})\\tilde\\theta_{ij},\\ ] ] and this matrix needs to be transformed back to the original basis according to before being used in the main equation .",
    "the matrix elements of @xmath16 will , in general , grow linearly with time .",
    "this is of course a huge reduction when compared with the exponential growth of the perturbations , but one might want to make them behave even better by taking time into account with @xmath67 the reason for the additional 1 is that we will specify the initial conditions at @xmath68 and we want to avoid dividing by zero in the numeric procedure and the limit at infinity ( if it exists ) is not affected by this change . of course ,",
    "in the case of the autonomous systems any value of @xmath69 can be chosen as initial ( at the level of the particular solution ) but the non - autonomous case might require a particular value , which can be dealt with in a similar manner .",
    "we now have @xmath70.\\ ] ] as for the initial conditions , the fundamental matrix @xmath11 is equal to the identity matrix at @xmath68 , so that @xmath71 which in turn implies @xmath72 .    we are now ready to state the general steps of the proposed implementation . choosing a specific numerical routine to obtain the solution for a time step @xmath73 at each",
    "@xmath69 these are    1 .",
    "obtain the particular solution @xmath2 , calculate the jacobian matrix @xmath8 at @xmath74 and , from it , the two matrices @xmath75 and @xmath76 .",
    "start with @xmath77 2 .",
    "find the eigenvalues @xmath78 and eigenvectors @xmath79 of @xmath80 3 .",
    "transform @xmath75 to @xmath81 .",
    "4 .   compute the auxiliary matrix @xmath82_{ij } = \\psi_2((t+1)\\delta_{ij})\\tilde\\theta_{ij}$ ] 5 .",
    "take the derivative to be @xmath83 $ ] , and use it to integrate the solution to the next step @xmath84 .",
    "repeat steps 25 until large enough time is reached . 7 .",
    "the `` time - dependent '' lyapunov exponents at time @xmath69 are simply @xmath85 .",
    "the relation in the last point stems from the rescaling and , as can be seen , is only important for small values of @xmath69 .",
    "as suggested in the preceding section , one expects this method of obtaining the lyapunov spectrum to be relatively slow . in order to see that , we decided to compare it with the standard algorithm based on direct integration of the variational equation and gram - schmidt rescaling at each step @xcite .",
    "although usually the rescaling is required after times of order 1 , we particularly wish to study a system with increasing speed of oscillations and frequent renormalisation will become a necessity . in other words , we want to give the standard method a `` head start '' when it comes to precision .",
    "for numerical integration we chose the modified midpoint method ( with 4 divisions of the whole timestep @xmath86 ) , which has the advantage of evaluating the derivative fewer times than the standard runge - kutta routine with the same accuracy .",
    "since we intended a simple comparison on equal footing , we did not try to optimise either of the algorithms and wrote the whole code in wolfram s mathematica due to the ease of manipulation of the involved quantities and operations ( e.g. matrices and outer products ) .",
    "the most straightforward comparison is for the simplest , i.e. linear dynamical system , for which the main equation is the same as the variational one , with constant matrix @xmath8 .",
    "the exponents are then known to be the real parts of the eigenvalues of @xmath8 . to include all kinds of behaviour",
    ", we took a matrix which has a block form @xmath87 whose eigenvalues are @xmath88 , so that the lce are approximately equal to @xmath89 .",
    "the basic timestep was taken to be @xmath90 and the time to run from 0 to 1000 .",
    "the results are depicted in figures [ const_1 ] and [ const_2 ] with the horizontal axis representing the inverse time @xmath91 so that the sought for limit at infinity becomes the value at zero which is often clearly seen from the trend of the curves .",
    "we note that our method required 59 seconds , whereas the standard one only took 17 seconds .",
    "the final values of lce ( @xmath92 ) were @xmath93 and @xmath94 , respectively .",
    "the shape of the curves is different , which is to be expected because the matrix @xmath80 measures the true growth of the variation vectors at each point of time , and the other method provides more and more accurate approximations to the limit values of the spectrum .",
    "before we go on to the central example , which explores a system with accelerating oscillations , we will present numerical results for the system which is synonymous with chaos , namely the lorenz system @xcite .",
    "the equations read @xmath95 where we took @xmath96 , @xmath97 and @xmath98 , and integrated the equation for the initial conditions of @xmath99 from @xmath68 to 1000 .",
    "next we integrated the respective methods for the exponents with the timestep of @xmath100 .",
    "our method took about 591 seconds and the result is shown in figure [ lorenz_1 ] with the final value of the spectrum @xmath101 .",
    "note that we have shifted the lowest exponent by @xmath102 , so that all three could be presented on the same plot with enough detail .",
    "the standard method took about 152 seconds and its outcome is shown in figure [ lorenz_2 ] with the final values of @xmath103 ( we have shifted the graph in the same manner as before ) .",
    "one could note that there is less overall variation of the time - dependent exponents in our method similarly to the previous example .",
    "a good estimate of precision would be to calculate the sum of the exponents , which , in this system , should be exactly equal to -41/3 .",
    "the difference between that and the numerical estimates were : for the standard method ( at @xmath92 ) @xmath104 , and for our method @xmath105  a much better result .",
    "this seems to be the usual picture for the continuous methods which trade computing time for precision .    a presentation of some more complicated , including both integrable and chaotic",
    ", examples can be found in @xcite , and for such systems also , we observe the concordance of final results and the speed discrepancy . in order to see how one could benefit from the new method we have to turn to another class of models , ones for which the exponents present oscillatory behaviour .",
    "we found that for artificial systems with accelerated oscillations our method performs better and present here a simple physical model which exhibits such property .",
    "consider a ball moving between two walls which are moving towards each other and assume that the ball bounces off with perfect elasticity .",
    "as the distance between the walls decreases and the speed of the ball increases it takes less and less time for each bounce cycle . in order to model this",
    "analytically , without resorting to infinite square potential well we will take the following hamiltonian system @xmath106 which depends on time explicitly via the function @xmath107 whose meaning is seen as follows : the area hyperbolic tangent is infinite for @xmath108 , so that the potential becomes infinite for the position variable @xmath109 , so that @xmath107 is simply half the distance between the walls .",
    "in particular we take it to be @xmath110 so that it decreases from 1 to @xmath111 slowing down but never stopping .",
    "the reason for this is that we want the system not to end in a finite time , and also that the worse behaved @xmath107 is the faster the numerical integration of the main system itself will fail .",
    "the initial shape of the potential and the systems setup is depicted in figure [ potential ]    .",
    "( the vertical position of the ball has no meaning . ) ]    the slowing down of the walls , and the particular shape of @xmath112 allows us to find rigorous bounds on the lyapunov exponents .",
    "first we note , that the vector tangent to a trajectory in the phase space , i.e. a vector whose components are simply the components of @xmath11 from , is always ( for any dynamical system ) a solution of the variational equation .",
    "that means that just by measuring its length we can estimate the largest exponent , since for almost all initial conditions the resulting evolution is dominated by the largest exponent .",
    "second , the system is hamiltonian and it must have two exponents of the same magnitude but different signs , so analysing this particular vector will give us all the information regardless of the initial condition .",
    "thus we have to find the following quantity @xmath113 as a function of time , which boils down to finding bounds on the velocity and acceleration of the bouncing ball .    as the hamiltonian depends on time explicitly ,",
    "the energy is not conserved , but instead we have @xmath114 the velocity has its local maxima at @xmath115 when all the energy is in the kinetic term , and we are lead to define a virtual maximal velocity by equating the energy at any given time to a kinetic term @xmath116 we will take the positive sign of @xmath117 , and assume it is non - decreasing as the physical setup suggest . differentiating the above we",
    "get @xmath118 let us go back to the equation of motion for the momentum variable which reads @xmath119 and substitute that into the previous equation to get @xmath120 as mentioned above @xmath107 decreases very slowly at late times , which is when we estimate the exponents anyway .",
    "we thus assume , that @xmath121 is small enough for the fraction on the right - hand side to be considered constant over one cycle  that is over the time @xmath7 in which the ball moves from the centre up the potential wall and back to the centre .",
    "this time will get shorter and shorter , but also @xmath121 will get closer and closer to zero .",
    "the standard problem of the elastic ball and infinitely hard walls shows that the speed transfer at each bounce is of the order of @xmath121 so the ( virtual ) maximal velocity will change as slowly as @xmath107 and we are entitled to average the equations over one cycle : @xmath122_t^{t+t } -       \\int_t^{t+t } p^2\\mathrm{d}t",
    "\\right )      \\leq -\\frac{\\dot{f}}{f}v_m^2,\\ ] ] where we integrated by parts and used the fact that at the beginning and end of the cycle @xmath115 , and also that the momentum is never greater than the maximal velocity .",
    "we are thus left with a bound in the form of a differential equation , and since all the quantities involved are positive and non - decreasing ( @xmath123 with the `` initial '' value of @xmath117 taken at sufficiently large @xmath69 so that @xmath121 is small .",
    "similar considerations can be carried out for the acceleration @xmath124 , only this time we have to introduce a virtual points of return @xmath125 , that is the point at which all the energy is in the potential term @xmath126 since at the real turning points the acceleration reaches its local maxima .",
    "note that this is not the same as @xmath127 which describes the slow growth of the consecutive maxima of @xmath128 and not the maxima of its slope .",
    "this definition allows us to express @xmath125 as a function of @xmath117 ( via energy ) @xmath129 and the acceleration is @xmath130    bringing the two results together we see that @xmath131 because the function @xmath107 does not tend to zero , and by both lyapunov exponents must in turn be zero themselves .",
    "we also recognise that the hyperbolic cosine factor in @xmath132 could produce a nonzero exponents if @xmath107 were to decrease to zero as @xmath91 .",
    "let us now turn to the numerical results of both methods for this system .",
    "as initial conditions we take @xmath133 and @xmath134 .",
    "for the same time step @xmath90 we see in figure [ wall_1 ] that the new method predicts the values correctly , integrating for 59 seconds from @xmath68 to @xmath92 .",
    "however for the standard one , as shown in figure [ wall_2a ] , we see the exponents diverging from zero , for the same time limits , and integrating time of 17 seconds .",
    "it turns out @xmath135 also gives divergent results and the correct behaviour is recovered for @xmath136 , shown in figure [ wall_2b ] , for which the routine takes 171 seconds .    ) . ]    ) . ]    ) . ]",
    "we have presented a new algorithm for evaluation of the lyapunov spectrum , emerging in the context of differential geometric description of complex dynamical systems .",
    "this description seems especially suitable for systems found in general relativity like , e.g. , chaotic geodesic motion @xcite .",
    "the main advantage of the base method is its covariant nature and concise , albeit explicit , matrix equations that promise more analytic results in the future .",
    "also , this allows for study of curved phase spaces and general dynamical systems  not only autonomous or hamiltonian ones .",
    "the main differential equation , can be numerically integrated , giving a simple immediate algorithm for the computation of the lyapunov characteristic exponents .",
    "it is in general slower than the standard algorithm ( based on gram - schmidt orthogonalisation ) , but the first numerical test suggest it works betters in systems with increasing frequency of ( pseudo-)oscillations .",
    "we show this on the example of a simple mechanical system  a ball bouncing between two contracting walls .",
    "although in low dimensions the main equation can be cast into an explicit form ( with respect to the unknown variables ) , in general the numerical integration requires diagonalisation at each step , which is the main disadvantage of the method and the reason of its low speed .",
    "we hope to present a more developed algorithm without this problem in the future .",
    "this paper was supported by grant no .",
    "n n202 2126 33 of ministry of science and higher education of poland .",
    "the authors would also like to thank j. jurkiewicz and p. perlikowski for valuable discussion and remarks .",
    "g.  benettin , l.  galgani , a.  giorgilli and j.  m.  strelcyn `` lyapunov characteristic exponents for smooth dynamical systems and for hamiltonian systems ; a method for computing all of them .",
    "part 1 : theory , '' meccanica , * 15 * , 1:920 ( 1980 ) ."
  ],
  "abstract_text": [
    "<S> we present a new algorithm for computing the lyapunov exponents spectrum based on a matrix differential equation . </S>",
    "<S> the approach belongs to the so called continuous type , where the rate of expansion of perturbations is obtained for all times , and the exponents are reached as the limit at infinity . </S>",
    "<S> it does not involve exponentially divergent quantities so there is no need of rescaling or realigning of the solution . </S>",
    "<S> we show the algorithm s advantages and drawbacks using mainly the example of a particle moving between two contracting walls . </S>"
  ]
}