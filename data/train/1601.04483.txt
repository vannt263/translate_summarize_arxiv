{
  "article_text": [
    "about 100 years ago , bernstein @xcite introduced a concrete sequence of polynomials approximating a continuous function on a compact interval . that polynomials are dense in the set of continuous functions was shown by weierstrass @xcite , but bernstein was the first to give a concrete method , one that has withstood the test of time .",
    "we refer to @xcite for a history of approximation theory , including _",
    "inter alia _ historical references to weierstrass life and work and to the subsequent work of bernstein .",
    "bernstein s approach was probabilistic and is nowadays included in numerous textbooks on probability theory , see , e.g. , @xcite or ( * ? ? ? * theorem 6.2 ) .",
    "several years after bernstein s work , the nowadays known as wright - fisher stochastic model was introduced and proved to be a founding one for the area of quantitative genetics .",
    "the work was done in the context of mendelian genetics by ronald a.  fisher @xcite and sewall wright @xcite .",
    "this paper aims to explain the relation between the wright - fisher model and the bernstein operator @xmath0 , that takes a function @xmath1 $ ] and outputs a degree-@xmath2 approximating polynomial .",
    "bernstein s original proof was probabilistic .",
    "it is thus natural to expect that subsequent properties of @xmath0 can also be explained via probability theory . in doing so , we shed new light to what happens when we apply the bernstein operator @xmath0 a large number of times @xmath3 to a function @xmath5 .",
    "in fact , things become particularly interesting when @xmath3 and @xmath2 converge simultaneously to @xmath7 .",
    "this convergence can be explained by means of the original wright - fisher model as well as a continuous - time approximation to it known as wright - fisher diffusion .",
    "our paper was inspired by the monthly paper of abel and ivan @xcite that gives a short proof of the kelisky and rivlin theorem @xcite regarding the limit of the iterates of @xmath0 when @xmath2 is fixed .",
    "we asked what is the underlying stochastic phenomenon that explains this convergence and found that it is the composition of independent copies of the empirical distribution function of @xmath2 i.i.d .",
    "uniform random variables .",
    "the composition turns out to be precisely the wright - fisher model .",
    "being a markov chain with absorbing states , @xmath8 and @xmath9 , its distributional limit is a random variable that takes values in @xmath10 ; whence the kelisky and rivlin theorem @xcite .",
    "composing stochastic processes is in line with the first author s current research interests @xcite . indeed",
    ", such compositions often turn out to have interesting , nontrivial , limits @xcite .",
    "stochastic compositions become particularly interesting when they explain some natural mathematical or physical principles .",
    "this is what we do , in a particular case , in this paper . besides giving fresh proofs to some phenomena , stochastic compositions help find what questions to ask as well",
    ".    we will specifically provide probabilistic proofs for a number of results associated to the bernstein operator .",
    "first , we briefly recall bernstein s probabilistic proof ( theorem [ berthm ] ) that says that @xmath11 converges uniformly to @xmath5 as the degree @xmath2 converges to infinity .",
    "second , we look at iterates @xmath12 of @xmath0 , meaning that we compose @xmath0 @xmath3 times with itself and give a probabilistic proof of the kelisky and rivlin theorem stating that @xmath13 converges to @xmath14 as the number of iterations @xmath3 tends to infinity ( theorem [ krthm ] ) .",
    "third , we exhibit , probabilistically , a geometric rate of convergence to the kelisky and rivlin theorem ( proposition [ krrate ] ) .",
    "fourth , we examine the limit of @xmath13 when both @xmath2 and @xmath3 converge to infinity in a way that @xmath15 converges to a constant ( theorem [ jointlimsthm ] ) and show that probability theory gives us a way to prove and set up computation methods for the limit for `` simple '' functions @xmath5 such as polynomials ( proposition [ poly ] ) .",
    "a crucial step is the so - called voronovskaya s theorem ( theorem [ vorthm ] ) which gives a rate of convergence to bernstein s theorem but also provides the reason why the wright - fisher model converges to the wright - fisher diffusion ; this is explained in section [ secwfdiff ] .",
    "regarding notation , we let @xmath16 $ ] be the set of continuous functions @xmath17\\to \\r$ ] , and @xmath18 $ ] the set of functions having a continuous second derivative @xmath19 , including the boundary points , so @xmath20 ( respectively , @xmath21 ) is interpreted as derivative from the right ( respectively , left ) . for a bounded function @xmath22 \\to \\r$ ] , we denote by @xmath23 the quantity @xmath24 .",
    "the bernstein operator @xmath0 maps any function @xmath22\\to \\r$ ] into the polynomial @xmath25 we are mostly interested in viewing @xmath0 as an operator on @xmath16 $ ] .",
    "bernstein s theorem is :    [ berthm ] if @xmath1 $ ] then @xmath11 converges uniformly to @xmath5 : @xmath26    the proof of this theorem is elementary if probability theory is used and goes like this .",
    "let @xmath27 be independent bernoulli random variables with @xmath28 , @xmath29 for some @xmath30 .",
    "if @xmath31 denotes the number of variables with value @xmath9 then @xmath31 has a binomial distribution : @xmath32 therefore @xmath33 now let @xmath34 since @xmath5 is continuous on the compact set @xmath35 $ ] it is also uniformly continuous and so @xmath36 as @xmath37 .",
    "let @xmath38 be the event that @xmath39 and @xmath40 the indicator of @xmath38 ( a function that is @xmath9 on @xmath38 and @xmath8 on its complement ) .",
    "we then write @xmath41 by chebyshev s inequality , @xmath42 therefore , @xmath43 letting @xmath44 the last term goes to @xmath8 and letting @xmath37 the first term vanishes too , thus establishing the theorem .    a variant of bernstein s theorem due to marc kac @xcite gives better estimate if @xmath5 is lipschitz or , more generally , hlder continuous .",
    "indeed , if @xmath5 satisfies @xmath45 for some @xmath46 then , @xmath47 where the first inequality used the hlder continuity of @xmath5 , while the second used jensen s inequality twice ; indeed , if @xmath48 is a positive random variable then @xmath49 , by the concavity of the function @xmath50 when @xmath51 .",
    "hlder continuous functions with small @xmath52 are `` rough '' functions .",
    "the previous remark tells us that we may not have a good rate of convergence for these functions . on the other hand ,",
    "if @xmath5 is smooth can we expect a good rate of convergence ?",
    "a simple calculation with @xmath53 shows that @xmath54 . excluding the trivial case @xmath55 ( the only functions @xmath5 for which @xmath56 ) , can the rate of convergence be better than @xmath57 for some smooth function @xmath5 ?",
    "no , and this is due to voronovskaya s theorem ( theorem [ vorthm ] in section [ vsec ] ) .",
    "[ pj ] @xmath58 + ( i ) @xmath0 is an increasing operator : if @xmath59 then @xmath60 .",
    "( proof : @xmath11 is an expectation ; see . ) + ( ii ) if @xmath5 is a convex function then @xmath61 .",
    "indeed , @xmath62 , by jensen s inequality , and , clearly , @xmath63 .",
    "+ ( iii ) if @xmath5 is a convex function than @xmath11 is a also convex .",
    "see lemma [ bconv ] in section [ isec ] for a proof .",
    "let @xmath64 be the composition of @xmath0 with itself and , similarly , let @xmath65 ( @xmath3 times ) .",
    "abel and ivan @xcite give a short proof of the following .",
    "[ krthm ] for fixed @xmath66 , and any function @xmath17\\to \\r$ ] , @xmath67    note that this says that @xmath68 , as @xmath69 , uniformly in @xmath70 $ ] .",
    "if @xmath5 is convex by remark [ pj](ii ) , @xmath71 . by remark [ pj](i ) , @xmath72 is increasing in @xmath3 and hence the limit of theorem [ krthm ] is actually achieved by an increasing sequence of convex functions ( remark [ pj](iii ) ) .    to prepare the ground , we construct the earlier bernoulli random variables in a different way .",
    "we take @xmath73 to be independent random variables , all uniformly distributed on the interval @xmath35 $ ] , and their _ empirical distribution function _",
    "@xmath74 we shall think of @xmath75 as a random function .",
    "note that , for each @xmath76 , @xmath77 has the binomial distribution .",
    "the advantage of the current representation is that @xmath76 , instead of being a parameter of the probability distribution , is now an explicit parameter of the new random object @xmath78 .",
    "we are allowed to ( and we will ) pick a sequence of independent copies @xmath79 of @xmath75 . for a positive integer @xmath3 let @xmath80 be the composition of the first @xmath3 random functions .",
    "so @xmath81 is itself a random function . by using the independence and the definition of @xmath0 we have",
    "that ( see also section a1 in the appendix ) @xmath82 for any function @xmath5 .",
    "hence the limit over @xmath83 of the right - hand side is the expectation of the limit of the random variable @xmath84 , if this limit exists .",
    "( we make use of the fact that is a finite sum ! ) to see that this is the case , we fix @xmath2 and @xmath76 and consider the sequence @xmath85 with values in @xmath86 we observe that this has the markov property , namely , @xmath87 is independent of @xmath88 , conditional on @xmath89 . by",
    ", the one - step transition probability of this markov chain is @xmath90 since @xmath91 , states @xmath8 and @xmath9 are absorbing , whereas for any @xmath92 , we have @xmath93 for all @xmath94 .",
    "define the absorption time @xmath95 elementary markov chain theory ( * ? ? ?",
    "11 ) tells us that    [ markovelem ] for all @xmath76 , @xmath96 .",
    "therefore , with probability @xmath9 , we have that @xmath97 hence @xmath98 for all bur finitely many @xmath3 and so @xmath99 but the random variable @xmath100 takes two values : @xmath8 and @xmath9 .",
    "notice that @xmath101 for all @xmath3 .",
    "hence @xmath102 . but @xmath103 .",
    "thus @xmath104 , and @xmath105 .",
    "hence @xmath106 this proves the announced limit of theorem [ krthm ] but without the uniform convergence .",
    "however , since all polynomials of the sequence are of degree at most @xmath2 , and @xmath2 is a fixed number , convergence for each @xmath76 implies convergence of the coefficients of the polynomials .    to prove a rate of convergence in theorem [ krthm ] we need to show what was announced in remark [ pj](iii ) .",
    "recall that @xmath107 .",
    "[ bconv ] if @xmath5 is convex then so is @xmath11 .",
    "let @xmath22\\to \\r$ ] and @xmath108 .",
    "we shall prove that @xmath109 \\ ] ] this can be done by direct computation using .",
    "alternatively , we can give a probabilistic argument .",
    "consider @xmath110 $ ] and compute first - order terms in @xmath111 . by",
    ", @xmath112 is nonzero if and only if at least one of the @xmath113 s falls in the interval @xmath114 $ ] .",
    "the probability that @xmath115 or more variables fall in this interval is @xmath116 , as @xmath37 .",
    "hence , if @xmath117 is the event that _ exactly _ one of the variables falls in this interval , then @xmath118\\,\\p(s_n(x)=k , f_{\\varepsilon})+o({\\varepsilon}).\\ ] ] if we let @xmath119 be the event that only @xmath120 is in @xmath121 , then @xmath122 is independent of @xmath123 , so @xmath124 .",
    "so becomes @xmath125 + o({\\varepsilon}),\\ ] ] and , upon dividing by @xmath111 and letting @xmath37 , we obtain .",
    "applying the same formula once more ( no further work is needed ) we obtain @xmath126.\\ ] ] bring in now the assumption that @xmath5 is convex , whence @xmath127 , for all @xmath128 , and deduce that @xmath129 for all @xmath30 .",
    "so @xmath11 is a convex function .    [",
    "cols=\"^,^ \" , ]      + _ convergence of the iterates of @xmath130 as @xmath83 + for a convex @xmath5 ( left ) and a nonconvex one ( right ) .",
    "_    we can now exhibit a rate of convergence .",
    "[ krrate ] for all @xmath30 , @xmath131 , @xmath132 moreover , @xmath133 and @xmath134    we have , for all positive integers @xmath135 and @xmath3 , @xmath136 \\\\ & = \\e\\left [ f(g_n^{k+\\ell } { \\raisebox{0.1ex}{\\scriptsize $ \\circ$}}\\cdots{\\raisebox{0.1ex}{\\scriptsize $ \\circ$}}g_n^{k+1}(h_n^k(x ) ) ) - f(h_n^k(x))\\right ] \\\\ & = \\sum_{y\\in { \\mathbb{i}}_n\\setminus\\{0,1\\ } } \\p(h_n^k(x)=y)\\ , \\e\\left [ f(g_n^{k+\\ell}{\\raisebox{0.1ex}{\\scriptsize $ \\circ$}}\\cdots{\\raisebox{0.1ex}{\\scriptsize $ \\circ$}}g_n^{k+1}(y ) ) - f(y)\\right],\\end{aligned}\\ ] ] whence @xmath137 letting @xmath138 and using theorem [ krthm ] yields .",
    "to prove , we notice that @xmath139 , where @xmath140 if @xmath141 and @xmath9 otherwise , and , by , @xmath142 .",
    "note that @xmath143 is a concave function . by ,",
    "@xmath144 which is also concave by lemma [ bconv ] .",
    "hence @xmath145 since , by symmetry , @xmath146 , inequality follows . for the final inequality ,",
    "notice that @xmath147 \\le n\\ , \\e \\left[h_n^{k-1}(x ) \\left(1-h_n^{k-1}(x)\\right)\\right ] , \\ ] ] where we used the inequality @xmath148 , for all @xmath149 .",
    "therefore , @xmath150 = : n\\ , \\gamma(k-1,x).\\ ] ] using @xmath151 = \\left(1-\\frac{1}{n}\\right)\\ , x\\ , ( 1-x),\\ ] ] we obtain the recursion @xmath152 taking into account that @xmath153 we find that @xmath154 .    combining and we get @xmath155 this should be compared with ( * ? ? ? * eq .  ( 4 ) ) that says that @xmath156 , for some constant @xmath157 which has not been computed in @xcite , whereas we have an explicit constant @xmath158 .",
    "now , the factor @xmath2 is probably wasteful and this comes from the fact that the inequality @xmath148 is not good when @xmath2 is large .",
    "we only used it because of the simplicity of the right - hand side that enabled us to compute @xmath159 very easily .",
    "we have a better inequality , namely , but to make it explicit one needs to compute @xmath160 .",
    "we now take a closer look at the markov chain described by the sequence @xmath161 for fixed @xmath2 .",
    "we repeat formula : @xmath162 we recognize that it describes the simplest stochastic model for reproduction in population genetics that goes as follows .",
    "there is a population of @xmath163 individuals each of which carries 2 genes .",
    "genes come in 2 variants , i and ii , say , thus , an individual may have 2 genes of type i both , or of type ii both , or one of each .",
    "hence there are @xmath164 genes in total .",
    "we observe the population at successive generations and assume that generations are non - overlapping .",
    "suppose that the @xmath3-th generation consists of @xmath165 genes of type i and @xmath166 of type ii . in figure [ figgener ] below , type i genes are yellow , and type ii are red .    to specify generation @xmath167",
    ", we let each gene of generation @xmath167 select a single `` parent '' at random from the genes of the previous generation .",
    "the gene adopts the type of its parent .",
    "the parent selection is independent across genes .",
    "the probability that a specific gene selects a parent of type i is @xmath168 . since we have @xmath2 independent trials , the probability that generation @xmath167 will contain @xmath123 genes of type i is given by the right - hand side of formula .",
    "if we start the process at generation @xmath8 with genes of type i being chosen , independently , with probability @xmath76 each , then the number of alleles at the @xmath3-th generation has the distribution of @xmath169 .",
    "this stochastic model we just described is known as the wright - fisher model , and is fundamental in mathematical biology for populations of fixed size .",
    "the model is very far from reality , but has nevertheless been extensively studied and used .",
    "early on , wright and fisher observed that performing exact computations with this model is hard .",
    "they devised a continuous approximation observing that the probability @xmath170 as a function of @xmath76 , @xmath171 and @xmath3 can , when @xmath2 is large , be approximated by a smooth function of @xmath76 and @xmath171 .",
    "( see , e.g. , kimura @xcite and the recent paper by tran , hofrichter , and jost @xcite . ) rather than approximating this probability , we follow modern methods of stochastic analysis in order to approximate the discrete stochastic process @xmath161 by a continuous - time continuous - space stochastic process that is nowadays known as wright - fisher diffusion .",
    "our eventual goal is to understand what happens when we consider the limit of @xmath130 , when both @xmath3 and @xmath2 tend to infinity . from the bernstein and the kelisky - rivlin theorems",
    "we should expect that the order at which limits over @xmath3 and @xmath2 are taken matters .",
    "it turns out that the only way to obtain a limit is when the ratio @xmath15 tends to a constant , say , @xmath172 .",
    "this is intimately connected to the wright - fisher diffusion that we introduce next .",
    "we assume that the reader has some knowledge of stochastic calculus , including the it formula and stochastic differential equations driven by a brownian motion at the basic level of ksendal @xcite or at the more advanced level of bass @xcite .",
    "we first explain why we expect that the markov chain @xmath173 , @xmath174 has a limit , in a certain sense , as @xmath44",
    ". our explanation here will be informal .",
    "we shall give rigorous proofs of only what we need in the following sections .",
    "the first thing we do is to compute the expected variance of the increment of the chain , and examine whether it converges to zero and at which rate : see , theorem [ mc2diff ] , section a3 in the appendix .",
    "the rate of convergence gives us the right time scale .",
    "our case at hand is particularly simple because we have an exact formula : @xmath175 = \\e\\left[\\left(g_n(y)-y\\right)^2\\right ] = \\frac{1}{n } y ( 1-y).\\ ] ] this suggests that the right time scale at which we should run the markov chain is such that the time steps are of size @xmath57 . in other words , consider the points @xmath176 and draw the random curve @xmath177}(x)\\ ] ] ( where @xmath178 $ ] is the integer part of @xmath179 ) as in figure [ figcurve ] .",
    "this is at the right time scale .",
    "the second thing we do ( see , theorem [ mc2diff ] , section a3 ) is to compute the expected change of the markov chain . in our case , this is elementary : @xmath180 = \\e\\left[g_n(y)-y\\right ] = 0.\\ ] ] the functions @xmath181 and @xmath182 obtained in and suggest that the limit of the random curve @xmath183}(x ) , \\",
    ", t \\ge 0)$ ] should be a diffusion process @xmath184 , @xmath185 , satisfying the stochastic differential equation @xmath186 with initial condition @xmath187 , where @xmath188 , @xmath189 , is a standard brownian motion .",
    "it is actually possible to prove that @xmath183 } , t \\ge 0)$ ] converges _ weakly _ to @xmath190 , but this requires an additional estimate on the size of the increments of the markov chain that is , in our case , provided by the following inequality : for any @xmath108 , @xmath191 to see this , apply hoeffding s inequality ( see section a2 in the appendix ) .",
    "we thus have that , , are the conditions , and of theorem [ mc2diff ] , section a3 .",
    "in addition , it can be shown that the stochastic differential equation admits a unique strong solution for any initial condition @xmath76 .",
    "this is , e.g. , a consequence of the yamada - watanabe theorem ( * ? ? ?",
    "* theorem 24.4 ) .",
    "hence , by theorem [ mc2diff ] , the sequence of continuous random curves @xmath183}(x ) , t \\ge 0)$ ] converges weakly to the continuous random function @xmath192 .",
    "one particular conclusion of weak convergence is that @xmath193}(x ) ) \\to \\e f(x_t(x))$ ] for any @xmath1 $ ] or , equivalently , that    [ jointlimsthm ] for any @xmath1 $ ] and any @xmath185 , @xmath194 } f(x ) = \\e f(x_t(x)),\\quad \\text{uniformly in } x.\\ ] ]    since understanding the theorem of stroock and varadhan requires advanced machinery , we shall prove theorem [ jointlimsthm ] directly .",
    "the proof is deferred until section [ jointsec ] . the nice thing with this theorem is that we have a way to compute the limit by means of stochastic calculus , the tools of which we shall assume as known .",
    "let @xmath5 be a twice - continuously differentiable function . then , it s formula ( ( * ? ? ?",
    "11 ) , ( * ? ? ?",
    "* ch .  4 ) ) says that @xmath195 if we let @xmath196 take expectations in , and differentiate with respect to @xmath172 , we obtain @xmath197 the so - called forward equation of the diffusion .",
    "now let , for all @xmath198 , @xmath199 noticing that @xmath200 is defined for all bounded and measurable @xmath201 and that @xmath202 .",
    "if @xmath201 is such that @xmath203 then we can set @xmath204 in .",
    "now , @xmath205 , because of the markov property of @xmath206 , @xmath185 , and so becomes @xmath207 letting @xmath208 , we arrive at the backward equation @xmath209 which is valid if @xmath200 is twice continuously differentiable .",
    "the class of functions @xmath201 such that both @xmath201 and @xmath200 are in @xmath210 is nontrivial in our case .",
    "it contains , at least polynomials .",
    "this is what we show next .",
    "it turns out that in order to prove theorem [ jointlimsthm ] we need to compute @xmath211 when @xmath5 is a polynomial .",
    "[ poly ] for a positive integer @xmath212 , the following holds for the wright - fisher diffusion : @xmath213 where @xmath214 ( where , as usual , a product over an empty set equals @xmath9 ) .",
    "write @xmath215 to save space . by it s formula applied to @xmath216 , @xmath217 since",
    "the first integral is ( as a function of @xmath172 ) a martingale starting from @xmath8 its expectation is 0 .",
    "thus , if we let @xmath218 we have @xmath219 thus , @xmath220 , as expected , and @xmath221 defining the laplace transform @xmath222 and using integration by parts to see that @xmath223 we have @xmath224 iterating this easy recursion yields @xmath225 where the second equality was obtained by partial fraction expansion ( and the notation is as in ) . since the inverse laplace transform of @xmath226 is @xmath227 ,",
    "the claim follows .",
    "formula was proved by kelisky and rivlin ( * ? ? ?",
    "( 3.13 ) ) and karlin and ziegler ( * ? ? ?",
    "* eq .  ( 1.13 ) ) by entirely different methods .",
    "( the latter paper contains a typo in the formula ) .",
    "( 3.13 ) of @xcite reads : @xmath228 comparing this with and we obtain @xmath229 } = \\frac{i}{r }   { r\\choose i}^2 \\frac{\\displaystyle ( -1)^{i+j } { r - i\\choose j - i}^2 } { \\displaystyle { 2\\,j-2\\choose j - i}{j+r-1 \\choose r - j}},\\ ] ] valid for any integers @xmath230 with @xmath231 . this equality can be verified directly by simple algebra .",
    "an important result in the theory of approximation of continuous functions is voronovskaya s theorem @xcite .",
    "it is the simplest example of _ saturation _ , namely that , for certain operators , convergence can not be too fast even for very smooth functions .",
    "see devore and lorentz ( * ? ? ?",
    "* theorem 3.1 ) .",
    "voronovskaya s theorem gives a rate of convergence to bernstein s theorem . from a probabilistic point of view , the theorem is nothing else but the convergence of the generator of the discrete markov chain to the generator of the wright - fisher diffusion .",
    "we shall not use anything from the theory of generators , but we shall give an independent probabilistic proof below for @xmath210 functions @xmath5 , including a slightly improved form under the assumption that @xmath19 is lipschitz . in this case ,",
    "its lipschitz constant is @xmath232 recall that @xmath233 is defined by .",
    "[ vorthm ] for any @xmath234 $ ] , @xmath235}| n ( b_n f(x ) - f(x ) ) - \\ll f(x ) |=0.\\ ] ] if moreover @xmath19 is lipschitz then , for any @xmath236 , @xmath237}| n ( b_n f(x ) - f(x ) ) -",
    "\\ll f(x ) |\\le",
    "\\frac{\\lip(f'')}{16 \\cdot 3^{1/4 } } \\ , n^{-1/2}\\ ] ]    using taylor s theorem with the remainder in integral form , @xmath238 since @xmath239 , we have , from , @xmath240 .",
    "therefore , @xmath241 we estimate @xmath242 by splitting the expectation as @xmath243 + \\e[j_n(x ) ; |g_n(x)-x| > \\delta],\\ ] ] where @xmath244 is chosen by the uniform continuity of @xmath19 : for @xmath108 let @xmath245 be such that @xmath246 whenever @xmath247 .",
    "thus , @xmath248 and so @xmath249 on the other hand , with @xmath250 , we have @xmath251|   \\le 2 \\|f''\\| \\p(|g_n(x)-x| > \\delta ) \\le 4 \\|f''\\| e^{-\\delta n^2/2},\\ ] ] by .",
    "hence @xmath252 letting @xmath44 , and since @xmath253 is arbitrary , we obtain the first claim .",
    "+  assume next that @xmath19 is lipschitz with lipschitz constant @xmath254 .",
    "then @xmath255 we have @xmath256 , where @xmath31 is a binomial random variable ",
    "we can easily find ( or look in a textbook ) that @xmath257 since @xmath258 and , for @xmath259 , the function @xmath260 is concave in @xmath76 , it follows that @xmath261 . on the other hand , for @xmath262 , @xmath263 for all @xmath76 .",
    "thus , the last term of is upper bounded by @xmath264    probabilistically , the operator @xmath265 , where @xmath266 is the identity operator , maps a function @xmath1 $ ] to the function @xmath267 $ ] which is the expected change of the function @xmath5 ( under the action of the chain ) per unit time , conditional on the current state being equal to @xmath171 .",
    "since the natural time scale is counted in time units that are multiples of @xmath57 , we can interpret @xmath268 as the expected change of @xmath5 per unit of real time .",
    "thus , its `` limit '' @xmath269 should play a similar role for the diffusion . and ,",
    "indeed , it does , but we shall not use this here . for further information on diffusions and their generators see , e.g. , karlin and taylor @xcite .",
    "the goal of this section is a probabilistic proof of theorem [ jointlimsthm ] .",
    "first notice that it suffices to prove for polynomial functions . indeed ,",
    "if @xmath5 is continuous on @xmath35 $ ] and @xmath253 , there is a polynomial @xmath270 such that @xmath271 ( by bernstein s theorem [ krthm ] ) .",
    "but then @xmath272}_n f - f\\| \\le   \\|b_n^{[nt ] } f - b_n^{[nt ] } h\\|   + \\|\\sp_t f - \\sp_t h\\|   + \\|b_n^{[nt ] } h - \\sp_t h\\| \\le 2{\\varepsilon}+ \\|b_n^{[nt ] } h - \\sp_t h\\|,\\ ] ] where we used the fact that both @xmath273}$ ] and @xmath274 are defined via expectations , and so @xmath275 } f - b_n^{[nt ] } h\\| = \\|b_n^{[nt]}(f - h)\\| \\le \\|f - h\\|$ ] , and , similarly , @xmath276 .",
    "therefore , if @xmath275 } h - \\sp_t h\\| \\to 0 $ ] for polynomial @xmath277 then @xmath278}_n f - f\\| \\to 0 $ ] for any continuous @xmath5 .",
    "equivalently , we need to prove that @xmath279}(x ) ) = \\e h(x_t(x ) ) , \\text { uniformly in $ x$}.\\ ] ]    notice that @xmath280}(x)$ ] , @xmath185 , is not a markov process .",
    "however if @xmath281 , @xmath189 , is a standard poisson process with rate @xmath9 , starting from @xmath282 , and independent of everything else , then @xmath283 is a markov process for each @xmath2 .",
    "moreover , for all @xmath234 $ ] , @xmath284}_n(x))\\right| \\to 0 , \\quad \\text{uniformly in $ x$}.\\ ] ] to see this , let @xmath79 be i.i.d .",
    "copies of @xmath75 , as in , and write the triangle inequality @xmath285\\right| + \\left|\\e [ f(g_n^1(x ) ) - f(x)]\\right|.\\ ] ] since @xmath286\\right| \\le \\|b_n f - f\\|$ ] for all @xmath171 , and since @xmath287 is independent of @xmath288 , we have that the first term of the right side of is @xmath289 , and so @xmath290 by the same argument , for @xmath291 , @xmath292 since @xmath89 is independent of @xmath293 , we can replace the @xmath171 in the last display by @xmath89 and obtain @xmath294\\right| \\le ( \\ell - k ) \\|b_n f - f\\| , \\quad \\text{for all } 0 \\le x \\le 1.\\ ] ] using the fact that the poisson process @xmath295 is independent of everything else , we obtain @xmath296}(x))\\ } \\right| \\le \\e\\{|\\phi(nt)-[nt]|\\}\\,\\|b_n f - f\\| , \\quad \\text{for all } 0 \\le x \\le 1.\\ ] ] but @xmath297|\\ }   \\le \\e\\{|\\phi(nt)-nt|\\ } + 1 \\le \\sqrt{\\e\\{|\\phi(nt)-nt|\\}^2 } + 1 = \\sqrt{nt}+1 $ ] , while , from voronovskaya s theorem , @xmath298 .",
    "therefore the right - hand side of converges to @xmath8 as @xmath44 , and this proves .",
    "therefore will follow from @xmath299 for all polynomial @xmath277 .    for each @xmath198",
    ", define a random curve @xmath300 that follows @xmath301 up to time @xmath302 and then switches to @xmath303 . more precisely , define @xmath304 see figure [ gluing ] .    it is here assumed that the brownian motion @xmath305 driving the defining equation for the wright - fisher diffusion is independent of all random variables used for the construction of @xmath301 . since , for any given initial state , the solution to is unique , we may replace the initial state by a random variable independent of the brownian motion , and this is what we did in the last formula .",
    "thus , if we prove that @xmath306 is differentiable with respect to @xmath302 , we shall have , for @xmath307 , @xmath308 to show that the last derivative exists as well as estimate it , we estimate @xmath309 and @xmath310 . since @xmath277 is a polynomial , it follows that @xmath311 is also a polynomial function of @xmath76 ( see proposition [ poly ] ) and so the forward equation holds : @xmath312 therefore , for any random variable @xmath313 with values in @xmath35 $ ] and independent of @xmath314 , we have @xmath315 taking expectations of both sides and interchanging differentiation and expectation ( by the dct ) we have @xmath316 setting @xmath317 , we have @xmath318    assume next that @xmath17\\to \\r$ ] is any function . using the identity @xmath319 = \\e f(g_n(y ) ) - f(y ) = b_n f(y)-f(y),\\ ] ] valid for any function @xmath5 and any @xmath76 , together with the fact that @xmath320 , as @xmath321 , we arrive at @xmath322 . \\ ] ] setting now @xmath323 and observing that @xmath324 , we arrive at @xmath325   \\label{frontb}\\ ] ]    combining and we have a formula for the derivative appearing in the last term of : @xmath326 where @xmath327\\ ] ] assume now that @xmath328 is lipschitz with lipschitz constant @xmath329 .",
    "then , by , @xmath330 where @xmath331 and @xmath332 , and so @xmath333 by the formula for @xmath334 when @xmath277 is a polynomial ( proposition [ poly ] ) , it follows that the @xmath335 is a finite constant .",
    "hence has been proved .",
    "[ cor1 ] with @xmath336 , @xmath337 } f_r(x ) = \\sum_{i=1}^r b_{i , r}(t)\\ , x^i,\\ ] ] where the @xmath338 are given by .",
    "this is theorem 2 in kelisky and rivlin @xcite .    with @xmath339 , we have @xmath337 } f_\\theta(x ) = \\e e^{-\\theta x_t(x ) } = : h(t , x,\\theta),\\ ] ] where @xmath340 satisfies @xmath341 and the pde @xmath342    the solution to this pde can be expressed in terms of modified bessel functions .",
    "we shall not pursue this further here .",
    "we provided a fully stochastic explanation of the phenomenon of convergence of @xmath3 iterates of bernstein operators of degree @xmath2 when @xmath2 and @xmath3 tend to infinity in different ways .",
    "this problem has received attention in the theory of approximations of continuous functions .",
    "we showed that the problem can be interpreted naturally via stochastic processes .",
    "in fact , these processes , the wright - fisher model and wright - fisher diffusion are very basic in probability theory and are well - understood .",
    "there are a number of interesting directions that open up .",
    "the most crucial thing is that @xmath343 is the expectation of a random variable .",
    "we can construct different operators by using different random variables .",
    "see , e.g. , karlin and ziegler ( * ? ? ?",
    "* eq .  ( 1.5 ) ) for an operator related to a poisson random variable .",
    "whereas karlin and ziegler study iterates of these operators , their approach is more analytical than probabilistic . by using approximations by stochastic differential equations , and taking advantage of the tools stochastic calculus , it is possible to derive convergence rates and other interesting results , including explicit formulas , such as the formula for @xmath344 } f_r(x)$ ] ( corollary [ cor1 ] and formula ) , obtained here by a simple application of the it formula .",
    "in section [ interlude ] we explained the most standard wright - fisher model where mutations are not allowed .",
    "if we assume that the probability that a gene of one type changing to another type also depends on the number of genes of each type , in a possibly nonlinear fashion , we obtain a more general model .",
    "mathematically , this is captured by letting @xmath345\\to [ 0,1]$ ] be an appropriate function , and by considering the markov chain obtained by iterating independent copies of the function @xmath346 , that is the markov chain @xmath347 , @xmath348 . for the case",
    "@xmath349 with @xmath350 chosen so that @xmath351 , see ethier and norman @xcite .",
    "by a random map @xmath353 we mean a random function from some probability space @xmath354 into a subspace of @xmath355 of functions from @xmath356 to @xmath357 . in rigorous probability theory",
    ", this means that all sets involved are equipped with @xmath358-algebras in a way that @xmath359 is a measurable function of @xmath360 . as a concrete example , in this paper , we considered @xmath361 $ ] and @xmath362^n$ ] .",
    "we equipped all sets with the lebesgue measure . for @xmath363 ,",
    "the map @xmath364 is a random variable with the uniform distribution .",
    "moreover , @xmath73 are independent .",
    "we defined @xmath365 the function @xmath366 by taking a different @xmath354 , we are able to construct two ( or more ) random maps @xmath367 that are independent . as usual in probability , we suppress the symbol @xmath360 from the definition of @xmath368 .",
    "when we talk about the composition @xmath369 of two random functions as above , we are talking about the composition with respect to @xmath76 .",
    "that is , @xmath370 .",
    "if @xmath5 is a deterministic function we define the operator @xmath371 by @xmath372 , @xmath373 .",
    "we can then easily see that @xmath374 the point being that the order of composition outside the expectation is the reverse of the one inside .",
    "this is why , for instance , @xmath375 in eq .  .",
    "another example of a random map is the @xmath376 , where @xmath301 is the markov chain constructed in section [ jointsec ] . for fixed @xmath302 and @xmath2 , the initial state @xmath76",
    "is mapped into the state @xmath377 at time @xmath302 .",
    "and yet another random map is @xmath378 , where @xmath206 , @xmath185 , is the wright - fisher diffusion .",
    "we composed these random maps in , after assuming that they are independent .",
    "let @xmath27 be independent random variables with zero mean with values between @xmath379 and @xmath380 for some @xmath381 .",
    "then , for @xmath382 , @xmath383 this inequality , due to hoeffding @xcite , is very well - known and can be found in many probability theory books .",
    "we just prove it below for completeness .    since @xmath384 is a convex function of @xmath76 for all @xmath385 and",
    "so if we write @xmath386 as a convex combination of @xmath379 and @xmath380 , @xmath387 we obtain @xmath388 hence @xmath389 here we used the inequality @xmath390 , valid for all real @xmath172 .",
    "this implies that @xmath391 .",
    "hence , for any @xmath385 , @xmath392 the last exponent is minimized for @xmath393 and its minimum value is @xmath394 .",
    "hence @xmath395 .",
    "reversing the roles of @xmath386 and @xmath396 , we have @xmath397 also .",
    "recall that sequence of real - valued random variables @xmath398 is said to be a time - homogeneous markov chain if @xmath399 , for all @xmath3 , @xmath76 and @xmath171 . often ,",
    "markov chains depend on a parameter which , without loss of generality , we can take to be an integer @xmath2 .",
    "let @xmath400 , @xmath401 be such a sequence .",
    "frequently , it makes sense to consider this process at a time scale that depends on @xmath2 .",
    "the problem then is to choose ( if any ) a sequence @xmath402 of positive real numbers such that @xmath403 and study instead the random function @xmath404 } } , \\quad t \\ge 0,\\ ] ] which , hopefully , may have a limit in a certain sense .",
    "this can be made continuous by linear interpolation .",
    "that is , consider the random function @xmath405 , @xmath185 , defined by @xmath406 } } + ( \\tau_n t-[\\tau_n t ] ) ( z_{n,{[\\tau_n t]+1}}-z_{n,{[\\tau_n t]}}).\\ ] ] we seek conditions under which the sequence of random continuous functions @xmath407 converges weakly to a random continuous function @xmath408 .    to define weak convergence ,",
    "we first define the notion of convergence in @xmath409 by saying that a sequence of continuous functions @xmath410 converges to a continuous function ( write @xmath411 ) if @xmath412 , as @xmath44 , for all @xmath413 .",
    "then we say that @xmath414 is continuous if , for all continuous functions @xmath5 , @xmath415 whenever @xmath411 .",
    "finally , we say that the sequence of random continuous functions @xmath416 converges weakly @xcite to the random continuous function @xmath48 if @xmath417 , as @xmath44 , for all continuous @xmath414 .",
    "we now quote , without proof , a useful theorem that enables one to deduce weak convergence to a random continuous function that satisfies a stochastic differential equation .",
    "for the whole theory we refer to stroock and varadhan ( * ? ? ?",
    "* chapter 11 ) .",
    "[ mc2diff ] let , for each @xmath66 , @xmath418 , @xmath419 , be a sequence of real random variables forming a time - homogeneous markov chain .",
    "assume there is a sequence @xmath402 , with @xmath420 , such that @xmath421 \\to \\sigma^2(x),\\ ] ] uniformly over @xmath422 for all @xmath423 , for some continuous function @xmath424 .",
    "for the same @xmath402 , we also assume that @xmath425 \\to b(x),\\ ] ] uniformly over @xmath422 for all @xmath423 , for some continuous function @xmath426 .",
    "assume also that , for all @xmath427 , there are positive constants @xmath428 , such that @xmath429 for all @xmath108 and all @xmath422 .",
    "finally , assume that there is @xmath430 such that @xmath431 , for all @xmath108 .",
    "then , as @xmath44 , the sequence of random continuous functions defined as in converges weakly to the solution of the stochastic differential equation @xmath432 provided that this equation admits a unique strong solution .",
    "ronald a.  devore and george g.  lorentz ( 1993 ) .",
    "_ constructive approximation_. springer - verlag , heidelberg .",
    "stewart n.  ethier and thomas g.  kurtz ( 1986 ) .",
    "_ markov processes : characterization and convergence .",
    "_ wiley .",
    "marc kac ( 1937 ) .",
    "une remarque sur les plynomes de m.  s.  bernstein . _ studia math . _",
    "* 7 * , 49 - 51 .",
    "howard m.  taylor and samuel karlin ( 1981 ) .",
    "_ a second course in stochastic processes . _ academic press , new york .",
    "bernt ksendal ( 2003 ) .",
    "_ stochstic differential equationsa , 6th ed .",
    "_ springer - verlag , berlin .",
    "allan pinkus ( 2000 ) .",
    "weierstrass and approximation theory .",
    "_ j.  approx .",
    "_ * 107 * , 1 - 66 .",
    "albert n.  shiryayev ( 1984 ) .",
    "_ probability_. springer - verlag , new york .",
    "daniel w.  stroock and s.r.s .",
    "varadhan ( 1979 ) .",
    "_ multidimensional diffusion processes .",
    "_ springer - verlag , berlin .",
    "karl weierstrass ( 1885 ) .",
    "ber die analytische darstellbarkeit sogennanter willkrlicher functionen [ _ sic _ ] einer reelen vernderlichen .",
    "_ sitzungsberichte der kninglich preuischen akad .",
    "der wissensch .",
    "zu berlin _ , 663 - 639 , 789 - 805 ."
  ],
  "abstract_text": [
    "<S> this paper presents a stochastic approach to theorems concerning the behavior of iterations of the bernstein operator @xmath0 taking a continuous function @xmath1 $ ] to a degree-@xmath2 polynomial when the number of iterations @xmath3 tends to infinity and @xmath2 is kept fixed or when @xmath2 tends to infinity as well . in the first instance , the underlying stochastic process is the so - called wright - fisher model , whereas , in the second instance , the underlying stochastic process is the wright - fisher diffusion . </S>",
    "<S> both processes are probably the most basic ones in mathematical genetics . by using markov chain theory and stochastic compositions , </S>",
    "<S> we explain probabilistically a theorem due to kelisky and rivlin , and by using stochastic calculus we compute a formula for the application of @xmath0 a number of times @xmath4 to a polynomial @xmath5 when @xmath6 tends to a constant . </S>"
  ]
}