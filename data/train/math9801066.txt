{
  "article_text": [
    "herb wilf , in addition to having done important work on problems related to counting combinatorial objects , has also done pioneering research on algorithms for generating combinatorial objects `` at random '' ( that is , generating an element of a finite combinatorial set so that each element has the same probability of being generated as any other ) ; see @xcite , @xcite , @xcite , @xcite , @xcite , @xcite , @xcite , @xcite , @xcite , @xcite and @xcite for fruits of this research .",
    "this survey article describes a recent advance in the area of random generation , with applications to plane partitions , domino tilings , alternating sign matrices , and many other sorts of combinatorial objects .",
    "the algorithm is of the `` random walk '' or `` monte carlo '' variety , but unlike many such algorithms it does not have any initialization bias .",
    "the heart of the algorithm is the method of coupling from the past explored by david wilson and myself in a joint article @xcite . for the sake of readability and motivation",
    ", i will start by focusing on the application of our method to plane partitions .",
    "a beautiful formula of macmahon @xcite says that the number of plane partitions of @xmath0 with at most @xmath1 rows , at most @xmath2 columns , and no part exceeding @xmath3 ( hereafter to be called `` @xmath4-partitions '' ) is given by @xmath5 ( see @xcite and @xcite for definitions of ordinary partitions and plane partitions , and section 2 of @xcite for a fairly simple self - contained proof of macmahon s formula ) .",
    "note that in the case @xmath6 , a plane partition with no part exceeding 1 can be read as the ferrers diagram of an ordinary partition , and macmahon s formula devolves into the assertion that the number of ordinary partitions of @xmath0 with at most @xmath1 parts and no part exceeding @xmath2 is given by the binomial coefficient @xmath7 .",
    "indeed , it is easy to see that such partitions correspond to lattice paths of length @xmath8 joining @xmath9 to @xmath10 , or equivalently , combinations of @xmath8 elements taken @xmath1 at a time . in view of these correspondences",
    ", it is easy to generate a random @xmath11-partition .    just as a lattice path in the @xmath1 by @xmath2 rectangle is a 1-complex ( made up of edges in a 2-dimensional grid ) with prescribed boundary ( namely the pair of points @xmath9 and @xmath10 ) , an @xmath4-partition corresponds to a 2-complex ( made up of square 2-cells in a 3-dimensional grid ) whose boundary is a particular non - planar hexagon ( namely the one that goes from @xmath12 to @xmath13 to @xmath14 to @xmath15 to @xmath16 to @xmath17 to @xmath12 in cyclic order ) . in the former case ,",
    "one requires that the lattice path should have ( minimal ) length @xmath8 ; in the latter case , one requires that the surface spanning the hexagon should have ( minimal ) area @xmath18 .    in this paper",
    "i will describe an algorithm for generating a random @xmath4-partition with @xmath19 arbitrary .",
    "this algorithm was used to generate figure 1 , which shows a random @xmath20-partition , or rather the spanning surface that it determines , viewed from a point on the ray @xmath21 ; the three different orientations of grid - squares in 3-space are seen in projection as three different orientations of rhombuses in 2-space .",
    "it should be stressed that the size of the plane partition ( that is , the sum of the parts ) was not specified in advance ; it is a random variable with expected value @xmath22 .",
    "note the non - homogeneity of the picture : there is an approximately circular central region in which rhombuses of different orientations are mixed together , surrounded by six regions in which rhombuses of a single orientation predominate . as is shown in @xcite , in a certain strong probabilistic sense the boundary of the central region",
    "does indeed converge to a perfect circle when @xmath0 is large .",
    "this fact was first conjectured on the basis of pictures like figure 1 , and all known proofs depend on steps whose clearest motivation comes from `` knowing the answer in advance '' .",
    "thus we see that there are phenomena pertaining to random @xmath4-partitions that would not have been easy to divine by pure theory , and that an algorithm for generating such plane partitions randomly can be a valuable tool for discovering and investigating such phenomena experimentally .    in part 2 of this paper ,",
    "i will show that this problem , along with several others , is a special case of the problem of choosing a random element of a finite distributive lattice . in part 3",
    ", i will describe an algorithm that allows one to solve this problem .",
    "like the well - known folk - algorithm for generating a random element of a 3-element set via independent tosses of an unbiased coin , this algorithm runs in finite expected time , even though it can take arbitrarily long to return an answer .",
    "i conclude in part 4 with some open questions .",
    "the 3-dimensional ferrers diagram associated with an @xmath4-parti- tion is just an order ideal of the poset obtained as the product of chains of cardinalities @xmath1 , @xmath2 and @xmath3 .",
    "writing such chains as * a * , * b * and * c * , respectively , and using @xmath23 to represent the lattice of order ideals of a finite poset ( ordered by inclusion ) , we see that what we are effectively trying to do is generate a random element of the distributive lattice @xmath24 .",
    "( see @xcite for definitions of posets , order ideals , lattices , and distributive lattices , and for the fact that every finite distributive lattice can be represented as @xmath25 for some finite poset @xmath26 . )    here is another way to view this ordering .",
    "consider a hexagon whose internal angles all measure 60 degrees and whose sides in cyclic order have lengths @xmath27 , respectively , and dissect it into @xmath28 unit equilateral triangles .",
    "create a graph @xmath29 whose vertices correspond to these triangles , where two vertices of @xmath29 are adjacent if and only if the corresponding triangles in the dissection share an edge .",
    "( @xmath29 is called a `` honeycomb graph '' for obvious reasons . )",
    "then each @xmath4-partition corresponds to a tiling of the aforementioned hexagon by rhombuses of side length 1 ( each composed of two equilateral triangles joined edge to edge ) , and each of these tilings in turn corresponds to a perfect matching of @xmath29 , that is , to a subset of the edges of @xmath29 in which each vertex of @xmath29 appears just once .",
    "it is shown in @xcite ( which was inspired by earlier work of conway and lagarias @xcite and thurston @xcite ) that the perfect matchings of any bipartite planar graph can be given the structure of a distributive lattice . in the case of the honeycomb - graph @xmath29",
    "described above , one obtains the same distributive lattice structure @xmath24 as before .",
    "if instead one allows graphs @xmath29 that are subgraphs of a square grid , one is able to put a distributive lattice structure on the set of all tilings of a connected subset of the square grid by dominos .",
    "( these special cases are discussed in @xcite . )",
    "more generally ( again see @xcite ) , if @xmath29 is any bipartite planar graph , and @xmath30 is any function from the vertex set of @xmath29 to the non - negative integers , then the set of @xmath31-factors of @xmath29 ( defined as the set of subgraphs of @xmath29 in which vertex @xmath32 has degree @xmath33 for all vertices @xmath32 ) can be given the structure of a distributive lattice ( outside of the trivial case in which no @xmath31-factors exist ) .",
    "another class of examples of distributive lattices in combinatorics comes from constrained lattice paths .",
    "for instance , lattice paths of length @xmath34 that go from @xmath35 to @xmath36 without straying outside of the triangle with vertices @xmath37 , @xmath36 and @xmath36 are a standard incarnation of the `` catalan objects '' .",
    "more generally , we can consider all minimal - length lattice paths that go from one fixed lattice point to another without straying outside some fixed convex region .",
    "assuming that the set of such lattice paths is non - empty , it is easy to show that the set of all such lattice paths is a distributive lattice , with the ordering being defined by inclusion of the associated ferrers diagrams .",
    "one can also extend this approach to the lattice paths enumerated by trinomial coefficients ( with step - vectors @xmath38 , @xmath39 , and @xmath40 ) .    a further example is provided by the alternating sign matrices introduced by mills , robbins , and rumsey @xcite .",
    "one can transform each @xmath0 by @xmath0 alternating sign matrix into an @xmath41 by @xmath41 array of numbers in such a fashion that if one takes the component - wise minimum ( or component - wise maximum ) of any two such arrays , one gets another array associated with an @xmath0 by @xmath0 alternating sign matrix . in this fashion ,",
    "the set of alternating sign matrices of fixed size becomes a distributive lattice .",
    "( see @xcite for a more detailed discussion of this . )    a final situation i will mention in which a non - obvious distributive lattice structure exists is the set of independent sets in a bipartite graph @xmath29 .",
    "( this lattice structure has been noticed in the literature several times independently . ) here is the way to see it : if we color the vertices of @xmath29 black and white and write every independent set @xmath42 as @xmath43 where the vertices in @xmath44 and @xmath45 are black and white respectively , then we may define the meet and join of @xmath43 and @xmath46 as @xmath47 and @xmath48 , respectively .",
    "we recall here that every finite distributive lattice admits a unique representation ( up to isomorphism ) as @xmath25 , for @xmath26 some finite poset ( which in fact is easily constructible from the lattice as the sub - poset of join - irreducibles ) . in each of the cases described above ,",
    "the bijection between the combinatorial objects described and order ideals of an associated poset @xmath26 is easily implemented on a computer . thus ,",
    "if we can solve the problem of generating a random element of @xmath25 for an arbitrary finite poset @xmath26 , we will have solved the problem of generating random @xmath31-factors of bipartite planar graphs , the problem of generating random independent sets in a general bipartite graph , and many other problems as well .",
    "in this section i describe a monte carlo approach to sampling from the uniform distribution on the set @xmath25 , using a markov chain whose state are the elements of @xmath25 and whose steady state distribution is the uniform distribution on @xmath25 .",
    "if one merely simulated this markov chain for a large but finite number of steps in the ordinary way , one would have a distribution that was close to the steady - state ( uniform ) distribution , but there would be some residual error ( `` initialization bias '' ) . later in this section",
    "i will explain how one can get rid of this bias by effectively simulating the markov chain for _ infinitely _ many steps , from time minus infinity to time zero ( the method of coupling from the past ) .",
    "it is natural to make @xmath25 into a graph @xmath49 by declaring two order ideals to be adjacent iff their symmetric difference consists of exactly one element of @xmath26 .",
    "it is easy to show that this graph is connected .",
    "moreover , we can associate with each element @xmath50 of @xmath26 a randomization move that preserves the uniform distribution on @xmath25 ( the probability distribution that assigns each order ideal probability @xmath51 ) : given an order ideal @xmath52 , toss a fair coin , and if the coin comes up heads ( resp",
    ".  tails ) , replace @xmath52 by @xmath53 ( resp . , @xmath54 )",
    ", unless the resulting subset of @xmath26 is not an order ideal , in which case leave @xmath52 alone .    if one performs an infinite sequence of such randomization moves in which each new _ randomization site _",
    "@xmath50 is chosen independently from the uniform distribution on @xmath26 ( or more generally from any probability distribution that assigns positive probability to each element of @xmath26 ) , then this process is simply a stationary markov chain whose state space is the set of order ideals of @xmath26 ; standard ideas from the theory of markov chains guarantee that the probability of any particular order ideal being the current order ideal converges to @xmath51 as time goes to infinity .",
    "this markov chain gives us a way , in principle , of generating a random element of @xmath25 that is as close to unbiased as we like ( i.e. , whose governing distribution is as close to uniform as we like ) .",
    "however , in the absence of estimates of the mixing time of the markov chain , it is not clear for how long a time the chain must be run in order to drive the bias below some predetermined amount deemed acceptable .",
    "moreover , we seek a way of generating samples that has _ no _ bias when truly random bits are used .",
    "fortunately , there is a way around this problem . the markov chain that we have described is monotone in the sense that if we were to run _ two _ instantiations of it in parallel , using the same randomization sites and the same coin - tosses in both runs but starting from different initial order ideals @xmath55 and @xmath56 , then , provided @xmath57 , the order ideals @xmath58 and @xmath59 that result after @xmath0 steps of joint randomization must satisfy the relation @xmath60 . in particular , if we had chosen @xmath55 and @xmath56 to be the empty order ideal @xmath61 and the full order ideal @xmath62 , respectively , and if we find after @xmath0 steps that @xmath58 and @xmath59 are _ equal _ ( call their common value @xmath63 ) , then _ every _ run of the markov chain for @xmath0 steps using those randomization sites and coin - tosses will put us in state @xmath63 , regardless of the initial state @xmath52 ; all such histories are `` squeezed '' between the @xmath64-history and the @xmath65-history , and since these coalesce over the course of the simulation , so must all histories .",
    "it turns out that for most of the examples that arise in practice , this kind of coalescence occurs fairly quickly .",
    "this gives us a way of doing a kind of `` backwards simulation '' of the markov chain that effectively lets us run the chain for a huge number of steps without ( usually ) having to perform anywhere near the number of steps required in a straightforward simulation .",
    "say , for instance , that we want to run the markov chain on the state - space @xmath25 for one million steps , starting from initial state @xmath66 , using random updates from time @xmath67 to time 0 ( we will see shortly why it is convenient to index time in this way ) .",
    "suppose that our markov chain is sufficiently rapidly mixing that over the course of a thousand steps , it s fairly likely for the initial states @xmath64 and @xmath65 to lead to the same final state when evolved in tandem .",
    "if we simulate the markov chain from time @xmath68 to time 0 , using both @xmath64 and @xmath65 as initial states ( let us call this `` phase one '' of our backwards simulation ) , and we indeed find that both histories coalesce at some state @xmath63 at time 0 , then we do not need to run the full simulation from one million steps in the past , for we can already be sure that such a simulation would have given us @xmath63 as our sample .",
    "indeed , in this case we do not even have to choose what the randomization sites and coin - tosses before time @xmath68 are , since they do not enter into the simulation . in the unlikely event that the two histories that were started at time @xmath68 do not coalesce by time 0 ,",
    "then we could go back and do an honest simulation for a million steps , starting from @xmath66 at time @xmath67 ( let us call this `` phase two '' ) . in this way we can simulate the behavior of a million - step random",
    "walk using ( most of the time ) only about two thousand simulation steps .",
    "note however that if one wishes to avoid introducing bias into one s sample , it is crucial that one use the _ same _ randomization sites and coin - tosses from time @xmath68 onward during the long , `` honest '' run ( phase two ) as one did during the short preliminary run ( phase one ) .",
    "if one wants to simulate a _ billion _ steps of random walk , one can modify phase two of the preceding algorithm by running the million - step simulation ( in the rare case where one thousand steps do not suffice ) using @xmath64 and @xmath65 as starting states , rather than @xmath66 . only in the incredibly rare case where this million - step simulation fails to coalesce by time zero",
    "would one need to resort to a billion - step simulation starting from @xmath66 ( `` phase three '' ) , being careful once more to use the already - determined randomization sites and coin - tosses from time @xmath67 to time 0 .    note",
    "that the numbers one million and one billion enter into these procedures in the form of bounds on how far back into the past one is willing to go before one `` honestly '' uses @xmath66 as the starting state rather than trying to be clever by starting from @xmath64 and @xmath65 and hoping that they will coalesce by time 0 .",
    "suppose that one removes this upper bound on how far into the past one is willing to go : if coalescence fails , one goes back into the past 1000 times as far as one just did and tries again .",
    "then one can show that with probability 1 the desired coalescence _ will _ eventually occur ( where our notion of `` eventuality '' goes backward in time rather than forward ) , and that the sample returned is effectively a sample `` generated by a run of length infinity ''  that is , an absolutely unbiased sample .",
    "this is david wilson s method of coupling from the past .",
    "it can not be overemphasized that the idea of progressing backwards into the past is an indispensable feature of the algorithm . in particular ,",
    "if one were simply to run the markov chain forwards from initial states @xmath64 and @xmath65 in tandem until the histories coalesced and then to output as one s sample the coalescent state , one would in general get a biased sample .",
    "in contrast , samples generated via coupling from the past are entirely free of bias , to the extent that the coin - tosses used are random .",
    "the version of the algorithm discussed above can be improved upon ; for instance , it is much better to go progressively 1 , 2 , 4 , 8 , ... steps into the past rather than @xmath69 , @xmath70 , @xmath71 , ... steps .",
    "moreover , the algorithm can be generalized so as to apply to interesting situations in statistical mechanics where the desired distribution is not uniform , but is the boltzmann distribution for some non - constant energy function on the configuration space .",
    "all of these developments are described more fully in @xcite .    here , we content ourselves with showing that the expected running time is finite , in the case where there exists a finite @xmath72 and a positive @xmath73 such that over the course of any time interval of length @xmath72 in the simulation , the conditional probability of coalescence occurring , given initial states @xmath64 and @xmath65 , is at least @xmath73 .",
    "( this holds for all the interesting applications ; in each case , it suffices to find an @xmath72 such that the probability of going from @xmath64 to @xmath65 in @xmath72 steps , conditional upon starting in state @xmath64 , is positive , though the @xmath72 one gets from this approach is much , much larger than the typical time - scale over which coalescence occurs . ) to prove the claim , note that over the course of @xmath74 consecutive steps , divided into @xmath75 blocks of length @xmath72 , the only way in which coalescence could fail to occur is if all @xmath75 blocks are `` non - coalescing '' ; yet independence of the coin - tosses tells us that this is an event of probability at most @xmath76 .",
    "as @xmath0 gets large , this probability shrinks to zero exponentially , implying our claim on the finiteness of expected running time .    the algorithm described above is not always efficient ; indeed , in @xcite wilson and i describe a case in which the modified monte carlo algorithm takes exponentially long , even though a direct algorithm for constructing a random order ideal is quite easy to fashion ( see the cautionary note at the end of section 3.2 in @xcite ) .",
    "however , as a practical matter the modified monte carlo algorithm is quite efficient for many sorts of combinatorial objects that arise naturally , such as those mentioned in section 2 .",
    "three final points on implementation deserve note .",
    "first , the algorithm remains valid if instead of choosing randomization sites in accordance with some fixed distribution on @xmath26 one chooses randomization sites according to some other scheme , provided that two conditions are satisfied : the choice of randomization sites should not be affected by the outcomes of the coin flips , and it must be the case that with probability 1 each element of @xmath26 gets chosen as a randomization site infinitely often . under these hypotheses ,",
    "the ( non - stationary ) markov chain on @xmath25 has the uniform distribution as its unique steady - state measure , and the method of coupling from the past will get you there with a finite amount of simulation ( with probability 1 )",
    ". for instance , one may rotate among all the elements of @xmath26 in some fixed order , rather than choosing the randomization sites randomly . in this way one",
    "reduces the amount of information that the algorithm needs to save .",
    "second , if one is using pseudo - random bits given by some trusted pseudo - random number generator ( as i imagine most users of this algorithm will do ) , then , though it is often necessary to _ reuse _ bits , it is not necessary to _ save _ them all .",
    "one can for instance save only seeds that will enable one to re - create the formerly used bits when they are needed again .",
    "third , it should be borne in mind that the output of the monte carlo method is likely to be somewhat correlated to its running - time .",
    "if one were to use the method to generate @xmath77 samples , where @xmath77 was determined on - the - fly rather than chosen in advance , then one might be contaminating one s samples with bias .",
    "the scrupulous investigator may therefore wish to commit to a certain value of @xmath77 ahead of time , based on a preliminary investigation of how long it is likely to take to run the procedure @xmath77 times .",
    "another sort of scheme for randomly generating an order ideal of a finite poset @xmath26 is the recursive approach in which one decides whether or not to include @xmath50 in the random order ideal by tossing a coin whose bias corresponds to the ratio of the cardinalities of two distributive lattices , namely , the lattice of order ideals of @xmath26 containing @xmath50 and the lattice of order ideals of @xmath26 not containing @xmath50 .",
    "this method ( like coupling from the past ) will not always be fast , since the problem of counting antichains ( and hence , equivalently , order ideals ) in a finite partially ordered set is # p - complete ( see @xcite ) .",
    "yet another approach would be one along the lines of recent work of flajolet , zimmermann , and van cutsem ( see @xcite and @xcite ) , who have already created maple software that ( suitably instructed ) can create random plane partitions of the sort shown in figure 1 . _",
    "which way is `` best '' ? _ ( or rather : are there features of a lattice that might dictate when one or another of these approaches will do best ? )    in the case of planar graphs @xmath29 that are not bipartite , it is still possible to generate random perfect matchings of @xmath29 efficiently : the method of kasteleyn @xcite allows one to write the number of perfect matchings as a pfaffian . by calculating the ratio of two such pfaffians",
    ", one can determine the exact proportion of matchings of @xmath29 that contain a given edge , and one can accordingly make an unbiased decision as to whether or not to include this edge in the matching .",
    "applying this recursively , one can generate a random matching of @xmath29 .",
    "surprisingly , wilson @xcite showed that it is possible to randomly generate perfect matchings within a constant multiple of the time needed to compute just one pfaffian ; using sparse linear algebra , this time is @xmath78 arithmetic operations , or @xmath79 bit operations . in the case where @xmath29 is bipartite ,",
    "a specialized version of the pfaffian method ( the permanent - determinant method ) applies in much the same way ; but in this situation one can also apply the markov chain algorithm described in this paper .",
    "_ can the method of this paper be extended to apply in the non - bipartite case ? _",
    "if one uses a biased coin in place of a fair one , one can devise an algorithm in which the probability of a particular order ideal @xmath52 being generated is proportional to @xmath80 , where @xmath81 is the cardinality of @xmath52 and @xmath82 is any positive real number .",
    "that is , we can generate a random element of a distributive lattice so that all the elements of rank @xmath75 in the lattice have individual probability proportional to @xmath83 of being picked .",
    "we might try to choose @xmath82 so as to maximize the collective probability of the elements of rank @xmath75 , but even using this optimal @xmath82 we might have to run the biased procedure many times before we obtain a sample in rank @xmath75 .",
    "note , however , that the resulting sample will be governed by a uniform distribution on the @xmath75th rank of the lattice .",
    "_ is there an efficient procedure for selecting an element in a particular rank of a finite distributive lattice ? _",
    "note that work of flajolet , zimmermann and van cutsem ( @xcite ) provides a solution in some cases .",
    "lastly : _ to what extent can the method of coupling from the past be extended to sampling from more general partially ordered sets , _ such as modular lattices or lattices in general ? for an example of an application of the method to a special kind of non - distributive lattice , see the paragraphs in subsection 3.3 of @xcite that treat permutations .",
    "the article gives the impression that the method of section 3 was used to generate figure 1 .",
    "in fact , a more efficient approach was used , exploiting the special structure of the lattice @xmath25 in question . in particular , the poset @xmath26 of join - irreducibles of the lattice is a cube , and this cube can be divided into `` filaments '' ( where elements @xmath84 belong to the same filament ) . rather than merely attempting to add or delete a particular element of @xmath26 ,",
    "the algorithm attempts to modify @xmath52 by either deleting the largest element of the filament that is in @xmath52 or adjoining the smallest element of the filament that is not in @xmath52 .",
    "putting it differently : the basic steps of the markov chain are `` hexagon - moves '' on the tiling , where one executes a non - trivial hexagon - move by changing the way a small unit hexagon of side - length 1 inside the large region is tiled by three rhombuses ( there are exactly two ways such a hexagon can be tiled ) .",
    "section 3 specifies that one is to choose the successive randomization sites @xmath50 from the uniform distribution on @xmath26 ( or more generally from any probability distribution that assigns positive probability to each element of @xmath26 ) .",
    "however , one has a great deal of leeway here .",
    "for instance , one can use a deterministic sequence of @xmath50 s that cycles through the set of elements of @xmath26 ; as long as the coins used in the algorithm are random , the procedure will still lead to a random order ideal . in the case where @xmath26 is ranked , one particularly natural idea is to do all the @xmath50 s of even rank , followed by all the @xmath50 s of odd rank , and so on , in alternation .",
    "this particular scheme is well - suited to parallel computation , since all the randomizations of the same parity that are considered in any cycle can be done independently of one another .",
    "h.  wilf , a unified setting for selection algorithms , ii , _ annals of discrete mathematics _ * 2 * : _ algorithmic aspects of combinatorics _ , north holland ( 1978 ) , 135148 .",
    "h.  wilf , the uniform selection of free trees , _",
    "j.  algorithms _ * 2 * ( 1981 ) , 204207 ."
  ],
  "abstract_text": [
    "<S> this survey article describes a method for choosing uniformly at random from any finite set whose objects can be viewed as constituting a distributive lattice . </S>",
    "<S> the method is based on ideas of the author and david wilson for using `` coupling from the past '' to remove initialization bias from monte carlo randomization . </S>",
    "<S> the article describes several applications to specific kinds of combinatorial objects such as tilings , constrained lattice paths , and alternating - sign matrices .    </S>",
    "<S> _ this article is dedicated to herbert wilf + in honor of his sixty - fifth birthday . _ </S>"
  ]
}