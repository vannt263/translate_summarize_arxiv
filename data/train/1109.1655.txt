{
  "article_text": [
    "the problem of resolution of singularities has stimulated mathematical research for more than a century now , ranging from first results for curves in the late 19th century through to the case of surfaces ( e.g. @xcite , @xcite ) and 3-folds ( e.g. @xcite ) , culminating in the famous proof of hironaka for the general case in characteristic zero in 1964 @xcite .",
    "but this result did not end the interest in the problem : first of all , the case of positive characteristic is still an open problem and an active field of research ; on the other hand , the fact that hironaka s proof was highly non - constructive , led to the question of the existence of algorithmic approaches in characteristic zero and to the development thereof ( e.g. @xcite,@xcite,@xcite etc . ) .",
    "+ in its simplest form the problem of desingularization can be phrased as : given a variety @xmath0 , determine a non - singular variety @xmath1 and a proper birational morphism @xmath2 which leaves @xmath3 unchanged . in general , it is a rather complicated task to construct such a morphism @xmath4 by an iteration of improvements of @xmath0 through blow - ups in appropriate centers , where the choice of center turns out to be the crucial point . in certain special situations , however , like binomial varieties or curves and surfaces , significant simplifications in the choice of centers and",
    "the computation of the blow - ups or the additional use of normalization steps can lead to faster algorithms which sometimes also provide an @xmath1 which is covered by fewer charts than the one constructed by the general algorithm .",
    "this has led to implementations of the various types of algorithms of which at least one for each type is available as a singular library as of version 3.2 .",
    "being offered a variety of algorithms for very similar tasks is certainly a nice feature for the experienced user , but novice users are easily overwhelmed by it without hints to guide their choice .",
    "therefore a thorough discussion of the structural differences and the resulting pros and cons is the topic of this article . as it is not possible to explain all these algorithms in detail in one article ( this would rather require a book ) or at least do each of them justice in a short description , we only highlight the main ideas and general structure of each type of approach and give the corresponding singular commands and an interpretation of the resulting output in explicit examples . + for comparing algorithms ,",
    "computer science usually suggests time and space complexity considerations . in this case , however , it has been shown in @xcite that the complexity of the general resolution algorithm is in the complexity class @xmath5 for a @xmath6-dimensional variety contains all linear functions , @xmath7 all polynomial functions and @xmath8 all towers of exponential functions .",
    "] , which for a computer scientist basically translates to it is completely hopeless to calculate anything with this algorithm. on the other hand , algebraic geometers know from experience with groebner basis computations or primary decomposition ( both in @xmath8 ) that many examples , which they want to compute , are quite far from the maximum complexity of the algorithm .",
    "this suggests to select a set of typical examples from practical applications and use these for the comparison , which is our point of view in this article .",
    "+ after very briefly sketching the common main ideas of all hironaka style approaches and giving a singular example thereof in the section [ sec2 ] , we consider the structurally much simpler binomial and toric case in the section [ sec3 ] . in the subsequent section [ sec4 ] ,",
    "we then consider specialized algorithms for low - dimensional varieties and then conclude the article with a comparison of the algorithms in section [ sec5 ] .",
    "the authors are grateful to santiago encinas , herwig hauser , ana bravo , orlando villamayor , santiago zarzuela , nobuki takayama , mohammed barakat , hans schnemann and gerhard pfister for fruitful discussions , some concerning the mathematical side of this article , some related to software development and applicability of the respective singular libraries .",
    "hironaka s groundbreaking 1964 article @xcite on resolution of singularities in arbitrary dimension in characteristic zero contains both constructive and non - constructive arguments . seeking better understanding of this proof",
    ", these non - constructive steps were then studied in detail and filled with explicit algorithmic constructions leading to the first algorithmic proofs of desingularization in arbitrary dimension in the late 1980s / early 1990s ( see e.g. @xcite @xcite ) , which were subsequently refined further ( e.g. @xcite ) .",
    "although these approaches may differ significantly in various constructive steps they all follow the general structure of the original proof .",
    "+ to explain all variants of algorithmic proofs in the flavour of hironaka in detail would require at least a book , so we concentrate on giving a brief impression of the common main ideas of all these approaches and the resulting computational tasks  in the hope of providing the context for the corresponding examples in singular .",
    "+    for every algebraic variety over a field of characteristic zero , a desingularization can be achieved by a finite sequence of blow ups in suitable non - singular centers .    from this formulation",
    ", we already see that two different algorithmic tasks arise here : the blow up , which is a grbner basis computation and hence does not pose any significant problems , and the choice of suitable centers , which is the very heart of the construction . for our context , the gist of the choice of center can best be formulated by means of a resolution function whose maximal locus yields the upcoming center .",
    "+ to define the resolution function , we work with the ideal defining the algebraic variety , and we proceed by induction on the dimension of the ambient space . this resolution function , which needs to be both zariski- and infinitesimally upper semi - continuous , has the following general structure : @xmath9 where each component @xmath10 stands for the contribution by an auxiliary ideal in ambient dimension @xmath11 .",
    "each of these components is then composed of an order of the ideal ( or in top dimension in some approaches the hilbert - samuel function ) and some counting function which ensures normal crossing with the exceptional divisors .",
    "the construction of the auxiliary ideals is quite delicate and a key step in hironaka s inductive argument . to illustrate the flavour of this construction without going into too many technicalities ,",
    "let us consider a power series w.r.t .",
    "a main variable @xmath12 @xmath13 it has order at most @xmath14 and this order is attained if and only if the order of each coefficient @xmath15 is at least @xmath11 .",
    "this can also be phrased as @xmath16 where the ideal generated by these powers of the coefficients now plays the role of the first auxiliary ideal .",
    "of course , the choice of the main variable , i.e. the hypersurface of maximal contact , is crucial in this construction and additional difficulties here arise from the fact that such a hypersurface exists only locally .",
    "+ there are two implementations of villamayor - style algorithms for the general case , both in singular : @xcite and @xcite where the latter one is part of the standard singular distribution and is well suited for use with the utilities in the additional library @xcite for further computations with resolution data . in this article , we will only give a syntax example for this second implementation : +    ....    > lib \" resolve.lib \" ;            // load the library resolve   > ring r=0,x(1 .. 3),dp ;          // ring of char 0 with                                  //",
    "variables x(1),x(2 ) and x(3 )   > ideal j = x(1)^2-x(2)*x(3)^2 ;   //",
    "whitney umbrella   > list re = resolve(j ) ;           // compute the desingularization > size(re ) ;                     //",
    "the output is a list   2                               // of 2 components   > re[1 ] ;                        // list of final charts                                 // every chart is given by                                 //",
    "its defining ring [ 1 ] :                            //",
    "there is only one final chart //",
    "characteristic : 0 // number of vars : 3 //",
    "block    1 : ordering dp //                 : names",
    "x(2 ) x(3 ) y(1 ) //",
    "block    2 : ordering c > re[2 ] ;                        // list of all charts [ 1 ] : // characteristic",
    ": 0 // number of vars : 3 //",
    "block    1 : ordering dp //                 : names",
    "x(1 ) x(2 ) x(3 ) //",
    "block    2 : ordering c [ 2 ] : // characteristic : 0 // number of vars : 3 //       block    1 : ordering dp //                 : names",
    "x(2 ) x(3 ) y(1 ) //",
    "block    2 : ordering c ....    the output is a list consisting of two lists of rings .",
    "the first component gives the final charts , and the second component is the list of all charts . to see the information which is inside a concrete ring or chart it is enough to change to the respective ring and proceed as follows :    .... > def rr = re[2][2 ] ;                          //",
    "define a new ring > setring rr ;                               //",
    "set this ring > showbo(bo ) ;                               // show the information = = = = ambient space _ [ 1]=0                                      // the whole space = = = = ideal of variety :                      //",
    "transform ideal _ [ 1]=y(1)^2-x(2 ) = = = = exceptional divisors :                  // list of exceptional divisors [ 1 ] : _ [ 1]=x(3 ) = = = = images of variables of original ring : //",
    "morphism defining _ [ 1]=x(3)*y(1 )                              //   the blowing up _ [ 2]=x(2 ) _ [ 3]=x(3 ) ....    in addition , using the additional library @xcite it is possible to obtain a picture illustrating the hierarchy of charts .",
    "we include here a singular syntax example , but omit the picture , as it only contains two charts in this example .",
    "( example 2 in the next section leads to a more meaningful picture included as figure 1 . )    .... > lib \" reszeta.lib \" ;          //",
    "library needed for visualization > lib \" resgraph.lib \" ;         //",
    "library needed for visualization > list iden0=collectdiv(re ) ; // collect all the exceptional divisors > restree(re , iden0[1 ] ) ;       // creates a jpg file with the resolution tree   ....    as this general approach is obviously",
    "quite time and space consuming , it is worthwhile to use specialized algorithms wherever those are available .",
    "in the setting of binomial ideals or toric ideals , the situation is much simpler than in the general case .",
    "this allows a restriction of the methods to combinatorial constructions and arguments .",
    "apart from the classical algorithm of star subdivision as toric resolution of singularities ( see e.g. standard textbooks about toric geometry like @xcite ) , there are combinatorial variants of both main algorithmic approaches to hironaka resolution , i.e. one in the flavour of bierstone and milman @xcite and one in the philosophy of villamayor @xcite , @xcite .",
    "+ here we will only consider the latter one , which is available as @xcite in the standard distribution of singular .",
    "it is mainly a combinatorial game on the exponents of the generators of the ideal . roughly speaking",
    ", the algorithm looks for a smallest order term in the binomials and chooses one of the variables involved in that term to make an induction on the dimension of the ambient space .",
    "then , it looks again for the next smallest order . + this combinatorial game provides an ideal generated by hyperbolic equations that is locally monomial .",
    "this ideal needs to be rewritten as a monomial one to achieve a log - resolution , see @xcite and @xcite for details .",
    "another benefit of the purely combinatorial approach is the applicability of the algorithm in positive characteristic ( in contrast to the general algorithms ) . in a bit more detail",
    ", the philosophy of the computations can be illustrated in the scheme below :",
    "@xmath17    .... > lib \" resbinomial.lib \" ;          // load the library resbinomial > ring r = 2,(x(1 .. 3)),dp ;        // ring of char 2 with                                   // variables x(1),x(2 ) and x(3 )    > ideal j = x(1)^2-x(2)^2*x(3)^2 ; > list b = binresolution(j ) ;        // compute the binomial resolution > size(b ) ;                        //",
    "the output is a list of 4 components 4    > b[1 ] ;                           // list of final charts in char 0   > b[2 ] ;                           // list of all charts in char 0   > b[3 ] ;                           // list of final charts in char 2 > b[4 ] ;                           // list of all charts in char 2 ....    the first two components of the output are needed for internal computations and also for visualization of charts , since the input for the additional library @xcite has to be in characteristic zero .",
    "then , for visualization of the resolution tree , select the first two components .    .... > list l2=b[1],b[2 ] ; > list iden0=collectdiv(l2 ) ; > restree(l2,iden0[1 ] ) ; ....     lists the set of exceptional divisors visible in the chart .",
    ", width=302 ]",
    "the other main setting , in which specialized algorithms exist , is the situation of low dimensional varieties , i.e. curves and surfaces . as before , these situations are significantly simpler than the general case and the first approaches to these problems historically precede hironaka s proof by decades .",
    "+ as the singular loci of curves can only be finite sets of points , no special precautions to choose appropriate centers need to be taken and a resolution can be achieved by simply using the points of the singular locus as the centers of the blowing ups . for surfaces ,",
    "the situation already becomes significantly more complicated : the singular loci may be 1-dimensional and may themselves be singular .",
    "in contrast to hironaka s approach , the original proof of resolution of surface singularities , of which the ideas date back to jung s 1908 article ( @xcite,@xcite ) , does not only involve blow - ups , but also a different type of birational map : normalization .",
    "the general philosophy of jung s approach is to consider a projective surface as a ramified covering of the projective plane .",
    "the branch locus , i.e. the discriminant curve , of this covering can then be desingularized until it only has the simplest possible singularities  that is until it is normal crossing and all components are non - singular . modifying the ramified covering in this way and then passing to the normalization of the surface , the only remaining singularities of the resulting normal surface lie over the singularities of the resolved discriminant curve and are toroidal .",
    "these singularities can then be resolved combinatorially .",
    "+ in comparison to the projection , the resolution of the branch locus and the eventual combinatorial resolution of the toroidal singularities , the most expensive step here is the normalization . +    .... > lib",
    "\" resjung.lib \" ;           // load the library resjung > ring r=0,(x , y , z),dp ;         // ring of char 0 with                                 //",
    "variables x , y and z > ideal j = x2+y3 ;               // ideal of the surface   > list m = jungresolve(j,0 ) ;     // compute the resolution > m ;                           // the output is a list of rings    [ 1 ] :                           // here happens to be only one chart //",
    "characteristic : 0 // number of vars : 4 //       block    1 : ordering dp //                 : names     t(1 ) x y z //       block    2 : ordering c ....      like jung s approach , lipman s approach makes use of normalization . but here the surface is not prepared before normalizing it , instead normalization steps may occur at many different points in the algorithm .",
    "more precisely , given an excellent , noetherian , reduced 2-dimensional scheme , this algorithm proceeds by first normalizing , then blowing up in the singular locus and then continuing in this way by normalizing whenever the resulting scheme at an intermediate step is not normal and by blowing up the result of this normalization in its singular locus again .",
    "+ as normalization is a more expensive computation than a blow up , this can potentially slow down the algorithm significantly in comparison to jung s algorithm . on the other hand",
    ", this approach provides the advantage of being applicable for a wider range than the other one even opening up the possibilities for considering arithmetic surfaces . +    .... > lib",
    "\" reslipman.lib \" ;                         // load the library reslipman > ring",
    "r=0,(x(1 .. 3)),dp ;                       // ring of char 0 with the                                                // variables x(1),x(2),x(3 ) > ideal j = x(2)^2*x(3)^2-x(1)^3 ;                // ideal of the surface > list rl = lipmanresolve(j ) ;                    // compute the resolution > size(rl ) ;                                    //",
    "there are 3 charts 3         ....    if we had done the calculation by hand , we would have used one normalization and one subsequent blowing up whose center is the only singular point of the normal surface . + as before , we may pass to any of the charts and have a look at the data there :    .... > def s = rl[1 ] ;      //",
    "first chart > setring s ;       //",
    "set this ring    > slocus(j_new ) ;    // compute the singular locus _ [ 1]=1              // non singular ....",
    "the following table shows several examples computed with resbinomial , resolve , resjung and reslipman , over fields of characteristic zero .",
    "the computation times @xmath18 are measured in seconds , and the @xmath19 means the size of the output in terms of number of final affine charts .",
    "the subscripts @xmath20 , @xmath21 , @xmath22 and @xmath23 indicates resbinomial , resolve , resjung and reslipman respectively .",
    "test results with hardware : intel core i3 processor 330 m ( 2.13 ghz , 1066 mhz fsb ) , 4 gbyte memory . +",
    "the computed test examples show the stability of resbinomial with respect to the equations generating the ideal . since the algorithm is basically a combinatorial game on the exponents , similar equations provide similar size of the output increasing with growing size of exponents .",
    "note that the number of charts changes considerably also when passing to higher dimensional varieties .",
    "+ in the case of resolve we can see the influence of the geometry of the problem .",
    "it is more efficient than resbinomial if at the beginning is possible to consider a permissible center which is bigger than the center selected by resbinomial .",
    "+ with respect to resjung , the number of charts remains almost constant for the examples of hypersurfaces in ambient dimension three .",
    "+ in lipman s approach , @xmath24 means that we finish after the first normalization .",
    "this approach is the most efficient in the computed examples in ambient dimension @xmath25 , but this is mainly due to the rather simple structure of the chosen examples , which are very accessible to grauert s normalization algorithm , the bottleneck of lipman s approach .",
    "+            blanco , r. : _ desingularization of binomial varieties in arbitrary characteristic .",
    "part i. a new resolution function and their properties_. accepted for publication at _",
    "mathematische nachrichten_. + arxiv:0902.2887v2 [ math.ag ] .",
    "blanco , r. : _ desingularization of binomial varieties in arbitrary characteristic .",
    "combinatorial desingularization algorithm_. accepted for publication at _ the quarterly journal of mathematics_. quart",
    ". j. math . 00 ( 2011 ) , 124 ; in printing .",
    "blanco , r. : _ a new desingularization algorithm for binomial varieties in arbitrary characteristic_. k. fukuda et al .",
    "( eds . ) in _ icms 2010 _ , lncs vol",
    ". 6327 , pp @xmath26 , 2010 .",
    "springer - verlag berlin heidelberg , 2010 ."
  ],
  "abstract_text": [
    "<S> over the last decade , implementations of several desingularization algorithms have appeared in various contexts . </S>",
    "<S> these differ as widely in their methods and in their practical efficiency as they differ in the situations in which they may be applied . </S>",
    "<S> the purpose of this article is to give a brief overview over a selection of these approaches and the applicability of the respective implementations in singular . </S>"
  ]
}