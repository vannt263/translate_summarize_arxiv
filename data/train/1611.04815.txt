{
  "article_text": [
    "the speed , robustness and accuracy of the two- and three- parameter optimizations are tested during an 11-hour period by interleaving conventional and restless tuneups with crb and @xmath3 experiments .",
    "the data summarized in table  1 of the main text is shown in  [ fig : verification ] .",
    "the two - parameter ( three - parameter ) optimization loops over 4  ( 8) different starting conditions as specified in the main text .",
    "the starting condition is updated after each set of conventional and restless optimizations .    , a restless tuneup followed by a crb measurement of @xmath33 , and a @xmath3 experiment to determine @xmath88 .",
    "for each iteration , a new starting condition is chosen ( detailed in main text ) that is used for both the conventional and restless tuneup . ]",
    "5ifxundefined [ 1 ] ifx#1 ifnum [ 1 ] # 1firstoftwo secondoftwo ifx [ 1 ] # 1firstoftwo secondoftwo `` `` # 1''''@noop [ 0]secondoftwosanitize@url [ 0 ]  + 12$12  & 12#1212_12%12@startlink[1]@endlink[0]@bib@innerbibempty \\doibase    https://doi.org/10.5281/zenodo.160327 [ `` , ''  ] ( ) https://github.com/qcodes/qcodes [ `` , ''  ] ( ) @noop link:\\doibase 10.5281/zenodo.55595 [ `` , ''  ] ( ) @noop * * ,   ( )"
  ],
  "abstract_text": [
    "<S> we present a tuneup protocol for qubit gates with tenfold speedup over traditional methods reliant on qubit initialization by energy relaxation . </S>",
    "<S> this speedup is achieved by constructing a cost function for nelder - mead optimization from real - time correlation of non - demolition measurements interleaving gate operations without pause . applying the protocol on a transmon qubit achieves 0.999 average clifford fidelity in one minute , as independently verified using randomized benchmarking and gate set tomography . </S>",
    "<S> the adjustable sensitivity of the cost function allows detecting fractional changes in gate error with nearly constant signal - to - noise ratio . </S>",
    "<S> the restless concept demonstrated can be readily extended to the tuneup of two - qubit gates and measurement operations .    </S>",
    "<S> reliable quantum computing requires the building blocks of algorithms , quantum gates , to be executed with low error . </S>",
    "<S> strategies aiming at quantum supremacy without error correction  @xcite require @xmath0 gates , and thus gate errors @xmath1 . concurrently , a convincing demonstration of quantum fault tolerance using the circuits surface-17 and -49  @xcite under development by several groups worldwide requires gate errors one order of magnitude below the @xmath2 threshold of surface code  @xcite .    </S>",
    "<S> the quality of qubit gates depends on qubit coherence times and the accuracy and precision of the pulses realizing them . with the exception of a few systems known with metrological precision  @xcite </S>",
    "<S> , pulsing requires meticulous calibration by closed - loop tuning , i.e. , pulse adjustment based on experimental observations . </S>",
    "<S> numerical optimization algorithms have been implemented to solve a wide range of tuning problems with a cost - effective number of iterations  @xcite . however , relatively little attention has been given to quantitatively exploring the speed and robustness of the algorithms used . </S>",
    "<S> this becomes crucial with more complex and precise quantum operations , as the number of parameters and requisite precision of calibration grow .    </S>",
    "<S> though many aspects of tuning qubit gates are implementation independent , some details are specific to physical realizations . </S>",
    "<S> superconducting transmon qubits are a promising hardware for quantum computing , with gate times already exceeding coherence times by three orders of magnitude . </S>",
    "<S> conventional gate tuneup relies on qubit initialization , performed passively by waiting several times the qubit energy - relaxation time @xmath3 or actively through feedback - based reset  @xcite . </S>",
    "<S> passive initialization becomes increasingly inefficient as @xmath3 steadily increases  @xcite , while feedback - based reset is technically involved  @xcite .    in this letter </S>",
    "<S> , we present a gate tuneup method that dispenses with @xmath3 initialization and achieves tenfold speedup over the state of the art  @xcite without active reset . </S>",
    "<S> restless tuneup exploits the real - time correlation of quantum - non - demolition ( qnd ) measurements interleaving gate operations without pause , and the evaluation of a cost function for numerical optimization with adjustable sensitivity at all levels of gate fidelity . </S>",
    "<S> this cost function is obtained from a simple modification of the gate sequences of conventional randomized benchmarking ( crb ) to penalize both gate errors within the qubit subspace and leakage from it . </S>",
    "<S> we quantitatively match the signal to noise ratio of this cost function with a model that includes measured @xmath3 fluctuations . </S>",
    "<S> restless tuneup robustly achieves @xmath3-dominated gate fidelity of @xmath4 , verified using both crb with @xmath3 initialization and a first implementation of gate set tomography ( gst ) in a superconducting qubit . while this performance matches that of conventional tuneup , restless is tenfold faster and converges in one minute .     </S>",
    "<S> ( a ) a general qubit gate tuneup loop . in conventional tuneup </S>",
    "<S> ( b ) , the qubit is initialized before measuring the effect of @xmath5 . in restless tuneup ( c ) , the qubit is not initialized but @xmath6 is used to estimate the initial state ( @xmath7 ) . ( d ) benchmark of various contributions to the time per iteration in conventional and restless tuneup , without and with technical improvements ( see text for details ) . ]    in many tuneup routines  [ [ fig : concept](a ) ] , the relevant information from the measurements can be expressed as the fraction @xmath8 of non - ideal outcomes ( @xmath9 ) . in conventional gate tuneup </S>",
    "<S> , a qubit is repeatedly initialized in the ground state @xmath10 , driven by a set of gates ( @xmath5 ) whose net operation is ideally identity , and measured [ [ fig : concept](b ) ] . the conventional cost function is the raw infidelity , </S>",
    "<S> @xmath11    the central idea of restless tuning [ [ fig : concept](c ) ] is to remove the time - costly initialization step by measuring the correlation between subsequent qnd measurements interleaving gate operations without any rest   needed for passive depletion of photons leftover from the @xmath12 measurement  @xcite ] . for example </S>",
    "<S> , when the net ideal gate operation is a bit flip , we can define the error fraction @xmath13    we demonstrate restless tuneup of drag pulses  @xcite on the transmon qubit recently reported in  @xcite . </S>",
    "<S> we choose drag pulses ( duration @xmath14 ) for their proven ability to reduce gate error and leakage  @xcite with few - parameter analytic pulse shapes , consisting of gaussian ( g ) and derivative of gaussian ( d ) envelopes of the in- and quadrature - phase components of a microwave drive at the transition frequency @xmath15 between qubit levels @xmath10 and @xmath16 . </S>",
    "<S> these components are generated using four channels of an arbitrary waveform generator ( awg ) , frequency upconversion by sideband modulation of one microwave source , and two i - q mixers . </S>",
    "<S> the g and d components are combined inside a vector switch matrix ( vsm )  @xcite ( details in  @xcite ) . </S>",
    "<S> a key advantage of this scheme using four channels is the ability to independently set the g and d amplitudes ( @xmath17 and @xmath18 , respectively ) , without uploading new waveforms to the awg .    to measure the speedup obtained from the restless method </S>",
    "<S> , we must take the complete iteration into account . </S>",
    "<S> the traditional iteration of a tuneup routine involves : ( 1 ) setting parameters ( 4 channel amplitudes on a tektronix 5014 awg ) ; ( 2 ) acquiring @xmath19 measurement outcomes ; ( 3 ) sending the measurement outcomes to the computer and processing them ; and ( 4 ) miscellaneous overhead that includes determining the parameters for the next iteration , as well as saving and plotting data . in [ fig : concept](d ) , we visualize these costs for an example optimization experiment . </S>",
    "<S> we intentionally penalize the restless method by choosing a large number of gates ( @xmath20 ) . even in these conditions , </S>",
    "<S> restless sequences reduce the acquisition time from @xmath21 to @xmath22 . </S>",
    "<S> however , the improvement in total time per iteration ( from @xmath23 to @xmath24 ) is modest due to @xmath25 of overhead .    </S>",
    "<S> we take two steps to reduce overhead . </S>",
    "<S> the @xmath26 required to send all measurement outcomes to the computer and then calculate the error fraction is reduced to @xmath27 by calculating the fraction in real time using the same fpga system that digitizes and processes the raw measurement signals into bit outcomes . </S>",
    "<S> the @xmath28 required to set the four channel amplitudes in the awg is reduced to @xmath29 by setting @xmath17 and @xmath18 in the vsm . with these two technical improvements , </S>",
    "<S> the remaining overhead is dominated by the miscellaneous contributions ( @xmath30 ) . </S>",
    "<S> this reduces the total time per restless ( conventional ) iteration to @xmath31 ( @xmath32 ) .    </S>",
    "<S> a quantity of common interest in gate tuneup is the average clifford fidelity @xmath33 , which is typically measured using crb . in crb </S>",
    "<S> , @xmath5 consists of sequences of @xmath34 random cliffords , including a final recovery clifford that makes the ideal net operation identity . following  @xcite , we compose the 24 cliffords from the set of @xmath35 and @xmath36 rotations around the @xmath37 and @xmath38 axes , which requires an average of 1.875 gates per clifford . </S>",
    "<S> gate errors make @xmath39 increase with @xmath34 as  @xcite @xmath40 here , @xmath41 and @xmath42 are constants determined by state preparation and measurement error ( spam ) , and @xmath43 is the average depolarizing probability per gate , making @xmath44 . extracting @xmath33 from a crb experiment involves measuring @xmath39 for different @xmath34 and fitting [ eq : crb ] . </S>",
    "<S> however , for tuning it is sufficient to optimize @xmath39 at one choice of @xmath34 , because @xmath45 decreases monotonically with @xmath33  @xcite .    </S>",
    "<S> due to leakage , crb sequences and @xmath39 are not well suited for restless tuneup . </S>",
    "<S> typically , there is significant overlap in readout signals for the first- ( @xmath16 ) and second- ( @xmath46 ) excited state of a transmon . </S>",
    "<S> a transmon in @xmath46 can produce a string of identical measurement outcomes until it relaxes back to the qubit subspace . if the ideal net operation of @xmath5 is identity , the measurement outcomes can be indistinguishable from ideal behavior . by choosing the recovery clifford for restless randomized benchmarking ( rrb ) sequences so that the ideal net operation of @xmath5 is a bit flip , we penalize leakage and make @xmath47 a suitable cost function .     vs @xmath34 . </S>",
    "<S> ( b ) @xmath39 and @xmath47 as a function of @xmath17 for @xmath48 and @xmath49 . </S>",
    "<S> the curves are denoted by a dashed line in ( c - d ) . </S>",
    "<S> ( c - d ) @xmath8 for @xmath50 as a function of @xmath17 and @xmath18 . </S>",
    "<S> white circles indicate minimal @xmath8 . </S>",
    "<S> total acquisition time is shown at the bottom right . ]    </S>",
    "<S> we now examine the suitability of the restless scheme for optimization ( [ fig : equivalence_cost_func ] ) . </S>",
    "<S> plots of the average @xmath51 [ @xmath52 at various @xmath33 ( controlled via @xmath17 ) behave similarly to @xmath39 in crb . </S>",
    "<S> furthermore , @xmath47 is minimized at the same @xmath17 as @xmath39 , with only a shallower dip because of spam . </S>",
    "<S> the ( @xmath17 , @xmath18 ) landscapes for both cost functions [ [ fig : equivalence_cost_func](c - d ) ] are smooth around the optimum , making them suitable for numerical optimization . </S>",
    "<S> the fringes far from the optimum arise from the limited number of seeds ( always @xmath53 ) used to generate the rb sequences . </S>",
    "<S> note that , while the landscapes are visually similar , the difference in time required to map them is striking , @xmath54 for @xmath39 versus @xmath55 for @xmath47 at @xmath49 .    </S>",
    "<S> the sensitivity of @xmath47 to the tuning parameters depends on both the gate fidelity and @xmath34 . </S>",
    "<S> this can be seen in the variations between curves in [ fig : equivalence_cost_func](a ) . in order to quantify this sensitivity </S>",
    "<S> , we define a signal - to - noise ratio ( snr ) . for signal </S>",
    "<S> we take the average change in the error fraction , @xmath56 , from @xmath57 to @xmath58 ( halving the infidelity ) . for noise </S>",
    "<S> we take @xmath59 , the average standard deviation of @xmath47 between @xmath57 and @xmath60 . </S>",
    "<S> we find that the maximal snr remains @xmath61 for an optimal choice of @xmath34 that increases with @xmath57 ( [ fig : signal_noise ] and details in  @xcite ) . </S>",
    "<S> this allows tuning in logarithmic time since reducing error rates @xmath62 requires only @xmath63 optimization steps .     for a halving of the gate infidelity , plotted as a function @xmath34 at @xmath64 ( red ) , @xmath65 ( green ) and @xmath66 ( blue ) . </S>",
    "<S> ( b ) noise dependence on @xmath34 at the same fidelity levels . </S>",
    "<S> added curves are obtained from the two models described in the main text . ]    </S>",
    "<S> a simple model describes the measurement outcomes as independent and binomially distributed with error probability @xmath47 , as per [ eq : crb ] with @xmath67 . </S>",
    "<S> this model captures all the essential features of the signal . </S>",
    "<S> however , it only quantitatively matches the noise at high @xmath34 . </S>",
    "<S> experiment shows an increase in noise at low @xmath34 . in this range , @xmath47 is dominated by spam , which is primarily due to @xmath3 . </S>",
    "<S> we surmise that the increase stems from @xmath3 fluctuations  @xcite during the acquisition of statistics in these rrb experiments . to test this hypothesis </S>",
    "<S> , we develop an extensive model incorporating @xmath3 fluctuations into the calculation of both signal and noise  @xcite . </S>",
    "<S> we find good agreement with experimental results using independently measured values of @xmath68 and @xmath69 .    </S>",
    "<S> following its validation , we now employ @xmath47 in a two - step numerical optimization protocol ( [ fig : optimization ] ) . </S>",
    "<S> we choose the nelder - mead algorithm  @xcite as it is derivative - free and easy to use , requiring only the specification of a starting point and initial stepsizes . the first step using @xmath70 ensures convergence even when starting relatively far from the optimum , while the second step using @xmath71 fine tunes the result . </S>",
    "<S> we test the optimization for four realistic starting deviations from the optimal parameters @xmath72 . </S>",
    "<S> @xmath17 starts at roughly @xmath73 above or below @xmath74 , chosen as a worst - case estimate from a rabi - oscillation experiment . </S>",
    "<S> @xmath18 starts at roughly half or double @xmath75 . </S>",
    "<S> the initial stepsizes are @xmath76 , @xmath77 for the first step , and @xmath78 , @xmath79 for the second step .    </S>",
    "<S> we assess the accuracy of the above optimization and compare to traditional methods . a crb experiment [ [ fig : optimization](c ) ] following two - parameter restless optimization indicates @xmath80 . </S>",
    "<S> this value matches the average achieved by both restless and conventional tuneups for the different starting conditions . </S>",
    "<S> we also implement gst to independently verify results obtained using crb . from the process matrices we extract the average gst clifford fidelity , @xmath81 ( @xmath82 ) for restless ( conventional ) tuneup  @xcite , consistent with the value obtained from crb .     </S>",
    "<S> ( a ) and then at @xmath50 ( b ) . </S>",
    "<S> contour plots show a linear interpolation of @xmath47 . </S>",
    "<S> the starting point , intermediate result and final result are marked by orange , yellow and white dots , respectively . </S>",
    "<S> ( c ) crb of tuned pulses ( @xmath80 ) , and compared to @xmath83 and @xmath84 for reference . ]    . </S>",
    "<S> [ tab : verification ] tuning protocol performance . </S>",
    "<S> mean ( overlined ) and standard deviations ( denoted by @xmath85 ) of @xmath33 , time to convergence @xmath86 , and number of iterations @xmath87 for restless and conventional tuneups with 2 and 3 parameters . </S>",
    "<S> average @xmath3 measured throughout these runs and corresponding average @xmath88 are also listed . [ cols=\"^,^,^,^,^ \" , ] </S>"
  ]
}