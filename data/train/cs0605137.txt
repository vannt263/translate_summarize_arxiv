{
  "article_text": [
    "the capacity analysis of _ noncoherent _ fading channels has received considerable attention in recent years since it provides the ultimate limit on the rate of reliable communication on such channels .",
    "proposed approaches to modeling noncoherent fading channels can be classified into two broad categories . the first is to model the fading process as a _ block - independent _ process . in the standard version of this model@xcite ,",
    "the channel remains constant over blocks consisting of @xmath0 symbol periods , and changes independently from block to block .",
    "the second is to model the fading process as a symbol - by - symbol _ stationary _ process . in this model",
    ", the independence assumption is removed , but the block structure is not allowed . somewhat surprisingly , these two models lead to very different capacity results . for the standard block fading model ,",
    "the capacity is shown @xcite to grow logarithmically with snr , while for the symbol - by - symbol stationary model , the capacity grows only double - logarithmically in snr at high snr if the fading process is _ regular _ @xcite . for symbol - by - symbol stationary gaussian fading channels ,",
    "if the lebesgue measure of the set of harmonics where the spectral density of the fading process is zero is positive , the fading process is _ nonregular _ and the capacity grows logarithmically with snr @xcite .",
    "this result is consistent with the capacity result for block - independent fading channels in the sense that the @xmath1 behavior in the high snr regime results from the rank deficiency of the correlation matrix of the fading process .",
    "this point was elucidated in @xcite where a _ time - selective _ block fading model was considered in which the rank of the correlation within the block is allowed to be any number between one and the blocklength .    however , the mechanisms that cause the rank deficiency in the block - independent fading and nonregular symbol - by - symbol stationary models are different . for the block - independent fading model",
    ", the rank deficiency happens within each block .",
    "but for the nonregular symbol - by - symbol stationary fading channel model , the correlation matrix of the fading process over any finite block can still be full - rank ; the rank deficiency in this case is in the asymptotic sense . in general",
    ", the rank deficiency of the correlation matrix can be affected by both the short timescale correlation of the fading process as in the block - independent fading model and large timescale correlation as in the symbol - by - symbol stationary channel model . in order to capture both of these effects",
    ", we model the fading process as a _ block - stationary _ gaussian process .",
    "the block - stationary model was introduced and justified in @xcite .",
    "we summarize the main points of the justification here . in the block - independent fading model ,",
    "the channel is assumed to change in an i.i.d .",
    "manner from block to block . the independence can be justified in certain time division or frequency hopping systems where the blocks are separated sufficiently in time or frequency to undergo independent fading .",
    "the independence assumption is also convenient for information - theoretic analysis as it allows us to focus on one block in studying the capacity .",
    "if the blocks are not separated far enough in time or frequency , the fading process can be correlated across blocks and the block - stationary model is more appropriate in this scenario . without time or frequency",
    "hopping , the channel variations from one block to the next are dictated by the long term variations in the scattering environment .",
    "if we assume that the variations in average channel power are compensated for by other means such as power control , it is reasonable to model the variation from block to block as stationary and ergodic .",
    "[ rem : blockvsstat ] the block - stationary model does not imply that the fading process is stationary on a symbol - by - symbol basis as in the analysis of @xcite .",
    "but as explained in @xcite , the symbol - by - symbol stationary model is not realistic for time intervals that are larger than that corresponding to a few wavelengths . for this reason it may be more accurate to model the fading process using a block fading model with possible correlation across blocks than it is to model it as a symbol - by - symbol stationary process . from the viewpoint of analysis ,",
    "the block - stationary model generalizes all previously considered models discussed above and therefore so do the capacity results for this model .",
    "more importantly , the block - stationary model provides us with a framework to study the interplay between many aspects of fading channels which are not captured in the aforementioned models , and allows us to identify the properties that are shared by different models and the properties that depend on channel modelling .",
    "the channel capacity for the block - stationary model was only studied in @xcite under certain constraints on the correlation structure across blocks , which essentially disallow rank deficiency over the large timescale . in this paper",
    ", we conduct a more complete study of the capacity for this channel model .",
    "the following notation is used in paper . for deterministic objects ,",
    "uppercase letters denote matrices , lowercase letters denote scalars , and underlined lowercase letters denote vectors .",
    "random objects are identified by corresponding boldfaced letters .",
    "for example , @xmath2 denotes a random matrix , @xmath3 denotes the realization of @xmath2 , @xmath4 denotes a random vector , and @xmath5 denotes a random scalar . for simplicity ,",
    "sometimes we also use @xmath6 to denote the random vector @xmath7 .",
    "although uppercase letters are typically used for matrices , there are some exceptions , and these exceptions are noted explicitly in the paper .",
    "the operators @xmath8 , @xmath9 , @xmath10 , @xmath11 , and @xmath12 denote determinant , trace , conjugate , transpose and conjugate transpose , respectively .",
    "we let @xmath13 denote the @xmath14 identity matrix for any positive integer @xmath15 , and let @xmath16 denote @xmath17 $ ] for random vectors @xmath18 and @xmath19 .",
    "we consider a discrete - time channel whose time-@xmath20 complex - valued output @xmath21 is given by @xmath22 where @xmath23 is the input at time @xmath20 with peak power constraint @xmath24 ; @xmath25 models the fading process ; and @xmath26 models additive noise .",
    "the processes @xmath25 and @xmath26 are assumed to be independent and have a joint distribution that does not depend on the input @xmath27 .",
    "we assume that @xmath26 is a sequence of i.i.d .",
    "circularly symmetric complex - gaussian random variables of zero mean and unit variance , i.e. , @xmath28 .",
    "we assume that the fading process @xmath25 is a block - stationary process with @xmath29 and block length @xmath0 , i.e. , @xmath30 is a vector - valued stationary process . furthermore , we assume that @xmath31 is an ergodic process with a matrix spectral density function @xmath32 , @xmath33 .",
    "specifically , @xmath34 where @xmath35 . since @xmath36 , @xmath37 , it is not hard to check that @xmath32 is hermitian , i.e. , @xmath38 .",
    "moreover , we have @xmath39 ( @xmath33 ) ,",
    "i.e. , @xmath32 is a positive semi - definite matrix .",
    "there is an interesting relation between the matrix spectral density function and the asymptotic prediction error .",
    "specifically , for the block stationary process @xmath40 , define the following prediction error covariance matrices : @xmath41 then @xmath42 and @xmath43 are related to the matrix spectral density function @xmath32 of @xmath25 as @xcite @xmath44&=&\\exp\\left\\{\\frac{1}{2\\pi}\\int_{-\\pi}^{\\pi}\\log\\det\\left[s(e^{j\\omega})+\\frac{1}{{\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}}}i_t\\right]\\mbox{d}\\omega\\right\\},\\label{identity2}\\\\ \\det\\left[\\sigma(\\infty)\\right]&=&\\exp\\left\\{\\frac{1}{2\\pi}\\int_{-\\pi}^{\\pi}\\log\\det\\left[s(e^{j\\omega})\\right]\\mbox{d}\\omega\\right\\}.\\label{identity1}\\end{aligned}\\ ] ]    the remainder of this paper is organized as follows . in section  [ sec : asym_cap ] , we establish single - letter upper and lower bounds on channel capacity , and use these bounds to analyze the asymptotic capacity in the high snr regime . in section  [ sec : discussion ] , we discuss the robustness of the asymptotic capacity results , and the interplay between the codeword length , communication rate and decoding error probability . in section  [ sec : cap_energy ] , we adapt the formula of verd for capacity per unit cost @xcite to our channel model , and use it to derive an expression for the capacity per unit energy in the presence of a peak power constraint .",
    "we summarize our results in section  [ sec : concl ] .",
    "we denote the capacity with peak power constraint @xmath45 by @xmath46 . for any @xmath47 and @xmath48 , let @xmath49 let @xmath50 be the set of probability distributions on @xmath51 .",
    "since the channel is block - wise stationary and ergodic , a coding theorem exists and we have @xmath52      to derive a lower bound on @xmath46 for the channel model given in ( [ channelmodel ] ) , we adopt the interleaved decision - oriented training scheme proposed in @xcite with some modifications .",
    "this scheme can also be viewed as a way of interpreting the computations in ( * ? ? ?",
    "iv.e ) , ( * ? ? ?",
    "v ) .    let @xmath53 be a circularly symmetric distribution with @xmath54 $ ] .",
    "construct the codebook @xmath55 with @xmath56 sub - codebooks @xmath57 , where codebook @xmath58 ( @xmath59 ) contains @xmath60 codewords of length @xmath61 generated independently symbol by symbol using distribution @xmath53 .",
    "we assume that @xmath56 is a multiple of the block length @xmath0 , i.e. , @xmath62 for some positive integer @xmath63 .",
    "now we multiplex ( or interleave ) these @xmath56 codebooks .",
    "specifically , codebook @xmath58 ( @xmath59 ) is used at time instants @xmath64 . for codebook @xmath58",
    ", its codeword can be successfully decoded if @xmath65 for sufficiently large @xmath61 . furthermore , using the facts that @xmath66 are i.i.d . and that the channel is stationary over time instants @xmath67 ,",
    "we get @xmath68 this is to be expected since a channel with memory has a higher reliable communication rate than the memoryless channel with the same marginal transition probability .",
    "thus , reliable communication at rate @xmath69 is possible for sub - codebook @xmath70 .",
    "after @xmath66 is successfully decoded , the receiver can use these values as well as @xmath71 to estimate @xmath72 .",
    "specifically , @xmath73 is used to estimate @xmath74 , @xmath75 . since @xmath54 $ ] , it is easy to verify the following markov chain condition @xmath76 to facilitate the calculation",
    ", we assume that @xmath77 is used to estimate @xmath74 by forming the mmse estimate @xmath78 , @xmath75 .",
    "the receiver decodes the codeword in codebook @xmath79 using @xmath80 as side information .",
    "successful decoding is possible if @xmath81 similar to ( [ memoryhelp ] ) , we can use the lower bound @xmath82 to show that reliable communication at rate @xmath83 is possible for sub - codebook @xmath79 . by applying this procedure successively , we can conclude that for codebook @xmath58 , reliable communication is possible at rate @xmath84 thus , using this interleaved decision - oriented training scheme , we can have reliable communication at overall rate of @xmath85    we show in appendix [ app : monotonicity ] that @xmath86 is a monotone increasing sequence with @xmath87 now we let @xmath56 go to infinity ( i.e. , we let @xmath88 since @xmath0 is fixed ) , and we obtain @xmath89 \\\\ & = & \\frac{1}{t}\\sum\\limits_{i=1}^ti\\left({\\text{\\boldmath{$x$}}}_{i};{\\text{\\boldmath{$y$}}}_{i}\\left|\\mathbb{e}\\left({\\text{\\boldmath{$h$}}}_{i}\\left|\\left\\{{\\text{\\boldmath{$h$}}}_k+\\frac{1}{x_{\\min}}{\\text{\\boldmath{$z$}}}_k\\right\\}_{k=-\\infty}^{i-1}\\right.\\right)\\right.\\right)\\\\ & = & \\frac{1}{t}\\sum\\limits_{i=1}^ti\\left({\\text{\\boldmath{$x$}}}_{i};{\\text{\\boldmath{$h$}}}_{i}{\\text{\\boldmath{$x$}}}_i+{\\text{\\boldmath{$z$}}}_i\\left|\\mathbb{e}\\left({\\text{\\boldmath{$h$}}}_{i}\\left|\\left\\{{\\text{\\boldmath{$h$}}}_k+\\frac{1}{x_{\\min}}{\\text{\\boldmath{$z$}}}_k\\right\\}_{k=-\\infty}^{i-1}\\right.\\right)\\right.\\right).\\end{aligned}\\ ] ] this yields the single - letter lower bound @xmath90 where @xmath91 all have the same distribution @xmath53 , which is to be optimized later .",
    "although channel estimation and communication are intertwined in this interleaved decision - oriented training scheme , the effect of channel memory is isolated from channel coding through interleaving .",
    "this is because when @xmath56 is large enough , @xmath92 are roughly independent .",
    "thus the codeword in codebook @xmath58 , which is transmitted over time instants @xmath93 , essentially experiences a memoryless channel .",
    "this also suggests that as @xmath56 goes to infinity , the single - letter lower bound ( [ lowerbound ] ) provides a correct estimate of the rate supported by this interleaved decision - oriented training scheme .",
    "we can see that the channel memory manifests itself in the lower bound ( [ lowerbound ] ) only through @xmath94 .",
    "furthermore , in ( [ lowerbound ] ) , we can write @xmath95 as the sum of two independent random variables : the coherent fading component @xmath94 which is known the the receiver , and the non - coherent fading component @xmath96 which is unknown . isolating the effect of channel memory facilitates the channel code design : we only need to design channel codes for memoryless fading channels with different coherent and non - coherent components , instead of designing different codes for channels with different memory structures .    to derive a single - letter upper bound on @xmath46",
    ", we follow the approach in @xcite .",
    "the capacity @xmath46 is given by @xmath52 by the chain rule , @xmath97 we can upper - bound @xmath98 as @xmath99 since @xmath100 is a sufficient statistic for estimating @xmath101 from @xmath102 , it follows that @xmath103 note that by the block stationarity of the fading process , @xmath104 depends on @xmath105 only through ( @xmath105 mod @xmath0 ) .",
    "therefore , we obtain the single - letter upper bound @xmath106      now we proceed to show that the lower bound ( [ lowerbound ] ) and upper bound ( [ upperbound ] ) together characterize the asymptotic behavior of @xmath46 in the high snr regime .",
    "[ lemma : rank ] for every @xmath107 $ ] , let @xmath108 be an @xmath14 symmetric positive semidefinite matrix .",
    "we have @xmath109\\mbox{d}\\xi}{\\log\\epsilon}=\\sum\\limits_{i=0}^{m } ( m - i)\\mu\\left(\\mbox{rank}\\left(a(\\xi)\\right)=i\\right).\\end{aligned}\\ ] ] where @xmath110 is the lebesgue measure of the set @xmath111 .",
    "for the special case where @xmath112 for all @xmath113 $ ] and @xmath114 , we get @xmath115}{\\log\\epsilon}=m-\\mbox{rank}(a).\\end{aligned}\\ ] ]    see appendix [ app : rank ] .",
    "[ lemma : computation ] if @xmath5 is uniformly distributed over the set @xmath116 , @xmath117 , @xmath118 , @xmath119 , and @xmath120 are all independent , then @xmath121 where @xmath122 is the euler constant .",
    "[ th : asym_cap ] for the block - stationary gaussian fading channel model given in ( [ channelmodel ] ) , @xmath123}{t\\log{\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}}}=\\frac{1}{2\\pi t}\\sum\\limits_{i=0}^{t } ( t - i)\\mu\\left(\\mbox{rank}(s(e^{j\\omega}))=i\\right ) .",
    "\\label{prelog}\\end{aligned}\\ ] ]    the second equality in ( [ prelog ] ) follows from ( [ identity2 ] ) and lemma [ lemma : rank ] .",
    "below we provide an intuitive explanation of this theorem based on the lower bound ( [ lowerbound ] ) .",
    "the details of the proof are left to appendix [ app : asym_cap ] .    in the lower bound ( [ lowerbound ] ) ,",
    "let @xmath124 be uniformly distributed over the set @xmath116 , and write @xmath95 as @xmath125 where @xmath126 .",
    "suppose @xmath127 , @xmath128 .",
    "we can then write @xmath129 as @xmath130 where @xmath131 with @xmath132 . by viewing @xmath129 as the output of a coherent fading channel with the fading @xmath133 known at the receiver and noise @xmath134 , we get @xmath135 thus the lower bound ( [ lowerbound ] ) can be approximated by @xmath136 we then complete the proof by showing that @xmath137 is related to the matrix spectral density function @xmath32 by the equation @xmath138    theorem  [ th : asym_cap ] generalizes many previous results on the noncoherent capacity for gaussian channels in the high snr regime as we illustrate in the following subsection .",
    "_ constant fading within block _    for the special case where the fading remains constant within a block , i.e. , @xmath139 , for all @xmath140 , all the entries of @xmath141 for any fixed @xmath142 are identical .",
    "this implies that , for any fixed @xmath143 , all the entries of @xmath32 are identical , which we shall denote by @xmath144 .",
    "it is easy to see that @xmath144 is essentially the spectral density function of @xmath145 .",
    "the rank of @xmath32 is 1 if @xmath146 , and is 0 if @xmath147 .",
    "we therefore have @xmath148 when @xmath149 , we recover the result in @xcite that @xmath150 which illustrates the effect of large timescale correlation of the fading process on the pre - log term of the channel capacity in the high snr regime . when the fading is independent from block to block , we have @xmath151 , and thus recover the result in @xcite that @xmath152 which illustrates the effect of short timescale correlation of the fading process on the pre - log term of the capacity at high snr .    _",
    "time - selectivity within block _    in this example , we recover the main result in @xcite concerning the case where rank deficiency is caused purely by the correlation within a block .    if @xmath153 , then is satisfied , for instance , when the fading process is independent from block to block . ]",
    "@xmath154    to prove ( [ liangprelog ] ) , we first note that @xmath155 we therefore have the bound @xmath156}{\\log{\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}}}\\leq\\lim\\limits_{{\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}}\\rightarrow\\infty}\\frac{\\log\\det\\sigma({\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}})}{\\log{\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}}}\\leq\\lim\\limits_{{\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}}\\rightarrow\\infty}\\frac{\\log\\det\\left[r(0)+\\frac{1}{{\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}}}i_t\\right]}{\\log{\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}}}.\\end{aligned}\\ ] ] by lemma [ lemma : rank ] , @xmath156}{\\log{\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}}}&=&\\lim\\limits_{{\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}}\\rightarrow\\infty}\\frac{\\log\\det\\left[r(0)+\\frac{1}{{\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}}}i_t\\right]}{\\log{\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}}}\\\\ & = & -t+\\mbox{rank}(r(0)\\end{aligned}\\ ] ] which implies that @xmath157 therefore , by theorem [ th : asym_cap ] , @xmath158    it is worth noting that in this case the pre - log term of the capacity can be achieved by a scheme simpler than the aforementioned interleaved decision - oriented training scheme .",
    "suppose the rank of @xmath159 is @xmath160 , so that @xmath159 has @xmath161 positive definite principal submatrix .",
    "without loss of generality , suppose this submatrix is the covariance matrix of @xmath162 .",
    "then @xmath163 can be represented as a linear combination of @xmath164 for any @xmath140 and @xmath165 .",
    "the simpler scheme is described as follows :    the transmitter sends deterministic training symbols with maximum power at time instants @xmath166 , i.e. , @xmath167 , where @xmath168 .",
    "the receiver can form the mmse estimates @xmath169 , for @xmath170 and @xmath168 .",
    "clearly , we have @xmath171 with the side information @xmath172 at the receiver , we can communicate reliably at time instants @xmath173 with rate at least @xmath174 .",
    "let @xmath124 be uniformly distributed over the set @xmath175 . by lemma [ lemma : computation ] , @xmath176\\\\ & & + \\log\\left(1-\\mbox{var}\\left({\\text{\\boldmath{$h$}}}_{i}\\left|\\left\\{{\\text{\\boldmath{$h$}}}_{j}+\\frac{1}{\\sqrt{{\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}}}}{\\text{\\boldmath{$z$}}}_{j}\\right\\}_{j=1}^q\\right.\\right)\\right)-\\gamma-\\log\\frac{5e}{6}\\\\ & = & \\log{\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}}+o(\\log{\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}}).\\end{aligned}\\ ] ] threfore , the overall rate is lower - bounded by @xmath177 and the pre - log term is achieved .",
    "this scheme has the following obvious advantages over the interleaved decision - oriented training scheme : ( i ) channel estimation and communication are completely decoupled ; and ( ii ) channel estimation is done locally since the estimate @xmath169 , @xmath178 only depends @xmath179 .",
    "the following theorem generalizes ( * ? ? ?",
    "* corollary 4.42 ) for regular gaussian fading processes to the block - stationary case .",
    "[ th : asym_cap2 ] if @xmath180 , then @xmath181=-1-\\gamma-\\frac{1}{t}\\log\\det(\\sigma(\\infty))=-1-\\gamma-\\frac{1}{2\\pi t}\\int_{-\\pi}^{\\pi}\\log\\det\\left[s(e^{j\\omega})\\right]\\mbox{d}\\omega . \\label{fadingnum}\\end{aligned}\\ ] ]    the second equality in ( [ fadingnum ] ) follows from ( [ identity1 ] ) .",
    "see appendix [ app : asym_cap2 ] .",
    "_ gauss - markov process _",
    "suppose @xmath182 is a gauss - markov process with @xmath183 if @xmath184 , and @xmath185 otherwise . here",
    "@xmath186 are complex numbers with @xmath187 . in this case",
    ", we have @xmath188 therefore , by theorem [ th : asym_cap2 ] @xmath181=-1-\\gamma-\\log(1-|\\rho_2|^2)-\\frac{\\log(1-|\\rho_1|^2)-\\log(1-|\\rho_1|^2)}{t}.\\end{aligned}\\ ] ]",
    "for simplicity , we assume in this section that the fading process is symbol - by - symbol stationary , i.e. , @xmath149 . in this case , theorem 1 is specialized to equation ( [ symbolprelog ] ) .",
    "we can see that two fading processes with spectral density functions @xmath189 and @xmath190 can induce the same pre - log term in the high snr regime as long as @xmath191 .",
    "but in the non - asymptotic regime , the capacities of these two channels may behave very differently .",
    "so , for a fixed @xmath192 , it is natural to ask the question : which spectral density function @xmath144 gives the largest ( or smallest ) channel capacity at a given @xmath45 ?",
    "this question is difficult to answer since we do not have a closed - form expression for noncoherent channel capacity .",
    "we therefore turn to the lower bound ( [ lowerbound ] ) to formulate a closely - related problem .",
    "when @xmath149 , the lower bound ( [ lowerbound ] ) can be reduced to @xmath193 we can see that the lower bound ( [ lowerboundsym ] ) depends on @xmath144 only through @xmath194 .",
    "furthermore , if we fix the input distribution @xmath195 , then @xmath196 implies that @xmath197 we can therefore ask which @xmath144 gives the largest ( or smallest ) @xmath198 . more precisely , since @xmath199\\mbox{d}\\omega\\right\\}-\\frac{1}{x^2_{\\min}},\\end{aligned}\\ ] ] we can formulate the problem in the following form : @xmath200\\mbox{d}\\omega \\label{optimization}\\end{aligned}\\ ] ] subject to @xmath201 where @xmath202 . due to the strict concavity of @xmath203 , it is easy to show that the maximizers of the optimization problem ( [ optimization ] ) are the set of spectral density functions @xmath144 with the property : @xmath204 this solution has the following interpretation . without constraints on the spectral density function ,",
    "the worst fading process is the i.i.d .",
    "gaussian process whose spectral density function is flat . with the constraint @xmath205 ,",
    "the spectral density function @xmath144 can not be completely flat , but the worst fading process should have a spectral density function that is as flat as possible , i.e. , the correlation in the time domain should be the weakest possible .",
    "note that the solution does not depend on @xmath206 .",
    "we can use this fact to derive a universal lower bound on @xmath46 for the class of spectral density functions @xmath207 , which has further implications for the high snr asymptotic behavior of @xmath46 .",
    "let @xmath208 be a maximizer of ( [ optimization ] ) .",
    "we have @xmath209 for any spectral density function @xmath144 with @xmath205 , we have @xmath210 where @xmath5 is uniformly distributed over the set @xmath211 , @xmath212 , @xmath213 , @xmath119 , and @xmath120 are all independent",
    ". we can further optimize over @xmath53 to tighten the lower bound ( [ universallower ] ) .",
    "the minimizers of ( [ optimization ] ) do not exist .",
    "consider the following set spectral density functions @xmath214 given by @xmath215\\\\ \\frac{2\\pi\\theta^2 - 2\\pi\\theta+\\alpha\\theta+1}{\\theta } & |\\omega|\\in(\\pi-\\frac{1}{2\\theta},\\pi ] \\end{array}\\right.&\\\\\\end{aligned}\\ ] ] where @xmath216 with @xmath217 we can compute @xmath218\\mbox{d}\\omega\\\\ & = & \\lim\\limits_{\\theta\\rightarrow\\infty}\\left[-2\\alpha\\log x_{\\min}+\\left(2\\pi-\\alpha-\\frac{1}{\\theta}\\right)\\log\\left(\\frac{1}{\\theta}+\\frac{1}{x^2_{\\min}}\\right)+\\frac{1}{\\theta}\\log\\left(\\frac{2\\pi\\theta^2 - 2\\pi\\theta+\\alpha\\theta+1}{\\theta}+x^2_{\\min}\\right)\\right]\\\\ & = & -4\\pi\\log x_{\\min}.\\end{aligned}\\ ] ] note that @xmath219\\mbox{d}\\omega<-4\\pi\\log x_{\\min}$ ] .",
    "therefore , as @xmath220 goes to infinity , @xmath219\\mbox{d}\\omega$ ] approaches the lower bound that is not attainable by any spectral density function .",
    "intuitively , the fading process associated with @xmath221 becomes more and more deterministic as @xmath220 gets larger , and it can be verified that @xmath222 this result has interesting implications for the channel capacity .",
    "[ pro : nonuniform ] for any @xmath223 , @xmath224 if @xmath225 , then @xmath226    see appendix [ app : nonuniform ]    although by theorem [ th : asym_cap ] , for any fixed @xmath220 , the ratio between @xmath227 and @xmath1 converges to @xmath228 , proposition [ pro : nonuniform ] says that the convergence is not uniform with respect to @xmath220 .",
    "this is intuitively clear because when @xmath220 is large , we have @xmath229 for @xmath230 $ ] .",
    "therefore it can be expected that for a large range of snr , the channel capacity @xmath231 behaves like @xmath232 , which could be significantly larger than @xmath233 . for the extreme case where @xmath234 , by theorem [ th : asym_cap2 ] , for any fixed @xmath220 , the capacity @xmath235 grows like @xmath236 at high snr . but",
    "proposition [ pro : nonuniform ] implies that even in this extreme case , the capacity @xmath227 of some @xmath220 can grow linearly with @xmath1 for a large range of snr .",
    "this is consistent with the result in @xcite where is was shown that for the gauss - markov process with @xmath237 , the capacity @xmath46 grows like @xmath1 for a wide range of snr levels if @xmath238 is close 1 .",
    "an intuitive explanation is that if @xmath238 is close 1 , the spectrum @xmath239 is approximately zero for all @xmath143 except those around zero , and we can expect from equation ( [ symbolprelog ] ) that @xmath46 should grow like @xmath1 for a wide range of snr .",
    "but it should be noted that as opposed to a gauss - markov process , a general gaussian stationary process can not be characterized by a single parameter , and the behavior of @xmath46 can be much more complicated as shown in the following example .",
    "[ ex : twolevel ] consider the spectral density function @xmath240\\\\ \\frac{1-\\alpha_1\\epsilon_1-(\\alpha_2-\\alpha_1)\\epsilon_2}{1-\\alpha_2 } & |\\omega|\\in(\\pi\\alpha_2,\\pi ] \\end{array}\\right.&\\\\\\end{aligned}\\ ] ] where @xmath241 , and @xmath242 ( note : for two positive numbers @xmath243 and @xmath244 , @xmath245 means @xmath246 is much greater than 1 ) .",
    "we show in appendix [ app : twolevel ] that @xmath247 is approximately equal to @xmath248 for @xmath249 , and gradually decreases to @xmath250 as @xmath45 approaches @xmath251 .",
    "this example shows that @xmath247 can be highly snr dependent . for a regular gaussian fading process",
    ", it may require unreasonably high ( impractical ) values of snr in order for the noncoherent channel capacity @xmath46 to grow like @xmath236 , and the behavior of @xmath46 at moderate snr levels may depend highly on the spectral density function .",
    "overall , the above analysis suggests that great caution should be exercised when using the asymptotic results in theorem  [ th : asym_cap ] and theorem  [ th : asym_cap2 ] to approximate the channel capacity @xmath46 at a finite snr level .",
    "although the asymptotic capacity results might yield over - pessimistic approximations such as a @xmath252 growth with @xmath45 , they could also lead to over - optimistic conclusions . in the capacity analysis",
    ", it is assumed that the codeword is of infinite length .",
    "but when the length of codewords is finite , the situation can be dramatically different . by fano s inequality ,",
    "the communication rate @xmath253 is upper - bounded by @xmath254 where @xmath61 is the codeword length and @xmath255 is the decoding error probability .",
    "suppose we fix @xmath61 and @xmath255 , and let @xmath45 go to infinity .",
    "for a symbol - by - symbol stationary gaussian fading process , even if @xmath256 , the correlation matrix of the fading process over any finite block length can still be full - rank .",
    "note that @xmath257 is upper - bounded by the capacity of a block - independent gaussian fading channel with the correlation matrix of each block given by @xmath258 $ ] .",
    "since @xmath258 $ ] is full rank , it follows from theorem [ th : asym_cap2 ] that @xmath257 , and hence @xmath253 , grows at most like @xmath236 as @xmath45 goes to infinity .",
    "therefore , there is no nontrivial tradeoff between diversity and multiplexing in the sense of @xcite .",
    "if we want @xmath253 to grow linearly with @xmath1 while having the decoding error probability @xmath255 bounded away from 1 , the codeword length @xmath61 must scale with @xmath45 .",
    "it is of interest to determine how fast the codeword @xmath61 should scale with @xmath45 in order to guarantee that the rate @xmath253 can grow as @xmath1 with the decoding error probability not approaching 1 . more precisely ,",
    "letting the rate @xmath259 , codeword length @xmath260 and decoding error probability @xmath261 all depend on @xmath45 , we wish to determine conditions on @xmath260 to guarantee the existence of a sequence of codebooks ( indexed by @xmath45 ) with rate @xmath259 and codeword length @xmath260 such that @xmath262 and @xmath263 where @xmath264 and @xmath265 .",
    "now we proceed to derive a necessary condition on the growth rate of @xmath260 .",
    "it follows by chain rule that @xmath266 by ( [ lateruse ] ) , we can upper - bound @xmath267 as @xmath268 since @xmath269 , and @xmath270\\right\\}\\\\ & \\leq&\\log\\left[\\frac{1+{\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}}}{1+{\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}}\\cdot\\mbox{var}\\left({\\text{\\boldmath{$h$}}}_k\\left|\\left\\{{\\text{\\boldmath{$h$}}}_v+\\frac{1}{\\sqrt{{\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}}}}{\\text{\\boldmath{$z$}}}_v\\right\\}_{v=1}^{k-1}\\right.\\right)}\\right]\\\\&=&\\log\\left(\\frac{1+{\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}}}{{\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}}}\\right)-\\log\\mbox{var}\\left({\\text{\\boldmath{$h$}}}_k+\\frac{1}{\\sqrt{{\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}}}}{\\text{\\boldmath{$z$}}}_k\\left|\\left\\{{\\text{\\boldmath{$h$}}}_v+\\frac{1}{\\sqrt{{\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}}}}{\\text{\\boldmath{$z$}}}_v\\right\\}_{v=1}^{k-1}\\right.\\right)\\\\ & \\leq&\\log\\left(\\frac{1+{\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}}}{{\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}}}\\right)-\\log\\mbox{var}\\left({\\text{\\boldmath{$h$}}}_0+\\frac{1}{\\sqrt{{\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}}}}{\\text{\\boldmath{$z$}}}_0\\left|\\left\\{{\\text{\\boldmath{$h$}}}_v+\\frac{1}{\\sqrt{{\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}}}}{\\text{\\boldmath{$z$}}}_v\\right\\}_{v =- n({\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}})}^{-1}\\right.\\right),\\end{aligned}\\ ] ] it follows by fano s inequality and the condition @xmath271 that @xmath272 therefore , in order for @xmath273 we must have @xmath274 since @xmath275 is a monotone increasing function of @xmath61 , it is easy to see ( [ scaling ] ) implicitly provides us with a lower bound on the scaling rate of @xmath260 .    in order to derive an explicit lower bound on the scaling rate of @xmath260 , we need to introduce a concept called _ transfinite diameter _ @xcite .",
    "let @xmath276 be a compact set in the plane .",
    "set @xmath277 and @xmath278^{\\frac{2}{n(n-1)}}.\\end{aligned}\\ ] ] the transfinite diameter of @xmath276 is defined by @xmath279    we need the following facts regarding the transfinite diameter .    1 .   for two compact sets @xmath280 and @xmath281 with @xmath282 , we have @xmath283 .",
    "the diameter of the unit circle is 1 .",
    "more generally , the diameter of an arc of central angle @xmath220 on the unit circle is @xmath284 ; 3 .",
    "the transfinite diameter of any closed proper subset of the unit circle is less than 1 .",
    "a full discussion of the transfinite diameter can be found in @xcite .",
    "now return to the original problem .",
    "since @xmath285 we have @xmath286 let @xmath287 .",
    "it was shown in @xcite that if the set @xmath276 consists consist of a finite number of arcs of the unit circle , then @xmath288 under the conditions    1 .",
    "the set @xmath276 consists consist of a finite number of arcs of the unit circle , 2 .",
    "the set @xmath276 is a closed proper subset of the unit circle ,    it can be shown by using facts ( i ) , ( ii ) and ( iii ) that @xmath289 therefore , under conditions ( a ) and ( b ) , we have @xmath290 it is clear that in order to guarantee that ( [ scalelower ] ) is greater than or equal to @xmath291 , we must have @xmath292 which is a necessary condition on the scaling rate of @xmath260 .",
    "in contrast , we show in appendix [ app : awgn ] and appendix [ app : rayleigh ] that for the awgn channel and memoryless coherent rayleigh fading channel , it is possible to have the rate @xmath259 grow linearly with @xmath1 with fixed codeword length @xmath61 and bounded decoding error probability at high snr .",
    "for these two cases , to facilitate the calculation , we adopt the average power constraint .",
    "but our main conclusion holds also under the peak power constraint .",
    "in the preceding sections , we focused on the channel capacity in the high snr regime .",
    "now we proceed to characterize the behavior of channel capacity in the low average power regime for the block - stationary gaussian fading channel model . to this end , we shall study the capacity per unit energy ( which is denoted by @xmath293 ) due to its intrinsic connection with the channel capacity in this regime .",
    "the following theorem provides a general expression for the capacity per unit energy .",
    "@xmath294    furthermore , the capacity per unit energy is related to the capacity by @xmath295 where @xmath296 is the channel capacity with average power constraint @xmath297 and peak power constraint @xmath45 .",
    "the following theorem is an extension of ( * ? ? ?",
    "* proposition 3.1 ) for the symbol - symbol stationary channel model to the block - stationary model .",
    "for the block - stationary gaussian fading channel model given in ( [ channelmodel ] ) , @xmath298 where @xmath299\\mbox{d}\\omega,\\end{aligned}\\ ] ] and @xmath300 is an @xmath301 principal minor of @xmath32 with the indices of columns and rows specified by @xmath302 .    the proof is omitted since it is almost identical to that for the symbol - by - symbol stationary fading channel @xcite .",
    "the only difference is that although the capacity per unit energy of the block - stationary fading channel can be asymptotically achieved by temporal on - off signaling , we have to determine how to allocate on symbols in a block .",
    "it can be shown that the optimal allocation scheme is given by @xmath303 , which is the minimizer of @xmath304 . here",
    "@xmath303 might not be unique .",
    "@xmath293 is a monotonically increasing function of @xmath45 .",
    "it is easy to see that @xmath293 goes to 1 as @xmath305 , and goes to 0 as @xmath306 .",
    "the following result provides a more precise characterization of the convergence behavior .",
    "[ cor : snrasym ] at high @xmath45 , @xmath307 at low @xmath45 , if @xmath308\\mbox{d}\\omega<\\infty,\\end{aligned}\\ ] ] then @xmath309\\mbox{d}\\omega+o({\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}}).\\label{lowsnrasym}\\end{aligned}\\ ] ]    by lemma [ lemma : rank ] , at high @xmath45 @xmath310\\mbox{d}\\omega=-\\sum\\limits_{i=0}^{|\\mathcal{m}|}(|\\mathcal{m}|-i)\\mu(\\mbox{rank}(s_{\\mathcal{m}}(e^{j\\omega}))=i)\\log{\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}}+o(\\log{\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}}).\\end{aligned}\\ ] ] therefore , @xmath311\\mbox{d}\\omega+2\\pi\\log{\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}}\\right\\}\\\\ & = & 1+\\max\\limits_{\\mathcal{m}\\subseteq\\{1,\\cdots , t\\}}\\frac{\\sum\\limits_{i=0}^{|\\mathcal{m}|}(|\\mathcal{m}|-i)\\mu\\left(\\mbox{rank}(s_{\\mathcal{m}}(e^{j\\omega}))=i\\right)\\log{\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}}}{2\\pi|\\mathcal{m}|{\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}}}-\\frac{\\log{\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}}}{{\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}}}+o(\\frac{\\log{\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}}}{{\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}}})\\\\ & = & 1-\\min\\limits_{\\mathcal{m}\\subseteq\\{1,\\cdots , t\\}}\\frac{\\sum\\limits_{i=0}^{|\\mathcal{m}|}i\\mu\\left(\\mbox{rank}(s_{\\mathcal{m}}(e^{j\\omega}))=i\\right)\\log{\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}}}{2\\pi|\\mathcal{m}|{\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}}}+o(\\frac{\\log{\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}}}{{\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}}}).\\end{aligned}\\ ] ] at low @xmath45 , using the second - order approximation @xcite , we obtain @xmath312=\\mbox{tr}[s_{\\mathcal{m}}(e^{j\\omega})]{\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}}-\\frac{1}{2}\\mbox{tr}[s^2_{\\mathcal{m}}(e^{j\\omega})]{\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}}^2+o({\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}}^2).\\end{aligned}\\ ] ] therefore , @xmath313\\mbox{d}\\omega-\\frac{1}{2}\\int_{-\\pi}^{\\pi}\\mbox{tr}[s^2_{\\mathcal{m}}(e^{j\\omega})]{\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}}\\mbox{d}\\omega\\right\\}+o({\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}})\\\\ & = & \\frac{{\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}}}{4\\pi}\\max\\limits_{\\mathcal{m}\\subseteq\\{1,\\cdots , t\\}}\\frac{1}{|\\mathcal{m}|}\\int_{-\\pi}^{\\pi}\\mbox{tr}[s^2_{\\mathcal{m}}(e^{j\\omega})]\\mbox{d}\\omega+o({\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}})\\end{aligned}\\ ] ] where the last equality follows from the fact that @xmath314\\mbox{d}\\omega=1.\\end{aligned}\\ ] ]    using the inequality @xmath312\\geq\\mbox{tr}[s_{\\mathcal{m}}(e^{j\\omega})]{\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}}-\\frac{1}{2}\\mbox{tr}[s^2_{\\mathcal{m}}(e^{j\\omega})]{\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}}^2,\\end{aligned}\\ ] ] we can upper bound @xmath293 by @xmath315\\mbox{d}\\omega.\\end{aligned}\\ ] ] it can be seen from corollary [ cor : snrasym ] that this upper bound is a good approximation of @xmath293 in the low @xmath45 regime .",
    "now we proceed to compute @xmath293 in the following examples .",
    "[ ex : blockindep ] when the channel changes independently from block to block , @xmath293 is equal to @xmath316\\end{aligned}\\ ] ] where @xmath317 is an @xmath301 principal minor of @xmath159 with the indices of columns and rows specified by @xmath302 . if we further let the fading remain constant within a block , then all the entries of @xmath159 are one .",
    "it is not difficult to show that @xmath318=\\frac{\\log(1+|\\mathcal{m}|{\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}})}{|\\mathcal{m}|{\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}}}\\end{aligned}\\ ] ] which is minimized when @xmath319 , i.e. , @xmath320 .",
    "so we have @xmath321 as shown in @xcite .",
    "consider the case in which the fading process satisfies the following conditions    1 .",
    "all the off - diagonal entries of @xmath159 are equal to @xmath322 , where @xmath323 is a constant ; 2 .",
    "all the entries of @xmath141 are equal to @xmath324 for any non - zero integer @xmath142 , where @xmath325 is a constant that depends only on @xmath142 .",
    "we also know that the diagonal entries of @xmath159 are all one .",
    "so for any fixed @xmath143 ( @xmath33 ) , all the diagonal entries of @xmath326 are identical , and all the off - diagonal entries of @xmath326 are identical .",
    "it then follows from szasz s inequality @xcite that for any @xmath327 $ ] , @xmath328 is minimized when @xmath320 . in this case",
    "we therefor have @xmath329    if the fading remains constant within a block , then for any fixed @xmath143 , all the entries of @xmath32 are identical , which we shall denote by @xmath144 . it can be shown that @xmath330=1+t{\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}}s(e^{j\\omega}),\\end{aligned}\\ ] ] which yields @xmath331\\mbox{d}\\omega.\\label{tsnr}\\end{aligned}\\ ] ] we can see from ( [ tsnr ] ) that @xmath293 is a monotonically increasing function of @xmath0 and @xmath45 .",
    "intuitively , as @xmath0 gets larger and larger , the receiver can estimate the channel more and more accurately , and thus the capacity per unit energy of the non - coherent channel should converge to that of the coherent channel , which is equal to one ; as @xmath45 goes to infinity , @xmath293 should also converge to one since flash signaling can be used if there is no peak power constraint ( i.e. , @xmath332 ) @xcite .",
    "moreover , ( [ tsnr ] ) provides a precise characterization of the interplay between the coherence time and signal peakiness , stating that the capacity per unit energy is unaffected as long as the product of @xmath0 and @xmath45 is fixed .",
    "see @xcite for a related discussion .    for the special case where the fading is a block gauss - markov process , i.e.",
    ", all the entries of @xmath141 are equal to @xmath333 if @xmath334 and equal to @xmath335 if @xmath336 for some @xmath337 with @xmath338 , we have @xmath339 where @xmath340 and @xmath341 with @xmath342 .",
    "the function @xmath343 is analytic and nonzero in a neighborhood of the unit disk .",
    "thus , by jensen s formula @xmath344 from which we can recover ( * ? ? ?",
    "* corollary 4.1 ) by setting @xmath149 .    finding",
    "the optimal @xmath303 is a difficult problem in general .",
    "moreover , as shown in the following example , the optimal @xmath303 may depend on the snr level .",
    "[ example ] let the fading process be independent from block to block with @xmath345 where @xmath346 $ ] .",
    "it is shown in appendix [ app : snrdependent ] that    1 .   when @xmath347 , the optimal @xmath303 is @xmath348 , and @xmath349 2 .   when @xmath350 , @xmath351 and @xmath352 3 .",
    "when @xmath353 , the optimal @xmath303 is @xmath354 , and @xmath355    it can be verified that this result is consistent with the asymptotic analysis in corollary [ cor : snrasym ] . since @xmath356 for any @xmath357 , it is easy to see that @xmath358 is minimized at @xmath359 if @xmath360 , and minimized at @xmath361 if @xmath353 . therefore , by ( [ highsnrasym ] ) , the optimal @xmath303 at high snr should be @xmath348 if @xmath360 , and should be @xmath354 if @xmath353 . since @xmath362 it follows that @xmath363 $ ] is maximized at @xmath359 if @xmath364 , and maximized at @xmath361 if @xmath365 .",
    "therefore , by ( [ lowsnrasym ] ) , the optimal @xmath303 at low snr should be @xmath348 if @xmath364 , and should be @xmath354 if @xmath365 .    intuitively , if @xmath238 is close to 1 , we can approximate @xmath159 by the all - one matrix , and then it follows from example [ ex : blockindep ] that the optimal @xmath303 is @xmath354 .",
    "the approximation breaks down at high snr since corollary [ cor : snrasym ] implies that the optimal @xmath303 should be @xmath348 as @xmath305 .",
    "we conducted a detailed study of the block - stationary gaussian fading channel model introduced in @xcite .",
    "we derived single - letter upper and lower bounds on channel capacity , and used these bounds to characterize the asymptotic behavior of channel capacity .",
    "specifically , we computed the asymptotic ratio between the non - coherent channel capacity and the logarithm of the snr in the high snr regime .",
    "this result generalizes many previous results on noncoherent capacity .",
    "we showed that the behavior of channel capacity depends critically on channel modelling .",
    "we also derived an expression for the capacity per unit energy for the block - stationary fading model .",
    "it is clearly of interest to generalize these results to the multi - antenna scenario , but such an extension seems technically nontrivial .    another direction that we explored was the interplay between the codeword length , snr level , and decoding error probability .",
    "we showed that for noncoherent symbol - by - symbol stationary fading channels , the codeword length must scale with snr in order to guarantee that the communication rate can grow linearly with @xmath1 with bounded decoding error probability , and we found a necessary condition for the growth rate of the codeword length .",
    "we believe that a more complete characterization of the interplay between the codeword length , snr level , and decoding error probability is of both theoretical significance and practical value .",
    "by the block stationarity of the fading process , we have @xmath366 since for any @xmath367 , @xmath368 form a markov chain , it follows by data processing inequality that @xmath369 equations ( [ mono1 ] ) and ( [ mono2 ] ) together imply that @xmath86 is a monotone increasing sequence .    for every @xmath370 , we can construct a random variable @xmath371 independent of everything else such that @xmath372 in distribution .",
    "clearly , @xmath373 as @xmath374 .",
    "moreover , it is not difficult to show that @xmath375 combining ( [ mono1 ] ) and ( [ addnoiseequiv ] ) , we get @xmath376    since @xmath377 by ( * ? ? ?",
    "* lemma 6.11 ) , we get @xmath378 since conditioned on @xmath379 , @xmath380 are jointly gaussian with uniformly bounded differential entropy for any realization of @xmath379 ( note : @xmath381 ) , it follows by dominated convergence theorem that @xmath382 therefore , @xmath383",
    "by eigenvalue decomposition , we write @xmath384 and @xmath385 where @xmath386 is a unitary matrix , and @xmath387 is a diagonal matrix with nonnegative diagonal entries . since @xmath388 , define @xmath389 we have @xmath109\\mbox{d}\\xi}{\\log\\epsilon}&=&\\lim\\limits_{\\epsilon\\rightarrow 0}\\frac{\\int_{\\xi_1}^{\\xi_2}\\log\\det \\left[d(\\xi)+\\epsilon i_m\\right]\\mbox{d } \\xi}{\\log\\epsilon}\\\\ & = & \\lim\\limits_{\\epsilon\\rightarrow 0}\\frac{-\\sum\\limits_{i=0}^m\\int_{\\omega_i}\\log\\det \\left[d(\\xi)+\\epsilon i_m\\right]\\mbox{d } \\xi}{\\log\\epsilon}.\\end{aligned}\\ ] ] for @xmath390 , ( possibly after permutating diagonal entries ) we can write @xmath391 , where @xmath392 , @xmath393",
    ". therefore , @xmath109\\mbox{d}\\xi}{\\log\\epsilon } = \\lim\\limits_{\\epsilon\\rightarrow 0}\\frac{-\\sum\\limits_{i=0}^m\\int_{\\omega_i}\\sum\\limits_{j=1}^i\\log[d_j(\\xi)+\\epsilon]\\mbox{d } \\xi}{\\log\\epsilon}+\\sum\\limits_{i=0}^m(m - i)\\mu(\\mbox{rank}(a(\\xi))=i)\\end{aligned}\\ ] ] where @xmath110 is the lebesgue measure of @xmath394 . by the argument in (",
    "* section viii ) , it can be shown that @xmath395\\mbox{d}\\xi}{\\log\\epsilon}=0.\\end{aligned}\\ ] ] so we have @xmath396\\mbox{d}\\xi}{\\log\\epsilon } = \\sum\\limits_{i=0}^m(m - i)\\mu(\\mbox{rank}(a(\\xi))=i).\\end{aligned}\\ ] ]",
    "define @xmath397 in the lower bound ( [ lowerbound ] ) , let @xmath124 be uniformly distributed over the set @xmath398 . by lemma [ lemma : computation ] , @xmath399+\\log\\left(1-\\sigma_i\\left(\\frac{{\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}}}{4}\\right)+\\frac{4}{{\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}}}\\right)-\\gamma-\\log\\frac{5e}{6}\\\\ & = & -\\log\\left[\\sigma_i\\left(\\frac{{\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}}}{4}\\right)-\\frac{12}{5{\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}}}\\right]+o(\\log{\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}}).\\end{aligned}\\ ] ] since @xmath400 , it follows that @xmath401}{\\log{\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}}}.\\end{aligned}\\ ] ] let @xmath402 , where @xmath403 is a lower triangular matrix with unit diagonal entries , and @xmath404 .",
    "we have @xmath405&=&\\det\\left[l\\left(\\frac{{\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}}}{4}\\right)\\right]\\det\\left[\\lambda\\left(\\frac{{\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}}}{4}\\right)\\right]\\det\\left[l^\\dagger\\left(\\frac{{\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}}}{4}\\right)\\right]\\nonumber\\\\ & = & \\det\\left[\\lambda\\left(\\frac{{\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}}}{4}\\right)\\right]\\nonumber\\\\ & = & \\prod\\limits_{i=1}^t \\sigma_i\\left(\\frac{{\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}}}{4}\\right).\\label{ldl}\\end{aligned}\\ ] ] therefore , @xmath406}{\\log{\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}}}\\nonumber\\\\ & = & \\liminf\\limits_{{\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}}\\rightarrow\\infty}\\frac{-\\log\\det\\left[\\sigma\\left(\\frac{{\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}}}{4}\\right)\\right]}{\\log{\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}}}\\nonumber\\\\ & = & \\liminf\\limits_{{\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}}\\rightarrow\\infty}\\frac{-\\log\\det\\left[\\sigma\\left({\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}}\\right)\\right]}{\\log{\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}}}.\\label{preloginf}\\end{aligned}\\ ] ]    we use ( [ upperbound ] ) derive an upper bound on @xmath407 .",
    "first it is easy to see that @xmath408 it is shown in @xcite that @xmath409 now we proceed to upper - bound the first term in ( [ twoparts ] ) .",
    "@xmath410\\right\\}\\\\ & \\leq&\\log\\left[\\frac{1+{\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}}}{1+{\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}}\\cdot\\mbox{var}\\left({\\text{\\boldmath{$h$}}}_k\\left|\\left\\{{\\text{\\boldmath{$h$}}}_t+\\frac{1}{\\sqrt{{\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}}}}{\\text{\\boldmath{$z$}}}_t\\right\\}_{t=-\\infty}^{k-1}\\right.\\right)}\\right]\\\\&=&\\log\\left[\\frac{1+{\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}}}{{\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}}\\cdot\\sigma_k({\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}})}\\right].\\end{aligned}\\ ] ] therefore , @xmath411}{\\log{\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}}}\\nonumber\\\\ & = & \\limsup\\limits_{{\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}}\\rightarrow\\infty}\\frac{-\\log\\det\\left[\\sigma\\left({\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}}\\right)\\right]}{\\log{\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}}}.\\label{prelogsup}\\end{aligned}\\ ] ] the desired result follows by combining ( [ preloginf ] ) and ( [ prelogsup ] ) .",
    "define @xmath412 similar to ( [ ldl ] ) , we have @xmath413=\\prod\\limits_{i=1}^t\\sigma_i(\\infty).\\end{aligned}\\ ] ] therefore , @xmath414>0 $ ] implies @xmath415 for all @xmath142 .    note that if @xmath416 for some @xmath417 , then @xmath418 form a markov chain , and @xmath419 in the lower bound ( [ lowerbound ] ) , let @xmath420 be uniformly distributed over the interval @xmath421 $ ] . as @xmath422 grows sublinearly in @xmath1 to infinity ,",
    "we get @xmath423\\\\ & \\geq&\\liminf\\limits_{{\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}}\\rightarrow\\infty}\\left[i\\left({\\text{\\boldmath{$x$}}}_{i};{\\text{\\boldmath{$h$}}}_i{\\text{\\boldmath{$x$}}}_i+{\\text{\\boldmath{$z$}}}_i\\left|\\mathbb{e}\\left({\\text{\\boldmath{$h$}}}_{i}\\left|\\left\\{{\\text{\\boldmath{$h$}}}_k+\\delta{\\text{\\boldmath{$z$}}}_k\\right\\}_{k=-\\infty}^{i-1}\\right.\\right)\\right.\\right)-\\log\\log{\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}}\\right]\\\\ & = & -1-\\gamma-\\log\\mbox{var}\\left({\\text{\\boldmath{$h$}}}_i\\left|\\left\\{{\\text{\\boldmath{$h$}}}_j+\\delta{\\text{\\boldmath{$z$}}}_j\\right\\}_{j=-\\infty}^{i-1}\\right.\\right)\\end{aligned}\\ ] ] where the last equality follows from ( * ? ? ?",
    "* proposition 4.23 ) .",
    "therefore , @xmath424\\nonumber\\\\ & \\geq&\\liminf\\limits_{{\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}}\\rightarrow\\infty}\\left[\\frac{1}{t}\\sum\\limits_{i=1}^ti\\left({\\text{\\boldmath{$x$}}}_{i};{\\text{\\boldmath{$h$}}}_i{\\text{\\boldmath{$x$}}}_i+{\\text{\\boldmath{$z$}}}_i\\left|\\mathbb{e}\\left({\\text{\\boldmath{$h$}}}_{i}\\left|\\left\\{{\\text{\\boldmath{$h$}}}_k+\\frac{1}{x_{\\min}}{\\text{\\boldmath{$z$}}}_k\\right\\}_{k=-\\infty}^{i-1}\\right.\\right)\\right.\\right)-\\log\\log{\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}}\\right]\\nonumber\\\\ & = & -1-\\gamma-\\frac{1}{t}\\sum\\limits_{i=1}^t\\log\\mbox{var}\\left({\\text{\\boldmath{$h$}}}_i\\left|\\left\\{{\\text{\\boldmath{$h$}}}_j+\\delta{\\text{\\boldmath{$z$}}}_j\\right\\}_{j=-\\infty}^{i-1}\\right.\\right).\\label{fadingnumber}\\end{aligned}\\ ] ] since ( [ fadingnumber ] ) holds for arbitrary positive @xmath425 , it follows that @xmath426&\\geq&-1-\\gamma-\\frac{1}{t}\\lim\\limits_{\\delta\\rightarrow 0}\\sum\\limits_{i=1}^t\\log\\mbox{var}\\left({\\text{\\boldmath{$h$}}}_i\\left|\\left\\{{\\text{\\boldmath{$h$}}}_j+\\delta{\\text{\\boldmath{$z$}}}_j\\right\\}_{j=-\\infty}^{i-1}\\right.\\right)\\nonumber\\\\ & = & -1-\\gamma-\\frac{1}{t}\\log\\det\\left[\\sigma(\\infty)\\right].\\label{fadingnumberinf}\\end{aligned}\\ ] ]    from the upper bound ( [ upperbound ] ) , we have @xmath427\\nonumber\\\\ & \\leq & \\limsup\\limits_{{\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}}\\rightarrow\\infty}\\left[\\frac{1}{t}\\sum\\limits_{k=1}^t\\sup\\limits_{p_{{\\text{\\boldmath{$x$}}}_k}\\in\\mathcal{p}_1({\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}})}i\\left({\\text{\\boldmath{$x$}}}_k,\\mathbb{e}\\left({\\text{\\boldmath{$h$}}}_k\\left|\\left\\{{\\text{\\boldmath{$h$}}}_t+\\frac{1}{\\sqrt{{\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}}}}{\\text{\\boldmath{$z$}}}_{t}\\right\\}_{t=-\\infty}^{k-1}\\right.\\right);{\\text{\\boldmath{$y$}}}_k\\right)-\\log\\log{\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}}\\right]\\nonumber\\\\ & \\leq&\\limsup\\limits_{{\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}}\\rightarrow\\infty}\\left[\\frac{1}{t}\\sum\\limits_{k=1}^t\\sup\\limits_{p_{{\\text{\\boldmath{$x$}}}_k}\\in\\mathcal{p}_1({\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}})}i\\left({\\text{\\boldmath{$x$}}}_k,\\mathbb{e}\\left({\\text{\\boldmath{$h$}}}_k\\left|\\{{\\text{\\boldmath{$h$}}}_j\\}_{j=-\\infty}^{k-1}\\right);{\\text{\\boldmath{$y$}}}_k\\right.\\right)-\\log\\log{\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}}\\right]\\label{markov}\\\\ & \\leq&\\limsup\\limits_{{\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}}\\rightarrow\\infty}\\left[\\sup\\limits_{p_{{\\text{\\boldmath{$x$}}}_k}\\in\\mathcal{p}_1({\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}})}i({\\text{\\boldmath{$x$}}}_1;{\\text{\\boldmath{$y$}}}_1)+\\frac{1}{t}\\sum\\limits_{k=1}^t\\sup\\limits_{p_{{\\text{\\boldmath{$x$}}}_k}\\in\\mathcal{p}_1({\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}})}i\\left(\\left.\\mathbb{e}\\left({\\text{\\boldmath{$h$}}}_k\\left|\\{{\\text{\\boldmath{$h$}}}_j\\}_{j=-\\infty}^{k-1}\\right.\\right);{\\text{\\boldmath{$y$}}}_k\\right|{\\text{\\boldmath{$x$}}}_k\\right)-\\log\\log{\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}}\\right]\\nonumber\\end{aligned}\\ ] ] where ( [ markov ] ) follows from the fact that @xmath428 form a markov chain",
    ".    it was shown in ( * ? ? ?",
    "* corollary 4.19 ) that @xmath429=-1-\\gamma.\\end{aligned}\\ ] ] furthermore , @xmath430 where ( [ markov2 ] ) follows from the fact that @xmath431 form a markov chain .",
    "therefore , we get @xmath432&\\leq&-1-\\gamma-\\frac{1}{t}\\sum\\limits_{k=1}^t\\log\\sigma_k(0)\\nonumber\\\\ & = & -1-\\gamma-\\frac{1}{t}\\log\\det\\left[\\sigma(\\infty)\\right].\\label{fadingnumbersup}\\end{aligned}\\ ] ] the desired result follows by combining ( [ fadingnumberinf ] ) and ( [ fadingnumbersup ] ) .",
    "at high snr , we have @xmath433\\mbox{d}\\omega\\right|_{\\theta={\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}}^{r } } & = & \\alpha\\log\\left(\\frac{4}{{\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}}}\\right)+\\left(2\\pi-\\alpha-{\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}}^{-r}\\right)\\log\\left({\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}}^{-r}+\\frac{4}{{\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}}}\\right)\\\\ & & + { \\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}}^{-r}\\log\\left(\\frac{2\\pi{\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}}^{2r}-2\\pi{\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}}^{r}+\\alpha{\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}}^{r}+1}{{\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}}^{r}}+\\frac{4}{{\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}}}\\right)\\\\ & = & -2\\pi\\kappa\\log{\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}}+c(r)+o(1)\\end{aligned}\\ ] ] and thus @xmath434 where @xmath435 , and @xmath436    in the lower bound ( [ lowerboundsym ] ) , let @xmath437 be uniformly distributed over the set @xmath438 . by lemma [ lemma : computation ] and equation ( [ predict ] )",
    ", we get @xmath439+\\log\\left(1-\\frac{e^{\\frac{c(r)}{2\\pi}}}{{\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}}}+\\frac{4}{{\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}}}-o\\left(\\frac{1}{{\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}}\\kappa}\\right)\\right)-\\gamma-\\log\\frac{5e}{6}\\\\ & = & \\kappa\\log{\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}}+o(\\log{\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}}).\\end{aligned}\\ ] ] therefore , @xmath440    when @xmath225 , we have @xmath441 since the noncoherent channel capacity with peak power constraint @xmath442 is upper bounded by the coherent channel capacity with average power constraint @xmath443 , it follows that @xmath444 where @xmath445 .",
    "therefore , @xmath446 the proof is complete .",
    "in the lower bound ( [ lowerboundsym ] ) , let @xmath437 be uniformly distributed over the set @xmath438 . by lemma [ lemma : computation ] , we get @xmath447 where @xmath448^{1-\\alpha_2}-\\frac{4}{{\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}}}.\\end{aligned}\\ ] ]    by specializing the upper - bound ( [ upperbound ] ) to the case where @xmath149 , we obtain @xmath449 where @xmath450\\\\ & = & -\\log\\left\\{\\left(\\epsilon_1+\\frac{1}{{\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}}}\\right)^{\\alpha_1}\\left(\\epsilon_2+\\frac{1}{{\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}}}\\right)^{\\alpha_2-\\alpha_1}\\left[\\frac{1-\\alpha_1\\epsilon_1-(\\alpha_2-\\alpha_1)\\epsilon_2}{1-\\alpha_2}+\\frac{1}{{\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}}}\\right]^{1-\\alpha_2}-\\frac{1}{{\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}}}\\right\\}.\\end{aligned}\\ ] ] note that @xmath451 is the capacity of the memoryless noncoherent rayleigh fading channel ( see @xcite for a nonasymptotic upper bound ) , and we have @xmath452 for large @xmath45 .",
    "we can compute that @xmath471 it can be verified that @xmath472 so the optimal @xmath303 is either @xmath348 or @xmath354 . setting @xmath473 yields @xmath474 which , after some algebraic manipulation , is equivalent to @xmath475 the above equation has two solutions @xmath476 @xmath477 can be discarded since it is always negative .",
    "@xmath478 is positive for @xmath479 . when @xmath479 , it can be verified that @xmath480 if @xmath481 , and @xmath482 if @xmath483 .",
    "when @xmath484 $ ] , @xmath478 is non - positive . in this case , we have @xmath480 for all @xmath48 .              t. koch and a. lapidoth ,  the fading number and degrees of freedom in non - coherent mimo fading channels : a peace pipe , \" _",
    "proceedings 2005 ieee international symposium on information theory ( isit ) _ , adelaide , australia , sept . 4 - 9 , 2005",
    "by the random coding bound @xcite , we have @xmath455 where @xmath456+\\log\\left\\{e^r-\\frac{{\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}}(e^r-1)}{2}\\left[\\sqrt{1+\\frac{4e^r}{{\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}}(e^r-1)}}-1\\right]\\right\\}\\label{exponent1}\\end{aligned}\\ ] ] if @xmath457\\leq r\\leq\\log(1+{\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}})$ ] , and @xmath458 if @xmath459 $ ] .    let @xmath460 where @xmath461 . by ( [ exponent1 ] ) , @xmath462+\\log\\left\\{\\frac{{\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}}}{\\eta}-\\frac{{\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}}({\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}}-\\eta)}{2\\eta}\\left[\\sqrt{1+\\frac{4}{{\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}}-\\eta}}-1\\right]\\right\\}\\\\ & = & \\lim\\limits_{{\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}}\\rightarrow\\infty}\\frac{\\eta}{2}\\left[\\frac{{\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}}}{\\eta}+1-\\frac{{\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}}-\\eta}{\\eta}\\left(1+\\frac{2}{{\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}}-\\eta}\\right)\\right]+\\log\\left\\{\\frac{{\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}}}{\\eta}-\\frac{{\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}}({\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}}-\\eta)}{2\\eta}\\left[\\frac{2}{{\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}}-\\eta}-\\frac{2}{({\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}}-\\eta)^2}\\right]\\right\\}\\\\ & = & \\eta-1-\\log\\eta\\\\ & > 0&.\\end{aligned}\\ ] ] for any @xmath463 , we can find an @xmath61 such that @xmath464 therefore , for any @xmath463 , there exist a sequence of codebooks with rate @xmath259 and fixed codeword length @xmath61 such that @xmath465 and @xmath271 .",
    "choosing @xmath467 and @xmath468 , we get @xmath469\\\\ & = & \\liminf\\limits_{{\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}}\\rightarrow\\infty}\\left[-\\log\\mathbb{e}_{{\\text{\\boldmath{$h$}}}}\\left(\\frac{1}{{\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}}}+\\frac{1}{2}|{\\text{\\boldmath{$h$}}}|^2\\right)^{-1}+\\log\\log{\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}}+c\\right]\\\\ & = & \\liminf\\limits_{{\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}}\\rightarrow\\infty}\\left\\{-\\log\\left[\\int_{0}^\\infty\\left(\\frac{1}{{\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}}}+\\frac{t}{2}\\right)^{-1}e^{-t}\\mbox{d}t\\right]+\\log\\log{\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}}+c\\right\\}\\\\ & = & \\liminf\\limits_{{\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}}\\rightarrow\\infty}\\left\\{-\\log\\left[\\int_{0}^1\\left(\\frac{1}{{\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}}}+\\frac{t}{2}\\right)^{-1}e^{-t}\\mbox{d}t+\\int_{1}^\\infty\\left(\\frac{1}{{\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}}}+\\frac{t}{2}\\right)^{-1}e^{-t}\\mbox{d}t\\right]+\\log\\log{\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}}+c\\right\\}\\\\ & \\geq&\\liminf\\limits_{{\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}}\\rightarrow\\infty}\\left\\{-\\log\\left[\\int_{0}^1\\left(\\frac{1}{{\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}}}+\\frac{t}{2}\\right)^{-1}\\mbox{d}t+\\int_{1}^\\infty2e^{-t}\\mbox{d}t\\right]+\\log\\log{\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}}+c\\right\\}\\\\ & = & \\liminf\\limits_{{\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}}\\rightarrow\\infty}\\left[-\\log\\left[2\\log(2 + 2{\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}}+{\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}}^2)-2\\log(2 + 2{\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}})+2e^{-1}\\right]+\\log\\log{\\mathsf{s\\hspace{-0.011in}n\\hspace{-0.011in}r}}+c\\right]\\\\ & = & -\\log 2+c\\end{aligned}\\ ] ] which is positive if @xmath470 ."
  ],
  "abstract_text": [
    "<S> we consider a peak - power - limited single - antenna block - stationary gaussian fading channel where neither the transmitter nor the receiver knows the channel state information , but both know the channel statistics . </S>",
    "<S> this model subsumes most previously studied gaussian fading models . </S>",
    "<S> we first compute the asymptotic channel capacity in the high snr regime and show that the behavior of channel capacity depends critically on the channel model . </S>",
    "<S> for the special case where the fading process is symbol - by - symbol stationary , we also reveal a fundamental interplay between the codeword length , communication rate , and decoding error probability . </S>",
    "<S> specifically , we show that the codeword length must scale with snr in order to guarantee that the communication rate can grow logarithmically with snr with bounded decoding error probability , and we find a necessary condition for the growth rate of the codeword length . </S>",
    "<S> we also derive an expression for the capacity per unit energy . </S>",
    "<S> furthermore , we show that the capacity per unit energy is achievable using temporal on - off signaling with optimally allocated on symbols , where the optimal on - symbol allocation scheme may depend on the peak power constraint .    wireless channels , noncoherent capacity , capacity per unit cost , block fading </S>"
  ]
}