{
  "article_text": [
    "in brief the _ inverse optimal control problem _ ( iocp ) can be stated as follows .",
    "given a system dynamics @xmath0 with possibly state and/or control constraints @xmath1\\ ] ] and a set of trajectories @xmath2,\\:x_0 \\in x}\\ ] ] parametrized by time and initial states , and stored in a database , the goal is to find a _",
    "function @xmath3 such that all state and control trajectories in the database are _ optimal trajectories _ for the direct optimal control problem ( ocp ) with integral cost @xmath4 with fixed or free terminal time @xmath5 .",
    "inverse problems in the context of calculus of variations and control are old topics that arouse a renewal of interest in the context of optimal control , especially in humanoid robotics .",
    "actually , even the well - posedness of the iocp is an issue and a matter of debate between the robotics and computer science communities .      the problem of variational formulation of differential equations ( or the inverse problem of the calculus of variations ) dates back to the _ 19-th _ century .",
    "the one dimensional case is found in @xcite , historical remarks are found in @xcite . necessary and sufficient conditions for the existence and the enumeration of solutions to this problem have been investigated since , see also @xcite for a survey about recent developments . notice that calculus of variations problems correspond to the particular choice of dynamics @xmath6 in the ocp .",
    "kalman first formulated the inverse problem in the context of linear quadratic regulator ( lqr ) @xcite which triggered research efforts in this realm @xcite .",
    "departing from the linear case , hamilton - jacobi theory is used in @xcite to recover quadratic value functions , in @xcite to prove existence theorems for a class of inverse control problems , and in @xcite to generalize results obtained for lqr . in a slightly different context , @xcite linked lyapunov and optimal value functions for optimal stabilization problems .",
    "more recently the well - posedness issue was addressed in @xcite in the context of lqr .",
    "robustness and continuity aspects with respect to lagrangian variations were investigated in @xcite , results about well - posedness and experimental requirements were exposed in @xcite , both in the context of dubbins dynamics and strictly convex positive lagrangians .    on a more practical side , motivated by @xcite ,",
    "the authors in @xcite have proposed an algorithm based on the ability to solve the direct problem for parametrized lagrangians and on a formulation of the iocp as a ( finite - dimensional ) nonlinear program .",
    "similar approaches have been proposed in the context of markov decision processes @xcite . in a sense",
    "these methods are `` blind '' to the problem structure as testing optimality at each current candidate solution is performed by solving numerically the associated direct ocp . to further exploit the problem structure",
    ", we can use explicit analytical optimality conditions for the direct ocp .",
    "for instance the use of necessary optimality conditions for solving numerically the iocp have already been proposed in recent works . in @xcite",
    "the direct problem is first discretized and the iocp is expressed as a ( finite - dimensional ) nonlinear program .",
    "then the _ residual _ technique of @xcite for inverse parametric optimization is applied to the karush - kuhn - tucker optimality conditions of the nonlinear program to account for optimality of the database trajectories . on the other hand",
    ", @xcite proposes to use the maximum principle for kinetic parameter estimation .",
    "surprisingly , in all the above references , only the seminal theoretical works of @xcite are based on ( or use ) the hamilton - jacobi - bellman equation ( hjb in short ) , whereas the hjb provide a well - known sufficient condition for optimality and a perfect practical tool for verification .",
    "one reason might be that the hjb is rarely used for solving the direct ocp and is rather used only as a verification tool .      we claim and hope to convince the reader that the hjb optimality equation ( in fact even a certain relaxation of hjb ) is a very appropriate tool not only for analyzing but also for solving the iocp . indeed :    \\(a ) the hjb optimality equation provides an almost perfect criterion to express optimality for database trajectories .",
    "\\(b ) the hjb optimality equation ( or its relaxation ) _ sheds light _ on the many potential pitfalls related to the iocp when treated in full generality . among them ,",
    "the most concerning issue is the ill - posedness of the inverse problem and the existence of solutions carying very little physical meaning .",
    "the hjb condition can be used as a guide to restrict the search space for candidate lagrangians .",
    "previous approaches to deal with this problem , implicitly or explicitly , involve strong constraints on the class of functions among which candidate lagrangians are searched @xcite .",
    "this allows , in some cases , to alleviate the ill - posedness issue and to provide theoretical guarantees regarding the possibility to recover a true lagrangian from the observation of optimal trajectories @xcite .",
    "departing from these approaches , the search space restrictions that we propose stems from either simple relations between the candidate lagrangian and optimal value function associated with the ocp , obvious from the hjb equation , or from purely sparsity biased estimation arguments .",
    "we do _ not _ require an _ a priori _ ( and always questionable ) selection of the `` type '' of candidate lagrangian ( e.g. coming from some  physical \" observations and/or remarks ) .",
    "\\(c ) last but not least , a relaxation of the hjb optimality equation can be readily translated into a positivity condition for a certain function on some set . if the vector field @xmath7 is polynomial , and the state and/or control constraint sets @xmath8 and @xmath9 are basic semi - algebraic then a natural strategy is to consider _ polynomials _ as candidate lagrangians and ( approximated ) optimal value functions associated with the direct ocp . within this framework ,",
    "using powerful positivity certificates _  la putinar _ to look for an optimal solution of the iocp reduces to solving a hierarchy of semidefinite programs ( sdp ) , or linear matrix inequalities ( lmi ) of increasing size .",
    "importantly , a distinguishing feature of this approach is _ not _ to rely on iteratively solving a direct ocp .",
    "notice that since the 1990s , the availability of reasonably efficient sdp solvers @xcite has strengthened the interest in optimization problems with polynomial data .",
    "examples of applications of such positivity certificates are given in @xcite and @xcite for direct optimization and optimal control , and in @xcite for inverse ( static ) optimization .",
    "the paper is organized as follows . in section [ sec:2 ]",
    "we properly define the iocp .",
    "next , in section [ sec:3 ] , we present the conceptual ideas based on hjb theory , polynomial optimization and lmi .",
    "we emphasize that these ideas allow to highlight potential pitfalls of the iocp .",
    "a practical implementation of the discussed conceptual method is proposed in section [ sec:4 ] .",
    "finally , in section [ sec:5 ] we first illustrate the outputs of the method on a simple one - dimensional example and then provide promising results on more complex academic examples .",
    "if @xmath10 is a topological vector space , @xmath11 represents the set of continuous functions from @xmath10 to @xmath12 and @xmath13 represents the set of continuously differentiable functions from @xmath10 to @xmath12 .",
    "let @xmath14 denote the state space and @xmath15 denote the control space which are supposed to be compact subsets of euclidean spaces .",
    "system dynamics are represented by a continuously differentiable vector field @xmath16 which is supposed to be known .",
    "terminal state constraints are represented by a set @xmath17 which is also given .",
    "let @xmath18 denote the unit ball of the euclidean norm in @xmath19 , and let @xmath20 denote the boundary of set @xmath8",
    ".      given a lagrangian @xmath21 we consider a direct ocp of the form : @xmath22,\\\\      & & x(t ) = z , \\,x(t ) \\in x_t \\end{array}\\ ] ] with final time @xmath23 .",
    "in this formulation , the final time @xmath5 might be given or free , in which case it is a variable of the problem and the _ value function _ @xmath24 does not depend on @xmath25 . for the rest of this paper , direct problems of the form of ( [ eq : pdirect ] ) are denoted as @xmath26    more general problem classes could be considered . indeed , there is no terminal cost and the problem is stationary .",
    "further comments are found in next sections .",
    "the infimum in ( [ eq : pdirect ] ) might not be attained .",
    "the inverse problem consists of recovering the lagrangian of the direct ocp based on :    * knowledge of the dynamics @xmath7 as well as state and/or control constraint sets @xmath27 , * observation of optimal trajectories stored in a database indexed by some index set @xmath28    @xmath29 \\times x \\times u)^i.\\end{aligned}\\ ] ]    for complete trajectories , the index set @xmath28 is a continuum . for real world data , it is a finite set .",
    "more specifically , the inverse problem consists of finding @xmath30 such that @xmath31 is a subset of optimal trajectories of problem @xmath32 for all @xmath33 $ ] .",
    "a solution of this problem would be an operator mapping back @xmath31 to @xmath34 such that the input data satisfy optimality conditions for problem @xmath35 .",
    "for the rest of this paper , we define the following linear operator acting on lagrangians and value functions : @xmath36 a well - known sufficient condition for optimality in problem ( [ eq : pdirect ] ) follows from hamilton - jacobi - bellman ( hjb ) theory , see e.g. @xcite .",
    "[ prop-1 ] suppose that there exist state and control trajectories @xmath37}$ ] such that @xmath38,\\\\   x_0(t ) = z , \\:\\:x_0(t ) \\in x_t.\\end{aligned}\\ ] ] suppose in addition that there exists a function @xmath39 \\times x ) $ ] such that @xmath40\\times x\\times u,\\\\   \\label{aux3 } v_0(t , x ) = 0,\\,\\forall x \\in x_t,\\\\ \\label{aux2 } \\mathcal{l}(l_0,v_0)(s , x_0(s ) , u_0(s ) ) = 0,\\ , \\forall s \\in [ t , t].\\end{aligned}\\ ] ] then the state and control trajectories @xmath37}$ ] are optimal solutions of the direct problem ( [ eq : pdirect ] ) .",
    "recall that @xmath41 are compact .",
    "so integrating ( [ aux1 ] ) along _ any _ feasible state and control trajectories @xmath42 with initial state @xmath43 at time @xmath25 , and using ( [ aux3 ] ) yields @xmath44 whereas using ( [ aux2 ] ) one has @xmath45 .",
    "observe that ( [ aux1])-([aux3 ] ) are just a _ relaxation _ of the hjb equation and from proposition [ prop-1 ] ( [ aux1])-([aux2 ] ) provide a certificate of optimality of the proposed trajectory .",
    "additional assumptions on problem structure are required to make this condition necessary , see _",
    "e.g. _ @xcite",
    ". moreover , for most direct problems these conditions can not be met in the usual sense and _ viscosity solutions _ are needed , see _",
    "e.g. _ @xcite .",
    "our approach is based on a classical interpretation as well as a relaxation of these sufficient conditions alone .    in the free terminal time setting , the conditions ( [ aux1])-([aux3 ] ) can be simplified because @xmath24 does not depend on the initial time @xmath25 any more .",
    "we use hjb relations to characterize some approximate solutions of the inverse problem .",
    "the idea is based on the following weakening of proposition [ prop-1 ] .",
    "[ prop-2 ] let @xmath46}$ ] , with @xmath47 , be such that ( [ eq : dyncstr ] ) is satisfied .",
    "suppose that there exist a real @xmath48 and functions @xmath49 , @xmath50\\times x)$ ] such that @xmath51\\times x\\times u ,   \\label{eq : coniccstr}\\\\ v(t , x)=0,\\ , \\forall x \\in x_t,\\\\ \\int_t^t \\mathcal{l}({l},{v})(s , x_0(s),u_0(s ) ) ds \\leq \\epsilon .",
    "\\label{eq : fitcstr}\\end{aligned}\\ ] ] then , the input trajectory @xmath46}$ ] is @xmath48-optimal for problem @xmath52 .    proceeding as in the proof of proposition [ prop-1 ] , @xmath53 is a lower bound on the value function of problem @xmath52 and from the last linear constraint ( [ eq : fitcstr ] ) we deduce that @xmath54    proposition [ prop-2 ] can be easily extended to the case of multiple trajectories .",
    "the main advantage is that we have a certificate of @xmath48-optimality .",
    "observe that @xmath55-optimality is in principle impossible to obtain because the optimal value function @xmath56 of a direct ocp is in general non - differentiable ; however as soon as @xmath56 is continuous then by the stone - weierstrass theorem @xmath56 can be approximated on the compact @xmath57\\times x$ ] as closely as desired by a polynomial and so @xmath48-optimality is indeed achievable for arbitrary @xmath58 .    the conditions ( [ eq : coniccstr])-([eq : fitcstr ] )",
    "do not ensure that the infimum of the direct problem with cost @xmath59 is attained .",
    "however the fact that a trajectory is given ensures that it is feasible .",
    "the construction of multiple solutions to the inverse problem is trivial given the tools of proposition [ prop-2 ] . consider the free terminal time setting and suppose that the pair @xmath60 satisfies conditions ( [ eq : coniccstr])-([eq : fitcstr ] ) for some @xmath61 .",
    "take a differentiable @xmath62 such that @xmath63 for @xmath64",
    ". then the pair @xmath65 satisfies constraints ( [ eq : coniccstr])-([eq : fitcstr ] ) for the same @xmath48 .",
    "the possibility to construct such solutions stems from the existence of trivial solutions to the problem .    as we already mentioned , the constraint ( [ eq : coniccstr ] ) is positively homogeneous in @xmath66 and therefore , the pair @xmath67 is always feasible . in other words",
    "the trivial cost @xmath68 is always an optimal solution of the inverse problem , independently of input trajectories .",
    "but the well - posedness issue is even worse than this .",
    "consider a pair of functions @xmath66 such that @xmath69 on the domain of interest , then any feasible trajectory of the direct problem will be optimal for @xmath70 .",
    "consider the following one dimensional free terminal time direct setting @xmath71 the pair of functions @xmath72 satisfies constraint ( [ eq : coniccstr ] ) and @xmath69 .",
    "any feasible trajectory , @xmath46}$ ] with @xmath73 , @xmath47 , and such that ( [ eq : dyncstr ] ) is satisfied , is optimal for @xmath52 .",
    "indeed @xmath74    such pairs are solutions of the iocp in the sense that was proposed in the previous section . however , these solutions do not have any physical interpretation , because they do not depend on input trajectories .",
    "in addition , because the solutions of the iocp form a _ convex cone _ , the existence of such solutions allows to construct multiple solutions to the iopc . to avoid this ,",
    "one possibility is to include an additional normalizing constraint of the form : @xmath75 for some linear functional @xmath76 on the space of continuous functions .",
    "this can be viewed as a search space reduction as we intersect the cone defined by ( [ eq : coniccstr ] ) with an affine space .",
    "as we already mentioned , we do not consider terminal cost and limit ourselves to stationary problems .",
    "this setting was chosen to avoid more ill - posedness of the same type and keep the presentation clear .",
    "previous practical methods @xcite and theoretical work @xcite include , implicitly or explicitly , constraints of the form of ( [ eq : normcstr ] ) but only enforce them on the candidate lagrangian @xmath70 .      considering a single trajectory as input for the iocp leads to lagrangians that enforce closedness to this trajectory , which may have little physical meaning .",
    "consider the direct problem with free terminal time @xmath77 the optimal control is @xmath78 and the optimal value function is @xmath79 .",
    "consider the trajectory @xmath80 } = ( ( s - 1 , 0 ) , ( 1 , 0))_{s \\in[0 , 1]}.      \\end{aligned}\\ ] ] this trajectory is optimal for @xmath81 but it is also optimal for @xmath82 .",
    "however , the second lagrangian only captures a constant of the particular trajectory considered .      in practical settings , one rarely has access to complete trajectories .",
    "typical experiments produce discrete samples from trajectories and possibly with additional experimental noise .",
    "the database consists of a set of @xmath83 points @xmath84 . in this case",
    ", we replace the integral in ( [ eq : fitcstr ] ) by a discrete sum : @xmath85 in this setting , it is generically possible to find lagrangians that satisfy constraints ( [ eq : coniccstr ] ) and ( [ eq : fitcstr ] ) with @xmath86 .",
    "consider , in a free terminal time setting a discrete dataset @xmath87 .",
    "the pair of functions @xmath88 satisfies constraint ( [ eq : coniccstr ] ) and ( [ eq : fitdisccstr ] ) with @xmath86 .",
    "because of experimental noise and random perturbations of the input trajectories , one can find lagrangians which fit tightly a particular sample of trajectories .",
    "this does not give much insight about the true nature of the original trajectories .",
    "furthermore , the proposed lagrangian may be far from optimal if the database was fed up with a different sample of trajectories . in statistics",
    "this well - known phenomenon bears the name of _ overfitting _ ( see _ e.g. _",
    "@xcite for a nontechnical introduction and @xcite for an overview of the mechanisms it involves ) .",
    "a common approach to avoid overfitting is to introduce biases in the estimation procedure with search space restrictions or regularization terms .",
    "we adopt such a strategy in the practical method described in the next section .",
    "it is clear that this discretization , although intuitive , arises many questions regarding the effect of noise and of sample size in practical iocp , rarely discussed and even mentioned in previous works .",
    "these theoretical considerations are not specific to the method we propose .",
    "they are beyond the scope of this paper and constitute a strong motivation for future research work .",
    "we have seen that the hjb theory is very useful to address well - posedness issues regarding the inverse problem . in full generality the hjb equations ( or their relaxations ) are computationally intractable . on the other hand , in a polynomial and semi - algebraic context , some powerful positivity certificates from real algebraic geometry permit to translate the relaxation ( [ eq : coniccstr ] ) of the hjb equations into an appropriate lmi hierarchy , hence amenable to practical computation .",
    "therefore , in the sequel , we assume that @xmath7 is a polynomial and @xmath8 , @xmath9 and @xmath89 are basic semi - algebraic sets . recall that @xmath90 is basic semi - algebraic whenever there exists polynomials @xmath91 such that @xmath92 .",
    "in addition , we assume that the input database is indexed by a finite set : @xmath93 .",
    "we consider the following program @xmath94\\times x\\times u , \\\\",
    "& v(t , x ) = 0 , \\:\\:\\forall x \\in x_t , \\\\ & \\frac{1}{n } \\displaystyle\\sum_{i=1}^n\\mathcal{l}(l , v)(t_i , x_i , u_i ) \\leq \\epsilon , \\\\ & \\mathcal{a}(\\mathcal{l}(l , v ) ) = 1 \\end{array}\\ ] ] where @xmath34 and @xmath56 are polynomials , @xmath48 is a real , @xmath95 is a given regularization parameter , and @xmath96 denotes the @xmath97 norm of a polynomial , _",
    "i.e. _ the sum of absolute values of its coefficients when expanded in the monomial basis .",
    "the first two constraints come from the relaxation ( [ eq : coniccstr ] ) of the hjb equations while the third constraint comes from the _ fit _ constraint ( [ eq : fitdisccstr ] ) .",
    "finally , the last affine constraint is meant to avoid the trivial solutions that satisfy @xmath98 .",
    "the @xmath97 norm is not differentiable around sparse vectors ( with entries equal to zero ) and has therefore a sparsity promoting role which allows to bias solutions of the problem toward lagrangians with few nonzero coefficients .",
    "this regularization affects the problem well - posedness and will prove to be essential in numerical experiments .",
    "linear constraints are easily expressed in term of polynomial coefficients .",
    "a classical lifting allows to express the @xmath97 norm minimization as a linear program .",
    "the normalization functional @xmath99 is chosen to be an integral over a box contained in @xmath100 . to express nonnegativity of polynomials over a compact basic semi - algebraic set of the form @xmath101",
    ", we invoke powerful positivity certificates from real algebraic geometry . indeed ,",
    "if a polynomial @xmath102 is positive on @xmath103 then by putinar s positivstellensatz @xcite it can be written as @xmath104 where @xmath105 denotes the set of sum of squares ( sos ) polynomials .",
    "hence ( [ eq : soscstr ] ) provides a useful certificate that @xmath102 is nonnegative on @xmath103 .",
    "moreover , as membership to @xmath105 reduces to semidefinite programming , the constraint ( [ eq : soscstr ] ) is easily expressed as an lmi whose size depends on the degree bound allowed for the sos polynomials @xmath106 in ( [ eq : soscstr ] ) .",
    "therefore , replacing the positivity constraint in ( [ eq : primal1 ] ) with the constraint ( [ eq : soscstr ] ) allows to express problem ( [ eq : primal1 ] ) as a hierarchy of lmi problems @xcite indexed by the degree bounds on the sos in ( [ eq : soscstr ] ) .",
    "thus each lmi of the hierarchy can be solved efficiently ( of course up to some size limitations ) .",
    "we use the sos module of the ` yalmip ` toolbox @xcite to manipulate and express polynomial constraints at a high level in ` matlab ` .",
    "in our numerical experiments we considered several direct problems of the same form as ( [ eq : pdirect ] ) . that is , we give ourselves compact sets @xmath8 , @xmath9 , @xmath89 , the dynamics @xmath7 , and a lagrangian @xmath107 .",
    "we take known examples for which the optimal control law can be computed .",
    "given these , we generate randomly @xmath108 data points @xmath109 in the domain , such that @xmath110 is the optimal control value at point @xmath111 and time @xmath112 . for a given value of @xmath113 ,",
    "we compute a solution @xmath70 of problem ( [ eq : primal1 ] ) .",
    "we can then measure how @xmath70 is close to @xmath107 .",
    "note that in some simulations , the control is corrupted with noise .        for this problem",
    "we take @xmath114 the optimal law for this problem is @xmath115 and the value function is @xmath116 .      for this problem",
    "we take @xmath117 the optimal law for this problem is @xmath118 and the value function is @xmath119 .      for this problem",
    "we take @xmath120 the optimal law for this problem is @xmath121 and the value function is @xmath122 .      for this problem",
    "we take @xmath123 , \\ ,",
    "t=1,\\\\      l_0&= x^t \\left (        \\begin{array}{cc }          2 & \\frac{1}{4}\\\\          \\frac{1}{4 } & 1      \\end{array }      \\right)x + u^2,\\\\      f & =       \\left (   \\begin{array}{c c }          0 & 1\\\\          0 & 0      \\end{array } \\right ) x      +       \\left (   \\begin{array}{c }          0 \\\\          1       \\end{array } \\right ) u\\\\\\end{aligned}\\ ] ] for a big enough value of @xmath124 .",
    "this is an lqr problem , the optimal control is of the form @xmath125 where @xmath126 is obtained by solving the corresponding riccati differential equation .      .",
    "the first column is the distribution of the error @xmath48 , the second is a representation of the value function @xmath127 and the third column is a representation of its derivative for solutions of problem ( [ eq : primal1 ] ) with and without regularization .",
    "we take 100 points on the segment .",
    "lagrangian @xmath70 and value function @xmath127 are both polynomials of degree 16.,scaledwidth=80.0% ]      we consider the one dimensional minimum exit time problem in [ sec : pb1 ] .",
    "the results are presented in figure [ fig : onedexit ] .",
    "we compare the output of ( [ eq : primal1 ] ) with ( @xmath128 ) and without ( @xmath129 regularization .",
    "the main comments are as follows .",
    "* given any symmetric differentiable concave function @xmath127 vanishing on @xmath130 , the pair @xmath131 solves problem ( [ eq : primal1 ] ) with @xmath86 .",
    "* given any polynomial @xmath127 vanishing on @xmath130 , and any positive polynomial @xmath102 on @xmath132\\times x\\times u$ ] , the pair @xmath133 solves problem ( [ eq : primal1 ] ) with @xmath86 .",
    "note that this solution only captures the fact that @xmath134 . * any convex combination of solutions of the types mentioned above",
    "also solve problem ( [ eq : primal1 ] ) .",
    "it is therefore very hard , in the absence of regularization ( @xmath135 ) , to recover the true lagrangian . *",
    "the sparsity inducing effect of @xmath97-norm regularization allows to recover the true lagrangian ( @xmath128 ) .",
    "* the value function associated to this lagrangian is not smooth around the origin and therefore hard to approximate , hence the value of the error is high .    .",
    "a : minimum exit time .",
    "a : minimum exit time sampling far from the origin .",
    "b : minimum exit norm .",
    "c : double integrator . estimation error is the metric defined in ( [ eq : metric ] ) .",
    "epsilon error is the value of the term @xmath48 in program ( [ eq : primal1 ] ) . for a , a and b",
    ", we take 20 random points and corresponding control value . for c ,",
    "we take 50 random points and time with corresponding control . for all problems ,",
    "lagrangian @xmath70 is a polynomial of degree 4 and value function @xmath127 is a polynomial of degree 10.,scaledwidth=80.0% ]      we consider the following settings    * problem [ sec : pb2 ] with @xmath136 sampled on @xmath137",
    ". * problem [ sec : pb2 ] with @xmath136 sampled on @xmath138 . *",
    "problem [ sec : pb3 ] with @xmath136 sampled on @xmath137 .",
    "* problem [ sec : pb4 ] with @xmath136 sampled uniformly on the unit @xmath139 ball .    in all cases , @xmath70 has degree @xmath140 and @xmath127 has degree @xmath141 .",
    "[ [ estimation - error ] ] estimation error + + + + + + + + + + + + + + + +    since the inverse problem is positively homogeneous , our objective is to recover a lagrangian @xmath107 , up to a positive multiplicative factor .",
    "since we use polynomials , the lagrangians we estimate can be represented as vectors in the monomial basis .",
    "we use the following metric to account for the estimation error : @xmath142 where the scalar product of polynomials is defined as the usual scalar product of their vectors of coefficients in the monomial basis .    .",
    "a : minimum exit time .",
    "a : minimum exit time sampling far from the origin .",
    "b : minimum exit norm .",
    "c : double integrator .",
    "estimation error is the metric defined in ( [ eq : metric ] ) .",
    "we vary the number of random points .",
    "the control is corrupted by uniform noise and we repeat the experiment five times for each value of @xmath113 . for all problems ,",
    "lagrangian @xmath70 is a polynomial of degree 4 and value function @xmath127 is a polynomial of degree 10.,scaledwidth=80.0% ]    [ [ deterministic - setting ] ] deterministic setting + + + + + + + + + + + + + + + + + + + + +    the results for the four problems are presented in figure [ fig : deterministic ] . for all problems ,",
    "@xmath70 is of degree 4 .",
    "therefore , for problems a , a and b , @xmath70 is represented by a 70-dimensional vector and for problem @xmath143 , it is a 35-dimensional vector . when the estimation error is close to 1 , we estimate a lagrangian @xmath70 that is orthogonal to @xmath107 in the monomial basis . for all problems we are able to recover the true lagrangian with good accuracy for some value of the regularization parameter @xmath113 . in the absence of regularization , we do not recover the true lagrangian at all .",
    "this highlights the important role of @xmath97 regularization which allows to bias the estimation toward _",
    "sparse polynomials_. when the estimation error is minimal , the value of @xmath48 is reasonably low , depending on how the value function can be approximated by a polynomial .",
    "for example , a shows lower @xmath48 value because we avoid sampling database points close to the nondifferentiable point of the true value function . in example",
    "c , the value function is not a polynomial and therefore harder to approximate .",
    "the estimation accuracy is still very reasonable .",
    "[ [ stochastic - setting ] ] stochastic setting + + + + + + + + + + + + + + + + + +    the results for the four problems are presented in figure [ fig : noise ] .",
    "the setting is similar to the deterministic case of the previous paragraph , except that we add uniform noise ( of maximum magnitude @xmath144 ) to the control input .",
    "therefore , the problem is harder than the one presented in the previous paragraph .",
    "several samples and noise realizations are considered to highlight the global trends .",
    "these simulations show that despite the stochastic corruption of the input control , we are still able to recover the true lagrangian with reasonable accuracy . as one could expect , increasing the number of datapoints allows to recover the true lagrangian with a better accuracy .",
    "we have presented how hamilton - jacobi - bellman sufficient condition can be used to analyse the inverse problem of optimal control and proposed a practical method based on polynomial optimization and linear matrix inequality hierarchies to provide a candidate solution to this problem .",
    "numerical results suggest that the method is able to estimate accurately lagrangians comming from various optimal control problems .    for the specific examples proposed , the optimality conditions allow to highlight many sources of ill - posedness for the inverse problem .",
    "in addition to a relaxation of the optimality conditions , we added a constraint and a penalization to circumvent ill - posedness .",
    "numerical simulations support the idea that these are essential to estimate a lagrangian accuartely .",
    "we do not rely on strong bias toward specific candidate lagrangians and are able to perform accurate estimation in many different settings using the same regularization technique . a natural question that arises here is to find necessary conditions under which this is possible .",
    "the motivation for the use of hamilton - jacobi - bellman optimality condition is the guarantees it provides when one has access to complete noiseless trajectories .",
    "however , practical experimental settings require to consider the effects of discretization and additive noise . along these lines , consistency and asymptotic properties of the proposed estimation procedure with respect to random",
    "discretization and noise are natural questions .",
    "finally , it is necessary to carry out further experiments on real world datasets in order to determine if the proposed method works on practical inverse problems , our primary target being those coming from humanoid robotics @xcite .",
    "this work was partly funded by an award of the simone and cino del duca foundation of institut de france .",
    "the authors would like to thank frdric jean , jean - paul laumond , nicolas mansard and ulysse serres for fruitful discussions ."
  ],
  "abstract_text": [
    "<S> in the context of optimal control , we consider the inverse problem of lagrangian identification given system dynamics and optimal trajectories . </S>",
    "<S> many of its theoretical and practical aspects are still open . </S>",
    "<S> potential applications are very broad as a reliable solution to the problem would provide a powerful modeling tool in many areas of experimental science . </S>",
    "<S> we propose to use the hamilton - jacobi - bellman sufficient optimality conditions for the direct problem as a tool for analyzing the inverse problem and propose a general method that attempts at solving it numerically with techniques of polynomial optimization and linear matrix inequalities . </S>",
    "<S> the relevance of the method is illustrated based on simulations on academic examples under various settings . </S>"
  ]
}