{
  "article_text": [
    "due to the finite resolution of sensors and particle detector systems , inverse problems involving poisson counts received considerable attention in particle physics  @xcite . in this field , reconstruction of particle spectra that involves solving corresponding statistical inverse problems is usually referred to as `` unfolding '' .",
    "most widely used techniques , popularized by the code availability in the roounfold software package  @xcite , include `` svd '' unfolding  @xcite and iterative expectation - maximization ( a.k.a .",
    "dagostini , or bayesian ) unfolding  @xcite regularized by early stopping .",
    "the expectation - maximization unfolding with a smoothing step was introduced in  @xcite , where convergence of the method was established and its relation to penalized maximum likelihood techniques was pointed out . in the context of particle physics applications , this method became widely known after its reinvention , albeit in a less general form , in  @xcite .",
    "expectation - maximization with smoothing will be abbreviated `` ems '' for the remainder of this paper .",
    "this article is structured as follows .",
    "the statistical formulation of the unfolding problem and basic mathematical notation used throughout the manuscript are introduced in section  [ sec : problemstatement ] . in section  [ sec : regularization ] , the concept of regularization is discussed and its necessity is illustrated with a simple example .",
    "regularization by smoothing in the ems approach is described in section  [ sec : ems ] , together with the formulae for error propagation . a  method for determining the effective number of fitted parameters for unfolding procedures",
    "is proposed in section  [ sec : effectivenum ] .",
    "an  automatic choice of the regularization strength based on the akaike information criterion is advocated in section  [ sec : emschoice ] .",
    "numerical studies of the frequentist coverage of the developed uncertainty formulae are described in section  [ sec : simulation ] using two density models similar to those encountered in particle physics applications .",
    "presentation and use of the unfolded results are discussed in section  [ sec : resultpresent ] .",
    "finally , the advantages of the developed methodology are summarized in section  [ sec : conclusions ] .",
    "for the purpose of stating the unfolding problem , it will be assumed that the detector can be described by an operator @xmath0 .",
    "this operator ( also called _ kernel _ , _ transfer function _ , _ observation function _ , or _",
    "response function _ , depending on the author and context ) converts probability densities @xmath1 in the physical process space @xmath2 into the densities @xmath3 in the observation space @xmath4 : @xmath5 the response function does not have to be fully efficient : @xmath6 does not have to integrate to 1 when @xmath7 is normalized . in the subsequent discussion , operator @xmath0 will be assumed exactly known but not necessarily invertible .    in many situations of interest ,",
    "observations are described by the empirical density function ( _ i.e. _ , there is no uncertainty associated with each individual observation ) : @xmath8 in this case , the probability density function to observe a point at @xmath9 is given by the normalized version of @xmath6 called @xmath10 : @xmath11 . in case",
    "@xmath7 is normalized , @xmath12 is the overall detector acceptance for the physical process under study .",
    "the purpose of unfolding is to learn as much as possible about @xmath1 given @xmath13 when a  parametric model for @xmath1 is lacking . reporting @xmath1 ( rather than @xmath3 ) and its uncertainty simplifies testing of theoretical models against results obtained by multiple experiments and allows for preservation of scientific results in a form suitable for comparison with models that have not been invented yet .",
    "it should be noted that , in case operator @xmath0 has a non - empty nullspace , the problem of @xmath1 determination is ill - posed even in the large sample limit .",
    "the nullspace of the response function is defined as the set of all functions @xmath14 satisfying the equation @xmath15 which are not identical zeros . if @xmath1 is treated in eq .",
    "[ eq : kernelaction ] as the function to be solved for , the general solution of this equation is @xmath16 , where @xmath17 is any particular solution and @xmath14 is an arbitrary nullspace member .",
    "this nullspace definition is also appropriate for a  discretized representation of @xmath2 and @xmath4 spaces ( discussed further in section  [ sec : ems ] ) , with @xmath18 represented by a  matrix and integration over @xmath19 replaced by matrix - vector multiplication .",
    "nullspace forms a linear subspace in the space of functions ( for the discretized problem , in the space of vectors ) . assuming that an inner product is postulated ( _ e.g. _ , as in the @xmath20-space ) , an arbitrary function can be uniquely decomposed into two additive components : the component that belongs to the nullspace and the component that belongs to the orthogonal complement of the nullspace . for numerical computations with finite precision ,",
    "the effective nullspace is enlarged .",
    "a reasonably useful definition of this extended nullspace can be introduced procedurally , by performing singular value decomposition of the operator @xmath0 and by using the basis that consists of right - singular vectors corresponding to `` small '' singular values .",
    "an appropriate method for qualifying singular values as `` small '' will , in general , depend on the precision of floating point operations and on algorithm implementation details .",
    "the difficulty of the unfolding problem can be easily appreciated from the following argument .",
    "@xmath0 typically acts as low - pass filter . for measurements of a  single scalar quantity",
    ", it can often be assumed that the detector has resolution @xmath21 and that @xmath22 , where @xmath23 stands for the normal distribution with mean @xmath24 and variance @xmath25 .",
    "the detector thus simply convolves @xmath26 with the normal distribution which leads to the product of the corresponding fourier coefficients .",
    "if @xmath6 was exactly known , the fourier transform of @xmath7 could be obtained from @xmath27 , where @xmath28 and @xmath29 are the fourier transforms of the observation density and the response function , respectively .",
    "as @xmath28 is not known , the closest available approximation is the characteristic function of @xmath30 : @xmath31 . for the normal distribution , @xmath32 , so that the ratio @xmath33 becomes arbitrarily large as @xmath34 .",
    "the `` naive '' method of estimating @xmath35 as @xmath33 thus fails miserably : the high frequency components of the noise contained in the @xmath36 are multiplied by an arbitrarily large factor so that @xmath33 is not even square - integrable .",
    "a number of effective approaches to solving the pure deconvolution problem just described are detailed in  @xcite .",
    "these approaches invariably involve introduction of additional smoothness assumptions about either @xmath26 or @xmath37 or both .",
    "it is averred that the high frequency components of @xmath26 are of little interest and , therefore , can be suppressed in the @xmath33 ratio so that the inverse fourier transform can exist .",
    "introduction of new information by applying additional assumptions which make an  originally ill - posed problem treatable is called _",
    "regularization_.    in the problems of interest for particle physics , the action of @xmath18 on @xmath1 is usually more complicated than the simple convolution while the necessity of regularizing the ill - posed problem is as pressing . in the formulation of the svd unfolding method presented in  @xcite",
    ", one - dimensional @xmath2 is assumed , and the regularization is performed by penalizing the discretized second derivative of the @xmath26 density . the expectation - maximization unfolding is most commonly regularized by imposing a  subjective limit on the number of iteration cycles .",
    "this early stopping criterion penalizes deviations from the distribution used to start the iterations .",
    "however , due to the method nonlinearity , it is difficult to supplement this statement with a concise analytic derivation of a  penalty term that would permit determination of the penalized likelihood maximum as well as a  subsequent quantification of the relationship between these deviations and the number of iterations performed .    in these unfolding approaches",
    ", it is assumed that the @xmath2 and @xmath4 spaces are binned , and that locations of the bin boundaries are beyond the control of the method .",
    "however , it should be appreciated that sample binning is an important part of problem regularization .",
    "the unfolding problem can even be fully regularized by making very wide bins , much wider than the typical scales associated with the detector resolution function .",
    "this leads to a  discretized representation of the response function by a diagonally dominant matrix which is easily invertible . however , information about probability density structures within each bin is now lost , as the actual density is replaced by the uniform approximation .",
    "the lack of knowledge about these structures gives rise to a `` systematic error '' on the unfolding result which is subjective and difficult to formalize .",
    "the standard expectation - maximization unfolding algorithm iteratively updates the reconstructed values of @xmath1 according to the formula  @xcite @xmath38 here , @xmath39 are the unnormalized @xmath1 values ( event counts ) discretized on a grid in the physical process space @xmath2 , obtained on a  @xmath40@xmath41 iteration .",
    "the index @xmath42 refers to the  _ linearized _ cell number in this ( possibly multidimensional ) grid . in this study",
    ", it will be assumed that all grid cells are small in comparison with the typical scales associated with the response function .",
    "all @xmath43 values ( the starting point for the iterations ) can be set to the same constant , @xmath44 , where @xmath45 is the number of observed events and @xmath46 is the overall detector efficiency for a  constant @xmath1 .",
    "the number of observed events inside the cell with linearized index @xmath47 ( @xmath48 ) in the space of observations @xmath4 is denoted @xmath49 .",
    "dimensionalities of the @xmath2 and @xmath4 spaces are arbitrary and can be different .",
    "@xmath50 is the discretized response matrix .",
    "it is the probability that an event from the physical cell @xmath51 causes an observation in the cell @xmath47 of the @xmath4 space .",
    "the detector efficiency for the physical cell @xmath51 , @xmath52 , is defined by @xmath53 .",
    "these iterations are modified by introducing a smoothing step .",
    "the updating scheme becomes @xmath54 where @xmath55 is the _",
    "smoothing matrix_. the smoothing step normalization constant , @xmath56 , is introduced in order to preserve the overall event count obtained during the preceding expectation - maximization step , so that @xmath57 .",
    "the values @xmath58 obtained upon iteration convergence are therefore solutions of the equation @xmath59 where @xmath60 .",
    "convergence of the smoothed iterations to this fixed point has been established in  @xcite under the sufficient condition that the smoothing operator ( for this case , the product @xmath61 ) has no eigenvalues greater than unity in absolute value .",
    "the equation for the error propagation matrix , @xmath62 , is obtained by differentiating eq .",
    "[ eq : semeq ] with respect to @xmath63 . in the matrix notation , this equation is @xmath64 where @xmath65 and @xmath66 is the fitted number of observed events in the cell with index @xmath47 . in practice , an equation equivalent to  [ eq : errprop ] , @xmath67 , can be solved using the lu factorization algorithm ( for example , as implemented in lapack  @xcite ) . assuming that the covariance matrix of observations is denoted by @xmath68 , the covariance matrix of the unfolded values , @xmath69 , is estimated according to @xmath70    it has been suggested that , upon convergence of the smoothed expectation - maximization iterations , one extra iteration without the smoothing step should be performed  @xcite . while the utility of adding such an iteration is questionable is not available , and only a  monte carlo procedure for sampling from @xmath1 can be devised . assuming that the theory sample is sufficiently copious , the smoothing matrix can be used to construct @xmath1 estimate from the empirical density function of this sample in the manner appropriate for subsequent comparison with unfolded observations . ] , the error propagation matrix for this approach , @xmath71 , is given by @xmath72 .",
    "subsequently , the covariance matrix of the unfolded result should be estimated as @xmath73 , where the covariance matrix of observations , @xmath74 , is obtained using the @xmath75 values defined by eq .",
    "[ eq : semone ] and processed according to eq .",
    "[ eq : kernelaction ] .    constructed with an appropriate method ,",
    "the smoothing matrix @xmath76 can have a  rather intuitive interpretation . setting @xmath77 leads to the maximum likelihood estimate of the @xmath78 parameters @xmath58  @xcite .",
    "the number of these parameters can be large and , according to the cramer-rao bound , the amount of information present in the observed data is insufficient to constrain them with limited variance .",
    "the smoothing matrix introduces a reasonable assumption that the `` nearby '' unfolded values should not be very different .",
    "this assumption shifts the bias - variance tradeoff of the maximum likelihood estimate towards a strong reduction of the variance at the cost of a slight increase in the estimator bias .",
    "finally , it should be noted that the error propagation formulae are simplified for doubly stochastic smoothing matrices for all @xmath10 and @xmath79 for all @xmath6 ( _ i.e. _ , each row and each column sum up to  1 ) .",
    "note that any reasonable smoother should map the uniform density into itself and , therefore , satisfy the row summation conditions . ] .",
    "for such matrices , @xmath80 for all  @xmath40 and @xmath81 .",
    "this simplification is important for software implementations utilizing sparse matrix algorithms as @xmath82 is , generally , not sparse .",
    "in various unfolding procedures , it is desirable to choose the regularization strength by an  automatic criterion amenable to simulation studies .",
    "a number of possible choices are based on the comparison of the fit with the observed data . a  least squares matching criterion",
    "is advocated , for example , in  @xcite and  @xcite . in order to properly estimate the @xmath7-value resulting from the application of such a  criterion",
    ", one has to estimate the number of parameters used to fit the data .",
    "we propose to estimate the number of fitted parameters from the effective rank of the matrix @xmath83 .",
    "this proposal is based on the following argument matrix plays a similar role to the hat matrix in linear regression problems .",
    "this leads to the same conclusion about the number of model parameters . ] .",
    "the covariance matrix of the fitted folded values ( _ i.e. _ , @xmath84 ) is @xmath85 .",
    "if , using polynomial series ( _ e.g. _ , legendre polynomials ) , one fits multiple independent samples of random points taken from the uniform distribution , with the number of points per sample varying according to the poisson distribution , the rank of the covariance matrix of the fitted unnormalized density values calculated over these samples equals the degree of the fitted polynomial plus one .",
    "this is precisely the number of parameters of the fitted model . it does not matter how many abscissae are used to construct the covariance matrix of the fitted values as long as the number of abscissae exceeds the degree of the polynomial and the average number of points in the samples is `` large enough '' . while the model fitted to the observed values by various unfolding procedures is not polynomial , some measure of the rank of @xmath86 can still be identified with the number of model parameters .",
    "the  effective rank of a symmetric positive - semidefinite matrix ( say , * q * ) can be estimated in at least two different ways .",
    "the first one is the exponent of the von neumann entropy  @xcite of @xmath87 . in terms of the @xmath88 eigenvalues , @xmath89 ,",
    "it is expressed as is also the exponent of the shannon entropy of the normalized eigenspectrum . ]",
    "@xmath90 the second definition finds the ratio of the matrix trace to the largest eigenvalue  @xcite : @xmath91 it is not obvious _ a priori _ which effective rank definition will lead to better practical results for different regularization strength selection criteria . this method of calculating the effective number of parameters in the fit can be applied in any unfolding procedure that supplies the matrix for propagating errors from the observed data to the unfolded values .",
    "it should be noted that the effective number of fitted parameters can be overestimated in case the bins in the observation space are only sparsely populated .",
    "a possible adjustment of the method that can be applied in such cases is discussed in section  [ sec : adaptiveregularization ] .",
    "for likelihood - based inference , a useful model selection principle is provided by the akaike information criterion ( aic )  @xcite .",
    "the aic adjusted for the finite sample size is  @xcite @xmath92 where @xmath93 is the model likelihood , @xmath45 is the sample size , and @xmath40 the number of parameters in the model . selecting a model by minimizing @xmath94 avoids overfitting by reaching a compromise between complexity of the model and goodness - of - fit . on the use of aic in density estimation scenarios without deconvolution consult , for example ,",
    "@xcite .    with",
    "the number of model parameters estimated by the method presented in the previous section , application of the @xmath94 to the ems unfolding procedure is straightforward .",
    "the likelihood is calculated in the assumption of poisson distributed counts with means given by @xmath84 .",
    "if , for a  one - dimensional unfolding problem , the smoothing matrix is constructed utilizing a  typical spatial bandwidth parameter @xmath95 then , for small @xmath95 , @xmath96 represents the effective number of independent intervals in the support of @xmath26 . in the absence of smoothing",
    ", the likelihood tends to a constant value obtained with the poisson means derived by iterating eq .",
    "[ eq : nosmooth ] to convergence .",
    "therefore , for small values of @xmath95 , @xmath94 is a  decreasing function of @xmath95 . at the same time ,",
    "decrease in @xmath40 is not so pronounced for larger values of @xmath95 while the likelihood is rapidly diminishing when @xmath95 becomes comparable with the typical spatial scale of the response function .",
    "combined together , these dependencies result in the @xmath94 behavior which exhibits a minimum at some value of @xmath95 .    the @xmath94 criteria that correspond to the two different definitions of the effective rank will be called @xmath97 ( @xmath98 in this abbreviation stands for `` entropic '' ) and @xmath99 ( @xmath100 stands for `` trace '' ) .",
    "one of these criteria can be optimized as a  function of the bandwidth parameter(s ) used to construct the smoothing matrix .",
    "use of an effective rank to determine the number of model parameters leads to the requirement that the number of discretization cells in the observation space @xmath4 should be substantially larger than this rank .",
    "this condition should be verified once the unfolding is performed with the optimal smoother .",
    "data - dependent choice of regularization parameters introduces an  additional uncertainty on the unfolded results due to the variability of these parameters .",
    "while this uncertainty remains a  subject of recent  @xcite and , potentially , future studies , use of an automated criterion represents a  substantial improvement upon the subjective choice of regularization strength widespread in the current unfolding practice in particle physics .",
    "the concepts and the formulae discussed in the preceding sections are illustrated with two examples .",
    "the first example density consists of two gaussian peaks combined with the uniform distribution : @xmath101 .",
    "@xmath102 stands for the uniform distribution on the interval @xmath103 $ ] .",
    "the support of this distribution mixture is restricted to the interval @xmath104 $ ] in the physical process space , truncating small fractions of the gaussian tails outside of this interval . the response function for this example",
    "is @xmath105 .",
    "this simulation setup was used previously to investigate performance of a  different unfolding technique  @xcite . the density used in this example",
    "is illustrated in fig .",
    "[ fig : density1 ] , together with the corresponding density @xmath106 for the observed data .",
    "the second density is a pareto distribution restricted to the interval @xmath107 $ ] : @xmath108 . in this case , the response function is chosen as @xmath109 .",
    "this example emulates a differential cross section measurement of jet production in proton - proton collisions , @xmath110 , with jet transverse momentum resolution @xmath111 .",
    "densities for this example are shown in fig .",
    "[ fig : density2 ] . for both examples ,",
    "the observed space is limited to the same interval as the physical process space in order to illustrate effects of imperfect detection efficiency and to simplify plotting .",
    "points are drawn at random from the example densities in the physical process space , and additional random shifts are added to the point coordinates by sampling the respective response functions . in order to unfold the first example density",
    ", the space of observations is discretized into 100 uniformly spaced bins .",
    "the physical process space is split into 420 bins , so that the standard deviation of the response function is 30 times larger than the bin width . for the second example",
    ", the bin width is taken to be proportional to the width of the response function ( _ i.e. _ , the binning is uniform in the @xmath112 variable ) . with 1000 bins in the physical process space ,",
    "the response is @xmath113  times wider than the bins .",
    "the same binning scheme ( uniform in @xmath114 ) is used for the observed data , with 200 bins .    for the purpose of this study ,",
    "the smoothing matrix is generated by discretizing the green s function of the homogeneous heat equation in one dimension with neumann boundary conditions ( _ i.e. _ , with boundaries not permeable to the heat transfer ) .",
    "this function is fully determined by a  single parameter : product of time , @xmath115 , and thermal diffusivity , @xmath116 . for the convenience of presentation ,",
    "the bandwidth parameter @xmath95 used in this study is the standard deviation of the green s function far away from the density support boundaries : @xmath117 . on the @xmath118 $ ] interval , this function is given by , these series are better suited for numerical evaluation than the mathematically equivalent trigonometric series derived by separation of variables . ]",
    "@xmath119 $ ] with @xmath120 $ ] .",
    "this function is illustrated in fig .",
    "[ fig : gf ] . for an arbitrary interval",
    "@xmath103 $ ] , the green s function values can be obtained by appropriate shifting and scaling of its arguments , including the bandwidth .",
    "the @xmath121 variable maps to the row number of the smoothing matrix while @xmath122 maps to the column number .",
    "multiplication of the smoothing matrix by a  vector in the discretized physical process space thus approximates the integral @xmath123 .    as @xmath124 ,",
    "the smoothing matrix constructed in this manner is doubly stochastic .",
    "all of its eigenvalues belong to the @xmath118 $ ] interval which guarantees convergence of the ems unfolding iterations . for the second example density ,",
    "@xmath112 is used in place of the green s function arguments @xmath121 and @xmath122 , so that the characteristic bandwidth of the smoothing matrix is increasing concordantly with the response function resolution .",
    "both the smoothing matrix construction and the subsequent ems unfolding are performed with the aid of the npstat software package  @xcite .",
    "on @xmath121 for bandwidth @xmath125 and three different values of @xmath122 indicated in the vertical axis labels ( @xmath122 at the boundary , not far from the boundary , and at the interval center ) . for illustration purposes , in these plots",
    "the ratio of @xmath95 to the length of the @xmath126 interval is significantly larger than the typical ratios employed in the unfolding examples .",
    "individual elements of the smoothing matrix are obtained by integrating @xmath127 over the corresponding discretization cells @xmath128.,title=\"fig : \" ]   on @xmath121 for bandwidth @xmath125 and three different values of @xmath122 indicated in the vertical axis labels ( @xmath122 at the boundary , not far from the boundary , and at the interval center ) . for illustration purposes , in these plots",
    "the ratio of @xmath95 to the length of the @xmath126 interval is significantly larger than the typical ratios employed in the unfolding examples .",
    "individual elements of the smoothing matrix are obtained by integrating @xmath127 over the corresponding discretization cells @xmath128.,title=\"fig : \" ]   on @xmath121 for bandwidth @xmath125 and three different values of @xmath122 indicated in the vertical axis labels ( @xmath122 at the boundary , not far from the boundary , and at the interval center ) . for illustration purposes , in these plots",
    "the ratio of @xmath95 to the length of the @xmath126 interval is significantly larger than the typical ratios employed in the unfolding examples .",
    "individual elements of the smoothing matrix are obtained by integrating @xmath127 over the corresponding discretization cells @xmath128.,title=\"fig : \" ]    example unfolded results for random samples containing 10,000 simulated observations each are shown in fig .",
    "[ fig : unfexample ] . in this figure ,",
    "the unfolded densities are compared with the corresponding physical process densities processed by the respective smoothing matrices",
    ".     stands for `` smoothed '' .",
    "the smoothing matrix bandwidth is @xmath129 for the plot on the left ( the first model ) and @xmath130 in the @xmath112 space for the plot on the right ( the second model ) .",
    "the filled black regions correspond to @xmath131 standard deviation interval estimates .",
    "poisson uncertainties on the observed event counts are propagated to the unfolded results according to eqs .",
    "[ eq : errprop ] and  [ eq : covmat ] .",
    "it is apparent that , for the second model , the event sample size is insufficient to reconstruct the density reliably at large values of @xmath132.,title=\"fig : \" ]   stands for `` smoothed '' .",
    "the smoothing matrix bandwidth is @xmath129 for the plot on the left ( the first model ) and @xmath130 in the @xmath112 space for the plot on the right ( the second model ) .",
    "the filled black regions correspond to @xmath131 standard deviation interval estimates .",
    "poisson uncertainties on the observed event counts are propagated to the unfolded results according to eqs .",
    "[ eq : errprop ] and  [ eq : covmat ] .",
    "it is apparent that , for the second model , the event sample size is insufficient to reconstruct the density reliably at large values of @xmath132.,title=\"fig : \" ]    in the simulation studies presented in this manuscript , ems unfolding iterations are declared converged upon reaching the iteration number @xmath133 satisfying the condition @xmath134 , where @xmath78 is the number of cells in the discretization of @xmath132 space , and @xmath135 .",
    "this condition results in a  typical relative difference between @xmath39 and @xmath58 of the order @xmath136 .",
    "this value of @xmath136 is chosen so that the relative precision of @xmath137 evaluation ( which is on the order of @xmath138 ) is substantially better than @xmath139 for all sample sizes considered .",
    "the dependence of the number of iterations needed for convergence on the smoothing matrix bandwidth is illustrated in fig .",
    "[ fig : niter ] .",
    "note that , for an  implementation of the ems unfolding algorithm utilizing dense matrices , the computational complexity of each iteration is @xmath140 while the computational complexity of solving eq .",
    "[ eq : errprop ] is @xmath141 .",
    "therefore , the iterative stage dominates the computation time only for very small bandwidth values .",
    ", on the smoothing matrix bandwidth for the first example distribution .",
    "1,000 points per sample were generated on average .",
    "right : the same dependence for the second example distribution , with 10,000 points per sample on average .",
    "the number of iterations does not change appreciably from one simulated sample to another , so standard deviations would not be visible in these plots .",
    "the decrease in @xmath142 with increasing @xmath95 is in qualitative agreement with the discussions of ems convergence rates in  @xcite.,title=\"fig : \" ] , on the smoothing matrix bandwidth for the first example distribution .",
    "1,000 points per sample were generated on average .",
    "right : the same dependence for the second example distribution , with 10,000 points per sample on average .",
    "the number of iterations does not change appreciably from one simulated sample to another , so standard deviations would not be visible in these plots .",
    "the decrease in @xmath142 with increasing @xmath95 is in qualitative agreement with the discussions of ems convergence rates in  @xcite.,title=\"fig : \" ]      for the coverage studies presented in this article , the total sample counts are allowed to fluctuate according to the poisson distribution with averages described in the text or in the figure captions .",
    "the number of points actually generated is larger ( on average , by factor @xmath143 ) because only the points that end up inside the observation intervals after the addition of random shifts are counted .",
    "example densities processed by the smoothing matrix are used as references in coverage calculations without bias correction ( after bias correction the reference no longer matters ) .",
    "the pointwise frequentist coverage of the ems unfolding method is illustrated in figs .",
    "[ fig : coverage1 ] and  [ fig : coverage2 ] for density estimation performed with fixed regularization strength .",
    "the expected frequentist coverage of 68.3% by @xmath131 standard deviation intervals is recovered after correcting for the unfolding bias , @xmath144 .",
    "bias is defined as the average difference between the unfolded result and the unnormalized physical process density filtered by the smoothing matrix .",
    "its dependence on @xmath132 is illustrated in fig .",
    "[ fig : bias ] for the example densities .",
    "it is worth emphasizing that bias correction of this kind can be used to validate covariance matrix estimates in simulation studies but can not be performed when the process density is not known in advance .",
    "according to the binomial statistical uncertainty of the coverage determination method . for the plot on the left , the bias correction is not performed .",
    "the smoothing matrix bandwidth is fixed at @xmath129 .",
    "the red line is drawn at 68.3%.,title=\"fig : \" ]   according to the binomial statistical uncertainty of the coverage determination method . for the plot on the left",
    ", the bias correction is not performed .",
    "the smoothing matrix bandwidth is fixed at @xmath129 .",
    "the red line is drawn at 68.3%.,title=\"fig : \" ]     in the @xmath112 space .",
    "degradation of frequentist coverage above @xmath145 is due to the breakdown of the linear error propagation approximation for small samples .",
    "the fraction of the second example distribution in the @xmath146 region is 0.16%.,title=\"fig : \" ]   in the @xmath112 space .",
    "degradation of frequentist coverage above @xmath145 is due to the breakdown of the linear error propagation approximation for small samples .",
    "the fraction of the second example distribution in the @xmath146 region is 0.16%.,title=\"fig : \" ]        for the example densities under study , the component of the unfolding bias that belongs to the effective nullspace of the response function is illustrated in fig .",
    "[ fig : nullspacebias ] .",
    "this component is , in some sense , irreducible  information about it is destroyed and can not be recovered without introducing further assumptions beyond those needed to regularize the problem .",
    "the irreducible bias is inherent in all unfolding procedures and can be viewed as an argument against using unfolding methods in the data analysis practice .",
    "comparison of theoretical predictions with experimental results in the observation space avoids this issue altogether .",
    "however , due to the complexity and uniqueness of large particle physics experiments , realistic response functions are not exactly known , and standards for developing and publishing response functions together with their uncertainties have not been established yet .    . to make these plots , the response function singular values were considered `` small '' if their ratios to the largest singular value did not exceed @xmath147 .",
    "this approximate cutoff is of the order @xmath138.,title=\"fig : \" ] . to make these plots , the response function singular values were considered `` small '' if their ratios to the largest singular value did not exceed @xmath147 .",
    "this approximate cutoff is of the order @xmath138.,title=\"fig : \" ]    as the expectation - maximization unfolding procedure is nonlinear , the frequentist uncertainty coverage is also affected by the fidelity of the linear error propagation approximation .",
    "the breakdown of this approximation at high values of @xmath132 for the second model is apparent from fig .",
    "[ fig : coverage2 ] .",
    "the effect of the sample size , @xmath45 , on the first model is illustrated in fig .",
    "[ fig : covdegrade ] .",
    "the difference between gaussian and poisson distributions becomes more pronounced for smaller values of @xmath45 , and the influence of nonlinearities in the unfolding procedure is increased for smaller samples due to the increase in the relative statistical uncertainty of the observation counts .",
    "points on average per sample ( left ) and with @xmath148 points ( right ) .",
    "the smoothing matrix bandwidth is set to 0.2 for the left plot and to 0.8 for the right plot.,title=\"fig : \" ]   points on average per sample ( left ) and with @xmath148 points ( right ) .",
    "the smoothing matrix bandwidth is set to 0.2 for the left plot and to 0.8 for the right plot.,title=\"fig : \" ]      for the ems unfolding examples considered in this section , the regularization strength is defined by the smoothing matrix bandwidth . as the bandwidth is increasing , the variance of the unfolded result is decreasing at the cost of increase in the bias with respect to the true density . the optimal tradeoff between the bias and the variance will , in general , depend on the manner in which the unfolded results are to be used .",
    "if the results are to be compared with model distributions lacking high frequency components then larger bandwidth values may be preferred , as the variance is reduced without loosing relevant information . on the other hand ,",
    "a  reduction in bandwidth may be beneficial if the results are to be searched for sharp peaks .",
    "it should also be noted that , although the width of the smoothing matrix is proportional to the width of the response function everywhere in @xmath132 for the examples considered in this section , other schemes of constructing the smoothing matrix can be envisioned , possibly along the lines of variable - bandwidth kernel density estimation techniques  @xcite .    while the most relevant distance measure between a normalized density function , @xmath26 , and its estimate , @xmath149 , will be application - dependent , a simple and convenient distance is given by the integrated squared error : @xmath150 .",
    "it may also be interesting to consider the smoothed ise ( sise ) in which the original density is processed by the smoothing matrix before comparison with the estimate .",
    "the mean integrated squared error ( mise ) and the mean smoothed ise ( msise ) are , respectively , the ise and the sise averaged over many simulated samples .",
    "the dependence of mise and msise on the smoothing matrix bandwidth is illustrated in fig .",
    "[ fig : mise ] for the example densities considered .",
    "the distributions of bandwidth values selected by the @xmath94 criteria are shown in fig .",
    "[ fig : bwdistro ] , and the corresponding distributions of the effective number of model parameters used to fit simulated observations are presented in fig .",
    "[ fig : effparams ] .     criteria for the first example distribution . 2000 samples are used , with 1,000 points per sample on average .",
    "right : bandwidth selected for the second example distribution .",
    "2000 samples , 10,000 points per sample .",
    "it appears that for both distributions there is no substantial difference between bandwidth values selected by @xmath97 and @xmath99.,title=\"fig : \" ]   criteria for the first example distribution .",
    "2000 samples are used , with 1,000 points per sample on average .",
    "right : bandwidth selected for the second example distribution .",
    "2000 samples , 10,000 points per sample .",
    "it appears that for both distributions there is no substantial difference between bandwidth values selected by @xmath97 and @xmath99.,title=\"fig : \" ]     and @xmath151 values ( calculated , respectively , according to eqs .",
    "[ eq : erank1 ] and  [ eq : erank2 ] ) are substantially different , the corresponding @xmath94 criteria depend not on the values themselves but rather on their derivatives with respect to the bandwidth.,title=\"fig : \" ]   and @xmath151 values ( calculated , respectively , according to eqs .",
    "[ eq : erank1 ] and  [ eq : erank2 ] ) are substantially different , the corresponding @xmath94 criteria depend not on the values themselves but rather on their derivatives with respect to the bandwidth.,title=\"fig : \" ]    for the first example density ( plots on the left ) , the bandwidth value chosen by @xmath94 is , on average , consistent with the bandwidth that would be selected on the basis of mise . for the second example , bandwidth choice based on @xmath94 results in substantial oversmoothing . due to a significant fraction of empty bins in the observation space ( 57.8% on average for @xmath152 ) , for this example the effective number of parameters in the fit",
    "is overestimated . as this number is monotonously decreasing as a function of bandwidth , its overestimation results in the shift of the @xmath94 minimum towards increased bandwidth values .    a simple method of mitigating the effect of sparsely populated bins consists in scaling the effective number of fitted parameters by the fraction of populated bins in the observed data . for a known density",
    ", one can simply eliminate the lowest probability bins whose combined probability content does not exceed a  threshold of the order @xmath139 . the optimal way to proceed without such an _",
    "a priori _ knowledge is not obvious . for example",
    ", the simple approach proposed in the text breaks down in case the number of bins gets so large that the bin width becomes comparable with the typical distance between two neighboring sample points . ] .",
    "distributions of bandwidth values selected by the @xmath94 criteria with this scaling are presented in fig .",
    "[ fig : corrparams ] for the second example density .",
    "this adjustment significantly improves the mise - based bandwidth selection performance of @xmath94 .",
    "mise and a few other useful characteristics of the ems unfolding method are summarized in table  [ tab : effparam ] for several sample sizes .",
    "criteria for the second example after correcting for sparsely populated bins .",
    "the starting pile - up of bandwidth values at @xmath153 is due to the fact that the smallest bandwidth value considered was set to the width of one bin in the discretized physical process space.,title=\"fig : \" ]   criteria for the second example after correcting for sparsely populated bins .",
    "the starting pile - up of bandwidth values at @xmath153 is due to the fact that the smallest bandwidth value considered was set to the width of one bin in the discretized physical process space.,title=\"fig : \" ]    .summary of the ems unfolding performance for samples of average size @xmath45 drawn from the example densities . for @xmath154",
    ", the number of bins in the discretization of both @xmath132 and @xmath155 spaces was increased .",
    "@xmath95 is the smoothing matrix bandwidth selected by @xmath97 .",
    "@xmath156 is the effective number of model parameters calculated according to eq .",
    "[ eq : erank1 ] . for the second example density",
    ", @xmath156 is adjusted for sparsely populated bins .",
    "@xmath157 is the number of principal components of the result covariance matrix with frequentist coverage above 61.4% ( _ i.e. _ , at least 0.9 of the expected 68.3% ) , determined with a bandwidth - dependent bias correction .",
    "the principal component coverage is discussed further in section  [ sec : resultpresent ] .",
    "values given for each example in the first four rows represent the medians of the corresponding distributions and the ranges that cover 68.3% of the samples . [ cols=\"^,<,^,^,^\",options=\"header \" , ]     the bias - corrected pointwise frequentist coverage of the uncertainty estimated according to eq .",
    "[ eq : covmat ] is shown in fig .",
    "[ fig : eaiccoverage ] .",
    "( without adjustment for sparsely populated bins ) .",
    "the bias is corrected by subtracting a  single average curve from all unfolded results . on average , 1,000 points per sample are used for the first model ( left plot ) and 10,000 points per sample are used for the second model ( right plot).,title=\"fig : \" ]   ( without adjustment for sparsely populated bins ) .",
    "the bias is corrected by subtracting a  single average curve from all unfolded results . on average , 1,000 points per sample are used for the first model ( left plot ) and 10,000 points per sample are used for the second model ( right plot).,title=\"fig : \" ]    the effect of coverage reduction due to the data - dependent choice of the regularization strength ( _ i.e. _ , the bandwidth ) is apparent .",
    "the increase in the uncertainty can be attributed to the dependence of the unfolding bias on the bandwidth .",
    "this dependence is illustrated in fig .",
    "[ fig : bwdependentbias ] .",
    "the coverage can be restored almost fully by subtracting , for each simulated sample , the bias curve conditioned upon the bandwidth value used to unfold the sample .",
    "the effect of this conditional bias correction is shown in fig .",
    "[ fig : eaicbwdependent ] .    .",
    "this deterioration can be attributed to the assumption that @xmath76 is fixed in the derivation of the error propagation formula ( i.e. , eq .",
    "[ eq : errprop ] ) . with the data - dependent choice of bandwidth",
    ", this assumption is no longer valid.,title=\"fig : \" ] .",
    "this deterioration can be attributed to the assumption that @xmath76 is fixed in the derivation of the error propagation formula ( i.e. , eq .",
    "[ eq : errprop ] ) . with the data - dependent choice of bandwidth , this assumption is no longer valid.,title=\"fig : \" ]    in realistic data analysis scenarios , dependence of the unfolding bias on the regularization strength is not known _ a priori _ , and the uncertainty must be adjusted by other means . a promising but computationally intensive approach",
    "consists in evaluating the uncertainty by simulations  @xcite . by analogy with a similar statistical technique utilized without deconvolution  @xcite , its application to ems unfolding will be called `` folded smoothed bootstrap '' . in this method ,",
    "the estimate of the density of the observed data , @xmath158 , is derived from the unfolded result , @xmath149 , according to eq .",
    "[ eq : kernelaction ] .",
    "@xmath158 is then sampled repeatedly , and all these samples are in turn unfolded so that a collection of secondary unfolded results , @xmath159 , is generated .",
    "the result covariance matrix is estimated from this collection , possibly utilizing robust techniques  @xcite .",
    "it has also been suggested that the difference between the @xmath159 mean and @xmath149 could be used to estimate the unfolding bias  @xcite .",
    "the pointwise frequentist coverage of the uncertainties obtained for the example distributions by the folded smoothed bootstrap method with different bias correction schemes is presented in figs .",
    "[ fig : bootstrapcoverage1 ] and  [ fig : bootstrapcoverage2 ] .",
    "the regularization strength is chosen by @xmath97 .",
    "it appears that the method provides an  acceptable estimate of the variance .",
    "however , the utility of obtaining the bias correction from the bootstrap remains questionable .",
    "in fact , such a bias correction introduces an additional source of variability into the unfolding procedure and , for densities under consideration , leads to a  noticeable overall reduction in coverage .",
    "points per sample ) and the second distribution is on the right ( @xmath152 ) .",
    "1,000 bootstrapped replicas are generated for each unfolded result .",
    "for each bin of each sample , the uncertainty is defined as half of the difference between 84.13@xmath41 and 15.87@xmath41 percentiles of unfolded replica results in that bin ( using asymmetric uncertainties makes virtually no difference ) . for the top plots , bias correction was not performed .",
    "the plots at the bottom were made by subtracting the known bandwidth - dependent bias , as in fig .",
    "[ fig : eaicbwdependent ] , which leads to reasonable coverage properties.,title=\"fig : \" ]   points per sample ) and the second distribution is on the right ( @xmath152 ) .",
    "1,000 bootstrapped replicas are generated for each unfolded result .",
    "for each bin of each sample , the uncertainty is defined as half of the difference between 84.13@xmath41 and 15.87@xmath41 percentiles of unfolded replica results in that bin ( using asymmetric uncertainties makes virtually no difference ) . for the top plots ,",
    "bias correction was not performed .",
    "the plots at the bottom were made by subtracting the known bandwidth - dependent bias , as in fig .",
    "[ fig : eaicbwdependent ] , which leads to reasonable coverage properties.,title=\"fig : \" ]   points per sample ) and the second distribution is on the right ( @xmath152 ) .",
    "1,000 bootstrapped replicas are generated for each unfolded result .",
    "for each bin of each sample , the uncertainty is defined as half of the difference between 84.13@xmath41 and 15.87@xmath41 percentiles of unfolded replica results in that bin ( using asymmetric uncertainties makes virtually no difference ) . for the top plots ,",
    "bias correction was not performed .",
    "the plots at the bottom were made by subtracting the known bandwidth - dependent bias , as in fig .",
    "[ fig : eaicbwdependent ] , which leads to reasonable coverage properties.,title=\"fig : \" ]   points per sample ) and the second distribution is on the right ( @xmath152 ) .",
    "1,000 bootstrapped replicas are generated for each unfolded result .",
    "for each bin of each sample , the uncertainty is defined as half of the difference between 84.13@xmath41 and 15.87@xmath41 percentiles of unfolded replica results in that bin ( using asymmetric uncertainties makes virtually no difference ) . for the top plots ,",
    "bias correction was not performed .",
    "the plots at the bottom were made by subtracting the known bandwidth - dependent bias , as in fig .",
    "[ fig : eaicbwdependent ] , which leads to reasonable coverage properties.,title=\"fig : \" ]     mean and @xmath149 . for the plots at the bottom",
    ", the bias is conditioned upon the smoothing matrix bandwidth chosen by @xmath97 for the primary sample .",
    "additional unfolding is performed , with that bandwidth value only , for the same bootstrap replicas .",
    "the additional results are averaged and used in place of @xmath159 to define the bias .",
    "the estimate of the variance still comes from the unfolding of the replicas with adaptive regularization strength.,title=\"fig : \" ]   mean and @xmath149 . for the plots at the bottom",
    ", the bias is conditioned upon the smoothing matrix bandwidth chosen by @xmath97 for the primary sample .",
    "additional unfolding is performed , with that bandwidth value only , for the same bootstrap replicas .",
    "the additional results are averaged and used in place of @xmath159 to define the bias .",
    "the estimate of the variance still comes from the unfolding of the replicas with adaptive regularization strength.,title=\"fig : \" ]   mean and @xmath149 . for the plots at the bottom",
    ", the bias is conditioned upon the smoothing matrix bandwidth chosen by @xmath97 for the primary sample .",
    "additional unfolding is performed , with that bandwidth value only , for the same bootstrap replicas .",
    "the additional results are averaged and used in place of @xmath159 to define the bias .",
    "the estimate of the variance still comes from the unfolding of the replicas with adaptive regularization strength.,title=\"fig : \" ]   mean and @xmath149 . for the plots at the bottom",
    ", the bias is conditioned upon the smoothing matrix bandwidth chosen by @xmath97 for the primary sample .",
    "additional unfolding is performed , with that bandwidth value only , for the same bootstrap replicas .",
    "the additional results are averaged and used in place of @xmath159 to define the bias .",
    "the estimate of the variance still comes from the unfolding of the replicas with adaptive regularization strength.,title=\"fig : \" ]",
    "the uncertainties of the unfolded results can be presented in a  convenient form by utilizing the principal component analysis  @xcite of the result covariance matrix .",
    "discretization of the physical process space with a large number of bins avoids the dependence of the response function ( and , consequently , of the unfolded result ) on the behavior of the physical process density inside each bin . at the same time",
    ", information content of large covariance matrices becomes an  important issue that needs to be explicitly addressed .    according to the cramer-rao bound , for unbiased estimators the largest amount of information",
    "is associated with the smallest covariance matrix eigenvalues .",
    "the eigenvalue spectrum of the covariance matrices of the unfolded results obtained with the simulations described in the previous section is shown in fig .  [ fig : eigenspectrum ] .",
    "the spectrum decays quickly , so the amount of information associated with the covariance matrices appears to be disproportionately large .",
    "this effect , however , is a  consequence of defining the covariance matrix for the complete set of @xmath78 parameters @xmath58 using a model with a substantially lower effective number of parameters .",
    "regularization ( by smoothing , as in the ems unfolding , or by other techniques ) suppresses high frequency components of the unfolded result , thus preventing unbiased estimation of these components .",
    "variance of a  biased estimator is no longer subject to the cramer-rao bound , while the lack of coverage after bias correction can be attributed to the imperfections of the linear error propagation approximation . on the other hand , for sufficiently smooth densities",
    ", reasonable pointwise bias - corrected coverage is attained because the combined variance of high frequency components is substantially smaller than the variance of low frequency components not affected by regularization .    for the example densities considered in the previous section , frequentist coverage of the covariance matrix principal components",
    "is illustrated in figs .",
    "[ fig : eigencoverage ] and  [ fig : biasedeigencoverage ] . to construct these figures ,",
    "the principal components of the covariance matrix returned by the unfolding procedure for each simulated sample were arranged in the order of decreasing eigenvalues .",
    "this ordering determined the `` eigenvector number '' represented by the horizontal axes on the plots .",
    "the difference between the unfolded result ( bias - corrected in case of fig .",
    "[ fig : eigencoverage ] ) and the known `` true '' density processed by the smoothing matrix was decomposed using the basis provided by the normalized eigenvectors .",
    "the components of the difference in this basis were divided by their estimated standard deviations ( _ i.e. _ , square roots of the corresponding eigenvalues ) .",
    "the ratios with the same eigenvector number were grouped together , and the fraction of the samples falling inside the @xmath160 $ ] interval was determined for the resulting distributions .    .",
    "the plot for the second example density is on the right , with @xmath152 . for both examples ,",
    "the smoothing matrix bandwidth is chosen by @xmath97 ( same procedure as in fig .",
    "[ fig : eaicbwdependent ] ) . before averaging ,",
    "eigenvalues are sorted in the decreasing order and divided by the largest one . for the left plot ,",
    "covariance matrix dimensions are @xmath161 , so only about 1/10@xmath41 of the complete eigenspectrum is shown .",
    "for the right plot , matrix dimensions are @xmath162 .",
    "three parts can be visibly discerned in each spectrum : the structure of the largest eigenvalues ( the left side of the curve ) is dominated by the covariance matrix of the signal density , sampling noise determines the middle part of the spectrum , and the onset of the numerical round - off noise is apparent on the right.,title=\"fig : \" ] .",
    "the plot for the second example density is on the right , with @xmath152 . for both examples ,",
    "the smoothing matrix bandwidth is chosen by @xmath97 ( same procedure as in fig .",
    "[ fig : eaicbwdependent ] ) . before averaging ,",
    "eigenvalues are sorted in the decreasing order and divided by the largest one . for the left plot ,",
    "covariance matrix dimensions are @xmath161 , so only about 1/10@xmath41 of the complete eigenspectrum is shown .",
    "for the right plot , matrix dimensions are @xmath162 .",
    "three parts can be visibly discerned in each spectrum : the structure of the largest eigenvalues ( the left side of the curve ) is dominated by the covariance matrix of the signal density , sampling noise determines the middle part of the spectrum , and the onset of the numerical round - off noise is apparent on the right.,title=\"fig : \" ]     and  [ fig : eigenspectrum].,title=\"fig : \" ]   and  [ fig : eigenspectrum].,title=\"fig : \" ]    .",
    "there , the section with poor coverage coincides with the most populous region in the support of the density.,title=\"fig : \" ] .",
    "there , the section with poor coverage coincides with the most populous region in the support of the density.,title=\"fig : \" ]    the lack of coverage by the principal components of the covariance matrix is also expected for the unfolding procedures that utilize _ ad hoc _ binning .",
    "the author , therefore , suggests that statistical uncertainties of data analysis results obtained with unfolding procedures should be presented by publishing , electronically , the eigenvalues and the corresponding eigenvectors of the result covariance matrix that are expected to possess proper frequentist coverage in the assumption that the procedure is unbiased .",
    "table  [ tab : effparam ] hints that , in addition to the eigenspectrum shape , the effective number of model parameters corresponding to the @xmath94-selected bandwidth might be instrumental in predicting how many principal components of the result covariance matrix will have appropriate coverage",
    ". the rest of the statistical uncertainty should be bundled together into a  single `` overflow '' set encompassing the orthogonal complement of these components .",
    "the formal variance of this set is simply the difference between the trace of the result covariance matrix and the sum of the eigenvalues for the principal components that have been specified explicitly .",
    "however , proper frequentist coverage for this set is not guaranteed .",
    "such a decomposition of experimental uncertainty will provide specific diagnostic information during comparisons of theoretical models with unfolded results , will be instrumental in tuning model parameters , and will avoid spurious rejection of models due to inadequate coverage .",
    "due to a significant amount of arbitrariness associated with the choice of regularization method and strength , attaining correct frequentist coverage is difficult for the unfolding procedures most commonly employed in the particle physics data analysis practice .",
    "use of wide bins in the physical process space leads to a hard - to - quantify dependence of the discretized response function on the assumed process density inside each bin .",
    "the automated regularization optimization technique developed in this article addresses several methodological issues in unfolding applications .",
    "it permits a  fine - grained discretization of the physical process space and enables the use of precise response functions not affected by prior distribution assumptions .",
    "the choice of the regularization strength is based on a  well - established model selection criterion .",
    "the empirical success of this regularization choice and the expected frequentist coverage of the resulting unfolding procedure are validated by simulations .",
    "the software package implementing this type of unfolding is freely available  @xcite .",
    "the proposed presentation of uncertainties is based on the expected coverage of the covariance matrix principal components and offers a  considerable improvement upon the common practice of providing just the diagonal elements of the covariance matrix .",
    "accounting for the unfolding bias , and especially for the part of the bias that belongs to the nullspace of the response function , remains a difficult problem .",
    "it is unclear whether this issue could be adequately resolved within the unfolding paradigm .",
    "the ultimate solution will consist in developing a standard for publishing experimental response functions for particle detector systems , so that theory predictions could be compared with experimental spectra in the space of observations .",
    "the author thanks gnter zech and the statistics committee of the cms collaboration for comments and productive discussions .",
    "this work was supported in part by the united states department of energy grant de - fg02 - 12er41840 .",
    "h.b .  prosper and l.  lyons ( eds . ) , `` proceedings of the phystat 2011 workshop on statistical issues related to discovery claims in search experiments and unfolding , cern , geneva , switzerland 17 - 20 january 2011 '' , https://cdsweb.cern.ch/record/1306523/files/cern-2011-006.pdf[cern-2011-006 ] ( 2011 ) .",
    ", `` a smoothed em approach to indirect estimation problems , with particular reference to stereology and emission tomography '' , _ journal of the royal statistical society b _ * 52 * , 271 ( 1990 ) .",
    "r. vershynin , `` introduction to the non - asymptotic analysis of random matrices '' , in y.  eldar and g.  kutyniok ( eds . ) , `` compressed sensing , theory and applications '' , cambridge university press ( 2012 ) .",
    "den haan and a. levin , `` a practitioner s guide to robust covariance matrix estimation '' , in `` handbook of statistics 15 : robust inference '' , g.s .",
    "maddala and c.r .",
    "rao ( eds . ) , elsevier science ( 1997 ) ."
  ],
  "abstract_text": [
    "<S> error propagation formulae are derived for the expectation - maximization iterative unfolding algorithm regularized by a smoothing step . </S>",
    "<S> the effective number of parameters in the fit to the observed data is defined for unfolding procedures . based upon this definition , </S>",
    "<S> the akaike information criterion is proposed as a principle for choosing the smoothing parameters in an  automatic , data - dependent manner . </S>",
    "<S> the performance and the frequentist coverage of the resulting method are investigated using simulated samples . </S>",
    "<S> a number of issues of general relevance to all unfolding techniques are discussed , including irreducible bias , uncertainty increase due to a  data - dependent choice of regularization strength , and presentation of results . </S>"
  ]
}