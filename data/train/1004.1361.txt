{
  "article_text": [
    "master equations are a convenient tool to treat stochastic markov processes@xcite . in some cases ,",
    "they offer an alternative approach to the chapman - kolmogorov equation and have been used extensively in discrete - jumps , or birth - death , processes , such as chemical reactions ( including those happening inside a cell ) , population dynamics or other ecology problems@xcite , opinion formation and cultural transmission in the field of sociophysics@xcite , etc . in all these cases ,",
    "it is important to consider that the population number ( whether molecules , individuals , agents , etc . )",
    "might not be very large ( maybe ranging in the tens or hundreds ) and the fluctuations , that typically scale as the square root of the inverse of this number , can not be considered as negligible .",
    "it is therefore , of the greatest importance to derive evolution equations for the average behavior and the fluctuations .",
    "the important work by van kampen@xcite offers a systematic way of deriving these equations from an expansion of the master equation in a parameter @xmath0 , typically the system volume .",
    "the @xmath0-expansion is mostly used in its lowest order form , in which one can prove that the error in the average value , the second moment and the fluctuations ( the variance ) , scale at most as @xmath1 , @xmath2 and @xmath3 , respectively .",
    "the van kampen @xmath0-expansion , furthermore , shows that , at this lowest order , the fluctuations follow a gaussian distribution . in this paper",
    ", we take this result of van kampen s theory and , considering from the very beginning that fluctuations are gaussian , we derive a closed system of equations for the average value and the second moment .",
    "this gaussian closure of the hierarchy of moments turns out to be more accurate that the @xmath0-expansion as the above - mentioned errors scale at most as @xmath4 , @xmath3 and @xmath3 , respectively .",
    "furthermore , the gaussian closure scheme is very simple to carry on in practice and can be easily generalized to systems described by more than one variable .",
    "the paper is organized as follows : in the following section , we will briefly review the @xmath0-expansion and derive the main equations for the gaussian closure approximation .",
    "the errors of both methods are discussed in section [ sec : error ] . in sections",
    "[ sec : annihilation ] and [ sec : autocatalytic ] , we will give examples of the application of the method in the cases of a binary chemical reaction and an autocatalytic reaction .",
    "the results of these two examples confirm the error - analysis performed before .",
    "for both processes we compare with the results coming from the exact solution of the master equation in the stationary regime ( derived in the appendix for the binary chemical reaction ) , and the results of numerical simulations using the gillespie algorithm in the time - dependent evolution . in section [ sec : opinion ] we present an application to a recently introduced model for opinion formation which requires two variables for its full description .",
    "finally , in section [ sec : conclusions ] we end with a brief summary of the work .",
    "let @xmath5 be the probability that at time @xmath6 the population number takes the value @xmath7 .",
    "we consider that it evolves according to a general master equation of the form : @xmath8 ,   \\label{me}\\ ] ] where @xmath9 is the linear step operator such that @xmath10\\equiv f(n+k)$ ] and @xmath11 runs over the integer numbers . besides @xmath7 , the coefficients @xmath12 depend on @xmath0 , which is a large parameter of the system ( typically the system volume ) .",
    "we consider that these functions are polynomials or can be expanded in power series of @xmath7 as @xmath13 where the coefficients @xmath14 scale as + @xmath15 .",
    "master equations of this form appear in the description of chemical reactions @xcite , ecological systems @xcite and opinion dynamics @xcite , among many other cases .",
    "more specific examples will be considered in the next sections .    in a seminal work",
    ", van kampen@xcite has given a way of finding an approximate solution of eq .",
    "( [ me ] ) .",
    "the approximation is based upon the splitting of the variable @xmath7 using the ansatz @xmath16 , where @xmath17 is a function of time accounting for the deterministic part of @xmath7 and @xmath18 corresponds to the fluctuations .",
    "changing variables from @xmath7 to @xmath19 in eq .",
    "( [ me ] ) , and expanding in powers of @xmath0 one obtains a fokker - planck equation for the probability distribution @xmath20 of the new variable @xmath19 : @xmath21\\frac{\\partial(\\xi\\pi)}{\\partial\\xi}+\\left[\\sum_{a , k}c_{k,0}^{a}\\frac{k^{2}}{2}\\phi^{a}\\right]\\frac{\\partial^{2}\\pi}{\\partial\\xi^{2}}+o(\\omega^{-\\frac{1}{2}}),\\ ] ] where the macroscopic variable @xmath22 satisfies @xmath23 from eq.([fpe ] ) we obtain the first and second moments of the fluctuations : @xmath24\\langle \\xi\\rangle , \\label{vk2 } \\\\ \\frac{\\partial\\langle\\xi^{2}\\rangle}{\\partial t}&=&-2\\left[\\sum_{a , k}c_{k,0}^{a}ka\\phi^{a-1}\\right]\\langle \\xi^{2}\\rangle+2\\left[\\sum_{a , k}c_{k,0}^{a}\\frac{k^{2}}{2}\\phi^{a}\\right].\\label{vk3}\\end{aligned}\\ ] ]    as proven by van kampen , the solution of the fokker - planck equation ( [ fpe ] ) is a gaussian distribution . therefore , the @xmath0-expansion method tells us that , up to corrections of order @xmath25 , the fluctuations of the variable @xmath7 follow a gaussian distribution .",
    "it suffices , then , to know the first and second moments of this distribution .",
    "our intention is to use from the very beginning the gaussian property in order to obtain a closed system of equations for the first two moments @xmath26 and @xmath27 .    from ( [ me ] )",
    "we get the ( exact ) equations for these first two moments , as : @xmath28 after substitution of the series expansion @xmath13 in the right hand side of these equations , one obtains higher order moments @xmath29 for @xmath30 .",
    "the gaussian closure replaces these higher order moments with the expressions @xmath31 that hold in the case of a gaussian distribution , i.e. @xmath32 , @xmath33 and @xmath34}{m \\choose 2k } ( 2k-1)!!\\langle n\\rangle^{m-2k}\\left[\\langle n^2\\rangle -\\langle n\\rangle^2\\right]^k\\ ] ] for @xmath30 .",
    "the first moments are explicitly shown in table [ gaussmoments ] .",
    ".gaussian moments [ cols=\"^,<\",options=\"header \" , ]     the van kampen ansatz @xmath16 allows us to find the error of this approximation .",
    "it follows that : @xmath35 in the gaussian approximation , the first three terms of the sum , @xmath36 are exact and the term @xmath37 scales as @xmath4 , or : @xmath38 if we use this result in each of the terms of eq.([dndt ] ) and @xmath39 we obtain @xmath40 with @xmath41 .",
    "similarly , one finds @xmath42 with @xmath43 .",
    "this gaussian approximation scheme ( or equivalently , finding a hierarchy of equations for the cumulants and neglecting those of order greater than two ) has been used many times in the literature in different contexts @xcite .",
    "we will show in the next section that the direct use of eqs .",
    "( [ dndtf],[dn2dtf ] ) has a smaller error that the use of eqs .",
    "( [ macro]-[vk3 ] ) . before showing this",
    ", we will generalize this procedure for the case of two - variable problems .",
    "let us consider a master equation of the following form : @xmath44 .",
    "\\label{me2v}\\ ] ]    the evolution equations for the first , second order moments and the correlations are : @xmath45 ( @xmath46 ) .",
    "again , the gaussian closure consists in replacing @xmath47 by the expression @xmath48 that holds assuming that the joint distribution @xmath49 is gaussian .",
    "this can be computed using wick s theorem@xcite . in table",
    "( [ gaussmoments ] ) we write the expression of some of the terms .",
    "we now calculate the error of the gaussian approximation and compare it with the one of the @xmath0-expansion . in eqs .",
    "( [ dndtf]-[dn2dtf ] ) we have shown that the errors we introduce in the equations for the moments when performing the gaussian approximation are of order @xmath50 for @xmath26 and @xmath51 for @xmath52 .",
    "the gaussian approximation scheme proceeds by considering approximations @xmath53 , @xmath54 to the true moments @xmath55 , @xmath56 . these approximations are defined as the solution of the evolution equations ( [ dndtf],[dn2dtf ] ) : @xmath57 defining the errors @xmath58 as : @xmath59 , @xmath60 ; expanding in first order in @xmath61 and @xmath62 , and using equations ( [ dndtf]-[dn2dtf ] ) and ( [ f1 g ] ) we get : @xmath63 taking into account that @xmath64 , @xmath65 , we have : @xmath66 if we set @xmath67 , @xmath68 , and the initial conditions are known , so that initially @xmath69 , equations ( [ depsilondt ] ) , ( [ depsilon2dt ] ) imply that @xmath70 and @xmath71 , a scaling respected during the time evolution .    in conclusion , solving equations ( [ dndtf]-[dn2dtf ] ) , we get @xmath26 and @xmath52 with errors of order @xmath72 and @xmath73 , or smaller . using the equations ( [ macro]-[vk3 ] ) of first order van kampen s expansion",
    "the error is of higher order in both cases : @xmath74 for @xmath26 and @xmath75 for @xmath52 .",
    "however , for the variance , @xmath76 , both approximations have an error of order @xmath51",
    ". we will show in the next sections that the gaussian approximation has the extra advantage that it is easier to derive for many problems of practical interest .",
    "one might be tempted to go to higher order schemes , where one neglects all the cumulants of order greater than @xmath77 with @xmath78 , and in this way obtain a closed set of equations for the first @xmath77 moments .",
    "for example , if we neglect all the cumulants of order greater than 3 , applying the same analysis as before , it is possible to derive that the errors in the first , second and third moments are of order @xmath79 , respectively .",
    "a word of caution is needed here .",
    "when truncating beyond the second cumulant , it is not ensured that the resulting probability distribution is positive definite @xcite .",
    "this means that one could get from such an scheme inconsistent results , e.g. a negative variance . nevertheless ,",
    "according to our analysis , the importance of these spurious results would decrease with @xmath0 as indicated , so one can still get useful results from higher order schemes .    in the following sections we will compare the gaussian approximation presented here with the first order @xmath0-expansion in some specific examples .",
    "chemical reactions are suitable processes for a stochastic description .",
    "the stochastic approach is specially necessary when the number of molecules considered is small , as it is the frequently addressed case of chemical reactions inside a cell , because in this situation fluctuations can be very important .",
    "we consider the general process @xmath80 , limited by reaction .",
    "this means that any two particles @xmath81 and @xmath82 have the same probability of reaction . denoting by @xmath83 and @xmath84 , respectively , the number of molecules of the @xmath81 and @xmath82 substances , the rate for the @xmath85 reaction is @xmath86 . for the reverse reaction",
    ", it is assumed that @xmath87 has a constant concentration , and hence the rate is @xmath88 . in these expressions @xmath0 is proportional to the total volume accessible .",
    "since @xmath89 is a constant , one only needs to consider one variable , for example , the number of @xmath81 molecules at time @xmath6 .",
    "let us denote by @xmath5 the probability that there are @xmath7 @xmath81-molecules at time @xmath6 .",
    "the master equation describing the process is : @xmath90 + \\omega\\omega[p(n-1,t)-p(n , t)],\\ ] ] which is the basis of the subsequent analysis .",
    "note that this equation can be written in the form ( [ me ] ) setting @xmath91 .    in the irreversible case ,",
    "@xmath92 , this master equation can be solved exactly using the generating function technique . in the general case , @xmath93 , an exact solution",
    "can also be found for the stationary state @xmath94 .",
    "details of the calculation are given in the appendix .",
    "we will compare the results obtained from the gaussian approximation and the first order @xmath0-expansion with the exact results , when available .",
    "the equations for the first two moments , using ( [ dndt ] ) , are : @xmath95    using the gaussian approximation , the evolution equations for the moments are : @xmath96    and the first order @xmath0-expansion gives : @xmath97,\\label{n3vkreac}\\end{aligned}\\ ] ] where @xmath98 .",
    "we compare the two approximations in the time - dependent case with results obtained by averaging over single realizations of the process , obtained numerically using the gillespie algorithm@xcite . in the next figures we compare the exact results with those obtained from the gaussian approximation ( computed by numerical integration of equations [ ngreac ] , [ n2greac ] ) and @xmath0-expansion ( equations [ n1vkreac]-[n3vkreac ] ) .",
    ", @xmath99 and @xmath100 for the binary reaction @xmath80 with parameters @xmath101 , @xmath102 , @xmath103 and initial conditions @xmath104 , @xmath105 . for the first two moments",
    "the gaussian approximation ( solid ) is very close to the results obtained with the gillespie algorithm ( dot - dashed , obtained averaging over one million realizations ) and the exact stationary value ( thin line ) , while @xmath106 order @xmath0-expansion ( dashed ) gives clearly different values . for @xmath107 ,",
    "the @xmath0-expansion gives more accurate results but both approximations differ from the exact values . ]    , @xmath52 and @xmath107 in the stationary state in the same case than in fig.[anieq ] .",
    "the straight thin lines are fits to the data and have slope @xmath108 , @xmath109 or @xmath110 . for the gaussian approximation ( solid ) , the errors in @xmath111 scale as @xmath112 . for the @xmath0-expansion ( dashed ) ,",
    "the errors scale as @xmath113 . ]",
    "figure ( [ anieq ] ) shows that the gaussian approximation reproduces better the exact results for the first two moments ; for the variance , the @xmath0-expansion gives more accurate results but both approximations differ from the exact values .",
    "figure ( [ aniesc ] ) shows that the errors in the stationary state , coming from the gaussian approximation for the mean value , the second moment and the variance scale as @xmath114 , respectively , while the errors of the @xmath0-expansion at first order scale as @xmath113 .",
    "this scaling is consistent with the previous analysis , as the exponents of the errors are smaller than the obtained bounds .",
    "the master equation describing this process is@xcite : @xmath117+\\frac{k'}{\\omega}[(n+2)(n+1)p(n+2,t)-n(n-1)p(n , t ) ] , \\label{me2}\\ ] ] where the concentration of @xmath81 particles is consider to be constant with a value @xmath118 .",
    "this equation if of the form ( [ me ] ) with @xmath119 .",
    "the general solution for this equation is not known , but the stationary solution @xmath120 can be obtained using the generating function technique@xcite .",
    "the exact equations for the first moments are : @xmath121    performing the gaussian approximation , we get : @xmath122    while first order @xmath0-expansion approach leads to : @xmath123    in the next figures we show the results obtained with the gaussian approximation ( computed by numerical integration of equations [ ngauto]-[n2gauto ] ) , @xmath0-expansion ( equations [ n1vkauto]-[n3vkauto ] ) , the gillespie algorithm , and the exact stationary solution .    ,",
    "@xmath124 and @xmath100 for the autocatalytic reaction @xmath115 , @xmath116 with @xmath125 , @xmath126 , @xmath103 and initial condition @xmath127 . for the first two moments",
    "the gaussian approximation ( solid ) is very close to the results coming from the gillespie algorithm ( dot - dashed ) and the exact value in the stationary case ( thin line ) whereas the @xmath0-expansion result ( dashed ) is clearly different , although for @xmath107 the @xmath0-expansion provides more accurate results.[autocat ] ]    as in the previous example , we see that the gaussian approximation fits better the evolution of the moments , but the variance is somehow better approximated by the first order @xmath0-expansion . in figure ( [ scalingerr ] )",
    "we show the errors in the stationary state for the two approximations as a function of @xmath0 .",
    "we see that the errors in @xmath128 decay as @xmath129 for the gaussian approximation , while the first - order @xmath0-expansion leads to errors that scale as @xmath130 . again",
    ", this scaling is consistent with the analysis of the approximations performed .     and @xmath107 in the stationary state as a function of @xmath0 in the same case than in fig.[autocat ] .",
    "the thin lines have slope @xmath108 , @xmath109 or @xmath110 . for the gaussian approximation ( solid ) , the errors in @xmath131 scale ( asymptotically ) as @xmath132 . for the @xmath0-expansion ,",
    "the errors scale as @xmath113 . ]",
    "in the last few years there has been a growing interest in the application of methods and techniques coming from statistical physics to the study of complex phenomena in fields traditionally far from physics research , particularly in biology , medicine , information technology or social systems .",
    "in particular the application of the physical approach to social phenomena has been discussed in several reviews @xcite . as an example of the use of master equations in this field , we mention a recent paper @xcite in which the process of opinion formation in a society is modeled as follows : society is divided in two parties ,",
    "a and b , plus an  intermediate  group of undecided agents i. the supporters of a and b do not interact among them , but only through their interaction with the group i , convincing one of its members with a given probability .",
    "in addition there is a nonzero probability of a spontaneous change of opinion from i to the other two parties and vice - versa .",
    "more specifically , if @xmath133 is the number of supporters of party a(b ) , @xmath134 is the number of undecided agents and @xmath0 is the total number of individuals , the possible transitions are :    spontaneous change @xmath135 , occurring with a rate @xmath136 ,    spontaneous change @xmath137 , occurring with a rate @xmath138 ,    spontaneous change @xmath139 , occurring with a rate @xmath140 ,    spontaneous change @xmath141 , occurring with a rate @xmath142 ,    convincing rule @xmath143 , occurring with a rate @xmath144 ,    convincing rule @xmath145 , occurring with a rate @xmath146 .    as the total number of individuals ( @xmath147 )",
    "is fixed , there are only two independent variables , say @xmath148 and @xmath149 .",
    "the master equation of the process is : @xmath150 \\nonumber\\\\ & & -\\left[\\alpha_{1}n_a+\\alpha_{3}n_b+(\\alpha_{2}+\\alpha_{4})(\\omega - n_a - n_b)+\\frac{\\beta_{1}n_a+\\beta_{2}n_b}{\\omega}(\\omega - n_a - n_b)\\right]p(n_a , n_b , t).\\nonumber\\end{aligned}\\ ] ]    we note that this master equation can be written in the general form ( [ me2v ] ) by setting @xmath151 , @xmath152 , @xmath153 and @xmath154 .",
    "an exact solution of this master equation is not known . in the following",
    ", we will apply to this problem the gaussian approximation scheme and compare it with the results of the @xmath0-expansion .",
    "the exact equations for the first moments are :    @xmath155    denoting by @xmath156 the gaussian approximations to the moments @xmath157 and the correlation @xmath158 , respectively , and using the results in table [ gaussmoments ] , we obtain : @xmath159.\\nonumber \\label{opgauss}\\end{aligned}\\ ] ]    in van kampen s expansion method , we define @xmath160 such that @xmath161 .",
    "the equations for the macroscopic components are @xcite : @xmath162(1-\\phi_{a}-\\phi_{b}),\\\\   \\frac{d\\phi_{b}}{dt}&=&-\\alpha_{3}\\phi_{b}+[\\alpha_{4}+\\beta_{2}\\phi_{b}](1-\\phi_{a}-\\phi_{b}),\\end{aligned}\\ ] ] and for the fluctuations : @xmath163\\langle \\xi_{a}\\rangle-(\\alpha_{2}+\\beta_{1}\\phi_{a})\\langle \\xi_{b}\\rangle,\\\\   \\frac{d\\langle \\xi_{b}\\rangle}{dt}&=&-[\\alpha_{3}+\\alpha_{4}+\\beta_{2}(2\\phi_{b}+\\phi_{a})-\\beta_{2}]\\langle \\xi_{b}\\rangle-(\\alpha_{4}+\\beta_{2}\\phi_{b})\\langle \\xi_{a}\\rangle,\\\\ \\frac{d\\langle \\xi_{a}^{2}\\rangle}{dt}&=&-2\\alpha_{1}\\langle \\xi_{a}^{2}\\rangle-2(\\alpha_{2}+\\beta_{1}\\phi_{a})(\\langle \\xi_{a}^{2}\\rangle+\\langle \\xi_{a}\\xi_{b}\\rangle)+2\\beta_{1}\\langle \\xi_{a}^{2}\\rangle(1-\\phi_{a}-\\phi_{b})\\nonumber\\\\ & & + \\alpha_{1}\\phi_{a}+(\\alpha_{2}+\\beta_{1}\\phi_{a})(1-\\phi_{a}-\\phi_{b}),\\\\ \\frac{d\\langle \\xi_{b}^{2}\\rangle}{dt}&=&-2\\alpha_{3}\\langle \\xi_{b}^{2}\\rangle-2(\\alpha_{4}+\\beta_{2}\\phi_{b})(\\langle \\xi_{b}^{2}\\rangle+\\langle \\xi_{a}\\xi_{b}\\rangle)+2\\beta_{2}\\langle \\xi_{b}^{2}\\rangle(1-\\phi_{a}-\\phi_{b})\\nonumber\\\\ & & + \\alpha_{3}\\phi_{b}+(\\alpha_{4}+\\beta_{2}\\phi_{b})(1-\\phi_{a}-\\phi_{b}),\\\\ \\frac{d\\langle \\xi_{a}\\xi_{b}\\rangle}{dt}&=&-(\\alpha_{1}+\\alpha_{3})\\langle \\xi_{a}\\xi_{b}\\rangle-(\\alpha_{2}+\\beta_{1}\\phi_{a})(\\langle \\xi_{a}\\xi_{b}\\rangle+\\langle \\xi_{b}^{2}\\rangle)-(\\alpha_{4}+\\beta_{2}\\phi_{b})(\\langle \\xi_{a}\\xi_{b}\\rangle+\\langle \\xi_{a}^{2}\\rangle)\\nonumber\\\\ & & + ( 1-\\phi_{a}-\\phi_{b})(\\beta_{1}+\\beta_{2})\\langle \\xi_{a}\\xi_{b}\\rangle.\\end{aligned}\\ ] ]    from those we can recover the original variables @xmath164 .    in the next figures we compare the results coming from both approximations ( obtained by numerical integration of the previous equations ) and from simulations of the process using the gillespie algorithm , for some representative values of the parameters and initial conditions .",
    "again , the gaussian approximation reproduces better the values for the average and the second moment whereas in this case both methods perform very similarly for the fluctuations and correlation .    , @xmath165 and @xmath166 for the opinion formation model of reference @xcite , for @xmath167 , and initial conditions @xmath168 . for the average @xmath169 ,",
    "the gaussian approximation ( solid ) follows very accurately the gillespie simulation results ( dot - dashed ) , whereas the @xmath0-expansion ( dashed ) differs clearly .",
    "for the second moment @xmath170 the gaussian approximation performs clearly better as well , while for the variance @xmath165 and correlations @xmath171 , the gaussian approximation and the @xmath0-expansion give very similar results , although both are far from the simulation data . ]",
    "in this paper , we have given explicit expressions for the equations for the first and second moments of a stochastic process defined by a general class of master equations using the gaussian approximation closure .",
    "the approach is motivated by van kampen s @xmath0-expansion result that , at lowest order , the fluctuations are gaussian .",
    "we have shown that the gaussian closure is simple to perform and leads to errors in the average value , the second moment and the fluctuations ( the variance ) , that scale at most as @xmath172 , respectively .",
    "this is to be compared with the @xmath0-expansion result in which the respective errors scale at most as @xmath173 .",
    "therefore , the gaussian approximation is more accurate , which turns out to be important , specially for small values of @xmath0 .",
    "we have checked these results by comparing the performance of the two methods in three examples : ( i ) a binary chemical reaction , ( ii ) an autocatalytic reaction and ( iii ) a model for opinion formation . in all cases",
    "studied , the gaussian closure has given a better approximation to the average and the second moment , although the @xmath0-expansion , due to a cancellation of errors , yields a somehow smaller numerical error in the variance .",
    "in general , the gaussian closure scheme is very simple to carry on in practice and this simplicity and the improvement of the predictive power is more apparent in many - variable systems .",
    "we believe that this method can be usefully applied to the study of other problems of recent interest in the literature involving stochastic processes in systems with a small number of particles .",
    "we now find the solution of the master equation ( [ eq : master ] ) in the equilibrium state for the general case , and the full dynamical solution for the irreversible case @xmath92 . without loss of generality ,",
    "let us rescale @xmath174 and @xmath175 to get the simpler equation : @xmath176.\\ ] ] furthermore , only the case @xmath177 needs to be considered . if @xmath178 the change @xmath179 leaves invariant the previous equation provided that we make the identification @xmath180 .",
    "this means that the solutions in both cases are related by @xmath181 .          by setting @xmath184",
    "one gets the differential equation : @xmath185 the solution around the singular regular point @xmath186 can be found by the frobenius method as a power series @xmath187 .",
    "the regular solution satisfying the boundary condition @xmath188 is and it has to be discarded since it can not be expanded in a power series of @xmath189 . in the following @xmath190 is the modified bessel function of the first kind . ] : @xmath191 and the equilibrium probabilities , rescaling back to the original parameters , are : @xmath192 from where the first two moments can be computed as : @xmath193      we now study how the system relaxes towards equilibrium .",
    "we will restrict ourselves to the irreversible case @xmath92 .",
    "this corresponds to the process @xmath194 , inert .",
    "the partial differential equation ( [ eq : pde ] ) can be solved by the technique of separation of variables by trying solutions of the form @xmath195 .",
    "this leads to the pair of ordinary differential equations : @xmath196 being @xmath197 the constant arising from the method of separation of variables .",
    "the solution of the time dependent function is @xmath198 and the solution of the @xmath189-function is the hypergeometric function . ]",
    "the explicit series is : @xmath200 @xmath201 is the pochhammer s symbol : @xmath202 , or for @xmath203 , and we have introduced @xmath204 the solution for the function @xmath205 is obtained by linear combination of the elementary solutions found above : @xmath206 this function is , in general , an infinite series on the variable @xmath189 .",
    "in fact the coefficients , according to ( [ eq : fpn ] ) are nothing but the time - dependent probabilities .",
    "however , in this irreversible case , the probability of having more @xmath81-molecules that the initial number at @xmath207 , say @xmath208 , has to be zero .",
    "therefore the series must be truncated after the power @xmath209 .",
    "this implies that in the previous expression only hypergeometric functions that represent a polynomial in @xmath189 can be accepted .",
    "this is achieved by forcing @xmath210 , since the series ( [ eq : hyper ] ) becomes then a polynomial of degree @xmath11 .",
    "the condition @xmath211 is equivalent to the parameter @xmath212 adopting one of the possible values @xmath213 . finally , noticing that @xmath214 , the solution can be written as : @xmath215 the notation emphasizes that @xmath216 depends both on @xmath217 and @xmath208 but @xmath218 depends only on @xmath217 : @xmath219 all that remains is to impose the initial condition .",
    "we start with @xmath208 @xmath81-molecules at time @xmath207 , such that @xmath220 .",
    "this implies that the coefficients @xmath216 must satisfy : @xmath221 for @xmath222 .",
    "the solution starts by finding first @xmath223 and then proceeds backwards to find @xmath224 in a recursive manner .",
    "after some lengthy algebra , the result is : @xmath225 ( in the case @xmath226 the correct interpretation of the undetermined expression is @xmath227 ) .",
    "going back to the original time variable , we now give the expression for the probabilities : @xmath228 the normalization condition @xmath229 is verified with the help of the relation @xmath230 . the relation @xmath231 ( the indetermination arising when",
    "@xmath226 must be resolved as @xmath109 ) helps to find the average of the number of particles : @xmath232 the second moment @xmath233 can be found with the help of eq.([dndtd ] ) as , or : @xmath234    financial support from ministerio de ciencia e innovacin ( spain ) and feder ( eu ) grant fis2007 - 60327 is acknowledged .",
    "l. f. l. is supported by the jae - predoc program of csic .",
    "we acknowledge fruitful discussions with h.s .",
    "n. g. van kampen , _",
    "stochastic processes in physics and chemistry _ , ( north - holland , amsterdam , 2004 ) . c. w gardiner , _ handbook of stochastic methods for physics , chemistry and the natural sciences _ ( springer - verlag , 1990 ) .",
    "d. t. gillespie , _ exact stochastic simulation of coupled chemical reactions _ j. phys .",
    "chem . * 81*,2340 ( 1977 ) .",
    "castellano , c. , fortunato , s. , loreto , _ statistical physics of social dynamics _ v. rev .",
    "81 * , 591 ( 2009 ) .",
    "s. pigolotti , a. flammini , m. marsili , a. maritan , _ species lifetime distribution for simple models of ecologies _ , proc .",
    "usa * 102 * , 44 , 15747 ( 2005 ) .",
    "m. s. de la lama , i.g .",
    "szendro , j.r .",
    "iglesias , h.s .",
    "wio , _ van kampen s expansion approach in an opinion formation model _ , eur .",
    "j. b * 51 * , 435 ( 2006 ) .",
    "r. c. desai and r. zwanzig , _ statistical mechanics of a nonlinear stochastic model _",
    "* 19 * , 1 ( 1978 ) .",
    "d. cubero , _ finite - size fluctuations and stochastic resonance in globally coupled bistable systems _ , phys .",
    "e * 77 * , 021112 ( 2008 ) d.j .",
    "amit and v. martin - mayor , _ field theory , the renormalization group and critical phenomena _",
    ", 3rd edition , world scientific ( 2005 ) .",
    "p. hnggi and p. talkner , _ a remark on truncation schemes of cumulant hierarchies _ , j. stat",
    "* 22 * , 65 ( 1980 ) .",
    "w. weidlich , _ sociodynamics- a systematic approach to mathematical modeling in social sciences _",
    "( taylor and francis , london , 2002 ) .",
    "w weidlich phys",
    "204 * , 1 ( 1991 ) .",
    "d. stauffer , s. moss de oliveira , p.m.c . de oliveira , j.s .",
    "sa martins , _ biology , sociology , geology by computational physicists _",
    "( elsevier , amsterdam , 2006 ) ."
  ],
  "abstract_text": [
    "<S> we analyze the gaussian approximation as a method to obtain the first and second moments of a stochastic process described by a master equation . </S>",
    "<S> we justify the use of this approximation with ideas coming from van kampen s expansion approach ( the fact that the probability distribution is gaussian at first order ) . </S>",
    "<S> we analyze the scaling of the error with a large parameter of the system and compare it with van kampen s method . our theoretical analysis and the study of several examples shows that the gaussian approximation turns out to be more accurate </S>",
    "<S> . this could be specially important for problems involving stochastic processes in systems with a small number of particles . </S>"
  ]
}