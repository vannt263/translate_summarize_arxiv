{
  "article_text": [
    "this paper considers a point - to - point communication scenario where a source denoted by @xmath0 wants to transmit a message to a destination denoted by @xmath1 through a set of independent additive white gaussian noise ( awgn ) channels .",
    "the set of independent awgn channels is referred to as the _ parallel gaussian channel _",
    "9.4 ) ( also called the _",
    "gaussian product channel _ in  ( * ? ? ?",
    "* sec  3.4.3 ) ) .",
    "the parallel gaussian channel has been used to model the multiple - input multiple - output ( mimo ) channel  ( * ? ? ?",
    "7.1 )  an essential channel model in wireless communications .",
    "the parallel gaussian channel consists of  @xmath2 independent awgn channels through which the source @xmath0 wants to send a message to the destination @xmath1 .",
    "let @xmath3 be the index set of the @xmath2  channels . for the @xmath4 channel use ( or time slot ) , the relation for the @xmath5 channel between the input signal @xmath6 and output signal @xmath7 is @xmath8 where @xmath9 are independent gaussian noises . for each @xmath10 , the variance of the noise induced by the @xmath5  channel",
    "is assumed to be some positive number @xmath11 for all channel uses , i.e. , @xmath12=n_\\ell$ ] for all @xmath13 .",
    "to keep notation compact , let @xmath14 , @xmath15 and @xmath16 denote the random column vectors @xmath17^t$ ] , @xmath18^t$ ] and @xmath19^t$ ] respectively .",
    "every codeword @xmath20 transmitted by node  @xmath21 over  @xmath22 channel uses should satisfy the following _ peak power constraint _ where @xmath23 denotes the permissible power for  @xmath20 : @xmath24    if we would like to transmit a uniformly distributed message @xmath25 across this channel , it was shown by shannon  @xcite that as the blocklength  @xmath22 approaches to infinity , the maximum rate of communication  @xmath26 converges to a certain limit called _",
    "capacity_. the closed - form expression of the capacity can be obtained by finding the optimal power allocation among the  @xmath2 channels , which is described as follows .",
    "define the mapping @xmath27 as @xmath28 where @xmath29 can be viewed as the power allocated to channel  @xmath30 . if we let @xmath31 , @xmath32 , @xmath33 , @xmath34 , @xmath35 denote the @xmath36 real numbers yielded from the water - filling algorithm  ( * ? ? ?",
    "* ch  9.4 ) where @xmath37 and @xmath38 for each @xmath10 and let @xmath39^t \\label{pellvalue*}\\ ] ] be the optimal power allocation vector , then the capacity of the parallel gaussian channel was shown in  @xcite to be @xmath40 bits per channel use .",
    "more specifically , if @xmath41 designates the maximum number of messages that can be transmitted over @xmath22 channel uses with permissible power  @xmath42 and average error probability @xmath43 , one has @xmath44 the capacity result   has been strengthened by polyanskiy - poor - verd ( * ? ? ?",
    "78 ) and tan - tomamichel ( * ? ? ?",
    "appendix  a ) as @xmath45 where @xmath46 is the gaussian dispersion function defined as @xmath47 and @xmath48 is the cumulative distribution function ( cdf ) of the standard normal distribution . _",
    "feedback _ , which is the focus of the current paper , is known to simplify coding schemes and improves the performance of communication systems in many scenarios .",
    "see ( * ? ? ?",
    "17 ) for a thorough discussion of the benefits of feedback in single- and multi - user information theory .",
    "when feedback is allowed , each input symbol @xmath14 depends on not only the transmitted message @xmath49 but also all the previous channel outputs up to time @xmath50 , i.e. , the symbols @xmath51 .",
    "it was shown by shannon  @xcite that the presence of noiseless feedback does not increase the capacity of point - to - point _",
    "memoryless channels_. therefore , the feedback capacity of the parallel gaussian channel remains to be @xmath40 . in the presence of feedback ,",
    "if we let @xmath52 denote the maximum number of messages that can be transmitted over @xmath22 channel uses with permissible power  @xmath42 and average error probability @xmath43 , it follows directly from   that the optimal rate @xmath53 satisfies @xmath54 in this paper , the main contribution is a conceptually simple , concise and self - contained proof that in the presence of feedback , the first- and second - order terms in the asymptotic expansion in   remains unchanged , i.e. , @xmath55      our work is inspired by the recent study of the fundamental limits of communication over discrete memoryless channels ( dmcs ) with feedback  @xcite .",
    "it was shown by altu and wagner  ( * ? ? ?",
    "1 ) that for some classes of dmcs whose capacity - achieving input distributions are not unique ( in particular , the minimum and maximum conditional information variances differ ) , coding schemes with feedback achieve a better second - order asymptotics compared to those without feedback . they also showed ( * ? ? ?",
    "2 ) that feedback does not improve the second - order asymptotics of dmcs @xmath56 if the conditional variance of the log - likelihood ratio @xmath57 , where @xmath58 is the unique capacity - achieving output distribution , does not depend on the input @xmath59 .",
    "such dmcs include the class of weakly - input symmetric dmcs initially studied by polyanskiy - poor - verd  @xcite .",
    "however , we note that the proof technique used by altu and wagner requires the use of a berry - essen - type result for bounded martingale difference sequences  @xcite , and their technique can not be extended to the parallel gaussian channel with feedback because each input symbol  @xmath6 belongs to an interval @xmath60 $ ] that grows unbounded as  @xmath22 increases",
    ". instead , our proof uses curtiss theorem to show that a sum of dependent random variables that naturally appears in the non - asymptotic analysis converges in distribution to a sum of independent random variables , thus facilitating the use of the usual central limit theorem  @xcite . for @xmath61 ,",
    "the parallel gaussian channel with feedback reduces to the awgn channel with feedback , whose second - order coding rate is identical to the same channel without feedback by the following symmetry argument : the log - likelihood ratios @xmath57 for all @xmath59 on the power sphere with radius @xmath62 are the same .",
    "see  @xcite for a rigorous but simple proof .",
    "in contrast , for @xmath63 , this symmetry argument no longer holds due to the flexible power allocation among the  @xmath2 channels , and hence the simple proof suggested in  @xcite can not be extended to the parallel gaussian channel with feedback .",
    "if the peak power constraint in   is replaced with the expected power constraint @xmath64\\le p$ ] , the first - order coding rate of the awgn channel with feedback can be improved from @xmath65 to @xmath66  ( * ? ? ?",
    "ii ) where @xmath43 denotes the tolerable error probability . for the general case @xmath63 , the proof in ( * ? ? ?",
    "ii ) can easily be extended to show that the first - order coding rate of the parallel gaussian channel with feedback can be improved from @xmath40 to @xmath67 , and hence   no longer holds .",
    "this paper is organized as follows .",
    "the next subsection summarizes the notation used in this paper .",
    "section  [ sectiondefinition ] provides the problem setup of the parallel gaussian channel with feedback under the peak power constraint and presents our main theorem .",
    "section  [ sectionprelim ] contains the preliminaries required for the proof of our main theorem , which include important properties of non - asymptotic binary hypothesis testing quantities and modification of power allocation among the parallel channels",
    ". section  [ sectionmainresult ] presents the proof of our main theorem .",
    "section  [ sectionconclusion ] concludes this paper by explaining the novel ingredients in the proof of the main theorem and the major difficulty in strengthening the main theorem .",
    "the sets of natural numbers , non - negative integers , real numbers and non - negative real numbers are denoted by @xmath68 , @xmath69 , @xmath70 and @xmath71 respectively .",
    "an @xmath2-dimensional column vector is denoted by @xmath72^t$ ] where @xmath73 denote the @xmath5 element of @xmath74 . the euclidean norm of a vector @xmath75 is denoted by @xmath76 .",
    "we will take all logarithms to base  @xmath77 throughout this paper .",
    "we use @xmath78 to represent the probability of an event  @xmath79 , and we let @xmath80 be the indicator function of @xmath79 . every random variable is denoted by a capital letter ( e.g. , @xmath81 ) , and the realization and the alphabet of the random variable are denoted by the corresponding small letter ( e.g. , @xmath59 ) and calligraphic letter ( e.g. , @xmath82 ) respectively .",
    "we use @xmath83 to denote a random tuple @xmath84 , where all the elements @xmath85 have the same alphabet  @xmath82 . we let @xmath86 and @xmath87 denote the probability distribution of @xmath81 and the conditional probability distribution of @xmath88 given @xmath81 respectively for any random variables  @xmath81 and  @xmath88 ( can be both discrete , both continuous or one discrete and one continuous ) .",
    "we let @xmath89 denote the joint distribution of @xmath90 , i.e. , @xmath91 for all @xmath59 and @xmath92 .",
    "for any random variable  @xmath93 and any real - valued function  @xmath94 whose domain includes @xmath82 , we let @xmath95 denote @xmath96 for any real constant @xmath97 .",
    "the expectation and the variance of  @xmath98 are denoted as @xmath99 $ ] and @xmath100 $ ] respectively . for simplicity , we drop the subscript of a notation if there is no ambiguity .",
    "for any real - valued gaussian random variable @xmath101 whose mean and variance are @xmath102 and @xmath103 respectively , we let @xmath104 be the corresponding probability density function .",
    "suppose node  @xmath0 transmits a message to node  @xmath1 over @xmath22 channel uses ( or time slots ) through the @xmath2  independent awgn channels .",
    "before any transmission begins , node  @xmath0 chooses message  @xmath49 destined for node  @xmath1 where @xmath49 is uniformly distributed on the message alphabet @xmath105 whose size is denoted by @xmath106 . for the @xmath4 channel use",
    ", node  @xmath0 transmits @xmath107 and the corresponding channel output  @xmath108 satisfies @xmath109 we assume that a noiseless feedback link from the destination node @xmath110 to the source node @xmath21 exists so that @xmath111 is available for encoding @xmath14 for each @xmath112 .",
    "the codewords @xmath20 transmitted by  @xmath0 should satisfy the following the sum peak power constraint where @xmath23 denotes the permissible power for @xmath20 .",
    "in other words , @xmath113    [ defcode ] an @xmath114-feedback code consists of the following :    1 .   a message set @xmath115 at node  @xmath0 as defined in  .",
    "message @xmath49 is uniform on @xmath115 .",
    "an encoding function @xmath116 for each @xmath117 and each @xmath112 , where @xmath118 is the encoding function at node  @xmath0 for encoding @xmath6 such that @xmath119 and the peak power constraint   holds .",
    "3 .   a decoding function @xmath120 where @xmath121 is the decoding function for @xmath49 at node  @xmath122 such that @xmath123    [ defawgnchannel ] let @xmath124 and @xmath125 denote the random vectors @xmath126^t$ ] and @xmath127^t$ ] respectively , and let @xmath128 and @xmath129 be their realizations respectively .",
    "the _ parallel gaussian channel with feedback _ is characterized by the conditional probability density distribution @xmath130 satisfying @xmath131 such that the following holds for any @xmath114-feedback code : for each @xmath112 , @xmath132 where @xmath133 for all @xmath134 .    for any @xmath114-feedback code , let @xmath135 be the joint distribution induced by the code .",
    "we can use definition  [ defcode ] , and to factorize @xmath135 as follows : @xmath136    [ deferrorprobability ] for an @xmath114-feedback code , we can calculate according to   the _ average probability of decoding error _ defined as @xmath137 .",
    "we call an @xmath114-feedback code with average probability of decoding error no larger than @xmath43 an @xmath138-feedback code .",
    "define @xmath139{2.7 in}{there exists an $ (",
    "n , m , p , \\varepsilon)$-feedback code}\\right.\\right\\}.\\ ] ]    [ defcapacity ] let @xmath140 .",
    "the @xmath43-capacity of the parallel gaussian channel with feedback , denoted by @xmath141 , is defined to be @xmath142 the capacity is defined to be @xmath143    [ defdispersion ] let @xmath140 . the @xmath43-second - order coding rate of the parallel gaussian channel with feedback , denoted by @xmath144 , is defined to be @xmath145    recall the definition of @xmath40 in . since the capacity of the parallel gaussian channel without feedback is @xmath40 ( see , e.g. , @xcite and ( * ? ? ?",
    "3.4.3 ) ) and an introduction of an extra noiseless feedback link does not increase the capacity  ( see , e.g. , @xcite and ( * ? ? ?",
    "9.6 ) ) , it follows that @xmath146 before stating our main result , recall that @xmath147 is the cdf of the standard normal distribution and recall the definitions of @xmath40 and @xmath148 in and respectively .",
    "since @xmath48 is strictly increasing on @xmath149 , the inverse of @xmath48 is well - defined and is denoted by @xmath150 .",
    "the following theorem is the main result in this paper .",
    "[ thmmainresult ] fix an @xmath151 .",
    "then , @xmath152 and the @xmath43-dispersion satisfies @xmath153    combining and theorem  [ thmmainresult ] , we complete the characterizations of the first- and second - order asymptotics of the parallel gaussian channel with feedback as shown in  .",
    "the following definition concerning the non - asymptotic fundamental limits of a simple binary hypothesis test is standard .",
    "see for example ( * ? ? ?",
    "* section  2.3 ) .",
    "[ defbhtdivergence ] let @xmath154 and @xmath155 be two probability distributions on some common alphabet @xmath82 .",
    "let @xmath156 be the set of randomized binary hypothesis tests between @xmath154 and @xmath155 where @xmath157 indicates the test chooses @xmath158 , and let @xmath159 $ ] be a real number .",
    "the minimum type - ii error in a simple binary hypothesis test between @xmath154 and @xmath155 with type - i error less than @xmath160 is defined as @xmath161    the existence of a minimizing test @xmath162 is guaranteed by the neyman - pearson lemma .",
    "we state in the following lemma and proposition some important properties of @xmath163 , which are crucial for the proof of theorem  [ thmmainresult ] .",
    "the proof of the following lemma can be found in , for example , wang - colbeck - renner  ( * ? ? ?",
    "* lemma  1 ) .",
    "[ lemmadpi ] let @xmath154 and @xmath155 be two probability distributions on some @xmath82 , and let @xmath94 be a function whose domain contains @xmath82 .",
    "then , the following two statements hold :    1 .",
    "( data processing inequality ( dpi ) ) @xmath164 .",
    "2 .   for all @xmath165 , @xmath166 .",
    "the proof of the following proposition can also be found in wang - colbeck - renner  ( * ? ? ?",
    "* lemma 3 ) .",
    "[ propositionbhtlowerbound ] let @xmath167 be a probability distribution defined on @xmath168 for some finite alphabet @xmath115 , and let @xmath169 be the marginal distribution of @xmath167 .",
    "in addition , let @xmath170 be a distribution defined on @xmath115 .",
    "suppose @xmath171 is the uniform distribution , and let @xmath172 be a real number in @xmath173 where @xmath174 is distributed according to @xmath167 .",
    "then , @xmath175      for each transmitted codeword @xmath176 , we can view @xmath177 as the power allocated to the @xmath5 channel for each @xmath117 . in the proof of theorem  [ thmmainresult ] , an early step is to discretize the power allocated to the @xmath2 channels . to this end",
    ", we need the following definition which defines the power allocation vector of a sequence @xmath176 .",
    "[ definitionpowertype ] the _ power allocation mapping _",
    "@xmath178 is defined as @xmath179^t.\\ ] ] we call @xmath180 the _ power type of @xmath181_.    the proof of theorem  [ thmmainresult ] involves modifying a given length-@xmath22 code so that useful bounds on the performance of the given code can be obtained by analyzing the modified code .",
    "more specifically , the encoding functions the given code are modified so that the power type of the random codeword generated by the modified code always falls into some small bounding box .",
    "the specific modification of the encoding functions is described in the following definition .",
    "[ definitiontransformedcode ] given an @xmath114-feedback code , let @xmath115 , @xmath182 and @xmath121 be the corresponding message alphabet , encoding functions and decoding function respectively .",
    "in addition , let @xmath183 and @xmath184\\in \\mathbb{r}_+^l$ ] such that @xmath185 .",
    "then , the _ @xmath186-modified code based on the @xmath114-feedback code _ consists of the following message alphabet , encoding functions and decoding function which are denoted by @xmath187 , @xmath188 and @xmath189 respectively : + * 1 ) * a message set @xmath190 at node  @xmath0 .",
    "message @xmath49 is uniform on @xmath187 .",
    "+ * 2 ) * an encoding function @xmath191 for each @xmath117 and each @xmath112 , which is defined as follows . for each @xmath192 and each @xmath193 , define @xmath194 in a recursive manner in this order @xmath195 as follows : for each @xmath196 , define @xmath194 recursively for @xmath197 as @xmath198{4 in}{if $ f_{\\ell , k}(w , \\mathbf{y}^{k-1})^2+\\sum\\limits_{i=1}^{k-1 } \\tilde f_{\\ell , i}(w , \\mathbf{y}^{i-1})^2 \\le n(s_\\ell+\\gamma)$ , } \\\\ 0 & \\parbox[t]{4 in}{if $ f_{\\ell , k}(w , \\mathbf{y}^{k-1})^2+\\sum\\limits_{i=1}^{k-1 } \\tilde f_{\\ell , i}(w , \\mathbf{y}^{i-1})^2 > n(s_\\ell+\\gamma)$. }   \\end{cases } \\label{deftildefeq1}\\end{aligned}\\ ] ] it follows from   that @xmath199 and @xmath200 in addition , in view of  , we define @xmath201 recursively for @xmath202 as @xmath203{5 in}{if $ f_{\\ell , n}(w , \\mathbf{y}^{n-1})^2+\\sum\\limits_{i=1}^{n-1 } \\tilde f_{\\ell , i}(w , \\mathbf{y}^{i-1})^2 \\in[n(s_\\ell - l\\gamma ) , n(s_\\ell+\\gamma)]$,}\\\\   \\sqrt{n(s_\\ell - l\\gamma ) - \\sum\\limits_{i=1}^{n-1 } \\tilde f_{\\ell , i}(w , \\mathbf{y}^{i-1})^2 } & \\parbox[t]{5 in}{if $ f_{\\ell , n}(w , \\mathbf{y}^{n-1})^2+\\sum\\limits_{i=1}^{n-1 } \\tilde f_{\\ell , i}(w , \\mathbf{y}^{i-1})^2 < n(s_\\ell - l\\gamma)$. }   \\end{cases } \\label{deftildefeq2}\\end{aligned}\\ ] ] combining   and , we conclude that @xmath204\\bigg\\}\\bigg\\}=1.\\label{deftildefeq2*}\\end{aligned}\\ ] ] on the other hand , it follows from  , , the fact @xmath205 and the assumption @xmath185 that @xmath206 finally , in view of  , we define @xmath207 as @xmath208{4 in}{if $ f_{l , n}(w , \\mathbf{y}^{n-1})^2+\\hspace{-0.25 in}\\sum\\limits_{\\substack{(\\ell , i)\\in\\\\\\hspace{0.25 in } \\mathcal{l}\\times\\{1 , 2 , \\ldots , n\\ } \\setminus\\{(l , n)\\ } } } \\hspace{-0.55 in}\\tilde f_{\\ell , i}(w , \\mathbf{y}^{i-1})^2 = np$,}\\\\   \\sqrt{np - \\hspace{-0.25 in}\\sum\\limits_{\\substack{(\\ell , i)\\in\\\\\\hspace{0.25 in } \\mathcal{l}\\times\\{1 , 2 , \\ldots , n\\ } \\setminus\\{(l , n)\\ } } } \\hspace{-0.55 in}\\tilde f_{\\ell , i}(w , \\mathbf{y}^{i-1})^2 } & \\parbox[t]{4 in}{if $ f_{l , n}(w , \\mathbf{y}^{n-1})^2+\\hspace{-0.25 in}\\sum\\limits_{\\substack{(\\ell , i)\\in\\\\\\hspace{0.25 in } \\mathcal{l}\\times\\{1 , 2 , \\ldots , n\\ } \\setminus\\{(l , n)\\ } } } \\hspace{-0.55",
    "in}\\tilde f_{\\ell , i}(w , \\mathbf{y}^{i-1})^2 < np$. }   \\end{cases } \\label{deftildefeq3}\\end{aligned}\\ ] ] combining  , and the assumption that @xmath185 , we have @xmath209\\bigg\\}\\cap\\bigg\\{\\sum\\limits_{\\ell=1}^{l}\\sum\\limits_{i=1}^{n}\\tilde f_{\\ell , i}(w , \\boldsymbol{y}^{i-1})^2   = np\\bigg\\}\\bigg\\}=1 . \\label{deftildefeq3*}\\end{aligned}\\ ] ] * 3 ) * a decoding function @xmath210 for providing an estimate of @xmath49 at node  @xmath1 .",
    "@xmath211    the basic idea behind transforming a code in definition  [ definitiontransformedcode ] is simple .",
    "suppose we are given an @xmath114-feedback code , a @xmath183 and an @xmath184\\in \\mathbb{r}_+^l$ ] such that @xmath185 .",
    "then , the @xmath186-modified code is formed by    1 .",
    "truncating a transmitted codeword if the power transmitted over the @xmath5 channel exceeds @xmath212 , which can be seen from  ; 2 .   boosting the power of the transmitted codeword if the power transmitted over the @xmath5 channel falls below @xmath213 , which can be seen from the second clause of",
    "; 3 .   adjusting the last symbol transmitted over the @xmath214 channel ( i.e. , @xmath215 ) so that the total transmitted power is exactly equal to  @xmath216 , which can be seen from the second clause of  .",
    "given an @xmath114-feedback code , we consider the corresponding @xmath186-modified code constructed in definition  [ definitiontransformedcode ] and let @xmath217 be the distribution induced by the modified code . by  , we see that @xmath218\\bigg\\}\\cap\\bigg\\{\\sum\\limits_{\\ell=1}^{l}\\sum\\limits_{k=1}^{n}x_{\\ell , k}^2   = np\\bigg\\}\\right\\}=1 . \\label{modifiedcodeproperty*}\\end{aligned}\\ ] ] define the @xmath219-bounding box @xmath220\\times [ s_2-\\delta , s_2+\\delta]\\times \\ldots \\times [ s_l-\\delta , s_l+\\delta ] .",
    "\\label{defgammas}\\ ] ] for each @xmath221 and each @xmath222 .",
    "it then follows from   that @xmath223 the following lemma is a natural consequence of definition  [ definitiontransformedcode ] , and the proof is deferred to appendix  [ appendixa ] .",
    "[ lemmatransformedcode ] given an @xmath114-feedback code , let @xmath224 be the distribution induced by the code .",
    "fix any @xmath221 and any @xmath222 such that @xmath185 , and let @xmath217 be the distribution induced by the @xmath186-modified code based on the @xmath114-feedback code .",
    "then , we have @xmath225 for all @xmath134 .",
    "fix an @xmath140 and choose an arbitrary sequence of @xmath226-feedback codes . since @xmath227 by",
    ", it suffices to show that @xmath228 for all @xmath229 . to this end , fix an arbitrary @xmath229 .      using definition  [ defcode ]",
    ", we have @xmath230 for the chosen @xmath226-feedback code for each  @xmath231 . given the chosen @xmath226-feedback code , we can always construct an @xmath232-feedback code by appending a carefully chosen tuple @xmath233 to each transmitted codeword @xmath234 generated by the @xmath226-feedback code such that @xmath235 which implies that @xmath236 in addition , given the @xmath232-feedback code , we can always construct an @xmath237-feedback code by appending a carefully chosen @xmath238 to each transmitted codeword @xmath239 generated by the @xmath240-feedback code such that @xmath241 to simplify notation , we let @xmath242 construct the set of power allocation vectors @xmath243 which can be viewed as a set of quantized power allocation vectors @xmath244 with quantization level @xmath245 that satisfy the equality power constraint @xmath246 it follows from  , and definition  [ definitionpowertype ] that @xmath247 and @xmath248      let @xmath135 be the probability distribution induced by the @xmath249-feedback code constructed above for each @xmath250 , where @xmath224 is obtained according to . fix an @xmath251 and the corresponding @xmath249-feedback code .",
    "recall the definition of @xmath252 for each @xmath117 in   and define the distribution @xmath253 where @xmath254 the choice of @xmath255 in   is motivated by the choice of the auxiliary output distribution in  ( * ? ? ?",
    "x - a ) where dmcs are considered .",
    "then , it follows from proposition  [ propositionbhtlowerbound ] and definition  [ defcode ] with the identifications @xmath256 , @xmath257 , @xmath258 , @xmath259 , @xmath260 and @xmath261 that @xmath262      using the dpi of @xmath263 by introducing @xmath20 and @xmath264 , we have @xmath265 where @xmath266 by  . combining , and  , we have @xmath267 fix any constant @xmath268 to be specified later . using lemma  [ lemmadpi ] , and",
    ", we have @xmath269 which together with implies that @xmath270      define term in   is replaced by @xmath271 for any @xmath272 . ]",
    "@xmath273 to be the set of power allocation vectors in @xmath274 that are close to the optimal power allocation vector @xmath275 ( cf .  )",
    ". following  , we use   to obtain @xmath276 in order to bound the first term in  , we let @xmath277 and define @xmath278 be the distribution induced by the @xmath279-modified code based on the @xmath249-feedback code defined in definition  [ definitiontransformedcode ] . then , consider the following chain of inequalities : @xmath280 where    * is due to lemma  [ lemmatransformedcode ] .",
    "* is due to the definition of @xmath255 in  .",
    "similarly , in order to bound the second term in  , we let @xmath281 be the distribution induced by the @xmath282-modified code and consider the following chain of inequalities for each @xmath283 : @xmath284 where    * is due to lemma  [ lemmatransformedcode ] . *",
    "is due to the definition of @xmath255 in  .",
    "combining  , , and the definition of @xmath130 in   followed by letting @xmath285 for each @xmath117 and each @xmath112 , we obtain @xmath286 where @xmath287 is as defined in  . in order to simplify the rhs of",
    ", we define @xmath268 such that @xmath288 in addition , for each @xmath289 , let @xmath290 for each @xmath112 . by using  , and together with the facts by   that @xmath291 and @xmath292 for each @xmath293 , we can express as @xmath294      in order to simplify the first term in  , we define @xmath296 for each @xmath112 and want to show that @xmath297 = \\lim_{n\\rightarrow \\infty}\\e_{p _ { \\boldsymbol{z}^n}^{*}}\\left[e^{\\frac{t}{\\sqrt{n } } \\sum\\limits_{k=1}^n v_k^{(\\mathbf{p}^*)}}\\right ] \\label{levythmeq1}\\end{aligned}\\ ] ] for all @xmath298 .",
    "to this end , recall the following statements due to the channel law :    1 .",
    "@xmath299 for all @xmath10 and all @xmath112 ; 2 .",
    "@xmath300 are independent ; 3 .",
    "@xmath16 and @xmath301 are independent for all @xmath112 .    for any @xmath302 and any  @xmath250 such that @xmath303 , since @xmath304 by   and @xmath305 for all @xmath117 , we have @xmath306 \\notag\\\\ *   & \\le \\e_{p_{\\boldsymbol{x}^n , \\boldsymbol{y}^n}^{*}}\\left[e^{\\frac{t}{\\sqrt{n } } \\sum\\limits_{k=1}^n u_k^{(\\mathbf{p}^*)}}\\right ] \\\\ *    & \\le \\e_{p_{\\boldsymbol{x}^n , \\boldsymbol{y}^n}^{*}}\\left[e^{\\frac{t}{\\sqrt{n}}\\sum\\limits_{k=1}^n u_k^{(\\mathbf{p}^*)}}\\cdot e^{t^2\\sum\\limits_{\\ell=1}^l\\frac{n_\\ell \\left(p_\\ell + l^2\\gamma-\\frac{1}{n}\\sum\\limits_{k=1}^n x_{\\ell , k}^2\\right ) } { 2(p_\\ell+n_\\ell)\\left(p_\\ell+n_\\ell+\\frac{tp_\\ell}{\\sqrt{n } } \\right)}}\\right ] , \\label{levythmeq1 * }   \\end{aligned}\\ ] ] which implies by straightforward calculations based on  , and the channel law that @xmath307 \\cdot e^{-t^2 l^2\\gamma \\sum\\limits_{\\ell=1}^l\\frac{n_\\ell } { 2(p_\\ell+n_\\ell)\\left(p_\\ell+n_\\ell+\\frac{tp_\\ell}{\\sqrt{n } } \\right ) } }   \\notag\\\\ & \\le \\e_{p_{\\boldsymbol{x}^n , \\boldsymbol{y}^n}^{*}}\\left[e^{\\frac{t}{\\sqrt{n } } \\sum\\limits_{k=1}^n u_k^{(\\mathbf{p}^*)}}\\right ] \\\\ &",
    "\\le \\e_{p_{\\boldsymbol{x}^n , \\boldsymbol{y}^n}^{*}}\\left[e^{\\frac{t}{\\sqrt{n } } \\sum\\limits_{k=1}^n v_k^{(\\mathbf{p}^*)}}\\right ] \\cdot e^{t^2 l^2\\gamma \\sum\\limits_{\\ell=1}^l\\frac {   n_\\ell } { 2(p_\\ell+n_\\ell)\\left(p_\\ell+n_\\ell+\\frac{tp_\\ell}{\\sqrt{n } } \\right)}}. \\label{levythmeq2}\\end{aligned}\\ ] ] for the sake of completeness , the derivation of   can be found in appendix  [ appendixc ] . combining and  , we conclude that holds for each @xmath302 . since the moment generating functions of @xmath308 and @xmath309 converge to the same function , it follows from curtiss theorem  ( * ? ? ?",
    "3 ) that @xmath310 recognizing that @xmath311 are independent zero - mean gaussian random variables with variance @xmath148 by the definition of @xmath312 in   and the definition of @xmath148 in  , we apply the central limit theorem  @xcite and obtain @xmath313 which together with   implies that @xmath314      in order to bound the second term in  , we consider a fixed  @xmath250 and want to show that there exists some @xmath315 such that @xmath316 for all @xmath293 .",
    "to this end , we first define the lagrangian function @xmath317 as @xmath318 where @xmath319 is the unique number that satisfies   and   and @xmath320 is defined for each @xmath117 as @xmath321 define @xmath322 . then for all @xmath293",
    ", we use taylor s theorem to obtain @xmath323 for some @xmath324 that lies on the line that connects @xmath244 and @xmath275 , where @xmath325 denotes the gradient which satisfies @xmath326 and @xmath327 denotes the hessian matrix that satisfies @xmath328 for the sake of completeness , the derivations of   and   are contained in appendix  [ appendixb ] .",
    "combining  , and  , we have for all @xmath293 @xmath329 which together with the definitions of  @xmath330 and  @xmath331 in   and   respectively implies that @xmath332 consequently , holds by setting @xmath333 following  , we consider for each @xmath283 @xmath334 where    * is due to  . *",
    "follows from the definition of  @xmath335 in  .",
    "following the standard approach for obtaining large deviation bounds , we apply markov s inequality on the rhs of   and obtain for each @xmath283 @xmath336}{e^{\\kappa n^{1/6}+ \\sqrt{\\mathrm{v}(\\mathbf{p}^*)}\\ , \\phi^{-1}(\\varepsilon+\\tau)}}. \\label{eqnbht8thchain}\\end{aligned}\\ ] ] in order to bound the rhs of  , consider the following chain of inequalities for each @xmath283 : @xmath337 & = \\left(\\prod_{\\ell=1}^l\\frac{s_\\ell+n_\\ell}{(1+n^{-1/2})s_\\ell+n_\\ell}\\right)^{n/2}e^{\\sum\\limits_{\\ell=1}^l\\left(\\frac{\\sqrt{n}s_\\ell}{2(s_\\ell+n_\\ell)}+\\frac{n_\\ell s_\\ell}{2(s_\\ell+n_\\ell)\\left(\\left(1+n^{-1/2}\\right)s_\\ell+n_\\ell\\right)}\\right)}\\label{eqnbht9thchaina}\\\\    & \\le \\left(\\prod_{\\ell=1}^l\\left(1-\\frac{n^{-1/2}s_\\ell}{(1+n^{-1/2})s_\\ell+n_\\ell}\\right)^{n/2}e^{\\frac{\\sqrt{n}s_\\ell}{2(s_\\ell+n_\\ell)}}\\right)e^{\\sum\\limits_{\\ell=1}^l\\frac{n_\\ell s_\\ell}{2(s_\\ell+n_\\ell)^2 } } \\\\ & \\le e^{\\sum\\limits_{\\ell=1}^l\\left ( \\frac{s_\\ell^2}{2((1+n^{-1/2})s_\\ell+n_\\ell)(s_\\ell+n_\\ell ) } + \\frac{n_\\ell s_\\ell}{2(s_\\ell+n_\\ell)^2}\\right ) } \\label{eqnbht9thchainb}\\\\ & \\le e^{\\sum\\limits_{\\ell=1}^l\\frac { s_\\ell}{2(s_\\ell+n_\\ell ) } } \\\\ & \\le e^{l/2},\\label{eqnbht9thchain}\\end{aligned}\\ ] ] where    * follows from straightforward calculations based on the definition of @xmath338 in  , the property of  @xmath281 in   and the channel law , which are elaborated in appendix  [ appendixd ] for the sake of completeness .",
    "* is due to the fact that @xmath339 for all @xmath340 .",
    "combining   and  , we have the following large deviation bound for each @xmath283 : @xmath341 following  , we use and   to obtain @xmath342      combining  , , , , and  , we have @xmath343 for all sufficiently large  @xmath22 , which together with   implies that @xmath344 since @xmath229 is arbitrary , it follows from   and definition  [ defdispersion ] that @xmath345",
    "as mentioned in section  [ subsecrelatedwork ] , the proof of  ( * ? ? ?",
    "2 ) which obtains upper bounds on the second - order asymptotics of dmcs with feedback can not be generalized to the parallel gaussian channel with feedback .",
    "indeed , the proof of theorem  [ thmmainresult ] follows the standard procedures for obtaining the second - order asymptotics of dmcs without feedback ( see , e.g. , ( * ? ? ?",
    "* proof of th .",
    "50 ) and  ( * ? ? ?",
    "iii ) ) except the following three novel ingredients :    1 .   instead of classifying transmitted codewords into polynomially many type classes based on their empirical distributions which is generally not possible for channels with continuous input alphabet",
    ", we discretize the transmitted power and classify the codewords into polynomially many type classes based on their discretized power types . in particular , the collection of _ power type classes _ @xmath274 in   plays a key role in our analysis , and there are polynomially many power type classes by  .",
    "the details can be found in section  [ stepainproof ] in the proof .",
    "curtiss theorem rather than berry - essen theorem is invoked to bound the information spectrum term ( the first term in  ) related to transmitted codewords whose types are close to the optimal power allocation . in particular , berry - essen theorem for bounded martingale difference sequences can not be used to bound the information spectrum term in the presence of feedback because each input symbol  @xmath6 belongs to an interval @xmath60 $ ] that grows unbounded as  @xmath22 increases . instead",
    ", we apply curtiss theorem to show that the distribution of the sum of random variables in the information spectrum term converges to some distribution generated from a sum of i.i.d .",
    "random variables ( i.e. , ) , thus facilitating the use of the usual central limit theorem  @xcite .",
    "the details can be found in section  [ stepbinproof ] .",
    "3 .   in order to bound the information spectrum term related to transmitted codewords whose types are far from the optimal power allocation ( the second term in  )",
    ", the usual approach is to bound the information spectrum term by an _",
    "average _ of exponentially many upper bounds where each upper bound is then further simplified by invoking chebyshev s inequality  ( * ? ? ?",
    "however , due to the presence of feedback , the information spectrum term can be expressed as only a sum ( instead of average ) of polynomially many upper bounds as shown in the second term in  . in order to control the _ sum _ of polynomially many upper bounds",
    ", we have to resort to large deviation bounds as shown in   rather than the weaker chebyshev s inequality .",
    "the details can be found in section  [ stepcinproof ] .      if the feedback link is absent , the third - order term of the optimal finite blocklenth rate @xmath53 is @xmath346 as shown in   in section  [ introduction ] .",
    "the third - order term can be obtained by applying berry - essen theorem to bound an information spectrum term ( analogous to the first term in  ) .    in the presence of feedback , theorem  [ thmmainresult ]",
    "shows that the third - order term is @xmath347 .",
    "if we want to compute an explicit upper bound on the third - order term using the current proof technique , an intuitive way is to invoke a non - asymptotic version of curtiss theorem that can measure the proximity between two distributions based on the proximity between their moment generating functions .",
    "however , such a non - asymptotic version of curtiss theorem does not exist to the best of our knowledge , which prohibits us from strengthening the current @xmath347 bound on the third - order term .",
    "it is worth noting that   and   in our proof break down if the moment generating functions are replaced with characteristic functions . if one can find a way to make characteristic functions amenable to our proof approach , then a non - asymptotic version of lvy s continuity theorem known as _",
    "essen s smoothing lemma _ ( see , e.g. , ( * ? ? ?",
    "1.5.2 ) ) may be invoked to tighten the third - order term herein .",
    "let @xmath118 and @xmath194 be the encoding functions of the @xmath114-feedback code and the @xmath186-modified code respectively for each @xmath117 and each @xmath112 . for",
    "any @xmath348 and any @xmath349 such that @xmath350 , \\ldots , \\left[\\begin{matrix } f_{1,n}(w , \\mathbf{y}^{n-1 } ) \\\\\\vdots\\\\ f_{l , n}(w , \\mathbf{y}^{n-1 } ) \\end{matrix } \\right]\\right)\\in \\gamma^{(\\gamma)}(\\mathbf{s } ) \\label{lemmatransformedcodeeq1}\\end{aligned}\\ ] ] and @xmath351 it follows from  , and   in definition  [ definitiontransformedcode ] that @xmath352,\\ldots , \\left[\\begin{matrix } f_{1,n}(w , \\mathbf{y}^{n-1 } ) \\\\\\vdots\\\\ f_{l , n}(w , \\mathbf{y}^{n-1 } ) \\end{matrix } \\right]\\right)= \\left ( \\left[\\begin{matrix } \\tilde f_{1,1}(w ) \\\\\\vdots\\\\ \\tilde f_{l,1}(w ) \\end{matrix } \\right ] , \\ldots , \\left[\\begin{matrix } \\tilde f_{1,n}(w , \\mathbf{y}^{n-1 } ) \\\\\\vdots\\\\ \\tilde f_{l , n}(w , \\mathbf{y}^{n-1 } ) \\end{matrix } \\right]\\right ) .",
    "\\label{lemmatransformedcodeeq3}\\end{aligned}\\ ] ] since   holds for any @xmath348 and @xmath349 that satisfy   and  , it follows that   holds for all @xmath134 .",
    "fix any @xmath221 and any @xmath302 .",
    "it suffices to show that @xmath353 = \\e_{p_{\\boldsymbol{x}^n , \\boldsymbol{y}^n}^{*}}\\left[e^{t\\sum\\limits_{k=1}^n v_k^{(\\mathbf{p}^*)}}\\right ] , \\label{appendixceq1 }   \\end{aligned}\\ ] ] which will then imply by using   that   holds . to this end",
    ", we consider the following chain of equalities for each @xmath354 : @xmath355 \\notag\\\\ & =   \\e\\left[\\e\\left[\\left.e^{t\\sum\\limits_{k=1}^{m } u_k^{(\\mathbf{p}^*)}}\\cdot e^{t^2\\sum\\limits_{\\ell=1}^l\\frac{n_\\ell \\left(np_\\ell   -\\sum\\limits_{k=1}^{m } x_{\\ell , k}^2\\right ) } { 2(p_\\ell+n_\\ell)\\left((1+t)p_\\ell+n_\\ell\\right)}}\\right|\\boldsymbol{x}^{m } , \\boldsymbol{z}^{m-1}\\right]\\right ] \\\\ & = e^{t\\sum\\limits_{\\ell=1}^l\\frac{p_\\ell}{2(p_\\ell+n_\\ell)}}\\sqrt{\\prod_{\\ell=1}^l\\frac{p_\\ell+n_\\ell}{(1+t)p_\\ell+n_\\ell } } \\cdot\\e\\left[\\e\\left[\\left.e^{t\\sum\\limits_{k=1}^{m-1 } u_k^{(\\mathbf{p}^*)}}\\cdot e^{t^2\\sum\\limits_{\\ell=1}^l\\frac{n_\\ell \\left(np_\\ell   -\\sum\\limits_{k=1}^{m-1 } x_{\\ell , k}^2\\right ) } { 2(p_\\ell+n_\\ell)\\left((1+t)p_\\ell+n_\\ell\\right)}}\\right|\\boldsymbol{x}^{m-1 } , \\boldsymbol{z}^{m-1}\\right ] \\right ] \\label{appendixceq2b }   \\end{aligned}\\ ] ] where   is due to the definition of  @xmath356 in   and the fact that @xmath357 and @xmath358 are independent .",
    "applying recursively from @xmath359 to @xmath360 , we have @xmath361 \\notag\\\\ & = \\left(\\prod_{\\ell=1}^l\\frac{p_\\ell+n_\\ell}{(1+t)p_\\ell+n_\\ell}\\right)^{n/2}e^{n\\sum\\limits_{\\ell=1}^l\\left(\\frac{tp_\\ell}{2(p_\\ell+n_\\ell)}+\\frac{t^2n_\\ell p_\\ell}{2(p_\\ell+n_\\ell)\\left((1+t)p_\\ell+n_\\ell\\right)}\\right)}. \\label{appendixceq3 }    \\end{aligned}\\ ] ] on the other hand , straightforward calculations based on the definition of  @xmath362 in   and the fact that @xmath363 are independent implies that @xmath364 & = \\left(\\prod_{\\ell=1}^l\\frac{p_\\ell+n_\\ell}{(1+t)p_\\ell+n_\\ell}\\right)^{n/2}e^{n\\sum\\limits_{\\ell=1}^l\\left(\\frac{tp_\\ell}{2(p_\\ell+n_\\ell)}+\\frac{t^2n_\\ell p_\\ell}{2(p_\\ell+n_\\ell)\\left((1+t)p_\\ell+n_\\ell\\right)}\\right)}. \\label{appendixceq4 }   \\end{aligned}\\ ] ] combining   and  , we obtain  .",
    "straightforward calculations based on   reveal that for all @xmath222 , we obtain that @xmath365 \\label{appendixbeq1}\\end{aligned}\\ ] ] and @xmath366 is a diagonal matrix that satisfies @xmath367 .",
    "\\label{appendixbeq2}\\end{aligned}\\ ] ] combining  , , and  , we have  @xmath368 .",
    "in addition , for any @xmath244 such that @xmath369 , it follows from   that @xmath370 for all @xmath117 , which then implies that   holds for all @xmath293 .",
    "let @xmath371 . fix any @xmath283 . due to  , it suffices to show that @xmath372 \\notag\\\\   & = \\left(\\prod_{\\ell=1}^l\\frac{s_\\ell+n_\\ell}{(1+t)s_\\ell+n_\\ell}\\right)^{n/2}e^{n\\sum\\limits_{\\ell=1}^l\\left(\\frac{ts_\\ell}{2(s_\\ell+n_\\ell)}+\\frac{t^2n_\\ell s_\\ell}{2(s_\\ell+n_\\ell)\\left((1+t)s_\\ell+n_\\ell\\right)}\\right)}. \\label{appendixdeq1 }   \\end{aligned}\\ ] ] replacing @xmath244 with @xmath275 in the steps leading to   and  , we obtain  .",
    "i.  a. ibragimov and y.  v. linnik , _ independent and stationary sequences of random variables _ , j.  f.  c. kingman ,",
    "ed.1em plus 0.5em minus 0.4emgroningen , netherlands : wolters - noordhoff publishing , 1971 ."
  ],
  "abstract_text": [
    "<S> this paper investigates the asymptotic expansion for the maximum coding rate of a parallel gaussian channel with feedback under the following setting : a peak power constraint is imposed on every transmitted codeword , and the average error probability of decoding the transmitted message is non - vanishing as the blocklength increases . </S>",
    "<S> it is well known that the presence of feedback does not increase the first - order asymptotics of the channel , i.e. , capacity , in the asymptotic expansion , and the closed - form expression of the capacity can be obtained by the well - known water - filling algorithm . </S>",
    "<S> the main contribution of this paper is a self - contained proof of an upper bound on the second - order asymptotics of the parallel gaussian channel with feedback . </S>",
    "<S> the proof techniques involve developing an information spectrum bound followed by using curtiss theorem to show that a sum of dependent random variables associated with the information spectrum bound converges in distribution to a sum of independent random variables , thus facilitating the use of the usual central limit theorem . </S>",
    "<S> combined with existing achievability results , our result implies that the presence of feedback does not improve the second - order asymptotics .    </S>",
    "<S> asymptotic expansion , curtiss theorem , feedback , parallel gaussian channel , second - order asymptotics </S>"
  ]
}