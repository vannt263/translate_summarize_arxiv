{
  "article_text": [
    "in quite a few domains related to combinatorial optimization , such as constraint solving @xcite , planning or scheduling @xcite , software environments have been designed to achieve good performances in expectation over a given distribution of problem instances .",
    "such environments usually rely on a portfolio of heuristics , leaving the designer with the issue of finding the best heuristics , or the best heuristics sequence , for his particular distribution of problem instances .",
    "the simplest solution naturally is to use the default heuristics , assumedly the best one on average on all problem instances .",
    "another approach , referred to as _ pilot or rollout _ method , iteratively optimizes the option selected at each choice point @xcite , while sticking to the default heuristics for other choice points . yet",
    "another approach , referred to as _ monte - carlo tree search _ ( mcts ) @xcite and at the origin of the best current computer - go players @xcite , has been proposed to explore the search space while addressing the exploration _ versus _ exploitation dilemma in a principled way ; as shown by @xcite , mcts provides an approximation to optimal bayes decision .",
    "the mcts approach , rooted in the multi - armed bandit ( mab ) setting @xcite , iteratively grows a search tree through tree walks . for each tree walk , in each node ( choice point ) the selection of the child node ( heuristics )",
    "is handled as a mab problem ; the search tree thus asymmetrically grows to explore the most promising tree paths ( the most promising sequences of heuristics ) .    whereas increasingly used today in sequential decision making algorithms including games @xcite , to our best knowledge mcts methods",
    "have rarely been used within the framework of combinatorial optimization , with the recent exception of @xcite .",
    "this paper investigates the application of mcts to job - shop scheduling , an np - hard combinatorial optimization problem . as each job - shop scheduling problem instance defines a deterministic optimization problem , the standard _",
    "upper confidence bound applied to tree _ ( uct ) framework used in @xcite does not apply .",
    "more precisely , the sought solution is the one with best payoff ( as opposed to the one with best payoff on average ) ; the mab problem nested in the uct thus is a max @xmath1-armed bandit problem @xcite . along this line",
    ", the randomized aspects in uct must be addressed specifically to fit deterministic problems .",
    "specifically , a critical difficulty lies in the randomized default handling of the choice points which are outside the current search tree ( in contrast , these choice points are dealt with using the default heuristics in the pilot methods ) .",
    "another difficulty , shared with most mcts applications , is to preserve the exploration/ exploitation trade - off when the problem size increases .",
    "a domain - aware randomized default handling is proposed in this paper , supporting a mcts - based scheduling approach called _ monte - carlo tree scheduling _",
    "mcs  is empirically validated , using well established greedy heuristics and the pilot methods based on these heuristics as baselines .",
    "the empirical evidence shows that pilot methods significantly outperform the best - known default heuristics ; mcs  significantly outperforms on the pilot methods for small problem sizes . for larger problem sizes , however , mcs  is dominated by the best pilot methods , which is partly explained from the experimental setting as the computational cost of the pilot methods is about 4 times higher than that of the mcs  one . that is , heuristic scheduling is more costly than random scheduling .    the paper is organized as follows .",
    "job - shop scheduling is introduced in section [ sec : scheduling ] , together with some basic greedy algorithms based on domain - specific heuristics called _ dispatching rules_. the generic pilot method is recalled in section [ sec : pilot ] .",
    "the general mcts ideas are introduced in section [ sec : mcts ] ; its adaptation to the job - shop scheduling problem is described and an overview of mcs  is given . and together with its application to combinatorial problems , and to the job - shop scheduling problem .",
    "section [ sec : experiments ] is devoted to the empirical validation of the proposed approach . after describing the experimental setting , the section reports on the mcs  results on different problem sizes , with the dispatching rules and the pilot methods as baselines .",
    "the paper concludes with a discussion of these results and some perspectives for further research .",
    "scheduling is the sequencing of the order in which a set of _ jobs _ @xmath2 are processed through a set of _ machines _ @xmath3 . in a _ job shop _ , the order in which a job is processed through the machines is predetermined . in a _ flow shop",
    "_ this order is the same for all jobs , and in a _ open shop _",
    "the order is arbitrary .",
    "we will consider here only the _ job shop _",
    ", where the jobs are strictly - ordered sequences of operations .",
    "a job can only be performed by one type of machine and each machine processes one job at a time .",
    "once a job is started it must be completed .",
    "the performance metric for scheduling problems is generally based on flow or dues date . here",
    "we will consider the completion time for the last job or the so called makespan .",
    "each job has a specified processing time @xmath4 and the order through the machines is given by the permutation vector @xmath5 ( @xmath6 is the @xmath7 machine for job @xmath8 ) .",
    "let @xmath9 be the start time for job @xmath8 on machine @xmath10 , then @xmath11 the disjunctive condition that each machine can handle at most one job at a time is the following : @xmath12 for all @xmath13 and @xmath14 .",
    "the makespan can then be formally defined as @xmath15    smaller problems can be solved using a specialized branch and bound procedure @xcite and an algorithmic implementation may be found as part of lisa @xcite .",
    "jobs up to 14 jobs and 14 machines can still be solved efficiently , but at higher dimensions , the problems rapidly become intractable .",
    "several heuristics have been proposed to solve job shop problems when their size becomes too large for exact methods .",
    "one such set of heuristics are based on _ dispatch rules _ ,",
    "i.e. rules to decide which job to schedule next based on the current state of all machines and jobs",
    ". a survey of over 100 such rules may be found in @xcite .",
    "commonly used priority dispatch rules have been compared on a number of benchmark problems in @xcite . when considering the makespan as a performance metric , the rule that selects a job which has the _ most work remaining _ ( mwkr , the job with the longest total remaining processing time ) performed overall best .",
    "it was followed by the rule that selects a job with the _ shortest processing time _ ( spt ) , and by the rule that selects a job which the _ least operation number _ ( lopn ) .",
    "these rules are among the simplest ones , and are by no means optimal .",
    "however , only these 3 rules will be considered in the remaining of this paper . in particular ,",
    "experimental results of the corresponding 3 greedy algorithms can be found in section [ sec : experiments ] .",
    "the simplest way to use any of these rules is to embed them in a greedy algorithm : the jobs are processed in the order given by the repeated application of the chosen rule .",
    "algorithm [ alg : greedy ] gives the pseudo - code of such an algorithm .",
    "the variable @xmath16 represents which machine is next in line for job @xmath8 ( more precisely machine @xmath17 ) .",
    "when starting with an empty schedule , one would set @xmath18 for @xmath19 and @xmath20 . at each step of the algorithm ,",
    "one job is chosen according to the dispatching rule * r * ( line [ lin : choosejob ] ) , and the job is scheduled on the next machine in its own list , i.e. , the pair ( job , machine ) is added to the partial schedule @xmath21 ( line [ lin : schedulejob ] ) ( @xmath22 denotes the concatenation of two lists ) .",
    "the _ pilot method _ @xcite or equivalently the _ rollout algorithm _ @xcite can enhance any heuristic by a simple look - ahead procedure .",
    "the idea is to add one - step look - ahead and hence apply greedy heuristics from different starting points .",
    "the procedure is applied repeatedly , effectively building a tree .",
    "this procedure is not unlike strategies used in game playing programs , that search a game trees for good moves . in all cases",
    "the basic idea is to examine all possible choices with respect to their future advantage .",
    "an alternative view is that of a sequential decision problem or dynamic programming problem where a solution is built in stages , whereby the components ( in our cases the jobs ) are selected one - at - a - time .",
    "the first @xmath1 components form a so called @xmath1-solution @xcite . in the same way as a schedule",
    "was built in stages in algorithm  [ alg : greedy ] , where the @xmath1-solution is the partial schedule @xmath23 .",
    "however , for the pilot method the decisions made at each stage will depend on a look - ahead procedure .",
    "the pilot method is then described in algorithm [ alg : pilot ] .",
    "the algorithm may seem a little more complicated than necessary , however , as will be seen in the next section this algorithm is a special case of monte carlo tree search .",
    "the heuristic rollout is performed @xmath24 times and each time adding a node to the tree .",
    "clearly if all nodes can be connected to a terminal node , the repetition may be halted before the budget @xmath24 is reached .",
    "this is not shown here for clarity .",
    "furthermore , a new leaf on the tree is chosen such that those closer to the root have priority else branches are chosen arbitrarily with equal probability . in some version of the pilot method ,",
    "the tree is not expanded breadth first manner but with some probability allows for depth first search .",
    "this would be equivalent to executing line  [ line : infty ] with some probability .",
    "this is also commonly used in mcts and is called progressive widening .    @xmath25 @xmath26 @xmath27    the greedy algorithm  [ alg : greedy ] is then used as the rollout algorithm on line  [ line : rollout ] . as will be seen in the following section ,",
    "the key difference between the mcts and pilot method is in the way a node is found to expand in the tree and the manner in which a rollout is performed .",
    "other details of the algorithm  [ alg : pilot ] will also become clearer .",
    "monte - carlo tree search inherits from the so - called multi - armed bandit ( mab ) framework @xcite .",
    "mab considers a set of independent @xmath1 arms , each with a different payoff distribution .",
    "here each arm corresponds to selecting a job to be dispatched and the payoff the results returned by a rollout or greedy heuristic .",
    "several goals have been considered in the mab setting ; one is to maximize the cumulative payoff gathered along time ( @xmath1-arm bandit ) @xcite ; another one is to identify the arm with maximum payoff ( max-@xmath1 arm ) @xcite . at one extreme is the exploitation - only strategy ( selecting the arm with best empirical reward ) ; at the other extreme is the exploration - only strategy ( selecting an arm with uniform probability ) .    when it comes to find a sequence of options , the search space is structured as a tree .",
    "in order to find the best sequence , a search tree is iteratively used and extended , growing in an asymmetric manner to focus the exploration toward the best regions of the search space . in each iteration",
    ", a tree path a.k.a simulation is constructed through three building blocks : the first one is concerned with navigating in the tree ; the second one is concerned with extending the tree and assessing the current tree path ( reward ) ; the third one updates the tree nodes to account for the reward of the current tree path .",
    "the search tree is initialized to the root node ( current partial schedule ) . in each given node until arriving at a leaf ,",
    "the point is to select among the child nodes of the current node ( fig .",
    "[ fig : mcts ] , left ) . for deterministic optimization problems ,",
    "the goal is to maximize the maximum ( rather than the expected ) payoff . for this aim ,",
    "a sound strategy has been introduced in @xcite and used in @xcite .",
    "this approach , referred to as chernoff rule , estimates the upper bound on the maximum payoff of the arm , depending on its number of visits and the maximum value gathered .",
    "however , the main goal of this work is to bridge the gap between the pilot method and mcts algorithms .",
    "indeed , the pilot method , as presented in algorithm  [ alg : pilot ] , can be viewed as an mcts algorithm in which the strategy used to chose next child to explore is to choose the best child after one deterministic rollout using the dispatch rule at hand",
    " a rather greedy exploitation - oriented strategy .",
    "such strategy is very close to a simple rule to balance exploration and exploitation known in the mcts world as @xmath28-greedy : with probability @xmath29 , one selects the empirically best child node . ]",
    "( i.e. the one with maximum empirical value ) ; otherwise , another uniformly selected child node is retained .",
    "furthermore , similar to the pilot method described in the previous section , unexplored nodes ( line : [ line : infty ] in algorithm[alg : pilot ] ) will have priority",
    ". however , line : [ line : maxval ] should be replaced by @xmath30.q\\ ] ] .      upon arriving in a leaf , a new option",
    "is selected and added as child node of the current one ; the tree is thus augmented of one new node in each simulation ( fig .",
    "[ fig : mcts ] , right ) .",
    "the simulation is resumed until arriving in a final state ( e.g. , when all jobs have been processed ) .",
    "as already mentioned , the choices made in the further choice points in the pilot method rely on the default heuristics ( and the rollout is hence deterministic ) . in the mcts method",
    "however , these choices must rely on randomized heuristics out of consistency with the mab setting .",
    "the question thus becomes which heuristics to use in the so - called random phase ( see section [ sec : domaink ] ) . upon arriving in a final state , the reward associated to the simulation",
    "is computed ( e.g. , the makespan of the current schedule ) .          the number of visits of the nodes of the current tree that were in the path is incremented by 1 ; likewise , the cumulative reward associated to these nodes is incremented by the reward associated to the current path .",
    "note that other statistics can be maintained in each node , such as the rave values @xcite , and must be updated there too .      as already pointed out , solving a combinatorial problem",
    "can be viewed as a sequential decision making process , incrementally building a solution by choosing an element of a partial solution at a time ( e.g. , next town for tsp problems , of next machine to schedule for the job shop scheduling problem ) . in order to solve this sequential decision problem through a mcts algorithm ,",
    "several specific issues must be considered .    a first issue concerning the reward design has a significant impact on the exploration _ versus _ exploitation dilemma ; it might require some instance - dependent parameter to reach a proper balance ( see e.g. , @xcite ) .",
    "indeed , in the case of job - shop scheduling for instance , different instances will have very different makespans .",
    "a second issue concerns the heuristics to be used in the random phase ( section [ sec : montecarlo ] ) .",
    "the original mcts method @xcite advocates pure random choices .",
    "domain knowledge could however be used to propose a smarter procedure , e.g. using random selected dispatching rules for job - shop scheduling .",
    "still , a lesson consistently learned from mcts applications @xcite is that doing many simulations completed with a brute random phase is more effective than doing less simulations completed with a smart final phase .",
    "for instance in the domain of computer - go , the overall results were degraded by using gnugo in the random phase , compared to a uniform move selection .",
    "likewise , the use of the three dispatching rules ( described in section [ sec : scheduling ] ) in the random phase was outperformed by a pure random strategy , uniformly selecting the next job to be considered .",
    "here we have chosen to follow this path and our rollout phase consists of the purely random dispatching of jobs . replacing this with line [ line : rollout ] in algorithm 2 , along with the @xmath0greedy policy , and the pilot method is transformed into mcts .",
    "another important detail must be taken into account : when performing random rollouts , we might forget the best choices found previously during the building of a schedule .",
    "for this reason , a global best found sequence is kept throughout the scheduling procedure .",
    "if a suboptimal choice is found in a later partial schedule ( @xmath1-solution ) , the globally better choice previously found during a random rollout will be forced . in some sense",
    "the idea here is similar to that of the fortified rollouts used by the pilot method @xcite .",
    "finally , in mcts , the stopping criterion is defined by the total number of simulations ( i.e. , rollouts here ) , and one single decision is taken after a complete tree exploration , chosen as the child of the root node with the maximum expected reward @xcite .",
    "the situation is rather different here , and , in this first approach to mcts for combinatorial optimization , similarly to the pilot method , a single tree exploration is done , with a limited budget in terms of number of rollouts",
    ". a complete schedule is then built by descending the tree and always choose the child with maximum expected reward ( makespan ) .",
    "this section reports on the experimental validation of the proposed approaches . after detailing the experimental setting ,",
    "the results of the mcs  method is reported and compared to the baseline methods , the greedy application of the three dispatching rules mwkr , spt and lopn ( section [ sec : scheduling ] ) , and the pilot methods built on these three dispatching rules ( section [ sec : pilot ] ) .",
    "all experiments have been conducted using the set of test instances proposed in @xcite .",
    "the machine orders for the jobs are randomly generated and the processing times are discrete values uniformly distributed between 1 and 200 .",
    "three different @xmath31 problem sizes were generated using this setup , @xmath32 , @xmath33 and @xmath34 .",
    "the optimal makespans for one hundred instances generated of each size was then found using brucker s branch and bound algorithm @xcite .",
    "a further four instance of size @xmath35 are also tested @xcite and compared with their best known solution @xcite .",
    "for all methods except the greedy ones , the time budget is varied to assess the convergence behavior of the pilot and mcs  optimization methods , considering a total of 100 , 1,000 and 5,000 rollouts a.k.a .",
    "each rollout corresponds to designing and evaluating a complete solution ( computing its total makespan ) .",
    "it is worth noting that not all rollouts are equally expensive ; the rollout based on a dispatching rule ( as used in the pilot methods ) is more computationally demanding than the random rollout used in mcs , all the more so as the size of the problem instance increases .",
    "nevertheless , the fixed rollout budget is meant to allow cpu - independent comparisons and assess the empirical behavior of the methods under restricted computational resources ( e.g. in real - world situations ) .    for each method , each problem size and each time budget , the result is given as the average over 100 problem instances of the normalized makespan ( 1 .",
    "being the optimal value ) , together with the minimum , maximum and median values , and the standard deviation ; the number of times where the optimal value was found is additionally reported .",
    "while the greedy and pilot algorithms actually are deterministic , mcs  is not . the usual way to measure",
    "the performance of a stochastic algorithm on a given problem domain is through averaging the result out of a few dozen or hundred independent runs . for the sake of computational convenience however",
    ", mcs  was run only once on each problem instance and the reported result is the average over the 100 independent instances .",
    "[ resultsdispatchrules ]    .greedy algorithms : performance statistics of the mwkr , spt and lopn rules on three problem sizes . [ cols=\"<,<,^,^,^,^,^,^\",options=\"header \" , ]",
    "the main contribution of this paper is to demonstrate the feasibility of using mcts to address job - shop scheduling problems .",
    "this result has been obtained by using the simplest exploration / exploitation strategy in mcts , the @xmath0-greedy strategy , defining the _ monte - carlo tree scheduling _ approach ( mcs ) .",
    "the empirical evidence gathered from the preliminary experiments presented here shows that mcs  significantly outperforms its competitors on small and medium size problems . for larger problem sizes",
    "however , the pilot method with the best dispatching rule outperforms this first verions of mcs .",
    "this fact is blamed on our adversary experimental setting , as we compared methods based on the number of rollouts , whereas the computational cost of a rollout is larger by almost an order of magnitude in the pilot framework , as compared to that of the mcs .",
    "the mcs  scalability can also be improved through reconsidering the exploration vs exploitation trade - off , ever more critical in larger - sized problem instances .",
    "first of all , the max - k - arm strategy should be tried in lieu of the simple @xmath0-greedy rule .",
    "furthermore , this tradeoff can be also adjusted by avoiding the systematic first trial of all possible children , as this becomes harmful for large number or arms ( jobs here ) .",
    "it is possible to control when a new child node should be added in the tree , and which one .",
    "regarding the former aspect , a heuristics referred to as _ progressive widening _ has been designed to limit the branching factor of the tree , e.g. @xcite . regarding the second aspect , the use of a rapid action value estimate ( rave ) , first developed in the computer - go context @xcite can be very efficient to aggregate the various rewards computed for the same option ( _ queen elisabeth _ ) , and guide the introduction of the most efficient rules / jobs in average .",
    "this work has shown how the pilot method may be considered a special case of mcts , with an exploratory - only strategy to traversing the tree and using a deterministic rollout driven by the pilot heuristic .",
    "it has demonstrated that the pilot method can be sensitive to the chosen pilot heuristic . as the chosen pilot heuristic becomes more effective ,",
    "so too may its computational costs .",
    "an extension of the pilot method in the realm of mcts algorithms , the mcs , has been proposed , using a simple @xmath28greedy strategy to traverse down the tree .",
    "however , more sophisticated strategies , such as the one based on the max-@xmath1 bandit problem @xcite , need now be investigated . for larger problems",
    ", progressive widening should be an avenue for further research , as similar strategies have already been investigated in the pilot framework .",
    "finally , rapid action value estimates may not only be used to bias how the tree is traversed , possibly replacing the exploration term in the bandit formulas , but can also help to improve over the random rollouts .",
    "lagoudakis , m.g . , parr , r. : reinforcement learning as classification : leveraging modern classifiers . in fawcett , t. , mishra , n. ,",
    "20th int . conf . on machine learning ( icml03 ) , aaai press ( 2003 ) 424431    kocsis , l. , szepesvri , c. : bandit based monte - carlo planning . in frnkranz , j. , scheffer , t. , spiliopoulou , m. ,",
    "eur . conf . on machine learning ( ecml06 ) ,",
    "lncs 4112 , springer verlag ( 2006 ) 282293          de  mesmay , f. , rimmel , a. , voronenko , y. , pschel , m. : andit - based optimization on graphs with application to library performance tuning . in danyluk ,",
    "a. , bottou , l. , littman , m. , eds .",
    "int . conf . on machine learning ( icml09 ) .",
    "volume 382 of acm international conference proceeding series . , acm ( 2009 ) 729736    rolet , p. , sebag , m. , teytaud , o. : boosting active learning to optimality : a tractable monte - carlo , billiard - based algorithm . in wray l. buntine",
    "et al . , ed . : proc .",
    "ecml / pkdd , lncs 5782 , springer verlag ( 2009 ) 302317                      cicirello , v. , smith , s. : the max _",
    "k_-armed bandit : a new model of exploration applied to search heuristic selection . in veloso , m.m . ,",
    "kambhampati , s. , eds . : proc .",
    "conf . on artificial intelligence , aaai press / the mit press ( 2005 ) 13551361    fialho , a. , da  costa , l. , schoenauer , m. , sebag , m. : dynamic multi - armed bandits and extreme value - based rewards for adaptive operator selection in evolutionary algorithms . in t.",
    "stuetzle et al . , ed . :",
    "3rd intl conf .",
    "on learning and intelligent optimization ( lion09 ) , lncs 5851springer verlag ( 2009 ) 176190"
  ],
  "abstract_text": [
    "<S> greedy heuristics may be attuned by looking ahead for each possible choice , in an approach called the rollout or pilot method . </S>",
    "<S> these methods may be seen as meta - heuristics that can enhance ( any ) heuristic solution , by repetitively modifying a master solution : similarly to what is done in game tree search , better choices are identified using lookahead , based on solutions obtained by repeatedly using a greedy heuristic . </S>",
    "<S> this paper first illustrates how the pilot method improves upon some simple well known dispatch heuristics for the job - shop scheduling problem . </S>",
    "<S> the pilot method is then shown to be a special case of the more recent monte carlo tree search ( mcts ) methods : unlike the pilot method , mcts methods use random completion of partial solutions to identify promising branches of the tree . the pilot method and a simple version of mcts , using the @xmath0-greedy exploration paradigms , are then compared within the same framework , consisting of 300 scheduling problems of varying sizes with fixed - budget of rollouts . </S>",
    "<S> results demonstrate that mcts reaches better or same results as the pilot methods in this context . </S>"
  ]
}