{
  "article_text": [
    "state estimation over noisy channels is a first step towards a complete theory of control of non - linear systems over noisy channels .",
    "the results in this area have either almost exclusively considered linear systems , or in the non - linear case only been on deterministic systems over deterministic channels , with few exceptions .",
    "state estimation over digital channels was studied in @xcite for linear discrete - time systems in a stochastic framework with the objective to bound the estimation error in probability . in these works ,",
    "the inequality@xmath2 for the channel capacity @xmath3 was obtained as a necessary and almost sufficient condition . here",
    "@xmath4 is the dynamical matrix of the system and the summation is over its eigenvalues @xmath5 with multiplicities @xmath6 . some relevant studies that have considered non - linear systems are the following .",
    "the papers @xcite , @xcite and @xcite studied state estimation for non - linear deterministic systems and noise - free channels . in @xcite , liberzon and mitra characterized the critical bit rate @xmath0 for exponential state estimation with a given exponent @xmath7 for a continuous - time system on a compact subset @xmath8 of its state space . as a measure for @xmath0",
    ", they introduced a quantity named estimation entropy @xmath9 , which coincides with the topological entropy on @xmath8 when @xmath10 , but for @xmath11 is no longer a purely topological quantity .",
    "furthermore , they derived an upper bound @xmath12 of @xmath9 in terms of @xmath13 , the dimension of the state space and a lipschitz constant of the dynamical system .",
    "they also provided an algorithm accomplishing the estimation objective with bit rate @xmath12 .",
    "the paper @xcite provided a lower bound on @xmath9 in terms of lyapunov exponents under the assumption that the system preserves a smooth measure . in @xcite , matveev and pogromsky studied three estimation objectives of increasing strength for discrete - time non - linear systems .",
    "for the weakest one , the smallest bit rate was again shown to be equal to the topological entropy . for the other ones , general upper and lower bounds were obtained which can be computed directly in terms of the linearized right - hand side of the equation generating the system .",
    "moreover , a concrete design of a coding and decoding / estimation scheme was provided , which achieves the strongest state estimation objective with a bit rate described in terms of singular values of the linearization .",
    "further related work for non - linear systems , mainly focusing on noiseless channels or erasure channels , includes @xcite .",
    "there also have been important relevant studies in the information theory community .",
    "the source coding theory exclusively deals with the state estimation problem under information - rate constraints . towards a further understanding of such a theory , we review shannon s rate - distortion function , which is defined operationally as follows : given a componentwise @xmath14-valued stochastic process @xmath15 , a _ rate - distortion _",
    "pair @xmath16 is achievable if given the source process @xmath17 , and a distortion function @xmath18 , there exist sequences of    1",
    ".   quantizers ( encoders ) : @xmath19 with @xmath20 and 2 .",
    "decoders : @xmath21 such that @xmath22 , @xmath23 , with@xmath24 \\leq d,\\quad \\lim_{n \\to \\infty } d_n \\leq d.\\ ] ]    the quantity @xmath25 is the ( operational ) _ rate - distortion _ function of the source at the distortion level @xmath26 . the case where @xmath27 constitutes an important special setting . in the information theory community ,",
    "the study of problems on state estimation has almost exclusively focused on stationary processes . for a class of such processes",
    ", the rate - distortion function admits a simple formula , often referred to as _ a single - letter characterization_. we also note that if the source process is a finite - valued stationary and ergodic process , the rate - distortion function with @xmath28 reduces to the metric entropy of the source .",
    "as noted , there have been few contributions in the information theory literature on non - causal coding of non - stationary / unstable sources .",
    "these have only , to our knowledge , focused on gaussian linear models : consider the gaussian auto - regressive ( ar ) process@xmath29 where @xmath30 is an i.i.d .  zero - mean , gaussian random sequence with variance @xmath31 = \\sigma^2 $ ] .",
    "if the roots of the complex polynomial @xmath32 are all in the interior of the unit disk , then the process is asymptotically stationary and its rate - distortion function ( with the distortion being the expected , normalized euclidean error ) is given parametrically by the following @xcite , obtained by considering the asymptotic distribution of the eigenvalues of the correlation matrix:@xmath33 where @xmath34 .",
    "if at least one root is on the unit circle or outside the unit disk , the analysis is more involved as the asymptotic eigenvalue distribution contains unbounded components .",
    "gray and hashimoto ( see @xcite ) have shown , using the properties of the eigenvalues as well as jensen s formula for integrations along the unit circle , that @xmath35 above should be replaced by@xmath36 where @xmath37 are the roots of the polynomial @xmath38 .",
    "it is important to emphasize that the second term on the right - hand side of the equation is exactly the topological entropy for a linear system with eigenvalues @xmath39 . on related problems ,",
    "berger @xcite obtained the rate - distortion function for wiener processes , and in addition , developed a two - part coding scheme , which was later generalized in @xcite and @xcite to unstable markov processes driven by bounded noise .",
    "it is useful to note that , when @xmath14 is finite , the source @xmath40 is stationary , and @xmath28 , the solution to the operational problem stated above is given by the _ entropy rate _ of the source , i.e.  @xmath41})$ ] .",
    "we also note that the above formulation is what is known as a non - causal construction .",
    "when one also inserts causality constraints , the problem typically becomes far more challenging , even when the source process is an i.i.d .",
    "process , because in this case the optimization problem becomes non - convex ( * ? ? ?",
    "* ch .  5 ) .",
    "we refer the reader to @xcite and ( * ? ? ?",
    "* ch .  5 ) on further subtle differences between causal and non - causal coding of stochastic processes .",
    "structural results , see e.g.  ( * ? ? ?",
    "10 ) , @xcite for finite horizon problems , and @xcite for asymptotic average - distortion criteria , are available ; in addition explicit bounds for the low - distortion regime building on shannon s lower bound are available in the literature , see notably @xcite .",
    "the findings in @xcite are particularly relevant to our study here , since they consider infinite - horizon criteria .",
    "a related problem is the control of stochastic non - linear systems over communication channels .",
    "this problem has been studied in few publications , and mainly only for deterministic systems or deterministic channels .",
    "recently , @xcite studied stochastic stability properties such as asymptotic mean stationarity , ergodicity and non - positive normalized state entropy for a more general class of stochastic non - linear systems .",
    "the analysis in @xcite builds on information - theoretic bounds and markov - chain - theoretic constructions , however these bounds do not distinguish between the unstable and stable components of the tangent space associated with a dynamical non - linear system , except for the linear system case .",
    "our paper here provides such a refinement , but only for estimation problems and in the low - distortion regime .",
    "we also mention a different approach that can be found in @xcite . in this paper , a general theory of non - stochastic information was developed , and for exponential state estimation with a given exponent @xmath11 over an uncertain channel , a characterization of the critical bit rate similar to was obtained .",
    "in the present paper , we consider stochastic non - linear systems of the form @xmath42 with @xmath43 being an i.i.d .  sequence of random variables distributed according to a common probability @xmath44 , modeling the noise .",
    "the initial state @xmath45 is assumed to be a random variable , independent of the noise , distributed with @xmath46 .",
    "we assume that the system is estimated via a noisy channel with feedback of a very general form ( a so - called class a type channel , cf .",
    "@xcite ) . at time @xmath47",
    ", the estimator generates an estimate @xmath48 of the state @xmath40 , using the information it has received through the channel up to this time .",
    "we consider three estimation objectives of different strength for a given @xmath49 , describing the accuracy of the estimation :    1 .",
    "eventual almost sure stability of the estimation error : @xmath50 for all @xmath51 almost surely .",
    "asymptotic almost sure stability of the estimation error : @xmath52 .",
    "asymptotic quadratic stability in expectation : @xmath53 \\leq \\epsilon$ ] .",
    "we study the smallest channel capacity @xmath54 above which a coder and a decoder / estimator can be designed achieving one of these objectives , and in particular @xmath55 . in the case when the channel is noiseless , we view the state process as a shift dynamical system on the space of trajectories and we relate the capacity of the channel with the topological entropy of this shift restricted to the support of the stochastic process .",
    "this approach is new , to our knowledge , for the study of such stochastic processes .",
    "in particular , we prove that @xmath0 for the objectives ( e1 ) and ( e2 ) is bounded below by the topological or metric entropy of a shift dynamical system on the space of ( typical ) trajectories of the system , respectively .",
    "this entropy is typically infinite , because the noise in the system generates so many possible trajectories that the space of relevant trajectories becomes infinite - dimensional .",
    "the result , in the noise - free source and channel case , reduces to the existing results in the literature for deterministic setups .",
    "the information - theoretic approach allows for results that do not require a compact state space or strong continuity conditions on the dynamical system .",
    "we show that essentially if the entropy rate of the source process is positive , @xmath0 can not be finite for asymptotically small estimation errors for all three estimation objectives .",
    "we also establish connections with high - rate quantization theory .",
    "another approach considered in the present paper views the given system as a random dynamical system whose base space consists of all noise realizations . through this approach , we can show that for compact state spaces and noiseless channels , @xmath0 is bounded below by the entropy of the random dynamical system for ( e1 ) and ( e2 ) .",
    "essentially , this implies that positive lyapunov exponents are an obstruction to a state estimation with zero capacity .",
    "this is in correspondence with the results of the deterministic theory , but in view of the results described above , exhibits this approach as non - adequate for the problem , since the lower bounds obtained here are finite under mild assumptions .",
    "finally , we prove that for noiseless dynamical systems with finite topological entropy , state estimation over a discrete memoryless channel of finite capacity is possible for ( e2 ) , and in this case @xmath0 is bounded above by the topological entropy .",
    "however , the coding and estimation policy used to prove this result is highly impractical to implement .",
    "we show that for linear systems and erasure channels , a more realistic coding and estimation policy exists .",
    "the zero - noise results in this paper essentially coincide with the results in the literature on deterministic setups for either when the system noise is absent or the channel noise is absent .",
    "our findings are also new in the information theory literature , where the estimation error results have exclusively focused on stable sources , except for linear models , as reviewed above .",
    "one main message conveyed by our results is that typically none of above estimation objectives can be achieved over a channel of finite capacity with an arbitrarily small estimation error , i.e. , @xmath1 .",
    "more specifically , this is the case whenever the noise in the system influences the dynamics to such an extent that a recovery of the state with some accuracy @xmath56 would allow a recovery of a sufficiently large part of the noise realization with an accuracy of the same order .",
    "this is made precise in several theorems , using principally different methodologies .",
    "the present paper is organized as follows .",
    "section [ sec_prelim ] introduces some concepts and notations from dynamical systems and information theory and provides a detailed exposition of the state estimation problems studied in the subsequent sections . in section [ sec_noiseless_compact ]",
    "we derive lower bounds for the almost sure estimation objectives in terms of the entropy of an associated dynamical system on the space of trajectories , assuming a noiseless channel .",
    "the subsequent section [ sec_information_theory ] is dedicated to the information - theoretic approach . here",
    "we assume that the state space is @xmath57 and impose no restrictions on the channel .",
    "for all three estimation objectives , we formulate sufficient conditions for @xmath1 . furthermore , for positive @xmath56 , finite lower bounds for @xmath54",
    "are derived .",
    "section [ sec_rds ] contains the lower bound result obtained via the random dynamical systems view . in section [ sec_positive ]",
    ", it is shown that a memoryless channel of finite capacity is sufficient to achieve ( e2 ) if there is no noise in the system .",
    "finally , in section [ sec_conclusion ] some concluding remarks are presented .",
    "[ [ subsec_notation ] ] notation and definitions .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + +    all logarithms in this paper are taken to the base @xmath58 . if @xmath59 is a measurable map between measurable spaces @xmath60 and @xmath61 , we write @xmath62 for the push - forward operator associated with @xmath63 on the space of measures on @xmath60 , i.e. , for any measure @xmath64 on @xmath60 , @xmath65 is the measure on @xmath61 defined by @xmath66 for all @xmath67 . using this notation ,",
    "the invariance of a measure @xmath64 under a map @xmath68 can be expressed by writing @xmath69 .",
    "an important concept used in this paper is the topological entropy of a dynamical system .",
    "if @xmath70 is a continuous map on a metric space @xmath71 , and @xmath72 is a compact set , we say that @xmath73 is @xmath74-separated for some @xmath75 and @xmath49 if for all @xmath76 with @xmath77 , @xmath78 for some @xmath79 . we write @xmath80 for the maximal cardinality of an @xmath74-separated subset of @xmath8 and",
    "define the topological entropy @xmath81 of @xmath63 on @xmath8 by@xmath82 if @xmath83 is compact and @xmath84 , we also omit the argument @xmath8 and call @xmath85 the topological entropy of @xmath63 .",
    "alternatively , one can define @xmath81 using @xmath86-spanning sets .",
    "a set @xmath87 @xmath86-spans another set @xmath72 if for each @xmath88 there is @xmath89 with @xmath90 for @xmath91",
    ". letting @xmath92 ( or @xmath93 if the map @xmath63 is clear from the context ) denote the minimal cardinality of a set which @xmath86-spans @xmath8 , the topological entropy of @xmath63 on @xmath8 satisfies@xmath94 if @xmath70 is a measure - preserving map on a probability space @xmath95 , i.e. , @xmath69 , its metric entropy @xmath96 is defined as follows .",
    "let @xmath97 be a finite measurable partition of @xmath83 .",
    "then the entropy of @xmath63 with respect to @xmath97 is defined by@xmath98 here @xmath99 denotes the join operation , i.e. , @xmath100 is the partition of @xmath83 consisting of all intersections of the form @xmath101 with @xmath102 . for any partition @xmath103 of @xmath83 , @xmath104 .",
    "the existence of the limit in follows from a subadditivity argument .",
    "the metric entropy of @xmath63 is then defined by@xmath105 where the supremum is taken over all finite measurable partitions @xmath97 of @xmath83 .",
    "if @xmath63 is continuous , @xmath83 is compact metric and @xmath64 is ergodic , there is an alternative characterization of @xmath96 due to katok @xcite : for any @xmath75 , @xmath49 and @xmath106 put@xmath107    then for every @xmath106 it holds that@xmath108 topological and metric entropy are related to each other via the variational principle : for a continuous map @xmath68 on a compact metric space @xmath83,@xmath109 where the supremum is taken over all @xmath63-invariant borel probability measures .",
    "we will also use several concepts from information theory .",
    "let @xmath110 be an @xmath14-valued random variable , where @xmath14 is countable .",
    "the _ entropy _ of @xmath110 is defined as @xmath111 where @xmath112 is the probability mass function ( pmf ) of the random variable @xmath110 .",
    "if @xmath110 is an @xmath113-valued random variable , and the probability measure induced by @xmath110 is absolutely continuous with respect to the lebesgue measure , the _ ( differential ) entropy _ of @xmath110 is defined by @xmath114 where @xmath115 is the probability density function ( pdf ) of @xmath110 .",
    "the _ mutual information _ between a discrete ( continuous ) random variable @xmath110 , and another discrete ( continuous ) random variable @xmath116 , defined on a common probability space , is defined as @xmath117 where @xmath118 is the entropy of @xmath110 ( differential entropy if @xmath110 is a continuous random variable ) , and @xmath119 is the conditional entropy of @xmath110 given @xmath116 ( @xmath120 is the conditional differential entropy if @xmath110 is a continuous random variable ) . for more general settings including when",
    "the random variables are continuous , discrete or a mixture of the two , mutual information is defined as @xmath121 where @xmath122 and @xmath123 are quantizers with finitely many bins ( see ( * ? ? ?",
    "* ch .  5 ) ) .",
    "an important relevant result is the following .",
    "let @xmath110 be a random variable and @xmath124 be a quantizer applied to @xmath110 .",
    "then , @xmath125 .",
    "for a concise overview of relevant information - theoretic concepts , we refer the reader to ( * ? ? ?",
    "* ch .  5 ) .",
    "for a more complete coverage , see @xcite .",
    "when the realization @xmath110 of a random variable @xmath40 needs to be explicitly mentioned , the event @xmath126 will be emphasized .",
    "we use the conditional probability ( expectation ) notation @xmath127 ( @xmath128 $ ] ) to denote @xmath129 ( @xmath130 $ ] ) . throughout the paper , we assume that all random variables are modeled on a common probability space @xmath131 .",
    "[ [ stochastic - networked - systems - and - estimation - objectives . ] ] stochastic networked systems and estimation objectives . + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    in this paper , we consider non - linear noisy systems given by an equation of the form@xmath132 here @xmath40 is the state at time @xmath47 and @xmath43 is an i.i.d",
    ".  sequence of random variables with common distribution @xmath133 , modeling the noise . in general , we assume that@xmath134 is a borel measurable map , where @xmath83 and @xmath135 are polish spaces , so that for any @xmath136 the map @xmath137 is a homeomorphism of @xmath83 .",
    "we further assume that @xmath45 is a random variable on @xmath83 with an associated probability measure @xmath138 , independent of @xmath43 .",
    "we use the notations@xmath139    this system is connected over a noisy channel with a finite capacity to an estimator , as shown in fig .",
    "the estimator has access to the information it has received through the channel .",
    "a source coder maps the source symbols ( i.e. , state values ) , to corresponding channel inputs .",
    "the channel inputs are transmitted through the channel ; we assume that the channel is a discrete channel with input alphabet @xmath140 and output alphabet @xmath141 .    , width=377,height=68 ]    we refer by a _ coding policy _",
    "@xmath142 , to a sequence of functions @xmath143 which are causal such that the channel input at time @xmath47 , @xmath144 , under @xmath142 is generated by a function of its local information , i.e.,@xmath145 where @xmath146 } , q'_{[0,t-1]}\\}$ ] and @xmath144 , the channel input alphabet given by @xmath147 for @xmath148 . here",
    ", we use the notation @xmath149 } = \\{x_s , 0 \\leq s \\leq t-1 \\}$ ] for @xmath150 .",
    "the channel maps @xmath151 to @xmath152 in a stochastic fashion so that @xmath153 } , q'_{[0,t-1]})$ ] is a conditional probability measure on @xmath141 for all @xmath154 .",
    "if this expression is equal to @xmath155 , the channel is said to be memoryless , i.e. , the past variables do not affect the channel output @xmath152 given the current channel input @xmath151 .    even though many of our results will focus on discrete memoryless channels ( dmc )",
    ", we will have occasions to study more general channels .",
    "in particular , we consider the following class of channels ( see ( * ? ? ?",
    "8.5.1 ) ) .",
    "[ classachanneldefinition ] a channel is said to be of class a type , if    * it satisfies the following markov chain condition:@xmath156 } , q'_{[0,t-1 ] } \\leftrightarrow \\{x_{0 } , w_s , s \\geq 0\\},\\label{classamarkov}\\ ] ] i.e. , almost surely , for all borel sets @xmath157,@xmath158 } , q'_{[0,t-1 ] } , x_{0 } , w_s , s \\geq 0 ) = p(q'_t \\in b| q_t , q_{[0,t-1 ] } , q'_{[0,t-1]})\\ ] ] for all @xmath159 , and * its capacity with feedback is given by@xmath160},q'_{[0,t-1]}),\\ 0 \\leq t \\leq t-1\\ } } \\frac{1}{t } i(q_{[0,t-1 ] } \\to q'_{[0,t-1]}),\\ ] ] where the directed mutual information is defined by@xmath161 } \\to q'_{[0,t-1 ] } ) : = \\sum_{t=1}^{t-1 } i(q_{[0,t]};q'_t|q'_{[0,t-1 ] } ) + i(q_0;q'_0).\\ ] ]    discrete noiseless channels and memoryless channels belong to this class ; for such channels , feedback does not increase the capacity @xcite .",
    "class a type channels also include finite state stationary markov channels which are indecomposable @xcite , and non - markov channels which satisfy certain symmetry properties @xcite .",
    "further examples can be found in @xcite .",
    "the receiver , upon receiving the information from the channel , generates an estimate @xmath48 at time @xmath47 , also causally : an admissible causal estimation policy is a sequence of functions @xmath162 such that @xmath163})$ ] with@xmath164    for a given @xmath49 , we denote by @xmath54 the smallest channel capacity above which there exist an encoder and an estimator so that one of the following estimation objectives is achieved :    1 .",
    "eventual almost sure stability of the estimation error : there exists @xmath165 so that@xmath166 2 .",
    "asymptotic almost sure stability of the estimation error:@xmath167 3 .",
    "asymptotic quadratic stability of the estimation error in expectation:@xmath168 \\leq \\epsilon.\\ ] ]    it is easy to see that implies and ( with @xmath169 ) . on the other hand , and do not imply one another in general ; one can construct examples where one holds and the other does not .",
    "the primary goal of the paper is to find @xmath54 and in particular@xmath170 observe that this limit exists as a number in @xmath171 $ ] , since @xmath54 is non - decreasing as @xmath172 .",
    "in this section , we assume that the channel is noiseless . under this assumption ,",
    "we derive lower bounds of @xmath0 for the estimation objectives and .",
    "we consider the space @xmath173 of all sequences in @xmath83 , equipped with the product topology .",
    "we write @xmath174 for the elements of @xmath173 and we fix the product metric@xmath175 where @xmath176 is the given metric on @xmath83 . a natural dynamical system on @xmath173",
    "is the shift map @xmath177 , @xmath178 , which is continuous with respect to the product topology .",
    "an analogous shift map is defined on @xmath179 and denoted by @xmath180 . observing that the sequence of random variables @xmath181 forms a markov chain , when @xmath45 is fixed , the following lemma shows how a stationary measure of this markov chain defines an invariant measure for @xmath182 .",
    "[ lem_mu ] let @xmath183 be a stationary measure of the markov chain @xmath181 .",
    "then an invariant borel probability measure @xmath64 for @xmath182 is defined on cylinder sets by@xmath184 where @xmath185 are arbitrary borel sets in @xmath83 .",
    "here@xmath186 the support of @xmath64 is contained in the closure of the set of all trajectories , i.e.,@xmath187    we consider the map@xmath188 which maps a pair @xmath189 with @xmath190 to the trajectory @xmath181 obtained by @xmath191 .",
    "we claim that this map is measurable and its associated push - forward operator on measures maps @xmath192 to @xmath64 . to prove that @xmath193 is measurable , consider a cylinder set @xmath194 in @xmath173 .",
    "then@xmath195 hence , @xmath196 can be expressed as the preimage of @xmath197 under the map@xmath198 to show that this map is measurable , it suffices to show that each component is a measurable map .",
    "this follows from the fact that the projection @xmath199 to the first @xmath200 components is measurable and @xmath63 is measurable .",
    "hence , we have proved that @xmath193 is measurable . to see that @xmath201 , observe that for a set of the form @xmath202 we have@xmath203 for more general cylinder sets , the claim follows inductively .",
    "the fact that @xmath204 is contained in @xmath205 follows from@xmath206({\\mathrm{cl}}{\\mathcal{t } } ) = \\pi_0 { \\times}\\nu^{{\\mathbb{z}}_+}(g^{-1}({\\mathrm{cl}}{\\mathcal{t } } ) ) \\geq \\pi_0 { \\times}\\nu^{{\\mathbb{z}}_+}(g^{-1}({\\mathcal{t}}))\\\\                   & = \\pi_0 { \\times}\\nu^{{\\mathbb{z}}_+}(g^{-1}(g(x { \\times}w^{{\\mathbb{z}}_+ } ) ) ) = \\pi_0 { \\times}\\nu^{{\\mathbb{z}}_+}(x { \\times}w^{{\\mathbb{z}}_+ } ) = 1.\\ ] ] finally , we show that @xmath64 is @xmath182-invariant . to this end , note that the map @xmath207 , @xmath208 , satisfies @xmath209 . using that@xmath210 i.e. , @xmath211 , we find that@xmath212 completing the proof",
    ".    the next lemma will be useful to relate @xmath0 for the estimation objective to the topological entropy of the shift map @xmath182 .",
    "[ lem_entr_timeshift ] let @xmath68 be a homeomorphism on a compact metric space @xmath71 .",
    "fix @xmath49 and @xmath213 .",
    "for @xmath214 we say that a set @xmath215 is @xmath216-separated if @xmath78 for some @xmath217 , whenever @xmath76 with @xmath77 .",
    "we write @xmath218 for the maximal cardinality of an @xmath216-separated set .",
    "then , for any choice of @xmath219 , @xmath49 , we have@xmath220    any @xmath221-separated set is trivially @xmath86-separated , hence @xmath222 , implying the inequality `` @xmath223 '' in .",
    "conversely , assume that @xmath224 is @xmath86-separated and put @xmath225",
    ". then @xmath226 and @xmath227 is @xmath228-separated .",
    "this implies@xmath229 letting @xmath230 on both sides , we find that@xmath231 finally , letting @xmath232 , the desired inequality follows .    [ thm_topent_lb ] consider the estimation objective for an initial measure @xmath138 which is stationary under the markov chain @xmath181 .",
    "if @xmath204 is not compact , we have @xmath1 . otherwise,@xmath233 as a consequence , the metric entropy of @xmath182 with respect to @xmath64 is also a lower bound of @xmath0 .",
    "assume that for some @xmath49 the objective is achieved by a pair of coder and estimator via a noiseless channel of capacity @xmath234 .",
    "then for every @xmath235 we define the set@xmath236 of all possible estimation sequences of length @xmath237 the estimator can generate in the time interval @xmath238 $ ] .",
    "assume to the contrary that there exists a measurable set @xmath239 of positive measure @xmath240 so that for every @xmath241 there exists @xmath51 with @xmath242 in case the sequence @xmath243 is realized as a trajectory of the system .",
    "if @xmath244 is the map from the proof of lemma [ lem_mu ] , then the preimage @xmath196 is measurable in @xmath245 with @xmath192-measure @xmath11 .",
    "this contradicts the assumption that the almost sure estimation objective is achieved .",
    "hence , the set@xmath246 has measure one and consequently is dense in @xmath204 .",
    "choose @xmath247 large enough so that@xmath248 let @xmath249 be a finite @xmath250-separated set for some @xmath251 . since @xmath252 is dense in @xmath204 , a small perturbation of @xmath224 yields a @xmath250-separated set in @xmath252 with the same cardinality as @xmath224 ( using that @xmath182 is continuous ) .",
    "hence , we may assume @xmath253 .",
    "we define a map @xmath254 by assigning to @xmath255 the estimation sequence generated by the estimator when it receives the signals @xmath256 for @xmath257 .",
    "assuming @xmath258 for some @xmath259 , we find for @xmath260 that@xmath261 implying @xmath262 , since @xmath224 is @xmath250-separated .",
    "hence , the map @xmath13 is injective .",
    "the set @xmath204 is a closed subset of the complete metric space @xmath263 , hence it is also a complete metric space .",
    "if we assume that @xmath204 is not compact , it thus follows that @xmath204 is not totally bounded , implying that @xmath250-separated subsets of @xmath204 of arbitrarily large ( finite ) cardinality exist .",
    "hence , @xmath264 must be infinite , leading to the contradiction @xmath265 .",
    "hence , in this case the estimation problem can not be solved via a channel of finite capacity .",
    "now assume that @xmath204 is compact . choosing a maximal @xmath250-separated set @xmath224 , for the dynamical system",
    "@xmath266 we obtain the inequality@xmath267 this implies@xmath268 using lemma [ lem_entr_timeshift ] , the result follows by letting @xmath269 and @xmath232 .",
    "the statement about the metric entropy now follows from the variational principle .    to make the statement of the theorem clearer ,",
    "let us consider the two extreme cases when there is no noise and when there is only noise :    1 .",
    "if the system is deterministic , i.e. , @xmath270 for a homeomorphism @xmath68 of a compact metric space @xmath83 , then @xmath138 is an invariant measure of @xmath63 .",
    "moreover , @xmath271 if @xmath272 and @xmath273 otherwise , implying@xmath274 from this expression , we see that the support of @xmath64 is contained in the set @xmath275 of all trajectories of @xmath63 ( which in this case coincides with its closure ) , as already proved in lemma [ lem_mu ] . the map @xmath276 defined by @xmath277 , is easily seen to be a homeomorphism , which conjugates @xmath278 and @xmath63 .",
    "that is , the following diagram commutes:@xmath279 since @xmath280 and conjugate systems have the same entropy , our theorem implies@xmath281 the right - hand side of this inequality is finite under mild assumptions , e.g. , if @xmath63 is lipschitz continuous on @xmath282 and @xmath282 has finite upper box dimension ( see @xcite ) .",
    "these conditions are in particular satisfied when @xmath63 is a diffeomorphism on a finite - dimensional manifold .",
    "however , one should be aware that even on a compact interval there exist continuous maps with infinite topological entropy on the support of an invariant measure . 2 .",
    "assume that @xmath283 is compact and the system is given by @xmath284 , i.e. , the trajectories are only determined by the noise . in this case , with @xmath285 , the measure @xmath64 is the product measure @xmath286 .",
    "hence , @xmath0 is bounded below by the topological entropy of the shift on @xmath179 restricted to @xmath287 .",
    "this number is finite if and only if @xmath288 is finite and in this case is given by @xmath289 .",
    "if the system is not deterministic , then usually @xmath1 .",
    "in fact , this is always the case if the estimator is able to recover the noise to a sufficiently large extent .",
    "the following corollary treats the case , when the noise can be recovered completely from the state trajectory .    additionally to the assumptions in theorem [ thm_topent_lb ] ,",
    "suppose that @xmath135 and @xmath83 are compact and @xmath290 is invertible for every @xmath291 so that @xmath292 is continuous .",
    "then@xmath293 where @xmath207 is the skew - product map @xmath294 . as a consequence , @xmath1 whenever @xmath288 contains infinitely many elements .",
    "we consider the map @xmath295 , @xmath296 with@xmath297 if we equip @xmath179 with the product topology , @xmath298 becomes continuous .",
    "indeed , if the distance of two points @xmath299 is small , then the distances @xmath300 are small for finitely many values of @xmath47 . hence , by the uniform continuity of @xmath301 on the compact space @xmath302 , also the distances @xmath303 can be made small for sufficiently many values of @xmath47 , guaranteeing that @xmath304 becomes small , where @xmath26 is a product metric on @xmath179 .",
    "the map @xmath305 , used in the proof of lemma [ lem_mu ] , satisfies@xmath306 because we can write@xmath307 consequently , @xmath193 - as a map from @xmath245 to the space @xmath275 of trajectories - is invertible with@xmath308 from the assumptions it follows that @xmath193 is continuous , hence @xmath193 is a homeomorphism and @xmath275 is compact . by the proof of lemma [ lem_mu ] , we have @xmath209 , where @xmath309 is the skew - product map @xmath310 and @xmath311 .",
    "hence , @xmath193 is a topological conjugacy between @xmath312 and @xmath313 , implying@xmath314 since the projection map @xmath315 exhibits @xmath180 as a topological factor of @xmath309 and @xmath316 , the second inequality in follows .",
    "let @xmath317 .",
    "let @xmath318 and let @xmath319 be the normalized lebesgue measure on @xmath320 . in this case , the map @xmath321 , @xmath322 , is obviously invertible and @xmath323 is continuous .",
    "hence , @xmath1 for the estimation objective .",
    "now we consider the asymptotic estimation objective .",
    "[ thm_metricent_lb_det ] consider the estimation objective for an initial measure @xmath138 which is stationary and ergodic under the markov chain @xmath181 .",
    "then , if @xmath204 is compact , @xmath324    first observe that the ergodicity of @xmath138 implies the ergodicity of @xmath64 .",
    "indeed , it is well - known that the product measure @xmath192 is ergodic for the skew - product @xmath309 if @xmath138 is ergodic ( cf .",
    "@xcite ) . since @xmath325 and @xmath209",
    ", this implies the ergodicity of @xmath64 .",
    "now consider a noiseless channel with input alphabet @xmath326 and a pair of coder and decoder / estimator which solves the estimation problem for some @xmath49 .",
    "for every @xmath327 and @xmath328 let@xmath329 where the infimum is defined as @xmath330 if the corresponding set is empty . note that @xmath331 depends measurably on @xmath332 .",
    "define@xmath333 and observe that these sets are measurable . from it",
    "follows that for every @xmath328,@xmath334 fixing a @xmath8 large enough so that @xmath335 , katok s characterization of metric entropy yields the assertion , which is proved with the same arguments as in the proof of theorem [ thm_topent_lb ] , using the simple fact a maximal @xmath86-separated set contained in some set @xmath8 also @xmath86-spans @xmath8 . for more details , see the proof of theorem [ thm_metricent_lb_rds ] .",
    "in this section , we again allow noise in the channel and assume that @xmath336 .",
    "we prove further impossibility results via information - theoretic methods .",
    "these results will shed more light on the precise conditions that force @xmath0 to be infinite .",
    "[ negresult ] consider system with state space @xmath336 .",
    "suppose that@xmath337 and @xmath338 for all @xmath154 .",
    "then , under ( [ eq_quadratic_obj ] ) ( and thus under ( [ eq_bowenball_obj])),@xmath339 in particular , @xmath1",
    ".    let @xmath340 be a sequence of non - negative real numbers so that @xmath341 \\leq \\epsilon_t$ ] for all @xmath154 and @xmath342 .",
    "observe that for @xmath343 : @xmath344 } | q'_{[0,t-1 ] } ) & = & h(q'_t | q'_{[0,t-1 ] } ) -   h(q'_t | q_{[0,t ] } , q'_{[0,t-1 ] } ) \\nonumber \\\\ & = & h(q'_t | q'_{[0,t-1 ] } ) -   h(q'_t | q_{[0,t ] } , x_t , q'_{[0,t-1 ] } ) \\label{classaassumption } \\\\ & \\geq & h(q'_t | q'_{[0,t-1 ] } ) -   h(q'_t | x_t , q'_{[0,t-1 ] } ) \\nonumber \\\\ & = & i(x_t ; q'_t| q'_{[0,t-1 ] } ) .",
    "\\nonumber\\end{aligned}\\ ] ] here , ( [ classaassumption ] ) follows from the assumption that the channel is of class a type .",
    "define @xmath345},q'_{[0,t-1]}),\\ 0 \\leq t \\leq t-1\\ } } \\frac{1}{t}\\sum_{t=0}^{t-1 } i(q'_t ; q_{[0,t ] } | q'_{[0,t-1]}).\\ ] ] now consider the following:@xmath346 } ) ) + i(x_0;q'_0 ) \\bigg ) \\label{usefulstep2_1 } \\\\   & = & \\limsup_{t \\to \\infty } \\frac{1}{t}\\bigg ( \\sum_{t=1}^{t-1 } \\bigg(h(x_t | q'_{[0,t-1 ] } ) - h(x_t|q'_{[0,t]})\\bigg ) + i(x_0;q'_0)\\bigg)\\nonumber \\\\   & \\geq & \\limsup_{t \\to \\infty } \\frac{1}{t}\\bigg ( \\sum_{t=1}^{t-1 } \\bigg(h(x_t | x_{[0,t-1]},q'_{[0,t-1 ] } ) - h(x_t|q'_{[0,t]})\\bigg ) + i(x_0;q'_0)\\bigg)\\nonumber \\\\   & = & \\limsup_{t \\to \\infty } \\frac{1}{t}\\bigg ( \\sum_{t=1}^{t-1 } \\bigg(h(x_t | x_{[0,t-1]},q'_{[0,t-1 ] } ) - h(x_t - \\hat{x}_t|q'_{[0,t]})\\bigg ) + i(x_0;q'_0)\\bigg)\\nonumber \\\\   & \\geq & \\limsup_{t \\to \\infty } \\frac{1}{t}\\bigg ( \\sum_{t=1}^{t-1 } \\bigg(h(x_t | x_{[0,t-1]},q'_{[0,t-1 ] } ) - h(x_t - \\hat{x}_t)\\bigg ) + i(x_0;q'_0)\\bigg)\\nonumber \\\\   & \\geq & \\limsup_{t \\to \\infty } \\frac{1}{t}\\bigg ( \\sum_{t=1}^{t-1 } \\bigg(h(x_t | x_{[0,t-1]},q'_{[0,t-1 ] } ) - \\frac{n}{2}\\log(2\\pi e \\epsilon_t)\\bigg ) + i(x_0;q'_0)\\bigg)\\nonumber \\\\   & = & \\limsup_{t \\to \\infty } \\frac{1}{t}\\bigg ( \\sum_{t=1}^{t-1 } h(x_t | x_{t-1 } ) \\bigg ) - \\frac{n}{2}\\log(2\\pi e \\epsilon).\\label{denklem}\\end{aligned}\\ ] ] here , the second inequality uses the property that entropy decreases under conditioning on more information .",
    "the second equality follows from the fact that @xmath48 is a function of @xmath347}$ ] , and the last inequality follows from that fact that among all real random variables @xmath83 that satisfy a given second moment constraint @xmath348 \\leq \\epsilon$ ] , a gaussian maximizes the entropy and the differential entropy in this case is given by @xmath349 . using the fact that for an @xmath350-dimensional vector @xmath351^t$ ] , @xmath352 } ) \\leq \\sum_{i=1}^n h(x_i)$ ]",
    ", it follows that with @xmath341 \\leq \\epsilon_t$ ] , @xmath353 .",
    "the final equality then follows from the fact that conditioned on @xmath354 , @xmath40 and @xmath355}$ ] are independent . for the final result , in ( [ denklem ] ) , taking the limit as @xmath356 , @xmath357 , and @xmath1 follows .",
    "we note that the result also applies to the case when @xmath358 is not i.i.d . , but is stationary . here",
    ", one needs to consider @xmath359 } ) > 0 $ ] , however .",
    "the proof presented above in part builds on what is known as shannon s lower bounding technique ; this method is commonly used in information theory ( see e.g. @xcite ) .",
    "we now consider the asymptotic almost sure criterion for additive noise systems on @xmath57 .",
    "[ negresult2 ] suppose that @xmath360 and the system is given by @xmath361 , where the noise measure @xmath44 admits a bounded density which is positive everwhere .",
    "then , under , @xmath1 .    for a given time stage @xmath343 ,",
    "let @xmath362 be given .",
    "due to the additive nature of the noise , for all borel sets @xmath157 , it follows that for some @xmath363,@xmath364 implying that this measure is bounded from above by a constant multiple of the lebesgue measure . given a communication rate for a given time stage @xmath47 , under any encoding and decoding policy with the finite partitioning of the state space @xmath83 for encoding @xmath40 leading to @xmath48 , there exists @xmath365 so that for all @xmath366 , the set@xmath367 has a positive measure bounded from below by ( since @xmath368 is a bounded set)@xmath369 } , q'_{[0,t-1 ] } \\bigr ) \\nonumber \\\\ & &   \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\geq 1 - |{\\cal m}'| k \\lambda(b_{\\epsilon } )   > 0 , \\nonumber\\end{aligned}\\ ] ] where @xmath370 is the lebesgue measure of the ball @xmath371 .",
    "this implies that , uniform over @xmath372 @xmath373 uniform over all realizations of @xmath374 .",
    "with @xmath375 and@xmath376 and@xmath377 let @xmath378 and @xmath379 , where @xmath380 stands for the indicator function of the event @xmath224 .",
    "our goal is to show that @xmath381 almost surely , leading to the desired conclusion .",
    "it is evident that @xmath381 or @xmath382 almost surely .",
    "suppose that @xmath383 .",
    "we will show that this implies that @xmath384 is infinite as well .",
    "note now that the event @xmath385 is implied by the simultaneous occurrence of the events @xmath386 and @xmath387 .",
    "let@xmath388 it is evident that @xmath389 by a repeated use of ( [ boundj ] ) , since the event @xmath390 would imply an infinite number of violating the event whose probability is lower bounded by ( [ boundj ] ) .",
    "thus , @xmath391 . since @xmath358 is i.i.d .",
    ", by a repeated use of ( [ boundj ] ) and induction,@xmath392 where @xmath393 is the @xmath394-field generated by @xmath395 up to time @xmath396 and the last inequality follows since @xmath397 by the strong markov property .",
    "thus , for every @xmath398 , @xmath399 , and it follows by continuity in probability that @xmath400 .",
    "hence , for any finite communication rate , almost sure boundedness is not possible for arbitrarily small @xmath401 .    now let @xmath40 be a stationary source and suppose that the goal is to achieve a uniform lower bound on the estimation error in the quadratic sense .",
    "we first revisit and state a general and a quite strong result due to graf and luschgy @xcite ( further relevant results are due to various authors @xcite ) on the asymptotic performance of optimal quantizers .",
    "[ gl]let @xmath83 be an @xmath402-valued random variable with density @xmath112 .",
    "let @xmath403 denote the set of all quantizers with cardinality at most @xmath350 .",
    "let@xmath404.\\ ] ] then ,    * @xmath405 + where @xmath406^k ) = k_2 $ ] with@xmath407^k)= { v_n(u[0,1]^k ) \\over ( \\lambda^k([0,1]^k))^{(2/d ) } } \\ ] ] is a coefficient for optimal quantization of the uniformly distributed source on @xmath408^k$ ] and@xmath409 * if @xmath410 < \\infty$ ] for some @xmath411 , then@xmath412    for scalar sources , i.e.  such with @xmath413 , we note that the value @xmath414 is equal to @xmath415 , cf .",
    "an implication of the result above is the following .",
    "[ posresult ] assume that the stationary source is such that @xmath40 admits a density and that @xmath416 < \\infty$ ] for some @xmath411 .",
    "suppose further that the channel under consideration is a discrete noiseless channel . under , memoryless quantization of the marginal source process leads to a distortion upper bound for any @xmath47 given by the following so that for every @xmath417 , there exists @xmath365 so that for all @xmath418 , the following holds : @xmath419 \\leq k_2 ( l_c + \\eta ) 2^{-2 c / n},\\ ] ] where@xmath420 with @xmath3 being the channel capacity .",
    "in particular , for we have , for every @xmath421 and for sufficiently small @xmath56 , @xmath422    the proof follows by encoding @xmath40 in a memoryless fashion , letting @xmath423 , and applying theorem [ gl ] .",
    "one could also obtain a lower bound for the special case of additive systems , by encoding only the noise process .",
    "[ negresultgl ] assume that the system is given by@xmath424 and @xmath133 , where @xmath44 admits a density @xmath425 .",
    "further assume that the channel is of class a type .",
    "then@xmath426 implies that there exists no encoder and decoder which can achieve for @xmath56 sufficiently small .",
    "in particular , @xmath1 .",
    "the proof follows from the fact that the estimation error for the noise process gives a lower bound for the estimation error of the dynamical system itself . in particular , given any encoding policy , the following holds:@xmath427 } ) } e[|x_t - \\hat{x}_t|^2 | q'_{[0,t ] } ]   \\nonumber \\\\ & & \\geq \\inf_{\\hat{x}_t = \\gamma_t(q'_{[0,t]},x_{t-1 } ) }   e[|x_t - \\hat{x}_t|^2 | q'_{[0,t ] } , x_{t-1 } ]   \\nonumber \\\\ & & = \\inf_{\\hat{x}_t = \\gamma_t(q'_{[0,t]},x_{t-1 } ) } e[|f(x_{t-1 } ) + w_{t-1 } - \\hat{x}_t|^2 | q'_{[0,t ] } , x_{t-1 } ]   \\nonumber \\\\ & & = \\inf_{\\hat{x}_t = \\gamma_t(q'_{[0,t]},x_{t-1 } ) } e[|w_{t-1 } - ( \\hat{x}_t- f(x_{t-1 } ) ) |^2 | q'_{[0,t ] } , x_{t-1 } ]   \\nonumber \\\\ & & = \\inf_{\\hat{v}_t = \\gamma_t(q'_{[0,t]},x_{t-1 } ) } e[|w_{t-1 } - \\hat{v}_t |^2 | q'_{[0,t ] } , x_{t-1 } ]   \\nonumber \\end{aligned}\\ ] ] thus , a lower bound is obtained by trying to estimate the noise realizations , given the additional side information of the previous state realization . at any",
    "given time the conditional probability @xmath428 } , x_{t-1 } ) = p({\\mathrm{d}}w_t)$ ] can be partitioned into at most @xmath429 bins , leading to the applicability of the asymptotic quantization theory results for each noise realization .",
    "the argument then follows from theorem [ gl](a ) .",
    "in this section , the system is viewed as a random dynamical system ( briefly an rds ) .",
    "we will prove that under the assumption of a compact state space and a noiseless channel , the metric entropy of the rds is a lower bound on @xmath0 for the objective , and hence also for .",
    "next we define a random dynamical system .",
    "the base space is defined as @xmath430 and for its elements we use the notation @xmath431 .",
    "the @xmath394-field on @xmath157 is the product field of the borel @xmath394-field on @xmath135 ( generated by cylinder sets ) , and the measure on this space is @xmath286 , the corresponding product measure of @xmath44 .",
    "the dynamics on @xmath157 is given by the left shift operator @xmath432 , which obviously preserves the measure @xmath286 and is easily seen to be ergodic . a random dynamical system ( briefly an _ rds _ ) over @xmath182",
    "is given by@xmath433 the associated skew - product transformation is given by@xmath434 we will work with a time - invertible extension of @xmath435 , which replaces @xmath157 with @xmath436 ( two - sided sequences ) endowed with the measure @xmath437 and the shift operator @xmath438 on two - sided sequences .",
    "since @xmath439 is invertible by assumption for every @xmath136 , it is obvious that also the cocycle @xmath435 over @xmath440 can be extended to a cocycle@xmath441 over @xmath442 . for simplicity , we drop the superscript @xmath443 again and just write @xmath444 for the time - invertible extension . for technical reasons",
    ", we also extend the one - sided sequence @xmath445 of random variables by a two - sided sequence @xmath446 , which is still i.i.d .  such that @xmath133 . consider a probability measure @xmath64 on @xmath447 , invariant under the time-@xmath448-map @xmath449 , with marginal @xmath437 on @xmath157 .",
    "then @xmath64 is called a _",
    "@xmath435-invariant measure_. such @xmath64 disintegrates with respect to @xmath437 , i.e. , @xmath450 for a family @xmath451 of conditional probabilities , defined @xmath437-almost everywhere .",
    "the general definition of the metric entropy @xmath452 of an rds @xmath435 with respect to an invariant measure @xmath64 can be found in @xcite .",
    "we will use a characterization of the metric entropy in terms of so - called @xmath453-spanning sets , which generalizes katok s characterization for the deterministic case ( see subsect .",
    "[ subsec_notation ] ) .",
    "first , define for every @xmath454 the family of bowen - metrics@xmath455 we say that a set @xmath456 @xmath453-spans another set @xmath457 if for each @xmath458 there is @xmath89 with @xmath459 .",
    "a set @xmath460 is @xmath453-separated if for each @xmath76 with @xmath77 it holds that @xmath461 . by @xmath462",
    "we denote the smallest cardinality a @xmath453-spanning set for @xmath4 can have .",
    "we use the notation @xmath463 to denote the maximal cardinality of a @xmath453-separated set contained in some @xmath457 .",
    "now let @xmath64 be an ergodic invariant measure for the rds @xmath435 ( i.e. , @xmath64 is ergodic w.r.t .",
    "the skew - product @xmath309 ) . then @xmath64 disintegrates as @xmath450 with almost everyhwere defined sample measures @xmath464 .",
    "for any @xmath106 put@xmath465 we will use the following generalization of katok s result from ( * ? ? ?",
    "3.1 ) , which describes the metric entropy of an rds for an ergodic measure via cardinalities of @xmath453-spanning sets .",
    "[ thm_zhu ] if @xmath466 , then for any @xmath106,@xmath467    in addition to this theorem , we will make use of the following technical lemma .",
    "[ lem_probs ] let @xmath131 be a probability space , @xmath468 $ ] an integrable function and @xmath469 such that@xmath470 then @xmath471 for all @xmath472 in a set of measure @xmath473 .",
    "assume to the contrary that@xmath474 this is equivalent to@xmath475 splitting @xmath476 into the set @xmath477 , where @xmath471 , and its complement @xmath478 , we see that@xmath479 a contradiction .",
    "now we are in position to prove the announced theorem . in the proof we will also use the following concepts and notations : for any @xmath480",
    ", we say that a set @xmath460 is @xmath481-separated if @xmath482 for some @xmath483 , whenever @xmath76 and @xmath77 .",
    "we write @xmath484 for the maximal cardinality of a @xmath481-separated set .",
    "[ thm_metricent_lb_rds ] consider the estimation objective to be achieved for an initial measure @xmath138 which is equivalent to an ergodic measure @xmath183 of the markov chain @xmath485 .",
    "then there exists an ergodic measure @xmath64 for the random dynamical system @xmath435 such that@xmath486 holds if @xmath466 .    in the proof of lemma [ lem_mu ]",
    "we showed that the product measure @xmath487 is invariant under the rds with one - sided time .",
    "it is well - known that this measure has a unique extension to an ergodic invariant measure @xmath64 for the two - sided system ( cf .",
    "we write @xmath450 for the disintegration of @xmath64 .",
    "now we prove the theorem in three steps .",
    "_ step 1 . _",
    "consider a noiseless channel with input alphabet @xmath326 and a pair of coder and decoder / estimator which solves the estimation problem for some @xmath49 .",
    "for all @xmath488 and @xmath328 let@xmath489 where the infimum is defined as @xmath330 if the corresponding set is empty .",
    "note that @xmath490 depends measurably on @xmath491 , since @xmath492 is measurable and also the coder and estimator maps are assumed to be measurable .",
    "define@xmath493 and observe that these sets are measurable .",
    "for every @xmath494 we write@xmath495 from it follows that for every @xmath328,@xmath496 here the measure @xmath497 is the two - sided extension of the product measure @xmath498 . since we assume that that @xmath183 is absolutely continuous with respect to @xmath138 , for every @xmath11 there exists @xmath499 so that @xmath500 if @xmath501 .",
    "this property carries over to the two - sided extensions of these product measures . applying this to the complements of the sets @xmath502 , we find that@xmath503 consider the sequence @xmath504 , @xmath75 . for each",
    "fixed @xmath350 we can choose @xmath505 large enough so that@xmath506 this is possible , since @xmath507 for all @xmath75 .",
    "observe that@xmath508 by lemma [ lem_probs ] we find a set @xmath509 of measure@xmath510 so that for all @xmath511 we have@xmath512    _ step 2 . _ in this step , we fix @xmath350 and write @xmath513 , @xmath505 , @xmath514 .",
    "for a given channel and coder - decoder pair which solves the estimation problem for @xmath515 define for every integer @xmath516 the set@xmath517 } : q_{[0,t-1 ] } \\in { \\mathcal{m}}^t \\right\\},\\ ] ] i.e. , the set of all possible estimation sequences of length @xmath518 .",
    "let @xmath519 be @xmath520-separated for a fixed @xmath521 and some @xmath522 .",
    "define a map @xmath523 , by assigning to each @xmath524 an @xmath525 } \\in \\hat{e}(t)$ ] with@xmath526 which is possible by the definition of @xmath527 .",
    "the map @xmath13 is injective , because @xmath528 by the triangle inequality implies@xmath529 and hence @xmath530 , since @xmath224 is @xmath520-separated .",
    "consequently , @xmath531 , implying@xmath532 if @xmath533 is a @xmath534-separated set , then @xmath535 is a @xmath520-separated set of the same cardinality , implying@xmath536 and with @xmath537 we thus obtain@xmath538 using the invariance property of the sample measures ( see ( * ? ? ?",
    "1.2.3 ) ) and , we find@xmath539 since the channel was chosen arbitrarily ( within the class of channels that allow for the estimation criterion with accuracy @xmath56 ) , we have@xmath540    _ step 3 . _",
    "we claim that the set @xmath541 defined as follows has positive measure:@xmath542 indeed , using and the fact that @xmath437 is invariant under @xmath182 , we find@xmath543^c\\bigr ) \\geq 1 - \\sum_{n=1}^{\\infty } \\nu^{{\\mathbb{z}}}([\\theta^{k(n)}(\\tilde{b}(n))]^c)\\\\                             & = & 1 - \\sum_{n=1}^{\\infty}(1 - \\nu^{{\\mathbb{z}}}(\\tilde{b}(n ) ) ) \\geq 1 - \\sum_{n=1}^{\\infty}3^{-n } = \\frac{1}{2}.\\ ] ] hence , there are generic elements @xmath544 ( i.e. , elements that are contained in an arbitrary but fixed full measure subset of @xmath157 ) so that ( with ) @xmath545 where @xmath546 is a set with @xmath547 .",
    "fixing such a generic element @xmath548 with respect to the full measure set provided by theorem [ thm_zhu ] with @xmath549 , we find@xmath550 here we use the simple fact that a maximal @xmath551-separated set in @xmath546 also @xmath551-spans @xmath546 and the assumption that @xmath552 .",
    "it should be mentioned that the metric entropy @xmath452 in the theorem can be expressed in terms of the positive lyapunov exponents of the rds @xmath435 , given that the state space is a smooth manifold and the system satisfies some regularity assumptions . in particular , this includes that @xmath63 is twice differentiable with respect to @xmath110 and the invariant measure @xmath64 satisfies the so - called srb property , cf .",
    "in this section , we study the estimation objective in the case when there is only noise in the channel , but not in the source .",
    "the following result shows that in case of a noise - free system , the topological entropy provides an upper bound on @xmath0 for the objective .",
    "the proof uses similar arguments as employed in @xcite for the case of a noiseless channel .",
    "[ nonlinearastop ] consider a non - linear deterministic system @xmath270 on a compact state space @xmath83 , estimated via a discrete memoryless channel ( dmc ) .",
    "then , for the asymptotic estimation objective , @xmath553    without loss of generality , we may assume that @xmath554 , since otherwise the statement trivially holds .",
    "then it suffices to show that for any @xmath49 the estimation objective can be achieved whenever the channel capacity satisfies @xmath555 .",
    "since the capacity of a dmc can take any positive value , it follows that @xmath556 for every @xmath49 and thus @xmath557 .",
    "now , consider a channel with capacity @xmath555 and fix @xmath49 . recall that the input alphabet is denoted by @xmath326 and the output alphabet by @xmath558 . by the random coding construction of shannon @xcite , we can achieve a rate @xmath12 satisfying@xmath559 with a sequence of increasing sets @xmath560 of input messages so that for all @xmath350,@xmath561 furthermore , there exists a sequence of encoders @xmath562 , yielding codewords @xmath563 , and a sequence of decoders @xmath564 so that@xmath565 } ) \\neq c| q_{[0,n-1 ] } = x^n(c ) ) \\leq { \\mathrm{e}}^{-ne(r ) + o(n)},\\ ] ] uniformly for all @xmath566 . here @xmath567 as @xmath568 and @xmath569 .",
    "in particular , we observe that with @xmath570 being the message transmitted and @xmath571})$ ] the decoder output,@xmath572 } ) \\neq c_n ) \\nonumber \\\\ & = \\sum_{c   \\in \\{1,\\ldots , m_n\\}}p ( d^n(q'_{[0,n-1 ] } ) \\neq c | q_{[0,n-1 ] } = x^n(c ) ) p(q_{[0,n-1 ] } = x^n(c ) ) \\leq { \\mathrm{e}}^{-n e ( r ) + o(n)}.\\ ] ] this also implies that the bound holds even when the messages to be transmitted are not uniformly distributed .",
    "thus , for the sequence of encoders and decoders constructed above we have@xmath573 } ) \\neq c_n ) \\leq \\sum_n { \\mathrm{e}}^{-n e ( r ) + o(n ) } < \\infty.\\ ] ] the borel - cantelli lemma then implies@xmath574 } ) \\neq c_n \\",
    "\\mbox{infinitely often } \\bigr\\ } \\bigr ) = 0.\\ ] ] now we choose @xmath575 so that , by uniform continuity,@xmath576 furthermore , we choose @xmath577 sufficiently large so that@xmath578 this is possible , because by and , for every @xmath579 we have@xmath580 let @xmath581 be a @xmath582-spanning set of cardinality @xmath583 and fix injective functions@xmath584 in fact , by possibly enlarging the set @xmath581 , we can assume that @xmath585 is bijective . for any @xmath586 let @xmath587 denote a fixed element of @xmath581 satisfying @xmath588 for @xmath589 .",
    "define sampling times by@xmath590 in the following , we specify the coding scheme . in this coding scheme ,",
    "the encoder from @xmath591 to @xmath592 , encodes the information regarding the orbit of the state from @xmath593 to @xmath594 . for all @xmath595 , at time @xmath591 , use the input @xmath596 for the encoder , where @xmath597 is the state at time @xmath591 . then @xmath598 is sent during the next @xmath599 units of time .",
    "this is possible by . for @xmath600 ,",
    "it is not important what we transmit .",
    "let the estimator apply @xmath601 to the output of the decoder , obtaining an element @xmath602 , and use @xmath603 as the estimates during the forthcoming time interval of length @xmath604 .",
    "then @xmath605 , and the fact that @xmath606 is @xmath607-spanning implies that the desired estimation accuracy is achieved , provided that there was no error in the transmission . now implies that after a finite random time , there are no more errors in the transmission . by the analysis above , the errors will be uniformly bounded by @xmath56 .",
    "hence , the objective is achieved .",
    "we note that the proof above crucially depends on the fact that the system is deterministic .",
    "note also that the proof above admittedly is impractical to implement .",
    "the theorem is essentially a possibility result .",
    "note that the proof even does not make use of the fact that the encoder has access to the realizations of the channel output , hence feedback is not utilized .    in the following , for noisefree linear systems",
    ", we will show that there exist stationary policies which guarantee the almost sure estimation criterion .",
    "we consider a noiseless linear system@xmath608 with @xmath609 .",
    "the following result gives a positive answer to the question whether the estimation objective can be achieved , when no noise is present in the system , via an erasure channel of finite capacity .",
    "recall that such a channel has @xmath610 and @xmath611 , with@xmath612 where @xmath613 denotes the erasure symbol and @xmath112 is the erasure probability .",
    "[ erasureas ] consider system estimated over a memoryless erasure channel with finite capacity .",
    "then , for , we have@xmath614    we note that if one samples the system with a sufficiently large period and work with the sampled system , the upper bound in ( [ asstaberasure ] ) , normalized by the sampling period , can be made arbitrarily close to @xmath615 which is the topological entropy of the linear system ( [ eq_ls ] ) .",
    "we will show that the capacity bound is almost achievable .",
    "we first assume that the system is diagonalizable .",
    "consider the eigenvalues @xmath616 .",
    "similar to the construction in @xcite ( see also @xcite and @xcite for related discussions with different constructions ) where a uniform quantizer is employed ; we can show that with @xmath617 and @xmath618 $ ] , a dynamical stochastic system can be obtained where for some @xmath619 , @xmath620 where @xmath621 $ ] and @xmath622 is the rate allocated for the @xmath623th unstable mode .    now , suppose that @xmath624 it follows that @xmath625 .",
    "furthermore , for every @xmath626 , by markov s inequality @xmath627 and since @xmath628 borel - cantelli lemma implies that @xmath629 infinitely often .",
    "this applies for every @xmath626 , and thus it follows that convergence in almost sure sense applies .",
    "now , we take a careful look at the expression @xmath630 the proof above shows that for every @xmath631 , this condition implies the almost sure convergence .",
    "the claim is that if @xmath632 , there exists some @xmath617 so that the above holds . observing that at @xmath633 ( [ denklem1 ] ) is an equality",
    ", we can take the derivative of this expression and show that the right derivative is negative ( defined as the limit @xmath634 ) . to check that we observe that the derivative writes as @xmath635 finally",
    ", one can check by writing that the condition @xmath632 implies ( by substituting @xmath636 ) that ( [ denklem2 ] ) is less than @xmath273 for sufficiently small @xmath617 .",
    "the above applies for each dimension .",
    "the capacity of the erasure channel is given by @xmath637 , where @xmath622 is the rate allocated to the @xmath623th component .",
    "the same discussion also applies for the non - diagonalizable setting . in this case",
    ", one could apply the following alternative reasoning for each jordan block in the system ; these jordan blocks are decoupled .",
    "let @xmath638 where @xmath639 denote the support of the uncertainty size @xmath640 .",
    "it can be shown that the evolution of @xmath641 evolves as @xmath642 where @xmath643 with probability @xmath112 and @xmath644 with probability @xmath645 , and @xmath646 is a jordan matrix with eigenvalue @xmath647 , and @xmath648 is a jordan matrix with eigenvalue @xmath649 .",
    "one can thus view the process @xmath650 as the outcome of the product of random matrices .",
    "in general , the computation of the limit of the product of a sequence of random matrices , even in the i.i.d .",
    "case , is a very challenging problem , but in this case one observes that the diagonal term of the matrix @xmath651 is always the product of @xmath652 and @xmath649 , multiplied according to the number of erasures and successful transmissions across the channel . by the strong law of large numbers , it then follows that if@xmath653 the product of the random matrices converges to pointwise zero almost surely .",
    "this condition is identical to the condition @xmath654 .",
    "thus , the result follows .",
    "sahai and mitter @xcite show in corollary 5.3 and theorem 4.3 of their paper that for a discrete memoryless channel indeed it suffices that @xmath655 for the existence of encoder and controller policies leading to stochastic stability .",
    "this result is in agreement with theorems [ nonlinearastop ] and [ erasureas ] .",
    "in this paper , we considered three estimation objectives for stochastic non - linear systems @xmath42 with i.i.d .",
    "noise @xmath656 , assuming that the estimator receives state information via a noisy channel of finite capacity .",
    "we studied three fundamentally different approaches to obtain lower bounds for @xmath0 , the smallest channel capacity above which the estimation objective under consideration can be achieved for arbitrarily small errors . these approaches and the corresponding results",
    "can be summarized as follows :    1 .   for noiseless channels , assuming that the initial measure @xmath138 is stationary , we proved that @xmath0 is bounded below by either the topological or the metric entropy of a shift dynamical system on the space of trajectories ( theorems [ thm_topent_lb ] and [ thm_metricent_lb_det ] ) .",
    "we saw that these lower bounds are infinite when the noise substantially influences the dynamics so that the space of relevant trajectories becomes too large .",
    "2 .   for systems on euclidean space and noisy channels",
    ", we provided several information - theoretic conditions enforcing @xmath1 .",
    "in particular , theorem [ negresult ] shows that @xmath1 for the quadratic stability objective , whenever@xmath657 since @xmath658 is a measure for the uncertainty of @xmath40 given @xmath354 , this condition says that the noise on the long run ( in average ) influences the state process in a substantial way .",
    "similarly to the results in section [ sec_noiseless_compact ] , this means that the noise makes the space of relevant trajectories too large ( or too complicated ) to estimate the state with arbitrarily small error over a finite capacity channel .",
    "3 .   in section [ sec_rds ]",
    "we viewed the stochastic system @xmath42 as a random dynamical system , defined as a cocycle over the shift on the space of noise realizations . assuming a compact state space and a noiseless channel",
    ", we proved that the metric entropy of the random dynamical system provides a lower bound on @xmath0 for the objective .",
    "since this lower bound is finite under mild assumptions and in case of a smooth system its value only depends on the average divergence rates of nearby trajectories ( i.e. , lyapunov exponents ) , we see that the random dynamical systems view is not shedding too much light on the problem .",
    "4 .   in section [ sec_positive ]",
    "we assumed that the system is deterministic with a compact state space , but the channel is noisy .",
    "we proved that in this case @xmath0 is bounded above by the topological entropy of the system for the asymptotic almost sure objective .",
    "furthermore , we showed the analogous result , when the system is linear and the channel is an erasure channel .",
    "it would be interesting to generalize the analysis in this paper to controlled non - linear systems , as well as to establish further connections between the ergodic theory of random dynamical systems and information theory .",
    "d.  liberzon and s.  mitra .",
    "entropy and minimal data rates for state estimation and model detection . in _ proceedings of the 19th international conference on hybrid systems : computation and control",
    "_ , pp .  247256 .",
    "acm , 2016 ."
  ],
  "abstract_text": [
    "<S> this paper studies state estimation over noisy channels for stochastic non - linear systems . </S>",
    "<S> we consider three estimation objectives , a strong and a weak form of almost sure stability of the estimation error as well as quadratic stability in expectation . </S>",
    "<S> for all three objectives , we derive lower bounds on the smallest channel capacity @xmath0 above which the objective can be achieved with an arbitrarily small error . </S>",
    "<S> lower bounds are obtained via a dynamical systems ( through a novel construction of a dynamical system ) , an information - theoretic and a random dynamical systems approach . </S>",
    "<S> the first two approaches show that for a large class of systems , such as additive noise systems , @xmath1 , i.e. , the estimation objectives can not be achieved via channels of finite capacity . </S>",
    "<S> the random dynamical systems approach is shown to be operationally non - adequate for the problem , since it yields finite lower bounds @xmath0 under mild assumptions . finally , we prove that a memoryless noisy channel in general constitutes no obstruction to asymptotic almost sure state estimation with arbitrarily small errors , when there is no noise in the system .     </S>",
    "<S> state estimation ; non - linear systems ; topological entropy ; metric entropy ; information theory ; dynamical systems     93e10 , 93e15 , 93c10 , 37a35 </S>"
  ]
}