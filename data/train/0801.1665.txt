{
  "article_text": [
    "heavy ion collisions at very high energy are of interest due to the formation of a novel partonic medium approximately the size of a large nucleus , but with an energy density exceeding that of normal nuclei by considerably more than an order of magnitude . at such high energy densities",
    ", it is believed that quarks and gluons are no longer confined in hadrons , but may be constituents of a quark - gluon plasma with characteristics of a near - perfect fluid  ( for a detailed review see @xcite ) .",
    "experiments at the relativistic heavy ion collider ( rhic ) have already demonstrated that a very hot and dense , strongly interacting medium is created in au+au  collisions at @xmath7 gev  @xcite .",
    "the goal is now to quantitatively determine the properties of this medium .",
    "important properties of the medium include the density of color - charges as well as the exchange of transverse momentum between parton probes and the medium . in rare events , in addition to the creation of the medium",
    ", there can also be a hard scattering ( high-@xmath8 process ) between the colliding partons that , at leading order , sends two high - energy quark or gluon partons in opposite transverse directions .",
    "these high - energy partons can be utilized to probe both the color - charge density of the medium and the coupling strength between the parton and the medium .",
    "there are various calculational frameworks for modeling these interactions ( for a detailed review see @xcite ) .    in this paper , we consider four specific calculations of parton energy - loss ( discussed below ) : the parton quenching model ( pqm )  @xcite , the gyulassy - levai - vitev ( glv ) model  @xcite , the wicks - horowitz - djordjevic - gyulassy ( whdg ) model  @xcite , and the zhang - owens - wang - wang ( zoww ) model  @xcite .",
    "we detail a quantitative method of assessing the sensitivity of the latest measurements to the input parameters of these models that characterize the initial parton density or medium transport coefficients .",
    "during the 2004 data - taking period at the relativistic heavy ion collider , the phenix experiment recorded an integrated luminosity of 0.24 nb@xmath9 in @xmath10=200  gev au+au  collisions , which extends the measurement of @xmath11 to much higher @xmath12  than previous data sets allowed .",
    "the results and further details of this measurement are given in  @xcite .",
    "a brief description is given below .",
    "the phenix experiment measures @xmath11 s via the two - photon decay mode with two types of highly segmented ( @xmath13 ) electromagnetic calorimeters  ( emcal ) located at the radial distance of approximately 5  m from the vertex  @xcite .",
    "one is a lead scintillator sampling calorimeter  ( pbsc ) , which covers the geometrical acceptance of @xmath14 and @xmath15 .",
    "the other is a lead glass cerenkov calorimeter  ( pbgl ) , whose geometrical coverage is @xmath14 and @xmath16 .",
    "the energy resolution of the pbsc and pbgl calorimeters as determined from test beam measurements are given by @xmath17 and @xmath18 , respectively .",
    "the energy calibration of the emcal modules is based upon the measured position of the @xmath11 mass peak , the deposited energy of minimum ionizing particles which traverse the calorimeter , and the ratio of energy to momentum which is expected to be about 1 for electrons identified by the ring - imaging cerenkov detector .",
    "the systematic uncertainty on the energy scale is @xmath19 1  % , which corresponds to @xmath19 7 - 12  % uncertainty on the invariant @xmath11 yield over the @xmath12  range of the measurement .",
    "neutral pions were reconstructed in their @xmath20 decay channel .",
    "photon candidates are identified by applying particle identification cuts based mainly on the shower shape .",
    "the invariant mass for all photon - pair combinations within one event that satisfy cuts on the energy asymmetry @xmath21 were calculated in bins of @xmath12 .",
    "the combinatorial background is determined by combining into pairs uncorrelated photons from different events with similar centrality , reaction plane , and vertex location .",
    "nuclear suppression factor @xmath22 as a function of transverse momentum for 0 - 5% au+au  collisions at @xmath23=200 gev .",
    "point - to - point uncorrelated statistical and systematic uncertainties are shown as uncertainty bars .",
    "correlated systematic uncertainties are shown as gray boxes around the data points . the global scale factor",
    "systematic uncertainty is @xmath612% . ]",
    "the raw @xmath11 yield was obtained by integrating the mass peak region of the invariant mass distribution after subtracting the combinatorial background .",
    "the raw spectra are corrected for the detector response ( energy resolution ) , the reconstruction efficiency , and occupancy effects ( e.g. overlapping clusters ) .",
    "these corrections are made by embedding simulated single @xmath11 s from a full geant simulation of the phenix detector into real events , and analyzing the embedded @xmath11 events with the same analysis cuts as used with real events .",
    "after computing the invariant yields in au+au  collisions  @xcite , the medium effects are quantified using the nuclear modification factor  ( @xmath22 ) .",
    "@xmath22 is the ratio between the measured yield and the expected yield for point - like processes scaled from the p+p  result , and is defined as :    @xmath24    where  @xmath25 is the average glauber nuclear overlap function for the au+au  centrality bin under consideration @xmath26 where @xmath27 is the average number of inelastic nucleon - nucleon collisions for the au+au  centrality bin under consideration calculated with inelastic nucleon - nucleon cross section @xmath28 .",
    "[ cols=\"^,^,^,^,^\",options=\"header \" , ]     it is also interesting to inquire what simple linear fit function best describes the experimental data for @xmath12@xmath29 gev/@xmath30 . the identical procedure to that described above is applied to the function @xmath31 @xmath12to determine the best values for the two parameters .",
    "the best fit line and the envelope of lines with one standard deviation uncertainties are shown in fig .",
    "[ fig_simplefits_results ] .",
    "the results including all types of uncertainties are @xmath32 and @xmath33 ( @xmath30/gev ) .",
    "the uncertainties on these parameters are correlated as shown by the one , two , and three standard deviation contours in fig .",
    "[ fig_simplefits_contour ] .",
    "thus the data are consistent with a completely flat @xmath12-dependence of @xmath22 for @xmath12@xmath29 gev/@xmath30 ( i.e. @xmath34 ) within one standard deviation uncertainties .",
    "the maximum p - value  for this simple linear function fit is 11.6% .",
    "the p - value s for all models considered are less than 12% .",
    "it is notable that the five highest @xmath12  points ( @xmath12@xmath35 gev/@xmath30 ) , contribute over 70% to the total @xmath36 . as a check on the influence of these points on the extracted parameter values",
    ", we have repeated the above procedure to the restricted range 5 @xmath37 @xmath12@xmath37 9.5  gev/@xmath30 .",
    "we find the following new constraints : pqm model @xmath3q@xmath4  = 13.2 @xmath38  gev@xmath39/fm ; glv model @xmath40 ; whdg model @xmath41 ; zoww model @xmath42  gev / fm ; simple linear fit @xmath43 and @xmath44 ( @xmath30/gev ) .",
    "we find that the resulting new constraints are within the one standard deviation uncertainties of those quoted for the full @xmath12  range .",
    "however , with the restricted range , the p - value s increase to 55% , 36% , 17% , 62% , and 75% for the pqm model , glv model , whdg model , zoww model , and the simple linear fit , respectively .",
    "improvements in the data for @xmath45 gev / c expected from future measurements will be crucial in determining whether any of the models discussed provide a statistically valid description of the data over the full range @xmath46 gev / c .     nuclear suppression factor @xmath22 as a function of transverse momentum for 0 - 5% au+au  collisions at @xmath23=200 gev .",
    "point - to - point uncorrelated statistical and systematic uncertainties are shown as uncertainty bars .",
    "correlated systematic uncertainties are shown as gray boxes around the data points . the global scale factor",
    "systematic uncertainty is quoted as text .",
    "also shown are the best fit and the envelope of lines with one standard deviation uncertainty for a simple linear fit function constrained by the statistical and systematic uncertainties . ]",
    "in this paper , we have compared model predictions of parton energy - loss with experimental data of semi - inclusive single high transverse momentum @xmath0 suppression in central au+au  reactions at @xmath23=200 gev . in the comparison ,",
    "statistical and systematic uncertainties were taken into account .",
    "we have obtained experimental constraints on model parameters of the color - charge density of the medium or its transport coefficient .",
    "these values indicate a large medium density .",
    "it is crucial to note that the quoted constraints on these parameters do not include any systematic uncertainties in the models , but rather give the limits assuming a `` perfect theory '' with one unknown parameter , for example the color - charge density , constrained by the measurements including the experimental statistical and systematic uncertainties .",
    "additional theoretical systematic uncertainties from the time evolution , energy - loss approximations , and calculation details need further investigation .",
    "we thank the staff of the collider - accelerator and physics departments at brookhaven national laboratory and the staff of the other phenix participating institutions for their vital contributions .",
    "we thank w. horowitz , c. loizides , i. vitev , and x .-",
    "n . wang for the theoretical calculation input and useful discussions .",
    "we acknowledge support from the office of nuclear physics in the office of science of the department of energy , the national science foundation , abilene christian university research council , research foundation of suny , and dean of the college of arts and sciences , vanderbilt university ( u.s.a ) , ministry of education , culture , sports , science , and technology and the japan society for the promotion of science ( japan ) , conselho nacional de desenvolvimento cientfico e tecnolgico and fundao de amparo  pesquisa do estado de so paulo ( brazil ) , natural science foundation of china ( people s republic of china ) , ministry of education , youth and sports ( czech republic ) , centre national de la recherche scientifique , commissariat  lnergie atomique , and institut national de physique nuclaire et de physique des particules ( france ) , ministry of industry , science and tekhnologies , bundesministerium fr bildung und forschung , deutscher akademischer austausch dienst , and alexander von humboldt stiftung ( germany ) , hungarian national science fund , otka ( hungary ) , department of atomic energy ( india ) , israel science foundation ( israel ) , korea research foundation and korea science and engineering foundation ( korea ) , ministry of education and science , russian academy of sciences , federal agency of atomic energy ( russia ) , vr and the wallenberg foundation ( sweden ) , the u.s .",
    "civilian research and development foundation for the independent states of the former soviet union , the us - hungarian nsf - otka - mta , and the us - israel binational science foundation .",
    "in the case of only point - to - point uncorrelated uncertainties ( statistical and/or systematic ) , if one assumes they are gaussian distributed and characterized by @xmath47 , the root - mean square ( rms ) , calculating the best - parameter fit is straightforward via a log - likelihood or least squares-@xmath48 method  @xcite .",
    "the likelihood function @xmath49 is defined as the _ a priori _ probability of a given outcome .",
    "let @xmath50 be @xmath51 samples from a population with normalized probability density function @xmath52 where @xmath53 represents a vector of @xmath54 parameters . for instance",
    "@xmath55 could represent a measurement of a cross section at transverse momentum ( @xmath56 , where the probability density of the measurement is gaussian distributed about the expectation value @xmath57 : @xmath58 }   \\qquad     \\label{eq : gaussian}\\ ] ] if the samples are independent , then the likelihood function is :      however , if the samples are correlated , for example via correlated systematic uncertainties , then the full covariance matrix must be used @xmath60 then the likelihood function takes the more general form : @xmath61 }    \\qquad      \\label{eq : lcorr - gaussian}\\ ] ] where @xmath62 is the determinant of the covariance matrix @xmath63 .",
    "note that eq .",
    "[ eq : lcorr - gaussian ] reduces to eq .",
    "[ eq : l - gaussian ] if the correlations vanish so that the covariances are zero and @xmath64 is diagonal @xmath65 since gaussian probability distributions are inevitable ( as a consequence of the central limit theorem ) and since there is also an important theorem regarding likelihood ratios for composite hypotheses , it is convenient to use the logarithm of the likelihood @xmath66    we separate the uncertainties into four classes : type a ) point - to - point uncorrelated systematic uncertainties ; type b ) correlated systematic uncertainties , for which the point - to - point correlation is 100% by construction , since the uncorrelated part has been separated out and included in uncertainty a ) ; type c ) overall systematic uncertainties by which all the points move by the same fraction ( i.e. normalization uncertainties ) ; and type d ) statistical . categories",
    "a and d are simply added in quadrature and represent the total point - to - point uncorrelated uncertainties , denoted @xmath67 below .",
    "we model a correlated systematic uncertainty as if there were an underlying uncertainty , e.g. absolute momentum scale , which may cause correlated systematic variations @xmath68 of the set of measurements , @xmath69 , around their nominal value , that can be represented as a random variable , @xmath70 .",
    "the correlated type b variation of the measurements is represented by the displacement of all points from their nominal values by the correlated amounts @xmath71 where @xmath72 .    since @xmath73 , @xmath74 and",
    "the random variable @xmath70 is the same for all @xmath75 measurements while @xmath76 is a constant of proportionality which may be different for each @xmath75 .",
    "we define @xmath77 , where @xmath78 is the systematic uncertainty bar shown on each point ( gray box on each data point in fig .  [ fig_data_only ] ) and where @xmath76 may be of either sign , as it is possible that one point could move up while its neighbor moves down .",
    "the random variable @xmath70 is assumed to have a gaussian probability distribution @xmath79 , with r.m.s .",
    "@xmath80 @xmath81 } \\qquad .",
    "\\label{eq : gausszb}\\ ] ]    the type c variation is independent of the type b variation .",
    "it is similarly assumed to be caused by an underlying random variable @xmath82 that results in a systematic displacement of the measurement by an amount @xmath83 with @xmath84 where by definition @xmath85 is the same for all points .",
    "we then assume that the likelihood function factorizes as the product of independent gaussian probabilities as in eq .",
    "[ eq : l - gaussian ] , but that the distributions are correlated through their dependence on the random variables @xmath70 and @xmath82 :      to account for the type b systematic uncertainty , we allow any given sample of measurements , @xmath55 , corresponding to theoretical predictions @xmath87 to have a correlated variation from their nominal values by an amount corresponding to a certain fraction @xmath88 of the underlying root - mean - square variation of @xmath70 , i.e. @xmath89 , such that each point moves by an amount @xmath90 , the same fraction @xmath88 of its systematic uncertainty bar ; and similarly for the type c uncertainty",
    ". then the likelihood function for any outcome , including the variation of @xmath88 and @xmath91 would be :      where the last two terms represent @xmath93 and @xmath94 since we assumed the probability of the systematic displacements @xmath95 to be gaussian .",
    "other probability distributions for the correlated systematic uncertainty could be used .",
    "for instance if @xmath78 had represented full extent systematic uncertainties , with equal probability for any @xmath96 , then the @xmath97 term and associated normalization constant @xmath98 would be absent from eq .",
    "[ eq : l - gaussian - sys ] .        because we will eventually take the ratio of the likelihood of a given set of parameters @xmath53 to the maximum likelihood when all the parameters @xmath88 , @xmath91 and @xmath53 are varied ( the minimum value of eq .  [ eq:-2lnl - gaussian - sys2 ] ) so that the terms preceding the exponential in eq .",
    "[ eq : l - gaussian - sys ] cancel because they are not varied .",
    "[ eq:-2lnl - gaussian - sys2 ] follows the @xmath48-distribution with @xmath100 degrees of freedom because it is the sum of @xmath100 independent gaussian distributed random variables ( i.e. in statistical terminology @xmath101 is @xmath102 ) .",
    "this establishes eq .",
    "[ eq:-2lnl - gaussian - sys2 ] as the @xmath48-distributed quantity that we use for least squares fit to the theoretical predictions including the systematic uncertainties .",
    "note that eq .",
    "[ eq:-2lnl - gaussian - sys2 ] agrees with eq .",
    "8 in  @xcite in the discussion of fits with correlated systematics .",
    "the specific procedure is described in the next paragraph .",
    "first ` fit the theory ' to the data by minimizing eq .",
    "[ eq:-2lnl - gaussian - sys2 ] by varying all the parameters to find @xmath103 , @xmath104 , @xmath105 , the values of the parameters which give the overall minimum @xmath106 .",
    "if the @xmath106 for this fit is acceptable for the @xmath107 degrees of freedom , where @xmath108 are the number of parameters in @xmath53 , then the theory is not rejected at this level .",
    "a confidence interval is then found for testing any other set of @xmath54 parameters constrained to specific values , @xmath109 , by again finding the minimum of eq .",
    "[ eq:-2lnl - gaussian - sys2 ] for the @xmath54 fixed values of @xmath109 , by letting all the other parameters including @xmath88 and @xmath91 vary . for constant values of @xmath110 , and large values of @xmath51 ,",
    "the `` likelihood ratio '' @xmath111=-2[\\ln{\\cal l}(\\vec{p}_0)-\\ln{\\cal l}(\\vec{\\hat{p}})]$ ] , i.e. @xmath112 is @xmath48-distributed with @xmath54 degrees of freedom , from which the confidence interval on the parameters can be evaluated .",
    "however , in general , the uncertainty on the parameters is estimated in the gaussian approximation by @xmath113 for @xmath114 standard deviation uncertainties ( for example using a minuit  @xcite type fitting algorithm ) .    for the present data , the statistical and random systematic uncertainties are such that the shift in the measurement @xmath55 due to the correlated systematic uncertainties preserves the fractional uncertainty . in this case the maximum likelihood and least squares methods no longer coincide and we use a least squares fit of eq .",
    "[ eq : lstsq - appendix ] instead of eq .",
    "[ eq:-2lnl - gaussian - sys2 ] to estimate the best fit parameters : @xmath115 } \\qquad ,   \\label{eq : lstsq - appendix}\\ ] ] where @xmath116 is the uncertainty scaled by the multiplicative shift in @xmath55 such that the fractional uncertainty is unchanged under shifts @xmath117                w.a .",
    "horowitz , s. wicks , m. djordjevic , m. gyulassy , in preparation ; s. wicks , w. horowitz , m. djordjevic , m. gyulassy , nucl . phys .",
    "* a783 * , 493 ( 2007 ) .",
    "s. wicks , w. horowitz , m. djordjevic , m. gyulassy , nucl .",
    "a784 * , 426 ( 2007 ) ."
  ],
  "abstract_text": [
    "<S> the phenix experiment has measured the suppression of semi - inclusive single high transverse momentum @xmath0 s in au+au  collisions at @xmath1 gev . </S>",
    "<S> the present understanding of this suppression is in terms of energy - loss of the parent ( fragmenting ) parton in a dense color - charge medium . </S>",
    "<S> we have performed a quantitative comparison between various parton energy - loss models and our experimental data . </S>",
    "<S> the statistical point - to - point uncorrelated as well as correlated systematic uncertainties are taken into account in the comparison . </S>",
    "<S> we detail this methodology and the resulting constraint on the model parameters , such as the initial color - charge density @xmath2 , the medium transport coefficient @xmath3q@xmath4 , or the initial energy - loss parameter @xmath5 . </S>",
    "<S> we find that high transverse momentum @xmath0 suppression in au+au  collisions has sufficient precision to constrain these model dependent parameters at the @xmath6 2025% ( one standard deviation ) level . </S>",
    "<S> these constraints include only the experimental uncertainties , and further studies are needed to compute the corresponding theoretical uncertainties . </S>"
  ]
}