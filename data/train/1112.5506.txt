{
  "article_text": [
    "representing data as graphs is becoming increasingly popular , as technological progress facilitates measuring `` connectedness '' in a variety of domains , including social networks , trade - alliance networks , and brain networks . while the theory of pattern recognition is deep @xcite , previous theoretical efforts regarding pattern recognition",
    "almost invariably assumed data are collections of vectors . here , we assume data are collections of graphs ( where each graph is a set of vertices and a set of edges connecting the vertices ) . for some data sets , the vertices of the graphs are _ labeled _ , that is , one can identify the vertex of one graph with a vertex of the others ( note that this is a special case of assuming vertices are labeled , where each vertex has a unique label ) .",
    "for others , the labels are unobserved and/or assumed to not exist .",
    "we investigate the theoretical and practical implications of the absence of vertex labels .",
    "these implications are especially important in the emerging field of `` connectomics '' , the study of connections of the brain @xcite . in connectomics ,",
    "one represents the brain as a graph ( a brain - graph ) , where vertices correspond to ( groups of ) neurons and edges correspond to connections between them . in the lower tiers of the evolutionary hierarchy ( e.g. , worms and flies )",
    ", many neurons have been assigned labels @xcite . however , for even the simplest vertebrates , vertex labels are mostly unavailable when vertices correspond to neurons .",
    "classification of brain - graphs is therefore poised to become increasingly popular .",
    "although previous work has demonstrated some possible strategies of graph classification in both the labeled @xcite and unlabeled @xcite scenarios , relatively little work has compared the theoretical limitations of the two .",
    "we therefore develop a random graph model amenable to such theoretical investigations .",
    "the theoretical results lead to universally consistent graph classification algorithms , and practical approximations thereof .",
    "we demonstrate that the approximate algorithm has desirable finite sample properties via a real brain - graph classification problem of significant scientific interest : sex classification .",
    "a labeled graph @xmath0 consists of a vertex set @xmath1 , where @xmath2 is the number of vertices , and an edge set @xmath3 , where @xmath4 .",
    "let @xmath5 be a _ labeled _ graph - valued random variable taking values @xmath6 , where @xmath7 is the set of labeled graphs on @xmath8 vertices .",
    "the cardinality of @xmath7 is super - exponential in @xmath8 .",
    "for example , when all labeled graphs are assumed to be simple ( that is , undirected binary edges without loops ) , then @xmath9 .",
    "let @xmath10 be a categorical random variable , @xmath11 , where @xmath12 .",
    "assume the existence of a joint distribution , @xmath13 which can be decomposed into the product of a class - conditional distribution ( likelihood ) @xmath14 and a class prior @xmath15 .",
    "because @xmath8 is finite , the class - conditional distributions @xmath16 can be considered discrete distributions @xmath17 , where @xmath18 is an element of the @xmath19-dimensional unit simplex @xmath20 ( satisfying @xmath21 @xmath22 and @xmath23 ) .      in the above , it was implicitly assumed that the vertex labels were observed .",
    "however , in certain situations ( such as the motivating connectomics example presented in section [ sec:1 ] ) , this assumption is unwarranted . to proceed , we define two graphs @xmath24 to be isomorphic if and only if there exists a vertex permutation ( shuffle ) function @xmath25 such that @xmath26 .",
    "let @xmath27 be a permutation - valued random variable , @xmath28 , where @xmath29 is the space of vertex permutation functions on @xmath8 vertices so that @xmath30 .",
    "[ def : shuffled ] let @xmath31 be a _ shuffled _ graph - valued random variable , that is , a labeled graph valued random variable that has been passed through a random shuffle channel @xmath27 .    extending the above graph - classification model to include this vertex shuffling distribution yields @xmath32",
    "we assume throughout this work ( with loss of generality ) that the shuffling distribution is both _",
    "class independent _ and _ graph independent _ ; therefore , this joint model can be decomposed as @xmath33 as in the labeled case , the shuffled graph class - conditional distributions @xmath34 can be represented by discrete distributions @xmath35 . because @xmath36 can be any of @xmath37 different graphs",
    ", it must be that @xmath38 . when @xmath39 is uniform on @xmath29 , all shuffled graphs within the same isomorphism set are equally likely ; that is @xmath40 for some @xmath41 .",
    "note that one can think of a labeled graph as a shuffled graph for which @xmath27 is a point mass at @xmath42 , where @xmath43 is the identity matrix .",
    "the above shuffling view is natural whenever the vertices of the collection of graphs share a set of labels , but the labeling function is unknown .",
    "however , when the vertices of the collection of graphs have different labels , perhaps a different view is more natural .    an _ unlabeled graph _",
    "@xmath44 is the collection of graphs isomorphic to one another , that is , @xmath45 .",
    "let @xmath44 be an element of the collection of graph isomorphism sets @xmath46 .",
    "the number of unlabeled graphs on @xmath8 vertices is @xmath47 ( see @xcite and references therein ) .",
    "an _ unlabeling function _",
    "@xmath48 is a function that takes as input a graph and outputs the corresponding unlabeled graph .",
    "let @xmath49 be an _",
    "unlabeled _ graph - valued random variable , that is , a labeled graph - valued random variable that has been passed through an unlabeled channel .",
    "in other words , @xmath50 , and takes values @xmath51 .    the joint distribution over unlabeled graphs and classes is therefore @xmath52 , which decomposes as @xmath53 .",
    "the class - conditional distributions @xmath54 over isomorphism sets ( unlabeled graphs ) can also be thought of as discrete distributions @xmath55 where @xmath56 are vectors in the @xmath57-dimensional unit simplex .",
    "comparing shuffling and unlabeling for the independent and uniform shuffle distribution @xmath39 , we have @xmath58 for all @xmath59 .",
    "we consider graph classification in the three scenarios described above : labeled , shuffled , and unlabeled . to proceed , in each scenario we define three mathematical objects : ( i ) a graph classifier , ( ii ) risk , ( iii ) , the bayes optimal classifier , and ( iv ) the bayes risk .      a _ labeled graph classifier _",
    "@xmath60 is any function that maps from labeled graph space to class space .",
    "the risk of a labeled graph classifier @xmath61 under @xmath62 loss is the expected misclassification rate @xmath63 $ ] , where the expectation is taken against @xmath13 . the _ labeled graph bayes optimal classifier _ is given by @xmath64 where @xmath65 is the set of possible labeled graph classifiers .",
    "the _ labeled graph bayes risk _ is given by @xmath66 , where @xmath67 implicitly depends on @xmath13 .",
    "a _ shuffled graph classifier _ is also any function @xmath60 ( note that the set of shuffled graphs is the same as the set of labeled graphs ) .",
    "however , by virtue of the input being a shuffled graph as opposed to a labeled graph , the shuffled risk under @xmath62 loss is given by @xmath68 $ ] , where the expectation is taken against @xmath69 .",
    "the _ shuffled graph bayes optimal classifier _ is given by @xmath70 where @xmath65 is again the set of possible labeled ( or shuffled ) graph classifiers .",
    "the _ shuffled graph bayes risk _ is given by @xmath71 , where @xmath72 implicitly depends on @xmath69 .",
    "an _ unlabeled _ graph classifier @xmath73 is any function that maps from unlabeled graph space to class space .",
    "the risk under @xmath62 loss is given by @xmath74 $ ] , where the expectation is taken against @xmath75 .",
    "the _ unlabeled graph bayes optimal classifier _ is given by @xmath76 the _ unlabeled graph bayes risk _ is given by @xmath77 , where @xmath78 is the set of possible unlabeled graph classifiers and @xmath79 implicitly depends on @xmath75 .",
    "the three bayes optimal graph classifiers can be written explicitly in terms of their model parameters : @xmath80",
    "the result of either shuffling or unlabeling a graph can only degrade , but not improve bayes risk .",
    "this is a restatement of the data processing lemma for this scenario .",
    "specifically , @xcite shows that the data processing lemma indicates that in the classification domain @xmath81 for any transformation @xmath82 and data @xmath83 . in our setting , this becomes :    [ thm:1 ] @xmath84 .",
    "assume for simplicity @xmath85 and @xmath86 .",
    "@xmath87    an immediate consequence of the above proof is that the inequality in the statement of lemma [ thm:1 ] strict whenever the inequality in eq .",
    "is strict :    [ thm:2 ] @xmath88 if and only if there exists @xmath44 such that @xmath89    the above result demonstrates that even when the labels _ do _ carry some class - conditional signal , it may be the case that shuffling or unlabeling does not degrade performance .",
    "in other words , the following two statements are equivalent : ( i ) the labels contain information with regard to the classification task , and ( ii ) some graphs within an isomorphism set are class - conditionally more likely than others : @xmath90 where @xmath91 for some @xmath92 , @xmath93 , and @xmath94 .",
    "uniform shuffling has the effect of `` flattening '' likelihoods within isomorphism sets , from @xmath18 to @xmath95 , so that @xmath95 satisfies @xmath96 .",
    "but just because the shuffling changes class - conditional likelihoods does _ not _ mean that bayes risk must also change .",
    "this result follows immediately upon realizing that posteriors can change without classification performance changing .",
    "the above results are easily extended to consider non - equal class priors and @xmath97-class classification problems . to see this , ignoring ties",
    ", simply replace each minimum likelihood with a sum over all non - maximum posteriors : @xmath98    prior to concluding this section , we remark that one can achieve bayes optimal risk using graph invariants .",
    "a graph invariant on @xmath7 is any function @xmath99 such that @xmath100 for all @xmath101 and @xmath93 ( note that an unlabeling function @xmath102 is a special case of @xmath99 ) .",
    "a graph invariant classifier is a composition of a classifier with an invariant function , @xmath103 .",
    "the bayes optimal graph invariant classifier minimizes risk over all invariants : @xmath104,\\end{aligned}\\ ] ] where @xmath105 is the space of all possible invariants and @xmath106 is the space of classifiers composable with invariant @xmath99 .",
    "the expectation in eq . is taken against @xmath13 or equivalently @xmath69 , since invariants are invariant .",
    "let @xmath107 denote the bayes invariant risk .",
    "[ thm:3 ] @xmath108 .",
    "let @xmath99 indicate in which equivalence set @xmath109 resides ; that is , @xmath110 if and only if @xmath111",
    ". then @xmath112",
    "throughout this paper , we consider two distinct `` flavors '' of graph classifiers that we can estimate from the data : ( i ) bayes plug - in and ( iii ) nearest neighbor .",
    "below , we first introduce bayes plug - in graph classifiers . in the following sections , we will discuss their asymptotic properties , as well as the asymptotic properties of @xmath113 nearest neighbor graph classifiers .      implementing the above optimal classifiers",
    "requires knowing the model parameters .",
    "when the parameters are unknown ( effectively always ) , we assume that the data are sampled identically and independently from some unknown joint distribution : @xmath114 . for _ labeled _ graph classification , @xmath39 is assumed to be the identity function , therefore , @xmath115}$ ] , because when graphs are labeled @xmath116 . for _ shuffled _ graph classification @xmath39 is assumed to be uniform over the permutation matrices , so that all label information is both unavailable and irrecoverable .",
    "the training data are therefore @xmath117}$ ] , where @xmath118 . for _ unlabeled _ graph classification",
    "the training data are again @xmath119 .",
    "our task is to utilize training data to induce a classifier that approximates a bayes classifier as closely as possible .",
    "a _ labeled _ graph bayes plugin classifier , @xmath120 , estimates the parameters @xmath121 using the training data @xmath115}$ ] , and then plugs those estimates into the labeled bayes classifier , eq . , resulting in @xmath122 where the dependency on the training data is implicit in the @xmath123 notation .",
    "a _ shuffled _ graph bayes plugin classifier , @xmath124 , estimates the parameters @xmath125 using the training data @xmath117}$ ] , and then plugs those estimates into the shuffled bayes classifier , eq . , resulting in @xmath126    an _ unlabeled _ graph bayes plugin classifier , @xmath127 , first determines in which unlabeled set each shuffled graph resides , using @xmath99 as defined in section [ sec : gi ] .",
    "then , it estimates the parameters @xmath128 and @xmath129 using the training data @xmath119 .",
    "finally , it plugs those estimates into the unlabeled bayes classifier , eq . , resulting in @xmath130    for brevity , we will sometimes refer to the above three induced classifiers as simply `` classifiers '' .",
    "moreover , the sequence of classifiers ( for example , @xmath131 ) we will also refer to as a `` classifier '' .",
    "the three parametric classifiers , eqs .",
    " , admit classifier estimators that exist , are unique , and moreover , are universally consistent , although the relative convergence rates and values that they converge to differ .",
    "let @xmath132 be the risk of the induced _ labeled _ graph bayes plugin classifier using the training data @xmath133 to obtain maximum likelihood estimators for @xmath121 .",
    "note that @xmath134 is a random variable , as it is a function of the random training data @xmath133 .",
    "this yields    [ thm:4 ] @xmath135 as @xmath136 .",
    "because @xmath137 and @xmath138 are both finite , the maximum likelihood estimates for the categorical parameters @xmath121 are guaranteed to exist and be unique @xcite .",
    "hence , the labeled graph bayes plugin classifier is universally consistent to @xmath139 ( that is , it converges to @xmath139 regardless of the true joint distribution , @xmath140 ) @xcite .",
    "similarly , let @xmath141 be the risk of the induced _ shuffled _ graph bayes plugin classifier using the training data @xmath119 to obtain maximum likelihood estimators for @xmath125 .",
    "this yields    [ cor : sh_plug ] @xmath142 as @xmath136 .",
    "the previous proof rests on the finitude of @xmath7 , which remains finite after shuffling ( uniform or otherwise ) , and therefore , the previous proof holds , replacing @xmath67 with @xmath72 .",
    "thus while one could merely plug the shuffled graphs into @xmath95 , such a procedure is inadvisable .",
    "specifically , the above procedure does not use the fact that all @xmath143 whenever @xmath144 for some @xmath145 .",
    "instead , consider the risk @xmath146 of the induced _ unlabeled _ graph bayes plugin classifier upon using the @xmath99 function to map each shuffled graph to its corresponding unlabeled graph , and then obtaining maximum likelihood estimates of the unlabeled graph parameters , @xmath147 .",
    "[ cor : un_plug ] @xmath148 as @xmath136 .",
    "because @xmath149 ( by a factor of approximately @xmath150 ) , it follows that classifying by first projecting the graphs into a lower dimensional space should yield improved performance .",
    "specifically , we have the following result :    [ thm : tdomp ] @xmath151 dominates @xmath152 for _ shuffled _ graph data .",
    "consider the scalar @xmath153 decomposed into the vector @xmath154 , where each @xmath155 .",
    "note that each @xmath156 .",
    "yet , the estimators , @xmath157 and @xmath158 are not equal , because the former can borrow strength from all shuffled graphs within the same unlabeled graph , but the latter does not . assuming without loss of generality that the class priors are equal and known , the above domination claim is equivalent to stating that for each @xmath109 , @xmath159 \\leq       { \\mathbb{p}}[{\\operatornamewithlimits{argmax}}_{y \\in { \\mathcal{y } } } { \\hat{\\theta}}'_{g|y }   \\neq { \\operatornamewithlimits{argmax}}_{y \\in { \\mathcal{y } } } \\theta'_{g|y } | { \\mathcal{t}}_s'].\\end{aligned}\\ ] ] because @xmath160 , the only difference between the two sides of the above inequality is the estimators .",
    "we know that the estimators have the following distributions :    @xmath161    where @xmath162 is the number of observations of any @xmath111 in the training data , and @xmath163 is the number of observations of @xmath109 in the training data . from this",
    ", we see that for each @xmath109 , @xmath164 will have a tighter concentration around the truth due to is borrowing strength , because @xmath165 , so our result holds .",
    "corollary [ cor : un_plug ] demonstrates that one can induce a universally consistent classifier @xmath151 using eq . .",
    "lemma [ thm : tdomp ] further shows that the performance of @xmath151 dominates @xmath152 . yet",
    ", using @xmath151 is practically useless for two reasons .",
    "first , it requires solving @xmath166 graph isomorphism problems .",
    "unfortunately , there are no algorithms for solving graph isomorphism problems with worst - case performance known to be in only polynomial time @xcite .",
    "second , the number of parameters to estimate is super - exponential in @xmath8 ( @xmath167 ) , and acceptable performance will typically require @xmath168 .",
    "we can therefore not even store the parameter estimates for small graphs ( e.g. , @xmath169 ) , much less estimate them .",
    "this motivates consideration of an alternative strategy .",
    "a @xmath113 nearest - neighbor ( @xmath170nn ) classifier using euclidean norm distance is universally consistent to @xmath67 for vector - valued data as long as @xmath171 with @xmath172 as @xmath136 @xcite .",
    "this non - parametric approach circumvents the need to estimate many parameters in high - dimensional settings such as graph - classification .",
    "the universal consistency proof for @xmath113nn was extended to graph - valued data in reference @xcite , which we include here for completeness .",
    "specifically , to compare labeled graphs , reference @xcite considered a frobenius norm distance @xmath173 where @xmath174 is the adjacency matrix representation of the labeled graph , @xmath175 .",
    "let @xmath176 denote the frobenius norm @xmath113nn classifier on _ labeled _ graphs using @xmath177 , and let @xmath178 indicate the misclassification rate for this classifier .",
    "reference @xcite showed :    [ thm:5 ] @xmath179 as @xmath136 .    because both @xmath180 and @xmath138 have finite cardinality , the law of large numbers ensures that eventually as @xmath136 , the plurality of nearest neighbors to a test graph will be identical to the test graph .",
    "let @xmath181 denote the frobenius norm @xmath113nn classifier on _ shuffled _ graphs using @xmath182 , and let @xmath183 indicate the misclassification rate for this classifier .",
    "from the above lemma and corollary [ cor : sh_plug ] , the below follows immediately :    [ cor : knn1 ] @xmath184 as @xmath136 .",
    "given shuffled graph data @xmath119 , however , other distance metrics appear more `` natural '' to us .",
    "for example , consider the `` graph - matched frobenius norm '' distance : @xmath185 where @xmath186 and @xmath187 are shuffled adjacency matrices .",
    "let @xmath188 indicate the misclassification rate of the @xmath113nn classifier using the above graph - matched norm @xmath182 _ shuffled _ graphs , and let @xmath183 indicate the misclassification rate for this classifier . given an exact graph matching function ",
    "a function that actually solves eq .",
    "we have the following result :    [ cor : sh_knn ] @xmath189 as @xmath136 .    thus , given shuffled data @xmath119 , one could consider either @xmath190 or @xmath191 .",
    "interestingly , when the data are labeled graphs , @xmath133 , one can outperform @xmath190 by _ shuffling _ , that is , by apparently destroying the label information .",
    "consider an example in which @xmath192 , such that no information is in the labels .",
    "in such scenarios , shuffling can effectively borrow strength from different labeled graphs that are within the same unlabeled graph set .",
    "let @xmath193 indicate the misclassification rate of the @xmath113nn classifier using @xmath182 _ labeled _ graphs , and let @xmath194 indicate the misclassification rate for this classifier .",
    "we therefore state without proof :    [ thm : nodom ] neither @xmath195 nor @xmath190 dominates when data are _ labeled _ graphs .",
    "thus , when the training data consists of shuffled graphs , the best universally consistent classifier ( of those considered herein ) is a @xmath113nn that uses @xmath182 as the distance metric .",
    "other universally consistent classifiers that we considered either require estimating more parameters than there are molecules in the universe , or are inadmissible under @xmath62 loss . when vertex labels are available , no classifier dominates .",
    "the above theoretical results consider bayes plug - in and @xmath113nn classifiers . here",
    "we consider other classifiers .",
    "specifically , let @xmath196 be the misclassification rate for some classifier that operates on @xmath119 , that is , only has access to shuffled graphs .",
    "consider the set of seven graph invariants studied in @xcite : size , max degree , max eigenvalue , scan statistic , number of triangles , and average path length . via monte",
    "carlo , @xcite was unable to find a uniformly most powerful graph invariant ( test statistic @xcite ) for a particular hypothesis testing scenario with unlabeled graphs .",
    "the above results , however , indicate that there exists optimal classifiers ( or test statistics ) for any unlabeled or shuffled graph setting . to proceed , let @xmath197 be the _ chance _ classifier , that is @xmath198 and let @xmath199 be the misclassification rate for this classifier .",
    "moreover , let @xmath200 be the risk of the invariant classifier that is equivalent to the unlabeled bayes plug - in classifier ( see lemma [ thm:3 ] ) . from the above results , it follows that :    [ thm : order ] in expectation , + @xmath201 as @xmath136 .",
    "while asymptotic results can be informative and insightful , understanding the computational properties of the different classifiers can be as ( or even more ) informative for real applications .",
    "table [ tab : comp ] compares the space and time complexity of the various classifiers considered above .",
    "only the @xmath170nn classifiers have the property that they do not require more space than there are atoms in the universe ( for any @xmath8 bigger than @xmath202 ) . of those ,",
    "the labeled @xmath113nn classifier does not require time exponential in the number of vertices .",
    "therefore , we only found one type of classifier with performance guarantees that has both polynomial space and time .",
    "unfortunately , the finite sample performance of this classifier is abysmal .",
    "this motivates constructing approximate classifiers .",
    ".order of computational properties for training the various shuffled graph classifiers . [ cols=\">,^,^,^\",options=\"header \" , ]     [ tab : comp ]",
    "we buttress the above theoretical results via numerical experiments .",
    "the asymptotic results combined with the computational complexities of the above described algorithm suggest that none of the proposed algorithms have all the properties we effectively require for real world applications , in particular , polynomial space and time complexity , as well as reasonable convergence rates .",
    "we therefore propose a different algorithm , which lacks universal consistency , but can be run on real data with good hope for reasonable performance . in particular , we modify @xmath191 , the _ unshuffled _ @xmath170nn classifier . instead of requiring this classifier to actually solve the graph matching problem , eq . , we use a recently proposed state - of - the - art approximate cubic time algorithm @xcite . denote this classifier @xmath203 .",
    "a `` connectome '' is a brain - graph in which vertices correspond to ( groups of ) neurons , and edges correspond to connections between them .",
    "diffusion magnetic resonance ( mr ) imaging and related technologies are making the acquisition of mr connectomes routine @xcite .",
    "49 subjects from the baltimore longitudinal study on aging comprise this data , with acquisition and connectome inference details as reported in @xcite .",
    "each connectome yields a @xmath204 vertex simple graph ( binary , symmetric , and hollow adjacency matrix ) . associated with each graph is class label based on the sex of the individual ( 24 males , 25 females ) .",
    "because the vertices are labeled , we can compare the results of having the labels and not having the labels .",
    "consider the following five classifiers :    * @xmath177-@xmath205nn : a @xmath205-nearest neighbor ( @xmath205nn ) with frobenius norm distance on the _ labeled _ adjacency matrices .",
    "* @xmath182-@xmath205nn : a @xmath205nn with frobenius norm distance on the _ shuffled _ adjacency matrices .",
    "* @xmath206-@xmath205nn : a @xmath205nn with an _ approximate _ graph - matched frobenius norm distance on the shuffled adjacency matrices , as described above .",
    "because graph - matching is @xmath207-hard @xcite , we instead use an inexact graph matching approach based on the quadratic assignment formulation described in @xcite , which only requires @xmath208 time . *",
    "@xmath99-@xmath205nn : a @xmath205nn with euclidean distance using the seven graph invariants described above .",
    "prior to computing the euclidean distance , for each invariant , we rescale all the values to lie between zero and one . *",
    "@xmath209 : use the chance classifier defined above .",
    "performance is assessed by leave - one - out misclassification rate .",
    "figure [ fig:1 ] reifies the above theoretical results in a particular finite sample regime .",
    "we apply the five algorithms discussed above to sub - samples of the connectome data , which shows approximate convergence rates for this data . fortunately",
    ", this real data example supports the main lemmas of this work .",
    "specifically , the @xmath113nn classifier using @xmath177 on the _ labeled _ graphs ( dashed gray line ) achieves the lowest misclassification rate for all @xmath166 , which one would expect if labels contain appropriate class signal .",
    "moreover , the @xmath113nn classifier using the inexact graph - matching frobenius norm on the shuffled adjacency matrices , @xmath206 , performs best of all classifiers using only shuffled graphs ( compare dashed black line with solid black and gray lines ) . on the other hand , while the @xmath113nn classifier using the frobenius norm on shuffled graphs , @xmath182 , must eventually converge to @xmath210 , its convergence rate is quite slow , so the classifier using standard invariants @xmath99 outperforms the simple @xmath182 based @xmath113nn .",
    ", such that errorbars were neglibly small .",
    "five classifiers were compared , as described in main text . note that when @xmath166 is larger than @xmath211 , as predicted by theory , we have @xmath212 .",
    "moreover , @xmath213 . ]",
    "in this work , we address both the theoretical and practical limitations of classifying shuffled graphs , relative to labeled and unlabeled graphs . specifically , first we construct the notion of shuffled graphs and shuffled graph classifiers in a parallel fashion with labeled and unlabeled graphs / classifiers , as we were unable to find such notions in the literature .",
    "then , we show that shuffling the vertex labels results in an irretrievable situation , with a possible degradation of classification performance ( lemma [ thm:1 ] ) .",
    "even if the vertex labels contained class - conditional signal , bayes performance may remain unchanged ( lemma [ thm:2 ] ) .",
    "moreover , although one can not recover the vertex labels , one can obtain a bayes optimal classifier by solving a large number of graph isomorphism problems ( lemma [ thm:3 ] ) .",
    "this resolves a theoretical conundrum : is there a set of graph invariants that can yield a universally consistent graph classifier ? when the generative distribution is unavailable , one can induce a consistent and efficient `` unshuffling '' classifier by using a graph - matching strategy ( corollary [ cor : un_plug ] ) . while this unshuffling approach dominates the more nave approach ( lemma [ thm : tdomp ] ) , it is intractable in practice due to the difficulty of graph matching and the large number of isomorphism sets . instead",
    ", a frobenius norm @xmath113nn classifier applied to the adjacency matrices may be used , which is also universally consistent ( corollary [ cor : sh_knn ] ) .",
    "surprisingly , none of the considered classifiers dominate the other for labeled data ( lemma [ thm : nodom ] ) , yet asymptotically , we can order shuffled graph classifiers ( lemma [ thm : order ] ) .",
    "because graph - matching is @xmath207-hard , we instead use an approximate graph - matching algorithm in practice ( see @xcite for details ) . applying these @xmath113nn classifiers to a problem of considerable scientific interest  classifying human mr connectomes",
    " we find that even with a relatively small sample size ( @xmath214 ) , the approximately graph - matched @xmath113nn algorithm performs nearly as well as the @xmath113nn algorithm _ using _ vertex labels , and slightly better than a @xmath113nn algorithm applied to a set of graph invariants proposed previously @xcite .",
    "this suggests that the asymptotics might apply even for very small sample sizes .",
    "thus , this theoretical insight has led us to improved practical classification performance .",
    "extensions to weighted or ( certain ) attributed graphs are straightforward .",
    "this work was partially supported by the research program in applied neuroscience .",
    "l.  devroye , l.  gyrfi , g.  lugosi , and l.  gyorfi , _ a probabilistic theory of pattern recognition_.1em plus 0.5em minus 0.4emnew york : springer , 1996 .",
    "[ online ] .",
    "available : http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20&amp;path=asin/0387946187        j.  white , e.  southgate , j.  n. thomson , and s.  brenner , `` the structure of the nervous system of the nematode caenorhabditis elegans . ''",
    "_ philosophical transactions of royal society london .",
    "series b , biological sciences _ , vol .",
    "1165 , pp . 1340 , 1986 .",
    "r.  p.  w. duin , e.  pkalska , and e.  pkalskab , `` the dissimilarity space : bridging structural and statistical pattern recognition , '' _ pattern recognition letters _ , vol . in press ,",
    "april , may 2011 .",
    "[ online ] .",
    "available : http://linkinghub.elsevier.com/retrieve/pii/s0167865511001322    http://www.sciencedirect.com/science/article/pii/s0167865511001322    http://dx.doi.org/10.1016/j.patrec.2011.04.019[http://linkinghub.elsevier.com/retrieve/pii/s0167865511001322    http://www.sciencedirect.com/science/article/pii/s0167865511001322    http://dx.doi.org/10.1016/j.patrec.2011.04.019 ]          j.  t. vogelstein , r.  j. vogelstein , and c.  e. priebe , `` are mental properties supervenient on brain properties ? '' _ nature scientific reports _ , vol . in press , p.  11",
    "[ online ] .",
    "available : http://arxiv.org/abs/0912.1672    h.  pao , g.  a. coppersmith , c.  e. priebe , h.  p. ao , g.  a.  c. oppersmith , and c.  e.  p. riebe , `` statistical inference on random graphs : comparative power analyses via monte carlo , '' _ journal of computational and graphical statistics _ , pp . 122 , 2010 .",
    "[ online ] .",
    "available : http://pubs.amstat.org/doi/abs/10.1198/jcgs.2010.09004      p.  hagmann , l.  cammoun , x.  gigandet , s.  gerhard , p.  ellen grant , v.  wedeen , r.  meuli , j .-",
    "thiran , c.  j. honey , and o.  sporns , `` mr connectomics : principles and challenges , '' _ j neurosci methods _ , vol .",
    "194 , no .  1 ,",
    "pp . 3445 , 2010 .",
    "[ online ] .",
    "available : http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=retrieve&db=pubmed&dopt=citation&list_uids=20096730    w.  r. gray , j.  a. bogovic , j.  t. vogelstein , b.  a. landman , j.  l. prince , and r.  j. vogelstein , `` magnetic resonance connectome automated pipeline : an overview . ''",
    "_ ieee pulse",
    "_ , vol .  3 , no .  2 ,",
    "pp . 428 , mar",
    "[ online ] .",
    "available : http://ieeexplore.ieee.org/xpl/articledetails.jsp?arnumber=6173097    m.  r. garey and d.  s. johnson , _ computers and intractability : a guide to the theory of np - completeness ( series of books in the mathematical sciences)_.1em plus 0.5em minus 0.4emw .",
    "h. freeman , 1979 .",
    "[ online ] .",
    "available : http://www.amazon.com/computers-intractability-np-completeness-mathematical-sciences/dp/0716710455    j.  t. vogelstein , j.  c.  m. conroy , l.  j. podrazik , s.  g. kratzer , d.  e. fishkind , r.  j. vogelstein , and c.  e. priebe , `` ( brain ) graph matching via fast approximate quadratic programming , '' _ arxiv preprint _"
  ],
  "abstract_text": [
    "<S> we develop a formalism to address statistical pattern recognition of graph valued data . </S>",
    "<S> of particular interest is the case of all graphs having the same number of uniquely labeled vertices . when the vertex labels are latent , such graphs are called </S>",
    "<S> _ shuffled graphs_. our formalism provides insight to trivially answer a number of open statistical questions including : ( i ) under what conditions does shuffling the vertices degrade classification performance and ( ii ) do universally consistent graph classifiers exist ? the answers to these questions lead to practical heuristic algorithms with state - of - the - art finite sample performance , in agreement with our theoretical asymptotics . </S>"
  ]
}