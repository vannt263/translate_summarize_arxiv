{
  "article_text": [
    "as customers and competitors rely on yelp reviews to judge the quality of a business , it is important for yelp to be able to predict the sentiment polarity and rating of a given review . with yelp s newly released dataset @xcite",
    ", we perform two types of classifications based on the review text alone : simple positive / negative classification , and a star rating ( 1 through 5 inclusive ) . to build these classifiers",
    ", we will use naive bayes , support vector machines , and logistic regression .",
    "note that we are using the review text as the only input to the classifier ( e.g. , given the review `` the best british food in new york '' , we want to predict ` positive ' , or 5 stars ) .",
    "it is useful for yelp to associate review text with a star rating ( or at least a positive or negative assignment ) accurately in order to judge how helpful and reliable certain reviews are .",
    "perhaps users could give a good review but a bad rating , or vice versa .",
    "also yelp might be interested in automating the rating process , so that all users would have to do is write the review , and yelp could give a suggested rating .",
    "given a review of a business , we try to solve two problems : positive or negative ( sentiment polarity ) classification , and 5-star classification . in both cases the input to the classifier is a string representing a review , and the output ( or class label ) is either _ positive _ or _ negative _ in the former case , and an integer in the interval @xmath0 $ ] in the latter case .",
    "the input to the classifier is text only , but this text will be uncleaned with a lot of unnecessary characters .",
    "for example , it could have unusual capitalization , extra whitespace , and of course punctuation , which is not needed for classification . therefore all of these things must be cleaned .",
    "furthermore , we are only interested in tokens with two or more alphanumeric characters .",
    "some tokens may be stop words , that is , words that convey no information but are very common in english .",
    "so we should remove these also , as they will reduce the accuracy of the classifier ( or at least slow down the classifier as there would be more unnecessary text to process ) .",
    "+ once the text is cleaned , we need to build feature vectors .",
    "we will use a bag of words representation to store the occurrences of each word in a matrix .",
    "( see the next section for more details . )",
    "now that we have these occurrence counts , we still need to weigh each word , i.e. , how important it is to a review in the corpus .",
    "we will use the _ tf - idf _",
    "statistic for this .",
    "finally we can build the classifier with either naive bayes , support vector machines , or logistic regression .",
    "there are four steps to perform : first we preprocess the data , then we build a vectorizer , then a transformer , and finally the classifier . for all of these steps we use the _ scikit - learn _ package for python",
    ".      text preprocessing is done by a ` countvectorizer ` class from ` sklearn.feature_extraction.text ` . by default",
    ", a built - in regular expression specifies what is considered a token : it must have two or more alphanumeric characters ( punctuation is always ignored ) .",
    "furthermore , all the text is made lowercase with extra whitespace ignored .",
    "stop words are also removed .",
    "after preprocessing , we need to transform the text into feature vectors . for that we use the bag of words representation .",
    "to each word in all reviews we assign a unique integer i d .",
    "this assignment is done with a dictionary or map from words to integers . and",
    "for each review @xmath1 , we count the number of occurrences of each word @xmath2 , and this count is stored in @xmath3 $ ] , where @xmath4 is the index of @xmath2 in the dictionary .",
    "note that the majority of the elements in @xmath5 will be zero , that is , @xmath5 is a sparse matrix .",
    "this is because for each review , a relatively small number of distinct words are used .",
    "( an implementation detail : to save memory , @xmath5 is stored as a ` scipy.sparse ` matrix , so that only the nonzero elements of the feature vectors remain in memory . )      now we need to build the transformer to calculate the weight of each word . for this",
    "we use the _ tf - idf _ statistic .",
    "so at this point , although we have a count of the occurrences of each word , there is a discrepancy between long and short reviews , as the former will have a higher count than the latter .",
    "therefore we divide the occurrence count of each word in a review by the total number of words in the review .",
    "we call these new features term frequencies , or _ tf_. + there remains a problem with _",
    "tf _ : some words could appear in many reviews ranging from 1 to 5 stars , so they are not informative because they are not unique to a certain class of reviews .",
    "the solution is called inverse document frequency , or _",
    "idf_. the idea is to offset or downscale the weight of a word based on its frequency in the corpus .      finally , the class labels in this problem are simple . in the case of binary positive or negative classification ,",
    "a review is assigned the _ positive _ label if its star rating is greater than or equal to 3 , and any review with a rating less than 3 is assigned the _ negative _ label . in the case of 5-star classification , the review is assigned its star rating .      to build the classifier we use three different supervised techniques : naive bayes , support vector machines , and logistic regression .",
    "these techniques were chosen as they are simple to understand and implement , they run relatively quickly , and they have historically given good results for text classification @xcite . in each case",
    "we used 70% of the data for training , and the rest for testing .      to read the data file , which has a json object on each line",
    ", we use a function ` loaddata(filename , startline , endline ) ` to read between lines # ` startline ` and # ` endline ` . ` loaddata ` returns two lists : one containing each review , and the other containing the corresponding rating .",
    "the elements of the latter will be either _ positive _ or _ negative _ , or an integer in the interval @xmath0 $ ] , depending on whether we do positive / negative or 5-star classification .",
    "+ note that we use ` loaddata ` to load both the training and testing data .",
    "so of course , the intersection between the two sets is empty , thanks to the interval of line numbers as parameters .",
    "+ now that the data is loaded and we have built the vectorizer and transformer , we can build the classifier using ` sklearn.pipeline.pipeline ` .",
    "the ` pipeline ` class `` behaves like a compound classifier '' @xcite class .",
    "the transformer is the _ tf - idf _",
    "statistic , and the classifier is built using either ` sklearn.naive_bayes.multinomialnb ` for naive bayes , ` sklearn.linear_model.sgdclassifier ` for support vector machines , or , for logistic regression , ` sklearn.linear_model.logisticregression ` .",
    "for example , using the ` pipeline ` class , we can build and train a naive bayes classifier as in the code in figure  [ fig : code ] .    in figure",
    "[ fig : code ] , we first instantiate ` countvectorizer ` and specify that we want to remove english stop words",
    ". then we use ` tfidftransformer ` to calculate the weights of each word , and lastly we create the naive bayes classifier with ` multinomialnb ` .",
    "after the classifier is built , we train it by simply passing in the training data and training labels .",
    "for this project we use the dataset from the yelp dataset challenge .",
    "the data are in json format .",
    "the format of the review data is shown in figure  [ fig : data ] .",
    "we are interested in two fields only : ` text ' and ` stars ' .",
    "the other fields are not used here , but they could be useful as features for future work ( see the final discussion section ) .",
    "+    the file containing the review data has a json object formatted as in figure  [ fig : data ] on each line .",
    "this file has 1,569,264 reviews , of which we use varying amounts ( see figures  [ fig : pndataplot ] and  [ fig:5dataplot ] ) .",
    "the review text in the data file is uncleaned and taken directly from the website without modification .",
    "therefore , as described above , some text preprocessing was necessary before building the classifier . to read this data we use the ` json ` package built in to python",
    "+ it is worth mentioning that this review data is by no means comprehensive .",
    "it includes data from 10 cities total , in the united kingdom , germany , canada , and the united states .",
    "furthermore , the data comes from all types of businesses on yelp , not just restaurants , for instance .",
    "the results for both positive / negative classification and 5-star classification are shown in figure  [ fig : accuracy ] .    [ cols=\"^,^,^,^\",options=\"header \" , ]      like their speeds , the accuracies for both naive bayes and support vector machines are quite similar , differing by at most about 4% when using the same amount of data .",
    "the accuracy of logistic regression is the highest in both types of classification .",
    "the results we obtained are similar to what we had anticipated in some ways , and surprising in other ways .",
    "first of all , positive / negative classification is a much simpler problem than 5-star classification , largely because it is less specific ; for example , both 1 and 2 star reviews will be classified as negative , whereas with 5-star classification , it could be hard to tell the difference between the reviews since they will both use similar language .",
    "therefore it was expected that we would have far better accuracy for positive / negative classification than for 5-star classification , which was indeed the case .",
    "another expected result was that more data would improve accuracy .",
    "this turned out to be true to some extent , as more data provided further training examples .",
    "+ one surprising result was the better performance of naive bayes in the case of positive / negative classification .",
    "it is a very simple classifier , and we had expected support vector machines to outperform it in both types of classification .",
    "the difference in accuracy in both cases is about 4% , which is slight but not insignificant .",
    "+ another surprise was the excellent performance of logistic regression .",
    "it was expected to outperform naive bayes , but not necessarily support vector machines , and not by such a margin : its accuracy was 9.84% and 4.36% higher than support vector machines in positive / negative and 5-star classification respectively .      according to jong s paper `` predicting rating with sentiment analysis '' @xcite , which also uses yelp s dataset , `` for opinionated texts , there is usually a 70% agreement between human raters '' .",
    "our best result for positive / negative classification exceeds that by 22.90% .",
    "however , for 5-star classification , our maximum accuracy is about 6.08% lower , but far better than a random star guess , which would have an accuracy of only 20% .",
    "+ for positive / negative classification , jong achieved a maximum test accuracy of about 78% with naive bayes , compared to our maximum test accuracy of 92.90% with logistic regression .",
    "+ carbon et al .",
    "@xcite worked on 5-star classification of yelp reviews as well , using several models including gaussian discriminant analysis and logistic regression . using their entire feature set",
    ", they achieved a maximum test accuracy of 46.09% with gda , compared to our maximum test accuracy of 63.92% with logistic regression .",
    "a.   _ use a different learning model . _",
    "the models used here are quite simple .",
    "a more advanced one such as random forests or neural networks could produce better results , perhaps with a trade - off in time depending on the model .",
    "b.   _ use more data .",
    "_ although there are almost 1.6 million reviews in yelp s dataset , more data could improve classification accuracy . in our results ,",
    "the accuracy of logistic regression in particular increased with greater data usage ( see figures  [ fig : pndataplot ] and  [ fig:5dataplot ] ) .",
    "c.   _ use more features .",
    "_ the only input to our classifiers was the review text .",
    "however , there is an abundance of other interesting features in yelp s dataset that could be used for classification .",
    "for example , each review itself has a rating ( called ` votes ' ) of how funny , cool , or useful it is .",
    "perhaps a review with many such votes could be considered more reliable than other reviews with fewer votes , and therefore the predicted rating from the classifier would be deemed more trustworthy with a higher score assigned to it .",
    "another idea would be to use the business i d of the review to look up attributes of the business to help you determine the reliability of a review s rating .",
    "so you would effectively be building and combining two different classifiers ( one for the review , and one for the business being reviewed ) , both with the goal of predicting a review s star rating .",
    "overall the results were satisfactory for positive / negative classification , but there is room for improvement for 5-star classification .",
    "there are many general challenges to overcome besides using more data or more features for 5-star classification . as pang and lee",
    "discuss , `` some potential obstacles to accurate rating inference include lack of calibration ( e.g. , what an understated author intends as high praise may seem lukewarm ) , author inconsistency at assigning fine - grained ratings , and ratings not entirely supported by the text '' @xcite . these are nontrivial problems , and it is hard to imagine how to solve them by any kind of data preprocessing before building the feature vectors , or by other means . with that said ,",
    "there are several promising avenues for future research which could considerably improve 5-star classification accuracy .",
    "bo pang and lillian lee , `` seeing stars : exploiting class relationships for sentiment categorization with respect to rating scales , '' cornell univ . ,",
    "ithaca , ny and carnegie mellon univ . , pittsburgh , pa , 2005 ."
  ],
  "abstract_text": [
    "<S> online reviews of businesses have become increasingly important in recent years , as customers and even competitors use them to judge the quality of a business . </S>",
    "<S> yelp is one of the most popular websites for users to write such reviews , and it would be useful for them to be able to predict the sentiment or even the star rating of a review . in this paper , we develop two classifiers to perform positive / negative classification and 5-star classification . we use naive bayes , support vector machines , and logistic regression as models , and achieved the best accuracy with logistic regression : 92.90% for positive / negative classification , and 63.92% for 5-star classification . </S>",
    "<S> these results demonstrate the quality of the logistic regression model using only the text of the review , yet there is a promising opportunity for improvement with more data , more features , and perhaps different models . </S>"
  ]
}