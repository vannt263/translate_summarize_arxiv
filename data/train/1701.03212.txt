{
  "article_text": [
    "-way or multi - class classification , where the goal is to correctly predict one out of @xmath0 classes for any data sample , poses one of the most challenging problems in supervised machine learning .",
    "however , a large number of real - world sensing problems in a variety of domains such as computer vision , robotics and remote diagnostics , do consist of multiple classes .",
    "examples include human face recognition for surveillance , object detection for mobile robot navigation , and critical equipment condition monitoring for preventive maintenance .",
    "the number of classes in these problems often exceeds ten and sometimes goes up to a hundred depending on the complexity of the sensed system or environment and the number and types of sensor modalities .    while a whole host of techniques such as artificial neural networks , decision trees , nave bayes , nearest neighbors , and support vector machines ( svms ) have been successfully applied for binary classification problems , extensions of these techniques",
    "have had mixed success in addressing multi - way classification problems with more than a few classes .",
    "other approaches involving hierarchical classification or transformation to binary classification have not been particularly successful either .",
    "the success rates diminish further in the absence of a large number of data samples for each of the labeled classes .",
    "the primary reason is that all of these methods encounter difficulties in selecting the right set of distinguishing features among the different classes .",
    "recent research has started investigating completely new techniques for multi - way classification that attempt to better understand the structure of the underlying high - dimensional sample space .",
    "one such class of techniques is topological data analysis , or tda in short .",
    "tda represents the unknown sample space in the form of persistent shape descriptors that are coordinate free and deformation invariant .",
    "thus , the descriptors define topological features and yield insights regarding suitable feature selection .    here",
    ", we bring together the two research areas of tda and sparse sampling in the context of multi - way classification . in particular , we leverage sparse sampling for optimal feature selection once the features are extracted using a state - of - the - art tda method in challenging computer vision problems .",
    "the problems comprise three benchmark data sets pertaining to 3d meshes of synthetic and real human postures and textured images , respectively .",
    "we call our new method the sparse - tda algorithm and show that it achieves comparable accuracy as the tda method with significantly lower training times .",
    "thus , our method opens up a new direction in making online multi - way classification practically feasible .",
    "over the past decade or so , an increasing interest in utilizing tools from algebraic topology to extract insights from high dimensional data has given rise to the field of tda .",
    "the successful applications of tda have spanned a large number of areas , ranging from computer vision @xcite to medical imaging @xcite , biochemistry @xcite , neuroscience @xcite and materials science @xcite .",
    "a predominant tool in tda is persistent homology , which tracks the evolution of the topological features in a multi - scale manner to avoid information loss @xcite .",
    "the multi - scale information is summarized by the persistence diagram ( pd ) , a multiset of points in @xmath1 that encodes the lifetime ( i.e. , persistence ) of the features .",
    "more recently , researchers have started utilizing tda for machine learning problems .",
    "pachauri et al .",
    "@xcite first computed a gaussian kernel to estimate the density of points on a regular grid for each rasterized pd , and fed the discrete density estimation as a vector into an svm classifier without any feature selection .",
    "however , their method did not establish the stability of the kernel - induced vector representation .",
    "reininghaus et al .",
    "@xcite then designed a stable multi - scale kernel for pds motivated by scale - space theory as will be described in the next section .",
    "experiments on three benchmark data sets showed that this method greatly outperformed an alternative approach based on persistence landscape @xcite , a popular statistical treatment of tda . similar to this work , kusano et al .",
    "@xcite proposed a stable persistence weighted gaussian kernel , allowing one to control the effect of persistence .",
    "however , the computational complexity of both the kernel - based methods for calculating the gram matrix is @xmath2 if there are @xmath3 pds for training and the pds contain at most @xmath4 points , which can be quite expensive for many practical applications . to enable large - scale computations with pds",
    ", recent methods have mapped each pd to a stable vector to allow direct use of vector - based learning methods .",
    "for example , adams et al .",
    "@xcite constructed vectors by discretizing the weighted sum of probability distributions centered at each point in transformed pds .",
    "carrire et al .",
    "@xcite rearranged the entries of the distance matrix between points in a pd and bonis et al .",
    "@xcite adopted a pooling scheme to construct the vectors .    in this work ,",
    "we employ the vector representation from @xcite and integrate with a sparse sampling method using qr pivots to identify discriminative features in the presence of noisy and redundant information to further improve classifier training time and sometimes prediction accuracy .",
    "we first introduce the basic terminology of any tda method by formally defining the mathematical operations and stating the key results .",
    "we then use these definitions and results to summarize the multi - scale kernel tda method .",
    "while the kernel tda method is directly adopted from @xcite , we outline it here for the sake of completeness .      *",
    "filtration : * in computational topology , the  shapes \" of data ( e.g. , point clouds , shapes , images ) are frequently described by simplicial ( or cubical ) complexes .",
    "a filtration of a finite simplicial ( or cubical ) complex @xmath5 is a sequence of simplicial complexes @xmath6 such that @xmath7 . a common way to generate",
    "a filtration is to consider the sublevel sets @xmath8)$ ] of a descriptor function @xmath9 on a topological space @xmath10 indexed by a parameter @xmath11 .",
    "* persistent homology : * as a prevalent tool in tda , persistent homology is an algebraic approach that quantifies topological features during a filtration of  shapes \" @xcite .",
    "accordingly , given a topological space @xmath10 and a descriptor function @xmath9 , persistent homology essentially studies the topological changes of the sublevel sets @xmath12)$ ] as @xmath13 increases from @xmath14 to @xmath15 . during filtration ,",
    "topological features appear and disappear at different scales that are referred to as the _ birth _ and _ death _ times of the features .",
    "the short - lived features are considered as noise terms .",
    "* persistence diagram ( pd ) : * a pd is a concise summary of the topological information captured by persistent homology . from a geometric perspective , the topological features are interpreted as @xmath16-dimensional holes , e.g. , connected components as 0-dimension holes , tunnels as 1-dimensional holes and voids as 2-dimensional holes .",
    "thus , a @xmath16-dimensional pd is a collection of points in @xmath1 , where each point @xmath17 represents a @xmath16-dimensional hole that is born at time @xmath18 and filled at time @xmath19 .",
    "= -1    * stability : * a critical property of pds is their stability with respect to input noise @xcite .",
    "a general metric associated with pds is the _",
    "@xmath20-wasserstein distance_. the @xmath20-wasserstein distance between two pds @xmath21 and @xmath22 is defined by @xmath23 where @xmath24 is over all bijections from the points in @xmath21 to the points in @xmath22 .",
    "let @xmath25 be a compact triangulable metric space and @xmath26 be two tame lipschitz functions with the corresponding pds @xmath27 and @xmath28 for each dimension @xmath16 .",
    "it has been prove that assuming @xmath25 satisfies a weak condition ( see details in @xcite ) , there exist constants @xmath29 and @xmath30 , which depend on @xmath25 and the lipschitz constants of @xmath31 and @xmath32 , such that @xmath33 this upper bound on @xmath34 implies that a pd @xmath27 is stable with respect to the @xmath20-wasserstein distance under small perturbations of @xmath31 .    * kernel : * given a set @xmath35 , @xmath36 is a kernel if there exists a hilbert space @xmath37 , called _ feature space _ , and a map @xmath38 such that @xmath39 for all @xmath40 . in machine learning ,",
    "a kernel represents a similarity measure between the samples , and @xmath41 is called its _",
    "feature map_. a kernel satisfying eq .",
    "( [ kernel_def ] ) is also symmetric and positive definite @xcite .      in @xcite ,",
    "reininghaus et al .",
    "devise the _ persistence scale space _",
    "kernel on the set of pd @xmath42 as a multi - scale kernel via a feature map @xmath43 , where @xmath44 denotes the space above the diagonal . given a pd @xmath45 , the feature map @xmath46 is the solution of a heat diffusion problem with a dirichlet boundary condition on the diagonal : @xmath47 where @xmath48 is the mirror image of @xmath49 across the diagonal .",
    "the map then yields the kernel @xmath50 in a closed form as @xmath51 for @xmath52 and @xmath53 , which has been shown to be 1-wasserstein stable .",
    "further , note that because the summation in eq .",
    "( [ pss_kernel ] ) is carried out over all pairwise combinations of the points in the pds @xmath21 and @xmath22 , evaluation of the kernel requires @xmath54 time , where @xmath55 and @xmath56 denote the number of points in @xmath21 and @xmath22 , respectively .",
    "we now introduce a vector representation of a pd , termed a persistence image ( pi ) , presented in @xcite .",
    "since our sparse - tda method will combine pi - based tda with sparse sample selection , we first summarize the sparse sampling method before describing the combination .",
    "let @xmath57 be a training set of pds . to construct a pi from a given pd @xmath58 @xcite ,",
    "@xmath58 is first transformed from birth - death coordinates to birth - persistence coordinates .",
    "let @xmath59 be the linear transformation , @xmath60 a persistence surface @xmath61 on @xmath62 is defined by @xmath63 where @xmath64 is a non - negative weighting function that is zero along the horizontal axis , continuous , and piecewise differentiable ; @xmath65 is a probability function with mean @xmath66 and variance @xmath67 .    in our experiments ,",
    "the linear weighting function is @xmath68 where @xmath69 .",
    "the form of the nonlinear weighting function is inspired by the weighting function used in @xcite and chosen as @xmath70 where @xmath71 .",
    "we choose @xmath72 to be the gaussian distribution , i.e. , @xmath73/2\\sigma^2}.\\ ] ] where @xmath74 .",
    "then the pi , a matrix of pixel values , is obtained by calculating the integral of @xmath75 on each grid box from discretization , @xmath76 pi has also been proven to be 1-wasserstein stable .",
    "let the grid resolution for each pi be @xmath77 .",
    "we reshape each pi to be a vector @xmath78 , @xmath79 .",
    "our sparse sample selection method is unsupervised , where we then stack the vectors from all the classes columnwise into a matrix as @xmath80 .\\ ] ] assume that the number of desired features is @xmath81 .",
    "applying the sparse sampling method on @xmath82 , we obtain the row index of @xmath81 optimal feature locations and the _ reduced feature vectors _",
    "@xmath83 for the corresponding classifiers .",
    "we now discuss the performance of our sparse - tda method on three benchmark computer vision data sets .",
    "the data sets are explained first , followed by illustrations of the selected features and quantitative comparisons of our method with the multi - scale kernel tda method .",
    "the illustrations and comparison results show the usefulness of the method on challenging multi - way classification problems .      for shape classification ,",
    "shrec14 synthetic and real data sets are used , given in the format of triangulated 3d meshes @xcite .",
    "the synthetic set contains meshes from five males , five females and five children in 20 different poses , while the real set consists of 20 males and 20 females in 10 different poses .    for texture recognition",
    ", we use the ` outex_tc_00000 ` data set @xcite .",
    "this data set contains 480 images equally categorized into 24 classes and provides 100 predefined 50/50 training / testing splits . during preprocessing",
    ", we downsample the original images to @xmath84 pixel images as done in the multi - scale kernel tda method .",
    "we first follow the same procedure performed in the multi - scale kernel tda method to obtain pds . for shrec14 data sets ,",
    "we compute the heat kernel signature @xcite on the surface mesh of each object and then compute the 1-dimensional pds using dipha . for the outex data set",
    ", we take the sign component of the completed local binary pattern operator @xcite as the descriptor function .",
    "then we generate the 0-dimensional pds from the filtration of its rotation - invariant version with @xmath85 neighbors and radius @xmath86 .",
    "to generate the pis , we set the resolution to be 30 @xmath87 30 for all three data sets .",
    "in fact , the classification accuracy is fairly robust to the choice of resolution @xcite .",
    "we also set @xmath88 to be 0.15 , 0.0001 and 0.02 for shrec14 synthetic , shrec14 real and outex data sets , respectively .",
    "[ fig_data_images ] shows representative pis for three different classes in all of our benchmark data sets .",
    "noticeable differences are observed among the pis for each of the three data sets , although the differences are most pronounced for the shrec14 synthetic data set , reasonably clear for the shrec14 synthetic data set , and less evident for the outex data set .",
    "these differences in the pixel values of the pis form the distinguishing class features from which an optimal set is selected by qr pivots .",
    ".size of the training sets and energy contained in the 100 optimized pixel locations ( in % ) [ cols=\"<,^,^,^ \" , ]     [ table_time ]    fig .",
    "[ fig_accuracy ] and fig .",
    "[ fig_time ] show the trends in improving the classification accuracy and reducing the classifier training time , respectively , as a function of increasing training / testing split for all the benchmark data sets .",
    "consistent with the results reported in tables  [ table_accuracy ] , our classification accuracy is marginally inferior to that of the kernel tda method for the shrec14 synthetic and outex data sets .",
    "however , the sparse - tda method with linear and non - linear weighting marginally outperform the kernel method for the most challenging shrec14 real data set .",
    "the training time trends are also very similar to the results presented earlier in table  [ table_time ] , with more than an order of magnitude reduction for the shrec14 synthetic data set , comparable values for the shrec14 real set , and significant reduction for the outex data set .",
    "the increase in classifier training times with higher training / test splits is , however , slightly more for both the variants of our method as compared to the kernel tda method .",
    "overall , we observe that , for each of the benchmark data sets , at least one of the variants of our sparse - tda method outperforms the multi - scale kernel tda method either in terms of classification accuracy or classifier training time .",
    "in this paper , we present a new method , referred to as the sparse - tda algorithm , that provides a sparse realization of a topological data analysis ( tda ) algorithm . more specifically , we combine an optimal sparse sample selection method based on qr factorization using column pivoting with a state - of - the - art tda method . instead of persistence diagrams",
    ", we use a vector - based representation of persistent homology , called persistence images , with two different weighting functions to extract the topological features .",
    "the results are promising on three benchmark multi - way classification problems pertaining to 3d meshes of human posture recognition , both for real and synthetic shapes , and image texture detection .",
    "while our method gives comparable classification accuracy to the multi - scale kernel method , it results in a significant reduction of the classifier training times .",
    "this reduction is expected to lay the foundation for on - line adaptation of tda on challenging data sets , which have a large number of classes , in response to changes in training sample availability .    in the future",
    ", we would like to further improve the accuracy of the sparse - tda method by designing our own weighting function for the persistence images .",
    "we would also like to come up with theoretical performance guarantees based on the characteristics of the data sets , particularly the training sample size for each individual class .",
    "last but not the least , we plan to show the effectiveness of our method on other hard classification problems arising in robot visual perception and human face recognition .",
    "we would like to thank the boeing company for sponsoring this work in part under contract # ssow - brt - w0714 - 0004 and dr .",
    "tom hogan for helpful discussions .",
    "the views and opinions expressed in the paper are , however , solely of the authors and do not necessarily reflect those of the sponsor .",
    "m.  gao _ et  al .",
    "_ , `` segmenting the papillary muscles and the trabeculae from high resolution cardiac ct through restoration of topological handles , '' in _ int . conf .",
    "info . process . in medical imaging_.1em plus",
    "0.5em minus 0.4emspringer , 2013 , pp . 184195 .",
    "m.  barrault _ et  al .",
    "_ , `` an ` empirical interpolation ' method : application to efficient reduced - basis discretization of partial differential equations , '' _ comptes rendus mathematique _ , vol . 339 , no .  9 , pp . 667672 , 2004 .",
    "z.  drmac and s.  gugercin , `` a new selection operator for the discrete empirical interpolation method  improved a priori error bound and extensions , '' _ siam j. sci .",
    "_ , vol .",
    "a631a648 , 2015 ."
  ],
  "abstract_text": [
    "<S> topological data analysis ( tda ) has emerged as one of the most promising techniques to reconstruct the unknown shapes of high - dimensional spaces from observed data samples . </S>",
    "<S> tda , thus , yields key shape descriptors in the form of persistent topological features that can be used for any supervised or unsupervised learning task , including multi - way classification . sparse sampling , on the other hand , provides a highly efficient technique to reconstruct signals in the spatial - temporal domain from just a few carefully - chosen samples . here </S>",
    "<S> , we present a new method , referred to as the sparse - tda algorithm , that combines favorable aspects of the two techniques . this combination is realized by selecting an optimal set of sparse pixel samples from the persistent features generated by a vector - based tda algorithm . </S>",
    "<S> these sparse samples are selected using a low - rank matrix representation of persistent features . </S>",
    "<S> we show that the sparse - tda method demonstrates promising performance on three benchmark problems related to human posture recognition and image texture classification .    </S>",
    "<S> guo : sparse - tda    topological data analysis , sparse sampling , multi - way classification , human posture data , image texture data . </S>"
  ]
}