{
  "article_text": [
    "this work gives a self - contained description of how to build a highly flexible , portable density - functional production code which attains significant fractions of peak performance on scalar cached architectures , shared - memory processors ( smp ) , and distributed - memory processors ( dmp ) .",
    "more importantly , however , this work introduces a new formalism , dft++ , for the development , implementation , and dissemination of new _ ab initio _ generalized functional theoretic techniques among researchers .",
    "the most well - known and widely used generalized functional theory ( gft ) is density - functional theory , where the energy of the system is parametrized as a functional of the electron density . although the formalism presented here is applicable to other single - particle gfts , such as self - interaction correction or hartree - fock theory , for concreteness we concentrate primarily on density functional theory ( dft ) .",
    "this formalism is of particular interest to those on the forefront of exploring new _ ab initio _ techniques and novel applications of such in the physical sciences .",
    "it allows practitioners to quickly introduce new physics and techniques without expenditure of significant effort in debugging and optimizing or in developing entirely new software packages .",
    "it does so by providing a new , compact , and explicit matrix - based language for expressing gft calculations , which allows new codes to be `` derived '' through straightforward formal manipulations .",
    "it also provides a high degree of modularity , a great aid in maintaining high computational performance .",
    "this language may be thought of as being for gft what the dirac notation is for quantum mechanics : a fully explicit notation free of burdensome details which permits the ready performance of complex manipulations with focus on physical content .",
    "direct application of the dirac notation to gft is particularly cumbersome because in single - particle theories , the quantum state of the system is not represented by a single ket but rather a collection of kets , necessitating a great deal of indexing .",
    "previous attempts to work with the dirac notation while eliminating this indexing have included construction of column vectors whose entries were kets @xcite but such constructions have proved awkward because , ultimately , kets are members of an abstract hilbert space and are not the fundamental objects of an actual calculation .    the foundation of the new dft++ formalism is the observation that all the necessary computations in an _ ab initio _ calculation can be expressed explicitly as standard linear - algebraic operations upon the actual computational representation of the quantum state without reference to complicated indexing or to the underlying basis set . with traditional approaches , differentiating the energy functional , which is required for self - consistent solution for the single - particle orbitals , is a frequent source of difficulty .",
    "issues arise such as the distinction between wave functions and their duals , covariant versus contravariant quantities , establishing a consistent set of normalization conventions , and translation from continuum functional derivatives to their discrete computational representations .",
    "however , by expressing the energy explicitly in our formalism , all these difficulties are automatically avoided by straightforward differentiation of a well - defined linear - algebraic expression .",
    "this new formalism allows not only for ease of formal manipulations but also for direct transcription of the resulting expressions into software , i.e. literal typing of physical expressions in their matrix form into lines of computer code .",
    "literal transcription of operations such as matrix addition and multiplication is possible through the use of any of the modern , high - level computer languages which allows for the definition of new object types ( e.g. vectors and matrices ) _ and _ the action of the standard operators such as `` + '' , `` - '' , or `` * '' upon them .",
    "once the basic operators have been implemented , the task of developing and debugging is simplified to checking the formulae which have been entered into the software .",
    "this allows the researcher to modify or extend the software and explore entirely new physical ideas rapidly . finally , a very important practical benefit of using matrix operations wherever possible is that the theory of attaining peak performance on modern computers is well developed for matrix - matrix multiplication .",
    "the high level of modularity which naturally emerges within the dft++ formalism compartmentalizes and isolates from one another the primary areas of research in electronic structure calculation : ( i ) derivation of new physical approaches , ( ii ) development of effective numerical techniques for reaching self - consistency , and ( iii ) optimization and parallelization of the underlying computational kernels .",
    "this compartmentalization brings the significant advantage that researchers with specialized skills can explore effectively the areas which pertain to them , without concerning themselves with the areas with which they are less familiar .",
    "a few anecdotes from our own experience serve to illustrate the efficacy of this approach .",
    "the extension of our production software to include electron spin through the local spin - density approximation ( lsda ) required a student with no prior familiarity with our software only one - half week to gain that familiarity , three days to redefine the software objects to include spin , and less than one day to implement and debug the new physics .",
    "the time it took another student to develop , implement , explore , and fine - tune the new numerical technique of section  [ sec : subspacerot ] was less than a week .",
    "finally , our experience with parallelization and optimization has been similarly successful .",
    "to parallelize our software for use with an smp ( using threads ) required a student starting with no prior knowledge of parallelization two weeks to develop a code which _ sustains _ an average per processor flop rate of 80% of the processor clock speed .",
    "( see section [ sec : smpparallel ] for details . ) finally , for massively parallel applications , the development of an efficient dmp code ( based on mpi ) , a task which often requires a year or more , required two students working together approximately two months to complete .",
    "figure [ fig : overview ] both illustrates the interconnections among the primary areas of active research in modern electronic structure calculations and serves as a road - map for the content of this article .",
    "the figure emphasizes how the dft++ formalism forms an effective central bridge connecting these areas .",
    "reduction to practice of new physical approaches generally requires expressions for an energy functional and the derivatives of that functional , as indicated in the upper - left portion of the figure .",
    "our discussion begins in section  [ sec : lagr ] with an exposition of the mathematical framework which we employ throughout this work , a lagrangian formulation of generalized density functional theories . in section  [ sec : matrixnotation ] we introduce our matrix - based formalism using density - functional theory ( dft ) within the local - density approximation ( lda ) @xcite as a case study , deriving the requisite expressions for the energy functional and its gradient .    in section  [ sec : otherfuncs ] , we go on to consider several examples of other functionals for physical calculations , including the local spin - density approximation ( lsda ) , self - interaction correction ( sic ) , density - functional variational perturbation theory , and band - structure calculations .",
    "we derive the requisite expressions for the corresponding functionals and their derivatives in the space of a few pages and thereby show the power and compactness of our formulation for the treatment of a wide range of single - particle quantum mechanical problems .",
    "as mentioned in the introduction , our matrix - based formalism allows the relevant formulae to be literally typed into the computer .",
    "because these formulae are self - contained , we can make , as illustrated in the upper - right portion of the figure , a clear distinction between the expression of the physics itself and the algorithms which search for the stationary point of the energy functional to achieve self - consistency . for concreteness , in section  [ sec : minalgs ]",
    "we provide full specification for both a preconditioned conjugate - gradient minimization algorithm and a new algorithm for accelerating convergence when working with metallic systems .    due to our matrix - based formulation ,",
    "the expressions for the objective function and its derivatives are built from linear - algebraic operations involving matrices .",
    "as the lower portion of figure  [ fig : overview ] illustrates , the dft++ formalism clearly isolates the software which contains the actual computational kernels .",
    "these kernels therefore may be optimized and parallelized independently from all other considerations .",
    "section  [ sec : imploptpara ] describes these computational considerations in detail . in section",
    "[ sec : cppimplem ] we discuss the use of object - oriented languages for linking the underlying computational kernels with higher level physical expressions .",
    "section  [ sec : flopcount ] discusses the scaling with physical system size of the burden for the most time consuming computational kernels .",
    "there are in fact two distinct types of computational kernels , both of which appear in the lower portion of the figure .",
    "the first type are kernels which implement those few operators in our formalism that depend on the choice of basis set ( @xmath0 , @xmath1 , @xmath2 , @xmath3 , @xmath4 , @xmath5 , defined in section  [ sec : basisdepops ] ) .",
    "these kernels represent the only entrance of basis - set details into the overall framework .",
    "( appendix  [ appendix : implementpw ] provides the requisite details for plane - wave calculations . )",
    "this allows for coding of new physics and algorithms without reference to the basis and for a single higher - level code to be used with `` plug - ins '' for a variety of different basis sets .",
    "the application of the basis - dependent operators can be optimized as discussed in section [ sec : optim ] by calling standard packages such as fftw @xcite .",
    "parallelization for the basis - dependent operators is trivial because they act in parallel on all of the electronic wave functions at once .",
    "section  [ sec : parallel ] discusses such parallelization for smp and dmp architectures .",
    "finally , the second class of kernels are basic linear - algebraic operations ( e.g. matrix multiplication * , addition + , subtraction - , and hermitian - conjugated multiplication ^ ) which do not in any way depend on the basis set used for the calculation .",
    "as such , the work of optimization and parallelization for these kernels need only be performed once .",
    "section  [ sec : optim ] presents the two strategies we employ for these optimizations : blocking of matrix multiplication and calling optimized linear - algebra packages such as blas3 .",
    "parallelization of these operations is not trivial because data - sharing or communication is required between processors .",
    "we detail high performance strategies for dealing with this issue in sections  [ sec : parallel ] for both smp and dmp architectures .",
    "the traditional equations of density - functional theory are the kohn - sham equations @xcite for a set of effective single - particle electronic states @xmath6 .",
    "below , when we refer to `` electrons '' , we are in fact always referring to these effective electronic degrees of freedom .",
    "the electrostatic or hartree field @xmath7 caused by the electrons is traditionally found from solving the poisson equation with the electron density derived from these wave functions as the source term .",
    "the ground - state energy of the system is then found by minimizing the traditional energy functional , which ensures the self - consistent solution of the kohn - sham equations .",
    "a great advantage of this variational principle is that first - order errors in the wave functions lead to only second order errors in the energy .",
    "however , although not frequently emphasized , errors in solving the poisson equation due to the incompleteness of the basis set used in a calculation may produce a non - variational ( i.e. first - order ) error in the energy .",
    "we now consider a new variational principle which ultimately leads to identical results for complete basis sets , but which places @xmath8 and @xmath9 on an equal footing and has several advantages in practice .",
    "the central quantity in this principle is the lagrangian @xmath10 introduced in @xcite , which within the local - density approximation ( lda ) , is @xmath11 where the electron density @xmath12 is defined in terms of the electronic states and the fermi - dirac fillings @xmath13 as @xmath14 here and throughout this article we work in atomic units and therefore have set @xmath15 , where @xmath16 is the electron mass and @xmath17 is the charge of the proton . finally , the kohn - sham electronic states @xmath8 must satisfy the orthonormality constraints @xmath18    above , @xmath19 is the exchange - correlation energy per electron of a uniform electron gas with electron density @xmath20 , and @xmath21 is the potential each electron feels due to the ions .",
    "the constant @xmath22 is used in calculations in periodic systems as a uniform positive background that neutralizes the electronic charge density .",
    "the effect of this background on the total energy is properly compensated when the ewald summation is used to compute the interionic interactions .",
    "the following equations , subject to the constraints of eq .",
    "( [ eq : orthonorm ] ) , specify the stationary point of @xmath10 , @xmath23\\psi_i(r ) - \\epsilon_i\\psi_i(r)\\ , \\label{eq : kohnsham}\\\\ { \\delta { { \\cal l}_{lda}}\\over \\delta \\phi(r ) } & = & 0 = -(n(r)-n_0 ) + { 1\\over 4\\pi}\\nabla^2\\phi(r)\\ , .",
    "\\label{eq : poisson}\\end{aligned}\\ ] ] these are seen to be the standard kohn - sham eigenvalue equations for @xmath24 and the poisson equation for the hartree potential @xmath7 where the negative sign in the second equation properly accounts for the negative charge of the electrons .",
    "the behavior of @xmath10 is in fact quite similar to that of the traditional lda energy functional , @xmath25 first , as shown in @xcite , evaluation of @xmath26 , where @xmath27 is the solution of the poisson equation , recovers the value of the traditional energy functional .",
    "moreover , the derivatives of @xmath10 and @xmath28 are also equal at @xmath27 .",
    "this result follows by considering a variation of the equality @xmath29 , which expands into @xmath30 because poisson s equation ( eq .  ( [ eq : poisson ] ) ) is the condition that the functional derivative of @xmath10 with respect to @xmath9 vanishes , the last term on the right - hand side is zero when @xmath31 .",
    "therefore , the functional derivatives of @xmath28 and @xmath10 with respect to the electronic states @xmath8 are equal when evaluated at @xmath32 . finally , the critical points of @xmath10 are in one - to - one correspondence with the minima of @xmath28 .",
    "the reason is that ( i ) for fixed @xmath8 , there is a unique @xmath27 ( up to a choice of arbitrary constant ) which solves the poisson equation because @xmath10 as a function of @xmath9 is a negative - definite quadratic form , and ( ii ) as we have just seen , at such points the derivatives with respect to @xmath8 of @xmath28 and @xmath10 are identical .",
    "one advantage of placing @xmath9 and @xmath8 on an equal footing is that now errors in the lagrangian are second - order in the errors of both the wave functions _ and _ the hartree field .",
    "additionally , as a practical matter , one has greater flexibility in locating the stationary point . rather than solving for the optimal @xmath9 at each value of @xmath8 ,",
    "as is done in traditional dft methods , one has the option of exploring in both @xmath8 and @xmath9 simultaneously .",
    "however , some care in doing this is needed , because the stationary points of @xmath10 are not extrema but saddle points .",
    "( note that the first term of eq .",
    "( [ eq : lagr ] ) , the kinetic energy , is unbounded above , whereas the last term , the hartree self - energy , is unbounded below . )",
    "this saddle has a particularly simple structure , and a method to exploit this is outlined in @xcite .    finally , by allowing @xmath9 to be a free variable , we have rendered local all interactions among the fields",
    "one great formal advantage is that the subtle mathematical issues in periodic systems arising from the long - range nature of the coulomb interaction no longer require special treatment .",
    "for example , the choice of the neutralizing background @xmath22 in periodic systems is straightforward and is treated in detail in section  [ sec : ehinter ] .",
    "because of this and the aforementioned advantages , we will work in the lagrangian framework throughout this article .",
    "our basis - set independent matrix formalism allows us to express the structure of any single - particle quantum theory in a compact and explicit way . in this section",
    ", we apply it to the lagrangian of eq .",
    "( [ eq : lagr ] ) which contains energetic terms and non - linear couplings that are common to all such theories .    to make progress , we first must deal with the fact that the lagrangian is a function of continuous fields .",
    "when we perform a computation , we are forced to represent these fields in terms of expansions within a finite basis set . denoting our basis functions as @xmath33 , where greek letters index basis functions",
    ", we expand the wave functions and hartree potential in terms of expansion coefficients @xmath34 and @xmath35 through @xmath36 typical and popular choices of basis functions are plane waves ( i.e. fourier modes ) @xcite , finite - element functions @xcite , multiresolution analyses @xcite , or gaussian orbitals @xcite .",
    "once a basis set has been chosen , @xmath10 becomes an explicit function of the finite set of variables @xmath34 and @xmath35 .",
    "in addition to the basis set itself , we require a grid of points @xmath37 in real space covering the simulation cell . this grid is necessary for a number of operations , such as for computing the values of the wave functions or the electron density in real - space and for computing the exchange - correlation energy density @xmath38 of eq .",
    "( [ eq : lagr ] ) , which is a non - algebraic function of the electron density @xmath12 and can only be computed point by point on the real - space grid .",
    "our aim is to find a compact , matrix - based notation that works in the space of expansion coefficients @xmath34 and @xmath35 and is thus applicable to any calculation within any basis set . in the course of doing so , we will be able to clearly identify which parts of our formalism require information about the particular basis that is chosen and which parts are completely general and independent of this choice .",
    "in addition , when we have arrived at a matrix - based notation , it will be clear that only a few fundamental types of computational kernels are needed to perform the calculation , so that parallelization and optimization need only address themselves to these few kernels .",
    "this provides a great boon for portability , ease of programming , and extensibility to new physical scenarios .    in the discussion",
    "below , we describe our formalism only for the case of local ionic potentials . the use of non - local potentials ( e.g. for the important case of pseudopotential calculations ) results in only minor changes that are addressed in appendix  [ appendix : nlpots ] .",
    "furthermore , for periodic systems , we will be working with only a single @xmath39-point at @xmath40 , as is evident from the choice of expansion in eq .",
    "( [ eq : defcphi ] ) .",
    "we work at @xmath40 in order to keep the mathematical expressions as transparent as possible .",
    "the minor extensions required to accommodate non - zero and multiple @xmath39-points are straightforward and are dealt with in appendix  [ appendix : kpts ] .      in this section",
    "we describe all the operators in our formalism that depend on the basis set chosen for the calculation .",
    "we will see that there are a small number of such operations , and that we can easily separate their role from the rest of the formalism .",
    "the first two operators involve matrix elements of the identity and the laplacian between pairs of basis functions .",
    "specifically , we define @xmath41 we call these operators the overlap and laplacian respectively .",
    "note that for orthonormal bases , we have @xmath42 where @xmath43 is the identity matrix .    the integrals of the basis functions are the components of the column vector @xmath44 , @xmath45 for periodic systems , we use the vector @xmath44 to define a new operator @xmath46 through @xmath47 where @xmath48 is the volume of the periodic supercell . for calculations in systems without boundaries , the volume @xmath48 is infinite so that @xmath49 .",
    "the chief use of @xmath46 is for solving the poisson equation in periodic systems where divergences due to the long - range coulomb interaction must be avoided .",
    "the automatic avoidance of such divergences and the proper choice of @xmath22 in eq .",
    "( [ eq : lagr ] ) both follow directly from the nature of the lagrangian as will be discussed in section  [ sec : ehinter ] .",
    "the next four operators involve the values of the basis functions on the points @xmath37 of the real - space grid introduced above .",
    "the _ forward transform _",
    "operator @xmath2 allows for changing representation from the space of expansion coefficients to the space of function values on the real - space grid . specifically , given a basis function @xmath50 and a grid point @xmath37",
    ", we define @xmath51 thus the @xmath50th column of @xmath2 consists of the values of the @xmath50th basis function on the points of the real - space grid .",
    "next , it is at times necessary to find the expansion coefficients for a function given its values on the real - space grid .",
    "we denote this linear _ inverse transform _ by @xmath3 . in implementations where the number of grid points @xmath37 is equal to the number of basis functions , the natural choice is to take @xmath52 ( e.g. , plane - wave basis sets ) .",
    "however , this is not necessary : in some applications , one may choose to use a very dense real - space grid which has more points than the number of basis functions .",
    "hence , we keep the formal distinction between @xmath3 and @xmath53 .",
    "we will also require two _ conjugate _ transforms , which are the hermitian conjugates @xmath4 and @xmath5 .",
    "the final mathematical object that depends on the basis set involves the ionic potential @xmath21 .",
    "we define a column vector @xmath54 whose components are the integrals @xmath55 which encodes overlaps of the ionic potential with the basis functions .",
    "we will use @xmath54 when evaluating the electron - ion interaction energy in section  [ sec : eiinter ] .",
    "although the operators @xmath1 , @xmath46 , @xmath0 , @xmath2 , @xmath3 , @xmath4 , and @xmath5 depend on the choice of basis , they satisfy various identities which will prove important below . in addition to their formal properties ,",
    "these identities allow for verification of the implementation of these operators .",
    "the most important identity involves the constant function . to represent the constant function on the grid , we define the column vector * 1 * as having the value of unity on each grid point @xmath37 : * 1*@xmath56 = 1 .",
    "many basis sets can represent this function exactly ( e.g. plane waves or finite - element sets ) .",
    "for such bases , for all points @xmath57 in the simulation cell , we must have the identity @xmath58 evaluating this identity on the real - space grid yields @xmath59 for basis sets that can not represent the constant function exactly , the identity of eq .",
    "( [ eq : ijident ] ) and the ones below should hold approximately in the regions described by the basis .    according to eq .",
    "( [ eq : j1ident ] ) , the vector @xmath60 specifies the coefficients of the expansion of the constant function . using the integrals @xmath44 of eq",
    "( [ eq : sdef ] ) , we can see that @xmath61 thus we have that @xmath62 .",
    "we can also derive the normalization condition @xmath63 where @xmath48 is the volume in which the calculation is performed .",
    "when solving poisson s equation for the electrostatic potential ( eq .  ( [ eq : poisson ] ) ) , we must take special care regarding the null space of the laplacian operator @xmath0 , which is the space of constant functions . integrating the identity @xmath64 against the complex conjugate of each basis function yields @xmath65 we use this identity when dealing with the poisson equation in periodic systems to avoid divergences due to the long - range nature of the coulomb interaction .",
    "we now use the above operators to express the lagrangian of eq .",
    "( [ eq : lagr ] ) in a matrix - based , basis - independent manner .",
    "we begin by introducing two operators , `` diag '' and `` diag '' .",
    "the operator diag converts a square matrix @xmath66 into a column vector containing the diagonal elements of the matrix .",
    "the operator diag converts a vector @xmath67 into a diagonal matrix with the components of @xmath67 on its diagonal . in terms of components",
    ", we have that @xmath68 where @xmath69 is the kronecker delta .",
    "thus , diag diag @xmath67 = @xmath67 for any vector @xmath67 whereas diag diag @xmath66 = @xmath66 if and only if @xmath66 is a diagonal matrix .",
    "two useful identities involving these operators are @xmath70 where @xmath71 indicates hermitian or complex - conjugated transposition .    next , if we regard the expansion coefficients @xmath34 as a matrix whose @xmath72th column contains the expansion coefficients of the @xmath72th wave function ( eq .",
    "( [ eq : defcphi ] ) ) , and we also define the diagonal matrix of fermi fillings @xmath73 , it is easy to see that @xmath74 is the representation of the single - particle density matrix in the space of basis functions .    before considering the lagrangian itself",
    ", we will also need expressions for the electron density @xmath12 which appears in most of the terms of the lagrangian of eq .",
    "( [ eq : lagr ] ) .",
    "we define a vector @xmath20 whose components are the values of the electron density on the points @xmath37 of the real - space grid . specifically , @xmath75 whence we arrive at the identity defining the vector @xmath20 @xmath76 given the values of the electron density on the real - space grid , we use the inverse transform @xmath3 to find the expansion coefficients of @xmath12 in terms of the basis functions .",
    "this vector of coefficients is just @xmath77 .",
    "armed with these few tools , we now proceed to write the various energetic terms of the lagrangian in the matrix language developed above .",
    "the kinetic energy @xmath78 can be transformed into the matrix language by using the expansion coefficients @xmath79 of eq .",
    "( [ eq : defcphi ] ) and by using the definition of the laplacian @xmath0 of eq .",
    "( [ eq : ldef ] ) : @xmath80 where the last two equivalent expressions are related by the cyclic property of the trace .",
    "thus , we are able to write the kinetic energy explicitly as a function of the density matrix @xmath81 of eq .",
    "( [ eq : pdef ] ) .",
    "since the electron density @xmath12 is real , we may write the electron - ion interaction as @xmath82{{\\cal i}}p\\right ) , \\label{eq : eeiexpr}\\end{aligned}\\ ] ] where we have used the definition of @xmath54 from eq .",
    "( [ eq : viondef ] ) and have used eqs .",
    "( [ eq : nexpr ] ) and ( [ eq : diagidents ] ) to rewrite this interaction in terms of @xmath81 .      given the vector @xmath20 of electron - density values on the grid",
    ", we can evaluate the exchange - correlation energy per particle at each grid point @xmath37 through @xmath83 .",
    "we collect these values into a vector @xmath19 .",
    "we then inverse transform this vector and the electron density vector , and we use the overlap operator to arrive at @xmath84{{\\cal i}}p\\right)\\ , , \\label{eq : excexpr}\\end{aligned}\\ ] ] where we again have conjugated the electron density for ease of formal manipulations .",
    "the derivation of the final expression in terms of @xmath81 uses eq .",
    "( [ eq : nexpr ] ) .      the self - energy of the hartree field can be written as @xmath85 where we have first integrated by parts and then substituted the expansion coefficients @xmath9 of eq .",
    "( [ eq : defcphi ] ) .",
    "the complex conjugation of the real - valued function @xmath7 allows for the simplicity of the final expression .",
    "the interaction of the electron density @xmath12 and hartree potential @xmath7 can be written as @xmath86^\\dag{{\\cal o}}\\phi\\ , .",
    "\\label{eq : eehdef}\\ ] ] the proper choice of @xmath22 for periodic systems can be found by noting that the hartree self - energy @xmath87 of eq .",
    "( [ eq : ehhexpr ] ) has no dependence on the projection of @xmath9 onto the null space of @xmath0 which , as we saw in section  [ sec : olijidents ] , lies along the vector @xmath60 .",
    "thus , for the lagrangian of eq .",
    "( [ eq : lagr ] ) to have a saddle - point , there can be no coupling of @xmath88 with the projection of @xmath9 along @xmath60 .",
    "that is , we must have @xmath89^\\dag{{\\cal o}}\\cdot{{\\cal j}}{\\bf 1 } = 0 $ ] .",
    "the identities of section  [ sec : olijidents ] then lead to the choice @xmath90 .",
    "our final expression for @xmath91 is thus given by @xmath92{{\\cal i}}p\\right)\\ , .",
    "\\label{eq : eehexpr}\\ ] ]      summing all the contributions above , we arrive at two equivalent expressions for the lagrangian @xmath10 , @xmath93 + { 1\\over 8\\pi}\\phi^\\dag l\\phi \\label{eq : lagrexpr1}\\\\ & = & -{1\\over 2}\\mbox{tr}\\left(lp\\right ) + { 1\\over 8\\pi}\\phi^\\dag l\\phi \\nonumber\\\\ & & + \\",
    "\\mbox{tr}\\left({{{\\cal i}}^\\dag}\\mbox{diag}\\left [ { { { \\cal j}}^\\dag}v_{ion } + { { { \\cal j}}^\\dag}{{\\cal o}}{{\\cal j}}{\\epsilon_{xc}}(n ) - { { { \\cal j}}^\\dag}{\\bar{{{\\cal o}}}}\\phi \\right]{{\\cal i}}p\\right)\\ , .",
    "\\label{eq : lagrexpr2}\\end{aligned}\\ ] ] the first , compact form is computationally efficient for evaluating the lagrangian as a function of @xmath79 and @xmath9 .",
    "the second form , written as a function of the density matrix @xmath81 , finds its best use in the formal manipulations required to find the gradient of the lagrangian .",
    "the orthonormality constraints of eq .",
    "( [ eq : orthonorm ] ) are equivalent to the matrix equation @xmath94 if we wish to compute gradients of the lagrangian with respect to @xmath79 in order to arrive at the kohn - sham equations , we must do so while always obeying these constraints .",
    "the analytically - continued functional approach @xcite deals with these constraints by introducing a set of expansion coefficients @xmath95 which are _ unconstrained _ and which can have any overlap @xmath96 , @xmath97 we also allow for the possibility of subspace rotation , which is a unitary transformation mapping the subspace of occupied states @xmath8 onto itself .",
    "such a transformation is affected by a unitary matrix @xmath98 , and we parameterize @xmath98 as the exponential of a hermitian matrix @xmath99 through @xmath100    the coefficients @xmath79 are defined as dependent variables through the mapping @xmath101 which ensures that eq .",
    "( [ eq : coc ] ) is automatically obeyed , as is easy to verify by direct substitution .",
    "the density matrix @xmath81 takes the following form in terms of @xmath95 and @xmath98 , @xmath102 in most cases , we simply set @xmath103 .",
    "in fact , for the case of constant fillings , @xmath104 , the unitary matrix @xmath98 drops out of @xmath81 completely .",
    "the subspace rotations find their primary use in the study of metallic or high - temperature systems where the fermi - dirac fillings are not constant , and the rotations allow for greatly improved convergence rates when searching for the saddle point of the lagrangian .",
    "this point is explained in more detail in section  [ sec : minalgs ] .",
    "since the most effective modern methods that search for stationary points require knowledge of the derivative of the objective function , we will now find the derivative of the lagrangian of eq .",
    "( [ eq : lagrexpr1 ] ) or ( [ eq : lagrexpr2 ] ) with respect to the variables @xmath95 and @xmath9 ( and @xmath99 if subspace rotations are used ) .",
    "differentiation with respect to @xmath95 is far more complex due to the orthonormality constraints , and we begin with this immediately .      computing the derivative of the lagrangian with respect to @xmath95 is intricate , and we break the problem into smaller pieces by first finding the derivative with respect to the density matrix @xmath81 .",
    "once the derivative with respect to @xmath81 is found , we can use the relation between @xmath81 and @xmath95 ( eq .  ( [ eq : pofy ] ) ) to find the derivative with respect to @xmath95 .",
    "we begin by noting that except for the exchange - correlation energy , the entire expression of eq .",
    "( [ eq : lagrexpr2 ] ) is linear in the density matrix @xmath81 .",
    "the exchange - correlation energy is a function of the electron density @xmath20 , which , through eq .",
    "( [ eq : nexpr ] ) , is also a function of @xmath81 .",
    "thus if we consider a differential change @xmath105 of the density matrix , the only term in @xmath106 that needs to be considered carefully is @xmath107 & = & n^\\dag{{{\\cal j}}^\\dag}{{\\cal o}}{{\\cal j}}\\left[\\mbox{diag } { \\epsilon'_{xc}}(n)\\right]dn\\\\ & = & \\mbox{tr}\\left\\{{{{\\cal i}}^\\dag}\\mbox{diag}\\left ( \\left[\\mbox{diag } { \\epsilon'_{xc}}(n)\\right]{{{\\cal j}}^\\dag}{{\\cal o}}{{\\cal j}}n\\right ) { { \\cal i}}\\,dp\\right\\}.\\end{aligned}\\ ] ] in the above derivation , we have used eq .",
    "( [ eq : nexpr ] ) to relate @xmath108 to @xmath105 as well as the identities of eq .",
    "( [ eq : diagidents ] ) .",
    "the vector @xmath109 is given by its values on the real - space grid points @xmath37 via @xmath110 .",
    "we can now write the differential of the lagrangian of eq .",
    "( [ eq : lagrexpr2 ] ) with respect to @xmath81 as @xmath111{{{\\cal j}}^\\dag}{{\\cal o}}{{\\cal j}}n - { { { \\cal j}}^\\dag}{\\bar{{{\\cal o}}}}\\phi\\right]{{\\cal i}}\\,dp\\right\\}\\nonumber\\\\ & \\equiv & \\mbox{tr}\\left(h\\,dp\\right)\\ , , \\label{eq : hdp}\\end{aligned}\\ ] ] where the single - particle kohn - sham hamiltonian operator @xmath112 is given by @xmath113\\,{{\\cal i}}\\ , , \\ \\",
    "\\mbox{where}\\nonumber\\\\ v_{sp } & = & { { { \\cal j}}^\\dag}v_{ion } + { { { \\cal j}}^\\dag}{{\\cal o}}{{\\cal j}}{\\epsilon_{xc}}(n ) + [ \\mbox{diag } { \\epsilon'_{xc}}(n)]{{{\\cal j}}^\\dag}{{\\cal o}}{{\\cal j}}n - { { { \\cal j}}^\\dag}{\\bar{{{\\cal o}}}}\\phi\\ , .",
    "\\label{eq : hspdef}\\end{aligned}\\ ] ]",
    "the single - particle hamiltonian is the sum of a kinetic operator and a local single - particle potential @xmath114 ( a vector of numbers on the real - space grid specifying the values of the potential ) .",
    "( [ eq : hdp ] ) has conveniently separated out the physical description of the system , the hamiltonian @xmath112 , from the variation @xmath105 which we now compute .",
    "differentiating the relation @xmath115 , we find that @xmath116 = - u^{-1/2}d[u^{1/2}]u^{-1/2},\\ ] ] and we use this to express the variation of the density matrix of eq .",
    "( [ eq : pofy ] ) as @xmath117u^{-1/2}v^\\dag fv + v^\\dag fvu^{-1/2}d[u^{1/2}]\\right)u^{-1/2}y^\\dag.\\end{aligned}\\ ] ] we now substitute this expression for @xmath105 into eq .",
    "( [ eq : hdp ] ) .",
    "we use the definition of the operator @xmath118 ( eq .  ( [ eq : qdef ] ) of appendix  [ appendix : umhalfq ] ) , its relation to @xmath119 $ ] ( eq .  (",
    "[ eq : uhalfq ] ) ) , and the identities which @xmath118 satisfies ( eqs .",
    "( [ eq : qidents ] ) ) . after some manipulations involving the cyclicity of the trace , we arrive at @xmath120,\\ \\mbox{where}\\nonumber\\\\ \\left({\\partial { { \\cal l}_{lda}}\\over \\partial y^\\dag}\\right ) & \\equiv &   \\left(i-{{\\cal o}}cc^\\dag\\right)hcfvu^{-1/2 } +   { { \\cal o}}cvq\\left(v^\\dag[\\tilde{h},f]v\\right)\\,,\\ \\mbox{and}\\nonumber\\\\ \\tilde{h } & \\equiv &   c^\\dag hc\\ , , \\label{eq : dldydag}\\end{aligned}\\ ] ] where @xmath121 is the subspace hamiltonian and contains matrix elements of the hamiltonian @xmath112 among the wave functions @xmath6 .",
    "square brackets denote the commutator , @xmath122\\equiv ab - ba$ ] .",
    "physical interpretation of the terms in eq .",
    "( [ eq : dldydag ] ) is provided in section  [ sec : kohnshampoisson ] .",
    "finally , since @xmath95 and @xmath123 are not independent , we can simplify the expression for the differential of @xmath10 to @xmath124\\,,\\ ] ] where re denotes the real part of its argument .      since the lagrangian in eq .",
    "( [ eq : lagrexpr1 ] ) is quadratic in @xmath9 , its derivative with respect to @xmath9 may be readily calculated .",
    "however , to arrive at a symmetric expression for the derivative in terms of @xmath9 and @xmath125 , we note that the linear dependence on @xmath9 , given by @xmath126 , is a real number because both @xmath12 and @xmath7 are real in eq .",
    "( [ eq : eehdef ] ) . for convenience ,",
    "we rewrite this as @xmath127 , which is an equivalent expression symmetric in @xmath9 and @xmath125 . by using this",
    ", we compute the variation of @xmath10 and arrive at @xmath128 again , since @xmath9 and @xmath125 are not independent , we can express the variation as @xmath129\\,.\\ ] ]      we have parameterized the unitary matrix @xmath98 of eq .",
    "( [ eq : cyumhalfvdag ] ) by the hermitian matrix @xmath99 of eq .",
    "( [ eq : bdef ] ) as @xmath130 .",
    "we will now find the derivative of @xmath10 with respect to @xmath99 .",
    "first , we consider the variation of @xmath10 with respect to those of @xmath98 and @xmath131 by using eq .",
    "( [ eq : hdp ] ) as our starting point . using the definition of @xmath81 in eq .",
    "( [ eq : pofy ] ) , we have that @xmath132u^{-1/2}y^\\dag\\right\\}\\\\ & = & \\mbox{tr}\\left\\{\\tilde{h}'[dv^\\dag fv + v^\\dag fdv]\\right\\}\\,,\\end{aligned}\\ ] ] where @xmath133 . differentiating the identity @xmath134 leads to @xmath135 which allows us to write @xmath136dvv^\\dag\\right\\}\\,,\\ ] ] where again @xmath137 is the subspace hamiltonian .",
    "we place the eigenvalues of @xmath99 on the diagonal of a diagonal matrix @xmath138 and place the eigenvectors of @xmath99 in the columns of a unitary matrix @xmath139 .",
    "thus @xmath140 and @xmath141 .",
    "we now use the result of eq .",
    "( [ eq : dfu ] ) of appendix  [ appendix : umhalfq ] applied to the case @xmath142 to arrive at the following result relating @xmath143 to @xmath144 : @xmath145 & \\mbox{if } m \\neq n \\end{array } \\right . .\\ ] ] using this and the fact that @xmath146 , we have that @xmath147z(z^\\dag dvz)z^\\dag v^\\dag\\right\\}\\\\ & = & \\mbox{tr}\\left\\{z^\\dag [ \\tilde h , f]z(z^\\dag dvz)e^{-i\\beta}\\right\\}\\\\ & = & \\sum_{n , m } ( z^\\dag [ \\tilde h , f]z)_{nm}(z^\\dag dbz)_{mn}\\cdot\\left\\ { \\begin{array}{cc } i & \\mbox{if } m = n\\\\ \\left[{e^{i\\beta_m - i\\beta_n}-1 \\over \\beta_m-\\beta_n}\\right ] & \\mbox{if } m \\neq n \\end{array } \\right . .\\end{aligned}\\ ] ] we define the operator @xmath148 acting on a general matrix @xmath149 via @xmath150 & \\mbox{if } m \\neq n \\end{array } \\right . .\\ ] ] this allows us to write the variation of @xmath10 as @xmath151\\right)zz^\\dag dbz\\right\\ } = \\mbox{tr}\\left\\{r\\left([\\tilde h , f]\\right)db\\right\\}\\,,\\ ] ] so that the derivative of @xmath10 with respect to @xmath99 is @xmath152\\right)\\ , .",
    "\\label{eq : dldb}\\ ] ]      the kohn - sham and poisson equations ( eqs .",
    "( [ eq : kohnsham ] ) and ( [ eq : poisson ] ) ) are obtained by setting the derivative of the lagrangian with respect to @xmath95 and @xmath9 to zero .",
    "this results in the two equations @xmath153v)\\,,\\label{eq : ksexpr}\\\\ \\left({\\partial { { \\cal l}_{lda}}\\over \\partial \\phi^\\dag } \\right ) & = & 0 = -{1\\over 2}{\\bar{{{\\cal o}}}}{{\\cal j}}n + { 1\\over 8\\pi}l\\phi\\ , .",
    "\\label{eq : poissonexpr}\\end{aligned}\\ ] ] eq .",
    "( [ eq : ksexpr ] ) states the stationarity of the lagrangian with respect to variations of the wave - function coefficients @xmath95 , and we examine it first .",
    "we define the projection operator @xmath154 which satisfies @xmath155 and which projects onto the subspace of occupied states @xmath8 used in the calculation .",
    "its complement @xmath156 projects onto the orthogonal subspace spanned by the unoccupied states . by multiplying eq .",
    "( [ eq : ksexpr ] ) on the left by @xmath157 and assuming that none of the fermi fillings are zero , we find that @xmath158 this reproduces the well known condition that at the stationary point , the hamiltonian must map the occupied subspace onto itself .",
    "conversely , we can project eq .",
    "( [ eq : ksexpr ] ) onto the occupied subspace by multiplying on the left by @xmath159 .",
    "this , combined with the fact that @xmath118 is an invertible linear operator , leads to the condition @xmath160 = 0\\,.\\ ] ] given that @xmath161 is a diagonal matrix , for arbitrary fillings , the subspace hamiltonian @xmath162 also must be diagonal : the states @xmath8 must be eigenstates of @xmath112 with eigenvalues @xmath163 , as we have explicitly written in eq .",
    "( [ eq : kohnsham ] ) . however , if a pair of states @xmath164 and @xmath165 have degenerate fillings , @xmath166 , then @xmath167 need not be zero . converting such degenerate cases into the conventional diagonal representation requires a further unitary rotation , which , however , is not required for stationarity .    the second condition for stationarity , eq .",
    "( [ eq : poissonexpr ] ) , rearranges into @xmath168 we have arrived at the poisson equation for the hartree potential @xmath9 generated by the electron density @xmath20 ( the negative electronic charge is reflected by the positive coefficient of the right - hand side ) . since we have explicitly projected out the null - space of @xmath0 from the right - hand side , we may invert @xmath0 and find the solution to the poisson equation @xmath169    finally , if we substitute the result of eq .",
    "( [ eq : poissonsolution ] ) for @xmath9 into our lagrangian , we find the lda energy functional ( cf .",
    "( [ eq : elda ] ) ) : @xmath170 .",
    "\\label{eq : eldaexpr}\\ ] ]      we now collect the expressions for the lda lagrangian and its derivatives in one place . as we will see in section  [ sec : imploptpara ] , formulae in the dft++ notation translate directly into lines of computer code , so that we will also be specifying the computational implementation of the lagrangian .",
    "in addition , given the lagrangian and its derivatives , we can apply any suitable algorithm to find the stationary point ( section  [ sec : minalgs ] ) .",
    "the key expressions are    as discussed in section  [ sec : lagr ] , the value of @xmath10 and its @xmath95 and @xmath99 derivatives are equal to the value and respective derivatives of the energy @xmath28 of eq .",
    "( [ eq : eldaexpr ] ) when we evaluate the lagrangian - based quantities at the solution of the poisson equation .",
    "therefore , the above expressions can also be used to find the derivatives of @xmath28 , a fact that we will exploit in section  [ sec : minalgs ] .",
    "in the previous section , we presented a detailed derivation of the expression for the lda lagrangian and its derivatives in the dft++ formalism .",
    "we believe that the community of physicists and chemists using this and other general - functional methods should use this formalism for the communication of new energy functionals and comparisons among them .    from a physicist s or chemist s viewpoint , which we adopt in this section , linear algebra and matrices are the settings in which quantum mechanical computations must be performed .",
    "therefore , they are the fundamental objects in the new formalism .",
    "this is in contrast with the dirac notation , which while an excellent conceptual tool for studying quantum problems , can never be used to carry out an actual calculation : matrix elements of bras and kets must first be found before an actual computation can proceed .",
    "once an expression for an energy functional is found , its derivative is found by straightforwardly differentiating it with respect to the matrices of independent variables .",
    "armed with expressions for the functional and its derivative , the methods discussed in section  [ sec : minalgs ] can then be applied to achieve self - consistency .    in this spirit",
    ", we now present a few examples of energy functionals . some are extensions of the lda , while others are similar to the lda only in that they involve the study of single - particle systems . in all cases ,",
    "our aim will be to show how quickly and easily we can find the requisite expressions for the appropriate functional and its derivative .",
    "the most straightforward generalization of the lda approximation is to allow for spin - up and spin - down electrons to have different wave functions but to still treat exchange - correlation energies in a local approximation .",
    "specifically , the exchange - correlation energy per particle at position @xmath57 is now a function of both the spin - up and spin - down electron densities , @xmath171 and @xmath172 , and the total lsda exchange - correlation energy is given by @xmath173 where @xmath174 is the total electron density .",
    "the lsda has been found to show substantial improvements over the lda for atomic and molecular properties @xcite since the spin of the electrons is explicitly dealt with .",
    "the changes required in the expressions of the lagrangian and its derivatives in order to incorporate the lsda are straightforward and easy to implement .",
    "we label spin states by @xmath175 , which can take the value @xmath176 or @xmath177 .",
    "we have spin - dependent expansion coefficient matrices @xmath178 for the wave functions ( cf .",
    "( [ eq : defcphi ] ) ) .",
    "each spin channel has its own fillings @xmath179 and density matrix @xmath180 , @xmath181 the electron densities @xmath182 and the total electron density @xmath20 are given by ( cf .",
    "( [ eq : nexpr ] ) ) @xmath183    the lsda lagrangian is given by @xmath184 + { 1\\over 8\\pi}\\phi^\\dag l\\phi.\\ ] ] the orthonormal expansion coefficients @xmath178 are found from unconstrained variables @xmath185 via @xmath186 where , for simplicity , we have set subspace rotations to unity , @xmath187 . finding the derivatives of the lagrangian with respect to the coefficients",
    "@xmath185 follows the analysis of section  [ sec : yderiv ] .",
    "each spin channel has a single - particle hamiltonian @xmath188 given by @xmath189\\,{{\\cal i}}\\ , \\",
    "\\mbox{where}\\\\ v_\\sigma & = & { { { \\cal j}}^\\dag}v_{ion } + { { { \\cal j}}^\\dag}{{\\cal o}}{{\\cal j}}{\\epsilon_{xc}}(n_\\uparrow , n_\\downarrow ) + \\mbox{diag}\\left[{\\partial { \\epsilon_{xc}}(n_\\uparrow , n_\\downarrow ) \\over \\partial n_\\sigma}\\right]{{{\\cal j}}^\\dag}{{\\cal o}}{{\\cal j}}n - { { { \\cal j}}^\\dag}{\\bar{{{\\cal o}}}}\\phi.\\end{aligned}\\ ] ] the derivative of the lagrangian with respect to @xmath185 ( cf . eq .",
    "( [ eq : dldydag ] ) ) is given by @xmath190),\\ \\mbox{where}\\ \\tilde{h}_\\sigma \\equiv c_\\sigma^\\dag h_\\sigma c_\\sigma.\\end{aligned}\\ ] ]    in summary , we have the following expressions for the lsda lagrangian and derivatives      the lda and lsda exchange - correlation functionals suffer from self - interaction errors : the functionals do not correctly subtract away the interaction of an electron with its own hartree field when the electron density is not uniform .",
    "perdew and zunger @xcite proposed a scheme to correct for these errors ( the sic - lda which we simply refer to as sic below ) .    the idea is to subtract the individual electrostatic and exchange - correlation contributions due to the density @xmath191 of each quantum state @xmath24 from the lda functional .",
    "this procedure has the virtue of yielding the correct result for a one - electron system as well as correcting for the hartree self - interaction exactly . in terms of our formalism",
    ", we define the density matrix @xmath192 and electron density @xmath193 for the state @xmath72 and relate them to the total density matrix @xmath81 and total electron density @xmath20 through @xmath194 where @xmath195 is the column vector with unity in the @xmath72th entry and zero elsewhere .",
    "in addition to the total hartree field @xmath9 , we also introduce hartree fields @xmath196 for each state @xmath72 , and the sic lagrangian takes the form @xmath197 + { 1\\over 8\\pi}\\phi^\\dag l\\phi\\\\ & & -\\sum_i ( { { \\cal j}}n_i)^\\dag \\left [ { { \\cal o}}{{\\cal j}}{\\epsilon_{xc}}(n_i ) -   { \\bar{{{\\cal o}}}}\\phi_i \\right ] - { 1\\over 8\\pi}\\sum_i \\phi_i^\\dag l \\phi_i \\,.\\end{aligned}\\ ] ]    setting the variation with respect to @xmath196 and @xmath9 to zero ( cf . section  [ sec : kohnshampoisson ] ) results in the poisson equations @xmath198 substituting these solutions into the sic lagrangian yields the familiar sic energy @xmath199 \\\\ & & -\\sum_i ( { { \\cal j}}n_i)^\\dag \\left [ { { \\cal o}}{{\\cal j}}{\\epsilon_{xc}}(n_i ) -   { 1\\over 2}{\\bar{{{\\cal o}}}}(4\\pi l^{-1}{\\bar{{{\\cal o}}}}{{\\cal j}}n_i ) \\right ] .\\end{aligned}\\ ] ]    the derivatives of the sic lagrangian with respect to the density matrices @xmath192 generate state - dependent hamiltonians @xmath200 and state - dependent potentials @xmath201 given by @xmath202{{\\cal i}}\\ , \\\\",
    "v_i & = & { { { \\cal j}}^\\dag}{{\\cal o}}{{\\cal j}}{\\epsilon_{xc}}(n_i ) +   \\left[\\mbox{diag } { \\epsilon_{xc}}'(n_i)\\right]{{{\\cal j}}^\\dag}{{\\cal o}}{{\\cal j}}n_i - { { { \\cal j}}^\\dag}{\\bar{{{\\cal o}}}}\\phi_i\\ , \\end{aligned}\\ ] ] where the state - independent potential @xmath114 is that of eq .",
    "( [ eq : hspdef ] ) .",
    "the derivation of the expression for the derivative of the lagrangian with respect to @xmath95 follows precisely the same steps as in section  [ sec : yderiv ] , and the final form is @xmath203\\right),\\nonumber\\\\ \\tilde{h}_i & = & c^\\dag h_i c\\ , .\\end{aligned}\\ ] ] an examination of this form shows that to compute the derivative , each hamiltonian @xmath200 need only be applied to the @xmath72th column of @xmath79 ( as the product @xmath204 occurs in all places ) , so that computation of the derivative is only slightly more demanding than the corresponding lda derivative .",
    "the above results for the derivative are a generalization of those in @xcite .",
    "those authors , however , work in the traditional real - space representation ( where necessarily all the sums over indices appear ) and , at each step of the minimization , orthonormalize their wave functions , so that their expressions are a special case of ours when @xmath205 .",
    "the summary of the sic lagrangian and derivatives follows .",
    "very often , we aim to find a set of quantum states @xmath8 that are the lowest energy eigenstates of a fixed hamiltonian .",
    "one case where this occurs is in the calculation of band structures for solids within dft , where one has already found the stationary point of the lagrangian and the optimal electron density @xmath12 .",
    "one then aims to explore the band structure for various values of @xmath39-vectors .",
    "( see appendix  [ appendix : kpts ] for a full discussion of @xmath39-points . )",
    "this requires finding the lowest energy eigenstates of the hamiltonian .",
    "the problem is the same as a tight - binding calculation in the sense that the hamiltonian is fixed and the electronic energy of the system is sought after , i.e. the minimum of the expectation value of the hamiltonian among an orthonormal set of states . in both cases ,",
    "the approach described below is most useful when the number of basis functions is much larger than the number of states @xmath8 so that direct diagonalization of the hamiltonian is computationally prohibitive .    in such cases",
    ", we have a hamiltonian @xmath112 , and we expand our wave functions as shown in eq .",
    "( [ eq : defcphi ] ) .",
    "we must minimize the energy @xmath206 @xmath207 we introduce unconstrained variables @xmath95 in the same way as before ( eq .",
    "( [ eq : udef ] ) and onwards ) .",
    "the variation of the energy is given by @xmath208 ) = 2\\,\\mbox{re}\\,\\mbox{tr}\\left[dy^\\dag \\left({\\partial e \\over \\partial y^\\dag}\\right)\\right]\\,,\\ ] ] where the derivative of @xmath206 is @xmath209 when we are at the minimum of @xmath206 , we have an orthonormal set @xmath79 that spans the subspace of the lowest - energy eigenstates of @xmath112 . the minimum value of @xmath206 is the electronic energy for the case of a tight - binding hamiltonian . if the energy eigenvalues and eigenvectors are desired , we diagonalize the subspace hamiltonian @xmath210 to obtain the eigenvalues @xmath211 .",
    "we then use the unitary matrix @xmath212 which diagonalizes @xmath121 , @xmath213 , to find the expansion coefficients for the eigenstates , given by the product @xmath214 .",
    "the summary of key equations follows .",
    "a slightly more complex variant of the previous problem arises when we have converged a calculation , found the orthonormal states @xmath79 spanning the occupied subspace , and are interested in finding the eigenvalues and eigenstates for the low - lying unoccupied states .",
    "for example , let us say that we have converged a calculation in an insulator or semi - conductor , where the occupied space specifies the valence band .",
    "we wish to find the low - lying conduction states in order to study the band structure and band - gap of the material .",
    "thus , we start with a fixed hamiltonian @xmath112 and a fixed set of occupied states @xmath79 .",
    "we aim to find a set of orthonormal unoccupied states @xmath215 that are orthogonal to @xmath79 and which also minimize the expectation of the hamiltonian . specifically , we wish to minimize @xmath216 under the orthogonality constraint @xmath217 .",
    "we introduce a set of unconstrained states @xmath139 .",
    "we project out the part of @xmath139 lying in the occupied subspace by using the projection operator @xmath218 of section  [ sec : kohnshampoisson ] , @xmath219 then , following the results of the previous section , the differential of @xmath206 is given by @xmath220 ) = 2\\,\\mbox{re}\\,\\mbox{tr}\\left[dz^\\dag \\left({\\partial e \\over \\partial z^\\dag}\\right)\\right]\\ , \\ ] ] where the derivative of @xmath206 with respect to @xmath139 is given by @xmath221 as expected , the derivative has two projection operators : @xmath222 , which projects out the component lying in the occupied subspace , and @xmath223 , which projects out the component lying in the portion of the unoccupied subspace under consideration .",
    "minimization of @xmath206 leads to a set of states @xmath215 that span the lowest - lying unoccupied states . at the minimum",
    ", the resulting unoccupied subspace hamiltonian @xmath224 can be diagonalized to obtain the desired eigenvalues and eigenstates .",
    "the energy and its gradient are summarized by      in this final application , we consider perturbation theory within a single - particle formalism , which is required to compute response functions .",
    "specifically , we consider the important case of linear response , which was first dealt with in @xcite .",
    "we imagine that we have converged the calculation of the zeroth - order ( i.e. unperturbed ) configuration and have found the zeroth - order wave functions @xmath225 for our problem .",
    "we now wish to find the first - order changes of the wave functions , @xmath226 , due to an external perturbation to the system .",
    "depending on the type of perturbation applied , the variation @xmath226 allows for the calculation of the corresponding response functions .",
    "for example , the displacement of atoms along a phonon mode allows for the computation of the dynamical matrix for that mode whereas perturbations due to an external electrostatic field allow for calculation of the dielectric tensor .",
    "regardless of the physical situation , all perturbations enter as a change in the ionic ( or external ) potential @xmath54 which drives the electronic system . letting @xmath227",
    "be the perturbation parameter , we expand any physical quantity @xmath149 in powers of @xmath227 and let @xmath228 be the coefficient of @xmath229 in the expansion .",
    "a few examples follow @xmath230 as is well known from perturbation theory , the first order change @xmath231 determines the first order shift of the wave functions @xmath226 .",
    "the work of @xcite shows that @xmath226 can be obtained via the constrained minimization of an auxiliary quadratic functional of @xmath226 . in our matrix - based notation , for the case of constant fillings ( taken to be unity ) and the lda approximation , this quadratic functional",
    "is given by @xmath232\\right\\}\\\\ & & + ( { { \\cal j}}n_1)^\\dag\\left\\{v_{ion,1 } + { { \\cal o}}{{\\cal j}}\\left[\\mbox{diag } a(n_0)\\right]n_1 - { 1\\over 2}{\\bar{{{\\cal o}}}}\\phi_1 \\right\\}+e_{nonvar}\\,.\\end{aligned}\\ ] ] the energy @xmath233 contains terms that depend only on @xmath225 or the ewald sum over atomic positions and need not concern us any further .",
    "the zeroth - order hamiltonian @xmath234{{\\cal i}}$ ] is the same as that of eq .",
    "( [ eq : hspdef ] ) where we have simply renamed the zeroth - order single - particle potential to @xmath235 .",
    "the diagonal matrix @xmath236 holds the eigenvalues of the zeroth - order hamiltonian .",
    "the vector @xmath237 is found by evaluating the function @xmath238 on the zeroth - order electron density @xmath22 over the real - space grid .",
    "the vector @xmath239 , the first order shift of the electron density , is given by @xmath240 the first order change of the hartree potential @xmath241 is the solution of the poisson equation @xmath242 .    given the quadratic nature of @xmath243 , its differential with respect to @xmath226 follows immediately and is given by @xmath244 + { { { \\cal i}}^\\dag}\\left[\\mbox{diag } v_1\\right]{{\\cal i}}c_0\\right)\\right\\}\\,,\\ ] ] where the first - order single - particle potential @xmath245 is given by @xmath246n_1 + \\left[\\mbox{diag } a(n_0)\\right]{{{\\cal j}}^\\dag}{{\\cal o}}{{\\cal j}}n_1 - { { { \\cal j}}^\\dag}{\\bar{{{\\cal o}}}}\\phi_1\\,.\\ ] ]    the constraint to be obeyed during the minimization is that the first - order shifts @xmath226 be orthonormal to the zeroth - order wave functions @xmath225 , @xmath247 this constraint is easily handled in the manner of the previous section by using a projection operator .",
    "we introduce an unconstrained set of wave functions @xmath248 from which we project out the part laying in the space spanned by @xmath225 , @xmath249 based on this relation , we find the gradient of @xmath206 with respect to @xmath248 @xmath250 + { { { \\cal i}}^\\dag}\\left[\\mbox{diag } v_1\\right]{{\\cal i}}c_0\\right\\}\\,.\\end{aligned}\\ ] ]    finally , we can convert the energy function into a lagrangian by letting @xmath241 be a free variable and by adding the appropriate hartree self - energy and coupling to @xmath239 .",
    "we arrive at the summarized expressions",
    "in this section , we show how the dft++ formalism can succinctly specify the algorithm which finds the stationary point of the lagrangian or energy function ( derived in the previous sections ) .",
    "such an algorithm only requires the value and derivative of the objective function , which is the reason that we have repeatedly emphasized the importance of these two quantities in our analysis above .",
    "once we choose a minimization algorithm , we need only `` plug in '' the objective function and its derivative into the appropriate slots . furthermore , since the dft++ formalism is compact and at the same time explicit , once we specify the operations that must be performed for a given algorithm in our notation , the transition to coding on a computer is trivial : the formulae translate directly into computer code ( as shown in section  [ sec : imploptpara ] ) .",
    "calc - energy(@xmath95 ) : +   + @xmath251 calculate the overlap @xmath252 + @xmath251 diagonalize @xmath253 and calculate @xmath254 + @xmath251 calculate the orthonormal states @xmath255 + @xmath251 calculate the electron density @xmath256 + @xmath251 solve the poisson equation @xmath257 + @xmath251 return the lda energy @xmath28 : +   +    specifically , we aim to find the stationary point of the lagrangian of eq .",
    "( [ eq : lagrexpr1 ] ) with respect to @xmath95 and @xmath9 and possibly @xmath99 .",
    "a direct search for the stationary point is possible , and at the saddle point , both the kohn - sham and poisson equations hold true simultaneously .",
    "this highly effective strategy has been followed in @xcite . alternatively , other approaches to reach a solution of these equations through self - consistent iteration and use of broyden - like schemes @xcite may be considered .",
    "however , in order to make direct contact with dft calculations within the traditional minimization context @xcite , and to keep our presentation as simple as possible , we choose instead to solve the poisson equation ( eq .  ( [ eq : poissonexpr2 ] ) ) for the optimal @xmath9 at each iteration of the minimization algorithm . for cases where @xmath258 is easy to compute ( e.g. the plane - wave basis where @xmath0 is diagonal )",
    ", we may compute the solution @xmath9 directly from eq .",
    "( [ eq : poissonsolution ] ) .",
    "otherwise , the straightforward approach of maximizing the quadratic functional @xmath259 via conjugate gradients ( or some other method ) achieves the same goal . for certain basis sets , multigrid methods or other specialized techniques",
    "are possibilities as well @xcite .",
    "once the poisson equation has been solved , the remaining free variable is the matrix of coefficients @xmath95 , and the aim of the calculation is to minimize the energy @xmath28 of eq .",
    "( [ eq : eldaexpr ] ) with respect to @xmath95 .    as shown in section  [ sec : lagr ] , the value and @xmath95-derivatives of the lagrangian @xmath10 and energy @xmath28 are identical if we evaluate the lagrangian - based expressions using the hartree potential @xmath9 which is the solution of poisson s equation .",
    "therefore , in our algorithms below , we can use expressions derived for derivatives of the lagrangian when dealing with the energy .",
    "@xmath251 calculate the ionic potential @xmath54 ( eq .  ( [ eq : viondef ] ) ) +",
    "@xmath251 randomize @xmath95 and choose the stepsize @xmath227 + @xmath251 iterate until @xmath28 is sufficiently converged : +   +   +    consider the case of a semiconducting system with a large unit cell .",
    "the fillings are constant , @xmath104 , and we will use a single @xmath39-point at @xmath40 ( as appropriate for a large cell ) .",
    "the simplest algorithm for minimizing the energy is the steepest descent method : we update @xmath95 by shifting along the negative gradient of the energy with respect to @xmath95 , scaled by a fixed multiplicative factor . as a first organizational step",
    ", we introduce the function calc - energy(@xmath95 ) , whose code we display in figure  [ fig : calcener ] . given @xmath95 ,",
    "this function computes the overlaps @xmath96 and @xmath260 , the orthonormalized @xmath79 , the electron density @xmath20 , the solution to poisson s equation @xmath9 , and returns the lda energy .",
    "figure  [ fig : sdalgorithm ] displays the steepest descent algorithm as it appears in the dft++ language",
    ".    we would like to emphasize a number of points regarding this code .",
    "first , the algorithm optimizes all the wave functions ( i.e. the entire matrix @xmath95 ) at once , leading to a very effective minimization and a complete avoidance of charge creep @xcite or other instabilities .",
    "second , the code is independent of the basis set used : the basis - dependent operators @xmath0 , @xmath1 , etc . , are coded as low - level functions that need to be written only once .",
    "the choice of physical system and minimization algorithm is a high - level matter that is completely decoupled form such details .",
    "third , the figure shows _ all _ the operations required for the entire minimization loop . that this is possible is grace to the succinct matrix formalism .",
    "quadratic - line - min(@xmath261 ) : +   + @xmath251 compute the directional derivative of @xmath28 at @xmath95 : @xmath262 + @xmath251 compute the energy at trial position @xmath263 + @xmath251 compute the curvature of the energy function @xmath264/\\lambda_t^2 $ ] + @xmath251 compute the minimizing shift @xmath265 + @xmath251 shift to the minimum : @xmath266 +   +    the only part of the algorithm of figure [ fig : sdalgorithm ] that is specific to the steepest descent method is the last operation where @xmath95 is updated . to generalize to a preconditioned conjugate - gradient algorithm",
    "is quite straightforward , and we specify the necessary changes below .",
    "conjugate - gradient algorithms require line minimization of the objective function along a specified direction , i.e. an algorithm is needed that minimizes @xmath267 with respect to the real number @xmath227 for a fixed search vector @xmath268 .",
    "the subject of line minimization is rich , and an abundance of algorithms with varying degrees of complexity exist in the literature .",
    "( for a brief introduction see @xcite . ) however , for typical dft calculations , most of the effort for the calculation is spent in the quadratic basin close to the minimum .",
    "thus , a simple and efficient line - minimizer that exploits this quadratic behavior should be sufficient , and we have found this to be the case in our work .",
    "our line - minimizer takes the current value of the energy and its derivative as well as the value of the energy at the shifted trial configuration @xmath269 ( where @xmath270 is a trial step - size ) to achieve the quadratic fit @xmath271 . here , @xmath272 is the directional derivative of @xmath206 with respect to @xmath227 , and @xmath273 is the curvature of @xmath206 with respect to @xmath227 .",
    "the line - minimizer then moves to the minimum of this quadratic fit located at @xmath265 .",
    "figure [ fig : linmin ] shows the code for this line - minimizer .",
    "@xmath251 calculate the ionic potential @xmath54 + @xmath251 randomize @xmath274 + @xmath251 for @xmath275=0 , 1 , 2 , ... +   +    using this line minimizer , we present the entire preconditioned conjugate - gradient algorithm in figure [ fig : cgalgorithm ] . note that we have omitted some of the formulae which are identical to those of figure [ fig : sdalgorithm ] .",
    "a simple diagonal preconditioning , as described in @xcite , is quite effective for plane - wave basis sets , and the operator @xmath276 is the preconditioner in the algorithm of the figure .      while the degrees of freedom in the variable @xmath95 are sufficient to describe any electronic system , the convergence of minimization algorithms can be hampered by ill - conditioning of the physical system .",
    "a standard case of such a problem is when the fermi - dirac fillings @xmath13 are not constant and some fillings are very small , a situation encountered when studying metals or high - temperature insulators .",
    "one type of ill - conditioning that arises due to states with small fillings , @xmath277 , stems from the fact that changes in such states do not affect the value of the energy @xmath28 very much when compared to the states with large fillings , @xmath278 .",
    "thus modes associated with the small - filling states are `` soft '' and we have an ill - conditioned problem .",
    "the solution to this problem , however , is rather straightforward and involves scaling the derivative of @xmath10 with respect to the state @xmath164 by @xmath279 .    much harder to deal with are soft modes due to subspace rotations which were introduced in section  [ sec : orthonorm ] .",
    "as we saw there , the unitary transformations @xmath98 , which generate the rotations , cancel out completely from the expression for the density matrix @xmath81 in the case of constant fermi fillings , @xmath104 .",
    "since the entire energy can be computed from @xmath81 alone , the energy will not depend on @xmath98 .",
    "hence we have found that the unitary transformations @xmath98 are an exact symmetry of a system with constant fillings .    however , once we introduce variations in the fillings , the symmetry is broken .",
    "now both the density matrix and the energy change when @xmath98 mixes states with different fillings . if the difference in fillings between the mixed states is small , a case typically encountered in a real system , the mixing produces small changes in the energy .",
    "again , we have soft modes , this time due to the breaking of the unitary subspace - rotation symmetry .    the idea of using subspace rotations was first suggested in @xcite .",
    "its use as a cure for the ill - conditioning described above was discussed and demonstrated convincingly in @xcite .",
    "the strategy is first to minimize the objective function over @xmath99 ( since @xmath99 parameterizes the rotation @xmath98 ) and only then perform minimization on the wave functions @xmath95 . by ensuring that we are always at the minimum with respect to @xmath99",
    ", we automatically set the derivative of @xmath28 with respect to subspace - rotations to zero . when this is true , changing @xmath95 can not ( to first order ) give rise to contributions due to the soft modes , and we have eliminated the ill - conditioning .    in practice ,",
    "we have found it unnecessary for our calculations to be at the absolute minimum with respect to @xmath99 : being close to the minimum is sufficiently beneficial computationally . in our algorithm",
    ", we take steps along both @xmath95 and @xmath99 simultaneously but ensure that our step - size in @xmath99 is much larger than that in @xmath95 . as the minimization proceeds",
    ", this choice automatically drives the system to stay close to the minimum along @xmath99 at all times .",
    "our simpler procedure has been found as effective as the original strategy of @xcite and translates into using the following search direction @xmath268 in the space @xmath280 @xmath281 where @xmath282 is a numerical scaling factor .",
    "we have found @xmath283 to be a good choice for efficient minimization while avoiding the ill - conditioning mentioned above .    as a practical showcase of the improvement in convergence in a metallic system ,",
    "we study the convergence rate for the conjugate - gradient minimization of the energy of bulk molybdenum .",
    "we study the bcc cubic unit cell containing two mo atoms .",
    "we use a plane - wave basis set ( details of implementation in appendix  [ appendix : implementpw ] ) with an electronic cutoff of 22.5 hartree ( 45 ryd ) , and a 4@xmath2844@xmath2844 cubic @xmath39-point mesh to sample to brillouin zone .",
    "the electronic temperature used is @xmath285=0.0037 hartree ( 0.1 ev ) , the fermi fillings are recomputed every twenty conjugate - gradient steps based on the eigenvalues of the subspace hamiltonian from the previous iteration , and a value of @xmath286 is used to calculate the search direction .",
    "non - local pseudopotentials of the kleinmann - bylander form @xcite are used with @xmath37 and @xmath287 projectors .",
    "figure [ fig : subspace ] presents a plot of the convergence of the energy per atom to its minimum value ( as determined by a run with many more iterations than shown in the figure ) .",
    "we compare minimization with and without the use of subspace rotation variables , and both minimizations are started with the same initial random wave functions .",
    "the extra cost required for the use of subspace rotations was very small in this case , the increase in the time spent per iteration being less than two percent .",
    "as we can see , the use of subspace rotations dramatically improves the convergence rate .",
    "in this final section we address how the dft++ formalism can be easily and effectively implemented on a computer , and what steps must be taken to ensure efficient optimization and parallelization of the computations .",
    "as is clear from the previous sections , the dft++ formalism is firmly based on linear algebra .",
    "the objects appearing in the formalism are vectors and matrices .",
    "the computations performed on these objects are matrix addition and multiplication and the application of linear operators .",
    "an important benefit is that linear - algebraic products involve matrix - matrix multiplications ( i.e. blas3 operations ) , which are precisely those operations that achieve the highest performance .",
    "we use an object - oriented approach and the c++ programming language to render the implementation and coding as easy as possible .",
    "in addition , object - oriented programming introduces modularity and localization of computational kernels allowing for effective optimization and parallelization . in the sections below , we present outlines of our implementation , optimization , and parallelization strategies .      in our work",
    ", we have found that an object - oriented language such as c++ is ideal for implementing the required vectors and matrices and for defining the operations on them in a manner that follows the dft++ formalism as closely as possible .",
    "the object - oriented approach presents a number of advantages .",
    "first , the programming task becomes highly modular : we identify the object types needed and the operations that must be performed on them , and we create a separate module for each object that can be tested independently .",
    "for example , we define the class of matrices and the operations on them ( e.g. multiplication , addition , diagonalization , etc . ) , and we can test and debug this matrix module separate from any other considerations .",
    "second , we gain transparency : the internal structure or functioning of an object can be modified for improved performance without requiring any changes to higher - level functions that use the object .",
    "this gives us a key feature in that the high - level programmer creating new algorithms or testing new energy functionals does not need to know about or interact with the lower - level details of how the objects actually are represented or how they function .",
    "third , this separation of high - level function from low - level implementation allows for a centralization and reduction in the number of computational kernels in the code : there can be a large variety of high - level objects for the convenience of the programmer , but as all the operations defined on them are similar linear - algebraic ones , only a few actual routines must be written .",
    "fourth , modularity produces shorter and more legible code .",
    "this , combined with the object - oriented approach , implies that the high - level computer code will read the same as the equations of the dft++ formalism so that debugging will amount to checking formulae , without any interference of cumbersome loops and indices .    to give a concrete example of what this means , consider the simplest object in the formalism , a column vector such as the electron density @xmath20 . in c++",
    ", we define an object class ` vector ` which will contain an array of ` complex ` numbers ( itself a lower - level object ) .",
    "a ` vector v ` has a member ` v.size ` specifying the number of rows it contains as well as a pointer to the array containing the data .",
    "we define the action of the parenthesis so as to allow convenient access of the ` i`th element of ` v ` via the construction ` v(i ) ` .",
    "a very common operation between two vectors @xmath67 and @xmath288 is the scalar product @xmath289 .",
    "we implement this by defining ( in c++ parlance overloading ) an operator ` ^ ` that takes two ` vector`s and returns a ` complex ` result .",
    "the code accomplishing this is    friend complex operator^(vector & v , vector & w ) + \\ {   + complex result = 0 ; +   + for= ( int i=0 ; i < v.size ; i++ ) + result + = conjugate(v(i))*w(i ) ; +   + return result ; + }    an example of an operator acting on vectors is the inverse transform @xmath3 .",
    "this operator can be coded as a function ` j ` that takes a ` vector v ` as its argument and returns the ` vector ` result ` j(v ) ` .",
    "of course , the details of what @xmath3 does internally are basis - dependent .    based on this definition ,",
    "the evaluation of the electron - ion interaction energy of section  [ sec : eiinter ] , given by the expression @xmath290 , is coded by +   +   +   + where ` v_ion ` is the vector @xmath54 of eq .",
    "( [ eq : viondef ] ) .",
    "following the same idea , we define a ` matrix ` class to handle the matrices such as @xmath96 , @xmath291 , @xmath121 , etc . that occur in the formalism .",
    "physically , expansion coefficients such as @xmath95 and @xmath79 are collections of column vectors ( a column of coefficients @xmath34 for each wave function @xmath164 ) , and we define the class ` column_bundle ` to handle these objects .",
    "although mathematically ` column_bundle`s such as @xmath95 and @xmath79 are matrices , the choice not to use the ` matrix ` class for representing them is deliberate , as @xmath95 and @xmath79 have a distinct use and a special physical meaning that an arbitrary matrix will not have . in this way",
    ", we can tailor our objects to reflect the physical content of the information they contain .",
    "of course , when a matrix multiplication is performed , such as when we evaluate the expression @xmath255 , the ` column_bundle ` class and ` matrix ` class call a single , low - level , optimized multiplication routine",
    ". we thus gain flexibility and legibility of codes on the higher levels while avoiding an accumulation of specialized functions on the lower levels .        as a concrete example of the power and ease of this style of programming , consider writing the code for the function calc - energy(@xmath95 ) of figure  [ fig : calcener ] . in order to do so",
    ", we will need a few more operators .",
    "following the example of the ` vector`s , we define the ` ^ ` operator between two ` column_bundle`s to handle hermitian - conjugated multiplications such as @xmath292 , where the result of the product is of type ` matrix ` .",
    "next , we define the ` * ` operator between a ` column_bundle ` and ` matrix ` to handle multiplications of the type @xmath293 , where the result is a ` column_bundle ` .",
    "we code the action of the basis - dependent operators such as @xmath1 or @xmath2 on a ` vector ` @xmath9 or a ` column_bundle ` @xmath79 as function calls ` o(phi ) ` or ` i(c ) ` , which return the same data type as their argument .",
    "finally , we implement multiplication by scalars in the obvious way .",
    "figure [ fig : calcenergycode ] presents the c++ code for the energy calculation routine .",
    "the code is almost exactly the same as the corresponding expressions in the dft++ formalism , making the translation from mathematical derivation to actual coding trivial .",
    "before we describe our approach to optimization and parallelization , we will work out the scalings of the floating - point operation counts as a function of system size for the various computational operations in the dft++ formalism .",
    "thus it will be clear which optimizations and parallelizations will increase the overall performance most efficaciously .",
    "let @xmath20 be the number of wave functions @xmath8 and let @xmath294 be the number of basis functions @xmath33 in the calculation .",
    "a ` vector ` contains @xmath294 complex numbers , a ` matrix ` is @xmath295 , and a ` column_bundle ` is @xmath296 and is the largest data structure in the computation .",
    "both @xmath20 and @xmath294 are proportional to the number of atoms @xmath297 in the simulation cell , or equivalently , to the volume of the cell .",
    "typically , for accurate dft calculations , the number of basis functions required is much larger than the number of quantum states , @xmath298 .",
    ".floating - point operation count for various common operations in the dft++ formalism .",
    "the size of the basis set is @xmath294 and the number of wave functions is @xmath20 .",
    "thus a ` column_bundle ` is @xmath296 , a ` matrix ` is @xmath295 , and a ` vector ` is @xmath294 long . [ cols=\"^,^,^\",options=\"header \" , ]     in table [ table : flopcount ] we present the floating - point operation counts for the different operations required in the dft++ formalism .",
    "we note that for very large systems , the basis - set independent matrix products dominate the overall computational workload .",
    "however , for medium - sized or slightly larger problems , the application of the basis - dependent operators can play an important role as well .    for most basis sets , there are techniques available in the literature that allow for efficient application of the basis - dependent operators to a column vector in @xmath299 or @xmath300 operations . for example , when working with plane waves , the fast fourier transform @xcite is the algorithm of choice for implementing the operators @xmath2 , @xmath3 , @xmath4 , and @xmath5 and allows us to affect these operators in @xmath300 operations .",
    "( see appendix  [ appendix : implementpw ] for the details of a plane - wave implementation . )",
    "the operators @xmath0 and @xmath1 are already diagonal in a plane - wave basis and are thus trivial to implement . for real - space , grid - based computations , multigrid methods @xcite are highly effective for inverting @xmath0 and solving the poisson equation .",
    "special techniques exist for multiresolution @xcite and gaussian @xcite basis sets that allow for the application of the basis - dependent operators in @xmath299 operations as well .      due to the modularity of our object - oriented approach ,",
    "the physical nature of the problem under study is a high - level issue that is completely independent of the functioning of the few , low - level computational kernels which handle most of the calculations in the code .",
    "the aim now is to optimize these kernels to obtain maximum computational performance . by optimization we mean increasing performance on a single processor .",
    "parallelization , by which we mean distribution of the computational task among several processors , will be addressed in the next section , but good parallel performance is only possible when each processor is working most effectively .",
    "the computationally intensive operations involved in the dft++ formalism fall into two overall classes .",
    "first are the application of the basis - dependent operators such as @xmath0 , @xmath1 , @xmath2 , etc . , whose operation counts scale quadratically in the system size ( see table [ table : flopcount ] ) .",
    "given their basis - dependent nature , no general recipe can be given for their optimization .",
    "however , for many widely used basis sets , highly efficient methods exist in the literature which allow for the application of these operators , and we refer the reader to the references cited in the preceding section . for the case of plane waves , we have used the fftw package @xcite to affect the fourier transformations .",
    "this highly portable , freely obtainable software library provides excellent per processor performance across many platforms .",
    "the second class of operations are the basis - independent matrix products , and we will now consider the optimization of these operations . as a case study , we examine the hermitian - conjugated matrix product between two ` column_bundle`s , which occurs in an expression such as @xmath292 and which is coded using the column_bundle^column_bundle operator as ` y_1^y_2 ` .",
    "the most `` naive '' and straightforward implementation of this operator in c++ is given by    friend matrix operator^(column_bundle & y_1 , column_bundle & y_2 ) + \\ {   + // create a matrix of size y_1.n_columns x y_2.n_columns + // to hold the result + matrix m(y_1.n_columns , y_2.n_columns ) ; + int i , j , k ; +   + for= ( i=0 ; i < y_1.n_columns ; i++ ) + for= ( j=0 ; j < y_2.n_columns ; j++ ) \\ { + m(i , j ) = 0 ; + for= ( k=0 ; k < y_1.n_rows ; k++ ) + m(i , j ) + = conjugate(y_1(k , i))*y_2(k , j ) ; + } +   + return m ; + }    while easy to follow , this implementation is quite inefficient on modern computer architectures for large matrix sizes because the algorithm does not take any advantage of caching .",
    "the access pattern to memory is not localized , and the processor must continually read and write data to the slower - speed main memory instead of to the much faster ( but smaller ) cache memory .    one solution to this problem",
    "is to resort to vendor - specific linear algebra packages .",
    "for example , one can use a version of lapack optimized for the computational platform at hand , and this generally results in very good performance .",
    "an alternative choice is to perform the optimizations by hand .",
    "while this second choice may sacrifice some performance , it does ensure highly portable code , and this is the strategy that we have followed in our work .",
    "our basic approach to increasing performance is to use blocking : we partition each of the input and output matrices into blocks of relatively small dimensions , and the matrix multiplication is rewritten as a set of products and sums over these smaller blocks . provided that the block sizes are small enough , say 32@xmath28432 or 64@xmath28464 for todays typical processor and memory architectures , both the input and output blocks will reside in the high - speed cache memory and fast read / write access to the cache will dramatically improve performance .",
    "figure [ fig : blocking ] shows a schematic diagram of how the product @xmath301 would be carried out in a blocked manner .",
    "( 6.5,3)(0,0 ) ( 0,0)(6.5,3 ) ( 0.5,1.5)(0.2,1)[l ] ( 1.5,1.5)(0.2,1)[r ] ( 1.0,1.0)(0,1)1 ( 0.5,1.5)(1,0)1 ( 2.0,1.5)(0,0)= ( 2.0,2.8)(0,0)= ( 0.75,1.75)(0,0)@xmath302 ( 1.25,1.75)(0,0)@xmath303 ( 0.75,1.25)(0,0)@xmath304 ( 1.25,1.25)(0,0)@xmath305 ( 1.0,2.8)(0,0)@xmath66 ( 3.5,2.0)(2,0.2)[t ] ( 3.5,1.0)(2,0.2)[b ] ( 2.5,1.5)(1,0)2 ( 4.0,1.0)(0,1)1 ( 3.5,1.0)(0,1)1 ( 3.0,1.0)(0,1)1 ( 2.75,1.75)(0,0)@xmath306 ( 3.25,1.75)(0,0)@xmath307 ( 3.75,1.75)(0,0)@xmath308 ( 4.25,1.75)(0,0)@xmath309 ( 2.75,1.25)(0,0)@xmath310 ( 3.25,1.25)(0,0)@xmath311 ( 3.75,1.25)(0,0)@xmath312 ( 4.25,1.25)(0,0)@xmath313 ( 3.5,2.8)(0,0)@xmath314 ( 4.75,1.5)(0,0)@xmath284 ( 5,1.5)(0.2,2)[l ] ( 6,1.5)(0.2,2)[r ] ( 5.5,0.5)(0,1)2 ( 5.0,2.0)(1,0)1 ( 5.0,1.5)(1,0)1 ( 5.0,1.0)(1,0)1 ( 5.25,2.25)(0,0)@xmath315 ( 5.75,2.25)(0,0)@xmath316 ( 5.25,1.75)(0,0)@xmath317 ( 5.75,1.75)(0,0)@xmath318 ( 5.25,1.25)(0,0)@xmath319 ( 5.75,1.25)(0,0)@xmath320 ( 5.25,0.75)(0,0)@xmath321 ( 5.75,0.75)(0,0)@xmath322 ( 5.5,2.8)(0,0)@xmath323 ( 3.5,0.4)(0,0 )    please note that due to blocking , the task of optimization is now also modularized .",
    "we need only write a single , low - level , block - block matrix multiplication routine that should be highly optimized .",
    "all higher - level matrix multiplication functions will then loop over blocks of the input and output data and copy the contents to small , in - cache matrices which are then multiplied by calling the low - level multiplier .    applying these ideas to our @xmath301 example , the rewritten code for the + column_bundle^column_bundle operator takes the following form :    friend matrix operator^(column_bundle & y_1 , column_bundle & y_2 ) + \\ {   + matrix m(y_1.n_columns , y_2.n_columns ) ; //",
    "m = y_1^y_2 holds the result +   + int b = 32 ; // pick a reasonable block size +   + matrix in1(b , b),in2(b , b),out(b , b ) ; // input and output blocks +   + int ib , jb , kb , i , j , k ; +   + //",
    "loop over blocks of the output + for= ( ib=0 ; ib < y_1.n_columns ; ib+=b ) + for= ( jb=0 ; jb < y_2.n_columns ; jb+=b )",
    "\\ { +   + //",
    "zero the output block + for= ( i=0 ; i < b ; i++ ) + for= ( j=0 ; j < b ; j++ ) + out(i , j ) = 0 ; +   + // loop over blocks to be multiplied + for= ( kb=0 ; kb < y_1.nrows ; kb+=b ) \\",
    "{ +   + // load data into input blocks + for= ( i=0 ; i < b ; i++ ) + for= ( k=0 ; k < b ; k++ ) \\ { + in1(i , k ) = conjugate(y_1(kb+k , ib+i ) ) ; + in2(i , k ) = y_2(kb+k , jb+i ) ; + } +   +",
    "// perform the block multiplication + low_level_mutliply(in1 , in2 , out , b ) ; + } +   + // write the result to memory + for= ( i=0 ; i < b ; i++ ) + for= ( j=0 ; j < b ; j++ ) + m(ib+i , jb+j ) = out(i , j ) ; + } +   + return m ; + }    the function ` low_level_multiply ` performs the block - block multiplication of the input blocks and accumulates into the output block .",
    "not only the ` column_bundle^column_bundle ` operator but _ all _ matrix multiplications can be blocked in a similar way and will thus call the low - level multiplier .    the simplest implementation for ` low_level_multiply ` is the straightforward one :    void low_level_multiply(matrix & in1 , matrix & in2 , + matrix & out , int b ) + \\ {   + int i , j , k ; + for= ( i=0 ; i < b ; i++ ) + for= ( j=0 ; j < b ; j++ ) \\ { + complex z = 0 ; + for= ( k=0 ; k < b ; k++ ) + z + = in1(i , k)*in2(j , k ) ; + out(i , j ) + = z ; + } + }    the use of this simple low - level multiplier combined with blocking can provide a tremendous improvement .",
    "figure [ fig : blockingmflops ] shows a plot of the performance of the @xmath301 blocked - multiplication as a function of the block size when run on a 333 mhz sun ultrasparc 5 microprocessor . for comparison , the performance of the `` naive '' code with no blocking , which was presented above , is also indicated in the figure .",
    "initially , the performance increases dramatically with increasing block size due to more effective caching .",
    "however , there is an optimal size above which performance decreases because the blocks become too large to fit effectively into the cache . on most computational platforms that we have had experience with , this simple blocked multiplier runs at at least half the peak theoretical rate of the processor , as exemplified by the results in the figure .",
    "further speedups can be found by rewriting the ` low_level_multiply ` routine so as to use register variables ( as we have done and found up to 40% performance enhancements ) or by using a hierarchical access pattern to memory which can provide better performance if the memory system has multiple levels of caching .",
    "once the computer code has been optimized to perform well on a single processor , the computation can be divided among multiple processors .",
    "we now discuss how this division can be achieved effectively .",
    "the architectures of modern parallel supercomputers can generally be divided into two categories : shared - memory ( smp ) versus distributed - memory ( dmp ) processors . in the smp case ,",
    "a set of identical processors share access to a very large repository of memory .",
    "the main advantages of shared memory are that the processors can access whatever data they need , and that , with judicious choice of algorithms , very little inter - processor communication is required .",
    "in addition , only small changes are required to parallelize a serial code : the computational task is divided among the processors , and each processor executes the original serial code on the portion of the data allotted to it . however , as the number of processors increases , the traffic for accessing the main memory banks increases dramatically and the performance will stop to scale well with the number of processors utilized .",
    "nevertheless , many mid - sized problems are well suited to smps and can take full advantage of the key features of smp systems .",
    "examples of such calculations can be found in @xcite .",
    "the largest of today s supercomputers have distributed memory : each processor has a private memory bank of moderate size to which it has exclusive access , and the processors communicate with each other by some message passing mechanism .",
    "the main advantages of dmp are scalability and heterogeneity , as the processors need not all be identical nor located in close physical proximity .",
    "however , the price paid is the necessity of an inter - processor communication mechanism and protocol .",
    "in addition , computer algorithms may have to be redesigned in order to minimize the required communication .",
    "furthermore , a slow communication network between processors can adversely affect the overall performance .",
    "we will describe , in outline , the strategies we employ for both smp and dmp architectures , and we will continue to examine the case of the + column_bundle^column_bundle matrix multiplication as a specific example . as our results for actual calculations will demonstrate , we only need to parallelize two main operations in the entire code , ( a ) the application of basis - dependent operators such as @xmath2 or @xmath0 to ` column_bundle`s ( which is trivial ) and ( b ) the matrix products involving ` column_bundle`s such as @xmath324 or @xmath293 , to obtain excellent or highly satisfactory performance on smp and dmp systems .",
    "since all processors in an smp computer have access to all the data in the computation , the parallelization of the basis - dependent operators is trivial .",
    "for example , the operation @xmath325 involves the application of @xmath2 to each column of @xmath79 separately , and the columns can be divided equally among the processors .",
    "this leads to near perfect parallelization as none of the processors read from or write to the same memory locations .",
    "based on the discussion of section  [ sec : flopcount ] , for large problems , the most significant gains for parallelization involve the basis - independent matrix - products .",
    "below , we focus on the column_bundle^column_bundle operation as a case study . for this operation",
    ", it is impossible to distribute the task so that all processors always work on different memory segments .",
    "however , we divide up the work so that no two processors ever write to the same memory location : not only does this choice avoid possible errors due to the synchronizations of simultaneous memory writes , it also avoids performance degradation due to cache - flushing when memory is written to .",
    "consider the matrix product @xmath326 , which we have implemented as a blocked matrix multiplication .",
    "parallelization is achieved simply by assigning each processor to compute a subset of the output blocks .",
    "the main program spawns a set of subordinate tasks ( termed threads ) whose sole purpose is to compute their assigned output blocks and to write the results to memory .",
    "the main program waits for all threads to terminate before continuing onwards .",
    "referring to figure [ fig : blocking ] , this strategy corresponds to distributing the computation of the blocks @xmath327 among the processors , and since memory is shared , all processors have access to all of the data describing @xmath248 and @xmath323 at all times . for large problem sizes , the overhead in spawning and terminating the threads is far smaller than the work needed to compute the results , so the simplicity of this strategy does not sacrifice performance .",
    "we now present the code which accomplishes this parallelized matrix product in order to highlight the ease with which such parallelizations can be performed . in the interest of brevity , we assume that the number of columns of @xmath248 is a multiple of the number of threads launched .",
    "parallelization is affected by assigning different threads to compute different rows of the result @xmath301 .",
    "friend matrix operator^(column_bundle & y_1 , column_bundle & y_2 ) + \\ {   + matrix m(y_1.n_columns , y_2.n_columns ) ; //",
    "m = y_1^y_2 holds the result +   + int n_threads = 8 ; // a reasonable number of threads +   + int thread_id[n_threads ] ; + int i , start , n ; +   + for ( i=0 ; i < n_threads ; i++ ) \\",
    "{ +   + // the set of rows of m that this thread should compute + n = y_1.n_columns / n_threads ; + start = i*n ; +   + // launch a thread that runs the routine calc_rows_of_m + // and pass it the remaining arguments . store",
    "the thread i d .",
    "+ thread_id[i ] = launch_thread(calc_rows_of_m , y_1 , y_2 , m , + start , n ) ; + } +   + //",
    "wait for the threads to terminate + for ( i=0 ; i < n_threads ; i++ ) + wait_for_thread(thread_id[i ] ) ; +   + return m ; + }    the routine ` calc_rows_of_m(y_1,y_2,m , start , n ) ` computes rows ` start ` through + ` start+n-1 ` of ` m ` , where ` m = y_1^y_2 ` .",
    "the routine s algorithm is identical to that of the blocked multiplier presented in the previous section .",
    "the only change required is to have the ` ib ` loop index start at ` start ` and end at ` start+n-1 ` .",
    "we parallelize other matrix multiplications involving ` column_bundle`s analogously . in addition , we parallelize the application of the basis - dependent operators as discussed above . for a realistic study of performance and scaling ,",
    "we consider a system of bulk silicon with 128 atoms in the unit cell .",
    "we use a plane - wave cutoff of 6 hartrees ( 12 ryd ) which leads to a basis of size @xmath328 .",
    "we use kleinmann - bylander @xcite non - local pseudopotentials with @xmath37 and @xmath287 non - local projectors to eliminate the core states , and we have @xmath329 bands of valence electrons .",
    "we sample the brillouin zone at @xmath40 . in figure",
    "[ fig : smp1 ] , we show a plot of the performance of the parallelized @xmath301 multiplication as well as the overall performance of the code for a single conjugate - gradient step as a function of the number of processors employed .",
    "the calculation was run on a sun ultra hpc 5000 with eight 167 mhz ultrasparc 4 microprocessors and 512 mb of memory .",
    "as the figure shows , the parallelized @xmath301 matrix multiplication shows near ideal scaling .",
    "there are a number of reasons for this behavior : ( 1 ) since different processors always write to different segments of memory , the algorithm does not suffer from memory write - contentions , ( 2 ) the inputs @xmath248 and @xmath323 are never modified so that memory reads are cached effectively , and ( 3 ) the problem size is large enough so that each processor s workload is much larger than the overhead required to distribute the work among the processors .",
    "this scaling is all the more impressive because when using eight processors , each processor performs the multiplications at 140 mflops or at 83% of the processor clock rate .",
    "the figure also displays the total performance of the code , which shows evidence of saturation . to understand this behavior in more detail , we model the overall execution time in accordance with amdahl s law .",
    "we assume that there exists an intrinsic serial computation time @xmath330 which must be spent regardless of the number of processors available .",
    "in addition , there is an analogous parallel computation time @xmath331 which , however , is divided equally among all the processors .",
    "thus the total execution time will be given by @xmath332 , where @xmath37 is the number of processors .",
    "we show a plot of the total execution time versus @xmath333 in figure [ fig : smp2 ] , and the model shows an excellent fit to the available data .",
    "the vertical asymptote of the least - squares fit straight line is the extrapolated value of @xmath330 , in this case approximately 10% of the single processor or serial execution time .",
    "thus the few operations that we have chosen to parallelize do in fact constitute the largest share of the computational burden and our parallelization strategy is quite effective .",
    "when we reach the data point with eight processors , the total execution time is already within a factor of two of @xmath330 , so that the total serial and parallel components have become comparable . indeed ,",
    "timing various portions of the code confirms this hypothesis : for example , with eight processors , the time needed to perform a parallel multiplication @xmath301 is equal to the time needed by the sun high - performance lapack library to diagonalize the overlap matrix @xmath96 ( cf .",
    "( [ eq : udef ] ) ) . with eight processors ,",
    "the code has each processor _ sustaining _ an average of 134 mflops or 80% of the processor clock rate .",
    "we are quite satisfied with this level of performance , but if more improvements are desired , the remaining serial portions of the code can be further optimized and parallelized .",
    "parallelization on dmp architectures requires careful thought regarding how the memory distribution and inter - process communications are to be implemented .",
    "the most memory - consuming computational objects are the ` column_bundle`s , and for a large system , no single processor in a dmp computer can store the entire data structure in its local memory banks .",
    "therefore , we parallelize the storage of ` column_bundle`s by distributing equal numbers of the columns comprising a ` column_bundle ` among the processors .    given this distribution by columns , the application of basis - dependent operators is unchanged from how it is done in a serial context : each processor applies the operator to the columns that are assigned to it , and perfect parallelization is achieved as no inter - processor communication is required .",
    "the large basis - independent matrix products , however , are more challenging to parallelize as they necessarily involve inter - processor communication .    (",
    "6.5,3)(0,0 ) ( 0,0)(6.5,3 ) ( 1.0,1.5)(0.2,2.4)[l ] ( 2.5,1.5)(0.2,2.4)[r ] ( 1.45,0.3)(0,1)2.4 ( 2.05,0.3)(0,1)2.4 ( 1.0,1.1)(1.75,1.1)(2.5,1.1 ) ( 1.0,1.9)(1.75,1.9)(2.5,1.9 ) ( 1.22,2.3)(0,0)@xmath334 ( 1.75,2.3)(0,0)@xmath335 ( 2.30,2.3)(0,0)@xmath336 ( 1.22,1.5)(0,0)@xmath337 ( 1.75,1.5)(0,0)@xmath338 ( 2.30,1.5)(0,0)@xmath339 ( 1.22,0.7)(0,0)@xmath340 ( 1.75,0.7)(0,0)@xmath341 ( 2.30,0.7)(0,0)@xmath342 ( 1.75,2.85)(0,0)@xmath95 ( 1.75,0.15)(0,0)@xmath20 ( 0.70,1.5)(0,0)@xmath294 ( 3.1,1.5)(0,0)@xmath343 ( 4.7,0.75)(2.4,0.2)[b ] ( 4.7,2.25)(2.4,0.2)[t ] ( 4.3,0.75)(0,1)1.5 ( 5.1,0.75)(0,1)1.5 ( 3.5,1.2)(4.7,1.2)(5.9,1.2 ) ( 3.5,1.8)(4.7,1.8)(5.9,1.8 ) ( 3.9,2.03)(0,0)@xmath344 ( 4.7,2.03)(0,0)@xmath345 ( 5.5,2.03)(0,0)@xmath346 ( 3.9,1.50)(0,0)@xmath347 ( 4.7,1.50)(0,0)@xmath348 ( 5.5,1.50)(0,0)@xmath349 ( 3.9,0.98)(0,0)@xmath350 ( 4.7,0.98)(0,0)@xmath351 ( 5.5,0.98)(0,0)@xmath352 ( 4.7,2.85)(0,0)@xmath353 ( 6.20,1.5)(0,0)@xmath20 ( 4.70,0.40)(0,0)@xmath294    consider again the product @xmath326 , which in terms of components is given by @xmath354 the column - wise parallel distribution of @xmath248 and @xmath323 means that the full range of the @xmath72 and @xmath275 indices is distributed among the processors while the full range of the @xmath39 index is accessible locally by each processor . since @xmath248 and @xmath323 are @xmath296 , each processor has a @xmath355 block ( i.e. @xmath356 columns of length @xmath294 ) in its local memory , where @xmath37 is the number of processors .",
    "unfortunately , computing @xmath66 using this column - wise distribution requires a great deal of inter - processor communication .",
    "for example , the processor computing the @xmath72th row of @xmath66 requires knowledge of _ all _ the columns of @xmath323 , so that in total , the @xmath357 data items describing @xmath323 will have to be sent @xmath358 times between all the processors .",
    "a more efficient communication pattern can be developed that avoids this redundancy . denoting the transpose of @xmath95 by @xmath353 ,",
    "the matrix product can be rewritten as @xmath359 hence , if we first transpose @xmath248 and @xmath323 , then the column - wise distribution of the transposed ` column_bundle`s insures that the full range of the @xmath72 and @xmath275 indices can be accessed locally on each processor while the full range of the @xmath39 index is now distributed among the processors .",
    "figure [ fig : transpose ] presents a schematic of how the transposition of a ` column_bundle ` @xmath95 is be accomplished : each processor has a @xmath355 block of @xmath95 whose contents it sends to @xmath358 other processors as @xmath358 blocks of size @xmath360 .",
    "next , each processor receives @xmath358 similar blocks sent to it by other processors , transposes them , and stores them in the appropriate sections of @xmath353 .",
    "each processor sends or receives only @xmath361 data items , and a total of @xmath362 data items are communicated among all the processors .",
    "the computation of @xmath66 in the transposed mode has the same operation count as in the non - transpose mode ( i.e. @xmath363 operations ) , which when distributed across processors , amounts to @xmath364 operations per processor .",
    "of course , we block the matrix multiplications on each processor to ensure the best performance . finally , a global sum across all the processors @xmath295 resulting matrices is required to obtain the final answer @xmath66 , and this requires @xmath365 communications of size @xmath366 when using a binary tree .    assuming that processors can simultaneously send and receive data across the network , the time required to perform the transpose is @xmath367 , the time needed to perform the multiplications is @xmath364 , and the time required to perform the final global sum is @xmath368 . for large problem sizes",
    ", the time needed to perform the multiplications will always be larger than the time required for the communications by a factor of @xmath369 .",
    "thus interprocessor communications are , in the end , never an issue for a sufficiently large physical system , and the computation will be perfectly parallelized in the asymptotic limit of an infinitely large system .",
    "figure  [ fig : dmp1 ] shows a plot of the performance of our dmp parallelized plane - wave code for a single conjugate - gradient step when run on a 256 atom silicon cell .",
    "the choice of pseudopotential , cutoff , and @xmath39-point sampling are the same as for the smp calculation above .",
    "the basis set is of size @xmath370 and the system has @xmath371 valence bands .",
    "the calculations were run on an ibm sp2 system with 336 nodes , and each node has four 332 mhz power2 architecture risc system/6000 processors and 1.536 gb of memory .",
    "again , we see excellent and near perfect scaling for the parallelized matrix multiplications , validating our claim that the transposition approach combined with the large system size provides for very good parallelization . with 32 processors , each parallelized multiplication runs at an average rate of 188 mflops per processor ( 57% of the processor clock rate ) , which is impressive given the fact that the processors are busily communicating the data required for the transpositions and global sums .",
    "the plot also shows the saturation of the total performance of the code with increasing number of processors . with eight processors",
    ", the overall performance translates into an average rate of 254 mflops per processor ( 76% of the clock rate ) , whereas with 32 processors the rate has reduced to 160 mflops per processor ( 48% of the clock rate ) .",
    "clearly , the serial portions of the calculation begin to contribute significantly to the run time of the code .",
    "following the discussion of the smp results above , figure  [ fig : dmp2 ] presents a plot of the total execution time versus inverse number of processors .",
    "the extrapolated serial time @xmath330 in this case is only 2 - 3% of the total theoretical run time on a single processor , which shows how effectively the calculation has been parallelized .",
    "in addition , for the 32 processor run , the total run time is only two times larger that @xmath330 , signalling the end of significant gains from the use of more processors .",
    "we would like to thank jason a. cline for his work in implementing the lsda functional .",
    "we are immensely grateful to tairan wang for his work in creating the mpi implementation of the software and to kenneth p. essler for creating the mpi distributed transposition routine and the accompanying efficient matrix multiplication routines .",
    "this work was supported primarily by the mrsec program of the national science foundation under award number dmr 94 - 00334 , by the alfred p. sloan foundation ( br-3456 ) , and also by an asci asap level 2 grant ( contract numbers # b338297 and # b347887 ) .",
    "code development was carried out on the mit xolas prototype smp cluster as well as on the mit pleiades alpha cluster .",
    "the calculations were carried out on the xolas cluster and on the asci blue pacific teraflops ibm sp2 platform .",
    "this work made use of the cornell center for materials research shared experimental facilities , supported through the nsf mrsec program ( dmr-9632275 ) .",
    "a widely used basis - set for _ ab initio _ calculation has been the plane - wave basis set @xcite .",
    "plane waves are ideally suited for periodic calculations that model the bulk of a crystalline material .",
    "in addition , plane waves provide uniform spatial resolution throughout the entire simulation cell , and the results of the calculations can be converged easily by simply increasing the number of plane waves in the basis set .",
    "we will use plane waves as a concrete example of how the basis - dependent operators of section  [ sec : basisdepops ] are to be implemented .",
    "given the lattice vectors of a periodic supercell , we compute the reciprocal lattice vectors and denote the points of the reciprocal lattice by the vectors @xmath372 .",
    "each element of our basis set @xmath33 will be a plane wave with vector @xmath373 , @xmath374 where @xmath48 is the real - space volume of the periodic cell .",
    "this basis is orthonormal , and the overlap operator @xmath1 is the identity operator , @xmath375 the integrals of the basis functions @xmath44 are given by @xmath376 so that the @xmath46 operator is given by @xmath377 the laplacian operator @xmath0 is diagonal in this basis and is given by @xmath378    the forward transform @xmath2 is given by a fourier transformation .",
    "specifically , for a point @xmath37 on the real - space grid , we have that @xmath379 consider applying @xmath2 to the column vector @xmath380 and evaluating the result at the point @xmath37 : @xmath381 this is the forward fourier transform of @xmath380 .    for the case of plane waves ,",
    "the inverse transform @xmath3 can be chosen to be the inverse of @xmath2 , @xmath382 , as per the discussion of section  [ sec : basisdepops ] .",
    "it follows that @xmath383 where @xmath294 is the number of points in the real - space grid . applying @xmath3 to a column vector @xmath384",
    ", we have @xmath385 thus @xmath3 is a reverse fourier transform .",
    "the operators @xmath4 and @xmath5 are also fourier transforms with appropriate scaling factors .",
    "computationally , fast fourier transforms @xcite can be used to implement these operators most efficiently .",
    "the last remaining basis - dependent item is the ionic potential @xmath54 . for periodic systems ,",
    "this potential is a periodic sum of atomic potentials @xmath386 , @xmath387 where @xmath388 ranges over the real - space lattice sites , @xmath43 ranges over the atoms in the unit cell , and @xmath389 is the position of the @xmath43th atom .",
    "based on this , the elements of the vector @xmath54 of eq .",
    "( [ eq : viondef ] ) are given by @xmath390 where the structure factor @xmath391 is given by @xmath392 and the fourier transform of the atomic potential @xmath393 is defined by @xmath394",
    "in this section we show how non - local potentials can easily be incorporated into the dft++ formalism .",
    "the total non - local potential operator @xmath395 for a system is given by a sum over each atom s potential , @xmath396 where @xmath397 is the non - local potential of the @xmath43th atom .",
    "the non - local energy is given by the expectation of @xmath395 over all the occupied states @xmath8 with fillings @xmath13 , @xmath398 given the linearity of @xmath399 with respect to the atoms @xmath43 , in our discussion below we will only consider the case of a single atom and will drop the index @xmath43 .",
    "the results below can then be summed over the atoms to provide general expressions for multiple atoms .    using the expansion coefficients @xmath34 of eq .",
    "( [ eq : defcphi ] ) , we rewrite the non - local energy as @xmath400 where @xmath401 is the ket representing the basis function @xmath402 , @xmath81 is the single - particle density matrix of eq .",
    "( [ eq : pdef ] ) , the matrix @xmath161 was defined as @xmath403 , and the matrix elements of the non - local potential are defined as @xmath404 the matrix @xmath98 clearly depends on both the basis set and the potential .",
    "the contribution of the non - local potential to the total lagrangian of eq .",
    "( [ eq : lagrexpr2 ] ) is given simply by @xmath405 .",
    "following the derivations of eqs .",
    "( [ eq : hdp ] ) and ( [ eq : hspdef ] ) , we see that the single - particle hamiltonian @xmath112 is modified only by the addition of @xmath98 , @xmath406\\,{{\\cal i}}+ v\\ , .",
    "\\label{eq : handv}\\ ] ]    we now write the potentials in separable form , @xmath407 where @xmath44 and @xmath408 range over the quantum states of the atom , @xmath409 are matrix elements specifying the details of the potential , and @xmath410 is the ket describing the contribution of the @xmath44th quantum state to the potential",
    ". typical choices of @xmath44 are the traditional atomic state labels @xmath411 and possibly the spin @xmath175 .",
    "once we define the matrix elements @xmath412 , which are again basis - dependent , we find two equivalent forms for @xmath399 , @xmath413 = \\mbox{tr}\\left[kmk^\\dag p\\right]\\ .",
    "\\label{eq : kmkdagp}\\end{aligned}\\ ] ] the first form involving @xmath414 is most useful for efficient computation of the energy , and the second form is most useful for derivation of the gradient ( cf .",
    "the discussion of eqs .",
    "( [ eq : lagrexpr1 ] ) and ( [ eq : lagrexpr2 ] ) ) . the energetic contribution to the lagrangian",
    "is given by eq .",
    "( [ eq : kmkdagp ] ) and the contribution to the hamiltonian @xmath112 is @xmath415 , which replaces @xmath98 in eqs .",
    "( [ eq : vpexpr ] ) and ( [ eq : handv ] ) .",
    "a further specialization involves the popular case of kleinmann - bylander potentials @xcite where the double sum in eq .",
    "( [ eq : vnlseparable ] ) is reduced to a single sum over @xmath44 .",
    "thus , the matrix @xmath66 is diagonal with elements @xmath416 .",
    "the expression for the total non - local energy , this time including the sum over atoms @xmath43 , is @xmath417\\,.\\ ] ] unfortunately , this expression is not very efficient for evaluating the energy of a system with many atoms , as the sum on @xmath43 is large but the matrix @xmath418 only has a single row .",
    "this limits our ability to exploit the cache effectively ( which only occurs for large matrix sizes ) .",
    "we can rewrite the above energy expression so as to employ larger matrices and thus achieve greater computational efficiency . to do this , we define a diagonal matrix @xmath419 that contains the @xmath420 values for all the atoms , @xmath421 , and we define the matrices @xmath422 via @xmath423 .",
    "we then reorganize the previous expression for the non - local energy , @xmath424 = \\mbox{tr}\\left[\\left(\\sum_s a_s \\bar{m}_s a_s^\\dag\\right)p\\right]\\,.\\ ] ] if we have @xmath294 basis functions , @xmath20 quantum states @xmath8 , and @xmath297 atoms in the system , then @xmath79 is @xmath296 and @xmath422 is @xmath425 .",
    "thus , for large system sizes , the products @xmath426 involve matrices with large dimensions , and optimized matrix - multiplication routines function at peak efficiency .",
    "we consider the generalization of our formalism to the case of multiple @xmath39-points , which arises in the study of periodic systems . in periodic cells ,",
    "the wave functions satisfy bloch s theorem and can be labeled by a quantum number @xmath39 , a vector in the first brillouin zone .",
    "the quantum states obey the bloch condition @xmath427 where @xmath388 is a lattice vector of the periodic cell .",
    "this implies that @xmath428 where @xmath429 is a periodic function of @xmath57 , @xmath430 .",
    "we define the expansion coefficients @xmath431 for the vector @xmath39 as being those of the periodic function @xmath432 and arrive at ( cf .",
    "( [ eq : defcphi ] ) ) @xmath433 where the integer @xmath434 labels the energy bands ( i.e. different states at the same value of @xmath39 ) .",
    "the fermi - dirac fillings may also have a @xmath39-dependence and are denoted as @xmath435 .",
    "in addition to @xmath39-vectors , calculations in periodic systems attach a weight @xmath436 to the wave vector @xmath39 .",
    "the rationale is that we require the integrals of physical functions over the brillouin zone in order to compute the lagrangian , energies , and other quantities .",
    "ideally , we would like to integrate a function @xmath437 over the brillouin zone , but in a practical computation this must be replaced by a discrete sum over a finite number of @xmath39-points with weights @xmath436 .",
    "that is , we perform the following replacement @xmath438    the required generalizations of the dft++ formalism are straightforward and are outlined below .",
    "the density matrices ( cf .",
    "( [ eq : pdef ] ) ) now depend on @xmath39-points @xmath439 where the filling matrix is @xmath440 , and the expansion coefficient matrices @xmath431 are given by eq .",
    "( [ eq : ckdef ] ) .",
    "we define the total density matrix @xmath81 through @xmath441 the electron density @xmath20 ( cf .",
    "( [ eq : nexpr ] ) ) is given by @xmath442 the electron - ion , exchange - correlation , and electron - hartree energies depend only on @xmath20 , and provided the above @xmath39-dependent expression for @xmath20 is used , these contributions require no further modification from the forms already given in eqs .",
    "( [ eq : eeiexpr ] ) , ( [ eq : excexpr ] ) , and ( [ eq : eehexpr ] ) respectively .",
    "the only change required to the basis - dependent operators involves the use of the laplacian for computing the kinetic energy .",
    "the proper generalization is to define @xmath39-dependent laplacian matrices @xmath443 through @xmath444^*\\,\\nabla^2\\,\\left[e^{ik\\cdot r}b_\\beta(r)\\right]\\,.\\ ] ] this immediately leads to the following expression for the kinetic energy : @xmath445 we still require the operator @xmath0 as defined in eq .",
    "( [ eq : ldef ] ) for operations involving the hartree field @xmath9 and the poisson equation .",
    "the @xmath0 operator is @xmath443 evaluated at @xmath40 .",
    "the generalization of non - local potentials ( appendix  [ appendix : nlpots ] ) to multiple @xmath39-points is also straightforward .",
    "the energy expression of eq .",
    "( [ eq : vpexpr ] ) generalizes to @xmath446    having completed the specification of the lagrangian with multiple @xmath39-points , the generalizations required for the orthonormality condition and the expressions for the derivatives of the lagrangian follow immediately .",
    "we introduce overlap matrices @xmath447 and unconstrained variables @xmath448 ( cf .",
    "( [ eq : udef ] ) and ( [ eq : cyumhalfvdag ] ) ) , @xmath449 where for simplicity we have set all subspace - rotation matrices to identity , @xmath450 .",
    "the differential of the lagrangian takes the form ( cf .",
    "( [ eq : hdp ] ) ) @xmath451 the single - particle hamiltonians @xmath452 depend on @xmath39 only through the kinetic operators @xmath443 , @xmath453{{\\cal i}}\\ + v\\,.\\ ] ] the expression for the single - particle potential @xmath114 is unmodified from that of eq .",
    "( [ eq : hspdef ] ) as it only depends on the total electron density @xmath20 .",
    "the term @xmath98 is to be added only if non - local potentials are employed ( see appendix  [ appendix : nlpots ] ) .",
    "the expressions of eq .",
    "( [ eq : dldydag ] ) for the derivative of the lagrangian also generalize in the following straightforward way , @xmath454,\\ \\mbox{where}\\nonumber\\\\ \\left({\\partial { { \\cal l}_{lda}}\\over \\partial y_k^\\dag}\\right ) & \\equiv & w_k \\left\\{\\left(i- { { \\cal o}}c_kc_k^\\dag\\right)h_kc_kf_ku_k^{-1/2 } + { { \\cal o}}c_kq_k([\\tilde{h}_k , f_k])\\right\\},\\ \\mbox{and}\\nonumber\\\\ \\tilde{h}_k & \\equiv & c_k^\\dag h_kc_k\\ , \\end{aligned}\\ ] ] where @xmath455 is the natural generalization of the @xmath118 operator which uses the eigenvalues and eigenvectors of @xmath447 ( appendix  [ appendix : umhalfq ] ) .",
    "in this section , we summarize and gather together the expressions for the lda lagrangian and its derivatives in the dft++ formalism for a system with @xmath39-points and non - local potentials .",
    "this type of system provides the natural starting point for studying bulk systems and the properties of defects in bulk - like systems @xcite .",
    "as we have emphasized previously , it is sufficient for us to display the formulae for the lagrangian and its derivatives because formulae in the dft++ language specify all the operations that must be performed and translate directly into computer code .",
    "( see section  [ sec : imploptpara ] . )",
    "given the lagrangian and its derivatives , we can use a variety of methods to achieve self - consistency .",
    "( see section  [ sec : minalgs ] . )",
    "we follow the notation of appendix  [ appendix : kpts ] and refer the reader to it for relevant details and definitions .",
    "the point we wish to emphasize is the compactness of the formalism and how it allows us to specify an entire quantum - mechanical lagrangian or energy function in a few lines of algebra which explicitly show the operations required for the computation .",
    "we specialize to the case of kleinmann - bylander @xcite non - local potentials ( appendix  [ appendix : nlpots ] ) .",
    "in this appendix , we define the @xmath118 operator which appears in expressions for the derivative of the lagrangian , e.g. in eq .",
    "( [ eq : dldydag ] ) .",
    "the formal properties satisfied by @xmath118 are also presented , properties used in the derivation of the expression for the derivative based on the connection between @xmath118 and the differential of the matrix @xmath456 .",
    "( see the derivation starting from eq .",
    "( [ eq : hspdef ] ) and resulting in eq .",
    "( [ eq : dldydag ] ) in section  [ sec : yderiv ] . )",
    "we start with the hermitian matrix @xmath96 .",
    "let @xmath457 be a diagonal matrix with the eigenvalues of @xmath96 on its diagonal , and let @xmath291 be the unitary matrix of eigenvectors of @xmath96 .",
    "thus , the following relations hold : @xmath253 , @xmath458 , and @xmath459 .",
    "consider the differential of the matrix @xmath96 .",
    "the leibniz rule results in @xmath460 using the unitarity of @xmath291 , we have @xmath461 differentiating the relation @xmath462 , we have that @xmath463 or @xmath464 . substituting this above",
    ", we arrive at the relation @xmath465 + d\\mu\\ , .",
    "\\label{eq : wdagduw}\\ ] ] this equation describes how differentials of the eigenvalues and eigenvectors of @xmath96 are related to the differential of @xmath96 , and it is simply a convenient matrix - based expression of the results of first - order perturbation theory familiar from elementary quantum mechanics . to see this equivalence ,",
    "we first examine the diagonal elements of eq .",
    "( [ eq : wdagduw ] ) and find @xmath466 the familiar expression for the first order shift of the eigenvalue @xmath467 . considering off diagonal matrix elements of eq .",
    "( [ eq : wdagduw ] ) leads to @xmath468 which is the expression for the first order shift of the @xmath434th wave function projected on the @xmath20th unperturbed wave function .",
    "next , we consider @xmath469 , an arbitrary analytic function of @xmath96",
    ". using the eigenbasis of @xmath96 , we can write @xmath470 where by @xmath471 we mean the diagonal matrix obtained by applying @xmath472 to each diagonal entry of @xmath457 separately . following the same logic as above , the differential of @xmath469 satisfies @xmath473 w = [ w^\\dag dw , f(\\mu ) ] + f'(\\mu)d\\mu\\,.\\ ] ] computing matrix elements of the above equation and using eqs .",
    "( [ eq : dmun ] ) and ( [ eq : wdagdw ] ) , we arrive at the general result @xmath474 w)_{nm } = ( w^\\dag du w)_{nm } \\cdot \\left\\ { \\begin{array}{cc } f'(\\mu_n ) & \\mbox{if } m = n\\\\ \\left[{f(\\mu_m)-f(\\mu_n ) \\over \\mu_m-\\mu_n}\\right ] & \\mbox{if } m \\neq n \\end{array } \\right . .",
    "\\label{eq : dfu}\\ ] ]    we now apply this result to the case where @xmath475 .",
    "this means that @xmath476 and that @xmath477 in eq .",
    "( [ eq : dfu ] ) . by employing the algebraic identity @xmath478",
    ", we arrive at the expression @xmath479 w)_{nm } = { ( w^\\dag du w)_{nm } \\over \\sqrt{\\mu_n } + \\sqrt{\\mu_m } } = ( w^\\dag q(du ) w)_{nm}\\ , , \\label{eq : uhalfq}\\ ] ] where we define the operator @xmath480 for an arbitrary matrix @xmath149 to be @xmath481 from this definition of @xmath118 , it is easy to prove that the following identities are satisfied for arbitrary matrices @xmath149 and @xmath99 and arbitrary power @xmath37 : @xmath482\\nonumber\\\\ \\mbox{tr}\\left(q(a)b\\right ) & = & \\mbox{tr}\\left(aq(b)\\right)\\nonumber\\\\ \\mbox{tr}\\left(q(u^pa)b\\right ) & = & \\mbox{tr}\\left(u^pq(a)b\\right)\\nonumber\\\\ \\mbox{tr}\\left(q(au^p)b\\right ) & = & \\mbox{tr}\\left(q(a)u^pb\\right)\\nonumber\\\\ a & = & q(a)u^{1/2 } + u^{1/2}q(a)\\ , .",
    "\\label{eq : qidents}\\end{aligned}\\ ] ] these are the identities used in the derivation of the expression for the derivative of the lagrangian with respect to @xmath95 in section  [ sec : yderiv ] ."
  ],
  "abstract_text": [
    "<S> this article addresses a fundamental problem faced by the community employing single - particle _ ab initio _ methods : the lack of an effective formalism for the rapid exploration and exchange of new methods . to rectify this </S>",
    "<S> , we introduce a new , basis - set independent , matrix - based formulation of generalized density functional theories which reduces the development , implementation , and dissemination of new techniques to the derivation and transcription of a few lines of algebra . </S>",
    "<S> this new framework enables us to concisely demystify the inner workings of fully functional , highly efficient modern _ ab initio _ codes and to give complete instructions for their construction for calculations employing arbitrary basis sets . within this framework </S>",
    "<S> , we also discuss in full detail a variety of leading - edge techniques , minimization algorithms , and highly efficient computational kernels for use with scalar as well as shared and distributed - memory supercomputer architectures . </S>"
  ]
}