{
  "article_text": [
    "several systems , e.g. , trains have been produced to date which model the progress of a dialogue between two agents engaged in a common task . these systems typically represent agents as having a set of possible reasoning methods which they can adopt in response to a situation , e.g. , they can react to what has just been said to them , they can make a plan involving saying something themselves , or they can attempt to recognize the plan being executed by the agent who just spoke .",
    "all such reasoning must take place in relation to the agents beliefs .",
    "a belief model capable of supporting all relevant inferences is thus a necessary component of a simulated agent .",
    "the more complex the reasoning being done , the more expressive the agent s belief model must be . in particular ,",
    "if agents are going to use planning and plan recognition , they must be capable of making inferences about nested beliefs , i.e. , beliefs about other agents beliefs .",
    "belief models thus correspond to epistemic logics , and are sometimes implemented as theorem provers in standard logics , e.g. , .",
    "these logics allow repeated nestings of beliefs without limit , and are computationally intractable . however , deeply - nested beliefs appear to be useful only in equally deeply - nested reasoning , e.g. , recognizing an agent s plan to have a different plan recognized . reasoning at this depth of nesting is invariably associated with the attempted practice or recognition of deception .",
    "furthermore , in most attempts to define logics combining epistemic and temporal properties , e.g. , each level of belief nesting includes a temporal argument , allowing the representation of propositions such as `` fred believed at 3 pm that doris believed at 6 pm that the cat was out '' .",
    "even with a simple representation of time such as the situation calculus @xcite , such representations result in unnecessary complexity , as the persistence of beliefs over time has to be deduced explicitly at each level .",
    "noting that some dialogue simulators , e.g. , jam @xcite work well with hard limits on belief nesting and only the simplest representation of time , we have developed a specification for a belief model which embodies these limits . we have shown that as far as nesting levels are concerned ,",
    "the model s limitations cause few alterations in dialogue competence and in any case human dialogue behaviour corresponds in some ways to that of such a model @xcite . however , the computational advantages of such models can only be realized by their use in conjunction with customized reasoning systems , in which the expressiveness of the formulae specifying the `` ideal '' behaviour has been narrowed to cover only the actual cases embodied by the simplified model .",
    "we are currently in the process of building a `` compiler '' for belief models .",
    "this system will accept as input a description of agents interactions with a task domain , expressed in a fully - expressive belief logic with non - monotonic and temporal extensions @xcite .",
    "it produces a self - contained model of an agent s beliefs and inferences in the specified domain .",
    "this model includes an interface to events in the simulated domain based on an update and query language which is a subset of the original fully - expressive language .",
    "the model can thus be used in conjunction with planning and plan recognition components to create a full simulated agent for the domain , and multiple instances of such agents can be made to simulate dialogue .    in overview ,",
    "the process of compilation is as follows :    1 .",
    "the fully - expressive specification is checked for constructs which can not be compiled ; these should not be found necessary in specifications of plausible domains 2 .",
    "the specification is translated into a standard form resembling conjunctive - normal form ( cnf ) 3 .",
    "constructions that would create excess complexity in reasoning about beliefs or times are substituted for instantiations involving finite sets of agents , nesting depths or times 4 .",
    "clauses that contain no quantifiers are now added as premises or assumptions ( if atomic ) or justifications ( if disjunctive ) to an assumption - based truth maintenance system ( dekleer s @xcite atms ) .",
    "the other clauses are held in a `` rule base '' .",
    "5 .   when an atms node unifies with a disjunct in a rule , a new rule or atms entity is generated by substituting the individuals in that node into the rule 6 .",
    "updates to the model ( corresponding to ongoing events in the simulated domain ) are translated using the same process .",
    "queries are handled by examining the labels of atms nodes .",
    "this is a fairly complex process , and will require some elucidation . in each of the sections that follow , we shall discuss a particular aspect of the simplifications that are made _ en route _ from the fully - expressive specification language to the operational principles of the compiled belief model . for each such aspect , we shall examine the following compiler features :    * the restrictions applying to the specification language * the principles that allow reductions in complexity * the ways in which these principles are applied    we shall illustrate them with reference to our pilot domain , the map task .",
    "this is a problem in which two agents each have a map , and one must guide the other along a route marked only on her own map , with reference to landmarks that may or may not be on both maps .",
    "if we work on the assumptions that agents are attempting common goals , and that while agents may also have private goals these never require their dialogue partners to be misled , we can eliminate the need for explicit deeply - nested reasoning .",
    "agents will still need to react , to plan and to recognize plans , but in the case of planning for plan recognition the plan to be recognized is always part of the speaker s actual plan .",
    "so though planning for plan recognition always requires deeply nested beliefs , under the cooperative assumption these are always identical in content to less deeply nested beliefs .",
    "an agent can therefore generate a full repertoire of dialogue behaviour in a cooperative setting while distinguishing between only three types of nesting for its beliefs , namely : beliefs about facts at the domain level ( non - nested beliefs ) , beliefs about the partner s domain - level beliefs ( singly nested beliefs ) and beliefs about what is believed at all deeper levels .",
    "we call the last type residual mutual beliefs ( rmb ) , because if two agents share all three of these types of belief in a fact , they have mutual belief of that fact .",
    "when an agent has evidence that the individual deeply - nested beliefs that make up a rmb differ from each other , the rmb becomes undefined .",
    "while this is certainly a limitation on the capabilities of the agents , it appears that human believers in cooperative situations behave as if they have similar limitations on their representational capabilities , i.e. , they will avoid utterances that depend for their success on such beliefs @xcite .",
    "given that we are making the assumption of cooperation throughout , we must restrict the domain specification to rules appropriate to a cooperative domain .",
    "specifically we disallow arbitrary implications from one nested belief to another , e.g. , `` if a believes x , then b believes y '' .",
    "we allow the following constructs :    * deduction by an agent , e.g. , if doris has a swamp on her map , and knows where she should be in relation to the swamp , then she knows where she should be on the map .",
    "* relations between domain properties and beliefs , e.g. , if fred says he has a waterfall , then doris believes he said this .",
    "* initial beliefs of the three types mentioned above , e.g. , private belief in the absence of a palm beach from one s own map , the presence of the route on one s partner s map , and mutual belief in the other relations described above .",
    "even with these restrictions , there exists the potential for an unlimited proliferation of beliefs , as a formula such as @xmath0 can be repeatedly unified with its own antecedent .",
    "however , when translated into cnf , each conjunct contains terms separated by at most one level of belief nesting .",
    "such conjuncts may themselves be beliefs , including mutual beliefs , in disjunctions of belief terms , so to create the rule base the mutual belief prefixes must be expanded into sequences that are then limited to the finite nesting depth of the rapid model .",
    "the rapid model itself takes the role of a single agent , so beliefs not of that agent are irrelevant .",
    "terms in the model can have three belief prefixes : @xmath1 , meaning an object - level belief of the simulated agent , @xmath2 , meaning a belief about the partner s beliefs , and @xmath3 for residual mutual beliefs",
    ". the @xmath3 level is only added for beliefs that are explicitly mutual , or beliefs that recursively imply themselves at deeper levels .",
    "so for instance , the formula @xmath4 ( i.e. , it is mutually known that all agents know about all utterances that happen ) would be rendered @xmath5 . in the cases where individual agents are named in the specification , e.g. , it is mutually believed that fred does not know where the route is , beliefs of type @xmath3 can not be inferred , because they would have to be about that agent s beliefs in particular and the rapid model does not allow nesting of its belief operators .",
    "there are two basic reasons for including nonmonotonic inferences in a logic of belief for dialogue .",
    "firstly , if the agents are having to cooperate , then neither initially has full knowledge of the domain , and they must rely on assumptions in order to make plans to communicate . for instance , in the map task , agents start with the assumption that the landmarks appearing on their own maps also apear on their partners maps . as the dialogue proceeds , they will occasionally have to abandon such assumptions .",
    "secondly , cooperating agents use plan recognition to enhance the effectiveness of their communication .",
    "typically an addressee applies plan recognition to the speaker , and then supplements her reactive reply with an initial utterance addressing an unfulfilled goal in the recognized plan , e.g. .",
    "since plan recognition is an imprecise process , and indeed most initial utterances could potentially form part of a number of plans , the beliefs that one agent ascribes to another in the process of plan recognition follow in part from assumptions and must be defeasible .    given the multiple sources of defaults in a belief model , an appropriate logic is hierarchical autoepistemic logic , or hael @xcite which allows such defaults to be prioritized .",
    "the specification of default reasoning in hael is extremely flexible ; formulae are distributed amongst evidential spaces , which are partially ordered from strongest to weakest .",
    "a modal operator @xmath6 allows formulae in any evidential space to refer to the presence or absence of conclusions in stronger spaces , allowing such concepts as `` if wilbur is a mammal , conclude that he does nt fly , unless there is stronger evidence that he does '' , with the stronger evidential space containing `` if wilbur is a bat , conclude that he flies , unless there is stronger evidence that he does not '' .",
    "combining this notation with other modal operators for beliefs causes problems ; in domains such as the map task , the world itself is always a certain way  it is only the beliefs that are uncertain .",
    "this seems to require that we use the @xmath6 operator inside the scope of beliefs .",
    "however that would only make sense if the agent s beliefs were themselves divided into different evidential spaces , rather than simply occurring in them . in order to avoid this requirement we never put the @xmath6 operator inside any modal context ; fortunately , uncertain beliefs and beliefs in uncertainties behave the same way .    to express the concept of mutual defaults , i.e. , things mutually known to be defaults , without violating this rule",
    ", we restrict the specification language to _ normal defaults_. these are schemata for propositions which are always true if not contradicted . a normal default @xmath7 is equivalent to @xmath8 , where @xmath9 is the evidential space immediately above that containing @xmath7 . for instance , in the bat example above",
    ", we would create a normal default `` terrestrial - mammal '' ( @xmath10 ) and write @xmath11 , and thence @xmath12 .",
    "( this can be made even simpler by using many - sorted logic and allowing @xmath13 to be a sort rather than a predicate . )    using @xmath14 , we can specify mutual defaults without putting any references to other evidential spaces inside belief contexts . the behaviour of a mutual default @xmath15 is defined as if by : @xmath16 . a map task agent s belief that all landmarks appear on both maps unless they are known not to , is thus a mutual default ; it will hold at any level of nesting unless specifically blocked at that level .    constrained to these schemata",
    ", defaults can be added to the rapid model without any further simplification .",
    "mutual defaults are replaced by individual default beliefs at each of the nesting levels explicitly represented , just as mutual knowledge is replaced by individual beliefs .",
    "the individual defaults specify the generation of assumed nodes in the atms , with the assumption indicating the evidential space in which the default holds .",
    "where a proposition and its negation both exist as nodes in the atms , the truth value of each is worked out by looking at the labels of both to see which has justification in which evidential space ; the outcome may be :    * one has justification in a stronger space than the other ; it is then true in all spaces weaker than that space , while the other is not true at all * each is justified in a space not ordered with respect to the other ; both are then true in different spaces * both are justified in the same space ; this is an inconsistency and should never happen .",
    "determining these truth values could be done by placing node states on a bilattice , as in ginsberg s @xcite logical interpretation of the atms , or the pruning routine of the atms itself could be enhanced to remove groups of assumptions contradicted by stronger ones , as well as those contradicting premises .",
    "ai research in planning looks at problems that are `` nearly decomposable '' ; where steps to achieve separate subgoals only occasionally interfere with each other .",
    "there are many temporal formalisms available for representing such domains in logical notations , but to model agents discussing and reasoning about such problems , these must be combined with logics of belief .",
    "this invariably results in the need to ascribe a time point or interval to the belief itself as well as the believed proposition .",
    "nested beliefs need a time point at each level of nesting , e.g. , . however , the only respect in which a full temporal logic appears to be necessary is that of the object level , where getting temporal relations wrong might cause , e.g. , trains to collide .",
    "beliefs themselves have temporal properties that make them easier to model than object level facts in a complex domain .",
    "they are generated by acts of observation or inference and persist just until some other observation or inference overturns them .",
    "modelling such persistence in temporal logic requires the application of a frame axiom , and where there are several types of event that can overturn a belief these must be circumscriptive , i.e. , be expressible as `` in the absence of any conclusion that belief b is contradicted at time @xmath17 , allow it to persist to @xmath18 '' .",
    "such axioms are also necessary to model persistence in the domain , but because here only certain types of event can influence a given property , circumscriptive axioms and their extra logical complexity are typically not required .",
    "the need to model the behaviour of beliefs over time is the main motivation for the use of the atms .",
    "indeed this is the motivation behind many rmss ; we have chosen the atms simply because it has the closest correspondence in its functionality to the evidential spaces of hael . in its role as a continuing simulation of a believer confronting new evidence concerning an essentially static world ( i.e. , the map task ) ,",
    "the atms nodes need make no reference to time at all .",
    "so our tactic in translating formulae referring to times for use in the rapid model is simply to strip out all temporal arguments from belief operators , and replace all temporal relations with @xmath19 .",
    "but our agent shares her world with others , whose beliefs also change , so as well as the case familiar in rmss where beliefs are revised in response to stronger evidence ( as discussed by grdenfors @xcite ) , beliefs about beliefs can also become out of date .",
    "for instance , in the map task , one agent may at one point believe that the other does not know where a particular landmark is , but at a later point she may realize that from the information she has provided , the other agent has now deduced where it is",
    ". this would be awkward if such beliefs are added to the atms as premises , as there is no way of retracting a premise , so they must be made into assumed nodes .",
    "each time a justification for a @xmath20 or @xmath21 node is added , a special assumption is included in its antecedents .",
    "this assumption includes the ordinality of the time at which it is added , so when labels justifying contradictory beliefs are compared , that depending on the most recent evidence can be preferred .",
    "when we extend the system to cope with domains in which physical change occurs , such as the trains world , we will need a more complex representation of temporal interactions .",
    "points the way for doing temporal reasoning in a network structure ; the truth of a proposition at a given time in his planner tweak is defined by a _ modal truth criterion (",
    "mtc)_. describes how a simplified version of chapman s mtc can be used in conjunction with the atms to model an agent s estimation of the value of a proposition at a given time as knowledge of relevant events at earlier times is added to the agent s world knowledge . here",
    ", the system is also used for keeping track of other agents beliefs , a task for which it is overcomplex .",
    "such a system in conjunction with the currently proposed method of tagging out - of - date beliefs should result in a highly efficient system for reasoning about plans .",
    "the compiler itself is currently under construction .",
    "so far , we have developed a characterization of the map task supporting the same dialogues as carletta s jam @xcite as a test domain .",
    "this characterization has been formalized in our fully - expressive language , and we have completed a package in prolog for carrying out the first stage of its conversion to to the rapid model , i.e. , conversion into cnf .",
    "the resulting characterization can be analysed with a theorem prover , also written in prolog , to illustrate that the desired inferences all follow , although quite understandably , the computational complexity of actually following a whole dialogue by this means is prohibitive .    in parallel with this exercise",
    "we hace constructed a rapid model for the same task , based on an atms and a rule - based inference system as has been described for the models generated by the compiler .",
    "this was originally developed simply with the object of constructing a working system to support map task dialogue simulation @xcite .",
    "for the purposes of the work described here , it was compared with the logical characterization of the domain , and then both were refined to the point where an orderly relationship existed between the formulae of one and the node names and inference rules of the other .",
    "this relationship conformed to the overview of the compilation process given in section  [ overview - sec ] , and is the basis for the automated translation from one to the other which is the subject of work at the time of writing .",
    "when this is complete , the next step will be to specify the update and query language ; this will be a simplified version of the fully - expressive language used to create the model , eliminating modal operators except when applying to whole formulae .    to illustrate the compilation process as it is curently envisaged",
    ", we will take just a few axioms from the map task ; those required for one agent to believe that after the other has given him a description of part of the route , he believes the other agent to believe as a default that he is vividly acquainted with that route section .",
    "we use many - sorted notation , for the practical advantages noted by @xcite and because it allows time and agent variables to be marked for the special preprocessing they require .",
    "informally , the language describes the domain as follows : terms can be of sort @xmath22 @xmath23 @xmath24 @xmath25 @xmath26 @xmath27 ( of an utterance ) , @xmath28 or @xmath29 ( standing for propositions in quantified modal formulae . )",
    "the sorts @xmath30 and @xmath31 are subsorts of @xmath32 .",
    "we then have the following predicates to comprise what agents can know about the domain :    [ cols= \" < , < \" , ]      the axioms are as follows :    map information makes landmarks vivid @xmath33    utterances always get heard : @xmath34 @xmath35    all assertions are true ( our model assumes the planner treats truth as a precondition for utterances ; this could be done differently ) @xmath36    descriptions confer vividness @xmath37 @xmath38    all landmarks ( but not all map items ) are expected to be on other agents maps @xmath39 @xmath40    route sections are known to be on the instruction giver s ( doris ) map @xmath41",
    "@xmath42      these are first translated into cnf , and then fitted to the requirements of the rapid model .",
    "this involves the expansion of mutual beliefs and mutual defaults into finite series of individual beliefs and defaults about beliefs as described in section  [ belmod_sec ] .",
    "time parameters are simply stripped out , as there is currently no use for them in the domain .",
    "the results are as follows :    [ mpcv_eqn ] becomes : @xmath43 @xmath44 @xmath45    [ percep_eqn ] becomes : @xmath46 @xmath47 a similar pair relating to fred are also created .",
    "note that the original implication from a shallow nested belief to an identical deeper one allows the @xmath48 to be included .",
    "[ truth_eqn ] becomes : @xmath49 @xmath50 @xmath51    [ dcv_eqn ] becomes : @xmath37 @xmath52 @xmath37 @xmath53 @xmath37 @xmath54    [ share_eqn ] becomes : @xmath55 @xmath56    [ ig_know_eqn ] becomes : @xmath57 this is the only rule produced for this formula ; although the original refers to all levels below the first , putting @xmath58 here would refer to doris beliefs about fred s map .",
    "all the above contain quantifiers , so none of them cause any nodes to be added initially to the atms .",
    "formulae corresponding to map information are also included ; these will be added using the update and query language .",
    "suppose fred has a swamp on his map , which he refers to internally as @xmath59 .",
    "his database is initially updated with the proposition @xmath60 which , containing no quantifiers , is added as a premise in the atms .",
    "once in the atms , a test is made to see if it resolves with any disjunct from the rule base ; it does with [ mpcv_eqn_r1 ] , and the substituted version of this is added to the atms as a justification from @xmath60 to @xmath61 , the latter being supported by this justification .",
    "now suppose fred s partner doris opens the dialogue by saying `` the first part of the route goes left of the palm beach '' .",
    "as we are looking at a database that is modelling fred , his hearing this utterance is modelled by his awareness of it being established by its assertion in the update and query language : @xmath62 .",
    "this too is unquantified , so produces a premise node in the atms .",
    "it unifies with [ percep_eqn_r1 ] to produce @xmath63 , which in turn unifies with [ percep_eqn_r2 ] justifying + @xmath64 .",
    "these three unify with terms in [ truth_eqn_r1 ]  [ truth_eqn_r3 ] to justify beliefs at the three levels in the actual description , which in turn unify with [ dcv_eqn_r1 ]  [ dcv_eqn_r3 ] to produce justifications for vividness of the first section based on vividness of the palm beach .",
    "however the nodes @xmath65 , @xmath66 and @xmath67 as yet have no justification .",
    "they do however unify with [ mpcv_eqn_r1 ]  [ mpcv_eqn_r3 ] , giving them justifications from @xmath68 , @xmath69 and @xmath70 , and the latter two of these match up to the default clauses in [ share_eqn_r1 ] and [ share_eqn_r2 ] , which result in assumptions being created for them . @xmath69 and @xmath70 each get a @xmath71 assumption , which is created with a serial number .",
    "these assumptions are propagated through the links that have been added , and appear in the labels of the nodes for @xmath72 and @xmath73 .",
    "the first of these is made a premise by [ mpcv_eqn_r2 ] and [ ig_know_eqn_r ] , and the assumption label for this becomes redundant and is removed by the atms , but the second remains as an assumption .",
    "this is the situation illustrated in figure  [ atms_state_fig ] .",
    "what happens next is that fred makes an utterance indicating he has not understood the description ; this will give him a justification for @xmath74 depending only on a current time - stamp assumption .",
    "this will form a contradiction with the positive node and result in the assumption justifying it ( @xmath75 ) being removed from the system .",
    "subsequently , queries to the database regarding the status of @xmath73 will be answered in the negative . in her next utterance",
    ", doris may offer fred a description of the palm beach in terms of the swamp , which he has ( and which she can assume him to have ) .",
    "this will create a new justification for @xmath73 , resulting in the first section finally becoming mutually vivid for them .",
    "the compiler should illustrate the adequacy of belief models of the type that we propose , by allowing the creation of a number of such models and their comparison with the results that would be obtained directly from the original specification of the domain , as well as the performance of systems using these models in conjunction with planning and plan recognition systems to model conversational agents .",
    "furthermore it is expected that the models produced by the compiler in this way will have sufficiently rapid performance to allow their use in real - time dialogue systems .",
    "this is the case for a prototype model developed for a map task dialogue system , whereas use of an automated theorem prover working in the unrestricted logical language in this domain appears to be impossible due to computational complexity .",
    "allen , j.  f. , l.  k. schubert , g.  ferguson , p.  heeman , c.  h. hwang , t.  kato , m.  light , n.  g. martin , b.  w. miller , m.  poesio , and d.  r. traum ( 1994 )",
    ". the trains project : a case study in building a conversational agent .",
    "technical report 94 - 3 , computer science dept .",
    "university of rochester , rochester , new york .",
    "taylor , j. and j.  carletta ( 1994 ) . limiting nested beliefs in cooperative dialogue . in a.",
    "ram and k.  eiselt ( eds . ) , _ proceedings of the sixteenth annual conference of the cognitive science society _ , hillsdale , new jersey , pp .",
    "lawrence erlbaum associates ."
  ],
  "abstract_text": [
    "<S> we have shown that belief modelling for dialogue can be simplified if the assumption is made that the participants are cooperating , i.e. , they are not committed to any goals requiring deception . in such domains , there is no need to maintain individual representations of deeply nested beliefs ; instead , three specific types of belief can be used to summarize all the states of nested belief that can exist about a domain entity .    here , we set out to design a `` compiler '' for belief models . </S>",
    "<S> this system will accept as input a description of agents interactions with a task domain expressed in a fully - expressive belief logic with non - monotonic and temporal extensions . </S>",
    "<S> it generates an operational belief model for use in that domain , sufficient for the requirements of cooperative dialogue , including the negotiation of complex domain plans . </S>",
    "<S> the compiled model incorporates the belief simplification mentioned above , and also uses a simplified temporal logic of belief based on the restricted circumstances under which beliefs can change .    </S>",
    "<S> we shall review the motivation for creating such a system , and introduce a general procedure for taking a logical specification for a domain and procesing it into an operational model . </S>",
    "<S> we shall then discuss the specific changes that are made during this procedure for limiting the level of abstraction at which the concepts of belief nesting , default reasoning and time are expressed . </S>",
    "<S> finally we shall go through a worked example relating to the map task , a simple cooperative problem - solving exercise . </S>"
  ]
}