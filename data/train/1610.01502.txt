{
  "article_text": [
    "the shape of a set of points , the shape of a signal , the shape of a surface , or the shapes in an image can be defined as follows : the remainder after we have filtered out the position and the orientation of the object @xcite . statistics on shapes appear in many fields .",
    "paleontologists combine shape analysis of monkey skulls with ecological and biogeographic data to understand how the _ skull shapes _ have changed in space and time during evolution @xcite .",
    "molecular biologists study how _ shapes of proteins _ are related to their function .",
    "statistics on misfolding of proteins is used to understand diseases , like parkinson s disease @xcite .",
    "orthopaedic surgeons analyze _",
    "bones shapes _ for surgical pre - planning @xcite . in signal processing ,",
    "the _ shape of neural spike trains _ correlates with arm movement @xcite . in computer vision , classifying _ shapes of handwritten digits _ enables automatic reading of texts @xcite . in medical imaging and more precisely in neuroimaging , studying _ brain shapes _ as they appear in the mris facilitates discoveries on diseases , like alzheimer @xcite .",
    "what do these applications have in common ?",
    "position and orientation of the skulls , proteins , bones , neural spike trains , handwritten digits or brains do not matter for the study s goal : only _ shapes _ matter .",
    "mathematically , the study analyses the statistical distributions of _ the equivalence classes of the data _ under translations and rotations .",
    "they project the data in a quotient space , called the _ shape space_.    the simplest - and most widely used - method for summarizing shapes is the computation of the mean shape .",
    "almost all neuroimaging studies start with the computation of the mean brain shape @xcite for example .",
    "one refers to the mean shape with different terms depending on the field : mean configuration , mean pattern , template , atlas , etc .",
    "the mean shape is an average of _ equivalence classes of the data _ : one computes the mean after projection of the data in the shape space .",
    "one may wonder if the projection biases the statistical procedure .",
    "this is a legitimate question as any bias introduced with this step would make the conclusions of the study less accurate .",
    "if the mean brain shape is biased , then neuroimaging s inferences on brain diseases will be too .",
    "this paper shows that a bias is indeed introduced for the mean shape estimation under certain conditions .",
    "we review works on the shape space s geometry as a quotient space , and existing results on the mean shape s bias .",
    "* shapes of landmarks : kendall analyses * the theory for shapes _ of landmarks _ is introduced by kendall in the 1980 s @xcite .",
    "he considers shapes of @xmath1 labeled landmarks in @xmath2 .",
    "the size - and - shape space , written @xmath3 , takes also into account the overall size of the landmarks set . the shape space , written @xmath4 , quotients by the size as well .",
    "both @xmath3 and @xmath4 have a riemannian geometry , whose metrics are given in @xcite .",
    "these studies model the probability distribution of the data directly in the shape space @xmath4 .",
    "they do not consider that the data are observed in the space of landmarks @xmath5 and projected in the shape space @xmath4 .",
    "the question of the bias is not raised .",
    "* shapes of landmarks : procrustean analyses * procrustean analysis is related to kendall shape spaces but it also considers shapes of landmarks @xcite .",
    "kendall analyses project the data in the shape space by explicitly computing their coordinates in @xmath4 .",
    "in contrast , procrustean analyses keep the coordinates in @xmath5 : they project the data in the shape space by `` aligning '' or `` registering '' them .",
    "orthogonal procrustes analysis `` aligns '' the sets of landmarks by rotating each set to minimize the euclidean distance to the other sets . procrustean analysis considers the fact that the data are observed in the space @xmath5 but does not consider the geometry of the shape space . the bias on the mean shape is shown in @xcite with a reducto ad absurdum proof .",
    "but there is no geometric intuition given about how to control or correct the phenomenon .",
    "* shapes of curves * the curve data are projected in their shape space by an alignment step @xcite , in the spirit of a procrustean analysis .",
    "the bias of the mean shape is discussed in the literature .",
    "unbiasedness was shown for shapes of signals in @xcite but under the simplifying assumption of no measurement error on the data .",
    "some authors provide examples of bias when there is measurement error @xcite .",
    "their experiments show that the mean signal shape may converge to pure noise when the measurement error on simulated signals increases .",
    "the bias is proven in @xcite for curves estimated from a finite number of points in the presence of error .",
    "but again , no geometric intuition nor correction strategy is given .",
    "we are missing a global geometric understanding of the bias . which variables control its magnitude ?",
    "is it restricted to the mean shape or does it appear for other statistical analyses ?",
    "how important is it in practice : do we even need to correct it ?",
    "if so , how can we correct it ?",
    "our paper is addressing these questions .",
    "we use a geometric framework that unifies the cases of landmarks , curves , images etc .",
    "[ [ contributions ] ] contributions + + + + + + + + + + + + +    we make three contributions .",
    "first , we show that statistics on shapes are biased when the data are measured with error .",
    "we explicitly compute the bias in the case of the mean shape .",
    "second , we offer an interpretation of the bias through the geometry of the shape space . in applications ,",
    "this aids in deciding when the bias can be neglected in contrast with situations when it must be corrected .",
    "third , we leverage our understanding to suggest several correction approaches .",
    "[ [ outline ] ] outline + + + + + + +    the paper has four sections .",
    "section 1 introduces the geometric framework of shape spaces .",
    "section 2 presents our first two contributions : the proof and geometric interpretation of the bias .",
    "section 3 describes our third contribution : the procedures to correct the bias .",
    "section 4 validates and illustrates our results on synthetic and real data .",
    "we introduce two simple examples of shape spaces . we will refer to them constantly to provide intuition .    first , we consider two landmarks in the plane @xmath6 ( figure  [ fig : simple ] ( a ) ) .",
    "the landmarks are parameterized each with 2 coordinates .",
    "for simplicity we consider that one landmark is fixed at the origin on @xmath6 .",
    "thus the system is now parameterized by the 2 coordinates of the second landmark only , e.g. in polar coordinates @xmath7 .",
    "we are interested in the shape of the 2 landmarks , i.e. in their distance which is simply @xmath8 .",
    "second , we consider two landmarks on the sphere @xmath9 ( figure  [ fig : simple ] ( b ) ) .",
    "one of the landmark is fixed at the origin of @xmath9 .",
    "the system is now parameterized by the 2 coordinates of the second landmark only , i.e. @xmath10 . the shape of the two landmarks is the angle between them and is simply @xmath11 .",
    "the data are objects @xmath12 that are either sets of landmarks , curves , images , etc .",
    "we consider that each object @xmath13 is a point in a riemannian manifold @xmath14 .",
    "we restrict in this paper to finite dimensional manifolds in order to avoid complications .",
    "we have @xmath15 in the plane example : a flat manifold of dimension 2 .",
    "we have @xmath16 in the sphere example : a manifold of constant positive curvature and of dimension 2 .    by definition ,",
    "the objects shapes are their equivalence classes @xmath17\\}_{i=1}^n$ ] under the action of some finite dimensional lie group @xmath18 : @xmath18 is a group of continuous transformations that models what does not change the shape . the action of @xmath18 on @xmath14 will be written with `` @xmath19 '' . in our examples ,",
    "the rotations are the transformations that leave the shape of the systems invariant .",
    "let us take @xmath20 a rotation .",
    "the action of @xmath20 on the landmark @xmath21 is illustrated by a blue arrow in figures  [ fig : leadingcases1 ] ( a ) for the plane and ( d ) for the sphere .",
    "we observe that the action does not change the shape of the systems : the distance between the two landmarks is preserved in ( a ) , the angle between the two landmarks is preserved in ( d ) .",
    "the equivalence class of @xmath13 is also called its orbit and written @xmath22 .",
    "the equivalence class / orbit of @xmath21 is illustrated with the blue dotted circle in figure  [ fig : leadingcases1 ] ( a ) for the plane example and in figure  [ fig : leadingcases1 ] ( b ) for the sphere example .",
    "the orbit of @xmath21 in @xmath14 is the submanifold of all objects in @xmath14 that have the same shape as @xmath21 .",
    "the curvature of the orbit as a submanifold of @xmath14 is the key point of the results in section  [ sec : quant ] .",
    "the _ shape space _ is by definition the space of orbits .",
    "this is a quotient space denoted @xmath23 .",
    "one orbit in @xmath14 , i.e. one circle in figure  [ fig : leadingcases1 ] ( b ) or ( e ) , corresponds to a point in @xmath24 .",
    "the shape space is @xmath25 in the plane example .",
    "this is the space of all possible distances between the two landmarks , see figure  [ fig : leadingcases1 ] ( c ) .",
    "the shape space is @xmath26 $ ] in the sphere example .",
    "this is the space of all possible angles between the two landmarks , see figure  [ fig : leadingcases1 ] ( f ) .",
    "we consider that the action of @xmath18 on @xmath14 is _ isometric with respect to the riemannian metric of @xmath14_. this implies that the distance @xmath27 between two objects in @xmath14 does not change if we transform both objects in the same manner . in the plane example , rotating the landmark @xmath28 and another landmark @xmath29 with the same angle does not change the distance between them .",
    "the distance in @xmath14 induces a quasi - distance @xmath30 in @xmath24 : @xmath31 .",
    "the distance between the shapes of @xmath28 and @xmath29 is computed by first registering / aligning @xmath28 onto @xmath29 by the mean of @xmath20 , and then using the distance in the ambient space @xmath14 . in the plane example",
    ", the distance between two shapes is the difference in distances between the landmarks .",
    "one can compute it by first aligning the landmarks , say on the first axis of @xmath6 .",
    "then , one uses the distance in @xmath6 .      both object space @xmath14 and shape space @xmath24 are stratified because of the notion of isotropy group .",
    "the _ isotropy group of @xmath13 _ is the subgroup of transformations of @xmath18 that leave @xmath13 invariant .",
    "for the plane example , every @xmath32 has isotropy group the identity and @xmath33 has isotropy group the whole group of 2d rotations .",
    "objects on the same orbit , i.e. objects that have the same shape , have conjugate isotropy groups .",
    "the _ orbit type _ of an orbit is the corresponding conjugate class .    _",
    "principal shapes _ are shapes with smallest isotropy group conjugation class . in the plane example",
    ", @xmath34 is the set of objects with principal shapes .",
    "it corresponds to @xmath35 in the shape space and is colored in blue on figure  [ fig : leadingcases1 ] ( c ) .",
    "_ singular shapes _ are shapes with larger isotropy group conjugation class . in the plane example",
    ", @xmath33 is the only object with singular shape .",
    "it corresponds to @xmath36 in @xmath37 and is colored in red in figure  [ fig : leadingcases1 ] ( c ) .",
    "the ( connected components of ) the _ orbit types _ form a stratification of @xmath14 , called the _ orbit - type stratification of @xmath14_. the principal type is predominant in the following sense : the set of principal strata , which we denote @xmath38 , is open and dense in @xmath14 .",
    "this means that there are objects with non - degenerated shapes almost everywhere .",
    "the stratification of @xmath14 into orbit types strata gives a stratification of the shape space @xmath39 .",
    "also , non - degenerated shapes are dense in the shape space .",
    "we have focused on an intuitive introduction of the concepts .",
    "we refer to @xcite for mathematical details . from now on ,",
    "the mathematical setting is the following : we assume a proper , effective and isometric action of a finite dimensional lie group @xmath18 on a finite dimensional riemannian manifold @xmath14 .",
    "we recall that the data are the @xmath12 that are sets of landmarks , curves , images , etc .",
    "we interpret the data @xmath13 s as random realizations of the generative model : @xmath40 where the observed object @xmath41 is a shape @xmath42 with a given position or parameterization @xmath43 and observed with noise @xmath44 . here",
    "exp(p , u ) denotes the riemannian exponential of @xmath45 at point @xmath46 .",
    "the @xmath47 are themselves i.i.d .",
    "realizations of random variables . drawing them",
    "lead to the following three step interpretation of the generative model  [ eq : genmodel ] .",
    "[ [ step-1-generate - the - shape - y_i - in - mg ] ] step 1 : generate the shape @xmath48 + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    we assume that there is an probability density of shapes in @xmath23 , with respect to the measure on @xmath24 induced by the riemannian measure of @xmath14 .",
    "the @xmath49 s are i.i.d .",
    "samples drawn from this distribution .",
    "for example , it can be a gaussian as illustrated in figure  [ fig : genmodel1 ] on the shape spaces for the plane and sphere examples .",
    "this is the variability that is meaningful for the statistical study , whether we are analyzing shapes of skulls , proteins , bones , neural spike trains , handwritten digits or brains .",
    "we assume in this paper that the distribution is simply a dirac at @xmath50 which we call the _ template shape_. this is the most common assumption in these generative models @xcite .",
    "[ [ step-2-generate - its - positionparameterization - g_i - in - g ] ] step 2 : generate its position / parameterization @xmath43 + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    we can not observe shapes in @xmath23 .",
    "we rather observe objects in @xmath14 , that are shapes posed or parameterized in a certain way .",
    "we assume that there is a probability distribution on the positions or parameterizations of @xmath18 , or equivalently a probability distribution on principal orbits with respect to their intrinsic measure .",
    "we assume that the distribution does not depend on the shape @xmath49 that has been drawn .",
    "the @xmath51 s are i.i.d . from this distribution .",
    "for example , it can be a gaussian as illustrated in figure  [ fig : genmodel2 ] on the shape spaces for the plane and sphere examples .",
    "[ [ step-3-generate - the - noise - epsilon_i - in - t_g_i - cdot - y_im ] ] step 3 : generate the noise @xmath44 + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    the observed @xmath13 s are results of noisy measurements .",
    "we assume that there is a probability distribution function on @xmath52 representing the noise .",
    "we further assume that this is a gaussian centered at @xmath53 , the origin of the tangent space @xmath52 , and with standard deviation @xmath0 , see figures  [ fig : genmodel3 ]",
    ". the parameter @xmath0 will be extremely important in the developments of section , as we will compute taylor expansions around @xmath54 .",
    "other generative models may be considered in the literature .",
    "we find in @xcite the model : @xmath55 and in @xcite the model : @xmath56 .",
    "our goal is to unveil the variability _ of shapes in @xmath23 _ while we in fact observe the noisy _ objects @xmath13 s in @xmath14_. first , we focus on the case where the variability in the shape space is assumed to be a dirac at @xmath50 ( step 1 of generative model ) .",
    "our goal is thus to estimate the template shape @xmath50 .",
    "one may consider the maximum likelihood estimate of @xmath50 : @xmath57 we have hidden variables , the @xmath20 s .",
    "the expectation - maximization ( em ) algorithm would be the natural implementation for computing the ml estimator . but the em algorithm is computationally expensive , above all for tridimensional images .",
    "thus , one usually relies on another procedure that is an approximation of the em .",
    "@xcite .",
    "[ [ estimating - the - template - shape - with - the - frchet - mean - in - the - shape - space ] ] estimating the template shape with the frchet mean in the shape space + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    one initializes the estimate with @xmath58 .",
    "then , one iterates the following two steps until convergence : @xmath59 ( 1 ) is an estimation of the hidden observations @xmath51 and an approximation of the e - step of the em algorithm .",
    "( 2 ) is the m - step of the em algorithm : the maximization of the surrogate in the m - step amounts to the maximization of the variance of the projected data .",
    "this is exactly the minimization of the squared distances to the data of ( 2 ) .",
    "the procedure converges because it decreases at each step a cost bounded below by zero .",
    "the estimator computed with this procedure is : @xmath60 the term @xmath61 in equation  [ eq : frechet ] is the distance in the shape space between the shapes of @xmath50 and @xmath13 .",
    "thus , we recognize in equation  [ eq : frechet ] the frchet mean on the shape space .",
    "the frchet mean is a definition of mean on manifolds @xcite : it is the point that minimizes the squared distances to the data in the shape space .",
    "all in all , one projects the probability distribution function of the @xmath13 s from @xmath14 to @xmath39 and computes its `` expectation '' , in a sense made precise later .",
    "we illustrate the procedure with the examples of the plane and the sphere .",
    "we take @xmath28 , @xmath29 , @xmath62 three objects in @xmath6 in figure  [ fig : estimator ] ( a ) and on @xmath9 in figure  [ fig : estimator ] ( b ) .",
    "step ( 1 ) is the registration / alignment step .",
    "one filters out the position / parameterization component , i.e. the coordinate on the orbit .",
    "one projects the objects @xmath28 , @xmath29 , @xmath62 in the shape space @xmath24 using the blue arrows .",
    "step ( 2 ) is the computation of the frchet mean of the registered data .",
    "we implemented the generative model and the estimation procedure on the plane and the sphere in shiny applications available online : https://nmiolane.shinyapps.io/shinyplane and https://nmiolane.shinyapps.io/shinysphere .",
    "we invite the reader to look at the web pages and play with the different parameters of the generative model .",
    "figure  [ fig : shinyplane1 ] shows screen shots of the applications .",
    "[ fig : shinyplane1 ]    our main result is to show that this procedure gives an inconsistent estimate of the template shape @xmath50 of the generative model .",
    "the estimator @xmath63 converges when the number of data goes to infinity .",
    "however it has an asymptotic bias with respect to the parameter @xmath50 it is designed to estimate : @xmath64 $ ] .",
    "this is a vector at the tangent space of @xmath39 at the real parameter @xmath50 .",
    "the vector represents how much one has to shoot from @xmath50 to get the estimated parameter @xmath63 .",
    "it simply writes @xmath65 $ ] for linear spaces .",
    "we could also consider the variance of the estimator .",
    "the variance is defined as @xmath66)^2]$ ] . in the limit of an infinite sample , we have : @xmath67 .",
    "this is why we focus on the asymptotic bias .",
    "we first compute the asymptotic bias for the examples of the plane and the sphere to give the intuition .",
    "the probability distribution function of the @xmath13 s comes from the generative model .",
    "this is a probability distribution on @xmath6 for the plane example , parameterized in polar coordinates @xmath7 like figure  [ fig : simple ] .",
    "so we can compute the projected distribution function on the shapes , which are the radii @xmath8 here .",
    "this is done simply by integrating out the distribution on @xmath11 , the position on the circles .",
    "this gives a probability distribution on @xmath37 for the plane example .",
    "we write it @xmath68 .",
    "we remark that @xmath69 does not depend on the probability distribution function on the @xmath70 s of step 2 of the generative model .",
    "we can also compute @xmath71 in the sphere example : we integrate over @xmath72 the probability distribution function on @xmath73 .    figure  [ fig : pdfs ] ( a ) shows @xmath69 for the plane example , for a template @xmath74 .",
    "we plot it for two different noise levels @xmath75 and @xmath76 .",
    "note that here @xmath69 is the rice distribution .",
    "figure  [ fig : pdfs ] ( b ) shows @xmath69 for the sphere example , for a template @xmath77 .",
    "we plot it for different noise levels and @xmath75 and @xmath76 . in both cases",
    ", the x - axis represents the shape space which is @xmath37 for the plane example and @xmath78 $ ] for the sphere example .",
    "the green vertical bar represents the template shape , which is 1 in both cases .",
    "the red vertical bar is the expectation of @xmath69 in each case .",
    "it is @xmath63 , the estimate of @xmath50 we see on these plots that @xmath69 is not centered at the template shape : the green and red bars do not coincide .",
    "@xmath69 is skewed away from 0 in the plane example and away from @xmath36 and @xmath79 in the sphere example .",
    "the skew increases with the noise level @xmath0 .",
    "the difference between the green and red bars is precisely the bias of @xmath63 with respect to @xmath50 .",
    "figure  [ fig : bias ] shows the bias of @xmath63 with respect to @xmath50 , as a function of @xmath0 , for the plane ( left ) and the sphere ( right ) .",
    "increasing the noise level @xmath0 takes the estimate @xmath63 away from @xmath50 .",
    "the estimate is repulsed from @xmath36 in the plane example : it goes to @xmath80 when @xmath81 .",
    "it is repulsed from @xmath36 and @xmath79 in the sphere example : it goes to @xmath82 when @xmath83 .",
    "one can show numerically that the bias varies as @xmath84 around @xmath85 in both cases .",
    "this is also observed on the shiny applications @xcite at https://nmiolane.shinyapps.io/shinyplane and https://nmiolane.shinyapps.io/shinysphere .",
    "these examples already show the origin of the asymptotic bias of @xmath63 . _",
    "the bias comes from the curvature of the template s orbit .",
    "_ figure  [ fig : curvature ] shows the template s orbit in blue , in ( a ) for the plane and ( b ) for the sphere . in both cases",
    "the black circle represents the level set @xmath0 of the gaussian noise .",
    "the probability of generating an observation @xmath13 outside of the template s shape orbit is bigger than the probability of generating it inside : the grey area in the black circle is bigger than the white area in the white circle .",
    "there will be more registered data that are greater than the template .",
    "their expected will therefore be greater than the template and thus biased .",
    "we prove this in the general case in the next section .",
    "we show the asymptotic bias of @xmath63 in the general case and prove that it comes from the external curvature of the template s orbit . we show it for @xmath50 a principal shape and for a gaussian noise of variance @xmath84 , truncated at @xmath86 .",
    "our results will need the following definitions of curvature .",
    "the _ second fundamental form @xmath87 _ of a submanifold @xmath88 of @xmath14 is defined on @xmath89 by @xmath90 , where @xmath91 denotes the orthogonal projection of covariant derivative @xmath92 onto the normal bundle .",
    "mean curvature vector @xmath93 of @xmath88 _ is defined as : @xmath94 . intuitively , @xmath87 and @xmath93 are measures of extrinsic curvature of @xmath88 in @xmath14 .",
    "for example an hypersphere of radius @xmath95 in @xmath2 has mean curvature vector @xmath96 .",
    "[ th : pdf ] the probability distribution function on the shapes induced by the generative model is : @xmath97 here @xmath98 is the riemannian logarithm @xmath99 $ ] of the shape @xmath100 $ ] at the template shape @xmath50 , @xmath87 is the second fundamental form of the orbit of @xmath98 , @xmath95 is the ricci curvature , @xmath101 are constants independent of @xmath98 and @xmath0 .",
    "the proof is given in appendix  [ app : proofpdf ] .    the exponential in the expression of @xmath69 belongs to a gaussian distribution centered at @xmath102 .",
    "this is a riemannian gaussian centered at the template shape @xmath50 , because @xmath98 are coordinates at the tangent space of @xmath39 at @xmath50 .",
    "however the whole distribution @xmath69 differs from the gaussian because of the @xmath98-dependent term in the right parenthesis .",
    "this induces a skew of the distribution away from the singular shapes , as observed for the examples in figure  [ fig : pdfs ] .",
    "[ th : bias ] the asymptotic bias of the template s shape estimation writes : @xmath103 here @xmath93 is the mean curvature vector of the template shape s orbit and @xmath84 the variance of the noise on the objects .    the proof is given in appendix  [ app : proofbias ] .",
    "this generalizes the quadratic behavior observed in the examples on figure  [ fig : bias ] .",
    "the asymptotic bias has a geometric origin : it comes from the external curvature of the template s orbits , see figure  [ fig : curvature ] .",
    "we can vary two parameters in equation  [ eq : bias ] : @xmath50 and @xmath0 .",
    "the external curvature of orbits generally increases when @xmath50 is closer to a singularity of the shape space ( see section 1 ) @xcite .",
    "the singular shape of the two landmarks in @xmath6 arises when their distance is 0 . in this case",
    ", the mean curvature vector is @xmath104 : it is inversely proportional to @xmath105 , the radius of the orbit .",
    "@xmath105 is also the distance of @xmath50 to the singularity @xmath36 .",
    "[ [ beyond - y - being - a - principal - shape ] ] beyond @xmath50 being a principal shape + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    our results are valid when the template @xmath50 is a principal shape .",
    "this is a reasonable assumption as the set of principal shapes is dense in the shape space .",
    "what happens when @xmath50 approaches a singularity , i.e. when @xmath50 changes stratum in the stratified space @xmath24 ?",
    "taking the limit @xmath106 in the coefficients of the taylor expansion is not a legal operation .",
    "therefore , we can not conclude on the taylor expansion of the bias for @xmath106 .",
    "indeed , the taylor expansion may even change order for @xmath106 .",
    "we take @xmath107 with the action of @xmath108 and the template @xmath109 : @xmath110 the bias is linear in @xmath0 in this case .",
    "[ [ beyond - sigma-1 ] ] beyond @xmath111 +",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    the assumption @xmath111 is reasonable as we hope that the noise on the data is not too large",
    ". nevertheless it would be very interesting to study the asymptotic bias for any @xmath0 , including large noises ( @xmath112 ) .",
    "the distribution over the @xmath13 s in @xmath14 will be spread on the whole manifold @xmath14 .",
    "we can not rely on local computations on @xmath14 ( at the scale of @xmath0 ) anymore .",
    "we have to make global assumptions on the manifold @xmath14 .",
    "the plane example is the canonical example of a flat manifold .",
    "the sphere example is the canonical example of manifold with constant ( positive ) curvature .",
    "the bias as a function of @xmath0 is plotted in figure  [ fig : bias ] .",
    "it leads us to the conjecture that the estimate converges towards a barycenter of shape space s singularities when the noise level increases .",
    "singularities have a repulsive action on the estimation of each template s shape .",
    "such repulsive force acts on each estimators . as a result ,",
    "the estimators of the mean shape finds an equilibrium position : the barycenter .",
    "[ [ beyond - one - dirac - in - q - several - templates ] ] beyond one dirac in @xmath24 : several templates + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    we have considered so far that there is a unique template shape @xmath50 : the generative model has a dirac distribution at @xmath50 in the shape space .",
    "what happens for other distributions ?",
    "we assume that there are @xmath113 template shapes @xmath114 .",
    "observations are generated in @xmath14 from each template shape @xmath115 with the generative model of section 2 .",
    "our goal is to unveil the structure of the shape distribution , i.e. the @xmath113 template shapes here , given the observations in @xmath14 .",
    "the distributions on shapes projected on the shape space is a mixture of probability density functions of the form of equation  [ eq : f ] .",
    "its modes are related to the template shapes .",
    "the k - means algorithm is a very popular method for data clustering .",
    "we study what happens if one uses k - means algorithms on shapes generated with the generative model above .    the goal is to cluster the shape data in @xmath113 distinct and significant groups .",
    "one performs a coordinate descent algorithm on the following function : @xmath116 in other words , one minimizes @xmath117 by successively minimizing on the assignment labels @xmath118 s and the cluster s centers @xmath119 s .",
    "given the @xmath118 , minimizing @xmath117 with respect to the @xmath119 s is exactly the simultaneous computation of @xmath113 frchet means in the shape space .",
    "one looks for meaningful well separated clusters ( high inter - clusters dissimilarity ) whose members are close to each other ( high intra - cluster similarity ) . in other words ,",
    "the quality of the clustering is evaluated by the following criterion : @xmath120 which is the dissimilarity between clusters quotiented by the diameter of the clusters . in the absence of singularity in the shape space",
    ", the projected distribution looks like figure  [ fig : kmeans ] ( a ) and @xmath121 . the criterion is worse in the presence of singularities .",
    "figure  [ fig : kmeans ] illustrates this behavior for the plane example .",
    "we consider any two clusters @xmath122 and call @xmath123 , @xmath124 the estimated centroids .",
    "the criterion @xmath125 writes : @xmath126 even in the best case with correct assignments to the clusters @xmath127 and @xmath128 , the k - means algorithm looses an order of validation when computed on shapes .",
    "[ [ beyond - the - finite - dimensional - case ] ] beyond the finite dimensional case + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    our results are valid when @xmath14 is a finite dimensional manifold and @xmath18 a finite dimensional lie group .",
    "some interesting examples belong to the framework of infinite dimensional manifold with infinite dimensional lie groups .",
    "this is the case for the lddmm framework on images @xcite",
    ". it would be important to extend these results to the infinite dimensional case .",
    "we take @xmath107 with the action of @xmath108 .",
    "we have a analytic expression of @xmath69 in this case @xcite .",
    "figure  [ fig : finitedims ] shows the influence of the dimension @xmath129 for the probability distribution functions on the shape space and for the bias .",
    "the bias increases with @xmath129 .",
    "this leads to think that it appears in infinite dimensions as well .",
    "we propose two procedures to correct the asymptotic bias on the template s estimate .",
    "they rely on the bootstrap principle @xcite , more precisely a parametric bootstrap . as such , they are directly applicable to any type of data .",
    "we assume that we know the variance @xmath130 from the experimental setting .      the first procedure is called iterative bootstrap .",
    "algorithm  [ alg : iterative ] details it .",
    "figure  [ fig : iterativebootstrap ] illustrates it on the plane example .",
    "algorithm  [ alg : iterative ] starts with the usual template s estimate @xmath131 , see figure  [ fig : iterativebootstrap ] ( a ) . at each iteration , we correct @xmath63 with a better approximation of the bias .",
    "first , we generate bootstrap data by using @xmath63 as the template shape of the generative model .",
    "we perform the template s estimation procedure with the frchet mean in the shape space .",
    "this gives an estimate @xmath132 of @xmath133 .",
    "the bias of @xmath134 with respect to @xmath133 is @xmath135 .",
    "it gives an approximation of the bias @xmath136 , see figure  [ fig : iterativebootstrap ] ( b ) .",
    "we correct @xmath63 by this approximation of the bias .",
    "this gives a new estimate @xmath137 , see figure  [ fig : iterativebootstrap ] ( c ) .",
    "we recall that the bias @xmath136 depends on @xmath50 , see theorem [ th : bias ] .",
    "@xmath137 is closer to the template @xmath50 than @xmath133 .",
    "thus , the next iteration gives a better approximation @xmath138 of @xmath136 .",
    "we correct the initial @xmath63 with this better approximation of the bias , etc .",
    "the procedure is written formally for a general manifold @xmath14 in algorithm [ alg : iterative ] .",
    "[ alg : iterative ]    * input : * objects @xmath12 , noise variance @xmath84 + * initialization : * + @xmath139\\}_{i=1}^n)$ ] + @xmath140 + * repeat : * + generate bootstrap sample @xmath141 from @xmath142 + @xmath143_i\\}_{i=1}^n)$ ] + @xmath144 + @xmath145 + @xmath146 + * until convergence : * @xmath147 + * output : @xmath148 *    in algorithm  [ alg : iterative ] , @xmath149 denotes the parallel transport from @xmath150 to @xmath151 . for linear spaces , @xmath152 , @xmath153 , @xmath154 .",
    "algorithm  [ alg : iterative ] is a fixed - point iteration @xmath155 where : @xmath156 in a linear setting we have simply @xmath157 .",
    "one can show that @xmath158 is a contraction and that @xmath50 , the template shape , is the unique fixed point of @xmath158 ( using the local bijectivity of the riemannian exponential and the injectivity of the estimation procedure ) .",
    "thus the procedure converges to @xmath50 in the case of an infinite number of observations @xmath159 .",
    "figure  [ fig : iterativebootstrap_fixedpoint ] illustrates the convergence for the plane example , with a gaussian noise of standard deviation @xmath160 .",
    "the template shape @xmath161 was initially estimated at @xmath162 .",
    "algorithm  [ alg : iterative ] corrects the bias .",
    "figures  [ fig : iterationsplane ] and  [ fig : iterationssphere ] show the iterations of iterative bootstrap for the plane and the sphere example .      the second procedure is called the nested bootstrap .",
    "algorithm  [ alg : nested ] details it .",
    "figure  [ fig : nestedbootstrap ] illustrates it on the plane example .",
    "algorithm  [ alg : nested ] starts like algorithm  [ alg : iterative ] with @xmath163 , see figure  [ fig : nestedbootstrap ] ( a ) .",
    "it also performs a parametric bootstrap with @xmath164 as the template , computes the bootstrap replication @xmath165 and the approximation @xmath166 of @xmath167 , see figure  [ fig : iterativebootstrap ] ( b ) .",
    "now algorithm  [ alg : nested ] differs from algorithm  [ alg : iterative ] .",
    "we want to know how biased is @xmath166 as an estimate of @xmath167 ? this is a valid question as the bias depends on the template @xmath50 , see theorem  [ th : bias ] .",
    "we want to estimate this dependence .",
    "we perform a bootstrap , nested in the first one , with @xmath168 as the template .",
    "we compute the estimate @xmath169 and the approximation @xmath170 of @xmath166 , see figure  [ fig : iterativebootstrap ] ( c ) .",
    "we observe how far @xmath170 is from @xmath166 .",
    "this gives the blue arrow , which is the bias of @xmath170 as an estimate of @xmath166 , see figure  [ fig : iterativebootstrap ] ( d ) .",
    "the blue arrow is an approximation of how far @xmath166 is from @xmath167 .",
    "we correct our estimation of the bias ( in red ) by the blue arrow .",
    "we correct @xmath171 by the bias - corrected estimate of its bias , see figure  [ fig : iterativebootstrap ] ( e ) .",
    "[ alg : nested ]    * input : * objects @xmath12 , noise variance @xmath84 + * initialization : * + @xmath139\\}_{i=1}^n)$ ] + * bootstrap : * + generate bootstrap sample @xmath172 from @xmath173 + @xmath174_i\\}_{i=1}^n)$ ] + @xmath175 + * nested bootstrap : * + for each @xmath127 :    * generate bootstrap sample @xmath176 from @xmath177 * @xmath178_i\\}_{k=1}^n)$ ]    @xmath179 + @xmath180 + * output : @xmath137 *      one may use the iterative bootstrap or the nested bootstrap depending on the experimental setting .",
    "we illustrate them both on the plane example in figure  [ fig : comparison ] .",
    "the advantages of the iterative bootstrap are the following .",
    "it corrects perfectly the bias of @xmath63 in the case of a very large number of observations @xmath181 .",
    "it can be used to experimentally compute the mean curvature vector @xmath93 of each orbit of a group action .",
    "one probes the orbit s curvature by `` feeling it '' with a riemannian gaussian on @xmath14 and projecting on the shape space .",
    "its drawbacks are the following .",
    "it works only with very large @xmath181 .",
    "it is not robust as it uses the generative model several times .",
    "if the generative model is far from being true , then the iterative bootstrap fails .",
    "the advantages of the nested bootstrap are the following .",
    "it is a standard statistical procedure that is more robust with respect to variations of the generative model .",
    "even if generative model is different from the one that we assume , the nested bootstrap performs well .",
    "moreover , it does not need as many data as the iterative bootstrap .",
    "its drawback is that it does not correct perfectly the bias , especially when the noise is important .",
    "these simulations give a rule of thumb for when the bias needs to be corrected .",
    "this is when the noise @xmath0 is comparable to the distance of the template @xmath50 to the singularity .",
    "we perform a simulation using the iterative bootstrap on triangles .",
    "we randomly generate @xmath182 triangles in @xmath6 .",
    "the mean triangle is chosen by taking two coordinates randomly from a uniform distribution on @xmath183 $ ]",
    ". then we add bivariate gaussian noise on each landmark .",
    "these experiments are illustrated in figure  [ fig : iterationstriangles ] .",
    "the number of iterations required for the convergence of algorithm 1 with respect to the noise level are shown in figure  [ fig : iterationstriangles ] .",
    "we observe the convergence in the three experiments for less than 10 iterations .",
    "now we go to real triangle data .",
    "we have 24 images of rhesus monkeys eyes , acquired with a heidelberg retina tomograph @xcite . for each monkey ,",
    "an experimental glaucoma was introduced in one eye , while the second eye was kept as control .",
    "one seeks a significant difference between the glaucoma and the control eyes . on each image ,",
    "three anatomical landmarks were recorded : @xmath184 for the superior aspect of the retina , @xmath185 for the nose side of the retina , and @xmath186 for the side of the retina closest to the temporal bone of the skull .",
    "the data are matrices @xmath12 where the landmark coordinates form the rows . for the onh example , @xmath14 is the space of @xmath187 landmarks in 3d , @xmath188 and the rotations act isometrically on each object @xmath13 .",
    "* analysis * this simple example illustrates the estimation of the template shape .",
    "we use the following procedure to compute the mean shape for each group .",
    "we initialize @xmath63 with @xmath28 and repeat the following two steps until convergence : @xmath189 figure  [ fig : onh ] shows the mean shapes @xmath190 of the control group ( left ) and @xmath191 of the glaucoma group ( right ) in orange , while the initial data are in grey . the difference between the two groups is quantified by the distance between their means : @xmath192 m .",
    "we want to determine if this analysis presents an bias that significantly changes the estimated shape difference between the groups .",
    "we use the nested bootstrap to compute an approximation of the asymptotic bias on each mean shape , for a range of noise s standard deviation in @xmath193 .",
    "the asymptotic bias on the template shape of the glaucoma group is @xmath194 @xmath195 and of the control group is @xmath196 .",
    "the corrected template shape differences are @xmath197 .",
    "in particular , for @xmath198 , we observe that the bias in the template shape are respectively @xmath199 for the healthy group and @xmath200 for the glaucoma group .",
    "this follows the rule - of - thumb : the bias is more important for the healthy group , for which the overall size is smaller than the glaucoma group , for a same noise level .",
    "the bias of the template shape estimate accounts for less than @xmath201 in this case , which is less than @xmath202% of the shapes sizes .",
    "this computation guarantees that this study has not been significantly affected by the bias .",
    "we estimate the impact of the bias on statistics on protein shapes .",
    "a standard hypothesis in biology is that structure ( i.e. shape ) and function of proteins are related .",
    "fundamental research questions about protein shapes include structure prediction - given the protein amino - acid sequence , one tries to predict its structure - and design - given the shape , one tries to predict the sequence needed .",
    "one relies on experimentally determined 3d structures gathered in the protein data base ( pdb ) @xcite .",
    "they contain errors on the protein s atoms coordinates .",
    "average errors range from 0.01 @xmath203 to 1.76 @xmath203 , which is of the magnitude of the length of some covalent bonds .",
    "these values are averaged over the whole protein and in general , the main - chain atoms are better defined than the side - chain atoms or the atoms at the periphery .",
    "this is illustrated on figure where we have plot the b - factor ( related to coordinates errors @xcite ) as a colored map on the atoms for proteins of pdb - codes 1h7w and 4hbb .        [ [ proteins - radius - of - gyration ] ] protein s radius of gyration + + + + + + + + + + + + + + + + + + + + + + + + + + + +    a biased estimate of a protein shape has consequences for studies on proteins folding .",
    "stability and folding speed of a protein depend on both the estimated shape of the denatured state ( unfolded state ) and of the native state ( folded state ) .",
    "one may study if compact initial states yield to faster folding .",
    "the protein compactness is represented by the protein s radius of gyration , defined as : @xmath204 , where @xmath185 is the number of non - hydrogen atoms , @xmath205 , @xmath206 are resp .",
    "the coordinates of atoms and centers and @xmath207 their mass .",
    "note that we assume ( as it is usually the case ) that all masses @xmath207 for non - hydrogen atoms are equal and that hydrogen atoms have mass @xmath36 .",
    "error on atoms coordinates give a bias on the estimate of the radius of gyration : @xmath208    the radius of protein hjsj ( 85 residues ) is known to be around 10 @xmath203 .",
    "the error on @xmath209 is of @xmath210% with an average error of positions on the atoms of @xmath211 .",
    "it is 8.6% for an error of @xmath212 .",
    "the error will be greater if one consider binding sites at the periphery of the proteins rather than the whole protein .",
    "indeed sites size is smaller and they have less atoms",
    ".    one could think about doing clustering on radii of gyration using the k - means algorithm on shapes .",
    "the index @xmath125 of section  [ sec : correction ] is : @xmath213 clustering on radii of gyration may lead to a misleading indicator .",
    "@xmath125 indicates that the clustering performs better that it actually does .",
    "[ [ false - positive - probability - in - proteins - motif - detection ] ] false positive probability in protein s motif detection + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    the relation between a protein s shape and function is linked to its motifs , which define the supersecondary structure .",
    "motifs have biological properties : for example the helix  turn ",
    "helix motif @xciteis responsible for the binding of dna within several prokaryotic proteins .",
    "automatic motif detection is another challenge in the study of protein shapes .",
    "we investigate the impact of bias on the false positive probability estimation in motif detection .",
    "let us consider a set @xmath214 of proteins each with @xmath215 atoms .",
    "one is interested in the motifs of @xmath1 atoms that can be detected in the protein s set , where @xmath216 .",
    "we define @xmath0 that represents an allowed error zone . the number of detected motifs increases if : ( i ) one decreases @xmath1 , or ( ii ) one increases @xmath0 , or ( iii ) increases @xmath181 .",
    "thus how many detected motifs actually come from chance , with respect to the parameters @xmath1 , @xmath0 , @xmath181 ?",
    "the false positives probability indicates when one detects truth and when one detects noise .",
    "the usual estimate of the false positive probability is @xmath217 .",
    "here @xmath218 is the volume of the error zone allowed .",
    "@xmath219 is the total volume of the protein @xcite , thus the a ball of radius the radius of gyration .",
    "thus @xmath219 may be biased and overestimated .",
    "the probability of false positive is underestimated .",
    "we consider the example of @xcite .",
    "one tries to find motifs between the tryptophan repressor of escherichia coli ( pdb code 2wrp ) and the cro protein of phage 434 ( pdb code 2cro ) .",
    "these two proteins are known to share the helix - turn - helix motif .",
    "the radius of gyration of 2wrp is @xmath220 , the total volume is : @xmath221 .",
    "we assume an error zone that takes the form of a diagonal covariance matrix with standard deviations @xmath222 .",
    "we get the error zone volume : @xmath223 and the estimation of the false positive probability : @xmath224 .",
    "we find that @xmath225 is underestimated by @xmath226 using the expression of the radius of gyration s bias .",
    "we apply the rule of thumb of section  [ sec : correction ] to determine when the bias needs a correction in the computation of a brain template from medical images . here",
    "@xmath14 and @xmath18 will be infinite dimensional .",
    "nevertheless we apply our results to get intuition for this application .    in neuroimaging ,",
    "a template is an image representing a reference anatomy .",
    "computing the template is often the first step in medical image processing .",
    "then , the subjects anatomical shapes may be characterized by their spatial deformations _ from the template_. these deformations may serve for ( i ) a statistical analysis of the subject shapes , or ( ii ) for automated segmentation by mapping the template s segmented regions into the subject spaces . in both cases , if the template is not centered among the population , i.e. if it is biased , then the analyzes and conclusions could be biased .",
    "we are interested in highlighting the variables that control the template s bias .",
    "the framework of large deformation diffeomorphic metric mapping ( lddmm ) @xcite embeds the template estimation in our geometric setting .",
    "the lie group of diffeomorphisms acts on the space of images as follows : @xmath227 the isotropy group of @xmath228 writes : @xmath229 .",
    "its lie algebra @xmath230 consists of the infinitesimal transformations whose vector fields are parallel to the level sets of @xmath228 : @xmath231 .",
    "the orbit of @xmath228 is : @xmath232 .",
    "the `` shape space '' is by definition the space of orbits .",
    "two images that are diffeomorphic deformations of one another are in the same orbit .",
    "they correspond to the same point in the shape space .",
    "topology of an image is defined as the image s properties that are invariant by diffeomorphisms .",
    "consequently , the shape space is the space of the images topology , represented by the topology of their level sets .",
    "we get a stratification of the shape space when we gather the orbits by orbit type .",
    "a stratum is more singular than another , if it has higher orbit type , i.e. larger isotropy group .",
    "the manifold @xmath14 has an infinite stratification .",
    "one changes stratum every time there is a change in the topology of an image s level sets .",
    "singular strata are toward simpler topology .",
    "`` principal '' strata are toward a more complicated topology .",
    "indeed , the simpler the topology of the level sets is , the higher is the `` symmetry '' of the image .",
    "thus the larger is its isotropy group .",
    "note that strata with smaller isotropy group ( more detailed topology ) do not represent `` singularities '' from the point of view of a given image and do not influence the bias .",
    "in fact , such strata are at distance 0 : an infinitesimal local change in intensity can create a maximum or minimum , thus complexifying the topology .    using the rule - of - thumb of section",
    "[ sec : correction ] , the template s bias depends on its distance @xmath105 to the next singularity , at the scale of @xmath0 the intersubjects variability .",
    "the template is biased in the regions where the difference in intensity between maxima and minima is of the same amplitude as the variability .",
    "the template may converge to pure noise in these regions .",
    "we introduced tools of statistics on manifolds to study the properties of template s shape estimation in medical imaging and computer vision .",
    "we have shown its asymptotic bias by considering the shape space s geometry .",
    "the bias comes from the external curvature of the template s orbit at the scale of the noise on the data .",
    "this provides a geometric interpretation for the bias observed in @xcite .",
    "we investigated the case of several templates and the performance k - mean algorithms on shapes : clusters are less well separated because of each centroid s bias .",
    "the variables controlling the bias are : ( i ) the distance in shape space from the template to a singular shape and ( ii ) the noise s scale .",
    "this gives a rule - of - thumb for determining when the bias is important and needs correction .",
    "we proposed two procedures for correcting the bias : an iterative bootstrap and a nested bootstrap .",
    "these procedures can be applied to any type of shape data : landmarks , curves , images , etc .",
    "they also provide a way to compute the external curvature of an orbit .",
    "our results are exemplified on simulated and real data .",
    "many studies use the template s shape estimation algorithm in molecular biology , medical imaging or computer vision .",
    "their estimations are necessarily biased . but these studies often belong to a regime where the bias is not important ( less than @xmath233 ) .",
    "for example , the bias is important in landmark shapes analyses when the landmarks noise is comparable to the template shape s size .",
    "studies are rarely in this regime .",
    "we have considered shapes belonging to infinite dimensional shape spaces .",
    "our results do not apply to the infinite dimensional case .",
    "we have used them to gain intuition about it .",
    "the bias might be more important in infinite dimensions and need the correction we have suggested .",
    "biblabel[1]#1 .    10    , _ the riemannian geometry of orbit spaces . the metric , geodesics , and integrable systems _ , publ",
    "debrecen , 62 ( 2003 ) .    , _ towards a coherent statistical framework for dense deformable template estimation _ , journal of the royal statistical society . , 69 ( 2007 ) ,",
    "329 .    , _ estimating the template in the total space with the frchet mean on quotient spaces may have a bias .",
    "_ , proceedings of the fifth international workshop on mathematical foundations of computational anatomy ( mfca15 ) , 2015 , pp .  131142 .    ,",
    "_ convergent stochastic expectation maximization algorithm with efficient sampling in high dimension .",
    "application to deformable template model estimation _ , computational statistics & data analysis , 91 ( 2015 ) , pp .  4  19 .    , _ the protein data bank _ , nucleic acids res , 28 ( 2000 ) , pp .",
    "235242 .",
    ", _ on the consistency of frchet means in deformable models for curve and image analysis _ , electronic journal of statistics , ( 2011 ) , pp .",
    "10541089 .    , _ a deconvolution approach to estimation of a common shape in a shifted curves model _ , ann",
    ", 38 ( 2010 ) , pp .",
    "24222464 .    ,",
    "_ the helix - turn - helix dna binding motif .",
    "_ , journal of biological chemistry , 264 ( 1989 ) , pp .  19036 .    , _ analyse biomtrique de lanneau pelvien en 3 dimensions ",
    " propos de 100 scanners _ ,",
    "revue de chirurgie orthopdique et traumatologique , 100 ( 2014 ) , pp .",
    "s241 .    , _ statistical shape analysis _ , john wiley & sons , new york , 1998 .    , _",
    "bootstrap methods : another look at the jackknife _ , the annals of statistics , 7 ( 1979 ) , pp .  126 .    , _ morphometrics for nonmorphometricians _ , springer , 2012 .    , _ brain templates and atlases _ , neuroimage , 62(2 ) ( 2012 ) , pp",
    ".  911922 .",
    ", _ intrinsic shape analysis : geodesic principal component analysis for riemannian manifolds modulo lie group actions . _ , statistica sinica , 20 ( 2010 ) , pp .",
    "1100 .    , _ riemannian structures on shape spaces : a framework for statistical inferences _ , in statistics and analysis of shapes , 2006 , pp .  313333 .    ,",
    "_ the diffusion of shape _ , advances in applied probability , 9 ( 1977 ) , pp .",
    "428430 .",
    ", _ shape manifolds , procrustean metrics , and complex projective spaces _ , bulletin of the london mathematical society , 16 ( 1984 ) , pp",
    ".  81121 .    , _",
    "signal estimation under random time - warpings and nonlinear signal alignment _ , in advances in neural information processing systems 24 , 2011 , pp",
    ".  675683 .    , _ the riemannian structure of euclidean shape spaces : a novel environment for statistics _ , the annals of statistics , 21 ( 1993 ) , pp .",
    "12251271 .    ,",
    "_ euclidean distance matrix analysis ( edma ) : estimation of mean form and mean form difference _ , mathematical geology , 25 ( 1993 ) , pp .",
    "573602 .    .    ,",
    "_ mapping the effects of a@xmath234 levels on the longitudinal changes in healthy aging : hierarchical modeling based on stationary velocity fields _ , in proceedings of medical image computing and computer assisted intervention ( miccai ) , vol .",
    "6892 of lncs , springer , 2011 , pp .",
    "663670 .    , _ curvature explosion in quotients and applications _ , j. differential geom",
    ". , 85 ( 2010 ) , pp .  117140 .    , _ biased estimators on quotient spaces _ , proceedings of the 2nd international of geometric science of information ( gsi2015 ) , ( 2015 ) .    , _ nonparametric statistics on manifolds and their applications to object data analysis _ , taylor & francis group , 2016 .    , _ toward a generic framework for recognition based on uncertain geometric features _ ,",
    "videre : journal of computer vision research , 1 ( 1998 ) , pp .",
    "5887 .    , _ intrinsic statistics on riemannian manifolds : basic tools for geometric measurements _ , journal of mathematical imaging and vision , 25 ( 2006 ) , pp .  127154",
    ", _ a geometric algorithm to find small but highly similar 3d substructures in proteins .",
    "_ , bioinformatics , 14 ( 1998 ) , pp .  516522 .    ,",
    "_ riemannian geometry",
    "_ , encyclopaedia of mathem .",
    "sciences , springer , 2001 .    , _ easy web applications in r. _ , 2013 .",
    "url : http://www.rstudio.com / shiny/.    , _ error estimates of protein structure coordinates and deviations from standard geometry by full - matrix refinement of * @xmath235*b- and * @xmath236*b2-crystallin _ , acta crystallographica section d , 54 ( 1998 ) , pp .",
    "243252 .    ,",
    "_ shapes and diffeomorphisms _ , applied mathematical sciences , springer london , limited , 2012 .",
    "here @xmath21 is a point in @xmath14 .",
    "we consider that @xmath21 belongs to a principal orbit @xmath237 .",
    "this will have no impact on the integration because the set of principal orbits is dense in @xmath14 .",
    "we write @xmath238 the projection of @xmath21 in the shape space .",
    "we write the template shape @xmath50 .",
    "we write its estimate @xmath63 .",
    "we take a normal coordinate system centered at the template @xmath50 .",
    "we have the decomposition @xmath239 , where @xmath88 is the orbit of @xmath50 .",
    "we note that @xmath240 , so that @xmath241 are _ not _ the coordinates of @xmath238 in the normal coordinate system at @xmath50 , see figure  [ fig : notations ] .",
    "we denote @xmath129 the dimension of @xmath14 , @xmath46 the dimension of the principal orbits and @xmath242 the dimension of the quotient space .",
    "we write coordinates in @xmath24 with indices @xmath243 $ ] and coordinates in an orbit with indices @xmath244 $ ] .",
    "the generative model implies the following riemannian normal distribution on the objects : @xmath245 the distance @xmath246 expressed in the normal coordinate system at @xmath50 is simply @xmath247 . the riemannian measure @xmath248 at @xmath21 in the normal coordinate system at @xmath50 has the taylor expansion : @xmath249 .",
    "we recognize the riemannian curvature tensor @xmath95 .",
    "we truncate the riemannian gaussian : @xmath250 where @xmath184 is the normalization coefficient coming of the univariate truncated gaussian at @xmath251 .",
    "@xmath252 , @xmath253 and @xmath254 refer to geodesic balls of radius @xmath255 in their respective spaces .",
    "we denote @xmath256 and remark that @xmath257 where @xmath242 is the dimension of the quotient space and @xmath46 the dimension of the principal orbits .",
    "we represent @xmath88 in @xmath260 as the graph of a smooth function from @xmath261 to @xmath262 , around @xmath263 by : @xmath264 the local graph @xmath18 is : @xmath265 .",
    "its 0-th and 1-th order derivatives are zero because the graph goes through @xmath238 and is tangent at @xmath266 .",
    "its second order derivative is @xmath267 and represents the best quadratic approximation of the graph .",
    "we need the coordinate of @xmath238 in the ncs at @xmath50 . we parallel transport @xmath270 from @xmath268 to @xmath50 : @xmath271 .",
    "the @xmath36-th order term of the parallel transport at @xmath268 in a ncs at @xmath50 is 0 : @xmath272 this concludes .",
    "we take an ncs at @xmath50 .",
    "we denote @xmath98 the coordinate of @xmath238 in the shape space .",
    "we compute the induced probability distribution @xmath69 on shapes by integrating the distribution on the orbit of @xmath21 out of @xmath273 : @xmath274 the point @xmath21 has coordinates @xmath275 where @xmath276 is the integration coordinate .",
    "@xmath277      the lie group action is isometric so the riemannian metric splits onto @xmath280 at any point .",
    "moreover , the taylor expansion of the metric around @xmath21 still respects the splitting at the third order .",
    "the measure @xmath281 for @xmath276 close enough to @xmath21 is the restriction of this taylor expansion to the orbit .",
    "we have : @xmath282 so that : @xmath283 where @xmath95 is the ricci curvature .      for the last term ( 3 ) , we assume again that the graph of the orbit is smooth enough so that it admits a taylor serie at @xmath263 , ie : @xmath286 . by plugging this , we get the moments with the same manipulation as in the proof of theorem 1",
    ". as the moments of order @xmath187 ( and of odd order ) are zero : @xmath287 .",
    "we want to compute the systematic bias .",
    "to this aim , we compute the mean of the distribution of shapes in @xmath24 , in a coordinate system centered at the real @xmath50 .",
    "it writes : @xmath289 the coordinates of @xmath21 in the euclidean coordinate system at @xmath50 are simply @xmath290 .",
    "thus @xmath291 . from the lemma",
    "above : @xmath292        we denote ( 1 ) the first term of the sum and ( 2 ) the second term of the sum .",
    "we compute them independently .",
    "@xmath296 where the last line comes from the definitions of the moments of the truncated gaussian .",
    "we perform a taylor expansion under the integration , in @xmath0 , using the chain rule : @xmath303 again , the terms in @xmath304 integrate to 0 .",
    "we have : @xmath305 the term @xmath306 is precisely the normalization constant of the truncated gaussian @xmath307 , so that : @xmath308    the coefficient @xmath309 comes from the fact that we have truncated the gaussian .",
    "its expression is independent of @xmath0 because we have truncated at a multiple of @xmath0 .",
    "now we show that the second term ( 2 ) is of order @xmath310 .",
    "we assume that the local graph of the orbit is smooth enough so that it has a multivariate taylor serie : @xmath286 .",
    "we have : @xmath312 here the @xmath313 depend on @xmath241 .",
    "we first perform a majoration on each on them by a @xmath314 ( integration on a compact ball ) .",
    "@xmath315 we compute : @xmath316 so that : @xmath317 where we recognize the moment of the truncated gaussian , which are non zero only for even power .",
    "this gives : @xmath318 ."
  ],
  "abstract_text": [
    "<S> we use tools from geometric statistics to analyze the usual estimation procedure of a template shape . </S>",
    "<S> this applies to shapes from landmarks , curves , surfaces , images etc . </S>",
    "<S> we demonstrate the asymptotic bias of the template shape estimation using the stratified geometry of the shape space . </S>",
    "<S> we give a taylor expansion of the bias with respect to a parameter @xmath0 describing the measurement error on the data . </S>",
    "<S> we propose two bootstrap procedures that quantify the bias and correct it , if needed . </S>",
    "<S> they are applicable for any type of shape data . </S>",
    "<S> we give a rule of thumb to provide intuition on whether the bias has to be corrected . </S>",
    "<S> this exhibits the parameters that control the bias magnitude . </S>",
    "<S> we illustrate our results on simulated and real shape data .    </S>",
    "<S> shape , template , quotient space , manifold </S>"
  ]
}