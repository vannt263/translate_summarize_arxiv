{
  "article_text": [
    "description logics ( dls ) are a well - known family of knowledge representation formalisms  @xcite .",
    "they are based on the notion of concepts ( unary predicates , classes ) and roles ( binary relations ) , and are mainly characterised by constructors that allow complex concepts and roles to be built from atomic ones .",
    "sound and complete algorithms for the interesting inference problems such as subsumption and satisfiability of concepts are known for a wide variety of dls .",
    "transitive and inverse roles play an important role not only in the adequate representation of complex , aggregated objects  @xcite , but also for reasoning with conceptual data models  @xcite . moreover , defining concepts using general concept inclusion axioms seems natural and is crucial for representing conceptual data models .    the relevant inference problems for ( an extension of ) @xmath0augmented in the described manner are known to be decidable  @xcite , and worst - case optimal inference algorithms have been described  @xcite . however , to the best of our knowledge , nobody has found efficient means to deal with their high degree of non - determinism , which so far prohibits their use in realistic applications .",
    "this is mainly due to the fact that these algorithms can handle not only transitive roles but also the transitive closure of roles .",
    "it has been shown  @xcite that restricting the dl to transitive roles can lead to a lower complexity , and that transitive roles , even when combined with role hierarchies , allow for algorithms that behave quite well in realistic applications  @xcite . however , until now it has been unclear if this is still true when inverse roles are also present .    in this paper",
    "we present various aspects of our research in this direction .",
    "firstly , we motivate our use of logics with transitive roles instead of transitive closure by contrasting algorithms for several pairs of logics that differ only in the kind of transitivity supported .",
    "secondly , we present an algorithm that decides satisfiability of @xmath0extended with transitive and inverse roles , role hierarchies , and functional restrictions .",
    "this algorithm can also be used for checking satisfiability and subsumption with respect to general concept inclusion axioms ( and thus cyclic terminologies ) because these axioms can be `` internalised '' .",
    "the fact that our algorithm needs to deal only with transitive roles , instead of transitive closure , leads to a lower degree of non - determinism , and experiments indicate that the algorithm is well - suited for implementation .",
    "thirdly , we show that @xmath0extended with both transitive _ and _ inverse roles is still in pspace .",
    "the algorithm used to prove this result introduces an enhanced blocking technique that should also provide useful efficiency gains in implementations of more expressive dls .",
    "fourthly , we investigate the limits of decidability for this family of dls , showing that relaxing the constraints we will impose on the kind of roles allowed in number restrictions leads to the undecidability of all inference problems .    finally , we describe a range of optimisation techniques that can be used to produce implementations of our algorithms that exhibit good typical case performance .",
    "in this section , we present the syntax and semantics of the various dls that are investigated in subsequent sections .",
    "this includes the definition of inference problems ( concept subsumption and satisfiability , and both of these problems with respect to terminologies ) and how they are interrelated .",
    "the logics we will discuss are all based on an extension of the well known dl @xmath0",
    "@xcite to include transitively closed primitive roles  @xcite ; we will call this logic @xmath1due to its relationship with the propositional ( multi ) modal logic @xmath2  @xcite . , but this becomes too cumbersome when adding letters to represent additional features . ]",
    "this basic dl is then extended in a variety of ways  see figure  [ fig : sfamily ] for an overview .",
    "[ syntax+semantics ] let @xmath3 be a set of _ concept names _ and @xmath4a set of _ role names _ with transitive role names @xmath5 .",
    "the set of @xmath6-_roles _ is @xmath7 . to avoid considering roles such as @xmath8",
    ", we define a function @xmath9 on roles such that @xmath10 if @xmath11 is a role name , and @xmath12 if @xmath13 . in the following , when speaking of roles , we refer to @xmath6-roles , as our approach is capable of dealing uniformly with both role names and inverse roles .",
    "obviously , a role @xmath11 is transitive iff @xmath14 is transitive .",
    "we therefore define @xmath15 to return @xmath16 iff @xmath11 is a transitive role .",
    "more precisely , @xmath17 ( and we say that @xmath11 is transitive ) iff @xmath18 or @xmath19 .",
    "the set of @xmath6-_concepts _ is the smallest set such that    1 .",
    "every concept name is a concept , and , 2 .",
    "if @xmath20 and @xmath21 are concepts and @xmath11 is an @xmath6-role , then @xmath22 , @xmath23 , @xmath24 , @xmath25 , and @xmath26 are also concepts .",
    "a _ role inclusion axiom _ is of the form @xmath27 , where @xmath11 and @xmath28 are two roles , each of which can be inverse .",
    "a _ role hierarchy _ is a finite set of role inclusion axioms , and @xmath29is obtained from @xmath6by allowing , additionally , for a role hierarchy @xmath30 .",
    "the _ sub - role relation _",
    "@xmath31 is the transitive - reflexive closure of @xmath32 over @xmath33 .",
    "@xmath34is obtained from @xmath29by allowing , additionally , for qualified number restrictions  @xcite , i.e. , for concepts of the form @xmath35 and @xmath36 , where @xmath11 is a _ simple _ role , @xmath20 is a concept , and @xmath37 .",
    "a role is called _ simple _ iff it is neither transitive nor has transitive sub - roles . @xmath38is",
    "the restriction of @xmath34allowing only unqualified number restrictions ( i.e. , concepts of the form @xmath39 and @xmath40 ) , while @xmath41represents a further restriction where , instead of arbitrary number restrictions , only _ functional restrictions _ of the form @xmath42 and their negation @xmath43 may occur .",
    "an _ interpretation _ @xmath44 consists of a set @xmath45 , called the _",
    "domain _ of @xmath46 , and a function @xmath47 which maps every concept to a subset of @xmath45 and every role to a subset of @xmath48 such that , for all concepts @xmath20 , @xmath21 , roles @xmath11 , @xmath28 , and non - negative integers @xmath49 , the properties in figure  [ fig : sfamily ] are satisfied , where @xmath50 denotes the cardinality of a set @xmath51 .",
    "an interpretation satisfies a role hierarchy @xmath52 iff @xmath53 for each @xmath54 ; we denote this fact by @xmath55 and say that @xmath46 is a model of @xmath52 .",
    "a concept @xmath20 is called _ satisfiable _ with respect to a role hierarchy @xmath52 iff there is some interpretation @xmath46 such that @xmath55 and @xmath56 .",
    "such an interpretation is called a _ model of _",
    "@xmath20 w.r.t .",
    "a concept @xmath21 _ subsumes _ a concept @xmath20 w.r.t .",
    "@xmath52 ( written @xmath57 ) iff @xmath58 holds for each model @xmath46 of @xmath52 . for an interpretation @xmath46",
    ", an individual @xmath59 is called an _ instance _ of a concept @xmath20 iff @xmath60 .",
    "all dls considered here are closed under negation , hence subsumption and ( un)satisfiability w.r.t .",
    "role hierarchies can be reduced to each other : @xmath61 iff @xmath62 is unsatisfiable w.r.t .",
    "@xmath52 , and @xmath20 is unsatisfiable w.r.t .  @xmath52 iff @xmath63 for some concept name @xmath64 .    [",
    "cols=\"<,^,^,^\",options=\"header \" , ]     as for @xmath41 , correctness of the algorithm is proved by first showing that a @xmath6-concept is satisfiable iff it has a tableau , and next proving the @xmath6-analogue of lemma  [ lemma : shin - algo - correct ] .",
    "[ theo : si - algo ] the tableaux algorithm is a decision procedure for satisfiability and subsumption of @xmath6-concepts .    the dynamic blocking technique for @xmath6and @xmath29described in section  [ sec : blocking ] , which is based on label equality , may lead to completion trees with exponentially long paths because there are exponentially many possibilities to label sets on such a path .",
    "due to the non - deterministic @xmath65-rule , these exponentially many sets may actually occur .",
    "this non - determinism is not problematical for @xmath1 because disjunctions need not be completely decomposed to yield a subset - blocking situation .",
    "for an optimal @xmath6algorithm , the additional label @xmath66 was introduced to enable a sort of subset - blocking which is independent of the @xmath65-non - determinism . intuitively , @xmath67 is the restriction of @xmath68 to those non - decomposed concepts that @xmath69 must satisfy , whereas @xmath68 contains boolean decompositions of these concepts as well as those that are imposed by value restrictions in descendants .",
    "if @xmath69 is blocked by @xmath70 , then all concepts in @xmath67 are eventually decomposed in @xmath71 ( if no clash occurs )",
    ". however , in order to substitute @xmath69 by @xmath70 , @xmath69 s constraints on predecessors must be at least as strong as @xmath70 s ; this is taken care of by the second blocking condition .",
    "let us consider a path @xmath72 where all edges are labelled @xmath11 with @xmath73 , the only kind of paths along which the length of the longest concept in the labels might not decrease .",
    "if no rules can be applied , we have @xmath74 and @xmath75 ( where @xmath76 triggered the generation of @xmath77 ) . this limits the number of labels and guarantees blocking after a polynomial number of steps .",
    "[ lemma : poly_paths ] the paths of a completion tree for a concept @xmath21 have a length of at most @xmath78 where @xmath79 .    finally , a slight modification of the expansion rules given in figure  [ table : alci ] yields a pspacealgorithm .",
    "this modification is necessary because the original algorithm must keep the whole completion tree in its memory  which needs exponential space even though the length of its paths is polynomially bounded .",
    "the original algorithm may not forget about branches because restrictions which are pushed _ upwards _ in the tree might make it necessary to revisit paths which have been considered before .",
    "we solve this problem as follows :    whenever the @xmath80- or the @xmath81-rule is applied to a node @xmath69 and its _ predecessor _ @xmath70 ( case 2 of these rules ) , we delete all successors of @xmath70 from the completion tree .",
    "while this makes it necessary to restart the generation of successors for @xmath70 , it makes it possible to implement the algorithm in a depth - first manner which facilitates the re - use of space .",
    "this modification does not affect the proof of soundness and completeness for the algorithm , but we have to re - prove termination @xcite as it relied on the fact that we never removed any nodes from the completion tree .",
    "summing up we get :    the modified algorithm is a pspacedecision procedure for satisfiability and subsumption of @xmath6-concepts .",
    "in @xcite we describe an algorithm for @xmath34based on the @xmath41-algorithm already presented . like earlier dls that combine a hierarchy of ( transitive and non - transitive ) roles with some form of number restrictions  @xcite and @xmath41 ,",
    "the dl @xmath34allows only _ simple _ roles in number restrictions .",
    "the justification for this limitation has been partly on the grounds of a doubtful semantics ( of transitive functional roles ) and partly to simplify decision procedures . in this section",
    "we will show that , even for the simpler @xmath82logic , allowing arbitrary roles in number restrictions leads to undecidability , while decidability for the corresponding variant of @xmath41is still an open problem . for convenience",
    ", we will refer to @xmath82with arbitrary roles in number restrictions as @xmath83 .",
    "the undecidability proof uses a reduction of the domino problem  @xcite adapted from  @xcite .",
    "this problem asks if , for a set of domino types , there exists a _",
    "tiling _ of an @xmath84 grid such that each point of the grid is covered with one of the domino types , and adjacent dominoes are `` compatible '' with respect to some predefined criteria .",
    "a domino system @xmath85 consists of a non - empty set of domino types @xmath86 , and of sets of horizontally and vertically matching pairs @xmath87 and @xmath88 . the problem is to determine if , for a given @xmath89 , there exists a _",
    "tiling _ of an @xmath90 grid such that each point of the grid is covered with a domino type in @xmath21 and all horizontally and vertically adjacent pairs of domino types are in @xmath91 and @xmath92 respectively , i.e. , a mapping @xmath93 such that for all @xmath94 , @xmath95 and @xmath96 .",
    "this problem can be reduced to the satisfiability of @xmath83-concepts , and the undecidability of the domino problem implies undecidability of satisfiability of @xmath83-concepts .",
    "ensuring that a given point satisfies the compatibility conditions is simple for most logics ( using value restrictions and boolean connectives ) , and applying such conditions throughout the grid is also simple in a logic such as @xmath83which can deal with arbitrary axioms .",
    "the crucial difficulty is representing the @xmath97 grid using `` horizontal '' and `` vertical '' roles @xmath98 and @xmath99 , and in particular forcing the coincidence of @xmath100 and @xmath101 successors .",
    "this can be accomplished in @xmath83using an alternating pattern of two horizontal roles @xmath102 and @xmath103 , and two vertical roles @xmath104 and @xmath105 , with disjoint primitive concepts @xmath64 , @xmath106 , @xmath20 , and @xmath21 being used to identify points in the grid with different combinations of successors .",
    "the coincidence of @xmath107 and @xmath101 successors can then be enforced using number restrictions on transitive super - roles of each of the four possible combinations of @xmath98 and @xmath99 roles .",
    "a visualisation of the resulting grid and a suitable role hierarchy is shown in figure  [ fig : grid ] , where @xmath108 are transitive roles .",
    "the alternation of @xmath98 and @xmath99 roles in the grid means that one of the transitive super - roles @xmath108 connects each point @xmath109 to the points @xmath110 , @xmath111 and @xmath112 , and to no other points . a number restriction of the form @xmath113",
    "can thus be used to enforce the necessary coincidence of @xmath100 and @xmath101 successors .",
    "a complete specification of the grid is given by the following axioms : @xmath114 it only remains to add axioms which encode the local compatibility conditions ( as described in  @xcite ) and to assert that @xmath64 is subsumed by the disjunction of all domino types .",
    "the @xmath83-concept @xmath64 is now satisfiable w.r.t .",
    "the various axioms ( which can be internalised as described in lemma  [ lemma : terminologies ] ) iff there is a compatible tiling of the grid .",
    "the development of the @xmath6family of dls has been motivated by the desire to implement systems with good typical case performance . as discussed in section  [ sec : blocking ] , this is achieved in part through the design of the logics and algorithms themselves , in particular by using transitive roles and by reasoning with number restrictions directly , rather than via encodings .",
    "another important feature of these algorithms is that their relative simplicity facilitates the application of a range of optimisation techniques .",
    "several systems based on @xmath1logics have now been implemented ( e.g. , fact  @xcite , dlp  @xcite and race  @xcite ) , and have demonstrated that suitable optimisation techniques can lead to a dramatic improvement in the performance of the algorithms when used in realistic applications .",
    "a system based on the @xmath41logic has also been implemented ( ifact  @xcite ) and has been shown to be similarly amenable to optimisation .",
    "systems are typically used to classify a kb , and the optimisation techniques used in such systems can be divided into four categories based on the stage of the classification process at which they are applied .    1 .   preprocessing optimisations that try to modify the kbso that classification and subsumption testing are easier",
    ". 2 .   partial ordering optimisations that try to minimise the number of subsumption tests required in order to classify the kb .",
    "subsumption optimisations that try to avoid performing a potentially expensive satisfiability test , usually by substituting a cheaper test . 4 .",
    "satisfiability optimisations that try to improve the typical case performance of the underlying satisfiability testing algorithm .",
    "many optimisations in the first three categories are relatively independent of the underlying subsumption ( satisfiability ) testing algorithm and could be applied to any system . as we are mostly concerned with algorithms for the @xmath6family of s we will concentrate on the fourth kind of optimisation , those that try to improve the performance of the algorithm itself .",
    "most of these are aimed at reducing the size of the search space explored by the algorithm as a result of applying non - deterministic tableaux expansion rules .",
    "implementations of the algorithms described in the previous sections typically use a search technique called _",
    "syntactic branching_. when expanding the label of a node @xmath69 , syntactic branching works by choosing an unexpanded disjunction @xmath115 in @xmath68 and searching the different models obtained by adding each of the disjuncts @xmath116 ,  ,",
    "@xmath117 to @xmath68  @xcite .",
    "as the alternative branches of the search tree are not disjoint , there is nothing to prevent the recurrence of an unsatisfiable disjunct in different branches .",
    "the resulting wasted expansion could be costly if discovering the unsatisfiability requires the solution of a complex sub - problem .",
    "for example , tableaux expansion of a node @xmath69 , where @xmath118 and @xmath64 is an unsatisfiable concept , could lead to the search pattern shown in figure  [ 09-fig : synbranch ] , in which the unsatisfiability of @xmath119 must be demonstrated twice .",
    "this problem can be dealt with by using a _",
    "semantic branching _",
    "technique adapted from the davis - putnam - logemann - loveland procedure ( dpl ) commonly used to solve propositional satisfiability ( sat ) problems  @xcite . instead of choosing an unexpanded disjunction in @xmath68 ,",
    "a single disjunct @xmath21 is chosen from one of the unexpanded disjunctions in @xmath68 .",
    "the two possible sub - trees obtained by adding either @xmath21 or @xmath120 to @xmath68 are then searched .",
    "because the two sub - trees are strictly disjoint , there is no possibility of wasted search as in syntactic branching .",
    "note that the order in which the two branches are explored is irrelevant from a theoretical viewpoint , but may offer further optimisation possibilities ( see section  [ 09-sec : heuristics ] ) .",
    "semantic branching search has the additional advantage that a great deal is known about the implementation and optimisation of the dpl algorithm .",
    "in particular , both _ local simplification _ ( see section  [ 09-sec : bcp ] ) and _ heuristic guided search _ ( see section  [ 09-sec : heuristics ] ) can be used to try to minimise the size of the search tree ( although it should be noted that both these techniques can also be adapted for use with syntactic branching search ) .",
    "there are also some disadvantages to semantic branching search .",
    "firstly , it is possible that performance could be degraded by adding the negated disjunct in the second branch of the search tree , for example if the disjunct is a very large or complex concept .",
    "however this does not seem to be a serious problem in practice , with semantic branching rarely exhibiting significantly worse performance than syntactic branching . secondly , its effectiveness is problem dependent .",
    "it is most effective with randomly generated problems , particularly those that are over - constrained ( likely to be unsatisfiable )  @xcite .",
    "it is also effective with some of the hand crafted problems from the tableaux98 benchmark suite  @xcite .",
    "however it is of little benefit when classifying realistic kbs  @xcite .",
    "local simplification is another technique used to reduce the size of the search space resulting from the application of non - deterministic expansion rules .",
    "before any non - deterministic expansion of a node label @xmath68 is performed , disjunctions in @xmath68 are examined , and if possible simplified .",
    "the simplification most commonly used is to deterministically expand disjunctions in @xmath68 that present only one expansion possibility and to detect a clash when a disjunction in @xmath68 has no expansion possibilities .",
    "this simplification has been called _ boolean constraint propagation _ ( bcp )  @xcite . in effect , the inference rule @xmath121 is being used to simplify the conjunctive concept represented by @xmath68 .",
    "for example , given a node @xmath69 such that @xmath122 bcp deterministically expands the disjunction @xmath123 , adding @xmath124 to @xmath68 , because @xmath125 . the deterministic expansion of @xmath124 adds both @xmath126 and @xmath127 to @xmath68 , allowing bcp to identify @xmath128 as a clash ( without any branching having occurred ) , because @xmath129 .",
    "bcp simplification is usually described as an integral part of sat based algorithms  @xcite , but it can also be used with syntactic branching .",
    "however , it is more effective with semantic branching as the negated concepts introduced by failed branches can result in additional simplifications . taking the above example of @xmath130 , adding @xmath131 to @xmath68 allows bcp to deterministically expand both of the disjunctions using the simplifications @xmath132 and @xmath133 .",
    "the reduced search space resulting from the combination of semantic branching and bcp is shown in figure  [ 09-fig : sembranch ] .",
    "local simplification has the advantage that it can never increase the size of the search space and can thus only degrade performance to the extent of the overhead required to perform the simplification .",
    "minimising this overhead does , however , require complex data structures  @xcite , particularly in a modal / description logic setting .    as with semantic",
    "branching , effectiveness is problem dependent , the optimisation being most effective with over - constrained randomly generated problems  @xcite .",
    "inherent unsatisfiability concealed in sub - problems can lead to large amounts of unproductive backtracking search , sometimes called thrashing .",
    "for example , expanding a node @xmath69 ( using semantic branching ) , where @xmath134 could lead to the fruitless exploration of @xmath135 possible @xmath11-successors of @xmath69 before the inherent unsatisfiability is discovered .",
    "the search tree resulting from the tableaux expansion is illustrated in figure  [ 09-fig : backjumping ] .",
    "this problem can be addressed by adapting a form of dependency directed backtracking called _ backjumping _ , which has been used in solving constraint satisfiability problems  @xcite ( a similar technique was also used in the harp theorem prover  @xcite ) . backjumping works by labelling each concept in a node label with a dependency set indicating the branching points on which it depends .",
    "a concept @xmath136 depends on a branching point if @xmath20 was added to @xmath68 at the branching point or if @xmath136 was generated by an expansion rule ( including simplification ) that depends on another concept @xmath137 , and @xmath137 depends on the branching point .",
    "a concept @xmath138 depends on a concept @xmath137 when @xmath20 was added to @xmath68 by a deterministic expansion that used @xmath137 .",
    "for example , if @xmath139 was derived from the expansion of @xmath140 , then @xmath139 depends on @xmath141 .",
    "when a clash is discovered , the dependency sets of the clashing concepts can be used to identify the most recent branching point where exploring the other branch might alleviate the cause of the clash .",
    "it is then possible to jump back over intervening branching points _ without _ exploring any alternative branches .",
    "let us consider the earlier example and suppose that @xmath142 has a dependency set @xmath143 and @xmath144 has a dependency set @xmath145 .",
    "the search proceeds until @xmath146 have been added to @xmath68 , when @xmath147 and @xmath144 are deterministically expanded and a clash occurs in @xmath71 between the @xmath64 derived from @xmath147 and the @xmath131 derived from @xmath148 .",
    "as these derivations were both deterministic , the dependency sets will be @xmath143 and @xmath145 respectively , and so @xmath149 is returned .",
    "this set can not include the branching points where @xmath146 were added to @xmath68 as @xmath143 and @xmath145 were defined before these branching points were reached .",
    "the algorithm can therefore backtrack through each of the preceding @xmath49 branching points without exploring the second branches , and will continue to backtrack until it reaches the branching point equal to the maximum value in @xmath149 ( if @xmath150 , then the algorithm will backtrack through all branching points and return `` unsatisfiable '' ) . figure  [ 09-fig : pruning ] illustrates the pruned search tree , with the number of @xmath11-successors explored being reduced by an exponential number .",
    "backjumping can also be used with syntactic branching , but the procedure is slightly more complex as there may be more than two possible choices at a given branching point , and the dependency set of the disjunction being expanded must also be taken into account .",
    "like local simplification , backjumping can never increase the size of the search space .",
    "moreover , it can lead to a dramatic reduction in the size of the search tree and thus a huge performance improvement .",
    "for example , when using either factor dlpwith backjumping disabled in order to classify a large ( @xmath1513,000 concept ) kbderived from the european galenproject  @xcite , single satisfiability tests were encountered that could not be solved even after several weeks of cpu time .",
    "classifying the same kbwith backjumping enabled takes less than 100s of cpu time for either factor dlp  @xcite .",
    "backjumping s only disadvantage is the overhead of propagating and storing the dependency sets .",
    "this can be alleviated to some extent by using a pointer based implementation so that propagating a dependency set only requires the copying of a pointer .",
    "heuristic techniques can be used to guide the search in a way that tries to minimise the size of the search tree .",
    "a method that is widely used in dpl sat algorithms is to branch on the disjunct that has the _ maximum number of occurrences in disjunctions of minimum size_the well known moms heuristic  @xcite . by choosing a disjunct that occurs frequently in small disjunctions , the moms heuristic tries to maximise the effect of bcp .",
    "for example , if the label of a node @xmath69 contains the unexpanded disjunctions @xmath152 , then branching on @xmath20 leads to their deterministic expansion in a single step : when @xmath20 is added to @xmath68 , all of the disjunctions are fully expanded and when @xmath153 is added to @xmath68 , bcp will expand all of the disjunctions , causing @xmath154 to be added to @xmath68 . branching first on any of @xmath154 , on the other hand ,",
    "would only cause a single disjunction to be expanded .",
    "the moms value for a candidate concept @xmath20 is computed simply by counting the number of times @xmath20 or its negation occur in minimally sized disjunctions .",
    "there are several variants of this heuristic , including the heuristic from jeroslow and wang  @xcite .",
    "the jeroslow and wang heuristic considers all occurrences of a disjunct , weighting them according to the size of the disjunction in which they occur .",
    "the heuristic then selects the disjunct with the highest overall weighting , again with the objective of maximising the effect of bcp and reducing the size of the search tree .    when a disjunct @xmath20 has been selected from the disjunctions in @xmath68 , a bcp maximising heuristic",
    "can also be used to determine the order in which the two possible branches , @xmath155 and @xmath156 , are explored .",
    "this is done by separating the two components of the heuristic weighting contributed by occurrences of @xmath20 and @xmath153 , trying @xmath155 first if @xmath20 made the _",
    "smallest _ contribution , and trying @xmath157 first otherwise .",
    "the intention is to prune the search tree by maximising bcp in the first branch .",
    "unfortunately moms - style heuristics can interact adversely with the backjumping optimisation because they do not take dependency information into account .",
    "this was first discovered in the factsystem , when it was noticed that using moms heuristic often led to much worse performance .",
    "the cause of this phenomenon turned out to be the fact that , without the heuristic , the data structures used in the implementation naturally led to `` older '' disjunctions ( those dependent on earlier branching points ) being expanded before `` newer '' ones , and this led to more effective pruning if a clash was discovered . using",
    "the heuristic disturbed this ordering and reduced the effectiveness of backjumping  @xcite .",
    "moreover , moms - style heuristics are of little value themselves in description logic systems because they rely for their effectiveness on finding the same disjuncts recurring in multiple unexpanded disjunctions : this is likely in hard propositional problems , where the disjuncts are propositional variables , and where the number of different variables is usually small compared to the number of disjunctive clauses ( otherwise problems would , in general , be trivially satisfiable ) ; it is unlikely in concept satisfiability problems , where the disjuncts are ( possibly non - atomic ) concepts , and where the number of different concepts is usually large compared to the number of disjunctive clauses . as a result , these heuristics will often discover that all disjuncts have similar or equal priorities , and the guidance they provide is not particularly useful .",
    "an alternative strategy is to employ an _ oldest - first _",
    "heuristic that tries to maximise the effectiveness of backjumping by using dependency sets to guide the expansion  @xcite .",
    "when choosing a disjunct on which to branch , the heuristic first selects those disjunctions that depend on the least recent branching points ( i.e. , those with minimal maximum values in their dependency sets ) , and then selects a disjunct from one of these disjunctions .",
    "this can be combined with the use of a bcp maximising heuristic , such as the jeroslow and wang heuristic , to select the disjunct from amongst the selected disjunctions .",
    "the oldest - first heuristic can also be used to advantage when selecting the order in which existential role restrictions , and the labels of the @xmath11-successors which they generate , are expanded .",
    "one possible technique is to use the heuristic to select an unexpanded existential role restriction @xmath158 from the label of a node @xmath69 , apply the @xmath159-rule and the @xmath80-rule as necessary , and expand the label of the resulting @xmath11-successor .",
    "if the expansion results in a clash , then the algorithm will backtrack ; if it does not , then continue selecting and expanding existential role restrictions from @xmath68 until it is fully expanded .",
    "a better technique is to first apply the @xmath159-rule and the @xmath80-rule exhaustively , creating a set of successor nodes .",
    "the order in which to expand these successors can then be based on the minimal maximum values in the dependency sets of all the concepts in their label , some of which may be due to universal role restrictions in @xmath68 .",
    "the main advantage of heuristics is that they can be used to complement other optimisations .",
    "the moms and jeroslow and wang heuristics , for example , are designed to increase the effectiveness of bcp while the oldest - first heuristic is designed to increase the effectiveness of backjumping .",
    "they can also be selected and tuned to take advantage of the kinds of problem that are to be solved ( if this is known ) .",
    "the bcp maximisation heuristics , for example , are generally quite effective with large randomly generated and hand crafted problems , whereas the oldest - first heuristic is more effective when classifying realistic kbs .",
    "unfortunately heuristics also have several disadvantages .",
    "they can add a significant overhead as the heuristic function may be expensive to evaluate and may need to be reevaluated at each branching point . moreover , they may not improve performance , and may significantly degrade it , for example by interacting adversely with other optimisations , by increasing the frequency with which pathological worst cases can be expected to occur in generally easy problem sets .      during a satisfiability check",
    "there may be many successor nodes created",
    ". some of these nodes can be very similar , particularly as the labels of the @xmath11-successors for a node @xmath69 each contain the same concepts derived from the universal role restrictions in @xmath68 .",
    "systems such as dlptake advantage of this similarity by caching the satisfiability status of the sets of concepts with which node labels are initialised when they are created . the tableaux expansion of a node can then be avoided if the satisfiability status of its initial set of concepts is found in the cache .    however , this technique depends on the logic having the property that the satisfiability of a node is completely determined by its initial label set , and , due to the possible presence of inverse roles , @xmath6logics do not have this property . for example , if the expansion of a node @xmath69 generates an @xmath11-successor node @xmath70 , with @xmath160 , then the satisfiability of @xmath70 clearly also depends on the set of concepts in @xmath68 .",
    "similar problems could arise in the case where @xmath71 contains number restriction concepts .",
    "if it is possible to solve these problems , then caching may be a very effective technique for @xmath6logics , as it has been shown to be in the dlpsystem with a logic that does not support inverse roles .",
    "caching is particularly useful in kbclassification as cached values can be retained across multiple satisfiability tests .",
    "it can also be effective with both satisfiable and unsatisfiable problems , unlike many other optimisation techniques that are primarily aimed at speeding up the detection of unsatisfiability .",
    "the main disadvantage with caching is the storage overhead incurred by retaining node labels ( and perhaps additional information in the case of @xmath6logics ) and their satisfiability status throughout a satisfiability test ( or longer , if the results are to be used in later satisfiability tests ) .",
    "an additional problem is that it interacts adversely with the backjumping optimisation as the dependency information required for backjumping can not be effectively calculated for nodes that are found to be unsatisfiable as a result of a cache lookup .",
    "although the set of concepts in the initial label of such a node is the same as that of the expanded node whose ( un)satisfiability status has been cached , the dependency sets attached to the concepts that made up the two labels may not be the same .",
    "however , a weaker form of backjumping can still be performed by taking the dependency set of the unsatisfiable node to be the union of the dependency sets from the concepts in its label .",
    "a new dl system is being implemented based on the @xmath34algorithm we have developed from the @xmath41-algorithm described in section  [ sec : shin - algo ]  @xcite .",
    "pending the completion of this project , the existing factsystem  @xcite has been modified to deal with inverse roles using the @xmath41blocking strategy , the resulting system being referred to as ifact .",
    "ifacthas been used to conduct some initial experiments with a terminology representing ( fragments of ) database schemata and inter schema assertions from a data warehousing application  @xcite ( a slightly simplified version of the proposed encoding was used to generate @xmath41terminologies ) .",
    "ifactis able to classify this terminology , which contains 19 concepts and 42 axioms , in less than 0.1s of ( 266mhz pentium ) cpu time .",
    "in contrast , eliminating inverse roles using an embedding technique  @xcite gives an equisatisfiable factterminology with an additional 84 axioms , but one which factis unable to classify in 12 hours of cpu time .",
    "as discussed in section  [ sec : blocking ] , an extension of the embedding technique can be used to eliminate number restrictions  @xcite , but requires a target logic which supports the transitive _ closure _ of roles , i.e. , _",
    ". the even larger number of axioms that this embedding would introduce makes it unlikely that tractable reasoning could be performed on the resulting terminology .",
    "moreover , we are not aware of any algorithm for _ converse_-pdlwhich does not employ a so - called _ look behind analytical cut _",
    "@xcite , the application of which introduces considerable additional non - determinism .",
    "it seems inevitable that this would lead to a further degradation in empirical tractability .",
    "the @xmath34will allow the above mentioned encoding of database schemata to be fully captured using qualified number restrictions .",
    "future work will include completing the implementation of the @xmath34algorithm , testing its behaviour in this kind of application and investigating new techniques for improving its empirical tractability .",
    "f.  baader .",
    "augmenting concept languages by transitive closure of roles : an alternative to terminological cycles .",
    "technical report rr-90 - 13 , dfki , kaiserslautern , deutschland , 1990 .",
    "an abridged version appeared in _ proc .",
    "of ijcai-91 _ , pp .",
    "446451 .",
    "f.  baader and u.  sattler .",
    "number restrictions on complex roles in description logics . in l.  c. aiello , j.  doyle , and s.  c. shapiro , editors , _ proc .",
    "of kr96 _ , pages 328339 .",
    "morgan kaufmann publishers , san francisco , california , november 1996 .",
    "d.  calvanese , m.  lenzerini , and d.  nardi . a unified framework for class based representation formalisms . in j.  doyle , e.  sandewall , and p.  torasso , editors , _ proc .  of kr-94",
    "_ , pages 109120 , bonn , 1994",
    ". m. kaufmann , los altos .",
    "f.  m. donini , m.  lenzerini , d.  nardi , and a.  schaerf .",
    "reasoning in description logics . in g.  brewka , editor , _ foundation of knowledge representation_. csli publication , cambridge university press , 1996 .",
    "f.  giunchiglia and r.  sebastiani . building decision procedures for modal logics from propositional decision procedures - the case study of modal k. in _ proc .  of cade-96",
    "_ , lnai , new brunswick , nj , usa , 1996 .",
    "i.  horrocks . using an expressive description logic : fact or fiction ? in a.  g. cohn , l.  schubert , and s.  c. shapiro , editors , _ proc .  of kr-98 _ , pages 636647 .",
    "morgan kaufmann publishers , san francisco , california , june 1998 .",
    "d.  kozen and j.  tiuryn .",
    "logics of programs . in j.  v. leeuwen , editor , _ handbook of theoretical computer science ",
    "formal models and semantics _ , pages 789840 .",
    "elsevier science publishers ( north - holland ) , amsterdam , 1990 ."
  ],
  "abstract_text": [
    "<S> description logics ( dls ) are a family of knowledge representation formalisms mainly characterised by constructors to build complex concepts and roles from atomic ones . </S>",
    "<S> expressive role constructors are important in many applications , but can be computationally problematical .    </S>",
    "<S> we present an algorithm that decides satisfiability of the dl @xmath0extended with transitive and inverse roles and functional restrictions with respect to general concept inclusion axioms and role hierarchies ; early experiments indicate that this algorithm is well - suited for implementation . </S>",
    "<S> additionally , we show that @xmath0extended with just transitive and inverse roles is still in pspace . </S>",
    "<S> we investigate the limits of decidability for this family of dls , showing that relaxing the constraints placed on the kinds of roles used in number restrictions leads to the undecidability of all inference problems . </S>",
    "<S> finally , we describe a number of optimisation techniques that are crucial in obtaining implementations of the decision procedures , which , despite the hight worst - case complexity of the problem , exhibit good performance with real - life problems . </S>"
  ]
}