{
  "article_text": [
    "parikh vectors of strings count the multiplicity of the characters .",
    "they have been reintroduced many times by different names ( compomer  @xcite , composition  @xcite , parikh vector  @xcite , permuted string  @xcite , permuted pattern  @xcite , and others ) .",
    "they are natural objects to study , due to their numerous applications ; for instance , in computational biology , they have been applied in alignment algorithms  @xcite , snp discovery  @xcite , repeated pattern discovery  @xcite , and , most naturally , in interpretation of mass spectrometry data  @xcite .",
    "parikh vectors can be seen as a generalization of strings , where we view two strings as equivalent if one can be turned into the other by permuting its characters ; in other words , if the two strings have the same parikh vector .",
    "the problem we are interested in here is answering the question whether a query parikh vector @xmath5 appears in a given text @xmath1 ( decision version ) , or where it occurs ( occurrence version ) .",
    "an occurrence of @xmath5 is defined as an occurrence of a substring @xmath6 of @xmath1 with parikh vector @xmath5 .",
    "the problem can be viewed as an approximate pattern matching problem : we are looking for an occurrence of a jumbled version of a query string @xmath6 , i.e.  for the occurrence of a substring @xmath17 which has the same parikh vector . in the following ,",
    "let @xmath8 be the length of the text @xmath1 , @xmath18 the length of the query @xmath5 ( defined as the length of a string @xmath6 with parikh vector @xmath5 ) , and @xmath19 the size of the alphabet .",
    "the above problem ( both decision and occurrence versions ) can be solved with a simple sliding window based algorithm , in @xmath9 time and @xmath20 additional storage space .",
    "this is worst case optimal with respect to the case of one query .",
    "however , when we expect to search for many queries in the same string , the above approach leads to @xmath21 runtime for @xmath22 queries . to the best of our knowledge ,",
    "no faster approach is known .",
    "this is in stark contrast to the classical exact pattern matching problem , where all _ exact _ occurrences of a query pattern of length @xmath18 are sought in a text of length @xmath8 . in that case , for one query , any naive approach leads to @xmath23 runtime , while quite involved ideas for preprocessing and searching are necessary to achieve an improved runtime of @xmath24 , as do the knuth - morris - pratt @xcite , boyer - moore @xcite and boyer - moore - type algorithms ( see , e.g. , @xcite ) .",
    "however , when many queries are expected , the text can be preprocessed to produce a data structure of size linear in @xmath8 , such as a suffix tree , suffix array , or suffix automaton , which then allows to answer individual queries in time linear in the length of the pattern ( see any textbook on string algorithms , e.g.  @xcite ) .",
    "jumbled pattern matching is a special case of approximate pattern matching .",
    "it has been used as a filtering step in approximate pattern matching algorithms  @xcite , but rarely considered in its own right .",
    "the authors of  @xcite present an algorithm for finding all occurrences of a parikh vector in a runlength encoded text .",
    "the algorithm s time complexity is @xmath25 , where @xmath26 is the length of the runlength encoding of @xmath1 .",
    "obviously , if the string is not runlength encoded , a preprocessing phase of time @xmath9 has to be added .",
    "however , this may still be feasible if many queries are expected .",
    "to the best of our knowledge , this is the only algorithm that has been presented for the problem we treat here .",
    "an efficient algorithm for computing all parikh fingerprints of substrings of a given string was developed in  @xcite .",
    "parikh fingerprints are boolean vectors where the @xmath27th entry is @xmath28 if and only if @xmath29 appears in the string .",
    "the algorithm involves storing a data point for each parikh fingerprint , of which there are at most @xmath30 many .",
    "this approach was adapted in  @xcite for parikh vectors and applied to identifying all repeated parikh vectors within a given length range ; using it to search for queries of arbitrary length would imply using @xmath31 space , where @xmath32 denotes the number of different parikh vectors of substrings of @xmath1 .",
    "this is not desirable , since , for arbitrary alphabets , there are non - trivial strings of any length with quadratic @xmath32  @xcite .      in this paper , we present two novel algorithms which perform significantly better than the simple window algorithm , in the case where many queries arrive .",
    "for the binary case , we present an algorithm which answers _ decision queries _ in @xmath10 time , using a data structure of size @xmath9 ( interval algorithm , sect .  [ sec : binary ] ) .",
    "the data structure is constructed in @xmath11 time .    for general alphabets ,",
    "we present an algorithm with expected sublinear runtime which uses @xmath9 space to answer _ occurrence queries _ ( jumping algorithm , sect .",
    "[ sec : jumping ] ) .",
    "we present two different variants of the algorithm .",
    "the first one uses a very simple data structure ( an inverted table ) and answers queries in time @xmath33 where @xmath34 denotes the number of iterations of the main loop of the algorithm .",
    "we then show that the expected value of @xmath34 for the case of random strings and patterns is @xmath35 , yielding an expected runtime of @xmath36 , per query    the second variant of the algorithm uses wavelet trees  @xcite and has query time @xmath37 , yielding an overall expected runtime of @xmath38 , per query .",
    "( here and in the following , @xmath39 stands for logarithm base @xmath40 . )",
    "our simulations on random strings and real biological strings confirm the sublinear behavior of the algorithms in practice .",
    "this is a significant improvement over the simple window algorithm w.r.t .",
    "expected runtime , both for a single query and repeated queries over one string .",
    "the jumping algorithm is reminiscent of the boyer - moore - like approaches to the classical exact string matching problem  @xcite .",
    "this analogy is used both in its presentation and in the analysis of the number of iterations performed by the algorithm .",
    "given a finite ordered alphabet @xmath41 . for a string @xmath42 , @xmath43 ,",
    "the _ parikh vector _ @xmath44 of @xmath1 defines the multiplicities of the characters in @xmath1 , i.e.  @xmath45 , for @xmath46 . for a parikh vector @xmath47 , the _ length _",
    "@xmath48 denotes the length of a string with parikh vector @xmath47 , i.e.  @xmath49 .",
    "an _ occurrence _ of a parikh vector @xmath47 in @xmath1 is an occurrence of a substring @xmath6 with @xmath50 .",
    "( an occurrence of @xmath6 is a pair of positions @xmath51 , such that @xmath52 . ) a parikh vector that occurs in @xmath1 is called a sub - parikh vector of @xmath1 .",
    "the prefix of length @xmath53 is denoted @xmath54 , and the parikh vector of @xmath55 as @xmath56 .    for two parikh vectors",
    "@xmath57 , we define @xmath58 and @xmath59 component - wise : @xmath60 if and only if @xmath61 for all @xmath62 , and @xmath63 where @xmath64 for @xmath65 . similarly , for @xmath60 , we set @xmath66 where @xmath67 for @xmath65 .    _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ * jumbled pattern matching ( jpm ) . *",
    "let @xmath68 be given , @xmath69 .",
    "for a parikh vector @xmath70 ( the query ) , @xmath71 , find all occurrences of @xmath5 in @xmath1 .",
    "decision version _ of the problem is where we only want to know whether @xmath5 occurs in @xmath1 .",
    "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _    we assume that @xmath22 many queries arrive over time , so some preprocessing may be worthwhile .    note that for @xmath72 , both the decision version and the occurrence version can be solved worst - case optimally with a simple window algorithm , which moves a fixed size window of size @xmath18 along string @xmath1 .",
    "maintain the parikh vector @xmath73 of the current window and a counter @xmath74 which counts indices @xmath53 such that @xmath75 .",
    "each sliding step costs either 0 or 2 update operations of @xmath73 , and possibly one increment or decrement of @xmath74 .",
    "this algorithm solves both the decision and occurrence problems and has running time @xmath76 , using additional storage space @xmath77 .",
    "precomputing , sorting , and storing all sub - parikh vectors of @xmath1 would lead to @xmath11 storage space , since there are non - trivial strings with a quadratic number of parikh vectors over arbitrary alphabets  @xcite .",
    "such space usage is inacceptable in many applications .    for small queries ,",
    "the problem can be solved exhaustively with a linear size indexing structure such as a suffix tree , which can be searched down to length @xmath78 ( of the substrings ) , yielding a solution to the decision problem in time @xmath79 . for finding occurrences , report all leaves in the subtrees below each match ; this costs @xmath80 time , where @xmath81 is the number of occurrences of @xmath5 in @xmath1 .",
    "constructing the suffix tree takes @xmath9 time , so for @xmath82 , we get a total runtime of @xmath9 , since @xmath83 for any query @xmath5 .",
    "in this section , we present an algorithm for strings over a binary alphabet which , once a data structure of size @xmath9 has been constructed , answers decision queries in constant time .",
    "it makes use of the following nice property of binary strings .",
    "[ lemma : continuous ] let @xmath84 with @xmath69 .",
    "fix @xmath85 .",
    "if the parikh vectors @xmath86 and @xmath87 both occur in @xmath1 , then so does @xmath88 for any @xmath89 .    consider a sliding window of fixed size @xmath18 moving along the string and let @xmath90 be the parikh vector of the current substring .",
    "when the window is shifted by one , the parikh vector either remains unchanged ( if the character falling out is the same as the character coming in ) , or it becomes @xmath91 resp .",
    "@xmath92 ( if they are different ) .",
    "thus the parikh vectors of substrings of @xmath1 of length @xmath18 build a set of the form @xmath93 for appropriate @xmath94 and @xmath95 .",
    "assume that the algorithm has access to the values @xmath94 and @xmath95 for @xmath96 ; then , when a query @xmath97 arrives , it answers yes if and only if @xmath98 $ ] .",
    "the query time is @xmath10 .",
    "the table of the values @xmath94 and @xmath95 can be easily computed in a preprocessing step in time @xmath11 by scanning the string with a window of size @xmath18 , for each @xmath18 .",
    "alternatively , lazy computation of the table is feasible , since for any query @xmath5 , only the entry @xmath78 is necessary .",
    "therefore , it can be computed on the fly as queries arrive .",
    "then , any query will take time @xmath10 ( if the appropriate entry has already been computed ) , or @xmath9 ( if it has not ) .",
    "after @xmath8 queries of the latter kind , the table is completed , and all subsequent queries can be answered in @xmath10 time .",
    "if we assume that the query lengths are uniformly distributed , then this can be viewed as a coupon collector problem where the coupon collector has to collect one copy of each length @xmath18 .",
    "then the expected number of queries needed before having seen all @xmath8 coupons is @xmath99 ( see e.g.  @xcite ) .",
    "the algorithm will have taken @xmath100 time to answer these @xmath101 queries .",
    "the assumption of the uniform length distribution may not be very realistic ; however , even if it does not hold , we never take more time than @xmath102 for @xmath22 many queries .",
    "since any one query may take at most @xmath9 time , our algorithm never performs worse than the simple window algorithm .",
    "moreover , for those queries where the table entries have to be computed , we can even run the simple window algorithm itself and report all occurrences , as well .",
    "for all others , we only give decision answers , but in constant time .",
    "the size of the data structure is @xmath103 .",
    "the overall running time for either variant is @xmath104 .",
    "as soon as the number of queries is @xmath105 , both variants outperform the simple window algorithm , whose running time is @xmath106 .",
    "let @xmath107 . in table",
    "[ tab : val ] , we give the table of @xmath108 and @xmath109 for @xmath1 .",
    "this example shows that the locality of  and  is preserved only in adjacent levels . as an example",
    ", the value @xmath110 corresponds to the substring @xmath111 appearing only at position @xmath112 , while @xmath113 corresponds to the substring @xmath114 appearing only at position @xmath115 .",
    "c * 30@r @xmath18 & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10 & 11 & 12 & 13 & 14 & 15 & 16 & 17 & 18 & 19 & 20 +    ' '' ''    @xmath108 & 0 & 0 & 0 & 1 & 2 & 2 & 3 & 3 & 4 & 4 & 5 & 5 & 6 & 7 & 7 & 8 & 8 & 9 & 9 & 10 & +    ' '' ''    @xmath109 & 1 & 2 & 3 & 3 & 4 & 4 & 4 & 5 & 5 & 6 & 7 & 7 & 7 & 8 & 8 & 9 & 9 & 9 & 10 & 10 & +    [ table : example - intervals ]",
    "in this section , we introduce our algorithm for general alphabets .",
    "we first give the main algorithm and then present two different implementations of it .",
    "the first one , an inverted prefix table , is very easy to understand and to implement , takes @xmath9 space and @xmath9 time to construct ( both with constant @xmath28 ) , and can replace the string .",
    "then we show how to use a wavelet tree of @xmath1 to implement our algorithm , which has the same space requirements as the inverted table , can be constructed in @xmath9 time , and improves the query time by a factor of @xmath16 .",
    "let @xmath116 be given . recall that @xmath117 denotes the parikh vector of the prefix of @xmath1 of length @xmath53 , for @xmath118 , where @xmath119 .",
    "consider parikh vector @xmath120 , @xmath121 .",
    "we make the following simple observations :    [ obs : pr ]    1 .   for any @xmath122 , @xmath123 if and only if @xmath47 occurs in @xmath1 at position @xmath124 .",
    "2 .   if an occurrence of @xmath47 ends in position @xmath125 , then @xmath126 .",
    "the algorithm moves two pointers @xmath127 and @xmath128 along the text , pointing at these potential positions @xmath53 and @xmath125 . instead of moving linearly , however ,",
    "the pointers are updated in jumps , alternating between updates of @xmath128 and @xmath127 , in such a manner that many positions are skipped . moreover , because of the way we update the pointers , after any update it suffices to check whether @xmath129 to confirm that an occurrence has been found ( cf .",
    "lemma  [ lemma : invariants ] below ) .",
    "we first need to define a function @xmath130 , which returns the smallest potential position where an occurence of a parikh vector can end .",
    "let @xmath120 , then    @xmath131    and set @xmath132 if no such @xmath125 exists .",
    "we use the following rules for updating the two pointers , illustrated in fig .",
    "[ fig : jumping ] .",
    "( above ) and after the update of @xmath127 ( below ) .",
    "@xmath128 is placed at the first fit of @xmath133 , thus @xmath134 is a super - parikh vector of @xmath5",
    ". then @xmath127 is placed at the beginning of the longest good suffix ending in @xmath128 , so @xmath135 is a sub - parikh vector of @xmath5.[fig : jumping ] ]    _ updating @xmath128 : _ assume that the left pointer is pointing at position @xmath127 , i.e.  no unreported occurrence starts before @xmath136 .",
    "notice that , if there is an occurrence of @xmath5 ending at any position @xmath137 , it must hold that @xmath138 .",
    "in other words , we must fit both @xmath139 and @xmath5 at position @xmath125 , so we update @xmath128 to    @xmath140    _ updating @xmath127 : _ assume that @xmath128 has just been updated .",
    "thus , @xmath141 by definition of @xmath142 .",
    "if equality holds , then we have found an occurrence of @xmath5 in position @xmath143 , and @xmath127 can be incremented by @xmath28 .",
    "otherwise @xmath144 , which implies that , interspersed between the characters that belong to @xmath5 , there are some  superfluous \" characters .",
    "now the first position where an occurrence of @xmath5 can start is at the beginning of a _ contiguous _ sequence of characters ending in @xmath128 which all belong to @xmath5 .",
    "in other words , we need the beginning of the longest suffix of @xmath145 $ ] with parikh vector @xmath146 , i.e.  the smallest position @xmath53 such that @xmath147 , or , equivalently , @xmath148 . thus we update @xmath127 to    @xmath149    finally , in order to check whether we have found an occurrence of query @xmath5 , after each update of @xmath128 or @xmath127 , we check whether @xmath129 . in figure",
    "[ fig : jumping_pseudocode ] , we give the pseudocode of the algorithm .",
    "jumping algorithm [ algo : jumping ] set @xmath150 ; @xmath151 ; + @xmath152 + @xmath153 ; + @xmath154 + add @xmath136 to @xmath155 ; + @xmath156 ; + @xmath157 ; + @xmath154 + add @xmath136 to @xmath155 ; + @xmath158 ; + @xmath155 ;    it remains to see how to compute the @xmath130 and @xmath159 functions .",
    "we first prove that the algorithm is correct . for this",
    ", we will need the following lemma .",
    "[ lemma : invariants ] the following algorithm invariants hold :    1 .   after each update of @xmath128 , we have @xmath141 .",
    "2 .   after each update of @xmath127",
    ", we have @xmath160 .",
    "3 .   @xmath161 .",
    "_ follows directly from the definition of @xmath130 and the update rule for @xmath128 . for _ 2 .",
    "_ , if an occurrence was found at @xmath162 , then before the update we have @xmath163 and @xmath164 .",
    "now @xmath127 is incremented by @xmath28 , so @xmath165 and @xmath166 , where @xmath167 is the @xmath27th unity vector .",
    "otherwise , @xmath168 , and again the claim follows directly from the definition of @xmath130 . for _ 3 . _ , if an occurrence was found , then @xmath127 is incremented by @xmath28 , and @xmath169",
    ". otherwise , @xmath170 .",
    "[ thm : jumping_correctness ] algorithm jumping algorithm is correct .",
    "we have to show that ( 1 ) if the algorithm reports an occurrence , then it is correct , and ( 2 ) if there is an occurrence , then the algorithm will find it .    _",
    "( 1 ) _ if the algorithm reports an index @xmath53 , then @xmath171 is an occurrence of @xmath5 : an index @xmath53 is added to @xmath155 whenever @xmath154 .",
    "if the last update was that of @xmath128 , then we have @xmath141 by lemma [ lemma : invariants ] , and together with @xmath172 , this implies @xmath173 , thus @xmath174 is an occurrence of @xmath5 . if the last update was @xmath127 , then @xmath160 , and it follows analogously that @xmath175 .",
    "_ ( 2 ) _ all occurrences of @xmath5 are reported : let s assume otherwise .",
    "then there is a minimal @xmath53 and @xmath176 such that @xmath177)=q$ ] but @xmath53 is not reported by the algorithm . by observation [ obs : pr ] , we have @xmath178 .",
    "let s refer to the values of @xmath127 and @xmath128 as two sequences @xmath179 and @xmath180 .",
    "so we have @xmath181 , and for all @xmath182 @xmath183 , and @xmath184 if @xmath185 and @xmath186 otherwise .",
    "in particular , @xmath187 for all @xmath27 .    first observe that if for some @xmath27 , @xmath188 , then @xmath128 will be updated to @xmath125 in the next step , and we are done .",
    "this is because @xmath189 .",
    "similarly , if for some @xmath27 , @xmath190 , then we have @xmath191 .",
    "so there must be a @xmath27 such that @xmath192 .",
    "now look at @xmath193 .",
    "since there is an occurrence of @xmath5 after @xmath194 ending in @xmath125 , this implies that @xmath195 .",
    "however , we can not have @xmath196 , so it follows that @xmath197 . on the other hand , @xmath198 by our assumption and by lemma [ lemma : invariants ] .",
    "so @xmath193 is pointing to a position somewhere between @xmath199 and @xmath125 , i.e.  to a position within our occurrence of @xmath5 .",
    "denote the remaining part of @xmath5 to the right of @xmath193 by @xmath134 : @xmath200 . since @xmath201",
    ", all characters of @xmath5 must fit between @xmath202 and @xmath193 , so the parikh vector @xmath203 is a super - parikh vector of @xmath134 .",
    "if @xmath204 , then there is an occurrence of @xmath5 at @xmath205 , and by minimality of @xmath162 , this occurrence was correctly identified by the algorithm .",
    "thus , @xmath206 , contradicting our choice of @xmath27 .",
    "it follows that @xmath207 and we have to find the longest good suffix of the substring ending in @xmath193 for the next update @xmath208 of @xmath127 .",
    "but @xmath209 $ ] is a good suffix because its parikh vector is a sub - parikh vector of @xmath5 , so @xmath210 , again in contradiction to @xmath211 .",
    "we illustrate the proof in fig .",
    "[ fig : proof_of_correctness ] .     illustration for proof of correctness . ]      storing all prefix vectors of @xmath1 would require @xmath212 storage space , which may be too much .",
    "instead , we construct an  inverted prefix vector table \" @xmath213 containing the increment positions of the prefix vectors : for each character @xmath214 , and each value @xmath125 up to @xmath215 , the position in @xmath1 of the @xmath125th occurrence of character @xmath29 .",
    "formally , @xmath216[j ] = \\min \\ { i \\mid prv(i)_k \\geq j \\}$ ] for @xmath217 , and @xmath216[0]=0 $ ]",
    ". then we have    @xmath218[p_k]\\}.\\ ] ]    we can also compute the prefix vectors @xmath117 from table @xmath213 : for @xmath219 ,    @xmath220[i ] \\leq j \\}\\ ] ]    the obvious way to find these values is to do binary search for @xmath125 in each row of @xmath213 .",
    "however , this would take time @xmath221 ; a better way is to use information already acquired during the run of the algorithm . by lemma [ lemma : invariants ]",
    ", it always holds that @xmath222 .",
    "thus , for computing @xmath223 , it suffices to search for @xmath128 between @xmath224 and @xmath225 .",
    "this search takes time proportional to @xmath226 .",
    "moreover , after each update of @xmath127 , we have @xmath227 , so when computing @xmath224 , we can restrict the search for @xmath127 to between @xmath228 and @xmath223 , in time @xmath229 . for more details , see section  [ sec : jumping_analysis ] .",
    "table @xmath213 can be computed in one pass over @xmath1 ( where we take the liberty of identifying character @xmath230 with its index @xmath27 ) .",
    "the variables @xmath231 count the number of occurrences of character @xmath29 seen so far , and are initialized to @xmath232 .",
    "construct @xmath213 [ algo : preproc ] @xmath233 @xmath8 + @xmath234 ; + @xmath235[c_{s_i } ] = i;$ ]    table @xmath213 requires @xmath9 storage space ( with constant 1 ) .",
    "moreover , the string @xmath1 can be discarded , so we have zero additional storage .",
    "( access to @xmath236 is still possible , at cost @xmath237 . )",
    "let @xmath238 and @xmath239 .",
    "the prefix vectors of @xmath1 are given below .",
    "note that the algorithm does not actually compute these .",
    "@xmath240s@xmath241c@xmath242a@xmath242b@xmath242c@xmath242c@xmath242c@xmath242a@xmath242a@xmath242a@xmath242b@xmath242c@xmath242c@xmath242b@xmath242a@xmath242a@xmath242c@xmath242c@xmath242a@xmath243a@xmath244b@xmath245c@xmath246    the inverted prefix table @xmath213 :    @xmath247    query @xmath248 has 4 occurrences , beginning in positions @xmath249 , since @xmath250 .",
    "the values of @xmath127 and @xmath128 are given below :    r|@*7p.5 cm @xmath27 , see proof of thm .",
    "[ thm : jumping_correctness ] & 1 & 2 & 3 & 4 & 5 & 6 & 7 + l & 0 & 4 & 5 & 6 & 7 & 10 & 12 + r & 8 & 10 & 11 & 12 & 14 & 18 & 18 + occurrence found ? &  & yes & yes & yes &  &  & yes +      a wavelet tree on @xmath68 allows _ rank , select , _ and _ access _ queries in time @xmath251 . for @xmath230 , @xmath252 ,",
    "the number of occurrences of character @xmath29 up to and including position @xmath53 , while @xmath253 , the position of the @xmath53th occurrence of character @xmath29 .",
    "when the string is clear , we just use @xmath254 and @xmath255 .",
    "notice that    * @xmath256 , and * for a parikh vector @xmath257 , @xmath258 .",
    "so we can use a wavelet tree of string @xmath1 to implement those two functions .",
    "we give a brief recap of wavelet trees , and then explain how to implement the two functions above in @xmath20 time each .    a wavelet tree is a complete binary tree with @xmath259 many leaves . to each inner node ,",
    "a bitstring is associated which is defined recursively , starting from the root , in the following way .",
    "if @xmath260 , then there is nothing to do ( in this case , we have reached a leaf ) .",
    "else split the alphabet into two roughly equal parts , @xmath261 and @xmath262 . now construct a bitstring of length @xmath8 from @xmath1 by replacing each occurrence of a character @xmath263 by @xmath232 if @xmath264 , and by @xmath28 if @xmath265 .",
    "let @xmath266 be the subsequence of @xmath1 consisting only of characters from @xmath261 , and @xmath267 that consisting only of characters from @xmath262 .",
    "now recurse on the left child with string @xmath268 and alphabet @xmath261 , and on the right child with @xmath267 and @xmath262 .",
    "an illustration is given in fig .",
    "[ fig : wavelet ] . at each inner node , in addition to the bitstring @xmath269 , we have a data structure of size @xmath270 , which allows to perform @xmath271 and @xmath272 queries on bit vectors in constant time ( @xcite ) .",
    "now , using the wavelet tree of @xmath1 , any _ rank _  or _ select _  operation on @xmath1 takes time @xmath273 , which would yield @xmath274 time for both @xmath275 and @xmath276 .",
    "however , we can implement both in a way that they need only @xmath20 time : in order to compute @xmath277 , the wavelet tree , which has @xmath278 levels , has to be descended from the root to leaf @xmath27 . since for @xmath275 , we need all values @xmath279 simultaneously , we traverse the complete tree in @xmath20 time .    for computing @xmath276 , we need @xmath280 , which can be computed bottom - up in the following way .",
    "we define a value @xmath281 for each node @xmath282 .",
    "if @xmath282 is a leaf , then @xmath282 corresponds to some character @xmath214 ; set @xmath283 . for an inner node @xmath282 , let @xmath284 be the bitstring at @xmath282 .",
    "we define @xmath281 by @xmath285 @xmath286 , where @xmath287 and @xmath288 are the values already computed for the left resp .",
    "right child of @xmath282 .",
    "the desired value is equal to @xmath289 .",
    "let @xmath290 ( cp .",
    "[ fig : wavelet ] ) .",
    "we demonstrate the computation of @xmath291 using the wavelet tree .",
    "we have @xmath291 @xmath292 , where in slight abuse of notation we put the character in the subscript instead of its number .",
    "denote the bottom left bitstring as @xmath293 , the bottom right one as @xmath294 , and the top bitstring as @xmath295 .",
    "then we get @xmath296 , and @xmath297 .",
    "so at the next level , we compute @xmath298 .    . for clarity",
    ", the leaves have been omitted .",
    "note also that the third line at each inner node ( the strings over the alphabet @xmath299 ) are only included for illustration .",
    "[ fig : wavelet ] ]      let @xmath300 denote the running time of the jumping algorithm using inverted tables over a text @xmath1 and a parikh vector @xmath5 , and @xmath301 that of the jumping algorithm using a wavelet tree .",
    "further , let @xmath302 be the number of iterations performed in the while loop in line 2 , i.e. , the number of jumps performed by the algorithm on the input @xmath303    the time spent in each iteration depends on how the functions @xmath142 and @xmath159 are implemented ( lines 3 and 7 ) . in the wavelet tree implementation , as we saw before , both take time @xmath20 , so the overall runtime of the algorithm is    @xmath304    for the inverted table implementation , it is easy to see that computing @xmath130 takes @xmath20 time",
    ". now denote , for each @xmath305 by @xmath306 the value of @xmath127 and @xmath128 after the @xmath53th execution of line 3 of the algorithm , respectively . and",
    "@xmath307 coincide with the @xmath202 and @xmath193 from the proof of theorem  [ thm : jumping_correctness ] almost but not completely : when an occurrence is found after the update of @xmath127 , then the corresponding pair @xmath308 is skipped here .",
    "the reason is that now we are only considering those updates that carry a computational cost . ]",
    "the computation of @xmath309 in line 3 takes @xmath310 : for each @xmath311 the component @xmath312 can be determined by binary search over the list @xmath216[prv(\\hat{r}_{i-1})_k - m ] , i[k][prv(\\hat{r}_{i-1})_k - m+1 ] , \\dots , i[k][prv(\\hat{r}_{i-1})_k].$ ] by @xmath313 the claim follows .",
    "the computation of @xmath314 in line 7 takes @xmath315 simply observe that in the prefix ending at position @xmath316 there can be at most @xmath317 more occurrences of the @xmath27th character than there are in the prefix ending at position @xmath318 therefore , as before , we can determine @xmath319 by binary search over the list @xmath216[prv(\\hat{l}_{i})_k ] , i[k][prv(\\hat{l}_{i})_k + 1 ] , \\dots , i[k][prv(\\hat{l}_{i})_k + \\hat{r_i } - \\hat{l_i}].$ ] using the fact that @xmath313 the desired bound follows .",
    "the last three observations imply @xmath320    notice that this is an overestimate , since line 7 is only executed if no occurrence was found after the current update of @xmath128 ( line 4 ) .",
    "standard algebraic manipulations using jensen s inequality ( see , e.g.  @xcite ) yield @xmath321 therefore we obtain    @xmath322      the worst case running time of the jumping algorithm , in either implementation , is superlinear , since there exist strings @xmath1 of any length @xmath8 and parikh vectors @xmath5 such that @xmath323 : for instance , on the string @xmath324 and @xmath325 , the algorithm will execute @xmath326 jumps .",
    "this sharply contrasts with the experimental evaluation we present later .",
    "the jumping algorithm appears to have in practice a sublinear behavior . in the rest of this section",
    "we provide an average case analysis of the running time of the jumping algorithm leading to the conclusion that its expected running time is sublinear .",
    "we assume that the string @xmath1 is given as a sequence of i.i.d .",
    "random variables uniformly distributed over the alphabet @xmath327 according to knuth _ et al .  _",
    "@xcite `` it might be argued that the average case taken over random strings is of little interest , since a user rarely searches for a random string .",
    "however , this model is a reasonable approximation when we consider those pieces of text that do not contain the pattern [  ] '' .",
    "the experimental results we provide will show that this is indeed the case .",
    "let us concentrate on the behaviour of the algorithm when scanning a ( piece of the ) string which does not contain a match . according to the above observation",
    "we can reasonably take this as a measure of the performance of the algorithm , considering that for any match found there is an additional step of size 1 , which we can charge as the cost of the output .",
    "let @xmath328 denote the expected value of the distance between @xmath128 and @xmath127 , following an update of @xmath329 i.e. if @xmath127 is in position @xmath330 then we are interested in the value @xmath331 such that @xmath332 notice that the probabilistic assumptions made on the string , together with the assumption of absence of matches , allows us to treat this value as independent of the position @xmath333 we will show the following result about @xmath334 for the sake of the clarity , we defer the proof of this technical fact to the next section .",
    "[ lemma : avg_jump ] @xmath335    at each iteration ( when there is no match ) the @xmath127 pointer is moved forward to the farthest position from @xmath128 such that the parikh vector of the substring between @xmath127 and @xmath128 is a sub - parikh vector of @xmath303 in particular , we can upper bound the distance between the new positions of @xmath127 and @xmath128 with @xmath336 thus for the expected number of jumps performed by the algorithm , measured as the average number of times we move @xmath127 , we have @xmath337 = \\frac{n}{e_{m,\\sigma } - m } = o\\left(\\frac{n}{\\sqrt{m \\sigma \\ln \\sigma } } \\right).\\ ] ]    recalling   and  , and using   for a random instance we have the following result concerning the average case complexity of the jumping algorithm .    [",
    "thm : time_jumping ] let @xmath68 be fixed . algorithm jumping algorithm finds all occurrences of a query @xmath5    1 .   in expected time @xmath338 using an inverted prefix table of size @xmath9 , which can be constructed in a preprocessing step in time @xmath9 ; 2 .   in expected time @xmath339 using a wavelet tree of @xmath1 of size @xmath9 , which can be computed in a preprocessing step in time @xmath9 .",
    "we conclude this section by remarking once more that the above estimate obtained by the approximating probabilistic automaton appears to be confirmed by the experiments .",
    "we shall argue asymptotically with @xmath18 and according to whether or not the parikh vector @xmath5 is balanced , and in the latter case according to its degree of _ unbalancedness _ , measured as the magnitude of its largest and smallest components .",
    "_ @xmath5 is balanced , i.e. , @xmath340 then , from equations ( 7 ) and ( 12 ) of @xcite , it follows that @xmath341    the author of @xcite studied a variant of the well known coupon collector problem in which the collector has to accumulate a certain number of copies of each coupon .",
    "it should not be hard to see that by identifying the characters with the coupon types , the random string with the sequence of coupons obtained , and the query parikh vector with the number of copies we require for each coupon type , the expected time when the collection is finished is the same as our @xmath342 it is easy to see that ( [ eq : coupcoll ] ) provides the claimed bound of lemma  [ lemma : avg_jump ] .",
    "_ @xmath343 assume , w.l.o.g . , that @xmath344 we shall argue by cases according to the magnitude of @xmath345    _ subcase 2.1 .",
    "_ suppose @xmath346 let us consider again the analogy with the coupon collector who has to collect @xmath347 copies of coupons of type @xmath330 with @xmath348 clearly the collection is not completed until the @xmath349th copy of the coupon of type @xmath28 has been collected .",
    "we can model the collection of these type-1 coupons as a sequence of bernoulli trials with probability of success @xmath350 the expected waiting time until the @xmath351th success is @xmath352 and from the previous observation this is also a lower bound on @xmath342 thus , @xmath353 which confirms the bound claimed , also in this case .    _ subcase 2.2 .",
    "_ finally , assume that @xmath354 then , for the smallest component @xmath355 of @xmath5 we have @xmath356 consider now the balanced parikh vector @xmath357 we have that @xmath358 and @xmath359 by the analysis of case 1 .",
    ", above , on balanced parikh vectors , and observing that collecting @xmath5 implies collecting @xmath134 also , it follows that    @xmath360    in agreement with the bound claimed .",
    "this completes the proof .",
    "we implemented the jumping algorithm in c++ in order to study the number of jumps @xmath34 .",
    "we ran it on random strings of different lengths and over different alphabet sizes .",
    "the underlying probability model is an i.i.d .",
    "model with uniform distribution .",
    "we sampled random query vectors with length between @xmath361 ( @xmath362 ) and @xmath363 , where @xmath8 is the length of the string .",
    "our queries were of one of two types :    1 .",
    "quasi - balanced parikh vectors : of the form @xmath364 with @xmath365 , and @xmath366 running from @xmath367 to @xmath368 . for simplicity , we fixed @xmath369 in all our experiments , and sampled uniformly at random from all quasi - balanced vectors around each @xmath366 .",
    "random parikh vectors with fixed length @xmath18 .",
    "these were sampled uniformly at random from the space of all parikh vectors with length @xmath18 .",
    "the rationale for using quasi - balanced queries is that those are clearly worst - case for the number of jumps @xmath34 , since @xmath34 depends on the shift length , which in turn depends on @xmath370 . since we are searching in a random string with uniform character distribution",
    ", we can expect to have minimal @xmath370 if @xmath5 is close to balanced , i.e.  if all entries @xmath347 are roughly the same .",
    "this is confirmed by our experimental results which show that @xmath34 decreases dramatically if the queries are not balanced ( fig .",
    "[ fig : simulations2 ] , right ) .",
    "we ran experiments on random strings over different alphabet sizes , and observe that our average case analysis agrees well with the simulation results for random strings and random quasi - balanced query vectors .",
    "plots for @xmath371 and @xmath372 with alphabet sizes @xmath373 resp.@xmath374 are shown in fig .",
    "[ fig : simulations1 ] .    in fig .",
    "[ fig : scott ] we show comparisons between the running time of the jumping algorithm and that of the simple window algorithm .",
    "the simulations over random strings and parikh vectors of different sizes appear to perfectly agree with the guarantees provided by our asymptotic analyses .",
    "this is of particular importance from the point of view of the applications , as it shows that the complexity analysis does not hide big constants .",
    "running time comparisons between the jumping algorithm and the window algorithm .",
    "the text is a random string ( uniform i.i.d . ) of size @xmath375 from a four letter alphabet .",
    "parikh vectors of different sizes between 10 and 2000 were randomly generated and the results averaged over all queries of the same size .",
    "on the left are the results for quasi - balanced parikh vectors ( cf .",
    "text ) . on the right",
    "are the results for random parikh vectors . ]    running time comparisons between the jumping algorithm and the window algorithm .",
    "the text is a random string ( uniform i.i.d . ) of size @xmath375 from a four letter alphabet .",
    "parikh vectors of different sizes between 10 and 2000 were randomly generated and the results averaged over all queries of the same size .",
    "on the left are the results for quasi - balanced parikh vectors ( cf .",
    "text ) . on the right",
    "are the results for random parikh vectors . ]    to see how our algorithm behaves on non - random strings , we downloaded human dna sequences from genbank  @xcite and ran the jumping algorithm with random quasi - balanced queries on them .",
    "we found that the algorithm performs 2 to 10 times fewer jumps on these dna strings than on random strings of the same length , with the gain increasing as @xmath8 increases .",
    "we show the results on a dna sequence of @xmath28 million bp ( from chromosome 11 ) in comparison with the average over 10 random strings of the same length ( fig .",
    "[ fig : simulations2 ] , left ) .",
    "number of jumps for different alphabet sizes for random strings of size @xmath376 ( left ) and @xmath377 ( right ) .",
    "all queries are randomly generated quasi - balanced parikh vectors ( cf .",
    "data averaged over 10 strings and all random queries of same length . ]",
    "number of jumps for different alphabet sizes for random strings of size @xmath376 ( left ) and @xmath377 ( right ) .",
    "all queries are randomly generated quasi - balanced parikh vectors ( cf .",
    "data averaged over 10 strings and all random queries of same length . ]",
    "number of jumps in random vs.  nonrandom strings : random strings over an alphabet of size @xmath378 vs.  a dna sequence , all of length @xmath379 , random quasi - balanced query vectors .",
    "data averaged over 10 random strings and all queries with the same length ( left ) .",
    "comparison of quasi - balanced vs.  arbitrary query vectors over random strings , alphabet size @xmath378 , length @xmath380 , 10 strings .",
    "the data shown are averaged over all queries with same length @xmath18 ( right ) . ]",
    "number of jumps in random vs.  nonrandom strings : random strings over an alphabet of size @xmath378 vs.  a dna sequence , all of length @xmath379 , random quasi - balanced query vectors .",
    "data averaged over 10 random strings and all queries with the same length ( left ) .",
    "comparison of quasi - balanced vs.  arbitrary query vectors over random strings , alphabet size @xmath378 , length @xmath380 , 10 strings .",
    "the data shown are averaged over all queries with same length @xmath18 ( right ) . ]",
    "our simulations appear to confirm that in practice the performance of the jumping algorithm is well predicted by the average case analysis we proposed .",
    "a more precise analysis is needed , however .",
    "our approach seems unlikely to lead to any refined average case analysis since that would imply improved results for the intricate variant of the coupon collector problem of  @xcite .",
    "we remark that our wavelet tree variant of the jumping algorithm , which uses rank / select operations only , opens a new perspective on the study of parikh vector matching .",
    "we have made another family of approximate pattern matching problems accessible to the use of self - indexing data structures  @xcite .",
    "we are particularly interested in compressed data structures which allow fast execution of rank and select operations , while at the same time using reduced storage space for the text .",
    "thus , every step forward in this very active area can provide improvements for our problem ."
  ],
  "abstract_text": [
    "<S> the parikh vector @xmath0 of a string @xmath1 over a finite ordered alphabet @xmath2 is defined as the vector of multiplicities of the characters , @xmath3 , where @xmath4 parikh vector @xmath5 occurs in @xmath1 if @xmath1 has a substring @xmath6 with @xmath7 . </S>",
    "<S> the problem of searching for a query @xmath5 in a text @xmath1 of length @xmath8 can be solved simply and worst - case optimally with a sliding window approach in @xmath9 time . </S>",
    "<S> we present two novel algorithms for the case where the text is fixed and many queries arrive over time .    </S>",
    "<S> the first algorithm only _ decides _ whether a given parikh vector appears in a binary text . </S>",
    "<S> it uses a linear size data structure and decides each query in @xmath10 time . </S>",
    "<S> the preprocessing can be done trivially in @xmath11 time .    </S>",
    "<S> the second algorithm finds all occurrences of a given parikh vector in a text over an arbitrary alphabet of size @xmath12 and has sub - linear expected time complexity . </S>",
    "<S> more precisely , we present two variants of the algorithm , both using an @xmath9 size data structure , each of which can be constructed in @xmath9 time . </S>",
    "<S> the first solution is very simple and easy to implement and leads to an expected query time of @xmath13 , where @xmath14 is the length of a string with parikh vector @xmath5 . </S>",
    "<S> the second uses wavelet trees and improves the expected runtime to @xmath15 , i.e. , by a factor of @xmath16 .    </S>",
    "<S> = 1    * keywords : * parikh vectors , permuted strings , pattern matching , string algorithms , average case analysis , text indexing , non - standard string matching </S>"
  ]
}