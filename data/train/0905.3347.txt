{
  "article_text": [
    "in pattern recognition , learning , and data mining one obtains information from objects containing information .",
    "this involves an objective definition of the information in a single object , the information to go from one object to another object in a pair of objects , the information to go from one object to any other object in a multiple of objects , and the shared information between objects , @xcite .    the classical notion of kolmogorov complexity @xcite is an objective measure for the information in an a _ single _ object , and information distance measures the information between a _",
    "pair _ of objects @xcite .",
    "this last notion has spawned research in the theoretical direction , among others @xcite .",
    "research in the practical direction has focused on the _ normalized _ information distance , the similarity metric , which arises by normalizing the information distance in a proper manner and approximating the kolmogorov complexity through real - world compressors @xcite , this normalized information distance is a parameter - free , feature - free , and alignment - free similarity measure that has had great impact in applications .",
    "a variant of this compression distance has been tested on all time sequence databases used in the last decade in the major data mining conferences ( sigkdd , sigmod , icdm , icde , ssdb , vldb , pkdd , pakdd ) @xcite .",
    "the conclusion is that the method is competitive with all 51 other methods used and superior in heterogenous data clustering and anomaly detection . in @xcite",
    "it was shown that the method is resistant to noise .",
    "this theory has found many applications in pattern recognition , phylogeny , clustering , and classification . for objects that are represented as computer files such applications range from weather forecasting , software , earthquake prediction , music , literature , ocr , bioinformatics , to internet @xcite . for objects that are only represented by name , or objects that are abstract like ` red , ' ` einstein , ' ` three , ' the normalized information distance uses background information provided by google , or any search engine that produces aggregate page counts .",
    "it discovers the ` meaning ' of words and phrases in the sense of producing a relative semantics .",
    "applications run from ontology , semantics , tourism on the web , taxonomy , multilingual questions , to question - answer systems @xcite . for more references on either subject see the textbook @xcite or google scholar for references to @xcite",
    ".    however , in many applications we are interested in shared information between many objects instead of just a pair of objects .",
    "for example , in customer reviews of gadgets , in blogs about public happenings , in newspaper articles about the same occurrence , we are interested in the most comprehensive one or the most specialized one .",
    "thus , we want to extend the information distance measure from pairs to multiples .      in @xcite",
    "the notion is introduced of the information required to go from any object in a multiple of objects to any other object in the multiple .",
    "this is applied to extracting the essence from , for example , a finite list of internet news items , reviews of electronic cameras , tv s , and so on , in a way that works better than other methods .",
    "let @xmath0 denote a finite list of @xmath1 finite binary strings defined by @xmath2 , the constituting strings ordered length - increasing lexicographic .",
    "we use lists and not sets , since if @xmath0 is a set we can not express simply the distance from a string to itself or between strings that are all equal .",
    "let @xmath3 be the reference universal turing machine , for convenience the prefix one as in section  [ sect.prel ] .",
    "given the string @xmath4 we define the information distance to any string in @xmath0 by @xmath5 for all @xmath6}. it is shown in @xcite , theorem 2 , that @xmath7 up to a logarithmic additive term .",
    "define @xmath8 .",
    "theorem 3 in @xcite states that for every list @xmath9 we have @xmath10 up to a logarithmic additive term .",
    "this is not a corollary of as stated in @xcite , but both inequalities follow from the definitions .",
    "the lefthand side is interpreted as the program length of the `` most comprehensive object that contains the most information about all the others [ all elements of @xmath0 ] , '' and the righthand side is interpreted as the program length of the `` most specialized object that is similar to all the others . ''",
    "the paper @xcite develops the stated results and applications .",
    "it does not develop the theory in any detail . that is the purpose of the present paper .",
    "information distance for multiples , that is , finite lists , appears both practically and theoretically promising . in all cases below the results imply the corresponding ones for the pairwise information distance defined as follows .",
    "the information distance in @xcite between strings @xmath12 and @xmath13 is @xmath14 . in the current paper @xmath15 .",
    "these two definitions coincide for @xmath16 since @xmath17 up to an additive constant term .",
    "we investigate the maximal overlap of information ( theorem  [ theo.maxo ] ) which for @xmath16 specializes to theorem 3.4 in @xcite , corollary  [ cor.1 ] shows and corollary  [ cor.2 ] shows that the lefthand side of can be taken to correspond to a single program embodying the `` most comprehensive object that contains the most information about all the others '' as stated but not argued or proved in @xcite ; metricity ( theorem  [ theo.metrics ] ) and universality ( theorem  [ t : optimal.cognitive.dist ] ) which for @xmath18 ( for metricity ) and @xmath16 ( for universality ) specialize to theorem 4.2 in @xcite ; additivity ( theorem  [ theo.additive ] ) ; minimum overlap of information ( theorem  [ thm - muchnik ] ) which for @xmath16 specializes to theorem 8.3.7 in @xcite ; and the nonmetricity of normalized information distance for lists of more than two elements and certain proposals of the normalizing factor ( section  [ sect.nid ] ) .",
    "in contrast , for lists of two elements we can normalize the information distance as in lemma v.4 and theorem v.7 of @xcite .",
    "the definitions are of necessity new as are the proof ideas .",
    "remarkably , the new notation and proofs for the general case are simpler than the mentioned existing proofs for the particular case of pairwise information distance .",
    "* kolmogorov complexity : * this is the information in a single object @xcite .",
    "the notion has been the subject of a plethora of papers .",
    "informally , the kolmogorov complexity of a finite binary string is the length of the shortest string from which the original can be losslessly reconstructed by an effective general - purpose computer such as a particular universal turing machine . hence it constitutes a lower bound on how far a lossless compression program can compress . for technical reasons we choose turing machines with a separate read - only input tape , that is scanned from left to right without backing up , a separate work tape on which the computation takes place , and a separate output tape . upon halting ,",
    "the initial segment @xmath19 of the input that has been scanned is called the input `` program '' and the contents of the output tape is called the `` output . '' by construction , the set of halting programs is prefix free .",
    "we call @xmath3 the reference universal prefix turing machine .",
    "this leads to the definition of `` prefix kolmogorov complexity '' which we shall designate simply as `` kolmogorov complexity . ''",
    "the _ conditional kolmogorov complexity _",
    "@xmath20 is the length of the shortest input @xmath21 such that the reference universal prefix turing machine @xmath3 on input @xmath21 with auxiliary information @xmath22 outputs @xmath23 .",
    "the _ unconditional kolmogorov complexity _",
    "@xmath24 is defined by @xmath25 where @xmath26 is the empty string ( of length 0 ) . in these definitions",
    "both @xmath23 and @xmath22 can consist of a nonempty finite lists of finite binary strings . for more details and theorems that are used in the present work see appendix  [ sect.kolm ] .",
    "* lists : * a _ list _ is a multiple @xmath27 of @xmath28 finite binary strings in length - increasing lexicographic order . if @xmath0 is a list , then some or all of its elements may be equal .",
    "thus , a list is not a set but an ordered _ bag _ of elements . with some abuse of the common set - membership notation we write @xmath29 for every @xmath30 ( @xmath31 ) to mean that `` @xmath4 is an element of list @xmath0 . ''",
    "the conditional prefix kolmogorov complexity @xmath32 of a list @xmath0 given an element @xmath23 is the length of a shortest program @xmath19 for the reference universal turing machine that with input @xmath23 outputs the list @xmath0 .",
    "the prefix kolmogorov complexity @xmath33 of a list @xmath0 is defined by @xmath34 .",
    "one can also put lists in the conditional such as @xmath35 or @xmath36 .",
    "we will use the straightforward laws @xmath37 and @xmath38 up to an additive constant term , for @xmath39 and @xmath40 equals the list @xmath0 with the element @xmath23 deleted .    *",
    "information distance : * to obtain the _ pairwise information distance _ in @xcite we take @xmath41 in . then is equivalent to @xmath42 .",
    "we use the notation and terminology of section  [ sect.relwork ] . define @xmath43 , @xmath44 , and @xmath45 .",
    "we prove a _",
    "maximal overlap _ theorem : the information needed to go from any @xmath4 to any @xmath46 in @xmath0 can be divided in two parts : a single string of length @xmath47 and a string @xmath48 of length @xmath49 ( possibly depending on @xmath4 ) , everything up to an additive logarithmic term .",
    "[ theo.maxo ] a single program of length @xmath50 bits concatenated with a string of @xmath49 bits , possibly depending on @xmath30 , suffice to find @xmath0 from @xmath4 for every @xmath29 . to find an arbitrary element @xmath51 from @xmath4 it suffices to concatenate at most another @xmath52 bits , possibly depending on @xmath30 and @xmath53 .",
    "enumerate the finite binary strings lexicographic length - increasing as @xmath54 let @xmath55 be a graph defined as follows .",
    "let @xmath56 be the set of finite binary strings and @xmath57 the set of vectors of strings in @xmath56 defined by @xmath58 such that @xmath59 given @xmath47 and @xmath60 the set @xmath57 can be enumerated .",
    "define @xmath61 .",
    "define @xmath62 by length - increasing lexicographic enumerating @xmath63 and put @xmath64 with @xmath65 and @xmath66 if @xmath67 for some @xmath68 ( @xmath69 ) , where @xmath48 is chosen as follows .",
    "it is the @xmath70th string of length @xmath49 where @xmath30 is the number of times we have used @xmath71 .",
    "so the first @xmath72 times we choose an edge @xmath73 we use @xmath74 , the next @xmath72 we use @xmath75 , and so on . in this way , @xmath76 so that @xmath77 . by adding @xmath48 to @xmath78 we take care that the degree of @xmath79 is at most @xmath72 and not at most @xmath80 as it could be without the prefix @xmath48 .",
    "the degree of a node @xmath81 is trivially @xmath1 .",
    "in addition , we enumerate @xmath57 length - increasing lexicographic and ` color ' everyone of the @xmath1 edges incident with an enumerated vector @xmath81 with the same binary string @xmath82 of length @xmath83 . if @xmath84 and @xmath85 is connected by edges to nodes @xmath86 , then choose @xmath82 as the minimum color not yet appearing on any edge incident with any @xmath87 ( @xmath69 ) .",
    "since the degree of every node @xmath65 is bounded by @xmath72 and hence the colors already used for edges incident on nodes @xmath86 number at most @xmath88 , a color is always available .    knowing @xmath89 one can reconstruct @xmath90 and color its edges . given an element @xmath23 from the list @xmath0 , and knowing the appropriate string @xmath48 of length @xmath49 and the color @xmath82 of the edge @xmath91 , we can find @xmath0 .",
    "hence a single program , say @xmath19 , of length @xmath92 bits suffices to find @xmath0 from @xmath93 for any @xmath39 and with @xmath94 .",
    "an additional @xmath52 bits suffice to select any element of @xmath0 .",
    "taking these @xmath52 bits so that they encode the difference from @xmath30 to @xmath95 we can compute from every @xmath29 to every @xmath51 and vice versa with the same program @xmath19 of length @xmath92 concatenated with a string @xmath48 of length @xmath49 and a string of length @xmath52 , both possibly depending on @xmath30 and @xmath53 .",
    "since we know @xmath89 from the fixed program @xmath19 , where they are encoded as a self - delimiting prefix of length @xmath96 say , we can concatenate these strings without separation markers and reconstruct them .",
    "[ cor.1 ] since @xmath97 , the theorem implies , that is , theorem 2 of @xcite .",
    "it is not a priori clear that @xmath98 in the lefthand side of corresponds to a _",
    "program that represents the information overlap of every shortest program going from any @xmath4 to the list @xmath0 .",
    "this seems in fact assumed in @xcite where @xmath98 is interpreted as the [ kolmogorov complexity of ] `` the most comprehensive object that contains the most information about all the others . ''",
    "in fact , for every @xmath29 we can choose a shortest program going from @xmath4 to the list @xmath0 so that these programs have pairwise no information overlap at all ( theorem  [ thm - muchnik ] ) .",
    "but here we have proved :    [ cor.2 ] the quantity @xmath98 corresponds to a _ single _",
    "shortest program that represents the maximum overlap of information of all programs going from @xmath4 to the list @xmath0 for any @xmath29 .",
    "we consider nonempty finite lists of finite binary strings , each list ordered length - increasing lexicographic .",
    "let @xmath99 be the set of such ordered nonempty finite lists of finite binary strings .",
    "a _ distance function _",
    "@xmath100 on @xmath99 is defined by @xmath101 where @xmath102 is the set of nonnegative real numbers .",
    "define @xmath103 if @xmath104 is a list of the elements of the lists @xmath3 and @xmath105 and the elements of @xmath104 are ordered length - increasing lexicographical .",
    "a distance function @xmath100 is a _",
    "metric _ if @xmath106 and    1 .",
    "_ positive definiteness _ : @xmath107 if all elements of @xmath0 are equal and @xmath108 otherwise .",
    "symmetry _ : @xmath109 is invariant under all permutations of @xmath0 .",
    "triangle inequality _ : @xmath110 .",
    "[ theo.metrics ] the information distance for lists , @xmath111 , is a metric where the ( in)equalities hold up to a @xmath112 additive term . here",
    "@xmath113 is the largest quantity involved in the metric ( in)equalities .",
    "it is clear that @xmath114 satisfies positive definiteness and symmetry up to an @xmath115 additive term where @xmath116 .",
    "it remains to show the triangle inequality .",
    "let @xmath117 be three nonempty finite lists of finite binary strings and @xmath118 .",
    "then , @xmath119 up to an @xmath112 additive term .    by theorem  [ theo.maxo ]",
    ", @xmath120 equalities up to a @xmath112 additive term . here",
    "@xmath121 are the elements for which the maximum is reached for the respective @xmath111 s .",
    "assume that @xmath122 , the case @xmath123 being symmetrical .",
    "let @xmath21 be some element of @xmath124 .",
    "then , @xmath125 the first inequality follows from the general @xmath126 , the second inequality by the obvious subadditive property of @xmath127 , the third inequality since in the first term @xmath128 and the @xmath129 is reached for @xmath130 and in the second term both @xmath122 and for @xmath21 take any element from @xmath124 , and the fourth inequality follows by in the second term dropping @xmath0 from the conditional and moving @xmath124 from the conditional to the main argument and observing that both @xmath131 and the @xmath132 is reached for @xmath133 .",
    "the theorem follows with ( in)equalities up to an @xmath112 additive term .",
    "let @xmath134 . a priori we allow asymmetric distances . we would like to exclude degenerate distance measures such as @xmath135 for all @xmath0 .",
    "for each @xmath100 , we want only finitely many lists @xmath0 such that @xmath136 .",
    "exactly how fast we want the number of lists we admit to go to @xmath137 is not important ; it is only a matter of scaling . for every distance @xmath138 we require the following _ density condition _ for every @xmath139 : @xmath140 thus , for the density condition on @xmath138 we consider only lists @xmath0 with @xmath141 and not all elements of @xmath0 are equal .",
    "moreover , we consider only distances that are computable in some broad sense .",
    "an _ admissible list distance _",
    "@xmath142 is a total , possibly asymmetric , function from @xmath99 to the nonnegative real numbers that is 0 if all elements of @xmath0 are equal , and greater than @xmath143 otherwise ( up to an additive @xmath144 additive term with @xmath145 ) , is upper semicomputable , and satisfies the density requirement in .",
    "[ t : optimal.cognitive.dist ] the list information distance @xmath146 is admissible and it is minimal in the sense that for every admissible list distance function @xmath142 we have @xmath147 up to an additive constant term .",
    "it is straightforward that @xmath146 is a total real - valued function , is 0 only if all elements of @xmath0 are equal and unequal 0 otherwise ( up to an @xmath112 additive term with @xmath145 ) , and is upper semicomputable .",
    "we verify the density requirement of . for every @xmath139 , consider lists @xmath0 of at least two elements not all equal and @xmath39 .",
    "define functions @xmath148 .",
    "then , @xmath149 .",
    "it is easy to see that for every @xmath139 , @xmath150 where the righthand sum is taken over all programs @xmath19 for which the reference prefix machine @xmath3 , given @xmath23 , computes a finite list @xmath0 of at least two elements not all equal and such that @xmath39 .",
    "this sum is the probability that @xmath3 , given @xmath23 , computes such a list @xmath0 from a program @xmath19 generated bit by bit uniformly at random .",
    "therefore , the righthand sum is at most 1 , and @xmath146 satisfies the density requirement .",
    "we prove minimality .",
    "fix any @xmath139 . since @xmath138 is upper semicomputable ,",
    "the function @xmath151 defined by @xmath152 for @xmath0 satisfying @xmath39 and @xmath153 , and 0 otherwise , is lower semicomputable . since @xmath154",
    ", we have @xmath155 for every @xmath23 . note that given @xmath138 we can compute @xmath151 , and hence @xmath156 .",
    "by the conditional version of in @xcite theorem 4.3.2 , we have @xmath157 with @xmath158 , that is , @xmath159 is a positive constant depending on @xmath138 only . by the conditional version of in @xcite theorem 4.3.4",
    ", we have for every @xmath39 that @xmath160 .",
    "hence , for every @xmath39 we have @xmath161 .",
    "altogether , for every admissible distance @xmath138 and every @xmath139 , and every list @xmath0 satisfying @xmath39 , there is a constant @xmath162 such that @xmath163 .",
    "hence , @xmath164 .",
    "[ theo.additive ] @xmath111 is not subadditive : neither @xmath165 nor @xmath166 , the ( in)equalities up to logarithmic additive terms , holds for all lists @xmath167 .",
    "below , all ( in)equalities are taken up to logarithmic additive terms .",
    "let @xmath168 be strings of length @xmath169 , @xmath170 and @xmath171 with @xmath26 denoting the empty word .",
    "then @xmath172 , @xmath173 , and @xmath174 .",
    "if @xmath175 and @xmath176 , then @xmath177 . hence , @xmath178 .",
    "let @xmath168 be strings of length @xmath169 such that @xmath179 , @xmath180 , @xmath181 , and @xmath182 .",
    "then @xmath183 , @xmath184 , and @xmath185 .",
    "hence , @xmath186 .",
    "let @xmath187 and @xmath188 .",
    "note that subadditivity holds for lists of singleton elements since @xmath189 , where the equality holds up to an additive @xmath190 term and the inequality holds up to an additive constant term ..",
    "let @xmath191 and @xmath192 be a shortest program converting @xmath4 to @xmath0 ( @xmath193 ) .",
    "naively we expect that the shortest program that that maps @xmath4 to @xmath0 contains the information about @xmath0 that is lacking in @xmath4 . however , this is too simple , because different short programs mapping @xmath4 to @xmath0 may have different properties .",
    "for example , suppose @xmath194 and both elements are strings of length @xmath169 with @xmath195 .",
    "let @xmath19 be a program that ignores the input and prints @xmath23 .",
    "let @xmath196 be a program such that @xmath197 ( that is , @xmath198 ) , where @xmath199 denotes bitwise addition modulo 2 .",
    "then , the programs @xmath19 and @xmath196 have nothing in common .",
    "now let @xmath23 and @xmath22 be arbitrary strings of length at most @xmath169 .",
    "muchnik , theorem 8.3.7 in @xcite , shows that there exists a shortest program @xmath19 that converts @xmath22 to @xmath23 ( that is , @xmath200 and @xmath201 ) , such that @xmath19 is simple with respect to @xmath23 and therefore depends little on the origin @xmath22 , that is , @xmath202 ) .",
    "this is a fundamental coding property for individual strings that parallels related results about random variables known as the slepian  wolf and csiszr  krner ",
    "marton theorems @xcite .",
    "[ thm - muchnik ] let @xmath203 be a list of binary strings of length at most @xmath169 .",
    "for every @xmath29 there exists a string @xmath192 of length @xmath204 such that @xmath205 and @xmath206 .",
    "muchnik s theorem as stated before gives a code @xmath19 for @xmath23 when @xmath22 is known .",
    "there , we assumed that @xmath23 and @xmath22 have length at most @xmath169 .",
    "the proof in @xcite does not use any assumption about @xmath22 .",
    "hence we can extend the result to information distance in finite lists as follows .",
    "suppose we encode the constituent list elements of @xmath0 self - delimitingly in altogether @xmath207 bits ( now @xmath0 takes the position of @xmath23 and we consider strings of length at most @xmath207 ) .",
    "substitute @xmath22 by @xmath4 for some @xmath30 ( @xmath193 )",
    ". then the theorem above follows straightforwardly from muchnik s original theorem about two strings of length at most @xmath169 .",
    "the code @xmath192 is not uniquely determined .",
    "for example , let @xmath208 and @xmath21 be a string such that @xmath209 , @xmath210 , and and @xmath211 .",
    "then , both @xmath21 and @xmath212 can be used for @xmath19 with @xmath213 and @xmath214 . but",
    "@xmath21 and @xmath212 have no mutual information at all .    [ th.vere ]",
    "let @xmath215 .",
    "for every string @xmath4 there is a program @xmath192 such that @xmath216 ( @xmath193 ) , where @xmath217 , and @xmath218 @xmath219 , and the last four equalities hold up to an additive @xmath220 term .",
    "the quantitative difference in a certain feature between many objects can be considered as an admissible distance , provided it is upper semicomputable and satisfies the density condition .",
    "theorem  [ t : optimal.cognitive.dist ] shows that @xmath111 is universal in that among all admissible list distances in that it is always least .",
    "that is , it accounts for the dominant feature in which the elements of the given list are alike .",
    "many admissible distances are absolute , but if we want to express similarity , then we are more interested in relative ones . for example , if two strings of @xmath221 bits have information distance @xmath222 bits , then we are inclined to think that those strings are relatively similar .",
    "but if two strings of @xmath222 bits have information distance @xmath222 bits , then we find them very different .",
    "therefore , our objective is to normalize the universal information distance @xmath111 to obtain a universal similarity distance",
    ". it should give a similarity with distance 0 when the objects in a list are maximally similar ( that is , they are equal ) and distance 1 when they are maximally dissimilar .",
    "naturally , we desire the normalized version of the universal list information distance metric to be also a metric . for pairs of objects ,",
    "say @xmath168 , the normalized version @xmath223 of @xmath111 defined by @xmath224 takes values in @xmath225 $ ] and is a metric .",
    "several alternatives for the normalizing factor @xmath226 do not work .",
    "dividing by the length , either the sum or the maximum does not satisfy the triangle property .",
    "dividing by @xmath227 results in @xmath228 for @xmath229 and @xmath230 ( and hence @xmath231 ) , and this is improper as @xmath232 should be 1 in this case .",
    "we would like a proposal for a normalization factor for lists of more than two elements to reduce to that of for lists restricted to two elements .",
    "this leads to the proposals below , which turn out to be improper .    as a counterexample to normalization",
    "take the following lists : @xmath187 , @xmath233 , and @xmath234 . with @xmath229 and the equalities below up to an @xmath235 additive term",
    "we define : @xmath236 , @xmath237 , and @xmath238 . using the symmetry of information we have @xmath239 .",
    "let @xmath240 be lists .",
    "we show that for the proposals below the triangle property @xmath241 is violated .",
    "* consider the normalized list information distance @xmath242 that is , we divide @xmath243 by @xmath244 with @xmath245 where the list @xmath246 equals the list @xmath105 with the @xmath30th element deleted ( @xmath247 ) .",
    "then , with equalities holding up to @xmath248 we have : @xmath249 , @xmath250 , and @xmath251 .",
    "hence the triangle inequality does not hold .",
    "* instead of dividing by @xmath244 in divide by @xmath252 where @xmath253 equals @xmath105 with @xmath254 deleted . the same counterexample to the triangle inequality holds . * instead of dividing by @xmath244 in divide by @xmath255 where @xmath256 is the set of elements in @xmath257 . to equate the sets approximately with the corresponding lists , change @xmath124 to @xmath258 where @xmath259 equals @xmath22 but with the @xmath30th bit flipped ( @xmath260 ) .",
    "again , the triangle inequality does not hold . * instead of dividing by @xmath252 in divide by @xmath261 where @xmath262 is the set of elements in @xmath253 . change @xmath124 as in the previous item .",
    "again , the triangle inequality does not hold .",
    "theory and applications are given in the textbook @xcite . here",
    "we give some relations that are needed in the paper . the _ information about @xmath23 contained in @xmath22 _ is defined as @xmath263 .",
    "a deep , and very useful , result due to l.a .",
    "levin and a.n .",
    "kolmogorov @xcite called _ symmetry of information _ shows that @xmath264 with the equalities holding up to @xmath144 additive precision . here , @xmath265 . hence , up to an additive logarithmic term @xmath266 and we call this the _ mutual ( algorithmic ) information _ between @xmath23 and @xmath22 .",
    "there exists a lower semicomputable function @xmath268 $ ] with @xmath269 , such that for every lower semicomputable function @xmath270 $ ] with @xmath271 we have @xmath272 for every @xmath23 . here",
    "@xmath273 is the length of a shortest program for the reference universal prefix turing machine to lower semicompute the function @xmath274 .",
    "for every @xmath275 , @xmath276 with equality up to an additive constant independent of @xmath23 .",
    "thus , the kolmogorov complexity of a string @xmath23 coincides up to an additive constant term with the logarithm of @xmath277 and also with the logarithm of @xmath278 .",
    "this result is called the `` coding theorem '' since it shows that the shortest upper semicomputable code is a shannon - fano code of the greatest lower semicomputable probability mass function .",
    "chernov , an.a .",
    "muchnik , a.e .",
    "romashchenko , a.k .",
    "shen , n.k .",
    "vereshchagin , upper semi - lattice of binary strings with the relation `` @xmath23 is simple conditional to @xmath22 '' , _ theor .",
    "_ , 271:12(2002 ) , 6995 .",
    "b. hu and b. hu , on capturing semantics in ontology mapping , _ world wide web _ , 11:3(2008 ) , 361385 .",
    "e. keogh , s. lonardi , c.a .",
    "ratanamahatana , l. wei , h.s .",
    "lee , and j. handley , compression - based data mining of sequential data , _ data mining and knowledge discovery _ , 14:1(2007 ) , 99129 .",
    "a. kocsor , a. kertsz - farkas , l. kajn , and s. pongor , application of compression - based distance measures to protein sequence classification : a methodology study , _ bioinformatics _ , 22:4(2006 ) , 407412 .",
    "m. li , j. badger , x. chen , s. kwong , p. kearney , and h. zhang , an information - based sequence distance and its application to whole mitochondrial genome phylogeny , _ bioinformatics _ , 17:2(2001 ) , 149154 .",
    "m. nykter , n.d .",
    "price , m. aldana , s.a .",
    "ramsey , s.a .",
    "kauffman , l.e .",
    "hood , o. yli - harja , and i. shmulevich , gene expression dynamics in the macrophage exhibit criticality , _ proc .",
    "usa _ , 105:6(2008 ) , 18971900 .",
    "m. nykter , n.d .",
    "price , a. larjo , t. aho , s.a .",
    "kauffman , o. yli - harja and i. shmulevich , critical networks exhibit maximal information diversity in structure - dynamics relationships , _ physical review lett .",
    "_ , 100(2008 ) , 058702(4 ) .",
    "j. zhou , s. wang , and c. cao , a google - based statistical acquisition model of chinese lexical concepts , proc .",
    "knowledge science , engineering and management , _ lect .",
    "notes comp .",
    "_ , vol . 4798 , springer , 2007 , 243254 .",
    "zvonkin and l.a .",
    "levin , the complexity of finite objects and the development of the concepts of information and randomness by means of the theory of algorithms , _ russian math . surveys _ 25:6 ( 1970 ) 83 - 124 ."
  ],
  "abstract_text": [
    "<S> information distance is a parameter - free similarity measure based on compression , used in pattern recognition , data mining , phylogeny , clustering , and classification . </S>",
    "<S> the notion of information distance is extended from pairs to multiples ( finite lists ) . </S>",
    "<S> we study maximal overlap , metricity , universality , minimal overlap , additivity , and normalized information distance in multiples . </S>",
    "<S> we use the theoretical notion of kolmogorov complexity which for practical purposes is approximated by the length of the compressed version of the file involved , using a real - world compression program .    _ index terms_ information distance , multiples , pattern recognition , data mining , similarity , kolmogorov complexity </S>"
  ]
}