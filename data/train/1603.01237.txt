{
  "article_text": [
    "the general goal of quantum control is to actively manipulate dynamical processes at the atomic or molecular scale  @xcite . in recent years",
    ", the advances in quantum control have emerged through the introduction of appropriate and powerful tools coming from mathematical control theory and by the use of sophisticated experimental techniques to shape the corresponding control fields  @xcite . in this framework ,",
    "different numerical optimal control algorithms @xcite have been developed and applied to a large variety of quantum systems .",
    "optimal control was used in physical chemistry in order to steer chemical reactions  @xcite , but also for spin systems  @xcite with applications in nuclear magnetic resonance  @xcite and magnetic resonance imaging  @xcite . recently",
    ", optimal control has attracted attention in view of applications to quantum information processing , for example as a tool to implement high - fidelity quantum gates in minimum time  @xcite .",
    "generally , algorithms can also be designed to account for experimental imperfections or constraints related to a specific material or device @xcite .",
    "the possibility of including such constraints renders optimal control theory more useful in view of experimental applications and helps bridge the gap between control theory and control experiments .",
    "the standard numerical optimal control algorithms based on an iterative procedure compute the control fields through many time propagations of the state of the system , which can be prohibitive for systems of large dimensions in terms of computational time .",
    "this numerical limit can be bypassed by making use of parallel computing  @xcite . in the case the computational time is divided by the number of computers , the method is said to be fully efficient",
    ". this full efficiency can be viewed as the physical limit in terms of performance of a parallel algorithm . while in applied mathematics different techniques",
    "have been developed using space or time decomposition  @xcite , very little has been done in quantum mechanics .",
    "the exponential growth of the hilbert space dimension with the system size makes this question even more crucial in order to simulate the dynamics of complex quantum systems .",
    "note that quantum control computations can also be speeded up by the parallelization of matrix exponential algorithms @xcite and by parallelizing density operator time evolutions using minimal sets of pure states @xcite .",
    "this paper is not aimed at proposing a new optimization approach , but rather at describing and studying a general framework , namely the intermediate state method ( ism ) , introduced in @xcite , which uses a time - parallelization to speed up the computation of optimal control fields .",
    "we investigate the efficiency of ism on three benchmark quantum control problems , ranging from the control of coupled spin systems and the control of molecular orientation to the control of bose - einstein condensates . as a by - product",
    ", we show under which conditions ism can be made fully efficient .",
    "the paper is organized as follows .",
    "section  [ sec:2 ] is dedicated to the description of the time - parallelization method .",
    "the numerical schemes involved in this algorithm are defined in sec .",
    "[ sec:3 ] .",
    "numerical results on the control of spin systems , molecular orientation and bose - einstein condensates are presented in sec .",
    "[ sec:4 ] . conclusion and prospective views are given in sec .",
    "[ sec:5 ] .",
    "we first introduce the optimal control problem and we derive the corresponding optimality conditions . we consider pure quantum states and we assume that the time evolution is coherent . note that the formalism can be easily extended to mixed states or to the control of evolution operators  @xcite .",
    "the control process is aimed at maximizing the transfer of population onto a target state , but modification of the algorithms in view of optimizing the expectation value of an observable is straightforward .",
    "the dynamics of the quantum system is governed by the hamiltonian @xmath0 .",
    "the initial and target states are denoted by @xmath1 and @xmath2 , respectively and the general state of the system at time @xmath3 , by @xmath4 .",
    "the dynamics of the quantum system is governed by the schrdinger equation : @xmath5 where @xmath6 is the field to be determined .",
    "the control time @xmath7 is fixed .",
    "the objective of the control problem is to maximize the figure of merit @xmath8 @xmath9=\\re [ \\langle\\psi(t)|\\psi_{f}\\rangle]-\\frac\\alpha2\\int_0^t u(t)^2dt,\\ ] ] @xmath10 being a positive parameter which expresses the relative weight between the projection onto the target state and the energy of the control field .",
    "a necessary condition to ensure the optimality of @xmath11 is given by the cancellation of the gradient of @xmath8 with respect to @xmath11 @xcite : @xmath12(t)=-\\alpha u(t)+\\im [ \\langle \\chi(t ) |\\partial_{u(t ) } h ( u(t))|\\psi(t)\\rangle]=0,\\ ] ] where @xmath13 is the adjoint state that satisfies @xmath14 with the final condition @xmath15 .",
    "we now present ism .",
    "a schematic description is displayed in fig .",
    "[ fig0 ] .",
    "( init ) at ( 0,0 ) ; ( cible ) at ( 5,3 ) ; ( p1 ) at ( 1,1/25 * 1 ^ 2+.2*sin(40*pi*1)+1/5*(3 - 1/25 * 5 ^ 2-.2*sin(40*pi*5 ) ) ) ; ( p2 ) at ( 2,1/25 * 2 ^ 2+.2*sin(40*pi*2)+2/5*(3 - 1/25 * 5 ^ 2-.2*sin(40*pi*5 ) ) ) ; ( p3 ) at ( 3,1/25 * 3 ^ 2+.2*sin(40*pi*3)+3/5*(3 - 1/25 * 5 ^ 2-.2*sin(40*pi*5 ) ) ) ; ( p4 ) at ( 4,1/25 * 4 ^ 2+.2*sin(40*pi*4)+4/5*(3 - 1/25 * 5 ^ 2-.2*sin(40*pi*5 ) ) ) ;    ( 0,1 )  ( 2,0 )  ( 0,-1) ( .5,0 )  ( 0,1 ) ;    ( 0,1 )  ( 2,0 )  ( 0,-1)(.5,0 )  ( 0,1 ) ;    ( 0,1 )  ( 2,0 )  ( 0,-1) ( .5,0 )  ( 0,1 ) ;    ( 0,1 )  ( 2,0 )  ( 0,-1) ( .5,0 )  ( 0,1 ) ;    ( init ) node @xmath16 ( cible ) node @xmath16 ; ( 0,-.5 )  ( 5.5,-.5 ) ; ( 0,-.6 )  ( 0,-.4 ) ( 1,-.6 )  ( 1,-.4 ) ( 2,-.6 )  ( 2,-.4 ) ( 3,-.6 )  ( 3,-.4 ) ( 4,-.6 )  ( 4,-.4 ) ( 5,-.6 )  ( 5,-.4 ) ;    ( -.2,-.8 ) node @xmath17 ; ( 5.2,-.8 ) node @xmath18 ;    ( 3+.2,1.4 ) to[bend left=30 ] ( 7,1/25 * 3 ^ 2+.2*sin(40*pi*3)+3/5*(3 - 1/25 * 5 ^ 2-.2*sin(40*pi*5))+.2 - 2 ) ; ( 6.1,-3 ) to[bend left=40 ] ( 2.5,-2.2 ) ;    ( 7.2,1.5 ) node @xmath19 ; ( -.2,.6 ) node _",
    "@xmath1 _ ; ( 5.85,3 ) node _",
    "@xmath2 _ ; ( 4,0.2 ) node _",
    "@xmath20 _ ; ( 2,2.7 ) node _ @xmath21 _ ;    plot [ domain=0:5 ] ( , 1/25*^2+.2*sin(40*pi * ) ) ; plot [ domain=0:5 ] ( , 1/25*^2+.2*sin(40*pi * ) + 3 - 1/25 * 5 ^ 2-.2*sin(40*pi*5 ) ) ; plot [ domain=0:5 ] ( , 1/25*^2+.2*sin(40*pi*)+/5*(3 - 1/25 * 5 ^ 2-.2*sin(40*pi*5 ) ) ) ;    ( p1 ) node @xmath16 ; ( p2 ) node @xmath16 ; ( p3)node @xmath16 ; ( p4 ) node @xmath16 ;    ( 2-.2,1/25 * 2 ^ 2+.2*sin(40*pi*2)+2/5*(3 - 1/25 * 5 ^ 2-.2*sin(40*pi*5))-.2 ) rectangle ( 3+.2,1/25 * 3 ^ 2+.2*sin(40*pi*3)+3/5*(3 - 1/25 * 5 ^ 2-.2*sin(40*pi*5))+.2 ) ;    ( 2-.2,1/25 * 2 ^ 2+.2*sin(40*pi*2)+2/5*(3 - 1/25 * 5 ^ 2-.2*sin(40*pi*5))-.75 ) rectangle ( 3+.2,1/25 * 3 ^ 2+.2*sin(40*pi*3)+3/5*(3 - 1/25 * 5 ^ 2-.2*sin(40*pi*5))+.2 ) ;    ( 2,1/25 * 2 ^ 2+.2*sin(40*pi*2)+2/5*(3 - 1/25 * 5 ^ 2-.2*sin(40*pi*5))-.1 ) rectangle ( 3,1/25 * 3 ^ 2+.2*sin(40*pi*3)+3/5*(3 - 1/25 * 5 ^ 2-.2*sin(40*pi*5))+.1 ) ; plot [ domain=0:5,samples=200 ] ( , 1/11*^2-.1*sin(160*pi * ) - 1/11 * 2 ^ 2+.1*sin(160*pi*2 ) + 2/5*(3 - 1/25 * 5 ^ 2-.2*sin(40*pi*5 ) ) ) ; plot [ domain=0:5,samples=200 ] ( , 1/11*^2-.1*sin(160*pi * ) - 1/11 * 3 ^ 2+.1*sin(160*pi*3 ) + 1/25 * 3 ^ 2+.2*sin(40*pi*3)+3/5*(3 - 1/25 * 5 ^ 2-.2*sin(40*pi*5 ) ) ) ;    ( 2,1/25 * 2 ^ 2+.2*sin(40*pi*2)+2/5*(3 - 1/25 * 5 ^ 2-.2*sin(40*pi*5 ) ) ) node @xmath16 ( 3,1/25 * 3 ^ 2+.2*sin(40*pi*3)+3/5*(3 - 1/25 * 5 ^ 2-.2*sin(40*pi*5 ) ) ) node @xmath16 ; ( 1.9,.6 ) ",
    "( 3.15,.6 ) ; ( 2,.7 ) ",
    "( 2,.5 ) ( 3,.7 ) ",
    "( 3,.5 ) ; ( 2,.3 ) node @xmath22 ; ( 3,.3 ) node @xmath23 ; ( 2.9,.9 ) node @xmath24 ; ( 2.2,1.7 ) node @xmath25 ;    ( .5,-.6 )  ( .5,-1 ) ; at(.5,-1.6)_cpu",
    "1 _ ; ( 1.5,-.6 )  ( 1.5,-1 ) ; at(1.5,-1.6)_cpu 2 _ ; ( 2.5,-.6 )  ( 2.5,-1 ) ; at(2.5,-1.6)_cpu 3 _ ; ( 3.5,-.6 ) ",
    "( 3.5,-1 ) ; at(3.5,-1.6)_cpu 4 _ ; ( 4.5,-.6 )  ( 4.5,-1 ) ; at(4.5,-1.6)_cpu 5 _ ;    the main idea consists in considering a combination of the trajectories followed by @xmath4 and @xmath21  @xcite . given @xmath26",
    ", we decompose the interval @xmath27 $ ] into a partition of sub - intervals @xmath27=\\cup_{n=0}^{n-1 } [ t_n , t_{n+1}]$ ] , with @xmath28 .",
    "the parallelization strategy is based on this decomposition .",
    "we consider an arbitrary control @xmath11 and we introduce the sequence @xmath29 that interpolates the state and adjoint state trajectories at time @xmath22 as follows : @xmath30 and @xmath13 are defined by eqs .   and , respectively .",
    "note that @xmath31 does not sample any usual dynamics , e.g. @xmath31 does not correspond to a solution of eq .  .",
    "its initial and final states are @xmath32 and @xmath33 , respectively . the choice of intermediate states made in eq .",
    "is crucial to demonstrate theorem [ th:1 ] below @xcite .",
    "we then introduce in each sub - interval the optimal control problem @xmath34 $ ] defined by the maximization of the sub - functional : @xmath35= -\\frac{1}{2 } || |\\psi_n(t_{n+1})\\rangle -|\\phi_{n+1}^u\\rangle ||^2 \\\\ & & -\\frac{\\alpha_n}2\\int_{t_n}^{t_{n+1 } } u_n(t)^2dt,\\end{aligned}\\ ] ] with @xmath36 . in this problem , the state @xmath37",
    "is defined on @xmath38 $ ] by : @xmath39 starting from @xmath40 .",
    "the penalization coefficient is defined by @xmath41 . since @xmath35=-\\frac{1}{2}|| |\\psi_n(t_{n+1})\\rangle ||^2-\\frac{1}{2}|| |\\phi_{n+1}^u\\rangle ||^2 \\\\ & & + \\re[\\langle \\psi_n(t_{n+1})|\\phi^{u}_{n+1}\\rangle]-\\frac{\\alpha_n}2\\int_{t_n}^{t_{n+1 } } u_n(t)^2dt,\\end{aligned}\\ ] ] maximizing @xmath42 with respect to @xmath11 is equivalent to maximize a figure of merit of the form : @xmath43-\\frac{\\alpha_n}2\\int_{t_n}^{t_{n+1 } }   u_n(t)^2dt$ ] . in this way",
    ", each sub - problem has the same structure as the initial one .",
    "we now review some properties of the time decomposition in order to establish the relation with the original optimal control problem . given an arbitrary trajectory @xmath44 , we define an auxiliary figure of merit : @xmath45=\\sum_{n=0}^{n-1}\\beta_{n}{\\mathcal{j}}_{n}[u_n,|\\phi\\rangle ] , \\ ] ] with @xmath46 . a first relation between @xmath47 and @xmath8",
    "is given in theorem [ th:1 ] ( see ref .",
    "@xcite for the proof ) .",
    "[ th:1 ] given an arbitrary control @xmath11 , we have : @xmath48\\big).\\ ] ] moreover , the following relation is satisfied : @xmath49={\\mathcal{j}}[u].\\ ] ]    as a by - product , this theorem allows us to compute in parallel @xmath50 $ ] , knowing only the sequence @xmath51 .",
    "a similar relation also holds between the gradients of the functionals , as stated in theorem [ th : gradient ] .",
    "[ th : gradient ] given an arbitrary control @xmath11 , we have : @xmath52_{|[t_{n},t_{n+1 } ] } = \\beta_{n}\\nabla { \\mathcal{j}}_n [ { u_{|[t_{n},t_{n+1}]}},|\\phi^{u}\\rangle].\\ ] ]    this result provides a new interpretation of the time - parallelized method since the sequence @xmath53 , @xmath54 of intermediate states enables the decomposition of the computation of the gradient .",
    "+ _ proof : _ let us consider a fixed value @xmath55 , with @xmath36 , @xmath56 $ ] and denote by @xmath25 and @xmath57 the trajectories defined by @xmath58 and @xmath59 with @xmath60 and @xmath61 . for @xmath56",
    "$ ] , we repeat with @xmath42 the computation made to derive the gradient of @xmath8 : @xmath62 } , |\\phi^{u}\\rangle ] ( t ) & = & \\im\\left(\\langle \\chi_n(t)|\\partial_{u(t)}h|\\psi_n(t)\\rangle \\right)\\\\ & & -\\alpha_n u(t).\\end{aligned}\\ ] ] using the fact that : @xmath63 and @xmath64 we arrive at : @xmath62},|\\phi^{u}\\rangle](t ) & = & \\frac{1}{\\beta_n}\\im\\left(\\langle \\chi(t)|\\partial_{u(t)}h |\\psi(t)\\rangle \\right)\\\\ \\\\&&-\\frac{\\alpha}{\\beta_n}u(t),\\end{aligned}\\ ] ] and the result follows . +",
    "we now give the general structure of ism .",
    "let @xmath65 and @xmath66 be an initial control field .",
    "[ alg : ism ]    1 .",
    "set @xmath67 , @xmath68 .",
    "2 .   while @xmath69 , do : + 1 .",
    "[ etape:1 ] compute on @xmath27 $ ] the trajectories @xmath70 and @xmath71 associated with @xmath72 according to eqs .   and  .",
    "[ etape:2 ] compute @xmath73 according to eq .  .",
    "[ etape:3 ] on each sub - interval @xmath38 $ ] compute in parallel an approximation of the solution @xmath74 of the problem @xmath75 $ ] .",
    "[ etape:4 ] define @xmath76 as the concatenation of the controls @xmath74 , @xmath77 .",
    "5 .   set @xmath78}](t)\\|dt$ ] .",
    "6 .   set @xmath79 .",
    "step  [ etape:1 ] contradicts the parallelization paradigm , since it requires a sequential solving of an evolution equation on the full interval @xmath27 $ ] .",
    "we will see how this problem can be solved in sec .",
    "[ sec:4 ] .",
    "however , note that the most time consuming step , namely step  [ etape:3 ] , is achieved in parallel .",
    "different schemes can be used to implement the time - parallelized algorithm in practice .",
    "this requires two ingredients , a numerical scheme to solve approximately the evolution equations of steps  [ etape:1 ] and  [ etape:3 ] and an optimization procedure for the sub - problem of step  [ etape:3 ] . in this paragraph",
    ", we give some details about the used numerical methods and we explain how the full efficiency can be approached in the case of quantum systems of sufficiently small dimensions .    in the different numerical examples , we consider two numerical solvers for the schrdinger equation  : a crank - nicholson scheme and a second order strang operator splitting .",
    "such solvers can be described through an equidistant time - discretization grid @xmath80 of an interval @xmath81 $ ] .",
    "the time step is denoted by @xmath82 for some @xmath83 . for each time grid point @xmath84",
    ", we introduce the state @xmath85 and the control @xmath86 , which are some approximations of the exact state @xmath87 and of the exact control field @xmath88 .",
    "the crank - nicholson algorithm is based on the following recursive relation : @xmath89 which can be rewritten in a more compact form as @xmath90 where @xmath91 is the identity operator and @xmath92 .",
    "the second order strang operator splitting is rather used in the case of infinite dimensional systems . indeed , this method is particularly relevant when the hamiltonian includes a differential operator .",
    "we consider , for example , the case @xmath93 where @xmath94 denotes the laplace operator and @xmath95 is a scalar potential . in this case ,",
    "strang s method gives rise to the iteration : @xmath96 in eq .",
    ", each product can be determined very quickly since the operator @xmath97 is diagonal in the physical space , while @xmath94 is generally diagonal in the fourier space , and the change of basis can be achieved efficiently by fast fourier transform .",
    "these schemes provide a second order approximation with respect to time , which leads to an accurate approximation of the trajectory @xmath4 .",
    "in addition , both propagators automatically preserve the normalization of the wave function , which is very interesting to avoid non - physical solutions .",
    "a specific advantage of these solvers is that they allow an exact differentiation with respect to the control in the discrete setting , in the case of scalar control for the strang solver   and in any case for the crank - nicholson solver  .",
    "we now explain how the full efficiency can be reached with the parallelization algorithm .",
    "both solvers lead to a linear relation between the initial and the final states of the system of the form : @xmath98 as an example , for the crank - nicholson solver , we have : @xmath99 the matrix @xmath100 can be computed in parallel during the propagation of eq .  .",
    "knowing the state @xmath101 , this matrix enables to compute in one matrix - vector product @xmath102 . as a consequence ,",
    "this propagator assembling technique allows us to avoid the sequential solving on the full interval @xmath27 $ ] in step  [ etape:1 ] of algorithm  [ alg : ism ] .",
    "more precisely , assume for example that at iteration @xmath103 of algorithm  [ alg : ism ] and on each sub - interval , a matrix @xmath104 is computed and transmitted to the main processor .",
    "the computations of the sequences @xmath105 and @xmath106 , that are required to define the intermediate states @xmath107 , can be achieved in @xmath108 matrix - vector products .",
    "due to storage and communications issues of the matrices , note that this approach can only be used for quantum systems of small dimensions .",
    "we conclude this paragraph by presenting a way to derive the gradient of time - discretized figures of merit of the form : @xmath109= \\re\\langle { \\psi}_j|\\psi_f\\rangle-\\frac{\\alpha}{2 } \\tau \\sum_{j=0}^{j-1 } u_j^2.\\ ] ] we consider the case of a crank - nicholson solver , but similar computations can be made for strang s solver .",
    "we introduce the functional @xmath110 defined by : @xmath111={\\mathcal{j}}_{\\tau}[u]+ \\re ( \\sum_{j=0}^{j-1 } \\langle \\chi_j|\\openone+l_j|\\psi_{j+1}\\rangle   \\\\ & - \\langle \\chi_j|\\openone - l_j|\\psi_j\\rangle).\\end{aligned}\\ ] ] since @xmath112 is anti - hermitian , differentiating @xmath110 with respect to @xmath113 gives rise to the discrete adjoint evolution equation : @xmath114 with the final condition @xmath115 . to derive the gradient of @xmath116 $ ] , it remains to differentiate @xmath117 with respect to @xmath11 , which leads to the @xmath118-th entry of the gradient of @xmath119 : @xmath120\\right)_j= \\alpha dt u_j + \\frac{i \\tau}2 \\langle \\chi_j|\\partial_u h|\\psi_{j+1}+\\psi_j\\rangle.\\ ] ] in the sequel , we use this result to implement a constant step gradient method : the approximation of the solution of the sub - problem in step  [ etape:4 ] is computed by iterating on @xmath121 in the formula : @xmath122 for some @xmath123 . +",
    "other optimization methods such as pseudo or quasi - newton approaches can be used to perform step  [ etape:3 ] .",
    "this section is dedicated to some numerical results obtained with ism , used with the schemes presented in sec .",
    "[ sec:3 ] .",
    "the efficiency of this approach is illustrated on three benchmark examples in quantum control @xcite , namely the control of a system of coupled spins , the control of molecular orientation and the control of a bose - einstein condensate whose dynamics is governed by the gross - pitaevskii equation .      in this paragraph",
    ", we consider the control of a system of coupled spin 1/2 particles .",
    "the principles of control in nuclear magnetic resonance being described in different books @xcite , only a brief account will be given here in order to introduce the used model .",
    "we investigate the control of a system of coupled spins by means of different magnetic fields acting as local controls on each spin .",
    "each field only acts on one spin and does not interact with the others , i.e. the spins are assumed to be selectively addressable .",
    "we introduce a system of 5 coupled spins @xcite , the evolution of which is described by the following hamiltonian : @xmath124\\ ] ] where the operators @xmath125 and @xmath126 are , up to a factor , pauli matrices which only act on the @xmath103th spin : @xmath127 @xmath128 we assume that the free evolution hamiltonian @xmath129 is associated with a topology @xcite defined by : @xmath130 note that this model system is valid in heteronuclear spin systems if the coupling strength between the spins is small with respect to the frequency shifts @xcite . the coupling constant between the spins",
    "is taken to be uniform and equal to @xmath131 .",
    "for the numerical simulations , we move to the density matrix formalism with @xmath132 and @xmath133 as initial and final states , respectively . the control time is fixed to @xmath134 .",
    "the parameter @xmath10 is set to 0 .    for the time - parallelization",
    ", we consider a uniform grid , so that @xmath135 , for @xmath136 and we compare the results for different values of @xmath137 .",
    "the time discretization is done by the crank - nicholson method of eq .   with the time step @xmath138 . in step  [ etape:3 ] , one iteration of the constant step gradient descent method",
    "[ see eq .  ]",
    "is used , with @xmath139 . as a result of theorem  [ th : gradient ] , the values obtained after a given number of iterations are the same for all values of @xmath137 . in this way , the method is almost fully efficient .",
    "it is actually equivalent to a standard gradient method , except that the computation of the gradient is done in parallel .",
    "the computational effort is therefore exactly divided by the number of processors , and the full efficiency is only limited by the memory usage and also by the communication between processors required by the update of the intermediate states in steps  [ etape:1 ] and  [ etape:2 ] of the algorithm .",
    "figure  [ fig1 ] displays the figure of merit with respect to the parallel computational time .",
    "( the number of processors ) with respect to computational time ( wall - clock time ) in the case of the control of a spin system .",
    "as stated in theorem  [ th : gradient ] , the values obtained after a given number of iterations are the same for all values of @xmath137 .",
    "log - scale is used in the x - axis . ]    in order to evaluate more precisely the efficiency of the algorithm , we give some details about the speedup of the numerical computations .",
    "numerical simulations are implemented with matlab , where the parallelization is realized using the open source library matlabmpi  @xcite .",
    "the tests have been carried out on a shared memory machine under a linux system with a core of intel(r ) xeon(r ) cpu type ( @ 2.90ghz with 198 giga byte shared memory ) .",
    "the parallel computation uses @xmath137 processors where @xmath137 stands , as above , for the number of sub - intervals of the time domain decomposition . in fig .",
    "[ figspeedup ] , parallel numerical performances are compared with the sequential performance which is obtained when a single processor is used to treat the whole time domain .",
    "given @xmath140 , we introduce the quantities @xmath141 and @xmath142 as the parallel speedup and the efficiency respectively , where @xmath143 denotes the computational time ( with @xmath137 processors ) necessary to reach a value @xmath144 $ ] such that @xmath145-\\mathcal{j}[u^k]<\\varepsilon$ ] , where @xmath146 is the value of the sequence @xmath147 obtained at the numerical convergence .",
    "figure  [ figspeedup ] displays results about the speedup of the parallel implementation .     of the parallel implementation ( y- axis ) with respect to the number of processors @xmath137 ( x- axis ) .",
    "the blue dots indicate the speedup achieved with matlabmpi for @xmath148 ( see table [ tabefficiency ] for details ) .",
    "the red solid line corresponds to a linear evolution of the speedup as a function of @xmath137 . ]",
    "we observe that the algorithm behaves as expected when increasing the number of processors . despite the use of input / output ( i / o ) data files to ensure the communication between cpus ( as required by matlabmpi )",
    ", ism achieves a linear scalability .",
    "a profiling of the parallel computing is reported in fig .  [ profiling ] where we present the time spent to achieve the communications for the master and one slave processors during 20 iterations of the optimization process .",
    "as expected , the speedup is independent on the value of @xmath149 .",
    "this point is clearly exhibited in table  [ tabefficiency ] .",
    "the communications in matlabmpi are of point - to - point type through i / o files , a for - loop is therefore necessary to cover all sender and receiver processors . in this view , a slave processor waits for its turn in order to be able to read the message from the master processor . on the contrary ,",
    "the printing message addressed to the master processor is done on slave processors and hence is non - blocking .    [ cols=\"^,^ \" , ]     we observe that the full efficiency is reached , as confirmed in table  [ tabgp ] .",
    "this feature is certainly a consequence of the nonlinear setting .",
    "the sub - control problems are simpler not only because of the size reduction induced by the time decomposition , but also because of the dynamics itself , which is simplified on a shorter time interval .",
    "in this work , we have investigated the numerical efficiency of a time parallelized optimal control algorithm on standard quantum control problems extending from the manipulation of spin systems and molecular orientation to the control of bose - einstein condensates .",
    "we have shown that the full efficiency can be reached in the case of a linear dynamics optimized by means of gradient methods . on the contrary , full efficiency is not achieved when using monotonic algorithms and newton solvers . in the case of a newton method , the parallelization setting reduces the length of time intervals where the solver is used , and makes the subproblems easier to solve .",
    "such a property is also observed in the case of nonlinear dynamics , as shown with the example of bose - einstein condensates .",
    "the results of this work can be viewed as an important step forward for the implementation of parallelization methods in quantum optimal control algorithms .",
    "their use will become a prerequisite in a near future to simulate quantum systems of increasing complexity .",
    "* acknowledgment * + s.j .",
    "glaser acknowledges support from the dfg ( gl 203/7 - 1 ) , sfb 631 and the bmbf fkz 01ez114 project .",
    "d. sugny and s. j. glaser acknowledge support from the anr - dfg research program explosys ( anr-14-ce35 - 0013 - 01 ; dfg - gl 203/9 - 1 ) .",
    "j.s was partially supported by the agence nationale de la recherche ( anr ) , projet blanc emaqs number anr-2011-bs01 - 017 - 01 .",
    "this work has been done with the support of the technische universitt mnchen ",
    "institute for advanced study , funded by the german excellence initiative and the european union seventh framework programme under grant agreement 291763 ."
  ],
  "abstract_text": [
    "<S> we present a time - parallelization method that enables to accelerate the computation of quantum optimal control algorithms . </S>",
    "<S> we show that this approach is approximately fully efficient when based on a gradient method as optimization solver : the computational time is approximately divided by the number of available processors . </S>",
    "<S> the control of spin systems , molecular orientation and bose - einstein condensates are used as illustrative examples to highlight the wide range of application of this numerical scheme . </S>"
  ]
}