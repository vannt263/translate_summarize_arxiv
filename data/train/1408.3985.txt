{
  "article_text": [
    "automation of financial and legal processes requires enforcement of confidentiality and integrity of transactions . for practical integration with the existing manual systems , such enforcement should be transparent to users .",
    "for instance , a person continually signs paper - based documents ( e.g. , bank checks ) by hand , while his embedded handwritten signature images are used to secure the digitized version of the signed documents .",
    "such scenario can be realizable using biometric cryptosystems ( also known as bio - cryptographic systems @xcite ) by means of the offline handwritten signature images . in bio - cryptography , biometric signals like fingerprints , iris , face or signature images , etc .",
    ", secure private keys within cryptography schemes like digital signatures and encryption .",
    "biometric samples provide a more trusted identification tool when compared to simple passwords .",
    "for instance , a fingerprint is attached to a person and it is harder to impersonate than traditional passwords .    despite its identification power , biometrics forms a challenging design problem due to its fuzzy nature .",
    "for instance , while it is easy for a person to replicate his password during authentication , it rarely happens that a person applies exact fingerprint each time .",
    "the main source of variability in physiological biometrics like fingerprint , face , iris , retina , etc . is the imperfect acquisition of the traits .",
    "on the other hand , behavioral biometrics like handwritten signatures , gait , and even voice , have intrinsic variability that is harder to cancel .",
    "fuzzy vault ( fv ) is a reliable scheme presented mainly to enable usage of fuzzy keys for cryptography @xcite .",
    "a fv decoder permits limited variations in the decryption key so that secrets can be decrypted even with variable keys . accordingly",
    ", this scheme fits the bio - cryptography implementations , where biometrics are considered as fuzzy keys by which private cryptographic keys are secured .",
    "since the fv scheme has been proposed , it has being extensively employed for bio - cryptography , where most implementations focused on physiological biometrics , e.g. , fingerprints @xcite , face @xcite and iris @xcite .",
    "fv implementations based on the behavioral handwritten signatures are few and mostly employed online signature traits , where dynamic features like pressure and speed are acquired in real time by means of special devices as electronic pens and tablets @xcite .",
    "static offline signature images , that are scanned after the signing process ends , however , integrate too much variability to cancel by a fv decoder @xcite .",
    "recently , the authors have proposed the first offline signature - based fuzzy vault ( osfv ) implementation @xcite-@xcite .",
    "this implementation is employed to design a practical digital signature system by means of handwritten signatures @xcite . in this paper , this implementation is reviewed and extended .",
    "in particular , we propose an extension to enhance the security and accuracy of the basic osfv system by adapting cryptographic key size for individual users .",
    "finally , system performance on the gpds public signature database @xcite , besides the private pucpr brazilian database @xcite , are presented and interpreted .",
    "the rest of the paper is organized as follows . in the next section ,",
    "the osfv implementation and its application to produce digital signatures by means of the handwritten signature images are reviewed .",
    "section iii describes the signature representation and lists some aspects for enhanced representations .",
    "section iv introduces some osfv variants for enhanced accuracy .",
    "section v lists some variants for enhanced security .",
    "the new variant that adapts key sizes for enhanced security and accuracy is described in section vi .",
    "the simulation results are presented in section vii .",
    "finally , some research directions and conclusions are discussed in section viii .",
    "the system proposed for osfv consists of two main sub - systems : enrollment and authentication ( see figure [ fig : figure6 ] ) . in the enrollment phase , some signature templates @xmath0 are collected from the enrolling user .",
    "these templates are used for the user representation selection , as described in section iii .",
    "the user representation selection process results in a user representations matrix @xmath1 , where @xmath2 is the vector of indexes of the selected features , @xmath3 is a vector of indexes mapping represented in @xmath4-bits , and @xmath5 is the vector of expected variabilities associated with the selected features .",
    "this matrix is user specific and contains important information needed for the authentication phase .",
    "accordingly , @xmath6 is encrypted by means of a user password @xmath7 . both fv and password",
    "are then stored as a part of user bio - cryptography template ( @xmath8 ) .",
    "then , the user parameters @xmath9 and @xmath10 are used to lock the user cryptography key @xmath11 by means of a single signature template @xmath12 in a fuzzy vault @xmath13 .    in the authentication phase ,",
    "user password @xmath7 is used to decrypt the matrix @xmath6 .",
    "then , the vectors @xmath14 and @xmath15 are used to decode the fv by means of user query signature sample @xmath16 .",
    "finally , user cryptographic key @xmath11 is released to the user so he can use it to decrypt some confidential information or digitally signs some documents .",
    "the enrollment sub - system uses the user templates @xmath0 , the password @xmath7 , and the cryptography key @xmath11 to generate a bio - cryptography template ( bct ) that consists of the fuzzy vault @xmath13 and the encrypted user representation matrix @xmath17 .",
    "the user representation selection module generates the @xmath6 matrix as described in section iii .",
    "the osfv encoding module ( illustrated in figure [ fig : figure7 ] ) describes the following processing steps :    1 .",
    "the virtual indexes @xmath3 are quantized in @xmath4-bits and produces a vector @xmath18 .",
    "2 .   the user feature indexes @xmath19 are used to extract feature representation @xmath20 from the signature template @xmath12 . this representation is then quantized in @xmath4-bits and produces a vector @xmath21 .",
    "the features are encoded to produce the locking set @xmath22 , where @xmath23 consists of @xmath24-bits fv points 4 .",
    "the cryptography key @xmath11 of size @xmath25 where : + @xmath26 + is split into @xmath27 parts of @xmath24-bits each , that constitutes a coefficient vector @xmath28 .",
    "a polynomial @xmath29 of degree @xmath30 is encoded using @xmath31 , where @xmath32 .",
    "the polynomial is evaluated for all points in @xmath22 and constitutes the set @xmath33 where @xmath34 .",
    "chaff ( noise ) points @xmath35 are generated , where @xmath36 , i \\in [ 1,t ] $ ] , and @xmath37 $ ] .",
    "a chaff point @xmath38 is composed of two parts : the index part @xmath39 and the value part @xmath40 .",
    "two groups of chaff points are generated .",
    "chaffs of @xmath41 have their indexes equal to the indexes of the genuine points .",
    "the chaff points and the genuine point that have the same index part are all equally spaced by a distance @xmath42 , eliminating the possibility to differentiate between the chaffs and the genuine point .",
    "chaffs of @xmath43 have their index part differs than that of the genuine points as the number of chaffs in @xmath41 is limited by the parameters @xmath44 and @xmath42 , so to inject higher quantity of chaffs we define @xmath45 as a chaff groups ratio , where : + @xmath46 + where @xmath47 and @xmath48 are the amount of chaff features belong to @xmath41 and @xmath43 , respectively .",
    "@xmath43 chaffs are generated with @xmath49 indexes different than the @xmath44 genuine indexes .",
    "hence , the fv size @xmath50 is given by : + @xmath51 + so , the total number of chaffs @xmath52 is given by : + @xmath53 7 .",
    "the genuine set @xmath54 , and the chaff set @xmath55 are merged to constitute the fuzzy vault @xmath56 , where @xmath57 , @xmath22 , @xmath58 and @xmath59 , @xmath60 .",
    "the authentication sub - system uses the user query sample @xmath16 and the password @xmath7 , to decode the fuzzy vault @xmath13 and restore the user cryptography key @xmath11 .",
    "first the password @xmath7 is used to decrypt the @xmath6 matrix .",
    "then the vectors @xmath14 , and @xmath15 are used to decode the fv by means of the query @xmath16 .",
    "the osfv decoding module ( illustrated in figure [ fig : figure9 ] ) describes the following processing steps :    1 .",
    "the virtual indexes @xmath3 are quantized in @xmath4-bits and produces a vector @xmath61 .",
    "2 .   the user feature indexes @xmath19 are used to extract feature representation @xmath62 from @xmath16 . this representation is then quantized in @xmath4-bits and produces a vector @xmath63 .",
    "the features are encoded to produce the unlocking set @xmath64 , where @xmath65 .",
    "hence , the unlocking elements are represented in a field @xmath66 .",
    "the unlocking set @xmath67 is used to filter the chaff points from the fv .",
    "an adaptive matching method is applied to match unlocking and locking points .",
    "items of @xmath67 are matched against all items in @xmath68 .",
    "this process results in a matching set @xmath69 , where @xmath70 represents the projection of the matching features on the polynomial space .",
    "chaff filtering is done as follows .",
    "if the feature indexes are correct , then all elements of @xmath71 will have corresponding elements in @xmath72 .",
    "so , all of chaffs of @xmath43 will be filtered out .",
    "then , each of the remaining fv points will be compared to corresponding points extracted from the query sample .",
    "an adaptive matching method is applied : for every feature @xmath73 , a matching window @xmath74 is adapted to the feature modeled variability @xmath75 , where @xmath76 .",
    "a fv point @xmath77 is considered matching with an unlocking point @xmath78 , if they reside in the same matching window .",
    "i.e. , @xmath79 .",
    "the matching set @xmath80 is used to reconstruct a polynomial @xmath81 of degree @xmath30 by applying the rs decoding algorithm @xcite .",
    "the coefficients of @xmath81 are assembled to constitute the secret cryptography key @xmath82 .      in @xcite ,",
    "the osfv implementation is employed to produce digital signatures using offline handwritten signatures .",
    "this methodology facilitates the automation of business processes , where users continually employ their handwritten signatures for authentication .",
    "users are isolated from the details related to the generation of digital signatures , yet benefit from enhanced security .",
    "figure [ signature ] illustrates the osfv - based digital signature framework .",
    "the user fv that is constructed during enrollment is used to sign user documents offline as follows . when a user signs a document by hand , his handwritten signature image is employed to unlock his private key @xmath83 .",
    "the unlocked key produces a digital signature by encrypting some message @xmath84 extracted from the document ( e.g. , check amount ) .",
    "the encrypted message is considered as a digital signature and it is attached to the digitized document .",
    "any party who possesses the user public key can verify the digital signature , where verification of the digital signature implies authenticity of the manuscript signature and integrity of the signed document ( e.g. , check amount did not change ) .",
    "according to aforementioned osfv implementation , the fv points encode some features extracted from the signature images .",
    "it is obvious that accuracy of a fv system relies on the feature representation .",
    "representations of intra - personal signatures should sufficiently overlap so that matching errors lie within the error correction capacity of the fv decoder . on contrary , representations of inter - personal signatures should sufficiently differ so that matching errors are higher than the error correction capacity of the fv decoder .",
    "accordingly , the authors proposed to design signature representations adapted for the fv scheme by applying a feature selection process in a feature - dissimilarity space . in this space ,",
    "features are extracted from each pair of template and query samples and the pair - wise feature distances are used as space dimensions .        to illustrate this approach , see figure [ fig : figure12 ] . in this example , three signature images are represented : @xmath85 is the template signature , @xmath86 is a genuine query sample and @xmath87 is a forgery query sample . in the left side ,",
    "signatures are represented in the fv feature encoding space , where a fv point encodes a feature index @xmath73 and its value @xmath88 . for simplicity ,",
    "only two features ( @xmath89 and @xmath90 ) are shown , while the full representation consists of @xmath44 dimensions .",
    "on the right side , signatures are represented in the feature dissimilarity space . in this space ,",
    "a feature is replaced by its distance from a reference value .",
    "for instance , @xmath89 and @xmath90 are replaced by their dissimilarity representations @xmath91 , where @xmath92 , and @xmath93 .",
    "accordingly , while a point in the feature encoding space represents a signature image , a point in the feature dissimilarity space represents the dissimilarity between two different signature images .",
    "the point @xmath94 represents the dissimilarity between the genuine signature @xmath86 and the template @xmath85 , and a point @xmath95 represents the dissimilarity between the forgery signature @xmath87 and the template @xmath85 , where @xmath94= ( @xmath96 ) , and @xmath95= ( @xmath97 ) .    in this example ,",
    "@xmath98 and @xmath99 are discriminant features . for instance , for all genuine query samples like @xmath86 , @xmath100 and for all forgery query samples like @xmath87 , @xmath101 .",
    "unfolding these discriminant dissimilarity features to the original feature encoding space produces discriminant features in the encoding feature space , where the distance between two feature instances is used to determine their similarity .",
    "for instance , a genuine feature ( like @xmath102 ) lies close to the template feature @xmath103 , so they are similar , where closeness here implies that both features reside in a matching window @xmath76 .",
    "features extracted from a forgery image ( like @xmath104 ) do not resemble the template feature @xmath103 , as they reside outside the matching window @xmath74 .",
    "aforementioned description of the process to design representations is generic .",
    "some extensions are reviewed and compared below .",
    "shortage of user samples for training is addressed by designing a global writer - independent ( wi ) representation @xcite .",
    "a large number of signature images from a development database are represented in the feature - dissimilarity space of high dimensionality , and feature selection process runs to produce a global space of reduced dimensionality .",
    "such global approach permits designing fv systems for any user even who provides a single signature sample during enrollment .    for performance improvement",
    ", the global representation is specified for individual users once enough number of enrolling samples becomes available . to this end",
    ", training samples are firstly represented in the global representation space , then an additional training step runs to produce a local writer - dependent ( wd ) representation that discriminates the specific user from others .",
    "simulation results have shown that local representations enhanced fv decoding accuracy by about 30% , where the average error rate ( aer ) is decreased from 25% in case of global representations to 17.75% for the local ones .      in @xcite , the extended shadow code ( esc ) feature extraction method is adapted for the fv implementation @xcite .",
    "these features consist in the superposition of a bar mask array over a binary image of handwritten signatures . each bar",
    "is assumed to be a light detector related to a spatially constrained area of the 2d signal .",
    "this method is powerful in detecting various levels of details in the signature images by varying the extraction scale .",
    "for instance , an image could be split to @xmath105 of horizontal and vertical cells , respectively , and shadow codes are extracted within individual cells .",
    "the higher the number of cells , the higher the resolution of detectors .",
    "the authors observed that designing fvs based on a single extraction scale results in varying performance for the different users .",
    "for instance , while high resolution scales are fine with users whose signatures are easy to forge or those who have high similarities with others , the low resolutions are better for users whose signatures integrate high variabilities .",
    "accordingly , a multi - scale feature fusion method is proposed , where different feature vectors are extracted based on different extraction scales and they are combined to produce a high - dimensional representation .",
    "this representation is then processed through the wi and wd design phased and produces the final local representation that encodes in the fv .          besides fusing feature vectors that are extracted based on different scales , it is possible to fuse different types of features . in @xcite , the directional probability density function ( dpdf )",
    "features @xcite are fused with esc features to constitute a huge dimensional representation ( of 30,201 dimensionality ) .",
    "this representation is reduced through the wi and wd training steps and produced a concise representation of only 20 features .",
    "it is shown that injecting the additional feature type increased the fv decoding accuracy by about 22% ( aer is reduced from 17.75% to 13.75% ) .",
    "the aforementioned approach provides a practical scenario to produce representations with low intra - personal and high inter - personal variabilities which is mandatory feature for fv systems .",
    "however , the authors observed that the margin between the intra and the inter classes differs when using different signature prototypes ( templates ) for fv encoding .",
    "accordingly , a prototype selection method is proposed @xcite .",
    "the wd representation is projected to a dissimilarity space where distances to different user prototypes are the space constituents .",
    "then , a feature selection process runs in the dissimilarity space and locates the best prototype .",
    "this method has enlarged the separation between the intra and inter clusters significantly ( area under roc curve ( auc ) is increased from 0.93 to 0.97 ) .",
    "although accuracy of an osfv system relies mainly on quality of the feature representation , the proposed implementation provides additional opportunities for enhanced accuracy by applying some other design variants as described in this section .",
    "the results mentioned so far report accuracy of fv decoders that apply strict matching approach .",
    "two fv points are matching only if they have identical values .",
    "accuracy of a fv decoder is enhanced by applying the adaptive matching method , where the feature variability matrix @xmath15 is used for matching so that corresponding fv points are considered matching if their difference lies within the expected variability of their encoding feature ( see figure [ fig : figure3 ] ) .",
    "this method increased accuracy by about 27% ( aer is reduced from 13.75% to 10.08% ) @xcite .      instead of decoding a single fv token ,",
    "it is possible to decode several fvs for enhanced performance . in case that some fvs are correctly decoded , the decrypted key is released to the user based on the majority vote rule .",
    "this method has increased detection accuracy by about 18% ( aer is reduced from 10.08% to 8.21% ) @xcite .",
    "the limited discriminative power of fvs is alleviated by using an additional password @xmath7 , so that the false accept rate ( far ) is reduced without significantly affecting the false reject rate ( frr ) .",
    "for the results reported so far , it was assumed that the user password @xmath7 is compromised . however , to report the actual performance of the system we have to consider the case when an attacker neither possesses a correct password nor a genuine signature sample . in this case",
    ", he can not decrypt the ur model and hence he randomly guesses the feature indexes .",
    "it is shown that the additional password has increased detection accuracy by about 65% ( aer is reduced from 8.21% to 2.88% ) @xcite .      using additional passwords for enhanced system accuracy",
    "comes with the expense of the user inconvenience . in @xcite ,",
    "a novel user - convenient approach is proposed for enhancing the accuracy of signature - based biometric cryptosystems .",
    "since signature verification ( sv ) systems designed in the original feature space have demonstrated higher discriminative power to detect impostors @xcite , they can be used to improve the fv systems . instead of using an additional password ,",
    "the same signature sample is processed by a sv classifier before triggers the fv decoders ( see figure [ sv - fv ] ) . using this",
    "cascaded approach , the high far of fv decoders is alleviated by the higher capacity of sv classifiers to detect impostors .",
    "this method has increased detection accuracy by about 35% ( aer is reduced from 10.08% to 6.55% ) . when multiple fvs are fused ,",
    "the aer is decreased by 31.30% ( from 8.21% to 5.64% ) .",
    "security of the osfv implementation is analyzed in terms of the brute - force attack @xcite .",
    "assume an attacker could compromise the fv without possessing neither valid password nor genuine signature sample . in this case , the attacker tries to separate enough number of genuine points ( @xmath27 ) from the chaff points .",
    "security of a fv is given by :    @xmath106    where @xmath45 is the chaff group ratio , @xmath44 is the number of genuine points in the fv , @xmath30 is the degree of the encoding polynomial and @xmath42 is the chaff separation distance .",
    "high value of @xmath45 implies a high number of g2 features which are compromised in case that the password is compromised .",
    "the parameter @xmath44 should be concise as it impacts the accuracy and complexity of the fv .",
    "accordingly , entropy of the system can be increased through using different values of the parameters : @xmath42 and @xmath30 . however , there is a trade - off between system security and its recognition accuracy that could be alleviated by applying the following approaches .      in the traditional chaff generation method ,",
    "equal - spaced chaff points are generated with a separation factor @xmath42 @xcite .",
    "in such case , there is a trade - off between security and robustness .",
    "for instance , with small separation , e.g. , @xmath107 , there are 40 fv points generated with the same index ( 1 genuine + 39 chaff points ) . in this case , a high number of chaffs is generated and results in high system entropy of about 68-bits and low accuracy of about @xmath108 aer .",
    "the adaptive chaff generation method enables the injection of high number of chaff with minimal impact on the fv decoding robustness . to this end , the feature variability vector @xmath15 is used during the fv locking phase so that chaff points are generated adaptively according to feature variability . for each feature",
    "@xmath88 , @xmath109 ( see figure [ fig : figure3 ] ) . by this method , it is less likely that an unlocking element equates a chaff element .",
    "for or instance , the same entropy ( 68-bits ) could be achieved with a minimal impact on system robustness ( aer = 10.52% ) @xcite .      according to eq.[s ] ,",
    "the longer the cryptographic key size the higher entropy of the fv .",
    "however , this comes with expense of the accuracy @xcite . in @xcite , different key sizes ( ks )",
    "are tried ( 128 , 256 , 512 , 1024-bits ) and it is shown that different key sizes result in different performance for the different users .",
    "this observation motivates adapting the key length for each user as proposed in the following section ,",
    "in @xcite , functionality of a fv decoder is formulated as a simple dissimilarity threshold as follows :    = -1 pt    @xmath110    where a fv encoded by a template @xmath85 can be correctly decoded by a query @xmath16 only if the total dissimilarity between @xmath16 and @xmath85 is less than the error correction capacity @xmath111 of the fv decoder . here , @xmath112 is the dissimilarity part that results from the variability between the two samples , and @xmath113 is the dissimilarity part that results from wrong matches with chaff points .",
    "the methods discussed so far aimed to optimize the dissimilarity parts of eq.[fvd ] .",
    "for instance , the multi - scale and multi - type feature extraction approach results in separating intra - personal and inter - personal dissimilarity ranges .",
    "selection of robust templates ( prototypes ) and applying adaptive matching enlarged this separation .",
    "also , impact of the chaff error is minimized by presenting the adaptive chaff method . with applying all these methods ,",
    "however , accuracy of a signature - based fv is still below the level required for practical applications . accordingly",
    ", performance is increased by applying some complex and user inconvenient solutions like ensemble of fvs and using additional passwords or cascading sv and fv systems .    here",
    "we investigate a new room for enhancing fvs by optimizing the error correction capacity @xmath114 which is given by :    = -1 pt    @xmath115    it is obvious that this parameter relies on the fv encoding size @xmath44 and the encoding polynomial degree @xmath30 .",
    "also , from eq.[ks ] , we see that @xmath30 determines the key size @xmath25 .",
    "accordingly , we select user specific key sizes through changing the parameter @xmath30 so that @xmath114 for a specific user covers the range of his expected signature variability . to this end",
    ", we set @xmath114 for a user to his maximum intra - personal variability @xmath116 .",
    "based on the resulting user - specific error correction capacity , the parameter @xmath30 is determined using eq.[fv ] and user key size @xmath25 is computed using eq.[ks ] .",
    "once appropriate key size is computed for a user , his key is enlarged through injecting some padding bits in the original key during fv encoding . during authentication ,",
    "the enlarged key is reconstructed and the padding bits are removed to produce the original cryptographic key .",
    "all aforementioned performance results are reported for the pucpr brazilian signature database @xcite . here",
    "we test the system for the public gpds-300 database @xcite as well .",
    "this database contains signatures of @xmath117 users , that were digitized as 8-bit greyscale at resolution of 300 dpi and contains images of different sizes ( that vary from @xmath118 pixels to @xmath119 pixels ) .",
    "all users have 24 genuine signatures and 30 simulated forgeries .",
    "it is split into two parts .",
    "the first part contains signatures of the first 160 users .",
    "a subset of this part is used to design the local representation and the remaining of this part is used for performance evaluation .",
    "the second part contains signatures of the last 140 users and it is used to design the global representation . see @xcite for a similar experimental protocol for both databases .",
    "table [ table : impact of using a user password ] shows results for the two databases for fixed and adaptive key sizes .",
    "it is obvious that employing the adaptive key size approach decreased the far significantly with low impact on the frr .",
    "for instance , the aer for the pucpr database in decreased by about 21% ( from 10.08 to 7.94 ) . also , performance of the system for the gpds database is comparable to state - of - the - art traditional sv systems ( aer is about 15% ) that employ more complex classifiers @xcite .",
    "moreover , the proposed method also enhances system security as it is possible to increase the key size , and hence the polynomial degree @xmath30 , without much impact on the accuracy . for instance , figure [ fig : adaptive ] shows the adapted polynomial degrees for different users in the pucpr database and the corresponding user variability @xmath116 .",
    "it is obvious that users with more stable signatures have their cryptographic keys more enlarged than users with less stable signatures . according to eq.[s ] ,",
    "system entropy of the standard osfv implementation ( with fixed keys of size 128-bits and polynomial degree @xmath120 ) is about 45-bits . with applying the adaptive key size method",
    ", the average @xmath30 is about 9.6-bits ( see figure [ fig : adaptive ] ) which provides an average entropy of about 51-bits .",
    ".impact of using a user password as a second authentication measure [ cols=\"^,^,^,^,^ \" , ]",
    "in this paper , a recently published offline signature - based fv implementation is reviewed .",
    "several variants of the system are listed and compared for enhanced accuracy and security . a novel method to adapt cryptography key sizes for different users",
    "is proposed and have shown accuracy and security enhancement .",
    "the performance is also validated on a public signature database where comparable results of complex sv in the literature is reported .",
    "although the proposed key adaptation method sounds , there is need to propose more intelligent tuning technique taking in consideration the similarities with simulated forgeries for higher forgery detection .",
    "this study listed many new approaches that are applied successfully to the signature based bio - cryptography .",
    "we believe that these methods shall be investigated for other biometrics which might enhance state - of - the - art of the area of bio - cryptosystems .",
    ", r.  sabourin , and e.  granger , on the dissimilarity representation and prototype selection for signature - based bio - cryptographic systems . ,",
    "york , uk , 3 - 5 july 2013 , lncs , vol.7953 , pp.265 - 280 .",
    "eskander . , r.  sabourin , and e.  granger , improving signature - based biometric cryptosystems using cascaded signature verification ",
    "fuzzy vault ( sv - fv ) approach . , crete island , greece , 1 - 4",
    "september 2014 .",
    "g.  eskander , r.  sabourin , and e.  granger .",
    "`` hybrid writer - independent  writer - dependent offline signature verification system '' . _",
    "iet - biometrics journal , special issue on handwriting biometrics _ ,",
    "vol.2 , no.4 , pp ."
  ],
  "abstract_text": [
    "<S> an offline signature - based fuzzy vault ( osfv ) is a bio - cryptographic implementation that uses handwritten signature images as biometrics instead of traditional passwords to secure private cryptographic keys . having a reliable osfv implementation is the first step towards automating financial and legal authentication processes , as it provides greater security of confidential documents by means of the embedded handwritten signatures . </S>",
    "<S> the authors have recently proposed the first osfv implementation which is reviewed in this paper . in this system , </S>",
    "<S> a machine learning approach based on the dissimilarity representation concept is employed to select a reliable feature representation adapted for the fuzzy vault scheme . </S>",
    "<S> some variants of this system are proposed for enhanced accuracy and security . in particular , a new method that adapts user key size is presented . </S>",
    "<S> performance of proposed methods are compared using the brazilian pucpr and gpds signature databases and results indicate that the key - size adaptation method achieves a good compromise between security and accuracy . while average system entropy is increased from 45-bits to about 51-bits , the aer ( average error rate ) is decreased by about 21% . </S>"
  ]
}