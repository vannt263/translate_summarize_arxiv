{
  "article_text": [
    "multilayer neural networks ( mln ) are more powerful devices for information processing than the single - layer perceptron because of the possibility of _ different _ activation patterns , so - called internal representations ( ir ) , at the hidden units for the _ same _ input - output mapping .",
    "it is well known that the correlations between the activities at the hidden units are crucial for the understanding of the storage and generalization properties of a mln @xcite . a particular simple situation to study these correlations",
    "is the implementation of random input - output mappings by the network , the so - called storage problem , near the storage capacity . using the replica trick and assuming replica symmetry the correlation coefficients building up in this case",
    "were calculated in @xcite and shown to be characteristic for the prewired boolean function between hidden layer and output .",
    "conversely , _ prescribing _",
    "these correlations the storage properties of the networks change @xcite .    the assumption of replica symmetry ( rs ) in this calculation is somewhat doubtful .",
    "in fact it is well known that the storage capacity of mln is strongly modified by replica symmetry breaking ( rsb ) @xcite , which is due to the very possibility of different internal representations . moreover",
    ", even the distribution of the output field of a simple perceptron is influenced by rsb effects @xcite .    in the present paper",
    "we elucidate the impact of rsb on the correlation coefficients between the activity of different hidden units in mln with one hidden layer and nonoverlapping receptive fields .",
    "the central quantity of interest is the joint probability distribution for the local fields at the hidden units . in the general part of this paper",
    "we show how this distribution can be calculated both in rs and in one - step rsb . for a detailed analysis",
    "we than specialize to mln with @xmath0 hidden units and discuss , in particular , the parity , committee and and machines . together with the corrections from one - step rsb",
    "the rs results give insight in the division of labor between different subperceptrons in mln and the role of rsb .",
    "calculating finally the correlation coefficients we find that although modifying the local field distribution markedly rsb gives rise to minor corrections to the correlation coefficients only .",
    "we consider feed - forward neural networks with @xmath1 inputs @xmath2 , one hidden layer of @xmath3 units @xmath4 and a single output @xmath5 .",
    "the hidden units have nonoverlapping receptive fields of dimension @xmath6 ( tree structure ) .",
    "they are determined by the inputs via spherical coupling vectors @xmath7 according to @xmath8 with @xmath9 denoting the local fields .",
    "we call an activation pattern @xmath10 of the hidden units an internal representation ( ir ) .",
    "the output @xmath5 of the mln is a fixed boolean function @xmath11 of the ir .",
    "examples of special interest include the parity machine , @xmath12 , the committee machine , @xmath13 , and the and machine , @xmath14 .",
    "all ir consistent with a desired output are called legal internal representations ( lir ) .",
    "the number of and similarity between lir to a given output specifies the division of labor taking place between the different perceptrons forming the mln .",
    "it is quantitatively characterized by the correlation coefficients @xmath15 @xmath16 , where @xmath17 denotes the average over the inputs and the output and @xmath18 is a subset of @xmath19 natural numbers between @xmath20 and @xmath3 . for permutation symmetric boolean functions ,",
    "the @xmath21 only depend on @xmath19 and not on the particular choice of this subset .",
    "we focus on the so - called storage problem in which the inputs @xmath2 and the outputs @xmath22 are generated independently at random according to the probability distributions @xmath23 and @xmath24 where @xmath25 , @xmath26 and @xmath27 .",
    "the basic quantity which gives us access to the probability of the lir and to the correlation coefficients is the distribution @xmath28 of the local fields @xmath29 at the @xmath30th hidden unit .",
    "it is given by @xmath31 @xmath32 denotes the average over all stored input - output patterns .",
    "@xmath33 denotes the partition function @xmath34 @xmath35 the measure on the gardner sphere @xcite @xmath36 and @xmath37 the integration measure @xmath38    we use the replica trick @xmath39 in eq .",
    "( [ p_h ] ) to perform the average over the inputs @xmath40 and introduce the overlaps @xmath41 between different replicas @xmath42 of a coupling vector @xmath43 of hidden unit @xmath44 .",
    "we will consider only permutation symmetric booleans @xmath45 .",
    "hence all hidden units have the same statistical properties implying @xmath46 and @xmath47 with @xmath48 .",
    "equation ( [ p_h ] ) takes on the form @xmath49 in terms of the @xmath50-dimensional order parameter matrix @xmath51 where @xmath52 and @xmath53 .",
    "here @xmath54 -\\sum_{k , a < b}x_k^{a}x_k^{b}q^{ab}\\right ) \\nonumber\\\\ & \\times&\\prod\\limits_{a}\\theta(\\sigma f(\\{{\\text{sgn}}(\\lambda_k^{a})\\}))\\delta(h_j-\\lambda_1^{1 } ) \\label{ph_central},\\end{aligned}\\ ] ] and the expression for @xmath55 is specified in the appendix , eq .",
    "( [ g1 ] ) , together with some more details of the calculation .    in the limit",
    "@xmath56 the integral ( [ ph_1 ] ) is dominated by the saddle point values of the order parameters @xmath57 which extremize the partition function @xmath58    in the following , we simplify eqs .",
    "( [ ph_central ] ) and ( [ sad_cond ] ) using the assumption that the order parameter matrix @xmath51 is either replica symmetric or describes one - step replica symmetry breaking .",
    "we will always consider the saturation limit @xmath59 since the expressions then simplify and the correlations become most characteristic in this limit .",
    "the rs case is specified by @xcite @xmath60 the saturation limit @xmath61 is characterized by the existence of a unique solution @xmath43 , e.g. , @xmath62 .",
    "we then get @xmath63 for the conditional probability to find a specific value @xmath64 of the postsynaptical potential under the constraint of a given output @xmath5 .",
    "the terms abbreviated by @xmath65 ensure that only lir for the respective value of @xmath5 contribute to the sum in eq .",
    "( [ ph_rs ] ) . as usual",
    "we have used the error function @xmath66 with @xmath67 .",
    "let us now turn to main features of the solution within the ansatz of one - step rsb .",
    "then the following form for the order parameter matrix is assumed @xcite : @xmath68 accordingly there are two overlap scales characterizing the similarity between coupling vectors belonging to the same and different regions of the solution space , respectively .    using this ansatz we find after standard manipulations @xcite for the probability distribution of the local field for a specific output @xmath5 @xmath69 where now @xmath70 @xmath71 these expressions simplify in the saturation limit @xmath72 in which one finds @xmath73 and @xmath74 .",
    "the remaining order parameters @xmath75 are given by the saddle point equations corresponding to the following expression for the storage capacity @xmath76 : @xmath77 + q_0 w/[1+w(1-q_0 ) ] } { -2\\lim\\limits_{q_1\\rightarrow 1 } \\left\\langle\\!\\!\\left\\langle{\\displaystyle \\int}\\prod\\limits_{k}dy_k\\ln\\left\\ { { \\displaystyle \\int}\\prod\\limits_{k}dz_k\\left(\\phi_{\\rm lir}(\\sigma)\\right)^m\\right\\ } \\right\\rangle\\!\\!\\right\\rangle_{\\sigma } } \\right]\\quad .",
    "\\label{saddle2}\\end{aligned}\\ ] ] as in the rs case the analytical and numerical analysis of these expressions for concrete situations needs some care ( see next section ) .    to finally obtain @xmath78",
    "we must average eqs .",
    "( [ ph_rs ] ) and ( [ ph_rsb ] ) over the two possible outputs @xmath79 , @xmath80 from this probability distribution we find the distributions @xmath81 of the lir according to @xmath82 the correlation coefficients @xmath21 , @xmath16 , are then given by @xmath83 the kronecker @xmath84 in eq .",
    "( [ corr1 ] ) restricts the sum to all lir of the output @xmath5 .",
    "equation ( [ corr1 ] ) is valid as long as the pattern load of the mln does not exceed its saturation threshold @xmath76 .",
    "in this section we apply the general formalism developed above to the analysis of simple versions of three popular examples of mln , namely , the parity , committee and and machines , each with @xmath0 hidden units .",
    "we start with the rs results .      in committee and",
    "parity machines there is for every lir of output @xmath85 an ir with all signs reversed that realizes output @xmath86 . therefore @xmath87 and the final average over @xmath5 in eq .",
    "( [ ph_rs_av ] ) is trivial . analyzing eqs .",
    "( [ lir1_rs ] ) and ( [ lir2_rs ] ) in the limit @xmath62 one realizes that they depend on both the sign and values of all integration variables @xmath88 .",
    "expression ( [ lir1_rs ] ) as well as eq .",
    "( [ lir2_rs ] ) are either equal to one or exponentially small in some or all integration variables .",
    "the quotient of both figuring in eq .",
    "( [ ph_rs ] ) can hence become one , zero , or singular with respect to @xmath89 .",
    "whenever it is one the integral in eq .",
    "( [ ph_rs ] ) gives rise to @xmath90 for @xmath91 .",
    "whenever the quotient is singular a contribution @xmath92 results .    keeping track of the different contributions arising in this way we find for the @xmath0 committee machine @xmath93 and for the parity machine @xmath94 note that @xmath78 for the parity machine is an even function due to the additional symmetry of the boolean function @xmath45 for this case .    in the and machine the output @xmath85 can be realized by one lir only whereas the output @xmath86 results from all the remaining @xmath95 ir .",
    "hence @xmath96 and @xmath97 differ significantly .",
    "in fact we find for the @xmath0 and machine @xmath98 and @xmath99/2 $ ] .",
    "note that we have introduced two different singular contributions @xmath100 and @xmath101 in eqs .",
    "( [ ph_com_rs ] ) , ( [ ph_par_rs ] ) and eqs .",
    "( [ ph_andplus_rs ] ) , ( [ ph_andmin_rs ] ) .",
    "the reason for this is that the weight of @xmath101 adds to the probability of positive local fields whereas the weight of @xmath100 adds to that of negative local fields .",
    "this distinction will be important later when calculating the correlation coefficients from @xmath78 ( cf .",
    "( [ h1 ] ) ) . the results ( [ ph_com_rs ] ) , ( [ ph_par_rs ] ) and ( [ ph_andplus_rs ] ) , ( [ ph_andmin_rs ] ) are shown as the dashed lines in figs .",
    "[ fig1]-[fig3 ] respectively .",
    "these rs results are in fact very intuitive and can be even quantitatively understood by assuming that the outcome of a gardner calculation corresponds to the result of a learning process in which the initially wrong ir are eliminated with least adjustment @xcite . due to the permutation symmetry between the hidden units we may consider only the local field @xmath102 of the first unit of the hidden layer . before learning the couplings @xmath43 are uncorrelated with the patterns and the local field @xmath102 is consequently gaussian distributed with zero mean and unit variance .",
    "now consider , e.g. , the parity machine . due to",
    "the discussed symmetries it is sufficient to analyze the case @xmath85 and @xmath103 .",
    "if @xmath104 and @xmath105 are equal in sign , which will occur with probability @xmath106 , there is no need to modify the couplings at all .",
    "this gives rise to the first term in eq .",
    "( [ ph_par_rs ] ) which is just the original gaussian and describes the chance that a randomly found ir with @xmath103 is legal .",
    "if @xmath104 and @xmath105 differ in sign the ir is illegal and the couplings @xmath43 have to be modified until one of the hidden units changes sign . in an optimal learning scenario the local field with the smallest magnitude",
    "would be selected and the corresponding coupling vector would be modified such that the field just barely changes sign .",
    "hence @xmath102 remains still unmodified if either @xmath104 or @xmath105 is smaller in absolute value which gives rise to the second term in eq .",
    "( [ ph_par_rs ] ) .",
    "finally , if really @xmath102 is selected for the sign change , which will happen with probability @xmath107 for symmetry reasons , it will after learning be either slightly smaller or slightly larger than zero , which is the origin of the last two terms in eq .",
    "( [ ph_par_rs ] ) .    with a similar reasoning it is possible to rederive the rs result for the committee machine .",
    "again it is sufficient to consider the case @xmath85 . if @xmath103 initially it will not be modified , which gives rise to the last term in eq .",
    "( [ ph_com_rs ] ) .",
    "if , on the other hand , @xmath108 , prior to learning it will not be modified only if both @xmath104 and @xmath105 are either positive from the start or easier to make positive than @xmath102 .",
    "hence a negative @xmath102 survives the learning process if the other two fields are both larger .",
    "this is described by the first term in eq .",
    "( [ ph_com_rs ] ) .",
    "finally , with probability @xmath109 we find that @xmath108 and either @xmath104 or @xmath105 is even smaller than @xmath102 and therefore harder to correct . in this case",
    "the learning would shift @xmath102 to positive values as described by the second term in eq .",
    "( [ ph_com_rs ] ) .",
    "the resulting distribution of local fields will hence have a dip for negative values of small absolute value clearly visible in fig .",
    "[ fig1 ] .",
    "the case of the and machine is the simplest .",
    "the output @xmath85 requires all local fields to be positive .",
    "hence positive fields are not modified , negative ones are shifted to @xmath110 resulting immediately in eq .",
    "( [ ph_andplus_rs ] ) which is , of course , identical to the result for the single - layer perceptron @xcite . in the case of a negative output @xmath86",
    "only the ir @xmath111 is illegal and must be eliminated which is again done by changing the sign of the smallest field .",
    "this gives rise to eq .",
    "( [ ph_andmin_rs ] ) .",
    "it is finally interesting to compare the distribution of local fields found above with that for a single perceptron above saturation @xcite .",
    "the individual perceptrons in a mln certainly operate above their storage limit even when the storage capacity of the mln is not yet reached .",
    "the most remarkable feature of the distribution of local fields for a perceptron above saturation minimizing the number of misclassified inputs is a _",
    "gap _ separating positive from negative values .",
    "being intimately related to the failure of any finite level of rsb for this problem this gap is believed to exist even in the solution with continuous rsb @xcite . on the other hand , none of the distributions for mln showed a gap .",
    "as should be clear from the above qualitative discussion the reason for this is quite simple .",
    "the single perceptron above saturation has to reject some inputs as not correctly classifiable . in order to keep the number of these errors smallest",
    "it chooses those with negative fields of large absolute value .",
    "inputs with initially only slightly negative local fields will be learned whereby their local fields shift to values just above zero . in this way",
    "the gap occurs .",
    "in mln , on the other hand , there is no reason to shift all negative local fields of small absolute value because the correct output may be realized by the other hidden units",
    ". therefore one will not find an interval of @xmath64 values for which @xmath78 is strictly zero . on the other hand , the tendency that predominantly fields of small absolute value will be modified in the learning process",
    "is clearly shown by the dips of the distribution functions around @xmath112 ( cf . figs .",
    "[ fig1]-[fig3 ] ) .",
    "let us now discuss how the above results get modified by rsb .",
    "the analytical and subsequent numerical analysis of eqs .",
    "( [ ph_rsb]-[saddle2 ] ) for the @xmath0 machines under consideration needs some care in order not to miss the various singular contributions .",
    "we have first to determine the values of the order parameters at the saddle point using eq .",
    "( [ saddle2 ] ) . in the saturation limit @xmath113 , @xmath114",
    "is dominated by one specific lir which is selected among all other lir by the sign and absolute value of the compound variables @xmath115 .",
    "@xmath114 either tends to 1 or becomes exponentially small in one or more compound variables @xmath116 .",
    "transforming the integration from @xmath117 space to @xmath116 space allows us to reduce the @xmath3-fold @xmath118 integral to a one - dimensional integral .",
    "this is performed numerically by rhomberg integration whereas the outer @xmath88 integrals are done using gauss - legendre quadrature @xcite .",
    "the saddle point equation ( [ saddle2 ] ) is solved with a standard minimization routine ( powells method in two dimensions @xcite ) .",
    "the values we get for the order parameters and for the storage capacity are consistent with those obtained earlier . for the @xmath0 parity machine we find @xmath119 , @xmath120 , and @xmath121 in agreement with@xcite . in the case of the @xmath0 committee machine",
    "we get @xmath122 , @xmath123 , and @xmath124 , a result somewhat larger than reported previously @xcite .",
    "the @xmath0 and machine finally does not show rsb at all and we find accordingly @xmath125 , @xmath126 together with @xmath127 .    in a second step",
    ", we use this values of the order parameters @xmath75 to calculate the respective distribution of local fields ( [ ph_rsb ] ) .",
    "the distribution functions @xmath78 obtained in this way are included as full lines in figs .",
    "[ fig1]-[fig3 ] .",
    "table [ tab1 ] quantifies the main changes .",
    "the main modification of the distribution functions of local fields that occurs in one - step rsb is a redistribution of probability from the @xmath84 peaks at @xmath128 to the continuous part of the distribution around zero resulting in a reduction of the weight of the singular parts of roughly 50% .",
    "this gives rise to a less pronounced dip of the distribution functions around @xmath112 and is qualitatively similar to the rsb modifications for a single perceptron above saturation @xcite . from the results for the parity machine",
    "it is conceivable that the central peak may get reduced further if higher orders of rsb are included and that it might eventually disappear completely in the full parisi solution using continuous rsb .",
    "for all machines the probability of fields with large absolute values is hardly affected by rsb .    for the and machine we did not find rsb at all .",
    "the numerical solution of the saddle point equations only gave the rsb result @xmath129 , @xmath130 .",
    "we therefore suspect that replica symmetry is correct for the and machine .",
    "this is also in accordance with the rule of thumb that rsb is necessary if the solution space is disconnected . in the and machine the output @xmath85",
    "can be realized only by one lir which clearly corresponds to a connected ( even convex ) solution space .",
    "the output @xmath86 is realized by all remaining ir , which as the complement of the previous solution space must be connected too .",
    "we have finally to clarify how much the modifications found for the distributions of local fields will change the probabilities of the internal representations and the correlation coefficients @xmath21 depending only on the _ sign _ of the local fields .",
    "this question is , in fact , nontrivial only in the case of the committee machine . for",
    "the and machine no rsb occurs at all and for the parity machine the correlation coefficients are completely determined by the symmetry of the boolean function @xmath45 between hidden units and output .    for the committee machine",
    "we find that the probability of the lir @xmath111 is shifted from its rs value @xmath131 to @xmath132 , which is an increase by roughly 13% whereas the probability of the three remaining lir ( consisting of two pluses and one minus each ) is reduced by 1.9% from 0.2917 to 0.2861 .",
    "qualitatively this means that more inputs are stored with the lir @xmath111 than the fraction @xmath133 that had this lir already by chance before learning .",
    "the learning process hence does not shift illegal ir just up to the decision boundary of the boolean @xmath45 but in some cases the correlations between inputs @xmath134 and couplings @xmath135 neglected in rs allow even the safer lir @xmath111 .",
    "( [ corr1 ] ) we can now also calculate the correlation coefficients and find that @xmath136 increases by 2.7% from its rs value 5/12 , @xmath137 decreases in absolute value by 13.3% from its rs value 1/6 and @xmath138 decreases in absolute value by 4.5% from its rs value 3/4 .",
    "this confirms the prediction of @xcite that although crucial for the storage capacity rsb will have only a minor influence on the correlation coefficients in mln .",
    "generalizing the calculation of the distribution function of local fields for the single - layer perceptron we introduced a general formalism to determine the joint probability distribution @xmath139 of local fields at the @xmath3 hidden units of a two - layer neural network of tree architecture with fixed boolean function between hidden layer and output both in replica symmetry and in one - step replica symmetry breaking .",
    "explicit results were obtained for the parity , committee , and and machine with @xmath0 hidden units in the saturation limit @xmath140 .",
    "although the individual perceptrons are by far overloaded there is no gap in the distribution of local fields as known from a single perceptron above saturation .",
    "there is no rsb for the and machine which we attribute to the connected solution space for this architecture . for the parity and committee machine",
    "we find as a result of rsb a slight redistribution of probability from the singular parts at @xmath128 to the continuous part around the origin .",
    "the correlation coefficients @xmath21 characterizing the correlations between the legal internal representations are not modified by rsb for the parity machine since in this case they are fixed already by symmetries . for the committee machine",
    "the changes of the correlation coefficients are rather small and the rs results derived in @xcite may serve as useful approximations .",
    "in this appendix we give some more details on the calculation of the distribution function @xmath78 of the local fields at the hidden units following gardner s approach @xcite .    introducing the replica trick @xmath39 into eq .",
    "( [ p_h ] ) yields @xmath141 with replica index @xmath142 . in the integration measures ( [ measure_j ] ) , ( [ measure_fields ] ) we replace the @xmath84 functions by their integral form",
    "@xmath143 @xmath144    we now perform the average over the gaussian distributed patterns @xmath145 and introduce the overlaps @xmath146 of different replicas of the same perceptron @xmath43 as well as its conjugated variable @xmath147 . from the assumed permutation symmetry of the boolean function @xmath45 with respect to all hidden units we infer @xmath148 , @xmath149 , and @xmath150 for all @xmath25 .",
    "this gives rise to the form @xmath151 where @xmath51 and @xmath152 denote the symmetric matrices @xmath52 , @xmath153 and @xmath154 , @xmath155 . moreover , @xmath156 -\\sum_{k , a < b}x_k^{a}x_k^{b}q^{ab}\\right ) \\nonumber\\\\ & \\times&\\prod\\limits_{a}\\theta(\\sigma f(\\{{\\text{sgn}}(\\lambda_k^{a})\\}))\\delta(h-\\lambda_1^{1}),\\end{aligned}\\ ] ] @xmath157 -\\sum_{k , a < b}x_k^{a}x_k^{b}q^{ab}\\right ) \\nonumber\\\\ & \\times&\\prod\\limits_{a}\\theta(\\sigma f(\\{{\\text{sgn}}(\\lambda_k^{a})\\ } ) ) , \\label{g1}\\\\ g_2(a)&=&\\int\\!\\prod\\limits_{k , a}\\frac{dj_k^a}{\\sqrt{2\\pi e } } \\exp\\left(-\\frac{1}{2}\\sum\\limits_{k;a , b } j_k^aa^{ab}j_k^b\\right).\\end{aligned}\\ ] ]    in the limit @xmath56 the integral in eq . ( [ ph_replic2 ] )",
    "is dominated by the saddle point values of the order parameters @xmath158 , @xmath159 , and @xmath57 . solving the saddle point equation with respect to @xmath160 and @xmath159 yields @xmath161 .",
    "( [ ph_replic2 ] ) takes the form @xmath162 @xmath163 can be calculated by assuming either rs or one - step rsb for the matrix @xmath51 resulting in eqs .",
    "( [ ph_rs ] ) and ( [ ph_rsb ] ) , respectively .",
    "the remaining saddle point condition for the matrix @xmath57 has in one - step rsb ( [ rsb ] ) the form @xmath164 } +   \\frac{1}{2m}\\ln\\left(1+\\frac{m(q_1-q_0)}{1-q_1}\\right ) + \\frac{1}{2}\\ln(1-q_1)\\right .",
    "\\nonumber\\\\ & + & \\left.\\frac{\\alpha}{m } \\left\\langle\\!\\!\\left\\langle\\int\\prod\\limits_{k}dy_k\\ln\\left\\ { \\int\\prod\\limits_{k}dz_k\\left(\\phi_{\\rm lir}(\\sigma)\\right)^m\\right\\ } \\right\\rangle\\!\\!\\right\\rangle_{\\sigma } \\right ] .",
    "\\label{saddle1}\\end{aligned}\\ ] ]    it determines a set of order parameters @xmath165 for every pattern load below the storage capacity @xmath166 . the abbreviation @xmath167 is defined by eq .",
    "( [ sum_lir_1 ] ) .",
    "the angular brackets @xmath168 indicate the average over the two possible outputs @xmath169 .    [",
    "99 ] m. mezard and s. patarnello , lptens report , 1989 ( unpublished ) .",
    "m. griniasty and t. grossman , phys .",
    "a * 45 * , 8924 ( 1992 ) .",
    "a. priel , m. blatt , t. grossman , e. domany and i. kanter , phys .",
    "e * 50 * , 577 ( 1994 ) .",
    "b. schottky , j. phys .",
    "a * 28 * , 4515 ( 1995 ) .",
    "r. monasson and r. zecchina , phys .",
    "lett . * 75 * , 2432 ( 1995 ) .",
    "a. engel , j. phys .",
    "a * 29 * , l323 ( 1996 ) .",
    "d. malzahn , a. engel and i. kanter , phys .",
    "e * 55 * , 7369 ( 1997 ) .",
    "e. barkai , d. hansel and i. kanter , phys .",
    "lett . * 65 * , 2312 ( 1990 ) .",
    "e. barkai , d. hansel and h. sompolinsky , phys .",
    "a * 45 * , 4146 ( 1992 ) .",
    "a. engel , h. m. khler , f. tschepke , h. vollmayr and a. zippelius , phys .",
    "a * 45 * , 7590 ( 1992 ) .",
    "p. majer , a. engel and a. zippelius , j. phys .",
    "a * 26 * , 7405 ( 1993 ) , whyte and sherrington , _ ibid . _",
    "* 29 * , 3063 ( 1996 ) .",
    "g. gyrgyi and p. reimann , phys .",
    "lett . * 79 * , 2746 ( 1997 ) .",
    "e. gardner , j. phys .",
    "a * 21 * , 257 ( 1988 ) , e. gardner , b. derrida , _ ibid . _",
    "* 21 * , 271 ( 1988 ) .",
    "m. mzard , g. parisi and m. virasoro , _ spin glass theory and beyond _",
    "( world scientific , singapore , 1987 ) .",
    "e. gardner , j. phys .",
    "a * 22 * , 1969 ( 1989 ) .",
    "m. opper , phys .",
    "a * 38 * , 3824 ( 1988 ) .",
    "d. j. amit , m. r. evans , h. horner and k. y. wong , j. phys .",
    "a * 23 * , 3361 ( 1990 ) . w. h. press , s. a. teukolsky , w. t. vetterling and b. p. flannery , _ numerical recipes _ ( cambridge university press , cambridge , england , 1992 ) .        .",
    "saturated @xmath0 machines : integrated features of the probability distribution @xmath78 of the local field .",
    "corrections by one - step rsb are given in percent of the respective rs value .",
    "dashes indicate that a respective singular contribution does not occur ( committee ) or that we found no rsb ( and ) .",
    "[ cols=\"<\",options=\"header \" , ]"
  ],
  "abstract_text": [
    "<S> we consider feed - forward neural networks with one hidden layer , tree architecture and a fixed hidden - to - output boolean function . </S>",
    "<S> focusing on the saturation limit of the storage problem the influence of replica symmetry breaking on the distribution of local fields at the hidden units is investigated . </S>",
    "<S> these field distributions determine the probability for finding a specific activation pattern of the hidden units as well as the corresponding correlation coefficients and therefore quantify the division of labor among the hidden units . </S>",
    "<S> we find that although modifying the storage capacity and the distribution of local fields markedly replica symmetry breaking has only a minor effect on the correlation coefficients . </S>",
    "<S> detailed numerical results are provided for the parity , committee and and machines with k=3 hidden units and nonoverlapping receptive fields . </S>"
  ]
}