{
  "article_text": [
    "the design of a computationally efficient soft - decision decoding algorithm for reed - solomon ( rs ) codes has been the topic of significant research interest for the past several years .",
    "currently , there are several soft - decision decoding algorithms for rs codes which exhibit a wide range of trade - offs between computational complexity and error performance",
    ".    among such decoding methods is a class of algorithms called multiple errors - and - erasures decoding .",
    "the algorithms belonging to this class first construct a set of erasure patterns based on the available soft information and then run an errors - and - erasures decoding algorithm , such as the berlekamp - massey ( bm ) algorithm , multiple times .",
    "each time one erasure pattern in the set is used for decoding . by doing this , the algorithm outputs a list of candidate codewords and then chooses the best codeword from the list .",
    "several algorithms of this type , including the popular generalized minimum distance ( gmd ) decoding algorithm , are discussed in @xcite .    in @xcite ,",
    "the authors proposed a rate - distortion ( rd ) approach for constructing the set of erasure patterns .",
    "the main idea is to choose an appropriate distortion measure so that the decoding is successful if and only if the distortion between the error pattern and erasure pattern is smaller than a fixed threshold .",
    "after that , a set of erasure patterns is generated randomly ( similar to a random codebook generation ) in order to minimize the expected minimum distortion .",
    "the approach was also extended to analyze multiple - decoding for decoding schemes beyond conventional errors - and - erasures decoding .",
    "one of the drawbacks in the rd approach is that the mathematical framework is only valid as the block - length goes to infinity .",
    "therefore , we also consider the natural extension to a rate - distortion _ exponent _ ( rde ) approach that studies the behavior of the probability , @xmath0 , that the transmitted codeword is not on the list as a function of the block - length @xmath1 .",
    "the overall error probability can be approximated by @xmath0 because the probability that the transmitted codeword is on the list but not chosen is very small compared to @xmath0 .",
    "hence , our new approach essentially focuses on investigating the exponent at which the error probability decays as @xmath1 goes to infinity .",
    "the proposed rde approach can also be considered as the generalization of the rd approach since the latter is a special case of the former when the rde function tends to zero . using the rde analysis , our proposed approach also helps answer the following two questions : ( i ) what is the maximum rate - distortion exponent achievable at or below a given number of decoding attempts ( or a given size of the set of erasure patterns ) ?",
    "( ii ) what is the minimum number of decoding attempts required to achieve a rate - distortion exponent at or above a given level ?",
    "the paper is organized as follows . in section [ sec : multiplebma ] , we review multiple errors - and - erasures decoding algorithms and highlight the connection between multiple errors - and - erasures decoding and rate - distortion .",
    "then , in section [ sec : exp - approach ] , we propose a rde approach to construct a good set of erasure patterns for a finite length codewords .",
    "next , we discuss how to compute the rde function which is required in the proposed approach .",
    "finally , simulation results are presented in section [ sec : simulation ] and conclusion is provided in section [ sec : conclusion ] .",
    "in this section , we discuss several multiple errors - and - erasures decoding algorithms .",
    "while each algorithm uses a different set of erasure patterns , the common trend is that one either erases or tries several different candidates for each symbol in the least reliable positions ( lrps ) .",
    "one focuses on the lrps because the hard - decision made at these positions are more likely to be incorrect .",
    "let @xmath2 be the galois field with @xmath3 elements denoted as @xmath4 .",
    "we consider an @xmath5 ) rs code of length @xmath1 and dimension @xmath6 over @xmath2 .",
    "assume that we send a codeword @xmath7 over some channel and @xmath8 is the received vector .",
    "a well - known decoding threshold states that a single attempt of errors - and - erasures decoding succeeds if and only if @xmath9       where @xmath10 is number of erased symbols and @xmath11 is the number of errors in unerased positions .",
    "a multiple errors - and - erasures decoding is considered to succeed if the decoding threshold ( [ eq : decthreshold ] ) is satisfied for at least one attempt of decoding .",
    "intuitively , the best case is when one erases an error and the worst case is when ones wastes an erasure on a hard - decision symbol that turns out be correct .",
    "the first algorithm of this type is called generalized minimum distance ( gmd ) decoding @xcite where the set of erasure patterns is obtained by successively erasing the @xmath12 lrps ( with the assumption that the minimum distance @xmath13 is odd )",
    ". recent work by lee and kumar @xcite proposes a soft - information successive ( multiple ) error - and erasure decoding ( sed ) which constructs the set of erasure patterns in a more exhaustive way .",
    "specifically , sed@xmath14 tries to erase all possible combinations of an even number less than or equal to @xmath15 of positions within the @xmath16 lrps .",
    "the sed algorithm hence yields better performance but at increased complexity .    in an attempt to answer the question how to build a good set of erasure patterns in terms of performance - versus - complexity , in @xcite , we proposed a probabilistic method based on rate - distortion theory and random coding arguments instead of the deterministic methods which had been used in previously proposed algorithms .",
    "basically , after defining @xmath17 and @xmath18 as an error pattern and an erasure pattern whose letters @xmath19 s and @xmath20 s are in the alphabets @xmath21 and @xmath22 respectively , a letter - by - letter distortion measure @xmath23 is chosen properly so that the condition ( [ eq : decthreshold ] ) can be reduced to the form@xmath24       where the distortion between an error pattern and an erasure pattern @xmath25 is smaller than a fixed threshold . in general , an appropriate distortion measure @xmath26 for every @xmath27 and @xmath28 should be specified .",
    "consider a specific class of multiple errors - and - erasures ( berlekamp - massey ) top-@xmath29 decoding ( mbm-@xmath29 ) for an positive integer @xmath29 smaller than the field size @xmath3 where at each codeword index , up to the @xmath29-th most likely symbols are taken care of . in this case , @xmath30 and @xmath31 where at each index @xmath32 , @xmath33 implies that using up to the @xmath29-th most likely symbols as the hard - decision all gives an error , @xmath34 implies that the @xmath35-th most likely symbol is correct for @xmath36 ; @xmath37 where at each index @xmath32 , @xmath38 implies that an erasure is applied and @xmath39 implies that the @xmath40-th most likely symbol is used as the hard - decision for @xmath41 .",
    "for example , mbm-1 is the case of multiple conventional errors - and - erasures decoding .",
    "the letter - by - letter distortion measure for mbm-1 is chosen in the following way@xmath42    it is also possible to choose appropriate distortion measures that work for @xmath43 and other decoding schemes such as algebraic soft - decision ( asd ) decoding .",
    "still , the main idea is to convert the decoding threshold of the corresponding decoding scheme into the form of ( [ eq : distorthreshold ] ) .",
    "thus , by viewing @xmath17 ( resp .",
    "@xmath18 ) as a source sequence ( resp .",
    "reproduction sequence ) and choosing a suitable distortion measure , the task of designing a good set of erasure patterns turns out to be how to best approximate the source sequence with a minimum number of reproduction sequences . in other words",
    ", it becomes a covering problem where one wants to cover the most - likely error patterns with the fewest number of balls whose centers are erasure patterns .",
    "the main steps in the rd based algorithm are given here briefly , but more detail can be found in @xcite .",
    "_ step 1 _ : empirically compute the reliability matrix whose entries are @xmath44 for @xmath45 and @xmath46 . from this , determine probability matrix @xmath47 where @xmath48 ) for @xmath49 and @xmath27 .",
    "_ step 2 _ : compute the rd function using @xmath47 . determine the test - channel input - distribution matrix @xmath50 where @xmath51 for @xmath52 and @xmath53 that achieves a point on the rd curve corresponding to a chosen rate @xmath54 .",
    "_ step  3 : _ randomly generate a set @xmath55 of  @xmath56  erasure patterns using the distribution matrix @xmath50 in the correct reliability order of the codeword positions .",
    "_ step  4 : _ run multiple attempts of the corresponding decoding scheme using the set @xmath55 to produce a list of candidate codewords .",
    "_ step  5 : _ use maximum - likelihood ( ml ) decoding to pick the best codeword on the list .",
    "in the rd approach , the set @xmath55 of @xmath57 ( or @xmath56 ) erasure patterns can be generated randomly so that and @xmath58 , respectively , using unnormalized quantities , i.e. , @xmath59 and @xmath60 . ]",
    "@xmath61<\\bar{d}.\\ ] ]       thus , for large enough @xmath1 , with high probability we have @xmath62 .",
    "basically , @xcite focuses on minimizing the average minimum distortion with little knowledge of how the tail of the distribution behaves . in this paper , we instead focus on directly minimizing the probability that the minimum distortion is not less than the pre - determined threshold @xmath63 ( due to the condition ( [ eq : distorthreshold ] ) ) with the help of an error - exponent analysis .",
    "the exact probability of interest is @xmath64 that reflects how likely the decoding threshold ( [ eq : decthreshold ] ) is going to fail .    in other words ,",
    "every error pattern @xmath17 can be covered by a sphere centered at an erasure pattern @xmath18 except for a set of error patterns of probability @xmath0 .",
    "the rde analysis shows that @xmath0 decays exponentially as @xmath65 and the maximum exponent attainable is the rde function . in our context",
    ", we have a source sequence @xmath17 of @xmath1 independent non - identical source components .",
    "we denote the rate - distortion exponent by @xmath66 using unnormalized quantities ( i.e. , without dividing by @xmath1 ) and note that exponent used by other authors in @xcite is often the normalized version @xmath67 .    the original rde function @xmath66 , defined in @xcite for a single source @xmath68 ,",
    "is given by@xmath69     where @xmath70 , @xmath71 , and    @xmath72    the rde was first extensively discussed in @xcite and their results show that there exists a set @xmath55 of roughly @xmath57 codewords , generated randomly using the test - channel input distribution matrix @xmath50 , that achieves @xmath73 .",
    "this gives the upper bound that for every @xmath74 , we have @xmath75}.\\label{eq : blahutub}\\ ] ]       for @xmath1 large enough ( see @xcite ) .",
    "an exponentially tight lower bound for @xmath0 can also be obtained for @xmath1 large enough ( see @xcite ) and this gives@xmath76     in the rde approach proposed here , instead of computing the rd function , we need to compute the rde function @xmath66 along with the optimal test - channel input distribution matrix @xmath50 ( see section [ sec : exp - func ] ) .",
    "this distribution serves as a replacement for the distribution used in step 2 of the rd based algorithm given in the previous section .",
    "apart from this , the other steps of that algorithm are unchanged for the proposed rde - based algorithm .",
    "[ rem : the - rde - approach]the rde approach possesses several advantages .",
    "first , it can help one estimate the smallest number of decoding attempts to get to a rde of @xmath77 ( or get to an error probability of roughly @xmath78 ) or , similarly , allow one to estimate the rde ( and error probability ) for a fixed number of decoding attempts",
    ". second , it provides a converse based on the sphere - packing bound lower bound for @xmath0 .",
    "this implies that , given an arbitrary set @xmath55 of roughly @xmath57 erasure patterns and any @xmath74 , the probability @xmath0 can not be made lower than @xmath79}$ ] for @xmath1 large enough .",
    "thus , no matter how one chooses the set @xmath55 of erasure patterns , the difference between the induced probability of error and the @xmath0 for the rde approach becomes negligible for @xmath1 large enough .",
    "it is interesting to note that the rde approach for asd decoding schemes contains the special case where the codebook has only one entry ( i.e. , asd decoding is run one time ) . in this case , the distribution of the codebook that maximizes the exponent implicitly generates the optimal multiplicity matrix .",
    "this is similar to the line of work @xcite where various researchers tried to find the multiplicity matrix that optimizes the error - exponent obtained by either applying a chernoff bound @xcite or using sanov s theorem @xcite .",
    "in this section , we first present an extension of arimoto s numerical method for computing the rde function @xcite that works for any chosen discrete distortion measure .",
    "next , we consider some special case where we can give an analytical treatment of the function .      for each discrete source component @xmath19 , given two parameters @xmath80 and @xmath81 ,",
    "the arimoto algorithm given in @xcite computes the rde function numerically as follows .",
    "@xmath82 step 1 : choose an arbitrary all - positive distribution vector  @xmath83 .",
    "@xmath82 step 2 : iterate the following steps at @xmath84    @xmath85       for @xmath27 and @xmath28 .",
    "it is shown by arimoto that @xmath86 and @xmath87 as @xmath88 . using the resulting @xmath89 and @xmath90 , we can compute@xmath91     where @xmath92 .",
    "however , in the context we consider , the source ( error pattern ) @xmath17 comprises independent but not necessarily identical source components @xmath19 s .",
    "the complexity is a problem if we consider a group of source letters @xmath93 as a supper - source letter @xmath94 , a group of reproduction letters @xmath95 as a super - reproduction letter @xmath96 and apply the arimoto algorithm straightforwardly . instead",
    ", we can avoid this computational obstacle by choosing the initial distribution still arbitrarily but following a factorization rule @xmath97 .",
    "then , we can verify that this factorization rule still holds for @xmath98 and @xmath99 after every step of the arimoto algorithm .",
    "this leads to @xmath100    combining with @xmath101 and @xmath102 we have @xmath103    this gives the following proposition .",
    "( factored arimoto algorithm for rde function ) consider a discrete source @xmath17 of independent but non - identical source components @xmath19 s .",
    "given parameters @xmath80 and @xmath81 , the exponent , rate and distortion are given by@xmath104where the components @xmath105 are computed parametrically by the arimoto algorithm .      in this subsection , we consider the case m - bm1 whose distortion measure is given in ( [ eq : dstmb1 ] ) .",
    "we study the setup that rs codewords defined over galois field @xmath2 are transmitted over the @xmath3-ary symmetric channel ( @xmath3-sc ) which for each parameter @xmath106 can be modeled as@xmath107 here , @xmath108 ( resp .",
    "@xmath109 ) is the transmitted ( resp",
    ". received ) symbol and @xmath110 . with this channel model",
    ", we consider @xmath106 not too small so that @xmath111",
    ". therefore , at each index @xmath32 of the codeword , the hard - decision is also the received symbol and then it is correct with probability @xmath106",
    ". thus , we have @xmath112 for every index @xmath32 of the error pattern @xmath17 . that means , in this context we have a source @xmath17 with i.i.d .",
    "binary components @xmath19 .",
    "since the components @xmath19 are i.i.d we can treat each @xmath19 as a binary source @xmath113 with @xmath114 and @xmath115 and first compute the rde function for this source @xmath113 .    according to @xcite ,",
    "for any admissible @xmath116 pair we can find two parameters @xmath80 and @xmath81 so that @xmath66 can be parametrically evaluated as@xmath117 where@xmath118 and @xmath119 are given in terms of optimizing @xmath120 which we will discuss later .    for the distortion measure in ( [ eq : dstmb1 ] ) and note that @xmath121 , we have @xmath122 which is a convex function in @xmath123 .",
    "we then see that@xmath124    in order to minimize @xmath125 over @xmath126 $ ] , we consider three following cases where the optimal @xmath127 is either on the boundary or at a point with zero gradient .",
    "@xmath82 case 1 : @xmath128 then @xmath129 . since @xmath15 convex , it is non - decreasing in the interval @xmath130 and therefore in the interval @xmath131 $ ] .",
    "thus , the optimal @xmath132 and we can also compute from ( [ eq : ffromq ] ) , ( [ eq : rfromq ] ) , ( [ eq : dfromq ] ) that@xmath133     where in this case @xmath134 .",
    "@xmath82 case 2 : @xmath135 then @xmath136 . since @xmath15 convex , it is non - increasing in the interval @xmath137 $ ] and therefore in the interval @xmath131 $ ] .",
    "thus , the optimal @xmath138 and similarly we get@xmath139    where in this case @xmath140 .",
    "we can further see that @xmath141 $ ] and @xmath142 $ ] .",
    "@xmath82 case 3 : @xmath143 then @xmath144 . in this case , the optimal @xmath145 .",
    "we then can find @xmath146 according to @xcite and plug in ( [ eq : ffromq ] ) , ( [ eq : rfromq ] ) , ( [ eq : dfromq ] ) to get and the kullback - leibler divergence is @xmath147.]@xmath148 where @xmath149 .",
    "with this notation of @xmath150 , we can express @xmath151 and @xmath152 we can see that @xmath153 . it can also be verified that , in this case , by varying @xmath154 and @xmath155 @xmath150 spans @xmath156 and @xmath54 spans @xmath157 .    based on the above analysis , we obtain the following lemmas and theorems .    [",
    "lem : lemmah]let @xmath158 map @xmath159 to @xmath54 .",
    "then , the inverse mapping of @xmath160 , @xmath161\\to\\left[1-d,1-d/2\\right),\\ ] ] is well - defined and maps @xmath54 to @xmath150 .",
    "we first notice that @xmath162 is strictly decreasing since the derivative is negative over @xmath163 , hence the mapping @xmath164 $ ] is one - to - one . from the analysis above",
    ", one can also see that @xmath160 is onto .    using mbm-1 with @xmath56 decoding attempts where @xmath165 $ ] , the maximum rate - distortion exponent that can be achieved is@xmath166    first , note that in our context where we have a source sequence @xmath17 of @xmath1 i.i.d .",
    "source components , the rate and exponent for each source component is now @xmath167 and @xmath168 . from case 3 in the analysis above and from lemma [ lem : lemmah ] , we have @xmath169 and the theorem follows .",
    "let @xmath170 map @xmath142 $ ] to @xmath77 .",
    "then , the inverse mapping of @xmath171 , @xmath172\\rightarrow[1-d , p]\\ ] ] is well - defined and maps @xmath77 to @xmath150 .",
    "we first see that @xmath173 is a strictly convex function and achieved minimum value at @xmath134 and therefore @xmath173 is strictly decreasing over @xmath174 $ ] .",
    "thus , the mapping @xmath175\\to[0,d_{kl}(1-d\\,||\\ , p)]$ ] is one - to - one . from the analysis above",
    ", one can also see that @xmath171 is onto .    in order to achieve a rate - distortion exponent of @xmath176 $ ] ,",
    "the minimum number of decoding attempts required for mbm-1 is @xmath56 where@xmath177^{+}\\ ] ]    we also note that the rate , distortion and exponent for each source component is @xmath178 and @xmath168 respectively .",
    "combining all the cases in the above analysis , we have @xmath179^{+}\\ ] ] and the theorem follows .",
    "performance of various decoding algorithms for the ( 255,239 ) rs code over an awgn channel . ]",
    "simulations of the proposed algorithm were conducted for the ( 255,239 ) rs code over an awgn channel with bpsk as the modulation format . in fig .",
    "[ fig : simulation ] , the mbm-2(rd,11 ) curve belongs to the algorithm mbm-2 using rd approach proposed in @xcite while the mbm-2(rde,11 ) one corresponds to the algorithm mbm-2 using rde approach proposed in this paper .",
    "the label sed(12,12 ) denotes the algorithm presented in @xcite . while all these three algorithms use the same number of @xmath180 erasure patterns , at a fer of @xmath181 , the mbm2(rde,11 )",
    "provides a performance gain of roughly 0.4 db over the sed(12,12 ) and outperforms the mbm2(rd,11 ) by about 0.1 db .",
    "the conventional hdd and the gmd algorithms have modest performance since they use only one or a few decoding attempts . compared to the conventional hdd , the proposed algorithm mbm-2(rde,11 ) gives approximately a 0.9 db gain .",
    "it also outperforms the koetter - vardy ( kv ) algorithm @xcite with infinite multiplicity @xmath182 .",
    "the performance of mbm-2(rde,11 ) is roughly the same as the performance of masd-3(rde,11 ) .",
    "this implies that , for this setup , algorithms based on multiple trials of bm decoding perform as good as algorithms based on running the more complicated asd decoding multiple times . in fig .",
    "[ fig : simqsc ] , we simulate the performance mbm-1(rde,11 ) for the same rs code over an @xmath3-sc channel .",
    "one curve reflects the simulated frame - error rate ( fer ) and the other is the approximation derived from @xmath183 where @xmath77 is given in ( [ eq : computef ] ) with @xmath184 .",
    "performance of mbm-1(rde,11 ) and its approximation @xmath183 where @xmath77 is given in ( [ eq : computef ] ) for the ( 255,239 ) rs code over an @xmath3-sc(@xmath106 ) channel . ]",
    "a rde - based algorithm has been proposed for multiple decoding attempts of rs codes .",
    "the rde analysis shows that this approach has several advantages .",
    "firstly , the rde approach achieves a near optimal performance - versus - complexity trade - off among algorithms that consider running a decoding scheme multiple times ( see remark [ rem : the - rde - approach ] ) .",
    "secondly , it can help one estimate the error probability using exponentially tight bounds for @xmath1 large enough .",
    "simulations are used to confirm that algorithms using this approach achieve a better trade - off than previously known algorithms . along with this , a numerical method is given to compute the required rde function .",
    "our future work focuses on extending this approach to analyze multiple decoding attempts for isi channels . in this case",
    ", it makes sense for the decoder to consider multiple candidate error - events during decoding .",
    "extending the rd approach directly gives a rd problem for markov sources in the large distortion regime .",
    "some work is required though because this is a well - known open problem .",
    "lee and b.  v. k.  v. kumar , `` soft - decision decoding of reed - solomon codes using successive error - and - erasure decoding , '' in _ proc .",
    "ieee global telecom .",
    "_ , new orleans , la , nov . 2008 , pp . 15 .",
    "s. nguyen , h.  d. pfister , and k.  r. narayanan , `` a rate - distortion perspective on multiple decoding attempts for reed - solomon codes , '' in _ proc .",
    "47th annual allerton conf .  on commun . , control , and comp",
    "_ , monticello , il , oct . 2009",
    ".            m.  el - khamy and r.  j. mceliece , `` interpolation multiplicity assignment algorithms for algebraic soft - decision decoding of reed - solomon codes , '' _ ams - dimacs volume on algebraic coding theory and information theory _ ,",
    "68 , pp . 99120 , 2005 .",
    "h.  das and a.  vardy , `` multiplicity assignments for algebraic soft - decoding of reed - solomon codes using the method of types , '' in _ proc .",
    "ieee int .",
    "symp .  information theory _ ,",
    "seoul , korea , june 2009 , pp ."
  ],
  "abstract_text": [
    "<S> algorithms based on multiple decoding attempts of reed - solomon ( rs ) codes have recently attracted new attention . </S>",
    "<S> choosing decoding candidates based on rate - distortion theory , as proposed previously by the authors , currently provides the best performance - versus - complexity trade - off . in this paper , an analysis based on the rate - distortion exponent </S>",
    "<S> is used to directly minimize the exponential decay rate of the error probability . </S>",
    "<S> this enables rigorous bounds on the error probability for finite - length rs codes and leads to modest performance gains . as a byproduct </S>",
    "<S> , a numerical method is derived that computes the rate - distortion exponent for independent non - identical sources . </S>",
    "<S> analytical results are given for errors / erasures decoding . </S>"
  ]
}