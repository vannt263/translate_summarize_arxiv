{
  "article_text": [
    "n - body simulations have traditionally been used in fields such as astrophysics and molecular dynamics , where the physics is naturally described by pairwise interaction of discrete bodies .",
    "however , applications for n - body solvers can be found in many other areas of physics including elastics , fluid dynamics , electromagnetics , acoustics , and quantum mechanics .",
    "this is made possible by transforming the partial differential equation governing the continuum field into an integral equation over discrete quadrature points .",
    "therefore , n - body solvers are used in numerous scientific application codes and are considered as one of the key algorithmic components in scientific computing .",
    "the fast multipole method ( fmm ) is a fast algorithm that reduces the complexity of the n - body problem from @xmath1 to @xmath2 .",
    "it is widely regarded as one of the top 10 algorithms in scientific computing @xcite , along with fft and krylov subspace methods .",
    "it is quite common that algorithms with low byte / flop ( dense linear algebra ) have high complexity @xmath3 , and algorithms with low complexity ( fft , sparse linear algebra ) have high byte / flop .",
    "the fmm has an exceptional combination of @xmath2 complexity and a byte / flop that is even lower than matrix - matrix multiplication @xcite . in other words",
    ", it is an _",
    "efficient _ algorithm that is _ compute _ bound , which makes it an interesting alternative algorithm for many elliptic pde solvers , on architectures of the future that will most likely have low byte / flop .",
    "the recent trend in computer architecture is shifting towards less and less byte / flop ratios .",
    "a summary of the byte / flop of flagship architectures from each vendor ( as of august 2012 ) is shown in table [ tab : byteperflop ] . from this table",
    ", one can see that the byte / flop will soon fall below 0.2 , which makes it very difficult for most algorithms to extract a high percentage of peak flop / s from these architectures . according to the roofline study by williams _",
    "@xcite , sparse matrix - vector multiplication has about @xmath4 byte / flop , stencil calculations have about @xmath5 byte / flop , and 3-d fft has about @xmath6 byte / flop .",
    "it is clear how much the modern architectures are _ off balance _ compared to the requirements of these common algorithms .",
    "this trend will most likely continue , so it is necessary to rethink the underlying algorithms in scientific simulations .",
    "matrix - free methods seem to have an advantage in this respect , and fmm can be viewed as one of them .    in a recent study",
    "we have shown that fmm becomes faster than fft when scaling to thousands of gpus @xcite .",
    "the comparative efficiency between fmm and fft can be explained from the asymptotic amount of communication . on a distributed memory system with @xmath7 nodes ,",
    "a 3-d fft requires two global transpose communications between @xmath8 processes so the communication complexity is @xmath9 . on the other hand ,",
    "the hierarchical nature of the fmm reduces the amount of communication to @xmath10 . a preliminary feasibility study for exascale machines @xcite indicates that the necessary bandwidth for fft could only be provided by a fat - tree or hypercube network .",
    "however , constructing such network topologies for millions of nodes is prohibitive in terms of cost , and the current trend of using torus networks is likely to continue .",
    "therefore , network topology is another area where the trend in hardware is deviating from the requirements of common algorithms .",
    "hierarchical methods are promising in this respect , and fmm is undoubtedly one of them .",
    "it is clear from the above arguments that fmm could be an efficient alternative algorithm for many scientific applications on exascale machines .",
    "one common objection is that fmm requires much more operations than other fast algorithms like multigrid and fft , and therefore is much slower .",
    "however , as future microarchitectures move towards less and less byte / flop , the asymptotic constant of the _ arithmetic _ complexity becomes less of a concern .",
    "therefore , the advantage in the _ communication _ complexity trumps the disadvantages as mentioned in the previous paragraph .    .byte",
    "/ flop of modern microprocessors .",
    "byte / s is the theoretical peak of the memory bandwidth , and flop / s is the theoretical peak of the double - precision arithmetic throughput when fused - multiply - add units are fully utilized , along with maximum clock frequency by turbo boost ( if available ) . [",
    "cols=\"^,^,^,^,^,^\",options=\"header \" , ]     the characteristics of the 5 different codes are summarized in table [ tab : characteristics ] .",
    "` pepc ` is a treecode , while the other four are fmms . `",
    "pepc ` inherits most of it s features from salmon and warrens treecode @xcite , and has the structure of a typical treecode . on the other hand , ` ufmmlap ` can be thought of as a typical fmm code , so the contrast in the tree data structure , interaction list , series expansion , and accuracy control are most drastic between these two . `",
    "kifmm ` is similar to ` ufmmlap ` in the sense that it also uses a typical fmm framework , except the series expansion is unique .",
    "the high performance of ` kifmm ` mostly comes from the implementation ( openmp+sse with low level optimizations ) , and on a 12 ( hyper - threaded ) core machine this results in a big difference between the single core non - simd implementation of ` ufmmlap ` .",
    "although ` falcon ` is also a single core non - simd implementation , it achieves the same speed as ` kifmm ` just from purely algorithmic improvements .",
    "these algorithmic improvements include the dual tree traversal , mutual interaction , error aware local optimization of the opening angle @xmath11 , and a multipole acceptance criterion based on @xmath12 and @xmath13 @xcite . finally , `",
    "exafmm ` combines the algorithmic improvements of ` falcon ` with a highly parallel implementation using mpi , intel tbb , and avx .",
    "accuracy can be controlled by both @xmath14 and @xmath11 , the dual tree traversal is parallelized efficiently with task - based parallelism that can either use openmp 3.0 or intel tbb , and the kernels are optimized with avx to yield 300 gflop / s on a single cpu socket . with the combination of these techniques , ` exafmm ` can calculate the laplace potential+force for @xmath15 particles to 3 digits of accuracy for the force in approximately @xmath16 seconds on a single cpu socket , which exceeds the performance of most gpu implementations of fmm .",
    "the present work attempts to integrate the independent efforts in the fast n - body community to create the fastest n - body library for many - core architectures of the future .",
    "focus is placed on low accuracy optimizations , in response to the recent interest to use fmm as a preconditioner for sparse linear solvers .",
    "a direct comparison with other state - of - the - art fast @xmath0-body codes demonstrates that orders of magnitude increase in performance can be achieved by careful selection of the optimal algorithm and low - level optimization of the code .",
    "the low byte / flop of future architectures affects the choice of series expansions and translation methods , and our focus on low accuracy perturbs this decision even further .",
    "for example , the cartesian taylor expansion was shown to be much faster that spherical harmonics with rotation in the range of accuracy of interest .",
    "furthermore , simultaneous control over the order of expansion @xmath14 and opening angle @xmath11 was also shown to yield a significant increase in performance over conventional treecodes and fmms that only control either of them .",
    "the dual tree traversal offers an interesting alternative to conventional interaction list construction , and modern compilers now provide the necessary tools to parallelize them efficiently .",
    "the fact that dual tree traversals allow rectangular cells , enables great flexibility in the partitioning / load - balancing on distributed memory architectures .",
    "there has been little work in this promising area , because dual tree traversal has not been used in the fmm community until now .",
    "although the scope of the present article is focused on single node performance , we would like to point out that the current framework enables various interesting possibilities for partitioning / load - balancing fmms .",
    "the performance of the fmm code described in this article is made available to the general public .",
    "the developer has made a significant effort to make the code readable by carefully designing the code structure to make it as simple as possible , while retaining the performance .",
    "one can easily see by comparing the source code with the other 4 codes in the benchmark study , that ` exafmm ` is more than an order of magnitude smaller in terms of lines of code , while being orders of magnitude faster .",
    "a.  chandramowlishwaran , k.  madduri , and r.  vuduc .",
    "diagnosis , tuning , and redesign for multicore performance : a case study of the fast multipole method . in _ proceedings of the 2010 acm / ieee international conference for high performance computing , networking , storage and analysis _ , sc 10 , 2010 .",
    "q.  hu , n.  a. gumerov , and r.  duraiswami .",
    "scalable fast multipole methods on distributed heterogeneous architectures . in _ proceedings of the 2011 acm / ieee international conference for high performance computing , networking , storage and analysis _ ,",
    "sc 11 , 2011 .",
    "p.  jetley , l.  wesolowski , f.  gioachin , l.  v. kale , and t.  r. quinn .",
    "scaling hierarchical n - body simulations on gpu clusters . in _ proceedings of the 2010 acm / ieee international conference for high performance computing , networking , storage and analysis _ ,",
    "sc 10 , 2010 .",
    "a.  rahimian , i.  lashuk , k.  veerapaneni , a.  chandramowlishwaran , d.  malhotra , l.  moon , r.  sampath , a.  shringarpure , j.  vetter , r.  vuduc , d.  zorin , and g.  biros .",
    "petascale direct numerical simulation of blood flow on 200k cores and heterogeneous architectures . in _ proceedings of the 2010 acm / ieee international conference for high performance computing , networking , storage and analysis _ ,",
    "sc 10 , 2010 ."
  ],
  "abstract_text": [
    "<S> the present work attempts to integrate the independent efforts in the fast n - body community to create the fastest n - body library for many - core and heterogenous architectures . </S>",
    "<S> focus is placed on low accuracy optimizations , in response to the recent interest to use fmm as a preconditioner for sparse linear solvers . </S>",
    "<S> a direct comparison with other state - of - the - art fast @xmath0-body codes demonstrates that orders of magnitude increase in performance can be achieved by careful selection of the optimal algorithm and low - level optimization of the code . </S>",
    "<S> the current n - body solver uses a fast multipole method with an efficient strategy for finding the list of cell - cell interactions by a dual tree traversal . </S>",
    "<S> a task - based threading model is used to maximize thread - level parallelism and intra - node load - balancing . in order to extract the full potential of the simd units on the latest cpus </S>",
    "<S> , the inner kernels are optimized using avx instructions . </S>"
  ]
}