{
  "article_text": [
    "non - gaussian distributions occur in a multitude of applications .",
    "they may capture manifold structure  @xcite , or elicit sparsity  @xcite , express heavy or light tailed behavior  @xcite , characterize independence  @xcite , or help us model a variety of other properties of data .",
    "we focus on a particular non - gaussian distribution : the _ elliptical gamma ( eg ) distribution _ ( egd )  @xcite . the ( mean - zero ) eg density ( when it exists ) for a point @xmath0 is given by @xmath1 where @xmath2 is the scatter matrix , and @xmath3 are scale and shape parameters  @xcite .",
    "observe that   generalizes the gaussian density ( which corresponds to @xmath4 ) by reshaping it with an additional elliptical factor @xmath5 that encodes different tail and peak behaviors  see figure  [ fig : one ] for an illustration .",
    "it is worth noting that for @xmath6 the eg density can be written as a scale mixture of gaussians , using beta density as its scale ( see appendix  [ app : gsm ] ) .    [ cols=\"^,^,^ \" , ]",
    "we evaluate the performance of different models using the _ multi - information rate _",
    "( mi rate ) criterion",
    ". mi rate ( in bits / pixel ) measures the number of bits per pixel that one saves compressing the patch jointly compared to compressing all pixels independently .",
    "formally , it is defined as @xmath7 where @xmath8 is the entropy of one pixel and @xmath9 is the patch - size .",
    "the relation becomes exact if @xmath10 @xcite .",
    "table  [ table_comparison ] summarizes the performance of different procedures using mi rate .",
    "the numerical values reported had very small error bars ( variance ) between 0.0040.006 , so we do not include these in the comparisons to avoid clutter . for all models except the gaussian restricted boltzmann machine ( grbm ) and the deep belief network ( dbn ) , the dc component is modeled independently using a mixture of gaussians with 10 components .",
    "two different patch sizes are included in order to observe how the mi rate estimates of different models change if the patch size increases . among the different methods",
    ", meg shows the best performance , _ yielding the highest mi rate per pixel . _    in the table , gauss denotes the simple gaussian model ; the mi rate captured by this model is called the amount of second - order information present in the data .",
    "rg+ica corresponds to radial gaussianisation followed by one layer of independent component analysis ( ica )  @xcite .",
    "the number of layers in hierarchical ica ( hica ) @xcite and the number of components in mog ( mixtures of gaussians ) @xcite , meg and mica ( mixtures of icas )  @xcite is 16 for @xmath11 patches and 8 for @xmath12 patches .",
    "note that models like mog , hica and mica are universal approximators , therefore theoretically they may reach the performance of meg _ but with more parameters_. in practice , however , parsimonious models are usually preferred .",
    "the mi rate of dbn and grbm were evaluated by the method explained in @xcite .",
    "similar to  @xcite , we also observed that increasing the number of layers beyond two layers only worsens the results for dbn .",
    "the number of hidden variables for grbm and for both layers in dbn are 144 for @xmath11 and 720 for @xmath12 patches .",
    "we emphasize that _ the differences in mi rate shown in table  [ table_comparison ] are significant _ , because closer to the upper limit of the mi rate any improvement means capturing a lot of perceptually relevant regularities of the underlying distribution , a claim grounded in the recent psychophysical results in @xcite .    to visualize how better mi rate corresponds to capturing more regularities .",
    "we sample image patches from two different models , the eg distribution and the meg distribution with 16 components . the result is shown in fig",
    ".  [ fig.samples ] , where middle and right images correspond to sample patches from eg and meg models , respectively .",
    "the left image consists of some random image patches taken from the van hateren dataset .",
    "[ fig.samples2 ] is the same result as fig .",
    "[ fig.samples ] but for patch sizes @xmath13 . in fig .",
    "[ fig.samples ] , image patches sampled from meg is almost indistinguishable from natural image patches . for @xmath13 patch sizes , although meg captured a lot of redundancy but it has not captured all regularities and samples are distinguishable from natural images .     that are organized in a 10 by 10 grid.,title=\"fig:\",scaledwidth=32.0% ]   that are organized in a 10 by 10 grid.,title=\"fig:\",scaledwidth=32.0% ]   that are organized in a 10 by 10 grid.,title=\"fig:\",scaledwidth=32.0% ]     for @xmath12 patches.,title=\"fig:\",scaledwidth=32.0% ]   for @xmath12 patches.,title=\"fig:\",scaledwidth=32.0% ]   for @xmath12 patches.,title=\"fig:\",scaledwidth=32.0% ]    finally , fig .",
    "[ fig.nummix ] visualizes the effect of number of mixture components and number of layers on the performance of different models for @xmath14 image patches .",
    "the baseline gaussian mi rate is plotted as a dotted line .",
    "we studied a powerful class of symmetric distributions , namely , elliptical gamma distributions .",
    "we presented theory outlining existence and uniqueness of maximum likelihood estimators for egds and developed simple and computationally effective algorithms computing these .",
    "several avenues of further research remain open .",
    "the most important direction is to study robust subspace recovery and its applications  @xcite .",
    "other potential directions involve developing mathematical tools to study stochastic processes based on egds , as well as to investigate other applications where non - gaussian data can benefit from egds or their mixture models .",
    "we hope that the theory and its practical application outlined in this paper encourage a wider study of non - gaussian modeling with egds or more general ecds .",
    "51 # 1isbn # 1#1#1 # 1#1 # 1#1#1 # 1#1 # 1*#1*#1#1 # 1#1 # 1#1 # 1#1 # 1#1 # 1#1 # 1#1 # 1#1 # 1#1 # 1_#1 _ # 1#1 # 1#1 # 1#1 # 1#1 # 1#1 # 1#1 # 1#1 # 1#1 # 1#1 # 1#1 # 1#1 # 1#1 # 1#1 # 1#1 # 1#1 # 1#1    , , , .",
    "( ) ,  ( )    , , , , . , ",
    "( )    , , _ method and device for image compression _ , 2014 . us patent 8,750,603    , , .",
    "( ) ,  ( )    , , , , . ,",
    " ( ) .    , .",
    "( , , )    , , , , , , , .",
    "( ) ,  ( )    , , , . , ",
    "( )    , , ( , , )    , , , ( , , )    , , , ( ) , ( )    , , ( , , )    , .",
    "( ) ,  ( )    , , ( , , )    , , , in ,    , , , .",
    "( ) ,  ( )    , natural image modelling using mixture models with compression as an application , phd thesis , technische universtitt berlin , 2012    , , mixest : an estimation toolbox for mixture models . arxiv preprint arxiv:1507.06065 ( 2015 )    , .",
    "( ) ,  ( )    , , .",
    "( ) ,  ( )    , , ( , , )    , , , ( , , )    , , in , ed . by , , ( , , ) ,",
    "( ) ,  ( )    , , , .",
    "( ) ,  ( )    , , , , in , , pp .",
    "( ) ,  ( )    , , , , representation of higher - order statistical structures in natural scenes via spatial phase distributions",
    ". vision research * doi : 10.1016/j.visres.2015.06.009 * ( 2015 )    , .",
    "( ) ,  ( )    , , , , in ,    , , the em algorithm  an old folk - song sung to a fast new tune . journal of the royal statistical society .",
    "series b ( methodological ) , 511567 ( 1997 )    , _ estimating a gamma distribution _ , http://research.microsoft.com/en-us/um/people/minka/papers/minka-gamma.pdf , 2002    , , ( , , )    , , , , . ( ) ,  ( )    , .",
    "( ) ,  ( )    , , .",
    "( ) ,  ( )    , , .",
    "( )    , , .",
    "( ) ,  ( )    , , .",
    "( ) ,  ( )    , , , in , , pp .     , , .",
    "( ) ,  ( )    , , .",
    "( ) ,  ( )    , , , , .",
    "( )    , , , , . , ",
    "( ) ,  ( a )    , .",
    "( ) ,  ( b )    , , .",
    "( ) ,  ( )    , , kl - divergence between angular central gaussian distributions ( 2015 ) . manuscript submitted for publication    , , , .",
    "( ) ,  ( )    , robust subspace recovery by tyler s m - estimator . information and inference * doi : 10.1093/imaiai / iav012 * ( 2015 )    , , , in , , pp . ",
    "from properties of laplace transform , we know that the inverse laplace transform of the following function @xmath15 is equal to @xmath16 using the definition of laplace transform , we obtain : @xmath17 now assume @xmath18 , @xmath19 and @xmath20 , then the left term in the equation above is the eg density given in  .",
    "after straightforward computations , we can write the eg density as a scale mixture of gaussian densities : @xmath21 without loss of generality assume @xmath22 and use the change of variable @xmath23 , we obtain : @xmath24 interestingly , the first term is beta density with parameters @xmath25 : @xmath26",
    "by the assumption @xmath27 , we have : @xmath28 substituting @xmath29 and @xmath30 in the previous equation , we obtain :    @xmath31    let @xmath32 be a right eigenvector for @xmath33 corresponding to the eigenvalue @xmath34 , then multiplying   from left by @xmath35 and from right by @xmath32 and using the fact that the following equality holds for the eigenprojection : @xmath36 we obtain : @xmath37    using the fact that the product of two positive definite matrices has positive eigenvalues @xcite , following two inequalities can be derived by straightforward computations : @xmath38 where @xmath39 and @xmath40 are the largest and the smallest eigenvalues respectively .",
    "it is clear that if @xmath41 or @xmath42 then inequalities in   contradicts the equality in  .",
    "therefore , all eigenvalues of @xmath43 need to be equal to one which implies @xmath44 or @xmath45 and the proof is complete .",
    "by definition , @xmath46 we multiply both the numerator and denominator of the first term by @xmath47 , and in the numerator we replace @xmath47 by @xmath48 . in addition , we multiply on both sides by an orthogonal matrix @xmath49 .",
    "this yields : @xmath50 since the square root of the matrix @xmath51 can be written as @xmath52 , using  , we obtain the identity @xmath53 now substitute into   to obtain the equation @xmath54 by the extremal properties of the largest and smallest eigenvalues , we know that @xmath55 therefore , on applying the inequalities   to  , we obtain following two inequalities : @xmath56+\\alpha_p{\\bm{\\gamma}}_{p+1}^{-1 } \\geq { \\bm{i}},\\\\ \\label{eqn_2m2 }     & { \\bm{i}}\\geq \\lambda_{1,p}^{-1}\\left [ c \\sum_{i=1}^{n}{\\frac{{\\bm{\\gamma}}_{p+1}^{-\\frac{1}{2}}\\ { \\bm{y}}_i^\\top    { \\bm{y}}_i\\ { \\bm{\\gamma}}_{p+1}^{-\\frac{1}{2}}}{{\\bm{y}}_i^\\top   \\ { \\bm{\\gamma}}_{p+1}^{-1 } \\   { \\bm{y}}_i } } \\right ] + \\alpha_p{\\bm{\\gamma}}_{p+1}^{-1}.\\end{aligned}\\ ] ] rearranging the equality in  , we have the equality @xmath57 which can be applied to   to obtain the following inequality : @xmath58+\\alpha_p{\\bm{\\gamma}}_{p+1}^{-1 } \\geq { \\bm{i } } , \\label{eqn_2fpow}\\end{aligned}\\ ] ] which in turn can be rearranged to @xmath59 writing the singular value decomposition of @xmath60 as @xmath61 , and multiplying   from the left by @xmath62 and from the right by @xmath63 , we obtain @xmath64 let @xmath65 , then if the data points span @xmath66 , the matrix @xmath67 is positive semidefinite , and in particular its diagonal elements are nonnegative . consequently , all diagonal elements of @xmath68 are larger than or equal to @xmath69 .",
    "therefore , if @xmath70 , then @xmath71 holds true .",
    "+ applying the same procedure to the other inequality  , we obtain @xmath72 let @xmath73 , then if the data points span @xmath66 , the matrix @xmath74 is positive semidefinite . therefore",
    ", all its diagonal are nonnegative , whereby all diagonal elements of @xmath68 are smaller or equal to @xmath75 . therefore , if @xmath73 then @xmath76 holds true ."
  ],
  "abstract_text": [
    "<S> we study modeling and inference with the _ elliptical gamma distribution _ ( egd ) . </S>",
    "<S> we consider maximum likelihood ( ml ) estimation for egd scatter matrices , a task for which we develop new fixed - point algorithms . </S>",
    "<S> our algorithms are efficient and converge to global optima despite nonconvexity . moreover , they turn out to be much faster than both a well - known iterative algorithm of kent & tyler ( 1991 ) and sophisticated manifold optimization algorithms . </S>",
    "<S> subsequently , we invoke our ml algorithms as subroutines for estimating parameters of a mixture of egds . </S>",
    "<S> we illustrate our methods by applying them to model natural image statistics  </S>",
    "<S> the proposed egd mixture model yields the most parsimonious model among several competing approaches . </S>"
  ]
}