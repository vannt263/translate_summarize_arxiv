{
  "article_text": [
    "today s search engine interfaces are appropriate when the user knows _ what _ to seek and _ how _ to seek it . however , they are unable to reflect the user context and therefore they are not smart enough to understand the real user s needs . for several years",
    "researchers in the artificial intelligent community have talked about the importance of intelligent systems that cooperate with the user to facilitate a number of computer mediated task  @xcite .",
    "more recently , the problem of accessing relevant information through intelligent systems has become a main research area . in order to implement intelligent information retrieval ( ir ) systems",
    "some researchers have proposed taking advantage of existing services to build more powerful tools on top of them  @xcite .",
    "examples of systems that apply this approach take advantage of major search engines to perform intelligent context - based search  @xcite    the web can be regarded as a rich repository of collective memory . an intelligent system that incrementally searches this repository to find material that is useful to the user s current needs can act as a memory augmentation aid . by an association of similarities , this aid can help users remember information ,",
    "assure that areas relevant to the current task have been considered , and pursue new directions .",
    "descriptions of a user s needs , however , are usually deficient because they are typically based on the a priori knowledge of the topic of interest .",
    "this knowledge might be insufficient to formulate a good query , or more commonly , the vocabulary used by the user might not be appropriate to target the request at the right kind of material . in certain scenarios , attaining novelty and diversity may be as important , or even more important , than attaining similarity . for human - generated queries",
    "users frequently decide , based on initial results , to refine subsequent queries .",
    "if contextual information is available , part of the query formation and refinement process can be automated .",
    "this paper proposes a new technique for incrementally learning a better characterization of the user context .",
    "the work presented here suggests and tests the following hypotheses : ( 1 ) the vocabulary describing the initial context can be used to identify semantically related documents and terms , but ( 2 ) the terms describing the initial context are not necessarily the most appropriate ones to generate search queries , and ( 3 ) the characterization of the search context can be incrementally improved by a semi - supervised learning algorithm .",
    "our algorithm is based on the dynamic extraction of topic descriptors and discriminators , as first introduced in @xcite .",
    "the main contribution of this paper is the proposal of a new mechanism for learning rich vocabularies associated with a thematic context .",
    "the learned vocabulary provides an improved characterization of the topic of interest in the sense that it allows to better identify topically relevant material .",
    "the effectiveness of our proposal is assessed by carrying out a comprehensive evaluation on a large collection of human - generated topic descriptions .",
    "for many computer - mediated tasks , the user context provides a rich set of terms that can be exploited by intelligent systems to generate queries and present related information to the user .",
    "such systems can be equipped with special monitoring capabilities , designed to generate a model of the user context .",
    "the system will be in charge of observing how the user interacts with different kinds of computer utilities ( such as email systems , browsers and text editors ) to characterize the user s information needs as a collection of weighted terms .",
    "this requires a framework for learning context - specific terms .",
    "a central question addressed in our work is how to learn context - specific terms based on the user current context and an open collection of incrementally retrieved documents . in what follows",
    ", we will assume that a user context is represented as a set of terms .",
    "consider for example a topic involving the _ java virtual machine_. context - specific terms may play different roles . for example , the term _ java _ is a good descriptor of the topic for a general audience .",
    "however , _",
    "java _ is not a good discriminator for that topic because it might also refer to the island in indonesia , the java shark , a brand of russian cigarettes or a variety of coffee grown on the island of java , among other possibilities .    if we reconsider the topic _ java virtual machine _",
    "we notice that terms such as _ jvm _ and _ jdk_which stand for `` java virtual machine '' and `` java development kit''may not be good descriptors of the topic for a general audience , but are effective in bringing information that is relevant for our topic of interest when presented in a query .",
    "therefore , _",
    "jvm _ and _ jdk _ are good discriminators of that topic .",
    "a natural question that arises in this scenario is how to identify the terms that act as good descriptors and good discriminators of a topic . in previous work",
    "@xcite we have studied and tested the following two hypotheses :    * good topic descriptors can be found by looking for terms that occur in documents related to the given topic . *",
    "good topic discriminators can be found by looking for terms that occur in documents related to the given topic .",
    "both topic descriptors and discriminators are important as query terms . because topic descriptors occur often in relevant pages , using them as query terms may improve recall .",
    "similarly , good topic discriminators occur primarily in relevant pages , and therefore using them as query terms may improve precision .      as a first approximation to compute descriptive and discriminating power , we begin with a collection of @xmath0 documents and @xmath1 terms . as a starting point",
    "we build an @xmath2 matrix @xmath3 , such that @xmath4=k$ ] if @xmath5 is the number of occurrences of term @xmath6 in document @xmath7 .",
    "in particular we can assume that one of the documents ( e.g. , @xmath8 ) corresponds to the initial user context .",
    "the matrix @xmath3 allows us to formalize the notions of good descriptors and good discriminators .",
    "we define _ descriptive power of a term in a document _ as a function @xmath9 $ ] : @xmath10 }                       { \\sqrt{\\sum_{k=0}^{n-1 } ( { { \\bf h}}[i , k])^2}}.\\ ] ] note that @xmath11 can be regarded as a version of matrix @xmath3 normalized by row ( i.e , by document ) .",
    "if we adopt @xmath12 whenever @xmath13 and @xmath14 otherwise , we can define the _ discriminating power of a term in a document _ as a function @xmath15$]:@xmath16 ) }                       { \\sqrt{\\sum_{k=0}^{m-1 } { \\mathrm s}({{\\bf h}}[k , i])}}.\\ ] ]    in this case @xmath17 can be regarded as a transposed version of matrix @xmath3 normalized by column ( i.e , by term ) .",
    "our current goal is to learn a better characterization of the user needs .",
    "therefore rather than extracting descriptors and discriminators directly from the user context , we want to extract them from _ the topic _ of the user context .",
    "this requires an incremental method to characterize the topic of the user context , which is done by identifying documents that are similar to the user current context .",
    "assume the user context and the retrieved documents are represented as document vectors in term space . to determine how similar two documents @xmath7 and",
    "@xmath18 are we adopt the ir cosine similarity @xcite .",
    "this measure is defined as a function @xmath19$]:@xmath20.\\ ] ]    we formally define the _ term descriptive power in the topic of a document _ as a function @xmath21 $ ] .",
    "we set @xmath22 if @xmath23 .",
    "otherwise we define @xmath24 as follows : @xmath25 ^ 2 ] }                        { \\sum_{\\stackrel{k=0}{k\\neq i}}^{m-1 }                                         { \\sigma}(d_i , d_k)}.\\ ] ] thus , the descriptive power of a term @xmath6 in the topic of a document @xmath7 is a measure of the quality of @xmath6 as a descriptor of documents similar to @xmath7 .",
    "analogously , we define the _ discriminating power of a term in the topic of a document _ as a function @xmath26 $ ] calculated as follows:@xmath27 ^ 2 \\cdot { \\sigma}(d_k , d_j ) ] .",
    "\\end{array}\\ ] ] thus the discriminating power of term @xmath28 in the topic of document @xmath18 is an average of the similarity of @xmath18 to other documents discriminated by @xmath28 . for a worked example showing",
    "the results of computing topic descriptors and discriminators see  @xcite .",
    "[ sec : context ] attempting to find an optimal set of terms to characterize the user thematic context gives rise to a combinatorial problem .",
    "this is not only intractable but unreasonable from a pragmatic point of view .",
    "instead , we propose to apply an intelligent ir strategy to explore and exploit potentially useful vocabularies .",
    "assume the vocabulary defines a landscape , where the initial context is a given region of this landscape .",
    "in this scenario , exploitation means to thoroughly explore a given set of terms in order to find local optima , i.e. , the best descriptors and discriminators based on a given characterization of the current context .",
    "exploration , on the other hand , refers to probe new regions of the landscape , which is dynamically discovered by performing incremental search , in the hope of finding either better descriptors or better discriminators and therefore a better characterization of the thematic context .        many machine learning techniques that apply the exploration - exploitation strategy ( e.g. , simulated annealing and reinforcement learning ) attempt to diversify ( i.e. , to explore ) during initial generation and to focus ( i.e. , to exploit ) towards the end . in our approach",
    "we take a different approach and propose an algorithm that evolves topic descriptors and discriminators by alternating the exploration and the exploitation of the vocabulary landscape .",
    "we begin by exploiting the initial vocabulary by focusing on the initial context .",
    "this vocabulary is used to iteratively form queries that are submitted to a search engine . if after a certain number of iterations there are no significant improvements on the search results , our algorithm performs a phase change to explore new potentially useful regions of the vocabulary landscape .",
    "a phase change can be regarded as a vocabulary leap , which can be thought of as a significant transformation ( typically an improvement ) of the context characterization .",
    "a schematic illustration of the proposed mechanism for learning better context characterization is shown in figure  [ fig : algdiagram ] and is summarized in the following steps :    1 .",
    "let @xmath29 be the initial context description .",
    "2 .   set @xmath30 .",
    "@xmath31 , repeat 1 .   start phase @xmath32 2 .",
    "set @xmath33 and @xmath34 3 .",
    "@xmath35 , repeat 1 .",
    "start @xmath32 evolution , @xmath36 .",
    "2 .   set @xmath37 equal to some combination of context terms . for details on how the combination was implemented in our tests . ]",
    "3 .   do search with @xmath37 .",
    "make lists of topic descriptors and discriminators , @xmath38 and @xmath39 , based on search results and @xmath40 .",
    "update @xmath41 and @xmath42 * @xmath43",
    ". 6 .   analyze the documents similarity for reasons that will become obvious in that section . ] to @xmath40 every @xmath44 iterations : * if there is a low variation ( @xmath45 ) , end @xmath36 .",
    "return @xmath46 and @xmath47 .",
    "* if the process has run for at least @xmath48 iterations and there is a very low variation ( @xmath49 ) , end @xmath32 and goto  [ step : end ] .",
    "4 .   update @xmath40 with terms containing high @xmath51 and @xmath52 values to obtain @xmath53 .",
    "5 .   let @xmath54 represent the weight of term @xmath55 in context @xmath56 .",
    "6 .   set the terms weights @xmath57 7 .",
    "[ step : end]end process .",
    "the goal of this section is to provide empirical evidence supporting the hypotheses postulated in section  [ sec : introduction ] .",
    "we show that the proposed algorithm can help enrich the topic vocabulary and that the learned vocabulary allows to generate queries that result in better retrieval performance than queries generated directly from the initial vocabulary .    to perform our tests we used nearly 500 topics from the open directory project ( odp ) .",
    "the topics were selected from the third level of the odp hierarchy .",
    "a number of constraints were imposed on this selection with the purpose of ensuring the quality of our test set .",
    "the minimum size for each selected topic was 100 urls and the language was restricted to english . for each topic",
    "we collected all of its urls as well as those in its subtopics .",
    "the total number of collected pages was more than 350000 .",
    "the terrier framework  @xcite was used to index these pages and to run our experiments .    in our tests",
    "we used the odp description of each selected topic to create an initial context description @xmath29 .",
    "the proposed algorithm was run for each topic for at least @xmath59 iterations , with 10 queries per iteration and retrieving 10 results per queries . to create the queries @xmath37 at each iteration we used the roulette selection mechanism .",
    "roulette selection is a technique typically used by genetic algorithms  @xcite to choose potentially useful solutions for recombination , where the fitness level is used to associate a probability of selection . in our case ,",
    "the fitness level was determined by the descriptive or discriminating power values of the terms .",
    "the descriptor and discriminator lists were limited to up to 100 terms each .",
    "the other parameters in our algorithm were set as follows : @xmath60 , @xmath61=0.5 , @xmath62=0.5 , @xmath63=0.33 , @xmath64=0.33 , @xmath65=0.33 , @xmath66=0.2 and @xmath67=0.1 .",
    "in addition , we used the stopword list provided by terrier , porter stemming was performed on all terms and none of the query expansion methods offered by terrier was applied .    to analyze the evolution of the context vocabulary we propose here a revised notion of similarity .",
    "this measure of similarity is based on @xmath68 but disregards the terms that form the query , favoring the exploration of new material .",
    "given a set of queries @xmath69 we define a novelty - driven similarity measure @xmath70 $ ] as : @xmath71 the notation @xmath72 stands for the representation of the document @xmath7 with all the values corresponding to the terms from query @xmath73 set to zero .",
    "the same applies to @xmath74 .",
    "home@xmath75cooking@xmath75for_children ( left ) and top@xmath75computers@xmath75open_source@xmath75software ( right).,title=\"fig : \" ] home@xmath75cooking@xmath75for_children ( left ) and top@xmath75computers@xmath75open_source@xmath75software ( right).,title=\"fig : \" ]    we computed the novelty - driven similarity measure @xmath76 between the initial context ( topic descriptions ) and the retrieved results .",
    "the goal was to investigate the impact that each phase change had on the query performance .",
    "figure  [ fig : evolution - novel - sim ] shows the evolution of the novelty - driven similarity for the topics top@xmath75home@xmath75cooking@xmath75for_children and top@xmath75computers@xmath75open_source@xmath75software .",
    "we used the minimum , average and maximum novelty - driven similarity between the initial context and the search results at each iteration to illustrate the evolution of the context vocabulary .",
    "it is worth noticing that the vocabulary leaps that generally take effect every 10 iterations have an important impact on the quality of the retrieved material .",
    "this provides evidence that the proposed algorithm can help enrich the topic vocabulary .            after observing that our algorithm had an impact on the retrieval performance , our next step was to quantify this impact . with that purpose we computed four measures of query quality for the queries formed using the initial vocabulary and for the queries constructed using the evolved vocabulary .",
    "the measures used for this performance comparison are ( 1 ) maximum novelty - driven similarity , ( 2 ) precision ( fraction of retrieved documents which are known to be relevant ) , ( 3 ) recall ( fraction of known relevant documents which were effectively retrieved ) , and ( 4 ) the harmonic mean f1 ( a measure which combines recall and precision ) . for a detailed description of these",
    "well - known performance metrics we refer the reader to any ir textbook ( e.g. ,  @xcite ) .",
    "it is worth mention that the relevant set for each analyzed topic was set as the collection of its urls as well as those in its subtopics .",
    "the charts in figure  [ fig : novelty - precison - recall - f1score ] compare the performance of queries using the initial vocabulary against queries using the evolved vocabulary .",
    "each of the topics corresponds to a trial and is represented by a point .",
    "the point s horizontal coordinate corresponds to the performance of the queries at the first iteration ( initial vocabulary ) , while the vertical coordinate corresponds to the performance of the queries at the best iteration ( evolved vocabulary ) .",
    "the points above the diagonal corresponds to cases in which an improvement is observed for the evolved vocabulary . in this evaluation ,",
    "queries constructed using the evolved vocabulary outperform the initial ones in 100% of the cases for novelty - driven similarity , 89.18% of the cases for precision , 89.38% of the cases for recall , and 89.38% of the cases for the harmonic mean f1 .",
    "it is interesting to note that for all the topics analyzed the system managed to identify a better context characterization as evidenced by the 100% improvement for the novelty - driven similarity performance metric .",
    "this highlights the usefulness of evolving the context vocabularies to discover good query terms .",
    "novelty - driven similarity and precision are useful metrics at the time of evaluating the performance of ir systems that recover a few pages out of a large set of relevant documents .",
    "this is the case for our particular scenario and therefore we can use these two metrics to statistically analyze the improvements achieved by the proposed algorithm . in table  [ table : statistics ] we present the means and confidence intervals resulting from this analysis .",
    "these comparison tables show that the use of an evolved vocabulary results in statistically significant improvements over the use of the initial vocabulary .",
    ".statistical analysis comparing query performance for the initial vocabulary ( first iteration ) vs. query performance for the evolved vocabulary ( best iteration ) .",
    "[ cols=\"<,^,^,^\",options=\"header \" , ]",
    "extensions to basic ir approaches have examined some of the issues raised in this paper . for instance , some automatic relevance feedback techniques , such as the rocchio s method @xcite , make use of the full search context for query refinement . in these approaches the original query is expanded by adding a weighted sum of terms corresponding to relevant documents , and subtracting a weighted sum of terms from irrelevant documents . as a consequence the terms that occur often in documents similar to the input topic will be assigned the highest rank , as in our descriptors .",
    "however , our technique also gives priority to terms that _ occur only in relevant documents _ and not just to those that",
    "_ occur often_. in other words , we prioritize terms for both discriminating and descriptive power . the techniques for query term selection proposed in this paper share insights and motivations with other methods for query expansion and refinement  @xcite .",
    "however , systems applying these methods differ from our framework in that they support this process through a query or browsing interfaces requiring explicit user intervention , rather than formulating queries automatically .",
    "our techniques rely on the notions of document similarity to discover higher - order relationships in collections of documents .",
    "this relates to the use of lsa  @xcite to uncover the latent relationships between words in a collection .",
    "less computationally expensive techniques are based on mapping documents to a kernel space where documents that do not share any term can still be close to each other  @xcite .",
    "another corpus - based technique that has been applied to estimate semantic similarity is pmi - ir  @xcite , which measures the strength of association between two elements ( e.g. , terms ) by contrasting their observed frequency against their expected frequency . differently from our proposal ,",
    "the goal of these techniques is to estimate the semantic distance between terms and documents , without identifying topic descriptors and discriminators .",
    "in this paper we have presented an intelligent ir approach for learning context - specific terms . based on this approach ,",
    "an intelligent system can take advantage of the information available in the user context to perform search on the web or other information retrieval systems .",
    "we have shown that the user context can be usefully exploited to access relevant material .",
    "however , terms that occur in the user context are not necessarily the most useful ones . in light of this",
    "we have proposed an incremental method for context refinement based on the analysis of search results .",
    "we also distinguish two natural notions , namely topic descriptors and topic discriminators .",
    "the proposed notions are useful for meaning disambiguation and therefore can help deal with the problem of polysemy .",
    "our evaluations show the effectiveness of incremental methods for learning better vocabularies and for generating better queries .",
    "learning better vocabularies is a way to increase the awareness and accessibility of useful material .",
    "we have proposed a promising method to identify the need behind the query , which is one of the main goals for many current and next generation web services and tools . as part of our future work",
    "we expect to investigate different parameter settings for the proposed algorithm and to develop methods that automatically learn and adjust these parameters .",
    "in addition , we expect to run additional tests comparing our approach with other existing query refinement mechanisms .",
    "bodo billerbeck , falk scholer , hugh  e. williams , and justin zobel .",
    "query expansion using associated queries . in _ proceedings of the twelfth international conference on information and knowledge management _ , pages 29 .",
    "acm press , 2003 .",
    "oren etzioni . moving up the information food chain : deploying softbots on the world wide web . in _ proceedings of the thirteenth national conference on artificial intelligence and the eighth innovative applications of artificial intelligence conference _ ,",
    "pages 13221326 , menlo park , 48 1996 . aaai press / mit press .",
    "carlos  m. lorenzetti , rocio  l. cecchini , and ana  g. maguitman .",
    "intelligent methods for information access in context : the role of topic descriptors and discriminators . in _ proceedings of viii workshop",
    "de agentes y sistemas inteligentes - cacic 2007 : xiii congreso argentino de ciencias de la computacin _ , 2007 .",
    "ana maguitman , david leake , and thomas reichherzer . suggesting novel but related topics : towards context - based support for knowledge model extension . in _",
    "iui 05 : proceedings of the 10th international conference on intelligent user interfaces _ , pages 207214 , new york , ny , usa , 2005 .",
    "acm press .",
    "ana maguitman , david leake , thomas reichherzer , and filippo menczer .",
    "dynamic extraction of topic descriptors and discriminators : towards automatic context - based topic search . in _ proceedings of the thirteenth conference on information and knowledge management ( cikm ) _ ,",
    "washington , dc , november 2004 .",
    "acm press .",
    "eduardo  h. ramirez and ramon  f. brena .",
    "semantic contexts in the internet . in _",
    "la - web 06 : proceedings of the fourth latin american web congress _ , pages 7481 ,",
    "washington , dc , usa , 2006 .",
    "ieee computer society .",
    "j.  j. rocchio .",
    "relevance feedback in information retrieval . in g.",
    "salton , editor , _ the smart retrieval system - experiments in automatic document processing _ , pages 313323 .",
    "englewood cliffs , nj : prentice - hall , 1971 .",
    "falk scholer and hugh  e. williams .",
    "query association for effective retrieval . in _ proceedings of the eleventh international conference on information and knowledge management _ , pages 324331 .",
    "acm press , 2002 .",
    "peter  d. turney . mining the web for synonyms : pmi - ir versus lsa on toefl . in _",
    "emcl 01 : proceedings of the 12th european conference on machine learning _ ,",
    "pages 491502 , london , uk , 2001 .",
    "springer - verlag ."
  ],
  "abstract_text": [
    "<S> this paper proposes an incremental method that can be used by an intelligent system to learn better descriptions of a thematic context . </S>",
    "<S> the method starts with a small number of terms selected from a simple description of the topic under analysis and uses this description as the initial search context . using these terms , </S>",
    "<S> a set of queries are built and submitted to a search engine . </S>",
    "<S> new documents and terms are used to refine the learned vocabulary . </S>",
    "<S> evaluations performed on a large number of topics indicate that the learned vocabulary is much more effective than the original one at the time of constructing queries to retrieve relevant material . </S>"
  ]
}