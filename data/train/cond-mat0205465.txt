{
  "article_text": [
    "in this paper we consider the behaviour at high memory loading of a hopfield - like attractor network of @xmath0 bistable elements , the bistable gradient network or bgn@xcite@xcite .",
    "this is a sequel to an earlier paper @xcite which considered the bgn at low loading .",
    "we compare the bgn to the deterministic hopfield network ( hn)@xcite-@xcite , examining the storage capacity and other key properties .    to begin , we review the bgn model and establish some notation .",
    "the bgn is described by the coupled differential equations @xmath1 where @xmath2 are @xmath3  continuous - valued real variables ( or components of an @xmath3-dimensional state vector @xmath4 ) representing the outputs of the @xmath3 nodes of the network , and @xmath5 is the hamiltonian @xmath6 the quantities @xmath7 are the elements of a symmetric matrix of connection strengths and @xmath8 is a control parameter determining the overall strength of the coupling among nodes .  as in the hopfield modelhopfield@xcite , the connections or synaptic weights are determined by the hebb learning rule@xcite @xmath9 where the n - dimensional vectors @xmath10 represent a set of @xmath11 distinct _ memory patterns _ to be recognized by the network .",
    "we take these patterns to consist of binary elements @xmath12 only ,  and we assign them random values , thus introducing quenched disorder .  the bgn s key difference from the hn and from most of its continuous - valued relatives @xcite lies in the presence of the local quartic potential term @xmath13 in the hamiltonian , which renders each node bistable .",
    "the interaction term @xmath14 furnishes an input to each node given by @xmath15 so that the dynamical equation for each node is given by @xmath16 the input may also be referred to as a magnetic field  by analogy with ising spin systems .  in the absence of input",
    "each node has two stable fixed points at @xmath12 , but a nonzero field shifts the two fixed points .",
    "if the critical magnitude @xmath17 is exceeded then the field is strong enough to overcome the potential barrier in the quartic potential and there is then only one fixed point .",
    "we define two sets of order parameters @xmath18 and @xmath19 by @xmath20 and@xmath21 @xmath18 are inner products or overlaps of the state vector with the memorized patterns , while @xmath19 , the bit overlaps ,  encode information about sign agreements between the state vector and the stored patterns .  for the purposes of this paper",
    ", we will for the most part be more interested in @xmath19 than in @xmath22 , so where there is little risk of confusion we will drop the word bit  and simply refer to @xmath19 as an overlap .",
    "the degree of loading of the network s memory can be parametrized by the ratio @xmath23 .  in the companion paper",
    "@xcite we examined the behaviour of the bgn in the low - loading limit @xmath24 .",
    "it was shown that the network can function as an associative memory and correct sign flip errors in a stored pattern as long as @xmath25  .",
    "we found that the attractors of the bgn s dynamics are readily classified into three categories which are separated from each other in energy .",
    "the lowest energy states are the _ memory _ or _ retrieval states _ ,  each of which corresponds to one of the memorized patterns .",
    "in addition to these there are higher - energy spurious attractors of two types",
    ".  the _ mixture _ or _ spin glass states _ have partial overlaps with several patterns and thus lie close to the subspace spanned by the memory patterns .  _ uncondensed states",
    "_ , which have no counterpart in the hn , are states in which none of the fields acting on the nodes are strong enough to cause sign flips and the dynamics is therefore dominated by the local potential .",
    "they have energies per node close to @xmath26 .",
    "the spin glass states are intermediate in energy between the memory states and the uncondensed states .  in the range @xmath27 , pattern recognition by the network",
    "was found to be highly selective ;  the input must be close to the stored pattern in order for the pattern to be fully restored .",
    "the uncondensed states are numerous ( of order @xmath28 ) and fill most of the configuration space .",
    "the memorized patterns and their basins of attraction occupy isolated valleys among these states , but these valleys expand as @xmath8 increases .  for @xmath29 , on the other hand",
    ", the behaviour resembles that of the hn :  there are no uncondensed states , and the memory states have large basins of attraction .    in this paper",
    "we turn to the case where @xmath30 is of order unity .",
    "we are interested in the maximum storage capacity , or the maximum number of patterns that can be successfully stored and retrieved , as well as changes in the network s performance as this limit is approached .",
    "earlier work with small networks @xcite suggested that at least under certain conditions the bgn could store many more patterns than the hn while possessing few spurious attractors .",
    "it is known that the hopfield storage limit of @xmath31 memory patterns can be exceeded if a more complicated learning algorithm is used @xcite ,  but in the bgn case improved capacity is achieved with the familiar hebb rule .  since the previous results @xcite@xcite were obtained with networks much too small to be of practical interest ( e.g. , @xmath32 ) ,  we now examine larger networks , mainly through numerical simulations .",
    "( at the end of the paper we will return briefly to the small - network case . )",
    "we find that the high - loading behaviour , like that at low loading , depends strongly on @xmath33  for @xmath34 , a hopfield - like first - order phase transition results in the destabilization of all memory states at a critical value of @xmath35 .  for @xmath36",
    "this transition occurs at @xmath37 , compared to @xmath38 for the hn .  for @xmath39 ,",
    "on the other hand ,  we find that it is possible for the stored patterns to remain stable even at loading factors of @xmath40 and higher .",
    "furthermore , there is no sudden blackout ; instead , the performance degrades gradually as @xmath35 increases .",
    "the price of this high capacity is that the retrieval of the patterns from corrupted versions may be imperfect .",
    "the remainder of the paper is organized as follows :  in section crosstalk we discuss in general terms the effects of crosstalk , or interference between different stored patterns .",
    "it is crosstalk which is responsible for limitations on storage capacity .",
    "we compare the effects of crosstalk in the bgn and the hn .",
    "this discussion provides a framework for interpreting our numerical results .  in section [ br ]",
    "we examine numerically the stability of memory patterns as a function of @xmath35 .",
    "we find evidence of a first - order memory blackout phase transition in the bgn at high @xmath8 , but not at low @xmath8 .  in section [ basins ]",
    ",  we examine the effects of high loading on the basins of attraction for the memory states and on their retrieval from corrupted input .",
    "we see that increasing the loading markedly alters the energy landscape .",
    "in section [ smallnet ] we comment briefly on the behaviour of smaller networks and on the relation between the previous small network results @xcite@xcite and those we have obtained for larger networks .",
    "we conclude with some discussion of the bgn results and possible directions for further study .",
    "we make some conjectures concerning the performance of the bgn in the presence of stochastic noise .",
    "in a given state @xmath4 ,  the input to the @xmath41-th node of the network can be expressed as @xmath42 using the hebb rule ( [ hebb ] ) and the definition ( [ mdef ] ) of @xmath18 .  in @xcite",
    ", we showed that when @xmath24 there are stable retrieval states in which  @xmath43 for one particular @xmath44 .  for a state",
    "in which the @xmath44-th overlap is large , we can decompose the field as follows:@xmath45 we refer to the first term , @xmath46 , as the signal  term and the second term , @xmath47 , as the crosstalk  term .  in the limit @xmath48 ,  the mutual overlaps between different patterns is small ,  so that @xmath49 , and the last two terms in ( field ) can be neglected .",
    "the signal term is then dominant and there is a stable retrieval state given by @xmath50 with @xmath51 .",
    "we expect this solution to be approximately valid for small but nonzero values of @xmath52 .  for this case ,",
    "the overlaps @xmath53 behave as gaussian distributed random variables with zero mean and variance @xmath54 . accordingly , the crosstalk term @xmath55 in ( [ field ] ) , being a sum of @xmath11 such quantities , is a random quantity with zero mean and variance @xmath56 .",
    "the third term , which arises from the subtraction of the diagonal elements , is of order @xmath30 and thus is generally smaller than the crosstalk term .",
    "we will neglect it for the moment .    in the absence of crosstalk ,  a retrieval state is not only linearly stable ( i.e. , stable against small perturbations ) but , for @xmath25 , it is also stable against individual sign flips .",
    "the latter means that if a retrieval state is corrupted by changing the sign of one or a small number @xmath57 of nodes , then the dynamics will reverse the flipped sign and restore the pattern .",
    "this happens because , in the absence of crosstalk , each node experiences a field @xmath58 which has the same sign as @xmath59 and for @xmath25 that field is strong enough to overcome the potential barrier of the individual node .",
    "now consider a given node ( say , the @xmath41-th node ) in the presence of crosstalk .  the crosstalk field acting on the @xmath41-th node may be either aligned with or opposed to @xmath2 .",
    "if it is aligned , then its effect on that node is to increase the magnitude of @xmath2 , making it larger than @xmath60 .  if it is opposed to @xmath2 , then its effect is to _ decrease _ the equilibrium magnitude of @xmath2 .",
    "if the crosstalk term is large enough , then it may be sufficient to overcome the local potential barrier and reverse the sign of @xmath2 , thus introducing a sign error into the pattern .",
    "this will occur only if @xmath61 by contrast , in the hopfield model a sign error is introduced if @xmath62 thus the relative strength of crosstalk required to introduce sign errors is greater for the bgn than for the hn , and the discrepancy is greatest for small values of @xmath8 .",
    "one might expect that this would make the bgn less vulnerable to crosstalk ( and the memory states more stable )  than the hn , especially at low @xmath8 , but this is not a foregone conclusion as the bgn s dynamics include mechanisms which tend to amplify small initial overlaps@xcite and could conceivably also amplify crosstalk .",
    "our numerical results confirm that the bgn is in fact less prone to crosstalk - induced errors at low values of @xmath8 , but not at high values .",
    "if @xmath63 the crosstalk will not be strong enough to reverse the sign of @xmath2 if initially @xmath2 is correctly aligned with @xmath64 but it will nonetheless destroy the stability against a sign flip .  in other words , if @xmath65 is initially misaligned , it will not be corrected .",
    "we may say that the node is _",
    "_ bistabilized  _ _ but not destabilized .",
    "( such an effect can not occur in the hn where the nodes are not individually bistable . )",
    "since the crosstalk is random ,  it will in general bistabilize some nodes and not others , with the result that the memory state will be stable against sign flips of certain nodes but not of others .",
    "thus , even though a memory state may be linearly stable , the dynamics may only be able to correct some sign errors , not all .",
    "this contrasts with the low - loading case where crosstalk is negligible and there is a single threshold coupling strength , @xmath66 above which any single sign error can be corrected .  in general , crosstalk results in non - uniform behaviour among nodes , including different magnitudes of @xmath2 for different @xmath41 .",
    "to examine the stability of the memory states ,  we followed a procedure similar to that of reference @xcite .",
    "using an ensemble of realizations of the random patterns , we made a number of trials in which the network was initialized to the state @xmath67 for some pattern @xmath44 .",
    "the initial bit overlap @xmath68 was thus equal to 1 .",
    "we then allowed the state to evolve until an attractor was reached .",
    "in each case we measured the final energy as well as the bit overlap between the initial and final states , to which we refer as the _ remanent _ bit overlap @xmath69 .",
    "we then constructed histograms showing the probabilities @xmath70 for @xmath69 falling in intervals of width 0.05 .",
    "each of the histograms discussed in this section represents an ensemble of at least 200 initial conditions .",
    "if the memory state is entirely stable , as is the case at very low loading , then after the dynamics converges the final bit overlap will still be equal to @xmath71 .",
    "for higher loading , however ,  the crosstalk fields may introduce sign errors so that @xmath72 .",
    "first consider the case of the hn@xmath74  figure [ ohisth2000 ] shows a series of @xmath75 histograms for the hn at different values of @xmath76 .",
    "( the data here are our own , but the results are comparable to those given in @xcite . we include them for comparison with bgn results . ) at lower levels of loading , crosstalk introduces few errors , so @xmath77 in the large majority of cases .",
    "however , as @xmath78 increases beyond the critical value @xmath79 ,  the high-@xmath69  peak ofthe distribution begins to vanish and a second , broader peak begins to grow in the vicinity of @xmath80 .",
    "the states in the second peak are spin glass states .  as shown in figure [ ohisth ] , this transition becomes sharper with increasing network size , and finite - size scaling analysis shows behaviour characteristic of a first order phase transition in the thermodynamic limit @xcite . in the limit @xmath81 the associative memory fails suddenly as the critical loading is exceeded the remanent overlap drops abruptly from near 1 to 0.3 .",
    "this nonzero value of the remanent overlap above the critical loading was noted in @xcite and attributed to replica symmetry breaking , as the replica symmetric theory predicts that @xmath69 should drop to zero above the phase transition .",
    "this phenomenon is related to the non - zero remanent magnetization of a spin glass  @xcite .",
    "[ ptb ]    fig1.eps    [ ptb ]    fig2.eps    [ ptb ]    fig3.eps    in the bgn with @xmath36 ,  a similar transition evidently occurs at @xmath37 .  as evidence , in figure [ ohist2 ]  we show two series of histograms at increasing @xmath3 , one below the suspected transition and one above .  as in the hn case , the transition grows sharper with increasing network size .  below the critical loading ,",
    "the high-@xmath82 peak remains robust as @xmath3 increases ,  while above the critical loading the high-@xmath82 peak shrinks with increasing network size and the low-@xmath82 peak grows .",
    "two quantitative differences are that the critical loading @xmath83 is lower in the bgn case , @xmath84 ,  while the average remanent overlap above the critical loading is higher , near 0.45 .    the first - order nature of the transition is confirmed by examining the energies of the final states .",
    "these energies and the overlaps are shown in a scatter plot in figure  [ scatcombined]a .",
    "the spin glass states associated with the low-@xmath69 peak are clustered at energies below those of the retrieval states .",
    "the gap in energy between these two clusters corresponds to the latent heat of the phase transition .",
    "[ ptb ]    fig4.eps      for @xmath39 , in contrast to @xmath36 , the bgn s behaviour differs markedly from that of the hn .",
    "a series of @xmath75 histograms for different values of @xmath30 is shown in figure [ ohist05 ] .",
    "two features are evident .",
    "first , the stored patterns remain stable with few errors even up to high levels of storage ,  @xmath85 .",
    "second , there is no evidence of a discontinuous memory failure ;  rather , the retrieval quality as measured by @xmath69 appears to degrade continuously as @xmath35 increases .",
    "no second peak appears in the histograms ; instead , the high-@xmath82 peak first spreads and then begins to drift downward as errors accumulate .     at an intermediate value @xmath86",
    "the @xmath75 histograms  ( figure ohist1 ) suggest a first - order transition , although the evidence is less pronounced than in the @xmath36 case .",
    "a second peak appears above the transition , and the high-@xmath69 peak shows clear signs of shrinking as @xmath3 increases , but the tails of the two peaks overlap substantially .",
    "the greater overlap between the peaks comes about for two reasons .",
    "first , the high-@xmath69 peak above the critical loading is broader than in the @xmath87 case .",
    "second , the remanent magnetisation is much higher ( i.e. , the drop in @xmath69 at the critical point is much smaller . )",
    "the latent heat is also much smaller , as can be seen from the scatter plot of the energy ( figure [ scatcombined]b ) .",
    "the critical loading , or storage capacity , is approximately 0.17 , higher than for @xmath36 and higher than for the hn .",
    "[ ptb ]    fig5.eps    [ ptb ]    fig6.eps",
    "in the previous section , we examined the trajectories of initial conditions corresponding to memorized patterns and determined whether these trajectories remain close to the pattern or move away from it .",
    "such experiments , however , probe only one aspect of network performance .",
    "we are interested not only in the stability of memory states but also in the sizes of their basins of attraction .",
    "the function of associative memory depends on the ability of the dynamics to correct partially corrupted patterns . more generally , we are interested in the evolution of the energy landscape with increasing @xmath35 .  to address these issues , we performed two additional sets of numerical experiments . first , we examined the attractors reached from a large number of _ random _ initial conditions to obtain a uniform sampling of the phase space and a broad picture of the energy landscape .",
    "second , we examined the fate of initial conditions at specified hamming distances from memory patterns .",
    "the latter set of experiments probes the landscape in the vicinity of the memory states .",
    "results of similar experiments were given in ref .",
    "@xcite for the case of low loading .       in the case of the hn",
    ",  it is known that in the thermodynamic limit the memory states are the lowest energy states for @xmath88 , while for higher values of @xmath35 spin glass states arise which have lower energies .  up to @xmath89",
    "the memory states remain local minima of the energy even though they are not the global minima .  above @xmath83",
    "they cease even to be local minima and therefore become unstable@xcite .",
    "the drop in energy from the memory states to the spin glass states at @xmath83 is the latent heat .",
    "one way to observe the evolution of the energy landscape is to examine the attractors reached from an ensemble of random initial conditions which effectively samples the configuration space .",
    "figures [ seedh]-seed075 show histograms for the energies of attractors sampled in this manner .  in each case , we sampled a total of at least 200 random initial conditions with several realizations of the random patterns * *  * * @xmath90 .  in figure [ seedh ] , for the hn , we can see that at low loading the attractors are separated into two groups , the retrieval states at @xmath91 and spurious states at a range of higher energies .",
    "the probability of retrieving a memory state from a random initial condition is high .  with increasing @xmath35",
    ",  the spurious states move to lower in energies until they are below the memory states .  at the same time , their basins of attraction take up a larger portion of the configuration space , as is apparent from the growing size of the spin glass peak in the histogram and the shrinking size of the retrieval state peak .",
    "figure [ seed2 ] shows that for the bgn with @xmath36 the evolution is qualitatively similar .  in figure [ seed075 ] , for @xmath92",
    "we observe that an additional effect of high loading is to destabilize the uncondensed states .  at low loading ,",
    "the uncondensed states dominate the configuration space ",
    "almost all random initial conditions land on an uncondensed state , as was noted in @xcite .",
    "the other two types of state begin to show their presence as the loading is increased , while the uncondensed states eventually disappear .",
    "[ ptb ]    fig7.eps    [ ptb ]    fig8.eps    [ ptb ]    fig9.eps      to obtain information about the landscape in the vicinity of the memory states and about the shapes of their basins of attraction , we examined the fates of initial conditions which were not random but rather at specified initial overlaps with particular stored patterns .",
    "as in @xcite , these initial configurations were generated by starting with a particular target  pattern and flipping the signs of a specified number of randomly chosen nodes .",
    "for each value of the initial overlap @xmath93 , we generated an ensemble of initial conditions for several different realizations of the random set of memory patterns .",
    "we then evolved these states until the dynamics converged , and evaluated @xmath94 , the final overlap with the target pattern , for each trajectory .",
    "if @xmath95 , this signifies that all signs which were initially flipped have been corrected and the target pattern has been retrieved perfectly .",
    "if @xmath96 ,  then the pattern has been retrieved imperfectly .  the final state is closer to the stored pattern , but not all errors have been corrected .  if @xmath97 , then the trajectory has moved farther away from the stored pattern .  as discussed in section [ crosstalk ] , the ability of the network to correct sign errors depends on the competition among the signal , the crosstalk , and the local potential .",
    "the initial states currently discussed have at least a moderately large overlap with the target pattern , resulting in a signal , and random overlaps with the other memory patterns , resulting in crosstalk .",
    "consider now the hn .  at low loading",
    ", there is very little crosstalk .",
    "the crosstalk term is typically of order @xmath56 .",
    "if the hn is set in an initial condition whose overlap with the target pattern @xmath98 is @xmath99 ,  then most nodes experience a net field which is aligned with the target pattern .",
    "nodes which are initially misaligned with the target state ( @xmath100 ) will tend to change their signs and align with @xmath101 .",
    "each node which realigns in this way increases the value of @xmath82 and thus increases the strength of the signal acting on the remaining nodes .  as a result ,",
    "even if in the initial state some fraction of the nodes experience a net field opposed to @xmath101 , eventually the growing signal may overcome the crosstalk and correct those nodes as well .",
    "therefore for low loading , as long as the initial state has @xmath102 , the probably of completely retrieving the target pattern is close to unity .",
    "as the loading ratio @xmath35 increases , however ,  the typical crosstalk becomes stronger , and a higher signal is required to overcome the crosstalk noise .",
    "therefore sign errors are not likely to be corrected unless the initial overlap is above a threshold , which grows higher with increasing @xmath35 .",
    "if the crosstalk is too large , then some signs which are initially aligned with the pattern may be flipped , and the state may move away from the target pattern instead of toward it .  each node which flips out of alignment with the target pattern",
    "reduces the size of the overlap and hence of the signal , which makes other nodes more susceptible to crosstalk - induced errors , and a cascade of errors can occur .",
    "the critical loading @xmath83 is the level at which even a state with @xmath103 becomes unstable against such a cascade of errors .",
    "figure [ boundscath2]a shows a scatter plot of @xmath104 vs. @xmath93 for a hn slightly below critical loading .",
    "there is a threshold overlap for retrieval .",
    "if @xmath105 the signal is strong enough to correct errors and the majority of trajectories flow towards the target pattern .  for @xmath106",
    "the majority of trajectories move instead away from the target pattern .",
    "as @xmath35 increases , the threshold value of @xmath93 for retrieval increases until at @xmath83 it reaches 1 .",
    "the plot in figure [ boundscath2]a is for a network with @xmath107 ;  experiments with networks of different sizes reveal that the retrieval threshold becomes sharper as @xmath3 increases .     in the bgn ,",
    "on the other hand , the dynamics of error correction is more complicated due to the local potential .  at strong coupling @xmath34 ,",
    "the potential barriers against sign flips are less important than at weak coupling .  as a result",
    "the bgn in this regime behaves in many respects like the hn .",
    "it is not surprising , then , that the scatter plot of @xmath104 vs. @xmath93 for a bgn with @xmath36 slightly below its critical loading ( figure [ boundscath2]b ) appears qualitatively similar to the corresponding figure [ boundscath2]a for the hn .",
    "there is a threshold ( approximately @xmath108 )  below which the probability of fully retrieving the target pattern drops sharply .  above this threshold ,",
    "the signal is evidently strong enough to correct most sign errors .  a key difference",
    ", however , is that even below this threshold the average @xmath109 is larger than @xmath110  this means that the majority of a trajectories move toward the target pattern rather than away from it ,  but only some of the sign errors are corrected , not all .",
    "[ ptb ]    fig10.eps    in the case of the bgn with @xmath39 , the local potential barriers are important , and interesting dynamics results from the competition among the signal from the target pattern , the crosstalk from other patterns , and the local potential .  in the @xmath24 case @xcite",
    ", sign errors can be corrected only if the signal is strong enough to overcome the local potential barriers ,  and therefore there is a threshold value of the initial overlap which is much larger than @xmath56 .",
    "for the case @xmath111 , @xmath112 , for example , we find that this threshold is approximately @xmath113 .",
    "for @xmath105 there is a large probability that the target pattern is retrieved perfectly , while for @xmath114 there is a large probability that the network will be stuck in an uncondensed state with @xmath115 .  in the intermediate range @xmath116",
    ", there is also a significant probability that the trajectory is attracted to an asymmetric spurious state in which @xmath104 is large but not unity and there are larger than random overlaps with one or more other memory patterns .",
    "this behaviour is illustrated by the scatter plot of figure [ scat05]a .",
    "as the loading increases  ( figure [ scat05]a - d ) , something surprising happens :  at first , the basins of attraction of the memory states _ expand _ slightly ,  contrary to what one would expect from the hn .  the frontier of the uncondensed states is pushed back to lower values of @xmath93 .  for @xmath117 , or @xmath118 ( fig .",
    "[ scat05]d )  almost all states with @xmath119 undergo some motion toward the target pattern , even if the pattern is not retrieved perfectly .",
    "as @xmath11 increases further , the @xmath104 vs. @xmath93 plot preserves the approximate shape of fig .",
    "[ scat05]d .",
    "the dynamics of retrieval and error correction for the bgn with weak coupling and high loading is evidently quite different from that of the hn .  in the @xmath120 case of figure [ scat05]d ,",
    "@xmath104 is always @xmath121 if @xmath122 , which means that the memory state is stable .",
    "however , it is retrieved only imperfectly when sign errors are introduced : if @xmath123 then  @xmath96 .",
    "this indicates that some nodes remain bistable and can not be corrected .",
    "if the initial state is close to the target pattern , then the majority of errors are corrected , but that fraction decreases with decreasing @xmath93 .",
    "such a partial correction of errors does not often occur in the hn case .",
    "in the latter case , an initial condition either flows all the way to the retrieval state or moves away from it toward another attractor .",
    "the retrieval state may itself have a small number of errors due to crosstalk , but the presence of these errors does not depend on the initial state .",
    "the energy landscape of the hn in the neighborhood of a memory state apparently has the shape of a smooth basin  once the basin is entered ,  the trajectory usually runs without obstruction to the attractor at the bottom .  for the weakly coupled bgn",
    ", on the other hand , the landscape appears to have the structure of a funnel ,  @xcite@xcite@xcite i.e. , a sequence of local minima at decreasing energies , with low potential barriers separating each state from the next .",
    "there is a region of configuration space which has an overall tilt toward the retrieval state , but in which there are many local minima which may trap the trajectory before it reaches the retrieval state .",
    "this is illustrated schematically in figure [ bumpy ] .",
    "funnel - shaped energy landscapes were first suggested in the context of protein folding dynamics .",
    "[ ptb ]    fig11.eps    [ ptb ]    fig12.eps",
    "so far , this paper and the companion paper @xcite have focused mainly on large networks of @xmath111 or more .  however ,  some applications of neural network algorithms to robotics and other areas make use of networks of only 20 or 100 nodes .  experimental studies of bgn - like chemical reactor networks @xcite@xcite used fewer than 10 nodes .  the current work on the bgn was inspired in part by results suggesting that the bgn could store many more patterns than the hn , with fewer spurious attractors @xcite .",
    "the latter results were inferred from a few selected cases using very small networks ,  and so we attempted to test the genericness of these results for a variety of small networks as well as for larger networks .     it should be noted that with very small networks , there are great fluctuations in properties depending on the particular set of memory patterns chosen ,  as it is impossible to ignore the mutual correlations among patterns .  results for the maximum storage capacity of a network are well - defined only in the thermodynamic limit @xmath124 , and for small @xmath3 even an hn may in particular cases be able to store more than @xmath125 stable patterns .  for these reasons one can not draw strong general conclusions about storage capacity based on small networks alone ,  but it is nonetheless instructive to make some comparative studies of pattern stability in small networks .",
    "for several small values of @xmath3 and @xmath11 , we generated random sets of stored patterns and tested their stability , using the hn and the bgn at several different values of @xmath8 .",
    "we counted the average fraction of memory patterns which were stable , @xmath126 .",
    "in addition , we estimated the fraction of configuration space @xmath127 occupied by spurious attractors by following the trajectories of random initial conditions inside the hypercube @xmath128 these results are collected in table [ smallnettable ] .  in all cases",
    "the results were averaged over at least 100 sets of randomly generated patterns .  in generating random sets of patterns",
    ", we did not eliminate cases in which two or more patterns are identical .",
    "the results show that , contrary to the selected examples discussed in @xcite and @xcite , the spurious attractors do _ not _ generically occupy much less configuration space in the bgn than in the hn ( in fact they normally occupy more , especially at low values of @xmath8 ) .  however ,  for the most part the percentage of memory patterns which are stable is larger in the bgn than in the hn as long as @xmath129 .  as with larger networks ,",
    "the bgn becomes most similar to the hn when @xmath130 while lower @xmath8 leads to increased pattern stability .",
    "the increased pattern stability at low @xmath8 is associated , however , with smaller basins of attraction for the memory states and therefore with a greater volume of phase space occupied by spurious states .",
    ".properties of small networks[smallnettable ] [ cols= \" < , < , < , < , < , < , < , < , < \" , ]",
    "we have studied the properties of the bgn at high memory loading @xmath35 .",
    "our results can be summarized as follows :  for high values of @xmath8 , such as 2 ,  there is a first - order transition similar to that of a hn .  for @xmath36 ,",
    "the transition  occurs at a critical loading @xmath131 , which is lower than the critical loading of @xmath132 for the hn .  as @xmath8 decreases , the critical loading increases and the phase transition evidently becomes weaker and eventually disappears .",
    "for @xmath86 the critical loading is apparently @xmath133  ( higher than for the hn ) and the phase transition is much less pronounced for the finite - size networks we have studied .  for @xmath134",
    "there is no evidence of a phase transition at all and patterns are stable with very few errors up to @xmath135 .",
    "a phenomenon that occurs in the bgn much more than in the hn is the partial retrieval of a pattern , whereby the dynamics corrects some sign errors in a pattern without correcting all of them .",
    "this is especially noticeable in the case of low @xmath8 and high @xmath35 .",
    "this phenomenon suggests that in this case the energy landscape in the vicinity of a stored pattern has the shape of a funnel rather than a smooth basin of attraction .  by a smooth basin of attraction , we mean a connected neighborhood which is sloped toward an attractor and in which there are few local minima that might obstruct a trajectory once it has begun to flow toward the attractor .  by a funnel we mean a region with an overall average slope toward an attractor which however contains many other local minima in which the trajectory might become stuck before reaching the bottom .",
    "the presence of these local minima is due to the bistability of the individual nodes and the local potential barriers against spin flips .",
    "these same potential barriers are also responsible for stabilizing the patterns .",
    "they make it less likely that crosstalk noise will induce an error in a pattern , but they also can inhibit the correction of an error which is present initially .",
    "funnel - shaped landscapes were first examined in the context of protein folding dynamics@xcite@xcite .",
    "it was suggested that at a finite temperature such a landscape would allow the protein dynamics efficiently to find the global minimum of energy in spite of the presence of numerous local minima separated by potential barriers . if indeed the landscape of the bgn at low @xmath8 forms a funnel , then it is possible that the introduction of some stochastic noise ( i.e. , finite temperature ) could improve pattern retrieval by allowing trajectories to jump over the comparatively small potential barriers into lower energy minima , just as in the protein case .",
    "the effect of stochastic noise could be a fruitful subject for further study .",
    "an interesting question is whether there is an optimum level of noise which would improve the pattern retrieval ability of the bgn with low @xmath8 while at the same time maintaining the larger storage capacity .",
    "intriguing questions remain concerning the dynamics of the bgn at low @xmath8 .",
    "the apparent initial expansion of the basins of attraction of the memory states with increasing loading is counterintuitive , and the patterns visible in figure [ scat05 ] hint at some dynamics which is not yet fully understood .",
    "v. chinarov and m. menzinger ,  bistable gradient networks : their computational properties  in j. mira and a. prieto , eds . , connectionist models of neurons , learning processes , and artificial intelligence , p.333 .",
    "springer verlag , berlin 2001 .",
    "w. hohmann , m. krauss and f.w .",
    "schneider , j. phys .",
    "a * 103 * , 7606 ( 1999 ) ;  j phys .",
    "chem a 102 , 3103 ( 1998 ) ;  j. phys .",
    "chem a 101 , 7364 ( 1997 ) .",
    "g. dechert , k .-",
    "zeyer , d. lebender and f.w .",
    "schneider , j. phys chem a 100 , 19043 ( 1996 ) .",
    "laplante , m. pemberton , a. hjelmfelt and j. ross , j. phys .",
    "chem 99 , 10063 ( 1995 ) .",
    "v. booth , t. erneux and j .- p .",
    "laplante , j. phys .",
    "chem 98 , 6537 ( 1994 ) .",
    "a. hjelmfelt and j. ross , j. phys .",
    "97 , 7998 ( 1993 ) ."
  ],
  "abstract_text": [
    "<S> we examine numerically the storage capacity and the behaviour near saturation of an attractor neural network consisting of bistable elements with an adjustable coupling strength , the bistable gradient network ( bgn ) . for strong coupling </S>",
    "<S> , we find evidence of a first - order memory blackout  phase transition as in the hopfield network . for weak coupling , </S>",
    "<S> on the other hand , there is no evidence of such a transition and memorized patterns can be stable even at high levels of loading .  </S>",
    "<S> the enhanced storage capacity comes , however , at the cost of imperfect retrieval of the patterns from corrupted versions . </S>"
  ]
}