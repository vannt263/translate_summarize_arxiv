{
  "article_text": [
    "compressive sensing  @xcite ( cs ) has led to real applications , including the single - pixel camera  @xcite , the lensless camera  @xcite , video compressive sensing  @xcite , depth compressive sensing  @xcite , hyperspectral compressive imaging  @xcite , polarization compressive sensing  @xcite , terahertz imaging  @xcite , and millimeter wave imaging  @xcite . in this paper , we focus on the two - dimensional ( 2d ) image case , though similar technique can be used for videos  @xcite and other bandwidths . specifically , we develop our algorithm under the lensless compressive imaging architecture  @xcite , which has provided excellent reconstruction images from the compressive measurements using simple and off - the - shelf hardware  @xcite .    diverse algorithms  @xcite have been developed for compressive sensing recovery , which plays a pivot role in cs , to reconstruct the desired signal from compressive measurements .",
    "sparsity , the key ingredient of cs , has been investigated extensively in these algorithms .",
    "the wavelet transformation  @xcite is generally used since it provides the sparse representation of an image with fast transformations ( thus very efficient ) .",
    "a parallel research is using the total variation ( tv ) for cs recovery  @xcite , which provides good results for piecewise smooth signals .",
    "the aforementioned algorithms do not increase the unknown parameters significantly during the reconstruction , as usually the wavelet coefficients will have similar ( or the same ) number of the image pixels .",
    "recently , researchers have found that by exploiting the sparsity of local patches  @xcite , better results can be achieved . in summary ,",
    "cs recovery algorithms fall into the following three categories : 1 ) global basis based algorithm , _",
    "e.g. _ , using the wavelet transformation , 2 ) tv based algorithm , and 3 ) local basis based algorithm , _",
    "i.e. _ , dct or dictionary learning or denoising based algorithms .",
    "state - of - the - art cs inversion results have been obtained in  @xcite , which generally lie within the third category . in this paper",
    ", we propose an alternative inversion algorithm that exploits the low - rank property of image patches .",
    "generally , the cs recovery is an iterative process in which two steps are performed at each iteration  @xcite : @xmath0 projecting the measurements to the image level , which can be done by the majorization - minimization ( mm ) approach  @xcite , or the euclidean projection  @xcite , or the alternating direction method of multipliers ( admm )  @xcite , @xmath1 denoising this projected image and updating the recovery of the desired image .",
    "these two steps are performed _",
    "iteratively _ until some criterion is satisfied .",
    "a general framework is developed in  @xcite under the approximate message passing ( amp ) framework , in which diverse denoising algorithms  @xcite can be plugged in .",
    "one key difference of the denoising based cs inversion algorithms compared with",
    "the wavelet based cs inversion algorithms is that the former exploits the local sparsity based on ( overlapping ) patches , as state - of - the - art denoising algorithm is using sparse representation of local patches , _",
    "e.g. _ ,  @xcite .",
    "the number of coefficients for the patches ( under some basis or dictionary ) is usually larger than the image pixel number ( because the overlapping patches are used ) .",
    "the proposed algorithm in this paper also lies in the third category mentioned earlier , which is based on the local basis ( for image patches )",
    ". specific contributions of this work can be summarized as below :    * we investigate the low - rank property of image patches under the gaussian mixture model ( gmm ) framework .",
    "different from the low - rank model investigated in  @xcite , which requires patch clustering ( block matching ) as an additional step , in our algorithm , each patch is modeled by a gmm with different weights corresponding to different gaussian components , which can be seen as a _ soft clustering _ approach based on these weights .",
    "furthermore , these weights are updated in each iteration .",
    "* we develop an general framework using admm to explore the sparsity ( and low - rank property ) of patches in order to recover the desired signal . *",
    "if each patch is modeled by a single gaussian component , our gmm degrades to the piecewise linear estimator ( ple )  @xcite .",
    "therefore , a low - rank ple algorithm is also proposed for cs recovery .",
    "* we conduct experiments using our proposed algorithm and other leading algorithms on the real data captured by our lensless camera .",
    "this verifies real applications of each algorithm .",
    "we start with the derivation of an admm formulation for cs recovery to investigate the sparsity of local overlapping patches in section  [ sec : admm_slope ] .",
    "the proposed low - rank gmm algorithm is developed in section  [ sec : gmm ] and the joint reconstruction algorithm is summarized in section  [ sec : joint ] .",
    "extensive results on both simulation and real data are reported in sections  [ sec : simresults]-[sec : realresults ] .",
    "section  [ sec : con ] concludes the paper .",
    "under the cs framework , the problem we are solving can be formulated as : @xmath2 where @xmath3 is the sensing matrix , @xmath4 is the desired signal , @xmath5 is the coefficients which are sparse under the basis @xmath6 . from @xmath5",
    ", we can recover @xmath7 easily via @xmath6 , which can be _ known a priori _ , ( _ e.g. _ , a wavelet or dct basis ) or learned based on @xmath7 during the reconstruction .",
    "considering the image case investigated here , let @xmath7 denote the vectorized image and the sparse representation , @xmath5 , is now modeled on image patches .",
    "therefore , ( [ eq : xbz ] ) can be reformulated as : @xmath8 where @xmath9 denotes the patch extraction and vectorization operation and considering each patch , we have @xmath10 with @xmath11 indexes the patches .",
    "the problem can be reformulated as : @xmath12 note this @xmath6 is shared for all patches for current discussion , and in the following analysis , similar patches can be grouped together  @xcite and each group can have its own @xmath6 .",
    "next , we develop an admm  @xcite formulation of to solve the problem , which will also be used in our gmm formulation in section  [ sec : joint ] . introducing lagrange multipliers @xmath13 and parameter @xmath14 in ( [ eq : p1 ] ) results in the objective function @xmath15 define @xmath16 , @xmath17 the admm cyclically solves the following 3 sub - problems : @xmath18 where @xmath19 denotes the iteration index .",
    "equation ( [ eq : x_k+1 ] ) is a quadratic optimization problem and can be simplified to @xmath20 which admits the closed - form solution , @xmath21.\\ ] ] however , the dimension of @xmath22 is large ( the pixels of the desired image ) , requiring a high computational workload . alternatively , since @xmath22 is invertible , the matrix inversion formula can be used to reduce the computational workload . as @xmath23 is used to extract @xmath11-th patch from an image , @xmath24 is a diagonal matrix @xmath25 each of the diagonal entries corresponds to an image pixel location and its value is the number of overlapping patches that cover that pixel . therefore , @xmath26 and @xmath27 however , this is not necessarily easy to calculate though @xmath28 can be pre - computed .",
    "@xmath29 needs to be saved for computation .",
    "alternatively , ( [ eq : xinv ] ) can be solved by the conjugate gradient algorithm  @xcite .    to mitigate this problem",
    ", we apply the admm again on ( [ eq : p1 ] ) and introduce another auxiliary variable @xmath30 , leading to the following optimization problem : @xmath31 following this , @xmath32 which can be simplified to ( by setting @xmath33 ) : @xmath34 the optimization of ( [ eq : min3 ] ) consists of the following iterations : @xmath35 for fixed \\{@xmath36 } , @xmath37 admits the following closed - form solution : @xmath38,\\end{aligned}\\ ] ] which can be simplified to @xmath39,\\end{aligned}\\ ] ] for the case considered in our work ( as implemented in the lensless camera  @xcite ) , @xmath40 is the permuted hadamard matrix and thus @xmath41 is an identity matrix : @xmath42\\nonumber\\\\ & = \\frac{{{\\bf a}}^{\\top}{\\boldsymbol{y}}}{\\beta+1 } + ( { \\boldsymbol{w}}^t - { \\boldsymbol{v}}^t ) - \\frac{{{\\bf a}}^{\\top}{{\\bf a}}({\\boldsymbol{w}}^t - { \\boldsymbol{v}}^t)}{\\beta + 1 } \\nonumber \\\\ & = ( { \\boldsymbol{w}}^t - { \\boldsymbol{v}}^t ) + \\frac{{{\\bf a}}^{\\top}({\\boldsymbol{y}}- { { \\bf a}}({\\boldsymbol{w}}^t - { \\boldsymbol{v}}^t))}{\\beta+1}. \\ ] ] similarly , for fixed \\{@xmath43 } , @xmath44 admits the following closed - form solution : @xmath45\\end{aligned}\\ ] ] recall that @xmath24 is a diagonal matrix @xmath46 , thus @xmath30 can be computed element wise via @xmath47_n}{\\eta r_n + \\beta}\\end{aligned}\\ ] ] where @xmath48_n$ ] denotes the @xmath49-th entry of the vector inside @xmath50 $ ] .",
    "similar to ( [ eq : z_k+1 ] ) , ( [ eq : z3_k+1 ] ) can be considered as a dictionary learning model , where @xmath6 is the dictionary .",
    "if the orthonormal transformation is used ( _ e.g. _ , the dct ) , @xmath5 can be solved by the shrinkage thresholding operation  @xcite .    since the key of this algorithm is to investigate the sparsity of the local overlapping patches , we term this framework as slope ( shrinkage of local overlapping patches estimator ) , where the ` local ' stands for the local basis rather than the global basis such as wavelet .",
    "the admm - slope is summarized in algorithm  [ algo : slope ] .    while good results have been obtained using similar approaches  @xcite as in algorithm  [ algo : slope ] , in the next section , we develop a low - rank gmm framework imposed on the patches and a full formulation of the proposed algorithm is presented in section  [ sec : joint ] .",
    "measurements @xmath51 , sensing matrix @xmath40 , \\{@xmath52 , @xmath14 , @xmath53}. initial @xmath54 to all 0 .",
    "update @xmath7 by eq .",
    "( [ eq : xp3_k+1 ] ) .",
    "update @xmath30 by eq .",
    "( [ eq : wp3_k+1 ] ) .",
    "update @xmath5 by shrinkage operator .",
    "update @xmath55 by eq .",
    "( [ eq : v3_k+1 ] ) .",
    "[ algo : slope ]",
    "the gaussian mixture model ( gmm ) has been re - recognized as an advanced dictionary learning approach and has achieved excellent results in image processing  @xcite and video compressive sensing  @xcite .",
    "recall the image patches @xmath56 extracted from the 2d image , where the patch size is @xmath57 and there are in total @xmath58 patches . for @xmath11-th patch @xmath59",
    ", it is modeled by a gmm with @xmath60 gaussians  @xcite : @xmath61 where @xmath62 represent the mean and covariance matrix of @xmath63-the gaussian , and @xmath64 denotes the weights of these gaussian component .    in this paper",
    ", we further impose the gmm is low - rank and now the model in ( [ eq : xbz ] ) becomes ( [ eq : xigmm ] ) and the problem to be solved becomes @xmath65 where @xmath59 denotes @xmath11-th patch from @xmath7 , which is an vectorized image .",
    "@xmath66 symbolize the low - rank gmm .",
    "the following problem is to estimate this low - rank gmm . recalling section  [ sec : intro ]",
    ", we review that the cs recovery is an iterative two - step procedure . in each iteration , one can get an estimate from the projection of the measurements ( details discussed in section  [ sec : joint ] ) .",
    "we hereby learn a ( full rank ) gmm from this estimate and then proposing the eigenvalue thresholding approach to derive the low - rank gmm based on this full rank gmm .      in the following ,",
    "we provide a motivation for the next step in the algorithm .",
    "the random vector @xmath59 in ( [ eq : xigmm ] ) ( modeled as a gmm ) can be written as , dropping the subscript @xmath11 for simplicity , @xmath67 where each @xmath68 is a random vector of multivariate normal distribution , given by @xmath69 the random vector @xmath68 can be decomposed into independent random variables of normal distribution  @xcite as follows @xmath70 where @xmath71 , @xmath72 is the rank of @xmath73 , and @xmath74 is a vector whose @xmath72 components are independent random variables .    in order to reduce noise , we use a model in which @xmath68 has a small number of independent random components , _",
    "i.e. _ , we require @xmath72 to be small .",
    "this is equivalent to requiring @xmath73 have a reduced rank .",
    "more specifically , introducing the parameter @xmath75 , we solve the following minimization problem @xcite : @xmath76 where @xmath77 is the frobenious norm , and @xmath78 is the nuclear norm ( sum of the singular values ) .",
    "it is shown in @xcite that the solution to ( [ eq : sigmalowrank ] ) can be readily obtained by a shrinkage on the singular values ( which are similar to the eigenvalues ) of @xmath73 . specifically , consider @xmath79.\\end{aligned}\\ ] ] we impose that @xmath80 via @xmath81,\\\\ \\tilde{\\lambda}_i & = & \\max(\\lambda_i-\\lambda_{\\gamma_k + 1 } ,   0 ) , \\quad \\forall i = 1,\\dots , p.\\end{aligned}\\ ] ] and we term this as the eigenvalue thresholding ( evt ) . following this , @xmath82 is obtained by @xmath83    we further define @xmath84 next , we define a new random vector @xmath85 which is modeled by a low - rank gmm , parameterized by @xmath86 .      given an estimated image @xmath87 , the gmm in ( [ eq : xigmm ] ) can be learned via the expectation - maximization ( em ) algorithm  @xcite based on overlapping patches .",
    "then for each gaussian component , we adopt the evt to the covariance matrix to obtain the low - rank gmm @xmath66 . following this ,",
    "the estimated image @xmath88 or patches @xmath59 can be updated via this low - rank gmm , to @xmath89 or @xmath90 .",
    "dropping the subscript @xmath11 , given @xmath91 , the conditional distribution for @xmath89 maybe evaluated as @xmath92 since @xmath93 is a low - rank version of @xmath94 , we assume : @xmath95 where @xmath96 is modeled as an additive gaussian noise , thus @xmath97 plugging ( [ eq : xxtilde ] ) into ( [ eq : postxhat ] ) , we have @xmath98 which is an analytical solution with  @xcite @xmath99 note that @xmath82 is low - rank obtained via evt from @xmath73 , but by adding @xmath100 ( @xmath101 ) , @xmath102 is invertible .",
    "while ( [ eq : xv_pdf ] ) provides a posterior distribution for @xmath103 , we obtain the point estimate of @xmath89 via the posterior mean : @xmath104&= & \\sum_{k=1}^k \\phi_k { { \\boldsymbol{\\nu}}}_k\\end{aligned}\\ ] ] which is a closed - form solution .",
    "the procedure of learning and updating the gmm can be summarized as below :    * step 1 : lean a gmm ( not low - rank ) @xmath105 via em from an estimate of @xmath88 , which can be obtained from ist , gap or admm described below in section  [ sec : joint ] . *",
    "step 2 : for each gaussian component , derive the low - rank version @xmath66 by eigenvalue value thresholding via ( [ eq : lr_siguu])-([eq : mut ] ) .",
    "* step 3 : update the estimate of the image by @xmath89 using ( [ eq : xv_pdf])-([eq : txhatmean ] ) .",
    "the piecewise linear estimator ( ple ) proposed in  @xcite has demonstrated excellent performance on diverse image processing tasks .",
    "if each patch is considered drawn from a single gaussian distribution , our gmm degrades to the ple and the weights @xmath106 ( or @xmath107 ) are not required .",
    "furthermore , the update equation of @xmath103 will become the winer filter .",
    "the map - em procedure proposed in  @xcite can still be used to determine which gaussian each patch lies in and to estimate the denoising version of the each patch . however",
    ", this method has been shown that it is very sensitive to the initialization and selecting @xmath60 is critical to the performance of the method .",
    "we compare our proposed algorithm with ple by experiments in section  [ sec : gmm_ple ] .",
    "it is worthing nothing that , even using ple , the eigenvalue thresholding method used to obtain the low - rank gaussian model is first proposed in this paper . in this case , the ple model is very similar to the nlr - cs  @xcite , where the low - rank is imposed on each cluster of patches , while in the ple , the low - rank is imposed on the patches belonging to the same gaussian component ; this can also be seen as a cluster .",
    "next , we review the map - em algorithm proposed in  @xcite and adopt it to the current context . in the e - step , assuming that the estimates of the _ low - rank _ gaussian parameters @xmath66 are known , ( following the previous m - step ) , for each patch , one calculates the map estimates @xmath108 of all the gaussian models and selects the best gaussian model @xmath109 to obtain the estimate of the patch @xmath110 . in the m - step , assuming that the gaussian models selection @xmath109 and the signal estimate @xmath111 , are known ( following the previous e - step ) , one updates the gaussian models @xmath66 and then impose them to be low - rank .    * _ e - step : signal estimation and model selection : _ + for each image patch @xmath11 , the signal estimation and the model selection are calculated to maximize the log _ a posteriori _",
    "probability @xmath112 : @xmath113 recall that we consider @xmath114 is a low - rank version of @xmath59 and @xmath115 therefore : @xmath116 this maximization is first calculated over @xmath117 and then over @xmath63 .",
    "given a prior gaussian signal model @xmath118 , @xmath117 can be estimated by the posteriori mean @xmath119 the best gaussian model @xmath109 that generates the maximum map probability among all the models is then selected with the estimated @xmath120 @xmath121 the signal estimate is obtained by plugging in the best model @xmath109 in the map estimate @xmath122 * _ m - step : model estimation : _ + in the m - step , the gaussian model selection @xmath109 and the signal estimate @xmath123 of all the patches are assumed to be know ( derived from the ist , gap or admm as shown in section  [ sec : joint ] ) .",
    "the parameters of each gaussian model are estimated with the maximum - likelihood ( ml ) estimate using all the patches in the same gaussian model : @xmath124 where @xmath125 denotes the ensemble of the patch indices @xmath11 that are assigned to the @xmath63-th gaussian model and @xmath126    return to the low - rank model proposed in this paper .",
    "the e - step is same as above and one more step is added in the m - step .",
    "the full rank ( not low - rank ) gaussian models are first estimated via ( [ eq : plemu_sig])-([eq : plesig ] ) , and then each gaussian model is imposed to be low - rank by thresholding the eigenvalues via ( [ eq : lr_siguu])-([eq : lr_sig ] ) .",
    "the new low - rank ple algorithm can be summarized into the following 3 steps :    * step 1 : signal estimation and model selection by ( [ eq : txv_k])-([eq : xv_i ] )",
    ". * step 2 : model update for the ( non low - rank ) gaussian models @xmath127 by ( [ eq : plemu_sig])-([eq : plesig ] ) .",
    "* step 3 : estimate the low - rank gaussian models @xmath128 from @xmath127 via ( [ eq : lr_siguu])-([eq : mut ] ) .",
    "section  [ sec : gmm ] presents an algorithm to obtain a better estimate ( or a denoised version ) of the signal @xmath7 given an initial estimate utilizing the low - rank gmm . in this section",
    ", the gmm will be wrapped into our joint reconstruction algorithm by different update methods to get the initial estimate , which can be considered as projecting the measurement @xmath129 to the image plane @xmath7 .",
    "this is obtained by minimizing the following objection function @xmath130 diverse algorithms have been proposed and we review two of them below and develop an admm formulation in section  [ sec : admm ] . other approaches , for example , the twist  @xcite can also be used .      by using the majorization - minimization approach  @xcite to minimize @xmath131",
    ", we can avoid solving a system of linear equations . at each iteration @xmath19 of the mm approach ,",
    "we should find a function @xmath132 that coincides with @xmath131 at @xmath133 but otherwise upper - bounds @xmath131 .",
    "we should choose a majorizer @xmath132 which can be minimized more easily ( without having to solve a system of equations ) .",
    "the @xmath132 is defined as @xmath134 where @xmath135 denotes the identity matrix and @xmath136 must be chosen to be equal to or greater than the maximum eigenvalue of @xmath137 . for the hadamard sensing matrix used in our camera ,",
    "the maximum eigenvalue of @xmath137 is easily obtained .",
    "the update equation of @xmath133 in this iterative shrinkage thresholding ( ist ) algorithm  @xcite is given by : @xmath138      the generalized alternating projection ( gap ) algorithm proposed in  @xcite , which enjoys the anytime property and has been demonstrated high performance in video compressive sensing  @xcite , has the following update equation by using the euclidean projection : @xmath139 under some condition of the sensing matrix @xmath140 , as the hadamard matrix used in our system , @xmath141 is the identity matrix and thus ( [ eq : gapxk ] ) is same as ( [ eq : istxk ] ) with @xmath142 .",
    "in addition to ( [ eq : gapxk ] ) , aiming to speed - up the convergence , the authors in  @xcite have proposed the accelerated update equations @xmath143 better results have been achieved in our experiments using this accelerated gap .",
    "measurements @xmath51 , sensing matrix @xmath40 .",
    "initial @xmath7 .",
    "update @xmath7 by ist  , or gap   or admm  .",
    "update related parameters in ist , gap or admm .",
    "learn a gmm ( not low - rank ) from @xmath7 .",
    "obtain the low - rank gmm via eigenvalue shrinkage thresholding  .",
    "update @xmath7 by the low - rank gmm using expectation in  .",
    "[ algo : gmmslope ]    measurements @xmath51 , sensing matrix @xmath40 .",
    "initial @xmath7 .",
    "update @xmath7 by ist  , or gap   or admm  .",
    "update related parameters in ist , gap or admm .",
    "update the gaussian models ( not low - rank ) from @xmath7 via ( [ eq : plemu_sig])-([eq : plesig ] ) . obtain the low - rank gaussian models via .",
    "update @xmath7 by the low - rank gaussian models using ( [ eq : txv_k])-([eq : xv_i ] ) .",
    "[ algo : pleslope ]      under the gmm framework , we do nt have the sparse variable @xmath5 as in ( [ eq : p1 ] ) , the objective function can be formulated as : @xmath144 where @xmath114 is obtained by the low - rank gmm model . following the procedure in ( [ eq : p2 ] ) by introducing the auxiliary variable \\{@xmath145 } , we have @xmath146 the optimization of ( [ eq : minxgmm ] ) consists of the following iterations : @xmath147 where the update of @xmath114 is given by the low - rank gmm in ( [ eq : xv_pdf])-([eq : txhatmean ] ) . under the sensing matrix considered here in our work , @xmath148",
    ", the solution of ( [ eq : x4_k+1 ] ) is given by ( [ eq : xp3_k+1 ] ) .",
    "( [ eq : w4_k+1 ] ) can be solved by @xmath149\\end{aligned}\\ ] ] similar to ( [ eq : wnk+1 ] ) , @xmath44 can be solved element - wise but in one shot .",
    "the proposed low - rank gmm algorithm , integrated with the three approaches to update @xmath7 ( projecting @xmath129 to @xmath7 ) , constitutes the lr - gmm - slope algorithm summarized in algorithm  [ algo : gmmslope ] .",
    "similarly , when the low - rank constraint is imposed on the ple , we obtain the lr - ple - slope in algorithm  [ algo : pleslope ] .",
    "[ table : sim_psnr ]    [ table : sim_psnr_rgb ]",
    "we test the proposed algorithm on simulation datasets with 2d images .",
    "the proposed algorithm is compared with other leading algorithms 1 ) tval3  @xcite , 2 ) gap based on wavelet  @xcite , 3 ) damp  @xcite with bm3d denoising , and 4 ) nlr - cs  @xcite , which explores the low rank of similar patches .",
    "state - of - the - art results have been obtained by  @xcite .",
    "the gaussian components in our mixture model is set to @xmath150 for all the experiments and the analysis of this number is provided in section  [ sec : gmm_k ] .",
    "when updating @xmath7 , accelerated gap in ( [ eq : gapaccxk ] ) is used and the comparison of different approaches is shown in section  [ sec : compx ] .",
    "we obtained the low - rank gmm by setting the rank of each gaussian component learned via the em algorithm to the half of the full rank @xmath151 , where p = 64 for the patch size @xmath152 used in this paper .",
    "the proposed algorithm is further compared with jpeg compression in section  [ sec : jpeg ] .        +        , image size @xmath153.,scaledwidth=48.0% ]    following the formulation of the lensless camera  @xcite , the permuted hadamard matrix is used as the sensing matrix .",
    "each image is resized to @xmath153 and these images are shown in figure  [ fig : csimage ] .",
    "the csr is defined as : @xmath154 where the number of columns in @xmath40 is equivalent to the total pixel number of the image . the sensing matrix",
    "is constructed from rows of a hadamard matrix of order @xmath155 .",
    "the columns of the hadamard matrix is permuted according to a predetermined random permutation ( the same permutation is used in the real data captured by our lensless camera ) . for each csr",
    ", we use the first csr@xmath156 rows of the column - permuted hadamard matrix as the sensing matrix . by selecting some other rows of the permutated hadamard matrix",
    ", we can get better results  @xcite .",
    "however , here we just select the top rows to be consistent to the implementation of our lensless camera .",
    "note that in this case , @xmath157 is an identity matrix and it is very fast to use accelerated gap update for @xmath7 in  .",
    "we observed that best results are obtained by the lr - gmm - slope with gap updates of @xmath7 and these results are reported in this section . for the comparison of ist , gap and admm",
    ", please refer to section  [ sec : compx ] .    since when csr=0.1 , good results have been achieved for most images ( see figure  [ fig : baba01 ] for one example )",
    ", we here spend more efforts on the extremely low csr , in particular csr@xmath158 , which may be of interest to the real applications that are used to detect anomalous events  @xcite without caring too much about the image quality .",
    "the results are summarized in table  [ table : sim_psnr ] .",
    "we can observe that best results are obtained by the proposed aglorithm , nlr - cs or d - amp .",
    "when csr is less than 0.1 , the proposed algorithm usually provides best results except  foreman \" , where nlr - cs is the best .",
    "we also observed that nlr - cs is very sensitive to the parameters and sometimes the psnrs are not linearly increasing as the csr increases , while the other algorithms including the proposed do not have this problem . on average ,",
    "our proposed algorithm works best when csr@xmath159 .",
    "though did not reported here , when csr@xmath160 , the proposed algorithm also provides comparable or better results than d - amp and nlr - cs .",
    "but we need to tune the noise parameter used in @xmath161 , while for all the results presented here , we set it to the same value @xmath162 .",
    "in addition , we need to tune the rank thresholds @xmath72 , for which we have observed that a higher csr requires a larger @xmath72 .",
    ".,scaledwidth=48.0% ]    in addition to the grayscale images tested above as in other papers , we also conduct our proposed algorithm on the rgb images with results shown in table  [ table : sim_psnr_rgb ] .",
    "three sensors are simulated to capture the r , g and b components of the image .",
    "book \" scene corresponds to the real data captured by our lensless camera .",
    "again , our proposed algorithm provides the best results .",
    "one example with csr@xmath163 is shown in figure  [ fig : peppers003 ] .",
    "it can be seen that our algorithms provide more details than nlr - cs and d - amp ; both of them presents  blob \" artifacts .",
    ".jpeg compression at different qualities compared with the proposed compressive sensing recovery [ cols=\"^,^,^,^,^,^\",options=\"header \" , ]     [ table : jpeg_psnr ]     +    we now compare lr - gmm - slope under the compressive sensing framework with the jpeg compression , which is based on the sparsity of the dct coefficients of @xmath152 blocks ( non - overlapping patches ) .",
    "we first use an png file as the ground truth and then use the script within matlab ",
    "imwrite(@xmath164 ) \" by choosing 8-bits ` jpeg ' compression with different qualities ( 100 denotes the highest quality ) .",
    "we treat the quality 100 as the standard full file size .",
    "for the ` barbara ' image we used here , psnr = 58.47db ( w.r.t . the png file ) and the file size is 45.6 kb at quality 100 .",
    "the compressed image is obtained by changing the compression quality from 1 to 100 and we compare the file size with the full size at quality 100 , computing the csr used in this paper .",
    "table  [ table : jpeg_psnr ] summarizes the results of jpeg compression compared with the results obtained by our algorithm .",
    "this is a rough , high level comparison because jpeg also performs an entropy encoding after the dct transform and quantization , while in our method , the number of compressive measurements is compared with the number of total pixels , and we did not consider the entropy coding on quantized measurements .",
    "we intend to take the effect of the entropy encoding in jpeg out of the comparison by computing the jpeg compression ratio as compared to the quality 100 .",
    "when the compression is high ( lower csr ) , the gap between our approach and the jpeg compression is small .",
    "it is worth noting that when csr=0.0334 , our algorithm performs better than jpeg .",
    "when the compression gets lower , the gap becomes larger .",
    "one possible reason is that when jpeg is performed on the image , the ground truth is available and it is very easy to capture useful information from the truth .",
    "however , under the compressive sensing framework and using the current algorithm , increasing a few number of measurements can help the reconstruction , but not that significantly .",
    "example images can be found in figure  [ fig : jpeg_comp ] .",
    "it can be seen that jpeg compression has obvious block artifacts while the results of the proposed algorithm become better progressively with increasing number of measurements .",
    "furthermore , in jpeg compression , if we lose some bits , we may not be able to decode entire blocks . by contrast , in our compressive sensing framework , if we lose some measurements , we can still reconstruct the image , maybe not at a high fidelity .",
    ".,scaledwidth=48.0% ]      we provide three approaches in section  [ sec : ist ] to update @xmath7 in order to minimize the objective function in ( [ eq : jx ] ) .",
    "now we compare these three updates via experiments .",
    "we emphasize again that we are using the permuted hadamard matrix as the sensing matrix and thus @xmath157 is an identity matrix .",
    "therefore , updating @xmath7 via gap in ( [ eq : gapxk ] ) is same as updating @xmath7 via ist in ( [ eq : istxk ] ) .",
    "however , the accelerated gap in ( [ eq : gapaccxk ] ) provides best results in our experiments . without tunning the admm parameters carefully ,",
    "we compare these three update methods with different images at various csr , and one example is shown in figure  [ fig : comp_admm_gap ] . it can be observed that the accelerated gap update always provides the best result and when csr is low , ist is better than admm . when csr is getting larger , admm becomes better than ist .",
    "because of this , all the results reported in this paper is generated by the accelerated gap update .    ) .",
    "barbara is used with csr = 0.1.,scaledwidth=48.0% ]      one problem of using gmm is how to set the component number @xmath60 . as we are using the mixture model , each patch",
    "is represented by the posterior distribution , another gmm .",
    "therefore , selecting this @xmath60 is not as critical as in the ple  @xcite . an alternative way to infer this",
    "@xmath60 is utilizing the manifold factor analysis model as developed in  @xcite .",
    "hereby , we investigate this point empirically by using the  barbaba \" image as used before with different number of @xmath165 $ ] .",
    "the results at csr@xmath166 are shown in figure  [ fig : gmm_k ] .",
    "it can be seen that our algorithm is not sensitive to this @xmath60 , since the standard deviation of the psnrs with different @xmath60 is only 0.04265db compared with the mean value 26.0707db .    ) .",
    ", scaledwidth=48.0% ]      as mentioned earlier , when we consider that each patch is drawn from a single gaussian component , the proposed approach degrades to the ple .",
    "we verify the performance of lr - ple - slope compared with the lr - gmm - slope in figure  [ fig : gmm_ple ] .",
    "it can be seen that the gmm always performs better than the ple at lower csr .",
    "when csr is getting larger , they start to perform similarly .",
    "regrading the computational time , our algorithm is similar to nlr - cs .",
    "if a warm start is used to initialize the @xmath88 , we can obtain a good reconstruction within 20 iterations .",
    "one @xmath153 grayscale image reconstruction at csr@xmath166 takes around 1 minute on an i7cpu with 24 g ram .",
    "similar time is required for the lr - ple - slope but it needs more memory . while the most time consumption of lr - gmm - slope is the em training of gmm , the lr - ple - slope requires a long time for the model selection , and it usually needs more gaussian components ( _ i.e. _ , 20 ) than the gmm to get good results .",
    "we now verify our proposed algorithm on the real data captured by our lensless camera  @xcite , which is composed of an aperture assembly and a single sensor ( a photodiode ) to capture grayscale images ; it can also be a rgb sensor to capture color images . the aperture assembly implements the sensing matrix and we programmed it to be the permuted hadamard matrix . by capturing the scene with different sensing matrices",
    ", we obtain the measurement vector @xmath129 .",
    "we implemented the aperture assembly with a transparent lcd and thus we can control the image resolution by merging the neighboring pixels .    .",
    "two photos ( top : lena , bottom : alexander graham bell ) are used as the scene.,title=\"fig:\",scaledwidth=48.0% ] + .",
    "two photos ( top : lena , bottom : alexander graham bell ) are used as the scene.,title=\"fig:\",scaledwidth=48.0% ]      we first consider the case with gray scale sensor and the image resolution of @xmath167 . to capture compressive measurements ,",
    "we use a sensing matrix which is constructed from rows of a hadamard matrix of order @xmath168 .",
    "each row of the hadamard matrix is permuted according to a predetermined random permutation .",
    "the scene is composed of a photo printed on a paper and we capture the measurements of this photo .",
    "example results using different numbers of measurement are shown in fig .",
    "[ fig : lena_real ] .",
    "we also compare the five algorithms used in the simulation .",
    "it can be seen that , similar to the simulation , our proposed algorithm provides best result when csr is small .",
    "especially , at csr = 0.05 and 0.1 , our algorithm can present many details of the face , for example , the left eye of  lena \" .",
    "d - amp introduces some  blob \" noise because the bm3d denoising approach is used . though nlr - cs can provide good results at csr = 0.05 and 0.1",
    ", it introduces some unpleasant artifacts when csr is from 0.15 to 0.25 .",
    "we also tried the algorithm ( shm ) proposed in  @xcite , where a bayesian model is developed to investigate the tree - structure in wavelet .",
    "surprisingly , shm now works better than tval3 and gap , mainly due to the following two reasons .",
    "firstly , the tree structure in wavelet helps the reconstruction and secondly , the bayesian framework developed in  @xcite is very robust to noise ; it infers noise from the measurements .",
    ".,scaledwidth=50.0% ]      next we consider the rgb images captured by the rgb sensor , and now the resolution is @xmath169 . the sensing matrix is constructed from rows of a hadamard matrix of order @xmath155 and the first @xmath170 elements are used .",
    "the scene is the real scene of four books as shown  @xcite .",
    "the reconstruction result is shown in figure  [ fig : books_real ] with diverse csr .",
    "note that by using compressive measurements , we can save the sensors as well as the bandwidth .",
    "as stated earlier , we may progressively get better results by receiving more measurements .",
    "one of the main usage of compressive sensing is to get features in limited data by using a small bandwidth . from the results in figure  [ fig : lena_real ] , we may identity high quality features from the reconstructed image at csr around 0.1 .",
    "if we want to get some details , for example , the book titles in figure  [ fig : books_real ] , we may need csr around 0.2 . on the other hand , if we only need to identify that these are  books \" in figure  [ fig : books_real ]",
    ", csr at 0.05 may be sufficient .",
    "a novel compressive sensing reconstruction algorithm is developed via exploiting the low - rank property of overlapping patches . a general iteratively two - step framework for compressive sensing recovery is proposed .",
    "a denoising operator is used to update the estimate of the desired image ( obtained by the projection of the measurements ) , which can be implemented by investigating the sparsity or low - rank property of the image patches .",
    "we develop a probabilistic regime by representing each patch via a gaussian mixture model and impose low - rank on each gaussian component to achieve the state - of - the - art compressive sensing reconstruction results , in particular when the measurement number is small .",
    "additionally , the proposed low - rank gmm algorithm degrades to the low - rank piecewise linear estimator if each patch is modeled by a single gaussian model .",
    "extensive results on both simulation and real data demonstrate high performance of the proposed algorithm .",
    "e.  j. cands , j.  romberg , and t.  tao , `` robust uncertainty principles : exact signal reconstruction from highly incomplete frequency information , '' _ ieee transactions on information theory _ , vol .  52 , no .  2 , pp .",
    "489509 , february 2006 .",
    "x.  yuan , p.  llull , x.  liao , j.  yang , g.  sapiro , d.  j. brady , and l.  carin , `` low - cost compressive sensing for color video and depth , '' in _ ieee conference on computer vision and pattern recognition ( cvpr ) _ , 2014 .",
    "a.  stevens , l.  kovarik , p.  abellan , x.  yuan , l.  carin , and n.  d. browning , `` applying compressive sensing to tem video : a substantial framerate increase on any camera , '' _ advanced structural and chemical imaging _ , 2015 .",
    "p.  llull , x.  yuan , x.  liao , j.  yang , l.  carin , g.  sapiro , and d.  brady , `` compressive extended depth of field using image space coding , '' in _ computational optical sensing and imaging ( cosi ) _ , 2014 , pp . 13 .",
    "x.  yuan , t .- h .",
    "tsai , r.  zhu , p.  llull , d.  j. brady , and l.  carin , `` compressive hyperspectral imaging with side information , '' _ ieee journal of selected topics in signal processing _ , vol .",
    "9 , no .  6 , pp . 964976 , september 2015",
    ".        w.  l. chan , k.  charan , d.  takhar , k.  f. kelly , r.  g. baraniuk , and d.  m. mittleman , `` a single - pixel terahertz imaging system based on compressed sensing , '' _ applied physics letters _",
    "93 , no .  12 , pp . 1211051211053 , 2008 .",
    "s.  babacan , m.  luessi , l.  spinoulas , a.  katsaggelos , n.  gopalsami , t.  elmer , r.  ahern , s.  liao , and a.  raptis , `` compressive passive millimeter - wave imaging , '' _ international conference on image processing _ , pp . 27052708 , 2011 .",
    "j.  yang , x.  liao , x.  yuan , p.  llull , d.  j. brady , g.  sapiro , and l.  carin , `` compressive sensing by learning a gaussian mixture model from measurements , '' _ ieee transaction on image processing _ , vol .",
    "24 , no .  1 , pp .",
    "106119 , january 2015 .",
    "m.  a. figueiredo , j.  m. bioucas - dias , and r.  d. nowak , `` majorization  minimization algorithms for wavelet - based image restoration , '' _ ieee transactions on image processing _",
    "16 , no .  12 , pp . 29802991 , 2007 .",
    "i.  daubechies , r.  devore , m.  fornasier , and c.  s. gntrk , `` iteratively reweighted least squares minimization for sparse recovery , '' _ communications on pure and applied mathematics _ ,",
    "63 , no .  1 ,",
    "138 , 2010 .    j.  bioucas - dias and m.  figueiredo , `` a new twist : two - step iterative shrinkage / thresholding algorithms for image restoration , '' _ ieee transactions on image processing _ , vol .",
    "16 , no .",
    "12 , pp . 29923004 , december 2007 .",
    "c.  li , w.  yin , h.  jiang , and y.  zhang , `` an efficient augmented lagrangian method with applications to total variation minimization , '' _ computational optimization and applications _ , vol .",
    "56 , no .  3 , pp .",
    "507530 , 2013 .",
    "y.  huang , j.  paisley , q.  lin , x.  ding , x.  fu , and x.  zhang , `` bayesian nonparametric dictionary learning for compressed sensing mri , '' _ ieee transactions on image processing _ ,",
    "23 , no .",
    "50075019 , december 2014 .",
    "x.  liao , h.  li , and l.  carin , `` generalized alternating projection for weighted-@xmath172 minimization with applications to model - based compressive sensing , '' _ siam journal on imaging sciences _ , vol .  7 , no .  2 , pp . 797823 , 2014 .",
    "s.  boyd , n.  parikh , e.  chu , b.  peleato , and j.  eckstein , `` distributed optimization and statistical learning via the alternating direction method of multipliers , '' _ found .",
    "trends mach .",
    "_ , vol .  3 , no .  1 , pp .",
    "1122 , january 2011 .",
    "k.  dabov , a.  foi , v.  katkovnik , and k.  egiazarian , `` image denoising by sparse 3d transform - domain collaborative filtering , '' _ ieee transactions on image processing _ ,",
    "16 , no .",
    "8 , pp . 20802095 , august 2007 .",
    "j.  yang , x.  yuan , x.  liao , p.  llull , g.  sapiro , d.  j. brady , and l.  carin , `` video compressive sensing using gaussian mixture models , '' _ ieee transaction on image processing _ , vol .",
    "23 , no .  11 , pp .",
    "48634878 , november 2014 .",
    "m.  chen , j.  silva , j.  paisley , c.  wang , d.  dunson , and l.  carin , `` compressive sensing on manifolds using a nonparametric mixture of factor analyzers : algorithm and performance bounds , '' _ ieee transactions on signal processing _ , vol .",
    "58 , no .  12 ,",
    "61406155 , december 2010 ."
  ],
  "abstract_text": [
    "<S> we develop a new compressive sensing ( cs ) inversion algorithm by utilizing the gaussian mixture model ( gmm ) . </S>",
    "<S> while the compressive sensing is performed globally on the entire image as implemented in our lensless camera , a low - rank gmm is imposed on the local image patches . </S>",
    "<S> this low - rank gmm is derived via eigenvalue thresholding of the gmm trained on the projection of the measurement data , thus learned _ in situ_. the gmm and the projection of the measurement data are updated iteratively during the reconstruction . </S>",
    "<S> our gmm algorithm degrades to the piecewise linear estimator ( ple ) if each patch is represented by a single gaussian model . </S>",
    "<S> inspired by this , a low - rank ple algorithm is also developed for cs inversion , constituting an additional contribution of this paper . </S>",
    "<S> extensive results on both simulation data and real data captured by the lensless camera demonstrate the efficacy of the proposed algorithm . furthermore , we compare the cs reconstruction results using our algorithm with the jpeg compression . </S>",
    "<S> simulation results demonstrate that when limited bandwidth is available ( a small number of measurements ) , our algorithm can achieve comparable results as jpeg .    </S>",
    "<S> compressive sensing , gaussian mixture models , dictionary learning , sparse representation , lensless camera , low - rank . </S>"
  ]
}