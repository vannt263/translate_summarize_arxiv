{
  "article_text": [
    "checkpointing the state of a database is important for audit or recovery purposes . when compared to its counterpart in distributed systems , the database checkpointing problem has additionally to take into account the serialization order of the transactions that manipulates the data objects forming the database",
    "actually , transactions create dependencies among data objects which makes harder the problem of defining _ consistent _ global checkpoints in database systems .",
    "of course , it is always possible , in a database environment , to design a special transaction , that reads all data objects and saves their current values .",
    "the underlying concurrency control mechanism ensures this transaction gets a consistent state of the data objects .",
    "but this strategy is inefficient , intrusive ( from the point of view of the concurrency control @xcite ) and not practical since , a read only transaction may take a very long time to execute and may cause intolerable delays for other transactions @xcite .",
    "moreover , as pointed out by salem and garcia - molina @xcite , this strategy may drastically increase the cost of rerunning aborted transactions .",
    "so , it is preferable to base global checkpointing ( 1 ) on local checkpoints of data objects taken by their managers , and ( 2 ) on a mechanism ensuring mutual consistency of local checkpoints ( this will ensure that it will always be possible to get consistent global checkpoints by piecing together local checkpoints ) .    in this paper",
    "we are interested in exploiting such an approach .",
    "we consider a database in which each data object can be individually checkpointed ( note that a data object could include , practically , a set of physical data items ) .",
    "if these checkpoints are taken in an independent way , there is a risk that no consistent global checkpoint can ever be formed ( this leads to the well known _ domino effect _",
    "so , some kind of coordination is necessary when local checkpoints are taken in order they be mutually consistent . in this paper",
    "we are interested in characterizing mutual consistency of local checkpoints .",
    "more precisely , we are interested in the two following points .    * first , we address the following question : `` given an arbitrary set @xmath1 of checkpoints , can this set be extended to get a global checkpoint ( i.e. , a set including exactly one checkpoint from each data object ) that is consistent ? '' .",
    "the answer to this question is well known when the set @xmath1 includes exactly one checkpoint per data object @xcite .",
    "it becomes far from being trivial , when the set @xmath1 is incomplete , i.e. , when it includes checkpoints from only a subset of data objects .",
    "when @xmath1 includes a single data checkpoint , the previous question is equivalent to `` can this local checkpoint belong to a consistent global checkpoint ? '' . * then , we focus on data checkpointing protocols .",
    "let us consider the property `` local checkpoint @xmath2 belongs to a consistent global checkpoint '' .",
    "we design two non - intrusive protocols .",
    "the first one ensures the previous property when @xmath2 is any local checkpoint .",
    "the second one ensures it when @xmath2 belongs to a predefined set of local checkpoints .",
    "the paper consists of 4 main sections .",
    "section [ model ] introduces the database model we consider in this paper .",
    "section [ cgc ] defines consistency of global checkpoints .",
    "section [ dgc ] answers the previous question . to provide such an answer",
    ", it studies the kind of dependencies both the transactions and their serialization order create among checkpoints of distinct data objects . more specifically , it is shown that , while some data checkpoint dependencies are causal , and consequently can be captured on the fly @xcite , some others are `` hidden '' , in the sense that , they can not be revealed by causality .",
    "it is the existence of those hidden dependencies that actually makes non - trivial the answer to the previous question .",
    "then , section [ protocols ] shows how the necessary and sufficient condition stated in section [ dgc ] , can be used to design `` transaction - induced '' data checkpointing protocols ensuring the property `` local checkpoint @xmath2 belongs to a consistent global checkpoint '' .",
    "these protocols allow managers of data objects to take checkpoints independently on each other , and use transactions as a means to diffuse information , among data managers , encoding dependencies on the previous states of data objects .",
    "when a transaction that accessed a data object is committed , the data manager of this object may be directed to take a checkpoint in order previously taken checkpoints belong to consistent global checkpoints .",
    "such a checkpoint is called _ forced _ checkpoint .",
    "this is done by the data manager which exploits both its local control data and the information exchanged at the transaction commit point .",
    "last but not least , this paper can be seen as a bridge between the area of distributed computing and the area of databases . for a long time , databases have provided distributed computing with very interesting problems and protocols related to data replication , concurrency control , etc .",
    "we show here how database checkpointing can benefit from studies that originated from distributed computing .",
    "actually , a similar question has been addressed in the context of the asynchronous process / message - passing model @xcite . in this context",
    "a message establishes a simple relation between a pair of process local states . in the database context",
    ", a transaction may establish several relations between states of data objects .",
    "so , albeit there are some correspondences between the process / message - passing model and the data object / transaction model ) .",
    "] , it appears that extending process / message - passing model results to the context of database transactions is not trivial as a transaction is `` something '' more complicated than a message : a transaction is on several data objects at a time , and accesses them by read and write operations whose results depend on the serialization order .",
    "we consider a classical distributed database model .",
    "the system consists of a finite set of data objects , a set of transactions and a concurrency control mechanism ( see @xcite for more details ) .",
    "[ [ data - objects . ] ] data objects .",
    "+ + + + + + + + + + + + +    each data object is managed by a data manager @xmath3 .",
    "a set of data objects can be managed by the same data manager @xmath3 . for clarity",
    ", we suppose that the set of data managed by the same @xmath3 constitutes a single logical data .",
    "so , there is a data manager @xmath4 per data @xmath5 .",
    "[ [ transactions . ] ] transactions .",
    "+ + + + + + + + + + + + +    a transaction is defined as a partial order on _ read _ and _ write _ operations on data objects and terminates with a _ commit _ or an _ abort _ operation .",
    "@xmath6 ( resp .",
    "@xmath7 ) denotes a read ( resp .",
    "write ) operation issued by transaction @xmath8 on data object @xmath5 .",
    "each transaction is managed by an instance of the transaction manager ( tm ) that forwards its operations to the scheduler which runs a specific concurrency control protocol .",
    "the write set of a transaction is the set of all the data objects it wrote .",
    "[ [ concurrency - control . ] ] concurrency control .",
    "+ + + + + + + + + + + + + + + + + + + +    a concurrency control protocol schedules read and write operations issued by transactions in such a way that any execution of transactions is _ strict _ and _ serializable_. this is not a restriction as concurrency control mechanisms used in practice ( e.g. , two - phase locking 2pl and timestamp ordering ) generate schedules ensuring both properties @xcite .",
    "the _ strictness _ property states that no data object may be read or written until the transaction that currently writes it either commits or aborts .",
    "so , a transaction actually writes a data object at its commit point .",
    "hence , at some abstract level , which is the one considered by our checkpointing mechanisms , transactions execute atomically at their commit points .",
    "if a transaction is aborted , strictness ensures no cascading aborts and the possibility to use _ before images _ for implementing abort operations which restore the value of an object before the transaction access .",
    "for example , a 2pl mechanism , that requires that transactions keep their write locks until they commit ( or abort ) , generates such a behavior @xcite .",
    "[ [ distributed - database . ] ] distributed database .",
    "+ + + + + + + + + + + + + + + + + + + + +    we consider a distributed database as a finite set of sites , each site containing one or several ( logical ) data objects .",
    "so , each site contains one or more data managers , and possibly an instance of the tm .",
    "tms and dms exchange messages on a communication network which is asynchronous ( message transmission times are unpredictable but finite ) and reliable ( each message will eventually be delivered ) .",
    "[ [ execution . ] ] execution .",
    "+ + + + + + + + + +    let @xmath9 be a set of transactions accessing a set @xmath10 of data objects ( to simplify notations , data object @xmath11 is identified by its index @xmath12 ) .",
    "an execution @xmath13 over @xmath14 is a partial order on all read and write operations of the transactions belonging to @xmath14 ; this partial order respects the order defined in each transaction",
    ". moreover , let @xmath15 be the partial order defined on all operations accessing a data object @xmath5 , i.e. , @xmath15 orders all pairs of conflicting operations ( two operations are conflicting if they access the same object and one of them is a write ) . given an execution @xmath13 defined over @xmath14 ,   @xmath14",
    "is structured as a _ partial order _ @xmath16 where @xmath17 is the following ( classical ) relation defined on @xmath14 :    @xmath18",
    "each write on a data object @xmath5 issued by a transaction defines a new version of @xmath5 .",
    "let @xmath19 denote the @xmath12-th version of @xmath5 ; @xmath19 is called a _",
    "local state_. transactions establish dependencies between local states .",
    "this can be formalized in the following way .",
    "when @xmath20 issues a write operation @xmath21 , it moves the state of @xmath5 from @xmath19 to @xmath22 .",
    "more precisely , @xmath19 and @xmath22 are the local states of @xmath5 , just before and just after the execution '' means `` just before and just after @xmath20 is committed '' . ] of @xmath20 , respectively .",
    "this can be expressed in the following way by extending the relation @xmath17 to include local states : @xmath23 let @xmath24 be the transitive closure of the extended relation @xmath17 .",
    "when we consider only local states , we get the following _ happened - before _",
    "relation denoted @xmath25 ( which is similar to lamport s happened - relation defined on process events @xcite in the process / message - passing model ) :    [ precedence between states ] ( precedence on local states , denoted @xmath25 ) @xmath26    as the relation @xmath17 defined on transactions is a partial order , it is easy to see that the relation @xmath25 defined on local states is also a partial order . figure [ dipendenza ] shows examples of relation @xmath25 .",
    "it considers three data objects @xmath5 , @xmath27 , and @xmath28 , and two transactions @xmath29 and @xmath30 .",
    "transactions are defined in the following way :    @xmath31    @xmath32    as there is a read - write conflict on @xmath5 , two serialization orders are possible .",
    "figure [ dipendenza].a displays the case @xmath33 while figure [ dipendenza].b displays the case @xmath34 .",
    "each horizontal axis depicts the evolution of the state of a data object .",
    "for example , the second axis is devoted to the evolution of @xmath27 : @xmath35 and @xmath36 are the states of @xmath27 before and after @xmath29 , respectively .",
    "let us consider figure [ dipendenza].a .",
    "it shows that @xmath37 and @xmath38 add four pairs of local states to the relation @xmath25 , namely : @xmath39",
    "@xmath40 @xmath41 @xmath42 precedence on local states , due to write operations of transactions @xmath29 and @xmath43 , are indicated with continuous arrows , while the ones due to the serialization order are indicated in dashed arrows .",
    "figure [ dipendenza].b shows which precedences are changed when the serialization order is reversed",
    ".      a _ global state _ of the database is a set of local states , one from each data object .",
    "a global state @xmath44 is _ consistent _ if it does not contain two dependent local states , i.e. , if:@xmath45 \\rightarrow \\neg ( \\sigma^{i_x}_{x } < _ { ls } \\sigma^{i_y}_{y})\\ ] ] let us consider again figure [ dipendenza].a . the three global states @xmath46 , @xmath47 and @xmath48 are consistent .",
    "the global state @xmath49 is not consistent either because @xmath50 ( due to the fact @xmath33 ) or because @xmath51 ( due to the fact @xmath29 writes both @xmath27 and @xmath28 ) .",
    "intuitively , a non - consistent global state of the database is a global state that could not be seen by any omniscient observer of the database .",
    "it is possible to show that , as in the process / message - passing model , the set of all the consistent global states is a partial order @xcite .",
    "a _ local checkpoint _ ( or equivalently a _ data checkpoint _ ) of a data object @xmath5 is a local state of @xmath5 that as been saved in a safe place is stored on a disk , a copy is saved on another disk . ] by the data manager of @xmath5 .",
    "so , all the local checkpoints are local states , but only a subset of local states are defined as local checkpoints .",
    "let @xmath52 denote the @xmath12-th local checkpoint of @xmath5 ; so , @xmath52 corresponds to some @xmath53 with @xmath54 .",
    "a _ global checkpoint _ is a set of local checkpoints one for each data object .",
    "it is _ consistent _ if it is a consistent global state .",
    "we assume that all initial local states are checkpointed .",
    "moreover , we also assume that , when we consider any point of an execution @xmath13 , each data object will eventually be checkpointed .",
    "as indicated in the previous section , due to write operations of each transaction , or due to the serialization order , transactions create dependencies among local states of data objects .",
    "let us consider the following 7 transactions accessing data objects @xmath5 , @xmath27 , @xmath28 and @xmath55 :    @xmath56    @xmath57    @xmath58    @xmath59    @xmath60    @xmath61    @xmath62    figure [ serialization ] depicts the serialization imposed by the concurrency control mechanism .",
    "figure [ z - path ] describes dependencies between local states generated by this execution .",
    "five local states are defined as data checkpoints ( they are indicated by dark rectangles ) .",
    "we study dependencies between those data checkpoints .",
    "let us first consider @xmath63 and @xmath64 .",
    "@xmath63 is the ( checkpointed ) state @xmath55 before @xmath29 wrote it , while @xmath64 is the ( checkpointed ) state of @xmath27 after @xmath65 wrote it ( i.e. , just after @xmath65 is committed ) .",
    "the serialization order ( see figure [ serialization ] ) shows that @xmath66 , and consequently @xmath67 , i.e. , the data checkpoint @xmath64 is causally dependent @xcite on the data checkpoint @xmath63 ( figure [ z - path ] shows that there is a directed path of local states from @xmath63 to @xmath64 ) .",
    "now let us consider the pair of data checkpoints consisting of @xmath63 and @xmath68 .",
    "figure [ z - path ] shows that @xmath63 precedes @xmath29 , and that @xmath68 follows @xmath69 .",
    "figure [ serialization ] indicates that @xmath29 and @xmath69 are not connected in the serialization graph .",
    "so , there is no causal dependence between @xmath63 and @xmath68 ( figure [ z - path ] shows that there is no directed path from @xmath63 to @xmath68 ) .",
    "but , as the reader can check , there is no consistent global checkpoint including both @xmath63 and @xmath68 ( and @xmath70 to @xmath63 and @xmath68 can not produce a consistent global state as @xmath71 .",
    "adding @xmath72 instead of @xmath70 has the same effect as @xmath73 . ] ) .",
    "so there is an _ hidden _ dependence between @xmath63 and @xmath68 which prevents them to belong to the same consistent global checkpoint .",
    "we now provide a definition of dependence that takes into account both causal dependencies and hidden dependencies .",
    "( interval ) a checkpoint interval @xmath74 is associated with data checkpoint @xmath52 .",
    "it consists of all the local states @xmath75 such that : @xmath76    as an example , figure [ z - path ] shows that @xmath77 includes 4 consecutive local states of @xmath28 .",
    "note that , due to the assumptions on data checkpoints stated in section [ cons ] , any local state belongs to exactly one interval .",
    "let us call an edge of the partial order on local states a dependence edge .",
    "( dependence path ) .",
    "so , as shown by the next theorem , the _ dependence edge _ abstraction allows to extend results of @xcite to data checkpoints .",
    "]    there is a dependence path ( @xmath78 ) from a data checkpoint @xmath52 to @xmath79 ( denoted @xmath80 ) iff :    \\i ) @xmath81 and @xmath82 ; or    \\ii ) there is a sequence @xmath83 of dependence edges , such that :    * @xmath84 starts after @xmath52 ; * @xmath85 , @xmath86 : let @xmath87 be the interval in which @xmath86 arrives ; then @xmath88 starts in the same or in a later interval ( i.e. , an interval @xmath89 such that @xmath90 ) can start before @xmath91 arrives .",
    "this is where the dependence is `` hidden '' .",
    "if @xmath92 starts after @xmath86 arrives , then , the dependence path @xmath83 is purely causal . ] ; * @xmath93 arrives before @xmath79 .",
    "[ consi ] let @xmath94 and @xmath95 be a set of data checkpoints .",
    "then @xmath96 is a part of a consistent global checkpoint if and only if : @xmath97    * sufficiency .",
    "* we prove that if @xmath98 is satisfied then @xmath96 can be included in a consistent global checkpoint .",
    "let us consider the global checkpoint defined as follows :    * if @xmath99 , we take @xmath100 ; * if @xmath101 , for each @xmath102 we consider the integer @xmath103 ( with @xmath104 if @xmath105 or if this set is empty ) . then we take @xmath100 with @xmath106 .",
    "let us note that , from that definition , it is possible that @xmath107 ( in that case , @xmath100 is an initial data checkpoint ) .    by construction ,",
    "this global checkpoint satisfies the two following properties : @xmath108 @xmath109    we show that @xmath110 is consistent .",
    "assume the contrary .",
    "so , there exists @xmath5 and @xmath27 and a dependence edge @xmath111 that starts after @xmath112 and arrives before @xmath113 .",
    "so , it follows that :    @xmath114    four cases have to be considered :    1 .",
    "@xmath99 , @xmath102 .",
    "( 3 ) is contradicted by assumption @xmath98 .",
    "2 .   @xmath99 , @xmath115 .",
    "since @xmath116 , from ( [ eq2 ] ) we have : @xmath117 .",
    "+ as , at data @xmath5 both the dependence edge ending the path @xmath118 , and the dependence edge starting the path @xmath119 belong to the same interval , we conclude from ( [ eq2 ] ) that @xmath120 which contradicts the assumption @xmath98 .",
    "3 .   @xmath101 , @xmath121 .",
    "( [ pippo ] ) contradicts ( [ eq1 ] ) .",
    "@xmath101 , @xmath122 .",
    "since @xmath116 , from ( [ eq2 ] ) we have : @xmath123 .",
    "+ as in case 2 , we can conclude that @xmath124 which contradicts ( [ eq1 ] ) .",
    "* necessity .",
    "* we prove that , if there is a consistent global checkpoint @xmath125 including @xmath96 , then property @xmath126 holds for any @xmath94 .",
    "assume the contrary .",
    "so , there exist @xmath99 and @xmath102 such that @xmath127 . from the definition of @xmath128",
    ", there exists a sequence of dependence edges @xmath129 such that :    [ cols= \" < , < , < \" , ]     from the assumption induction applied to the path of dependence edges @xmath130 , we have : for any @xmath131 , @xmath100 and @xmath132 can not belong to the same consistent global checkpoint .",
    "moreover , @xmath133 starts in @xmath134 and arrives in @xmath135 imply that , for any @xmath136 and for any @xmath137 , @xmath138 and @xmath139 can not belong to the same consistent checkpoint . since @xmath140 , it follows that no checkpoint of @xmath141 can be included with @xmath100 and @xmath113 to form a consistent global checkpoint .",
    "[ [ messages - vs - transactions . ] ] messages _ vs _ transactions .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + +    an analogous result for message - passing systems has been designed in @xcite and generalized in @xcite .",
    "as indicated in section [ dp ] , point - to - point message - passing systems are characterized by the fact each message generates exactly one dependence edge between two process local checkpoints . in database systems ,",
    "a dependence edge is due either to a write operation or to the serialization order . as a transaction may issue several write operations and is serialized in some order by the concurrency control mechanism , it follows that it may generate a lot of dependence edges between data checkpoints .",
    "for example , when a transaction writes @xmath142 data objects , these writes establish @xmath143 dependence edges and supplementary edges are added according to the serialization order .",
    "[ [ consistency - of - a - recovery - line . ] ] consistency of a recovery line .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    let us call _ recovery line _",
    ", when adopting the distributed computing terminology .",
    "] a line joining all the data checkpoints of a global checkpoint .",
    "a recovery line is consistent iff the associated global checkpoint is consistent .",
    "let us remind black and dashed arrows introduced in the example of section [ localstates ] : a black arrow denotes a local checkpoints precedence created by a transaction , while a dashed arrow denotes a local checkpoints precedence created by the serialization order .",
    "when considering such black and dashed arrows ( see figure [ z - path ] ) , it is possible to show that a recovery line @xmath144 is consistent iff :    * no black arrow crosses @xmath144 . * no dashed arrow crosses @xmath144 from the right of @xmath144 to the left of @xmath144 .    in a message - passing system ,",
    "a recovery line ( cut ) is consistent iff no message crosses it from the right to the left @xcite .",
    "messages crossing the recovery line from left to right are `` in - transit '' with respect to the recovery line .",
    "this intuitively shows that , in a message - passing system : ( 1 ) a message corresponds to a `` dashed arrow '' , and ( 2 ) there is no `` black arrow '' .",
    "so , it appears that consistency of global checkpoints is a problem more involved in database systems than in message - passing systems .",
    "[ [ required - properties . ] ] required properties .",
    "+ + + + + + + + + + + + + + + + + + + +    if we suppose that the set @xmath1 includes only a checkpoint @xmath100 , the previous theorem leads to an interesting corollary @xmath145 :    @xmath100 belongs to a consistent global checkpoint if and only if @xmath146 .    providing checkpointing protocols ensuring property @xmath145 is interesting for two reasons : + - ( 1 ) it avoids to waste time in taking a data checkpoint that will never be used in any consistent global checkpoint , and + - ( 2 ) no domino - effect can ever take place as any data checkpoint belongs to a consistent global checkpoint .",
    "it follows from @xmath145 that @xmath2 belongs to a consistent global checkpoint .",
    "so the database can be restarted as soon as each data manager has restored its data checkpoint contained in a consistent global checkpoint including @xmath2 .",
    "note that , when compared to message - passing systems , no `` channel state '' has to be restored . ] .",
    "+ moreover , let us consider the following property @xmath147 : `` if it exists , the set @xmath148 formed by the data checkpoints with the same index @xmath149 ( one from each data object ) , is a consistent global checkpoint '' . in the following we provide two checkpointing protocols :    * the first protocol ( @xmath150 ) guarantees @xmath145 for all local checkpoints , and guarantees @xmath147 for any value of @xmath151 .",
    "* the second protocol ( @xmath152 ) ensures @xmath145 only for a subset of local checkpoints , and @xmath147 for some particular values of @xmath151 .",
    "actually , those protocols can be seen as adaptations to the data - object / transactions model , of protocols developed for the process / message - passing model .",
    "more precisely , protocol @xmath150 corresponds with briatico _",
    "s protocol @xcite , while protocol @xmath152 corresponds with wang - fuchs s protocol @xcite .",
    "[ [ local - control - variables . ] ] local control variables",
    ". + + + + + + + + + + + + + + + + + + + + + + + +    in both protocols we assume each data manager @xmath4 has an index @xmath153 , which indicates the index ( rank ) of the last checkpoint of @xmath5 ( it is initialized to zero ) .",
    "moreover , each data manager can take checkpoint independently ( _ basic checkpoints _ ) , for example , by using a periodic algorithm which could be implemented by associating a timer with each data manager .",
    "a local timer is set whenever a checkpoint is taken . when a local timer expires , a basic checkpoint is taken by the data manager .",
    "data managers are directed to take additional data checkpoints ( _ forced checkpoints _ ) in order to ensure @xmath145 or @xmath147 . the decision to take forced checkpoints",
    "is based on the control information piggybacked by transactions .",
    "a protocol consists of two interacting parts .",
    "the first part , shared by both algorithms , specifies the checkpointing - related actions of transaction managers .",
    "the second part defines the rules data managers have to follow to take data checkpoints .",
    "[ [ protocols - cala - and - calb - behavior - of - a - transaction - manager . ] ] protocols @xmath150 and @xmath152 : behavior of a transaction manager .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    let @xmath154 be the write set of a transaction @xmath8 managed by a transaction manager @xmath155 .",
    "we assume each time an operation of @xmath8 is issued by @xmath155 to a data manager @xmath4 , it returns the value of @xmath5 plus its index @xmath153 .",
    "@xmath155 stores in @xmath156 the maximum value among the indices of the data objects read or written by @xmath8 .",
    "when transaction @xmath8 is committed , the transaction manager @xmath155 sends a commit message to each data manager @xmath4 involved in @xmath154 .",
    "such commit messages piggyback @xmath156 .",
    "[ [ protocol - cala - behavior - of - a - data - manager . ] ] protocol @xmath150 : behavior of a data manager .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    as far as checkpointing is concerned , the behavior of a data manager @xmath4 is defined by the two following procedures namely take - basic - ckpt and take - forced - ckpt .",
    "they defined the rules associated with checkpointing .",
    "take - basic - ckpt(@xmath150 ) : :    : +    the timer expires : +    ( ab1 ) @xmath157 ; +    ( ab2 ) take checkpoint @xmath158 ; +    ( ab3 ) reset the local timer .",
    "take - forced - ckpt(@xmath150 ) : :    : +    @xmath4 * receives * commit(@xmath156 ) * from *    @xmath155 : +    @xmath159 * then * +    ( a1 ) @xmath160 ; +    ( a2 ) take a ( forced ) checkpoint @xmath158 ; +    ( a3 ) reset the local timer .",
    "+    ; +    ( a4 ) process the commit message .    from the increase of the index @xmath153 of a data object @xmath5 , and from the rule take - forced - ckpt(@xmath150 ) ( which forces a data checkpoint whenever @xmath159 ) , the condition @xmath161 follows for any data checkpoint .",
    "actually , this simple protocol ensures that , if @xmath162 , then the index @xmath153 associated with @xmath100 is strictly lesser than the index @xmath163 associated with @xmath164 .",
    "it follows from the previous observation that if two data checkpoints have the same index , then they can not be related by @xmath128 .",
    "so , all the sets @xmath148 that exist are consistent .",
    "note that the take - forced - ckpt(@xmath150 ) rule may produce gaps in the sequence of indices assigned to data checkpoints of a data object @xmath5 .",
    "so , from a practical point of view , the following remark is interesting : when no data checkpoint of a data object @xmath5 is indexed by a given value @xmath151 , then the first data checkpoint of @xmath5 whose index is greater than @xmath151 , can be included in a set containing data checkpoints indexed by @xmath151 , to form a consistent global checkpoint .",
    "[ [ protocol - calb - behavior - of - a - data - manager . ] ] protocol @xmath152 : behavior of a data manager .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    this protocol introduces a system parameter @xmath165 known by all the data managers @xcite . only for subset of data checkpoints whose index is equal to @xmath166 ( where @xmath167 is an integer )",
    ", we have : @xmath168 .",
    "moreover , when , @xmath169 , @xmath170 exists , then the global checkpoint @xmath171 exists and is consistent .",
    "the rule take - basic - ckpt(@xmath152 ) is the same to the one of the protocol @xmath150 .",
    "in addition to the previous control variables , each data manager @xmath4 has an additional variable @xmath172 , which is incremented by @xmath173 each time a data checkpoint indexed @xmath174 is taken .",
    "the rule take - forced - ckpt(@xmath152 ) is the following .",
    "take - forced - ckpt(@xmath152 ) : :    : +    @xmath4 * receives * commit(@xmath156 ) * from *    @xmath155 : +    @xmath175 * then * +    ( b1 )    @xmath176 ; +    ( b2 ) take a ( forced ) checkpoint @xmath158 ; +    ( b3 ) reset the local timer ; +    ( b4 ) @xmath177 .",
    "+    ; +    ( b5 ) process the commit message .",
    "[ [ about - coordination . ] ] about coordination .",
    "+ + + + + + + + + + + + + + + + + + +    compared to previous checkpointing protocols appeared in the literature @xcite , which use an explicit coordination among data managers to get consistent global checkpoints , the proposed protocols provide the same result by using a _ lazy _ coordination which is propagated among data managers by transactions ( with commit messages ) .",
    "in particular , protocol @xmath150 starts a `` transaction - induced '' coordination each time a basic checkpoint is taken ; while protocol @xmath152 starts a coordination each time a basic checkpoint , whose index is a multiple of the parameter @xmath173 , is taken .",
    "the latter protocol seems to be particularly interesting for database systems as it shows a tradeoff , mastered by a system parameter @xmath173 , between the number of forced checkpoints and the extent of rollback during a recovery phase .",
    "the greater @xmath173 is , the larger will be the rollback distance .",
    "this paper has presented a formal approach for consistent data checkpoints in database systems . given an arbitrary set of data checkpoints ( including at least a single data checkpoint from a data manager , and at most a data checkpoint from each data manager )",
    ", we answered the following important question `` can these data checkpoints be members of a same consistent global checkpoint ? '' by providing a necessary and sufficient condition .",
    "we have also derived two _ non - intrusive _ data checkpointing protocols from this condition ; these checkpointing protocols use transactions as a means to diffuse information among data managers .",
    "this paper can also be seen as a bridge between the area of distributed computing and the area of databases .",
    "we have shown that the checkpointing problem is harder in data - object / transaction systems than in process / message - passing systems . from a distributed computing point of view",
    ", we could say that database systems are difficult because they merge the `` synchronous world '' ( every transaction taken individually has to be perceived as _ atomic _ : it can be seen as a multi - rendezvous among the objects it is on ) and the `` asynchronous world '' ( due to relations among transactions managed by the concurrency control mechanism ) ."
  ],
  "abstract_text": [
    "<S> whether it is for audit or for recovery purposes , data checkpointing is an important problem of distributed database systems . </S>",
    "<S> actually , transactions establish dependence relations on data checkpoints taken by data object managers . </S>",
    "<S> so , given an arbitrary set of data checkpoints ( including at least a single data checkpoint from a data manager , and at most a data checkpoint from each data manager ) , an important question is the following one : `` can these data checkpoints be members of a same consistent global checkpoint ? '' .    </S>",
    "<S> this paper answers this question by providing a necessary and sufficient condition suited for database systems . </S>",
    "<S> moreover , to show the usefulness of this condition , two _ non - intrusive _ data checkpointing protocols are derived from this condition . </S>",
    "<S> it is also interesting to note that this paper , by exhibiting `` correspondences '' , establishes a bridge between the data object / transaction model and the process / message - passing model .    </S>",
    "<S> [ section ] [ section ] [ theorem]lemma [ theorem]property [ theorem]corollary    @xmath0    technical report 22 - 97 + dipartimento di informatica e sistemistica + universit di roma `` la sapienza '' + luglio 1997 </S>"
  ]
}