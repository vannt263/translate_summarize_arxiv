{
  "article_text": [
    "this paper is concerned with checking whether or not a chosen statistical model @xmath0 is in agreement with observed data @xmath1 where @xmath2 is the sample space with @xmath3-algebra @xmath4 and each @xmath5 is a probability measure on @xmath6 if it is determined that the observed data does not contradict the model , then inferences can proceed about the true value of @xmath7 . if the model fails to pass its checks",
    ", then there is a concern about the correctness of the inferences .",
    "thus , checking a proposed model based on the observed data is a matter of some significance .",
    "while there have been many methods developed for model checking , the approach taken here is bayesian in nature in that a prior is placed on the set of all probability measures on @xmath8 and inference is then conducted concerning model correctness .",
    "the approach taken to inference is based on a particular measure of evidence known as the relative belief ratio which measures how beliefs have changed from a priori to a posteriori .",
    "so a relative belief ratio is computed which indicates whether there is evidence for or against the model @xmath0 holding .",
    "furthermore , a calibration of this evidence is provided concerning whether there is strong or weak evidence for or against the model .",
    "relative belief ratios and the associated inferences are discussed in section 2 .",
    "recently , there has been considerable interest in developing bayesian nonparametric procedures for model checking .",
    "most of this has focused on embedding the proposed model as a null hypothesis in a larger family of distributions .",
    "then priors are placed on the null and the alternative and a bayes factor is computed .",
    "for example , florens , richard , and rolin ( 1996 ) used a dirichlet process for the prior on the alternative .",
    "carota and parmigiani ( 1996 ) , verdinelli and wasserman ( 1998 ) , berger and guglielmi ( 2001 ) and mcvinish , rousseau , and mengersen ( 2009 ) considered a mixture of dirichlet processes , a mixture of gaussian processes , a mixture of plya trees and a mixture of triangular distributions , respectively , for the prior on the alternative .",
    "another approach for model testing is based on placing a prior on the true distribution generating the data and measuring the distance between the posterior distribution and the proposed one .",
    "swartz ( 1999 ) and al - labadi and zarepour ( 2013 , 2014 ) considered the dirichlet process prior and used the kolmogorov distance to derive a goodness - of - fit test for continuous models .",
    "viele ( 2000 ) used the dirichlet process and the kullback - leibler distance to test only discrete models .",
    "hsieh ( 2011 ) used the plya tree prior and the kullback - leibler distance to test continuous distributions .",
    "the methodology developed in this paper combines the previous two approaches and provides some unique , beneficial features . a dirichlet process @xmath9 is considered as a prior on the set of all distributions on @xmath10 and then the concentration of the posterior distribution about the model of interest is compared to the concentration of the prior distribution about the model of interest .",
    "this comparison is made via a relative belief ratio to measure the evidence in the observed data for or against the model .",
    "a measure of the strength of this evidence is also provided .",
    "implementing the approach is fairly simple and does not require obtaining a closed form of the relative belief ratio .",
    "the methodology does not require the use of a prior on @xmath11 and so is truly a check on the model itself avoiding any issues with the prior on @xmath12 it is shown that , by appropriate choices of the hyperparameters @xmath13 and @xmath14 prior - data conflict with respect to @xmath15 namely , the distributions in the model lie in the tails of the prior , can be avoided .",
    "any prior on @xmath11 should be checked for prior - data conflict separately from a check on the model , and only when the model passes its checks , as this avoids confounding model error with error introduced by a poor choice of a prior , see evans and moshonov ( 2006 ) .    in section 3 the dirichlet process prior @xmath9 is briefly reviewed and in section 4 the basis of our goodness - of - fit measure , namely , the cramr - von mises distance between probability measures is discussed .",
    "section 5 deals with the heart of our proposal where it is argued that a particular usage of the cramr - von mises distance together with particular choices of the hyperparameters @xmath16 be employed . in section 6 a computational algorithm is developed for the implementation of relative belief inferences in this context .",
    "section 7 presents a number of examples where the behavior of the methodology is examined in some detail .",
    "let @xmath17 denote a collection of densities on a sample space @xmath18 and let @xmath19 denote a prior on @xmath20 after observing data @xmath21 the posterior distribution of @xmath11 is given by the density @xmath22 where @xmath23 is the prior predictive density of @xmath24 for an arbitrary parameter of interest @xmath25 denote the prior and posterior densities of @xmath26 by @xmath27 and @xmath28 respectively .",
    "the relative belief ratio for a value @xmath26 is then defined by @xmath29 where @xmath30 is a sequence of neighborhoods of @xmath26 converging ( nicely ) to @xmath26 as @xmath31 quite generally @xmath32 the ratio of the posterior density to the prior density at @xmath33 so @xmath34 is measuring how beliefs have changed concerning @xmath26 being the true value from _ a priori _ to _ a posteriori _ by comparing a posterior probability to a prior probability . note that a relative belief ratio is similar to a bayes factor , as both are measures of evidence , but the latter measures this via the change in an odds ratio .",
    "the full relationship between relative belief ratios and bayes factors is discussed in evans ( 2015 ) .",
    "our developments here are based on the relative belief ratio as the associated theory is much simpler .    by a basic principle of evidence , when @xmath35 the data have lead to an increase in the probability that @xmath26 is correct , and so there is evidence in favor of @xmath36 when @xmath37 the data have lead to a decrease in the probability that @xmath26 is correct , and so there is evidence against @xmath36 and when @xmath38 there is no evidence either way .",
    "note that @xmath34 is invariant under smooth changes of variable and also invariant to the choice of the support measure for the densities .",
    "as such all relative belief inferences possess this invariance which is not the case for many bayesian inferences such as using a posterior mode or expectation for estimation .",
    "the value @xmath39 then measures the evidence for the hypothesis @xmath40 it is also necessary , however , to calibrate whether this is strong or weak evidence for or against @xmath41 certainly the bigger @xmath39 is than 1 , the more evidence there is in favor of @xmath42 while the smaller @xmath39 is than 1 , the more evidence there is against @xmath43 but what exactly does a value of @xmath44 mean ? it would appear to be strong evidence in favor of @xmath42 because beliefs have increased by a factor of 20 after seeing the data .",
    "but what if other values of @xmath26 had even larger increases ? a  useful calibration of @xmath39 is given by@xmath45 namely , the posterior probability that the true value of @xmath26 has a relative belief ratio no greater than that of the hypothesized value @xmath43 note that ( [ strength ] ) is not a p - value as it has a very different interpretation .",
    "when @xmath46 so there is evidence against @xmath47 then a small value for ( [ strength ] ) indicates a large posterior probability that the true value has a relative belief ratio greater than @xmath39 and so there is strong evidence against @xmath43 when @xmath48 so there is evidence in favor of @xmath47 then a large value for ( [ strength ] ) indicates a small posterior probability that the true value has a relative belief ratio greater than @xmath49 and so there is strong evidence in favor of @xmath47 while a small value of ( [ strength ] ) only indicates weak evidence in favor of @xmath43    as @xmath34 measures the evidence that @xmath26 is the true value , it naturally leads to an estimate of @xmath33 for example , the best estimate of @xmath26 is clearly the value for which the evidence is greatest , namely , @xmath50 associated with this is a @xmath51-credible region @xmath52 where @xmath53 notice that @xmath54 for every @xmath55 $ ] and so , for selected @xmath56 we can take the `` size '' of @xmath57 as a measure of the accuracy of the estimate @xmath58 the interpretation of @xmath34 as the evidence for @xmath59forces the sets @xmath57 to be the credible regions .",
    "for if @xmath60 is in such a region and @xmath61 then @xmath62 must also be in the region as there is at least as much evidence for @xmath62 as for @xmath63    a number of optimality results have been established for relative belief inferences and these are discussed in evans ( 2015 ) .",
    "for example , suppose we use the relative belief ratio to accept @xmath64 when @xmath65 and reject when @xmath66 it is the case then that the acceptance region @xmath67 and the rejection region @xmath68 are optimal among all such regions in the following sense .",
    "let @xmath69 be another acceptance region such that @xmath70 where @xmath71 is the conditional prior predictive probability measure given that @xmath72 then among all such acceptance regions , @xmath73 minimizes the prior probability of rejecting @xmath74 when it is false .",
    "a similar result holds for @xmath75 furthermore , under mild conditions it is proved in evans ( 2015 ) that @xmath76 and @xmath77 as the amount of data increases .",
    "so the values of @xmath78 and @xmath79 can be set by design and it is then known that we are using the optimal tests with these characteristics .",
    "numerous additional optimality results are proved for the relative credible regions @xmath80 and the estimator @xmath81 in evans ( 2015 ) .",
    "the view is taken here that anytime continuous probability is used , then this is an approximation to a finite , discrete context .",
    "for example , if @xmath26 is a mean and the response measurements are to the nearest centimeter , then of course the true value of @xmath26 can not be known to an accuracy greater than 1/2 of a centimeter , no matter how large a sample we take . furthermore , there are implicit bounds associated with any measurement process .",
    "as such the restriction is made here to discretized parameters that take only finitely many values .",
    "so when @xmath26 is a continuous , real - valued parameter , it is discretized to the intervals @xmath82,(\\psi_{0}-\\delta,\\psi_{0}+\\delta],(\\psi_{0}+\\delta,\\psi_{0}+3\\delta],\\ldots$ ] for some choice of @xmath83 and there are only finitely may such intervals covering the range of possible values .",
    "it is of course possible to allow the intervals to vary in length as well . with this discretization , then @xmath84 @xmath85.$ ]    note that throughout the paper the notation @xmath86 could refer to either a probability measure or its corresponding cdf where the context determines the appropriate interpretation .",
    "the dirichlet process , formally introduced in ferguson ( 1973 ) , is the most well - known and widely used prior in bayesian nonparametric inference .",
    "consider a space @xmath2 with a @xmath87algebra @xmath4 of subsets of @xmath2 .",
    "let @xmath88 be a fixed probability measure on @xmath89 and @xmath13 be a positive number .",
    "following ferguson ( 1973 ) , a random probability measure @xmath90 is called a dirichlet process on @xmath91 with parameters @xmath13 and @xmath88 , if for any finite measurable partition @xmath92 of @xmath2 , the joint distribution of the vector @xmath93 has the dirichlet distribution with parameters @xmath94 @xmath95 where @xmath96 .",
    "we assume that if @xmath97 , then @xmath98 with a probability one .",
    "if @xmath86 is a dirichlet process with parameters @xmath13 and @xmath14 we write @xmath99 for any @xmath100 @xmath101 has a beta distribution with parameters @xmath102 and @xmath103 and so @xmath104 and @xmath105 the probability measure @xmath88 is called the _ base measure _ of @xmath86 .",
    "clearly @xmath88 plays the role of the _ center _ of the process , while @xmath13 can be viewed as the _ concentration parameter_. the larger @xmath13 is , the more likely it is that the realization of @xmath86 is close to @xmath88 .",
    "an attractive feature of the dirichlet process is the conjugacy property . if @xmath106 is a sample from @xmath107 , then the posterior distribution of @xmath86 is @xmath108 where @xmath109 with @xmath110 and @xmath111 the dirac measure at @xmath112 notice that , the posterior base distribution @xmath113 is a convex combination of the prior base distribution and the empirical distribution .",
    "the posterior base @xmath113 approaches the prior base @xmath88 as @xmath114 while @xmath113 converges to the empirical distribution as @xmath115    ferguson ( 1973 ) provided a series representation for @xmath99 specifically , let @xmath116 be i.i.d .",
    "exponential@xmath117 random variables , @xmath118 be i.i.d .",
    "@xmath88 random variables independent of @xmath119 and put @xmath120 where @xmath121 and @xmath122 from ( [ series - dp ] ) , it follows clearly that a realization of the dirichlet process is a discrete probability measure .",
    "this is true even when the base measure is absolutely continuous .",
    "note that , although the dirichlet process is discrete with probability one , this discreteness is no more troublesome than the discreteness of the empirical process . by imposing the weak topology ,",
    "the support for the dirichlet process is quite large .",
    "specifically , the support for the dirichlet process is the set of all probability measures whose support is contained in the support of the base measure .",
    "this means if the support of the base measure is @xmath2 , then the space of all probability measures is the support of the dirichlet process . for example , if we have a normal base measure , then the dirichlet process can choose any probability measure .",
    "recently , zarepour and al - labadi ( 2012 ) derived an efficient series approximation with monotonically decreasing weights for the dirichlet process .",
    "let @xmath123 be i.i.d .",
    "@xmath88 independent of @xmath124 be the co - cdf of the g@xmath125 distribution , and @xmath126 then@xmath127 converges almost surely to @xmath86 defined by ( [ series - dp ] ) , as @xmath128 . note that @xmath129 is the @xmath130-th quantile of the g@xmath131 distribution .",
    "this provides the following algorithm.@xmath132    * algorithm a : approximately generating a value from * @xmath9 * * * *    \\1 .",
    "fix a relatively large positive integer @xmath133 . *",
    "generate i.i.d .",
    "@xmath134 for @xmath135 * * * *    \\3 . for @xmath136 generate i.i.d .",
    "@xmath137exponential@xmath117 distribution independent of @xmath138 and put @xmath139 * * * *    \\4 . for @xmath140",
    "compute @xmath141 * * * *    \\6 .",
    "use ( [ eq11 ] ) to obtain an approximate value from @xmath9.@xmath132    for other simulation methods for the dirichlet process , see bondesson ( 1982 ) , sethuraman ( 1994 ) , and wolpert and ickstadt ( 1998 ) .",
    "a widely used distance between distributions is the cramr - von mises distance . for cdf",
    "s @xmath142 and @xmath143 this is defined as @xmath144 note that other distances could be employed in our analysis , see gibbs and su ( 2002 ) , but @xmath145 has some convenient attributes .",
    "the following lemma , as given in al - labadi and zarepour ( 2014 ) , provides a simple formula for the distance between a discrete and a continuous cdf .",
    "[ cvm1 ] let @xmath143 be a continuous cdf and @xmath146 be a discrete distribution , where @xmath147 are the order statistics of @xmath123 and @xmath148 are the associated jump sizes such that @xmath149 when @xmath150 then @xmath151    a corollary gives that the distribution of @xmath152 is independent of @xmath143 whenever @xmath153 and @xmath154 .",
    "[ cvm2]suppose that @xmath155 are i.i.d . , independent of @xmath156 and @xmath146 .",
    "then @xmath157 where @xmath158 is the @xmath159-th order statistic for @xmath160 i.i.d .",
    "uniform@xmath161.$ ]    since @xmath123 is a sequence of i.i.d .",
    "random variables with continuous distribution @xmath143 , then @xmath162 is i.i.d .",
    "uniform@xmath161 $ ] and the result follows from lemma [ cvm1 ] .    the following result allows the use of the approximation to the dirichlet process when considering the prior and posterior distributions of the cramr - von mises distance .",
    "[ cvm3]if @xmath107 and @xmath163 is given by ( [ eq11 ] ) , then @xmath164 as @xmath165    this follows by the dominating convergence theorem since for any cdf s @xmath143 and @xmath166 and @xmath167 .",
    "let @xmath168 denote the collection of cumulative distribution functions for the model and assume hereafter that these are continuous .",
    "suppose that @xmath106 is a sample from a distribution @xmath86 and the aim is to test the hypothesis @xmath169 . to this end",
    ", we use the prior @xmath107 for some choice of @xmath13 and @xmath88 so , by ( [ dp_posterior ] ) , @xmath170 .",
    "if @xmath171 is true , then we expect the observed data to lead to the posterior distribution of the distance between @xmath86 and @xmath172 being more concentrated about @xmath173 than the prior distribution of the distance between @xmath86 and @xmath174 for example , figure 1-a ( see example 1 ) is a plot of the prior and posterior densities of @xmath145 in a case where @xmath171 is true and indeed the posterior is much more concentrated about 0 than the prior .",
    "so our test will involve a comparison of the concentrations of the prior and posterior distributions of @xmath145 via a relative belief ratio based on @xmath145 with the interpretation as discussed in@xmath175section 2 .",
    "the first step is to determine how @xmath145 is to be used to measure the concentration of the prior and posterior about @xmath174 one possibility is to look at the prior and posterior distributions of @xmath176 while this is reasonable , a simpler approach , that avoids the computation of the infimum , is to choose the distribution @xmath177 which is best supported by the data and look at the prior and posterior distributions of @xmath178 as a measure of the closeness of @xmath86 to @xmath179 of course , when using relative belief ratios to measure evidence , the @xmath177 that is best supported by the data is @xmath180 where @xmath181 is the relative belief estimate of @xmath182 .",
    "note that the relative belief estimate of the full parameter @xmath11 is also the mle and this is independent of any prior @xmath183 on @xmath12 this would appear to induce a data dependent prior distribution for @xmath145 but in fact this is not the case for the approach developed here .",
    "this is accomplished by letting @xmath184 in the @xmath9 prior so the lack of dependence on the data is immediate from corollary [ cvm2 ] .",
    "so , considering the space of all probability measures @xmath86 on @xmath185 we take @xmath186 and assess @xmath171 using @xmath187 and its corresponding strength .",
    "lemma [ cvm4 ] justifies this approach . from lemma [ cvm3 ] ,",
    "note that the prior distribution of @xmath188 can be approximated by the prior distribution of @xmath189    there is another reason why choosing @xmath184 makes sense . for ,",
    "whatever choice of @xmath88 is made , it is necessary to avoid prior - data conflict as discussed , for example , in evans and moshonov ( 2006 ) .",
    "prior - data conflict here means that every @xmath177 lies in the `` tails '' of @xmath190 while it is true that the effect of the prior is overwhelmed by large amounts of data , for small sample sizes the prior can seriously distort things . in this context , when prior - data conflict exists , there can fail to be an appreciable concentration of the posterior distribution of @xmath191 about 0 even when @xmath171 is true .",
    "prior - data conflict will occur whenever there is a only tiny overlap between the effective support regions of @xmath86 and @xmath192 . specifically , by lemma [ cvm1 ] , @xmath193 depends on the base measure @xmath88 through the jump points @xmath194 .",
    "if the @xmath194 lie in one tail of @xmath192 , then we get prior - data conflict between @xmath86 and @xmath192 as @xmath88 and @xmath86 have the same effective support . to avoid this",
    "it is necessary that the @xmath194 are selected in a region that contains most of the mass of @xmath195 note that when @xmath184 then @xmath192 is the prior mean of @xmath86 and thus both share the same effective support .",
    "the effect of prior - data conflict is demonstrated in example 1 .",
    "the choice of @xmath88 should also avoid any effects due to `` double use of the data '' .",
    "such an effect typically means that the methodology results in overly conservative outcomes such that model failure is not detected when @xmath171 is false . to see that this is not the case when @xmath196",
    "it is now established that the posterior distribution of @xmath188 becomes concentrated around 0 as sample size increases if and only if @xmath171 holds . throughout the remainder of this paper @xmath197",
    "is the value that minimizes the divergence between the true distribution and a member of @xmath179    [ cvm4]let @xmath198 and suppose that @xmath199 as @xmath200 ( i ) if @xmath171 is true , then @xmath201 and ( ii ) if @xmath171  is false , then @xmath202    \\(i ) since @xmath203 , then the triangle inequality implies @xmath204 the result follows , as @xmath205 as @xmath206 from james ( 2008 ) , and @xmath207 under @xmath74 by the continuous mapping theorem and poly s theorem , see dasgupta ( 2008 ) .",
    "( ii ) as proved in choi and bulgren ( 1968 ) , @xmath208 using the triangle inequality , @xmath209 again @xmath210and , since @xmath171 does nt hold , @xmath211 therefore , @xmath212 which implies @xmath213 .",
    "the hyperparameter @xmath13 also needs to be chosen and so its effect needs to be studied . for this let @xmath214 denote the finite dimensional approximation of the @xmath9 process developed in ishwaran and zarepour ( 2002 ) , where @xmath215 is i.i.d .",
    "@xmath88 independent of @xmath216dirichlet@xmath217 .",
    "then @xmath218 in distribution as @xmath219 , for any measurable function @xmath220 with @xmath221 and @xmath107 .",
    "in particular , @xmath222 converges in distribution to @xmath86 , where @xmath223 and @xmath86 are random values in the space @xmath224 of probability measures on @xmath225 endowed with the topology of weak convergence . to generate @xmath226 put @xmath227 where @xmath228 is a sequence of i.i.d .",
    "gamma@xmath229 random variables independent of @xmath230 .",
    "this leads to the following result .",
    "[ cvm5]if @xmath231 and @xmath232 then ( i ) @xmath233@xmath234 and ( ii ) @xmath235    the result in lemma [ cvm1 ] applied to @xmath223 implies @xmath236 .",
    "furthermore , from properties of the dirichlet , @xmath237 and , as @xmath238beta@xmath239 independent of @xmath240 then @xmath241 the identities @xmath242 and @xmath243 establish ( i ) .",
    "taking the limit in @xmath244 as @xmath245 and using lemma [ cvm3 ] and dominated convergence gives ( ii ) .",
    "note that , from lemma [ cvm5](ii ) , @xmath246 as @xmath114 .    the selection of @xmath13 is an important step in determining the success of the algorithm .",
    "this is dependent on an number of criteria .",
    "for example , if @xmath142 corresponds to @xmath247 distribution , namely , a @xmath248 distribution on 3 degrees of freedom , and @xmath249 is the location - scale normal family , then @xmath250 while when @xmath142 is @xmath251 , then @xmath252 clearly then , the methodology discussed here will have more problems detecting model failure when the true distribution is like a @xmath247 than like a @xmath253 a natural approach then , to selecting a relevant @xmath254 is to first determine what kind of deviations from @xmath249 it is desired to detect , for example , a @xmath247 distribution in the context of assessing normality , and then run a simulation study to determine what values of @xmath13 are needed to detect this . in principal larger values of @xmath13 must be chosen to detect smaller deviations .",
    "this issue is further discussed in section 7 .",
    "it is also possible to consider several values of @xmath13 .",
    "for example , one may start with @xmath255 . if the relative belief ratio is less than 1 , then this is evidence against @xmath171 and larger values of @xmath13 will tend to reinforce this .",
    "on the other hand , if the relative belief ratio is greater than 1 , one may also consider larger values of @xmath13 to see if a more concentrated prior produces the same evidence .",
    "it is recommended that @xmath256 however , else the prior may become too influential .",
    "if , as the value of @xmath13 is increased , the corresponding relative belief ratio drops rapidly below 1 , then this is a clear indication against @xmath171 . as will be seen in the examples ,",
    "when the model is correct , the relative belief ratio always remains above 1 when larger values of @xmath13 are considered .",
    "closed forms of the prior and posterior densities of @xmath257 are typically not available and these are necessary if using ( [ relbel ] ) to compute @xmath258 .",
    "as such the relative belief ratios need to be approximated via simulation .",
    "a special problem arises here as @xmath171 corresponds ( approximately ) to @xmath259 and both @xmath260 and @xmath261 see figures 1 and 2 . in such a case determining @xmath187",
    "precisely is difficult .",
    "the formal definition of @xmath262 however , as given in section 2 , is as a limit and this limit can be approximated by @xmath263 , the ratio of the posterior to prior probability that @xmath264 for a suitably small value of @xmath265 in general @xmath266 can be chosen to be @xmath267 the @xmath268-th quantile of the prior distribution of @xmath269where @xmath270 is chosen close to 0 .",
    "the following gives a computational algorithm for the evidence , and its strength , for @xmath171 .",
    "of necessity this requires a discretization of the range of possible values for @xmath271 and this is chosen here to be based on quantiles of the prior distribution of @xmath272    * algorithm b : relative belief algorithm for model checking *    \\1 .",
    "use algorithm a to ( approximately ) generate a @xmath86 from @xmath273 . * *    \\2 .",
    "compute @xmath274 . * *    \\3 . repeat steps ( 1)-(2 ) to obtain a sample of @xmath275 values from the prior of @xmath271 . *",
    "use algorithm a to ( approximately ) generate a @xmath86 from @xmath276 . * *    \\5 .",
    "compute @xmath274 . * *    \\6 . repeat steps ( 4)-(5 ) to obtain a sample of @xmath277 values from the posterior of @xmath271 . * *    \\7 .",
    "let @xmath278 be a positive number .",
    "let @xmath279 denote the empirical cdf of @xmath271 based on the prior sample in ( 3 ) and for @xmath280 let @xmath281 be the estimate of @xmath282 the @xmath283-th prior quantile of @xmath284 here @xmath285 , and @xmath286 is the largest value of @xmath287 .",
    "let @xmath288 denote the empirical cdf of @xmath271 based on the posterior sample in ( 6 ) .",
    "for @xmath289 , estimate @xmath258 by @xmath290 the ratio of the estimates of the posterior and prior contents of @xmath291 also , estimate @xmath187 by @xmath292 where @xmath293 and @xmath294 is chosen so that @xmath295 is not too small ( typically @xmath296 . * *    \\8 . estimate the strength @xmath297 by the finite sum @xmath298    for fixed @xmath299 as @xmath300 then @xmath281 converges almost surely to @xmath301 and ( [ rbest ] ) and ( [ strest ] ) converge almost surely to @xmath258 and @xmath302 , respectively .",
    "the following establishes the consistency of the approach to testing the model as sample size increases .",
    "[ cvm6]consider the discretization @xmath303@xmath304 . as @xmath305 ( i ) if @xmath171 is true , then @xmath306 and ( ii ) if @xmath171 is false and @xmath307 , then @xmath308 and @xmath309    these results follow immediately from evans ( 2015 ) , section 4.7.1 .",
    "so the procedure performs correctly as sample size increases when @xmath171 is true .",
    "there is one small caveat , however , that needs to be considered when @xmath171 is false , namely , for large @xmath310the model will be identified as correct when @xmath311@xmath312 this underscores the need to identify what deviations from @xmath171 one wants to detect and then choosing @xmath13 so that indeed such a failure can be detected .",
    "in this section , the approach is illustrated through three examples , namely , the location normal , location - scale normal , and the scale exponential models .",
    "the effectiveness of the methodology is assessed using simulated samples from a variety of distributions and in example 2 an application to a real data set is presented .",
    "the following notation is used for the distributions in the tables , namely , @xmath313 is the normal distribution with mean @xmath314 and variance @xmath315 is the @xmath248 distribution with @xmath316 degrees of freedom , exp@xmath317 is the exponential distribution with mean @xmath318 and @xmath319 is the uniform distribution over @xmath320 $ ] . for all cases we set @xmath321 in algorithm",
    "b. we also provide the value @xmath322 , where @xmath142 is the true sampling distribution , as this indicates how close the true sampling distribution is to the family @xmath168 .",
    "the r code distrmod \" is used to calculate @xmath323    for the simulations , samples of @xmath324 were generated from the distribution @xmath142 in the table and then the methodology was applied to assess whether or not the relevant model in the example is correct .",
    "always the prior was taken to be @xmath325 except in table [ tab2 ] where the effect of making an inappropriate choice of @xmath88 is illustrated .",
    "also , we always took @xmath326 with @xmath327 so that @xmath328 is the @xmath329-quantile of the prior distribution of @xmath330 while one could always choose @xmath268 smaller , the critical factor here is the choice of @xmath13 as the prior has to be sufficiently concentrated about the family.@xmath331    * example 1 . * _ location normal model .",
    "_    in this example @xmath332 and so @xmath333 in table [ tab1 ] the relative belief ratios and the strengths are recorded for testing the location normal model against a variety of alternatives using several choices of the hyperparameter @xmath334 recalling that we want @xmath335 and the strength close to 1 when @xmath171 is true and @xmath336 and the strength close to 0 when @xmath171 is false , it is seen that the methodology performs wonderfully in every instance except one , namely , when the alternative is the @xmath247 distribution and @xmath255 .",
    "surprisingly , the @xmath247 distribution has distance from the location normal family equal to @xmath337 which is quite a bit smaller than the other alternatives .",
    "it is obviously more difficult to detect model failure when this distance is small than otherwise .",
    "the solution to this , however , is seen from the table as this failure is detected for larger values of @xmath13 .",
    "so to detect small deviations it is necessary to use a prior that is more concentrated and this can be assessed a priori .",
    "notice that in all other cases the appropriate conclusion is reached with @xmath255 .",
    "figure 1 provides plots of the density of the prior distance and the posterior distance for some cases .",
    "it follows , for instance , from figure 1 that the posterior density of the distance is more concentrated about 0 than the prior density of the distance when the model is correct but not to the same degree otherwise .",
    "[ c]|c|c|c|c|c|distribution & @xmath338 & @xmath13 & @xmath339 & @xmath340 ( strength ) + @xmath341 & @xmath342 & @xmath343 & @xmath344 & @xmath345 + & & @xmath346 & @xmath347 & @xmath348 + & & @xmath349 & @xmath350 & @xmath351 + @xmath352 & @xmath342 & @xmath343 & @xmath353 & @xmath354 + & & @xmath346 & @xmath355 & @xmath356 + & & @xmath349 & @xmath350 & @xmath357 + @xmath358 & @xmath359 & @xmath343 & @xmath360 & @xmath361 + & & @xmath346 & @xmath362 & @xmath361 + & & @xmath349 & @xmath363 & @xmath361 + @xmath364 & @xmath365 & @xmath343 & @xmath344 & @xmath361 + & & @xmath346 & @xmath366 & @xmath361 + & & @xmath349 & @xmath367 & @xmath361 + @xmath368 & @xmath369 & @xmath343 & @xmath370 & @xmath371 + & & @xmath346 & @xmath366 & @xmath361 + & & @xmath349 & @xmath372 & @xmath361 + @xmath373 & @xmath374 & @xmath343 & @xmath375 & @xmath361 + & & @xmath346 & @xmath376 & @xmath361 + & & @xmath349 & @xmath377 & @xmath361 + @xmath247 & @xmath378 & @xmath343 & @xmath344 & @xmath379 + & & @xmath346 & @xmath380 & @xmath381 + & & @xmath349 & @xmath367 & @xmath371 + @xmath382 & @xmath383 & @xmath343 & @xmath384 & @xmath361 + & & @xmath346 & @xmath376 & @xmath361 + & & @xmath349 & @xmath385 & @xmath361 + @xmath386 $ ] & @xmath387 & @xmath343 & @xmath344 & @xmath361 + & & @xmath346 & @xmath380 & @xmath361 + & & @xmath349 & @xmath388 & @xmath361 + @xmath389 $ ] & @xmath390 & @xmath343 & @xmath375 & @xmath391 + & & @xmath346 & @xmath392 & @xmath393 + & & @xmath349 & @xmath394 & @xmath361 + @xmath395 & @xmath396 & @xmath343 & @xmath360 & @xmath397 + & & @xmath346 & @xmath398 & @xmath399 + & & @xmath349 & @xmath388 & @xmath361 + @xmath400 & @xmath401 & @xmath343 & @xmath384 & @xmath361 + & & @xmath346 & @xmath392 & @xmath361 + & & @xmath349 & @xmath402 & @xmath361 +    it is interesting to consider the effect of prior - data conflict on the methodology as this illustrates the importance of an appropriate choice of @xmath88 in the @xmath9 prior .",
    "table [ tab2 ] gives the outcomes of model checking for a particular sample of @xmath324 from the @xmath352 distribution where @xmath403 was obtained and where various choices of @xmath88 and @xmath13 are made .",
    "clearly when @xmath184 , we get the correct conclusion about the location normal model but not otherwise even though each @xmath88 is in the location normal family . if @xmath13 is increased when @xmath88 is far from the truth , this increases prior - data conflict and its ill effects .",
    "[ c]|c|c|c|c|distribution & @xmath13 & @xmath339 & @xmath340 ( strength ) + & @xmath343 & @xmath404 & @xmath405 + & @xmath346 & @xmath366 & @xmath406 + & @xmath349 & @xmath388 & @xmath379 + & @xmath343 & @xmath407 & @xmath361 + & @xmath346 & @xmath366 & @xmath361 + & @xmath349 & @xmath377 & @xmath361 + & @xmath343 & @xmath408 & @xmath399 + & @xmath346 & @xmath347 & @xmath361 + & @xmath349 & @xmath409 & @xmath361 +    * example 2 . * _ location - scale normal model . _    in this example @xmath410 and so @xmath411 the results are reported in table [ tab3 ] .",
    "it is seen that in all cases where the normal is correct the methodology gives the correct answer .",
    "failures occur with the mixture of normals and the @xmath389 $ ] distributions , as evidence is not obtained against the model in these cases . in these cases",
    "the cramr - von mises distance does not appear to give a particularly powerful test against these alternatives .",
    "when the sample size @xmath412 and @xmath13 are increased , however , model failure is detected .",
    "for example , with @xmath413 and @xmath414 the relevant relative belief ratios ( strengths ) are @xmath415 and @xmath416 for the mixture of normals and @xmath389 $ ] distributions , respectively .",
    "so reasonably strong evidence is obtained against normality in both cases and even more conclusive results are obtained with @xmath417 namely , @xmath418 and @xmath419 respectively .",
    "[ c]|c|c|c|c|c|distribution & @xmath338 & @xmath13 & @xmath339 & @xmath340 ( strength ) + @xmath341 & @xmath342 & @xmath343 & @xmath408 & @xmath420 + & & @xmath346 & @xmath421 & @xmath422 + & & @xmath349 & @xmath350 & @xmath351 + @xmath352 & @xmath342 & @xmath343 & @xmath423 & @xmath424 + & & @xmath346 & @xmath376 & @xmath425 + & & @xmath349 & @xmath350 & @xmath357 + @xmath358 & @xmath342 & @xmath343 & @xmath344 & @xmath426 + & & @xmath346 & @xmath355 & @xmath427 + & & @xmath349 & @xmath409 & @xmath428 + @xmath364 & @xmath342 & @xmath343 & @xmath370 & @xmath429 + & & @xmath346 & @xmath372 & @xmath430 + & & @xmath349 & @xmath367 & @xmath431 + @xmath368 & @xmath432 & @xmath343 & @xmath433 & @xmath434 + & & @xmath346 & @xmath435 & @xmath436 + & & @xmath349 & @xmath367 & @xmath437 + @xmath373 & @xmath438 & @xmath343 & @xmath439 & @xmath361 + & & @xmath346 & @xmath376 & @xmath361 + & & @xmath349 & @xmath402 & @xmath361 + @xmath247 & @xmath440 & @xmath343 & @xmath353 & @xmath441 + & & @xmath346 & @xmath380 & @xmath442 + & & @xmath349 & @xmath377 & @xmath443 + @xmath382 & @xmath444 & @xmath343 & @xmath445 & @xmath361 + & & @xmath346 & @xmath446 & @xmath361 + & & @xmath349 & @xmath377 & @xmath361 + @xmath386 $ ] & @xmath447 & @xmath343 & @xmath448 & @xmath449 + & & @xmath346 & @xmath450 & @xmath451 + & & @xmath349 & @xmath402 & @xmath452 + @xmath389 $ ] & @xmath453 & @xmath343 & @xmath454 & @xmath455 + & & @xmath346 & @xmath456 & @xmath457 + & & @xmath349 & @xmath377 & @xmath458 + @xmath395 & @xmath459 & @xmath343 & @xmath460 & @xmath461 + & & @xmath346 & @xmath366 & @xmath399 + & & @xmath349 & @xmath367 & @xmath361 + @xmath400 & @xmath459 & @xmath343 & @xmath462 & @xmath463 + & & @xmath346 & @xmath435 & @xmath464 + & & @xmath349 & @xmath402 & @xmath465 +    consider now the data of 100 stress - rupture lifetimes of kevlar pressure vessels presented in andrews and herzberg ( 1985 ) .",
    "the goal is to test whether the underlying distribution is normal .",
    "in this case @xmath466 .",
    "previous studies such as evans and swartz ( 1994 ) and verdinelli and wasserman ( 1998 ) , suggested that model is not correct . in this case",
    "@xmath467 @xmath468 , which is relatively a small distance , while @xmath469 .",
    "the results in table [ tab4 ] support somewhat the non - normality of this data set although only when using a more concentrated prior .",
    "figure 2 provides plots of the prior and posterior densities of the distance for various values of the concentration parameter @xmath13 .",
    "it follows clearly from this figure that increasing the concentration parameter @xmath13 makes the density of the prior distance more concentrated about @xmath173 than the density of the posterior distance .",
    "thus , figure 2 supports the conclusion of the non - normality of the data set .",
    "[ c]|c|c|c|@xmath13 & @xmath339 & @xmath340 ( strength ) + @xmath343 & @xmath470 & @xmath471 + @xmath346 & @xmath362 & @xmath472 + @xmath349 & @xmath367 & @xmath473 + @xmath474 & @xmath475 & @xmath476 + @xmath477 & @xmath478 & @xmath479 +    * example 3 . * _ scale - exponential model . _    in this example @xmath480 and so @xmath333 the results are reported in table [ tab5 ] and it is seen that the methodology performs very well here .",
    "in fact , the model is always correctly identified when it is true and always strong evidence is obtained against the model when it is false except when considering the @xmath386 $ ] distribution with @xmath255 but the more concentrated prior leads to evidence against .",
    "[ c]|c|c|c|c|c|distribution & @xmath338 & @xmath13 & @xmath339 & @xmath340 ( strength ) + @xmath341 & @xmath481 & @xmath343 & @xmath482 & @xmath361 + & & @xmath346 & @xmath392 & @xmath361 + & & @xmath349 & @xmath367 & @xmath361 + @xmath352 & @xmath483 & @xmath343 & @xmath484 & @xmath361 + & & @xmath346 & @xmath347 & @xmath361 + & & @xmath349 & @xmath409 & @xmath361 + @xmath358 & @xmath485 & @xmath343 & @xmath408 & @xmath361 + & & @xmath346 & @xmath456 & @xmath361 + & & @xmath349 & @xmath388 & @xmath361 + @xmath364 & @xmath486 & @xmath343 & @xmath487 & @xmath361 + & & @xmath346 & @xmath488 & @xmath361 + & & @xmath349 & @xmath377 & @xmath361 + @xmath368 & @xmath489 & @xmath343 & @xmath384 & @xmath361 + & & @xmath346 & @xmath376 & @xmath361 + & & @xmath349 & @xmath409 & @xmath361 + @xmath373 & @xmath490 & @xmath343 & @xmath353 & @xmath361 + & & @xmath346 & @xmath347 & @xmath361 + & & @xmath349 & @xmath491 & @xmath361 + @xmath247 & @xmath492 & @xmath343 & @xmath493 & @xmath361 + & & @xmath346 & @xmath435 & @xmath361 + & & @xmath349 & @xmath377 & @xmath361 + @xmath382 & @xmath494 & @xmath343 & @xmath448 & @xmath361 + & & @xmath346 & @xmath366 & @xmath361 + & & @xmath349 & @xmath377 & @xmath361 + @xmath386 $ ] & @xmath495 & @xmath343 & @xmath496 & @xmath497 + & & @xmath346 & @xmath450 & @xmath463 + & & @xmath349 & @xmath367 & @xmath479 + @xmath389 $ ] & @xmath498 & @xmath343 & @xmath360 & @xmath361 + & & @xmath346 & @xmath450 & @xmath361 + & & @xmath349 & @xmath409 & @xmath361 + @xmath395 & @xmath173 & @xmath343 & @xmath499 & @xmath500 + & & @xmath346 & @xmath488 & @xmath501 + & & @xmath349 & @xmath402 & @xmath502 + @xmath400 & @xmath173 & @xmath343 & @xmath503 & @xmath504 + & & @xmath346 & @xmath376 & @xmath505 + & & @xmath349 & @xmath367 & @xmath506 +",
    "a general methodology for model checking based on the use of the dirichlet process and relative belief has been considered .",
    "this combination is seen to lead to some unique advantages for this problem and this has been demonstrated by developing theoretical properties of the procedure . through several examples",
    ", it has been shown that the approach performs extremely well .    while cramr - von mises distance has been used here ,",
    "other distance measures could be used instead and may have distinct advantages in some problems .",
    "for instance , the anderson - darling distance and the kullback - leibler distance are possible substitutes .",
    "this entails simply substituting such alternatives for @xmath145 in the algorithms .",
    "an important extension is the generalization of the approach to construct tests for families of multivariate distributions . while conceptually similar , there are computational and inferential issues that need to be addressed and this is the subject of current research .",
    "al - labadi , l. , and zarepour , m. ( 2013 ) . a bayesian nonparametric goodness of fit test for right censored data based on approximate samples from the beta  stacy process .",
    "_ canadian journal of statistics _ , 41 , 3 , 466487 .",
    "carota , c. , and parmigiani , g. ( 1996 ) .",
    "on bayes factors for nonparametric alternatives . in _",
    "bayesian statistics 5 _ ( j. m. bernardo , j. .",
    "berger , a. p. dawid , and a. f. m. , eds . ) smith .",
    "oxford university press , london .",
    "florens , j. p. , richard , j. f. , and rolin , j. m. ( 1996 ) .",
    "bayesian encompassing specification tests of a parametric model against a nonparametric alternative .",
    "technical report 9608 , universits catholique de louvain , institut de statistique .",
    "james , l. f. ( 2008 ) .",
    "large sample asymptotics for the two - parameter poisson - dirichlet process . in _ pushing the limits of contemporary statistics : contributions in honor of jayanta k. ghosh _ , ed .",
    "b. clarke and s. ghosal , ohio : institute of mathematical statistics , 187 - 199 ."
  ],
  "abstract_text": [
    "<S> model checking procedures are considered based on the use of the dirichlet process and relative belief . </S>",
    "<S> this combination is seen to lead to some unique advantages for this problem . in particular , it avoids double use of the data and prior - data conflict . </S>",
    "<S> several examples have been incorporated , in which the proposed approach exhibits excellent performance . </S>"
  ]
}