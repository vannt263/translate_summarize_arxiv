{
  "article_text": [
    "low - density parity - check ( ldpc ) codes , first invented by gallager in 1960 s @xcite , have been found to be capable of approaching the channel capacity .",
    "later , ldpc convolutional codes ( ldpcccs ) have been shown to outperform ldpc block codes in terms of error performance ( e.g. , lower error floors and higher coding gains ) under a similar decoding complexity  @xcite .",
    "the comparisons between ldpcccs and ldpc block codes from the perspectives of hardware complexity , delay requirements , memory requirements have been discussed in @xcite and @xcite .",
    "ldpccc has inherited the basic structure of convolutional code and enables a continuous encoding and decoding of messages of varying lengths .",
    "such a property has made ldpccc a promising solution in many applications . when designing an ldpccc for an application , furthermore ,",
    "many factors such as code rate , sub - block length , coding gain , throughput , error performance and the encoder / decoder complexity may have to be taken into consideration .",
    "high data rate optical communications require powerful error correction codes with low redundancies to achieve an error floor lower than a bit error rate ( ber ) of @xmath0 , preferably @xmath2  @xcite .",
    "motivated by such applications , the goal of this work is to design and implement an efficient decoder architecture such that codes can achieve _ high throughput _ , _ high coding gain _ , _ high code rate _ and _ low error floor_.    designing high - throughput decoder architectures for ldpc block codes has been extensively studied . in @xcite , a high - throughput memory - efficient decoder architecture that jointly optimizes the code design , the decoding algorithm and",
    "the architecture level has been proposed .",
    "a practical coding system design approach has been presented in @xcite whereby the ldpc codes are constructed subject to decoder hardware constraints .",
    "simulation results have shown that the codes constructed suffer from only minor performance loss compared with unconstrained ones . in @xcite , a quasi - cyclic ldpc",
    "( qc - ldpc ) decoder architecture that achieves a throughput of @xmath3 mbps has been studied .",
    "the high throughput is achieved by reducing the critical path through modifying the decoding algorithm as well as the check - node and variable - node processor architectures . in @xcite , the throughput of a qc - ldpc decoder",
    "is further improved by parallelizing the processing of all layers in layered decoding .",
    "subsequently , the decoder can achieve a maximum throughput of @xmath4 gbps with an operating frequency of @xmath5  mhz and @xmath6 min - sum decoding iterations . in @xcite ,",
    "the authors have proposed a high - speed flexible shift - ldpc decoder that can adapt to different code lengths and code rates .",
    "the decoder employs the benes network to handle the complicated interconnections for various code parameters .",
    "it adopts the single - minimum min - sum decoding and achieves a throughput of @xmath7 gbps with an operating frequency of @xmath8 mhz .",
    "although ldpccc decoders may `` borrow '' some design techniques used in the ldpc block decoder architectures , overall they are very different from the block code counterparts due to the distinct code construction mechanism and unique characteristics of ldpcccs .",
    "high - throughput ldpccc decoder architectures based on parallelization have been studied in @xcite .",
    "such architectures can achieve a throughput of over @xmath9 gbps with a clock frequency of @xmath10 mhz .",
    "they , however , are confined to time - invariant ldpcccs and can not be easily applied to time - varying ones , which usually produce a better error performance . in @xcite , a register - based decoder architecture attaining up to @xmath11 mbps throughput has been proposed .",
    "this architecture has successfully implemented a pipeline decoder with @xmath6 processing units .",
    "nonetheless , its register - intensive architecture has limited its power efficiency . in @xcite ,",
    "a low - cost low - power memory - based decoder architecture that uses a single decoding processor has been proposed .",
    "on one hand , the _ serial _ node operation uses a small portion of the field - programmable gate array  ( fpga ) resources . on the other hand ,",
    "such a design has posed a significant limitation on the achievable throughput .",
    "subsequently , the memory - based designs with _ parallel _ node operations have been proposed and have led to a substantial improvement in throughput @xcite .",
    "the high throughput accomplished under these designs , however , is achieved at the cost of a complicated switch network .    to the best of the authors knowledge ,",
    "the previously proposed ldpccc decoder architectures mainly handle random time - varying ldpcccs . in this paper , we propose a decoder architecture for ldpcccs with regular structures",
    ". in particular , the proposed decoder caters for a class of ldpcccs that have a quasi - cyclic structure and can be derived from a qc - ldpc block code @xcite .",
    "the motivation of considering codes with regular structures is twofold .",
    "first , ldpcccs with regular structures have recently attracted much interest both theoretically and empirically @xcite .",
    "second , following the insights from ldpc block codes , regular codes can make the decoder structure much simpler and at the same time achieve good error performance .",
    "therefore , developing an efficient architecture for regular codes is of high importance in practice .",
    "the contributions in our paper are distinct from previous works in many aspects including complexity , throughput , reliability and scalability .",
    "firstly , we eliminate all switch networks , which are included in most of the previous implementations and are very complex for a high - rate ldpccc . instead , we propose the use of dedicated block processing units , with which we can provide higher throughput with similar decoder complexity .",
    "second , the quantized sum - product algorithm ( qspa ) applied in our ldpccc decoder is more reliable compared with the min - sum - based ldpccc decoder , i.e. , qspa outperforms the min - sum - based decoder in terms of error performance . furthermore , our proposed qspa implementation has a complexity only linearly proportional to the check - node degree .",
    "third , it is known that more decoding iterations can enhance the error performance of the decoder . in our decoder design , each decoding iteration",
    "is accomplished by one processor and the processors are serially connected .",
    "our decoder architecture also enables us to change the number of processors easily without re - designing the whole decoder .",
    "thus , our decoder is scalable in terms of the number of processors .",
    "we have implemented our decoder architecture for a rate @xmath12 ldpccc in an altera stratix fpga .",
    "the decoder has produced a throughput of @xmath13 gbps with a clock running at @xmath14 mhz .",
    "moreover , the ldpccc has an excellent error performance , achieving an error of lower than @xmath0 at a bit - energy - to - noise - power - spectral - density ratio ( @xmath1 ) of @xmath15 db .",
    "the rest of the paper is organized as follows .",
    "section  [ sec : review ] reviews the construction of qc - ldpcccs and the decoding process for such codes .",
    "section  [ sec : dec ] describes the proposed decoder architecture and pipeline schedule .",
    "section  [ sec : results ] presents the implementation complexity of the decoder architecture .",
    "the fpga simulation results are also presented in this section .",
    "finally , section  [ sec : conclude ] concludes the paper .",
    "@xmath16      the parity - check matrix of an unterminated time - varying periodic ldpccc is shown in where @xmath17 is termed as the memory of the parity - check matrix ; and @xmath18 , @xmath19 , are @xmath20 sub - matrices with full rank .",
    "an ldpccc is periodic with period @xmath21 if @xmath22 for all @xmath19 . if @xmath23 , the code is time - invariant ; otherwise , it is time - varying .",
    "the code rate of the ldpccc is given by @xmath24 .",
    "moreover , a coded sequence @xmath25 } = [ \\bv_0 , \\bv_1 , \\cdots,]$ ] with @xmath26 $ ] ( @xmath27 ) satisfies @xmath28 } \\bv_{[0,\\infty]}^t = 0.\\ ] ]    given a quasi - cyclic ldpc ( qc - ldpc ) block code with a base matrix of size @xmath29 and an expansion factor of @xmath30@xcite , we can construct a qc - ldpccc in the parity - check matrix @xmath31 are composed of identity matrices , cyclic - right - shifted identity matrices or zero matrices .",
    "] as follows .    1",
    "expand the parity - check matrix of the qc - ldpc block code into a @xmath32 matrix @xmath33 .",
    "2 .   represent the @xmath32 parity - check matrix @xmath33 as a @xmath34 matrix , where @xmath35 is the greatest common divisor of @xmath36 and @xmath37 , i.e. , @xmath38 .",
    "then we have @xmath39,\\ ] ] where @xmath40 is a @xmath41 matrix , for @xmath42 .",
    "split @xmath33 into @xmath43 and @xmath44 which correspond to the lower triangular part and the strictly upper triangular part of @xmath33 , respectively . @xmath43 and @xmath44 are therefore denoted , respectively , by + @xmath45_{m \\times m } $ ] + and + @xmath46_{m \\times m}. $ ] 4 .",
    "unwrap the parity - check matrix of the block code to obtain the parity - check matrix of a qc - ldpccc in the form of , i.e. , @xmath47 } = \\left [ \\begin{array}{cccc } \\bh^{b}_{l } &   &    & \\\\ \\bh^{b}_{u } & \\bh^{b}_{l }   & &    \\\\               & \\bh^{b}_{u } & \\bh^{b}_{l } & \\\\               &               & \\ddots & \\ddots\\\\ \\end{array } \\right].\\ ] ]    the above construction process is illustrated in fig .",
    "[ fig : protographldpccc ] . by comparing and",
    ", it can be observed that the period of the qc - ldpccc is @xmath48 and the memory @xmath17 satisfies @xmath49 .",
    "it can also be observed that the relative positions between the variable nodes and the check nodes do not change .",
    "hence the girth of the qc - ldpccc is no less than that of the original qc - ldpc block code  @xcite .",
    "therefore , we can construct a large - girth qc - ldpccc by first designing the sub - matrices to obtain a large - girth qc - ldpc block code and then performing the unwrapping operation .",
    "ldpccc has an inherent pipeline decoding process@xcite .",
    "the pipeline decoder consists of @xmath50 processors , separated by @xmath51 code symbols , with @xmath50 being the maximum number of decoding iterations . throughout the decoding process , we assume that messages in log - likelihood - ratio ( llr ) form are being used .    at the start of each decoding step (",
    "say at time @xmath52 ) , the incoming channel messages associated with the @xmath53 new variable nodes @xmath54 $ ] enter the first processor .",
    "moreover , the corresponding variable - to - check messages for these variable nodes have the same values as the incoming channel messages .",
    "at the same time , the messages associated with the variable nodes @xmath55 are shifted from the @xmath56-th processor to the @xmath57-th processor , where @xmath58 .",
    "then , each processor updates the @xmath59 check nodes corresponding to the @xmath60-th block row of @xmath61}$ ] in using @xmath62 where @xmath63 is the check - to - variable message from check node @xmath64 to variable node @xmath65 ; @xmath66 is the variable - to - check message from variable node @xmath65 to check node @xmath64 ; @xmath67 is the set of variable nodes connected to check node @xmath64 ; and @xmath68 is the set @xmath67 excluding variable node @xmath65 .",
    "next , the processors perform variable - node updating for @xmath69 , @xmath70 using @xmath71 where @xmath72 is the channel message for variable node @xmath65 ; @xmath73 is the set of check nodes connected to variable node @xmath65 ; and @xmath74 is the set @xmath73 excluding check node @xmath64 .",
    "finally , the _ a posteriori probabilities _  ( apps ) for the @xmath53 variable nodes @xmath75 leaving the last processor are computed using @xmath76 based on which the binary value of each individual variable node is determined .",
    "thus , each _ decoding step _ consists of inputting new channel messages to the decoder , shifting messages , updating check - to - variable messages , updating variable - to - check messages , computing apps and decoding the output bits . as a result , after an initial delay of @xmath77",
    "decoding steps , there is a continuous output of the decoded bits .",
    "in the hardware design of an ldpccc decoder , the processor complexity , memory requirement , throughput and error performance are closely related .",
    "it is worthwhile to study their tradeoffs so as to design a decoder meeting the application requirements . following the notations presented in the construction of a qc - ldpccc",
    ", we can roughly characterize the factors affecting the decoder as follows .",
    "suppose the decoding process is divided into @xmath78 stages .",
    "a smaller @xmath78 provides a higher level of parallelism that the decoder can achieve .",
    "the error performance of an ldpccc improves as @xmath30 increases and/or @xmath50 increases and/or @xmath79 decreases .",
    "furthermore , the information throughput is proportional to @xmath80 while the memory usage is proportional to @xmath81 . also , the processor complexity in terms of combinational logics is proportional to @xmath82 .",
    "more details about the complexity of memory usage are shown in section  [ sec : mem ] .",
    "it can be seen that the error performance of an ldpccc can generally be improved at the cost of a higher processor complexity , more memory usage or a lower throughput .",
    "for instance , with the sub - matrix size @xmath83 fixed , as the code rate @xmath79 decreases , the error performance becomes better at the cost of a lower information throughput .",
    "furthermore , both the processor complexity and the memory requirement become higher due to an increase in the number of check nodes . with the code rate and",
    "the throughput fixed , as the sub - matrix size increases , the error performance improves with the same processor complexity but more memory usage .",
    "the experiment results presented in section  [ sec : results ] will provide a rough guideline on how to choose the parameters in order to achieve a targeted error performance , processor complexity and memory usage .    in most of the previous works , a generic processing unit such as that shown in fig .",
    "[ fig : bpu](a ) is applied in the ldpccc decoder . for this type of design ,",
    "a switch network and some corresponding control logics are required .",
    "the complexity overhead of the switch network is not a concern in the previous works mainly because the number of edges between the check nodes and the variable nodes is small .",
    "when the number of edges between the check nodes and the variable nodes is large , e.g. , for a high - throughput and high code - rate ldpccc , the routing and hardware complexity of the switch network becomes a critical issue .",
    "in our proposed decoder , we use dedicated block processing units ( bpus ) instead of generic processing units .",
    "consequently , the complexity of routing and switching the messages are no longer required i.e. , the complex switch network is eliminated . as shown in fig .",
    "[ fig : bpu](b ) , we use @xmath35 bpus in one processor .",
    "one bpu is used during each decoding step of one codeword and @xmath35 bpus are used to facilitate the pipeline of @xmath35 distinct codewords simultaneously . in general , our approach can obtain a @xmath35 times speed - up in throughput with the pipeline of @xmath35 distinct codewords .",
    "details will be described in section  [ subsec : pipeline ] .",
    "a high - throughput decoder requires parallel processing of the ldpccc .",
    "we propose a partially parallel decoder architecture that utilizes parallelization on both the node level and the iteration level .",
    "the number of rows and the number of columns of the sub - matrices @xmath84 in ( corresponding to @xmath18 in ) are @xmath85 and @xmath86 , respectively . our proposed decoder architecture",
    "is illustrated in fig .",
    "[ fig : dec ] .",
    "the decoder consists of @xmath50 processors where @xmath50 is the maximum number of decoding iterations .",
    "since the memory of a qc - ldpccc constructed using the method in section  [ sec : review ] is @xmath87 , the variable nodes and the check nodes in each processor are separated by a maximum of @xmath88 time instants .",
    "denote the @xmath89 check nodes and the @xmath53 variable nodes that enter a particular processor by @xmath90 $ ] and @xmath91 $ ] , respectively .",
    "then the check nodes and the variable nodes that are about to leave the processor are given by @xmath92 $ ] and @xmath93 $ ] , respectively . at each decoding step , a bpu is responsible for processing the check nodes that enter the processor ( i.e. , @xmath94 ) and the variable nodes that are about to leave the processor ( i.e. , @xmath95 ) .        at the start of each decoding step ,",
    "@xmath89 check nodes are to be processed .",
    "we divide them into @xmath78 groups and consequently we divide a complete decoding step into @xmath78 stages . at the @xmath56-th stage ( @xmath96 ) , @xmath97 check nodes @xmath98 $ ] are processed in parallel .",
    "the variable - to - check messages expressed in the sign - and - magnitude format are input to a group of @xmath97 check - node processors  ( cnps ) . among the resulting check - to - variable messages ,",
    "those between the check nodes in @xmath94 and the variable nodes _ not _ in the set @xmath95 will be written to the local rams , waiting to be further processed by other bpus . on the other hand , the updated check - to - variable messages between the check nodes in @xmath94 and the variable nodes in @xmath95 are converted to the format of 2 s complement before being processed by the variable - node processor ( vnp ) . since each check node is connected to a total of @xmath99 variable nodes in @xmath95 , @xmath100 variable nodes in @xmath95 are connected to the newly updated check nodes and hence @xmath101 vnps are needed in one bpu .",
    "finally , the updated variable - to - check messages are converted back to the format of sign - and - magnitude and they will be shifted to the next processor together with their associated channel messages in the next decoding step .    in the bpus ,",
    "the cnps update the check nodes according to .",
    "in practical implementations we need to quantize the messages to reduce the complexity . in our implementation",
    ", we adopt a four - bit quantization , where the quantization step is derived based on density evolution  @xcite and differential evolution  @xcite .",
    "empirical results show that its error performance is only 0.1 db worse than the floating - point sum - product algorithm ( spa ) .",
    "we consider a check node with degree @xmath102 . for a full quantized - spa ( qpsa )",
    "implementation , there should be @xmath102 inputs , each of length @xmath103-bits .",
    "consequently , the size of the look - up table ( lut ) becomes @xmath104 , which equals @xmath105 ( as we use @xmath106 ) in our design .",
    "we can observe that it is impractical to implement such an enormous lut . here , we propose to implement the cnp with quantization ( qspa ) by first pairing up the input messages and then calculating the extrinsic messages excluding the input itself . more specifically ,",
    "suppose the variable nodes connected to check node @xmath64 is listed as @xmath107 $ ] and the corresponding input messages are denoted by @xmath108 $ ] .",
    "the updated check - to - variable message to variable node @xmath109 is then calculated as @xmath110 where @xmath111 thus , can be implemented based on a simple lut tree , as shown in fig .",
    "[ fig : cnp ] .",
    "in fact , it can be easily verified that each lut is of size @xmath112 and the total number of units required is always @xmath113 .",
    "thus , our proposed tree - structured implementation ensures that the cnp complexity remains low , namely in @xmath114 .",
    "moreover , the vnp is basically an adding operation which can be implemented using an adder tree .",
    "for clarity of presentation , we first assume @xmath115 .",
    "hence we have @xmath116 and @xmath117 .",
    "as mentioned earlier , we divide the decoding step into @xmath78 stages with @xmath118 check nodes being processed in parallel .",
    "we consider the @xmath52-th block row of @xmath61}^{\\rm cc}$ ] shown in fig .",
    "[ fig : protographldpccc ] .",
    "this block row consists of @xmath119 sub - matrices , each having a size of @xmath83 .",
    "thus , this block row corresponds to @xmath30 check nodes and @xmath120 variable nodes in the tanner graph .",
    "we also assume that the @xmath119 sub - matrices are either the identity matrix or cyclic - right - shifted identity matrices .",
    "suppose @xmath94 and @xmath121 just enter a particular processor and @xmath122 and @xmath95 are about to be shifted out of the same processor . the memory requirement is explained as follows .",
    "we denote the check nodes by @xmath123 $ ] .",
    "we further divide them into @xmath78 groups with the @xmath56-th group being denoted by @xmath124 \\",
    "( i = 1,2,\\ldots , g)$ ] .",
    "as explained previously , in processing @xmath94 , @xmath124 $ ] are processed in parallel at the @xmath56-th stage of a decoding step . therefore in order to avoid the collisions of memory access , @xmath118 different rams are needed for storing the @xmath118 messages on the edges if each of the @xmath118 check nodes is connected to only one variable node . from the construction of the qc - ldpccc",
    ", moreover , each check node has a regular degree of @xmath37 , i.e. , each check node is connected to @xmath37 variable nodes .",
    "consequently , a total of @xmath125 rams are needed for storing the edge - messages passing between the check nodes in @xmath94 and their connected variable nodes to avoid the collisions of memory access .",
    "further , each processor has @xmath35 sets of such check nodes , i.e. , @xmath126 . as a result ,",
    "@xmath127 rams are allocated in one processor to store the edge - messages , i.e. , check - to - variable or variable - to - check messages .",
    "in addition , the data - depth and the data - width of the rams are equal to @xmath78 and the number of quantization bits , respectively .      for the channel messages , the memory storage mechanism is similar .",
    "the set of @xmath30 variable nodes corresponding to every @xmath83 sub - matrix are first divided into @xmath78 groups .",
    "then @xmath118 rams , each of which having @xmath78 entries , are allocated to store the channel messages .",
    "moreover , the variable nodes in @xmath121 correspond to @xmath128 sub - matrices and each processor contains @xmath35 variable - node sets denoted by @xmath129 .",
    "consequently , a total of @xmath130 rams are allocated to store the channel messages in one processor .",
    "the data - depth and the data - width of the rams are equal to @xmath78 and the number of quantization bits , respectively .    for a general case where @xmath35 is not necessarily equal to @xmath36 ,",
    "@xmath131 rams are needed to store the edge - messages and @xmath132 rams are required to store the channel messages in one processor . in modern fpgas ,",
    "the total number of internal memory bits is usually sufficient for storing the messages of codes with a reasonable length and with a reasonable number of decoding iterations .",
    "however , the number of ram blocks is usually insufficient .",
    "note that the operations of the pipeline processors are identical , the connections between the rams and the bpus are the same and the addresses of accessing the rams are the same . by taking advantage of the homogeneity of the processors , we can combine the rams in different processors into one large ram block .",
    "in particular , for the rams handling edge - messages , we can combine the @xmath50 sets of @xmath133 ram blocks distributed in the @xmath50 processors into _ one _ set of @xmath133 ram blocks .",
    "similarly , for the rams storing the channel messages , @xmath50 sets of @xmath134 ram blocks are combined into _",
    "one _ set of @xmath134 ram blocks .",
    "the data - depth of the rams remains the same while the data - width becomes @xmath50 times wider .",
    "note that the memory combination is a unique feature of ldpccc and is not boasted by ldpc block codes .",
    "another advantage of such a memory storage mechanism is that the address controller is a simple counter incrementing by one at every cycle , thanks to the quasi - cyclic structure .",
    "specifically , at the start of each decoding step , the addresses of accessing the rams are initialized based on the parity - check matrix @xmath61}^{cc}$ ] .",
    "as the decoding process proceeds , the addresses are incremented by one after every stage , until all @xmath78 stages are completed .",
    "conventional ldpccc decoder architectures @xcite@xcite@xcite adopt the pipeline design shown in fig .  [",
    "fig : conventional pipeline ] .",
    "each processor sequentially does the following : shift the messages in , update the check nodes , write the data to memories , input the messages to vnp and update the variable nodes .",
    "this pipeline schedule only utilizes pipelining on the iteration level following the standard decoding process . in this paper ,",
    "we propose a more efficient pipeline scheduling based on our dynamic memory storage structure .",
    "we first describe the pipeline schedule for a single codeword . instead of writing the updated messages from cnp and those from vnp in two separate stages , we combine them with the shifting operation .",
    "the updated messages from vnp and the channel messages associated with the updating variable nodes are directly output to the next processor , which completes the writing and shifting operations at the same time .",
    "since some of the updated messages from cnp need not be processed by vnp , they are written to the local memories at the same time .",
    "note that the memory locations into which the messages are shifted are exactly those storing the original messages loaded by the bpu .",
    "therefore , there would not have any memory collisions during the process .",
    "it can also be inferred from this process that the types of messages stored in the memories are dynamically changing .",
    "the messages associated with @xmath94 are all variable - to - check messages by the time @xmath94 first enters a processor and is ready to be processed by cnp . after each decoding step ,",
    "some of the messages are substituted by the updated variable - to - check messages from the previous processor .",
    "when @xmath35 decoding steps are completed , all the check - to - variable messages originally associated with @xmath94 will be completely substituted by variable - to - check messages . yet , they are now messages for @xmath135 and are ready for cnp in a new round of decoding .    figure  [ fig : pipeline2 ] describes the pipeline for a single codeword assuming @xmath136 and @xmath137 . comparing fig .",
    "[ fig : conventional pipeline ] and fig .",
    "[ fig : pipeline2 ] , it can be observed that decoding a group of check nodes using the proposed pipeline scheduling only takes @xmath138 of the time cost in conventional scheduling .",
    "the homogeneity of the pipeline processors also facilitates a pipeline processing of multiple codewords . as shown in fig .",
    "[ fig : pipeline2 ] where a single codeword is being decoded , the processing time of different bpus are separated in the sense that while one bpu is processing , the other bpus remain idle .",
    "to further increase the throughput , we can schedule other bpus to process other codewords .",
    "since the total number of blocks in a processor is @xmath35 , we can incorporate a maximum of @xmath35 different codewords in one processor , i.e. , allowing @xmath139 to process codeword-@xmath56 , for @xmath140 .",
    "depending on the number of codewords incorporated , the throughput can be increased by a factor of @xmath35 at the cost of additional memory storage and additional hardware complexity of the bpus .",
    "figure  [ fig : pipeline3 ] illustrates the pipeline schedule for four codewords with @xmath136 and @xmath137 .    using our proposed pipeline schedule , the throughput of the decoder is @xmath141 information bits for every @xmath142 cycles , where @xmath102 is the time delay for each pipeline stage such that @xmath142 cycles are used by one bpu .",
    "as there are more decoding stages , i.e. , @xmath78 increases , the throughput tends to @xmath143 bits / s with a running clock of @xmath144 hz .        [ fig : proposedpiepline ]    _ an illustrative example of the ram storage and decoding process _",
    "_ example : _ we consider a qc - ldpccc with @xmath145 , @xmath146 , @xmath147 and @xmath148 . since @xmath149 , each processor has @xmath150 bpus . in each processor ,",
    "@xmath151 rams are dedicated to store edge - messages and @xmath152 rams are dedicated to store channel messages .",
    "assume that the check nodes @xmath153 $ ] just enter a processor and the variable nodes @xmath154 $ ] are about to leave .",
    "the decoding step of processing @xmath139 @xmath155 is divided into @xmath145 stages .",
    "figure  [ fig : ram example ] shows the dynamic storage of the edge - messages in the rams at different time instances .",
    "step 1 ) it shows the ram storage at the start of processing @xmath94 and @xmath156 by @xmath157 .",
    "it can be seen that ram 1 to 8 store the variable - to - check messages for @xmath94 which is ready to be processed .",
    "ram 13 to 16 store the latest check - to - variable messages for @xmath158 , which are updated in the previous decoding step by @xmath159 .",
    "ram 9 to 12 store the variable - to - check messages that are newly updated in the previous decoding step and are shifted from the previous processor .",
    "step 2 ) it shows the ram storage after the first stage of @xmath157 processing . at the first stage",
    ", @xmath157 will process @xmath160 and @xmath161 and their connected variable nodes in @xmath156 , e.g. , @xmath162 $ ] .",
    "cnp reads the variable - to - check messages from the first set of entries located in ram 1 to 8 .",
    "the newly updated check - to - variable messages between @xmath94 and @xmath121 from cnp are input to the first set of entries in ram 1 to 4 ( i.e. , from where the check - to - variable messages are read ) , while the newly updated check - to - variable messages between @xmath94 and @xmath156 are input to the vnp and the resulting variable - to - check messages are shifted to the next processor . as a result , the updated variable - to - check messages between @xmath163 and @xmath164 are written to ram 5 to 8 and those between @xmath163 and @xmath165 are written to ram 13 to 16 .",
    "step 3 ) it shows the rams after the second stage of @xmath157 processing . at the second stage",
    ", @xmath157 will process @xmath166 and @xmath167 and their connected variable nodes in @xmath156 , e.g. , @xmath168 $ ] .",
    "cnp reads the variable - to - check messages from the second set of entries located in ram 1 to 8 .",
    "the newly updated check - to - variable messages between @xmath94 and @xmath121 from cnp are input to the second set of entries in ram 1 to 4 ( i.e. , from where the check - to - variable messages are read ) , while the newly updated check - to - variable messages between @xmath94 and @xmath156 are input to the vnp and the resulting variable - to - check messages are shifted to the next processor . as a result , the updated variable - to - check messages between @xmath163 and @xmath164 are written to ram 5 to 8 and those between @xmath163 and @xmath165 are written to ram 13 to 16 .",
    "the ram updating at the decoding step of @xmath159 is analogous to steps 2 ) and 3 ) above .",
    "after the second stage of @xmath159 , ram 1 to 8 will have the variable - to - check messages ready for @xmath164 and their connected variable nodes in @xmath163 .",
    "the ram storage is similar to that in step 1 ) with the time instances incrementing by @xmath150 .",
    "a new round of @xmath157 updating will follow according to steps 2 ) and 3 ) .",
    "also note that once the address controller is initialized at the start of the @xmath78 stages , the read / write address of accessing the rams are simply incremented by 1 .",
    "we have implemented the qc - ldpccc decoder on altera stratix iv .",
    "all the ber results for the qc - ldpccc decoder are hence obtained from fpga experiments under additive white gaussian noise ( awgn ) channels and @xmath103-bit quantization .",
    "based on a qc - ldpc block code with a @xmath169 base matrix , we construct qc - ldpcccs of different sub - matrix sizes .",
    "moreover , the sub - matrices of the block code are chosen such that the girth equals @xmath170 .",
    "then we simulate the ber performance of the qc - ldpcccs under different decoding iteration numbers .",
    "specifically , we have implemented ldpccc decoders with the following parameters : ( a ) @xmath171 and @xmath172 ; ( b ) @xmath173 and @xmath172 ; ( c ) @xmath174 and @xmath175 ; ( c ) @xmath174 and @xmath176 .",
    "recall that @xmath83 represents the sub - matrix size of each entry in the @xmath169 base matrix while @xmath50 denotes the number of iterations ( i.e. , processors ) used in the ldpccc decoders .    [ cols=\"<,<,<,<,<,<,<,<,<,^,^,^,^,^,^,^,^ \" , ]     -bit quantization.,scaledwidth=50.0% ]    table  [ tab : implementation ] shows the hardware complexity of the decoders when combined with the noise generator .",
    "the complexities for a single - codeword implementation as well as a four - codeword pipeline implementation are shown .",
    "we observe that the hardware complexity increases as the code length and the number of processors increases .",
    "figure  [ fig : ber ] further shows the ber results for the ldpcccs .",
    "based on fig .",
    "[ fig : ber ] and table  [ tab : implementation ] , we can see a tradeoff between ( i ) the ber performance , ( ii ) the code length and ( iii ) the number of processors ( i.e. , the number of iterations ) . we compare the performance of ldpccc with @xmath174 but with different number of decoding iterations @xmath50 .",
    "we can see that the ldpccc with @xmath175 is more than @xmath177  db better than that with @xmath176 at a ber of @xmath178 .",
    "we further compare the error performance of codes with similar processor complexity .",
    "we observe from table  [ tab : implementation ] that the ldpccc using @xmath174 and @xmath175 has a similar complexity with the ones using ( i ) @xmath171 and @xmath172 or ( ii ) @xmath173 and @xmath172 .",
    "figure  [ fig : ber ] shows that the ldpccc using @xmath174 and @xmath175 is outperformed by the ones using ( i ) @xmath171 and @xmath172 or ( ii ) @xmath173 and @xmath172 , even though the latter two codes have smaller sub - matrix sizes .",
    "it is therefore obvious that a larger number of decoding iterations can help reducing the error rate even when a smaller sub - matrix size is used . in summary , we find that the number of decoding iterations plays an important role in the error performance of the ldpccc .",
    "based on the above results , the following guidelines can be used in designing a ldpccc decoder .    * to increase the decoder throughput while maintaining a similar ber performance and the same number of memory bits , we can reduce the memory depth @xmath78 at the cost of more combinational logics . * to reduce the cost of combinational logics while maintaining a similar ber performance and throughput , we can increase @xmath30 and use a smaller number of processors @xmath50 . under such circumstances , the total memory bits may increase . * to reduce the memory bits while maintaining a similar ber performance and throughput , we can use a smaller @xmath30 and a larger @xmath50 at the cost of combinational logics .",
    "in addition , we attempt to compare our implementation results with those found from the literature . since the objective of our work is to achieve high throughput and good error performance , the code length and code rate of the codes used in our experiments are relatively large . while we can find quite a number of decoders in the literature , none of them consider codes with length comparable to the ones we use .",
    "all of them assume lengths which are relatively short and consequently they have high error floors and small coding gains .",
    "the `` closest '' one we can find is the qc - ldpc block decoder described by wang and cui @xcite , who target a high - speed decoder and adopt a length-@xmath179 qc - ldpc code in the experiment . in table",
    "i , we add the implementation results of the decoder in @xcite .",
    "although the decoder in @xcite seems to be less complex than our designs , its throughput ( @xmath180 gbps ) is only @xmath181 of ours ( @xmath182 gbps ) .",
    "if @xmath6 decoders in @xcite are put together in order to achieve the same throughput as our decoders , the total complexity of the decoders will become larger than ours .",
    "furthermore , the decoder in @xcite displays an error floor at a ber of @xmath183 while our decoder does not .",
    "in fact , at a ber of @xmath183 , our decoders can achieve an extra coding gain of @xmath184 db to @xmath9 db over the decoder in @xcite .",
    "thus , our proposed decoder is superior in achieving high throughput , high coding gain and low error floor .",
    "we also compare the ber performance of ldpcccs and their block - code counterparts under similar processor complexity and throughput . compared with a single - processor decoder of an ldpc block code with the same iteration number @xmath50 , the ldpccc decoder with @xmath50 processors , the length of the coded bits stored in each processor being the code length of the block code , incurs @xmath50 times more complexity , but achieves @xmath50 times higher throughput . in order for the ldpc block decoder to attain the same throughput , @xmath50 times",
    "more processors are needed to decode in parallel . under such circumstances ,",
    "the overall complexity of the ldpc block decoder will increase by @xmath50 times and becomes the same as the ldpccc counterpart .",
    "therefore , the fairness of comparing ldpccc with its block - code counter part based on which the ldpccc is derived is validated from the perspective of processor complexity and throughput .",
    "figure  [ fig : berqcldpcvsldpccc ] shows the ber performance of ldpcccs and their block - code counterparts .",
    "the results of the ldpc block codes are obtained from computer simulations ( using c programming ) based on 4-bit quantized messages .",
    "it can be seen that the ber performance of ldpcccs are generally superior .",
    "for instance , the ldpccc with @xmath171 and @xmath172 has a gain of @xmath180  db at a ber of @xmath185 over its block - code counterpart .",
    "another observation is that the advantage of ldpccc over its block - code counterpart becomes obvious as the number of decoding iterations increases .",
    "for example , the performance of ldpccc with @xmath174 and @xmath176 has a similar performance of its block - code counterpart at a ber of @xmath185 ; and it outperforms its block - code counterpart by @xmath177  db at a ber of @xmath186 when the number of decoding iterations increases to @xmath187 , i.e. , @xmath175 . as a result , when the number of decoding iterations is large , ldpccc is considered to be a better choice in terms of error performance .",
    "-bit quantization while and those of the ldpc block codes are obtained from computer simulations ( using c programming ) based on 4-bit quantized messages.,scaledwidth=50.0% ]",
    "the authors would like to thank the associate editor and the anonymous reviewers for their invaluable comments on the earlier version of this paper .",
    "an efficient partially parallel decoder architecture for qc - ldpccc has been proposed in this paper .",
    "the dedicated block processing unit is also proposed such that the complexity overhead of the switch network can be removed .",
    "rate-@xmath12 ldpccc decoders of different sub - matrix sizes have been implemented on an altera fpga with our proposed architecture .",
    "it is found that our decoders can achieve a throughput of @xmath13  gb / s .",
    "experimental results further show that qc - ldpcccs outperform their block - code counterparts under the same throughput and similar overall decoder complexity .",
    "moreover , the qc - ldpcccs derived from well - designed block codes can achieve an error floor of lower than @xmath0 .",
    "a.  jimenez  felstrom and k.  zigangirov , `` time - varying periodic convolutional codes with low - density parity - check matrix , '' _ information theory , ieee transactions on _ , vol .  45 , no .  6 , pp .",
    "21812191 , sept .",
    "1999 .",
    "a.  pusane , a.  feltstrom , a.  sridharan , m.  lentmaier , k.  zigangirov , and d.  costello , `` implementation aspects of ldpc convolutional codes , '' _ communications , ieee transactions on _ , vol .",
    "56 , no .  7 , pp .",
    "10601069 , july 2008 .",
    "t.  mizuochi , y.  konishi , y.  miyata , t.  inoue , k.  onohara , s.  kametani , t.  sugihara , k.  kubo , h.  yoshida , t.  kobayashi , and t.  ichikawa , `` experimental demonstration of concatenated ldpc and rs codes by fpgas emulation , '' _ ieee photonics technology letters _ ,",
    "21 , no .  18 , pp . 13021304 , july 2009 .",
    "i.  b. djordjevic , m.  arabaci , and l.  l. minkov , `` next generation fec for high - capacity communication in optical transport networks , '' _ journal of lightwave technology _ , vol .",
    "27 , no .",
    "35183530 , aug .",
    "2009 .",
    "m.  tavares , e.  matus , s.  kunze , and g.  fettweis , `` a dual - core programmable decoder for ldpc convolutional codes , '' in _ circuits and systems , 2008 .",
    "iscas 2008 .",
    "ieee international symposium on _ , may 2008 , pp .",
    "532535 .",
    "e.  matus , m.  tavares , m.  bimberg , and g.  fettweis , `` towards a gbit / s programmable decoder for ldpc convolutional codes , '' in _ circuits and systems , 2007 .",
    "iscas 2007 .",
    "ieee international symposium on _ , may 2007 , pp .",
    "16571660 .",
    "r.  swamy , s.  bates , t.  brandon , b.  cockburn , d.  elliott , j.  koob , and z.  chen , `` design and test of a 175-mb / s , rate-1/2 ( 128,3,6 ) low - density parity - check convolutional code encoder and decoder , '' _ solid - state circuits , ieee journal of _ , vol .  42 , no .  10 , pp . 22452256 , oct .",
    "s.  bates , z.  chen , l.  gunthorpe , a.  pusane , k.  zigangirov , and d.  costello , `` a low - cost serial decoder architecture for low - density parity - check convolutional codes , '' _ circuits and systems i : regular papers , ieee transactions on _ , vol .",
    "55 , no .  7 , pp . 19671976 , aug .",
    "s.  bates and g.  block , `` a memory - based architecture for fpga implementations of low - density parity - check convolutional decoders , '' in _ circuits and systems , 2005 .",
    "iscas 2005 .",
    "ieee international symposium on _ , may 2005 , pp .",
    "336  339 vol . 1 .    t.  brandon , j.  koob , l.  van den berg , z.  chen , a.  alimohammad , r.  swamy , j.  klaus , s.  bates , v.  gaudet , b.  cockburn , and d.  elliott , `` a compact 1.1-gb / s encoder and a memory - based 600-mb / s decoder for ldpc convolutional codes , '' _ circuits and systems i : regular papers , ieee transactions on _ , vol .  56 , no .  5 , pp .",
    "1017 1029 , may 2009 .",
    "z.  chen , t.  brandon , d.  elliott , s.  bates , w.  krzymien , and b.  cockburn , `` jointly designed architecture - aware ldpc convolutional codes and high - throughput parallel encoders / decoders , '' _ circuits and systems i : regular papers , ieee transactions on _ , vol .",
    "57 , no .  4 , pp . 836849 , apr . 2010 .",
    "z.  chen , s.  bates , and w.  krzymien , `` high throughput parallel decoder design for ldpc convolutional codes , '' in _ circuits and systems for communications , 2008 .",
    "iccsc 2008 .",
    "4th ieee international conference on _ , may 2008 , pp .",
    "35 39 .",
    "d.  l. donoho , a.  javanmard , and a.  montanari , `` information - theoretically optimal compressed sensing via spatial coupling and approximate message passing , '' _ computing research repository _ ,",
    "abs/1112.0708 , 2011 .",
    "chung , j.  g. forney , t.  j. richardson , and r.  urbanke , `` on the design of low - density parity - check codes within 0.0045 db of the shannon limit , '' _ communications letters , ieee _ , vol .  5 , no .  2 , pp .",
    "5860 , february 2001 .",
    "x.  chen , j.  kang , s.  lin , and v.  akella , `` memory system optimization for fpga - based implementation of quasi - cyclic ldpc codes decoders , '' _ circuits and systems i : regular papers , ieee transactions on _ , vol .",
    "58 , no .  1 , pp .",
    "98111 , jan .",
    "[ ] chiu - wing sham received the bachelor degree in computer engineering , and the m.phil .",
    "degree and the ph.d .",
    "degree from the chinese university of hong kong , hong kong , in 2000 , 2002 , and 2006 , respectively .",
    "he was a research engineer with synopsys , shanghai , china , and an electronic engineer working on the fpga applications of motion control system with asm ( hk ) .",
    "he joined the electronic and information engineering department of the hong kong polytechnic university , as a lecturer in august 2006 .",
    "his research interests include design automation of vlsi , design optimization of digital vlsi systems and embedded systems .",
    "[ ] xu chen received his b.e .",
    "degree from sun yat - sen ( zhongshan ) university , china in 2007 and his m.s .",
    "degree from purdue university , west lafayette in 2009 . from 2009 to 2011",
    ", he was a research assistant in the hong kong polytechnic university , hong kong .",
    "he is currently working towards the ph.d .",
    "degree at northwestern university , usa .",
    "his research interests include coding theory , optimization and cooperative communications .",
    "[ ] francis c.m .",
    "lau ( m93sm03 ) received the beng  ( hons ) degree in electrical and electronic engineering and the phd degree from king s college london , university of london , uk , in 1989 and 1993 , respectively . + he is a professor and associate head at the department of electronic and information engineering , the hong kong polytechnic university , hong kong .",
    "he is also a senior member of ieee .",
    "he is the co - author of _ chaos - based digital communication systems _",
    "( heidelberg : springer - verlag , 2003 ) and _ digital communications with chaos : multiple access techniques and performance evaluation _ ( oxford : elsevier , 2007 ) .",
    "he is also a co - holder of three us patents and one pending us patent .",
    "he has published over 230 papers .",
    "his main research interests include channel coding , cooperative networks , wireless sensor networks , chaos - based digital communications , applications of complex - network theories , and wireless communications . + he served as an associate editor for _ ieee transactions on circuits and systems ii _ in 20042005 and _ ieee transactions on circuits and systems i _ in 20062007 .",
    "he was also an associate editor of _ dynamics of continuous , discrete and impulsive systems , series b _ from 2004 to 2007 , a co - guest editor of _ circuits , systems and signal processing _ for the special issue `` applications of chaos in communications '' in 2005 , and an associate editor for ieice transactions ( special section on recent progress in nonlinear theory and its applications ) in 2011 .",
    "he has been a guest associate editor of _ international journal and bifurcation and chaos _ since 2010 and an associate editor of _ ieee circuits and systems magazine _ since 2012 .",
    "[ ] yue zhao yue zhao received the be degree in information engineering from shanghai jiaotong university , china in 2009 .",
    "he was a postgraduate student and research assistant at the hong kong polytechnic university , hong kong , from 2009 to 2012 , where he was working on algorithms and implementations for the ldpc decoding .",
    "he is currently working at the qualcomm research center , beijing , china .",
    "[ ] wai m.  tam received the b.sc .",
    "degree in electronics and information systems from jinan university , china , and the m.phil . and",
    "d. degree in electronic and information engineering from the hong kong polytechnic university , hong kong .",
    "+ she is currently a research fellow at the department of electronic and information engineering , the hong kong polytechnic university , hong kong .",
    "her research interests include channel coding , mobile cellular systems , complex networks and chaos - based digital communications ."
  ],
  "abstract_text": [
    "<S> this paper propose a decoder architecture for low - density parity - check convolutional code ( ldpccc ) . specifically , the ldpccc is derived from a quasi - cyclic ( qc ) ldpc block code . by making use of the quasi - cyclic structure </S>",
    "<S> , the proposed ldpccc decoder adopts a dynamic message storage in the memory and uses a simple address controller . </S>",
    "<S> the decoder efficiently combines the memories in the pipelining processors into a large memory block so as to take advantage of the data - width of the embedded memory in a modern field - programmable gate array ( fpga ) . </S>",
    "<S> a rate-5/6 qc - ldpccc has been implemented on an altera stratix fpga . </S>",
    "<S> it achieves up to 2.0 gb / s throughput with a clock frequency of 100 mhz . </S>",
    "<S> moreover , the decoder displays an excellent error performance of lower than @xmath0 at a bit - energy - to - noise - power - spectral - density ratio ( @xmath1 ) of 3.55 db .    </S>",
    "<S> decoder architecture , fpga implementation , ldpc convolutional code , qc - ldpc convolutional code </S>"
  ]
}