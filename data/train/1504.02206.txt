{
  "article_text": [
    "as a fundamental step in image processing , image segmentation partitions an image into several disjoint regions such that pixels in the same region share some uniform characteristics such as intensity , color , and texture . during the last two decades , image segmentation methods using variational methods and partial differential equations are very popular due to their flexibility in problem modeling and algorithm design .",
    "there are two key ingredients of variational segmentation models .",
    "one is how to describe the regions or boundaries between these regions , and the other is how to model the noise and describe the uniform characteristics of each region .",
    "the mumford - shah model  @xcite , a well - known variational segmentation model , penalizes the combination of the total length of the segmentation boundaries and the l2-norm error of approximating the observed image with an unknown piecewise smooth approximation . in other words",
    ", the mumford - shah model seeks an optimal piecewise smooth function with smooth boundaries to approximate the observed image .",
    "however , the mumford - shah model is hard to implement in practice because the discretization of the unknown set of boundaries is very complex .",
    "therefore , a parametric / explicit active contour method is used to represent the segmentation boundaries  @xcite .",
    "in addition , the special mumford - shah model with a piecewise constant approximation is studied by chan and vese  @xcite , and the level set method  @xcite is applied to solve this problem . using an implicit representation of boundaries , the level set method has many advantages over methods using explicit representations of boundaries .",
    "for instance , the level set method handles the topological change of zero level set automatically  @xcite .",
    "both the parametric / explicit active contour method and the level set method assume that each pixel belongs to a unique region .",
    "an alternative way to represent various regions is to use fuzzy membership functions  @xcite , which describe the levels of possible membership .",
    "fuzzy membership functions assume that each pixel can be in several regions simultaneously with probability in [ 0,1 ] .",
    "these probabilities satisfy two constraints : ( i ) nonnegativity constraint , i.e. , the membership functions are nonnegative at all pixels ; ( ii ) sum - to - one constraint , i.e. , the sum of all the membership functions at each pixel equals one",
    ". then the length of boundaries can be approximated by the total variation ( tv ) of fuzzy membership functions .",
    "the main advantages of using fuzzy membership functions over other methods include : i ) the energy functional is convex with respect to fuzzy membership functions , guaranteeing the convergence and stability of many numerical optimization methods .",
    "ii ) fuzzy membership function has a larger feasible set , and it is possible to find better segmentation results .    for two - phase segmentation , where there are only two regions , we only need one level set function or one fuzzy membership function .",
    "multiphase segmentation is more challenging than two - phase segmentation since more variables and constraints are involved in representing multiple regions and their boundaries effectively .",
    "the two - phase chan - vese model  @xcite has been generalized to multiphase segmentation by using multiple level set functions to represent multiple regions  @xcite .",
    "partitioning an image into @xmath0 disjoint regions requires @xmath1 level set functions .",
    "the advantage of using multiple level set functions is that it automatically avoids the problems of vacuum and overlap of regions .",
    "however , the implementation is not easy , and special numerical schemes are needed to ensure stability  @xcite . for fuzzy membership functions ,",
    "the sum - to - one constraint is not satisfied automatically in multiphase segmentation .",
    "however , this constraint is easy to deal with in many cases , e.g. , fuzzy c - mean ( fcm ) and its variants have closed - form solutions for the membership functions and are widely used in data mining and medical image segmentation  @xcite .",
    "variable splitting schemes are used in both  @xcite and  @xcite to get efficient numerical algorithms .",
    "the alternating direction method of multipliers ( admm ) method is used in  @xcite to derive the algorithm with two sets of extra variables .",
    "primal - dual type algorithm is derived in  @xcite to solve the tv regularized fcm segmentation model .",
    "both  @xcite and  @xcite use projection to simple to handle the constraints of membership functions .",
    "other segmentation approaches include a convex approach  @xcite , two - stage methods  @xcite , one single level set function approach  @xcite , et.al .",
    "noise is unavoidable in images , and it is important to develop segmentation methods that work on noisy images . among many types of noise , the gaussian white noise",
    "is frequently assumed , and the l2-norm fidelity is adopted .",
    "however , when images are corrupted by non - gaussian noise , in order to obtain a faithful segmentation , one has to model the noise according to its specific type  @xcite .",
    "particularly , the l1-norm fidelity is used for both salt - and - pepper impulse noise and random - valued impulse noise in image processing  @xcite .",
    "in addition , it is robust to outliers and able to preserve contrast because the denoising process of l1-norm models is determined by the geometry such as area and length rather than the contrast in the l2-norm case  @xcite .    inspired by the fact that l1-norm is more robust to impulse noise and outliers and can better preserve contrast , in this paper , we propose a variational _ multiphase _ fuzzy segmentation model based on _",
    "l1-norm fidelity _ and _ fuzzy membership functions_. this model can also deal with missing data in images .",
    "when there are missing pixels in an image , we randomly assign 0 or 255 at these pixels by considering these pixels as corrupted by salt - and - pepper impulse noise .",
    "admm  @xcite , which was rediscovered as split bregman  @xcite and found to be very useful for l1 and tv type optimization problems , is applied to solve this nonconvex optimization problem . by introducing two sets of auxiliary variables ,",
    "we derive an efficient algorithm with all the subproblems having closed - form solutions . in the theoretical aspect",
    ", we prove the existence of the minimizer and analyze the convergence of the algorithm .",
    "we note that the proposed method is closely related to the method in  @xcite since both methods use tv regularization and admm algorithm .",
    "the difference is that l1-norm fidelity is considered in the proposed method , while l2-norm fidelity is used in  @xcite .",
    "the outline of this paper is as follows . in section",
    "[ sec : preliminary ] , we review some closely related existing works . in section  [ sec : model ] , the proposed model is described in detail , and the existence of the minimizer to the model is proved . in section  [ sec : algorithm ] , a numerical algorithm is derived , and its convergence analysis is presented . in section  [ sec : experiment ] , experimental results and comparisons are presented to illustrate the effectiveness of the proposed method .",
    "finally , the paper is concluded in section  [ sec : conclusion ] .",
    "let @xmath2 be a bounded open subset with lipschitz boundary , and let @xmath3 be the given clean or noisy image .",
    "let @xmath4 for grayscale images and @xmath5 for color images .",
    "our goal is to find an @xmath0-phase `` optimal '' partition @xmath6 such that @xmath7 for all @xmath8 and @xmath9 .",
    "define the set of @xmath0-phase fuzzy membership functions as @xmath10 where @xmath11 is the space of functions with bounded variation  @xcite .",
    "the closely related works are listed in the following and will be compared with our proposed method in section  [ sec : experiment ] . for the sake of simplicity , we use the notations @xmath12 and @xmath13 , where @xmath14 for grayscale images and @xmath15 for color images .",
    "fcm  @xcite fuzzy c - means clustering method that solves @xmath16 using the alternating minimization algorithm .",
    "though @xmath17 can be any number no smaller than @xmath18 , it is commonly set to 2 .",
    "fcm_s2  @xcite  a variant of fcm that solves @xmath19 where @xmath20 is obtained by applying the median filter on @xmath21 and @xmath22 is a weight parameter .",
    "it can also be solved by the alternating minimization algorithm , and it is more robust to impulse noise than fcm .",
    "flicm  @xcite  fuzzy local information c - means clustering method that solves @xmath23 where @xmath24 is a neighborhood of @xmath25 .",
    "flicm is more robust to both gaussian noise and impulse noise than fcm .",
    "l2fs  @xcite  l2-norm fidelity based fuzzy segmentation method that solves @xmath26 by admm . here",
    "@xmath27 is a parameter and @xmath28 denotes the tv of @xmath29 with @xmath30 for @xmath31 . for fixed @xmath32 ,  @xcite",
    "is related to the popular tv denoising method  @xcite .",
    "note that the similar model is solved by other fast numerical methods in  @xcite .",
    "l1ss  @xcite  l1-norm fidelity based soft segmentation method , in which @xmath1 soft functions are introduced to represent @xmath0 phases . since the model for multiphase segmentation is complicated for more than four phases , we show the four - phase model as follows : @xmath33,\\mathbf{c}\\in\\mathbb{r}^{sn } } \\left\\{\\sum_{i=1}^2\\int_\\omega\\left\\|\\nabla u_i(x)\\right\\|dx + \\lambda\\sum_{j=1}^4\\int_\\omega \\left|i(x ) - c_j\\right|m_j(x)dx\\right\\},\\ ] ] where the membership functions @xmath34 , @xmath35 , are represented by soft functions @xmath36 $ ] in the following way :",
    "@xmath37    l2l0  @xcite  l2-norm fidelity and l0-norm regularization based image partition model :",
    "@xmath38 this model seeks a piecewise constant approximation of the original image @xmath21 . since this model can not specify the number of classes , a second step is applied to combine some classes if this model returns more classes than required . here",
    "we apply fcm on the piecewise constant approximation @xmath39 to obtain the final segmentation result .",
    "* remark : * there are two advantages of our proposed method over l1ss .",
    "firstly , we use fuzzy membership functions to represent regions , where @xmath0 fuzzy membership functions are required for an @xmath0-phase segmentation .",
    "hence , the solution space is much larger than l1ss , which ensures the higher possibility to obtain optimal segmentation .",
    "secondly , the proposed method can take use of other commonly used segmentation methods such as fcm to gain good initialization of fuzzy membership functions .",
    "multiphase segmentation is sensitive to initialization , and a good initialization is very important for a successful segmentation .",
    "however , it is hard to use the existing segmentation methods to get a good initialization for soft membership functions in l1ss .",
    "in this paper , we assume that the given image can be approximated by a piecewise constant function , i.e. , @xmath40 here @xmath41 denotes the indicator function of region @xmath42 , i.e. , @xmath43 @xmath44 is a constant that represents the given data in region @xmath42 , and @xmath45 can be outliers , impulse noise or other mixture types rather than gaussian noise .    instead of using the l2-norm fidelity to measure the approximation error",
    "when the noise is the gaussian white noise , we use the l1-norm fidelity .",
    "same as in the mumford - shah model , we require the segmentation boundaries to be smooth . then we have the following model @xmath46 where @xmath27 is a tuning parameter .",
    "note that the tv of @xmath41 in the first term is equal to the length of boundary @xmath47 .",
    "an equivalent form of model ( [ tvl1 ] ) is @xmath48 because @xmath41 can take values 0 and 1 only and @xmath49 is a partition , @xmath50 belongs to the set @xmath51 at any point @xmath52 , there is only one function having value 1 , and all the other functions have value 0 .",
    "thus set @xmath53 is not continuous , which leads to difficulties and instabilities in numerical implementations .",
    "however , we can relax binary indicator functions @xmath49 to fuzzy membership functions @xmath54 , which satisfy the nonnegativity constraint and the sum - to - one constraint , i.e. , @xmath55 belongs to the set @xmath56 defined in ( [ delta ] ) .",
    "it is obvious that @xmath57 $ ] and @xmath56 is a simplex at any @xmath52 .",
    "so @xmath58 can be understood as the probability of pixel @xmath25 to be in the @xmath59th class .",
    "then we can rewrite our model ( [ tvl12 ] ) as @xmath60 note that model ( [ tvfcml1 ] ) is convex with respect to @xmath61 and @xmath32 separately but not jointly .",
    "the difference between   and   is that the l2 fidelity term in   is replaced by the l1 fidelity term .",
    "the existence of a minimizer for @xmath62 in ( [ tvfcml1 ] ) is stated in theorem  [ minimizer ] .",
    "[ minimizer ] given an image @xmath63 , there exists a minimizer of @xmath62 in @xmath64 for any parameter @xmath27 .",
    "since @xmath65 is positive and proper , the infimum of @xmath65 must be finite .",
    "let us pick a minimizing sequence @xmath66 that satisfies @xmath67 as @xmath68 .",
    "then there exists a constant @xmath69 such that @xmath70 then each term in @xmath71 is bounded , i.e. , for each @xmath72 , @xmath73 since @xmath74 $ ] , we have @xmath75 , where @xmath76 is the area of @xmath77 . together with the first equality in ( [ tvisbound ] )",
    ", we have that @xmath78 is uniformly bounded in @xmath11 for all @xmath79 . by the compactness property of @xmath11 and the relative compactness of @xmath11 in @xmath80 , up to a subsequence also denoted by @xmath81 after relabeling ,",
    "there exists a function @xmath82 such that @xmath83 then by the lower semicontinuity of the tv semi - norm , @xmath84 meanwhile since @xmath85 , we have @xmath86 .    it is easy to derive the first order optimality condition about @xmath87 , which is @xmath88 where @xmath89 is the subdifferential of @xmath90 .",
    "since @xmath91 and @xmath92 , the above equation implies that the constant @xmath87 satisfies @xmath93 by the boundedness of sequence @xmath94 , we can extract a subsequence also denoted by @xmath94 such that for some constant @xmath95 @xmath96    finally , since @xmath97 , a.e . @xmath98 and @xmath99 as @xmath100 , fatou s lemma yields @xmath101 combining inequalities ( [ lsc1 ] ) and ( [ lsc3 ] ) for all @xmath59 , on a suitable subsequence , we established @xmath102 and hence @xmath103 must be a minimizer of the energy @xmath104 .",
    "this completes the proof .",
    "the minimizer of @xmath62 is not unique due to the following hidden symmetry property .",
    "denote @xmath105 as the permutation group of @xmath106 , i.e. , each permutation @xmath107 is defined as a one - to - one map @xmath108 such that @xmath109 is a rearrangement of @xmath106 .",
    "denote @xmath110 , @xmath111 .",
    "it is straightforward to show the following theorem .    for any @xmath112 and any @xmath107 , @xmath113 in particular",
    ", suppose that @xmath114 is a minimizer of @xmath62 , i.e. , @xmath115 then , for any @xmath107 , we have @xmath116",
    "in this section , we provide an efficient algorithm based on admm and discuss its convergence .",
    "admm is applied , in this subsection , to solve the proposed fuzzy segmentation model  .",
    "we introduce two sets of auxiliary variables @xmath117 such that @xmath118",
    ". then the model ( [ tvfcml1 ] ) is equivalent to the following minimization problem with equality constraints : @xmath119 where @xmath120 is the indicator function of the set @xmath56 , i.e. , @xmath121 the augmented lagrangian function for problem ( [ cons ] ) is :    @xmath122    where @xmath123 are the lagrangian multipliers and @xmath124 is a positive constant .",
    "here @xmath125 , and @xmath126 .",
    "the admm solves the primal variables one by one in the gauss - seidel style and then updates the dual variables ( lagrangian multipliers ) .",
    "it can be summarized as follows : @xmath127 in the following , we show how to solve each subproblem and then give the algorithm .      the subproblem for @xmath128 is equivalent to @xmath129 this is separable and the optimal solution of @xmath130 can be explicitly expressed using shrinkage operators .",
    "we simply compute @xmath131 where @xmath132 is the shrinkage operator defined as @xmath133 for the sake of simplicity , we denote this step as @xmath134      the subproblem for @xmath135 is equivalent to @xmath136 since @xmath56 is a convex simplex at any @xmath52 , the solution is given by @xmath137_{i=1}^n\\right),\\ ] ] where @xmath138 is the projection onto the simplex @xmath56 , for which more details can be found in  @xcite .",
    "we denote the step as @xmath139      the subproblem for @xmath32 is @xmath140 it is separable , and @xmath141 can be solved independently .",
    "the optimality condition for each @xmath141 is @xmath142 because the right - hand side of   is maximal monotone  @xcite , the bisection method and admm are applied to solve it  @xcite .",
    "the next lemma provides a new way to find an optimal solution for discrete cases .",
    "[ lemma1 ] given a finite non - decreasing sequence @xmath143}\\}_{j=1}^n$ ] , i.e. , @xmath144}\\le i_{[2]}\\le ... \\le i_{[n]},\\ ] ] and a non - negative sequence @xmath145}\\}_{j=1}^n$ ] with @xmath146}>0 $ ] , the optimal solution set for @xmath147}-c\\right|w_{[j]},\\ ] ] is @xmath148},i_{[j_*+1]}]\\right]$ ] , where @xmath149 and @xmath150 satisfy @xmath151}\\leq 0 < a-2\\sum_{j=1}^{j^*-1}{w}_{[j]},\\\\ a-2\\sum_{j=1}^{j_*+1}{w}_{[j]}<0\\leq a-2\\sum_{j=1}^{j_*}{w}_{[j]}.\\end{aligned}\\ ] ] the fuzzy median of @xmath152 with respect to the weight @xmath145}\\}_{j=1}^n$ ]  @xcite , which is defined as @xmath153}+i_{[j_*+1]}])/2 $ ] , is an optimal solution .",
    "if , in addition , there exists @xmath149 such that @xmath151 } < 0 < a-2\\sum_{j=1}^{j^*-1}{w}_{[j]},\\end{aligned}\\ ] ] then @xmath154 , and the optimal solution is unique",
    ".    the optimality condition of   is @xmath155}-c|{{w_{[j]}}}.\\ ] ] we can see that @xmath156 is non - increasing and it can be expressed as @xmath157},\\\\ { [ a-2{w}_{[1]},a ] } , & c = i_{[1]},\\\\ a-2{w}_{[1 ] } , & c\\in ( i_{[1]},i_{[2 ] } ) , \\\\",
    "\\cdots&\\\\ { [ a-2\\sum_{j=1}^s{w}_{[j]},a-2\\sum_{j=1}^{s-1}{w}_{[j ] } ] } , & c = i_{[s]},\\\\ a-2\\sum_{j=1}^s{w}_{[j ] } , & c_i\\in ( i_{[s]},i_{[s+1 ] } ) , \\\\ \\cdots & \\\\ -a , & c > i_{[n]}.\\\\",
    "\\end{array}\\right.\\end{aligned}\\ ] ] the range of @xmath158 is @xmath159 $ ] , and @xmath156 can take multiple values when @xmath160}$ ] for any @xmath161 with @xmath162}\\neq0 $ ] .",
    "therefore , we can always find @xmath149 such that @xmath151}\\leq 0<a-2\\sum_{j=1}^{j^*-1}{w}_{[j]}.\\end{aligned}\\ ] ] thus @xmath163})=\\left[a-2\\sum_{j=1}^{j^*}{w}_{[j]},a-2\\sum_{j=1}^{j^*-1}{w}_{[j]}\\right]$ ] , and @xmath164}$ ] is an optimal solution .",
    "in addition , we have that @xmath165 when @xmath166}$ ] .",
    "similarly , we can find @xmath150 such that @xmath167}<0\\leq a-2\\sum_{j=1}^{j_*}{w}_{[j]},\\end{aligned}\\ ] ] and @xmath168}$ ] is an optimal solution .",
    "in addition , we have that @xmath169 when @xmath170}$ ]",
    ". then @xmath156 being non - increasing gives us that the set of optimal solutions for   is @xmath148},i_{[j_*+1]}\\right]$ ] .",
    "when @xmath171 , the optimal solution is unique .",
    "* remark : * when there are missing pixels in images , we can put a mask on the data fidelity term as in image inpainting problems  @xcite or assign a value to each missing pixel . in  @xcite , the missing pixels are assigned with zero , and @xmath32 changes based on the percentage of missing pixels . while , this lemma tells us that assigning 0 or 255 ( for grayscale images ) randomly to these missing pixels will not change the value of @xmath172 with a high probability because @xmath44 is a weighted median . also , by assigning 0 or 255 randomly , this algorithm is able to deal with cases where more than half of the pixels are missing .",
    "see the numerical experiments in section  [ sec : experiment ] .",
    "assume that @xmath21 and @xmath173 are vectors in @xmath174 , where @xmath45 is the total number of pixels .",
    "we can reorder the components of @xmath21 and @xmath175 such that the monotonicity of @xmath21 in lemma  [ lemma1 ] is satisfied .",
    "if there are multiple optimal solutions for @xmath44 , we choose the smallest one .",
    "we denote this step as @xmath176      the subproblem for @xmath61 is equivalent to @xmath177 it is separable for @xmath178 , and , from the following first order optimality condition for each @xmath178 : @xmath179 we can derive the closed - form solution of @xmath178 from the equation : @xmath180 a diagonalization trick can be applied to find @xmath178 efficiently  @xcite .",
    "we denote this step as @xmath181    * updating dual variables . * we denote the steps as @xmath182    combining all these steps together , we obtain the proposed l1 fuzzy segmentation algorithm ( l1fs ) in algorithm 1 for solving  .",
    "* initialization : @xmath183 and @xmath184 , @xmath185 . * for @xmath186 , repeat until the stopping criterion is reached . @xmath187 * output : @xmath188 .",
    "+    * remark : * though there are four variables @xmath189 , @xmath190 , @xmath191 and @xmath192 , they can be grouped into two variables @xmath193 and @xmath194 and the subproblems for these two variables can be decoupled into the four subproblems .",
    "so it is essentially a two block admm applied on a nonconvex optimization problem .    because problem   is nonconvex , a good initial guess of @xmath183 and @xmath184 , which can be obtained from other methods using fuzzy membership functions , is helpful for the stability of l1fs .",
    "thus we update @xmath195 and @xmath196 first because both of them can use the initial guess of @xmath197 .      if @xmath191 is given , problem   is convex .",
    "then , the algorithm is a standard admm by considering @xmath193 together , and its convergence is guaranteed  @xcite . in this section ,",
    "we give a convergence result of algorithm 1 for unknown @xmath191 .",
    "to simplify notations , let us define the sextuples : @xmath198a point @xmath199 is a kkt point of ( [ cons ] ) if it satisfies the following kkt conditions :    @xmath200    where @xmath201 and @xmath202 are subdifferentials of @xmath203 and @xmath204 , respectively .",
    "[ conkkt ] let @xmath205 be a sequence generated by algorithm 1 that satisfies the condition @xmath206 then any accumulation point of @xmath205 is a kkt point of problem ( [ cons ] ) .",
    "consequently , any accumulation point of @xmath207 is a stationary point of problem ( [ tvfcml1 ] ) .    from the updating formulas in algorithm 1 , we obtain the following inequalities related to the subsequent iteration :    [ difall ] @xmath208    by the assumption @xmath209 , the left - hand side and right - hand side of each equality in   go to zero as @xmath210",
    ". then we have    [ limall ] @xmath211    assume @xmath212 is an accumulation point of @xmath213 .",
    "gives us    @xmath214    by ( [ limm1 ] ) , it follows that @xmath215 is a solution of the minimization problem @xmath216 thus @xmath217 satisfies the first order optimality condition @xmath218 using ( [ limm5 ] ) , we simplify the above condition as @xmath219 by ( [ limm2 ] ) , @xmath220 is a solution of the following minimization problem : @xmath221 hence @xmath220 satisfies the optimality condition @xmath222 together with the equality in ( [ limm6 ] ) , the above equation can be simplified as @xmath223 the equation ( [ limm3 ] ) implies that @xmath224 is a solution of the minimization problem @xmath225 and the optimal condition is @xmath226    the equivalence of equations ( [ limm1])-([limm3 ] ) with ( [ limmm3])-([limmm2 ] ) , together with equations ( [ limm4])-([limm6 ] ) shows that the accumulation point @xmath227 satisfies the kkt condition in equations ( [ kkt1])-([kkt2 ] ) , thus @xmath227 is a kkt point of problem ( [ cons ] ) .    since problem ( [ cons ] ) and problem ( [ tvfcml1 ] ) are equivalent , the convergence of @xmath207 in the statement follows directly .",
    "the convergence analysis is motivated by  @xcite .",
    "this theorem implies that whenever @xmath205 converges , it converges to a kkt point of problem ( [ cons ] ) .",
    "however , since the minimization problem ( [ cons ] ) is nonconvex , the kkt point is not necessary to be an optimal solution .",
    "in order to demonstrate the effectiveness of the proposed method , we compare our method with some existing methods on both synthetic and real images .",
    "these methods ( fcm , fcm_s2 , flicm , l2fs , l2l0 , and l1ss ) are discussed in section  [ sec : preliminary ] .",
    "since the segmentation models in these methods are not jointly convex , and they are easy to get stuck in local minima , `` good '' initialization is crucial for all algorithms , especially when the given image is noisy . for fcm , fcm_s2 , and flicm , the initial @xmath61 is uniformly distributed in @xmath228 $ ] and normalized to satisfy the sum - to - one constraint . while for tv based methods l2fs and l1fs , one can also use the results of fcm and fcm_s2 as the initial @xmath61 and @xmath32 . here",
    "we consider three ways for choosing the initial @xmath61 and @xmath32 : the result of fcm , the result of fcm_s2 , and @xmath61 as functions uniformly distributed in @xmath228 $ ] and @xmath32 as the result of fcm . in all the experiments",
    ", we choose the one with the highest performance among all the three initializations .",
    "for l1ss , we use the initialization method as described in the original paper . the stopping criterion , which is the same for all the methods except l1ss , is defined as @xmath229 where @xmath230 is a very small number . for l1ss , this stopping criterion does not work since l1ss leads to contrast loss due to the error in calculating class centers @xmath231 at early iterations .",
    "however , the contrast of l1ss will be enhanced gradually if the number of iterations increases . to gain satisfactory results , we choose to stop l1ss by setting the maximum number of iterations to be 1000 .",
    "the parameters of the methods being compared are set as follows . in fcm , we set @xmath232 . in fcm_s2",
    ", we set @xmath233 , and the window size for the median filter as @xmath234 . in flicm",
    ", we set @xmath232 and the window size of the neighborhoods as @xmath235 or @xmath236 , which depends on the noise level .",
    "however , the weight parameter @xmath237 for l2fs , l1ss , and l1fs are tuned for each experiment to achieve optimal results . in all experiments ,",
    "the range of @xmath237 for l2fs is @xmath238 $ ] , for l1ss is @xmath239 $ ] , and for l1fs is @xmath240 $ ] .",
    "for all methods , @xmath241 for the two - phase segmentation and @xmath242 for the multiphase segmentation .",
    "we use the default parameters in l2l0 except that we set @xmath243 .",
    "the clustering results of all methods are obtained by checking the maximum value of their membership functions .",
    "then we display the recovered piecewise constant image as the final result .",
    "to compare segmentation results quantitatively , we consider the segmentation accuracy ( sa ) defined by @xmath244    the synthetic piecewise constant test images are displayed in fig .",
    "[ fig:1 ] .",
    "the noisy images are contaminated by three types of noise : gaussian noise ( gn ) with zero mean and standard deviation varying from 10 to 80 , salt - and - pepper impulse noise ( spin ) with 10% to 60% pixels contaminated , and random - valued impulse noise ( rvin ) with 10% and 60% pixels contaminated .",
    "[ fig:2c ] +     +     +    tab .",
    "[ tab:1 ] provides the sa comparison of these six algorithms , and figs .",
    "[ fig:2]-[fig:4 ] show some of the corresponding results . for gn ,",
    "all methods being tested give correct segmentation results for small standard deviations ( e.g. , @xmath245 ) . as the standard deviation increases",
    ", the sa value of fcm decays very fast .",
    "all the other algorithms have very large sa values even when the standard deviation is @xmath246 .",
    "l1fs has the best performance for all cases , and it is able to give correct segmentation results even when @xmath247 .",
    "l2fs is the second best algorithm , and it is able to give correct segmentation results when @xmath248 .    the results of all methods when @xmath249 and @xmath250 are displayed in fig .",
    "[ fig:2 ] .",
    "the results of fcm are relatively `` noisy '' ( the second column ) . for flicm ( the third column ) and l1ss ( the fifth column ) , the segmentation error occurs on the middle edge .    for spin , tab .",
    "[ tab:1 ] shows that flicm performs much better than fcm for noise levels 10%-30% .",
    "however , if the noise level is higher than 30% , both fcm and flicm have very poor performance .",
    "l1ss achieves much better performance than flicm , even when the noise level is higher than 30% .",
    "l2fs is slightly better than l1ss .",
    "meanwhile , if the noise level is higher than 50% , l1ss fails to give a satisfactory result .",
    "l1fs has the highest sa among all methods .",
    "it gives completely correct segmentation results for noise levels 10%-50% .",
    "[ fig:3 ] shows the results of all methods for noise levels 20% and 40% , respectively . for l2fs and l1ss",
    ", the segmentation errors occur along the middle edge .",
    "we also observe that for high noise levels such as 40% , both l2fs and l1ss suffer from slight contrast loss , e.g. , fig .",
    "[ fig:3j ] and fig .",
    "[ fig:3k ] .",
    "however , l1fs is still able to preserve contrast , e.g. , fig .",
    "[ fig:3f ] and fig .  [ fig:3l ] .    for rvin",
    ", fcm_s2 is used to initialize @xmath61 and @xmath32 for tv based methods l2fs and l1fs .",
    "[ tab:1 ] shows that fcm_s2 has the worst performance among all .",
    "l1ss is much better than fcm_s2 especially for high noise levels .",
    "flicm performs slightly better than fcm_s2 .",
    "l1fs achieves the best performance which is slightly better than l2fs .",
    "l2fs gives correct segmentation results at noise levels 10%-30% , while our method l1fs can give the correct segmentation results at noise levels 10%-50% .",
    "[ fig:4 ] shows the results for noise levels 20% and 40% .",
    "again , we find that most of the errors occur along the middle edge for flicm and l1ss .",
    "moreover , the results of l2fs in fig .",
    "[ fig:4j ] , l1ss in fig .",
    "[ fig:4e ] and fig .",
    "[ fig:4k ] lose some contrast .",
    "next we analyze the contrast problem for tv based methods . for l2fs ,",
    "the estimated intensity @xmath44 in each segmented region roughly equals the mean value of the intensities in that region . in the gaussian noise case ,",
    "the noise has zero mean and therefore it has almost no impact on the estimation of @xmath44 .",
    "however , for both impulse noise cases , the noise has a significant influence on the estimation of @xmath44 by taking the average . more specifically , assuming that the impulse noise follows the uniform distribution , its impact on the estimation of @xmath44 is like this .",
    "given an image with intensity range @xmath251 $ ] , for the region @xmath42 with true intensity @xmath252 , if there are more noisy pixels with intensity greater than @xmath253 than those with intensity less than @xmath253 , then @xmath254 after taking the average and vice versa .",
    "hence , the range of the image will be shrunk by applying l2fs even when the segmentation is correct , and thereby the recovered image will suffer from contrast loss . note that the contrast loss problem has also been reported for the tvl2 restoration model in impulse noise removal  @xcite . for l1ss algorithm ,",
    "one step of admm is used to solve the @xmath191-subproblem approximately .",
    "thus @xmath44 is not accurate for the first few iterations .",
    "however , since l1ss uses the l1-norm fidelity , the loss of contrast becomes more and more subtle as the number of iterations increases . in l1fs",
    ", we solve the @xmath32-subproblem exactly .",
    "thus , l1fs can preserve contrast well in the segmentation process .     +   +   +      the performance comparison for the multiphase synthetic piecewise constant gray image fig .",
    "[ fig:1b ] is shown in tab .",
    "[ tab:2 ] and fig .",
    "[ fig:5 ] .    as shown in tab .",
    "[ tab:2 ] , fcm performs poorly for gn , while l2fs and l1fs perform relatively well with similar sa . for the noise level @xmath245 , both l2fs and",
    "l1fs give a correct segmentation result . for spin",
    ", fcm also gives the worst performance in terms of sa , while l1fs achieves the best performance .",
    "l2fs fails to yield a correct segmentation result when noise levels @xmath255 . for rvin",
    ", fcm_s2 achieves high sa values since it can smooth out some noise in the segmentation process .",
    "l2fs performs much better than fcm_s2 , and l1fs performs the best among all methods .    fig .",
    "[ fig:5 ] shows some results corresponding to tab.[tab:2 ] .",
    "the first row is the noisy images being tested .",
    "the second row shows the results of fcm ( fig .",
    "[ fig:5g]-[fig:5j ] ) and fcm_s2 ( fig .",
    "[ fig:5k]-[fig:5l ] ) .",
    "most of them looks very `` noisy '' except fig .",
    "[ fig:5k ] .",
    "l2fs and l1fs give very clean results in the third row and last row , respectively .",
    "comparing the results by l2fs and l1fs for gaussian noise , both of them have high visual qualities .",
    "however , for spin and rvin , it is obvious that l1fs preserves the contrast much better than l2fs and has better segmentation results .",
    "+   +   +   +    in tab .",
    "[ tab:3 ] and fig .",
    "[ fig:6 ] , we test the multiphase synthetic piecewise constant color image fig .",
    "[ fig:1c ] with various levels of gn , spin , and rvin .    from tab .",
    "[ tab:3 ] , in the gn case , when the standard deviation of noise @xmath256 , all the four methods , including fcm , l2fs , l2l0 and l1fs , give correct segmentation results .",
    "moreover , both l2fs and l1fs yield correct segmentation results when @xmath257 .",
    "when @xmath255 , the performance of fcm decreases rapidly , while l2fs , l2l0 , and l1fs still achieve very large sa values .",
    "note that we initialize @xmath61 randomly for gn in this test . for spin and rvin",
    ", fcm has the worst performance which is far lower than that of the other three methods .",
    "it is also obvious that l1fs outperforms l2l0 and l2fs .",
    "[ fig:6 ] shows some results corresponding to tab .",
    "[ tab:3 ] .",
    "the first row shows the tested noisy images .",
    "the results of fcm in the second row seems to be `` noisy '' in most cases .",
    "the results of l2fs ( the third row ) , l2l0 ( the fourth row ) , and l1fs ( the last row ) are very clean . however , in terms of contrast , it is obvious that l1fs outperforms l2l0 and l2fs particularly for spin and rvin .",
    "we test some real images including two medical images and six natural images in fig .",
    "[ fig:7 ] without artificial noise .",
    "however , the images can be regarded as containing some types of noise due to the acquisition and transmission processes .",
    "the results of fcm and l1fs are displayed for comparison .",
    "one can see that fcm tends to produce some tiny components and irregular segmentation boundaries .",
    "by contrast , l1fs tends to smooth out tiny components to generate large ones and smooth boundaries between regions , which is more natural for human vision system and good for postprocessing .",
    "this smoothing effect is mainly achieved by total variation regularization in the l1fs model . moreover , l1fs preserves slightly better contrast in the piecewise constant approximation than fcm , which is mainly achieved by the use of the l1-norm fidelity .    in figs .",
    "[ fig:7d]-[fig:7f ] , fcm and l1fs give quite different segmentation results .",
    "obviously , fcm fails to segment the blue color part of the clothes in the original image , while the proposed l1fs works well . to illustrate the difference of these two methods , we display , in fig",
    "[ fig:8 ] , the corresponding six segmented regions of fcm and l1fs for the women image fig .",
    "[ fig:7d ] , respectively .",
    "we find that the segmented regions of fcm in fig .",
    "[ fig:8a]-[fig:8e ] are somehow `` noisy '' . in particular ,",
    "the background lattice pattern is partitioned into five regions as shown in fig .",
    "[ fig:8a]-[fig:8e ] . compared with fcm",
    ", the proposed l1fs gives quite clean segmented regions in the second row in fig .",
    "[ fig:8 ] . especially , the background lattice pattern are classified into only two classes as shown in fig .  [ fig:8g]-[fig:8h ] .",
    "we further compare the blue parts of the clothes corresponding to fig .",
    "[ fig:8c ] and fig .",
    "[ fig:8i ] . in fig .",
    "[ fig:8c ] , some background pattern heavily affects the estimation of @xmath32 , and therefore the color is not blue any more . however , in fig .",
    "[ fig:8i ] , since the background is clean , the correct color can be obtained . to sum up , fig .",
    "[ fig:8 ] demonstrates that the proposed l1fs gives smoother segmentations than fcm .",
    "[ real ]     +   +   +    [ cluster ]     +",
    "this paper presents a novel piecewise constant image segmentation model based on fuzzy membership functions and l1-norm fidelity .",
    "admm is applied to derive an efficient numerical algorithm , in which each subproblem has a closed - form solution . in particular ,",
    "an efficient algorithm is proposed to find the fuzzy median .",
    "the numerical results on both synthetic and real piecewise constant images demonstrate that the proposed method is superior to some existing state - of - the - art methods since it is more robust to impulse noise and can preserve better contrast . even in the case of gaussian noise ,",
    "the proposed method can achieve similar results as its l2-fidelity counterpart . in this work",
    ", we assume that the image to be dealt with is piecewise constant , which works well on images with homogeneous image features . the future work is to extend this framework to piecewise smooth image segmentation .",
    "the research of f. li was supported by the 973 program 2011cb707104 , the research of s. osher and j. qin was supported by onr grants n00014120838 and n00014140444 , nsf grants dms-1118971 and ccf-0926127 , and the keck foundation , the research of m. yan was supported by nsf grants dms-1317602 .",
    "the work was done when the first author was visiting ucla department of mathematics .",
    "roland glowinski and a  marroco .",
    "sur lapproximation , par lments finis dordre un , et la rsolution , par pnalisation - dualit dune classe de problmes de dirichlet non linaires .",
    ", 9(r2):4176 , 1975 .",
    "yanyan he , m  yousuff  hussaini , jianwei ma , behrang shafei , and gabriele steidl .",
    "a new fuzzy c - means method with total variation regularization for segmentation of images with noisy and incomplete data .",
    ", 45(9):34633471 , 2012 .",
    "nawal houhou , j  thiran , and xavier bresson .",
    "fast texture segmentation model based on the shape operator and active contour . in _ computer vision and pattern recognition , 2008 .",
    "cvpr 2008 .",
    "ieee conference on _ , pages 18 .",
    "ieee , 2008 ."
  ],
  "abstract_text": [
    "<S> in this paper , we propose a variational multiphase image segmentation model based on fuzzy membership functions and l1-norm fidelity . </S>",
    "<S> then we apply the alternating direction method of multipliers to solve an equivalent problem . </S>",
    "<S> all the subproblems can be solved efficiently . </S>",
    "<S> specifically , we propose a fast method to calculate the fuzzy median . </S>",
    "<S> experimental results and comparisons show that the l1-norm based method is more robust to outliers such as impulse noise and keeps better contrast than its l2-norm counterpart . </S>",
    "<S> theoretically , we prove the existence of the minimizer and analyze the convergence of the algorithm . </S>"
  ]
}