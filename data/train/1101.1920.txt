{
  "article_text": [
    "cognitive channel is a special case of an interference channel in which the second transmitter has complete and non - causal knowledge of the messages and codewords of the first transmitter .",
    "this channel can be used to model an ideal operating scenario for cognitive radios , a device that can sense and adapt to the environment intelligently in coexistence with primary users .",
    "fundamental limits of such a communication channel are of interest .",
    "achievable rates of the cognitive channel was first obtained in @xcite by merging gelfand - pinsker coding with the well - known han - kobayashi encoding @xcite for the interference channel . at low interference , the capacity region of this channel in the gaussian case",
    "has recently been established by @xcite and @xcite independently .",
    "while the former considers the gaussian channel only , the latter studies the general discrete memoryless channel case , also called the interference channel with degraded message set ( ic - dms ) .",
    "cognitive channel capacity is also known for very strong interference , when both receivers can decode both messages @xcite . at medium interference ,",
    "the capacity is still an open problem , with some achievable rate regions presented in @xcite , @xcite , and @xcite .",
    "the z - interference channel ( zic ) is an interference channel in which only one receiver suffers from interference .",
    "its capacity is also unknown even for the gaussian channel , except for some special cases . from the capacity perspective , it is not important which transmitter interferes with the other in the zic . in a cognitive zic , however , due to asymmetric transmitters , two different zic are conceivable .",
    "one is with interference from the cognitive transmitter to the primary receiver , and the other from the primary transmitter to the cognitive receiver .",
    "while achievable rate regions for the first one have been studied recently in @xcite , @xcite , there has not been such an investigation for the second one .    in this paper , we study the cognitive channel in general and apply the results to the gaussian cognitive zic ( gczic ) in which the cognitive transmitter interferes with the primary receiver .",
    "the contribution can be summarized as follows .",
    "first , we introduce a new discrete memoryless cognitive interference channel ( dm - cic ) in which the primary receiver is more capable than the secondary receiver .",
    "we term it the more capable dm - cic . then , using superposition coding , we establish inner and outer bound on its capacity .",
    "we also define a strong interference condition and show that the proposed outer bound holds under this condition also . implicitly , both inner and outer bounds are also valid for cognitive z - interference channel that the interfered receiver is more capable than the other receiver .",
    "second , we show that at strong interference ( @xmath4 ) , where @xmath1 is the gain of interference link from secondary user to primary receiver , the outer bound is applicable to the gaussian cic , and thus to the gczic .",
    "then we prove that in gaussian noise channel , jointly gaussian distribution is the optimum distribution for this outer bound ; and therefore , we are able to compute this outer bound for the gczic . the outer bound",
    "is proven to be the best outer bound for the gczic at strong interference .",
    "finally , we derive the gaussian version of the achievable rate region and prove that when interference is highly strong , i.e. , @xmath3 , the inner and outer bounds coincide .",
    "thus , we establish the capacity region of the gczic at this range , and show that superposition coding is the capacity achieving scheme .",
    "for such a large @xmath1 , superposition encoding at the cognitive transmitter and successive decoding at the primary receiver are capacity - achieving .",
    "the rest of paper is organized as follows . in section",
    "[ sec : models ] , we discuss models for the gaussian cognitive interference channel and the gczic as well as the existing capacity result for this channel at @xmath5",
    ". we also introduce the more capable dm - cic in this section . in section [ sec : dm - czic ] , we provide new inner and outer bounds on the capacity region of the dm - cic .",
    "then in section [ sec : cap ] , we show that for @xmath4 we can apply the introduced inner and outer bounds to the gczic ; and , we compute these bounds for this range . for @xmath6 , we prove the outer bound is equal to the proposed achievable region ; and thus , establish the capacity of the gczic .",
    "section [ sec : sum ] concludes the paper .",
    "the classical interference channel ( ic ) consists of two independent , non - cooperating pairs of transmitter and receiver , both communicating over the same channel and interfering each other .",
    "a special case of the ic is the cognitive ic , also called an ic with degraded message sets ( ic - dms ) , in which a transmitter , the cognitive one , has non - causal knowledge of the messages and codewords to be transmitted by the other transmitter , the primary one . in this section",
    "we formally define this channel and some other derivative of that .",
    "consider the discrete memoryless cognitive interference channel ( dm - cic ) , also termed the discrete memoryless interference channel with degraded message sets ( ic - dms ) , depicted in figure [ fig : dm - czic ] , where sender 1 wishes to transmit message @xmath7 to receiver 1 and sender 2 wishes to transmit message @xmath8 to receiver 2 .",
    "message @xmath8 is available only at sender 2 , while both senders know @xmath7 .",
    "this channel is defined by a tuple @xmath9 where two inputs @xmath10 , and two outputs @xmath11 are related by a collection of conditional probability density functions @xmath12 .",
    "the discrete memoryless cognitive z - interference channel ( dm - czic ) is a dm - cic in which interference is one sided .",
    "more specifically , we consider the case where the primary user does not interfere the secondary one .",
    "this only affects the channel transition matrix .",
    "thus , the dm - czic with two private messages @xmath13 , for the two receivers , two inputs @xmath14 , and two outputs @xmath15 is a dm - cic in which @xmath16 for all @xmath17 .",
    "the dm - cic is said to be more capable if @xmath18 for all @xmath17 .    since the second transmitter can encode and broadcast both messages , in the absence of the first transmitter this channel reduces to the well - known more capable dm - bc . in the presence of first sender ,",
    "this channel is no longer a bc but an interference channel ( ic ) .",
    "however , due to cognition , the second transmitter has complete and non - causal knowledge of both messages and codewords ; thus , it can act similarly to the bc s transmitter .",
    "this observation motivated us to define a condition similar to the one that makes one receiver more capable than the other one in a dm - bc .",
    "we also define another condition to identify that primary receiver is in a better situation than secondary receiver in receiving the signal of cognitive user .",
    "we name this strong cognitive inference condition , as it indicates , roughly speaking , the interference link from cognitive user to primary reciter is stronger the direct link of cognitive sender to its corresponding receiver .",
    "the dm - cic is under strong cognitive interference if @xmath19 for all @xmath17 .",
    "note that in general neither of these two definitions and implies the other one .      without loss of generality , we use the standard form of the gaussian interference channel @xcite , @xcite , in which the gains of both direct links are 1 and both noises are independent with unit variance . the standard gaussian cognitive interference channel is shown in figure [ fig : standardic ] and is expressed as @xmath20 here the interference links are arbitrary constants @xmath1 and @xmath21 known at all the transmitters and receivers ; @xmath22 represent the primary and secondary users transmit signals , and @xmath23 their received signals ; @xmath24 are independent additive noises @xmath25 ( @xmath26 ) .",
    "we also assume that transmitted signals are subject to average power constraint as @xmath27 \\leq p_{1 } $ ] and @xmath28 \\leq p_{2 } $ ] .",
    "depending on the values of the interference links @xmath1 and @xmath21 , different classes of ic emerge .",
    "a special class is the z - interference channel ( zic ) when either @xmath29 or @xmath30 . for a non - cognitive system",
    ", there is no difference in the capacity analysis of these two zics . in a cognitive system , however , due to asymmetric knowledge at the transmitters , two different cognitive zics are conceivable .",
    "one is when the primary receiver has no interference ( @xmath29 ) , and the other is when the secondary receiver has no interference ( @xmath30 ) .",
    "these two gczic channels have completely different capacity regions .    the capacity of the gczic with @xmath31 can be simply obtained from the well - known result of dirty paper coding by costa @xcite .",
    "achievable rate and capacity regions of this cognitive zic for the discrete memoryless case can also be found in @xcite .",
    "on the other hand , to the best of our knowledge , not much work has been done on the second gczic ( with @xmath30 ) . in this paper , we investigate the capacity region for this gczic with @xmath30 . in the rest of this paper , gczic refers to this channel .    in the following sections",
    ", we establish an inner bound and an outer bound for the dm - cic satisfying either or .",
    "these bounds are valid for the dm - czic as well .",
    "later , we will use these bounds to prove the capacity of the gczic with very strong interference .",
    "in the first part of this section , we derive an achievable rate region for the dm - cic . in the second part , we introduce a new outer bound on the capacity of the more capable dm - cic which is valid for dm - cic with strong interference also . since the more capable dm - cic is an extension of the more capable dm - bc , the achievable region also is an extension of its component s capacity region .",
    "the technique used for achievability is the same as capacity achieving technique for the conventional more capable dm - bc .",
    "in addition , the outer bound also resembles that of the more capable dm - bc .",
    "similarly , achievability , error analysis , and the proof of converse ( outer bound ) follow those of the dm - bc",
    ". nevertheless , in general the inner bound and the outer bound are not equal in the more capable dm - cic while they are proven to be the same for the more capable dm - bc .",
    "indeed , this difference , which will be addressed later in this section , prevents establishing capacity region for the more capable dm - cic .",
    "theorem 1 provides an achievable region for the dm - cic .",
    "the achievable technique uses superposition encoding at the cognitive transmitter .",
    "the decoding is based on the joint typicality .",
    "an achievable rate region for the dm - cic consist of all rate pairs @xmath32 that satisfy @xmath33 for some joint distributions that factors as @xmath34 , where @xmath35 is a function which can be random or deterministic .",
    "[ thm1 ]    the proof uses the superposition coding idea in which @xmath36 can only decode @xmath8 ( the cloud center ) while @xmath37 is intended to decode the satellite codeword . for completeness",
    "we provide the proof in the appendix a.      inspired by capacity of more capable bc @xcite , @xcite , instead of proving the outer bound for region , we prove it for the slightly altered rate region below .",
    "the following outer bound on the capacity holds both for the more capable dm - cic and dm - cic with strong interference .",
    "the union of all rate pairs @xmath32 such that @xmath38 for some joint distributions @xmath39 constitutes an outer bound on the capacity region of a dm - cic satisfying either the more capable condition in or strong interference condition in .",
    "[ thm2 ]    the proof is based on the proof of converse for the more capable bc in @xcite but adapted for the dm - cic . for completeness , we provide the proof in the appendix b. in the bc , this new form is shown to be an alternative representation of the rate region in theorem [ thm1 ] @xcite ; thus , proving the converse for this equivalent region establishes the capacity of the more capable bc .",
    "however , these two regions are not equivalent for dm - cic because of different input distributions .",
    "therefore , theorem [ thm2 ] provides only an outer bound for the capacity of the more capable dm - cic and dm - czic .",
    "nevertheless , later in this paper we show that this outer bound is tight for the gczic at very strong interference .",
    "the gczic at weak interference ( @xmath40 ) is a special case of the gaussian cognitive interference channel ( when @xmath30 ) , for which the capacity region is known for @xmath41 and any real @xmath21 @xcite .",
    "the cognitive user partially devotes its power to help send the codeword of the primary user .",
    "it dirty paper encodes its own codeword against the codeword of the primary user .",
    "the cognitive receiver performs dirty paper decoding to extract its message free of interference @xcite and @xcite . at strong interference regime ( @xmath42 )",
    "however , the capacity of the gczic is not known in general . an outer bound on the capacity of the gaussian cognitive ic was established by maric et al . in @xcite ,",
    "corollary 1 .    in this section ,",
    "we first find the condition in which the gczic is a more capable or under strong interference .",
    "we show that for the gaussian cic , strong interference conditions is equivalent to @xmath42 .",
    "thus for @xmath42 , we provide new inner and outer bounds by evaluating the inner and outer bounds in section [ sec : dm - czic ] .",
    "finally , we prove that these inner and outer bounds coincide when the interference is very strong ( @xmath43 ) , thus establish the capacity of the gczic for this range of interference .      in this section",
    "we explore the conditions for which theorem  [ thm2 ] holds for the gczic ; i.e , we find the condition that the gczic is either more capable or under strong interference .",
    "intuitively , the gczic is more capable when interference is very strong . considers the equivalent channel in figure [ fig : zic - eq ] which is achieved by manipulating figure [ fig : zic ] .",
    "since both figures have the same @xmath36 , and @xmath37 is a scaled transformation of @xmath44 @xmath45 , the channels depicted in these figures are equivalent from capacity point of view .",
    "the equivalent channel in figure [ fig : zic - eq ] looks like a broadcast channel if we consider @xmath46 as interference . without @xmath46",
    "this channel is a degraded bc and its capacity is known .",
    "now , considering the interference @xmath46 as noise , and assuming that @xmath1 is large enough that the power associated with noise plus interference ( @xmath47 ) is less than noise power at @xmath36 , then @xmath44 can be more capable than @xmath36 .",
    "we need to find the range of @xmath1 for which @xmath48 in figure  [ fig : zic - eq ] ( or equivalently @xmath37 in figure  [ fig : zic ] ) is more capable than @xmath36 in decoding @xmath49 .",
    "the condition ( [ eq : defn1 ] ) is equivalent to @xmath50 because of channel transition matrix at ( [ eq : cond0 ] ) . for the gczic ,",
    "this is equivalent to @xmath51 for all @xmath52 . with jointly gaussian @xmath53 with correlation factor",
    "@xmath54 then becomes @xmath55 choosing @xmath56 , which is the worst case , the gczic is more capable if @xmath57 it is not clear , however , if this condition implies more capability .",
    "let s now find the range of @xmath1 for which the strong interference condition holds for the gczic .",
    "the proof follows directly from the strong interference condition for the gaussian cognitive ic @xcite , which shows that condition is equivalent to @xmath58 we can draw the conclusion that the strong interference condition implies the more capability condition for any gaussian cognitive ic .",
    "this completes the proof that theorem  [ thm2 ] is applicable for the gaussian cic , and thus for the gczic , if @xmath59 .",
    "the capacity of the gczic is partially unknown for strong interference ( @xmath4 ) . at this regime , the best outer bound on the capacity",
    "the gczic was established in @xcite , corollary 1 . in this section ,",
    "we provide a new outer bound for the capacity of the gczic at strong interference .",
    "this outer bound is the gaussian version of the outer bound in theorem [ thm2 ] , with the extra inequality @xmath60 @xcite , @xcite to that .",
    "any achievable rate pair @xmath61 of the gczic with @xmath4 , is upper bounded by the following constraints @xmath62 where @xmath63 , and @xmath64 .",
    "[ lem1 ]    the proof of this lemma involves showing that the jointly gaussian distribution is the optimum distribution and evaluating the outer bound in theorem [ thm2 ] for the gczic , then finding the covariance matrix of jointly gaussian @xmath65 to maximize the rhs of all inequalities in theorem [ thm1 ] .",
    "details of evaluation and maximization can be found in appendix c.     and the best existing outer bound in @xcite , for the gczic with @xmath66 . ]    from the proof , it can be seen that without , optimality condition is @xmath67 which is achieved when @xmath68 , and implies that @xmath49 is a function of @xmath69 .",
    "this condition is the same as that in the inner bound .",
    "however , the inner bound applies to independent @xmath70 and @xmath71 whereas the outer bound is for general @xmath70 and @xmath71 . in section  [ capacity ] , we show that for a certain range of @xmath1 ( @xmath72 ) the optimal @xmath70 and @xmath71 for the outer bound are also independent , thus establish the capacity at that range .",
    "figure  [ fig : fig1 ] numerically compares the outer bound proposed in lemma  [ lem1 ] with the best existing outer bound in @xcite .",
    "it shows that new outer bound is strictly better than the existing one .",
    "moreover , as @xmath73 becomes larger , the gap between these two bounds increases , and the outer bound in lemma  [ lem1 ] gets much closer to the achievable region .",
    "this lemma establishes the best outer bound on the capacity region of the gczic at strong inference ( @xmath4 ) .",
    "we prove this claim by simplifying the outer bound in lemma  [ lem1 ] into three simpler outer bounds in the following corollaries .",
    "to do so , we first introduce @xmath74 , @xmath75 , and @xmath76 $ ] to make the bounds easier to read . these corollaries give the capacity of the desired channel for two disjoint ranges of @xmath1 .",
    "any achievable rate pair @xmath61 of the gczic , is upper bounded by the convex hull of the following region @xmath77 where @xmath78 $ ] .",
    "[ cor1 ]    this follows immediately by removing , from the lemma  [ lem1 ] .",
    "this is the same as the best existing outer bound in @xcite , and our claim that lemma  [ lem1 ] provides the best outer bound follows readily .",
    "it should be highlighted that , this region has been recently proven in @xcite and @xcite to be the capacity of the gczic for @xmath79 .",
    "any achievable rate pair @xmath61 of the gczic , is upper bounded by the convex hull of the following region @xmath80 where @xmath81 $ ] .",
    "[ cor2 ]    similar to the corollary  [ cor1 ] , we first eliminate , in the lemma  [ lem1 ] . then , the proof of is immediate by looking at , and is achieved for @xmath82 . as we will show later in section  [ capacity ] , corollary  [ cor2 ] is also the capacity region for the gczic when interference gain is considerably large ( @xmath83 ) .",
    "any achievable rate pair @xmath61 of the gczic , is upper bounded by the convex hull of the following region @xmath84 where @xmath85 $ ] .",
    "[ cor3 ]    to prove this , we first remove in the lemma  [ lem1 ] .",
    "then , in we use @xmath86 where the last inequality follows applying triangle inequality @xmath87 with @xmath88 and @xmath89 to the lhs of @xmath63 .",
    "the maximum is attained when @xmath90 has the same sign with @xmath1 .",
    "finally , the outer bound in corollary  [ cor3 ] is obtained considering that @xmath91 , @xmath92 .",
    "similar to corollary  [ cor2 ] , in section  [ capacity ] , we will show that for @xmath93 , corollary  [ cor3 ] results in the capacity region of the gczic when @xmath6 .",
    "in this section , we compute the gaussian version of the achievable region introduced in section [ inner ] for the gczic . following lemma , which extends theorem [ thm1 ] to the gczic ,",
    "provides the achievable region by superposition coding .    any rate pair @xmath61 satisfying @xmath94 with @xmath81 $ ] is achievable for the gczic . [ lem2 ]",
    "the achievability of this region is straightforward by theorem [ thm1 ] . in the proof of lemma  [ lem1 ]",
    ", we have shown that jointly gaussian input is the optimum input to maximize @xmath95 and @xmath96 .",
    "the cognitive user partially uses its power to help send the codewords of the primary user .",
    "@xmath49 contains two independent gaussian parts , @xmath97 .",
    "the primary user dedicates its whole power to transmit @xmath98 , as @xmath99 .",
    "decoding in the primary receiver is based on successive cancelation , where it first decode and subtract the cognitive user s codeword in order to decode its own codeword free of interference .",
    "cognitive receiver simply decodes its own codeword assuming the other codeword as interference .",
    "this achievable region even simplifies when the interference gain is substantially large , that is @xmath83 . in the following section",
    "we show that , when interference is very strong ( @xmath6 ) , the inner bound in lemma  [ lem2 ] gives the capacity of the desired channel .      in this section",
    ", we prove that superposition coding achieves the capacity of the gczic for @xmath3 .",
    "specifically , we show that in corollary  [ cor3 ] , @xmath100 has to be @xmath101 for this range of @xmath1 .",
    "hence , the outer bound coincides with the inner bound in lemma  [ lem2 ] and gives the capacity of the desired channel .",
    "the capacity region the gczic for @xmath6 is the set of all rate pairs @xmath61 satisfying @xmath102 for @xmath81 $ ] . [ thm3 ]    we want to show that for @xmath6 the outer bound in corollary  [ cor3 ] and the inner bound in lemma  [ lem2 ] coincide .",
    "let s define @xmath103 as the set of all rate pairs satisfying the constraints in lemma  [ lem2 ] and @xmath104 as the set of all rate pairs satisfying - .",
    "using the same argument as el gamal @xcite , we can show that @xmath105 . here",
    "@xmath106 can be thought of as the rate of common message which can be decoded at both receivers while @xmath107 is the rate of the private message .",
    "now @xmath108 if and only if @xmath109 for any @xmath110 . this means the common rate ( @xmath106 ) can be partially or entirely private .",
    "thus region @xmath104 can be represented as @xmath103 .",
    "we next show that the outer bound in corollary  [ cor3 ] simplifies to @xmath104 .",
    "to do so , it suffices to show that for @xmath6 , @xmath100 has to be @xmath101 in corollary  [ cor3 ] .",
    "consider the first two inequalities of the outer bound in corollary  [ cor3 ] ; we can see that on the boundary of this outer bound we must have @xmath111 comparing this inequality with the first inequity in @xmath103 , we conclude that either @xmath100 has to be @xmath101 or the first inequity of @xmath103 must be loose ; since otherwise the outer bound is less that the inner bound , which is not possible .",
    "for this inequality to be redundant in @xmath103 we need @xmath112 for to hold with any @xmath113 then @xmath114 this implies the first inequality of lemma  [ lem2 ] is redundant only for @xmath115 . in other words , if @xmath116 there exist some @xmath113 for which this inequality can not be redundant ; this in turn enforces @xmath93 .",
    "thus , for this range of @xmath1 , the outer bound in corollary  [ cor3 ] simplifies to @xmath104 .",
    "note also that with @xmath117 the optimal input for the outer bound is the same as the input for the inner bound ( i.e. , @xmath70 , @xmath71 are independent and @xmath118 ) , thus the capacity is established .",
    "as a special case , when the third constraint is redundant in @xmath103 and @xmath104 , the outer bound in corollary  [ cor2 ] is tight .",
    "for such an @xmath1 , the capacity region in theorem  [ thm3 ] further simplifies as below .",
    "the capacity region the gczic for @xmath83 is the set of all rate pairs @xmath61 satisfying @xmath119 for @xmath81 $ ] . [ cor4 ]",
    "first consider the achievable rate region in lemma  [ lem2 ] .",
    "the third inequality becomes redundant if @xmath120 for to hold with any @xmath113 then @xmath121 on the other hand , without the third inequality , the achievable region in corollary  [ cor4 ] is also equal to the outer bound in the corollary  [ cor2 ] .",
    "this is because , for the same value of @xmath113 , any point on the boundary of this region is on the boundary of the region in corollary  [ cor2 ] , and vice versa .",
    "hence , we obtain the capacity region in corollary  [ cor4 ] if ( [ eq : e6 ] ) holds for any @xmath113 , i.e. , @xmath122 .",
    "corollary  [ cor4 ] provides a special case of theorem  [ thm3 ] with simpler rate expressions . in the concurrent and independent work @xcite , ",
    "theorem v.3 .",
    "capacity for s - g - cifc \" archives the same capacity result in corollary  [ cor4 ] using a different approach .",
    "the achievability follows from a more general dpc - based scheme for the gaussian cognitive interference channel .",
    "although the achievability seems to be based on dpc , a close observation reveals that dpc is not necessary to achieve the capacity .",
    "this is because the parameter of dpc is zero ( @xmath123 ) which means that , in effect , dpc has no contribution ; thus , the achievability scheme reduces to superposition coding .",
    "the outer bound is completely different and is based on the mimo - bc outer bound @xcite .",
    "theorem  [ thm3 ] shows that , when the interference is very strong , the interfered primary receiver can decode the message of the interfering cognitive transmitter in a rate higher than its own receiver .",
    "this is as though the interference link from the cognitive transmitter to the primary receiver is less noisy than the direct link for the cognitive user s message .",
    "this sheds light on the optimal coding scheme as well .",
    "that is , the primary user encodes independently while the cognitive user encodes by superimposing the primary user s codeword on its own .",
    "then , the cognitive receiver decodes its message treating primary user s codeword as noise .",
    "the primary receiver , on the other hand , performs successive cancellation ; it first decodes the cognitive user s message , then subtracts it from the received signal to decode its own message free of interference .",
    "analysis of the capacity results of the gczic shows that superposition coding appears to be an indispensable tool in any capacity - achieving techniques for this channel . at very strong interference ,",
    "superposition coding single - handedly achieves its capacity .",
    "however , both dpc and superposition coding are needed to establish the capacity when interference is weak or intermediate .",
    "table i summarizes the capacity results for the gczic .",
    "as it can be seen , up to now , the capacity of this channel is characterized except for @xmath124 . for this range of @xmath1 , a more general and inclusive form of the proposed capacity - achieving outer bounds at @xmath125 , as represented in lemma [ lem1 ] ,",
    "provides the best outer bound on the capacity region of the gczic .",
    "* reference + * & & * technique & + @xmath126 & @xmath127 & superposition coding & @xcite , @xcite + @xmath128 & @xmath129 & and dpc & + * * * * * *    @xmath130 & @xmath131 & superposition coding & @xcite , @xcite + @xmath128 & @xmath129 & and dpc & +    @xmath132 & unknown & unknown &  + @xmath133 & ( lemma  [ lem1 ] gives the best outer bound ) & & +    @xmath128 & @xmath134 & & + @xmath135 & @xmath136 & superposition coding & theorem [ [ thm3 ] ] + @xmath128 & @xmath137 & & +    @xmath138 & @xmath134 & superposition coding & corollary  [ [ cor4 ] ] , + @xmath128 & @xmath139 & & @xcite +",
    "fix @xmath140 , @xmath141 and @xmath142 that achieve capacity . randomly and independently generate @xmath143 sequences @xmath144 , @xmath145 $ ] _ i.i.d . _ according to @xmath146 .",
    "also , randomly and independently generate @xmath147 sequences @xmath148 , @xmath149 $ ] with elements _ i.i.d .",
    "_ according to @xmath150 .",
    "next , for each pair of sequences @xmath151 , randomly and conditionally independently generate one sequence @xmath152 with elements _ i.i.d .",
    "_ according to @xmath153 .",
    "decoding is based on standard joint typicality . the less capable receiver ( @xmath36 )",
    "can only distinguish the auxiliary random variable @xmath71 .",
    "decoder 2 declares that message @xmath157 is sent if it is a unique message such that @xmath158 ; otherwise it declares an error .",
    "decoder 1 declares that message @xmath159 is sent if it is a unique message such that @xmath160 for some @xmath161 ; otherwise it declares an error .      to analyze the probability of error , without loss of generality , assume that @xmath162 is sent .",
    "first we consider the average probability of error for decoder 2 .",
    "let s define the error events @xmath163 by union bound , the probability of error for decoder 2 is upper bounded by @xmath164 now by law of large numbers ( lln ) @xmath165 also , since @xmath166 is independent of @xmath167 for @xmath168 by the packing lemma @xcite @xmath169    then , consider the average probability of error for decoder 1 .",
    "we define the following error events @xmath170 using union bound , the probability of error for decoder 2 is upper bounded by @xmath171 now we evaluate each term in the right - hand side ( rhs ) of this inequality when @xmath172 .",
    "first consider @xmath173 ; again by lln @xmath174 next consider @xmath175 .",
    "for @xmath176 since @xmath177 is conditionally independent of @xmath178 given @xmath179 , by packing lemma @xmath180 because @xmath49 is a function of @xmath181",
    ". finally consider @xmath182 .",
    "for @xmath176 and @xmath168 , @xmath183 is independent of @xmath178 ; hence , by packing lemma @xmath184 .",
    "the equality follows because @xmath185 forms a markov chain .",
    "the above analysis completes the proof of achievability since it shows that both receivers can decode corresponding messages with the total probability of error tending to zero if is satisfied .",
    "therefore , there exists a sequence of codes with error probability tending to 0 .",
    "the proof is also similar to the converse proof for the more capable broadcast channel @xcite .",
    "we follow the same line of proof as in @xcite ; the only difference is replacing @xmath70 in @xcite with @xmath186 , since here @xmath49 also encodes @xmath7 .",
    "we can bound the rates @xmath187 and @xmath188 as @xmath189 and @xmath190 where and ( [ eq : f-2 ] ) follow by fano s inequality . in a very similar fashion , sum rate can be also bounded by @xmath191 now we manipulate the rhs of - to obtain the desired terms in .",
    "first , consider the mutual information term in @xmath192 in which ( [ eq : r2 - 1 ] ) follows from the chain rule , and we have defined the auxiliary random variable @xmath193 moving to ( [ eq : r2 - 2 ] ) .",
    "next , we bound the mutual information terms of the second inequality in ( [ eq : f-2 ] ) .",
    "@xmath194 where ( [ eq : sum ] ) follows by the csiszar sum identity and the auxiliary random variable @xmath195 ; ( [ eq : rsum1 ] ) follows by markov chain @xmath196 .",
    "in which ( [ eq : a0 ] ) follows similar steps to the bound for the first inequality on sum rate ; ( [ eq : a1 ] ) follows from @xmath199 ; and ( [ eq : b ] ) follows by ( [ eq : defn1 ] ) that gives @xmath200 , and implies that @xmath201 .",
    "the proof outer bound under the strong interference condition is almost the same , with only slight difference in the proof of last inequality .",
    "this is because the first two inequalities hold for any dm - cic . under the strong interference condition we can we can bound the mutual information terms in ( [ eq : f-3 ] ) as @xmath212 in which ( [ eq : a6 ] ) follows by ( [ eq : defn2 ] ) that gives @xmath213 , and implies that @xmath214 .",
    "the other steps are straightforward .",
    "finally , this proves that theorem  [ thm2 ] holds both for more capable strong and interference dm - cic .",
    "we need to find the distribution that maximize the rate region in theorem [ thm2 ] for the gaussian channel . in what follows ,",
    "we show that jointly gaussian @xmath215 is optimum , i.e. , it provides the largest outer bound for the gaussian channel . by maximum entropy theorem , the rhs of the third inequality is maximized when @xmath37 is gaussian , thus @xmath216    similarly , @xmath217 where @xmath218 denotes @xmath36 when the inputs @xmath14 are gaussian .",
    "the last inequality follows by conditional version of entropy power inequality ( epi ) for which equality is achieved when @xmath219 .",
    "likewise , for the term @xmath220 we can write @xmath221 where where @xmath222 denote@xmath223 when the inputs @xmath14 are gaussian , and inequalities follow by maximum entropy theorem and conditional version of epi , respectively .",
    "again equality is achieved when all terms are gaussian .",
    "hence , all inequalities in the outer bound are maximized with jointly gaussian @xmath215 .",
    "now the problem is to find the optimum covariance matrix to maximize the bounds , i.e. , to determine correlation coefficients among @xmath224 and @xmath225 .",
    "let @xmath226 , which are correlated gaussian random variables @xmath224 and @xmath225 with covariance matrix @xmath227    since the covariance matrix is positive semidefinite , the determinant of this matrix must be nonnegative .",
    "that is @xmath228 the inequality holds if @xmath229 or equivalently the covariance matrix is positive semidefinite if @xmath230 now we evaluate the rate constraints defining the outer bound in theorem [ thm2 ] .",
    "@xmath231 where @xmath232 similarly @xmath233 where @xmath234 to check",
    "if the inequality ( [ eq : ineq1 ] ) can hold with equality , we evaluate the term @xmath235 @xmath236 in which the covariance matrix @xmath237 is defined by ( [ eq : cov ] ) .",
    "since both numerator and denominator are nonnegative in ( [ eq : ineq1 ] ) , the argument of this function is either zero or positive . therefore , @xmath238 is achieved when @xmath239 , or equivalently , @xmath240 .",
    "note that @xmath241 implies @xmath49 to be a function of @xmath69 .    keeping this in mind that @xmath242 is optimum condition for ( [ eq : ineq1 ] )",
    ", we evaluate @xmath220 as follows .",
    "@xmath243 where , the last inequality follows from ( [ eq : cond4 ] ) .",
    "interestingly , again @xmath244 turns out to be the optimum condition . from this two values for @xmath54 are plausible which are respectively @xmath245 then , it is also straightforward to calculate the third bound in theorem [ thm2 ] to obtain @xmath246      as a last step , we can evaluate and add the gaussian version of the standard inequality @xmath60 @xcite , @xcite , to these bounds ; the corresponding inequality is @xmath249 as a result , the outer bound is as given in lemma [ lem1 ] .",
    "a. jovicic and p. viswanath , `` cognitive radio : an information- theoretic perspective , '' in proc .",
    "theory , july 2006 , pp .",
    "2413 - 2417 .",
    "w. wu , s. vishwanath , and a. arapostathis , `` capacity of a class of cognitive radio channels : interference channels with degraded message sets , '' _ ieee transactions on information theory _ ,",
    "4391 - 4399 , nov .",
    "2007 .",
    "i. maric , a. goldsmith , g. kramer , and s. shamai ( shitz ) , `` on the capacity of interference channels with one cooperatig taransmitter , '' _",
    "european trans .",
    "10 , pp . 405 - 420 , april 2008 .",
    "n. liu , i. maric , a. goldsmith and shlomo shamai ( shitz ) , `` bounds and capacity results for the cognitive z - interference channel , '' in proc .",
    "theory , ( isit09 ) , seoul , korea , june 2009 .",
    "s. rini , d. tuninetti and n. devroye , `` new results on the capacity of the gaussian cognitive interference channel , '' forty - eighth annual allerton conference on communication , control , and computing , monticello , sept . 2010 .",
    "s. rini , d. tuninetti and n. devroye , `` inner and outer bounds for the gaussian cognitive interference channel and new capacity results , '' submitted to _ ieee trans . on inf .",
    "theory _ , october 2010 , available at http://arxiv.org/abs/1010.5806 ."
  ],
  "abstract_text": [
    "<S> this paper considers the cognitive interference channel ( cic ) with two transmitters and two receivers , in which the cognitive transmitter non - causally knows the message and codeword of the primary transmitter . </S>",
    "<S> we first introduce a discrete memoryless more capable cic , which is an extension to the more capable broadcast channel ( bc ) . using superposition coding </S>",
    "<S> , we propose an inner bound and an outer bound on its capacity region . </S>",
    "<S> the outer bound is also valid when the primary user is under strong interference . for the gaussian cic , </S>",
    "<S> this outer bound applies for @xmath0 , where @xmath1 is the gain of interference link from secondary user to primary receiver . </S>",
    "<S> these capacity inner and outer bounds are then applied to the gaussian cognitive z - interference channel ( gczic ) where only the primary receiver suffers interference . upon showing that jointly gaussian input maximizes these bounds for the gczic </S>",
    "<S> , we evaluate the bounds for this channel . </S>",
    "<S> the new outer bound is strictly tighter than other outer bounds on the capacity of the gczic at strong interference ( @xmath2 ) . </S>",
    "<S> especially , the outer bound coincides with the inner bound for @xmath3 and thus , establishes the capacity of the gczic at this range . </S>",
    "<S> for such an @xmath1 , superposition encoding at the cognitive transmitter and successive decoding at the primary receiver are capacity - achieving . </S>"
  ]
}