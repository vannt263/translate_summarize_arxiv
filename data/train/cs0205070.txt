{
  "article_text": [
    "today , very large amounts of information are available in on - line documents . as part of the effort to better organize this information for users , researchers have been actively investigating the problem of automatic text categorization .",
    "the bulk of such work has focused on _ topical _ categorization , attempting to sort documents according to their subject matter ( e.g. , sports vs.  politics ) .",
    "however , recent years have seen rapid growth in on - line discussion groups and review sites ( e.g. , the new york times books web page ) where a crucial characteristic of the posted articles is their _ sentiment _ , or overall opinion towards the subject matter  for example , whether a product review is positive or negative .",
    "labeling these articles with their sentimentwould provide succinct summaries to readers ; indeed , these labels are part of the appeal and value - add of such sites as www.rottentomatoes.com , which both labels movie reviews that do not contain explicit rating indicators and normalizes the different rating schemes that individual reviewers use .",
    "sentimentclassification would also be helpful in business intelligence applications ( e.g. mindfuleye s lexant system ) and recommender systems ( e.g. , , ) , where user input and feedback could be quickly summarized ; indeed , in general , free - form survey responses given in natural language format could be processed using sentimentcategorization .",
    "moreover , there are also potential applications to message filtering ; for example , one might be able to use sentimentinformation to recognize and discard `` flames''@xcite .    in this paper ,",
    "we examine the effectiveness of applying machine learning techniques to the sentimentclassification problem . a challenging aspect of this problem that seems to distinguish it from traditional topic - based classification is that while topics are often identifiable by keywords alone , sentimentcan be expressed in a more subtle manner .",
    "for example , the sentence `` how could anyone sit through this movie ? ''",
    "contains no single word that is obviously negative .",
    "( see section [ sec : discuss ] for more examples ) .",
    "thus , sentimentseems to require more _ understanding _ than the usual topic - based classification .",
    "so , apart from presenting our results obtained via machine learning techniques , we also analyze the problem to gain a better understanding of how difficult it is .",
    "this section briefly surveys previous work on non - topic - based text categorization .",
    "one area of research concentrates on classifying documents according to their _ source _ or _ source style _",
    ", with statistically - detected stylistic variation @xcite serving as an important cue .",
    "examples include author , publisher ( e.g. , the _ new york times _ vs. _ the daily news _ ) , native - language background , and `` brow '' ( e.g. , high - brow vs. `` popular '' , or low - brow ) @xcite .",
    "another , more related area of research is that of determining the _ genre _ of texts ; subjective genres , such as `` editorial '' , are often one of the possible categories @xcite",
    ". other work explicitly attempts to find features indicating that subjective language is being used @xcite .",
    "but , while techniques for genre categorization and subjectivity detection can help us _",
    "recognize _ documents that express an opinion , they do not address our specific _",
    "task of determining what that opinion actually is",
    ".    most previous research on sentiment - based classification has been at least partially knowledge - based .",
    "some of this work focuses on classifying the semantic orientation of individual words or phrases , using linguistic heuristics or a pre - selected set of seed words @xcite .",
    "past work on sentiment - based categorization of entire documents has often involved either the use of models inspired by cognitive linguistics @xcite or the manual or semi - manual construction of discriminant - word lexicons @xcite .",
    "interestingly , our baseline experiments , described in section [ sec : closer ] , show that humans may not always have the best intuition for choosing discriminating words .",
    "turney s work on classification of reviews is perhaps the closest to ours .",
    "he applied a specific unsupervised learning technique based on the mutual information between document phrases and the words `` excellent '' and `` poor '' , where the mutual information is computed using statistics gathered by a search engine . in contrast , we utilize several completely prior - knowledge - free supervised machine learning methods , with the goal of understanding the inherent difficulty of the task .",
    "for our experiments , we chose to work with movie reviews .",
    "this domain is experimentally convenient because there are large on - line collections of such reviews , and because reviewers often summarize their overall sentimentwith a machine - extractable _ rating _ indicator , such as a number of stars ; hence , we did not need to hand - label the data for supervised learning or evaluation purposes .",
    "we also note that found movie reviews to be the most difficult of several domains for sentiment classification , reporting an accuracy of 65.83% on a 120-document set ( random - choice performance : 50% ) .",
    "but we stress that the machine learning methods and features we use are not specific to movie reviews , and should be easily applicable to other domains as long as sufficient training data exists .",
    "our data source was the internet movie database ( imdb ) archive of the rec.arts.movies.reviews newsgroup .",
    "we selected only reviews where the author rating was expressed either with stars or some numerical value ( other conventions varied too widely to allow for automatic processing ) .",
    "ratings were automatically extracted and converted into one of three categories : positive , negative , or neutral . for the work described in this paper , we concentrated only on discriminating between positive and negative sentiment . to avoid domination of the corpus by a small number of prolific reviewers",
    ", we imposed a limit of fewer than 20 reviews per author per sentimentcategory , yielding a corpus of 752 negative and 1301 positive reviews , with a total of 144 reviewers represented .",
    "this dataset will be available on - line at .    [",
    "cols=\"^,<,<,<\",options=\"header \" , ]",
    "we used documents from the movie - review corpus described in section [ sec : domain ] . to create a data set with uniform class distribution ( studying the effect of skewed class distributions was out of the scope of this study ) , we randomly selected 700 positive - sentiment and 700 negative - sentiment documents .",
    "we then divided this data into three equal - sized folds , maintaining balanced class distributions in each fold .",
    "( we did not use a larger number of folds due to the slowness of the maxenttraining procedure . ) all results reported below , as well as the baseline results from section [ sec : closer ] , are the average three - fold cross - validation results on this data ( of course , the baseline algorithms had no parameters to tune ) .    to prepare the documents , we automatically removed the rating indicators and extracted the textual information from the original html document format , treating punctuation as separate lexical items .",
    "no stemming or stoplists were used .",
    "one unconventional step we took was to attempt to model the potentially important contextual effect of negation : clearly `` good '' and `` not very good '' indicate opposite sentimentorientations . adapting a technique of , we added the tag not _ to every word between a negation word ( `` not '' , `` is nt '' , `` did nt '' , etc . ) and the first punctuation mark following the negation word .",
    "( preliminary experiments indicate that removing the negation tag had a negligible , but on average slightly harmful , effect on performance . )    for this study , we focused on features based on unigrams ( with negation tagging ) and bigrams . because training maxentis expensive in the number of features , we limited consideration to ( 1 ) the 16165 unigrams appearing at least four times in our 1400-document corpus ( lower count cutoffs did not yield significantly different results ) , and ( 2 ) the 16165 bigrams occurring most often in the same data ( the selected bigrams all occurred at least seven times ) .",
    "note that we did not add negation tags to the bigrams , since we consider bigrams ( and @xmath0-grams in general ) to be an orthogonal way to incorporate context .",
    "[ [ initial - unigram - results ] ] initial unigram results + + + + + + + + + + + + + + + + + + + + + + +    the classification accuracies resulting from using only unigrams as features are shown in line ( 1 ) of figure [ fig : results - plain ] . as a whole ,",
    "the machine learning algorithms clearly surpass the random - choice baseline of 50% .",
    "they also handily beat our two human - selected - unigram baselines of 58% and 64% , and , furthermore , perform well in comparison to the 69% baseline achieved via limited access to the test - data statistics , although the improvement in the case of svms is not so large .    on the other hand , in topic - based classification , all three classifiers have been reported to use bag - of - unigram features to achieve accuracies of 90% and above for particular categories @xcite  and such results are for settings with more than two classes .",
    "this provides suggestive evidence that sentimentcategorization is more difficult than topic classification , which corresponds to the intuitions of the text categorization expert mentioned above .",
    "nonetheless , we still wanted to investigate ways to improve our sentimentcategorization results ; these experiments are reported below .",
    "[ [ feature - frequency - vs .- presence ] ] feature frequency vs. presence + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    recall that we represent each document @xmath1 by a feature - count vector ( @xmath2 .",
    "however , the definition of the maxentfeature / class functions @xmath3 only reflects the presence or absence of a feature , rather than directly incorporating feature frequency . in order to investigate whether reliance on frequency information could account for the higher accuracies of naive bayes and svms , we binarized the document vectors , setting @xmath4 to 1 if and only feature @xmath5 appears in @xmath1 , and reran naive bayes and @xmath6on these new vectors .    as can be seen from line ( 2 ) of figure [ fig : results - plain ]",
    ", better performance ( _ much _ better performance for svms ) is achieved by accounting only for feature presence , not feature frequency .",
    "interestingly , this is in direct opposition to the observations of with respect to naive bayes topic classification .",
    "we speculate that this indicates a difference between sentimentand topic categorization  perhaps due to topic being conveyed mostly by particular content words that tend to be repeated  but this remains to be verified . in any event , as a result of this finding , we did not incorporate frequency information into naive bayes and svms in any of the following experiments .",
    "[ [ bigrams ] ] bigrams + + + + + + +    in addition to looking specifically for negation words in the context of a word , we also studied the use of bigrams to capture more context in general .",
    "note that bigrams and unigrams are surely not conditionally independent , meaning that the feature set they comprise violates naive bayes conditional - independence assumptions ; on the other hand , recall that this does not imply that naive bayes will necessarily do poorly @xcite .",
    "line ( 3 ) of the results table shows that bigram information does not improve performance beyond that of unigram presence , although adding in the bigrams does not seriously impact the results , even for naive bayes .",
    "this would not rule out the possibility that bigram presence is as equally useful a feature as unigram presence ; in fact , found that bigrams alone can be effective features for word sense disambiguation .",
    "however , comparing line ( 4 ) to line ( 2 ) shows that relying just on bigrams causes accuracy to decline by as much as 5.8 percentage points .",
    "hence , if context is in fact important , as our intuitions suggest , bigrams are not effective at capturing it in our setting .",
    "[ [ parts - of - speech ] ] parts of speech + + + + + + + + + + + + + + +    we also experimented with appending pos tags to every word via oliver mason s qtag program .",
    "this serves as a crude form of word sense disambiguation @xcite : for example , it would distinguish the different usages of `` love '' in `` i love this movie '' ( indicating sentimentorientation ) versus `` this is a love story '' ( neutral with respect to sentiment ) .",
    "however , the effect of this information seems to be a wash : as depicted in line ( 5 ) of figure [ fig : results - plain ] , the accuracy improves slightly for naive bayes but declines for svms , and the performance of maxentis unchanged .    since",
    "adjectives have been a focus of previous work in sentimentdetection @xcite , we looked at the performance of using adjectives alone .",
    "intuitively , we might expect that adjectives carry a great deal of information regarding a document s sentiment ; indeed , the human - produced lists from section [ sec : closer ] contain almost no other parts of speech . yet , the results , shown in line ( 6 ) of figure [ fig : results - plain ] , are relatively poor : the 2633 adjectives provide less useful information than unigram presence . indeed ,",
    "line ( 7 ) shows that simply using the 2633 most frequent unigrams is a better choice , yielding performance comparable to that of using ( the presence of ) all 16165 ( line ( 2 ) ) .",
    "this may imply that applying explicit feature - selection algorithms on unigrams could improve performance .",
    "[ [ position ] ] position + + + + + + + +    an additional intuition we had was that the position of a word in the text might make a difference : movie reviews , in particular , might begin with an overall sentimentstatement , proceed with a plot discussion , and conclude by summarizing the author s views .",
    "as a rough approximation to determining this kind of structure , we tagged each word according to whether it appeared in the first quarter , last quarter , or middle half of the document .",
    "the results ( line ( 8) ) did nt differ greatly from using unigrams alone , but more refined notions of position might be more successful .",
    "the results produced via machine learning techniques are quite good in comparison to the human - generated baselines discussed in section [ sec : closer ] . in terms of relative performance , naive bayes tends to do the worst and svms tend to do the best , although the differences are nt very large .    on the other hand , we were not able to achieve accuracies on the sentimentclassification problem comparable to those reported for standard topic - based categorization , despite the several different types of features we tried .",
    "unigram presence information turned out to be the most effective ; in fact , none of the alternative features we employed provided consistently better performance once unigram presence was incorporated . interestingly , though , the superiority of presence information in comparison to frequency information in our setting contradicts previous observations made in topic - classification work @xcite .    what accounts for these two differences",
    " difficulty and types of information proving useful  between topic and sentimentclassification , and how might we improve the latter ? to answer these questions , we examined the data further .",
    "( all examples below are drawn from the full 2053-document corpus . )    as it turns out , a common phenomenon in the documents was a kind of `` thwarted expectations '' narrative , where the author sets up a deliberate contrast to earlier discussion : for example , `` this film should be brilliant .",
    "it sounds like a great plot , the actors are first grade , and the supporting cast is good as well , and stallone is attempting to deliver a good performance .",
    "however , it ca nt hold up '' or `` i hate the spice girls . ... [ 3 things the author hates about them ] ... why i saw this movie is a really , really , really long story , but i did , and one would think i d despise every minute of it .",
    "but ... okay , i m really ashamed of it , but i enjoyed it .",
    "i mean , i admit it s a really awful movie ... the ninth floor of hell ... the plot is such a mess that it s terrible .",
    "but i loved it . ''    in these examples , a human",
    "would easily detect the true sentiment of the review , but bag - of - features classifiers would presumably find these instances difficult , since there are many words indicative of the opposite sentiment to that of the entire review .",
    "fundamentally , it seems that some form of discourse analysis is necessary ( using more sophisticated techniques than our positional feature mentioned above ) , or at least some way of determining the focus of each sentence , so that one can decide when the author is talking about the film itself .",
    "( makes a similar point , noting that for reviews , `` the whole is not necessarily the sum of the parts '' . )",
    "furthermore , it seems likely that this thwarted - expectations rhetorical device will appear in many types of texts ( e.g. , editorials ) devoted to expressing an overall opinion about some topic .",
    "hence , we believe that an important next step is the identification of features indicating whether sentences are on - topic ( which is a kind of co - reference problem ) ; we look forward to addressing this challenge in future work .      we thank joshua goodman , thorsten joachims , jon kleinberg , vikas krishna , john lafferty , jussi myllymaki , phoebe sengers , richard tong , peter turney , and the anonymous reviewers for many valuable comments and helpful suggestions , and hubie chen and tony faradjian for participating in our baseline experiments .",
    "portions of this work were done while the first author was visiting ibm almaden .",
    "this paper is based upon work supported in part by the national science foundation under itr / im grant iis-0081334 .",
    "any opinions , findings , and conclusions or recommendations expressed above are those of the authors and do not necessarily reflect the views of the national science foundation .",
    "aidan finn , nicholas kushmerick , and barry smyth .",
    "genre classification and domain transfer for information filtering . in _ proc . of theeuropean colloquium on information retrieval research _ ,",
    "pages 353362 , glasgow ."
  ],
  "abstract_text": [
    "<S> we consider the problem of classifying documents not by topic , but by overall sentiment , e.g. , determining whether a review is positive or negative . using movie reviews as data , we find that standard machine learning techniques definitively outperform human - produced baselines </S>",
    "<S> . however , the three machine learning methods we employed ( naive bayes , maximum entropy classification , and support vector machines ) do not perform as well on sentiment classification as on traditional topic - based categorization . </S>",
    "<S> we conclude by examining factors that make the sentiment classification problem more challenging . </S>"
  ]
}