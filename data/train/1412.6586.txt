{
  "article_text": [
    "structured inference , where the goal is to infer a structured state output from a structured observation input , is a crucial component for a wide range of applications such as object recognition  @xcite , image classification  @xcite , natural language processing  @xcite , gesture recognition  @xcite , handwriting recognition  @xcite , and bioinformatics",
    ". a powerful and commonly - used approach to structured inference is the use of markov random field ( mrf ) and conditional random field ( crf )  @xcite models .",
    "a limitation of such graphical models is that they utilize unary and pairwise potentials on local neighborhoods only , and as such can result in smoothed state boundaries as well as prohibit long - range state boundaries given the limitations of constraint locality .",
    "this becomes particularly problematic in the presence of high observational uncertainties such as measurement noise and outliers .",
    "recently there has been significant interest in the application of two types of models for the purpose of structured inference that help address the issues associated with locally - connected graphical models : i ) fully - connected graphical models , and ii ) deep - structured graphical models .",
    "fully - connected graphical models address issues of locally - connected models by assuming full connectivity amongst all nodes in the graph , thus taking full advantage of long range relationships to improve inference accuracy .",
    "one of the main hurdles in utilizing fully - connected graphical models is the complexity of inference , which becomes computationally intractable as the size of the problem scales .",
    "much of recent research in fully - connected graphical models have revolved around addressing the computational complexity of inference step .",
    "krhenbhl and koltun  @xcite introduced an efficient inference procedure for fully - connected crf based on specific potential functions , where the edge potentials are obtained by use of gaussian kernels , thus allowing them to formulate the inference problem as a filtering problem . by computing the energy function via convolution , computational complexity is reduced to linear complexity by use of a permutohedral lattice  @xcite .",
    "zhang and chen  @xcite utilized a stationary constraint where the spatial potentials over two nodes are assumed to depend only on their relative positions for each of their states , thus allowing for statistical encoding by different distributions and thus relaxing the gaussian assumption made by krhenbhl and koltun .",
    "campbell et .",
    "@xcite further generalized the pairwise potentials to non - linear dissimilarity measures by representing the pairwise terms as density estimates of the conditional probability .",
    "ristovski et al .",
    "@xcite introduced a continuous fully - connected crf that is similar to that proposed by campbell et al . , but targets the regression problems with continuous outputs .",
    "nevertheless , while the aforementioned methods significantly reduce the computational complexity of inference on fully - connected graphical models , they all address the problem similarly by defining specific potential functions to manage the inference as a filtering approach , thus limiting the effectiveness of such models as the key merit of such models is to allow for arbitrary feature function selection .",
    "deep - structured graphical models take a different approach to improving inference performance by introducing intermediate state layers , where there is a dependency of each layer on its previous layer , and inference is carried out in a layer - by - layer manner from bottom to top .",
    "prabhavalkar and fosler - lussier  @xcite and peng et al .",
    "@xcite both introduced multi - layer conditional random field models where the local factors in linear - chain conditional random fields are replaced by multi - layer neural networks and trained via back - propagation .",
    "ratajczak et al .",
    "@xcite introduce a context - specific deep conditional random field model by replacing the local factors in linear - chain conditional random fields with sum - product networks .",
    "yu et al .",
    "@xcite introduced a deep - structured conditional random field model which consists of multiple layers of simple crfs where each layer s input consists of the previous layer s input and the resulting marginal probabilities .",
    "while such deep - structured graphical models are good at handling high observational uncertainties such as measurement noise and outliers by characterizing different information at the different layers , they only implicitly take advantage of long range relationships and are more limited in this aspect when compared to fully - connected graphical models .",
    "while fully - connected and deep - structured graphical models both have their own benefits and limitations , these two types of graphical models have been largely explored independently , leaving the unification of these two concepts ripe for exploration .",
    "such a unified graphical model could yield significant benefits in improving state boundary preservation , better enable long - range state boundaries , and better handle high observational uncertainties such as measurement noise and outliers . a fundamental challenge with unifying these two types of graphical models",
    "is in dealing with computational complexity , as not only are all nodes fully - connected within a layer , there are also multiple layers to process due to the deep structure of the graphical model . in this study , we investigate the feasibility of unifying fully - connected graphical models and deep - structured models in a computationally tractable manner for the purpose of statistical inference . to accomplish this",
    ", we introduce a deep - structured fully - connected random field ( dfrf ) model which integrates a series of intermediate sparse auto - encoding layers placed between state layers to significantly reduce computational complexity while still maintaining the benefits of fully - connected and deep - structured graphical models .",
    "this paper is organized as follows .",
    "first , the methodology behind the proposed dfrf model and structured inference using dfrf for image segmentation is described in section  [ methods ] .",
    "the experimental setup for evaluating the performance of the proposed dfrf model for solving the image segmentation problem is described in section  [ setup ] . the experimental results and discussion",
    "is presented in section  [ results ] , and conclusions are drawn and future work discussed in section  [ conclusions ] .",
    "from the bayes rule  @xcite , the joint distribution of the observation @xmath0 and labels @xmath1 are modeled based on the product of conditional probability of labels given observation , @xmath2 , and the probability of observation , @xmath3 as @xmath4    the goal of the proposed work is to incorporate fully connected interactions into the model that can preserve more information by taking advantage of the long range interactions in the modeling .",
    "however , incorporating fully connected interactions imposes a high computational complexity into the model which makes inference intractable . to address the issue of computational tractability",
    ", we introduce a sparse auto - encoding layer that describes the fully connected interactions among random variables more concisely with a smaller number of variables .",
    "the auto - encoding layer is made possible as a result of the sparsity inherent in the structure of many types of data that are measured in a higher dimension than that needed to represent the data .",
    "in essence the auto - encoding layer is representing the data as a smaller set of variables that describe the data in a more concise manner .",
    "the interaction among variables are determined by extracting the interaction parameters from the auto - encoding layer variables instead of the variable @xmath1 . as a result eq .",
    "can be reformulated as @xmath5 where @xmath6 represents the auto - encoding layer where the number of its variables is much smaller than the number of output states .",
    "@xmath7 characterizes the auto - encoding layer based on the observation and , based on the chain rule principle , is added to eq .  .",
    "the role of the auto - encoding layer is to involve the fully connected relationship among nodes into the model implicitly .",
    "the auto - encoding layer is constructed based on a specific number of variables , where the number of variables determines the fineness of structure in the data that can be characterized by the model ( e.g. , auto - encoding layers with fewer number of variables assume greater sparsity in the structure of the data and thus characterizes structure in the data more coarsely than when a higher number of variables are used ) .    to fully utilize the different concise structure characterization properties of the auto - encoding layer ,",
    "a deep structure is used during the modeling .",
    "this results in the deep - structured fully - connected random field ( dfrf ) as shown in fig .",
    "[ fig : deepmodel ] .",
    "it is important to note that the configuration setup of the auto - encoding layers can be fine to coarse structure characterization or coarse to fine structure characterization depending on the specific application .",
    "the coarse to fine configuration is utilized in this study for the problem of image segmentation described in the next section .    ) and label layer(@xmath8 ) .",
    "the layer @xmath9 is provided by finite mixture model ( fmm ) model and is an initialization for layer @xmath10 .",
    "each node of layer @xmath11 is connected to all nodes in label layer @xmath8 .",
    "more information are provided to the model by increasing the number of nodes in the auto - encoding layers from the bottom to the top of the model . ]    to represent the proposed model mathematically , the joint probability distribution of labels @xmath1 and observation @xmath0 is formulated as a chain product of the conditional probability of labels given observation , auto - encoding variables , and previous layer of labels , multiplied by the joint probability of observation and auto - encoding variables ( see eq .",
    "( 4 ) , where @xmath8 represents the label layer of @xmath12 , @xmath11 is the auto - encoding layer corresponding to layer @xmath12 , and the number of layers is @xmath13 ) .",
    "@xmath14    although there is no intra - layer connections among variables , the inter - layer interaction is fully connected and as such the interaction parameters among random variables in the label layer are computed by use of the auto - encoding layer . therefore , the two aforementioned probabilities together are expressing a fully connected graphical model .",
    "we use dfrf for interactive image segmentation to illustrate the feasibility of dfrf for structured inference in a computationally tractable manner .",
    "interactive image segmentation is a type of binary classification in which each pixel in an image must be classified as foreground ( object ) or background based on a small set of user annotated pixels as illustrated in fig .",
    "[ fig : interactiveseg ] .        a simple approach to tackle this problem is to learn a model based on the available training data , such as a gaussian mixture model ( gmm ) or non - parametric histogram model , and apply the trained model to the image .",
    "however , this simple approach does not take into account the structure of the data . as a result , a common approach to tackle this problem is to use the trained model as the unary potential in a pairwise markov random field ( mrf ) where the mrf enforces structural consistency .    here ,",
    "we utilize two finite mixture models ( fmm ) to model the background and foreground distributions and use them to define the first layer @xmath9 in the deep structure model : @xmath15 where @xmath16 is the set of trained mixture model parameters based on user annotated pixels .",
    "the results of layer @xmath9 are propagated to the next layer ( i.e. @xmath10 ) by means of auto - encoding layer @xmath17 .",
    "each auto - encoding layer @xmath11 is constructed by maximizing the joint probability @xmath18 .",
    "the role of auto - encoding layer is to represent the structure of the image data in a concise manner using a smaller set of variables .",
    "each auto - encoding layer characterizes the structural properties of the image data concisely at a certain fineness level as specified by the number of nodes in that layer .",
    "the joint probability @xmath18 is modeled by a fmm as well : @xmath19 where @xmath20 represents the mixture model parameters .",
    "the number of parameters @xmath21 is different for each auto - encoding layer based on the level the sparseness of the layer .",
    "each node in the auto - encoding layer conveys the interactions of a random variable in the label layer with other random variables based on a specific image data structure . on the other hand ,",
    "the interactions among random variables in a label layer @xmath8 are expressed by the nodes in the lower adjacent auto - encoding layer @xmath11 that determines the weights and , therefore , the random variables in label layer @xmath8 are fully connected implicitly .",
    "the state of each random variable in the label layer @xmath8 is obtained by a conditional probability given the auto - encoding layer @xmath11 , observation @xmath0 and the previous label layer @xmath22 : @xmath23 where the conditional probability is formulated as a gibbs distribution  @xcite by the exponential of negative energy of the layer .",
    "@xmath24 is the constant normalization and @xmath25 is the energy of the layer .",
    "the interaction weight between two random variables is computed based on their connections regarding to the auto - encoding layer .",
    "each random variable in the label layer @xmath8 has two possible states , 0 and 1 determining the background or the foreground states .",
    "the energy in the layer @xmath8 is minimized based on maximum a posterior ( map ) approach .",
    "the map framework tries to minimize the energy @xmath25 of layer @xmath8 based on the observation and image data structural properties as characterized by auto - encoding layer @xmath11 .",
    "the computed state configuration of layer @xmath8 is passed to the layer @xmath26 after each optimization .",
    "a step - by - step summary of image segmentation by dfrf is presented in algorithm  [ alg1 ] .",
    "set @xmath27 and @xmath28 @xmath29 @xmath30   ( the layer number ( @xmath12 ) ) _ loop _ : find the auto - encoding layer @xmath31@xmath27@xmath32 @xmath33 @xmath34 increase @xmath27 if i<=n then * goto * _ loop _ _ endloop _    [ alg1 ]",
    "in this study , we use natural images to study the performance of the dfrf model for interactive image segmentation .",
    "natural images from the weizmann segmentation evaluation database  @xcite and the cssd complex scene database  @xcite were used in this study .",
    "the weizmann database consists of two different datasets both with manual segmentation ground truth : i ) a single - object dataset consisting of 100 images , and ii ) a two - objects dataset consisting of 100 images .",
    "the cssd database consists of 200 images with manual ground truth .",
    "furthermore , to study binary classification performance at different noise levels , each of the images in the two datasets from the weizmann database as well as the dataset from the cssd database were also contaminated by white gaussian noise with standard deviations at 25% and 50% of the dynamic range of the image , resulting in a total of 1200 different image permutations used in the analysis .",
    "a small set of seed pixels in the foreground and background are provided by the authors ( fig .",
    "[ fig : interactiveseg](a ) ) .",
    "all methods were compared based on the same annotated seed pixels .",
    "to quantitatively evaluate segmentation performance , we compute the f@xmath35-score as follows  @xcite : @xmath36 where @xmath37 denotes true positive pixels , @xmath38 denotes false negative pixels , and @xmath39 denotes false positive pixels .    our dfrf method is compared to the inference method for fully - connected crfs proposed by  @xcite ( which we will refer to as fcrf ) using the implementation provided by the authors  @xcite .",
    "fcrf is the state - of - the - art method for structured inference using fully - connected graphical models .",
    "this method was also chosen for comparison because it had been shown  @xcite that fcrf performs better than state - of - the - art approaches such as grid crfs  @xcite and @xmath40  crf  @xcite . for a fair comparison ,",
    "the same 5-component gmm model used for the dfrf is used as the unary potential for the fcrf approach .",
    "the dfrf has the following three parameters : i ) the number of layers , ii ) the number of encoding nodes at each sparse encoding layer ( i.e. , @xmath27 ( see algorithm  [ alg1 ] ) ) , and iii ) the set of trained mixture models for layer @xmath9 ( i.e. , @xmath16 ( see eq .  ) ) .",
    "for our interactive image segmentation problem , we use 15 layers , and the number of encoding nodes at each sparse encoding layer is set to 450 - 660 nodes ( increasing by @xmath4115 nodes between each layer and a 5-component gaussian mixture model ( gmm ) is trained with the annotated samples and used for layer @xmath9 in the dfrf .",
    "these parameters were found to provide strong classification performance based on comprehensive testing .",
    "the dfrf is implemented in matlab ( the mathworks , inc . ) and can classify a 300 @xmath42 200 colour image ( a total of 900,000 state nodes for this configuration ) in @xmath4160s on an intel(r ) core(tm ) i5 - 3317u cpu at 1.70ghz cpu with 4 gb ram .",
    "the fcrf was implemented in c++ by the authors of  @xcite , and can classify a 300 @xmath42 200 colour image in @xmath410.48s .",
    "the f@xmath35-score achieved by the tested methods at the various noise levels for the weizmann single - object dataset , the weizmann two - objects dataset , and the cssd dataset are shown in table  [ tab : f1-scoreoneobj ] , table  [ tab : f1-scoretwoobj ] , and table  [ tab : f1-scorecssd ] respectively .",
    "it can be observed that the binary image segmentation results produced using the dfrf model for the noise - free scenarios is comparable to the state - of - the - art fcrf method for the weizmann single - object case . for the weizmann two - object case",
    ", we see that dfrf performs slightly better than fcrf by @xmath412% for the noise - free scenario . for the cssd case",
    ", we see that fcrf performs slightly better than dfrf by @xmath41 1% for the noise - free scenario .",
    ".f@xmath35-score for weizmann single - object dataset . [ cols=\"<,^,^,^,^\",options=\"header \" , ]     [ tab : f1-scorecssd ]    example segmentation results for weizmann single - object and two - object datasets are shown in fig .",
    "[ fig3 ] and fig .",
    "[ fig4 ] , respectively .",
    "dfrf and fcrf preserve image structure much better than the baseline gmm method ( used as unary ) which has no structural cues . the lack of structural cues results in noise - like appearance in the segmentation as seen in fig .",
    "[ fig4](c ) and ( r ) .",
    "furthermore , the fully connected random field model allows both dfrf and fcrf to capture elongated and thin object boundaries ( see the metal posts in fig .",
    "[ fig3]j , wooden fence post in fig .",
    "[ fig3]t , and the light post in fig .",
    "[ fig4]e ) .        unlike fcrf",
    ", the deep - structure of our dfrf method allows us to handle slight variations in the observation that is not fully modeled by the small set of seeds provided by the user .",
    "for example , the sky and water in fig .",
    "[ fig4 ] have slight variation in illumination and texture which are not captured by the user annotation . as a result ,",
    "the fcrf method starts misclassifying regions of the sky and water as foreground . however , our dfrf method is better able to handle these variations and correctly classify the entire sky and water as background .",
    "dfrf s ability to handle variations in observation , due to its deep structure , can clearly be seen when we add noise to the image .",
    "quantitatively , from table  [ tab : f1-scoreoneobj ] , table  [ tab : f1-scoretwoobj ] , and table  [ tab : f1-scorecssd ] , we can see that dfrf clearly outperforms fcrf under the presence of noise for all datasets .",
    "visually , from fig .",
    "[ fig5 ] , we can see that under the presence of noise fcrf starts to degrade and fails to maintain structural cues . on the other hand",
    "our dfrf method is able to handle the uncertainty in the observation and can better segment the image , even under presence of strong noise .",
    "in this study , the feasibility of unifying fully - connected and deep - structured models in a computationally tractable manner for the purpose of structured inference was investigated through the introduction of a deep - structured fully - connected random field ( dfrf ) model with sparse auto - encoding layers . by incorporating intermediate sparse auto - encoding layers between state layers to condense node - to - node interactions , we were able to significantly reduce the computational complexity of the inference process .",
    "a quantitative performance analysis of the dfrf model for the problem of interactive image segmentation was performed to illustrate the feasibility of using the dfrf for structured inference in a computationally tractable manner .",
    "results in this study show that it is feasible to unify fully - connected and deep - structured models in a computationally tractable manner for solving structured inference problems such as image segmentation .",
    "given the promising results , we aim in the future to investigate alternative auto - encoding approaches to better condense node - to - node interactions , as well as strategies for automatically determining the number of auto - encoding nodes to use for each auto - encoding layer .",
    "furthermore , we aim in the future to explore the efficacy of the dfrf for solving other types of large - scale , vision - domain structured inference problems such as image reconstruction  @xcite , image decomposition and representation  @xcite , image restoration  @xcite , and saliency detection  @xcite .",
    "this work was supported by the natural sciences and engineering research council of canada , canada research chairs program , and the ontario ministry of research and innovation .",
    "j. lafferty , a. mccallum and f. pereira , ",
    "conditional random fields : probabilistic models for segmenting and labeling sequence data , \" proc . international conf .",
    "machine learning , vol .",
    "282 - 289 , 2001 .",
    "j. shotton , j. winn , c. rother and a. criminisi , `` textonboost for image understanding : multi - class object recognition and segmentation by jointly modeling texture , layout , and context , '' ijcv , vol .",
    "81 , pp . 2 - 23 , 2009 .",
    "a. wong , a. mishra , p. fieguth and d. clausi , `` sparse reconstruction of breast mri using homotopic l0 minimization in a regional sparsified domain , '' ieee trans .",
    "743 - 752 , 2010 .",
    "d. liang , h. wang and l. ying , `` sense reconstruction with nonlocal tv regularization , '' proc .",
    "1 , pp . 1032 - 1035 , 2009",
    ". m. frankovich and a. wong , `` enhanced seam carving via integration of energy gradient functionals , '' ieee signal processing letters , vol . 18 , pp .",
    "375 - 378 , 2011 .",
    "a. mishra , a. wong , d. clausi and p. fieguth , `` quasi - random nonlinear scale space , '' pattern recognition letters , vol .",
    "1850 - 1859 , 2010 .",
    "a. wong and d. clausi , `` aisir : automated inter - sensor / inter - band satellite image registration using robust complex wavelet feature representations , '' pattern recognition letters , vol .",
    "1160 - 1167 , 2010 .",
    "p. siva and a. wong , `` grid seams : a fast superpixel algorithm for real - time applications , '' proc .",
    "127 - 134 , 2014 .",
    "a. moore , s. prince , j. warrell , and u. mohammed , `` superpixel lattices , '' proc .",
    "cvpr , pp . 1 - 8 , 2008 .",
    "a. wong and j. orchard , `` robust multimodal registration using local phase - coherence representations , '' journal of signal processing systems , vol .",
    "89 - 100 , 2009 .",
    "a. wong and a. mishra , `` generalized probabilistic scale space for image restoration , '' ieee transactions on image processing , vol .",
    "2774 - 2780 , 2010 .",
    "a. wong , p. fieguth and d. clausi , `` a perceptually adaptive approach to image denoising using anisotropic non - local means , '' proc .",
    "icip , vol .",
    "537 - 540 , 2008 .",
    "y. li and d. huttenlocher , `` sparse long - range random field and its application to image denoising , '' proc .",
    "eccv , vol .",
    "344 - 357 , 2008 .",
    "m.  j. shafiee , s. haider , a. wong , d. lui , a. cameron , a. modhafar , p. fieguth and m. haider , `` apparent ultra - high b - value diffusion - weighted image reconstruction via hidden conditional random fields , '' ieee transactions on medical imaging , vol .",
    "pp , pp . 1 - 14 , 2015",
    ".      j. yang and m. yang , `` top - down visual saliency via joint crf and dictionary learning , '' proc .",
    "cvpr , vol .",
    "1 , pp . 16 - 21 , 2012 .",
    "a. jain and a. wong and p. fieguth , `` saliency detection via statistical non - redundancy , '' proc .",
    "icip , pp .",
    "1073 - 1076 , 2012 ."
  ],
  "abstract_text": [
    "<S> there has been significant interest in the use of fully - connected graphical models and deep - structured graphical models for the purpose of structured inference . </S>",
    "<S> however , fully - connected and deep - structured graphical models have been largely explored independently , leaving the unification of these two concepts ripe for exploration . </S>",
    "<S> a fundamental challenge with unifying these two types of models is in dealing with computational complexity . in this study </S>",
    "<S> , we investigate the feasibility of unifying fully - connected and deep - structured models in a computationally tractable manner for the purpose of structured inference . to accomplish this </S>",
    "<S> , we introduce a deep - structured fully - connected random field ( dfrf ) model that integrates a series of intermediate sparse auto - encoding layers placed between state layers to significantly reduce computational complexity . </S>",
    "<S> the problem of image segmentation was used to illustrate the feasibility of using the dfrf for structured inference in a computationally tractable manner . </S>",
    "<S> results in this study show that it is feasible to unify fully - connected and deep - structured models in a computationally tractable manner for solving structured inference problems such as image segmentation .    </S>",
    "<S> a deep - structured fully - connected random field model for structured inference    random fields , structured inference , deep structured , fully connected , learning , image , segmentation </S>"
  ]
}