{
  "article_text": [
    "after the discovery of the @xmath1 gev higgs boson at the large hadron collider @xcite , we have a complete picture of the standard model ( sm ) of particle physics .",
    "the next step beyond the sm could be the identification of the dark matter ( dm ) particles that were suggested to be widely present in the universe by a series of astronomical observations . although the astronomical evidence could be attributed to gravitational interactions between dm and sm particles",
    ", we are yet to exclude the possibility of weakly interacting massive particles ( wimps ) .",
    "the potential weak interactions between dm and sm particles provide us with the opportunity to identify dm , directly via collisions between dm particles and underground targets or indirectly via the products of dm annihilation or decay in the universe .",
    "many efforts have been made to find a direct signal of dm in an underground detector ; however , no convincing evidence has been found till date  @xcite . on the other hand , with the operation of several new - generation space telescopes and detectors , such as pamela , ams-02 , and fermi",
    ", many anomalies have been found in the high - energy sky @xcite .",
    "the uncertainties from astrophysical backgrounds and/or astrophysical sources , however , make the identification of possible dm signals more challenging .",
    "nevertheless , the constraints on dm models have become more and more stringent with the new direct and indirect data .",
    "some of these constraints depend on certain assumptions about the backgrounds ( e.g. , the positron anomaly @xcite ) . since there is no consistent signal of dm present in all observations , we may expect that the assumptions of astrophysical contributions to those anomalies are reasonable .",
    "the combination of various kinds of observations is expected to give much improved constraints on dm models , which is one of the motivations for developing this tool for calculating the dm likelihood .",
    "another motivation is that it is non - trivial to confront dm models with observational data due to the complicated astrophysical backgrounds .",
    "first , a proper modeling of the backgrounds , with possible systematic uncertainties ( e.g. , the cosmic ray ( cr ) propagation parameters ) , is necessary when calculating the likelihood of a dm signal .",
    "second , it is better to decouple the dm model inputs from the following astrophysical processes , as it enables our tool to be applied to any dm particle model .",
    "third , we intend to have an efficient computation of the dm signal as well as the backgrounds . with these goals",
    ", we develop this likelihood calculator of dm detection , .",
    "the basic function of  is to deal with the intermediate steps between a dm model and data . to achieve this goal ,",
    "we 1 ) calculate the propagation of cr electrons / positrons and antiprotons with green s functions with respect to energy ( e.g. , integrated with space and time ) , 2 ) model the cr backgrounds with phenomenological forms , 3 ) model the @xmath0-ray emission with standard fermi - lat diffuse emission templates and point sources , and 4 ) calculate the likelihood map of @xmath0-rays on the `` energy - flux '' plane for given regions of interest ( rois ) .",
    "some works have been published based on parts of these methods @xcite . here",
    "we present the first version of this tool and make the code publicly available in the community and summarize the details in this manual .",
    "constraints from direct detection have not been included in this release , and will be added in the subsequent version .",
    "this manual is structured as follows . in sec .  [",
    "sec : charge ] , we describe the calculation of charged crs from both the dm signal and the background .",
    "the green s function for fast computation of the propagation of charged crs is presented . in sec .",
    "[ sec : gamma ] , we describe the likelihood calculation from fermi - lat observations of dwarf spheroids ( dsphs ) .",
    "we give the energy - flux likelihood map with updated fermi - lat data .",
    "we introduce the code , installation procedure , and explain the usage of  in sec .",
    "[ sec : manual ] . finally , we summarize in sec .  [",
    "sec : sum ] .",
    "the charged cosmic rays ( crs ) propagate diffusively in the random magnetic field of the milky way .",
    "the interaction with the interstellar medium ( ism ) will result in energy losses and/or fragmentation of the primary crs , as well as the production of secondary crs . for electrons",
    "/ positrons , there will be additional energy losses due to radiation in the interstellar radiation field ( isrf ) and the magnetic field .",
    "the random shocks in the interstellar space may reaccelerate the low - energy cr particles .",
    "there may also be convective transport of crs as evidenced by the wide existence of galactic winds .",
    "the general propagation equation of crs in the milky way can be written as @xcite @xmath2- \\frac{\\psi}{\\tau_f}-\\frac{\\psi}{\\tau_r } , \\label{prop}\\end{aligned}\\ ] ] where @xmath3 is the cr differential density per unit momentum interval , @xmath4 is the source function , @xmath5 is the spatial diffusion coefficient , @xmath6 is the convection velocity , @xmath7 is the diffusion coefficient in momentum space , @xmath8 is the momentum loss rate , and @xmath9 and @xmath10 are timescales for fragmentation and radioactive decay , respectively",
    ". a homogeneous spatial diffusion coefficient @xmath5 is assumed , and the rigidity dependence is assumed to be of a power - law form @xmath11 , with @xmath12 being the velocity of the particle and @xmath13 reflecting the property of the ism turbulence . for kolmogrov turbulence , we have @xmath14 .",
    "the reacceleration is described by diffusion in momentum space .",
    "the momentum diffusion coefficient @xmath7 can be related to the spatial diffusion coefficient @xmath5 by @xcite @xmath15 where @xmath16 is the alfven speed , and @xmath17 characterizes the level of turbulence which can be absorbed in @xmath16 .",
    "the crs are assumed to be confined in an extended halo with characteristic height @xmath18 , beyond which free escape is assumed .",
    "thus , the major propagation parameters are @xmath19 , @xmath13 , @xmath16 , @xmath20 and @xmath18 .    the secondary - to - primary ratios , such as b / c and ( sc+ti+v)/fe , and the unstable - to - stable ratios of secondary particles , such as @xmath21be/@xmath22be and @xmath23al/@xmath24al are often used to determine the propagation parameters @xcite .",
    "there are numerical codes to compute cr propagation in the galaxy , such as galprop @xcite and dragon @xcite .    in this tool",
    ", we adopt galprop version 50 to calculate the propagation of charged particles .",
    "we adopt six sets of propagation parameters , with @xmath18 varying from @xmath25 kpc to @xmath26 kpc , which reflect the major uncertainties in the propagation parameters @xcite .",
    "all groups are consistent with the b / c data as well as the fermi diffuse @xmath0-ray emission data @xcite .    .propagation parameters . [ cols=\"^,^,^,^,^ \" , ]     [ table : bkg ]                when a dm component is added to the model , we should allow for some freedom in the backgrounds to obtain a global best - fit to the data .",
    "therefore , we multiply by factors of @xmath27 , with @xmath28 , on the primary electrons , the secondary positrons / electrons , the extra positrons / electrons and the secondary antiprotons .",
    "we adopt the profile likelihood method to manage the nuisance parameters @xmath29 and @xmath30 , with the scan ranges @xmath31 $ ] and @xmath32 $ ] , respectively .",
    "the code ` minuit `  @xcite is used to find the maximum likelihood within the parameter space @xmath33 $ ] .",
    "the low - energy charged crs will be modulated by solar activity .",
    "we adopt the simple force - field approximation with only one parameter , _ viz . _ the modulation potential , to calculate the effect of solar modulation @xcite .",
    "since our background model is an empirical one instead of a physical model , the solar modulation only applies to the cr fluxes from the dm annihilation or decay .      in this subsection",
    "we present some results on the dm model parameter constraints from charged crs derived with the above method .",
    "we adopt a dm annihilation scenario for illustration , and assume that the dm density profile is nfw",
    ". given one set of the dm model parameters , such as the mass , the annihilation cross section , and the branching ratios to each annihilation channel , we calculate the production spectra of positrons and antiprotons using the tables . ] of ref .",
    "the propagated fluxes , calculated with the aforementioned green s function method , together with the backgrounds , are then combined with the data to derive the likelihood , @xmath34 , of this particular set of dm parameters .             the top - left panel of fig .",
    "[ fig : con ] shows a map of @xmath35 , where @xmath36 is the likelihood of the model with different values of @xmath37 and @xmath38 , and @xmath39 is the likelihood for the null hypothesis ( _ i.e_. , pure background ) .",
    "the likelihood is calculated using the ams-02 @xmath40 data .",
    "the propagation model is # 2 , the solar modulation potential is 0.5 gv , and the dm annihilation channel is assumed to be @xmath41 .",
    "the dashed line shows the @xmath42 confidence level ( cl ) upper limit , defined by @xmath43 for a single - sided probability distribution .",
    "other panels of fig .",
    "[ fig : con ] illustrate the @xmath42 upper limits of the dm annihilation cross section for different channels ( top - right ) , propagation models ( bottom - left ) , and solar modulation potentials ( bottom - right ) .",
    "gamma - rays are another very important messenger for the indirect detection of dm .",
    "gamma - rays travel through space without deflection , thus they can point back to the sources emitting them . it is advantageous to choose regions in the sky with high dm density and low astrophysical background to search for dm .",
    "the dsphs in the milky way are widely believed to be favorable targets with a high signal - to - noise ratio .",
    "many works have been performed to search for dm - induced @xmath0-rays from dsphs with fermi - lat data , yet none of them reported a significant detection @xcite .",
    "recently , the ongoing dark energy survey ( des ) reported some new candidates of dsphs in the southern hemisphere @xcite .",
    "several groups had claimed possible weak @xmath0-ray signals from reticulum 2 @xcite and tucana iii @xcite . since there are no reliable kinematic measurements available for these newly - discovered dsphs candidates ( hence no reliable dm density profiles ) , the constraints and implications on dm from them are very uncertain .",
    "we adopt the dsphs sample of ref .",
    "@xcite in .      to ensure an easy computation of the total likelihood for any given shape of @xmath0-ray spectrum , we take the likelihood map method first proposed in our earlier work  @xcite and further developed in refs .",
    "@xcite . briefly speaking ,",
    "the likelihood @xmath44 of any flux @xmath45 in each energy bin @xmath46 $ ] is calculated to give a likelihood map on the ( @xmath47 ) plane .",
    "the total likelihood of a given spectrum can be simply obtained through a product of the likelihoods over all energy bins .",
    "this method is dm particle model independent , flexible and time - saving .",
    "also , as shown in ref .",
    "@xcite , it is simple to combine this method with data from other observations .",
    "we describe the method in more detail .",
    "dm annihilation in dsphs is adopted for illustration radius integration , from the markov chain monte carlo ( mcmc ) fittings to the kinematic data of dsphs @xcite to generate normalized two - dimensional * spatialmap*. then we calculate the likelihood map for these extended sources . for j - factors and corresponding errors",
    "please see ref .",
    "@xcite . ] .",
    "the case of dm decay can be easily obtained via proper re - adjustment of the formula ( see e.g. , eq .",
    "( [ source ] ) ) .",
    "the @xmath0-ray flux from the annihilation of dm in a dsph is @xmath48 where @xmath49 is the so - called @xmath50-factor which characterizes the amount of annihilation from a specified direction given the density distribution @xmath51 of dm . as the bin widths are small , for each energy bin @xmath46 $ ] , we approximate @xmath52 with a constant , @xmath53 .",
    "this approximation enables us to calculate the total log - likelihood of the spectrum @xmath54 from the logarithm of the likelihood map @xmath44 as @xmath55    we use the standard fermi science tools package  @xcite version v10r0p5 to analyze the fermi - lat data .",
    "we use the newly released fermi pass 8 data , with four subsets of different point spread function ( psf ) levels ( i.e. , psf0 , psf1 , psf2 and psf3 ) , recorded from 4 august 2008 to 4 august 2015 .",
    "these data are selected from 10@xmath56 10@xmath57 box regions centered on each dsph , and 500 mev to 500 gev energies to reduce the impact from the bright earth limb due to the large psfs at low energies .",
    "the events with zenith angles greater than 100@xmath57 are also excluded .",
    "these selected data are divided into 100 @xmath58 100 spatial bins with 0.1@xmath57 bin size and 24 logarithmically spaced energy bins .",
    "using the suggested diffuse background model including a structured galactic component and an isotropic component , as well as point sources within 15@xmath57 of each dsph from the third fermi catalog ( 3fgl ; @xcite ) as astrophysical background , we first carry out a standard binned likelihood fitting over the entire energy range to get the best - fitting parameters for each point source and the diffuse components .",
    "then we fix all the parameters of diffuse backgrounds and known point sources in the roi , and add a point source at the position of the dsph . on varying the flux from the newly added point source , we calculate the @xmath59 for the @xmath60th dsph and @xmath61th subset of data in each energy bin and sum over @xmath61 to obtain the likelihood map @xmath62 for the @xmath60th dsph .      if the @xmath50-factors of dsphs are known , then we can define a new variable , @xmath63 , and derive a combined log - likelihood map on the ( @xmath64 ) plane by adding the log - likelihoods of all dsphs together .",
    "[ fig : lkmp ] shows a combined log - likelihood map on the @xmath65 plane , from the 15 dsphs as listed in ref .",
    "the @xmath50-factors of the dsphs are taken from ref .",
    "the solid line shows the one - sided 95% confidence limit obtained from @xmath66 , where @xmath67 is the likelihood for null - hypothesis ( i.e. , @xmath68 ) for the @xmath69th energy bin . for any spectrum @xmath70",
    ", the combined log - likelihood can be derived via a sum of log - likelihoods in all energy bins",
    ".        however , in general the @xmath50-factors of dsphs can not be well determined .",
    "if that is the case , we may not be able to have a combined likelihood map ( such as that in fig . [",
    "fig : lkmp ] ) which is independent of @xmath50-factors - factors in the likelihood function for each energy bin , and obtained a combined likelihood map .",
    "however , this method multi - counts the @xmath50-factor uncertainties . a proper treatment",
    "should first combine likelihoods in different energy bins and then apply the @xmath50-factor likelihoods @xcite . ] .",
    "we can define a likelihood term due to the uncertainties in @xmath50-factors as @xcite @xmath71^{2}/{2\\sigma_k^2}},\\ ] ] where @xmath60 represents the @xmath60th dsph , @xmath72 is the `` real '' value of the @xmath50-factor and @xmath73 is the measured @xmath50-factor with error @xmath74 .",
    "the joint log - likelihood is then @xmath75 maximizing the above joint log - likelihood by varying @xmath72 for each dsph , we can obtain the final log - likelihood of the spectrum @xmath54 .    in fig .",
    "[ fig : dwarf_limit ] we show the combined 95% upper limits for the @xmath76 annihilation channel .",
    "here we adopt the @xmath50-factors given in ref .",
    "the two solid lines show the differences between the cases with ( green ) and without ( red ) uncertainties in @xmath50-factor measurements .",
    "it shows the potential to improve the constraints with better determination of the @xmath50-factors .",
    "in this section we describe the structure of the  code .",
    "users can download the source code from ref .",
    "@xcite or the batch file from the ancillary files to this paper on the arxiv website .",
    "is written in ` fortran95 ` , with a ` python ` interface .",
    "uses the external package ` minuit `  @xcite to maximize the likelihoods , which needs to be installed first . to install pylikedm ,",
    "the `` ` f2py ` '' package is required .",
    "we provide a ` bash ` script ( create_likedm.sh ) for quick installation . after running create_likedm.sh ,",
    "the user is prompted to enter a method of ` pyminuit ` installation :    ./create_likedm.sh",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + start installing pyminuit + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + # two ways to install pyminuit : # ( enter `` use_pip '' or `` local '' and other keys for doing nothing . ) local . .",
    "end installing pylikedm enjoy use",
    "!    there are three options : use_pip , ` local ` , and any other key .",
    "if one chooses use_pip , ` sudo ` authorization is required to install ` iminuit ` via ` pip ` .",
    "if the user does not have ` pip ` installed , he / she can install ` pyminuit ` by using the ` local ` option .",
    "this step can be skipped if ` pyminuit ` has already been installed .    has been successfully installed and tested under ` scientific linux ` , ` fedora ` , and ` ubuntu ` operating systems .",
    "the  code can be called by    ./pylikedm.py likedm_input_example.ini [ dnde.spec ]    where ` likedm_input_example.ini ` is an example file of the input parameters ( see below part c for details ) , and the argument ` dnde.spec ` is optional , depending on the value of the logical parameter ` use_pppc4 ` . if ` use_pppc4=t ` , then the dm annihilation or decay yield spectrum @xmath77 is computed using the ` pppc4 ` tables @xcite .",
    "otherwise , the file ` dnde.spec ` with the spectrum generated by the user needs to be provided .",
    "the output looks like    likedm ( version 1.0 )    * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *  dsphs result : delta [ chisq/-2ln(likelihood ) ] > > > > > fermi_dsphs : 1.3990486012771726  dsphs result : delta [ chisq/-2ln(likelihood ) ] < < < < < * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *    * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *  charged particle result > > > > > ams02efr : 41.720980097527232 ams02e+ : 27.994316562248855 ams02e- : 33.345732360973315 ams02e+e- : 28.933019605100434 ams02_total_ep : 131.99404862584984    pamela_pbar : 11.168610838448940  charged particle result <",
    "< < < < * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *      we provide an example of the input file , ` likedm_input_example.ini ` , in the main folder of :    . .",
    "likedm2016 # see all the information ? # 0 for chisq results # 1 for inputs # 2 for fitting ( alpha , beta ) # 3 for input dnde # 4 for propagated fluxes of e+ and pbar # 5 for individual dsph spectrum # > = 6 for fitting results in each step , very slow !",
    "seebug=0 # debug_level    # which gamma - ray likelihood map you are going to include ? # ( the way to generate likelihood map can be found in arxiv 1212.3990 ) # optimal likelihood map for annihilation dm dsphs_map=./dat / galikemap / likelihood_fix_p8_psf0123.dat # optimal likelihood map for decaying dm # dsphs_map=./dat / galikemap / likelihood_ext_psf0123.dat    # solor modulation potential epmod=0.6 # gv , positron apmod=0.6 # gv , antiproton    # what is the dm halo you want to use during propagation ?",
    "whathalo=1 # whathalo , 1 for nfw , 2 for einasto and 3 for isothermal    # 6 propagation parameters combination # see propagation model in 1205.6474 .",
    "# 1 - 6 correspond to table i from left to right .",
    "whatgalprop=2 # propagation parameters combination    use_dsphs = t # use_dsphs use_ep = t # use_ep use_ap = t # use_ap    # if users want to compute decaying dm , this flag should be true . # then",
    ", code will read decay_time instead of sigmav .",
    "decaydm = f    dmmass=104.00 sigmav=1e-26 # sigma v [ cm^3/s ] for annihilation decay_time=1e26 # tau [ s ] for decay    # t : use pppc4 table # false : use external table from 2nd arguement , ./likedm.exe",
    "likedmexample.ini dnde.txt use_pppc4= t # use pppc4 dnde    # branch ratio of xx- >",
    "sm sm or x - > sm sm br_3=0.0 # e br_6=0.0 # mu br_9=0.0 # tau br_12=1.0 # b br_16=0.0 # w br_19=0.0 # z    this input format is exactly the same as that in ` cosmomc ` @xcite and ` superbayes `  @xcite .",
    "the modules to read the input file are ` src / read_parameters.py ` and alternatively ` src / inifile.f90 ` .",
    "the parameters are explained below :    * ` output_name ` + the name of the prefix of the output files . for the python interface ,",
    "this is not used because the output is shown on the screen .",
    "however , a user can always modify the subroutine ` print_debug_info ` to store the output with the name defined by this flag",
    ". * ` seebug ` + an integer number to control the debug information shown on the screen . `",
    "seebug=0 ` to 6 will print different kinds of results , for debugging or any interesting outputs such as the pre- or post - propagated particle spectra , and the fitting results of nuisance parameters . * ` dsphs_map ` + likelihood map of dsphs .",
    "the full path of the map is needed . for the case of decaying dm , the optimal likelihood map is recommended . * ` epmod ` and ` apmod ` + solar modulation potentials in units of gv , for electrons / positrons and protons / antiprotons , respectively . * ` whathalo ` + an integer number to specify the dm halo profile . 1 for nfw , 2 for einasto and 3 for isothermal .",
    "* ` whatgalprop ` + an integer number to determine the propagation parameters . 1 to 6 corresponds to the six sets of propagation parameters given in ref .",
    "@xcite ( see also table [ table : prop ] of this manual ) . * ` use_dsphs ` , ` use_ep ` , and ` use_ap ` + logical flags to choose whether or not to use the corresponding data .",
    "the current version includes fermi @xmath0-ray data from dsphs , ams-02 @xmath40 data , and pamela @xmath78 data . * ` decaydm ` + logical flag to determine whether the dm annihilates or decays . * ` dmmass ` , ` sigmav ` , ` decay_time ` + the dm mass in gev , annihilation cross section in @xmath79s@xmath80 , and decaying lifetime in s , respectively . `",
    "sigmav ` takes effect when ` decaydm = f ` , and ` decay_time ` takes effects when ` decaydm = t ` . * ` use_pppc4 ` + logical flag to specify whether to use the pppc4 table to calculate @xmath77 .",
    "if ` f ` , an external file needs to be provided by the user . _",
    "the file needs to be 4 columns , with @xmath81 in gev , @xmath82 in gev@xmath80 , @xmath83 in gev@xmath80 , and @xmath84 in gev@xmath80 , respectively . _ * ` br_x ` + branching ratios for different channels when using the pppc4 table .",
    "the identification numbers can be found either at the ` pppc4 ` website or in the beginning of the file ` src / pythia_pppc4.f90 ` .",
    "the outputs include the computed @xmath85 values on the screen .",
    "users can easily modify the code ` src / monitorlikedm.f90 ` to generate their own favored outputs or store the outputs to a file .",
    "the source code of  is located in the ` src/ ` folder .",
    "the main routine is ` pylikedm.py ` for the ` python ` interface .",
    "we introduce the other routines grouped by their functionality :    *   + + .... src / readtable.f90 src / pythia_pppc4.f90 src / inifile.f90 .... + the routine ` src / readtable.f90 ` reads the tables of the dsph likelihood map , the green s functions for the propagation of positrons and antiprotons in the galaxy , and the dm annihilation / decay spectra @xmath77 either from pppc4 ( connected with ` src / pythia_pppc4.f90 ` ) or the user supplied external file .",
    "+ in addition to reading the tables , we also collect all the initialization subroutines in the ` src / readtable.f90 ` module and hence this module is the heart of .",
    "+ the module ` src / inifile.f90 ` is taken from ` cosmomc ` .",
    "it reads the parameter file and sets default values of the parameters .",
    "it is _ not _ used by default but a user can use this module if they wish to construct their own interface . *   + + .... src / gamma_dsphs.f90 .... + this module provides the computation of dm annihilation / decay fluxes from a set of dsphs and their combined likelihood .",
    "the @xmath50-factors of these dsphs have been implemented in the likelihood calculation with a profile likelihood method . by default ,",
    "a total of 15 dsphs , which are bootes i , canes venatici ii , carina , coma , draco , fornax , hercules , leo ii , leo iv , sculptor , segue i , sextans , ursa major ii , ursa minor , and willman i , are included in the current version of .",
    "users can enable or disable some dsphs likelihood by turning on / off the flags ` dsphs__use ` in the ` src / readtable.f90 ` module .",
    "the @xmath50-factors are taken from ref .",
    "@xcite for both annihilating and decaying dm . *   + + .... src / charge_bkg.f90 .... + this routine calculates the background fluxes of @xmath40 and @xmath78 using the empirical formulae described in sec .",
    "ii - c . *   + + .... src / charge_lepton.f90 src / charge_antip.f90 .... + these two routines compute the propagated fluxes of positrons and antiprotons from dm annihilation or decay , using the green s function method described in sec .",
    "ii - b . *   + + .... src / charge_data.f90 .... + this routine gives the cosmic ray data from ams-02 @xcite and pamela @xcite , and returns the calculated @xmath85 values for given theoretical fluxes . *   + + .... src / mathlib.f90   src / monitorlikedm.f90 src / main.f90   .... + the file ` src / mathlib.f90 ` provides some useful mathematical tools such as interpolation and integration .",
    "the routine ` src / monitorlikedm.f90 ` gives the outputs controlled by the flag ` seebug ` .",
    "we also have a main routine , ` src / main.f90 ` , which is currently _ not _ used in the ` python ` version but left as an alternative in the pure ` fortran ` version .",
    "we present a publicly - available tool , , for likelihood calculations in dm models .",
    "it enables fast computation of the likelihood of a given dm model ( defined by mass , cross section or decay rate , and annihilation or decay yield spectrum ) , without digging into the details of cr propagation , fermi - lat data analysis , or related astrophysical backgrounds .",
    "this code depends only on the ` minuit ` minimization package , and is easy to install and run .",
    "the code  also provides an easy framework that can be linked to any particle model or monte - carlo code to perform a global study .",
    "the currently released version ( v1.0 ) contains only the indirect detection data , including the electron / positron measurements by ams-02 , the antiproton measurements by pamela , and the @xmath0-ray observations from dsphs by fermi - lat .",
    "further developments with more data , e.g. , from the @xmath0-ray observations of the galactic center and isotropic background , as well as underground direct detection data , will be carried out soon .",
    "we thank vincent bonnivard who kindly provides the mcmc results about the profile parameters of dsphs , and andrew fowlie and shankha banerjee who carefully read and improve the presentation of the manuscript .",
    "y.s.t . was supported by world premier international research center initiative ( wpi ) , mext , japan .",
    "q.y . was supported by the national key program for research and development ( no .",
    "2016yfa0400200 ) and the 100 talents program of chinese academy of sciences .",
    "g.  aad _ et al . _ [ atlas collaboration ] , phys .",
    "b * 716 * , 1 ( 2012 ) [ arxiv:1207.7214 [ hep - ex ] ] .",
    "s.  chatrchyan _ et al . _",
    "[ cms collaboration ] , phys .",
    "b * 716 * , 30 ( 2012 ) [ arxiv:1207.7235 [ hep - ex ] ] .",
    "e.  aprile _ et al .",
    "_ [ xenon100 collaboration ] , phys .  rev .",
    "lett .   * 109 * , 181301 ( 2012 ) [ arxiv:1207.5988 [ astro-ph.co ] ] .",
    "d.  s.  akerib _ et al . _",
    "[ lux collaboration ] , arxiv:1310.8214 [ astro-ph.co ] .",
    "a.  w.  strong and i.  v.  moskalenko , astrophys .",
    "j.   * 509 * , 212 ( 1998 ) [ astro - ph/9807150 ] .",
    "d.  maurin , f.  donato , r.  taillet and p.  salati , astrophys .",
    "j.   * 555 * , 585 ( 2001 ) [ astro - ph/0101231 ] .",
    "a.  putze , l.  derome and d.  maurin , astron .",
    "astrophys .   * 516 * , a66 ( 2010 ) [ arxiv:1001.0551 [ astro-ph.he ] ] . c.  evoli , d.  gaggero , d.  grasso and l.  maccione , jcap * 0810 * , 018 ( 2008 ) [ arxiv:0807.4730 [ astro - ph ] ] . m.  ackermann _ et al . _",
    "[ lat collaboration ] , astrophys .",
    "j.   * 761 * , 91 ( 2012 ) [ arxiv:1205.6474 [ astro-ph.co ] ] .",
    "m.  ackermann _ et al .",
    "_ [ lat collaboration ] , astrophys .  j.   * 750 * , 3 ( 2012 )      j.  n.  bahcall and r.  m.  soneira , astrophys .  j.  suppl .   * 44 * , 73 ( 1980 ) .",
    "g.  bertone , m.  cirelli , a.  strumia and m.  taoso , jcap * 0903 * , 009 ( 2009 ) [ arxiv:0811.3744 [ astro - ph ] ] . c.  s.  shen , astrophys .",
    "j.  * 162 * , l181 ( 1970 ) .",
    "q.  yuan , x.  j.  bi , g.  m.  chen , y.  q.  guo , s.  j.  lin and x.  zhang , astropart .",
    "phys .   * 60 * , 1 ( 2015 ) [ arxiv:1304.1482 [ astro-ph.he ] ] .",
    "q.  yuan and x.  j.  bi , phys .",
    "b * 727 * , 1 ( 2013 ) [ arxiv:1304.2687 [ astro-ph.he ] ] .",
    "l.  feng , q.  yuan , x.  li and y.  z.  fan , phys .",
    "b * 720 * , 1 ( 2013 ) [ arxiv:1206.4758 [ astro-ph.he ] ] .",
    "l.  bergstrom , t.  bringmann , i.  cholis , d.  hooper and c.  weniger , phys .",
    "lett .   * 111 * , 171101 ( 2013 ) [ arxiv:1306.3983 [ astro-ph.he ] ] .",
    "t.  kamae , n.  karlsson , t.  mizuno , t.  abe and t.  koi , astrophys .",
    "j.   * 647 * , 692 ( 2006 ) [ erratum - ibid .   * 662 * , 779 ( 2007 ) ] [ astro - ph/0605581 ] .",
    "l.  accardo _ et al .",
    "_ [ ams collaboration ] , phys .",
    "lett .   *",
    "113 * , 121101 ( 2014 ) .",
    "m.  aguilar _ et al . _ [ ams collaboration ] , phys .",
    "* 113 * , 121102 ( 2014 ) .",
    "m.  aguilar _ et al .",
    "_ [ ams collaboration ] , phys .",
    "lett .   * 113 * , 221102 ( 2014 ) .",
    "o.  adriani _ et al .",
    "_ [ pamela collaboration ] , phys .",
    "lett .   * 105 * , 121101 ( 2010 ) [ arxiv:1007.0821 [ astro-ph.he ] ] .",
    "f.  james and m.  roos , comput .",
    "commun .",
    "* 10 * , 343 ( 1975 ) .    l.  j.  gleeson and w.  i.  axford , astrophys .",
    "j.   * 154 * , 1011 ( 1968 ) .",
    "m.  cirelli , g.  corcella , a.  hektor , g.  hutsi , m.  kadastik , p.  panci , m.  raidal and f.  sala _ et al .",
    "_ , jcap * 1103 * , 051 ( 2011 ) [ jcap * 1210 * , e01 ( 2012 ) ] [ arxiv:1012.4515 [ hep - ph ] ]",
    ". m.  ackermann _ et al .",
    "_ [ fermi - lat collaboration ] , phys .",
    "lett .   * 107 * , 241302 ( 2011 ) [ arxiv:1108.3546 [ astro-ph.he ] ] .",
    "the code can be downloaded from following websites .",
    "+ https://likedm.hepforge.org + https://github.com/likedm/likedm_v1.0 + http://www.space.pmo.cas.cn/aboutus/yuanqiang/likedm/201612/t20161226_358632.html"
  ],
  "abstract_text": [
    "<S> with the large progress in searches for dark matter ( dm ) particles with indirect and direct methods , we develop a numerical tool that enables fast calculations of the likelihoods of specified dm particle models given a number of observational data , such as charged cosmic rays from space - borne experiments ( e.g. , pamela , ams-02 ) , @xmath0-rays from the fermi space telescope , and underground direct detection experiments . the purpose of this tool </S>",
    "<S>  , likelihood calculator for dark matter detection  is to bridge the gap between a particle model of dm and the observational data . </S>",
    "<S> the intermediate steps between these two , including the astrophysical backgrounds , the propagation of charged particles , the analysis of fermi @xmath0-ray data , as well as the dm velocity distribution and the nuclear form factor , have been dealt with in the code . </S>",
    "<S> we release the first version ( v1.0 ) focusing on the constraints from indirect detection of dm with charged cosmic and gamma rays . </S>",
    "<S> direct detection will be implemented in the next version . </S>",
    "<S> this manual describes the framework , usage , and related physics of the code .    </S>",
    "<S> ipmu16 - 0037 + tum - hep-1039 - 16    1.25 cm    * program summary *    _ program title : _   + _ licensing provisions : gplv3 _ + _ programming language : fortran 90 and python _ + _ operating system : linux . </S>",
    "<S> _ + _ nature of problem : dealing with the intermediate steps between a dark matter model and data . </S>",
    "<S> _ + _ solution method : fast computation of the likelihood of a given dark matter model ( defined by a mass , cross section or decay rate , and annihilation or decay yield spectrum ) , without digging into the details of cosmic - ray propagation , fermi - lat data analysis , or related astrophysical backgrounds . _ </S>",
    "<S> +   + </S>"
  ]
}