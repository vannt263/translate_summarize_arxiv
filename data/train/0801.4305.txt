{
  "article_text": [
    "in the course of this paper , we investigate a model in which agents with different strategies participate in an simple investment scenario with noisy returns @xcite .",
    "we use this setup to approach the question how the ( internal ) complexity of agents enhances their performance in a hard - to - predict environment . in the field of artificial intelligence and complex systems",
    ", one can distinguish between two types of agents : first , agents which only react on external changes ( also known as `` zero - intelligence agents '' @xcite ) and second , agents which have a complex internal architecture ( e.g. `` belief - desire - intention agents '' ) . despite these clear differences in agent architecture , it is difficult to determine what influence these properties have on the overall performance of the agents . in order to study this question in a controlled environment , we have chosen an investment model with noisy returns , to compare the performance of simple and complex agents . to which extent is worthwhile to equip an agent with complex learning mechanisms instead of having a reactive response to exogenous returns ?    as a necessary step to study more complex scenarios , we are interested in an initial study of the performance of different agent architectures / investment strategies in the following simple setup : each agent has a certain budget @xmath0 and is able to invest a certain fraction of its budget on a market . the gain or loss it makes depends on the market return , or",
    "return on investment ( roi ) .",
    "in other words , at each time step @xmath4 , the agent adjust its risk propensity , the fraction of its budget that it are willing to invest on the market , denoted by @xmath1 , thereby controlling gains and losses resulting from the roi , denoted by @xmath2 .",
    "we assume that only the past and current values of @xmath2 are known to the agent ; it does not know the dynamics governing future values of @xmath2 .",
    "agents observe the market through the value of @xmath2 and , based on analysing a set of past @xmath2 values , they predict future @xmath2 values and determine their behaviour on that market through specifying @xmath1 .",
    "in this simple model , we consider agents that invest independently in the market , i.e. there is no interaction or communication with other agents . also , there is no feedback of the investments done by agents on the market return . in other words ,",
    "the _ environment _ of the agents is not influenced by their investments .",
    "this is a crucial assumption which makes our model different from other attempts to model real market dynamics , e.g. as for financial markets @xcite .",
    "consequently , we do not construct and investigate a market model ; rather , our focus lies on investigating what are good and what are bad strategies  in a rather artificial and controlled market environment ( see also section [ sec : returnoninvestment ] ) .",
    "regarding the relevance of our results for real financial markets , see also our comments in the concluding section [ sec : conclusions ] .     was computed for a current price @xmath5 as follows : @xmath6 .",
    "( b ) the dynamics of the market as indicated by the market return @xmath2 and the strategy as defined by the invested budget @xmath1 .",
    "note that our model does not consider the feedback of investments on the market dynamics ( dashed line).,width=253 ]     was computed for a current price @xmath5 as follows : @xmath6 .",
    "( b ) the dynamics of the market as indicated by the market return @xmath2 and the strategy as defined by the invested budget @xmath1 .",
    "note that our model does not consider the feedback of investments on the market dynamics ( dashed line).,width=253 ]    \\(a ) ( b )    the essence of the model is captured in figure [ fig : rq ] : ( a ) plots the returns in percent of a real stock item over the range of about two years .",
    "this illustrates the range and shape of values of returns of a real - world stock item .",
    "( b ) illustrates the dynamics of the model : @xmath2 , the market return , influences the strategies agents have to adjust @xmath1 , the risk propensity . in this particular model",
    ", we do not consider the influence that adjusted risk propensity has on the market return , i.e. the influence of @xmath1 on @xmath2 .",
    "the challenge for the agents thus is twofold : _ first _ , agents have to predict @xmath2 as accurately as possible , and _ second _ , they have to adjust @xmath1 to the proper values as quickly as possible .",
    "this is a complex and difficult task since most investment environments are uncertain and fluctuating . choosing to avoid risk and investing too little may lead to small gains , and choosing to take risk and investing too much may lead to large losses .    the task of finding an appropriate strategy that controls the risk and balances between these two extrema is by far not trivial .",
    "methods from technical analysis , such as estimations based on _ moving averages _ or _ moving least squares _",
    "( see also section [ sec : technicalanalysis ] ) try to approximate the behaviour of the environment and , based on that approximation , determine the most appropriate investment at a particular time .",
    "in the theory of risk , several authors assume that individuals choose among assets based on the mean return and on the variance of the return @xcite .",
    "others have focused their attention to the important task of how to measure risk , which lead to different type of measures @xcite . in general , these measures are based on the risk aversion of a decision maker having the choice to receive a random or a non - random amount .    a typical scenario to study investment strategies is to let an agent choose between investing in a risk - free asset or in a risky asset@xcite .",
    "it was shown@xcite that sometimes it may be more reasonable to invest in a risk - free asset as a means to transfer wealth over time .",
    "however , assuming a model with no consumption @xcite , those agents investing in risk - free assets will be driven out of the market in the long run by agents investing in a risky asset .",
    "when dealing with risky assets , it is typically assumed that the agent considers the expected return and its volatility as indicators for the investment strategy @xcite .",
    "for the sake of simplicity , in this paper we assume that the agent s behavior is risk - neutral in the sense that the agent estimates only the expected return , @xmath2 , and does not consider risk measures such as the volatility .",
    "based on the estimation of @xmath2 , the decision to increase or decrease the investment fraction of the risky asset should be taken .",
    "hence , the two terms risk - seeking and risk - avoiding refer only to the choice of the investment fraction , @xmath1 .",
    "the remainder of this paper is organised as follows : in the next section , section [ sec : model ] , we present the details of the investment model , the properties and abilities of an agent acting / investing in this environment . following",
    "that , section [ sec : agentstrategies ] presents some of the strategies that an agent can use to control its risk propensity and section [ sec : returnoninvestment ] presents the properties of the return on investment ( roi ) that we are considering ; section [ sec : optimalparameteradjustment ] illustrates the optimal parameter adjustment for the presented strategies and their derivation ; section [ sec : results ] compares the different investment strategies .",
    "this is done by means of simulations where the average total budget of agents using each investment strategy is obtained for a large a number of trials . finally , in section [ sec : conclusions",
    "] , we present our conclusions .",
    "in this model , agents are characterised by the following two variables :    1 .",
    "their _ budget _ @xmath0 , which is a measure of their `` wealth '' or `` liquidity '' , and 2 .",
    "the _ strategy _ that they employ in order to control the fraction of the budget @xmath1 to invest at each time step .    in other words , at each time step @xmath4 ,",
    "an agent invests a portion @xmath7 of its budget .",
    "the investment yields a gain or a loss , determined by the value of @xmath2 .",
    "being a fraction of the investment budget , @xmath1 , is , of course , restricted to the interval between @xmath8 $ ] .",
    "however , in our model we further restrict it to be from the interval @xmath9 $ ] where we choose @xmath10 and @xmath11 .",
    "this implies that , at each time step @xmath4 , there is a minimal investment of @xmath12 of the budget , and a maximal investment of the entire budget .",
    "we can then define the dynamics for the budget of agents @xmath0 as @xmath13\\ ] ] where @xmath2 is the market return at the previous time step @xmath4 .",
    "the market return function @xmath2 is restricted to the range of @xmath14 $ ] .",
    "a value of @xmath15 corresponds to a total loss of the invested fraction of the budget @xmath1 and @xmath16 corresponds to a gain equivalent to the invested fraction .",
    "thus , an agent can , at any time step @xmath4 , loose its complete budget ( for @xmath17 and @xmath15 ) , but also double its budget ( for @xmath17 and @xmath16 ) . in principle , there is no upper boundary for @xmath2 , @xmath16 was chosen to obtain a mean of zero for @xmath2 which allows us to better understand the basic dynamics of this model .",
    "we emphasize again that , in our model , the aim is not a most realistic simulation of the market return , but a comparison of different agent strategies .",
    "the difficulty for the agents lies in properly predicting the next value of @xmath2 and then adjusting @xmath1 fast enough .",
    "note that the restriction of @xmath2 to the range of @xmath14 $ ] is not a realistic assumption for a real market .",
    "there , some @xmath2 will also fall into the range @xmath18  these are rare , extreme events that occur , e.g. in cases of stock market bubbles and crashes .",
    "however , normally , returns will be in the range of @xmath14 $ ] , e.g. as the ones of the stock depicted in figure [ fig : rq ] . as we would like to focus on the questions of choosing appropriate agent strategies in environments with noisy , periodic returns ,",
    "it is reasonable to exclude such rare , extreme events and assume a restriction of @xmath2 to the range of @xmath14 $ ] .    in the next two sections",
    ", we will outline the agent strategies ( section [ sec : agentstrategies ] ) and return on investment ( section [ sec : returnoninvestment ] ) that we consider .",
    "as explained before , we are interested in how the market dynamics , @xmath2 , affect the different investment strategies of the agent , @xmath1 .",
    "it is very important to realise that the market dynamics  while affecting each agent s @xmath1  are _ not known _ to the agents .",
    "i.e. , at time @xmath4 , each agent only receives the _ actual value _ of the return on investment ( roi ) and adjusts its risk propensity accordingly , _ without _ having a complete knowledge about the dynamics of @xmath2 .",
    "the agent may , of course , have some bounded memory about past roi that could be used for predictions of future roi .",
    "however , the agent has to gather information about the ups and downs of the roi and to draw its own conclusions from this information by itself .",
    "therefore , the agent will perform better in the environment if it is able to guess the market dynamics .    in the following , we present a selection of strategies that can be applied by agents .",
    "we distinguish a reference strategy , which serves as a frame of reference to compare and evaluate the performance of other strategies , as well as technical analysis - based and machine learning - based strategies .",
    "usually ( there are exceptions , as will be discussed in the following ) , a strategy consists of two components : a _ prediction component _ and an _",
    "action component_. for such strategies , the prediction component predicts a variable in the system  in this case , the next value of @xmath2  and the action component then defines an action upon the prediction of the variable  in this case , it defines the appropriate value for @xmath1 .      in order to compare different strategies ,",
    "we need a point of reference against which the performance of each strategy can be measured .",
    "the reference strategy that we are using is the most simple strategy possible , i.e. that an agent always assumes a _ constant risk - propensity value _",
    "@xmath19 at every time step @xmath4 : @xmath20 since the value of @xmath1 is always fixed , this is not really a `` strategy '' , but it plays a role in more physics - inspired investment models @xcite .",
    "we use this strategy to compare it with more complex strategies .",
    "note that this reference strategy requires no knowledge on the roi .",
    "the following simple strategies for risk adjustment are based on `` technical analysis '' @xcite .",
    "technical analysis tries to deduce information about the dynamics of @xmath2 by looking at trends ( averages , variances , higher order moments ) of the roi values over a range of time .",
    "this assumes that an agent has a bounded memory of size @xmath21 to record previous roi ; this information is then processed in different ways to predict the next roi . in the following ,",
    "we consider two strategies from the field of technical analysis : the first strategy is based on calculating _ moving averages _ ( ma ) on previous roi , while the second strategy uses _ moving least squares _ ( mls ) on previous roi , @xmath2 , over a fixed period of time , @xmath21 . both of them can be regarded as `` zero - intelligence '' strategies , as agents do not do any reasoning or learning .",
    "the moving averages technique computes @xmath22 , an estimate of the next @xmath2 , as the average of the previous @xmath21 values of @xmath2 : @xmath23      the moving least squares technique fits a function to the data of the previous @xmath21 values of @xmath2 to estimate the next @xmath2 . in our case , we choose this function to be a linear trend - line , which is found by minimising the distance to the data points of @xmath2 .",
    "based on the previous @xmath21 values of @xmath2 , the squared estimation error @xmath24 is defined as : @xmath25^{2}\\ ] ] where @xmath26 is the predicted roi based on the linear regression trend - line , defined as : @xmath27 now , the best fitting values @xmath28 and @xmath29 are obtained by minimising the squared error estimation , eq .",
    "( [ eq : mls_error ] ) . from @xmath30 and @xmath31",
    ", we get , as it is well known : @xmath32\\end{aligned}\\ ] ] these two strategies use different approaches to estimate future @xmath2 ; it remains to define the corresponding adjustment of the risk propensity : here , we consider two possibilities .",
    "first , a _ risk - seeking _",
    "( rs ) and , second , a _ risk - avoiding _ ( ra ) approach . in the risk - seeking approach ,",
    "the value of @xmath33 is defined as follows for @xmath34 , i.e. for @xmath35 being an ma or mls estimate of @xmath2 : @xmath36 where @xmath37 $ ] and @xmath38 . in other words , agents invest @xmath39 if the next value of @xmath2 is predicted to be negative or zero , and agents invest @xmath40 if the next value of @xmath2 is predicted to be positive .    in the risk - avoiding approach ,",
    "the value of @xmath41 is defined as follows for @xmath34 , i.e. for @xmath35 being an ma or mls estimate of @xmath2 : @xmath42 where @xmath37 $ ] and @xmath38 . here ,",
    "the respective @xmath1 is set to the predicted @xmath2 ( with appropriate adjustments to ensure that @xmath43 whenever @xmath44 and @xmath45 whenever @xmath46 )  agents only invest a fraction of the budget which corresponds in size to the expected return .",
    "another class of strategies for risk adjustment is based on more complex agent information processing capabilities from the field of machine learning . in this paper , we consider two such approaches : one based on an incremental update rule ( iur ) , which is a form of reinforcement learning , and the other based on a genetic algorithm ( ga ) , which is a form of evolutionary learning .",
    "the following machine learning approach is based on the incremental update rule , an application of reinforcement learning @xcite .",
    "the idea of reinforcement learning is that an agent continuously uses a reward signal to adjust its own performance . in our scenario ,",
    "the values of the return are the reward signal ; at each step , the agent computes the error between the predicted and the actual value of the return and uses this error to adjust the estimation of the following return .",
    "the general incremental update rule from reinforcement learning is defined as follows : @xmath47\\ ] ] @xmath48 and @xmath49 are the old and new estimates for the quantity of interest .",
    "so , @xmath50 gives the error of the current estimation , which is weighted by the factor @xmath51 .",
    "this is , a new estimate is computed by taking the old estimate and adjusting it by the error of the current estimate .",
    "@xmath49 has to be updated at each time step .",
    "applying eq .",
    "( [ eq : iur ] ) to our model , we find the following instance of the incremental update rule : @xmath52\\ ] ] consequently , @xmath48 and @xmath49 are the old and new estimates for the return , @xmath53 and @xmath54 ; furthermore , @xmath55 is the error of the current estimate . because of its recursive definition",
    ", the incremental update rule considers an infinite history of returns  of course , the weight of a value depends on its age and its impact fades over time .",
    "we chose @xmath56 as the initial value of @xmath53 .",
    "different values of @xmath57 lead to different performance of the algorithm ; in other words , for small @xmath57 , the adjustment of the estimate will be small , and for large @xmath57 , the adjustment of the estimate will be large .",
    "it is important to choose an _ optimal _ value for @xmath57 in order to be able to compare the algorithm with other algorithms ; in the next section , we will discuss this in more detail .",
    "finally , it remains to specify what action to do given a particular estimate for the next return ; we again define a risk - seeking and a risk - avoiding approach , similar to eq .",
    "[ eq : mamls_rs ] and [ eq : mamls_ra ] for the ma and mls strategies :    in the risk - seeking approach , @xmath33 is defined as follows for @xmath53 : @xmath58 and in the risk - avoiding approach , @xmath41 is defined as follows for @xmath53 : @xmath59 where , for both definitions , @xmath60 $ ] and @xmath38 .",
    "it is important to note that reinforcement learning and the incremental update rule are not identical ; rather , reinforcement learning describes a group of machine learning approaches and the incremental update rule is one instance of these approaches .",
    "we note eventually that a different representation of @xmath57 in eq.([eq : iur_instance ] ) could be used to study some aspects of the prospect theory of decision - making .",
    "this theory takes into account that decisions are made based on changes from a certain reference point , i.e. humans for example decide differently for profits and for losses , as they cognize losses twice as large as profits , @xcite .",
    "this , however , is not the target of the present investigations .",
    "genetic algorithms ( ga ) are a technique from the field of artificial intelligence which finds approximate solutions to problems .",
    "genetic algorithms belong to the class of evolutionary algorithms .",
    "genetic algorithms are based on modelling solutions to a problem as a population of chromosomes ; and the chromosomes are candidate solutions to the problem which gradually evolve to better solutions to the problem .",
    "the following is a description of the instance of a genetic algorithm which we apply to our scenario :    let @xmath61 be a chromosome with population size @xmath62 . each chromosome @xmath63 is an array of genes , @xmath64 @xmath65 .",
    "the values of the genes are real numbers @xcite . in our model ,",
    "each chromosome @xmath63 represents a _ set of possible strategies _ of an agent , so the @xmath64 refers to possible values for the risk propensity @xmath66 .    in the beginning , each @xmath64 is assigned a random value : @xmath67 .",
    "each chromosome @xmath63 is then evaluated by a _ fitness function _",
    ", @xmath68 , which is defined as follows : @xmath69 in our model , the fitness is determined by the gain / loss that each strategy @xmath64 yields depending on the roi , @xmath2 .",
    "since the fitness of a chromosome must to be maximised , negative @xmath2 lead to very small values of @xmath64 , i.e. a low risk propensity , whereas positive @xmath2 lead to larger values of @xmath64 .",
    "this lets us consider the product of @xmath70 as a performance measure of a chromosome .",
    "the values of @xmath64 are always multiplied by different @xmath2 values ",
    "i.e. , depending on @xmath4 . for the chromosome , we define a further time scale @xmath71 in terms of generations .",
    "a generation is completed after each @xmath64 is multiplied by a roi from consecutive time steps , @xmath4 .",
    "this means that the index @xmath72 refers to a particular time @xmath4 in the following manner : @xmath73 , which means @xmath74 , with @xmath75 , @xmath76 .",
    "after time @xmath71 , the population of chromosomes is replaced by a new population of better fitting chromosomes with the same population size @xmath62 .",
    "this new population is determined in the following manner : after calculating the fitness of each chromosome according to eq .",
    "( [ eq : ga_fitness ] ) , we find the best chromosomes from the old population by applying elitist and tournament selection of size two :    * _ elitist selection _ considers the best @xmath77 percentage of the population which is found by ranking the chromosomes according to their fitness .",
    "the best chromosomes are directly transferred to the new population . *",
    "_ tournament selection _ is done by randomly choosing two pairs of two chromosomes from the old population and then selecting from each pair the one with the higher fitness .",
    "these two chromosomes are not simply transferred to the new population , but undergo a transformation based on the genetic operators crossover and mutation , as follows : a single - point crossover operator finds the cross point , or cut point , in the two chromosomes beyond which the genetic material from two parents is exchanged , to form two new chromosomes .",
    "this cut point is the integer part of a random number drawn from a uniform distribution @xmath78 .",
    "after the crossover , a mutation operator is applied to each gene of the newly formed chromosomes . with a given mutation probability @xmath79 ,",
    "a gene is to be mutated by replacing its value by a random number from a uniform distribution @xmath80 . after the cycle of selection , crossover and mutation",
    "is completed , we eventually arrive at a new population of chromosomes that consists of a percentage of the best fitted chromosomes from the old population plus a number of new chromosomes that ensure further possibilities for the evolution of the set of strategies .    given the optimised population of chromosomes representing a set of possible strategies , the agent still needs to update its actual risk propensity , @xmath81 .",
    "this works as follows : at time @xmath82 , the agent takes the set of strategies @xmath64 from the chromosome @xmath63 with the highest fitness in the previous generation .",
    "given @xmath83 , this means that the agent for each time step of the upcoming cyclic change chooses the appropriate risk propensity by computing the following : @xmath84 this concludes the overview of the different agent strategies applied in our scenario . in the following section we will adjust the respective parameters of each of these strategies so that they are optimal",
    "this is crucial for a comparison of the different agent strategies  only strategies that perform at their best can be compared .",
    "given the assumptions stated , we have to provide a function for @xmath2 which is independent of @xmath1 . in some of the models previously studied in the literature @xcite , the influence of the market",
    "is simply treated as random , i.e. @xmath2 is a random number drawn from a uniform distribution in the interval @xmath14 $ ] .    however , it is known that for returns with a uniform distribution centered around the origin and agents which do not have any information on future market returns , this situation will lead the agents to a complete loss of their budget .",
    "this is a well - known property of multiplicative stochastic processes @xcite .",
    "the only way to make a profit on the return is by having a certain knowledge on future returns of the market .",
    "this requires both that there exist correlations in the market return function , and that the agents are able to resolve and use those correlations to make correct predictions .",
    "consequently , we choose to introduce correlations in our market return @xmath2 under the form of a seasonal or periodic signal .",
    "we study two different market return functions that depend on a noise level @xmath85 ; for @xmath86 , they correspond to a pure sine wave function with frequency @xmath87 and for @xmath88 , they are completely uncorrelated : @xmath89 where @xmath90 is distributed uniformly in the interval @xmath14 $ ] , i.e. @xmath91 . there are two types of noise that can occur with such a sine wave function  noise on the phase and noise on the amplitude .",
    "we consider both cases : the first function can be seen as a periodic market return signal with phase noise ( determined by @xmath92 ) , the second as a periodic market return signal with amplitude noise ( determined by @xmath93 ) . in our simulations , we chose the arbitrary value of @xmath94 for the period of the sine wave .",
    "[ fig : roi_sin ] shows plots for these two kinds of return functions with different noise levels .",
    "note that periodic returns with a periodicity changing over time are invested recently as well.@xcite    the noise parameter @xmath85 gives us a way of controlling the noise in the roi , thereby allowing us to evaluate the various strategies for different scenarios , ranging from a completely clear signal with no noise at all ( for @xmath86 ) to a noise - only signal ( for @xmath88 ) .",
    "this makes it possible for us to determine how well multiple strategies perform for different types and levels of noise and what impact the type and level of noise has on a single strategy .    , eq .",
    "[ eq : r ] for : ( a ) two different phase noise levels : ( top ) @xmath95 and ( bottom ) @xmath96 ; ( b ) two different amplitude noise levels : ( top ) @xmath97 and ( bottom ) @xmath98.,title=\"fig:\",width=253 ] , eq . [ eq : r ] for : ( a ) two different phase noise levels : ( top ) @xmath95 and ( bottom ) @xmath96 ; ( b ) two different amplitude noise levels : ( top ) @xmath97 and ( bottom ) @xmath98.,title=\"fig:\",width=253 ] + ( a ) ( b )    agents have no knowledge about future market returns ; of course , they do not know the functions that determine @xmath2 .",
    "thus , the only way for agents to maximize their gain and minimize their losses is by making a correct prediction of the future market return and choosing the appropriate investment action .",
    "conceptually , we can separate an agent s strategy into two components : a prediction component and an action component .",
    "the prediction algorithm estimates the future values of the market return and the action algorithm determines the best action based on the predicted results .",
    "we study the performance of the different algorithms or strategies that are explained in section [ sec : agentstrategies ] .",
    "we define the _ performance _ of an agent employing a particular strategy as being the average growth of the budget @xmath0 of the agent collected after a certain number of time steps .",
    "we choose to take this average over @xmath99 time steps , @xmath100 being the period of the sine wave .",
    "the reason for this particular choice is that , for a constant investment action and a return function with no noise , this average value will have zero standard deviation .",
    "in contrast , if we do the averaging of the growth over all the time steps there will be a non - zero standard deviation associated with the sine wave . in section [ sec : results ] , we compare the performance of the different strategies .    ,",
    "eq . [ eq : r ] , for : ( a ) phase noise @xmath101 and ( b ) amplitude noise @xmath102.,title=\"fig:\",width=253 ] , eq .",
    "[ eq : r ] , for : ( a ) phase noise @xmath101 and ( b ) amplitude noise @xmath102.,title=\"fig:\",width=253 ] + ( a ) ( b )    in order to interpret the results that we obtain and present in this paper , it is useful to understand some properties of the two different return functions .",
    "two properties are of particular interest : the absolute average value of the return , and the correlation between the sign of two consecutive returns .    for the sake of completeness , we show the probability distribution of the roi in fig . [",
    "fig : distribution_roi ] . for the probability distributions of @xmath2 with phase noise",
    ", we see that there is a higher probability for values close to @xmath103 and @xmath104 , and a lower probability for values close to @xmath105 .",
    "note that this is the same distribution that is found for a sine wave with no noise at all . for phase noise",
    ", the value of @xmath106 has no effect  the distributions are virtually identical . for the probability distributions of @xmath2 with amplitude noise",
    ", we observe a probability distribution which is a combination of the probability distribution of a sine wave without noise ( caused by the sine wave ) and a uniform probability distribution ( caused by the noise ) . for higher levels of noise , the convolution of probability distributions more closely resembles the uniform distribution , and for lower levels of noise , the convolution of probability distributions more closely resembles the sine wave distribution . for amplitude noise ,",
    "the value of @xmath107 is crucial and different values lead to different distributions .",
    "note that the distribution of the returns for phase noise is independent of the level of noise , whereas for the roi with amplitude noise there is a significant change as the level of noise is increased .    , eq .",
    "[ eq : r ] , for phase noise ( red , top line ) and for amplitude noise ( black , bottom line).,width=253 ]    since the distribution of the roi is independent of the noise level @xmath106 for phase noise , it is expected that the average absolute roi , fig . [",
    "fig : average_abs_roi ] , is constant with respect to @xmath106 in the roi .",
    "this , as we have explained , is not the case for the noise level @xmath107 for amplitude noise , where the average absolute roi is varying with respect to @xmath107 in the roi . for @xmath108 and @xmath109 ,",
    "the average absolute value of the roi are equal . roughly , the average absolute value of the roi with amplitude noise decreases for @xmath110 and it increases for @xmath111 .",
    "this matches with the observations for the probability distributions : there , for @xmath98 , the values are concentrated around @xmath112 , leading to smaller @xmath113 , and for @xmath97 and @xmath114 , the values are less concentrated around @xmath112 , leading to larger @xmath113 .",
    "the average absolute roi is of importance because its known from multiplicative stochastic processes @xcite , that for a constant investment @xmath115 the better performing constant strategies are the ones that invest the least possible amount . in our model ,",
    "the agents are forced to invest the minimum amount of @xmath10 . since @xmath1 is multiplied with @xmath2 in eq .",
    "[ eq : budget ] , the change in average absolute value of @xmath2 has an impact similar to the change in @xmath19 seen in the multiplicative stochastic processes @xcite studied .",
    "this leads to changes in performance that are not necessarily related with the performance of agents , and should be taken into account when interpreting the results .    , eq .",
    "[ eq : r ] , for : ( a ) phase noise with @xmath101 and ( b ) amplitude noise with @xmath102.,title=\"fig:\",width=253 ] , eq .",
    "[ eq : r ] , for : ( a ) phase noise with @xmath101 and ( b ) amplitude noise with @xmath102.,title=\"fig:\",width=253 ] ( a ) ( b )    the correlation between the sign of two consecutive returns shows whether it is possible to draw conclusions from the sign of @xmath2 on the sign of @xmath116 . in fig .",
    "[ fig : correlations_roi_in_time ] we show the distribution of the correlations of the roi with respect to two consecutive returns , @xmath117 .",
    "we can clearly see that for low levels of noise there is bigger correlation between consecutive values . as the noise increases this correlation diminishes until ,",
    "finally , for high levels of noise , the returns are completely uncorrelated .",
    "most of the algorithms studied are sensitive to correlations in consecutive roi with the same sign .",
    "we notice that between the returns with phase noise and amplitude noise , correlations do not vary exactly in the same manner with noise . in particular , it can clearly be seen that for @xmath118 the amplitude noise has still more correlation than the phase noise .",
    "this difference can account for some discrepancies seen between the performance of the agents for the two types of market return functions .",
    "in the previous sections , we have defined several different strategies that can be applied by agents to determine when to invest which amount of money . in the next section ,",
    "we want to compare their performance in a periodic environment",
    ". however , in order to make this comparison meaningful , we have to ensure that we have adjusted the different parameters of the strategies properly .",
    "only if the strategies perform at their optimum , they can really be compared .",
    "the procedure that we apply to adjust the optimal parameters is straightforward : we compare the performance  averaged over @xmath119 periods  of each of the algorithms for a range of possible parameters and then choose the optimal one . at this point , it remains to define the notion of optimality : we have already defined that we measure the performance of agents as the average of their budget growth over a certain number of time steps .",
    "the optimal strategy is the strategy that performs better than all the other strategies , i.e. the strategy that , on average , leads to the greatest budget growth .",
    "of course , for the measurement , each agent has to be provided with enough time to gather the information necessary for the proper calibration of the algorithm that it applies .    for the ma , mls , and iur strategies ,",
    "there is only one parameter that requires adjustment : either the memory size @xmath21 ( in the case of ma and mls ) or the step size @xmath57 ( in the case of iur ) .",
    "this implies that for these strategies , it is possible to choose the optimal value of the parameter by comparing the average budget @xmath120 for several possible values of the parameter , and then take the one which gives the best results . for ma and mls , we have considered memory sizes @xmath121 $ ] and for iur , we have considered step sizes @xmath122 $ ] .    for the ga strategy , there are , however , several parameters which require adjustment : the population size , @xmath62 , the crossover probability , @xmath123 , the mutation probability , @xmath124 , and the elitism size , @xmath77 . consequently , the process of finding the optimal combination of values for the parameters is not as trivial as for the other strategies .",
    "the _ + carps ( multiagent system for configuring algorithms in real problem solving ) _",
    "tool @xcite was used during this step .",
    "this application uses autonomous , distributed , cooperative agents that search for solutions to a configuration problem , thereby fine - tuning the meta - heuristic s parameters .",
    "the agents in _ + carps _ apply a random restart hill - climbing approach and they exchange their so - far best solutions to the problem in the process .",
    "the intervals of definition , i.e. the intervals in which the most acceptable ga configurations should lie , were set as follows : @xmath125 , @xmath126 $ ] , @xmath127 $ ] , and @xmath128 $ ] ,    [ tab : optimal_parameters ]    table 1 shows the optimal parameters that we choose for the comparison of the different strategies .",
    "of course , the optimal parameters usually are not the same for different types and levels of noise or for risk - seeking and risk - avoiding behaviour , so at times , a compromise between several alternative values for different situations had to be found .",
    "in this section , we compare all strategies presented in this article for roi with periodicity @xmath94 and different noise levels for both phase and amplitude noise . in our comparison , we consider a set of agents , each one using one of the following strategies : q0 eq .",
    "( [ eq : q0 ] ) , ma eq .",
    "( [ eq : ma ] ) , mls eq .",
    "( [ eq : mls ] ) , iur eq .",
    "( [ eq : iur_instance ] ) , and ga eq .  ( [ eq : ga ] ) .",
    "note that periodic returns with a periodicity changing over time are invested recently as well.@xcite    in our comparison , we make two assumptions : first , all agents receive the same roi at a particular time , i.e. the fact that some agents win or loose more than others is influenced only by their different strategies to determine the correct risk - propensity value ; second , all agents use the optimal parameter values of their respective strategies .",
    "let us state again that only the past and current values of @xmath2 are known to the agents ; they do not know the dynamics governing future values of @xmath2 .",
    "we perform @xmath129 trials of the same experiment , i.e. roi with same parameters , where at each end of a cycle of the roi , i.e. for all @xmath4 such that @xmath130 , an average budget is obtained for each agent over the 100 trials .",
    "this is done for a large number of time steps , i.e. @xmath131 .",
    "we vary the amplitude noise values , @xmath132 , while leaving the phase noise value constant , @xmath108 , and we vary the phase noise values , @xmath133 , while leaving the amplitude noise value constant , @xmath109 . for the simulations which distinguish between a risk - seeking and a risk - avoiding action upon a prediction of the roi , we compute the average budget for both approaches .",
    "this gives us four variants of the simulations : amplitude noise / risk seeking , phase noise / risk seeking , amplitude noise / risk avoiding , and phase noise / risk avoiding .",
    "[ fig : comparison - all ] shows the result of the simulations by plotting the average budget resulting from the different strategies against the noise level for each of the four variants of the simulations ( amplitude noise / risk seeking in ( a ) , phase noise / risk seeking in ( b ) , amplitude noise / risk avoiding in ( c ) , and phase noise / risk avoiding in ( d ) ) .",
    "trials , for agents using strategies q0 , ma , mls , ga , iur and sw ( square wave , to be introduced in section [ sec : optimalstrategy ] ) , over @xmath131 time steps .",
    "agents use optimal parameter values for roi with periodicity , @xmath94 , and different noise levels : ( a ) different amplitude noise values , @xmath132 , and no phase noise , @xmath108 with a risk - seeking strategy ; ( b ) different phase noise values , @xmath133 , and no amplitude noise , @xmath109 with a risk - seeking strategy ; ( c ) different amplitude noise values , @xmath132 , and no phase noise , @xmath108 with a risk - avoiding strategy , and ( d ) different phase noise values , @xmath133 , and no amplitude noise , @xmath109 with a risk - avoiding strategy.,title=\"fig:\",width=253 ]   trials , for agents using strategies q0 , ma , mls , ga , iur and sw ( square wave , to be introduced in section [ sec : optimalstrategy ] ) , over @xmath131 time steps .",
    "agents use optimal parameter values for roi with periodicity , @xmath94 , and different noise levels : ( a ) different amplitude noise values , @xmath132 , and no phase noise , @xmath108 with a risk - seeking strategy ; ( b ) different phase noise values , @xmath133 , and no amplitude noise , @xmath109 with a risk - seeking strategy ; ( c ) different amplitude noise values , @xmath132 , and no phase noise , @xmath108 with a risk - avoiding strategy , and ( d ) different phase noise values , @xmath133 , and no amplitude noise , @xmath109 with a risk - avoiding strategy.,title=\"fig:\",width=253 ] + ( a ) ( b ) +   trials , for agents using strategies q0 , ma , mls , ga , iur and sw ( square wave , to be introduced in section [ sec : optimalstrategy ] ) , over @xmath131 time steps .",
    "agents use optimal parameter values for roi with periodicity , @xmath94 , and different noise levels : ( a ) different amplitude noise values , @xmath132 , and no phase noise , @xmath108 with a risk - seeking strategy ; ( b ) different phase noise values , @xmath133 , and no amplitude noise , @xmath109 with a risk - seeking strategy ; ( c ) different amplitude noise values , @xmath132 , and no phase noise , @xmath108 with a risk - avoiding strategy , and ( d ) different phase noise values , @xmath133 , and no amplitude noise , @xmath109 with a risk - avoiding strategy.,title=\"fig:\",width=253 ]   trials , for agents using strategies q0 , ma , mls , ga , iur and sw ( square wave , to be introduced in section [ sec : optimalstrategy ] ) , over @xmath131 time steps .",
    "agents use optimal parameter values for roi with periodicity , @xmath94 , and different noise levels : ( a ) different amplitude noise values , @xmath132 , and no phase noise , @xmath108 with a risk - seeking strategy ; ( b ) different phase noise values , @xmath133 , and no amplitude noise , @xmath109 with a risk - seeking strategy ; ( c ) different amplitude noise values , @xmath132 , and no phase noise , @xmath108 with a risk - avoiding strategy , and ( d ) different phase noise values , @xmath133 , and no amplitude noise , @xmath109 with a risk - avoiding strategy.,title=\"fig:\",width=253 ] + ( c ) ( d ) +    for all variants of the simulations , the constant - risk strategy is the worst strategy .",
    "the constant - risk strategy always puts a constant proportion of the budget at stake .",
    "this money is won when the return is positive , but also lost when the return is negative ; even though @xmath134 , this leads to a loss in budget over time , as this is a well known property for multiplicative stochastic processes .",
    "furthermore , for all strategies , the average budget decreases with increasing noise .",
    "that is the expected behaviour : with increasing noise , the accuracy of the predictions made by the agents decreases , and thus they can not necessarily chose the appropriate risk propensity in the action .",
    "there are no significant crossovers of the performance of different strategies . in general",
    ", this implies that if a strategy @xmath135 performs better than a strategy @xmath136 for a given noise level @xmath137 ( either on the phase or on the amplitude ) , @xmath135 can be expected to perform better than @xmath136 for a different noise level @xmath138 .",
    "consequently , the _ choice of strategy is independent of the noise in the return _  a good strategy is a good strategy for all noise levels , and a bad strategy is a bad strategy for all noise levels , too .",
    "however , for low noise levels , the ga is slightly outperformed by the other strategies  this is due to the intrinsic stochastic nature of the algorithm ; for the same reason , this algorithm performs better for high noise levels .",
    "note that the experiments in this simulations are done for @xmath131 time steps , which corresponds also to the learning phase for the ga .    for phase noise ,",
    "the average budget obtained is roughly comparable to that for amplitude noise , although the differences between strategies are greater for phase noise than for amplitude noise .    from the range of strategies employed ,",
    "the simple strategies ( ma , mls , iur ) were almost always outperformed by the complex one ( ga ) .",
    "other researchers @xcite have shown that this needs not necessarily be the case .      as a consequence of the comparison it is logical to investigate what would be the optimal strategy in the given scenario .",
    "given the fact that the ga performs best of all the strategies , it makes sense to look at the @xmath1 as chosen by the ga for @xmath2 over time , in order to analyse why the ga performs so well .",
    "[ fig : ga_sw_behaviour ] plots the values of @xmath2 and the corresponding @xmath1 as chosen by the ga against time @xmath4 for different noises and from different times @xmath139 on . from the graph ,",
    "it is visible that the behaviour of the ga resembles a square wave function which is a type of a ramp - rectangle function .     and",
    "the risk propensity @xmath1 as chosen by the ga for roi with different types of noise and for different times during the simulation : ( a ) amplitude noise , @xmath140 , @xmath141 , ( b ) amplitude noise , @xmath140 , @xmath142 , ( c ) phase noise , @xmath143 , @xmath144 , ( d ) phase noise , @xmath143 , @xmath145.,title=\"fig:\",width=253 ]   and the risk propensity @xmath1 as chosen by the ga for roi with different types of noise and for different times during the simulation : ( a ) amplitude noise , @xmath140 , @xmath141 , ( b ) amplitude noise , @xmath140 , @xmath142 , ( c ) phase noise , @xmath143 , @xmath144 , ( d ) phase noise , @xmath143 , @xmath145.,title=\"fig:\",width=253 ] + ( a ) ( b ) +   and the risk propensity @xmath1 as chosen by the ga for roi with different types of noise and for different times during the simulation : ( a ) amplitude noise , @xmath140 , @xmath141 , ( b ) amplitude noise , @xmath140 , @xmath142 , ( c ) phase noise , @xmath143 , @xmath144 , ( d ) phase noise , @xmath143 , @xmath145.,title=\"fig:\",width=253 ]   and the risk propensity @xmath1 as chosen by the ga for roi with different types of noise and for different times during the simulation : ( a ) amplitude noise , @xmath140 , @xmath141 , ( b ) amplitude noise , @xmath140 , @xmath142 , ( c ) phase noise , @xmath143 , @xmath144 , ( d ) phase noise , @xmath143 , @xmath145.,title=\"fig:\",width=253 ] + ( c ) ( d ) +    the ramp - rectangle ( rr ) function maps roi that are uncertain to increasing / decreasing risk - propensity values and roi that are certainly positive or negative to a maximal or minimal risk - propensity value , respectively . the corresponding strategy is expressed as follows : @xmath146 $ } \\\\",
    "\\left(\\frac{q_{\\mathrm{max}}-q_{\\mathrm{min}}}{h_2-h_3}\\right)(\\hat{t}-h_2)+q_{\\mathrm{max } } &   \\textrm{if $ \\hat{t}\\in(h_2,h_3)$ } \\\\",
    "q_{\\mathrm{min } } & \\textrm{if $ \\hat{t}\\in[h_3,h_4]$ }    \\end{cases}\\ ] ] in this function , @xmath147 ( @xmath148 ) sets the transition from an increasing ( decreasing ) ramp function to a rectangle function and @xmath149(@xmath150 ) sets the transition from a rectangle function to a decreasing ( increasing ) ramp function .",
    "moreover , for each time step , @xmath4 , the following congruence is used : @xmath151 ; this maps each time step @xmath152 to a time step in the ramp - rectangle function , @xmath153 .",
    "furthermore , we assume that the differences between time steps when an agent increases and decreases its risk propensity values are symmetric .",
    "this means that the time difference @xmath154 between when the ramp function starts and stops to increase or decrease can be expressed as follows : @xmath155 which for @xmath156 , means that agents use a _ square wave _ ( sw ) strategy .",
    "we are particularly interested in this case of the ramp - rectangle function : it implies that an agent invests @xmath3 for time steps @xmath157 , and invests @xmath158 for time steps @xmath159 $ ] .",
    "this is the optimal strategy .",
    "the ga approaches the optimal strategy : for all different noises , the risk propensity @xmath1 chosen by the ga approximates the one that would have been chosen by sw . considering that the ga does not have an ` a priori'-behaviour defined , it is interesting to realise that it finds the _ optimal _ strategy  investing the maximum when , at a particular time @xmath4 in the period , the probability of winning is higher than loosing and vice versa  on its own .",
    "[ fig : ga_sw_behaviour ] illustrates this behaviour .",
    "it plots the values of @xmath2 and the corresponding @xmath1 as chosen by the genetic algorithm against time @xmath4 for different noises and from different times @xmath139 on . from this , it is clearly visible that the behaviour of the ga is very similar to the behaviour of the sw , which is the optimal strategy . comparing fig .",
    "[ fig : ga_sw_behaviour ] ( a ) with ( b ) and fig .",
    "[ fig : ga_sw_behaviour ] ( c ) with ( d ) , i.e. the same scenario , but at different times @xmath160 and @xmath161 , one can see that the @xmath1 chosen by the ga approach the ones chosen by the sw more closely as time goes on  i.e. , as the ga has more time to evolve .",
    "additionally , from the simulation results , it can be observed the approximation of the sw by the ga is closer for low levels of noise than for high levels of noise .",
    "this is the expected behaviour .",
    "furthermore , from the plots , we can observe that for low levels of noise , the _ risk - seeking _ behaviour clearly outperforms the _ risk - avoiding _ behaviour : always investing the maximum when a positive return is expected and investing the minimum when a negative return is expected outperforms investing a quantity proportional to the expected return .",
    "this may seem counter - intuitive  humans would probably choose not to invest their complete budget when they know that there is a certain probability to lose it .",
    "however , this behaviour is explained as follows : consider @xmath2 to be periodic with a period of @xmath100 and , for the moment , assume that there is no noise , i.e. @xmath108 as well as @xmath109 .",
    "then , the optimal strategy would be to invest the complete budget or @xmath3 during @xmath162 and to invest nothing or @xmath158 during @xmath163 .",
    "this is because it is certain  we assumed that there is no noise  that during the first half of the period , @xmath162 , the value of @xmath2 will be positive and during the second half of the period , @xmath163 , the value of @xmath2 will be negative .",
    "no matter what the precise values of @xmath2 are , once they are positive , this leads to a gain , and thus @xmath1 should be as large as possible to maximise the gain ; conversely , once the values of @xmath2 are negative , this leads to a loss , and thus @xmath1 should be as small as possible or zero to minimise the loss . in other words , _ for determining @xmath1 , not the quantity of the expected return matters , but whether the probability of the expected return being positive is greater than the probability of the expected return being negative_. this explains why the risk - seeking behaviour outperforms the risk - avoiding behaviour for periodic returns with no noise .",
    "the behaviour of this strategy is shown in fig .",
    "[ fig : certain_uncertain_intervals ] ( a ) .    for periodic returns with noise ,",
    "i.e. , @xmath164 or @xmath165 , the situation is quite similar .",
    "depending on the values of @xmath106 and @xmath107 , there will be two intervals @xmath166 and @xmath167 such that during @xmath166 , the value of @xmath2 will  on average  be positive and such that during @xmath167 , the value of @xmath2 will  on average  be negative , see fig .",
    "[ fig : certain_uncertain_intervals ] ( a ) . in these intervals , the optimal strategy would again be to invest the complete budget or @xmath3 and to invest nothing or @xmath158 , respectively .",
    "the value of @xmath168 , of course , depends on @xmath106 and @xmath107 , i.e. the more noise , the greater @xmath168 .",
    "now , what still has to be considered are the intervals @xmath169 , @xmath170 , and @xmath171 . because of the noise",
    ", it is not possible to determine the exact sign of @xmath2 during these intervals .     with no noise and the corresponding @xmath1 of the square wave ( sw ) strategy plotted against @xmath4 and",
    "( b ) shows @xmath2 with noise and the different intervals for which different conclusions about the sign of the return can be drawn : ( 2 ) and ( 5 ) are the intervals in which the sign of @xmath2 is certain to be positive or negative , respectively , and ( 1 ) , ( 3 ) , ( 4 ) , and ( 6 ) are the intervals in which the the sign of @xmath2 is uncertain.,title=\"fig:\",width=253 ]   with no noise and the corresponding @xmath1 of the square wave ( sw ) strategy plotted against @xmath4 and ( b ) shows @xmath2 with noise and the different intervals for which different conclusions about the sign of the return can be drawn : ( 2 ) and ( 5 ) are the intervals in which the sign of @xmath2 is certain to be positive or negative , respectively , and ( 1 ) , ( 3 ) , ( 4 ) , and ( 6 ) are the intervals in which the the sign of @xmath2 is uncertain.,title=\"fig:\",width=253 ] ( a ) ( b )    however , it still is possible to say that  on average  the probability of @xmath2 being positive is greater than the probability of @xmath2 being negative during @xmath169 and @xmath172 and the probability of @xmath2 being negative is greater than the probability of @xmath2 being positive during @xmath173 and @xmath171 . consequently , it makes sense to invest during @xmath169 and @xmath172 and not to invest during @xmath173 and @xmath171 .    with such behaviour , there will , however , be the situation that an agent invests the complete budget , but the return is negative . in this type of situation ,",
    "@xmath174 depends on @xmath106 and @xmath107 : for small @xmath106 and @xmath107 , it will be small , too .",
    "consequently , for low levels of noise , the product of @xmath175 would be a small value , which signifies , for @xmath176 , a small loss , and for @xmath177 , a small gain .",
    "thus , even for @xmath17 , the loss is bound to a proportion of the budget corresponding to the value of @xmath2 .",
    "this explains why the risk - seeking behaviour outperforms the risk - avoiding behaviour for low levels of noise . for high levels of noise ,",
    "the product of @xmath175 needs not necessarily be a small value , which potentially signifies , for @xmath176 , a large loss , and for @xmath177 , a large gain .",
    "thus , an agent could potentially loose a significant amount of its budget if it invests the complete budget ; this is the reason why , for _ high _ levels of noise , the risk - avoiding behaviour _ outperforms _ the risk - seeking behaviour .",
    "this also provides a straightforward explanation why different algorithms using the same rule to determine @xmath1 perform differently . even though the best strategy is to still invest the maximum when there is a slightly better probability that @xmath177 than that @xmath178",
    ", the algorithms fail to predict the exact probabilities of @xmath177 and of @xmath178 with good enough accuracy to determine how to properly invest .",
    "in other words , the performance of the action depends on the accuracy of the prediction ; if the accuracy of the prediction is high , then the performance of the action is good , and if the accuracy of the prediction is low , then the performance of the action is bad , too .",
    "the ga does not exhibit this prediction - action behaviour and it is able to adjust better than the other strategies .",
    "in this paper , we have presented a number of strategies that can be applied by agents in an investment market scenario with periodic returns and different types and levels of noise .",
    "we have compared their performance  the respective average budget growth over a certain number of time steps  and analysed the results .",
    "we have made three main observations :    1 .",
    "the _ type _ of noise  whether the roi has phase or amplitude noise  does not have a significant influence on the performance of the algorithms , while the _ level _ of noise certainly does  for increasing noise , we observe decreasing performance .",
    "the ga performs best of all strategies for almost all scenarios ; it discovers a strategy which resembles a square wave strategy and which follows the principle of always investing the complete budget or the maximum amount possible when the expected return is positive and not investing anything or the least amount possible when the expected return is negative .",
    "the best rule for investment is the _ risk - seeking behaviour _ of always putting the complete budget in an investment ; this behaviour clearly outperforms a risk - avoiding behaviour which humans would probably apply intuitively : whilst it may seem intuitive to a human to invest an amount proportional to the expected return , this is not the approach which yields the greatest budget growth over time .",
    "consequently , returning to our original goal to find an answer to the question of to which extent the internal complexity of agents influences their overall performance , we can state that , in our simple scenario , the agents with a complex architecture outperform the agents with a simple architecture .",
    "although , with respect to the question above , the major focus on this paper is more related to issues of computer science , one may also ask for the application of the results in an economic context , in particular to financial markets . surely , our paper can be seen as a computational experiment on the performance of different _ trading _ strategies in face of noisy market returns . in this context , the agent in our model may have two possible preferences : liquidity preference @xcite and speculative preference .",
    "i.e. based on the previous returns the agent has a preference to keep cash or to invest in the market , respectively - which is modeled by the risk - seeking and risk - avoiding behavior .",
    "apart from this , our model allows only a limited interpretation in the context of financial markets , because a number of important features in these markets are not covered or are even explicitely excluded , for the sake of a controlled simulation setup :    _ heterogeneity _ : : :    agents in our model are homogenous with respect to the strategy    employed , i.e. there is no variability in their individual    strategies.@xcite in this respect , the model is basically a    `` representative agent model '' , which takes into account only the    limited information of the previous @xmath2 .",
    "more    elaborated strategies , where agents are assumed to be fundamentalist    or chartists @xcite are also not considered here .",
    "_ interaction _ : : :    agents in our model do not interact with other agents .",
    "they rather    `` learn '' the dynamics of the market return , in order to predict it    more accurately .",
    "important collective interactions in financial    markets , such as herding behavior , is neglected here , as well as    interactions between ( heterogeneous ) trading strategies @xcite .",
    "this    implies the absence of emergent properties in our model , as    _ heterogeneity _ and _ interaction _ are indeed basic premises for the    existence of emergent properties in financial markets . _ feedback _ :",
    ": :    agents in our model have no effect upon the market , and consequently    the price of an asset and the return on investment are treated as    exogenous variables .",
    "this is equivalent to the atomistic market    assumption .",
    "our model also neglects the collective impact of _ all _    agents on the price and the return of an asset .",
    "other feedbacks on the    market , such as agent s expectations about the market dynamics itself ,    are also not explicitely modeled here .",
    "some artificial market models    consider an endogeneous approach , where the returns are generated by    means of constant trading between heterogeneous agents @xcite .",
    "_ microfoundation _ : : :    our model is lacking an adequate economic microfoundation of the    ( representative ) agent behaviour .",
    "the terms `` risk - avoiding '' and    `` risk - seeking '' are used to denote the investment preference of the    agent .",
    "however , since decisions are always taken based on just the    expected return , the behaviour of the agent has to be classified as    `` risk neutral ''  risk - adverse agents indeed account also for the    `` variance '' of returns in their decisions . recent literature in    economics and finance",
    "presents a more realistic approach about    behaviour toward risk . @xcite _ multi - assets _ : : :    agents in our model can only invest in one ( risky ) asset , whereas in    financial markets multi - asset investments and portfolio strategies    play the most crucial role .",
    "@xcite multi - asset optimal    investment strategies for risky assets were already discussed 50 years    ago , with an interesting relation to gambling @xcite .",
    "more recently ,    investment strategies to readjust portfolios @xcite have been    extended @xcite for a general distribution of return per capital .",
    "similar to our model , these contributions consider exogeneous returns    which are drawn from a probability distribution or are modeled by a    stochastic processes .",
    "we thank dagmar monett daz for her help in finding the optimal parameters for the genetic algorithm applied in this paper using the _ + carps _ tool and shown in table 1 .",
    "we furthermore thank joo f. m. rodrigues , mauro napoletano and robert mach for valuable comments and discussions , and the latter one for his help in obtaining the data and creating the plots for figure [ fig : rq ] .",
    "breiman , l. ( 1960 ) .",
    "investment policies for expanding businesses optimal in a long- run sense .",
    "_ naval research logistics _ * 7(4 ) * , 647651 .",
    "a reprint can be found in stochastic optimization models in finance , eds .",
    "w.t . ziemba and r.g .",
    "vickson , academic press , new york ( 1975 ) 593 - 598 .",
    "daniels , m. ; farmer , j.  d. ; gillemot , l. ; iori , g. ; smith , d.  e. ( 2003 ) . quantitative model of price diffusion and market friction based on trading as a mechanistic random process .",
    "_ physical review letters",
    "_ * 90(10 ) * , 108102 .",
    "follmer , h. ; horst , u. ; kirman , a. ( 2005 ) .",
    "equilibria in financial markets with heterogeneous agents : a probabilistic perspective .",
    "_ journal of mathematical economics _",
    "* 41(1 - 2 ) * , 123155 .",
    "special issue on evolutionary finance .",
    "gode , d.  k. ; sunder , s. ( 1993 ) .",
    "allocative efficiency of markets with zero - intelligence traders : market as a partial substitute for individual rationality .",
    "_ journal of political economy _",
    "* 101(1 ) * , 119137 .",
    "monett , d. ( 2004 ) .",
    "+ carps : configuration of metaheuristics based on cooperative agents . in : c.  blum ; a.  roli ; m.  sampels ( eds . ) , _ proceedings of the 1@xmath179 international workshop on hybrid metaheuristics , hm2004 , at the 16@xmath180 european conference on artificial intelligence , ecai2004_. valencia , spain , pp . 115125 .",
    "monett , d. ( 2004 ) .",
    "collaborative jade agents enabling the configuration of algorithms . in : d.  khadraoui ( ed . ) , _ proceedings of the international conference on advances in intelligent systems  theory and applications , aista2004_. ieee computer society , kirchberg ",
    "luxembourg , luxembourg : university of canberra and crp henri tudor .",
    "navarro - barrientos , j.  e. ; schweitzer , f. ( 2003 ) .",
    "the investors game : a model for coalition formation . in : l.",
    "czaja ( ed . ) , _ proceedings of the workshop on concurrency , specification and programming , cs&p2003_. czarna , poland : warsaw university , vol .  2 , pp",
    ". 369381 ."
  ],
  "abstract_text": [
    "<S> we study the performance of various agent strategies in an artificial investment scenario . </S>",
    "<S> agents are equipped with a budget , @xmath0 , and at each time step invest a particular fraction , @xmath1 , of their budget . </S>",
    "<S> the return on investment ( roi ) , @xmath2 , is characterized by a periodic function with different types and levels of noise . </S>",
    "<S> risk - avoiding agents choose their fraction @xmath1 proportional to the expected positive roi , while risk - seeking agents always choose a maximum value @xmath3 if they predict the roi to be positive ( `` everything on red '' ) . </S>",
    "<S> in addition to these different strategies , agents have different capabilities to predict the future @xmath2 , dependent on their internal complexity . here </S>",
    "<S> , we compare zero - intelligent agents using technical analysis ( such as moving least squares ) with agents using reinforcement learning or genetic algorithms to predict @xmath2 . </S>",
    "<S> the performance of agents is measured by their average budget growth after a certain number of time steps . </S>",
    "<S> we present results of extensive computer simulations , which show that , for our given artificial environment , ( i ) the risk - seeking strategy outperforms the risk - avoiding one , and ( ii ) the genetic algorithm was able to find this optimal strategy itself , and thus outperforms other prediction approaches considered .    </S>",
    "<S> _ keywords : _ risk , investment strategies , genetic algorithm    _ pacs nos . : _ 05.40.-a , 89.65.gh </S>"
  ]
}