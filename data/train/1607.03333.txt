{
  "article_text": [
    "aliency detection , which is to predict where human looks in the image , has attracted a lot of research interests in recent years .",
    "it serves as an important pre - processing step in many problems such as image classification , image retargeting and object recognition @xcite . unlike rgb saliency detection which receives much research attention , there are not many exploration on rgbd cases .",
    "the recently emerged sensing technologies , such as time - of - flight sensor and microsoft kinect , provides excellent ability and flexibility to capture rgbd image @xcite .",
    "detecting rgbd saliency becomes essential for many applications such as 3d content surveillance , retrieval , and image recognition @xcite . in this paper , we focus on how to integrate rgb and the additional depth information for rgbd saliency detection .",
    "+    [ fig : intro ]    according to how saliency is defined , saliency detection methods can be classified into two categories : top - down approach and bottom - up approach @xcite .",
    "top - down saliency detection is task - dependent that incorporates high level features to locate the salient object . on the other hand , bottom - up approach",
    "is task - free , and it utilizes low level features that are biologically motivated to estimate salient regions .",
    "most of the existing bottom - up saliency detection methods focus on designing different low - level cues to represent salient objects .",
    "the saliency maps of these low - level features are then fused to become a master saliency map .",
    "as human attention are preferentially attracted by the high contrast regions with their surrounding , contrast - based features ( like the color , edge orientation or texture contrasts ) make a crucial role to derive the salient objects .",
    "background @xcite and color compactness priors  @xcite consider salient object in different perspectives .",
    "the first one leverages the fact that most of the salient objects are far from image boundaries , the latter one utilizes the color compactness of the salient object .",
    "in addition to rgb information , depth has been shown to be one of the practical cue to extract saliency @xcite .",
    "most existing approaches for 3d saliency detection either treat the depth map as an indicator to weight the rgb saliency map @xcite or consider depth cues as an independent image channel @xcite .    notwithstanding",
    "the demonstrated success of these features , whether these features complement to each other remains a question .",
    "the interaction mechanism of different saliency features is not well explored , and it is not clear how to integrate 2d saliency features with depth - induced saliency feature in a better way .",
    "linearly combining the saliency maps produced by these features can not guarantee better result ( as shown in figure  [ fig : intro : g ] ) .",
    "some other more complex combination algorithms have been proposed in @xcite .",
    "_ @xcite propose a multi - layer cellular automata ( mca , a bayesian framework ) to merge different saliency maps by taking advantage of the superiority of each saliency detection methods .",
    "recently , several heuristic algorithms are designed to combine the 2d related saliency maps and depth - induced saliency map @xcite . however , as restricted by the computed saliency values , these saliency map combination methods are not able to correct wrongly estimated salient regions .",
    "for example in figure [ fig : intro ] , heuristic based algorithms ( figure [ fig : intro : d ] to [ fig : intro : f ] ) can not detect the salient object correctly . adopting these saliency maps for further fusion , neither simple linear fusion ( figure [ fig : intro : g ] ) nor mca integration ( figure [ fig : intro : h ] ) are able to recover the salient object .",
    "we wonder whether a good integration can address this problem by further adopting convolutional neural network technique to train a saliency map integration model . the resulted image shown in figure [ fig : intro : i ]",
    "indicates that saliency map integration is hugely influenced by the quality of the input saliency maps . based on the these observations ,",
    "we take one step back to handle more raw and flexible saliency features .    in this paper",
    ", we propose a deep fusion framework for rgbd saliency detection .",
    "the proposed method takes advantage of the representation learning power of cnn to extract the hyper - feature by fusing different hand - designed saliency features to detect salient object ( as shown in figure  [ fig : intro : j ] ) .",
    "we first compute several feature vectors from original rgbd image , which include local and global contrast , background prior , and color compactness .",
    "we then propose a cnn architecture to incorporate these regional feature vectors into a more representative and unified features .",
    "compared with feeding raw image pixels , these extracted saliency features are well - designed and they can guide the learning of cnn towards saliency - optimized more effectively . as",
    "the resulted saliency map may suffer from local inconsistency and noisy false positive , we further integrate a laplacian propagation framework with the proposed cnn .",
    "this approach propagates high confidence saliency to the other regions by taking account of the color and depth consistency and the intrinsic structure of the input image @xcite , which is able to remove noisy values and produce smooth saliency map .",
    "the laplacian propagation is solved with fast convergence by the adoption of conjugate gradient and preconditioner .",
    "experimental evaluations demonstrate that , once our deep fusion framework are properly trained , it generalizes well to different datasets without any additional training and outperforms the state - of - the - art approaches .",
    "the main contributions of this paper are summarized as follows .",
    "we propose a simple yet effective deep learning model to explore the interaction mechanism of rgb and depth - induced saliency features for rgbd saliency detection .",
    "this deep model is able to generate representative and discriminative hyper - features automatically rather than hand - designing heuristical features for saliency .",
    "we adopt laplacian propagation to refine the resulted saliency map and solve it with fast convergence .",
    "different from crf model , our laplacian propagation not only considers the spatial consistency but also exploits the intrinsic structure of the input image @xcite .",
    "extensive experiments further demonstrate that this proposed laplacian propagation is able to refine the saliency maps of existing approaches , which can be widely adopted as a post processing step .",
    "we investigate the limitations of saliency map integration , and demonstrate that simple features fusion are able to obtain superior performance .",
    "in this section , we give a brief survey and review of rgb and rgbd saliency detection methods , respectively .",
    "comprehensive literature reviews on these saliency detection methods can be found in  @xcite .",
    "* rgb saliency detection : * as suggested by the studies of cognitive science  @xcite , bottom - up saliency is driven by low - level stimulus features . this concept is also adopted in computer vision to model saliency .",
    "contrast - based cues , especially color contrast , are the most widely adopted features in previous works .",
    "these contrast - based methods can be roughly classified into two categories : local and global approaches .",
    "local method calculates color , edge orientation or texture contrast of a pixel / region with respect to a local window to measure saliency @xcite . in @xcite , they develop an early local based visual saliency detection method by computing center surrounding differences across multi - scale image features to estimate saliency .",
    "_ @xcite propose to apply sparse representation on local image patches .",
    "however , based only on local contrast , these methods may highlight the boundaries of salient object @xcite and be sensitive to high frequency content @xcite .",
    "in contrast to local approach , the global approach measures salient region by estimating the contrast over the entire image .",
    "_ @xcite model saliency by computing color difference to the mean image color .",
    "et al .  _",
    "@xcite propose a histogram - based global contrast saliency method by considering the spatial weighted coherence .",
    "although these global methods achieve superior performances , they may suffer from distractions when background shares similar color to the salient object .",
    "background and color compactness priors are proposed as a complement to contrast - based methods @xcite .",
    "these methods are built on strong assumptions , which may invalid in some scenarios .    as each feature has different strengths ,",
    "some works focus on designing the integration mechanism for different saliency features @xcite .",
    "et al .  _",
    "@xcite use crf to integrate three different features from both local and global point of views .",
    "et al .  _",
    "@xcite propose a hierarchical framework to integrate saliency maps in different scales , which can handle small high contrast regions well . unlike these methods that directly combine the saliency maps obtained from different saliency cues , the proposed method records low - level saliency feature in vector forms and",
    "jointly learns the interaction mechanism to become a hyper - feature with cnn .",
    "similar to the proposed method , cnn has been adopted in some other works to extract hierarchical feature representations for detecting salient regions @xcite .",
    "in contrast to most of these deep networks that take raw image pixels as input , the proposed method aims at designing a unified cnn framework to learn the interaction mechanism of different saliency cues .",
    "* rgbd saliency detection : * unlike rgb saliency detection , rgbd saliency receives less research attention @xcite .",
    "et al .  _",
    "@xcite propose an early computational model on depth - based attention by measuring disparity , flow and motion .",
    "similar to color contrast , zhang _ et al .",
    "_ design a stereoscopic visual attention algorithm based on depth and motion contrast for 3d video @xcite .",
    "et al .  _",
    "@xcite estimate saliency regions by fusing the saliency maps produced by appearance and depth cues independently .",
    "these methods either treat the depth map as an indicator to weight the rgb saliency map @xcite or consider depth map as an independent image channel for saliency detection @xcite . on the other hand , peng _ et al .  _",
    "@xcite propose a multi - stage rgbd model to combine both depth and appearance cues to detect saliency .",
    "et al .  _",
    "@xcite integrate the normalized depth prior and the surface orientation prior with rgb saliency cues directly for the rgbd saliency detection .",
    "these methods combine the depth - induced saliency map with rgb saliency map either directly @xcite or in a hierarchy way to calculate the final rgbd saliency map @xcite . however , these saliency map level integration is not optimal as it is restricted by the determined saliency values . on the contrary ,",
    "we incorporate different saliency cues and fuse them with cnn in feature level .",
    "as shown in figure [ fig : convnet ] , the proposed deep fusion framework for rgbd salient object detection composes of three modules .",
    "the first module generates various saliency feature vectors for each superpixel region .",
    "the second module is to extract hyper - feature representation from the obtained saliency feature vectors .",
    "the third module is the laplacian propagation framework which helps to detect a spatially consistent saliency map .",
    "given an image , we aim to represent saliency by some demonstrated effective saliency features .",
    "figure [ fig : saliency_cue ] gives an illustration on the proposed saliency feature extraction .",
    "we first segment the image into _",
    "n _ superpixels using slic method @xcite . given a rgb image @xmath0",
    ", we denote the segmented _",
    "n _ regions as @xmath1 . for each superpixel @xmath2",
    ", we denote the calculated saliency features as a vector @xmath3 . in the following ,",
    "we will take region @xmath4 ( the region that marked in orange in figure [ fig : saliency_cue ] ) as an example to show how we calculate different saliency feature vectors .        different from the classical saliency detection methods that directly calculate the saliency values for each superpixel , we record the saliency features for each image region and no further operation",
    "is performed to make saliency features as raw as possible . for region",
    "@xmath4 , there are seven types of feature vectors : @xmath5 , where @xmath6 and @xmath7 represent color and depth information respectively , @xmath8 indicates that saliency is determined in the local scope and @xmath9 indicates the global scope , @xmath10 and @xmath11 represent the background and color compactness priors respectively .",
    "more specifically , the color based feature vectors are recorded in the following formula , @xmath12 and the depth based feature vectors are defined similarly .",
    "we compute the color - based features in @xmath13 color space .",
    "the local color contrast @xmath14 is calculated as : @xmath15 where @xmath16 is the total number of pixels in region @xmath17 , and a larger superpixel contributes more to the saliency . @xmath18 and @xmath19 are the mean color values of the region @xmath4 and @xmath17 .",
    "@xmath20 is used to control the spatial influential distance .",
    "this weight is defined as @xmath21 , and @xmath22 and @xmath23 are the centers of corresponding regions . in our experiment , the parameter @xmath24 = 0.15 is set to make the neighbors have higher influence on the calculated contrast values , while the influence of other regions are negligible .",
    "similar to the local color contrast vector , the global color contrast vector is defined as , @xmath25 the difference between the global contrast and local contrast lies in the spatial weight @xmath26 , where in the global contrast the parameter @xmath27 is set to 0.45 to cover the entire image .    likewise , the depth contrast between region @xmath17 and region @xmath4 can be calculated as in eq .",
    "[ depth_local ] and eq .",
    "[ depth_global ] .",
    "@xmath28 @xmath29 where @xmath30 and @xmath31 are the mean depth values of the region @xmath4 and @xmath17 respectively .    generally speaking , the colors of an object are compacted together whereas the colors belong to the background are widely distributed in the entire image . the element @xmath32 in the color compactness based feature vector is calculated as following .",
    "@xmath33 where the function @xmath34 is used to calculate the similarity of two colors @xmath35 and @xmath36 , and is defined as @xmath37 .",
    "@xmath38 defines the weighted mean position of color @xmath35 .",
    "the parameter @xmath39 is set to 20 in our implementation .",
    "we omit the depth compactness prior in our method since the depth map contains only dozens of depth levels and their spatial distributions can be very random .",
    "the experiment results also show that whether adding the depth compactness or not does not affect the final results too much .    beside color compactness",
    "prior , we further introduce the background prior , which leverages the fact that salient object is less possible to be arranged to close to the image boundaries .",
    "we first extract @xmath40 regions along the image boundary as pseudo - background regions .",
    "then the color or depth contrast to the pseudo - background regions will be calculated similar to eq .",
    "[ color_contrast_global ] and eq .",
    "[ depth_global ] . in our experiment ,",
    "the number of superpixels @xmath41 is set to 1024 and @xmath40 is set to 160 .",
    "given the obtained saliency feature vectors , we then propose a cnn architecture to automatically incorporate them into unified and representative features .",
    "we formulate saliency detection as a binary logistic regression problem , which takes a patch as input and output the probabilities of two classes .",
    "our cnn takes an input of size @xmath42 , and generates a prediction as saliency output . for each superpixel @xmath4 , all the seven saliency feature vectors are integrated into a multiple channel image as follows :    \\(1 ) reshape the @xmath41 length vector ( @xmath43 , @xmath44 , @xmath45 , @xmath46 and @xmath47 ) to size @xmath48 to form the first five channels , respectively ;    \\(2 ) perform zero padding to the @xmath40 length vector @xmath49 and @xmath50 to length @xmath51 and then concatenate and reshape them into size @xmath48 to form the sixth channel .",
    "as shown in figure [ fig : convnet ] , our network consists of three convolutional layers followed by a fully connected layer and a logistic regression output layer with sigmoid nonlinear function .",
    "following the first and second convolutional layers , we add an average pooling layer for translation invariance .",
    "we adopt the sigmoid function as the nonlinear mapping function for the three convolutional layers , while rectified linear unites ( relus ) is applied in the last two layers .",
    "dropout procedure is applied after the first fully connected layers to avoid overfitting .    for simplification ,",
    "we use @xmath52 and @xmath53 to indicate the convolutional layer and the fully connected layer with @xmath41 output and kernel size @xmath54 .",
    "@xmath55 indicates the pooling layer with type @xmath56 and kernel size @xmath54 . @xmath57 and",
    "@xmath58 represent the sigmoid function and relus .",
    "then the architecture of our cnn can be described as @xmath59 .",
    "this proposed cnn was trained with back - propagation using stochastic gradient descent ( sgd ) .",
    "as saliency values are estimated for each superpixel individually , the proposed cnn in section [ title_3_2 ] may fail to retain the spatial consistency and lead to noisy output .",
    "figure [ fig : init_refine : c ] shows two examples of the saliency maps produced by our cnn for rgbd image .",
    "it indicates that our cnn omits some salient regions and wrongly detects some background regions as salient . despite these misdetected regions , most of the regions with high probability to be salient are correct , robust , and reliable .",
    "the same situation also occurs for non - salient probability in the background ( figure [ fig : init_refine : d ] ) . as a consequence ,",
    "these high confident regions are used as guidance , and they are employed in a laplacian propagation framework @xcite to obtain a more spatially consistent saliency map .",
    "the key of the laplacian propagation lies in propagating the saliency from the regions with high probability to those ambiguous regions by considering two criteria : ( 1 ) neighboring regions are more likely to have similar saliency values ; and ( 2 ) regions within the same manifold are more likely to have similar saliency values .",
    "+   +    [ fig : init_refine ]    given a set of superpixels @xmath60 of an input image @xmath0 and a label set @xmath61 , we denote the salient and non - salient probability generated by the proposed cnn as @xmath62 and @xmath63 .",
    "the superpixels in @xmath64 are labeled as 1 if @xmath65 , or as 2 if @xmath66 .",
    "the goal of laplacian propagation is to predict the labels of the remaining regions .",
    "let @xmath67^t}$ ] denotes a @xmath68 non - negative matrix which corresponds to the binary classification results of @xmath64 , and each region @xmath4 is assigned with a label @xmath69 , where @xmath70 .",
    "an indicator matrix is defined as @xmath71_{n \\times 2}}$ ] with @xmath72 if region @xmath4 is labeled as @xmath73 , otherwise @xmath74 .",
    "we further adopt the color and depth information to form the affinity matrix @xmath75_{n \\times n}}$ ] : @xmath76 where the first term defines the color distance of superpixel region @xmath4 and @xmath17 , and the second term defines the relative depth distance .",
    "most of the elements of the affinity matrix @xmath77 are zero except for those neighbouring @xmath4 and @xmath17 pairs . in order to better leverage the local smoothness ,",
    "we use a two - hierarchy neighboring connection model , i.e. , each region is not only connected to its neighboring regions but also connected to the regions that share the same boundaries with its neighboring regions .",
    "we set @xmath78 to avoid self - reinforcement .",
    "then the laplacian propagation can be formulated to solve the following optimization functions : @xmath79 @xmath80 where parameter @xmath81 controls the balance between the smoothness constraint ( the first term ) and the fitting constraint ( the second term ) .",
    "@xmath82 is the element of the degree matrix @xmath83 derived from affinity matrix @xmath77 , and @xmath84 .",
    "this designed smoothness constraint not only considers local smoothness but also confines the regions within the same manifold to have the same label by constructing a smooth classifying function .",
    "this classifying function can change sufficiently slow along the coherent structure revealed by the original image @xcite .",
    "this optimization function eq .",
    "[ sal_optimization ] can be solved using an iteration algorithm as shown in @xcite , or it can be reformulated into a linear system . for efficiency , we set the derivative of the @xmath85 to zero and the optimal solution of eq .",
    "[ sal_optimization ] can be obtained by solving the following linear equation : @xmath86 where @xmath87 is an identity matrix and @xmath88 .",
    "we further adopt conjugate gradient and preconditioner to solve this linear equation for fast convergence .    after propagating from the high probability salient and non - salient regions ,",
    "the final saliency map is normalized to [ 0,1 ] and it is denoted as @xmath89 .",
    "two examples of the proposed propagation are shown in figure [ fig : init_refine ] . those wrongly estimated regions in figure [ fig : init_refine : b ] and figure [ fig : init_refine : c ]",
    "are corrected in the final saliency maps produced by the laplacian propagation . in our implementation , parameters @xmath90 and @xmath91",
    "are adaptively determined by otsu method @xcite .",
    "+   +   +   +   +   +   +   +   +",
    "in this section , we evaluate the proposed method on three datasets , nlpr rgbd salient dataset @xcite , njuds2000 stereo datast @xcite , and lfsd dataset @xcite .    * nlpr dataset @xcite . * the nlpr rgbd salient dataset @xcite contains 1000 images captured by microsoft kinect in different indoor and outdoor scenarios .",
    "we split this dataset into two part randomly : 750 for training and 250 for testing .    *",
    "njuds2000 dataset @xcite . *",
    "the njuds2000 dataset contains 2000 stereo images , as well as the corresponding depth maps and manually labeled groundtruth .",
    "the depth maps are generated using an optical flow method .",
    "we also split this dataset into two part randomly : 1000 for training and 1000 for testing .",
    "* lfsd dataset @xcite . *",
    "the lfsd dataset @xcite contains 100 images with depth information and manually labeled groundtruth .",
    "the depth information are captured with lytro light field camera .",
    "all the images in this dataset are for testing",
    ".    * evaluation metrics . *",
    "we compute the precision - recall ( pr ) curve , mean of average precision and recall , and f - measure score to evaluate the performance of different saliency detection methods .",
    "the pr curve indicates the mean precision and recall of the saliency map at different thresholds .",
    "the f - measure is defined as @xmath92 , where @xmath93 is set to 0.3 .",
    "we use the randomly sampled 750 training images of nlpr dataset @xcite and the randomly sampled 1000 training images of njuds2000 dataset @xcite to train our deep learning framework .",
    "these randomly selected training dateset covers more than 1000 kinds of common objects under different circumstances .",
    "the remaining nlpr , njuds2000 , and lfsd datesets are used to verify the generalization of the proposed method .",
    "the proposed method is implemented using matlab .",
    "we set the momentum in our network to 0.9 and the weight decay to be 0.0005 .",
    "the learning rate of our network is gradually decreased from 1 to 0.001 . due to the `` data - hungry '' nature of cnn ,",
    "the existing training data is insufficient for training , in addition to the dropout procedure , we also employed data augmentation to enrich our training dataset . similar to @xcite , we adopted two different image augmentation operations , the first one consists of image translations and horizontal flipping and the other is to alter the intensities of the rgb channels .",
    "these data augmentations greatly enlarge our training dataset and make it possible for us to train the proposed cnn without overfitting .",
    "it took around @xmath94 days for our training to converge .",
    "ours + nlpr test set & 0.5141 & 0.5634 & 0.6049 & 0.6335 & 0.6519 & 0.5448 & 0.7184 & * 0.7823 * + njud test set & 0.6096 & 0.6133 & 0.6156 & 0.6791 & 0.6381 & 0.6952 & 0.7246 & * 0.7874 * + lfsd dataset & 0.6982 & 0.7311 & 0.7029 & 0.7384 & 0.7041 & 0.7567 & 0.7877 & * 0.8439 * +             in this section , we compare our method with four state - of - the - art methods designed for rgb image ( s - cnn @xcite , bsca @xcite , mb+ @xcite , and legs @xcite ) , and three rgbd saliency methods designed specially for rgbd image ( lmh @xcite , acsd @xcite , and gp @xcite ) .",
    "the results of these different methods are either provided by authors or achieved using the publicly available source codes .",
    "the qualitative comparisons of different methods on different scenes are shown in figure [ fig : saliency2 ] . as can be seen in the first and fifth rows of figure [ fig : saliency2 ]",
    ", the salient object has a high color contrast with the background , as thus rgb saliency methods are able to detect salient object correctly .",
    "however , when the salient object shares similar color with the background , e.g. , sixth , seventh , and eighth rows in figure [ fig : saliency2 ] , it is difficult for existing rgb models to extract saliency . with the help of depth information , salient object can be easily detected by the proposed rgbd method .",
    "figure [ fig : saliency2 ] also shows that the proposed method consistently outperforms all the other rgbd saliency methods ( lmh @xcite , acsd @xcite , and gp @xcite ) .",
    "the quantitative comparisons on nlpr , njuds2000 , and lfsd dataset are shown in figure [ fig : saliency_qut ] and table [ table : belta ] .",
    "figure [ fig : saliency_qut ] and table [ table : belta ] show that the proposed method performs favorably against the existing algorithms with higher precision , recall values and f - measure scores on all the three datasets . for the nlpr dataset ,",
    "it is challenging as most of the salient object share similar color to the background . as a consequence ,",
    "rgb saliency methods perform relative worse than rgbd saliency methods in terms of precision . by providing accurate depth map ( nlpr dataset ) ,",
    "lmh @xcite and gp @xcite methods perform well in both precision and recall",
    ". however , they performs not well when tested on the njuds2000 dataset and lfsd dataset .",
    "this is because these two datasets provide only the rough depth information ( calculated from stereo images or using light field camera ) , lmh @xcite and gp @xcite can only detect a small fraction of the salient objects ( high precision but with low recall ) .",
    "acsd @xcite works worse when the salient object lies in the same plane with the background , e.g. , the third row in the figure [ fig : saliency2 ] , and the bad quantitative results on the nlpr dataset .",
    "both qualitative and quantitative results show that the proposed method performs better in terms of accuracy and robustness than the compared methods with rgbd input images .     & lf & crf & mca & cnn - f & lf & crf & mca & cnn - f & lmh & gp & + & 0.393 & 0.2991 & 0.3713 & 0.4667 & 0.7020 & 0.698 & 0.7017 & 0.6921 & 0.6519 & * 0.718 & + yes & * 0.536 & * 0.398 & * 0.486 & * 0.597 & * 0.711 & * 0.739 & * 0.7623 & * 0.737 & * 0.665&0.7111&*0.7823 * + * * * * * * * * * *     & lf & crf & mca & cnn - f & lf & crf & mca & cnn - f & lmh & gp & + & 0.437 & 0.450 & 0.458 & 0.644 & 0.675 & 0.671 & 0.7376 & 0.7319 & 0.6381 & * 0.7246 & + yes & * 0.605 & * 0.609 & * 0.632 & * 0.731 & * 0.698 & * 0.741 & * 0.742 & * 0.7423 & * 0.6810&0.7179&*0.7874 * + * * * * * * * * * *     & lf & crf & mca & cnn - f & lf & crf & mca & cnn - f & lmh & gp & + & 0.461 & 0.436 & 0.558 & 0.672 & 0.723 & 0.771 & 0.8071 & 0.706 & 0.704 & * 0.7877 & + yes & * 0.616 & * 0.693 & * 0.654 & * 0.757 & * 0.762 & * 0.792 & * 0.802 & * 0.800 & * 0.718 & 0.7830&*0.8439 * + * * * * * * * * * *    * saliency maps vs. features . * in here we conduct a series of experiments to analyze the flexibility of the proposed framework and the effectiveness of laplacian propagation . apart from previous heuristic saliency map merging algorithm @xcite",
    ", we further compare our method with four other saliency map integration methods on three test dataset @xcite to show the flexibility of fusing different cues in feature level .",
    "these four integration methods are directly linear fusion ( lf ) , fusing in crf @xcite , the latest multi - layer cellular automata ( mca ) integration @xcite , and a cnn based fusion ( denoted as cnn - f ) . to investigate the importance of saliency map quality , we test these saliency map merging methods on two set of inputs .",
    "the first set is from seven saliency maps computed by widely used features ( similar to those seven saliency feature vectors computed in section [ title_3_1 ] ) , and the second set is from more representative sophisticated saliency maps ( obtained using three state - of - the - art rgbd saliency detection methods @xcite ) .",
    "the original crf fusion framework in @xcite is utilized for merging three color based saliency maps . in our implementation",
    ", we retrain this crf framework for merging the seven adopted fundamental saliency maps and three sophisticated saliency maps respectively .    for cnn - f , we utilize the same cnn architecture as shown in fig .",
    "[ fig : saliency_cue ] to perform the cnn based saliency map fusion , i.e. , the same convolutional layers and fully connected layers except the input layer .",
    "more specifically , we formulate the saliency map merging as a binary logistic regression problem , which takes several saliency map patches as input ( size @xmath95 for fundamental saliency map merging and @xmath96 for sophisticated saliency map merging ) , and output the probabilities of the pixel being salient and non - salient .",
    "cnn - f is trained in patch - wise manner .",
    "we collect training samples by cropping patches of size @xmath97 from each saliency map using sliding window .",
    "we label a patch as salient if the central pixel is salient or 75% pixels in this patch are salient , otherwise it is labeled as non - salient .",
    "this cnn - f is trained on the cropped patches of the nlpr training set @xcite and njuds2000 training set @xcite .",
    "the relevant comparison results of our proposed methods with these saliency map merging methods are shown in figure [ fig : sal_map ] , table [ table : anlysis_nlpr ] , table [ table : anlysis ] , and table [ table : anlysis_lfsd ] .",
    "`` fundamental fusion '' represents the results of four merging methods performed on seven fundamental saliency maps .",
    "`` heuristic fusion '' gives the results of two state - of - the - art heuristic saliency map merging methods @xcite , while `` sophisticated fusion '' gives the results of four merging methods performed on three sophisticated saliency maps ( calculated from the existing state - of - the - art rgbd saliency detection methods lmh @xcite , acsd @xcite , and gp @xcite ) .",
    "for `` fundamental fusion '' in table [ table : anlysis_lfsd ] , all the existing saliency map merging methods ( including deep learning framework ) can not achieve satisfactory performance .",
    "even though feeding with the state - of - the - art sophisticated saliency maps , these saliency merging methods still perform worse than our saliency feature fusion without lp framework ( 0.8071 vs 0.8157 ) , which further validates the flexibility of our feature level fusion .",
    "note that 0.8157 are obtained from our initial saliency feature fusion network , which performs only on the pixel level and without considering spatial consistency .",
    "our model achieves superior performance even though the input features are very simple ( similar to the features used in `` fundamental fusion '' ) .",
    "compared to those methods using similar features ( in `` fundamental fusion '' ) , we can observe that fusing features is much more flexible than fusing saliency map .",
    "+   +   +   +   +   +    * analysis of laplacian propagation .",
    "* we then evaluate the effective of the proposed laplacian propagation , and the optimized results of the existing methods using laplacian propagation .",
    "the f - measure scores of our rgbd method without laplacian propagation on three test dataset @xcite are shown in blue in table [ table : anlysis_nlpr ] , table [ table : anlysis ] , and table [ table : anlysis_lfsd ] .",
    "these learned hyper - features still outperform the state - of - the - art approaches , while with lp we achieve almost 0.79 , 0.79 , and 0.84 f - measures .",
    "figure [ fig : sal_lp ] shows some examples of the optimized results of the existing methods ( lmh @xcite , acsd @xcite , and gp @xcite ) using laplacian propagation .",
    "these quantitative and qualitative experimental evaluations further demonstrate that the proposed laplacian propagation is able to refine the saliency maps of existing methods , which can be widely adopted as a post processing step",
    ".     +   +   +   +   +   +   +    * failure cases .",
    "* figure [ fig : saliencyrgbvsrgbd ] gives more visual results and some failure cases of our proposed method on rgbd images .",
    "compared with the these two pictures , we can find that depth information is more helpful when the salient objects have high depth contrast with background or lie closer to the camera .",
    "our method may fail when the salient object shares a very similar color and depth information with the background .",
    "in this paper , we propose a novel rgbd saliency detection method .",
    "our framework consists of three different modules .",
    "the first module generates various low level saliency feature vectors from the input image .",
    "the second module learns the interaction mechanism of rgb saliency features and depth - induced features and produces hyper - feature using cnn .",
    "feeding with these hand - designed features can guide the learning process of cnn towards saliency - optimized . in the third module",
    ", we integrate a laplacian propagation framework with cnn to obtain a spatially consistent saliency map .",
    "both quantitative and qualitative experiment results show that the fused rgbd hyper - feature outperforms all the state - of - the - art methods .",
    "we demonstrated that an optimized fusion leads to superior performance , and this flexible hyper - feature extraction framework can be further extended by including more saliency cues ( e.g. , flash cue @xcite ) .",
    "we aim to explore a deeper and more effective fusion network and extend it to other applications in our future work .",
    "d.  banica and c.  sminchisescu , `` second - order constrained parametric proposals and sequential search - based structured prediction for semantic segmentation in rgb - d images , '' in _ cvpr _ , 2015 , pp .",
    "35173526 .",
    "liangqiong qu received the b.s .",
    "degree in automation from central south university , china , in 2011 .",
    "she is currently a joint ph.d .",
    "student of university of chinese academy of sciences and city university of hong kong .",
    "her research interests include illumination modeling , image processing , saliency detection and deep learning .",
    "shengfeng he obtained his b.sc .",
    "degree and m.sc .",
    "degree from macau university of science and technology , and the ph.d degree from city university of hong kong .",
    "he is currently a research fellow at city university of hong kong .",
    "his research interests include computer vision , image processing , computer graphics , and deep learning .",
    "jiawei zhang received his beng degree in electronic information engineering from the university of science and technology of china in 2011 and master degree in institute of acoustics , chinese academy of sciences in 2014 .",
    "he is currently a computer science phd student in city university of hong kong .",
    "jiandong tian received his b.s .",
    "degree in automation at heilongjiang university , china , in 2005 .",
    "he received his ph.d .",
    "degree in pattern recognition and intelligent system at chinese academy of sciences , china , in 2011 .",
    "he is currently an asassociate professor in computer vision at state key laboratory of robotic , shenyang institute of automation , chinese academy of sciences .",
    "his research interests include pattern recognition and robot vision .",
    "yandong tang received b.s . and",
    "degrees in the department of mathematics , shandong university in 1984 and 1987 . in 2002",
    "he received the doctor s degree in applied mathematics from the university of bremen , germany .",
    "currently he is a professor in shenyang institute of automation , chinese academy of sciences .",
    "his research interests include robot vision , pattern recognition and numerical computation .",
    "qingxiong yang received the b.e .",
    "degree in electronic engineering and information science from the university of science and technology of china , hefei , china , in 2004 , and the ph.d .",
    "degree in electrical and computer engineering from the university of illinois at urbana - champaign , champaign , il , usa , in 2010 .",
    "he is currently an assistant professor with the department of computer science , city university of hong kong , hong kong .",
    "his research interests reside in computer vision and computer graphics .",
    "he was a recipient of the best student paper award at the 2010 international workshop on multimedia signal processing and the best demo award at the 2007 ieee computer society conference on computer vision and pattern recognition ."
  ],
  "abstract_text": [
    "<S> numerous efforts have been made to design different low level saliency cues for the rgbd saliency detection , such as color or depth contrast features , background and color compactness priors . </S>",
    "<S> however , how these saliency cues interact with each other and how to incorporate these low level saliency cues effectively to generate a master saliency map remain a challenging problem . in this paper , we design a new convolutional neural network ( cnn ) to fuse different low level saliency cues into hierarchical features for automatically detecting salient objects in rgbd images . </S>",
    "<S> in contrast to the existing works that directly feed raw image pixels to the cnn , the proposed method takes advantage of the knowledge in traditional saliency detection by adopting various meaningful and well - designed saliency feature vectors as input . this can guide the training of cnn towards detecting salient object more effectively due to the reduced learning ambiguity . </S>",
    "<S> we then integrate a laplacian propagation framework with the learned cnn to extract a spatially consistent saliency map by exploiting the intrinsic structure of the input image . </S>",
    "<S> extensive quantitative and qualitative experimental evaluations on three datasets demonstrate that the proposed method consistently outperforms state - of - the - art methods .    </S>",
    "<S> shell : bare demo of ieeetran.cls for ieee journals    rgbd saliency detection , convolutional neural network , laplacian propagation . </S>"
  ]
}