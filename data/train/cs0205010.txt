{
  "article_text": [
    "the van  emde  boas data structure ( veb )  @xcite represents an ordered multiset of integers .",
    "the data structure supports query operations for the current minimum and maximum element , the predecessor and successor of a given element , and the element closest to a given number , as well as the operations of insertion and deletion .",
    "each operation requires @xmath5 time , where the elements are taken from a universe @xmath6 .",
    "we give variants of the veb data structure that are faster than the original veb , but only guarantee approximately correct answers .",
    "the notion of approximation is the following : the operations are guaranteed to be consistent with the behavior of the corresponding exact data structure that operates on the elements after they are mapped by a fixed function  @xmath7 . for the multiplicatively approximate variant , the function  @xmath7 preserves the order of any two elements differing by at least a factor of some @xmath8 . for the additively approximate variant , the function  @xmath7 preserves the order of any two elements differing additively by at least some @xmath9 .",
    "let the elements be taken from a universe @xmath10 $ ] . on an arithmetic ram with @xmath11-bit words , the times required per operation in our approximate data structures are as follows : @xmath12    [ cols=\"^,^,^ \" , ]     @xmath12    the space requirements of our data structures are @xmath13 and @xmath14 , respectively .",
    "the space can be reduced to close to linear in the number of elements by using dynamic hashing .",
    "specifically , the space needed is @xmath15 , where @xmath16 is the set of elements , @xmath7 is the fixed function mapping the elements of @xmath16 ( hence , @xmath17 is the number of distinct elements under the mapping ) , and @xmath18 is the time required per operation .",
    "the overhead incurred by using dynamic hashing is constant per memory access with high probability  @xcite .",
    "thus , if the data structures are implemented to use nearly linear space , the times given per operation hold only with high probability .      [",
    "sec : description ] the approach is simple to explain , and we illustrate it for the multiplicative variant with @xmath19 and @xmath20 .",
    "let @xmath21 ( the index of @xmath22 s most significant bit ) .",
    "the mapping preserves the order of any two elements differing by more than a factor of two and effectively reduces the universe size to @xmath23 . on an arithmetic ram with @xmath11-size words ,",
    "a bit - vector for the mapped elements fits in a single word , so that successor and predecessor queries can be computed with a few bitwise and arithmetic operations .",
    "the only additional structures are a linked list of the elements and a dictionary mapping bit indices to list elements .",
    "in general , each of the approximate problems with universe size  @xmath24 reduces to the exact problem with a smaller universe size  @xmath25 : for the case of multiplicative approximation we have size @xmath26 and for the case of additive approximation @xmath27 each reduction is effectively reversible , yielding an equivalence between each approximate problem and the exact problem with a smaller universe .",
    "the equivalence holds generally for any numeric data type whose semantics depend only on the ordering of the elements .",
    "the equivalence has an alternate interpretation : each approximate problem is equivalent to the exact problem on a machine with larger words .",
    "thus , it precludes faster approximate variants that do nt take advantage of fast operations on words .    for universe sizes bigger than the number of bits in a word",
    ", we apply the recursive divide - and - conquer approach from the original veb data structure .",
    "each operation on a universe of size @xmath25 reduces to a single operation on a universe of size @xmath28 plus a few constant time operations . when the universe size is @xmath11 , only a small constant number of arithmetic and bitwise operations are required .",
    "this gives a running time of @xmath29 , where @xmath25 is the effective universe size after applying the universe reduction from the approximate to the exact problem .      in the next section",
    "we motivate our development of approximate veb data structures by demonstrating how they can be used in three well - known algorithms : prim s algorithm for minimum spanning trees , dijkstra s shortest paths algorithm , and an on - line version of the graham scan for finding convex hulls .",
    "related work is discussed in section  [ sec : related ] .",
    "our model of computation is defined in section  [ sec : model ] . in section  [ sec : veb ] , we show how to construct our approximate veb data structures and we analyze their characteristics .",
    "we make concluding remarks in section  [ sec : conclusions ] .",
    "we consider three prototypical applications : to minimum spanning trees , to single - source shortest paths , and to semi - dynamic on - line convex hulls .",
    "our approximate minimum spanning tree algorithm runs in linear time and is arguably simpler and more practical than the two known linear - time mst algorithms .",
    "our approximate single - source shortest paths algorithm is faster than any known algorithm on sparse graphs .",
    "our on - line convex hull algorithm is also the fastest known in its class ; previously known techniques require preprocessing and thus are not suitable for on - line or dynamic problems .",
    "the first two applications are obtained by substituting our data structures into standard , well - known algorithms .",
    "the third is obtained by a straightforward adaptation of an existing algorithm to the on - line case .",
    "these examples are considered mainly as prototypical applications . in general , approximate data structures can be used in place of any exact counterpart .",
    "our results below assume a ram with a logarithmic word size as our model of computation , described in more detail in section  [ sec : model ] .",
    "the proofs are simple and are given in the full paper .      for the minimum spanning tree problem ,",
    "we show the following result about the performance of prim s algorithm  @xcite when our approximate veb data structure is used to implement the priority queue :    [ thm : prim ] given a graph with edge weights in @xmath30 , prim s algorithm , when implemented with our approximate veb with multiplicative error @xmath31 , finds a @xmath31-approximate minimum spanning tree in an @xmath3-node , @xmath32-edge graph in @xmath33 time .",
    "for @xmath34 , theorem  [ thm : prim ] gives a linear - time algorithm .",
    "this algorithm is arguably simpler and more practical than the two known linear - time mst algorithms .",
    "this application is a prototypical example for which the use of an approximate data structure is equivalent to slightly perturbing the input .",
    "approximate data structures can be `` plugged in '' to such algorithms without modifying the algorithm .      for the single - source shortest paths problem ,",
    "we get the following result by using an approximate veb data structure as a priority queue in dijkstra s algorithm ( see , e.g. ,  ( * ? ? ?",
    "* thm 7.6 ) ) :    [ thm : shortestpaths ] given a graph with edge weights in @xmath6 and any @xmath35 , dijkstra s algorithm , when implemented with our approximate veb with multiplicative error @xmath36 , computes single - source shortest path distances within a factor of @xmath31 in @xmath37 time .",
    "if @xmath38 , the algorithm runs in @xmath39 time  faster than any known algorithm on sparse graphs  and is simpler than theoretically competitive algorithms .",
    "this is a prototypical example of an algorithm for which the error increases by the multiplicative factor at each step .",
    "if such an algorithm runs in polynomial time , then @xmath1 time per veb operation can be obtained with insignificant net error .",
    "again , this speed - up can be obtained with no adaptation of the original algorithm .",
    "* analysis .  *",
    "the proof of theorem  [ thm : shortestpaths ] follows the proof of the exact shortest paths algorithm ( see , e.g. ,  ( * ? ? ?",
    "* thm 7.6 ) ) .",
    "the crux of the proof is an inductive claim , saying that any vertex @xmath40 that becomes labeled during or after the scanning of a vertex @xmath41 also satisfies @xmath42 , where @xmath43 is a so - called tentative distance from the source to @xmath40 .",
    "when using a @xmath31-approximate veb data structure to implement the priority queue , the inductive claim is replaced by @xmath44 where vertex @xmath41 is the @xmath22th vertex to be scanned .",
    "thus , the accumulated multiplicative error is bounded by @xmath45 we leave the details to the full paper , and only note that it is not difficult to devise an example where the error is actually accumulated exponentially at each iteration .",
    "finally , we consider the semi - dynamic on - line convex hull problem . in this problem ,",
    "a set of planar points is processed in sequence .",
    "after each point is processed , the convex hull of the points given so far must be computed .",
    "queries of the form `` is @xmath46 in the current hull ? ''  can also be given at any time .",
    "for the approximate version , the hull computed and the answers given must be consistent with a @xmath47-approximate hull , which is contained within the true convex hull such that the distance of any point on the true hull to the approximate hull is @xmath48 times the diameter .",
    "we show the following result about the graham scan algorithm @xcite when run using our approximate veb data structure :    [ on - line ch ] the on - line @xmath47-approximate convex hull can be computed by a graham scan in constant amortized time per update if @xmath49 for any fixed @xmath50 , and in @xmath1 amortized time per update if @xmath51 .",
    "this represents the first constant - amortized - time - per - query approximation algorithm for the on - line problem .",
    "this example demonstrates the usefulness of approximate data structures for dynamic / on - line problems .",
    "related approximate sorting techniques require preprocessing , which precludes their use for on - line problems .",
    "* analysis .",
    "* graham s scan algorithm is based on scanning the points according to an order determined by their polar representation , relative to a point that is in the convex hull , and maintaining the convex hull via local corrections .",
    "we adapt graham s scan to obtain our on - line algorithm , as sketched below . as an invariant",
    ", we have a set of points that are in the intermediate convex hull , stored in an approximate veb according to their angular coordinates .",
    "the universe is @xmath52 $ ] with a @xmath9 additive error , which can be interpreted as the perturbation error of points in their angular coordinate , without changing their values in the distance coordinates .",
    "this results in point displacements of at most @xmath47 times the diameter of the convex hull .",
    "given a new point , its successor and predecessor in the veb are found , and the operations required to check the convex hull and , if necessary , to correct it are carried on , as in graham s algorithm  @xcite .",
    "these operations may include the insertion of the new point into the veb ( if the point is on the convex hull ) and the possible deletion of other points .",
    "since each point can only be deleted once from the convex hull , the amortized number of veb operations per point is constant .",
    "our work was inspired by and improves upon data structures developed for use in dynamic random variate generation by matias , vitter , and ni  @xcite .",
    "approximation techniques such as rounding and bucketing have been widely used in algorithm design .",
    "this is the first work we know of that gives a general - purpose approximate data structure .    *",
    "finite precision arithmetic .",
    "* the sensitivity of algorithms to approximate data structures is related in spirit to the challenging problems that arise from various types of error in numeric computations .",
    "such errors has been studied , for example , in the context of computational geometry  @xcite .",
    "we discuss this further in section  [ sec : conclusions ] .",
    "* approximate sorting .",
    "* bern , karloff , raghavan , and schieber  @xcite introduced _",
    "approximate sorting _ and applied it to several geometric problems .",
    "their results include an @xmath53-time algorithm that finds a @xmath31-approximate euclidean minimum spanning tree .",
    "they also gave an @xmath54-time algorithm that finds a @xmath47-approximate convex hull for any @xmath55 1/polynomial .    in a loose sense ,",
    "approximate veb data structures generalize approximate sorting .",
    "the advantages of an approximate veb are the following .",
    "an approximate veb bounds the error for each element individually .",
    "thus , an approximate veb is applicable for problems such as the general minimum spanning tree problem , for which the answer depends on only a subset of the elements .",
    "the approximate sort of bern _ et al .",
    "_ bounds the _ net _ error , which is not sufficient for such problems .",
    "more importantly , a veb is dynamic , so is applicable to dynamic problems such as on - line convex hull and in algorithms such as dijkstra s algorithm in which the elements to be ordered are not known in advance .",
    "sorting requires precomputation , so is not applicable to such problems .",
    "* convex hull algorithms .",
    "* there are several relevant works for the on - line convex hull problem .",
    "shamos ( see , e.g. ,  @xcite ) gave an on - line algorithm for ( exact ) convex hull that takes @xmath56 amortized time per update step .",
    "preparata  @xcite gave a _",
    "real - time _ on - line ( exact ) convex hull algorithm with @xmath56-time worst - case time per update step .",
    "bentley , faust , and preparata  @xcite give an @xmath57-time algorithm that finds a @xmath47-approximate convex hull .",
    "their result was superseded by the result of bern _",
    "et  al .  _",
    "mentioned above .",
    "janardan @xcite gave an algorithm maintaining a fully dynamic @xmath58-approximate convex hull ( allowing deletion of points ) in @xmath59 time per request .",
    "our on - line approximation algorithm is based on graham s scan algorithm  @xcite and can be viewed as a combination of the algorithms by shamos and by bentley _",
    "et al . _ , with the replacement of an exact veb data structure by an approximate variant . *",
    "computation with large words .  *",
    "kirkpatrick and reich  @xcite considered exact sorting with large words , giving upper and lower bounds .",
    "their interest was theoretical , but lemma  [ equivlemma ] , which in some sense says that maintaining an approximate veb data structure is equivalent to maintaining an exact counterpart using larger words , suggests that lower bounds on computations with large words are relevant to _ approximate _ sorting and data structures .    * exploiting the power of ram .",
    "* fredman and willard have considered a number of data structures taking advantage of arithmetic and bitwise operations on words of size @xmath60 . in",
    "@xcite , they presented the _ fusion tree _ data structure . briefly , fusion trees implement the veb data type in time @xmath61 .",
    "they also presented an _",
    "atomic heap _ data structure  @xcite based on their fusion tree and used it to obtain a linear - time minimum spanning tree algorithm and an @xmath62-time single - source shortest paths algorithm .",
    "willard  @xcite also considered similar applications to related geometric and searching problems .",
    "generally , these works assume a machine model similar to ours and demonstrate remarkable theoretical consequences of the model . on the other hand , they are more complicated and involve larger constants .",
    "subsequent to our work klein and tarjan recently announced a randomized minimum spanning tree algorithm that requires only expected linear time  @xcite .",
    "arguably , our algorithm is simpler and more practical .",
    "the model of computation assumed in this paper is a modernized version of the _ random access machine _ ( ram ) .",
    "many ram models of a similar nature have been defined in the literature , dating back to the early 1960s @xcite .",
    "our ram model is a realistic variant of the logarithmic - cost ram  @xcite : the model assumes constant - time exact binary integer arithmetic ( @xmath63 , @xmath64 , @xmath65 , @xmath66 ) , bitwise operations ( @xmath67 , @xmath68 , @xmath69 , @xmath70 ) , and addressing operations on words of size  @xmath11 .",
    "put another way , the word size of the ram is  @xmath11 .",
    "we assume that numbers are of the form @xmath71 , where @xmath22 and @xmath72 are integers with @xmath73 , and that the numbers are represented with two words , the first holding @xmath22 and the second holding @xmath72 .",
    "for simplicity of exposition , we use the `` most - significant - bit '' function @xmath74 ; it can be implemented in small constant time via the previously mentioned operations and has lower circuit complexity than , e.g. , division .",
    "this section gives the details of our approximate veb data structure .",
    "first we give the relevant semantics and notations .",
    "the operations supported are : +   + @xmath75 , + @xmath76 , + @xmath77 , + @xmath78 , + @xmath79 , + @xmath80 , + @xmath81 , + @xmath82 , and + @xmath83 .",
    "+   + the @xmath84 operation and the query operations return the _ name _ @xmath85 of the element in question .",
    "the name is just a pointer into the data structure allowing constant - time access to the element .",
    "subsequent operations on the element are passed this pointer so they can access the element in constant time .",
    "@xmath84 takes an additional parameter @xmath86 , an arbitrary auxiliary data item .",
    "@xmath87 , where @xmath46 is a real number ( but not necessarily an element ) , returns the name of the largest element less than or equal to @xmath46 . for the approximate variants , the query operations are approximate in that the element returned by the query is within a @xmath88 relative factor or a @xmath9 absolute amount of the correct value .",
    "operations @xmath89 and @xmath90 , given an element s name  @xmath85 , return the element and its data item , respectively .",
    "the universe ( specified by @xmath24 ) and , for the approximate variants , the error of approximation ( @xmath91 or @xmath9 ) are specified when the data structure is instantiated .",
    "the lemma below assumes a logarithmic word - size ram .",
    "the notion of equivalence between data structures is that , given one of the data structures , the other can be simulated with constant - time overhead per operation .",
    "[ equivlemma ] the problem of representing a multiplicatively @xmath31-approximate veb on universe @xmath10 $ ] is equivalent to the problem of representing an exact veb on universe @xmath92 .",
    "the problem of representing an additively @xmath9-approximate veb on universe @xmath93 $ ] is equivalent to the problem of representing an exact veb on universe @xmath94 .",
    "assume we have a data structure for the exact data type on the specified universe . to simulate the multiplicatively approximate data structure ,",
    "the natural mapping to apply to the elements ( as discussed previously ) is @xmath95 .",
    "instead , we map  @xmath46 to approximately @xmath96 and we use a mapping that is faster to compute : let @xmath97 , let @xmath98 , and let @xmath99 .",
    "we use the mapping @xmath7 that maps @xmath46 to @xmath100 if @xmath101 , then to right - shift by @xmath102 means to left - shift by @xmath103 .",
    "note that in this case the fractional part of @xmath46 is shifted in .",
    "this mapping effectively maps @xmath46 to the lexicographically ordered pair @xmath104 , where @xmath105 represents the bits with indices @xmath106 though @xmath107 in @xmath46 .",
    "the first part of the tuple distinguishes between any two @xmath46 values that differ in their most significant bit .",
    "if two @xmath46 values have @xmath108 , then it suffices to distinguish them if they differ additively by @xmath109 .",
    "the second part of the tuple suffices for this .",
    "note that @xmath110 and @xmath111 .",
    "this shows one direction of the first part .",
    "the other direction of the first part is easily shown by essentially inverting the above mapping , so that distinct elements map to elements that differ by at least a factor of @xmath8 .",
    "finally , the second part follows by taking the mapping @xmath112 and its inverse .",
    "lemma  [ equivlemma ] reduces the approximate problems to the exact problem with smaller universe size .",
    "this section gives an appropriate solution to the exact problem .",
    "if an approximate variant is to be implemented , we assume the elements have already been mapped by the constant - time function @xmath7 in lemma [ equivlemma ] . the model of computation is a ram with @xmath11-bit words .",
    "a _ dictionary _ data structure supports update operations @xmath113 and @xmath114 and query operation @xmath115 ( returning the value , if any , associated with the key ) .",
    "it is well known how to implement a dictionary by hashing in space proportional to the number of elements in the dictionary or in an array of size proportional to the key space . in either case ,",
    "all dictionary operations require only constant time . in the former case ,",
    "the time is constant with high probability  @xcite ; in the latter case , a well - known trick is required to instantiate the dictionary in constant time .",
    "each instance of our data structure will have a doubly - linked list of element / datum pairs .",
    "the list is ordered by the ordering induced by the elements .",
    "the name of each element is a pointer to its record in this list .",
    "if the set to be stored is a multiset , as will generally be the case in simulating an approximate variant , then the elements will be replaced by buckets , which are doubly - linked lists holding the multiple occurrences of an element .",
    "each occurrence holds a pointer to its bucket . in this case",
    "the name of each element is a pointer to its record within its bucket .",
    "each instance will also have a dictionary mapping each element in the set to its name .",
    "if the set is a multiset , it will map each element to its bucket .",
    "in general , the universe , determined when the data structure is instantiated , is of the form @xmath116 .",
    "each instance records the appropriate  @xmath117 and @xmath24 values and subtracts @xmath117 from each element , so that the effective universe is @xmath118 .",
    "the ordered list and the dictionary suffice to support constant - time , , , and operations .",
    "the other operations use the list and dictionary as follows .",
    "@xmath119 finds the predecessor - to - be of @xmath22 by calling @xmath120 , inserts @xmath22 into the list after the predecessor , and updates the dictionary .",
    "if @xmath16 is a multiset , @xmath22 is inserted instead into its bucket and the dictionary is updated only if the bucket did nt previously exist .",
    "@xmath76 deletes the element from the list ( or from its bucket ) and updates the dictionary appropriately .",
    "how @xmath121 works depends on the size of the universe .",
    "the remainder of this section describes @xmath121 queries and how @xmath84 and @xmath122 maintain the additional structure needed to support @xmath121 queries .      for a universe of size @xmath11 ,",
    "the additional structure required is a single @xmath11-bit word  @xmath40 .",
    "as described in section  [ sec : description ] , the word represents a bit vector ; the @xmath22th bit is 1 iff the dictionary contains an element @xmath22 .",
    "@xmath84 sets this bit ; @xmath122 unsets it if no occurrences of @xmath22 remain in the set . setting or unsetting bits",
    "can be done with a few constant time operations .",
    "the @xmath120 operation is implemented as follows",
    ". if the list is empty or @xmath22 is less than the minimum element , return * nil*. otherwise , let @xmath123 i.e. , let @xmath72 be the index of the most significant 1-bit in @xmath40 that is at most as significant as the @xmath22th bit . return @xmath72 s name from the dictionary .",
    "* analysis .",
    "* on universes of size @xmath11 , all operations require only a few constant - time operations . if hashing is used to implement the dictionary , the total space ( number of words ) required at any time is proportional to the number of elements currently in the set .",
    "the fully recursive data structure is a straightforward modification of the original van  emde  boas data structure . for those not familiar with the original data structure , we first give an intermediate data structure that is conceptually simpler as a stepping stone .",
    "the additional data structures to support @xmath120 for a universe @xmath124 are as follows .",
    "divide the problem into @xmath125 subproblems : if the current set of elements is @xmath16 , let @xmath126 denote the set @xmath127 .",
    "inductively maintain a veb data structure for each non - empty set @xmath126 .",
    "note that the universe size for each @xmath126 is @xmath128 .",
    "each @xmath126 can be a multiset only if @xmath16 is .",
    "let @xmath129 denote the set @xmath130 .",
    "inductively maintain a veb data structure for the set @xmath129 .",
    "the datum for each element @xmath131 is the data structure for @xmath126 .",
    "note that the universe size for @xmath129 is @xmath11 .",
    "note also that @xmath129 need not support multi - elements .",
    "implement @xmath120 as follows .",
    "if @xmath22 is in the dictionary , return @xmath22 s name . otherwise , determine  @xmath131 such that @xmath22 would be in @xmath126 if @xmath22 were in @xmath16 .",
    "recursively search in @xmath129 for the largest element @xmath132 less than or equal to @xmath131 .",
    "if @xmath133 or @xmath22 is less than the minimum element of @xmath126 , return the maximum element of @xmath134 .",
    "otherwise , recursively search for the largest element less than or equal to @xmath22 in @xmath126 and return it .",
    "@xmath84 and @xmath122 maintain the additional data structures as follows .",
    "@xmath119 inserts @xmath22 recursively into the appropriate  @xmath126 .",
    "if @xmath126 was previously empty , it creates the data structure for @xmath126 and recursively inserts @xmath131 into @xmath129 .",
    "@xmath76 recursively deletes the element from the appropriate  @xmath126 .",
    "if @xmath126 becomes empty , it deletes @xmath131 from @xmath129 .    * analysis .  *",
    "because the universe of the set @xmath129 is of size @xmath11 , all operations maintaining @xmath129 take constant time .",
    "thus , each @xmath121 , @xmath84 , and @xmath122 for a set with universe of size @xmath135 requires a few constant - time operations and possibly one recursive call on a universe of size @xmath128 .",
    "thus , each such operation requires @xmath136 time .    to analyze the space requirement , note that the size of the data structure depends only on the elements in the current set .",
    "assuming hashing is used to implement the dictionaries , the space required is proportional to the number of elements in the current set plus the space that would have been required if the _",
    "distinct _ elements of the current set had simply been inserted into the data structure . the latter space would be at worst proportional to the time taken for the insertions .",
    "thus , the total space required is proportional to the number of elements plus @xmath137 times the number of distinct elements .",
    "we exponentially decrease the above time by balancing the subdivision of the problem exactly as is done in the original van  emde  boas data structure .",
    "the first modification is to balance the universe sizes of the set @xmath129 and the sets @xmath138 .",
    "assume the universe size is @xmath139 .",
    "note that @xmath140 .",
    "define @xmath141 and define @xmath142 .",
    "note that the universe size of each @xmath126 _ and _ of @xmath129 is @xmath143 .    with this modification , @xmath121 , @xmath84 , and @xmath122 are still well defined .",
    "inspection of @xmath121 shows that if @xmath121 finds @xmath131 in @xmath129 , it does so in constant time , and otherwise it does not search recursively in @xmath126 .",
    "thus , only one non - constant - time recursion is required , into a universe of size @xmath143 .",
    "thus , @xmath121 requires @xmath144 time .",
    "@xmath84 and @xmath122 , however , do not quite have this nice property . in the event that @xmath126 was previously empty",
    ", @xmath84 descends recursively into both @xmath126 and @xmath129 .",
    "similarly , when @xmath126 becomes empty , @xmath122 descends recursively into both @xmath126 and @xmath129 .",
    "the following modification to the data structure fixes this problem , just as in the original van  emde  boas data structure .",
    "note that @xmath84 only updates @xmath129 when an element is inserted into an empty @xmath126 .",
    "similarly , @xmath122 only updates @xmath129 when the last element is deleted from the set  @xmath126 .",
    "modify the data structure ( and all recursive data structures ) so that the recursive data structures exist only when @xmath145 . when @xmath146 , the single element is simply held in the list .",
    "thus , insertion into an empty set and deletion from a set of one element require only constant time .",
    "this insures that if @xmath84 or @xmath122 spends more than constant time in @xmath129 , it will require only constant time in @xmath126 .",
    "this modification requires that when @xmath16 has one element and a new element is inserted , instantiates the recursive data structures and inserts both elements appropriately .",
    "the first element inserted will bring both @xmath129 and some @xmath126 to size one ; this requires constant time . if the second element is inserted into the same set @xmath126 as the first element , @xmath129 is unchanged .",
    "otherwise , the insertion into its newly created set @xmath134 requires only constant time . in either case ,",
    "only one non - constant - time recursion is required .",
    "similarly , when @xmath16 has two elements and one of them is deleted , after the appropriate recursive deletions , destroys the recursive data structures and leaves the data structure holding just the single remaining element .",
    "if the two elements were in the same set @xmath126 , then @xmath129 was already of size one , so only the deletion from @xmath126 requires more than constant time .",
    "otherwise , each set @xmath126 and @xmath134 was already of size one , so only the deletion of the second element from @xmath129 took more than constant time .    * analysis .  * with the two modifications , each @xmath121 , @xmath84 , and @xmath122 for a universe of size @xmath147 requires at most one non - constant - time recursive call , on a set with universe size @xmath143 .",
    "thus , the time required for each operation is @xmath148 . as for the intermediate data structure ,",
    "the total space is at worst proportional to the number of elements , plus the time per operation ( now @xmath149 ) times the number of distinct elements .",
    "the approximate data structures described in this paper are simple and efficient .",
    "no large constants are hidden in the asymptotic notations  in fact , a `` back of the envelope '' calculation indicates significant speed - up in comparison to the standard van  emde  boas data structure .",
    "the degree of speed - up in practice will depend upon the machines on which they are implemented .",
    "machines on which binary arithmetic and bitwise operations on words are nearly as fast as , say , comparison between two words will obtain the most speed - up .",
    "practically , our results encourage the development of machines which support fast binary arithmetic and bitwise operations on large words .",
    "theoretically , our results suggest the need for a model of computation that more accurately measures the cost of operations that are considered to require constant time in traditional models .",
    "the applicability of approximate data structures to specific algorithms depends on the robustness of such algorithms to inaccurate intermediate computations . in this sense",
    ", the use of approximate data structures has an effect similar to computational errors that arise from the use of finite precision arithmetic . in recent years",
    "there has been an increasing interest in studying the effect of such errors on algorithms .",
    "of particular interest were algorithms in computational geometry .",
    "frameworks such as the `` epsilon geometry '' of guibas , salesin and stolfi  @xcite may be therefore relevant in our context .",
    "the `` robust algorithms '' described by fortune and milenkovic  @xcite are natural candidates for approximate data structures .",
    "expanding the range of applications of approximate data structures is a fruitful area for further research .",
    "other possible candidates include algorithms in computational geometry that use the well - known sweeping technique , provided that they are appropriately robust . for instance , in the sweeping algorithm for the line arrangement problem with approximate arithmetic , presented by fortune and milenkovic  @xcite , the priority queue can be replaced by an approximate priority queue with minor adjustments , to obtain an output with similar accuracy .",
    "if the sweeping algorithm of chew and fortune  @xcite can be shown to be appropriately robust then the use of the van  emde  boas priority queue there can be replaced by an approximate variant ; an improved running time may imply better performance for algorithms described in  @xcite .",
    "m. dietzfelbinger and f. meyer auf der heide . a new universal class of hash functions and dynamic hashing in real time , in _ proc .",
    "of 17th international colloquium on automata languages and programming _ , springer lncs 443 : 619 , 1990 .",
    "m.  l. fredman and d.  e. willard .",
    "trans - dichotomous algorithms for minimum spanning trees and shortest paths . in _ proc . of the 31st ieee annual symp . on foundation of computer science _ , pages 719725 , 1990",
    "l. i. guibas , d. salesin , and j. stolfi .",
    "epsilon geometry : building robust algorithms from imprecise computations . in _ proc . of the 5th annual symposium on computational geometry _ ,",
    "pages 208217 , 1989 .",
    "r. janardan . on maintaining the width and diameter of a planar point - set online .",
    "in _ proc .",
    "2nd international symposium on algorithms _ , volume 557 of _ lecture notes in computer science _ , pages 137149 .",
    "springer - verlag , 1991 . to appear in international journal of computational geometry & applications .",
    "v. milenkovic .",
    "double precision geometry : a general technique for calculating line and segment intersections using rounded arithmetic . in _ proc . of the 30th ieee annual symp . on foundation of computer science _ , 1989"
  ],
  "abstract_text": [
    "<S> in this paper we introduce the notion of _ approximate data structures _ , in which a small amount of error is tolerated in the output . </S>",
    "<S> approximate data structures trade error of approximation for faster operation , leading to theoretical and practical speedups for a wide variety of algorithms . </S>",
    "<S> we give approximate variants of the van  emde  boas data structure , which support the same dynamic operations as the standard van  emde  boas data structure  @xcite , except that answers to queries are approximate . </S>",
    "<S> the variants support all operations in constant time provided the error of approximation is @xmath0 , and in @xmath1 time provided the error is @xmath2 , for @xmath3 elements in the data structure .    </S>",
    "<S> we consider the tolerance of prototypical algorithms to approximate data structures . </S>",
    "<S> we study in particular prim s minimum spanning tree algorithm , dijkstra s single - source shortest paths algorithm , and an on - line variant of graham s convex hull algorithm . </S>",
    "<S> to obtain output which approximates the desired output with the error of approximation tending to zero , prim s algorithm requires only linear time , dijkstra s algorithm requires @xmath4 time , and the on - line variant of graham s algorithm requires constant amortized time per operation . </S>"
  ]
}