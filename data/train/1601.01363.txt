{
  "article_text": [
    "main purpose of this paper is to show that the gaussian regularized shannon sampling formula to reconstruct a bandlimited function can achieve by far the best convergence rate among all regularization methods for the shannon sampling series in the literature . as a result , we improve l. qian s error estimate @xcite for this highly successful method in engineering .",
    "we first introduce the _ paley - wiener space _ @xmath4 with the bandwidth @xmath5 defined as @xmath6\\},\\ ] ] where @xmath7:=\\prod_{k=1}^d[-\\delta_k,\\delta_k]$ ] . in this paper ,",
    "the fourier transform of @xmath8 takes the form @xmath9 where @xmath10 denotes the standard inner product of @xmath11 and @xmath12 in @xmath13 . the classical _ shannon sampling theorem _",
    "@xcite states that each @xmath14 can be completely reconstructed from its infinite sampling data @xmath15 .",
    "specifically , it holds @xmath16 where @xmath17 .",
    "many generalizations of shannon s sampling theorem have been established ( see , for example , @xcite and the references therein ) .    in practice , we can only sum over finite sample data `` near '' @xmath11 in ( [ shannonseries ] ) to approximate @xmath18 . truncating the series ( [ shannonseries ] ) results in a convergence rate of the order @xmath19 due to the slow decayness of the sinc function , @xcite .",
    "besides , this truncated series was proved to be the optimal reconstruction method in the worst case scenario in @xmath20",
    ". dramatic improvement of the convergence rate can be achieved when @xmath21 , @xmath1 . in this case",
    ", @xmath15 turns out to be a set of oversampling data , where oversampling means to sample at a rate strictly larger than the nyquist rate @xmath22 .",
    "three explicit methods @xcite have been proposed in order to reconstruct a univariate bandlimited function @xmath23 ( @xmath1 ) from its finite oversampling data @xmath24 with an exponentially decaying approximation error .",
    "they work by multiplying the sinc function with a rapidly - decaying regularization function .",
    "jagerman @xcite used a power of the sinc functions as the regularizer and obtained the convergence rate of @xmath25 micchelli _ et al .",
    "_ @xcite chose a spline function as the regularizer and attained the convergence rate @xmath26 which is by far the best convergence rate among all regularization methods for the shannon sampling series in reconstructing a bandlimited function .",
    "however , the spline regularization function in @xcite is implicit and involves the solving of a linear system .",
    "a third method using a gaussian function as the regularizer was first proposed by wei @xcite . precisely , the _",
    "gaussian regularized shannon sampling series _ in @xcite is defined as @xmath27 a convergence analysis of the method was presented by qian @xcite .",
    "taking a small computational mistake in ( 2.33 ) in @xcite into consideration and optimizing about the variance @xmath28 of the gaussian function as done in @xcite , qian actually established the following convergence rate for ( [ grsseries ] ) @xmath29    due to its simplicity and high accuracy ( [ qianrate ] ) , the gaussian regularized shannon sampling series ( [ grsseries ] ) has been widely applied to scientific and engineering computations . in fact , more than a hundred such papers have appeared ( see http://www.math.msu.edu/~wei/pub-sec.html for the list , and @xcite for comments and discussion ) .",
    "we note that although the exponential term in ( [ qianrate ] ) is as good as that in ( [ bestrate ] ) for the spline function regularization @xcite , the first term @xmath30 is much worse than @xmath31 in ( [ bestrate ] ) .",
    "the first purpose of this paper is to show that the convergence rate of the gaussian regularized shannon sampling series can be improved to ( [ bestrate ] ) .",
    "thus , this method enjoys both simplicity and the best convergence rate by far .",
    "this will be done in section ii , where we also improve the convergence rates of the gaussian regularized shannon sampling series for derivatives and multivariate bandlimited functions . in section iii , we show that the gaussian regularization method can also improve the convergence rate for the useful average sampling . in the last section",
    ", we demonstrate our results via several numerical experiments .",
    "in this section , we improve the convergence rate analysis for the gaussian regularized shannon sampling series .",
    "specifically , we shall show that it can achieve by far the best rate ( [ bestrate ] ) for univariate bandlimited functions and its derivatives , and for multivariate bandlimited functions .",
    "we separate the three cases into different subsections .",
    "let @xmath23 with @xmath32 throughout this subsection .",
    "we shall use the gaussian regularized shannon sampling series ( [ grsseries ] ) to reconstruct the values of @xmath33 at @xmath34 from the finite localized oversampling data @xmath24 .",
    "we shall need a few technical facts in order to improve the convergence rate established in @xcite .",
    "they were also frequently used in the estimates in @xcite .",
    "firstly , it is well - known that @xmath35 , @xmath36 form an orthonormal basis for @xmath20 . as @xmath37",
    ", we have by the parseval identity @xmath38 the second result needed is the following upper bound estimate of mills ratio @xcite of standard normal law : @xmath39 we shall also need a variant of its discrete version : @xmath40}e^{-\\frac{(t - j)^2}{r^2}}<\\frac{r^2}{n-1}e^{-\\frac{(n-1)^2}{r^2 } } , r>0 , n\\ge2 , t\\in(0,1).\\ ] ] the next two are a useful computation of the fourier transform @xmath41 and an associated estimate @xmath42.\\ ] ] the last one is the upper bound estimate @xmath43    we are in a position to present an improved convergence rate analysis for the gaussian regularized shannon sampling series .",
    "we follow the methods in @xcite and emphasize that the improvement is achieved by applying the cauchy - schwartz inequality to obtain a better estimate for ( 2.5 ) in @xcite .",
    "[ theorem1 ] let @xmath44 , @xmath45 , and choose @xmath46 .",
    "the gaussian regularized shannon sampling series ( [ grsseries ] ) satisfies @xmath47    let @xmath23 with @xmath48 .",
    "set @xmath49 , @xmath34 , where @xmath50 } f(j)\\sinc(t - j ) e^{-\\frac{(t - j)^2}{2r^2}}. } \\end{array}\\ ] ] bound @xmath51 by its fourier transform as follows @xmath52 computing and bounding @xmath53 by ( [ lemma3 ] ) , ( [ lemma4 ] ) and similar arguments as those in @xcite , we have @xmath54.\\ ] ] thus , @xmath55 } |f(j)|\\left|\\frac{\\sin\\pi(t - j)}{\\pi(t - j)}\\right| e^{-\\frac{(t - j)^2}{2r^2}}}\\\\ & \\displaystyle{\\le \\frac{1}{\\pi n}\\sum_{j\\notin(-n , n ] } |f(j)| e^{-\\frac{(t - j)^2}{2r^2 } } , \\",
    "t\\in(0,1 ) . } \\end{array}\\ ] ] apply the cauchy - schwartz inequality , we get by ( [ parseval ] ) and ( [ lemma2 ] ) @xmath56 } |f(j)|^2\\big)^{\\frac12}\\big(\\sum_{j\\notin(-n , n]}e^{-\\frac{(t - j)^2}{r^2 } } \\big)^{\\frac12}}\\\\ & \\displaystyle{\\le \\frac{re^{-\\frac{(n-1)^2}{2r^2}}}{\\pi n\\sqrt{n-1 } } , \\ t\\in(0,1 ) . }",
    "\\end{array}\\ ] ] combining ( [ e11 ] ) with ( [ e12 ] ) and optimally choosing @xmath57 completes the proof .",
    "we remark that the estimate ( [ mainrate ] ) is of the same order as the best convergence rate ( [ bestrate ] ) by far in the literature .",
    "a second remark is on the degenerated case when @xmath58 . in this case , the estimate in @xcite or the above ( [ mainrate ] ) is apparently meaningless . to make up for the drawback ,",
    "a more delicate upper bound estimate is needed for @xmath59 .",
    "specifically , we have @xmath60\\setminus[-\\pi+n^{-\\frac{3}{4}},\\pi - n^{-\\frac{3}{4 } } ] } |\\hat{e}_1(\\xi)|d\\xi\\big)}\\\\ & \\displaystyle{\\quad + \\frac{1}{\\sqrt{2\\pi}}\\int_{-\\pi+n^{-\\frac{3}{4}}}^{\\pi - n^{-\\frac{3}{4 } } } |\\hat{e}_1(\\xi)|d\\xi}\\\\ & \\displaystyle{\\le \\frac{1}{\\sqrt{\\pi}}\\frac{1}{n^{\\frac38}}+   \\sqrt{\\frac{2}{\\pi } } \\frac{n^{\\frac34}}{r}. } \\end{array}\\ ] ] taking @xmath61 above and using ( [ e12 ] ) , we obtain the convergence rate @xmath62 for @xmath63 .      by the paley - wiener theorem , each function in @xmath64 is infinitely differentiable . in this subsection , we are concerned with the reconstruction of the derivatives of @xmath21 by the gaussian regularized shannon sampling series ( [ grsseries ] ) .",
    "the convergence rate obtained in @xcite is also of the order ( [ qianrate ] ) .",
    "we shall improve the estimate .",
    "[ theorem2 ] let @xmath65 , @xmath66 , and @xmath67 .",
    "it holds @xmath68    we may suppose that @xmath23 with @xmath48 .",
    "set @xmath69 , @xmath34 , where @xmath70}f(j)\\big(\\sinc(t - j)e^{-\\frac{(t - j)^2}{2r^2}}\\big)^{(s)}. } \\end{array}\\ ] ] it has been estimated in @xcite that @xmath71 for each @xmath34 , we calculate @xmath72}f(j)}\\\\ & \\displaystyle{\\quad\\cdot\\left[\\sum_{k=0}^s \\frac{s!}{k!(s - k ) ! } \\big(\\frac{\\sin ( \\pi t - j\\pi)}{\\pi(t - j)}\\big)^{(s - k)}\\big(e^{-\\frac{(t - j)^2}{2r^2}}\\big)^{(k ) } \\right]}\\\\ & \\displaystyle{=\\frac{1}{\\sqrt{2\\pi}}\\sum_{j\\notin(-n , n]}f(j)\\left[\\sum_{k=0}^s \\frac{s!}{k!}\\right.}\\\\ & \\displaystyle{\\quad\\cdot \\biggl(\\sum_{l=0}^{s - k}\\frac{\\pi^{s - k - l-1}\\sin\\big(\\pi(t - j+\\frac{(s - k - l)}{2})\\big)}{l!(s - k - l)!}\\cdot\\frac{(-1)^l l!}{(t - j)^{l+1}}\\biggr)}\\\\ & \\displaystyle{\\quad\\cdot\\left.\\frac{(-1)^k h_k(\\frac{t - j}{\\sqrt{2}r})}{(\\sqrt{2}r)^k}\\right ] e^{-\\frac{(t - j)^2}{2r^2}}.}\\\\ \\end{array}\\ ] ] noticing the simple fact @xmath73,\\ t\\in(0,1),\\ l\\in\\bz_+,\\ ] ] we obtain by ( [ lemma5 ] ) @xmath74}|f(j)| } \\\\ & \\displaystyle{\\quad\\cdot\\left[\\sum_{k=0}^s\\frac{1}{k!}\\big(\\sum_{l=0}^{s - k}\\frac{\\pi^{s - k - l}}{(s - k - l)!}\\frac{1}{|t - j|^{l+1}}\\big)\\frac{|t - j|^k}{r^{2k}}\\right ] e^{-\\frac{(t - j)^2}{2r^2}}}\\\\ & \\displaystyle{\\le\\frac{s!}{n\\pi\\sqrt{2\\pi}}\\sum_{|j|\\ge n}|f(j+1)|}\\\\ & \\displaystyle{\\quad\\cdot\\left[\\sum_{k=0}^s\\frac{|j|^k}{k!r^{2k}}\\cdot\\big(\\sum_{l=0}^{s - k}\\frac{\\pi^{s - k - l}}{(s - k - l)!}\\big)\\right]e^{-\\frac{j^2}{2r^2}}}. \\end{array}\\ ] ] since @xmath75 for all @xmath76 and @xmath77 , we have @xmath78 note that @xmath79 and @xmath80 implies @xmath81 .",
    "we thus get by ( [ parseval ] ) , ( [ lemma2 ] ) and the cauchy - schwartz inequality @xmath82 substituting @xmath80 into ( [ be1 ] ) and ( [ be2 ] ) , we have @xmath83 in the last inequality , we use @xmath84 and @xmath85 .",
    "the proof is complete .      in this subsection , we show that the best convergence rate ( [ bestrate ] ) can also be achieved in the reconstruction of a multivariate bandlimited function by the gaussian regularized shannon sampling series .",
    "techniques to be used for this case is quite different from those in the univariate case and also much differs from those in @xcite .",
    "let @xmath86 and @xmath87^d\\}$ ] in this subsection .",
    "the gaussian regularized shannon sampling series @xcite to reconstruct a multivariate function @xmath88 from its finite sample data @xmath89 is defined as @xmath90 where @xmath91 and @xmath92 denotes the standard euclidean norm of @xmath93 in @xmath13 .",
    "two lemmas are needed to present an improved convergence analysis for ( [ multilocalsampling ] ) .",
    "[ lemma6 ] let @xmath94 and @xmath95 .",
    "it holds for all @xmath96 @xmath97    observe that @xmath98\\}.\\ ] ] by ( [ subset ] ) , we have for each @xmath96 @xmath99 } \\sinc^2(t_k - j_k)e^{-\\frac{(t_k - j_k)^2}{r^2}}\\big ) } \\\\ & \\displaystyle{\\quad\\cdot\\prod_{l\\ne k}\\big(\\sum_{j_l\\in\\bz}\\sinc^2(t_l - j_l)e^{-\\frac{(t_l - j_l)^2}{r^2}}\\big ) . }",
    "\\end{array}\\ ] ] note that @xmath100 , @xmath101 .",
    "thus , we have @xmath102 } \\sinc^2(t_k - j_k)e^{-\\frac{(t_k - j_k)^2}{r^2}}\\big).}\\\\ \\end{array}\\ ] ] applying ( [ lemma2 ] ) to the last inequality gives the desired result .",
    "introduce the important constant @xmath103    [ lemma8 ] let @xmath104 .",
    "it holds for @xmath105 $ ] @xmath106    by ( [ lemma1 ] ) , we have for @xmath105 $ ] @xmath107 we then apply the elementary fact that for constants @xmath108 , @xmath109 with @xmath110 , it holds @xmath111 as a consequence , @xmath112 the proof is completed by noting that @xmath113 is decreasing on @xmath114 .    with the above preparation , we have the following main theorem .    [ theorem3 ]",
    "let @xmath115 , @xmath95 , and @xmath116 .",
    "the multivariate gaussian regularized shannon sampling series ( [ multilocalsampling ] ) satisfies @xmath117    let @xmath118 with @xmath119 .",
    "set @xmath120 , @xmath96 , where @xmath121 by lemma [ lemma8 ] and similar arguments as those in @xcite for the univariate case , we have @xmath122 . }",
    "\\end{array}\\ ] ] bounding @xmath123 by its fourier transform and then applying the cauchy - schwartz inequality , we get @xmath124 } |\\hat{\\ce}(\\xi)|d\\xi}\\\\ & \\displaystyle{\\le \\frac{d}{\\pi}\\frac{e^{-\\frac{(\\pi-\\delta)^2r^2}{2}}}{(\\pi-\\delta)r}\\int_{[-\\delta,\\delta]}|\\hat{f}(\\xi)|d\\xi}\\\\ & \\displaystyle{\\le \\frac{d(2\\delta)^{\\frac{d}{2}}}{\\pi}\\frac{e^{-\\frac{(\\pi-\\delta)^2r^2}{2}}}{(\\pi-\\delta)r}. } \\end{array}\\ ] ] recall that @xmath125 by this , lemma [ lemma6 ] , and the cauchy - schwartz inequality , we obtain @xmath126 the proof is completed by taking @xmath127 in ( [ e231 ] ) and ( [ e232 ] ) .",
    "in this section , we will apply the method of gaussian regularization to the useful average sampling .",
    "a main purpose is again to improve the convergence rate .",
    "we first introduce some basic facts about the average sampling .    sampling a function @xmath33 at @xmath36",
    "can be viewed as applying the delta distribution to the function @xmath128 .",
    "the delta distribution is used theoretically but hard to implement physically .",
    "hence , a practical way is to approximate the delta distribution by an averaging function with small support around the origin . for this sake",
    ", we consider the following average sampling strategy : @xmath129 where @xmath130 and @xmath131 is a symmetric positive borel probability measure on @xmath132 $ ] . it was observed in @xcite that @xmath133 thus , @xmath134 is in fact induced by a frame in @xmath64 . by the standard frame theory , we are able to completely reconstruct @xmath33 from the infinite sample data @xmath134 through a dual frame . for studies along this direction ,",
    "see , for example , @xcite .",
    "motivated by the shannon sampling theorem , we desire a dual frame that is generated by the shifts of a single function . in other words ,",
    "we prefer a complete reconstruction formula of the following form @xmath135 where @xmath136 is to be chosen .",
    "it has been proved in @xcite that if @xmath137 with @xmath138 $ ] then ( [ reconstruction2 ] ) holds if and only if @xmath139,\\ ] ] where @xmath140.\\ ] ] under the above assumptions on @xmath131 , @xmath141 is an even function on @xmath7 $ ] and satisfies @xmath142 . }",
    "\\end{array}\\ ] ]    in practice , we only have the finite sample data @xmath143 , @xmath144 . a natural reconstruction method is by @xmath145 the main purpose of this section is to illustrate by an explicit example that compared to the above direct truncation , regularization by a gaussian function as follows @xmath146 } \\tilde{f}(j)\\phi(t - j)e^{-\\frac{(t - j)^2}{2r^2 } } , t\\in(0,1 ) , f\\in\\cb_\\delta(\\br)\\ ] ] may lead to a better convergence rate .",
    "the function @xmath136 satisfying ( [ exactreconst ] ) in our example is specified as @xmath147,\\\\ \\left[\\frac{|\\xi|-(2\\pi-\\delta)}{2\\pi-2\\delta}\\right]^2 p(\\xi ) , & \\delta\\le|\\xi|\\le 2\\pi-\\delta,\\\\ 0,&\\mbox{elsewhere } , \\end{array } \\right.\\ ] ] where @xmath148.\\ ] ] then @xmath149 $ ] , @xmath150 and @xmath151 is absolutely continuous on @xmath152 . by ( [ wrange ] )",
    ", we have @xmath153 finally , we shall use an elementary fact from the fourier analysis @xcite that @xmath154 let @xmath32 , @xmath95 , @xmath155 , @xmath156 and @xmath157 be given as ( [ phi ] ) .",
    "then the convergence rate of ( [ averagesampling ] ) is @xmath158 where @xmath159    let @xmath23 with @xmath48 .",
    "set @xmath160 , @xmath34 , where @xmath161}\\tilde{f}(j)\\phi(t - j)e^{-\\frac{(t - j)^2}{2r^2}}. } \\end{array}\\ ] ]    _ estimate of @xmath162 .",
    "_ by ( [ reconstruction2 ] ) , we have @xmath163}(\\xi)$ ] , @xmath164 .",
    "then , for @xmath164 , @xmath165}(\\xi)}{\\hat{\\phi}(\\xi)}\\big[\\hat{\\phi}(\\xi)-\\frac{1}{\\sqrt{2\\pi}}\\int_\\br \\hat{\\phi}(\\xi-\\eta)r e^{-\\frac{r^2\\eta^2}{2}}d\\eta\\big].}\\\\ \\end{array}\\ ] ] if @xmath166 then @xmath167 . if @xmath168 then by ( [ lemma2 ] ) , ( [ wrange ] ) and ( [ phi ] ) , we have @xmath169}\\\\ & \\displaystyle{\\le \\frac{|\\hat{f}(\\xi)|}{\\sqrt{2\\pi}}\\left [ \\big|\\int_{|\\eta|<\\varepsilon } \\big(\\hat{\\phi}'(\\xi)\\eta+\\frac{\\hat{\\phi}''(\\xi-\\theta \\eta)}{2}\\eta^2\\big)r e^{-\\frac{r^2\\eta^2}{2}}d\\eta\\big|\\right.}\\\\ & \\displaystyle{\\quad\\left.+\\int_{|\\eta|\\ge\\varepsilon } \\big|\\hat{\\phi}(\\xi)-\\hat{\\phi}(\\xi-\\eta)\\big| re^{-\\frac{r^2\\eta^2}{2}}d\\eta\\right]}\\\\ & \\displaystyle{\\le \\frac{|\\hat{f}(\\xi)|}{\\sqrt{2\\pi}}\\left [ \\frac{\\|\\hat{\\phi}''\\|_{l^\\infty(\\bi_\\delta)}}{2}\\cdot\\int_{|\\eta|<\\varepsilon } \\eta^2r e^{-\\frac{r^2\\eta^2}{2}}d\\eta\\right.}\\\\ & \\displaystyle{\\quad\\left .",
    "+ 2\\|\\hat{\\phi}\\|_{l^\\infty(\\bi_\\delta ) } \\cdot\\int_{|\\eta|\\ge\\varepsilon } r e^{-\\frac{r^2\\eta^2}{2}}d\\eta\\right]}\\\\ & \\displaystyle{\\le \\frac{|\\hat{f}(\\xi)|}{\\sqrt{2\\pi}}\\left [ \\frac{\\|\\hat{\\phi}''\\|_{l^\\infty(\\bi_\\delta)}}{2r^2}\\cdot\\int_{|x|<r\\varepsilon}x^2e^{-\\frac{x^2}{2}}dx\\right.}\\\\ & \\displaystyle{\\quad\\left.+4\\sqrt{2}\\|\\hat{\\phi}\\|_{l^\\infty(\\bi_\\delta)}\\cdot\\int_{\\frac{r\\varepsilon}{\\sqrt{2}}}^{+\\infty } e^{-x^2}dx \\right]},\\\\ \\end{array}\\ ] ] where @xmath170 and @xmath171 .",
    "combining the last inequality above with @xmath172 and ( [ lemma1 ] ) yields @xmath173 bounding @xmath162 by the @xmath174-norm of its fourier transform , we get by the above equation @xmath175    _ estimate of @xmath176 . _ by ( [ fourier ] ) and by the cauchy - schwartz inequality , for each @xmath34 , @xmath177 } |\\tilde{f}(j)||\\phi(t - j)| e^{-\\frac{(t - j)^2}{2r^2}}}\\\\ & \\displaystyle{\\le\\frac{\\|\\hat{\\phi}''\\|_{l^1(\\bi_\\delta)}}{\\sqrt{2\\pi}n^2}\\sum_{j\\notin(-n , n ] }",
    "|\\tilde{f}(j)| e^{-\\frac{(t - j)^2}{2r^2}}}\\\\ & \\displaystyle{\\le \\frac{\\|\\hat{\\phi}''\\|_{l^1(\\bi_\\delta)}}{\\sqrt{2\\pi}n^2}\\big(\\sum_{j\\notin(-n , n]}|\\tilde{f}(j)|^2\\big)^{\\frac12}\\big(\\sum_{j\\notin(-n , n]}e^{-\\frac{(t - j)^2}{r^2 } } \\big)^{\\frac12 } } .",
    "\\end{array}\\ ] ] it follows from ( [ lemma2 ] ) and ( [ framebound ] ) that latexmath:[\\[\\label{e22 }    taking @xmath156 in ( [ e21 ] ) and ( [ e22 ] ) , we obtain @xmath179 which , by ( [ phinorm ] ) , completes the proof .",
    "we see that if @xmath150 and @xmath151 is absolutely continuous on @xmath152 then the convergence rate of the direcr truncation ( [ truncation ] ) is @xmath180 .",
    "therefore , the gaussian regularized version ( [ averagesampling ] ) indeed results in a better convergence rate .",
    "we present in this section numerical experiments to illustrate the effectiveness of the gaussian regularized sampling formula and to demonstrate the validness of our convergence analysis for the formula .",
    "let @xmath1 .",
    "the bandlimited function under investigation has the form @xmath181 we point out that @xmath182 and @xmath183 .",
    "we shall reconstruct the values of @xmath33 on @xmath184 from @xmath24 by the the truncated gaussian regularized shannon sampling series @xmath185 the error of reconstruction is measured by @xmath186 this error is to be compared with the theoretical estimate in theorem [ theorem1 ] : @xmath187 we also compute the reconstruction error resulting from directly truncating the shannon series @xmath188 for comparison , where @xmath189 the above three errors for @xmath190 and @xmath191 are listed in tables [ tab1 ] , [ tab2 ] , and [ tab3 ] , respectively .",
    "we also plot @xmath192 and @xmath193 in fig .",
    "we see that the gaussian regularized shannon sampling formula converges extremely fast and our theoretical estimate for the convergence rate in theorem [ theorem1 ] is pretty sharp .",
    ".reconstruction erros for @xmath194 .",
    "[ cols=\"^,^,^,^\",options=\"header \" , ]      and @xmath195 for @xmath196 ( top ) , @xmath197 ( middle ) , @xmath198 ( bottom).,title=\"fig:\",width=403 ] +",
    "we present refined convergence analysis for the gaussian regularized shannon sampling formula in reconstructing bandlimited functions .",
    "the formula is simple , highly efficient , and has received considerable attention in engineering applications .",
    "we show in the paper that the formula can achieve by far the best convergence rate among all regularization methods for the shannon sampling series .",
    "extensive numerical experiments show that our theoretical estimates of the convergence rates are valid and sharp .",
    "30 l.  qian , `` on the regularized whittaker - kotelnikov - shannnon sampling formula , '' _ proc .",
    "4 , pp . 11691176 , oct . 2003 . c.  e.  shannon , `` communication in the presence of noise , '' _ proc . ire _ ,",
    "1021 , jan . 1949 .",
    "e.  t.  whittaker , `` on the functions which are represented by the expansion of the interpolation theory , '' _ proc .",
    "edinburgh sect .",
    "a _ , vol .",
    "181194 , 1915 .",
    "a.  aldroubi , `` non - uniform weighted average sampling and reconstruction in shift - invariant and wavelet spaces , '' _ appl .",
    "2 , 151161 , sept . 2002 .",
    "k.  grchenig , `` reconstruction algorithms in irregular sampling , '' _ math .",
    "181194 , jul",
    "a.  j.  jerri , `` the shannon sampling theorem  its various extensions and applications : a tutorial review , '' _ proc .",
    "ieee _ , vol .",
    "11 , pp . 15651596 ,",
    "d.  k.  hoffman , n.  nayar , o.  a.  sharafeddin and d.  j.  kouri , `` analytic banded approximation for the discretized free propagator , '' _ j. phys .",
    "chem - us _ , vol .",
    "95 , pp . 82998305 , mar .",
    "l.  qian , `` the regularized whittaker - kotelnikov - shannon sampling theorem and its application to the numerical solutions of partial differential equations , '' ph.d .",
    "dissertion , dept .",
    ", singap . , 2004 . w.  sun and x.  zhou , `` reconstruction of band - limited signals from local averages , '' _ ieee trans .",
    "inform . theory _",
    "29552963 , nov .",
    "w.  sun and x.  zhou , `` reconstruction of bandlimited functions from local averages , '' _ constr .",
    "2 , pp . 205222 , apr . 2002 .",
    "m.  unser , `` sampling50 years after shannon , '' _ proc .",
    "ieee _ , vol .",
    "4 , pp . 569587 , apr .",
    "h.  zhang , y.  xu and j.  zhang , `` reproducing kernel banach spaces for machine learning , '' _ j. mach .",
    "27412775 , dec .",
    "h.  d.  helms and j.  b.  thomas , `` truncation error of sampling - theorem expansions , '' _ proc .",
    "50 , pp . 179184 , 1962 .",
    "d.  jagerman , `` bounds for truncation error of the sampling expansion , '' _ siam j. appl . math . _ , vol .",
    "4 , pp . 714723 , jul . 1966 . k.  l.  jordan , `` discrete representation of random signals , '' technical report 378 , mit , cambridge , 1961 . b.  s.  tsybakov and v.  p.  iakovlev , `` on the accuracy of restoring a function with a finite number of terms of kotelnikov series , '' _ radio eng . electron .",
    "274275 , 1959 .",
    "c.  a.  micchelli , y.  xu and h.  zhang , `` optimal learning of bandlimited functions from localized sampling , '' _ j. complexity _ , vol .",
    "2 , pp . 85114 , apr .",
    "g.  w.  wei , `` quasi wavelets and quasi interpolating wavelets , '' _ chem .",
    "215222 , nov .",
    "g.  w.  wei , `` discrete singular convolution method for the sine - gordon equation , '' _ physica d _",
    "137 , pp . 247259 , mar",
    "g.  w.  wei , `` solving quantum eigenvalue problems by discrete singular convolution , '' _ j. phys .",
    "b _ , vol .",
    "343359 , 2000 .",
    "g.  w.  wei , d.  s.  zhang , d.  j.  kouri and d.  k.  hoffman , `` lagrange distributed approximating functionals , '' _ phys .",
    "79 , pp . 775779 ,",
    "g.  w.  wei and s.  zhao , `` on the validity of `` a proof that the discrete singular convolution ( dsc)/langrange - distributed approximation function ( ldaf ) method is inferior to high order finite differences '' , ''",
    "_ j. comput .",
    "226 , pp . 23892392 , 2007 . s.  zhao and g.  w.  wei , `` comparison of the discrete singular convolution and three other numerical schemes for solving fisher s equation , ''",
    "_ siam j. sci .",
    "_ , vol . 25 , no",
    ". 1 , pp . 127147 , 2003 .",
    "h.  d.  pollak ,  a remark on  elementary inequalities for mills ratio \" by ysaku komatu ,  _ rep .",
    "res . , un . jap .",
    "_ , vol . 4 , p. 110",
    "h.  zhang , `` exponential approximation of bandlimited functions from average oversampling , '' preprint , arxiv:1311.4294 .",
    "a.  aldroubi , q.  sun and w.  s.  tang , `` @xmath199-frames and shift invariant subspaces of @xmath200 , ''",
    "_ j. fourier anal .",
    "_ , vol . 7 , no",
    ". 1 , pp . 121 , 2001 .",
    "a.  aldroubi , q.  sun and w.  s.  tang , `` convolution , average sampling , and a calderon resolution of the identity for shift - invariant spaces , '' _ j. fourier anal .",
    "2 , pp . 215244 , 2005 .",
    "c.  gasquet and p.  witomski , `` _ fourier analysis and applications _ , '' texts in applied mathematics 30 , new york : springer - verlag , 1999 , pp . 155161 .",
    "r. lin received the b.s .",
    "degree in mathematics and applied mathematics from zhangzhou normal university , zhangzhou , p.r .",
    "china , in 2012 .",
    "he is currently pursuing the ph.d .",
    "degree in computational mathematics at sun yat - sen university , guangzhou , p.r .",
    "china , through a five - year ph.d . program .",
    "h. zhang received the b.s .",
    "degree in mathematics and applied mathematics from beijing normal university , beijing , p.r .",
    "china , in 2003 , the m.s .",
    "degree in computational mathematics from the chinese academy of sciences , beijing , p. r. china in 2006 , and the ph.d .",
    "degree in mathematics from syracuse university , ny , in 2009 .    from june 2009 to may 2010",
    ", he was a postdoctoral research fellow at university of michigan , ann arbor . since june 2010",
    ", he has been a professor with the school of mathematics and computational science , sun yat - sen university , guangzhou , p. r. china ."
  ],
  "abstract_text": [
    "<S> we consider the reconstruction of a bandlimited function from its finite localized sample data . truncating the classical shannon sampling series results in an unsatisfactory convergence rate due to the slow decayness of the sinc function . to overcome this drawback , </S>",
    "<S> a simple and highly effective method , called the gaussian regularization of the shannon series , was proposed in engineering and has received remarkable attention . </S>",
    "<S> it works by multiplying the sinc function in the shannon series with a regularization gaussian function . </S>",
    "<S> l. qian ( proc . </S>",
    "<S> amer . </S>",
    "<S> math . </S>",
    "<S> soc . , 2003 ) established the convergence rate of @xmath0 for this method , where @xmath1 is the bandwidth and @xmath2 is the number of sample data . c. micchelli _ et al . _ </S>",
    "<S> ( j. complexity , 2009 ) proposed a different regularization method and obtained the corresponding convergence rate of @xmath3 . </S>",
    "<S> this latter rate is by far the best among all regularization methods for the shannon series . </S>",
    "<S> however , their regularized function involves the solving of a linear system and is implicit and more complicated . </S>",
    "<S> the main objective of this note is to show that the gaussian regularized shannon series can also achieve the same best convergence rate as that by c. micchelli _ </S>",
    "<S> et al_. we also show that the gaussian regularization method can improve the convergence rate for the useful average sampling . </S>",
    "<S> numerical experiments are presented to justify the obtained results .    </S>",
    "<S> bandlimited functions , gaussian regularization , oversampling , shannon s sampling theorem , average sampling . </S>"
  ]
}