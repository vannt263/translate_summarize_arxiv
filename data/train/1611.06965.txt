{
  "article_text": [
    "the amount of data available in astronomy grows continuously in size and complexity .",
    "this creates the need to develop more effective visualizations techniques to analyze and present the data .",
    "+ typically , astronomers work analyzing datacubes , which are simply multidimensional arrays of values , such as the physical fields of hydrodynamic simulations or integral field spectroscopy data .",
    "it is easy to display the complete information of 1d arrays or 2d matrices using lineplots and colormaps .",
    "however , a problem appears for 3d datacubes , when only a single projection or a sequence of layers are displayed to visualize the dataset .",
    "this procedure comes with a reduction of the dimensionality of the data , and can cause to miss part of the information in the visual analysis .",
    "+ 3d visualization and volume rendering are now alternatives for astronomers to display 3-dimensional data @xcite .",
    "current softwares and libraries allow the user to do it in real time with different levels of interactivity .",
    "viewers like frelled ] @xcite allow to load fits datacubes and manipulate them interactively through rotations , scaling , and mask selection .",
    "alternatives like virtual reality immersions go one step forward , and let the user get inside the data to observe its features @xcite . using these novel techniques not only allow to produce an attractive outreach material , but also provide an additional perspective of the complete dataset while doing scientific analysis along with the traditional methods@xcite .",
    "+ in this work we provide a procedure to generate a volume rendering from astronomical data ( from numerical simulations , in particular ) in the 3d graphics software blender ] , that can be used to perform a qualitative visual analysis , and to create presentation material .",
    "blender is free and open source , and in the recent years has shown potential as an astronomy visualization tool .",
    "@xcite presents a series of tutorialsbkent / blender/ ] ] showing the software features and possible applications like : loading as halo points a galaxy catalog or a particle simulation , use the mesh modeling tools to recreate an asteroid , and also a demonstration of volume rendering using an image sequence .",
    "the library astroblend ] , developed by @xcite , provides further tools to import and display different types of astronomical data in the interactive 3d environment of blender , such as 3d contours and also particle simulations using halos with a colorscale . +",
    "a datacube can be imported into blender through the voxel data format , which is the file used to generate volumetric renderings . by importing a simulation , for example",
    ", the software can display in a 3d space one of the physical properties of interest ( density , temperature , etc ) using a colorscale , and show its evolution in time . using the blender functions it is possible",
    "adjust the colorscale interactively to highlight different features , incorporate a fly - around camera animation to zoom in through the relevant regions of the datacube , and finally produce an animation to use as outreach material .",
    "+ the use of volume rendering provides a smooth and continuous display of the whole dataset , in contrast with visualizations using particles or contours .",
    "since blender colorscale also provides control over the transparency , it is also possible to explore the different depths of the volume without reloading additional data .",
    "+ this article is meant to serve as a guideline for the user to convert its own data into the voxel data format , learn the steps to set up a blender scene , and render an image or a movie .",
    "section [ sec_voxel ] explains the format of the voxel data files that can be used as an input to blender .",
    "section [ sec_convert ] provides simple algorithms to convert some common simulation data formats into voxel data . in section [ sec_setup ] it",
    "is described the setup process in blender from the initial scene , through loading the voxel data , and finally the rendering process .",
    "section [ sec_examples ] displays examples using gadget2@xcite and fargo3d@xcite simulations rendered in blender . + to complement this article , the reader can watch the tutorial series : `` blender & astronomy tutorial . using voxel data for 3d visualization '' ] , which covers the whole process described above with real time demonstrations in blender . through the article these videos",
    "will be referred as tut:#. all the material used for this work is available in the github repository : `` blender bvoxer '' ] , which includes the blender scenes , scripts to generate voxel data files , and simulation data provided by j. cuadra and s. perez to test this visualization techniche . through the article these codes will be referred as git : foldername .",
    "this section will explain the key concepts related to the voxel data , which is the link between the astrophysical data , and the 3d visualization in the blender scene .",
    "the voxel data is a binary datacube file that will serve as input for the visualization . although the voxel data can be generated from a sequence of images ( as we will discuss later in this section ) , we prefer ( and recommend ) to use a single binary file to store the information .",
    "this approach allows to represent the datacube as a single array ( which is convenient when performing operations over the data ) , it easier and faster to write a single binary file than multiple images , and finally , it allows to store all the information in a compact format , rather than in a directory . to complement this section",
    "the reader can refer to the tutorial series tut:1 and github repository git : example , where there are demonstrations for generating a simple voxel data file from a function @xmath0 .",
    "+ to visualize 3-dimensional data it is necessary to define a finite volume within the blender scene , this is done by creating a cube object that will be the domain for the visualization . once the voxel data file is assigned to this domain , the 3d information stored in the file will be rendered in the blender scene within the boundaries of the cube .",
    "further technical details of the setup , such as the material and texture settings , will be addressed later in section [ sec_setup ] .",
    "+ the voxel file represents a datacube subdivided in the three cartesian axes @xmath1 . for each discrete cartesian coordinate @xmath2 inside the volume",
    "there is one voxel value @xmath3 .",
    "additionally , it is possible to include multiple snapshots ( frames ) in the same file .",
    "this allows to show the evolution of the datacube in time .",
    "therefore , the voxel data is defined by :    * the resolution numbers @xmath4 , that indicate the number of subdivisions of the domain in each axis .",
    "* the frame number @xmath5 , that indicates the total number of frames contained in the file .",
    "* @xmath6 values , which describe the astrophysical data that will be visualized inside the domain .    by the time of writing",
    "this article , blender can receive the voxel data as an input in three different file formats : blender voxel , 8bit raw and image sequence .",
    "the following subsections will describe each format , and point their advantages(+ ) and disadvantages( ) .",
    "+ the guidelines and notation provided in this article to write both blender voxel and 8bit raw file formats are based on the description and examples available at pythology blogspot ] . also , @xcite ( section 4.1 ) provides a brief description about how to use the image sequence format and a complete example on his websitebkent / blender / tutorials.html ] ] .",
    "the blender voxel format consists in a binary file that has @xmath7 integers in the header , corresponding to @xmath8 , followed by the @xmath9 floating point values that represent the actual data . for this format",
    "the values must be normalized to a [ 0,1 ] interval .",
    "the order to write the full datacube after the header is :    1 .",
    "frame by frame , where each frame has @xmath10 layers . 2 .",
    "layer by layer , where each layer has @xmath11 lines .",
    "line by line , where each line has @xmath12 values .",
    "4 .   value by value , until completing the @xmath12 values .",
    "the following example pseudo - code illustrates the order in which the file is written :    .... write([nx , ny , nz , nf ] ) for t from 0 to nf :        for k from 0 to nz :             for j from 0 to ny :            for i from 0 to nx :             write(data[i , j , k , t ] ) ....    * ( + ) allows high dynamic range for the data values by using 32bit floats . * ( + ) includes a header .",
    "it only requires to input the file into blender . *",
    "( + ) allows multiple frames . *",
    "(  ) high memory usage because of using 32bit float",
    ".    we want to remark that the high memory usage may be specially troublesome when multiple frames are stored in the voxel data file , since it is not possible create arbitrarily large files . for large number of frames",
    "it may be more convenient to store each frame in a separate voxel file , and then use the python api of blender to switch between frames .",
    "this will be discussed again in section [ sec_setup_tips ] .",
    "this format is a binary file of @xmath13 integer values .",
    "the values for this format should normalized to a [ 0,255 ] interval .",
    "the order to write the file is the same as the used for the blender voxel format , the only difference is the absence of the header and the size of the values . for this format",
    "the @xmath4 values must be written as an input in the blender interface .",
    "the value of @xmath5 is calculated internally by blender based on the file size and the previous three values .    * (  ) low dynamic range for the data values . * (  ) does not include a header .",
    "it is necessary to input the resolution manually in blender . *",
    "( + ) allows multiple frames . *",
    "( + ) memory efficient because of using 8bit integers .",
    "the image sequence format allows to construct a datacube using multiple images as layers .",
    "the format consists in a directory that contains @xmath10 image files ( png , for example ) of @xmath14 pixels .",
    "if the user already has the tools to save his data as a set of images , this would be the most straightforward method to construct the voxel data .",
    "+ the total number of images must be specified in the interface along with the image # 1 .",
    "the ( @xmath12 , @xmath11 ) values are obtained from the files . those files must be numerated to guarantee that the datacube will be build in the correct order .",
    "for example , if there are 100 images a valid numeration would be : name001.png , ... , name100.png .    *",
    "( + ) convenient if the images can be easily generated in order to build the datacube .",
    "this would save extra coding . *",
    "( + ) does not need a header .",
    "blender computes the resolution automatically from the number of images and their dimensions . * (  ) only support a single frame . *",
    "(  ) requires multiple files .",
    "the memory usage of this method will depend on the image number of channels and their dynamic range .",
    "however , notice that blender will interpret all images as monochromatic , so using anything but a grayscale is unnecessary .",
    "the dynamic range of the grayscale will determine the level of detail .",
    "for example , an 8bit image will provide greater detail than a 1bit image at the cost of memory usage . we have tested this method with 1bit , 8bit grayscale images , and also with 24bit ( rgb ) and 32bit ( rgba ) images .",
    "further information can be found in @xcite .",
    "as mentioned in the previous section , the blender voxel and 8bit raw inputs take the form of datacubes . by the time of writing",
    "this article , blender can only subdivide the visualization domain in the cartesian axes ( x , y , z ) .",
    "therefore , the algorithm to construct the voxel file needs to fill each grid cell of this datacube from the simulation data .",
    "+ for a simulation that uses an evenly spaced cartesian grid , writing the voxel data is quite straightforward , as the only thing required to do is to match @xmath4 with the resolution of the simulation , and scale the data values to the appropriate range before writing the file in the blender voxel or 8bit raw format .",
    "however , if the simulation is done using a cylindrical or spherical grid , a logarithmic scale , or if it is a particle simulation ( like n - body or sph ) , it is necessary to transform the space of the original data into a cartesian datacube .",
    "+ in this section we propose methods to generate a cartesian datacube from a grid simulation in spherical coordinates , and also from a particle simulation . as it is impossible to address all the possible data formats and methods",
    "we expect that these two should serve as good examples that the user can adjust to his / her own needs .",
    "+ the tutorial video tut:3 ( and the second half of tut:4 ) also explain these methods by going through the example scripts , however these videos are aimed to people with little or none programming skills .",
    "an experienced programmer will find more convenient to read the following subsections and look the referenced codes straight away .",
    "converting an spherical grid into a cartesian datacube requires to fill each voxel @xmath2 ( where @xmath15 $ ] , @xmath16 $ ] , @xmath17 $ ] ) using the spherical coordinates @xmath18 , which are the radial , azimuthal and co - latitude directions in the simulation , and the physical properties @xmath19 of each grid cell , such as density , energy , temperature , etc .",
    "notice that the spherical coordinates should indicate the middle of the grid cell , and not the borders .",
    "+ we propose the following algorithm to perform the transformation :    1 .",
    "first transform the @xmath18 coordinates into their cartesian equivalent @xmath1 .",
    "2 .   define the cartesian boundaries of the datacube using the minimum and maximum @xmath1 values from the previous step .",
    "3 .   define a resolution @xmath4 for the voxel datacube .",
    "4 .   for each voxel position @xmath2 obtain its cartesian equivalent ( @xmath20 ) , using the following transformation @xmath21 .",
    "repeat this for @xmath22 and @xmath23 .",
    "5 .   check if the values @xmath24 are within the spherical boundaries of the simulation .",
    "if they do , proceed to the next step .",
    "if they do not , assign the voxel @xmath25 .",
    "this is expected to happen since a spherical grid can not fill completely the borders of a cartesian grid , or the regions inside the inner radial boundary of the simulation .",
    "6 .   the value of each voxel @xmath3 in the datacube with position @xmath24 will be defined by the @xmath26 closest grid cells of the simulation and their physical properties @xmath27 , with @xmath28 the @xmath29 closest cell neighbor .",
    "we present two alternatives for determining @xmath3 .",
    "1 .   for @xmath30 use the closest neighbor as the only contribution to the voxel value .",
    "then , @xmath31 .",
    "2 .   for @xmath32",
    "it is possible to use a trilinear interpolation if the 8 positions @xmath1 of the neighbors form a box that contains the @xmath24 coordinate of the voxel .",
    "then , @xmath33 where @xmath34 is the weight for the trilinear interpolation of the grid cell @xmath28 .",
    "( this is the method used in the example shown in figure [ examplea ] ) .",
    "after having all the voxel values , rescale them to be in the interval @xmath35 $ ] or @xmath36 $ ] , depending if the voxel format is blender voxel or 8bit raw , respectively .",
    "notice that in the step 5 a value of 0.0 was assigned to the voxels outside the simulation boundaries , so it may be necessary to force them again back to 0.0 for the visualization if the property @xmath19 allowed negative values .",
    "an implementation of this algorithm is available in the github repository git : fargo3dvoxelizer , where fargo3d outputs are converted from an spherical grid to blender voxel format .",
    "both alternatives for steps 6.1 and 6.2 are available in the repository .",
    "while the former is enough for the visualization , it may cause discontinuities in the sampling . on the other hand ,",
    "the latter solves this problem and samples the cartesian datacube smoothly .",
    "the process to generate a datacube from a particle simulation can be divided in two steps : first , to define a cartesian grid and find the position of the particles on it , and second , to use the particles in each grid cell to compute its voxel value @xmath3 . + for a simulation with @xmath26 particles , we have their position , velocities and physical properties @xmath19 .",
    "the latter can be masses and sizes for n - body simulations , or density , thermal energy and other fluid properties for hydrodynamic simulations like sph @xcite . +",
    "we propose the following algorithm to convert an array of particles into an evenly spaced datacube :    1 .   define the boundaries of the simulation using the minimum and maximum values of the particles positions in each axis @xmath1 .",
    "2 .   define a resolution @xmath4 that is convenient for the particle count and available memory .",
    "3 .   transform the @xmath37 positions of the particles from the range [ @xmath38 , @xmath39 to the range [ @xmath40 using the linear transformation @xmath41 .",
    "repeat for the y and z coordinates .",
    "4 .   identify if a particle @xmath42 is inside ( or should influence ) a certain grid cell @xmath2 , and its contribution to the voxel value @xmath3 . for this step , we propose the following alternatives : 1 .   simple average estimation . truncate the transformed positions to their integer forms .",
    "a particle @xmath42 is inside a certain grid cell if the coordinates @xmath43 match the @xmath2 indexes of the cell in the datacube .",
    "the value of each voxel will be given by @xmath44 where @xmath45 are the @xmath46 particles inside a grid cell @xmath47 , and @xmath48 is the physical property chosen for visualization of the @xmath45 particle .",
    "( this is the method used in the example shown in figure [ exampleb ] ) .",
    "2 .   sph interpolation . using the interpolation method implemented in splashdprice / splash/ ] ] ( @xcite , section 4.1 and 4.2 ) , the value of each voxel is given by : @xmath49 where @xmath50 is the sph kernel function , r is the distance between the particle @xmath45 and the center of the grid cell @xmath2 , @xmath51 and @xmath52 are the mass and density of the particle , and @xmath53 is the maximum between the smoothing length of the particle and the half width of the grid cell .",
    "3 .   other possible methods could include using the n - nearest particles to influence a grid cell , and use a customized weight functions instead the sph kernel , such as power laws of the distance .",
    "the value of the voxel can be computed in an analogous way as in the previous methods .",
    "+ these procedures can be optimized by iterating over the particles , and adding their contribution to the voxels that are within their range of influence , rather iterating over all the voxels and looking for the contribution of all the n particles @xcite .",
    "5 .   the last step is to rescale the whole voxel datacube to have values in the interval @xmath35 $ ] or @xmath36 $ ] , depending if the voxel format is blender voxel or 8bit raw , respectively .",
    "an implementation of this algorithm is available in the github repository git : sph .",
    "the example code reads a particle list , and generates a blender voxel file using the density field of the particles .",
    "the approach of step 4.1 is used for simplicity , but the interpolation recipe described by @xcite should be implemented for a more accurate result , specially if the size of the grid cells is smaller than the relevant smoothing lengths of the simulation .",
    "in order to produce a volume rendering , the light needs to pass through the defined volume , be absorbed , scattered , and transmitted by interacting with the voxels according to their properties ( density , emission , etc ) , until it reaches the camera .",
    "the concept is similar to the radiative transfer process in astrophysics , although interactions are computed in the color space , rather than in wavelenght . +",
    "this section will cover the overall steps required to load a voxel data file into blender , set up the material , render an image , and also create a fly - around camera animation .",
    "this procedure is also demonstrated in our tutorial series tut:2 in real time .",
    "@xcite also covered the setup of a blender scene , going through the steps of a standard workflow .",
    "+ before starting , it is advised to take a look at the basic blender commands , just to be able to navigate quickly through the interface .",
    "some pages that cover the basics are : blender 3d design course - lesson 1 ] by neal hirsig , and also the blender basics course ] from cg cookie . to learn about any specific feature of the software",
    "the reader can refer to the online manual ] .",
    "+ after opening blender , the default scene will be displayed as shown in figure [ set1 ] .          here",
    "are listed the steps to set the 3d material , starting from the default scene .",
    "the default * cube * object will act as domain for the voxel data as mentioned in section [ sec_voxel ] . for the complete procedure we will use the default internal engine * blender render * , which allows to use customized voxel files as input .    1 .",
    "right - clicking on the default * cube * gives access to the object properties , including the * material * and * texture * properties .",
    "select the * material * property , set the type to * volume * and * density = 0.0 * ( see figure [ set2 ] ( a ) ) .",
    "the integration of the light rays through the volume can be customized in the * integration * panel through the * step size * and the * depth cutoff * , both parameters can be adjusted to improve the accuracy at the cost of rendering time .",
    "more details about the other volume rendering settings can be found in its respective section in the manual ] .",
    "2 .   select the * texture * property and set the type to * voxel data * ( see figure [ set2 ] ( b ) ) . in the * voxel data * panel select the file format to one of the discussed in the section [ sec_voxel ] ( see figure [ set2 ] ( c ) ) .",
    "if the datacube used contains only a single frame ( @xmath54 ) , then check the * still frame only * , and set the * still frame number = 1 * to display the frame . for @xmath55",
    "leave * still frame only * unchecked . in this case",
    "the * current frame * value of the blender * timeline * will determine which frame of the datacube should be displayed .",
    "3 .   in the * influence *",
    "panel check the * density * , * emission * and * emission color * fields , and set them all to * 1.0 * ( see figure [ set2 ] ( c ) ) .",
    "the * influence * panel determines which parameters of the volume will be defined from the * voxel data * input .",
    "the * density * field defines the opacity of the volume , the * emission * defines its brightness , and * emission color * allows to use a colorscale that can be customized in the * color * panel , instead of a grayscale .",
    "4 .   in the * color *",
    "panel check the * ramp * option ( see figure [ set2 ] ( d ) ) .",
    "the ramp is a function that receives the values of the * voxel data * file as a position between * 0.0 * and * 1.0 * , and returns the color specified at that position ( notice that it is also possible to control the transparency with the @xmath56 channel , allowing see through or completely hide a range of values ) .",
    "selecting the sliders allows to control their position in the ramp , and the color output . for the interpolation we suggest to start using the * rgb * color mode , and select the * linear * method for the transition between consecutive sliders",
    "the reader is encouraged to experiment with the other non - linear interpolation methods available in order to find the colorscale that best suits the data .",
    "finally , adjusting the * brightness * and * contrast * helps to highlight the features of the volume and to expose its internal structure .",
    "this last part is mostly a process of trial and error , and may depend on the resolution of the * voxel data * file .",
    "the following steps consist in the scene adjustments , positioning of the camera , correct the cube scaling , and other tweaks to improve the quality of the visualization .    1 .",
    "start by deleting the default * lamp * object , since the datacube will illuminate by itself .",
    "it is recommended to scale up the * cube * object in order to resolve better the volume ( see figure [ set3 ] ( a ) ) .",
    "it is advised to use a scale consistent with the geometry of the simulation , for example , the scale of a disk simulation in the z axis should be smaller than the scale of the x and y axes . 3 .   in the * world",
    "* properties it is convenient to set the * horizon * color to black in order to increase the contrast between the voxel data and the background ( see figure [ set3 ] ( b ) ) .",
    "4 .   to have a preliminary visualization of the voxel data switch the * viewport shading * to * rendered*.",
    "the viewport should look like figure [ set3 ] ( c ) .",
    "this mode can be used to explore the data interactively , and to adjust the color , brightness and contrast in the * texture * property in real time .",
    "5 .   to render a quick image , orient the * camera * looking toward the cube object , and",
    "position it at a distance such that the volume is contained inside the * camera * field of view .",
    "there are many ways to do this and can be learned from every basic tutorial , but for now it is advised to use the command * align camera to view*. then , select the resolution of the image in the * render * properties and press * render * ( see figure [ set3 ] ( d ) ) .",
    "if the datacube contains multiple frames to generate an animation ( @xmath55 ) , select the * start frame * and * end frame * to go from 1 to @xmath5 , remember to leave unchecked the * still frame only * option in the * texture * properties . then , go to the * output * panel in the * render * properties , choose a destination and format for the movie file , and press the * animation * button .",
    "different setup tools can help to produce more appealing results . here , we listed some of them , but since illustrating each step would greatly extend the length of this section , these will only be explained briefly",
    ". these are standard methods in blender that can be found in many video tutorials , including tutorials tut:2 and tut:4 .",
    "* camera fly - around : the * camera * can be constrained to move in time through a customized path , and kept pointing toward the object of interest .",
    "this allows to focus on the different regions of the simulation as it evolves in time , or simply go around all the details of a single frame of the datacube .",
    "+ the overall procedure is : * * create a * bezier curve * or * bezier circle * , and go to * edit mode * in order to customize the animation path . * * in the * curve * properties check the * path animation * and set the number of frames needed to go through the whole path . * * to animate the * evaluation time * set it to 0.0 at the starting frame , right click of the value slider and select * insert keyframe*. repeat this last step at the final frame with a different value for the * evaluation time*. this will cause the * evaluation time * to change between the selected values during the animation . *",
    "* reset all the position and rotation values of the * camera * object to 0.0 .",
    "* * then , in the * constraints * properties add the * follow path * constraint .",
    "set the * bezier curve * as the * target * object , the y axis to point forward , the z axis to point upwards .",
    "* * add the * track to * constraint , and set the * cube * as the target object , the -z axis to point towards the * cube * , and the y axis to point upwards .",
    "* * by pressing * play * you should see the camera following the specified path . * * an optional method is to create an * empty object * , and use it as the focus of the * camera * in the * track to * constraint .",
    "animating the position of this object allows to move the camera focus point through the animation . * adding halo - points : as the data is related to astronomical subjects , it may be appealing to include a nice background if the audience is non - scientific .",
    "the * halo points * are ideal to simulate stars in the background of the scene . *",
    "* add any * mesh * object and switch from * object mode * to * edit mode*. * * select all the vertices and use the * merge at center * command to collapse them into a single vertex .",
    "* * in the * material * property , switch the type to * halo*. use * size * and * hardness * values to control the appearance of the halo . * * to add multiple halo points at once , create an object like a * sphere * , and in * edit mode * use the command * delete edges and faces*. repeat the material setup to produce as many halo points as vertices had the object .",
    "* compositor post - processing : the previous sections showed how to set up a * color ramp * for the datacube .",
    "however , while the * brightness * and * contrast * values help to highlight the features of the data , these do not always produce a colorscale that favors the image as a whole . by switching from the * 3d view * to the * node editor * it is possible to post - process the rendered image for more appealing results .",
    "one useful node is the * color balance * , which corrects the image * shadows * , * midtones * and * highlights * through the * lift * , * gamma * and * gain * colors respectively . * switch voxel data files with python",
    ": it is also possible to automatize some of the tasks done in the interface using the * blender api * for python scripting . as was noted in section [ sec_voxel ] ,",
    "storing a whole simulation in a single * voxel data * file can be inconvenient for long ( or even moderate ) simulations . in this case",
    ", it is easier to have one voxel file for each snapshot and perform the switch every frame through a script .",
    "+ in the python script import the _ bpy _ library ( blender internal library ) , and iterate over the frame count .",
    "then , in each frame assign the corresponding voxel file to the texture , render the image , and save it .",
    "the individual images can be joined in a single video with the blender * movie editor * , or with an external program . an example script for",
    "this process is available in the github repository git : voxelanimation .",
    "the image was post - processed to brighten the colors , and the halo points were added to emulate surrounding stars.,width=321 ]    .",
    "the image was post - processed to brighten the colors , and also the blend sky option of the world properties was used to add the background colors.,width=321 ]    the voxel data visualization described in this work was tested for gadget2 and fargo3d simulation outputs .",
    "the gadget2 code uses the lagrangian formalism with the smoothed particle hydrodynamics ( sph ) method , while fargo3d uses the eulerian formalism and support cartesian , cylindrical , and spherical grids .",
    "+ the image shown in figure [ examplea ] was rendered using fargo3d outputs provided by s. perez .",
    "the figure shows a protoplanetary disk with a giant planet embedded , and the between the planet and the gas . the planet gravity opens a gap along its orbit and excites the spiral wakes that propagate through the disk .",
    "central and surrounding stars were included for aesthetic reasons . the available video animation ]",
    "shows the gap opening process and the circumplanetary disk that surrounds the planet . + the image shown in figure [ exampleb ] was rendered using gadget2 outputs provided by j. cuadra .",
    "the figure shows the stellar winds emitted by a wolf - rayet star as it moves through the galactic center , and how the ejected material form clumps by cooling in the interstellar medium .",
    "the available turn - around animation ] also shows that the clumps are distributed in a parabolic shell , rather than through all the space ( as could be misinterpreted by using a projection view ) .",
    "+ in both examples ( images and videos ) we illustrated different animation techniques that help to highlight the particular features of each simulation , such as the circumplanetary region or the clump distribution .",
    "we also encourage the reader to explore more features of the software , in order to find the most effective way to present its own work , and guide its audience through the data visualization .",
    "we have discussed how to use the volumetric rendering features of the software blender to display the results of astrophysical simulations . we have described the voxel data formats , which are binary files ( or image sequences ) used to import a datacube into the blender interface , and discussed the advantages and disadvantages of each one in terms of flexibility and memory usage . in this context , we have proposed algorithms to convert simulation outputs ( either grid or particle based ) into a voxel datacube , and provided examples using stellar winds gadget2 simulations , and protoplanetary disks fargo3d simulations . + in the blender interface",
    "we showed the process of setting up a scene , loading the voxel data file , and adjusting the colorscale to render an image .",
    "we have also presented some basic tools , such as color balance corrections and camera - fly around animation , that may help to create appealing outreach material .",
    "+ the whole process is available in our mentioned youtube tutorial series `` blender & astronomy tutorial .",
    "using voxel data for 3d visualization '' .",
    "we want to mention that though this article was focused on representing numerical simulations , the overall procedure is the same if the information can be stored in a datacube .",
    "+ the use of volume rendering and 3d visualization offers a whole new range of possibilities to perform complementary data analysis and to display our results for the public .",
    "softwares like blender present many useful tools to accomplish this task .",
    "furthermore , along with the evolution of computer graphics more alternatives will be available , allowing us to create more detailed and effective visualizations .",
    "we would like to thank jorge cuadra and sebastin perez for providing their simulation data to test this visualization procedure , and pablo bentez - llambay for his collaboration in the development of the fargo3d to voxel data converter .",
    "we thank s. perez , p. bentez - llambay , and d. caldern for their comments in the early version of this paper , and also to the anonymous referee for the comments and suggestions to improve this article .",
    "the author acknowledges financial support from the millennium nucleus rc130007 ( chilean ministry of economy ) and the associated pme project : `` mad community cluster '' , from fondecyt grant 1141175 , and basal ( pfb0609 ) grant .",
    "the geryon clusters housed at the centro de astro - ingenieria uc were used for the sph calculations of this paper .",
    "the basal pfb-06 cata , anillo act-86 , fondequip aic-57 , and quimal 130008 provided funding for several improvements to the geryon clusters .",
    "the fargo3d simulations used in this work were performed in the belka cluster , financed by fondequip project eqm140101 and housed at mad / cerro calan .",
    "barnes , d. g. , fluke , c. j. , 2008 , new astronomy , 13 , 599 bentez - llambay , p. , masset , f.s . , 2016 , apjs , 223 , 11 cuadra , j. , nayakshin , s. , martins , f. , 2008 , mnras , 383 , 458 ferrand , g. , english , j. , irani , p. , 2016",
    ", arxiv:1607.08874 goodman , a. a. , 2012 , astronomische nachrichten , 333 , 505 kent , b. r. , 2013 , pasp , 125 , 731 monaghan , j. j. , 1992 , ara&a , 30 , 543 naiman , j. p. , 2016 , astronomy and computing , 15 , 50 price , d. j. , 2007 , pasa , 24 , 159 springel , v. , 2005 , mnras , 364 , 1105 taylor , r. , 2015 , astronomy and computing , 13 , 67    this is an author - created , un - copyedited version of an article accepted for publication in publications of the astronomical society of the pacific .",
    "iop publishing ltd is not responsible for any errors or omissions in this version of the manuscript or any version derived from it ."
  ],
  "abstract_text": [
    "<S> the growth of computational astrophysics and complexity of multidimensional datasets evidences the need for new versatile visualization tools for both analysis and presentation of the data . in this work </S>",
    "<S> we show how to use the open source software blender as a 3d visualization tool to study and visualize numerical simulation results , focusing on astrophysical hydrodynamic experiments . with a datacube as input , the software can generate a volume rendering of the 3d data , show the evolution of a simulation in time , and do a fly - around camera animation to highlight the points of interest . </S>",
    "<S> we explain the process to import simulation outputs into blender using the voxel data format , and how to set up a visualization scene in the software interface . </S>",
    "<S> this method allows scientists to perform a complementary visual analysis of their data , and display their results in an appealing way , both for outreach and science presentations . </S>",
    "<S> + * keywords * : methods : miscellaneous  methods : numerical </S>"
  ]
}