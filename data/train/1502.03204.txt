{
  "article_text": [
    "the multiple access channel ( mac ) is one of the most well - studied problems in network information theory @xcite .",
    "the capacity region of the discrete memoryless mac was independently derived by ahlswede @xcite and liao @xcite in the early 1970s . in this paper , we are interested in the gaussian version of this problem for which the channel output @xmath1 corresponding to the inputs @xmath2 is @xmath3 where @xmath4 is standard gaussian noise . we assume an average transmission power constraint of @xmath5 corresponding to each transmitter @xmath6 .",
    "the capacity region was derived by cover @xcite and wyner  @xcite and is the set of all rate tuples @xmath7 that satisfy @xmath8 for all subsets @xmath9 . for the @xmath10 case , the pentagonal region of rate tuples in is known as the _ cover - wyner _ region and",
    "is illustrated in figure  [ fig : cap_reg ] .    despite our seemingly complete understanding of fundamental limits of the gaussian mac ,",
    "it is worth highlighting that in the above - mentioned seminal works @xcite , it is assumed that the average error probability tends to zero as the length of the code grows without bound .",
    "this implies that those established converses are , in fact , _",
    "weak converses_. fano s inequality  ( * ? ? ?",
    "2.1 ) is typically used as a key tool to establish such weak converses . in this work ,",
    "we strengthen the results of cover @xcite and wyner  @xcite and show that any rate tuple that can be supported by a sequence ( in the blocklength ) of gaussian multiple access codes with asymptotic average error probability _ strictly less than one _ ( and not necessarily tending to zero ) must lie in the cover - wyner region .",
    "this is a _",
    "strong converse _ statement , akin to the work on strong converses for point - to - point channels by wolfowitz  @xcite .",
    "it indicates that the boundary of the cover - wyner region designates a sharp phase transition of the smallest achievable asymptotic error probability , which is zero for any rate tuple inside the capacity region and one for any rate tuple outside the capacity region .",
    "thus , this work augments our understanding of the first - order fundamental limit of the gaussian mac .",
    "additionally , it may also serve as a stepping stone for studying the second - order asymptotics  @xcite or upper bounds ( e.g. , the sphere - packing bound ) on the reliability function of the gaussian mac ( cf .",
    "* th .  4 ) ) .",
    "( 115 , 135 ) ( 10,60)(4,0)18(1,0)2 ( 60,10)(0,4)18(0,1)2 ( 0 , 10)(1 , 0)110 ( 10 , 0)(0,1)110 ( 110,8 ) @xmath11 ( -6 , 105 ) @xmath12 ( 53 , 0)@xmath13 ( 80 , 0)@xmath14 ( -5,55)@xmath15 ( -1,79)@xmath16 ( 35,35)@xmath17 ( 3,3)@xmath18 ( 10 , 80)(1 , 0)50 ( 80 , 10)(0,1)50 ( 60 , 80)(1 , -1)20      the study of macs has a long history and we refer the reader to the excellent exposition in el gamal and kim ( * ? ? ? * ch .",
    "4 ) for a thorough discussion .",
    "dueck @xcite proved the strong converse for the ( two - source ) discrete memoryless mac using the the technique of blowing up decoding sets originally due to ahlswede , gcs and krner @xcite , combined with a novel strategy known as the _ wringing technique_. the technique of blowing up decoding sets uses the so - called _ blowing - up lemma _",
    "@xcite ( see also ( * ? ? ?",
    "5 ) or ( * ? ? ?",
    "* sec .  3.6 ) ) . this technique is useful for establishing strong converse results for memoryless channels with finite output alphabets .",
    "dueck s proof proceeds in three steps .",
    "first , dueck expurgates an appropriate subset of codeword pairs to convert any given sequence of codes with asymptotic _ average _ error probability bounded away from one to a sequence of codes with asymptotic _",
    "maximal _ error probability bounded away from one .",
    "this expurgation step is performed so that the blowing - up lemma to be applied in the third step yields tight upper bounds on the sum - rate , which will then lead to the desired strong converse result",
    ". unfortunately , the expurgation step introduces undesirable correlations among the codewords transmitted by the  @xmath0 encoders .",
    "second , a wringing technique is introduced to wring out any residual dependence among the symbols transmitted by the @xmath0 encoders by choosing a further subcode from each subcode obtained in the expurgation step .",
    "wringing is necessary for establishing a tight sum - rate bound , because the sum - rate capacity of the mac is expressed as the supremum of mutual information terms over all independent input distributions ( the independence is due to the fact that the @xmath0 encoders do not cooperate ) .",
    "third , the blowing - up lemma is applied to the resultant subcode to yield a tight upper bound on the sum - rate .",
    "ahlswede @xcite presented another strong converse proof for the ( two - source ) discrete memoryless mac by modifying dueck s wringing technique as well as replacing the use of the blowing - up lemma in dueck s proof with an application of augustin s non - asymptotic converse bound  @xcite .",
    "however , the proofs of dueck and ahlswede are specific to the discrete ( finite alphabet ) setting and it is not clear by examining the proofs that the same strong converse statement follows in a straightforward way for the gaussian mac with peak power constraints .",
    "another approach to proving the strong converse for a general mac is due to han @xcite , who used the information spectrum technique  @xcite to provide a general formula for macs and stated a condition ( * ? ?",
    "6 ) for the strong converse to hold .",
    "however , unlike for the point - to - point setting  ( * ? ? ?",
    "3.63.7 ) , the property is difficult to verify for various classes of memoryless macs .",
    "in view of the above works and the practical and theoretical importance of strong converse theorems , we are motivated to provide a self - contained proof for the strong converse of the gaussian mac .      in this subsection",
    ", we discuss the challenges of leveraging existing techniques to prove the strong converse for the gaussian mac .",
    "in particular , we highlight the difficulties in directly using the ideas contained in dueck s @xcite and ahlswede s  @xcite proofs .",
    "we also describe , at a high level , the strategy we employ to overcome these difficulties .",
    "finally , we discuss some other auxiliary proof techniques .      in dueck",
    "s paper  @xcite , he used a version of the _ blowing - up lemma _ , together with other tools , to prove the strong converse theorem for the discrete memoryless mac . a crucial step in dueck s proof",
    "involves the establishing of an upper bound on the list size of possible messages for every output sequence based on the blown - up decoding sets .",
    "if the resultant list size is too large ( e.g. , contains an exponential number of messages ) , the dueck s technique can not lead to the strong converse theorem .",
    "since this crucial step heavily relies on the finiteness of the output alphabet and the output alphabet of the gaussian mac is uncountably infinite , it is not immediately apparent how to extend this step to the gaussian case .",
    "as mentioned in the previous section , ahlswede s proof @xcite is based on a modification of dueck s wringing technique and augustin s non - asymptotic converse bound  @xcite .",
    "however , it is not apparent how to adapt his techniques to obtain a strong converse bound on the sum - rate .",
    "more specifically , ahlswede s wringing technique ( see equation ( 5.3 ) in @xcite ) leads to the following sum - rate bound for any sequence of length-@xmath19 codes whose asymptotic average error probability is bounded away from one : @xmath20 in , @xmath21 and @xmath22 are _ independent _ random variables .",
    "however , the bound in is sensitive to the sizes of the input and output alphabets , which prevents us from directly extending ahlswede s proof to the gaussian case .",
    "furthermore , there are no cost constraints in the discrete memoryless mac and incorporating cost constraints does not seem to be trivial .",
    "a nave strategy to extend ahlswede s proof to the gaussian case is to quantize the input and output alphabets of the gaussian mac so that @xmath23 , @xmath24 and @xmath25 depend on @xmath19 and their cardinalities grow with  @xmath19 .",
    "say we denote the quantized alphabets as @xmath26 , @xmath27 and @xmath28 .",
    "this sequence of quantized alphabets and the corresponding channels will be designed to provide increasingly refined approximations to the gaussian mac as @xmath19 increases . in designing @xmath26 , @xmath27 and @xmath28",
    ", we would also like to ensure that the power constraints are satisfied and the term @xmath29 in vanishes as  @xmath19 tends to infinity .",
    "however , quantization arguments that are used to prove information - theoretic statements for continuous - valued alphabets are usually applied to the achievability parts of coding theorems .",
    "for example , a quantization argument is used in ( * ? ? ?",
    "3.4.1 ) for leveraging the achievability proof for the discrete memoryless channel ( dmc ) with cost constraints to prove the achievability part of the capacity of the awgn channel .",
    "to the best of our knowledge , standard quantization arguments for achievability parts do not work for strong converse proofs because upon quantization , one has to ensure that the resultant asymptotic error probability is bounded away from one .",
    "the reader is also referred to ( * ? ? ?",
    "* appendix  d.6 ) for a complementary explanation of why ahlswede s original wringing technique works for only macs with finite alphabets but not the gaussian mac .",
    "the difficulties in directly using dueck s and ahlswede s techniques led the authors to combine a novel quantization argument together with ahlswede s wringing idea .",
    "we use a scalar quantizer of increasing precision in the blocklength to discretize ( only ) the input alphabets of the channel so that the ahlswede s wringing technique can be performed _ on the quantized channel inputs _ for any given code whose asymptotic error probability is bounded away from one . in doing so , we obtain a sequence of subcodes whose asymptotic error probability is bounded away from one such that the resultant correlations among the codeword symbols transmitted by the different sources vanish as  @xmath19 increases . note that if the quantizer s precision is too small or too large , the resultant upper bound on the sum - rate will be too loose and hence not useful in proving the strong converse .",
    "we discuss feasible choices of the quantizer s precision and the parameters used in the wringing technique in section  [ sectiondiscussionquantizer ] . in our proof",
    ", the quantizer s precision is chosen in such a way that the quantized input alphabets @xmath30 grow no faster than @xmath31 .",
    "it turns out that this choice of quantization also allows us to control the approximation errors between the true channel inputs and the quantized ones uniformly .      in ahlswede",
    "s proof of the strong converse for the discrete memoryless mac , he appealed to a non - asymptotic converse bound by augustin  @xcite . in our proof",
    "we use a conceptually similar non - asymptotic converse bound that is motivated by modern techniques relating binary hypothesis testing to channel coding .",
    "in particular , we use a form of the _ meta - converse _ ( * ? ? ? * sec .",
    "iii - e ) due to wang , colbeck and renner  ( * ? ? ?",
    "* lemma  1 ) .",
    "we derive a multi - user version of this non - asymptotic converse bound .",
    "after doing so , we choose the auxiliary conditional output distributions therein to be product distributions that approximate the _ quantized _ code distribution .",
    "we note that the flexibility of the choice of the output distributions is essential for proving the strong converse for the gaussian mac as we can allow these distributions to depend not only on the peak powers but also the chosen precision of the scalar quantizer ( cf .",
    "section  [ sec : remedy ] ) .      in the next subsection , we state the notation used in this paper . in section [ sectiondefinition ]",
    ", we describe the system model and define the @xmath32-capacity region of the gaussian mac . in section [ sec : main_res ] , we present the main result of the paper .",
    "we present a few preliminaries for the proof in section [ sectionprelim ] .",
    "the complete proof is then presented in section [ sec : prf_main_result ] .",
    "section  [ sectionic ] extends our strong converse result to the two - source two - destination gaussian ic under strong interference .",
    "we use the upper case letter  @xmath33 to denote an arbitrary ( discrete or continuous ) random variable with alphabet @xmath34 , and use a lower case letter @xmath35 to denote a realization of  @xmath33 .",
    "we use @xmath36 to denote the random tuple @xmath37 .",
    "the following notations are used for any arbitrary random variables  @xmath33 and  @xmath1 and any mapping @xmath38 whose domain includes @xmath34 .",
    "we let @xmath39 and @xmath40 denote the probability distribution of @xmath41 ( can be both discrete , both continuous or one discrete and one continuous ) and the conditional probability distribution of @xmath1 given @xmath33 respectively .",
    "we let @xmath42 and @xmath43 be the evaluations of @xmath39 and @xmath40 respectively at @xmath44 . to avoid confusion , we do not write @xmath45 to represent @xmath42 unless @xmath33 and @xmath1 are both discrete . to make the dependence on the distribution explicit ,",
    "we let @xmath46 denote @xmath47 for any real - valued function  @xmath38 and any set @xmath48 .",
    "the expectation and the variance of  @xmath49 are denoted as @xmath50 $ ] and @xmath51=\\e_{p_x}[(g(x)-\\e_{p_x}[g(x)])^2]$ ] respectively , where we again make the dependence on the underlying distribution @xmath52 explicit .",
    "we let @xmath53 denote the probability density function of a gaussian random variable whose mean and variance are @xmath54 and @xmath55 respectively .",
    "this means that @xmath56 we will take all logarithms to base 2 throughout this paper .",
    "the euclidean norm of a vector @xmath57 is denoted by @xmath58 .",
    "we consider a gaussian mac that consists of @xmath0 sources and one destination .",
    "let @xmath59 be the index set of the sources ( or encoders ) , and let @xmath60 denote the destination ( or decoder ) .",
    "the @xmath0 message sources transmit information to the destination in @xmath19 time slots ( channel uses ) as follows . for each @xmath61 ,",
    "node  @xmath62 chooses message @xmath63 and sends @xmath64 to node  @xmath60 where @xmath65 denotes the message size .",
    "based on @xmath66 , each node  @xmath62 prepares a codeword @xmath67 to be transmitted and @xmath68 should satisfy @xmath69 where @xmath5 denotes the power constraint for the codeword transmitted by node  @xmath62 . then for each @xmath70 ,",
    "each node  @xmath62 transmits @xmath71 in time slot  @xmath72 and node  @xmath60 receives the real - valued symbol @xmath73 where @xmath74 are i.i.d .",
    "and @xmath75 is a standard gaussian random variable .",
    "after  @xmath19 time slots , node  @xmath60 declares  @xmath76 to be the transmitted  @xmath77 based on @xmath78 .",
    "to simplify notation , we use the following convention for any @xmath79 . for any random tuple @xmath80 , we let @xmath81 be its subtuple , whose generic realization and alphabet are denoted by @xmath82 and @xmath83 respectively .",
    "similarly , for any @xmath70 and any random tuple @xmath84 , we let @xmath85 be its subtuple , whose realization is denoted by @xmath86 .",
    "the following five definitions formally define a gaussian mac and its capacity region .",
    "[ defcode ] let @xmath87 be a non - empty subset in @xmath88 .",
    "@xmath89-code _ for the gaussian mac , where @xmath90 and @xmath91 , consists of the following :    1 .   a message set @xmath92 at node  @xmath62 for each @xmath61 .",
    "2 .   a support set of the message tuple @xmath93 denoted by @xmath94 where @xmath93 is uniform on @xmath48 .",
    "in addition , all the @xmath95 s in @xmath48 have the same @xmath96 , i.e. , there exists a @xmath97 such that for all @xmath98 , we have @xmath99 .",
    "define @xmath100 to be the support of @xmath101 . consequently , the message tuple @xmath101 is uniform on @xmath102 .",
    "an encoding function @xmath103 for each @xmath61 , where @xmath104 is the encoding function at node  @xmath62 such that @xmath105 and @xmath106 for all @xmath107 .",
    "the set of codewords @xmath108 is called the _",
    "codebook for @xmath66_. for each @xmath109 , the finite alphabet @xmath110 is called the _ support _ of symbols transmitted by  @xmath62 because @xmath111 .",
    "note that @xmath112 for each @xmath61 by .",
    "a ( possibly stochastic ) decoding function @xmath113 which is used by node  @xmath60 to estimate the message tuple @xmath114 , i.e. , @xmath115 .    if @xmath116 and @xmath117 , then @xmath93 is uniformly distributed on @xmath118 , which implies that the @xmath0 messages are mutually independent .",
    "since @xmath119-codes are of our main interest , they are also called @xmath120-codes for notational convenience . however , in the present work , it is necessary to allow @xmath48 and @xmath87 to be strict subsets of @xmath118 and @xmath88 respectively so the generality afforded in the above definition is necessary . in this case , the @xmath0 messages need not be independent . in the rest of this paper ,",
    "if we fix a code with encoding functions @xmath121 , then @xmath122 as defined in   denotes the support of symbols transmitted by each @xmath109 .",
    "[ defgaussianmac ] a _ gaussian mac _ is characterized by the conditional probability density function @xmath123 satisfying @xmath124 for all @xmath125 and all @xmath126 such that the following holds for any @xmath127-code : let @xmath128 be the probability distribution induced by the @xmath127-code .",
    "then , @xmath129 for all @xmath130 where @xmath131 since @xmath132 does not depend on  @xmath72 by and , the channel is stationary .    for",
    "any @xmath127-code defined on the gaussian mac , let @xmath133 be the joint distribution induced by the code .",
    "since @xmath134 is a function of @xmath78 by definition  [ defcode ] , it follows that @xmath135 which implies from that @xmath136    [ deferror ] for an @xmath137-code defined on the gaussian mac , we can calculate according to the _ average probability of decoding error _ which is defined as @xmath138 an @xmath137-code with average probability of decoding error no larger than @xmath32 is called an @xmath139-code . similarly for an @xmath127-code , we can calculate the _ maximal probability of decoding error _ defined as @xmath140 an @xmath127-code with maximal probability of decoding error no larger than @xmath32 is called an @xmath141-code .",
    "[ defachievablerate ] a rate tuple @xmath142 is _",
    "@xmath32-achievable _ for the gaussian mac if there exists a sequence of @xmath143-codes on the gaussian mac such that @xmath144 for each @xmath109 and @xmath145    [ defcapacityregion ] for each @xmath146 , the _ @xmath32-capacity region _ of the gaussian mac , denoted by @xmath147 , is the set consisting of all @xmath32-achievable rate tuples @xmath148 .",
    "the _ capacity region _ is defined to be the @xmath18-capacity region @xmath149 .",
    "the following theorem is the main result in this paper .",
    "[ thmmainresult ] define @xmath150{2 in}{$\\sum_{i\\in t}r_i\\le \\frac{1}{2}\\log\\big(1+\\sum_{i\\in t}p_i\\big)$ } \\right.\\right\\}. \\label{rout}\\ ] ] then for each @xmath146 , @xmath151    we now present three remarks concerning theorem [ thmmainresult ] .    1 .   note that @xmath152 is the cover - wyner @xcite region for an @xmath0-source gaussian mac .",
    "the theorem says that regardless of the admissible average error probability ( as long as it is strictly smaller than @xmath153 ) , all achievable rate tuples must lie in @xmath152 .",
    "since all rate tuples in @xmath152 are @xmath18-achievable  ( * ? ? ?",
    "4.7 ) , we have for every @xmath154 @xmath155 2 .",
    "in fact , the proof allows us to additionally assert the following : for any non - vanishing average error probability @xmath154 and any subset @xmath79 , it can be shown that the sum - rate of the messages indexed by @xmath87 of any sequence of @xmath156-codes satisfying the constraint in   also satisfies @xmath157 \\le\\overline{\\upsilon}(\\varepsilon , t , p_{\\mathcal{i}})<\\infty\\label{eqn : sec_order}\\ ] ] for some finite constant @xmath158 .",
    "see in the proof of theorem [ thmmainresult ] . even though the normalizing speed of @xmath159 is not the desired @xmath160 ( as usually defined in second - order asymptotic analyses  @xcite )",
    ", the techniques in this work may serve as a stepping stone to establish an outer bound for the second - order coding rate region @xcite for the gaussian mac .",
    "the best inner bound for the second - order coding rates for the gaussian mac was established independently by scarlett , martinez , and guilln i fbregas  @xcite and molavianjazi and laneman  @xcite . according to the inner bounds in  @xcite and the relation between second - order coding rates and second - order asymptotics of sum - rates in  @xcite , @xmath161 \\ge\\underline{\\upsilon}(\\varepsilon , t , p_{\\mathcal{i } } ) > -\\infty \\label{eqn : sec_inner}\\ ] ] for some finite constant @xmath162 .",
    "our normalizing speed of @xmath163 in is slightly better than in ahlswede s work on the discrete memoryless mac  @xcite , which is @xmath164 .",
    "we have attempted to optimize ( reduce ) the exponent of the logarithm @xmath165 in the normalizing speed @xmath166 . however , as we will discuss in section  [ sectiondiscussionquantizer ] in the sequel , we are unable to use our proof technique to further reduce ( improve ) @xmath167 from  @xmath168 .",
    "for both the discrete and gaussian macs , it is challenging to prove that the exact normalizing speed of the second - order term is @xmath169 .",
    "this is , in part , due to the use of wringing technique in the converse part , which prevents one from obtaining a converse that matches the achievability in the rate of growth of the second - order term .",
    "unless new techniques are invented to replace the wringing argument in the strong converse proof for the mac ( such techniques have remained elusive for over 30 years ) , the exact normalizing speed of the second - order term for the discrete and gaussian macs will remain an open problem .    in the next section",
    ", we will present a few preliminaries for the proof of theorem  [ thmmainresult ] , which will be detailed in section [ sec : prf_main_result ] .",
    "the following lemma is based on the technique of expurgating message tuples introduced by dueck  ( * ? ? ?",
    "ii ) , and the proof is provided in the appendix for completeness .    [ lemmaexpurgation ]",
    "let @xmath170 .",
    "suppose an @xmath139-code for the gaussian mac is given .",
    "then for each nonempty @xmath79 such that @xmath171 there exist a set @xmath94 and an @xmath172-code such that @xmath173 where @xmath102 is as defined in . as a consequence ,",
    "if we let @xmath174 denote the probability distribution induced on the gaussian mac by the @xmath175-code , then we have for each @xmath176 @xmath177    lemma  [ lemmaexpurgation ] says that restricted to the set @xmath102 , the @xmath178 ( for @xmath179 ) codebooks have almost the same sizes as the original codebooks .",
    "in addition , the conditional probability of decoding error for each message tuple in this restricted codebook is upper bounded by @xmath180 , which is still smaller than one because @xmath146 . according to",
    ", the probability of each message tuple can not be greater than its original value by a factor of @xmath181 .",
    "the following lemma forms part of the wringing technique proposed by ahlswede and its proof can be found in ( * ? ? ?",
    "* lemma 4 ) .",
    "[ lemmafromahlswede ] let @xmath34 be a finite alphabet , let @xmath182 and @xmath183 be two probability mass functions defined on @xmath184 and let @xmath185 be a real number such that @xmath186 for all @xmath187 . fix any @xmath188 .",
    "then for any @xmath189 , there exist @xmath190 natural numbers in @xmath191 , denoted by @xmath192 , and @xmath190 elements of @xmath34 denoted by @xmath193 , such that the following three statements hold :    1 .",
    "2 .   @xmath195 3 .   for all @xmath196",
    ", we have @xmath197 for all @xmath198 .",
    "the crux of lemma  [ lemmafromahlswede ] is in the identification of the event @xmath199 such that conditioned on  @xmath200 , the distributions of the resultant codeword symbols transmitted in each time slot  @xmath72 can be approximated by  @xmath201 ( cf .  ) . in the sequel where each @xmath202 in lemma  [ lemmafromahlswede ] is substituted by @xmath203 where @xmath203 is some quantized version of @xmath204 to be specified later",
    ", the joint distribution @xmath205 that approximates @xmath206 will be chosen to be a product distribution ( cf .  ) with marginals @xmath207 . in order to use lemma  [ lemmafromahlswede ] for proving theorem  [ thmmainresult ] ,",
    "an important step involves controlling the size of @xmath34 in lemma  [ lemmafromahlswede ] . to this end",
    ", we use the following scalar quantizer to quantize the alphabet @xmath122 ( in  ) which is exponential in the blocklength @xmath19 ( cf .  )",
    "so that its quantized version is an alphabet whose size is polynomial in the blocklength .",
    "[ scalarquantizer ] let @xmath208 be a natural number and @xmath209 be a positive real number , and let @xmath210 be a set of @xmath211 quantization points where @xmath209 specifies the quantization precision .",
    "a scalar quantizer with domain @xmath212 $ ] and precision @xmath209 is the mapping @xmath213\\rightarrow \\mathbb{z}_{l,\\delta}\\ ] ] such that @xmath214 in other words , @xmath215 maps @xmath35 to the closest quantized point whose value is smaller than or equal to @xmath35 if @xmath216 , and to the closest quantized point whose value is larger than or equal to @xmath35 if @xmath217 .",
    "in addition , define the scalar quantizer for a real - valued tuple as @xmath218^n\\rightarrow \\mathbb{z}_{l,\\delta}^n\\ ] ] such that @xmath219 @xmath220    by our careful choice of the quantizer in definition  [ scalarquantizer ] , we have the following property for all @xmath221 : @xmath222    although the following lemma looks similar to ( * ? ? ?",
    "* corollary 2 ) and they both rely on lemma  [ lemmafromahlswede ] , the proof of the following lemma is more involved due to the additional consideration of the quantizer s precision and the quantized input symbols .",
    "if the quantizer s precision is too small or too large , then the resultant bound obtained from the following lemma will not be useful in proving the strong converse .",
    "see section  [ sectiondiscussionquantizer ] for a detailed discussion on the appropriate choice for the quantizer s precision .",
    "[ lemmawringing ] suppose we are given an @xmath223-code such that @xmath224 and @xmath225 for each @xmath226 where @xmath227 denotes the probability distribution induced on the gaussian mac by the @xmath228-code .",
    "then , there exists an @xmath172-code with @xmath229 such that the following holds : let @xmath174 denote the probability distribution induced on the gaussian mac by the @xmath175-code .",
    "in addition , let @xmath230 define the alphabet @xmath231 for each @xmath232 ( @xmath233 is always in the domain of @xmath234 because of , and , and hence @xmath235 ) , define @xmath236 and define @xmath237 for all @xmath238 .",
    "then there exists a distribution @xmath239 defined on @xmath240 where @xmath241 such that for all @xmath242 , we have @xmath243 for all @xmath244 and @xmath245 \\le \\sum_{i\\in t}np_i . \\label{corollarywringingst5}\\ ] ]    before presenting the proof of lemma  [ lemmawringing ] , we would like to stress the following two important implications of lemma  [ lemmawringing ] .    1 .   by identifying a certain event @xmath246 ( whose probability is quantified in   in the following proof ) , we can find a subcode such that for each time slot  @xmath72 , the resultant probability distribution of the quantized vector of transmitted symbols  @xmath247 can be approximated by a product distribution @xmath248 as in  .",
    "this is the essence of the wringing technique  @xcite which involves approximating the joint distribution of the random variables corresponding to the different encoders with a product distribution . by approximating @xmath203 with a product distribution , we effectively _ wring _ out",
    "the dependence among the collection of random variables @xmath249 .",
    "the alphabet size of the quantized transmitted symbol @xmath203 grows no faster than polynomially in  @xmath19 as in  .",
    "our quantization strategy that results in the polynomial growth of the alphabet sizes of the quantized symbols appears to be an important and necessary step , because the original alphabet size @xmath250 could be exponentially large in  @xmath19 ( cf .  ) .",
    "furthermore , the controlled growth of @xmath251 ensures that @xmath252 does not decay to zero exponentially fast as shown in   in the following proof and hence the asymptotic rates of the resultant subcode are the same as that of the original code .",
    "an important point to note here is the following : we are able to lower bound the probability @xmath252 because we defined @xmath253 in terms of the _ quantized _ random variables ( rather than the original ones ) .",
    "the application of the wringing technique on the quantized random variables is one of the major contributions of the present work .",
    "let @xmath227 be the probability distribution induced on the gaussian mac by the @xmath254-code that satisfies and , and let @xmath255 define a probability mass function @xmath256 as @xmath257 for all @xmath258 ( cf .   and ) , where @xmath259 represents the encoding function for @xmath66 of the @xmath228-code ( cf .  definition  [ defcode ] ) .",
    "the distribution @xmath256 is well - defined ( the probability masses sum to one ) through because @xmath260 using , we obtain @xmath261 where @xmath262 for all @xmath263 .",
    "we will use lemma  [ lemmafromahlswede ] to prove the existence of a subcode of the @xmath228-code such that the subcode satisfies , and for some @xmath264 defined on  @xmath240 . to this end , we first consider the following chain of inequalities for each @xmath265 such that @xmath266 : @xmath267 where ( a ) follows from and .",
    "it follows from and lemma  [ lemmafromahlswede ] with the identifications @xmath268 that there exist @xmath190 natural numbers in @xmath191 , denoted by @xmath192 , and @xmath190 real - valued @xmath269-dimensional tuples in @xmath270 , denoted by @xmath271 , such that the following three statements hold :    1 .",
    "2 .    3 .   for all @xmath196",
    ", we have @xmath273 for all @xmath244 .    using statement ( ii ) , statement ( iii ) and",
    ", we can construct an @xmath172-code by collecting all the codewords @xmath274 for the @xmath223-code which satisfy @xmath275 such that the following two statements hold :    1 .",
    "2 .   let @xmath174 denote the probability distribution induced on the gaussian mac by the @xmath277-code , and let @xmath278 then , @xmath279 and we have for all @xmath280 @xmath281 for all @xmath244 .    since for each @xmath282 @xmath283 for all @xmath244",
    ", it follows from that the following statement holds :    1 .   for all @xmath242",
    ", we have @xmath284 for all @xmath244 .",
    "consequently , follows from statement  ( i ) and statement  ( i ) , and follows from statement  ( iii ) by letting @xmath285    it remains to prove the upper bounds on @xmath251 and @xmath286 $ ] in   and   respectively .",
    "to prove  , we consider @xmath287 to prove  , we first use and to obtain @xmath288 since @xmath289 for all @xmath232 and all @xmath242 by and , it follows from that @xmath290 consequently , @xmath291\\notag\\\\   & \\quad \\stackrel{\\eqref{defu}}{= } \\sum_{i\\in t}\\sum_{k=1}^n\\e_{u_{\\hat x_{i , k}|\\hat x_{i , t_1}=\\bar x_{i , t_1 } , \\hat x_{i , t_2}=\\bar x_{i , t_2 } , \\ldots , \\hat x_{i , t_\\ell}=\\bar x_{i , t_\\ell}}^\\prime}\\left[\\hat x_{i , k}^2\\right]\\\\   & \\quad \\stackrel{\\eqref{distuproductform}}{=}\\sum_{i\\in t}\\sum_{k=1}^n\\e_{u_{\\hat x_{t , k}|\\hat x_{t , t_1}=\\bar x_{t , t_1 } , \\hat x_{t , t_2}=\\bar x_{t , t_2 } , \\ldots , \\hat x_{t , t_\\ell}=\\bar x_{t , t_\\ell}}^\\prime}\\left[\\hat x_{i , k}^2\\right]\\\\   & \\quad = \\sum_{i\\in t}\\sum_{k=1}^n\\e_{u_{\\hat x_t^n|\\hat x_{t , t_1}=\\bar x_{t , t_1 } , \\hat x_{t , t_2}=\\bar x_{t , t_2 } , \\ldots , \\hat x_{t , t_\\ell}=\\bar x_{t , t_\\ell}}^\\prime}\\left[\\hat x_{i , k}^2\\right]\\\\   & \\quad = \\e_{u_{\\hat x_t^n|\\hat x_{t , t_1}=\\bar x_{t , t_1 } , \\hat x_{t , t_2}=\\bar x_{t , t_2 } , \\ldots , \\hat x_{t , t_\\ell}=\\bar x_{t , t_\\ell}}^\\prime}\\left[\\sum_{i\\in t}\\sum_{k=1}^n\\hat x_{i , k}^2\\right]\\\\   & \\quad \\stackrel{\\eqref{uprimexhatpowerconstraint}}{\\le}\\sum_{i\\in t } np_i\\ , .",
    "\\end{aligned}\\ ] ]      the following definition concerning the non - asymptotic fundamental limits of a simple binary hypothesis test is standard .",
    "see for example ( * ? ? ?",
    "iii - e ) .    [ defbhtdivergence ]",
    "let @xmath292 and @xmath293 be two probability distributions on some common alphabet @xmath34 .",
    "let @xmath294 be the set of randomized binary hypothesis tests between @xmath292 and @xmath293 where @xmath295 indicates the test chooses @xmath296 , and let @xmath297 $ ] be a real number .",
    "the minimum type - ii error in a simple binary hypothesis test between @xmath292 and @xmath293 with type - i error no larger than @xmath298 is defined as @xmath299    the existence of a minimizing test @xmath300 is guaranteed by the neyman - pearson lemma .",
    "we state in the following lemma and proposition some important properties of @xmath301 , which are crucial for the proof of theorem  [ thmmainresult ] .",
    "the proof of the following lemma can be found in , for example , the paper by wang , colbeck , and renner  ( * ? ? ? * lemma  1 ) .    [ lemmadpi ]",
    "let @xmath292 and @xmath293 be two probability distributions on some alphabet @xmath34 , and let @xmath38 be a function whose domain contains @xmath34 .",
    "then , the following two statements hold :    1 .",
    "data processing inequality ( dpi ) : @xmath302 2 .   for all @xmath303 , @xmath304",
    "the proof of the following proposition is similar to lemma  3 in @xcite and therefore omitted .",
    "[ propositionbhtlowerbound ] let @xmath305 be a probability distribution defined on @xmath306 for some finite alphabet @xmath307 .",
    "in addition , let @xmath308 be a distribution defined on @xmath307 , and let @xmath309 be a real number in @xmath310 where @xmath311 is distributed according to @xmath305 . then for each @xmath312 , @xmath313",
    "let @xmath170 and suppose @xmath314 is an @xmath32-achievable rate tuple . by definition  [ defachievablerate ] ,",
    "there exists a @xmath315 and a sequence of @xmath143-codes such that @xmath316 for all sufficiently large  @xmath19 and @xmath317 for each @xmath109 .",
    "fix a non - empty set @xmath79 .",
    "our goal is to prove that @xmath318 since holds trivially if @xmath319 , we assume without loss of generality that @xmath320 it follows from and that @xmath321 for all sufficiently large  @xmath19 . fix a sufficiently large  @xmath19 and the corresponding @xmath143-code for the gaussian mac such that and hold . using lemma  [ lemmaexpurgation ] ,",
    "lemma  [ lemmawringing ] and definition  [ defcode ] , there exists an @xmath322-code , which induces a probability distribution on the gaussian mac denoted by @xmath174 , such that the following four statements hold :    1 .   for all @xmath98 and all @xmath176 , @xmath323 2 .",
    "there exists a @xmath97 such that for all @xmath98 , we have @xmath99 .",
    "3 .   the support of @xmath101 satisfies @xmath324 4 .",
    "define @xmath325 for all @xmath326 , where @xmath327 and @xmath328 then there exists a distribution @xmath239 defined on @xmath240 such that for all @xmath242 , we have @xmath329 for all @xmath244 and @xmath330 \\le \\sum_{i\\in t}np_i \\ , .",
    "\\label{eqn : statement(v ) }   \\end{aligned}\\ ] ]    note that @xmath174 is not the distribution induced by the original @xmath143-code but rather it is induced by the expurgated @xmath322-code .      now ,",
    "let @xmath331 be a distribution such that for each @xmath242 , the auxiliary conditional output distribution is chosen to be @xmath332 + \\sum_{j\\in t^c}x_{j , k},1+\\sum_{i\\in t}p_i \\right ) \\label{defsimulatingdistsksumrate}\\ ] ] for all @xmath333 and @xmath334 .",
    "it can be seen from and that @xmath335 depends on the choice of  @xmath87 we fixed at the start of the proof and the distribution @xmath239 in statement  ( iv ) .",
    "we shall see later that this choice of @xmath335 , in particular the mean of the distribution in   namely @xmath336 + \\sum_{j\\in t^c}x_{j , k}$ ] , combined with proposition  [ propositionbhtlowerbound ] and lemma  [ lemmadpi ] enables us to prove  .",
    "we do not index @xmath335 by @xmath87 nor @xmath239 for notational brevity . to simplify notation ,",
    "let @xmath337 be the maximal probability of decoding error of the @xmath322-code , where @xmath338 because @xmath339 .",
    "then for each @xmath340 , since @xmath341 it follows from proposition  [ propositionbhtlowerbound ] and definition  [ defcode ] with the identifications @xmath342 , @xmath343 , @xmath344 , @xmath345 and @xmath346 that @xmath347      consider the following chain of inequalities for each @xmath348 : @xmath349 where    1 .   follows from the dpi of @xmath350 by introducing the channel output @xmath78 .",
    "2 .   follows from the fact that @xmath351 forms a markov chain under the distribution @xmath352 .",
    "3 .   follows from the dpi of @xmath350 by introducing the channel input @xmath353 .",
    "4 .   follows from definition  [ defcode ] , which says @xmath354 is a function of @xmath355 .      following , we consider @xmath356 and we obtain from lemma  [ lemmadpi ] and that for each @xmath98 and each @xmath357 , @xmath358 combining , and , we obtain for each @xmath98 and each @xmath357 @xmath359 which implies that @xmath360 for each @xmath98 , let @xmath361 \\notag \\\\ & \\qquad + \\sqrt{\\frac{2}{1-\\bar \\gamma}\\var_{p_{x_{\\mathcal{i}}^n , y^n|w_\\mathcal{i}=w_\\mathcal{i}}}\\left[\\sum_{k=1}^n \\log\\left ( \\frac{p_{y_k|x_{\\mathcal{i},k}}(y_k|x_{\\mathcal{i},k})}{s_{y_{k}|x_{t^c , k}}(y_k|x_{t^c , k})}\\right)\\right]}\\ , \\ , .",
    "\\label{defxiwi}\\end{aligned}\\ ] ] using chebyshev s inequality , it follows from that for each @xmath98 @xmath362 which implies from that @xmath363 since @xmath364 is convex for @xmath365 , by jensen s inequality @xmath366 we have @xmath367 where ( a ) follows from the definition of @xmath102 in and the fact stated in statement  ( ii ) that @xmath99 for all @xmath98 . using and ,",
    "we obtain @xmath368 taking expectation with respect to @xmath369 on both sides of and applying  , we obtain @xmath370      in order to simplify , we will simplify the log - likelihood term in @xmath371 defined in . to this end",
    ", we first let @xmath372 ( @xmath104 is the encoding function at node  @xmath62 defined in definition  [ defcode ] ) and we also let @xmath373 denote the @xmath374 component of @xmath375 for each @xmath109 and each @xmath376 such that @xmath377 in addition , we let @xmath378 and we let @xmath379 be a subtuple of @xmath380 . similarly , let @xmath381 and let @xmath382 be a subtuple of @xmath383 . using the fact that @xmath68 is a function of @xmath66 for all @xmath109 and the notations defined above , we obtain from that @xmath384 \\notag \\\\ & \\qquad + \\sqrt{\\frac{2}{1-\\bar \\gamma}\\var_{p_{y^n|w_\\mathcal{i}=w_\\mathcal{i},x_{\\mathcal{i}}^n = x_\\mathcal{i}^n(w_\\mathcal{i})}}\\left[\\sum_{k=1}^n \\log\\left ( \\frac{p_{y_k|x_{\\mathcal{i},k}}(y_k|x_{\\mathcal{i},k}(w_\\mathcal{i}))}{s_{y_{k}|x_{t^c , k}}(y_k|x_{t^c , k}(w_{t^c}))}\\right)\\right]}\\ , \\ , , \\end{aligned}\\ ] ] which implies from that @xmath385 \\notag \\\\ & \\qquad + \\sqrt{\\frac{2}{1-\\bar \\gamma}\\var_{\\prod_{k=1}^np_{y_k|x_{\\mathcal{i},k}=x_{\\mathcal{i},k}(w_\\mathcal{i } ) } } \\left[\\sum_{k=1}^n \\log\\left ( \\frac{p_{y_k|x_{\\mathcal{i},k}}(y_k|x_{\\mathcal{i},k}(w_\\mathcal{i}))}{s_{y_{k}|x_{t^c , k}}(y_k|x_{t^c , k}(w_{t^c}))}\\right)\\right]}\\ , \\ , , \\end{aligned}\\ ] ] which then implies that @xmath386 \\notag \\\\ & \\qquad + \\sqrt{\\frac{2}{1-\\bar \\gamma}\\sum_{k=1}^n\\var_{p_{y_k|x_{\\mathcal{i},k}=x_{\\mathcal{i},k}(w_\\mathcal{i } ) } } \\left [ \\log\\left ( \\frac{p_{y_k|x_{\\mathcal{i},k}}(y_k|x_{\\mathcal{i},k}(w_\\mathcal{i}))}{s_{y_{k}|x_{t^c , k}}(y_k|x_{t^c , k}(w_{t^c}))}\\right)\\right]}\\ , \\ , .",
    "\\label{defxiwi*}\\end{aligned}\\ ] ] following , we use , and to obtain @xmath387)\\right)\\left(y_k-\\sum_{i\\in\\mathcal{i}}x_{i , k}(w_i)\\right ) + \\left(\\sum_{i\\in t}(x_{i , k}(w_i)-\\e_{u_{\\hat x_{i , k}}}[\\hat x_{i , k}])\\right)^2\\bigg ) .",
    "\\label{eqnbht8thchain}\\end{aligned}\\ ] ] for each @xmath98 and each @xmath242 , it follows from definition  [ defgaussianmac ] that @xmath388 is a standard normal random variable if @xmath389 is distributed according to @xmath390 , which then implies that @xmath391 \\notag\\\\ *   & \\stackrel{\\eqref{eqnbht8thchain}}{= } \\frac{1}{2}\\log\\left(1+\\sum_{i\\in t}p_i\\right)+\\frac{\\log e}{2(1+\\sum_{i\\in t}p_i)}\\left(-\\left(\\sum_{i\\in t}p_i\\right ) + \\left(\\sum_{i\\in t}(x_{i , k}(w_i)-\\e_{u_{\\hat x_{i , k}}}[\\hat x_{i , k}])\\right)^2\\right ) \\label{infospectrumexptimek}\\end{aligned}\\ ] ] and @xmath392 \\notag\\\\ * & \\stackrel{\\eqref{eqnbht8thchain}}{=}\\bigg ( \\frac{\\log e}{2(1+\\sum_{i\\in t}p_i ) } \\bigg)^2 \\var_{p_{y_k|x_{\\mathcal{i},k}=x_{\\mathcal{i},k}(w_\\mathcal{i})}}\\bigg [ -\\bigg(\\sum_{i\\in t}p_i\\bigg)\\bigg(y_k-\\sum_{i\\in\\mathcal{i}}x_{i , k}(w_i)\\bigg)^2 \\notag\\\\ *   & \\qquad + 2\\left(\\sum_{i\\in t}(x_{i , k}(w_i)-\\e_{u_{\\hat x_{i , k}}}[\\hat x_{i , k}])\\right)\\bigg(y_k-\\sum_{i\\in\\mathcal{i}}x_{i , k}(w_i)\\bigg ) \\bigg ] \\\\ *   & = \\frac{\\left((\\sum_{i\\in t}p_i)^2 + 2\\left(\\sum_{i\\in t}(x_{i , k}(w_i)-\\e_{u_{\\hat x_{i , k}}}[\\hat x_{i , k}])\\right)^2\\right)(\\log e)^2}{2(1+\\sum_{i\\in t}p_i)^2}.   \\label{infospectrumvarexptimek}\\end{aligned}\\ ] ] define @xmath393 and @xmath394",
    ". \\label{defbarxik}\\ ] ] combining , , , , and , we obtain for each @xmath98 @xmath395 which implies from jensen s inequality ( @xmath396 is concave for @xmath397 ) that @xmath398 in the following , we will obtain an upper bound on the crucial term @xmath399 which appears in the second and third terms on the right - hand - side of .",
    "following , we consider for each @xmath242 @xmath400 since @xmath68 is a function of @xmath66 for each @xmath179 , it follows from that for each @xmath242 @xmath401\\right)\\right)^2,\\ ] ] which implies from that @xmath402\\right)\\right)^2 . \\label{eqnbht10thchain*}\\ ] ] recalling the definition of @xmath403 and @xmath240 in and respectively , we write for each @xmath242 @xmath404\\right)\\right)^2 \\notag\\\\ * & = \\sum\\limits_{x_{t , k}\\in \\mathcal{x}_t , \\hat x_{t , k}\\in \\hat{\\mathcal{x}}_t}p_{x_{t , k } , \\hat x_{t , k}}(x_{t , k } , \\hat x_{t , k})\\left(\\sum\\limits_{i\\in t } \\left(x_{i , k}-\\hat x_{i , k}+\\hat x_{i , k}- \\e_{u_{\\hat x_{i , k}}}[\\hat x_{i , k}]\\right)\\right)^2 \\\\ & = \\sum\\limits_{x_{t , k}\\in \\mathcal{x}_t , \\hat x_{t , k}\\in \\hat{\\mathcal{x}}_t}p_{x_{t , k } , \\hat x_{t , k}}(x_{t , k } , \\hat x_{t , k})\\left(\\sum\\limits_{i\\in t } ( x_{i , k}-\\hat x_{i , k})\\right)^2 \\notag\\\\ * & \\qquad + 2\\sum\\limits_{x_{t , k}\\in \\mathcal{x}_t , \\hat x_{t , k}\\in \\hat{\\mathcal{x}}_t}p_{x_{t , k } , \\hat x_{t , k}}(x_{t , k } , \\hat x_{t , k})\\left(\\sum\\limits_{i\\in t } ( x_{i , k}-\\hat x_{i , k})\\right)\\left(\\sum\\limits_{i\\in t}(\\hat x_{i , k}- \\e_{u_{\\hat x_{i , k}}}[\\hat x_{i , k}])\\right)\\notag\\\\ * & \\qquad + \\sum\\limits_{\\hat x_{t , k}\\in \\hat{\\mathcal{x}}_t}p_{\\hat x_{t , k}}(\\hat x_{t , k})\\left(\\sum\\limits_{i\\in t}(\\hat x_{i , k}- \\e_{u_{\\hat x_{i , k}}}[\\hat x_{i , k}])\\right)^2 \\\\ & \\le \\sum\\limits_{x_{t , k}\\in \\mathcal{x}_t , \\hat x_{t , k}\\in \\hat{\\mathcal{x}}_t}p_{x_{t , k } , \\hat x_{t , k}}(x_{t , k } , \\hat x_{t , k})\\left|\\sum\\limits_{i\\in t } ( x_{i , k}-\\hat x_{i , k})\\right|^2 \\notag\\\\ * & \\qquad + 2\\sum\\limits_{x_{t , k}\\in \\mathcal{x}_t , \\hat x_{t , k}\\in \\hat{\\mathcal{x}}_t}p_{x_{t , k } , \\hat x_{t , k}}(x_{t , k } , \\hat x_{t , k})\\left|\\sum\\limits_{i\\in t } ( x_{i , k}-\\hat x_{i , k})\\right|\\left|\\sum\\limits_{i\\in t}(\\hat x_{i , k}- \\e_{u_{\\hat x_{i , k}}}[\\hat x_{i , k}])\\right|\\notag\\\\ * & \\qquad + \\sum\\limits_{\\hat x_{t , k}\\in \\hat{\\mathcal{x}}_t}p_{\\hat x_{t , k}}(\\hat x_{t , k})\\left(\\sum\\limits_{i\\in t}(\\hat x_{i , k}- \\e_{u_{\\hat x_{i , k}}}[\\hat x_{i , k}])\\right)^2 \\\\ & \\le \\sum\\limits_{x_{t , k}\\in \\mathcal{x}_t , \\hat x_{t , k}\\in \\hat{\\mathcal{x}}_t}p_{x_{t , k } , \\hat x_{t , k}}(x_{t , k } , \\hat x_{t , k})\\left(\\sum\\limits_{i\\in t } |x_{i , k}-\\hat x_{i , k}|\\right)^2 \\notag\\\\ * & \\qquad + 2\\sum\\limits_{x_{t , k}\\in \\mathcal{x}_t , \\hat x_{t , k}\\in \\hat{\\mathcal{x}}_t}p_{x_{t , k } , \\hat x_{t , k}}(x_{t , k } , \\hat x_{t , k})\\left(\\sum\\limits_{i\\in t } |x_{i , k}-\\hat x_{i , k}|\\right)\\left(\\sum\\limits_{i\\in t}(|\\hat x_{i , k}| + \\e_{u_{\\hat x_{i , k}}}[|\\hat x_{i , k}|])\\right)\\notag\\\\ * & \\qquad + \\sum\\limits_{\\hat x_{t , k}\\in \\hat{\\mathcal{x}}_t}p_{\\hat x_{t , k}}(\\hat x_{t , k})\\left(\\sum\\limits_{i\\in t}(\\hat x_{i , k}- \\e_{u_{\\hat x_{i , k}}}[\\hat x_{i , k}])\\right)^2 \\\\ & \\stackrel{\\text{(a)}}{\\le}\\frac{|t|^2}{n^2 } + \\frac{4|t|}{\\sqrt{n}}\\left(\\sum_{i\\in t}\\sqrt{p_i}\\right ) + \\sum\\limits_{\\hat x_{t , k}\\in \\hat{\\mathcal{x}}_t}p_{\\hat x_{t , k}}(\\hat x_{t , k})\\left(\\sum\\limits_{i\\in t}(\\hat x_{i , k}- \\e_{u_{\\hat x_{i , k}}}[\\hat x_{i , k}])\\right)^2 \\label{eqnbht11thchain}\\end{aligned}\\ ] ] where ( a ) follows from the facts below for each @xmath179 , each @xmath242 and each @xmath405 ( recall the definition of @xmath406 in ): @xmath407 and @xmath408      in order to bound the last term in , we use the bound in for bounding @xmath409 in terms of @xmath410 to obtain @xmath411)\\right)^2 \\notag\\\\ & \\quad \\le \\sum\\limits_{\\hat x_{t , k } \\in \\hat{\\mathcal{x}}_t}\\left(\\left(1+\\sqrt{\\frac{\\log n}{n}}\\right)\\prod_{i\\in t}u_{\\hat x_{i , k}}(\\hat x_{i , k})+ \\frac{1}{n^{4|t|}}\\right)\\left(\\sum\\limits_{i\\in t}(\\hat x_{i , k}- \\e_{u_{\\hat x_{i , k}}}[\\hat x_{i , k}])\\right)^2 \\label{eqnbht12thchain_a}\\\\ & \\quad = \\sum\\limits_{\\hat x_{t , k } \\in \\hat{\\mathcal{x}}_t}\\bigg[\\left(1+\\sqrt{\\frac{\\log n}{n}}\\right)\\prod_{i\\in t}u_{\\hat x_{i , k}}(\\hat x_{i , k})\\left(\\sum\\limits_{i\\in t}(\\hat x_{i , k}- \\e_{u_{\\hat x_{i , k}}}[\\hat x_{i , k}])\\right)^2 \\notag\\\\ * & \\qquad\\qquad\\qquad\\qquad+ \\frac{1}{n^{4|t| } } \\left(\\sum\\limits_{i\\in t}(\\hat x_{i , k}- \\e_{u_{\\hat x_{i , k}}}[\\hat x_{i , k}])\\right)^2 \\bigg]\\label{eqnbht12thchain}\\end{aligned}\\ ] ] for each @xmath242 . the bound in   consists of two distinct terms which we now bound separately .",
    "consider the following two chains of inequalities for each @xmath242 : @xmath412)\\right)^2 \\notag \\\\ * & = \\sum_{i\\in t } \\e_{u_{\\hat x_{i , k}}}\\left [ ( \\hat x_{i , k}- \\e_{u_{\\hat x_{i , k}}}[\\hat x_{i , k}])^2\\right ] \\\\ * & \\le \\sum_{i\\in t } \\e_{u_{\\hat x_{i , k } } } \\left[\\hat x_{i , k}^2\\right ] \\label{eqnbht13thchain}\\end{aligned}\\ ] ] and @xmath413)\\right)^2 \\notag\\\\ * & \\quad \\le \\sum\\limits_{\\hat x_{t , k } \\in \\hat{\\mathcal{x}}_t } \\left(|t|\\max\\limits_{i\\in t}\\left\\{|\\hat x_{i , k}- \\e_{u_{\\hat x_{i , k}}}[\\hat x_{i , k}]|\\right\\ } \\right)^2 \\\\ & \\quad = |t|^2\\sum\\limits_{\\hat x_{t , k } \\in \\hat{\\mathcal{x}}_t } \\max\\limits_{i\\in t}\\left\\{(\\hat x_{i , k}- \\e_{u_{\\hat x_{i , k}}}[\\hat x_{i , k}])^2\\right\\ } \\\\ & \\quad \\le |t|^2\\sum\\limits_{\\hat x_{t , k } \\in \\hat{\\mathcal{x}}_t } \\sum_{i\\in t}(\\hat x_{i , k}- \\e_{u_{\\hat x_{i , k}}}[\\hat x_{i , k}])^2 \\\\ & \\quad \\stackrel{\\text{(a)}}{\\le } 2|t|^2\\sum\\limits_{\\hat x_{t , k } \\in \\hat{\\mathcal{x}}_t } \\sum_{i\\in t}\\left(\\hat x_{i , k}^2 + ( \\e_{u_{\\hat x_{i , k}}}[\\hat x_{i , k}])^2\\right ) \\\\ & \\quad \\stackrel{\\eqref{boundonhatxik}}{\\le } 2|t|^2\\sum\\limits_{\\hat x_{t , k } \\in \\hat{\\mathcal{x}}_t } \\sum_{i\\in t}2np_i \\\\ & \\quad \\stackrel{\\text{(b)}}{\\le } 4n|t|^2 |p_t| | \\hat{\\mathcal{x}}_t|\\\\ & \\quad \\stackrel{\\eqref{eqn : size_xhat } } { < } 4n^{3|t|}|t|^2 |p_t|\\prod\\limits_{i \\in t}(2\\sqrt{p_i } + 3 ) , \\label{eqnbht14thchain}\\end{aligned}\\ ] ] where    1",
    ".   follows from the fact that @xmath414 for all real numbers @xmath415 and @xmath416 .",
    "2 .   follows from the definition of @xmath417 in  .    combining , and",
    ", we obtain for each @xmath242 @xmath418)\\right)^2 \\notag\\\\ * & \\quad \\le \\left(1+\\sqrt{\\frac{\\log",
    "n}{n}}\\right)\\sum_{i\\in t } \\e_{u_{\\hat x_{i } } } \\left[\\hat x_{i , k}^2\\right ] + 4n^{-|t|}|t|^2 |p_t|\\prod\\limits_{i \\in t}(2\\sqrt{p_i } + 3),\\end{aligned}\\ ] ] which implies from and that @xmath419 + 4n^{-|t|}|t|^2 |p_t|\\prod\\limits_{i \\in t}(2\\sqrt{p_i } + 3 ) .",
    "\\label{eqnbht15thchain}\\end{aligned}\\ ] ] using and and recalling that @xmath420 ( because @xmath87 is non - empty ) , we obtain @xmath421 to simplify notation , let @xmath422 be two constants that are independent of  @xmath19 . then , we combine and to yield @xmath423 combining and , we obtain @xmath424 dividing both sides of by @xmath19 and taking limit inferior as  @xmath19 goes to infinity , we obtain from that holds as desired .",
    "this completes the proof of theorem  [ thmmainresult ] .",
    "our choice of  @xmath425 in   has been optimized in the following sense .",
    "if @xmath425 is chosen such that @xmath426 , then the second - order term on the rhs of   would be @xmath427 ( cf .   and  ) , which then leads to an upper bound on  @xmath428 with a looser ( larger ) second - order term @xmath429 ; if @xmath425 is chosen such that @xmath430 , then the magnitude of the first term on the lhs of   would be @xmath427 ( cf .  ) , which then leads to an upper bound on  @xmath428 with a looser second - order term @xmath429 .",
    "hence our choice of @xmath431  balances \" the rates of growth of the two second - order terms in  . in this sense",
    ", our choice of @xmath425 is optimal .",
    "we now discuss the choice of the quantizer s precision @xmath432 as shown in . based on this choice of @xmath433",
    ", we note that any choice of @xmath434 in   satisfying @xmath435 does not affect the second - order term of the resultant upper bound on @xmath428 implied by  .",
    "in particular , the current choice @xmath436 stated in   leads to the rightmost term in  , which contributes to the fourth constant term in   as well as the constant term on the rhs of  .",
    "if the quantizer s precision is chosen to be some other @xmath437 , then it can be seen by inspecting  , the upper bound obtained at step  ( a ) in the chain of inequalities leading to , and   that the second - order term of resultant upper bound on @xmath428 is @xmath438 . in particular ,",
    "if @xmath437 is chosen such that @xmath439 for any fixed @xmath440 , we can follow similar calculations ( with a slight modification of @xmath434 ) to conclude that the second - order term of the upper bound on @xmath428 is proportional to @xmath441 . as explained in the second remark after lemma  [ lemmawringing ] , as long as @xmath437 decays to zero no faster than polynomially in  @xmath19",
    ", then @xmath251 grows at most polynomially fast in  @xmath19 , which will ensure that the asymptotic rates of the resultant sequence of subcodes obtained from the wringing step are the same as that of the original sequence of codes .",
    "however , if @xmath437 decays to zero exponentially fast ( i.e. , @xmath442 for some @xmath443 ) , then @xmath251 will grow exponentially fast in  @xmath19 and the rhs of   will decay exponentially rather than polynomially fast .",
    "this in turn causes the asymptotic rates of the resultant sequence of subcodes to decrease by a positive quantity , thus resulting in a loose first - order term on the rhs of the final inequality   ( which does not match the corresponding term in the cover - wyner capacity region ) .",
    "therefore , with this choice of @xmath437 , the strong converse can not be shown .",
    "the capacity region of a two - source two - destination gaussian interference channel ( ic ) under strong interference was derived by han and kobayashi  @xcite and sato  @xcite .",
    "let @xmath444 be the received signal - to - noise ratios and let @xmath445 be the received interference - to - noise ratios  ( * ? ? ?",
    "6.4 ) . under the formulation of the gaussian ic under _ strong interference _ , it is assumed that @xmath446 and @xmath447 . under this condition , the capacity region was shown in ( * ? ? ?",
    "5.2 ) to be the han - kobayashi region @xmath448{3.6",
    "in}{$r_1\\le \\frac{1}{2}\\log(1+p_1)$ , \\vspace{0.04 in}\\\\ $ r_2\\le \\frac{1}{2}\\log(1+p_2 ) $ , \\vspace{0.04 in } \\\\ $ r_1+r_2\\le \\min\\{\\frac{1}{2}\\log(1+p_1+i_1),\\frac{1}{2}\\log(1+p_2+i_2 ) \\ } $ } \\right.\\right\\}. \\label{strong_interference}\\ ] ] by applying theorem  [ thmmainresult ] to each of the decoders of the two - source two - destination gaussian ic , we can show that the corresponding @xmath449-capacity region @xmath450 is outer bounded as @xmath451 as long as @xmath452 , where @xmath453 characterizes the asymptotic average probability of destination  @xmath62 decoding message  @xmath62 wrongly .",
    "since the rate pairs in @xmath454 are @xmath455-achievable via simultaneous non - unique decoding  ( * ? ? ?",
    "6.4 ) , we have @xmath456 as long as @xmath452 . the strong converse ( in fact , the complete second - order asymptotics ) for the gaussian ic under the more restrictive condition of strictly very strong interference",
    "was shown by le , tan , and motani  @xcite . in the rest of this section , we will describe the formulation of the gaussian ic under strong interference and present in section  [ sectionproofofthmic ] the corresponding strong converse result .",
    "we follow the standard setting of the gaussian ic under strong interference as given in ( * ? ? ?",
    "the gaussian ic under strong interference consists of two sources , denoted by  @xmath457 and @xmath458 respectively , and two destinations , denoted by  @xmath459 and @xmath460 respectively . for each @xmath461",
    ", @xmath462 chooses a message  @xmath66 and transmits  @xmath68 in  @xmath19 time slots , and @xmath463 receives @xmath464 in  @xmath19 time slots and declares  @xmath465 to be the transmitted @xmath66 .",
    "the channel law in each time slot  @xmath72 is @xmath466 = \\left[\\begin{array}{cc}1 & g_{12}\\\\ g_{21 } & 1\\end{array}\\right]\\left[\\begin{array}{c}x_{1,k } \\\\",
    "x_{2,k}\\end{array}\\right ] + \\left[\\begin{array}{c}z_{1,k } \\\\ z_{2,k}\\end{array}\\right ] , \\label{channellawic}\\ ] ] where @xmath467 and @xmath468 are two real constants characterizing the channel gains of the interference links , and @xmath469 are @xmath19 independent copies of a gaussian random vector denoted by @xmath470 ( @xmath75 and @xmath471 need not be independent ) such that @xmath472=\\e\\left[z_{2}\\right ] = 0 \\label{channellawic1 }   \\end{aligned}\\ ] ] and @xmath473=\\e\\left[z_{2}^2\\right ] = 1 .",
    "\\label{channellawic2 }   \\end{aligned}\\ ] ] for each @xmath461 , the codewords transmitted by  @xmath462 should satisfy the peak power constraint @xmath474 for some @xmath475 .",
    "we assume that the ic is under strong interference , i.e. , @xmath476 and @xmath477 , which implies that @xmath478 and @xmath479 where @xmath480 and @xmath481 characterize the interference power received at  @xmath459 and @xmath460 respectively ( cf .  ) .",
    "the gaussian ic is characterized by some conditional probability density function @xmath482 and we define the gaussian ic in a similar way to a gaussian mac ( cf .",
    "definition  [ defgaussianmac ] ) such that , and hold .",
    "in addition , we define a length-@xmath19 code for the gaussian ic as follows .",
    "[ defcodeic ] an _ @xmath483-code _ for the gaussian ic consists of the following :    1 .   a message set @xmath92 at node  @xmath62 for each @xmath484 , where @xmath66 is uniform on @xmath485 .",
    "an encoding function @xmath103 for each @xmath484 , where @xmath104 is the encoding function at node  @xmath62 such that @xmath105 and @xmath486 for all @xmath107 .",
    "3 .   a ( possibly stochastic ) decoding function @xmath487 for each @xmath461 , where @xmath488 is used by node  @xmath463 to estimate  @xmath66 , i.e. , @xmath489    we define an @xmath490-code as follows .",
    "[ deferroric ] for an @xmath483-code defined on the gaussian ic , the _ average probability of decoding error for @xmath66 _ is defined for each @xmath461 as @xmath491 an @xmath483-code with @xmath492 and @xmath493 is called an @xmath494-code .    for each @xmath495 and each @xmath496",
    ", we define an @xmath449-achievable rate pair as in definition  [ defachievablerate ] , and we define the @xmath449-capacity region , denoted by @xmath450 , to be the set of @xmath449-achievable rate pairs .",
    "the following theorem is the main result in this section .",
    "[ thmmainresultic ] for each @xmath495 and each @xmath496 such that @xmath452 , @xmath497      we need the following definitions and lemma before presenting the proof of theorem  [ thmmainresultic ] .",
    "the definition below concerning a multicast code differs from definition  [ defcodeic ] in the decoding functions only , but we state the whole definition for clarity .",
    "essentially , a multicast code for the gaussian ic is the same as a standard code except that each decoder must output estimates of _ both _ messages .",
    "[ defcodeicandmac ] an _ @xmath483-multicast code _ for the gaussian ic consists of the following :    1 .   a message set @xmath92 at node  @xmath62 for each @xmath484 , where @xmath66 is uniform on @xmath485 .",
    "an encoding function @xmath103 for each @xmath484 , where @xmath104 is the encoding function at node  @xmath62 such that @xmath105 and @xmath498 for all @xmath107 .",
    "3 .   a ( possibly stochastic ) decoding function @xmath499 for each @xmath461 , where @xmath488 is used by node  @xmath463 to estimate both @xmath500 and @xmath501 such that the pair of message estimates is @xmath502 .",
    "we define an @xmath490-multicast code as follows .",
    "note that the multicast code is used for the gaussian ic but not a general multicast channel .",
    "[ deferroricandmac ] for an @xmath483-multicast code defined on the gaussian ic , the _ average probability of decoding error at destination @xmath463 _ is defined for each @xmath461 as @xmath503 an @xmath483-multicast code with average probability of decoding error at destination @xmath463 no larger than @xmath453 for each @xmath461 is called an @xmath490-code .    the following lemma plays a crucial role in extending our strong converse result for the gaussian mac to the gaussian ic under strong interference , because it relates the error probabilities for standard codes defined for the gaussian ic in definition  [ deferroric ] to the error probabilities for multicast - codes defined for the gaussian ic in definition  [ deferroricandmac ] .",
    "[ lemmaic ] for each @xmath490-code for the gaussian ic , there exists an @xmath504-multicast code for the gaussian ic .",
    "suppose we are given an @xmath490-code whose encoding and stochastic decoding functions are denoted by @xmath505 and @xmath506 respectively ( cf .  definition  [ defcodeic ] ) .",
    "let @xmath507 be the probability distribution induced by the @xmath490-code . by definition  [ deferroric ] , we have for each @xmath461 @xmath508 which implies from that @xmath509 and @xmath510 in the rest of the proof , we construct new stochastic decoding functions at  @xmath459 and  @xmath460 , denoted by @xmath511 and @xmath512 respectively , such that @xmath513 and @xmath514 can be viewed as the stochastic decoding functions of an @xmath515-multicast code . to this end , we first define @xmath516 and @xmath517 to be  @xmath19 independent copies of the standard normal random variable such that @xmath516 , @xmath518 and @xmath519 are independent . in addition , there exist @xmath520 and @xmath521 such that @xmath522 and @xmath523 which implies from and that @xmath524 and @xmath525 then , we define the stochastic decoders @xmath526 and @xmath527 where the randomness properties of the stochastic functions originate from not only  @xmath528 and  @xmath529 but also  @xmath516 and  @xmath518 . since @xmath530 and @xmath531 have the same distribution by , it follows from and that @xmath532 combining and , we obtain @xmath533 following similar procedures for deriving , we obtain the following inequality by using , and : @xmath534 replacing the decoding functions of the @xmath490-code with @xmath513 and @xmath514 and keeping the encoding functions unchanged , we conclude from and that the resultant code is an @xmath535-multicast code",
    ".    we are now ready to prove the strong converse theorem for the gaussian ic under strong interference .",
    "fix @xmath536 and @xmath537 such that @xmath538 as discussed at the beginning of section  [ sectionic ] , it follows from theorem  5.2 in @xcite that @xmath539 where the quantities @xmath480 and @xmath481 in @xmath540 are defined in and respectively . since @xmath541 for all non - negative real numbers @xmath542 and @xmath543 by definition , @xmath544 therefore , it suffices to prove @xmath545 to this end , fix a rate pair @xmath546 . by definition , there exists a sequence of @xmath547-codes such that @xmath548 and @xmath549 for each @xmath461 .",
    "it then following from lemma  [ lemmaic ] and that there exists a sequence of @xmath550-multicast codes such that @xmath551 for each @xmath461 .",
    "construct a subnetwork of the gaussian ic formed by deleting  @xmath460 as well as the links connecting to it . by inspection ,",
    "the resultant subnetwork is a two - source gaussian mac and the sequence of @xmath552-multicast codes for the gaussian ic induces a sequence of @xmath553-codes for the two - source gaussian mac .",
    "it then follows from and that @xmath554 is @xmath555-achievable for the two - source gaussian mac , which implies from theorem  [ thmmainresult ] , and that @xmath556 @xmath557 and @xmath558 similarly , if we repeat the above procedures for the other two - source gaussian mac resulting from deleting @xmath459 from the gaussian ic , we obtain @xmath559 @xmath560 and @xmath561 combining the bounds in , , , , the capacity region in , and the strong interference conditions in and , we have @xmath562 .",
    "consequently , the outer bound in   holds , and the theorem follows from and the inner bound stated in  .",
    "suppose an @xmath139-code is given for some @xmath170 , and let @xmath563 be the probability of decoding error given that @xmath95 is the message tuple transmitted by the sources .",
    "then by choosing @xmath95 one by one in an increasing order of @xmath564 , we can construct a set @xmath565 such that @xmath566 for all @xmath567 and @xmath568 this is essentially an expurgation argument .",
    "the bound in means that there exists an @xmath569-code such that holds .",
    "fix a nonempty @xmath79 .",
    "define @xmath570 for each @xmath571 such that @xmath572 since @xmath573 , it follows from and that there exists a @xmath97 such that @xmath574 or otherwise we would obtain the following chain of inequalities which would eventually contradict : @xmath575 which contradicts . due to , we can construct an @xmath576-code based on the @xmath569-code such that they have the same message sets , encoding functions and decoding function and differ in only the support set of the message tuple @xmath93 ( cf .  definition  [ defcode ] ) .",
    "in particular , the second statement in definition  [ defcode ] is satisfied because of the following reasons :    1 .   by construction , @xmath93 is uniform on @xmath577 .",
    "2 .   for all @xmath578",
    ", we have @xmath99 by .",
    "let @xmath579 .",
    "it remains to show that and hold for the @xmath175-code .",
    "recalling the definition of @xmath102 in , we obtain from that @xmath580 which implies from that @xmath241 consequently , follows from , and .",
    "it remains to prove . to this end , let @xmath581 denote the probability distribution induced on the gaussian mac by the @xmath175-code , where @xmath582 for all @xmath176 by definition  [ defcode ] . using and , we obtain @xmath583 for each @xmath176 .",
    "the authors are extremely grateful to yury polyanskiy for pointing out an error in an earlier version of the manuscript .",
    "they would also like to thank the associate editor prof .",
    "sandeep pradhan and the two anonymous reviewers for the useful comments which greatly improve the presentation of this paper .",
    "v.  y.  f. tan , `` asymptotic estimates in information theory with non - vanishing error probabilities , '' _ foundations and trends in communications and information theory _ , vol .  11 , no . 1 - 2 , pp . 1183 , 2014 .",
    "j.  scarlett , a.  martinez , and a.  guilln i fbregas , `` second - order rate region of constant - composition codes for the multiple - access channel , '' _ ieee trans .  on inf .",
    "theory _ , vol .",
    "61 , no .  1 ,",
    "pp . 157172 , 2015 .",
    "e.  molavianjazi and j.  n. laneman , `` a second - order achievable rate region for gaussian multi - access channels via a central limit theorem for functions , '' _ accepted to ieee trans .  on inf .",
    "theory _ , 2015 .",
    "r.  ahlswede , p.  gcs , and j.  krner , `` bounds on conditional probabilities with applications in multi - user communication , '' _ z. wahrscheinlichkeitstheorie verw .",
    "gebiete _ , vol .",
    "34 , no .  3 , pp . 157177 , 1976 .",
    "m.  raginsky and i.  sason , `` concentration of measure inequalities in information theory , communications , and coding , '' _ foundations and trends in communications and information theory _ , vol .",
    "10 , no . 1 - 2 , pp .",
    "1246 , 2013 ."
  ],
  "abstract_text": [
    "<S> we prove the strong converse for the @xmath0-source gaussian multiple access channel ( mac ) . </S>",
    "<S> in particular , we show that any rate tuple that can be supported by a sequence of codes with asymptotic average error probability less than one must lie in the cover - wyner capacity region . </S>",
    "<S> our proof consists of the following . </S>",
    "<S> first , we perform an expurgation step to convert any given sequence of codes with asymptotic average error probability less than one to codes with asymptotic maximal error probability less than one . </S>",
    "<S> second , we quantize the input alphabets with an appropriately chosen resolution . upon quantization , we apply the wringing technique ( by ahlswede ) on the quantized inputs to obtain further subcodes from the subcodes obtained in the expurgation step so that the resultant correlations among the symbols transmitted by the different sources vanish as the blocklength grows . </S>",
    "<S> finally , we derive upper bounds on achievable sum - rates of the subcodes in terms of the type - ii error of a binary hypothesis test . </S>",
    "<S> these upper bounds are then simplified through judicious choices of auxiliary output distributions . </S>",
    "<S> our strong converse result carries over to the gaussian interference channel under strong interference as long as the sum of the two asymptotic average error probabilities less than one .    </S>",
    "<S> gaussian multiple access channel , strong converse , binary hypothesis testing , expurgation , wringing technique </S>"
  ]
}