{
  "article_text": [
    "a huge amount of information in the form of news , photos , and tweets propagates through social media and networks . analyzing these information , can help us understand the users interests and their influence on each other . this kind of knowledge help us to understand how applications such as online advertising operate through incentivizing users @xcite .",
    "considering the temporal dynamics of the different topics discussed over the networks can immensely help marketers run more effective campaigns @xcite .",
    "therefore , there has been a large amount of research on the analysis and modeling of the content being shared over social networks to extract users preferences and the amount of their influence on each other .",
    "users of social networks often share information in one form or another .",
    "the content and temporal characteristics of what is shared as well as the relations among members are the three main sources that allow us to identify users interests over time and their influence characteristics .    modeling the content that is shared on a network over time",
    "has many challenges .",
    "this content covers a wide range of topics .",
    "each of these topics emerge at some point , become popular to some extent , influence some parts of the network , and eventually fade out .",
    "however , topics propagate with different rates . therefore , we need a flexible model that can not only represent the dynamics of topic popularity , but also model the diversity and diffusion rate of topics over time .",
    "there exist many dependent nonparametric models for the diversity and dynamics of the topics in a text stream .",
    "two nonparametric topic - cluster models were introduced in @xcite that cluster news based on their topics and infer the number of clusters , concurrently .",
    "these models have two main drawbacks .",
    "first , they only model a single source of information and hence do not consider the impact of different sources on each other .",
    "second , they only consider time as a covariate , while modeling the time of news events can enhance accuracy of the method in finding topics and also the influence of users on each other .",
    "the authors in @xcite have recently proposed a nonparametric point process that jointly models both topic and time of the events . however",
    ", this method assumes that the data are generated by a single source and hence is not applicable of analyzing events over a network .",
    "a rich literature exists on modeling information diffusion over networks @xcite .",
    "these methods model the time of events using a point process such as hawkes process @xcite but fall short of considering the content .",
    "some recent methods such as @xcite consider the content of the event but assume that the topics are already known .",
    "the authors in @xcite have recently proposed a method that jointly models the content and the time of events to infer the topic of the events and the influence network . however",
    ", this method assumes that the number of topics is bounded and known , and also the time and topics of events are assumed to be independent .",
    "these assumptions are not valid in social and information networks , where new topics arise over time , and the rate of diffusion of different content is heavily dependent on their topic @xcite . in this paper",
    ", we propose a nonparametric point process that jointly models the topic and time of events generated by the users of a network , infers the users influence on each other , and their dynamic interests over time in an online manner . in this model",
    ", each topic has a specific temporal dynamic which determines its diffusion rate through the network .",
    "the model is nonparametric and adapts the number of topics according to the complexity of data . in summary",
    ", we make the following contributions :    * we introduce a nonparametric multidimensional point process that can jointly model the time and topic of events for a set of dependent sources .",
    "this model permits topics to be shared among different sources using a hierarchical structure and is able to adapt its complexity according to the complexity of data . *",
    "our model provides a dynamic hierarchical clustering over the events , in three levels . in the first level ,",
    "the events are clustered based on the root event that has triggered them . in the second level , for each user , the root events of each cluster are grouped based on their topic and temporal dynamics .",
    "finally , in the third level , the topics of events are clustered irrespective of their user .",
    "this clustering allows us to better understand the interests of users and also the trending of topics over the network .",
    "* we propose an efficient online inference algorithm based on the collapsed sequential monte carlo that relies on marginalizing global latent variables to speed up the inference process .",
    "the inference algorithm is online , which makes it a suitable choice for real applications with millions of events .",
    "* we conduct several experiments on synthetic and real world datasets to evaluate the performance of our model . to this end",
    ", we collected a dataset consisting of 100,000 news articles published over 3 months by 100 news websites .",
    "the remainder of this paper is organized as follows . in section [ sec : settingsandbackground ] we briefly review the necessary background .",
    "details of the proposed method is discussed in section [ sec_proposed_model ] .",
    "the proposed inference algorithm is discussed in section [ sec : inference ] . to demonstrate the effectiveness of the proposed model , extensive experimental results",
    "are reported and analyzed in section [ sec : experiments ] .",
    "finally , section [ sec : conclusion ] concludes this paper and discusses paths for future research .",
    "we aim to infer the users interests and their influence on each other by analyzing the contents being propagated over the network . to this end",
    ", we use dependent nonparametric models and point processes to jointly model the occurring time and topics of the events . for the sake of self - sufficiency , in this section , we review some necessary background on non - exchangeable nonparametric models and temporal point processes .      a bayesian nonparametric model , is a bayesian model with an infinite - dimensional parameter space .",
    "dependent nonparametric models extend traditional models to define a probability measure over a set of dependent measures or clusterings usually indexed by a covariate @xcite .",
    "for example , recurrent chinese restaurant franchise process ( rcrfp ) is a dependent nonparametric model for clustering dependent groups of data @xcite .",
    "this process assumes that data is categorized into a set of disjoint groups and the data in each group is exchangeable .",
    "however , it is assumed that the groups are indexed by a covariate such as time and are dependent of each other . in this model",
    ", the number of clusters is unknown and hence rcrfp infers the number of clusters in each group and simultaneously clusters them in to a set of shared clusters to capture the latent structure of each group . for example , in our problem rcrfp can be used to cluster the set of events of different users . moreover , since the people are interested in a set of common topics , rcrfp shares the clusters among the users .",
    "although this model is a good match for clustering the events over a network , the exchangeability of events of each user is not a valid assumption in this problem . in section [ sec_proposed_model ]",
    ", we propose an extended version of rcrf that also models the dependency among the customers of a restaurant .",
    "temporal point processes are a set of powerful methods for modeling a list of time - stamped events @xmath0 .",
    "a temporal point process can be completely specified by distribution of its inter - event times @xcite : @xmath1 to specify a point process , it suffices to define @xmath2 , or equivalently @xmath3 , where @xmath4 is the history of events up to time @xmath5 . a more intuitive way to characterize",
    "a temporal point process is to define the conditional intensity function @xcite , which is defined as : @xmath6 where @xmath7 is the cdf of @xmath8 .",
    "different point processes can be determined by specifying appropriate intensity functions .",
    "for instance , in a homogeneous poisson process , the intensity is independent of the history , and is constant over time , i.e. @xmath9 @xcite . in order to model the events of multiple dependent sources ,",
    "multidimensional point processes can be utilized . in a multidimensional point process",
    ", the intensity of a dimension depends on the event history of all dimensions .",
    "each event can also be associated with some auxiliary information .",
    "this information is known as the mark of an event , and the associated point process is called a marked point process . for example , the topics of tweets propagated through a network can be considered as the marks of events .",
    "dependent nonparametric models are a set of flexible tools for modeling marks of events that can adapt their complexity according to data .",
    "these models can become a powerful tool for modeling temporal data when combined with point processes .",
    "moreover , these models can become more flexible if the complexity of intensity function can be adapted to the complexity of temporal data . in the next section ,",
    "we describe hnp3 , which is a nonparametric multidimensional point process .",
    "in order to model the propagation of content over a social network , we propose the hierarchical nonparametric point process ( hnp3 ) .",
    "hnp3 is a framework for modeling the event histories of a group of dependent sources , in which the topics are shared among the sources and the number of topics is unbounded .",
    "the main idea of hnp3 is to use a multidimensional point process to model the time of events and a hierarchical nonparametric model to model the marks of events .",
    "let @xmath10 denote the set of events observed until time @xmath5 , where the event @xmath11 is a triple @xmath12 which indicates that at time @xmath13 , user @xmath14 shares document @xmath15 .",
    "since the members of a network influence each other , the events in a network are mutually - exciting , i.e. each event triggers some new events in the network .",
    "hence , the events can be categorized into endogenous and exogenous events .",
    "endogenous events are the responses of users to the actions of their neighbors within the network , and exogenous events are user actions based on external drivers .",
    "let @xmath16 denote the triggering event for event @xmath17 .",
    "if the event is exogenous , then @xmath18 and otherwise it is the index of event that has triggered the @xmath17th event .",
    "each event @xmath11 also has a corresponding latent topic @xmath19 which is regarded as its mark .",
    "we assume that the topic of an endogenous event is the same as the topic of its triggering event .",
    "moreover , we assume that each user @xmath20 has a distribution @xmath21 over the topics at time @xmath5 that represents his interest over different topics , and he selects the topic of an exogenous event randomly from this distribution at time @xmath5 .",
    "since the users of a network are usually interested in a set of common topics , we assume that the favorite topics are shared among the users . let @xmath22 denote the set of unique topics over the network until time @xmath5 .",
    "each user @xmath20 is interested in a subset of these topics at any time @xmath5 which is denoted by @xmath23 , where @xmath24 denotes the number of topics that user @xmath20 is interested in , at time @xmath5 .",
    "each topic is a distribution over the words of the dictionary .",
    "every document with topic @xmath25 has the same distribution over the words as the distribution of @xmath25 .",
    "moreover , we assume that each topic has a specific temporal dynamic which shows the rate at which the events of that topic diffuse over the network .        as depicted in fig .",
    "[ fig : hierarchicalclustering ] , we propose a three - level nonparametric model for clustering events according to their topic .",
    "in the first level , the hawkes process clusters the events based on their triggering event .",
    "we use a variation of rcrfp to cluster the exogenous events of each user in the second level and share the topics among all users in the last level .    for clarity , we use the following notation for the remainder of this paper .",
    "@xmath26 denotes the set of events triggered by event @xmath27 generated by user @xmath20 until time @xmath5 with topic @xmath28 .",
    "let @xmath29 be the set of exogenous events until time @xmath5 .",
    "we use dot notation to represent union over the dotted variable , _",
    "e.g. _ , @xmath30 represent the events of user @xmath20 before time @xmath5 with any topic , and @xmath31 represent the events of all users except @xmath20 , before time @xmath5 , with topic @xmath32 .",
    "moreover , let @xmath33 be the index of the topic of the @xmath17th event among @xmath28s .",
    "that is , @xmath34 .",
    "we assume that the time at which user @xmath20 publishes documents follows a hawkes process with intensity function : @xmath35 where @xmath36 is the exogenous intensity which shows the tendency of user @xmath20 to generate new events .",
    "@xmath37 represents the number of events until time @xmath5 .",
    "@xmath38 is the amount of intensity of user @xmath20 at time @xmath5 that is caused by event @xmath27 .",
    "@xmath38 is defined as @xmath39 where @xmath40 is the influence of event @xmath27 s user on @xmath20 .",
    "@xmath41 is a kernel function which determines the diffusion rate of events with topic @xmath42 . in our case",
    ", we use the exponential kernel : @xmath43 as it was mentioned before , we use the topic of the document as the mark of events . using the aforementioned assumptions , if the event @xmath11 is exogenous and we know the triggering event @xmath16 , then the topic of @xmath11 is the same as the topic of @xmath44 , i.e. @xmath45 .",
    "otherwise , the user @xmath14 selects one of his previously used topics @xmath46 with probability @xmath47 or selects a new topic with probability @xmath48 : @xmath49 where @xmath50 is a parameter which shows the tendency of users to talk about new topics , and @xmath51 is the weighted number of exogenous events of user @xmath20 with topic @xmath52 , that is : @xmath53 where @xmath54 is a kernel which represents the decaying impact of events over time . in order to share the topics among the users , we use the same idea as rcrf and assume that users select their new topics from a common discrete distribution which shows the popularity of topics over the network : @xmath55 where @xmath56 shows the popularity of topic @xmath28 over the whole network , and is the weighted number of times users",
    "select a new topic @xmath28 from [ eqn : g_0 ] , that is : @xmath57 where @xmath58 indicates that the topic of the exogenous event @xmath59 is a new one and is sampled from [ eqn : g_0 ] .",
    "finally , we draw the content of a document from the distribution of its topic over the words of dictionary : @xmath60",
    "we use a two - step iterative algorithm to update our beliefs about the latent variables in an online manner .",
    "first , we use collapsed sequential monte carlo ( smc ) @xcite to estimate the posterior distribution of local latent variables by marginalizing out all global latent variables except @xmath61s . in the second step , we estimate @xmath61 using the learned distributions .",
    "each particle represent a hypothesis about the set of latent variables and its weight shows our confidence about it . by observing every new event , each particles",
    "is updated by appending a new @xmath62 to it , and updating their weights correspondingly . to this end , we need a proposal distribution @xmath63 to sample from . in order to minimize the variance of the weights , we use its posterior , @xcite i.e. @xmath64 .",
    "we assume a gamma prior over the betas . in order to compute the expected value of its posterior , we draw @xmath65 samples from the prior and find the mean as follows : @xmath66\\approx \\sum_{m=1}^mw_m\\beta^{(m)}\\end{aligned}\\ ] ] where @xmath67 is the weight of @xmath68th sample and is proportional to likelihood @xmath69 . in the next section",
    "we show the effectiveness of the proposed inference algorithm by several experiments on synthetic and real data .",
    "in this section , we empirically evaluate the performance of hnp3 by using both synthetic and real data .",
    "the experiments on synthetic data are used to evaluate the effectiveness of the inference algorithm introduced in section [ sec : inference ] . for the real data ,",
    "we investigate the performance of hnp3 model in inferring the hot topics over the network and their corresponding temporal dynamics .",
    "moreover , we evaluate its power to predict the time of next events and also inferring the influence network .          in order to evaluate the performance of the proposed inference algorithm",
    ", we generated a set of @xmath70 events by using the proposed generative model .",
    "we used the exponential kernel for all four topics with different @xmath71 parameters .",
    "figure [ fig : synthetic](a ) shows the performance of hnp3 in estimating the influence matrix @xmath72 , and exogenous intensity parameters @xmath36s .",
    "as it is evident in figure [ fig : synthetic](a ) , although in the first @xmath73 events , hnp3 does not make a significant improvement over the hawkes method , but after learning the topics and their corresponding kernel , the error considerably decreases .    since the ability of hnp3 in predicting the time of future events heavily depends on correctly estimating the topics kernel , we compared hnp3 and hawkes process based on the mean likelihood of time of next events , to confirm the efficiency of the proposed algorithm in learning the kernels .",
    "as it is depicted in figure [ fig : synthetic](b ) , the likelihood of the time of future events is consistently more than the hawkes process . in order to determine number of particles in the inference algorithm",
    ", we tested the algorithm with different number of particles .",
    "as it is depicted in figure [ fig : synthetic](c ) , the precision of the algorithm in estimating the parameters of the model does not depend on the number of particles too much . therefore , we used @xmath74 particles in all of our experiments .",
    "we also evaluated performance of the proposed method on a real dataset , gathered from eventregistry .",
    "for the real data , we first analyze the performance of hnp3 on modeling the content of events . to this end",
    ", we try to address the following questions : 1 ) how well hnp3 can capture different topics ? , and 2 ) how well hnp3 can capture the temporal dynamics of topics ? we also analyze the performance of hnp3 on predicting the time of next events and compare its performance with two well known state of the art methods .",
    "our real dataset corresponds to articles extracted from eventregistry , which is an online aggregator of news articles around the world .",
    "we have collected news articles containing each of 3 different tags ; _ fifa _ , _",
    "iran - sanctions _ , and _",
    "paris - attack _ from 2015/11/01 to 2016/01/13 .",
    "the collected data contains about @xmath75 news articles and @xmath76 different news sites .",
    "the sites are treated as nodes and the articles as events .",
    "we have preprocessed the data and removed some stop - words and irrelevant words and extracted the bag of words for each article .",
    "* + content analysis . * to show the performance of hnp3 on detecting different topics , we depicted the top frequent words in 3 main topics discovered by hnp3 .",
    "figures [ fig : fifa_cloud ] , [ fig : iran_cloud ] , and [ fig : paris_cloud ] shows the word cloud of top frequent words in 3 main topics learned by hnp3 . as it can be seen , hnp3 can detect meaningful clusters which are representative of true real topics and represent corresponding events .    to analyze the temporal dynamics of different topics , we depicted the intensity function of each topic against time , which is representative of their popularity over time .",
    "figures [ fig : fifa_intensity ] , [ fig : iran_intensity ] , and [ fig : paris_intensity ] represents the intensity function of 3 different detected topics over time .",
    "the results show some interesting patterns that confirm the good performance of hnp3 in capturing temporal dynamics of popularity for different topics . as it can be seen from fig .",
    "[ fig : paris_intensity ] , the popularity of _ paris - attack _ topic rises suddenly somewhere in time .",
    "this is reasonable , since we collected data two weeks before the _",
    "paris - attack _ event .",
    "therefore , the intensity of events is zero before the event , and suddenly rises after a large number of events are generated after it happens .",
    "since the _ fifa _ topic is discussed all the time , its intensity is also evenly distributed over the time axis .",
    "iran - sanctions _ topic also has a periodical popularity pattern . since the negotiations about iran sanctions took place periodically , it is desirable that its popularity rises just after these negotiations and then fades out .",
    "the above results indicate that the hnp3 performance is acceptable on detecting different topics , capturing their triggering kernels , and their temporal dynamics over time .    * prediction .",
    "* we also compared the performance of hnp3 on predicting the time of next events with the hawkes and dirichlet - hawkes(dh ) models . to this end , we trained each model with some events , and computed the time likelihood of next events for each model .",
    "[ fig : real_time_likelihood ] represents the likelihood of next 100 events for hnp3 , hawkes , and dh models . as it is shown in fig .",
    "[ fig : real_time_likelihood ] , hnp3 performs better than the hawkes and dh models .",
    "moreover , it can be seen that the hnp3 and dh models which utilize the content of events , perform better than the hawkes model which ignores the content .",
    "we also observe that the hnp3 model which considers the network effect and the influence of friends , performs better than the dh model which do not consider the influence of users on each other .",
    "in this paper , we introduced a framework for modeling dependent groups of temporal events with complex longitudinal dependencies .",
    "this framework is able to jointly model the time and marks of events and adapt itself to the complexity of data .",
    "the framework also provides a hierarchical clustering of the events by utilizing the dependency among content and time of events .",
    "this clustering may have many applications in different areas .",
    "for instance , we used the framework for modeling the content diffusion over social media and the clustering allowed us to infer the source of events and also the hot topics over the network .",
    "moreover , hnp3 uses multidimensional point processes for modeling time of events .",
    "however , the intensity function of this process is a mixture of intensities and its complexity grows with the number of data .",
    "in addition , hnp3 utilizes dependent nonparametric methods for modeling marks of events .",
    "these capabilities allow hnp3 to adapt its temporal and topical complexity according to the complexity of data , which makes it a suitable candidate for real world scenarios .    since diffusion of contents over networks has gained a lot of attention in recent years , we applied hnp3 to this real application and designed an online inference algorithm based on smc , which can efficiently infer parameters of the model .",
    "experiments on synthetic data showed the efficiency of our inference algorithm .",
    "the experimental results on real data confirmed the superior performance of the proposed method compared to other recent methods in finding different topics and their diffusion rates .",
    "there are many lines to extend this study .",
    "for example , we used hawkes process for modeling time of events .",
    "one plan to extend this method is to use more complex point processes that are analogous to more complex clustering algorithms such as hierarchical dd - crp @xcite ."
  ],
  "abstract_text": [
    "<S> this paper introduces a novel framework for modeling temporal events with complex longitudinal dependency that are generated by dependent sources . </S>",
    "<S> this framework takes advantage of multidimensional point processes for modeling time of events . </S>",
    "<S> the intensity function of the proposed process is a mixture of intensities , and its complexity grows with the complexity of temporal patterns of data . </S>",
    "<S> moreover , it utilizes a hierarchical dependent nonparametric approach to model marks of events . </S>",
    "<S> these capabilities allow the proposed model to adapt its temporal and topical complexity according to the complexity of data , which makes it a suitable candidate for real world scenarios . </S>",
    "<S> an online inference algorithm is also proposed that makes the framework applicable to a vast range of applications . </S>",
    "<S> the framework is applied to a real world application , modeling the diffusion of contents over networks . </S>",
    "<S> extensive experiments reveal the effectiveness of the proposed framework in comparison with state - of - the - art methods . </S>"
  ]
}