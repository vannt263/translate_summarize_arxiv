{
  "article_text": [
    "cross - matching two two - dimensional points lists is a crucial step in astrometry and source identification .",
    "the tasks involves finding the appropriate geometrical transformation that transforms one list into the reference frame of the other , followed by finding the best matching point - pairs .",
    "one of the lists usually contains the pixel coordinates of sources in an astronomical image ( e.g.  point - like sources , such as stars ) , while the other list can be either a reference catalog with celestial coordinates , or it can also consist of pixel coordinates that originate from a different source of observation ( another image ) . throughout this paper",
    "we denote the reference ( list ) as @xmath1 , the image ( list ) as @xmath2 , and the function that transforms the reference to the image as @xmath3 .",
    "the difficulty of the problem is that in order to find matching pairs , one needs to know the transformation , and vica versa : to derive the transformation , one needs point - pairs .",
    "furthermore , the lists may not fully overlap in space , and may have only a small fraction of sources in common .    by making simple assumptions on the properties of @xmath3 ,",
    "however , the problem can be tackled .",
    "a very specific case is when there is only a simple translation between the lists , and one can use cross - correlation techniques ( see * ? ? ?",
    "* ) to find the transformation .",
    "we note , that the a method proposed by @xcite uses the whole image information to derive a transformation ( translation and magnification ) .",
    "a more general assumption , typical to astronomical applications , is a that @xmath4 is a similarity transformation ( rotation , magnification , inversion , without shear ) , i.e.  @xmath5 , where @xmath6 is a ( non - zero ) scalar @xmath7 times the orthogonal matrix , @xmath8 is an arbitrary translation , and @xmath9 is the spatial vector of points . exploiting that geometrical patterns remain similar after the transformation",
    ", more general algorithms have been developed that are based on pattern matching @xcite .",
    "the idea is that the initial transformation is found by the aid of a specific set of patterns that are generated from a subset of the points on both @xmath1and @xmath2 .",
    "for example , the subset can be that of the brightest sources , and the patterns can be triangles . with the knowledge of this initial transformation , more points can be cross - matched , and the transformation between the lists can be iteratively refined .",
    "some of these methods are implemented as an task in `` @xcite .",
    "the above pattern matching methods perform well as long as the dominant term in the transformation is linear , such as for astrometry of narrow field - of - view ( fov ) images , and as long as the number of sources is small ( because of the large number of patterns that can be generated ",
    "see later ) . in the past decade of astronomy , with the development of large format ccd cameras or mosaic imagers , many wide - field surveys appeared , such as those looking for transient events ( e.g.  rotse  @xcite ) , transiting planets ( e.g.  kelt  @xcite , tres ",
    "@xcite , hatnet ",
    "@xcite , see @xcite for further references ) , or all - sky variability ( e.g.  asas  @xcite ) .",
    "there are non - negligible , higher order distortion terms in the astrometric solution that are due to , for instance , the projection of celestial to pixel coordinates and the properties of the fast focal ratio optical systems .",
    "furthermore , these images may contain @xmath10 sources , and pattern matching is non - trivial .",
    "these surveys necessitated a further generalization of the algorithm , which we present in this paper .",
    "to be more specific , we were motivated by the astrometric requirements of the hungarian - made automated telescope network ( hatnet ) .",
    "each hat telescope of the network consists of a @xmath11 , @xmath12 telephoto lens and a @xmath13 ccd yielding an @xmath14 fov . in our experience , we need at least 4th order polynomial functions of the pixel coordinates in order to properly describe the distortion of the lens . with a typical exposure time of 5 minutes in i - band , in a moderately dense field ( @xmath15 )",
    "there are 30000 stars brighter than i=13 for which better than 10% photometry can be achieved .",
    "if we consider all 3-@xmath16 detections , we have to deal with the identification of @xmath17100,000 sources .",
    "the algorithm presented in this paper is based on , and is a generalization of the above pattern matching algorithms .",
    "it is very fast , and works robustly for wide - field imaging with minimal assumptions .",
    "namely , we assume that : i ) the distortions are non - negligible , but small compared to the linear term , ii ) there exists a smooth transformation between the reference and image points , iii ) the point lists have a considerable number of sources in common , and iv ) the transformation is locally invertible .",
    "the paper is presented as follows .",
    "first we describe symmetrical point matching in before we go on to the discussion of finding the transformation ( ) . the software implementation and its performance on a large and inhomogeneous dataset is demonstrated in .",
    "finally , we draw conclusions in .",
    "first , let us assume that @xmath3  is known .",
    "to find point - pairs between @xmath1  and @xmath2 one should first transform the reference points to the reference frame of the .",
    "now it is possible to perform a simple symmetric point matching between @xmath18and @xmath2 . one point ( @xmath19 ) from the first and one point ( @xmath20 ) from the second set are treated as a pair if the closest point to @xmath21 is @xmath22 _ and _ the closest point to @xmath22 is @xmath21 .",
    "this requirement is symmetric by definition and excludes such cases when e.g.  the closest point to @xmath21 is @xmath22 , but there exists an @xmath23 that is even closer to @xmath22 , etc .    in one dimension , finding the point of a given list nearest to a specific point ( @xmath24 )",
    "can be implemented as a binary search .",
    "let us assume that the point list with @xmath25 points is ordered in ascending order .",
    "this has to be done only once , at the beginning , and using the quicksort algorithm , for example , the required time scales on average as @xmath26 .",
    "then @xmath24 is compared to the median of the list : if it is less than the median , the search can be continued recursively in the first @xmath27 points , if it is greater than the median , the second @xmath27 half is used . at the end",
    "only one comparison is needed to find out whether @xmath24 is closer to its left or right neighbor , so in total @xmath28 comparisons are needed , which is an @xmath29 function of @xmath25 .",
    "thus , the total time including the initial sorting also goes as @xmath26 .",
    "as regards a two dimensional list , let us assume again , that the points are ordered in ascending order by their @xmath24 coordinates ( initial sorting @xmath30 ) , and they are spread uniformly in a square of unit area .",
    "finding the nearest point in @xmath24 coordinate also requires @xmath31 comparisons , however , the point found presumably will not be the nearest in euclidean distance .",
    "the expectation value of the distance between two points is @xmath32 , and thus we have to compare points within a strip with this width and unity height , meaning @xmath33 comparisons .",
    "therefore , the total time required by a symmetric point matching between two catalogs in two dimensions requires @xmath34 time .",
    "we note that finding the closest point within a given set of points is also known as nearest neighbor problem ( for a summary see * ? ? ? * and references therein ) .",
    "it is possible to reduce the computation time in 2 dimensions to @xmath26 by the aid of voronoi diagrams and voronoi cells , but we have not implemented such an algorithm in our matching codes .",
    "let us go back to finding the transformation between @xmath1  and @xmath2 .",
    "the first , and most crucial step of the algorithm is to find an initial `` guess '' @xmath35  for the transformation based on a variant of triangle matching .",
    "using @xmath35 , @xmath1  is transformed to @xmath2 , symmetric point - matching is done , and the paired coordinates are used to further refine the transformation ( leading to @xmath36  in iteration @xmath37 ) , and increase the number of matched points iteratively . a major part of this paper is devoted to finding the initial transformation .      it was proposed earlier by @xcite and @xcite , and recently by others ( see * ? ? ?",
    "* ) to use triangle matching for the initial `` guess '' of the transformation .",
    "the total number of triangles that can be formed using @xmath25 points is @xmath38 , an @xmath39 function of @xmath25 . as this can be an overwhelming number",
    ", one can resort to using a subset of the points for the vertices of the triangles to be generated .",
    "one can also limit the parameters of the triangles , such as exclude elongated or large ( small ) triangles .",
    "as triangles are uniquely defined by three parameters , for example the length of the three sides , these parameters ( or their appropriate combinations ) naturally span a 3-dimensional triangle space . because our assumption is that @xmath3  is dominated by the linear term , to first order approximation there is a single scalar magnification between @xmath1  and @xmath2  ( besides the rotation , chirality and translation ) .",
    "it is possible to reduce the triangle space to a normalized , two - dimensional triangle space ( @xmath40 ) , whereby the original size information is lost .",
    "similar triangles ( with or without taking into account a possible flip ) can be represented by the same points in this space , alleviating triangle matching between @xmath1and @xmath2 .",
    "there are multiple ways of deriving normalized triangle spaces .",
    "one can define a `` mixed '' normalized triangle space @xmath41 , where the coordinates are insensitive to inversion between the original coordinate lists , i.e.  all similar triangles are represented by the same point irrespective of their chirality @xcite : @xmath42 where @xmath43 , @xmath44 and @xmath45 are the sides of the triangle in descending order .",
    "triangles in this space are shown on the left panel of fig .",
    "[ fig : trichir ] .",
    "coordinates in the mixed triangle space are continuous functions of the sides ( and therefore of the spatial coordinates of the vertices of the original triangle ) but the orientation information is lost . because we assumed that @xmath3  is smooth and bijective ,",
    "no local inversions and flips can occur .",
    "in other words , @xmath1  and @xmath2  are either flipped or not with respect to each other , but chirality does not have a spatial dependence , and there are no `` local spots '' that are mirrored .",
    "therefore , using mixed triangle space coordinates can yield false triangle matchings that can lead to an inaccurate initial transformation , or the match may even fail .",
    "thus , for large sets of points and triangles it is more reliable to fix the orientation of the transformation .",
    "for example , first assume the coordinates are not flipped , perform a triangle match , and if this match is unsatisfactory , then repeat the fit with flipped triangles .",
    "this leads to the definition of an alternative , `` chiral '' triangle space : @xmath46 where @xmath43 , @xmath47 and @xmath48 are the sides in counter - clockwise order and @xmath43 is the longest side . in this space",
    "similar triangles with different orientations have different coordinates .",
    "the shortcoming of @xmath49  is that it is not continuous : a small perturbation of an isosceles triangle can result in a new coordinate that is at the upper rightmost edge of the triangle space .    in the following ,",
    "we show that it is possible to define a parametrization that is both continuous and preserves chirality .",
    "flip the chiral triangle space in the right panel of fig .",
    "[ fig : trichir ] along the @xmath50 line .",
    "this transformation moves the equilateral triangle into the origin . following this ,",
    "apply radial magnification of the whole space to move the @xmath50 line to the @xmath51 arc ( the magnification factor is not constant : @xmath52 along the direction of @xmath24 and @xmath53-axis and @xmath54 along the @xmath55 line ) .",
    "finally , apply an azimuthal slew by a factor of @xmath56 to identify the @xmath57 and @xmath58 edges of the space .",
    "to be more specific , let us denote the sides as in @xmath49 : @xmath43 , @xmath47 and @xmath48 in counter - clockwise order where @xmath43 is the longest , and define @xmath59 using these values , it is easy to prove that by using the definitions of the following variables : @xmath60 one can define the triangle space coordinates as : @xmath61    the above defined @xmath62  continuous triangle space has many advantages .",
    "it is a continuous function of the sides for all non - singular triangles , and also preserves chirality information .",
    "furthermore , it spans a larger area , and misidentification of triangles ( that may be very densely packed ) is decreased . some triangles in this space are shown in fig .",
    "[ fig : tricont ] .      as it was mentioned before",
    ", the total number of triangles that can be formed from @xmath25 points is @xmath63 .",
    "wide - field images typically contain @xmath64 points or more , and the total number of triangles that can be generated  a complete triangle list  is unpractical for the following reasons .",
    "first , storing and handling such a large number of triangles with typical computers is inconvenient . to give an example , a full triangulation of 10,000 points yields @xmath65 triangles .",
    "second , this complete triangle list includes many triangles that are not optimal to use .",
    "for example large triangles can be significantly distorted in @xmath2  with respect to @xmath1 , and thus are represented by substantially different coordinates in the triangle space .",
    "the size of optimal triangles is governed by two factors : the distortion of large triangles , and the uncertainty of triangle parameters for small triangles that are comparable in size to the astrometric errors of the vertices .    to make an estimate of the optimal size for triangles ,",
    "let us denote the characteristic size of the image by @xmath66 , the astrometric error by @xmath67 , and the size of a selected triangle as @xmath68 .",
    "for the sake of simplicity , let us ignore the distortion effects of a complex optical assembly , and estimate the distortion factor @xmath69 in a wide field imager as the difference between the orthographic and gnomonic projections ( see * ? ? ?",
    "* ) : @xmath70 where @xmath71 is the radial distance as measured from the center of the field . for the hatnet frames ( @xmath72 to the corners )",
    "this estimate yields @xmath73 .",
    "the distortion effects yield an error of @xmath74 in the triangle space ",
    "the bigger the triangle , the more significant the distortion .",
    "for the same triangle , astrometric errors cause an uncertainty of @xmath75 in the triangle space that decreases with increasing @xmath68 . making the two errors equal ,",
    "@xmath76 an optimal triangle size can be estimated by @xmath77 in our case @xmath78 pixels ( or @xmath79 ) , @xmath80 and the centroid uncertainty for an @xmath81 star is @xmath82 , so the optimal size of the triangles is @xmath83 pixels .",
    "third , dealing with many triangles may result in a triangle space that is over - saturated by the large number of points , and may yield unexpected matchings of triangles . in all definitions of the previous subsection ,",
    "the area of the triangle space is approximately unity . having triangles with an error of @xmath16 in triangle space and assuming them to have a uniform distribution , allowing a @xmath84 spacing between them , and assuming @xmath85 , the number of triangles is delimited to : @xmath86 in our case ( see values of @xmath66 , @xmath69 and @xmath67 above ) the former equation yields @xmath87 triangles .",
    "note that this is 5 orders of magnitude smaller than a complete triangulation ( @xmath88 ) .",
    "delaunay triangulation ( see * ? ? ?",
    "* ) is a fast and robust way of generating a triangle mesh on a point - set .",
    "the delaunay triangles are disjoint triangles where the circumcircle of any triangle contains no other points from any other triangle .",
    "this is also equivalent to the most efficient exclusion of distorted triangles in a local triangulation . for a visual example of a delaunay triangulation of a random set of points , see the left panel of fig .",
    "[ fig : delaunay ] .    following euler s theorem ( also known as the polyhedron formula )",
    ", one can calculate the number of triangles in a delaunay triangulation of @xmath25 points : @xmath89 where @xmath90 is the number of edges on the convex hull of the point set . for large values of @xmath25",
    ", @xmath91 can be estimated as @xmath92 , as @xmath93 is negligible .",
    "therefore , if we select a subset of points ( from @xmath1  or @xmath2 ) where neighboring ones have a distance of @xmath94 , we get a delaunay triangulation with approximately @xmath95 triangles .",
    "the @xmath66 , @xmath67 and @xmath69 values for hat images correspond to @xmath96 triangles , i.e.  3000 points . in our experience , this yields very fast matching , but it is not robust enough for general use , because of the following reasons .",
    "delaunay triangulation is very sensitive for removing a point from the star list . according to the polyhedron formula , on the average",
    ", each point has 6 neighboring points and belongs to 6 triangles . because of observational effects or unexpected events",
    ", the number of points fluctuates in the list . to mention a few examples , it is customary to build up @xmath2  from the brightest stars in an image , but stars may get saturated or fall on bad columns , and thus disappear from the list . star detection algorithms may find sources depending on the changing full - width at half maximum ( fwhm ) of the frames .",
    "transients , variable stars or minor planets can lead to additional sources on occasions .",
    "in general , if one point is removed , 6 delaunay triangles are destroyed and 4 new ones are formed that are totally disjoint from the 6 original ones ( and therefore they are represented by substantially different points in the triangle space ) . removing one third of the generating points",
    "might completely change the triangulation .",
    "second , and more important , there is no guarantee that the spatial _ density _ of points in @xmath1  and @xmath2  is similar .",
    "for example , the reference catalog is retrieved for stars with different magnitude limits than those found on the image . if the number of points in common in @xmath1  and @xmath2  is only a small fraction of the total number of points , the triangulation on the reference and image has no common triangles .",
    "third , the number of the triangles with delaunay triangulation ( @xmath97 ) is definitely smaller than @xmath98 ; i.e.  the triangle space could support more triangles without much confusion .",
    "therefore , it is beneficial to extend the delaunay triangulation . a natural way of extension can be made as follows .",
    "define a level @xmath99 and for any given point ( @xmath100 ) select all points from the point set of @xmath25 points that can be connected to @xmath100 via maximum @xmath99 edges of the delaunay triangulation . following this",
    ", one can generate the _ full _ triangulation of this set and append the new triangles to the whole triangle set .",
    "this procedure can be repeated for all points in the point set at fixed @xmath99 . for self - consistence",
    ", the @xmath101 case is defined as the delaunay triangulation itself .",
    "if all points have 6 neighbors , the number of `` extended '' triangles _ per data point _ is : @xmath102 for @xmath103 , i.e.  this extension introduces @xmath104 new triangles . because some of the extended triangles are repetitions of other triangles from the original delaunay triangulation and from the extensions of another points",
    ", the final dependence only goes as @xmath105 .",
    "we note that our software implementation is slightly different , and the expansion requires @xmath106 time and automatically results in a triangle set where each triangle is unique .",
    "to give an example , for @xmath107 points the delaunay triangulation gives @xmath108 triangles , the @xmath109 extended triangulation gives @xmath110 triangles , @xmath111 some @xmath112 triangles , @xmath113 @xmath114 and @xmath115 @xmath116 triangles , respectively . the extended triangulation is not only advantageous because of more triangles , and better chance for matching , but also , there is a bigger variety in size that enhances matching if the input and reference lists have different spatial density .",
    "if the triangle sets for both the reference and the input list are known , the triangles can be matched in the normalized triangle space ( where they are represented by two dimensional points ) using the symmetric point matching as described in .    in the next step",
    "we create a @xmath117 `` vote '' matrix @xmath118 , where @xmath119 and @xmath120 are the number of points in the reference and input lists that were used to generate the triangulations , respectively .",
    "the elements of this matrix have an initial value of 0 .",
    "each matched triangle corresponds to 3 points in the reference list ( identified by @xmath121 , @xmath122 , @xmath123 ) and 3 points in the input list ( @xmath124 , @xmath125 and @xmath126 ) . knowing these indices , the matrix elements @xmath127 , @xmath128 and @xmath129 are incremented .",
    "the magnitude of this increment ( the _ vote _ ) can depend on the distances of the matching triangles in the triangle space : the closer they are , the higher votes these points get . in our implementation , if @xmath130 triangles are matched in total , the closest pair gets @xmath130 votes , the second closest pair gets @xmath131 votes , and so on .",
    "having built up the vote matrix , we select the greatest elements of this matrix , and the appropriate points referring to these row and column indices are considered as matched sources .",
    "we note that not all of the positive matrix elements are selected , because elements with smaller votes are likely to be due to misidentifications .",
    "we found that in practice the upper 40% of the matrix elements yield a robust match .",
    "if an initial set of the possible point - pairs are known from triangle - matching , one can fit a smooth function ( e.g.  a polynomial ) that transforms the reference set to the input points .",
    "our assumption was that the dominant term in our transformation is the similarity transformation , which implies that the homogeneous linear part of it should be _ almost _ almost a unitarity operator . , where @xmath132 is the adjoint of @xmath6 and @xmath133 is the identity , i.e.  @xmath6 is an orthogonal transformation with possible inversion and magnification .",
    "] after the transformation is determined , it is useful to measure how much we diverge from this assumption .",
    "as mentioned earlier ( ) , similarity transformations can be written as @xmath134 where @xmath135 , and the @xmath136 matrix components are the sine and cosine of a given rotational angle , i.e.  @xmath137 and @xmath138 .",
    "if we separate the homogeneous linear part of the transformation , as described by a matrix similar to that in eq .",
    "[ eq : lintr2 ] , it will be a combination of rotation and dilation with possible inversion if @xmath139 and @xmath140 .",
    "we can define the unitarity of a matrix as : @xmath141 where the @xmath142 indicates the definition for regular and inverting transformations , respectively . for a combination of rotation and dilation ,",
    "@xmath143 is zero , for a distorted transformation @xmath144 .",
    "the @xmath143 unitarity gives a good measure of how well the initial transformation was determined .",
    "it happens occasionally that the transformation is erroneous , and in our experience , in these cases @xmath143 is not just larger than the expectational value of @xmath69 , but it is @xmath145 .",
    "this enables fine - tuning of the algorithm , such as changing chirality of the triangle space , or adding further iterations till satisfactory @xmath143 is reached .      in practice , matching points between the @xmath1  reference and @xmath2image goes as the following :    1 .",
    "generate two triangle sets @xmath146 and @xmath147 on @xmath1  and @xmath2 , respectively : 1 .",
    "in the first iteration , generate only delaunay triangles .",
    "2 .   later , if necessary , extended triangulation can be generated with increasing levels of @xmath99 .",
    "2 .   match these two triangle sets in the triangle space using symmetric point matching .",
    "3 .   select some possible point - pairs using a vote - algorithm ( yielding @xmath148 pairs ) .",
    "4 .   derive the initial smooth transformation @xmath35   using a least - squares fit",
    "check the unitarity of @xmath35 .",
    "2 .   if it is greater than a given threshold ( @xmath149 ) , increase @xmath99 and go to step 1/b",
    ". if the unitarity is less than this threshold , proceed to step 5 .",
    "if we reached the maximal allowed @xmath99 , try the procedure with triangles that are flipped with respect to each other between the image and reference , i.e.  switch chirality of the @xmath62  triangle space .",
    "transform @xmath1  using this initial transformation to the reference frame of the image ( @xmath150 ) .",
    "perform a symmetric point matching between @xmath18  and @xmath2  ( yielding @xmath151 pairs ) .",
    "refine the transformation based on the greater number of pairs , yielding transformation @xmath36 , where @xmath37 is the iteration number .",
    "if necessary , repeat points 5 , 6 and 7 iteratively , increase the number of matched points , and refine the transformation .    for most astrometric transformations and distortions",
    "it holds that locally they can be approximated with a similarity transformation . at a reasonable density of points on @xmath2  and @xmath2 ,",
    "the triangles generated by a ( possibly extended ) delaunay triangulation are small enough not to be affected by the distortions . the crucial step is the initial triangle matching , and due to the use of local triangles , it proves to be robust procedure .",
    "it should be emphasized that @xmath36can be any smooth transformation , for example an affine transformation with small shear , or polynomial transformation of any reasonable order .",
    "the optimal value of the order depends on the magnitude of the distortion .",
    "the detailed description of fitting such models and functions can be found in various textbooks ( see e.g.  chapter 15 . in * ? ? ?",
    "it is noteworthy that in step 7 one can perform a weighted fit with possible iterative rejection of n-@xmath16 outlier points .",
    "the coordinate matching and coordinate transforming algorithms are implemented in two stand - alone binary programs written in ansi c. the program named `` matches point sets , including triangle space generation , triangle matching , symmetric point matching and polynomial fitting , that is steps 1 through 4 in . the other program , `` , transforms coordinate lists using the transformation coefficients that are output by `` .",
    "the `` code is also capable of fitting a general polynomial transformation between point - pair lists if they are paired or matched manually or by an external software .",
    "we should note that in the case of degeneracy , e.g.  when all points are on a perfect lattice , the match will fail .",
    "both programs are part of the /hatpipe package that is under development for the massive data reduction of the hatnet data - flow .",
    "they can be easily embedded into unix environments , as both of them parses wide - range of command line arguments for defining the structure of the input data and fine - tuning the algorithm .",
    "the programs are also capable of redirecting their input and/or output to standard streams .    by combining `` and ``",
    ", one can easily derive the world coordinate system ( wcs ) information for a fits data file .",
    "output of wcs keywords is now fully implemented in `` , following the conventions of the package `` ( see * ? ? ?",
    "such information is very useful for manual analysis with well - known fits viewers ( e.g.  `` , see * ? ? ?",
    "for a more detailed description of wcs see @xcite and on the representation of distortions see @xcite .",
    "the package containing the programs `` and `` and other related software are accessible after registration from the web address ` http://www.hatnet.hu/software ` .",
    "we used `` and `` to perform astrometry and star identification on a large set of images taken by the hat network of telescopes @xcite .",
    "the results presented in this paper are based on observations originating from the following hatnet telescopes : hat-5 , hat-6 and hat-7 located at the fred lawrence whipple observatory ( flwo ) , arizona , plus hat-8 and hat-9 at the smithsonian submillimeter array roof ( sma ) atop mauna kea , hawaii .",
    "to recall , these telescopes have an identical setup : @xmath11 , @xmath12 telephoto lens and a @xmath13 ccd yielding an @xmath14 fov . in order to test the method on different instruments",
    ", we also performed astrometry on data taken by the tophat ( flwo ) photometry follow - up instrument .",
    "tophat is a 0.26 m diameter , f/5 ritchey - crtien design with a baker wide - field corrector , aided by a @xmath13 marconi chip , yielding 1.3  fov .",
    "the steps of the astrometry and identification were the following .",
    "first , for all observed fields , reference star lists were generated using the 2mass catalog ( see * ? ? ?",
    "* ) as reference .",
    "these reference lists include the source identifiers , the original celestial coordinates ( ra , dec ) , an estimated i - band magnitude and the @xmath152 projected coordinates of the stars .",
    "we used arc projection ( see * ? ? ?",
    "* ) centered at the nominal center of the given field , and scaling of the projection was unity in the manner that a star located at 1 degree distance from the center of the given celestial field has a unit distance in the @xmath152 plane from the origin in the reference list . the fov of the reference lists were a bit wider than the nominal fov of the hat telescopes so as to ensure a full overlap between the two lists in spite of the small uncertainties in the positioning of the telescopes .",
    "second , an input star list was generated for each image , using our star detection algorithm ``  ( also part of /hatpipe ) that detects and fits star - like objects above a given s / n threshold .",
    "this detection yields a set of input lists that include the pixel coordinates , @xmath153 of the stars and other quantities ( including the flux , fwhm and the shape parameters ) .",
    "third , for each image , the input star list and the relevant reference star list was matched using the program `` .",
    "the match was performed between the projected reference coordinates , @xmath152 , and the detected pixel coordinates , @xmath153 .",
    "the program outputs two files : the list of the matched lines ( this is the `` match '' file ) and a small file that includes the fitted polynomial transformation parameters and some statistical data ( this is the `` transformation '' file ) .",
    "it should be emphasized that the match was not done directly using the original celestial coordinates , as they exhibit an unwanted curvature in the field .",
    "finally , the reference star list @xmath152 was transformed by the program `` into the system of the image @xmath153 using the `` transformation '' file .",
    "the transformed list shows where each star with a given identifier would fall on the image .",
    "the transformation can be also used to calculate the wcs information for the given image .",
    "we note that the crucial part of the process is the third step",
    ". this can be fine - tuned by many parameters , one of the most important being the polynomial order . for a small fov ( less than one degree ) and small distortions ,",
    "linear or second order polynomials yield good result . for hat images",
    ", we had to increase the order up to 6 to achieve the best results .",
    "[ fig : distvect ] exhibits two vector plots that show the difference between the transformed reference coordinates and the detected star coordinates using a second and a fourth - order polynomial transformation for a typical hat image . in the first case , using a second - order fit , definite radial structures remain , and the stars located at the corners of the image are not even matched due to the large distortions in the optics . using a fourth - order fit , however , all segments of the image are matched and the residuals are also smaller .",
    "these small residuals can be better visualized if only the difference between one of the coordinates is shown in a gradient plot : fig .",
    "[ fig : distshift ] illustrates the difference between the @xmath154 coordinates for the same image using a fourth- and sixth - order polynomial fit .",
    "while there is a definite residual structure in the fourth - order fit , it disappears using the sixth - order polynomial transformation .",
    "as regards statistics , we performed the astrometry and source identification for 243,447 hat images that had been acquired between the beginning of 2003 and june 2006 .",
    "the wide - field telescopes observed 52 individual and almost non - overlapping fields between @xmath155 and @xmath156 galactic latitudes .",
    "we initiated the processing with the following parameters .",
    "for the triangulation , the 3000 brightest sources were used from both the reference catalog and the detected stars .",
    "the critical unitarity was set to @xmath157 , therefore if the fitted initial transformation had an unitarity larger than this value , the level of the triangulation expansion was increased .",
    "the final transformation was determined using a weighted sixth - order polynomial fit .",
    "because the astrometric errors of brighter stars are smaller , we weighted data - points based on their magnitude during the fit .",
    "finally , the maximal distance of matches was set to one pixel to reject false identifications .",
    "astrometry and cross - identification of sources was successful for 238,353 images .",
    "the remaining 5094 images were analyzed manually , and we found that only 13 of them were good enough to expect astrometry to succeed ; all the other ones were cloudy or had shown various other errors .",
    "astrometry on these 13 images also succeeded by decreasing the number of stars for triangulation to 2000 .",
    "it means that a completely automatic run yielded 99.995% success rate , and the other images were also matched by applying small changes to the fine - tune parameters .    in order to test the algorithm with a different instrument",
    ", we also performed astrometry on 22,936 tophat images taken in 2005 .",
    "the only difference in the procedure was that the polynomial transformation was only of 2nd order .",
    "the success ratio was 93% , but 90% of the frames where astrometry failed were cloudy with virtually no stars .",
    "astrometry also failed on very short exposure ( 10sec ) v - band frames .",
    "fine - tuning the parameters ( number of triangles , input lists ) resolved most of these cases .",
    "the following statistics was done on the wide - field hat frames . the median value of the number of matched sources relative to the number of stars in the reference or the input list was @xmath158 ( median deviation ) .",
    "the average value of the cpu usage was @xmath159 seconds per frame on a 64-bit amd opteron machine running at 2ghz .",
    "astrometry was successful on 96.78% of the images using delaunay - triangulation without extended triangles ( cpu : 0.73sec ) , while 0.49% of the frames were processed at level @xmath160 extended triangulation ( cpu : 1.79 sec ) , 0.06% at @xmath161 ( cpu : 2.22 sec ) , 33 images at @xmath162 ( cpu : 3.67 sec ) and 1334 + 5094 images at @xmath163 extended triangulation ( cpu : 5.20 sec ) . here",
    "5094 refers to those images were astrometry failed even at @xmath115 , mostly because of bad data quality ( see before ) .",
    "the reason for the delaunay triangulation being successful for 96% of the wide - field hat frames _ without _ extended triangulation is because the hat instruments perform homogeneous data acquisition , and are very well characterized ( zero - points , saturation ) .",
    "thus , the 2mass reference catalogs can be retrieved for the given field in such a way that there are many sources in common . in general applications , however , when the saturation limit and faint magnitude limits of an image have only a crude estimate , the extended triangulation is essential .",
    "although the procedure is fast , we note that the most time consuming part of the process is the triangulation generation and the triangle matching itself . on average ,",
    "this required more than 60% of the total time , and at @xmath163 , 92% of the time .",
    "the median value of the fit residuals was 0.06 pixels , while the median value of the unitarities was 0.0042 .",
    "the latter is in a quite good agreement with the expected value of the nonlinearity factor @xmath164 .",
    "we also compared the performance of the program `` with an existing implementation within iraf , namely the `` package with its relevant tasks `` , `` and `` .",
    "the steps of the point matching were as described in .",
    "first , an initial set of possible pairs were established using `` and the `` triangles '' option as matching method . because the triangle sets generated by `` are full triangulations , we limited our input lists to the brightest sources , otherwise the @xmath39 dependence of the number of the triangles would have resulted in an unrealistically long matching time .",
    "second , the initial transformation was fitted using `` , and followed by transforming the reference catalog to the frame of the input list using `` and this fit .",
    "third , the transformed reference and the original input list were also matched by `` , but this time using the `` tolerance '' matching method .",
    "finally , this new list of point pairs were used again to refine the geometrical transformation by `` .    the comparison of `` and the iraf `` implementation was based on 950 individual images , all acquired by tophat from the same fov .",
    "we note that we had to use the relatively narrow field tophat for the comparison , as the triangle match on the original 8.2  hatnet frames is almost hopeless given the spatial distortions , the large number of stars , and the difficulty to select the brightest stars and at the same time retain a small total number of selected sources ( in order to be able to cope with a full triangulation ) . on each image",
    "there were approximately @xmath165 detected stars , depending on the airmass or thin clouds .",
    "for the triangulation and the initial `` fit we used the @xmath166 brightest sources both from the reference catalog and from the input star lists .",
    "we found that `` required @xmath167  sec cpu time on average while the whole procedure using these iraf - based tasks , as described above , required @xmath168  sec net cpu time for a single image .",
    "both algorithms yielded the same transformation coefficients and found the same number of pairs , however , in @xmath169 cases , the number of sources used for triangulation had to be increased manually to @xmath170 or @xmath171 .",
    "it is noteworthy that although the iraf version proved to be significantly slower , the time consuming part was the first `` matching .",
    "all other tasks , including the second matching ( with `` tolerance '' option ) required only a fraction of a second per image .",
    "in this paper we present a robust algorithm for cross - matching two two - dimensional point lists .",
    "the task is twofold : finding the smooth spatial transformation between the lists , and cross - matching points .",
    "these two steps are intertwined , and are performed in an iterative way till satisfactory transformation and matching rate are reached .",
    "we make only very basic assumptions that hold for almost all astronomical applications , including wide - field surveys with distorted fields and large number of sources .",
    "namely , the transformation between the point lists is dominantly a similarity transformation ( arbitrary shift , rotation , magnification , inversion ) .",
    "a significant distortion term can be present , given it can be linearized on the scale - length of the average distance of neighboring points .",
    "in we briefly described symmetric point - matching in one and two dimensions , because this tool is used throughout the astrometry procedure .",
    "finding the initial transformation between the point lists is based on triangle matching .",
    "first we defined various normalized triangle spaces in .",
    "the `` mixed '' triangle space of @xcite is a continuous function of the triangle parameters , but flipped triangles are not distinguished .",
    "the `` chiral '' triangle space ensures that chirality information is preserved , but this space is not continuous .",
    "we showed that it is possible to define a `` continuous '' triangle space that is both continuous and preserves chirality , and which , furthermore , spans a larger volume and diminishes confusion of triangles having similar coordinates .",
    "taking into account the distortion of a field and the astrometric errors , we calculated both the optimal size and number of triangles . for the typical setup of a hatnet telescope ( @xmath14 fov , distortion factor @xmath172 ) the optimal size is @xmath173 , and the optimal number of triangles is less than @xmath174 .",
    "we use delaunay triangulation for generating the triangles of the triangle - space .",
    "this has the advantage of being fast , robust , and generating local triangles that are less prone to being distorted . in we noted , however , that delaunay triangulation is sensitive for removing or adding points to the list , and thus instable .",
    "we introduced an extension of this triangulation that is parametrized by an @xmath99 level .",
    "having determined the transformation between the two lists , one can check how well our initial assumption of the dominant term being linear holds .",
    "in we introduced the unitarity of the transformation , a simple scalar measure of this property .",
    "we described the practical details of the algorithm in , and the actual software implementation ( `` , `` ) in .    finally , we ran the above programs on some 240,000 frames taken by the wide - angle cameras of hatnet , plus 20,000 frames acquired by the tophat telescope .",
    "the success rate was very close to 100% , and the routines handled the various pointing errors , defocusing and 6th order distortions in the wide fields .",
    "both programs will become available in binary format for a wide range of architectures upon request from the authors .",
    "a.  p.  would like to thank the hospitality of the harvard - smithsonian center for astrophysics , where this work has been partially carried out .",
    "a.  p.  was also supported by the hungarian otka grant t-038437 .",
    "the hatnet project is funded by nasa grant nng04gn74 g .",
    "b. wishes to acknowledge funding by the nasa hubble fellowship grant hst - hf-01170.01-a .",
    "both authors would like to thank istvn domsa for the early development of triangle and point - matching codes .",
    "akerlof , c. , et al.2000 , , 119 , 1901 alonso , r. , et al.2004 , , 613 , l153 bakos , g.  . , lzr , j. , papp , i. , sri , p. , green , e. m. 2002 , , 114 , 974 bakos , g.  . ,",
    "noyes , r. w. , kovcs , g. , stanek , k. z. , sasselov , d. d. and domsa , i. 2004 , , 116 , 266 calabretta , m. r. , greisen , e. w. 2002 , a&a , 395 , 1077 charbonneau , d. , brown , t.  m. , burrows , a. , laughlin , g.  2006 , in conference proceedings of protostars and planets v , astro - ph/0603376 gionis , a. : computational geometry : nearest neighbor problem ( lecture notes ) groth , e.  j.  1986 , , 91 , 1244 hartman , j. d. , bakos , g.  . ,",
    "stanek , k. z. , noyes , r. w. 2004 , , 128 , 1761 joye , w. a. , mandel , e. 2003 , asp conf .",
    "ser . , 295 , 489 mink , d. j. , 2002 , asp conf .",
    "ser , 281 , 169 pepper , j. , gould , a. , & depoy , d.  l.2004 , aip conf .",
    "proc .  713 : the search for other worlds , 713 , 185 phillips , a. c. , davis , l. e. 1995 , in astronomical data analysis software and systems iv , asp conference series vol .",
    "77 , 297 ( eds .",
    "r. a. shaw , h. e. payne and j. j. e. hayes ) pojmanski , g.  1997 , acta astronomica , 47 , 467 press , w. h. , teukolsky , s. a. , vetterling , w.t . ,",
    "flannery , b.p .",
    "1992 , numerical recipes in c : the art of scientific computing , second edition , cambridge university press shewchuk , r. j. 1996 , in applied computational geometry : towards geometric engineering , ed . m. c. lin & d. manocha ( berlin : springer ) , 1148 , 203 shupe , d. l. , moshir , mehdrdad , li , j. ; makovoz , d. , narron , r. , hook , r. n. , 2005 , asp conf .",
    "ser . , 347 , 491 skrutskie , m. f. , cutri , r. m. , stiening , r. , weinberg , m. d. , schneider , s. , carpenter , j. m. , beichman , c. , capps , r. , chester , t. , elias , j. , huchra , j. , liebert , j. , lonsdale , c. , monet , d. g. , price , s. , seitzer , p. , jarrett , t. , kirkpatrick , j. d. , gizis , j. , howard , e. , evans , t. , fowler , j. , fullmer , l. , hurt , r. , light , r. , kopan , e. l. , marsh , k. a. , , mccallon , h. l. , tam , r. , van dyk , s. , and wheelock , s. , , 131 , 1163 stetson , p. b. 1989 , in advanced school of astrophysics , image and data processing / interstellar dust , ed .",
    "b. barbury , e. janot - pacheco , a. m. magalhes and s. m. viegas ( so paulo , instituto astrnomico e geofsico ) valdes , f. g. , campusano , l. e. , velsquez , j. d. , stetson , p. b. 1995 , , 107 , 1119 thiebaut , c. , bor , m. 2001 , asp conf .",
    "ser . , 238 , 388"
  ],
  "abstract_text": [
    "<S> we present a robust and fast algorithm for performing astrometry and source cross - identification on two dimensional point lists , such as between a catalogue and an astronomical image , or between two images . </S>",
    "<S> the method is based on minimal assumptions : the lists can be rotated , magnified and inverted with respect to each other in an arbitrary way . the algorithm is tailored to work efficiently on wide fields with large number of sources and significant non - linear distortions , as long as the distortions can be approximated with linear transformations locally , over the scale - length of the average distance between the points . </S>",
    "<S> the procedure is based on symmetric point matching in a newly defined continuous triangle space that consists of triangles generated by an extended delaunay triangulation . </S>",
    "<S> our software implementation performed at the 99.995% success rate on @xmath0 frames taken by the hatnet project . </S>"
  ]
}