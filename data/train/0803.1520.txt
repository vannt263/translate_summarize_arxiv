{
  "article_text": [
    "strong replica consistency is an essential property for replication - based fault tolerant distributed systems .",
    "it can be achieved via a number of different techniques . in this paper , we investigate the challenges in achieving integrity - preserving strong replica consistency and present our solutions for state - machine based byzantine fault tolerant systems  @xcite . while it is widely known that strong replica consistency can also be achieved through the systematic - checkpointing technique  @xcite for nondeterministic applications in the benign fault model , it is generally regarded as too expensive and it is not suitable for byzantine fault tolerance .",
    "the state - machine based approach is one of the fundamental techniques in building fault tolerant systems  @xcite . in this approach ,",
    "replicas are assumed to be either deterministic or rendered - deterministic .",
    "there has been a large body of work on how to render replicas deterministic in the presence of replica nondeterminism under the benign fault model ( _ e.g.,@xmath0 _  @xcite ) . however , when the replicas can be subject to byzantine faults , which is the case for many internet - based systems , most of the previous work is no longer effective .",
    "furthermore , the determinism ( or rendered - determinism ) of the replicas is often considered harmful from the security perspective ( _ e.g.,@xmath0_with replication , an adversary can compromise any of the replicas to obtain confidential information  @xcite ) and for many applications , their integrity is strongly dependent on the randomness of some of their internal operations ( _ e.g.,@xmath0_random numbers are used for unique identifier generation in transactional systems and for shuffling cards in online poker games , and if the randomness is taken away by a deterministic algorithm to ensure replica consistency , the identifiers or the hands of cards can be made predictable , which can easily lead to exploit  @xcite ) .",
    "this calls for new approaches towards achieving strong replica consistency while preserving the randomness of each replica s operations .    in this paper",
    ", we present two alternative approaches towards our goal . the first one is based on byzantine agreement  @xcite ( referred to as the ba - algorithm in this paper ) and the other on a threshold coin - tossing scheme  @xcite ( referred to as the ct - algorithm ) .",
    "both approaches rely on a collective determination for decisions involving randomness , and the determination is based on the contributions made by a set of replicas ( at least one of which must be correct ) , to avoid the problems mentioned above .",
    "they differ mainly by how the collective determination is carried out . in the ba - algorithm ,",
    "the replicas first reach a byzantine agreement on the set of contributions from replicas , and then apply a deterministic algorithm ( for all practical purposes , the bitwise exclusive - or operation  @xcite ) to compute the final random value .",
    "the ct - algorithm uses the threshold coin - tossing scheme introduced in  @xcite to derive the final random value , without the need of a byzantine agreement step .",
    "even though the ct - algorithm saves on communication cost , it does incur significant computation overhead due to the cpu - intensive exponentiation calculations .",
    "consequently , as we will show in section  [ implsec ] , the ba - algorithm performs the best in a local - area network ( lan ) environment , where the ct - algorithm is more appropriate for the wide - area network ( wan ) environment where message passing is expensive .",
    "furthermore , to ensure the freshness of the random numbers generated , the replicas using the ba - algorithm should have access to high entropy sources ( which is relatively easy to satisfy ) and the replicas should be able to refresh their key shares periodically in the ct - algorithm . for the latter , we envisage that a proactive threshold signature scheme could be used  @xcite . however , the discussion of proactive threshold signature techniques is out of the scope of this paper .    to summarize ,",
    "we make the following research contributions in this paper :    * we point out the danger and pitfalls of controlling replica randomness for the purpose of ensuring replica consistency . removing randomness from replica operations ( when it is needed ) could seriously compromise the system integrity .",
    "* we propose the use of collective determination of random numbers contributed from replicas , as a practical way to reconcile the requirement of strong replica consistency and the preservation of replica randomness .",
    "* we present a light - weight , byzantine agreement based algorithm to carry out the collective determination .",
    "the ba - algorithm only introduces two additional communication steps because the byzantine agreement for the collective determination of random numbers can be integrated into that for message total ordering , as needed by the state - machine replication .",
    "the ba - algorithm is particularly suited for byzantine fault tolerant systems operating in the lan environment , or where replicas are connected by high - speed low - latency networks .",
    "* we further present an algorithm that uses the threshold coin - tossing scheme  @xcite as an alternative method for collective determination of random numbers .",
    "the coin - tossing scheme is introduced in  @xcite as an instrumental mechanism for a group of replicas to reach byzantine agreement in asynchronous systems . to the best of our knowledge ,",
    "our work is the first to show its usefulness in helping to ensure strong replica consistency without compromising the system integrity .",
    "* we conduct extensive experiments , in both a lan testbed and an emulated wan environment , to thoroughly characterize the performance of the two approaches .",
    "in this section , we introduce the system model for our work , and the practical byzantine fault tolerance algorithm ( bft algorithm , for short ) developed by castro and liskov  @xcite as necessary background information .",
    "byzantine fault tolerance refers to the capability of a system to tolerate byzantine faults .",
    "it can be achieved by replicating the server and by ensuring that all server replicas reach an agreement on the total ordering of clients requests despite the existence of byzantine faulty replicas and clients .",
    "such an agreement is often referred to as byzantine agreement  @xcite .    in recent several years , a number of efficient byzantine agreement algorithms  @xcite have been proposed . in this work ,",
    "we focus on the bft algorithm and use the same system model as that in  @xcite .",
    "the bft algorithm operates in an asynchronous distributed environment .",
    "the safety property of the algorithm , _",
    "i.e.,@xmath0_all correct replicas agree on the total ordering of requests , is ensured without any assumption of synchrony .",
    "however , to guarantee liveness , _ i.e.,@xmath0_for the algorithm to make progress towards the byzantine agreement , certain synchrony is needed .",
    "basically , it is assumed that the message transmission and processing delay has an asymptotic upper bound .",
    "this bound is dynamically explored in the algorithm in that each time a view change occurs , the timeout for the new view is doubled .",
    "the bft algorithm is executed by a set of @xmath1 replicas to tolerate up to @xmath2 byzantine faulty replicas .",
    "one of the replicas is designated as the primary while the rest are backups .",
    "each replica is assigned a unique i d @xmath3 , where @xmath3 varies from @xmath4 to @xmath5 . for view @xmath6 , the replica whose i d @xmath3 satisfies @xmath7 would serve as the primary",
    "the view starts from 0 .",
    "for each view change , the view number is increased by one and a new primary is selected .",
    "the normal operation of the bft algorithm involves three phases . during the pre - prepare phase , the primary multicasts a pre - prepare message containing the client s request , the current view and a sequence number assigned to the request to all backups . a backup verifies the request and the ordering information .",
    "if the backup accepts the pre - prepare message , it multicasts a prepare message containing the ordering information and the digest of the request being ordered .",
    "this starts the prepare phase .",
    "a replica waits until it has collected @xmath8 matching prepare messages from different replicas , and the pre - prepare message , before it multicasts a commit message to other replicas , which starts the commit phase .",
    "the commit phase ends when a replica has collected @xmath9 matching commit messages from different replicas ( possibly including the one sent or would have been sent by itself ) . at this point ,",
    "the request message has been totally ordered and it is ready to be delivered to the server application once all previous requests have been delivered .",
    "all messages exchanged among the replicas , and those between the replicas and the clients are protected by an authenticator  @xcite ( for multicast messages ) , or by a message authentication code ( mac ) ( for point - to - point communications ) .",
    "an authenticator is formed by a number of macs , one for each target of the multicast .",
    "we assume that the replicas and the clients each has a public / private key pair , and the public keys are known to everyone .",
    "these keys are used to generate symmetric keys needed to produce / verify authenticators and macs . to ensure freshness ,",
    "the symmetric keys are periodically refreshed by the mechanism described in  @xcite .",
    "we assume that the adversaries have limited computing power so that they can not break the security mechanisms described above .",
    "furthermore , we assume that a faulty replica can not transmit the confidential state , such as the random numbers collectively determined , to its colluding clients in real time .",
    "this can be achieved by using an application - level gateway , or a privacy firewall as described by yin et al.@xcite , to filter out illegal replies .",
    "a compromised replica may , however , replace a high entropy source to which it retrieves random numbers with a deterministic algorithm , and convey such an algorithm via out - of - band or covert channels to its colluding clients .",
    "in this section , we analyze a few well - known approaches possibly be used to ensure replica consistency in the presence of replica randomness .",
    "we show that they are not robust against byzantine faulty replicas and clients .    for replicas that use a pseudo - random number generator ,",
    "they can be easily rendered deterministic by ensuring that they use the same seed value to initialize the generator .",
    "one might attempt to use the sequence number assigned to the request as the seed . even though this approach is perhaps the most economical way to render replicas deterministic ( since no extra communication step is needed and no extra information is to be included in the control messages for total ordering of requests ) , it virtually takes the randomness away from the fault tolerant systems . in the presence of byzantine clients",
    ", the vulnerability can be exploited to compromise the integrity of the system .",
    "for example , a byzantine faulty client in an online poker game can simply try out different integer values as the seed to the pseudo - random generator ( if it is known to the client ) to guess the hands of the cards in the dealer and compare with the ones it has gotten .",
    "the client can then place its bets accordingly and gain unfair advantage .",
    "a seemingly more robust approach is to use the timestamp as the seed to the pseudo - random number generator .",
    "as shown in  @xcite , the use of timestamp does not offer more robustness to the system because it can also be guessed by byzantine faulty clients .",
    "furthermore , the use of timestamp imposes serious challenges in asynchronous distributed systems because of the requirement that all replicas must use the same timestamp to seed the pseudo - random number generator . in  @xcite",
    ", a mechanism is proposed to handle this problem by asking the primary to piggyback its timestamp , to be used by backups as well , with the pre - prepare message . however , the issue is that the backups have very limited ways of verifying the timestamp proposed ( other than that the timestamp must be monotonically increasing ) without resorting to strong synchrony assumptions ( such as bounds on processing and message passing ) .    the only option remaining seems to be the use of a truly random number to seed the pseudo - random number generator ( or to obtain random numbers entirely from a high entropy source ) .",
    "we note that the elegant mechanism described in  @xcite can not be used in this case because backups have no means to verify whether the number proposed by the primary is taken from a high - entropy source , or is generated according to a deterministic algorithm .",
    "if the latter is the case , the byzantine faulty primary could continue colluding with byzantine faulty clients without being detected .",
    "therefore , we believe the most effective way in countering such threats is to collectively determine the random number , based on the contributions from a set of replicas so that byzantine faulty replicas can not influence the final outcome .",
    "the set size depends on the algorithms used , as we will show in the next two sections , but it must be greater than the number of faulty replicas tolerated ( @xmath2 ) by the system .",
    "the normal operation of the ba - algorithm is illustrated in figure  [ bafig ] . as can be seen , the collective - determination mechanism is seamlessly integrated into the original bft algorithm . on ordering a request ,",
    "the primary determines the order of the request ( _ i.e.,@xmath0_assigns a sequence number to the request ) , and queries the application for the type of operation associated with the request .",
    "if the operation involves with a random number as input , the primary activates the mechanism for the ba - algorithm .",
    "the primary then obtains its share of random number by extracting from its own entropy source , and piggybacks the share with the pre - prepare message multicast to all backups .",
    "the pre - prepare message has the form @xmath10pre - prepare,@xmath11@xmath12@xmath13 , where @xmath6 is the view number , @xmath14 is the sequence number assigned to the request , @xmath15 is the digest of the request , @xmath16 is the random number generated by the primary , and @xmath13 is the authenticator for the message .    on receiving the pre - prepare message , a backup performs the usual chores such as the verification of the authenticator before it accepts the message .",
    "it also checks if the request will indeed trigger a randomized operation , to prevent a faulty primary from putting unnecessary loads on correct replicas ( which could lead to a denial of service attack ) .",
    "if the pre - prepare message is acceptable , the replica creates a pre - prepare certificate for storing the relevant information , generates a share of random number from its entropy source , and multicasts to all replicas a pp - update message , in the form @xmath10pp - update,@xmath17@xmath12@xmath18 , where @xmath3 is the sending replica identifier , @xmath19 is the random number contributed by replica @xmath3 .",
    "when the primary has collected @xmath8 pp - update messages , it combines the random numbers received according to a deterministic algorithm ( referred to as the entropy combination step in figure  [ bafig ] ) , and builds a pp - update message with slightly different content than those sent by backups . in the pp - update message sent by the primary ,",
    "the @xmath19 component is replaced by a set of @xmath9 tuples containing the random numbers contributed by replicas ( possibly including its own share ) , @xmath20 .",
    "each tuple has the form @xmath10@xmath21@xmath12 .",
    "the replica identifier is included in the tuple to ease the verification of the set at backups .    on receiving a pp - update message , a backup accepts the message and stores the message in its data structure provided that the message has a correct authenticator , it is in view @xmath6 and it has accepted a pre - prepare message to order the request with the digest @xmath15 and sequence number @xmath14 . a backup proceeds to the entropy combination step only if ( 1 ) it has accepted a pp - update message from the primary , and ( 2 ) @xmath8 pp - update messages sent by the replicas referenced in the set @xmath20 .",
    "the backup requests a retransmission from the primary for any missing pp - update message .",
    "after the entropy combination step is completed , a backup multicasts a prepare message in the form @xmath10prepare@xmath22@xmath12@xmath23 , where @xmath24 is the digest of the request concatenated by the combined random number .    when a replica has completed the entropy combination step , and it has collected @xmath8 valid prepare messages from different replicas ( possibly including the message sent or would have been sent by itself ) , it multicasts to all replicas a commit message in the form @xmath10commit@xmath22@xmath12@xmath23 . when a replica receives @xmath9 valid commit messages , it decides on the sequence number and the collectively determined random number . at the time of delivery to the application , both the request and the random number",
    "are passed to the application .    in figure",
    "[ bafig ] , the duration of the entropy extraction and combination steps have been intentionally exaggerated for clarify . in practice , the entropy combination can be achieved by applying a bitwise exclusive - or operation on the set of random numbers collected , which is very fast .",
    "the cost of entropy extraction depends on the scheme used .",
    "some schemes , such as the truerand method  @xcite , allows very prompt entropy extraction .",
    "truerand works by gathering the underlying randomness from a computer by measuring the drift between the system clock and the interrupts - generation rate on the processor .",
    "the normal operation of the ct - algorithm is shown in figure  [ ctfig ] .",
    "the ct - algorithm is the same as the bft algorithm in the first two phases ( _ i.e.,@xmath0_pre - prepare and prepare phases ) .",
    "the commit phase is modified by incorporating threshold coin - tossing operations .",
    "most existing @xmath25 threshold signature schemes  @xcite can be used for the ct - algorithm , where @xmath26 is the threshold number of signature shares needed to produce the group signature , and @xmath27 is the total number of players ( _ i.e.,@xmath0_replicas in our case ) participating the threshold signing . in most @xmath25 threshold signature schemes ,",
    "a correct group signature can be derived by combining shares from @xmath28 players , where @xmath29 is the maximum number of corrupted players tolerated .",
    "some schemes , such as the rsa - based scheme in  @xcite , allow the flexibility of using up to @xmath30 as the minimum number of shares required to produce the group signature .",
    "since @xmath27 in our work , @xmath26 can be set as high as @xmath9 .",
    "this property offers additional protection against byzantine faulty replicas  @xcite .    at the beginning of the commit phase",
    ", each replica generates its share of threshold signature by signing @xmath10@xmath31@xmath12 using its private key share , where @xmath15 is the digest of the request message and @xmath14 is the sequence number assigned to the request .",
    "this operation is referred to as the share - generation step in figure  [ ctfig ] .",
    "the signature share is piggybacked with the commit message , in the form @xmath10commit@xmath32@xmath12@xmath23 , where @xmath33 is the replica @xmath3 s share of threshold signature .",
    "when a replica has collected @xmath8@xmath34@xmath35 valid commit messages from different replicas , it executes the shares - combination step by combining @xmath26 threshold signature shares piggybacked with the commit messages .",
    "after the shares have been combined into a group signature , it is mapped into a random number , first by hashing the group signature with a secure hash function ( _ e.g.,@xmath0_sha1 ) , and then by taking the first group of most significant bits from the hash according to the type of numbers needed ,",
    "_ e.g.,@xmath0_32bits .",
    "the random number will be delivered together with the request to the application , when all previous requests have been delivered .",
    "in this section , we provide an informal argument on the correctness of our two algorithms .",
    "the correctness criteria for the algorithms are :    * all correct replicas deliver the same random number to the application together with the associated request , and * the random number is secure ( _ i.e.,@xmath0_it is truly random ) in the presence of up to @xmath2 byzantine faulty replicas .",
    "we first argue for the ba - algorithm .",
    "c1 is guaranteed by the use of byzantine agreement algorithm .",
    "c2 is ensured by the collection of @xmath9 shares contributed by different replicas , and by a sound entropy combination algorithm ( _ e.g.,@xmath0_by using the bitwise exclusive - or operation on the set to produce the combined random number ) . by collecting @xmath9 contributions",
    ", it is guaranteed that at least @xmath36 of them are from correct replicas , so faulty replicas can not completely control the set .",
    "shares are all that needed for this purpose . however , collecting more shares is more robust in cases when some correct replicas use low - entropy sources .",
    "this is analogous to the benefit of shoup s threshold signature scheme  @xcite . ]",
    "the entropy combination algorithm ensures that the combined random number is secure as long as at least one share is secure .",
    "the bitwise exclusive - or operation could be used to combine the set and it is provably secure for this purpose  @xcite .",
    "therefore , the ba - algorithm satisfies both c1 and c2 .",
    "next we argue for the ct - algorithm .",
    "c1 is guaranteed by the following fact : ( 1 ) the same message ( @xmath10@xmath31@xmath12 ) is signed by all correct replicas , according to the ct - algorithm .",
    "( 2 ) the threshold signature algorithm guarantees the production of the same group signature by combining @xmath26 shares .",
    "different replicas could obtain different set of @xmath26 shares and yet they all lead to the same group signature .",
    "( 3 ) the same secure hash function is used to hash the group signature .",
    "c2 is guaranteed by the threshold signature algorithm . for the threshold signature algorithm used in our implementation",
    ", its security is ensured by the random oracle model  @xcite .",
    "therefore , the ct - algorithm is correct as well .",
    "this completes our proof .",
    "the ba - algorithm and the ct - algorithm have been implemented and incorporated into a java - based bft framework .",
    "the java - based bft framework is developed in house and it is ported from the c++ based bft framework of castro and liskov  @xcite . due to space limitation , the details of the framework implementation is omitted .",
    "the ct - algorithm uses shoup s threshold signature scheme  @xcite , implemented by steve weis and made available at sourceforge  @xcite .",
    "the development and test platform consists of a group of dell sc440 servers each is equipped with a pentiumd processor of 2.8ghz and 1 gb of ram running suse 10.2 linux .",
    "the nodes are connected via a 100mbps lan . as we noted earlier ,",
    "the wan experiments are emulated by introducing artificial delays in communication , without injecting message loss .",
    "to character the cost of the two algorithms , we use an echo application with fixed 1kb - long requests and replies .",
    "the server is replicated at four nodes , and hence , @xmath37 in all our measurements .",
    "up to 12 concurrent clients are launched across the remaining nodes ( at most one client per node ) .",
    "each client issues consecutive requests without any think time . for the ct - algorithm",
    ", we vary a number of parameters , including the threshold value and the key length .",
    "we also experiment with certain optimizations .",
    "for all measurements , the end - to - end latency is measured at the client and the throughput is measured at the replicas . the java system.nanotime ( ) api",
    "is used for all timing - related measurements .",
    "we first report the mean execution latency of basic cryptographic operations involved in the ba - algorithm and the ct - algorithm because such information is beneficial to the understanding of the behaviors we observe .",
    "the latency cost is obtained when running a single client and 4 server replicas in the lan testbed .",
    "the results are summarized in table  [ cryptocost ] . as can be seen , the threshold signature operations are quite expensive , and it is impractical to use a key as large as 1024bit - long .",
    ".execution time for basic cryptographic operations involved with our algorithms .",
    "the data shown for ct signing is for a single share . [",
    "cols=\"<,<,<\",options=\"header \" , ]     without any optimization ( and without fault ) , an end - to - end remote call from a client to the replicated server using the original bft algorithm involves a total of 4 authenticator generation operations ( @xmath38 ) , 5 authenticator verification operations ( @xmath39 ) ( one does not need to verify the message sent by itself ) , 1 mac generation operation ( @xmath40 ) and 2 mac verification operation ( @xmath41 ) on the critical execution path ( _ i.e.,@xmath0_@xmath42 for request sending and receiving , @xmath42 for the pre - prepare phase , @xmath42 for the prepare phase , @xmath43 for the commit phase , and @xmath44 for the reply sending and receiving ) .",
    "the ba - algorithm introduces two additional communication steps and 2 @xmath38 and 3 @xmath39 on the critical path .",
    "the ct - algorithm does not require any additional communication step , but introduces 1 threshold signing operation ( @xmath45 ) and 1 operation for threshold shares verification and combination ( @xmath46 ) . from this analysis ,",
    "the minimum end - to - end latency achievable using the ba - algorithm is @xmath47 ( a replica can proceed to the next step as soon as it receives 1 valid prepare message from other replica in the prepare phase , and 2 valid commit messages from other replicas in the commit phase , and the client can proceed to deliver the reply as soon as it has gotten 2 consistent replies ) .",
    "similarly , the minimum latency using the ct - algorithm is @xmath48 .",
    "based on the values given in table  [ cryptocost ] , @xmath49 and @xmath50 for @xmath51 and 64bit - long key .",
    "the minimum overhead incurred by the ba - algorithm is @xmath52 and that by the ct - algorithm is @xmath53 for @xmath51 and 64bit - long key .",
    "figure  [ lanperf ] shows the summary of the experimental results obtained in the lan testbed .",
    "the end - to - end latency ( plotted in log - scale ) measured at a single client under various configurations is shown in figure  [ lanperf](a ) . as a reference ,",
    "the latency for the bft system without the additional mechanisms described in this paper is shown as `` base '' . in the figure ,",
    "the result for the ba - algorithm is shown as `` ba '' , and the results for the ct - algorithm with different parameter settings are labeled as ct#-i , where # is the @xmath26 value , and @xmath3 is the key length . as can be seen , only if a very short key is used , the ct - algorithm incurs significant overhead .",
    "furthermore , the observed end - to - end latency results are in - line with the analysis provided in the previous subsection .",
    "the throughput measurement results shown in figure  [ lanperf](b ) are consistent with those in the end - to - end latency measurements .",
    "the results labeled with `` no batching '' are obtained for the original ct - algorithm described in section  [ ctsec ] , _",
    "i.e.,@xmath0_one coin - tossing operation ( _ i.e.,@xmath0_threshold share signing , combination and verification of @xmath26 shares ) is used for _ every _ request . those labeled with `` with batching '' are measured when the requests are batched ( for total ordering , they all share the same sequence number  @xcite ) and only one coin - tossing operation is used for the entire batch of requests . as can be seen from figure  [ lanperf](b )",
    ", the gain in throughput is significant with the batching optimization .",
    "however , if sharing the same random number among several requests is a concern , this optimization must be disabled .    for the ba - algorithm ,",
    "the communication steps for reaching a byzantine agreement on the set of random numbers are automatically batched together with that for requests total - ordering . batching the byzantine agreement for",
    "a set of random numbers does not seem to introduce any vulnerability .",
    "the additional optimization of one set of entropy extraction and combination per batch of requests does not have any noticeable performance benefit .",
    "therefore , it is advised that this further optimization not to be considered in practice due to possible security concerns .",
    "figure  [ lanperf](c ) shows the end - to - end latency as a function of the load on the system in the presence of concurrent clients .",
    "we use the system throughput as a metric for the system load because it better reflects the actual load on the system than the number of clients .",
    "it is also useful to compare with the results in the wan experiments . as can be seen , for the ct - algorithm , without the batching optimization , the latency increases very sharply with the load , due to the cpu intensive threshold signature computations .",
    "the results for the ct - algorithm with keys larger than 64bits are omitted in figure  [ lanperf](b ) and ( c ) to avoid cluttering .",
    "the throughput is significantly lower and the end - to - end latency is much higher than those of the ba - algorithm in these configurations , especially when the load is high .",
    "the experimental results obtained in an emulated wan environment are shown in figure  [ wanperf ] .",
    "the observed metrics and the parameters used are identical to those in the lan experiments . as can be seen in figure  [ wanperf](a ) , the end - to - end latency as perceived by a single client is similar for the ba - algorithm and the ct - algorithm with a key size up to 256bits ( for either @xmath51 or @xmath54 ) .",
    "this can be easily understood because the end - to - end latency is dominated by the communication delays , as indicated by the end - to - end latency for the base system included in the figure .",
    "figure  [ wanperf](b ) shows part of the measurement results on system throughput under different number of concurrent clients . to avoid cluttering ,",
    "only the results for @xmath51 and key sizes of up to 256bits are shown .",
    "the throughput for the base system is included as a reference .",
    "as can be seen , when batching for the coin - tossing operation is enabled , the ct - algorithm with short - to - medium sized keys out - performs the ba - algorithm .",
    "when batching is disabled , however , the ba - algorithm performs better unless very small key is used for the ct - algorithm .",
    "the end - to - end latency results shown in figure  [ wanperf](c ) confirm the trend .",
    "how to ensure strong replica consistency in the presence of replica nondeterminism has been of research interest for a long time , especially for fault tolerant systems using the benign fault model  @xcite .",
    "however , while the importance of the use of good random numbers has long been recognized in building secure systems  @xcite , we have yet to see substantial research work on how to preserve the randomized operations necessary to ensure the system integrity in a fault tolerant system . for the type of systems where the use of random numbers is crucial to their service integrity ,",
    "the benign fault model is obviously inadequate and the byzantine fault model must be employed if fault tolerance is required .    in the recent several years",
    ", significant progress has been made towards building practical byzantine fault tolerant systems , as shown in the series of seminal papers such as  @xcite .",
    "this makes it possible to address the problem of reconciliation of the requirement of strong replica consistency and the preservation of each replica s randomness for real - world applications that requires both high availability and high degree of security .",
    "we believe the work presented in this paper is an important step towards solving this challenging problem .",
    "we should note that some form of replica nondeterminism ( in particular , replica nondeterminism related to timestamp operations ) has been studied in the context byzantine fault tolerant systems  @xcite .",
    "however , we have argued in previous sections that the existing approach is vulnerable to the presence of colluding byzantine faulty replicas and clients .    the main idea of this work , _",
    "i.e.,@xmath0_collective determination of random values based on the contributions made by the replicas , is borrowed from the design principles for secure communication protocols  @xcite . however , the application of this principle in solving the strong replica consistency problem is novel .",
    "the ct - algorithm is inspired by the work of cachin , kursawe and shoup  @xcite , in particular , the idea of exploiting threshold signature techniques for agreement .",
    "however , we have adapted this idea to solve a totally different problem , _",
    "i.e.,@xmath0_it is used towards reaching integrity - preserving strong replica consistency .",
    "furthermore , we carefully studied what to sign for each request so that the final random number obtained is not vulnerable to attacks .",
    "in this paper , we presented our work on reconciling the requirement of strong replica consistency and the desire of maintaining each replica s individual randomness .",
    "based on the central idea of collective determination of random values needed by the applications for their service integrity , we designed and implemented two algorithms . the first one , the ba - algorithm , is based on reaching a byzantine agreement on a set of random number shares provided by @xmath9 replicas . the second one , the ct - algorithm , is based on threshold signature techniques .",
    "we thoroughly characterized the performance of the two algorithms in both a lan testbed and an emulated wan environment .",
    "we show that the ba - algorithm in general out - performs the ct - algorithm in most cases except in wan operations under relatively light load .",
    "furthermore , the overhead incurred by the ba - algorithm with respect to the base bft system is relatively small , making it possible for practical use .",
    "future research work will focus on the threshold key share refreshment issue for the ct - algorithm . to ensure long - term robustness of the system",
    ", the key shares must be proactively refreshed periodically .",
    "otherwise , the random numbers generated this way may age over time , which may open the door for attacks . the threshold signature algorithm used in this work  @xcite does not have built - in mechanism for key share refreshment .",
    "we will explore other threshold signature algorithms that offer this capability  @xcite .",
    "j.  slember and p.  narasimhan . living with nondeterminism in replicated middleware applications . in _ proceedings of the acm / ifip / usenix 7th international middleware conference _ , pages 81100 , melbourne , australia , 2006 .",
    "j.  yin , j .-",
    "martin , a.  venkataramani , l.  alvisi , and m.  dahlin . separating agreement from execution for byzantine fault tolerant services . in _ proceedings of the acm symposium on operating systems principles _ , pages 253267 , bolton landing , ny , usa , 2003 ."
  ],
  "abstract_text": [
    "<S> strong replica consistency is often achieved by writing deterministic applications , or by using a variety of mechanisms to render replicas deterministic . </S>",
    "<S> there exists a large body of work on how to render replicas deterministic under the benign fault model . </S>",
    "<S> however , when replicas can be subject to malicious faults , most of the previous work is no longer effective . </S>",
    "<S> furthermore , the determinism of the replicas is often considered harmful from the security perspective and for many applications , their integrity strongly depends on the randomness of some of their internal operations . </S>",
    "<S> this calls for new approaches towards achieving replica consistency while preserving the replica randomness . in this paper </S>",
    "<S> , we present two such approaches . </S>",
    "<S> one is based on byzantine agreement and the other on threshold coin - tossing . </S>",
    "<S> each approach has its strength and weaknesses . </S>",
    "<S> we compare the performance of the two approaches and outline their respective best use scenarios .    </S>",
    "<S> * keywords * : replica consistency , byzantine fault tolerance , middleware , threshold signature , coin - tossing </S>"
  ]
}