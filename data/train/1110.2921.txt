{
  "article_text": [
    "the simulation of homogeneous isotropic turbulence is one of the most demanding benchmarks for computational fluid dynamics .",
    "the phenomenon of turbulence itself is a grand challenge problem , of crucial importance in many applications .",
    "atmospheric phenomena , combustion physics , aerodynamics of high - speed vehicles , and transport of pollutants are only a few examples . given the difficulty of capturing a wide range of physical scales , turbulence simulations must rely on parallel computing , and even so are yet unable to reach the large values of reynolds numbers that are encountered in many industrial settings without the use of turbulence models .",
    "direct numerical simulations that are used to generate data for investigating the nature itself of turbulence , are almost always conducted using the pseudo - spectral method . in this method ,",
    "the numerical engine is the fast fourier transform and thus scalability of turbulence simulations in parallel computers is directly dictated by the fft algorithm .",
    "the largest direct numerical simulation of isotropic turbulence to date has been performed on a cubic grid of size @xmath3 .",
    "the first work to reach that record problem size calculated turbulence at @xmath4 @xcite on the _ earth simulator_a large vector machine that can efficiently perform large - scale fft .",
    "this record has not been broken even though the peak performance of supercomputers has increased nearly 50-fold since then .",
    "the record @xmath3 grid size has been matched in the us recently @xcite , with simulations running on 16 thousand processors of the ranger system ( sun constellation linux cluster ) . but as far as we know , it has not been surpassed .    as the high - performance - computing community is pushing to achieve exascale ( @xmath5 operations per second ) ,",
    "it is important to ask how and which algorithms will be able to scale in future systems .",
    "fft is an algorithm that requires communication among all processes involved in the computation , and this is the limiting factor for its scalability to large systems . in a recent feasibility study , gahvari and gropp @xcite conclude that the bandwidth that would be needed for fft at exascale rules out mesh or torus networks , and only fat - tree or hypercube interconnects would be feasible .",
    "this poses significant constraints for future high - performance - computing systems .",
    "therefore , it is becoming increasingly important to look at alternative algorithms that may achieve better performance on the extremely parallel machines of the future .",
    "most standard methods of incompressible cfd require the solution of a poisson - type equation , this being the most expensive part of the calculation , in terms of runtime .",
    "in addition to standard sparse linear solvers ( such as multigrid ) and fft - based algorithms , there are some formulations which allow a solution via the fast multipole method , fmm .",
    "this use of the fmm , best known as an @xmath0-body solver , has not gained much traction due to both its perceived complexity to code and use , and its much longer runtimes compared to fft . the runtime advantage of fft , however , may be trumped by parallel scalability at the extreme scales of future systems .",
    "our current effort is part of an ongoing program of research into the role of fmm in the computational - science ecosystem at the exascale .",
    "we selected homogeneous isotropic turbulence in a periodic box as a test case , and apply a fast multipole vortex method for direct numerical simulation .",
    "there have been only a few works testing vortex methods with the benchmark of homogeneous isotropic turbulence , partly due to their comparative inefficiency for solving this particular flow .",
    "et al . _",
    "@xcite used the vortex - in - cell method , which is a semi - lagrangian method that relies on both particles and meshes and interpolations of field values between them .",
    "they compared with a spectral method for @xmath6 grid points at @xmath7 and showed good agreement between the two methods in the evolution of the energy spectrum , kinetic energy , dissipation , enstrophy and skewness .",
    "et al . _",
    "@xcite compared a pure lagrangian ( mesh - free ) vortex method against a pseudo - spectral method for @xmath6 at @xmath8 and 50 .",
    "they showed quantitative agreement between the vortex method and spectral method for the decay rate of kinetic energy and energy spectrum , and also higher - order turbulence statistics . that work was aimed at investigating different schemes for diffusion and also studied the effect of periodic boundary conditions on the fmm .",
    "spectral methods are based on fft while vortex methods rely on the fmm to achieve high performance . on a small number of cpus and for the same problem size",
    ", fft can be orders of magnitude faster than fmm  @xcite .",
    "however , in massively parallel systems , and especially with the help of gpu hardware , the difference in runtime between these two numerical algorithms becomes less important .",
    "we aim to investigate the range of problem sizes and the scale of parallelism that will make these algorithms comparable in time - to - solution . of course , in the application to fluid turbulence in particular , there are other advantages of spectral methods over vortex methods .",
    "spectral methods offer exponential convergence , and there are arguments against comparing high - order methods with lower - order methods at the same problem sizes ( we are using a vortex method that is second - order accurate ) . despite this very reasonable objection ,",
    "we persist in using this benchmark because it is the accepted standard for dns of turbulence , and provides a methodical approach to validation of the fmm - based vortex method .",
    "the goal of this paper is to provide evidence that the vortex method , accelerated with the fmm algorithm and gpu hardware , is indeed a proper tool for dns .",
    "this needs to be established before we can make further progress exploring the scalability advantages of the fmm as a numerical engine in the post - petascale era .    in this paper ,",
    "we compare simulations using a pseudo - spectral dns code and a vortex method dns code .",
    "we used the ` hit3d ` pseudo - spectral dns code developed at the center for turbulence research of stanford university @xcite .",
    "this code is parallel on cpu clusters using mpi and relies on the ` fftw3 ` library .",
    "our vortex method uses a highly parallel fmm library for gpus that we have recently developed , called ` exafmm ` .",
    "the performance of our fmm has appreciably increased from our previous studies , and we have added significant new functionality , such as auto - tuning @xcite .",
    "the comparisons are made under the same test conditions : same taylor - scale reynolds number , @xmath9 ; same discretization parameters , @xmath10 and @xmath11 ; and same initial / boundary conditions .",
    "we perform a systematic survey of the effect of the various parameters that affect the accuracy and speed of vortex method simulations  order of fmm series expansion @xmath12 , frequency of particle reinitialization , tolerance of the rbf solver , @xmath11 , overlap ratio @xmath13 , and @xmath14 , looking not only at the kinetic energy spectrum , but also the high - order turbulence statistics ( skewness and flatness of velocity derivatives ) . obtaining good agreement with the spectral method on the high - order statistics is a considerable challenge , since velocity derivatives require a higher spatial resolution to be calculated accurately @xcite . we show that the fmm is a satisfactory numerical engine for the direct numerical simulation of fluid turbulence , despite the inherent approximations in the algorithm and even when using single precision on the gpu hardware .",
    "this supports the case that fmm as a numerical engine will gain increasing importance , given its favorable parallel scalability and computational intensity that make it suitable for many - core architectures .",
    "the present work focuses on validating an fmm - based vortex method code on gpu , using a spectral method code as reference and looking at high - order turbulence statistics . in another publication @xcite",
    ", we focus on the performance on massively parallel systems of the vortex method , compared to the spectral method .",
    "that work included simulations of isotropic turbulence on up to 4096 gpus , with a @xmath3 problem size and exceeding 1  pflop / s of sustained performance .",
    "the reference numerical method used in this work is a pseudo - spectral method with primitive - variable formulation .",
    "pseudo - spectral methods have for decades been the preferred method for computing isotropic fluid turbulence , and their results are trusted .",
    "therefore , a quantitative comparison of the statistics of turbulence  kinetic energy decay , energy spectrum , high - order velocity statistics  will reveal the accuracy of our vortex method .",
    "we have used the open - source ` hit3d ` code for homogeneous isotropic turbulence of an incompressible fluid in 3d .",
    "this code uses ` fftw3 ` and is implemented in parallel for cpu clusters using mpi ( see acknowledgements for a link to the code project ) .",
    "the initial condition for all runs was generated with a separate code using the method described in section [ sse : initial ] , and given as an input file to ` hit3d ` .",
    "the original initial condition generated by the ` hit3d ` code has a fully developed energy spectrum , where the dissipation at the high wave numbers is in equilibrium with the energy transfer between the wave numbers .",
    "the time evolution of the velocity derivative skewness and flatness in this case is very different from that in similar studies @xcite , and is not suitable for validating the vortex method s ability to predict the initial evolution of high - order turbulence statistics . for this reason ,",
    "we have generated the initial velocity field in the same way as yokota _",
    "_ @xcite and used that as an input to ` hit3d ` .",
    "the term  vortex method \" is used in the literature somewhat loosely referring to one of several lagrangian and semi - lagrangian methods based on either the vorticity - streamfunction or vorticity - velocity formulation of the navier - stokes equation .",
    "all vortex methods obtain the convection term of the equation in a lagrangian manner , and are not constrained by the traditional limitations of eulerian methods in regards to the cfl condition , numerical diffusion and dispersion .",
    "this feature alone allows vortex methods to use time - step sizes that are an order of magnitude larger than other methods treating convection explicitly @xcite .",
    "the differentiating feature of various vortex methods is the way in which they obtain the viscous term and the stretching term of the navier - stokes equation in vorticity formulation .",
    "one variant , called vortex - in - cell or particle - mesh vortex method , performs the calculation of viscosity and stretching terms on a grid , and continuously interpolates quantities back and forth between particles and grid . the first work to undertake the simulation of homogeneous isotropic turbulence with a vortex method used an fft - based poisson solver to obtain the stream function on a grid @xcite .",
    "the velocity and vortex stretching can then be obtained using finite - difference formulas ; cottet _ et al . _",
    "@xcite , for example , use fourth - order centered differences . the early vortex - in - cell method @xcite used low - order interpolation schemes , which were too numerically diffusive , but",
    "modern versions utilize high - order interpolation and have been assessed and compared well with finite - difference and spectral methods @xcite .",
    "the other main variant of vortex methods maintains the grid - free character of the general approach by means of @xmath0-body solvers to obtain the particle velocity and the vortex stretching term on the particle locations .",
    "the first attempt to simulate homogeneous isotropic turbulence with the grid - free vortex method used a single - cpu code on an @xmath15 problem with @xmath16 @xcite .",
    "that work examined the effect of different viscosity schemes , the number of periodic image boxes in the fmm , and the effect of the series truncation parameter , @xmath12 .",
    "the main challenge for these grid - free vortex methods is the relatively high calculation cost of the fmm , when compared to fast poisson solvers using multigrid methods or fft .",
    "however , recent studies on large gpu clusters suggest that the high parallel scalability of the fmm becomes an advantage over the fft algorithm when thousands of mpi processes and gpu acceleration are used @xcite .",
    "the present vortex method solves the velocity poisson equation , which is derived from mass conservation .",
    "this is solved along with the vorticity equation , which is derived from momentum conservation .",
    "the governing equations are : @xmath17 where @xmath18 is the velocity vector , @xmath19 is the vorticity vector , and @xmath20 is the kinematic viscosity . the velocity poisson equation can be formulated as an integral equation using green s methods , which becomes an @xmath0-body problem that can be efficiently solved using the fmm .",
    "the vorticity equation is solved by updating the convection , stretching , and diffusion terms separately .",
    "this does not imply a fractional - step method since all three terms can be expressed as ordinary differential equations updating separate variables  the particle positions , @xmath21 , for convection ; the particle strengths , @xmath22 , for vortex stretching ; and the particle width , @xmath23 , for diffusion  and the updates happen simultaneously .",
    "the lagrangian discretization is based on moving gaussian basis functions , where the total vorticity field is expressed by their superposition as @xmath24 with @xmath25 the vortex strength of each basis function ( interpreted as a particle of vorticity ) .",
    "the gaussian basis function with standard deviation @xmath23 is defined by @xmath26 where @xmath27 is the distance between point @xmath28 and point @xmath29 .",
    "the integral form of equation , also known as the biot - savart equation , can be written as @xmath30 where @xmath31 is the green s function of the laplace kernel and @xmath32 is the cutoff function , derived by integrating the gaussian distribution in ( [ eq : gaussian ] ) while considering radial symmetry .",
    "the vorticity equation expresses the simultaneous convection , stretching and diffusion of vorticity . in the lagrangian vortex method formulation , the spatial discretization using gaussian basis functions results in a system of ordinary differential equations , which can be integrated explicitly .",
    "the convection term is accounted for by integrating the position coordinates of vortex particles according to the local velocity .",
    "the eulerian convection term , @xmath33 , is equivalent to a lagrangian convection of the gaussian basis functions , @xmath34 unlike eulerian methods , which alter the value of vorticity on the mesh to account for the effect of convection , lagrangian methods simply move the point without changing the value associated to it .",
    "lagrangian convection of basis functions combined with reinitialization or remeshing schemes results in a convergent numerical method , as has been shown with semi - lagrangian methods . for the vortex method",
    ", leonard @xcite proved that lagrangian convection of gaussian bases in the vortex method result in a second - order truncation error for the convection term ( this truncation error is known as `` convection error '' in the vortex method literature ) .",
    "the stretching term , @xmath35 , is solved by substituting the biot - savart equation ( [ eq : biotsavart ] ) into @xmath18 , and the gaussian basis function ( [ eq : smoothingfunction ] ) into @xmath19 , yielding @xmath36 this update occurs in a lagrangian frame since the lagrangian convection is happening simultaneously .    finally , the diffusion term , @xmath37 , can be calculated by changing the variance of the gaussian distribution according to @xmath38    since the gaussian distribution is an exact solution of the diffusion equation , spreading the distribution / variance of the gaussian basis function is equivalent to solving the diffusion equation exactly , as long as @xmath23 remains below a certain threshold .",
    "in fact , the core spreading method is an exact solution to the linearized navier - stokes equation ( i.e. , the convection - diffusion equations ) in a lagrangian frame with a constant flow field .",
    "the method is convergent as long as @xmath23 is small .",
    "rossi @xcite analyzed rigorously the residual of the core spreading method and proved convergence by showing boundedness of the solution and that the residual tends to zero with the numerical parameters .    in order to keep @xmath23 from growing indefinitely ,",
    "we perform a radial basis function ( rbf ) interpolation to smaller gaussian distributions .",
    "this technique is known to achieve higher accuracy than particle strength exchange methods with remeshing @xcite .",
    "rbf interpolation is obtained by solving a linear system for equation , with @xmath22 as the unknown vector and @xmath19 as the right - hand side .",
    "we used a gmres method , where the matrix - vector multiplications are done in matrix - free form by calculating equation .",
    "since the gaussian function decays rapidly , we use the fmm neighbor list to calculate equation between neighboring particles only . for an overlap ratio of @xmath39 , where @xmath40 is the average distance between particles ,",
    "the rbf system is well conditioned and converges in @xmath41@xmath42 iterations @xcite .",
    "the six fmm kernels and the matrix - vector multiplication in rbf interpolation are done on the gpu . in the current implementation , the tree construction , update of particles , gmres outer iteration , and vortex method time integration ( forward euler ) are all performed on the cpu .",
    "the biot - savart equation ( [ eq : biotsavart ] ) and the stretching term ( [ eq : stretching ] ) are @xmath0-body problems where the effect of all particles must be calculated against each other .",
    "thus , they appear to require @xmath43 operations for @xmath0 particles , but with fmm the complexity is @xmath44 . the fmm is based on approximation of the green s function by multipole and local expansions .",
    "for example , the green s function for the laplace kernel can be approximated by the following multipole expansion @xmath45 and also by the local expansion @xmath46 where @xmath12 is the order of expansion .",
    "the definition of variables follows the nomenclature of cheng _ et al .",
    "_  @xcite . in these equations ,",
    "the location of particle @xmath28 with respect to the center of expansion is expressed in spherical coordinates using @xmath47 , and the location of particle @xmath29 is @xmath48 ; @xmath49 are the spherical harmonic functions .",
    "we define the operators @xmath50 , @xmath51 , @xmath52 , @xmath53 as shown in equations and . using these operators ,",
    "equation can be approximated by @xmath54    note that these equations are used to calculate the far field , where the cutoff function @xmath55 , and can be omitted from the calculation .",
    "similarly , equation can be approximated by @xmath56 the near field , on the other hand , is calculated by solving equation exactly . for more details ,",
    "in particular explaining the method to obtain periodic boundary conditions , see previous publications  @xcite .",
    "the basic idea for periodic fmm is to place periodic images around the original domain and use multipole expansions to calculate their influence .",
    "these periodic images can be accounted for with very few multipole expansions and little computational effort , and the calculation time required does not depend on the number of particles .",
    "the fmm algorithm that we used in previous work @xcite , similarly to all other authors , required precise tuning of the parameters every time we changed the desired accuracy or hardware .",
    "for example , for a given problem and hardware , the number of levels in the tree that results in optimal runtime varies .",
    "one of the most useful modifications of the algorithm , which could aid its wider adoption by computational scientists , is eliminating the need for parameter selection and tuning .",
    "arguably , parameter auto - tuning is the most important feature that makes scientific software libraries successful .",
    "we have also observed in a separate work @xcite that the @xmath57 treecode exhibits more acceleration compared to the @xmath44 fmm when using gpu hardware . this suggested that treecodes could gain over the complexity advantage of fmm by means of hardware acceleration  contrary to the common wisdom that `` complexity trumps hardware '' , as eloquently stated by board and schulten  @xcite . on the other hand , cheng _",
    "et al . _",
    "state that `` a properly implemented fmm [ ... ] always selects the least expensive option '' @xcite .",
    "inspired by all these considerations , we recently developed a novel treecode - fmm hybrid algorithm with the capability of auto - tuning the parameters @xcite .",
    "the hybrid treecode - fmm uses a generic and flexible @xmath44 algorithm for traversing the tree , which can handle cases where the target particles and source particles are different .",
    "this feature is useful for calculating the velocity on a lattice that is induced by scattered , lagrangian particles ( e.g. , during rbf interpolation ) .",
    "the traversal is based on a stack data structure , and allows the interactions in the algorithm to be of cell - cell or cell - particle type , while at the same time automatically choosing the number of particles per box at the deepest levels of the tree , without user input .",
    "see details in our recent publication  @xcite .",
    "the flow field of interest consists of decaying homogeneous isotropic turbulence in a periodic box .",
    "the calculation domain is a cube of size @xmath58 ^ 3 $ ] , and the number of calculation points was @xmath59 for both the vortex method and spectral method . for the vortex method calculation",
    ", we studied the effect of various parameters , as described in the next section .",
    "the base parameters are set to the following values , unless otherwise noted .",
    "* order of fmm expansion : @xmath60 * number of periodic images : @xmath61 * drop tolerance of the krylov solver : @xmath62 * frequency of reinitialization : every 10 steps * temporal resolution : @xmath63 ( using euler method ) * taylor - scale reynolds number : @xmath2 * spatial resolution : @xmath64    the same temporal and spatial resolution was used for the spectral method , and @xmath11 was set to the maximum value that the spectral method can calculate stably .",
    "we will show later that the lagrangian vortex method remains stable and accurate for larger values of @xmath11 .",
    "the vortex method calculations were run on a single gpu using single precision ( 64 threads per thread - block ) , while the spectral method calculations were performed on all six cores of a multi - core cpu using local mpi processes ( and no gpu acceleration ) .",
    "note that for a value of @xmath60 in the fmm we obtain 4 significant digits of accuracy in the velocity and stretching calculations , which is lower than single - precision accuracy .",
    "accordingly , we observed no appreciable change in the results when running in double precision .",
    "the spectral method code ` hit3d ` does not have the feature to allow testing in single precision , and so we can only run it in double .",
    "this should be kept in mind when we report runtimes , below .",
    "the system used consists of intel nehalem - generation cpus ( intel  xeon   e5650 2.66ghz ) , and we used nvidia c2070 fermi gpus . with these hardware specifications ,",
    "the vortex method takes approximately 10 seconds per time step on one gpu chip , while the spectral method takes about 1 second per time step on a single cpu socket ( 6 cores ) .",
    "however , as the number of processes is increased the difference between the runtime of the vortex method and spectral method decreases @xcite .",
    "we used an expansion order @xmath65 for the timings , since it has been confirmed that this yields sufficient accuracy to calculate high - order turbulence statistics , as we will show later . using @xmath65 instead of",
    "the default value @xmath60 reduces the calculation time from 20 seconds to 10 seconds .      for the reasons mentioned in section [ sse :",
    "spectral ] , we do not use the initial condition provided by ` hit3d ` , but generate our own initial condition and use it as an input to ` hit3d ` ( and to the vortex method code ) .",
    "the initial velocity field was given a prescribed energy spectrum of @xmath66 the velocity field was generated in fourier space as a solenoidal isotropic field with random phases , and transformed to physical space @xcite , so that the resulting velocity field would have a zero mean and a gaussian distribution in the fluctuation .",
    "the peak wave number of the prescribed energy spectrum is @xmath67 .",
    "we use this velocity field in fourier space as the initial condition for the pseudo - spectral method .",
    "the vortex method requires the information of coordinates @xmath21 , vortex strength @xmath22 , and core radius @xmath23 .",
    "these values are calculated in the following manner .",
    "first , the coordinates for the vortex elements are obtained from their chosen locations in - between the grid points of the spectral method .",
    "for example , if the grid points of the spectral method were at the corners of a box , the vortex elements are placed at the center of this box .",
    "the vorticity at these points is calculated from the initial velocity field using a fourth - order central difference scheme .",
    "then , the core radius of the elements is set to @xmath68 , where @xmath40 is the distance between the vortex elements / grid points , resulting in an overlap ratio of @xmath39 .",
    "finally , the vortex strength is calculated by rbf interpolation with the same gaussian basis function that is used for the vortex elements with @xmath68 .",
    "it is common in vortex methods to use a smaller overlap ratio , say @xmath69 , but the homogeneity of the flow in isotropic turbulence allows us to use this relatively large overlap ratio ( see evidence presented in section [ s : overlap ] ) .",
    "this is beneficial because it reduces the ill - conditioning of the rbf matrix , and thus increases the speed of our rbf interpolation process .",
    "spectral methods have very few parameters that affect their accuracy and efficiency .",
    "once the spatial and temporal resolutions are set correctly , there is little room for a spectral method simulation of isotropic turbulence to go wrong .",
    "on the other hand , lagrangian vortex methods have a number of tunable parameters such as : expansion order in fmm , frequency of particle reinitialization , tolerance of the rbf interpolation .",
    "the effect of such parameters on direct numerical simulation of turbulence ( especially when looking at high - order statistics ) has not been investigated in much detail . in this section",
    ", we present the results of a wide range of parameter studies for the isotropic turbulence benchmark .",
    "we use a spectral method code as the reference and compare it with a vortex method code by varying the tunable parameters .",
    "computing with the fmm using @xmath12 expansion terms for @xmath0 particles requires @xmath70 work and @xmath71 storage @xcite , while the error decreases exponentially with @xmath12 .",
    "it is obvious that the accuracy in the calculation of the velocity and stretching terms of the vorticity equation depends on @xmath12 .",
    "however , it is not apparent how large @xmath12 actually needs to be in order to calculate a turbulence simulation with sufficient accuracy . therefore , as a first test case for our sequence of parameter studies , we vary @xmath12 between 6 , 8 and 10 .",
    "the energy spectra for the initial velocity field are shown in figure [ fig : init_p ] . in the legend , ",
    "spectral \" represents the spectral method and  vortex ( p= * ) \" is the vortex method with expansion order @xmath72 . as mentioned in section [ sse : initial ] , the initial condition for vortex methods is calculated by determining the proper vortex strength @xmath73 of each element , such that the sum of the velocities induced by all particles matches the initial velocity field .",
    "each vortex particle has a gaussian distribution of vorticity , and a system of equations is solved to determine the vortex strength of all particles so as to reproduce the vorticity field accurately .",
    "then , the energy spectrum is obtained by calculating the velocity field on a lattice using the biot - savart law ( [ eq : biotsavart ] ) and performing a 3-d fft on this velocity field .",
    "therefore , the discrepancy in figure [ fig : init_p ] between spectral methods and vortex methods can be caused by either the inaccuracy of the representation of the velocity field by a superposition of gaussian basis functions , or the inaccuracy of the biot - savart calculation using fmm .",
    "as seen in figure [ fig : init_p ] , the order of expansion @xmath12 has a significant effect on the tail of the energy spectrum .",
    "this effect is somewhat exaggerated in the artificial velocity field at the initial step , which has a very sharp drop in energy at high wave numbers . at later time steps ,",
    "as shown in figure [ fig : k_p ] , the high - frequency noise is less prominent , although we see a marked difference with varying value of @xmath12",
    ". we will show in the following subsection that this difference in the high - frequency range has little effect on high - order turbulence statistics .",
    "this issue of @xmath12-dependence was not discussed in previous calculations of isotropic turbulence using lagrangian vortex methods @xcite .",
    "the present simulations also use higher spatial resolution relative to the reynolds number than previous works .",
    "therefore , the damping of high - frequency modes is not as noticeable , and the energy spectrum matches that of the spectral method up to higher wave numbers .",
    "this is consistent with our previous claims that lagrangian vortex methods can match the results of spectral methods if the spatial resolution is sufficient .      using the notation @xmath74 , the skewness and flatness of the velocity derivative moments",
    "are defined by @xmath75    where @xmath76 is the skewness , and @xmath77 is the flatness of the velocity derivative moment .",
    "the time evolution of the skewness and flatness of the velocity derivative moments are shown in figure [ fig : p ] for different values of @xmath12 .",
    "time is normalized by the large - eddy - turnover time @xmath78 , which is defined as @xmath79    where the integral length scale @xmath80 and fluctuating velocity @xmath81 are , respectively ,    @xmath82    the large - eddy - turnover time increases as the decaying isotropic turbulence simulation proceeds .",
    "therefore , we use the initial value of @xmath83 to normalize the time .",
    "both the skewness and flatness show little variation among the vortex method calculations with different values of @xmath12 . in the case of the skewness in figure [ fig : sk_p ] ,",
    "the vortex method matches quantitatively with the spectral method throughout the entire duration of the simulation to @xmath84 . since the skewness of the velocity derivative is closely related to the cascade of kinetic energy from low to high wave numbers , fig .",
    "[ fig : sk_p ] is proof that our stretching - term calculation is accurate enough to simulate the energy cascade even with a relatively low expansion order of @xmath65 .",
    "the flatness of the velocity derivative agrees among the three vortex method calculations , but there is a discrepancy between the spectral method and vortex method in the range @xmath85  210 .",
    "the fact that the flatness matches better at later times can be explained by the decrease in reynolds number and the increase in relative spatial resolution of the turbulence .",
    "this supports our argument that vortex methods simply need more points to represent the same physics , when compared to spectral methods ( which is not surprising , given that spectral methods offer exponential convergence ) .",
    "this is also supported by the fact that the present vortex method calculation with @xmath64 at @xmath86 has much better agreement in the flatness when compared to the previous calculation with @xmath87 at @xmath88 @xcite , due to the increase in relative spatial resolution .",
    "further investigations should consider the possibility of large eddy simulation ( les ) with gaussian filtering , which could be a good match with the vortex elements that use gaussian basis functions .",
    "lagrangian vortex methods converge to the navier - stokes equation only if there is sufficient overlap between the vortex particles @xcite . in order to maintain overlap of all particles in long simulations , particle coordinates",
    "must be reinitialized onto a regular lattice every few steps .",
    "in the present simulations , we use a core spreading method with rbf interpolation for the reinitialization . in previous publications using this",
    "approach @xcite , the frequency of remeshing and tolerance of the linear solver for rbf interpolation were chosen by trial and error .",
    "readers could not know if these parameters were optimal , or how much they affected the accuracy and efficiency of the simulation . in the present work , we performed a parametric study regarding the frequency of reinitialization , tolerance of the linear solver and temporal resolution @xmath11 , to shed some light on this matter and aid reproducibility of accurate turbulence simulations with the fmm - based vortex method .",
    "the default parameters in our tests are listed in the previous section .",
    "we first change the frequency of reinitialization to determine its effect on the high - order turbulence statistics .",
    "the process of rbf interpolation is performed using a very efficient approach that re - uses the fmm interaction list to compute the matrix - vector multiplications .",
    "nevertheless , it requires significantly longer runtime than the highly scalable and gpu - accelerated biot - savart and stretching term calculations using the ` exafmm ` code @xcite .",
    "therefore , the total runtime can be appreciably reduced by minimizing the frequency of reinitialization , but reducing it too much may hurt accuracy .",
    "figure [ fig : skip ] shows the effect of reinitialization frequency on the time evolution of the skewness and flatness . in the legend ,  vortex ( reinit= * ) \" represents the vortex method calculation that reinitializes every @xmath89 steps . the cases with",
    " reinit=10 \" and  reinit=20 \" give similar results , but  reinit=50 \" clearly diverts from the other two . in the current simulations",
    ", reinitialization takes approximately ten times longer than the sum of the biot - savart , stretching , and diffusion terms for one time step .",
    "therefore , reinitializing every 10 steps will reduce the calculation runtime by roughly 5 times , compared to doing it on every step .",
    "it is rather surprising that reinitializing only every 50 steps still reproduces high - order turbulence statistics to the degree that it does .",
    "it is important to point out , however , that isotropic turbulence is a very special flow field where the distribution of vortex particles remains quite regular due to the homogeneous and isotropic nature of the convection at small scales .",
    "the frequency of reinitialization and large overlap ratio @xmath39 used in the isotropic turbulence simulations would not be applicable to any other flow field .",
    "the reinitialization process can be further accelerated if we can afford to use a lower exit tolerance in the iterative solver for the rbf interpolation .",
    "results with different solver tolerances are shown in figure [ fig : tol ] , and we note that skewness and flatness are almost indistinguishable for the three cases .",
    "we use the approximation @xmath90 as an initial guess for the solver , where @xmath10 is the distance between the grid points .",
    "the tolerance is measured by the relative drop of the residual from this initial guess .",
    "therefore , figure [ fig : tol ] indicates that this initial guess is not too far from the actual solution .",
    "however , just because the rbf interpolation requires very little iteration , this does not mean that the reinitialization is not necessary .",
    "this is evident from figure [ fig : skip ] , where the vortex method with infrequent reinitialization shows some discrepancy .",
    "the advantage of lagrangian methods is often viewed as the ability to use larger time - step sizes . in order to justify this claim",
    "we have increased @xmath11 and compared the high - order turbulence statistics ; the skewness and flatness are shown for different @xmath11 in figure [ fig : dt ] .",
    "the frequency of reinitialization is kept constant with respect to time and not the number of steps .",
    "for example , when @xmath11 is doubled the reinitialization is performed every 5 steps instead of 10 .",
    "it can be seen from figure [ fig : dt ] that increasing @xmath11 to @xmath91 does not change the results of the turbulence statistics . however , increasing @xmath11 to @xmath92 does result in an appreciable discrepancy in both the skewness and flatness .",
    "it is worth noting that @xmath63 is the maximum step size that spectral methods can calculate stably , and the lagrangian vortex method is only able to double the step size without significant drawbacks .",
    "the present results with the vortex method were obtained using 1st - order euler time integration . using a higher - order time integration scheme",
    "would likely allow larger time steps without harming the turbulence statistics .",
    "the overlap ratio @xmath13 is an important parameter for vortex method simulations .",
    "firstly , maintaining @xmath93 is a necessary condition for the vortex particle method to converge to the navier - stokes equation .",
    "secondly , this parameter affects the ill - conditioning of the rbf interpolation matrix , and therefore it affects the calculation time . for simulations of external flows with a large variation of particle density , a small overlap ratio would be necessary .",
    "note that the overlap ratio is traditionally defined in a counterintuitive way , where small overlap ratio actually means that the particles are overlapping more .",
    "this is due to the fact that the convergence proof of the vortex method relies on the limit @xmath94 .",
    "the effective spatial resolution of vortex methods depends not on the particle spacing @xmath40 , but on the core radius @xmath23 .",
    "even as we increase the number of particles , if @xmath23 is not simultaneously decreased , the spatial resolution will not increase .",
    "this is clearly observed in figure [ fig : over ] , where the overlap ratio is changed from @xmath95 to @xmath96 for a constant @xmath97 ; @xmath98 means the core radius @xmath23 is the largest of the three , and the effective spatial resolution is the worst among the three .",
    "the flatness of the velocity derivative shows a larger discrepancy with the spectral method in this case .",
    "the skewness is affected less by the spatial resolution , as will be discussed in further detail below .      in order to check the effect of reynolds number",
    ", we have performed the same calculations with the spectral method and vortex method on a @xmath99 lattice , but for @xmath100 .",
    "the results are shown in figure [ fig : re100 ] , where it can be seen that the high - order turbulence statistics do not match as well as in the @xmath86 case .",
    "for example , the skewness of the velocity derivative matches very well in figures [ fig : p ] , [ fig : skip ] , [ fig : tol ] , and [ fig : dt ] , but noticeable differences are seen in figure [ fig : re100 ] .",
    "also , the flatness of the velocity derivate deviates visibly for the @xmath100 case , illustrating the challenge of obtaining high - order statistics .",
    "as discussed by schumacher _",
    "@xcite , each moment has its own dissipative scale , and higher resolution ( or lower reynolds number ) is needed to resolve higher - order derivatives .",
    "the present results also illustrate this point , but with the vortex method : reducing @xmath9 from 100 to 50 with the @xmath1 lattice makes the skewness match very well with the spectral method and lessens the deviation in the flatness .",
    "figure [ fig : isosurf ] shows the isosurface of the second invariant of the velocity derivative tensor at time @xmath84 for @xmath86 and @xmath100 .",
    "not only do the statistical properties of the turbulence agree between the vortex method and spectral method , but also the instantaneous velocity field itself is almost identical .",
    "this also confirms that our periodic fmm , which calculates the effect of @xmath101 periodic images with multipole expansions , is producing an accurate velocity field even at the edges of the domain .",
    "the wall - clock time of a single time step was 10 seconds on a single gpu for the fmm - based vortex method ( @xmath65 ) , and 1 second on one cpu socket ( 6 cores ) for the fft - based pseudo - spectral method .",
    "note that calculating the fft on gpus would not provide a significant performance improvement , since the performance increase of ` cufft ` over ` fftw ` is small when the data transfer between the host and device is taken into account ] . in a separate publication @xcite ,",
    "we report much larger calculations with less emphasis on the physics and more emphasis on the efficiency and scalability of the codes .",
    "we performed a simulation of isotropic turbulence at @xmath102 on a @xmath103 lattice using vortex methods and spectral methods .",
    "the fmm - based vortex method used 4096 nvidia m2050 gpus on the tsubame 2.0 system and achieved 74% parallel efficiency , while the spectral method reached only 14% parallel efficiency on 4096 cpu cores @xcite .",
    "the wall - clock times of those simulations were 100 seconds per time step for both the vortex method and spectral method , showing that at this level of parallelism ( and with the help of gpu hardware ) , the fmm- and fft - based methods may start to compete .",
    "we have presented results of homogeneous isotropic turbulence with @xmath64 ( almost 17 million particles ) , at @xmath2 and 100 , using a vortex particle method and compared the results with a pseudo - spectral method with the same @xmath99 mesh . in particular , we have performed an array of parametric studies for the various parameters that affect the accuracy / efficiency of our vortex particle method .    we found that using a lower - order expansion in the fmm produces some noise at the higher frequency of the kinetic energy spectrum , but has little effect on the overall turbulence statistics .",
    "for example , with @xmath65 the noise at the tail of the spectrum is quite large , but the skewness and flatness of the velocity derivative show little deviation between @xmath104 6 , 8 , and 10 .",
    "the frequency of reinitialization plays and important role in assuring the overlap between vortex elements . for the case of homogenous isotropic turbulence",
    ", we observed that the homogeneity and isotropy of the flow permits infrequent remeshing to a larger extent than other turbulent flows . for the present overlap ratio of @xmath39 , the results of reinitializing every 10 steps are the same as reinitializing every 20 steps .",
    "one of the advantages of lagrangian vortex methods is said to be the use of larger time increments , @xmath11 .",
    "our studies show that high - order turbulence statistics can only be accurately calculated when @xmath11 is sufficiently small to resolve the small scales of turbulence . for this reason",
    ", we are only able to double @xmath11 from the stability limit of the spectral method , making the advantage quite moderate .",
    "this is with first - order euler integration , however , so the use of higher - order time integration schemes could allow even larger time step sizes .",
    "the comparison for different reynolds numbers reveals the effect of spatial resolution in vortex methods .",
    "we are able to provide , for the first time , quantitative results indicating the number of vortex particles that are needed to reproduce high - order turbulence statistics for a given reynolds number .",
    "our conclusion is that at least @xmath64 is necessary to obtain accurate velocity derivate skewness at @xmath86 .",
    "this conclusion applies to the vortex method with gaussian bases , which offer second - order convergence with respect to the core size .",
    "higher - order basis functions that should require less resolution are available , but they are very sensitive to particle overlap so the trade - off would need to be studied .",
    "these observations emphasize the importance of the choice of parameters when performing a vortex method simulation for turbulence .",
    "the relative efficiency of vortex methods depends heavily on each of these parameters , since adjusting them makes a large difference in the calculation runtime .",
    "although a quantitative assessment of the relative performance between vortex methods and spectral methods is beyond the scope of this paper , we are able to provide the necessary conditions for achieving the required accuracy .",
    "this information can be used to optimize the parameters in performance studies of vortex methods .",
    "our current results indicate that the spectral method is an order of magnitude faster than the vortex method when using a single gpu for the fmm and six cpu cores for the fft .",
    "our most recent results , to be published in a separate paper @xcite , show that as the number of gpus / cpus increases , the scalability of fmm compared to fft allows vortex methods to achieve higher parallel efficiency .",
    "the wall - clock time for solving with @xmath105 particles using the vortex method on 4096 gpus is comparable to that of spectral methods using the same number of points .    with these studies and our policy of open - source code , we are able to provide a lagrangian vortex method for the direct numerical simulation of turbulence that is validated and well understood , and results that are reproducible .",
    "the entire code that was used to obtain the present results is available from https://bitbucket.org/exafmm/exafmm .",
    "the revision number used for the present runs is 146 .",
    "documentation and links to other publications are found in the project homepage at http://exafmm.org/. the fact that we compare with a highly reliable reference  a pseudo - spectral method in one of the most commonly used benchmarks of turbulence provides a concrete starting point for further investigations regarding performance and scalability of the numerical engines .",
    "funding is acknowledged from nsf grant oci-0946441 , onr grant # n00014 - 11 - 1 - 0356 and nsf career award oci-1149784 .",
    "lab is also grateful for the support from nvidia corp .  via an academic partnership award",
    "we acknowledge the use of the ` hit3d ` pseudo - spectral dns code for isotropic turbulence , and appreciate greatly their authors for their open - source policy ; the code is available via google code at http://code.google.com / p / hit3d/. we thank anthony leonard , louis f. rossi and victor yakhot for helpful discussions during the revision of this paper .",
    "l.  a. barba .",
    "computing high - reynolds number vortical flows : a highly accurate method with a fully meshless formulation . in _",
    "parallel computational fluid dynamics  multidisciplinary applications _ , pages 305312 .",
    "elsevier b.  v. , 2005 .",
    "l.  a. barba , a.  leonard , and c.  b. allen .",
    "numerical investigations on the accuracy of the vortex method with and without remeshing . in _ 16th aiaa computational fluid dynamics conference _ , number aiaa 2003 - 3426 .",
    "american institute of aeronautics and astronautics , 2003 .",
    "s.  g. chumakov , j.  larsson , c.  schmitt , and h.  pitsch . lag - modeling approach for dissipation terms in large eddy simulation .",
    "annual research briefs , center for turbulence research , 2009 .",
    "http://www.stanford.edu/group/ctr/resbriefs/arb09.html .",
    "h.  gahvari and w.  d. gropp .",
    "an introductory exascale feasibility study for ffts and multigrid . in _ int .",
    "symposium on parallel & distributed processing ( ipdps ) _ , pages 19 , atlanta , ga , april 2010 .",
    "t.  hamada , t.  narumi , r.  yokota , k.  yasuoka , k.  nitadori , and m.  taiji .",
    "42 tflops hierarchical n - body simulations on gpus with applications in both astrophysics and turbulence . in _",
    "sc 09 : proceedings of the conference on high performance computing networking , storage and analysis _ , pages 112 .",
    "acm , 2009 .",
    "t.  ishihara , y.  kaneda , m.  yokokawa , k.  itakura , and a.  uno .",
    "small - scale statistics in high - resolution direct numerical simulation of turbulence : reynolds number dependence of one - point velocity gradient statistics . , 592:335366 , 2007 .",
    "van  rees , a.  leonard , di  pullin , and p.  koumoutsakos .",
    "a comparison of vortex and pseudo - spectral methods for the simulation of periodic vortical flows at high reynolds numbers .",
    ", 230(8):27942805 , 2011 .",
    "m.  yokokawa , k.  itakura , a.  uno , t.  ishihara , and y.  kaneda .",
    "16.4-tflops direct numerical simulation of turbulence by a fourier spectral method on the earth simulator . in _ supercomputing ,",
    "acm / ieee 2002 conference _ , pages 5050 .",
    "ieee , 2002 .",
    "rio yokota and l.  a. barba .",
    "treecode and fast multipole method for @xmath0-body simulation with cuda . in wen - mei hwu , editor ,",
    "_ gpu computing gems emerald edition _ , chapter  9 , pages 113132 .",
    "elsevier/ morgan kaufman , 2011 .",
    "preprint on http://arxiv.org/abs/1010.1482[arxiv:1010.1482 ] .",
    "rio yokota , l.  a. barba , tetsu narumi , and kenji yasuoka .",
    "petascale turbulence simulation using a highly parallel fast multipole method .",
    "accepted in _ comput .",
    "_ ; preprint on http://arxiv.org/abs/1106.5273 [ arxiv:1106.5273 ] ."
  ],
  "abstract_text": [
    "<S> the lagrangian vortex method offers an alternative numerical approach for direct numerical simulation of turbulence . the fact that it uses the fast multipole method ( fmm)a hierarchical algorithm for @xmath0-body problems with highly scalable parallel implementations  as numerical engine makes it a potentially good candidate for exascale systems . </S>",
    "<S> however , there have been few validation studies of lagrangian vortex simulations and the insufficient comparisons against standard dns codes has left ample room for skepticism . </S>",
    "<S> this paper presents a comparison between a lagrangian vortex method and a pseudo - spectral method for the simulation of decaying homogeneous isotropic turbulence . </S>",
    "<S> this flow field is chosen despite the fact that it is not the most favorable flow problem for particle methods ( which shine in wake flows or where vorticity is compact ) , due to the fact that it is ideal for the quantitative validation of dns codes . </S>",
    "<S> we use a @xmath1 grid with @xmath2 and 100 and look at the turbulence statistics , including high - order moments . </S>",
    "<S> the focus is on the effect of the various parameters in the vortex method , e.g. , order of fmm series expansion , frequency of reinitialization , overlap ratio and time step . </S>",
    "<S> the vortex method uses an fmm code ( ` exafmm ` ) that runs on gpu hardware using cuda , while the spectral code ( ` hit3d ` ) runs on cpu only . </S>",
    "<S> results indicate that , for this application ( and with the current code implementations ) , the spectral method is an order of magnitude faster than the vortex method when using a single gpu for the fmm and six cpu cores for the fft .    </S>",
    "<S> computational fluid dynamics , isotropic turbulence , spectral method , fast multipole method , gpu computing </S>"
  ]
}