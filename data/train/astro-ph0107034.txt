{
  "article_text": [
    "a recurrent statistical problem in astrophysical data analysis is to decide whether data are consistent with the predictions of a theoretical model .",
    "consider , as an example , the comparison between an observed power spectrum ( e.g. , of galaxies or clusters ) , where each data point gives a noisy estimate of the true power spectrum at a single wave number , and the functional form hypothesized by a specific cosmological model .",
    "one can test for overall differences between data and model using a statistical measure of discrepancy , such as a simple @xmath1 if the data are uncorrelated .",
    "if this discrepancy is sufficiently large , we conclude that there are `` significant '' differences beyond those accounted for by randomness in the data .",
    "this is an example of a statistical hypothesis test .",
    "however , this test indicates only whether the data and model differ overall ; it does not specify where or how they differ . to address such questions ,",
    "a single test is not enough .",
    "instead , one would need to perform multiple hypothesis tests , one at each wave number , based on the discrepancy between the data and model spectrum at that wave number .",
    "it is common , for example , to declare a test significant if the discrepancy is greater than twice the standard error of the measurement ; we call this the `` @xmath0 '' approach .",
    "this rule is calibrated to declare significance erroneously with probability about 0.05 .",
    "however , the probability of making such errors increases rapidly with the number of tests performed , so this calibration will typically be inappropriate for multiple testing .",
    "one can adjust , in part , by making the tests more stringent at each wave number , such as using a `` @xmath2 '' cut off .",
    "unfortunately , while this does reduce the probability of spurious detections , it also reduces ( often severely ) the probability of correctly detecting real deviations , especially those on the edge of detectability that can be most interesting .",
    "the need to perform multiple hypothesis tests , and the attendant difficulties , are ubiquitous in astronomy and astrophysics . in this paper",
    ", we present an effective method for multiple testing that improves the probability of correct detections over methods in current use while still controlling the probability of spurious detections .",
    "the method , due to benjamini & hochberg ( 1995 ) and the subject of much recent research in the statistical literature , bounds a particular measure of inaccuracy called the false discovery rate ( fdr ) .    we stress here that fdr is not a new testing technique but rather a method for combining the results of many tests of any kind .",
    "fdr is still relatively new in the statistical literature , but it has already been shown to possess several key advantages over existing methods :    * it has a higher probability of correctly detecting real deviations between model and data . *",
    "it controls a scientifically relevant quantity  the average fraction of false discoveries over the total number of discoveries . *",
    "only a trivial adjustment to the basic method is required to handle correlated data .    in section [ sec::mult - test",
    "] , we review statistical hypothesis testing and discuss the problems that arise when multiple tests are performed .",
    "we illustrate these ideas with the example of image source detection : how does one decide which pixels in a ccd image belong to the sky background and which are part of a source ? in section [ sec::fdr ] , we describe the fdr method in detail .",
    "section [ sec::sims ] gives simulation results based on the source - detection example that compare and contrast the available methods .",
    "sec::phys - examp ] describes how fdr is applied in a variety of other astrophysical examples .",
    "finally , section [ sec::disc ] discusses the role of fdr in astrophysical data analysis .",
    "we present a heuristic proof of the fdr procedure in appendix [ sec::fdrproof ] and a step by step worked example in appendix [ sec::wexamp ] .",
    "consider a common astronomical problem : source detection in images .",
    "each pixel in the image can be thought of as being mostly part of the background or mostly part of a source .",
    "we will call these `` background '' and `` source '' pixels , respectively . to illustrate hypothesis testing , we will focus in this section on the simplified problem of deciding , for each pixel , whether it is background or source .",
    "we will take up the full details of source detection ( _ e.g. _ , identifying stars and galaxies from the source pixels ) in a future paper ( hopkins et al .",
    ", in preparation ) .",
    "the data in the source detection problem is a measured photon count at every pixel .",
    "we expect the counts for source pixels to be larger ( on average ) than the counts for background pixels .",
    "hence , we select a critical threshold and classify a pixel as source ( background ) if its count lies above ( below ) that threshold .",
    "such a rule for classifying a pixel using the data is an example of a _ statistical hypothesis test_. we are deciding between two competing hypotheses : the _ null hypothesis _ that the pixel is background and the _ alternative hypothesis _ that the pixel is source .",
    "the test is performed by comparing a _ test statistic _ to a _",
    "critical threshold_. the test statistic is a function of the data whose probability distributions under the null and alternative hypotheses are as separated as possible . in source detection ,",
    "the test statistic might be , for example , the photon count minus the estimated background , divided by the standard deviation of the background counts .",
    "the choice of critical threshold determines the statistical properties of the test , as we will discuss below . if the test statistic is above the threshold , we _ reject _ the null hypothesis in favor of the alternative .",
    "otherwise , we _ maintain _ the null hypothesis because it is either true or because we can not detect that it is false with the available data .    in practice ,",
    "no matter what the threshold , we will incorrectly classify some pixels ( e.g. false positives or false negatives ) .",
    "we graphically represent this in figure [ fig::typeerror ] , where a threshold is set and null hypotheses with test statistics to the right of this threshold are rejected . in this example , we have mistakenly rejected one true null hypothesis , while we have maintained ( to the left of the threshold ) three real sources ( null hypothesis false ) .",
    "this illustrates the two types of errors we can make : ( i )  incorrectly identifying a background pixel as source and ( ii )  incorrectly identifying a source pixel as background . in the first case , we have erroneously _ rejected _ the null hypothesis when it is true . in the second case , we have erroneously maintained the null hypothesis when it is false .",
    "statisticians refer to these ( memorably ) as type i and type ii errors respectively .",
    "generally , statisticians talk about _ power _ rather than type ii error ; the power of a test is the probability of rejecting the null hypothesis given that it is false .",
    "the power is thus one minus the probability of a type ii error .",
    "one wants the power to be as high as possible , but there is a trade - off between power and the probability of a type i error : reducing one raises the other .    the trade - off between minimizing type i error and power is illustrated in figure [ fig::power ] . in the top panel",
    ", we show the null distribution ( i.e. the real background ) .",
    "we reject anything to the right of the threshold ( vertical line ) as a source .",
    "we will mistakenly identify the background data above the threshold as real sources , since our test rejects those data . as we raise the threshold ( for a fixed null distribution )",
    ", we minimize the number of type i errors ( false discoveries ) . in the bottom panel",
    ", we show the source ( alternative ) distribution .",
    "we identify sources as those data which lie to the right of the same threshold ( meaning that we will fail to identify real sources to the left of the threshold ) .",
    "if we raise the threshold ( which reduces false discoveries ) , we identify fewer real sources , i.e. there is a trade - off between the number of false discoveries and the power .    throughout this paper",
    ", we use the terms `` rejection '' , `` discovery '' , `` detection '' , and `` event '' interchangeably , based on what is clearest in context .",
    "thus , a type i error can be described as a `` false discovery '' or a `` false detection '' .",
    "similarly , we focus on power rather than the complementary probability of type ii errors , so we write `` correct discovery '' or `` correct detection '' for cases where the null hypothesis was rejected when it is false .    to clarify these ideas , we begin by considering a test of the null hypothesis at a single pixel in the source detection problem .",
    "it is common practice to choose a critical threshold that maximizes the power subject to capping the probability of a false detection ( i.e. , type i error ) at a pre - specified _ significance level _ @xmath3 .",
    "for example , if the test statistic has an approximately gaussian distribution then choosing @xmath4 is equivalent to using a `` @xmath0 '' threshold .",
    "see figure [ fig::pval ] for more on the relationship between @xmath3 and the critical threshold . a useful quantity to compute is the p - value .",
    "the p - value is defined as the probability _ when the null hypothesis is true _ of getting a test statistic ( e.g. , normalized photon count ) that is at least as extreme as the observed test statistic . as illustrated in figure [ fig::pval ] , there are two equivalent ways to decide whether to reject the null hypothesis : reject when the test statistic is bigger than the critical threshold or when the p - value is less than @xmath3 .",
    "next , consider how the situation changes when we test the null hypotheses at many different pixels simultaneously .",
    "we again select a critical threshold , or equivalently a significance level , and this threshold is applied as above at each pixel to reject or maintain the null hypothesis .",
    "however , because there are many tests being performed , there are many more ways to make errors .",
    "the following are commonly used approaches to multiple hypothesis testing , to which we will later compare the fdr method .    * naive multiple testing .",
    "use the same threshold ( e.g. @xmath0 ) as is used for a single test .",
    "* 3@xmath5 multiple testing .",
    "increase the threshold to something more stringent than naive thresholding , such as a 3@xmath5 cutoff , using the same threshold regardless of the number of tests . *",
    "the bonferroni method .",
    "reject any hypothesis whose p - value is less than @xmath6 , where @xmath7 is the number of tests .",
    "naive multiple testing rejects any pixel whose p - value is less than the @xmath3 defined as for a single test . unfortunately , this leads to a higher than expected rate of making type i errors : the chance of at least one false rejection over the many pixels is much larger than @xmath3 .",
    "for example , if @xmath4 and there are 10,000 pixels , then the chance of at least one false discovery is @xmath8 .",
    "this naturally leads to the idea of increasing the critical threshold ( i.e. , @xmath5-cutoff ) to make the test at each pixel more stringent .",
    "as shown in figure [ fig::pval ] , increasing the threshold is equivalent to replacing the significance level @xmath3 by a smaller number @xmath9 .",
    "for example , choosing @xmath10 corresponds to using a @xmath2 cutoff .",
    "( because this choice is so common in astrophysical data analysis , we call this `` @xmath2 '' multiple testing . ) while this adjustment does reduce the average number of false discoveries relative to naive multiple testing , it has the same problem : the probability of making a false discovery is typically much larger than the desired significance level @xmath3 .",
    "the difference is that this probability grows more slowly with the number of tests .",
    "for example , with @xmath4 and @xmath10 and @xmath11 , the probability of at least one false discovery is @xmath12 for naive multiple testing and is @xmath13 for @xmath2 multiple testing .",
    "when @xmath14 , both probabilities are larger than @xmath15 .",
    "the same argument applies to any critical threshold that is fixed relative to the number of tests @xmath7 and suggests that one should increase the threshold with @xmath7 .",
    "this is equivalent to choosing a significance level @xmath16 as a function of @xmath7 .",
    "the bonferroni method takes @xmath17 .",
    "it can be shown that bonferroni guarantees that the probability of making at least one false rejection is no greater than @xmath3 .",
    "unfortunately , this control on false rejections comes at a high cost : the probability of erroneously maintaining the null hypothesis goes to one as @xmath7 gets large .    to summarize , in the naive ( @xmath0 ) multiple testing",
    ", we allow many false discoveries in return for more correct detections . in the bonferroni method",
    ", we tightly control the propensity for making false discoveries but as a result tend to miss many real detections .",
    "these two methods represent the opposite extremes .",
    "naive and @xmath2 multiple testing are the typical methods of choice in astrophysical data analysis , but although the latter is more stringent , both suffer the same fate when the number of tests is large . with the vast data sets being acquired today ,",
    "this is a common and potentially severe problem .",
    "methods that control the false discovery rate , described in the next section , are intermediate between these extremes .",
    "these methods adapt to the size of the data to give control of false discoveries comparable to the fixed threshold methods while maintaining good power .",
    "the solution that we put forward in this paper is the false discovery rate ( fdr ) method due to benjamini & hochberg ( 1995 ) .",
    "fdr improves on existing methods for multiple testing : it has higher power than bonferroni , it controls errors better than the naive method , and it is more adaptive than the @xmath2 method .",
    "moreover , the fdr method controls a measure of error that is more scientifically relevant than other multiple testing procedures .",
    "specifically , naive testing controls the fraction of errors _ among those tests for which the null hypothesis is true _ whereas fdr controls the fraction of errors _ among those tests for which the null hypothesis is rejected_. since we do not know _ a priori _ the number of true null hypotheses but we do know the number of rejections , the latter is easier to understand and evaluate .",
    "suppose we perform @xmath7 hypothesis tests .",
    "we can classify these tests into four categories as follows , according to whether the null hypothesis is rejected and whether the null hypothesis is true : @xmath18 the columns in table 1 are the results of our testing procedure ( in which we either maintain or reject a test ) .",
    "the rows in table 1 are the true numbers of source ( null false ) and background ( null true ) pixels .",
    "for example , @xmath19 is the number of false discoveries , @xmath20 is the number of correct discoveries , @xmath21 is the number of correctly maintained hypotheses , and @xmath22 is the number of falsely maintained hypotheses .",
    "we thus define the false discovery rate fdr to be @xmath23 where fdr is taken to be 0 if there are no rejections .",
    "this is the fraction of rejected hypotheses that are false discoveries .",
    "in contrast to bonferroni , which seeks to control the chance of even a single false discovery among _ all _ the tests performed , the fdr method controls the proportion of errors among those tests whose null hypotheses were rejected .",
    "thus , fdr attains higher power by controlling the most relevant errors .",
    "we first select an @xmath24 .",
    "the fdr procedure described below guarantees , where the right - hand side is always @xmath25 . if the test statistic has a continuous distribution , the first inequality is also an equality . ] that @xmath26 in contrast , the naive and @xmath2 multiple testing procedures guarantee that @xmath27 where pfd ( `` proportion of false discoveries '' ) equals @xmath28 and where , for instance , @xmath4 for a @xmath0 cutoff and @xmath29 for a @xmath2 cutoff . similarly",
    ", the bonferroni method guarantees that @xmath30 where @xmath31 ( `` any false discoveries ? '' ) equals 1 if @xmath32 and 0 if @xmath33 .",
    "the expectations @xmath34 in all these expressions represent ensemble averages over replications of the data .",
    "note that , like any statistical procedure , all these methods control an ensemble average ; they do not guarantee that the realized value is less than @xmath3 on any one data analysis .",
    "the fdr procedure is as follows .",
    "we first select an @xmath24 .",
    "let @xmath35 denote the p - values from the @xmath7 tests , listed from smallest to largest .",
    "let @xmath36 where @xmath37 is a constant defined below .",
    "now reject all hypotheses whose p - values are less than or equal to @xmath38 . note that every null hypothesis with @xmath39 less than @xmath38 is rejected even if @xmath39 is not less than @xmath40 .",
    "graphically , this procedure corresponds to plotting the @xmath39s versus @xmath41 , superimposing the line through the origin of slope @xmath42 , and finding the last point at which @xmath39 falls below the line .    when the p - values are based on statistically independent tests , we take @xmath43 .",
    "if the tests are dependent , we take @xmath44 note that in the dependent case , @xmath37 only increases logarithmically with the number of tests .",
    "the fact that this procedure guarantees that ( eqn . [ eq::fdr ] ) holds is not obvious . for the somewhat technical proof",
    ", the reader is referred to benjamini & hochberg ( 1995 ) and benjamini & yekutieli ( 1999 ) .",
    "we give a heuristic argument for a special case in appendix [ sec::fdrproof ] .",
    "we also provide a simple step - by - step tutorial and sample code that may be easily implemented in appendix [ sec::wexamp ]",
    "consider a stylized version of the source detection problem with a 1,000 by 1,000 image where the measurement at each pixel follows a gaussian distribution . for simplicity",
    ", we assume here that each source is a single pixel and thus the pixels are uncorrelated , though we return to this issue in section [ sec::hubbledf ] .",
    "we assume that the distribution for background pixels has a mean @xmath45 and a standard deviation @xmath46 , and that the distribution for source pixels has a mean @xmath47 and a standard deviation @xmath48 .",
    "we perform a test at each of the @xmath49 pixels .",
    "we use 960,000 background pixels and 40,000 source pixels . the null hypothesis for pixel @xmath50",
    "is that it is a background pixel ; the alternative hypothesis for pixel @xmath50 is that it is a source pixel .",
    "the p - value for pixel @xmath50 is the probability that a background pixel will have intensity @xmath51 or greater : @xmath52 we repeated the simulation 100 times and taking the average counts . in table 2",
    ", we present our results when trying to recover the original sources in uncorrelated noise .",
    "notice that the @xmath0 technique produces 53100 events ( or discoveries ) , of which 40% are in reality false .",
    "while the bonferroni technique produces zero false discoveries , it only finds 27138 sources out of 40,000 in the image .",
    "the fdr technique yields nearly as many real source detections as the @xmath0 technique , and only 1505 false discoveries , a factor of 15 fewer than @xmath0 .",
    "we stress here that this advantage over the @xmath0 technique is a direct result of the adaptive nature of fdr and comes at no cost to the user .",
    "this example illustrates the worth of fdr in helping the statistical discovery in astrophysics , and we thus champion its use throughout the community .",
    "cccccc @xmath53 & @xmath54 & 30389 & 1505 &  9611 & 958495 2@xmath5 & @xmath55 & 31497 & 22728 &  8503 & 937272 @xmath56 & @xmath57 & 27137 & 0 & 12863 & 960000    to show how the fdr procedure adapts , we perform this same simulation using different alternative ( or source ) distributions .",
    "in particular , we increase the mean intensity of the source pixels over a range from 1500 to 3000 counts per pixel , that is from values that are close to the background ( sky ) mean to values that are well separated from the background ( sky ) mean .",
    "figure [ fig::fdrmonte ] , displays the results of four such simulations .",
    "notice that the fdr method adapts to the data : the p - value cutoff changes systematically as the source intensity changes .",
    "also notice in this figure that the recovery rate of fdr is nearly that of the much more liberal @xmath0 method , and always greater than the ultra- conservative bonferroni technique .",
    "the average false discovery rate over the simulation is @xmath58 for the fdr method , as it should be , and is zero for bonferroni .",
    "the false discovery rate for the @xmath0 method varies widely but never gets below 35% , even when the source and background distributions are entirely separated .",
    "we stress again that this problem can not be solved by simply increasing the threshold to , say , @xmath2 since one then trades a low false rejection rate for power in detecting real rejections .",
    "in this section , we show two applications of the fdr procedure to astrophysical data .",
    "specifically , we consider the one - dimensional power spectrum of the distribution of galaxies and clusters in the universe and source detection in a two - dimensional image of the sky . however , fdr can be applied to any problem involving multiple hypothesis testing .      during its first @xmath59 years",
    ", the universe was a fully ionized plasma with a tight coupling between the photons and matter via thompson scattering .",
    "a direct consequence of this coupling is the acoustic oscillation of both the primordial temperature and density fluctuations ( within the horizon ) caused by the trade  off between gravitational collapse and photon pressure .",
    "the relics of these acoustic oscillations are predicted to be visible in both the matter and radiation distributions , with their relative amplitudes and locations providing a powerful constraint on the cosmological parameters ( _ e.g. _ @xmath60 ) .",
    "recently , the boomerang and maxima teams announced the first high confidence detection of these acoustic oscillations in the temperature power spectrum of the cosmic microwave background ( cmb ) radiation ( netterfield et al .",
    "2001 , lee et al .",
    "recently , miller , nichol , & batuski ( 2001 ) used fdr to show that the corresponding acoustic oscillations are in the matter power spectra of three independent large - scale structure datasets .",
    "in figure [ fig::baryons ] ( left ) we plot @xmath61 , the power spectrum , for the three large - scale structure samples described in miller et al . 2001 .",
    "the solid line is the smooth , featureless , null - hypothesis as discussed in miller et al .",
    "the circled points are rejected using the fdr procedure with @xmath62 , while the points outlined with squares are rejected with @xmath63 .",
    "we detect the `` valleys '' at both @xmath64mpc@xmath65 and at @xmath66mpc@xmath65 . with @xmath67",
    ", we only reject five point , while with @xmath68 we reject eight points .",
    "the properties of the fdr bound suggest the fluctuations are true outliers against a smooth , featureless spectrum .",
    "note that each of the three data sets contributes to the features , and so the detection is not dominated by one sample . in the right panel , we plot the p - value versus index for the combined lss dataset .",
    "the solid red line is for @xmath62 , and anything to the left of the vertical blue dotted line is detected as being part of a feature in the power spectrum with a maximum false discovery rate of 0.25 .    as discussed in miller et al .",
    "2001 , the use of fdr improves our ability to detect these features in these three power spectra .",
    "this would not have been as convincing if we had used the usual `` @xmath0 '' procedure of multiple hypothesis testing _",
    "i.e. _ demanding that all the points in the `` valleys '' in the @xmath61 ( figure [ fig::baryons ] ) be greater than @xmath0 from a smooth function .      in section [ sec::sims ] , we showed the results of using fdr on a simulated image of the sky ( with sources in gaussian background ) . here",
    ", we will utilize fdr on the image created by szalay , connolly , and szokoly ( 1999 ) , who applied a novel source detection algorithm to the hubble deep field ( hdf ) .",
    "the basis for the szalay et al .",
    "analysis is straightforward : for an uncorrelated set of images with zero mean and unit variance ( i.e. the normalized sky ) the probability distribution of the pixel values forms a chi - square distribution .",
    "they combine the individual pass bands from the hdf into one image used for source pixel detection .",
    "however , instead of summing ( with or without weights ) the individual colors images , szalay et al .",
    "build up a @xmath1 ( or @xmath69-image ) .",
    "this @xmath69-image is constructed by calculating @xmath1 for @xmath70 degrees - of - freedom ( where @xmath70 equals the number of pass - bands ) .",
    "the source pixels are in a pre - determined background with a well known error in each band .",
    "each pixel in the @xmath69-images is then a @xmath1 value with @xmath70 degrees of freedom .",
    "the chi - square construction provides an almost optimal use of the color information .",
    "szalay et al .",
    "provide some nice examples of how source pixels are `` amplified '' compared to the individual pass - bands ( see their figure 5 ) .",
    "the next step in szalay et al .",
    "( 1999 ) was to determine the threshold in @xmath1 space ( probability space ) above ( below ) which a pixel can be considered statistically above the background .",
    "szalay use the so - called optimal bayes threshold , i.e. the threshold that chooses the class with maximal posterior probability .",
    "szalay et al .",
    "determine that the `` best '' threshold is for a @xmath1 value @xmath71 .",
    "if we convert from @xmath1 to the probability of randomly finding a pixel with this @xmath1 or higher , we find the p - value equals @xmath72 .",
    "this p - value threshold , which is highlighted in table 3 , corresponds ( in gaussian terms ) to a 2.42@xmath5 detection per pixel . in table 3 , we show how varying degrees of @xmath3 correspond to the false discovery rate using the methods described in this paper . in other words , we can use the fdr procedure to place bounds on the false discovery rate for past analyses that used standard thresholding techniques .",
    "note in table 3 that the cut - off used by szalay et al . corresponds to a false discovery of 11% .",
    "this means that , of the total number of source pixels used to find galaxies in the @xmath69-image , 11% could be in error ( on average ) . therefore the bayes threshold that they applied did not introduce a large amount of false discoveries . in figure",
    "[ fig::hdf ] , we plot the rejected pixels for two different @xmath3 s in a piece of the @xmath69-image .",
    "the above example shows how the fdr procedure provides a much more relevant ( and useful ) quantity : a bound on the fraction of false discoveries out of the total number of source pixel detections .",
    "if the derived false discovery rate had been extremely high ( say 50% ) , than their bayes threshold used would have been too low , and their conclusions less reliable . however , this was not the case .",
    "unfortunately , standard thresholding techniques do not provide this information . in the above example",
    ", we assumed that the individual pixels are uncorrelated .",
    "this is not entirely true , since the point spread function for the hst will result in correlations between blocks of 10 or so pixels .",
    "also , true sources ( e.g. galaxies ) must have a minimum number of connected source pixels ( which are physically correlated ) .",
    "we could also use fdr with the factor ( @xmath37 ) for correlations included . in a future work ( see e.g. hopkins et al . in preparation ) , we will examine in greater detail the process of accounting for these correlations in the fdr procedure .",
    "cccc 0.150 & 0.01172 & 2.27@xmath5 & 78122 & * 0.00761 * & * 2.42@xmath5 * & * 70444 * 0.100 & 0.00688 & 2.46@xmath5 & 68882 0.050 & 0.00294 & 2.75@xmath5 & 58598 0.010 & 0.00047 & 3.31@xmath5 & 46878",
    "the methods discussed in this paper are frequentist ( non - bayesian ) methods .",
    "readers who are familiar with bayesian inference might ask if there are bayesian analogs of the fdr procedure .",
    "indeed , one can construct a bayesian version of the fdr procedure .",
    "for example , let @xmath73 mean that the null hypothesis holds for the @xmath74 hypothesis and let @xmath75 mean that the alternative hypothesis holds for the @xmath74 hypothesis .",
    "let @xmath76 denote the vector of p - values . by bayes theorem , the posterior probability that @xmath75 is @xmath77 where @xmath78 is the density of p - values under the null hypothesis and @xmath79 is the density of p - values under the alternative hypothesis ( indexed by a vector of parameters @xmath80 ) , @xmath81 is the prior probability that a null hypothesis is false and @xmath82 is the posterior for the parameters @xmath83 and @xmath80 given by @xmath84 where the sum is over all vectors @xmath85 of length @xmath70 consisting of 0 s and 1 s and @xmath86 is a prior on @xmath83 and @xmath80 .",
    "( we have expressed this in terms of p - values to be consistent with the rest of the paper but the expressions can be written in terms of the test statistics directly . ) using similar calculations , one can derive a bayesian posterior probability on the false discovery rate of a given set of hypotheses . developing these ideas",
    "further and comparing them to the non - bayesian method discussed in this paper will be the subject of future work .",
    "we will make two points , however .",
    "first , as always , the bayesian approach requires more assumptions , for example , specification of the form of @xmath87 and the prior @xmath86 .",
    "second , in estimation problems , bayesian and non - bayesian methods agree in large samples .",
    "for example , an interval with bayesian posterior probability 0.95 will cover the true parameter value with frequency probability 0.95 + @xmath88 where @xmath70 is sample size . a well known fact in statistics",
    "is that this agreement between bayes and non - bayes methods breaks down in hypothesis testing situations .",
    "indeed , this is the source of much debate in statistics .",
    "this is not meant to speak for or against the bayesian approach but merely to warn the reader that there are subtle issues to consider ( see genovese and wasserman ( 2001 ) for more details ) .",
    "in this paper , we have introduced the false discovery rate ( fdr ) to the astronomical community .",
    "we believe this method of performing multiple hypothesis testing on data is superior to the `` @xmath0 '' method commonly used within astrophysics .",
    "we say this for two reasons : _",
    "i ) _ fdr is adaptive to the number of tests performed and thus provides the same power as the usual `` @xmath0 '' test , but with a greatly reduced false rejection rate ( see the simulations in section 5 ) ; _ ii ) _ correlated errors are easy to incorporate into fdr which is of great benefit to many astronomical analyses . to help aid the reader , we have provided several examples of how to use fdr and a tutorial on how to implement fdr within data analyses .",
    "we hope that the astronomical community will use this powerful new tool .",
    "the authors would like to thank eric gawiser for his comments and suggestions .",
    "this work was support in part by nsf kdi grant xxxxxxx and by nsf grant ses-9866147 .",
    "benjamini , y. , hochberg , y. 1995 , j. r. stat .",
    "b , 57 , 289    benjamini , y. , yekutieli 1999 , j. stat . plan .",
    ", 82 , 171    genovese , c. and wasserman , l. 2001 , cmu technical reports , 737 , http://lib.stat.cmu.edu/www/cmu-stats/tr/ , submitted to j. r. stat .",
    "b.    lee et al .",
    "2001 , astro - ph/0104459    miller , c.j . ,",
    "nichol , r.c . ,",
    "batuski , d.j .",
    "2001 , apj in press , astro - ph/103018    netterfield et al .",
    "2001 , submitted to apj , astro - ph/0104460    szalay , a.  s. , connolly , a.  s. j. , & szokoly , g.  p.  1999 , aj , 117 , 68",
    "in this appendix , we provide an illustrative proof of the false discovery rate procedure . this heuristic proof is not intended to replace the full treatment given in benjamini and hochberg ( 1995 ) .",
    "we consider one very simple case with non - overlapping source and null distributions .",
    "we can compare this simple scenario to fig .",
    "[ fig::fdrmonte ] .",
    "we dictate two distinct intensity distributions , @xmath89 and @xmath90 for the background and source pixels respectively .",
    "the differential distributions are shown in fig .",
    "[ fig::dist ] .",
    "the distribution of source intensities is entirely separated from those of the background .",
    "let @xmath91 be the cumulative distribution function for the background intensity .",
    "the p - values are then @xmath92 for a given test statistic , @xmath93 . since the intensities of the sources are so high compared to the background , @xmath94 for the @xmath50 sources .",
    "what we would like to know is the distribution of @xmath95 for many realizations of the test statistic , @xmath93 .",
    "let @xmath96 denote @xmath95 , which is a random variable between zero and one ( since @xmath91 is a cumulative distribution ) .",
    "now , consider the cumulative distribution function for random variable @xmath96 : @xmath97 we can derive @xmath98 for all @xmath99 by considering the the following regimes : @xmath100 the final regime needs some explanation .",
    "since @xmath91 is a cumulative distribution function , it is monotonically increasing and continuous .",
    "this means that @xmath91 has an inverse function , @xmath101 which is also monotonically increasing .",
    "we can apply this inverse function in the following way : @xmath102 in words , the cumulative distribution function for the random variable @xmath96 is between zero and one and increases linearly with slope one .",
    "the probability density of @xmath96 is then @xmath103 for @xmath104 , and zero elsewhere .",
    "therefore , the distribution of @xmath105 is uniform between between zero and one .    in our very simple case ( with two entirely separated distributions )",
    ", we will perform the fdr procedure by sorting the p - values . recall that the p - values for the source distribution are so small that we take them to be zero .",
    "the p - values for the background are drawn from the probability density function for random variable @xmath105 .",
    "since the distribution of @xmath95 is uniform , the distribution of each p - value , @xmath106 , is also uniform . but what will a plot of the @xmath70 ordered p - values look like ? we need to first determine the density function and fortunately , there is a theorem in order statistics which states :    _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ let @xmath107 be independent identically distributed continuous random variables with common distribution function @xmath108 and common density function @xmath109 .",
    "if @xmath110 denotes the @xmath50th - order statistic , then the density function of @xmath110 is given by : @xmath111^{n - i}h(u_i)\\ ] ] _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _    for our case , @xmath112 , as shown above in equation ( a3 ) .",
    "if we replace @xmath113 with @xmath114 in the above equation , we simply have a beta distribution , @xmath115 where @xmath116 and @xmath117 .",
    "the beta distribution has an expectation value of @xmath118 and so : @xmath119 for the @xmath70 p - values .",
    "now , we know the expected values of all of the p - values in this simple example .",
    "the sources have @xmath120 while the background pixels have @xmath121 .",
    "the sorted p - values are shown in fig .",
    "[ fig::app_pval ] , where we have overplotted the line @xmath122 where @xmath67 . in this figure ,",
    "the probability below which we reject all pixels ( as background ) , occurs at the first undercrossing between the line and the p - values ( working from the right ) .",
    "the horizontal line indicates this cutoff probability ( p - cutoff ) .",
    "however , we know that all of the real source pixels have p - values set to zero , and so we are rejecting some pixels that are truly background ( those pixels with @xmath123 ) .",
    "we now wish to show that the fraction of these mistakenly rejected background pixels is equal to @xmath3 .",
    "we can do this many ways by simply counting the number of tests with p - values in this region ( 10 ) and comparing to the total number of rejections ( 100 ) , by geometrical arguments , or by examining the value of the probability cutoff . for instance , over a large number of realizations of the intensities , we know that @xmath124 but we also know that any p - value is the probability of finding a background pixel with @xmath125 .",
    "so we may also write : @xmath126 where @xmath127 means the index of the p - value below which we reject all tests as sources",
    ". we can now set equations ( a6 ) and ( a7 ) equal and solve for @xmath3 .",
    "as expected , we find : @xmath128",
    "suppose we conduct ten tests leading to the following p - values :                  step 4 .",
    "find the largest index ( from 1 to 10 ) for which the corresponding number in step 3 is negative . in this example , it is the 5th p - value @xmath131 corresponding to the difference @xmath132 .",
    "note that this step corresponds to finding the largest @xmath133 such that @xmath134 .",
    "reject all null hypothesis whose p - values are less than or equal to @xmath131 . the null hypothesis for the other tests are not rejected .",
    "thus , in this example , the hypothesis with p - values 0.0010 , 0.0060 , 0.0180 , 0.0210 , and 0.0230 are rejected .",
    "the procedure is illustrated in figure [ fig::fdr ] .",
    "[ note that the p - values in figure [ fig::fdr ] are not the same as those used in this step by step procedure . ]"
  ],
  "abstract_text": [
    "<S> the false discovery rate ( fdr ) is a new statistical procedure to control the number of mistakes made when performing multiple hypothesis tests , _ i.e. _ when comparing many data against a given model hypothesis . </S>",
    "<S> the key advantage of fdr is that it allows one to _ a priori _ control the average fraction of false rejections made ( when comparing to the null hypothesis ) over the total number of rejections performed . </S>",
    "<S> we compare fdr to the standard procedure of rejecting all tests that do not match the null hypothesis above some arbitrarily chosen confidence limit , _ e.g. _ </S>",
    "<S> @xmath0 , or at the 95% confidence level . </S>",
    "<S> we find a similar rate of correct detections , but with signicantly fewer false detections . </S>",
    "<S> moreover , the fdr procedure is quick and easy to compute and can be trivially adapted to work with correlated data . </S>",
    "<S> the purpose of this paper is to introduce the fdr procedure to the astrophysics community . </S>",
    "<S> we illustrate the power of fdr through several astronomical examples , including the detection of features against a smooth one - dimensional function , _ </S>",
    "<S> e.g. _ seeing the `` baryon wiggles '' in a power spectrum of matter fluctuations , and source pixel detection in imaging data . in this era of large datasets and high precision measurements </S>",
    "<S> , fdr provides the means to adaptively control a scientifically meaningful quantity  </S>",
    "<S> the number of false discoveries made conducting multiple hypothesis tests . </S>"
  ]
}