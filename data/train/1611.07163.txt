{
  "article_text": [
    "this section describes the terms used in this paper .",
    "a _ unit test _ examines a small unit of code ( usually a method or a class ) .",
    "it consists of a sequence of method calls and assertions that verify that the computed results of the invocations equal the expected ones .",
    "a unit test can also check the absence of thrown exceptions for a given program flow .",
    "a _ system test _ examines a complete software system , which may consist of several components . unlike a unit test",
    ", it covers many methods by executing a large proportion of the whole system .",
    "a system test often triggers the execution of a large functionality and compares the end result ( which can be aggregated data , a report , or a log file ) with the expected one .",
    "_ code coverage _ is a metric that expresses which ratio of application code of a software project is executed when running all test cases .",
    "it can be computed at different levels ; widely used are measures at method / function , statement or branch level .",
    "when we refer to code coverage in this paper , we mean method coverage .",
    "it corresponds to the ratio of methods that are executed by tests .",
    "we consider a method to be _ test - executed _ if it is covered by at least one test case .",
    "a test - executed method is considered _ tested _ if at least one covering test case fails when the whole logic of the method is removed .",
    "in contrast , a test - executed method is considered _ pseudo - tested _ if none of the covering test cases fails when the whole logic of the method is removed .",
    "we define _ test effectiveness _ as the capability of test cases to detect regression faults in methods that they execute .",
    "intuitively , we understand the overall ratio of code that is effectively tested as the upper bound of the probability that test cases detect a novel regression fault in a project .",
    "this paper is based on the master s thesis of the first author @xcite .",
    "related work is in the areas of code coverage , test suite effectiveness and mutation testing .",
    "wong , horgan , london and mathur @xcite showed that the correlation between fault detection effectiveness and block coverage is higher than between effectiveness and the size of the test set .",
    "this indicates that coverage can be a valid measure for test effectiveness .",
    "however , they did not differentiate between different test types .",
    "in @xcite , andrew , briand , labiche and namin conducted an empirical study on one industrial program with known faults to investigate test coverage criteria on fault - detection effectiveness .",
    "their results showed that no one coverage criteria is more cost - effective than any other , but more demanding criteria lead to larger test suites that detect more faults .",
    "in contrast , we analyzed open - source systems and made use of mutation testing .    in @xcite , mockus , nagappan and",
    "dinh - trong revealed that an increase in coverage exponentially increases the test effort and linearly reduces the field problems .",
    "they suggested that `` code coverage is a sensible and practical measure of test effectiveness '' , but did not differentiate between unit and system tests .",
    "namin and andrews @xcite studied the relationship between size , coverage , and fault - finding effectiveness of test suites .",
    "they found that both size and coverage are important for effectiveness and suggested a nonlinear relationship between them .",
    "they analyzed very small c programs ( the largest one consisted of less than 6,000 lines of code ) .",
    "inozemtseva and holmes @xcite came to different conclusions .",
    "they evaluated the relationship between test suite size , coverage , and effectiveness for java programs .",
    "they found that : `` high levels of coverage do not indicate that a test suite is effective . ''",
    "in addition , they discovered that the type of coverage had little effect on the correlation between coverage and effectiveness .",
    "they also used mutation testing , but they generated test suites of a fixed size by randomly selecting test cases .",
    "marick @xcite critically analyzed code coverage as a metric for test effectiveness .",
    "he showed how code coverage is commonly misused and argued for a cautious approach to the use of coverage .",
    "his work did not assess the validity of code coverage as effectiveness indicator .",
    "mutation testing was first proposed in the 1970s and is an established , powerful technique to evaluate test suites .",
    "the general principle is to generate mutants by introducing faults into a program and check if the tests can detect ( _ kill _ ) these .",
    "experimental studies ( @xcite , @xcite , @xcite , @xcite ) provide evidence that mutation testing is a good indicator for the fault - detection capability of test suites .",
    "mutation testing has two major drawbacks , which explain why it is not widely used in practice .",
    "first , the computational costs are high because mutation testing involves creating a large number of mutants and the execution of all tests that cover the mutated code chunk for each mutant .",
    "second , some of the generated mutants are semantically equivalent to the original code .",
    "the so - called _ equivalent mutants _ do not represent injected faults , can not be killed by tests and so distort the results .",
    "the detection of these mutants is generally undecidable .",
    "grn , schuler and zeller @xcite identified equivalent mutants as an important problem because they are surprisingly common .",
    "our approach addressed these issues and is explained in the next section .",
    "the general idea is to apply mutation testing as mean to collect data for assessing test effectiveness .",
    "we used an extreme mutation operator in which we eliminated the whole logic from a method and determined whether or not a method is pseudo - tested .",
    "therefore , we got around the two drawbacks of mutation testing ( mentioned in section [ subsection_related_work_mutation_testing ] ) .",
    "first , we created , at most , two different mutants for a method , keeping the number of mutants manageable and the execution time for analyzing a medium - sized software project within a few hours .",
    "second , the mutation operator radically changes the methods and generates less equivalent mutants .",
    "the majority of the generated equivalent mutants can be identified automatically .",
    "our approach consists of four steps and is depicted in figure [ figure_mutation_process ] .",
    "the first two steps are executed once and are necessary to collect information about the test cases .",
    "the latter two steps comprise the actual mutation process .",
    "they are executed for each method under test and can be run concurrently .",
    "+ in _ step 1 _ , the project code is instrumented .",
    "this is done by inserting logging statements .",
    "+ in _ step 2 _ , all test cases are executed once on the instrumented code .",
    "this allows us to determine the relationships between test cases and methods . from the information of the test - executed methods for a given test case , the opposite direction of the relation ( all test cases covering a given method ) can be computed .",
    "test cases that fail at this point are excluded from further analysis .",
    "+ in _ step 3 _ , the mutation of one method under test is performed .",
    "the mutation operator removes the whole logic of the method .",
    "this is done as follows :    * for void methods , all statements are removed .",
    "no further actions are necessary . * for methods that return a primitive or a string value ,",
    "two mutants are generated .",
    "the mutation removes the original code by replacing it with a return statement .",
    "the value to be returned depends on the return type and is different for both created mutants .",
    "table [ tbl : simple_return_value_generators ] lists the return values for the primitive types and string .",
    "note that it is sufficient for a method to be considered as tested if at least one of the two mutants can be killed by any of the test cases . * for methods that return an object ,",
    "a factory is used to generate a suitable instance .",
    "the original code is removed and the generated instance is returned .",
    "we developed factories for three study objects ( see section [ subsection_experiment_procedure ] ) .",
    ".return values for primitive types and string [ cols=\"<,<,<\",options=\"header \" , ]     [ table_results_pseudo_tested ]    * rq 2 : does the ratio of pseudo - tested methods depend on the type of test ? * + the mean ratio of pseudo - tested methods of the study objects differs for unit and system tests .",
    "the mean ratio was 11.41% for unit tests and 35.48% for system tests .",
    "it is striking that the ratio is within a small range for unit tests but greatly deviates among systems tests .",
    "the standard deviation of the ratio of pseudo - tested methods ( 6.42% for unit and 20.60% for system tests ) confirms this observation .",
    "the boxplot in figure [ figure_rq_1_2_boxplot ] depicts the key figures and the deviation between unit and system tests .",
    "the results show that the type of test influences the ratio of pseudo - tested methods .",
    "* rq 3 : how severe are the pseudo - tested methods ? * + figure [ figure_rq_1_3_barchart ] presents the absolute and relative number of pseudo - tested methods , grouped by severity . for 11 study objects ,",
    "more than half of the pseudo - tested methods were of medium or high severity .",
    "this was not the case for _ apache commons math _ , which contains a significant amount of irrelevant pseudo - tested methods ( some test utility methods were mutated in the analysis ) ; and _ apache commons lang _ as well as _",
    "conqat lib commons _ with some low - importance methods .",
    "the results confirm the relevance of pseudo - tested methods and suggest that the lack of test effectiveness is a problem for a software project .",
    "we separated the threats to validity into internal and external threats .",
    "the threats to internal validity comprise reasons why the results could be invalid for the study objects .",
    "one threat to the internal validity is that some methods considered pseudo - tested might actually result in equivalent mutants .",
    "we tried to mitigate this issue by the choice of the mutation operator and additional filtering .",
    "the mutation operator modifies the whole method body , while many common operators only mutate single lines , and is therefore less likely to create an equivalent mutant .",
    "additionally , we filtered out empty and trivial methods such as one - line setters and getters ( see section [ section_mutation_approach ] ) .",
    "as we generated two mutants for methods with primitive or string return types , the results were not distorted if only one mutants was equivalent .",
    "we manually reviewed a random sample to make sure that the number of remaining undetected equivalent mutants was negligible .",
    "study objects with test cases that fail on the original code are a further threat to internal validity .",
    "this can happen because of the test environment or faulty code in the study object .",
    "some test cases rely on further data stored in files , a database with a certain data model and content , other connected systems , or the network connection .",
    "we tried to supply all the needed and available files in the test execution folder and set up the databases according to the project manuals . nevertheless , some test cases still failed .",
    "this was the case for the _ apache commons net _ project , which presumably required certain firewall settings for some of its test cases .",
    "we excluded these failing test cases from the analysis . if the excluded test cases had worked , they might have killed some mutants that were not killed by the other test cases ( and therefore categorized as pseudo - tested ) . for this reason , we only selected projects as study objects in which most test cases could be successfully executed on the original code .",
    "another threat to internal validity is custom class loaders that could interfere with the test execution on mutated code and affect the results in some seldom cases .",
    "this may occur if a class is loaded multiple times by different class loaders during the execution of a single test case . in this case",
    ", another class version is loaded in addition to the mutated one .",
    "we consider this threat to be negligible .",
    "one threat regarding the definition of test effectiveness is the fact that test cases can reveal faults that cause an exception to be thrown , even in pseudo - tested methods ( that are considered as not effectively tested ) .    concerning research question 3 ,",
    "the categorization of pseudo - tested methods according to their purpose was performed by considering the method name . due to the high number of methods ,",
    "it was not feasible to inspect all the code to determine their purpose . therefore , some methods might actually belong to another category and severity than the assigned one .",
    "the external validity concerns the generalization of the results of the experiment .",
    "one threat to external validity is that analyses were performed only for void methods and methods returning a primitive or string value .",
    "although we additionally executed the analysis for three ( unit - test ) study objects with methods returning objects and observed comparable results , the obtained results might not be representative of methods returning objects .",
    "furthermore , the results of the selected open - source projects might not be representative of closed - source systems .",
    "we tried to mitigate this issue by considering several projects with different characteristics and application domains as study objects .",
    "further studies are necessary to determine if the results also apply to closed - source systems .",
    "the results of the experiment show that approximately 9% to 19% of the test - executed methods are pseudo - tested in projects with unit tests .",
    "the ratio does not heavily deviate among study objects with unit tests ( mean : 11.41% , standard deviation : 6.42% ) .",
    "therefore , code coverage at the method level is not completely misleading and can be used as an approximation for the effectiveness of unit tests .",
    "in contrast , the ratio of pseudo - tested methods for system tests is generally higher than the ratio for unit tests .",
    "it ranges between 6% and 72% for the analyzed study objects and heavily deviates ( mean : 35.48% , standard deviation : 20.60% ) .",
    "therefore , code coverage at the method level is not a valid indicator for the effectiveness of system tests .",
    "the assessment of the functional purpose and severity of pseudo - tested methods confirms the relevance of these methods for the software .",
    "faults in these methods would not be detected and could cause failures .    for future work , we intend to investigate characteristics of pseudo - tested methods and their relationship to test cases .",
    "we want to find indicators that reveal pseudo - tested methods .",
    "such indicators would enable rapid detection of these methods in a static code analysis and make the computationally expensive mutation testing approach superfluous .",
    "this static code analysis could support developers in a continuously integrated development process .",
    "moreover , we plan to replicate the experiment with closed - source study objects .",
    "m.  hutchins , h.  foster , t.  goradia , and t.  ostrand .",
    "experiments of the effectiveness of dataflow - and controlflow - based test adequacy criteria . in _ proc .",
    "16th international conference on software engineering ( icse)_. ieee , 1994 .",
    "a.  mockus , n.  nagappan , and t.  t. dinh - trong .",
    "test coverage and post - verification defects : a multiple case study . in _ proc .",
    "3rd international symposium on empirical software engineering and measurement ( esem)_. ieee , 2009 .",
    "w.  e. wong , j.  r. horgan , s.  london , and a.  p. mathur .",
    "effect of test set size and block coverage on the fault detection effectiveness . in _ proc .",
    "5th international symposium on software reliability engineering ( issre)_. ieee , 1994 ."
  ],
  "abstract_text": [
    "<S> automated tests play an important role in software evolution because they can rapidly detect faults introduced during changes . in practice , </S>",
    "<S> code - coverage metrics are often used as criteria to evaluate the effectiveness of test suites with focus on regression faults . </S>",
    "<S> however , code coverage only expresses which portion of a system has been executed by tests , but not how effective the tests actually are in detecting regression faults .    </S>",
    "<S> our goal was to evaluate the validity of code coverage as a measure for test effectiveness . </S>",
    "<S> to do so , we conducted an empirical study in which we applied an extreme mutation testing approach to analyze the tests of open - source projects written in java . </S>",
    "<S> we assessed the ratio of pseudo - tested methods ( those tested in a way such that faults would not be detected ) to all covered methods and judged their impact on the software project . </S>",
    "<S> the results show that the ratio of pseudo - tested methods is acceptable for _ unit _ tests but not for _ system _ tests ( that execute large portions of the whole system ) . </S>",
    "<S> therefore , we conclude that the coverage metric is only a valid effectiveness indicator for unit tests .    </S>",
    "<S> < ccs2012 > < concept > < concept_id>10011007.10011074.10011099.10011102.10011103</concept_id > < concept_desc > software and its engineering  software testing and debugging</concept_desc > < concept_significance>500</concept_significance > < /concept > < </S>",
    "<S> /ccs2012 >    this code snippet demonstrates that high code coverage does not imply test effectiveness :    .... public class calculation {    private int value ;             public calculation ( ) {      this.value = 0 ;    }    public void add(int x ) {      this.value + = x ;    }    public boolean iseven ( ) {      return this.value % 2 = = 0 ;    } } ....    the class ` calculation ` consists of an integer field named ` value ` and two public methods . </S>",
    "<S> the ` add ` method allows for adding an integer to the internal value . </S>",
    "<S> the ` iseven ` method returns a boolean value , which indicates if the current internal value is an odd or even number . </S>",
    "<S> this class is tested by a junit test in the ` calculationtest ` class .    .... public class calculationtest {    @test    public void testcalculation ( ) {      calculation calc = new calculation ( ) ;      calc.add(6 ) ;      asserttrue(calc.iseven ( ) ) ;    } } ....    the test case creates a new instance of the ` calculation ` class and implicitly assigns 0 to the field ` value ` . </S>",
    "<S> it then uses the ` add ` method to increase the internal value by 6 . </S>",
    "<S> finally , the test case verifies that the ` iseven ` method returns true , which is expected for 6 .    </S>",
    "<S> the test case executes all methods , statements , and branches of the class under test . </S>",
    "<S> this results in 100% code coverage at the method , statement and branch levels . </S>",
    "<S> consequently , one could assume that the ` calculation ` class is effectively tested .    however , this is not the case . </S>",
    "<S> let s assume that the programmer forgot to implement the logic of the ` add ` method so that its body is empty . </S>",
    "<S> although the test case covers that method , it will not detect the fault , because both 0 and 6 are even numbers . </S>",
    "<S> therefore , the ` add ` method is executed , but not effectively tested , because the test case would not detect any faults . </S>",
    "<S> we call this a pseudo - tested method .    </S>",
    "<S> according to fowler @xcite , test cases that do not contain any assertions are another example of tests that increase the coverage , but are useless ( unless their purpose is to check if exceptions are thrown ) . </S>"
  ]
}