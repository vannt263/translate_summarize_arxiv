{
  "article_text": [
    "research related to construction of coding systems whose performance is close to shannon limit while encoding and decoding algorithms are of low complexity , goes for more than 60 years .",
    "a significant modern example of such system is linear codes with low - density parity checks ( ldpc ) .",
    "usually these are binary linear block codes with sparse parity - check matrix .",
    "decoding is performed via iterative algorithms whose convergence is described by quite a few theoretical results and in general , these algorithms are quite good . in practice ,",
    "ldpc codes have good performance for high noise levels .",
    "there exist experimentally constructed codes approaching shannon limit very closely ( e.g. @xcite ) .",
    "however for high bandwidth region , short ldpc codes exhibit so - called `` error floor '' , i.e. significant slowdown in decrease of decoding error probability corresponding to channel improvement , occurring due to decoding algorithm features .    polar codes were invented by e.  arikan in 2008 .",
    "they are the first coding system possessing , on the theorem level , the convergence to shannon limit for code length @xmath0 , as well as fast encoding / decoding algorithms with complexity bound @xmath1 .",
    "thus polar codes are a significant theoretical result .",
    "on the other hand , the performance of polar codes in their initial form presented by arikan , is considerably inferior , for a fixed code length , to other coding systems .",
    "to date there exist many proposals for improvement of polar codes performance ( e.g. @xcite ) , yet work in this direction seems to be very promising .    in this paper",
    "we consider two problems related to polar codes .",
    "first is the problem of polar codes construction and analysis of their performance for various types of binary symmetric channel without monte carlo method .",
    "the formulas proposed are the same as those in @xcite , yet we believe that our approach is original and has clear advantages . moreover , the resulting computational procedure is presented in a fast algorithm form which can be easily implemented on a computer . secondly , we present an original method of construction of concatenated codes based on polar codes .",
    "we give an algorithm for construction of such codes and present numerical experiments showing significant performance improvement with respect to original polar codes proposed by arikan .",
    "it should be noted that we use the term _ concatenated code _ not in its classical sense ( e.g. @xcite ) .",
    "however we believe that our usage is quite appropriate for the exploited construction .",
    "our idea is simple .",
    "it is known that approaching the shannon limit is possible only with sufficiently large code length . increasing",
    "the code length however makes the problem of code construction with large minimum distance and efficient ml decoder very hard .",
    "the situation is different for low - noise channel",
    ". here codes of moderate length are sufficient so that ml decoder complexity is not too large . in order to obtain those low - noise channels we employ the polarization effect observed by e.  arikan in polar codes .",
    "further , we solve the optimization problem of choosing codes minimizing the block error of the whole concatenated code under the constraint of its fixed rate .",
    "unfortunately , we do not have a theorem on asymptotic optimality of our approach or just on its clear advantage with respect to known approaches , like e.g. @xcite . yet",
    "the simplicity of our approach , its flexibility and further possibilities of its improvement make it hopefully interesting .    other examples of concatenated and generalized concatenated codes based on polar codes can be found in e.g. @xcite .    a word on the channels considered here .",
    "we assume that the channel is defined by input alphabet @xmath2 , output alphabet @xmath3 and transition function @xmath4\\ ] ] defined for any pair @xmath5 the function @xmath6 defines the probability ( or its density ) that symbol @xmath7 is received under the condition that symbol @xmath8 was sent .",
    "for the sake of simplicity and in order to avoid generalized distributions we restrict our discussion to finite output alphabet .",
    "all formulas can be easily transplanted to the case of continuous channel by replacing the probabilities by the probability densities and replacing some sums by integrals .",
    "note also that most frequently used channel models can be approximated by discrete ones .",
    "moreover , data transmission systems used in practice represent output symbols with some fixed accuracy which is equivalent to some discrete channel model .",
    "besides , we consider only symmetric channels with binary input @xcite . in such channels ,",
    "the input alphabet contains two symbols:@xmath9 output alphabet @xmath3 is a subset of real numbers , and the function @xmath6 possesses the following symmetry , @xmath10    the rest of this paper contains 5 sections . in section  [ sec : bp - on - trees ] we consider the problem of obtaining the optimal statistical estimate of a bit variable restricted by a linear system",
    ". results of this auxiliary section are well known and belong to factor graph theory . these results are used in obtaining relations which determine the probability of erroneous bit decoding for ml decoder in section  [ sec : polar ] .",
    "our derivation essentially differs from original one proposed by e.  arikan .",
    "it is based on explicit representation of factor graph of polar code , its interpretation as a set of trees and application of density evolution method .",
    "note also that for polar codes we consider two types of factor graphs : encoder graph and decoder graph . in section  [ sec :",
    "design ] we describe the polar code construction method in the form of fast algorithms taking on input discrete probability function defined by the channel . presented also is the analysis of obtained codes and numerical simulation for polar codes of different length .    in section",
    "[ sec : kernels ] we discuss the possibility of polar code construction using polarization kernels other than @xmath11 which was introduced in arikan s paper .",
    "finally , in section  [ sec : new - polar ] we introduce a class of concatenated codes based on polar codes and present numerical comparison of concatenated and classical polar codes performance .",
    "before proceeding directly to polar codes , consider the problem of estimation of one random bit entering as a variable in a linear system . to this end",
    "we investigate two simpler problems : estimation of sum of two random bits transmitted through the channels and estimation of one random bit for which we have several independent sources of information .",
    "actually , this section contains short presentation of factor graph theory which is widely used in the modern coding theory @xcite .",
    "let the values of two independent random bits @xmath12 and @xmath13 taking the values @xmath14 and @xmath15 equiprobably , were transmitted through channels @xmath16 and @xmath17 , respectively , which resulted in received symbols @xmath18 $ ] . using the channel model",
    "we compute the logarithmic likelihood ratios ( llrs ) @xmath19 assume the following quantity is required @xmath20 i.e. estimate the sum of two bits provided @xmath21 and @xmath22 are known .",
    "considering two possible equiprobable cases , we get @xmath23 since the bits @xmath24 and @xmath25 are transmitted independently , @xmath26 hence @xmath27 in a similar way we get @xmath28 inserting the last two formulas in likelihood ratio @xmath29 and cancelling the factor @xmath30 , we obtain @xmath31 divide the numerator and the denominator by @xmath32 @xmath33 : @xmath34 using the likelihood ratios @xmath35 and @xmath36 , rewrite the last formula as follows , @xmath37 or using logarithms , @xmath38 for convenience introduce the binary operation @xmath39 now , @xmath40 note some useful properties of the @xmath41 operation : @xmath42 we now extend the problem to three bits @xmath43 let these quantities be transmitted via channels @xmath44 , respectively , and symbols @xmath45 $ ] be received .",
    "assume the following quantity is required @xmath46 introduce new variable @xmath47 taking values @xmath14 and @xmath15 equiprobably : @xmath48 we can assume that @xmath47 was transmitted via channel with the following transition function , @xmath49 and write its llr value as @xmath50 then @xmath51 since the @xmath41 operation is associative , drop the parentheses : @xmath52 using induction , we obtain formula for arbitrary number of variables : @xmath53 we now proceed to estimation of bit transmitted independently via several channels .",
    "let random bit @xmath8 taking values @xmath14 and @xmath15 equiprobably be transmitted via @xmath54 different channels @xmath55 receiving symbols @xmath56.$ ] one can compute llrs relying only on one channel : @xmath57 we need to estimate @xmath8 , that is @xmath58 since channels transmit symbols independently , @xmath59 inserting the last formula in expression for @xmath60 , we have @xmath61 or taking logarithms , @xmath62 obtained formula gives the estimate of a bit for which we have several independent sources of information .",
    "let random vector variable @xmath63^{t}$ ] whose components take values @xmath14 and @xmath15 equiprobably , satisfy the linear system @xmath64 where the matrix @xmath65 is exactly known .",
    "assume that the quantities @xmath66 are transmitted via channels @xmath67 , and received symbols are @xmath56 $ ] .",
    "then initial llrs are known @xmath68 assume the following llr is required @xmath69 without knowledge of @xmath8 .",
    "note that if some component @xmath70 is exactly known , we can assume that it is transmitted via binary symmetric channel with zero error probability , and @xmath71 vice versa , if some bit @xmath70 is not transmitted , we can assume that it is transmitted via absolutely noisy channel with the transition function @xmath72 it is easy to see that in this case @xmath73 if such bit enters only one equation , we can remove this bit and respective equation .",
    "if some equation contains only exactly known bits ( with@xmath74 ) , this equation also can be removed .",
    "associate matrix @xmath75 with a bipartite undirected graph by the following rule .",
    "each matrix row ( i.e. each equation ) is associated with a square vertex .",
    "each matrix column ( i.e. each bit variable ) is associated with a round vertex .",
    "a round vertex and a square vertex are connected by an edge if respective matrix row and matrix column intersect at value one ( i.e. if the respective variable enters respective equation ) .",
    "such a graph is referred to as tanner graph for the matrix @xmath75 .",
    "we focus on just one bit variable , say @xmath12 .",
    "if the tanner graph is disconnected , remove all connected components save one containing the vertex @xmath12 .",
    "now if removing some bit @xmath76 results in emerging of @xmath77 graph components @xmath78 , our problem of estimating @xmath12 is split into @xmath77 smaller problems .",
    "let @xmath79 be a subvector of @xmath7 containing only those components which arise in transmission of bits entering the subgraph @xmath80 .",
    "assume @xmath81 , and let @xmath82 .",
    "we can assume that @xmath76 is transmitted via @xmath83 different channels with transition functions @xmath84 compute llrs of @xmath76 considering only channel @xmath85 , @xmath86 then the subgraphs @xmath87 may be removed with updating the initial @xmath88 estimate to @xmath89 note that for each @xmath85 the problem of computation of @xmath90 is also a bit estimation problem formulated on a smaller graph @xmath91 augmented by the vertex @xmath76 .",
    "now assume that the tanner graph is a tree , i.e. it is connected and acyclic .",
    "assume also that every equation contains at least two variables .",
    "choose the vertex @xmath12 as a tree root vertex .",
    "the leaf vertices will be some subset of @xmath92 .",
    "let the vertex @xmath12 be incident to equations @xmath93 , and let each vertex @xmath94 be incident to variables @xmath95 , not counting @xmath12 .",
    "let @xmath96 be the subtree with root at @xmath97 , not counting the root itself ( see fig .",
    "[ fig : tanner - tree ] ) .    ]",
    "let @xmath98 be an index set for variables entering the subgraph @xmath96 .",
    "for all @xmath99 define the set @xmath100 i.e. the set of all symbols obtained via transmitting variables entering the subtree rooted at @xmath97 .",
    "assume that for each pair @xmath99 we know the llrs @xmath101 i.e. bit @xmath97 estimates based only on tree rooted at the vertex @xmath97 .",
    "this can be interpreted as transmitting each such bit via the channel with the following transition function , @xmath102 write each equation @xmath103 in the following way : @xmath104 we can assume that @xmath12 was transmitted via independent channels @xmath105 with transition functions @xmath106 then llrs based on these channels have the form @xmath107 inserting ( [ eq : x1eq ] ) , we get @xmath108 taking into account ( [ eq : lxkij ] ) and using result of section [ sub : check - node - update ] , we obtain @xmath109 finally assuming @xmath12 be transmitted via the channels @xmath110 and also via @xmath16 , write @xmath111 in order to compute @xmath112 , we can apply the same reasoning to the subtree rooted at @xmath97 .",
    "thus we have a recursive algorithm computing @xmath113 .",
    "it is essentially equivalent to the algorithm known as `` belief propagation '' .",
    "in this section we consider polar codes in exactly that form which they were presented in originally @xcite , but take a slightly different look .",
    "let @xmath114 and @xmath115 be two independent random bits taking values @xmath14 and @xmath15 equiprobably .",
    "define two more bits @xmath116 & = & u^{0}\\oplus u^{1},\\nonumber \\\\",
    "x[1 ] & = & u^{1}.\\label{eq : x0x1}\\end{aligned}\\ ] ] in matrix notation , @xmath117,x[1]]=[u^{0},u^{1}]\\cdot g_{2},\\quad\\mbox{ } g_{2}=\\left[\\begin{array}{cc } 1 & 0\\\\ 1 & 1 \\end{array}\\right].\\ ] ] note that bits @xmath118 $ ] , @xmath119 $ ] also take the values @xmath14 and @xmath15 equiprobably .",
    "construct the tanner graph for the system ( [ eq : x0x1 ] ) and denote it as _ encoder graph _",
    "( see fig .",
    "[ fig : coder - graph ] ) .    ]    since @xmath120 , we can rewrite the system ( [ eq : x0x1 ] ) in equivalent form @xmath121\\oplus x[1],\\\\ u^{1 } & = & x[1].\\end{aligned}\\ ] ] construct the tanner graph for this system also and denote it as _ decoder graph _ ( see fig .",
    "[ fig : decoder - graph ] ) .    ]",
    "let bits @xmath118 $ ] and @xmath119 $ ] be transmitted via a given channel @xmath122 receiving symbols @xmath123 $ ] .",
    "assume the following llr is required @xmath124 using results of the section  [ sec : bp - on - trees ] , we have @xmath125){\\mathbin{\\scalebox{0.75}{$\\square$}}}l(x[1]),\\ ] ] where @xmath126)=\\ln\\frac{w(y^{i}\\,|\\,0)}{w(y^{i}\\,|\\,1)},\\quad i=0,1.\\ ] ] now assume that the value of @xmath127 is exactly known and that we need @xmath128 using again section  [ sec : bp - on - trees ] , we get @xmath129)+(l(x[0]){\\mathbin{\\scalebox{0.75}{$\\square$}}}l(u^{0}))=l(x[1])+(-1)^{u^{0}}l(x[0]).\\ ] ] we proceed to recursive construction of the larger system and then to similar problem of determining of one bit .",
    "double the encoder graph taking two copies of each variable and of each equation .",
    "now let @xmath130 be the transmitted random bits while @xmath131,u_{1}^{0}[1],u_{1}^{1}[0],u_{1}^{1}[1]$ ] are their functions : @xmath132 & = & u^{0}\\oplus u^{1},\\nonumber \\\\ u_{1}^{0}[1 ] & = & u^{1},\\nonumber \\\\ u_{1}^{1}[0 ] & = & u^{2}\\oplus u^{3},\\nonumber \\\\ u_{1}^{1}[1 ] & = & u^{3}.\\label{eq : duplicated}\\end{aligned}\\ ] ] from the other hand , @xmath133\\oplus u_{1}^{0}[1],\\\\ u^{1 } & = & u_{1}^{0}[1],\\\\ u^{2 } & = & u_{1}^{1}[0]\\oplus u_{1}^{1}[1],\\\\ u^{3 } & = & u_{1}^{1}[1].\\end{aligned}\\ ] ] for consistency , set @xmath134\\equiv u^{i}$ ] .",
    "figure  [ fig : duplicated ] gives the graph for the system ( [ eq : duplicated ] ) .    )",
    "[ fig : duplicated ] ]    introduce four new variables ( fig .",
    "[ fig : coder-2 ] ) , @xmath135 & = & u_{1}^{0}[0]\\oplus u_{1}^{1}[0],\\nonumber \\\\ u_{2}^{0}[1 ] & = & u_{1}^{1}[0],\\nonumber \\\\ u_{2}^{0}[2 ] & = & u_{1}^{0}[1]\\oplus u_{1}^{1}[1],\\nonumber \\\\ u_{2}^{0}[3 ] & = & u_{1}^{1}[1].\\label{eq : coder-2}\\end{aligned}\\ ] ] in matrix notation , @xmath136,u_{2}^{0}[1 ] ] & = & [ u_{1}^{0}[0],u_{1}^{1}[0]]\\cdot g_{2},\\\\ { } [ u_{2}^{0}[2],u_{2}^{0}[3 ] ] & = & [ u_{1}^{0}[1],u_{1}^{1}[1]]\\cdot g_{2}.\\end{aligned}\\ ] ]    ) [ fig : coder-2 ] ]    again employ the relation @xmath120 and express old variables in terms of new ones ( fig .",
    "[ fig : decoder-2 ] ) , @xmath132 & = & u_{2}^{0}[0]\\oplus u_{2}^{0}[1],\\nonumber \\\\ u_{1}^{1}[0 ] & = & u_{2}^{0}[1],\\nonumber \\\\ u_{1}^{0}[1 ] & = & u_{2}^{0}[2]\\oplus u_{2}^{0}[3],\\nonumber \\\\",
    "u_{1}^{1}[1 ] & = & u_{2}^{0}[3],\\label{eq : decoder-2}\\end{aligned}\\ ] ]    ) [ fig : decoder-2 ] ]    we call the graph displayed on fig .",
    "[ fig : coder-2 ] the encoder graph and the graph displayed on fig .",
    "[ fig : decoder-2 ] the decoder graph .",
    "now we are able to repeat the whole operation , double the graph and introduce eight new variables @xmath137,\\ , i=\\overline{0,7}$ ] , and proceed further .",
    "we can express new variables in terms of old ones , @xmath138,u_{k+1}^{i}[2j+1]]=[u_{k}^{2i}[j],u_{k}^{2i+1}[j]]\\cdot g_{2},\\label{eq : new - old}\\ ] ] and vice versa : @xmath139,u_{k}^{2i+1}[j]]=[u_{k+1}^{i}[2j],u_{k+1}^{i}[2j+1]]\\cdot g_{2}.\\ ] ] assume we make @xmath54 steps and stop at introducing new variables @xmath140 $ ] .",
    "indices in the expression @xmath141 $ ] have the following interpretation based on decoder graph .",
    "lower index @xmath142 specifies the vertical `` layer '' of the graph of @xmath143 variables where the given vertex is , if we count layers right to left .",
    "bracketed index @xmath144 specifies the independent group of variables in a layer .",
    "upper index @xmath85 specifies the variable inside a group .    increasing layer number by one doubles the number of independent groups @xmath145 , i.e. @xmath146 layer indexed @xmath14 contains one group of @xmath143 variables , i.e. @xmath147 . hence @xmath148 since every layer contains @xmath143 variables , the number of variables in every group of layer @xmath142 is @xmath149 thus , upper index in the expression @xmath141 $ ] has range @xmath14 to @xmath150 , while bracketed index has range @xmath14 to @xmath151 .",
    "figure  [ fig : decoder-4 ] shows decoder graph for @xmath152 .",
    ".[fig : decoder-4 ] ]      let the variables @xmath153 $ ] constituting the graph last layer , be transmitted via some channel @xmath122 and received as symbols @xmath154.$ ] using the channel model , we have @xmath155 assume that for some @xmath156 we exactly know the quantities @xmath157,u_{0}^{1}[0],u_{0}^{2}[0],\\ldots , u_{0}^{m-1}[0].\\ ] ] assume that the estimate of the next bit @xmath158 $ ] is required , i.e. @xmath159)\\equiv\\ln\\frac{\\pr\\big\\ { y\\,|\\ , u_{0}^{m}[0]=0,\\ , u_{0}^{i}[0],i=\\overline{0,m-1}\\big\\}}{\\pr\\big\\ { y\\,|\\ , u_{0}^{m}[0]=1,\\ , u_{0}^{i}[0],i=\\overline{0,m-1}\\big\\}}.\\label{eq : final - llr}\\ ] ] denote the subvector of @xmath7 consisting of contiguous bits from index @xmath160 up to index @xmath161 inclusively by symbol @xmath162 $ ]",
    ". then the vector @xmath7 has the following representation in terms of its parts @xmath162 $ ] , @xmath163,y_{k}[1],\\ldots , y_{k}[j_{k}]\\big].\\ ] ] on the decoder graph , the subvector @xmath162 $ ] may be interpreted as components of @xmath7 corresponding to those bits @xmath164 $ ] which are strictly on the left of variables of group @xmath144 , layer @xmath142 .",
    "for example , if @xmath152 ( fig .",
    "[ fig : decoder-4 ] ) then group @xmath15 of layer @xmath165 consists of variables @xmath166,u_{2}^{1}[1],u_{2}^{2}[1],u_{2}^{3}[1],$ ] while the subvector @xmath167 $ ] is obtained via transmission of the bits @xmath168,u_{4}^{0}[5],u_{4}^{0}[6],u_{4}^{0}[7]$ ] .",
    "introduce the following notation , @xmath169)\\equiv\\ln\\frac{\\pr\\big\\ { y_{k}[j]\\,|\\ , u_{k}^{i}[j]=0,\\ , u_{k}^{l}[j],l=\\overline{0,i-1}\\big\\}}{\\pr\\big\\ { y_{k}[j]\\,|\\ , u_{k}^{i}[j]=1,\\ , u_{k}^{l}[j],l=\\overline{0,i-1}\\big\\}}.\\label{eq : intermediate - llr}\\ ] ] this means that @xmath170)$ ] is the llr for the bit @xmath141 $ ] provided that @xmath162 $ ] is received and that the quantities @xmath171,u_{k}^{1}[j],\\ldots , u_{k}^{i-1}[j]\\ ] ] are exactly known .",
    "note that the formula ( [ eq : final - llr ] ) is a special case of ( [ eq : intermediate - llr ] ) for @xmath172 , and that for @xmath173 the formula ( [ eq : intermediate - llr ] ) takes the form @xmath174)\\equiv\\ln\\frac{\\pr\\big\\ { y_{j}\\,|\\ , u_{n}^{0}[j]=0\\big\\}}{\\pr\\big\\ { y_{j}\\,|\\ , u_{n}^{0}[j]=1\\big\\}}=\\lambda_{j}.\\label{eq : llr - base}\\ ] ]    our goal is to obtain recursive formula for @xmath170)$ ] in terms of @xmath175).$ ] if we have it , we can compute the required @xmath176)$ ] using ( [ eq : llr - base ] ) as a recursion base .",
    "denote the subgraph consisting of single vertex @xmath153 $ ] by @xmath177 $ ] . by induction ,",
    "let @xmath178 $ ] for @xmath179 be the union of subgraphs @xmath180,a_{k+1}[2j+1],$ ] of all vertices of group @xmath144 , layer @xmath142 and of incident equations . on the graph drawing we can interpret @xmath181 $ ] as a subgraph whose vertices are all bits of group @xmath144 , layer @xmath142 and all vertices on the left of these . for example , if @xmath152 , the subgraph @xmath182 $ ] consists of the variables @xmath183 , & u_{4}^{0}[5 ] , & u_{4}^{0}[6 ] , & u_{4}^{0}[7],\\\\ u_{3}^{0}[2 ] , & u_{3}^{1}[2 ] , & u_{3}^{0}[3 ] , & u_{3}^{1}[3],\\\\ u_{2}^{0}[1 ] , & u_{2}^{1}[1 ] , & u_{2}^{2}[1 ] , & u_{2}^{3}[1 ] \\end{array}\\ ] ] and incident equations ( fig .",
    "[ fig : decoder-4 ] ) .",
    "note that the subgraph @xmath178 $ ] contains those and only those variables of layer @xmath54 , whose transmission results in the vector @xmath162 $ ] .",
    "here we find the expression for @xmath170)$ ] under the constraint @xmath184 .",
    "all variables of layer @xmath14 enter only one equation , and for @xmath185 we do not have any immediate information for them , thus we remove them and the incident equation . now for @xmath186 the same can be done for layer @xmath15 etc .",
    "finally we retain only layers with index at least @xmath142 .",
    "the graph will be divided in @xmath187 connected components @xmath188 $ ] .",
    "remove all components save one containing @xmath141 $ ] , which means that we keep only the component @xmath178 $ ] .",
    "denote @xmath189 .",
    "if bits @xmath190,u_{k}^{1}[j],\\ldots , u_{k}^{i-1}[j]$ ] are exactly known , then according to the equation ( [ eq : new - old ] ) , exactly known are also the quantities @xmath191,\\ , u_{k+1}^{l}[2j+1],\\quad l=\\overline{0,q-1}.\\label{eq : u - k - plus-1}\\ ] ] hence the equations incident to @xmath190,u_{k}^{1}[j],\\ldots , u_{k}^{i-1}[j]$ ] and to ( [ eq : u - k - plus-1 ] ) may be removed : these equations contain only known quantities .",
    "after the removal the vertices @xmath171,u_{k}^{1}[j],\\ldots , u_{k}^{2q-1}[j]\\ ] ] become isolated and also may be removed .",
    "the vertices @xmath192,u_{k}^{2q+3}[j],\\ldots , u_{k}^{s_{k}-1}[j]\\ ] ] are not transmitted and do not have any estimates , thus also may be removed with corresponding equations ( one per vertex ) .",
    "after these transformations the graph will have the form depicted on fig .",
    "[ fig : two - subgraphs ] .    ]    since removing the vertex @xmath193 $ ] divides the graph into two components one of which is @xmath180 $ ] , we can assume that the bit @xmath193 $ ] is transmitted via the channel with the following transition function @xmath194\\,|\\ ,",
    "a)&=&\\pr\\big\\ { y_{k+1}[2j]\\,\\big|\\ , u_{k+1}^{q}[2j]=a;\\\\ & & u_{k+1}^{l}[2j+i],l=\\overline{0,q-1}\\big\\}. \\end{array}\\label{eq : w0-k - plus-1}\\ ] ] also we can substitute the subgraph @xmath180 $ ] by the single vertex @xmath193 $ ] , with the following initial likelihood ratio , @xmath195=\\ln\\frac{\\hat{w}_{0}(y_{k+1}[2j]\\,|\\,0)}{\\hat{w}_{0}(y_{k+1}[2j]\\,|\\,1)}.\\ ] ] comparing ( [ eq : intermediate - llr ] ) with ( [ eq : w0-k - plus-1 ] ) , we conclude that @xmath195=l(u_{k+1}^{q}[2j]).\\ ] ] similarly , the vertex @xmath196 $ ] can be substituted for the whole subgraph @xmath197 $ ] , if we set @xmath198=l(u_{k+1}^{q}[2j+1]).\\ ] ] resulting graph is displayed on fig .",
    "[ fig : simplified ] .",
    "we know already that for such graph , @xmath199 ) & = & l(u_{k+1}^{q}[2j]){\\mathbin{\\scalebox{0.75}{$\\square$}}}l(u_{k+1}^{q}[2j+1 ] ) , \\\\ l(u_{k}^{2q+1}[j ] ) & = & l(u_{k+1}^{q}[2j+1])+(-1)^{u_{k}^{2q}[j]}l(u_{k+1}^{q}[2j ] ) .",
    "\\end{array } \\label{eq : llr - recursion}\\ ] ]    $ ] , @xmath200 $ ] instead of subgraphs @xmath180 $ ] , @xmath197 $ ] , respectively.[fig : simplified ] ]    thus we have obtained the recursive formulas giving @xmath201)$ ] for all @xmath202 using ( [ eq : llr - base ] ) as a recursion base .",
    "let the vector @xmath203,u_{0}^{1}[0],u_{0}^{2}[0],\\ldots , u_{0}^{2^{n}-1}[0]\\big]\\ ] ] be the message required for transmission .",
    "starting from @xmath204 we can compute @xmath205,u_{n}^{0}[1],u_{n}^{0}[2],\\ldots , u_{n}^{0}[2^{n}-1]\\big],\\ ] ] using the formulas ( [ eq : new - old ] ) .",
    "the vector @xmath8 will be considered as a codeword and transmitted componentwise via given symmetric channel @xmath122 producing vector @xmath7 at the receiver .",
    "we want to recover @xmath204 using @xmath7 .",
    "we do it sequentially bit by bit .",
    "first we compute @xmath206)$ ] and estimate the bit @xmath207 $ ] as follows , @xmath208=\\begin{cases } 0 , & l(u_{0}^{0}[0])>0,\\\\ 1 , & l(u_{0}^{0}[0])<0,\\\\ \\mbox{choose randomly , } & l(u_{0}^{0}[0])=0 .",
    "\\end{cases}\\ ] ] now assuming @xmath207 $ ] exactly known , we compute @xmath209)$ ] , estimate @xmath210 $ ] etc . each bit is estimated using the rule @xmath211=\\begin{cases } 0 , & l(u_{0}^{i}[0])>0,\\\\ 1 , & l(u_{0}^{i}[0])<0,\\\\ \\mbox{choose randomly , } & l(u_{0}^{i}[0])=0 .",
    "\\end{cases}\\label{eq : hard - decision}\\ ] ] finally we produce some estimate of the initial message @xmath204 .",
    "this decoding method is called _ successive cancellation_. of course , presented coding system is useless since the redundancy is missing .",
    "choose some index set @xmath212 denote @xmath213 make a convention that the only possible messages are those with bits from @xmath214 equal to zero .",
    "we call these bits _ frozen _ , and other ones _ information _ bits .",
    "again we use the successive cancellation however with modified bit estimation rule : @xmath211=\\begin{cases } 0 , & i\\in f,\\\\ \\mbox{choose using ( \\ref{eq : hard - decision } ) , } & \\mbox{otherwise . } \\end{cases}\\ ] ] since the admissible messages form the linear space of dimension @xmath215 and codewords @xmath8 depend linearly on @xmath204 , the set of all codewords is also a linear space . in other words , we have linear block code of length @xmath143 and of rate @xmath216 .",
    "it can be shown that its generator is obtained by deleting rows with indices in @xmath214 from the matrix @xmath217 where @xmath218 denotes the @xmath54-th kronecker power of the matrix @xmath11 and @xmath219 the _ bit reverse permutation _ matrix .",
    "the rule describing this permutation is as follows : let binary representation of index @xmath85 be @xmath220 , then the element @xmath85 is swapped with the element indexed @xmath221 , in binary representation . thus constructed code is called the _ polar code .",
    "_    how to choose the set @xmath214 of frozen bits ?",
    "denote the probability of erroneous detection of the bit @xmath134 $ ] using the successive cancellation method provided that all previous bits are detected correctly and @xmath222 by @xmath223 .",
    "the probability of block error @xmath224 with @xmath214 fixed may be estimated from above as a sum of probability errors for each information bit , i.e. @xmath225 the set @xmath214 may contain indices of bits with maximal error probabilities , which will minimize the upper bound ( [ eq : fer - upper - bound ] ) of the block error probability . to this end , one has to compute the probabilities @xmath226 , which is discussed in section  [ sec : design ] .",
    "polar codes would not have any practical value without fast algorithms of encoding and decoding .",
    "the encoding process is carried out by recursive formulas ( [ eq : new - old ] ) @xmath138,u_{k+1}^{i}[2j+1]]=[u_{k}^{2i}[j],u_{k}^{2i+1}[j]]\\cdot g_{2}\\ ] ] and requires @xmath54 sequential steps @xmath227 . on each of these steps ,",
    "all variables of layer @xmath142 are defined .",
    "since each layer contains @xmath143 bits , the overall encoding complexity is @xmath228 operations , which is @xmath229 if we introduce the code length @xmath230 .",
    "decoding by successive cancellation method using the recursive formulas ( [ eq : llr - recursion ] ) requires computation of @xmath231 different quantities @xmath170)$ ] and of @xmath231 quantities @xmath141 $ ] in a more complex order .",
    "hence the decoding complexity also is @xmath232 operations .",
    "construction of polar code of given length @xmath230 and rate @xmath233 for a given channel @xmath122 amounts to choosing the set @xmath214 of @xmath234 frozen bits .",
    "the choice which minimizes the block error probability @xmath224 would be optimal .",
    "however computation of @xmath224 is complicated and it is reasonable to substitute its upper bound in the minimization problem , @xmath235 where @xmath236 is the probability of erroneous detection of bit @xmath85 by successive cancellation under assumption that all previous bits are detected without error . in this formulation",
    ", it is sufficient to choose @xmath234 indices corresponding to maximal values of @xmath236 as the set @xmath214 provided that @xmath236 are known for @xmath202 .",
    "thus the polar code construction problem is reduced to computation of quantities @xmath236 .",
    "since the channel is symmetric and the code is linear , in computation of @xmath236 we can assume that all - zeros codeword is transmitted . in this case the probability to receive the vector @xmath7 is @xmath237 by definition of @xmath236 we assume all bits @xmath238 zero . in this case",
    "the recursion ( [ eq : llr - recursion ] ) takes the form @xmath239 ) & = & l(u_{k+1}^{q}[2j]){\\mathbin{\\scalebox{0.75}{$\\square$}}}l(u_{k+1}^{q}[2j+1]),\\nonumber \\\\ l(u_{k}^{2q+1}[j ] ) & = & l(u_{k+1}^{q}[2j+1])+l(u_{k+1}^{q}[2j]).\\label{eq : llr - recursion - zero}\\end{aligned}\\ ] ] the recursion base ( [ eq : llr - base ] ) remains unchanged : @xmath174)=\\lambda_{j}=\\ln\\frac{w(y_{j}\\,|\\,0)}{w(y_{j}\\,|\\,1)}.\\ ] ] now the quantities @xmath170)$ ] depend only on @xmath7 and do not depend on @xmath240,\\ldots , u_{0}^{n-1}[0]]$ ] , thus we consider @xmath170)$ ] as random variables defined on probability space @xmath241 with probability measure ( [ eq : prob - measure ] ) .    according to ( [ eq : prob - measure ] ) , the quantities @xmath242 are mutually independent . hence the quantities @xmath243),l(u_{n}^{0}[1]),\\ldots , l(u_{n}^{0}[n-1])$ ] are also mutually independent , because every quantity @xmath244)$ ] depends on only one symbol @xmath245 .",
    "the quantities @xmath246)$ ] and @xmath247)$ ] are independent for all @xmath185 , @xmath248 , @xmath249 and @xmath250 , because they are defined by recursive formulas ( [ eq : llr - recursion - zero ] ) via non - intersecting sets of @xmath244)$ ] .    following the hard decision rule ( [ eq : hard - decision ] ) we see that the bit @xmath85 is detected erroneously in all cases when @xmath201)<0 $ ] and in half of cases when @xmath201)=0 $ ] .",
    "in other words , @xmath236 is)$ ] has continuous distribution , the term @xmath251)=0\\}$ ] should be deleted . ]",
    "@xmath252)<0\\big\\}+\\frac{1}{2}\\pr\\big\\ { l(u_{0}^{i}[0])=0\\big\\}.\\ ] ] extend the problem of computation of @xmath236 to computation of distributions of random variables @xmath201)$ ] .",
    "denote by @xmath253 $ ] the probability function$ ] will be the probability density function .",
    "] of the random variable @xmath170)$ ] : @xmath254(z)=\\pr\\big\\ { l(u_{k}^{i}[j])=z\\big\\}.\\ ] ] from the channel model we have @xmath255,j=\\overline{0,n-1}$ ] : @xmath256(z ) & = & \\pr\\big\\{\\ln\\frac{w(y_{j}|0)}{w(y_{j}|1)}=z\\,\\big|\\ , u_{n}^{0}[j]=0\\big\\}=\\\\   & = & \\sum_{b:\\ln\\frac{w(b|0)}{w(b|1)}=z}w(b\\,|\\,0).\\end{aligned}\\ ] ] we see that the distributions @xmath255 $ ] of random variables @xmath244)$ ] are the same for all @xmath144 . formulas ( [ eq : llr - recursion - zero ] ) imply that for @xmath184 the distributions of @xmath170)$ ] also do not depend on @xmath144 , i.e. @xmath257=f_{k}^{i}[j'']\\;\\forall i , k , j',j''$ ] .",
    "therefore in what follows , we drop the square brackets in the notation @xmath253 $ ] .      here",
    "we show that the distributions @xmath258 satisfy the recurrent relations analogous to the formulas ( [ eq : llr - recursion - zero ] ) .",
    "we start from random variables with odd indices : @xmath259)=l(u_{k+1}^{q}[2j+1])+l(u_{k+1}^{q}[2j]).\\ ] ] since @xmath260)$ ] and @xmath261)$ ] are i.i.d . , @xmath262)=z\\big\\}\\\\ & = & \\sum_{a , b\\,\\in\\,\\operatorname{supp}f_{k+1}^{q}:\\ ; a+b = z,}f_{k+1}^{q}(a)f_{k+1}^{q}(b),\\end{aligned}\\ ] ] where @xmath263 rewrite the sum so that it will go over one index only : @xmath264 if @xmath265 is a uniform mesh , the formula ( [ eq : f-2q - plus-1-z ] ) is nothing else but discrete convolution of a sequence with itself . in the continuous case ,",
    "the formula ( [ eq : f-2q - plus-1-z ] ) will have the form @xmath266 which is also convolution of the function @xmath267 with itself .",
    "hence it is quite natural to call the probability function @xmath268 defined by the formula @xmath269 the convolution of the functions @xmath270 and @xmath271 with the notation @xmath272 thus in new notation @xmath273 random variables with even indices are treated analogously . using the corresponding recursive formula @xmath274)=l(u_{k+1}^{q}[2j]){\\mathbin{\\scalebox{0.75}{$\\square$}}}l(u_{k+1}^{q}[2j])\\ ] ] we write @xmath275)=z\\big\\}\\\\ & = & \\sum_{a , b\\,\\in\\,\\operatorname{supp}f_{k+1}^{q}:\\ ;",
    "a{\\mathbin{\\scalebox{0.75}{$\\square$}}}b = z,}f_{k+1}^{q}(a)f_{k+1}^{q}(b).\\end{aligned}\\ ] ] introduce the notation @xmath276 and rewrite the recursion as @xmath277 while the operation @xmath278 is not a convolution in the usual sense , we still will use this term .",
    "now we have the recurrent formulas ( [ eq : f - odd ] ) and ( [ eq : f - even ] ) which give the required distributions of random variables @xmath201)$ ] if the initial probability function @xmath279 is used as the recursion base .",
    "the probability error @xmath236 is obtained from the probability function @xmath280 : @xmath281 in what follows we consider a simple case when the convolutions @xmath282 and @xmath278 of two functions are reduced to simple operations on pairs of numbers .",
    "the problem of polar codes construction for bec was solved in that very article where the polar codes were introduced , however in a different formulation @xcite .",
    "the bec scheme is shown on fig .",
    "[ fig : bec ] .",
    "]    binary erasure channel is a binary input symmetric channel , possibly simplest one in terms of decoding : if the received symbol is @xmath15 or @xmath283 , the transmitted symbol is unconditionally known .",
    "initial probability function has the support of two values , @xmath284 the quantity @xmath285 $ ] is termed the erasure probability .",
    "consider the convolution of functions @xmath286 and @xmath287 for some @xmath288.$ ] the sum @xmath289 of all possible pairs @xmath290 has the form @xmath291 hence @xmath292 .",
    "value of zero is obtained only with @xmath293 , @xmath294 therefore @xmath295 and @xmath296 now we turn to the convolution @xmath297 . again",
    "consider all possible pairs @xmath298 and the output of @xmath299 : @xmath300 again @xmath301 .",
    "since the value of @xmath302 is obtained only with @xmath303 , @xmath304 therefore @xmath305 and @xmath306 thus the formulas ( [ eq : f - odd ] ) and ( [ eq : f - even ] ) take the form @xmath307 the recursion base will be @xmath308 , the erasure probability of the channel . it only remains to note that @xmath309 the case of general symmetric channel is considered in the next subsection .",
    "in the general case the complexity of exact computation of convolutions becomes too high since the support cardinality ( and memory requirements ) for the probability function grows exponentially with the code length .",
    "approximation of the probability functions using a uniform grid is quite natural .",
    "denote by @xmath310 the grid step and by @xmath311 the grid cell number @xmath85 with @xmath312 : @xmath313,\\quad i=\\overline{-q+1,-1},\\\\ \\omega_{q } & = & \\left[q\\delta-\\frac{\\delta}{2},\\,+\\infty\\right),\\\\ \\omega_{-q } & = & \\left(-\\infty,\\,-q\\delta+\\frac{\\delta}{2}\\right],\\end{aligned}\\ ] ] where @xmath314 is a positive integer which will be called _ the number of quantization levels .",
    "_ thus the grid consists of @xmath315 cells .",
    "the points @xmath316 will be called the grid nodes .",
    "all cells except for extreme ones have grid nodes as centers .",
    "define the grid projection operator .",
    "let @xmath270 be some probability function .",
    "for each grid node , sum all nonzero values of @xmath270 which belong to the corresponding grid cell is the probability density function , let @xmath317 : @xmath318 let @xmath271 and @xmath268 be two functions supported at grid nodes .",
    "the convolutions @xmath319 and @xmath320 can take nonzero values outside the set of grid nodes .",
    "use the projection ( [ eq : grid - projection ] ) to restrict the resulting function to the grid .",
    "note that the convolution @xmath319 can have nonzeros only at points @xmath316 with @xmath85 from @xmath321 up to @xmath322 . among these points ,",
    "only those with @xmath323 are not grid nodes . if @xmath324 , these points belong to the rightmost cell @xmath325 , and if @xmath326 , to the leftmost cell @xmath327 .",
    "thus the projection operation for the convolution result consists in summing the values outside the interval @xmath328 $ ] .",
    "the convolution @xmath320 , on the contrary , is not supported outside the interval @xmath328 $ ] because @xmath329 .",
    "denote by @xmath330 the index of the cell @xmath331 containing the point @xmath8 .",
    "in other words , @xmath330 is the index of the grid node closest to @xmath8",
    ". then the approximate computation of convolutions @xmath282 and @xmath278 described above corresponds to algorithms [ alg : star ] and [ alg : starbox ] , respectively .",
    "@xmath332 @xmath333 @xmath334 @xmath335 @xmath336    @xmath333 @xmath337 @xmath338    since the grid is uniform , the convolution @xmath339 from the first step of the algorithm [ alg : star ] may be computed in @xmath340 operations using fft .",
    "the rest of the algorithm takes only @xmath341 operations , hence the overall complexity of the algorithm [ alg : star ] is @xmath340 operations . the complexity of the algorithm [ alg : starbox ] is @xmath342 , which is much worse .",
    "convolutions @xmath282 and @xmath278 arise also in the problem of optimizing the weight distributions for rows and columns of the ldpc check matrix .",
    "results from this area may be used for the design of fast version of the algorithm [ alg : starbox ] , namely the algorithm from @xcite .",
    "it is based on the following inequalities for the quantity @xmath142 appearing in the line @xmath343 of the algorithm [ alg : starbox ] , @xmath344 also , @xmath345 , i.e. the quantity @xmath346 estimates @xmath142 with an error not exceeding @xmath347 .",
    "this observation helps to reduce the complexity of the algorithm to @xmath348 operations .",
    "however taking finer grid makes @xmath349 larger , and the speedup smaller .",
    "however the speedup is noticeable .",
    "let @xmath350 be the rightmost grid node and @xmath351 $ ] the segment containing all grid nodes .",
    "typical values used in our numerical experiments were @xmath352 @xmath353 .",
    "in this case @xmath354 and @xmath355 .    thus making the grid projection of the initial probability function @xmath356 and substituting approximations for the exact computations which use formulas ( [ eq : f - odd ] ) and ( [ eq : f - even ] )",
    "we obtain a numerical method for computation of probability errors @xmath226 . while the accuracy analysis for this method remains an open question ,",
    "our numerical experiments show that good accuracy can be achieved without refining the grid too much .",
    "construction procedure described above implies that the polar code is built for a concrete channel . in practice",
    ", channel properties may change with time , therefore it is important to analyze the performance of the constructed code for channel models with different noise levels . for most modern coding systems ,",
    "in particular for low - density parity check codes , the only available tool is the monte - carlo simulation .    for polar codes ,",
    "such analysis is available in much less expensive way . to obtain the upper bound for the block error probability",
    ", one can compute the error probabilities @xmath236 by the method used in code construction and sum these quantities over indices of information bits .",
    "numerical experiments show that this estimate is quite accurate .",
    "it is instructive to check the quality of the estimates given by the described performance analysis method . to this end",
    ", one can compare the monte - carlo simulation results and the obtained estimate for some concrete code .",
    "using random number generator , form `` received '' vector @xmath7 satisfying the channel model and decode it . for large number of trials",
    "@xmath357 , the decoder will make @xmath358 errors .",
    "we can estimate the block error probability as follows , @xmath359 according to the central limit theorem , with the probability of some @xmath360 this estimate belongs to the confidence interval of the radius @xmath361 where @xmath362 is the variance of the random variable taking the value of @xmath15 if the decoder makes an error and @xmath14 otherwise @xcite .",
    "exact value of @xmath362 is @xmath363 and while it is unknown , we can estimate it using the sample variance formula @xmath364 thus the monte - carlo method has the accuracy of the order @xmath365 which implies large computational costs . for @xmath366 , obtaining a @xmath367 confidence estimate requires according to formula ( [ eq : confidence ] ) , some @xmath368 trials .",
    "for example , if @xmath369 , one will need @xmath370 trials . further , with @xmath371 confidence level the number of trials increases up to @xmath372 .",
    "if @xmath369 , this number will be approximately @xmath373 .",
    "therefore in monte - carlo simulations we restrict the noise level to interval corresponding to @xmath224 exceeding @xmath374 .    ,",
    "rate @xmath30 on binary symmetric channel estimated by monte - carlo simulations and proposed analysis method[fig : mc - vs - a ] ]    for this experiment we constructed a polar code of length @xmath375 and rate @xmath30 for binary symmetric channel with error probability @xmath376 .",
    "monte - carlo simulation was run for binary symmetric channels with various error probabilities .",
    "also , an estimate of block error probability was computed using the proposed analysis method .",
    "obtained graphs are shown on fig .",
    "[ fig : mc - vs - a ] .",
    "one can see that the results produced independently in two different ways are very close .",
    "consider now a different channel model , an awgn channel with binary input and additive normal noise .",
    "output alphabet for this channel is the real axis , while the transition function has the form @xmath377 in other words , transmission over such channel amounts to mapping input bits @xmath14 and @xmath15 to symbols @xmath15 and @xmath283 , respectively , and adding afterwards normal noise with zero average and variance @xmath362 .",
    "note that this channel has continuous output alphabet and does not fit to previous sections theory .",
    "however a similar numerical experiment is perfectly possible for a discrete approximation of this channel . instead of @xmath362 ,",
    "on the horizontal axis we plot the signal / noise ratio in decibels @xmath378 we constructed a polar code of length @xmath375 and rate @xmath30 for the noise level @xmath379db .",
    "monte - carlo simulation was run for various noise levels .",
    "also , an estimate was computed using the proposed analysis method .",
    "the results are shown in fog .",
    "[ fig:1024-awgn ] .",
    "one can see that the graphs again are almost identical .",
    ", rate @xmath30 on awgn channel estimated by monte - carlo simulations and proposed analysis method[fig:1024-awgn ] ]    fig .",
    "[ fig : polar - bsc ] shows performance graphs for polar codes of rate @xmath380 and of lengths @xmath381 , @xmath382 and @xmath383 for binary symmetric channel . for code rate @xmath380 and binary symmetric channel",
    ", the shannon limit corresponds to @xmath384 .",
    "one can see that the convergence to shannon limit is rather slow .",
    "next section is devoted to generalization of polar codes which allows to increase the convergence rate .",
    "and different lengths for binary symmetric channel[fig : polar - bsc ] ]",
    "for the definition of polar codes , the following matrix was used in section  [ sec : polar ] , @xmath385.\\ ] ] one can use another invertible matrix @xmath386 of arbitrary order @xmath387 . then the hierarchical graph construction will involve taking @xmath387 copies of encoder graph , instead of doubling .",
    "new variables will be expressed in terms of old ones by the formula @xmath388,u_{k+1}^{i}[lj+1],\\ldots , u_{k+1}^{i}[lj+l-1]=\\\\ & & \\qquad[u_{k}^{li}[j],u_{k}^{li+1}[j],\\ldots , u_{k}^{li+l-1}]\\cdot g,\\end{aligned}\\ ] ] and old variables in terms of new ones , by the formula @xmath389,u_{k}^{li+1}[j],\\ldots , u_{k}^{li+l-1}]=\\\\ & & [ u_{k+1}^{i}[lj],u_{k+1}^{i}[lj+1],\\ldots , u_{k+1}^{i}[lj+l-1]]\\cdot g^{-1}.\\end{aligned}\\ ] ] after @xmath54 steps of graph construction , the code length will be @xmath390 and the decoder graph will consist of @xmath54 layers , each having @xmath391 groups of @xmath392 variables .",
    "the vector of output symbols @xmath162 $ ] corresponding to group @xmath144 of layer @xmath142 , still will consist of contiguous bits from index @xmath160 up to index @xmath161 inclusively .",
    "the problem of computation of quantities @xmath393),l(u_{k}^{li+1}[j]),\\ldots , l(u_{k}^{li+l-1}[j])\\ ] ] using the values of @xmath394),l(u_{k+1}^{i}[lj+1]),\\ldots , l(u_{k+1}^{i}[lj+l-1])\\ ] ] leads to a graph analogous to the shown in the fig .",
    "[ fig : simplified ] , this time isomorphic to the tanner graph of the matrix @xmath395 . in general this problem can not be reduced to belief propagation algorithm working on a tree and requires exponential in @xmath387 number of operations .",
    "computation of @xmath396)$ ] is always possible by enumeration of all possible events . for brevity ,",
    "denote @xmath397,$]@xmath398,y = y_{k}[j]$],@xmath399 $ ] .",
    "then @xmath400 let @xmath401 be the set of all vectors @xmath8 such that @xmath402=xg^{-1},\\ ] ] where @xmath403 stands for @xmath404 arbitrary bits .",
    "then @xmath405 where @xmath406 is component @xmath47 of @xmath407 . inserting the last equality for @xmath408 into numerator and denominator of ( [ eq : l - u - m ] ) , we get @xmath409 dividing the numerator and denominator by @xmath410 we get @xmath411 where @xmath412 using the last equality , write @xmath413 this gives the recursive formula for computation of @xmath396)$ ] in the case of arbitrary matrix @xmath386 , however involving sums with exponential in @xmath387 number of terms .      for",
    "some polarization kernels , the formulas ( [ eq : kernel - recursion ] ) may be replaced by simpler relations containing familiar operations @xmath414 and @xmath41 .",
    "for example , consider the matrix @xmath415.\\ ] ] note that @xmath416 and draw the tanner graph analogous to the shown in the fig .",
    "[ fig : simplified ] but corresponding to @xmath417 ( fig .",
    "[ fig : g3 ] ) .",
    "[ fig : g3 ] ]    we now find the expression for @xmath418)$ ] .",
    "the vertices @xmath419 $ ]  @xmath420 $ ] may be removed from the graph together with incident equations .",
    "we obtain the graph shown in the fig .",
    "[ fig : g3 - 1 ] . using results of section",
    "[ sec : bp - on - trees ] , one can write @xmath421)=l(u_{k+1}^{q}[3j]){\\mathbin{\\scalebox{0.75}{$\\square$}}}l(u_{k+1}^{q}[3j+1]){\\mathbin{\\scalebox{0.75}{$\\square$}}}l(u_{k+1}^{q}[3j+2]).\\ ] ]     after removal of excessive vertices[fig : g3 - 1 ] ]    in order to find @xmath422)$ ] , the quantity @xmath423 $ ] should be considered known exactly .",
    "we have to remove the vertex @xmath420 $ ] from the graph in fig .",
    "[ fig : g3 ] and the incident equation ( fig .",
    "[ fig : g3 - 2 ] ) . from the last graph",
    "we conclude that @xmath424)= l(u_{k+1}^{q}[3j+1])+\\\\ & & \\qquad(-1)^{u_{k}^{3q}[j]}(l(u_{k+1}^{q}[3j]){\\mathbin{\\scalebox{0.75}{$\\square$}}}l(u_{k+1}^{q}[3j+2])).\\end{aligned}\\ ] ] similarly we can write the third formula : @xmath425)=l(u_{k+1}^{q}[3j+2])+\\\\ & & \\qquad(-1)^{u_{k}^{3q}[j]\\oplus u_{k}^{3q+1}[j]}l(u_{k+1}^{q}[3j]).\\end{aligned}\\ ] ]     after removal of excessive vertex[fig : g3 - 2 ] ]    in an analogous way , one can try to obtain recurrent formulas for an arbitrary polarization kernel .",
    "if the tanner graph for some fixed index is not tree - like , one can try to amend it by adding some equations to other ones .",
    "further , if a cycle contains an exactly known bit , the cycle can be broken by doubling the respective vertex .",
    "unfortunately , starting from @xmath426 the tree - like graph can be obtained only for some of polarization kernels .",
    "those kernels which admit simple formulas also admit simple code construction and analysis .",
    "for instance , in the example considered above the recurrent formulas for probability functions have the form @xmath427 for polarization kernels which do not admit simple recurrent formulas , the problem of code construction is open . in general , the computation of probability functions @xmath428 via @xmath267 is a multidimensional summation problem .",
    "possible solutions are monte - carlo method and approximations by normal distribution .",
    "in this section we consider a method of performance improvement for polar codes in which short classic error correcting codes are used together with polar codes .",
    "let @xmath429 be a set of linear codes of equal length @xmath430 .",
    "let @xmath431 be the number of information bits in the code @xmath432 .",
    "let @xmath433 be some @xmath434 matrix each of whose elements is @xmath14 or @xmath15 .",
    "denote by @xmath435 with @xmath436 and @xmath437 the elements of @xmath433 , by @xmath438 its row @xmath144 and by @xmath439 its column @xmath85 . for all @xmath440 choose some integer @xmath441 in the range @xmath15 to @xmath77 .",
    "we consider only such matrices @xmath433 whose columns @xmath439 are codewords of @xmath442 , i.e. @xmath443    consider an arbitrary polar code of length @xmath444 and rate @xmath15 , i.e. without redundancy , with matrix generator @xmath445 .",
    "encode each row of @xmath433 with this polar code obtaining a new matrix @xmath446 : @xmath447 if the matrix @xmath448 is `` reshaped '' into a row , one can consider the set of all such possible rows subject to restriction ( [ eq : constraint ] ) as a linear code of length @xmath449 and rate @xmath450 thus obtained linear code we will call the _ concatenated polar code_. let @xmath407 be the matrix received after the transmission of @xmath448 through the channel and let @xmath451 be its row @xmath144 .",
    "the decoder works by applying alternatively the steps of successive cancellation method for rows of @xmath407 and maximum likelihood decoder for its columns .    in order to decode the column @xmath452 ,",
    "compute for each row of @xmath407 independently the logarithmic likelihood ratios @xmath453 just like in the usual successive cancellation method .",
    "then the values @xmath454 , @xmath455 gathered in a vector @xmath7 are given as input to ml - decoder for the code @xmath456 .",
    "the most likely codeword @xmath457 produced on output is taken as an estimate of @xmath452 .",
    "next we compute the estimate of @xmath458 . assuming @xmath452 already known ,",
    "again compute for each row independently the llrs @xmath459 concatenate the values @xmath460 into a vector @xmath7 , which will be the input of ml - decoder for the code @xmath461 .",
    "the obtained codeword is taken as an estimate of @xmath458 .",
    "next , assuming @xmath452 and @xmath458 exactly known , compute the estimate of @xmath462 etc .",
    "note that the polar codes are a special case of concatenated polar codes for @xmath463 , @xmath464 and @xmath465 @xmath466 . in this case ,",
    "bit @xmath85 is frozen if @xmath467 , and it is information bit , if @xmath468 .",
    "let @xmath236 be the error probability for estimation of column @xmath85 under the constraint that all previous columns were estimated error - free .",
    "write again the upper bound for block error probability : @xmath469    fix some symmetric channel @xmath122 , set of codes @xmath470 of length @xmath430 , polar code of length @xmath444 and rate @xmath15 .",
    "we require to construct a concatenated polar code of given rate @xmath471 , i.e. choose numbers @xmath472 such that @xmath473 we will choose these numbers so as to minimize the upper bound ( [ eq : upper - bound ] ) .",
    "denote by @xmath474 the error probability for estimation of the column @xmath475 under the constraint that all previous columns were estimated error - free and @xmath476 .",
    "note that @xmath474 does not depend on @xmath477 for all @xmath478 .",
    "for a concrete choice of @xmath472 we can write the following upper bound for @xmath479 , @xmath480 assume for now that for all @xmath440 and @xmath481 we can compute @xmath474 . in order to choose the optimal @xmath472 , we will use the dynamic programming method .",
    "let @xmath482 be the minimal possible value of the sum @xmath483 under the constraint @xmath484 or let @xmath485 , if there is no sets of @xmath486 satisfying ( [ eq : sum - k - equals - t ] ) . for convenience ,",
    "set @xmath485 for @xmath487 .",
    "it is easy to note that @xmath488 introduce the notation , any of those can serve as @xmath489 . ]",
    "@xmath490 to make the formula ( [ eq : f - s - plus - one ] ) correct also for @xmath491 , let @xmath492 now using ( [ eq : f - s - plus - one ] ) for sequential computation of @xmath493 for @xmath494 and all @xmath47 , and saving the corresponding quantities @xmath489 , one can compute @xmath495 which by definition is the minimal possible value of the sum ( [ eq : upper - bound - re ] ) under the constraint ( [ eq : sum - k - equals - k ] ) . if @xmath496",
    ", there is no set of @xmath472 satisfying the constraint ( [ eq : sum - k - equals - k ] ) .",
    "now we get back to the problem of estimating @xmath474 .",
    "since the channel is symmetric and the code is linear , we assume the all - zero codeword is sent .",
    "suppose that the columns @xmath499 have been estimated correctly and the decoder is to estimate @xmath439 . next",
    "the ml - decoder for the code @xmath500 takes on input the vector @xmath501.\\ ] ] for convenience , introduce the notation @xmath502 .",
    "the components of @xmath503 are i.i.d",
    ". random variables . their probability function ( or pdf )",
    "@xmath504 can be computed approximately using the method described in section  [ sec : design ] .",
    "we can assume that the column @xmath439 is transmitted via some symmetric channel with llr distribution @xmath504 .",
    "thus the problem of computing @xmath474 is reduced to the estimation of error probability for the ml - decoder on a channel with given probability function @xmath505 . as stated in the introduction ,",
    "the ml - decoder minimizes the linear functional @xmath506 where @xmath507 $ ] runs over all codewords of the code @xmath508 .",
    "for the all - zero codeword the functional @xmath509 is zero .",
    "hence if the decoding error occurs , there necessarily exists some codeword @xmath510 such that @xmath511 .",
    "the last inequality can be rewritten as the sum of @xmath512 terms , @xmath513 some nonzero codeword @xmath510 will be strictly more preferable than @xmath14 if @xmath514 and in this case the decoder error will surely occur . if @xmath515 , the decoder may choose the correct codeword among those which zero the functional @xmath509",
    ". for simplicity assume that @xmath515 also implies the decoder error .",
    "write the probability of the event that for a fixed @xmath510 the inequality @xmath511 holds as @xmath516 the sum consists of @xmath512 i.i.d .",
    "random variables with the probability function @xmath504 , therefore the probability function of the sum is @xmath517 it follows that the probability of the event @xmath511 depends only on the weight @xmath518 of the codeword @xmath510 and it can be written as @xmath519 the main contribution in the error probability is made by codewords of minimal weight .",
    "let @xmath520 be the code distance of the code @xmath508 , and let @xmath521 be the number of different codewords of weight @xmath520 in the code @xmath508 .",
    "then the probability @xmath474 may be estimated as @xmath522 experiments show that this value is likely to overestimate the real error probability ( computed by a monte - carlo simulation ) by a constant factor which does not depend on the channel .",
    "for this reason in experiments reported in this paper a simple empiric technique was used to correct the multiplier @xmath523 .",
    "each of the codes @xmath524 was simulated on an awgn channel with different snr ratios to obtain its fer curve .",
    "the number @xmath523 was chosen so that the estimate ( [ eq : estimate ] ) fitted the experimental curve best .",
    "we do not have a theoretical justification of this procedure , however the results of numerical experiments show its high accuracy .    in a similar way one can estimate the fer of a concrete concatenated polar code on a given channel .",
    "it is sufficient to approximate numerically the sum @xmath525 and take it as an upper bound for block error rate .      for the construction of concatenated polar codes",
    "consider a set of @xmath526 different codes of length @xmath527 .",
    "numbers of information bits @xmath528 and code distances @xmath529 for each code are given in the table  [ tab : palette ] .",
    "the first interesting question is the accuracy of the block error estimate ( [ eq : fer - bound ] ) which is computed approximately . in the fig .",
    "@xmath530 we show the performance graph of the concatenated polar code of length @xmath375 and rate @xmath380 on an awgn channel .",
    "the code was constructed for the channel with snr@xmath531db .",
    "the solid curve represents the monte - carlo estimate , the dotted curve is the estimate ( [ eq : fer - bound ] ) computed approximately .",
    "one can see that the curves are practically identical within the limit of applicability of the monte - carlo method .",
    "c|cccc|cccc|cccc|cc @xmath85 & @xmath431 & @xmath532 & & @xmath85 & @xmath431 & @xmath532 & & @xmath85 & @xmath431 & @xmath532 & & @xmath85 & @xmath431 & @xmath532 1 & 0 & @xmath533 & & 8 & 7 & 14 & & 15 & 21 & 6 & & 22 & 28 & 2 2 & 1 & 32 & & 9 & 8 & 13 & & 16 & 22 & 5 & & 23 & 29 & 2 3 & 2 & 21 & & 10 & 11 & 12 & & 17 & 23 & 4 & & 24 & 30 & 2 4 & 3 & 18 & & 11 & 13 & 10 & & 18 & 24 & 4 & & 25 & 31 & 2 5 & 4 & 16 & & 12 & 14 & 8 & & 19 & 25 & 4 & & 26 & 32 & 1 6 & 5 & 16 & & 13 & 15 & 8 & & 20 & 26 & 4 & & & & 7 & 6 & 16 & & 14 & 16 & 8 & & 21 & 27 & 2 & & & &            it is also interesting to compare the performance of polar code and of concatenated polar code of the same length and rate .",
    "[ fig:1024-ecc - vs - simple ] shows the performance graph of the concatenated polar code of length @xmath375 and rate @xmath30 which was already presented above together with the polar code of the same length and rate .",
    "both codes were constructed for an awgn channel with snr@xmath531db .",
    "one can see that the concatenated code outperforms the usual one by an order of magnitude .",
    "the figures  [ fig:8k - ecc - vs - simple ] and [ fig:8k - r75-ecc - vs - simple ] show analogous comparative graphs for the codes of length @xmath535 and rates @xmath30 and @xmath536 , respectively .",
    "similar to the previous example , concatenated polar codes also outperform the usual ones approximately by an order of magnitude .",
    "s.  chung , g.  d. forney , t.  j. richardson , and r.  urbanke , `` on the design of low - density parity - check codes within 0.0045 db of the shannon limit , '' _ ieee communications letters _ ,",
    "vol .  5 , pp .",
    "5860 , 2001 ."
  ],
  "abstract_text": [
    "<S> we consider two problems related to polar codes . first is the problem of polar codes construction and analysis of their performance without monte - carlo method . </S>",
    "<S> the formulas proposed are the same as those in [ mori - tanaka ] , yet we believe that our approach is original and has clear advantages . </S>",
    "<S> the resulting computational procedure is presented in a fast algorithm form which can be easily implemented on a computer . </S>",
    "<S> secondly , we present an original method of construction of concatenated codes based on polar codes . </S>",
    "<S> we give an algorithm for construction of such codes and present numerical experiments showing significant performance improvement with respect to original polar codes proposed by arikan . </S>",
    "<S> we use the term _ concatenated code _ not in its classical sense ( e.g. [ forney ] ) . </S>",
    "<S> however we believe that our usage is quite appropriate for the exploited construction . </S>",
    "<S> further , we solve the optimization problem of choosing codes minimizing the block error of the whole concatenated code under the constraint of its fixed rate . </S>"
  ]
}