{
  "article_text": [
    "we consider interactive learning and covering problems , a term introduced in @xcite . in these problems",
    ", there is an algorithm that interactively selects actions and receives a response for each action .",
    "its goal is to achieve an objective , whose value depends on the actions it selected , their responses , and the state of the world .",
    "the state of the world , which is unknown to the algorithm , also determines the response to each action .",
    "the algorithm incurs a cost for every action it performs .",
    "the goal is to have the total cost incurred by the algorithm as low as possible .",
    "many real - world problems can be formulated as interactive learning and covering problems .",
    "these include pool - based active learning problems @xcite , maximizing the influence of marketing in a social network @xcite , interactive sensor placement @xcite and document summarization @xcite with interactive user feedback .",
    "interactive learning and covering problems can not be solved efficiently in general @xcite .",
    "nevertheless , many such problems can be solved near - optimally by efficient algorithms , when the functions that map the sets of actions to the total reward are _",
    "submodular_.    it has been shown in several settings , that a simple greedy algorithm pays a near - optimal cost when the objective function is submodular ( e.g. ,  @xcite ) .",
    "many problems naturally lend themselves to a submodular formulation .",
    "these include covering objectives , objectives promoting diversity @xcite and active learning @xcite .",
    "interactive learning and covering problems have so far been studied mainly under the assumption that the cost of the action is known to the algorithm before the action is taken . in this work",
    "we study the setting in which the costs of actions depend on the outcome of the action , which is only revealed by the observed response .",
    "this is the case in many real - world scenarios .",
    "for instance , consider an active learning problem , where the goal is to learn a classifier that predicts which patients should be administered a specific drug .",
    "each action in the process of learning involves administering the drug to a patient and observing the effect . in this case , the cost ( poorer patient health ) is higher if the patient suffers adverse effects . similarly , when marketing in a social network , an action involves sending an ad to a user .",
    "if the user does not like the ad , this incurs a higher cost ( user dissatisfaction ) than if they like the ad .",
    "we study the achievable approximation guarantees in the setting of response - dependence costs , and characterize the dependence of this approximation factor on the properties of the cost function .",
    "we propose a natural generalization of the greedy algorithm of @xcite to the response - dependent setting , and provide two approximation guarantees .",
    "the first guarantee holds whenever the algorithm s objective describes an active learning problem .",
    "we term such objectives _ learning objectives_. the second guarantee holds for general objectives , under a mild condition . in each case , the approximation guarantees depend on a property of the cost function , and we show that this dependence is necessary for any greedy algorithm . thus , this fully characterizes the relationship between the cost function and the approximation guarantee achievable by a greedy algorithm .",
    "we further report experiments that demonstrate the achieved cost improvement .",
    "response - dependent costs has been previously studied in specific cases of active learning , assuming there are only two possible labels @xcite . in @xcite",
    "this setting is also mentioned in the context of active learning .",
    "our work is more general : first , it addresses general objective functions and not only specific active learning settings .",
    "our results indicate that the active learning setting and the general setting are inherently different .",
    "second , it is not limited to settings with two possible responses . as we show below , previous guarantees for two responses do not generalize to tight guarantees for cases with more than two responses .",
    "we thus develop new proof techniques that allow deriving these tighter bounds .",
    "for an integer @xmath0 , denote @xmath1 : = \\{1,\\ldots , n\\}$ ] . a set function",
    "@xmath2 is _ monotone _ ( non - decreasing ) if @xmath3 , @xmath4 .",
    "let @xmath5 be a domain , and let @xmath6 be a set function .",
    "define , for any @xmath7 , @xmath8 .",
    "@xmath9 is _ submodular _ if @xmath10    assume a finite domain of actions @xmath11 and a finite domain of responses @xmath12 . for simplicity of presentation",
    ", we assume that there is a one - to - one mapping between world states and mappings from actions to their responses .",
    "thus the states of the world are represented by the class of possible mappings @xmath13 .",
    "let @xmath14 be the true , unknown , mapping from actions to responses .",
    "let @xmath15 be a set of action - response pairs .",
    "we consider algorithms that iteratively select a action @xmath16 and get the response @xmath17 , where @xmath14 is the true state of the world , which is unknown to the algorithm .",
    "for an algorithm @xmath18 , let @xmath19 $ ] be the set of pairs collected by @xmath18 until termination if @xmath20 .",
    "let @xmath21 $ ] be the set of pairs collected by @xmath18 in the first @xmath22 iterations if @xmath20 . in each iteration",
    ", @xmath18 decides on the next action to select based on responses to previous actions , or it decides to terminate .",
    "@xmath23 denotes the action that @xmath18 selects after observing the set of pairs @xmath24 , where @xmath25 if @xmath18 terminates after observing @xmath24 .",
    "each time the algorithm selects an action and receives a response , it incurs a cost , captured by a cost function @xmath26 .",
    "if @xmath16 is selected and the response @xmath27 is received , the algorithm pays @xmath28 .",
    "denote @xmath29 .",
    "the total cost of a run of the algorithm when the state of the world is @xmath30 , is thus @xmath31)$ ] . for a given @xmath32 , define the _ worst - case cost _ of @xmath18 by @xmath33)$ ] .",
    "let @xmath34 be a threshold , and let @xmath35 be a monotone non - decreasing submodular objective function .",
    "we assume that the goal of the interactive algorithm is to collect pairs @xmath24 such that @xmath36 , while minimizing @xmath37 .",
    "guillory and bilmes @xcite consider a setting in which instead of a single global @xmath9 , there is a set of monotone non - decreasing objective functions @xmath38 , and the value @xmath39 , for @xmath15 , represents the reward obtained by the algorithm if @xmath20 .",
    "they show that obtaining @xmath40 is equivalent to obtaining @xmath41 , where @xmath42 is defined by @xmath43 here @xmath44 is the _ version space _ induced by @xmath24 on @xmath32 , defined by .",
    "it is shown in @xcite that if all the functions in @xmath45 are monotone and submodular then so is @xmath46 .",
    "thus our setting of a single objective function can be applied to the setting of @xcite as well .",
    "let @xmath47 .",
    "an interactive algorithm @xmath18 is an _",
    "_ _ greedy algorithm _ for _ utility function _ , if the following holds : for all @xmath15 , if @xmath36 then @xmath25 , and otherwise , @xmath49 and @xmath50 . as shown below , consistently with previous works , ( e.g. @xcite ) , competitive guarantees are better for @xmath48-approximate - greedy algorithms with @xmath51 or @xmath48 close to @xmath52 . however ,",
    "due to efficiency of computation or other practical considerations , it is not always feasible to implement a @xmath52-greedy algorithm .",
    "thus , for full generality , we analyze also @xmath48-greedy algorithms for @xmath53 .",
    "let @xmath54 , where the minimum is taken over all interactive @xmath18 that obtain @xmath36 at termination , for all for all possible @xmath14 .",
    "if no such @xmath18 exist , define @xmath55 .",
    "in @xcite it is assumed that costs are not response - dependent , thus @xmath56 , and a greedy algorithm is proposed , based on the following utility function : @xmath57 it is shown that for integral functions , this algorithm obtains an integer @xmath58 with a worst - case cost of at most @xmath59 , where @xmath60 is a lower bound on @xmath61 . in @xcite , a different greedy algorithm and analysis guarantees a worst - case cost of @xmath62 for adaptive submodular objectives and @xmath48-approximate greedy algorithms .",
    "it is well known that the factor of @xmath63 can not be substantially improved by an efficient algorithm , even for non - interactive problems @xcite .",
    "the results of @xcite can be trivially generalized to the response - dependent cost setting using the _ cost ratio _ of the problem : @xmath64 consider a generalized version of @xmath65 : @xmath66 setting @xmath67 , we have @xmath68 . using this fact , it is easy to derive an approximation guarantee of @xmath69 , for a greedy algorithm which uses the utility function in eq .",
    "( [ eq : utilitygb ] ) with a response - dependent cost , or @xmath70 when applied to the setting of @xcite . however , in this work we show that this trivial derivation is loose , since our new approximation bounds can be finite even if @xmath71 is infinite .",
    "we provide approximation guarantee for two types of objective functions .",
    "the first type captures active learning settings , while the second type is more general .",
    "our results show that objective functions for active learning have better approximation guarantees than general objective functions . for both types of objective functions ,",
    "we analyze a greedy algorithm that selects an element maximizing ( or approximately maximizing ) the following utility function : @xmath72 note that @xmath73 is equal to the function @xmath65 defined in eq .",
    "( [ eq : utilitygb ] ) .",
    "we employ the following standard assumption in our results ( see e.g.  @xcite ) :    [ as : fterms ] let @xmath35 , @xmath74 , @xmath75 .",
    "assume that @xmath9 is submodular and monotone , @xmath76 , and that for any @xmath15 , if @xmath77 then @xmath36 .",
    "in section [ sec : learningobj ] we show an approximation guarantee for objectives meant for active learning , which we term _ learning objectives_. in section [ sec : generalobj ] we consider general monotone submodular objective functions .",
    "our guarantees hold for objective functions @xmath9 that satisfy the following property , which we term _ consistency - aware_. this property requires that the function gives at least @xmath58 to any set of action - response pairs that are inconsistent with @xmath32 .",
    "[ def : inconsistentweak ] a function @xmath35 is _ consistency - aware _ for threshold @xmath34 if for all @xmath15 such that @xmath78 , @xmath36 .    note that the definition is concerned with the value of @xmath9 only on inconsistent sets @xmath24 , which the algorithm never encounters .",
    "therefore , it suffices that there exist an extension of @xmath9 to these sets that is consistent with all the other requirements from @xmath9 .",
    "the function @xmath46 defined in eq .",
    "( [ eq : fbar ] ) is consistency - aware .",
    "in addition , a similar construction to @xmath46 with non - uniform weights for mappings is also consistency - aware .",
    "such a construction is sometimes more efficient to compute than the uniform - weight construction .",
    "for instance , as shown in @xcite , non - uniform weights allow a more efficient computation when the mappings represent linear classifiers with a margin . in general , any objective @xmath9 can be made consistency aware using a simple transformation such as @xmath46 .",
    "thus our results are relevant to a diverse class of problems .",
    "active learning is an important special case of interactive learning . in active learning ,",
    "the only goal is to discover information on the identity of @xmath30 .",
    "we term functions that represent such a goal _ learning objectives_.    [ def : learning ] a function @xmath35 is a _ learning objective _ for @xmath32 if @xmath79 where @xmath80 is a monotone non - increasing function .",
    "it is easy to see that all learning objectives @xmath81 are monotone non - decreasing in @xmath24 .",
    "in many useful cases , they are also submodular . in noise - free active learning , where the objective is to exactly identify the correct mapping @xmath30",
    ", one can use the learning objective @xmath82 , with @xmath83 .",
    "this is the _ version space reduction _ objective function @xcite . in @xcite noise - aware active learning and its generalization to the problem of equivalence class determination",
    "is considered . in this generalization",
    ", there is some partition of @xmath32 , and the goal is to identify the class to which @xmath30 belongs .",
    "the objective function proposed by @xcite measures the weight of pairs in @xmath44 in which each mapping belongs to a different class .",
    "this function is also a learning objective . in @xcite",
    "the _ total generalized version space reduction _ function is proposed .",
    "this function is also a learning objective .",
    "more generally , consider a set of structures @xmath84 , where the goal is to disqualify these structures from the version space , by proving that at least one of the mappings in this structure can not be the true @xmath30 . in this case",
    "one can define the submodular learning objective @xmath85 , where @xmath86 is a modular weight function on @xmath87 , and @xmath88 .",
    "for instance , if @xmath87 is the set of pairs from different equivalence classes in @xmath32 , this is the equivalence class determination objective . if @xmath87 is a set of triplets from different equivalence classes , this encodes an objective of reducing the uncertainty on the identity of @xmath30 to at most two equivalence classes",
    "we show that for learning objectives , the approximation factor for a greedy algorithm that uses @xmath89 depends on a new property of the cost function , which we term the _ second - smallest cost ratio _ , denoted by @xmath90}}_{\\mathfrak{cost}}$ ] . for @xmath16 ,",
    "let @xmath91 be the second - smallest value in the multiset .",
    "define @xmath92}}_{\\mathfrak{cost}}:= \\max_{x\\in { \\mathcal{x}},y \\in { \\mathcal{y}}}\\frac{{\\mathfrak{cost}}(x , y)}{\\operatorname{\\phi}(x)}.\\ ] ]    [ thm : worstcase ] let @xmath93 such that assumption [ as : fterms ] holds .",
    "let @xmath18 be an @xmath48-approximate greedy algorithm for the utility function @xmath89 .",
    "if @xmath9 is a learning objective , then @xmath94}}_{\\mathfrak{cost}}\\cdot \\alpha    ( \\ln(q/\\eta)+1){\\mathrm{opt}}.$ ]    the ratio between the trivial bound that depends on the cost ratio @xmath71 , mentioned in section [ sec : setting ] , and this new bound , is @xmath95}}_{\\mathfrak{cost}}$ ] , which is unbounded in the general case : for instance , if each action has one response which costs @xmath52 and the other responses cost @xmath96 , then @xmath97 but @xmath90}}_{\\mathfrak{cost}}= 1 $ ] . whenever @xmath98 , @xmath90}}_{\\mathfrak{cost}}=1 $ ] .",
    "thus , the approximation factor of the greedy algorithm for any binary active learning problem is independent of the cost function .",
    "this coincides with the results of @xcite for active learning with binary labels . if @xmath99 , then the bound is smallest when @xmath90}}_{\\mathfrak{cost}}= 1 $ ] , which would be the case if for each action there is one preferred response which has a low cost , while all other responses have the same high cost .",
    "for instance , consider a marketing application , in which the action is to recommend a product to a user , and the response is either buying the product ( a preferred response ) , or not buying it , in which case additional feedback could be provided from the user , but the cost ( user dissatisfaction ) remains the same regardlesss of that feedback .    to prove theorem [ thm : worstcase ] , we use the following property of learning objectives : for such objectives , there exists an optimal algorithm ( that is , one that obtains @xmath61 ) that only selects actions for which at least two responses are possible given the action - response pairs observed so far .",
    "formally , we define _ bifurcating _ algorithms . denote the set of possible responses for",
    "@xmath100 given the history @xmath24 by we omit the subscript @xmath32 when clear from context .",
    "an interactive algorithm @xmath18 is _ bifurcating _ for @xmath32 if for all @xmath22 and @xmath101 , @xmath102),s^h_{t}[{\\mathcal{a}}])| \\geq 2 $ ] .",
    "[ lem : bifurcating ] for any learning objective @xmath9 for @xmath32 with an optimal algorithm , then there exists a bifurcating optimal algorithm for @xmath103 .",
    "let @xmath18 be an optimal algorithm for @xmath9 .",
    "suppose there exists some @xmath104 such that for some @xmath105 , where @xmath106)$ ] .",
    "let @xmath107 be an algorithm that selects the same actions as @xmath18 , except that it skips the action @xmath108 it if has collected the pairs @xmath109 $ ] .",
    "that is , @xmath110 for @xmath111 $ ] , and @xmath112 for @xmath113 .",
    "since , and @xmath18 is a learning objective , @xmath107 obtains @xmath58 as well , at the same cost of @xmath18 or less . by repeating this process a finite number of steps , we can obtain an optimal algorithm for @xmath32 which is bifurcating .    the following lemma is the crucial step in proving theorem [ thm : worstcase ] , and will also be used in the proof for the more general case below .",
    "the lemma applies to general consistency - aware functions .",
    "it can be used for learning objectives , because all learning objectives with a finite @xmath61 are consistency - aware : suppose that @xmath9 is a learning objective , and let @xmath15 such that @xmath78 .",
    "for any @xmath101 , denote @xmath114 .",
    "we have @xmath115 , therefore , since @xmath9 is a learning objective , @xmath116 . since @xmath61 is finite , @xmath117 . therefore @xmath36 .",
    "thus @xmath9 is consistency - aware .",
    "[ lem : onestep ] let @xmath118 which satisfy assumption [ as : fterms ] such that @xmath9 is consistency - aware .",
    "let @xmath18 be an interactive algorithm that obtains @xmath36 at termination .",
    "let @xmath119}}_{\\mathfrak{cost}}$ ] if @xmath18 is bifurcating , and let @xmath120 otherwise .",
    "then @xmath121    denote for brevity @xmath122 .",
    "define @xmath123 .",
    "consider an algorithm @xmath124 such that for any @xmath24 that is consistent with some @xmath125 ( that is @xmath126 ) , @xmath127 , and @xmath128 otherwise .",
    "since @xmath9 is consistency - aware , we have @xmath129 ) \\geq q$ ] for all @xmath130 .",
    "consider a run of @xmath131 , and denote the pair in iteration @xmath22 of this run by @xmath132 .",
    "denote @xmath133 .",
    "choose the run such that in each iteration @xmath22 , the response @xmath134 is in @xmath135 .",
    "let @xmath136 be the length of the run until termination .",
    "denote @xmath137)$ ] , the worst - case cost of @xmath131 over @xmath138 .",
    "we have @xmath139 } ( f(s_t ) - f(s_{t-1}))}{\\sum_{t\\in [ t ] } { \\mathfrak{cost}}(x_t , y_t)}\\\\ & = \\frac{\\sum_{t\\in [ t ] } \\delta((x_t , y_t)\\mid s_{t-1})}{\\sum_{t \\in [ t ] } { \\mathfrak{cost}}(x_t , y_t ) } \\leq \\max _ { t\\in [ t ] } \\left(\\delta((x_t , y_t)\\mid s_{t-1})/{\\mathfrak{cost}}(x_t , y_t)\\right),\\end{aligned}\\ ] ] where we used @xmath76 in the second line .",
    "thus there exists some @xmath140 $ ] such that @xmath141    therefore @xmath142 the second line follows from the submodularity of @xmath9 .",
    "the third line follows from the definition of @xmath134 .",
    "to prove the claim , we have left to show that .",
    "consider again a run of @xmath131 .",
    "if all observed pairs are consistent with some @xmath101 , @xmath131 and @xmath18 behave the same .",
    "hence @xmath143 ) = { \\mathfrak{cost}}(s^h[{\\mathcal{a}}])$ ] .",
    "now , consider @xmath144 . by the definition of @xmath131 ,",
    "@xmath145 $ ] is a prefix of @xmath19 $ ] .",
    "let @xmath146|$ ] be the number of iterations until @xmath131 terminates . then @xmath147 $ ]",
    "is consistent with some @xmath148 .",
    "let @xmath149 be the action that @xmath18 and @xmath131 select at iteration @xmath136 , and let @xmath148 which is consistent with @xmath147 $ ] , and incurs the maximal possible cost in iteration @xmath136 .",
    "formally , @xmath150 satisfies @xmath151 ) }   { \\mathfrak{cost}}(x_t , y)$ ] .",
    "now , compare the run of @xmath131 on @xmath152 to the run of @xmath18 on @xmath150 . in the first @xmath153 iterations ,",
    "the algorithms observe the same pairs . in iteration @xmath136",
    ", they both select @xmath149 .",
    "@xmath131 observes @xmath154 , while @xmath18 observes @xmath155 .",
    "@xmath131 terminates after iteration @xmath136 .",
    "hence    @xmath143 ) = { \\mathfrak{cost}}(s_{t-1}^h[{\\mathcal{a } } ] ) + { \\mathfrak{cost}}(x_t , h(x_t ) ) = { \\mathfrak{cost}}(s_t^{h'}[{\\mathcal{a } } ] ) - { \\mathfrak{cost}}(x_t , h'(x_t ) ) + { \\mathfrak{cost}}(x_t , h(x_t)).$ ]    consider two cases : ( a ) @xmath18 is not bifurcating",
    ". then @xmath156 , and so @xmath157 .",
    "( b ) @xmath18 is bifurcating .",
    "then there are at least two possible responses in @xmath158)$ ] .",
    "therefore @xmath159 . by the definition of @xmath90}}_{\\mathfrak{cost}}$ ] , @xmath160}}_{\\mathfrak{cost}}\\cdot \\phi(x_t)$ ] .",
    "therefore @xmath161 .    in both cases ,",
    "@xmath162    therefore    @xmath143 ) \\leq { \\mathfrak{cost}}(s_t^{h'}[{\\mathcal{a } } ] ) + ( \\gamma - 1){\\mathfrak{cost}}(x_t , h'(x_t ) ) \\leq \\gamma{\\mathfrak{cost}}(s_t^{h'}[{\\mathcal{a}}]),$ ]    where the last inequality follows since @xmath163)\\leq { \\mathfrak{cost}}(s_t^{h'}[{\\mathcal{a}}])$ ] .",
    "thus for all @xmath130 , @xmath143 ) \\leq \\gamma \\cdot { \\mathfrak{cost}}({\\mathcal{a}})$ ] , hence @xmath164 . combining this with eq .",
    "( [ eq : costbar ] ) , the proof is concluded .    in the proof of theorem [ thm : worstcase ]",
    "we further use the following lemmas , which can be proved using standard techniques ( see e.g.  @xcite ) .",
    "the proofs are omitted due to lack of space ,    [ lem : greedylem ] let @xmath165 .",
    "let @xmath118 such that assumption [ as : fterms ] holds .",
    "if for all @xmath15 , @xmath166 , then for any @xmath48-approximate greedy algorithm with @xmath89 , @xmath167    [ lem : fprime ] let @xmath118 such that assumption [ as : fterms ] holds and @xmath9 is consistency - aware . let @xmath15 .",
    "define @xmath168 by @xmath169 .",
    ". then    1 .",
    "@xmath171 is submodular , monotone and consistency - aware , with @xmath172 .",
    "2 .   let @xmath18 be an interactive algorithm for @xmath173 .",
    "let @xmath174 . if @xmath175 , where @xmath176 is the optimal cost for @xmath173 , then for any @xmath15 , @xmath177    let @xmath178 as in lemma [ lem : fprime ] , and let @xmath179 be an optimal algorithm for @xmath173",
    "let @xmath179 be an optimal algorithm for @xmath173 . since @xmath9 is a learning objective , then",
    "so is @xmath171 , and by lemma [ lem : bifurcating ] we can choose @xmath179 to be bifurcating . combining this with the first part of lemma [ lem : fprime ] , the conditions of lemma [ lem : onestep ] hold .",
    "therefore @xmath180}}_{\\mathfrak{cost}}\\cdot{\\mathrm{opt}}').$ ] by the second part of lemma [ lem : fprime ] ,    @xmath181}}_{\\mathfrak{cost}}\\cdot{\\mathrm{opt}}}.$ ]    therefore , by lemma [ lem : greedylem ] , @xmath182}}_{\\mathfrak{cost}}\\cdot { \\mathrm{opt}}.$ ]    next , we show that a linear dependence of the approximation guarantee on @xmath90}}_{\\mathfrak{cost}}$ ] is necessary for any greedy algorithm .",
    "to show the lower bound , we must exclude greedy algorithms that choose the utility function according to the set of available actions @xmath11 .",
    "formally , define _ local _ greedy algorithms as follows .",
    "assume there is a super - domain of all possible actions @xmath183 , and consider an algorithm which receives as input a subset @xmath184 of available actions .",
    "we say that such an algorithm is _ local _ greedy if it greedily selects the next action out of @xmath11 using a fixed utility function @xmath185 , which does not depend on @xmath11 .",
    "the following lower bound shows that there exists a learning objective such that the approximation guarantee of any local greedy algorithm grows with @xmath90}}_{\\mathfrak{cost}}$ ] or is trivially bad .",
    "[ thm : lowerboundlearning ] let @xmath9 be the version - space reduction objective function with the corresponding @xmath83 and @xmath186 . for any value of @xmath61 , @xmath90}}_{\\mathfrak{cost } } > 1 $ ] , and integer size of @xmath187 , there exist @xmath188 , and @xmath189 such that @xmath28 depends only on @xmath190 , and such that for any local greedy algorithm @xmath18 , there exists an input domain @xmath184 such that , for @xmath191 as in theorem [ thm : worstcase ] , @xmath192}}_{\\mathfrak{cost}}}{\\log_2(q/\\eta)},\\frac{q/\\eta}{\\log_2(q/\\eta)}\\right ) \\cdot { \\mathrm{opt}}.\\ ] ] here @xmath37 and @xmath61 refer to the costs for the domain @xmath11 .",
    "define @xmath193 .",
    "let @xmath194\\ } \\cup \\{b_j^t \\mid j\\in [ k ] , t \\in [ { { \\lceil \\log_2(k-2)\\rceil}}]\\}$ ] .",
    "let @xmath195 for all @xmath16 , where @xmath196 .",
    "set @xmath197 such that @xmath90}}_{\\mathfrak{cost}}= c_3/c_2 $ ] .",
    "let @xmath198\\}$ ] , where @xmath199 is defined as follows : for @xmath200 , @xmath201 for @xmath202 and @xmath203 , let @xmath204 be the location of @xmath205 in @xmath206 , where the locations range from @xmath207 to @xmath208 .",
    "denote by @xmath209 the @xmath22th most significant bit in the binary expansion of @xmath204 to @xmath210 bits .",
    "define @xmath211    fix an index @xmath212 $ ] .",
    "let @xmath213\\ } \\cup \\ { b^t_n \\mid t \\in [ { { \\lceil \\log_2(k-2)\\rceil}}]\\}$ ] .",
    "we now show an interactive algorithm for @xmath214 and bound its worst - case cost . on the first iteration ,",
    "the algorithm selects action @xmath215 . if the result is @xmath52 , then @xmath216 , hence @xmath36 . in this case",
    "the cost is @xmath217 .",
    "otherwise , the algorithm selects all actions in @xmath218 .",
    "the responses reveal the binary expansion of @xmath219 , thus limiting the version space to the a single @xmath199 , hence @xmath36 . in this case",
    "the total cost is at most @xmath220 .",
    "now , consider a local greedy algorithm .",
    "let @xmath221 \\rightarrow [ k]$ ] be a permutation that represents the order in which @xmath222 would be selected by the utility function if only @xmath223 were available , and their response was always @xmath224 .",
    "formally , @xmath225 } u(a_{\\sigma(i)},\\{(a_{\\sigma(i')},2 ) \\mid i ' \\in [ i-1 ] \\})$ ] .",
    "whenever @xmath226    suppose the input to the algorithm is @xmath227 .",
    "denote @xmath228 \\}$ ] , and suppose @xmath229 .",
    "first , assume that @xmath230 .",
    "then all of @xmath231 are selected before any of @xmath232 , and the version space is reduced to a singleton only after these @xmath233 actions .",
    "therefore the cost of the run is at least @xmath234 .",
    "second , assume that this assumption does not hold .",
    "then there exists an integer @xmath235 such that @xmath236 .",
    "let @xmath235 be the smallest such integer .",
    "then , the algorithm receives @xmath224 on each of the actions @xmath237 , and its next action is @xmath232 for some @xmath22 . hence the cost of the run is at least @xmath238    to summarize , the worst - case cost of every local greedy algorithm is at least @xmath239 for at least one of the inputs @xmath214 .",
    "the worst - case cost of the optimal algorithm for each @xmath214 is at most @xmath220 .",
    "the statement of the theorem follows .      in the previous section we showed that for learning objectives , the achievable approximation guarantee for greedy algorithms is characterized by @xmath90}}_{\\mathfrak{cost}}$ ] .",
    "we now turn to general consistency - aware objective functions .",
    "we show that the factor of approximation for this class depends on a different property of the cost function , which is lower bounded by @xmath90}}_{\\mathfrak{cost}}$ ] .",
    "define @xmath240 , and let @xmath241}}_{\\mathfrak{cost}}:= \\frac{{{\\mathfrak{cost}}_{\\max}}}{\\phi_{\\min}}.\\ ] ] we term the ratio @xmath242}}_{\\mathfrak{cost}}$ ] the _ global second smallest cost ratio_. as we show below , the approximation factor is best when @xmath242}}_{\\mathfrak{cost}}$ ] is equal to @xmath52 .",
    "this is the case if there is at most one preferred response for every action , and in addition , all the non - preferred responses for all actions have the same cost .",
    "[ thm : nonlearning ] let @xmath93 such that assumption [ as : fterms ] holds and @xmath9 is consistency - aware .",
    "let @xmath18 be an @xmath48-approximate greedy algorithm for the utility function @xmath89",
    ". then @xmath243}}_{\\mathfrak{cost}},{r}_{\\mathfrak{cost } } ) \\cdot \\alpha \\cdot ( \\log(q/\\eta)+1 ) \\cdot { \\mathrm{opt}}.   $ ]    like theorem [ thm : worstcase ] for learning objectives , this result for general objectives is a significant improvement over the trivial bound , mentioned in section [ sec : setting ] , which depends on the cost ratio , since the ratio @xmath242}}_{\\mathfrak{cost}}/{r}_{\\mathfrak{cost}}$ ] can be unbounded .",
    "for instance , consider a case where each action has one response with a cost of @xmath52 and all other responses have a cost of @xmath96 . then @xmath97",
    "but @xmath242}}_{\\mathfrak{cost}}= 1 $ ] .",
    "the proof of theorem [ thm : nonlearning ] hinges on two main observations : first , any interactive algorithm may be `` reordered '' without increasing its cost , so that all actions with only one possible response ( given the history so far ) are last .",
    "second , there are two distinct cases for the optimal algorithm : in one case , for all @xmath101 , the optimal algorithm obtains a value of at least @xmath244 before performing actions with a single possible response . in the other case , there exists at least one mapping @xmath152 for which actions with a single possible response obtain at least @xmath244 of the value .",
    "we start with the following lemma , which handles the case where @xmath245 .",
    "[ lem : smallopt ] let @xmath35 , @xmath34 .",
    "suppose that @xmath9 is submodular , and @xmath246 .",
    "if @xmath245 , then @xmath247 .",
    "for every action @xmath16 there is at most a single @xmath190 with @xmath248 .",
    "denote this response by @xmath249 .",
    "let @xmath18 be an optimal algorithm for @xmath250 .",
    "for any value of @xmath14 , @xmath18 only receives responses with costs less than @xmath251 .",
    "therefore for any @xmath100 that @xmath18 selects , it receives the response @xmath249 , regardless of the identity of @xmath30 . in other words , for all @xmath101 , in every iteration @xmath22 , @xmath18 selects an action @xmath100 such that @xmath252 ) = \\{y(x)\\}$ ] .",
    "it follows that for all @xmath22 , @xmath253 $ ] is the same for all @xmath101 . therefore , there is a fixed set of actions that @xmath18 selects during its run , regardless of @xmath30 .",
    "let @xmath254 be that set .",
    "then for all @xmath255 , @xmath256 . for a set @xmath257 , denote @xmath258 } } = \\{(x , y(x ) ) \\mid x \\in a\\}$ ] .",
    "we have @xmath259 } } ) \\geq q$ ] and @xmath260 } } ) = { \\mathrm{opt}}$ ] . by the submodulrity of @xmath9 , and since @xmath76 , we have    @xmath261}})/{\\mathrm{opt}}\\leq \\sum_{x \\in { \\mathcal{x } } ' } f((x , y(x)))/\\sum_{x \\in { \\mathcal{x}}'}{\\mathfrak{cost}}(x , y(x)).$ ]    therefore there exists some @xmath262 with @xmath263 .",
    "moreover , for this @xmath100 we have @xmath264 .",
    "therefore @xmath265    we now turn to the main lemma , to address the two cases described above .",
    "[ lem : optc2 ] let @xmath35 , @xmath34 .",
    "suppose that @xmath9 is submodular , and @xmath246 .",
    "assume that @xmath9 is consistency - aware .",
    "there exists @xmath16 such that @xmath266}}_{\\mathfrak{cost } } , { r}_{\\mathfrak{cost } } ) { \\mathrm{opt}}}$ ] .    if @xmath245 , the statement holds by lemma [ lem : smallopt ] .",
    "suppose that @xmath267 .",
    "let @xmath179 be an optimal algorithm for @xmath250 .",
    "we may assume without loss of generality , that for any @xmath14 , if @xmath179 selects an action that has only one possible response ( given the current version space ) at some iteration @xmath22 , then all actions selected after iteration @xmath22 also have only one possible response .",
    "this does not lose generality : let @xmath22 be the first iteration such that the action at iteration @xmath22 has one possible response , and the action at iteration @xmath268 has two possible responses . consider an algorithm which behaves the same as @xmath179 , except that at iteration @xmath22 it selects the second action , and at iteration @xmath268 it selects the first action ( regardless of the response to the first action ) .",
    "this algorithm has the same cost as @xmath179 .    for @xmath101 ,",
    "define @xmath269)$ ] , where @xmath270 is the last iteration in which an action with more than one possible response ( given the current version space ) is selected , if @xmath20 .",
    "consider two cases : ( a ) @xmath271 and ( b ) @xmath272 . in case ( a )",
    ", there is a bifurcating algorithm that obtains @xmath273 at cost at most @xmath61 : this is the algorithm that selects the same actions as @xmath179 , but terminates before selecting the first action that has a single response given the current version space .",
    "we also have @xmath90}}_{\\mathfrak{cost}}\\leq \\min({gr^{[2]}}_{\\mathfrak{cost}},{r}_{\\mathfrak{cost}})$ ] . by lemma [ lem : onestep ]",
    ", there exists some @xmath16 such that @xmath266}}_{\\mathfrak{cost}},{r}_{\\mathfrak{cost}}){\\mathrm{opt}}}$ ] .    in case",
    "( b ) , let @xmath101 such that @xmath274 . denote @xmath275 $ ] .",
    "let @xmath276 be the action and the response received in iteration @xmath22 if @xmath20 .",
    "then @xmath277 . let @xmath278 . then @xmath279 .",
    "since @xmath76 and @xmath9 is submodular ,    @xmath280    in addition , @xmath281 .",
    "hence @xmath282 therefore there is some @xmath283 such that    @xmath284    therefore , @xmath285    now , @xmath286}}_{\\mathfrak{cost}}\\cdot \\phi_{\\min } \\leq { gr^{[2]}}_{\\mathfrak{cost}}\\cdot { \\mathrm{opt } } , $ ] from our assumption that @xmath267 , and @xmath287 therefore @xmath288}}_{\\mathfrak{cost}},{r}_{\\mathfrak{cost}}){\\mathrm{opt } } } , \\min_{y \\in { \\mathcal{y}}\\setminus \\{h(x_{t'})\\ } } \\frac{f(\\{(x_{t'},y)\\})}{{\\mathfrak{cost}}(x_{t'},y)}\\bigg\\}.\\end{aligned}\\ ] ]    we have left to show a lower bound on @xmath289 . by the choice of @xmath283 , @xmath290 has only one possible response given the current version space , that is @xmath291 .",
    "since the same holds for all @xmath292 , we have @xmath293 , hence also @xmath294 .",
    "it follows that for @xmath295 , the set @xmath296 is not consistent with any @xmath101 .",
    "since @xmath9 is consistency - aware , it follows that @xmath297 .",
    "therefore    @xmath298    hence @xmath299}}_{\\mathfrak{cost}},{r}_{\\mathfrak{cost}}){\\mathrm{opt}}}.$ ] it follows that @xmath300}}_{\\mathfrak{cost}},{r}_{\\mathfrak{cost}}){\\mathrm{opt}}}$ ] also in case ( b ) .",
    "using the lemmas above , the proof of theorem [ thm : nonlearning ] is straight forward .",
    "let @xmath178 as in lemma [ lem : fprime ] , and let @xmath179 be an optimal algorithm for @xmath173 .",
    "let @xmath179 be an optimal algorithm for @xmath173 .",
    "from the first part of lemma [ lem : fprime ] , the conditions of lemma [ lem : optc2 ] hold for @xmath173 .",
    "therefore @xmath301}}_{\\mathfrak{cost}},{r}_{\\mathfrak{cost}}){\\mathrm{opt}}'}.$ ] by the second part of lemma [ lem : fprime ] , @xmath302}}_{\\mathfrak{cost}},{r}_{\\mathfrak{cost}}){\\mathrm{opt}}}.$ ] therefore , by lemma [ lem : greedylem ] ,    @xmath303}}_{\\mathfrak{cost}},{r}_{\\mathfrak{cost } } ) ( \\log(q/\\eta ) + 1)\\cdot { \\mathrm{opt}}.$ ]    the guarantee of theorem [ thm : nonlearning ] for general objectives is weaker than the guarantee for learning objectives given in theorem [ thm : worstcase ] : the ratio @xmath304}}_{\\mathfrak{cost}},{r}_{\\mathfrak{cost}})/{r^{[2]}}_{\\mathfrak{cost}}$ ] is always at least @xmath52 , and can be unbounded .",
    "for instance , if there are two actions that have two responses each , and all action - response pairs cost @xmath52 , except for one action - response pair which costs @xmath96 , then @xmath305 but @xmath242}}_{\\mathfrak{cost}}= m$ ] .",
    "nonetheless , the following theorem shows that for general functions , a dependence on @xmath304}}_{\\mathfrak{cost}},{r}_{\\mathfrak{cost}})$ ] is essential in any greedy algorithm .",
    "[ thm : lowerboundgeneral ] for any values of @xmath242}}_{\\mathfrak{cost}},{r}_{\\mathfrak{cost } } > 0 $ ] , there exist @xmath306 with @xmath98 and @xmath90}}_{\\mathfrak{cost}}= 1 $ ] , and a submodular monotone @xmath9 which is consistency - aware , with @xmath307 , such that for any local greedy algorithm @xmath18 , there exists an input domain @xmath184 such that @xmath308}}_{\\mathfrak{cost}},{r}_{\\mathfrak{cost}})\\cdot { \\mathrm{opt } } , $ ] where @xmath37 and @xmath61 refer to the costs of an algorithm running on the domain @xmath11 .",
    "define @xmath309 .",
    "let @xmath310 be the desired values for @xmath242}}_{\\mathfrak{cost } } , { r}_{\\mathfrak{cost}}$ ] .",
    "let @xmath311 , @xmath312 .",
    "if @xmath313 , define @xmath314 , @xmath315 . otherwise , set @xmath316 .",
    "define @xmath317 .",
    "let @xmath194\\ } \\cup \\{b_i \\mid i \\in [ k]\\ } \\cup \\{c\\}$ ] .",
    "let @xmath318\\}$ ] where @xmath199 is defined as follows : @xmath319 , h_i(a_j ) = h_i(b_j)$ ] , and equal to @xmath52 if and only if @xmath320 , and zero otherwise , and @xmath321 , h_i(c ) = i \\bmod 2.$ ] let the cost function be as follows , where @xmath322 , and @xmath323 : @xmath324 , @xmath325 , and @xmath326 then @xmath242}}_{\\mathfrak{cost}}= g$ ] , @xmath327 as desired .",
    "define @xmath9 such that @xmath328 , @xmath329 if there exists in @xmath24 at least one of @xmath330 for some @xmath331 $ ] or @xmath332 for some @xmath331,y\\in { \\mathcal{y}}$ ] .",
    "otherwise , @xmath333 .",
    "note that @xmath334 is consistency - aware .",
    "fix an index @xmath212 $ ] .",
    "let @xmath213\\ } \\cup \\{b_n\\}$ ] .",
    "we have @xmath335 : an interactive algorithm can first select @xmath215 , and then , only if the response is @xmath336 , select @xmath337 . now , consider a local greedy algorithm with a utility function @xmath65 .",
    "let @xmath221 \\rightarrow [ k]$ ] be a permutation that represents the order in which @xmath222 would be selected by the utility function if only @xmath223 were considered , and their response was always @xmath336 .",
    "formally , @xmath225 } u(a_{\\sigma(i)},\\{(a_{\\sigma(i')},0 ) \\mid i ' \\in [ i-1 ] \\})$ ] .",
    "whenever @xmath226    now , suppose the input to the algorithm is @xmath227 .",
    "denote @xmath338 \\}$ ] , and suppose that there exists an integer @xmath235 such that @xmath339 , and let @xmath235 be the smallest such integer .",
    "then , if the algorithm receives @xmath207 on each of the actions @xmath237 , its next action will be @xmath340 . in this case , if @xmath229 , then @xmath340 is queried before @xmath341 is queried and the response @xmath342 is received .",
    "thus the algorithm pays at least @xmath343 in the worst - case . on the other hand ,",
    "if such an integer @xmath235 does not exist , then if @xmath229 , the algorithm selects actions @xmath231 before terminating . in this case",
    "the algorithm receives @xmath233 responses @xmath207 , thus its cost is at least @xmath344 . to summarize",
    ", every local greedy algorithm pays at least @xmath345 for at least one of the inputs @xmath214 , while @xmath335 . by the definition of @xmath346 , @xmath347 .",
    "hence the cost of the local greedy algorithm is at least @xmath348 .    to summarize , for both learning objectives and general objectives , we have shown that the factors @xmath90}}_{\\mathfrak{cost}}$ ] and @xmath242}}_{\\mathfrak{cost}}$ ] , respectively , characterize the approximation factors obtainable by a greedy algorithm .",
    ".results of experiments . left : facebook dataset , right : gr - qc dataset [ cols= \" < , < , < , < , < , < \" , ]     we performed experiments to compare the worst - case costs of a greedy algorithm that uses the proposed @xmath89 , to a greedy algorithm that ignores response - dependent costs , and uses instead variant of @xmath89 , notated @xmath349 , that assumes that responses for the same action have the same cost , which was set to be the maximal response cost for this action .",
    "we also compared to @xmath350 , a utility function which gives the same approximation guarantees as given in theorem [ thm : nonlearning ] for @xmath89 .",
    "formally , @xmath351 and @xmath352    we tested these algorithms on a social network marketing objective , where users in a social network are partitioned into communities .",
    "actions are users , and a response identifies the community the user belongs to .",
    "we tested two objective functions : `` edge users '' counts how many of the actions are users who have friends not from their community , assuming that these users can be valuable promoters across communities .",
    "the target value @xmath58 was set to @xmath353 .",
    "the second objective function was the version - reduction objective function , and the goal was to identify the true partition into communities out of the set of possible partitions , which was generated by considering several possible sets of `` center users '' , which were selected randomly .",
    "we compared the worst - case costs of the algorithms under several configurations of number of communities and the values of @xmath90}}_{\\mathfrak{cost}}$ ] , @xmath242}}_{\\mathfrak{cost}}$ ] .",
    "the cost ratio @xmath71 was infinity in all experiments , obtained by always setting a single response to have a cost of zero for each action .",
    "social network graphs were taken from a friend graph from facebook @xcite , and a collaboration graph from arxiv gr - qc community  .",
    "the results are reported in table [ tab : results ] .",
    "we had @xmath354 for all tests with 3 communities , and @xmath355 for all tests with 10 communities .",
    "lin , h. , bilmes , j. : a class of submodular functions for document summarization . in : proceedings of the 49th annual meeting of the association for computational linguistics : human language technologies - volume 1 .",
    "510520 . hlt 11 ( 2011 )"
  ],
  "abstract_text": [
    "<S> we consider interactive learning and covering problems , in a setting where actions may incur different costs , depending on the response to the action . we propose a natural greedy algorithm for response - dependent costs . </S>",
    "<S> we bound the approximation factor of this greedy algorithm in active learning settings as well as in the general setting . </S>",
    "<S> we show that a different property of the cost function controls the approximation factor in each of these scenarios . </S>",
    "<S> we further show that in both settings , the approximation factor of this greedy algorithm is near - optimal among all greedy algorithms . </S>",
    "<S> experiments demonstrate the advantages of the proposed algorithm in the response - dependent cost setting .    </S>",
    "<S> learning , submodular functions , outcome costs </S>"
  ]
}