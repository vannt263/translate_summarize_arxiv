{
  "article_text": [
    "visual attention is one of the main components in scene understanding .",
    "primates use eye movements to analyze complex natural scenes in real time . as an example , yarbus ( 1967 )  @xcite showed that verbally - communicated task specification may dramatically cause highly variable spatio - temporal eye movements . as another example , tanenhaus et al .",
    "( 1995 )  @xcite tracked fixations of subjects in an object manipulation task .",
    "they showed that visual context influenced syntactic processing when subjects received ambiguous verbal instructions .",
    "these two examples demonstrate an interplay between attention and scene understanding .",
    "several attention models have been proposed to find bottom - up salient regions by detecting regions that stand out from their surroundings  @xcite .",
    "several cues that attract attention and guide eye movements have already been discovered ( e.g. , color , texture , motion , text , face , object center - bias , scene center - bias , cultural cues , and gaze direction ) .",
    "scene structural information such as scene gist , scene layout , horizontal line , depth , and openness influence eye movements as well as human scene categorization  @xcite . here , we systematicaly investigate the role of vanishing point ( vp ) and perspective on eye movements .",
    "in graphical perspective , a vanishing point is a 2d point ( in image plane ) which is the intersection of parallel lines in the 3d world ( but not parallel to the image plane ) .",
    "vp can be seen in fields , rail roads , streets , tunnels , forest , buildings , objects such as ladder , etc .",
    "it has been used in camera calibration , 3d reconstruction as well as in painting .",
    "[ fig : onecol ] shows some images with vps , fixations and model outputs .",
    "[ fig : onecol ]",
    "our stimuli are images with vanishing points from existing datasets ( overall 115 : 14 from dut- omron  @xcite and 101 from mit300  @xcite dataset ) .",
    "these images have been shown shuffled among other images so subjects have had no bias in viewing them .",
    "we manually annotated vps by drawing rectangles around them .",
    "our model is the weighted linear combination of the saliency map and the vanishing point map ( a square centered at the vp ) as follows : @xmath0    where s is the saliency map of the original model ( one of 4 models : aim , bms , houcvpr , itti . ) , vp is the vanishing point map , and @xmath1 is a parameter that controls the relative influence of the two maps .",
    "we empirically found that @xmath2 leads to best results .",
    "the final map was smoothed by a gaussian filter ( see fig .  [ fig : onecol ] ) .",
    "we also optimized the size of the vp square ( i.e. , window size ) .",
    "[ fig:2 ] shows performance of our model as a function of vp window size .",
    "we first show results over all data in tables 1 and 2 using auc and nss  @xcite .",
    "as you can see , using both scores , we achieved a significant improvement over all baseline models ( average of @xmath3%6 improvement using auc , @xmath3%32 using nss ) .",
    "vp only model performs well above chance but below baseline models .",
    "our combined model shows @xmath3%24 improvement over the vp model ( @xmath3%34 using nss ) .",
    "our best score is using bms ( auc = 0.8707 , nss = 2.041 ) .",
    "next , we check the statistical significance of our results .",
    "we perform cross validation by randomly splitting data into two halves .",
    "we train our model ( i.e. , finding the best @xmath1 using the learned best window size ) on train set and apply it to the test set .",
    "we repeat this procedure 20 times and compare the means .",
    "results of statistical tests using t - test are as follows .",
    "auc score of the combined model using aim model is 0.85 ( std= 0.01 ) which is significantly higher than the original model ( 0.8 , p= 3.14e-16 ) and the vp only model ( 0.64 , p= 4.02e-22 ) .",
    "auc scores for the combined model using other models ( bms , houcvpr , and itti ) in order are : 0.88 , 0.82 , 0.84 and all are significantly higher than the original and vp only models ( p @xmath4 1e-17 ) .",
    "the original model scores better than the vp only model and both perform significantly above chance ( auc = 0.5 ) .",
    "we obtain the same pattern of results using nss score . using nss",
    ", vp only model outperforms the original model .",
    "we obtain nearly the same best @xmath1 using all original models .",
    "we showed that vanishing point is an strong predictor of eye movements in free viewing by proposing a combined model .",
    "since vp happens in many cases in real life when taking pictures , we believe that adding this channel to a model can in general enhance fixation prediction power .    we intend to study the followings in our future work :",
    "1 ) do people prioritize vanishing points in presence of other salient regions in a scene ?",
    "we will design behavioral studies ( using reaction time ) to study this , 2 ) we intend to apply a auto detector for vanishing point to replace our annotations , 3 ) investigate other forms of biasing vanishing point regions ( e.g. , using a circle or a gaussian ) , and 4 ) collecting a large dataset of eye movements on images with vanishing points ."
  ],
  "abstract_text": [
    "<S> eye movements are crucial in understanding complex scenes . by predicting where humans look in natural scenes , we can understand how they percieve scenes and priotriaze information for further high - level processing . here </S>",
    "<S> , we study the effect of a particular type of scene structural information known as vanishing point and show that human gaze is attracted to vanishing point regions . </S>",
    "<S> we then build a combined model of traditional saliency and vanishing point channel that outperforms state of the art saliency models . </S>"
  ]
}