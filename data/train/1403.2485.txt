{
  "article_text": [
    "clustering is a fundamental and key primitive to discover structural groups of homogeneous data , called _ clusters _ , in data sets .",
    "the most famous clustering technique is the celebrated _ @xmath1-means _",
    "@xcite that seeks to minimize the sum of intra - cluster variances by prescribing beforehand the number of clusters , @xmath1 .",
    "on one hand , solving the @xmath1-means problem is _ np - hard _",
    "@xcite when the dimension @xmath2 and @xmath3 and various heuristics _ locally _ optimizing the @xmath1-means objective function like lloyd s batched @xmath1-means  @xcite have been proposed .",
    "when @xmath2 and @xmath3 , np - hardness also holds for other clustering problems like @xmath1-medoids , @xmath1-medians and @xmath1-centers  @xcite . on the other hand ,",
    "it is well - known that those center - based clustering problems are fully characterized when @xmath4 : for example , the _ centroid _  @xcite is the solution of the @xmath5-mean , the fermat - weber point  @xcite the solution of the geometric @xmath5-median , the circumcenter  @xcite the solution of the @xmath5-center , etc .",
    "surprisingly , it is less known that @xmath1-means can be solved _",
    "exactly _ in 1d by using _ dynamic programming _",
    "@xcite ( dp ) .    in this letter , we first revisit and extend the seminal dynamic programming ( dp ) paradigm  @xcite for optimally clustering @xmath0 1d elements into @xmath1 pairwise disjoint intervals , the clusters .",
    "we term clustering with this property : the _",
    "1d contiguous _ or _ interval clustering problem_. we further show how to incorporate constraints on the minimum and the maximum cluster sizes , and perform model selection ( i.e. , choosing the appropriate @xmath1 ) from the dp table .",
    "the generic dp solver requires either @xmath6 time using @xmath7 memory or @xmath8 time using @xmath9 memory , where @xmath10 is the time requires for solving the corresponding @xmath5-cluster problem .",
    "second , we consider two applications that refine the generic dp method : in the first application , we report a @xmath11-time optimal bregman @xmath1-means relying on 1d summed area tables  @xcite ( sats ) and also consider the bregman @xmath12-clustering problems  @xcite . in the second application , we consider learning statistical mixture models from independently and identically ( iid . ) univariate observations by maximizing the complete likelihood : using the one - to - one mapping between bregman divergences and exponential families  @xcite , we transform this problem into a series of equivalent 1d bregman @xmath1-means clustering that can be solved optimally by dp for statistical mixtures of _ singly - parametric exponential families _ ( like zero - centered gaussians , rayleigh or poisson families ) . in the general case ,",
    "we require that the density graphs intersect pairwise in at most a single point like the cauchy or laplacian location families ( not belonging to the exponential families ) to guarantee optimality .",
    "let @xmath13 be a one - dimensional space totally ordered with respect to @xmath14 ( usually , @xmath15 ) , and @xmath16 a set of @xmath0 distinct elements .",
    "a clustering of @xmath17 into @xmath18 clusters partitions @xmath17 into pairwise disjoint subsets @xmath19 so that @xmath20 .",
    "let us preliminary sort @xmath17 in @xmath21 time , so that we assume @xmath22 in the remainder .",
    "the output of a 1d contiguous clustering is a collection of @xmath1 intervals @xmath23 $ ] ( such that @xmath24 ) that can be encoded using @xmath25 _ delimiters _ @xmath26 ( @xmath27 ) since @xmath28 ( @xmath29 and @xmath30 ) and @xmath31 :    @xmath32}_{\\calc_1}\\    \\underbrace{[x_{l_2 } ...",
    "x_{l_3 - 1}]}_{\\calc_2 }   ...     \\underbrace{[x_{l_{k } } ...",
    "x_n]}_{\\calc_k}\\ ] ]    to define an optimal clustering among the potential @xmath33 contiguous partitions , we ask to minimize a clustering _ objective function _ or _ energy function _ :",
    "@xmath34    where @xmath35 denotes the _ intra - cluster cost _ and @xmath36 is a commutative and associative operator for calculating the _ inter - cluster cost_. this framework includes the @xmath1-means and the @xmath1-medians ( @xmath37 ) , and the @xmath1-center  @xcite ( @xmath38 ) criteria ( and their discrete counterparts : @xmath1-medoids , etc . ) among others .",
    "clusters is necessarily found from an optimal clustering with @xmath39 clusters ( see text and eq .  [",
    "eq : recdp]).[fig : decomp ] ]    recall that after sorting , we have @xmath22 . let @xmath40 ( @xmath41 ) and @xmath42 .",
    "we define a @xmath43 cost matrix @xmath44 $ ] that stores at entry @xmath45 the optimal clustering cost @xmath46 , where @xmath47 is defined using eq .",
    "[ eq : clusteringcost ] .",
    "similarly , we define a matrix @xmath48 $ ] of dimension @xmath43 that stores at position @xmath45 the index @xmath49 of the leftmost point in the @xmath50-th cluster in @xmath51",
    ". therefore the global clustering solution shall be found at entry @xmath52 with cost @xmath53 .    to define the _ optimality equation _ of dynamic programming",
    ", we observe that the optimal solution for a 1d contiguous clustering with @xmath50 clusters can be defined from the solution of an optimal clustering with @xmath54 clusters : indeed , consider the last cluster interval with left position index @xmath55 , say @xmath56 , as depicted in figure  [ fig : decomp ] .",
    "then the clustering of the @xmath54 first clusters should be an optimal clustering too : namely , the optimal 1d contiguous clustering with @xmath54 clusters on subset @xmath57 .",
    "it follows the following recurrence equation : @xmath58 with @xmath59 ( note that @xmath60 for @xmath61 ) .",
    "we store the argmin of eq .",
    "[ eq : recdp ] in matrix @xmath62 at position @xmath45 ( entry @xmath63 ) .",
    "we compute the energy matrix @xmath64 from left to right columns , and from bottom to top lines .",
    "this yields a @xmath65-time dp algorithm using @xmath66 memory , where @xmath10 denotes the time required for computing @xmath67 : indeed , each of the @xmath68 entries of @xmath64 requires @xmath69 time to evaluate eq .",
    "[ eq : recdp ] .    to recover the optimal clustering , we _",
    "backtrack _ the solution in @xmath70 time from the @xmath62 matrix storing the left indexes of the last cluster of the best solutions : that is , the left index @xmath71 of the @xmath1-th cluster is stored at @xmath72 : @xmath73 .",
    "the cardinality of @xmath74 is @xmath75 .",
    "then we iteratively retrieve the previous left interval indexes at entries @xmath76 for @xmath77 with @xmath78 since @xmath79 .",
    "note that @xmath80 denotes the remaining number of elements to cluster using @xmath81 clusters ( thus we also have @xmath82 ) .",
    "note that when the clustering does not satisfy the 1d contiguous partition property , dp yields _ anyway _ a solution that may not be optimal .",
    "furthermore , we may consider adding a weight @xmath83 to each element @xmath84 ( and thus assume the @xmath85 s are all distinct ) .      by precomputing all the potential intra - cluster costs @xmath86 in @xmath87 time using an auxiliary matrix @xmath88 of size @xmath89",
    ", we evaluate eq .",
    "[ eq : recdp ] as @xmath90\\}$ ] , i.e. in @xmath91 time .",
    "matrix @xmath88 plays the role of a _",
    "look up table _ ( lut ) , and the time complexity for the dp solver reduces to @xmath92 once the lut matrix @xmath88 has been computed .",
    "the generic 1d contiguous clustering can be solved optimally using dynamic programming in time @xmath65 using @xmath66 memory , or in time @xmath8 time using @xmath9 memory .",
    "note that @xmath93 ( in fact , usually , @xmath94 ) . in section",
    "[ sec : bregman ] , we will further improve the running time to @xmath11 using @xmath7 memory when considering bregman @xmath1-means .",
    "let us add constraints on the sizes of clusters .",
    "let @xmath95 and @xmath96 denote lower and upper bound constraints on the size of the @xmath97-th cluster @xmath98 , with @xmath99 and @xmath100 .",
    "when no constraints are required , we simply add the _ dummy _ constraints @xmath101 and @xmath102 ( all clusters non - empty ) .",
    "[ eq : recdp ] , @xmath49 range from @xmath50 to @xmath97 .",
    "the @xmath50-th cluster size @xmath103 has to satisfy @xmath104 .",
    "that is , @xmath105 and @xmath106 .",
    "clearly , @xmath49 has also to be greater than @xmath107 ( an optimal solution for the constrained optimal @xmath54-clustering ) .",
    "it follows , that the optimality equation writes as :    @xmath108    for example , a balanced clustering may be obtained by setting @xmath109 and @xmath110 for some @xmath111 .       for the optimal @xmath1-means for @xmath112 $ ] .",
    "[ fig : modelselection ] ]    the task of clustering data set @xmath17 asks also to find the appropriate number of clusters  @xcite : @xmath1 .",
    "clearly , the more clusters we allow and the less costly the objective function @xmath113 is , but the more complex the clustering model to encode . observe that function @xmath114 is _ monotonically decreasing _ with @xmath1 and reaches a minimum when @xmath115 ( e.g. , @xmath116 for the euclidean @xmath1-means ) as depicted in figure  [ fig : modelselection ] ( see [ sec : mixture ] for an explanation of the data - set ) .",
    "thus we have to perform some kind of _ model selection",
    "_  @xcite by choosing the _ best model _ among all potential models ( with number of clusters ranging from @xmath5 to @xmath0 ) .",
    "the canonical _ regularized objective clustering cost _",
    "@xcite is @xmath117 where @xmath118 is the cost function of choosing a model with @xmath1 clusters .",
    "we can compute the best model minimizing @xmath119 by computing for the dp table entries for the _ last matrix row _ of @xmath64 ( indexed by @xmath0 , with columns @xmath1 ranging from @xmath5 to @xmath0 ) the regularized cost . to compute the last row ,",
    "we iteratively solve dp for @xmath120 and avoid redundant computations by checking whether entry @xmath121 $ ] has already been computed or not .",
    "we then choose @xmath122 by scanning the last row with column ranging from @xmath4 to @xmath115 .",
    "center - based clustering methods like @xmath1-means , @xmath1-medians or @xmath1-centers store for each cluster @xmath123 a _ prototype _ @xmath124 , the cluster center . for discrete center - based clustering ,",
    "the prototypes @xmath124 s are required to belong to the respective @xmath123 s .",
    "the @xmath12 _ center - based clustering objective function _ asks to minimize : @xmath125 where @xmath126 is a _ dissimilarity measure function _",
    "( _ not _ necessarily a distance ) .",
    "we do not take the @xmath127 power of the sum since it changes the value of @xmath35 but not the argmin ( prototype ) .",
    "note that in 1d , @xmath128-norm distance is always @xmath129 , independent of @xmath130 .",
    "thus the intra - cluster cost @xmath131 of a @xmath12 center - based clustering has to solve the following minimization problem : @xmath132 and retrieve the @xmath49-th cluster prototype by @xmath133 .    in order for dp to return the optimal clustering , we need to assume that we have the 1d contiguous clustering property . for euclidean @xmath1-means , this",
    "was proved in  @xcite . in general , consider the _ voronoi cell _ of prototype @xmath124 of @xmath123 : @xmath134 since @xmath135 is a monotonically increasing function on @xmath136 , it is equivalent to @xmath137 .",
    "a sufficient condition is to prove that for _ all _ potential choices of the @xmath1 cluster prototypes @xmath138 the induced 1d dissimilarity voronoi diagram is made of _ connected voronoi cells_. a @xmath139-clustering displays the voronoi bisector .",
    "we now consider two case studies to illustrate and refine the dp method .",
    "the @xmath12-norm bregman center  @xcite is defined for @xmath140 , where @xmath141 is a univariate bregman divergence  @xcite : @xmath142 induced by a strictly convex and differentiable function @xmath143 . when @xmath144 , we recover the squared euclidean distance .",
    "bregman divergences are _ not _ metric  @xcite , since they violate the triangular inequality and are _ asymmetric _ except when @xmath145 for @xmath146 .    for bregman @xmath1-means , the _",
    "bregman information _",
    "@xcite of a cluster generalizes the notion of cluster variance .",
    "it is the _ intra - cluster sum of bregman divergences _ ( bregman @xmath1-means , for @xmath147 ) :    @xmath148    the cluster prototype  @xcite is @xmath149 and the bregman information is  @xcite : @xmath150 .",
    "observe that the bregman information relies on three sums @xmath151 , @xmath152 and @xmath153 that can be preprocessed using _ summed area tables _",
    "@xcite ( sats ) since @xmath123 is a contiguous cluster .",
    "that is , by computing all the _ cumulative sums _",
    "@xmath154 , @xmath155 , and @xmath156 in @xmath157 time at preprocessing stage , we can evaluate the bregman information @xmath86 in constant time @xmath158 .",
    "for example , @xmath159 with the convention that @xmath160 .",
    "the voronoi cells of prototypes are defined by @xmath161 . since _",
    "bregman voronoi diagrams _ have connected cells  @xcite , it follows that the 1d hard @xmath12 bregman clustering satisfies the contiguous interval property , and therefore dp yields the optimal solution .",
    "a similar argument directly hold for the bregman @xmath1-center that is also the limit case of @xmath12 bregman clustering when @xmath162 .",
    "the 1d @xmath12 bregman clustering and bregman @xmath1-center can be solved exactly using dynamic programming in @xmath65 time using @xmath66 memory , where @xmath10 denotes the time to solve the case @xmath4 for @xmath0 elements .",
    "the optimal bregman @xmath1-means can be solved in @xmath11 time .",
    "statistical mixtures are semi - parametric probability models often met in practice . consider a finite _ statistical mixture _",
    "@xmath163 with @xmath18 components .",
    "the probability measure @xmath50 of @xmath163 with respect to a dominating measure @xmath164 ( usually the lebesgue or counting measure ) can be written as : @xmath165 with @xmath166 a normalized positive weight vector belonging to the @xmath39-dimensional _ probability simplex _ , @xmath167 , @xmath168 and @xmath13 the support of the distribution .",
    "let @xmath169 denote the number of scalar parameters indexing the probability family @xmath170 , called the _",
    "order_. mixture @xmath50 is defined by a vector @xmath171 with @xmath172 , and @xmath173 is called the _ parameter",
    "space_. mixtures are inferred from data usually using the expectation - maximization algorithm  @xcite . since em locally maximizes the _ incomplete likelihood _",
    "@xcite and is often trapped into a local maximum , we need some proper mixture parameter initialization or several guided restarts to hopefully reach the optimal solution . on the other hand , maximizing the _ complete log - likelihood _ @xmath174 for a iid . observation data - set @xmath17 amounts to maximize  @xcite : @xmath175 where @xmath176 denotes the hidden labels of the @xmath85 s . thus maximizing",
    "the complete likelihood is equivalent to minimizing the following objective function : @xmath177 this is a hard clustering problem for the dissimilarity function @xmath178 ( given fixed @xmath179 ) . as proved in  @xcite , the cluster weights @xmath180 s are then updated as the cluster proportion of observations , and the algorithm reiterates by solving eq .",
    "[ eq : clopt ] .",
    "initially , we choose @xmath181 .",
    "let the _ additively - weighted minus log - likelihood voronoi cell _ be defined by @xmath182 .",
    "in order for dp to return the optimal solution , we need to assert the contiguity property . using the one - to - one mapping between exponential families  @xcite and bregman divergences  @xcite , it turns out that the optimization problem of eq .",
    "[ eq : clopt ] yields an equivalent additively - weighted bregman @xmath1-means problem ( and additively - weighted bregman voronoi cells are connected  @xcite ) .",
    "thus when the order of the exponential family is @xmath183 , we have the contiguity property and dp returns the optimal solution .",
    "this works also for curved exponential families with one free parameter like the family of gaussian distributions @xmath184 . in general",
    ", the contiguity property holds when density graphs in @xmath185 are pairwise intersecting at exactly one point of the support @xmath13 . for example , some ( unimodal ) _ location families _ with density @xmath186 for a prescribed value of @xmath187 and a standard density @xmath188 ( e.g. , isotropic gaussian densities @xmath189 and @xmath190 intersect at @xmath191 ) .",
    "this includes location cauchy distributions and location laplacian distributions ( both not belonging to the exponential families  @xcite ) among others .",
    "note that @xmath5-order exponential families may have pairwise densities intersecting in more than one point ( like the family @xmath192 ) but after reparameterization by their sufficient statistic  @xcite @xmath193 , data - set @xmath194 satisfies the contiguous property .",
    "consider fitting a gaussian mixture model ( gmm ) on the intensity histogram of the renown lena color image .",
    "for each pixel , we compute its grey value and add a small perturbation noise to ensure that we get distinct @xmath85 s ( alternatively , without adding noise , we set the weight @xmath195 of @xmath85 as the proportion of pixels having grey value @xmath85 ) .",
    "we then compute the optimal euclidean 1d @xmath1-means for @xmath196 ( it corresponds to fitting a 1d gmm @xmath197 with gaussian components having identical as the relative proportion of points . ]",
    "standard deviation ) , and calculate the 1d gmm @xmath198 allowing different standard deviations . in that case , we do _ not _ have the contiguous clustering property ( densities pairwise intersect in two points ) and dp may _ not _ yield the optimal clustering ( give prescribed weights ) .",
    "however , in this case , we experimentally obtained a better gmm .",
    "the results are illustrated in figure  [ fig : res ] . for model selection in mixtures , to choose the optimal @xmath1",
    ", we use the _ akaike information criterion _  @xcite ( aic ) : @xmath199 .",
    "other criteria like the bayesian information criterion ( bic ) , minimum description length ( mdl ) , etc can also be used .",
    "components maximizing the complete data likelihood of the intensity histogram of lena   retrieved from an optimal euclidean @xmath1-means , and @xmath200 allowing different standard deviations .",
    "the average complete data log - likelihood of @xmath197 is @xmath201 and that of @xmath198 is @xmath202 ( better than the one for @xmath197 ) .",
    "[ fig : res ] ]",
    "we first described a clustering algorithm based on dynamic programming ( whose seminal idea was briefly outlined in bellman s @xmath139-page paper  @xcite in 1973 ) that computes the generic optimal 1d contiguous clustering either in @xmath65-time using @xmath7 memory , or in @xmath8 time using @xmath9 memory , where @xmath10 denotes the time required for solving the case @xmath4 on @xmath0 scalar elements .",
    "we then extended the method to incorporate cluster size constraints and show how to perform model selection from the dp table .",
    "this algorithm solves optimally and generically 1d @xmath1-means , @xmath1-median and @xmath1-center among others .",
    "second , we reported two tailored center - based clustering applications of the optimal 1d contiguous clustering : ( 1 ) bregman @xmath1-means and @xmath1-centers clustering , and ( 2 ) learning statistical mixtures maximizing the complete likelihood provided that ( a ) their densities belong to a @xmath5-order exponential family or ( b ) their density graphs pairwise intersect in one point . for bregman @xmath1-means , we showed how to use summed area tables ( sats ) to further speed the dp solver in @xmath11-time using @xmath7 memory .",
    "franklin  c. crow .",
    "summed - area tables for texture mapping . in _ proceedings of the 11th annual conference on computer graphics and interactive techniques _ , siggraph 84 , pages 207212 , new york , ny , usa , 1984 .",
    "acm .",
    "dan pelleg and andrew moore .",
    "@xmath203-means : extending @xmath204-means with efficient estimation of the number of clusters . in _ proc .",
    "17th international conf . on machine learning _ , pages 727734 .",
    "morgan kaufmann , san francisco , ca , 2000 ."
  ],
  "abstract_text": [
    "<S> we present a generic dynamic programming method to compute the optimal clustering of @xmath0 scalar elements into @xmath1 pairwise disjoint intervals . </S>",
    "<S> this case includes 1d euclidean @xmath1-means , @xmath1-medoids , @xmath1-medians , @xmath1-centers , etc . </S>",
    "<S> we extend the method to incorporate cluster size constraints and show how to choose the appropriate @xmath1 by model selection . </S>",
    "<S> finally , we illustrate and refine the method on two case studies : bregman clustering and statistical mixture learning maximizing the complete likelihood .    : clustering , dynamic programming , @xmath1-means , bregman divergences , statistical mixtures , exponential families . </S>"
  ]
}