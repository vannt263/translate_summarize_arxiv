{
  "article_text": [
    "we study the effect on channel capacity of quantizing the output of the discrete - time average - power - limited gaussian channel using a one - bit quantizer .",
    "we focus on the low signal - to - noise ratio regime , where communication at very low spectral efficiencies takes place ( as in spread - spectrum and ultra - wideband communications ) . in this regime ,",
    "a symmetric one - bit quantizer reduces the capacity by a factor of @xmath0 , corresponding to a 2db power loss @xcite .",
    "hence the rule of thumb that `` hard decisions cause a 2db power loss . '' here we demonstrate that if we allow for _ asymmetric one - bit quantizers _ with corresponding _ asymmetric signal constellations _ , these two decibels can be fully recovered .",
    "we further demonstrate that the capacity per unit - energy can be achieved by a simple pulse - position modulation ( ppm ) scheme .",
    "the problem of output quantization is relevant for communication systems where the receiver uses digital signal processing techniques , which require the conversion of the analog received signal to a digital signal by means of an analog - to - digital converter ( adc ) .",
    "for adcs with high resolution , the effects of quantization are negligible . however , using a high - resolution adc may not be practical , especially when the bandwidth of the communication system is large and the adc therefore needs to operate at a high sampling rate @xcite . in this case",
    "a low - resolution adc has to be employed .",
    "the capacity of the discrete - time gaussian channel with one - bit output quantization indicates what communication rates can be achieved when the receiver employs a low - resolution adc .    for a symmetric one - bit quantizer ( which produces @xmath1 if the quantizer input is nonnegative and @xmath2 otherwise ) , the capacity @xmath3 under the average - power constraint @xmath4 on the channel inputs is given by ( * ? ? ?",
    "* ( 3.4.18 ) ) , ( * ? ?",
    "2 ) @xmath5 where @xmath6 denotes the natural logarithm function ; @xmath7 the variance of the additive gaussian noise ; @xmath8 ( with @xmath9 ) the binary entropy function ; and @xmath10 the @xmath11-function .",
    "( here @xmath12 denotes the set of real numbers . )",
    "this capacity can be achieved by transmitting @xmath13 equiprobably .",
    "from , the capacity per unit - energy @xmath14 for a symmetric one - bit quantizer can be computed as ( * ? ? ? * ( 3.4.20 ) ) @xmath15 this is a factor of @xmath16 smaller than the capacity per - unit energy @xmath17 of the gaussian channel without output quantization @xcite .",
    "thus , quantizing the channel output by a symmetric one - bit quantizer causes a loss of roughly 2db .",
    "it is tempting to attribute this loss to the fact that the quantizer discards information on the received signal s magnitude and allows the decoder to perform only hard - decision decoding .",
    "however , we demonstrate that the loss of 2db is not a consequence of the hard - decision decoder but of the suboptimal quantizer .",
    "in fact , with an asymmetric quantizer the loss vanishes .",
    "the rest of the paper is organized as follows .",
    "section  [ sec : channel ] describes the considered channel model , defines the capacity per unit - energy , and presents our main result .",
    "section  [ sec : mainproof ] provides the proof of this result .",
    "section  [ sec : ppm ] shows that the capacity per unit - energy can be achieved by a simple ppm scheme .",
    "section  [ sec : capacity ] briefly discusses the capacity of the considered channel . and",
    "section  [ sec : summary ] concludes the paper with a summary and discussion of our results .",
    "[ cb][cb]@xmath18 [ rc][rc]@xmath19 [ cc][cc]@xmath20 [ cc][cc]encoder [ cc][cc]decoder [ cc][cc]quantizer [ cb][cb]@xmath21 [ lc][lc]@xmath22 [ cb][cb]@xmath23    we consider the discrete - time communication system depicted in figure 1 .",
    "it is assumed that the message @xmath19 is uniformly distributed over the set @xmath24 .",
    "the encoder maps @xmath19 to the length-@xmath25 sequence @xmath26 , which is then corrupted by additive gaussian noise and quantized .",
    "thus , at every time instant @xmath27 ( where @xmath28 denotes the set of integers ) , the received signal @xmath23 corresponding to the channel input @xmath29 is @xmath30 where @xmath31 is a sequence of independent and identically distributed ( i.i.d . )",
    "gaussian random variables of zero mean and variance @xmath7 .",
    "the quantizer produces @xmath1 if @xmath23 is in the quantization region @xmath32 and @xmath2 otherwise , for some borel set @xmath33 .",
    "for example , the quantization region of the symmetric quantizer is given by @xmath34 .",
    "the decoder observes the quantizer s outputs @xmath35 and tries to guess which message was transmitted .",
    "we assume that the energy in the transmitted sequence does not exceed @xmath36 , i.e. , that the encoder is such that , for every realization of @xmath19 , the sequence @xmath37 satisfies @xmath38 we define the capacity per unit - energy along the lines of @xcite .",
    "we say that a _ rate per unit - energy _",
    "@xmath39 ( in nats per energy ) is _ achievable _ if for every @xmath40 there exists an encoder , a quantizer , and a decoder such that @xmath41 and such that the probability of error @xmath42 tends to zero as @xmath36 tends to infinity .",
    "the _ capacity per unit - energy _ is the supremum of all achievable rates per unit - energy .",
    "it follows from ( * ? ? ?",
    "* ths .  2 & 3 ) that the capacity per unit - energy is given by    lclcl ( 0 ) & = & _ > 0 & = & _ 0 , [ eq : formulacuc ]    where @xmath43 denotes the relative entropy , i.e. , @xmath44 ( where @xmath45 indicates that @xmath46 is absolutely continuous with respect to @xmath11 ) ; @xmath47 denotes the output distribution given that the input is @xmath48 ; and @xmath49 is the capacity of the above channel under the average - power constraint @xmath4 on the channel inputs , i.e. , @xcite @xmath50 with the maximization being over all quantization regions @xmath32 and over all distributions on @xmath51 satisfying @xmath52 .",
    "note that the first supremum in is approached when @xmath4 tends to zero .",
    "thus , the capacity per unit - energy is equal to the slope of the capacity - vs - power curve at zero .    by the data processing inequality ( * ?",
    "2.8.1 ) , the capacity per unit - energy of the above channel is upper - bounded by the capacity per unit - energy of the gaussian channel without output quantization , i.e. , @xcite @xmath53 in the following , we show that there exists a one - bit quantizer that achieves this upper bound .",
    "[ thm : main ] the capacity per unit - energy of the discrete - time gaussian channel with one - bit output quantization is @xmath54 moreover , the capacity per unit - energy can be achieved by a quantization region of the form @xmath55 where @xmath56 depends on the distribution of the channel input .",
    "see section  [ sec : mainproof ] .",
    "we prove theorem  [ thm : main ] in section  [ sec : mainproof ] .",
    "a simple ppm scheme that achieves the capacity per unit - energy is presented in section  [ sec : ppm ] .",
    "we show that a one - bit quantizer with quantization region  @xmath32 of the form achieves the rate per unit - energy @xmath57 together with , this proves theorem  [ thm : main ] .    to this end",
    ", we first note that , for the quantization region , the conditional probability of the output @xmath58 given the input @xmath48 is    lcl p(y_1=1| x_1=x ) & = & q ( ) , x    and @xmath59 .",
    "together with , this yields    lcl ( 0 ) & = & _ 0 , \\{. + & & .",
    "+ } + & = & _ 0 , \\{. + & & + + & & . - } .[eq:1 ]    we choose @xmath60 for some fixed @xmath61 and lower - bound the right - hand side ( rhs ) of by letting @xmath62 tend to infinity .",
    "this yields for the last two terms on the rhs of @xmath63 and @xmath64\\log\\frac{1}{1-q\\left(\\frac{\\xi-\\mu}{\\sigma}\\right)}}{\\xi^2 } = 0.\\ ] ] we use the upper bound on the @xmath11-function ( * ? ? ?",
    "19.4.2 ) @xmath65 to lower - bound the first term on the rhs of as    lcl + & & q(- ) _ + & = & q(-).[eq:4 ]    combining , , and with yields @xmath66 from which we obtain by letting @xmath67 tend to infinity .",
    "this proves theorem  [ thm : main ] .",
    "the capacity per unit - energy can be achieved by the following ppm scheme . for each message @xmath68",
    ", the encoder produces the sequence @xmath69 , where @xmath70 and where @xmath62 satisfies the energy constraint with equality .",
    "thus , we have @xmath71 , which for a fixed rate per unit - energy @xmath72 is equal to @xmath73 note that , while the _ rate per unit - energy _ is fixed , the _ rate _ of this scheme is @xmath74 and tends to zero as @xmath75 tends to infinity .",
    "nevertheless , by the capacity per unit - energy is equal to the slope of the capacity - vs - power curve at zero .",
    "it thus follows from theorem  [ thm : main ] that there also exists a transmission scheme of nonzero rate that achieves .",
    "we employ a quantizer with quantization region @xmath76 i.e. , at every time instant @xmath77 the quantizer produces @xmath1 if and @xmath2 otherwise .",
    "we choose the threshold @xmath56 such that the probability that the quantizer produces @xmath2 given that the transmitter sends @xmath62 is equal to some arbitrary @xmath78 , i.e. , @xmath79 which yields @xmath80 here @xmath81 denotes the inverse @xmath11-function .",
    "note that this threshold is of the same form as the threshold we chose in section  [ sec : mainproof ] to prove theorem  [ thm : main ] .",
    "the decoder guesses @xmath82 if @xmath83 and @xmath84 for @xmath85 . if @xmath86 for more than one @xmath77 , or if @xmath84 for all @xmath87 , then the decoder declares an error .",
    "suppose that message @xmath88 was transmitted .",
    "the probability of an error is given by    lcl + & = & ( ._km(y_k=1)(y_m=-1)| m = m ) + & & _ km p(y_k=1| x_k=0 ) + p(y_m=-1|x_m= ) + & = & _ km p(y_k=1|x_k=0 ) + + & = & ( -1 ) p(y_1=1|x_1=0 ) + [ eq : union ]    where the second step follows from the union bound ; the third step follows from our choice of @xmath56 ; and the fourth step follows because the channel is memoryless which implies that the probability @xmath89 does not depend on @xmath77 . since the rhs of does not depend on @xmath90 , it follows that the probability of error @xmath91 is also upper - bounded by .",
    "the first term on the rhs of can be evaluated as    lcl + & = & ( -1 ) q ( ) + & = & ( -1 ) q ( ) [ eq : p10 ]    where the second step follows from .",
    "we continue by showing that if @xmath92 then , for every fixed @xmath93 , the rhs of tends to zero as @xmath75 tends to infinity .",
    "indeed , we have    lcl + & & _ ( ^2(0)(+q^-1())^2 ) q ( ) + & & _ ( ^2(0)(+q^-1())^2-^2)[eq : mlarge ]    where the first step follows by upper - bounding @xmath94 and by substituting @xmath95 and the second step follows from .",
    "the limit on the rhs of vanishes for @xmath96 .    combining with",
    ", we obtain that if @xmath96 , then the probability of error tends to @xmath97 as @xmath36and hence also @xmath98tends to infinity .",
    "since @xmath97 is arbitrary , it follows that the probability of error can be made arbitrarily small by choosing @xmath56 sufficiently large , thus proving that the capacity per unit - energy is achievable by the above ppm scheme .",
    "the definition of channel capacity is analog to that of capacity per unit - energy .",
    "a rate @xmath99 is said to be achievable if for every @xmath40 there exists an encoder , a quantizer , and a decoder satisfying @xmath100 such that @xmath101 and such that the probability of error @xmath102 tends to zero as @xmath25 tends to infinity .",
    "the capacity @xmath49 is the supremum of all achievable rates . for the above channel",
    ", the capacity is given by @xcite @xmath103 where the supremum is over all quantization regions @xmath33 and over all distributions on @xmath51 satisfying @xmath52 .",
    "if we do not maximize over the quantization region but assume a symmetric quantizer , i.e. , @xmath104 , then the capacity is given by ( * ? ? ?",
    "* ( 3.4.18 ) ) , ( * ? ?",
    "2 ) @xmath105 where @xmath106 denotes the binary entropy function and @xmath107 denotes the @xmath11-function , see section  [ sec : intro ] . in this case",
    "the capacity - achieving input distribution is binary with equiprobable mass points at @xmath108 and @xmath109 .    to the best of our knowledge ,",
    "the capacity of the above channel ( maximized over the input distribution and the quantization region ) as well as the capacity - achieving input distribution and the optimal quantization region are unknown .",
    "the following two propositions present results on the latter two problems .",
    "[ prop : input ] the capacity - achieving input distribution is discrete with at most three mass points @xmath110 , @xmath111 satisfying @xmath112 where @xmath113 denotes the probability corresponding to mass point @xmath114 , i.e. , @xmath115 , @xmath111 and @xmath116 .    omitted .",
    "this result is consistent with ( * ? ? ?",
    "* th .  1 ) , which shows that if the quantization regions of a @xmath117-bit quantizer partition the real line into @xmath118 intervals , then a discrete input distribution with not more that @xmath119 mass points achieves the capacity .",
    "[ prop : quant ] a threshold quantizer is optimal , i.e. , the capacity - achieving quantizer is of the form @xmath120 where @xmath56 is determined by @xmath4 and @xmath121 .    omitted .",
    "propositions  [ prop : input ] and [ prop : quant ] demonstrate that the capacity of the above channel is equal to the capacity of a discrete memoryless channel with input alphabet @xmath122 , output alphabet @xmath123 , and channel law @xmath124 it can be further shown that the supremum on the rhs of is achieved , so @xmath125 where @xmath126 denotes the mutual information of a channel with channel law @xmath127 when the channel input is distributed according to @xmath128 ; @xmath129 denotes the set of probability vectors @xmath130 ^ 3 $ ] and mass points @xmath131 satisfying @xmath132 and @xmath133 denotes the channel law given by .",
    "thus , instead of maximizing the mutual information over all borel sets @xmath32 and all probability distributions on @xmath51 satisfying @xmath52 , it suffices to maximize the mutual information over the four real numbers @xmath134 , @xmath135 , @xmath136 , and @xmath56 and the three - dimensional probability vector @xmath128 satisfying .",
    "it is well - known that quantizing the output of the discrete - time average - power - limited gaussian channel using a symmetric one - bit quantizer reduces the capacity per unit - energy by a factor of @xmath0 .",
    "we have shown that this loss can be fully recovered by allowing for asymmetric one - bit quantizers with corresponding asymmetric signal constellations .",
    "we have further shown that the capacity per unit - energy can be achieved by a simple ppm scheme .",
    "for this scheme , the error probability can be analyzed directly using the union bound and the upper bound on the @xmath11-function .",
    "we thus need not resort to conventional methods used to prove coding theorems , such as the method of types , information - spectrum methods , or random coding exponents .",
    "the above results demonstrate that the 2db power loss incurred on the gaussian channel with symmetric one - bit output quantization is not due to the hard - decision decoder , but due to the symmetric quantizer . in fact , if we employ an asymmetric quantizer , and if we use asymmetric signal constellations , then hard - decision decoding achieves the capacity per unit - energy of the gaussian channel",
    ".    the above results also demonstrate that a threshold quantizer is asymptotically optimal as the signal - to - noise ratio tends to zero .",
    "we have further shown that this is true not only asymptotically : for a fixed signal - to - noise ratio , we have shown that , among all one - bit output quantizers , a threshold quantizer is optimal .",
    "the authors would like to thank p.  sotiriadis , who sparked their interest in the problem of quantization .",
    "j.  singh , o.  dabeer , and u.  madhow , `` on the limits of communication with low - precision analog - to - digital conversion at the receiver , '' _ ieee transactions on communications _",
    "57 , no .  12 , pp .",
    "36293639 , december 2009 ."
  ],
  "abstract_text": [
    "<S> we study the behavior of channel capacity when a one - bit quantizer is employed at the output of the discrete - time average - power - limited gaussian channel . </S>",
    "<S> we focus on the low signal - to - noise ratio regime , where communication at very low spectral efficiencies takes place , as in spread - spectrum and ultra - wideband communications . </S>",
    "<S> it is well known that , in this regime , a symmetric one - bit quantizer reduces capacity by @xmath0 , which translates to a power loss of approximately two decibels . </S>",
    "<S> here we show that if an asymmetric one - bit quantizer is employed , and if asymmetric signal constellations are used , then these two decibels can be recovered in full . </S>"
  ]
}