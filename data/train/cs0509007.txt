{
  "article_text": [
    "most iterative decoders , e.g. turbo decoders @xcite , rely on knowledge of the signal - to - noise ratio ( snr ) or the channel reliability constant @xcite .",
    "the snr is also required for other functionalities in the receiver .",
    "many snr estimators have been proposed , both data - aided ( da )  that require pilot symbols or feedback from the decoders @xcite , and non - data - aided ( nda )  that are only based on the received observables @xcite .",
    "a comparison of both da and nda snr estimators was performed in @xcite and compared to the cramr - rao lower bound ( crlb ) for da estimators .",
    "the crlb for nda estimators was later derived in @xcite . the nda maximum likelihood ( ml )",
    "estimator based on the expectation maximization ( em ) algorithm was proposed in @xcite and also compared to other nda estimators .",
    "this nda ml estimator was found iteratively , but unfortunately requiring processing of all observables for each iteration , making it computationally complex .",
    "the contributions in this paper are as follows .",
    "to complement the nda crlb for snr in @xcite , we derive the nda crlb for the signal amplitude , the noise variance , the channel reliability constant , and the bit - error rate ( ber ) .",
    "it is also shown how to estimate the _ a priori _ probability of the transmitted symbols , in the case when they are not equally likely .",
    "furthermore , we provide a more direct , alternative derivation of the nda ml estimator and we propose a new , low complexity nda snr estimator .",
    "the performance of the new estimator is compared to previously suggested nda estimators and found to be similar to that of the nda ml estimator .",
    "this performance is achieved with significantly lower computational complexity than the ml estimator . only binary - phase - shift - keying ( bpsk ) transmission is considered here , but generalization to @xmath0-psk is straightforward @xcite .",
    "let @xmath1 denote a binary random variable with equally likely symbols .",
    "further , let @xmath2 represent a zero - mean gaussian random variable with unit variance . define a new random variable @xmath3 according to @xmath4 with probability density function ( pdf ) expressed as @xcite @xmath5    let @xmath6 , @xmath7 , and @xmath8 denote samples from @xmath9 , @xmath3 , and @xmath2 , respectively .",
    "@xmath10 independent samples of @xmath3 is observed and collected in a column vector @xmath11}{^t}$ ] . if @xmath12 and @xmath13 , the model in represents bpsk transmission in additive white gaussian noise ( awgn ) @xmath14 where @xmath15 is the matched filter output , @xmath16}{^t}$ ] the transmitted data , and @xmath17}{^t}$ ] white gaussian noise .",
    "@xmath18 is the transmitted energy and @xmath19 is the double - sided noise power spectral density .",
    "define the snr as @xmath20 since all samples in @xmath15 are assumed independent , the logarithm of their joint pdf is given by @xcite @xmath21    the average ber can be expressed as @xmath22 where @xmath23 is the gaussian @xmath24-function .",
    "the average mutual information ( mi ) @xcite between @xmath9 and @xmath3 in can be expressed as @xmath25 where @xmath26 is defined as @xcite @xmath27 the log - likelihood ratio ( llr ) for @xmath28 is defined as @xcite @xmath29 where @xmath30 is the channel reliability constant @xcite @xmath31 the instantaneous ber for a specific received symbol at position @xmath32 can be estimated by @xcite @xmath33 the corresponding instantaneous mi for a symbol at position @xmath32 can be estimated by @xcite @xmath34    with no knowledge of the transmitted symbols the average ber in or the average mi in depend solely on the snr , @xmath35 . also , in order to use an llr - based decoder ( basically all turbo - like decoders @xcite or soft decoders ) , to estimate the instantaneous ber in , or to estimate the instantaneous mi in , the channel reliability constant in needs to be known . however , as we show in section [ sec_estimators ] , the snr and the channel reliability constant are related through the second moment of the observables .",
    "we therefore only need to estimate one of the two . here , we have chosen to estimate the snr , @xmath36 .",
    "the crlb , here denoted by @xmath37 , provides a lower bound on the variance of any unbiased estimator @xcite .",
    "let @xmath38 represent an arbitrary function of the parameters @xmath39 and @xmath40 , and define @xmath41 .",
    "the normalized crlb ( ncrlb ) for @xmath42 can then be calculated as @xcite @xmath43    { \\textbf{j}^{-\\!1}}\\left [   \\begin{array}{cc }      \\!\\!\\!{\\frac{\\partial { g(\\mu,{\\sigma})}}{\\partial \\mu } } & \\!{\\frac{\\partial { g(\\mu,{\\sigma})}}{\\partial { \\sigma } } } \\\\",
    "\\end{array }   \\!\\!\\!\\right ]    { ^t}\\ ! ,    \\label{eq_crlbd}\\end{aligned}\\ ] ] where @xmath44 is the fisher information matrix @xcite , defined as @xmath45 .",
    "\\label{eq_fm}\\end{aligned}\\ ] ] here @xmath46 denotes the expectation over @xmath3 .",
    "a similar fisher information matrix as in has been derived in @xcite and the inverse can be expressed as @xmath47 ,    \\label{eq_fminv}\\end{aligned}\\ ] ] where @xmath48 is a function of @xmath35 @xcite @xmath49 using , the crlb for @xmath35 can be calculated as reported in @xcite and @xcite .",
    "the ncrlbs for @xmath39 , @xmath40 , @xmath35 , @xmath30 , and @xmath50 are @xmath51 the ncrlb for @xmath52 can also be found in a similar way by replacing @xmath50 in with @xmath53 .",
    "unfortunately , there is no simple form to express @xmath54 .",
    "note that @xmath55 for da estimation is found by setting @xmath56 in @xcite .",
    "this implies that the ncrlbs for da estimation of @xmath39 , @xmath40 , @xmath35 , @xmath30 , and @xmath50 are easily found by letting @xmath56 in .",
    "define moment @xmath57 of @xmath3 as @xmath58 which can be approximated by its sample average @xcite .",
    "the second moment of @xmath3 is @xmath59 assume that an estimate of @xmath35 exists , denoted by @xmath60 . combining with and gives the following estimators for @xmath39 , @xmath40 , and @xmath30 @xmath61 the next sub - sections present different estimators for @xmath35 that can be used to estimate the above parameters .",
    "the absolute moment ( am ) of @xmath3 is defined as @xcite @xmath62 and can also be approximated by the sample average @xcite @xmath63 for large @xmath39 or small @xmath40 , the am will tend to @xmath39 @xmath64 in other words , for high values of @xmath35 , @xmath60 can be closely approximated by @xmath65 using and .",
    "this estimator was first introduced in @xcite and will here be referred to as the conventional method ( cm ) estimate .      the ml estimator maximizes the joint pdf in . taking the partial derivatives of @xmath66",
    "gives @xmath67 setting the derivatives in and to zero and solve for @xmath68 gives @xmath69 inserting in gives an expression depending only on @xmath15 , @xmath39 and @xmath70 , which can be solved iteratively by @xmath71 where @xmath72 denotes the estimate of @xmath39 after @xmath57 iterations .",
    "the iteration in is identical to the iteration in the em algorithm presented in @xcite , but here derived in a different way .",
    "a good starting point for the iterative estimator is the cm estimate of @xmath39 , @xmath73 .",
    "after @xmath74 iterations the snr can be estimated by @xmath75 which will be referred to as the ml estimator .",
    "the approach of estimating a parameter based on the moments of the observables is known as the method of moments ( mm ) @xcite .",
    "the fourth moment of @xmath3 is @xcite @xmath76 combining with gives the mm estimator , e.g. @xcite , @xmath77 where @xmath70 and @xmath78 are approximated by the sample average .",
    "if @xmath79 , is no longer real and @xmath60 is set to zero .",
    "this will be referred to as the mm estimator .",
    "an estimator based on the second moment and the am can be found by combining with .",
    "unfortunately , there is no closed - form analytical solution for @xmath39 and @xmath40 as for the mm estimator .",
    "however , dividing the square of @xmath80 by @xmath70 gives an expression that only depends on @xmath35 , @xmath81 an estimator for @xmath35 can therefore be stated as @xmath82 since there is no closed - form solution to , alternative methods must be explored . in @xcite , a table - lookup for @xmath83 is suggested .",
    "a different approach is to approximate @xmath83 with a simple closed - form function , which was done in @xcite as , @xmath84 the estimator in , using the approximation in is referred to as the second - order polynomial ( p2 ) estimator .    from it is easy to verify that @xmath85 therefore , we suggest the following approximation of @xmath86 and its inverse @xmath87 numerical optimization , using the nelder - mead simplex method @xcite to minimize the mean squared difference between and gives @xmath88 , @xmath89 , and @xmath90 . the estimator in , using the novel approximation in , with @xmath91 whenever @xmath92 , is a new approach we propose and is here referred to as the am estimator .",
    "( 94,84)(-1,-2 ) ( -3,0 ) .,title=\"fig:\",width=321 ] ( -2,46)(0,0)[r ] ( 49,-1)(0,0)[t]@xmath93    fig .",
    "[ fig_h_approx ] shows the analytical expression from together with its indistinguishable approximation in .",
    "since the cm estimator in depends only on @xmath93 it is also shown in fig .",
    "[ fig_h_approx ] .",
    "it is clear that the function used by the cm estimator converges to the analytical one for large @xmath35 , but differs for small @xmath35 .",
    "the same figure also shows the approximation in .",
    "since this polynomial approximation was only optimized between @xmath94 to @xmath95 db ( @xmath96@xmath97 ) @xcite it differs from the analytical expression outside this region .",
    "define @xmath98 to be the _ a priori _ probability of @xmath9 in @xmath99 the ml estimator is invariant to non - equiprobable symbols and gives the same results even if @xmath100 @xcite .",
    "it is straightforward to show that @xmath80 , @xmath70 , and @xmath78 are independent of @xmath98 @xcite .",
    "since the cm , the mm , the p2 , and the am estimators are based only on these quantities , they will give the same results independent of @xmath98 .    however , when @xmath101 , the odd moments are non - zero , @xmath102 this means that the _ a priori _",
    "probability @xmath98 can be estimated using @xmath103 , by combining with and @xmath104",
    "the performance of the snr estimators is evaluated based on their normalized mean squared error ( nmse ) @xmath105 and their normalized bias ( nb ) @xmath106 where @xmath107 is estimated based on @xmath10 samples .",
    "the number of trials was chosen to @xmath108 .",
    "the best estimator is an unbiased estimator with minimum nmse @xcite .",
    "[ fig_nmse_g_gs ] shows the nmse and fig .",
    "[ fig_nb_g_gs ] shows the nb , both for @xmath109 observables .",
    "the nda and the da ncrlb are also included as a reference , even though they are only bounds for unbiased estimators . all the estimators presented here are biased when @xmath109 , even for high @xmath35 which is evident from fig .",
    "[ fig_nb_g_gs ] .",
    "different approaches to reduce the bias has been suggested , e.g. , @xcite .",
    "the cm estimator has a large nb ( and therefore also a large nmse ) for low @xmath35 .",
    "for large @xmath35 the cm estimator approaches the ml estimator , which was shown analytically in @xcite .",
    "in fact , figs .   show that all estimators , except the p2 estimator converges to the same constant nmse and constant nb for high @xmath35 ( the nb is around 5% above the true @xmath35 ) .",
    "the p2 estimator only works well between -3 to 3 db , the interval for which it was optimized .",
    "the mm estimator has the second highest nmse for low @xmath35 .",
    "the ml estimator after @xmath110 iterations has the lowest nmse at -6 db , but fig .",
    "[ fig_nb_g_gs ] shows that it at the same time has the second highest nb .",
    "finally , the suggested am estimator has almost identical performance ( both in nmse and nb ) as the ml estimator for all @xmath35 , even though it has a computationally complexity that is less than the first ml iteration",
    ".    figs .",
    "show the nmse and the nb for different @xmath10 at -2 db .",
    "this corresponds to an @xmath111 around 1 db for a half - rate code , e.g. the original turbo code @xcite .",
    "at this low snr , the cm estimator has bad performance .",
    "the nb saturates around 60% above the true value ( not shown here ) , which gives the high nmse in fig .",
    "[ fig_nmse_g_k ] .",
    "the p2 estimator has a negative nb for large @xmath10 at this snr .",
    "the ml estimator after @xmath112 iterations and the am estimator have a small positive nb ( around 1% ) for large @xmath10 .",
    "the ml estimator and the mm estimator are the only two estimators that are unbiased for large @xmath10 , but only the ml estimator approaches the ncrlb in fig .",
    "[ fig_nmse_g_k ] which makes it asymptotically optimal @xcite .",
    "the second best estimator , after the ml estimator , over the whole range of @xmath10 is the suggested am estimator .",
    "in this paper we have derived the nda ncrlb for the signal amplitude , the noise variance , the channel reliability constant , and the ber in an awgn channel with bpsk modulated transmission .",
    "it was also shown that these parameters , as well as the _ a priori _ probability of the transmitted symbols and the instantaneous mi can all be estimated based on the snr estimate .",
    "a novel snr estimator with low computationally complexity was introduced and shown to be surpassed in performance only by the iterative ml estimator among previously suggested estimators .",
    "the proposed estimator performs close to the performance of the iterative ml estimator at significantly lower computationally complexity .              c.  berrou , a.  glavieux , and p.  thitimajshima , `` near shannon limit error - correcting coding and decoding : turbo - codes , '' in _ proc .",
    "ieee int .",
    "( icc  93 ) _ , vol .  2 ,",
    "geneva , switzerland , may 1993 , pp .",
    "10641070 .",
    "p.  hoeher , i.  land , and u.  sorger , `` log - likelihood values and monte carlo simulation  some fundamental results , '' in _ proc",
    ".  int .",
    "symp .  on turbo codes and rel .",
    "topics _ , brest , france , sept . 2000 , pp . 4346 ."
  ],
  "abstract_text": [
    "<S> non - data - aided ( nda ) parameter estimation is considered for binary - phase - shift - keying transmission in an additive white gaussian noise channel . </S>",
    "<S> cramr - rao lower bounds ( crlbs ) for signal amplitude , noise variance , channel reliability constant and bit - error rate are derived and it is shown how these parameters relate to the signal - to - noise ratio ( snr ) . </S>",
    "<S> an alternative derivation of the iterative maximum likelihood ( ml ) snr estimator is presented together with a novel , low complexity nda snr estimator . </S>",
    "<S> the performance of the proposed estimator is compared to previously suggested estimators and the crlb . </S>",
    "<S> the results show that the proposed estimator performs close to the iterative ml estimator at significantly lower computational complexity . </S>"
  ]
}