{
  "article_text": [
    "the semantic web @xcite , a project with the stated purpose of forming a consistent logical and meaningful web of data using semantic technologies to make data machine - understandable and processable , has been highly successful in biology and biomedicine @xcite . many major bioinformatics databases now make their data available as linked data in which both biological entities and connections between them are identified through a unique identifier ( an internationalized resource identifier or iri ) and the connections between them are expressed through standardized relations @xcite .",
    "linked data can enable interoperability between multiple databases simply by reusing identifiers and utilizing no - sql query languages such as sparql @xcite that can perform distributed queries over multiple databases .",
    "some of the first major efforts to make life science data available as linked data have been the uniprot rdf initiative @xcite and the bio2rdf project @xcite .",
    "uniprot focuses on making data within a single database , uniprot , available as linked data so that information and identifiers can be reused in other databases , while bio2rdf has the aim to combine multiple databases and demonstrate the potential of linked data in life sciences , in particular with regard to provenance tracking , usability and interoperability .",
    "now , major databases , such as those provided by the european bioinformatics institute ( ebi ) and the national center for biotechnology information ( ncbi ) , are made available as linked data @xcite .",
    "additionally , community guidelines and principles for data publishing such as the fair principles @xcite require data to be made available in a way that is amenable to interoperability through linking and federation of queries .",
    "a second major component of applications of the semantic web in the life sciences has been the development and use of ontologies .",
    "ontologies are specificiations of a conceptualization of a domain @xcite , i.e. , they formally and explicitly specify some of the main regularities ( classes of entities ) that can be found within a domain and their interconnections @xcite .",
    "ontologies are now widely used in biological datasets for the annotation and provision of metadata .",
    "they are commonly represented in formal languages with model theoretic semantics @xcite which makes them amenable to automated reasoning",
    ". however , the large size of the ontologies and the complexity of the languages and reasoning tasks involved have somewhat limited ontologies use in automated reasoning . in particular , there is still a large disparity between the ontologies in biomedicine and the databases that uses them for annotation . while inferences over the ontologies , as part of ontology development and quality assurance process , become increasingly common @xcite , they are not always applied to infer new relations between biomedical data .",
    "recently , several machine learning methods have become available that can be utilized to learn features from raw data @xcite .",
    "several of these methods can also be applied to graph - structured data @xcite .",
    "while most of these methods are developed for graphs without edge labels ( in contrast to linked data in which edge labels represent the type of relation between entities ) , some methods have also been extended to incorporate edge labels @xcite . however , to be applicable to biological data , a crucial aspect is the interoperability between both the data layer ( as expressed in linked data formats ) and the annotations of data items or semantic layer ( expressed through ontologies and the background knowledge they provide ) .",
    "this tight integration between data and knowledge , as dominantly present in biological databases , benefits from automated reasoning so that it becomes possible to consider inferred knowledge , handle data consistency and identify incompatible conceptualizations .",
    "we developed a method to leverage the semantic layer in knowledge graphs such as the semantic web or wikidata by combining automated reasoning over ontologies and feature learning with neural networks , to generate vector representations of nodes in these graphs ( node embeddings ) .",
    "we demonstrate that these representations can be used to predict edges with biological meaning .",
    "in particular , we demonstrate that our approach can predict disease genes , drug targets , drug indications , gene functions and other associations with high accuracy , in many cases matching or outperforming state of the art methods .",
    "our results demonstrate how linked data and ontologies can be used to form biological knowledge graphs in which heterogeneous biological data and knowledge are combined within a formal framework , and that these graphs can not only be used for data retrieval and search , but provide a powerful means for data analysis and discovery of novel biological knowledge .",
    "in our experiments , we build a knowledge graph based on three ontologies : the gene ontology ( go ) @xcite downloaded on 18 july 2016 , the human phenotype ontology @xcite downloaded on 18 july 2016 , and the disease ontology @xcite downloaded on 19 august 2016 .",
    "we also use the following biological databases in our knowledge graph :    * human go annotations from swissprot @xcite , and phenotype annotations from the hpo databases @xcite , downloaded on 23 july 2016 .",
    "we include a total of 211,975 go annotations and 153,575 phenotype annotations .",
    "* human proteins interactions from the string database @xcite downloaded on 18 july 2016 .",
    "we filter proteins by their interactions confidence score and choose those above 700 .",
    "the total number of interactions in this dataset is 188,424 . *",
    "human chemical ",
    "protein interactions downloaded from the stitch database @xcite , on 28 august 2016 , filtered for confidence score of @xmath0 .",
    "the total number of drug - target interactions present in the graph is 554,366 . * genes and disease associations from disgenet @xcite , downloaded on 28 august 2016 , consisting of 236,259 associations . *",
    "drug side effects and indications from sider @xcite , downloaded on 15 august 2016 .",
    "we include a total of 48,702 drug  side effect pairs and 6,159 drug  indication pairs in our graph . * diseases and their phenotypes from the hpo database @xcite and text mining @xcite .",
    "we include a total of 84,508 phenotype annotations of diseases .",
    "we map all protein identifiers to entrez gene identifiers and use these to represent both genes and proteins .",
    "we use pubchem identifiers to represent chemicals and we map umls identifiers associated with diseases in disgenet and indications in sider to the disease ontology using mappings provided by disease ontology .",
    "we further map umls identifiers associated with side effects in sider to hpo identifiers using mapping between umls and hpo @xcite .",
    "a knowledge graph is a graph - based representation of entities in the world and their interrelations .",
    "knowledge graphs are widely used to facilitate and improve search , and they are increasingly being developed and used through semantic web technologies such as the resource description framework ( rdf ) @xcite . here , we focus on knowledge graphs centered around biological entities and their interactions , ignoring all meta - data including labels or provenance .",
    "the knowledge graphs we consider have two distinct types of entities : biological entities , and classes from biomedical ontologies that provide background knowledge about a domain .",
    "the aim of building a biological knowledge graph is to represent , within a single formal structure , biological relations between entities , their annotations with biological ontologies , and the background knowledge in ontologies .",
    "we make a clear distinction beween instances and classes .",
    "while there is some debate about which kinds of biological entities should be treated as instances and which as classes @xcite , similarly to other linked data approaches @xcite , we treat biological entities such as types of proteins , diseases , or chemicals , as instances in the knowledge graph . in our case ,",
    "classes from the disease ontology are also treated as instances . on the level of instances",
    ", we can integrate existing graph - based representations used in biology and biomedicine , in particular biological networks such as protein - protein interaction networks , genetic interaction networks , metabolic interactions or pathways .",
    "ontology - based annotations are expressed by asserting a relation between the instance ( e.g. , a disease or protein ) and an instance of the ontology class .",
    "for example , we express the information that the protein _",
    "foxp2 _ has the function _ transcription factor binding _ ( go:0003700 ) by the two axioms @xmath1 and",
    "@xmath2 where @xmath3 and @xmath4 are instances , @xmath5 the class http://purl.obolibrary.org/obo/go_0003700 in go , @xmath6 an object property , and @xmath7 the rdf : type property specified in the owl standard @xcite as expressing an instantiation relation .",
    "the instance @xmath4 can be expressed as an anonymous instance ( i.e. , a blank node in the rdf representation ) or be assigned a unique new iri . in our knowledge graph , we create a new iri ( i.e. , an iri that does not occur anywhere else in the graph ) for each of these instances .      due to the large size of the knowledge graphs we process , we rely on polynomial - time automated reasoning methods .",
    "owl provides three profiles @xcite that facilitate polynomial time inferences , and multiple rdf stores implement different subsets of owl to facilitate inferences and improve querying .",
    "for example , the owl - horst subset @xcite is used by several rdf stores and is useful in data management and querying . in biological and biomedical ontologies , the owl 2 el profile is widely used to develop the large ontologies that are in use in the domain , and has been found to be useful and sufficient for a large number of tasks @xcite .",
    "owl 2 el supports basic inferences over ontologies class hierarchies ( including intersection , existential quantification and disjointness between named classes ) , supports inferences over object properties ( transitivity , reflexivity , and object property composition ) , and can infer the classification of instances . we make use of owl 2 el for representing the knowledge graphs we generate and utilize the elk reasoner @xcite for automated reasoning over them . in principle , other profiles of owl can also be used following a similar approach , but may not be feasible due to the high computational complexity of generating inferences @xcite .",
    "owl 2 el supports the following class descriptions , class and object property axioms ( using capital letters for classes , lower case letters for object properties , and @xmath8 for instances ) :    * class description : class intersection ( @xmath9 ) , existential quantification ( @xmath10 ) , limited enumeration using a single instance ( @xmath11 ) * class axioms : subclass ( @xmath12 ) , equivalent class ( @xmath13 ) , disjointness ( @xmath14 ) * object property axioms : sub - property ( @xmath15 ) , property chains ( @xmath16 ) , equivalent property ( @xmath17 ) , transitive properties ( @xmath18 ) , reflexive properties    we deductively close the knowledge graph with respect to the owl 2 el profile , using an owl 2 el reasoner @xcite .",
    "a knowledge graph @xmath19 is deductively closed if and only if for all @xmath20 such that @xmath21 , @xmath22 . in general , the deductive closure of a knowledge is countably infinite .",
    "therefore , we only add inferences that can be represented explicitly as edges between named individuals and classes in @xmath19 , i.e. , between entities that are explicitly named in @xmath19 . in particular",
    ", for all instances @xmath23 and object properties ( i.e. , edge labels ) @xmath24 , if @xmath25 , then @xmath26 . furthermore , for all named classes @xmath27 and instances @xmath28 , if @xmath29 , then @xmath30 .",
    "finally , we also infer relations between classes , in particular subclass axioms , and add them to the inferred graph : for any class @xmath31 , if @xmath32 , then @xmath33 .",
    "we use the owl api version 4 @xcite to classify the input knowledge graph and add all inferences obtained by using the elk reasoner as new edges to the knowledge graph to generate @xmath34 .",
    "we use this fully inferred graph as a basis for generating the node embeddings through our method .      to generate node embeddings",
    ", we use a modified version of the deepwalk algorithm @xcite in which we consider edge labels as part of the walk . a random walk of length @xmath35 over a graph @xmath36 and",
    "start vertex @xmath37 is an ordered sequence of vertices @xmath38 , @xmath39 , and each @xmath40 ( @xmath41 ) is determined by randomly selecting an adjacent node of @xmath42 .",
    "as knowledge graphs generated by our method additionally have edges of different types ( i.e. , edge labels , @xmath43 ) , we extend this notion to edge - labeled random walks .",
    "an edge - labeled random walk of length @xmath35 over the graph @xmath36 , edge labels @xmath44 in the label space @xmath45 ( i.e. , the set of object properties in the knowledge graph underlying @xmath46 ) , and start vertex @xmath37 is a sequence @xmath47 such that @xmath39 , @xmath48 , and , starting with @xmath49 and for all @xmath40 ( @xmath50 ) , a random outgoing edge @xmath51 of @xmath40 , ending in @xmath52 is chosen to generate @xmath53 from @xmath54 and @xmath52 .",
    "we implement this algorithm as an extension of the deepwalk @xcite .",
    "the algorithm takes a knowledge graph @xmath55 as input and generates a corpus @xmath56 consisting of a set of edge - labeled random walks , starting either from all vertices @xmath57 , or all vertices @xmath58 of a specified subset of @xmath59 .",
    "parameters of the algorithm are the length of the walks and the number of walks per node .",
    "source code of the algorithm and documentation are freely available at https://github.com/bio-ontology-research-group/walking-rdf-and-owl .",
    "we use the corpus @xmath56 of edge - labeled random walks as an input for learning embeddings of each node .",
    "we follow the skip - gram model @xcite to generate these embeddings .",
    "given a sequence of words , @xmath60 in @xmath56 , a skip - gram model aims to maximize the average log probability @xmath61 in which @xmath62 represents a context or window size . to define @xmath63",
    ", we use negative sampling , following @xcite , i.e. , replacing @xmath64 above with a function to discriminate target words ( @xmath65 ) from a noise distribution @xmath66 @xcite , drawing @xmath67 words from @xmath66 : @xmath68\\ ] ] the vector representation ( embedding ) of a word @xmath69 occurring in corpus @xmath70 is the vector @xmath71 in eqn .",
    "[ eqn : noise ] derived by maximizing eqn . [ eqn : optimize ] .",
    "the dimension of this vector is a parameter of the method .    since our corpus consists of often repeated edge labels ( due to the relatively small size of the label space @xmath72 ) , we further use sub - sampling of frequent words @xcite ( which mainly represent edge labels in the corpora",
    "we generate ) to improve the quality of node embeddings .",
    "we follow @xcite and discard , during training , each word @xmath73 ( i.e. , node or edge ) with a probability @xmath74 where @xmath75 is a threshold parameter .",
    "it is obvious from this formulation that the parameters for learning the representation of nodes in a knowledge graph include the number of walks to perform for each vertex , the length of each individual walk , a subset @xmath76 of vertices from which to start walks , the size of the vector representations learned by the skip - gram model , the window or context size employed in the skip - gram model , the parameter @xmath75 used to sub - sample frequent words ( we use @xmath77 for all our experiments ) , and the number of words to draw from the noise distribution ( we fix this parameter to @xmath78 in our experiments ) .",
    "there are several additional parameters for training a skip - gram model , including learning rate and certain processing steps on the corpus , for which we chose default values in the gensim ( https://radimrehurek.com/gensim/ ) skip - gram implementation .",
    "the embeddings can be used as features in machine learning tasks that should encode for the local neighborhood of each node , thereby encoding for the ( local ) information contained in a knowledge graph about a certain vertex .",
    "we apply these features to the task of edge prediction , in which we aim to estimate the probability that an edge with label @xmath79 exists between vertices @xmath80 and @xmath81 given their vector representation , @xmath82 and @xmath83 : @xmath84 .",
    "we use the logistic regression classifier implemented in the sklearn library @xcite to train logistic regression models .",
    "we build separate binary prediction models for each edge type in the knowledge graphs . for model building and testing ,",
    "we employ 5-fold cross - validation .",
    "each cross - validation fold is built by randomly removing 20% of edges of a particular type in the knowledge graph , then applying deductive inference , corpus generation through edge - labeled random walks , learning of vector representations of nodes , and building of a binary logistic regression model . a model for edges with label @xmath79",
    "is trained using as positive instances all pairs of vertices for which an edge with label @xmath79 exists in the modified knowledge graph ( in which 20% of edges with label @xmath79 have previously been removed ) , and using as negatives a random subset of all pairs of vertices @xmath85 such that @xmath86 is of the same type ( i.e. , an instance of the same class in the knowledge graph ) as all sources of edges with label @xmath79 , and @xmath87 is of the same type as all targets of edges with label @xmath79 .",
    "for example , if edges with label @xmath79 are all between instances of _ drug _ and _ disease _ in a knowledge graph , then we sub - sample negative instances among all pairs of instances of _ drug _ and _ disease _ for which no edge exists in the original knowledge graph .",
    "the constraint of choosing negatives from the same general types of entities is necessary because instances of different types will be clearly separable within the embeddings , and evaluation using those would therefore bias the results .",
    "we randomly generate a set of negative samples with the same cardinality as the set of positive samples , both for model training and prediction .",
    "the embeddings can also be used for findings similar nodes using a measure of similarity .",
    "we use cosine similarity to compute the similarity between two vectors : @xmath88      using the performance on the final prediction model , we perform parameter optimization through a limited grid search . we only optimize embedding size , number of walks , walk length and context size for the skip - gram model through a grid search since an exhaustive optimization would be too computationally expensive .",
    "furthermore , we only use a single edge type to test how results change with each choice of parameter , due to computational constraints .",
    "we tested the following 625 parameters : embedding sizes of @xmath89 , @xmath90 , @xmath91 , @xmath92 , and @xmath93 , number of walks @xmath94 , @xmath95 , @xmath96 , @xmath97 , and @xmath98 , walk length @xmath78 , @xmath99 , @xmath100 , @xmath101 , and @xmath102 , and skip - gram context sizes @xmath78 , @xmath99 , @xmath100 , @xmath101 , and @xmath102 .",
    "we found the best performing parameters to be @xmath93 for the embedding size , @xmath95 for the number of walks , @xmath101 for the walks length and @xmath99 for the skip - gram context size , and we fix these parameters throughout our experiments .",
    "we build a knowledge graph using semantic web technologies centered on human biomedical data .",
    "the graph incorporates several biological and biomedical datasets and is split in two layers , instances and classes . on the level of instances in the knowledge graph , we combine protein - protein interactions ( ppis ) @xcite , chemicals ( drugs ) and their protein targets @xcite , drugs and their indications @xcite , and genes and the diseases they are involved in @xcite . on the level of classes ,",
    "we include the human phenotype ontology @xcite , and the gene ontology @xcite , and we include annotations of diseases and their phenotypes @xcite , genes and their phenotypes @xcite , and human protein functions and subcellular locations @xcite .",
    "the knowledge graph , including the data , ontologies and our formal representation of ontology - based annotations , consists of 7,855,737 triples .",
    "we use the elk reasoner @xcite to deductively close this graph , and through the application of ontology - based inference , we further infer 5,664,387 new triples and add them to the knowledge graph . we utilize this knowledge graph as the input to our algorithm that can learn representations of nodes . these representations represent the neighborhood of a node as well as the kind of relations that exist to the neighboring nodes . to learn these representations , we perform random walks from each node in the knowledge graph repeatedly , use the resulting walks as sentences within a corpus , and apply the word2vec skip - gram model @xcite to learn embeddings for each node .",
    "we use the fully inferred , deductively closed knowledge graph to perform the random walks . performing random walks on the deductively closed graph has the advantage that not only asserted axioms will be taken into consideration , but representations can also include inferred knowledge that is not present explicitly in the graph .",
    "for example , for an assertion that a gene @xmath103 has a function @xmath104 ( where @xmath104 is a class in the go ) , all superclasses of @xmath104 in go will be added as annotations to @xmath103 ; sub - properties ( such as @xmath105 ) asserted in an ontology or database will be resolved ; transitive , reflexive object properties and property chains resolved and the inferred edges added .    we automated these steps ( ontology - based classification , repeated random walk , generation of embeddings ) in an algorithm that combines the steps relying on symbolic inference and the learning of embeddings using a neural network .",
    "the input of the algorithm is a knowledge graph and the parameters needed for the algorithm such as the length and number of walks and size of the resulting embeddings , the output is an embedding ( of a specified size ) for each node in the knowledge graph .",
    "figure [ fig : overview ] illustrates our basic workflow .",
    "the resulting embeddings can be used in standard machine learning classifiers .",
    "we demonstrate these uses in two settings .",
    "first , we remove edges from the knowledge graph , regenerate the embeddings using the reduced graph , and train a logistic regression classifier to predict whether or not an edge exists between two nodes , given the embeddings for two nodes as input .",
    "this kind of application is intended to demonstrate how associations between two potentially different types of entities , such as a gene and disease , can be identified .",
    "we perform these experiments in 5-fold cross - validation setting for every edge type in our graph except edges that exist only between ontology classes .",
    "table [ tab : performance ] summarizes the results .",
    ".[tab : performance]performance results for edge prediction in a biological knowledge graph .",
    "edge types marked with an asterix are between instances and instances of ontology classes .",
    "[ cols=\"<,^,^,^,^ \" , ]     we find that the performance of the prediction differs significantly by edge type , but some types of relations can be predicted with high f - measure .",
    "furthermore , using the knowledge graph with reasoning improves the performance slightly when predicting edges between instances and mostly results in decreased performance when aiming to predict edges between instances and and instance of an ontology class .",
    "we achieve overall highest performance on predicting _ has target _ edges with an f - measure of @xmath106 and rocauc of @xmath107 , and lowest overall performance on associations between diseases and their phenotypes ( _ has disease phenotype _ , rocauc @xmath108 ) . while our aim here is not to propose a novel method of predicting drug targets , protein functions or phenotypes , state of the art approaches that incorporate multiple types of information and use graph inference for predicting drug ",
    "target edges achieve rocauc of up to @xmath109 @xcite , albeit using a different set of positive and negative drug  target pairs .",
    "similarly , some of the edges , such as has function or has phenotype , have to be predicted in a hierarchical output space ( i.e. , an ontology such as the gene ontology @xcite and the human phenotype ontology @xcite ) and need to satisfy additional consistency constraints ( due to formal dependencies between the labels ) , which may overall result in lower performance when applied to these tasks @xcite .",
    "while the evaluation results demonstrate that the embeddings of vertices learned through our approach contain sufficient information about the node to be useful in predictive models , more specific knowledge graphs , containing different types of information , need to be built for specific applications .      as second use case",
    ", we also test how well the node embeddings can be used to predict novel relations , i.e. , relations that are not explicitly represented in the knowledge graph .",
    "such an evaluation can provide information about how well the embeddings our algorithm generates can be reused in novel applications or as part of larger predictive systems for hypothesis generation @xcite .",
    "we aim to test how much information about shared mode of action is encoded in the embeddings of drug nodes generated by our method , and how the performance of our approach compares to related efforts . using side - effect similarity alone",
    ", it is possible to identify pairs of drugs that share protein targets and indications @xcite , thereby demonstrating that side effects provide some information about drugs modes of action @xcite .",
    "we train a logistic regression classifier to predict whether a pair of drugs ( represented by the embeddings we generate ) share an indication or target . to make our input data comparable to studies that compare only drugs side effects , and to avoid bias introduced by encoding targets and indications in the knowledge graph",
    ", we remove all _ has indication _ and _ has target _ edges from our graph and further retain only drugs contained in the sider database @xcite . we then train a logistic regression classifier to determine whether a pair of drugs shares an indication , a target , or both , using 80% of the drug pairs as training and keeping 20% as testing .",
    "figure [ fig : rocauc ] shows the resulting performance .",
    "we can achieve up to @xmath110 rocauc for predicting pairs of drugs that share both an indication and a target , @xmath111 rocauc for drugs that share targets , and @xmath108 rocauc for drugs that share indications . in comparison , ranking drug pairs by their side effect similarity alone can achieve a rocauc of up to @xmath112 for drugs sharing targets and @xmath113 for drugs sharing indications @xcite .",
    "our results demonstrate that our method generates embeddings that encode for the explicit information in a knowledge graph , is capable of utilizing this for prediction and achieve comparable results to other approaches .",
    "moreover , after removing _ has target _ and _ has indication _ edges , drugs are not directly linked to protein - protein interactions , protein functions or disease phenotypes .",
    "nevertheless , the embeddings generated for drugs based on the corpus generated by random walks can encode some of this information , for example by linking both genes and drugs to similar phenotypes ( and thereby providing information about potential drug targets ) , linking diseases and drugs to similar phenotypes ( and thereby providing information about potential indications ) , as well as more complex interactions . instead of using a classifier , similarity between the embeddings can also be exploited to identify biological relations . using the full knowledge graph , we further tested whether drug - drug similarity can be used to identify drugs that fall in the same indication group .",
    "we use cosine similarity to determine how similar two drugs are and evaluate whether drugs that share the same top - level anatomical therapeutic chemical classification system ( atc ) code are more similar than drugs that do not share codes .",
    "we find drugs in the same atc top - level category are significantly ( @xmath114 , mann - whitney u test ) more similar than drugs that do not fall in the same atc top - level category .",
    "rocauc test scores of sider drug pairs the for predicting novel indications or targets or both . ]",
    "a limitation of our approach is the reliance on qualitative data and ignoring quantitative information .",
    "many of the edges in biological networks have associated weights that represent either the strength of a biological relation or the certainty of the existence of a relation . for example , networks which are based primarily on correlation between quantitative , experimentally measured variables use correlation coefficients to quantify the strength of a biological association , while network databases such as string @xcite include data from multiple databases and associate a confidence value for the existence of an edge . while random walk algorithms can , in principle , be extended to account for edge weights @xcite , the different semantics of the edge weights will require different treatments by the algorithm . in particular , incorporating edge weights may need to distinguish between weights that represent confidence in the existence of a relation ( as in confidence scores from a prediction method ) and weights that quantify the biological strength of the relation ( as in correlation coefficients ) .    despite the large success of machine learning methods in the past years @xcite , they have not yet widely been applied to symbolically represented biological knowledge .",
    "symbolic representations in biology , based on linked data and ontologies , are relying on formal languages such as owl and rdf , and utilize symbolic inference .",
    "the kind of inferences performed on this knowledge is either formally specified in the knowledge representation language @xcite or arised from hand - crafted inference rules that are applicable within a particular database , application , or query @xcite . here",
    ", we use knowledge graphs built using the semantics of owl and data is represented as instances of owl classes , but our approach of building knowledge graphs can be replaced with , or amended by , the use of explicit inference rules . in this case , instead of applying an owl reasoner to infer edges with respect to the owl semantics , rules can be used to infer edges and deductively close the knowledge graph with respect to a set of inference rules .",
    "a key difference between the knowledge graphs we use in our approach and knowledge graphs widely used in biological databases is the strong focus on representing biological entities and their relations in contrast to representing the ( non - biological ) meta - data about these entities and their associations , such as provenance @xcite and authorship .",
    "while inclusion of such metadata in knowledge graphs is required for retrieval and to ensure data quality @xcite , our method relies on the use of data models that make it possible to separate the biological content of a knowledge graph from the metadata .",
    "we demonstrate that knowledge graphs based on semantic web standards and technologies can not only be used to store and query biological information , but also have the capability to model and represent biological phenomena , such as the totality of known protein - protein interactions within a cell .",
    "the key advantage of choosing knowledge graphs over other representations is the inherent focus on representing heterogeneous information in contrast to single types of relations , the possibility to continuously add information , the use of inference rules , and the use of world wide web standards .",
    "our method allows all these advantages to be utilized for data analysis and to build predictive models , and may encourage database curators and biologists to increasingly rely on knowledge graphs to represent the biological phenomena of their interest .",
    "a prototype of the feature learning algorithm was implemented at the nbdc / dbcls biohackathon 2016 in tsuruoka .",
    "this work was supported by funding from king abdullah university of science and technology ( kaust ) .",
    "alison callahan et  al . _",
    "bio2rdf release 2 : improved coverage , interoperability and provenance of life science linked data _ , pages 200212 .",
    "springer berlin heidelberg , berlin , heidelberg , 2013 .",
    "isbn 978 - 3 - 642 - 38288 - 8 .",
    "warren  a. kibbe et  al .",
    "disease ontology 2015 update : an expanded and updated database of human diseases for linking biomedical knowledge through disease data .",
    "_ nucleic acids res _ , 43:0 d1071d1078 , 2014 .",
    "tomas mikolov et  al .",
    "distributed representations of words and phrases and their compositionality . in c.  j.  c. burges , l.  bottou , m.  welling , z.  ghahramani , and k.  q. weinberger , editors , _ advances in neural information processing systems 26 _ , pages 31113119 .",
    "curran associates , inc . , 2013 .",
    "bryan perozzi et  al .",
    "deepwalk : online learning of social representations . in _ proceedings of the 20th acm sigkdd international conference on knowledge discovery and data mining _ , kdd 14 , pages 701710 , new york , ny , usa , 2014 .",
    "isbn 978 - 1 - 4503 - 2956 - 9 .",
    "petar ristoski and heiko paulheim .",
    "rdf2vec : rdf graph embeddings for data mining . in _",
    "the semantic web - iswc 2016 : 15th international semantic web conference , kobe , japan , october 17 - 21 , 2016 , proceedings , part i _ , volume 9981 , pages 498514 , cham , 2016 .",
    "springer international publishing .",
    "boontawee suntisrivaraporn et  al .",
    "replacing sep - triplets in snomed ct using tractable description logic operators . in jim  hunter riccardo  bellazzi ,",
    "ameen abu - hanna , editor , _ proceedings of the 11th conference on artificial intelligence in medicine ( aime07 ) _ , lecture notes in computer science .",
    "springer - verlag , 2007 .",
    "herman  j. ter horst .",
    "combining rdf and part of owl with rules : semantics , decidability , complexity . in _",
    "the semantic web - iswc 2005 , 4th international semantic web conference , iswc 2005 , galway , ireland , november 6 - 10 , 2005 , proceedings _ , pages 668684 , 2005 .",
    "pinar yanardag and s.v.n .",
    "vishwanathan . deep graph kernels . in _ proceedings of the 21th acm sigkdd international conference on knowledge discovery and data mining _ , kdd 15 , pages 13651374 , new york , ny , usa , 2015 .",
    "isbn 978 - 1 - 4503 - 3664 - 2 ."
  ],
  "abstract_text": [
    "<S> * motivation : * biological data and knowledge bases increasingly rely on semantic web technologies and the use of knowledge graphs for data integration , retrieval and federated queries . in the past years , feature learning methods that are applicable to graph - structured data are becoming available , but have not yet widely been applied and evaluated on structured biological knowledge . + </S>",
    "<S> * results : * we develop a novel method for feature learning on biological knowledge graphs . </S>",
    "<S> our method combines symbolic methods , in particular knowledge representation using symbolic logic and automated reasoning , with neural networks to generate embeddings of nodes that encode for related information within knowledge graphs . through the use of symbolic logic , </S>",
    "<S> these embeddings contain both explicit and implicit information . </S>",
    "<S> we apply these embeddings to the prediction of edges in the knowledge graph representing problems of function prediction , finding candidate genes of diseases , protein - protein interactions , or drug target relations , and demonstrate performance that matches and sometimes outperforms traditional approaches based on manually crafted features . </S>",
    "<S> our method can be applied to any biological knowledge graph , and will thereby open up the increasing amount of semantic web based knowledge bases in biology to use in machine learning and data analytics . </S>",
    "<S> + * availability and implementation : * https://github.com/bio-ontology-research-group/walking-rdf-and-owl + * contact : * robert.hoehndorf@kaust.edu.sa </S>"
  ]
}