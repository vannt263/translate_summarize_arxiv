{
  "article_text": [
    "observations suggest that the present universe is populated by very large structures like galaxies , clusters of galaxies etc .",
    "current models for formation of these structures are based on the assumption that gravitational amplification of small perturbations leads to the formation of large scale structures . in absence of analytical methods for computing quantities of interest ,",
    "numerical simulations are the only tool available for study of clustering in the non - linear regime .",
    "the last two decades have seen a rapid development of techniques and computing power for cosmological simulations and the results of these simulations have provided valuable insight into the study of structure formation . in this paper",
    "we will describe some aspects of the cosmological n - body simulation , based on the code developed and used by the authors .",
    "we will stress the key physical and numerical ideas and detail some useful tests of the n - body code .",
    "after an initial introduction to cosmological n - body codes the discussion of n - body codes will focus on particle mesh [ pm ] codes .",
    "[ for a comprehensive discussion of numerical simulations using particles , see hockney and eastwood ( 1988 ) . ]",
    "an n - body code consists of two basic modules : one part computes the force field for a given configuration of particles and the other moves the particles in this force field .",
    "these two are called at each step to ensure that the force field and the particle trajectories evolve in a self consistent manner .",
    "apart from these we also need to setup the initial conditions and write the output .",
    "thus the basic plan of an n - body code follows the flow chart shown in figure  1 .",
    "structure of these modules depends on the specific application at hand .",
    "here we outline some features that are particular to cosmological n - body codes . to make quantitative statements about the required parameters of an n - body simulation",
    "we shall assume that the particles populate a region of volume @xmath0 .",
    "we shall also assume that we are using @xmath1 particles to describe the density field .",
    "the following physical requirements have to be taken into account while writing cosmological n - body codes .        *",
    "the universe is filled with matter over scales that are much larger than the scales of interest in an n - body simulation .",
    "density averaged over larger and larger scales in the universe approaches a constant value .",
    "thus the simulation volume @xmath0 can not be assumed to exist in isolation and we must fill the region outside this volume by some method .",
    "periodic boundary conditions are the only viable solution to this problem . in absence of periodic boundary conditions",
    "most of the matter in the simulation volume has a tendency to collapse towards the centre of the box , giving rise to a spurious , large rate of growth for perturbations .",
    "[ a compromise solution , called quasiperiodic boundary conditions , has been tried to solve this problem for tree codes . in this scheme",
    "periodic boundary conditions are used to restructure the simulation volume to bring a particle at the centre of the box while computing force at its position .",
    "this is done for each particle so that there is no strong tendency to collapse towards the centre of the box .",
    "( @xcite ) ] the most natural geometry for a volume with periodic boundary conditions is a cube .",
    "* we would like the evolution of perturbations to be independent of the specific boundary conditions .",
    "thus the simulation volume should not be dominated by any one object . [",
    "if the simulation volume is dominated by one object then the tidal force due to its own periodic copies will influence its later evolution . ] * we require the average density in the box to equal the average density of the universe .",
    "thus perturbations averaged at the scale of the box must be ignorable at all times for the model of interest , i.e. , @xmath2 .",
    "[ here @xmath3 is the rms dispersion in the mass averaged at scale @xmath4 . ] for example , in case of the standard cdm model this would require the box to be at least @xmath5mpc [ at @xmath6 in extent .",
    "* we would like to probe scales that are sufficiently non - linear in order to justify the use of n - body simulations .",
    "if we wish to compare the results with the real universe then we should be able to study the formation of structures with a large range in scales .",
    "in other words , the mass of individual particles in an ideal simulation must be less than the mass of the smallest structure of interest .",
    "therefore the smallest number of particles required to cover the relevant range of scales to study galaxy clustering , say , is @xmath7 we need a very large number of particles to represent the density field over this range of scales .",
    "therefore most numerical techniques used in cosmological n - body codes are oriented towards reducing the number of operations and stored quantities per particle .",
    "* we approximate collection of a very large number of particles in the universe by one particle in an n - body simulation",
    ". therefore the particles in an n - body simulation must interact in a purely collisionless manner .    the periodic boundary conditions and a very large number of particles are the key considerations in developing the detailed algorithm for an n - body code . of the two main components in an n - body code ,",
    "integration of the equation of motion is a process of order @xmath8 .",
    "the calculation of force , if done by summing the force over all pairs , is a process of order @xmath9 .",
    "therefore the calculation of force is likely to be more time consuming than evolving the trajectories in n - body codes with a large number of particles .",
    "it can be shown that , for particle numbers greater than a few hundred , direct computation of force takes an excessively long time even on the fastest computers .",
    "[ the very high speed special purpose computers are an exception to this .",
    "( @xcite ) ] three schemes have been evolved to address this problem and replace direct summation over pairs by methods that are less time consuming .",
    "these are    * _ particle mesh _",
    "( pm ) : poisson equation is solved in the fourier domain and the potential / force is computed on a fixed grid .",
    "is then interpolated to particle positions for moving the particles . density field , the source for gravitational potential , is also computed on the same mesh / grid from particle positions by using a suitable interpolating function .",
    "the `` smoothing '' of particles limits the resolution of such simulations but ensures collisionless evolution .",
    "[ see bouchet , adam and pellat ( 1984 ) and bouchet and kandrup , ( 1985 ) for an excellent discussion of pm codes . ]",
    "* _ particle - particle particle mesh _ ( p@xmath10 m ) : this scheme ( efstathiou et al , 1985 ) improves the resolution of pm method by adding a correction to the mesh force for pairs of particles with separation of the order of , and smaller than , the grid length .",
    "the number of operations required for this correction is proportional to @xmath11 where @xmath12 is the average number of neighbouring particles within a distance @xmath4 .",
    "this can be written as @xmath13 , where @xmath14 is the average number density and @xmath15 is the averaged correlation function .",
    "it is obvious that such corrections can become time consuming in highly clustered situations [ when @xmath16 . *",
    "_ tree _ : in this scheme , information about the density field is set up in form of a hierarchical tree .",
    "each level of the tree specifies position of the centre of mass and the total mass for a region in the simulation volume .",
    "force from particles in distant regions in the simulation box is approximated by the force from the centre of mass for particles in that region .",
    "this leads to a reduction in the number of operations required for calculating force .",
    "[ barnes and hut ( 1986 ) ; bouchet and hernquist ( 1988 ) ] to estimate the number of operations required for setting up the tree structure and evaluate the force , let us assume that the simulation volume is a cube and is subdivided into eight equal parts at each level .",
    "this subdivision of cells is continued till we have at most one particle per cell at the smallest level .",
    "each particle is parsed at most once at each level , therefore the upper bound on the total number of operations is proportional to @xmath17 where @xmath18 is the smallest inter - particle separation for the given distribution of particles .",
    "we have , @xmath19 where @xmath14 is the average number density , @xmath20 is the maximum density contrast and @xmath21 is the highest number density in the given distribution of particles .",
    "this implies that the upper bound on number of operations is proportional to @xmath22 .",
    "incorporating periodic boundary conditions is a very nontrivial problem in the context of tree codes .",
    "[ see hernquist , bouchet and suto ( 1991 ) for a discussion of periodic boundary conditions for tree codes . ]    amongst these methods the pm scheme has two advantages over the other methods .",
    "firstly it is the only one of the three methods outlined above that ensures a collisionless evolution .",
    "[ see melott et al .",
    "( 1997 ) ; suisalu and saar ( 1996 ) . ] secondly it has the simplest algorithm and it is also the fastest of the three methods discussed above . in the remaining discussion",
    "we shall focus only on pm codes .",
    "however , apart from computation of force , all other components are the same in all these codes [ with some minor variations ] and most of the conclusions about relative merits of the available alternatives are applicable for all three types of codes .",
    "in this section we will first present the system of equations that describe the evolution of trajectories of particles .",
    "this will be followed by a description of the methods used for numerical integration of equation of motion .",
    "it can be shown that the evolution of perturbations in a non - relativistic medium in an expanding background can be studied in the newtonian limit at scales that are much smaller than the hubble radius @xmath23 .",
    "the equations for a set of particles interacting only through the gravitational force can be written as @xmath24 here the last equality follows from the friedmann equations that describe evolution of the scale factor for the universe .",
    "the variables used here are : comoving co - ordinates @xmath25 , time @xmath26 , scale factor @xmath27 , gravitational potential due to perturbations @xmath28 , density @xmath29 and density contrast @xmath30 .",
    "cosmological parameters used in this equation are : the hubble s constant @xmath31 and the density parameter contributed by non - relativistic matter @xmath32 .",
    "n - body simulations integrate this equation numerically for each particle .",
    "numerical integration can be simplified by modifying the equation of motion so that the velocity dependent term is removed from the equation of motion .",
    "this can be achieved by using a different time parameter @xmath33 ( @xcite ) .",
    "this is defined as @xmath34 in terms of which we have @xmath35 in this form , all the cosmological factors can be clubbed in the source term in the equation of motion , making numerical implementation much simpler .      in any n - body code , a great deal of computer time is devoted to integration of the equation of motion .",
    "the basic idea of time integration is simple : the equation of motion expresses the second derivative of position in terms of position , velocity and time .",
    "time integration translates this into the subsequent changes in position and velocity . in the following discussion",
    "we will develop the idea of numerical integration of trajectories .",
    "writing the position and velocity at time @xmath36 in a taylor series about the position and velocity at time @xmath26 , we have @xmath37 here @xmath38 is the position , @xmath39 is the velocity , @xmath27 is the acceleration and @xmath40 is the rate of change of acceleration , and the subscript is used to identify the particle .",
    "we can use the equation of motion to express acceleration and the higher derivatives of position in terms of positions and velocities .",
    "therefore , in principle , we can find the new position and velocity with arbitrary accuracy .",
    "however , such a scheme is not very practical from the computational point of view as it requires an infinite series to be summed .",
    "a more practical method consists of truncating the series at some point and using sufficiently small time steps to ensure the required level of accuracy . to illustrate this point ,",
    "let us consider terms up to first order in the above series , we get @xmath41 this is the euler s method of solving differential equations and the error in the solution is of order @xmath42 . thus choosing a smaller time step leads to smaller error in each step .",
    "however , the number of steps required to integrate over a given interval in time is inversely proportional to the time step so that the overall error changes only linearly with step size .",
    "let us consider terms up to @xmath42 in order to device a more accurate integrator .",
    "@xmath43 this equation contains the rate of change of acceleration and therefore is not very useful in this form . to simplify these equations without loosing accuracy ,",
    "let us specify @xmath40 as @xmath44 this reduces the above equations to the following form @xmath45 this method can be used for velocity independent forces and is identical to the leap - frog method .",
    "the standard leap - frog method involves updating the velocity and position at an offset of half a step . to see the equivalence of the above equations and the leap - frog method",
    "let us consider the expressions for velocity at @xmath46 and @xmath47 .",
    "@xmath48 these two equations can be combined to give @xmath49 we can also use the expression for velocity at @xmath50 to write @xmath51 these two equations can now be combined to give the leap - frog method . @xmath52 this is called the leap - frog method as it updates velocities halfway between the step that is used to update the position . for velocity",
    "dependent forces these methods have to be modified into a predictor - corrector form .",
    ".this table lists the values of @xmath53 used in forward and backward integration of trajectories of a set of particles in an external potential and the corresponding error in recovering the initial conditions .",
    "here we have used one grid length as the unit of length . [ cols=\"<,<\",options=\"header \" , ]     the above test checks the working of an n - body code for a very special case . in a more general situation",
    "it is difficult to compare the output of numerical simulation at the level of positions of particles and only a statistical comparison is possible .",
    "we will use the averaged correlation function @xmath15 and the scaled pair velocity @xmath54 ( @xcite ) for testing the accuracy of the n - body code .     as a function of @xmath55 for two power law models [ @xmath56 and @xmath57 and the cdm model .",
    "the thick line depicts the relation between these quantities in linear theory and the results from simulations are shown as points .",
    "all the points in the range @xmath58 lie along the line with little dispersion . ]    in linear regime the averaged correlation function @xmath15 evolves as @xmath59 , i.e. , @xmath60 .",
    "in addition we know that @xmath58 in this regime .",
    "these can be used , along with the pair conservation equation @xcite to show that @xmath61 for @xmath58 .",
    "this equation is valid for all models in linear theory .",
    "we have plotted @xmath62 as a function of @xmath55 in figure  8 .",
    "we have plotted the line corresponding to the linear theory result and have shown results from n - body simulations as points .",
    "we used simulations of power law models [ @xmath56 and @xmath57 and the standard cdm model for this plot .",
    "points corresponding to different simulations have been shown with different symbols .",
    "all the points crowd around the line @xmath61 in the linear regime with little dispersion .",
    "the points deviate from this line for large @xmath15 but the dispersion between different models remains small .",
    "this corresponds to an approximate `` universality '' in the relation between @xmath54 and @xmath15 .",
    "[ @xcite ; @xcite ]     as a function of @xmath63 for the @xmath56 power spectrum .",
    "the points have been plotted for two epochs .",
    "the overlap between points clearly shows that the system is evolving in a self similar manner .",
    "the dashed line shows the linear slope of the averaged correlation function . ]",
    "self similar evolution of @xmath15 for power law models ( @xcite ) can be used to test correctness of the non - linear evolution of gravitational clustering . in figure  9",
    "we have plotted @xmath55 as a function of @xmath63 for the @xmath56 power law model . here",
    "@xmath64 is the scale where the linearly extrapolated @xmath15 is unity .",
    "this scale is proportional to @xmath65 for the @xmath56 power law model .",
    "if the evolution is self - similar then the points from different epochs must lie along a single curve .",
    "figure  9 clearly shows that the evolution of averaged correlation function follows a self similar pattern over a large range of scales .     for three cdm simulations done with boxsize of @xmath66 , @xmath67 and @xmath68mpc .",
    "matching of curves in the overlapping region shows that the numerical simulation is not introducing any artifacts .",
    "the dashed line shows the same function from a p@xmath10 m simulation by brieur et al.(1995 ) .",
    "this simulation was done with the same initial power spectrum but a different realisation of the gaussian random field was used .",
    "the similarity between @xmath15 in the three pm simulations and the p@xmath10 m simulation shows that the non - linear evolution is being followed in the same manner in both the simulations . ]",
    "the last test we consider here compares the averaged correlation function for simulations of the standard cdm model .",
    "we compare @xmath69 for three simulations carried out with boxsize @xmath66 , @xmath67 and @xmath68mpc .",
    "figure  10 shows that the curves match in the overlapping region , implying that the numerical simulation is not introducing any scale in the non - linear evolution of density perturbations .",
    "we also compare these curves with @xmath69 obtained from a different simulation .",
    "this reference simulation was done by brieur , summers and ostriker ( 1995 ) using a p@xmath10 m code implemented on a grape machine .",
    "this simulation was done with the same theoretical power spectrum but using a different realisation of the initial density field .",
    "the two types of simulations being compared have virtually nothing in common as far as the implementation of the mathematical model is concerned .",
    "the similarity in these curves implies that both the codes are evolving density perturbations in the same manner .",
    "in this section we will outline the method used for computing the correlation function and the scaled pair velocity ( @xcite ) from simulation data .",
    "the averaged pair velocity @xmath54 is defined as @xmath70 in this equation subscripts label particles and the averaging is over all pairs with separation equal to @xmath38 , i.e. , @xmath71 .",
    "this quantity is computed from simulation data by binning the pairs by pair separation @xmath38 .",
    "the number of pairs in a given bin as well as the quantity to be averaged is summed for each pair in each bin .",
    "the ratio of these quantities for each bin gives the value of @xmath62 .",
    "the correlation function was defined in  1.4 as the fourier transform of the power spectrum .",
    "this is equivalent to the following definition @xmath72 where the average is over all pairs of points with separation @xmath25 _ and over all @xmath25 with the same magnitude .",
    "_ this can be rewritten as @xmath73 here we have used the fact that density contrast is a random field with zero mean . we can replace the densities by number densities and the product of number densities at points separated by a given distance by the number of pairs with that separation . with this",
    "the above equation reduces to @xmath74 where @xmath75 is the number of pairs with separation @xmath38 and @xmath14 is the number of pairs in a uniform distribution .",
    "therefore the problem is again reduced to computing the number of pairs separated by a given distance .",
    "this is done by dividing the range of @xmath38 into small intervals and binning the pairs into these intervals .",
    "similar operation is required for computing the scaled pair velocity , therefore the binning operation for computing these quantities can be combined conveniently .",
    "we can obtain an expression for the averaged correlation by averaging @xmath76 .",
    "@xmath77 where we have used the fact that the average number of pairs with a given separation is proportional to the square of the separation for a uniform distribution of particles . in the discrete realisation of this expression the integrals over number of pairs are replaced by summation over bins .",
    "computationally this quantity is less error prone than the correlation function as for large separations the number of pairs in a given bin in the simulation output approaches the number of pairs for a uniform distribution .",
    "subtracting two nearly equal numbers can give large error .",
    "however , in case of the averaged correlation function the excess number of pairs at small scales is carried over to large scales through summation over all smaller scales . and",
    "in general the ratio @xmath78 is larger at all scales in comparison with @xmath79 .",
    "in the preceding sections we have described the basic mathematical model that is implemented in particle mesh cosmological n - body codes .",
    "we have not discussed the p@xmath10 m codes , tree codes , etc . in this review as only pm codes are known to ensure collisionless evolution ( @xcite ) though they suffer from a very limited resolution .",
    "other methods improve spatial resolution but do not ensure collisionless evolution .",
    "however , most of the the machinery is common to these codes and many of the results can be carried over to these codes .",
    "authors thank s.f.shandarin and f.r.bouchet for useful discussions on many aspects of n - body codes .",
    "jsb thanks csir india for the senior research fellowship ."
  ],
  "abstract_text": [
    "<S> in this review we discuss cosmological n - body codes with a special emphasis on particle mesh codes . </S>",
    "<S> we present the mathematical model for each component of n - body codes . </S>",
    "<S> we compare alternative methods for computing each quantity by calculating errors for each of the components . </S>",
    "<S> we suggest an optimum set of components that can be combined reduce overall errors in n - body codes . </S>"
  ]
}