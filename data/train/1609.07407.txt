{
  "article_text": [
    "non - contact depth measurement has a wide range of uses , from industrial to military or scientific purposes .",
    "active optical methods , such as light detection and ranging ( lidar ) systems , are especially useful due to their high spatial resolution relative to radar or ultrasound methods  @xcite . as a result",
    ", lidar has been successfully used for applications as varied as forest biomass estimation  @xcite , geological surveying  @xcite , land mine detection  @xcite , and autonomous navigation  @xcite .",
    "lidar systems have recently begun to employ single - photon avalanche diode ( spad ) detectors as sensors , replacing the previously used photomultiplier tubes ( pmts ) .",
    "these spad detectors allow for measurement of signals with much lower intensities , such as those from distant , poorly reflective , or oblique - angled surfaces  @xcite , or power - limited systems used for covert imaging or in mobile applications  @xcite . by forming histograms from hundreds to thousands of repeated measurements , photon - counting systems can approximate the full - waveform output of a pmt and use cross - correlation or maximum likelihood ( ml ) estimation to determine the depth of a scene  @xcite .",
    "new photon - counting lidar systems have demonstrated dramatic improvements in photon efficiency , forming accurate depth and reflectivity images from literally a single detected photon per pixel  @xcite or about 1.0 detected photon per pixel on average  @xcite by exploiting probabilistic models for individual photon detections and regularization inspired by typical scene structure .",
    "a key contribution of  @xcite is the use of photon - by - photon processing that attempts to remove the detections that are likely due to background noise . while this _ censoring _ is also an exploitation of spatial structure , it is introduced primarily to remove a nonconvexity inherent to ml estimation of depth in the presence of background noise .",
    "furthermore , it is applied only to depth estimation  not to reflectivity estimation .",
    "the censoring in  @xcite is also applied only to depth estimation and is based on the depths in the entire field of view being sparse after appropriate discretization . while these methods are effective in low - light scenarios where histogramming techniques perform poorly , the imaging accuracy degrades significantly in the presence of high background noise .",
    "this is of particular importance for long - distance or low - power measurements in daylight , when the rate of photon detection from ambient light may be significantly higher than the detection rate from the active illumination .",
    "building primarily upon  @xcite , this paper reexamines the model of low - flux detection as an inhomogeneous poisson mixture process .",
    "given that estimation from few detections has been demonstrated when signal and noise levels are equal , we aim to use new insights from the model to make accurate imaging possible when noise levels are 25 times higher than signal ( with other imaging conditions unchanged ) .",
    "the central idea is that by effectively separating the signal and noise contributions , estimates can be computed that are almost as good as an oracle that uses only the signal detections .",
    "here we focus on using detection times and intuition from the poisson process model to approximately unmix signal and noise contributions at each pixel .",
    "we also introduce spatial adaptivity to overcome low - reliability depth estimates when too few signal photons are detected .",
    "while some key concepts are first introduced within a pixelwise ml estimation framework , as in previous works  @xcite , we ultimately apply regularization to improve image formation . in section  [ sec :",
    "setup ] , we give a brief overview of the experimental setup , the probabilistic model of photon detection , and the ml estimators for reflectivity and depth . section  [ sec : unmix ] motivates the use of windowing for imaging at low signal - to - background ratio ( sbr ) by limiting the false acceptance of background detections as signal detections .",
    "it also motivates a spatially - adaptive approach and discusses how one can fill in information for pixels with too few signal detections .",
    "section  [ sec : algorithm ] introduces our unmixing algorithm , built into the framework of  @xcite .",
    "we demonstrate the algorithm s performance on both simulated and real data in section  [ sec : results ] .",
    "finally , section  [ sec : conclusion ] presents our conclusions and suggestions for further work .",
    "the methods of this paper are applicable to a generic raster - scanning lidar system .",
    "dwell times are fixed , so acquisition could be parallelized with simultaneous illumination of multiple scene patches and array detection .",
    "we review specifically the experimental data collection , modeling , and image formation methods of  @xcite , as it is most closely related to the present work and the publicly distributed data associated with that paper will be used to validate our new methods .",
    "the scenes used in  @xcite are rather simple . to validate our methods on more complicated scenes",
    ", we also simulate the data collection method of  @xcite on scenes from  @xcite .",
    "the setup in figure  [ fig : setup ] was used to raster - scan a scene by directing a pulsed laser at each patch @xmath0 in a scene via a two - axis galvanometer .",
    "the illumination has a pulse shape @xmath1 with rms duration @xmath2 .",
    "each scene patch corresponds to one pixel in our depth image @xmath3 and reflectivity image @xmath4 .",
    "the reflectivity @xmath5 includes the effects of radial fall - off , view angle , and material properties of patch @xmath0 .",
    "each patch is illuminated with @xmath6 pulses at a repetition period of @xmath7 . to prevent distance aliasing",
    ", we ensure that @xmath8 , where @xmath9 is the maximum scene depth and @xmath10 is the speed of light .",
    "the spad detector triggers a picosecond - resolution time stamp when a photon is detected , marking the time @xmath11 relative to the previous laser pulse .",
    "the full vector of photon detections at @xmath0 is given as @xmath12 , where @xmath13 is the total number of photons detected at that pixel .",
    "detector counts may be the result of laser - pulse photons back - reflected from the scene , ambient photons emitted by an incandescent lamp , or spad dark counts not caused by incident photons . after a detection , a spad detector has a _ reset time _ or _",
    "dead time _ during which there is no sensitivity to incident light .",
    "because of dead time , at most one detection event is recorded for each pulse - repetition period .",
    "further acquisition details can be found in  @xcite and its supplement  @xcite , with the modifications for the use of fixed dwell time in  @xcite .          as described in  @xcite , the illumination of pixel @xmath0 with a pulse @xmath1 results in photon flux at the detector described by @xmath14 where @xmath15 is the flux due to ambient light at the optical operating frequency @xmath16 . at the detector , this photon flux is reduced by the detector s quantum efficiency @xmath17 , which describes the probability that an incident photon is registered by the device .",
    "detector dark counts are added at rate @xmath18 , resulting in a total detection _ intensity _ given by    @xmath19    which groups the non - informational noise terms together and ignores any effect of detector dead time .",
    "over one illumination period , the detection _ rate _ is    @xmath20    where we define @xmath21 and @xmath22 .",
    "operating in a low - flux regime , we have @xmath23 , so the probability of a detection in any given illumination period is small , and the probability of multiple detections in one period is negligible .",
    "thus , by restricting our operation to the low - flux regime , we incur little error by ignoring the detector dead time effects throughout the model . in particular , by ignoring dead time , the detections are an inhomogeneous poisson process with intensity @xmath24  @xcite . as a result ,",
    "each detection time is an independent , identically distributed random variable @xmath25 with common probability density @xmath26    unlike in  @xcite , we observe the detection process for a fixed , deterministic number of illumination repetition periods ; thus , no information is conveyed by the order of the detection times or the identities of the repetition intervals in which the detections occur .",
    "it is convenient to exploit the periodicity of @xmath24 to fold time interval @xmath27 down to @xmath28 to obtain an equivalent model in which all detections occur within one illumination period due to a process with intensity @xmath29\\ ] ] and rate @xmath30 the distribution of photon counts is @xmath31 and the probability density of detection times is @xmath32    it is useful to decompose @xmath33 into two independent processes .",
    "a _ signal process _",
    "is inhomogeneous with intensity @xmath34 and a _ background process _ is homogenous with intensity @xmath35 at each @xmath0 , the number of detections due to signal is @xmath36 and the number of detections due to noise is @xmath37      the duration of a typical spad detector dead time is similar to a typical repetition period @xmath7 .",
    "thus , as noted earlier , at most one detection event is recorded for each pulse - repetition period .",
    "as developed in  @xcite , under the simplifying approximation that a dead period ends at the subsequent pulse - repetition boundary , this makes detection within each pulse - repetition period a bernoulli trial and the total number of detections in @xmath6 pulse - repetition periods a binomial random variable .",
    "more precisely ,    [ eqs : binomial_model ] @xmath38 where @xmath39\\ ] ]    is the probability of zero detections in one pulse - repetition period .    under a low - flux assumption ,",
    "the models and for @xmath40 are approximately equal ; a formal equivalence can be shown through the poisson limit theorem .",
    "the binomial model is perhaps slightly more accurate because it ignores only the portion of the dead period that falls after the subsequent pulse - repetition boundary , but this is negligible by assumption and introduces a bias ( which is again negligible by assumption ) .",
    "a possible downside of the binomial model is philosophical : it encourages one to discard the detection times when estimating reflectivity , as is done in  @xcite .",
    "the poisson model instead encourages the separation into signal and background processes , which leads to a separation of @xmath40 into its constituents @xmath41 ; estimation of reflectivity from @xmath42 is more accurate than from @xmath40 , especially when sbr is low .",
    "the binomial model results in a constrained ml ( cml ) reflectivity estimate given by @xmath43,0\\right \\}.\\ ] ] this expression essentially counts the number of detections @xmath13 out of the @xmath6 illumination intervals and subtracts a constant offset @xmath44 , the expected number of noise detections per illumination period . for @xmath44 characterized as either a poisson or binomial random variable , it is a low - variance estimator of the true number of noise detections @xmath45 as long as @xmath44 is small , since the mean and variance of these random variables are proportional .",
    "the problem with this estimator arises when @xmath46 remains small but @xmath44 is significantly larger . in that case , the variance of @xmath44 is also increased , so its reliability as an estimator of @xmath45 decreases .      by instead approaching detection entirely as an inhomogeneous poisson process",
    ", we can take advantage of the detection times in both the reflectivity and depth estimates .",
    "the signal back - reflected from @xmath0 is approximately the illumination pulse with intensity modulated by the reflectivity @xmath5 .",
    "estimation of @xmath5 then requires the same approach as estimation in amplitude - modulated optical communication as described in  @xcite .",
    "the likelihood function for the set of observed photon detections @xmath47 is @xmath48      = e^{-\\lambda_{\\nr}(\\alpha_{i , j } ) } \\prod_{\\ell=1}^{k_{i , j } }   \\lambda_{i , j}^{\\nr}(t_{i , j}^{(\\ell)}),\\ ] ] which yields a cml estimate given by @xmath49 - \\lambda_{\\nr}(\\alpha_{i , j}).\\end{aligned}\\ ] ] differentiating with respect to @xmath5 , we have @xmath50 since all terms in are nonnegative , the left - hand side is monotonically decreasing in @xmath51 , so a unique optimal estimate of @xmath5 exists .",
    "unfortunately , this expression requires knowledge of the true depth for the optimal estimate .    at high sbr ,",
    "an approximate solution is given by @xmath52 which preserves the non - negativity of @xmath51 and simplifies to @xmath53 if noise is completely eliminated .",
    "conveniently , these estimates have a closed form solution , which is simply the normalized photon count . when noise is low , all detections are due to signal , so the count is a sufficient statistic for the reflectivity  we no longer need to use the detection times or know the true depth @xmath54 .",
    "the process of depth estimation from the set of detection times is also derived in  @xcite .",
    "the cml depth estimate is given by @xmath55.\\end{aligned}\\ ] ] we can see that this requires knowledge of the true @xmath5 value , and furthermore that the noise term adds a nonconvexity . in practice , @xmath56 is computed by finding the delay that maximizes the output of a log - matched filter .",
    "again we remark on the case of zero noise , where the depth estimate is given by @xmath57.\\ ] ] in this case the noise - free solution is also greatly simplified , as it is convex and has no dependence on @xmath5 .",
    "the key observation from the parameter estimates is that the reflectivity and depth estimates are coupled and complicated in the presence of noise , but both are greatly simplified if noise is removed . indeed ,",
    "if we could unmix detection into its component signal and background processes , we could ignore the noise detections and simply apply the noise - free estimators . rather than a conventional approach of forming estimates first and then denoising ,",
    "this observation is motivation for separating signal from noise first and then forming estimates .      at an individual pixel",
    ", no marker distinguishes between signal and noise detections , so no explicit information is available to separate the signal from the noise . in order to unmix the processes , the only information we have _ a priori _ is the different probabilistic models of the detection processes .",
    "the signal process rate is related to the short - duration illumination pulse , so signal detection times have a small variance .. in a bayesian formulation in which @xmath54 has a prior distribution , the signal detection times have a small conditional variance given @xmath54 or with other conditioning that approximately localizes @xmath54 . ]",
    "this suggests that when several signal photons are detected at the same pixel , the detections will be clustered together near the true depth , as illustrated in figures  [ fig : proc_pdf ] and  [ fig : sample_dets ] .",
    "the background process has a constant rate , meaning no time is more likely than any other to have a background detection . since the background photons are uniformly distributed in time , we expect them to be fairly spread out in general , unless the background detection rate is very high .",
    "since signal detections tend to cluster together more readily than background detections , an intuitive approach to identifying signal photons is to search for the largest of those clusters .",
    "one way to define a cluster of detections is to choose a window of duration @xmath58 and a minimum cluster size @xmath59 .",
    "the window duration should be chosen such that @xmath60 , so that a well - placed window ( one shifted by approximately @xmath61 ) is large enough to capture most or all signal detections , without accepting too many noise detections .",
    "if at @xmath0 there are at least @xmath59 detections within some window of duration @xmath58 , then we can consider @xmath0 as having a cluster of detections .",
    "if there happen to be multiple clusters at @xmath0 , we choose the window with the most detections @xmath62 as our signal cluster . from the shift of the window",
    ", we have an estimate of the depth @xmath54 , and since the mean number of noise detections in a short interval @xmath58 is close to zero , @xmath62 yields a rather accurate estimate of the number of signal detections @xmath63 analogously to . as detailed later , the purpose of the @xmath59 minimum  rather than to seek the largest cluster regardless of its size  is to have a mechanism to produce no depth estimate rather than an unreliable one .",
    "in fact , this intuitive windowing approach falls out of the ml reflectivity and depth estimates . crudely approximating @xmath1 by a square wave of duration @xmath2 centered at @xmath61 , the reflectivity estimate in",
    "is due only to detections that occur within @xmath64 of the true depth . even for a more realistic pulse shape , only detections within a short duration around the true depth",
    "contribute non - negligible weight to the reflectivity estimate .",
    "furthermore for the depth estimate , again approximating @xmath1 as a square wave , the log - matched filter is maximized at the window containing the largest number of detections .    in the appendix , we derive the separate probabilities that the signal and background processes will generate detection clusters , according to our definition .",
    "figures  [ fig : sig_clust ] and  [ fig : noise_clust ] compare these derivations to monte carlo simulations of clustering based on the detection model , confirming that these derivations produce reasonable probability estimates and that the simplifying assumptions are minor . for all experiments and derivations , @xmath58 was fixed to @xmath65 , where @xmath66  ps is the measured rms pulse width of the experiments in  @xcite .",
    "this window size covers more then 95@xmath67 of the probability mass of signal detection for a gaussian pulse shape approximation .",
    "the pulse repetition period @xmath68  ns is also used from  @xcite .",
    "0.32    0.32    0.32    using the plots of these probabilities in figure  [ fig : clust_prob ] , we observe that for some rates of signal and background detection , our intuition of finding clusters of detections by windowing is justified .",
    "for instance , if the signal and background rates were each 10 photons per pixel ( ppp ) , the probability of observing a cluster of signal detections would be about 1 for any of the minimum cluster sizes shown ( see figure  [ fig : sig_clust ] ) , whereas the probability of observing a cluster of background detections would be negligible for @xmath69 ( see figure  [ fig : noise_clust ] ) . as a result ,",
    "the largest cluster of detections is likely to have more than two detections , and thus the largest cluster could be safely assumed to contain at least one signal detection .",
    "ideally , we could select optimal @xmath58 and @xmath59 values for each pixel based on the local signal and noise rates .",
    "however , we only know the background rate from calibration ; the signal rate is unknown since it depends on the unknown reflectivity parameter .",
    "our approach from the given data is to fix a reasonable window size and choose @xmath59 based solely on the noise rate , which is known from calibration testing with no signal input . given that we assume the largest cluster at a pixel is due to signal , we restrict our minimum cluster size to limit the number of clusters falsely accepted as signal when they are actually due to noise .",
    "as in figure  [ fig : noise_clust ] , we set a threshold @xmath70 for the probability of clusters due to noise that we will allow .",
    "for any given noise rate , we can then choose the smallest @xmath59 that will yield @xmath71 < \\taufa$ ] .",
    "this method of choosing @xmath59 as a function of the noise rate is illustrated in figure  [ fig : ncl_rule ] .",
    "since the theoretical derivation tends to slightly overestimate @xmath71 $ ] , we are likely to see even fewer clusters due to noise than the actual threshold we set .    now that a reasonable cluster definition is established",
    ", we can window the detections at each pixel , and if @xmath72 , we discard all detections except those in the best window as noise .      while setting a low @xmath70 is a good approach for limiting the number of accepted noise clusters , the resulting @xmath59 may be too high for any cluster to be found . moreover , for photon - efficient imaging , it is common for large regions of scenes to have very few signal detections , such as in @xcite , where some scenes were reported as having @xmath73 of pixels with no detections . even with no background present , it would be impossible to estimate the depth purely from windowing , since there are no clusters to identify . as a result , relying on windowing for low-@xmath51 ,",
    "low - sbr data often yields too many pixels with no depth estimate .    a key insight into solving this problem comes from analyzing the behavior of ml depth estimates in noise .",
    "is approximated by a gaussian pulse of rms width approximately equal to our measured laser pulse . ]",
    "figure  [ fig : monte_carlo ] shows the results of monte carlo simulations of depth estimation for various @xmath51 and sbr values , where we see a thresholding behavior that is common to nonlinear estimators @xcite .",
    "specifically , if enough signal detections are present , the ml depth estimate has low mean - squared error , regardless of the sbr .",
    "this phenomenon is due to the small variance of the signal process relative to the noise , resulting in a strong peak where large numbers of signal detections cluster together , even when @xmath74 .",
    "the natural solution is that used by conventional lidar : by acquiring many detections over long acquisitions times , the coherent signal becomes easier to detect in incoherent noise , even if the signal is relatively weak .",
    "given the purpose of photon - efficient imaging , extending acquisition time is an inadequate solution , but a few further observations allow this method to be used as inspiration .",
    "first , natural scenes , especially depth maps , are generally smooth except at object boundaries , so neighboring pixels often have approximately equal depth .",
    "this was the justification for the total variation ( tv ) regularization used in  @xcite , since tv regularization tends to smooth out noise while still preserving jump discontinuities  @xcite .",
    "secondly , edges in reflectivity and object boundaries in depth tend to be co - located , so scene patches that are similar in both reflectivity and transverse position likely are similar in longitudinal position ( depth ) as well .",
    "these observations can be codified through the construction of _ superpixels _ , oversegmentations of an image into small regions of similar pixels , which are a common tool in computer vision applications .",
    "superpixels were originally introduced in @xcite with the idea that pixels are arbitrary elementary units of digital images , and that breaking images into more natural building blocks could improve and speed up further processing such as larger - scale image segmentation and object detection .",
    "the general reasoning is that pixels that are similar in both some color space ( e.g. , lab ) and in transverse position have a high probability of belonging to the same object . as a result",
    ", superpixels have been used as a preprocessing tool to provide noise robustness and to fill in gaps of depth maps for stereo @xcite , rgb - d @xcite , and lidar @xcite systems .",
    "our approach is to use a variant of superpixels to artificially extend acquisition times , which facilitates depth estimation .",
    "consider a small neighborhood of pixels in a scene , such as the one illustrated in figure  [ fig : sample_spxl ] .",
    "assuming that the scene has been sampled with adequate transverse spatial resolution , pixels within this neighborhood will have similar depth values , unless the neighborhood crosses a boundary between objects .",
    "if @xmath75 is in the neighborhood of @xmath0 , then @xmath76 for all @xmath77 .",
    "thus , combining detections from @xmath75 into the @xmath0 vector is almost equivalent to doubling the acquisition time at @xmath0 .",
    "this borrowing will maintain sbr but increase @xmath63 , helping to reduce the estimation error , as we observed in figure  [ fig : monte_carlo ] .",
    "borrowing creates some smoothing in the transverse directions , and the ideal trade - off between noise reduction and this smoothing probably occurs just to the left of the estimation threshold illustrated in figure  [ fig : monte_carlo ] .    for practical purposes , reinforcing the coherent signal by borrowing detections from neighboring pixels will enhance the size of signal clusters and make windowing more reliable and useful , as illustrated in figure  [ fig : sample_form_spxl ] .",
    "when superpixels are formed , the noise rate is effectively amplified by @xmath78 , the number of pixels that contributed to the enhanced detection vector at @xmath0 , so we update our cluster size requirement for windowing to @xmath79 to avoid falsely accepting noise clusters .",
    "this formulation in fact describes the generic windowing procedure , where @xmath80 if the detections at only a single pixel are used .",
    "there are many existing superpixel definitions and implementations , each designed to meet particular performance criteria @xcite . in principle , any definition could be used within our algorithm to select groups of similar pixels from which to borrow photon detections .",
    "a key difference of our approach to that of the other depth - estimation applications of superpixels in @xcite is that the existing methods all incorporate a conventional digital camera .",
    "superpixels are formed using the high - quality color images , and then the assumed redundancy of these regions is applied to corresponding regions of a lower - quality depth map to fill in gaps or filter out noise . in our system , reflectivity is a grayscale value estimated from the same active illumination data used to estimate the depth . due to the low signal counts and high background levels , the intensity data is much less reliable than that from a conventional camera . as a result , we use a simple definition of selecting the subset of pixels in a square region that meet a reflectivity tolerance compared to @xmath0 .",
    "since pixels are chosen within a fixed distance of @xmath0 , the set of candidate pixels changes slightly from one pixel of interest to the next .",
    "we use this particular definition in order to promote a high degree of localization , which helps preserve small changes in reflectivity and depth .",
    "other superpixel definitions that consider each region to be homogeneous would smooth over these small changes .",
    "our method for forming depth and reflectivity images from the raw detection data builds off the image formation procedure of @xcite , adding in the windowing and spatial adaptivity introduced in section  [ sec : unmix ] .",
    "the procedure is summarized by the block diagram in figure  [ fig : block_diag ] , and we now detail each component .",
    "+        the raw data input to the algorithm is the set of photon detections @xmath12 for each patch @xmath0 ( thus implicitly including the values @xmath13 ) .",
    "it is also assumed that @xmath44 , the mean background count per patch per pulse - repetition period , and @xmath81 , the mean signal count per pulse in the absence of any attenuation , have been measured through calibration or approximated from environmental conditions and hardware specifications .",
    "a small number of algorithm parameters are introduced as needed .",
    "the process of noise censoring at patch @xmath0 by adaptive windowing uses two parameters : a window length @xmath58 and a target probability of false acceptance of a noise cluster @xmath70 .",
    "it is performed as follows , assuming for the moment no borrowing of detections from neighboring patches :    1 .   for each @xmath82 , find the set of detections in the interval of length @xmath58 starting at the detection time @xmath83 : @xmath84 2 .   among these sets ,",
    "select a set @xmath85 with the largest number of detections : @xmath86 and define @xmath87 .",
    "( resolve ties by choosing uniformly at random among the sets with @xmath62 detections . )",
    "3 .   using false acceptance threshold @xmath70 ,",
    "compute minimum cluster size @xmath59 as the smallest integer such that @xmath88 < \\taufa,\\ ] ] where @xmath71 $ ] is derived in and @xmath89 for windowing a single pixel .",
    "note that this step does not depend on the detection time data and thus desirable values of @xmath59 may be precomputed .",
    "4 .   if @xmath90 , retain only the detections that fall in the selected window @xmath85 and censor the rest , yielding the set of uncensored detections @xmath91 , where @xmath92    when this windowing is applied with superpixels ( i.e. , @xmath93 ) , the detection time data @xmath12 is replaced by augmented detection times @xmath94 .      in the window @xmath85 , the expected number of noise detections is @xmath95 , which is small even at low sbr and is considerably lower than the number of detections due to noise on the entire @xmath96 interval .",
    "since noise detection is a homogeneous poisson process , the variance in the number of noise detections in the window is also small , so @xmath95 is a good estimator of the number of noise detections .",
    "thus , we can modify to estimate @xmath5 from the window output as @xmath97 for those pixels where @xmath98 , this formula tends to slightly overestimate the reflectivity , since we have likely chosen the window with the largest cluster of noise detections . however , the @xmath99 estimate is temporary for those pixels , since the value of @xmath62 will be updated after windowing the augmented data from the superpixels .",
    "we form a reflectivity image by regularized ml estimation with a regularization parameter @xmath100 . using  ,",
    "the negative log - likelihood of the scene reflectivity @xmath5 given the number of detections in @xmath85 is @xmath101,\\end{aligned}\\ ] ] ignoring terms not dependent on @xmath5 .",
    "as in  @xcite , we take advantage of spatial correlations in natural scenes to form a penalized ml ( pml ) estimate that enforces smoothness : @xmath102      after windowing , all pixels have a reflectivity estimate , but only those @xmath0 where @xmath103 have reliable depth estimates . for those pixels with insufficient signal detection counts , superpixels are formed so that strongly correlated depth data from similar neighboring pixels can be combined to improve the performance of windowing .",
    "the key to our superpixel formation is to set bounds for what constitutes a similar pixel . in this paper , superpixels borrow detections from all neighboring pixels within a fixed distance and a fixed reflectivity tolerance of our pixel of interest .",
    "in particular , fix a neighborhood distance @xmath104 ( typically 1 , 2 , or 3 ) and a reflectivity tolerance @xmath105 ( typically around @xmath106 of the full range of @xmath107 values ) .",
    "the superpixel at @xmath0 is defined as @xmath108 the set of superpixel detections @xmath109 is then defined as @xmath110 where @xmath111 is the new detection count for the superpixel at @xmath0 . in this way",
    ", the algorithm searches a small local area and adaptively borrows from pixels that are similar in both transverse position and reflectivity .",
    "once superpixel vectors have been formed , the windowing process of section  [ sec : windowing ] and the reflectivity estimation of section  [ sec : refl_est ] are repeated .",
    "the windowing is performed on the set of superpixel detections @xmath109 , resulting in a different ( usually larger ) value of @xmath62 .",
    "note that the @xmath59 computation and the reflectivity estimate change to account for the number of pixels @xmath78 contributing to the superpixel vector .",
    "ideally , the smallest possible @xmath78 such that @xmath90 would be chosen at each pixel , which would ensure accurate depth estimates with the minimum amount of spatial smoothing .",
    "this could be accomplished by incorporating detections from one pixel at a time and re - windowing to check whether the @xmath59 criterion had been met .",
    "unfortunately , this repeated windowing of new detection vectors is too computationally intensive for large images .",
    "instead , we take a coarser approach that gradually increases the candidate neighborhood for forming superpixels by incrementing @xmath104 .",
    "we cycle through the procedures of windowing , estimating reflectivity , and forming superpixels , gradually increasing @xmath104 with each iteration from @xmath112 until either @xmath90 for all @xmath0 or some terminal neighborhood size @xmath113 has been reached .",
    "for any remaining pixels without a reliable depth estimate , @xmath56 is filled in by inpainting during the depth estimation procedure .",
    "it is assumed that all detections retained in @xmath114 are due to signal , although if too many noise clusters are falsely accepted , further rank - ordered mean ( rom ) censoring as in @xcite can be useful in cleaning up the data .",
    "the negative log - likelihood of the depth @xmath54 given only signal detections is @xmath115.\\ ] ] again applying a smoothness penalization appropriate for depth maps of natural scenes , the pml depth estimate is @xmath116 where @xmath117 controls the amount of penalization .",
    "a detailed account of the experimental setup and procedure is given in  @xcite and its supplement  @xcite .",
    "the important quantities for our algorithm are the illumination pulse width , measured to be @xmath66 ps , and the pulse repetition period @xmath68 ns .",
    "the spad detector quantum efficiency was @xmath118 .    in  @xcite and  @xcite ,",
    "the photon - efficient methods are compared to `` ground truth '' reconstructions of reflectivity and depth , generated using conventional lidar processing on data from long acquisition times .",
    "while these measurements serve as effective baseline comparisons , they still suffer from the same shortcomings as all lidar data .",
    "in particular , the conventional processing assumes only one depth exists at each point in the image , and we make this assumption as well . taking into account multiple depths at a single pixel as in @xcite would require adjustments to our algorithm , since superpixels would borrow detections from multiple true depths , only one of which would be registered . since experimental lidar data",
    "has effects of shadowing or reflections from multiple depths , we consider the conventional processing to produce `` baseline '' estimates , but not ground truth .",
    "+                         +                in order to quantify the algorithm performance compared to an actual ground - truth reference , we first simulated data sets using the model outlined in section  [ sec : measurement ] , where each pixel has only a single true depth .",
    "the same parameters from the experiments were used in the simulation in order to maintain consistency .",
    "furthermore , although detections are generated from a model , we use real scenes from the middlebury dataset @xcite to form @xmath119 and @xmath120 . in particular",
    ", we chose the art and bowling scenes as representative of fairly complex and fairly simple scenes , respectively .",
    "the art scene is @xmath121 pixels , and the bowling scene is @xmath122 pixels .",
    "signal counts were generated as poisson random variables with parameters equal to scaled pixel intensities .",
    "signal detection times were generated from a gaussian pulse shape with mean @xmath123 and @xmath124 .",
    "background detection counts were also generated as poisson random variables , and given the count at each pixel , the detection times were generated as uniform random variables over the repetition period @xmath96 . in order to meet the low - flux requirement , scenes were simulated so that the average pixel would require 500 illuminations to generate one signal photon .",
    "thus , performance evaluation of scenes with 2.0 and 3.0 signal ppp used 1000 and 1500 illumination periods per pixel , respectively . at the maximum evaluated noise level ( with sbr = 0.04 ) , the average photon detection rate was one detection in approximately 5@xmath67 of illumination periods .    to quantify performance",
    ", we use the mean - squared error ( mse ) in db for reflectivity : @xmath125 and the root mean - square error for depth : @xmath126    figure  [ fig : sim_results ] shows example simulation results for both scenes at sbr = 0.04 and only 2.0 signal photons per pixel on average .",
    "the scaled photon count is shown for reflectivity and the log - matched filter output for depth as a baseline for what conventional methods produce for such noisy , photon - efficient data .",
    "we compare the results of our proposed method with that of  @xcite , which is the state - of - the - art for photon - efficient imaging at lower noise levels .",
    "we also show the ideal results from a _ signal oracle _ , which represents the ideal case of perfect unmixing and using only the signal detections for estimation ( equivalently , sbr = @xmath127 ) .    throughout the simulations , we use @xmath128 ,",
    "@xmath105 = 0.05 , and @xmath129 for our algorithm , which work for a variety of scenes and experimental conditions .",
    "these parameters were mainly tuned for very - low sbr data ( around 25 times as much background as signal ) and could be adjusted to optimize performance for different noise conditions or a particular scene .    the results in figure  [ fig : sim_results ] exemplify the typical performance of the different methods .",
    "for reflectivity , it is clear that high levels of background reduce contrast too much for the method of @xcite to produce a good estimate from detection counts alone .",
    "the unmixing does a much better job at estimating the number of signal detections at each pixel .",
    "in particular , the absolute error maps show the smallest errors for the darkest regions , since formation of superpixels allows for precise fractional estimates of signal photon counts in these areas .",
    "in the case of depth estimation , the method of @xcite fails , as noise detections pull the depth estimates towards the mean scene depth ( 7.5 meters in this case ) . for our unmixing method ,",
    "the windowing procedure is much more effective at handling the high - variance noise .",
    "the largest errors that remain in our depth estimation occur in the darkest regions of the scene , particularly at object boundaries .",
    "in many of the dark regions , forming superpixels is enough to overcome the low signal photon count . at object boundaries ,",
    "however , @xmath78 decreases since many candidate pixels in the neighborhood fall outside the reflectivity tolerance so the signal clusters are too small , or if the reflectivity contrast between objects at different depths is not sufficient , the superpixels will borrow pixels at multiple depths , causing errors .",
    "nevertheless , the unmixing process produces depth estimates that are almost as good as the signal oracle in many cases .",
    "figure  [ fig : performance_results ] contains plots comparing the oracle , , and unmixing methods for 2.0 and 3.0 signal detections per pixel at various sbr levels .",
    "the mse and rmse metrics are shown for the @xmath130 and @xmath131 values that produced the best average performance over 10 trials at each value of sbr . as expected , the best performance is achieved by the oracle estimator with the most signal detections per pixel , since this case has the most signal information available and is not corrupted by background .",
    "estimation of both parameters improves in general for all methods as the signal detection count increases .",
    "it is also clear that the reflectivity and depth estimation performance of degrades significantly as sbr decreases .",
    "this is due to the shortcomings of the binomial estimator for reflectivity and the limitations of the rom censoring for removing noise detections at low sbr . for our proposed unmixing method",
    ", the parameter estimation performance also tends to increase as sbr decreases , although the change in error is smaller than for , indicating a higher robustness to noise . at sbr = 0.04 ,",
    "our reflectivity estimate outperforms the method of @xcite by about 15 db .",
    "the difference in depth estimation error is even more stark  at sbr = 0.04 , our method has rmse almost two orders of magnitude better than .",
    "+    0.49 )",
    ". plotted performance is the average error of 10 trials for each value of sbr .",
    ", title=\"fig : \" ]    0.49 ) .",
    "plotted performance is the average error of 10 trials for each value of sbr .",
    ", title=\"fig : \" ]     +    0.49 ) .",
    "plotted performance is the average error of 10 trials for each value of sbr .",
    ", title=\"fig : \" ]    0.49 ) .",
    "plotted performance is the average error of 10 trials for each value of sbr .",
    ", title=\"fig : \" ]                                                      we further evaluate the performance of our unmixing algorithm on the @xmath132 pixel dataset of the mannequin scene from @xcite , with results shown in figure  [ fig : man_results ] .",
    "baseline estimates were formed using conventional lidar processing on detection data from long acquisition times under constant conditions at sbr = 1 .",
    "the data was range - gated to capture the extent of the scene ( 4.2 to 6 meters ) , while limiting the influence of noise on the baseline estimates .",
    "depth estimates were formed by applying the log - matched filter to the first 200 detections at each pixel .",
    "reflectivity estimates were formed by scaling the detection count by the number of illumination pulses required to reach 200 detections at each pixel .",
    "truncated photon - efficient datasets were created by using only the first 3000 illumination periods ( 300 @xmath133s per pixel ) , which resulted in 4.05 signal photons per pixel on average .",
    "additional background detections were synthetically generated as uniformly distributed detection times on @xmath96 given a poisson number of background detections .",
    "including the background detections already present in the data , the background rate was adjusted to set the sbr to 0.04 to match the simulated data . for our algorithm , we use @xmath134 , @xmath105 = 0.05 , and @xmath129 .",
    "the signal oracle processing was computed on the range - gated data , truncated to the first 3000 illumination periods . since the data was collected with ambient light injected into the scene , this data was not exactly noise - free .",
    "this effectively sets sbr @xmath135 8.3 , so the oracle data represented much more favorable conditions than that for the other methods . still , there are certainly background detections present , as evidenced by the estimation of the mannequin biased slightly to the mean acquisition range @xmath136 .",
    "this bias is most noticeable in the darkest areas such as the torso , where the local sbr is significantly lower than that for the entire scene .",
    "although there is little distinction when comparing the approximate mse for the reflectivity estimates using all three methods , there is a clear advantage to using our method over that of .",
    "the results using the method of @xcite are far more smoothed with less contrast , making the text unreadable and the facial features harder to distinguish .",
    "our method instead produces much clearer results , which compare very favorably to the oracle and baseline reflectivity estimates .    as in the simulations , the method of @xcite yields an estimate that is completely out of the range of the true scene .",
    "the rom censoring is unable to handle such low sbr , so the entire estimate is dominated by noise , which yields an estimate very close to @xmath136 .",
    "the resulting rmse is then mostly an indication of how close the scene subject was to the middle of the imaging range : since the simulated scenes were positioned farther from the center of the scene , the rmse measures were larger . on the other hand , our unmixing method proves to be considerably more effective at handling the high levels of background .",
    "in particular , the brightest regions ( the wall , the mannequin s face , and the shirt around the text ) have low absolute error .",
    "the largest errors occur as in the simulations at object boundaries and in the darkest regions , such as the several small patches of the mannequin s shirt that have considerable errors .",
    "one reason that the mannequin unmixing fared worse than the simulations is the starker contrast between regions of high and low reflectivity , which makes the average number of signal detections less representative of the distinct regions .",
    "the mannequin s shirt is a very large region with very few signal detections , so a higher @xmath113 value and a higher average signal detection count were necessary to improve estimates .",
    "the conventional approaches to active imaging in significant ambient light are to increase either the acquisition time or the illumination power . in many situations , neither solution is practically feasible . in the case of autonomous navigation , for instance ,",
    "vehicle lidar systems need rapid depth acquisition using safe laser intensities and without draining the limited power resources .",
    "the only possible approach is a photon - efficient solution , which can make accurate measurements from very little incident signal illumination , even when the ambient light levels are high .    based on key observations of the probabilistic nature of the signal and background detection processes , a simple windowing approach yields an effective unmixing of the component detection processes . by setting cluster size requirements based on the easily - measured background rate ,",
    "we ensure that the number of falsely accepted background detections is limited .",
    "remaining gaps where too few signal detections were collected can be effectively filled through the spatially - adaptive process of forming superpixels and aggregating detections within those regions .    finally , a great benefit to our approach is the modularity of the algorithm , which leaves room for improvement with upgrades to the component blocks . for the results presented in this paper ,",
    "we perform only a few loops through the algorithm using well - tuned parameters that provide good results at low sbr .",
    "while forming superpixels helps fill in values for many pixels with empty depth estimates , we still require some inpainting to fill in the rest . an ideal approach would likely perform more iterations , incrementing @xmath78 by one until each pixel has a reasonable depth estimate .",
    "a major factor preventing this goldilocks approach for the just - right @xmath78 at each pixel is the computational cost of concatenating and windowing many large vectors of detections .",
    "better implementations of our code could take advantage of the embarrassingly parallel problem structure @xcite with more distributed or gpu - accelerated computations .",
    "additional approaches to possibly improve results include alternative superpixel definitions , such as the fast slic method @xcite , or regularizers such as joint basis pursuit @xcite that take further advantage of correlations between depth and reflectivity images .    in this appendix",
    ", we derive approximations for probabilities of clusters due to noise and due to signal .",
    "the final expressions are simple enough to enable tabulation of @xmath137 .",
    "since detection of noise photons is a homogeneous poisson process , given @xmath138 noise detections , the detection times @xmath139 are distributed as the order statistics of @xmath138 independent uniform random variables on @xmath28 @xcite .",
    "rescaling the set of ordered detections @xmath140 by @xmath7 so they occur in the range @xmath141 $ ] , the @xmath142th order statistic @xmath143 has the beta distribution @xmath144 .    according to (",
    "2.3 ) , the time difference @xmath145 between the @xmath142th and @xmath146th detections where @xmath147 is @xmath148 , which is a beta - distributed random variable that depends only on the difference between the @xmath146 and @xmath142 and not on their particular values .",
    "recall that @xmath59 denotes the minimum number of detections needed in a window of size @xmath58 to consider that window as having a cluster of detections . to have @xmath59 detections in a window beginning at the @xmath142th detection",
    ", we must have @xmath149 .",
    "now for pixel @xmath0 to not have any clusters , we need all candidate windows to not have clusters .",
    "since there are @xmath138 noise detections , any of the first @xmath150 detections may be followed by @xmath151 additional detections within an interval of @xmath58 and thus these are candidates for the beginning of a cluster .",
    "then the probability of no clusters is @xmath152 \\nonumber \\\\      & = \\pr[\\{\\text{no cluster starting at detection 1}\\}\\cap \\dots \\nonumber \\\\      & \\quad \\cap \\{\\text{no cluster starting at detection } ( n-\\ncl+1)\\}\\\\      & \\quad |\\,n_{i , j}=n].\\end{aligned}\\ ] ] the different candidate windows are overlapping and thus the intersected events above are not independent . making an independence assumption greatly simplifies the computation and gives an approximation that is supported by the numerical evaluations shown in figure  [ fig : noise_clust ] : @xmath152 \\nonumber \\\\      & \\approx ( \\pr[\\text{no cluster starting at detection 1}\\,|\\,n_{i , j}=n])^{n-\\ncl+1 } \\nonumber \\\\      & = ( 1-\\pr[s_{\\ncl-1}^{(1 ) } < \\twind / \\tr\\,|\\,n_{i , j}=n])^{n-\\ncl+1}.\\end{aligned}\\ ] ] from this , we have that the conditional probability of a cluster satisfies @xmath153 \\nonumber \\\\      & \\approx 1-(1-\\pr[s_{\\ncl-1}^{(1 ) } < \\twind / \\tr\\,|\\,n_{i , j}=n])^{n-\\ncl+1}.\\end{aligned}\\ ] ] finally , since @xmath154 is poisson - distributed , we can approximate the unconditional probability of a cluster by @xmath155 \\nonumber \\\\      & \\leq \\sum_{n=\\ncl}^\\infty      \\underbrace{\\pr[n_{i , j } = n]}_{\\operatorname{poisson}(\\nsp\\nr b ) } \\nonumber \\\\      & \\qquad \\cdot \\big",
    "( 1-(1-\\underbrace{\\pr[s_{\\ncl-1}^{(1 ) } < \\twind / \\tr\\,|\\,n_{i , j}=n]}_{\\beta(\\ncl-1,n+1-(\\ncl-1))})^{n-\\ncl+1 } \\big).\\end{aligned}\\ ] ]      we would like to derive the probability of clusters due to signal in a similar way , but we operate under the assumption of a gaussian pulse shape , and the order statistics for the normal distribution are not available in closed form .",
    "instead , we restrict ourselves to consider a cluster present only when @xmath59 signal detections occur in a window of length @xmath58 centered at the true depth . since we omit other window positions , we obtain a lower bound for the probability of a cluster being present .",
    "the detection time of a signal photon , shifted based on the true depth and divided by @xmath2 , is given by a standard normal random variable . denoting the standard normal cdf by @xmath156",
    ", we have the probability of any particular detection landing in the centered window as @xmath157 given @xmath158 signal detections , the probability that exactly @xmath142 of them land in the centered window is @xmath159 \\nonumber \\\\      & = { m \\choose k } ( \\pwind)^k ( 1-\\pwind)^{m - k}.\\end{aligned}\\ ] ] the conditional probability of no signal cluster at @xmath0 is the probability of having fewer than @xmath59 of the @xmath158 detections in the window , which is @xmath160 \\nonumber \\\\      & = \\sum_{k=0}^{\\ncl-1 } { m \\choose k } ( \\pwind)^{k } ( 1-\\pwind)^{m - k}.\\end{aligned}\\ ] ] finally , since @xmath42 is poisson - distributed , the unconditional probability of a signal cluster at @xmath0 is bounded as @xmath161 \\nonumber \\\\      & \\geq \\pr[\\text{cluster in centered window } ] \\nonumber \\\\      & = \\sum_{m=\\ncl}^\\infty \\underbrace{\\pr[m_{i , j } = m]}_{\\operatorname{poisson}(\\nr \\eta \\alpha_{i , j } s ) } \\nonumber \\\\      & \\quad \\cdot \\bigg ( 1- \\underbrace{\\sum_{k=0}^{\\ncl-1 } { m \\choose k } ( \\pwind)^{k } ( 1-\\pwind)^{m - k}}_{\\operatorname{binomial}(m,\\pwind ) \\text { cdf at } \\ncl-1 } \\bigg).\\end{aligned}\\ ] ]",
    "the authors thank dongeek shin for providing code beyond @xcite and several extraordinarily helpful conversations .",
    "computing resources provided by boston university s research computing services are gratefully appreciated .",
    "j.  a. shaw , n.  l. seldomridge , d.  l. dunkle , p.  w. nugent , l.  h. spangler , j.  j. bromenshenk , c.  b. henderson , j.  h. churnside , and j.  j. wilson , `` polarization lidar measurements of honey bees in flight for locating land mines , '' _ opt . express _",
    ", vol .  13 , pp .",
    "58535863 , july 2005 .",
    "s.  pellegrini , g.  s. buller , j.  m. smith , a.  m. wallace , and s.  cova , `` laser - based distance measurement using picosecond resolution time - correlated single - photon counting , '' _ meas .",
    "_ , vol .  11 , pp .  712716",
    ", june 2000 .",
    "a.  colao , a.  kirmani , h.  s. yang , n .- w .",
    "gong , c.  schmandt , and v.  k. goyal , `` mime : compact , low - power 3d gesture sensing for interaction with head - mounted displays , '' in _ proc .",
    "26th acm symp . user interface software & technology ( uist ) _ , ( st .",
    "andrews , uk ) , pp .  227236 , oct .",
    "a.  mccarthy , r.  j. collins , n.  j. krichel , v.  fernndez , a.  m. wallace , and g.  s. buller , `` long - range time - of - flight scanning sensor based on high - speed time - correlated single - photon counting , '' _ appl .",
    "optics _ , vol .",
    "48 , pp .",
    "62416251 , nov .",
    "a.  m. wallace , r.  c.  w. sung , g.  s. buller , r.  d. harkins , r.  e. warburton , and r.  a. lamb , `` detecting and characterising returns in a pulsed ladar system , '' _ iee proc .- vis .",
    "image signal process .",
    "_ , vol .  153 , pp .",
    "160172 , apr .",
    "2006 .",
    "d.  shin , a.  kirmani , v.  k. goyal , and j.  h. shapiro , `` photon - efficient computational 3d and reflectivity imaging with single - photon detectors , '' _ ieee trans .",
    "comput . imaging _ ,",
    "vol .  1 , pp .  112125 , june 2015 .",
    "y.  altmann , x.  ren , a.  mccarthy , g.  s. buller , and s.  mclaughlin , `` lidar waveform - based analysis of depth images constructed using sparse single - photon data , '' _ ieee trans .",
    "image process .",
    "_ , vol .  25 , pp .",
    "19351946 , may 2016 .",
    "d.  shin , f.  xu , d.  venkatraman , r.  lussana , f.  villa , f.  zappa , v.  k. goyal , f.  n.  c. wong , and j.  h. shapiro , `` photon - efficient imaging with a single - photon camera , '' _ nat . commun .",
    "_ , vol .  7 , june 24 , 2016",
    "doi : 10.1038/ncomms12046 .",
    "a.  kirmani , d.  venkatraman , d.  shin , a.  colaco , f.  n.  c. wong , j.  h. shapiro , and v.  k. goyal , `` supporting materials for first - photon imaging . '' http://www.sciencemag.org/content/343/6166/58/suppl/dc1 , 2014 .",
    "r.  achanta , a.  shaji , k.  smith , a.  lucchi , p.  fua , and s.  ssstrunk , `` slic superpixels compared to state - of - the - art superpixel methods , '' _ ieee trans .",
    "_ , vol .",
    "34 , no .  11 , pp .",
    "22742282 , 2012 ."
  ],
  "abstract_text": [
    "<S> conventional lidar systems require hundreds or thousands of photon detections to form accurate depth and reflectivity images . </S>",
    "<S> recent photon - efficient computational imaging methods are remarkably effective with only 1.0 to 3.0 detected photons per pixel , but they are not demonstrated at signal - to - background ratio ( sbr ) below 1.0 because their imaging accuracies degrade significantly in the presence of high background noise . we introduce a new approach to depth and reflectivity estimation that focuses on unmixing contributions from signal and noise sources . at each pixel in an image , short - duration range gates are adaptively determined and applied to remove detections likely to be due to noise . for pixels with too few detections to perform this censoring accurately , we borrow data from neighboring pixels to improve depth estimates , where the neighborhood formation is also adaptive to scene content . algorithm performance is demonstrated on experimental data at varying levels of noise . </S>",
    "<S> results show improved performance of both reflectivity and depth estimates over state - of - the - art methods , especially at low signal - to - background ratios . in particular , accurate imaging is demonstrated with sbr as low as 0.04 . </S>",
    "<S> this validation of a photon - efficient , noise - tolerant method demonstrates the viability of rapid , long - range , and low - power lidar imaging .    </S>",
    "<S> 3-d imaging , computational imaging , depth cameras , lidar , low - light imaging , photon counting , poisson processes , ranging , time - of - flight imaging </S>"
  ]
}