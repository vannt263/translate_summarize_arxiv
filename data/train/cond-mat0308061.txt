{
  "article_text": [
    "in recent years , there is an increasing interest in studying the adaptive behavior of players when they learn to play games together @xcite .",
    "much work focused on learning algorithms computing nash equilibria for players connected by graphs @xcite , or mutually interacting through global functions @xcite .",
    "since these processes are dynamical in nature , it would be interesting to consider how the transient and steady states of the system depend on the choice of initial conditions . when it reaches the steady state , it is possible that the system evolves periodically or even chaotically , or gets trapped in suboptimal attractors .",
    "it is therefore important to study the collective dynamical behavior of multi - agent systems .    in this paper",
    ", we consider the dynamics of a version of large population games which models the collective behavior of players simultaneously and adaptively competing for limited resources .",
    "the game is a variant of the minority game ( mg ) , in which the players making the minority decision are the winners @xcite .",
    "it may be applied to various adaptive systems , such as predators searching for hunting grounds with fewer competitors , network routers trying to find the path with least delay , or traders in a financial market trying to buy stocks at a low price when most other traders are trying to sell ( or vice versa ) .",
    "we are interested in whether the entire system performs efficiently .",
    "for example , if the mg corresponds to the distribution of resources among a network of load balancers , then the system is said to be efficient if the load is uniformly distributed among the players .",
    "similarly , if the mg corresponds to trading agents in a stock market , then the system is said to be efficient if the fractions of winners and losers are the same .",
    "previous work @xcite showed that when the complexity of the players strategies is too high , the players can not collectively explore the strategy space thoroughly , thus limiting the market efficiency . on the other hand ,",
    "when the complexity of the players strategies is too low , the market efficiency suffers from the _ maladaptive _ behavior of the players , meaning that they prematurely rush to adapt to market changes in bursts .",
    "maladpatation is a common but undesirable phenomenon in many adaptive systems .",
    "as will be shown in this paper , the introduction of diversity to the preference of strategies of the players can lead to a better system efficiency .",
    "the minority game ( mg ) involves a population of players repeatedly competing to be in the minority group in an environment of limited resources @xcite .",
    "each of the @xmath0 players can make a decision 1 or 0 at each time step , @xmath0 being odd .",
    "the decisions may represent buy ( 1 ) or sell ( 0 ) if the mg models a market , or the choice of one of two tasks if the mg models a group of load balancers .",
    "each agent makes her decision independently according to her own finite set of `` strategies '' which will be defined later .",
    "after all players have made their choices , players who have made decision 1 are declared winners if there are fewer 1 s than 0 s , and we denote the outcome by 1 ; otherwise , players who have made decision 0 win and the outcome is 0 . the wealth acquired by an individual player",
    "is measured by her real points , which increases ( decreases ) by 1 if she wins ( loses ) at a time step .",
    "the time series of 1 s and 0 s is called `` history '' , and is made available to all players as the only global information for their next choices .    at each time step , the players make their decisions based on the most recent @xmath1 bits in the history , hence @xmath1 is known as the memory size .",
    "there are @xmath2 possible histories , thus @xmath3 is the dimension of the strategy space .",
    "a strategy is then a function which maps each of the @xmath3 histories to decisions 1 or 0 .",
    "before the game starts , each agent randomly picks @xmath4 strategies from the pool of strategies , with repetitions allowed .",
    "each agent holds her strategy set throughout the whole game . at each time step , the players choose , out of the @xmath4 strategies she has , the one which has so far adapted most successfully to the game , and make decisions accordingly .",
    "the success of a strategy is measured by its virtual point , which increases ( decreases ) by 1 if it indicates the winning ( losing ) decision at a time step , irrespective of whether it is chosen at that time step by an agent or not .",
    "the availability of multiple strategies provides an agent with adaptivity , such that she may use an alternative strategy when the one she chooses does not work well .",
    "though we only consider random strategies instead of organized ones , we expect that the model is sufficient to capture the main features of the macroscopic collective behavior of many players with diverse strategies",
    ".    to model diversity among the players , the players may enter the game with diverse preferences of their strategies .",
    "this is done by randomly assigning @xmath5 virtual points to the @xmath4 strategies of each agent before the game starts , @xmath5 being an odd integer .",
    "hence the initial virtual point of each strategy obeys a multinomial distribution with mean @xmath6 and variance @xmath7 .",
    "@xmath5 can thus be considered as a parameter of randomness .",
    "the ratio @xmath8 is referred to as the _ diversity_. furthermore , the game is deterministic for odd @xmath5 and @xmath9 , since in this case no two strategies have the same virtual points throughout the game .",
    "this is in contrast with previous versions of the game , in which the virtual points of all strategies are initialized to zero , corresponding to the special case of @xmath10 .",
    "the homogeneous initial condition leads to the further simplification that the virtual points of a strategy appears the same to all players subsequently .",
    "however , this assumption needs to be re - examined for two reasons .",
    "first , if the mg is used as a model of distributed load balancing , it becomes natural to investigate whether the artificially created maladaptive behavior has prevented an efficient exploration of the phase space , thus hindering the attainment of optimal system efficiency .",
    "second , if the mg is used as a model of financial markets , it is not natural to expect that all agents have the same preference of a strategy at all instants of the game .",
    "let @xmath11 be the population of players making decision 1 at the @xmath12-th time step . to study whether the game distributes resources efficiently",
    ", we first consider the case of small @xmath5 .",
    "as shown in fig .",
    "[ sd](a ) , the variance @xmath13 of the population for decision 1 scales as a function of the _ complexity _",
    "@xmath14 , agreeing with previous observations @xcite . when @xmath15 is small , games with increasing complexity create time series of decreasing fluctuations .",
    "however , the variance does not decrease with @xmath15 monotonically . instead",
    ", there is a minimum around @xmath16 , after which it increases gradually to a so - called coin - toss limit , as if they were making their decisions randomly , with @xmath17 .    the existence of a minimum variance lower than the coin - toss limit shows that the players are able to cooperate to improve the system efficiency , despite the fact that the players are selfish and making independent decisions .",
    "@xmath19 @xcite identified that as the complexity changes across a critical value , the system undergoes a phase transition . in the high complexity phase",
    ", the players can not coordinate to explore the strategy space effectively .",
    "this is because the coordination of the players strategies depends on the availability of information of the population s responses to @xmath3 different strings .",
    "when @xmath20 , the number @xmath21 of strategies possessed by the population is much less than the number @xmath3 of input states of the strategies .",
    "this makes the coordination of players difficult , limiting the market efficiency .    on the other hand ,",
    "the dynamics is highly periodic in the low complexity phase @xcite .",
    "this periodicity is caused by the existence of some players who , on losing the game , switch their strategies in an attempt to win at the next occurence of the same game history .",
    "however , their switch turns out to tip the balance of the strategy distribution , and the previously winning bit ( which used to be the minority bit ) becomes at the next occurence a losing bit ( which newly becomes the majority bit ) .",
    "this switching can go on back and forth indefinitely , resulting in the periodic dynamics .",
    "in other words , the game is undesirably influenced by players who are maladaptive to the environment .",
    "this causes the very large variances of the decisions , which becomes larger than that of random decisions in most of the low complexity phase .",
    "hence we show , on the same figure , the variance for different values of diversity @xmath22 .",
    "it is observed that the variance decreases significantly with diversity in the low complexity phase , although it remains unaffected in the high complexity phase .",
    "furthermore , for a game efficiency prescribed by a given value of variance @xmath13 , the required complexity of the players is much reduced .",
    "figure [ sd](a ) also illustrates the scaling of the variance with respect to complexity and diversity .",
    "when both @xmath1 and @xmath0 vary , we find that the data points collpase together for the same values of @xmath22 and @xmath15 . this means that randomness affects the system behavior in multiples of @xmath0 .    the scaling of the variance with diversity is further confirmed in figure [ sd](b ) for given memory sizes @xmath1 . furthermore , except for the several points with very small @xmath5 ( @xmath23 ) , the variance scales as @xmath24 over a wide range of diversity .    to illustrate the physical picture , we consider the fraction of players switching strategies at low values of @xmath1 . in this case , there are relatively few pairs of possible strategies .",
    "hence when @xmath5 is not too small , the virtual point distribution for a strategy pair can be described by a gaussian distribution with standard deviation scaling as @xmath25 . at each time step , the fraction of players switching strategies is determined by those whose strategies have equal virtual points .",
    "hence this fraction scales as @xmath26 , leading to a variance of @xmath27 .",
    "( the scaling relation deviates at small @xmath5 because the multinomial nature of the virtual point distribution deviates from the gaussian profile at larger @xmath5 . )",
    "qualitatively , with random initial conditions , there is now a diversity of players having different preferences of strategies . at each time step , only those with weak preferences switch strategies .",
    "this greatly reduces the maladaptive behavior and the population variance .",
    "this physical picture is further illustrated by considering the fraction of players who switches their strategies even after the game has reached the steady state .",
    "these _ dynamic players _ hold strategy pairs whose virtual point differences are distributed near zero , and hence should scale as @xmath26 .",
    "this is confirmed in fig .",
    "[ dynamic](a ) .    on the other hand ,",
    "since diversity reduces the fraction of players switching strategies at each time step , it also slows down the convergence to the steady state .",
    "it has been argued that the dynamics of the game proceeds in a direction which reduces the variance @xcite .",
    "since the step size scales as @xmath26 , and the fractional difference of the population with decisions 1 s and 0 s has an initial variance scaling as @xmath28 , the convergence time scales as @xmath29 .",
    "as shown in fig .",
    "[ dynamic](b ) , the dynamics converges almost instantly to the steady state for small @xmath5 . beyond that , the predicted scaling relation holds for various values of @xmath0 over a wide range of diversity .",
    "it is instructive to consider how the distribution of wealth or resources acquired by the players changes with diversity , both at the transient and steady states .",
    "we find that all _ frozen _ players ( that is , players who do not switch their strategies at the steady state ) have constant average wealth at the steady state . hence any differences in their wealth are a consequence of the transient dynamics .",
    "the variance of the wealth distribution should scale as the square of the convergence time , that is , as @xmath22 . as shown in fig .",
    "[ wealth](a ) , this scaling relation indeed holds beyond the region of small @xmath5 where the dynamics converges almost instantly to the steady state .",
    "it is interesting to note the similarities between figs .",
    "[ wealth](a ) and [ dynamic](b ) , demonstrating that they have the same origin .",
    "figure [ wealth](b ) shows the individual wealth acquired per step by the players at the steady state , ranked from left to right in descending order for games with various diversity . for @xmath30 ,",
    "the game is relatively inefficient , since even the most successful players can not break even in their wealth acquisition .",
    "when diversity increases , there is an increasing fraction of players with maximum individual wealth .",
    "it is interesting to note that the individual wealth of the players has a maximum of 0 per step in all cases with nonvanishing diversity , indicating the tendency of the game to distribute resource evenly .",
    "the collective wealth acquired by the game , or the overall resource utilization , is measured by the area under the curve of individual wealth , which again increases with diversity .",
    "we have formulated a theory for the dynamics of the mg at small memory sizes @xmath1 . consider the history of the game denoted by the series @xmath31 .",
    "we describe the state of the game at time @xmath12 by an integer @xmath32 of modulo @xmath3 , where @xmath33 let @xmath34 be the decision of strategy @xmath15 at state @xmath35 . in the following analysis ,",
    "we will write @xmath36 for decisions 1 and 0 respectively . the strategies @xmath15 are labelled from 1 to @xmath37 .",
    "the @xmath3-dimensional phase space of the game is described by the collective decision components @xmath38 where @xmath39 denotes the number of players using strategy @xmath15 at time @xmath12 .",
    "note that one of these states corresponds to the historical state of the game , and is denoted by @xmath40 .",
    "below , we compute @xmath39 for @xmath9 ; generalization to other values of @xmath4 is straightforward .",
    "let @xmath41 be the number of players holding strategies @xmath15 and @xmath42 ( with @xmath43 ) , and the virtual point of strategy @xmath15 is initially displaced by @xmath44 with respect to @xmath42 .",
    "the average of @xmath41 is given by @xmath45 this equation is valid for general values of @xmath5 . in particular , when @xmath5 is not too small , the binomial distribution in eq .",
    "( [ sab ] ) approaches a gaussian distribution with variance @xmath5 , rendering the analysis even more transparent .",
    "the key to analysing the game dynamics with random initial conditions is the observation that the virtual points of all strategies displace by exactly the same amount when the game proceeds , though their initial values may be different .",
    "hence for a given strategy pair , the profile of the virtual point distribution remains binomial , but the peak position shifts with the game dynamics . if the virtual point displacement of strategy @xmath15 is @xmath46 at time @xmath12 , then the players holding strategies @xmath15 and @xmath42 make decisions according to strategy @xmath15 if @xmath47 , and strategy @xmath42 otherwise .",
    "let us consider the change in @xmath48 when state @xmath35 is the historical state .",
    "since the winning state is @xmath49 , the virtual points of strategy @xmath15 shift from @xmath46 to @xmath50 .",
    "changes in the collective decision are only contributed by players with virtual points on the verge of switching signs , that is , @xmath51 , and @xmath52 .",
    "hence we have @xmath53 , \\label{dec}\\end{aligned}\\ ] ] where @xmath54 denotes the kronecka delta . in the region where @xmath55 , we have @xmath56 , and the decision component in eq .",
    "( [ dec ] ) is self - averaging . writing @xmath57 and observing that the magnitude of virtual point displacements are typically much less than the width @xmath25 of the virtual point distribution , so that @xmath58 can be approximated by its value at @xmath59 , we arrive at @xmath60 since @xmath61 , the final result is @xmath62 similarly , one can verify that if @xmath63 is not the historical state at time @xmath12 , then @xmath64 now we can consider the steady state dynamics , which has a period of @xmath65 .",
    "this is consistent with the picture that the dynamics proceeds in the direction which reduces the variance of the decisions , as evident in eq .",
    "( [ hist ] ) .",
    "concretely , the state evolution is given by the integer equation @xmath66 so that every state @xmath35 appears as historical states two times in a steady - state period , with @xmath67 appearing as 0 and 1 , each exactly once .",
    "one occurence brings the decision component @xmath68 from positive to negative , and another bringing it back from negative to positive , thus completing a cycle . due to the maladaptive nature of the dynamics",
    ", the component keeps on oscillating , but never reaches the zero value . for examples , the steady state for @xmath69",
    "is given by the sequence @xmath70 , where one notes that both states 0 and 1 are followed by 0 and 1 once each .",
    "for @xmath71 , there are 2 attractors , described by the sequences @xmath72 and @xmath73 .",
    "again , one notes that each of the states 0 , 1 , 2 , 3 are followed by an even ( @xmath74 ) and an odd state ( @xmath75 ) once each .    as a result",
    ", each state is eventually confined in a @xmath3-dimensional hypercube of size @xmath76 , irrespective of the initial position of the decision components .",
    "this confinement enables us to compute the variance of the decisions .",
    "without loss of generality , let us relabel the time steps in the periodic attractor , with @xmath77 corresponding to the state with @xmath78 and @xmath79 being odd , and let us denote as @xmath80 the step at which state @xmath35 first appears in the relabeled sequence .",
    "( for example , for the first @xmath71 attractor mentioned above , @xmath81 , @xmath82 , @xmath83 and @xmath84 . )",
    "when state @xmath35 first appears in the attractor on or after @xmath77 , its decision component is @xmath85 by virtue of eq .",
    "( [ nhist ] ) , and the winning state is @xmath86 .",
    "when state @xmath35 appears in the attractor the second time , its decision component is @xmath87\\sqrt{2/\\pi r}$ ] from eq .",
    "( [ hist ] ) , and the winning state is @xmath88 .",
    "since the winning state is determined by the minority decision , these impose the conditions @xmath89<0.\\ ] ] suppose the game starts from the initial state @xmath90 , which are gaussian numbers with mean 0 and variance @xmath91 .",
    "they change in steps of size @xmath76 until they reaches the attractor , whose @xmath65 historical states are then given by @xmath92 where @xmath93 represents the decimal part of @xmath94 .",
    "this corresponds to a variance of decisions given by @xmath95 ^ 2\\rangle          = \\frac{1}{2\\pi\\rho}f(\\rho ) , \\label{var}\\ ] ] where @xmath96 is a smooth function of @xmath22 , which approaches @xmath97 for @xmath98 . note that eq .",
    "( [ var ] ) holds for general values of @xmath1 , provided that they are not too large .",
    "this is verified in fig .",
    "[ sd](b ) where the simulation results for @xmath69 and @xmath71 collapse , and agree with the theory .",
    "results for higher values of @xmath1 , to be presented elsewhere , also yield excellent agreement with simulations . for small values of @xmath5 ,",
    "the @xmath65 historical states can be computed similarly , taking into account the multinomial nature of the virtual point distribution , and yield excellent agreement with simulation results .",
    "other parameters , such as the convergence time , the fraction of dynamic players , and the wealth distribution , can be computed from the same physical picture of the game dynamics .",
    "detailed derivations will be presented elsewhere .",
    "we have studied the effects of diversity in the initial preference of strategies on a version of large population games .",
    "we find that it leads to an increase in the system efficiency , and a reduction of the required complexity for a given efficiency .",
    "both theoretical and simulational studies show that scaling relations exist for the dependence of the efficiency on the diversity . the variance of decisions in the low complexity phase decreases , showing that the maladaptive behavior is reduced .",
    "likewise , the resource at the steady state is also more evenly distributed . on the other hand ,",
    "the convergence time increases with diversity .",
    "theoretical studies confirm the physical picture that the game proceeds in steps which tend to reduce the difference between the population of the two decisions , projected along one state at each step .",
    "maladaptation prevents the difference from reducing to zero , overshooting at each step by a step size scaling as @xmath26 , resulting in the periodic attractor at the low complexity phase .",
    "this provides an explanation for the scaling behavior of the variance of decisions and other parameters as a function of the diversity .",
    "the sensitivity of the steady state to the initial conditions has implications to adaptation and learning in games .",
    "when distributive learning algorithms of the reinforcement - learning type are devised , it may be possible that a nash equilibrium can not be reached . in the present example of mg , we find that the dynamic players lose wealth continuously at the steady state , because of their untimely switching between two strategies . in other words , the dynamical rules of virtual point updates",
    "prevent them from adopting the best response in a timely fashion .    hence care",
    "should be taken to avoid maladaptation .",
    "if maladaptation is indeed a problem , it will be useful to limit its effects by introducing diversity among the players , so that the phase space is more efficiently explored . like the present experiment ,",
    "diversity may help us to attain an increased system efficiency with less complex players ."
  ],
  "abstract_text": [
    "<S> we consider a version of large population games whose players compete for resources using strategies with adaptable preferences . </S>",
    "<S> the system efficiency is measured by the variance of the decisions . in the regime where the system can be plagued by the maladaptive behavior of the players </S>",
    "<S> , we find that _ diversity _ among the players improves the system efficiency , though it slows the convergence to the steady state . </S>",
    "<S> diversity causes a mild spread of resources at the transient state , but reduces the uneven distribution of resources in the steady state . </S>"
  ]
}