{
  "article_text": [
    "optimization problems are formulated based on the practical situations in which they occur in .",
    "the resultant model is grossly unfit for processing by classical algorithms in many ways . primarily , there are few simplifying assumptions that can be made .",
    "such algorithms often require the constraints to be eased , which can impact the quality of the solution produced .",
    "in addition , there efficiency depends on the complexity of the objective and scope and structure of the solution space . instead of providing a general solution ,",
    "they offer a specific solution that can be rendered useless by adding a single variable @xcite .",
    "this makes classical algorithms a poor choice for large , non - linear optimization tasks @xcite .",
    "a more fit design paradigm is that of the multipurpose heuristic ( metaheuristics ) algorithm . crafted to be able to solve an entire class of problems ,",
    "metaheuristics are fast , and flexible to be tailored to precise specifications .",
    "these algorithms use iterative refinement and evolutionary methods to improve a solution candidate with regard to a fitness function @xcite .",
    "one particular class of interest is based on swarm intelligence .",
    "swarm intelligence uses the cooperative behavior of animal societies to design algorithms . as in the real world",
    ", this allows a large solution space to be quickly searched , while also providing fault tolerance and parallelism @xcite .",
    "though diverse in their inspiration throughout nature , swarm algorithms depend on individual orientation and a fair division of labor . the ability for individuals to react to external stimuli",
    "also removes the need of processing cycle - consuming central hive - mind .",
    "popular examples of such algorithms include particle swarm ( pso ) , ant colony , artificial bee colony ( abc ) , firefly ( fa ) , and various cellular networks .",
    "these methods have been shown to be superior to previous optimization strategies such as genetic algorithms ( ga ) and simulated annealing ( sa ) .",
    "other swarm strategies based on physical nature ( as opposed to biological nature ) include water droplets , electromagnetism , river dynamics , and musical based metrics @xcite .",
    "in addition to being more accurate , these strategies tend to be easier to implement and more robust .",
    "more recent advancements like particle swarm algorithms also have the added benefit of only using real numbers in computation as opposed to complex mutation functions as in genetic algorithms @xcite .    in this work , the sparkling squid algorithm ( ssa ) will be introduced and its performance investigated when compared with other relevant algorithms . before outlining the sparkling squid algorithm , the particle swarm algorithm will be briefly outlined .",
    "the rest of the paper is organized as follows . in section 2",
    ", the particle swarm algorithm is described , and various applications are introduced . in sections 3 and 4 ,",
    "the sparkling squid algorithm is defined and its behavior studied . in section 5 , it is compared with pertinent algorithms , and evaluated in section 6 .",
    "particle swarm optimization is an optimization paradigm which travels the search space while attempting to optimize an objective function .",
    "it does so by tweaking the motion of individual particles ( agents ) as they traverse the space .",
    "the idea originates from the study of the swarming behavior of fish or birds .",
    "though many variants of pso exist , the idea by eberhart and kennedy ( 1995 ) is discussed below .",
    "as the name suggest , pso is a strategy for finding the values of parameters that give the optimum value of an objective function .",
    "this is critical if one wishes to maximize a certain value , such as profit or yield .",
    "that is :    @xmath0    @xmath1    of course , is one wishes to minimize ( @xmath2 , they can maximize the value of @xmath3 .",
    "the domain @xmath4of @xmath5z represents the search ( parameter ) space .",
    "every element is a possible o , and so is referred to as a candidate solution .",
    "the dimension of this space is equivalent to the number of variables , eq , while the fitness space of the fitness function has only a single dimension@xcite .",
    "this problem is trivial to solve if we are sure of the function @xmath5 .",
    "however , in optimization tasks , the objective function within a `` black - box '' , which prevents the methods of calculus from being applicable .",
    "one also may have to content with constrained optimization tasks where additional constraints such as positivity or primality are enforced@xcite .",
    "the simplest example of an optimization task can be seen below in figure 1 .",
    "the relevant interval of a function f is shown . this function maps the candidate solutions on the x - axis , to the result of the objective function on the y - axis . in general , this fitness landscape shows the one - dimensional parameter space versus the one - dimensional fitness value .",
    "in addition , there is the presence of a local maximum , the maximum if we restrict the domain of candidate solutions , and a separate global maximum .",
    "many variants of the pso algorithm exist to find such local maximum ; the pso described here , is designed to find the global maximum@xcite .",
    "pso searches through the fitness landscape by having particles known as agents fly , while attempting to find the optimal value .",
    "each particle is randomly instantiated , and evaluated at each stage by the objective function .",
    "thus , the particles represent candidate solutions .",
    "as previously stated , the pso algorithm runs within a `` black - box '' , and so all iterative refinements are based on the particles , with no awareness of the presence of abnormalities in the objective function@xcite .    as shown above ( figure 1 )",
    ", particles are created as candidate solutions on the fitness landscape .",
    "each particle ( @xmath6 ) is aware of its position ( @xmath7 ) , velocity ( @xmath8 ) , and the best position it has previously reached .",
    "its position is comprised of both the candidate solution and its related fitness .",
    "the best position it previously reached is comprised of its individual best candidate and its individual best fitness .",
    "similarly , the swarm as a single entity maintains its global best comprised of its global best candidate and its global best fitness@xcite .",
    "the pso algorithm itself functions quite similarly to a parallel iterative refinement method .",
    "it repeats three steps until its stopping condition ( e.g. @xmath9 ) .    1 .",
    "evaluate current finesses 2 .",
    "update individual ( and global ) best positions 3 .",
    "update velocity and position for all agents    steps one and two have been covered above , with fitness being evaluated by evaluating the objective function with the candidate solution as an argument .",
    "similarly , best fitness positions are updates by comparing the current best with the current evaluation for all individual particles and the swarm",
    ". however , these steps are identical to those of a complete search of the entire fitness landscape .",
    "the third step gives particles a position and velocity based on the swarm s intelligence@xcite .",
    "the velocity update formula can be subdivided into three independent parts .",
    "first , the formula for the velocity at time @xmath10 must take the previous velocity ( at time @xmath11 ) into account .",
    "however , this velocity is subject to change due to the particle s natural inertia .",
    "so , the first component of the formula is @xmath12 , where w is a user supplied coefficient ( generally @xmath13 ) .",
    "this inertial component forces the particle to continue travelling in the direction that it previously was .",
    "the exact value of @xmath14 allows the particle to experience acceleration or deceleration .",
    "acceleration makes the swarm more likely to search a larger position of the fitness landscape , while deceleration usually makes the stopping condition be met sooner@xcite .",
    "the second term allows the particle to remember which areas of the fitness landscape have given more fruitful results .",
    "this cognitive component , @xmath15 $ ] , is comprised of the cognitive coefficient @xmath16 ( generally @xmath17 ) and is related to the particle s affinity to move towards its individual best position ( @xmath18 ) . the third term , the social component takes the same form as the cognitive component , replacing the individual best position @xmath19with the global best position,@xmath20 , and the cognitive coefficient with a social coefficient ( @xmath21 ) .",
    "the resulting term , @xmath22 $ ] , , is related to the particle s affinity to move towards the current global best position .",
    "both terms represent the magnitude of the step that should be taken in a particular direction@xcite .",
    "the values @xmath16 and @xmath23 represent random coefficients in the cognitive and social components .",
    "these provide a stochastic nature to the velocity which makes particles move in a pseudo - random way that is constrained by the previous best solutions ( individual and global)@xcite .    a velocity clamp way be applied to prevent any particles from leaving the desired search space .",
    "for a search space bounded by @xmath24 $ ] , the velocity clamp can be represented as @xmath25 $ ] , where @xmath26 is a user - supplied parameter around@xcite .",
    "the position of a particle is given in terms of its previous position and the velocity by :    @xmath27    @xmath28++c_2r_2[g(t)-x_i\\left(t\\right)]\\ ] ]      as previously stated , this process is repeated indefinitely till a stopping condition is met .",
    "differences in the stopping condition has led to some variation among the various implementations of the pso .",
    "other modifications include the inertial weight , which was not included in the velocity update , but has since become a standard component of the pso .",
    "other variations divide the swarm into separate populations , include an evolutionary ranking component , and stretching the objective function@xcite .",
    "_ watasenia scintillans _ , or the sparkling squid is a small squid that lives around 1,200 feet deep in the western pacific ocean .",
    "the sparkling squid is one of the brightest of all the bioluminescent creatures of the sea .",
    "every year during summer , japan s shores are greeted to the amazing sight of the water glowing blue as millions of sparkling squid mate .",
    "each squid has photophores across its body to attract other members of its species , and photophores on its tentacles and eyes to attract prey .",
    "it is also able to use its photophores across its body for counter - illumination in an impressive form of camouflage .    the exact behavior and patterns of illumination of the sparkling squid remain unknown .",
    "in order to create a useful model that uses squid behavior , the ambiguity of the behavior of real squid has to be removed . to do so",
    ", we have divided the squid population into two sub - populations , a primary population and a secondary population .",
    "the primary population primarily moves on mutual attraction , while the secondary pursues unseen prey in a herd .",
    "the primary population operates on two basic assumptions :    1 .",
    "all squid are genderless ; a less attractive squid will move toward a more attractive squid .",
    "the most attractive squid will move randomly .",
    "the attractiveness of a squid is based on its brightness .",
    "the brightness of a squid is derived from its location on the fitness landscape .",
    "similarly , the secondary population is modeled by two simple assumptions :    1 .",
    "the secondary population pursues unseen prey .",
    "the prey are more heavily populated in more fit areas of the fitness landscape .",
    "2 .   each individual squid seeks to improve its location by following the leader , and two random neighbors .",
    "communication between members of the swarm may be imperfect .    using these characteristics ,",
    "we have developed a stricter set of rules to model the sparkling squid population .",
    "we then use those rules to formulate an algorithmic procedure .",
    "we known that light intensity follows an inverse - square law with distance .",
    "impurities in the water ( and the water itself ) cause the intensity of the light to decrease with distance . as stated previously , the brightness of the squid can be derived from the squid s location on the fitness landscape .    under our model for the squid s behavior ,",
    "only two factors have to be accounted for , the relation between attractiveness and intensity , and the change in light intensity as a function of distance .",
    "the second one of these two problems is much easier to solve as it requires a purely physical answer .",
    "we say that the distance between squid @xmath29 and @xmath30 is @xmath31 , and model the intensity in two parts .",
    "firstly , we use an inverse - square law to represent the change in intensity with distance : @xmath32 .",
    "the second part is the absorption of light in imperfect conditions , like the presence of water , impurities and murkiness .",
    "assuming an absorption coefficient of @xmath33 , gives @xmath34 .",
    "these two models can be combined , assuming an original light intensity of @xmath35 .",
    "@xmath36    this model also removes the singularity at @xmath37 .",
    "we chose to use a rational approximation over the gaussian model to expedite computation .",
    "finally , as the intensity of light decreases asymptotically , it is no longer noticeable by the squid .",
    "we use a piecewise function to make a fixed distinction between little light and no light .",
    "@xmath38 the length scale @xmath39 is proportional to our choice of @xmath33 .",
    "algorithmically , this separation speeds up the computation by ignoring extremely unfit solutions .",
    "while fine - tuning the length scale leads to better results , we use @xmath40 .",
    "the squid population is modeled in two parts , a primary population and a secondary population .",
    "the primary population is more fit , and therefore more attractive .",
    "these are the squid that are able to significantly influence the movement of other squid .",
    "the less - fit squid would be pushed and pulled around , without significantly influencing the movement of other squid .",
    "therefore , we create a secondary squid population with those squid .",
    "the population division is dynamic , and is updated after every generation .",
    "we form the populations by ordering all squid @xmath41 by @xmath42 . then",
    ", the primary population is @xmath43 .",
    "similarly , the secondary population is @xmath44.by dividing the populations in this way , we allow the primary swarm to function as a scout , explore the fitness landscape , while the secondary swarm provides leverage against local extrema , randomness and other abnormalities",
    ". it also reduces the runtime by a constant - factor of @xmath45 .",
    "it is also worth noting that squid change population constantly .",
    "the least - fit squid in the primary swarm will most likely play the role of the leader in the secondary swarm , while the leader of the secondary swarm will be toyed with in the primary swarm .",
    "this communication allows the two separate swarms to function as a single unit . on a parallel machine ,",
    "the population may be further subdivided to trade accuracy for speed .",
    "we have chosen to make @xmath46 , and @xmath47 .",
    "this means that for a given position vector @xmath48 , @xmath49 . by stacking all of our constants into @xmath50 gives an attraction of :    @xmath51    algorithmically , we remove the position vector @xmath48 in favor of a pointer to the @xmath29-th squid .",
    "the attractiveness of squid @xmath29 is @xmath50 gives an attraction of :    @xmath52    theoretically , @xmath33 can hold any value that suits the test problem ; we choose assign a standardized value to @xmath33 that depends on @xmath53 , the average size of the search space in each dimension and @xmath54 , the average attractiveness at @xmath37 .",
    "@xmath55    each squid is modeled a random @xmath56-dimensional position vector .",
    "based on the fitness of the function , the squid has a derived attractiveness from its position .",
    "the primary squid population then evolves without interference .",
    "however , the population is prone to finding local optima and getting stuck at nonoptimal locations .",
    "therefore , we have included a random factor movement factor .",
    "the most attractive squid s movement are entirely governed by this factor .",
    "the random update term is based on a the simple idea of randomly moving the squid in either direction up to @xmath57 units in every dimension .",
    "this is represented as :    @xmath58\\ ] ]    as solution quality improves , the random effects should decrease .",
    "this is accomplished by a randomness - reduction factor , @xmath59 .",
    "@xmath60,\\delta \\in ( 0,1]\\ ] ]    the lower the value of @xmath61 , the faster the reduction , while a value of @xmath62 represents no reduction .",
    "the random value is generated according to the @xmath63 , the arcsine distribution .",
    "the secondary generation is far less individualized .",
    "each squid looks toward the best squid , and two of its randomly chosen colleagues to choose a new position to move to .",
    "its own position is only considered if the current squid is in the best position .",
    "computationally , squid that are updated earlier are also considered in the update of later squid . at every stage , two distinct random squid ( @xmath64and @xmath65 )",
    "are chosen .",
    "the next generation population is then created as :    @xmath66    @xmath63 , is a mutation factor in the range @xmath67 $ ] .",
    "we can also add a requirement for the new position of the squid to be better than the previous one for it to move .",
    "it is worth noting by centering the new swarm around the previous best , a non - zero number of squid are expected to switch swarms .",
    "this helps lagging squid in the primary swarm escape local optima , and squid in the secondary swarm explore more parts of the fitness landscape .",
    "based on our assumptions and model , we can now outline the basic sparkling squid algorithm .",
    "note that in implementation , distances ( @xmath31 ) can be calculated using any metric in @xmath56 - dimensions .",
    "we choose to use the @xmath68 norm , or euclidean norm .",
    "it might also be interesting to use other norms , such as the frobenius norm , or hilbert - schmidt norm in certain applications .",
    "initial solution to a @xmath56 - dimensional problem : @xmath69 create initial squid population : @xmath70 evaluate fitness of squid population : @xmath71 @xmath72 sort @xmath70 by @xmath73 @xmath74 @xmath75 calculate distance and attraction update position and position - based values update position @xmath76 @xmath77 current best solution @xmath78",
    "we have used a set of @xmath79 standard functions for the purpose of validation @xcite .",
    "beale s function , easom s fucntion and michalewicz s function are all standard functions for the purpose of validating and comparing new algorithms .",
    "the beale function    @xmath80    has @xmath81 at @xmath82 .",
    "easom s function    @xmath83    has @xmath84 at @xmath85 .",
    "finally , michalewicz s function    @xmath86    for @xmath87 has @xmath88 . in all three cases ,",
    "the ssa found the global minimum to within @xmath89 within 90 seconds .",
    "this was true in over @xmath90 trials .",
    "in the case of the beale function , the ssa was able to escape the four sharp peaks around the corners within ( approx . )",
    "@xmath91 evaluations , and the the valley ridges within ( approx . )",
    "@xmath92 evaluations .",
    "when tested with the easom function , the ssa spent ( approx . )",
    "@xmath93 evaluations in various ridges , before finding the global minima in ( approx . )",
    "@xmath94 evaluations . finally , on the michaelwicz function",
    ", the ssa spent ( approx . ) @xmath95 evaluations going between the various local minima , and hill climbing . finally , after ( approx .",
    ") @xmath96 evaluations it found the global minima .    across all @xmath79 benchmark functions ,",
    "the ssa was able to find the global minima in time comparable to the psa and ga .",
    "given additional evaluations , the solution quality increases negligibly .",
    "we have chosen a set of eight common benchmark function to evaluate the performance of ssa against other common evolutionary algorithms@xcite . due to the existence of countless modifications and improvements to the particle swarm and genetic algorithms ,",
    "we have implemented them in their original forms . for pso",
    ", we use the standard implementation of kennedy and eberhart , with @xmath97 , and a constant inertial term of @xmath98.for ga , we ignore the effects of elitism , use a mutation probability @xmath99 and a crossover probability of @xmath100@xcite .",
    "there are many valid ways of running such a comparision test ; we have opted to run each algorithm @xmath90 times per function and report and best , worst , mean and standard deviation of the global minima reported . in the interest of fairness ,",
    "each algorithm was given @xmath101 seconds to run .",
    "in addition , comparable population sizes , etc . were used across all three algorithms .",
    "previous analysis of the ssa , pso and ga were used to define optimal parameters under the testing conditions@xcite .",
    "simulations were completed using matlab , with the code for pso and ga taken directly from their source paper .",
    "all tests were completed on an intel i7 - 2670qm with 2.2ghz per each of 4 cores .",
    "tests were completed with constant minimal background and system processes .",
    "the data is presented in tables following a brief description of the trial function , followed by results .",
    "the objective function for the first test problem is the ackley function .",
    "this problem is given as :    @xmath102    it has @xmath81 at @xmath103 .",
    ".comparison among pso , ga and ssa on ackley s function(@xmath104 ) [ cols=\"^,^,^,^,^,^,^ \" , ]     [ table : final ]    after all @xmath105 tests ,",
    "we have taken the model of the behavior of the sparkling squid and successfully formulated a new sparkling squid algorithm ( ssa ) from it . from initial testing and benchmark evaluations",
    ", we have seen that it is a powerful and promising algorithm .",
    "more specifically , we found that the ssa is able to outperform both pso and ga at optimizing various functions .",
    "this makes it probable that the ssa will be useful in solving np - hard problems , a topic for further investigation .",
    "in addition , looking at the convergence behaviour of the ssa shows that it is able to escape from local optima quite well .    although quite efficient the ssa is not specifically tailored to any problem .",
    "one possible modification would be the addition of an adaptive control parameter .",
    "secondly , various methods of providing direction to the squid could improve overall performance . more simply , fine - tuning of the various parameters ( @xmath106 , etc . )",
    "can improve overall performance .",
    "it might also be interesting to apply the ssa to various np - hard problems , such as the traveling salesman problem .",
    "lastly , the combination of the ssa with existing optimization paradigms such as the pso and ga may prove fruitful .",
    "b.  jia , q. p. y.  w. , j.  li and xie , s. a hybrid particle swarm optimization and tabu search algorithm for flexible job - shop scheduling problem .",
    "_ international journal of computer theory and engineering_."
  ],
  "abstract_text": [
    "<S> the swarm intelligence of animals is a natural paradigm to apply to optimization problems . </S>",
    "<S> ant colony , bee colony , firefly and bat algorithms are amongst those that have been demonstrated to efficiently to optimize complex constraints . </S>",
    "<S> this paper proposes the new sparkling squid algorithm ( ssa ) for multimodal optimization , inspired by the intelligent swarm behavior of its namesake . </S>",
    "<S> after an introduction , formulation and discussion of its implementation , it will be compared to other popular metaheuristics . finally , applications to well - known problems such as image registration and the traveling salesperson problem will be discussed .    </S>",
    "<S> * multimodal optimization by sparkling squid populations * + videh seksaria + lexington high school + department of computer science + 01vssv10@gmail.com    [ [ key - words . ] ] key words .    </S>",
    "<S> heuristics , multimodal optimization , np problems , particle swarm , genetic algorithm . </S>"
  ]
}