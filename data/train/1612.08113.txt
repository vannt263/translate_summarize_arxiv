{
  "article_text": [
    "applied to a wide range of fields such as biology , medical sciences , communications , and insurance , the negative binomial distribution ( nbd ) has proven to be one of the most useful discrete distributions . as a result of its frequent application , an increasing number of papers on parameter estimation have appeared , and continue to appear , in literature ( fisher , 1941 and 1953 ; gurland , 1959 ; johnson and kotz , 1969 ; clark and perry 1989 ; chow , 1990 ; shishebor and towhidi , 2003 ; famoye , 2011 , among others ) .    in this article , we contribute further to this development by showing how to build an accurate confidence region for the unknown parameters of nbd . a frequently used method for parameter estimation",
    "has been the method of moments . as such , our confidence region",
    "will be constructed based on this approach .",
    "there have been several choices of parameterization ; in the field of biology some have focused their attention on the dispersion parameter @xmath0 , and @xmath1 ; while others have used the reciprocal of @xmath0 .",
    "we use the expected value @xmath2 ( location parameter ) and shape parameter @xmath3 motivated by johnson ( johnson et al . , p.131 ) .",
    "the nbd can be defined in two ways : the first version of the negative binomial distribution , first formulated by montmort in 1714 , is an extension of the geometric distribution , where @xmath4 counts the number of _ trials _ until ( and including ) the @xmath5 success . in this version ,",
    "@xmath6 here @xmath7 is a positive integer ; @xmath8 and @xmath9 .    the second version , which we consider for the purpose of this paper , counts the number of _ failures _ before achieving the @xmath5 success . in this version ,",
    "@xmath10    this version allows us to extend the definition of the negative binomial distribution to a positive _ real _",
    "parameter @xmath11 ( which was called @xmath7 in the previous distribution)@xmath12 although it is impossible to visualize a non - integer number of `` successes '' , we can still formally define the distribution through its probability mass function .",
    "this form for dealing with nbd which has been used by our predecessors , will be inconvenient to manipulate in the manner desired for this paper ; so , instead of using @xmath13 in its current form , we use the following parametrization @xmath14where as already mentioned in the introduction , @xmath15 the symbolic notation we use for this version will be @xmath16 .    the mean and the variance of @xmath4 are : @xmath17 and @xmath18thus , the variance is always larger than the mean for the nbd .",
    "this property is at times referred to as _ over - dispersion_.    note that the poisson distribution is a limiting case of the @xmath19 when @xmath20 while keeping @xmath21 fixed .",
    "the probability mass function of the poisson distribution is , @xmath22=\\frac{\\mu ^{i}}{i!}e^{-\\mu } ~\\text { where } ~i=0,1,2,\\ldots \\label{8}\\ ] ]    the pgf ( probability generating function ) of the negative binomial distribution is given by : @xmath23 as @xmath24 , then the limit of is @xmath25 which we recognize as the poisson pgf .",
    "an efficient method for estimating the parameters of most distributions is a procedure known as the maximum likelihood .",
    "it is well known that maximum likelihood estimators ( mles ) are preferred over method of moment estimators ( mmes ) in the case of the nbd . however , when it comes to constructing confidence regions , mles , are rather difficult to deal with because they lead to a complicated function for which we do not have an analytic expected value .",
    "@xmath26 where @xmath27 is the digamma function ,  defined by:@xmath28 using mles then requires performing a non - trivial numerical procedure for computation of this expected value . for this reason , we have decided to go with mmes instead , and the choice is justified by our results . moreover , from a practical point of view , our method is simple and can be applied easily by anyone in the field of statistics .",
    "investigating mles however , gave us a guideline as to how to deal with mmes when faced with the condition of @xmath29 .",
    "where @xmath30 unlike the mme which gives us a non - sensical answer ( i.e. @xmath31 ) , the mle technique tells us that we have reached the poisson limit .",
    "being guided by the mles then , we take @xmath31 to be an indication that we have to switch to poisson distribution , and set @xmath32 .",
    "one of the most straightforward methods for estimating parameters of the negative binomial and other distributions is equating the first few sample moments to the corresponding theoretical moments , and solving the resulting equations for the unknown parameters .",
    "this is known as the method of moments ( mme ) .",
    "the number of moments used is the same as the number of unknown parameters .    in the case of the negative binomial distribution",
    "@xmath33[2]@xmath34 the equations for the first two moments are @xmath35 where @xmath36 , and @xmath37 are the sample mean and sample variance , respectively .",
    "the mme estimators of @xmath21 and @xmath38 are then equal to : @xmath39 and @xmath40    from we see that we end up with a negative estimate @xmath41 whenever we are faced with a sample which has @xmath42 . this again implies the distribution is poisson . to investigate the probability of this happening , we have utilized a monte carlo simulation .",
    "@xmath43    we are quoting only the digits that are reliable .",
    "a look at the above tables reveals , as expected , a high percentage of occurrences of @xmath42 when both parameters are small , while the percentage of @xmath42 begins to decrease as @xmath2 and @xmath38 get larger .  if @xmath38 @xmath44is much smaller than @xmath2 , then @xmath45 ; so , it is likely in this case to obtain samples with @xmath46    now that we have our estimators , we want to present them in the form of a confidence region , which gives us a better idea of what the actual parameters can be .",
    "since we do not have the exact joint distribution of @xmath21 and @xmath38 , we have to use the central limit theorem .",
    "the central limit theorem applies to all parameters based on sample _ means_. upon analyzing our @xmath47 and @xmath41 distribution , we discovered that , for relatively small @xmath48 ( i.e. @xmath49 ) , their behaviour was far from a perfect bivariate normal distribution .",
    "see figure [ 534a ] and [ 534b ] .",
    "we found that transforming our parameters to @xmath50 and @xmath51 achieved a significant improvement towards normality and thus made our @xmath52 more accurate .",
    "see figure [ 534a ] .",
    "the corresponding method - of - moment estimators of ln@xmath53 and @xmath54 are @xmath55 and @xmath56 respectively .",
    "to construct cr for @xmath2 and @xmath38 , we need to know the first few moments of the _ sampling distribution _ of two estimators , and , namely the two means , two variances and covariance . we know that the expected value of any function of sample means can always be expanded , starting with the corresponding expected values .",
    "thus , to a sufficient approximation ( ignoring the @xmath57  proportional correction ) @xmath58 and @xmath59 .",
    "what is left now is to find the formulas for the two variances and covariance . to do that , we need to expand the two estimators at their respective means , up to the linear terms in @xmath36 and @xmath60 , thus : @xmath61 and @xmath62 where @xmath63 .    replacing @xmath64 by @xmath65 in yields the following mgf : @xmath66 which we expand to compute the first four simple moments of a single @xmath4:@xmath67    remembering that @xmath68 is simply equal to @xmath69 and similarly @xmath70 , and @xmath71 , we get :    @xmath72 } { n }   \\nonumber \\\\",
    "\\operatorname{cov } ( { \\overline{x}},\\ , { \\overline{x}}^2 ) & = \\frac{{{\\rm e}}(x^{3})-\\mu { { \\rm e}}(x^2 ) } { n}=\\frac{\\mu ( 1+p ) ( 1 + 2\\mu+2p ) } { n } .",
    "\\nonumber\\end{aligned}\\ ] ]    the variances and covariance of our estimators can now be easily computed using , , and : @xmath73",
    "before discussing how to construct @xmath52 , we would like to make a more general statement about any two estimators which we are now going to call @xmath74 and @xmath75 . in the context of our discussion @xmath76 and @xmath77 . recall that any general @xmath78 can be standardized by :    @xmath79    and@xmath80    the corresponding joint ( bivariate ) pdf is given by : @xmath81where @xmath82 , @xmath83 , @xmath84 , @xmath85 are the means and variances of @xmath74 and @xmath75 respectively , and @xmath86 is their correlation coefficient .",
    "finding a contour of still proves to be rather difficult , because of the correlation coefficient .  to simplify matters we first transform @xmath74 and @xmath75 further to make them uncorrelated .",
    "this can be achieved by    1 .   leaving the @xmath74 unchanged , then 2 .",
    "we subtract a linear term @xmath87 from @xmath75    which yields : @xmath88 in our case @xmath89 implying that @xmath90 this equals to @xmath91 , which is the variance of .",
    "we define @xmath92 the same way as @xmath93 but now @xmath94 changes to @xmath95 this yields the desired pdf for building @xmath52 namely @xmath96 with the corresponding contour plot given in figure [ 540 ] .    constructing a @xmath97 joint confidence region for any @xmath98 and",
    "@xmath99 now amounts to solving @xmath100or simply @xmath101 so that @xmath102 this yields @xmath103    switching to polar coordinates , and solving for @xmath104 amounts to solving @xmath105 , thus : @xmath106 implying .    in the context of our distribution , the @xmath52",
    "is given by:@xmath107 ^2}{\\frac{1+p}{n\\mu } } + \\frac{\\left [ \\ln ( { \\widehat{p}}+1 ) -\\ln ( p+1 ) -\\frac{p}{1+p } ( \\ln ( { \\widehat{\\mu } } ) -\\ln ( \\mu ) ) \\right ] ^2}{\\frac{2 ( \\mu + p ) } { n\\mu } } \\leq -2\\ln ( \\delta ) \\label{40}\\ ] ] where @xmath48 , @xmath108 , @xmath109 , and @xmath110 must be replaced by their numerical values : @xmath111 specifies the desired level of confidence .",
    "consider a computer generated random independent sample of size @xmath112 from the nbd with @xmath113 and @xmath114 ( assumed unknown and to be estimated ) , namely @xmath115 computing @xmath116 and @xmath117 allows us evaluate the mme expressions of and , getting @xmath118 to find ( say ) a @xmath119 @xmath120 and @xmath121 confidence regions for @xmath21 and @xmath38 , one needs to solve for each @xmath108 .",
    "evaluating with the estimates found in , we get @xmath122 ^2}{\\frac{1+p}{50\\mu } } + \\frac{\\left [ \\ln ( 1.906 ) -\\ln ( p+1 ) -\\frac{p}{1+p } ( \\ln ( 0.960 ) -\\ln ( \\mu ) ) \\right ] ^2}{\\frac{2 ( \\mu + p ) } { 50\\mu } }   \\leq -2\\ln ( \\delta ) .",
    "\\label{51}\\ ] ]    even though is a non - linear equation in terms of @xmath21 and @xmath38 , plotting the actual contours is fairly simple with the help of a computer .",
    "thus , for a @xmath121 , @xmath123 , and @xmath124 confidence level , we figure [ 542 ] .",
    "we find that all our confidence regions contain the `` true '' values used in our simulation .",
    "we investigate the accuracy of this method in the following section .",
    "impressively , our method works even in the @xmath42 situation .",
    "suppose now that our generated random sample of size 50 is drawn from a nbd with @xmath125 and @xmath126 , and consists of:@xmath127    we once again compute @xmath128 and @xmath129 which allows us to find the mme using and @xmath130    clearly @xmath38 can not be negative .",
    "however , when the nbd distribution is close to the poisson limit , the mme estimate may easily become negative , unlike the mle estimate which becomes zero . even though we have a nonsensical estimate in @xmath41",
    ", we can still build an accurate confidence region using the same formulas . solving with the same @xmath108 as the previous example",
    ", we get the contour plot of figure [ 545 ] .    as seen in figure [ 545 ] , there is a strong indication that the distribution is poisson .",
    "however , there is also the possibility that it is not .",
    "the region under the @xmath21- axis is what we consider to imply poisson .",
    "conversely , the region above is negative binomial . in the mle case ,",
    "the negative region is never observed ; the entire non - physical region is clasped on the @xmath21-axis . using this ` hint '",
    ", we can present the same results in a new , more meaningful form of figure [ 546 ] .",
    "in order to compare how well our approximation matches the respective confidence levels , we generate a large collection of random independent samples ( say @xmath131 ) from the nbd , using a specific choice of @xmath21 and @xmath38 , and establish , for each of these samples , the percentage of the corresponding confidence regions which cover the two values @xmath21 and @xmath38 . when done correctly",
    ", the probability of this happening should be close to the chosen significant level .",
    "we then repeat this for as many different choices of @xmath21 and @xmath38 as feasible .",
    "@xmath132    .monte carlo verification [ cols=\"<,<,<,<,<\",options=\"header \" , ]     @xmath132    as a result , we can observe a reasonably close match between the desired and actually achieved value of @xmath133 .",
    "we have demonstrated how to find confidence regions for unknown parameters of the negative binomial distribution .",
    "uniquely , the method described in this article works even in the case of over - dispersed samples ( i.e. @xmath42 ) . in this case",
    ", we find that our confidence region split into two regions , one corresponding to the poisson and the other to negative binomial distribution .",
    "one could now consider the edgeworth expansion ( improving over normal approximation ) , but , considering how good the results were in table 2 , and also the extra difficulties one runs into when lowering the sample size , it is something we saw as a direction of decreasing marginal returns .",
    "we are , however , looking forward to contrasting our results with a future paper in which we will show how to build confidence regions for unknown parameters of the nbd using the mle method ."
  ],
  "abstract_text": [
    "<S> we describe a general method for the construction of a confidence region for the two parameters of the negative binomial distribution . this is achieved by expanding the sampling distribution of method - of - moments estimators , using the central limit theorem . </S>"
  ]
}