{
  "article_text": [
    "detection aims at highlighting salient foreground objects automatically from the background , and has received increasing attentions for many computer vision and graphics applications such as object recognition  @xcite , content - aware image retargeting  @xcite , video compression  @xcite and image classification  @xcite . driven by these recent applications ,",
    "saliency detection has also evolved to aim at assigning pixel - accurate saliency values , going far beyond its early goal of mimicing human eye fixation . due to",
    "lacking of a rigorous definition of saliency itself , inferring the ( pixel - accurate ) saliency assignment for diversified natural images without any user intervention is a highly ill - posed problem . to tackle this problem ,",
    "a myriad of computational models  @xcite have been proposed using various principles or priors ranging from high - level biological vision  @xcite to low - level image properties  @xcite .",
    "focusing on bottom - up , low - level saliency computation models in this paper , we identify several remaining issues to be addressed though existing models have demonstrated impressive results .    how to uniformly highlight the salient objects .",
    "natural images usually contain diverse patterns ( i.e. rich appearances ) so that the saliency computed through the bottom - up feature extraction could be discrete or incomplete without regard to salient objects .",
    "like other low - level vision tasks ( e.g. , image segmentation ) , most existing saliency models were built upon color information only , and they may degenerate when similar colors distribute on both foreground and background objects , e.g. , fig .  [",
    "fig : fig1](fourth row : f - h ) .",
    "moreover , these approaches  @xcite may render some elements inside a salient object as non - salient or some elements of the background as salient , due to their shortcoming on handling inhomogeneous structures in foreground ( e.g. , fig .",
    "[ fig : fig1](third row : e - h ) ) and background ( e.g. , fig .  [",
    "fig : fig1](second row : e - h ) ) .    how to make the saliency values coherent with image content .",
    "several saliency detection approaches demonstrated impressive results on generating pixelwise saliency maps  @xcite .",
    "they usually assign the saliency values based on the over - segmentation of images ( i.e. small regions or superpixels ) , and further exploit the post - relaxation ( e.g. local filtering ) to smooth the saliency values over pixels .",
    "however , the image segmentation may introduce errors in processing complex image content ( e.g. , local cluttered textures ) , upon which the incompatibility with saliency values and object details could be caused by the post - relaxation step .",
    "these phenomenons are exhibited with the examples in fig .",
    "[ fig : fig1](first row : g - h ) .",
    "[ fig : original1 ] [ fig : color1 ] [ fig : gradient1 ] [ fig : pisa1 ] [ fig : ca1 ] [ fig : hc1 ] [ fig : rc1 ] [ fig : sf1 ]    inspired by the insights and lessons from a significant amount of previous work as well as several priors supported by psychological evidences and observations of natural images , we address these above mentioned challenges in a more holistic manner .",
    "in particular , we propose a unified framework called pisa , which stands for pixelwise image saliency aggregating complementary saliency cues .",
    "it enables to generate spatially coherent yet detail - preserving , pixel - accurate and fine - grained image saliency . in the following ,",
    "we briefly discuss the motivations and main components of pisa .    _",
    "i ) complementary appearance features for measuring saliency . _",
    "though color information is a popular saliency cue used dominantly in many methods  @xcite , other influential factors do exist , which can also be used to make salient pixels or regions outstanding , even these pixels or regions are not unique or rare by color information .",
    "for instance , they can have unique appearance features in edge / texture patterns  @xcite , demonstrating distinct contrast expressed by structure information . in fact , color and structure can be complementary to each other to provide more informative evidences for extracting complete salient objects .",
    "in addition , it is known from the perceptual research  @xcite that different local receptive fields are associated with different kinds of visual stimuli , so local analysis regions where saliency cues are extracted should be adapted to match specific image attributes .    instead of using color only treatment , pisa directly performs saliency modeling for each individual pixel on two complementary cues ( i.e. color and structure features ) and makes use of densely overlapping , feature - adaptive observations for saliency confidence computation .",
    "[ fig : fig1 ] shows a few motivating examples that highlight the advantage of our pisa method , compared with some leading methods  @xcite .    _",
    "ii ) non - parametric feature modeling in a global context .",
    "_ existing saliency detection approaches usually group image pixels based on local small regions or superpixels  @xcite , which could give rise to less informative saliency measures . in contrast , using non - local approaches to summarize the extracted features  @xcite tends to be more robust and reasonable than those of local homogeneous superpixel - based methods , and its advantage has been demonstrated in recent works  @xcite .    rather than using superpixel - based representations , we propose to compute the saliency confidence by considering both the global appearance contrast in the feature space as well as the image domain smoothness . specifically , we first group all image pixels by summarizing their extracted features ( i.e. either the color or structure histograms ) , and model the saliency confidence according to the global rarity ( i.e. uniqueness ) of the pixel group in the color / structure feature space .",
    "meanwhile , we further impose the spatial priors , including the center preference and boundary exclusion in the image domain to complete the saliency modeling for each pixel .",
    "_ iii ) fine - grained saliency assignment .",
    "_ many high level tasks prefer generating more abundant and fine - grained saliency maps ( i.e. each pixel can be assigned with several saliency levels ) .",
    "pixel - accurate saliency maps are often required to be spatially coherent with discontinuities well aligned to image edges , according to existing studies  @xcite .",
    "in particular , the spatial connectivity and correlation involved in neighborhood pixels should be preserved in saliency computing .    in this work , we pose the fine - grained saliency assignment as a multiple labeling problem , in which the appearance contrast based saliency measure is jointly modeled with the neighborhood coherence constraint .",
    "the resulting target function can be minimized by using global discrete labeling optimizers such as graph cuts  @xcite or belief propagation  @xcite .",
    "these methods , however , are often relatively time - consuming and do not scale well to fine - grained labeling ( i.e. a large space of labels ) .",
    "some other continuous approaches are efficient but usually require a restricted form of the energy function . in this paper",
    ", we employ a recently proposed filter - based method , namely cost - volume filtering  @xcite , to smoothly assign the saliency levels while preserving structural coherence ( i.e. keeping the edges and boundaries of salient objects ) .",
    "to balance the accuracy - efficiency trade - off , we also propose a faster version called f - pisa .",
    "it first performs saliency computation for a feature - driven , subsampled image grid , and then uses an adaptive upsampling scheme with the color image as the guidance signal to recover a full - resolution saliency map .",
    "compared to segmentation - based saliency methods  @xcite , our f - pisa method reduces the computational complexity similarly by considering a coarse image grid , while having the advantage of utilizing image structural information for saliency reasoning over  @xcite .",
    "our extensive experiments on six public benchmarks demonstrate the superior detection accuracy and competitive runtime speed of our approaches over the state - of - the - arts .",
    "moreover , we construct a new and meaningful database of image saliency including real commodity images from online shops .",
    "the remainder of the paper is organized as follows : sect .",
    "[ sec : related ] reviews related works of saliency detection . sect .",
    "[ sec : formul ] introduces the proposed framework and its main components .",
    "more details for inference and implementation are discussed in sect .",
    "[ sec : alg ] .",
    "extensive experimental evaluations and comparisons are presented in sect .",
    "[ sec : exper ] .",
    "the paper concludes in sect .",
    "[ sec : conclusion ] .",
    "recently , numerous bottom - up saliency detection models have been proposed for explaining visual attention based on different mathematical principles or priors .",
    "we classify most of the previous methods into two basic classes depending on the way that saliency cues are defined : _ contrast priors _ and _ background priors _  @xcite . assuming that saliency is unique and rare in appearance , contrast priors have been widely adopted in many previous methods to model the appearance contrast between foreground salient objects and the background .",
    "et al . _",
    "@xcite presented a bottom - up method in which an input image is represented with three features including color , intensity and orientation in different scales .",
    "et al . _",
    "@xcite proposed a frequency - tuned method that defines the saliency likelihood of each pixel based on its difference from the average image color by exploiting the center - prior principle .",
    "et al . _",
    "@xcite used a patch based approach to incorporate global properties to highlight salient objects along with their contexts . however , due to using the local contrast only , it tends to produce higher salient values near edges . to highlight the entire object , cheng _",
    "et al . _",
    "@xcite presented color histogram contrast ( hc ) in the @xmath1 color space and region contrast ( rc ) in a global scope .",
    "et al . _",
    "@xcite formulated saliency estimation using two gaussian filters by which color and position are respectively exploited to measure region uniqueness and variance of the spatial distribution .",
    "_ et al . _",
    "@xcite proposed a hierarchical framework that infers important values from three image layers in different scales . also using a hierarchical indexing mechanism , cheng _",
    "et al . _",
    "@xcite proposed a gaussian mixture model based abstract representation which decomposes an image into large scale perceptually homogeneous elements .",
    "but their saliency cues integration based on the compactness measure may not always be effective .",
    "typical limitations of the existing methods based on contrast priors include attenuated object interior and ambiguous saliency detection for images with rich structures in foreground or / and background .    complementing the prime role of contrast priors in this research topic , background priors  @xcite",
    "have been proposed recently to exploit two interesting priors about backgrounds  connectivity and boundary priors .",
    "the background prior is based on an observation that the distance of a pair of background regions is shorter than that of a region from the salient object and a region from the background .",
    "et al . _",
    "@xcite exploited background priors and the geodesic distance for the saliency detection .",
    "et al_.  @xcite proposed a graph - based manifold ranking approach to characterize the overall differences between salient objects and background .",
    "et al_.  @xcite integrated the background cues into the designed absorbing markov chain .",
    "regarding image boundaries as likely cues for background templates , li _",
    "et al_.  @xcite proposed a saliency detection algorithm from the perspective of dense and sparse appearance model reconstructions .",
    "however , these methods fail when objects touch the image boundary to quite some extent , or when connectivity assumptions are invalid in the presence of complex backgrounds or textured scenes . for instance , the maple leave case in fig .",
    "[ fig : fig1 ] poses a challenge for the method  @xcite .",
    "energy minimization based methods have also been introduced for saliency detection . liu _",
    "et al_.  @xcite proposed a nonparametric saliency model based on kernel density estimation ( kde ) .",
    "et al_.  @xcite proposed an iterative energy minimization framework to integrate both bottom - up salient stimuli and an object - level shape prior . treating saliency computation as a regression problem , jiang _",
    "et al_.  @xcite integrated regional contrast , regional property and regional backgroundness .",
    "et al_.  @xcite proposed to account for the relationships of objectness and saliency by iteratively optimizing an energy function .",
    "this paper provides a more complete understanding of the pisa algorithm first presented in the conference version  @xcite , giving further background , insights , analysis , and evaluation .",
    "furthermore , we improve the previous framework in two aspects . first , the improved pisa is cast as the energy minimization problem , which efficiently solved by the edge - aware cost - volume filter to generate the spatially coherent and fine - grained saliency maps in one shot .",
    "second , for suppressing the effect of background , a more general spatial prior is integrated in our framework to obtain more compact saliency maps .",
    "in this section , we introduce the formulation of pisa , and briefly overview the main components .    given an input image @xmath2 ,",
    "the objective of pisa is to extract salient objects automatically and assign consistently high saliency levels to them . without loss of generality",
    ", we achieve this goal by minimizing the following energy function    @xmath3 where @xmath4 represents the cost of labeling pixel @xmath5 with the saliency level @xmath6 , which composes the data term according to the contrast based measures .",
    "@xmath7 defines the neighborhood coherence to preserve the local structures and edges centered at @xmath5 .",
    "we further specify @xmath4 as    @xmath8 where @xmath9 denotes the normalized feature measure of @xmath5 , aggregating two complementary contrast measures defined in a global context .",
    "[ fig : framework ] illustrates the main flowchart of pisa .",
    "we introduce two types of features to capture contrast information of salient objects with respect to the scene background .",
    "they are a color - based contrast feature and a structure - based contrast feature , each of which is further integrated with the spatial priors holistically .",
    "these two features complement each other in detecting saliency cues from different perspectives , and are combined together in a pixelwise adaptive manner to measure the saliency .",
    "more formally , given an image @xmath2 , we compute the feature - based saliency confidence @xmath10 for each pixel @xmath5 by aggregating the two contrast measures ( i.e. the uniqueness in the feature spaces ) @xmath11 with the spatial priors @xmath12 , as    @xmath13    * appearance contrast term * @xmath11 . the contrast measure is proposed based on the observation or principle that rare or infrequent visual features in a global context give rise to high salient values  @xcite . here",
    "we exploit the structure - based contrast measure in addition to the well exploited color - based contrast measure , and we fuse the two measures @xmath11 to achieve better performance . @xmath14 denotes the uniqueness of pixel @xmath5 with respect to the entire image in the color feature space , and @xmath15 denotes the uniqueness of pixel @xmath5 in the orientation - magnitude ( om ) feature space .",
    "their detailed implementations will be discussed in sect .",
    "[ sec : cc ] and sect .",
    "[ sec : sc ] , respectively . instead of describing the features for pixel",
    "@xmath5 via its assigned superpixel , we use the non - parametric histogram distribution to capture and represent both the color and structure features with an appropriate observation region around @xmath5 .",
    "it is worth mentioning that our framework is very general to incorporate more saliency cues in the similar way .",
    "[ fig : framework ]    * spatial priors term @xmath12*. they are evaluated based on the generally valid spatial prior that salient pixels tend to distribute near the image center and away from the image boundary , i.e. people tend to frame an image by placing salient objects of interest in the center with background borders .",
    "thus , we integrate the image center preference and boundary exclusion in the saliency reweighting process .",
    "we use @xmath16 and @xmath17 to denote the integration of image center spatial distance and image boundary exclusion of visually similar peers on the color and structure contrast measurement , respectively ( sect .",
    "[ sec : spatial ] ) .",
    "after reweighting the above saliency measurement based on appearance contrast , we keep the salient pixels compact and centered with the exclusion to the image boundary in the image domain .",
    "we normalize the feature - based saliency confidence to the discrete saliency level set @xmath18 for further calculating the label cost @xmath4 .",
    "this normalization is given by the following sigmoid - like function :    @xmath19 where @xmath20 denotes a rounding function , which rounds a float - point number to the nearest integer , and @xmath21 is the user defined maximum saliency level .",
    "we fix @xmath22 to 24 in our all experiments .      to suppress spurious noises and non - uniform saliency assignment , we further incorporate the spatial connectivity and correlation constraint among neighborhood pixels together with the feature - based measures .",
    "the saliency level @xmath6 for pixel @xmath5 should be consistent with its neighborhood pixels which have similar appearance with @xmath5 within its local observation region @xmath23 in the image domain .",
    "the coherence constraint @xmath7 can be thus defined as    @xmath24 where the observation window @xmath23 for the anchor pixel @xmath5 delineates an arbitrarily - shaped and connected local support region ( see fig .",
    "[ fig : feature ] ) , @xmath25 represents a neighboring pixel to @xmath5 in @xmath23 , and @xmath26 is the saliency level assigned to @xmath25 .",
    "@xmath27 encodes the similarities between @xmath5 and @xmath25 within @xmath23 , which will be explained in the next section .",
    "in this section , we unfold the framework of pisa and discuss the implementation details .",
    "in addition , a faster version of pisa , namely f - pisa , is also developed to greatly improve the runtime efficiency and keep comparable performance .    [ !",
    "t ]      unlike the traditional methods@xcite that usually process fixed - size windows or over - segmented superpixels , pisa computes saliency by generating an arbitrarily - shaped observation region for each pixel in the image .",
    "this pixelwise observation plays a key role in feature extraction and fine - grained saliency assignment .    for a pixel @xmath5 centered at a square window @xmath28",
    ", we first define a color similarity criterion for a test pixel @xmath25 as follows ,    @xmath29 where @xmath30 is the intensity of the color band @xmath31 of the @xmath32 median smoothed input image @xmath2 . set empirically",
    ", @xmath33 denotes the preset maximum arm length of the observation window @xmath28 centered at pixel @xmath5 ( the size of @xmath28 is @xmath34 ) , and @xmath35 controls the confidence level of the color similarity .",
    "the method of generating @xmath23 follows our previous study in image filtering ( i.e. cross - based local multipoint filtering )  @xcite .",
    "we first decide a pixelwise adaptive cross with four arms ( left , right , up , bottom ) for every pixel @xmath5 . by changing four arms of every pixel @xmath5 adaptively ,",
    "the local image structure is captured reliably .",
    "these arms record the largest left / right horizontal and up / bottom vertical span of the anchor pixel @xmath5 , where all the pixels covered by the arms are similar to pixel @xmath5 in color ( i.e. they satisfy eqn .",
    "( [ equ : adaptive ] ) ) .",
    "let @xmath36 and @xmath37 denote all the pixels covered by the horizontal and vertical arms of the pixel @xmath5 , respectively .",
    "let @xmath25 denote any pixel covered by the vertical arms of the pixel @xmath5 ( i.e. @xmath38 ) , as shown in fig .",
    "[ fig : clmf ] .",
    "then we can further construct the arbitrarily - shaped , connected local observation window @xmath23 by integrating multiple @xmath39 sliding along @xmath37    @xmath40    [ !",
    "t ]        directly computing pixelwise color contrast in a global image context is computationally expensive , as its complexity is @xmath41(@xmath42 ) with @xmath43 being the number of pixels in the image @xmath2 .",
    "recently , cheng _ et al._@xcite proposed an effective and efficient color - based contrast measure , i.e. , histogram - based contrast ( hc ) .",
    "they assume that if neglecting spatial correlations , pixels with the similar color value should have the same saliency value . however , without taking the neighborhood of pixels into consideration , their strategy of defining contrast on color information of individual pixels is sensitive to noise , and it is not extensible for measuring additional attributes . in this work ,",
    "we compute the color contrast based on a non - parametric color distribution extracted from a local homogeneous region . as pixels within the homogeneous region share similar appearance with the central pixel , it is more robust to define a contrast measure on color information of homogeneous regions rather than individual pixels .    for each pixel @xmath5",
    ", we first construct a local observation region efficiently as described in sect .",
    "[ sec : observationwindow ] .",
    "a color histogram @xmath44 for pixel @xmath5 is then built from the pixels @xmath45 covered in the localized homogeneous region .",
    "using @xmath44 rather than @xmath46 is more consistent with psychological evidences on human eyes receptive field on homogeneous regions . using the @xmath1 color space ,",
    "we quantize each color channel uniformly into 12 bins , so the color histogram @xmath44 is a 36-d descriptor ( see fig .",
    "[ fig : feature ] ) .",
    "next , we cluster pixels that share similar color histograms together using _ kmeans_. the whole color feature space for the input image @xmath2 is then quantized into @xmath47 clusters , indexed by @xmath48 . as a result",
    ", we use the rarity of color clusters as the proxy to evaluate the rarity or contrast measure of pixels .",
    "let @xmath49 denote the cluster that pixel @xmath5 , or more precisely @xmath44 , is assigned to .",
    "we estimate the color - based contrast measure @xmath14 for pixel @xmath5 as    @xmath50    where @xmath51 uses the number of pixels belonging to the cluster @xmath52 as a weight to emphasize the color contrast to bigger clusters , and @xmath53 is the average color histogram of cluster @xmath49 . fig .  [",
    "fig : spatial ] ( a ) illustrates an example image with eight color clusters and their contrast measure @xmath14 .    [ !",
    "t ]    feature space quantization may cause undesirable artifacts .",
    "when directly calculating the @xmath54 distance of histograms or giving an inappropriate cluster number @xmath47 , similar color histograms can sometimes be quantized into different clusters .",
    "we tackle this problem in three aspects : i ) improve clustering with color dissimilarity .",
    "we sightly modify _ kmeans _ in its distance when clustering .",
    "in addition to the @xmath54 distance between the two histograms , we add the color dissimilarity between the center pixels into the distance measurement .",
    "ii ) decide @xmath47 adaptively according to the histogram distribution .",
    "the cluster number @xmath47 of the color feature space is adaptively decided with regard to the image content .",
    "similar to that used in  @xcite , we choose the most frequently occurring color features by ensuring they cover 95% of the histogram distributions of all pixels in the input image @xmath2 .",
    "iii ) reweight the salient values of clusters with respect to their visual similarities .",
    "we adopt a linearly - varying smoothing scheme  @xcite to refine the quantization - based saliency measurement .",
    "the saliency value of each cluster is replaced by the weighted average of the saliency values of visually similar clusters .",
    "larger weights are assigned to those clusters which share similar color features .",
    "such a refinement smooths the saliency assignments to each pixel .",
    "our proposed method that computes the color contrast based on non - parametric color distribution reduces the computational complexity from @xmath55 to @xmath56 , where the second term corresponds to the complexity of _ kmeans _ and usually is very small . as we observed , @xmath47 typically takes values in the range of 6 to 403 in the asd dataset @xcite which contains 1000 images .      as discussed in sect .",
    "[ sec : intro ] , using only color information is not adequate to completely depict salient objects or parts of them against the non - salient background .",
    "even though in the cases that the color - based measure produces good results , other complementary measures can still contribute to reinforce the saliency assignment .",
    "therefore , we propose a structure - based measure to complement the color - based contrast measure here .",
    "the proposed structure - based measure models the image gradient distribution for every pixel @xmath5 by a histogram @xmath57 in a rectangular region @xmath28 .",
    "@xmath57 measures the occurrence frequency of a concatenated vector consisting of a gradient orientation component and a gradient magnitude component .",
    "similarly , we quantize both components into eight bins , and call the resulting feature space the om space .",
    "it is clear that a point in such a om space is 16-d ( see fig .",
    "[ fig : feature ] ) . in this paper",
    ", we fix the local window @xmath28 to the same size as the maximum observation window of the color histogram extraction for the comparability .",
    "as will be shown later , we find that our om structure descriptor , though simple , is more effective and reliable than other gradient features such as gabor@xcite and lbp@xcite in the image saliency detection task .",
    "similar to the color contrast measure , _ kmeans _ is utilized to partition the om feature space into @xmath58 clusters , indexed by @xmath59 .",
    "the structure contrast measure for pixel @xmath5 is equivalent to measuring that of the cluster @xmath60 which @xmath5 is grouped to as    @xmath61 where @xmath51 is the weight stressing the contrast against bigger clusters , and @xmath62 is the average om histogram of the cluster @xmath60 .",
    "@xmath63 may suffer from the influence of side effects caused by the brute - force feature space quantization process . again , we alleviate these artifacts by adopting the same strategy illustrated in sect .  [",
    "sec : cc ] .",
    "i.e. , using slightly modified _ kmeans _ , determining the cluster number @xmath58 adaptively by representing the most frequent om vectors and accounting for at least 95% pixels , and applying local smoothing scheme .",
    "we observe @xmath58 typically varies from 11 to 43 in the asd dataset  @xcite .",
    "motivated by recent works@xcite , we impose a spatial prior term on each of the two contrast measures @xmath11 , constraining pixels rendered salient to be centered and excluded to the image boundary in the image domain based on the image center preference and the image boundary exclusion . for each pixel @xmath5",
    ", we evaluate the initial spatial prior term @xmath64 based on the cluster @xmath65 that contains @xmath5 from two aspects : i ) preference to the image center , and ii ) exclusion to the image boundary .",
    "combining these two criteria , we compute @xmath64 as follows :    @xmath66 where @xmath67 is the number of pixels which are contained in the same color ( or om ) cluster @xmath52 ( or @xmath68 ) with @xmath5 .",
    "@xmath69 is the image center position .",
    "@xmath70 indicates the image border region , which is formed by the pixels close to the image borders . as a matter of fact",
    ", this region typically belongs to non - salient background .",
    "thus , we incorporate the @xmath71 as the probability of @xmath52/@xmath68 belonging to the image border region .",
    "we use a user - specified parameter @xmath72 to control the relative weight of the image boundary exclusion .",
    "[ fig : spatial ] ( d ) and ( e ) illustrate the spatial prior together with using the color - based measure and the effectiveness for saliency assignment .",
    "since clusters closer to the image border or farther from the image center are often unlikely to be salient , we compute the final spatial prior term @xmath73 for pixel @xmath5 using a threshold @xmath74 as    @xmath75 where @xmath76 controls the fall - off rate of the exponential function . by",
    "now we have defined all the four terms necessary for computing @xmath10 in eqn .",
    "( [ equ : contrast ] ) .",
    "our goal is to assign each pixel @xmath5 in the image @xmath2 to a saliency level @xmath77 from the discrete saliency level set @xmath78 , with the formulation in eqn .",
    "( [ equ : energyequ ] ) .",
    "this is a multi - labeling minimization task integrating a data term and a smoothness term . instead of using global discrete optimization methods",
    ", we employ the cost - volume filtering technique  @xcite to achieve this goal , which computes the discrete assignment efficiently while keeping local labeling coherence . specifically , this method aggregates the label costs within a support window by applying a local edge - preserving smoothing filter , and then selects the label in a winner - takes - all fashion .",
    "the fine - grained saliency is computed for each pixel with the following steps .    *",
    "( i ) constructing the cost - volume * : following  @xcite , the cost - volume is a three dimensional array , and each element @xmath79 in the array represents the cost for choosing a saliency level @xmath77 at pixel @xmath5 .",
    "we compute @xmath79 as the square difference between @xmath77 and the normalized feature - based saliency measure @xmath9 :    @xmath80    * ( ii ) filtering the cost - volume * : to smooth the label costs in the image domain , the cost - volume will be further filtered with an edge - preserving filter .",
    "the original cost volume filtering method uses the guided filter  @xcite , which employs fixed - sized square observation windows , and it derives the output of the filtering simply as an average of multiple linear regression results from shifted windows of neighboring pixels .    in this work , to incorporate the local edge - aware coherence ( eqn .",
    "( [ straint ] ) ) and also to achieve more efficient runtime , we extend the guided filter into a new form based on the pixelwise adaptive observation  @xcite .",
    "specifically , for pixel @xmath5 we estimate the correlation of @xmath5 and its neighbor @xmath81 by    @xmath82    where @xmath83 is the observation region of pixel @xmath84 ( a neighbor of @xmath5 ) , and @xmath85 denotes the number of pixels in @xmath83 . intuitively , the correlation of pixel @xmath5 and the neighbor @xmath84 is proportional to @xmath85 .",
    "we refer to  @xcite for the technical background .",
    "the cost of @xmath5 can be updated by the weighted average of the initial costs of all pixels in @xmath23 as    @xmath86    this step encourages the saliency values to be smooth in the homogeneous regions and also preserves the object details ( e.g. edges and structures ) in the fine - grained saliency assignment .    * ( iii ) winner - takes - all label selection * : after the cost - volume is updated , the final saliency level @xmath6 at pixel @xmath5 is selected by    @xmath87      salient object detection is always cast as a preprocessing technique for subsequent applications , which demands a fast and accurate solution . to optimize accuracy - complexity trade - off , we present a faster version f - pisa , which contains well - designed algorithmic choices . instead of processing the full image grid ,",
    "we perform a gradient - driven subsampling of the input image @xmath2 , so the saliency computation in eqn .",
    "( [ equ : energyequ ] ) is only applied to this set of selected pixels .",
    "more specifically , for a given image @xmath2 , we pick the pixel with the largest gradient magnitude from a 3@xmath883 rectangular patch on the regular image grid to form a sparse image @xmath89 .",
    "the two proposed contrast saliency measures with edge - preserving coherence are then computed for @xmath89 , giving a sparse saliency map @xmath90 . to obtain a full - resolution saliency map @xmath91 , we propagate the saliency values among pixels in the same pixel - adaptive observation region , as they share the similar appearance .",
    "this propagation scheme resembles the principle of joint bilateral upsampling  @xcite , using a high - resolution color image @xmath2 as a guidance to upsample a sparsely - valued solution map @xmath90 .",
    "it can produce a smoothly varying dense saliency map @xmath91 without blurring the edges of salient objects .",
    "thus given a pixel @xmath92 , its saliency value is obtained as    @xmath93 where @xmath94 belongs to @xmath89 and its pixel - adaptive support region @xmath95 contains @xmath5 , @xmath96 is the total number of such pixels , and @xmath97 . in sect .",
    "[ sec : exper ] , we evaluate the performance of this fast version quantitatively and qualitatively on six public benchmark datasets .",
    "we present empirical evaluation and analysis of the proposed pisa against several state - of - the - art methods ( including the conference version  @xcite ) on six public available datasets .",
    "we further analyze the effectiveness of the two complementary components , i.e. , color - based contrast measure and structure - based contrast measure , as well as their corresponding spatial priors ( image center preference and boundary exclusion ) .",
    "we justify the importance of the proposed energy minimization framework and the sigmoid - like function for the feature - based saliency confidence normalization . at last ,",
    "we discuss our limitations through failure cases .",
    "we evaluate the proposed methods on six public available datasets .",
    "they are asd  @xcite , sod  @xcite , sed1  @xcite , ecssd  @xcite , pascal-1500  @xcite and the taobao commodity dataset ( tcd ) newly created by us .",
    "the asd is also called msra-1000 which contains 1000 images with accurate human - labeled masks for salient objects and has been widely used by recent methods .",
    "the sod dataset is more challenging with complex objects and scenes included in its 300 images , and we obtain the ground - truth for this dataset from the authors of the work  @xcite . the sed1 dataset is exploited recently which contains 100 images of single objects , and we consider a pixel salient if it is annotated as salient by all subjects .",
    "the ecssd contains 1000 diversified patterns in both background and foreground images , which includes many semantically meaningful but structurally complex images for evaluation .",
    "the pascal-1500 , created from pascal voc 2012 , is also a challenge dataset , in which the images contain multiple objects appearing at a variety of locations and scales with cluttered background .",
    "the tcd dataset that we make available with this paper contains 800 commodity images from the shops on the taobao website .",
    "the ground truth masks of the tcd dataset are obtained by inviting common sellers of taobao website to annotate their commodities , i.e. , masking salient objects that they want to show from their exhibition .",
    "these images include all kinds of commodity with and without human models , thus having complex backgrounds and scenes with highly complex foregrounds .",
    "we choose the total saliency level @xmath98 . for the step of generating pixelwise adaptive observation , we set \\{@xmath35 , @xmath33 } = \\{60 , 10 } to extract color features and build saliency coherence support regions .",
    "we set \\{@xmath99 } = \\{@xmath100 , 0.006 , 0.001 , 30}. while for f - pisa , we set \\{@xmath35 , @xmath33 } = \\{50 , 5 } and \\{@xmath99 } = \\{@xmath101 , 0.035 , 0.001 , 30}. these parameters are fixed in all experiments for the six datasets .",
    "we use ( p)recision-(r)ecall curves ( pr curves ) , @xmath102 metric and mae to evaluate all the algorithms . given the binarized saliency map via the threshold value from 0 to 255 , precision means the ratio of the correctly assigned salient pixel number in relation to all the detected salient pixel number , and recall means the ratio of the correct salient pixel number in relation to the ground truth number .",
    "different from ( p)recision-(r)ecall curves using a fixed threshold for every image , the @xmath102 metric exploits an adaptive threshold of each image to perform the evaluation .",
    "the adaptive threshold is defined as    @xmath103 where @xmath104 and @xmath105 denote the width and height of an image , respectively .",
    "the f - measure is defined as follows with the precision and recall of the above adaptive threshold :    @xmath106 where we set the @xmath107 = 0.3 to emphasize the precision as suggested in @xcite . as pointed out in @xcite ,",
    "pr curves and @xmath102 metric are aimed at quantitative comparison , while mean absolute error ( mae ) are better than them for taking visual comparison into consideration to estimate dissimilarity between a saliency map @xmath91 and the ground truth @xmath108 , which is defined as    @xmath109 where @xmath110 is the number of image pixels .",
    "we compare our methods with thirteen recent state - of - the - art works : dense and sparse reconstruction ( dsr )  @xcite , global cues ( gc )  @xcite , histogram - based contrast ( hc )  @xcite , context - aware saliency ( ca )  @xcite , frequency - tuned saliency ( ft )  @xcite , spectral residual saliency  ( sr )  @xcite , spatial - temporal cues  ( lc )  @xcite , context - based saliency ( cb )  @xcite , markov chain saliency ( mc )  @xcite , hierarchical saliency ( hs )  @xcite , graph - based manifold ranking ( gm )  @xcite , saliency filter ( sf )  @xcite , and region - based contrast ( rc )  @xcite .",
    "whenever they are available , we use the author - provided results . results of hc , ft , sr , lc , rc are generated by using the codes provided by  @xcite , and we adopt the public implementations from the original authors for dsr , gc , ca , cb , hs , gm , mc and sf . note that the saliency maps of all methods are mapped to the range [ 0 , 255 ] by the same max - min normalization method for the further evaluation .",
    "the evaluation results are shown in fig .",
    "[ fig : prf ] and  [ fig : prf2 ] , respectively .",
    "[ htbp ]    [ htbp ]    in fig .",
    "[ fig : prf ] , based on the pr curves of asd , sod and sed1 , our proposed method pisa performs nearly the same as compared methods . to evaluate the overall performance of the pr curve",
    ", we calculate the average precision , which is the integral area under the pr curve . for the asd dataset ,",
    "our pisa , dsr , hs , gm and mc all achieve more than 93.0% accuracy , while the average precision of pisa is 1.5% , 0.6% , 2.1% , 1.7% less than dsr , hs , gm , mc , respectively . for the sod dataset , pisa , dsr and mc all achieve more than 80% accuracy , while the average precision of pisa is 0.5% better than both of them .",
    "for the sed1 dataset , pisa , dsr , hs , gm and mc all achieve more than 90.0% accuracy , while the average precision of pisa is only 2.8% less than gm .",
    "based on the @xmath102 metric in fig .",
    "[ fig : prf ] , pisa obtains 2% less than gm / mc on asd , 0.5% less than dsr / mc on sod , 4% less than gm",
    "/ mc on sed1 . based on the mae in fig .",
    "[ fig : prf ] , pisa obtains the best results on the sod datasets and advances together with the best method gm on asd / sed1 .",
    "hence , compared with all the compared methods , pisa is only slightly better on sod , and is only a little worse on asd and sed1 .",
    "since asd and sed1 datasets are simple and not challenging , it is not suitable for showing the advantage of pisa .    the superior performance of pisa is demonstrated in fig .",
    "[ fig : prf2 ] . based on the pr curves , @xmath102 and mae in fig .",
    "[ fig : prf2 ] , one can clearly see that our pisa consistently outperforms all the compared methods on ecssd , pascal-1500 , tcd , respectively .",
    "in particular , tcd is different in focusing on commodity images , whose salient objects contain diverse patterns and rich structure information .",
    "this is consistent with our motivations i ) and ii ) in sect  [ sec : intro ] . designed to meet these objectives",
    ", our pisa achieves clearly higher performance than the compared methods .",
    "in addition , pisa in this paper performs 2% better than the conference version ( pisa - prev ) on average , and readers are encouraged to see the supplementary file for more details .",
    "[ htbp ]    [ htbp ]      we further analyze the effectiveness of the two complementary measures , i.e. color - based contrast ( cc ) and structure - based contrast ( sc ) . the quantitative results on the six datasets in fig .",
    "[ fig : cuepr ] demonstrate the requisite of aggregating the two measures : pisa ( sc + cc ) performs consistently better than sc or cc alone .",
    "we can observe that the aggregated saliency detection achieves superior performance , as cc and sc capture saliency from different aspects , verified by the visual results in fig .",
    "[ fig : fig1 ] .",
    "it is worth noting that we obtain favorable results on the images in the second and third rows in fig .",
    "[ fig : fig1 ] , which are exhibited in  @xcite and  @xcite as failure cases .",
    "they serve as good evidences to advocate our choice in fusing complementary saliency cues .",
    "we also analyze the contribution of the introduced spatial priors , i.e. image center preference and boundary exclusion .",
    "the quantitative results on the six datasets in fig .",
    "[ fig : comppr ] illustrate the advantage of introducing these spatial priors .",
    "`` without be '' represents the pisa framework without boundary exclusion ( be ) only , while `` without cp '' represents without image center preference ( cp ) only",
    ". justified by the experiments on the six datasets , the introduced spatial priors contribute to achieve superior performance , as cp and be represent the typical choices when people take pictures .",
    "we also justify the significance of the proposed energy - minimization framework ( eqn .",
    "( [ equ : energyequ ] ) ) by comparing with our conference framework ( pisa - prev framework )  @xcite . for fair comparison ,",
    "we conduct the experiment with all other parameters fixed , i.e. they share the same normalized feature - based saliency measure @xmath9 , and the only difference is the framework .",
    "[ fig : compframework ] demonstrates that our energy - minimization framework obtains higher precision when the recall belongs to [ 0 , 0.2 ] on pr curves and achieves better mae results .",
    "thus , by modeling the appearance contrast based saliency measure and the neighborhood coherence constraint jointly , the proposed energy - minimization framework can highlight saliency objects more uniformly .",
    "we have also explored other commonly used features gabor  @xcite and lbp  @xcite to substitute om for capturing structure information .",
    "for all the features , we choose their best results for comparison by tuning their quantizations .",
    "the dimensions for gabor and lbp features are @xmath111 and @xmath112 , respectively .",
    "the pr - curves of the experiments evaluated on the asd dataset  @xcite are shown in fig .",
    "[ fig : grad ] .",
    "the om descriptor outperforms the others .",
    "meanwhile , under the proposed framework , our om descriptor also shows higher computational efficiency than gabor and lbp due to its low dimension .",
    "[ htbp ]    in our proposed framework , the normalization step , which maps the feature - based saliency measure @xmath10 into discrete saliency level set \\{0 , ... , @xmath113 } , has an impact on the final saliency maps .",
    "[ fig : norm_visual ] illustrates this impact of different normalizations , such as commonly used max - min ( linear ) , log - like ( nonlinear ) , and exp - like ( nonlinear ) .",
    "compared with the linear normalization , log - like increases the saliency levels of the whole pixels ( fig .",
    "[ fig : norm_visual](c ) ) , while exp - like decreases all pixels saliency levels ( fig .",
    "[ fig : norm_visual](d ) ) .",
    "sigmoid - like increases the number of high salient value pixels and reduces those of low salient value for its s shape ( fig .",
    "[ fig : norm_visual](e ) ) . for exploring these normalization functions ,",
    "we conduct the experiment on the pascal-1500 dataset  @xcite as it is the most challenging and the largest dataset with @xmath102 metric and mae evaluation .",
    "note that we discard the pr curves for that the change of normalization methods will not affect pr results as long as the mapping is one - to - one .",
    "[ fig : normalization ] demonstrates that a sigmoid - like function performs a little better in @xmath102 metric and much better in mae evaluation than others .",
    "thus we adopt a sigmoid - like normalization ( eqn .",
    "( [ equ : sigmoid ] ) ) to produce better visual saliency maps .",
    "the experiments are carried out on a desktop with an intel i7 3.4ghz cpu and 8 gb ram .",
    "the average runtime with ranking of our approaches ( pisa and f - pisa ) and competing methods on the asd dataset  @xcite , whose most images have a resolution of @xmath114 , are reported in table  [ tab : time ] . though pisa is a little slow ( rank 13 , slightly faster than our conference version pisa - prev )",
    ", our fast implementation f - pisa , significantly improves the efficiency ( rank 6 , @xmath115 times faster than pisa ) , while keeping comparable accuracy ( better than the top five methods in the rank list , see fig .",
    "[ fig : prf ] and  [ fig : prf2 ] ) . specifically , for pisa : calculating the normalized feature - based saliency measure costs 310ms ( about 50% ) , minimizing the energy function costs 280ms ( about 45% ) , and others cost 30ms ( about 5% ) . for f - pisa : computing saliency costs 30ms ( about 68% ) , while subsampling and joint bilateral upsampling costs 12ms ( about 27% ) , and others cost 2ms ( about 5% ) .",
    "[ tab : time ]    .comparison of the average running time ( seconds per image ) on the asd dataset  @xcite . [ cols=\"^,^,^,^\",options=\"header \" , ]      in fig .",
    "[ fig : limit ] , we present unsatisfying results generated by pisa . as our approach uses the spatial priors , it has problems when such priors are invalid .",
    "for example , if the saliency object occurs near the image boundary to quite extent , some regions of it can be suppressed ( see fig .  [",
    "fig : limit](first row ) ) due to the image boundary exclusion prior .",
    "if the center prior does not hold , the background regions located near the image center can not be effectively suppressed in saliency evaluation ( see fig .  [",
    "fig : limit](second row ) ) . by adjusting the relative contribution of these priors through tuning @xmath72",
    ", we can alleviate their influences .",
    "thus , the weakness of the proposed methods is : for any background regions that have been assigned high saliency values from either of the contrast cues after the modulation of the spatial priors , they remain salient in the final saliency map .",
    "this problem could be tackled by incorporating high - level knowledge to adjust the confidence of two measures in the formulation .",
    "we have presented a generic and unified framework for pixelwise saliency detection by aggregating multiple image cues and priors , where the feature - based saliency confidence are jointly modeled with the neighborhood coherence constraint . based on the saliency model , we employed the shape - adaptive cost - volume filtering technique to achieve fine - grained saliency value assignment while preserving edge - aware image details .",
    "we extensively evaluated our pisa on six public datasets by comparing with previous works .",
    "experimental results demonstrated the advantages of our pisa in detection accuracy consistency and runtime efficiency . for future work",
    ", we plan to incorporate high - level knowledge and multilayer information , which could be beneficial to handle more challenging cases , and also investigate other kinds of saliency cues or priors to be embedded into the pisa framework .",
    "k.  shi , k.  wang , j.  lu , and l.  lin .",
    "pisa : pixelwise image saliency by aggregating complementary appearance contrast measure with spatial priors . in _ proc .",
    "ieee conf .",
    "pattern recognit .",
    "_ , pp . 2115 - 2122 , 2013 .                              keze wang received the bs degree in software engineering from sun yat - sen university , guangzhou , china , in 2012 .",
    "he is currently pursuing the ph.d .",
    "degree in computer science and technology at sun yat - sen university , advised by professor liang lin .",
    "his current research interests include computer vision and machine learning .",
    "liang lin is a professor with the school of advanced computing , sun yat - sen university ( sysu ) , china .",
    "he received the b.s . and ph.d .",
    "degrees from the beijing institute of technology ( bit ) , beijing , china , in 1999 and 2008 , respectively . from 2006",
    "to 2007 , he was a joint ph.d .",
    "student with the department of statistics , university of california , los angeles ( ucla ) . his ph.d .",
    "dissertation was achieved the china national excellent ph.d .",
    "thesis award nomination in 2010 .",
    "he was a post - doctoral research fellow with the center for vision , cognition , learning , and art of ucla .",
    "his research focuses on new models , algorithms and systems for intelligent processing and understanding of visual data such as images and videos .",
    "he has published more than 70 papers in top tier academic journals and conferences .",
    "he was supported by several promotive programs or funds for his works , such as `` program for new century excellent talents '' of ministry of education ( china ) in 2012 , and guangdong nsfs for distinguished young scholars in 2013 .",
    "he received the best paper runners - up award in acm npar 2010 , google faculty award in 2012 , and best student paper award in ieee icme 2014 .",
    "he has served as an associate editor for neurocomputing and the visual computer .",
    "jiangbo lu(m09 ) received the b.s . and",
    "degrees in electrical engineering from zhejiang university , hangzhou , china , in 2000 and 2003 , respectively , and the ph.d .",
    "degree in electrical engineering from katholieke universiteit leuven , leuven , belgium , in 2009 . from april 2003 to august 2004 , he was with via - s3 graphics , shanghai , china , as a graphics processing unit ( gpu ) architecture design engineer . in 2002 and 2005",
    ", he conducted visiting research at microsoft research asia , beijing , china . since october 2004",
    ", he has been with the multimedia group , interuniversity microelectronics center , leuven , belgium , as a ph.d .",
    "researcher . since september 2009",
    ", he has been with the advanced digital sciences center , singapore , which is a joint research center between the university of illinois at urbana - champaign , urbana , and the agency for science , technology and research ( a*star ) , singapore , where he is leading a few research projects currently as a senior research scientist .",
    "his research interests include computer vision , visual computing , image processing , video communication , interactive multimedia applications and systems , and efficient algorithms for various architectures .",
    "chenglong li received the bs degree in applied mathematics in 2010 , and the m.s .",
    "degree in computer science in 2013 from anhui university , hefei , china .",
    "he is currently pursuing the ph.d .",
    "degree in computer science at anhui university .",
    "his current research interests include computer vision , machine learning , and intelligent media technology .    keyang shi received the bs and ms degrees in software engineering and computer science respectively , from sun yat - sen university , guangzhou , china , in 2011 and 2014 .",
    "his research interests include computer vision , machine learning and cloud computing ."
  ],
  "abstract_text": [
    "<S> driven by recent vision and graphics applications such as image segmentation and object recognition , computing pixel - accurate saliency values to uniformly highlight foreground objects becomes increasingly important . in this paper </S>",
    "<S> , we propose a unified framework called pisa , which stands for pixelwise image saliency aggregating various bottom - up cues and priors . </S>",
    "<S> it generates spatially coherent yet detail - preserving , pixel - accurate and fine - grained saliency , and overcomes the limitations of previous methods which use homogeneous superpixel - based and color only treatment . </S>",
    "<S> pisa aggregates multiple saliency cues in a global context such as complementary color and structure contrast measures with their spatial priors in the image domain . </S>",
    "<S> the saliency confidence is further jointly modeled with a neighborhood consistence constraint into an energy minimization formulation , in which each pixel will be evaluated with multiple hypothetical saliency levels . instead of using global discrete optimization methods </S>",
    "<S> , we employ the cost - volume filtering technique to solve our formulation , assigning the saliency levels smoothly while preserving the edge - aware structure details . </S>",
    "<S> in addition , a faster version of pisa is developed using a gradient - driven image sub - sampling strategy to greatly improve the runtime efficiency while keeping comparable detection accuracy . </S>",
    "<S> extensive experiments on a number of public datasets suggest that pisa convincingly outperforms other state - of - the - art approaches . </S>",
    "<S> in addition , with this work we also create a new dataset containing @xmath0 commodity images for evaluating saliency detection .    </S>",
    "<S> k. wang : pisa : pixelwise image saliency by aggregating complementary appearance contrast measures with edge - preserving coherence    visual saliency , object detection , feature engineering , image filtering </S>"
  ]
}