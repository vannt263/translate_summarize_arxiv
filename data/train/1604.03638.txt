{
  "article_text": [
    "covariance structure is of fundamental importance in multivariate analysis and applications . while in the classical low - dimensional setting ,",
    "a usually unknown covariance structure can be estimated by the sample covariance matrix , in the high - dimensional setting , it is now well understood that the sample covariance matrix is not a consistent estimator . furthermore ,",
    "in many applications the observations are contaminated .",
    "below , we explain one such setting that motivates this work .",
    "similar situations arise in many other settings , especially in signal processing ( see , e.g. , @xcite , @xcite , and @xcite ) .",
    "our motivating question arises in the context of estimating the so - called integrated covariance matrix of the high - dimensional diffusion process and has applications to the study of stock price processes .",
    "more specifically , suppose that we have @xmath0 stocks whose ( latent ) log price processes are denoted by @xmath1 for @xmath2 .",
    "let @xmath3 , where @xmath4 denotes the transpose .",
    "a widely used model for @xmath5 is @xmath6 , \\label{diffusion}\\end{aligned}\\ ] ] where @xmath7 is a @xmath0-dimensional drift process , @xmath8 is a @xmath9 matrix for any  @xmath10 called the covolatility process , and @xmath11 is a @xmath0-dimensional standard brownian motion . both @xmath12 and @xmath8 can be stochastic and depend on the brownian motion @xmath11 .",
    "the interval @xmath13 $ ] is the time period of interest , say , one trading day ( = six and a half hours ) .",
    "the integrated covariance ( icv ) matrix refers to @xmath14 the icv matrix , in particular , its spectrum ( i.e. , its set of eigenvalues ) , plays an important role in financial applications such as factor analysis and risk management .",
    "a classical estimator of the icv matrix is the so - called realized covariance ( rcv ) matrix , which relies on the assumption that @xmath5 could be observed at high frequency . more specifically ,",
    "suppose that @xmath5 could be observed at time points @xmath15 for @xmath16 .",
    "then , the rcv matrix is defined as @xmath17where @xmath18 stands for the vector of log returns over the period @xmath19 $ ] . the consistency and central limit theorems for the rcv matrix under such a setting _ and _ when the dimension @xmath0 is fixed are well known ; see , for example , @xcite , @xcite , @xcite , @xcite , @xcite , among others .    to obtain a better understanding of the above setting , it is instructive to connect it with the usual multivariate analysis setting . in the simplest case , when @xmath20 and @xmath21 , we have ( 1 ) @xmath22 ; ( 2 ) the returns @xmath23 , where @xmath24 , and @xmath25 .",
    "in other words , this simplest setting is equivalent to an observation setting in multivariate analysis , where the sample covariance matrix is used to estimate the population covariance matrix . in general",
    ", this situation is more complicated because both @xmath12 and @xmath8 can be stochastic and dependent on the underlying brownian motion .",
    "the so - called market microstructure noise presents another challenge . in practice ,",
    "the observed prices are always contaminated versions of the latent prices , the error being referred to as market microstructure noise .",
    "such noise is induced by various frictions in the trading process such as the bid - ask spread and the discreteness of price . despite its small size",
    ", market microstructure noise accumulates at high frequency and badly affects inferences about the latent price processes .",
    "@xcite compare various volatility estimators and point out that microstructure noise is not negligible when the sampling frequency is higher than one observation per five minutes .",
    "the following additive model has been widely adopted in recent studies on volatility estimation : @xmath26 where @xmath27 denotes the observations and @xmath28 denotes the noise , which is independent of @xmath5 with @xmath29 and certain covariance matrix @xmath30 . observe that under , the observed log - returns @xmath31 relate to the true log - returns @xmath32 by the following equation : @xmath33 where , as usual , @xmath34 .",
    "we are therefore in a noisy observation setting in which the observations are contaminated by additive noise .",
    "such a setting forms the basis of the current work .",
    "one striking feature in that differs from most noisy observation settings is that as the observation frequency @xmath35 goes to infinity , the signal , namely , the true log - return @xmath32 becomes diminishingly small , while the noise @xmath36 remains being of the same order of magnitude .",
    "therefore , the signal - to - noise ratio goes to 0 .",
    "a direct consequence is that even when the dimension is @xmath37 , the optimal rate for estimating @xmath38 is only @xmath39 instead of the usual  @xmath40 ; see @xcite .",
    "in other words , due to the _ dominance of noise over signal _ , the `` effective sample size '' is only @xmath41 rather than  @xmath35 .",
    "this can be clearly seen from the preaveraging method that we will explain in section [ ssec : preaveraging ] .",
    "while the problem above constitutes our main motivation for considering a signal - plus - noise observation setting , our results are not restricted to this particular application .",
    "our first main result , theorem [ thm : lsd_signal_noise ] , applies to a general setting where the signal and noise are of the same order of magnitude .",
    "our main goal is to make inferences about the spectral distribution of the underlying population covariance matrix , in the setting above , the @xmath38 matrix , based on the noisy observations  @xmath42 as in .",
    "we provide two approaches , which we summarize as follows .",
    "approach i requires two steps .",
    "we shall introduce an intermediate matrix , @xmath43 as defined in below .",
    "think of the @xmath38 matrix as the underlying population covariance matrix . because our observations are contaminated , the resulting sample covariance matrix is a signal - plus - noise sample covariance matrix .",
    "the intermediate matrix @xmath43 is a sample covariance matrix based on only signals .",
    "the two steps are then    * step 1 : derive the stieltjes transform of the spectral distribution of  @xmath43 based on the signal - plus - noise sample covariance matrix . * step 2 : based on the derived stieltjes transform of @xmath43 in step 1 , further consistently estimate the spectral distribution of @xmath38 .",
    "the two steps rely on two asymptotic results , theorems [ thm : lsd_signal_noise ] and [ thm : main ] , respectively .",
    "roughly speaking , theorem [ thm : lsd_signal_noise ] enables us to make inferences about the signal sample covariance based on noisy observations , and theorem [ thm : main ] allows us to go further back to the population covariance matrix .",
    "approach ii is more direct .",
    "it makes use of some special properties in the setting that we described in section [ ssec : motivation ] .",
    "the properties allow us to asymptotically eliminate the effect of noise , thus saving us from step i above and enabling us to take only one step , which relies on theorem [ thm : b_n ] .",
    "we also see below that approach ii is more robust , particularly in that it allows for rather general dependence structures in the noise process , both cross - sectional and temporal , and even dependence between the noise and price process .",
    "the drawback is that approach  ii heavily relies on the setting in section [ ssec : motivation ] , while approach  i can be applied to wider situations involving noisy observations .    in the simulation studies , we explain in detail how to generalize the algorithm proposed by @xcite to implement the estimation procedure in practice .",
    "we can see that approaches i and ii both yield satisfactory estimates of the spectral distribution of the targeting icv matrix .",
    "other algorithms , such as those introduced in @xcite , @xcite and @xcite , can also be adapted to our setting .",
    "the rest of the paper is organized as follows .",
    "section [ sec : main_result ] explains the two approaches and the underlying theories .",
    "section [ sec : simulation ] demonstrates how to implement the two approaches in practice .",
    "section [ sec : conclusion ] concludes .",
    "the proofs are given in the supplementary article @xcite .",
    "* notation .",
    "* for any @xmath9 hermitian matrix @xmath44 with eigenvalues @xmath45 , its empirical spectral distribution ( esd ) is defined as @xmath46 the limit of esd as @xmath47 , if it exists , is referred to as the limiting spectral distribution , or lsd for short ; see , for example , the book @xcite . for any real matrix @xmath48 , @xmath49 denotes its spectral norm , where @xmath50 denotes the largest eigenvalue . for any nonnegative definite matrix @xmath51",
    ", @xmath52 denotes its square root matrix . for any @xmath53 , write @xmath54 and @xmath55 as its real and imaginary parts , respectively , and @xmath56 as its complex conjugate . for any distribution @xmath57",
    ", @xmath58 denotes its stieltjes transform , which is defined as @xmath59 in particular , the stieltjes transform of @xmath60 above , denoted by @xmath61 , is given by @xmath62 where @xmath63 is the identity matrix .",
    "finally , for any vector @xmath64 , @xmath65 stands for its euclidean norm .",
    "the pre - averaging ( pav ) method is introduced in @xcite , @xcite , and @xcite to deal with microstructure noise .",
    "other approaches include the two / multi - scales estimators @xcite , realized kernel @xcite , and quasi - maximum likelihood method @xcite .",
    "we use a slight variant of the pav approach in this work .",
    "first , choose a window length @xmath66 .",
    "then , group the intervals @xmath67 $ ] for @xmath68 into @xmath69 pairs of non - overlapping windows , each of width @xmath70 , where @xmath71 represents rounding down to the nearest integer .",
    "introduce the following notation for any process @xmath72",
    ", @xmath73 with such notation , the observed return based on the pre - averaged price becomes @xmath74    one key observation is that if @xmath66 is chosen to be of order @xmath40 ( which is the order chosen in @xcite , @xcite , and @xcite ) , then , in , the `` signal '' @xmath75 and `` noise ''  @xmath76 can be shown to be of the same order of magnitude .",
    "observe that with such a chosen window width , the resulting number of windows is only of order  @xmath40 ; hence our statement earlier that the effective sample size is only  @xmath41 and consequently , even in the one - dimensional case , the optimal rate of convergence for estimating @xmath38 is only @xmath77 .",
    "our starting point is the pav matrix , which is defined as a multiple of the sample covariance matrix of @xmath78 , the returns based on the pre - averaged prices : @xmath79 ( coefficient 3 is inherited from @xcite and comes from the convergence below . )",
    "this is slightly different from the estimator in @xcite , particularly in that there is no bias correction term involved .",
    "this is because ( 1 ) in the high - dimensional setting , even with the bias correction , the pav is still inconsistent , just as in high - dimensional multivariate analysis the sample covariance matrix is inconsistent ; and ( 2 ) our version of the pav facilitates further analysis , which leads us all the way back to the target @xmath38 .    the matrix @xmath80 can be viewed as the sample covariance matrix based on observations @xmath81 , which model the situation of the information vector @xmath82 being contaminated by additive noise @xmath83 . @xcite",
    "consider such signal - plus - noise sample covariance matrices as @xmath84 where @xmath85 indicates a matrix consisting of signals , while @xmath86 , independent of @xmath87 , consists of noise .",
    "let @xmath88 be the signal sample covariance matrix . under certain regularity conditions , the authors show that if @xmath89 converges to a probability distribution @xmath90 , then so does @xmath91 .",
    "they further show that the lsd of @xmath92 is determined by @xmath90 in that its stieltjes transform @xmath93 uniquely solves the following equation @xmath94 where @xmath95 are given in assumptions and below .",
    "our goal in this article , as in many other applications , is to make inferences about signals based on noisy observations ; in this case , to make inferences about @xmath96 based on @xmath92 .",
    "this motivates us to investigate the problem from a different angle than @xcite .",
    "unlike , which states how the lsd of @xmath92 depends on that of  @xmath96 , we show how the lsd of @xmath96 depends on that of @xmath92 ; see equation below .",
    "we further explain how such a relation enables us to consistently estimate the esd of  @xmath96 based on @xmath92 .",
    "the relation that we establish is essentially an inverse relation of  .",
    "inverting such relations is in general notoriously difficult .",
    "for example , the marenko - pastur equation , which is similar to equation   and describes how the lsd of the sample covariance matrix depends on that of the population covariance matrix , is established long time ago in @xcite , but it was after more than forty years that researchers realized how the ( unobservable ) esd of the population covariance matrix can be recovered based on the ( observable ) esd of the sample covariance matrix ( @xcite ) . in particular , @xcite derived an inverse formula for estimating individual population eigenvalues , under the assumption that the population covariance matrix admits only finitely many distinct eigenvalues with known multiplicity .",
    "our first result , theorem  [ thm : lsd_signal_noise ] below , gives an inverse relation of that allows the derivation of the esd of @xmath96 based on that of @xmath92 , under rather general assumptions .",
    "we impose the following assumptions on the underlying matrices .",
    "assumptions and are from @xcite ; in particular , is about the convergence of the esd of the signal sample covariance matrix .",
    "assumption allows the variance of noise to depend on @xmath35 as in the case of pav .",
    "assumption is standard in the studies of random matrices .",
    "[ asm : fa_conv ] @xmath97 is @xmath98 , independent of @xmath99 , and with @xmath100 , @xmath101 , where @xmath90 is a probability distribution with the stieltjes transform denoted by @xmath102 ;    [ asm : sigma_n_conv ] @xmath103 with @xmath104 ;    [ asm : eps ] @xmath105 is @xmath98 with the entries @xmath106 being and centered with unit variance ; and    [ asm : yn_conv ] @xmath107 with @xmath108 as @xmath47 .",
    "we now present our first result about how the lsd of @xmath96 depends on that of @xmath92 .",
    "[ thm : lsd_signal_noise][thm1 ] suppose that assumptions - hold .",
    "then , almost surely , the esd of @xmath92 converges in distribution to a probability distribution  @xmath57 .",
    "moreover , if @xmath57 is supported by a finite interval @xmath109 $ ] with @xmath110 and possibly has a point mass at 0 , then @xmath90 can be identified as follows . for all @xmath111",
    "such that @xmath112 , @xmath113 uniquely solves the following equation @xmath114    [ rmk : alpha_range ] the restriction on @xmath113 to be in @xmath115 is such that the integral on the right hand side of is well - defined .",
    "note that because @xmath116 and @xmath117 as @xmath118 , @xmath113 does belong to @xmath115 for all @xmath119 with @xmath55 sufficiently large .",
    "furthermore , by the uniqueness of analytic continuation , knowing the values of @xmath113 for @xmath119 with @xmath55 sufficiently large is sufficient to determine @xmath113 for all @xmath120    let us explain how theorem [ thm : lsd_signal_noise ] can be used to make inferences about signals based on noisy observations .    * in practice , we observe noisy observations and can compute @xmath121 and hence its esd .",
    "we can then replace @xmath57 in with @xmath122 and solve for @xmath123 .",
    "the empirical version of can be solved numerically using , for example , the r package `` rootsolve . ''",
    "the uniqueness of the solution to equation   is theoretically justified using analytic tools . for its empirical version ,",
    "we prove that if @xmath124 solves the empirical version , then it is close to the true @xmath125 ( see appendix [ appendix : claim ] ) .",
    "this property guarantees that even if the empirical version of admits multiple solutions , they are all close to the true one . consequently , because @xmath123 fully characterizes the esd of @xmath96 , the estimated @xmath123 enables us to consistently estimate the esd . in the simulation studies , we explain in detail how to implement this procedure in practice . * more importantly , to further estimate the esd of the population covariance matrix , in the next step to be developed , we need @xmath123 . theorem [ thm : lsd_signal_noise ] provides such a necessary input .",
    "this is an important outcome of establishing the inverse relation .    in practice ,",
    "if we are only interested in estimating the spectral distribution of the population covariance matrix , then , because in the second step we only need @xmath123 , there is actually no need to estimate the esd of @xmath96 . in the simulation studies ,",
    "we still include this part but only for the purpose of illustrating the application of theorem [ thm : lsd_signal_noise ] .",
    "we now apply theorem [ thm : lsd_signal_noise ] to our pav matrix .",
    "as mentioned in the summary in section [ ssec : summary ] , in step 1 , we relate the pav matrix to an intermediate matrix @xmath43 defined as follows : @xmath126 it differs from the pav matrix in that it does not involve the noise and can be regarded as a signal sample covariance matrix .",
    "the assumptions under our setting analogous to - for theorem [ thm : lsd_signal_noise ] are then as follows .",
    "[ asm : a_conv ] the esd of @xmath43 converges to a probability distribution @xmath90 with the stieltjes transform denoted by @xmath113 ;    [ asm : noise ] the noise @xmath127 are independent of @xmath5 and are i.i.d . with zero mean and covariance matrix @xmath128 for some @xmath129 and @xmath130 as @xmath47 ;    [ asm : k_pav ] @xmath131 for some @xmath132 , and",
    "@xmath133 satisfies @xmath134 .",
    "we then have the following corollary as a direct consequence of theorem  [ thm : lsd_signal_noise ] .",
    "[ cor : a_pav ] suppose that for all @xmath0 , @xmath5 is a @xmath0-dimensional process satisfying .",
    "suppose also that assumptions - hold .",
    "then , almost surely , the esd of pav defined in converges to a probability distribution @xmath57 .",
    "moreover , if @xmath57 is supported by a finite interval @xmath109 $ ] with @xmath110 and possibly has a point mass at 0 , then @xmath90 can be identified as follows .",
    "for all @xmath111 such that @xmath135 , @xmath113 uniquely solves the following equation @xmath136    [ rmk : thm_apply_general_case ] although corollary [ cor : a_pav ] is stated for the case when noise components have the same standard deviations , it can readily be applied to the case when the covariance matrix @xmath30 is a general diagonal matrix , say , @xmath137 . to see this , let @xmath138 .",
    "we can then artificially add additional @xmath139 to the original observations , where @xmath139 are independent of @xmath140 and are with zero mean and covariance matrix @xmath141 .",
    "the noise components in the modified observations then have the same standard deviation @xmath142 , and corollary [ cor : a_pav ] can be applied .",
    "note that the variances , @xmath143 , can be consistently estimated ; see , for example , theorem a.1 in @xcite .",
    "a similar remark applies to theorem [ thm : lsd_signal_noise ] .",
    "step 1 enables us to infer the spectral distribution of @xmath43 based on @xmath80 .",
    "however , just as in high - dimensional multivariate analysis where the sample covariance matrix is not consistent , neither is @xmath43 .",
    "this is why we need this second step , which enables us to go further back to the @xmath38 matrix .",
    "first , we introduce some structural assumptions on the latent process @xmath144 in order to go further .",
    "note that the term @xmath145 in can be written in a more clear form by using the triangular kernel : @xmath146 based on this , it can be shown that if the dimension @xmath0 is fixed , then , as @xmath147 , @xmath148 it is also easy to verify that @xmath149 where @xmath150s are random vectors with mean zero and covariance matrix  @xmath30",
    ".    corollary [ cor : a_pav ] in step 1 allows us to consistently estimate the esd of  @xmath43 . in light of the convergence",
    ", it would have been sufficient for us to make inferences about the icv if the convergence also held in the high - dimensional case .",
    "unfortunately , this is not the case , and a further step to go from @xmath43 to  is needed .",
    "such an inference is generally impossible , as can be seen in the following .",
    "is an integral @xmath151 . in the simple situation where @xmath152 and @xmath153 is deterministic , the building blocks in defining @xmath43 , @xmath154 , are multivariate normals with mean 0 and covariance matrices @xmath155 the bottom line is all the @xmath35 covariance matrices , @xmath156 for @xmath157 , could be very different from the !",
    "we can easily change the @xmath35 covariance matrices @xmath156 and hence the distributions of @xmath154 _ without _ changing . and as both the dimension @xmath0 and observation frequency @xmath35 go to infinity , there is too much freedom in the underlying distributions , which makes inferences about   impossible .",
    "certain structural assumptions are necessary to turn the impossible possible .",
    "the simplest is to assume that @xmath158 , in which case @xmath154 are the apparent drawback of this assumption is that it can not capture stochastic volatility , which is a stylized feature in financial data .",
    "the following class of processes , introduced in @xcite , accommodates both stochastic volatility and the leverage effect while still making the inference about   possible ( and the theory is already much more complicated than the observation setting ) .",
    "[ classc ] suppose that @xmath159 is a @xmath0-dimensional process satisfying  ( [ diffusion ] ) .",
    "we say that @xmath159 belongs to class @xmath160 if , almost surely , there exist @xmath161;{{\\mathbb r}})$ ] and @xmath162 a @xmath9 matrix satisfying tr@xmath163 such that @xmath164 where @xmath165;{{\\mathbb r}})$ ] stands for the space of cdlg functions from @xmath13 $ ] to @xmath166 .",
    "[ rmk : ga_lam ] the convention that tr@xmath163 is made to resolve the non - identifiability built into the formulation , in which one can multiply @xmath167 and divide @xmath162 by a same constant without modifying the process  @xmath8 .",
    "it is thus not a restriction .",
    "class @xmath160 incorporates some widely used models as special cases :    * the simplest case is when the drift @xmath152 and @xmath168 , in which case the returns @xmath169 are @xmath170 . * more generally , again , when the drift @xmath152 while @xmath171 is independent of the underlying brownian motion @xmath11 , the returns @xmath169 follow mixed normal distributions . * * mixed normal distributions , or their asymptotic equivalent form in the high - dimensional setting , elliptic distributions ( see section  2 of @xcite for the asymptotic equivalence ) , have been widely used in financial applications .",
    "@xcite state that `` elliptical distributions ... provided far superior models to the multivariate normal for daily and weekly us stock - return data '' and that `` multivariate return data for groups of returns of a similar type often look roughly elliptical . ''",
    "* * more recently , el karoui , in a series of papers @xcite , studied the markowitz optimization problem under the setting that the returns follow mixed normal / elliptic distributions . * furthermore , class @xmath160 allows the drift @xmath12 to be non - zero and more importantly , the @xmath172 process to be stochastic and even dependent on the brownian motion @xmath11 that drives the price process , thus featuring the so - called leverage effect in financial econometrics .",
    "the leverage effect is an important stylized fact of financial returns and has drawn a great deal of attention in recent years ; see , for example , @xcite and @xcite .",
    "observe that if @xmath173 belongs to class @xmath160 , then the icv matrix @xmath174 furthermore , if the drift process @xmath175 and @xmath172 is independent of @xmath176 , then , conditional on @xmath171 and using , we have @xmath177 where @xmath178 consists of independent standard normals and @xmath179 it follows that @xmath180    we now explain how to make further inferences about the  matrix based on @xmath43 .",
    "doing so relies on another asymptotic result which relates @xmath43 to .",
    "we impose the following assumptions on the underlying process .",
    "they are inherited from proposition 5 of @xcite , and we refer the readers to that article for further background and explanations .",
    "observe in particular that assumption allows the covolatility process to be dependent on the brownian motion that drives the price processes .",
    "such dependence allows us to capture the leverage effect .",
    "assumptions and concern the spectral norm of the  matrix .",
    "we do not require the norm to be bounded , which allows , for example , spike eigenvalues .",
    "* assumption c : *    [ asm : x_in_c ] for all @xmath0 , @xmath159 is a @xmath0-dimensional process in class @xmath160 for some drift process @xmath181 and covolatility process @xmath182 ;    [ asm : mu_bdd ] there exists @xmath183 such that for all @xmath0 and all @xmath2 , @xmath184 for all @xmath185 almost surely ;    [ asm : sigma_conv ] as @xmath47 , the esd of @xmath186 converges to a probability distribution @xmath187 ;    [ asm : sigma_bdd ] there exist @xmath188 and @xmath189 such that for all @xmath0 , @xmath190 almost surely ;    [ asm : leverage ] there exists a sequence of index sets  @xmath191 satisfying @xmath192 and @xmath193 such that @xmath172 may depend on @xmath176 but only on @xmath194 ;    [ asm : gamma_conv ] there exists @xmath195 such that for all @xmath0 and for all @xmath185 , @xmath196 almost surely , and additionally , almost surely , @xmath171 converges uniformly to a nonzero process @xmath197 that is piecewise continuous with finitely many jumps .",
    "we then have the following result connecting @xmath43 with .",
    "[ thm : main][thm2 ] suppose that assumptions - and hold , then as @xmath47 ,    the esds of  and @xmath43 converge to probability distributions @xmath198 and  @xmath90 respectively , where @xmath199    @xmath90 and @xmath198 are related as follows : @xmath200 where @xmath201 and another function @xmath202 uniquely solve the following equations in @xmath203 @xmath204    equation in theorem [ thm : main ] forms the basis for us to further estimate the esd of @xmath38 .",
    "it involves an unknown function @xmath201 , which can be solved as follows .",
    "first note that multiplying @xmath202 and @xmath201 on both sides of the first and second equations in , respectively , yields @xmath205 where the last step is due to .",
    "it follows that @xmath206 and @xmath207 substituting the last expression of @xmath202 into equation yields @xmath208 @xmath201 is then obtained by plugging in the @xmath209 that we derived in step 1 into and solving for the solution that is unique in @xmath210 by theorem 1 in @xcite .",
    "having solved @xmath201 , we can then utilize equation to estimate the esd of   by generalizing the algorithms in @xcite , @xcite , @xcite and @xcite the resulting estimate can be shown to be consistent by using an argument similar to that for theorem 2 of @xcite . the estimation procedure is explained in detail in the simulation studies .",
    "the second step in approach i involves the process  @xmath211 which is unknown in practice . estimating this process inevitably introduces an additional source of error .",
    "motivated by this consideration , we draw ideas from @xcite and develop an alternative approach that overcomes this difficulty .",
    "it is also worth mentioning that the alternative approach allows for rather general dependence structures in the noise process , both cross - sectional and temporal , and even dependence between the noise and price process .",
    "the temporal dependence between microstructure noise has been documented in recent studies ; see , e.g. , @xcite , @xcite and @xcite .",
    "we shall define a matrix that is an extension of the time - variation adjusted rcv matrix introduced in @xcite to our noisy setting .",
    "to start , fix an @xmath212 and @xmath132 , and let @xmath213 and @xmath214 .",
    "the time - variation adjusted pav matrix is then defined as @xmath215 where @xmath216    note that here , the window length @xmath66 has a higher order than in theorem  [ thm : main ] .",
    "the reason is that , after pre - averaging , the underlying returns are @xmath217 and the noises are @xmath218 . in theorem",
    "[ thm : main ] , we balance the orders of the two terms by choosing @xmath219 ; here we take @xmath220 for some @xmath221 , which enables us to asymptotically eliminate the effect of noise .    next , recall the concept of @xmath222-mixing coefficients .",
    "[ rho_corr ] suppose that @xmath223 is a stationary time series .",
    "for @xmath224 , let @xmath225 be the @xmath226-field generated by the random variables @xmath227 .",
    "the @xmath222-mixing coefficients are defined as @xmath228 where , for any probability space @xmath229 , @xmath230 refers to the space of square - integrable , @xmath229-measurable random variables .",
    "we now introduce a number of assumptions .",
    "assumption   below says that we allow for rather general dependence structures in the noise process , both cross - sectional and temporal .",
    "we actually do not put any restrictions on the cross - sectional dependence , and even dependence between the noise and price process is allowed .",
    "note also that @xcite provides an approach to estimate the decay rate of the @xmath222-mixing coefficients .",
    "assumption   concerns the dependence between the covolatility process and the brownian motion that drives the price processes .",
    "assumption is about the boundedness of individual volatilities .",
    "[ asm : eps_general ] for all @xmath231 , the noise @xmath232 is stationary , has mean 0 and bounded @xmath233th moments , and has @xmath222-mixing coefficients @xmath234 satisfying @xmath235 for some integer @xmath236 ;    [ asm : leverage_2 ] there exist @xmath237 and a sequence of index sets @xmath191 satisfying @xmath238 and @xmath239 such that @xmath171 may depend on @xmath11 but only on @xmath240 ;    [ asm : gamma_bdd ] there exists @xmath188 such that for all @xmath0 , @xmath241 for all @xmath242 almost surely ;    [ asm : vol_bdd ] there exists @xmath195 such that for all @xmath0 and all @xmath243 , the individual volatilities @xmath244 for all @xmath245 $ ] almost surely ;    [ asm : sigma_bdd_2 ] there exist @xmath246 and @xmath247 such that for all @xmath0 , @xmath248 almost surely ;    the @xmath249 in and @xmath250 in satisfy that @xmath251 ;    [ asm : ym_conv ] @xmath252 for some @xmath132 and @xmath253 , and @xmath133 satisfy @xmath254 , where @xmath255 is the integer in .",
    "[ rmk : compatibility ] careful readers may have noted that assumptions and are mathematically incompatible , as assumption requires @xmath256 while assumption requires @xmath257 for some @xmath258 .",
    "the two assumptions are , however , perfectly compatible in practice when we deal with finite samples .",
    "take the choices of @xmath259 in the simulation study in section [ ssec : sim_syn ] below for example .",
    "there , we take @xmath260 . when applying corollary [ cor : a_pav ] and theorem [ thm : main ] , we take @xmath261 , which leads to @xmath262 in assumption ; when applying theorem [ thm : b_n ] below , we take @xmath263 , which gives @xmath264 in assumption .",
    "we have the following convergence result connecting @xmath265 with icv .",
    "[ thm : b_n][thm3 ] suppose that assumptions ( [ asm : x_in_c ] ) , ( [ asm : mu_bdd ] ) , , , and - hold .",
    "then , as @xmath47 , the esds of @xmath38 and @xmath265 converge almost surely to probability distributions @xmath198 and @xmath266 , respectively , where @xmath198 satisfies and @xmath266 is determined by @xmath198 in that its stieltjes transform , denoted by @xmath267 , satisfies the following ( standard ) marenko - pastur equation @xmath268    theorem [ thm : b_n ] states that the lsds of icv and @xmath265 are related via the marenko - pastur equation .",
    "several algorithms have been developed to consistently recover @xmath198 by inverting the marenko - pastur equation ; see , for example , @xcite we can therefore consistently estimate the esd of icv by using these existing algorithms .      in multivariate high - frequency data analysis , in addition",
    "to microstructure noise , there is another challenge due to asynchronous trading . in practice ,",
    "different stocks are traded at different times ; consequently , the tick - by - tick data are not observed synchronously .",
    "there are several existing methods for synchronizing data , such as the refresh times @xcite and previous tick methods @xcite .",
    "asynchronicity is less of an issue than microstructure noise .",
    "for example , as pointed out in @xcite , asynchronicity does not induce bias in the two - scales estimator , and even the asymptotic variance is the same as if there is no asynchronicity . while a rigorous treatment is beyond the scope of this article",
    ", we expect our methods to work for asynchronous data as well .",
    "the reason , roughly speaking , is as follows .",
    "take the previous tick method for example . here , we choose a ( usually equally spaced ) grid of time points @xmath269 , and for each stock @xmath243 , for each time point  @xmath270 , let  @xmath271 be the latest transaction time before @xmath270 .",
    "one then acts as if one observes  @xmath272 at time @xmath270 for stock @xmath243 . with the original additive model at time",
    "@xmath271 : @xmath273 we have at time @xmath270 , @xmath274 in other words , the asynchronicity induces an additional error @xmath275 .",
    "the error is , however , diminishingly small as the sampling frequency @xmath147 because @xmath276 . in short",
    ", asynchronicity induces an additional error ( and violates our model assumption ) ; fortunately , the error is of negligible order compared with the microstructure noise @xmath277 .",
    "we therefore keep our focus on the model . in simulation studies , in addition to the synchronous observation setting , we consider an asynchronous setting where the observation times for different stocks are independent poisson processes .",
    "we shall see that our methods still work well ( see section [ ssec : sim_asyn ] for more details ) .",
    "in this section , we demonstrate how to estimate the esd of icv by using approach i , which uses the pav matrix , and approach ii , which uses the alternative matrix @xmath265 .",
    "we first consider a setting where observations are synchronous . to generate the underlying process @xmath144 , the process @xmath171 in definition [ classc ]",
    "is taken to be a stochastic u - shaped @xmath171 process as follows : @xmath278,\\ ] ] where @xmath279 , @xmath280 , @xmath281 and @xmath282 with @xmath283 being the @xmath284th component of the brownian motion @xmath11 that drives the price process .",
    "observe that such a formulation makes @xmath171 dependent on _ all _ the component of the underlying brownian motion ; hence , assumptions and are both violated .",
    "however , we shall see that our methods still work well .",
    "a sample path of @xmath171 is given in figure [ fig : gamma_t ] in the supplementary article of @xcite .",
    "next , the matrix @xmath186 is taken to be @xmath285 , where @xmath286 is a random orthogonal matrix and @xmath287 is a diagonal matrix whose diagonal entries are drawn independently from the beta@xmath288 distribution .",
    "such generated @xmath289 does not necessarily have trace @xmath0 , but as we pointed out in remark [ rmk : ga_lam ] , the assumption @xmath290 is a convention rather than a requirement . with such @xmath171 and @xmath289 ,",
    "the individual daily volatilities are around @xmath291 , which is similar to what one observes in practice .",
    "the latent log price process @xmath5 follows @xmath292 finally , the noise @xmath127 is taken to be @xmath293 .    in the studies below , the dimension , that is , the number of stocks @xmath0 , is taken to be 100 , and the observation frequency @xmath35",
    "is set to be 23,400 , which corresponds to one observation per second on a regular trading day .",
    "note again that because of the presence of noise , the `` effective sample size '' is only of order @xmath294 , which is comparable to our chosen @xmath295 .",
    "we start with approach i , which involves two steps .    in the first step ,",
    "we replace @xmath57 in equation with the esd of pav and solve for @xmath209 using the r package `` rootsolve . ''",
    "the window length  @xmath66 in defining pav is set to be @xmath296 . as to the @xmath209 to be solved ,",
    "we choose a set of @xmath119 s whose real and imaginary parts are equally spaced in the intervals @xmath297 $ ] and @xmath298 $ ] , respectively .",
    "denote these @xmath119 s by @xmath299 and the estimated @xmath300 by @xmath301 .",
    "we then need to estimate the esd of  @xmath43 based on @xmath302 , which we do as follows .",
    "inspired by the nonparametric estimation method proposed in @xcite , we approximate @xmath303 with a weighted sum of point masses @xmath304 where @xmath305 is a grid of points to be specified and the @xmath306s are weights to be estimated . to choose the grid @xmath307 , naturally , we would like @xmath308 $ ] to cover the support of @xmath303 , which is unknown . to overcome this difficulty , note that the support of the esd of pav always covers that of @xmath43",
    "; hence , we can choose @xmath309s to be equally spaced between 0 and the largest eigenvalue of pav , and we are guaranteed that @xmath308 $ ] covers the support of @xmath303 .    next we discuss how to estimate the weights @xmath310 in .",
    "observe that the discretization   gives an approximate stieltjes transform of @xmath303 as @xmath311 let @xmath312 be the approximation errors .",
    "the weights @xmath313 are then estimated by minimizing the approximation errors : @xmath314    next , in step 2 , we estimate the esd of icv . by plugging in the @xmath302 obtained in the first step and solving equation",
    ", we obtain @xmath315 .",
    "the estimation of the esd of  is then conducted similarly as above as follows .",
    "discretize the esd of @xmath38 as @xmath316 where @xmath317s are again weights to be estimated . by equation",
    ", we expect that @xmath318 to be small .",
    "the @xmath317s are then estimated by minimizing the approximation errors @xmath319 just as in .",
    "figures [ fig : thm1 - 2 ] and [ fig : thm1 - 2 - 2 ] below illustrate the estimation results .",
    "the left plot of figure [ fig : thm1 - 2 ] shows three esds , those of , @xmath43 , and pav .",
    "the three curves are clearly different from each : the difference between pav and  @xmath43 is induced by noise , while that between @xmath43 and  is caused by high - dimensionality .",
    "note that we only observe the esd of pav , whereas the esds of both  and @xmath43 are underlying .",
    "our goal is to estimate the esd of icv . as we explained below theorem [ thm : lsd_signal_noise ] , such a goal does not require estimating the esd of @xmath43 . here",
    ", we still estimate this esd to illustrate the application of corollary [ cor : a_pav ] .",
    "the estimation of the esd of @xmath43 is conducted in the first step , and the result is shown in the right plot of figure [ fig : thm1 - 2 ] .",
    "the second step estimates the esd of , with the result given in figure [ fig : thm1 - 2 - 2 ] .",
    "based on synchronous noisy observations under model .",
    "the dimension @xmath295 , and the observation frequency @xmath320 .",
    ", title=\"fig : \" ]   based on synchronous noisy observations under model .",
    "the dimension @xmath295 , and the observation frequency @xmath320 .",
    ", title=\"fig : \" ]        figures [ fig : thm1 - 2 ] and [ fig : thm1 - 2 - 2 ] show that the esds of both @xmath43 and   can be estimated quite well .",
    "we now apply approach ii to estimate the esd of . according to theorem [ thm : b_n ] ,",
    "asymptotically , the esd of @xmath265 is related to that of icv through the standard marenko - pastur equation .",
    "this allows us to directly apply existing algorithms that are developed to invert the marenko - pastur equation to estimate the esd of , and in the below we adopt the algorithm proposed in @xcite .    specifically , set the window length @xmath66 in defining @xmath265 to be @xmath321 .",
    "discretize the esd of icv as . according to theorem [ thm : b_n ] ,",
    "the stieltjes transform of the esd of @xmath265 , denoted by @xmath322 , should approximately satisfy equation with @xmath198 replaced with the esd of icv .",
    "in other words , we again expect the approximation errors @xmath323 to be small .",
    "thus , again , we estimate the weights @xmath317 s by minimizing the approximation errors @xmath324 as in .",
    "the estimation results are given in figure [ fig : thm3 ] .",
    "again , we see from the left plot that the esd of @xmath265 clearly differs from the ( latent unobserved ) esd of , yet the right plot shows that we can estimate this latent distribution well .     and the observation frequency @xmath320.,title=\"fig : \" ]   and the observation frequency @xmath320.,title=\"fig : \" ]      we now consider a setting where the observations are asynchronous .",
    "more specifically , for each stock @xmath2 , we simulate a poisson process of rate 23,400 denoted by @xmath325 because the poisson processes @xmath326 are to be generated independently , almost surely , @xmath327 for all @xmath328 and @xmath329 , namely , the observation times are all different for different stocks .",
    "figure [ fig : poisson ] in the supplementary article @xcite shows the observation times for three stocks generated in such a way during the first ten seconds .",
    "the observation times are highly irregularly spaced : there can be several seconds without a single observation , while there can also be several observations within a single second .",
    "furthermore , because observation times for different stocks are generated independently , different stocks are observed in a rather unsynchronized manner , making the estimation of covariances difficult .",
    "for this reason , a synchronization procedure needs to be carried out before we apply either approach i or ii .    before we discuss how to synchronize data , we first continue with the simulation design . to generate the latent process @xmath330 , because of the asynchronicity and high - dimensionality ( we are dealing with @xmath295 independent poisson processes and , consequently , roughly @xmath331 distinct observation times ) , there is a real technical difficulty in incorporating interactions among component processes in the data generating process .",
    "we adopt the following simplified setting to facilitate the simulation .",
    "observe that the results in the previous subsection are achieved when the component processes have dependence , so we believe our mathods would still work when there is asynchronicity _ and _ dependence .",
    "the simplified setting is as follows : @xmath332 where both @xmath333 and @xmath287 are as in the previous subsection .",
    "our observations are @xmath334 where @xmath335 are @xmath336 .",
    "now we discuss how to synchronize data .",
    "we adopt the previous tick method explained in section [ ssec : asyn ] .",
    "more specifically , we choose an equally spaced grid @xmath337 $ ] , and for each @xmath270 , for each @xmath2 , let @xmath338 we then proceed as if we observe @xmath339 at time @xmath270 . as we explained in section  [ ssec : asyn ] , because @xmath340 , such a synchronization procedure introduces an additional error @xmath341 .      the additional error @xmath341 that the synchronization procedure induces depends on the latent process .",
    "for this reason , our independence assumption between the noise and the latent process ( [ asm : noise ] ) is violated . to alleviate this problem ,",
    "we synchronize less frequently so that the signals @xmath342 tend to be bigger and better approximate the true signals @xmath343 .",
    "more specifically , we choose the equally spaced grid to be @xmath344  in other words , we synchronize once every four seconds .",
    "then , following the estimation procedure in section  [ ssec : sim_app_i ] , we have the following results .",
    "based on asynchronous noisy observations under model  .",
    "the dimension is @xmath295 .",
    "the synchronization frequency is 4 seconds , which leads to @xmath345 observations .",
    ", title=\"fig : \" ]   based on asynchronous noisy observations under model  .",
    "the dimension is @xmath295 .",
    "the synchronization frequency is 4 seconds , which leads to @xmath345 observations .",
    ", title=\"fig : \" ]        we see that in such a highly asynchronous noisy observation setting , approach  i still works quite well .",
    "approach ii relies on theorem [ thm : b_n ] , which allows for dependence in the noise process and between the noise and price process .",
    "for this reason , it is more robust than approach i , and we can synchronize more frequently . in the estimation",
    "below we choose to synchronize once every second ; that is , the time grid is taken to be @xmath346 .",
    "then , following the estimation procedure in section [ ssec : sim_app_ii ] , we obtain the following results .    .",
    "the synchronization frequency is one second , which leads to @xmath347 observations .",
    ", title=\"fig : \" ] .",
    "the synchronization frequency is one second , which leads to @xmath347 observations .",
    ", title=\"fig : \" ]    again , we see that in such an asynchronous noisy observation setting , approach  ii works quite well .",
    "the two approaches have their own pros and cons .",
    "* approach i is more widely applicable to noisy observation situations .",
    "moreover , in our particular application , because the window width in defining the  matrix is @xmath41 , which is of lower order than that for @xmath265 in approach ii , approach i essentially has a larger `` effective sample size . ''",
    "this approach , however , is more sensitive to the model assumptions . in particular , in the asynchronous observation setting , because of the additional error introduced by asynchronicity , we may need to synchronize less frequently . * approach ii is more direct because it only involves a one - step estimation procedure .",
    "it is also more robust because it allows for rather general dependence structures in the noise process , both cross - sectional and temporal , and even dependence between the noise and price process . for this reason , in the asynchronous setting in section [ ssec : sim_asyn ] , we can use a higher synchronization frequency than for approach i. a major drawback of approach ii is that it relies heavily on some special properties of the particular setting under study and hence may not be applicable to other noisy observation situations .",
    "finally , while in the estimation above we largely adapt the algorithms proposed by @xcite to fit our setting , other algorithms such as those in @xcite , @xcite and @xcite can also be adapted .",
    "motivated by the inference about the spectral distribution of the   matrix based on high - frequency noisy data ,    we establish an asymptotic relationship that describes how the spectral distribution of the signal sample covariance matrices depends on that of the sample covariance matrices constructed from noisy observations ;    using further a ( generalized ) connection between the spectral distribution of the signal sample covariance matrices and that of the population covariance matrix , we propose a two - step procedure that can consistently estimate the spectral distribution of icv for a class of diffusion processes ;    we further develop an alternative approach that possesses several desirable properties : it is more robust , it eliminates the effects of microstructure noise , and the asymptotic relationship that enables the consistent estimation of the spectral distribution of icv is the standard marenko - pastur equation .",
    "numerical studies demonstrate that our proposed methods work well , under both synchronous and asynchronous observation settings .",
    "we are very grateful to the editor , the associate editor , and the anonymous referees for their valuable comments and constructive suggestions , which led to a substantial improvement of this paper .",
    "20 andersen , t. g. , and bollerslev , t. ( 1998 ) .",
    "`` answering the skeptics : yes , standard volatility models do provide accurate forecasts . '' _ international economic review _",
    ", 39 , 885905 .",
    "andersen , t. g. , bollerslev , t. , diebold , f. x. and labys , p. ( 2001 ) .",
    "`` the distribution of realized exchange rate volatility . '' _ journal of the american statistical association _ , 96 , 4255 .",
    "at - sahalia , y. , fan , j. and li , y. ( 2010 ) .",
    "`` the leverage effect puzzle : disentangling sources of bias at high frequency . '' _ journal of financial economics _ , 109 , 224249 .",
    "at - sahalia , y. , fan , j. and xiu , d. ( 2010 ) .",
    "`` high frequency covariance estimates with noisy and asynchronous financial data . ''",
    "_ journal of the american statistical association _",
    ", 105 , 15041517 .",
    "bai , z. , chen , j. and yao , j. ( 2010 ) .",
    "`` on estimation of the population spectral distribution from a high - dimensional sample covariance matrix . ''",
    "_ australian & new zealand journal of statistics _",
    ", 52 , 423437 .",
    "bai , z. , and silverstein , j. ( 2010 ) .",
    "`` spectral analysis of large dimensional random matrices , 2nd edition . '' _ springer , new york . _    barndorff - nielsen , o. e. , hansen , p. r. , lunde a. and shephard n. ( 2008 ) .",
    "`` designing realized kernels to measure ex - post variation of equity prices in the presence of noise . '' _ econometrica _ , 76 , 14811536 .",
    "barndorff - nielsen , o. e. , and shephard n. ( 2002 ) .",
    "`` econometric analysis of realized volatility and its use in estimating stochastic volatility models . '' _ journal of the royal statistical society .",
    "series b. statistical methodology _",
    ", 64 , 253280 .",
    "barndorff - nielsen , o. e. , hansen , p.r . , lunde , a. and shephard n. ( 2011 ) .",
    "`` multivariate realised kernels : consistent positive semi - definite estimators of the covariation of equity prices with noise and non - synchronous trading . ''",
    "_ journal of econometrics _ , 162 , 149169 .",
    "christensen , k. , kinnebrock , s. and podolskij , m. ( 2010 ) .",
    "`` pre - averaging estimators of the ex - post covariance matrix in noisy diffusion models with non - synchronous data . ''",
    "_ journal of econometrics _",
    ", 159 , 116133 .",
    "dozier , r. and silverstein , j. ( 2007a ) .",
    "`` on the empirical distribution of eigenvalues of large dimensional information - plus - noise - type matrices . ''",
    "_ journal of multivariate analysis _ , 98 , 678694 .",
    "dozier , r. and silverstein , j. ( 2007b ) .",
    "`` analysis of the limiting spectral distribution of large dimensional information - plus - noise type matrices . '' _ journal of multivariate analysis _",
    ", 98 , 10991122 .",
    "el karoui , n. ( 2008 ) .",
    "`` spectrum estimation for large dimensional covariance matrices using random matrix theory . ''",
    "_ annals of statistics _ , 36 , 27572790 .",
    "el karoui , n. ( 2009 ) .",
    "`` concentration of measure and spectra of random matrices : applications to correlation matrices , elliptical distributions and beyond . ''",
    "_ annals of applied probability _ , 19 , 23622405 .",
    "el karoui , n. ( 2010a ) .",
    "`` high - dimensionality effects in the markowitz problem and other quadratic programs with linear constraints : risk underestimation . ''",
    "_ annals of statistics _ , 38 , 34873566 .",
    "el karoui , n. ( 2010b ) .",
    "`` on information plus noise kernel random matrices . ''",
    "_ annals of statistics _ , 38 , 31913216 .",
    "el karoui , n. ( 2013 ) .",
    "`` on the realized risk of high - dimensional markowitz portfolios . ''",
    "_ siam j. financial math .",
    "_ , 4 , 737783 .",
    "gloter , a. and jacod , j. ( 2001 ) .",
    "`` diffusions with measurement errors . ii - optimal estimators . ''",
    "_ esaim _ , 5 , 243260 .",
    "hachem , w. , loubaton , p. , mestre , x. , najim , j. and vallet , p. ( 2012 ) .",
    "`` large information plus noise random matrix models and consistent subspace estimation in large senor networks . '' _ random matrices : theory appl _ , 1 , 1150006 .",
    "hansen , p. r. and lunde , a. ( 2006 ) .",
    "`` realized variance and market microstructure noise . ''",
    "_ journal of business and economic statistics _ , 24 , 127161 .",
    "jacod , j. , li , y. , mykland , p. a. podolskij , m. and vetter , m. ( 2009 ) .",
    "`` microstructure noise in the continuous case : the pre - averaging approach . '' _ stochastic process .",
    "_ , 119 , 22492276 .",
    "jacod , j. , and protter , p. ( 1998 ) .",
    "`` asymptotic error distributions for the euler method for stochastic differential equations . ''",
    "_ annals of probability _ , 26 , 267307 .",
    "jacod , j. , li , y. and zheng , x. ( 2017 ) .",
    "`` statistical properties of microstructure noise . ''",
    "available at ssrn : _",
    "http://ssrn.com/abstract=2212119_ , to appear in _",
    "econometrica_.    ledoit , o. , and wolf , m. ( 2015 ) .",
    "`` spectrum estimation : a unified framework for covariance matrix estimation and pca in large dimensions . '' _ journal of multivariate analysis _ , 139 , 360384 .",
    "liu , l. , patton , a. and sheppard , k. ( 2015 ) .",
    "`` does anything beat 5-minute rv ?",
    "a comparison of realized measures across multiple asset classes . '' _ journal of econometrics _",
    ", 187 , 293311 .",
    "marenko , v. a. and pastur , l. a. ( 1967 ) .",
    "`` distribution of eigenvalues in certain sets of random matrices . '' _ mat .",
    "_ , 72 ( 114 ) , 507536 .",
    "mcneil , a. frey , r. and embrechts , p. ( 2005 ) .",
    "`` quantitative risk management : concepts , techniques , and tools . '' _ princeton university press_.    mestre , x. ( 2008 ) .",
    "`` improved estimation of eigenvalues and eigenvectors of covariance matrices using their sample estimates . ''",
    "_ ieee transactions on information theory _",
    ", 54 , 51135129 .",
    "mykland , p. and zhang , l. ( 2006 ) .",
    "`` anova for diffusions and ito processes . ''",
    "_ annals of statistics _ , 34 , 19311963 .",
    "podolskij , m. and vetter , m. ( 2009 ) .",
    "`` estimation of volatility functionals in the simultaneous presence of microstructure noise and jumps . ''",
    "_ bernoulli _ , 15 , 634658 .",
    "silverstein , j. and bai , z. ( 1995 ) .",
    "`` on the empirical distribution of eigenvalues of a class of large - dimensional random matrices . ''",
    "_ journal of multivariate analysis _",
    ", 54 , 175192 .",
    "ubukata , m. and k. oya ( 2009 ) .",
    "`` estimation and testing for dependence in market microstructure noise . '' _ journal of financial econometrics _ , 7 , 106151 .",
    "wang , c. and mykland , p. ( 2014 ) . `` the estimation of leverage effect with high - frequency data . '' _ journal of the american statistical association _ , 109 , 197215 .",
    "xia , n. and zheng , x. ( 2017 ) .",
    "`` supplement to `` on the inference about the spectral distribution of high - dimensional covariance matrix based on high - frequency noisy observations '' . ''",
    "xiu , d. ( 2010 ) .",
    "`` quasi - maximum likelihood estimation of volatility with high frequency data . '' _ journal of econometrics _ , 159 , 235250 .",
    "zhang , l. ( 2006 ) . `` efficient estimation of stochastic volatility using noisy observations : a multi - scale approach . '' _ bernoulli _ , 12 , 10191043 .    zhang , l. ( 2011 ) .",
    "`` estimating covariation : epps effect , microstructure noise . ''",
    "_ journal of econometrics _ , 160 , 3347 .",
    "zhang , l. , mykland , p. and at - sahalia , y. ( 2005 ) .",
    "`` a tale of two time scales : determining integrated volatility with noisy high - frequency data . ''",
    "_ journal of the american statistical association _ , 100 , 13941411 .",
    "zheng , x. and li , y. ( 2011 ) .",
    "`` on the estimation of integrated covariance matrices of high dimensional diffusion processes . ''",
    "_ annals of statistics _ , 39 , 31213151 .    ningning xia : school of statistics and management , shanghai , key laboratory of financial information technology , shanghai university of finance and economics , 777 guo ding road , china , 200433 . xia.ningning@mail.shufe.edu.cn    xinghua zheng : department of information systems business statistics and operations management , hong kong university of science and technology , clear water bay , kowloon , hong kong .",
    "the proposition / lemma / equation numbers below refer to the main article @xcite .",
    "theorem [ thm : lsd_signal_noise ] is a consequence of the following proposition .    [",
    "prop : lsd_signal_noise ] under the assumptions of theorem [ thm : lsd_signal_noise ] , there exists @xmath348 such that almost surely , for all @xmath349 we have @xmath350=0,\\ ] ] where for all sufficiently large @xmath0 , @xmath351 is the unique solution to the equation @xmath352 in the set @xmath353 and @xmath354    in section [ ssec : pf_thm_lsd_signal_noise ] below , we show how proposition [ prop : lsd_signal_noise ] leads to theorem [ thm : lsd_signal_noise ] .    as to the proof of proposition [ prop : lsd_signal_noise ] , we shall use the following results from @xcite . by theorem 1.1",
    "therein , the sequence @xmath355 converges weakly to a probability distribution @xmath57 .",
    "moreover , by using the same truncation and centralization technique as in @xcite , we may assume that    [ asm : eps_bd ] @xmath356 for some @xmath357 ,    [ asm : eps_mean_var ] @xmath358 , @xmath359 , and    [ asm : a_bd ] @xmath360 .",
    "+    in addition to equation , we shall also study its limiting equation @xmath361 where @xmath362 is the stieltjes transform of the probability distribution @xmath57 .",
    "it is shown in @xcite that the distribution @xmath57 admits a continuous density on @xmath363 . because we assume that @xmath57 is supported by a finite interval @xmath109",
    "$ ] with @xmath110 and possibly has a point mass at  0 , we conclude that @xmath57 admits a bounded density  @xmath364 supported by @xmath109 $ ] and possibly a point mass at zero .",
    "[ lem : tn_exist ] there exists @xmath365 such that for all @xmath366 , for all sufficiently large @xmath35 , equation ( [ eqn : t_n ] ) admits a unique solution in @xmath367 .",
    "rewrite equation ( [ eqn : t_n ] ) as @xmath368    first , under the assumptions of theorem [ thm : lsd_signal_noise ] , by theorem 1.1 in @xcite , if we let @xmath369 $ ] be an interval containing the support of  @xmath91 , then we may assume that for all large @xmath35 , @xmath370 .",
    "let @xmath371 , @xmath372 and @xmath373 . because @xmath374 and @xmath375 , we have for all large @xmath35 and for all @xmath376 , @xmath377    define @xmath378 we apply the banach fixed point theorem to show that for all sufficiently large @xmath35 , there exists a unique point @xmath379 such that @xmath380 .",
    "the desired conclusion then follows .",
    "step ( i ) : we prove that the mapping @xmath381 is defined from @xmath382 to @xmath382 . from the definition of @xmath383 and that of @xmath384 , we have @xmath385 and hence for all sufficiently large @xmath35 , by , we have @xmath386 where the last inequality follows from the fact that for any @xmath387 , @xmath388    step ( ii ) : we shall show that @xmath389 is a contraction mapping .",
    "in fact , for any two points @xmath10 , @xmath390 , @xmath391 by the cauchy - schwartz inequality and we get that for all sufficiently large @xmath35 , for all @xmath392 , @xmath393 which is strictly smaller than 1 when @xmath387 . therefore , the mapping @xmath381 is contractive in  @xmath382 , and the banach fixed point theorem guarantees the existence of a unique solution to equation ( [ eqn : t_n ] ) .    [",
    "lem : t_properties ] suppose that @xmath10 solves equation for @xmath111 .",
    "write @xmath394 and @xmath395 . then , @xmath396 ; moreover , as @xmath397 , uniformly in @xmath398 , one has @xmath399 and @xmath400 .",
    "taking imaginary parts on both sides of equation ( [ eqn : t ] ) yields @xmath401 it is then straightforward to verify that @xmath402 and @xmath403 .",
    "furthermore , since @xmath404 when @xmath405 , we have @xmath406    denote @xmath407 and @xmath408 . by , if @xmath57 admits a bounded density @xmath364 and possibly a point mass at 0 , then @xmath409 because @xmath410 is bounded and @xmath411 when @xmath412 , there exists a constant @xmath413 such that @xmath414 this , combined with , implies that @xmath415 in particular , uniformly in @xmath398 , @xmath416 moreover , from ( [ eqn : t ] ) we get @xmath417 thus as @xmath397 , @xmath418 also uniformly in @xmath398 .",
    "[ lem : t_exist ] there exists @xmath419 such that for any @xmath420 , equation admits a unique solution .",
    "first , by the same proof as for lemma [ lem : tn_exist ] , one can show that for all @xmath395 with @xmath421 , equation admits a unique solution in @xmath367 .",
    "moreover , by lemma [ lem : t_properties ] , if @xmath394 solves , then @xmath402 ; furthermore , we can find a constant @xmath422 such that if @xmath10 solves   for  @xmath119 with @xmath423 then we must have @xmath424 .",
    "the latter two properties imply that for all @xmath119 with @xmath425 the solution to must lie in @xmath367 . redefining @xmath426 if necessary",
    ", we see that for all @xmath427 , admits a unique solution .",
    "[ lem : t_analytic ] there exists @xmath428 such that the solution @xmath429 to is analytic on @xmath430 .",
    "define a function @xmath381 as @xmath431 that @xmath432 solves is equivalent to @xmath433 .",
    "write @xmath395 and @xmath394 . by taking the partial derivative with respect to @xmath10",
    "we get @xmath434 note that @xmath435 which , by , goes to zero as @xmath397 .",
    "thus there exists a constant @xmath436 such that for all @xmath437 , @xmath438 .",
    "it follows from the implicit function theorem and lemma  [ lem : t_exist ] that @xmath429 is analytic on @xmath439 .",
    "[ lem : tlimit ] suppose that @xmath351 solves equation for @xmath427 ; then , @xmath440 and @xmath441 . moreover , if @xmath351 is the unique solution in the set @xmath367 , then , with probability one , as @xmath147 , @xmath351 converges to a nonrandom complex number @xmath10 that uniquely solves equation .",
    "write @xmath395 and @xmath442 .",
    "similar to the proof of lemma [ lem : t_properties ] , taking imaginary parts on both sides of equation ( [ eqn : t_n ] ) , one can easily show that @xmath443 and @xmath444 .",
    "next we show that @xmath445 is tight ; in other words , for any @xmath446 , there exists @xmath447 , such that for all sufficiently large @xmath35 , @xmath448 . because @xmath449 , it suffices to show that @xmath450 is tight .",
    "let @xmath451 , and let @xmath452 be the stieltjes transform of the esd @xmath453 .",
    "the spectra of @xmath92 and @xmath454 differ by @xmath455 number of zero eigenvalues ; hence , @xmath456 and @xmath457 thus , equation ( [ eqn : t_n ] ) can also be expressed as @xmath458 taking real parts on both sides yields @xmath459 solving for @xmath460 yields @xmath461    now suppose that @xmath462 is not tight ; then , with positive probability , there exists a subsequence @xmath463 such that @xmath464 . by , we have @xmath465 however , as @xmath66 goes to infinity , if @xmath464 , because @xmath466 is tight and @xmath467 , one gets that the rhs goes to 1 .",
    "this contradicts the supposition that @xmath464 .",
    "next , for any convergent subsequence @xmath468 in set @xmath367 , by , for all sufficiently large @xmath469 , we have @xmath470 .",
    "we can then apply the dominated convergence theorem to conclude that the limit point of @xmath468 must satisfy equation . by lemma [ lem : t_exist ] ,",
    "the solution is unique ; hence , the whole sequence @xmath445 converges to the unique solution to equation  .",
    "let @xmath471@xmath472 for @xmath473 , @xmath422 and @xmath474 as defined in lemmas [ lem : tn_exist ] , [ lem : t_exist ] and [ lem : t_analytic ] , respectively . also define @xmath475 .",
    "below we work with @xmath476 .",
    "let @xmath477 and @xmath478 , @xmath479 , be the @xmath243th column of @xmath97 and @xmath86 , and let @xmath480 .",
    "denote @xmath481 so that @xmath482 . for any complex number @xmath351 such that @xmath483 , define @xmath484    according to equation ( 2.2 ) in @xcite , we have @xmath485 thus , using the identity @xmath486 we obtain @xmath487    next , we introduce another definition of @xmath351 as the solution to the following equation @xmath488 we claim that the definition of @xmath351 in ( [ dfn : t_alternative ] ) is equivalent to the earlier definition of defining @xmath351 to be the solution to equation . in fact , write @xmath489 right - multiplying both sides by @xmath490 and using yield @xmath491 taking the trace on both sides and dividing by @xmath35 , one gets @xmath492 this shows that if @xmath351 satisfies , then @xmath351 satisfies equation . on the other hand , if @xmath351 satisfies equation , from we have @xmath493 namely , @xmath351 satisfies .",
    "we proceed to analyze the difference in . because @xmath494 and recall that @xmath495 and @xmath496 , we have @xmath497    using ( [ rrbeta ] ) , we obtain @xmath498\\\\ & & + \\ \\dfrac{t_n\\sigma_n^2}{p }",
    "\\ { \\rm tr}({\\bf r}_n^{-1}{\\bf b}_n^{-1}).\\end{aligned}\\ ] ] define @xmath499 certainly , @xmath500 , but introducing @xmath501 makes the computations below more clear .",
    "recall that @xmath502 , and so @xmath503 . we can then rewrite @xmath504 as @xmath505 where @xmath506 and in the last equality we used the equivalent definition of @xmath351 .",
    "[ 4lems ] suppose that @xmath351 solves equation ( [ eqn : t_n ] ) for @xmath507 ; then ,    [ betabound ] for all @xmath479 , @xmath508 is bounded by @xmath509 ;    [ bbound ] @xmath510 is bounded by @xmath511 ;    [ rv4 ] the random variables @xmath512 satisfy @xmath513 where @xmath512 can be any of @xmath514 , @xmath515 , @xmath516 and @xmath517 defined in ( [ etaj ] ) , and @xmath413 is a constant independent of @xmath35 ;    [ ww ] the random variables @xmath518 and @xmath519 satisfy @xmath520    we first prove .",
    "write @xmath442 . note that @xmath521{\\pmb\\xi}_j\\\\ = & & \\dfrac{v - t_{n2}\\sigma_n^2}{|z - t_n\\sigma_n^2|^2 } \\ { \\pmb\\xi}_j^t\\left(\\dfrac{1}{z - t_n\\sigma_n^2}{\\bf s}_{nj}-{{\\bf i}}\\right)^{-1 }",
    "{ \\bf s}_{nj}\\left(\\dfrac{1}{\\overline{z - t_n\\sigma_n^2}}{\\bf s}_{nj}-{{\\bf i}}\\right)^{-1}{\\pmb\\xi}_j \\\\ \\geq & & 0,\\end{aligned}\\ ] ] where the last inequality is because of lemma [ lem : tlimit ] .",
    "therefore , @xmath522    as to , note that any eigenvalue of @xmath523 can be expressed as @xmath524 , where @xmath525 is an eigenvalue of @xmath526 .",
    "we have @xmath527 where the last step follows from the fact that @xmath528 because of lemma [ lem : tlimit ] .",
    "now we prove .",
    "we shall only establish the inequality for @xmath529 ; the other two variables @xmath515 and @xmath517 can be handled in a similar way by using  .    because for any hermitian matrix @xmath530 and @xmath111 , @xmath531 , we have by lemma [ lem : tlimit ] that @xmath532    recall that @xmath480 , and @xmath478 satisfies @xmath533 .",
    "the strengthened assumption implies that @xmath534 .",
    "note also that @xmath478 is independent of @xmath535 and @xmath477 .",
    "moreover , using lemma [ xtrx ] in appendix [ appendix : lemmas ] , assumption and , we get @xmath536 finally , we prove . using , , , lemma [ xtrx ] and lemma  2.6 in @xcite , we obtain @xmath537 the result for @xmath519 can be proved similarly .",
    "first , the existence and uniqueness of @xmath351 have been established in lemma [ lem : tn_exist ] .",
    "next , to show , we recall the @xmath538 defined in .",
    "the proof is completed if we show @xmath539 almost surely for all @xmath540 .    by , and lemma [ 4lems ] , there exists a constant @xmath413 such that @xmath541 moreover , by lemmas [ lem : tlimit ] and [ lem : t_properties ] and the convergence of @xmath355 , we have that as @xmath47 , @xmath542 and @xmath543 .",
    "in particular , for all sufficiently large @xmath35 , we have @xmath544    we now show that @xmath545 almost surely . using markov s inequality and hlder s inequality , for any @xmath446",
    ", we have @xmath546 where the last step follows from lemma [ 4lems ] and .",
    "thus , @xmath545 almost surely by lemmas [ lem : tlimit ] and [ lem : t_properties ] and the borel - cantelli lemma .",
    "similarly we can prove that @xmath539 almost surely for @xmath547 by using lemmas [ lem : tlimit ] , [ lem : t_properties ] , and [ 4lems ] and inequalities ( [ rhoj ] ) and ( [ delta0 ] ) .",
    "we first show that equation ( 1.1 ) in @xcite can be derived from proposition [ prop : lsd_signal_noise ] . for any fixed @xmath476 , by proposition  [ prop : lsd_signal_noise ] , lemmas [",
    "lem : tlimit ] , [ lem : t_properties ] , and lemma [ 4lems ] , and the dominated convergence theorem , we obtain @xmath548 where @xmath10 is the unique solution to equation , @xmath549 , and @xmath362 is the stieltjes transform of the probability distribution @xmath57 .",
    "moreover , if we let @xmath550 , then by   and , we have @xmath551 and @xmath552 substituting the expressions of @xmath10 , @xmath553 , and @xmath119 in terms of @xmath554 into equation ( [ rem ] ) yields @xmath555 where @xmath556 .",
    "note further that by lemma  [ lem : t_analytic ] , @xmath557 is analytic on @xmath558 .",
    "it then follows from the uniqueness of analytic continuation that equation ( [ rem_limit ] ) holds for every @xmath559  in other words , equation  ( 1.1 ) in @xcite holds .    in the following ,",
    "we show that equation ( [ eqn : lsd_signal_to_noisy ] ) in theorem [ thm : lsd_signal_noise ] holds .    for any @xmath476 , denote @xmath560 , where @xmath561 and @xmath562 .",
    "we further define @xmath563 we show the following facts :    [ f1 ] @xmath564 ,    [ f2 ] @xmath565 , or equivalently , + @xmath566 .    in fact , we can rewrite equation as @xmath567 noting that @xmath568 we have @xmath569 namely , holds . in addition , @xmath570 implies @xmath571 because @xmath572 by lemma [ lem : t_properties ] .",
    "we now show .",
    ". then @xmath574 by substituting and @xmath575 into equation , we obtain @xmath576 that is , @xmath577 therefore , @xmath578 namely , holds .",
    "next , by and the definitions of @xmath579 and @xmath580 and , we have @xmath581 using the facts and , we obtain @xmath582 by plugging in the expression of @xmath583 , we see that for all @xmath584 , @xmath585 satisfies @xmath586 it follows from the uniqueness of analytic continuation that the above equation holds for all @xmath571 such that @xmath587    it remains to show that the solution to equation is unique in @xmath115 .",
    "suppose that @xmath588 satisfies equation .",
    "define @xmath589 by and , we have @xmath590 hence , @xmath591 the second identity implies that @xmath592 using and , we have @xmath593 because the stieltjes transform @xmath594 is uniquely determined by equation  , we obtain @xmath595 it then follows from the first identity in that @xmath596  in other words , @xmath113 is the unique solution in @xmath115 .",
    "the convergence of @xmath597 follows easily from assumption   and the fact that @xmath598    next , by theorem 3.2 in @xcite , the assumption that @xmath57 has a bounded support implies that @xmath198 also has a bounded support .",
    "thus , assumption ( a.iii@xmath599 ) in @xcite , which requires that @xmath198 has a finite second moment , is satisfied .    we proceed to show the convergence of @xmath43 .",
    "as discussed in section [ ssec : app_i_2 ] , if the diffusion process @xmath159 belongs to class  @xmath160 , the drift process @xmath175 , and @xmath172 is independent of @xmath176 , then , conditional on @xmath600 , we have @xmath601 where @xmath602 is as in and is independent of @xmath603 , and @xmath178 consists of independent standard normals .",
    "hence , @xmath43 has the same distribution as @xmath604 defined as @xmath605    * claim 1*. without loss of generality , we can assume that the drift process @xmath152 and @xmath172 is independent of @xmath176 .",
    "first , whether the drift term @xmath12 vanishes or not does not affect the lsd of @xmath43 . to see this , note that @xmath606 , where @xmath607 and @xmath608 because all the entries of @xmath609 are of order @xmath610 , by lemma [ lemma1 ] in appendix [ appendix : lemmas ] , @xmath43 and @xmath611 have the same lsd .",
    "next , by the same argument as in the beginning of the proof of theorem  1 in @xcite , we can assume without loss of generality that @xmath171 is independent of @xmath11 .",
    "it follows that @xmath43 and @xmath604 have the same lsd .",
    "* claim 2*. @xmath612 is bounded , and there exists a piecewise continuous process @xmath613 with finitely many jumps such that @xmath614    using the boundedness of @xmath171 assumed in and @xmath131 , one can easily show that @xmath612 is bounded .    next we show that is satisfied for @xmath615 .",
    "define @xmath616    suppose that @xmath617 has @xmath618 jumps for @xmath619 . for each @xmath620",
    ", there exists an @xmath621 such that the @xmath243th jump falls in the interval @xmath622 .",
    "then @xmath623 because @xmath624 and @xmath625 are both bounded , for any @xmath626 and for any sufficiently large @xmath35 , we have @xmath627 for the second term @xmath628 , because @xmath617 is continuous in @xmath629 $ ] when @xmath630 , and by , @xmath171 uniformly converges to @xmath617 , for any @xmath626 and for sufficiently large @xmath631 , we have @xmath632 , \\mbox { and } |{\\gamma}_t-{\\gamma}_t^*|<\\varepsilon\\mbox { for all } t.\\ ] ] moreover , because @xmath633 , for all large @xmath35 , we have @xmath634 this completes the proof of .    finally , because @xmath635 and @xmath636 for @xmath637 , using claim  2 and applying theorem 1 in @xcite , we conclude that the esd of  @xmath43 converges to @xmath90 , whose stieltjes transform satisfies @xmath638 where @xmath201 , together with another function @xmath202 , uniquely solve the following equations in @xmath203 @xmath639",
    "the convergence of the esd of @xmath38 has been proved in theorem [ thm : main ] .",
    "the rest of theorem [ thm : b_n ] is a direct consequence of the following two convergence results .",
    "[ pthm3_a ] under the assumptions of theorem [ thm : b_n ] , we have @xmath640    [ pthm3 ] under the assumptions of theorem [ thm : b_n ] , @xmath641 converges almost surely , and the limit @xmath642 is determined by @xmath187 in that its stieltjes transform @xmath643 satisfies the following equation @xmath644    we prove proposition [ pthm3 ] first , and then give the proof of lemma  [ pthm3_a ] .",
    "we first show the convergence of @xmath645 .",
    "the main reason that we choose  @xmath66 in such a way that @xmath646 is to make the noise term negligible . to be more specific , by choosing @xmath647 for some @xmath253 where @xmath255 is the integer in assumption , we shall show that @xmath648 have the same lsd .",
    "this follow if we can show that @xmath649 and @xmath650    we start with . because @xmath651 to prove , it suffices to show @xmath652 below , we shall prove the following slightly stronger result : @xmath653 where for any vector @xmath654 , @xmath655 denotes its @xmath243th entry .    note further that for , using lemma [ lemma1 ] in appendix [ appendix : lemmas ] , to prove , it also suffices to show .    we now prove .",
    "we start with the denominator term @xmath82 .",
    "we have @xmath606 for @xmath609 and @xmath656 as defined in and , respectively .",
    "write @xmath656 as @xmath657 , where @xmath602 is defined in and @xmath658    by assumption , for all @xmath659 , @xmath660 are @xmath661 . by using the same trick as in the proof of ( 3.34 ) in @xcite , we have @xmath662 note that @xmath663    assumption implies that for all @xmath284 , there exists @xmath664 such that @xmath665 therefore , by assumption , there exists @xmath447 such that @xmath666 which , together with , implies that there exists @xmath667 such that for all sufficiently large @xmath35 , @xmath668 moreover , by assumption , @xmath669 for all @xmath670 ; hence , @xmath671 , which , by assumption , is @xmath672 .",
    "therefore , there exists a constant @xmath673 such that , almost surely , for sufficiently large all  @xmath35 , @xmath674    it remains to prove that @xmath675 observe that if we can show that there exists @xmath447 such that @xmath676 where @xmath677 is the integer in assumption  , then , for any @xmath626 , by markov s inequality , we have @xmath678 where the last equation is due to assumption . because + @xmath679 by assumption again , we have @xmath680 ; hence , by the borel - cantelli lemma , holds .",
    "we now show , which is a marcinkiewicz - zygmund type inequality .",
    "we use theorem 1 in @xcite to prove .",
    "for that , we need to verify that @xmath681 , where @xmath682 where @xmath683    we now verify that @xmath681 . for any @xmath243 and for any @xmath684 , using the definition of @xmath222-mixing coefficients we have @xmath685 by hlder s inequality , we have @xmath686 and , similarly , for @xmath687 .",
    "because @xmath232s have bounded @xmath233th moments and @xmath688 by assumption , we get @xmath681 .",
    "finally , by using an argument similar to the last part of the proof of proposition 8 in @xcite ( see pp.31423143 ) , we have that @xmath689 has the same lsd as @xmath690 where @xmath691 consists of independent standard normals .",
    "it is well known that the lsd of @xmath692 is determined by ; hence , by the previous arguments , so is that of @xmath693 .",
    "we now prove lemma [ pthm3_a ] .",
    "we have @xmath694 the convergence and @xmath695 imply that @xmath696 almost surely . to prove the lemma",
    ", it then suffices to show that @xmath697 and @xmath698    we start with .",
    "write @xmath606 as in the proof of proposition  [ pthm3 ] .",
    "the convergence implies that @xmath699 where the error term converges to 0 almost surely . by riemann integration and assumption",
    "it is easy to show that @xmath700 , so we get @xmath701 furthermore , by using the bound that @xmath671 one can easily show that @xmath702 we therefore get .",
    "finally , follows from and .",
    "suppose that @xmath704 satisfies the empirical version of equation  ; in other words , @xmath705    first , we claim that @xmath706 is tight ( regardless of whether @xmath124 is the unique solution or not ) .",
    "suppose to the contrary that @xmath706 is not tight ; then , with positive probability , there exists a subsequence @xmath463 such that @xmath707 .",
    "however , by the tightness of @xmath355 , along such a subsequence , the right - hand side of would converge to 0 , while the left - hand side blows up , a contradiction .",
    "next we show that any limit of @xmath124 as @xmath147 , denoted by @xmath708 , has to be @xmath209 . because @xmath709 , the limit @xmath708 satisfies @xmath710 we want to show that @xmath711 ; in other words , the equality sign can not hold .",
    "this can be be seen as follows .",
    "first , by rewriting as @xmath712 we see that @xmath713 can not converge to 0 ( because otherwise the right - hand side would converge to 0 while the left - hand side would converge to @xmath714 ) .",
    "it follows by taking the limits on both sides of the equation above that @xmath708 satisfies @xmath715 now , if @xmath716 , then the right - hand side would be a real number ; consequently , @xmath708 has to be a real number as well .",
    "however , because we have just proved that @xmath717 , if @xmath708 is a real number , then @xmath718 can not be zero , a contradiction .    to sum up",
    ", we have shown that @xmath708 satisfies equation   and is inside @xmath719 .",
    "therefore , by the uniqueness of the solution to equation   inside @xmath719 , we have @xmath720 .",
    "consequently , @xmath721 when @xmath35 ( and @xmath0 ) are large .    finally , because @xmath722 , we have that @xmath723 .",
    "( lemma 2.7 in @xcite ) .",
    "let @xmath724 be a vector where the @xmath725s are centered random variables with unit variance .",
    "let @xmath48 be an @xmath726 deterministic complex matrix .",
    "then , for any @xmath727 , @xmath728 [ xtrx ]    ( lemma 1 in @xcite ) .",
    "suppose that for each @xmath0 , @xmath729 and @xmath730 , @xmath731 , are all @xmath0-dimensional vectors .",
    "define @xmath732 if the following conditions are satisfied ,    @xmath733 with @xmath254 ,    there exists a sequence @xmath734 such that for all @xmath0 and all @xmath735 , all the entries of @xmath736 are bounded by @xmath737 in absolute value ;    @xmath738 almost surely .",
    "then , @xmath739 almost surely , where for any two probability distribution functions @xmath57 and @xmath381 , @xmath740 denotes the levy distance between them .",
    "figure [ fig : gamma_t ] plots a sample path of @xmath171 .",
    "bai , z. and silverstein , j. ( 2012 ) .",
    "`` no eigenvalues outside the support of the limiting spectral distribution of information - plus - noise type matrices . '' _ random matrices : theory and applications _ , 1 , 1150004 ."
  ],
  "abstract_text": [
    "<S> in practice , observations are often contaminated by noise , making the resulting sample covariance matrix a signal - plus - noise sample covariance matrix . aiming to make inferences about the spectral distribution of the population covariance matrix under such a situation </S>",
    "<S> , we establish an asymptotic relationship that describes how the limiting spectral distribution of ( signal ) sample covariance matrices depends on that of signal - plus - noise - type sample covariance matrices . as an application </S>",
    "<S> , we consider inferences about the spectral distribution of integrated covolatility ( icv ) matrices of high - dimensional diffusion processes based on high - frequency data with microstructure noise . </S>",
    "<S> the ( slightly modified ) pre - averaging estimator is a signal - plus - noise sample covariance matrix , and the aforementioned result , together with a ( generalized ) connection between the spectral distribution of signal sample covariance matrices and that of the population covariance matrix , enables us to propose a two - step procedure to consistently estimate the spectral distribution of icv for a class of diffusion processes . </S>",
    "<S> an alternative approach is further proposed , which possesses several desirable properties : it is more robust , it eliminates the effects of microstructure noise , and the asymptotic relationship that enables consistent estimation of the spectral distribution of icv is the standard marenko - pastur equation . </S>",
    "<S> the performance of the two approaches is examined via simulation studies under both synchronous and asynchronous observation settings . </S>"
  ]
}