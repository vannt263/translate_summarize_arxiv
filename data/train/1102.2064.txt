{
  "article_text": [
    "the analysis of the second order structure of time series is usually based on the characterization of the autocovariance function .",
    "one possibility is that the time series is not stationary , with a periodic or an almost periodic autocovariance function .",
    "the models with this structure were applied in many fields , including telecommunications @xcite , meteorology @xcite , econometrics @xcite and many others ( see the review in @xcite or @xcite ) .",
    "this class of non - stationary time series was introduced by @xcite .",
    "formally , we say that a second - order real - valued time series @xmath1 is _ periodically correlated _",
    "( pc for short ) if both the mean @xmath2 and the autocovariance function @xmath3 are periodic at @xmath4 for every @xmath5 , with the same period @xmath6 .",
    "a  second - order real - valued time series @xmath7 is called _ almost periodically correlated _ ( apc for short ) if both the mean @xmath8 and the autocovariance function @xmath9 are almost periodic function at @xmath4 for every @xmath5 .",
    "the definition of almost periodic function that we use in this paper can be found in @xcite , page 45 .",
    "it is easy to see that the class of apc time series contains the class of pc time series and the class of stationary time series .",
    "one of the main problems is how to detect this kind of non - stationary structure in the time series .",
    "this problem was considered in the time domain by vecchia and ballerini @xcite , dandawate and giannakis @xcite , dehay and lekow @xcite , synowiecki @xcite and , recently , by lenart _",
    "_ @xcite present tests for pc structure based on the estimator of fourier coefficient @xmath10 and the subsampling methodology . in the frequency domain ,",
    "the problem of detecting periodicity was considered by hurd and gerr @xcite , lund _",
    "@xcite , broszkiewicz - suwaj _ et al . _",
    "@xcite , lii and rosenblatt @xcite and hurd and miamee @xcite . hurd and gerr @xcite and hurd and miamee @xcite present a graphical method for detecting stationarity and periodicity , where the testing statistics were approximated by a beta distribution .",
    "however , this method has not yet been justified for non - gaussian white noise or dependent random variables .",
    "broszkiewicz - suwaj _ et al .",
    "_ @xcite have used the _ moving block bootstrap _ to construct methods for detecting periodicity in time series .",
    "still , the consistency of the bootstrap applied for their testing statistics remains an open problem .",
    "lii and rosenblatt @xcite present an innovative algorithm for estimating the support of the spectral measure for gaussian apc processes .",
    "the authors considered the case where the support of the spectral measure is concentrated on a finite number of parallel lines .    in the next section ,",
    "we recall the theoretical background and formulate the assumptions which are used in the sections which follow .",
    "we consider general apc time series for which the support of the spectral measure can be concentrated on an infinite number of parallel lines .",
    "section  [ sec3 ] presents the consistent estimator for the magnitude of coherence and the extension of the spectral density function to the bifrequency square @xmath11 ^ 2 $ ] . in this section",
    ", we show the asymptotic normality of the normalized spectral density estimator , the asymptotic distribution of the normalized magnitude of the spectral density estimator and the coherence statistic for all points from the bifrequency square @xmath11 ^ 2 $ ] . we give the exact forms for these distributions .",
    "it is shown that the asymptotic distribution of the normalized magnitude of the coherence statistic strongly depends on the support of the spectral measure .",
    "this distribution is not gaussian for the points which do not belong to the support of the spectral measure .",
    "recall that for the time series , the asymptotic normality of the spectral density estimator was shown for the stationary case in @xcite under an @xmath0-mixing condition and in @xcite for linear filters .",
    "for the pc case , the asymptotic normality was established in @xcite for linear filters .",
    "asymptotic distributions from section [ sec3 ] provide a possibility to establish consistency of the subsampling for the magnitude of spectral density and coherence , which is shown in section [ sec4 ] .",
    "it should be emphasized that magnitude of spectral density and coherence are broadly used as fundamental characteristics for telecommunication signals ( see @xcite ) .",
    "section [ sec5 ] presents a simulation study , where we show applications of our results . following the ideas of hurd and gerr @xcite and hurd and miamee @xcite , we present graphical methods for detecting periodicity in autocovariance and give theoretical justifications for these methods .",
    "finally , the asymptotic distribution and consistency of subsampling provide a possibility to construct asymptotically consistent confidence intervals for magnitude of spectral density and coherence .",
    "all proofs can be found in the .",
    "we will be focusing on second - order inference for time series , therefore , for simplicity , we make the following assumption :    _ assume that the real - valued time series @xmath7 is zero - mean . _    moreover",
    ", we will consider non - stationary , almost periodically correlated time series ; therefore , we formulate the next assumption :    _ assume that the time series @xmath7 is apc .",
    "_    in the apc case with @xmath12 for any @xmath5 , the autocovariance function @xmath9 has the fourier representation @xmath13 where @xmath10 are the fourier coefficients of the form @xmath14 and the set @xmath15 is countable ( see @xcite ) .",
    "define the set @xmath16 .",
    "we make the following assumption concerning the set @xmath17 and the fourier coefficients @xmath10 .",
    "we need this assumption in order to establish asymptotic properties of the spectral density estimator :    _ assume that for any @xmath18 , there exists a real - valued sequence @xmath19 such that we have @xmath20 and @xmath21 for @xmath22 . _    by ( a3 ) , we have that @xmath23 which implies that @xmath24 if @xmath25 , and we assume that @xmath26 uniformly at @xmath4 and @xmath27 for @xmath28 , then ( a3 ) holds",
    ". note that ( [ fourierx ] ) implies that for any @xmath29 , we have that @xmath30 as @xmath22 .    to introduce the spectral theory for apc time series , we need the following assumption :    _",
    "assume that the time series @xmath7 is harmonizable ( for the definition , see _ @xcite _ or _",
    "@xcite__)__.    by assumptions ( a2 ) and ( a4 ) , the spectral measure @xmath31 , defined on the bifrequency square @xmath32 ^ 2 $ ] , has support contained in the set ( see @xcite ) @xmath33 ^ 2\\dvtx\\omega=\\nu-\\lambda\\}.\\ ] ]    moreover , the coefficients @xmath10 are the fourier transforms of complex measures @xmath34 , that is , @xmath35 .",
    "the measure @xmath36 can be identified with the restriction of the spectral measure @xmath31 to the line @xmath37 , where @xmath38 .",
    "we need the following assumption :    _ assume that the measure @xmath39 is absolutely continuous with respect to the lebesgue measure . _    by the above assumptions , for any @xmath38 , there exists a spectral density function @xmath40 such that @xmath41 ( see @xcite and @xcite ) .",
    "now , let us define the extension of the spectral density function @xmath42 to the bifrequency square @xmath43 ^ 2 $ ] via @xmath44 hence , @xmath45 for any @xmath46 ^ 2}$ ] , which follows from the fact that @xmath47 for any @xmath48 and @xmath5 .",
    "if we assume that @xmath49 for any @xmath50 $ ] , then for any point @xmath51 from the bifrequency square @xmath52 ^ 2 $ ] , we define a magnitude of coherence via @xmath53    note that the magnitude of coherence is a real number from the interval @xmath54 $ ] , while the extension of the spectral density function is a complex number .",
    "the estimator of @xmath55 ( based on a sample @xmath56 ) of the form @xmath57 is generally not consistent in the mean square sense for apc time series .",
    "the exact form of the asymptotic variance of this estimator was calculated in @xcite .    to obtain a consistent estimator",
    ", we consider the following class of smoothed estimators of @xmath55 ( see @xcite for the stationary case ) : @xmath58 where @xmath59 is a lag window function such that @xmath60 for @xmath61 , @xmath5 and @xmath62 is a sequence of positive integers tending to infinity with @xmath63 .",
    "moreover , we assume that @xmath64 .",
    "if we assume that @xmath49 for any @xmath65 $ ] , then we define a magnitude of coherence statistic based on the estimator ( [ dens ] ) via @xmath66    the following considerations will involve the general assumption that we have a sample @xmath67 from time series @xmath7 , where @xmath68 and @xmath69 are arbitrary sequences of non - negative integers such that @xmath70 .",
    "this will help us to prove the consistency of the subsampling procedure to be discussed in section [ sec4 ] .    given a sample @xmath67",
    ", we define the estimators of @xmath55 and @xmath71 via @xmath72 and @xmath73 besides the fact that , in this work , we consider zero - mean time series , in the following remark , we define the estimator of the spectral density function in the case where the mean function @xmath8 is an almost periodic function such that @xmath74 .",
    "assume that the mean function @xmath75 for apc time series is an almost periodic function such that @xmath76 , where @xmath77 are the fourier coefficients and the set @xmath78 is known and finite .",
    "the natural estimator of the mean function @xmath8 ( for @xmath79 ) based on a sample @xmath80 then takes the form @xmath81 , where @xmath82 is an estimator of the fourier coefficient @xmath77 for any @xmath83 .",
    "the more general natural estimator of the spectral density @xmath55 based on a sample @xmath84 then takes the form @xmath85 similar modification in the pc case can be found in @xcite , section 10.4 .",
    "[ non - zero ]    in theorem [ covariance ] , we show the asymptotic covariance between normalizing estimators @xmath86 and @xmath87 for @xmath88 , @xmath89 .",
    "we need the following assumption concerning the lag window function @xmath59 .    for the convenience of the reader , before theorem [ covariance ]",
    ", we introduce the concept of @xmath0-mixing .",
    "let @xmath90 be a real - valued time series .",
    "the @xmath0-mixing sequence @xmath91 which corresponds to the time series @xmath90 is defined as @xmath92 where @xmath93 stands for the @xmath94-algebra generated by @xmath95 .",
    "the time series @xmath90 is called @xmath0-mixing if @xmath96 as @xmath97 .    for any random variable @xmath98 and positive constant @xmath99",
    ", we define the norm @xmath100 .",
    "[ covariance ] assume that and hold . if , additionally , there exist @xmath101 , @xmath102 and @xmath103 such that :    * @xmath104 * @xmath105 ,    then for any @xmath106 ^ 2 $ ] , we have the convergence @xmath107 where @xmath108 .    in theorem [ normality ] ,",
    "we show that the estimator ( [ den - h ] ) has an asymptotically normal distribution .",
    "this result is crucial for establishing the asymptotic distribution for the magnitude of coherence statistic and proving the consistency of subsampling applied for magnitude of coherence and spectral density .",
    "[ normality ] assume that and hold .",
    "additionally , assume that :    there exists @xmath101 such that @xmath109    @xmath110 for some @xmath111 ;    @xmath112 , where @xmath113 is the even integer such that @xmath114    then @xmath115 - \\left [ \\matrix { \\operatorname{re}(p(\\nu,\\omega))\\cr \\operatorname{im}(p(\\nu,\\omega ) ) } \\right ] \\right ) \\stackrel{d}{\\longrightarrow } \\mathcal{n}_{2}(0,\\sigma(\\nu,\\omega)),\\ ] ] where @xmath116_{i , j=1,2}$ ] , @xmath117 ^ 2- [ \\operatorname{im}(p(\\nu,\\omega))]^2 \\bigr),\\nonumber\\\\ \\sigma_{12 } & = & \\sigma_{21 } = - [ \\operatorname{re}(p(\\nu,\\omega))]^2 [ \\operatorname{im}(p(\\nu,\\omega))]^2 - \\tfrac{1}{2}\\operatorname{im } \\bigl(p(\\nu,2\\uppi- \\nu)p(2\\uppi- \\omega,\\omega ) \\bigr),\\qquad \\\\ \\sigma_{22 } & = & \\tfrac{1}{2 } \\bigl ( g_{0}(\\nu)g_{0}(\\omega ) + |p(\\nu,2 \\uppi- \\omega)|^2 - \\operatorname{re } \\bigl ( p(\\nu,2 \\uppi- \\nu ) p(2\\uppi- \\omega , \\omega ) \\bigr)\\nonumber\\\\ & & \\hphantom{\\frac{1}{2 } \\bigl ( } { } - [ \\operatorname{re}(p(\\nu,\\omega))]^2 + [ \\operatorname{im}(p(\\nu,\\omega))]^2 \\bigr).\\nonumber\\end{aligned}\\ ] ]    recall that in the stationary case , for the majority of spectral windows , the optimal @xmath118 ( in the mean square sense ) for the estimator @xmath119 is of order @xmath120 ( see @xcite , pages 462463 , or @xcite , page 86 ) .",
    "note that condition ( ii ) of theorem [ normality ] includes the case @xmath121 for @xmath122 .",
    "the following corollary is a natural generalization of the previous theorem to the multidimensional case .",
    "we need this result to establish the asymptotic distribution for the magnitude of coherence statistic .",
    "let @xmath7 be a time series such that all the assumptions of theorem [ normality ] hold .",
    "we then have the convergence @xmath123 - \\left [ \\matrix { \\operatorname{re}(p(\\nu,\\omega))\\cr g_{0}(\\nu ) \\cr g_{0}(\\omega)\\cr \\operatorname{im}(p(\\nu,\\omega ) ) } \\right ] \\right ) \\stackrel{d}{\\longrightarrow } \\mathcal{n}_{4}(0,{\\psi}(\\nu,\\omega ) ) , \\ ] ] where the covariance matrix @xmath124 can be obtained by theorem [ covariance ] .",
    "[ mnormality ]    note that in the special case where @xmath125 , we have @xmath126 and @xmath127 , which follow from the fact that @xmath128 .",
    "let us establish the asymptotic distribution of the normalized estimator @xmath129 ( under all the assumptions of theorem [ normality ] ) .",
    "note that if @xmath130 , then by theorem [ normality ] and the continuous mapping theorem , we get @xmath131 where @xmath132 and the random vector @xmath133 has a two - dimensional normal distribution with mean zero and a covariance matrix equal to @xmath134 .",
    "if we assume that @xmath135 then the distribution of a random variable @xmath136 is continuous . now , assume that @xmath137 .",
    "applying the delta method for the convergence ( [ eq32 ] ) and the function @xmath138 that is differentiable at the point @xmath139 , we get @xmath140 where @xmath141 and @xmath142 is the transpose of the matrix @xmath143 .",
    "now , let us establish the asymptotic distribution of a normalized statistic @xmath144 for @xmath145 ( in the case @xmath125 , we have @xmath146 ) . to do this , we assume that @xmath147 . in the first case ,",
    "take @xmath46 ^ 2}$ ] such that @xmath130 . by theorem",
    "[ normality ] , the continuous mapping theorem , consistency of the estimators @xmath148 and @xmath149 and slutsky s lemma , we then have @xmath150\\\\[-8pt ] & \\stackrel{d}{\\longrightarrow } & \\mathcal{l } \\biggl(\\frac{z}{\\sqrt{g_{0}(\\nu ) g_{0}(\\omega ) } } \\biggr).\\nonumber\\end{aligned}\\ ] ] if the @xmath151 , then the limiting distribution in ( [ 11111a ] ) is continuous . as a final consideration , assume that @xmath137 . in this case",
    ", we use the delta method to show the asymptotic normality of the normalized estimator @xmath144 . in doing this ,",
    "we use convergence ( [ gamma1 ] ) and the function @xmath152 that is differentiable at a point @xmath153 applying the delta method , we conclude that @xmath154 where @xmath155    by elementary calculation , the assumption that @xmath156 is equivalent to @xmath157 which is true if we assume that @xmath158 for any @xmath159 $ ] .",
    "moreover , @xmath160 if we assume that @xmath161 , and @xmath162 if we assume that @xmath163 .    in the corollaries which follow , we summarize considerations concerning the asymptotic distributions of normalized estimators @xmath164 and @xmath144 .    [ j1-dis ] let @xmath7 be a time series such that all the assumptions of theorem [ normality ] hold and that @xmath165 for any @xmath159 $ ] .",
    "take any @xmath46 ^ 2}$ ] .",
    "for the case where @xmath137 , we require that @xmath166 , where matrix @xmath134 is given by theorem [ normality ] . under these assumptions",
    ", we have the convergence @xmath167\\\\[-8pt ] & & \\quad   \\stackrel{d}{\\longrightarrow } j^{p(\\nu,\\omega ) } : = \\cases { \\mathcal{l}(z ) & \\quad   if $ p(\\nu,\\omega)=0$,\\cr \\mathcal{n}_1 ( 0,\\mathrm{d}_{1}\\sigma(\\nu,\\omega)\\mathrm{d}_{1}^{\\mathrm{t } } ) & \\quad if $ p(\\nu,\\omega)\\not=0 $ , } \\nonumber\\end{aligned}\\ ] ] where @xmath168 and @xmath169 are given by ( [ z - square ] ) and ( [ d1 ] ) , respectively . moreover ,",
    "the distribution @xmath170 ( @xmath171 for short ) is continuous .",
    "[ j2-dis - a ] suppose that all the assumptions of theorem [ normality ] hold and that @xmath165 for any @xmath159 $ ] .",
    "take any @xmath46 ^ 2}$ ] such that @xmath145 .",
    "for the case where @xmath137 , we require that @xmath172 , where the matrix @xmath173 is given by ( [ gamma1 ] ) .",
    "then @xmath174 where @xmath175 and @xmath176 are given by ( [ 11111a ] ) and ( [ da ] ) , respectively . moreover , the distribution @xmath177 ( @xmath178 for short ) is continuous .",
    "note that we can not use the asymptotic distributions from corollaries [ j1-dis ] and [ j2-dis - a ] in practice if we do not know that @xmath130 . even if we know the period @xmath6 for pc time series , the value of @xmath179 for @xmath180 can be equal to zero . for example",
    ", consider the model ( [ pmaa ] ) with period @xmath181 .",
    "after calculations ( we omit overly long formulae ) , @xmath182 , @xmath183 , @xmath184 , @xmath185 , @xmath186 and , crucially for this example , @xmath187 , @xmath188 for @xmath189 $ ] .",
    "therefore , we refer to the subsampling methodology , which does not require information about @xmath55 .",
    "let us introduce the subsampling procedure . some of the notation is adopted from @xcite . by @xmath190 and @xmath191",
    ", we denote the subsampling estimators of distribution functions of @xmath192 and @xmath193 , respectively . for any point @xmath194 , we define those estimators as @xmath195 where @xmath196 and @xmath197 is an indicator function of the event @xmath198 .",
    "denote by @xmath199 and @xmath200 the distribution functions of @xmath171 and @xmath178 , respectively . for any @xmath201 let @xmath202 and @xmath203 be quantiles of the nominal level @xmath204 from subsampling distributions ( [ sub1 ] ) and ( [ sub2 ] ) , respectively .",
    "the following theorems concerning consistency of subsampling then hold .    [ subsamplingp ] under all assumptions of corollary [ j1-dis ] :    @xmath205 for any @xmath194 ;    @xmath206 ;    the subsampling confidence intervals for @xmath207 are consistent , which means that @xmath208 where @xmath209 and @xmath210 .",
    "[ subsamplingc ] under all the assumptions of corollary [ j2-dis - a ] :    @xmath211 for any @xmath194 ;    @xmath212 ;    the subsampling confidence intervals for @xmath71 are consistent , which means that @xmath213 where @xmath209 and @xmath210 .",
    "in this section , we show possible applications of the results from sections [ sec3 ] and [ sec4 ] . in section  [ sec5.1 ] ,",
    "we present graphical methods for detecting the presence of periodic autocorrelation .",
    "we consider simulated data sets . in section [ sec5.2 ] , we calculate confidence intervals for the magnitude of a spectral density using subsampling and asymptotic distributions .",
    "take any point @xmath214 from the bifrequency square @xmath11 ^ 2 $ ] such that @xmath145 .",
    "let us consider the null hypothesis @xmath215 and the alternative hypothesis @xmath216 .",
    "if we assume that @xmath217 , then the above hypotheses @xmath218 and @xmath219 are equivalent to @xmath220 and @xmath221 respectively . under the assumptions of theorems [ subsamplingp ] and [ subsamplingc ] , we can use the statistics @xmath222 and @xmath223 and critical values from the subsampling distributions ( [ sub1 ] ) and ( [ sub2 ] ) for the above testing problems . under @xmath218 , the rejection probability tends to @xmath0 and under @xmath219 , this probability tends to one , which means that the both tests are asymptotically consistent .",
    "additionally , by corollary [ j1-dis ] , we use the statistics @xmath224 for the above testing problem , where @xmath225 and @xmath226 are estimators of the asymptotic variances of @xmath227 and @xmath228 , respectively ( see theorem [ covariance ] ) , obtained by replacing the unknown spectral densities by their estimates ( see formula ( [ dens ] ) ) . under hypothesis",
    "@xmath218 , the matrix @xmath134 from theorem [ normality ] has non - zero elements only on the main diagonal .",
    "therefore , under @xmath218 , the test statistic @xmath229 has , asymptotically , a chi - square distribution with two degrees of freedom .    for different points",
    "@xmath214 from the bifrequency square @xmath11 ^ 2 $ ] , we may consider the above testing problems .",
    "if we reject hypothesis @xmath218 for many points for which @xmath230 , where @xmath231 is some constant different from zero , then it can be suspected that the time series @xmath7 is not stationary ( see @xcite , figure 1 ) .",
    "we calculate values of the statistic @xmath232 for data for each point from the set @xmath233 ^ 2 $ ] and we compare these values with the critical values @xmath202 .",
    "if the value of @xmath234 exceeds @xmath202 , then we reject hypothesis @xmath218 and put a black mark at the point @xmath51 on the bifrequency square .",
    "the same steps are repeated using statistics @xmath235 , @xmath229 and appropriate critical values from subsampling and chi - square distributions .",
    "we fix @xmath236 , @xmath237=4 $ ] , @xmath238=80 $ ] , @xmath239=2 $ ] and @xmath240 .",
    "we put @xmath241 , where @xmath197 is an indicator function of the event @xmath198 .",
    "we compare our methods with the method presented in @xcite and @xcite .",
    "we put @xmath242 into @xcite , formula ( 11 ) .",
    "note that using multiple testing procedures for various points seems to be difficult for graphical methods presented in figures [ fig_hist1](b)(e ) and [ fig_hist2](b)(e ) because the number of different tests on each figure is 14400 and this is bigger than the length of the sample , which is @xmath236 .",
    "if we use multiple testing procedures and we calculate the quantiles from the subsampling distribution , then the justified significant level should not be too small in comparison with the sample size .",
    "some intuitive adjustment for the significant level in the graphical method presented in figures [ fig_hist1](e ) and [ fig_hist2](e ) for the pc case was made in @xcite .",
    "the theoretical results which can help in multiple testing procedures in connection with subsampling approximation can be found in @xcite , where the question of how well the subsampling distribution approximates the tail of an unknown distribution that we approximate was considered .    , with @xmath243-distributed innovations : ( a ) time series ; ( b )  tests for @xmath244 based on the statistic @xmath245 and subsampling ; ( c ) tests for @xmath244 based on the statistic @xmath246 and central chi - square distribution with two degrees of freedom ; ( d ) tests for @xmath247 based on the statistic @xmath248 and subsampling ; ( e ) tests for @xmath247 based on the statistic presented in @xcite , formula ( 11 ) , page 342 , and the beta distribution . ]    , with period @xmath249 and normal(0,1)-distributed innovations @xmath250 : ( a ) time series ; ( b ) tests for @xmath244 based on the statistic @xmath245 and subsampling ; ( c ) tests for @xmath244 based on the statistic @xmath246 and central chi - square distribution with two degrees of freedom ; ( d ) tests for @xmath247 based on the statistic @xmath248 and subsampling ; ( e ) tests for @xmath247 based on the statistic presented in @xcite , formula ( 11 ) , page 342 , and the beta distribution . ]",
    "figure [ fig_hist1 ] presents the stationary case .",
    "all methods for this case fail to show the evidence of periodic correlation .",
    "figure [ fig_hist2 ] presents methods for the sample from the periodic moving average model of order one with period equal to @xmath249 .",
    "all methods for this case clearly reveal the presence of periodic correlation with appropriate length of period @xmath249 . in summary",
    ", all methods can successfully distinguish the stationary case from the pc case .",
    "moreover , there is no clear difference in these examples between the efficiency of the above graphical methods based on subsampling , the central chi - square distribution with two degrees of freedom and the beta distribution.=-1    we chose the parameters @xmath118 and @xmath251 to satisfy the assumptions in theorems [ subsamplingp ] and [ subsamplingc ] .",
    "note that in @xcite , pages 190191 , the problem of choosing @xmath251 in practice in special cases was considered .",
    "it was found that the choice of @xmath251 is , in practice , a delicate issue , like the choice of the bandwidth @xmath118 in nonparametric spectral density estimation .",
    "it was also shown in @xcite in simulations that the type i error and power of the test based on subsampling approximation for significance of the value @xmath252 strongly depends on the choice of the parameter @xmath251 .",
    "it is likely that a similar problem occurs in the graphical methods presented in this work , where the choice of the parameters @xmath62 and @xmath251 is a open problem .      from theorem [ subsamplingp ]",
    ", we can obtain a two - sided equal - tailed consistent confidence interval for the parameter @xmath207 in the form @xmath253 where @xmath254 is a nominal level .",
    "a similar confidence interval can be obtained for coherence using theorem [ subsamplingc ] .",
    "consider the periodic moving average model of order one with period equal to @xmath6 , @xmath255 where @xmath256 and @xmath250 is a gaussian white noise with mean zero and variance equal to one .",
    "the aim of this section is to calculate confidence intervals for @xmath257 for time series of the form ( [ pmaa ] ) .",
    "figure [ fig_hist ] presents @xmath258 confidence intervals ( [ sub_c_i ] ) for @xmath179 , @xmath249 , @xmath259 and for @xmath260 .",
    "we put @xmath237 $ ] , @xmath238 $ ] and @xmath261 .",
    "we also present @xmath262 confidence intervals based on the asymptotic distribution @xmath171 ( see the formula in corollary [ j1-dis ] ) by replacing unknown values of spectral densities in the asymptotic distribution @xmath171 by their estimates using ( [ dens ] ) .",
    "the confidence interval for @xmath263 based on the asymptotic distribution @xmath171 has spikes on the interval @xmath11 $ ] being considered .",
    "it follows from the fact that asymptotic variance in the limiting distribution @xmath264 depends ( for fixed @xmath231 ) on a value @xmath265 that is non - zero for the considered @xmath266 only for the points @xmath267 .",
    "this can also be observed for the stationary case , where the asymptotic variance of the normalized spectral density estimator on the main diagonal , expressed as a function of @xmath268 , has a discontinuity at points @xmath269 and @xmath270 ( see @xcite and @xcite ) .",
    "note , that the distribution @xmath264 can be used to construct a confidence interval for @xmath271 under additional information concerning parameter @xmath55 .",
    "therefore , subsampling seems to be more useful in practice when there is no rule to obtain the parameter @xmath251 in our testing problem .    [ cols=\"^,^ \" , ]",
    "in this work , we give the exact forms of the asymptotic distributions for normalized spectral density and magnitude of coherence statistics and we prove the consistency of subsampling applied for magnitude of spectral density and coherence .",
    "this research was done for @xmath0-mixing zero - mean apc time series with the support of the spectral measure concentrated on a countable set of parallel lines . by the consistency of subsampling",
    ", we construct asymptotically consistent confidence intervals for magnitude of spectral density and coherence .",
    "importantly , this confidence intervals does not depend on the support of the spectral measure , unlike confidence intervals based on asymptotic distributions .",
    "graphical methods for detecting the presence of periodic autocovariance were presented and their theoretical properties explored .",
    "one of the main problems is the choice of the parameter @xmath251 in graphical methods , as presented in section [ sec5 ] .",
    "the next problem connected with applications is the estimation of spectral density and coherence for non - zero - mean time series .",
    "note that the well - known differencing operation , popular in time series analysis , is useful when the mean function is a constant or a periodic function with known period . generally ,",
    "if we assume that the mean function is almost periodic , then we can not use the differencing operation , even if we known the set @xmath78 ( see remark [ non - zero ] ) , in the fourier representation of the mean function . to cope with this problem",
    ", we can consider spectral density estimators for non - zero - mean time series of the form ( [ dens2 ] ) .",
    "this , and other open problems , are currently being researched by the author .",
    "to begin , we formulate a few auxiliary lemmas which are crucial for proving the theorems .    [ base ]",
    "let @xmath7 be real - valued time series with corresponding @xmath272-mixing sequence @xmath91 .",
    "assume that there exist real numbers @xmath101 and @xmath273 such that @xmath274 .",
    "for any @xmath275 , @xmath276 and @xmath5 , we then have the following estimates :    @xmath277 ;    @xmath278 .",
    "the proof of ( i ) is elementary and is based on @xcite , theorem 3 , page 9 .",
    "the proof of ( ii ) follows from ( i ) by noting that @xmath279 for any @xmath275 and @xmath5 .",
    "[ fazekas ] let @xmath7 be a zero - mean time series .",
    "assume that there exist real numbers @xmath280 and @xmath101 and an even integer @xmath281 such that @xmath282 and @xmath283 there then exists a constant @xmath284 ( which depends only on the sequence @xmath91 and constant @xmath285 ) such that for any @xmath286 and @xmath287 , we have the estimate @xmath288^{l/2 } \\})^{1/l},\\ ] ] where @xmath289 .    [ as - norm ]",
    "let @xmath290 be a triangular array of zero - mean real - valued random vectors , where @xmath291 is a sequence of positive integers tending to infinity .",
    "define @xmath292 assume that :    a.   there exists a constant @xmath293 such that @xmath294 b.   @xmath295 c.   there exists a sequence of positive integers @xmath296 such that @xmath297 for some @xmath298 , and a sequence @xmath299 such that @xmath300 for all @xmath301 and @xmath302 for some @xmath303 , where @xmath304 is a mixing sequence for a triangular array @xmath305 defined for any @xmath306 and @xmath307 as @xmath308 @xmath309 stands for the @xmath94-algebra generated by @xmath310 and @xmath311 stands for the @xmath94-algebra generated by @xmath312 .",
    "then @xmath313    the proof is based on the same steps as that of the clt of @xcite , and the cramr ",
    "wold device .",
    "[ inequality1 ] let @xmath7 be a zero - mean and @xmath0-mixing time series .",
    "assume that there exists a real number @xmath101 such that :    @xmath314    @xmath315 .",
    "for any sequences @xmath316 and @xmath317 of integers where @xmath318 , we then have @xmath319 where the constant @xmath320 depends only on @xmath321 and @xmath322 .    this proof is based on a similar technique as in the proof of @xcite , theorem 4.1 , and is therefore omitted .",
    "[ bias ] suppose that assumptions hold .",
    "using the notation from section [ sec3 ] , for any @xmath323 ^ 2 $ ] , we have @xmath324 = p(\\nu,\\omega).\\ ] ]    take any @xmath46 ^ 2}$ ] and note that ( @xmath325 , @xmath326 ) @xmath327 & = & \\frac{1}{2\\uppi d_n}\\sum_{s = c_n+1}^{c_n+d_n}\\sum _ { t = c_n+1}^{c_n+d_n}e(x_{s}x_{t})\\mathrm{e}^{-\\mathrm{i } ( \\nu-\\omega ) t}\\mathrm{e}^{-\\mathrm{i } \\nu ( s - t)}\\\\ & = & \\frac{1}{2\\uppi d_n } \\sum_{j = c_n+1}^{c_n+d_n}\\sum_{\\tau = c_n+1-j}^{c_n+d_n - j } b(j,\\tau)\\mathrm{e}^{-\\mathrm{i } ( \\nu-\\omega ) j}\\mathrm{e}^{-\\mathrm{i } \\nu \\tau}\\\\ & = & \\frac{1}{2\\uppi d_n } \\sum_{j = c_n+1}^{c_n+d_n } \\sum_{\\tau = c_n+1-j}^{c_n+d_n - j}\\sum_{\\lambda\\in\\lambda_\\tau } a(\\lambda,\\tau ) \\mathrm{e}^{\\mathrm{i } ( \\lambda-(\\nu-\\omega ) ) j } \\mathrm{e}^{-\\mathrm { i } \\nu \\tau } \\\\ & = & \\frac{1}{2\\uppi d_n } \\sum_{j = c_n+1}^{c_n+d_n}\\sum_{\\tau = c_n+1-j}^{c_n+d_n - j } a(\\nu-\\omega,\\tau ) \\mathrm{e}^{-\\mathrm{i } \\nu \\tau}\\\\ & & { } + \\frac{1}{2\\uppi d_n } \\sum_{j = c_n+1}^{c_n+d_n}\\sum_{\\tau = c_n+1-j}^{c_n+d_n - j } \\sum_{\\lambda\\in\\lambda_\\tau\\setminus\\{\\nu-\\omega\\ } } a(\\lambda , \\tau)\\mathrm{e}^{\\mathrm{i } ( \\lambda-(\\nu-\\omega ) ) j } \\mathrm{e}^{-\\mathrm{i } \\nu \\tau } \\\\ & = & \\frac{1}{2\\uppi } \\sum_{|\\tau|<d_n } \\biggl ( 1- \\frac{|\\tau|}{d_n } \\biggr)a(\\nu -\\omega,\\tau ) \\mathrm{e}^{-\\mathrm{i } \\nu \\tau}\\\\ & & { } + \\frac{1}{2\\uppi d_n } \\sum_{j = c_n+1}^{c_n+d_n}\\sum_{\\tau = c_n+1-j}^{c_n+d_n - j } \\sum_{\\lambda\\in\\lambda_\\tau\\setminus\\{\\nu-\\omega\\ } } a(\\lambda , \\tau)\\mathrm{e}^{\\mathrm{i } ( \\lambda-(\\nu-\\omega ) ) j } \\mathrm{e}^{-\\mathrm{i } \\nu \\tau}.\\end{aligned}\\ ] ] denote the first and second terms of the last equality by @xmath328 and @xmath329 , respectively .",
    "note that @xmath330 is a cesro mean for the sequence @xmath331 .",
    "hence , @xmath330 goes to @xmath55 . by the estimate @xmath332",
    ", we have @xmath333 which means that @xmath334 ( by ( a3 ) ) .",
    "this completes the proof .",
    "[ biasx ] suppose that and hold .",
    "additionally , assume that there exist @xmath101 , @xmath102 and @xmath103 such that :    @xmath335    @xmath336    using the notation from section [ sec3 ] , for any @xmath337 ^ 2 $ ] and any @xmath338 , we then have @xmath339 where @xmath340 and @xmath341 does not depend on @xmath342 .",
    "take any @xmath46 ^ 2}$ ] and note that using the same steps as in the proof of lemma  [ bias ] , we get @xmath343 where @xmath344 , @xmath345 , @xmath346 and @xmath347 are the first , second , third and fourth terms , respectively , of the last equation .",
    "it it easy to see that @xmath348 .",
    "therefore , to prove the theorem , it is sufficient to show that @xmath349 , @xmath350 and @xmath351 . by lemma [ base](ii ) , for the term @xmath345 , we have @xmath352 for the term @xmath346 , we have @xmath353 now , using the property @xmath354 which is true for any @xmath355 modulo @xmath356 and @xmath357 ( see @xcite , exercise 1.2 , page 10 ) for the terms @xmath358 , @xmath359 , @xmath360 , we obtain the estimate @xmath361 using the same arguments , we get that @xmath351 .",
    "this completes the proof .",
    "proof of theorem [ covariance ] using simple decomposition , we have @xmath362 where @xmath363 , @xmath364 , @xmath365 are the first , second and the third term , respectively , of the last equation . to prove the theorem , it is sufficient to show that @xmath366 , @xmath367 , @xmath368 as @xmath369 note that by the estimate @xmath370 and lemma [ inequality1 ] , we get that @xmath371 . considering the term @xmath364 , we get ( @xmath372 , @xmath373 , @xmath374 , @xmath375 ) @xmath376 where @xmath377 and @xmath378 .",
    "we show that the terms @xmath379 tend to zero , which means that @xmath364 has the same limit as @xmath380 .",
    "we start with the term @xmath381 . by lemma [ base](i ) , we have @xmath382 , which means that @xmath383 & & \\hphantom{\\frac{64 \\delta^4 } { d_n l_{d_n } } \\sum_{j_1=c_n+1}^{c_n+d_n } \\sum_{\\tau_1=-l_{d_n}}^{l_{d_n } } \\sum_{\\tau_2=-l_{n}}^{-1 } \\sum_{j_2=c_n+1}^{c_n-\\tau_2 } } { } \\times\\alpha^{\\delta /{(2+\\delta)}}\\bigl(|j_1-j_2-(\\tau_1-\\tau_2)|\\bigr)\\\\[-1pt ] & & { } + \\frac{64 \\delta^4 } { d_n l_{d_n } } \\sum_{j_1=c_n+1}^{c_n+d_n } \\sum_{\\tau_1=-l_{d_n}}^{l_{d_n } } \\sum_{\\tau_2=1}^{l_{n } } \\sum_{j_2=c_n+d_n-\\tau_2 + 1}^{c_n+d_n } \\alpha^{\\delta/{(2+\\delta)}}(|j_1-j_2|)\\\\[-1pt ] & & \\hphantom { { } + \\frac{64 \\delta^4 } { d_n l_{d_n } } \\sum_{j_1=c_n+1}^{c_n+d_n } \\sum_{\\tau_1=-l_{d_n}}^{l_{d_n } } \\sum_{\\tau_2=1}^{l_{n } } \\sum_{j_2=c_n+d_n-\\tau_2 + 1}^{c_n+d_n } } { } \\times\\alpha^{\\delta /{(2+\\delta)}}\\bigl(|j_1-j_2-(\\tau_1-\\tau_2)|\\bigr)\\\\[-1pt ] & \\leq & \\frac{64 \\delta^4 } { d_n l_{d_n } } \\biggl ( \\sum_{k=1-l_{d_n}}^{d_n-1 } l_{d_n } \\alpha^{\\delta/{(2+\\delta)}}(|k| ) \\sum_{\\tau_1=-l_{d_n}}^{l_{d_n } } \\sum_{\\tau_2=-l_{d_n}}^{l_{d_n } } \\alpha^{\\delta/{(2+\\delta ) } } \\bigl(|k-(\\tau_1-\\tau_2)|\\bigr ) \\\\[-1pt ] & & \\hphantom{\\frac{64 \\delta^4 } { d_n l_{d_n } } \\biggl ( } { } + \\sum_{k =- d_n+1}^{l_n-1 } l_{d_n } \\alpha^{\\delta/{(2+\\delta)}}(|k| ) \\sum_{\\tau_1=-l_{d_n}}^{l_{d_n } } \\sum_{\\tau_2=-l_{d_n}}^{l_{d_n } } \\alpha^{\\delta/{(2+\\delta ) } } \\bigl(|k-(\\tau_1-\\tau_2)|\\bigr ) \\biggr ) \\\\[-1pt ] & \\leq & \\frac{64 \\delta^4 } { d_n l_{d_n } } \\biggl ( \\sum_{k=1-l_{d_n}}^{d_n-1 } l_{d_n } \\alpha^{\\delta/{(2+\\delta)}}(|k| ) ( 2 l_{d_n } + 1)2 k\\\\[-1pt ] & & \\hphantom{\\frac{64 \\delta^4 } { d_n l_{d_n } } \\biggl ( } { } + \\sum_{k =- d_n+1}^{l_n-1 } l_{d_n } \\alpha^{\\delta /{(2+\\delta)}}(|k| ) ( 2 l_{d_n}+1)2 k \\biggr)\\\\[-1pt ] & \\leq&\\frac{64 \\delta^4 } { d_n l_{d_n } } ( 2 l_{d_n}+1)^2 8 k^2 \\to0 \\qquad \\mbox{as } n \\to\\infty.\\end{aligned}\\ ] ] using the same steps , we have that the terms @xmath384 and @xmath385 tend to zero . for @xmath380 , we get @xmath386 & & \\hphantom{\\frac{1}{d_n l_{d_n } } \\sum_{j_1=c_n+1}^{c_n+d_n } \\sum _ { j_2=c_n+1}^{c_n+d_n } } { } \\times \\sum_{\\tau_1=-l_{d_n}}^{l_{d_n } } \\sum_{\\tau_2=-l_{d_n}}^{l_{d_n } } e(x_{j_1+\\tau_1 } x _ { j_1+\\tau_2 } ) \\\\[-1pt ] & & \\hphantom{\\hphantom{\\frac{1}{d_n l_{d_n } } \\sum_{j_1=c_n+1}^{c_n+d_n } \\sum _ { j_2=c_n+1}^{c_n+d_n } } { } \\times\\sum_{\\tau_1=-l_{d_n}}^{l_{d_n } } \\sum_{\\tau_2=-l_{n}}^{l_{d_n } } } { } \\times h_{l_{d_n}}(\\tau_1)^2 \\mathrm{e}^{-\\mathrm{i}(\\nu_1 ( j_1+\\tau_1 ) - \\nu _ 2 ( j_1+\\tau_2))}\\\\ & & { } + \\frac{1}{d_n l_{d_n } } \\sum_{j_1=c_n+1}^{c_n+d_n } \\sum _ { j_2=c_n+1}^{c_n+d_n } e(x_{j_1}x_{j_2 } ) \\mathrm{e}^{-\\mathrm{i } ( \\omega_2 j_2 - \\omega_1 j_1 ) } \\\\ & & \\hphantom { { } + \\frac{1}{d_n l_{d_n } } \\sum_{j_1=c_n+1}^{c_n+d_n } \\sum _ { j_2=c_n+1}^{c_n+d_n } } { } \\times \\sum_{\\tau_1=-l_{d_n}}^{l_{d_n } } \\sum_{\\tau_2=-l_{d_n}}^{l_{d_n } } \\bigl ( e(x_{j_1+\\tau_1 } x _ { j_2+\\tau_2 } ) \\mathrm{e}^ { \\mathrm{i } \\nu_2 ( j_2+\\tau_2 ) ) } \\\\ & & \\hphantom{\\hphantom { { } + \\frac{1}{d_n l_{d_n } } \\sum_{j_1=c_n+1}^{c_n+d_n } \\sum _ { j_2=c_n+1}^{c_n+d_n } } { } \\times \\sum_{\\tau_1=-l_{d_n}}^{l_{d_n } } \\sum_{\\tau_2=-l_{n}}^{l_{d_n } } \\bigl ( } { } - e(x_{j_1+\\tau_1 } x _ { j_1+\\tau_2 } ) \\mathrm{e}^ { \\mathrm{i } \\nu_2 ( j_1+\\tau_2 ) ) } \\bigr)\\\\ & & \\hphantom{\\hphantom { { } + \\frac{1}{d_n l_{d_n } } \\sum_{j_1=c_n+1}^{c_n+d_n } \\sum _ { j_2=c_n+1}^{c_n+d_n } } { } \\times \\sum_{\\tau_1=-l_{d_n}}^{l_{d_n } } \\sum_{\\tau_2=-l_{n}}^{l_{d_n } } } { } \\times h_{l_{d_n}}(\\tau_1)^2 \\mathrm{e}^{-\\mathrm{i } \\nu_1 ( j_1+\\tau_1 ) } \\\\ & & { } + \\frac{1}{d_n l_{d_n } } \\sum_{j_1=c_n+1}^{c_n+d_n } \\sum _ { j_2=c_n+1}^{c_n+d_n } e(x_{j_1}x_{j_2 } ) \\mathrm{e}^{-\\mathrm{i } ( \\omega_2 j_2 - \\omega_1 j_1 ) } \\\\ & & \\hphantom { { } + \\frac{1}{d_n l_{d_n } } \\sum_{j_1=c_n+1}^{c_n+d_n } \\sum _ { j_2=c_n+1}^{c_n+d_n } } { } \\times\\sum_{\\tau_1=-l_{d_n}}^{l_{d_n } } \\sum_{\\tau_2=-l_{d_n}}^{l_{d_n } } e(x_{j_1+\\tau_1 } x _ { j_2+\\tau_2 } ) \\\\ & & \\hphantom{\\hphantom { { } + \\frac{1}{d_n l_{d_n } } \\sum_{j_1=c_n+1}^{c_n+d_n } \\sum _ { j_2=c_n+1}^{c_n+d_n } } { } \\times\\sum_{\\tau_1=-l_{d_n}}^{l_{d_n } } \\sum_{\\tau_2=-l_{n}}^{l_{d_n } } } { } \\times h_{l_{d_n}}(\\tau_1 ) \\bigl ( h_{l_{d_n}}(\\tau_2 ) - h_{l_{d_n}}(\\tau_1 ) \\bigr)\\\\ & & \\hphantom{\\hphantom { { } + \\frac{1}{d_n l_{d_n } } \\sum_{j_1=c_n+1}^{c_n+d_n } \\sum _ { j_2=c_n+1}^{c_n+d_n } } { } \\times\\sum_{\\tau_1=-l_{d_n}}^{l_{d_n } } \\sum_{\\tau_2=-l_{n}}^{l_{d_n } } } { } \\times\\mathrm{e}^{-\\mathrm{i}(\\nu_1 ( j_1+\\tau_1 ) - \\nu_2 ( j_2+\\tau_2))}. \\ ] ] denote the first , second and third terms of the last equality by @xmath387 , @xmath388 and @xmath389 , respectively . for the term @xmath388",
    ", we have @xmath390 , where @xmath391 using lemma [ base](i ) and similar steps as for the term @xmath392 , it can be proven that @xmath393 tends to zero .",
    "for the term @xmath394 , we have @xmath395 in the same way , we may prove that @xmath396 .",
    "this means that @xmath397 . using lemma [ base](i ) , inequality @xmath398 and similar steps as for the term @xmath399",
    ", it can be proven that @xmath400 tends to zero .",
    "this means that the term @xmath380 has the same limit as @xmath401 .",
    "now , using lemmas [ bias ] and [ biasx ] for the term @xmath401 , we get @xmath402 for the term @xmath403 , we have @xmath404 hence , @xmath405 .",
    "following the same steps , we get that @xmath406 .",
    "this completes the proof .",
    "proof of theorem [ normality ] let us consider the following decomposition for the estimator @xmath407 : @xmath408 where @xmath409 , @xmath410 we will now split the proof into two steps . in the first step , we will show that the deterministic term @xmath411 tends to zero for @xmath412 . in the second step",
    ", we will show that @xmath413 \\stackrel{d}{\\longrightarrow}\\mathcal{n}_{2}(0,\\sigma(\\nu,\\omega)).\\ ] ]    _ step _ 1 . without loss of generality",
    ", we may assume that @xmath414 .",
    "changing variables and using , sequentially , ( [ fourier2 ] ) , ( [ spec_rec ] ) , ( [ as - per ] ) , ( a3 ) and assumption ( ii ) of our theorem , we then obtain @xmath415 where @xmath197 is an indicator function of the event @xmath198 .",
    "this completes the proof of step 1 .",
    "_ step _ 2 . in this step ,",
    "we use theorem [ covariance ] and lemma [ as - norm ] to show ( [ s_as_nor ] ) . note that @xmath416 where @xmath417 and @xmath418 are defined via @xmath419 and @xmath420 .",
    "we show that for triangular array @xmath421 , the assumptions of theorem [ as - norm ] hold .",
    "note that by the minkowski inequality , lemma [ base](i ) and , finally , by the hlder inequality , we have @xmath422 in the next step , we use lemma [ fazekas ] to estimate the term @xmath423 .",
    "let @xmath424 and note that @xmath425 , which means that assumption ( i ) of lemma  [ fazekas ] holds . assumption ( ii ) of lemma  [ fazekas ] follows from assumption ( iii ) of our theorem .",
    "therefore , using lemma  [ fazekas ] ( similarly as for @xmath426 ) , we get @xmath427 \\hspace*{-4pt}&&\\quad   \\leq \\delta\\bigl(k_{\\alpha ,",
    "l } \\max\\bigl\\ { q(3 + 3\\delta/2,\\delta ,- l_{d_n}-1,2 l_{d_n}+1),\\\\[2pt ] \\hspace*{-4pt}&&\\qquad\\hphantom{\\delta\\bigl(k_{\\alpha , l}\\max\\ { } [ q(2,\\delta ,- l_{d_n}-1,2 l_{d_n}+1)]^{(3 + ( 3/2)\\delta)/2 } \\bigr\\ } \\bigr)^{1/(3 + ( 3/2)\\delta)}/\\sqrt{l_{d_n } } + 16 \\delta^2 k \\\\[2pt ] \\hspace*{-4pt}&&\\quad   \\leq\\delta k_{\\alpha , l}^{1/(3 + ( 3/2)\\delta ) } \\bigl ( \\max\\bigl\\ { ( 2 l_{d_n}+1 ) \\delta^{3 + ( 3/2)\\delta},\\bigl((2 l_{d_n}+1 ) \\delta ^{2}\\bigr)^{(3 + ( 3/2)\\delta)/2 } \\bigr\\}\\bigr)^{1/(3 + ( 3/2)\\delta)}/\\sqrt { l_{d_n}}\\\\[2pt ] \\hspace*{-4pt}&&\\qquad { } + 16 \\delta^2 k \\\\[2pt ] \\hspace*{-4pt}&&\\quad   \\leq\\delta^2 k_{\\alpha , l}^{1/(3 + ( 3/2)\\delta ) } \\sqrt{2 l_{d_n}+1 } /\\sqrt{l_{d_n } } + 16 \\delta^2 k \\\\[2pt ] \\hspace*{-4pt}&&\\quad\\leq\\delta^2 \\bigl(2 k_{\\alpha , l}^{1/(3 + ( 3/2)\\delta ) } + 16 k\\bigr ) , \\ ] ] which means that assumption ( i ) of lemma [ as - norm ] holds .",
    "condition ( ii ) of lemma [ as - norm ] follows from theorem [ covariance ] by noting that @xmath428 finally , putting @xmath429 and @xmath430 , and taking into consideration assumption ( iii ) of our theorem , we get that condition ( iii ) of lemma [ as - norm ] holds , which means that ( [ s_as_nor ] ) holds , where @xmath134 can be obtained by the last three equations and theorem [ covariance ] .",
    "the calculation of the matrix @xmath431 is too technical to be presented here .",
    "this completes the proof .",
    "proof of theorem [ subsamplingp ] by politis _",
    "@xcite , theorem 4.2.1 , it is sufficient to prove that there exists a continuous distribution @xmath432 such that :    @xmath433 ;    for any sequence of positive integers @xmath434 such that @xmath435 , @xmath436 as @xmath437 , we have @xmath438 where @xmath439 and @xmath440 is a distribution function at the point @xmath441 for the distribution @xmath432 .",
    "this follows immediately from corollary [ j1-dis ] by setting @xmath442 and @xmath443 .",
    "this completes the proof .",
    "proof of theorem [ subsamplingc ] this proof is analogous to the proof of theorem 4.1 .",
    "the only difference is that we use corollary [ j2-dis - a ] instead of corollary [ j1-dis ] .",
    "my thanks go to dominique dehay , jacek lekow and rafa synowiecki for stimulating discussions .",
    "this research was supported in part by nato grant ics.nukr.clg 983335 .",
    "dehay , d. and hurd , h. ( 1994 ) . representation and estimation for periodically and almost periodically correlated random processes . in _",
    "cyclostationarity in communications and signal processing _",
    "gardner , ed . ) 295329 .",
    "new york : ieee press ."
  ],
  "abstract_text": [
    "<S> the aim of this article is to establish asymptotic distributions and consistency of subsampling for spectral density and for magnitude of coherence for non - stationary , almost periodically correlated time series . </S>",
    "<S> we show the asymptotic normality of the spectral density estimator and the limiting distribution of a magnitude of coherence statistic for all points from the bifrequency square . </S>",
    "<S> the theoretical results hold under @xmath0-mixing and moment conditions . </S>"
  ]
}