{
  "article_text": [
    "we consider the problem in which the recovery of a discrete time signal @xmath0 of length @xmath1 is sought when only @xmath13 signal values are known . in general",
    ", this is of course an insoluble problem ; we consider it here under the additional assumption that the signal has a sparse fourier transform .",
    "let us fix the notations : the signal is denoted by @xmath14 , but we have at our disposal only the @xmath15 , where the set @xmath16 is a subset of @xmath17 and @xmath18 .",
    "the fourier transform of signal @xmath0 is @xmath19 , defined by @xmath20 . in terms of the fourier basis functions @xmath21 ,",
    "@xmath0 can be written as @xmath22 ; this is the ( discrete ) fourier representation of @xmath0 .",
    "a signal @xmath0 is said to have a @xmath4-sparse fourier representation , if there exists a subset @xmath23 with @xmath24 , and values @xmath25 for @xmath26 , such that @xmath27 . for a signal that does not have a @xmath4-sparse fourier representation ,",
    "we denote by @xmath28 the optimal @xmath4-term sparse fourier representation of @xmath0 .",
    "this paper presents a sublinear algorithm to recover a @xmath4-sparse fourier representation of a signal @xmath0 from incomplete data .",
    "our algorithm also extends to the case where the fourier transform @xmath29 is not @xmath4-sparse , where we aim to find a near - optimal @xmath4-term fourier representation , i.e. @xmath30 , such that @xmath31    a typical situation where our study applies is the observation of non - equispaced data , where the samples are nevertheless all elements of @xmath32 for some @xmath33 . for a signal with evenly spaced data , the famous fast fourier transform ( fft )",
    "computes all the fourier coefficients in time @xmath34 .",
    "however , the requirement of equally distributed data by fft raises challenges for many important applications . for instance , because of the occurrence of instrumental drop - outs , the data may be available only on a set of non - consecutive integers .",
    "another example occurs in astronomy , where the observers can not completely control the availability of observational data : a telescope can only see the universe on nights when skies are not cloudy .",
    "in fact , computing the fourier representation from irregularly spaced data has wide applications @xcite in processing astrophysical and seismic data , the spectral method on adaptive grids , the tracking of lagrangian particles , and the implementation of semi - lagrangian methods .    in many of these applications ,",
    "a few large fourier coefficients already capture the major time - invariant wave - like information of the signal , and we can thus ignore very small fourier coefficients . to find a small set of the largest fourier coefficients and hence a ( near ) optimal @xmath4-sparse fourier representation of a signal that describes most of the signal characteristics is a fundamental task in applied fourier analysis .",
    "an equivalent version of this problem is as follows : define the matrix @xmath35 @xmath36 , where the @xmath37 are the locations of the available samples . given @xmath38 , we want to reconstruct the signal @xmath0 , or equivalently , its fourier coefficients @xmath39 , so that @xmath40 .",
    "this linear system is over - determined .",
    "several algorithms @xcite@xcite @xcite have provided efficient approaches to solve this problem . among all infft algorithms ,",
    "the iterative cgne approach of @xcite in the benchmark software nfft 2.0 is one of the fastest methods ; it takes time @xmath41 , where @xmath13 is the number of available points , @xmath42 is the number of dimensions , and @xmath43 is the smoothness for the original signal . the super - linearity relationship between the running time and @xmath1 ( recall @xmath44 , where @xmath45 is the percentage of available data ) poses difficulties in processing large dimensional signals , which have nothing to do with the unequal spacing .",
    "it follows that identifying a sparse number of significant modes and amplitudes is expensive for even fairly modest @xmath1 .",
    "our goal in this paper is to discuss much faster ( sublinear ) algorithms that can identify the sparse representation or approximation with coefficients @xmath46 and modes @xmath47 for unevenly spaced data .",
    "these algorithms will not use all the samples @xmath48 , but only a very sparse subset of them .",
    "our approach is based on the paper @xcite that shows how to construct the fourier representation for a signal @xmath0 with @xmath4-sparse fourier representation in time and space @xmath49 @xmath50 on equal spacing data .",
    "the algorithm contains some random elements ( which do not depend on the signal ) ; their approach guarantees that the error of estimation is of order @xmath51 with probability exceeding @xmath6 .",
    "the ideas in @xcite have also been applied by its authors to sparse wavelet , wavelet packet representation , and histograms @xcite .",
    "we have dubbed the whole family of algorithms ra@xmath52sta ( for randomized algorithm for sparse transform approximation ) ; when dealing only with fourier transforms , as is the case here , we specialize it to ra@xmath52sfa ( f for fourier ) .",
    "zou , gilbert , strauss and daubechies @xcite improved and implemented the algorithm greatly .",
    "it convincingly beats fft when the number of grid points @xmath1 is reasonably large .",
    "the crossover point lies at @xmath53 in one dimension , and at @xmath54 for data on a @xmath55 grid in two dimensions for a two - mode signal .",
    "when @xmath56 , ra@xmath52sfa surpasses @xmath57 at @xmath58 for one dimensional signals and @xmath59 for two dimensional signals .    in this paper",
    ", we modify ra@xmath52sfa to solve the irregularly spaced data problem .",
    "the new nera@xmath52sfa ( nonequispaced ra@xmath52sfa ) uses sublinear time and space @xmath60 @xmath61 to find a near - optimal @xmath4-term fourier representation , such that @xmath62 with high probability @xmath6 .",
    "similar to the ra@xmath52sfa algorithm , it outperforms existing infft algorithms in processing sparse signals of large size .",
    "* notation and terminology * denote by @xmath63 a signal that equals 1 on a set @xmath16 and zero elsewhere in the time domain .",
    "we say a signal @xmath64 is @xmath65 percent pure , if there exists a frequency @xmath66 and a signal @xmath67 , such that @xmath68 , with @xmath69 . to quantify the unevenness of the data , introduce a parameter @xmath3 to be the percentage of the available data over all the data , where @xmath13 is the number of available data .",
    "obviously a larger @xmath45 corresponds to more information about the signal .",
    "we use @xmath70-norm throughout the paper , which is denoted by @xmath71 . the convolution @xmath72 is defined as @xmath73 .",
    "it follows that @xmath74 .",
    "a box - car filter with width @xmath75 is defined as follows : @xmath76 in the frequency domain , this filter is in the form of @xmath77    a dilation operation on signal @xmath64 with a dilation factor @xmath78 is defined as @xmath79 for every points @xmath80 .",
    "* organization * the paper is organized as follows . in section 2 ,",
    "we give the outline of the ra@xmath52sfa algorithm .",
    "section 3 presents the modification of ra@xmath52sfa that deals with the unavailability of some samples by a greedy method . in section 4 ,",
    "an interpolation technique is introduced for better performance .",
    "finally , we compare numerical results with existing algorithms in section 5 .",
    "given a signal @xmath0 of length @xmath1 , the optimal @xmath4-term fourier representation @xmath28 uses only @xmath4 frequencies ; it is simply a truncated version of the fourier representation of @xmath0 , retaining only the @xmath4 largest coefficients .",
    "the following theorem is the main result of @xcite .",
    "let an accuracy factor @xmath81 , a failure probability @xmath82 , and a sparsity target @xmath83 be given .",
    "then for an arbitrary signal @xmath0 of length @xmath1 , ra@xmath52sfa will find a @xmath4-term approximation @xmath5 to @xmath0 , at a cost in time and space of order @xmath84 and with probability exceeding @xmath6 , so that @xmath85 .",
    "the striking fact is that ra@xmath52sfa can build a near - optimal representation @xmath5 in sublinear time @xmath86 instead of the @xmath34 time requirement of other algorithms .",
    "its speed surpasses fft as long as the length of a signal is sufficiently large .",
    "if a signal is composed of only @xmath4 modes , ra@xmath52sfa constructs @xmath0 without any error .",
    "the main procedure is a greedy pursuit with the following steps :    [ alg : total1]total scheme @xcite    1 .",
    "initialize the representation signal @xmath5 to 0 .",
    "set the maximum number of iterations @xmath87 .",
    "2 .   test whether @xmath88 appears to be less than some user threshold , @xmath89 .",
    "if yes , return the representation signal @xmath5 and the whole algorithm ends ; else go to step 3 .. 3 .",
    "locate fourier modes @xmath66 for the signal @xmath90 by isolation and group test procedures .",
    "estimate fourier coefficients at @xmath66 : @xmath91 .",
    "5 .   update the representation signal @xmath92 .",
    "if the total number of iterations is less than @xmath93 , go to 2 ; else return the representation @xmath5 .",
    "[ alg : total1 ]    the basic idea of algorithm [ alg : total1 ] is to identify significant frequencies and then estimate their corresponding coefficients . in order to locate those nonzero frequencies ,",
    "we first construct a new signal where a previous significant frequency becomes predominant . then a recursive approach called group test finds the exact label of this predominant mode , by splitting intervals , comparing energies , and keeping only intervals with large energies . after the frequency",
    "is located , coefficient estimation procedures give a good estimation by taking means and medians of random samples .",
    "ra@xmath52sfa samples from a signal , implicitly assuming that uniform and random sampling is possible , with a fixed cost per sample .",
    "this raises challenges for processing unevenly spaced data . specifically speaking ,",
    "fourier coefficients and norms can not be estimated properly .",
    "thus one has to modify steps 3 and 4 accordingly . in this section ,",
    "nera@xmath52sfa , a modified version of ra@xmath52sfa with greedy technique , is introduced to overcome these problems .",
    "the basic idea is a greedy pursuit for an available data point . whenever the algorithm samples at a missing data point , it searches some other random indices @xmath80 until it finds one available data point @xmath94 as the substitute .",
    "this technique is used in estimating both fourier coefficients and norms .",
    "a good data structure is important to save running time cost .",
    "we denote the availability of a data point by a label , say + 1 for available and 0 for unavailable .",
    "hence , the label is tested to see if its corresponding sample is valid .",
    "an alternative solution is to store all the sorted labels of available data in a long list .",
    "however , each search takes time @xmath95 , which introduces a @xmath96 factor into the whole computation . as the empirical results show , the running time of nera@xmath52sfa algorithm is linear to @xmath97 .",
    "for this reason , we selected the first method .",
    "we now give a more detailed discussion of the different procedures used in steps 3 and 4 of algorithm [ alg : total1 ] .",
    "first , we give the procedure for estimating fourier coefficients for unevenly spaced data as follows .    estimating individual fourier coefficients [ estcoef ] + input a signal @xmath0 , a frequency @xmath66 , @xmath98 , @xmath99 .    1 .   for @xmath100 2 .   for @xmath101",
    "+ randomly generate the index @xmath80 until @xmath94 is available . + then let @xmath102 .",
    "evaluate @xmath103 .",
    "3 .   take the means of @xmath104 samples @xmath105 , i.e. @xmath106 , where @xmath107 .",
    "4 .   take the median of @xmath108 samples @xmath109 , where @xmath110 .",
    "return @xmath111 as the estimation of the fourier coefficient @xmath112 .",
    "[ alg : coeff ]    next , we show that using unevenly spaced data leads to a very good approximation to the true coefficient .",
    "the first lemma is one of most fundamental theorems in randomized algorithms .",
    "it essentially states that by repeating an experiment enough times , a small probability event will happen eventually .",
    "[ lm : rept ] if an event happens with probability @xmath45 , then in the first @xmath113 iterations , it happens at least once with success probability @xmath6 .",
    "[ lm : rept ]    in our case , only @xmath3 percentage of the data is available , so that @xmath114 trials are needed to generate one available data point with success probability at least @xmath6 .",
    "in fact , most of the fourier coefficients of a characteristic function on a typical set @xmath16 are small , under some conditions .",
    "the following lemma makes this more explicit .",
    "[ lm : smallfilter ] suppose the components @xmath115 of a discrete random variable @xmath116 are identically and independently distributed in @xmath117 , with @xmath118 .",
    "define the random set @xmath119 to be the set of all available data ; @xmath120 is the fourier transform of @xmath121 . if @xmath122 , then + @xmath123 [ lm : smallfilter ]    first , we claim that @xmath124 .",
    "+ since @xmath125 , we have @xmath126 it follows that @xmath127 observe that @xmath128 , hence @xmath129 by markov s inequality , when @xmath130 , we have @xmath131 since @xmath132 , it follows that @xmath133 that is , for any @xmath134 , with probability at least @xmath135 @xmath136    in particular , we want both @xmath137 and @xmath138 to be small , meaning that @xmath45 can not be too small itself .",
    "next , we consider the conditions for the two coefficients @xmath112 and @xmath139 to be close .",
    "[ lm : diffest ] suppose the parameters @xmath16 , @xmath0 , @xmath140 , @xmath137 , @xmath138 , @xmath45 are as stated in lemma [ lm : smallfilter ] , and define @xmath141 .",
    "if @xmath142 , and @xmath143 , then , for any @xmath66 , @xmath144 with probability exceeding @xmath6 .",
    "[ lm : diffest ]    suppose the significant terms of signal @xmath0 are @xmath145 , where @xmath146 .",
    "+ since @xmath147 and thus @xmath148 , then @xmath149 therefore @xmath150 @xmath151 because @xmath132 , we have @xmath152 with probability at least @xmath153 for any @xmath154 .",
    "this implies that @xmath155 with probability at least @xmath156 + then @xmath157 for those @xmath158 , @xmath159 and we conclude similarly that @xmath160 , with probability at least @xmath6 .",
    "we shall use algorithm [ alg : coeff ] to estimate @xmath161 ; we now look at how close the approximation @xmath162 ( i.e. the output of algorithm [ alg : coeff ] ) of @xmath161 is to the true coefficient @xmath112 .",
    "[ lm : coefftot ] for a set of parameters @xmath16 , @xmath0 , @xmath140 , @xmath137 , @xmath138 , @xmath45 as stated in lemma [ lm : smallfilter ] , if @xmath142 , and @xmath163 , then algorithm [ alg : coeff ] for signal @xmath164 gives a good estimation @xmath162 of @xmath112 , such that @xmath165 with high probability.[lm : coefftot ]    lemma 4.2 in @xcite says that the coefficient estimation algorithm returns @xmath162 , such that @xmath166 by lemma [ lm : diffest ] @xmath167 thus @xmath168    finally , we derive the conclusion about estimating coefficients .",
    "[ lm : mycoeff2 ] for a set of parameters @xmath16 , @xmath0 , @xmath140 , @xmath137 , @xmath138 , @xmath45 as stated in lemma [ lm : smallfilter ] , if @xmath169 and @xmath142 , then every application of algorithm [ estcoef ] produces , for each frequency @xmath66 and each signal @xmath0 , and each @xmath170 , with high probability , an output @xmath162 ( after inputting @xmath171 ) , such that @xmath172 .    by lemma [ lm : coefftot ]",
    ", @xmath173 thus we have @xmath174 from the conditions @xmath175 , it follows that @xmath176    when we are able to get most of the data , the computational cost for estimating fourier coefficients on unevenly spaced data is only slightly more than for the evenly spaced data case .",
    "the time to compute the signal value remains almost the same as for the evenly spaced data case .",
    "the extra time , in the worst case @xmath177 , comes from visiting unavailable data .",
    "fortunately , the visit operation is very fast and therefore contributes little to the total time , especially when most of the data are available .",
    "moreover , as in @xcite , one can speed up the algorithm by using multi - step coarse - to - fine coefficient estimation procedures , which turns out to be more efficient than single - step accurate estimation ; the proof is entirely analogous to lemma 4.3 in @xcite .",
    "the basic idea for locating the label of a significant frequency is to compare the energies ( i.e. the @xmath70 norm ) of signals restricted in different frequency intervals .",
    "if the energy of some interval is relatively large , the significant mode is in that region with higher probability .",
    "we construct the following new signals to focus on certain intervals @xmath178}(\\sigma t)e^{\\frac{2\\pi it\\theta}{n}}\\ast s\\ ] ] where 2@xmath179 is the filter width , @xmath180 , @xmath78 and @xmath181 are random dilation and modulation factors .",
    "( please see @xcite for an explanation of the role of @xmath78 and @xmath181 ) . for convenience ,",
    "we denote @xmath182 by @xmath183 .",
    "we need to evaluate values @xmath183 for random indices @xmath184 .",
    "note that the signal @xmath64 results from the convolutions of two finite bandwidth box - car filters with the original signal @xmath0 . therefore , any missing point needed by the two convolutions would lead to a failure of computing @xmath185 .",
    "the total number of signal points involved depends on the number of nonzero taps in these two filters .",
    "moreover , random dilation and modulation factors of the second box - car filter make computation more tricky .",
    "one naive way is to dive into the two convolutions and sample each signal point .",
    "if it is not available , stop evaluating this @xmath185 and start with a new index @xmath80 .",
    "this definitely increases time cost by wasting abundant computation .",
    "for example , suppose five data are needed and only one of them is missing , then the algorithm may compute four data in vain in the worst case , where the missing data point is visited last in the sequence of 5 .",
    "to avoid the above situation , we first compute the locations of all the points that will be needed for the convolution ; only if they are all available will we start the computation .",
    "the locations related to the convolution are given in the following lemma .",
    "[ lm : location ] suppose we have a signal @xmath186 , where @xmath187 , @xmath188 , @xmath189 , and @xmath190 are dilation factors . from the definition of box car filter ,",
    "the taps for @xmath191 lies in the interval @xmath192 $ ] , the taps for @xmath193 in @xmath194 $ ] , then in order to evaluate @xmath183 , we need values of @xmath0 with indices at @xmath195 , where integers @xmath196 , @xmath197 .    to evaluate h(t ) , first let signal @xmath198 , then @xmath199 @xmath200 thus , in order to get the value of @xmath183 , we need values of all @xmath201 , where @xmath202 , with @xmath196 and @xmath203 .",
    "the scheme of the norm estimation algorithm is as follows .",
    "[ alg : norm ]    norm estimation [ estnorm ] + input : signal @xmath64 , @xmath204 , the number of iterations @xmath205 .",
    "+ while @xmath206 :    1 .",
    "randomly generate the index @xmath207 .",
    "2 .   compute all indices needed by the two convolutions : @xmath208 , where @xmath196 and @xmath203 .",
    "3 .   if all the points @xmath209 are available , then compute @xmath210 else go to step 1 and generate another index @xmath207 .",
    "4 .   estimate = 60-th percentile of the sequence @xmath211 , where @xmath212 .",
    "[ estnorm ]    if there exist satisfactory data groups , although maybe very few , the norm estimation will eventually find them .",
    "however , when most data are unavailable , the program may struggle in a long loop and take a huge amount of time .",
    "we introduce some tricks to avoid this .",
    "for example , set an upper bound max on the number of the loops .",
    "if it is reached , just use the sample points generated so far to estimate the norms .",
    "this technique may lead to a larger error , and thus hamper our frequency identification .",
    "however , by repeating the calculation , as stipulated by lemma 3.2 , we reduce the inaccuracy .",
    "anyway we can not hope to recover the signal , if @xmath45 is too small .",
    "the following lemma investigates the number of repetitions to get a satisfactory data group for estimating norms .",
    "suppose @xmath193 and @xmath213 are two box - car filters with numbers of taps @xmath214 and @xmath215 respectively .",
    "define @xmath216 .",
    "then @xmath217 has @xmath218 nonzero taps in the time domain .",
    "randomly choose an index for signal @xmath183 , then after @xmath219 iterations , we can get at least one satisfactory index with high probability @xmath6 .",
    "it is easy to prove by lemma [ lm : rept ] .",
    "here is a new scheme for estimating norms , which uses much fewer samples than the original one and still achieves good estimation . in @xcite ,",
    "we propose a lemma that enabled us to achieve a good norm estimation by only a few samples .",
    "the following lemma is its adaption to the case of unevenly spaced data .    if a signal @xmath64 is 95% pure and if @xmath220 , the output of algorithm [ estnorm ] gives an estimation of its energy which exceeds @xmath221 with probability exceeding @xmath6 .",
    "the proof is very similar to that of lemma 4.5 in @xcite .",
    "we shall present only the difference of these two proofs .",
    "suppose we sample @xmath222 times for the signal @xmath64 .",
    "let @xmath223 , with @xmath224 as its complement , we have @xmath225 on the other hand , we know that the signal is 95@xmath226 pure , i.e. @xmath227 for some @xmath228 . by modulating ,",
    "@xmath228 can be moved to 0 ; therefore , we can , without loss of generality , suppose most of the energy concentrates at the frequency 0 ; then @xmath229 so we have @xmath230 on the other hand,@xmath231 , so that @xmath232 let @xmath233 ; the above inequality becomes @xmath234 thus @xmath235 .",
    "define now a random variable @xmath236 ; it will be useful to estimate @xmath237 and the expectation of the random variable @xmath238 , @xmath239 suppose now we sample the signal @xmath64 @xmath222 times , and take the percentile of the numbers @xmath240 . by chernoff s standard argument and similar procedure of lemma 4.5 in @xcite , we have for @xmath241 , @xmath242^r .",
    "\\nonumber \\end{aligned}\\ ] ] take @xmath243 , then @xmath244 the right hand side of ( 35 ) is increasing in @xmath245 on the interval @xmath246 $ ] ; since @xmath247 , we obtain an upper bound by substituting @xmath248 for @xmath245 : @xmath249^r = \\left [ 1.97 \\alpha^{0.6 } ( 1-\\alpha)^{0.4 } \\right ] ^r \\leq e^{-0.90 r}.\\end{aligned}\\ ] ]    for @xmath250 , we need @xmath251 , we have @xmath252    this norm estimation procedure will be used repeatedly in the group testing step below .      for a significant frequency in signal @xmath0 , isolation aims to construct a series of new signals , such that this significant frequency becomes predominant in at least one of the new isolation signals",
    ".    given signals @xmath0 , @xmath253 , and the parameters as stated in lemma [ lm : smallfilter ] .",
    "suppose @xmath254 , @xmath255 . if @xmath142 , then for each @xmath66 with @xmath256 , isolation algorithm can create a signal @xmath257 , such that @xmath258    [ lem : iso ]    since @xmath259 , we have @xmath260 .",
    "then there exists some @xmath261 , such that @xmath262 lemma [ lm : diffest ] states that @xmath263",
    ". therefore @xmath264 isolation algorithm returns @xmath265 with @xmath266 , as described in @xcite . for any @xmath66 with @xmath267 ,",
    "there exists some @xmath268 , such that @xmath269    let @xmath270 , then    @xmath258    theoretically , in order to capture a significant mode , we need @xmath271 signals .",
    "however , in practice , much fewer signals is enough to achieve this goal .",
    "isolation has produced several signals , one of which contains the most significant frequency .",
    "group testing uses repeated zoom - ins on one of the signals , and norm testing to select where to zoom in , in order to determine the frequency .",
    "the goal of group testing is thus to find the most significant mode of the signal @xmath272 from isolation .",
    "it uses recursive procedures msb ( most significant bit ) to approach this mode gradually .    _ definition",
    "_ : denote a set @xmath273 by @xmath274 .",
    "group test algorithm is given as follows .",
    "[ alg : grouptest]group testing + input isolation signal @xmath257 to @xmath275 , @xmath276 , @xmath277 + while @xmath278 , in the @xmath279-th iteration ,    1 .",
    "find the most significant bit @xmath280 and the number of significant intervals @xmath111 by the procedure msb .",
    "update @xmath281 , modulate the signal @xmath282 by @xmath283 and dilate it by a factor of @xmath284 . store it in @xmath285 .",
    "call group test again with the new signal @xmath282 , denote its output by @xmath286 .",
    "4 .   update the accumulation factor @xmath287 .",
    "if @xmath288 , then @xmath289 . 6 .   return @xmath290 ;    the msb procedure is as follows .",
    "[ alg : msb]msb ( most significant bit ) + input : signal @xmath282 with length @xmath1 , a threshold @xmath291 .    1 .",
    "get a series of new signals @xmath292 , @xmath293 .",
    "2 .   estimate the energies @xmath294 of @xmath295 , @xmath293 .",
    "3 .   for @xmath296 ,",
    "compare the energies @xmath297 with all other energies @xmath294 , where @xmath298 . if @xmath299 for all these @xmath268 , label it as an interval with large energy .",
    "4 .   find the longest consecutive intervals of large energies .",
    "take their center as @xmath300 , and the number of those intervals as @xmath301 .",
    "if @xmath302 , then do the original msb in _",
    "@xcite _ to get @xmath280 and set @xmath303 ; 6 .",
    "return the dilation - related factor @xmath111 and the most significant bit @xmath280 .",
    "[ alg : msb ]    for convenience , we denote @xmath304 by @xmath305 .    given a @xmath306 pure signal @xmath307 , suppose @xmath308 .",
    "then algorithm [ alg : grouptest ] , with algorithm [ alg : msb ] as its subroutine , can find the significant frequency @xmath309 of the signal @xmath307 with high probability .",
    "the proof is similar to that of lemma 5 in @xcite , with some changes :    since the signal @xmath307 is @xmath310 pure , there exist a frequency mode @xmath309 and a signal @xmath67 , such that @xmath311 , where @xmath312 and @xmath313 . without loss of generality ,",
    "assume @xmath314 $ ] .",
    "the whole region is divided into 16 subintervals @xmath315 $ ] , where @xmath316 . to estimate @xmath317 for @xmath318",
    ", we use that @xmath319 for @xmath318 .",
    "it follows that @xmath320 therefore the estimation @xmath321 of @xmath322 satisfies : @xmath323 next consider the energy of @xmath324 .",
    "@xmath325 since @xmath326 , we have @xmath327 .",
    "thus    @xmath328 it follows that @xmath329 then we compare @xmath330 with the lower bound of the estimation of @xmath331 , which is @xmath332 which is less than the estimation for @xmath333 in general , @xmath334 , for @xmath268 not necessarily 0 .",
    "therefore we compare @xmath335with @xmath336 , where @xmath337 .",
    "if there is some @xmath268 with @xmath336 apparently larger than @xmath338 , then we conclude @xmath339 . otherwise , possibly @xmath340 . by the above argument",
    ", we can always eliminate 9 consecutive interval regions out of 16 , leaving a cyclic interval of length at most @xmath341 .",
    "the remaining proof is exactly the same as lemma 8 in paper @xcite .",
    "remark : in @xcite , we showed that group testing works for a box - car filter with width more than @xmath342 , i.e. @xmath343 . in that case , @xmath75 intervals are sufficient .",
    "a similar conclusion still holds in the unevenly spaced data case .",
    "however , the lemma above proves the success of group testing under different conditions . in our proof",
    ", we use a box - car filter with much shorter width , namely 3 in time domain ; this works well if 16 intervals are taken . in practice",
    ", we use these shorter filters ; we can usually ( if @xmath4 is small ) get away with using much fewer intervals as well ( e.g. 3 instead of 16 ) .      in summary , given a signal @xmath0 , for an accuracy @xmath81 and for @xmath4 modes",
    ", we can find a very good approximation of the signal @xmath0 by using algorithm [ alg : total1 ] .",
    "[ lm : totalcost ] given a signal @xmath0 , an accuracy @xmath81 , success probability @xmath6 , algorithm [ alg : total1 ] can output a @xmath4-term representation @xmath5 with sum - square - error @xmath344 , where @xmath345 is the @xmath4-term representation for @xmath0 with the least sum - square - error , with time and space cost @xmath346 for computing and @xmath347 @xmath348 for just visiting samples .",
    "the greedy algorithm described above is fast .",
    "when @xmath45 is sufficiently large ( e.g. @xmath349 ) , the approach proposed and discussed in the previous section works well . for smaller @xmath45 ,",
    "the amount of time wasted to find available sample groups becomes unacceptably long .",
    "for example , when @xmath350 , @xmath351 , @xmath352 , the algorithm could nt find the signal within 200 greedy pursuit iterations .",
    "for this reason , we introduced an interpolation technique to get an approximate value of the missing point in the norm estimation procedure . this algorithm is efficient even in smaller @xmath45 cases .",
    "the task of interpolation is to estimate @xmath94 for arbitrary @xmath80 by drawing a smooth curve through all the known points @xcite .",
    "it is called interpolation when the desired @xmath80 is between the largest and smallest of these @xmath353 s .",
    "we use lagrange polynomial interpolation , one of the simplest and most popular interpolation techniques .",
    "generally , the number of interpolation points determines the degree of a polynomial .",
    "a polynomial of higher degree is smoother with smaller approximation errors at the expense of more computation .",
    "thus we choose a second degree polynomial , as a balance between computational complexity and accuracy .",
    "it is given explicitly by lagrange s classical formula .",
    "if the three nearest neighbors are @xmath354 , @xmath355 , @xmath356 , the polynomial is @xmath357    if @xmath94 is three times differentiable in an interval @xmath358 $ ] , and the points @xmath359 $ ] are different , then there exists some @xmath360 $ ] , such that the approximation error is @xmath361 .",
    "we introduce the interpolation scheme into estimating norms .",
    "the idea is to estimate the value of a missing point by the lagrange interpolation .",
    "the detailed algorithm for estimating norms is as follows .",
    "estimate norm with interpolation technique + input : signal @xmath64 , @xmath204 , the maximum number of samples @xmath362 .    1 .",
    "randomly generate the index @xmath207 , where @xmath363 .",
    "2 .   for each @xmath364 , if @xmath210 is not available , estimate @xmath365 by lagrange interpolation ; else compute @xmath210 directly .",
    "3 .   estimation = 60-th percentile of the sequence @xmath211 , where @xmath212 .",
    "note that we use interpolation _ only _ in norm estimation steps , where precision is less critical .",
    "with less precise norm estimation , the localization of important modes could still work well when iterated . for coefficient estimation , which needs to be more precise ,",
    "we always search for available samples .",
    "in this section , we present striking numerical results of nera@xmath52sfa , comparing to the inverse non - equispaced fast fourier transform ( infft ) algorithms .",
    "the popular benchmark software nfft version 2.0 is used to give performance of infft , with default cgne_r method and dirichlet kernel .",
    "its time cost excludes the precomputation of samples values , which takes @xmath366 .",
    "numerical experiments show the advantage of our nera@xmath52sfa algorithm in processing large amount of data .",
    "we begin in section 5.1 with comparing nera@xmath52sfa with infft for some one and two dimensional examples with different length . in section 5.2",
    ", the performance for different number of modes is shown . finally , we test the capability of nera@xmath52sfa to recover the signal in the situation with a large amount of missing data and in presence of large noise .",
    "all the experiments were run on an amd athlon(tm ) xp1900 + machine with cache size 256 kb , total memory 512 mb , linux kernel version 2.4.20 - 20.9 and compiler gcc version 3.2.2 .",
    "the numerical data is an average of 10 runs of the code ; errors are given in the @xmath70 norm .",
    "we ran the comparison for a 8-mode superposition signal @xmath367 , plus white noise @xmath368 with the standard deviation @xmath369 , damped by a factor of @xmath370 , ( so that @xmath371 ; since @xmath372 , this implies @xmath373 ) .",
    "other parameters are @xmath374 , @xmath375 , @xmath376 , and @xmath377 .",
    "the missing data are randomly and uniformly distributed .",
    "nera@xmath52sfa outperforms infft in speed when @xmath1 is large ; see table [ tab : b13 ] and figure [ fig : diffn1d ] .",
    "the corresponding crossover point is @xmath378 .",
    "for example , to process @xmath379 data , more than nineteen minutes ( estimated ) are needed for infft versus approximately one second for nera@xmath52sfa .",
    "experiments support the theoretical conclusion that nera@xmath52sfa would be faster than infft after some @xmath1 for a sparse signal ; whatever the sparsity , i.e. whatever the value of @xmath4 , there always exists some crossover @xmath1 .",
    ".[tab : b13]experiments with fixed @xmath374 , @xmath380 , @xmath381 ( one dimension ) , and varying length @xmath1 of signals ; an i.i.d .",
    "white noise is added with @xmath369 , or @xmath382 ( see text ) . for each length of the signal ,",
    "10 different runs were carried out ; the average result is shown .",
    "we did all the tests for nera@xmath52sfa with lagrange interpolation , as explained in the text .",
    "two kinds of time costs for nera@xmath52sfa are provided .",
    "one is the total running time and another is the running time excluding the sampling time .",
    "the time of infft does not include the precomputation time for samples . [ cols=\"^,^,^,^ \" , ]     10 r. bass and k. grchenig , _ random sampling of multivariate trigonometric polynomials _ , siam j. math .",
    "36 ( 2004 ) , pp .",
    "773 - 795 .",
    "a. bjrck .",
    "_ numerical methods for least squares problems_. siam , philadelphia , 1996 . j.p .",
    "boyd , _ a fast algorithm for chebyshev , fourier and sinc interpolation onto an irregular grid _ , j. comput .",
    "phys . , 103 ( 1992 ) , pp .",
    "243 - 257 .",
    "e. c__andes _ _ , j. romberg , and t. tao , robust uncertainty principles : exact signal reconstruction from highly incomplete frequency information , http://arxiv.org/pdf/math.ca/0411273 h. fassbender , _ on numerical methods for discrete least - squares approximation by trigonometric polynomials _ , math .",
    ", 66(1997 ) , pp719 - 741 . h. feichtinger , k__. _ _ grchenig and t. strohmer , _ efficient numerical methods in non - uniform sampling theory _ , numer . math . , 69 ( 1995 ) , pp423 - 440 .",
    "a. c. gilbert , s. guha , p. indyk , y. kotidis , s. muthukrishnan , m. strauss , _ fast , small - space algorithms for approximate histogram maintenance_. stoc 2002 : 389 - 398 .",
    "gilbert , s. guha , p. indyk , s. muthukrishnan and m. strauss , _ near - optimal sparse fourier representations via sampling _ , stoc , 2002 a.c .",
    "gilbert , s. muthukrishnan and m. strauss , improved time bounds for near - optimal sparse fourier representation , to appear .",
    "l. greengard and j. lee . accelerating the nonuniform",
    "fast fourier transform , siam review , 46 ( 2004 ) , pp .",
    "443 - 454 .",
    "g. grimmett and d. stirzaker .",
    "_ probability and random processes_. oxford university press , 2001 .",
    "conjugate gradient type method for ill - posed problems .",
    "wiley , new york , 1995 .",
    "s. kunis and d. potts , _ stability results for scattered data interpolation by trigonometric polynomials _ , preprint .",
    "s. kunis , d. potts , _ nfft , software , c subroutine library , _",
    "http://www.math.uni-luebeck.de/potts/nfft , 2002 - 2004 .",
    "s. kunis , d. potts , g. steidl , _ fast fourier transform at nonequispaced knots : a user s guide to a c - library _ , manual of nfft 2.0 software .",
    "y. mansour , _ randomized interpolation and approximation of sparse polynomials _ , siam journal on computing 24:2 ( 1995 ) .",
    "a. oppenheim , a. willsky with s. nowab .",
    "_ signals and systems_. prentice hall , 1998 .",
    "w. press , s. teukolsky , w. vetterling and b. flannery .",
    "_ numerical recipes in c : the art of scientific computing_. cambridge university press , 1992 . l. reichel , g. s. ammar , and w. b. gragg .",
    "_ discrete least squares approximation by trigonometric polynomials .",
    "comput . , 57(1991 ) , pp .",
    "273 - 289 .",
    "a. f. ware , _",
    "fast approximate fourier transforms for irregularly spaced data _",
    ", siam rev .",
    ", 40 ( 1998 ) , pp .",
    "j. zou , a.c .",
    "gilbert , m. strauss and i. daubechies , _ theoretical and experimental analysis of a randomized algorithm for sparse fourier transform analysis _ , submitted to journal of computational physics ."
  ],
  "abstract_text": [
    "<S> we present a sublinear randomized algorithm to compute a sparse fourier transform for nonequispaced data . </S>",
    "<S> suppose a signal @xmath0 is known to consist of @xmath1 equispaced samples , of which only @xmath2 are available . </S>",
    "<S> if the ratio @xmath3 is not close to 1 , the available data are typically non - equispaced samples . </S>",
    "<S> then our algorithm reconstructs a near - optimal @xmath4-term representation @xmath5 with high probability @xmath6 , in time and space @xmath7 @xmath8 , such that @xmath9 , where @xmath10 is the optimal @xmath4-term fourier representation of signal @xmath0 . the sublinear @xmath11 time is compared to the superlinear @xmath12 time requirement of the present best known inverse nonequispaced fast fourier transform ( infft ) algorithms . </S>",
    "<S> numerical experiments support the advantage in speed of our algorithm over other methods for sparse signals : it already outperforms infft for large but realistic size @xmath1 and works well even in the situation of a large percentage of missing data and in the presence of noise . </S>"
  ]
}