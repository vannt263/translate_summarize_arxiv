{
  "article_text": [
    "neural networks ( nn s ) have become in the last years a very effective instrument for solving many difficult problems in the field of signal processing due to their properties like non - linear dynamics , adaptability , self - organization and high speed computational capability ( see for example @xcite and the papers therein quoted ) .",
    "aim of this paper is to show the feasibility of the use of nn s to solve difficult problems of signal processing regarding the so called virgo project .",
    "gravitational waves ( gw s ) are travelling perturbations of the space - time predicted by the theory of  general relativity , emitted when massive systems are accelerated .",
    "up to now , there is only an indirect evidence of their existence , obtained by the observations of the binary pulsar system psr 1913 + 16 .",
    "moreover , the direct detection of gw s is not only a relevant test of general relativity , but the start of a new picture of the universe .",
    "in fact , gw s carry complementary information with respect to electromagnetic and optical waves , since the gw s are practically not absorbed by the matter .",
    "the aim of the virgo experiment is the direct detection of gravitational waves and , in joint operation with other similar detectors , to perform gravitational waves astronomical observations .",
    "in particular , the virgo project is designed for broadband detection from @xmath0 to @xmath1 .",
    "the principle of the detector is shown in figure  1 .",
    "a @xmath2 @xmath3 arm - length michelson interferometer with suspended mirrors ( test masses ) is used .",
    "the phase difference @xmath4 between the two arms is amplified using fabry - perot cavities of finesse @xmath5 in each arm .",
    "aiming for detection sensitivity of @xmath6 , virgo is a very delicate experimental challenge because of the competition between various sources of noise and the very small expected signal .",
    "in fact , the interferometer will be tuned on the dark fringe , and then the signal to noise ratio will be mainly limited , in the above defined range of sensitivity , by residual seismic noise , thermal noise of the suspensions photon counting noise ( shot noise ) . in figure 2 the overall sensitivity of the apparatus is shown . in this figure",
    "it is easy to see the contribution of the different noise sources to the global noise .    in this context",
    "we use a multi - layer perceptron ( mlp ) nn with the back - propagation learning algorithm to model and identify the noise in the system , because we experimentally found that fir nn s and elman nn s did not work in a satisfying manner .",
    "both the fir @xcite and elman @xcite models proved to be very sensible to overfitting and were not stable .",
    "furthermore the elman network required a great number of hidden units , while the fir network required a great number of delay terms .",
    "instead , the mlp proved succesfull and easy to train because we used the bayesian learning paradigm .",
    "nn s are massively parallel , distributed processing systems .",
    "they are composed of a large number of processing elements ( called nodes , units or neurons ) which operate in parallel .",
    "scalars ( called weights ) are associated to the connections between units and determine the strength of the connections themselves .",
    "computational capability is due to the connections between the units and to their collective behaviour .",
    "furthermore , information representation is distributed , i.e. no single unit is charged with specific information .",
    "nn s are well - known for their universal approximation capability @xcite .",
    "system identification consists in finding the input - output mapping of a dynamic system .",
    "a discrete - time multi - input multi - output ( mimo ) system ( or a continuous - time sampled - data system ) can be described with a set of non - linear difference equations of the form ( _ input - state - output _ representation ) : @xmath7 where @xmath8 is the state vector of the system , @xmath9 is the input vector and @xmath10 is the output vector .",
    "since we can not always access the state vector of the system , therefore we can use an input - output representation of the form : @xmath11   \\label{eq : io}\\end{aligned}\\ ] ] where @xmath12 and @xmath13 are the maximum lags of the input and output vectors , respectively , and @xmath14 is the pure time - delay ( or dead - time ) in the system .",
    "this is called an arx model ( autoregressive with exogenous inputs , ) and it can be shown that a wide class of discrete - time systems can be put in this form  @xcite . to build a model of the form  ( [ eq : io ] ) , we must therefore obtain an estimation of the functional @xmath15 $ ] , which generally is nonlinear .",
    "given a set of input - output pairs , a neural network can be built @xcite which approximates the desired functional @xmath16 $ ] .",
    "such a network has @xmath17 inputs and @xmath18 outputs ( see figure 3 ) .",
    "a difficulty in this approach arises from the fact that generally we do not have information about the model order ( i.e. the maximum lags to take into account ) unless we have some insight into the system physics .",
    "furthermore , the system is non - linear .",
    "recently @xcite a method has been proposed for determining the so - called _ embedding dimension _ of nonlinear dynamical systems , when the input - output pairs are affected by very low noise .",
    "furthermore , the lags can be determined by evaluating the _ average mutual information _ ( ami)@xcite . such methodologies , although not always successful , can be nevertheless used as a starting point in model design .",
    "in the virgo data analysis , the most difficult problem is the gravitational signal extraction from the noise due to the intrinsic weakness of the gravitational waves , to the very poor signal - to - noise ratio and to their not well known expected templates .",
    "furthermore , the virgo detector is not yet operational , and the noise sources analyzed are purely theoretical models ( often stationary noises ) , not based on experimental data .",
    "therefore , we expect a great difference between the theoretical noise models and the experimental ones . as a consequence",
    ", it is very important to study and to test algorithms for signal extraction that are not only very good in signal extraction from the theoretical noise , but also very adaptable to the real operational conditions of virgo .",
    "for this reason , we decided the following strategy for the study , the definition and the tests of algorithms for gravitational data analysis .",
    "the strategy consists of the following independent research lines .",
    "the first line starts from the definition of the expected theoretical noise models .",
    "then a signal is added to the virgo noise generated and the algorithm is used for the extraction of the signal of known and unknown shape from this noise at different levels of signal - to - noise ratio .",
    "this will allow us to make a number of data analysis controlled experiments to characterize the algorithms .",
    "the second line starts from the real measured environmental noise ( acoustic , electromagnetic , ... ) and tries to identify the noise added to a theoretical signal . in this way we can test the same algorithms in a real case when the noise is not under control .    using this strategy , at the end ,",
    "when in a couple of years virgo will be ready for the first test of data analysis , the procedure will be moved to the real system , being sure to find small differences from theory and reality after having acquired a large experience in the field .",
    "as we have seen in the introduction , the virgo interferometer can be characterized by a sensitivity curve , which expresses the capability of the system to filter undesired influences from the environment , and which could spoil the detection of gravitational waves ( such a noise is generally called seismic noise ) .",
    "the sensitivity curve has the following expression : @xmath19 + s_{\\nu } & \\quad f\\geq f_{\\textrm{min } } \\\\",
    "s(f_{\\textrm{min } } ) & \\quad f < f_{\\textrm{min } } \\end{array } \\right .",
    "\\label{eq : exprsenscurve}\\ ] ] where :    * @xmath20 * @xmath21 is the shot noise cut - off frequency * @xmath22 is the pendulum mode * @xmath23 is the mirror mode * @xmath24 is the shot noise    the contribution @xmath25 of violin resonances is given by : @xmath26 ^{2}+\\phi _ { i}^{2}}+\\frac{1}{i^{4}}\\frac{f_{i}^{(f)}}{f}\\frac{c_{f}\\phi _ { i}^{2}}{\\left [ \\left ( \\frac{f}{if_{i}^{(f)}}\\right ) ^{2}-1\\right ] ^{2}+\\phi _ { i}^{2 } }   \\label{eq : violinres}\\ ] ] where the different masses of close and far mirrors are taken into account :    * @xmath27 * @xmath28 * @xmath29 * @xmath30 * @xmath31    note that we used a simplified curve for our simulations , in which we neglected the resonances ( see figure 4 ) .",
    "samples of the sensitivity curve @xmath32 can be obtained by evaluating the expression ( [ eq : exprsenscurve ] ) at a set of frequencies @xmath33 , @xmath34 $ ] .",
    "the samples of the sensitivity curve allow us to obtain the system transfer function ( in the frequency domain ) , @xmath35 , such that : @xmath36 > from this , by means of an inverse discrete fourier transform , samples of the system transfer function ( in the time domain ) can be obtained .",
    "our aim is to build a model of the system transfer function ( [ eq : tranfun ] ) .    assuming that the interferometer input noise is a zero mean gaussian process , by feeding it to the system ( i.e. filtering it through the system transfer function ) we obtain a coloured noise .",
    "the so obtained white noise - colored noise pairs can then be used to train an mlp , as shown in figure 3 .",
    "the first step in building an arx model is the model order determination . to determine suitable lags which describe the system dynamics",
    ", we used the ami criterion @xcite .",
    "this can be seen as a generalization of the autocorrelation function , used to determine lags in linear systems .",
    "a strong property of the ami statistic is that it takes into account the non - linearities in the system .",
    "usually , the lag is chosen as the first minimum of the ami function .",
    "the result is reported in figure  5 , in which the first minimum is at 1 . to find how many samples are necessary to unfold the ( unknown ) state - space of the model ( the so called _ embedding dimension _",
    "@xcite ) we used the method of @xcite , the lipschitz decomposition .",
    "the result of the search is reported in figure  6 .    from the figure",
    "we can see that , starting from lag three , the order index decreases very slowly , and so we can derive that the width of the input window is at least three . in order to test",
    "the nn s capability in solving the problem , we chose a width of 5 , both for input and output ( i.e. @xmath37 ) . in this way , we obtained a nn with a simple structure .",
    "furthermore , some preliminary experiments showed that the system dead - time is @xmath38 ; this gives the best description of the system dynamics .",
    "another fundamental issue is the nn complexity , i.e. the number of units in the hidden layers of the nn .",
    "usually the determination of the network complexity is critical because of the risks of overfitting .",
    "since the nn was trained following a bayesian framework , then overfitting was of no concern ; so we directed our search for a model with the minimum possible complexity . in our case",
    ", we found a hidden layer with 6 @xmath39 units is optimal .",
    "the bayesian learning framework ( see @xcite and @xcite ) allows the use of a _ distribution _ of nn s , that is , the model is a realization of a random vector whose components are the nn weights .",
    "the so obtained nn is the _ most probable _ given the data used to train it .",
    "this approach avoids the bias of the cross - validatory techniques commonly used in practice to reduce model overfitting @xcite . to allow for a smooth mapping which does not produce overfitting , several regularization parameters ( also called",
    "_ hyperparameters _ ) embedded in the error criterion have been used :    * one for each set of connections out of each input node , * one for the set of connections from hidden to output units , * one for each of the bias connections , * one for the data - contribution to the error criterion .    usually , the hyperparameters of the first three kinds are called _ alphas _ , while the last is called a _",
    "beta_.    the approach followed in the application of the bayesian framework is the `` exact integration '' scheme , where we sample from the analytical form of the distribution of the network weights .",
    "this can be done if we assume an analytic form for the prior hyperparameters distribution , in particular a distribution uniform on a logarithmic scale : @xmath40 this distribution is _ non - informative _ , i.e. it embodies our complete lack of knowledge about the values the hyperparameters should take .",
    "the chosen model was trained using a sequence of little less than a million of patterns ( we sampled the system at 4096hz for 240s ) normalized to zero mean and unity variance with a _ whitening _ process .",
    "note that the input - output pairs were processed through discrete integrators to obtain pattern - target pairs , as shown in figure 3 .",
    "the nn was then tested on a 120s long sequence .",
    "the nn was trained for @xmath41 epochs , with the hyperparameters being updated every @xmath42 epochs .",
    "a close look at the @xmath43 hyperparameters shows that all the inputs are relevant for the model ( they are of the same magnitude ; note that this further confirms the pre - processing analysis ) .",
    "the @xmath44 hyperparameter shows that the data contribution to the error is very small ( as we would expect , since the data are synthetic ) .",
    "the simulations were made using the matlab@xmath45 language , the netlab toolbox  @xcite and other software designed by us .    in figure  7 , the psds of the target and the predicted time series are shown ; in the lower part of the figure is reported the psds of the prediction residuals .    in figure  8 ,",
    "the psd of a 100hz sine wine added to the noise is shown , with the signal extracted by the network .",
    "as can be seen , the network recognizes the frequency of the sine wave with the maximum precision allowed by the residuals .",
    "in this paper we have shown some preliminary tests on the use of nn s for signal processing in the virgo project .",
    "some observations can be elicited from the experimental results :    * in evaluating the power spectral densities ( psds ) , we made the hypothesis that the system is sampled at @xmath46 .",
    "it is only a work hypothesis , but it shows how the network reproduces the system dynamics up to @xmath47 . note that the psds are nearly the same also if we were near the nyquist frequency . *",
    "the psd of the residuals shows a nearly - white spectrum , which is index of the model goodness ( see @xcite ) .",
    "- : :    to increase the system model order and to test if there are    significant differences in prediction ; - : :    to test the models with a greater number of samples to obtain a better    estimate of the system dynamics ; - : :    to model the noise inside the system model to improve the system    performance and to allow a multi - step ahead prediction ( i.e. an    output - error model )"
  ],
  "abstract_text": [
    "<S> in this paper a neural networks based approach is presented to identify the noise in the virgo context . </S>",
    "<S> virgo is an experiment to detect gravitational waves by means of a laser interferometer . </S>",
    "<S> preliminary results appear to be very promising for data analysis of realistic interferometer outputs . </S>"
  ]
}