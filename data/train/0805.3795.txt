{
  "article_text": [
    "@xmath1 denotes the space of square integrable functions @xmath3 with norm @xmath4 .",
    "we use @xmath5 to mean @xmath6 .",
    "the following result was announced in @xcite .",
    "[ thmbumps]for any @xmath7 and any @xmath8 there exists @xmath9 and @xmath10 and @xmath11 such that@xmath12    since the span of the hermite functions is dense in @xmath13 we have for some @xmath14@xmath15 now use finite backward differences to approximate the derivatives .",
    "we have for some small @xmath9@xmath16   + b_{2}\\tfrac{1}{t^{2}}\\left [ e^{-x^{2}}-2e^{-\\left (   x - t\\right )   ^{2}}+e^{-\\left (   x-2t\\right )   ^{2}% } \\right ] \\nonumber\\\\ & + b_{3}\\tfrac{1}{t^{3}}\\left [   e^{-x^{2}}-3e^{-\\left (   x - t\\right )   ^{2}% } + 3e^{-\\left (   x-2t\\right )   ^{2}}-e^{-\\left (   x-3t\\right )   ^{2}}\\right ] + \\cdots\\nonumber\\\\ & = \\overset{n}{\\underset{n=0}{% % tcimacro{\\tsum } % % beginexpansion { \\textstyle\\sum } % endexpansion } } b_{n}\\frac{1}{t^{n}}\\overset{n}{\\underset{k=0}{% % tcimacro{\\tsum } % % beginexpansion { \\textstyle\\sum } % endexpansion } } \\left (   -1\\right )   ^{k}\\binom{n}{k}e^{-\\left (   x - kt\\right )   ^{2}}% \\text{.}\\label{pfmaincoeffs}%\\end{aligned}\\ ] ]    this result may be surprising ; it promises we can approximate to any degree of accuracy a function such as the following characteristic function of an interval@xmath17   } \\left (   x\\right )   : = \\left\\ { \\begin{array } [ c]{l}% 1\\\\ 0 \\end{array } \\right .",
    "\\begin{array } [ c]{l}% \\text{for } x\\in\\left [   -10,-11\\right ] \\\\",
    "\\text{otherwise}% \\end{array}\\ ] ] with support far from the means of the gaussians @xmath18 which are located in @xmath19 at the points @xmath20 .",
    "the graphs of these functions @xmath21 are extremely simple geometrically , being gaussians with the same variance .",
    "we only use the right translates , and they all shrink precipitously ( exponentially ) away from their means .",
    "@xmath22{2.5261in}{\\begin{center } \\includegraphics [ natheight=9.364200 in , natwidth=13.749600 in , height=1.7244 in , width=2.5261 in ] % { i100.png}% \\\\ $ \\sum a_n e^{-\\left (   x - nt\\right )   ^2}\\approx$ characteristic function ?",
    "\\end{center}}}% % endexpansion\\ ] ]    _ surely there is a gap in this sketchy little proof ? _    no . we will , however , flesh out the details in section [ secappalgo ] . the coefficients @xmath23",
    "are explicitly calculated and the @xmath2 convergence carefully justified . but these details are elementary .",
    "we include them in the interest of appealing to a broader audience .",
    "_ then is this merely another pathological curiosity from analysis ?",
    "we probably need impractically large values of _ @xmath14 _ _  to approximate any interesting functions . _ _",
    "no , @xmath14 need only be as large as the hermite expansion demands .",
    "certainly this particular approach depends on the convergence of the hermite expansion , and for many applications hermite series converge slower than other fourier approximations ",
    "after all , hermite series converge on all of @xmath24 while , e.g. , trigonometric series focus on a bounded interval .",
    "hermite expansions do have powerful convergence properties , though .",
    "for example , hermite series converge uniformly on finite compact subsets whenever @xmath25 is twice continuously differentiable ( i.e. , @xmath26 ) and @xmath27 for some @xmath28 as @xmath29 .",
    "alternately if @xmath25 has finitely many discontinuities but is still @xmath26 elsewhere and @xmath30 the expansion again converges uniformly on any closed interval which avoids the discontinuities @xcite , @xcite : .",
    "if @xmath25 is smooth and properly bounded , the hermite series converges faster than algebraically @xcite .",
    "_ then is the method unstable ? _",
    "yes , there are two serious drawbacks to using theorem [ thmbumps ] .    \\1 .",
    "numerical differentiation is inherently unstable .",
    "fortunately we are estimating the derivatives of gaussians , which are as smooth and bounded as we could hope , and so we have good control with an explicit error formula .",
    "it is true , though , that dividing by @xmath31 for small @xmath32 and large @xmath33 will eventually lead to huge coefficients @xmath23 and round - off error .",
    "there are quite a few general techniques available in the literature for combatting round - off error in numerical differentiation .",
    "we review the well - known @xmath33-point difference formulas for derivatives in section [ secimpconv ] .",
    "the surprising approximation is only possible because it is weaker than the typical convergence of a series in the mean .",
    "unfortunately@xmath34 theorem [ thmbumps ] requires recalculating all the @xmath23 each time @xmath14 is increased .",
    "further , the @xmath23 are not unique .",
    "the least squares best choice of @xmath23 are calculated in section [ secleastsqrs ] , but this approach gives an ill - conditioned matrix .",
    "a different formula for the @xmath23 is given in theorem [ algbump ] which is more computationally efficient .",
    "despite these drawbacks the result is worthy of note because of the new and unexpected opportunities which arise using an approximation method with such simple functions . in this vein ,",
    "section [ seclowftrig ] details an interesting corollary of theorem [ thmbumps ] : apply the fourier transform to see that low - frequency trigonometric series are dense in @xmath13 with gaussian weight function .",
    "in this section theorem [ algbump ] gives an explicit formula for the coefficients @xmath23 of theorem [ thmbumps ] .",
    "let s review the details of the hermite - inspired expansion@xmath35 claimed in the proof .",
    "the formula for these coefficients is@xmath36 be warned this is not precisely the standard hermite expansion , but a simple adaptation to our particular requirements .",
    "let s check this formula for the @xmath37 using the techniques of orthogonal functions .",
    "remember the following properties of the hermite polynomials @xmath38 ( @xcite , e.g. ) .",
    "define @xmath39 .",
    "the set of hermite functions@xmath40 is a well - known basis of @xmath1 and is orthonormal since@xmath41 this means given any @xmath42 it is possible to write@xmath43 @xmath44equality in the @xmath2 sense@xmath45 where@xmath46 the necessity of this formula for @xmath47 can easily be checked by multiplying both sides of @xmath48 by @xmath49 , integrating and applying @xmath50 .",
    "however , we want@xmath51 so apply this process to @xmath52 .",
    "but @xmath53 may not be @xmath2 integrable . if it is not , we must truncate it : @xmath54   } \\left (   x\\right )   $ ] is @xmath2 for any @xmath55 and @xmath56   } \\underset{\\epsilon/3}{\\approx}f$ ] for a sufficiently large choice of @xmath57 .",
    "now we get new @xmath47 as follows@xmath58   } \\left (   x\\right ) &   = \\overset{\\infty}{\\underset{n=0}{% % tcimacro{\\tsum } % % beginexpansion { \\textstyle\\sum } % endexpansion } } c_{n}\\tfrac{1}{\\sqrt{n!2^{n}\\sqrt{\\pi}}}h_{n}\\left (   x\\right )   e^{-x^{2}% /2}\\text{\\qquad so}\\\\ f\\left (   x\\right )   \\chi_{\\left [   -m , m\\right ]   } \\left (   x\\right )    & = \\overset{\\infty}{\\underset{n=0}{% % tcimacro{\\tsum } % % beginexpansion { \\textstyle\\sum } % endexpansion } } c_{n}\\tfrac{\\left (   -1\\right )   ^{n}}{\\sqrt{n!2^{n}\\sqrt{\\pi}}}\\left ( -1\\right )   ^{n}h_{n}\\left (   x\\right )   e^{-x^{2}}=\\overset{\\infty}% { \\underset{n=0}{% % tcimacro{\\tsum } % % beginexpansion { \\textstyle\\sum } % endexpansion } } b_{n}\\frac{d^{n}}{dx^{n}}e^{-x^{2}}%\\end{aligned}\\ ] ] where@xmath59   } \\left (   x\\right ) h_{n}\\left (   x\\right )   e^{-x^{2}/2}\\left (   x\\right )   dx\\\\ & = \\tfrac{1}{\\sqrt{n!2^{n}\\sqrt{\\pi}}}\\underset{\\mathbb{r}}{% % tcimacro{\\tint } % % beginexpansion { \\textstyle\\int } % endexpansion } f\\left (   x\\right )   \\chi_{\\left [   -m , m\\right ]   } \\left (   x\\right )   h_{n}\\left ( x\\right )   dx\\end{aligned}\\ ] ] so we must have@xmath60   } \\left (   x\\right )   e^{x^{2}% } \\frac{d^{n}}{dx^{n}}e^{-x^{2}}dx\\text{.}\\label{line b_n}%\\ ] ]    now the second step of the proof of theorem [ thmbumps ] claims that the gaussian s derivatives may be approximated by divided backward differences@xmath61 in the @xmath1 norm .",
    "we ll use the `` big oh '' notation : for a real function @xmath62 the statement `` @xmath63 as @xmath64 '' means there exist @xmath65 and @xmath66 such that @xmath67 for @xmath68 .",
    "[ proplpdivdiff]for each @xmath69 and @xmath70@xmath71    in appendix [ secimpconv ] the pointwise formula is derived:@xmath72 where all of the @xmath73 are between @xmath74 and @xmath75 .",
    "therefore the proposition holds with @xmath76 since @xmath77 is integrable for each @xmath78 .",
    "this is not perfectly obvious because we do nt have explicit formulae for the @xmath73 .",
    "but the tails of @xmath79 vanish exponentially , the continuity of @xmath79 guarantees a finite maximum on the bounded interval between the tails , and @xmath80 .    continuing the derivation of the coefficients @xmath23 we now have for sufficiently small @xmath81@xmath82   e^{-\\left ( x - kt\\right )   ^{2}}\\label{line f approxi}%\\ ] ] in the last equality we just switched the order of summation ( see @xcite , section 2.4 for an overview of such tricks ) . combining @xmath83 and @xmath84 we have    [ algbump]for any @xmath7 and any @xmath8 there exist @xmath10 and @xmath85 such that for any @xmath81 with @xmath86@xmath87 for some choice of @xmath11 dependent on @xmath14 and @xmath32 .",
    "if @xmath53 is integrable , then one choice of coefficients is@xmath88 if @xmath53 is not integrable , replace @xmath25 in the above formula with @xmath56   } $ ] where @xmath57 is chosen large enough that @xmath89   } \\right\\| _ { 2}<\\epsilon$ ] .    [ remunifg]the approximation in theorem [ algbump ] also holds on @xmath90   $ ] with the uniform norm since the hermite expansion is uniformly convergent on @xmath91   $ ] ( see @xcite , @xcite ) and the finite difference formula s error term from appendix [ secimpconv ] converges to 0 uniformly as @xmath92 .",
    "the stone - weierstrass theorem does not apply in this situation because linear combinations of gaussians with a single variance do not form an algebra .",
    "[ remdense]as a consequence of theorem [ algbump ] for any @xmath8 the closed linear span of @xmath93 is @xmath1 .",
    "it is even sufficient to replace @xmath94 with @xmath95 .",
    "let s explore some concrete examples in applying theorem [ algbump ] .",
    "choose an interesting function with discontinuities and some support negative:@xmath96 } \\left (   x\\right )   : = \\left\\ { \\begin{array } [ c]{l}% \\left (   x-1\\right )   ^{2}\\\\ 0 \\end{array } \\right .",
    "\\begin{array } [ c]{l}% \\text{for } x\\in\\left [   -1,2\\right ] \\\\",
    "\\text{otherwise}% \\end{array}\\ ] ] and observe graphically :    @xmath97   \\left (   x\\right )   $ } } % % { } { 200.png}{\\special { language \" scientific word \" ;   type \" graphic \" ; % maintain - aspect - ratio true ;   display \" pict \" ;   valid_file \" f \" ; % width 1.7253 in ;   height 1.1917 in ;   depth 0 in ;   original - width 8.8643 in ; % original - height 6.1039 in ;   cropleft \" 0 \" ;   croptop \" 1 \" ;   cropright \" 1 \" ; % cropbottom \" 0 \" ;   filename ' 200.png';file-properties \" xnpeu\";}}}% % beginexpansion { \\parbox[b]{1.7253in}{\\begin{center } \\includegraphics [ natheight=6.103900 in , natwidth=8.864300 in , height=1.1917 in , width=1.7253 in ] % { i200.png}% \\\\ $ f\\left (   x\\right )   : = \\left (   x-1\\right )   ^2\\chi_{\\left [   -1,2\\right ] }   \\left ( x\\right )   $ \\end{center}}}% % endexpansion% % tcimacro{\\frame{itbpfu}{1.6094in}{1.1122in}{0in}{\\qcb{hermite series $ n=20$}% % } { } { 210.png}{\\special { language \" scientific word \" ;   type \" graphic \" ; % maintain - aspect - ratio true ;   display \" usedef \" ;   valid_file \" f \" ; % width 1.6094 in ;   height 1.1122 in ;   depth 0 in ;   original - width 8.5833 in ; % original - height 5.9171 in ;   cropleft \" 0 \" ;   croptop \" 1 \" ;   cropright \" 1 \" ; % cropbottom \" 0 \" ;   filename ' 210.png';file-properties \" xnpeu\";}}}% % beginexpansion { \\parbox[b]{1.6094in}{\\begin{center } \\includegraphics [ natheight=5.917100 in , natwidth=8.583300 in , height=1.1122 in , width=1.6094 in ] % { i210.png}% \\\\ hermite series $ n=20 $ \\end{center}}}%",
    "% endexpansion% % tcimacro{\\frame{itbpfu}{1.6025in}{1.1087in}{0in}{\\qcb{hermite $ n=40$}}% % { } { 220.png}{\\special { language \" scientific word \" ;   type \" graphic \" ; % maintain - aspect - ratio true ;   display \" usedef \" ;   valid_file \" f \" ; % width 1.6025 in ;   height 1.1087 in ;   depth 0 in ;   original - width 8.4371 in ; % original - height 5.8228 in ;   cropleft \" 0 \" ;   croptop \" 1 \" ;   cropright \" 1 \" ; % cropbottom \" 0 \" ;   filename ' 220.png';file-properties \" xnpeu\";}}}% % beginexpansion { \\parbox[b]{1.6025in}{\\begin{center } \\includegraphics [ natheight=5.822800 in , natwidth=8.437100 in , height=1.1087 in , width=1.6025 in ] % { i220.png}% \\\\ hermite",
    "$ n=40 $ \\end{center}}}% % endexpansion $ ] @xmath98{c}% % theorem \\ref{algbump}\\\\ %",
    "$ n=20 $ , $ t=.05$% % \\end{tabular } % } } { } { 230.png}{\\special { language \" scientific word \" ;   type \" graphic \" ; % maintain - aspect - ratio true ;   display \" usedef \" ;   valid_file \" f \" ; % width 1.6155 in ;   height 1.1147 in ;   depth 0 in ;   original - width 9.052 in ; % original - height 6.2292 in ;   cropleft \" 0 \" ;   croptop \" 1 \" ;   cropright \" 1 \" ; % cropbottom \" 0 \" ;   filename ' 230.png';file-properties \" xnpeu\";}}}% % beginexpansion { \\parbox[b]{1.6155in}{\\begin{center } \\includegraphics [ natheight=6.229200 in , natwidth=9.052000 in , height=1.1147 in , width=1.6155 in ] % { i230.png}% \\\\% \\begin{tabular } [ c]{c}% theorem \\ref{algbump}\\\\ $ n=20 $ , $ t=.05$% \\end{tabular } \\end{center}}}% % endexpansion% % tcimacro{\\frame{itbpfu}{1.6172in}{1.1156in}{0in}{\\qcb{{}% % \\begin{tabular } % [ c]{c}% % theorem \\ref{algbump}\\\\ % $ n=20 $ , $ t=.01$% % \\end{tabular } % } } { } { 240.png}{\\special { language \" scientific word \" ;   type \" graphic \" ; % maintain - aspect - ratio true ;   display \" usedef \" ;   valid_file \" f \" ; % width 1.6172 in ;   height 1.1156 in ;   depth 0 in ;   original - width 8.6983 in ; % original - height 5.9897 in ;   cropleft \" 0 \" ;   croptop \" 1 \" ;   cropright \" 1 \" ; % cropbottom \" 0 \" ;   filename ' 240.png';file-properties \" xnpeu\";}}}% % beginexpansion { \\parbox[b]{1.6172in}{\\begin{center } \\includegraphics [ natheight=5.989700 in , natwidth=8.698300 in , height=1.1156 in , width=1.6172 in ] % { i240.png}% \\\\ { } % \\begin{tabular } [ c]{c}% theorem \\ref{algbump}\\\\ $ n=20 $ , $ t=.01$% \\end{tabular } \\end{center}}}% % endexpansion% % tcimacro{\\frame{itbpfu}{1.6163in}{1.1147in}{0in}{\\qcb{{}% % \\begin{tabular } % [ c]{c}% % theorem \\ref{algbump}\\\\ % $ n=40 $ , $ t=.01$% % \\end{tabular } % } } { } { 250.png}{\\special { language \" scientific word \" ;   type \" graphic \" ; % maintain - aspect - ratio true ;   display \" usedef \" ;   valid_file \" f \" ; % width 1.6163 in ;   height 1.1147 in ;   depth 0 in ;   original - width 8.8955 in ; % original - height 6.1246 in ;   cropleft \" 0 \" ;   croptop \" 1 \" ;   cropright \" 1 \" ; % cropbottom \" 0 \" ;   filename ' 250.png';file-properties \" xnpeu\";}}}% % beginexpansion { \\parbox[b]{1.6163in}{\\begin{center } \\includegraphics [ natheight=6.124600 in , natwidth=8.895500 in , height=1.1147 in , width=1.6163 in ] % { i250.png}% \\\\ { } % \\begin{tabular } [ c]{c}% theorem \\ref{algbump}\\\\ $ n=40 $ , $ t=.01$% \\end{tabular } \\end{center}}}% % endexpansion\\ ] ]    the hermite approximation is slowed by discontinuities , but does converge .",
    "the next choice of @xmath25 is continuous but not smooth .",
    "@xmath99   \\left (   x\\right )   $ } } % % { } { 300.png}{\\special { language \" scientific word \" ;   type \" graphic \" ; % maintain - aspect - ratio true ;   display \" usedef \" ;   valid_file \" f \" ; % width 1.6414 in ;   height 1.1277 in ;   depth 0 in ;   original - width 8.6144 in ; % original - height 5.9067 in ;   cropleft \" 0 \" ;   croptop \" 1 \" ;   cropright \" 1 \" ; % cropbottom \" 0 \" ;   filename ' 300.png';file-properties \" xnpeu \" ; } } } % % beginexpansion { \\parbox[b]{1.6414in}{\\begin{center } \\includegraphics [ natheight=5.906700 in , natwidth=8.614400 in , height=1.1277 in , width=1.6414 in ] % { i300.png}% \\\\ $ f\\left (   x\\right )   : = \\left (   \\sin x\\right )   \\chi_{\\left [   -\\pi,\\pi\\right ] } \\left (   x\\right )   $ \\end{center } } } % endexpansion% % tcimacro{\\frame{itbpfu}{1.6622in}{1.1312in}{0in}{\\qcb{% % \\begin{tabular } % [ c]{c}% % hermite expansion\\\\ % $ n=10$% % \\end{tabular } % } } { } { 311.png}{\\special { language \" scientific word \" ;   type \" graphic \" ; % maintain - aspect - ratio true ;   display \" usedef \" ;   valid_file \" f \" ; % width 1.6622 in ;   height 1.1312 in ;   depth 0 in ;   original - width 9.4585 in ; % original - height 6.4169 in ;   cropleft \" 0 \" ;   croptop \" 1 \" ;   cropright \" 1 \" ; % cropbottom \" 0 \" ;   filename ' 311.png';file-properties \" xnpeu \" ; } } } % % beginexpansion { \\parbox[b]{1.6622in}{\\begin{center } \\includegraphics [ natheight=6.416900 in , natwidth=9.458500 in , height=1.1312 in , width=1.6622 in ] % { i311.png}% \\\\% \\begin{tabular } [ c]{c}% hermite expansion\\\\ $ n=10$% \\end{tabular } \\end{center } } } % endexpansion% % tcimacro{\\frame{itbpfu}{1.6302in}{1.132in}{0in}{\\qcb{% % \\begin{tabular } % [ c]{c}% % hermite expansion\\\\ % $ n=20$% % \\end{tabular } % } } { } { 320.png}{\\special { language \" scientific word \" ;   type \" graphic \" ; % maintain - aspect - ratio true ;   display \" usedef \" ;   valid_file \" f \" ; % width 1.6302 in ;   height 1.132 in ;   depth 0 in ;   original - width 10.0733 in ; % original - height 6.979 in ;   cropleft \" 0 \" ;   croptop \" 1 \" ;   cropright \" 1 \" ; % cropbottom \" 0 \" ;   filename ' 320.png';file-properties \" xnpeu \" ; } } } % % beginexpansion { \\parbox[b]{1.6302in}{\\begin{center } \\includegraphics [ natheight=6.979000 in , natwidth=10.073300 in , height=1.132 in , width=1.6302 in ] % { i320.png}% \\\\% \\begin{tabular } [ c]{c}% hermite expansion\\\\ $ n=20$% \\end{tabular } \\end{center } } } % endexpansion\\]]@xmath100{l}% % theorem \\ref{algbump}\\\\ % $ n=10 $ , $ t=.01$% % \\end{tabular } % } } { } { 330.png}{\\special { language \" scientific word \" ;   type \" graphic \" ; % maintain - aspect - ratio true ;   display \" usedef \" ;   valid_file \" f \" ; % width 1.6431 in ;   height 1.126 in ;   depth 0 in ;   original - width 9.8018 in ; % original - height 6.698 in ;   cropleft \" 0 \" ;   croptop \" 1 \" ;   cropright \" 1 \" ; % cropbottom \" 0 \" ;   filename ' 330.png';file-properties \" xnpeu \" ; } } } % % beginexpansion { \\parbox[b]{1.6431in}{\\begin{center } \\includegraphics [ natheight=6.698000 in , natwidth=9.801800 in , height=1.126 in , width=1.6431 in ] % { i330.png}% \\\\% \\begin{tabular } [ c]{l}% theorem \\ref{algbump}\\\\ $ n=10 $ , $ t=.01$% \\end{tabular } \\end{center } } } % endexpansion% % tcimacro{\\frame{itbpfu}{1.6579in}{1.1346in}{0in}{\\qcb{% % \\begin{tabular } % [ c]{l}% % theorem \\ref{algbump}\\\\ % $ n=20 $ , $ t=.05$% % \\end{tabular } % } } { } { 340.png}{\\special { language \" scientific word \" ;   type \" graphic \" ; % maintain - aspect - ratio true ;   display \" pict \" ;   valid_file \" f \" ; % width 1.6579 in ;   height 1.1346 in ;   depth 0 in ;   original - width 10.1149 in ; % original - height 6.9064 in ;   cropleft \" 0 \" ;   croptop \" 1 \" ;   cropright \" 1 \" ; % cropbottom \" 0 \" ;   filename ' 340.png';file-properties \" xnpeu \" ; } } } % % beginexpansion { \\parbox[b]{1.6579in}{\\begin{center } \\includegraphics [ natheight=6.906400 in , natwidth=10.114900 in , height=1.1346 in , width=1.6579 in ] % { i340.png}% \\\\% \\begin{tabular } [ c]{l}% theorem \\ref{algbump}\\\\ $ n=20 $ , $ t=.05$% \\end{tabular } \\end{center } } } % endexpansion% % tcimacro{\\frame{itbpfu}{1.6475in}{1.1277in}{0in}{\\qcb{% % \\begin{tabular } %",
    "[ c]{l}% % theorem \\ref{algbump}\\\\ % $ n=20 $ , $ t=.01$% % \\end{tabular } % } } { } { 350.png}{\\special { language \" scientific word \" ;   type \" graphic \" ; % maintain - aspect - ratio true ;   display \" usedef \" ;   valid_file \" f \" ; % width 1.6475 in ;   height 1.1277 in ;   depth 0 in ;   original - width 10.1149 in ; % original - height 6.9064 in ;   cropleft \" 0 \" ;   croptop \" 1 \" ;   cropright \" 1 \" ; % cropbottom \" 0 \" ;   filename ' 350.png';file-properties \" xnpeu \" ; } } } % % beginexpansion { \\parbox[b]{1.6475in}{\\begin{center } \\includegraphics [ natheight=6.906400 in , natwidth=10.114900 in ,",
    "height=1.1277 in , width=1.6475 in ] % { i350.png}% \\\\% \\begin{tabular } [ c]{l}% theorem \\ref{algbump}\\\\ $ n=20 $ , $ t=.01$% \\end{tabular } \\end{center } } } % endexpansion\\ ] ]    in section [ secimpconv ] we review a standard technique accelerating this convergence in @xmath32 . in our experiments , though , we ve found the hermite expansion is generally the bottleneck , not the round - off error of the derivative approximations for @xmath0.@xmath101{c}% % hermite expansion\\\\ % $ n=60$% % \\end{tabular } % } } { } { 400.png}{\\special { language \" scientific word \" ;   type \" graphic \" ; % maintain - aspect - ratio true ;   display \" usedef \" ;   valid_file \" f \" ; % width 1.4961 in ;   height 1.0222 in ;   depth 0 in ;   original - width 9.9168 in ; % original - height 6.7706 in ;   cropleft \" 0 \" ;   croptop \" 1 \" ;   cropright \" 1 \" ; % cropbottom \" 0 \" ;   filename ' 400.png';file-properties \" xnpeu \" ; } } } % % beginexpansion { \\parbox[b]{1.4961in}{\\begin{center } \\includegraphics [ natheight=6.770600 in , natwidth=9.916800 in , height=1.0222 in , width=1.4961 in ] % { i400.png}% \\\\% \\begin{tabular } [ c]{c}% hermite expansion\\\\ $ n=60$% \\end{tabular } \\end{center } } } % endexpansion% % tcimacro{\\frame{itbpfu}{1.4875in}{1.0188in}{0in}{\\qcb{% % \\begin{tabular } % [ c]{c}% % hermite expansion\\\\ % $ n=100$% % \\end{tabular } % } } { } { 410.png}{\\special { language \" scientific word \" ;   type \" graphic \" ; % maintain - aspect - ratio true ;   display \" usedef \" ;   valid_file \" f \" ; % width 1.4875 in ;   height 1.0188 in ;   depth 0 in ;   original - width 10.031 in ; % original - height 6.8545 in ;   cropleft \" 0 \" ;   croptop \" 1 \" ;   cropright \" 1 \" ; % cropbottom \" 0 \" ;   filename ' 410.png';file-properties \" xnpeu \" ; } } } % % beginexpansion { \\parbox[b]{1.4875in}{\\begin{center } \\includegraphics [ natheight=6.854500 in , natwidth=10.031000 in , height=1.0188 in , width=1.4875 in ] % { i410.png}% \\\\% \\begin{tabular } [ c]{c}% hermite expansion\\\\ $ n=100$% \\end{tabular } \\end{center } } } % endexpansion% % tcimacro{\\frame{itbpfu}{1.5333in}{1.0144in}{0in}{\\qcb{% % \\begin{tabular } % [ c]{c}% % hermite expansion\\\\ % $ n=120$% % \\end{tabular } % } } { } { 420.png}{\\special { language \" scientific word \" ;   type \" graphic \" ; % maintain - aspect - ratio true ;   display \" usedef \" ;   valid_file \" f \" ; % width 1.5333 in ;   height 1.0144 in ;   depth 0 in ;   original - width 10.1356 in ; % original - height 6.6876 in ;   cropleft \" 0 \" ;   croptop \" 1 \" ;   cropright \" 1 \" ; % cropbottom \" 0 \" ;   filename ' 420.png';file-properties \" xnpeu \" ; } } } % % beginexpansion { \\parbox[b]{1.5333in}{\\begin{center } \\includegraphics [ natheight=6.687600 in , natwidth=10.135600 in , height=1.0144 in , width=1.5333 in ] % { i420.png}% \\\\% \\begin{tabular } [ c]{c}% hermite expansion\\\\ $ n=120$% \\end{tabular } \\end{center } } } % endexpansion\\ ] ] we need about 120 terms before visual accuracy is achieved for this simple function .",
    "there is a host of methods in the literature for improving convergence of the hermite expansion , but generally we have better success with functions that are smooth and bounded @xcite .",
    "our last examples in this section illustrate how convergence is faster for functions which are smooth and `` clamped off '' , meaning multiplied by @xmath102   } $ ] whether or not they are positive or symmetric .",
    "theorem [ thmbumps ] promises any @xmath2 function can be approximated @xmath103 .",
    "theorem [ algbump ] gives a formula for the coefficients @xmath23 but this formula is not unique , and in fact is not `` best '' according to the classical continuous least squares technique .    in least squares we minimize the error function@xmath104 by setting @xmath105 for @xmath106 and solving for the @xmath23 . these @xmath107 linear equations are called the * normal equations*. the matrix form of this system is @xmath108 where @xmath57 is the matrix@xmath109   _ { j , k=0}^{n}%\\ ] ] and@xmath110   _ { j=0}^{n}\\text{\\qquad and\\qquad } \\overrightarrow{b}=\\left [   \\underset{\\mathbb{r}}{\\int}f\\left (   x\\right ) e^{-\\left (   x - jt\\right )   ^{2}}dx\\right ]   _ { j=0}^{n}%\\ ] ] @xmath57 is symmetric and invertible , so we can always solve for the @xmath23 . but",
    "these least squares matrices are notorious for being ill - conditioned when using non - orthogonal approximating functions .",
    "the hilbert matrix is the archetypical example .",
    "the current application is no exception since the matrix entries are very similar for most choices of @xmath14 and @xmath32,@xmath111so round - off error is extreme .",
    "choosing @xmath112 instead of @xmath113 in the graphed example above requires almost 300 significant digits .",
    "for @xmath114 define the norm@xmath115 write @xmath116 @xmath117 to mean @xmath118 .",
    "[ thmlowfreq]for every @xmath114 and @xmath8 there exists @xmath14 @xmath119 and @xmath85 such that for any @xmath81 with @xmath86 @xmath120 for some choice of @xmath121 dependent on @xmath14 and @xmath32 .",
    "we use the fourier transform with convention@xmath122   \\left (   s\\right )   = \\frac{1}{\\sqrt{2\\pi}}% \\underset{\\mathbb{r}}{% % tcimacro{\\tint } % % beginexpansion { \\textstyle\\int } % endexpansion } f\\left (   x\\right )   e^{-isx}dx\\text{.}%\\ ] ] @xmath123 is a linear isometry of @xmath124 with@xmath125    & = \\frac{1}{\\sqrt{2\\alpha}% } e^{-\\frac{s^{2}}{4\\alpha}}\\text{,}\\\\ \\mathcal{f}\\left [   f\\left (   x+r\\right )   \\right ]    & = e^{-irs}\\mathcal{f}% \\left [   f\\left (   x\\right )   \\right ]   \\text{\\qquad and}\\\\ \\mathcal{f}\\left [   g\\ast h\\right ]    & = \\sqrt{2\\pi}\\mathcal{f}\\left [   g\\right ] \\mathcal{f}\\left [   h\\right ]   \\text{.}%\\end{aligned}\\ ] ] where @xmath126 is convolution .",
    "let @xmath127 and we now show @xmath128   \\left (   x\\right )   \\in l^{2}$ ] . notice @xmath129",
    "\\in l^{2}$ ] and@xmath130 \\right\\|   _ { 1}=c\\left\\|   g^{2}\\right\\|   _ { 1}=c\\left\\|   g\\right\\|   _ { 2}% ^{2}=c\\left\\|   f\\right\\|   _ { 2}^{2}<\\infty\\end{aligned}\\ ] ] for some @xmath131 . here",
    "$ ] is the solution to the diffusion equation for time @xmath32 and initial condition @xmath133 .",
    "( the notation @xmath134 refers to the weierstrass transform . )",
    "the reason for the third equality in the previous calculation is that @xmath135 maintains the @xmath136 integral of any positive initial condition @xmath133 for all time @xmath9 @xcite .",
    "now approximate the real and imaginary parts of @xmath137 with theorem [ algbump ] .",
    "then we get@xmath138   \\left ( x\\right )   \\underset{\\epsilon}{\\approx}\\ \\overset{n}{\\underset{n=0}{% % tcimacro{\\tsum } % % beginexpansion { \\textstyle\\sum } % endexpansion } } a_{n}e^{-\\left (   x - nt\\right )   ^{2}}\\text{\\qquad}a_{n}\\in\\mathbb{c}%\\ ] ] and applying @xmath123 gives@xmath139 hence@xmath140 using the fact that @xmath141 .",
    "this result is surprising , even in the context of this paper , because for instance , series of the form @xmath142 for all @xmath32 and @xmath23 are not dense in @xmath2 and in fact only inhabit a 4-dimensional subspace of the infinite dimensional hilbert space @xcite .    on any finite interval @xmath143   $ ] for any @xmath144",
    "the finite linear combinations of sine and cosine functions with frequency lower than @xmath145 are dense in @xmath146   , \\mathbb{r}\\right )   $ ] .    on @xmath143",
    "$ ] the gaussian is bounded and so the norms with or without weight function are equivalent",
    ". apply theorem [ thmlowfreq ] to @xmath147   , \\mathbb{r}\\right )   $ ] and choose @xmath32 such that @xmath148 to get@xmath149 where @xmath150   \\left (   x\\right ) \\right ]   e^{x^{2}}\\frac{d^{k}}{dx^{k}}\\left (   e^{-x^{2}}\\right )   dx\\text{.}%\\ ] ]    applying remark [ remdense ] to this result shows even discrete sets of positive frequencies that approach 0 make the span of the corresponding sine and cosine functions equal to@xmath146   , \\mathbb{r}% \\right )   $ ] .    finally , low - frequency cosines span the even functions :    on any finite interval @xmath151   $ ] for any @xmath144 the finite linear combinations of cosine functions with frequency lower than @xmath145 are dense in @xmath152   , \\mathbb{r}\\right )   $ ] .",
    "let @xmath153   , \\mathbb{r}\\right )   $ ] and extend it as an even function on @xmath154   $ ] .",
    "now use the previous corollary to write @xmath155 we d like to conclude right now that the @xmath156 or @xmath157 , but that is not true .",
    "however , every function @xmath117 on @xmath154   $ ] may be written uniquely as a sum of even and odd functions@xmath158 and so@xmath159 therefore@xmath160 _ { e}=\\overset{n}{\\underset{n=0}{% % tcimacro{\\tsum } % % beginexpansion { \\textstyle\\sum } % endexpansion } } a_{n}\\cos\\left (   ntx\\right )   \\text{.}%\\ ] ]    beware this last result ; it s not as strong as fourier approximation .",
    "the coefficients for the sine functions calculated above may be large ; the proposition merely promises the linear combination of the sine terms is small .",
    "using least squares , however , will have vanishing sine coefficients .",
    "the mathematical inspiration for theorem [ thmbumps ] comes from geometrical investigations in infinite dimensional control theory .",
    "we noticed that function translation and vector translation in @xmath161 do not commute .",
    "specifically , `` function translation '' is a flow on the infinite dimensional vector space @xmath1 given by the map @xmath162 where @xmath163 .",
    "`` vector translation '' in the direction of @xmath42 is the flow @xmath164 where @xmath165 .",
    "taking for example @xmath166 and composing @xmath167 and @xmath168 we see @xmath169 since for @xmath170@xmath171 notice however the key fact@xmath172 in finite dimensions the commutator quotient above gives the lie bracket @xmath173   $ ] of the vector fields @xmath174 and @xmath175 which generate the flows @xmath167 and @xmath168 , respectively . a fundamental result in",
    "finite - dimensional control theory states that the reachable set via @xmath174 and @xmath175 is given by the integral surface to the distribution made up of iterated lie brackets starting from @xmath174 and @xmath175 ( chow s theorem , which is an interpretation of frobenius foliation theorem , see @xcite , e.g. ) .",
    "the idea we are exploiting is that iterated lie brackets for our flows @xmath167 and @xmath168 will give successive derivatives of the gaussian , whose span is dense in @xmath13 . consequently , the reachable set via @xmath167 and @xmath168 from @xmath170 should be all of @xmath1 .",
    "that is to say , sums of translates and multiples of one gaussian ( with fixed variance ) can approximate any integrable function .",
    "unfortunately this program does nt automatically work on the infinite dimensional vector space @xmath1 since the function translation flow is not generated by a simple vector field on @xmath13 .",
    "so instead of studying vector fields , we consider flows as primary .",
    "the fundamental results can be rewritten and still hold in the general context of a metric space @xcite .",
    "then other functions besides @xmath76 can be checked to be derivative generating and other flows may be used in place of translation .",
    "e.g. , fourier approximation is achieved using dilation @xmath176 where @xmath177 and @xmath178 .",
    "this gives us a general tool for determining the density of various families of functions .",
    "another opportunity for generalizing the results of this paper presents itself with the observation that hermite expansions are valid for functions defined on @xmath179 or @xmath180 and in spaces of tempered distributions ; and divided differences works in all of these spaces as well .",
    "note also that while the results of section [ secappalgo ] work for uniform approximations of continuous functions on finite intervals ( remark [ remunifg ] ) , this is an open question for low - frequency trigonometric approximations .",
    "the results of this paper can be ported to the language of control theory where we can then conclude the system@xmath181 is bang - bang controllable with controls of the form @xmath182 .",
    "theorem [ algbump ] drives the initial condition @xmath170 to any state in @xmath2 under the system @xmath183 , but may be nowhere near optimal for approximating a function such as @xmath184 , since it uses only gaussians @xmath185 with choices of @xmath186 .    finally , interpreting theorem [ thmbumps ] in terms of signal analysis , we see a gaussian filter is a universal synthesizer with arbitrarily short load time",
    ". let @xmath187 .",
    "a gaussian filter is a linear time - invariant system represented by the operator@xmath188 notice if you feed @xmath134 a dirac delta distribution @xmath189 ( an ideal impulse at time @xmath190 ) you get @xmath191 .",
    "then theorem [ thmbumps ] gives    for any @xmath7 and any @xmath8 and any @xmath192 there exists @xmath9 and @xmath10 with @xmath193 such that@xmath194 for some choice of @xmath11 .",
    "feed a gaussian filter a linear combination of impulses and we can synthesize any signal and arbitrarily small load time @xmath195 .",
    "the design of physical approximations to an analog gaussian filter are detailed in @xcite , @xcite .",
    "the results in this paper may be much improved with voluminous techniques available from numerical analysis .",
    "e.g. , @xcite gives an algorithm which speeds the calculation of sums of gaussians , and @xcite explores hermite expansion acceleration useful in step 1 of the proof of theorem [ thmbumps ] .",
    "this section is devoted to reviewing methods which improve the error in step 2 , approximating derivatives of the gaussian with finite differences .",
    "we also derive the error formula used in proposition [ proplpdivdiff ] .",
    "above we approximated derivatives with the formula@xmath196{c}% $ \\underbrace{\\frac{1}{t^{n}}% % tcimacro{\\tsum _ { k=0}^{n}}% % beginexpansion { \\textstyle\\sum_{k=0}^{n } } % endexpansion \\left (   -1\\right )   ^{n - k}\\binom{n}{k}f\\left (   x+kt\\right )   } $ \\\\ gives round - off error as $ t\\rightarrow0^{+}$% \\end{tabular}% \\begin{tabular } [ c]{c}%",
    "$ \\underset{}{+}$% \\end{tabular}% \\begin{tabular } [ c]{l}% $ \\underbrace{o\\left (   t\\right )   } $ \\\\ truncation error \\end{tabular } \\text{.}\\label{linenthder = o(t)}%\\ ] ] the nrlund - rice integral may be of interest for extremely large @xmath33 as it avoids the calculation of the binomial coefficient by evaluating a complex integral . in this section , though , we devote our attention to deriving @xmath33-point formulas ; these formulas decrease round - off error by increasing the number of evaluations @xmath197this shrinks the truncation error without sending @xmath64 .    in approximating the @xmath78th derivative with an @xmath198 point formula@xmath199",
    "we wish to calculate the coefficients @xmath200 . in the forward difference method , the @xmath201 , but keeping these values general allows us to find the coefficients for the central or backward difference formulas just as easily . the following method for finding the @xmath200",
    "was shown to us by our student jeffrey thornton who rediscovered the formula .",
    "taylor s theorem has@xmath202 for some @xmath203 between @xmath74 and @xmath204 . from this",
    "it follows@xmath205{c}% $ f\\left (   x\\right )   $ \\\\ $ tf^{\\prime}\\left (   x\\right )   $ \\\\ $ \\vdots$\\\\ $ t^{n}f^{\\left (   n\\right )   } \\left (   x\\right )   $ \\\\ $ t^{n+1}$% \\end{tabular } \\right ]   ^{t}\\left [ \\begin{tabular } [ c]{cccc}% $ 1 $ & $ 1 $ & $ \\cdots$ & $ 1$\\\\ $ k_{0}$ & $ k_{1}$ & $ \\cdots$ & $ k_{n}$\\\\ $ \\frac{k_{0}^{2}}{2!}$ & $ \\frac{k_{1}^{2}}{2!}$ & $ \\cdots$ & $ \\frac{k_{n}^{2}% } { 2!}$\\\\ $ \\vdots$ & $ \\vdots$ & $ \\ddots$ & $ \\vdots$\\\\ $ \\frac{k_{0}^{n}}{n!}$ & $ \\frac{k_{1}^{n}}{n!}$ & $ \\cdots$ & $ \\frac{k_{n}^{n}% } { n!}$\\\\ $ \\tfrac{k_{0}^{n+1}f^{\\left (   n+1\\right )   } \\left (   \\xi_{0}\\right )   } { \\left ( n+1\\right )   ! } $ & $ \\frac{k_{1}^{n+1}f^{\\left (   n+1\\right )   } \\left (   \\xi _ { 1}\\right )   } { \\left (   n+1\\right )   ! }",
    "$ & $ \\cdots$ & $ \\frac{k_{n}% ^{n+1}f^{\\left (   n+1\\right )   } \\left (   \\xi_{n}\\right )   } { \\left (   n+1\\right ) ! } $ % \\end{tabular } \\right ]   \\left [ \\begin{tabular } [ c]{c}% $ c_{0}$\\\\ $ c_{1}$\\\\ $ \\vdots$\\\\ $ c_{n}$% \\end{tabular } \\right]\\end{aligned}\\ ] ] now pick @xmath206   $ ] as a solution to@xmath207{cccc}% $ 1 $ & $ 1 $ & $ \\cdots$ & $ 1$\\\\ $ k_{0}$ & $ k_{1}$ & $ \\cdots$ & $ k_{n}$\\\\ $ \\frac{k_{0}^{2}}{2!}$ & $ \\frac{k_{1}^{2}}{2!}$ & $ \\cdots$ & $ \\frac{k_{n}^{2}% } { 2!}$\\\\ $ \\vdots$ & $ \\vdots$ & $ \\ddots$ & $ \\vdots$\\\\ $ \\frac{k_{0}^{n}}{n!}$ & $ \\frac{k_{1}^{n}}{n!}$ & $ \\cdots$ & $ \\frac{k_{n}^{n}% } { n!}$% \\end{tabular } \\right ]   \\left [ \\begin{tabular } [ c]{c}% $ c_{0}$\\\\ $ c_{1}$\\\\ $ \\vdots$\\\\ $ c_{n}$% \\end{tabular } \\right ]   = \\left [ \\begin{tabular } [ c]{c}% $ 0$\\\\ $ \\vdots$\\\\ $ 1$\\\\ $ \\vdots$\\\\ $ 0$% \\end{tabular } \\right ] \\label{linenumdiffcoeffmatrix}%\\ ] ] which is possible since the @xmath208 are different , so the matrix is invertible , as is seen using the vandermonde determinant@xmath209 then we must have@xmath210{c}% $ f\\left (   x\\right )   $ \\\\ $ tf^{\\prime}\\left (   x\\right )   $ \\\\ $ \\vdots$\\\\ $ t^{n}f^{\\left (   n\\right )   } \\left (   x\\right )   $ \\\\ $ t^{n+1}$% \\end{tabular } \\right ]   ^{t}\\left [ \\begin{tabular } [ c]{l}% $ 0$\\\\ $ \\vdots$\\\\ $ 1$\\quad($k$-th position)\\\\ $ \\vdots$\\\\ $ 0$\\\\ $ \\frac{1}{\\left (   n+1\\right )   ! } \\overset{n}{\\underset{i=0}{% % tcimacro{\\tsum } % % beginexpansion { \\textstyle\\sum } % endexpansion } } c_{i}k_{i}^{n+1}f^{\\left (   n+1\\right )   } \\left (   \\xi_{i}\\right )   $ % \\end{tabular } \\right ] \\\\ & = t^{k}f^{\\left (   k\\right )   } \\left (   x\\right )   + \\frac{t^{n+1}}{\\left ( n+1\\right )   ! }",
    "\\overset{n}{\\underset{i=1}{% % tcimacro{\\tsum } % % beginexpansion { \\textstyle\\sum } % endexpansion } } c_{i}k_{i}^{n+1}f^{\\left (   n+1\\right )   } \\left (   \\xi_{i}\\right )   \\text{.}%\\end{aligned}\\ ] ] therefore@xmath211 for @xmath200 which satisfy @xmath212 where@xmath213 this @xmath214 formula shows how truncation error may be decreased by increasing @xmath33 without shrinking @xmath32 , thus combatting round - off error at the expense of increased computation of sums .",
    "thornton also points out that the @xmath208 may be chosen as complex values when @xmath25 is analytic ( as is the case with our gaussians ) .",
    "this gives us another opportunity to mitigate round - off error , since a greater quantity of regularly - spaced nodes @xmath208 can be packed into an epsilon ball around zero in the complex plane than on the real line .",
    "as final note we mention there have been numerous advances to the present day in inverting the vandermonde matrix .",
    "we mention only the earliest application to numerical differentiation @xcite which gives a formula in terms of the stirling numbers .",
    "greg leibon , daniel rockmore & gregory chirikjian , a fast hermite transform with applications to protein structure determination , proceedings of the 2007 international workshop on symbolic - numeric computation , acm , new york , ny , pp .",
    "117 - 124 , 2007 .",
    "j. madrenas , m. verleysen , p. thissen , and j. l. voz , a cmos analog circuit for gaussian functions , ieee transactions on circuits and systems - ii : analog and digital signal processing , vol .",
    "43 , no . 1 , 1996"
  ],
  "abstract_text": [
    "<S> linear combinations of translations of a single gaussian , @xmath0 , are shown to be dense in @xmath1 . two algorithms for determining the coefficients for the approximations </S>",
    "<S> are given , using orthogonal hermite functions and least squares . </S>",
    "<S> taking the fourier transform of this result shows low - frequency trigonometric series are dense in @xmath2 with gaussian weight function .    _ </S>",
    "<S> key words : hermite series , gaussian function , low - frequency trigonometric series _    </S>",
    "<S> ams subject classifications : 41a30 , 42a32 , 42c10    = 1 </S>"
  ]
}