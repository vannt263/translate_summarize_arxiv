{
  "article_text": [
    "electricity can not be stored efficiently in large quantities , therefore it is critical to ensure that the amount generated at a given time is sufficient to meet the load plus the losses while not exceeding this amount significantly .",
    "predictive methods for accurately forecasting the demand of electricity have thus become important tools that guide planning and operation of utility companies .",
    "while electric load forecasting is a well - established , several decades old research area in engineering , new modeling problems keep appearing as technological and legislative transformations affect the power industry . with the advent of smart grids and meters ,",
    "larger and richer sources of data are becoming available , making it possible to build more sophisticated models that enable more accurate billing of electricity and dynamic pricing .",
    "a variety of tools from time series analysis , statistics , and more recently machine learning , have been employed for electricity load forecasting . for an overview on the vast body of available literature on the subject , we refer the reader to the recent book by @xcite .",
    "classical techniques include linear and non - linear regression models estimated by means of variants of least squares fitting , and various types of armax models expressing the forecast as a function of previously observed values of the load and possibly other weather or social variables .",
    "techniques inspired by artificial intelligence research such as expert systems , fuzzy logic , and neural networks have also been applied to load forecasting . in particular , black - box models based on neural networks have been extensively analyzed , see the influential review by @xcite .    in recent years ,",
    "generalized additive models ( gam ) @xcite have established themselves as state of the art tools for electricity load forecasting @xcite , due to the existence of efficient and scalable training algorithms and the interpretability of the model , which allows to clearly visualize the effect of individual variables on the load by means of simple longitudinal plots .",
    "meanwhile , kernel methods have been employed with great success in the last decade . already back in 2001 , a kernel - based support vector regression ( svr ) approach was employed to win a competition on electricity load forecasting @xcite organized by eunite ( european network on intelligent technologies for smart adaptive systems ) .",
    "later on , various types of kernel - based regularization methods and support vector machines have been applied to predict the demand of electricity , see for instance @xcite .",
    "most research articles on electricity load forecasting focus on predicting a single time series representing the electricity load aggregated over a large number of nodes of the electricity network . due to aggregation ,",
    "such time series exhibit high regularity and are therefore significantly easier to forecast than load profiles at lower levels of the network .",
    "nevertheless , making forecasts of the loads at lower levels is becoming increasingly feasible due to the availability of rich smart meter datasets , therefore the problem is attracting considerable interest in the industry .",
    "forecasting electricity demand at low levels of the network ( such as the demand of an individual household ) presents several challenges .",
    "first of all , it involves analyzing a much larger number of time series , calling for scalable techniques that can handle a very large amount of measurements .",
    "in addition , demand profiles at lower levels of the electricity network are much less regular and thus harder to predict . to tackle these challenges ,",
    "recent works have investigated the use of clustering techniques for automatically aggregating multiple load time series , reporting improved predictive performance at aggregated level @xcite .    in this paper , we study the problem of electricity load forecasting at low network level , and we suggest to solve it by means of kernel - based multi - task learning techniques that can discover and take advantage of the relationships between multiple profiles . kernel based multi - task learning has been studied in a variety of papers @xcite while , in recent years , the problem of learning and exploiting relationships between multiple tasks is a topic that is attracting considerable attention in the machine learning literature @xcite .",
    "herein , we develop and compare a variety of kernel - based models for long - term electricity demand forecasting in multiple nodes , with the goal of identifying the best way to capture the complex seasonal effects that characterize such demand patterns .",
    "we design kernels specifically tailored to capture the seasonal effects present in electricity load data . by doing so",
    ", we expose the performance limits of the very popular additive models , showing that they are often outperformed by multiplicative kernel models .",
    "we formulate the problem of forecasting the demand in multiple nodes of the network as a multi - task learning problem , illustrating the usefulness of jointly learning and exploiting similarities between multiple load profiles .",
    "finally , we show how recently developed multi - task learning techniques can be used to gain insights and interpretability on real demand data , while achieving state of the art predictive performance .",
    "our experimental analysis is based on data provided by the irish commission for energy regulation ( cer ) .",
    "electric load forecasting aims at predicting the future load in one or multiple nodes of an electricity network . depending on how far ahead in time the forecast is required ,",
    "the corresponding estimation problem exhibits different characteristics , and influence decisions of significantly different nature .",
    "it is therefore common to classify forecasting problems in three categories : short - range forecasting ( several minutes up to one week ahead ) , medium - range forecasting ( up to 10 years ahead ) , and long - range forecasting ( as far as several decades ahead ) , see @xcite for a more comprehensive discussion .",
    "forecasting models are built starting from datasets containing one or multiple time series , each of them representing the load measurement at a specific location and level in the network , ranging from highly aggregated loads in the transmission network down to the distribution network and to the loads of individual users .",
    "missing measurements and different sampling rates contribute to make these data noisy and challenging to analyze . moreover , defective meters at a low level in the network are hard to detect , and faulty meters can report wrong measurements before being replaced .",
    "being mostly driven by human activity , a variety of temporal patterns can be observed in the load data .",
    "the top panel of fig .",
    "[ fig : patterns ] shows a typical profile for aggregated electricity load over several years ( data source : french rseau de transport delectricit ) , from which a clear yearly seasonal pattern can be observed , with higher demand in winter and lower demand in the summer . a closer look at this data also reveals typical weekly ( fig .",
    "[ fig : patterns ] , middle panel ) and daily ( fig .  [",
    "fig : patterns ] , bottom panel ) profiles .",
    "correctly capturing these seasonal patterns is an crucial aspect of the problem , which can be dealt with by properly extracting and utilizing temporal and calendar features .",
    "the type of day of the week can be also taken into account : the bottom panel of fig .",
    "[ fig : patterns ] shows a specific week where all days have a similar profile but a difference between week days and weekend can be clearly noticed .",
    "forecasting is particularly challenging on public holidays , and different public holidays may exhibit significantly different load profiles .",
    "[ fig : holidays ] illustrates the difficulty of fitting and forecasting the demand in correspondence of public holidays and special events : without including specific information in the model , the prediction error can be particularly high in corrispondence with such events .     for more details about cer data.,scaledwidth=100.0% ]    a variety of additional features can be typically extracted from the data or obtained from other sources and utilized to forecast the electricity demand .",
    "for instance , the electricity consumption is affected by weather conditions ( particularly due to heating and air - conditioning ) , therefore variables such as temperature , humidity and irradiance are often taken into account by forecasting models .",
    "economic indicators such as gross domestic product can be used to model trends in long - range scenarios .",
    "finally , short term forecasting models are typically based on time series techniques , where auto - regressive lagged values of the load itself are incorporated in the model and used to track short - range trends and deviations from stationarity .    in summary , typical forecasts of the electricity demand",
    "may depend on a variety of features that include time and calendar variables , weather and economic conditions , previously observed values of the load , and information about the node of the network where the forecast is required . a general model that takes into account the previously discussed features takes the form @xmath0 where the dependent variables are the following :    * @xmath1 is the time of day expressed in hours , * @xmath2 is the day of the year , * @xmath3 is the type of day , e.g. monday to sunday , weekday / weekend , holiday , * @xmath4 is a real vector containing lagged values of the measured electric load , * @xmath5 is a real vector containing measurements of lagged values of exogenous variables other than the load ( such as temperature ) , * @xmath6 is the node i d in the electricity network , e.g. meter / customer / zone i d , * @xmath7 is a vector of features describing the node type , e.g. customer / zone type .    in section  [ sec : lfbymtl ] , we analyze one of the many possible multi - task learning problems that naturally appear within this framework , namely the problem of simultaneously predicting the load in each node of the network . this amount to disaggregate the overall dataset over the multiple smart meters and treat each node @xmath6 of the network as a different learning task . in the next section",
    ", we briefly recall the standard setup of multi - task regression and review the techniques that will be employed in section  [ sec : lfbymtl ] to solve the problem sketched above .",
    "in the following , we focus on multi - variate ( multi - task ) regression problems where the goal is to learn multiple functions @xmath8 from multiple datasets of pairs @xmath9 . here , @xmath10 is a set of input features , @xmath11 denotes the number of tasks , and @xmath12 the number of examples for the @xmath13-th task . letting @xmath14 denote the vector - valued function with components",
    "@xmath15 , we are going to search @xmath16 by minimizing the following regularization functional @xmath17 where @xmath18 is a regularization parameter , and @xmath19 is a reproducing kernel hilbert space ( rkhs ) of vector - valued functions with ( matrix - valued ) kernel @xmath20 here , @xmath21 is a positive semidefinite kernel called _ input kernel _ , and the square matrix @xmath22 is the _ output kernel _ matrix whose entries @xmath23 express the similarity between the tasks ( output components ) @xmath13 and @xmath6 . in view of the _ representer theorem _ , there exist functions @xmath24 minimizing @xmath25 in the form : @xmath26 we refer to @xcite for more details about rkhs of vector - valued functions and the corresponding representer theorem .",
    "expression shows that inter - task transfer is possible only when off - diagonal elements of the output kernel matrix are different from zero .",
    "indeed , by choosing @xmath28 equal to the identity matrix all the tasks are learned independently by solving a standard kernel regularized least squares problem @xmath29 where @xmath30 is the rkhs of scalar functions with kernel @xmath31 .",
    "this single - task baseline is referred to as _ independent _ kernel ridge regression .      in this subsection",
    ", we review a kernel - based multi - task regression approach called low - rank output kernel learning ( okl ) , recently developed in @xcite . in such approach , the functions @xmath15 and the output kernel @xmath28 are jointly optimized by solving the following problem @xmath32 where @xmath33 is the cone of positive semidefinite matrices with rank less than or equal to @xmath34 . instead of imposing a low - rank constraint or regularizing the trace of the output kernel",
    ", other type of regularizers could be tried , see e.g. @xcite .",
    "the low - rank approach has the advantage of allowing us to tightly control the memory required to store the models .",
    "the representer theorem still applies to the inner minimization problem of . by plugging the expression into ,",
    "one obtains a functional that is convex quadratic with respect to both the coefficients @xmath35 and @xmath28 .",
    "although the resulting problem is not jointly convex , the alternating minimization procedure described in @xcite can be applied to obtain a minimizer .",
    "an important aspect of the method is that , by selecting the rank parameter @xmath34 , is it possible to control the overall number of parameters of the model , as well as the memory requirements and the computation time to obtain a solution .",
    "more specifically , letting @xmath36 , one can show that the solution can be rewritten as @xmath37 where @xmath38 , @xmath39 , @xmath40 , and the coefficients @xmath41 form a low - rank factor of @xmath28 .",
    "it is therefore sufficient to store and optimize @xmath42 parameters , which can be much smaller than @xmath43 .",
    "in this section , we focus on predicting the demand of electricity in multiple nodes of an electricity network , a multi - task learning problem where each task corresponds to one of the measured smart meters in the network .",
    ".number of meters and sparsity for each customer group in the irish cer dataset [ cols=\"<,>,>\",options=\"header \" , ]     to analyze our long - term forecasting approach , we adopt data provided by the the irish commission for energy regulation ( cer ) , containing electric load measurements from 6435 smart meters , half - hourly sampled from july 14 , 2009 to december 31 , 2010 ( 536 days ) . these meters include residential customers and small - to - medium industrial sites .",
    "we consider a mid - term test scenario where the goal is to forecast the load in multiple nodes over a time horizon of 171 days , using one year of measurements to build the model . due to the long forecasting horizon ,",
    "dynamic features are not available and are therefore dropped from the general model in eq .  .",
    "such model does not rely on recent measurements of the load , therefore it is able to make predictions over an arbitrarily long horizon .",
    "the load forecast for the @xmath6-th node is thus simply given by @xmath44 , where @xmath45 are the multiple functions to be learned , taking into account time and calendar features .    from the original cer dataset",
    ", several pre - processing steps were performed .",
    "the day of the year and time of the day were extracted from the five - digit timestamps . in this dataset ,",
    "the time of day is an non - zero integer indexing the number of half - hours , and therefore it should be normally in the set @xmath46 .",
    "two meters containing time of days higher than @xmath47 half - hours were discarded , as it was unclear how to interpret these measurements .",
    "the dataset also contains days with 46 and 50 measurements and time of days up to 50 .",
    "these inconsistencies are caused by the start and the end of daylight saving time ( dst ) and are easily fixable .",
    "when dst starts in ireland , the 1 am to 2 am hour get skipped , and half - hourly time of day indices should be @xmath48 .",
    "when dst starts in ireland , the 1 am to 2 am hour `` happens twice '' , and half - hourly time of day indices should be @xmath49 , instead of @xmath50 as found in the dataset .",
    "we then downsampled each time - series from half - hourly sampling to 3-hour sampling , by averaging available measurements for each time slot of 3 hours ( [ 12 am , 3 am ) , [ 3 am , 6 am ) , etc ) and a total of 8 measurements per day",
    ". our final dataset contains @xmath51 smart meters sampled over @xmath52 time slots .",
    "characteristics of such pre - processed dataset are summarized in tab .",
    "[ tab : groups ] .",
    "one year ( @xmath53 downsampled observations ) was used for training and validation , and the remaining @xmath54 observations were used for testing . in order to perform tuning of the regularization parameter , we extracted a validation set containing a subset of the original non - test data , obtained by randomly choosing @xmath55 time samples , equal for all the meters .",
    "forecasting performance can be evaluated for each time slot @xmath56 and any arbitrary group of meters @xmath57 . for this purpose ,",
    "let @xmath58 denote the subset of @xmath57 for which measurements are available in the @xmath59-th time slot .",
    "we define two different metrics , namely the aggregated mean absolute percentage error ( @xmath60 ) and the normalized mean absolute error ( @xmath61 ) : @xmath62    @xmath63 measures the relative absolute percentage error incurred when forecasting the aggregated demand using the sum of the forecasts . on the other hand , @xmath64 is the sum of the forecasting errors over individual tasks , relative to the naive baseline of predicting @xmath65 for all @xmath66",
    ". since the demand values @xmath67 are always non - negative , the two metrics are undefined only for those groups on meters for which the cumulative demand in the @xmath59-th time slot is identically zero , or no measurements are available for any of the meters .",
    "we compute the average and standard deviation of these two metrics over all the time slots in the test period .",
    "one advantage of the long - term forecasting approach is that it allows to naturally incorporate and handle time series with missing observations , without resorting to inputing techniques or discarding data . in the following ,",
    "we analyze a variety of kernel based models to solve this multi - task regression problem .",
    "first of all we introduce kernels based on the time / calendar features of model  , @xmath68 where @xmath69 is a change of variable that yields @xmath70-periodic kernels over the square @xmath71 ^ 2 $ ] . by observing that the fourier transform of @xmath72 is non - negative",
    ", it can be easily shown that periodized kernels such as @xmath73 and @xmath74 are positive semidefinite , see @xcite . in our experiment , @xmath75 and @xmath76",
    "were respectively set to 4 hours and 120 days . in order to define @xmath77 , we combine these three kernels to define a variety of models :    * additive models @xmath78 * semi - additive models @xmath79 * multiplicative models @xmath80    first of all , we have trained independent kernel ridge regression models ( see sec .",
    "[ sec : krr ] ) for each measured smart meter using all the kernels from to .",
    "we compare these models against a multi - task learning approach that simultaneously performs estimates for all the meters , and also allows us to exploit the available meter grouping information in the dataset .",
    "specifically , we have trained two separate multi - task output kernel learning ( okl ) models ( see sec .",
    "[ sec : okl ] ) : the first is trained over all the residential meters ( the union of meters labeled `` residential '' and `` others '' ) , and the second over industrial ( sme ) meters . the maximum rank constraint for the first model was set to @xmath81 to obtain a compact model that fits into memory , while the okl model for sme meters was trained with full rank @xmath82 .",
    "we refer the reader to @xcite for a discussion on the effect of this parameter .",
    "both okl models utilize the multiplicative input kernel , as it proves to be the most effective at capturing the seasonal effects .",
    "figure  [ fig : predictions ] illustrates the challenges of long - term forecasting at low network level versus forecasting aggregated demands .",
    "we analyze the measured load and the corresponding forecast over a window of 5 weeks within the test period . in the top panel",
    ", one can see the aggregated load and the corresponding forecast obtained as the sum of all disaggregated forecasts obtained using model  .",
    "the kernel - based forecasts are rather accurate overall , only slighly estimating the total load during the christmas week , a particularly problematic period to predict . in the middle panel , the measured load for a single sme meter is compared with the corresponding forecast .",
    "the varying demand profiles of different days of the week are captured rather well by the model .",
    "again , there is a larger error over the christmas week , caused by a sudden drop of the demand to a low baseline value ( probably due to interruption of business activities followed by a slow resumption in the subsequent days ) .",
    "this leads the models to over - estimate the load , though the model learned with a multi - task approach is less affected .",
    "finally , the bottom panel shows the electricity demand of a residential customer , characterized by rapid variations with sharp consumption peaks and irregular patterns , that make the forecast even more difficult .",
    "@llrrrrr@ & & & & + & & mean & std & & mean & std + additive models & @xmath83 & 0.4829 & 0.0834 & & 8.0384 & 7.2644 + & @xmath84 & 0.4897 & 0.0846 & & 8.0435 & 6.9948 +   + semi - additive models & @xmath85 & 0.4546 & 0.0682 & & 7.1413 & 6.6078 + & @xmath86 & 0.4507 & 0.0649 & & 7.2921 & 6.5868 +   + multiplicative models & @xmath87 & 0.4663 & 0.0771 & & 5.5284 & 5.4252 + & @xmath88 & 0.4237 & 0.0528 & & 4.2917 & 4.3055 +   + multi - task okl & @xmath88 & * 0.4226 * & * 0.0487 * & & * 4.0222 * & * 4.0541 * +    @llrrrrr@ & & & & + & & mean & std & & mean & std + additive models & @xmath83 & 0.5114 & 0.0929 & & 13.1083 & 9.9519 + & @xmath84 & 0.5157 & 0.0941 & & 13.0127 & 10.2067 +   + semi - additive models & @xmath85 & 0.5005 & 0.0900 & & 10.7139 & 9.9966 + & @xmath86 & 0.4977 & 0.0846 & & 10.8144 & 9.6131 +   + multiplicative models & @xmath87 & 0.5058 & 0.0844 & & 8.4289 & 7.1833 + & @xmath88 & 0.4776 & 0.0721 & & 5.2692 & 5.6305 +   + multi - task okl & @xmath88 & * 0.4711 * & * 0.0716 * & & * 4.9166 * & * 5.2588",
    "* +    @llrrrrr@ & & & & + & & mean & std & & mean & std + additive models & @xmath83 & 0.4517 & 0.2204 & & 15.0748 & 23.1005 + & @xmath84 & 0.4590 & 0.1769 & & 16.6668 & 17.0665 +   + semi - additive models & @xmath85 & 0.3704 & 0.1238 & & 8.1880 & 10.8081 + & @xmath86 & 0.3646 & 0.1305 & & 8.1422 & 11.7269 +   + multiplicative models & @xmath87 & 0.4006 & 0.1923 & & 12.5359 & 20.4140 + & @xmath88 & * 0.3127 * & 0.1105 & & 5.9289 & 10.3842 +   + multi - task okl & @xmath88 & 0.3194 & * 0.0725 * & & * 5.2940 * & * 5.8227 * +    @llrrrrr@ & & & & + & & mean & std & & mean & std + additive models & @xmath83 & 0.4948 & 0.0779 & & 7.4672 & 6.9361 + & @xmath84 & 0.5001 & 0.0804 & & 7.4141 & 6.4660 +   + semi - additive models & @xmath85 & 0.4659 & 0.0638 & & 6.4749 & 5.9244 + & @xmath86 & 0.4601 & 0.0605 & & 6.6273 & 5.9189 +   + multiplicative models & @xmath87 & 0.4801 & 0.0710 & & 5.4504 & 5.5997 + & @xmath88 & 0.4370 & 0.0517 & & 4.0279 & 4.2522 +   + multi - task okl & @xmath88 & * 0.4361 * & 0.0490 & & * 3.7450 * & * 3.9503",
    "* +    table  [ tab : cerresults_overall ] reports the performance of all methods over the full set of 6433 smart meters , while tables  [ tab : cerresults_res ] , [ tab : cerresults_sme ] and [ tab : cerresults_others ] report disaggregated performance measures over each group from tab .",
    "[ tab : groups ] .",
    "we start by analyzing the performance of the additive models , which are probably the most widely adopted in the literature . by comparing the performance of models   and  , we can observe that adding a constant bias specific to the type of the day of week ( kernel @xmath89 ) does not necessarily improve the accuracy of the model .",
    "the overall @xmath61 and @xmath60 are in fact higher for model  , see tab .  [",
    "tab : cerresults_overall ] .",
    "semi - additive models where the type of day of the week is utilized to switch between different profiles yields a significant improvement in performance .",
    "the two semi - additive models   and   achieve similar performance over the groups residential and others ( see respectively tab .  [ tab : cerresults_res ] and tab .",
    "[ tab : cerresults_others ] ) .",
    "however , for the sme customer group , model   is better in terms of both @xmath61 and @xmath60 ( see tab .  [ tab : cerresults_sme ] ) . in previous works such as @xcite , semi - additive models of the form",
    "have been proposed to switch between different daily patterns , depending on the type of day .",
    "interestingly , our results show that in certain situations , such as when modeling industrial customers , it is even better to switch the overall sum of the daily pattern and the yearly pattern .",
    "we took a step even further by utilizing fully multiplicative models and  .",
    "the multiplicative model pools over different days of the week , while learns independent models for each day . while the former is not always better than the semi - additive models , the latter significantly outperforms them . we can conclude that a multiplicative kernel structure   is the best at capturing yearly , weekly and daily seasonal effect , both overall and for each customer group .",
    "such conclusion is aligned with recent results presented in @xcite , where tensor product basis functions were utilized to capture weekly and yearly seasonalities in the simpler context of load forecasting for a single highly aggregated time series .",
    "a further performance improvement can be obtained by utilizing a multi - task learning approach , where correlation between electricity demand behavior of multiple customers is learned and exploited .",
    "as the tables show , the multi - task okl approach provides the lowest mean @xmath61 over all the meters performance , residential and others , and second lowest mean @xmath61 for sme ( only @xmath90 higher than the lowest for this group ) .",
    "the multi - task learning approach also provides the lowest mean aggregated @xmath60 , overall and for each customer groups . finally , the multi - task approach is more robust , as the temporal standard deviation is the lowest for both @xmath61 and @xmath60 .",
    "again , such robustness can be observed overall the customers as well as for each customer group . in particular , it is worth mentioning a @xmath91 improvement of the standard deviation of the @xmath60 for sme meters , compared to the best single task model that uses the multiplicative model  .",
    "in addition to improving forecasting accuracy , the low - rank multi - task learning model is significantly more compact in terms of number of parameters .",
    "for all the single - task methods ( with additive , semi - additive and multiplicative kernels ) , the number of parameters is equal to the overall number of training observations @xmath92 . in our experiment",
    ", this amounts to about 13  million parameters ( precisely @xmath93 parameters ) .",
    "the low - rank output kernel learning method models each prediction function @xmath24 as a linear combination of @xmath34 latent functions , shared by all tasks ( see sec .  [",
    "sec : okl ] ) .",
    "these @xmath34 functions @xmath94 can be seen as typical load profiles . as a consequence , only @xmath95 parameters are required to learn the prediction functions for all smart meters . in our experiment , this gave a total of about 3  million parameters ( precisely @xmath96 ) thus producing a model that is about @xmath97 times more compact , in addition to being more accurate .",
    "our analysis shows that kernel - based multi - task learning is effective for the resolution of electric load forecasting problems .",
    "focusing on the challenging problem of forecasting the electric load of individual customers , we designed kernels that take into account relevant multiple seasonality patterns .",
    "we demonstrated the clear benefits of multiplicative kernel models over additive or semi - additive models .",
    "our results suggest a new modeling direction , as opposed to the ( generalized ) additive models , widely employed in the energy community .",
    "we illustrated further performance gain made possible by using a multi - task learning approach over a large number of single - tasks baselines . while recent studies reported @xmath60 around @xmath98 for the short term forecasting of an aggregated signal of a few thousands of smart meters e.g. @xcite",
    ", our method achieves a @xmath60 of @xmath99 on a long term forecasting scenario , which is a much harder problem as auto - regressive terms are not available .",
    "the ideas and results presented in this paper open a wide range of considerations .",
    "first of all , they suggest that electricity demand data can be used as natural test benchmarks for multi - task learning methods . in addition",
    ", these problems motivate developing new techniques that allow to incorporate more complex task relationships structures taking into account , for instance , topological and physical constraints from the electricity network .",
    "the development of online methods that can automatically discover relationships between multiple tasks seems to be particularly important for short - term load forecasting scenarios . finally , combining online multi - task learning methods with topological network constraints",
    "would allow to start tackling very complex scenarios such as forecasting on a full electricity network with dynamic reconfigurations .      c.  alzate and m.  sinn .",
    "improved electricity load forecasting via kernel spectral clustering of smart meters . in _",
    "2013 ieee 13th international conference on data mining ( icdm ) _ , pages 943948 .",
    "ieee , 2013 .    c.  alzate , m.  espinoza , b.  de  moor , and j.  ak suykens .",
    "identifying customer profiles in power load time series using spectral clustering . in _ artificial neural networks ",
    "icann 2009 _ , pages 315324 .",
    "springer , 2009 .",
    "a.  ba , m.  sinn , y.  goude , and p.  pompey .",
    "adaptive learning of smoothing functions : application to electricity load forecasting . in _ advances in neural information processing systems 25 ( nips 2012 ) _ , pages 25192527 , 2012 .",
    "f.  dinuzzo , c.  s. ong , p.  gehler , and g.  pillonetto .",
    "learning output kernels with block coordinate descent . in _ proceedings of the 28th annual international conference on machine learning _ ,",
    "bellevue , wa , usa , 2011 .",
    "f.  dinuzzo , c.s .",
    "ong , and k.  fukumizu .",
    "output kernel learning methods . in m ;  argyriou  a suykens , j ;  signoretto , editor , _ regularization , optimization , kernels , and support vector machines,_. crc press , 2014 .",
    "e.  elattar , j.  goulermas , and h.  wu . electric load forecasting based on locally weighted support vector regression .",
    "_ systems , man , and cybernetics , part c : applications and reviews , ieee transactions on _ , 400 ( 4):0 438447 , 2010 .",
    "s.  humeau , t.  k. wijaya , m.  vasirani , and k.  aberer .",
    "electricity load forecasting for residential customers : exploiting aggregation and correlation between households . in _",
    "sustainable internet and ict for sustainability ( sustainit ) , 2013 _ , pages 16 .",
    "ieee , 2013 .",
    "a.  saha , p.  rai , h.  daum iii , and s.  venkatasubramanian .",
    "online learning of multiple tasks and their relationships . in",
    "_ international conference on artificial intelligence and statistics ( aistats ) _ , ft .",
    "lauderdale , florida , 2011 .",
    "y.  zhang and d .- y .",
    "yeung . a convex formulation for learning task relationships in multi - task learning . in _ proceedings of the 26th conference on uncertainty in artificial intelligence ( uai ) _",
    ", pages 733442 , catalina island , ca , usa , 2010 ."
  ],
  "abstract_text": [
    "<S> we explore the application of kernel - based multi - task learning techniques to forecast the demand of electricity in multiple nodes of a distribution network . </S>",
    "<S> we show that recently developed output kernel learning techniques are particularly well suited to solve this problem , as they allow to flexibly model the complex seasonal effects that characterize electricity demand data , while learning and exploiting correlations between multiple demand profiles . </S>",
    "<S> we also demonstrate that kernels with a multiplicative structure yield superior predictive performance with respect to the widely adopted ( generalized ) additive models . </S>",
    "<S> our study is based on residential and industrial smart meter data provided by the irish commission for energy regulation ( cer ) . </S>"
  ]
}