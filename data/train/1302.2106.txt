{
  "article_text": [
    "the self - avoiding walk ( saw ) on a regular lattice is an important model in statistical mechanics with a long history  @xcite .",
    "an @xmath1-step saw is a map @xmath2 from the integers @xmath3 to sites on the lattice , with @xmath4 conventionally at the origin , @xmath5 , and @xmath6 .",
    "saw is a topic of much current interest : see @xcite for a recent review of rigorous results , and @xcite for an overview of self - avoiding polygons ( sap ) which has broader scope , including numerical aspects of sap and to a lesser extent saw .",
    "the most important quantities which characterize saw are the number of saw of length @xmath1 , @xmath7 , and measures of the size of the walk , such as the square end - to - end distance .",
    "the asymptotic behavior of @xmath7 on the simple cubic lattice is believed to be @xmath8 where the connective constant @xmath9 and amplitude @xmath10 are lattice dependent , the critical exponent @xmath11 is universal , and @xmath12 is the exponent of the leading correction to scaling .",
    "there are also sub - leading analytic corrections to scaling , and a contribution from the so - called anti - ferromagnetic singularity ; see for example  @xcite for more details on the asymptotic form of @xmath7 .",
    "enumeration is a particularly powerful method for studying saw on two - dimensional lattices , where the finite lattice method is highly effective  @xcite .",
    "the best estimate for @xmath9 on the square lattice comes from enumerations of self - avoiding polygons to 130 steps  @xcite , leading to the highly accurate estimate @xmath13 . for the simple cubic lattice ,",
    "the best estimate for @xmath9 comes from perm monte carlo simulations  @xcite : @xmath14 .",
    "the most powerful known enumeration method for three - dimensional lattices is the length - doubling algorithm  @xcite , which combines brute force enumeration with the inclusion - exclusion principle in a novel way",
    ". saw on the simple cubic lattice have been enumerated to 36 steps , with @xmath15 , and @xmath16  @xcite .",
    "in this paper we will obtain a highly accurate estimate of @xmath9 for saw on the simple cubic lattice using a monte carlo algorithm .",
    "our method can also be used to estimate the number of self - avoiding walks .",
    "our method to calculate @xmath9 for saw combines four key ideas :    1 .",
    "use of the pivot algorithm , the most powerful known method for sampling saw ; 2 .   a novel computer experiment which involves a telescoping sum that eliminates corrections to scaling ; 3 .   the adoption of scale - free moves to efficiently calculate the observable of interest ; 4 .   partitioning cpu time between different sub - problems in an optimal way .",
    "we now describe each of these aspects in turn .",
    "the pivot algorithm is an extremely powerful method for sampling saw in the canonical ensemble .",
    "it was invented by lal  @xcite , but the true power of the method was only appreciated after the ground - breaking work of madras and sokal  @xcite .",
    "recently , the implementation of the pivot algorithm has been improved to make it even more powerful  @xcite .",
    "the recent improvements make it an extremely attractive prospect to utilize the pivot algorithm whenever possible .",
    "the pivot algorithm is a markov chain monte carlo algorithm which works in the set of self - avoiding walks of fixed length , where the elementary move is a _ pivot _ as described below .",
    "the pivot algorithm generates a correlated sequence of saw via the following process :    1 .",
    "select a pivot site of the current saw according to some prescription - usually uniformly at random ; 2 .   randomly choose a lattice symmetry ( rotation or reflection )",
    "apply this symmetry to one of the two sub - walks created by splitting the walk at the pivot site ; 4 .",
    "if the resulting walk is self - avoiding : _",
    "accept _ the pivot and update the configuration ; 5 .",
    "if the resulting walk is not self - avoiding : _ reject _ the pivot and keep the old configuration ; 6 .   repeat .",
    "the pivot algorithm is ergodic , and satisfies the detailed balance condition which ensures that saw are sampled uniformly at random  @xcite .",
    "after a successful pivot , _ global _ observables , such as the square end - to - end distance , change significantly and are essentially uncorrelated .",
    "this observation is equivalent to the statement that the integrated autocorrelation time for a global observable @xmath10 , @xmath17 , is of the same order as the mean time for a successful pivot . in the language of @xcite ,",
    "once a successful pivot has been made the resulting configuration is `` essentially new '' with respect to global observables . for saw on the simple cubic lattice the probability of a pivot attempt being successful is @xmath18 , with @xmath19 .",
    "therefore global observables have @xmath20 ; see @xcite for extensive discussion .    for _ local _ observables , such as the angle between the 37th and 38th steps of a walk",
    ", one may need @xmath21 successful pivots before the observable changes .",
    "consequently @xmath22 for local observables .",
    "given walks @xmath23 and @xmath24 , we define a concatenation operation by placing the root point of @xmath23 at the origin , and the root point of @xmath24 at @xmath25 .",
    "we denote the resulting walk as @xmath26 . under this definition of concatenation , walks of @xmath27 and @xmath1 steps are fused together to create a walk of @xmath28 steps .",
    "we now define the observable of interest to be the indicator function defined as follows : @xmath29 see fig .",
    "[ fig : concatenation ] for two examples of concatenation .",
    "u    u    u    uu    the more common definition for concatenation has the root points for the two walks placed at the origin .",
    "we use an alternate definition because it is straightforward to calculate the indicator function using our saw - tree implementation  @xcite .",
    "if we let @xmath30 be the coordination number of the lattice ( @xmath31 for the simple cubic lattice ) , we then have @xmath32 the longest walks which have been exactly enumerated on the simple cubic lattice have 36 steps  @xcite , and we can recursively exploit this fact . for convenience",
    "we define @xmath33 and so @xmath34{\\vdots } } \\nonumber \\\\ c_{38797311 } & = { \\ensuremath{\\widetilde{b}}}_{19398655 } { \\ensuremath{\\widetilde{b}}}_{9699327}^2 \\cdots { \\ensuremath{\\widetilde{b}}}_{36}^{2^{19 } } c_{36}^{2^{20}}.\\label{eq : btlast}\\end{aligned}\\ ] ] thus , estimates for @xmath35 can be mapped to estimates of the number of walks @xmath7 .",
    "we can then use equation  ( [ eq : cnasympt ] ) to estimate @xmath9 : @xmath36 corrections to scaling vanish with increasing @xmath1 , and estimates for @xmath37 approach @xmath9 .    taking the logarithm of each side of equations ( [ eq : btfirst])([eq : btlast ] ) , one can see that the contribution of the @xmath38 term remains approximately constant , but the addition of higher order terms successively eliminate the higher order corrections .",
    "in particular , @xmath39    the approach described here may be thought of as a `` divide - and - conquer '' algorithm , where a long saw is successively split into halves .",
    "this is in stark contrast to typical growth algorithms such as perm , where saw ( and other combinatorial objects ) are incrementally built up step by step .      in order to accurately estimate @xmath9 from equation  ( [ eq : mu38797311 ] )",
    ", we must find an efficient way to estimate @xmath35 .",
    "we estimate @xmath35 by sampling pairs of saw of length @xmath1 via the pivot algorithm , and then @xmath35 is the time average of @xmath40 .",
    "the observable @xmath41 is _ not _ a global observable in the same sense as , for example , the square end - to - end distance : it clearly depends strongly on the details of the structure of each walk close to the concatenation joint .",
    "we now present a simple yet subtle argument to show that if we naively sample pivot sites uniformly at random , then @xmath42 for @xmath41 will be @xmath21 .",
    "we will assume throughout that we are considering pairs of walks of length @xmath1 .",
    "first , let us define zero atmosphere saw as those self - avoiding walks for which one of the ends has all neighboring sites occupied .",
    "it is well known that zero atmosphere walks have positive density in the set of all walks ( see e.g. @xcite ) .",
    "we denote a zero atmosphere saw as `` minimal '' if , starting from the end , we visit all of the neighbors of the end in the fewest possible number of steps . minimal zero atmosphere walks also have positive density in the set of saw . e.g. for the square lattice , the density of minimal zero atmosphere saw which start with the seven steps in fig .",
    "[ fig : trapped ] is bounded below as the saw length @xmath43 .    u    u    our ensemble is pairs of saw , each of fixed length .",
    "suppose we were to sample pivot sites uniformly at random , so generating a markov chain .",
    "assume we have equilibrated the markov chain so that we are guaranteed to be sampling from the equilibrium distribution . if we were to choose a random time in the markov chain , the probability of choosing a minimal zero atmosphere walk is then @xmath44 .",
    "however , the probability that the next pivot site chosen could change the value of the atmosphere is @xmath45 .",
    "therefore , in this case @xmath41 will , on average , remain zero for @xmath21 time steps in the markov chain . for the observable @xmath41",
    ", the contribution of zero atmosphere walks ensures that it must take time @xmath21 to achieve an essentially new configuration .",
    "thus , @xmath46 when pivots are sampled uniformly at random .",
    "note that this effect is actually quite subtle , as although zero atmosphere walks have positive density , in practice this density is small .",
    "thus the contribution of these configurations to @xmath47 is small in practice until @xmath1 is of the order of thousands or tens of thousands .",
    "however , it is possible to dramatically improve the integrated autocorrelation time for @xmath41 , and hence the accuracy of our estimate of @xmath35 .",
    "the key point is that the concatenation operation introduces a new , important length scale into the system , namely the distance from the concatenation joint to internal sites of the walk .",
    "@xmath41 depends strongly on the structure of the walk according to this distance .",
    "we make the following conjecture .",
    "[ conjecture ] suppose we have an observable for a polymer system that depends on a single internal distance , @xmath48 .",
    "then the integrated autocorrelation time for this observable is of the same order as the time it takes to make successful pivots at all length scales with respect to this distance .",
    "to be concrete , if @xmath48 is the distance from an internal site to the concatenation joint , then we believe that an essentially new configuration with respect to @xmath41 is obtained once pivots have been made at length scales @xmath48 of order @xmath49 .    by choosing pivot sites uniformly at random with respect to @xmath50",
    ", we therefore expect that there is only at most a @xmath51 penalty for the integrated autocorrelation time for @xmath35 as compared to a global observable , i.e. @xmath52 .",
    "since the cpu time per attempted pivot for the saw - tree implementation is @xmath53  @xcite , this means that in cpu units @xmath54 .      to estimate @xmath9",
    "we must calculate each of the terms in equation ( [ eq : mu38797311 ] ) .",
    "we do so by running separate monte carlo simulations for pairs of walks of length @xmath55 , @xmath56 , @xmath57 , @xmath58 , in order to calculate @xmath35 .",
    "since it takes cpu time @xmath59 to make a pivot attempt , and cpu time @xmath59 to calculate @xmath41 , we choose to sample @xmath41 for every time step in the markov chain .",
    "the procedure we used was :    1 .",
    "use the pseudo_dimerize procedure of @xcite to generate two initial @xmath1-step saw configurations .",
    "initialize markov chain by performing at least @xmath60 successful pivots on each saw .",
    "pivot sites are sampled uniformly at random .",
    "the stopping criterion must be based on the number of attempted pivots so as not to introduce bias .",
    "our sampling procedure for @xmath41 is then :    1 .",
    "select one of the two walks uniformly at random .",
    "2 .   select a pivot site on this walk by generating a pseudorandom number @xmath61 between 0 and @xmath51 , and let pivot site @xmath62 .",
    "attempt pivot move , update walk if result is self - avoiding .",
    "4 .   randomly pivot each of the walks around their root points .",
    "these pivots are always successful .",
    "calculate @xmath63 , and update our estimate of @xmath35 .",
    "repeat .",
    "our goal is to optimally partition cpu time amongst the terms in equation ( [ eq : mu38797311 ] ) , in order to minimize the overall error in our estimate of @xmath9 .",
    "the terms in equation ( [ eq : mu38797311 ] ) approach @xmath64 for large @xmath1 .",
    "we have @xmath65 the @xmath66 factor on the right hand side of the above equation dominates the increase in integrated autocorrelation time in cpu units for @xmath41",
    ". therefore if we were to invest the same cpu time in each term of equation ( [ eq : mu38797311 ] ) , the contributions to the error would diminish with increasing @xmath1 !    to minimize overall statistical error we now perform a short test run of cpu time @xmath67 for each length , determining the constants @xmath68 in @xmath69 we show these measured values of @xmath68 in fig .  [",
    "fig : an ] .",
    "however , we can also express @xmath70 in terms of the variance of @xmath41 and the integrated autocorrelation time of the algorithm .",
    "assuming that conjecture  [ conjecture ] is correct , modulo logarithmic factors we obtain the following expression for @xmath68 : @xmath71 in fig .",
    "[ fig : an ] , it is clear that @xmath68 decays as a power law with @xmath1 , as expected . by inspection",
    ", @xmath68 follows the predicted power law behavior quite closely , and thus fig .",
    "[ fig : an ] provides strong numerical support for conjecture  [ conjecture ] .    , which measures the expected error of contributions to equation  ( [ eq : mu38797311 ] ) , in units of @xmath72 .",
    "a line of slope @xmath73 is included in the plot for comparison.[fig : an ] ]    we then fix the total running time for our computer experiment at @xmath74 .",
    "the ( statistical ) square error in our estimate for @xmath9 is then @xmath75 the optimal choice of @xmath76 to minimize @xmath77 is then @xmath78 and the optimal value for the error is @xmath79 in practice , we did not rigorously apply this prescription to the longest walks , and instead spent at minimum 1% of the cpu time at each length .",
    "almost all of the computational effort is spent on the @xmath80 and @xmath81 terms in equation ( [ eq : mu38797311 ] ) .",
    "the higher order terms reduce the corrections to scaling , and essentially eliminate the systematic error in our estimate of @xmath9 .",
    "the analysis for this computer experiment is remarkably simple . it is an extremely rare example of a problem in lattice statistical mechanics for which we have strong evidence that systematic errors are negligible .",
    "hence the confidence intervals we report are purely statistical .",
    "we ran the computer experiment for a total of @xmath82 cpu hours on sunfire x4600m2 machines with 2.3ghz amd opteron cpus .    in table",
    "[ tab : cn ] we report our estimates for @xmath35 , and thence our estimates for @xmath7 from equations  ( [ eq : btfirst])([eq : btlast ] ) .",
    "note that the estimates for @xmath7 are highly correlated .",
    "the error in the mantissa is given in the final column ; for example , from table  [ tab : cn ] we estimate that @xmath83 , with the confidence interval of the mantissa being @xmath84 .",
    "this is a direct estimate from our @xmath35 values : it is _ not _ an extrapolation , and the reported error is purely statistical . as a technical aside ,",
    "the error estimates for @xmath35 in table  [ tab : cn ] are approximately constant for @xmath85 because we invested the same percentage of cpu time in each of these cases .",
    "rllc    ' '' ''    ' '' ''    @xmath1    & & & +    ' '' ''    73 & 2.47267030(65 ) & 2.139271@xmath86 & ( 2.139270 , 2.139271 ) + 147 & 2.20753977(91 ) & 1.010276@xmath87 & ( 1.010275 , 1.010277 ) + 295 & 1.9740142(14 ) & 2.014793@xmath88 & ( 2.014790 , 2.014796 ) + 591 & 1.7668271(18 ) & 7.172241@xmath89 & ( 7.172218 , 7.172264 ) + 1183 & 1.5823991(25 ) & 8.140025@xmath90 & ( 8.139971 , 8.140078 ) + 2367 & 1.4178577(36 ) & 9.394724@xmath91 & ( 9.394599 , 9.394850 ) + 4735 & 1.2708081(58 ) & 1.121626@xmath92 & ( 1.121595 , 1.121656 ) + 9471 & 1.1392521(81 ) & 1.433230@xmath93 & ( 1.433151 , 1.433308 ) + 18943 & 1.0214669(91 ) & 2.098243@xmath94 & ( 2.098013 , 2.098474 ) + 37887 & 0.9159517(92 ) & 4.032592@xmath95 & ( 4.031706 , 4.033477 ) +",
    "75775 & 0.8214372(97 ) & 1.335804@xmath96 & ( 1.335217 , 1.336391 ) + 151551 & 0.736643(10 ) & 1.314444@xmath97 & ( 1.313290 , 1.315600 ) + 303103 & 0.660651(10 ) & 1.141449@xmath98 & ( 1.139445 , 1.143457 ) + 606207 & 0.592531(11 ) & 7.720126@xmath99 & ( 7.693038 , 7.747310 ) + 1212415 & 0.531449(11 ) & 3.167451@xmath100 & ( 3.145262 , 3.189797 ) + 2424831 & 0.476654(11 ) & 4.782146@xmath101 & ( 4.715379 , 4.849858 ) + 4849663 & 0.427497(11 ) & 9.776394@xmath102 & ( 9.505309 , 1.005521 ) + 9699327 & 0.383408(12 ) & 3.664531@xmath103 & ( 3.464124 , 3.876531 ) + 19398655 & 0.343919(12 ) & 4.618409@xmath104 & ( 4.127077 , 5.168235 ) + 38797311 & 0.308455(11 ) & 6.579250@xmath105 & ( 5.253839 , 8.239029 ) +    in our analysis for @xmath9 we utilize an estimate for the critical exponent @xmath11 from a monte carlo computer experiment  @xcite : @xmath106 .",
    "in addition , we utilize the estimate of the critical amplitude @xmath107 from @xcite .",
    "we do this by setting @xmath108 , @xmath109 , and forming the improved estimates @xmath110 we denote the errors in the utilized estimates as @xmath111 and @xmath112 . in the limit of large @xmath1",
    ", @xmath113 will then have the following contributions to the systematic error : @xmath114 the @xmath12 term comes from the leading order correction in equation  ( [ eq : logscaling ] ) . from @xcite",
    "we have @xmath115 .",
    "the constant of this term is indeterminate , but we will see that it can not be so large so as to interfere with our estimates .    our estimates for @xmath9 are collected in table  [ tab : data ] .",
    "the @xmath113 estimates rapidly converge with increasing @xmath1 , which indicates that for the largest values of @xmath1 systematic errors are negligible .",
    "we can also see from the table that the statistical error , @xmath116 , is dominated by the low order terms .",
    "finally , it is clear that the contributions from the errors of the @xmath117 and @xmath118 terms are much smaller than the statistical error for large @xmath1 .",
    "one additional point is that for the largest values of @xmath1 , @xmath119 is of the order of @xmath120 . in principle , this term could have a large constant and result in a large and unknown systematic error . in practice , because of the smooth convergence of our estimates we know that the constant can not be large , and hence contributions from this term to @xmath113 are negligible for large @xmath1 .",
    "rlllll    ' '' ''    ' '' ''    @xmath1    & & & & & +    ' '' ''    73 & 4.68373253707 & 1.70@xmath121 & 2.79@xmath122 & 1.07@xmath123 & 1.60@xmath124 + 147 & 4.68392658487 & 2.13@xmath121 & 1.60@xmath122 & 5.28@xmath125 & 5.61@xmath123 + 295 & 4.68400034315 & 2.40@xmath121 & 9.06@xmath126 & 2.62@xmath125 & 1.97@xmath123 + 591 & 4.68402683289 & 2.53@xmath121 & 5.07@xmath126 & 1.31@xmath125 & 6.96@xmath125 + 1183 & 4.68403589477 & 2.60@xmath121 & 2.80@xmath126 & 6.52@xmath122 & 2.46@xmath125 + 2367 & 4.68403883775 & 2.64@xmath121 & 1.54@xmath126 & 3.26@xmath122 & 8.68@xmath122 + 4735 & 4.68403971655 & 2.68@xmath121 & 8.37@xmath121 & 1.63@xmath122 & 3.07@xmath122 + 9471 & 4.68403994072 & 2.70@xmath121 & 4.53@xmath121 & 8.14@xmath126 & 1.08@xmath122 + 18943 & 4.68403997588 & 2.71@xmath121 & 2.44@xmath121 & 4.07@xmath126 & 3.84@xmath126 + 37887 & 4.68403996593 & 2.71@xmath121 & 1.30@xmath121 & 2.04@xmath126 & 1.36@xmath126 + 75775 & 4.68403995443 & 2.71@xmath121 & 6.95@xmath127 & 1.02@xmath126 & 4.79@xmath121 + 151551 & 4.68403994395 & 2.71@xmath121 & 3.69@xmath127 & 5.09@xmath121 & 1.69@xmath121 + 303103 & 4.68403993749 & 2.72@xmath121 & 1.95@xmath127 & 2.54@xmath121 & 5.99@xmath127 + 606207 & 4.68403993406 & 2.72@xmath121 & 1.03@xmath127 & 1.27@xmath121 & 2.12@xmath127 + 1212415 & 4.68403993235 & 2.72@xmath121 & 5.41@xmath128 & 6.36@xmath127 & 7.49@xmath128 + 2424831 & 4.68403993145 & 2.72@xmath121 & 2.84@xmath128 & 3.18@xmath127 & 2.65@xmath128 + 4849663 & 4.68403993096 & 2.72@xmath121 & 1.49@xmath128 & 1.59@xmath127 & 9.36@xmath129 + 9699327 & 4.68403993069 & 2.72@xmath121 & 7.77@xmath129 & 7.95@xmath128 & 3.31@xmath129 + 19398655 & 4.68403993058 & 2.72@xmath121 & 4.05@xmath129 & 3.97@xmath128 & 1.17@xmath129 + 38797311 & 4.68403993052 & 2.72@xmath121 & 2.11@xmath129 & 1.99@xmath128 & 4.14@xmath130 +    we thus conclude that the estimate @xmath131 has negligible systematic error , and hence adopt this as our best estimate for @xmath9 .",
    "our final estimate is @xmath132 .",
    "note , we _ could _ have avoided the use of previous estimates of @xmath11 and @xmath10 , had the calculation of @xmath35 been extended to larger @xmath1 .",
    "this was not done because for @xmath1 of the order of 100 million or so , both memory management and initialization time become significant but not insurmountable issues for the simulation of saw using the saw - tree implementation  @xcite .",
    "as noted in the introduction , for the calculation of @xmath9 the approach which is most competitive with the algorithm presented in this paper is perm  @xcite , where the estimate @xmath133 was obtained .",
    "our error bar is approximately 40 times smaller , which is clearly a significant improvement upon the previous state of the art .",
    "other approaches to the calculation of @xmath9 worth noting are the method of atmospheres  @xcite , and the berretti - sokal algorithm  @xcite .",
    "we note in passing that the method of atmospheres could be combined with the pivot algorithm and scale - free moves to obtain an accurate estimate for @xmath9 .",
    "we will not go into any depth , but the method of atmospheres corresponds to estimating @xmath134 for small , fixed @xmath135 , and in the limit @xmath136 . from this expression",
    "one can then estimate @xmath9 once corrections - to - scaling have been taken into account . despite being more accurate than previous methods ,",
    "it is an order of magnitude less accurate than the method described here .",
    "this is because the mean cpu time per pivot attempt is @xmath59 for the saw - tree implementation .",
    "for the atmospheric sampling method , the dominant error comes from sampling walks in the large @xmath1 limit , while for the method described in this paper the dominant error term comes from sampling short walks ( in our case , with @xmath137 ) .    on the topic of approximation enumeration of saw beyond the limit of exact enumeration",
    ", there have been a number of papers in recent years .",
    "approaches include incomplete enumeration  @xcite , flatperm and flatgarm  @xcite , stochastic enumeration  @xcite , and the multicanonical monte carlo method  @xcite .",
    "the relative advantage of our approach is significant for small @xmath1 , e.g shirai and kikuchi  @xcite obtained @xmath138 for the square lattice , while for comparison we found @xmath139 on the simple cubic lattice . for larger @xmath1 , the relative advantage of our method increases ,",
    "since to generate a saw using an incremental growth method takes cpu time at least @xmath21 .",
    "this factor of @xmath1 becomes prohibitively large when @xmath1 is of the order of millions .",
    "it is not clear to us if our approach could be adapted to other approximate enumeration problems , or to estimations of the free energy for other models in statistical mechanics .",
    "the general principles of `` divide - and - conquer '' and the use of global moves in the canonical ensemble may be of wider use , or it may be that saw is a particularly favorable model .",
    "we consider fig .",
    "[ fig : an ] to be strong evidence in favor of the correctness of conjecture  [ conjecture ] .",
    "we therefore expect that the use of scale - free moves for the simulation of polymers will prove useful in other contexts where there are additional length scales .",
    "for example , in the cases of star polymers or confined polymers .",
    "we will explore this idea further in a future paper where we will also derive an estimate of the critical exponent @xmath11  @xcite .    in future",
    ", our implementation of the saw - tree could be optimized for the non - uniform selection of pivot sites according to our scale - free prescription . in particular",
    ", there is no reason a pivot being performed near the end of a walk should take mean cpu time @xmath59 .",
    "it is possible to arrange the binary tree data structure so that this operation would take time @xmath44 .",
    "one natural way of doing this would be to use a splay tree  @xcite , which would dynamically adjust to form an optimal tree structure for any choice of pivot site sampling distribution .",
    "we could also obtain a constant factor improvement , if it were possible to efficiently forbid configurations with immediate returns at the concatenation joint .",
    "finally , it is certainly possible to apply this approach to other lattices .",
    "unfortunately , in the case of the square lattice the finite lattice method enumerations of polygons provide estimates for @xmath9  @xcite which are approximately 2 orders of magnitude more accurate than our method .",
    "however , for three - dimensional lattices such as the body centered cubic lattice and the face centered cubic lattice , our method will allow for much more accurate calculations of @xmath9 than are currently available .",
    "we have applied the pivot algorithm to calculate the connective constant for self - avoiding walks on the simple cubic lattice , obtaining @xmath140 .",
    "our approach may also be used to derive extremely accurate estimates for the number of self - avoiding walks .",
    "the power of our approach derives from the application of an efficient global move ( the pivot algorithm ) , use of an observable which is calculated through a divide - and - conquer approach , and from the application of scale - free moves .",
    "we hope that these key ideas may prove useful in other contexts .",
    "financial support from the arc centre of excellence for mathematics and statistics of complex systems is gratefully acknowledged ."
  ],
  "abstract_text": [
    "<S> we calculate the connective constant for self - avoiding walks on the simple cubic lattice to unprecedented accuracy , using a novel application of the pivot algorithm . </S>",
    "<S> we estimate that @xmath0 . </S>",
    "<S> our method also provides accurate estimates of the number of self - avoiding walks , even for walks with millions of steps . </S>",
    "<S> +   + * keywords * self - avoiding walk ; connective constant ; monte carlo ; pivot algorithm ; approximate enumeration </S>"
  ]
}