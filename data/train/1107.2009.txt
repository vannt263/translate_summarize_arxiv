{
  "article_text": [
    "concurrent stochastic games are played by two players on a finite state space for an infinite number of rounds . in every round",
    ", the two players simultaneously and independently choose moves ( or actions ) , and the current state and the two chosen moves determine a probability distribution over the successor states .",
    "the outcome of the game ( or a _ play _ ) is an infinite sequence of states .",
    "these games were introduced by shapley  @xcite , and have been one of the most fundamental and well studied game models in stochastic graph games .",
    "we consider @xmath0-regular objectives specified as parity objectives ; that is , given an @xmath0-regular set @xmath1 of infinite state sequences , player  1 wins if the outcome of the game lies in  @xmath1",
    ". otherwise , player  2 wins , i.e. , the game is zero - sum .",
    "the class of concurrent stochastic games subsumes many other important classes of games as sub - classes : ( 1 ) _ turn - based stochastic _ games , where in every round only one player chooses moves ( i.e. , the players make moves in turns ) ; and ( 2 ) _ markov decision processes ( mdps ) _ ( one - player stochastic games ) .",
    "concurrent games and the sub - classes provide a rich framework to model various classes of dynamic reactive systems , and @xmath0-regular objectives provide a robust specification language to express all commonly used properties in verification , and all @xmath0-regular objectives can be expressed as parity objectives .",
    "thus concurrent games with parity objectives provide the mathematical framework to study many important problems in the synthesis and verification of reactive systems  @xcite ( see also  @xcite ) .",
    "the player-1 _ value _ @xmath2 of the game at a state @xmath3 is the limit probability with which player  1 can ensure that the outcome of the game lies in  @xmath1 ; that is , the value @xmath2 is the maximal probability with which player  1 can guarantee @xmath1 against all strategies of player  2 .",
    "symmetrically , the player-2 _ value _",
    "@xmath4 is the limit probability with which player  2 can ensure that the outcome of the game lies outside  @xmath1 .",
    "the problem of studying the computational complexity of mdps , turn - based stochastic games , and concurrent games with parity objectives has received a lot of attention in literature .",
    "markov decision processes with @xmath0-regular objectives have been studied in  @xcite and the results show existence of pure ( deterministic ) memoryless ( stationary ) optimal strategies for parity objectives and the problem of value computation is achievable in polynomial time .",
    "turn - based stochastic games with the special case of reachability objectives have been studied in  @xcite and existence of pure memoryless optimal strategies has been established and the decision problem of whether the value at a state is at least a given rational value lies in np @xmath5 conp . the existence of pure memoryless optimal strategies for turn - based stochastic games with parity objectives was established in  @xcite , and again the decision problem lies in np @xmath5 conp .",
    "concurrent parity games have been studied in  @xcite and for concurrent parity games optimal strategies need not exist , and @xmath6-optimal strategies ( for @xmath7 ) require both infinite memory and randomization in general , and the decision problem can be solved in pspace .",
    "almost all results in the literature consider the problem of computing values and optimal strategies when the game model is given precisely along with the objective .",
    "however , it is often unrealistic to know the precise probabilities of transition which are only estimated through observation .",
    "since the transition probabilities are not known precisely , an extremely important question is how robust is the analysis of concurrent games and its sub - classes with parity objectives with respect to small changes in the transition probabilities .",
    "this question has been largely ignored in the study of concurrent and turn - based stochastic parity games . in this paper",
    "we study the following problems related to continuity and robustness of values : ( 1 )  _ ( continuity of values ) : _ under what conditions can continuity of the value function be proved for concurrent parity games ; ( 2 )  _ ( robustness of values ) : _ can quantitative bounds be obtained on the difference of the value function in terms of the difference of the transition probabilities ; and ( 3 )  _ ( robustness of optimal strategies ) : _ do optimal strategies of a game remain @xmath6-optimal , for @xmath7 , if the transition probabilities are slightly changed .    _ our contributions .",
    "_ our contributions are as follows :    we consider _ structurally equivalent _ game structures , where the supports of the transition probabilities are the same , but the precise transition probabilities may differ .",
    "we show the following results for structurally equivalent concurrent parity games :    _ quantitative bound .",
    "_ we present a quantitative bound on the difference of the value functions of two structurally equivalent game structures in terms of the difference of the transition probabilities .",
    "we show when the difference in the transition probabilities are small , our bound is asymptotically optimal .",
    "our example to show the matching lower bound is on a markov chain , and thus our result shows that the bound for a markov chain can be generalized to concurrent games",
    ".    _ value continuity .",
    "_ we show _ value continuity _ for structurally equivalent concurrent parity games , i.e. , as the difference in the transition probabilities goes to  0 , the difference in value functions also goes to  0 .",
    "we then show that the structural equivalence assumption is necessary : we show a family of markov chains ( that are not structurally equivalent ) where the difference of the transition probabilities goes to  0 , but the difference in the value functions is  1 .",
    "it follows that the structural equivalence assumption is both necessary ( even for markov chains ) and sufficient ( even for concurrent games ) .",
    "it follows from above that our results are both optimal ( quantitative bounds ) as well as tight ( assumption both necessary and sufficient ) .",
    "our result for concurrent parity games is also a significant quantitative generalization of a result for concurrent parity games of  @xcite which shows that the set of states with value  1 remains same if the games are structurally equivalent .",
    "we also argue that the structural equivalence assumption is not unrealistic in many cases : a reactive system consists of many state variables , and given a state ( valuation of variables ) it is typically known which variables are possibly updated , and what is unknown is the precise transition probabilities ( which are estimated by observation ) .",
    "thus the system that is obtained for analysis is structurally equivalent to the underlying original system and it only differs in precise transition probabilities .    for turn - based stochastic parity games the value continuity and the quantitative bounds are same as for concurrent games .",
    "we also prove a stronger result for structurally equivalent turn - based stochastic games that shows that along with continuity of the value function , there is also robustness property for pure memoryless optimal strategies .",
    "more precisely , for all @xmath7 , we present a bound @xmath8 , such that any pure memoryless optimal strategy in a turn - based stochastic parity game is an @xmath6-optimal strategy in every structurally equivalent turn - based stochastic game such that the transition probabilities differ by at most @xmath9 .",
    "our result has deep significance as it allows the rich literature of work on turn - based stochastic games to carry over robustly for structurally equivalent turn - based stochastic games .",
    "as argued before the model of turn - based stochastic game obtained to analyze may differ slightly in precise transition probabilities , and our results shows that the analysis on the slightly imprecise model using the classical results carry over to the underlying original system with small error bounds .",
    "our results are obtained as follows .",
    "the result of  @xcite shows that the value function for concurrent parity games can be characterized as the limit of the value function of concurrent multi - discounted games ( concurrent discounted games with different discount factors associated with every state ) .",
    "there exists bound on difference on value function of discounted games  @xcite , however , the bound depends on the discount factor , and in the limit gives trivial bounds ( and in general this approach does not work as value continuity can not be proven in general and the structural equivalence assumption is necessary ) .",
    "we use a classical result on markov chains by friedlin and wentzell  @xcite and generalize a result of solan  @xcite from markov chains with single discount to markov chains with multi - discounted objective to obtain a bound that is independent of the discount factor for structurally equivalent games .",
    "then the bound also applies when we take the limit of the discount factors , and gives us the desired bound .",
    "our paper is organized as follows : in section  [ sec : defn ] we present the basic definitions , in section  [ sec : mc ] we consider markov chains with multi - discounted and parity objectives ; in section  [ sec : games ] ( subsection  [ sec : tb ] ) we prove the results related to turn - based stochastic games ( item ( 2 ) of our contributions ) and finally in subsection  [ sec : conc ] we present the quantitative bound and value continuity for concurrent games along with the two examples to illustrate the asymptotic optimality of the bound and the structural equivalence assumption is necessary .",
    "detailed proofs are presented in the appendix .",
    "in this section we define game structures , strategies , objectives , values and present other preliminary definitions",
    ".    * probability distributions . * for a finite set  @xmath10 , a _ probability distribution _ on @xmath10 is a function @xmath11 $ ] such that @xmath12 .",
    "we denote the set of probability distributions on @xmath10 by @xmath13 . given a distribution @xmath14 , we denote by @xmath15 the _ support _ of the distribution @xmath16 .    * concurrent game structures . *",
    "a ( two - player ) _ concurrent stochastic game structure _ @xmath17 consists of the following components .    * a finite state space @xmath18 and a finite set @xmath10 of moves ( or actions ) . * two move assignments @xmath19 . for @xmath20 , assignment",
    "@xmath21 associates with each state @xmath22 the nonempty set @xmath23 of moves available to player @xmath24 at state @xmath3 . * a probabilistic transition function @xmath25 , which associates with every state @xmath22 and moves",
    "@xmath26 and @xmath27 a probability distribution @xmath28 for the successor state .",
    "* at every state @xmath29 , player  1 chooses a move @xmath30 , and simultaneously and independently player  2 chooses a move @xmath31 .",
    "the game then proceeds to the successor state @xmath32 with probability @xmath33 , for all @xmath34 . for all states @xmath22 and moves",
    "@xmath35 and @xmath27 , we indicate by @xmath36 the set of possible successors of @xmath3 when moves @xmath37 , @xmath38 are selected .",
    "a _ path _ or a _ play _ of @xmath39 is an infinite sequence @xmath40 of states in @xmath18 such that for all @xmath41 , there are moves @xmath42 and @xmath43 such that @xmath44 .",
    "we denote by @xmath45 the set of all paths .",
    "we denote by @xmath46 the random variable that denotes the @xmath24-th state of a path . for a play @xmath47",
    ", we define @xmath48 to be the set of states that occur infinitely often in  @xmath49 .    * special classes of games .",
    "* we consider the following special classes of concurrent games .    _ turn - based stochastic games .",
    "_ a game structure @xmath39 is _ turn - based stochastic _ if at every state at most one player can choose among multiple moves ; that is , for every state @xmath22 there exists at most one @xmath20 with @xmath50 .    _ markov decision processes . _",
    "a game structure is a _",
    "player-1 markov decision process ( mdp ) _",
    "if for all @xmath22 we have @xmath51 , i.e. , only player  1 has choice of actions in the game .",
    "similarly , a game structure is a _",
    "player-2 mdp _ if for all @xmath22 we have @xmath52 .",
    "_ markov chains .",
    "_ a game structure is a markov chain if for all @xmath22 we have @xmath52 and @xmath51 .",
    "hence in a markov chain the players do not matter , and for the rest of the paper a markov chain consists of a tuple @xmath53 where @xmath54 is the probabilistic transition function .",
    "* strategies . *",
    "a _ strategy _ for a player is a recipe that describes how to extend a play .",
    "formally , a strategy for player @xmath55 is a mapping @xmath56 that associates with every nonempty finite sequence @xmath57 of states , representing the past history of the game , a probability distribution @xmath58 used to select the next move .",
    "the strategy @xmath59 can prescribe only moves that are available to player  @xmath24 ; that is , for all sequences @xmath60 and states @xmath29 , we require that @xmath61 .",
    "we denote by @xmath62 the set of all strategies for player @xmath55 .    given a state @xmath29 and two strategies @xmath63 and @xmath64 , we define @xmath65 to be the set of paths that can be followed by the game , when the game starts from @xmath3 and the players use the strategies @xmath66 and  @xmath67 . formally , @xmath68 if @xmath69 and if for all @xmath41 there exist moves @xmath42 and @xmath43 such that ( i )  @xmath70 ; ( ii )  @xmath71 ; and ( iii )  @xmath44 . once the starting state @xmath3 and the strategies @xmath66 and @xmath67 for the two players have been chosen , the probabilities of events are uniquely defined  @xcite , where an _ event _ @xmath72 is a measurable set of paths . for an event @xmath72 ,",
    "we denote by @xmath73 the probability that a path belongs to @xmath74 when the game starts from @xmath3 and the players use the strategies @xmath66 and  @xmath67 .    *",
    "classification of strategies .",
    "* we consider the following special classes of strategies .    _",
    "( pure ) . _",
    "a strategy @xmath75 is _ pure ( deterministic ) _ if for all @xmath57 there exists @xmath76 such that @xmath77 .",
    "thus , deterministic strategies are equivalent to functions @xmath78 .    _",
    "( finite - memory ) .",
    "_ strategies in general are _ history - dependent _ and can be represented as follows : let @xmath79 be a set called _ memory _ to remember the history of plays ( the set @xmath79 can be infinite in general ) .",
    "a strategy with memory can be described as a pair of functions : ( a ) a _ memory update _ function @xmath80 , that given the memory @xmath79 with the information about the history and the current state updates the memory ; and ( b ) a _ next move",
    "_ function @xmath81 that given the memory and the current state specifies the next move of the player . a strategy is _ finite - memory _ if the memory @xmath79 is finite .    _",
    "( memoryless ) .",
    "_ a _ memoryless _ strategy is independent of the history of play and only depends on the current state .",
    "formally , for a memoryless strategy @xmath75 we have @xmath82 for all @xmath22 and all @xmath83 . thus memoryless strategies are equivalent to functions @xmath84 .    _",
    "( pure memoryless ) . _",
    "a strategy is _ pure memoryless _ if it is both pure and memoryless .",
    "pure memoryless strategies neither use memory , nor use randomization and are equivalent to functions @xmath85 .",
    "* qualitative objectives . *",
    "we specify _ qualitative _ objectives for the players by providing the set of _ winning plays _",
    "@xmath86 for each player . in this paper",
    "we study only zero - sum games @xcite , where the objectives of the two players are complementary .",
    "a general class of objectives are the borel objectives  @xcite .",
    "borel objective _ @xmath87 is a borel set in the cantor topology on  @xmath88 . in this paper",
    "we consider _",
    "@xmath0-regular objectives _ , which lie in the first @xmath89 levels of the borel hierarchy ( i.e. , in the intersection of @xmath90 and  @xmath91 )  @xcite .",
    "all @xmath0-regular objectives can be specified as parity objectives , and hence in this work we focus on parity objectives , and they are defined as follows .    _ parity objectives . _ for @xmath92 , we let @xmath93 = { \\{c , c+1 , \\ldots , d\\}}$ ] .",
    "let @xmath94 $ ] be a function that assigns a _ priority _ @xmath95 to every state @xmath22 , where @xmath96 .",
    "the _ even parity objective _ requires that the minimum priority visited infinitely often is even .",
    "formally , the set of winning plays is defined as @xmath97 .    * quantitative objectives . *",
    "_ quantitative _ objectives are measurable functions @xmath98",
    ". we will consider _ multi - discounted _ objective functions , as there is a close connection established between concurrent games with multi - discounted objectives and concurrent games with parity objectives . given a concurrent game structure with state space @xmath18 ,",
    "let @xmath99 be a _ discount vector _ that assigns for all @xmath22 a discount factor @xmath100 ( unless otherwise mentioned we will always consider discount vectors @xmath99 such that for all @xmath22 we have @xmath100 ) .",
    "let @xmath101 be a reward function that assigns a real - valued reward @xmath102 to every state @xmath22 .",
    "the multi - discounted objective function @xmath103 maps every path to the mean - discounted reward of the path .",
    "formally , the function is defined as follows : for a path @xmath104 we have @xmath105 also note that a parity objective @xmath1 can be intepreted as a function @xmath106 by simply considering the characteristic function that assigns  1 to paths that belong to @xmath1 and  0 otherwise .",
    "* values , optimality , @xmath6-optimality . * given an objective @xmath1 which is a measurable function @xmath107 , we define the _ value _ for player  1 of game @xmath108 with objective @xmath1 from the state @xmath22 as @xmath109 i.e. , the value is the maximal expectation with which player  1 can guarantee the satisfaction of @xmath1 against all player  2 strategies .",
    "given a player-1 strategy @xmath66 , we use the notation @xmath110 a strategy @xmath66 for player  1 is _ optimal _ for an objective @xmath1 if for all states @xmath22 , we have @xmath111 for @xmath112 , a strategy @xmath66 for player  1 is _ @xmath6-optimal _ if for all states @xmath22 , we have @xmath113 the notion of values , optimal and @xmath6-optimal strategies for player  2 are defined analogously .",
    "the following theorem summarizes the results in literature related to determinacy and memory complexity of concurrent games and its sub - classes for parity and multi - discounted objectives .",
    "[ thrm_lit1 ] the following assertions hold :    1 .   _",
    "( determinacy  @xcite)_. for all concurrent game structures and for all parity and multi - discounted objectives @xmath1 we have @xmath114 2 .   _",
    "( memory complexity ) .",
    "_ for all concurrent game structures and for all multi - discounted objectives @xmath1 , randomized memoryless optimal strategies exist  @xcite . for all turn - based stochastic game structures and for all multi - discounted objectives @xmath1",
    ", pure memoryless optimal strategies exist  @xcite . for all turn - based stochastic game strucutures and for all parity objectives @xmath1 , pure memoryless optimal strategies exist  @xcite . in general optimal strategies",
    "need not exist in concurrent games with parity objectives , and @xmath6-optimal strategies , for @xmath7 , need both randomization and infinite memory in general  @xcite .",
    "the results of  @xcite established that the value of concurrent games with certain special multi - discounted objectives can be characterized as valuations of quantitaive discounted @xmath115-calculus formula . in the limit",
    ", the value function of the discounted @xmath115-calculus formula characterizes the value function of concurrent games with parity objectives .",
    "an elegant interpretation of the result was given in  @xcite , and from the interpretation we obtain the following theorem .",
    "[ thrm_lit2 ] let @xmath108 be a concurrent game structure with a parity objective @xmath1 defined by a priority function @xmath116 .",
    "let @xmath117 be a reward function that assigns reward  1 to even priority states and reward  0 to odd priority states .",
    "then there exists an order @xmath118 on the states ( where @xmath119 ) dependent only on the priority function @xmath116 such that @xmath120 in other words , if we consider the value function @xmath121 with the multi - discounted objective and take the limit of the discount factors to  1 in the order of the states we obtain the value function for the parity objective",
    ".    we now present notions related to _ structure equivalent _ game structures and distances .",
    "* structure equivalent game structures .",
    "* given two game structures @xmath122 and @xmath123 on the same state and action space , with different transition function , we say that @xmath124 and @xmath125 are _ structure equivalent _",
    "( denoted @xmath126 ) if for all @xmath22 and all @xmath127 and @xmath27 we have @xmath128 .",
    "similarly , two markov chains @xmath129 and @xmath130 are structurally equivalent ( denoted @xmath131 ) if for all @xmath29 we have @xmath132 . for a game structure @xmath108 ( resp .",
    "markov chain @xmath108 ) , we denote by @xmath133\\!]_\\equiv}}$ ] the set of all game structures ( resp .",
    "markov chains ) that are structurally equivalent to @xmath108 .",
    "* ratio and absolute distances . * given two game structures @xmath134 and @xmath123 , the _ absolute distance _ of the game structures is maximum absolute difference in the transition probabilities .",
    "formally , @xmath135 .",
    "the absolute distance for two markov chains @xmath129 and @xmath130 is @xmath136 .",
    "we now define the ratio distance between two structurally equivalent game structures and markov chains .",
    "let @xmath137 and @xmath138 be two structurally equivalent game structures .",
    "the _ ratio _",
    "distance is defined on the ratio of the transition probabilities .",
    "formally , @xmath139 the ratio distance between two structurally equivalent markov chains @xmath137 and @xmath138 is @xmath140 .",
    "* remarks about the distance functions .",
    "* we first remark that the ratio distance is not necessarily a metric .",
    "consider the markov chain with state space @xmath141 and let @xmath142 .",
    "for @xmath143 consider the transition functions @xmath144 such that @xmath145 , for all @xmath146 .",
    "let @xmath147 be the markov chain with transition function @xmath144 .",
    "then we have @xmath148 and @xmath149 , and hence @xmath150 .",
    "the above example is from  @xcite .",
    "also note that @xmath151 is only defined for structurally equivalent game structures , and without the assumption @xmath151 is @xmath152 .",
    "we also remark that the absolute distance that measures the difference in the transition probabilities is the most intuitive measure for the difference of two game structures .",
    "[ prop_dist ] let @xmath137 be a game structure ( resp .",
    "markov chain ) such that the minimum positive transition probability is @xmath153 . for all game structures ( resp .",
    "markov chains ) @xmath154\\!]_\\equiv}}$ ] we have @xmath155 .",
    "* notation for fixing strategies . * given a concurrent game structure @xmath156 , let @xmath66 be a randomized memoryless strategy .",
    "fixing the strategy @xmath66 in @xmath108 we obtain a player-2 mdp , denoted as @xmath157 , defined as follows : ( 1 ) the state space is @xmath18 ; ( 2 ) for all @xmath22 we have @xmath158 ( hence it is a player-2 mdp ) ; ( 3 ) the new transition function @xmath159 is defined as follows : for all @xmath22 and all @xmath160 we have @xmath161 .",
    "similarly if we fix a randomized memoryless strategy @xmath66 in an mdp @xmath108 we obtain a markov chain , denoted as @xmath157 .",
    "the following proposition is straightforward to verify from the definitions .",
    "[ prop_stra_fix ] let @xmath137 and @xmath138 be two concurrent game structures ( resp .",
    "mdps ) that are structurally equivalent .",
    "let @xmath66 be a randomized memoryless strategy",
    ". then @xmath162 and @xmath163 .",
    "in this section we consider markov chains with multi - discounted and parity objectives .",
    "we present a bound on the difference of value functions of two structurally equivalent markov chains that is dependent on the distance between the markov chains and is _ independent _ of the discount factors .",
    "the result for parity objectives is then a consequence of our result for multi - discounted objectives and theorem  [ thrm_lit2 ] .",
    "our result crucially depends on a result of friedlin and wentzell for markov chains and we present this result below , and then use it to obtain the main result of the section .    *",
    "result of friedlin and wentzell .",
    "* let @xmath53 be a markov chain and let @xmath164 be the initial state .",
    "let @xmath165 be a proper subset of @xmath18 and let us denote by @xmath166 the first hitting time to the set @xmath167 of states ( or the first exit time from set @xmath168 ) ( recall that @xmath169 is the random variable to denote the @xmath170-th state of a path ) .",
    "let @xmath171 denote the set of all functions from @xmath168 to @xmath18 .",
    "for every @xmath172 we define a directed graph @xmath173 where @xmath174 iff @xmath175 .",
    "let @xmath176 if the directed graph @xmath177 has no directed cycles ( i.e. , @xmath177 is a directed acyclic graph ) ; and @xmath178 otherwise . observe that since @xmath179 is a function , for every @xmath180 there is exactly one path that starts at @xmath3 .",
    "for every @xmath181 and every @xmath34 , let @xmath182 if the directed path that leaves @xmath3 in @xmath177 reaches @xmath32 , otherwise @xmath183 .",
    "we now state a result that can be obtained as a special case of the result from friedlin and wentzell  @xcite .",
    "below we use the formulation of the result as presented in  @xcite ( lemma  2 of  @xcite ) .",
    "[ thrm - fw ] let @xmath53 be a markov chain , and let @xmath184 be a proper subset of @xmath18 such that @xmath185 for every @xmath181 ( i.e. , from all @xmath181 with positive probability the first hitting time to the complement set is finite ) .",
    "then for every initial state @xmath186 and for every @xmath187 we have @xmath188 in other words , the probability that the exit state is @xmath32 when the starting state is @xmath189 is given by the expression on the right hand side ( very informally the right hand side is the normalized polynomial expression for exit probabilities ) .",
    "* value function difference for markov chains .",
    "* we will use the result of theorem  [ thrm - fw ] to obtain bounds on the value functions of markov chains .",
    "we start with the notion of mean - discounted time .    * mean - discounted time . * given a markov chain @xmath53 and a discount vector @xmath99 , we define for every state @xmath22 , the _ mean - discounted time _",
    "the process is in the state @xmath3 .",
    "we first define the mean - discounted time function @xmath190 that maps every path to the mean - discounted time that the state @xmath3 is visited , and the function is formally defined as follows : for a path @xmath104 we have @xmath191 where @xmath192 is the indicator function .",
    "the expected mean - discounted time function for a markov chain @xmath108 with transition function @xmath16 is defined as follows : @xmath193 $ ] , i.e. , it is the expected mean - discounted time for @xmath3 when the starting state is @xmath189 , where the expectation measure is defined by the markov chain with transition function @xmath16 .",
    "we now present a lemma that shows the value function for multi - discounted markov chains can be expressed as ratio of two polynomials ( the result is obtained as a simple extension of a result of solan  @xcite ) .    [ lemm : ratio ] for markov chains defined on state space @xmath18 , for all initial states @xmath164 , for all states @xmath3 , for all discount vectors @xmath99 , there exists two polynomials @xmath194 and @xmath195 in @xmath196 variables @xmath197 , where @xmath198 such that the following conditions hold :    1 .",
    "the polynomials have degree at most @xmath199 with non - negative coefficients ; and 2 .",
    "for all transition functions @xmath16 over @xmath18 we have @xmath200 , where @xmath201 , @xmath202 and @xmath203 denote the values of the function @xmath204 and @xmath205 such that all the variables @xmath197 is instantiated with values @xmath206 as given by the transition function @xmath16 .    _",
    "( sketch ) .",
    "_ we present a sketch of the proof ( details in appendix ) .",
    "fix a discount vector @xmath99 .",
    "we construct a markov chain @xmath207 as follows :",
    "@xmath208 , where @xmath209 is a copy of states of @xmath18 ( and for a state @xmath22 we denote its corresponding copy as @xmath189 ) ; and the transition function @xmath210 is defined below    1 .",
    "@xmath211 for all @xmath212 ( i.e. , all copy states are absorbing ) ; 2 .   for @xmath22",
    "we have @xmath213 i.e. , it goes to the copy with probability @xmath214 , it follows the transition @xmath16 in the original copy with probabilities multiplied by @xmath215 .",
    "we first show that for all @xmath164 and @xmath3 we have @xmath216 ; i.e. , the expected mean - discounted time in @xmath3 when the original markov chain starts in @xmath164 is the probability in the markov chain @xmath217 that the first hitting state out of @xmath18 is the copy @xmath189 of the state @xmath3 .",
    "the claim is easy to verify as both @xmath218 and @xmath219 are the unique solution of the following system of linear equations : for all @xmath34 we have @xmath220 we now claim that @xmath221 for all @xmath222 .",
    "this follows since for all @xmath22 we have @xmath223 and since @xmath224 we have @xmath225 .",
    "now we observe that we can apply theorem  [ thrm - fw ] on the markov chain @xmath207 with @xmath18 as the set @xmath168 of states of theorem  [ thrm - fw ] , and obtain the result . indeed the terms @xmath226 and @xmath227 are independent of @xmath16 , and the two products of equation ( [ eq1 ] ) each contains at most @xmath199 terms of the form @xmath228 for @xmath229 .",
    "thus the desired result follows .",
    "[ lemm : poly ] let @xmath230 be a polynomial function with non - negative coefficients of degree at most @xmath170 .",
    "let @xmath7 and @xmath231 be two non - negative vectors such that for all @xmath232 we have @xmath233 .",
    "then we have @xmath234 .    [ lemm_mc_multi ]",
    "let @xmath235 and @xmath236 be two structurally equivalent markov chains .",
    "for all non - negative reward functions @xmath101 such that the reward function is bounded by  1 , for all discount vectors @xmath99 , for all @xmath22 we have @xmath237 ; i.e. , the absolute difference of the value functions for the multi - discounted objective is bounded by @xmath238 .",
    "the proof of lemma  [ lemm_mc_multi ] uses lemma  [ lemm : ratio ] and lemma  [ lemm : poly ] and is presented in the appendix .",
    "[ thrm_mc_multi ] let @xmath235 and @xmath236 be two structurally equivalent markov chains .",
    "let @xmath239 be the minimum positive transition probability in @xmath137 .",
    "the following assertions hold :    1 .   for",
    "all non - negative reward functions @xmath101 such that the reward function is bounded by  1 , for all discount vectors @xmath99 , for all @xmath22 we have @xmath240 & \\leq & \\displaystyle ( 1+{\\varepsilon}_a)^{2\\cdot |s|}-1 \\end{array}\\ ] ] 2 .   for all parity objectives @xmath1 and for all @xmath22 we have @xmath241    where @xmath242 and @xmath243 .",
    "the first part follows from lemma  [ lemm_mc_multi ] and proposition  [ prop_dist ] .",
    "the second part follows from part  1 , the fact the value function for parity objectives is obtained as the limit of multi - discounted objectives ( theorem  [ thrm_lit2 ] ) , and the fact the bound for part  1 is independent of the discount factors ( hence independent of taking the limit ) .",
    "* remark on structural assumption in the proof .",
    "* the result of the previous theorem depends on the structural equivalence assumption in two crucial ways .",
    "they are as follows : ( 1 )  proposition  [ prop_dist ] that establishes the relation of @xmath151 and @xmath244 only holds with the assumption of structural equivalence ; and ( 2 )  without the structural equivalence assumption @xmath151 is @xmath152 , and hence without the assumption the bound of the previous theorem is @xmath152 , which is a trivial bound .",
    "we will later show ( in example  [ examp1 ] ) that the structural equivalence assumption is necessary .",
    "in this section we show two results : first we show robustness of strategies and present quantitative bounds on value functions for turn - based stochastic games and then we show continuity for concurrent parity games .      in this section",
    "we present quantitative bounds for robustness of optimal strategies in structurally equivalent turn - based stochastic games . for every @xmath7 , we present a bound @xmath8 , such that if the distance of the structurally equivalent turn - based stochastic games differs by at most @xmath9 , then any pure memoryless optimal strategy in one game is @xmath6-optimal in the other .",
    "the result is first shown for mdps and then extended to turn - based stochastic games ( both proofs are in the appendix ) .    [ thrm_tb_stochastic ]",
    "let @xmath137 be a turn - based stochastic game such that the minimum positive transition probability is @xmath153 .",
    "the following assertions hold :    1 .   for all turn - based stochastic games @xmath154\\!]_\\equiv}}$ ] , for all parity objectives @xmath1 and for all @xmath22 we have @xmath245 & \\leq & \\displaystyle \\bigg(1+\\frac{{\\mathit{dist}_a}(g_1,g_2)}{\\eta}\\bigg)^{2\\cdot |s|}-1 \\end{array}\\ ] ] 2 .   for @xmath7 ,",
    "let @xmath246 . for all @xmath154\\!]_\\equiv}}$",
    "] such that @xmath247 , for all parity objectives @xmath1 , every pure memoryless optimal strategy @xmath66 in @xmath137 is an @xmath6-optimal strategy in @xmath138 .      in this section",
    "we show value continuity for structurally equivalent concurrent parity games , and show with an example on markov chains that the continuity property breaks without the structural equivalence assumption . finally with an example on markov chains we show the our quantitative bounds are asymptotically optimal for small distance values .",
    "we start with a lemma for mdps .",
    "[ lemm_mdp_multi ] let @xmath137 and @xmath138 be two structurally equivalent mdps .",
    "let @xmath239 be the minimum positive transition probability in @xmath137 .",
    "for all non - negative reward functions @xmath101 such that the reward function is bounded by  1 , for all discount vectors @xmath99 , for all @xmath22 we have @xmath248 & \\leq & \\displaystyle   \\bigg(1+\\frac{{\\mathit{dist}_a}(g_1,g_2)}{\\eta}\\bigg)^{2\\cdot |s|}-1 \\end{array}\\ ] ]    the main idea of the proof of the above lemma is to fix a pure memoryless optimal strategy and then use the results for markov chains . using the same proof idea , along with randomized memoryless optimal strategies for concurrent game structures and the above lemma",
    ", we obtain the following lemma ( the result is identical to the previous lemma , but for concurrent game structures instead of mdps ) .",
    "[ lemm_conc_multi ] let @xmath137 and @xmath138 be two structurally equivalent concurrent game structures .",
    "let @xmath239 be the minimum positive transition probability in @xmath137 .",
    "for all non - negative reward functions @xmath101 such that the reward function is bounded by  1 , for all discount vectors @xmath99 , for all @xmath22 we have @xmath248 & \\leq & \\displaystyle   \\bigg(1+\\frac{{\\mathit{dist}_a}(g_1,g_2)}{\\eta}\\bigg)^{2\\cdot |s|}-1 \\end{array}\\ ] ]    we now present the main theorem that depends on lemma  [ lemm_conc_multi ] .    [ thrm_conc_multi ] let @xmath137 and @xmath138 be two structurally equivalent concurrent game structures .",
    "let @xmath239 be the minimum positive transition probability in @xmath137 .",
    "for all parity objectives @xmath1 and for all @xmath22 we have @xmath248 & \\leq & \\displaystyle   \\bigg(1+\\frac{{\\mathit{dist}_a}(g_1,g_2)}{\\eta}\\bigg)^{2\\cdot |s|}-1 \\end{array}\\ ] ]    the result follows from theorem  [ thrm_lit2 ] , lemma  [ lemm_conc_multi ] and the fact that the bound of lemma  [ lemm_conc_multi ] are independent of the discount factors and hence independent of taking the limits .    in the following theorem",
    "we show that for structurally equivalent game structures , for all parity objectives , the value function is continuous in the absolute distance between the game structures .",
    "we have already remarked ( after theorem  [ thrm_mc_multi ] ) that the structural equivalence assumption is required in our proofs , and we show in example  [ examp1 ] that this assumption is necessary .",
    "[ thrm_val_con ] for all concurrent game structures @xmath137 , for all parity objectives @xmath1 @xmath249\\!]_\\equiv } } , { \\mathit{dist}_a}(g_1,g_2 ) \\leq { \\varepsilon } } \\ \\",
    "\\sup_{s\\in s }",
    "let @xmath153 be the minimum positive transition probability in @xmath137 .",
    "by theorem  [ thrm_conc_multi ] we have @xmath250\\!]_\\equiv } } , { \\mathit{dist}_a}(g_1,g_2 ) \\leq { \\varepsilon } } \\",
    "\\sup_{s\\in s }     \\lim_{{\\varepsilon}\\to 0 }   \\bigg(1+\\frac{{\\varepsilon}}{\\eta}\\bigg)^{2\\cdot |s|}-1\\ ] ] the above limit equals to  0 , and the desired result follows .    [ examp1 ] in this example we show that in theorem  [ thrm_val_con ] the structural equivalence assumption is necessary , and thereby show that the result is tight .",
    "we show an markov chain @xmath137 and a family of markov chains @xmath251 , for @xmath7 , such that @xmath252 ( but @xmath137 is not structurally equivalent to @xmath251 ) with a parity objective @xmath1 and we have @xmath253 .",
    "the markov chains @xmath137 and @xmath251 are defined over the state space @xmath254 , and in @xmath137 both states have self - loops with probability  1 , and in @xmath251 the self - loop at @xmath164 has probability @xmath255 and the transition probability from @xmath164 to @xmath189 is @xmath6 ( see fig  [ figure : buchi - lim ] in appendix ) . clearly , @xmath256 .",
    "the parity objective @xmath1 requires to visit the state @xmath189 infinitely often ( i.e. , assign priority  2 to @xmath189 and priority  1 to @xmath164 ) .",
    "then we have @xmath257 as the state @xmath164 is never left , whereas in @xmath251 the state @xmath189 is the only closed recurrent set of the markov chain and hence reached with probability  1 from @xmath164 .",
    "hence @xmath258 .",
    "it follows that @xmath259 .",
    "we now show that our quantitative bound for the value function difference is asymptotically optimal for small distances .",
    "let us denote the absolute distance as @xmath6 , and the quantitative bound we obtain in theorem  [ thrm_conc_multi ] is @xmath260 , and if @xmath6 is small , then we obtain the following approximate bound @xmath261 we now illustrate with an example ( on structurally equivalent markov chains ) where the difference in the value function is @xmath262 , for small @xmath6 . consider the markov chain defined on state space @xmath263 as follows : states @xmath164 and @xmath264 are absorbing ( states with self - loops of probability  1 ) and for a state @xmath265 we have @xmath266 ; and @xmath267 ; i.e. , we have a markov chain defined on a line from @xmath268 to @xmath269 ( with @xmath268 and @xmath269 absorbing states ) and the chain moves towards @xmath268 with probability @xmath270 and towards @xmath269 with probability @xmath271 ( see fig  [ figure : asym ] with complete details in appendix ) .",
    "our goal is to estimate the probability to reach the state @xmath164 , and let @xmath272 denote the probability to reach @xmath164 from the starting state @xmath273 .",
    "we show ( details in appendix ) that if @xmath274 , then @xmath275 and for @xmath276 , such that @xmath6 is close to  0 , we have @xmath277 .",
    "observe that the markov chain obtained for @xmath274 and @xmath278 are structurally equivalent .",
    "thus the desired result follows .",
    "in this work we studied the robustness and continuity property of concurrent and turn - based stochastic parity games with respect to small imprecision in the transition probabilities .",
    "we presented ( i )  quantitative bounds on difference of the value functions and proved value continuity for concurrent parity games under the structural equivalence assumption , and ( ii )  showed robustness of all pure memoryless optimal strategies for structurally equivalent turn - based stochastic parity games .",
    "we also showed that the structural equivalence assumption is necessary and that our quantitative bounds are asymptotically optimal for small imprecision .",
    "we believe our results will find applications in robustness analysis of various other classes of stochastic games .    10    m.  abadi , l.  lamport , and p.  wolper .",
    "realizable and unrealizable specifications of reactive systems . in _ icalp89 _ , lncs 372 , pages 117 .",
    "springer , 1989 .",
    "r.  alur , t.a .",
    "henzinger , and o.  kupferman .",
    "alternating - time temporal logic .",
    ", 49:672713 , 2002 .",
    "k.  chatterjee , l.  de  alfaro , and t.a .",
    "the complexity of quantitative concurrent parity games . in _ soda06 _ , pages 678687 .",
    "acm - siam , 2004 .",
    "k.  chatterjee , t.a .",
    "henzinger , and m.  jurdziski .",
    "games with secure equilibria . in _ lics04 _ , pages 160169 .",
    "ieee , 2004 .",
    "k.  chatterjee , m.  jurdziski , and t.a .",
    "henzinger . quantitative stochastic parity games . in _ soda04 _ , pages 121130 .",
    "siam , 2004 .",
    "a.  church .",
    "logic , arithmetic , and automata . in _ proceedings of the international congress of mathematicians _ , pages 2335 .",
    "institut mittag - leffler , 1962 .",
    "a.  condon .",
    "the complexity of stochastic games .",
    ", 96(2):203224 , 1992 .    c.  courcoubetis and m.  yannakakis .",
    "the complexity of probabilistic verification .",
    ", 42(4):857907 , 1995 .",
    "l.  de  alfaro . .",
    "phd thesis , stanford university , 1997 .",
    "l.  de  alfaro and t.a .",
    "concurrent omega - regular games . in _",
    "lics00 _ , pages 141154 .",
    "ieee , 2000 .",
    "l.  de  alfaro , t.a .",
    "henzinger , and r.  majumdar .",
    "discounting the future in systems theory . in _ icalp03 _ , lncs 2719 , pages 10221037 .",
    "springer , 2003 .",
    "l.  de  alfaro and r.  majumdar . quantitative solution of omega - regular games . in _ stoc01 _ , pages 675683 .",
    "acm press , 2001 .    c.  derman . .",
    "academic press , 1970 .",
    "d.l . dill . .",
    "the mit press , 1989 .",
    "k.  etessami and m.  yannakakis .",
    "recursive concurrent stochastic games . in _",
    "icalp06 ( 2 ) _ , lncs 4052 , springer , pages 324335 , 2006 .",
    "j.  filar and k.  vrieze . .",
    "springer - verlag , 1997 .",
    "m.  i. friedlin and a.  d. wentzell . .",
    "springer , 1984 .",
    "h.  gimbert and w.  zielonka .",
    "discounting infinite games but how and why ?",
    ", 119(1):39 , 2005 .    a.  kechris .",
    "springer , 1995 .",
    "the determinacy of blackwell games .",
    ", 63(4):15651581 , 1998 .",
    "a.  pnueli and r.  rosner . on the synthesis of a reactive module . in _",
    "popl89 _ , pages 179190 .",
    "acm press , 1989 .",
    "raghavan and j.a .",
    "algorithms for stochastic games  a survey .",
    ", 35:437472 , 1991 .",
    "p.j . ramadge and w.m .",
    "supervisory control of a class of discrete - event processes .",
    ", 25(1):206230 , 1987 .",
    "stochastic games . , 39:10951100 , 1953 .",
    "e.  solan .",
    "continuity of the value of competitive markov decision processes .",
    ", 16:831845 , 2003 .",
    "w.  thomas .",
    "automata on infinite objects . in j.",
    "van leeuwen , editor , _ handbook of theoretical computer science _ ,",
    "volume  b , pages 133191 .",
    "elsevier , 1990 .",
    ". automatic verification of probabilistic concurrent finite - state systems . in _ focs85 _ , pages 327338 .",
    "ieee computer society press , 1985 .",
    "perfect - information stochastic parity games . in _ fossacs04 _ , pages 499513 .",
    "lncs 2987 , springer , 2004 .",
    "_ ( of proposition  [ prop_dist ] ) . _ consider @xmath22 , @xmath279 , and @xmath280",
    ". then we have the following two inequalities : we consider @xmath281 , and the argument for @xmath282 is symmetric .",
    "we consider @xmath281 and if @xmath283 , then @xmath284 , and otherwise we have the following inequality : @xmath285 it follows that in both cases we have @xmath286 .",
    "the desired result follows from the above inequalities .",
    "we now present the proof of lemma  [ lemm : ratio ] which is obtained as a simple extension of a result of solan  @xcite .    _",
    "( of lemma  [ lemm : ratio ] ) .",
    "_ fix a discount vector @xmath99 .",
    "we construct a markov chain @xmath207 as follows : @xmath208 , where @xmath209 is a copy of states of @xmath18 ( and for a state @xmath22 we denote its corresponding copy as @xmath189 ) ; and the transition function @xmath210 is defined below    1 .",
    "@xmath211 for all @xmath212 ( i.e. , all copy states are absorbing ) ; 2 .   for @xmath22",
    "we have @xmath213 i.e. , it goes to the copy with probability @xmath214 , it follows the transition @xmath16 in the original copy with probabilities multiplied by @xmath215 .",
    "we first show that for all @xmath164 and @xmath3 we have @xmath287 i.e. , the expected mean - discounted time in @xmath3 when the original markov chain starts in @xmath164 is the probability in the markov chain @xmath217 that the first hitting state out of @xmath18 is the copy @xmath189 of the state @xmath3 .",
    "the claim is easy to verify as both @xmath218 and @xmath219 are the solutions of the following system of linear equations @xmath288 the fact that @xmath218 is the solution of the above equation follows from the results of discounted reward markov chains ( detailed proofs with uniform discount factor for mdps is available in  @xcite ( e.g. , equation 2.15 of  @xcite ) , and specialization to markov chains and generalization to discount factor attached to every state is straightforward ) .",
    "the fact that @xmath219 is the solution of the above equation follows from the results of characterization of hitting time for transient markov chains ( see  @xcite for details ) .",
    "also the above system of linear equations has a unique solution .",
    "the uniqueness of the solution follows from the fact that this is a contraction mapping , and the proof is as follows : let @xmath289 and @xmath290 be two solutions of the system .",
    "we chose @xmath291 such that @xmath292 , i.e. , @xmath293 is a state that maximizes the difference of the two solutions .",
    "let @xmath294 .",
    "as @xmath295 and @xmath296 are solutions of the above system we have by the triangle inequality @xmath297   & \\leq &   \\displaystyle \\eta \\cdot \\sum_{t\\in s } { \\lambda}(t ) \\cdot { \\delta}(s_0)(t )   \\leq \\eta \\cdot \\max_{t\\in s } { \\lambda}(t ) \\cdot \\sum_{t \\in s}{\\delta}(s_0)(t ) . \\end{array}\\ ] ] since @xmath298 , it follows that @xmath299 .",
    "since @xmath300 it follows that we must have @xmath301 and hence the two solutions must coincide .",
    "we now claim that @xmath221 for all @xmath222 .",
    "this follows since for all @xmath22 we have @xmath223 and since @xmath224 we have @xmath225 .",
    "now we observe that we can apply theorem  [ thrm - fw ] on the markov chain @xmath207 with @xmath18 as the set @xmath168 of states of theorem  [ thrm - fw ] , and obtain the result . indeed the terms @xmath226 and @xmath227 are independent of @xmath16 , and the two products of equation ( [ eq1 ] ) each contains at most @xmath199 terms of the form @xmath228 for @xmath229 .",
    "thus the desired result follows .",
    "we now illustrate the construction of lemma  [ lemm : ratio ] with the aid of some examples .",
    "consider the markov chain @xmath108 with states @xmath3 and @xmath32 such that @xmath32 is absorbing and the transition from @xmath3 to @xmath32 has probability  1 , and let the discount factor be @xmath302 for all states .",
    "the markov chain @xmath108 along with @xmath303 is shown in fig .",
    "[ fig : illus_1 ] .",
    "if we start at @xmath3 , the mean - discounted time at @xmath32 is given by @xmath304 in the markov chain @xmath303 , the probability to reach @xmath32 from @xmath3 is @xmath302 , and once @xmath32 is reached the exit state is @xmath305 with probability  1 . hence the probability to exit through state @xmath305 is also @xmath302 .",
    "( 85,25)(0,0 ) ( n0)(0,18)@xmath3 ( n1)(20,18)@xmath32 ( n2)(70,18)@xmath3 ( n3)(90,18)@xmath32 ( n4)(70,0)@xmath189 ( n5)(90,0)@xmath305 ( n1)@xmath306 ( n3)@xmath302 ( n4)@xmath306 ( n5)@xmath306 ( n0,n1)@xmath306 ( n2,n3)@xmath302 ( n2,n4)@xmath307 ( n3,n5)@xmath307    ( 85,25)(0,0 ) ( n0)(0,18)@xmath3 ( n1)(20,18)@xmath32 ( n2)(70,18)@xmath3 ( n3)(90,18)@xmath32 ( n4)(70,0)@xmath189 ( n5)(90,0)@xmath305 ( n4)@xmath306 ( n5)@xmath306 ( n0,n1)@xmath306 ( n1,n0)@xmath306    ( n2,n3)@xmath302 ( n3,n2)@xmath302 ( n2,n4)@xmath307 ( n3,n5)@xmath307    we now consider another example to illustrate further . consider the markov chain @xmath108 and @xmath303 in fig  [ fig : illus_2 ] , where in @xmath108 it alternates between state @xmath3 and @xmath32 , and the discount factor is @xmath302 . if we start at state @xmath3 , the mean - discounted time at @xmath32 is given by @xmath308 the probability to exit through @xmath305 in @xmath303 in 2-steps is @xmath309 , in 4-steps is @xmath310 and so on .",
    "hence the probability to exit through @xmath305 in @xmath303 is @xmath311 the above examples show how the mean - discounted time in @xmath108 and the exit probability in @xmath303 has the same value .    _ ( of lemma  [ lemm : poly ] ) .",
    "_ we first write @xmath312 as follows : @xmath313 where @xmath314 , for all @xmath315 we have @xmath316 , @xmath317 , and @xmath318 for each @xmath319 . by the hypothesis of the lemma , for",
    "all @xmath320 we have @xmath321 since every @xmath316 , multiplying the above inequalities by @xmath322 and summing over @xmath315 yields the desired result .    _",
    "( of lemma  [ lemm_mc_multi ] ) .",
    "_ we first observe that for a markov chain @xmath108 we have @xmath323 , i.e. , the value function for a state @xmath3 is obtained as the sum of the product of mean - discounted time of states and the rewards with @xmath3 as the starting state .",
    "hence by lemma  [ lemm : poly ] it follows that @xmath324 can be expressed as a ratio @xmath325 of two polynomials of degree at most @xmath199 over @xmath196 variables .",
    "hence we have @xmath326 let @xmath327 . by definition for all",
    "@xmath328 , if @xmath329 , then we have both @xmath330 and @xmath331 are between @xmath332 and @xmath333 .",
    "it follows from lemma  [ lemm : poly ] , with @xmath334 that @xmath335 thus we have @xmath336 hence we have @xmath337 we consider the case when @xmath338 , and the other case argument is symmetric .",
    "we also assume without loss of generality that @xmath339 .",
    "otherwise if @xmath340 , since rewards are non - negative , it follows that no state with positive reward is reachable from @xmath3 both in @xmath137 and @xmath138 ( because if they are reachable , then they are reachable with positive probability and then the value is positive ) , and hence @xmath341 and the result of the lemma follows trivially .",
    "since we assume that @xmath338 and @xmath339 , we have @xmath342   & \\leq &    { { \\mathsf{val}}}(g_2,{\\mathsf{mdt}}({\\vec{\\lambda}},r))(s )   \\cdot \\big((1 + { \\varepsilon})^{2\\cdot|s|}-1\\big )   \\end{array}\\ ] ] since the reward function is bounded by  1 , it follows that @xmath343 , and hence we have @xmath344 the desired result follows .",
    "1 .   for all player-1 mdps @xmath154\\!]_\\equiv}}$ ] , for all parity objectives @xmath1 and for all",
    "@xmath22 we have @xmath345 & \\leq & \\displaystyle \\bigg(1+\\frac{{\\mathit{dist}_a}(g_1,g_2)}{\\eta}\\bigg)^{2\\cdot |s|}-1 \\end{array}\\ ] ] 2 .   for @xmath7 ,",
    "let @xmath246 . for all @xmath154\\!]_\\equiv}}$",
    "] such that @xmath247 , for all parity objectives @xmath1 , every pure memoryless optimal strategy @xmath66 in @xmath137 is an @xmath6-optimal strategy in @xmath138 .",
    "in other words , for the interval @xmath346 , every pure memoryless optimal strategy in @xmath137 is an @xmath6-optimal strategy in all structurally equivalent mdps of @xmath137 such that the distance lies in the interval @xmath346 .      1 .   without loss of generality ,",
    "let @xmath347 .",
    "let @xmath66 be a pure memoryless optimal strategy in @xmath137 and such a strategy exists by theorem  [ thrm_lit1 ] .",
    "then we have the following inequality @xmath348   & \\geq &   { { \\mathsf{val}}}(g_1 { \\upharpoonright}\\stra_1,\\phi)(s ) - \\big((1 + { \\mathit{dist}_r}(g_1,g_2))^{2\\cdot|s|}-1\\big ) \\\\[1ex ] & = & { { \\mathsf{val}}}(g_1,\\phi)(s ) - \\big((1 + { \\mathit{dist}_r}(g_1,g_2))^{2\\cdot|s|}-1\\big )   \\end{array}\\ ] ] the ( in)equalities are obtained : the first inequality follows because the value in @xmath138 is at least the value in @xmath138 obtained by fixing a particular strategy ( in this case @xmath349 ; the second inequality is obtained by appying theorem  [ thrm_mc_multi ] on the structurally equivalent markov chains @xmath350 and @xmath351 ; and the final equality follows since @xmath66 is an optimal strategy in @xmath137 .",
    "the desired result follows .",
    "2 .   let @xmath154\\!]_\\equiv}}$ ] such that @xmath352 .",
    "let @xmath66 be any pure memoryless optimal strategy in @xmath137 .",
    "then we have the following inequality @xmath353 & = & { { \\mathsf{val}}}(g_1,\\phi)(s ) -   \\big((1 + { \\mathit{dist}_r}(g_1,g_2))^{2\\cdot|s|}-1\\big ) \\\\[1ex ] & \\geq &    { { \\mathsf{val}}}(g_2,\\phi)(s ) -   2\\cdot \\big((1 + { \\mathit{dist}_r}(g_1,g_2))^{2\\cdot|s|}-1 \\big ) .",
    "\\end{array}\\ ] ] the first inequality is a consequence of theorem  [ thrm_mc_multi ] applied on markov chains @xmath351 and @xmath354 ; the equality follows from the fact @xmath66 is an optimal strategy in @xmath137 ; and the infinal equality follows by applying the result of part  1 . hence to prove that @xmath66 is @xmath6-optimal in @xmath138 we need to show that @xmath355 we have @xmath356 the inequality follows from proposition  [ prop_dist ] .",
    "hence to prove inequality ( [ eq - diff1 ] ) it suffices to show that @xmath357 since @xmath246 , we obtain the desired inequality .      _ ( of theorem  [ thrm_tb_stochastic ] ) . _ the proof is essentially to repeat the proof of theorem  [ thrm_mdp ] : as in mdps pure memoryless optimal strategies exist in turn - based stochastic games with parity objectives ( theorem  [ thrm_lit1 ] ) ; and once a pure memoryless strategy is fixed in a turn - based stochastic game we obtain an mdp .",
    "since theorem  [ thrm_mdp ] extend the result of theorem  [ thrm_mc_multi ] from markov chains to mdps , the proof for the desired result follows by mimicking the proof of theorem  [ thrm_mdp ] and instead of using the result of theorem  [ thrm_mc_multi ] for markov chains using the result of theorem  [ thrm_mdp ] for mdps .      _",
    "( of lemma  [ lemm_mdp_multi ] ) . _ the proof is essentially mimicking the proof of part(1 ) of theorem  [ thrm_mdp ] . without loss of generality ,",
    "let @xmath338 .",
    "let @xmath66 be a pure memoryless optimal strategy in @xmath137 and such a strategy exists by theorem  [ thrm_lit1 ] .",
    "then we have the following inequality @xmath358 & \\geq &   { { \\mathsf{val}}}(g_1 { \\upharpoonright}\\stra_1,{\\mathsf{mdt}}({\\vec{\\lambda}},r))(s ) - \\big((1 + { \\mathit{dist}_r}(g_1,g_2))^{2\\cdot|s|}-1\\big ) \\\\[1ex ] & = & { { \\mathsf{val}}}(g_1,{\\mathsf{mdt}}({\\vec{\\lambda}},r))(s ) - \\big((1 + { \\mathit{dist}_r}(g_1,g_2))^{2\\cdot|s|}-1\\big )   \\end{array}\\ ] ] the ( in)equalities are obtained : the first inequality follows because the value in @xmath138 is at least the value in @xmath138 obtained by fixing a particular strategy ( in this case @xmath349 ; the second inequality is obtained by appying theorem  [ thrm_mc_multi ] on the structurally equivalent markov chains @xmath350 and @xmath351 ; and the final equality follows since @xmath66 is an optimal strategy in @xmath137 .",
    "the desired result follows .    _",
    "( of lemma  [ lemm_conc_multi ] ) . _ the proof is essentially mimicking the proof of lemma  [ lemm_mdp_multi ] . without loss of generality ,",
    "let @xmath338 .",
    "let @xmath66 be a randomized memoryless optimal strategy in @xmath137 and such a strategy exists by theorem  [ thrm_lit1 ] .",
    "then we have the following inequality @xmath358 & \\geq &   { { \\mathsf{val}}}(g_1 { \\upharpoonright}\\stra_1,{\\mathsf{mdt}}({\\vec{\\lambda}},r))(s ) - \\big((1 + { \\mathit{dist}_r}(g_1,g_2))^{2\\cdot|s|}-1\\big ) \\\\[1ex ] & = & { { \\mathsf{val}}}(g_1,{\\mathsf{mdt}}({\\vec{\\lambda}},r))(s ) - \\big((1 + { \\mathit{dist}_r}(g_1,g_2))^{2\\cdot|s|}-1\\big )   \\end{array}\\ ] ] the argument for the inequalities are exactly the same as in lemma  [ lemm_mdp_multi ] . the desired result follows .",
    "we now show that the our quantitative bound for the value function difference is asymptotically optimal for small distances .",
    "let us denote the absolute distance as @xmath6 , and quantitative bound we obtain in theorem  [ thrm_conc_multi ] is @xmath359 , and if @xmath6 is small ( @xmath360 and @xmath6 close to zero ) , we obtain the following approximate bound @xmath361 we now illustrate with an example ( on structurally equivalent markov chains ) where the difference in the value function is @xmath262 , for small @xmath6 .",
    "consider the markov chain defined on state space @xmath263 as follows : states @xmath164 and @xmath264 are absorbing ( states with self - loops of probability  1 ) and for a state @xmath265 we have @xmath362 i.e. , we have a markov chain defined on a line from @xmath268 to @xmath269 ( with @xmath268 and @xmath269 absorbing states ) and the chain moves towards @xmath268 with probability @xmath270 and towards @xmath269 with probability @xmath271 ( see fig  [ figure : asym ] ) .",
    "our goal is to estimate the probability to reach the state @xmath164 , and let @xmath272 denote the probability to reach @xmath164 from the starting state @xmath273",
    ". then we have the following simple recurrence for @xmath265 @xmath363 and @xmath364 and @xmath365 .",
    "we will consider @xmath366 such that @xmath6 is very small and hence higher order terms ( like @xmath367 ) can be ignored .",
    "we claim that the values @xmath272 can be expressed as the following recurrence : @xmath368 , where @xmath369 .",
    "the proof is by induction and is shown below : @xmath370   & = &   ( \\frac{1}{2}+{\\varepsilon})\\cdot v_{i-1 } + ( \\frac{1}{2}-{\\varepsilon})\\cdot ( \\frac{1}{2 } + { \\varepsilon})\\cdot c_i \\cdot v_{i } \\quad \\text{(by inductive hypothesis $ v_{i+1}= ( \\frac{1}{2}+{\\varepsilon})\\cdot c_i \\cdot v_i$)}\\\\[1ex ] & = & ( \\frac{1}{2}+{\\varepsilon})\\cdot v_{i-1 } + ( \\frac{1}{4}-{\\varepsilon}^2 ) \\cdot",
    "c_i \\cdot v_{i}\\\\[1ex ]   & = & ( \\frac{1}{2}+{\\varepsilon})\\cdot v_{i-1 } + \\frac{1}{4 } \\cdot c_i \\cdot v_{i } \\qquad \\text{(ignoring $ { \\varepsilon}^2 $ ) } \\end{array}\\ ] ] it follows that @xmath371 .",
    "hence we have @xmath372 & = &   ( \\frac{1}{2}+{\\varepsilon})\\cdot 1 +   ( \\frac{1}{2}-{\\varepsilon})\\cdot ( \\frac{1}{2}+{\\varepsilon})\\cdot c_1 \\cdot v_1 \\\\[1ex ] & = &   ( \\frac{1}{2}+{\\varepsilon } ) + ( \\frac{1}{4}-{\\varepsilon}^2)\\cdot c_1 \\cdot v_1 \\\\[1ex ]   & = & ( \\frac{1}{2}+{\\varepsilon } ) + \\frac{1}{4}\\cdot c_1 \\cdot v_1 \\qquad \\text{(ignoring $ { \\varepsilon}^2 $ ) } \\end{array}\\ ] ] thus we obtain that @xmath373",
    ". then we have @xmath374 and then @xmath375 and so on .",
    "finally we obtain @xmath376 as follows : @xmath377 .",
    "observe that for the markov chain with @xmath274 , the states @xmath164 and @xmath264 are the recurrent states , and since the chain is symmetric from @xmath378 ( with @xmath274 ) the probability to reach @xmath264 and @xmath164 must be equal and hence is @xmath379 .",
    "it follows that we must have @xmath380 .",
    "hence we have that for @xmath7 , but very small , @xmath381 .",
    "thus the difference with the value function when @xmath274 as compared to when @xmath7 but very small is @xmath382 . also observe that the markov chain obtained for @xmath274 and @xmath278 are structurally equivalent .",
    "thus the desired result follows ."
  ],
  "abstract_text": [
    "<S> we consider two - player stochastic games played on a finite state space for an infinite number of rounds . </S>",
    "<S> the games are _ concurrent _ : in each round , the two players ( player  1 and player  2 ) choose their moves independently and simultaneously ; the current state and the two moves determine a probability distribution over the successor states . </S>",
    "<S> we also consider the important special case of turn - based stochastic games where players make moves in turns , rather than concurrently . </S>",
    "<S> we study concurrent games with @xmath0-regular winning conditions specified as _ parity _ objectives . </S>",
    "<S> the value for player  1 for a parity objective is the maximal probability with which the player can guarantee the satisfaction of the objective against all strategies of the opponent . </S>",
    "<S> we study the problem of continuity and robustness of the value function in concurrent and turn - based stochastic parity games with respect to imprecision in the transition probabilities . </S>",
    "<S> we present quantitative bounds on the difference of the value function ( in terms of the imprecision of the transition probabilities ) and show the value continuity for structurally equivalent concurrent games ( two games are structurally equivalent if the supports of the transition functions are the same and the probabilities differ ) . </S>",
    "<S> we also show robustness of optimal strategies for structurally equivalent turn - based stochastic parity games . </S>",
    "<S> finally , we show that the value continuity property breaks without the structural equivalence assumption ( even for markov chains ) and show that our quantitative bound is asymptotically optimal . </S>",
    "<S> hence our results are tight ( the assumption is both necessary and sufficient ) and optimal ( our quantitative bound is asymptotically optimal ) . </S>"
  ]
}