{
  "article_text": [
    "multigrid methods enable the asymptotically optimal approximate numerical solution to a wide array of partial differential equations .",
    "their major advantage is that they have , for a wide class of problems , @xmath0 complexity for solving a linear system of @xmath1 degrees of freedom ( dofs ) to a specified accuracy .",
    "however , there are many stumbling blocks to their full implementation in conjunction with adaptive unstructured finite element methods .",
    "algebraic multigrid ( amg ) methods and widely - available libraries implementing them have made great strides in allowing for the widespread use of multilevel methods in computational science @xcite .",
    "this is due to their relatively black - box nature and ability to be used for a wide variety of common problems without much expert tuning .",
    "interesting problems often must use meshes that have been adaptively refined in order to resolve numerical error or scale of interest without regard to multilevel discretization . in order to develop a fast multilevel method for such a problem , either an algebraic or geometric coarsening procedure must be employed .",
    "practitioners faced with such problems are often immediately drawn to amg because of the difficulties of geometric coarsening on nontrivial domains .    however , there are definite advantages to geometric multigrid .",
    "in fact , there have been several attempts to integrate some geometric intuition into algebraic methods @xcite . for one ,",
    "efficiency guarantees for amg are based upon heuristic , computational observation , or theoretical bounds that are hard to satisfy computationally .",
    "geometric multigrid methods , on the other hand , can be proven to have optimal convergence properties assuming certain conditions on the meshes , which will be elaborated upon in section  [ sec : umg ] .",
    "an observation made by adams @xcite on the state of unstructured geometric multigrid methods was that while zhang @xcite provided guarantees of the optimality of geometric multigrid methods , they are not directly applicable to the methods of mesh coarsening and hierarchy construction as they are typically implemented .",
    "our goal here is to use computational geometry methods to meet these quality criteria , to show a way of constructing a set of meshes in an optimal fashion that would satisfy these criteria , and to show that we have constructed a successful optimal - order multigrid method .",
    "a fairly typical scheme for constructing a series of meshes for geometric multigrid methods involves uniform refinement from some coarsest starting mesh .",
    "however , the goals of refinement for the purpose of resolving discretization or modelling error and refinement for the purposes of creating a multigrid hierarchy can easily be at odds with each other if care is not taken .",
    "if a mesh has been refined to satisfy some analytical or adaptively determined error control , then it may have vastly different length scales existing in different parts of the mesh .",
    "it is because of this that the combination of refinement in order to resolve physics and refinement for the purpose of multigrid is fraught with peril .",
    "if one refines for the purpose of creating a multigrid hierarchy from an initial coarse mesh with some grading to handle the numerical properties of the problem , the refinement of the finest mesh will not reflect the error properly .",
    "conversely if some stages of the refinement for the physics are used for the multigrid hierarchy , one may be unable to guarantee that the meshes would satisfy the quality and size constraints required by multigrid . because of this it is very difficult to make the two concepts , adaptive refinement and geometric multigrid , go hand in hand as a single adaptive meshing strategy that satisfies the needs of both methods in the general case .    in typical applications in computational science , one",
    "is often given a mesh that has already been adapted to the physics of some problem and asked to solve some some series of linear equations repeatedly on this static mesh .",
    "two examples where this happens quite frequently are in optimization problems , and in the solution of nonlinear equations by methods requiring the equations to be linearized and solved repeatedly . in this case , the only available geometric multigrid methods are based upon coarsening , and huge advantages may be reaped from precomputation of a series of coarser spaces that effectively precondition the problem .    the need for a mesh refined to resolve error can be demonstrated in some fairly straightforward cases . the need for _ a priori _ grading around a reentrant corner to resolve pollution effects @xcite is a well - studied classical phenomenon @xcite in adaptive finite element computation .",
    "multigrid computations on reentrant corner problems have been analyzed on simple meshes in the two dimensional case with shape - regular refinement @xcite or structured grading @xcite .",
    "a mesh arising from these requirements has disproportionately many of its vertices concentrated around the reentrant corner , such as the refined mesh shown in figure  [ fig : reentrantcorner ] . around a reentrant corner of mesh interior angle @xmath2",
    "we can define a factor @xmath3 then , given some constants @xmath4 and @xmath5 related to the maximum length scale in the mesh , a mesh that will optimally resolve the error induced by the reentrant corner , for @xmath6 as the length scale of the cell containing any point a distance @xmath7 away from the corner , will satisfy : @xmath8 this problem will be considered further in section  [ sec : problems ] .          when the creation of a coarsened hierarchy is considered in the geometric sense ,",
    "we mean that the problem is reduced to finding some series of meshes @xmath9 where @xmath10 is the initial mesh and and @xmath11 is the coarsest mesh .",
    "this hierarchy is constructed starting from @xmath10 .",
    "the differential operator is either rediscretized on each mesh in order to create the series of coarse problems , or interpolators between function spaces on the meshes are used to create approximate coarse versions of the original fine linear system , a process known as galerkin multigrid @xcite .",
    "the experiments in this paper are all done by rediscretization .",
    "one restriction that we will maintain throughout this paper is that the meshes are simplicial and node - nested .",
    "this means that the vertices of mesh @xmath12 are some subset of the vertices of mesh @xmath13 .",
    "this is an assumption used by many mesh refinement and coarsening methods , as it is a reasonable and common assumption that the vertices of the initial fine mesh adequately capture the domain s geometry .",
    "this is in contrast to fully nested multigrid hierarchies , where each coarse cell is the union of several fine cells .",
    "a series of non - nested unstructured coarse meshes do not necessarily need to be node - nested either . for instance , the mesh hierarchy may be created by repeatedly remeshing some cad or exact description of the domain at different resolutions .    there is some justification for extending the classical multigrid convergence results to the case of non - nested meshes @xcite .",
    "results of optimal multigrid convergence have been extended to non - quasi - uniform @xcite and degenerate meshes @xcite in two dimensions .",
    "three dimensional non - nested multigrid has been proven to work in the quasi - uniform case @xcite .",
    "we will use the mesh quality conditions required for the non - quasi - uniform case @xcite . while the example mesh hierarchies used in this paper might be quasi - uniform when considered alone",
    ", we may not assume quasi - uniformity independent of the size of the finest mesh in the asymptotic limit of refinement .",
    "it should be noted that the non - quasi - uniform theory does not exist for three dimensions , but the quasi - uniform theory @xcite serves as a guide to how the method should perform .      for any mesh @xmath14 and any cell @xmath15 in @xmath14 let @xmath16 be @xmath15 s incircle diameter and @xmath17 its longest edge , and define the aspect ratio as @xmath18 the quality of approximation @xcite and matrix condition number @xcite in fem calculations depend strongly on @xmath19 .",
    "for some constant @xmath20 , we must require that the aspect ratio of any given cell in @xmath21 satisfy @xmath22 the other half of the criteria are the local comparability conditions .",
    "assume that if we have two meshes , @xmath23 and @xmath24 , we define , for some cell @xmath15 in @xmath23 @xmath25 which defines the set of cells in a mesh @xmath24 overlapping a single cell @xmath15 in the next coarser mesh @xmath23",
    ". we can state the local comparability conditions as    @xmath26    @xmath27    eq .",
    "[ eq : loccomp1 ] implies that each cell intersects a bounded number of cells in the next finer mesh , and eq .",
    "[ eq : loccomp2 ] that the length scale differences of overlapping cells are bounded .",
    "we will also state here , for the sake of completeness , the assumption from the standard proofs of multigrid convergence necessary for the algorithmic efficiency of the method .",
    "define @xmath28 then , for some @xmath29 @xmath30 the implication is that at each coarser mesh there must be a sufficient decrease in the number of cells .",
    "a geometric decrease in the number of cells over the course of coarsening is necessary in order to have an @xmath0 method .",
    "for node - nested coarsening of an unstructured mesh , we separate the process of mesh coarsening into two stages : coarse vertex selection and remeshing .",
    "the problem of coarse vertex selection on a mesh @xmath14 involves creating some subset @xmath31 of the vertices @xmath32 of @xmath14 that is , by some measure , coarse .",
    "several techniques have been described for coarse vertex selection on unstructured simplicial meshes .",
    "the most widely used of these methods are maximum independent set ( mis ) algorithms @xcite .",
    "these choose a coarse subset of the vertices of the mesh such that no two vertices in the subset are connected by a mesh edge .",
    "the resulting set of vertices is then remeshed .",
    "given some mesh @xmath14 , we define the graph @xmath33 , which consists of the edges @xmath34 and vertices @xmath32 of @xmath14 .",
    "the mis algorithms may then be described as finding some set of coarse vertices @xmath35 such that @xmath36 this may be implemented by a simple greedy algorithm where at each stage a vertex is selected for inclusion in @xmath35 and its neighbors are removed from potential inclusion .",
    "there are a couple of issues with this method .",
    "the first being that there is no way to determine the size of the mesh resulting from coarsening .",
    "the other is that there are no real guarantees on the spatial distribution of vertices in the resulting point set .",
    "it has been shown that mis methods may , for very simple example meshes , degrade the mesh quality quite rapidly @xcite .",
    "other methods for choosing the coarse vertex selection have been proposed to mitigate this shortcoming , often based upon some notion of local increase in length scale @xcite .",
    "the coarse vertex selection method we will focus on for this was developed by miller et al .",
    "@xcite and is referred to as function - based coarsening .",
    "the method begins by defining some spacing function @xmath37 over the vertices @xmath38 of @xmath14 .",
    "@xmath37 is some approximation of the local feature size . in practice ,",
    "the approximation of the local feature size based upon the nearest - mesh - neighbor distance at each vertex is a reasonable and efficiently computable spacing function .",
    "define @xmath39 as the multiplicative coarsening parameter .",
    "@xmath39 can be considered the the minimum factor by which @xmath37 is increased at @xmath40 by the coarsening process . here",
    "we choose @xmath41 where @xmath42 in 2d and @xmath43 in 3d by the simple fact that @xmath44 for small @xmath45 would reproduce the repeated structured coarsening of an isotropic , structured , shape - regular mesh where the length scale is increased by two in every direction .",
    "@xmath39 may also be tuned , changing the size of the set of resulting coarse vertices in a problem - specific fashion to account for mesh and function - space properties , such as polynomial order .",
    "we say that a coarse subset of the vertices of @xmath14 , @xmath46 satisfies the spacing condition if @xmath47 after determining @xmath46 , @xmath48 may be created by some remeshing process .",
    "a hierarchy of meshes may then be created by reapplying the coarsening procedure to each newly - minted coarse mesh with constant @xmath39 and some recalculated @xmath49 in turn to create a yet coarser mesh .",
    "this may be done until the mesh fits some minimum size requirement , or until the creation of a desired number of meshes for the hierarchy .",
    "the original authors @xcite had fast numerical methods in mind when proving quality bounds for function - based coarsening , and a number of the properties required of the meshes are spelled out in the original work .",
    "for one , the maximum aspect ratio of the resulting mesh hierarchy may be bounded by some constant , satisfying eq .",
    "[ eq : aspectratiobound ] .",
    "we also have that , with @xmath50 being the length - scale of the cell overlapping the point @xmath51 for all @xmath52 : @xmath53 note that this condition implies the first of the local comparability conditions ( eq .  [ eq : loccomp1 ] ) . by combining the length scale bound with",
    "the aspect ratio bound , one may infer that only a certain number of fine cells may be in the neighborhood of a coarse cell , bounding the number of overlapping cells ( eq .  [ eq : loccomp2 ] ) .",
    "finally , for the coarsest mesh @xmath54 and some small constant @xmath55 , @xmath56 this implies that the coarsening procedure will be able to create a constant - sized coarse mesh . because of",
    "these conditions and their parallels with the conditions on the multigrid hierarchy , this method for coarsening is particularly appealing .",
    "parts of the function - based coarsening idea have been incorporated into other methods for mesh coarsening by ollivier - gooch @xcite .",
    "some similarities between the method we propose here and this previous work are that both use traversal of the mesh and local remeshing in order to coarsen meshes that exhibit complex features .",
    "this method constructs the conflict graph @xmath57 where @xmath58 this graph is then coarsened with an mis approach as shown above .",
    "note that in the limit of extreme grading or large @xmath39 the @xmath59 can grow to be of size @xmath60 .",
    "our method avoids this by localizing and simplifying the notion of the spacing function and choice of vertex comparisons .",
    "we modify function based coarsening in a way that reliably guarantees optimal complexity irregardless of mesh non - quasi - uniformity as discussed in section  [ sec : afem ] without dependence on the mesh and the parameter @xmath39 .",
    "we describe here a greedy algorithm for determining an approximation @xmath61 to the set of coarse vertices @xmath46 satisfying a weakened notion of the spacing condition based upon @xmath62 .",
    "talmor @xcite proposed using shortest - weighted - path distance determined by traversing along mesh edges to accomplish this . instead of doing using the shortest - weighted - path approach , we choose to use the edge connectivity to progressively transform @xmath62 into some final @xmath63 , which approximates the connectivity of the coarse mesh , @xmath48 .",
    "it should be noted that , beyond the initial @xmath62 formed at the start of the algorithm , @xmath62 does not necessarily satisfy the condition that its edges represent the edges of a valid simplicial mesh .",
    "remeshing given @xmath14 and @xmath64 as it is created in this section is discussed in section  [ sec : remeshing ] .",
    "+ [ fig : fbc ]    we begin this process by modifying condition [ eq : spacingfunctioncondition ] to be @xmath65 this restricts the spacing condition to take into account only distance between vertices connected by graph edges rather than all pairs of vertices .",
    "this restriction makes sense considering the calculation of the @xmath37 as nearest - neighbor distance is based upon adjacency of the mesh .",
    "this is an important simplification for complex domains , where the mesh may represent complex features of the domain such as holes , surfaces , and interfaces with different local characteristics on each side that may be hard to encode when the vertices are considered as a point cloud . in our model , the edges of the mesh are seen as encoding the topological connectivity of the domain .",
    "spacing only applies to topologically connected areas of the mesh as encoded in @xmath62 .",
    "define @xmath66 the algorithm starts with @xmath67 for all @xmath38 .",
    "vertices that must be included for some reasons such as the boundary issues described in section  [ sec : boundaries ] , are set to be ` included ` automatically and visited first .",
    "the remaining @xmath38 are then visited in some arbitrary order . if @xmath68 , the iteration skips the vertex . if @xmath67 , @xmath69 is changed to @xmath70 .    when @xmath69 is set to ` included ` , a subalgorithm is invoked that , given @xmath62 and some particular vertex @xmath40 , transforms @xmath62 to some intermediate @xmath71 .",
    "this subalgorithm corresponds to coarsening the area around @xmath40 until the spacing function is satisfied for all @xmath72 .",
    "each @xmath73 are tested to see if the edge @xmath74 violates eq .",
    "[ eq : graphspacingcondition ] . in the case",
    "that the condition is violated and @xmath75 , @xmath76 is removed from @xmath62 and @xmath77 is changed to @xmath78 .",
    "a removed @xmath76 s neighbors in @xmath62 are added to @xmath79 by adding edges in @xmath62 between @xmath40 and all @xmath80 if @xmath81 already . this may also be considered as an edge contraction from @xmath76 to @xmath40 .",
    "the outcome of this subalgorithm , @xmath82 , has that all @xmath83 such that @xmath84 obey eq .",
    "[ eq : graphspacingcondition ] .",
    "there is the possibility that for some @xmath85 , @xmath86 and eq .  [ eq : graphspacingcondition ] is not satisfied .",
    "this may arise due to the necessary inclusion of boundary vertices due to conditions described in section  [ sec : boundaries ] .",
    "after the subalgorithm terminates , one is left with @xmath82 .",
    "the algorithm then visits some @xmath87 ( figure [ fig : fbc_d ] ) , which , if ` included ` , will create some @xmath88 by modification of @xmath89 .",
    "once every vertex is visited , the whole algorithm terminates . at this point",
    "we may define @xmath90 despite the fact that we are considering coarsening and remeshing as a preprocessing step , we still have the goal that the algorithm should be @xmath0 with @xmath1 as the number of dofs in the discretized system . for piecewise linear finite elements ,",
    "the number of dofs in the system is exactly the number of vertices , @xmath91 , in @xmath14 . for all reasonably well - behaved meshes",
    ", we can additionally assume that @xmath92 and @xmath93 .",
    "this implies that @xmath94 .",
    "the complexity of a single invocation of the subalgorithm may be @xmath95 if some large fraction of the mesh vertices are contracted to some @xmath40 in one step .",
    "however , the aggregate number of operations taken to reach @xmath63 must be the order of the size of the original graph @xmath62 .",
    "this aggregate complexity bound is independent of the order in which @xmath40 are visited .",
    "while here we keep the assumed order in which the vertices are visited arbitrary , we see in section  [ sec : boundaries ] that specifing some restrictions on the order may be used to preserve mesh features .",
    "[ thm : complexity ] given a graph derived from a mesh @xmath62 , the graph coarsening algorithm will create @xmath61 in @xmath96 time .",
    "[ prf : complexity ] the fact that the complexity of the algorithm depends on @xmath91 at least linearly is apparent from the fact that every vertex is visited once . in order to show that the entire algorithm is @xmath97 we must establish that each edge @xmath98 is visited at most a constant number of times independent of the size of the graph .    as vertex @xmath40",
    "is visited and @xmath69 is set to ` included ` , the subalgorithm inspects each @xmath99 for @xmath100 to see if they satisfy the spacing condition with @xmath40 .",
    "@xmath98 is either deleted from @xmath62 if @xmath1 and @xmath40 do not satisfy the spacing condition , or left in place if the spacing condition is satisfied or if @xmath101 .",
    "edges that are deleted are not ever considered again .",
    "therefore , we must focus on edges that survive comparison .",
    "suppose that an edge @xmath102 is considered a second time by the subalgorithm at the visit to vertex @xmath103 .",
    "as this is the second visit to consider @xmath98 , @xmath104 must be ` included ` as in the first consideration of @xmath98 necessarily happened during the visit to @xmath87 .",
    "as both endpoints of @xmath98 have now been visited , there is no way @xmath98 may be considered a third time . as each vertex",
    "is visited once and the distance across each edge in @xmath62 is considered no more than twice , the algorithm runs in @xmath97 time .      in the node - nested case ,",
    "the problem of remeshing may be treated as a procedure taking a mesh @xmath14 and some coarse subset of @xmath14 s vertices @xmath31 and returning a new mesh @xmath48 that approximates the domain spanned by @xmath14 but only includes vertices @xmath31 .",
    "traditional constrained remeshing methods using standard meshing technology require specialized information about the domain , including the location and topology of holes in the domain , that is not typically provided with a pre - graded fine mesh .",
    "this inhibits automation since a great deal of expert input is necessary to preserve the boundary during coarsening .",
    "instead , we choose to locally remove the set of vertices @xmath105 from @xmath14 one at a time to create @xmath48 .    in the 2d case",
    ", we remove a vertices from @xmath14 in - place by a simple series of geometric predicates and edge flips .",
    "this procedure is completely localized to the neighborhood around the vertex being removed .",
    "this is done in a way that retains the delaunay condition  @xcite if the initial mesh was delaunay .",
    "similar but much more complex techniques exist in 3d  @xcite , but are difficult to make computationally robust enough for the requirements of multigrid methods , where the creation of a single bad cell may severely impact the strength of the resulting multigrid preconditioner . in this work ,",
    "we relax the delaunay condition and instead focus on mesh quality of the sort required by the multigrid method as stated in section  [ sec : umg ] .",
    "an extremely simple method of removing a vertex @xmath40 from the mesh @xmath14 is by quality - conserving edge contraction .",
    "similar approaches have been proposed for this problem previously @xcite .",
    "this may be stated as choosing @xmath106 such that for the set of cells @xmath107 that would be created during the contraction , @xmath108 subject to the constraint @xmath109 each resulting @xmath110 must also be properly oriented in space .",
    "the computational work done to remove a single vertex is @xmath111 as each potential configuration @xmath107 has that , when compared to the set of cells adjacent to @xmath40 , @xmath112 , @xmath113 because at least two cells adjacent to both @xmath1 and @xmath40 must be removed by each contraction . for each @xmath114 one must check the aspect ratio and orientation of each cell in the associated @xmath107 .",
    "assuming bounded mesh degree , the removal of @xmath115 vertices would take @xmath115 time .    note",
    "that we are directly enforcing the maximum aspect ratio that a given mesh modification may create , which makes this akin to best effort remeshing .",
    "if it is impossible to satisfy the quality conditions required of the mesh while removing a vertex , the vertex is left in place , at least for the time being .",
    "such vertices are revisited for removal if their link is modified by the removal of one of their neighbors , a process that may only happen @xmath116 times , bounding the number of attempts that may be made to remove a given vertex .",
    "due to this , we can not guarantee that this 3d remeshing finds a tetrahedralization including just the coarse vertices .",
    "however , we note that our experience with this method is that the number of vertices that must be left in place is significantly less than the typical number of steiner points added through direct delaunay remeshing using _ tetgen _  @xcite , and that this method produces tetrahedralizations entirely suitable for use with multigrid methods",
    ". the results of a study of the quality of meshes created by this method is shown in section  [ sec : quality ] .",
    "preservation of the general shape of the domain is important to the performance of the multigrid method as the coarse problem should be an approximation of the fine problem . in the worst case",
    "a coarser mesh could become topologically different from the finer mesh leading to very slow convergence or even divergence of the iterative solution .",
    "if this is to be an automatic procedure , then some basic criteria for the shapes of the sequence of meshes must be enforced .",
    "therefore , the vertex selection and remeshing algorithms must be slightly modified in order to take into account the mesh boundaries .",
    "first , we must define the features , in 2d and 3d , which require preservation .",
    "we choose these features by use of appropriate - dimensional notions of the curvature of the boundary .",
    "techniques like these are widely used in computational geometry and computer graphics @xcite . in 2d , the features we choose to explicitly preserve are the corners of the mesh .",
    "we consider any boundary vertex with an angle differing from a straight line more than @xmath117 to be a corner .",
    "for the sake of this work we assume @xmath118 .    in 3d ,",
    "the discrete curvature at a boundary vertex is computed as the difference between @xmath119 and the sum of the boundary facet angles tangent to that vertex .",
    "vertices where the absolute value of the discrete curvature is greater than @xmath117 are forced to be included .",
    "high - dihedral - angle edges , corresponding to ridges on the surface of the domain , must also be preserved .",
    "we consider any boundary edge with the absolute value of the dihedral angle greater than @xmath117 to be a boundary ridge .",
    "our approach to protecting the boundary during the coarse vertex selection procedure is to separate vertex selection into two stages , one for the interior , and one for the boundary . in the interior stage ,",
    "the boundary vertices are marked as ` included ` automatically , and therefore any interior vertices violating the spacing condition with respect to a boundary vertex are removed from @xmath62 ( figure [ fig : boundary_1 ] ) .",
    "all boundary vertices now respect the spacing condition with respect to all remaining interior vertices , making the second stage , boundary vertex selection , entirely independent of the previous coarsening of the interior .",
    "the boundary vertex selection procedure then operates independently of this , producing the completely coarsened graph @xmath120 ( figure [ fig : boundary_3 ] ) . in 3d",
    "this process is repeated once again . during the boundary coarsening procedure , vertices lying on edges that have been identified as ridges",
    "are automatically ` included ` .",
    "the ridge vertices are then coarsened in turn .",
    "corner vertices are automatically ` included ` during all stages of vertex selection , as shown in figure [ fig : boundary_2 ] .",
    "[ fig : boundaries ]    for remeshing , the only modification necessary for boundary preservation is that the removal of a boundary or ridge vertex may only be done by contraction along an edge lying on the boundary or ridge .",
    "this simple modification works especially well for meshes that have a lot of flat planes on their surfaces with sharp ridges separating them . without this procedure ,",
    "ridges may appear torn or flipped in the coarser meshes , changing the shape of the domain significantly .",
    "as the hierarchy coarse meshes are created , new edges or vertices may become marked as corners or as belonging to ridges .",
    "we have shown that local traversal is a powerful tool for the construction of node - nested coarse meshes .",
    "traversal of the node - nested meshes may also be used to efficiently construct the interpolation operators @xmath121 for @xmath122 $ ] .",
    "@xmath121 is defined as the interpolation operator between the finite element function spaces @xmath123 and @xmath124 , which are defined over the coarse mesh @xmath48 and fine mesh @xmath125 respectively for the adjacent @xmath126 and @xmath127 .",
    "we also assume that the domain @xmath128 spanned by all @xmath14 is connected .",
    "for the purposes of this paper , we assume that for each dof @xmath129 , associated with basis function @xmath130 in @xmath131 in the system has some nodal point @xmath132 and that a function @xmath133 may be projected into @xmath131 by constructing the coefficients @xmath134 given this assumption , we may construct the prolongation operator from functions in @xmath135 to @xmath131 by associating each @xmath129 with a cell @xmath136 in @xmath137 and constructing , for @xmath138 and basis functions @xmath139 supported on @xmath136 : @xmath140 one can , for the sake of simplicity , associate every @xmath141 with a single cell @xmath142 .",
    "the choice of cell is arbitrary between the cells the unknown is supported on .",
    "this makes the problem equivalent to finding , for some set of @xmath52 , @xmath143 , defined as the cell in @xmath137 that @xmath51 is located in .",
    "we also define @xmath144 , which is some cell in @xmath137 that is , in some sense , nearby @xmath51 .",
    "in addition to the points @xmath145 associated with all @xmath146 , we have the midpoint @xmath147 of every cell @xmath148 .",
    "we define a two - level nested - loop traversal algorithm .",
    "the outer loop locates @xmath149 for each @xmath150 , and the inner loop determines @xmath151 for all @xmath145 associated with @xmath138 supported on @xmath142 .",
    "once @xmath151 is resolved for all @xmath129 , one may construct the nodal interpolation operator .",
    "the outer loop consists of breadth - first searches ( bfses ) on the graph of the neighbor relations of the cells of @xmath137 in order to determine @xmath152 for each @xmath153 .",
    "this is implemented by a simple fifo queue in which the neighbors of a given cell are pushed on the back of the queue when it is visited .",
    "enqueued and visited cells are marked as such and not enqueued again .",
    "we say that two cells @xmath154 and @xmath155 are neighbors if they share a vertex , edge , or facet .",
    "the bfs to locate @xmath156 starts with the cell @xmath157 .    as @xmath158 is established for each cell @xmath159 ,",
    "the inner loop is invoked .",
    "this loop consists of a bfs for each @xmath160 associated with @xmath159 and determines @xmath151 by bfs starting from @xmath161 .",
    "the last ingredient in the algorithm is how to determine @xmath162 .",
    "one simple way of doing this is setting @xmath163 for any cell @xmath164 that is neighboring @xmath159 .",
    "this notion of locality may be exploited by setting the values of @xmath165 for all neighbors @xmath166 of a cell @xmath15 upon determining @xmath167 .",
    "when @xmath168 for any @xmath169 is determined , the connectivity of @xmath137 and @xmath170 may be effectively traversed in tandem in order to extend the search over the whole meshed domain .",
    "this process may be both started and made more efficient by exploiting the node - nested properties of the meshes .",
    "we have that meshes @xmath170 and @xmath137 will share some set of vertices @xmath171 due to our node - nested coarsening procedure . define @xmath172 to be a cell in mesh @xmath170 that is adjacent to some @xmath173 and @xmath174 to be an arbitrary cell in @xmath137 adjacent to that same @xmath40 .",
    "then , one may initialize @xmath175 to be @xmath174 .",
    "an obervation about the complexity of this algorithm may be established assuming that the conditions in section  [ sec : umg ] are satisfied by the hierarchy of meshes",
    ". it should be obvious that the complexity is going to be bounded by the total number of bfses done during the course of the algorithm multiplied by the worst - case complexity of an invocation of the bfs .",
    "it s easy to see that for @xmath176 cells in the fine mesh and @xmath1 unknowns , the geometric search must be done @xmath177 times .    in order to bound the complexity of a given bfs to a constant",
    ", we must show how many steps of traversal one must search outwards in order to locate some @xmath168 given @xmath178 .",
    "this may be accomplished by showing that the length scale the search has to cover on the fine mesh may only contain a given number of coarse mesh cells . we know",
    "that the @xmath179 is going to be less than some maximum search radius @xmath180 given that they are adjacent .",
    "we also may put a lower limit on the minimum length scale of cells in @xmath48 that overlap @xmath181 and @xmath182 by the constant in eq .",
    "[ eq : loccomp2 ] and by the aspect ratio limit in eq .",
    "[ eq : aspectratiobound ] as @xmath183 .",
    "this gives us that the number of cells that may fit between @xmath184 and @xmath168 is at most @xmath185 , which is independent of overall mesh size .",
    "note that the distance between the center of a cell @xmath15 and some nodal points @xmath145 of @xmath186 supported on @xmath15 is always less than or equal to @xmath17 .",
    "this extends this constant - size traversal bound to the inner loop also , making the entire algorithm run in @xmath187 time .",
    "in practice on isotropic meshes @xmath188 and @xmath189 are almost always in the same cell or one cell over , meaning that the topological search is an efficient method for building the interpolation operators .",
    "an extension of the algorithm that has proven necessary on complex meshes is to allow for interpolation to @xmath145 not located within a cell of the mesh .",
    "for example , the pacman mesh ( fig .",
    "[ fig : pacmanhierarchy ] ) , when coarsened , will have vertices that lie outside the coarser mesh on the round section .",
    "in order to do this , the outer loop bfses are replaced by a more complex arrangement where the bfses search for the nearest cell rather than an exact location .",
    "this nearest cell then becomes @xmath190 .",
    "the inner loop is replaced by a similar procedure , which then projects any @xmath145 that could not be exactly located to some @xmath191 on the surface of the nearest cell and modifies the basis function projection to use @xmath192 instead of @xmath193 .",
    "this procedure is easily extended to discretizations consisting of non - nodal dofs by locating sets of quadrature points associated with the fine mesh cells instead of dof nodes .",
    "this also allows for the construction of pseudointerpolants satisfying smoothness assumptions , such as the scott - zhang type interpolants  @xcite .",
    "we test the multigrid method using standard isotropic non - quasi - uniform examples from the literature .",
    "the domains used are the pacman in 2d and the fichera corner in 3d .",
    "the problems and boundary conditions computed are designed to induce a corner singularity that makes refinement such as that described in section  [ sec : afem ] necessary .",
    "the standard model problem for the pacman domain is @xcite designed to have a pollution effect at the corner singularity .",
    "the pacman domain is a unit circle with a tenth removed .",
    "the reentrant angle is therefore @xmath194 radians .",
    "the associated differential equation is @xmath195 for the fichera corner model problem , we separate the boundary of the domain into the reentrant surface @xmath196 and the outer surface @xmath197 .",
    "the fichera corner mesh consists of a twice - unit cube centered at the origin with a single octant removed .",
    "the reentrant angle is @xmath198 radians along the reentrant edges .",
    "a standard model problem with both dirichlet and neumann boundary conditions used for the fichera corner domain is @xcite @xmath199 where @xmath200 where @xmath7 and @xmath201 consist of the radius and angle when restricted to the @xmath145 , @xmath202 plane .",
    "unfortunately , this problem does not have an analytical exact solution .",
    "our goal is to show that we can effectively coarsen the _ a priori _ grading required to resolve the problem , so we will not be concerned with the solution accuracy as a measure of performance .      in order to motivate the use of the method with the multigrid solver",
    ", one must look if our implementation of the method actually lives up to the mesh quality metrics stated as requirements for guaranteed multigrid performance .",
    "this study was done using large initial pacman and fichera corner meshes coarsened using the same algorithm used for the multigrid studies in section  [ sec : multperf ] .",
    "the measurements of mesh quality we have taken correspond to the bounds on the meshes in the multigrid requirements .",
    "these are the number of vertices and cells in the mesh , the worst aspect ratio in each mesh , the maximum number of cells in a mesh overlapping any given cell in the next coarser mesh , and the maximum change in local length - scale between a mesh and the next coarser mesh at any point in the domain .",
    "the meshes are created by repeated application of the coarsening algorithm with @xmath203 in 2d and @xmath204 in 3d .",
    "level & cells & vertices & @xmath205 & @xmath206 & @xmath207 + 0 & 70740 & 35660 & 3.39 &  &  + 1 & 22650 & 11474 & 7.64 & 14 & 9.48 + 2 & 7562 & 3858 & 7.59 & 15 & 6.23 + 3 & 2422 & 1254 & 4.63 & 15 & 4.19 + 4 & 811 & 428 & 5.52 & 15 & 5.32 + 5 & 257 & 143 & 5.94 & 15 & 8.51 + 6 & 86 & 52 & 7.76 & 12 & 4.94 +    [ tab : coarsenperf2d ]         level & cells & vertices & @xmath205 & @xmath206 & @xmath207 + 0 & 373554 & 72835 & 4.41 &  &  + 1 & 49374 & 9120 & 59.3 & 197 & 6.63 + 2 & 11894 & 2269 & 59.2 & 131 & 6.70 + 3 & 3469 & 693 & 59.3 & 94 & 6.68 + 4 & 914 & 208 & 58.8 & 121 & 6.61 + 5 & 182 & 52 & 49.5 & 94 & 6.87 +    [ tab : coarsenperf3d ]    in 2d ( table [ tab : coarsenperf2d ] ) the aspect ratio of the resulting cells stays within acceptable limits during the entire process .",
    "the slight increase in the aspect ratio is expected for the coarsening of highly graded meshes , as the coarser versions must necessarily remove vertices lying between refined and coarse regions of the non - quasi - uniform mesh .",
    "however , the associated increase in aspect ratio is kept to a minimum by the enforcement of the delaunay condition .    in 3d ( table [ tab : coarsenperf3d ] ) ,",
    "we see consistent decrease of the mesh size and increase in the length scale .",
    "the maximum aspect ratio stays around @xmath20 for most of the levels .",
    "further work on our incredibly simple remeshing scheme should be able to improve this .",
    "however , we do not see successive degradation of the quality of the series of meshes as the coarsening progresses .",
    "we can assume that the quality constraints are reasonably met in both 2d and 3d .",
    "the performance of multigrid based upon the mesh series created by this algorithm using the two test examples was carried out using the dolfin @xcite finite element software modified to use the pcmg multigrid preconditioner framework from petsc @xcite .",
    "the operators were discretized using piecewise linear triangular and tetrahedral finite elements .",
    "the resulting linear systems were then solved to a relative tolerance of @xmath208 .",
    "the solvers used were ilu - preconditioned gmres for the standard iterative case , shown in the ilu columns as a control . in the multigrid case we chose to use gmres preconditioned with v - cycle multigrid .",
    "three pre and post - smooths using ilu as the smoother were performed on all but the coarsest level , for which a direct lu solve was used .",
    "for this to make sense , the coarsest mesh must have a small , nearly constant number of vertices ; a condition easily satisfied by the mesh creation routine .",
    "we coarsen until the coarsest mesh is around 200 vertices in 2d or 300 vertices in 3d .",
    "these experiments show that the convergence of the standard iterative methods becomes more and more arduous as the meshes become more and more singularly refined .",
    "the singularity in 2d is much greater , due to the sharper reentrant angle , than it is in 3d , so the more severe difference in performance between multigrid and the control method is to be expected .",
    "we see that the number of multigrid cycles levels out to a constant for both 2d ( table [ tab : mgperf2d ] ) and 3d ( table [ tab : mgperf3d ] ) .",
    "we also see that a steadily increasing number of multigrid levels are automatically generated and that the method continues to behave as expected as the coarsening procedure is continually applied .",
    "we have proposed and implemented a method for mesh coarsening that is well suited to the construction of geometric unstructured multigrid on 2d and 3d meshes . the technique used to construct the mesh hierarchy is novel in that it combines the advantages of graph - based mesh coarsening algorithms with those of techniques considering the local feature size of the mesh .",
    "this is done in a straightforward way that only considers the local connectivity of the mesh .",
    "the further extension of the method to a parallel environment is fairly straightforward .",
    "incorporating a separate parallel coarsening stage for vertices on the processor boundaries would be a natural extension of the method .",
    "techniques with a localized coarser solve , such as a variant of the bank - holst method @xcite , could be easily replicated in this framework as well .",
    "meshing issues still exist , as the local remeshing can be quite costly in 3d .",
    "there are several ways the remeshing could be improved , both in terms of efficiency and mesh quality guarantees .",
    "it is an experimental observation that remeshing using meshing software with constrained interior vertices is often faster than vertex removal .",
    "a mixed approach , where the domain could be topologically traversed and divided into regions that could be remeshed separately , may be an interesting compromise .",
    "both approaches to remeshing are also easily extendable to the creation of an all - encompassing parallel algorithm .    despite this cost ,",
    "the big win is twofold : treating the construction of coarse spaces as a precomputation step in some nonlinear or optimization solve , and using higher - order elements , where the topological description of the mesh is smaller compared to the number of dofs .",
    "it s been shown to be quite important to preserve the order of the approximation space when using multigrid for higher - order problems @xcite , and the techniques for efficiently building both pointwise and other types of interpolants shown here already work in a similar fashion for higher order fem discretizations .",
    "as we can easily control the rate at which the mesh is decimated , we can coarsen more aggressively for the high order methods , retaining the optimal complexity of the method .    one final future direction is to look at how this techique applies to problems on anisotropic meshes and the associated theory .",
    "there are successful node - nested technques proposed for semicoarsening anisotropic meshes @xcite , and the coarsening technique described here could be applied in interesting ways .",
    "the other related problem of interest involves multigrid methods for problems with highly variable coefficients .",
    "often these methods are developed and implemented in some nested framework @xcite , but with our ability to build meshes and interpolation operators that preserve interfaces ( due to their construction by traversal ) we should be able to look at these problems in the generalized unstructured setting ."
  ],
  "abstract_text": [
    "<S> the use of multigrid and related preconditioners with the finite element method is often limited by the difficulty of applying the algorithm effectively to a problem , especially when the domain has a complex shape or the mesh has adaptive refinement . </S>",
    "<S> we introduce a simplification of a general topologically - motivated mesh coarsening algorithm for use in creating hierarchies of meshes for geometric unstructured multigrid methods . </S>",
    "<S> the connections between the guarantees of this technique and the quality criteria necessary for multigrid methods for non - quasi - uniform problems are noted . </S>",
    "<S> the implementation details , in particular those related to coarsening , remeshing , and interpolation , are discussed . </S>",
    "<S> computational tests on pathological test cases from adaptive finite element methods show the performance of the technique . </S>"
  ]
}