{
  "article_text": [
    "code - based cryptography relies crucially on the hardness of decoding generic linear codes .",
    "this problem has been studied for a long time and despite many efforts on this issue @xcite the best algorithms for solving this problem @xcite are exponential in the number of errors that have to be corrected : correcting @xmath0 errors in a binary linear code of length @xmath1 has with the aforementioned algorithms a cost of @xmath2 where @xmath3 is a constant depending of the code rate @xmath4 and the algorithm .",
    "all the efforts that have been spent on this problem have only managed to decrease slightly this exponent @xmath3 .",
    "let us emphasize that this exponent is the key for estimating the security level of any code - based cryptosystem .",
    "all the aforementioned algorithms can be viewed as a refinement of the original prange algorithm @xcite and are actually all referred to as isd algorithms .",
    "there is however an algorithm that does not rely at all on prange s idea and does not belong to the isd family : statistical decoding proposed first by al jabri in @xcite and improved a little bit by overbeck in @xcite .",
    "later on , @xcite proposed an iterative version of this algorithm .",
    "it is essentially a two - stage algorithm , the first step consisting in computing an exponentially large number of parity - check equations of the smallest possible weight @xmath5 , and then from these parity - check equations the error is recovered by some kind of majority voting based on these parity - check equations .",
    "however , even if the study made by r. overbeck in @xcite lead to the conclusion that this algorithm did not allow better attacks on the cryptosystems he considered , he did not propose an asymptotic formula of its complexity that would have allowed to conduct a systematic study of the performances of this algorithm . such an asymptotic formula has been proposed in @xcite through a simplified analysis of statistical decoding , but as we will see this analysis does not capture accurately the complexity of statistical decoding .",
    "moreover both papers did not assess in general the complexity of the first step of the algorithm which consists in computing a large set of parity - check equations of moderate weight .",
    "the primary purpose of this paper is to clarify this matter by giving three results .",
    "first , we give a rigorous asymptotic study of the exponent @xmath3 of statistical decoding by relying on asymptotic formulas for krawtchouk polynomials @xcite .",
    "the number of equations which are needed for this method turns out to be remarkably simple for a large set of parameters . in theorem [ biassdecoding ]",
    "we prove that the number of parity check equations of weight @xmath6 that are needed in a code of length @xmath1 to decode @xmath7 errors is of order @xmath8 ( when we ignore polynomial factors ) and this as soon as @xmath9 .",
    "for instance , when we consider the hardest instances of the decoding problem which correspond to the case where the number of errors is equal to the gilbert - varshamov bound , then essentially our results indicate that we have to take _ all _ possible parity - checks of a given weight ( when the code is assumed to be random ) to perform statistical decoding .",
    "this asymptotic study also allows to conclude that the modeling of iterative statistical decoding made in @xcite is too optimistic .",
    "second , inspired by isd techniques , we propose a rather efficient method for computing a huge set of parity - check equations of rather low weight .",
    "finally , we give a lower bound on the complexity of this algorithm that shows that it can not improve upon prange s algorithm for the hardest instances of decoding .",
    "this lower bound follows by observing that the number @xmath10 of the parity - check equations of weight @xmath5 that are needed for the second step of the algorithm is clearly a lower - bound on the complexity of statistical decoding .",
    "what we actually prove in the last part of the paper is that irrelevant of the way we obtain these parity - check equations in the first step , the lower bound on the complexity of statistical decoding coming from the infimum of these @xmath10 s is always larger than the complexity of the prange algorithm for the hardest instances of decoding .",
    "as our study will be asymptotic , we neglect polynomial factors and use the following notation :    let @xmath11 , we write @xmath12 iff there exists a polynomial @xmath13 such that @xmath14 .    moreover",
    ", we will often use the classical result @xmath15 where @xmath16 denotes the binary entropy .",
    "we will also have to deal with complex numbers and follow the convention of the article @xcite we use here : @xmath17 is the imaginary unit satisfying the equation @xmath18 , @xmath19 is the real part of the complex number @xmath20 and we choose the branch of the complex logarithm with @xmath21,\\ ] ] and @xmath22 .",
    "in the whole paper we consider the computational decoding problem which we define as follows :    given a binary linear code of length @xmath1 of rate @xmath4 , a word @xmath23 at distance @xmath0 from the code , find a codeword @xmath24 such that @xmath25 where @xmath26 denotes the hamming distance .",
    "generally we will specify the code by an arbitrary generator matrix @xmath27 and we will denote by csd@xmath28 a specific instance of this problem . we will be interested as is standard in cryptography in the case where @xmath29 _ is supposed to be random_.    the idea behind statistical decoding may be described as follows .",
    "we first compute a very large set @xmath30 of parity - check equations of some weight @xmath5 and compute all scalar products @xmath31 ( scalar product is modulo @xmath32 ) for @xmath33 .",
    "it turns out that if we consider only the parity - checks involving a given code position @xmath34 the scalar products have a probability of being equal to @xmath35 which depends whether there is an error in this position or not . therefore counting the number of times when @xmath36 allows to recover the error in this position .",
    "let us analyze now this algorithm more precisely . to make this analysis tractable",
    "we will need to make a few simplifying assumptions .",
    "the first one we make is the same as the one made by r. overbeck in @xcite , namely that    [ ass : one ] the distribution of the @xmath31 s when @xmath37 is drawn uniformly at random from the dual codewords of weight @xmath5 is approximated by the distribution of @xmath31 when @xmath37 is drawn uniformly at random among the words of weight @xmath5 .",
    "a much simpler model is given in @xcite and is based on modeling the distribution of the @xmath38 s as the distribution of @xmath38 where the coordinates of @xmath37 are i.i.d . and distributed as a bernoulli variable of parameter @xmath39 .",
    "this presents the advantage of making the analysis of statistical decoding much simpler and allows to analyze more refined versions of statistical decoding .",
    "however as we will show , this is an oversimplification and leads to an over - optimistic estimation of the complexity of statistical decoding .",
    "the following notation will be useful .",
    "+ @xmath40 @xmath41 denotes the set of binary of words of length @xmath1 of weight @xmath5 ; + @xmath40 @xmath42 ; + @xmath40 @xmath43 ; + @xmath40 @xmath44 ; + @xmath40 @xmath45 means that @xmath46 follows a bernoulli law of parameter @xmath47 ; + @xmath40 @xmath48 means we pick @xmath37 uniformly at random in @xmath49 .",
    "we start the analysis of statistical decoding by computing the following probabilities which approximate the true probabilities we are interested in ( which correspond to choosing @xmath37 uniformly at random in @xmath50 and not in @xmath49 ) under assumption [ ass : one ] @xmath51 @xmath52 these probabilities are readily seen to be equal to @xmath53 @xmath54 they are independent of the error and the position @xmath34 .",
    "so , in the following we will use the notation @xmath55 and @xmath56 .",
    "we will define the biases @xmath57 and @xmath58 of statistical decoding by @xmath59 it will turn out , and this is essential , that @xmath60 .",
    "we can use these biases `` as a distinguisher '' .",
    "they are at the heart of statistical decoding .",
    "statistical decoding is nothing but a statistical hypothesis testing algorithm distinguishing between two hypotheses : @xmath61 based on computing the random variable @xmath62 for @xmath63 uniform and independent draws of vectors in @xmath50 : @xmath64    we have @xmath65 according to @xmath66 .",
    "so the expectation of @xmath62 is given under @xmath66 by : @xmath67    we point out that we have @xmath68 regardless of the term @xmath69 . in order to apply the following proposition",
    ", we make the following assumption :    [ ass : two ] @xmath70 are independent variables .",
    "[ chernoff s bound]@xmath71 let @xmath72 , @xmath73 i.i.d @xmath74 and we set @xmath75 .",
    "then , @xmath76",
    "* consequences : * under @xmath66 , we have @xmath77    to take our decision we proceed as follows : if @xmath78 where @xmath79 we choose @xmath80 and @xmath81 if not . for the cases of interest to us ( namely @xmath5 and @xmath0 linear in @xmath1 ) the bias @xmath82 is an exponentially small function of the codelength @xmath1 and it is obviously enough to choose @xmath63 to be of order @xmath83 to be able to make the good decisions on all @xmath1 positions simultaneously .",
    "_ on the optimality of the decision .",
    "_ all the arguments used for distinguishing both hypotheses are very crude and this raises the question whether a better test exists .",
    "it turns out that in the regime of interest to us , namely @xmath0 and @xmath5 linear in @xmath1 , the term @xmath84 is of the right order . indeed our statistical test amounts actually to the neymann - pearson test ( with a threshold in this case which is not necessarily in the middle , i.e. equal to @xmath85 ) . in the case of interest to us , the bias between both distributions @xmath82 is exponentially small in @xmath1 and chernoff s bound captures accurately the large deviations of the random variable @xmath86 .",
    "now we could wonder whether using some finer knowledge about the hypotheses @xmath87 and @xmath88 could do better .",
    "for instance we know the a priori probabilities of these hypotheses since @xmath89 . it can be readily verified that using bayesian hypothesis testing based on the a priori knowledge of the a priori probabilities of both hypotheses does not allow to change the order of number of tests which is still @xmath84 when @xmath0 and @xmath5 are linear in @xmath1 .",
    "statistical decoding is a randomized algorithm which uses the previous distinguisher .",
    "as we just noted , this distinguisher needs @xmath84 parity - check equations of weight @xmath5 to work .",
    "this number obviously depends on @xmath90 and @xmath0 and we use the notation :    @xmath91 .",
    "now we have two frameworks to present statistical decoding .",
    "we can consider the computation of @xmath92 parity - check equations as a pre - computation or to consider it as a part of the algorithm . to consider the case of pre - computation , simply remove line @xmath93 of algorithm 1 and consider the @xmath94 s as an additional input to the algorithm . `",
    "paritycheckcomputation`@xmath95 will denote an algorithm which for an input @xmath96 outputs @xmath92 vectors of @xmath50 .",
    "@xmath97 @xmath98 /*_error",
    "/*_auxiliary algorithm_*/ @xmath100 @xmath101 @xmath102 @xmath103 @xmath104    clearly statistical decoding complexity is given by    * when the @xmath94 s are already stored and computed : @xmath105 ; * when the @xmath94 s have to be computed : @xmath106 where @xmath107 stands for the complexity of the call ` paritycheckcomputation`@xmath95 .",
    "as explained in introduction , our goal is to give the asymptotic complexity of statistical decoding .",
    "we introduce for this purpose the following notations :    @xmath71    @xmath40 @xmath108 ;    @xmath40 @xmath109 .",
    "the two following quantities will be the central object of our study .",
    "we define the asymptotic complexity of statistical decoding when the @xmath110 s are already computed by @xmath111 whereas the asymptotic complexity of the complete algorithm of statistical decoding ( including the computation of the parity - check equations ) is defined by @xmath112    one could wonder why these quantities are defined as infimum limits and not directly as limits .",
    "this is due to the fact that in certain regions of the error weight and parity - check weights the asymptotic bias may from time to time become much smaller than it typically is .",
    "this bias is indeed proportional to values taken by a krawtchouk polynomial and for certain errors weights and parity - check weights we may be close to the zero of the relevant krawtchouk polynomial ( this corresponds to the second case of theorem [ th : expansion ] ) .",
    "we are looking for explicit formulas for @xmath113 and @xmath114 .",
    "the second quantity depends on the algorithm which is used .",
    "we will come back to this issue in subsection [ fram ] . for our purpose",
    "we will use krawtchouk polynomials and asymptotic expansions for them coming from @xcite .",
    "let @xmath63 be a positive integer , we recall that the krawtchouk polynomial of degree @xmath115 and order @xmath63 , @xmath116 is defined for @xmath117 by : @xmath118    these krawtchouk polynomials are readily related to our biases .",
    "we can namely observe that @xmath119 to recast the following evaluation of a krawtchouk polynomial as @xmath120 we have a similar computation for @xmath121 @xmath122    let us recall theorem 3.1 in @xcite .",
    "[ th : expansion ] let @xmath123 and @xmath124 be three positive integers .",
    "we set @xmath125 and @xmath126 .",
    "we assume @xmath127 .",
    "let @xmath128 @xmath129 has two solutions @xmath130 and @xmath131 which are the two roots of the equation @xmath132 .",
    "let @xmath133 and @xmath134 .",
    "the two roots are equal to @xmath135 and @xmath130 is defined to be root @xmath136 .",
    "there are two cases to consider    * in the case @xmath137 , @xmath138 is positive , @xmath130 is a real negative number and we can write @xmath139 where @xmath140 and @xmath141 .",
    "* in the case @xmath142 , @xmath138 is negative , @xmath130 is a complex number and we have @xmath143 where @xmath144 denotes the imaginary part of the complex number @xmath20 , @xmath145 denotes a function which is @xmath146 uniformly in @xmath115 , and @xmath147 .",
    "the asymptotic formulas hold uniformly on the compact subsets of the corresponding open intervals .",
    "note that strictly speaking is incorrectly stated in ( * ? ? ?",
    "the problem is that ( 3.20 ) is incorrect in @xcite , since both @xmath148 and @xmath149 are negative and taking a square root of these expressions leads to a purely imaginary number in ( 3.20 ) .",
    "this can be easily fixed since the expression which is just above ( 3.20 ) is correct and it just remains to take the imaginary part correctly to derive .",
    "it will be helpful to use the following notation from now on .",
    "@xmath150    and for @xmath151 we define the following quantities @xmath152    we are now going use these asymptotic expansions to derive explicit formulas for @xmath113 .",
    "we start with the following lemma .",
    "[ lem : real ] with the hypothesis of proposition just above , we have @xmath153    from and we have @xmath154    by using theorem [ th : expansion ] we obtain when plugging the asymptotic expansions of the krawtchouk polynomials into @xmath155    we clearly have @xmath156 and @xmath157 and therefore from the particular form of @xmath158 we deduce that @xmath159 we observe now that @xmath160 and therefore @xmath161    it is insightful to express the term @xmath162 as @xmath163    the point is that @xmath164 and @xmath165 where @xmath166 .",
    "therefore @xmath167 using this in and then in implies the lemma .    from this lemma we can deduce that    [ lem : realcomplete ] assume @xmath127 and @xmath168 for @xmath151",
    "we have @xmath169    we have @xmath170 where we used in @xmath171    the second case corresponding to @xmath172 is handled by the following lemma ( note that it is precisely the `` sin '' term that appears in it that lead us to define @xmath113 as an infimum limit and not as a limit )    [ lem : complex ] when @xmath172 for @xmath151 we have @xmath173 where @xmath174 and @xmath175 .",
    "the proof of this lemma is very similar to the proof of lemma [ lem : real ] . from",
    "and we have @xmath176    by plugging the asymptotic expansion of krawtchouk polynomials given in theorem [ th : expansion ] into we obtain @xmath177 where the @xmath178 s are functions which are of order @xmath146 uniformly in @xmath115 .",
    "we clearly have @xmath156 and @xmath157 and therefore from the particular form of @xmath179 we deduce that @xmath180 from this we deduce that @xmath181    we now observe that @xmath182 where follows from the observation @xmath160    recall that @xmath183 where @xmath166 and that @xmath184    the point is that @xmath164 and therefore @xmath185    using this in and then multiply by @xmath115 implies @xmath186 we can substitute for this expression in and obtain @xmath187 recall that @xmath188 by using this in we obtain @xmath189    from lemmas [ lem : realcomplete ] and [ lem : complex ] we deduce immediately that    [ cor : biassdecoding ]    we set @xmath190 ,    * if @xmath191 : @xmath192 @xmath193 * if @xmath194 : @xmath195 @xmath196    these asymptotic formulas turn out to be already accurate in the `` cryptographic range '' as it is shown in figure [ fig : numbias ] .",
    "amazingly enough these formulas can be simplified a lot in the second case of the corollary as shown by the following theorem .",
    "[ biassdecoding ] +    * if @xmath197 : @xmath198 where @xmath199 is the smallest root of @xmath200 . *",
    "if @xmath201 : @xmath202    the first case is just a slight rewriting . to prove the formula corresponding to the second case let us recall that the @xmath20 that appears in the second case of corollary [ cor : biassdecoding ] satisfies @xmath129 where @xmath203 let @xmath204 let us first differentiate this expression with respect to @xmath205 : @xmath206 since @xmath207 with @xmath208 , we deduce that @xmath209 substituting this expression for @xmath210 in yields @xmath211 we continue the proof by differentiating now @xmath212 with respect to @xmath213 : @xmath214 recall that @xmath20 is also given by one of the two roots of @xmath215 ( see theorem [ th : expansion ] for the root which is actually chosen ) and therefore @xmath216 from this we deduce that @xmath217 @xmath218 these two results on the derivative imply that @xmath219 for some constant @xmath220 which is easily seen to be equal to @xmath221 by letting @xmath205 go to @xmath222 and @xmath213 go to @xmath223 in @xmath212 .",
    "@xcite introduced another model for the parity - check equations used in statistical decoding . instead of assuming that they are chosen randomly of a given weight @xmath5",
    ", the authors of @xcite assume that they are random binary words of length @xmath1 where the entries are chosen independently of each other according to a bernoulli distribution of parameter @xmath39 .",
    "in other words , the expected weight is still @xmath5 but the weight of the parity - check equation is not fixed anymore and may vary .",
    "we will call it the _ binomial model _ of weight @xmath5 and length @xmath1 and refer to our model as the constant weight model of weight @xmath5 .",
    "the binomial model presents the advantage of simplifying significantly the analysis of statistical decoding .",
    "it is easy to analyze the simple statistical decoding algorithm that we consider here and to compute asymptotically the number of parity - check equations that ensure successful decoding .",
    "we will do this in what follows .",
    "but the authors of @xcite went further since they were even able to analyze asymptotically an iterative version of statistical decoding by following some of the ideas of @xcite .",
    "they showed that    in the binomial model of weight @xmath5 and length @xmath1 , the number of check sums that are necessary to correct with large enough probability @xmath0 errors by using the iterative decoding algorithm of @xcite is well estimated by @xmath224 with @xmath225 where the constant in the `` big o '' depends on the ratio @xmath226 .",
    "let us first show that naive statistical decoding performs almost as well when we forget about polynomial factors .",
    "it makes sense in order to compare both models to introduce some additional notation .",
    "@xmath227 where @xmath37 is a parity - check equation chosen according to the binomial model and the probability is taken over the random choice of @xmath37 in this model ( and @xmath228 means that we take the probabilities according to the binomial model ) .",
    "these quantities do not depend on @xmath34 .",
    "it will also be convenient to define @xmath229 and @xmath229 as @xmath230    the computations of ( * ? ? ? * sec ii .",
    "b ) show that @xmath231 this implies that @xmath232    it is also convenient in order to distinguish both models to rename the quantities @xmath233 , @xmath234 , @xmath121 and @xmath235 that were introduced before by referring to them as @xmath236 , @xmath237 , @xmath238 and @xmath239 respectively .",
    "we can perform the same statistical test as before by computing from @xmath63 parity - check equations @xmath240 all involving the bit @xmath34 we want to decode , the quantity @xmath241 the expectation of this quantity is @xmath242 depending on the value @xmath243 of the bit we want to decode .",
    "we decide that the bit we want to decode is equal to @xmath222 if @xmath244 and @xmath35 otherwise .",
    "as before , we observe that by chernoff s bound we make a wrong decision with probability at most @xmath245 .",
    "this probability can be made to be of order @xmath246 by choosing @xmath63 as @xmath247 for a suitable constant @xmath248 . in this case , decoding the whole sequence succeeds with probability @xmath249 .",
    "in other words , naive statistical decoding succeeds for @xmath250 .",
    "we may observe now that @xmath251 this means that naive statistical decoding needs only marginally more equations in the binomial model ( namely a multiplicative factor of order @xmath252 ) . to summarize the whole discussion ,",
    "the number of parity - checks needed for decoding is    * with iterative statistical decoding over the binomial model @xmath253 * with naive statistical decoding over the binomial model @xmath254 * with naive statistical decoding over the constant weight model @xmath255    one might wonder now whether there is a difference between both models .",
    "it is very tempting to conjecture that both models are very close to each other since the expected weight of the parity - checks is @xmath5 in both cases .",
    "however this is not the case , we are really in a large deviation situation where the bias of some extreme weights take over the bias corresponding to the typical weight of the parity check equations .",
    "to illustrate this point , we choose the weight to be @xmath256 , the number of errors as @xmath257 for some fixed @xmath205 and @xmath213 , and then let @xmath1 go to infinity . the normalized exponent and we mean here the coefficient @xmath258 .",
    "] of the number of parity - check equations which is needed is @xmath259 in the binomial case , whereas @xmath260 is given by theorem [ biassdecoding ] in the constant weight case and both terms are indeed different in general .",
    "one case which is particularly interesting is when @xmath213 and @xmath205 are chosen as @xmath261 and @xmath262 , where @xmath4 is the code rate we consider .",
    "this corresponds to the hardest case of syndrome decoding and when the parity - check equations of this weight can be easily obtained as we will see in section [ sec : naive ] .",
    "the two normalized exponents are compared on figure [ fig : kf ] as a function of the rate @xmath4 . as we see",
    ", there is a huge difference .",
    "the problem with the model chosen in @xcite is that it is a very favorable model for statistical decoding . to the best of our knowledge",
    "there are no efficient algorithms for producing such parity - checks when @xmath263 .",
    "note that even such an algorithm were to exist , selecting appropriately only one weight would not change the exponential complexity of the algorithm ( this will be proved in section [ sec : single ] ) . in other words , in order to study statistical decoding we may restrict ourselves , as we do here , to considering only one weight and not a whole range of weights .",
    "the difference between both formulas is even more apparent when considering the slopes at the origin as shown in figure [ fig : kfs ] .",
    "however both models get closer when the error weight decreases .",
    "for instance when considering a relative error @xmath264 , we see in figure [ fig : kfdgv2 ] that the difference between both models gets significantly smaller .",
    "actually the difference vanishes when the relative error tends to @xmath222 , as shown by proposition [ subcpx ] .",
    "[ asymptotic complexity of statistical decoding for a sub - linear error weight][subcpx]@xmath71 @xmath265    as @xmath213 decreases to @xmath222 , we consider for @xmath266 the first formula which is given in theorem [ biassdecoding ] .",
    "we have : @xmath267 with @xmath268    let us compute now taylor series expansion of @xmath199 when @xmath269 .",
    "we start with @xmath270    now using the fact that : @xmath271 we have : @xmath272    and we deduce that : @xmath273 @xmath274    and therefore @xmath275    now using the fact that : @xmath276 we have the asymptotic expansions with the logarithms : @xmath277 @xmath278 so we deduce that : @xmath279    so by plugging this expression with in we have the result .",
    "the sublinear case is also relevant to cryptography since several mceliece cryptosystems actually operate at this regime , this is true for the original mceliece system with fixed rate binary goppa codes @xcite or with the mdpc - mceliece cryptosystem @xcite . in this regime , @xcite showed that all isd algorithms have the same asymptotic complexity when the number @xmath0 of errors to correct is equal to @xmath280 and this is given by : @xmath281    let us compare the exponents of statistical decoding and the isd algorithms when we want to correct a sub - linear error weight .",
    "when @xmath282 the complexity we are after is subsexponential in the length . the only algorithm finding moderate weight parity - check equations in subexponential time we found is algorithm [ alg : gauss ] .",
    "it produces parity - check equations of weight @xmath283 in amortized time @xmath284 .",
    "so with this algorithm , the exponent of statistical decoding is given by @xmath285 which is twice the exponent of all the isds .",
    "we did not conclude for a relative weight @xmath286 as in any case , all the algorithms we found needed exponential time to output enough equations to perform statistical decoding .",
    "so unless one comes up with an algorithm that is able to produce parity - check equations of relative weight @xmath286 in subexponential time , statistical decoding is not better that any isds when we have to correct @xmath282 errors .",
    "the previous section showed that if it is much more favorable when it comes to perform statistical decoding to produce parity - check equations following the binomial model of weight @xmath5 rather than parity - checks of constant weight @xmath5 .",
    "the problem is that as far as we know , there is no efficient way of producing moderate weight parity - check equations ( let us say that we call moderate any weight @xmath287 ) which would follow such a model .",
    "even the `` easy case '' , where @xmath288 and where it is trivial to produce such equations by simply putting the parity - check matrix in systematic form and taking rows in this matrix , ] does not follow the binomial model : the standard deviation of the parity - check equation weight is easily seen to be different between what is actually produced by the algorithm and the binomial model of weight @xmath289 .",
    "of course , this does not mean that we should rule out the possibility that there might exist such efficient algorithms . we will however prove that under very mild conditions , that even such an algorithm were to exist then anyway it would produce by nature parity - checks of different weights and that we would have a statistical decoding algorithm of the same exponential complexity which would keep only _",
    "one very specific weight_. in other words , it is sufficient to care about the single weight case as we do here when we study just the exponential complexity of statistical decoding .    to verify this , we fix an arbitrary position we want to decode and assume that some algorithm has produced in time @xmath290 , @xmath291 parity check equations involving this position where @xmath292 denotes the number of parity - check equations of weight @xmath293 .",
    "the equations of weight @xmath293 are denoted by @xmath294 .",
    "statistical decoding is based on simple statistics involving the values @xmath295 . to simplify a little bit the expressions we are going to manipulate , let us introduce @xmath296    similarly to assumptions [ ass : one ] and [ ass : two ]",
    ", we assume that the distribution of @xmath297 is approximated by the distribution of @xmath297 when @xmath298 is drawn uniformly at random among the words of weight @xmath293 and the @xmath297 s are independent .",
    "so we have @xmath299 under the hypothesis @xmath66 and @xmath300 is the bias defined in subsection [ bias ] for a weight @xmath293 .",
    "our aim now is to find a test distinguishing both hypotheses @xmath80 and @xmath81 . as in subsection [ bias ] it will be the neymann - pearson test .",
    "we define the following quantity where @xmath301 denotes the probability under the hypothesis @xmath66 : @xmath302    the lemma of neymann - pearson tells to us to proceed as follows : if @xmath303 , where @xmath304 is some threshold , choose @xmath80 and @xmath81 otherwise . in this case",
    ", no other statistic test will lead to lower false detection probabilities at the same time . in our case",
    ", it is enough to set the threshold @xmath304 to @xmath222 since it can be easily verified that no other choices will not change the exponent of the number of samples we need for having vanishing false detection probabilities .",
    "we set @xmath305 , @xmath306 and @xmath307 , we have : @xmath308    therefore by taking the natural logarithm of this expression and @xmath309 and @xmath310 , we have : @xmath311 + i_{1}(j )   \\left [ \\ln(p_{0}(j ) ) - \\ln(p_{1}(j ) ) \\right ] \\\\          & = \\sum_{j=1}^{n } ( m_{j } - i_{1}(j ) )   \\left [ \\ln(1-p_{0}(j ) ) - \\ln(1-p_{1}(j ) ) \\right ] + \\sum_{s=1}^{m_{j } } x_{s}^{j }    \\left [ \\ln(p_{0}(j ) ) - \\ln(p_{1}(j ) ) \\right ] \\\\          & = \\sum_{j=1}^{n } \\sum_{s=1}^{m_{j } } x_{s }   \\left [ \\ln(p_{0}(j ) ) - \\ln(1-p_{0}(j ) ) + \\ln(1-p_{1}(j ) ) - \\ln(p_{1}(j ) ) \\right ] \\\\          &",
    "\\qquad \\qquad + m_{j } \\ln \\frac{1-p_{0}(j)}{1-p_{1}(j ) }          \\end{aligned}\\ ] ]    we now use the taylor series expansion around @xmath222 : @xmath312 and we deduce for @xmath34 in @xmath313 : @xmath314 @xmath315    we have , @xmath316 where @xmath317 and @xmath220 is the constant defined by : @xmath318 this computation suggests to use the random variables @xmath319 to build our distinguisher with the neyman - pearson likelihood test . by the assumptions on the @xmath320 s , the @xmath319 s",
    "are independent and we have under @xmath66 : @xmath321    the expectation of @xmath319 under @xmath66 is given by : @xmath322    as for our previous distinguisher we define the random variable @xmath62 for @xmath323 uniform and independent draws of vectors @xmath298 in @xmath324 : @xmath325    the expectation of @xmath62 depends on which hypothesis @xmath66 holds .",
    "when hypothesis @xmath66 holds , we denote the expecation of @xmath326 by @xmath327 .",
    "the difference @xmath328 is given by : @xmath329    the deviations of @xmath86 around its expectation will be quantified through hoeffding s bound which gives in this case up to constant factors in the exponent the right behavior of the probability that @xmath86 deviates from its expectation    let @xmath73 independent random variables , @xmath330 and @xmath331 with @xmath332 such that : @xmath333    we set @xmath334 , then : @xmath335    in order to distinguish both hypotheses , we set @xmath336 .",
    "so under @xmath66 , we have    @xmath337    we decide that hypothesis @xmath81 holds if @xmath244 and that @xmath80 holds otherwise .",
    "it is clear that the probability @xmath338 to make a wrong decision with this distinguisher is smaller than @xmath339 .",
    "if we want @xmath340 for any fixed @xmath341 , @xmath342 have to be such that : @xmath343 note that this is really the right order ( up to some contant factor ) for the amount of equations which is needed ( the hoeffding bound captures well up to constant factors the probability of the error of the distinguisher in this case ) and using optimal bayesian decision does not allow to change up to multiplicative factors the number of equations that are needed for a fixed relative error weight .",
    "now assume that    [ ass : polyeqpar ] if we can compute @xmath63 parity - check equations of weight @xmath5 in time @xmath290 , we are able to compute @xmath344 parity - check equations of this weight in time @xmath345 .",
    "this assumption holds for all `` reasonable '' randomized algorithms producing random parity - checks with uniform / quasi uniform probability as long as @xmath344 is at most some constant fraction ( with a constant @xmath346 ) of the total number of parity - check equations .",
    "now we set @xmath347 such that :    @xmath348    clearly if we take now instead of the original @xmath63 parity - check equations just the @xmath349 parity check equations of weight @xmath350 the probability does of error does not get smaller than the bound @xmath351 that we had before since @xmath352    so , under assumption [ ass : polyeqpar ] if our distinguisher with several weights has enough parity - check equations available , we are able in polynomial time to compute @xmath353 parity - check equations of weight @xmath354 where @xmath347 is chosen such that ( [ eq : leadingweight ] ) holds and with these parity - check equations the distinguisher of subsection [ bias ] can work too .",
    "the complexity of statistical decoding without the phase of computation of the parity - check equations is the number of parity - check equations that it is needed .",
    "so , under assumption [ ass : polyeqpar ] , its complexity with our first distinguisher will be for each codelength @xmath1 the same up to a polynomial mutiplicative factor as the complexity with the second distinguisher .",
    "moreover , under assumption [ ass : polyeqpar ] the complexity of the computation of the parity - check equations that is needed for both distinguishers is the same up to a polynomial factor .",
    "as the @xmath355 are exponentially small in @xmath1 , in order to have a probability of success which tends to @xmath35 , the @xmath356 s of both distinguisher have to be of order @xmath357 .",
    "it leads to the conclusion that the asymptotic exponent of the statistical decoding is the same with considering some well chosen weight or several weights .",
    "we stress that this conclusion is about an asymptotic study of the complexity of statistical decoding . indeed , in practice algorithms [ alg : gauss ] and",
    "[ alg : fusion ] can output many parity - check equations of weight  close  to @xmath283 and @xmath358",
    ". it will be counter - productive not to keep them and use them with the distinguisher we just described .",
    "as we are now able to give a formula for @xmath113 we come back to the algorithm + ` paritycheckcomputation`@xmath95 in order to estimate @xmath114 .",
    "there is an easy way of producing parity - check equations of moderate weight by gaussian elimination .",
    "this is given in algorithm [ alg : gauss ] that provides a method for finding parity - check equations of weight @xmath359 of an @xmath360 $ ] random code .",
    "gaussian elimination ( ` gelim ` ) of an @xmath361 matrix @xmath362 consists in finding @xmath363 ( @xmath364 and non - singular ) such that : @xmath365    @xmath366 denotes the @xmath367th row of @xmath27 in algorithm [ alg : gauss ] .",
    "input : @xmath368 output : @xmath110 /*_@xmath369 parity - check equations_*/ @xmath370 @xmath371 random @xmath372 permutation matrix @xmath373 ` gelim`(@xmath374 ) and if it fails return to line 5 @xmath375 @xmath376 /*parity matrix of the code*/ @xmath377 @xmath30    algorithm [ alg : gauss ] is a randomized algorithm .",
    "randomness comes from the choice of the permutation @xmath13 .",
    "it is straightforward to check that this algorithm returns @xmath369 parity - check equations of weight @xmath283 in time @xmath378 .",
    "now we set @xmath261 .",
    "this relative weight , which corresponds to the gilbert - varshamov bound , is usually used to measure the efficiency of decoding algorithms .",
    "indeed it corresponds to the critical error weight below which we still have with probability @xmath249 a unique solution to the decoding problem .",
    "it can be viewed as the weight for which the decoding problem is the hardest , since the larger the weight the more difficult the decoding problem seems to be ( this holds at least for all known decoding algorithms of generic linear codes ) . as a consequence of propositions 2 and 4",
    ", we have the following theorem :    [ theobias ] [ naive statistical decoding s",
    "asymptotic complexity]@xmath71    with the computation of parity - check equations of weight @xmath283 thanks to + _ _ ` paritycheckcomputation`__@xmath379 , we have : @xmath380 where @xmath381 is given by theorem [ biassdecoding ] .",
    "exponents ( as a function of @xmath4 ) of prange s isd and statistical decoding are given in figure [ prstatdec ] .",
    "as we see the difference is huge .",
    "this version of statistical decoding can not be considered as an improvement over isds . however , as @xmath382 for @xmath213 fixed is an increasing function in @xmath205 , we have to study the case @xmath383 .",
    "it is the subject of the next section",
    ". we will give there an algorithm computing efficiently parity - check equations of smaller weight than @xmath283 .",
    "however we also prove there that no matter how efficiently we perform the pre - computation step , any version of statistical decoding is worse than prange s isd .",
    "before giving an improvement and giving lower bounds on the complexity of statistical decoding , we would like to come back to the computation problem of the @xmath110 s in the complexity of statistical decoding .",
    "our aim is to clarify the picture a little bit .",
    "we stress that statistical decoding complexity is , if the @xmath94 s are already computed and stored , ( up to a polynomial factor ) the number of equations we use to take our decision .",
    "we denote by @xmath384 the part of statistical decoding which uses these parity - check equations to perform the decoding and by @xmath385 the randomized algorithm used for outputting a certain number of random parity - check equations of weight @xmath5 . `",
    "paritycheckcomputation`@xmath95 is assumed to make a certain number of calls to @xmath385 .",
    "it is assumed that @xmath385 outputs @xmath386 parity - check equations of weight @xmath5 in time @xmath387 each time we run it .",
    "we assume that statistical decoding needs @xmath388 equations .",
    "if we consider the computations of parity - check equations as part of statistical decoding , its complexity is given by : @xmath389    when @xmath390 , we say @xmath391 gives equations in amortized time @xmath284 . with this condition",
    "if we assume @xmath392 , the complexity is the number of equations needed .    in any case ,",
    "complexity of statistical decoding is lower - bounded by @xmath388 and the lower the equation weight @xmath5 , the lower the number of equations @xmath10 we need for performing statistical decoding .",
    "the goal of this section is to show how to find many parity - check equations of weight @xmath393 in an efficient way and to give a minimal weight for which it makes sense to make this operation .",
    "as we just pointed out , statistical decoding needs @xmath394 parity - check equations of weight @xmath5 to work .",
    "its complexity is therefore always greater than @xmath395 .",
    "we assume again the code we want to decode to be a random code .",
    "this assumption is standard in the cryptographic context .",
    "the expected number of parity - check equations of weight @xmath5 in an @xmath360 $ ] random binary linear code is @xmath396 .",
    "obviously if @xmath5 is too small there are not enough equations for statistical decoding to work , we namely need that @xmath397 the minimum @xmath398 such that this holds is clearly given by the minimal @xmath205 such that the following expression holds @xmath399    so @xmath398 gives the minimal relative weight such that asymptotically the number of parity - check equations needed for decoding is exactly the number of parity - check equations of weight @xmath400 in the code , where @xmath401 . below this weight",
    ", statistical decoding can not work ( at least not for random linear codes ) .",
    "in other words the asymptotic exponent of statistical decoding is always lower - bounded by @xmath402 .",
    "in the case of a relative error weight given by the gilbert - varshamov bound @xmath403 , theorem [ theobias ] leads to the conclusion that @xmath404    moreover for all relative weights greater than @xmath405 the number of parity - check equations that are needed is exactly the number of parity - check equations of this weight that exist in a random code .",
    "this result is rather intriguing and does not seem to have a simple interpretation .",
    "the relative minimal weight @xmath406 is in relationship with the first linear programming bound of mceliece - rodemich - rumsey - welch and can be interpreted through its relationship with the zeros of krawtchouk polynomials .",
    "this bound arises from the fact that from theorem [ theobias ] , we know that @xmath405 corresponds to the relative weight where we switch from the complex case to the real case , and this happens precisely when we leave the region of zeros of the krawtchouk polynomials .",
    "thanks to figure [ fig : limita ] which compares prange s isd , statistical decoding with parity - check equations of relative weight @xmath407 and @xmath398 with @xmath261 , we clearly see on the one hand that there is some room of improving upon naive statistical decoding based on parity - check equations of weight @xmath283 , but on the other hand that even with the best improvement upon statistical decoding we might hope for , we will still be above the most naive information set decoding algorithm , namely prange s algorithm .      the goal of this subsection is to present an improvement to the computation of parity - check equations and to give its asymptotic complexity .",
    "r. overbeck in ( * ? ? ?",
    "4 ) showed how to compute parity - check equations thanks to stern s algorithm .",
    "we are going to use this algorithm too .",
    "however , whereas overbeck used many iterations of this algorithm to produce a few parity - check equations of small weight , we observe that this algorithm produces in a natural way during its execution a large number of parity - check equations of relative weight smaller than @xmath407 . we will analyze this process here and show that it yields an algorithm @xmath391 that gives equations in amortized time @xmath284 .    to find parity - check equations , we described an algorithm which just performs gaussian elimination and selection of sufficiently sparse rows .",
    "in fact , it is the main idea of prange s algorithm .",
    "as we stressed in introduction , this algorithm has been improved rather significantly over the years ( isd family ) .",
    "our idea to improve the search for parity - check equations is to use precisely these improvements .",
    "the first significant improvement is due to stern and dumer @xcite .",
    "the main idea is to solve a sub - problem with the birthday paradox .",
    "we are going to describe this process and show how it allows to improve upon naive statistical decoding .",
    "we begin by choosing a random permutation matrix @xmath408 and putting the matrix @xmath374 into the systematic form :    @xmath409    \\1 .",
    "we solve csd(@xmath410 ) .",
    "\\2 . for each solution",
    "@xmath104 , we output @xmath411 .",
    "we recall that solving csd(@xmath410 ) means to find @xmath199 columns of @xmath412 which yield @xmath222 .",
    "@xmath40 * soundness : * we have @xmath413 and therefore @xmath104 is a parity - check equation of @xmath414 .",
    "@xmath40 * number of solutions : * the number of solutions is given by the number of solutions of 1 .",
    "furthermore , the complexity of this algorithm is up to a polynomial factor given by the complexity of 1 .",
    "this algorithm may not provide in one step enough solutions . in this case",
    ", we have to put @xmath27 in another systematic form ( _ i.e. _ choose another permutation ) .",
    "the randomness of our algorithm will come from this choice of permutation matrix .",
    "@xmath40 * solutions weight : * in our model @xmath27 is supposed to be random .",
    "so we can assume the same hypothesis for @xmath412 .",
    "as the length of its rows is @xmath415 , we get asymptotically parity - check equations of weight : @xmath416    the first part of this algorithm can be viewed as the first part of isd algorithms .",
    "there is a general presentation of these algorithms in @xcite in section 3 .",
    "all the efforts that have been spent to improve prange s isd can be applied to solve the first point of our algorithm . to solve this point ,",
    "dumer suggested to put @xmath412 in the following form : @xmath417 and to build the lists : @xmath418 @xmath419    then we intersect these two lists with respect to the second coordinate and we keep the associated first coordinate . in other words , we get : @xmath420    this process is called a fusion .    algorithm [ alg : fusion ] summarizes this formally .",
    "input : @xmath421 .",
    "output : @xmath30 /*_subset of @xmath422_*/ @xmath423 /*_empty list_*/ @xmath424 / * _ hash table_*/ @xmath371 random @xmath372 permutation matrix we find @xmath425 non - singular such that @xmath426 we partition @xmath412 as @xmath427 where @xmath428 @xmath429 @xmath430 @xmath431 @xmath432 @xmath433    as we neglect polynomial factors , the complexity of algorithm 3 . is given by : @xmath434    indeed , we only have to enumerate the hash table construction ( first factor ) and the construction of @xmath30 . in order to estimate @xmath435 we use the following classical proposition :",
    "let @xmath436 be two lists where inputs are supposed to be random and distributed uniformly .",
    "then , the expectation of the cardinality of their intersection is given by : @xmath437    as we supposed @xmath412 random , we can apply this proposition to ` dumerfusion ` .",
    "therefore ,    @xmath71    _ ` dumerfusion ` _ s complexity is given by : @xmath438 and it provides on average @xmath439 solutions    in order to study this algorithm asymptotically , we introduce the following notations and relative parameters :    @xmath71    @xmath40 @xmath440 ;    @xmath40 @xmath441 ;    @xmath40 @xmath442 ;    @xmath40 @xmath443 .",
    "we may observe that @xmath444 gives the number of parity - check equations that ` dumerfusion ` outputs in one iteration and @xmath445 is the running time of one iteration .",
    "there are many ways of choosing @xmath199 and @xmath446 .",
    "however in any case ( see subsection [ lim ] ) , as the weight of parity - check equations we get with ` dumerfusion ` is @xmath447 we have to choose @xmath199 and @xmath446 such that @xmath448 which is equivalent to @xmath449    the following lemma gives an asymptotic choice of @xmath450 and @xmath451 that allows to get parity - check equations in amortized time @xmath284 :    if @xmath452 _ ` dumerfusion ` _ provides parity - check equations of relative weight @xmath453 in amortized time @xmath284 .",
    "moreover , with this constraint we have asymptotically : @xmath454    we remark that @xmath455 .",
    "our goal is to find @xmath456 such that asymptotically @xmath457 .",
    "the constraint follows from @xmath458 .",
    "we are now able to give the asymptotic complexity of statistical decoding with the use of ` dumerfusion ` strategy .    with the constraints ( [ asym ] ) , ( [ amtime ] ) and @xmath459 for @xmath460 we have : @xmath461",
    "thanks to ( [ amtime ] ) and ( [ oneite ] ) we use subsection [ fram ] and we conclude that under theses constraints we have @xmath462 .",
    "we summarize the meaning of the constraints as :    * with ( [ asym ] ) we are sure there exists enough parity - check equations for statistical decoding to work ; * with ( [ amtime ] ) ` dumerfusion ` gives parity - check equations in amortized time @xmath284 ; * with ( [ oneite ] ) ` dumerfusion ` provides always no more equations in one iteration than we need .",
    "in order to get the optimal statistical decoding complexity we minimize @xmath463 ( with @xmath463 given by theorem [ biassdecoding ] ) under constraints , and .",
    "the exponent of statistical decoding with this strategy is given in figure [ fig : limit ] .",
    "as we see , ` dumerfusion ` with our strategy allows statistical decoding to be optimal for rates close to @xmath222 .",
    "we can further improve ` dumerfusion ` with ideas of @xcite and @xcite , however this comes at the expense of having a much more involved analysis and would not allow to go beyond the barrier of the lower bound on the complexity of statistical decoding given in the previous subsection .",
    "nevertheless with the same strategy , these improvements lead to better rates with an optimal work of statistical decoding .",
    "in this article we have revisited statistical decoding with a rigorous study of its asymptotic complexity . we have shown that under assumption 1 and 2 this algorithm is regardless of any strategy we choose for producing the moderate weight parity - check equations needed by this algorithm always worse than prange isd for the hardest instance of decoding ( i.e. for a number of errors equal to gilbert varshamov bound ) . in this case",
    "a very intriguing phenomenon happens , we namely need for a large range of parity - check weights all the parity - check available in the code to be be able to decode with this technique .",
    "it seems very hard to come up with choices of rate , error weight and length for which statistical decoding might be able to compete with isd even if this can not be totally ruled out by the study we have made here .",
    "however there are clearly more sophisticated techniques which could be used to improve upon statistical decoding .",
    "for instance using other strategies by grouping positions together and using all parity - check equations involving bits in this group could be another possible interesting generalization of statistical decoding .",
    "anja becker , antoine joux , alexander may , and alexander meurer . decoding random binary linear codes in @xmath464 : how @xmath465 improves information set decoding . in _ advances in cryptology - eurocrypt  2012",
    "_ , lecture notes in comput .",
    "springer , 2012 .",
    "rodolfo canto - torres and nicolas sendrier .",
    "analysis of information set decoding for a sub - linear error weight . in _ post - quantum cryptography  2016",
    "_ , lecture notes in comput .",
    ", pages 144161 , fukuoka , japan , february 2016 .",
    "marc p.  c. fossorier , kazukuni kobara , and hideki imai .",
    "modeling bit flipping decoding based on nonorthogonal check sums with application to iterative decoding attack of mceliece cryptosystem .",
    ", 53(1):402411 , 2007 .",
    "matthieu finiasz and nicolas sendrier .",
    "security bounds for the design of code - based cryptosystems . in m.",
    "matsui , editor , _ advances in cryptology - asiacrypt  2009 _ , volume 5912 of _ lecture notes in comput .",
    "_ , pages 88105 .",
    "springer , 2009 .",
    "abdulrahman  al jabri . a statistical decoding algorithm for general linear block codes . in bahram",
    "honary , editor , _ cryptography and coding .",
    "proceedings of the 8^th^ i m a international conference _ , volume 2260 of _ lecture notes in comput .",
    "_ , pages 18 , cirencester , uk , december 2001 .",
    "springer .",
    "alexander may , alexander meurer , and enrico thomae . decoding random linear codes in @xmath466 . in dong",
    "hoon lee and xiaoyun wang , editors , _ advances in cryptology - asiacrypt  2011 _ , volume 7073 of _ lecture notes in comput .",
    "_ , pages 107124 .",
    "springer , 2011 .",
    "alexander may and ilya ozerov . on computing nearest neighbors with applications to decoding of binary linear codes .",
    "in e.  oswald and m.  fischlin , editors , _ advances in cryptology - eurocrypt  2015 _ , volume 9056 of _ lecture notes in comput .",
    "_ , pages 203228 .",
    "springer , 2015 .",
    "rafael misoczki , jean - pierre tillich , nicolas sendrier , and paulo s. l.  m. barreto . : new mceliece variants from moderate density parity - check codes . in _ proc .",
    "symposium inf .",
    "theory - isit _ , pages 20692073 , 2013 .",
    "raphael overbeck .",
    "statistical decoding revisited . in reihaneh",
    "safavi - naini lynn  batten , editor , _ information security and privacy : 11^th^ australasian conference , acisp 2006 _ , volume 4058 of _ lecture notes in comput .",
    "_ , pages 283294 .",
    "springer , 2006 .",
    "jacques stern . a method for finding codewords of small weight . in g.",
    "d. cohen and j.  wolfmann , editors , _ coding theory and applications _ , volume 388 of _ lecture notes in comput .",
    "_ , pages 106113 .",
    "springer , 1988 ."
  ],
  "abstract_text": [
    "<S> the security of code - based cryptography relies primarily on the hardness of generic decoding with linear codes . </S>",
    "<S> the best generic decoding algorithms are all improvements of an old algorithm due to prange : they are known under the name of information set decoding techniques ( isd ) . </S>",
    "<S> a while ago a generic decoding algorithm which does not belong to this family was proposed : statistical decoding . </S>",
    "<S> it is a randomized algorithm that requires the computation of a large set of parity - check equations of moderate weight . </S>",
    "<S> we solve here several open problems related to this decoding algorithm . </S>",
    "<S> we give in particular the asymptotic complexity of this algorithm , give a rather efficient way of computing the parity - check equations needed for it inspired by isd techniques and give a lower bound on its complexity showing that when it comes to decoding on the gilbert - varshamov bound it can never be better than prange s algorithm . </S>"
  ]
}