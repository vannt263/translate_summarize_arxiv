{
  "article_text": [
    "for a number of random constraint satisfaction problems ( csp ) , by now very good estimates are available for the largest constraint density ( ratio of constraints to variables ) for which typical problems have solutions .",
    "for example  @xcite , a random graph of average degree @xmath0 is with high probability   occurs with high probability ( w.h.p . ) if @xmath1 = 1 $ ] . ]",
    "@xmath2-colorable if @xmath3 , but w.h.p .",
    "non-@xmath2-colorable if @xmath4 .",
    "this implies that for every @xmath5 , w.h.p .",
    "the chromatic number of a random graph with average degree @xmath0 is either @xmath6 or @xmath7 , where @xmath6 is the smallest integer @xmath2 such that @xmath8 .",
    "algorithmically , it is very easy to get a factor-2 approximation for the graph coloring problem on random graphs . the algorithm   repeatedly pick a random vertex and assign it a random available color \" will w.h.p .",
    "succeed in coloring a random graph of average degree @xmath0 if originally each vertex has @xmath9 available colors .",
    "alternatively , @xmath2 colors suffice when @xmath10 . in spite of significant efforts over the last 30 years",
    ", no improvement has been made over this trivial algorithm .",
    "specifically , no polynomial - time algorithm is known that @xmath2-colors random graphs of average degree @xmath11 , for some fixed @xmath12 and arbitrarily large @xmath2 .    in the random @xmath2-sat problem one",
    "asks if a random @xmath2-cnf formula , @xmath13 , with @xmath14 variables and @xmath15 clauses is satisfiable .",
    "it is widely believed that the probability that such a formula is satisfiable exhibits a sharp threshold .",
    "specifically , the _ satisfiability threshold conjecture _ asserts that @xmath16 for all @xmath17 , where @xmath18    it is easy to see that @xmath19 , since the probability that at least one assignment satisfies @xmath20 is bounded by @xmath21 , a quantity that tends to 0 for @xmath22 .",
    "recently , it was shown that random @xmath2-cnf formulas have satisfying assignments for densities very close to this upper bound  @xcite .",
    "specifically , it was proven that for all @xmath17 , @xmath23 as for the @xmath2-coloring problem , the lower bound on the largest density for which solutions exist w.h.p .",
    "is non - constructive , based on the second moment method . here",
    ", the gap relative to algorithms is ever greater : no polynomial algorithm is known that finds satisfying assignments in a random @xmath2-cnf formula when @xmath24 , for any function @xmath25 ( arbitrarily slowly ) . in table  [ tab : val ] , we illustrate this gap for some small values of @xmath2 . for @xmath26 ,",
    "the upper bound on @xmath27 comes from @xcite , while for @xmath28 from  @xcite .",
    "the best algorithmic lower bound for @xmath26 is from  @xcite , while for @xmath28 it is from @xcite .",
    "[ tab : val ] @xmath29    similar results ( and gaps ) exist for a number of other constraint satisfaction problems , such as random and hypergraph 2-coloring , regular random graph coloring , random max @xmath2-sat , and others ( for example , see  @xcite ) .",
    "indeed , this phenomenon seems to occur in nearly all random csp in which the underlying constraint graph is sparse and random , making it natural to ask if there is a common underlying cause .",
    "( the bipartite graphs where constraints are adjacent to the variables they bind are also known as factor graphs . )    as it turns out , sparse random csp have been systematically studied by physicists in the past few decades under the name ",
    "mean - field diluted spin - glasses \" .",
    "spins here are the variables ( reflecting the notion that variables have small , discrete domains ) , the term glass refers to the fact that the system has not been allowed to relax to a configuration in which spins interact in a mutually agreeable way ( reflecting that different constraints prefer different values for the variables ) , diluted refers to the fact that the factor graph is sparse ( reflecting that each spin interacts with only a few other spins ) , while ",
    "mean field \" refers to the fact that the factor graph is random , i.e. ,  there is no underlying geometry mandating the interactions .",
    "the interest in such `` unphysical '' systems is partly motivated by the fact that in many statistical mechanics problems where the variables do lie on a lattice such as @xmath30 , the effect of the underlying geometry vanishes for @xmath0 sufficiently large ( but finite ) .",
    "perhaps more surprising is the fact that in the last few years , motivated by ideas developed for the study of materials , physicists have put forward a hypothesis for the origin of the aforementioned algorithmic gap in random csp and , most remarkably , a method for overcoming it . specifically , mzard , parisi , and zecchina  @xcite developed an extremely efficient algorithm , called survey propagation ( sp ) , for finding satisfying assignments of random formulas in the satisfiable regime .",
    "for example , their algorithm typically finds a satisfying truth assignment of a random 3-cnf formula with @xmath31 variables and @xmath32 clauses in minutes ( and appears to scale as @xmath33 ) .",
    "no other algorithm practically solves formulas of such density with @xmath34 .",
    "our original motivation for this work was to see if some of the physically - motivated ideas underlying sp can be proven mathematically .",
    "more generally , we believe that understanding the geometry of the space of satisfying truth assignments in random formulas is essential for understanding the behavior of algorithms on them . this is particularly true for the case of random - walk type algorithms , which we view as the first natural class to target armed with such an understanding and",
    "for which very little is known rigorously , with the notable exception of  @xcite .",
    "we make significant progress towards this goal by proving that already much below the satisfiability threshold , the set of satisfying assignments fragments into exponentially many connected components .",
    "these components are relatively small in size , far apart from one another , and inside each one the majority of variables are  frozen \" , i.e. ,  take only one value . as the formula density is increased towards the threshold , the fraction of frozen variables in each component increases , causing the connected components to decrease in volume and grow further apart from one another .",
    "our results are in perfect agreement with the picture put forward by the physicists .",
    "moreover , as we discuss below , the existence of frozen variables provides a good explanation for the origin of the barrier faced by all analyzed algorithms on random csp , i.e. ,   local \" , dpll - type algorithms .",
    "finally , we show that one of the two main assumptions underlying sp regarding the structure of the set of solutions is essentially correct .",
    "this brings us closer to a rigorous analysis of sp and answers affirmatively the main open question raised by maneva , mossel and wainwright in  @xcite .",
    "specifically , we prove that for all @xmath35 , the connected components of the set of satisfying assignments of random formulas have non - trivial cores , as assumed by sp ( see definition  [ core_def ] ) .",
    "we point out that it is not clear whether this is true for small @xmath2 .",
    "indeed , @xcite gave experimental evidence that for @xmath26 , random formulas do _ not _ have non - trivial cores .",
    "as we will see , our methods also give some evidence in that direction .",
    "this gives additional motivation for the  core - like \" objects introduced in  @xcite whose existence would relate to the success of sp for small @xmath2 ( we discuss this point further in section  [ sec : sp_related ] ) .    in the next section",
    "we give an informal discussion relating the performance of dpll - type algorithms on random formulas to notions such as gibbs sampling and long - range correlations .",
    "this is meant to provide intuition for the empirical success of sp and motivate our results .",
    "we emphasize that while both the discussion and the results are about random , this is not strictly necessary : our ideas and proofs are quite generic , and should generalize readily to many other random csp , e.g. ,  graph coloring .      given a satisfiable formula @xmath36 on variables @xmath37 it is easy to see that the following simple procedure samples uniformly from the set of all satisfying assignments of @xmath36 :    * start with the input formula @xmath36 * for @xmath38 to @xmath14 do : 1 .   compute the fraction , @xmath39 , of satisfying assignments of the current formula in which @xmath40 takes the value 1 . 2 .",
    "set @xmath40 to 1 with probability @xmath39 and to 0 otherwise .",
    "3 .   simplify the formula .",
    "clearly , the first step in the loop above is meant only as a thought experiment .",
    "nevertheless , it is worth making the following two observations .",
    "the first is that if we are only interested in finding _ some _ satisfying assignment , as opposed to sampling a uniformly random one , then we do not need to compute exact marginals .",
    "for example , if we use the rule of always setting @xmath40 to 1 iff @xmath41 , then it is enough to ensure that if a variable takes the same value @xmath42 in _ all _ satisfying assignments , @xmath42 is the majority value in its computed marginal .",
    "the second observation is that the order in which we set the variables does not need to be determined a priori .",
    "that is , we can imagine that in each step we compute marginals for all remaining variables and that for each marginal we have an associated confidence . to improve our chances of avoiding a fatal error , we can then set only the variable for which we have highest confidence .",
    "the above two elementary observations in fact capture all algorithms that have been analyzed so far on random formulas ( and , in fact , most dpll - type algorithms used in practice ) .",
    "observe , for example , that both the _ unit - clause _ and the _ pure literal _ heuristics follow immediately from the above considerations . in the case of unit - clause ,",
    "the participation of a variable @xmath43 in a unit clause @xmath44 allows us to infer its marginal with perfect confidence and thus setting @xmath43 is an  obvious \" choice . in the case of a pure literal @xmath45 ,",
    "again we can infer with certainty the majority marginal of the underlying variable @xmath43 ( it is the value that satisfies @xmath45 ) . in the absence of such obvious choices , all dpll - type algorithms attempt to identify a variable whose marginal can be determined with some confidence .",
    "for example , below are the choices made in the absence of unit clauses and pure literals by some of the algorithms that have been analyzed on random 3-cnf formulas . in order of increasing performance :    * unit - clause  @xcite : select a random variable and assign it a random value .",
    "* 3-clause majority  @xcite : select a random variable and assign it its majority value among the 3-clauses . * short - clause@xcite : select a random shortest clause @xmath44 , a random variable @xmath43 in @xmath44 , and set @xmath43 so as to satisfy @xmath44 .",
    "* happiest literal  @xcite : satisfy a literal that appears in most clauses .",
    "each of the above heuristics attempts to compute marginals based on a different set of evidence , the content of which ranges from completely empty  @xcite , to considering all the clauses containing each variable  @xcite . correspondingly , the largest density for which these algorithms succeed on random 3-cnf formulas ranges from @xmath46 for  @xcite to 3.42 for  @xcite .",
    "unit - clause , in fact , succeeds for every @xmath2 as long as @xmath47 and , as we mentioned earlier , no algorithm is known to beat this bound asymptotically . given that improving upon the empty set of evidence is rather easy , it is tempting to think that by considering a larger set of evidence for each variable one can do significantly better .",
    "for example , consider an algorithm @xmath48 which computes a marginal for each variable @xmath43 based on the clauses that appear in the depth-@xmath0 neighborhood of @xmath43 in the factor graph .",
    "one could hope that as @xmath0 grows , such an algorithm would do well , perhaps even reach the satisfiability threshold .",
    "physicists say it is not so .",
    "the hope that local algorithms could do well on random formulas rests on the presumption that the influence exerted on a variable @xmath43 by other variables , diminishes rapidly with their distance from @xmath43 in the factor graph .",
    "that is , that there are no  long range correlations \" in random formulas , so that the joint probability distribution of a random finite subset of the variables should be , essentially , the product of their marginals .",
    "unfortunately , the existence of connected components of satisfying assignments ( clusters ) with numerous frozen variables can induce long - range correlations among the variables , eliminating such hopes .",
    "for example , if one considers any fixed set of variables , at sufficiently large densities their joint behavior over the set of satisfying assignments is dominated by a small number of connected components : those in which most of them are frozen , freeing up other variables to take multiple values and amplify the contribution of that particular joint collection of values to the variable marginals . in other words , assuming that the variables in the boundary of a variable s neighborhood behave independently with respect to the rest of the formula , can be very far off from the truth .    to overcome the above issue",
    ", physicists hypothesized that the above clustering is the only significant source of long - range correlations .",
    "( very ) roughly speaking , this amounts to modeling each connected component of satisfying assignments as a subcube that results by selecting a large fraction of the variables and freezing them independently at random , while leaving the rest ( largely ) free .",
    "our results imply that this simplified view of clusters is not very far off the truth .      in the next section",
    "we give mathematical statements of our main results , regarding the existence of exponentially many well - separated clusters and the existence of frozen variables in every cluster . in section  [ sec : clustering ]",
    "we outline the proof of the results on the existence of clusters and explain their relationship to the work of mora , mzard , and zecchina  @xcite . in section  [ sec : frozeness ] we provide some background on survey propagation and explain how our results on frozen variables relate to the implicit hypothesis made by mzard , parisi , and zecchina in their derivation of survey propagation  @xcite , and how our results answer the main open question of maneva , mossel and wainwright  @xcite . in section  [ sec : setup ]",
    "we introduce the probabilistic setup for our analysis and in section  [ sec : plantedmodel ] we discuss how it relates to the case @xmath49 and to the  planted assignment \" model .",
    "proving our main result on the existence of frozen variables boils down to a question in large deviations developed in section  [ sec : ana ] and an associated multi - dimensional optimization problem , resolved in section  [ sec : opt ] .",
    "we first need to introduce some definitions . throughout",
    ", we assume that we are dealing with a cnf formula @xmath36 , defined over variables @xmath50 , and we let @xmath51 denote the satisfying assignments of @xmath36 .",
    "[ def : clus ] the * diameter * of an arbitrary set @xmath52 is the largest hamming distance between any two elements of @xmath53 . the * distance * between two arbitrary sets @xmath54 , is the minimum hamming distance between any @xmath55 and any @xmath56 .",
    "the * clusters * of a formula @xmath36 are the connected components of @xmath57 when @xmath58 are considered adjacent if they have hamming distance 1 .",
    "a * cluster - region * is a non - empty set of clusters .",
    "our first set of results is captured by theorems  [ basic ] and [ sharp_basic ] below , which build upon the work in  @xcite .",
    "we discuss the relationship between our results and those in  @xcite in section  [ sec : related ] .",
    "[ basic ] for every @xmath59 , there exists a value of @xmath60 and constants @xmath61 and @xmath62 such that w.h.p .",
    "the set of satisfying assignments of @xmath63 consists of @xmath64 non  empty cluster - regions , such that    1 .",
    "the diameter of each cluster - region is at most @xmath65 .",
    "the distance between every pair of cluster - regions is at least @xmath66 .    in other words , for all @xmath59 , at some point below the satisfiability threshold , the set of satisfying assignments consists of exponentially many , well - separated cluster - regions .",
    "the picture suggested by theorem  [ basic ] comes in sharper focus for large @xmath2 .",
    "in particular , for sufficiently large @xmath2 , sufficiently close to the threshold , the cluster regions become arbitrarily small and maximally far apart ( while remaining exponentially many ) .",
    "the following result gives a quantitative version of this fact .",
    "[ sharp_basic ] for any @xmath67 , if @xmath68 , then for all @xmath69 , theorem  [ basic ] holds with @xmath70    it is worth noting that , as we will show shortly ,    theorems  [ basic ] and  [ sharp_basic ] remain valid for any definition of clusters in which a pair of assignments are deemed adjacent whenever their distance is at most @xmath71 for some function @xmath72 .",
    "our main result in this paper comes from  looking inside \" clusters and proving the existence of variables which take the same value in all the truth assignments of a cluster .",
    "more formally ,    the * projection * of a variable @xmath73 over a set of satisfying assignments @xmath74 , denoted as @xmath75 , is the union of the values taken by @xmath73 over the assignments in @xmath74 .",
    "if @xmath76 we say that @xmath73 is * frozen * in @xmath74 .",
    "no previous results were known about the existence of frozen variables .",
    "the existence of such variables is a fundamental underpinning of the approximations implicit in the survey propagation algorithm . to prove that random formulas have frozen variables we , in fact , prove that random formulas have non - trivial cores for all @xmath77 , thus also answering the main question of  @xcite ( we postpone the definition of cores until section  [ sec : frozeness ] ) .",
    "a strength of our approach is that it allows us to prove not just the existence , but the pervasiveness of frozen variables .",
    "specifically , theorem  [ gen_c ] below asserts that for sufficiently large @xmath2 , as we approach the satisfiability threshold , the fraction of frozen variables in every single cluster gets arbitrarily close to 1 .",
    "[ gen_c ] for every @xmath78 and all @xmath79 , there exists @xmath80 , such that for all @xmath81 , w.h.p .",
    "cluster of @xmath20 has at least @xmath82 frozen variables .",
    "as @xmath2 grows , @xmath83    by taking @xmath84 in theorem  [ gen_c ] we see that for sufficiently large @xmath2 , every cluster already has a majority of frozen variables at @xmath85 , with @xmath86 , i.e. ,  for a constant fraction of the satisfiable regime .",
    "more generally , theorem  [ gen_c ] asserts that as @xmath2 grows and the density approaches the threshold , clusters shrink in volume and grow further apart by having smaller and smaller internal entropy ( more frozen variables ) .",
    "the analysis that establishes theorem  [ gen_c ] also allows us to show    [ c_9 ] for every @xmath35 , there exists @xmath87 such that w.h.p .  * every * cluster of @xmath20 has frozen variables .    it remains open whether frozen variables exist for @xmath88 . as we mentioned above , @xcite reported experimental evidence suggesting that frozen variables do _ not _ exist for @xmath26 .",
    "we will see that our proof also gives evidence in this direction for small values of @xmath2 .",
    "there are two main ingredients for proving theorems  [ basic ] and  [ sharp_basic ] .",
    "the first one excludes the possibility of pairs of truth assignments at certain hamming distances .",
    "it is easy to show , see e.g. ,  @xcite , that the expected number of pairs of satisfying assignments in @xmath63 with hamming distance @xmath89 is at most @xmath90 , where @xmath91 therefore , if for some @xmath92 and @xmath93 we have @xmath94 , it immediately follows by the union bound that w.h.p .  in @xmath20",
    "no pair of satisfying assignments has distance @xmath89 .",
    "this observation was first made and used in  @xcite . in figure  [ ploo ]",
    "we draw the function @xmath95 ( upper curve ) , and a related function @xmath96 ( lower curve , to be discussed shortly ) , for @xmath97 $ ] with @xmath98 and @xmath99 .",
    "recall that , by the results in  @xcite , @xmath100 is w.h.p .",
    "satisfiable and , thus , excluding the possibility of satisfying pairs at certain distances is a non - vacuous statement .",
    "we see that @xmath101 for @xmath102 \\cup [ 0.68,1]$ ] , implying that w.h.p .  in @xmath100",
    "there is no pair of satisfying assignments with hamming distance @xmath103 for such values of @xmath104 .     and lower curve @xmath105 for @xmath97$].,scaledwidth=50.0% ]    establishing that there exists a distance @xmath89 such that there are no pairs of assignments at distance @xmath89 immediately implies an upper bound on the diameter of every cluster .",
    "this is because if a cluster @xmath74 has diameter @xmath0 , then it must contain pairs of solutions at every distance @xmath106 . to see this ,",
    "take any pair @xmath107 that have distance @xmath0 , any path from @xmath108 to @xmath109 in @xmath74 , and observe that the sequence of distances from @xmath108 along the vertices of the path must contain every integer in @xmath110 .",
    "therefore , if @xmath111 , then w.h.p .",
    "every cluster in @xmath20 has diameter at most @xmath112 .",
    "if we can further prove that @xmath113 in an interval @xmath114 , then we can immediately partition the set of satisfying assignments into well - separated regions , as follows .",
    "start with any satisfying assignment @xmath115 , let @xmath74 be its cluster , and consider the set @xmath116 of truth assignments that have distance at most @xmath117 from @xmath74 and the set @xmath118 of truth assignments that have distance at most @xmath119 from @xmath120 .",
    "observe now that the set @xmath121 can not contain any satisfying truth assignments , as any such assignment would be at distance @xmath122 from some assignment in @xmath74 .",
    "thus , the set of satisfying assignments in @xmath120 is a union of clusters ( cluster - region ) , all of which have distance at least @xmath119 from any cluster not in the region .",
    "repeating this process until all satisfying assignments have been assigned to a cluster region gives us exactly the subsets of theorems  [ basic ] and  [ sharp_basic ] .",
    "moreover , note that this arguments bounds the diameter of each entire cluster - region , not only of each cluster , by @xmath117 .",
    "the arguments above remains valid even if assignments are deemed adjacent whenever their distance is bounded by @xmath71 , for any @xmath72 . as a result , theorems  [ basic ] and  [ sharp_basic ] remain valid as stated for any definition of clusters in which assignments are deemed to belong in the same cluster if their distance is @xmath123 .      proving the existence of exponentially many non - empty cluster regions requires greater sophistication and leverages in a strong way the results of  @xcite .",
    "this is because having @xmath124 for some @xmath125 does _ not _ imply that pairs of satisfying assignments exist for such @xmath125 : in principle , the behavior of @xmath95 could be determined by a tiny minority of solution - rich formulas .",
    "hence the need for the second moment method  @xcite .",
    "specifically , say that a satisfying assignment is _ balanced _ if its number of satisfied literal occurrences is in the range @xmath126 , and let @xmath53 be the number of balanced assignments in @xmath20 . in  @xcite , it was shown that @xmath127 ^ 2 = \\lambda_b(1/2,k , r)^n$ ] and @xmath128 < c\\times \\max_{\\alpha \\in [ 0,1]}\\lambda_b(\\alpha , k , r)^n \\enspace , \\ ] ] for some explicit function @xmath129 and constant @xmath130 .",
    "it was also shown that for all @xmath131 , the maximum of @xmath129 occurs at @xmath84 , implying that for such @xmath92 we have @xmath132 < c\\times { \\mathbb{e}}[x]^2 $ ] . by the payley - zigmund inequality",
    ", this last fact implies that for any @xmath133 $ ] , @xmath134 \\geq \\frac{({\\mathbb{e}}[x]-t)^2}{{\\mathbb{e}}[x^2 ] } \\enspace .\\ ] ]    in  @xcite , inequality   was applied with @xmath135 , per the  second moment method \" , establishing that for @xmath131 , @xmath20 has at least one ( balanced ) satisfying assignment with probability at least @xmath136 . taking @xmath137/{\\mathrm{poly}}(n)$ ]",
    ", implies that @xmath53 is within a polynomial factor of its expectation @xmath138 , also with constant probability . since the property ",
    "has more than @xmath139 satisfying assignments \" has a sharp threshold  @xcite , this assertion implies that for every @xmath140 , @xmath20 has at least @xmath141 satisfying assignments w.h.p .    to prove that there are exponentially many clusters , we divide the above lower bound for the total number of satisfying assignments with the following upper bound for the number of truth assignments in each cluster - region . recall that @xmath142 and let @xmath143 } \\lambda(\\alpha , k , r ) \\enspace .\\ ] ]    if @xmath144 is the expected number of pairs of truth assignments with distance at most @xmath112 in @xmath20 , it follows that @xmath145 , since the expected number of pairs at each distance is at most @xmath146 and there are no more than @xmath147 possible distances . by markov s inequality",
    ", this implies that w.h.p .",
    "the number of pairs of truth assignments in @xmath20 that have distance at most @xmath112 is @xmath148 .",
    "recall now that w.h.p .",
    "every cluster - region in @xmath20 has diameter at most @xmath112 .",
    "therefore , w.h.p .",
    "the total number of pairs of truth assignments in each cluster - region is at most @xmath149 .",
    "thus , if @xmath150 , we can conclude that @xmath20 has at least @xmath151 cluster - regions .",
    "indeed , the higher of the two horizontal lines in figure  [ ploo ] highlights that @xmath152 .    from the discussions in this section we see that to establish theorem",
    "[ basic ] it suffices to prove the following .",
    "[ thm : est ] for every @xmath59 , there exists a value of @xmath60 and constants @xmath61 and @xmath62 such that @xmath94 for all @xmath153 and @xmath154 > \\epsilon_k \\enspace .\\ ] ] in particular , for any @xmath67 and all @xmath155 , if @xmath68 , we can take @xmath156    specifically , in section  [ sec : ab ] we will prove the claims in theorem  [ thm : est ] regarding @xmath157 , while in section  [ sec : e ] we prove the claims regarding @xmath158 .      the observation that if @xmath94 then w.h.p .",
    "@xmath20 has no pairs of satisfying assignments at distance @xmath103 was first made and used in  @xcite .",
    "moreover , in  @xcite the authors gave an expression @xmath159 for the expected number of _ locally maximal _ pairs of satisfying assignments at each distance , where a pair @xmath160 is locally maximal if there is no variable which has value 0 in @xmath115 and flipping its value in both @xmath115 and @xmath161 yields a new pair of satisfying assignments .",
    "( if a formula has a pair of satisfying assignments at distance @xmath0 , then it always has a locally maximal pair at distance @xmath0 ) .",
    "clearly , @xmath162 always , but for large @xmath2 and @xmath163 ) the difference is minuscule for all @xmath104 .",
    "the connection between @xmath164 in an interval and  clustering \" was also first made in  @xcite .",
    "unfortunately , in  @xcite no concrete definition of clusters was given and , certainly , no scheme for grouping clusters into well - separated cluster regions ( clusters need not be well separated themselves ) .",
    "besides these simple clarifications , our minor contribution regarding clustering lies in giving rigorous bounds on the diameter and distance of the cluster regions .",
    "the novel one , as we discuss below , lies in establishing the existence of exponentially many cluster regions .",
    "additionally , in  @xcite the authors derive an expression for the second moment of the number of _ pairs of _ balanced assignments at distance @xmath103 , for each @xmath165 $ ] .",
    "whenever , for some @xmath125 , the dominant contribution to this second moment comes from uncorrelated pairs of pairs of balanced assignments , this implies that with _ constant _ probability @xmath20 contains at least one ( balanced ) pair of assignments at distance @xmath103 .",
    "we note that determining the dominant contribution to the above second moment rigorously , given @xmath125 , is a highly non - trivial problem which the authors tackle numerically for small @xmath2 , and heuristically for general @xmath2 , i.e. ,  they make a guess for the locus of the maximizer . in particular , this ",
    "fourth moment \" optimization problem is _ much _ harder than the already complicated second moment analysis of  @xcite .",
    "finally , the authors prove that the property  has a pair of satisfying assignments at distance @xmath139 \" has a sharp threshold , thus boosting their constant probability result for having a pair of satisfying assignments at a given distance to a high probability one . to the best of our understanding ,",
    "these three are the only results established in  @xcite .",
    "combined , they imply that for every @xmath59 , there is @xmath166 and constants @xmath167 , such that in @xmath20 :    * w.h.p .  every pair of satisfying assignments has distance either less than @xmath168 or more than @xmath169 .",
    "* for every @xmath170 \\cdot n$ ] , w.h.p .",
    "there is a pair of truth assignments that have distance @xmath0 .",
    "we note that even if the maximizer in the second moment computation was determined rigorously and coincided with the heuristic guess of  @xcite , the strongest statement that can be inferred from the above two assertions in terms of  establishing clustering \" is : for every @xmath59 , there is @xmath87 , such that w.h.p.@xmath171 has at least two clusters .",
    "in contrast , our theorem  [ basic ] establishes that w.h.p .",
    "@xmath172 consists of _ exponentially _ many , well - separated cluster regions , each region containing at least one cluster .",
    "additionally , theorem  [ sharp_basic ] establishes that as @xmath2 grows and @xmath173 approaches the threshold , these regions grow maximally far apart and their diameter vanishes .",
    "for a cluster @xmath74 , the string @xmath174 is the * projection * of @xmath74 and we will use the convention @xmath175 , so that @xmath176 .",
    "imagine for a moment that given a formula @xmath36 we could compute the marginal of each variable over the cluster projections , i.e. ,  that for each variable we could compute the fraction of clusters in which its projection is @xmath177 , and @xmath178 . then , as long as we never assigned @xmath179 to a variable which in every cluster was frozen to the value @xmath42 , we are guaranteed to find a satisfying assignment : after each step there is at least one cluster consistent with our choices so far .",
    "being able to perform the above marginalization seems quite far fetched given that even if we are handed a truth assignment @xmath115 in a cluster @xmath74 , it is not at all clear how to compute @xmath180 in time less than @xmath181 .",
    "survey propagation ( sp ) is an attempt to compute marginals over cluster projections by making a number of approximations .",
    "one fundamental assumption underlying sp is that , unlike the marginals over truth assignments , the marginals over cluster projections essentially factorize , i.e. ,  if two variables are far apart in the formula , then their joint distribution over cluster projections is essentially the product of their cluster projection marginals .",
    "determining the validity of this assumption remains an outstanding open problem .    the other fundamental assumption underlying",
    "sp is that _ approximate _ cluster projections can be encoded as the solutions of a csp whose factor graph can be syntactically derived from the input formula .",
    "our results are closely related to this second assumption and establish that , indeed , the approximate cluster projections used in sp retain a significant amount of information from the cluster projections . to make this last notion concrete and enhance intuition",
    ", we give below a self - contained , brisk discussion of survey propagation .",
    "for the sake of presentation this discussion is historically inaccurate .",
    "we attempt to restore history in section  [ sec : sp_related ] .    as we said above ,",
    "even if we are given a satisfying assignment @xmath115 , it is not obvious how to determine the projection of its cluster @xmath182 . to get around this problem sp sacrifices information in the following manner .    given a string @xmath183 , a variable @xmath73 is * free * in @xmath42 if in every clause @xmath44 containing @xmath73 or @xmath184 , at least one of the other literals in @xmath44 is assigned true or @xmath178 .",
    "we will refer to the following as a    * coarsening - step : * if a variable is free , assign it @xmath178 .",
    "given @xmath185 say that @xmath42 is dominated by @xmath186 , written @xmath187 , if for every @xmath188 , either @xmath189 or @xmath190 .",
    "consider now the following process : @xmath191    [ lem : uni ] for every formula @xmath36 and truth assignment @xmath192 , there is a unique coarsening  fixed point @xmath193 .",
    "if @xmath194 belong to the same cluster @xmath74 , then @xmath195 .",
    "trivially , applying a coarsening  step to a string @xmath42 produces a string @xmath186 such that @xmath196",
    ". moreover , if @xmath73 was free in @xmath42 , then @xmath197 will be free in @xmath186 . as a result ,",
    "if both @xmath198 are reachable from @xmath183 by coarsening  steps , so is the string that results by starting at @xmath42 , concatenating the two sequences of operations and removing all but the first occurrence of each coarsening  step .",
    "this implies that there is a unique fixed point @xmath199 for each @xmath183 under coarsening .",
    "observe now that if @xmath200 differ only in the @xmath188-th coordinate , then the @xmath188-th variable is free in both @xmath201 and coarsening  it in both yields the same string @xmath161 . by our earlier argument , @xmath202 , where @xmath203 is the cluster containing @xmath201 .",
    "considering all adjacent pairs in @xmath74 , we see that @xmath204 .",
    "[ core_def ] the * core * of a cluster @xmath74 is the unique coarsening  fixed point of the truth assignments in @xmath74 .    by lemma  [ lem : uni ] , if a variable takes either the value 0 or the value 1 in the core of a cluster @xmath74 , then it is frozen to that value in @xmath74 . to prove theorem  [ gen_c ] we prove that the core of every cluster has many non-@xmath178 variables .",
    "[ gen_w ] for any @xmath78 , let @xmath205 and @xmath206 be as in theorem  [ gen_c ] .",
    "if @xmath207 and @xmath81 , then w.h.p .",
    "the coarsening  fixed point of * every * @xmath208 contains fewer than @xmath209 variables that take the value @xmath178 .    to prove theorem  [ gen_w ] ( which implies theorem  [ gen_c ] ) we derive sharp bounds for the large deviations rate function of the coarsening  process applied to a fixed satisfying assignment . as a result",
    ", we also prove that in the planted - assignment model the cluster containing the planted assignment already contains frozen variables at @xmath210 .",
    "also , we will see that our proof gives a strong hint that for small values of @xmath2 , such as @xmath26 , for all densities in the corresponding satisfiable regime , most satisfying assignments _ do _ converge to @xmath211 upon coarsening .",
    "we can think of coarsening  as an attempt to estimate the projection of @xmath182 by starting at @xmath115 and being somewhat reckless . to see this , consider a parallel version of coarsening  in which given @xmath212 we coarsen all free variables in it simultaneously .",
    "clearly , the first round of such a process will only assign @xmath178 to variables whose projection in @xmath182 is indeed @xmath178 .",
    "subsequent rounds , though , might not : a variable @xmath43 is deemed free , if in every clause containing it there is some other variable satisfying the clause , _ or _ a variable assigned @xmath178 .",
    "this second possibility is equivalent to assuming that the @xmath178-variables in the clauses containing @xmath43 , call them @xmath213 , can take joint values that allow @xmath43 to not contribute in the satisfaction of any clause . in general formulas",
    "this is , of course , not a valid assumption . on the other hand , the belief that in random formulas there are no long - range correlations _ among the non - frozen _ variables of each cluster makes this is a reasonable statistical assumption : since the formula is random , the variables in @xmath213 are probably far apart from one another in the factor graph that results after removing the clauses containing @xmath43 .",
    "thus , indeed , any subset of variables of @xmath213 that do not co - occur in a clause should be able to take _ any _ set of joint values .",
    "our results can be seen as evidence of the utility of this line of reasoning , since we prove that for sufficiently large densities , the coarseningfixed point of a satisfying assignment is _ never _ @xmath214 . indeed , as we approach the satisfiability threshold , the fraction of frozen variables in it tends to 1 .    of course",
    ", while the core of a cluster @xmath74 can be easily derived given some @xmath215 , such a @xmath115 is still hard to come by .",
    "the last leap of approximation underlying sp is to define a set @xmath216 that includes all cluster cores , yet is such that membership in @xmath217 is  locally checkable \" , akin to membership in @xmath218 .",
    "specifically ,    a string @xmath183 is a * cover * of a cnf formula @xmath36 if : ( i ) under @xmath42 , every clause in @xmath36 contains a satisfied literal or at least two @xmath178 , and ( ii ) every free variable in @xmath42 is assigned @xmath178 , i.e. ,  @xmath42 is @xmath178maximal .",
    "cores trivially satisfy ( ii ) as fixed points of coarsening ; it is also easy to see , by induction , that any string that results by applying coarsening  steps to a satisfying assignment satisfies ( i ) .",
    "thus , a core is always a cover . at the same time , checking whether @xmath219 satisfies ( i ) can be done trivially by examining each clause in isolation . for ( ii )",
    "it is enough to check that for each variable @xmath43 assigned @xmath220 or @xmath221 in @xmath42 , there is at least one clause satisfied by @xmath43 and dissatisfied by all other variables in it .",
    "again , this amounts to @xmath14 simple checks , each check done in isolation by considering the clauses containing the corresponding variable .",
    "the price we pay for dealing with locally - checkable objects is that the set of all covers @xmath217 can be potentially much bigger than the set of all cores .",
    "for example , @xmath211 is always a cover , even if @xmath36 is unsatisfiable .",
    "the survey propagation algorithm can now be stated as follows .",
    "* repeat until all variables are set : 1 .",
    "compute the marginals of variables over covers .",
    "2 .   select a variable with least mass on @xmath178 and assign it the 0/1 value on which it puts most mass .",
    "3 .   simplify the formula .",
    "the computation of marginals over covers in the original derivation  @xcite of sp was , in fact , done via a message passing procedure that runs on the factor graph of the original formula rather than a factor graph encoding covers ( more on this in section  [ sec : sp_related ] ) .",
    "also , in  @xcite , if a configuration is reached in which all variables put ( nearly ) all their mass on @xmath178 , the loop is stopped and a local search algorithm is invoked .",
    "the idea is that when such a configuration is reached , the algorithm has  arrived \" at a cluster and finding a solution inside that cluster is easy since only non - frozen variables remain unset .",
    "the original presentation of survey propagation motivated the algorithm in terms of a number of physical notions ( cavities , magnetic fields , etc . ) .",
    "specifically , the algorithm was derived by applying the  cavity method \" within a ",
    "1-step replica symmetry breaking \" scheme , with no reference whatsoever to notions such as cluster projections , cores , or covers ( in fact , even clusters where only specified as the connected components that result when satisfying assignments at  finite hamming distance \" are considered adjacent ) . on the other hand ,",
    "a very definitive message - passing procedure was specified on the factor graph of the original formula and the computer code accompanying the paper and implementing that procedure worked spectacularly well . moreover , a notion foreshadowing cores was included in the authors discussion of  warning propagation \" .",
    "casting sp as an attempt to compute marginals over cores was done independently by braunstein and zecchina in  @xcite and maneva , mossel , and wainwright in  @xcite . in particular , in both papers it is shown that the messages exchanged by sp over the factor graph of the input formula are the messages implied by the belief propagation formalism  @xcite applied to a factor graph encoding the set of all covers . the first author and thorpe  @xcite",
    "have additionally shown that for every formula @xmath36 , there is a factor graph @xmath222 encoding the set of @xmath36 s covers which inherits the cycle structure of @xmath36 s factor graph , so that if the latter is locally tree - like so is @xmath222 .    in  @xcite ,",
    "the authors give a number of formal correspondences between sp , markov random fields and gibbs sampling and note that a cover @xmath223 can also be thought of as partial truth assignment in which every unsatisfied clause has length at least 2 , and in which every variable @xmath43 assigned @xmath220 or @xmath221 has some clause @xmath44 for which it is essential in @xmath115 , i.e. ,  @xmath43 satisfies @xmath44 but all other variables in @xmath44 are set opposite to their sign in @xmath44 .",
    "this last view motivates a generalization of sp in which marginals are computed not only over covers , but over all partial assignments in which every unsatisfied clause has length at least 2 , weighted exponentially in the number of non - essential 0/1 variables and the number of @xmath178-variables .",
    "one particular motivation for this generalization is that while sp appears to work very well on random 3-cnf formulas , @xcite gives experimental evidence that such formulas do not have non - trivial cores , i.e. ,  upon coarsening  truth assignments end up as @xmath214 .",
    "this apparent contradiction is reconciled by attributing the success of sp to the existence of  near - core \" strings allowed under the proposed generalization .",
    "while  @xcite provided a framework for studying sp by connecting it to concrete mathematical objects such as cores and markov random fields , it did not provide results on the actual structure of the solution space of random @xmath2-cnf formulas .",
    "indeed , motivated by the experimental absence of cores for @xmath26 , the authors asked whether random formulas have non - trivial cores for any @xmath2 .",
    "our results , establish a positive answer to this question for all @xmath224 .",
    "theorem  [ gen_c ] follows from theorem  [ gen_w ] and lemma  [ lem : uni ] . to prove theorem  [ gen_w ] we say that a satisfying assignment @xmath115 is if its coarsening  fixed point @xmath193 has at least @xmath117 @xmath178-variables .",
    "let @xmath53 be the random variable equal to the number of @xmath225-coreless satisfying assignments in a random @xmath2-cnf formula @xmath20 . by symmetry ,",
    "@xmath226 & = & \\sum_{\\sigma \\in \\{0,1,\\}^n } \\pr[\\sigma \\mbox { is        $ { \\alpha}$-coreless $ \\mid$ $ \\sigma$ is satisfying } ] \\cdot \\pr[\\sigma      \\mbox { is satisfying}]\\\\    & = & 2^n\\cdot \\left(1-\\frac{1}{2^k}\\right)^{rn } \\cdot \\ ;    \\pr[\\mbox{$\\mathbf{0}$ is $ { \\alpha}$-coreless $ \\mid$ $ \\mathbf{0}$ is    satisfying}]\\enspace.\\label{conditional}\\end{aligned}\\ ] ]    observe that conditioning on ",
    "@xmath227 is satisfying \" is exactly the same as  planting \" the @xmath227 solution , and amounts to selecting the @xmath228 random clauses in our formula , uniformly and independently from amongst all clauses having at least one negative literal .",
    "we will see that for every @xmath17 , there exists @xmath229 such that @xmath230 =    \\begin{cases}\\label{tk }      1-o(1 ) & { \\mbox{if $ r <",
    "t_k^{{\\alpha}}$ \\enspace , } } \\cr      o(1 )    & { \\mbox{if $ r > t_k^{{\\alpha}}$ \\enspace . } }    \\end{cases}\\ ] ] in particular , we will see that @xmath231 .",
    "we find it interesting ( and speculate that it s not an accident ) that all algorithms that have been analyzed so far work for densities below @xmath232 .",
    "more precisely , all analyzed algorithms set each variable @xmath43 by considering only a subset of the not yet satisfied clauses containing @xmath43 and succeed for some @xmath233 , where @xmath44 depends on the choice of subset .    to prove @xmath127=o(1)$ ]",
    "we will derive a strong upper bound for the probability in   when @xmath234 .",
    "specifically , we will prove that @xmath235 < e^{-f(r)n}$ ] for a function @xmath236 such that for all @xmath81 , @xmath237 by  , for all such @xmath173 we have @xmath127 = o(1)$ ] and theorem  [ gen_w ] follows .",
    "given any cnf formula @xmath36 and any @xmath238 it is easy to see that @xmath193 is completely determined by the set of clauses @xmath239 that have precisely one satisfied literal under @xmath115 .",
    "this is because after any sequence of coarsening  steps applied to @xmath115 , a clause that had two or more satisfied literals under @xmath115 , will have at least one satisfied literal or at least two @xmath178 and thus never prevent any variable from being free .",
    "therefore , to coarsen a truth assignment @xmath115 it is enough to consider the clauses in @xmath239 .",
    "let us say that a variable @xmath43 is unfrozen if there is no clause in which it is the unique satisfying variable and let us say that a clause is unfrozen if it contains an unfrozen variable .",
    "it is now easy to see that coarsening  @xmath115 is equivalent to starting with @xmath240 and removing unfrozen clauses , one by one , in an arbitrary order until a fixed point is reached , i.e. ,  no unfrozen clauses remain .",
    "variables occurring in any remaining ( frozen ) clauses are , thus , frozen in @xmath193 ( to their value in @xmath115 ) , while all other variables are assigned @xmath178 .",
    "this view of coarsening  as repeated removal of clauses from @xmath239 will be very useful in our probabilistic analysis below .    to estimate @xmath241 $ ] we consider a random @xmath2-cnf formula with @xmath242 clauses chosen uniformly among those satisfying @xmath227 . to determine @xmath243 , by our discussion above",
    ", it suffices to consider the clauses in our formula that have precisely one satisfied ( negative ) literal .",
    "the number of such clauses is distributed as @xmath244    it will be convenient to work in a model where each of these @xmath15 clauses is formed by choosing 1 negative literal and @xmath245 positive literals , uniformly , independently _ and with replacement_. ( since @xmath246 , by standard arguments , our results then apply when replacement is not allowed and the original number of clauses is @xmath247 . ) we think of the @xmath2 literals in each clause as @xmath2 balls ; we paint the single satisfied literal of each clause red , and the @xmath245 unsatisfied literals blue .",
    "we also have one bin for each of the @xmath14 variables and we place each literal in the bin of its underlying variable .",
    "we will use the term  blue bin \" to refer to a bin that has at least one blue ball and no red balls . with this picture in mind",
    ", we see that the @xmath178-variables in @xmath243 correspond precisely to the set of empty bins when the following process terminates :    1 .",
    "[ qlegal ] let @xmath43 be any blue bin ; if none exists exit .",
    "2 .   remove any ball from @xmath43 .",
    "[ random ] remove @xmath248 random blue balls",
    ". 4 .   [ or : red ] remove a random red ball .",
    "note that the above process removes exactly one clause ( 1 red ball and @xmath245 blue balls ) in each step and , therefore , if we pass the condition in step 1 , there are always suitable balls to remove . to give a lower bound on the probability that the process exits before @xmath15 steps ( thus , reaching a non - trivial fixed point )",
    ", we will give a lower bound on the probability that it exits within the first @xmath249 steps , for some carefully chosen @xmath250 .",
    "in particular , observe that for the process to not exit within the first @xmath188 steps it must be that : @xmath251    to bound the probability of the event in   we will bound the probability it occurs in the following simplified process .",
    "the point is that this modified process is significantly easier to analyze , while the event in   is only ( slightly ) more likely ( for the values of @xmath92 of interest to us ) .    1 .",
    "let @xmath43 be any blue bin ; if none exists go to step  ( c ) .",
    "2 .   remove any ball from @xmath43 .",
    "3 .   remove a random red ball .",
    "[ ui ] the event in   is no less likely in the modified process than in the original process .",
    "we prove lemma  [ ui ] below . to bound the probability of the event in   in the modified process we argue as follows .",
    "let @xmath139 be the number of bins which do not contain any red ball after @xmath188 steps and let @xmath252 be the original number of blue balls in these @xmath139 bins .",
    "if @xmath253 , then after @xmath252 steps of the modified process every non - empty bin will contain at least one red ball , since up to that point we remove precisely one blue ball per step . therefore , the probability of the event in   is bounded above by the probability that @xmath254 . to bound this last probability",
    "we observe that the red balls in the modified process evolve completely independently of the blue balls .",
    "moreover , since we remove exactly one red ball in each step , the state of the red balls after @xmath188 steps is distributed exactly as if we had simply thrown @xmath255 red balls into the @xmath14 bins .",
    "so , all in all , given a random @xmath2-cnf formula @xmath36 with @xmath242 clauses and a fixed @xmath256 , conditional on @xmath227 satisfying @xmath36 , the probability that the coarsening  process started at @xmath227 fails to reach a fixed point within @xmath188 steps is bounded by the probability that @xmath254 , where @xmath257 where @xmath258 is the distribution of the number of empty bins when we throw @xmath42 balls into @xmath186 bins .    as a result , given @xmath92 ,",
    "our goal is to determine a value for @xmath188 that minimizes @xmath259 $ ] . before we delve into the probabilistic calculations , in the next section we comment on how our analysis relates to the planted assignment problem and to the existence of non - trivial cores for small values of @xmath2 .",
    "consider a process which is identical to the original process except with step  [ random ] removed . we will call this the intermediate process .",
    "we begin by proving that the original and the intermediate processes can be coupled so that whenever the event in   occurs in the original process it also occurs in the intermediate process .",
    "first , observe that the evolution of the red balls in both processes is purely random and therefore can be assumed to be identical , i.e. ,  we can think of the original process as making a genuine random choice in step  [ or : red ] and the intermediate process as mimicking that choice .",
    "( we think of all balls as carrying a distinct identifier . )",
    "similarly , we can assume that originally , the placement of the blue balls in bins is identical for the two processes .",
    "let us say that a pair of blue ball placements is good if in every bin the set of blue balls in the original process is a subset of the set of blue balls in the intermediate process .",
    "clearly , whenever we are in a good configuration , since the placement of the red balls is identical in the two processes , any choice of bin and ball of the original process in steps 1,2 , is an available choice for the intermediate process .",
    "moreover , if the intermediate process mimics these choices , this results is a new good pair of blue ball placements . by induction , since the original pair of blue ball placements is good , if the event in   occurs in the original process it also occurs in the intermediate process .",
    "next , we compare the intermediate process to the modified process observing that they are identical except that in the event that we run out of bins containing only blue balls the intermediate process stops , while the modified process carries on .",
    "therefore , we couple the two as follows : the modified process mimics the intermediate process for as long as the event in   does not occur , and makes its own random choices afterwards .",
    "therefore , if the event in   occurs in the intermediate process it also occurs in the modified process .",
    "conditional on @xmath227 being satisfying , analyzing @xmath243 is exactly the same as working in the  planted assignment model \" and analyzing the core of the cluster containing the planted assignment .",
    "this is rather easy to do if we are content with results holding with probability @xmath260 .",
    "specifically , by  , , and standard concentration results it follows immediately that if @xmath261 then w.h.p.@xmath262    with these conditionals in place , we can next determine the mean path of the coarsening  process using the method of differential equations  @xcite , i.e. ,  the number of red and blue balls after each step , up to @xmath123 . in particular , this allows us to show that    for every @xmath17 , there exists a critical value @xmath263 such that if @xmath264 then w.h.p .",
    "@xmath265 , while if @xmath266 then w.h.p .",
    "a bounded fraction of the variables in @xmath243 , and therefore in @xmath267 , are frozen .    in the table below we give the value of @xmath263 for some small values of @xmath2 ( rounding to two decimals ) . by lower / upper below",
    "we mean the best known lower / upper bound for satisfiability threshold .",
    "[ tab : valu ] @xmath268 [ marianthi ]    we see that for @xmath269 , the probability that @xmath227 has a non - trivial coarsening  fixed point conditional on being satisfying , tends to 0 for all densities in the satisfiable regime .",
    "clearly , conditioning on ",
    "@xmath227 is satisfying \" , is not the same as picking a  typical \" satisfying assignment .",
    "nevertheless , the gap between @xmath263 and the best threshold upper bound for @xmath26 is sufficiently large to strongly suggest that below the satisfiability threshold , most satisfying assignments do arrive at @xmath214 upon coarsening .",
    "this is consistent with the experimental results of  @xcite , who first raised this possibility .",
    "that said , a distinction worth mentioning is that even if the coarsening  procedure arrives at @xmath214 from most / all satisfying assignments there can still be ( many ) frozen variables : simply , their corresponding clusters may not be be compact (  cube - like \" ) enough for coarsening  to discover their core .",
    "we now comment on the couple of simplifications of the original process that we introduced in the previous section in order to get a process that is easier to analyze .",
    "as we showed , these simplifications only increase the probability of the event in   and it is natural to wonder if this increase is significant , allowing for the possibility that our analysis can be made much sharper .",
    "below we give evidence that this is not the case .",
    "in particular , if each of @xmath270 can be assumed to be within @xmath123 of its expected value , then the inequality @xmath254 in the modified process is equivalent to @xmath271 in the table above we give the value of @xmath272 for some small values of @xmath2 .",
    "as we can see , these values are quite close to @xmath263 and get relatively closer as @xmath2 is increased . in other words , considering the modified process does not cause too big a loss in the analysis .",
    "indeed , taking e.g.,@xmath273 , already gives @xmath274 , which is consistent with the physics prediction that @xmath275 .",
    "of course , if one is interested in establishing that certain properties of @xmath243 hold with exponentially small failure probability , as we do , then conditioning that @xmath270 are within @xmath123 of their expectation is not an option .",
    "one has to do a large deviation analysis of all these variables and their interactions in the coarsening  process and determine the dominant source of fluctuations .",
    "this is precisely what we do with respect to the event @xmath254 in the modified process .",
    "it is well - known that if @xmath276 then for every @xmath277 , @xmath278 \\leq f(np,\\delta ) \\enspace , \\ ] ] where @xmath279 ) \\enspace .\\ ] ] a similar large deviations bound was shown in  @xcite for the number of empty bins in a balls - in - bins experiment ( theorem  3 ) .",
    "that is , for every @xmath277 , @xmath280 \\leq f(ne^{-m / n},\\delta ) \\enspace .\\ ] ]      write @xmath281 and fix @xmath282 write @xmath283 in order to compress the expressions below .",
    "the probability that @xmath284 = ( 1+\\delta ) \\frac{rk}{2^k-1 } \\cdot n =    ( 1+\\delta ) \\lambda \\cdot n \\enspace , \\label{mdev } \\\\ q & = & ( 1+\\zeta ) { \\mathbb{e}}[q | m ] = ( 1+\\zeta )    \\exp\\left(-\\frac{m - i}{n}\\right ) \\cdot n = ( 1+\\zeta ) e^{-\\rho}\\cdot n    \\enspace , \\label{qdev}\\\\ b & = & ( 1+\\epsilon ) { \\mathbb{e}}[b|q , m ] = ( 1+\\epsilon ) ( k-1)m \\cdot    \\frac{q}{n } = ( 1+\\delta)(1+\\epsilon)(1+\\zeta)\\lambda(k-1 )     e^{-\\rho}\\cdot n \\ , , \\label{bdev}\\end{aligned}\\ ] ] is bounded by @xmath285 we write this as @xmath286 , where @xmath287 with @xmath288 .",
    "conditional on the events in   we see from   that the condition @xmath289 becomes @xmath290 , where @xmath291 for any fixed @xmath2 , @xmath173 and @xmath104 define @xmath292 .",
    "thus , @xmath293 < \\exp(-n \\cdot \\min_{\\phi}\\omega ) \\times \\mathrm{poly}(n)\\ ] ] and to prove that the expected number of @xmath104-coreless assignments in @xmath294 , it suffices to prove @xmath295",
    "to establish   it is enough to prove that the maximum of @xmath144 in the variables @xmath296 , @xmath297 and @xmath298 under the condition @xmath299 is negative . considering that the function @xmath144 is monotone in the three variables @xmath296 , @xmath297 and @xmath298 , the maximizer of @xmath144 in the region @xmath299 has to be on the boundary , that is for @xmath300 .",
    "the maximum of @xmath144 under the condition @xmath300 corresponds to the extremum of the function @xmath301 , where @xmath302 is a lagrange multiplier .",
    "the equations for the location of the maximizer are thus given by derivatives of @xmath303 with respect to @xmath296 , @xmath297 , @xmath298 and @xmath302 @xmath304    [ extremum ] for any fixed @xmath2 , @xmath173 and @xmath305 , at the extremum of the function @xmath303 defined by equations ( [ derdelta])-([dermu ] ) the following assertions hold    1 .",
    "@xmath298 is non - negative ; 2 .",
    "@xmath297 is non - negative ; 3 .",
    "@xmath296 is non - positive ;    the first assertion follows by observing that @xmath144 is an increasing function of @xmath298 and @xmath306 contains @xmath298 only in the third term through @xmath307 .",
    "therefore , if the maximizer would be in @xmath308 , moving to @xmath309 , with @xmath310 , would keep @xmath306 constant while increasing @xmath144 .    combining equations ( [ derzeta ] ) and ( [ dereps ] ) in order to remove @xmath302 we have @xmath311 that is @xmath312 which , after simplification , reduces to @xmath313 thus , for @xmath277 and @xmath314 we have that at the maximizer @xmath315 , proving the second assertion .    combining equations ( [ derdelta ] ) and",
    "( [ dereps ] ) we can write @xmath316\\end{gathered}\\ ] ] the term within square brackets can be simplified to @xmath317 which , using  , implies @xmath318 since for @xmath319 the second and third term terms of this expression are non - negative , we find that @xmath296 has to be non - positive at the maximizer in order to satisfy the last equation ( third assertion ) .",
    "we next prove some bounds on @xmath296 and @xmath298 , that hold at the maximizer .",
    "[ d_easy ] fix any @xmath320 , and @xmath321 . at the maximizer of @xmath144 ,",
    "@xmath322    since @xmath296 in non - positive at the maximizer , we observe that @xmath323 for @xmath324 .",
    "moreover each of the three terms in @xmath306 is non - negative for @xmath325 and this implies @xmath326    [ e_easy ] fix any @xmath320 , and @xmath305 . at the maximizer of @xmath144 , @xmath327    since every term in @xmath306 is non - negative , considering the second term , and using the fact @xmath328 we get @xmath329 observe now that for all @xmath330 , we have @xmath331 .",
    "therefore , @xmath332 using   to replace @xmath333 and the fact @xmath334 we can conclude from   that @xmath335 where for the last inequality we use that @xmath336 is non - negative .",
    "we conclude that at the maximizer @xmath337 where @xmath296 has been replaced by its lower bound value .",
    "thus , the stationary point of @xmath303 must occur in the region @xmath338 . in the next subsections we derive analytical results for this optimization for all @xmath339 , and we summarize results obtained by numerically finding the stationary point of @xmath303 for @xmath340 .",
    "for any fixed values of @xmath296 and @xmath298 , the requirement @xmath342 implies @xmath343 plugging this lower bound in the second term of @xmath306 , we see that the requirement @xmath344 implies @xmath345 + e^{-\\rho } \\le s \\enspace .\\ ] ] therefore , it suffices to find @xmath346 and @xmath104 such that   can not be satisfied by any @xmath347 and @xmath348 .",
    "this is certainly true if a lower bound to the l.h.s .",
    "of   makes such an equation unsatisfied , that is if @xmath349 + e^{-\\lambda(1-\\alpha ) } > s\\ ] ] and",
    "the term within the squared brackets above is positive .",
    "thus , to summarize , it suffices to find @xmath346 and @xmath104 such that @xmath350 > s - e^{-\\lambda(1-\\alpha ) } > 0 \\enspace . \\label{second}\\end{aligned}\\ ] ]    with the change of variable @xmath351 we have that @xmath352 and @xmath353 since for any @xmath354 $ ] , @xmath355 $ ] and @xmath356 @xmath357 therefore , it suffices to establish @xmath358 \\ge ( 1-c)\\ln 2 \\label{main } \\enspace .\\ ] ] based on lemmata  [ d_easy ] and[e_easy ] we now introduce simpler bounds for @xmath296 and @xmath298 , which hold for all @xmath359 and @xmath360 . specifically , @xmath361 and @xmath362 replacing   and in   we have @xmath363 -(1-c)\\ln 2 \\ge 0 \\;.\\ ] ] solving with respect to @xmath44 , the last inequality becomes @xmath364/\\ln 2 } { 1 + \\alpha(1-\\alpha ) \\frac{1 - 1/\\sqrt{k}}{1 + 1/k } } \\equiv g_c(k,\\alpha ) \\enspace .\\ ] ] for any fixed @xmath321 , @xmath365 is a decreasing function of @xmath2 , which as @xmath366 tends to @xmath367    in order to prove that there exists a choice of @xmath104 such that @xmath368 for some @xmath166 and all @xmath369 , we rescale the lower bound for @xmath370 from   as @xmath371 and observe that @xmath372 is increasing in @xmath2 . in figure  [ k14 ]",
    "we now see that the function @xmath373 dips below @xmath374 for a certain range of @xmath104 , implying that the left endpoint of this range is an upper bound on the fraction of unfrozen clauses . for larger values of @xmath2 things only get better since @xmath365 is monotonically decreasing with @xmath2 , whereas @xmath372 is increasing . for any fixed value of @xmath104",
    ", @xmath375 can be defined as the first @xmath2 value for which @xmath376 holds .     for @xmath377 as a function of @xmath104 . the horizontal line , slightly below 1 , is @xmath378.,scaledwidth=50.0% ]      recall that for any fixed @xmath92 and @xmath104 the function @xmath303 depends on four variables : @xmath296 , @xmath298 , @xmath297 and @xmath302 .",
    "we will plot @xmath303 for @xmath379 , @xmath380 and a few different values of @xmath173 , while fixing @xmath297 and @xmath302 at the value they take at the stationary point : @xmath297 is given readily by  , and substituting this value of @xmath297 into   we get @xmath381    in the upper left panel of figure  [ fig ] we show @xmath303 in the subregion of @xmath95 corresponding to the optimal @xmath382 for @xmath383 . by closer inspection",
    "one finds that there is a unique stationary point in this region .",
    "the remaining three plots are zoomed on the stationary point for @xmath383 , @xmath384 and @xmath385 .",
    "it is clear that the function @xmath303 at the stationary point is positive for the first two @xmath173 values and negative for the third one ( for the sake of clearness , negative values of @xmath303 are not plotted ) .",
    "thus , for @xmath379 and @xmath380 , the critical value of @xmath173 lies between @xmath386 and @xmath387 . in the next subsection",
    "we determine this critical value numerically for all @xmath388 .    ,",
    "@xmath380,title=\"fig:\",scaledwidth=30.0% ] , @xmath380,title=\"fig:\",scaledwidth=30.0% ]    , @xmath380,title=\"fig:\",scaledwidth=30.0% ] , @xmath380,title=\"fig:\",scaledwidth=30.0% ]      for any fixed @xmath2 and @xmath104 the value of @xmath206 , such that w.h.p .",
    "clustering exists for @xmath390 , can be computed by solving numerically  - together with @xmath391 [ which reduces to @xmath392 since @xmath300 by  ] . adding a sixth equation @xmath393 allows one to minimize @xmath394 with respect to @xmath104 ( at some @xmath395 ) thus determining the smallest density @xmath396 for which the existence of frozen variables can be established .",
    "numerical solutions of these six equations are given in the table below for @xmath389 along with the lower bound @xmath370 from  .    [ cols= \" > , > , > , < , < , < , < , < \" , ]",
    "in this section we prove the existence of @xmath157 as in theorem  [ thm : est ] .",
    "let @xmath397$.}\\end{aligned}\\ ] ]    we begin by bounding @xmath398 from above as follows , @xmath399 \\\\ & < & 2 \\ln 2 - 2 \\left(1/2 - { \\alpha}\\right)^2 - \\gamma \\ln 2 \\big[2 -    ( 1-{\\alpha})^k\\big ] \\\\ & \\equiv & w({\\alpha } , k , \\gamma)\\enspace .\\end{aligned}\\ ] ] we note that for any fixed @xmath400 , the function @xmath401 is non - increasing in @xmath2 and decreasing in @xmath402 .",
    "moreover , @xmath403 implying that for any fixed @xmath400 , the equation @xmath404 can have at most three roots for @xmath405 . to bound the location of these roots",
    "we observe that for any @xmath406 and @xmath407 , @xmath408 \\ln 2 > 0 \\enspace , \\\\",
    "w(99/100,k,\\gamma ) & < & w(99/100 , 8 , 2/3 ) = -0.0181019 ... < 0 \\enspace , \\label{alkis}\\end{aligned}\\ ] ] where the inequality in   relies on the mononicity of @xmath409 in @xmath400 . therefore ,",
    "from   we can conclude that for every @xmath410 and @xmath407 , if there exist @xmath411 such that @xmath412 and @xmath413 , then @xmath414 for all @xmath415 $ ] .",
    "below we first prove that such @xmath157 exist for all @xmath410 and then prove that for sufficiently large @xmath2 , we can take @xmath157 as in  .",
    "* for @xmath98 it is enough to consider the plot of @xmath416 in figure  [ ploo ] .",
    "for @xmath417 we take @xmath418 .",
    "note that @xmath419 is smaller than the lower bound for @xmath370 given in  , for all @xmath417 .",
    "* * we take @xmath420 .",
    "we note that @xmath421 and prove that @xmath422 is decreasing in @xmath2 for any @xmath423 and @xmath424 as follows , @xmath425 - \\frac{4}{k^2 } \\left(\\frac12 - \\frac1k \\right ) \\\\ & < & { \\gamma}\\ln 2 \\left(1 - \\frac1k\\right)^{k-1 } \\frac{1}{k^2 } - \\frac{4}{k^2 } \\left(\\frac12 - \\frac1k \\right ) \\\\ & < & \\frac{1}{k^2 } \\left(\\ln 2\\ , -2 + \\frac4k \\right ) \\\\ & < &    0   \\enspace .\\end{aligned}\\ ] ] * * we take @xmath426 .",
    "we note that @xmath427 is non - increasing in @xmath2 when @xmath225 and @xmath402 are fixed and that @xmath428 .",
    "* for the setting where @xmath429 , we will additionally use that @xmath430 for all @xmath431 to establish that for any @xmath432 , @xmath433 substituting @xmath434 into   we get @xmath435 * * if @xmath436 and @xmath437 , then   implies that @xmath438 for all sufficiently large @xmath2 .",
    "* * if @xmath439 , then for any @xmath440 @xmath441 which is negative for all sufficiently large @xmath2 .",
    "the choice @xmath442 corresponds to @xmath443 , which is a valid value . for @xmath2",
    "large enough we have @xmath444 for any @xmath445 .",
    "we will use the following two lemmata .    [ lemvol ]",
    "if @xmath446 and @xmath447 , or @xmath448 and @xmath449 , @xmath450    [ lembal ] for all @xmath406 , @xmath451 \\enspace , \\ ] ] where @xmath452    combining the two lemmata above we get that if @xmath434 and either @xmath453 and @xmath447 , or @xmath448 and @xmath449 , then @xmath454 > \\frac{1}{2 \\ln 2 }   \\left[\\ln 2 ( 1+\\gamma -2 \\gamma m(k ) ) - \\left(1+\\frac{9 \\ln      2}{16}\\right)k^{-2}\\right ] \\enspace , \\ ] ] where @xmath455 is as in lemma  [ lembal ] .",
    "it is not hard to check that @xmath455 is decreasing in @xmath2 .    * for @xmath456 ,",
    "the existence of @xmath457 can be verified by plotting @xmath95 and @xmath129 and noting that @xmath458 } \\lambda(\\alpha , k , r ) \\enspace , \\ ] ] both when @xmath98 and @xmath99 and when @xmath459 and @xmath460 . for @xmath461 and @xmath462 ,",
    "the existence of @xmath463 follows from the fact that the expression inside the square brackets in   is positive when @xmath464 and @xmath465 and @xmath455 is decreasing in @xmath2 .",
    "* for the setting where @xmath429 , we note that the limit of the expression inside the square brackets in   as @xmath466 is @xmath467 . in particular , writing @xmath468 , it is not hard to show that the right hand side of   is greater than @xmath469 for all @xmath470 .",
    "below , we consider @xmath2 and @xmath173 to be fixed , so that all derivatives are with respect to @xmath104 .",
    "specifically , we will give i ) a value @xmath471 such that @xmath95 is non - increasing in @xmath472 and ii ) a function @xmath473 which is non - decreasing in @xmath474 and for which @xmath475 .",
    "thus , we will conclude @xmath476 .",
    "we begin by getting an upper bound for @xmath477 , as follows : @xmath478    [ fede1 ] if @xmath479 , then for all @xmath410 and @xmath480 , there exists @xmath481 such that @xmath482 .",
    "let @xmath483 we begin by noting that if @xmath471 is such that @xmath484 then @xmath485 .",
    "now , let us define @xmath486 observe that the unique solution of @xmath487 is @xmath488 and that @xmath489 for all @xmath490 .",
    "recall that @xmath491 for all @xmath492 .",
    "therefore , @xmath493 for all @xmath104 such that @xmath494 .",
    "in particular , if @xmath495 , then since @xmath489 for all @xmath490 , we can conclude that the equation @xmath496 has at least one root @xmath497 , as desired .    by",
    ", the condition @xmath495 is equivalent to @xmath498 to establish that   holds we note that for any @xmath499 the quantity @xmath500 is decreasing in @xmath501 and , therefore , it is bounded by @xmath502 .",
    "as @xmath503 is decreasing for @xmath504 , for all @xmath410 we have @xmath505 , as desired .",
    "the fact @xmath506 along with the inequality @xmath507 valid for @xmath508 , gives us @xmath509 .    to bound @xmath95 by an non - decreasing function",
    "we note @xmath510    if @xmath479 , then for every @xmath410 and @xmath511 $ ] , @xmath512    using lemma  [ fede1 ] to pass from   to  , we see that for every @xmath410 and @xmath513 $ ] , @xmath514     \\label{kola } \\\\   & \\le &   ( 1-\\gamma)\\ln 2   + 2^{-\\gamma k } ( 1 + 4   { \\gamma}k^2 2^{-{\\gamma}k }",
    "\\ln     2 ) ( \\gamma k \\ln 2   + 1 ) \\label{mola } \\enspace .\\end{aligned}\\ ] ] recalling that   holds for all @xmath410 and @xmath515 , we conclude @xmath516    we can now prove lemma  [ lemvol ] .    recall the definition of the function @xmath473 from   and note that , since @xmath517 , it is non - decreasing for @xmath518 and @xmath519 . from   we see that @xmath520 and therefore we can conclude that @xmath521 for all @xmath522 . to complete the proof it thus suffices to prove that @xmath95 is non - increasing in the interval @xmath523 since , by our results in the previous section , we know that @xmath524 both when @xmath446 and @xmath447 , and when @xmath448 and @xmath449 .",
    "for that we first observe that @xmath525 since , by definition , @xmath485 this implies @xmath526 for all @xmath527 $ ] and since @xmath528 , it follows that @xmath529 also for such @xmath104 . using",
    ", it is straightforward to check that for @xmath530 $ ] , the derivative of @xmath95 is negative both when i ) @xmath446 and @xmath447 , and when ii ) @xmath531 and @xmath449 , thus concluding the proof .      recalling the definition of @xmath129 from  @xcite we have @xmath532 \\enspace , \\ ] ] where @xmath298 satisfies @xmath533 we note for later use that , as shown in  @xcite , if @xmath298 satisfies   then @xmath534    since all coefficients in the binomial expansion of @xmath535 are positive , @xmath536 to get a lower bound for the numerator inside the logarithm in   we consider the binomial expansion of @xmath537 .",
    "we observe that the sum of a pair of successive terms where the lower term corresponds to an even power equals @xmath538 \\enspace .\\ ] ] for @xmath539 and @xmath540 the expression in   is positive .",
    "moreover , when @xmath2 is even the last term in the binomial expansion has a positive coefficient and can be safely discarded .",
    "therefore , for all",
    "@xmath410 and @xmath540 , @xmath541    substituting   and   into   we get a lower bound of the form @xmath542 .",
    "it is not hard to check directly that @xmath543 for all @xmath406 .",
    "similarly , using the upper bound for @xmath298 from  , it is not hard to check that for @xmath544 , we have @xmath545 for all @xmath546 .",
    "therefore , we can conclude @xmath547 \\nonumber \\\\    & \\ge & 2 \\ln 2   + r \\ln\\left[1 - 2^{1-k } + 2^{-2k } -      k 2^{-k } ( 1 - 2^{-k } ) ( 2^{1-k } + 3 k 2^{-2k } ) \\right ] \\enspace ,    \\label{fola}\\end{aligned}\\ ] ] where in   we have replaced @xmath298 with its upper bound from  .",
    "the argument of the logarithm in   is increasing in @xmath2 for all @xmath548 ( a fact that can be easily established by considering its derivative ) . as a result",
    ", we have that for all @xmath59 , it is at least equal to its value for @xmath98 which is @xmath549",
    ". thus , using the inequality @xmath550 valid for all @xmath551 , we can finally write @xmath451 \\enspace , \\ ] ] where @xmath552",
    "this work has been partially supported by the ec through the fp6 ist integrated project `` evergrow '' .",
    "a.  kaporis , l.  m. kirousis , and e.  g. lalas , _ the probabilistic analysis of a greedy satisfiability algorithm _ , in proc .",
    "10th annual european symposium on algorithms , volume 2461 of _ lecture notes in computer science _ , springer ( 2002 ) , 574585 ."
  ],
  "abstract_text": [
    "<S> for a large number of random constraint satisfaction problems , such as random k - sat and random graph and hypergraph coloring , there are very good estimates of the largest constraint density for which solutions exist . </S>",
    "<S> yet , all known polynomial - time algorithms for these problems fail to find solutions even at much lower densities . to understand the origin of this gap we study how the structure of the space of solutions evolves in such problems as constraints are added . in particular </S>",
    "<S> , we prove that much before solutions disappear , they organize into an exponential number of clusters , each of which is relatively small and far apart from all other clusters </S>",
    "<S> . moreover , inside each cluster most variables are frozen , i.e. , take only one value . </S>",
    "<S> the existence of such frozen variables gives a satisfying intuitive explanation for the failure of the polynomial - time algorithms analyzed so far . at the same time , our results establish rigorously one of the two main hypotheses underlying survey propagation , a heuristic introduced by physicists in recent years that appears to perform extraordinarily well on random constraint satisfaction problems . </S>"
  ]
}