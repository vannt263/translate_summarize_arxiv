{
  "article_text": [
    "the discovery of the accelerated expansion of the universe  @xcite poses perhaps the greatest puzzle in fundamental physics today .",
    "a solution of this problem will profoundly impact cosmology and could also provide key insights in reconciling gravity with quantum theory .",
    "driven by these motivations , the fundamental aim of ground and space based missions such as the baryon oscillation spectroscopic survey ( boss )  @xcite , the dark energy survey  @xcite , the joint dark energy mission ( jdem )  @xcite , the large synoptic survey telescope ( lsst )  @xcite  to name just a few  is to unravel the secret of cosmic acceleration . in search of the underlying explanation ,",
    "theoretical approaches fall into two main categories : ( i ) dark energy  invoking a new cosmic ingredient , the simplest being a cosmological constant , and ( ii ) modified gravity  invoking new dynamics of space - time ( for a recent review , see ref .",
    "@xcite ) . in this paper",
    "we consider only the dark energy alternative , and , for the moment , ignore possible modifications of general relativity .",
    "a fundamental difficulty in dark energy investigations is the absence of any single _ compelling _ theory to test against observations .",
    "consequently , much of the work in this area has followed the approach to parameterize dark energy by its equation of state @xmath1 ( where @xmath2 is the pressure , and @xmath3 the density ) , see , e.g. , ref .",
    "@xcite ; dynamical models of dark energy such as quintessence fields lead to a time - varying equation of state  @xcite .",
    "data analysis efforts therefore focus on characterizing this time - dependence .",
    "current observations are consistent with the existence of a cosmological constant , @xmath4 , ( @xmath5 ) , at the 10% level , the time - variation being unconstrained ( for recent constraints on @xmath6 , see e.g. refs .",
    "the implied value of @xmath4 is , however , in utter disagreement with simple theoretical estimates of the vacuum energy , being too small by a factor @xmath7 .",
    "it is therefore an _ ad hoc _ addition with no hint of a possible origin , hence the focus on dynamical explanations , e.g. , field theory models or modified gravity .",
    "although a detection of any time or , equivalently , redshift - dependence in @xmath0 would immediately rule out a cosmological constant , such observational imprints must necessarily be subtle , otherwise they would have been discovered already .",
    "this is the motivation behind constructing a robust framework with controlled error bounds that allows a reliable extraction of @xmath0 from diverse datasets .    shortly after the discovery of the accelerated expansion , it was pointed out that a reconstruction program ( an inverse analysis of data ) for dark energy working directly with observational supernova data is computationally possible ( see , e.g. , refs .",
    "@xcite for early approaches ) .",
    "soon a large number of papers followed , suggesting many different ways of reconstructing diverse properties of dark energy , e.g. refs .",
    "@xcite ; a review on dark energy reconstruction methods including a comprehensive list of references is given in ref .",
    "@xcite . broadly speaking",
    ", reconstruction techniques fall into two classes , the first being those based on parameterized forms for @xmath0 such as @xmath8 , @xmath9  @xcite or @xmath10  @xcite .",
    "these possess the virtue of simplicity but can have serious shortcomings due to lack of generality and error control ( specifically issues of bias , see , e.g. , @xcite ) , especially as one goes to higher redshifts .",
    "the second class consists of nonparametric methods that aim to solve the inverse problem of determining the actual function @xmath0 given observational data , rather than just the parameters specifying some assumed form of @xmath0 .",
    "the hope is to avoid the possible biasing of results due to specific assumptions regarding the functional form of @xmath0 , which may turn out to be incorrect .",
    "the difficulty with direct reconstruction methods as applied to supernova data is that extracting the desired information formally involves taking a second derivative of the  unavoidably noisy ",
    "luminosity distance - redshift relation , and the robustness and error control of the resulting reconstruction can therefore be suspect .",
    "a separate alternative to the direct reconstruction approach for @xmath6 from the data , is to falsify classes of dark energy models .",
    "for example , in ref .",
    "@xcite different general forms for @xmath6 are considered that capture different dynamical dark energy models .",
    "a hypothesis test is then carried out for these models to determine how likely they are given current data . in the best case scenario , entire classes of models can be excluded in this way . in ref .",
    "@xcite classes of dark energy models are falsified by carrying out a combined analysis of the growth of structure and the expansion history of the universe from cosmic microwave background ( cmb ) and supernova data .",
    "this approach takes advantage of the fact that a viable dark energy model must be consistent with measurements of both of these relatively orthogonal probes of dark energy . as pointed out in ref .",
    "@xcite the falsification of the smooth dark energy class would be very interesting , and a different paradigm for explaining the accelerated expansion such as a modification of gravity on very large scales would be required .",
    "hypothesis testing therefore provides an interesting alternative to the direct reconstruction approach .",
    "in fact , in order to convincingly exclude a cosmological constant from future measurements , both approaches should be employed , with the aim of arriving at a consistent conclusion .    given finite data sets , there are  broadly speaking  two ways in which one can go wrong in the reconstruction task , ( i ) errors due to the assumption of the wrong shape of @xmath0 , as discussed above and ( ii ) errors due to the complex nature of the high - dimensional space within which the inverse problem is being attempted , in particular , problems due to the existence of degeneracy directions . in this paper ,",
    "our aim is to address the first of these problems , i.e. , to develop a technique that is sufficiently flexible , yet not dangerously susceptible to new error sources as a result of the extra degrees of freedom .",
    "the second aspect of the inverse problem , the difficulty of dealing with degeneracy directions ( as seen in the examples below ) , is not directly addressed here .",
    "this issue requires sensitivity analyses and a formalism for incorporating multiple data sources and will be treated elsewhere  @xcite .    in the current paper",
    ", we propose a new , nonparametric reconstruction approach that solves the associated statistical inverse problem by sampling the posterior distribution using markov chain monte carlo ( mcmc ) methods , while representing @xmath0 by a gaussian process ( gp ) .",
    "traditionally , gp modeling is a nonparametric regression approach based on a generalization of the gaussian probability distribution .",
    "it extends the notion of a gaussian distribution over scalar or vector random variables to function spaces . while a gaussian distribution is specified by a scalar mean @xmath11 or a mean vector and a covariance matrix , the gp is specified by a mean function and a covariance function  @xcite .",
    "gps have been successfully applied in astrophysics and cosmology to construct prediction schemes for the dark matter power spectrum and the cmb temperature angular power spectrum  @xcite , to model asteroseismic data  @xcite , and to derive photometric redshift predictions  @xcite . here",
    "we will use the gp modeling approach  in concert with mcmc  to reconstruct @xmath0 from supernova observations , and not as a data interpolation or regression tool applied directly to observational or computed data , as is most often the case .    as of now ,",
    "supernova datasets hold by far the most information about possible time dependence of @xmath0 , though baryon acoustic oscillation ( bao ) and cmb measurements contain complementary information ( see , e.g. , ref .",
    "@xcite for a recent combined reconstruction analysis ) .",
    "although the gp approach can be easily extended to accommodate more than one observational probe , for clarity we will restrict ourselves in this paper to supernova measurements only .",
    "a more inclusive methodology will be presented in future work  @xcite .",
    "since current data quality does not allow placement of strong constraints on a possible redshift dependence of @xmath0 , we create a set of simulated data of jdem - like quality to demonstrate and test our new method .",
    "we consider three models , one with a constant equation of state and two with varying @xmath0 .",
    "our new approach will be shown to perform well in capturing nontrivial deviations from a constant equation of state and in providing reliable error bounds .",
    "the paper is organized as follows . in section  [ sec : sne ] we provide a brief overview of how supernova data are used to constrain the equation of state of dark energy .",
    "we describe the simulated data sets and their error properties in section  [ sec : data ] . in section  [ sec : recon ] we introduce different reconstruction methods and present our approach in the same section , contrasting our nonparametric method with results obtained using the popular parametric forms of refs .",
    "we conclude in section  [ sec : concl ] .",
    "details of the implementation of the gp - based mcmc algorithm are given in an appendix .",
    "type ia supernova measurements are currently the single best source of information regarding possible deviations of @xmath0 from a constant value .",
    "the luminosity distance @xmath12 as measured by supernovae is directly connected to the expansion history of the universe described by the hubble parameter @xmath13 . for a spatially flat universe ,",
    "the relation is given by @xmath14 where @xmath15 is the speed of light , @xmath16 , the current value of the hubble parameter ( @xmath17 , where @xmath18 is the scale factor and the overdot represents a derivative with respect to cosmic time ) , and @xmath19 .",
    "the assumption of spatial flatness is in effect an `` inflation prior '' , although there do exist strong constraints on spatial flatness when cmb and bao observations are combined ( see , e.g. , ref .",
    "@xcite ) . in principle",
    ", we can relax this assumption , but enforce it here to simplify the analysis .    instead of @xmath20 ,",
    "supernova data are usually specified in terms of the distance modulus @xmath11 as a function of redshift .",
    "the relation between @xmath11 and the luminosity distance is @xmath21 - 5\\log_{10}(h_0)+25,\\nonumber\\end{aligned}\\ ] ] where we used eqn .",
    "( [ dl ] ) .",
    "@xmath22 is the absolute magnitude of the object and @xmath23 the ( @xmath24-band ) apparent magnitude .",
    "writing out the expression for the hubble parameter @xmath25 in eqn .",
    "( [ muh ] ) explicitly in terms of a general dark energy equation of state for a spatially flat frw universe leads to the relation @xmath26^{-1/2}\\right\\}. \\nonumber\\end{aligned}\\ ] ] note that @xmath16 can not be determined from supernova measurements in the absence of an independent distance measurement .",
    "thus @xmath16 can be treated as unknown and absorbed in a re - definition of the absolute magnitude : @xmath27 which accounts for the combined uncertainty in the absolute calibration of the supernova data , as well as in @xmath16 . using this ,",
    "the @xmath24-band magnitude can be expressed as @xmath28 where @xmath29 is the `` hubble - constant - free '' luminosity distance .",
    "the measurement of @xmath30 is only a relative measurement and @xmath31 allows for an additive uncertainty which can be left as a nuisance parameter . to simplify our notation",
    ", we absorb @xmath32 into our definition of the distance modulus , leading to : @xmath33.\\ ] ] with this definition of the distance modulus we have calibrated the overall off - set of the data to be zero . to account for uncertainties in the calibration ,",
    "we introduce a shift parameter @xmath34 with a broad uniform prior .",
    "given a set of observations for @xmath35 with associated errors , the task at hand is to solve the statistical inverse problem , i.e. , to extract the corresponding @xmath0 by inverting the stochastic version of eqn .",
    "( [ mu ] ) , i.e. , inverting a nonlinear smoothing operator , which can be viewed formally as requiring taking two derivatives of the ( noisy ) data , the key difficulty to be overcome in reconstruction .",
    "as previously stated , the present quality of supernova data is not good enough to determine the equation of state beyond a cosmological constant ( i.e. , use of the parameterized form @xmath8 ) . to do better than this ,",
    "both systematic and statistical errors need to be brought under further control .",
    "such systematic errors can occur due to , e.g. , uncertainties in luminosity corrections and therefore in distance estimates , or the fitting procedure for the supernova light curves ; for a recent discussion of these issues , see ref .",
    "larger numbers of supernovae , especially at high redshifts , are needed to get firm constraints on a possible variation in @xmath6 ( see , e.g. , refs .",
    "future supernova surveys , especially space - based , hold the promise to remedy this situation .",
    "we therefore explain our method for reconstructing @xmath0 with simulated data that mimics the expected quality of future space - based observations .",
    "we turn now to a description of the simulated datasets .",
    "redshift distribution of supernovae from the three simulated datasets investigated .",
    "in addition to jdem measurements of supernovae , we assume a low redshift sample of 300 supernovae for @xmath36 . the bin width is @xmath37.,width=259 ]              in this section we introduce three synthetic datasets which we will use to compare the gp approach to parameterized methods for estimating @xmath0 .",
    "synthetic datasets have three important attributes : ( i ) the underlying `` truth '' is known and one can therefore impose a quantitative measure on how well each method performs .",
    "( ii ) the data quality can be controlled , e.g. , we mimic the expected data quality from future space - based supernova surveys .",
    "( iii ) dark energy models with very different equations of state @xmath0 can be synthesized .",
    "we assume the measurement of @xmath38 2300 supernovae , distributed over a redshift range of @xmath39 with larger concentration of supernovae in the mid - range redshift bins ( @xmath40 ) and at low redshift ( @xmath41 ) .",
    "figure  [ snap ] shows the detailed distribution of the supernova data with respect to redshift . to create the simulated data ,",
    "we begin with points for @xmath42 shifted off - center according to some error model for the distance modulus ( gaussian variance ) .",
    "the distance modulus error can be related to that in @xmath43 by differentiating eqn .",
    "( [ tildemu ] ) to yield @xmath44 . for each supernova",
    ", we provide a measurement for the distance modulus @xmath45 and we assume a statistical error of @xmath46 , as expected from future surveys such as jdem  @xcite . for our purposes here , it is sufficent to use a simplified error model where the errors are the same for all supernovae and independent of redshift .",
    "we also do not explicitly introduce systematic errors .",
    "we represent the measured points in the following form : @xmath47 in this notation , the observations @xmath45 follow a normal distribution with mean @xmath48 , the standard deviation being set by the distribution of the error , @xmath49 , representing a mean - zero normal distribution with standard deviation , @xmath50 . here , @xmath51 is the observed error and @xmath52 accounts for a possible rescaling .",
    "in addition , we assume that the errors are independent .",
    "the assumption of normal distributed errors in magnitude space is consistent with the error distribution of real observations as quoted in ref .",
    "@xcite . for each of the datasets we choose @xmath53 .",
    "the three simulated datasets and corresponding equations of state are shown in figure  [ data ] .",
    "* dataset 1 : * the first dataset is that for a cosmological constant with a constant equation of state , @xmath5 .",
    "* dataset 2 : * the second dataset is based on a quintessence model with a minimally coupled scalar field .",
    "the equation of motion for the homogeneous mean field is @xmath54 .",
    "the equation of state parameter is given by @xmath55 the particular choice of potential used here is @xmath56 .",
    "this model predicts a relatively small variation in the equation of state as a function of @xmath57 as can be seen in the middle panel in the lower row in figure  [ data ] .",
    "* dataset 3 : * the last dataset is based on a quintessence model described in ref .",
    "this model has a dark energy equation of state of the form @xmath58,\\nonumber\\end{aligned}\\ ] ] with the constants having the values @xmath59 .",
    "this model has @xmath60 everywhere , therefore it can in principle be realized by a quintessence field .",
    "the time variability of the equation of state has an s - shaped form as shown in the right lower panel in figure  [ data ] . the parameter choices for this model lead to a steeper transition in @xmath0 from @xmath5 to @xmath61 than natural for most quintessence models .",
    "therefore , compared to dataset 2 , this scenario is less realistic .",
    "our choice of this dataset is dictated by the fact that it can not be easily fit by any of the currently used parametric reconstruction methods .",
    "( it represents a general class of models with equations of state that can exhibit rapid changes . )    simulated data for model 1 ( @xmath5 ) with error bars in red .",
    "the green and blue line show the exact distance modulus @xmath42 for model 2 and 3 .",
    "note the very small size of the difference.,width=259 ]    figure  [ simdata ] and the upper panels in figure  [ data ] give a visual impression of the difficulties posed by reconstruction .",
    "figure  [ simdata ] shows the simulated data for model 1 with error bars and the exact @xmath42 for models 2 and 3 , which are hardly distinguishable by eye .",
    "figure  [ data ] shows the differences @xmath62 for each dataset with respect to a @xmath4cdm model with @xmath5 ; models with nontrivial @xmath0 show relatively small deviations from the horizontal line . as we demonstrate below , inverse modeling using gaussian processes",
    "can successfully discriminate between these marginal differences and reconstruct the dark energy equation of state reliably within stated errors .",
    "as discussed previously , the dark energy equation of state is not directly measurable from the luminosity distance - redshift relation , given in eqn .",
    "( [ mu ] ) .",
    "the obvious idea of first fitting for @xmath35 and then extracting @xmath0 by taking two derivatives must deal with the noise in the data and the filtering required to estimate the derivatives . experience with inverse problems has shown that such approaches can easily yield unsatisfactory results .",
    "a detailed discussion on the shortcomings of this approach can be found in , e.g. , ref .",
    "@xcite .",
    "a simpler alternative is to assume a hopefully well - motivated parametric form for @xmath0 and then fit for the parameters ( for an early discussion about the advantages of this approach , see , e.g. , ref .",
    "for example , if we assume @xmath6 to be constant , the integral over @xmath0 in eqn .",
    "( [ mu ] ) can be solved analytically and the best - fit value for @xmath6 can then be determined from measurements of @xmath30 via , e.g. , maximum likelihood techniques .",
    "current data are in good agreement with a constant @xmath6 at the 10% level ( for a recent analysis see ref .",
    "@xcite and references therein for earlier results ) . going beyond this",
    ", a weak redshift dependence of @xmath0 may be assumed .",
    "one way to realize this is a taylor expansion of @xmath0 in its redshift evolution , of the form @xmath63 , as suggested in refs .",
    "@xcite . however , this parameterization is not well suited for @xmath64 , the regime that holds the most promise to distinguish different models of dark energy  @xcite . in ref .",
    "@xcite , the form @xmath10 is suggested as a better alternative ( also given previously in ref .",
    "this parameterization has several nice features : it is well behaved beyond @xmath65 , it has only two parameters and is therefore relatively easy to constrain , and it captures the general behavior of different classes of dynamical dark energy models .",
    "the major disadvantage is that the parameterization will only allow reconstruction of monotonic behaviors of @xmath0 .",
    "more involved parameterizations have been suggested to address this problem ; overviews can be found in refs .  @xcite .",
    "although parameter estimation is technically much easier than reconstruction , it can have shortcomings due to poor control over bias  @xcite .",
    "nonparametric reconstruction methods have received less attention , in part because the current data quality does not fully justify the use of sophisticated inverse methods .",
    "nevertheless , with future data quality in mind , nonparametric techniques can be a powerful alternative for extracting information about @xmath0 .",
    "they can capture more complex behavior in @xmath0 and  in principle  can prevent the existence of bias due to a restricted parameterization .",
    "early nonparametric approaches involve a smoothing procedure for either @xmath12 or related quantities at a characteristic smoothing scale , see , e.g.  @xcite .",
    "a somewhat intermediate approach is a piecewise constant description of @xmath0 ( see , e.g. , ref .",
    "@xcite ) using basis functions such as top - hat bins or wavelets  @xcite . in the extreme case of one bin for the whole data range , this method is equivalent to the @xmath66 .",
    "parametrization . determining",
    "the optimal number of bins informed by the data is therefore important though not straightforward .",
    "too few bins would erase important information , too many bins would enhance noise to ( incorrect ) information . in ref .",
    "@xcite , four redshift bins were used , while ref .",
    "@xcite used five redshift bins over a smaller redshift range . in order to obtain uncorrelated estimates of the dark energy parameters in the different bins ,",
    "a principal component analysis is carried out first .",
    "this method has been used recently by the jdem figure of merit science working group  @xcite to assess the performance of jdem with respect to constraining the dark energy equation of state . in ref .",
    "@xcite a combined analysis of diverse data sets has been performed based on this method and found no evolution in @xmath0 .",
    "in contrast to the piecewise constant description of the dark energy equation of state , our approach represents @xmath0 by a continuous gaussian process , the parameters specifying the process ",
    "the so - called hyperparameters  being completely determined as part of the solution of the inverse problem .",
    "it is important to distinguish the gp hyperparameters from the parameters of a conventional parametric method .",
    "the gp approach is nonparametric , the hyperparameters specifying aspects of the prior distribution in a bayesian approach ( such as properties of the allowed classes of functions ) .",
    "one advantage of this degree of freedom is that one can explicitly use it to test the sensitivity of the posterior distribution to assumptions made about the prior , e.g. , the order of differentiability . here",
    ", we make no binning assumptions or assumptions of the discrete properties of the gps , favorable when working with a physical process that is assumed to be continuous in nature .    in this paper",
    "we will study the ansatz @xmath8 and the parameterization suggested in refs .  @xcite as reference standards to compare with the gp modeling approach . as a simplification , in the first step of our analysis",
    ", we will assume knowledge of the value of @xmath67 and assume perfect calibration , i.e. @xmath68 .",
    "in the next step , we will drop these assumptions and include the parameters as part of the estimation process , as would be the case in a more realistic scenario ( albeit without directly including non - supernova datasets ) . to provide a context for the gp approach we will first present an analysis with parameterized models .                in the study of parametric reconstruction",
    ", we follow a bayesian analysis approach  @xcite .",
    "we focus the analysis on two of the previously discussed models : @xmath69 and @xmath70 and use mcmc algorithms to fit for the model parameters  @xcite , resulting in posterior estimates and probability intervals for @xmath67 , and the parameters that specify the form of @xmath0 .",
    "we have consistent priors in all of our models ( including the gp model described in the next section ) so the results are readily comparable : @xmath71 and the likelihood @xmath72 where @xmath73 encapsulates the cosmological parameters to be constrained , i.e. , a subset or all of @xmath74 , and @xmath34 . here",
    "the notation `` @xmath75 '' simply means `` distributed according to '' .",
    "@xmath76 is a uniform prior , with the probability density function @xmath77 for @xmath78 $ ] and @xmath79 otherwise .",
    "@xmath80 is a gaussian ( or normal distributed ) prior with the probability density function @xmath81/\\sqrt{2\\pi\\sigma^2}$ ] .",
    "the squared notation for the second parameter in @xmath82 is used to indicate that @xmath52 is the standard deviation ( to prevent possible confusion with the variance @xmath83 ) .",
    "( the parameters in the @xmath76 distribution do not have this same meaning of mean and standard deviation as in the normal distribution . ) for each case we study , we confirm that the mcmc chains converged by monitoring the trace plots and checking for good mixing and stationarity of the posterior distributions .    the prior for @xmath67 is informed by the 7-year wmap analysis  @xcite for a @xmath6cdm model combining cmb , bao , and @xmath16 measurement . since our assumptions on @xmath6 are less strict than @xmath8 we broaden the prior by a factor of two , leading to a gaussian prior given in eqn .",
    "( [ om ] ) .",
    "as discussed earlier , we also allow for an uncertainty in the overall calibration of the supernova data , @xmath34 .",
    "we choose a wide , uniform prior for @xmath34 given in eqn .",
    "( [ h0 ] ) .",
    "we consider two cases in all the analyses presented in this paper . in the first case we fix @xmath67 to a fiducial value and",
    "reconstruct @xmath0 .",
    "this allows us to focus on biases due to assumed parametric forms ( parametric models ) or possible shortcomings due to the ill - posedness of the inverse problem ( gp methodology ) . in the second case ,",
    "we let @xmath67 be a free variable within the specified prior , allowing us to study problems with degeneracies that are highlighted when @xmath6 is a nontrivial function of redshift .",
    "the simplest extension beyond a cosmological constant is to assume that @xmath0 is redshift independent . in this case ,",
    "( [ tildemu ] ) simplifies to @xmath84^{-1/2}\\right\\}.\\end{aligned}\\ ] ] current data are in good agreement with this assumption .",
    "we will use the ansatz @xmath69 as a first test in attempting to reconstruct all three datasets . as discussed previously ,",
    "an mcmc algorithm is employed with the chain being run about 10,000 times .",
    "convergence is very quickly attained , within about the first one hundred iterations .",
    "figure  [ wconst ] shows the results for the case where we fix @xmath53 and assume perfect calibration .",
    "as expected , the reconstruction works extremely well for the model where in fact @xmath8 ( left panel ) . the best fit value for @xmath85 and its probability intervals ( pis ) are given in table  [ table : m1 ] and match the chosen value within small errors .",
    "not surprisingly , the results for the models with time varying @xmath6 are rather inaccurate . for dataset 2 , the value for @xmath6 is predicted slightly higher than the average would be . in general , a larger @xmath6 leads to a lower @xmath62 . as can be seen in figure  [ data ]",
    ", @xmath86 is slightly below the @xmath4cdm model for this dataset .",
    "the one - parameter best fit for @xmath85 therefore has to be high in order to capture this behavior , if we do not allow any other parameter to vary . for the third dataset",
    ", we find a similar situation .",
    "as can be seen in figure  [ data ] in the right panel , @xmath62 is below the fiducial model . capturing this behavior with only one parameter to vary , @xmath85 , leads to a value @xmath87 in order to fit the behavior in @xmath86 reasonably well .",
    ".@xmath8 - 95% probability intervals ( pis ) [ cols=\"^,^,^,^,^ \" , ]     [ table : mse ]     residuals for @xmath11 considering the predictions for @xmath6 for dataset 3 with @xmath67 and @xmath88 free .",
    "the left plot shows the result for the @xmath89 parametrization , the right plot shows the results for the gp approach.,title=\"fig : \" ]   residuals for @xmath11 considering the predictions for @xmath6 for dataset 3 with @xmath67 and @xmath88 free .",
    "the left plot shows the result for the @xmath89 parametrization , the right plot shows the results for the gp approach.,title=\"fig : \" ]    table  [ table : mse ] shows a simple measure of how well the exact functional form of @xmath0 has been captured by the three different approaches .",
    "we calculate the mean square error of the reconstructed history for @xmath0 with respect to the perfect input @xmath0 as shown in the lower panels of fig .",
    "[ data ]  the smaller the error the better the reconstruction result",
    ". this simple test has two minor shortcomings ",
    "first , it does not account for the realization noise in the history of @xmath0 underlying the simulated data",
    "so the error will never be zero . in order to obtain the true @xmath0 we would have to perform two derivatives of the noisy simulated data which would render this test basically meaningless .",
    "second , the error bands of the predictions are not taken into account . nevertheless , this comparison should provide some information about how well the different methods perform compared to each other .",
    "for the first dataset @xmath66 .",
    "the parametric reconstruction ansatz @xmath90 provides  not surprisingly  the best results ; the history for @xmath0 is captured extremely well as is @xmath67 with small errors . for dataset 1",
    ", the gp model provides a more accurate answer than the @xmath89 parameterization in the case of @xmath67 free .",
    "this is mainly due to the fact that once the parameterized form has picked up some curvature in @xmath0 , the reconstructed @xmath0 will depart more and more from @xmath66 at higher @xmath57 .",
    "the gp model however is flexible enough to avoid such a behavior and stays close to @xmath5 over the whole redshift range . for dataset 2 ,",
    "the gp model performs slightly better than the two parametric reconstruction approaches for similar reasons as for dataset 1 .",
    "the @xmath89 parametrization picks up some time - dependence in the low-@xmath57 regime which overestimates the curvature of @xmath0 at higher @xmath57 while the gp approach reconstructs @xmath0 reasonably well over the whole redshift range and therefore has a smaller mean square error . for the third dataset ,",
    "the mean square error for the gp model is smallest in the case of @xmath67 fixed but for @xmath67 free kept it is worse than the result from the @xmath89 parametrization . for this last case",
    "( dataset 3 and @xmath67 and @xmath88 free ) we employ another assessment of the accuracy of the prediction which highlights the well - known degeneracy between @xmath6 and @xmath67 .",
    "we only consider the @xmath89 parametrization and the gp model approach for this test , since the @xmath8 parametrization has obvious shortcomings in this case .",
    "for each case we fit the @xmath0 result and then we find the associated fit for @xmath11",
    ". then we determine the difference between the predicted @xmath11 and the input @xmath11 for our simulated data . we show the residuals in figure  [ residuals ] .",
    "the left figure shows the residuals for the @xmath89 parametrization , the right figure for the gp reconstruction .",
    "the solution for @xmath0 found with the gp model is clearly a good fit to the data  it performs slightly better than the parametrized form in the low redshift range .",
    "due to the the degeneracy between @xmath6 and @xmath67 the overall reconstruction of @xmath0 is on the other hand worse for the gp model  this result will improve with tighter constraints on @xmath67 and complementary datasets such as bao measurements which help to break the degeneracy .",
    "characterizing the behavior of the dark energy equation of state is a first step in understanding the nature and origin of dark energy .",
    "although a simple cosmological constant model is consistent with current observations , the implied numerical value has no theoretical explanation .",
    "alternative dynamical models of dark energy generically predict time variations in @xmath6 and a robust detection of such a time dependence is one of the first targets in dark energy studies .",
    "supernova measurements remain a very promising probe of @xmath0 and future sky surveys can in principle measure @xmath0 with high accuracy .    in order to fully exploit the power of future measurements ,",
    "a reliable and robust reconstruction method is required . in this paper",
    "we have introduced a new reconstruction approach based on gp modeling .",
    "the approach is nonparametric with modeling hyperparameters constrained directly from the data .",
    "we have demonstrated that we can extract nontrivial behavior of @xmath6 as a function of redshift with data of the quality expected from future surveys .",
    "we have contrasted our new method against two approaches , an assumed cosmological constant , and one with a simple two - parameter model of the variation of @xmath0 .",
    "both of these models are effective descriptions for only a limited class of possible behaviors of @xmath0 .",
    "in contrast , the generality of the gp approach results in accurate reconstruction of potentially complex variability in @xmath0 .",
    "the gp model approach makes only mild smoothness assumptions about @xmath0 which are reasonable if we expect that the accelerated expansion of the universe is due to a physically well motivated reason .",
    "the major ingredient for the gp model is specified by the covariance function @xmath91 .",
    "while the choice of the specific form for @xmath91 is up to the modeler , the gp approach is rather robust to this choice and the major hyperparameters influencing @xmath91 are informed by the data themselves .",
    "in addition to choosing a covariance function , we have to specify a set of priors for cosmological and model parameters .",
    "these priors have to be broad enough to include the truth but should not be so broad that the bayesian approach does not converge .",
    "both model and cosmological parameters are then jointly determined from the data .",
    "while the bayesian approach is computationaly rather intensive , it has the great advantage that it provides robust error bands .",
    "the approach outlined here for the analysis of supernova measurements can easily be extended to include different cosmological probes such as data from cmb and bao observations ; work in this direction is currently in progress .",
    "moreover , the gp - based mcmc procedure can be integrated within supernova analysis frameworks , e.g. , snana  @xcite as a cosmology fitter , following the general methodology presented in ref .  @xcite .",
    "in this appendix we provide implementation details of the gp algorithm used to reconstruct @xmath0 .",
    "the gp model approach requires the estimation of several variables : the correlation hyperparameters ( @xmath3 and @xmath92 ) , the gaussian process points [ @xmath93 with @xmath94 , or rather @xmath95 with @xmath96 , the variance parameter ( @xmath83 ) , along with the physical parameters of interest ( @xmath67 and @xmath34 ) . @xmath67 and",
    "@xmath34 can be added as extra steps ; for simplicity we do not include them in the discussion here ( we did include them in our analysis presented in the main body of the paper . )    a gaussian process is defined by its mean and correlation function .",
    "we set the prior mean of the gaussian process to @xmath97 for stability ; other values are found to be equally acceptable when the true mean of @xmath0 is near @xmath97 .",
    "even though the mean is fixed , the posterior mean will not be exactly @xmath97 but will have a distribution spread around @xmath97 . in the case when the true mean is not @xmath97 the posterior value of the mean of @xmath0",
    "will indicate this .",
    "preliminary exploration of the posterior of @xmath0 can then be used to set the prior mean for subsequent runs , which provides more stable results .    in the correlation function",
    ", the parameter @xmath98 should be set as a constant beforehand in the range of 1 to 1.9999 , setting it exactly equal to 2 can cause numerical instability in the covariance matrix , and values above 2 are not mathematically valid values for the process .",
    "the parameter @xmath98 controls the smoothness of the overall gp : @xmath99 will produce a flexible continuous gp but it will not be differentiable anywhere , while @xmath100 produces a much smoother continuous gp that is infinitely differentiable everywhere . in order to allow for maximum flexibility we choose @xmath101 throughout the paper .",
    "the correlation length @xmath3 is a free parameter in the gp model and its value is informed by the data .",
    "it is highly correlated to @xmath98 and @xmath92 which makes the interpretation of its final value not straightforward .",
    "it is strictly limited to the region of [ 0,1 ) and the gp is not defined for the limiting case of @xmath102 . after investigation we found that @xmath3 has a much smaller role in the determination of the nature of the gp in comparison to @xmath98 and @xmath92 .",
    "integration of the gaussian process requires a grid for numerical integration .",
    "let @xmath103 be the number of supernova data points in our dataset , and @xmath104 be a finite number of gaussian process points over this region for evaluation . during the integration we add @xmath105 partition points between each gp point .",
    "our resulting integrated process @xmath95 has @xmath106 points .",
    "this provides a dense enough grid to carry out an accurate numerical integration for the outer integral without slowing down the computations .",
    "we find that an @xmath104 around 50 to 100 is sufficient , and an @xmath107 between 3 and 5 is a good balance between accuracy and speed .    as with the parametric models , we employ bayesian methods where we use our priors and likelihood to obtain a posterior that can then be sampled with an mcmc algorithm . in our case , with our given likelihood function ( given in eqn .",
    "( [ l ] ) ) , this leads to the following posterior for the parameters of interest : @xmath108 @xmath109 here denotes an arbitrary gp with parameters @xmath92 and @xmath3 .",
    "@xmath83 is the unknown variance parameter from the likelihood equation and @xmath57 , @xmath11 , and @xmath110 are `` observed '' values from the simulated dataset .    instead of the usual gaussian process formulation shown in eqn .",
    "( [ a1 ] ) , we choose an altered form to allow for slower changes in the gp and a more localized search .",
    "we let @xmath111 and @xmath112 .",
    "this leads to the following posterior : @xmath113 in this setup , we propose a gp @xmath114 and transform it to @xmath109 .",
    "we then keep track of @xmath114 and make our next proposal based on these values and not on the @xmath109 .",
    "thus we are allowing the proposal to make finer changes each time to boost the acceptance rate , which tends to be problematic if we were to propose @xmath109 directly .      1 .",
    "initialize all variables : @xmath115 , @xmath116 , and @xmath117 .",
    "@xmath93 will be a vector with @xmath104 points in our gp and @xmath95 has @xmath106 points .",
    "we run this algorithm @xmath118 times . set all tuning parameters , @xmath119 , which need to be tuned until good",
    "mixing occurs .",
    "2 .   propose @xmath120 1 .",
    "compute the covariance matrix @xmath121 2 .   compute the cholesky decomposition for @xmath122 3 .",
    "compute the special @xmath123 with chebyshev - gauss quadrature .",
    "we want @xmath124[\\kappa_{q-1}^2 k_{22*}^{-1}](w_{\\rho^*}(u)-(-1))$ ] where @xmath125w^o_{m , q-1 } + ( -1)$ ] + @xmath126[\\kappa_{q-1}^2k_{22*}]^{-1}(\\left(\\kappa_{q-1}u_{\\rho^*}'w^o_{m , q-1 } + ( -1)\\right)-(-1))\\\\                & = -\\ln(1+s)+\\kappa_{q-1}k_{12*}[(u_{\\rho^*}'u_{\\rho^*})^{-1}u_{\\rho^ * } ' ] w^o_{m , q-1}\\\\               & = -\\ln(1+s)+\\kappa_{q-1}k_{12*}[u_{\\rho^*}^{-1}]w^o_{m , q-1 }               \\end{aligned}\\ ] ] 5 .",
    "@xmath127 where the definite integrations in @xmath128 are done numerically through summations of the trapezoid algorithm",
    ". 6 .   accept the proposal @xmath129 with probability @xmath130 let @xmath131 , otherwise @xmath132 .",
    "draw @xmath133 1 .",
    "compute @xmath134w^o_{m , q-1}$ ] + 2 .",
    "@xmath135 where the definite integrations in @xmath136 are done numerically through summations of the trapezoid algorithm .",
    "3 .   accept with probability @xmath137 .",
    "we propose a non - standard @xmath138 for the gp .",
    "we start by drawing a proposal for @xmath139 , where @xmath140 is the identity matrix .",
    "1 .   compute @xmath141w^{o*}_{m,}$ ] + 2 .",
    "@xmath142 3 .   accept with probability @xmath143 letting @xmath144 and the corresponding gp realization is @xmath145 5 .",
    "@xmath146 + 6 .",
    "repeat steps 2 - 6 , @xmath147 times and rerun the entire algorithm as needed after resetting the tuning parameters    the authors acknowledge support from the lanl institute for scalable scientific data management .",
    "part of this research was supported by the doe under contract w-7405-eng-36 .",
    "ua , sh , kh , and dh acknowledge support from the ldrd program at los alamos national laboratory .",
    "kh was supported in part by nasa .",
    "sh and kh acknowledge the hospitality of the aspen center for physics , where part of this work was carried out .",
    "we are indebted to andreas albrecht , eric linder , adrian pope , martin white , and michael wood - vasey for several useful discussions .                      c.  wetterich , nucl .",
    "b * 302 * , 668 ( 1988 ) ; b.  ratra and p.j.e .",
    "peebles , phys .",
    "d * 37 * , 3406 ( 1988 ) ; p.j  e.  peebles and b.  ratra , astrophys .  j.  * 325 * , l17 ( 1988 ) ; r.  r.  caldwell , r.  dave and p.  j.  steinhardt , phys .",
    "* 80 * , 1582 ( 1998 ) ."
  ],
  "abstract_text": [
    "<S> a basic aim of ongoing and upcoming cosmological surveys is to unravel the mystery of dark energy . in the absence of a compelling theory to test , </S>",
    "<S> a natural approach is to better characterize the properties of dark energy in search of clues that can lead to a more fundamental understanding . </S>",
    "<S> one way to view this characterization is the improved determination of the redshift - dependence of the dark energy equation of state parameter , @xmath0 . to do this </S>",
    "<S> requires a robust and bias - free method for reconstructing @xmath0 from data that does not rely on restrictive expansion schemes or assumed functional forms for @xmath0 . </S>",
    "<S> we present a new nonparametric reconstruction method that solves for @xmath0 as a statistical inverse problem , based on a gaussian process representation . </S>",
    "<S> this method reliably captures nontrivial behavior of @xmath0 and provides controlled error bounds . </S>",
    "<S> we demonstrate the power of the method on different sets of simulated supernova data ; the approach can be easily extended to include diverse cosmological probes . </S>"
  ]
}