{
  "article_text": [
    "since the discovery of quasars ( schmidt 1963 ) , ambitious surveys ( e.g. , schmidt & green 1983 ; foltz et  al .",
    "1987 ; boyle et  al .",
    "2000 ; york et  al .",
    "2000 ) have caused the number of known quasars to rise from one to tens of thousands . yet even in this day of very large surveys and deep digital imaging , we are still far from identifying the more than 1.6 _ million _",
    "@xmath4 quasars that are expected to fill the celestial sphere to @xmath5 .",
    "the problem lies not in covering enough of the sky to faint enough magnitudes , but rather in the efficient separation of quasars from other astronomical sources .",
    "current algorithms are typically more than 60% efficient for uv - excess ( uvx ) quasars to relatively bright magnitudes , but the selection efficiency drops toward fainter magnitudes where the photometric errors are largest and most of the observable objects reside . further complicating the issue",
    "is the need to obtain spectra for each candidate .",
    "thus surveys of quasars would benefit considerably from algorithms with selection efficiencies that mitigate the need for confirming spectra .",
    "we describe such an algorithm based on the photometric data of the sloan digital sky survey ( sdss ; 2000 ) .    optical surveys for quasars , including the sdss , typically rely on simple color cuts in two or more colors to select objects that are likely to be quasars and to reject objects that are unlikely to be quasars .",
    "the color selection part of the sdss s quasar algorithm ( richards et  al .",
    "2002 ) is essentially two , 3-d color selection algorithms .",
    "one branch of the algorithm uses the @xmath6 bands to identify uvx quasars , the other uses the @xmath7 bands to identify @xmath8 quasars .",
    "another way to select quasars from imaging data is to use known quasars to determine what regions of color space quasars occupy .",
    "once these regions have been identified , spectroscopic quasar target selection involves simply observing objects from those regions of color space that are most likely to yield quasars ( or perhaps least likely to yield significant number of contaminants ) . at the beginning of the sdss survey",
    ", the construction of such an algorithm would have been difficult given the lack of data , but with the current abundance of sdss imaging data and spectroscopic follow - up , it is now possible to design such algorithms .    the approach used in this paper is based on the simple philosophy that the most efficient and complete way to find quasars is to target those regions of color space dominated by quasars and/or that have sufficiently low rates of contamination that we can afford to probe them for quasars . to accomplish this goal , we take advantage of an existing statistical technique known as kernel density estimation ( kde ; silverman 1986 ; gray et al .",
    "2004 ) . by applying this technique to `` training sets '' of stars and quasars",
    "we can optimally classify `` test sets '' of potential quasar candidates .",
    "our algorithm takes advantage of and goes well beyond the color - characterization of small samples of quasars ( e.g. , richards et  al .",
    "2001a ) , to efficiently select quasars ( or other objects for that matter ) from much larger samples of 5-band sdss imaging data .",
    "in fact , the algorithm is so efficient that the failure rate is comparable to that of automated identification of quasar _ spectra _ from the sdss , and thus , for many science applications , spectroscopy is _ not _ needed .",
    "furthermore , we capitalize on the structure in the quasar color - redshift relation to compute relatively accurate photometric redshifts ( richards et  al . 2001b ; budav '",
    "ari et  al .",
    "2001 ; weinstein et al .",
    "2004 ) for all the resulting quasar candidates .",
    "the end product is a catalog of over 100,000 @xmath4 quasar candidates with photometric redshifts that were selected from the 2099 deg@xmath1 of sdss dr1 imaging data .    in ",
    "2 we describe our input data .",
    "section  3 presents an overview of the algorithm and the details of its application . in   4 we present the catalog and discuss its completeness and efficiency along with matching to other catalogs and the computation of photometric redshifts .",
    "section  5 presents some ideas for future improvement and   6 discusses some science highlights .",
    "the imaging data that was used as the basis for our catalog is contained in the sdss first data release ( dr1 ; 2003 ) .",
    "the sdss is a project to map roughly 10,000 deg@xmath9 of sky in 5 photometric passbands ( @xmath10 ) using a large - format ccd camera ( gunn et  al .",
    "the characterization of the photometric system is discussed by ( 1996 ) , ( 2001 ) , ( 2002 ) , and ( 2002 ) . unless otherwise stated , all magnitudes discussed herein are `` asinh '' point - spread - function magnitudes ( lupton , gunn , & szalay 1999 ) that have been dereddened according to , finkbeiner , & davis ( 1998 ) .",
    "the astrometric accuracy of the survey ( and thus of the catalog presented herein ) is better than 100 mas per coordinate rms ( pier et  al .",
    "our work further makes use of the spectroscopic follow - up of quasars ; the selection algorithm is described by ( 2002 ) , the tiling algorithm by ( 2003 ) , and the dr1 spectroscopic quasar catalog by ( 2003 ) . in  ",
    "[ sec : train ] and [ sec : test ] we describe the cuts that were applied to the imaging data to construct our training and test sets .",
    "the basic idea of our quasar selection algorithm is conceptually as follows .",
    "we wish to classify a set of unlabeled objects ( the _ test set _ ) as either stars or quasars .",
    "we first create samples of `` stars '' and `` quasars '' that will serve as _",
    "training sets_. for each object in our test set that we wish to classify , we compute its probability of being a star and its probability of being a quasar .",
    "the test object is assigned the label corresponding to the higher probability .",
    "the `` probability of being a star '' for an object @xmath11 ( represented by four color measurements ) can be formalized as the likelihood of @xmath11 under the probability density function ( pdf ) which describes stars , i.e. , @xmath12 , where @xmath13 , or class 1 , is the star class .",
    "this pdf could be represented , for example , as a histogram .",
    "because our measurement space consists of four color dimensions , this would correspond to a 4-d grid of counts .",
    "instead , we will use a _ kernel density estimate _ ( kde ; silverman 1986 ) of the pdf of stars .",
    "this mature statistical method is a powerful generalization of the concept of a histogram which yields a more accurate estimate of the true underlying pdf . instead of discrete bins",
    "whose locations are defined by a grid , kde defines each ` bin ' by its center point and the extent of the bin by a continuous _ kernel function _  for example a gaussian function in 4-d .",
    "we describe kde in more detail later in the paper . for an introduction to density estimation , we refer the reader to silverman ( 1986 ) .    once we have a way of estimating the likelihood of @xmath11 being a star ( or quasar ) , or the value at @xmath11 of the star pdf ( or quasar pdf ) , we could simply choose the class corresponding to the higher likelihood .",
    "however , we will incorporate one further piece of information before determining the `` probability of being a star ''  the user s prior belief that the object is a star , denoted @xmath14 .",
    "this captures any and all subjective information which the user may have outside of observing the actual training set  namely here , the fraction of an unseen set of objects which the user roughly expects to be stars . to incorporate this prior information with the likelihoods given by kde",
    ", we use a simple application of bayes rule ( bayes 1763 ; press et  al .",
    "1992 ) , which weights each likelihood with its corresponding prior probability to obtain the a posterior probability of being a star or quasar :    @xmath15    specifically , in our context , objects with @xmath16 are classified as stars , while objects with @xmath17 are classified as quasars .",
    "we refer to the resulting overall classifier as a nonparametric bayes classifier ( nbc ) , for lack of a standard name in the statistical literature .      for the quasar training set",
    ", we simply used the four primary sdss colors ( @xmath18 , @xmath19 , @xmath20 , @xmath21 ) of the 16,713 quasars from ( 2003 ) without applying any additional cuts based on luminosity , morphology , method of selection , photometric errors , etc .",
    "these quasars span redshift and magnitude ranges of @xmath22 and @xmath23 .    for the stars training set",
    ", we used the four primary sdss colors extracted from a random sample of 10% of all point sources in the sdss s photometric database .",
    "morphologic classification accuracy is a function of magnitude , being nearly perfect for @xmath24 , but only 90% accurate at our @xmath0 limit . ] in the dr1 imaging area with @xmath25 .",
    "we rejected any objects that did not pass the photometric quality tests that the sdss quasar algorithm applies before it does color - selection .",
    "specifically , we rejected those objects that failed the `` fatal '' or `` non - fatal '' error tests ; see ( 2002 ) for details .",
    "finally , since we have included _ all _ point sources  including quasars  in the stars training set , we have also rejected any spectroscopically confirmed quasars and any radio sources ( which , for unresolved sources , are more likely to be quasars than anything else ) .",
    "the total number of objects in the initial stars training set was 478,144 .",
    "the final stars training set that we used to classify our objects went through an additional `` cleaning '' pass described in   [ sec : clean ] .",
    "the goal of this paper is to present a `` proof - of - concept '' of the nbc approach to efficient selection of astronomical objects .",
    "thus we start where quasar selection is admittedly easiest .",
    "the test set for which we have determined star / quasar classifications consists of sdss - dr1 point sources with @xmath26 , i.e. , uvx sources that were selected from the photoprimary dr1 database table . currently we exclude sources that are resolved in the sdss imaging data .",
    "we further restrict the sample to those objects with observed @xmath27 magnitudes fainter than 14.5 , dereddened @xmath27 magnitudes brighter than 21.0 , and @xmath28-band errors less than 0.5 mag ( i.e. , are at least @xmath29 detections in @xmath28 ) .",
    "we use the @xmath27 band instead of @xmath30 since our selection is a uvx one , meaning that our quasar candidates will generally have @xmath4 and little @xmath27-band ly@xmath31 forest absorption ; this choice also facilitates comparison with previous work such as the 2df qso redshift survey ( 2qz ; 2004 ) . as with the stars training set above",
    ", we reject objects that fail the `` fatal '' or `` non - fatal '' error tests used by the official sdss quasar selection algorithm ( richards et  al .",
    "the full test set contains @xmath32 objects .",
    "once we have defined the training and test sets we can begin the process of classification by computing the likelihood of each object @xmath11 in the test set with respect to each training set ( or equivalently , the density at @xmath11 under the stars and under the quasars ) , using the nonparametric ( i.e. , distribution - free ) _ kernel density estimator _ :",
    "@xmath33 where @xmath34 is the number of data points , @xmath35 is called the kernel function and satisfies @xmath36 , @xmath37 is a scaling factor called the bandwidth , and @xmath38 is the `` distance '' between a point in the test set to a point in the training set ( in our case , these distances are 4-d euclidean color differences , @xmath39 ) . in this work",
    "we mainly use a gaussian kernel , where the bandwidth corresponds to the variance of the gaussian , i.e. @xmath40 . to make an analogy with a 1d histogram ( the simplest kind of density estimator )",
    ", the reader can think of a 1d histogram with a bin width of @xmath37 as being a kernel density estimator with @xmath41 and with the location of the bins being fixed rather than being centered at the individual data points .",
    "kernel density estimation is the most widely - used and well - studied method for nonparametric density estimation , owing to both its simplicity and flexibility , and the many theorems establishing its consistency for near - arbitrary unknown densities and rates of convergence for its many variants .",
    "see silverman ( 1986 ) for more details regarding the concept of kernel density estimation .",
    "a naive algorithm for computing the kernel density estimate at one point among @xmath34 points requires @xmath34 distance operations . computing the density estimate at @xmath34 points among @xmath34 points thus scales as @xmath42 .",
    "this is intractable for large datasets such as ours .",
    "we use a fast computational algorithm based on space - partitioning trees and principles similar to those used in @xmath34-body solvers ( gray & moore 2003 ) .",
    "we will refer to this as the `` fast kde '' algorithm .    for the work in this paper a second",
    ", new algorithm was developed , for the different computational problem of _ quickly finding the higher posterior probability _ ,",
    "i.e. , finding the label for each test point more quickly than by explicitly finding its density under each of the two class training sets . a detailed description of the modifications of the standard nbc algorithm to make it faster are beyond the scope of this paper and will be described in a future publication ( gray et al .",
    "we will refer to this algorithm as `` fast nbc '' .",
    "the fast nbc algorithm need not estimate the density completely for each object to be classified .",
    "the algorithm need only maintain upper and lower bounds on the density for each class ; the code stops considering additional data when it finds that the bounds no longer overlap .",
    "it is exact , i.e. , computes the classification labels as if the kernel density estimates had been computed exactly . for additional speed",
    "we use an epanechnikov kernel for this step , which is gaussian - like but has finite rather than infinite extent .",
    "the resulting bandwidths are then scaled appropriately to find the optimal bandwidth for a true gaussian kernel .",
    "of the entire coverage . ]      the critical step in the kde process is determining the optimal `` bandwidths '' for kernel density estimation , i.e. , the bandwidth that spans the color space of each training set most efficiently .",
    "this process is similar to that of deciding upon the best bin size to represent data in a histogram ; using too small of a bin can cause artificial spikes in the histogram due to small number statistics , whereas using too large of a bin can hide real information ( silverman 1986 ) .",
    "there exist mature algorithms for choosing the bandwidth for kde which minimize a statistical measure of the difference between the true underlying pdf and the estimated pdf .",
    "perhaps the most accepted method for performing this is _",
    "least squares cross - validation _ ( silverman 1986 ) .",
    "initially we used this method to automatically determine the optimal bandwidths for the two classes separately .",
    "however , with a half million objects in the stars training set , this method of computing the ( optimal ) bandwidth was too computationally intensive .",
    "furthermore , this approach corresponds to nbc where the priors are equal , and where the bandwidths for the stars and quasars are estimated _ independently _ , based on a statistical criterion ( leave - one - out , cross - validated , least - squares error ) for optimal _",
    "density estimation _ for each class .",
    "instead , we chose the bandwidth pair using a statistical criterion for optimal _ classification accuracy _ ( leave - one - out , cross - validated accuracy , in this case . )",
    "this has significant advantages over the previous method .",
    "first , it considers the bandwidths for both training sets simultaneously , as a pair , rather than independently .",
    "optimal bandwidth selection for density estimation is known to be a difficult statistical problem . estimating each bandwidth independently compounds the problem that the true criterion of interest is the behavior of both bandwidths in unison , in terms of the performance of the resulting classifier ; estimating parameters for a classifier is known to be a statistically easier problem ( for example in terms of convergence rate ) .",
    "secondly , the density estimation approach is inherently more computationally difficult . as noted above , the fast kde algorithm",
    "( gray & moore 2003 ) must inherently perform more work than the fast nbc algorithm used here ( gray et al .",
    "using the fast nbc algorithm allows quick computation of the leave - one - out accuracy score for each pair of bandwidths for our two training sets .    in the context of leave - one - out accuracy ,",
    "one ideally determines the bandwidths by maximizing the classification accuracy of each training set simultaneously .",
    "however , in our case , we fully expect the algorithm to misclassify some quasars as stars .",
    "for example a small fraction of quasars are known to be dust reddened and are more likely than unreddened quasars to have colors more similar to stars . similarly , we are aware that the definition of our star training set is not exclusive to stars .",
    "thus we chose to maximize the classification accuracy after first accounting for reasonable expectations for misclassification .",
    "the best resulting bandwidth was 0.15 mag for each of the training sets , which resulted in an accuracy of 94.48% for the quasars and 97.91% for the stars .",
    "once we have bandwidths for each of our training sets , we can simply apply them to our test set to classify our objects .",
    "however , before final classification of our test set , we first chose to clean the stars training set by running it through the algorithm as a test set since our `` stars '' training set really consists of objects that are known only to be point sources . therefore , we have removed from the stars training set any objects that were classified by nbc as quasars . the final `` cleaned '' training",
    "set of stars contained @xmath43 objects .",
    "this process is admittedly somewhat circular , but is appropriate for the goal of this paper , which is to produce a sample that is as efficient as possible , leaving improvements in completeness to later work . after having thus cleaned the stars training set , the same @xmath44 mag bandwidths resulted in an accuracy within the training sets of 95.86% for the quasars and 99.89% for the stars .",
    "once the two bandwidth parameters ( from the quasars and cleaned stars training sets ) are finalized , we proceed with the classification of the objects in the test set , by computing @xmath45 for each test object @xmath11 .",
    "we use the bayesian prior @xmath14 = 0.88 .",
    "this is based on the fraction of objects in our test set that we believe are likely to be stars ( 88% ) given previous testing of the algorithm .",
    "the nbc classification of our @xmath32 uvx point source objects resulted in @xmath46 ( 13.7% ) objects classified as quasars and @xmath47 ( 86.3% ) classified as stars .",
    "the color distribution of these @xmath46 does indeed strongly resemble that of the input quasar training set .",
    "however , it was obvious that there was still a considerable amount of contamination , primarily faint f - stars , which have errors and metallicities that push them well into the usual quasar locus . since our current algorithm considers only the colors and not magnitudes ( see   [ sec : future ] ) , these objects are difficult to remove with the nbc algorithm and a single prior .    thus , the initial classification was supplemented by going back and computing the full kde star / quasar densities for each of the @xmath46 objects that were classified as quasars . in this process we used a gaussian rather than an epanechnikov kernel and bandwidths @xmath48 the size of the above ( see above ) , which yields specific quasar / star densities for each object as opposed to simple binary classification .",
    "this calculation is now feasible since the number of objects under consideration has been reduced from the original @xmath32 to @xmath46 and we have already decided on a bandwidth to use .",
    "the left panel of figure  [ fig : fig1 ] shows the log of the kde - computed quasar density vs.  star density for those objects classified by the nbc algorithm as quasars .",
    "objects classified as stars ( not shown ) populate the upper - left part of the diagram . also evident in this panel",
    "is an island of objects ( upper right ) with similar quasar and star densities .",
    "analysis of the color distribution ( fig .",
    "[ fig : fig2 ] ) of these objects suggests that they are stellar contaminants ; they can be excised with a simple cut on stellar density ( dashed line in left panel of fig .",
    "[ fig : fig1 ] ) .",
    "thus , for the final catalog , nbc - classified quasars were rejected if the stellar density exceeded @xmath49 .",
    "the right panel of figure  [ fig : fig1 ] plots the log of the ratio of the quasar density to star density .",
    "larger values indicate greater quasar probability .",
    "objects classified as stars by nbc , which would occupy the region beyond the left extent of the plot , have already been removed .",
    "plotted are both those objects initially classified as quasars by the nbc algorithm ( _ dotted line _ ) and those objects that also pass the stellar density cut shown by the dashed line in the left - hand panel ( _ solid line _ ) .",
    "our cut in stellar density is seen to remove objects roughly starting at the minimum between the quasar and the residual star distributions .",
    "the color distribution of the final classification scheme is shown in figure  [ fig : fig2 ] .",
    "the reader will notice in the above description that there is no mention of the photometric errors of the objects ; this is because we do not use them explicitly .",
    "however , we do make implicit use of the errors in the sense that they are `` in the model '' .",
    "that is , when we ask what the relative quasar / star likelihoods are for a given object , the answer automatically takes into account the smearing of the color distribution in the training sets due to photometric errors .",
    "if the magnitude ( and thus error ) distributions of the training sets were similar , this process is arguably an appropriate manner in which to handle errors .",
    "that is because we are asking how likely it is for an object to be scattered out of the stellar locus , given the distribution of all stars ( which includes the photometric errors ) rather than asking whether an object could conceivably be `` pushed back '' onto the stellar locus given the individual errors of the object .",
    "there is a difference between the two since a quasar that is much redder than the stellar locus ( in @xmath18 ) is necessarily much fainter in @xmath28 than a star on the stellar locus with the same @xmath19 color but a bluer @xmath18 color .",
    "that is , it is much more likely that including the errors of a quasar will cause it to be consistent with the stellar locus than it is for the errors of a star in the locus to move it out to the location of a quasar with the same @xmath19 color ; see ( 2002 ) for further discussion of this issue as it affects the sdss s selection of quasars .",
    "this method of error handling clearly ignores the fact that the errors are a function of magnitude and the fact that our quasar training set has fewer faint objects relative to the stars training set .",
    "objects as faint as @xmath50 . ]",
    "as we try to push our selection method to fainter magnitudes , accounting for the magnitude dependence of the errors will become important (   [ sec : future ] ) , but for our current limit of @xmath0 , the typical error on the @xmath18 color at the faint limit is only @xmath51 mag , which is not enough to adversely affect our selection method especially since the bandwidth is @xmath44 mag . in the future we hope to perform a _ weighted _ kde analysis , which will allow one to attach a weight ( such as the inverse variance ) to every point .",
    "after application of the nbc algorithm to identify quasars and further cleaning of this sample by rejecting objects with large kde stellar probabilities we are left with @xmath52 quasar candidates that define this catalog .",
    "these next sections describe the completeness and efficiency of the catalog along with matching to other catalogs .",
    "table  [ tab : tab1 ] is the catalog itself .",
    "( the complete version of this table is in the electronic edition of the journal ; the printed edition contains only a sample . )",
    "table  [ tab : tab2 ] provides a description of each column in table  [ tab : tab1 ] .",
    "the catalog is also available at http://sdss.ncsa.uiuc.edu/qso/nbckde/ , where updates will be posted .",
    "figure  [ fig : fig3 ] shows the @xmath27 magnitude distribution of all sources in the catalog , while figure  [ fig : fig4 ] shows the distribution of sources on the sky .",
    "the completeness of the sample is difficult to quantify since our selection extends to both brighter and fainter magnitudes than either of the sdss and 2df ( croom et  al .",
    "2004 ) quasar surveys . however , it is easy to ask what fraction of sdss - dr1 quasars are recovered that should be recovered .    of the 16,713 sdss - dr1 quasars in the ( 2003 ) catalog ,",
    "14,592 meet our magnitude , error , and color selection cuts . among those 14,592 ,",
    "13,574 are actually in the test set that formed the basis for our catalog .",
    "most of the 1018 `` missing '' objects result from the fact that we are using only that imaging area that formally belongs to the dr1 release whereas the ( 2003 ) catalog included all quasars found within any `` stripe '' that was part of the dr1 release .",
    "other objects are missing because of changes to the object parameters that result from using slightly different versions of the data processing pipelines . among those 13,574 sdss - dr1 quasars that the nbc algorithm could have recovered ,",
    "it actually recovered 12,856 or 94.7% .",
    "we expect roughly 5% additional incompleteness as a result of our filtering of objects via their photometric flags ( e.g. , those with `` fatal '' errors ) ; see ( 2004 ) for further discussion of the completeness of the sdss quasar survey .",
    "however , we caution that this completeness is only with respect to the reasonably bright quasars in the ( 2003 ) catalog and that we fully expect that 1 ) the catalog will be more incomplete with fainter magnitudes and that 2 ) the incompleteness of the whole catalog will be also be a function of redshift and color .",
    "in particular , the fact that we do not include magnitude as an explicit parameter in our selection algorithm ( other than limiting the magnitude ranges ) and the fact that the colors of stars appear to be a stronger function of magnitude than the colors of quasars , means that there are regions of color - space where we are likely to be more incomplete as a result of our desire to be as efficient as possible .",
    "utilization of the magnitudes ( see   5 ) in future applications of the algorithm should improve the completeness in such regions .",
    "we have additionally tested the completeness of the algorithm using simulations .",
    "application of the algorithm to simulated quasar colors constructed similarly to those of ( 1999 ) reveal that the algorithm is generally at least 95% complete between @xmath53 and @xmath54",
    ". some additional degree of incompleteness occurs at @xmath55 to @xmath56 for the reddest quasars as a result of our restriction to objects with low stellar likelihood ( see   3.8 ) . on the other hand ,",
    "the bluest quasars have a 95% completeness limit that extends to @xmath57 . at higher redshift ,",
    "the completeness drops rapidly and is difficult to characterize due to the complexity of accurately simulating quasar spectra blueward of ly@xmath31 emission ; furthermore we have restricted this catalog to uvx ( @xmath26 ) sources .      to estimate the efficiency of the catalog , we have matched it to three spectroscopic databases . first the sdss - dr1 quasar catalog ( schneider et  al .",
    "2003 ) , which includes only bonafide quasars ; these are objects that constituted part of the quasar training set and are labeled with i d `` dr1qso '' in the catalog .",
    "next we match to the 2qz ngp catalog ( croom et  al .",
    "2004 ) ; these objects are labeled with i d `` 2qz '' in the catalog and include quasars as well as non - quasars .",
    "we also extracted all `` good '' and specclass in ( 1,2,3,4,6 ) and zstatus in ( 3,4,6,7,9,11,12 ) '' . ] spectroscopic ids from the sdss - dr2 ( abazajian et al . 2004 ) database and matched them to our quasar candidate catalog .",
    "these `` dr2 '' objects are so labeled and include quasars as well as non - quasars .",
    "they are not meant to be a complete sample of all dr2 identifications , just those that with identifications that we can be reasonably certain are correct without having to look at the spectra by eye .",
    "users desiring a more complete sample may wish to perform a less restrictive matching .",
    "matching to these three catalogs was done in series in the order given , such that an object will only match the first occurrence .",
    "for example , any object that matched a sdss - dr1 quasar was not allowed to match any other catalog . in the future , matching against the faint quasars found in the recently combined sdss/2df quasar survey ( whose goal is to discover 10,000 quasars to @xmath58 using sdss imaging and the 2df spectrograph ; publication in preparation ) will allow for better characterization of the faint end of the sample .",
    "in all there were 22,737 matches to spectroscopically confirmed objects .",
    "a total of 22,191 , or 97.6% , were confirmed to be quasars ; figure  [ fig : fig5 ] shows the distribution of _ spectroscopic _ redshifts ( _ solid _ line ) along with the redshift distribution of re - discovered 2qz quasars ( _ dashed line _ ; 2004 ) .",
    "note that some redshifts are intrinsically harder for the sdss s automatic spectroscopic identification program to handle .",
    "our restriction to the most secure identifications when matching to the dr2 database causes a loss of quasars at certain redshifts ( e.g. , @xmath59 ) , which is plainly evident in figure  [ fig : fig5 ] .",
    "the distribution of _ photometric _ redshifts (   4.3 ) for all of the confirmed quasars is given by the _ dotted _ line in figure  [ fig : fig5 ] .",
    "the majority of the non - quasars appear to be relatively cool white dwarfs ( see   [ sec : propmo ] below ) .",
    "figure  [ fig : fig6 ] shows the efficiency as a function of @xmath27 magnitude for the above 22,737 spectroscopic identifications .",
    "comparison with figure  [ fig : fig3 ] reveals that the brightest magnitudes have very few objects in each bin  making these fractions less reliable , as indicated by the error bars in figure  [ fig : fig6 ] . applying the fractions as a function of magnitude to the overall magnitude distribution of the catalog",
    ", we expect that the overall efficiency of the catalog will be roughly 95.0% , yielding 95,502 quasars in all .",
    "it is difficult to extrapolate the efficiency for these confirmed objects to the entire sample since the selection algorithms of the three catalogs to which we matched are obviously different from that herein and we might , for example , be preferentially lacking spectra of non - quasars .",
    "however , the color distribution of those objects with matches appears to span the space occupied by the catalog as a whole .",
    "thus , we fully expect the catalog to be more than 90% efficient .",
    "in addition , some objects that were spectroscopically confirmed as galaxies or narrow emission line galaxies ( nelgs ) may indeed prove to be agn upon close examination .",
    "similarly , close inspection may reveal that some of the objects with cool white dwarf colors are actually bl lacs .",
    "contrasting with our estimated 95% efficiency is that which would be achieved by making a simple color - cut .",
    "for example , the uvx color - cut used by & green ( 1983 ) corresponds roughly to @xmath60 in the sdss photometric system .",
    "there are 97,035 objects with @xmath60 in the nbc catalog , whereas the input to our algorithm contains 139,161 such objects .",
    "if we make the extreme assumption that 95% of the uvx objects in our catalog are indeed quasars and that the excess in the input catalog consists of only contaminants , then this color cut would yield an efficiency ( quasars : quasar candidates ) of only 66.2% .",
    "this example gives a lower - limit to the efficiency that one can expect for a reasonably complete sample of uvx quasars ; further color - cuts could obviously be used to improve this efficiency .",
    "for each object in the catalog , we also report photometric redshifts that were determined via the method described in ( 2004 ) .",
    "this algorithm minimizes the difference between the measured colors of each object and the median colors of quasars as a function of redshift .",
    "we used the colors of uvx , @xmath28-detected dr1 , point - source quasars with spectroscopic redshifts as our color - redshift template , but using the entire dr1 quasar catalog produces similar results . for each object",
    "we list the most likely photometric redshift , a redshift range , and the probability that the redshift is within that range ; see ( 2004 ) for more details .",
    "the left panel of figure  [ fig : fig7 ] shows the spectroscopic versus photometric redshifts of the 22,191 confirmed quasars in the catalog , revealing those redshifts where the algorithm has the largest error rate ( either due to degeneracy between distinct redshifts or smearing of nearby redshifts ) .",
    "however , one can see from the highly zero - peaked distribution in the right panel that , overall , the quasar photo-@xmath38 algorithm performs quite well , with 19,086 ( 86.0% ) of the redshifts being correct to within @xmath61 and 14,371 ( 64.8% ) to within @xmath62 .",
    "figure  [ fig : fig8 ] shows the accuracy of the photometric redshifts as a function of redshift ( both spectroscopic and photometric , _ left panel _ ) and @xmath27 magnitude ( _ right panel _ ) for @xmath63 and @xmath64    the photo-@xmath38 code also gives a probability of an object being in a given redshift range ( where the size of that range can vary considerably ) .",
    "figure  [ fig : fig9 ] plots the estimated probability of the photometric redshift being in the given range versus the actual fraction of those objects with accurate photometric redshifts  demonstrating that these probabilities are accurate in the ensemble average .",
    "judicious use of the predicted redshifts , the range given , and the probability of the object having a redshift in that range allows these photometric redshift estimates to be very useful for a number of science applications .",
    "although the estimated efficiency of the algorithm that produces our catalog is already quite high , it is possible to make use of other data to improve our efficiency .",
    "for example , objects that match to radio and/or x - ray sources are that much more likely to be quasars , while objects with large proper motions are less likely to be quasars . thus , included in the catalog",
    "are matches to radio , x - ray , and proper motion catalogs as discussed below .",
    "these matches are primarily for the purpose of assessing the quasar likelihood of these objects ; the user should refer to the original catalogs for further information .",
    "we have matched the entire catalog to the first ( becker , white , & helfand 1995 ) vla 20 cm catalog .",
    "objects within @xmath65 are considered a match  the same radius used for the sdss s target selection algorithm .",
    "column 31 of table  1 indicates the peak 20 cm flux densities ( in mjy ) for those quasars with first matches .",
    "entries of `` @xmath66 '' indicate no radio detection ( or no coverage of that position ) .",
    "in addition , quasar candidates within the _ spitzer _ first look survey area have been matched to the deep 20 cm vla catalog of ( 2003 ) , which goes approximately 10 times deeper than first in this region of sky .",
    "those objects in the catalog that match to an object in the ( 2003 ) catalog within @xmath65 have their _ integrated _ 20 cm fluxes tabulated in column  31 of table  1 .",
    "objects that match both radio catalogs have only their first data reported ( as discerned by their @xmath67mjy flux densities ) .    in all we catalog 2533 radio detections .",
    "the apparent low fraction of radio - detected sources should not be taken as an indication that the fraction of quasars that are radio loud is lower than the nominal 810% ( e.g. , ivezi et  al .",
    "rather it reflects the fact that the catalog is going much deeper in optical than first does in the radio .",
    "we have cross - correlated the positions of the quasar candidates with the x - ray sources listed in the bright and faint source catalogs of the rosat all - sky survey ( rass ; 1999 , 2000 ) .",
    "positional accuracies for rass x - ray sources vary with count rate , but typically have an uncertainty of @xmath68@xmath69 . among the sdss",
    "quasar candidates presented here , there are 1304 cases whose optical positions fall within @xmath69 of a rass x - ray source ; for these sources column  32 of table  1 gives the log of the broadband ( 0.12.4  kev ) count rate ( counts sec@xmath70 ) corrected for vignetting .",
    "a `` 9 '' in column  32 indicates no x - ray detection . since the surface density of our quasar candidates is about 45.5 deg@xmath71 and since there are about 7000 rass x - ray sources within the sdss dr1 imaging region , the expected number of sdss quasar candidates superposed on unrelated rass @xmath69 radius x - ray error circles is about 69 , i.e. , about",
    "5% of the 1304 likely sdss / rass positional matches we tabulate here .",
    "there are 15 cases in which two sdss quasar candidates fall within the same 30@xmath72 radius rass error circle , making their association with the x - ray source especially ambiguous ; the catalog numbers of these ambiguous candidates are : 769/772 ,",
    "46119/46120 , 49117/49123 , 50252/50253 , 50751/50756 , 51095/51096 , 70101/70105 , 76539/76540 , 79692/79701 , 81782/81783 , 85386/85387 , 86170/86171 , 92237/92240 , 93927/93934 , and 99321/99322 .      objects with large proper motions are more likely to be stars than quasars .",
    "we have matched the quasar candidates to the improved usno - b+sdss proper motions tabulated by ( 2004 ) , which is 90% complete to @xmath73 .",
    "we chose to restrict ourselves to the most reliable proper motions , and thus require 1 ) a one - to - one match between the sdss and usno - b catalogs , 2 ) that the proper motion rms fit residual be less than 550 mas in both right ascension and declination , 3 ) that the sdss object be detected in at least four epochs , and 4 ) that the nearest neighbor ( to @xmath74 ) be more than @xmath75 away ( to avoid blended objects on the schmidt plates from which usno - b was created , which could lead to false high proper motions ) .    this matching results in 41,241 `` reliable '' proper motion measurements .",
    "since quasars will have measured `` proper motions '' comparable to the typical errors in the proper motions , we need to impose a limit on the proper motion to identify objects that are most likely to be stars .",
    "we find that 99.5% of spectroscopically confirmed quasars in our sample have proper motions less than 20 mas year@xmath70 .",
    "there are 799 objects with proper motions @xmath76 mas year@xmath70 in the catalog , most of which are likely to be stars .    in figure",
    "[ fig : fig10 ] we show the color distribution of the confirmed quasars ( _ black _ ) and confirmed non - quasars or large proper motion objects ( _ red _ ) .",
    "most of the non - quasars are cool white dwarfs with colors very similar to real quasars and are thus difficult to exclude .",
    "those desiring the most efficient samples possible may wish to exclude this color region ( especially for bright objects ) .",
    "note , however , that the contours are given as a fraction of the peak in each category and the overall level of contamination is small .",
    "although the selection algorithm from which this quasar catalog was derived is very efficient and complete with respect to unresolved uvx quasars , we can envision modifications that would improve the algorithm  especially with regard to high - redshift and extended quasars .",
    "we currently limit the test set for this catalog to uvx - selected objects in part because of a lack of a sufficiently large number of high-@xmath38 quasars from which to train the algorithm .",
    "that is , since the density of @xmath8 dr1 quasars is small , the algorithm would tend to identify any such objects as stars .",
    "however , we are hopeful that in the future we can use simulated quasars as the quasar training set , which will overcome the relative underdensity of high-@xmath38 objects and should allow for efficient selection of quasars to @xmath77 with the nbc method .",
    "in addition , we currently exclude extended sources even though they may be agn since their extended morphology necessarily means that the host galaxy is contributing a significant amount of light to the object s colors .",
    "we hope to include such objects in the future by explicitly including an extended quasar and normal galaxy training sets .",
    "furthermore , we intend to use a bayesian star / galaxy classification algorithm ( scranton et  al .",
    "2002 ) for future catalogs in order to reduce the fraction of objects that have misclassified morphologies .",
    "another improvement that could be made is to push the selection to fainter limits .",
    "the sdss imaging data have a @xmath78 completeness detection limit of 22.2 in the @xmath27-band which means that it should be possible to extend our sample to magnitudes fainter than @xmath0 .",
    "similarly we might make better use of the magnitudes in the selection algorithm itself .",
    "currently our algorithm makes use of only the four unique colors that can be derived from the five sdss magnitudes .",
    "since errors and metallicity make the width and location of the stellar locus a function of magnitude , one would like to include a magnitude in the selection algorithm .",
    "doing so is a complicated matter since magnitudes and colors are not distributed similarly and thus have different `` metrics '' .",
    "however , a possible solution for the future is to use the algorithm on the five sdss magnitudes rather than the four sdss colors .    our efficiency would also be improved if we were able to include properties such as radio- and x - ray detections and lack of proper motion into our algorithm rather than making use of that information after the fact .    finally ,",
    "since the density of stars is clearly a function of galactic position , it would be reasonable to make use of this information in the classification of quasars .",
    "one possibility is to make the stellar prior a function of galactic coordinate .",
    "here we highlight some of the science applications for which we envision the catalog being used .",
    "the most obvious of those is the study of the magnitude distribution of quasars , i.e. , their number counts .",
    "since 1 ) the efficiency of our algorithm is so high , 2 ) the selection yields a redshift distribution similar to that of the 2qz survey ( croom et  al .",
    "2004 ) , and 3 ) @xmath27 and @xmath79 are roughly equivalent , we can quite easily compare the number counts distribution of our quasar candidates to that of the 2qz/6qz catalog .",
    "such a comparison is shown in figure  [ fig : fig11 ] and shows remarkable agreement , confirming that the number counts roll over at the faint end and are better fit by a double power - law than a single power - law ( though we prefer not to use the term `` break '' to describe this behavior ) .",
    "further work is needed to properly compare the number counts of quasars from this catalog to the 2qz sample and to compute the luminosity function .",
    "currently the incompleteness of the catalog and the contamination of non - quasars are similar in fraction and fortuitously cancel , possibly making the comparison in figure  [ fig : fig11 ] look better than it really is .",
    "however , even accounting for this , the agreement of the raw catalog to previous work is a testament to the completeness and efficiency of our method .",
    "in addition to the number counts of quasars , there exists an abundance of other science that can be done with this catalog .",
    "for example , the sdss quasar selection algorithm is forced to reject the brightest quasars ( typically @xmath80 , but as faint as @xmath81 in the early data ) to avoid cross - talk between the spectroscopic fibers . as a result there 22 bright quasar candidates in the catalog without matches to our catalogs of known objects ; 13 of these are unknown to ned ( objects 2047 , 5398 , 16881 , 20333 , 23715 , 46200 , 50830 , 83155 , 93643 , 95179 , 95336 , 95341 , and 97262 ) .",
    "spectroscopy of three of these objects with the arc 3.5 m telescope at apache point observatory shows that objects 46200 and 50830 are not quasars , while object 83155 is a @xmath82 agn .",
    "based on their colors , objects 2047 , 5398 , and 95341 are the mostly likely agn candidates among the remaining 10 unknown objects .",
    "an obvious application of this catalog is to find wide - separation ( @xmath83 ) gravitational lens candidates that are clearly resolved in ground - based data .",
    "not only is it possible to find pairs of close quasars , but it is also possible to determine the likely similarity of their redshifts .",
    "hennawi et al .",
    "( 2005 , in preparation ) discuss such a search .",
    "preliminary application of our algorithm to post - dr1 successfully recovers ( with `` correct '' redshifts ) 3 of the 4 components of the quadruple lens , sdss  j1004 + 4112 ( the 4th component appears to be dust reddened ; 2003 ) and also both components of q  0957 + 561 ( , carswell , & weymann 1979 ) , again with redshifts accurate to within the errors .",
    "one can also use the catalog to measure the amplification bias of quasars .",
    "that is , to what extent are quasars magnified ( but not split into multiple images ) by foreground galaxies ? such studies require cross - correlation of the largest possible samples of foreground galaxies and background quasars .",
    "the efficiency of the algorithm is sufficient for such applications .",
    "furthermore , since we give the probability of the photometric redshifts in addition to the most likely value , it is possible to exclude quasars that may not be background sources to samples of foreground sdss galaxies .    finally , we emphasize that the expected density of uvx quasars in this catalog ( 45.5 deg@xmath71 ) is substantially larger than the density of 6.95 deg@xmath71 for similar objects from ( 2003 ) , so this sample will be very powerful for investigations of quasar - quasar and quasar - galaxy clustering .",
    "funding for the creation and distribution of the sdss archive has been provided by the alfred p. sloan foundation , the participating institutions , the national aeronautics and space administration , the national science foundation , the u.s .",
    "department of energy , the japanese monbukagakusho , and the max planck society .",
    "the sdss web site is http://www.sdss.org/. the sdss is managed by the astrophysical research consortium ( arc ) for the participating institutions .",
    "the participating institutions are the university of chicago , fermilab , the institute for advanced study , the japan participation group , the johns hopkins university , los alamos national laboratory , the max - planck - institute for astronomy ( mpia ) , the max - planck - institute for astrophysics ( mpa ) , new mexico state university , university of pittsburgh , princeton university , the united states naval observatory , and the university of washington .",
    "based also on observations obtained with the apache point observatory 3.5-meter telescope , which is owned and operated by the astrophysical research consortium .",
    "this research has made use of the nasa / ipac extragalactic database ( ned ) which is operated by the jet propulsion laboratory , california institute of technology , under contract with the national aeronautics and space administration .",
    "this work was partially supported by nsf grant ast 03 - 07582 .",
    ", a.  g. & moore , a.  w. 2003 , in proceedings of the third siam international conference on data mining , ed .",
    "daniel barbara & chandrika kamath ( san francisco : siam ) , http://www.siam.org/meetings/sdm03/proceedings/sdm03_19.pdf                                                        llrrlrrrrrrr 1 & 000001.88@xmath84094652.1 & 0.0078478 & @xmath849.7811413 & 1 - 1729 - 21 - 4 - 83 - 116 & 370.57 & 1729.17 & 19.781 & 19.530 & 19.335 & 19.401 & 19.407 + 2 & 000002.21@xmath84094956.0 & 0.0092176 & @xmath849.8322327 & 1 - 1729 - 21 - 4 - 83 - 118 & 389.98 & 1264.98 & 20.396 & 20.281 & 20.296 & 20.209 & 20.152 + 3 & 000006.53 + 003055.2 & 0.0272316 & 0.5153435 & 1 - 3325 - 20 - 5 - 108 - 117 & 656.47 & 978.59 & 20.405 & 20.459 & 20.336 & 20.100 & 20.076 + 4 & 000007.58 + 002943.3 & 0.0316062 & 0.4953686 & 1 - 3325 - 20 - 5 - 108 - 131 & 696.30 & 797.03 & 21.085 & 20.440 & 20.471 & 20.336 & 19.958 + 5 & 000008.13 + 001634.6 & 0.0339044 & 0.2762998 & 1 - 2662 - 20 - 4 - 283 - 149 & 253.50 & 673.27 & 20.240 & 20.201 & 19.949 & 19.498 & 19.194 +    lcl 1 & i6 & unique catalog number + 2 & a18 & name : sdss j@xmath85 ( j2000.0 ) + 3 & f11.7 & right ascension in decimal degrees ( j2000.0 ) + 4 & f11.7 & declination in decimal degrees ( j2000.0 ) + 5 & a21 & sdss object i d string : skyversion - run - rerun - camcol - field - id + 6 & f7.2 & row position of object in field ( pixel ) + 7 & f7.2 & column position of object in field ( pixel ) + 8 & f7.3 & psf @xmath28 asinh magnitude ( uncorrected for galactic extinction ) + 9 & f6.3 & psf @xmath27 asinh magnitude ( uncorrected for galactic extinction ) + 10 & f6.3 & psf @xmath86 asinh magnitude ( uncorrected for galactic extinction ) + 11 & f6.3 & psf @xmath30 asinh magnitude ( uncorrected for galactic extinction ) + 12 & f6.3 & psf @xmath38 asinh magnitude ( uncorrected for galactic extinction ) + 13 & f6.3 & error in psf @xmath28 asinh magnitude + 14 & f5.3 & error in psf @xmath27 asinh magnitude + 15 & f5.3 & error in psf @xmath86 asinh magnitude + 16 & f5.3 & error in psf @xmath30 asinh magnitude + 17 & f5.3 & error in psf @xmath38 asinh magnitude + 18 & f6.3 & galactic extinction ( magnitudes ) in @xmath28 + 19 & f5.3 & galactic extinction ( magnitudes ) in @xmath27 + 20 & f5.3 & galactic extinction ( magnitudes ) in @xmath86 + 21 & f5.3 & galactic extinction ( magnitudes ) in @xmath30 + 22 & f5.3 & galactic extinction ( magnitudes ) in @xmath38 + 23 & e11.4 & kde quasar density + 24 & e10.4 & kde star density + 25 & f6.3 & photometric redshift + 26 & f4.2 & lower limit of photometric redshift range + 27 & f4.2 & upper limit of photometric redshift range + 28 & f5.3 & photometric redshift range probability + 29 & a13 & previous catalog object classification + 30 & f6.3 & previous catalog object redshift + 31 & f9.3 & 20 cm flux density ( mjy ) ( @xmath66 for not detected or not covered ) + 32 & f6.3 & log rass full - band count rate ( 9 for not detected or not covered ) + 33 & f6.2 & proper motion ( mas year@xmath70 ) ( @xmath66 indicates unknown proper motion )"
  ],
  "abstract_text": [
    "<S> we present a catalog of 100,563 unresolved , uv - excess ( uvx ) quasar candidates to @xmath0 from 2099 deg@xmath1 of the sloan digital sky survey ( sdss ) data release one ( dr1 ) imaging data . </S>",
    "<S> existing spectra of 22,737 sources reveals that 22,191 ( 97.6% ) are quasars ; accounting for the magnitude dependence of this efficiency , we estimate that 95,502 ( 95.0% ) of the objects in the catalog are quasars . </S>",
    "<S> such a high efficiency is unprecedented in broad - band surveys of quasars . </S>",
    "<S> this `` proof - of - concept '' sample is designed to be maximally efficient , but still has 94.7% completeness to unresolved , @xmath2 , uvx quasars from the dr1 quasar catalog . </S>",
    "<S> this efficient and complete selection is the result of our application of a probability density type analysis to training sets that describe the 4-d color distribution of stars and spectroscopically confirmed quasars in the sdss . </S>",
    "<S> specifically , we use a non - parametric bayesian classification , based on kernel density estimation , to parameterize the color distribution of astronomical sources  allowing for fast and robust classification . </S>",
    "<S> we further supplement the catalog by providing photometric redshifts and matches to first / vla , rosat , and usno - b sources . </S>",
    "<S> future work needed to extend the this selection algorithm to larger redshifts , fainter magnitudes , and resolved sources is discussed . </S>",
    "<S> finally , we examine some science applications of the catalog , particularly a tentative quasar number counts distribution covering the largest range in magnitude ( @xmath3 ) ever made within the framework of a single quasar survey . </S>"
  ]
}