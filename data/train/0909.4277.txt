{
  "article_text": [
    "we want to consider sums of the form @xmath3 where @xmath4 ( @xmath5 ) are given matrices and @xmath2 is a partition of @xmath6 which constrains some of the indices @xmath7 to be the same .",
    "the formal definition of this is given in the following notation .",
    "\\1 ) a _ partition _ @xmath8 of @xmath9 is a decomposition of @xmath9 into disjoint non - empty subsets @xmath10 ; the @xmath10 are called the _ blocks _ of @xmath2 .",
    "the set of all partitions of @xmath9 is denoted by @xmath11 .",
    "\\2 ) for @xmath12 , we write @xmath13 if each block of @xmath2 is a union of some blocks of @xmath14 .",
    "\\3 ) for a multi - index @xmath15 we denote by @xmath16 that partition where @xmath17 and @xmath18 are in the same block if and only if @xmath19 .",
    "thus , for a given partition @xmath20 , the constraint @xmath21 in means that two indices @xmath22 and @xmath23 have to agree , whenever @xmath18 and @xmath17 are in the same block of @xmath2 . note that we do not exclude that more indices might agree .",
    "the problem which we want to address is the optimal bound of the sum .",
    "one expects a bound of the form @xmath24 for some exponent @xmath25 , where @xmath26 denotes the operator norm of the matrix @xmath27 .",
    "the question is : what is the optimal choice of this exponent ?",
    "our interest in sums of the form @xmath28 was aroused by investigations on random matrices where such sums show up quite canonically , see @xcite .",
    "indeed , when one considers the asymptotic properties of products of random and deterministic matrices , one has to find efficient bounds for the sums , @xmath28 , of products of entries of the deterministic matrices in order to determine their contribution to the limiting distribution .",
    "yin and krishnaiah @xcite , working on the product of random matrices , already faced this problem and obtained the first results for some special cases ; a more systematic approach was given by bai @xcite .",
    "our investigations are inspired by the presentation in the book of bai and silverstein @xcite .",
    "a first upper bound comes from the trivial observations that we have in @xmath28 one free summation index for each block of @xmath2 and that @xmath29 for all @xmath30 , and thus one clearly has with @xmath31 , where @xmath32 the number of blocks of @xmath2 .",
    "however , this is far from optimal .",
    "the main reason for a reduction of the exponent comes from the fact that some of the indices which appear are actually used up for matrix multiplication and thus do not contribute a factor of @xmath33 .",
    "for example , for @xmath34 one has @xmath35 thus @xmath36 hence the trivial estimate @xmath37 can here actually be improved to @xmath38 .",
    "other cases , however , might not be so clear .",
    "for example , what would one expect for @xmath39 the corresponding sum @xmath40 is @xmath41 subject to the constraints @xmath42 or , in terms of unrestricted summation indices : @xmath43    the trivial estimate here is of order @xmath44 , but it might not be obvious at all that in fact the optimal choice is @xmath45 .",
    "the non - integer value in this case shows that the problem does not just come down to a counting problem of relevant indices .",
    "we will show that there is an easy and beautiful algorithm for determining the optimal exponent @xmath25 for any @xmath2 .",
    "actually , it turns out that @xmath25 is most easily determined in terms of a graph @xmath1 which is associated to @xmath2 as follows .",
    "we start from the directed graph @xmath46 with @xmath47 vertices @xmath48 and directed edges @xmath49 , @xmath50 .",
    "( this is the graph which corresponds to unrestricted summation , i.e. , to @xmath51 , where @xmath52 is the minimal partition in @xmath53 with @xmath47 blocks , each consisting of one element .",
    "the reason that we orient our edges in the apparently wrong direction will be addressed in remark [ rem : orientation ] . )",
    "given a @xmath54 we obtain the directed graph @xmath1 by identifying in @xmath46 the vertices which belong to the same blocks of @xmath2 .",
    "we will not identify the edges ( actually , the direction of two edges between identified vertices might be incompatible ) so that @xmath1 will in general have multiple edges , as well as loops .",
    "for example , the graph @xmath55 for @xmath56 from equation @xmath57 is given in figure [ fig : g - tau ] .",
    "it should be clear how one can read off the graph @xmath55 directly from equation .",
    "the optimal exponent @xmath25 is then determined by the structure of the graph @xmath1 . before we explain how this works ,",
    "let us rewrite the sum more intrinsically in terms of the graph @xmath58 as @xmath59}\\ \\prod_{e\\in e}\\ t^{(e)}_{i_{t(e)},i_{s(e)}}.\\ ] ] we sum over all functions @xmath60 $ ] where @xmath61 , @xmath62 is the set of vertices of @xmath63 , @xmath64 the set of edges , and @xmath65 and @xmath66 denote the source vertex and the target vertex of @xmath67 respectively .",
    "note that we keep all edges through the identification according to @xmath2 , thus the @xmath68 matrices @xmath69 in show up in as the various @xmath70 for the @xmath68 edges of @xmath1 .",
    "[ rem : orientation ] note that a factor of @xmath71 in the sum in ( [ eq : graph - sum - for - pi ] ) produces an edge labelled @xmath72 starting at a vertex labelled @xmath73 and ending at a vertex labelled @xmath74 .",
    "this reversing of the indices is an artifact of the usual convention of writing @xmath75 for the operator where one first applies @xmath76 and then @xmath27 .",
    "clearly @xmath2 and @xmath1 contain the same information about our problem ; however , since the bound on @xmath77 is easily expressed in terms of @xmath1 , we will in the following forget about @xmath2 and consider the problem of bounding the graph sum @xmath77 in terms of @xmath33 for an arbitrary graph @xmath63 with attached matrices .",
    "we will call a picture as in figure [ fig : g - tau ] a _ graph of matrices _ ; for a precise definition , see definition [ def : graph - of - matrices ] .    in the figures below we",
    "give four directed graphs and below each graph the corresponding graph sum .",
    "one can see that if the graph is a circuit then the graph sum is a trace of the product of the matrices .",
    "however for more general graphs the graph sum can not easily be written in terms of traces .",
    "nevertheless , as theorem [ thm : graph - sum ] will show , there is a simple way to understand the dependence of the graph sum on @xmath33 , the size of the matrices .",
    "@xmath78 @xmath79    @xmath80 @xmath81    the relevant feature of the graph is the structure of its two - edge connected components .",
    "\\1 ) a _ cutting edge _ of a connected graph is an edge whose removal would result in two disconnected subgraphs .",
    "a connected graph is _ two - edge connected _ if it does not contain a cutting edge , i.e. , if it can not be cut into disjoint subgraphs by removing one edge .",
    "a _ two - edge connected component _ of a graph is a subgraph which is two - edge connected and can not be enlarged to a bigger two - edge connected subgraph .",
    "\\2 ) a _ forest _ is a graph without cycles .",
    "tree _ is a component of a forest , i.e. , a connected graph without cycles .",
    "a tree is _ trivial _ if it consists of only one vertex .",
    "a _ leaf _ of a non - trivial tree is a vertex which meets only one edge .",
    "the sole vertex of a trivial tree will also be called a _",
    "trivial leaf_.    it is clear that if one takes the quotient of a graph with respect to the two - edge connectedness relation ( i.e. , one shrinks each two - edge connected component of a graph to a vertex and just keeps the cutting edges ) , then one does not have cycles any more , thus the quotient is a forest .    for a graph @xmath63",
    "we denote by @xmath82 its _ forest of two - edge connected components _ : the vertices of @xmath82 consist of the two - edge connected components of @xmath63 and two distinct vertices of @xmath82 are connected by an edge if there is a cutting edge between vertices from the two corresponding components in @xmath63 .",
    "for the graph from figure [ fig : g - tau ] the corresponding forest @xmath83 is drawn in figure [ fig : tau - forrest ] .",
    "now we can present our main theorem on bounds for sums of the form . in the special case of a two - edge connected graph",
    "we obtain the same bound as appears in the book of bai and silverstein @xcite . in the general case , however , our bound is less than that of @xcite .",
    "[ thm : graph - sum ] @xmath84 let @xmath63 be a directed graph , possibly with multiple edges and loops .",
    "let for each edge @xmath67 of @xmath63 be given an @xmath85 matrix @xmath86 .",
    "let @xmath64 and @xmath62 , respectively , be the edges and vertices of @xmath63 and @xmath87}\\   \\prod_{e \\in e}\\   t^{(e)}_{i_{t(e)},i_{s(e)}}\\ ] ] where the sum runs over all functions @xmath88 $ ] .",
    "then @xmath89 where @xmath90 is determined as follows from the structure of the forest @xmath82 of two - edge connected components of @xmath63 : @xmath91 where @xmath92    @xmath93 the bound in equation [ eq : norm - sum - estimate ] is optimal in the following sense .",
    "for each graph @xmath63 and each @xmath94 there exist @xmath95 matrices @xmath70 with @xmath96 for all @xmath97 such that @xmath98    [ example ] consider again our example @xmath40 from",
    ". its forest @xmath83 , given in figure [ fig : tau - forrest ] , consists of one tree with three leaves ; thus theorem [ thm : graph - sum ] predicts an order of @xmath99 for the sum . in order to see that this can actually show up ( and thus give the main idea for the proof of optimality ) , put all the matrices in figure [ fig : g - tau ] for the non - cutting edges equal to the identity matrix",
    "; then the problem collapses to the corresponding problem on the tree , where we are just left with the four indices @xmath100 and the three matrices @xmath101 , @xmath102 , @xmath103",
    ". see figure [ fig : g - in - out-1 ] .",
    "the corresponding sum is @xmath104 let @xmath62 now be the matrix @xmath105 and put @xmath106 , @xmath107 . then @xmath108 and we have for this case    @xmath109    note that each tree of the forest @xmath82 makes a contribution of at least 1 in @xmath90 , because a non - trivial tree has at least two leaves .",
    "one can also make the above description more uniform by having a factor @xmath110 for each leaf , but counting a trivial leaf as actually two leaves .",
    "( the reason for this special role of trivial leaves will become apparent in the proof of theorem [ thm : graph - sum ] in the next section . ) note also that the direction of the edges plays no role in the estimate above .",
    "the direction of an edge is only important in order to define the contribution of an edge to the graph sum .",
    "one direction corresponds to the matrix @xmath70 , the other direction corresponds to the transpose @xmath111 .",
    "since the norm of a matrix is the same as the norm of its transpose , the estimate is the same for all graph sums which correspond to the same undirected graph .    finally , we want to give an idea of our strategy for the proof of theorem [ thm : graph - sum ] .",
    "one of the main steps consists in modifying the given graph of matrices ( by reversing some orientations , and by splitting some vertices into two ) in such a way that the corresponding sum @xmath77 is not changed and such that the modified graph has the structure of an input - output graph . by the latter we mean that we have a consistent orientation of the graph from some input vertices to some output vertices , see definition [ def : input - output ] .",
    "for example , a suitable modification of the graph @xmath55 is presented in figure [ fig : g - in - out ] .",
    "we have reversed the orientation of two edges ( but compensated this by taking the adjoint of the attached matrices ) and also split each of the vertices @xmath112 , @xmath113 , @xmath114 into two copies . to take care of the fact that in the summation we must have @xmath115 we have added an additional edge between @xmath112 and @xmath116 with the identity matrix attached and similarly for @xmath113 and @xmath117 and @xmath114 and @xmath118 .",
    "so in order to obtain a bound for @xmath40 it suffices to obtain a bound for the graph @xmath63 from figure [ fig : g - in - out ] .",
    "but this has now a kind of linear structure , with @xmath112 as input vertex and @xmath119 and @xmath120 as output vertices .",
    "this structure allows us to associate to the graph @xmath63 an operator @xmath121 , which is described in terms of tensor products of the maps @xmath70 and partial isometries describing the splittings at the internal vertices .",
    "@xmath121 maps from the vector space associated to @xmath112 to the tensor product of the vector spaces associated to @xmath119 and @xmath120 .",
    "it is then fairly easy to see that the norm of @xmath121 is dominated by the product of the norms of the involved operators @xmath70 ; and the estimate for the sum @xmath77 is finally just an application of the cauchy - schwarz inequality , where each of the input and output vertices gives a factor @xmath122 .",
    "the rest of the paper is organized as follows . in section [",
    "sect : two ] , we formulate a slight generalization of our theorem to rectangular matrices and introduce abstractly the notion of a graph of matrices .",
    "section [ sect : three ] deals with input - output graphs and the norm estimates for their associated operators . in section [ sect : four ] , we address the general case by showing how one can modify a general graph of matrices to become an input - output graph .",
    "finally , in section [ sect : five ] , we generalize the considerations from example [ example ] to show the optimality of our choice for @xmath90 .",
    "let us first formalize the input information for theorem [ thm : graph - sum ] .",
    "we will deal here with the more general situation of rectangular instead of square matrices . in order for the graph sum to make sense we require that for a given vertex @xmath123 all the matrices associated with an incoming edge have the same number of rows , @xmath124 and likewise all the matrices associated with an outgoing edge have the same number of columns @xmath124",
    ". moreover we shall find it advantageous to treat the matrices as linear operators between finite dimensional hilbert spaces .",
    "so for each vertex @xmath123 let @xmath125 have the standard inner product and let @xmath126 be the standard orthonormal basis of @xmath127 . note that we use the convention that inner products @xmath128 are linear in the second variable and we shall use dirac s bra - ket notation for rank one operators ; @xmath129 .    [ def :",
    "graph - of - matrices ] a _ graph of matrices _ consists of a triple @xmath130 in which    1 .",
    "@xmath131 is a directed graph ( possibly with multiple edges and loops ) , 2 .",
    "@xmath132 is a finite dimensional hilbert space equal to @xmath133 and 3 .",
    "@xmath134 is a linear operator .",
    "( this is also known as a representation of a quiver , but we shall not need this terminology . )    here is the generalization of theorem [ thm : graph - sum ] to the case of a rectangular matrices .",
    "[ thm : graph - sum - general ] let @xmath135 be a graph of matrices . let @xmath136 where the sum runs over all functions @xmath137 such that for each @xmath138 we have @xmath139 .",
    "let @xmath140 be the forest of two - edge connected components of @xmath63 .",
    "then @xmath141 where , for a leaf @xmath142 , @xmath123 runs over all vertices in the two edge connected component of @xmath63 corresponding to @xmath142 , and where @xmath143",
    "the main idea for proving the estimate for a graph of matrices is to first suppose that there is a flow from some vertices designated _ input vertices _ , @xmath144 , to some other vertices designated _ output vertices _ , @xmath145 , and then to show that every graph can be modified to have such a flow .",
    "all the remaining vertices , which are neither input nor output vertices , will be called _ internal vertices_.    [ def : input - output ] let @xmath63 be a directed graph ( possibly with multiple edges ) .",
    "we say that @xmath63 is an _ input - output graph _ if there exists two disjoint non - empty subsets , @xmath146 and @xmath147 , of the set of vertices of @xmath63 such that the following properties are satisfied .",
    "* @xmath63 does not contain a directed cycle .",
    "( recall that a cycle is a closed path and that a path is directed if all the edges are oriented in the same direction . ) * each vertex of @xmath63 lies on a directed path from some vertex in @xmath146 to some vertex in @xmath147 . *",
    "every internal vertex has at least one incoming edge and at least one outgoing edge . *",
    "every input vertex has only outgoing edges and every output vertex has only ingoing edges .",
    "recall that @xmath148 is an orthonormal basis for @xmath132 .",
    "let @xmath149 be a subset , suppose that we have a function @xmath150 such that @xmath151 then for each @xmath152 , @xmath153 is an element of our orthonormal basis of @xmath132 .",
    "thus an element of our orthonormal basis of @xmath154 is specified by a function @xmath155 such that @xmath156 for each @xmath123 in @xmath157 .",
    "when it is clear from the context we shall just say that a basis element of @xmath154 is specified by a function @xmath150 , but it should always be understood that @xmath156 .    hence if we form @xmath158 where @xmath159 runs over all functions @xmath150 , we obtain an orthonormal basis of @xmath160 . thus an operator @xmath161 can be specified by giving @xmath162 for each basis vector @xmath163 and @xmath164 . in the theorem below",
    "we shall show that a certain kind of graph sum can be written in terms of a vector state applied to an operator defined by the inner product above .",
    "this is the first of two key steps in proving theorem  [ thm : graph - sum - general ] .",
    "[ thm : graph - norm - estimate ] let @xmath165 be a graph of matrices and assume that @xmath63 is an input - output graph with input vertices @xmath144 and output vertices @xmath145 .",
    "@xmath84 we define @xmath166 by @xmath167 where @xmath163 , @xmath164 and @xmath168 runs over all maps @xmath169 such that @xmath170 and @xmath171",
    ".    then we have @xmath172    @xmath93 for the graph sum we have @xmath173 where @xmath174 , and we have the estimate @xmath175    the key point is to observe that we can write the operator @xmath176 as a composition of tensor products of the edge operators @xmath70 and isometries corresponding to the internal vertices .",
    "every internal vertex has , by the definition of an input - output graph , some incoming edges and some outgoing edges , let s say @xmath177 incoming and @xmath178 outgoing ( with @xmath179 ) .",
    "then the summation over the orthonormal basis of @xmath132 for this internal vertex corresponds to an application of the mapping @xmath180 given by @xmath181 in terms of our basis we have for all @xmath182 @xmath183 the mapping @xmath184 is , for all internal vertices @xmath123 , a partial isometry , and thus has norm equal to @xmath185 .    it remains to put all the edge operators and the vertex isometries together in a consistent way . for this",
    ", we have to make sure that we can order the application of all these operators in a linear way so that their composition corresponds to the operator defined by .",
    "however , this is guaranteed by the input - output structure of our graph .",
    "we can think of our graph as an algorithm , where we are feeding input vectors into the input vertices and then operate them through the graph , each edge doing some calculation , and each vertex acting like a logic gate , doing some compatibility checks .",
    "the main problem is the timing of the various operations , in particular , how long one has to wait at a vertex , before applying an operator on an outgoing edge . in algorithmic terms , it is clear that one has to wait until all the input information is processed ; i.e. one has to wait for information to arrive along the longest path from an input vertex to the given vertex .    to formalize this ,",
    "let us define a distance function @xmath186 on our graph @xmath63 which measures the maximal distance from a vertex to a input vertex , @xmath187 the length of a path is the number of edges it uses . note that since an input vertex has no incoming edges , we have @xmath188 for all input vertices .",
    "the number @xmath189 tells us how long we should wait before we apply the isometry corresponding to @xmath123 ; after @xmath189 steps all information from the input vertices has arrived at @xmath123 .",
    "let @xmath190 be the maximal distance ( which is achieved for one of the output vertices ) .",
    "the distance function @xmath191 gives us a decomposition of the vertices @xmath62 of our graph into disjoint level sets @xmath192 note that , for any edge @xmath67 , we have @xmath193 . in order to have a clearer notation",
    "it is preferable if our edges connect only vertices which differ in @xmath191 exactly by 1 .",
    "this can easily be achieved by adding vertices on edges for which this difference is bigger than 1 .",
    "the new vertices have one incoming edge and one outgoing edge .",
    "we have of course also to attach matrices to those edges , and we do this in such a way that all incoming edges of the new vertices get the identity matrix , the original matrix @xmath70 is reserved for the last piece of our decomposition .",
    "these new vertices will not change the operator @xmath194 nor the graph sum @xmath195 . in the same way we can insert some new vertices for all incoming edges of the output vertices and thus arrange that every output vertex @xmath123 has maximal possible distance @xmath196 .",
    "( note that there can not be a directed path from one output vertex to another output vertex , because an output vertex has no outgoing edges . )",
    "thus we can assume without loss of generality that we have @xmath197 for all edges",
    "@xmath97 and that @xmath196 for all @xmath198 .",
    "we have now also a decomposition of @xmath64 into a disjoint union of level sets , @xmath199 edges from @xmath200 are connecting vertices from @xmath201 to vertices from @xmath202 .",
    "note that our hilbert spaces correspond on one side to the vertices , but on the other side also to the edges as source and target hilbert spaces ; to make the latter clearer , let us also write @xmath203 where of course @xmath204 is the same as @xmath205 and @xmath206 is the same as @xmath207 .",
    "we can now write @xmath208 where @xmath209 is the tensor product of all partial isometries corresponding to the vertices on level @xmath168 , and @xmath210 is the tensor product of all edge operators corresponding to the edges on level @xmath168 .",
    "more precisely , @xmath211 is defined as @xmath212 whereas @xmath213 with the vertex partial isometry @xmath214 given by @xmath215 where @xmath178 and @xmath177 are the number of edges which have @xmath123 as their source and target , respectively .",
    "since we do not have incoming edges for @xmath216 nor outgoing edges for @xmath198 , one has to interpret @xmath217 and @xmath218 in the right way .",
    "namely , for @xmath216 , the operator @xmath184 acts on @xmath219 given by @xmath220 and similarly for @xmath198 .",
    "( formally , one can include this also in the general formalism by adding one incoming half - edge to each input vertex and one outgoing half - edge to each output vertex . ) with this convention , the product given in is an operator from @xmath221 to @xmath222 .",
    "it is clear that gives the same operator as .",
    "now the factorization and the fact that all @xmath184 and thus all @xmath209 are partial isometries yield @xmath223 this is the norm estimate claimed for the operator @xmath176 .",
    "in order to get the estimate for the graph sum @xmath195 we have to note the difference between @xmath176 and @xmath195 : for @xmath176 we sum only over the internal vertices and thus remain with a matrix , indexed by the input and output vertices ; for @xmath195 we also have to sum over these input and output vertices .",
    "if we denote by @xmath224 the sum over the vectors from our orthonormal basis of @xmath132 , then we have @xmath225 an application of the cauchy - schwartz inequality yields then @xmath226 since the norm of @xmath227 is , by pythagoras s theorem , given by @xmath228 , we get the graph sum estimate .",
    "let us now consider a graph of matrices as in theorem [ thm : graph - sum - general ] .",
    "the problem is that the underlying graph @xmath63 might not be an input - output graph .",
    "however , we have some freedom in modifying @xmath63 without changing the associated graph sum .",
    "first of all , we can choose the directions of the edges arbitrarily , because reversing the direction corresponds to replacing @xmath70 by its transpose @xmath229 .",
    "since the norm of @xmath70 is the same as the norm of @xmath229 the estimate for the modified graph will be the same as the one for the old graph .",
    "more serious is that , in order to apply theorem [ thm : graph - norm - estimate ] we should also remove directed cycles in @xmath63 .",
    "this can not , in general , be achieved by just reversing some directions .",
    "( as can clearly be seen in the case of a loop . )",
    "the key observation for taking care of this is that we can split a vertex @xmath123 into @xmath123 and @xmath230 and redistribute at will the incoming and outgoing edges from @xmath123 between @xmath123 and @xmath230 .",
    "we put one new edge @xmath231 between @xmath123 and @xmath230 with the corresponding operator @xmath232 being the identity matrix .",
    "the constraint from @xmath232 in the graph sum will be that after the splitting , the basis vector for the vertex @xmath123 has to agree with the basis vector for the vertex @xmath230 , so summation over them yields the same result as summation over the basis of @xmath132 before the splitting .",
    "thus this splitting does not change the given graph sum .",
    "since the norm of the identity matrix is 1 , this modification will also not affect the wanted norm estimate .",
    "one should of course also make sure that the forest structure of the two - edge connected components is not changed by such modifications . for the case of reversing arrows",
    "this is clear ; in the case of splitting vertices the only problem might be that the new edge between @xmath123 and @xmath230 is a cutting edge .",
    "this can actually happen , but only in the case where @xmath123 constitutes a two - edge connected component by itself . in that case",
    ", we do the splitting as before but add two new edges between @xmath123 and @xmath230 , both with the same orientation and both with the identity operator .",
    "this motivates the following definition of the modification of a graph of matrices .",
    "we say that @xmath233 is a _ modification _ of @xmath165 , if the former can be obtained from the latter by finitely many applications of the following operations :    * change the direction of the arrow of an edge @xmath67 and replace @xmath234 by its transpose @xmath235 * split a vertex @xmath123 into two vertices @xmath123 and @xmath230 , redistribute in some way the incoming and outgoing edges for @xmath123 together with their matrices to @xmath123 and @xmath230 and add a new edge between @xmath123 and @xmath230 with arbitrary direction for this edge and the identity matrix attached to it ; should @xmath123 be a two - edge connected component , then we add two edges between @xmath123 and @xmath230 , both with the same orientation , and both having the identity matrix attached to them    our discussion from above can then be summarized in the following proposition .",
    "let @xmath236 be a modification of @xmath165 .",
    "then we have :    * the graph sums are the same , @xmath237 * the forests of two - edge connected components are the same , @xmath238 * the product of the norm of the edge operators is the same , @xmath239    thus , in order to show the graph sum estimate for @xmath240 it is enough to prove this estimate for some modification @xmath241 .",
    "so the crucial step for the proof of theorem [ thm : graph - sum - general ] is now to modify a given graph @xmath63 to an input - output graph @xmath242 with the right number of input and output vertices .",
    "let @xmath240 be a graph of matrices .",
    "then there exists a modification @xmath243 such that the underlying graph @xmath244 of the modification is an input - output graph .",
    "furthermore , the input and output vertices can be chosen such that : for each non - trivial tree of the forest @xmath245 we have one leaf as input leaf and all the other leaves as output leaves . for a trivial tree ,",
    "the trivial leaf is considered both as input and output leaf .",
    "the input vertices of @xmath242 shall consist of one vertex from each input leaf , and the output vertices shall consist of one vertex from each output leaf .",
    "clearly we can assume that the underlying graph @xmath63 of @xmath240 is connected , because otherwise we do the following algorithm separately for each connected component .",
    "for such a connected @xmath63 , consider the tree of its two - edge connected components .",
    "declare arbitrarily one leaf as _ input leaf _",
    ", all the other leaves as _ output leaves _ ; if the tree is trivial , we declare its only leaf both as input and output leaf .",
    "furthermore , we choose an arbitrary vertex from the input leaf as input vertex , and for our output vertices we choose an arbitrary vertex from each output leaf .",
    "the direction from input leaf to output leaves defines uniquely a flow in our tree from the input leaf to the output leaves , i.e. , this gives us a direction for the cutting edges of @xmath63 .",
    "for each two - edge connected component we define now one input vertex and one output vertex . for the input leaf",
    "we have already chosen the input vertex ; its output vertex is the source vertex of one ( arbitrarily chosen ) of the outgoing cutting edges . for the output leaves",
    "we have already chosen their output vertices ; as input vertex we take the target vertex of the ( unique ) incoming cutting edge .",
    "for all the other , non - leaf , components we choose the target vertex of the ( unique ) incoming cutting edge as input vertex and the source vertex of one ( arbitrarily chosen ) of the outgoing cutting edges as the output vertex .",
    "we want all those input and output vertices to be different , which can be achieved by splitting , if necessary , some of them into two .",
    "so now each two - edge connected component has one input vertex and one output vertex .",
    "if we are able to modify each two edge connected component in such a way that it is an input - output graph with respect to its input and output vertex , then by putting the two - edge connected components together and declaring all input vertices but the one from the input leaf and all output vertices but the ones from the output leaves as internal indices , we get the modification @xmath242 with the claimed properties . it only remains to do the modification of the two - edge connected components .",
    "this will be dealt with in the next lemma .",
    "let @xmath240 be a graph of matrices and assume that the underlying graph @xmath63 is two - edge connected .",
    "let @xmath123 and @xmath246 be two disjoint vertices from @xmath63 .",
    "then there exists a modification @xmath241 of @xmath240 , such that the underlying graph @xmath242 of the modification is an input - output graph , with input vertex @xmath123 and output vertex @xmath246 .",
    "the proof of this can be found in ( * ? ? ?",
    "let us recall the main steps .",
    "one builds a sequence @xmath247 of input - output graphs ( all with @xmath123 as input vertex and @xmath246 as output vertex ) such that each step is manageable and that the last graph is the wanted one . for this construction",
    "we ignore the given orientation of the edges of @xmath63 , but will just use the information from @xmath63 as undirected graph ; then we will choose convenient orientations for the edges when constructing the sequence @xmath247 .",
    "first , we choose a simple path ( i.e. , a path without cycles ) , in our graph @xmath63 from @xmath123 to @xmath246 .",
    "we direct all edges on this path from @xmath123 to @xmath246 .",
    "this path with this orientation of edges is our first input - output graph @xmath248 .",
    "assume now we have constructed an input - output graph @xmath247 .",
    "if this is not yet the whole graph , then we can choose an edge @xmath67 which is not part of @xmath247 and which has one of its vertices , say @xmath249 , on @xmath247 .",
    "let us denote the other vertex of @xmath67 by @xmath250 .",
    "then one can find a simple path in @xmath63 which connects @xmath250 with @xmath247 and does not use @xmath67 .",
    "( this is possible , because otherwise @xmath67 would be a cutting edge . )",
    "denote the end point of this path ( lying on @xmath247 ) by @xmath251 .",
    "( note that @xmath251 might be the same as @xmath250 . )",
    "we have now to direct this path between @xmath249 and @xmath251 . if @xmath252 , then there was :    1 .   either a directed path from @xmath249 to @xmath251 in @xmath247 , in which case we direct the new path also from @xmath249 and @xmath251 ; 2 .   or a directed path from @xmath251 to @xmath249 in @xmath247 , in which case we direct the new path also from @xmath251 and @xmath249 ; 3 .   or there was no such path in @xmath247 , in which case we can choose any of the two orientations for the new path between @xmath249 and @xmath251 .",
    "( note that the first and second case can not occur simultaneously , because otherwise we would have had a directed cycle in @xmath247 . )",
    "the only problematic case is when @xmath253 , i.e. , when the new path is actually a cycle . in this case",
    "we split the vertex @xmath253 into two different vertices , @xmath249 and @xmath251 ; @xmath249 gets all the incoming edges from @xmath247 and @xmath251 gets all the outgoing edges from @xmath247 , and the new edge is directed from @xmath249 to @xmath251 .",
    "furthermore , the new cycle becomes now a directed path from @xmath249 to @xmath251 .",
    "our new graph @xmath254 is now given by @xmath247 ( possibly modified by the splitting of @xmath249 into @xmath249 and @xmath251 ) together with the new path from @xmath249 to @xmath251 .",
    "it is quite easy to see that @xmath254 is again an input - output graph , with the same input vertex and output vertex as @xmath247 .",
    "we repeat this adjoining of edges until we have exhausted our original graph @xmath63 , in which case our last input - output graph is the wanted modification .",
    "in order to show the second part of theorem [ thm : graph - sum ] , that our exponent @xmath90 is optimal , we just have to adapt the corresponding considerations in example [ example ] to the general case . for a given graph",
    "we attach to each non - cutting edge the identity matrix ; thus all indices in a two - edge connected component of @xmath63 get identified and we reduce the problem to the case that @xmath63 is a forest . since it suffices to look on the components separately , we can thus assume that @xmath63 is a tree .",
    "if this tree is trivial , then we have no cutting edges left and we clearly get a factor @xmath33 .",
    "otherwise , we put an orientation on our tree by declaring one leaf as input leaf and all the other leaves as output leaves .",
    "then we attach the following matrices to the edges of this tree @xmath255 where @xmath62 is the matrix given in .",
    "again , it is straightforward to see that this choice forces every index corresponding to an internal vertex to be equal to 1 , whereas there is no restriction for the indices corresponding to the leaves ; taking into account also the @xmath256 factors from the operators @xmath62 , we will get in the end @xmath257 for the sum .",
    "the authors would like to thank van vu for his comments on a preliminary version of the paper ."
  ],
  "abstract_text": [
    "<S> we provide a simple algorithm for finding the optimal upper bound for sums of products of matrix entries of the form @xmath0 where some of the summation indices are constrained to be equal . </S>",
    "<S> the upper bound is easily obtained from a graph @xmath1 associated to the constraints , @xmath2 , in the sum . </S>"
  ]
}