{
  "article_text": [
    "the revival of neural networks in the form of deep learning has been at the basis of significant breakthroughs in various application domains , including speech recognition and computer vision . in the context of robotics",
    ", however , adoption of deep learning methods seems to happen at a slower pace and is met with more skepticism .",
    "several complicating factors may be at the basis of this phenomenon .",
    "first and foremost , robotics involves embodied physical systems .",
    "this implies that datasets can not so easily be shared , as they tend to be robot - specific .",
    "data collection is thus considerably more time consuming , even more so since we are dealing with active systems , which interact with their environment .",
    "this high burden in terms of data collection hampers progress , given the data - hungry nature of deep neural networks .",
    "recently , however , @xcite has demonstrated that a control network for single - image obstacle avoidance trained solely in simulation can generalize to the real world . in this work ,",
    "we experiment in a simulated environment , focusing on the basics , assuming that the step to the real world can be solved in a similar manner .    on top of the difficulty of data collection ,",
    "there are the traditional objections with respect to neural networks , such as the non - convexity of the parameter spaces resulting in local minima ; the lack of interpretation of what the network has actually learned ; and the large number of hyperparameters which need to be set .    on the other hand , neural networks hold a lot of promises , also for robotics applications .",
    "in particular , they cope well with high - dimensional input data ; they can learn the optimal representation for a given task , instead of relying on handcrafted features ; and they are universal function approximators .",
    "finally , they are highly non - linear , as is the world and ( presumably ) the control needed in such world .",
    "most importantly , the introduction of ( deep ) learning in robotics holds the promise of going beyond the currently dominating model - driven , metric approach to robotics .",
    "indeed , while such model - driven approaches work well for low - level control and/or for robot operations in a highly structured and controlled environment , they reach their limits when it comes to more flexible systems which need to adapt to their environment in a smart way , or need to interact with people . for high - level tasks",
    ", it may be easier to just show examples of how one would like the robot to behave , and learn directly from such data , rather than handcrafting features , finite - state machines , rules and algorithms implementing the intended behavior . in an ideal setting ,",
    "learning a new task then boils down to collecting representative data , together with the desired outputs .",
    "in particular , our long term goal is a framework , in which one can train an unmanned aerial vehicle ( uav ) to perform a wide range of high - level navigation tasks , based on _",
    "imitation learning_. that is , the system learns how to perform a task based on training data , in which an expert steers the drone and demonstrates the desired behavior , similar to apprenticeship learning @xcite .",
    "note that we exclude low - level tasks such as attitude control like @xcite , for which we rely on standard algorithms which come with most commercial drones .",
    "instead , we focus on the higher - level task of navigation , i.e. steering the drone",
    ". high - level tasks we would like our framework to learn could vary from flying a fixed route , avoiding obstacles , passing through a door or following a corridor to tracking a person , recording a high - jump or inspecting a windmill .    moreover , we want to achieve this goal using a _ forward looking camera as the only sensor_. indeed , experience from human pilots performing such tasks shows that the input from such camera over time contains enough information .",
    "cameras can be made very light , both physically and power consumption wise .",
    "they are also not limited to a certain range unlike active sensors .",
    "additional sensors might simplify some problems , yet bring extra weight which reduces the flight time .    at test time",
    ", the system should then be able to steer the drone and perform the task , based on the video input stream only , under conditions similar to those seen at training time .",
    "for now , as a first step in that direction , we focus on a single , relatively simple task : traversing a room , with three known obstacles ( a bump in the floor , a wall on the left or right hand side and an obstacle hanging from the ceiling )  see figure  [ fig : theroom ] . the order in which the obstacles appear , is fixed for some experiments and variable for others ; their dimensions ( i.e. the height of the bump / overhang and the length of the wall ) always vary .",
    "this somewhat mimics a setting where a drone flies in an unknown environment , but is given high - level instructions so knows roughly what to expect or how to cope with certain obstacles . as indicated earlier , to easily generate different rooms and for ease of experimentation , we limit ourselves to a virtual world only . moreover , instead of manually flying the uav in this world to generate training data , we place additional virtual sensors on the drone , based on which a behavior arbitration algorithm for this particular task can be developed relatively easily .",
    "this algorithm serves as expert in our experiments .",
    "this saves time during experimentation and ensures reproducibility of the results .    within this setting",
    ", we then explore the impact of various design choices and the effect of different training methods .",
    "in particular , some of the questions we try to answer in this paper include :    1 .",
    "is it advantageous to use a network with a memory ( rnn instead of cnn ) ? 2 .    what is the best strategy to cope with the high correlation between samples in sequential data ? 3",
    ".    how to deal with the state space distribution shift when switching from the expert to the student ? 4",
    ".    is it necessary to train end - to - end , or is retraining the last layer(s ) sufficient ? 5 .",
    "what are some guidelines / best practices to ensure quick learning ?",
    "we focus especially on the first question , i.e. the introduction of networks with a memory",
    ". applications of neural networks for robot control in the real world are mainly limited to memory - free feedforward networks  @xcite . yet we believe that for high - level tasks , some form of memory or inner state is actually needed . in our setting , one can not expect the forward - looking camera to always provide enough information to take the proper action without such context .",
    "the memory provided by an lstm can help the control network to take the right decisions .",
    "for instance , the network can learn robustness to temporal distortions like delays which are common in real - time applications . or",
    ", it can remember the drone is in the middle of a complex maneuver ( e.g. overtaking or moving away from an obstacle ) , even if the current input is ambiguous .",
    "besides , the state can be extracted from both temporal as well as spatial features and there is no theoretical boundary on the time - span of the memory .",
    "the main difficulty with sequential prediction problems , like navigation control , is the high correlation between the samples .",
    "this makes training a network , especially an lstm , challenging . in this work",
    "we study how to successfully train an lstm . in this context",
    ", we propose a new sampling scheme , which we coin window - wise truncated backpropagation through time ( ww - tbptt ) .",
    "this addresses the second question .",
    "there is another issue , specific to imitation learning . in a naive approach ,",
    "training data is collected offline , with the expert controlling the drone .",
    "this data is used to train a model which is then applied at test time .",
    "however , navigation control is an active system . once the student , in our case the neural network , provides the control , it is likely to make mistakes never made by the expert .",
    "this brings the drone in situations never seen during training .",
    "special strategies are needed to learn how to recover from these mistakes .",
    "we explore different methods to cope with this state - space distribution shift : we experiment with dagger  @xcite , which stands for data aggregation and we test the use of recovery cameras during training , as used by @xcite and @xcite .",
    "this addresses the third question .",
    "it has been shown that convolutional neural networks ( cnn ) are capable of learning to estimate the optical flow @xcite or depth @xcite from an rgb image . with end - to - end learning",
    "the network can define a proper state representation combined with the proper control .",
    "using an rnn allows to build both temporal as well as spatial representations . yet",
    "end - to - end learning is especially data - hungry . to tackle the fourth question ,",
    "we compare different networks , either trained end - to - end or starting from a pretrained network and retraining only the last control layers . for the latter , we build on a standard image classification network .    the fifth and final question about guidelines and best practices is addressed throughout the entire paper and experimental setup .",
    "the main contributions of this paper can then be summarized as follows : i ) the successful demonstration of uav control based on lstm in a navigation task using imitation learning , including a novel sampling method during training ; ii ) a synthetic dataset and baselines for a specific use case , namely learning to cross a virtual room containing various obstacles , with a behavior arbitration algorithm as expert ; and iii ) a study of how to train neural networks for such a control task , resulting in guidelines and good practices which may be helpful for other researchers .",
    "the remainder of the paper is organized as follows .",
    "first , we describe related work ( section  [ sec : related ] ) .",
    "next , we give more details on the standard network architectures and training methods we will be building on ( section  [ sec : background ] ) . in section  [ sec : method ] , we first give more details on the overall setup ( section  [ sec : framework ] ) , the particular tasks we are addressing and the dataset used ( section  [ sec : data ] ) .",
    "then , we explain the behavior arbitration system we will be using as expert in our experiments ( section  [ sec : behaviorarbitration ] ) . after that , we propose an alternative sampling method for lstms , window - wise truncated backpropagation through time ( ww - tbptt ) ( section  [ sec : sampling ] ) .",
    "section [ sec : impldetails ] covers the implementation details . in section  [ sec :",
    "expres ] we describe our experimental results , and section  [ sec : conclu ] concludes the paper .",
    "[ [ vision - based - navigation ] ] vision - based navigation + + + + + + + + + + + + + + + + + + + + + + +    many systems tackle the navigation problem by simultaneously localizing the vehicle and building a map of the environment ( slam ) solely based on rgb images .",
    "but these systems fail as soon as the tracking fails , e.g. when there are no clear features in the camera view  @xcite .    in @xcite a control for autonomous navigation in the forest",
    "is implemented based on a forward and a downward looking camera , a sonar sensor and imu data .",
    "the images are sent to a base station on which depth is estimated . from the depth",
    ", a 3d reconstruction is made and used for motion planning .",
    "this is computationally very expensive and therefore unfeasible to run on board .    in other work  @xcite",
    ", the control is based on the difference in optic flow over a wide - view camera .    in this work",
    "we train a neural network to incorporate these different complex tasks .",
    "there is no need for an explicit 3d reconstruction as the network inherently learns to use the 3d information obtained from the image to navigate the drone correctly .",
    "this is computationally much less expensive and can happen on board .",
    "moreover , there is no need to explicitly choose the type of information provided to the control .",
    "[ [ control - systems - based - on - neural - networks ] ] control systems based on neural networks + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    training a control network with solely rgb images as input has already been demonstrated in 1990 , by @xcite . in that work ,",
    "an fnn was trained online from a set of shifted and rotated images .",
    "this important work showed that networks are capable of performing a restrictive task like following a road .",
    "also , it showed the need for recovery data in the training set .",
    "the network contained only 5 hidden units and 30 discrete output units .",
    "the computational power of today allows us to work with more complex networks and continuous control .",
    "it is much more difficult to pilot an aerial vehicle than it is to keep a car on the road , given the same amount of congestion .",
    "@xcite trained a deep cnn to follow forest trails .",
    "a big dataset of trails recorded from 3 cameras was created .",
    "one camera facing forward was annotated with the control of going straight .",
    "two cameras pointing sideways had annotated control to compensate for the different orientations .",
    "the deep network was able to classify the images with high accuracy .",
    "in this work we train a network to apply continuous control .",
    "this means that we change the machine learning problem from a classification task to a regression task .",
    "[ [ control - systems - based - on - imitation - learning ] ] control systems based on imitation learning + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    in @xcite the control is learned by imitation learning .",
    "they use svm ( support vector machines ) with as input a combination of image features , optic flow , imu data and the previous applied control . after an initial offline learning stage",
    ", the control is applied in an online fashion under supervision of a human expert . if the control is going to crash the human supervisor takes over .",
    "the svm is then retrained on the aggregated dataset .",
    "this principle is called dagger which stands for _ data aggregation _  @xcite . manually annotating and supervising the controller during training can be tedious and costly . in this work",
    "we propose an automated manner to overcome this difficulty .",
    "another difficulty encountered by  @xcite was that once the obstacle is out of the field of view of the drone , the navigation control stops avoiding this obstacle while it might still be in flying range .",
    "this was often the reason for a crash . in this work",
    "we train both fnns as well as rnns .",
    "rnns have a memory which can be especially useful in these situations .    in  @xcite a supervised guided policy search",
    "is applied to drones with the aid of model predictive control which uses extra sensor input in order to fully observe the current state of the drone .",
    "an fnn is trained to follow a corridor and to avoid thin obstacles based on the input from laser range sensors .",
    "our work differs in the sense that our supervisor is defined with behavior arbitration @xcite and we use rgb input only . adding memory",
    "could avoid the need for extra sensors .",
    "the tasks in the previous examples were relatively primitive .",
    "the image itself contains the necessary information to make the right decision . in this work",
    "we look at a higher level of control which comes closer to trajectory following .",
    "@xcite show how a cnn can learn to behave in a wide variety of situations .",
    "they train a very deep network of 9 layers for which a large amount of real world data , 72 hours of driving , was obtained . with the aid of a simulator",
    "the data was further augmented .",
    "the simulator interprets the real data and creates a model of the perceived environment . by shifting and interpolating between sideways looking cameras ,",
    "a variety of orientations and driving behavior is obtained and annotated with corresponding control labels .",
    "this driving behavior differs from the expert s behavior , providing examples which are unlike the perfect expert s behavior .",
    "neural networks need a lot of annotated data .",
    "@xcite have made a virtual environment from which a very big annotated dataset was obtained .",
    "they train a control network to drive a car autonomously on a dataset containing less than 8 percent of real data . in the same spirit , we see it fit to explore the training behavior of different control networks first in a simulated environment .",
    "once the control behaves properly the step to the real world only needs a relatively small amount of extra training data from the real world .",
    "in contrast to previous work , we do not restrict the control problem to 1 dimensional steering .",
    "our task also contains obstacle avoidance in the vertical plane , applying 2d control signals .",
    "avoiding objects in the vertical direction can be very effective .",
    "all the networks mentioned above are trained end - to - end .",
    "this means that both the feature extraction and the control behavior are learned simultaneously .",
    "it also means that the data required to avoid overfitting increases .    in  @xcite",
    "pretrained cnn models for object proposals are used to find free space in order to avoid obstacles .",
    "this is one way to overcome the big data demand , although it comes close to a handcrafting solution . in the area of image recognition",
    "it is a common practice to use off - the - shelf cnn features @xcite for representing the high dimensional input image . in this work",
    "we explore if this common practice can be applied to learning a control and reducing the big data demand .",
    "[ [ control - systems - based - on - reinforcement - learning ] ] control systems based on reinforcement learning + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    in the full reinforcement learning problem an agent with no prior knowledge of the task , needs to find the right policy which maximizes the reward .",
    "this is a very devious way of learning a desired policy or behavior .",
    "in contrast , in imitation learning an expert demonstrates the desired behavior in order to set the learning in the right direction .",
    "a big breakthrough in training control networks for full reinforcement learning , was the work of @xcite .",
    "they succeed in training a deep cnn to play several atari games at super human performance with deep q - learning . at the input",
    "they stack 4 consecutive frames of the player s view .",
    "the control output of the network is directly fed to the game .",
    "an important difference with our work is that the screen of an atari game is much better in representing the current state of the agent and shows better what the agent needs to do next , compared to the first person view coming from a forward looking camera on a drone spawned in a room in which it should follow a certain trajectory .",
    "finally , limited work has been done by @xcite in training an lstm for controlling an agent in a reinforcement learning toy example .",
    "this work focuses on online learning , i.e. with the training data provided sequentially .",
    "this makes the training procedure very slow for big networks .",
    ".overview of common abbreviations .",
    "[ table abbreviations ] [ cols= \" < ,",
    "< , < \" , ]      +          one of the main questions we want to address in this paper , is to see if memory helps for navigation control . we compare the different control architectures explained in section [ sec : controlnets ] . the first half of table [ t2 ] and the first and third row in figure [ fig : arch - and - rec ] show the results . as visible in table [ t2 ] the performance of the fc and",
    "the 5-fc is worse than the lstm on all the different performance measures for the known rooms .",
    "this is not always the case for the unknown rooms ( values between brackets ) .",
    "though the imitation loss is always lower for the networks with memory , none of the networks succeed in crossing the room .",
    "the training data is not sufficient for any network architecture to perform reasonably well on the unknown rooms .",
    "the first and third row of figure [ fig : arch - and - rec ] show the trajectories for the five known and four unknown rooms .",
    "also qualitatively it is visible for example in training room @xmath0 and @xmath1 that the trajectories of the lstms ( brown and orange ) are much closer to the experts trajectory ( black ) than the trajectories flown by the fc networks .",
    "the main cost of training an lstm instead of an fc control is the training time .",
    "the fc control is trained in less than 3 minutes while the lstm can easily take more than 30 minutes trained with ww - tbptt on the _ room crossing two _ dataset on a 2 g gpu .",
    "the online performance at test time happens at the same speed .",
    "there is a clear trend of lstms outperforming the fc control , which shows the usefulness of memory in navigation tasks .",
    "this is a very important result and a trend which is also visible in further experiments .",
    "it is important for the student not only to learn to copy the expert s behavior but also to learn how to recover from mistakes made .",
    "this is referred to as the state space shift .",
    "one way to deal with this , is by applying dagger iterations as we do in subsection [ sec : dagger ] . in this way",
    "the student makes a mistake and the expert annotates the proper control .",
    "this is a slow way of learning because the student can only learn one fatal mistake each test trajectory .",
    "another way of learning to recover is by providing this recovery data in the offline expert dataset .",
    "there are two sources of potential drift for which recovery data can be provided .",
    "the first source of drifting is a translation in the local z or y - axis perpendicular to the flying direction ( local x - axis ) .",
    "it is usually not necessary to really recover from this drift , though the path should be adjusted during obstacle avoidance . in the training data of the room crossing one dataset",
    "the expert starts off from different global z and x positions .",
    "this results in a tube of trajectories as visible in figure [ fig : room ] .",
    "if the student network drifts off the path it will still recognize the desired control from another trajectory of the expert closer to the current path .",
    "the second source of drifting is in orientation .",
    "this is very plausible especially when the framerate is different during test time .",
    "the student control might turn a bit earlier or later than the expert .",
    "this results in a translation and an orientation difference . in order to compensate for the orientation , we add a recovery camera on the left and the right of the center camera , as was also done by @xcite .",
    "the rgb images obtained from the recovery cameras are annotated with controls that compensate for the different orientation .",
    "the compensation control steers the drone in more or less 2 seconds back in the original orientation . during training the sequences from the right and the left camera",
    "are sampled in the same way as from the straight camera .",
    "this introduces a recovery bias as two trajectories out of three are coming from a recovery camera which is looking in another direction than it is actually flying .",
    "this bias only manifests itself over several frames so not for the fc network which uses only 1 frame .",
    "the performance of the networks on the _ room crossing two _ dataset are listed in the table [ t2 ] .",
    "the performance of the fc increases much more than the performance of the lstm . resulting for instance in 3 successes for the fc control in the known rooms , while the network succeeded only 1 time without the recovery cameras .",
    "this will probably be because of the bias explained above .    with the recovery cameras , the amount of data",
    "is multiplied by a factor three .",
    "this has a similar impact on the training time .",
    "besides handling the state space shift from expert to student , the data augmentation helps also against overfitting .",
    "this effect is visible in the sense that the fc and lstm networks are capable of crossing some unknown rooms .    given the positive effect on the performance , we use recovery cameras in the remaining experiments .",
    "recovery cameras improve the performance significantly .",
    "the impact seems to be bigger for fc control networks than for lstm networks probably due to the recovery bias .",
    "another way to compensate for the state space shift as explained before , is with the use of dagger iterations .",
    "figure [ fig : imitationmethod ] shows the general setup in which the student iterates between online flying with an expert annotating and retraining on the aggregated dataset .",
    "figure [ fig : dagger - lstm ] shows for each known and unknown room of the _ room crossing two _ dataset the different trajectories flown by an lstm trained with ww - tbptt over 4 different dagger iterations from blue to red . in room",
    "@xmath0 and @xmath2 it is visible how the network can make a mistake at a later iteration even though it succeeded in passing this obstacle before . in room",
    "@xmath1 the performance even seems to get worse at each dagger iteration .",
    "table [ t2 ] shows as well how the different performance measures of both the fc and the lstm are not improving as expected .",
    "it is clear that applying dagger iterations is not a waterproof way to deal with the state space shift in the context of deep control networks .",
    "+            it seems that applying dagger iterations introduces 2 biases which have a nefast influence on the performance .",
    "the first bias is due to the difference between the annotated control from the automated expert and the actual control applied by the network or student .",
    "this bias manifests itself only over different frames so it should not affect the fc control .",
    "the second bias comes from the aggregated data in which the student follows different trajectories than the expert would like to , provoking annotated control from the expert that the expert would not apply in a normal situation .",
    "if the task is low level reactive obstacle avoidance , each frame with an obstacle in front is relevant for training the network .",
    "if the task is to navigate through a room , many different trajectories can be followed while the expert only prefers one .",
    "this results in confusing annotations steering the control networks in a wrong direction .",
    "the two biases can be limited by working with a larger training set made by the expert to keep the proportion of the biased training data made by the student low .",
    "another way to increase the influence of the expert s dataset is by finetuning on a previously trained network . instead of initializing the weights of the fc or lstm network randomly at each dagger iteration",
    ", one can initialize the weights of the network with the last network trained . in this way",
    "the network does not need to learn from scratch .",
    "the lowest 2 rows of table [ t2 ] shows how this improves the performance on the unknown rooms for the second dagger iteration .",
    "dagger iterations seem to be unreliable for dealing with the state space shift when applied on the _ room crossing two _ dataset .",
    "this can be explained by 2 new biases , though further research is required .",
    "fine - tuning the networks instead of training from scratch appears to have a slight positive influence .",
    "after a series of experiments , numbers and figures , the most important preliminary conclusions are grouped in figure [ fig : arch - and - rec - imitloss ] which shows the imitation loss on the _ room crossing two _ dataset for our most important models . as the evaluation is done only in this basic simulated environment , we acknowledge limited reliability of the conclusions .    in this work",
    "we test how memory ( in fig [ fig : arch - and - rec - imitloss ] : lstm two right vs fc two left groups ) can help for deep neural networks in navigation control . in order to train an rnn , like an lstm , it can be useful to decorrelate the training data with a method called window - wise truncated back propagation through time ( ww - tbptt ) .",
    "the method avoids the sequential bias of sliding truncated back propagation through time , though the higher variance and the calculations of the stored value makes the training process slower ( in fig [ fig : arch - and - rec - imitloss ] : right - most group ) .",
    "we proposed a general imitation learning setup with an automated expert which uses extra sensor input . here",
    "the setup is applied in a simulated environment though the setting is also applicable to a real environment with for example external motion capture systems as extra sensor input .",
    "the automated expert allows us to evaluate different trained networks with an imitation loss .",
    "the automated expert is able to perform a task a number of times for annotating recovery trajectories without the need of human interaction .",
    "it is implemented with behavior arbitration which makes it easy to implement an expert for different tasks .",
    "the expert can also be used to supervise the student automatically when running through different dagger iterations .",
    "recovery data from different trajectories and differently oriented cameras seemed to be crucial for the state space shift ( in fig [ fig : arch - and - rec - imitloss ] : red and green ) while dagger iterations seemed to be unreliable when applied to the _ room crossing two _ dataset .",
    "further research about the biases introduced by these methods is necessary .",
    "another important message from this work is the usefulness of pretrained networks . only retraining the last fc layers of a convolutional network like inception",
    ", trained on the imagenet classification task , performs much better on the navigation control task than training the network end - to - end .",
    "end - to - end not only requires much more data , it also requires much more training time .",
    "this makes it often unfeasible to apply in real world situations in robotics .",
    "finally this work gives general guidelines on how to apply imitation learning to deep neural networks for navigation control tasks .",
    "after publication , we will share the _ room crossing one _ and _ room crossing two _ datasets which can be used as a benchmark for learning navigation control .",
    "the dataset serves as an indication of the required data for a task of a certain complexity . as a final good guideline we want to stress the need for different evaluation measures depending on the task and different visualizations in order to open the black box of deep learning .",
    "99 abadi  m and agarwal  a and barham  p and brevdo  e and chen  z and citro  c and corrado  g s and davis  a and dean  j and devin  m and ghemawat  s and goodfellow  i and harp  a and irving  g and isard  m and jia  y and jozefowicz  r and kaiser  l and kudlur  m and levenberg  j and mane  d and monga  r and moore  s and murray  d and olah  c and schuster  m and shlens  j and steiner  b and sutskever  i and talwar  k and tucker  p and vanhoucke  v and vasudevan  v and viegas  f and vinyals  o and warden  p and wattenberg  m and wicke  m and yu  y and zheng  x ( 2015 ) .",
    "tensorflow : large - scale machine learning on heterogeneous distributed systems._software available from tensorflow.org .",
    ", 2015_.        bakker  b ( 2002 ) .",
    "reinforcement learning with long short - term memory _ t.g .",
    "dietterich , s. becker , z. ghahramani ( eds . ) , advances in neural information processing systems , vol .",
    "14 , mit press , cambridge , ma ( 2002 ) , pp . 14751482 _    bojarski  m , del testa",
    "d , dworakowski  d , firner  b , flepp  b , goyal  p , jackel  d. l. , monfort  m , muller  u , zhang  j , zhang  x , zhao  j , zieba  k. end to end learning for self - driving cars .",
    "_ arxiv:1604.07316 , 2016_.      conroy  j and gremillion  g and ranganathan  b and humbert  j - s ( 2009 ) .",
    "implementation of wide - field integration of optic flow for autonomous quadrotor navigation .",
    "_ auton robot 2009 _ eigen  d and puhrsch  c and fergus  r ( 2014 ) .",
    "depth map prediction from a single image using a multi - scale deep network .",
    "_ arxiv:1406.2283 _      fischer  p and dosovitskiy  a and ilg  e and husser  p and hazrba  c and golkov  v and van der smagt  p and cremers  d and brox  t ( 2015 ) .",
    "flownet : learning optical flow with convolutional networks .",
    "arxiv:1504.06852 2015_.    giusti  a and guzzi  j and ciresan  n and he  f .- l . and rodriguez  j. p. and fontana  f. and faessler  m. and forster  c. and schmidhuber  j. and caro  g. d. and scaramuzza  d. and gambardella  l. ( 2015 ) .",
    "a machine learning approach to visual perception of forest trails for mobile robots .",
    "_ ieee robotics and automation letters , pp:17 , 2015_.                            ros  g and sellart  l and materzynska  j and vazquez  d and lopez  a. m. ( 2016 ) .",
    "the synthia dataset : a large collection of synthetic images for semantic segmentation of urban scenes _ computer vision and pattern recognition , 2016_.    ross  s and gordon  g j and bagnell  j a ( 2011 ) .",
    "a reduction of imitation learning and structured prediction to no - regret online learning . _ 14th international conference on artificial intelligence and statistics ( 2011)_.    ross  s and melik - barkhudarov  n and shankar  s k and wendel  a and dey  d and bagnell  j a and hebert  m ( 2013 ) .",
    "learning monocular reactive uav control in cluttered natural environments _ international conference on robotics and automation ( icra ) , 2013_.    russakovsky  o and deng  j and su  h and krause  j and satheesh  s and ma  s and huang  z and karpathy  a and khosla  a and bernstein  m and berg  a c and fei - fei  l ( 2015 ) .",
    "imagenet large scale visual recognition challenge .",
    "_ international journal of computer vision ( ijcv ) 2015 , v115 , n3 , p211 - 252 .",
    "_                zhang  t and kahn  g and levine  s and abbeel  p ( 2016 ) .",
    "learning deep control policies for autonomous aerial vehicles with mpc - guided policy search . _ the international conference on robotics and automation ( icra ) 2016_."
  ],
  "abstract_text": [
    "<S> this work explores the feasibility of steering a drone with a ( recurrent ) neural network , based on input from a forward looking camera , in the context of a high - level navigation task . </S>",
    "<S> we set up a generic framework for training a network to perform navigation tasks based on imitation learning . </S>",
    "<S> it can be applied to both aerial and land vehicles . as a proof of concept </S>",
    "<S> we apply it to a uav ( unmanned aerial vehicle ) in a simulated environment , learning to cross a room containing a number of obstacles . </S>",
    "<S> so far only feedforward neural networks ( fnns ) have been used to train uav control . to cope with more complex tasks , </S>",
    "<S> we propose the use of recurrent neural networks ( rnn ) instead and successfully train an lstm ( long - short term memory ) network for controlling uavs . </S>",
    "<S> vision based control is a sequential prediction problem , known for its highly correlated input data . </S>",
    "<S> the correlation makes training a network hard , especially an rnn . to overcome this issue </S>",
    "<S> , we investigate an alternative sampling method during training , namely window - wise truncated backpropagation through time ( ww - tbptt ) . </S>",
    "<S> further , end - to - end training requires a lot of data which often is not available . </S>",
    "<S> therefore , we compare the performance of retraining only the fully connected ( fc ) and lstm control layers with networks which are trained end - to - end . performing </S>",
    "<S> the relatively simple task of crossing a room already reveals important guidelines and good practices for training neural control networks . </S>",
    "<S> different visualizations help to explain the behavior learned . </S>"
  ]
}