{
  "article_text": [
    "let @xmath3 be a poisson process of constant intensity @xmath4 , and let @xmath5 be independent and identically distributed ( i.i.d . ) @xmath6-valued random vectors defined on the same probability space and having a common distribution function @xmath7 , which is assumed to be absolutely continuous with respect to the lebesgue measure with density @xmath8 .",
    "assume that @xmath9 and @xmath5 are independent and define the @xmath10-valued process @xmath11 by @xmath12 the process @xmath13 is called a compound poisson process ( cpp ) and forms a basic stochastic model in a variety of applied fields , such as , for example ,  risk theory and queueing ; see @xcite .",
    "suppose that , corresponding to the true parameter pair @xmath14 , a sample @xmath15 , @xmath16 from @xmath13 is available , where the sampling mesh @xmath17 is assumed to be fixed and thus independent of @xmath18 .",
    "the problem we study in this note is nonparametric estimation of @xmath0 ( and of @xmath1 ) .",
    "this is referred to as decompounding and is well studied for one - dimensional cpps ; see @xcite .",
    "some practical situations in which this problem may arise are listed in @xcite .",
    "however , the methods used in the above papers do not seem to admit ( with the exception of @xcite ) a generalization to the multidimensional setup .",
    "this is also true for papers studying nonparametric inference for more general classes of lvy processes ( of which cpps form a  particular class ) , such as , for example ,  @xcite .",
    "in fact , there is a dearth of publications dealing with nonparametric inference for multidimensional lvy processes .",
    "an exception is @xcite , where the setup is however specific in that it is geared to inference in lvy copula models and that , unlike the present work , the high - frequency sampling scheme is assumed ( @xmath19 and @xmath20 ) .    in this work",
    ", we will establish the posterior contraction rate in a suitable metric around the true parameter pair @xmath21 .",
    "this concerns study of asymptotic frequentist properties of bayesian procedures , which has lately received considerable attention in the literature ( see , e.g. ,   @xcite ) , and is useful in that it provides their justification from the frequentist point of view .",
    "our main result says that for a @xmath22-hlder regular density @xmath0 , under some suitable additional assumptions on the model and the prior , the posterior contracts at the rate @xmath23 , which , perhaps up to a logarithmic factor , is arguably the optimal posterior contraction rate in our problem .",
    "finally , our bayesian procedure is adaptive : the construction of our prior does not require knowledge of the smoothness level @xmath22 in order to achieve the posterior contraction rate given above .",
    "the proof of our main theorem employs certain results from @xcite but involves a substantial number of technicalities specifically characteristic of decompounding .",
    "we remark that a practical implementation of the bayesian approach to decompounding lies outside the scope of the present paper .",
    "preliminary investigations and a small scale simulation study we performed show that it is feasible and under certain conditions leads to good results .",
    "however , the technical complications one has to deal with are quite formidable , and therefore the results of our study of implementational aspects of decompounding will be reported elsewhere .",
    "the rest of the paper is organized as follows . in the next section ,",
    "we introduce some notation and recall a number of notions useful for our purposes .",
    "section [ main ] contains our main result , theorem [ mainthm ] , and a brief discussion on it .",
    "the proof of theorem [ mainthm ] is given in section [ proofs ] . finally , section [ pr.lem.1 ] contains the proof of the key technical lemma used in our proofs .",
    "assume without loss of generality that @xmath24 , and let @xmath25 , @xmath26 .",
    "the @xmath10-valued random vectors @xmath27 are i.i.d .",
    "copies of a random vector @xmath28 where @xmath5 are i.i.d .  with distribution function",
    "@xmath29 , whereas @xmath30 , which is independent of @xmath5 , has the poisson distribution with parameter @xmath1 .",
    "the problem of decompounding the jump size density @xmath0 introduced in section [ intro ] is equivalent to estimation of @xmath0 from observations @xmath31 , and we will henceforth concentrate on this alternative formulation .",
    "we will use the following notation :    @xmath32 : :    law of @xmath33 : :    law of @xmath34 : :    law of      we will first specify the dominating measure for @xmath35 , which allows us to write down the likelihood in our model . define the random measure @xmath36 by @xmath37\\bigr)\\otimes\\mathcal{b}\\bigl ( \\mathbb{r}^d\\setminus\\{0\\}\\bigr).\\ ] ] under @xmath38 , the random measure @xmath36 is a poisson point process on @xmath39\\times(\\mathbb{r}^d\\setminus\\{0\\})$ ] with intensity measure @xmath40 .",
    "provided that @xmath41 , and @xmath42 , by formula ( 46.1 ) on p.  262 in  @xcite we have @xmath43 the density @xmath44 of @xmath45 with respect to @xmath46 is then given by the conditional expectation @xmath47 where the subscript in the conditional expectation operator signifies the fact that it is evaluated under @xmath48 ; see theorem 2 on p.  245 in  @xcite and corollary 2 on p.  246 there .",
    "hence , the likelihood ( in the parameter pair @xmath49 ) associated with the sample @xmath50 is given by @xmath51      we will use the product prior @xmath52 for @xmath14 .",
    "the prior @xmath53 for @xmath1 will be assumed to be supported on the interval @xmath54 $ ] and to possess a density @xmath55 with respect to the lebesgue measure .",
    "the prior for @xmath0 will be specified as a dirichlet process mixture of normal densities .",
    "namely , introduce a convolution density @xmath56 where @xmath57 is a distribution function on @xmath10 , @xmath58 is a @xmath59 positive definite real matrix , and @xmath60 denotes the density of the centered @xmath61-dimensional normal distribution with covariance matrix @xmath58 .",
    "let @xmath62 be a finite measure on @xmath6 , and let @xmath63 denote the dirichlet process distribution with base measure @xmath62 ( see @xcite or , alternatively , @xcite for a modern overview ) . recall that if @xmath64 , then for any borel - measurable partition @xmath65 of @xmath6 , the distribution of the vector @xmath66 is the @xmath67-dimensional dirichlet distribution with parameters @xmath68 .",
    "the dirichlet process location mixture of normals prior @xmath69 is obtained as the law of the random function @xmath70 , where @xmath64 and @xmath71 for some prior distribution function @xmath72 on the set of @xmath59 positive definite matrices .",
    "for additional information on dirichlet process mixtures of normal densities , see , for example ,  the original papers @xcite and @xcite , or a recent paper @xcite and the references therein .",
    "let @xmath73 denote the class of probability densities of the form . by bayes theorem , the posterior measure of any measurable set @xmath74",
    "is given by @xmath75 the priors @xmath53 and @xmath69 indirectly induce the prior @xmath76 on the collection of densities @xmath44 .",
    "we will use the symbol @xmath77 to signify both the prior on @xmath21 and the density @xmath78 .",
    "the posterior in the first case will be understood as the posterior for the pair @xmath21 , whereas in the second case as the posterior for the density @xmath78 .",
    "thus , setting @xmath79 , we have @xmath80 in the bayesian paradigm , the posterior encapsulates all the inferential conclusions for the problem at hand .",
    "once the posterior is available , one can next proceed with computation of other quantities of interest in bayesian statistics , such as bayes point estimates or credible sets .",
    "the hellinger distance @xmath81 between two probability laws @xmath82 and @xmath83 on a measurable space @xmath84 is given by @xmath85 assuming that @xmath86 , the kullback ",
    "leibler divergence @xmath87 is @xmath88 we also define the @xmath89-discrepancy by @xmath90 in addition , for positive real numbers @xmath91 and @xmath92 , we put @xmath93 using the same symbols @xmath94 , @xmath89 , and @xmath95 is justified as follows .",
    "suppose that @xmath96 is a singleton @xmath97 and consider the dirac measures @xmath98 and @xmath99 that put masses @xmath91 and @xmath92 , respectively , on @xmath96 .",
    "then @xmath100 , and similar equalities are valid for the @xmath101-discrepancy and the hellinger distance .      for any @xmath102 , by @xmath103",
    "we denote the largest integer strictly smaller than @xmath22 , by @xmath104 the set of natural numbers , whereas @xmath105 stands for the union @xmath106 . for a multiindex @xmath107",
    ", we set @xmath108 . the usual euclidean norm of a vector @xmath109 is denoted by @xmath110 .",
    "let @xmath111 and @xmath112 be constants , and let @xmath113 be a measurable function .",
    "we define the class @xmath114 of locally @xmath22-hlder regular functions as the set of all functions @xmath115 such that all mixed partial derivatives @xmath116 of @xmath8 up to order @xmath117 exist and , for every @xmath67 with @xmath118 , satisfy @xmath119 see p.  625",
    "in @xcite for this class of functions .",
    "define the complements of the hellinger - type neighborhoods of @xmath14 by @xmath120 where @xmath121 is a sequence of positive numbers .",
    "we say that @xmath122 is a posterior contraction rate if there exists a constant @xmath123 such that @xmath124 as @xmath125 in @xmath126-probability .",
    "the @xmath127-covering number of a subset @xmath128 of a metric space equipped with the metric @xmath129 is the minimum number of @xmath129-balls of radius @xmath127 needed to cover it .",
    "let @xmath130 be a set of cpp laws @xmath131 .",
    "furthermore , we set @xmath132 we recall the following general result on posterior contraction rates .    [ thm2.1ghosal01 ] suppose that for positive sequences @xmath133 such that@xmath134 , constants @xmath135 , and sets @xmath136 , we have @xmath137 then , for @xmath138 and a constant @xmath123 large enough , we have that @xmath139 as @xmath125 in @xmath126-probability , assuming that the i.i.d .",
    "observations @xmath140 have been generated according to @xmath141 .    in order to derive the posterior contraction rate in our problem ,",
    "we impose the following conditions on the true parameter pair @xmath21 .    [",
    "ass : truth ] denote by @xmath142 the true parameter values for the compound poisson process .    1 .",
    "@xmath1 is in a compact set @xmath143\\subset(0,\\infty)$ ] ; 2 .   the true density @xmath0",
    "is bounded , belongs to the set @xmath144 , and additionally satisfies , for some @xmath145 and all @xmath146 , @xmath147 furthermore , we assume that there exist strictly positive constants @xmath148 , and @xmath149 such that @xmath150    the conditions on @xmath0 come from theorem 1 in @xcite and are quite reasonable .",
    "they simplify greatly when @xmath0 has a compact support .",
    "we also need to make some assumptions on the prior @xmath77 defined in section  [ prior.sec ] .",
    "[ ass : prior ] the prior @xmath52 on @xmath21 satisfies the following assumptions :    1 .",
    "the prior @xmath53 on @xmath151 has a density @xmath55 ( with respect to the lebesgue measure ) that is supported on the finite interval @xmath54\\subset(0,\\infty)$ ] and is such that @xmath152,\\ ] ] for some constants @xmath153 and @xmath154 ; 2 .",
    "the base measure @xmath62 of the dirichlet process prior @xmath155 is finite and possesses a strictly positive density on @xmath6 such that for all sufficiently large @xmath156 and some strictly positive constants @xmath157 , and @xmath158 , @xmath159^d\\bigr)\\leq b_1 \\exp \\bigl(-c_1 x^{a_1}\\bigr),\\ ] ] where @xmath160 3 .   there",
    "exist strictly positive constants @xmath161 , @xmath162 , @xmath163 , @xmath164 , @xmath165 , @xmath166 , @xmath167 , @xmath168 , @xmath169 such that for all @xmath156 large enough , @xmath170 for all @xmath156 small enough , @xmath171 and for any @xmath172 and @xmath173 , @xmath174 here @xmath175 denotes the @xmath176th smallest eigenvalue of the matrix @xmath177 .",
    "this assumption comes from @xcite , to which we refer for an additional discussion .",
    "in particular , it is shown there that an inverse wishart distribution ( a popular prior distribution for covariance matrices ) satisfies the assumptions on @xmath72 with @xmath178 . as far as @xmath62 is concerned",
    ", we can take it such that its rescaled version @xmath179 is a nondegenerate gaussian distribution on @xmath10 .",
    "[ cond_pi1 ] assumption requiring that the prior density @xmath55 is bounded away from zero on the interval @xmath180 $ ] can be relaxed to allowing it to take the zero value at the end points of this interval , provided that @xmath1 is an interior point of @xmath54 $ ] .",
    "we now state our main result .",
    "[ mainthm ] let assumptions  [ ass : truth ] and  [ ass : prior ] hold .",
    "then there exists a constant @xmath123 such that , as @xmath125 , @xmath181 in @xmath126-probability . here",
    "we conclude this section with a brief discussion on the obtained result : the logarithmic factor @xmath183 is negligible for practical purposes . if @xmath184 , then the posterior contraction rate obtained in theorem [ mainthm ] is essentially @xmath185 , which is the minimax estimation rate in a number of nonparametric settings .",
    "this is arguably also the minimax estimation rate in our problem as well ( cf .",
    "theorem 2.1 in @xcite for a related result in the one - dimensional setting ) , although here we do not give a formal argument .",
    "equally important is the fact that our result is adaptive : the posterior contraction rate in theorem [ mainthm ] is attained without the knowledge of the smoothness level @xmath22 being incorporated in the construction of our prior @xmath77 . finally , theorem [ mainthm ] , in combination with theorem 2.5 and the arguments on pp .",
    "506507 in @xcite , implies the existence of bayesian point estimates achieving ( in the frequentist sense ) this convergence rate .",
    "after completion of this work , we learned about the paper @xcite that deals with nonparametric bayesian estimation of intensity functions for aalen counting processes . although cpps are in some sense similar to the latter class of processes , they are not counting processes .",
    "an essential difference between our work and @xcite lies in the fact that , unlike @xcite , ours deals with discretely observed multidimensional processes . also @xcite uses the log - spline prior , or the dirichlet mixture of uniform densities , and not the dirichlet mixture of normal densities as the prior .",
    "the proof of theorem [ mainthm ] consists in verification of the conditions in theorem  [ thm2.1ghosal01 ] .",
    "the following lemma plays the key role .    [",
    "lem : ineq ] the following estimates are valid : @xmath186 moreover , there exists a constant @xmath187 , depending on @xmath188 and @xmath189 only , such that for all @xmath190 $ ] , @xmath191    the proof of the lemma is given in section [ pr.lem.1 ] .",
    "we proceed with the proof of theorem [ mainthm ] .",
    "let @xmath192 for @xmath193 and @xmath194 as in the statement of theorem [ mainthm ] .",
    "set @xmath195 , where @xmath196 is the constant from lemma [ lem : ineq ] .",
    "we define the sieves of densities @xmath197 as in theorem 5 in @xcite : @xmath198^d,\\forall i\\leq i_n ; \\sum _ { i >",
    "i_n}\\pi_i < \\varepsilon_n ; \\\\ & \\sigma_{0,n}^2 \\leq\\operatorname{eig}_j ( \\varsigma)<\\sigma _ { 0,n}^2\\bigl(1+\\varepsilon_n^2/d \\bigr)^{j_n } \\biggr\\},\\end{aligned}\\ ] ] where @xmath199 and @xmath200 and @xmath201 are as in assumption [ ass : prior ]",
    ". we also put @xmath202 \\bigr\\}.\\ ] ]    in @xcite , sieves of the type @xmath197 are used to verify conditions of theorem [ thm2.1ghosal01 ] and to determine posterior contraction rates in the standard density estimation context .",
    "we further will show that these sieves also work in the case of decompounding by verifying the conditions of theorem [ thm2.1ghosal01 ] for the sieves @xmath203 defined in .",
    "introduce the notation @xmath204 let @xmath205 be the centers of the balls from a minimal covering of @xmath206 $ ] with @xmath207-intervals of size @xmath208 .",
    "let @xmath209 be centers of the balls from a minimal covering of @xmath210 with @xmath211-balls of size @xmath208 . by lemma [ lem : ineq ] , for any @xmath212 , @xmath213 by appropriate choices of @xmath214 and @xmath176 .",
    "hence , @xmath215,\\overline { h}_1\\bigr ) \\times n ( \\overline{c } \\varepsilon_n , { \\mathcal{f}}_n , \\overline{h}_2 ) , \\ ] ] and so @xmath216,\\overline { h}_1\\bigr)+\\log n(\\overline{c } \\varepsilon_n,\\mathcal{f}_n,\\overline{h}_2).\\ ] ] by proposition 2 and theorem 5 in @xcite , there exists a constant @xmath217 such that for all @xmath18 large enough , @xmath218 on the other hand , @xmath219,\\overline{h}_1\\bigr ) & = \\log n\\bigl ( \\varepsilon_n,[\\underline{\\lambda } , \\overline{\\lambda}],|\\cdot|\\bigr ) , \\\\ & \\lesssim\\log \\biggl ( \\frac{1}{\\varepsilon_n } \\biggr ) \\\\ & \\lesssim\\log \\biggl ( \\frac{1}{\\overline{\\varepsilon}_n } \\biggr).\\end{aligned}\\ ] ] with our choice of @xmath220 , for all @xmath18 large enough , we have @xmath221 so that for all @xmath18 large enough , @xmath222 we can simply rename the constant @xmath223 in this formula into @xmath224 , and thus is satisfied with that constant .",
    "we first focus on .",
    "introduce @xmath225 suppose that @xmath226 . from we",
    "obtain @xmath227 furthermore , using , we have @xmath228 combination of these inequalities with the definition of the set @xmath229 in yields @xmath230 consequently , @xmath231 by assumption [ ass : prior](i ) , @xmath232 furthermore , theorem 4 in @xcite yields that for some @xmath233 and all sufficiently large @xmath18 , @xmath234 we substitute @xmath235 with @xmath236 and write @xmath237 to arrive at @xmath238 now , since @xmath239 , for all @xmath18 large enough , we have @xmath240 consequently , for all @xmath18 large enough , @xmath241 choosing @xmath242 , we have verified ( with @xmath243 ) .    for the verification of , we use the constants @xmath244 and @xmath245 as above .",
    "note first that @xmath246 by theorem 5 in @xcite ( see  also p.  627",
    "there ) , for some @xmath247 and any constant @xmath248 , we have @xmath249 provided that @xmath18 is large enough .",
    "thus , @xmath250 without loss of generality , we can take the positive constant @xmath251 greater than @xmath252 .",
    "this gives @xmath253 which is indeed .",
    "we have thus verified conditions  , and the statement of theorem [ mainthm ] follows by theorem  [ thm2.1ghosal01 ] since @xmath254 ( eventually ) .",
    "we start with a lemma from @xcite , which will be used three times in the proof of lemma  [ lem : ineq ] . consider a probability space @xmath255 .",
    "let @xmath256 be a probability measure on @xmath84 and assume that @xmath257 with radon  nikodym derivative @xmath258 .",
    "furthermore , let @xmath259 be a sub-@xmath260-algebra of @xmath261 . the restrictions of @xmath262 and @xmath256 to @xmath259 are denoted @xmath263 and @xmath264 , respectively . then @xmath265 and @xmath266=:\\zeta'$ ] .    [ lem : convexnew ] let @xmath267 be a convex function",
    ". then @xmath268    the proof of the lemma consists in an application of jensen s inequality for conditional expectations .",
    "this lemma is typically used as follows .",
    "the measures @xmath262 and @xmath256 are possible distributions of some random element @xmath13 . if @xmath269 is some measurable transformation of @xmath13 , then we consider @xmath263 and @xmath264 as the corresponding distributions of @xmath270 . here",
    "@xmath30 may be a projection . in the present context ,",
    "we take @xmath271)$ ] and @xmath272 , and so @xmath262 in the lemma should be taken as @xmath273 and @xmath263 as @xmath274 .    in the proof of lemma [ lem : ineq ] , for economy of notation ,",
    "a constant @xmath275 depending on @xmath188 and @xmath189 may differ from line to line .",
    "we also abbreviate @xmath141 and @xmath276 to @xmath82 and @xmath277 , respectively .",
    "the same convention will be used for @xmath278 , @xmath279 , @xmath280 , and @xmath281 .",
    "application of lemma  [ lem : convexnew ] with @xmath282 gives @xmath283 .",
    "using and the expression for the mean of a stochastic integral with respect to a poisson point process ( see , e.g. ,  property 6 on p.  68 in  @xcite ) , we obtain that @xmath284 \\biggr ) \\\\ & = \\lambda_0 \\mathrm{k}(\\mathbb{p}_{0},\\mathbb{p})+ \\mathrm{k}(\\lambda _ 0,\\lambda).\\end{aligned}\\ ] ] now @xmath285 where @xmath275 is some constant depending on @xmath188 and @xmath189 .",
    "the result follows .",
    "we have @xmath286 + { \\mathbb{e}}_{\\mathbb{q}_0 } \\biggl [ \\log^2 \\biggl ( \\frac{\\mathrm{d}\\mathbb { q}_0}{\\mathrm{d}\\mathbb{q } } \\biggr ) 1 _ { \\ { \\frac{\\mathrm{d}{\\mathbb { q}}_0}{{\\mathrm{d}}{\\mathbb { q } } } < 1   \\ } } \\biggr ] \\\\ & = \\mathrm{i}+\\mathrm{ii}.\\end{aligned}\\ ] ] application of lemma  [ lem : convexnew ] with @xmath287 ( which is a convex function ) gives @xmath288 } \\biggr ] \\le\\mathrm{v } ( { \\mathbb { r}}_0 , { \\mathbb { r}}).\\ ] ] as far as @xmath289 is concerned , for @xmath290 , we have the inequalities @xmath291 the first inequality is trivial , and the second is a particular case of inequality  ( 8.5 ) in and is equally elementary .",
    "the two inequalities together yield @xmath292 applying this inequality with @xmath293 ( which is positive on the event ) and taking the expectation with respect to @xmath294 give @xmath295 \\\\ & \\le4 \\int \\biggl ( \\sqrt{\\frac{{\\mathrm{d}}{\\mathbb { q}}_0}{{\\mathrm{d}}{\\mathbb { q } } } } -1 \\biggr)^2 { \\mathrm{d}}{\\mathbb { q } } \\\\ & = 4 h^2({\\mathbb { q}}_0 , { \\mathbb { q } } ) \\le4\\mathrm{k } ( { \\mathbb { q}}_0 , { \\mathbb { q } } ) . \\ ] ] for the final inequality , see @xcite , p.  62",
    ", formula  ( 12 ) .    combining the estimates on @xmath296 and @xmath297",
    "we obtain that @xmath298 after some long and tedious calculations employing and the expressions for the mean and variance of a stochastic integral with respect to a poisson point process ( see , e.g. ,  property 6 on p.  68 in  @xcite and lemma 1.1 in @xcite ) , we get that @xmath299 by the @xmath244-inequality @xmath300 we have @xmath301 from which we deduce @xmath302 for some constant @xmath303 depending on @xmath188 and @xmath189 only . as far as @xmath304 is concerned , the @xmath244-inequality and the cauchy  schwarz inequality give that @xmath305 \\biggr)^2\\nonumber \\\\",
    "& \\leq2 \\lambda_0 ^ 2 \\mathrm{v}(\\mathbb{p}_{0 } , \\mathbb{p})+2\\mathrm { k}(\\lambda_0,\\lambda)^2,\\label{ineqiv}\\end{aligned}\\ ] ] from which we find the upper bound @xmath306 for some constant @xmath275 depending on @xmath188 and @xmath189 . combining estimates and on @xmath307 and @xmath304 with inequalities and yields .",
    "similarly , the upper bounds and , combined with and , yield .",
    "first , note that for @xmath308}$ ] , @xmath309 = { \\mathbb{e}}_{{\\mathbb { q } } } \\biggl [ g \\biggl ( \\frac{{\\mathrm{d}}{\\mathbb { q}}_0}{{\\mathrm{d}}{\\mathbb { q } } } \\biggr ) \\biggr].\\ ] ] since @xmath310 is convex , an application of lemma  [ lem : convexnew ] yields @xmath311 . using and invoking lemma 1.5 in  @xcite , in particular , using formula ( 1.30 ) in its statement",
    ", we get that @xmath312 where @xmath313 denotes the @xmath314-norm .",
    "this proves .",
    "furthermore , from this we obtain the obvious upper bound @xmath315 which yields .",
    "the authors would like to thank the referee for his / her remarks .",
    "the research leading to these results has received funding from the european research council under erc grant agreement 320637 ."
  ],
  "abstract_text": [
    "<S> given a sample from a discretely observed multidimensional compound poisson process , we study the problem of nonparametric estimation of its jump size density @xmath0 and intensity @xmath1 . we take a nonparametric bayesian approach to the problem and determine posterior contraction rates in this context , which , under some assumptions , we argue to be optimal posterior contraction rates . in particular , </S>",
    "<S> our results imply the existence of bayesian point estimates that converge to the true parameter pair @xmath2 at these rates . to the best of our knowledge , </S>",
    "<S> construction of nonparametric density estimators for inference in the class of discretely observed multidimensional lvy processes , and the study of their rates of convergence is a  new contribution to the literature .    </S>",
    "<S> ./style / arxiv - vmsta.cfg    decompounding , multidimensional compound poisson process , nonparametric bayesian estimation , posterior contraction rate 62g20 , 62m30 </S>"
  ]
}