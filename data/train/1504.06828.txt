{
  "article_text": [
    "a general theory of games first introduced in @xcite has found several applications in the field of economics and engineering .",
    "a solution concept or a notion of equilibrium was proposed by nash ( known as nash equilibrium ) in @xcite and was shown to exist in every finite normal - form game .",
    "further generalizations of nash equilibrium such as correlated equilibrium and coarse correlated equilibrium were also introduced and studied .",
    "it is well known that for every game the set correlated and coarse - correlated equilibria are convex subsets of the strategy space .",
    "but in general the set of nash equilibria is not convex .",
    "a number of methods have been proposed to compute a nash equilibium strategy .",
    "lemke - howson s algorithm for bi - matrix games@xcite , global newton method@xcite , homotopy based methods@xcite are some of the few methods to compute a nash equilibrium strategy .    for a general n - player game ,",
    "the associated optimization problem is non - linear and non - convex and hence is difficult to solve .",
    "it is known that the problem of computing nash equilibria in bi - matrix games is a linear complementarity problem and for the general n - player scenario it is a non - linear complementarity problem .",
    "linear complimentarity problems ( the ones arising from games ) can be solved using lemke - howson s method , while non - linear complimentarity problems are in general hard to solve and require some sufficient conditions to be imposed on the problem to solve them which is not satisfied by every game .    in this paper",
    "we present optimization problems with biconvex objective function and linear constraints such that the set of global minima of the optimization problems is the same as the set of nash eqilibria of a n - player general - sum normal form game . global optimization algorithms",
    "exist that can compute the global minima of such optimization problems@xcite .",
    "the main idea in the formulation of these optimization problems is the fact that correlated or coarse - correlated equilibrium which are product of individual player s strategy is a nash equilibrium .",
    "we further show that the objective function is an invex function i.e. the set of stationary points is the same as the set of global minima .",
    "we also consider a projected gradient descent scheme and prove that is converges to a partial optimum of the objective function .    the remainder of this paper is organised as follows : in section 2 , necessary definitions and notations are stated . in section 3 ,",
    "functions with required properties are defined . in section 4 ,",
    "properties of the functions defined in section 2 are proved . in section 5 ,",
    "optimization problems are presented . in section 6 ,",
    "the projected gradient descent algorithm is stated and convergence analysis is performed . in section 7 ,",
    "simulation results of the projected gradient descent algorithm on certain test cases are presented . in section 8 , we summarize and present directions for future research .",
    "in this section we shall state definitions , introduce variables and notations used later in this paper .    a normal form game ( or simply a game ) ( @xmath0 )",
    "is defined by tuple @xmath1 where , @xmath2 denotes the set of players ( @xmath3 ) , @xmath4 denotes the set of actions of player @xmath5 ( @xmath6 ) .",
    "let @xmath7 and @xmath8 denotes the utility function of player @xmath5 .    for every @xmath9",
    ", @xmath10 denotes the set of probability distributions on @xmath11 .",
    "@xmath10 is identified by the probability simplex @xmath12 .",
    "@xmath13 denotes a generic element of @xmath10 .",
    "let @xmath14 which is identified as a vector in @xmath15 where @xmath16 .",
    "let @xmath17 .",
    "let @xmath18 denote the set of probability distributions on @xmath19 .",
    "@xmath18 is identified by the probability simplex @xmath20 where @xmath21 .",
    "@xmath22 denotes a generic element in @xmath18 .    for every @xmath9 , @xmath23 and @xmath24 denotes a generic element in @xmath25 .",
    "similarly , this can be extended to more than one player .",
    "@xmath26 . similarly define @xmath27 and @xmath28 denote a generic element in @xmath29 .",
    "@xmath30 .    for every @xmath9 , @xmath31 where @xmath32 . for every @xmath9 , @xmath33 where @xmath34 .    for every @xmath9 , @xmath35 and @xmath36 .",
    "similarly define @xmath37 .",
    "@xmath38 is said to be a * nash equilibrium strategy of the game @xmath0 ( or just n.e . )",
    "if @xmath39 .",
    "let @xmath40 denote the set of nash equilibria strategies of game @xmath0 .",
    "*    @xmath41 is said to be a * correlated equilibrium strategy of the game @xmath0 ( or just c.e . ) if @xmath42 .",
    "let @xmath43 denote the set of correlated equilibria of the game @xmath0 .",
    "*    @xmath41 is said to be a * coarse correlated equilibrium strategy of the game @xmath0 ( or just c.c.e . ) if @xmath44 .",
    "let @xmath45 denote the set of coarse correlated equilibria of the game @xmath0 .",
    "*    define @xmath46 , s.t .",
    ", @xmath47 where @xmath48 .",
    "let the graph of the function @xmath49 be @xmath50 . in the following lemma",
    "we summarize the relationship between the various equilibrium concepts defined.*lemma 2.1 : given a game @xmath0 . the following hold .",
    "*    * @xmath51 .",
    "* @xmath52 . * @xmath53 .",
    "the results in lemma follow directly from definitions .",
    "@xmath54 is a * nash equilibrium profile of game @xmath0 if @xmath55 is a nash equilibrium strategy of game @xmath0 and @xmath56 .",
    "*    let @xmath57 and @xmath58 be two convex subsets of @xmath59 and @xmath60 respectively .",
    "a function @xmath61 is said to be a * biconvex function if @xmath62 is a convex function and @xmath63 is a convex function .",
    "@xmath64 is a * partial optimum of a biconvex function @xmath65 if @xmath66 and @xmath67 . for a detailed study of biconvex functions",
    "see @xcite . *",
    "*    let @xmath68 be a subset of @xmath69 and @xmath70 .",
    "@xmath71 is said to the global optimum of the optimization problem @xmath72 , if , @xmath73 .",
    "in this section we shall define functions whose set of zeros is the same as the set of nash equilibria of the game @xmath0 .",
    "the following theorem gives a necessary and sufficient condition for @xmath74 to be in @xmath75 .",
    "* theorem 3.1 : given @xmath74",
    ". then , @xmath76 iff @xmath77 . *",
    "proof : [ @xmath78 assume @xmath76 .",
    "fix @xmath79 . then@xmath80 and @xmath81 . therefore @xmath82 . since @xmath83 are arbitrary , @xmath84 , @xmath85 .",
    "[ @xmath86 fix @xmath87 . from data ,",
    "we know that @xmath88 . using the above",
    ", we get , @xmath89 . from data , we also know that @xmath90 . therefore by substituting for the sum , we get , @xmath91 . similarly repeating the above procedure for actions of the third player we get , @xmath92 .",
    "proceeding all the way upto player @xmath93 we get , @xmath94 . since @xmath41 , we know that @xmath95 . therefore , @xmath96 . since @xmath97 is arbitrary , @xmath98.@xmath99 * *    using the above theorem we now define a non - negative function on @xmath100 such that the function takes the value zero on @xmath75 and is positive on @xmath101 .",
    "let @xmath102 such that , @xmath103 .",
    "* corollary 3.1 : given @xmath74",
    ". then , @xmath104 iff @xmath76 . *    from the definitions of coarse - correlated equilibrium and correlated equilibrium we now define the following non - negative functions on @xmath18 such that they take the value zero on the set of coarse - correlated equilibria ( @xmath45 ) and correlated equilibria ( @xmath43 ) respectively .",
    "let @xmath105 , such that , @xmath106 and @xmath107 , such that , @xmath108 .",
    "* lemma 3.1 : given @xmath109 . *",
    "* @xmath110 iff @xmath111 . * @xmath112 iff @xmath113 .",
    "* proof : follows directly from the definitions of correlated equilibrium and coarse correlated equilibrium in section 2.@xmath99 *    let @xmath114 s.t .",
    "the idea is that when @xmath116 and @xmath117 , then , @xmath118 is a best response to @xmath28 .",
    "* lemma 3.2 : given @xmath116 .",
    "@xmath117 iff @xmath55 is a nash equilibrium.*proof : [ @xmath78since @xmath117 , we have , @xmath119 . hence @xmath120 . since @xmath121 , @xmath122 and @xmath123 .",
    "therefore , @xmath124 , which by definition of a nash equilibrium strategy in section 2 , implies @xmath55 is nash equilibrium . * *    [ @xmath86 since @xmath55 is a nash equilibrium , we have , @xmath124 . since @xmath121 , @xmath122 and @xmath123 .",
    "therefore , @xmath120 , which further implies , @xmath119 .",
    "thus @xmath117.@xmath99",
    "we now characterise the set of nash equilibria of a game ( @xmath0 ) using the functions @xmath125 and @xmath126 .",
    "* theorem 3.2 : given @xmath54 .",
    "*    * @xmath127 is a nash equilibrium profile iff @xmath128 .",
    "* @xmath127 is a nash equilibrium profile iff @xmath129 .",
    "* @xmath127 is a nash equilibrium profile iff @xmath130 .",
    "* proof : first we shall prove ( 1).[@xmath78 assume @xmath127 is a nash equilibrium .",
    "then , by definition of nash equilibrium profile in section 2 , @xmath55 is a n.e . and",
    "@xmath56 . by lemma 2.1 , since @xmath55 is a n.e .",
    "@xmath131 and since @xmath56 , @xmath121 .",
    "thus @xmath104 and @xmath110 by theorem 3.1 and lemma 3.1 respectively .",
    "therefore @xmath128.assume @xmath128 .",
    "since both @xmath132 and @xmath133 are non - negative , @xmath104 and @xmath110 . by theorem 3.1 , @xmath104 will imply @xmath121 and by lemma 3.1 @xmath110 will imply @xmath111 . since @xmath134 and @xmath56 ,",
    "from lemma 2.1 , we have that @xmath55 is a n.e .",
    "thus @xmath127 is a nash equilibrium . *",
    "proof of ( 2 ) is similar to that of ( 1 ) and the proof of ( 3 ) follows from lemma 3.2 and corollary 3.1.@xmath99",
    "in this section we shall prove certain properties of the functions constructed in section * no . first , we shall prove that @xmath132 is biconvex and that @xmath133 and @xmath126 are convex .",
    "* lemma 4.1 : @xmath132 is a biconvex function i.e. @xmath135 is convex and @xmath136 is convex.*proof : @xmath137 where @xmath48 , @xmath138 is a linear function of @xmath41 and an affine function of @xmath139 . by proposition 1.1.4 in @xcite , @xmath140 is convex in @xmath41 and @xmath38 with the other fixed .",
    "since sum of convex functions is convex , @xmath141 is convex in @xmath142 for every fixed @xmath38 and is convex in @xmath55 for every fixed @xmath143.@xmath99 * lemma 4.2 : @xmath144 and @xmath145 are convex functions of @xmath41.*proof : first we shall show @xmath133 is convex .",
    "@xmath146 , @xmath147 is linear in @xmath41 .",
    "since supremum of convex functions is convex , we have , @xmath146 , @xmath148 . since composition of nondecreasing function and convex function is convex , @xmath146 , @xmath149 , is convex .",
    "therefore , @xmath150 is a convex function . * * * * *    similarly we can show that @xmath145 is also a convex function.@xmath99    it is easy to show @xmath151 and @xmath145 are continuously differentiable on an open set containing their respective domains ( for a similar proof refer @xcite ) . let @xmath152^t$ ] , where @xmath153 and @xmath154 . for every @xmath155 ,    @xmath156\\end{aligned}\\ ] ]    so as to compute @xmath157 , we shall write @xmath158 , where @xmath159 s.t . @xmath160 ( which is possible since @xmath138 is linear in @xmath142 ) .",
    "therefore , @xmath161    the following lemma says that set of partial optima of @xmath132 , the set of stationary points of @xmath132 and the set of global minima of @xmath132 are all the same.*lemma 4.3 : given @xmath162 .",
    "then the following are equivalent .",
    "*    * @xmath163 is a partial optimum of @xmath132 .",
    "* @xmath163 is s.t . @xmath104 .",
    "* @xmath163 is s.t . @xmath164 .",
    "* proof : [ @xmath165 . since @xmath163 is a partial optimum of @xmath132 , @xmath166 .",
    "hence , @xmath167 . therefore , @xmath168 . *    [ @xmath169 . since @xmath104 , @xmath77 . substituting the above in the expression of @xmath170 and @xmath157 we get , @xmath164 .",
    "[ @xmath171 . since @xmath132 is biconvex ( from lemma 4.1 ) ,",
    "@xmath172 and @xmath173 are convex functions . from proposition 1.1.7 in @xcite",
    ", we get , @xmath174 and @xmath175 . substituting @xmath176^t=0 $ ] ,",
    "will give , @xmath177 and @xmath178 .",
    "thus , @xmath163 is a partial optimum of @xmath132.@xmath99    so as to compute @xmath179 , we shall write @xmath180 where @xmath181 ( which is possible since @xmath147 is linear in @xmath142 ) . then @xmath182 .",
    "the following lemma says that the set of global minima of @xmath133 and the set of stationary points of @xmath133 are the same .",
    "* lemma 4.4 : given @xmath183 . @xmath184 iff @xmath185 . * proof : follows directly from the expression of the gradient and the convexity of @xmath133.@xmath99 * *    a similar result can be derived for @xmath126 . in what follows in this paper results proved for @xmath133 can be extended to @xmath126 as well .    in theorem 3.2",
    "we showed that the set of zeros of @xmath186 is the same as the set of nash equilibrium profiles of the game @xmath0 . in the following lemma",
    "we show that the set of zeros of @xmath186 is the same as the set of stationary points of the function @xmath186 .",
    "* lemma 4.5 : given @xmath187 . @xmath188 iff @xmath189 . * proof : [ @xmath78 since @xmath188 and that @xmath132 and @xmath133 are non - negative , will imply that @xmath168 and @xmath184 .",
    "thus , @xmath176^t=0 $ ] and @xmath185 by lemma 4.3 and 4.4 respectively",
    ". therefore , @xmath190^t=0 $ ] . * *    [ @xmath86since @xmath190^t=0 $ ] , we have @xmath191 . @xmath192 . by substituting the expressions for @xmath193 and @xmath194 we get , @xmath195 and @xmath196 .",
    "therefore , @xmath197.@xmath99    lemma 4.5 shows that the function @xmath186 is invex .",
    "similarly it can shown that @xmath198 is also invex .    in following lemma",
    "we show that @xmath199 is a biconvex function . as a consequence of this lemma , lemma 4.1 and lemma 3.3 in @xcite , we get , @xmath200 is a biconvex function .",
    "* lemma 4.6 : @xmath199 is a biconvex function i.e. @xmath201 is a convex function and @xmath202 is a convex function . *",
    "proof : proof is similar to that of lemma 4.1.@xmath99 * *",
    "in this section we shall state the optimization problems obtained using the functions constructed in the previous sections such that the global minima of the optimization problem correspond to nash equilibria of the game @xmath0 .",
    "first optimization problem ( @xmath203 ) is stated below :    @xmath204    the constraints in the above optimization problem ensure that the feasible set is @xmath205 . the second optimization problem ( @xmath206 )",
    "is stated below :",
    "@xmath207    the following theorem says that the set of global minima of the optimization problem ( @xmath203 ) is the same as the set of nash equilibria profiles of the game @xmath0.*theorem 5.1 : for every game @xmath0 , there exists @xmath162 s.t .",
    "@xmath188 . further given @xmath208 ,",
    "@xmath188 iff @xmath163 is a nash equilibrium profile.*proof : since for every game there exists @xmath209 , s.t . , @xmath210 is a n.e .",
    "( see @xcite ) .",
    "thus by theorem 3.2 , @xmath163 with @xmath211 satisfies @xmath188 .",
    "the other part follows directly from theorem 3.2.@xmath99 * *    a similar claim can be proved for @xmath206 .",
    "the above two optimization problems have a biconvex objective function with convex ( linear ) constraints .",
    "global optimization algorithm exists that solves the above two optimization problems ( see @xcite ) .",
    "in this section we shall consider a projected gradient descent algorithm to solve @xmath203 .",
    "the algorithm is stated below : * input : *    * @xmath212 : initial point for the algorithm , * @xmath0 : the underlying game , * @xmath213 : step size sequences chosen as follows : * * @xmath214 , * * @xmath215 , * * @xmath216 , * @xmath217 : projection operator ensuring that @xmath127 remains in @xmath205 .",
    "* output : after sufficiently large number of iterations(@xmath218 ) the algorithm outputs the terminal strategy @xmath219.@xmath220 *    in what follows we shall present the convergence analysis of the above projected gradient descent algorithm .",
    "we shall analyse the behaviour of the above algorithm using the o.d.e .",
    "method presented in @xcite . in order to use the results from @xcite , we need the gradient function to be lipschitz continuous on @xmath205 , which is proved in the following lemma.*lemma 6.1 : there exists @xmath221 , s.t . , @xmath222 , *    @xmath223    * proof : it is easy to see that the function @xmath224 is twice continuously differentiable on an open set containing @xmath205 . thus @xmath225 is continuously diffrentiable on @xmath205 .",
    "hence @xmath226 for some @xmath227 . by mean value theorem",
    ", we have , @xmath225 is lipschitz continous with lipschitz constant @xmath228 .",
    "let @xmath229 .",
    "fix @xmath230 . clearly , @xmath231 .",
    "therefore , we have , @xmath232 where @xmath233}|$ ] . since @xmath234",
    ", we have , @xmath235 , where @xmath236 .",
    "since sum of two lipschitz continuous functions is lipschitz continuous , we have , @xmath237 is lipschitz continous with lipschitz constant @xmath238.@xmath99 *    in order to study the asymptotic behaviour of the recursion presented in the algorithm , by results in section 3.4 of @xcite , it is enough to study the asymptotic behaviour of the o.d.e .",
    ", @xmath239 where @xmath240 i.e. the directional derivative of @xmath217 at @xmath241 along the direction @xmath242 . the above o.d.e .",
    "is well posed i.e. has a unique solution for every initial point in @xmath205 ( for a proof see @xcite ) .",
    "@xmath205 , is a cartesian product of simplices and hence the projection of @xmath243 on to @xmath205 is the same as projection of @xmath244 on to @xmath245 and @xmath246 on to @xmath18 i.e. @xmath247^t$ ] where @xmath248 denotes the projection operator which projects every vector in @xmath69 on to @xmath249 .",
    "thus , in order to compute the directional derivative of @xmath217 , it is enough to consider the directional derivative of the projection operator on to individual simplices and then juxtaposing them would give us the directional derivative of @xmath217 .",
    "the computation of the directional derivative of a projection operation on to a simplex can be found in @xcite which we shall state here .",
    "let @xmath250 and @xmath251 .",
    "then , @xmath252 where @xmath253 , s.t .",
    ", @xmath254 .",
    "let @xmath255 .",
    "fix @xmath256 be a initial point of the o.d.e .",
    "[ o.d.e . ] and",
    "the corresponding unique solution be @xmath257 .",
    "then , @xmath258    by substituing [ dd ] and the fact that @xmath259 in the above equation we get , @xmath260 where the last inequality follows from the application of cauchy schwartz and the fact that @xmath261 .    therefore along every solution of the o.d.e .",
    "] , the value of the potential function @xmath262 reduces and hence the above o.d.e . converges to an internally chain transitive invariant set contained in @xmath263 .    in the following lemma",
    "we shall prove that @xmath264 is an equilibrium point of o.d.e .",
    "[ o.d.e.].*lemma 6.2 : if @xmath264 , then , @xmath265.*proof : if @xmath264 is such that @xmath266 , then @xmath267 .",
    "assume @xmath268 .",
    "since @xmath264 , @xmath269 . by cauchy schwartz inequality , @xmath270 and @xmath271 .",
    "since their sum is zero , we get , @xmath272 and @xmath273 . hence , @xmath274 and @xmath275 . by , definition of @xmath276 in equation [ dd ] ,",
    "we get , @xmath277 and @xmath278 . substituing for @xmath279 and @xmath280 in the expression for @xmath281 and @xmath282 and using the fact that @xmath283^t$ ] we get the desired result.@xmath99 * *    in fact the converse is also true and the proof is similar to that of the previous lemma . therefore @xmath284 where @xmath285 denotes the set of equilibrium points of o.d.e.[o.d.e . ] .",
    "the following lemma says that every point in the set @xmath286 is a partial optimum of the biconvex function @xmath186.*lemma 6.3 : @xmath287 , then , @xmath288 and @xmath289.*proof : if @xmath287 is such that @xmath266 , then by lemma 4.5 the result follows .",
    "assume @xmath268 .",
    "then by lemma 6.2 we have , @xmath277 and @xmath278 . * *    by equation [ dd ] , @xmath290 and hence @xmath291 . therefore @xmath292 . by convexity of @xmath293 and",
    "proposition 1.1.8 in @xcite , we get @xmath289 .    by equation [ dd ] , @xmath294 and hence @xmath295 .",
    "therefore @xmath296 .",
    "since @xmath297 , we get , @xmath298 . thus by convexity of @xmath299 and by proposition 1.1.8 in @xcite , we have , @xmath300.@xmath99    even though the proof guarantees convergence to the set of partial optimum of the biconvex function in simulation on various test cases it was observed that the iterates converge to the set of nash equilibria of the game @xmath0 .",
    "in the simulations carried out , in order to perform the projection operation in every iteration we use the procedure in @xcite .",
    "we consider the following version of the standard rock - paper - scissor game .",
    "@xmath301 in the above game , @xmath302 is the only nash equilibrium strategy .",
    "having started the algorithm from a random initial point , variation of the objective function value and the strategies are shown in the plots below .",
    "0.47     0.495     the plots in fig:[fig : rps_ap ] show that the action probabilities converge to the nash equilibrium of the game . as the action probabilities converge to nash equilibrium strategy the objective function value approaches zero as seen in fig:[fig : rps_obj ] .",
    "the general form of jordan s game can be found in @xcite .",
    "we consider the following version .",
    "* player 3 action @xmath303 : @xmath304 * player 3 action @xmath305 : @xmath306    in the above game , @xmath307 is the only nash equilibrium strategy . having started the algorithm from a random initial point , variation of the objective function value and the strategies",
    "are shown in the plots in fig:[fig : jg_ap ] and fig:[fig : jg_ap_obj ] .",
    "0.435     0.485     0.435     0.45     simulations were also carried out on other versions of this game obtained from the general form in @xcite and convergence to nash equilibrium was observed .",
    "the following game was introduced in @xcite in order to show non - convergence of certain class of algorithms .",
    "the game is stated below .",
    "@xmath308 in the above game , @xmath309 and @xmath310 are the two nash equilibrium strategies .",
    "having started the algorithm from a random initial point , variation of the objective function value and the strategies are shown in the plots in fig:[fig : hm_ap ] and fig:[fig : hm_obj ] .",
    "0.428     0.428       @xmath311    in the above game , @xmath312 is the set of nash equilbria .",
    "having started the algorithm from a random initial point , variation of the objective function value and the strategies are shown in the plots in fig:[fig : ie_ap ] and fig:[fig : ie_obj ] .",
    "0.46     0.4",
    "we have presented optimization problems ( @xmath203 and @xmath206 ) such that the global minima of these optimization problems are nash equilibria of the game @xmath0 .",
    "the objective functions were shown to be bi - convex and in case of @xmath203 the objective function was also shown to be an invex function .",
    "we also considered a projected gradient descent scheme and proved that it converges to a partial optimum of the objective function . even though the proof gaurantees convergence to the set of partial optimum in various test cases considered we have seen convergence to a nash equilibrium strategy .    in future",
    "we wish to extend the above optimization problem formulation to discounted stochastic games and prove convergence to nash equilibrium or construct a counter example where the algorithm converges to a partial optimum which is not a nash equilibrium strategy .",
    "99 von neumann j.and o. morgenstern .",
    "theory of games and economic behaviour , princeton university press .",
    "equilibrium points in n - person games .",
    "proceedings of national academy of sciences , vol 44 , pp 48 - 49 , 1950 .",
    "lemke c. e. and j. t. howson .",
    "equilibrium points of bimatrix games .",
    "siam journal on applied mathematics , vol 12 , pp 413 - 423 , 1964 .",
    "s. govindan and r. wilson . a global newton method to compute nash equilibria .",
    "journal of economic theory , vol 110,issue 1 , pp 65 - 86 , 2003 .",
    "p c. a. floudas and v. vishweswaran .",
    "a global optimization algorithm for certain classes of nonconvex nlps - i .",
    "computers chem .",
    "engng , vol .",
    "1397 - 1417 , 1990 .",
    "j. gorski , f. pfeuffer and k. klamroth .",
    "biconvex sets and optimization with biconvex functions - a survey and extensions .",
    "methods of operations res , vol 66 , issue 3 , pp 373 - 407 , 2007 . v. s. borkar .",
    "stochastic approximations : a dynamical systems viewpoint .",
    "dimitri p. bertsekas .",
    "convex optimization theory .",
    "r. d. mckelvey .",
    "a liapunov function for nash equilibria . social science working paper , california institute of technology , 1998 .",
    "yunmei chen and xiojing ye .",
    "projection onto a simplex .",
    "p. dupuis and a. nagurney .",
    "dynamical systems and variational inequalities .",
    "annals of operations research , vol 44 , pp 7 - 42 , 1993 .",
    "sergiu hart and andreu mas - colell .",
    "uncoupled dynamics do not lead to nash equilibrium .",
    ", vol 93 , pp 1830 - 1836 , 2003 .",
    "sergiu hart and andreu mas - colell .",
    "stochastic uncoupled dynamics and nash equilibrium . games and economic behaviour , vol 57 ,",
    "pp 286 - 303 , 2006 ."
  ],
  "abstract_text": [
    "<S> in this paper we present optimization problems with biconvex objective function and linear constraints such that the set of global minima of the optimization problems is the same as the set of nash eqilibria of a n - player general - sum normal form game . </S>",
    "<S> we further show that the objective function is an invex function and consider a projected gradient descent algorithm . </S>",
    "<S> we prove that the projected gradient descent scheme converges to a partial optimum of the objective function . </S>",
    "<S> we also present simulation results on certain test cases showing convergence to a nash equilibrium strategy . </S>"
  ]
}