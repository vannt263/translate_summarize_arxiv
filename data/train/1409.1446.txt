{
  "article_text": [
    "safety line is a company that offers innovative solutions ( software and statistical analysis ) for risk management in the field of air transport ( airlines , maintenance organizations , airports ... ) .",
    "the main expertise of safety line relies in hazard identification and risk assessment , assurance and safety promotion .",
    "+ the objective of safety line for this cemracs project is to improve its technical modeling of plane systems . to monitor the proper functioning of a given system ,",
    "their overall approach is to follow the time evolution of an indicator of the state of the system and detect deviations from the expected behaviour , which could be indicative of a malfunction . for this ,",
    "the main challenge is to estimate as precisely as possible and at any time the value of this indicator in normal operating conditions .",
    "in this project , we are interested in evaluating the state of the plane braking system . to this aim , we chose to focus on the indicator given by the deceleration force of the plane during landing , from the moment when the plane wheels touch the ground up to the moment when the plane leaves the track .",
    "indeed , the deceleration force of the plane is the sum of an aerodynamic component and a component related to the brakes .",
    "there are no wear on the aerodynamic component , unlike that of the brakes which varies according to the state of the system .",
    "+ to this aim , we have at our disposal a database containing the measurements recorded over @xmath1 landings . for each landing ,",
    "different time - dependent quantities are available such as the deceleration profile , the angle of the brake level manipulated by the pilot , the speed of the plane ... + the goal of this project is to build a purely statistical model from the available data , which can be used to reconstruct the deceleration force profile of the plane given a new set of input quantities . to achieve this task , we chose a bayesian approach based on gaussian processes , inspired from ideas of  @xcite and present the results we obtained with this approach .",
    "we also compared our strategy with other regression models which were already used by safety line , such as linear regression methods or random forests .",
    "the approach using gaussian processes seems to perform significantly better than all these other methods .",
    "+ in section  [ sec 1 ] , we detail the structure of the database we trained our model on , before moving to the presentation of the bayesian approach with gaussian processes in section  [ sec 2 ] .",
    "the numerical results we obtained are commented in section  [ sec 3 ] . in section  [ disc ] , we provide some discussions about other methods that take into account time series influence in the prediction model .",
    "as announced in the introduction , we are interested in reconstructing the time - dependent profile in the deceleration force of the plane during landing , which is a good indicator of the state of the braking system , from given input quantities",
    ". + the objective of building this statistical model is to detect malfunctions of the plane from the deviation of the recorded deceleration force profile to the predicted one . in order to do so ,",
    "ideally , our statistical model should be trained on data recorded for planes whose braking systems are new , or at least in a good state .",
    "unfortunately this is a piece of information we did not have access to .",
    "thus , we trained our model on the data we had at hand , the main objective being to demonstrate the feasibility and potential of our approach .",
    "+ however , the state of the braking system of most planes recorded being hopefully good for most planes in average , it is reasonable to think that this data will nevertheless be sufficient to provide information on the mean behaviour of deceleration profiles of planes during landing , and that it should give useful indications in order to detect malfunctions of their braking system .",
    "+ at this point , a first difficulty was to clearly define the set of inputs our statistical model will be built on .",
    "indeed , for each landing , a huge amount of data is recorded and we have to select the quantities that are meaningful for the reconstruction of the deceleration force profile .",
    "we chose to select input quantities that enable us to evaluate the different forces which act on the plane during its landing . +",
    "all time - dependent data are provided discretely with one measurement per second during a period of @xmath2 seconds .",
    "thus , for any quantity @xmath3 , its profile during landing will be characterized by a vector of size @xmath4 , @xmath5 , where @xmath6 denotes the measurement of the quantity @xmath3 at time @xmath7 .",
    "we consider the following input data : +    * the weight of the plane @xmath8 ; + * the initial kinetic energy of the plane @xmath9 , where @xmath10 is the initial speed of the plane ; + * the speed of the plane during the landing @xmath11 ; + * the thrust force @xmath12 , where for all time @xmath13 , @xmath14 is evaluated as the product of the square of the speed of the plane @xmath15 times the level of the reverse throttle ; + * the vector @xmath16 ; at any time @xmath13 , @xmath17 is equal to the product of the speed times the angle of the brake level , thus @xmath18 gives an indication of the braking force during landing ; * the drag force @xmath19 , which is a function of @xmath15 at any time @xmath20 .",
    "all these quantities , except the weight and the initial kinetic energy , are time - dependent functions .",
    "note that rebuilding the deceleration from only the speed of the plane is not that obvious .",
    "in fact , the sensors are not optimal ( because of the noise ) , so that the derivative of the speed signal is not equal to the measured deceleration profile .",
    "this leads to additional difficulties .",
    "the output quantity we wish to reconstruct is the deceleration force of the plane @xmath21 , given as a vector @xmath22 , where for all @xmath23 , @xmath24 is equal to the product of the deceleration times the mass of the plane .",
    "+      we consider a training data set which contains the recordings related to @xmath25 different landings . in all the rest of the document",
    ", the superscript @xmath26 @xmath27 refers to the label of the landing recorded in the database ; the index @xmath28 refers to the type of input quantity among the @xmath29 considered and presented in section  [ sec 1.2 ] ( weight , initial kinetic energy , speed , thrust force , braking force and drag force ) ; lastly , the superscript @xmath30 refers to the instant of the measurement ( @xmath23 ) .",
    "+ more precisely , the data recorded for the @xmath31 landing at a time @xmath32 consists of : + @xmath33 where we use the same quantities as those introduced in sections  [ sec 1.2 ] and  [ sec 1.3 ] .",
    "+ we also denote by @xmath34 and @xmath35 .",
    "thus , for all @xmath36 , @xmath37 and @xmath38 . the training data set can then be written as @xmath39 .",
    "we also denote by @xmath40 ( respectively @xmath41 ) the set of input ( respectively output ) quantities of the database . for all @xmath23",
    ", we also define @xmath42 .",
    "we use here a bayesian approach presented in  @xcite .",
    "+ let @xmath43 be a probability space .",
    "all input and output quantities are considered as random vectors .",
    "+ let @xmath13 be a fixed time .",
    "we assume that , for all @xmath44 ( random ) value of the input quantities , the associated observed value of the output quantity at time @xmath30 , denoted by @xmath45 , can be written as : + @xmath46 where @xmath47 is a ( random ) function @xmath48 such that @xmath49 is equal to the true value of the output quantity at time @xmath30 for the input @xmath50 , and where @xmath51 is a random variable modeling the error due to the noise made on the measurement of the output quantity a time @xmath30 .",
    "more generally , for a set of @xmath52 random inputs , @xmath53 , if we denote by @xmath54 the set of measured associated output values , @xmath55 and @xmath56 the set of noises made on the measurement of the output quantities , we have + @xmath57    in a bayesian framework , the law of @xmath58 is called the _ likelihood _ and is chosen a priori .",
    "it is directly related to the choice of the law of the random vector @xmath59 modeling the noise made on the measurements of the output quantity . in the sequel",
    ", we will assume that the variables @xmath60 are independent , identically distributed , centered gaussian variables with variance @xmath61 , so that @xmath59 is a random gaussian vector of law @xmath62 where @xmath63 denotes the identity matrix of @xmath64 .",
    "thus , @xmath65 besides , the law of the function value @xmath66 conditioned to the knowledge of the value of the input @xmath50 is called the _ prior distribution _ and is also chosen a priori .",
    "we use here a model where @xmath67 is assumed to be a gaussian process characterized by its mean @xmath68 and covariance function @xmath69 , i.e. @xmath70 in particular , this implies that @xmath71 is a random gaussian vector of size @xmath72 , of mean @xmath73 and covariance matrix @xmath74 where    @xmath75    thus , @xmath76 . in the sequel",
    ", we assume that @xmath77 and that the covariance function ( or kernel ) @xmath78 is chosen as a squared exponential covariance function defined by : + for all @xmath79 , @xmath80 , + @xmath81\\ ] ] where @xmath82 denotes the frobenius norm on vectors of dimension @xmath4 .",
    "+ the parameters @xmath83 @xmath84 , @xmath85 , which the prior distribution and likelihood depend on , are positive real numbers called _ hyperparameters , and their values depend a priori on the time @xmath20 . they have to be chosen in an appropriate way which is detailed in section  [ sec 2.3 ] . _    at this point",
    ", we would like to comment on the simplistic choice we made assuming that the mean function @xmath86 should be zero , and in the particular form of the kernel function @xmath78 we introduced above .",
    "of course , this choice is not the only possibility and one could think for instance to borrow ideas from kriging methods in order to obtain a better guess of this mean function .",
    "the universal kriging technique is an example of such a method which could be used to evaluate the function @xmath86 .",
    "indeed , in this case , the function @xmath86 is approximated by @xmath87 for some @xmath88 , where @xmath89 is a set of a priori fixed basis functions , and @xmath90 are real coefficients which can be viewed as an additional set of hyperparameters and which are to be determined from the database we have at hand . however , in our case , because of the high - dimensional character of the input quantities of our database ( @xmath91 variates ) , the choice of a meaningful set of basis functions and the identification of associated parameters is a quite intricate task .",
    "indeed , even if we chose a simplistic linear regression model , we would have to fit @xmath92 additional hyperparameters .",
    "it would be interesting though to test if the choice of a better mean function @xmath86 could help in improving the results we obtained .",
    "as announced above , the numerical results presented below were obtained in the simple case where the mean function @xmath86 is assumed to be @xmath93 .",
    "assume for now that the values of the hyperparameters @xmath83 @xmath84 , @xmath94 ( @xmath95 ) , have been chosen for the time @xmath30 .",
    "+ let @xmath96 and @xmath97 be a set of @xmath98 new input vectors such that a priori @xmath99 is not included in the set @xmath100 of input values of the database .",
    "we present in this section how the set of the values of the deceleration of the plane at the time @xmath30 for each input vector , @xmath101 , can be reconstructed using the regression model based on gaussian processes .",
    "+ let us consider a test random vector of input quantities @xmath102 and denote by @xmath103 where for all @xmath104 , @xmath105 is the `` true '' output value for the input vector @xmath106 . + the joint distribution of the previously observed target values @xmath107 and the randon vector @xmath108 can be written as ( using the gaussian process model introduced in the preceding section ):",
    "@xmath109 \\sim   \\mathcal{n } \\left ( 0 , \\left [   \\begin{array}{cc } k_{\\textbf{x},\\textbf{x}}+ \\sigma^2i_{n_{ob } } & k_{\\textbf{x},\\textbf{x}_*}\\\\ k_{\\textbf{x}_*,\\textbf{x } } & k_{\\textbf{x}_*,\\textbf{x}_*}\\\\ \\end{array}\\right ] \\right),\\ ] ] where @xmath110 @xmath111 @xmath112 we thus obtain the law of @xmath113 which reads @xmath114    where @xmath115 , \\\\ & =   k_{\\textbf{x}_*,\\textbf{x}}\\big ( k_{\\textbf{x},\\textbf{x}}+ \\sigma^2i_{n_{ob } } \\big ) ^{-1}\\textbf{y}^t,\\\\ \\textbf{s}_*^t     & = k_{\\textbf{x}_*,\\textbf{x}_*}-k_{\\textbf{x}_*,\\textbf{x } } \\big [    k_{\\textbf{x},\\textbf{x}}+\\sigma^2i_{n_{ob}}\\big ] ^{-1 } k_{\\textbf{x},\\textbf{x } _ * } \\end{aligned}\\ ] ]    for all @xmath104 , the vector of the reconstructed values of the deceleration of the plane at time @xmath30 , @xmath116 associated to the set of input quantities @xmath117 is then given by @xmath118=   k_{x_*,x_d}\\big [ k_{x_d , x_d}+ \\sigma^2i_{n_{ob } } \\big ] ^{-1}y_d^t,\\\\\\end{aligned}\\ ] ] thus , for all @xmath119 , @xmath120 can be seen as a particular linear combination of the output values @xmath121 belonging to the database .",
    "the full time - dependent evolution of the deceleration force profile is then given by @xmath122 .",
    "we thus have built a purely statistical regression model from the database @xmath123 we have at our disposal : + @xmath124 from a training database @xmath123 , and a set of new random onput vectors @xmath125 , this regression model enables to reconstruct the profile of the deceleration force of the plane during the landing @xmath126 for the value of the input quantities @xmath127 ( @xmath104 ) .",
    "let us denote by @xmath128 a set of hyperparameters for the bayesian gaussian process model introduced in section  [ sec 2.1 ] , and let us denote by @xmath129 the random matrix defined by   using the kernel function @xmath78 defined by   with this set of hyperparameters .",
    "+ in this section , we present how we choose the value of these hyperparameters ( which a priori depends on the time @xmath30 considered ) , @xmath130 , which we use in order to build the regression model for the reconstruction of the deceleration force profile of the plane , as described in section  [ sec 2.2 ] .",
    "+ the probability density functions of the random variables @xmath131 and @xmath71 are functions which depend on the value of these hyperparameters and we denote then respectively by @xmath132 and @xmath133 . the probability density function of the variable @xmath134 is called the _ marginal likelihood _ , depends also on the value of the hyperparameters @xmath135 and can be expressed as a function of the prior and likelihood distributions @xmath136    using the gaussian process model described in the preceding section , we can derive an explicit expression of the _ log marginal likelihood _ @xmath137 as follows ( see  @xcite ) : @xmath138    a classical approach to set the values of the hyperparameters for a given time @xmath139 in an optimal way is to maximize the marginal likelihood of the database we have at our disposal , in other words , @xmath140 is chosen to be solution of @xmath141 where @xmath142 thus , this set @xmath130 of hyperparameters is chosen to be the one which makes the database we have `` as likely as possible '' . + in principle , the values of the hyperparameters @xmath130 should be computed for each time @xmath139 , which would lead to the resolution of @xmath143 optimization problems depending on @xmath144 parameters each .",
    "this ideal approach is too costly from a computational point of view , so we adopted a simplified approach which requires however to make additional assumptions on the law of the process @xmath145 . + for @xmath146 ,",
    "let us introduce @xmath147 such that @xmath148 instead of computing different sets of hyperparameters @xmath130 for all times @xmath139 , we only compute for all @xmath149 , one set of hyperparameters @xmath150 which will be the same for all times @xmath30 belonging to the time subinterval @xmath151 $ ] . to compute the optimal value @xmath150 of this set of hyperparameters , we make an additional assumption on the law of @xmath145 : we assume that for all @xmath152 , the random vectors @xmath134 are independent from one another for all @xmath153 $ ] .",
    "this implies that we assume that there is no correlation between the values of the observed output quantities at two different times belonging to the same time subinterval @xmath151 $ ] , which is not true in general of course .",
    "however , this very crude assumption enables us to significantly simplify the calculations of the hyperparameters while the produced regression model gives very reasonable results as will be seen in section [ sec 3 ] .",
    "+ for all @xmath152 , the optimal value of the hyperparameters @xmath150 is then chosen as the solution of the following optimization problem @xmath154 where @xmath155 in the numerical results presented in section  [ sec 3 ] , we illustrate two different ways to choose the times @xmath156 :    * a first choice consists in taking @xmath157 , and thus @xmath158 and @xmath159 ; in this case , we only compute one set of hyperparameters @xmath160 which are valid for the reconstruction of the deceleration profile of the plane at all times @xmath139 ; * a second choice , consists in taking @xmath161 and for all @xmath152 , @xmath162 ; the true interval @xmath163 $ ] is partitioned into @xmath164 time subintervals and we compute @xmath164 sets of optimal hyperparameters for each of these subintervals .    in section  [ sec 3 ] , we compare the results obtained with the first and second strategy .",
    "the optimization problems   are solved in practice using a standard gradient algorithm .",
    "as mentioned before , we compared the approach we detailed in section  [ sec 2 ] . to this aim",
    ", we consider the following different strategies :    * linear regression ( lr ) ; * generalized additive model ( gam ) ; * multivariate adaptative regression splines ( mars ) ; * random forests ( rf ) .",
    "we denote respectively by @xmath165 , @xmath166 , @xmath167 and @xmath168 the obtained regression models with the training database @xmath123 , which are all applications from @xmath169 to @xmath170 .",
    "let us present the general idea of each of those models except for the well - known linear regression , using the notation of the preceding section .",
    "for the sake of brievity , we do not give all implementation details here .",
    "+ the generalized additive model ( see  @xcite ) is an extension of the generalized linear regression approach to non - linear relationships proposed by hastie and tibshirani .",
    "this model is constructed as a sum of smooth functions of each of the covariates .",
    "the interest of such a method is that each smooth function is able to reproduce any shapes .",
    "the smooth functions were estimated by cubic regression splines .",
    "in other words , for all @xmath104 , if @xmath171 , then the associated deceleration profile @xmath172 is reconstructed as follows @xmath173 where @xmath174 is a smooth function for all @xmath175 and @xmath176 . + mars ( see  @xcite ) is an automatic procedure for modeling the output using the most significant non - linear relationships and interactions between covariates .",
    "the model is a sum of basis functions which are either a single hinge function or either a product of one or more hinge functions  .",
    "a hinge function is a piecewise function with two pieces on both sides of a knot .",
    "one piece is set at zero and the other piece corresponds to a linear function . for all @xmath177 ,",
    "then @xmath172 is reconstructed as follows @xmath178 where @xmath179 are the intercept and the slope parameters and @xmath180 being @xmath8 smooth real - valued functions defined on @xmath181 .",
    "mars automatically selects the most significant basis functions by applying a procedure with two steps : a forward pass and a pruning pass .",
    "the forward pass delivers a model with too many basis functions that overfit the data while the pruning pass removes the least significant basis functions to obtain the most accurate sub - model .",
    "the forward pass selects iteratively the best reflected pair of hinge function among all possible functions .",
    "the set of possible functions is built taking all observed covariates values as a knot .",
    "then , the pruning pass removes the least significant basis function one by one until it finds the most accurate subset of basis functions .",
    "+ finally , random forests ( see  @xcite ) is a machine learning algorithm .",
    "such a model is composed by an ensemble of decision tree models built on random learning datasets .",
    "briefly , a tree model is a recursive partitioning of the observations according to their similarities in covariates and output .",
    "tree models are built using the classification and regression tree ( cart ) algorithm .",
    "the initial dataset is split into two clusters according to a threshold value for one covariate : one cluster have higher value or the other cluster lower value .",
    "the algorithm evaluates all possible thresholds and selects the one which minimizes the total sum of squared errors .",
    "the partitioning is repeated for each cluster until there are less than @xmath182 observations per cluster .",
    "the random forest algorithm creates @xmath183 tree models from @xmath183 random samples of the original dataset .",
    "the output estimated by random forest is an average of the individual estimation of all tree models .      to assess the validity of a regression model @xmath184 such as the ones presented in section  [ sec 2 ] or in section  [ sec 3.1 ]",
    ", we perform _ cross - validation _ tests .",
    "the principle is the following : the full database @xmath123 we have at our disposal is composed of @xmath25 different landings , so that @xmath185 using the notation of section  [ sec 1.4 ] . a regression model @xmath186 ( which can be built for instance using the bayesian approach with gaussian processes we detailed in section  [ sec 2 ] ) depends of course of the information contained in @xmath123",
    ". cross - validation tests consist in training a regression model from a smaller database than the one we have access to , and , for all the recordings which were drawn from the training database , to compare the profile of the output quantities reconstructed from the statistical regression model and the measured output profile .",
    "more precisely , let @xmath187 be @xmath188 disjoint sets of recording indices .",
    "for all @xmath189 , we denote by @xmath190 the regression model built from the database @xmath191 using one of the strategies presented in sections  [ sec 2 ] or  [ sec 3.2 ] , where @xmath192 let us assume for the sake of simplicity that for all @xmath189 , @xmath193 . assessing the validation of a regression model @xmath184 amounts to comparing the error between the measured output profiles @xmath194 and the reconstructed output profile @xmath195 taking @xmath196 as a test input set .",
    "we performed cross - validation tests with these five different models using @xmath197 training data sets such that for all @xmath198 , @xmath199 .",
    "for the gaussian process model , we tried two different strategies for the splitting of the time interval for the fitting of hyperparameters as mentioned in section  [ sec 2.3 ] . in section  [ sec 3.3.1 ] , we compared the different regression strategies using only the gaussian process model reconstructed with @xmath157 time subinterval . in section",
    "[ sec 3.3.2 ] , we compare the results obtained for @xmath200 with @xmath157 or @xmath161 subintervals .",
    "the curve legen is the following :    * the black dots curve refers to the trye measured data ; * the black line curve refers to the gaussian process model ; * the black dashed line curve refers to the linear regression , * the black dotted line curve refers to the generalized additive model ; * the grey line curve refers to the random forest strategies ; * the grey dashed line curve refers to the multivariate adaptative regression splines ( mars ) .",
    "we apply the five regression strategies on this problem and we draw the curve of each estimated deceleration profile on two different landings , the @xmath201and the @xmath202 landing for example ( see figure 1 ) , but only on the first @xmath203 seconds .",
    "this is the time period when the influence of the braking system is the most important during the landing .",
    "cc    & [ 2lan ]     +    we can clearly see on these two examples that the gaussian process approach is the one that fits best the measured deceleration profiles .",
    "this was observed for the majority of the landing profiles considered .    in figure  2 , we plot the median absolute percentage error ( mape ) for all models , which is defined by the following formula ( using the notation of section  [ sec 3.2 ] ) : + @xmath204 from this criterion , it can be seen that the gaussian process approach we propose significantly improves the predictive quality of the regression models previously used by safety line .    [ eror ]",
    "the histogram of the number of errors plotted in figure  3 provides another criterion to compare the different regression models .",
    "more precisely , for all @xmath205 , the histogram plots the cardinal of the set @xmath206    [ hist ]    of course , a high - quality model will produce a large number of errors for small values of the error threshold @xmath207 and a small number of errors for large values of @xmath207 .",
    "this is indeed the case for the gaussian process model , and we can see that it also performs significantly better than the other regression models from this point of view .",
    "+      let us now compare the results we obtained with the gaussian process model presented in section  [ sec 2 ] , where we used only @xmath157 time interval , or @xmath161 different time subintervals .",
    "+ in this figure , we compare the error associated to these two different strategies , for each subintervals of @xmath164 seconds .",
    "in other words , for each @xmath208 , we compute the mape error @xmath209 for the two strategies , where @xmath210 and @xmath211 . + as expected , using different time subintervals improves the results , especially in the last part of landing .",
    "in this section , we wish to comment the way time correlations are taken into account in our model described in section  [ sec 2 ] through the very simplistic choice of the kernel @xmath78 we used here ( [ ker ] ) .",
    "let us first note that it is quite usual in time - dependent regression models that the output quantity to be reconstructed at time @xmath30 , @xmath212 , usually depends only on the value at time @xmath30 of an input quantity @xmath213 ( see  @xcite for instance ) . however , this is clearly not the case here since the deceleration of the place at an instant @xmath30 depends a priori on all the set of past input values @xmath214 .",
    "the form of the kernel function @xmath78 enables to take into account in some way the fact that the value of the ouput quantity @xmath212 at time @xmath30 depends on the whole trajectory @xmath214 .",
    "the dependence of the value of @xmath212 on the different values @xmath215 is somehow aggregated through the use of the frobenius norm @xmath216 , which is of course a very naive approach .",
    "one shortcoming of this model in particular is that the value @xmath212 then depends on the _ future values of the input quantities , which is of course unrealistic from a physical point of view .",
    "_    this very simplistic approach is sufficient to yield very satisfactory numerical results though and seems to capture somehow some features of the time correlations between input and output data",
    ". a possible explanation of the significant improvement of the results using our gaussian process based approach compared with the other methods we presented in this proceeding ( which do not take time correlation into account as well ) may be the following .",
    "+ in our approach , a new output signal is reconstructed as a linear combination of other signals that are already present in the database .",
    "however , other methods reconstruct the output signal as a linear combination of input signals , which are not of the same nature as the output signal , and may present different behaviour of time correlation effects .",
    "this particularity of the gaussian process based approach may account for the fact that the time dependencies of the output signal are qualitatively well reproduced in our case , even if we use such a naive way to incorporate time correlation effects in our statistical model .    in the rest of the section ,",
    "let us comment on different strategies which could have been used to incorporate time correlation effects using gaussian processes approach in our regression model .",
    "a first strategy could have been to consider the time @xmath217 as a random variable , in the same way as the input quantity @xmath50 .",
    "this would require to modify the mean function @xmath86 and kernel function @xmath78 so that they do not only depend on values of the input quantities @xmath50 but also on time .",
    "more precisely , following ideas of  @xcite , the output quantity @xmath218 could be modeled by @xmath219 where @xmath220 would be a random function to be determined by the regression model and @xmath221 a white noise random process for instance . using similar notation as those used above",
    ", the random value @xmath222 could be modeled as a gaussian process characterized by a mean @xmath223 and a covariance kernel @xmath224 so that the law of @xmath225 would be given by @xmath226 such an approach would enable to take into account correlations between values of the output and input quantities at different times in a natural way .",
    "the difficulty we encounter with such an approach is that the standard reconstruction procedure derived from this gaussian process approach requires the inversion of a matrix of size @xmath227 where @xmath228 in our case .",
    "the large size of this matrix makes its inversion very difficult from a practical point of view .",
    "however , in  @xcite , the authors proposed to convert such a _ spatio - temporal gaussian process into an infinite - dimensional kalmann filtering .",
    "the interest of such an approach is that the complexity of such an approach is linear ( instead of cubic ) in the number of time steps , thus avoiding the numerical difficulties mentioned above .",
    "we did not test this strategy in our case though .",
    "_    however , a second ( more tractable ) way to improve the choice of this kernel function could rely in the modification of the kernel function @xmath78 in order to take into account time correlatiosn as follows . indeed , using the squared exponential kernel function  , in order to reconstruct the value of the deceleration of the plane at a time @xmath30 , all the values of the input quantities at all times have the same importance , which is of course unrealistic .",
    "one would reasonably expect that that only the values of the input quantities at times anterior to @xmath30 would affect the value of the output quantity at a time @xmath30 .    to take this into account",
    ", one could think of using at each time @xmath30 a modified kernel function @xmath229 defined as follows : + for all @xmath230 @xmath231 , @xmath232\\ ] ] where the standard frobenius norm @xmath82 would be replaced by a modified semi - norm @xmath233 , which would depend on @xmath30 and could be written as follows : for all @xmath234 , @xmath235 with a weight function @xmath236 , satisfying @xmath237 for all @xmath238 ( the standard frobenius norm used in   corresponds to @xmath239 for all @xmath13 ) .",
    "it would be interesting to test if these modifications could improve the quality of our regression model .",
    "this strategy would lead to an additional computational cost though : it woud require the storage of @xmath4 matrices of size @xmath240 corresponding to all the matrices @xmath241 even if such a procedure could be more easly implementable than the first approach we described , we did not test this strategy here . it would be interesting though to check if one of these two possible strategies could help improving the numerical results presented in section  [ sec 3.3 ] .",
    "the authors thank tony lelivre and nicolas chopin for very helpful discussions .",
    "labex amies is granted for financial support .",
    "this work was done in a summer school `` cemracs 2013 '' .",
    "we would like to thank the organizers of this school .",
    "finally , houssam alrachid would like to thank `` enpc '' and `` cnrs libanais '' for supporting his phd thesis .",
    "l. breiman , _ random forests _ , machine learning 45 ( 2001 ) , 5 - 32 . p. hall , h. muller and f. yao , _ modelling sparse generalized longitudinal observations with latent gaussian processes _ , j. r. statist .",
    "b ( 2008 ) . j.h .",
    "friedman , _ multivariate adaptive regression splines _ , the annals of statistics 19 ( 1991 ) .",
    "t. hastie and r.tibshirani , _ generalized additive model _ , chapman and hall ( 1990 ) .",
    "s. sarkka , s. member , ieee , a. solin , and j. hartikainen , _ spatio - temporal learning via infinite - dimensional bayesian filtering and smoothing _ , ieee signal processing magazine .",
    "rasmussen and c.k.i .",
    "williams , _",
    "gaussian processes for machine learning _ ,",
    "massachusetts institute of technology ( 2006 ) .",
    "b. xu , z. shi , _ universal kriging control of hypersonic aircraft model using predictor model without back - stepping _ , iet control theory and applications ( 2012 ) ."
  ],
  "abstract_text": [
    "<S> we present numerical results obtained on the cemracs project predictive sms proposed by safety line . </S>",
    "<S> the goal of this work was to elaborate a purely statistical method in order to reconstruct the deceleration profile of a plane during landing under normal operating conditions , from a database containing around @xmath0 recordings . </S>",
    "<S> the aim of safety line is to use this model to detect malfunctions of the braking system of the plane from deviations of the measured deceleration profile of the plane to the one predicted by the model . </S>",
    "<S> this yields to a multivariate nonparametric regression problem , which we chose to tackle using a bayesian approach based on the use of gaussian processes similar to the one presented in @xcite . </S>",
    "<S> we also compare this approach with other statistical methods .    </S>",
    "<S> nous prsentons des rsultats numriques obtenus sur le projet cemracs predictive sms propos par safety line . </S>",
    "<S> lobjectif de ce travail tait dlaborer une mthode purement statistique afin de reconstruire le profil de dclration dun avion durant son atterissage ,  partir dune base de donnes contenant  peu prs @xmath0 enregistrements . </S>",
    "<S> le but de safety line est dutiliser ce modle pour dtecter des anomalies du systme de freinage de lavion  partir de lcart entre le profil de dclration de lavion mesur et celui prdit par le modle . </S>",
    "<S> ceci mne  un problme de rgression multivari non paramtrique que nous avons choisi de traiter via une approche baysienne utilisant des processus gaussiens similaire  celle prsente dans @xcite . </S>",
    "<S> nous comparons galement cette approche avec dautres mthodes statistiques classiques . </S>"
  ]
}