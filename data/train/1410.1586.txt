{
  "article_text": [
    "the probability density function ( pdf ) @xmath0 of an experimentally measured characteristic @xmath1 , in general , differs from the true physical pdf @xmath2 because of the limited acceptance ( probability ) @xmath3 to register an event with true characteristic @xmath4 , finite resolution and bias in the response function @xmath5 , which describes the probability to observe @xmath1 for a given true value @xmath4 .",
    "formally the relation between @xmath0 and @xmath2 is given by @xmath6 the integration in ( [ p1_main ] ) is carried out over the domain @xmath7 of the variable @xmath4 . in practical applications the experimental distribution is usually discretised by using a histogram representation , obtained by integrating @xmath0 over @xmath8 finite sized bins @xmath9 with @xmath10 the limits of bin @xmath11 .",
    "if a parametric ( theoretical ) model @xmath12 for the true pdf is known , then the unfolding can be done by determining the parameters .",
    "for example , by a least squares fit to the binned data @xcite . here the model , which allows to describe the true distribution by a finite number of parameter values , constitutes a priori information which is needed to correct for the distortions by the experimental setup ,    in contrast , model independent unfolding , as considered e.g. in @xcite , is an ill - posed problem , and every approach to solve it requires a priori information about the solution .",
    "methods differ , directly or indirectly , in the way a priori information is incorporated in the result .",
    "to solve the unfolding problem ( [ p1_main ] ) , a representation of the true distribution has to be chosen",
    ". this representation should be as flexible as possible and allow introducing a priori information .",
    "classical kernel statistics is an example that approximates the true distribution by putting a @xmath13-weighed copy of a kernel pdf at the location of each of @xmath14 observed data points and adding them up ( see e.g. @xcite ) . with enough data ,",
    "this comes arbitrarily close to any pdf .",
    "there exist methods that use a kernel representation of the true distribution to solve also the inverse problem @xcite .",
    "one drawback of this approach is that one has to store all the data points , another is that the known kernel based algorithms expect the response function of a set - up in analytical form , i.e. computer modelling can not be used .    in this paper",
    "the use of a mixture density model ( mdm ) @xcite to describe the true distribution @xmath2 is proposed , @xmath15 where the @xmath16 is the @xmath17th probability density function in mixture ( pdfm ) with parameters @xmath18 and the weight @xmath19 the fraction of the @xmath17th pdfm .",
    "the mdm lies between the cases of the parametric representation of the true density on one hand , i.e. the case when there is only one distribution in the sum ( [ repres ] ) , and the kernel statistics approach where the number of terms in the sum ( [ repres ] ) is equal to the number of observations @xmath14 .",
    "the mdm has a limited number of parameters for representing a pdf and computer modelling can be used to calculate the response of the system .",
    "the mdm is also convenient for taking into account different type of a priori information , such as knowledge about the type of distributions , constraints on parameters , smoothness of the distributions and so on .",
    "ideas and achievements of regression analysis as well as classical kernel statistics can be used in applications of a mdm for estimating the densities .    using eq.([repres ] ) to parameterise the solution @xmath2 reduces the unfolding problem from finding a solution in the infinite - dimensional space of all functions to finding a solution in a finite dimensional space . this way an approximation of the true density is performed",
    "which , in contrast to e.g. a discretisation by a histogram , has the advantage to introduce negligible quantisation errors for sufficiently smooth distributions .    without loss of generality two - parametric pdfms",
    "will be used throughout the paper .",
    "the first parameter , @xmath20 , defines the mean value ( location ) of term @xmath17 and the second one , @xmath21 , represents the standard deviation .",
    "different smooth pdfms commonly employed by kernel statistics , such as biweight , triweight , tricube , cosine , cauchy , b - spline and other kernels can be used .",
    "rather popular is the gaussian mixture model ( gmm ) @xcite with pdfms @xmath22 which provides a rather flexible model in the approximation of a wide class of statistical distributions .",
    "the standard deviation @xmath23 acts as a regularisation parameter , which allows to adjust the smoothness of the result .",
    "weights , positions @xmath24 and standard deviations @xmath23 are determined by the unfolding procedure described below .    substituting @xmath2 as represented by eq([repres ] ) into the basic eq.([p1_main ] ) yields @xmath25 and taking statistical fluctuations into account , the relation between the weights @xmath19 and the histogram of the observed distribution becomes a set of linear equations @xmath26 where @xmath27 is the @xmath8-component column vector of the experimentally measured histogram , @xmath28 is the @xmath29-component vector of weights and @xmath30 is an @xmath31 matrix with elements @xmath32 the vector @xmath33 is an @xmath8-component vector of random deviates with expectation value @xmath34=\\bm{0}$ ] and covariance matrix @xmath35 , the diagonal elements of which being @xmath36=\\mathrm{diag}(\\sigma_1 ^ 2,\\sigma_2 ^ 2,\\cdots,\\sigma_n^2)$ ] , where @xmath37 is the statistical error of the measured distribution for the @xmath11th bin .",
    "each column of the matrix @xmath30 is the response of the system to one of the pdfm in the mixture model for the true distribution .",
    "numerically the calculation of the column vectors can be done by weighting events of a monte carlo sample such that they follow the corresponding pdfm , see ref .",
    "@xcite , and taking the histogram of the observed distribution obtained with the weighted entries .    by a non - negative least - squares fit , the weight vector @xmath38 in eq.([basicp ] ) for a given set of pdfms",
    "is determined such that it minimizes @xmath39 under the constraints @xmath40 following reference @xcite , if an unconstrained solution satisfies eq.([ineq ] ) then @xmath41 solves the constrained problem .",
    "otherwise , the solution to the constrained problem must be a boundary point of @xmath42 and therefore at least one @xmath43 .",
    "it follows that after performing all possible regressions with one or more @xmath19 in eq.([ineq ] ) set to zero , the non - negative problem is solved by picking the subset of @xmath19 satisfying eq.([ineq ] ) such that @xmath44 as defined in eq.([xieq ] ) is smallest . the numerical algorithm and computer program for solving this minimisation problem has been developed in references @xcite . here , first the subset of components equal to zero is determined iteratively , and the vector of the remaining indices @xmath41 is found by simple linear regression @xmath45 where @xmath46 is the submatrix of @xmath30 that corresponds to the subset of indices of positive components of the solution .",
    "the result of the fit is an estimate of the unfolded distribution @xmath47 , defined by a subset of parameters @xmath48 , @xmath49 which are summed with positive weights @xmath50 to yield @xmath51    the choices of the optimal type of pdfms and the values of parameters ( mean values and the standard deviations for the gmm model ) are driven by the accuracy and the complexity of the model .",
    "the goal is a simple , and at the same time , accurate solution of the problem .",
    "a figure of merit for the accuracy is the prediction error ( @xmath52 ) @xcite , defined as the expectation value of the average squared normalised residual when using the predictor @xmath53 to describe an independent experimentally measured histogram @xmath54 drawn from the same parent distribution as the original , @xmath55 \\;.\\ ] ] the expectation is taken over @xmath54 . in the following we will denote the predictor @xmath53 as @xmath56 and call it the fitting histogram .",
    "following reference @xcite , @xmath57-fold cross - validation allows to estimate + @xmath58 . here",
    "the given data set @xmath59 is split into @xmath57 subsets @xmath60 with equal number of events .",
    "the complementary sets are denoted by @xmath61 . applying the minimisation procedure to @xmath62 and forming the predictors @xmath63 , the cross - validation error ( @xmath64 )",
    "is defined by @xmath65 where @xmath66 is the vector of histogram contents for the subset of the data @xmath67 .",
    "the cross - validation error is the estimate of the prediction error @xmath68 in order to have sufficient sampling of the configuration space , the number of folders used in the cross - validation procedure should not be too small .",
    "on the other hand , for statistically meaningful results , it should not be too large either .",
    "practice shows that taking @xmath57 in the range between 5 and 10 usually gives satisfactory results , and that the performance is not sensitive to the exact choice .",
    "the proposed unfolding procedure consists of three steps :      the positions @xmath69 of the pdfms are drawn randomly from a uniform distribution on the allowed range of @xmath4 and with a number of pdfms such that the average distance between individual centers is significantly smaller than the width of the pdfms .    in order to minimise the loss of information due to binning , the number of bins for the measured histogram @xmath27 should be as large as possible . on the other hand , in order to have meaningful error estimates for the least squares fits that determine @xmath70 , the number of entries in a single bin should not be less than @xmath71 .",
    "binning with approximately equal number of events in each bin is preferable .    in this first step",
    "the width for all pdfms in the mixture is taken to be the same , @xmath72 .",
    "different values @xmath73 are tried and the @xmath74 with the smallest cross - validation error @xmath75 is selected .      exploiting the information gained so far",
    ", the procedure is repeated with positions @xmath69 of the pdfms randomly drawn according to the estimate of the true density @xmath76 ( [ px ] ) obtained in the first step . in addition , the widths of the pdfms @xmath77 are taken to be inversely proportional to the square root of the result from the first step at the position @xmath69 @xmath78 with the value of @xmath79 again determined by means of cross - validation .",
    "this second step is motivated by the results of reference @xcite , where it is shown that by this way the bias of a kernel estimation of a pdf can be decreased .",
    "the approach balances better smoothing in less densely populated regions against the possibility to resolve finer structures in regions with a higher sampling .",
    "it is plausible that for the unfolding case the bias on the shape of the density estimate will decrease also .",
    "finally it has to be noted that this second step can be iterated several times , even though practical examples show that the gain is small .",
    "it is recommended to use the same number of pdfms for the second step as in the first step or more .",
    "since the number of terms obtained by the previous two steps can still be large , with not all pdfms contributing independent information , a third step is added to select the most relevant subset . to reduce the number of the pdfms , the non - negative garrote method @xcite is used .",
    "it amounts to taking the set of non - zero weights @xmath80 obtained in the second step and finding coefficients @xmath81 that minimise @xmath82 under the constraints @xmath83 for @xmath84 the solution from the previous step is not touched . for smaller values",
    "the garrote eliminates some of weights and modifies others , such that @xmath85 are the new values of the weights for the pdfms of the estimate the unfolded distribution .",
    "cross - validation is used to choose the optimal garrote parameter @xmath86 . to reduce a potential bias introduced by the garrote ,",
    "the weights of the pdfms are again determined by a non - negative least squares fit on the remaining terms .",
    "the quality of the fit can be assessed with common tools used in regression analysis @xcite :    1 .",
    "@xmath87-value of the fit is defined by @xmath88 , where @xmath89 stands for probability 2 .",
    "analysis of the normalised residuals @xmath90 1 .   as a function of the estimated value @xmath91 2 .   as a function of the observed value @xmath1 3 .",
    "q - q plot : ( data quantile)@xmath92= ( number of residuals @xmath93 versus + ( theoretical quantile)@xmath94 ( @xmath95 ) , @xmath96    since the unfolding procedure described above is not analytically defined , the bootstrap approach @xcite is the method of choice to estimate the statistical uncertainties of the unfolding result . keeping the normalisation of the observed histogram constant , replications are generated according to the multinomial distribution @xmath97 where the set of positive weights obtained in the final step is used .",
    "a histogram representation @xmath98 for the unfolded distribution @xmath47 with @xmath99 bins integrating over the @xmath4-intervals @xmath100,\\,i=1,\\ldots , m$ ] is obtained by @xmath101 where @xmath102 is an @xmath103 matrix with elements @xmath104    the unfolding method described above assumes that the matrix @xmath30 relating the weight vector @xmath70 to the measurements @xmath27 is known exactly .",
    "therefore , when @xmath30 is determined by means of a monte carlo simulation , the monte carlo sample should be significantly larger than the data sample .    in an extension of the method which is applicable also in cases where the monte carlo statistics is of the same order or less than the data statistics",
    "is obtained by using a modified matrix of errors @xmath35 which includes statistical errors for the elements of matrix @xmath30 @xcite , and the cross - validation statistics substituted by the goodness - of - fit statistics for the comparing unweighted @xmath66 and weighted @xmath63 histograms given in references @xcite .",
    "three types of numerical examples are discussed to illustrate the unfolding procedure .",
    "the first is the classic example of a double peak structure proposed by v.  blobel @xcite .",
    "the second is a strongly varying one - sided distribution , and the third one a two - dimensional case .",
    "the method described above is illustrated using the example proposed in reference @xcite .",
    "the true distribution , defined on the range @xmath105 $ ] is described by a sum of three breit - wigner functions @xmath106 from which the experimentally measured distribution is obtained by @xmath107 with an acceptance function @xmath3 @xmath108 and a response function describing a biased measurement with gaussian smearing @xmath109 the acceptance and resolution functions are shown in fig .  [",
    "fig : resaccept ] . also shown",
    "is an example for the measured distribution obtained by simulating a sample of @xmath110 events .",
    "a histogram with number of bins @xmath111 and approximately equal number of events in each bin was used .    [",
    "cols=\"^,^ \" , ]     the whole numerical experiment and unfolding was repeated ten times .",
    "the number of obtained final components varied between three and six .",
    "the obtained @xmath87-values show no clear deviation from an evenly distribution between zero and unity , indicating that the measured distributions are typically reasonably well described by the folded estimates of the true distribution  supporting the validity of the unfolding approach .      in this example",
    "the above method is applied to unfold a strongly varying one - sided pdf .",
    "the true distribution , defined in the range @xmath112 , is @xmath113 let us represent the true value @xmath4 as a function of two variables @xmath114 and @xmath115 , @xmath116 , with @xmath117 and @xmath118 , with the angular variable @xmath119 uniformly distributed in @xmath120 . the reconstructed value @xmath121 is obtained from @xmath122 and @xmath123 , defined as independent random variables with normal distributions @xmath124 and @xmath125 respectively .",
    "here we do not present an analytical formula for the resolution function @xmath5 , but notice that it is a generalisation of the rice distribution .",
    "an example for the measured distribution obtained by simulating a sample of @xmath126 events is presented in fig .",
    "[ fig : resaccept2 ] .     based on a sample of 10000 events generated for the true distribution .",
    "the true distribution @xmath2 is shown by the curve.,scaledwidth=80.0% ]    in general the choice of pdfms has should be adapted to the problem at hand , i.e. symmetric gaussian pdfms as used in the previous example are not directly suitable for this kind of unfolding problem .",
    "the gmm fit model can , however , be used after transforming the problem such that the true distribution becomes approximately gaussian in shape .",
    "the box - cox transformation @xcite @xmath127 is appropriate for this case . after transforming the unfolding result back to the original variables , the entire procedure is equivalent to using a pdfms of the form @xmath128 for the determination of the matrix @xmath30 a sample of 1000000 monte carlo events was simulated .",
    "the true distribution was taken to be uniform and the response of the pdfm was calculated by weighting the monte carlo events with weights proportional to the value of respective pdfms @xcite . in the first step an initial set of 400 pdfms was used with positions @xmath20 uniformly distributed over the interval @xmath129 $ ] .",
    "the transformation parameter @xmath130 was used , which leads to a transformed pdf @xmath131 with skewness close to 0 .",
    "as shown in fig.[fig : cross2 ] , the constant width parameter @xmath132 provides the minimum value for the cross - validation error @xmath133 . in the second step @xmath134",
    "is not constant but inversely proportional to the square root of the unfolded density obtained in the first step in order to have better smoothing in regions of low statistics .",
    "here one finds a preferred value of @xmath135 . in this case",
    "the cross - validation error does not improve . in the third step finally a best value for the garrote parameter @xmath136",
    "is found for @xmath137 .",
    "the minimun , however , is not very pronounced .",
    "these two parameters are used for the final calculation of the unfolded distribution .",
    "only three terms are retained for the estimate of the true distribution .",
    "( top ) and cross - validation errors for different values of @xmath86 ( @xmath138 ) ( bottom).,title=\"fig : \" ] +   ( top ) and cross - validation errors for different values of @xmath86 ( @xmath138 ) ( bottom).,title=\"fig : \" ]    figure [ fig : quality2 ] illustrates the quality of the fit . no structure in either of the control plots",
    "is observed .",
    "the @xmath87-value from the test for the comparison of the histogram of the measured distribution @xmath27 and the fitting histogram @xmath139 , fig .",
    "[ fig : quality2](a ) , is @xmath140 .",
    "the components of the unfolding results are shown together with the estimate @xmath47 in fig .",
    "[ fig : unfolded2 ] . also shown",
    "are the standard deviation bands @xmath141 compared to the true distribution @xmath2 .",
    "the binned presentation of the unfolded distribution shown in fig.[fig : unfoldedhist2 ] was done with @xmath142 bins .",
    "@xmath143{mesall_3.eps } & \\vspace * { -1.1 cm } \\hspace * { -0.6cm}\\includegraphics[width=5.3cm]{resp_3.eps } \\vspace * { 0.3cm}\\\\ \\includegraphics [ width=9cm]{res_3.eps } & \\vspace * { -1.1 cm } \\hspace * { -0.6cm}\\includegraphics[width=5.3cm]{qq_3.eps } \\end{array}$ ]    @xmath144{unfolded_boot_3.eps } & \\hspace*{-1.82cm}\\includegraphics[width=2.99in]{unfold_tr_boot_3.eps}\\\\ \\end{array}$ ]     for @xmath145 bins .",
    "the vertical error bars denote the standard deviations @xmath146 .",
    "the histogram shows the true bin contents @xmath147.,width=432 ]      the method presented in this paper is also directly applicable to multidimensional cases . here",
    "a two - dimensional example is given .",
    "the true distribution defined on the two - dimensional domain @xmath148\\times[10,40]$ ] and represented by a sum of three bivariate gaussian pdfs @xmath149 , with @xmath150 the expectation values , @xmath151 the standard deviations and @xmath152 the correlations coefficient .",
    "the actual density is given by @xmath153 the experimentally measured distribution is obtained by @xmath154 with a resolution function @xmath155    an example of a measured distribution is obtained by simulating a sample of @xmath126 events . in figure[fig : measured4 ] the true density and the measured distribution are shown . while the dominant component ( first gaussian ) is still clearly visible in the observed distribution , the weak component ( second gaussian ) is barely discernible .",
    "( left ) ) and histogram of the measured distribution @xmath27 based on a sample of 10000 events ( right).,title=\"fig:\",scaledwidth=50.0% ]   ( left ) ) and histogram of the measured distribution @xmath27 based on a sample of 10000 events ( right).,title=\"fig:\",scaledwidth=50.0% ]    to use the existing software , a one - dimensional histogram was created from the two - dimensional distribution by copying first the top row from left to right then the 2nd row from right to left and so on .",
    "adjacent bins of the one - dimensional histogram with a low number of events were merged to have at least 25 events per bin .",
    "the vector of the histogram contents @xmath156 finally used in the unfolding procedure has @xmath157 components . for the determination of the matrix @xmath30",
    "a sample of 1000000 monte carlo events was simulated .",
    "pdfms were defined as circular symmetric gaussian probability density functions with three parameters , the expectation values @xmath158 and the standard deviation @xmath21 . in the first step ,",
    "a set of 400 pdfms was used with positions @xmath159 uniformly distributed over the domain @xmath148\\times[10,40]$ ] .",
    "as shown in fig.[fig : cross4 ] , using 5-fold cross - validation , an optimal value @xmath160 is found .",
    "for the second step , with an adaptive width @xmath134 inversely proportional to the square root of the unfolded density obtained in the first step , the value @xmath161 minimises the cross - validation error @xmath133 . in the third step the optimal garrote parameter for @xmath161",
    "is found to be @xmath162 .",
    "these two parameters are used for the final calculation of the unfolded distribution .     in step 1 ( top ) and",
    "step 2 ( middle ) , and as a function of the garrote parameter @xmath86 for @xmath163 from the second step ( bottom).,title=\"fig:\",scaledwidth=90.0% ] +   in step 1 ( top ) and step 2 ( middle ) , and as a function of the garrote parameter @xmath86 for @xmath163 from the second step ( bottom).,title=\"fig:\",scaledwidth=90.0% ] +   in step 1 ( top ) and step 2 ( middle ) , and as a function of the garrote parameter @xmath86 for @xmath163 from the second step ( bottom).,title=\"fig:\",scaledwidth=90.0% ]    @xmath143{mesall_4.eps } & \\vspace * { -1.1 cm } \\hspace * { -0.6cm}\\includegraphics[width=5.3cm]{resp_4.eps } \\vspace * { 0.3cm}\\\\ \\includegraphics [ width=9cm]{res_4.eps } & \\vspace * { -1.1 cm } \\hspace * { -0.6cm}\\includegraphics[width=5.3cm]{qq_4.eps } \\end{array}$ ]    the quality of the unfolding result is illustrated by fig.[fig : quality4 ] .",
    "it shows the mixture of the folded gaussian pdfms , which approximates the measured distribution , together with the analysis of the residual and the quantile - quantile plot .",
    "no structure in either of the control plots is observed .",
    "the @xmath87-value for the comparison of the histogram of the measured distribution @xmath27 and the fitting histogram @xmath139 is @xmath164 .    the unfolded distribution @xmath165 is presented in fig .",
    "[ fig : unfolded4 ] together with the difference between the unfolded and the true distribution @xmath166 .",
    "one observes that the true distribution , including its weak component , is well reproduced by the unfolding result , with rather small deviations of the unfolded distribution from the true one .",
    "( left ) and the difference between unfolded and true distribution @xmath167 ( right).,title=\"fig:\",scaledwidth=50.0% ]   ( left ) and the difference between unfolded and true distribution @xmath167 ( right).,title=\"fig:\",scaledwidth=50.0% ]",
    "a new method for unfolding the true distribution from data obtained from detectors with finite resolution and limited acceptance is presented .",
    "the method ensures smoothness and positivity of the result by representing the true distribution as a weighted sum of smooth pdfs ( mixture densities model ) .",
    "the standard deviation of the pdfs acts as a regularisation parameter which determines the smoothness of the result .",
    "the amount of smoothing is adjusted to the local statistical precision of the data by scaling the width parameter inversely proportional to square root of the estimated density and the non - negative garrote method is used to eliminate insignificant terms in the solution .",
    "cross - validation is used to determine optimal values of the regularisation and garrote parameters .",
    "the method avoids discretisation of the true density entering the integral equation , thereby avoiding quantisation errors for the true distribution .",
    "the proposed procedure is directly applicable to multidimensional unfolding problems .",
    "numerical examples covering the problems of unfolding a simple double - peak structure , a strongly varying one - side distribution and a two - dimensional density were presented to illustrate and to validate the procedure",
    "the author would like to express very great appreciation to michael schmelling for constant interest to this work and many discussions stimulating the development of the method .",
    "the author is also grateful to markward britsch for useful discussions as well as for careful reading of the manuscript .",
    "special thanks are extended to the university of akureyri and the mpi for nuclear physics for support in carrying out the research .",
    "n.  gagunashvili , unfolding with system identification , in : proceedings of the conference on statistical problems in particle physics , astrophysics and cosmology , 1215 september , 2005 , oxford , imperial college press , london , 2006 , pp . 267210 .                  c.  l.  lawson and r.  j.  hanson , solving least squares problems , ch .",
    "23 , sec . 3 , prentice - hall , englewood cliffs , 1974 ; also available as classics in applied mathematics , vol .",
    "15 , siam , philadelphia , 1995 ."
  ],
  "abstract_text": [
    "<S> a procedure based on a mixture density model for correcting experimental data for distortions due to finite resolution and limited detector acceptance is presented . addressing the case that the solution is known to be non - negative , in the approach presented here </S>",
    "<S> , the true distribution is estimated by a weighted sum of probability density functions with positive weights and with the width of the densities acting as a regularisation parameter responsible for the smoothness of the result . to obtain better smoothing in less populated regions , </S>",
    "<S> the width parameter is chosen inversely proportional to the square root of the estimated density . </S>",
    "<S> furthermore , the non - negative garrote method is used to find the most economic representation of the solution . </S>",
    "<S> cross - validation is employed to determine the optimal values of the resolution and garrote parameters . </S>",
    "<S> the proposed approach is directly applicable to multidimensional problems . </S>",
    "<S> numerical examples in one and two dimensions are presented to illustrate the procedure .    </S>",
    "<S> deconvolution , mixture densities , adaptive algorithm , inverse problem , single sided strongly varying spectra , regularisation 02.30.zz , 07.05.kf , 07.05.fb </S>"
  ]
}