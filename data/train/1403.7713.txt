{
  "article_text": [
    "we consider the following problem .",
    "suppose that we observe a trajectory @xmath0 of the following diffusion process : @xmath1 where @xmath2 is a wiener process , @xmath3 is known smooth function , the initial value @xmath4 is deterministic and the trend coefficient @xmath5 is a unknown function .",
    "here @xmath6 is a given parameter .",
    "we have to test the composite ( parametric ) hypothesis @xmath7 against alternative @xmath8 . here",
    "@xmath9 is a known smooth function of @xmath10 and @xmath11 .",
    "the parameter @xmath12 is unknown and the set @xmath13 is open and bounded .",
    "let us fix some value @xmath14 and consider the class of tests of asymptotic ( @xmath15 ) size @xmath16 : @xmath17 the test @xmath18 is the probability to reject the hypothesis @xmath19 and @xmath20 stands for the mathematical expectation under hypothesis @xmath19 .",
    "our goal is to find goodness - of - fit ( gof ) tests which are _ asymptotically distribution free _ ( adf ) , that is , we look for a test statistics whose limit distributions under null hypothesis do not depend on the underlying model given by the functions @xmath9 , @xmath21 and the parameter  @xmath10 .",
    "this work is a continuation of the study kutoyants @xcite , where an adf test was proposed in the case of simple basic hypothesis .",
    "the behaviour of stochastic systems governed by such equations ( called _ perturbed dynamical systems _ ) is well studied , see , for example , freidlin and wentzell @xcite and the references therein . estimation theory ( parametric and non - parametric ) for such models of observations is also well developped , see , for example , kutoyants @xcite and yoshida @xcite .",
    "let us remind the well - known basic results in this problem for the i.i.d . model .",
    "we start with the simple hypothesis .",
    "suppose that we observe @xmath22 i.i.d .",
    "r.v.s @xmath23 with a continuous distribution function @xmath24 , and the basic hypothesis is @xmath25 then the cramr ",
    "von mises statistic is @xmath26 ^ 2\\ , \\mathrm{d}f_0 ( x ) , \\qquad \\hat f_n ( x ) = \\frac{1}{n}\\sum_{j=1}^{n}{\\mathbh{1 } } _ { \\ { x_j < x \\}},\\ ] ] where @xmath27 is the empirical distribution function .",
    "denote by @xmath28 the class of tests of asymptotic ( @xmath29 ) size @xmath30 , that is , @xmath31    we have the convergence ( under hypothesis @xmath19 ) @xmath32 where @xmath33 is a brownian bridge process .",
    "hence , it can be shown that @xmath34 and the _ cramr  von mises _",
    "test @xmath35 is _ asymptotically distribution - free _",
    "( adf ) .",
    "the situation changes in the case of parametric basic hypothesis : @xmath36 where @xmath37 .",
    "if we introduce the similar statistic @xmath38 ^ 2 \\ , \\mathrm{d}f ( \\hat\\vartheta_n , x ) , \\ ] ] where @xmath39 is the maximum likelihood estimator ( mle ) , then ( under regularity conditions ) we have @xmath40 for the mle , we can use its representation @xmath41 all this allows us to write the limit @xmath42 of the statistic @xmath43 as follows : @xmath44 where @xmath45 and we put @xmath46 .    if @xmath47 , then we obtain a similar equation @xmath48 where @xmath49 is the scalar product in @xmath50 .    this presentation of the limit process @xmath51 can be found in darling @xcite .",
    "of course , the test @xmath52 is not adf and the choice of the threshold @xmath53 can be a difficult problem . one way to avoid this problem is , for example , to find a transformation @xmath54 ( t ) = w ( t ) $ ] , where @xmath55 is the wiener process .",
    "this transformation allows to write the equality @xmath56 \\bigl(f ( \\vartheta , x ) \\bigr)^2\\,\\mathrm{d } f ( \\vartheta , x ) = \\int _ { 0}^{1}w ( t ) ^2\\,\\mathrm{d}t.\\ ] ] hence , if we prove the convergence @xmath57 ( x ) ^2\\,\\mathrm{d}f ( \\hat \\vartheta _ n , x ) \\longrightarrow\\delta,\\ ] ] then the test @xmath58 , with @xmath59 is adf .",
    "such transformation was proposed in khmaladze @xcite .    in the present work",
    ", we consider a similar problem for the model of observations ( [ 0 ] ) with parametric basic hypothesis ( [ 00 ] ) .",
    "note that several problems of gof testing for the model of observations ( [ 0 ] ) with simple basic hypothesis @xmath60 were studied in dachian and kutoyants @xcite , iacus and kutoyants @xcite , kutoyants @xcite .",
    "the tests considered there are mainly based on the normalized difference @xmath61 , where @xmath62 is a solution of equation ( [ 00 ] ) for @xmath63 .",
    "this statistic is in some sense similar to the normalized difference @xmath64 used in the gof problems for i.i.d .",
    "models . we propose two gof adf tests .",
    "note that the construction of the first test is in some sense close to the one considered in kutoyants @xcite and based on the score function process .",
    "these tests are originated by the different processes but after our first transformation of the normalized difference @xmath65 we obtain the same integrals to calculate as those in kutoyants @xcite .",
    "let us remind the related results in the case of simple hypothesis ( see kutoyants @xcite ) .",
    "suppose that the observed homogeneous diffusion process under null hypothesis is @xmath66 where @xmath67 is a known smooth function .",
    "denote @xmath68 .",
    "we have @xmath69 as @xmath15 and we construct a gof test based on statistic @xmath70 .",
    "the limit of this statistic is a gaussian process .",
    "this process can be transformed into the wiener process as follows : introduce the statistic @xmath71^{-2 } \\int_{0}^{t } \\biggl(\\frac{x_t - x_t}{\\varepsilon s_0 ( x_t ) ^{2 } } \\biggr)^2 \\sigma ( x_t ) ^2 \\,\\mathrm{d}t.\\ ] ] the following convergence : @xmath72 was proved and therefore the test @xmath73 with @xmath59 is adf .",
    "consider now the hypotheses testing problem ( [ 0 ] ) and ( [ 00 ] ) .",
    "the solution @xmath74 of equation ( [ 00 ] ) for @xmath63 depends on @xmath75 , that is , @xmath76 .",
    "the statistic @xmath77 ( here @xmath78 is the mle ) is in some sense similar to @xmath43 .",
    "denote by @xmath79 the limit of @xmath80 as @xmath15 and suppose that we know the transformation @xmath81   ( \\cdot ) $ ] of @xmath82 into the gaussian process @xmath83 with a vector - function @xmath84 satisfying @xmath85 here @xmath86 is the @xmath87 unit matrix .",
    "the next steps are two transformations of @xmath42 : one transformation into the brownian bridge @xmath88 ( s ) = b ( s ) $ ] and another one into the wiener process @xmath89",
    "( s ) = w ( s ) $ ] , respectively .",
    "this allows us to construct the adf gof tets as follows : let us introduce ( formally ) the statistics @xmath90 \\bigr ] ( t ) \\bigr)^2\\,\\mathrm{d}t,\\qquad \\delta _",
    "\\varepsilon = \\int _ { 0}^{t } \\bigl(l_w \\bigl[l_u [ \\hat v_\\varepsilon ] ( t ) \\bigr ] \\bigr)^2\\ , \\mathrm{d}t,\\ ] ] and suppose that we have proved the convergences @xmath91 then the tests @xmath92 belong to the class @xmath28 and are adf . our objective is to realize this program .    a similar result for ergodic diffusion processes is contained in kutoyants @xcite ( simple basic hypothesis ) and kleptsyna and kutoyants @xcite ( parametric basic hypothesis ) .",
    "we have the following stochastic differential equation : @xmath93 where @xmath12 , @xmath94 is an open bounded subset of @xmath95 and @xmath96 is a _ small parameter _ , that is , we study this equation in the asymptotics of _ small noise _ @xmath15 .",
    "introduce the lipschitz condition and that of linear growth :    @xmath97 . _ the functions @xmath9 and @xmath98 satisfy the relations",
    "_ @xmath99 recall that by these conditions the stochastic differential equation ( [ 2 ] ) has a unique strong solution ( liptser and shiryaev @xcite ) , and moreover this solution @xmath100 converges uniformly , with respect to @xmath101 , to the solution @xmath102 of the ordinary differential equation @xmath103 observe that @xmath76 ( for the proof see freidlin and wentzell @xcite , kutoyants @xcite ) .",
    "@xmath104 . _",
    "the diffusion coefficient @xmath105 is bounded away from zero _ @xmath106 conditions @xmath97 and @xmath107 provide the equivalence of the measures @xmath108 induced on the measurable space @xmath109 by the solutions of equation ( [ 2 ] ) ( liptser and shiryaev @xcite ) . here",
    "@xmath110 is the space of continuous functions on @xmath111 $ ] with uniform metrics and @xmath112 is the borelian @xmath113-algebra of its subsets .",
    "the likelihood ratio function is @xmath114 and the maximum likelihood estimator ( mle ) @xmath115 is defined by the equation @xmath116    the following regularity conditions ( smoothness and identifiability ) provides us necessary properties of the mle .",
    "below @xmath62 .",
    "@xmath117 . _",
    "the functions @xmath118 and @xmath21 have two continuous bounded derivatives w.r.t . @xmath11 and",
    "the function @xmath9 has two continuous bounded derivatives w.r.t .",
    "@xmath10_.    _ for any @xmath119 _",
    "@xmath120 _ and the information matrix ( @xmath87 ) @xmath121 is uniformly non - degenerate : _",
    "@xmath122    we denote by a prime the derivatives w.r.t . @xmath11 and @xmath101 , and by a dot those w.r.t .",
    "@xmath10 , that is , for a function @xmath123 we write @xmath124 of course , in the case of @xmath125 the derivative @xmath126 is a column vector .    if the conditions @xmath107 and @xmath117 hold , then the mle admits the representation @xmath127 here , @xmath76 . for the proof see ,",
    "kutoyants @xcite .",
    "note that @xmath128 ( solution of equation ( [ 2 ] ) ) under condition @xmath117 is continuously differentiable w.r.t .",
    "denote the derivatives @xmath129 the equations for @xmath130 and @xmath131 are @xmath132 \\,\\mathrm{d}w_t,\\qquad x_0^ { ( 1 ) } = 0\\ ] ] and @xmath133 respectively .",
    "hence @xmath131 , @xmath134 is a gaussian process and it can be written as @xmath135    denote @xmath136    we can write @xmath137 where @xmath138 introduce the random process @xmath139    [ l1 ] we have the equality @xmath140 where @xmath141 is a vector - valued function .    the solution of equation ( [ 4 ] ) can be written ( see ( [ x1 ] ) ) as @xmath142 for the vector @xmath143 , we can write @xmath144 the solution of this equation is @xmath145 introduce two stochastic processes @xmath146 and",
    "@xmath147 then we can write @xmath148    introduce the random process @xmath149 and denote @xmath150    then we can write @xmath151 and therefore @xmath152    note that @xmath153 is in some sense a _ universal limit _ which appears in the problems of goodness of fit testing for stochastic processes . for example",
    ", the same limit is obtained in the case of ergodic diffusion process and in the case of inhomogeneous poisson process ( kutoyants @xcite ) . the main difference with the i.i.d .",
    "case is due to the wiener process here , while in the i.i.d .",
    "case the brownian bridge @xmath154 , @xmath155 appears ( see ( [ iid ] ) ) .",
    "of course , we can immediately replace @xmath156 by a wiener process @xmath157 and this will increase the dimension of the vector @xmath158 . in the case of vector - valued parameter @xmath10 , this change is not essential and will slightly modify calculations of the test statistics for the first type test .",
    "at the same time if the parameter @xmath10 is one - dimensional , then we can easily construct the second - type goodness - of - fit test for stochastic processes and it remains unclear how to construct such tests in the i.i.d .",
    "the difference will be explained in section  [ sec3.2 ] .    in the construction of a gof test",
    ", we will use another condition .",
    "_ the functions @xmath160 , @xmath161 and @xmath162 have continuous bounded derivatives w.r.t .",
    "suppose that we observe a trajectory @xmath164 of the following diffusion process : @xmath165    we have to test the basic parametric hypothesis @xmath166 that is , that the observed process ( [ 5 ] ) has the stochastic differential @xmath167 with some @xmath12 . here",
    "@xmath118 and @xmath98 are known strictly positive smooth functions and @xmath168 is an open convex set .",
    "we have to test this hypothesis in the asymptotics of a _ small noise _ ( as @xmath15 ) .",
    "our goal is to construct such statistics @xmath169 ( \\cdot ) $ ] , @xmath170 ( \\cdot ) $ ] that ( under hypothesis @xmath171 ) @xmath172 ( t ) ^2\\,\\mathrm{d}t\\quad\\longrightarrow \\quad\\delta=\\int_{0}^{1}b ( s ) ^2\\ , \\mathrm{d}s , \\\\",
    "\\delta_\\varepsilon&=&\\int_{0}^{t}v_\\varepsilon \\bigl[x^\\varepsilon \\bigr ] ( t ) ^2\\,\\mathrm{d}t\\quad\\longrightarrow \\quad\\delta=\\int_{0}^{1}w ( s ) ^2\\ , \\mathrm{d}s,\\end{aligned}\\ ] ] where @xmath33 and @xmath173 are the brownian bridge and the wiener process , respectively",
    ". then we introduce the tests @xmath174 with the thresholds @xmath53 and @xmath175 satisfying the equations @xmath176 these tests will belong to the class @xmath177 and will be adf .",
    "we propose these tests in the sections  [ sec3.1 ] and  [ sec3.2 ] below .",
    "we call @xmath178 _ the first _ test and @xmath179 _ the second _ test .",
    "the construction of the first adf gof test is based on the following well known property .",
    "suppose that we have a gaussian process @xmath180 satisfying the equation @xmath181    introduce the process @xmath182 it is easy to see that @xmath183 and @xmath184=\\int_{0}^{t\\wedge s}h ( v ) ^2 \\,\\mathrm{d}v-\\int_{0}^{t}h ( v ) ^2 \\,\\mathrm{d}v\\int_{0}^ { s}h ( v ) ^2 \\,\\mathrm{d}v.\\ ] ]    let us put @xmath185 then @xmath186    suppose that the parameter @xmath10 is one - dimensional , @xmath187 and that we already proved the convergence ( see lemma  [ l1 ] ) @xmath188 where @xmath189 recall that @xmath190    introduce ( formally ) the statistic @xmath191 if we prove that @xmath192 then the test @xmath193 will be adf .    the main technical problem in carrying out this program is to define the stochastic integral @xmath194 containing the mle @xmath195 .",
    "we will proceed as follows : first , we formally differentiate and integrate and then we take the final expressions , which do not contain stochastic integrals , as starting statistics .    introduce the statistics @xmath196 , \\\\",
    "\\delta_\\varepsilon&=&\\int_{0}^{t}k_\\varepsilon ( \\hat\\vartheta _ \\varepsilon ,",
    "t)^2 h_\\varepsilon(\\hat \\vartheta_\\varepsilon , t ) ^2 \\,\\mathrm{d}t.\\end{aligned}\\ ] ] the first test is given in the following theorem .",
    "[ t1 ] suppose that the conditions @xmath97@xmath159 hold .",
    "then the test @xmath197 is adf and belongs to @xmath198",
    ".    we can write ( formally ) @xmath199 \\\\[-8pt ] & = & \\int_{0}^{t}\\frac{\\mathrm{d}x_s}{\\varepsilon\\sigma   ( s , x_s ) } - \\int _ { 0}^{t } \\biggl[\\frac{s(\\hat\\vartheta _ \\varepsilon , s , x_s(\\hat\\vartheta_\\varepsilon))}{\\varepsilon\\sigma   ( s , x_s ) } + \\frac{s'(\\hat\\vartheta_\\varepsilon , s , x_s ) ( x_s - x_s(\\hat\\vartheta_\\varepsilon ) ) } { \\varepsilon\\sigma   ( s , x_s ) } \\biggr ] \\,\\mathrm{d}s \\nonumber \\\\ & = & \\int_{0}^{t}\\frac{\\mathrm{d}x_s}{\\varepsilon\\sigma   ( s , x_s ) } - \\int _ { 0}^{t}\\frac{d(\\hat\\vartheta _ \\varepsilon , s , x_s)}{\\varepsilon\\sigma   ( s , x_s ) } \\,\\mathrm{d}s , \\nonumber\\end{aligned}\\ ] ] where we have used the equality @xmath200    hence ( formally ) , we obtain the following expression . @xmath201    the estimator @xmath202 and therefore the stochastic integral is not well defined because the integrand @xmath203 is not a non - anticipative random function . note that in the linear case @xmath204 we have no such problem ( see example below ) .",
    "this difficulty can be avoided in general case by at least two ways : the first one is to replace the stochastic integral by it s _ robust version _ as we show below .",
    "the second possibility is to use a consistent estimator @xmath205 of the parameter @xmath10 constructed after the observations @xmath206 , where @xmath207 but sufficiently slowly . with this estimator",
    ", we can calculate the integral @xmath208 without any problem , and all limits will be the same .",
    "such construction is discussed for a different problem in kutoyants and zhou @xcite .",
    "introduce the function @xmath209 then by the it formula @xmath210 and therefore @xmath211\\,\\mathrm{d}s \\\\ & & \\quad = \\int_{x_0}^{x_t}\\frac{\\dot s(\\vartheta , t , y ) } { \\sigma   ( t , y ) ^2 } \\ , \\mathrm{d}y-\\int_{0}^{t}\\int_{x_0}^{x_s } \\frac { \\dot s_s'(\\vartheta , s , y ) } { \\sigma   ( s , y ) ^2 } \\,\\mathrm{d}y \\\\ & & \\qquad { } + \\int_{0}^{t}\\int _ { x_0}^{x_s } \\frac{2\\dot s(\\vartheta , s , y)\\sigma_s '   ( s , y ) } { \\sigma   ( s , y ) ^3 } \\,\\mathrm{d}s- \\frac{\\varepsilon^2}{2}\\int_{0}^{t}{\\sigma ( s , x_s ) ^2 }    m_{xx } '' ( \\vartheta , s , x_s ) \\,\\mathrm{d}s.\\end{aligned}\\ ] ] note that the contribution of the term @xmath212 is asymptotically ( @xmath15 ) negligible .",
    "therefore , @xmath213\\ ] ] is asymptotically equivalent to @xmath214 the difference is in the dropped term of order @xmath215 .",
    "we have to verify the convergence of the integrals @xmath216    regularity conditions @xmath97@xmath117 give the uniform convergences @xmath217 introduce two processes @xmath218}{\\sigma ( s , x_s ) ^2 } \\,\\mathrm{d}s , \\\\",
    "z \\bigl(\\hat\\vartheta_\\varepsilon , t , x^t \\bigr)&=&{r \\bigl(\\hat \\vartheta _ \\varepsilon , t , x^t \\bigr)}- \\int_{0}^{t } \\frac{\\dot s ( \\hat \\vartheta _ \\varepsilon , s , x_s ) s ( \\vartheta , s , x_s ) } { \\sigma   ( s , x_s ) ^2 } \\,\\mathrm{d}s.\\end{aligned}\\ ] ] then @xmath219.\\ ] ] we have @xmath220 \\\\ & & \\quad = - ( \\hat\\vartheta_\\varepsilon-\\vartheta ) \\dot s ( \\tilde \\vartheta , s , x_s ) \\\\ & & \\qquad { } + \\bigl[s'(\\hat\\vartheta_\\varepsilon , s,\\tilde x_s)-s'(\\hat\\vartheta_\\varepsilon , s , x_s ) \\bigr ] \\bigl[x_s - x_s(\\hat\\vartheta_\\varepsilon ) \\bigr ] \\\\ & & \\quad = - ( \\hat\\vartheta_\\varepsilon-\\vartheta ) \\dot s ( \\tilde \\vartheta , s , x_s ) + \\mathrm{o } \\bigl(\\varepsilon^2 \\bigr).\\end{aligned}\\ ] ] therefore @xmath221 further , @xmath222 where @xmath223 we have uniform convergence of @xmath224 to @xmath74 w.r.t .",
    "hence , @xmath225 note that for any continuously differentiable function @xmath226 w.r.t .",
    "@xmath227 we have the relation @xmath228 since @xmath229 and @xmath230 hence , @xmath231 for all @xmath232 $ ] .    by the it formula , @xmath233 therefore",
    ", we obtain the convergence @xmath234 this convergence can be shown to be uniform w.r.t .",
    "this proves the convergence @xmath235 .",
    "therefore the theorem  [ t1 ] is proved .",
    "let us study the behaviour of the power function under the alternative .",
    "suppose that the observed diffusion process ( [ 0 ] ) has the trend coefficient @xmath5 which does not belong to the parametric family .",
    "this family we described as follows : @xmath236 here @xmath237 , @xmath238 is the solution of equation ( [ 3 ] ) .",
    "we introduce a slightly more strong condition of separability of the basic hypothesis and the alternative .",
    "suppose that the function @xmath5 satisfies conditions @xmath97 , @xmath104 and denote by @xmath239 , @xmath240 the solution of the ordinary differential equation obtained for @xmath241 @xmath242 then @xmath243 where @xmath244 is a solution of the equation @xmath245 and @xmath246 is defined by the relation @xmath247 suppose that this equation has a unique solution @xmath246 .",
    "note that @xmath248 is tight ( see kutoyants @xcite for details ) .",
    "moreover , we also suppose that the basic hypothesis and the alternative are separated in the following sense : @xmath249    first , formally , we write @xmath250}{\\sqrt{\\mathrm{i}(\\hat\\vartheta _ \\varepsilon ) } \\varepsilon\\sigma   ( s , x_s ) ^2 } \\,\\mathrm{d}s \\\\ & & \\quad = \\int_{0}^{t } \\frac{\\dot s(\\vartheta _ * , s , y_s)}{\\sqrt { \\mathrm{i}(\\vartheta _ * ) } \\sigma   ( s , y_s ) } \\ , \\mathrm{d}w_s-\\int_{0}^{t } \\frac { \\dot s(\\vartheta _ * , s , x_s )   [ s ( s , x_s ) - s(\\vartheta _ * , s , x_s ) ] } { \\sqrt{\\mathrm{i}(\\vartheta _ * ) } \\varepsilon\\sigma   ( s , x_s ) ^2}\\,\\mathrm{d}s.\\end{aligned}\\ ] ] further @xmath251 therefore , @xmath252}{\\sqrt{\\mathrm{i}(\\vartheta _ * ) } \\sigma   ( s , y_s ) ^2}\\,\\mathrm{d}s+ \\mathrm{o } \\bigl(\\varepsilon ^2 \\bigr ) \\\\ & = & i_1 ( t ) -i_2 ( t ) -\\varepsilon^{-1}i_3 ( t ) + \\mathrm{o } \\bigl(\\varepsilon ^2 \\bigr)\\end{aligned}\\ ] ] with an obvious notation .",
    "for the statistic @xmath253 we have the relations @xmath254 where @xmath255 and @xmath256 is the @xmath257 norm .",
    "recall that the quantities @xmath258 and @xmath259 are bounded in probability .",
    "introduce the condition    @xmath260 . _",
    "the functions @xmath261 and @xmath98 are such that _ @xmath262}{{\\mathrm{i}(\\vartheta _ * ) } \\sigma   ( s , y_s ) ^2}\\,\\mathrm{d}s \\biggr)^2\\frac{\\dot s ( \\vartheta _ * , t ) ^2}{\\sigma ( t , y_t ) ^2}\\,\\mathrm{d}t > 0 . \\ ] ]    this condition provides consistency of the test .",
    "[ t2 ] let conditions @xmath97@xmath260 hold .",
    "then the test @xmath263 is consistent .",
    "the proof follows from the convergence @xmath264 under alternative ( see ( [ i3 ] ) ) .",
    "note that if @xmath246 is an interior point of @xmath94 , then @xmath265 } { \\sigma   ( s , y_s ) ^2 } \\,\\mathrm{d}s=0.\\ ] ]    if condition @xmath260 does not hold , then @xmath266 } { \\sigma   ( s , y_s ) ^2 } \\,\\mathrm{d}s \\equiv0 , \\qquad\\mbox{for all } t\\in [ 0,t ] .\\ ] ] this equality is possible if @xmath267\\equiv0 , \\qquad\\mbox{for all } s\\in [ 0,t ] .\\ ] ]    an example of such _ invisible _ alternative can be constructed as follows : suppose that the function @xmath268 does not depend on @xmath10 for @xmath269 $ ] , that is , @xmath270 for all @xmath271 .",
    "then @xmath272 for @xmath273 $ ] .",
    "therefore if @xmath274 for @xmath275 $ ] and a corresponding @xmath246 then condition @xmath260 does not hold , but we can have @xmath276 for @xmath277 $ ] .",
    "this implies that the test @xmath278 is not consistent for this alternative .",
    "the second test is based on the following well - known transformation .",
    "suppose that we have a gaussian process @xmath279 , @xmath280 and @xmath87 matrix @xmath281 defined by the relations @xmath282 where @xmath86 is the @xmath87 unit matrix and @xmath283 is a continuous vector - valued function .",
    "[ l2 ] suppose that the matrix @xmath284 is non - degenerate for all @xmath285 .",
    "then @xmath286 where @xmath287 is a wiener process .",
    "this formula was obtained by khmaladze @xcite .",
    "the proof there is based on two results : a result of hitsuda @xcite and another one of shepp @xcite .",
    "observe that there are many publications dealing with this transformation ( see , e.g. , the paper maglaperidze _ et al .",
    "_ @xcite and the references therein ) .",
    "another direct proof is given in kleptsyna and kutoyants @xcite .",
    "note that representation ( [ 18 ] ) and ( [ 19 ] ) implies that @xmath288    suppose that @xmath289 . here",
    "@xmath94 is an open bounded subset of @xmath290 .",
    "now @xmath291 , @xmath292 and @xmath293 are @xmath294-vectors and the fisher information @xmath295 is a @xmath87 matrix .",
    "introduce the following stochastic processes : @xmath296 and put @xmath297 here @xmath298 \\\\[-8pt ] & & { } + \\varepsilon^{-1}\\int_{0}^{t}\\bar \\mathbf{h}_\\varepsilon(\\hat \\vartheta_\\varepsilon , s)^ * \\bar { \\mathbb{n}}_\\varepsilon ( \\hat\\vartheta_\\varepsilon , s ) _ + ^{-1 } \\bigl [ \\mathbf{r } \\bigl(\\hat\\vartheta_\\varepsilon , s , x^s \\bigr ) - \\mathbf{q } \\bigl(\\hat\\vartheta_\\varepsilon , s , x^s \\bigr ) \\bigr ] \\ , \\mathrm{d}s .",
    "\\nonumber\\end{aligned}\\ ] ] we use the following convention for the matrix @xmath299 : @xmath300 we have the following result .    [ t3 ] suppose that conditions @xmath104@xmath159 hold and the matrix @xmath301 is uniformly in @xmath12 non - degenerate for all @xmath285 .",
    "then the test @xmath302 is adf and belongs to @xmath28 .",
    "we have to show that under hypothesis @xmath303 the convergence @xmath304 holds .",
    "the construction of the adf gof test is based on lemmas  [ l1 ] and  [ l2 ] .",
    "we have the similar to ( [ 8 ] ) presentation ( [ 18 ] ) with @xmath305 defined in ( [ h ] ) .",
    "let us denote @xmath306 , and @xmath307 the _ empirical versions _ of @xmath308 and @xmath309 respectively : @xmath310 recall that there is a problem of definition of the integral for @xmath311 because the integrand depends on the future .",
    "as convergence is uniform w.r.t .",
    "@xmath312 $ ] : @xmath313 the required limits can be obtained .",
    "introduce ( formally ) the statistic @xmath314    observe that @xmath315 therefore this term does not depend on the information matrix @xmath316 and we can replace the statistics @xmath317 and @xmath318 in ( [ w ] ) by @xmath319 and @xmath320 .    for the process",
    "@xmath311 , we have equality ( [ u ] ) ( formally ) @xmath321    hence , we obtain the vector - valued integral @xmath322 introduce the vector - function @xmath323 then by the it formula @xmath324 put @xmath325.\\ ] ] note that we have dropped the term of order @xmath326",
    ".    then formal expression ( [ w ] ) for @xmath327 can be replaced by ( [ we ] ) @xmath328 \\,\\mathrm{d}s.\\end{aligned}\\ ] ] for the first two terms of @xmath329 we have @xmath330(x_s - x_s(\\hat\\vartheta _ \\varepsilon))}{\\varepsilon\\sigma ( s , x_s ) } \\ , \\mathrm{d}s \\\\ & = & w_t- \\biggl\\langle\\mathrm{i } ( \\vartheta ) ^{-1}\\int _ { 0}^{t}\\frac{\\dot\\mathbf{s } ( \\vartheta , s , x_s ) } { \\sigma   ( s , x_s ) } \\,\\mathrm{d}w_s , \\int_{0}^{t}\\frac{\\dot\\mathbf{s } ( \\vartheta , s , x_s ) } { \\sigma   ( s , x_s ) } \\,\\mathrm{d}s \\biggr\\rangle+\\mathrm{o } ( 1 ) \\\\ & = & u ( \\vartheta , t ) + \\mathrm{o } ( 1 ) .\\end{aligned}\\ ] ] here @xmath331 and @xmath332 & \\leq & \\bigl{\\vert}x_s(\\hat\\vartheta_\\varepsilon)-x_s ( \\vartheta ) \\bigr{\\vert}+\\bigl{\\vert}x_s ( \\vartheta ) -x_s \\bigr{\\vert}\\rightarrow0.\\end{aligned}\\ ] ] this convergence is uniform w.r.t .",
    "@xmath333 $ ] .",
    "hence , @xmath334 further , similar arguments give the uniform convergence w.r.t .",
    "@xmath232 $ ] @xmath335 we have to show that @xmath336 , where @xmath337 denote @xmath338}{\\sigma ( s , x_s ) ^2 } \\ , \\mathrm{d}s , \\\\ \\mathbf{z } \\bigl(\\hat\\vartheta_\\varepsilon , t , x^t \\bigr)&= & { \\mathbf{r } \\bigl(\\hat\\vartheta _ \\varepsilon , t , x^t \\bigr)}- \\int _ { 0}^{t}\\frac{\\dot\\mathbf{s } ( \\hat\\vartheta _ \\varepsilon , s , x_s ) s ( \\vartheta , s , x_s ) } { \\sigma   ( s , x_s ) ^2 } \\,\\mathrm{d}s.\\end{aligned}\\ ] ] then @xmath339.\\ ] ] we have @xmath340 \\\\ & & \\quad   = - \\bigl\\langle ( \\hat\\vartheta_\\varepsilon-\\vartheta ) , \\dot \\mathbf{s } ( \\tilde\\vartheta , s , x_s ) \\bigr\\rangle \\\\ & & \\qquad { } + \\bigl[s'(\\hat\\vartheta_\\varepsilon , s,\\tilde x_s)-s'(\\hat\\vartheta_\\varepsilon , s , x_s ) \\bigr ] \\bigl[x_s - x_s(\\hat\\vartheta_\\varepsilon ) \\bigr ] \\\\ & & \\quad   = - \\bigl\\langle ( \\hat\\vartheta_\\varepsilon-\\vartheta ) , \\dot \\mathbf{s } ( \\tilde\\vartheta , s , x_s ) \\bigr\\rangle+\\mathrm{o } \\bigl ( \\varepsilon^2 \\bigr).\\end{aligned}\\ ] ] therefore @xmath341    further , @xmath342 where @xmath343 here @xmath344 is the matrix of second derivatives w.r.t .",
    "we have uniform convergence of @xmath224 to @xmath74 w.r.t .",
    "@xmath101 , hence @xmath345 observe that for any continuously differentiable function @xmath226 w.r.t .",
    "@xmath227 we have @xmath228 since @xmath229 and @xmath346 hence , @xmath347 for all @xmath232 $ ] .    by the it formula @xmath348 therefore , we obtain the convergence @xmath349 further , the matrix @xmath350 converges uniformly in @xmath333 $ ] to the matrix @xmath351 .",
    "therefore , for @xmath119 we have uniform on @xmath352 $ ] convergence of @xmath353 to @xmath354 .",
    "introduce the random function @xmath355.\\ ] ] it is shown that we have convergence @xmath356 where @xmath357    hence we also have convergence for all @xmath285 @xmath358 a similar argument can show that for any @xmath359 we have convergence of the vectors @xmath360 further , a direct but cumbersome calculation allows us to write the estimate @xmath361.\\ ] ] these two conditions provide weak convergence of the integrals @xmath362 for any @xmath119 .",
    "it can be shown that for any @xmath363 there exist @xmath119 such that @xmath364 the proof is close to that given in maglaperidze _",
    "@xcite for a similar integral .",
    "[ exa1 ] we consider the simplest case which allows us to have an adf gof test for each  @xmath96 , that is , no need to study statistics as @xmath365 .",
    "observe that a similar situation is discussed in khmaladze @xcite but for a different problem .",
    "suppose that the observed diffusion process ( under hypothesis ) is @xmath366 then @xmath367 further @xmath368 therefore , @xmath369 \\,\\mathrm{d}s\\ ] ] and under the basic hypothesis we have @xmath370 therefore , @xmath371 and the test @xmath372 satisfies the equality @xmath373    [ exa2 ] consider the linear case @xmath374 where @xmath375 and assume that the functions @xmath376 and @xmath98 satisfy regularity conditions . in this case , we can take @xmath377 , that is , this vector - valued function does not depend on @xmath10 .",
    "hence , the stochastic integral is well defined and the test has a simplified form .",
    "we have @xmath378\\,\\mathrm{d}t } { \\varepsilon\\sigma ( t , x_t ) } , \\\\",
    "w_\\varepsilon ( t ) & = & u_\\varepsilon ( t ) + \\int_{0}^{t } \\mathbf{h } ( s , x_s ) ^ * \\bar{{\\mathbb{n}}}_\\varepsilon ( \\hat \\vartheta_\\varepsilon , s ) ^{-1}\\int_{0}^{s } \\mathbf{h } ( v , x_v ) \\,\\mathrm{d}u_\\varepsilon ( v ) \\,\\mathrm{d}s\\end{aligned}\\ ] ] and so on .",
    "this study was partially supported by russian science foundation ( research project no .",
    "14 - 49 - 00079 ) .",
    "the author thanks the referee for helpful comments ."
  ],
  "abstract_text": [
    "<S> we consider the problem of construction of goodness - of - fit tests for diffusion processes with a _ </S>",
    "<S> small noise_. the basic hypothesis is composite parametric and our goal is to obtain asymptotically distribution - free tests . we propose two solutions . </S>",
    "<S> the first one is based on a change of time , and the second test is obtained using a linear transformation of the `` natural '' statistics .    </S>",
    "<S> ./style / arxiv - general.cfg </S>"
  ]
}