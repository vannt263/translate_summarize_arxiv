{
  "article_text": [
    "the last decades have been characterized by a progressive increase of data production and storage .",
    "indeed , the informatization of most aspects of human activities , ranging from simple tasks such as phone calls to shopping habits generates an ever increasing collection of data that can be organized and used for planning . at the same time",
    ", most scientific projects  such as in genetics , astronomy and neuroscience  generate large amounts of data that needs to be analyzed and understood .",
    "this trend has given rise to the new term _",
    "big data _  @xcite .",
    "once such data is organized in a dataset , it is necessary to find patterns concealed in the vast mass of values , which is the objective of _ data mining _  @xcite . because the identification of important patterns ( e.g. those that recur frequently or are rare ) is impossible to be performed manually",
    ", it is necessary to resort to automated pattern recognition .",
    "nevertheless , it is important to note that pattern recognition remains also critical for organizing and understanding smaller sets of data , such as in medical diagnosis , industrial quality control , and expensive data .    the problem of pattern recognition consists in assigning classes or categories to observations or individuals  @xcite .",
    "this can be done in two main ways : ( i ) with the help of examples or prototypes ( _ supervised classification _ ) ; and ( ii ) taking into account only the properties of the objects ( _ unsupervised classification _ or _ clustering _ ) .",
    "though seemingly simple , pattern recognition often turns out to be a challenging activity .",
    "this is mainly a consequence of _ overlap _ between the features of different groups in the data , i.e.  objects in a class have similar properties as those of other classes .",
    "however , several other issues such as choice of features , noise , sampling , also impose further problems while classifying data  @xcite .",
    "even when the features are well - chosen and the data has good quality ( properly sampled and without noise ) , the results of the classification will frequently vary with the choice of different pattern recognition methods .",
    "this situation is typically aggravated for sparse data , presence of noise , or non - discriminative features . in an attempt to circumvent such problem and to obtain more robust and versatile classifiers ,",
    "a number of pattern recognition methods have been proposed in the literature  @xcite . despite the long tradition of pattern recognition research  @xcite",
    ", there are no definite guidelines for choosing classifiers .",
    "so , those faced with the need to apply pattern recognition are left with the rather difficult task of choosing among several alternative methods .",
    "there are many works in the literature describing which classifiers are more suitable for specific tasks ( see e.g.  @xcite and section related works ) , but only a few of them consider a systematic quantitative analysis of their performance .",
    "therefore , in this paper , we assess the performance of the classifiers in carefully chosen datasets , without trying to advocate for any specific method .",
    "this means that the dataset used in the study is of fundamental importance to the correct interpretation of the results .",
    "typical datasets employed to compare the performance of different methods include real world and/or artificial data .",
    "advantages of using real datasets include the presence of non - trivial relationships between variables , which may strongly influence the performance of a classifier , the fact that the obtained results will usually be of high confidence when used for samples obtained in the same domain and using a similar criteria , and the presence of noise or unreachable information about the samples ( hidden variables ) .",
    "but there is a main drawback associated with using real - world data .",
    "even if one manage to consistently compare the results obtained with hundreds of real world datasets , the results will still be specific to the datasets being used .",
    "trying to use the information gained in such analyses to a different dataset will most likely be ineffective .",
    "furthermore , obtaining more real data to evaluate other classifier characteristics represents sometimes an arduous task .",
    "this is the case of applications whose acquisition process is expensive .",
    "for this reason , here we chose synthetic datasets .",
    "although such datasets are often not representative of specific real - world systems , they can still be used as representations of large classes of data .",
    "for example , we can define that all variables in the dataset will have a pearson correlation of 0.8 , and study the behavior of the classifiers when setting this as the main data constrain .",
    "a natural choice of distribution for the variables in the dataset is the multivariate normal distribution .",
    "this choice is supported by the well - known central limit theorem @xcite , which states that , under certain conditions , the mean of a large number of independent random variables will converge to a normal distribution .",
    "this ubiquitous theorem can be used to conclude that , between all infinite possibilities of probability density distributions , the normal distribution is the most likely to represent the data at hand .",
    "a second possible choice of data distribution may be the power - law distribution .",
    "this is so because there is a version of the central limit theorem stating that the sum of independent random variable with heavy - tailed distributions is generally power - law distributed @xcite .",
    "nevertheless , here we use only normal distribution , leaving power - law distributed variables for a future study .",
    "since one of our main concerns is making an accessible practical study of the classifiers , we decided to only analyze classifiers available in the weka software  @xcite , which was chosen because of its popularity among researchers .",
    "in addition , since the software is open - source , any researcher can look at the code of any specific classifier and confirm the specific procedure being used for the classification . since weka has many classifiers available",
    ", we decided to select a subset of the most commonly used ones according to  @xcite .",
    "one distinctive feature of the present work is the procedure we use to compare classifiers .",
    "many works in the literature try to find the best accuracy that a classifier can give and then present this value as the quality of the classifier .",
    "the truth is that finding the highest accuracy for a classifier is usually a troublesome task .",
    "additionally , if this high accuracy can only be achieved for very specific values of the classifier parameters , it is likely that for a different dataset the result will be worse , since the parameter was tuned for the specific data analyzed .",
    "therefore , besides giving a high accuracy , it is desirable that the classifier can give such values for accuracy without being too _ sensitive _ regarding changes of parameters .",
    "that is , a good classifier must provide a good classification for a large range of values of its parameters .    in order to study all aforementioned aspects of the classifiers ,",
    "this work is divided in three main parts .",
    "first , we compare the performance of the classifiers when using the default parameters set by weka .",
    "this is probably the most common way researchers use the software .",
    "this happens because changing the classifier parameters in order to find the best classification value is a cumbersome task , and many researchers do not want to bother with that .",
    "our second analysis concerns the variation of single parameters of the classifiers , while maintaining other parameters in the default value .",
    "that is , we study how the classification results are affected when changing each parameter .",
    "therefore , we look for the parameters that actually matters for the results , and how one can improve their results when dealing with such parameters . finally , in order to estimate the optimum accuracy of the classifier , as well as verify its sensitivity to simultaneous changes of its parameters , we randomly sample sets of parameter values to be used in the classifier .",
    "the paper is organized as follows .",
    "firstly , we swiftly review some previous works aiming at comparing classifiers .",
    "we then describe the generation of synthetic datasets and justify the parameters employed in the algorithm .",
    "next , we introduce the measurements used to quantify the classifiers performance .",
    "we then present a quantitative comparison of classifiers , followed by the conclusions .",
    "typical works in the literature dealing with comparison between classifiers can be organized into two main groups : ( a ) comparing among few methods for the purpose of validation and justification of a new approach  @xcite ; and ( b ) systematic qualitative and quantitative comparison between many representative classifiers .",
    "examples of qualitative analysis in ( b ) can be for example found in  @xcite .",
    "these studies perform a comprehensive analysis of several classifiers , describing the drawbacks and advantages of each method , without considering any quantitative tests .",
    "a quantitative analysis of classifiers was performed in  @xcite , where 491 papers comparing quantitatively at least two classification algorithms were analyzed .",
    "a comparison of three representative learning methods ( naive bayes , decision trees and svm ) was conducted in  @xcite , concluding that naive bayes is significantly better than decision trees if the area under curve is employed as a performance measurement .",
    "other quantitative studies include the comparison of neural networks with other methods  @xcite and an extensive comparison of a large set of classifiers over many different datasets  @xcite , which showed that svms performances very well on classification tasks .",
    "finally , quantitative comparisons between classifiers can be also found in specific domain problems , such as in bioinformatics  @xcite , computer science  @xcite , medicine  @xcite and chemistry  @xcite .",
    "in this section we present a generic methodology to construct artificial datasets modeling the different characteristics of real datasets . in addition , we describe the measurements used to evaluate the quality of the classifiers .",
    "as noted above , there is a considerable number of reviews in the literature that use real data in order to compare the performance of classifiers .",
    "although this approach is useful when one wants to test the performance for specific classes of data , the small domain of possible cases analyzed renders the results insignificant for a true performance test .",
    "also , with real data it is impossible to systematically study how the classification is being influenced by different variances and correlations between the data , the dimension of the problem , number of classes , distribution of elements per class and , most importantly , the separation between the classes . in order to approach these problems , while having a diversified dataset to test the general purpose classifiers , we use a multivariate gaussian artificial data generation where many of the parameters chosen are justified by real data , but we can still test variations of them .",
    "data distributions may occur in many different forms .",
    "we chose a gaussian distribution because it has the potential to represent a large ensemble of possible data occurrences on the real world .",
    "this observation is supported by the central limit theorem , since it is assumed that the variables are independent and identically distributed @xcite .    here",
    "we present a novel method for generating random datasets with a given ensemble of covariances matrices , which was strongly based on the study made by hirschberger et al .",
    "we aim at generating @xmath0 classes of data with @xmath1 features for each object , with the additional constraint that the number of objects per class is given by the vector @xmath2 .",
    "this problem is mathematically restated as finding @xmath0 sets comprising @xmath1-dimensional vectors , where each set has a number of elements specified by @xmath3 .",
    "@xmath0 , @xmath1 and @xmath3 are referred to as _ strong _",
    "parameters , in the sense that they do not bring any information about the relationships between the objects ( or vectors ) .",
    "furthermore , we aimed at generating data complying with the three following constraints :    * * constraint 1 * : the variance of the @xmath4-th feature of each class is drawn from a fixed distribution , @xmath5 . * * constraint 2 * : the correlation between the @xmath4-th and @xmath6-th dimension of each class are drawn from another fixed distribution , @xmath7 . * * constraint 3 * : we can freely tune the expected separation between the classes , given by parameter @xmath8 , which is explained below .",
    "traditionally , constraints 1 and 2 are not fully satisfied to generate the data .",
    "many studies impose that all the classes display approximately the same variances and correlations , by defining an ensemble of covariance matrices with a fixed spectrum constraint @xcite . unfortunately , this approach is somewhat artificial to generate realistic data , since the assumption that all data classes share similar relationships between their features is quite unlikely .",
    "our approach is more general because , given the shape of the correlation distribution ( e.g. u - shaped ) , the classes can exhibit all kinds of correlations .    in order to generate the data with the strong parameters",
    "@xmath0 , @xmath1 and @xmath3 complying with constraints 1 , 2 and 3 , we need @xmath0 covariance matrices ( one for each class ) , where each diagonal and off - diagonal element is drawn , respectively , from @xmath5 and @xmath7 .",
    "the most common approach is to randomly draw the mentioned matrix elements from probability density distributions given by @xmath5 and @xmath7 in order to construct the desired matrices .",
    "unfortunately , this process does not guarantee a valid covariance matrix because every covariance matrix must be positive and semi - definite @xcite . to overcome this problem we use a well - known property stating that for every matrix @xmath9 , the @xmath10",
    "matrix @xmath11 is positive and semi - definite @xcite .",
    "this property allow us to create a random matrix @xmath12 that will generate a valid covariance matrix .",
    "the matrix @xmath12 is known as _ root _ matrix . what is left to us",
    "is to define a convenient root matrix so that @xmath11 follows constraints 1 , 2 and 3 .",
    "hirschberger et al .",
    "@xcite came up with an elegant demonstration on how to create a covariance matrix following constraints 1 and 2 .",
    "actually , by using their methodology it is even possible to set the skewness of @xmath13 , but this property will not be employed here , since our goal is to generate off - diagonal elements distributed according to a normal distribution . using our algorithm , it is possible to create datasets having the following parameters :    * * number of objects per class @xmath3 * : the number of instances in each class can be drawn according to a given distribution .",
    "the most common distributions to use are the normal , power - law and exponential distributions . nevertheless , in order to simplify our analysis , here we use classes having an equal number of instances . * * number of classes @xmath0 * : we use @xmath14 .",
    "this parameter is not varied throughout the study because we found that the results did not appreciably change for different number of classes ( including the binary case @xmath15 ) . *",
    "* number of features @xmath1 * : the case @xmath16 represents the most simple case , since it permits the easy visualization of the data . in order to improve the discriminability of the data ,",
    "real world datasets oftentimes are described by a larger number of features .",
    "here we vary @xmath1 in the range @xmath17 $ ] .",
    "hereafter , we refer to the dataset described by @xmath1 features as db@xmath1f . * * standard deviation of the features * : for each class , the standard deviation of each feature is drawn according to a given distribution @xmath5 .",
    "the process is repeated for each class , using the same distribution @xmath5 . * * correlation between features * : for each class , the correlations between the features are drawn according to a given distribution @xmath7 .",
    "the process is repeated for each class using the same distribution .",
    "this means that each class of our dataset will show different kinds of correlation .",
    "for example , instances from one class may be described by redundant features , while the same features may be much more efficient in describing samples form other classes .",
    "the most common choices for @xmath7 are : ( a ) _ uniform _ , to represent heterogeneous data ; ( b ) gaussian centered in zero , for mostly uncorrelated ; and ( c ) _ u - shaped _ , for data with strong correlations .",
    "here we chose a uniform distribution for the correlations . * * separation between the data ( @xmath8 ) * : it is a parameter to be varied throughout the experiments , quantifying how well - separated are the classes , compared to their standard deviation .",
    "this parameter is simply a scaling of the variance of the features for each class . since we randomly draw the mean , @xmath18 , for each class in the range @xmath19 , @xmath20 can be used to define an expected separation between the classes .",
    "if @xmath8 is large , the classes are well - localized and will present little overlap .",
    "otherwise , if @xmath8 is small , the opposite is true .",
    "clearly , the separation given by @xmath8 depends on the dimension of the space .",
    "nevertheless , there is no need to define a normalization for @xmath8 , because we are just comparing classifiers and not different configurations of the data .    throughout the paper we varied the number of features @xmath1 and the separation between classes ( @xmath8 ) . in figure",
    "[ f : random_data ] we show some examples of the data that can be generated by varying @xmath8 in a two - dimensional dataset .          a fundamental aspect that should be consider when comparing the performance of classifiers is the proper definition of what _ quality _ means .",
    "it is impossible to define a single metric that will provide a fair comparison in all possible situations .",
    "this means that quality is usually specific to the application and , consequently , many measurements have been proposed  @xcite",
    ". nevertheless , there are some measurements that have widespread use in the literature , the most popular being the accuracy rate , f - measure ( sometimes together with precision and recall ) , kappa statistic , roc area under curve and the time spent for classification ( see  @xcite for a comprehensive explanation of such measurements ) . because we are mostly interested in a more practical analysis of the classifiers , we use only the accuracy rate , which is defined as the number of true positives plus the number of true negatives , divided by the total number of instances .    in the literature , oftentimes the average accuracy rate is employed to evaluate the performance of classifiers .",
    "this practice is so ubiquitous because many researchers decide to use a number of different kinds of measurements , like the ones previously mentioned , and the specific analysis of each metric turns out to be overly cumbersome .",
    "the consequence of such approach is that only the average , and at most the deviation of each metric end up being analyzed . in the present study we only used the accuracy rate . to measure the performance of the classifiers ,",
    "we generate artificial datasets using the method presented in the previous section and calculate some statistics .",
    "the principal quantity extracted from each dataset is the average accuracy rate .",
    "in addition , we also compute the variation of accuracy across datasets for this quantity is useful to quantify the confidence of the classifier when the dataset is changed . as such ,",
    "if high values of both average and standard deviation appears then it is possible to state that the classifier performs well , but care must be taken when analyzing a new dataset .",
    "the standard deviation of accuracy rate computed over instantiations of the classifier with distinct parameters is useful to quantify the sensitivity with respect to a given parameter .",
    "the performance of the classifiers was evaluated according to three methodologies .",
    "the default values provided by weka were used in the first strategy .",
    "we then examined the influence of each parameter on the discriminability of the data .",
    "finally , we developed a multivariate strategy .",
    "the classifiers considered in the analysis are presented in table [ t : classifier_names ] . throughout the results we used db2f ,",
    "db3f @xmath21 db10f to refer to the datasets comprising instances characterized by 2 , 3 @xmath21 10 features , respectively .    .[t",
    ": classifier_names]list of classifiers evaluated in our study .",
    "the abbreviated names used for some classifiers are indicated after the respective name . [ cols=\"<,<,<\",options=\"header \" , ]      +   +",
    "machine learning methods have been applied to recognize patterns and classify instances in a wide variety of applications . currently , several researchers / practioners with different expertise have employed computational tools such as weka to study particular problems . since the appropriate choice of parameters requires a certain knowledge of the underlying mechanisms behind the algorithms , oftentimes these methods are applied with their default configuration of parameters . using the weka software",
    ", we evaluated the performance of classifiers using distinct configurations of parameters in order to verify whether it is feasible to improve their performance .",
    "a summary of the main results obtained in this study is provided in table  [ t : tabela_resumo ] .",
    "@llll & * case * & db2@xmath1 & db10@xmath1 + & & naive bayes & knn + & & logistic & perceptron + & & knn & c4.5 + & & svm & bayes net + & & svm & svm + & & knn & knn + & & simple cart & simplecart + & & c4.5 & perceptron +     +   +    the analysis of parameters in two - dimensional problems revealed that the naive bayes displays the best performance among all nine classifiers evaluated with default parameters . in this scenario ,",
    "the svm turned out to be the classifier with the poorest performance .",
    "when instances are described by a set of ten features , the knn outperformed by a large margin the other classifiers , while the svm retained its ordinary performance . when just one parameter is allowed to vary ,",
    "there is not a large variation in the accuracy compared with the classification achieved with default parameters .",
    "the only exceptions are the parameter k of the knn and parameter s of svm ( with puk kernel ) . in these cases ,",
    "the appropriate choice of the parameters enabled an average increase of 6% in accuracy .",
    "surprisingly , we found that when the same analysis is performed with a ten - dimensional dataset , the improvement in performance surpasses 20% for the svm .",
    "finally , we developed a strategy in which all the configuration of parameters are chosen at random . despite its outward simplicity , this strategy is useful to optimize svm performance especially in high - dimensional problems , since the average increase provided by this strategy is higher than 20  % .",
    "another important result arising from the experiments is the strong influence of the number of features on the performance of the classifiers .",
    "while small differences in performance across distinct classifiers were found in low - dimensional datasets , we found significative differences in performance when we analyzed problems involving several features . in high - dimensional tasks , knn and svm turned out to be the most accurate techniques when default and alternative parameters were considered , respectively .",
    "most importantly , we found that the behavior of the performance with the number of features follows three distinct patterns : ( i ) almost constant ( perceptron ) ; ( ii ) monotonic increase ( knn ) , and ( iii ) monotonic decrease ( bayes net ) .",
    "these results suggest that number of features of the problem plays a key role on the choice of algorithms and , therefore , it should be considered in practical applications .",
    "the results obtained here suggest that for low dimension classification tasks , weka s default parameters provide accuracy rates close to the optimal value , with a few exceptions .",
    "the highest discrepancies arose in high - dimensional problems for the svm , indicating that the use of default parameters in these conditions is not recommended in cases where the svm must be employed .",
    "one could pursue this line of analysis further to probe the properties of classifiers with regard to other factors such as number of classes , number of instance per class and overlapping between classes .",
    "it is also very important to probe the performance in problems where the amount of instances employed to train is scarce , as it happens in occasions when data acquisition represents an expensive , painstaking endeavor .",
    "the authors acknowledge financial support from cnpq ( brazil ) ( grant numbers 573583/2008 - 0 , 208449/2010 - 0 , 308118/2010 - 3 and 305940/2010 - 4 ) , fapesp ( grant numbers 2010/00927 - 9 , 2010/19440 - 2 , 2011/22639 - 8 , 2011/50761 - 2 , 2013/06717 - 4 and 2013/14984 - 2 ) and nap escience - prp - usp .",
    "10          marquand af , filippone m , ashburner j , girolami m , mourao - miranda j , et al .",
    "( 2013 ) automated , high accuracy classification of parkinsonian disorders : a pattern recognition approach .",
    "plos one 8(7 ) : e69237 .",
    "montavon g , rupp m , gobre v , vazquez - mayagoitia a , hansen k , tkatchenko a , mller k - r , lilienfeld oa ( 2013 ) machine learning of molecular electronic properties in chemical compound space .",
    "new journal of physics 15 095003 .",
    "yang j , frangi af , yang jy , zhang d , jin z ( 2005 ) kpca plus lda : a complete kernel fisher discriminant framework for feature extraction and recognition .",
    "ieee transactions pattern analysis and machine intelligence 27:230244 .",
    "tavares lg , lopes hs , lima cre ( 2008 ) a comparative study of machine learning methods for detecting promoters in bacterial dna sequences .",
    "international conference on intelligent computing 5227:959966 .",
    "hirschberger m , qi y , steuer re ( 2007 ) randomly generating portfolio - selection covariance matrices with specified distributional characteristics .",
    "european journal of operational research 177:16101625 ."
  ],
  "abstract_text": [
    "<S> pattern recognition techniques have been employed in a myriad of industrial , medical , commercial and academic applications . to tackle such a diversity of data , </S>",
    "<S> many techniques have been devised . however , despite the long tradition of pattern recognition research , there is no technique that yields the best classification in all scenarios . </S>",
    "<S> therefore , the consideration of as many as possible techniques presents itself as an fundamental practice in applications aiming at high accuracy . </S>",
    "<S> typical works comparing methods either emphasize the performance of a given algorithm in validation tests or systematically compare various algorithms , assuming that the practical use of these methods is done by experts . in many occasions , however , researchers have to deal with their practical classification tasks without an in - depth knowledge about the underlying mechanisms behind parameters . </S>",
    "<S> actually , the adequate choice of classifiers and parameters alike in such practical circumstances constitutes a long - standing problem and is the subject of the current paper . </S>",
    "<S> we carried out a study on the performance of nine well - known classifiers implemented by the weka framework and compared the dependence of the accuracy with their configuration parameter configurations . </S>",
    "<S> the analysis of performance with default parameters revealed that the k - nearest neighbors method exceeds by a large margin the other methods when high dimensional datasets are considered . </S>",
    "<S> when other configuration of parameters were allowed , we found that it is possible to improve the quality of svm in more than 20% even if parameters are set randomly . </S>",
    "<S> taken together , the investigation conducted in this paper suggests that , apart from the svm implementation , weka s default configuration of parameters provides an performance close the one achieved with the optimal configuration .    </S>",
    "<S> = 1 </S>"
  ]
}